ID: 0 --> 1
import pandas as pd
pd.DataFrame({'A': [1, 2, 3]})

---->   pandas.DataFrame

--------------------------------------
ID: 1 --> 1
In [1]: import pandas as pd

In [2]: pd.DataFrame({'A': [1, 2, 3]})
Out[2]: 
   A
0  1
1  2
2  3

---->   pandas.DataFrame

--------------------------------------
ID: 3 --> 1
In [1]: df = pd.DataFrame(
   ...:     {
   ...:         "a": np.random.randn(1000),
   ...:         "b": np.random.randn(1000),
   ...:         "N": np.random.randint(100, 1000, (1000)),
   ...:         "x": "x",
   ...:     }
   ...: )
   ...: 

In [2]: df
Out[2]: 
            a         b    N  x
0    0.469112 -0.218470  585  x
1   -0.282863 -0.061645  841  x
2   -1.509059 -0.723780  251  x
3   -1.135632  0.551225  972  x
4    1.212112 -0.497767  181  x
..        ...       ...  ... ..
995 -1.512743  0.874737  374  x
996  0.933753  1.120790  246  x
997 -0.308013  0.198768  157  x
998 -0.079915  1.757555  977  x
999 -1.010589 -1.115680  770  x

[1000 rows x 4 columns]

---->   pandas.DataFrame

--------------------------------------
ID: 19 --> 2
In [1]: data = pd.Series(range(1_000_000))  # noqa: E225

In [2]: roll = data.rolling(10)

In [3]: def f(x):
   ...:     return np.sum(x) + 5
# Run the first time, compilation time will affect performance
In [4]: %timeit -r 1 -n 1 roll.apply(f, engine='numba', raw=True)
1.23 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)
# Function is cached and performance will improve
In [5]: %timeit roll.apply(f, engine='numba', raw=True)
188 ms ± 1.93 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)

In [6]: %timeit roll.apply(f, engine='cython', raw=True)
3.92 s ± 59 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)

---->   pandas.Series; Series.rolling

--------------------------------------
ID: 20 --> 2
In [1]: import numba

In [2]: numba.set_num_threads(1)

In [3]: df = pd.DataFrame(np.random.randn(10_000, 100))

In [4]: roll = df.rolling(100)

In [5]: %timeit roll.mean(engine="numba", engine_kwargs={"parallel": True})
347 ms ± 26 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)

In [6]: numba.set_num_threads(2)

In [7]: %timeit roll.mean(engine="numba", engine_kwargs={"parallel": True})
201 ms ± 2.97 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)

---->   pandas.DataFrame; DataFrame.rolling

--------------------------------------
ID: 21 --> 1
import numba


@numba.jit
def f_plain(x):
    return x * (x - 1)


@numba.jit
def integrate_f_numba(a, b, N):
    s = 0
    dx = (b - a) / N
    for i in range(N):
        s += f_plain(a + i * dx)
    return s * dx


@numba.jit
def apply_integrate_f_numba(col_a, col_b, col_N):
    n = len(col_N)
    result = np.empty(n, dtype="float64")
    assert len(col_a) == len(col_b) == n
    for i in range(n):
        result[i] = integrate_f_numba(col_a[i], col_b[i], col_N[i])
    return result


def compute_numba(df):
    result = apply_integrate_f_numba(
        df["a"].to_numpy(), df["b"].to_numpy(), df["N"].to_numpy()
    )
    return pd.Series(result, index=df.index, name="result")

---->   pandas.Series

--------------------------------------
ID: 25 --> 1
In [18]: nrows, ncols = 20000, 100

In [19]: df1, df2, df3, df4 = [pd.DataFrame(np.random.randn(nrows, ncols)) for _ in range(4)]

---->   pandas.DataFrame

--------------------------------------
ID: 30 --> 1
In [24]: s = pd.Series(np.random.randn(50))

In [25]: %timeit df1 + df2 + df3 + df4 + s
26.4 ms +- 416 us per loop (mean +- std. dev. of 7 runs, 10 loops each)

---->   pandas.Series

--------------------------------------
ID: 32 --> 1
In [27]: df = pd.DataFrame(np.random.randn(5, 2), columns=["a", "b"])

In [28]: df.eval("a + b")
Out[28]: 
0   -0.246747
1    0.867786
2   -1.626063
3   -1.134978
4   -1.027798
dtype: float64

---->   pandas.DataFrame

--------------------------------------
ID: 33 --> 1
In [29]: df = pd.DataFrame(dict(a=range(5), b=range(5, 10)))

In [30]: df = df.eval("c = a + b")

In [31]: df = df.eval("d = a + b + c")

In [32]: df = df.eval("a = 1")

In [33]: df
Out[33]: 
   a  b   c   d
0  1  5   5  10
1  1  6   7  14
2  1  7   9  18
3  1  8  11  22
4  1  9  13  26

---->   pandas.DataFrame

--------------------------------------
ID: 36 --> 1
In [38]: df = pd.DataFrame(dict(a=range(5), b=range(5, 10)))

In [39]: df["c"] = df["a"] + df["b"]

In [40]: df["d"] = df["a"] + df["b"] + df["c"]

In [41]: df["a"] = 1

In [42]: df
Out[42]: 
   a  b   c   d
0  1  5   5  10
1  1  6   7  14
2  1  7   9  18
3  1  8  11  22
4  1  9  13  26

---->   pandas.DataFrame

--------------------------------------
ID: 37 --> 1
In [43]: df = pd.DataFrame(np.random.randn(5, 2), columns=list("ab"))

In [44]: newcol = np.random.randn(len(df))

In [45]: df.eval("b + @newcol")
Out[45]: 
0   -0.173926
1    2.493083
2   -0.881831
3   -0.691045
4    1.334703
dtype: float64

In [46]: df.query("b < @newcol")
Out[46]: 
          a         b
0  0.863987 -0.115998
2 -2.621419 -1.297879

---->   pandas.DataFrame

--------------------------------------
ID: 45 --> 1
In [65]: df = pd.DataFrame(
   ....:     {"strings": np.repeat(list("cba"), 3), "nums": np.repeat(range(3), 3)}
   ....: )
   ....: 

In [66]: df
Out[66]: 
  strings  nums
0       c     0
1       c     0
2       c     0
3       b     1
4       b     1
5       b     1
6       a     2
7       a     2
8       a     2

In [67]: df.query("strings == 'a' and nums == 1")
Out[67]: 
Empty DataFrame
Columns: [strings, nums]
Index: []

---->   pandas.DataFrame

--------------------------------------
ID: 47 --> 3
In [3]: ts = pd.Series(np.random.randn(1000), index=pd.date_range("1/1/2000", periods=1000))

In [4]: ts = ts.cumsum()

In [5]: ts.plot();

---->   pandas.Series; Series.cumsum; Series.plot

--------------------------------------
ID: 48 --> 3
In [6]: df = pd.DataFrame(np.random.randn(1000, 4), index=ts.index, columns=list("ABCD"))

In [7]: df = df.cumsum()

In [8]: plt.figure();

In [9]: df.plot();

---->   pandas.DataFrame; DataFrame.cumsum; DataFrame.plot

--------------------------------------
ID: 49 --> 3
In [10]: df3 = pd.DataFrame(np.random.randn(1000, 2), columns=["B", "C"]).cumsum()

In [11]: df3["A"] = pd.Series(list(range(len(df))))

In [12]: df3.plot(x="A", y="B");

---->   pandas.DataFrame; pandas.Series; DataFrame.plot

--------------------------------------
ID: 51 --> 1
In [15]: df = pd.DataFrame()

In [16]: df.plot.<TAB>  # noqa: E225, E999
df.plot.area     df.plot.barh     df.plot.density  df.plot.hist     df.plot.line     df.plot.scatter
df.plot.bar      df.plot.box      df.plot.hexbin   df.plot.kde      df.plot.pie

---->   pandas.DataFrame

--------------------------------------
ID: 53 --> 2
In [20]: df2 = pd.DataFrame(np.random.rand(10, 4), columns=["a", "b", "c", "d"])

In [21]: df2.plot.bar();

---->   pandas.DataFrame; DataFrame.plot

--------------------------------------
ID: 54 --> 1
In [22]: df2.plot.bar(stacked=True);

---->   DataFrame.plot

--------------------------------------
ID: 55 --> 1
In [23]: df2.plot.barh(stacked=True);

---->   DataFrame.plot

--------------------------------------
ID: 56 --> 1
In [24]: df4 = pd.DataFrame(
   ....:     {
   ....:         "a": np.random.randn(1000) + 1,
   ....:         "b": np.random.randn(1000),
   ....:         "c": np.random.randn(1000) - 1,
   ....:     },
   ....:     columns=["a", "b", "c"],
   ....: )
   ....: 

In [25]: plt.figure();

In [26]: df4.plot.hist(alpha=0.5);

---->   pandas.DataFrame

--------------------------------------
ID: 60 --> 1
In [33]: plt.figure();

In [34]: df.diff().hist(color="k", alpha=0.5, bins=50);

---->   DataFrame.diff

--------------------------------------
ID: 61 --> 2
In [35]: data = pd.Series(np.random.randn(1000))

In [36]: data.hist(by=np.random.randint(0, 4, 1000), figsize=(6, 4));

---->   pandas.Series; Series.hist

--------------------------------------
ID: 62 --> 2
In [37]: data = pd.DataFrame(
   ....:     {
   ....:         "a": np.random.choice(["x", "y", "z"], 1000),
   ....:         "b": np.random.choice(["e", "f", "g"], 1000),
   ....:         "c": np.random.randn(1000),
   ....:         "d": np.random.randn(1000) - 1,
   ....:     },
   ....: )
   ....: 

In [38]: data.plot.hist(by=["a", "b"], figsize=(10, 5));

---->   pandas.DataFrame; Series.plot

--------------------------------------
ID: 63 --> 2
In [39]: df = pd.DataFrame(np.random.rand(10, 5), columns=["A", "B", "C", "D", "E"])

In [40]: df.plot.box();

---->   pandas.DataFrame; DataFrame.plot

--------------------------------------
ID: 64 --> 1
In [41]: color = {
   ....:     "boxes": "DarkGreen",
   ....:     "whiskers": "DarkOrange",
   ....:     "medians": "DarkBlue",
   ....:     "caps": "Gray",
   ....: }
   ....: 

In [42]: df.plot.box(color=color, sym="r+");

---->   DataFrame.plot

--------------------------------------
ID: 65 --> 1
In [43]: df.plot.box(vert=False, positions=[1, 4, 5, 6, 8]);

---->   DataFrame.plot

--------------------------------------
ID: 66 --> 2
In [44]: df = pd.DataFrame(np.random.rand(10, 5))

In [45]: plt.figure();

In [46]: bp = df.boxplot()

---->   pandas.DataFrame; DataFrame.boxplot

--------------------------------------
ID: 67 --> 3
In [47]: df = pd.DataFrame(np.random.rand(10, 2), columns=["Col1", "Col2"])

In [48]: df["X"] = pd.Series(["A", "A", "A", "A", "A", "B", "B", "B", "B", "B"])

In [49]: plt.figure();

In [50]: bp = df.boxplot(by="X")

---->   pandas.DataFrame; pandas.Series; DataFrame.boxplot

--------------------------------------
ID: 68 --> 3
In [51]: df = pd.DataFrame(np.random.rand(10, 3), columns=["Col1", "Col2", "Col3"])

In [52]: df["X"] = pd.Series(["A", "A", "A", "A", "A", "B", "B", "B", "B", "B"])

In [53]: df["Y"] = pd.Series(["A", "B", "A", "B", "A", "B", "A", "B", "A", "B"])

In [54]: plt.figure();

In [55]: bp = df.boxplot(column=["Col1", "Col2"], by=["X", "Y"])

---->   pandas.DataFrame; pandas.Series; DataFrame.boxplot

--------------------------------------
ID: 69 --> 3
In [56]: df = pd.DataFrame(np.random.rand(10, 3), columns=["Col1", "Col2", "Col3"])

In [57]: df["X"] = pd.Series(["A", "A", "A", "A", "A", "B", "B", "B", "B", "B"])

In [58]: plt.figure();

In [59]: bp = df.plot.box(column=["Col1", "Col2"], by="X")

---->   pandas.DataFrame; pandas.Series; DataFrame.plot

--------------------------------------
ID: 70 --> 2
In [60]: np.random.seed(1234)

In [61]: df_box = pd.DataFrame(np.random.randn(50, 2))

In [62]: df_box["g"] = np.random.choice(["A", "B"], size=50)

In [63]: df_box.loc[df_box["g"] == "B", 1] += 3

In [64]: bp = df_box.boxplot(by="g")

---->   pandas.DataFrame; DataFrame.boxplot

--------------------------------------
ID: 71 --> 1
In [65]: bp = df_box.groupby("g").boxplot()

---->   DataFrame.groupby

--------------------------------------
ID: 72 --> 2
In [66]: df = pd.DataFrame(np.random.rand(10, 4), columns=["a", "b", "c", "d"])

In [67]: df.plot.area();

---->   pandas.DataFrame; DataFrame.plot

--------------------------------------
ID: 73 --> 1
In [68]: df.plot.area(stacked=False);

---->   DataFrame.plot

--------------------------------------
ID: 74 --> 3
In [69]: df = pd.DataFrame(np.random.rand(50, 4), columns=["a", "b", "c", "d"])

In [70]: df["species"] = pd.Categorical(
   ....:     ["setosa"] * 20 + ["versicolor"] * 20 + ["virginica"] * 10
   ....: )
   ....: 

In [71]: df.plot.scatter(x="a", y="b");

---->   pandas.DataFrame; pandas.Categorical; DataFrame.plot

--------------------------------------
ID: 75 --> 1
In [72]: ax = df.plot.scatter(x="a", y="b", color="DarkBlue", label="Group 1")

In [73]: df.plot.scatter(x="c", y="d", color="DarkGreen", label="Group 2", ax=ax);

---->   DataFrame.plot

--------------------------------------
ID: 76 --> 1
In [74]: df.plot.scatter(x="a", y="b", c="c", s=50);

---->   DataFrame.plot

--------------------------------------
ID: 77 --> 1
In [75]: df.plot.scatter(x="a", y="b", c="species", cmap="viridis", s=50);

---->   DataFrame.plot

--------------------------------------
ID: 78 --> 1
In [76]: df.plot.scatter(x="a", y="b", s=df["c"] * 200);

---->   DataFrame.plot

--------------------------------------
ID: 79 --> 2
In [77]: df = pd.DataFrame(np.random.randn(1000, 2), columns=["a", "b"])

In [78]: df["b"] = df["b"] + np.arange(1000)

In [79]: df.plot.hexbin(x="a", y="b", gridsize=25);

---->   pandas.DataFrame; DataFrame.plot

--------------------------------------
ID: 80 --> 2
In [80]: df = pd.DataFrame(np.random.randn(1000, 2), columns=["a", "b"])

In [81]: df["b"] = df["b"] + np.arange(1000)

In [82]: df["z"] = np.random.uniform(0, 3, 1000)

In [83]: df.plot.hexbin(x="a", y="b", C="z", reduce_C_function=np.max, gridsize=25);

---->   pandas.DataFrame; DataFrame.plot

--------------------------------------
ID: 81 --> 2
In [84]: series = pd.Series(3 * np.random.rand(4), index=["a", "b", "c", "d"], name="series")

In [85]: series.plot.pie(figsize=(6, 6));

---->   pandas.Series; Series.plot

--------------------------------------
ID: 82 --> 2
In [86]: df = pd.DataFrame(
   ....:     3 * np.random.rand(4, 2), index=["a", "b", "c", "d"], columns=["x", "y"]
   ....: )
   ....: 

In [87]: df.plot.pie(subplots=True, figsize=(8, 4));

---->   pandas.DataFrame; DataFrame.plot

--------------------------------------
ID: 83 --> 1
In [88]: series.plot.pie(
   ....:     labels=["AA", "BB", "CC", "DD"],
   ....:     colors=["r", "g", "b", "c"],
   ....:     autopct="%.2f",
   ....:     fontsize=20,
   ....:     figsize=(6, 6),
   ....: );
   ....: 

---->   Series.plot

--------------------------------------
ID: 84 --> 2
In [89]: series = pd.Series([0.1] * 4, index=["a", "b", "c", "d"], name="series2")

In [90]: series.plot.pie(figsize=(6, 6));

---->   pandas.Series; Series.plot

--------------------------------------
ID: 85 --> 1
In [91]: from pandas.plotting import scatter_matrix

In [92]: df = pd.DataFrame(np.random.randn(1000, 4), columns=["a", "b", "c", "d"])

In [93]: scatter_matrix(df, alpha=0.2, figsize=(6, 6), diagonal="kde");

---->   pandas.DataFrame

--------------------------------------
ID: 86 --> 2
In [94]: ser = pd.Series(np.random.randn(1000))

In [95]: ser.plot.kde();

---->   pandas.Series; Series.plot

--------------------------------------
ID: 89 --> 1
In [104]: from pandas.plotting import lag_plot

In [105]: plt.figure();

In [106]: spacing = np.linspace(-99 * np.pi, 99 * np.pi, num=1000)

In [107]: data = pd.Series(0.1 * np.random.rand(1000) + 0.9 * np.sin(spacing))

In [108]: lag_plot(data);

---->   pandas.Series

--------------------------------------
ID: 90 --> 1
In [109]: from pandas.plotting import autocorrelation_plot

In [110]: plt.figure();

In [111]: spacing = np.linspace(-9 * np.pi, 9 * np.pi, num=1000)

In [112]: data = pd.Series(0.7 * np.random.rand(1000) + 0.3 * np.sin(spacing))

In [113]: autocorrelation_plot(data);

---->   pandas.Series

--------------------------------------
ID: 91 --> 1
In [114]: from pandas.plotting import bootstrap_plot

In [115]: data = pd.Series(np.random.rand(1000))

In [116]: bootstrap_plot(data, size=50, samples=500, color="grey");

---->   pandas.Series

--------------------------------------
ID: 93 --> 1
In [121]: plt.figure();

In [122]: ts.plot(style="k--", label="Series");

---->   Series.plot

--------------------------------------
ID: 94 --> 3
In [123]: df = pd.DataFrame(np.random.randn(1000, 4), index=ts.index, columns=list("ABCD"))

In [124]: df = df.cumsum()

In [125]: df.plot(legend=False);

---->   pandas.DataFrame; DataFrame.cumsum; DataFrame.plot

--------------------------------------
ID: 95 --> 1
In [126]: df.plot();

In [127]: df.plot(xlabel="new x", ylabel="new y");

---->   DataFrame.plot

--------------------------------------
ID: 96 --> 3
In [128]: ts = pd.Series(np.random.randn(1000), index=pd.date_range("1/1/2000", periods=1000))

In [129]: ts = np.exp(ts.cumsum())

In [130]: ts.plot(logy=True);

---->   pandas.Series; Series.cumsum; Series.plot

--------------------------------------
ID: 98 --> 1
In [133]: plt.figure();

In [134]: ax = df.plot(secondary_y=["A", "B"])

In [135]: ax.set_ylabel("CD scale");

In [136]: ax.right_ax.set_ylabel("AB scale");

---->   DataFrame.plot

--------------------------------------
ID: 99 --> 1
In [137]: plt.figure();

In [138]: df.plot(secondary_y=["A", "B"], mark_right=False);

---->   DataFrame.plot

--------------------------------------
ID: 103 --> 1
In [145]: df.plot(subplots=True, figsize=(6, 6));

---->   DataFrame.plot

--------------------------------------
ID: 104 --> 1
In [146]: df.plot(subplots=True, layout=(2, 3), figsize=(6, 6), sharex=False);

---->   DataFrame.plot

--------------------------------------
ID: 105 --> 1
In [147]: df.plot(subplots=True, layout=(2, -1), figsize=(6, 6), sharex=False);

---->   DataFrame.plot

--------------------------------------
ID: 106 --> 1
In [148]: fig, axes = plt.subplots(4, 4, figsize=(9, 9))

In [149]: plt.subplots_adjust(wspace=0.5, hspace=0.5)

In [150]: target1 = [axes[0][0], axes[1][1], axes[2][2], axes[3][3]]

In [151]: target2 = [axes[3][0], axes[2][1], axes[1][2], axes[0][3]]

In [152]: df.plot(subplots=True, ax=target1, legend=False, sharex=False, sharey=False);

In [153]: (-df).plot(subplots=True, ax=target2, legend=False, sharex=False, sharey=False);

---->   DataFrame.plot

--------------------------------------
ID: 108 --> 3
# Generate the data
In [164]: ix3 = pd.MultiIndex.from_arrays(
   .....:     [
   .....:         ["a", "a", "a", "a", "a", "b", "b", "b", "b", "b"],
   .....:         ["foo", "foo", "foo", "bar", "bar", "foo", "foo", "bar", "bar", "bar"],
   .....:     ],
   .....:     names=["letter", "word"],
   .....: )
   .....: 

In [165]: df3 = pd.DataFrame(
   .....:     {
   .....:         "data1": [9, 3, 2, 4, 3, 2, 4, 6, 3, 2],
   .....:         "data2": [9, 6, 5, 7, 5, 4, 5, 6, 5, 1],
   .....:     },
   .....:     index=ix3,
   .....: )
   .....: 

# Group by index labels and take the means and standard deviations
# for each group
In [166]: gp3 = df3.groupby(level=("letter", "word"))

In [167]: means = gp3.mean()

In [168]: errors = gp3.std()

In [169]: means
Out[169]: 
                data1     data2
letter word                    
a      bar   3.500000  6.000000
       foo   4.666667  6.666667
b      bar   3.666667  4.000000
       foo   3.000000  4.500000

In [170]: errors
Out[170]: 
                data1     data2
letter word                    
a      bar   0.707107  1.414214
       foo   3.785939  2.081666
b      bar   2.081666  2.645751
       foo   1.414214  0.707107

# Plot
In [171]: fig, ax = plt.subplots()

In [172]: means.plot.bar(yerr=errors, ax=ax, capsize=4, rot=0);

---->   pandas.MultiIndex; pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 110 --> 2
In [178]: fig, ax = plt.subplots(1, 1, figsize=(7, 6.5))

In [179]: df = pd.DataFrame(np.random.rand(5, 3), columns=["a", "b", "c"])

In [180]: ax.xaxis.tick_top()  # Display x-axis ticks on top.

In [181]: df.plot(table=True, ax=ax);

---->   pandas.DataFrame; DataFrame.plot

--------------------------------------
ID: 111 --> 1
In [182]: fig, ax = plt.subplots(1, 1, figsize=(7, 6.75))

In [183]: ax.xaxis.tick_top()  # Display x-axis ticks on top.

In [184]: df.plot(table=np.round(df.T, 2), ax=ax);

---->   DataFrame.plot

--------------------------------------
ID: 112 --> 2
In [185]: from pandas.plotting import table

In [186]: fig, ax = plt.subplots(1, 1)

In [187]: table(ax, np.round(df.describe(), 2), loc="upper right", colWidths=[0.2, 0.2, 0.2]);

In [188]: df.plot(ax=ax, ylim=(0, 2), legend=None);

---->   DataFrame.describe; DataFrame.plot

--------------------------------------
ID: 113 --> 3
In [189]: df = pd.DataFrame(np.random.randn(1000, 10), index=ts.index)

In [190]: df = df.cumsum()

In [191]: plt.figure();

In [192]: df.plot(colormap="cubehelix");

---->   pandas.DataFrame; DataFrame.cumsum; DataFrame.plot

--------------------------------------
ID: 114 --> 1
In [193]: from matplotlib import cm

In [194]: plt.figure();

In [195]: df.plot(colormap=cm.cubehelix);

---->   DataFrame.plot

--------------------------------------
ID: 115 --> 3
In [196]: dd = pd.DataFrame(np.random.randn(10, 10)).applymap(abs)

In [197]: dd = dd.cumsum()

In [198]: plt.figure();

In [199]: dd.plot.bar(colormap="Greens");

---->   pandas.DataFrame; DataFrame.cumsum; DataFrame.plot

--------------------------------------
ID: 118 --> 1
In [204]: price = pd.Series(
   .....:     np.random.randn(150).cumsum(),
   .....:     index=pd.date_range("2000-1-1", periods=150, freq="B"),
   .....: )
   .....: 

In [205]: ma = price.rolling(20).mean()

In [206]: mstd = price.rolling(20).std()

In [207]: plt.figure();

In [208]: plt.plot(price.index, price, "k");

In [209]: plt.plot(ma.index, ma, "b");

In [210]: plt.fill_between(mstd.index, ma - 2 * mstd, ma + 2 * mstd, color="b", alpha=0.2);

---->   pandas.Series

--------------------------------------
ID: 120 --> 1
>>> pd.set_option("plotting.backend", "backend.module")
>>> pd.Series([1, 2, 3]).plot()

---->   pandas.Series

--------------------------------------
ID: 121 --> 1
>>> pd.options.plotting.backend = "backend.module"
>>> pd.Series([1, 2, 3]).plot()

---->   pandas.Series

--------------------------------------
ID: 122 --> 1
>>> import backend.module
>>> backend.module.plot(pd.Series([1, 2, 3]))

---->   pandas.Series

--------------------------------------
ID: 123 --> 2
In [3]: s1 = pd.Series([0, 1, 2], index=["a", "b", "b"])

In [4]: s1.reindex(["a", "b", "c"])
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
Cell In[4], line 1
----> 1 s1.reindex(["a", "b", "c"])

File ~/work/pandas/pandas/pandas/core/series.py:4918, in Series.reindex(self, index, axis, method, copy, level, fill_value, limit, tolerance)
   4901 @doc(
   4902     NDFrame.reindex,  # type: ignore[has-type]
   4903     klass=_shared_doc_kwargs["klass"],
   (...)
   4916     tolerance=None,
   4917 ) -> Series:
-> 4918     return super().reindex(
   4919         index=index,
   4920         method=method,
   4921         copy=copy,
   4922         level=level,
   4923         fill_value=fill_value,
   4924         limit=limit,
   4925         tolerance=tolerance,
   4926     )

File ~/work/pandas/pandas/pandas/core/generic.py:5360, in NDFrame.reindex(self, labels, index, columns, axis, method, copy, level, fill_value, limit, tolerance)
   5357     return self._reindex_multi(axes, copy, fill_value)
   5359 # perform the reindex on the axes
-> 5360 return self._reindex_axes(
   5361     axes, level, limit, tolerance, method, fill_value, copy
   5362 ).__finalize__(self, method="reindex")

File ~/work/pandas/pandas/pandas/core/generic.py:5375, in NDFrame._reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy)
   5372     continue
   5374 ax = self._get_axis(a)
-> 5375 new_index, indexer = ax.reindex(
   5376     labels, level=level, limit=limit, tolerance=tolerance, method=method
   5377 )
   5379 axis = self._get_axis_number(a)
   5380 obj = obj._reindex_with_indexers(
   5381     {axis: [new_index, indexer]},
   5382     fill_value=fill_value,
   5383     copy=copy,
   5384     allow_dups=False,
   5385 )

File ~/work/pandas/pandas/pandas/core/indexes/base.py:4275, in Index.reindex(self, target, method, level, limit, tolerance)
   4272     raise ValueError("cannot handle a non-unique multi-index!")
   4273 elif not self.is_unique:
   4274     # GH#42568
-> 4275     raise ValueError("cannot reindex on an axis with duplicate labels")
   4276 else:
   4277     indexer, _ = self.get_indexer_non_unique(target)

ValueError: cannot reindex on an axis with duplicate labels

---->   pandas.Series; Index.reindex

--------------------------------------
ID: 124 --> 1
In [5]: df1 = pd.DataFrame([[0, 1, 2], [3, 4, 5]], columns=["A", "A", "B"])

In [6]: df1
Out[6]: 
   A  A  B
0  0  1  2
1  3  4  5

---->   pandas.DataFrame

--------------------------------------
ID: 125 --> 1
In [9]: df2 = pd.DataFrame({"A": [0, 1, 2]}, index=["a", "a", "b"])

In [10]: df2
Out[10]: 
   A
a  0
a  1
b  2

In [11]: df2.loc["b", "A"]  # a scalar
Out[11]: 2

In [12]: df2.loc["a", "A"]  # a Series
Out[12]: 
a    0
a    1
Name: A, dtype: int64

---->   pandas.DataFrame

--------------------------------------
ID: 128 --> 1
In [18]: df2.groupby(level=0).mean()
Out[18]: 
     A
a  0.5
b  2.0

---->   DataFrame.groupby

--------------------------------------
ID: 129 --> 1
In [19]: pd.Series([0, 1, 2], index=["a", "b", "b"]).set_flags(allows_duplicate_labels=False)
---------------------------------------------------------------------------
DuplicateLabelError                       Traceback (most recent call last)
Cell In[19], line 1
----> 1 pd.Series([0, 1, 2], index=["a", "b", "b"]).set_flags(allows_duplicate_labels=False)

File ~/work/pandas/pandas/pandas/core/generic.py:450, in NDFrame.set_flags(self, copy, allows_duplicate_labels)
    448 df = self.copy(deep=copy and not using_copy_on_write())
    449 if allows_duplicate_labels is not None:
--> 450     df.flags["allows_duplicate_labels"] = allows_duplicate_labels
    451 return df

File ~/work/pandas/pandas/pandas/core/flags.py:107, in Flags.__setitem__(self, key, value)
    105 if key not in self._keys:
    106     raise ValueError(f"Unknown flag {key}. Must be one of {self._keys}")
--> 107 setattr(self, key, value)

File ~/work/pandas/pandas/pandas/core/flags.py:94, in Flags.allows_duplicate_labels(self, value)
     92 if not value:
     93     for ax in obj.axes:
---> 94         ax._maybe_check_unique()
     96 self._allows_duplicate_labels = value

File ~/work/pandas/pandas/pandas/core/indexes/base.py:706, in Index._maybe_check_unique(self)
    703 duplicates = self._format_duplicate_message()
    704 msg += f"\n{duplicates}"
--> 706 raise DuplicateLabelError(msg)

DuplicateLabelError: Index has duplicates.
      positions
label          
b        [1, 2]

---->   pandas.Series

--------------------------------------
ID: 130 --> 1
In [20]: pd.DataFrame([[0, 1, 2], [3, 4, 5]], columns=["A", "B", "C"],).set_flags(
   ....:     allows_duplicate_labels=False
   ....: )
   ....: 
Out[20]: 
   A  B  C
0  0  1  2
1  3  4  5

---->   pandas.DataFrame

--------------------------------------
ID: 131 --> 1
In [21]: df = pd.DataFrame({"A": [0, 1, 2, 3]}, index=["x", "y", "X", "Y"]).set_flags(
   ....:     allows_duplicate_labels=False
   ....: )
   ....: 

In [22]: df
Out[22]: 
   A
x  0
y  1
X  2
Y  3

In [23]: df.flags.allows_duplicate_labels
Out[23]: False

---->   pandas.DataFrame

--------------------------------------
ID: 135 --> 2
In [29]: s1 = pd.Series(0, index=["a", "b"]).set_flags(allows_duplicate_labels=False)

In [30]: s1
Out[30]: 
a    0
b    0
dtype: int64

In [31]: s1.head().rename({"a": "b"})
---------------------------------------------------------------------------
DuplicateLabelError                       Traceback (most recent call last)
Cell In[31], line 1
----> 1 s1.head().rename({"a": "b"})

File ~/work/pandas/pandas/pandas/core/series.py:4856, in Series.rename(self, index, axis, copy, inplace, level, errors)
   4849     axis = self._get_axis_number(axis)
   4851 if callable(index) or is_dict_like(index):
   4852     # error: Argument 1 to "_rename" of "NDFrame" has incompatible
   4853     # type "Union[Union[Mapping[Any, Hashable], Callable[[Any],
   4854     # Hashable]], Hashable, None]"; expected "Union[Mapping[Any,
   4855     # Hashable], Callable[[Any], Hashable], None]"
-> 4856     return super()._rename(
   4857         index,  # type: ignore[arg-type]
   4858         copy=copy,
   4859         inplace=inplace,
   4860         level=level,
   4861         errors=errors,
   4862     )
   4863 else:
   4864     return self._set_name(index, inplace=inplace, deep=copy)

File ~/work/pandas/pandas/pandas/core/generic.py:1042, in NDFrame._rename(self, mapper, index, columns, axis, copy, inplace, level, errors)
   1040     return None
   1041 else:
-> 1042     return result.__finalize__(self, method="rename")

File ~/work/pandas/pandas/pandas/core/generic.py:5955, in NDFrame.__finalize__(self, other, method, **kwargs)
   5952 for name in other.attrs:
   5953     self.attrs[name] = other.attrs[name]
-> 5955 self.flags.allows_duplicate_labels = other.flags.allows_duplicate_labels
   5956 # For subclasses using _metadata.
   5957 for name in set(self._metadata) & set(other._metadata):

File ~/work/pandas/pandas/pandas/core/flags.py:94, in Flags.allows_duplicate_labels(self, value)
     92 if not value:
     93     for ax in obj.axes:
---> 94         ax._maybe_check_unique()
     96 self._allows_duplicate_labels = value

File ~/work/pandas/pandas/pandas/core/indexes/base.py:706, in Index._maybe_check_unique(self)
    703 duplicates = self._format_duplicate_message()
    704 msg += f"\n{duplicates}"
--> 706 raise DuplicateLabelError(msg)

DuplicateLabelError: Index has duplicates.
      positions
label          
b        [0, 1]

---->   pandas.Series; Series.head

--------------------------------------
ID: 136 --> 1
In [1]: dates = pd.date_range('1/1/2000', periods=8)

In [2]: df = pd.DataFrame(np.random.randn(8, 4),
   ...:                   index=dates, columns=['A', 'B', 'C', 'D'])
   ...: 

In [3]: df
Out[3]: 
                   A         B         C         D
2000-01-01  0.469112 -0.282863 -1.509059 -1.135632
2000-01-02  1.212112 -0.173215  0.119209 -1.044236
2000-01-03 -0.861849 -2.104569 -0.494929  1.071804
2000-01-04  0.721555 -0.706771 -1.039575  0.271860
2000-01-05 -0.424972  0.567020  0.276232 -1.087401
2000-01-06 -0.673690  0.113648 -1.478427  0.524988
2000-01-07  0.404705  0.577046 -1.715002 -1.039268
2000-01-08 -0.370647 -1.157892 -1.344312  0.844885

---->   pandas.DataFrame

--------------------------------------
ID: 138 --> 2
In [14]: sa = pd.Series([1, 2, 3], index=list('abc'))

In [15]: dfa = df.copy()

---->   pandas.Series; DataFrame.copy

--------------------------------------
ID: 140 --> 1
In [24]: x = pd.DataFrame({'x': [1, 2, 3], 'y': [3, 4, 5]})

In [25]: x.iloc[1] = {'x': 9, 'y': 99}

In [26]: x
Out[26]: 
   x   y
0  1   3
1  9  99
2  3   5

---->   pandas.DataFrame

--------------------------------------
ID: 141 --> 1
In [1]: df = pd.DataFrame({'one': [1., 2., 3.]})
In [2]: df.two = [4, 5, 6]
UserWarning: Pandas doesn't allow Series to be assigned into nonexistent columns - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute_access
In [3]: df
Out[3]:
   one
0  1.0
1  2.0
2  3.0

---->   pandas.DataFrame

--------------------------------------
ID: 142 --> 1
In [30]: s2 = s.copy()

In [31]: s2[:5] = 0

In [32]: s2
Out[32]: 
2000-01-01    0.000000
2000-01-02    0.000000
2000-01-03    0.000000
2000-01-04    0.000000
2000-01-05    0.000000
2000-01-06   -0.673690
2000-01-07    0.404705
2000-01-08   -0.370647
Freq: D, Name: A, dtype: float64

---->   Series.copy

--------------------------------------
ID: 143 --> 1
In [35]: dfl = pd.DataFrame(np.random.randn(5, 4),
   ....:                    columns=list('ABCD'),
   ....:                    index=pd.date_range('20130101', periods=5))
   ....: 

In [36]: dfl
Out[36]: 
                   A         B         C         D
2013-01-01  1.075770 -0.109050  1.643563 -1.469388
2013-01-02  0.357021 -0.674600 -1.776904 -0.968914
2013-01-03 -1.294524  0.413738  0.276662 -0.472035
2013-01-04 -0.013960 -0.362543 -0.006154 -0.923061
2013-01-05  0.895717  0.805244 -1.206412  2.565646

---->   pandas.DataFrame

--------------------------------------
ID: 144 --> 1
In [38]: s1 = pd.Series(np.random.randn(6), index=list('abcdef'))

In [39]: s1
Out[39]: 
a    1.431256
b    1.340309
c   -1.170299
d   -0.226169
e    0.410835
f    0.813850
dtype: float64

In [40]: s1.loc['c':]
Out[40]: 
c   -1.170299
d   -0.226169
e    0.410835
f    0.813850
dtype: float64

In [41]: s1.loc['b']
Out[41]: 1.3403088497993827

---->   pandas.Series

--------------------------------------
ID: 145 --> 1
In [44]: df1 = pd.DataFrame(np.random.randn(6, 4),
   ....:                    index=list('abcdef'),
   ....:                    columns=list('ABCD'))
   ....: 

In [45]: df1
Out[45]: 
          A         B         C         D
a  0.132003 -0.827317 -0.076467 -1.187678
b  1.130127 -1.436737 -1.413681  1.607920
c  1.024180  0.569605  0.875906 -2.211372
d  0.974466 -2.006747 -0.410001 -0.078638
e  0.545952 -1.219217 -1.226825  0.769804
f -1.281247 -0.727707 -0.121306 -0.097883

In [46]: df1.loc[['a', 'b', 'd'], :]
Out[46]: 
          A         B         C         D
a  0.132003 -0.827317 -0.076467 -1.187678
b  1.130127 -1.436737 -1.413681  1.607920
d  0.974466 -2.006747 -0.410001 -0.078638

---->   pandas.DataFrame

--------------------------------------
ID: 146 --> 1
In [51]: mask = pd.array([True, False, True, False, pd.NA, False], dtype="boolean")

In [52]: mask
Out[52]: 

[True, False, True, False, , False]
Length: 6, dtype: boolean

In [53]: df1[mask]
Out[53]: 
          A         B         C         D
a  0.132003 -0.827317 -0.076467 -1.187678
c  1.024180  0.569605  0.875906 -2.211372

---->   pandas.array

--------------------------------------
ID: 147 --> 1
In [55]: s = pd.Series(list('abcde'), index=[0, 3, 2, 5, 4])

In [56]: s.loc[3:5]
Out[56]: 
3    b
2    c
5    d
dtype: object

---->   pandas.Series

--------------------------------------
ID: 149 --> 1
In [59]: s = pd.Series(list('abcdef'), index=[0, 3, 2, 5, 4, 2])

In [60]: s.loc[3:5]
Out[60]: 
3    b
2    c
5    d
dtype: object

---->   pandas.Series

--------------------------------------
ID: 150 --> 1
In [61]: s1 = pd.Series(np.random.randn(5), index=list(range(0, 10, 2)))

In [62]: s1
Out[62]: 
0    0.695775
2    0.341734
4    0.959726
6   -1.110336
8   -0.619976
dtype: float64

In [63]: s1.iloc[:3]
Out[63]: 
0    0.695775
2    0.341734
4    0.959726
dtype: float64

In [64]: s1.iloc[3]
Out[64]: -1.110336102891167

---->   pandas.Series

--------------------------------------
ID: 151 --> 1
In [67]: df1 = pd.DataFrame(np.random.randn(6, 4),
   ....:                    index=list(range(0, 12, 2)),
   ....:                    columns=list(range(0, 8, 2)))
   ....: 

In [68]: df1
Out[68]: 
           0         2         4         6
0   0.149748 -0.732339  0.687738  0.176444
2   0.403310 -0.154951  0.301624 -2.179861
4  -1.369849 -0.954208  1.462696 -1.743161
6  -0.826591 -0.345352  1.314232  0.690579
8   0.995761  2.396780  0.014871  3.357427
10 -0.317441 -1.236269  0.896171 -0.487602

---->   pandas.DataFrame

--------------------------------------
ID: 152 --> 1
# these are allowed in Python/NumPy.
In [76]: x = list('abcdef')

In [77]: x
Out[77]: ['a', 'b', 'c', 'd', 'e', 'f']

In [78]: x[4:10]
Out[78]: ['e', 'f']

In [79]: x[8:10]
Out[79]: []

In [80]: s = pd.Series(x)

In [81]: s
Out[81]: 
0    a
1    b
2    c
3    d
4    e
5    f
dtype: object

In [82]: s.iloc[4:10]
Out[82]: 
4    e
5    f
dtype: object

In [83]: s.iloc[8:10]
Out[83]: Series([], dtype: object)

---->   pandas.Series

--------------------------------------
ID: 153 --> 1
In [84]: dfl = pd.DataFrame(np.random.randn(5, 2), columns=list('AB'))

In [85]: dfl
Out[85]: 
          A         B
0 -0.082240 -2.182937
1  0.380396  0.084844
2  0.432390  1.519970
3 -0.493662  0.600178
4  0.274230  0.132885

In [86]: dfl.iloc[:, 2:3]
Out[86]: 
Empty DataFrame
Columns: []
Index: [0, 1, 2, 3, 4]

In [87]: dfl.iloc[:, 1:3]
Out[87]: 
          B
0 -2.182937
1  0.084844
2  1.519970
3  0.600178
4  0.132885

In [88]: dfl.iloc[4:6]
Out[88]: 
         A         B
4  0.27423  0.132885

---->   pandas.DataFrame

--------------------------------------
ID: 154 --> 1
In [89]: df1 = pd.DataFrame(np.random.randn(6, 4),
   ....:                    index=list('abcdef'),
   ....:                    columns=list('ABCD'))
   ....: 

In [90]: df1
Out[90]: 
          A         B         C         D
a -0.023688  2.410179  1.450520  0.206053
b -0.251905 -2.213588  1.063327  1.266143
c  0.299368 -0.863838  0.408204 -1.048089
d -0.025747 -0.988387  0.094055  1.262731
e  1.289997  0.082423 -0.055758  0.536580
f -0.489682  0.369374 -0.034571 -2.484478

In [91]: df1.loc[lambda df: df['A'] > 0, :]
Out[91]: 
          A         B         C         D
c  0.299368 -0.863838  0.408204 -1.048089
e  1.289997  0.082423 -0.055758  0.536580

In [92]: df1.loc[:, lambda df: ['A', 'B']]
Out[92]: 
          A         B
a -0.023688  2.410179
b -0.251905 -2.213588
c  0.299368 -0.863838
d -0.025747 -0.988387
e  1.289997  0.082423
f -0.489682  0.369374

In [93]: df1.iloc[:, lambda df: [0, 1]]
Out[93]: 
          A         B
a -0.023688  2.410179
b -0.251905 -2.213588
c  0.299368 -0.863838
d -0.025747 -0.988387
e  1.289997  0.082423
f -0.489682  0.369374

In [94]: df1[lambda df: df.columns[0]]
Out[94]: 
a   -0.023688
b   -0.251905
c    0.299368
d   -0.025747
e    1.289997
f   -0.489682
Name: A, dtype: float64

---->   pandas.DataFrame

--------------------------------------
ID: 156 --> 1
In [98]: dfd = pd.DataFrame({'A': [1, 2, 3],
   ....:                     'B': [4, 5, 6]},
   ....:                    index=list('abc'))
   ....: 

In [99]: dfd
Out[99]: 
   A  B
a  1  4
b  2  5
c  3  6

In [100]: dfd.loc[dfd.index[[0, 2]], 'A']
Out[100]: 
a    1
c    3
Name: A, dtype: int64

---->   pandas.DataFrame

--------------------------------------
ID: 159 --> 1
In [103]: s = pd.Series([1, 2, 3])

In [104]: s
Out[104]: 
0    1
1    2
2    3
dtype: int64

---->   pandas.Series

--------------------------------------
ID: 163 --> 1
In [109]: s = pd.Series(np.arange(4), index=['a', 'a', 'b', 'c'])

In [110]: labels = ['c', 'd']

---->   pandas.Series

--------------------------------------
ID: 167 --> 2
In [112]: s = pd.Series([0, 1, 2, 3, 4, 5])

# When no arguments are passed, returns 1 row.
In [113]: s.sample()
Out[113]: 
4    4
dtype: int64

# One may specify either a number of rows:
In [114]: s.sample(n=3)
Out[114]: 
0    0
4    4
1    1
dtype: int64

# Or a fraction of the rows:
In [115]: s.sample(frac=0.5)
Out[115]: 
5    5
3    3
1    1
dtype: int64

---->   pandas.Series; Series.sample

--------------------------------------
ID: 168 --> 2
In [116]: s = pd.Series([0, 1, 2, 3, 4, 5])

# Without replacement (default):
In [117]: s.sample(n=6, replace=False)
Out[117]: 
0    0
1    1
5    5
3    3
2    2
4    4
dtype: int64

# With replacement:
In [118]: s.sample(n=6, replace=True)
Out[118]: 
0    0
4    4
3    3
2    2
4    4
4    4
dtype: int64

---->   pandas.Series; Series.sample

--------------------------------------
ID: 169 --> 2
In [119]: s = pd.Series([0, 1, 2, 3, 4, 5])

In [120]: example_weights = [0, 0, 0.2, 0.2, 0.2, 0.4]

In [121]: s.sample(n=3, weights=example_weights)
Out[121]: 
5    5
4    4
3    3
dtype: int64

# Weights will be re-normalized automatically
In [122]: example_weights2 = [0.5, 0, 0, 0, 0, 0]

In [123]: s.sample(n=1, weights=example_weights2)
Out[123]: 
0    0
dtype: int64

---->   pandas.Series; Series.sample

--------------------------------------
ID: 170 --> 2
In [124]: df2 = pd.DataFrame({'col1': [9, 8, 7, 6],
   .....:                     'weight_column': [0.5, 0.4, 0.1, 0]})
   .....: 

In [125]: df2.sample(n=3, weights='weight_column')
Out[125]: 
   col1  weight_column
1     8            0.4
0     9            0.5
2     7            0.1

---->   pandas.DataFrame; DataFrame.sample

--------------------------------------
ID: 171 --> 2
In [126]: df3 = pd.DataFrame({'col1': [1, 2, 3], 'col2': [2, 3, 4]})

In [127]: df3.sample(n=1, axis=1)
Out[127]: 
   col1
0     1
1     2
2     3

---->   pandas.DataFrame; DataFrame.sample

--------------------------------------
ID: 172 --> 2
In [128]: df4 = pd.DataFrame({'col1': [1, 2, 3], 'col2': [2, 3, 4]})

# With a given seed, the sample will always draw the same rows.
In [129]: df4.sample(n=2, random_state=2)
Out[129]: 
   col1  col2
2     3     4
1     2     3

In [130]: df4.sample(n=2, random_state=2)
Out[130]: 
   col1  col2
2     3     4
1     2     3

---->   pandas.DataFrame; DataFrame.sample

--------------------------------------
ID: 173 --> 1
In [131]: se = pd.Series([1, 2, 3])

In [132]: se
Out[132]: 
0    1
1    2
2    3
dtype: int64

In [133]: se[5] = 5.

In [134]: se
Out[134]: 
0    1.0
1    2.0
2    3.0
5    5.0
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 174 --> 1
In [135]: dfi = pd.DataFrame(np.arange(6).reshape(3, 2),
   .....:                    columns=['A', 'B'])
   .....: 

In [136]: dfi
Out[136]: 
   A  B
0  0  1
1  2  3
2  4  5

In [137]: dfi.loc[:, 'C'] = dfi.loc[:, 'A']

In [138]: dfi
Out[138]: 
   A  B  C
0  0  1  0
1  2  3  2
2  4  5  4

---->   pandas.DataFrame

--------------------------------------
ID: 176 --> 1
In [148]: s = pd.Series(range(-3, 4))

In [149]: s
Out[149]: 
0   -3
1   -2
2   -1
3    0
4    1
5    2
6    3
dtype: int64

In [150]: s[s > 0]
Out[150]: 
4    1
5    2
6    3
dtype: int64

In [151]: s[(s < -1) | (s > 0.5)]
Out[151]: 
0   -3
1   -2
4    1
5    2
6    3
dtype: int64

In [152]: s[~(s < 0)]
Out[152]: 
3    0
4    1
5    2
6    3
dtype: int64

---->   pandas.Series

--------------------------------------
ID: 177 --> 1
In [154]: df2 = pd.DataFrame({'a': ['one', 'one', 'two', 'three', 'two', 'one', 'six'],
   .....:                     'b': ['x', 'y', 'y', 'x', 'y', 'x', 'x'],
   .....:                     'c': np.random.randn(7)})
   .....: 

# only want 'two' or 'three'
In [155]: criterion = df2['a'].map(lambda x: x.startswith('t'))

In [156]: df2[criterion]
Out[156]: 
       a  b         c
2    two  y  0.041290
3  three  x  0.361719
4    two  y -0.238075

# equivalent but slower
In [157]: df2[[x.startswith('t') for x in df2['a']]]
Out[157]: 
       a  b         c
2    two  y  0.041290
3  three  x  0.361719
4    two  y -0.238075

# Multiple criteria
In [158]: df2[criterion & (df2['b'] == 'x')]
Out[158]: 
       a  b         c
3  three  x  0.361719

---->   pandas.DataFrame

--------------------------------------
ID: 179 --> 1
In [160]: df = pd.DataFrame([[1, 2], [3, 4], [5, 6]],
   .....:                   index=list('abc'),
   .....:                   columns=['A', 'B'])
   .....: 

In [161]: s = (df['A'] > 2)

In [162]: s
Out[162]: 
a    False
b     True
c     True
Name: A, dtype: bool

In [163]: df.loc[s, 'B']
Out[163]: 
b    4
c    6
Name: B, dtype: int64

In [164]: df.iloc[s.values, 1]
Out[164]: 
b    4
c    6
Name: B, dtype: int64

---->   pandas.DataFrame

--------------------------------------
ID: 180 --> 2
In [165]: s = pd.Series(np.arange(5), index=np.arange(5)[::-1], dtype='int64')

In [166]: s
Out[166]: 
4    0
3    1
2    2
1    3
0    4
dtype: int64

In [167]: s.isin([2, 4, 6])
Out[167]: 
4    False
3    False
2     True
1    False
0     True
dtype: bool

In [168]: s[s.isin([2, 4, 6])]
Out[168]: 
2    2
0    4
dtype: int64

---->   pandas.Series; Series.isin

--------------------------------------
ID: 182 --> 2
In [171]: s_mi = pd.Series(np.arange(6),
   .....:                  index=pd.MultiIndex.from_product([[0, 1], ['a', 'b', 'c']]))
   .....: 

In [172]: s_mi
Out[172]: 
0  a    0
   b    1
   c    2
1  a    3
   b    4
   c    5
dtype: int64

In [173]: s_mi.iloc[s_mi.index.isin([(1, 'a'), (2, 'b'), (0, 'c')])]
Out[173]: 
0  c    2
1  a    3
dtype: int64

In [174]: s_mi.iloc[s_mi.index.isin(['a', 'c', 'e'], level=1)]
Out[174]: 
0  a    0
   c    2
1  a    3
   c    5
dtype: int64

---->   pandas.Series; pandas.MultiIndex

--------------------------------------
ID: 183 --> 2
In [175]: df = pd.DataFrame({'vals': [1, 2, 3, 4], 'ids': ['a', 'b', 'f', 'n'],
   .....:                    'ids2': ['a', 'n', 'c', 'n']})
   .....: 

In [176]: values = ['a', 'b', 1, 3]

In [177]: df.isin(values)
Out[177]: 
    vals    ids   ids2
0   True   True   True
1  False   True  False
2   True  False  False
3  False  False  False

---->   pandas.DataFrame; DataFrame.isin

--------------------------------------
ID: 184 --> 1
In [178]: values = {'ids': ['a', 'b'], 'vals': [1, 3]}

In [179]: df.isin(values)
Out[179]: 
    vals    ids   ids2
0   True   True  False
1  False   True  False
2   True  False  False
3  False  False  False

---->   DataFrame.isin

--------------------------------------
ID: 185 --> 1
In [180]: values = {'ids': ['a', 'b'], 'vals': [1, 3]}

In [181]: ~df.isin(values)
Out[181]: 
    vals    ids  ids2
0  False  False  True
1   True  False  True
2  False   True  True
3   True   True  True

---->   DataFrame.isin

--------------------------------------
ID: 186 --> 1
In [182]: values = {'ids': ['a', 'b'], 'ids2': ['a', 'c'], 'vals': [1, 3]}

In [183]: row_mask = df.isin(values).all(1)

In [184]: df[row_mask]
Out[184]: 
   vals ids ids2
0     1   a    a

---->   DataFrame.isin

--------------------------------------
ID: 189 --> 2
In [189]: s2 = s.copy()

In [190]: s2[s2 < 0] = 0

In [191]: s2
Out[191]: 
4    0
3    1
2    2
1    3
0    4
dtype: int64

In [192]: df2 = df.copy()

In [193]: df2[df2 < 0] = 0

In [194]: df2
Out[194]: 
                   A         B         C         D
2000-01-01  0.000000  0.000000  0.485855  0.245166
2000-01-02  0.000000  0.390389  0.000000  1.655824
2000-01-03  0.000000  0.299674  0.000000  0.281059
2000-01-04  0.846958  0.000000  0.600705  0.000000
2000-01-05  0.669692  0.000000  0.000000  0.342416
2000-01-06  0.868584  0.000000  2.297780  0.000000
2000-01-07  0.000000  0.000000  0.168904  0.000000
2000-01-08  0.801196  1.392071  0.000000  0.000000

---->   Series.copy; DataFrame.copy

--------------------------------------
ID: 191 --> 1
In [196]: df2 = df.copy()

In [197]: df2[df2[1:4] > 0] = 3

In [198]: df2
Out[198]: 
                   A         B         C         D
2000-01-01 -2.104139 -1.309525  0.485855  0.245166
2000-01-02 -0.352480  3.000000 -1.192319  3.000000
2000-01-03 -0.864883  3.000000 -0.227870  3.000000
2000-01-04  3.000000 -1.222082  3.000000 -1.233203
2000-01-05  0.669692 -0.605656 -1.169184  0.342416
2000-01-06  0.868584 -0.948458  2.297780 -0.684718
2000-01-07 -2.670153 -0.114722  0.168904 -0.048048
2000-01-08  0.801196  1.392071 -0.048788 -0.808838

---->   DataFrame.copy

--------------------------------------
ID: 192 --> 1
In [199]: df2 = df.copy()

In [200]: df2.where(df2 > 0, df2['A'], axis='index')
Out[200]: 
                   A         B         C         D
2000-01-01 -2.104139 -2.104139  0.485855  0.245166
2000-01-02 -0.352480  0.390389 -0.352480  1.655824
2000-01-03 -0.864883  0.299674 -0.864883  0.281059
2000-01-04  0.846958  0.846958  0.600705  0.846958
2000-01-05  0.669692  0.669692  0.669692  0.342416
2000-01-06  0.868584  0.868584  2.297780  0.868584
2000-01-07 -2.670153 -2.670153  0.168904 -2.670153
2000-01-08  0.801196  1.392071  0.801196  0.801196

---->   DataFrame.copy

--------------------------------------
ID: 193 --> 1
In [201]: df2 = df.copy()

In [202]: df.apply(lambda x, y: x.where(x > 0, y), y=df['A'])
Out[202]: 
                   A         B         C         D
2000-01-01 -2.104139 -2.104139  0.485855  0.245166
2000-01-02 -0.352480  0.390389 -0.352480  1.655824
2000-01-03 -0.864883  0.299674 -0.864883  0.281059
2000-01-04  0.846958  0.846958  0.600705  0.846958
2000-01-05  0.669692  0.669692  0.669692  0.342416
2000-01-06  0.868584  0.868584  2.297780  0.868584
2000-01-07 -2.670153 -2.670153  0.168904 -2.670153
2000-01-08  0.801196  1.392071  0.801196  0.801196

---->   DataFrame.copy

--------------------------------------
ID: 194 --> 1
In [203]: df3 = pd.DataFrame({'A': [1, 2, 3],
   .....:                     'B': [4, 5, 6],
   .....:                     'C': [7, 8, 9]})
   .....: 

In [204]: df3.where(lambda x: x > 4, lambda x: x + 10)
Out[204]: 
    A   B  C
0  11  14  7
1  12   5  8
2  13   6  9

---->   pandas.DataFrame

--------------------------------------
ID: 196 --> 1
In [207]: df = pd.DataFrame({'col1': list('ABBC'), 'col2': list('ZZXY')})

In [208]: df['color'] = np.where(df['col2'] == 'Z', 'green', 'red')

In [209]: df
Out[209]: 
  col1 col2  color
0    A    Z  green
1    B    Z  green
2    B    X    red
3    C    Y    red

---->   pandas.DataFrame

--------------------------------------
ID: 198 --> 1
In [214]: n = 10

In [215]: df = pd.DataFrame(np.random.rand(n, 3), columns=list('abc'))

In [216]: df
Out[216]: 
          a         b         c
0  0.438921  0.118680  0.863670
1  0.138138  0.577363  0.686602
2  0.595307  0.564592  0.520630
3  0.913052  0.926075  0.616184
4  0.078718  0.854477  0.898725
5  0.076404  0.523211  0.591538
6  0.792342  0.216974  0.564056
7  0.397890  0.454131  0.915716
8  0.074315  0.437913  0.019794
9  0.559209  0.502065  0.026437

# pure python
In [217]: df[(df['a'] < df['b']) & (df['b'] < df['c'])]
Out[217]: 
          a         b         c
1  0.138138  0.577363  0.686602
4  0.078718  0.854477  0.898725
5  0.076404  0.523211  0.591538
7  0.397890  0.454131  0.915716

# query
In [218]: df.query('(a < b) & (b < c)')
Out[218]: 
          a         b         c
1  0.138138  0.577363  0.686602
4  0.078718  0.854477  0.898725
5  0.076404  0.523211  0.591538
7  0.397890  0.454131  0.915716

---->   pandas.DataFrame

--------------------------------------
ID: 199 --> 1
In [219]: df = pd.DataFrame(np.random.randint(n / 2, size=(n, 2)), columns=list('bc'))

In [220]: df.index.name = 'a'

In [221]: df
Out[221]: 
   b  c
a      
0  0  4
1  0  1
2  3  4
3  4  3
4  1  4
5  0  3
6  0  1
7  3  4
8  2  3
9  1  1

In [222]: df.query('a < b and b < c')
Out[222]: 
   b  c
a      
2  3  4

---->   pandas.DataFrame

--------------------------------------
ID: 200 --> 1
In [223]: df = pd.DataFrame(np.random.randint(n, size=(n, 2)), columns=list('bc'))

In [224]: df
Out[224]: 
   b  c
0  3  1
1  3  0
2  5  6
3  5  2
4  7  4
5  0  1
6  2  5
7  0  1
8  6  0
9  7  9

In [225]: df.query('index < b < c')
Out[225]: 
   b  c
2  5  6

---->   pandas.DataFrame

--------------------------------------
ID: 201 --> 1
In [226]: df = pd.DataFrame({'a': np.random.randint(5, size=5)})

In [227]: df.index.name = 'a'

In [228]: df.query('a > 2')  # uses the column 'a', not the index
Out[228]: 
   a
a   
1  3
3  3

---->   pandas.DataFrame

--------------------------------------
ID: 203 --> 2
In [230]: n = 10

In [231]: colors = np.random.choice(['red', 'green'], size=n)

In [232]: foods = np.random.choice(['eggs', 'ham'], size=n)

In [233]: colors
Out[233]: 
array(['red', 'red', 'red', 'green', 'green', 'green', 'green', 'green',
       'green', 'green'], dtype='

In [234]: foods
Out[234]: 
array(['ham', 'ham', 'eggs', 'eggs', 'eggs', 'ham', 'ham', 'eggs', 'eggs',
       'eggs'], dtype='

In [235]: index = pd.MultiIndex.from_arrays([colors, foods], names=['color', 'food'])

In [236]: df = pd.DataFrame(np.random.randn(n, 2), index=index)

In [237]: df
Out[237]: 
                   0         1
color food                    
red   ham   0.194889 -0.381994
      ham   0.318587  2.089075
      eggs -0.728293 -0.090255
green eggs -0.748199  1.318931
      eggs -2.029766  0.792652
      ham   0.461007 -0.542749
      ham  -0.305384 -0.479195
      eggs  0.095031 -0.270099
      eggs -0.707140 -0.773882
      eggs  0.229453  0.304418

In [238]: df.query('color == "red"')
Out[238]: 
                   0         1
color food                    
red   ham   0.194889 -0.381994
      ham   0.318587  2.089075
      eggs -0.728293 -0.090255

---->   pandas.MultiIndex; pandas.DataFrame

--------------------------------------
ID: 205 --> 1
In [242]: df = pd.DataFrame(np.random.rand(n, 3), columns=list('abc'))

In [243]: df
Out[243]: 
          a         b         c
0  0.224283  0.736107  0.139168
1  0.302827  0.657803  0.713897
2  0.611185  0.136624  0.984960
3  0.195246  0.123436  0.627712
4  0.618673  0.371660  0.047902
5  0.480088  0.062993  0.185760
6  0.568018  0.483467  0.445289
7  0.309040  0.274580  0.587101
8  0.258993  0.477769  0.370255
9  0.550459  0.840870  0.304611

In [244]: df2 = pd.DataFrame(np.random.rand(n + 2, 3), columns=df.columns)

In [245]: df2
Out[245]: 
           a         b         c
0   0.357579  0.229800  0.596001
1   0.309059  0.957923  0.965663
2   0.123102  0.336914  0.318616
3   0.526506  0.323321  0.860813
4   0.518736  0.486514  0.384724
5   0.190804  0.505723  0.614533
6   0.891939  0.623977  0.676639
7   0.480559  0.378528  0.460858
8   0.420223  0.136404  0.141295
9   0.732206  0.419540  0.604675
10  0.604466  0.848974  0.896165
11  0.589168  0.920046  0.732716

In [246]: expr = '0.0 <= a <= c <= 0.5'

In [247]: map(lambda frame: frame.query(expr), [df, df2])
Out[247]: 

---->   pandas.DataFrame

--------------------------------------
ID: 206 --> 1
In [248]: df = pd.DataFrame(np.random.randint(n, size=(n, 3)), columns=list('abc'))

In [249]: df
Out[249]: 
   a  b  c
0  7  8  9
1  1  0  7
2  2  7  2
3  6  2  2
4  2  6  3
5  3  8  2
6  1  7  2
7  5  1  5
8  9  8  0
9  1  5  0

In [250]: df.query('(a < b) & (b < c)')
Out[250]: 
   a  b  c
0  7  8  9

In [251]: df[(df['a'] < df['b']) & (df['b'] < df['c'])]
Out[251]: 
   a  b  c
0  7  8  9

---->   pandas.DataFrame

--------------------------------------
ID: 210 --> 1
# get all rows where columns "a" and "b" have overlapping values
In [255]: df = pd.DataFrame({'a': list('aabbccddeeff'), 'b': list('aaaabbbbcccc'),
   .....:                    'c': np.random.randint(5, size=12),
   .....:                    'd': np.random.randint(9, size=12)})
   .....: 

In [256]: df
Out[256]: 
    a  b  c  d
0   a  a  2  6
1   a  a  4  7
2   b  a  1  6
3   b  a  2  1
4   c  b  3  6
5   c  b  0  2
6   d  b  3  3
7   d  b  2  1
8   e  c  4  3
9   e  c  2  0
10  f  c  0  6
11  f  c  1  2

In [257]: df.query('a in b')
Out[257]: 
   a  b  c  d
0  a  a  2  6
1  a  a  4  7
2  b  a  1  6
3  b  a  2  1
4  c  b  3  6
5  c  b  0  2

# How you'd do it in pure Python
In [258]: df[df['a'].isin(df['b'])]
Out[258]: 
   a  b  c  d
0  a  a  2  6
1  a  a  4  7
2  b  a  1  6
3  b  a  2  1
4  c  b  3  6
5  c  b  0  2

In [259]: df.query('a not in b')
Out[259]: 
    a  b  c  d
6   d  b  3  3
7   d  b  2  1
8   e  c  4  3
9   e  c  2  0
10  f  c  0  6
11  f  c  1  2

# pure Python
In [260]: df[~df['a'].isin(df['b'])]
Out[260]: 
    a  b  c  d
6   d  b  3  3
7   d  b  2  1
8   e  c  4  3
9   e  c  2  0
10  f  c  0  6
11  f  c  1  2

---->   pandas.DataFrame

--------------------------------------
ID: 214 --> 1
In [270]: df = pd.DataFrame(np.random.rand(n, 3), columns=list('abc'))

In [271]: df['bools'] = np.random.rand(len(df)) > 0.5

In [272]: df.query('~bools')
Out[272]: 
          a         b         c  bools
2  0.697753  0.212799  0.329209  False
7  0.275396  0.691034  0.826619  False
8  0.190649  0.558748  0.262467  False

In [273]: df.query('not bools')
Out[273]: 
          a         b         c  bools
2  0.697753  0.212799  0.329209  False
7  0.275396  0.691034  0.826619  False
8  0.190649  0.558748  0.262467  False

In [274]: df.query('not bools') == df[~df['bools']]
Out[274]: 
      a     b     c  bools
2  True  True  True   True
7  True  True  True   True
8  True  True  True   True

---->   pandas.DataFrame

--------------------------------------
ID: 216 --> 2
In [280]: df2 = pd.DataFrame({'a': ['one', 'one', 'two', 'two', 'two', 'three', 'four'],
   .....:                     'b': ['x', 'y', 'x', 'y', 'x', 'x', 'x'],
   .....:                     'c': np.random.randn(7)})
   .....: 

In [281]: df2
Out[281]: 
       a  b         c
0    one  x -1.067137
1    one  y  0.309500
2    two  x -0.211056
3    two  y -1.842023
4    two  x -0.390820
5  three  x -1.964475
6   four  x  1.298329

In [282]: df2.duplicated('a')
Out[282]: 
0    False
1     True
2    False
3     True
4     True
5    False
6    False
dtype: bool

In [283]: df2.duplicated('a', keep='last')
Out[283]: 
0     True
1    False
2     True
3     True
4    False
5    False
6    False
dtype: bool

In [284]: df2.duplicated('a', keep=False)
Out[284]: 
0     True
1     True
2     True
3     True
4     True
5    False
6    False
dtype: bool

In [285]: df2.drop_duplicates('a')
Out[285]: 
       a  b         c
0    one  x -1.067137
2    two  x -0.211056
5  three  x -1.964475
6   four  x  1.298329

In [286]: df2.drop_duplicates('a', keep='last')
Out[286]: 
       a  b         c
1    one  y  0.309500
4    two  x -0.390820
5  three  x -1.964475
6   four  x  1.298329

In [287]: df2.drop_duplicates('a', keep=False)
Out[287]: 
       a  b         c
5  three  x -1.964475
6   four  x  1.298329

---->   pandas.DataFrame; DataFrame.duplicated

--------------------------------------
ID: 217 --> 1
In [288]: df2.duplicated(['a', 'b'])
Out[288]: 
0    False
1    False
2    False
3    False
4     True
5    False
6    False
dtype: bool

In [289]: df2.drop_duplicates(['a', 'b'])
Out[289]: 
       a  b         c
0    one  x -1.067137
1    one  y  0.309500
2    two  x -0.211056
3    two  y -1.842023
5  three  x -1.964475
6   four  x  1.298329

---->   DataFrame.duplicated

--------------------------------------
ID: 218 --> 1
In [290]: df3 = pd.DataFrame({'a': np.arange(6),
   .....:                     'b': np.random.randn(6)},
   .....:                    index=['a', 'a', 'b', 'c', 'b', 'a'])
   .....: 

In [291]: df3
Out[291]: 
   a         b
a  0  1.440455
a  1  2.456086
b  2  1.038402
c  3 -0.894409
b  4  0.683536
a  5  3.082764

In [292]: df3.index.duplicated()
Out[292]: array([False,  True, False, False,  True,  True])

In [293]: df3[~df3.index.duplicated()]
Out[293]: 
   a         b
a  0  1.440455
b  2  1.038402
c  3 -0.894409

In [294]: df3[~df3.index.duplicated(keep='last')]
Out[294]: 
   a         b
c  3 -0.894409
b  4  0.683536
a  5  3.082764

In [295]: df3[~df3.index.duplicated(keep=False)]
Out[295]: 
   a         b
c  3 -0.894409

---->   pandas.DataFrame

--------------------------------------
ID: 219 --> 2
In [296]: s = pd.Series([1, 2, 3], index=['a', 'b', 'c'])

In [297]: s.get('a')  # equivalent to s['a']
Out[297]: 1

In [298]: s.get('x', default=-1)
Out[298]: -1

---->   pandas.Series; Series.get

--------------------------------------
ID: 220 --> 2
In [299]: df = pd.DataFrame({'col': ["A", "A", "B", "B"],
   .....:                    'A': [80, 23, np.nan, 22],
   .....:                    'B': [80, 55, 76, 67]})
   .....: 

In [300]: df
Out[300]: 
  col     A   B
0   A  80.0  80
1   A  23.0  55
2   B   NaN  76
3   B  22.0  67

In [301]: idx, cols = pd.factorize(df['col'])

In [302]: df.reindex(cols, axis=1).to_numpy()[np.arange(len(df)), idx]
Out[302]: array([80., 23., 76., 67.])

---->   pandas.DataFrame; pandas.factorize

--------------------------------------
ID: 221 --> 1
In [303]: index = pd.Index(['e', 'd', 'a', 'b'])

In [304]: index
Out[304]: Index(['e', 'd', 'a', 'b'], dtype='object')

In [305]: 'd' in index
Out[305]: True

---->   pandas.Index

--------------------------------------
ID: 222 --> 1
In [306]: index = pd.Index([1, 5, 12])

In [307]: index
Out[307]: Index([1, 5, 12], dtype='int64')

In [308]: 5 in index
Out[308]: True

---->   pandas.Index

--------------------------------------
ID: 223 --> 1
In [309]: index = pd.Index(['e', 'd', 'a', 'b'], dtype="string")

In [310]: index
Out[310]: Index(['e', 'd', 'a', 'b'], dtype='string')

In [311]: index = pd.Index([1, 5, 12], dtype="int8")

In [312]: index
Out[312]: Index([1, 5, 12], dtype='int8')

In [313]: index = pd.Index([1, 5, 12], dtype="float32")

In [314]: index
Out[314]: Index([1.0, 5.0, 12.0], dtype='float32')

---->   pandas.Index

--------------------------------------
ID: 224 --> 1
In [315]: index = pd.Index(['e', 'd', 'a', 'b'], name='something')

In [316]: index.name
Out[316]: 'something'

---->   pandas.Index

--------------------------------------
ID: 225 --> 2
In [317]: index = pd.Index(list(range(5)), name='rows')

In [318]: columns = pd.Index(['A', 'B', 'C'], name='cols')

In [319]: df = pd.DataFrame(np.random.randn(5, 3), index=index, columns=columns)

In [320]: df
Out[320]: 
cols         A         B         C
rows                              
0     1.295989 -1.051694  1.340429
1    -2.366110  0.428241  0.387275
2     0.433306  0.929548  0.278094
3     2.154730 -0.315628  0.264223
4     1.126818  1.132290 -0.353310

In [321]: df['A']
Out[321]: 
rows
0    1.295989
1   -2.366110
2    0.433306
3    2.154730
4    1.126818
Name: A, dtype: float64

---->   pandas.Index; pandas.DataFrame

--------------------------------------
ID: 226 --> 2
In [322]: ind = pd.Index([1, 2, 3])

In [323]: ind.rename("apple")
Out[323]: Index([1, 2, 3], dtype='int64', name='apple')

In [324]: ind
Out[324]: Index([1, 2, 3], dtype='int64')

In [325]: ind = ind.set_names(["apple"])

In [326]: ind.name = "bob"

In [327]: ind
Out[327]: Index([1, 2, 3], dtype='int64', name='bob')

---->   pandas.Index; Index.rename

--------------------------------------
ID: 227 --> 1
In [328]: index = pd.MultiIndex.from_product([range(3), ['one', 'two']], names=['first', 'second'])

In [329]: index
Out[329]: 
MultiIndex([(0, 'one'),
            (0, 'two'),
            (1, 'one'),
            (1, 'two'),
            (2, 'one'),
            (2, 'two')],
           names=['first', 'second'])

In [330]: index.levels[1]
Out[330]: Index(['one', 'two'], dtype='object', name='second')

In [331]: index.set_levels(["a", "b"], level=1)
Out[331]: 
MultiIndex([(0, 'a'),
            (0, 'b'),
            (1, 'a'),
            (1, 'b'),
            (2, 'a'),
            (2, 'b')],
           names=['first', 'second'])

---->   pandas.MultiIndex

--------------------------------------
ID: 228 --> 2
In [332]: a = pd.Index(['c', 'b', 'a'])

In [333]: b = pd.Index(['c', 'e', 'd'])

In [334]: a.difference(b)
Out[334]: Index(['a', 'b'], dtype='object')

---->   pandas.Index; Index.difference

--------------------------------------
ID: 229 --> 2
In [335]: idx1 = pd.Index([1, 2, 3, 4])

In [336]: idx2 = pd.Index([2, 3, 4, 5])

In [337]: idx1.symmetric_difference(idx2)
Out[337]: Index([1, 5], dtype='int64')

---->   pandas.Index; Index.symmetric_difference

--------------------------------------
ID: 230 --> 2
In [338]: idx1 = pd.Index([0, 1, 2])

In [339]: idx2 = pd.Index([0.5, 1.5])

In [340]: idx1.union(idx2)
Out[340]: Index([0.0, 0.5, 1.0, 1.5, 2.0], dtype='float64')

---->   pandas.Index; Index.union

--------------------------------------
ID: 231 --> 4
In [341]: idx1 = pd.Index([1, np.nan, 3, 4])

In [342]: idx1
Out[342]: Index([1.0, nan, 3.0, 4.0], dtype='float64')

In [343]: idx1.fillna(2)
Out[343]: Index([1.0, 2.0, 3.0, 4.0], dtype='float64')

In [344]: idx2 = pd.DatetimeIndex([pd.Timestamp('2011-01-01'),
   .....:                          pd.NaT,
   .....:                          pd.Timestamp('2011-01-03')])
   .....: 

In [345]: idx2
Out[345]: DatetimeIndex(['2011-01-01', 'NaT', '2011-01-03'], dtype='datetime64[ns]', freq=None)

In [346]: idx2.fillna(pd.Timestamp('2011-01-02'))
Out[346]: DatetimeIndex(['2011-01-01', '2011-01-02', '2011-01-03'], dtype='datetime64[ns]', freq=None)

---->   pandas.Index; Index.fillna; pandas.DatetimeIndex; Index.fillna

--------------------------------------
ID: 237 --> 2
In [360]: dfmi = pd.DataFrame([list('abcd'),
   .....:                      list('efgh'),
   .....:                      list('ijkl'),
   .....:                      list('mnop')],
   .....:                     columns=pd.MultiIndex.from_product([['one', 'two'],
   .....:                                                         ['first', 'second']]))
   .....: 

In [361]: dfmi
Out[361]: 
    one          two       
  first second first second
0     a      b     c      d
1     e      f     g      h
2     i      j     k      l
3     m      n     o      p

---->   pandas.DataFrame; pandas.MultiIndex

--------------------------------------
ID: 242 --> 1
In [364]: dfb = pd.DataFrame({'a': ['one', 'one', 'two',
   .....:                           'three', 'two', 'one', 'six'],
   .....:                     'c': np.arange(7)})
   .....: 

# This will show the SettingWithCopyWarning
# but the frame values will be set
In [365]: dfb['c'][dfb['a'].str.startswith('o')] = 42

---->   pandas.DataFrame

--------------------------------------
ID: 244 --> 1
In [366]: dfc = pd.DataFrame({'a': ['one', 'one', 'two',
   .....:                           'three', 'two', 'one', 'six'],
   .....:                     'c': np.arange(7)})
   .....: 

In [367]: dfd = dfc.copy()

# Setting multiple items using a mask
In [368]: mask = dfd['a'].str.startswith('o')

In [369]: dfd.loc[mask, 'c'] = 42

In [370]: dfd
Out[370]: 
       a   c
0    one  42
1    one  42
2    two   2
3  three   3
4    two   4
5    one  42
6    six   6

# Setting a single item
In [371]: dfd = dfc.copy()

In [372]: dfd.loc[2, 'a'] = 11

In [373]: dfd
Out[373]: 
       a  c
0    one  0
1    one  1
2     11  2
3  three  3
4    two  4
5    one  5
6    six  6

---->   pandas.DataFrame

--------------------------------------
ID: 248 --> 3
In [3]: ts = pd.Series(np.random.randn(1000), index=pd.date_range("1/1/2000", periods=1000))

In [4]: ts = ts.cumsum()

In [5]: ts.plot();

---->   pandas.Series; Series.cumsum; Series.plot

--------------------------------------
ID: 249 --> 3
In [6]: df = pd.DataFrame(np.random.randn(1000, 4), index=ts.index, columns=list("ABCD"))

In [7]: df = df.cumsum()

In [8]: plt.figure();

In [9]: df.plot();

---->   pandas.DataFrame; DataFrame.cumsum; DataFrame.plot

--------------------------------------
ID: 250 --> 3
In [10]: df3 = pd.DataFrame(np.random.randn(1000, 2), columns=["B", "C"]).cumsum()

In [11]: df3["A"] = pd.Series(list(range(len(df))))

In [12]: df3.plot(x="A", y="B");

---->   pandas.DataFrame; pandas.Series; DataFrame.plot

--------------------------------------
ID: 252 --> 1
In [15]: df = pd.DataFrame()

In [16]: df.plot.<TAB>  # noqa: E225, E999
df.plot.area     df.plot.barh     df.plot.density  df.plot.hist     df.plot.line     df.plot.scatter
df.plot.bar      df.plot.box      df.plot.hexbin   df.plot.kde      df.plot.pie

---->   pandas.DataFrame

--------------------------------------
ID: 254 --> 2
In [20]: df2 = pd.DataFrame(np.random.rand(10, 4), columns=["a", "b", "c", "d"])

In [21]: df2.plot.bar();

---->   pandas.DataFrame; DataFrame.plot

--------------------------------------
ID: 255 --> 1
In [22]: df2.plot.bar(stacked=True);

---->   DataFrame.plot

--------------------------------------
ID: 256 --> 1
In [23]: df2.plot.barh(stacked=True);

---->   DataFrame.plot

--------------------------------------
ID: 257 --> 2
In [24]: df4 = pd.DataFrame(
   ....:     {
   ....:         "a": np.random.randn(1000) + 1,
   ....:         "b": np.random.randn(1000),
   ....:         "c": np.random.randn(1000) - 1,
   ....:     },
   ....:     columns=["a", "b", "c"],
   ....: )
   ....: 

In [25]: plt.figure();

In [26]: df4.plot.hist(alpha=0.5);

---->   pandas.DataFrame; DataFrame.plot

--------------------------------------
ID: 258 --> 1
In [27]: plt.figure();

In [28]: df4.plot.hist(stacked=True, bins=20);

---->   DataFrame.plot

--------------------------------------
ID: 261 --> 1
In [33]: plt.figure();

In [34]: df.diff().hist(color="k", alpha=0.5, bins=50);

---->   DataFrame.diff

--------------------------------------
ID: 262 --> 2
In [35]: data = pd.Series(np.random.randn(1000))

In [36]: data.hist(by=np.random.randint(0, 4, 1000), figsize=(6, 4));

---->   pandas.Series; Series.hist

--------------------------------------
ID: 263 --> 2
In [37]: data = pd.DataFrame(
   ....:     {
   ....:         "a": np.random.choice(["x", "y", "z"], 1000),
   ....:         "b": np.random.choice(["e", "f", "g"], 1000),
   ....:         "c": np.random.randn(1000),
   ....:         "d": np.random.randn(1000) - 1,
   ....:     },
   ....: )
   ....: 

In [38]: data.plot.hist(by=["a", "b"], figsize=(10, 5));

---->   pandas.DataFrame; Series.plot

--------------------------------------
ID: 264 --> 2
In [39]: df = pd.DataFrame(np.random.rand(10, 5), columns=["A", "B", "C", "D", "E"])

In [40]: df.plot.box();

---->   pandas.DataFrame; DataFrame.plot

--------------------------------------
ID: 265 --> 1
In [41]: color = {
   ....:     "boxes": "DarkGreen",
   ....:     "whiskers": "DarkOrange",
   ....:     "medians": "DarkBlue",
   ....:     "caps": "Gray",
   ....: }
   ....: 

In [42]: df.plot.box(color=color, sym="r+");

---->   DataFrame.plot

--------------------------------------
ID: 266 --> 1
In [43]: df.plot.box(vert=False, positions=[1, 4, 5, 6, 8]);

---->   DataFrame.plot

--------------------------------------
ID: 267 --> 2
In [44]: df = pd.DataFrame(np.random.rand(10, 5))

In [45]: plt.figure();

In [46]: bp = df.boxplot()

---->   pandas.DataFrame; DataFrame.boxplot

--------------------------------------
ID: 268 --> 3
In [47]: df = pd.DataFrame(np.random.rand(10, 2), columns=["Col1", "Col2"])

In [48]: df["X"] = pd.Series(["A", "A", "A", "A", "A", "B", "B", "B", "B", "B"])

In [49]: plt.figure();

In [50]: bp = df.boxplot(by="X")

---->   pandas.DataFrame; pandas.Series; DataFrame.boxplot

--------------------------------------
ID: 269 --> 3
In [51]: df = pd.DataFrame(np.random.rand(10, 3), columns=["Col1", "Col2", "Col3"])

In [52]: df["X"] = pd.Series(["A", "A", "A", "A", "A", "B", "B", "B", "B", "B"])

In [53]: df["Y"] = pd.Series(["A", "B", "A", "B", "A", "B", "A", "B", "A", "B"])

In [54]: plt.figure();

In [55]: bp = df.boxplot(column=["Col1", "Col2"], by=["X", "Y"])

---->   pandas.DataFrame; pandas.Series; DataFrame.boxplot

--------------------------------------
ID: 270 --> 3
In [56]: df = pd.DataFrame(np.random.rand(10, 3), columns=["Col1", "Col2", "Col3"])

In [57]: df["X"] = pd.Series(["A", "A", "A", "A", "A", "B", "B", "B", "B", "B"])

In [58]: plt.figure();

In [59]: bp = df.plot.box(column=["Col1", "Col2"], by="X")

---->   pandas.DataFrame; pandas.Series; DataFrame.plot

--------------------------------------
ID: 271 --> 2
In [60]: np.random.seed(1234)

In [61]: df_box = pd.DataFrame(np.random.randn(50, 2))

In [62]: df_box["g"] = np.random.choice(["A", "B"], size=50)

In [63]: df_box.loc[df_box["g"] == "B", 1] += 3

In [64]: bp = df_box.boxplot(by="g")

---->   pandas.DataFrame; DataFrame.boxplot

--------------------------------------
ID: 272 --> 1
In [65]: bp = df_box.groupby("g").boxplot()

---->   DataFrame.groupby

--------------------------------------
ID: 273 --> 2
In [66]: df = pd.DataFrame(np.random.rand(10, 4), columns=["a", "b", "c", "d"])

In [67]: df.plot.area();

---->   pandas.DataFrame; DataFrame.plot

--------------------------------------
ID: 274 --> 1
In [68]: df.plot.area(stacked=False);

---->   DataFrame.plot

--------------------------------------
ID: 275 --> 3
In [69]: df = pd.DataFrame(np.random.rand(50, 4), columns=["a", "b", "c", "d"])

In [70]: df["species"] = pd.Categorical(
   ....:     ["setosa"] * 20 + ["versicolor"] * 20 + ["virginica"] * 10
   ....: )
   ....: 

In [71]: df.plot.scatter(x="a", y="b");

---->   pandas.DataFrame; pandas.Categorical; DataFrame.plot

--------------------------------------
ID: 276 --> 1
In [72]: ax = df.plot.scatter(x="a", y="b", color="DarkBlue", label="Group 1")

In [73]: df.plot.scatter(x="c", y="d", color="DarkGreen", label="Group 2", ax=ax);

---->   DataFrame.plot

--------------------------------------
ID: 277 --> 1
In [74]: df.plot.scatter(x="a", y="b", c="c", s=50);

---->   DataFrame.plot

--------------------------------------
ID: 278 --> 1
In [75]: df.plot.scatter(x="a", y="b", c="species", cmap="viridis", s=50);

---->   DataFrame.plot

--------------------------------------
ID: 279 --> 1
In [76]: df.plot.scatter(x="a", y="b", s=df["c"] * 200);

---->   DataFrame.plot

--------------------------------------
ID: 280 --> 2
In [77]: df = pd.DataFrame(np.random.randn(1000, 2), columns=["a", "b"])

In [78]: df["b"] = df["b"] + np.arange(1000)

In [79]: df.plot.hexbin(x="a", y="b", gridsize=25);

---->   pandas.DataFrame; DataFrame.plot

--------------------------------------
ID: 281 --> 2
In [80]: df = pd.DataFrame(np.random.randn(1000, 2), columns=["a", "b"])

In [81]: df["b"] = df["b"] + np.arange(1000)

In [82]: df["z"] = np.random.uniform(0, 3, 1000)

In [83]: df.plot.hexbin(x="a", y="b", C="z", reduce_C_function=np.max, gridsize=25);

---->   pandas.DataFrame; DataFrame.plot

--------------------------------------
ID: 282 --> 2
In [84]: series = pd.Series(3 * np.random.rand(4), index=["a", "b", "c", "d"], name="series")

In [85]: series.plot.pie(figsize=(6, 6));

---->   pandas.Series; Series.plot

--------------------------------------
ID: 283 --> 2
In [86]: df = pd.DataFrame(
   ....:     3 * np.random.rand(4, 2), index=["a", "b", "c", "d"], columns=["x", "y"]
   ....: )
   ....: 

In [87]: df.plot.pie(subplots=True, figsize=(8, 4));

---->   pandas.DataFrame; DataFrame.plot

--------------------------------------
ID: 284 --> 1
In [88]: series.plot.pie(
   ....:     labels=["AA", "BB", "CC", "DD"],
   ....:     colors=["r", "g", "b", "c"],
   ....:     autopct="%.2f",
   ....:     fontsize=20,
   ....:     figsize=(6, 6),
   ....: );
   ....: 

---->   Series.plot

--------------------------------------
ID: 285 --> 2
In [89]: series = pd.Series([0.1] * 4, index=["a", "b", "c", "d"], name="series2")

In [90]: series.plot.pie(figsize=(6, 6));

---->   pandas.Series; Series.plot

--------------------------------------
ID: 286 --> 1
In [91]: from pandas.plotting import scatter_matrix

In [92]: df = pd.DataFrame(np.random.randn(1000, 4), columns=["a", "b", "c", "d"])

In [93]: scatter_matrix(df, alpha=0.2, figsize=(6, 6), diagonal="kde");

---->   pandas.DataFrame

--------------------------------------
ID: 287 --> 2
In [94]: ser = pd.Series(np.random.randn(1000))

In [95]: ser.plot.kde();

---->   pandas.Series; Series.plot

--------------------------------------
ID: 290 --> 1
In [104]: from pandas.plotting import lag_plot

In [105]: plt.figure();

In [106]: spacing = np.linspace(-99 * np.pi, 99 * np.pi, num=1000)

In [107]: data = pd.Series(0.1 * np.random.rand(1000) + 0.9 * np.sin(spacing))

In [108]: lag_plot(data);

---->   pandas.Series

--------------------------------------
ID: 291 --> 1
In [109]: from pandas.plotting import autocorrelation_plot

In [110]: plt.figure();

In [111]: spacing = np.linspace(-9 * np.pi, 9 * np.pi, num=1000)

In [112]: data = pd.Series(0.7 * np.random.rand(1000) + 0.3 * np.sin(spacing))

In [113]: autocorrelation_plot(data);

---->   pandas.Series

--------------------------------------
ID: 292 --> 1
In [114]: from pandas.plotting import bootstrap_plot

In [115]: data = pd.Series(np.random.rand(1000))

In [116]: bootstrap_plot(data, size=50, samples=500, color="grey");

---->   pandas.Series

--------------------------------------
ID: 294 --> 1
In [121]: plt.figure();

In [122]: ts.plot(style="k--", label="Series");

---->   Series.plot

--------------------------------------
ID: 295 --> 3
In [123]: df = pd.DataFrame(np.random.randn(1000, 4), index=ts.index, columns=list("ABCD"))

In [124]: df = df.cumsum()

In [125]: df.plot(legend=False);

---->   pandas.DataFrame; DataFrame.cumsum; DataFrame.plot

--------------------------------------
ID: 296 --> 1
In [126]: df.plot();

In [127]: df.plot(xlabel="new x", ylabel="new y");

---->   DataFrame.plot

--------------------------------------
ID: 297 --> 3
In [128]: ts = pd.Series(np.random.randn(1000), index=pd.date_range("1/1/2000", periods=1000))

In [129]: ts = np.exp(ts.cumsum())

In [130]: ts.plot(logy=True);

---->   pandas.Series; Series.cumsum; Series.plot

--------------------------------------
ID: 299 --> 1
In [133]: plt.figure();

In [134]: ax = df.plot(secondary_y=["A", "B"])

In [135]: ax.set_ylabel("CD scale");

In [136]: ax.right_ax.set_ylabel("AB scale");

---->   DataFrame.plot

--------------------------------------
ID: 300 --> 1
In [137]: plt.figure();

In [138]: df.plot(secondary_y=["A", "B"], mark_right=False);

---->   DataFrame.plot

--------------------------------------
ID: 304 --> 1
In [145]: df.plot(subplots=True, figsize=(6, 6));

---->   DataFrame.plot

--------------------------------------
ID: 305 --> 1
In [146]: df.plot(subplots=True, layout=(2, 3), figsize=(6, 6), sharex=False);

---->   DataFrame.plot

--------------------------------------
ID: 306 --> 1
In [147]: df.plot(subplots=True, layout=(2, -1), figsize=(6, 6), sharex=False);

---->   DataFrame.plot

--------------------------------------
ID: 307 --> 1
In [148]: fig, axes = plt.subplots(4, 4, figsize=(9, 9))

In [149]: plt.subplots_adjust(wspace=0.5, hspace=0.5)

In [150]: target1 = [axes[0][0], axes[1][1], axes[2][2], axes[3][3]]

In [151]: target2 = [axes[3][0], axes[2][1], axes[1][2], axes[0][3]]

In [152]: df.plot(subplots=True, ax=target1, legend=False, sharex=False, sharey=False);

In [153]: (-df).plot(subplots=True, ax=target2, legend=False, sharex=False, sharey=False);

---->   DataFrame.plot

--------------------------------------
ID: 309 --> 3
# Generate the data
In [164]: ix3 = pd.MultiIndex.from_arrays(
   .....:     [
   .....:         ["a", "a", "a", "a", "a", "b", "b", "b", "b", "b"],
   .....:         ["foo", "foo", "foo", "bar", "bar", "foo", "foo", "bar", "bar", "bar"],
   .....:     ],
   .....:     names=["letter", "word"],
   .....: )
   .....: 

In [165]: df3 = pd.DataFrame(
   .....:     {
   .....:         "data1": [9, 3, 2, 4, 3, 2, 4, 6, 3, 2],
   .....:         "data2": [9, 6, 5, 7, 5, 4, 5, 6, 5, 1],
   .....:     },
   .....:     index=ix3,
   .....: )
   .....: 

# Group by index labels and take the means and standard deviations
# for each group
In [166]: gp3 = df3.groupby(level=("letter", "word"))

In [167]: means = gp3.mean()

In [168]: errors = gp3.std()

In [169]: means
Out[169]: 
                data1     data2
letter word                    
a      bar   3.500000  6.000000
       foo   4.666667  6.666667
b      bar   3.666667  4.000000
       foo   3.000000  4.500000

In [170]: errors
Out[170]: 
                data1     data2
letter word                    
a      bar   0.707107  1.414214
       foo   3.785939  2.081666
b      bar   2.081666  2.645751
       foo   1.414214  0.707107

# Plot
In [171]: fig, ax = plt.subplots()

In [172]: means.plot.bar(yerr=errors, ax=ax, capsize=4, rot=0);

---->   pandas.MultiIndex; pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 311 --> 2
In [178]: fig, ax = plt.subplots(1, 1, figsize=(7, 6.5))

In [179]: df = pd.DataFrame(np.random.rand(5, 3), columns=["a", "b", "c"])

In [180]: ax.xaxis.tick_top()  # Display x-axis ticks on top.

In [181]: df.plot(table=True, ax=ax);

---->   pandas.DataFrame; DataFrame.plot

--------------------------------------
ID: 312 --> 1
In [182]: fig, ax = plt.subplots(1, 1, figsize=(7, 6.75))

In [183]: ax.xaxis.tick_top()  # Display x-axis ticks on top.

In [184]: df.plot(table=np.round(df.T, 2), ax=ax);

---->   DataFrame.plot

--------------------------------------
ID: 313 --> 2
In [185]: from pandas.plotting import table

In [186]: fig, ax = plt.subplots(1, 1)

In [187]: table(ax, np.round(df.describe(), 2), loc="upper right", colWidths=[0.2, 0.2, 0.2]);

In [188]: df.plot(ax=ax, ylim=(0, 2), legend=None);

---->   DataFrame.describe; DataFrame.plot

--------------------------------------
ID: 314 --> 3
In [189]: df = pd.DataFrame(np.random.randn(1000, 10), index=ts.index)

In [190]: df = df.cumsum()

In [191]: plt.figure();

In [192]: df.plot(colormap="cubehelix");

---->   pandas.DataFrame; DataFrame.cumsum; DataFrame.plot

--------------------------------------
ID: 315 --> 1
In [193]: from matplotlib import cm

In [194]: plt.figure();

In [195]: df.plot(colormap=cm.cubehelix);

---->   DataFrame.plot

--------------------------------------
ID: 316 --> 3
In [196]: dd = pd.DataFrame(np.random.randn(10, 10)).applymap(abs)

In [197]: dd = dd.cumsum()

In [198]: plt.figure();

In [199]: dd.plot.bar(colormap="Greens");

---->   pandas.DataFrame; DataFrame.cumsum; DataFrame.plot

--------------------------------------
ID: 319 --> 1
In [204]: price = pd.Series(
   .....:     np.random.randn(150).cumsum(),
   .....:     index=pd.date_range("2000-1-1", periods=150, freq="B"),
   .....: )
   .....: 

In [205]: ma = price.rolling(20).mean()

In [206]: mstd = price.rolling(20).std()

In [207]: plt.figure();

In [208]: plt.plot(price.index, price, "k");

In [209]: plt.plot(ma.index, ma, "b");

In [210]: plt.fill_between(mstd.index, ma - 2 * mstd, ma + 2 * mstd, color="b", alpha=0.2);

---->   pandas.Series

--------------------------------------
ID: 321 --> 1
>>> pd.set_option("plotting.backend", "backend.module")
>>> pd.Series([1, 2, 3]).plot()

---->   pandas.Series

--------------------------------------
ID: 322 --> 1
>>> pd.options.plotting.backend = "backend.module"
>>> pd.Series([1, 2, 3]).plot()

---->   pandas.Series

--------------------------------------
ID: 323 --> 1
>>> import backend.module
>>> backend.module.plot(pd.Series([1, 2, 3]))

---->   pandas.Series

--------------------------------------
ID: 324 --> 1
In [1]: dates = pd.date_range('1/1/2000', periods=8)

In [2]: df = pd.DataFrame(np.random.randn(8, 4),
   ...:                   index=dates, columns=['A', 'B', 'C', 'D'])
   ...: 

In [3]: df
Out[3]: 
                   A         B         C         D
2000-01-01  0.469112 -0.282863 -1.509059 -1.135632
2000-01-02  1.212112 -0.173215  0.119209 -1.044236
2000-01-03 -0.861849 -2.104569 -0.494929  1.071804
2000-01-04  0.721555 -0.706771 -1.039575  0.271860
2000-01-05 -0.424972  0.567020  0.276232 -1.087401
2000-01-06 -0.673690  0.113648 -1.478427  0.524988
2000-01-07  0.404705  0.577046 -1.715002 -1.039268
2000-01-08 -0.370647 -1.157892 -1.344312  0.844885

---->   pandas.DataFrame

--------------------------------------
ID: 326 --> 2
In [14]: sa = pd.Series([1, 2, 3], index=list('abc'))

In [15]: dfa = df.copy()

---->   pandas.Series; DataFrame.copy

--------------------------------------
ID: 328 --> 1
In [24]: x = pd.DataFrame({'x': [1, 2, 3], 'y': [3, 4, 5]})

In [25]: x.iloc[1] = {'x': 9, 'y': 99}

In [26]: x
Out[26]: 
   x   y
0  1   3
1  9  99
2  3   5

---->   pandas.DataFrame

--------------------------------------
ID: 329 --> 1
In [1]: df = pd.DataFrame({'one': [1., 2., 3.]})
In [2]: df.two = [4, 5, 6]
UserWarning: Pandas doesn't allow Series to be assigned into nonexistent columns - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute_access
In [3]: df
Out[3]:
   one
0  1.0
1  2.0
2  3.0

---->   pandas.DataFrame

--------------------------------------
ID: 330 --> 1
In [30]: s2 = s.copy()

In [31]: s2[:5] = 0

In [32]: s2
Out[32]: 
2000-01-01    0.000000
2000-01-02    0.000000
2000-01-03    0.000000
2000-01-04    0.000000
2000-01-05    0.000000
2000-01-06   -0.673690
2000-01-07    0.404705
2000-01-08   -0.370647
Freq: D, Name: A, dtype: float64

---->   Series.copy

--------------------------------------
ID: 331 --> 1
In [35]: dfl = pd.DataFrame(np.random.randn(5, 4),
   ....:                    columns=list('ABCD'),
   ....:                    index=pd.date_range('20130101', periods=5))
   ....: 

In [36]: dfl
Out[36]: 
                   A         B         C         D
2013-01-01  1.075770 -0.109050  1.643563 -1.469388
2013-01-02  0.357021 -0.674600 -1.776904 -0.968914
2013-01-03 -1.294524  0.413738  0.276662 -0.472035
2013-01-04 -0.013960 -0.362543 -0.006154 -0.923061
2013-01-05  0.895717  0.805244 -1.206412  2.565646

---->   pandas.DataFrame

--------------------------------------
ID: 332 --> 1
In [38]: s1 = pd.Series(np.random.randn(6), index=list('abcdef'))

In [39]: s1
Out[39]: 
a    1.431256
b    1.340309
c   -1.170299
d   -0.226169
e    0.410835
f    0.813850
dtype: float64

In [40]: s1.loc['c':]
Out[40]: 
c   -1.170299
d   -0.226169
e    0.410835
f    0.813850
dtype: float64

In [41]: s1.loc['b']
Out[41]: 1.3403088497993827

---->   pandas.Series

--------------------------------------
ID: 333 --> 1
In [44]: df1 = pd.DataFrame(np.random.randn(6, 4),
   ....:                    index=list('abcdef'),
   ....:                    columns=list('ABCD'))
   ....: 

In [45]: df1
Out[45]: 
          A         B         C         D
a  0.132003 -0.827317 -0.076467 -1.187678
b  1.130127 -1.436737 -1.413681  1.607920
c  1.024180  0.569605  0.875906 -2.211372
d  0.974466 -2.006747 -0.410001 -0.078638
e  0.545952 -1.219217 -1.226825  0.769804
f -1.281247 -0.727707 -0.121306 -0.097883

In [46]: df1.loc[['a', 'b', 'd'], :]
Out[46]: 
          A         B         C         D
a  0.132003 -0.827317 -0.076467 -1.187678
b  1.130127 -1.436737 -1.413681  1.607920
d  0.974466 -2.006747 -0.410001 -0.078638

---->   pandas.DataFrame

--------------------------------------
ID: 334 --> 1
In [51]: mask = pd.array([True, False, True, False, pd.NA, False], dtype="boolean")

In [52]: mask
Out[52]: 

[True, False, True, False, , False]
Length: 6, dtype: boolean

In [53]: df1[mask]
Out[53]: 
          A         B         C         D
a  0.132003 -0.827317 -0.076467 -1.187678
c  1.024180  0.569605  0.875906 -2.211372

---->   pandas.array

--------------------------------------
ID: 335 --> 1
In [55]: s = pd.Series(list('abcde'), index=[0, 3, 2, 5, 4])

In [56]: s.loc[3:5]
Out[56]: 
3    b
2    c
5    d
dtype: object

---->   pandas.Series

--------------------------------------
ID: 337 --> 1
In [59]: s = pd.Series(list('abcdef'), index=[0, 3, 2, 5, 4, 2])

In [60]: s.loc[3:5]
Out[60]: 
3    b
2    c
5    d
dtype: object

---->   pandas.Series

--------------------------------------
ID: 338 --> 1
In [61]: s1 = pd.Series(np.random.randn(5), index=list(range(0, 10, 2)))

In [62]: s1
Out[62]: 
0    0.695775
2    0.341734
4    0.959726
6   -1.110336
8   -0.619976
dtype: float64

In [63]: s1.iloc[:3]
Out[63]: 
0    0.695775
2    0.341734
4    0.959726
dtype: float64

In [64]: s1.iloc[3]
Out[64]: -1.110336102891167

---->   pandas.Series

--------------------------------------
ID: 339 --> 1
In [67]: df1 = pd.DataFrame(np.random.randn(6, 4),
   ....:                    index=list(range(0, 12, 2)),
   ....:                    columns=list(range(0, 8, 2)))
   ....: 

In [68]: df1
Out[68]: 
           0         2         4         6
0   0.149748 -0.732339  0.687738  0.176444
2   0.403310 -0.154951  0.301624 -2.179861
4  -1.369849 -0.954208  1.462696 -1.743161
6  -0.826591 -0.345352  1.314232  0.690579
8   0.995761  2.396780  0.014871  3.357427
10 -0.317441 -1.236269  0.896171 -0.487602

---->   pandas.DataFrame

--------------------------------------
ID: 340 --> 1
# these are allowed in Python/NumPy.
In [76]: x = list('abcdef')

In [77]: x
Out[77]: ['a', 'b', 'c', 'd', 'e', 'f']

In [78]: x[4:10]
Out[78]: ['e', 'f']

In [79]: x[8:10]
Out[79]: []

In [80]: s = pd.Series(x)

In [81]: s
Out[81]: 
0    a
1    b
2    c
3    d
4    e
5    f
dtype: object

In [82]: s.iloc[4:10]
Out[82]: 
4    e
5    f
dtype: object

In [83]: s.iloc[8:10]
Out[83]: Series([], dtype: object)

---->   pandas.Series

--------------------------------------
ID: 341 --> 1
In [84]: dfl = pd.DataFrame(np.random.randn(5, 2), columns=list('AB'))

In [85]: dfl
Out[85]: 
          A         B
0 -0.082240 -2.182937
1  0.380396  0.084844
2  0.432390  1.519970
3 -0.493662  0.600178
4  0.274230  0.132885

In [86]: dfl.iloc[:, 2:3]
Out[86]: 
Empty DataFrame
Columns: []
Index: [0, 1, 2, 3, 4]

In [87]: dfl.iloc[:, 1:3]
Out[87]: 
          B
0 -2.182937
1  0.084844
2  1.519970
3  0.600178
4  0.132885

In [88]: dfl.iloc[4:6]
Out[88]: 
         A         B
4  0.27423  0.132885

---->   pandas.DataFrame

--------------------------------------
ID: 342 --> 1
In [89]: df1 = pd.DataFrame(np.random.randn(6, 4),
   ....:                    index=list('abcdef'),
   ....:                    columns=list('ABCD'))
   ....: 

In [90]: df1
Out[90]: 
          A         B         C         D
a -0.023688  2.410179  1.450520  0.206053
b -0.251905 -2.213588  1.063327  1.266143
c  0.299368 -0.863838  0.408204 -1.048089
d -0.025747 -0.988387  0.094055  1.262731
e  1.289997  0.082423 -0.055758  0.536580
f -0.489682  0.369374 -0.034571 -2.484478

In [91]: df1.loc[lambda df: df['A'] > 0, :]
Out[91]: 
          A         B         C         D
c  0.299368 -0.863838  0.408204 -1.048089
e  1.289997  0.082423 -0.055758  0.536580

In [92]: df1.loc[:, lambda df: ['A', 'B']]
Out[92]: 
          A         B
a -0.023688  2.410179
b -0.251905 -2.213588
c  0.299368 -0.863838
d -0.025747 -0.988387
e  1.289997  0.082423
f -0.489682  0.369374

In [93]: df1.iloc[:, lambda df: [0, 1]]
Out[93]: 
          A         B
a -0.023688  2.410179
b -0.251905 -2.213588
c  0.299368 -0.863838
d -0.025747 -0.988387
e  1.289997  0.082423
f -0.489682  0.369374

In [94]: df1[lambda df: df.columns[0]]
Out[94]: 
a   -0.023688
b   -0.251905
c    0.299368
d   -0.025747
e    1.289997
f   -0.489682
Name: A, dtype: float64

---->   pandas.DataFrame

--------------------------------------
ID: 344 --> 1
In [98]: dfd = pd.DataFrame({'A': [1, 2, 3],
   ....:                     'B': [4, 5, 6]},
   ....:                    index=list('abc'))
   ....: 

In [99]: dfd
Out[99]: 
   A  B
a  1  4
b  2  5
c  3  6

In [100]: dfd.loc[dfd.index[[0, 2]], 'A']
Out[100]: 
a    1
c    3
Name: A, dtype: int64

---->   pandas.DataFrame

--------------------------------------
ID: 347 --> 1
In [103]: s = pd.Series([1, 2, 3])

In [104]: s
Out[104]: 
0    1
1    2
2    3
dtype: int64

---->   pandas.Series

--------------------------------------
ID: 351 --> 1
In [109]: s = pd.Series(np.arange(4), index=['a', 'a', 'b', 'c'])

In [110]: labels = ['c', 'd']

---->   pandas.Series

--------------------------------------
ID: 355 --> 2
In [112]: s = pd.Series([0, 1, 2, 3, 4, 5])

# When no arguments are passed, returns 1 row.
In [113]: s.sample()
Out[113]: 
4    4
dtype: int64

# One may specify either a number of rows:
In [114]: s.sample(n=3)
Out[114]: 
0    0
4    4
1    1
dtype: int64

# Or a fraction of the rows:
In [115]: s.sample(frac=0.5)
Out[115]: 
5    5
3    3
1    1
dtype: int64

---->   pandas.Series; Series.sample

--------------------------------------
ID: 356 --> 2
In [116]: s = pd.Series([0, 1, 2, 3, 4, 5])

# Without replacement (default):
In [117]: s.sample(n=6, replace=False)
Out[117]: 
0    0
1    1
5    5
3    3
2    2
4    4
dtype: int64

# With replacement:
In [118]: s.sample(n=6, replace=True)
Out[118]: 
0    0
4    4
3    3
2    2
4    4
4    4
dtype: int64

---->   pandas.Series; Series.sample

--------------------------------------
ID: 357 --> 2
In [119]: s = pd.Series([0, 1, 2, 3, 4, 5])

In [120]: example_weights = [0, 0, 0.2, 0.2, 0.2, 0.4]

In [121]: s.sample(n=3, weights=example_weights)
Out[121]: 
5    5
4    4
3    3
dtype: int64

# Weights will be re-normalized automatically
In [122]: example_weights2 = [0.5, 0, 0, 0, 0, 0]

In [123]: s.sample(n=1, weights=example_weights2)
Out[123]: 
0    0
dtype: int64

---->   pandas.Series; Series.sample

--------------------------------------
ID: 358 --> 2
In [124]: df2 = pd.DataFrame({'col1': [9, 8, 7, 6],
   .....:                     'weight_column': [0.5, 0.4, 0.1, 0]})
   .....: 

In [125]: df2.sample(n=3, weights='weight_column')
Out[125]: 
   col1  weight_column
1     8            0.4
0     9            0.5
2     7            0.1

---->   pandas.DataFrame; DataFrame.sample

--------------------------------------
ID: 359 --> 2
In [126]: df3 = pd.DataFrame({'col1': [1, 2, 3], 'col2': [2, 3, 4]})

In [127]: df3.sample(n=1, axis=1)
Out[127]: 
   col1
0     1
1     2
2     3

---->   pandas.DataFrame; DataFrame.sample

--------------------------------------
ID: 360 --> 2
In [128]: df4 = pd.DataFrame({'col1': [1, 2, 3], 'col2': [2, 3, 4]})

# With a given seed, the sample will always draw the same rows.
In [129]: df4.sample(n=2, random_state=2)
Out[129]: 
   col1  col2
2     3     4
1     2     3

In [130]: df4.sample(n=2, random_state=2)
Out[130]: 
   col1  col2
2     3     4
1     2     3

---->   pandas.DataFrame; DataFrame.sample

--------------------------------------
ID: 361 --> 1
In [131]: se = pd.Series([1, 2, 3])

In [132]: se
Out[132]: 
0    1
1    2
2    3
dtype: int64

In [133]: se[5] = 5.

In [134]: se
Out[134]: 
0    1.0
1    2.0
2    3.0
5    5.0
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 362 --> 1
In [135]: dfi = pd.DataFrame(np.arange(6).reshape(3, 2),
   .....:                    columns=['A', 'B'])
   .....: 

In [136]: dfi
Out[136]: 
   A  B
0  0  1
1  2  3
2  4  5

In [137]: dfi.loc[:, 'C'] = dfi.loc[:, 'A']

In [138]: dfi
Out[138]: 
   A  B  C
0  0  1  0
1  2  3  2
2  4  5  4

---->   pandas.DataFrame

--------------------------------------
ID: 364 --> 1
In [148]: s = pd.Series(range(-3, 4))

In [149]: s
Out[149]: 
0   -3
1   -2
2   -1
3    0
4    1
5    2
6    3
dtype: int64

In [150]: s[s > 0]
Out[150]: 
4    1
5    2
6    3
dtype: int64

In [151]: s[(s < -1) | (s > 0.5)]
Out[151]: 
0   -3
1   -2
4    1
5    2
6    3
dtype: int64

In [152]: s[~(s < 0)]
Out[152]: 
3    0
4    1
5    2
6    3
dtype: int64

---->   pandas.Series

--------------------------------------
ID: 365 --> 1
In [154]: df2 = pd.DataFrame({'a': ['one', 'one', 'two', 'three', 'two', 'one', 'six'],
   .....:                     'b': ['x', 'y', 'y', 'x', 'y', 'x', 'x'],
   .....:                     'c': np.random.randn(7)})
   .....: 

# only want 'two' or 'three'
In [155]: criterion = df2['a'].map(lambda x: x.startswith('t'))

In [156]: df2[criterion]
Out[156]: 
       a  b         c
2    two  y  0.041290
3  three  x  0.361719
4    two  y -0.238075

# equivalent but slower
In [157]: df2[[x.startswith('t') for x in df2['a']]]
Out[157]: 
       a  b         c
2    two  y  0.041290
3  three  x  0.361719
4    two  y -0.238075

# Multiple criteria
In [158]: df2[criterion & (df2['b'] == 'x')]
Out[158]: 
       a  b         c
3  three  x  0.361719

---->   pandas.DataFrame

--------------------------------------
ID: 367 --> 1
In [160]: df = pd.DataFrame([[1, 2], [3, 4], [5, 6]],
   .....:                   index=list('abc'),
   .....:                   columns=['A', 'B'])
   .....: 

In [161]: s = (df['A'] > 2)

In [162]: s
Out[162]: 
a    False
b     True
c     True
Name: A, dtype: bool

In [163]: df.loc[s, 'B']
Out[163]: 
b    4
c    6
Name: B, dtype: int64

In [164]: df.iloc[s.values, 1]
Out[164]: 
b    4
c    6
Name: B, dtype: int64

---->   pandas.DataFrame

--------------------------------------
ID: 368 --> 2
In [165]: s = pd.Series(np.arange(5), index=np.arange(5)[::-1], dtype='int64')

In [166]: s
Out[166]: 
4    0
3    1
2    2
1    3
0    4
dtype: int64

In [167]: s.isin([2, 4, 6])
Out[167]: 
4    False
3    False
2     True
1    False
0     True
dtype: bool

In [168]: s[s.isin([2, 4, 6])]
Out[168]: 
2    2
0    4
dtype: int64

---->   pandas.Series; Series.isin

--------------------------------------
ID: 370 --> 2
In [171]: s_mi = pd.Series(np.arange(6),
   .....:                  index=pd.MultiIndex.from_product([[0, 1], ['a', 'b', 'c']]))
   .....: 

In [172]: s_mi
Out[172]: 
0  a    0
   b    1
   c    2
1  a    3
   b    4
   c    5
dtype: int64

In [173]: s_mi.iloc[s_mi.index.isin([(1, 'a'), (2, 'b'), (0, 'c')])]
Out[173]: 
0  c    2
1  a    3
dtype: int64

In [174]: s_mi.iloc[s_mi.index.isin(['a', 'c', 'e'], level=1)]
Out[174]: 
0  a    0
   c    2
1  a    3
   c    5
dtype: int64

---->   pandas.Series; pandas.MultiIndex

--------------------------------------
ID: 371 --> 2
In [175]: df = pd.DataFrame({'vals': [1, 2, 3, 4], 'ids': ['a', 'b', 'f', 'n'],
   .....:                    'ids2': ['a', 'n', 'c', 'n']})
   .....: 

In [176]: values = ['a', 'b', 1, 3]

In [177]: df.isin(values)
Out[177]: 
    vals    ids   ids2
0   True   True   True
1  False   True  False
2   True  False  False
3  False  False  False

---->   pandas.DataFrame; DataFrame.isin

--------------------------------------
ID: 372 --> 1
In [178]: values = {'ids': ['a', 'b'], 'vals': [1, 3]}

In [179]: df.isin(values)
Out[179]: 
    vals    ids   ids2
0   True   True  False
1  False   True  False
2   True  False  False
3  False  False  False

---->   DataFrame.isin

--------------------------------------
ID: 373 --> 1
In [180]: values = {'ids': ['a', 'b'], 'vals': [1, 3]}

In [181]: ~df.isin(values)
Out[181]: 
    vals    ids  ids2
0  False  False  True
1   True  False  True
2  False   True  True
3   True   True  True

---->   DataFrame.isin

--------------------------------------
ID: 374 --> 1
In [182]: values = {'ids': ['a', 'b'], 'ids2': ['a', 'c'], 'vals': [1, 3]}

In [183]: row_mask = df.isin(values).all(1)

In [184]: df[row_mask]
Out[184]: 
   vals ids ids2
0     1   a    a

---->   DataFrame.isin

--------------------------------------
ID: 377 --> 2
In [189]: s2 = s.copy()

In [190]: s2[s2 < 0] = 0

In [191]: s2
Out[191]: 
4    0
3    1
2    2
1    3
0    4
dtype: int64

In [192]: df2 = df.copy()

In [193]: df2[df2 < 0] = 0

In [194]: df2
Out[194]: 
                   A         B         C         D
2000-01-01  0.000000  0.000000  0.485855  0.245166
2000-01-02  0.000000  0.390389  0.000000  1.655824
2000-01-03  0.000000  0.299674  0.000000  0.281059
2000-01-04  0.846958  0.000000  0.600705  0.000000
2000-01-05  0.669692  0.000000  0.000000  0.342416
2000-01-06  0.868584  0.000000  2.297780  0.000000
2000-01-07  0.000000  0.000000  0.168904  0.000000
2000-01-08  0.801196  1.392071  0.000000  0.000000

---->   Series.copy; DataFrame.copy

--------------------------------------
ID: 379 --> 1
In [196]: df2 = df.copy()

In [197]: df2[df2[1:4] > 0] = 3

In [198]: df2
Out[198]: 
                   A         B         C         D
2000-01-01 -2.104139 -1.309525  0.485855  0.245166
2000-01-02 -0.352480  3.000000 -1.192319  3.000000
2000-01-03 -0.864883  3.000000 -0.227870  3.000000
2000-01-04  3.000000 -1.222082  3.000000 -1.233203
2000-01-05  0.669692 -0.605656 -1.169184  0.342416
2000-01-06  0.868584 -0.948458  2.297780 -0.684718
2000-01-07 -2.670153 -0.114722  0.168904 -0.048048
2000-01-08  0.801196  1.392071 -0.048788 -0.808838

---->   DataFrame.copy

--------------------------------------
ID: 380 --> 1
In [199]: df2 = df.copy()

In [200]: df2.where(df2 > 0, df2['A'], axis='index')
Out[200]: 
                   A         B         C         D
2000-01-01 -2.104139 -2.104139  0.485855  0.245166
2000-01-02 -0.352480  0.390389 -0.352480  1.655824
2000-01-03 -0.864883  0.299674 -0.864883  0.281059
2000-01-04  0.846958  0.846958  0.600705  0.846958
2000-01-05  0.669692  0.669692  0.669692  0.342416
2000-01-06  0.868584  0.868584  2.297780  0.868584
2000-01-07 -2.670153 -2.670153  0.168904 -2.670153
2000-01-08  0.801196  1.392071  0.801196  0.801196

---->   DataFrame.copy

--------------------------------------
ID: 381 --> 1
In [201]: df2 = df.copy()

In [202]: df.apply(lambda x, y: x.where(x > 0, y), y=df['A'])
Out[202]: 
                   A         B         C         D
2000-01-01 -2.104139 -2.104139  0.485855  0.245166
2000-01-02 -0.352480  0.390389 -0.352480  1.655824
2000-01-03 -0.864883  0.299674 -0.864883  0.281059
2000-01-04  0.846958  0.846958  0.600705  0.846958
2000-01-05  0.669692  0.669692  0.669692  0.342416
2000-01-06  0.868584  0.868584  2.297780  0.868584
2000-01-07 -2.670153 -2.670153  0.168904 -2.670153
2000-01-08  0.801196  1.392071  0.801196  0.801196

---->   DataFrame.copy

--------------------------------------
ID: 382 --> 1
In [203]: df3 = pd.DataFrame({'A': [1, 2, 3],
   .....:                     'B': [4, 5, 6],
   .....:                     'C': [7, 8, 9]})
   .....: 

In [204]: df3.where(lambda x: x > 4, lambda x: x + 10)
Out[204]: 
    A   B  C
0  11  14  7
1  12   5  8
2  13   6  9

---->   pandas.DataFrame

--------------------------------------
ID: 384 --> 1
In [207]: df = pd.DataFrame({'col1': list('ABBC'), 'col2': list('ZZXY')})

In [208]: df['color'] = np.where(df['col2'] == 'Z', 'green', 'red')

In [209]: df
Out[209]: 
  col1 col2  color
0    A    Z  green
1    B    Z  green
2    B    X    red
3    C    Y    red

---->   pandas.DataFrame

--------------------------------------
ID: 386 --> 1
In [214]: n = 10

In [215]: df = pd.DataFrame(np.random.rand(n, 3), columns=list('abc'))

In [216]: df
Out[216]: 
          a         b         c
0  0.438921  0.118680  0.863670
1  0.138138  0.577363  0.686602
2  0.595307  0.564592  0.520630
3  0.913052  0.926075  0.616184
4  0.078718  0.854477  0.898725
5  0.076404  0.523211  0.591538
6  0.792342  0.216974  0.564056
7  0.397890  0.454131  0.915716
8  0.074315  0.437913  0.019794
9  0.559209  0.502065  0.026437

# pure python
In [217]: df[(df['a'] < df['b']) & (df['b'] < df['c'])]
Out[217]: 
          a         b         c
1  0.138138  0.577363  0.686602
4  0.078718  0.854477  0.898725
5  0.076404  0.523211  0.591538
7  0.397890  0.454131  0.915716

# query
In [218]: df.query('(a < b) & (b < c)')
Out[218]: 
          a         b         c
1  0.138138  0.577363  0.686602
4  0.078718  0.854477  0.898725
5  0.076404  0.523211  0.591538
7  0.397890  0.454131  0.915716

---->   pandas.DataFrame

--------------------------------------
ID: 387 --> 1
In [219]: df = pd.DataFrame(np.random.randint(n / 2, size=(n, 2)), columns=list('bc'))

In [220]: df.index.name = 'a'

In [221]: df
Out[221]: 
   b  c
a      
0  0  4
1  0  1
2  3  4
3  4  3
4  1  4
5  0  3
6  0  1
7  3  4
8  2  3
9  1  1

In [222]: df.query('a < b and b < c')
Out[222]: 
   b  c
a      
2  3  4

---->   pandas.DataFrame

--------------------------------------
ID: 388 --> 1
In [223]: df = pd.DataFrame(np.random.randint(n, size=(n, 2)), columns=list('bc'))

In [224]: df
Out[224]: 
   b  c
0  3  1
1  3  0
2  5  6
3  5  2
4  7  4
5  0  1
6  2  5
7  0  1
8  6  0
9  7  9

In [225]: df.query('index < b < c')
Out[225]: 
   b  c
2  5  6

---->   pandas.DataFrame

--------------------------------------
ID: 389 --> 1
In [226]: df = pd.DataFrame({'a': np.random.randint(5, size=5)})

In [227]: df.index.name = 'a'

In [228]: df.query('a > 2')  # uses the column 'a', not the index
Out[228]: 
   a
a   
1  3
3  3

---->   pandas.DataFrame

--------------------------------------
ID: 391 --> 2
In [230]: n = 10

In [231]: colors = np.random.choice(['red', 'green'], size=n)

In [232]: foods = np.random.choice(['eggs', 'ham'], size=n)

In [233]: colors
Out[233]: 
array(['red', 'red', 'red', 'green', 'green', 'green', 'green', 'green',
       'green', 'green'], dtype='

In [234]: foods
Out[234]: 
array(['ham', 'ham', 'eggs', 'eggs', 'eggs', 'ham', 'ham', 'eggs', 'eggs',
       'eggs'], dtype='

In [235]: index = pd.MultiIndex.from_arrays([colors, foods], names=['color', 'food'])

In [236]: df = pd.DataFrame(np.random.randn(n, 2), index=index)

In [237]: df
Out[237]: 
                   0         1
color food                    
red   ham   0.194889 -0.381994
      ham   0.318587  2.089075
      eggs -0.728293 -0.090255
green eggs -0.748199  1.318931
      eggs -2.029766  0.792652
      ham   0.461007 -0.542749
      ham  -0.305384 -0.479195
      eggs  0.095031 -0.270099
      eggs -0.707140 -0.773882
      eggs  0.229453  0.304418

In [238]: df.query('color == "red"')
Out[238]: 
                   0         1
color food                    
red   ham   0.194889 -0.381994
      ham   0.318587  2.089075
      eggs -0.728293 -0.090255

---->   pandas.MultiIndex; pandas.DataFrame

--------------------------------------
ID: 393 --> 1
In [242]: df = pd.DataFrame(np.random.rand(n, 3), columns=list('abc'))

In [243]: df
Out[243]: 
          a         b         c
0  0.224283  0.736107  0.139168
1  0.302827  0.657803  0.713897
2  0.611185  0.136624  0.984960
3  0.195246  0.123436  0.627712
4  0.618673  0.371660  0.047902
5  0.480088  0.062993  0.185760
6  0.568018  0.483467  0.445289
7  0.309040  0.274580  0.587101
8  0.258993  0.477769  0.370255
9  0.550459  0.840870  0.304611

In [244]: df2 = pd.DataFrame(np.random.rand(n + 2, 3), columns=df.columns)

In [245]: df2
Out[245]: 
           a         b         c
0   0.357579  0.229800  0.596001
1   0.309059  0.957923  0.965663
2   0.123102  0.336914  0.318616
3   0.526506  0.323321  0.860813
4   0.518736  0.486514  0.384724
5   0.190804  0.505723  0.614533
6   0.891939  0.623977  0.676639
7   0.480559  0.378528  0.460858
8   0.420223  0.136404  0.141295
9   0.732206  0.419540  0.604675
10  0.604466  0.848974  0.896165
11  0.589168  0.920046  0.732716

In [246]: expr = '0.0 <= a <= c <= 0.5'

In [247]: map(lambda frame: frame.query(expr), [df, df2])
Out[247]: 

---->   pandas.DataFrame

--------------------------------------
ID: 394 --> 1
In [248]: df = pd.DataFrame(np.random.randint(n, size=(n, 3)), columns=list('abc'))

In [249]: df
Out[249]: 
   a  b  c
0  7  8  9
1  1  0  7
2  2  7  2
3  6  2  2
4  2  6  3
5  3  8  2
6  1  7  2
7  5  1  5
8  9  8  0
9  1  5  0

In [250]: df.query('(a < b) & (b < c)')
Out[250]: 
   a  b  c
0  7  8  9

In [251]: df[(df['a'] < df['b']) & (df['b'] < df['c'])]
Out[251]: 
   a  b  c
0  7  8  9

---->   pandas.DataFrame

--------------------------------------
ID: 398 --> 1
# get all rows where columns "a" and "b" have overlapping values
In [255]: df = pd.DataFrame({'a': list('aabbccddeeff'), 'b': list('aaaabbbbcccc'),
   .....:                    'c': np.random.randint(5, size=12),
   .....:                    'd': np.random.randint(9, size=12)})
   .....: 

In [256]: df
Out[256]: 
    a  b  c  d
0   a  a  2  6
1   a  a  4  7
2   b  a  1  6
3   b  a  2  1
4   c  b  3  6
5   c  b  0  2
6   d  b  3  3
7   d  b  2  1
8   e  c  4  3
9   e  c  2  0
10  f  c  0  6
11  f  c  1  2

In [257]: df.query('a in b')
Out[257]: 
   a  b  c  d
0  a  a  2  6
1  a  a  4  7
2  b  a  1  6
3  b  a  2  1
4  c  b  3  6
5  c  b  0  2

# How you'd do it in pure Python
In [258]: df[df['a'].isin(df['b'])]
Out[258]: 
   a  b  c  d
0  a  a  2  6
1  a  a  4  7
2  b  a  1  6
3  b  a  2  1
4  c  b  3  6
5  c  b  0  2

In [259]: df.query('a not in b')
Out[259]: 
    a  b  c  d
6   d  b  3  3
7   d  b  2  1
8   e  c  4  3
9   e  c  2  0
10  f  c  0  6
11  f  c  1  2

# pure Python
In [260]: df[~df['a'].isin(df['b'])]
Out[260]: 
    a  b  c  d
6   d  b  3  3
7   d  b  2  1
8   e  c  4  3
9   e  c  2  0
10  f  c  0  6
11  f  c  1  2

---->   pandas.DataFrame

--------------------------------------
ID: 402 --> 1
In [270]: df = pd.DataFrame(np.random.rand(n, 3), columns=list('abc'))

In [271]: df['bools'] = np.random.rand(len(df)) > 0.5

In [272]: df.query('~bools')
Out[272]: 
          a         b         c  bools
2  0.697753  0.212799  0.329209  False
7  0.275396  0.691034  0.826619  False
8  0.190649  0.558748  0.262467  False

In [273]: df.query('not bools')
Out[273]: 
          a         b         c  bools
2  0.697753  0.212799  0.329209  False
7  0.275396  0.691034  0.826619  False
8  0.190649  0.558748  0.262467  False

In [274]: df.query('not bools') == df[~df['bools']]
Out[274]: 
      a     b     c  bools
2  True  True  True   True
7  True  True  True   True
8  True  True  True   True

---->   pandas.DataFrame

--------------------------------------
ID: 404 --> 2
In [280]: df2 = pd.DataFrame({'a': ['one', 'one', 'two', 'two', 'two', 'three', 'four'],
   .....:                     'b': ['x', 'y', 'x', 'y', 'x', 'x', 'x'],
   .....:                     'c': np.random.randn(7)})
   .....: 

In [281]: df2
Out[281]: 
       a  b         c
0    one  x -1.067137
1    one  y  0.309500
2    two  x -0.211056
3    two  y -1.842023
4    two  x -0.390820
5  three  x -1.964475
6   four  x  1.298329

In [282]: df2.duplicated('a')
Out[282]: 
0    False
1     True
2    False
3     True
4     True
5    False
6    False
dtype: bool

In [283]: df2.duplicated('a', keep='last')
Out[283]: 
0     True
1    False
2     True
3     True
4    False
5    False
6    False
dtype: bool

In [284]: df2.duplicated('a', keep=False)
Out[284]: 
0     True
1     True
2     True
3     True
4     True
5    False
6    False
dtype: bool

In [285]: df2.drop_duplicates('a')
Out[285]: 
       a  b         c
0    one  x -1.067137
2    two  x -0.211056
5  three  x -1.964475
6   four  x  1.298329

In [286]: df2.drop_duplicates('a', keep='last')
Out[286]: 
       a  b         c
1    one  y  0.309500
4    two  x -0.390820
5  three  x -1.964475
6   four  x  1.298329

In [287]: df2.drop_duplicates('a', keep=False)
Out[287]: 
       a  b         c
5  three  x -1.964475
6   four  x  1.298329

---->   pandas.DataFrame; DataFrame.duplicated

--------------------------------------
ID: 405 --> 1
In [288]: df2.duplicated(['a', 'b'])
Out[288]: 
0    False
1    False
2    False
3    False
4     True
5    False
6    False
dtype: bool

In [289]: df2.drop_duplicates(['a', 'b'])
Out[289]: 
       a  b         c
0    one  x -1.067137
1    one  y  0.309500
2    two  x -0.211056
3    two  y -1.842023
5  three  x -1.964475
6   four  x  1.298329

---->   DataFrame.duplicated

--------------------------------------
ID: 406 --> 1
In [290]: df3 = pd.DataFrame({'a': np.arange(6),
   .....:                     'b': np.random.randn(6)},
   .....:                    index=['a', 'a', 'b', 'c', 'b', 'a'])
   .....: 

In [291]: df3
Out[291]: 
   a         b
a  0  1.440455
a  1  2.456086
b  2  1.038402
c  3 -0.894409
b  4  0.683536
a  5  3.082764

In [292]: df3.index.duplicated()
Out[292]: array([False,  True, False, False,  True,  True])

In [293]: df3[~df3.index.duplicated()]
Out[293]: 
   a         b
a  0  1.440455
b  2  1.038402
c  3 -0.894409

In [294]: df3[~df3.index.duplicated(keep='last')]
Out[294]: 
   a         b
c  3 -0.894409
b  4  0.683536
a  5  3.082764

In [295]: df3[~df3.index.duplicated(keep=False)]
Out[295]: 
   a         b
c  3 -0.894409

---->   pandas.DataFrame

--------------------------------------
ID: 407 --> 2
In [296]: s = pd.Series([1, 2, 3], index=['a', 'b', 'c'])

In [297]: s.get('a')  # equivalent to s['a']
Out[297]: 1

In [298]: s.get('x', default=-1)
Out[298]: -1

---->   pandas.Series; Series.get

--------------------------------------
ID: 408 --> 2
In [299]: df = pd.DataFrame({'col': ["A", "A", "B", "B"],
   .....:                    'A': [80, 23, np.nan, 22],
   .....:                    'B': [80, 55, 76, 67]})
   .....: 

In [300]: df
Out[300]: 
  col     A   B
0   A  80.0  80
1   A  23.0  55
2   B   NaN  76
3   B  22.0  67

In [301]: idx, cols = pd.factorize(df['col'])

In [302]: df.reindex(cols, axis=1).to_numpy()[np.arange(len(df)), idx]
Out[302]: array([80., 23., 76., 67.])

---->   pandas.DataFrame; pandas.factorize

--------------------------------------
ID: 409 --> 1
In [303]: index = pd.Index(['e', 'd', 'a', 'b'])

In [304]: index
Out[304]: Index(['e', 'd', 'a', 'b'], dtype='object')

In [305]: 'd' in index
Out[305]: True

---->   pandas.Index

--------------------------------------
ID: 410 --> 1
In [306]: index = pd.Index([1, 5, 12])

In [307]: index
Out[307]: Index([1, 5, 12], dtype='int64')

In [308]: 5 in index
Out[308]: True

---->   pandas.Index

--------------------------------------
ID: 411 --> 1
In [309]: index = pd.Index(['e', 'd', 'a', 'b'], dtype="string")

In [310]: index
Out[310]: Index(['e', 'd', 'a', 'b'], dtype='string')

In [311]: index = pd.Index([1, 5, 12], dtype="int8")

In [312]: index
Out[312]: Index([1, 5, 12], dtype='int8')

In [313]: index = pd.Index([1, 5, 12], dtype="float32")

In [314]: index
Out[314]: Index([1.0, 5.0, 12.0], dtype='float32')

---->   pandas.Index

--------------------------------------
ID: 412 --> 1
In [315]: index = pd.Index(['e', 'd', 'a', 'b'], name='something')

In [316]: index.name
Out[316]: 'something'

---->   pandas.Index

--------------------------------------
ID: 413 --> 2
In [317]: index = pd.Index(list(range(5)), name='rows')

In [318]: columns = pd.Index(['A', 'B', 'C'], name='cols')

In [319]: df = pd.DataFrame(np.random.randn(5, 3), index=index, columns=columns)

In [320]: df
Out[320]: 
cols         A         B         C
rows                              
0     1.295989 -1.051694  1.340429
1    -2.366110  0.428241  0.387275
2     0.433306  0.929548  0.278094
3     2.154730 -0.315628  0.264223
4     1.126818  1.132290 -0.353310

In [321]: df['A']
Out[321]: 
rows
0    1.295989
1   -2.366110
2    0.433306
3    2.154730
4    1.126818
Name: A, dtype: float64

---->   pandas.Index; pandas.DataFrame

--------------------------------------
ID: 414 --> 2
In [322]: ind = pd.Index([1, 2, 3])

In [323]: ind.rename("apple")
Out[323]: Index([1, 2, 3], dtype='int64', name='apple')

In [324]: ind
Out[324]: Index([1, 2, 3], dtype='int64')

In [325]: ind = ind.set_names(["apple"])

In [326]: ind.name = "bob"

In [327]: ind
Out[327]: Index([1, 2, 3], dtype='int64', name='bob')

---->   pandas.Index; Index.rename

--------------------------------------
ID: 415 --> 1
In [328]: index = pd.MultiIndex.from_product([range(3), ['one', 'two']], names=['first', 'second'])

In [329]: index
Out[329]: 
MultiIndex([(0, 'one'),
            (0, 'two'),
            (1, 'one'),
            (1, 'two'),
            (2, 'one'),
            (2, 'two')],
           names=['first', 'second'])

In [330]: index.levels[1]
Out[330]: Index(['one', 'two'], dtype='object', name='second')

In [331]: index.set_levels(["a", "b"], level=1)
Out[331]: 
MultiIndex([(0, 'a'),
            (0, 'b'),
            (1, 'a'),
            (1, 'b'),
            (2, 'a'),
            (2, 'b')],
           names=['first', 'second'])

---->   pandas.MultiIndex

--------------------------------------
ID: 416 --> 2
In [332]: a = pd.Index(['c', 'b', 'a'])

In [333]: b = pd.Index(['c', 'e', 'd'])

In [334]: a.difference(b)
Out[334]: Index(['a', 'b'], dtype='object')

---->   pandas.Index; Index.difference

--------------------------------------
ID: 417 --> 2
In [335]: idx1 = pd.Index([1, 2, 3, 4])

In [336]: idx2 = pd.Index([2, 3, 4, 5])

In [337]: idx1.symmetric_difference(idx2)
Out[337]: Index([1, 5], dtype='int64')

---->   pandas.Index; Index.symmetric_difference

--------------------------------------
ID: 418 --> 2
In [338]: idx1 = pd.Index([0, 1, 2])

In [339]: idx2 = pd.Index([0.5, 1.5])

In [340]: idx1.union(idx2)
Out[340]: Index([0.0, 0.5, 1.0, 1.5, 2.0], dtype='float64')

---->   pandas.Index; Index.union

--------------------------------------
ID: 419 --> 4
In [341]: idx1 = pd.Index([1, np.nan, 3, 4])

In [342]: idx1
Out[342]: Index([1.0, nan, 3.0, 4.0], dtype='float64')

In [343]: idx1.fillna(2)
Out[343]: Index([1.0, 2.0, 3.0, 4.0], dtype='float64')

In [344]: idx2 = pd.DatetimeIndex([pd.Timestamp('2011-01-01'),
   .....:                          pd.NaT,
   .....:                          pd.Timestamp('2011-01-03')])
   .....: 

In [345]: idx2
Out[345]: DatetimeIndex(['2011-01-01', 'NaT', '2011-01-03'], dtype='datetime64[ns]', freq=None)

In [346]: idx2.fillna(pd.Timestamp('2011-01-02'))
Out[346]: DatetimeIndex(['2011-01-01', '2011-01-02', '2011-01-03'], dtype='datetime64[ns]', freq=None)

---->   pandas.Index; Index.fillna; pandas.DatetimeIndex; Index.fillna

--------------------------------------
ID: 425 --> 2
In [360]: dfmi = pd.DataFrame([list('abcd'),
   .....:                      list('efgh'),
   .....:                      list('ijkl'),
   .....:                      list('mnop')],
   .....:                     columns=pd.MultiIndex.from_product([['one', 'two'],
   .....:                                                         ['first', 'second']]))
   .....: 

In [361]: dfmi
Out[361]: 
    one          two       
  first second first second
0     a      b     c      d
1     e      f     g      h
2     i      j     k      l
3     m      n     o      p

---->   pandas.DataFrame; pandas.MultiIndex

--------------------------------------
ID: 430 --> 1
In [364]: dfb = pd.DataFrame({'a': ['one', 'one', 'two',
   .....:                           'three', 'two', 'one', 'six'],
   .....:                     'c': np.arange(7)})
   .....: 

# This will show the SettingWithCopyWarning
# but the frame values will be set
In [365]: dfb['c'][dfb['a'].str.startswith('o')] = 42

---->   pandas.DataFrame

--------------------------------------
ID: 432 --> 1
In [366]: dfc = pd.DataFrame({'a': ['one', 'one', 'two',
   .....:                           'three', 'two', 'one', 'six'],
   .....:                     'c': np.arange(7)})
   .....: 

In [367]: dfd = dfc.copy()

# Setting multiple items using a mask
In [368]: mask = dfd['a'].str.startswith('o')

In [369]: dfd.loc[mask, 'c'] = 42

In [370]: dfd
Out[370]: 
       a   c
0    one  42
1    one  42
2    two   2
3  three   3
4    two   4
5    one  42
6    six   6

# Setting a single item
In [371]: dfd = dfc.copy()

In [372]: dfd.loc[2, 'a'] = 11

In [373]: dfd
Out[373]: 
       a  c
0    one  0
1    one  1
2     11  2
3  three  3
4    two  4
5    one  5
6    six  6

---->   pandas.DataFrame

--------------------------------------
ID: 435 --> 1
In [1]: arr = np.random.randn(10)

In [2]: arr[2:-2] = np.nan

In [3]: ts = pd.Series(pd.arrays.SparseArray(arr))

In [4]: ts
Out[4]: 
0    0.469112
1   -0.282863
2         NaN
3         NaN
4         NaN
5         NaN
6         NaN
7         NaN
8   -0.861849
9   -2.104569
dtype: Sparse[float64, nan]

---->   pandas.Series

--------------------------------------
ID: 436 --> 2
In [5]: df = pd.DataFrame(np.random.randn(10000, 4))

In [6]: df.iloc[:9998] = np.nan

In [7]: sdf = df.astype(pd.SparseDtype("float", np.nan))

In [8]: sdf.head()
Out[8]: 
    0   1   2   3
0 NaN NaN NaN NaN
1 NaN NaN NaN NaN
2 NaN NaN NaN NaN
3 NaN NaN NaN NaN
4 NaN NaN NaN NaN

In [9]: sdf.dtypes
Out[9]: 
0    Sparse[float64, nan]
1    Sparse[float64, nan]
2    Sparse[float64, nan]
3    Sparse[float64, nan]
dtype: object

In [10]: sdf.sparse.density
Out[10]: 0.0002

---->   pandas.DataFrame; DataFrame.astype

--------------------------------------
ID: 437 --> 1
In [11]: 'dense : {:0.2f} bytes'.format(df.memory_usage().sum() / 1e3)
Out[11]: 'dense : 320.13 bytes'

In [12]: 'sparse: {:0.2f} bytes'.format(sdf.memory_usage().sum() / 1e3)
Out[12]: 'sparse: 0.22 bytes'

---->   DataFrame.memory_usage

--------------------------------------
ID: 442 --> 1
In [22]: pd.array([1, 0, 0, 2], dtype='Sparse[int]')
Out[22]: 
[1, 0, 0, 2]
Fill: 0
IntIndex
Indices: array([0, 3], dtype=int32)

---->   pandas.array

--------------------------------------
ID: 443 --> 1
In [23]: s = pd.Series([0, 0, 1, 2], dtype="Sparse[int]")

In [24]: s.sparse.density
Out[24]: 0.5

In [25]: s.sparse.fill_value
Out[25]: 0

---->   pandas.Series

--------------------------------------
ID: 447 --> 1
# New way
In [31]: pd.DataFrame({"A": pd.arrays.SparseArray([0, 1])})
Out[31]: 
   A
0  0
1  1

---->   pandas.DataFrame

--------------------------------------
ID: 449 --> 1
# New way
In [32]: from scipy import sparse

In [33]: mat = sparse.eye(3)

In [34]: df = pd.DataFrame.sparse.from_spmatrix(mat, columns=['A', 'B', 'C'])

In [35]: df.dtypes
Out[35]: 
A    Sparse[float64, 0]
B    Sparse[float64, 0]
C    Sparse[float64, 0]
dtype: object

---->   pandas.DataFrame

--------------------------------------
ID: 451 --> 2
In [38]: dense = pd.DataFrame({"A": [1, 0, 0, 1]})

In [39]: dtype = pd.SparseDtype(int, fill_value=0)

In [40]: dense.astype(dtype)
Out[40]: 
   A
0  1
1  0
2  0
3  1

---->   pandas.DataFrame; DataFrame.astype

--------------------------------------
ID: 453 --> 1
In [42]: df = pd.DataFrame({"A": pd.arrays.SparseArray([0, 1])})

In [43]: df['B'] = [0, 0]  # remains dense

In [44]: df['B'].dtype
Out[44]: dtype('int64')

In [45]: df['B'] = pd.arrays.SparseArray([0, 0])

In [46]: df['B'].dtype
Out[46]: Sparse[int64, 0]

---->   pandas.DataFrame

--------------------------------------
ID: 454 --> 1
In [47]: from scipy.sparse import csr_matrix

In [48]: arr = np.random.random(size=(1000, 5))

In [49]: arr[arr < .9] = 0

In [50]: sp_arr = csr_matrix(arr)

In [51]: sp_arr
Out[51]: 
<1000x5 sparse matrix of type ''
	with 517 stored elements in Compressed Sparse Row format>

In [52]: sdf = pd.DataFrame.sparse.from_spmatrix(sp_arr)

In [53]: sdf.head()
Out[53]: 
          0    1    2         3    4
0  0.956380  0.0  0.0  0.000000  0.0
1  0.000000  0.0  0.0  0.000000  0.0
2  0.000000  0.0  0.0  0.000000  0.0
3  0.000000  0.0  0.0  0.000000  0.0
4  0.999552  0.0  0.0  0.956153  0.0

In [54]: sdf.dtypes
Out[54]: 
0    Sparse[float64, 0]
1    Sparse[float64, 0]
2    Sparse[float64, 0]
3    Sparse[float64, 0]
4    Sparse[float64, 0]
dtype: object

---->   pandas.DataFrame

--------------------------------------
ID: 456 --> 3
In [56]: s = pd.Series([3.0, np.nan, 1.0, 3.0, np.nan, np.nan])

In [57]: s.index = pd.MultiIndex.from_tuples(
   ....:     [
   ....:         (1, 2, "a", 0),
   ....:         (1, 2, "a", 1),
   ....:         (1, 1, "b", 0),
   ....:         (1, 1, "b", 1),
   ....:         (2, 1, "b", 0),
   ....:         (2, 1, "b", 1),
   ....:     ],
   ....:     names=["A", "B", "C", "D"],
   ....: )
   ....: 

In [58]: ss = s.astype('Sparse')

In [59]: ss
Out[59]: 
A  B  C  D
1  2  a  0    3.0
         1    NaN
   1  b  0    1.0
         1    3.0
2  1  b  0    NaN
         1    NaN
dtype: Sparse[float64, nan]

---->   pandas.Series; pandas.MultiIndex; Series.astype

--------------------------------------
ID: 460 --> 1
In [74]: ss = pd.Series.sparse.from_coo(A)

In [75]: ss
Out[75]: 
0  2    1.0
   3    2.0
1  0    3.0
dtype: Sparse[float64, nan]

---->   pandas.Series

--------------------------------------
ID: 461 --> 1
In [76]: ss_dense = pd.Series.sparse.from_coo(A, dense_index=True)

In [77]: ss_dense
Out[77]: 
1  0    3.0
   2    NaN
   3    NaN
0  0    NaN
   2    1.0
   3    2.0
   0    NaN
   2    1.0
   3    2.0
dtype: Sparse[float64, nan]

---->   pandas.Series

--------------------------------------
ID: 462 --> 1
In [1]: import pandas as pd

In [2]: import numpy as np

In [3]: def make_timeseries(start="2000-01-01", end="2000-12-31", freq="1D", seed=None):
   ...:     index = pd.date_range(start=start, end=end, freq=freq, name="timestamp")
   ...:     n = len(index)
   ...:     state = np.random.RandomState(seed)
   ...:     columns = {
   ...:         "name": state.choice(["Alice", "Bob", "Charlie"], size=n),
   ...:         "id": state.poisson(1000, size=n),
   ...:         "x": state.rand(n) * 2 - 1,
   ...:         "y": state.rand(n) * 2 - 1,
   ...:     }
   ...:     df = pd.DataFrame(columns, index=index, columns=sorted(columns))
   ...:     if df.index[-1] == end:
   ...:         df = df.iloc[:-1]
   ...:     return df
   ...: 

In [4]: timeseries = [
   ...:     make_timeseries(freq="1T", seed=i).rename(columns=lambda x: f"{x}_{i}")
   ...:     for i in range(10)
   ...: ]
   ...: 

In [5]: ts_wide = pd.concat(timeseries, axis=1)

In [6]: ts_wide.to_parquet("timeseries_wide.parquet")

---->   pandas.DataFrame

--------------------------------------
ID: 463 --> 1
In [7]: columns = ["id_0", "name_0", "x_0", "y_0"]

In [8]: pd.read_parquet("timeseries_wide.parquet")[columns]
Out[8]: 
                     id_0 name_0       x_0       y_0
timestamp                                           
2000-01-01 00:00:00   977  Alice -0.821225  0.906222
2000-01-01 00:01:00  1018    Bob -0.219182  0.350855
2000-01-01 00:02:00   927  Alice  0.660908 -0.798511
2000-01-01 00:03:00   997    Bob -0.852458  0.735260
2000-01-01 00:04:00   965    Bob  0.717283  0.393391
...                   ...    ...       ...       ...
2000-12-30 23:56:00  1037    Bob -0.814321  0.612836
2000-12-30 23:57:00   980    Bob  0.232195 -0.618828
2000-12-30 23:58:00   965  Alice -0.231131  0.026310
2000-12-30 23:59:00   984  Alice  0.942819  0.853128
2000-12-31 00:00:00  1003  Alice  0.201125 -0.136655

[525601 rows x 4 columns]

---->   pandas.read_parquet

--------------------------------------
ID: 464 --> 1
In [9]: pd.read_parquet("timeseries_wide.parquet", columns=columns)
Out[9]: 
                     id_0 name_0       x_0       y_0
timestamp                                           
2000-01-01 00:00:00   977  Alice -0.821225  0.906222
2000-01-01 00:01:00  1018    Bob -0.219182  0.350855
2000-01-01 00:02:00   927  Alice  0.660908 -0.798511
2000-01-01 00:03:00   997    Bob -0.852458  0.735260
2000-01-01 00:04:00   965    Bob  0.717283  0.393391
...                   ...    ...       ...       ...
2000-12-30 23:56:00  1037    Bob -0.814321  0.612836
2000-12-30 23:57:00   980    Bob  0.232195 -0.618828
2000-12-30 23:58:00   965  Alice -0.231131  0.026310
2000-12-30 23:59:00   984  Alice  0.942819  0.853128
2000-12-31 00:00:00  1003  Alice  0.201125 -0.136655

[525601 rows x 4 columns]

---->   pandas.read_parquet

--------------------------------------
ID: 465 --> 1
In [10]: ts = make_timeseries(freq="30S", seed=0)

In [11]: ts.to_parquet("timeseries.parquet")

In [12]: ts = pd.read_parquet("timeseries.parquet")

In [13]: ts
Out[13]: 
                       id     name         x         y
timestamp                                             
2000-01-01 00:00:00  1041    Alice  0.889987  0.281011
2000-01-01 00:00:30   988      Bob -0.455299  0.488153
2000-01-01 00:01:00  1018    Alice  0.096061  0.580473
2000-01-01 00:01:30   992      Bob  0.142482  0.041665
2000-01-01 00:02:00   960      Bob -0.036235  0.802159
...                   ...      ...       ...       ...
2000-12-30 23:58:00  1022    Alice  0.266191  0.875579
2000-12-30 23:58:30   974    Alice -0.009826  0.413686
2000-12-30 23:59:00  1028  Charlie  0.307108 -0.656789
2000-12-30 23:59:30  1002    Alice  0.202602  0.541335
2000-12-31 00:00:00   987    Alice  0.200832  0.615972

[1051201 rows x 4 columns]

---->   pandas.read_parquet

--------------------------------------
ID: 466 --> 1
In [15]: ts.memory_usage(deep=True)  # memory usage in bytes
Out[15]: 
Index     8409608
id        8409608
name     65176434
x         8409608
y         8409608
dtype: int64

---->   Series.memory_usage

--------------------------------------
ID: 467 --> 1
In [16]: ts2 = ts.copy()

In [17]: ts2["name"] = ts2["name"].astype("category")

In [18]: ts2.memory_usage(deep=True)
Out[18]: 
Index    8409608
id       8409608
name     1051495
x        8409608
y        8409608
dtype: int64

---->   Series.copy

--------------------------------------
ID: 468 --> 1
In [19]: ts2["id"] = pd.to_numeric(ts2["id"], downcast="unsigned")

In [20]: ts2[["x", "y"]] = ts2[["x", "y"]].apply(pd.to_numeric, downcast="float")

In [21]: ts2.dtypes
Out[21]: 
id        uint16
name    category
x        float32
y        float32
dtype: object

---->   pandas.to_numeric

--------------------------------------
ID: 470 --> 1
In [23]: reduction = ts2.memory_usage(deep=True).sum() / ts.memory_usage(deep=True).sum()

In [24]: print(f"{reduction:0.2f}")
0.20

---->   Series.memory_usage

--------------------------------------
ID: 472 --> 2
In [31]: %%time
   ....: files = pathlib.Path("data/timeseries/").glob("ts*.parquet")
   ....: counts = pd.Series(dtype=int)
   ....: for path in files:
   ....:     df = pd.read_parquet(path)
   ....:     counts = counts.add(df["name"].value_counts(), fill_value=0)
   ....: counts.astype(int)
   ....: 
CPU times: user 910 ms, sys: 73 ms, total: 983 ms
Wall time: 771 ms
Out[31]: 
name
Alice      1994645
Bob        1993692
Charlie    1994875
dtype: int64

---->   pandas.Series; pandas.read_parquet

--------------------------------------
ID: 479 --> 1
In [43]: N = 12

In [44]: starts = [f"20{i:>02d}-01-01" for i in range(N)]

In [45]: ends = [f"20{i:>02d}-12-13" for i in range(N)]

In [46]: divisions = tuple(pd.to_datetime(starts)) + (pd.Timestamp(ends[-1]),)

In [47]: ddf.divisions = divisions

In [48]: ddf
Out[48]: 
Dask DataFrame Structure:
                   id    name        x        y
npartitions=12                                 
2000-01-01      int64  object  float64  float64
2001-01-01        ...     ...      ...      ...
...               ...     ...      ...      ...
2011-01-01        ...     ...      ...      ...
2011-12-13        ...     ...      ...      ...
Dask Name: read-parquet, 1 graph layer

---->   pandas.to_datetime

--------------------------------------
ID: 486 --> 1
In [21]: df2 = pd.read_csv(StringIO(data))

In [22]: df2["col_1"] = pd.to_numeric(df2["col_1"], errors="coerce")

In [23]: df2
Out[23]: 
   col_1
0   1.00
1   2.00
2    NaN
3   4.22

In [24]: df2["col_1"].apply(type).value_counts()
Out[24]: 
col_1
    4
Name: count, dtype: int64

---->   pandas.to_numeric

--------------------------------------
ID: 487 --> 2
In [25]: col_1 = list(range(500000)) + ["a", "b"] + list(range(500000))

In [26]: df = pd.DataFrame({"col_1": col_1})

In [27]: df.to_csv("foo.csv")

In [28]: mixed_df = pd.read_csv("foo.csv")

In [29]: mixed_df["col_1"].apply(type).value_counts()
Out[29]: 
col_1
    737858
    262144
Name: count, dtype: int64

In [30]: mixed_df["col_1"].dtype
Out[30]: dtype('O')

---->   pandas.DataFrame; DataFrame.to_csv

--------------------------------------
ID: 493 --> 1
In [45]: df = pd.read_csv(StringIO(data), dtype="category")

In [46]: df.dtypes
Out[46]: 
col1    category
col2    category
col3    category
dtype: object

In [47]: df["col3"]
Out[47]: 
0    1
1    2
2    3
Name: col3, dtype: category
Categories (3, object): ['1', '2', '3']

In [48]: new_categories = pd.to_numeric(df["col3"].cat.categories)

In [49]: df["col3"] = df["col3"].cat.rename_categories(new_categories)

In [50]: df["col3"]
Out[50]: 
0    1
1    2
2    3
Name: col3, dtype: category
Categories (3, int64): [1, 2, 3]

---->   pandas.to_numeric

--------------------------------------
ID: 518 --> 1
In [121]: df = pd.read_csv(StringIO(content))

In [122]: df["a"] = pd.to_datetime(df["a"], utc=True)

In [123]: df["a"]
Out[123]: 
0   1999-12-31 19:00:00+00:00
1   1999-12-31 18:00:00+00:00
Name: a, dtype: datetime64[ns, UTC]

---->   pandas.to_datetime

--------------------------------------
ID: 520 --> 1
In [126]: data = io.StringIO("date\n12 Jan 2000\n2000-01-13\n")

In [127]: df = pd.read_csv(data)

In [128]: df['date'] = pd.to_datetime(df['date'], format='mixed')

In [129]: df
Out[129]: 
        date
0 2000-01-12
1 2000-01-13

---->   pandas.to_datetime

--------------------------------------
ID: 521 --> 1
In [130]: data = io.StringIO("date\n2020-01-01\n2020-01-01 03:00\n")

In [131]: df = pd.read_csv(data)

In [132]: df['date'] = pd.to_datetime(df['date'], format='ISO8601')

In [133]: df
Out[133]: 
                 date
0 2020-01-01 00:00:00
1 2020-01-01 03:00:00

---->   pandas.to_datetime

--------------------------------------
ID: 523 --> 2
In [139]: import io

In [140]: data = pd.DataFrame([0, 1, 2])

In [141]: buffer = io.BytesIO()

In [142]: data.to_csv(buffer, encoding="utf-8", compression="gzip")

---->   pandas.DataFrame; DataFrame.to_csv

--------------------------------------
ID: 553 --> 1
In [200]: from pandas._testing import makeCustomDataframe as mkdf

In [201]: df = mkdf(5, 3, r_idx_nlevels=2, c_idx_nlevels=4)

In [202]: df.to_csv("mi.csv")

In [203]: print(open("mi.csv").read())
C0,,C_l0_g0,C_l0_g1,C_l0_g2
C1,,C_l1_g0,C_l1_g1,C_l1_g2
C2,,C_l2_g0,C_l2_g1,C_l2_g2
C3,,C_l3_g0,C_l3_g1,C_l3_g2
R0,R1,,,
R_l0_g0,R_l1_g0,R0C0,R0C1,R0C2
R_l0_g1,R_l1_g1,R1C0,R1C1,R1C2
R_l0_g2,R_l1_g2,R2C0,R2C1,R2C2
R_l0_g3,R_l1_g3,R3C0,R3C1,R3C2
R_l0_g4,R_l1_g4,R4C0,R4C1,R4C2


In [204]: pd.read_csv("mi.csv", header=[0, 1, 2, 3], index_col=[0, 1])
Out[204]: 
C0              C_l0_g0 C_l0_g1 C_l0_g2
C1              C_l1_g0 C_l1_g1 C_l1_g2
C2              C_l2_g0 C_l2_g1 C_l2_g2
C3              C_l3_g0 C_l3_g1 C_l3_g2
R0      R1                             
R_l0_g0 R_l1_g0    R0C0    R0C1    R0C2
R_l0_g1 R_l1_g1    R1C0    R1C1    R1C2
R_l0_g2 R_l1_g2    R2C0    R2C1    R2C2
R_l0_g3 R_l1_g3    R3C0    R3C1    R3C2
R_l0_g4 R_l1_g4    R4C0    R4C1    R4C2

---->   DataFrame.to_csv

--------------------------------------
ID: 555 --> 2
In [209]: df = pd.DataFrame(np.random.randn(10, 4))

In [210]: df.to_csv("tmp.csv", sep="|")

In [211]: df.to_csv("tmp2.csv", sep=":")

In [212]: pd.read_csv("tmp2.csv", sep=None, engine="python")
Out[212]: 
   Unnamed: 0         0         1         2         3
0           0  0.469112 -0.282863 -1.509059 -1.135632
1           1  1.212112 -0.173215  0.119209 -1.044236
2           2 -0.861849 -2.104569 -0.494929  1.071804
3           3  0.721555 -0.706771 -1.039575  0.271860
4           4 -0.424972  0.567020  0.276232 -1.087401
5           5 -0.673690  0.113648 -1.478427  0.524988
6           6  0.404705  0.577046 -1.715002 -1.039268
7           7 -0.370647 -1.157892 -1.344312  0.844885
8           8  1.075770 -0.109050  1.643563 -1.469388
9           9  0.357021 -0.674600 -1.776904 -0.968914

---->   pandas.DataFrame; DataFrame.to_csv

--------------------------------------
ID: 556 --> 2
In [213]: df = pd.DataFrame(np.random.randn(10, 4))

In [214]: df.to_csv("tmp.csv", sep="|")

In [215]: table = pd.read_csv("tmp.csv", sep="|")

In [216]: table
Out[216]: 
   Unnamed: 0         0         1         2         3
0           0 -1.294524  0.413738  0.276662 -0.472035
1           1 -0.013960 -0.362543 -0.006154 -0.923061
2           2  0.895717  0.805244 -1.206412  2.565646
3           3  1.431256  1.340309 -1.170299 -0.226169
4           4  0.410835  0.813850  0.132003 -0.827317
5           5 -0.076467 -1.187678  1.130127 -1.436737
6           6 -1.413681  1.607920  1.024180  0.569605
7           7  0.875906 -2.211372  0.974466 -2.006747
8           8 -0.410001 -0.078638  0.545952 -1.219217
9           9 -1.226825  0.769804 -1.281247 -0.727707

---->   pandas.DataFrame; DataFrame.to_csv

--------------------------------------
ID: 564 --> 2
In [219]: dfj = pd.DataFrame(np.random.randn(5, 2), columns=list("AB"))

In [220]: json = dfj.to_json()

In [221]: json
Out[221]: '{"A":{"0":-0.1213062281,"1":0.6957746499,"2":0.9597255933,"3":-0.6199759194,"4":-0.7323393705},"B":{"0":-0.0978826728,"1":0.3417343559,"2":-1.1103361029,"3":0.1497483186,"4":0.6877383895}}'

---->   pandas.DataFrame; DataFrame.to_json

--------------------------------------
ID: 565 --> 2
In [222]: dfjo = pd.DataFrame(
   .....:     dict(A=range(1, 4), B=range(4, 7), C=range(7, 10)),
   .....:     columns=list("ABC"),
   .....:     index=list("xyz"),
   .....: )
   .....: 

In [223]: dfjo
Out[223]: 
   A  B  C
x  1  4  7
y  2  5  8
z  3  6  9

In [224]: sjo = pd.Series(dict(x=15, y=16, z=17), name="D")

In [225]: sjo
Out[225]: 
x    15
y    16
z    17
Name: D, dtype: int64

---->   pandas.DataFrame; pandas.Series

--------------------------------------
ID: 567 --> 1
In [227]: dfjo.to_json(orient="index")
Out[227]: '{"x":{"A":1,"B":4,"C":7},"y":{"A":2,"B":5,"C":8},"z":{"A":3,"B":6,"C":9}}'

In [228]: sjo.to_json(orient="index")
Out[228]: '{"x":15,"y":16,"z":17}'

---->   Series.to_json

--------------------------------------
ID: 568 --> 1
In [229]: dfjo.to_json(orient="records")
Out[229]: '[{"A":1,"B":4,"C":7},{"A":2,"B":5,"C":8},{"A":3,"B":6,"C":9}]'

In [230]: sjo.to_json(orient="records")
Out[230]: '[15,16,17]'

---->   Series.to_json

--------------------------------------
ID: 570 --> 1
In [232]: dfjo.to_json(orient="split")
Out[232]: '{"columns":["A","B","C"],"index":["x","y","z"],"data":[[1,4,7],[2,5,8],[3,6,9]]}'

In [233]: sjo.to_json(orient="split")
Out[233]: '{"name":"D","index":["x","y","z"],"data":[15,16,17]}'

---->   Series.to_json

--------------------------------------
ID: 571 --> 2
In [234]: dfd = pd.DataFrame(np.random.randn(5, 2), columns=list("AB"))

In [235]: dfd["date"] = pd.Timestamp("20130101")

In [236]: dfd = dfd.sort_index(axis=1, ascending=False)

In [237]: json = dfd.to_json(date_format="iso")

In [238]: json
Out[238]: '{"date":{"0":"2013-01-01T00:00:00.000","1":"2013-01-01T00:00:00.000","2":"2013-01-01T00:00:00.000","3":"2013-01-01T00:00:00.000","4":"2013-01-01T00:00:00.000"},"B":{"0":0.403309524,"1":0.3016244523,"2":-1.3698493577,"3":1.4626960492,"4":-0.8265909164},"A":{"0":0.1764443426,"1":-0.1549507744,"2":-2.1798606054,"3":-0.9542078401,"4":-1.7431609117}}'

---->   pandas.DataFrame; DataFrame.to_json

--------------------------------------
ID: 572 --> 1
In [239]: json = dfd.to_json(date_format="iso", date_unit="us")

In [240]: json
Out[240]: '{"date":{"0":"2013-01-01T00:00:00.000000","1":"2013-01-01T00:00:00.000000","2":"2013-01-01T00:00:00.000000","3":"2013-01-01T00:00:00.000000","4":"2013-01-01T00:00:00.000000"},"B":{"0":0.403309524,"1":0.3016244523,"2":-1.3698493577,"3":1.4626960492,"4":-0.8265909164},"A":{"0":0.1764443426,"1":-0.1549507744,"2":-2.1798606054,"3":-0.9542078401,"4":-1.7431609117}}'

---->   DataFrame.to_json

--------------------------------------
ID: 573 --> 1
In [241]: json = dfd.to_json(date_format="epoch", date_unit="s")

In [242]: json
Out[242]: '{"date":{"0":1356998400,"1":1356998400,"2":1356998400,"3":1356998400,"4":1356998400},"B":{"0":0.403309524,"1":0.3016244523,"2":-1.3698493577,"3":1.4626960492,"4":-0.8265909164},"A":{"0":0.1764443426,"1":-0.1549507744,"2":-2.1798606054,"3":-0.9542078401,"4":-1.7431609117}}'

---->   DataFrame.to_json

--------------------------------------
ID: 574 --> 1
In [243]: dfj2 = dfj.copy()

In [244]: dfj2["date"] = pd.Timestamp("20130101")

In [245]: dfj2["ints"] = list(range(5))

In [246]: dfj2["bools"] = True

In [247]: dfj2.index = pd.date_range("20130101", periods=5)

In [248]: dfj2.to_json("test.json")

In [249]: with open("test.json") as fh:
   .....:     print(fh.read())
   .....: 
{"A":{"1356998400000":-0.1213062281,"1357084800000":0.6957746499,"1357171200000":0.9597255933,"1357257600000":-0.6199759194,"1357344000000":-0.7323393705},"B":{"1356998400000":-0.0978826728,"1357084800000":0.3417343559,"1357171200000":-1.1103361029,"1357257600000":0.1497483186,"1357344000000":0.6877383895},"date":{"1356998400000":1356998400000,"1357084800000":1356998400000,"1357171200000":1356998400000,"1357257600000":1356998400000,"1357344000000":1356998400000},"ints":{"1356998400000":0,"1357084800000":1,"1357171200000":2,"1357257600000":3,"1357344000000":4},"bools":{"1356998400000":true,"1357084800000":true,"1357171200000":true,"1357257600000":true,"1357344000000":true}}

---->   DataFrame.copy

--------------------------------------
ID: 576 --> 1
In [250]: pd.DataFrame([1.0, 2.0, complex(1.0, 2.0)]).to_json(default_handler=str)
Out[250]: '{"0":{"0":"(1+0j)","1":"(2+0j)","2":"(1+2j)"}}'

---->   pandas.DataFrame

--------------------------------------
ID: 581 --> 1
In [255]: si = pd.DataFrame(
   .....:     np.zeros((4, 4)), columns=list(range(4)), index=[str(i) for i in range(4)]
   .....: )
   .....: 

In [256]: si
Out[256]: 
     0    1    2    3
0  0.0  0.0  0.0  0.0
1  0.0  0.0  0.0  0.0
2  0.0  0.0  0.0  0.0
3  0.0  0.0  0.0  0.0

In [257]: si.index
Out[257]: Index(['0', '1', '2', '3'], dtype='object')

In [258]: si.columns
Out[258]: Index([0, 1, 2, 3], dtype='int64')

In [259]: json = si.to_json()

In [260]: sij = pd.read_json(json, convert_axes=False)

In [261]: sij
Out[261]: 
   0  1  2  3
0  0  0  0  0
1  0  0  0  0
2  0  0  0  0
3  0  0  0  0

In [262]: sij.index
Out[262]: Index(['0', '1', '2', '3'], dtype='object')

In [263]: sij.columns
Out[263]: Index(['0', '1', '2', '3'], dtype='object')

---->   pandas.DataFrame

--------------------------------------
ID: 583 --> 1
In [271]: data = [
   .....:     {"id": 1, "name": {"first": "Coleen", "last": "Volk"}},
   .....:     {"name": {"given": "Mark", "family": "Regner"}},
   .....:     {"id": 2, "name": "Faye Raker"},
   .....: ]
   .....: 

In [272]: pd.json_normalize(data)
Out[272]: 
    id name.first name.last name.given name.family        name
0  1.0     Coleen      Volk        NaN         NaN         NaN
1  NaN        NaN       NaN       Mark      Regner         NaN
2  2.0        NaN       NaN        NaN         NaN  Faye Raker

---->   pandas.json_normalize

--------------------------------------
ID: 584 --> 1
In [273]: data = [
   .....:     {
   .....:         "state": "Florida",
   .....:         "shortname": "FL",
   .....:         "info": {"governor": "Rick Scott"},
   .....:         "county": [
   .....:             {"name": "Dade", "population": 12345},
   .....:             {"name": "Broward", "population": 40000},
   .....:             {"name": "Palm Beach", "population": 60000},
   .....:         ],
   .....:     },
   .....:     {
   .....:         "state": "Ohio",
   .....:         "shortname": "OH",
   .....:         "info": {"governor": "John Kasich"},
   .....:         "county": [
   .....:             {"name": "Summit", "population": 1234},
   .....:             {"name": "Cuyahoga", "population": 1337},
   .....:         ],
   .....:     },
   .....: ]
   .....: 

In [274]: pd.json_normalize(data, "county", ["state", "shortname", ["info", "governor"]])
Out[274]: 
         name  population    state shortname info.governor
0        Dade       12345  Florida        FL    Rick Scott
1     Broward       40000  Florida        FL    Rick Scott
2  Palm Beach       60000  Florida        FL    Rick Scott
3      Summit        1234     Ohio        OH   John Kasich
4    Cuyahoga        1337     Ohio        OH   John Kasich

---->   pandas.json_normalize

--------------------------------------
ID: 585 --> 1
In [275]: data = [
   .....:     {
   .....:         "CreatedBy": {"Name": "User001"},
   .....:         "Lookup": {
   .....:             "TextField": "Some text",
   .....:             "UserField": {"Id": "ID001", "Name": "Name001"},
   .....:         },
   .....:         "Image": {"a": "b"},
   .....:     }
   .....: ]
   .....: 

In [276]: pd.json_normalize(data, max_level=1)
Out[276]: 
  CreatedBy.Name Lookup.TextField                    Lookup.UserField Image.a
0        User001        Some text  {'Id': 'ID001', 'Name': 'Name001'}       b

---->   pandas.json_normalize

--------------------------------------
ID: 586 --> 1
In [277]: jsonl = """
   .....:     {"a": 1, "b": 2}
   .....:     {"a": 3, "b": 4}
   .....: """
   .....: 

In [278]: df = pd.read_json(jsonl, lines=True)

In [279]: df
Out[279]: 
   a  b
0  1  2
1  3  4

In [280]: df.to_json(orient="records", lines=True)
Out[280]: '{"a":1,"b":2}\n{"a":3,"b":4}\n'

# reader is an iterator that returns ``chunksize`` lines each iteration
In [281]: with pd.read_json(StringIO(jsonl), lines=True, chunksize=1) as reader:
   .....:     reader
   .....:     for chunk in reader:
   .....:         print(chunk)
   .....: 
Empty DataFrame
Columns: []
Index: []
   a  b
0  1  2
   a  b
1  3  4

---->   DataFrame.to_json

--------------------------------------
ID: 588 --> 3
In [285]: df = pd.DataFrame(
   .....:     {
   .....:         "A": [1, 2, 3],
   .....:         "B": ["a", "b", "c"],
   .....:         "C": pd.date_range("2016-01-01", freq="d", periods=3),
   .....:     },
   .....:     index=pd.Index(range(3), name="idx"),
   .....: )
   .....: 

In [286]: df
Out[286]: 
     A  B          C
idx                 
0    1  a 2016-01-01
1    2  b 2016-01-02
2    3  c 2016-01-03

In [287]: df.to_json(orient="table", date_format="iso")
Out[287]: '{"schema":{"fields":[{"name":"idx","type":"integer"},{"name":"A","type":"integer"},{"name":"B","type":"string"},{"name":"C","type":"datetime"}],"primaryKey":["idx"],"pandas_version":"1.4.0"},"data":[{"idx":0,"A":1,"B":"a","C":"2016-01-01T00:00:00.000"},{"idx":1,"A":2,"B":"b","C":"2016-01-02T00:00:00.000"},{"idx":2,"A":3,"B":"c","C":"2016-01-03T00:00:00.000"}]}'

---->   pandas.DataFrame; pandas.Index; DataFrame.to_json

--------------------------------------
ID: 589 --> 1
In [288]: from pandas.io.json import build_table_schema

In [289]: s = pd.Series(pd.date_range("2016", periods=4))

In [290]: build_table_schema(s)
Out[290]: 
{'fields': [{'name': 'index', 'type': 'integer'},
  {'name': 'values', 'type': 'datetime'}],
 'primaryKey': ['index'],
 'pandas_version': '1.4.0'}

---->   pandas.Series

--------------------------------------
ID: 590 --> 1
In [291]: s_tz = pd.Series(pd.date_range("2016", periods=12, tz="US/Central"))

In [292]: build_table_schema(s_tz)
Out[292]: 
{'fields': [{'name': 'index', 'type': 'integer'},
  {'name': 'values', 'type': 'datetime', 'tz': 'US/Central'}],
 'primaryKey': ['index'],
 'pandas_version': '1.4.0'}

---->   pandas.Series

--------------------------------------
ID: 591 --> 2
In [293]: s_per = pd.Series(1, index=pd.period_range("2016", freq="A-DEC", periods=4))

In [294]: build_table_schema(s_per)
Out[294]: 
{'fields': [{'name': 'index', 'type': 'datetime', 'freq': 'A-DEC'},
  {'name': 'values', 'type': 'integer'}],
 'primaryKey': ['index'],
 'pandas_version': '1.4.0'}

---->   pandas.Series; pandas.period_range

--------------------------------------
ID: 592 --> 2
In [295]: s_cat = pd.Series(pd.Categorical(["a", "b", "a"]))

In [296]: build_table_schema(s_cat)
Out[296]: 
{'fields': [{'name': 'index', 'type': 'integer'},
  {'name': 'values',
   'type': 'any',
   'constraints': {'enum': ['a', 'b']},
   'ordered': False}],
 'primaryKey': ['index'],
 'pandas_version': '1.4.0'}

---->   pandas.Series; pandas.Categorical

--------------------------------------
ID: 593 --> 1
In [297]: s_dupe = pd.Series([1, 2], index=[1, 1])

In [298]: build_table_schema(s_dupe)
Out[298]: 
{'fields': [{'name': 'index', 'type': 'integer'},
  {'name': 'values', 'type': 'integer'}],
 'pandas_version': '1.4.0'}

---->   pandas.Series

--------------------------------------
ID: 594 --> 2
In [299]: s_multi = pd.Series(1, index=pd.MultiIndex.from_product([("a", "b"), (0, 1)]))

In [300]: build_table_schema(s_multi)
Out[300]: 
{'fields': [{'name': 'level_0', 'type': 'string'},
  {'name': 'level_1', 'type': 'integer'},
  {'name': 'values', 'type': 'integer'}],
 'primaryKey': FrozenList(['level_0', 'level_1']),
 'pandas_version': '1.4.0'}

---->   pandas.Series; pandas.MultiIndex

--------------------------------------
ID: 595 --> 4
In [301]: df = pd.DataFrame(
   .....:     {
   .....:         "foo": [1, 2, 3, 4],
   .....:         "bar": ["a", "b", "c", "d"],
   .....:         "baz": pd.date_range("2018-01-01", freq="d", periods=4),
   .....:         "qux": pd.Categorical(["a", "b", "c", "c"]),
   .....:     },
   .....:     index=pd.Index(range(4), name="idx"),
   .....: )
   .....: 

In [302]: df
Out[302]: 
     foo bar        baz qux
idx                        
0      1   a 2018-01-01   a
1      2   b 2018-01-02   b
2      3   c 2018-01-03   c
3      4   d 2018-01-04   c

In [303]: df.dtypes
Out[303]: 
foo             int64
bar            object
baz    datetime64[ns]
qux          category
dtype: object

In [304]: df.to_json("test.json", orient="table")

In [305]: new_df = pd.read_json("test.json", orient="table")

In [306]: new_df
Out[306]: 
     foo bar        baz qux
idx                        
0      1   a 2018-01-01   a
1      2   b 2018-01-02   b
2      3   c 2018-01-03   c
3      4   d 2018-01-04   c

In [307]: new_df.dtypes
Out[307]: 
foo             int64
bar            object
baz    datetime64[ns]
qux          category
dtype: object

---->   pandas.DataFrame; pandas.Categorical; pandas.Index; DataFrame.to_json

--------------------------------------
ID: 596 --> 1
In [308]: df.index.name = "index"

In [309]: df.to_json("test.json", orient="table")

In [310]: new_df = pd.read_json("test.json", orient="table")

In [311]: print(new_df.index.name)
None

---->   DataFrame.to_json

--------------------------------------
ID: 610 --> 1
df = pd.DataFrame(np.random.randn(2, 2))
s = df.to_html(float_format="{0:.40g}".format)
dfin = pd.read_html(s, index_col=0)

---->   pandas.DataFrame

--------------------------------------
ID: 615 --> 1
In [323]: from IPython.display import display, HTML

In [324]: df = pd.DataFrame(np.random.randn(2, 2))

In [325]: df
Out[325]: 
          0         1
0 -0.345352  1.314232
1  0.690579  0.995761

In [326]: html = df.to_html()

In [327]: print(html)  # raw html

  
    
      
      0
      1
    
  
  
    
      0
      -0.345352
      1.314232
    
    
      1
      0.690579
      0.995761
    
  


In [328]: display(HTML(html))


---->   pandas.DataFrame

--------------------------------------
ID: 620 --> 1
In [339]: url_df = pd.DataFrame(
   .....:     {
   .....:         "name": ["Python", "pandas"],
   .....:         "url": ["https://www.python.org/", "https://pandas.pydata.org"],
   .....:     }
   .....: )
   .....: 

In [340]: html = url_df.to_html(render_links=True)

In [341]: print(html)

  
    
      
      name
      url
    
  
  
    
      0
      Python
      https://www.python.org/
    
    
      1
      pandas
      https://pandas.pydata.org
    
  


In [342]: display(HTML(html))


---->   pandas.DataFrame

--------------------------------------
ID: 621 --> 1
In [343]: df = pd.DataFrame({"a": list("&<>"), "b": np.random.randn(3)})

---->   pandas.DataFrame

--------------------------------------
ID: 624 --> 1
In [350]: df = pd.DataFrame([[1, 2], [3, 4]], index=["a", "b"], columns=["c", "d"])

In [351]: print(df.style.to_latex())
\begin{tabular}{lrr}
 & c & d \\
a & 1 & 2 \\
b & 3 & 4 \\
\end{tabular}

---->   pandas.DataFrame

--------------------------------------
ID: 640 --> 1
In [390]: geom_df = pd.DataFrame(
   .....:     {
   .....:         "shape": ["square", "circle", "triangle"],
   .....:         "degrees": [360, 360, 180],
   .....:         "sides": [4, np.nan, 3],
   .....:     }
   .....: )
   .....: 

In [391]: print(geom_df.to_xml())


  
    0
    square
    360
    4.0
  
  
    1
    circle
    360
    
  
  
    2
    triangle
    180
    3.0
  


---->   pandas.DataFrame

--------------------------------------
ID: 644 --> 1
In [395]: ext_geom_df = pd.DataFrame(
   .....:     {
   .....:         "type": ["polygon", "other", "polygon"],
   .....:         "shape": ["square", "circle", "triangle"],
   .....:         "degrees": [360, 360, 180],
   .....:         "sides": [4, np.nan, 3],
   .....:     }
   .....: )
   .....: 

In [396]: pvt_df = ext_geom_df.pivot_table(index='shape',
   .....:                                  columns='type',
   .....:                                  values=['degrees', 'sides'],
   .....:                                  aggfunc='sum')
   .....: 

In [397]: pvt_df
Out[397]: 
         degrees         sides        
type       other polygon other polygon
shape                                 
circle     360.0     NaN   0.0     NaN
square       NaN   360.0   NaN     4.0
triangle     NaN   180.0   NaN     3.0

In [398]: print(pvt_df.to_xml())


  
    circle
    360.0
    
    0.0
    
  
  
    square
    
    360.0
    
    4.0
  
  
    triangle
    
    180.0
    
    3.0
  


---->   pandas.DataFrame

--------------------------------------
ID: 650 --> 1
xlsx = pd.ExcelFile("path_to_file.xls")
df = pd.read_excel(xlsx, "Sheet1")

---->   pandas.ExcelFile

--------------------------------------
ID: 651 --> 1
with pd.ExcelFile("path_to_file.xls") as xls:
    df1 = pd.read_excel(xls, "Sheet1")
    df2 = pd.read_excel(xls, "Sheet2")

---->   pandas.ExcelFile

--------------------------------------
ID: 652 --> 1
data = {}
# For when Sheet1's format differs from Sheet2
with pd.ExcelFile("path_to_file.xls") as xls:
    data["Sheet1"] = pd.read_excel(xls, "Sheet1", index_col=None, na_values=["NA"])
    data["Sheet2"] = pd.read_excel(xls, "Sheet2", index_col=1)

---->   pandas.ExcelFile

--------------------------------------
ID: 653 --> 1
# using the ExcelFile class
data = {}
with pd.ExcelFile("path_to_file.xls") as xls:
    data["Sheet1"] = pd.read_excel(xls, "Sheet1", index_col=None, na_values=["NA"])
    data["Sheet2"] = pd.read_excel(xls, "Sheet2", index_col=None, na_values=["NA"])

# equivalent using the read_excel function
data = pd.read_excel(
    "path_to_file.xls", ["Sheet1", "Sheet2"], index_col=None, na_values=["NA"]
)

---->   pandas.ExcelFile

--------------------------------------
ID: 654 --> 1
import xlrd

xlrd_book = xlrd.open_workbook("path_to_file.xls", on_demand=True)
with pd.ExcelFile(xlrd_book) as xls:
    df1 = pd.read_excel(xls, "Sheet1")
    df2 = pd.read_excel(xls, "Sheet2")

---->   pandas.ExcelFile

--------------------------------------
ID: 660 --> 3
In [404]: df = pd.DataFrame(
   .....:     {"a": [1, 2, 3, 4], "b": [5, 6, 7, 8]},
   .....:     index=pd.MultiIndex.from_product([["a", "b"], ["c", "d"]]),
   .....: )
   .....: 

In [405]: df.to_excel("path_to_file.xlsx")

In [406]: df = pd.read_excel("path_to_file.xlsx", index_col=[0, 1])

In [407]: df
Out[407]: 
     a  b
a c  1  5
  d  2  6
b c  3  7
  d  4  8

---->   pandas.DataFrame; pandas.MultiIndex; DataFrame.to_excel

--------------------------------------
ID: 661 --> 1
In [408]: df.index = df.index.set_names(["lvl1", "lvl2"])

In [409]: df.to_excel("path_to_file.xlsx")

In [410]: df = pd.read_excel("path_to_file.xlsx", index_col=[0, 1])

In [411]: df
Out[411]: 
           a  b
lvl1 lvl2      
a    c     1  5
     d     2  6
b    c     3  7
     d     4  8

---->   DataFrame.to_excel

--------------------------------------
ID: 662 --> 2
In [412]: df.columns = pd.MultiIndex.from_product([["a"], ["b", "d"]], names=["c1", "c2"])

In [413]: df.to_excel("path_to_file.xlsx")

In [414]: df = pd.read_excel("path_to_file.xlsx", index_col=[0, 1], header=[0, 1])

In [415]: df
Out[415]: 
c1         a   
c2         b  d
lvl1 lvl2      
a    c     1  5
     d     2  6
b    c     3  7
     d     4  8

---->   pandas.MultiIndex; DataFrame.to_excel

--------------------------------------
ID: 671 --> 1
df.to_excel("path_to_file.xlsx", sheet_name="Sheet1")

---->   DataFrame.to_excel

--------------------------------------
ID: 672 --> 1
df.to_excel("path_to_file.xlsx", index_label="label", merge_cells=False)

---->   DataFrame.to_excel

--------------------------------------
ID: 673 --> 3
with pd.ExcelWriter("path_to_file.xlsx") as writer:
    df1.to_excel(writer, sheet_name="Sheet1")
    df2.to_excel(writer, sheet_name="Sheet2")

---->   pandas.ExcelWriter; DataFrame.to_excel; DataFrame.to_excel

--------------------------------------
ID: 674 --> 2
from io import BytesIO

bio = BytesIO()

# By setting the 'engine' in the ExcelWriter constructor.
writer = pd.ExcelWriter(bio, engine="xlsxwriter")
df.to_excel(writer, sheet_name="Sheet1")

# Save the workbook
writer.save()

# Seek to the beginning and read to copy the workbook to a variable in memory
bio.seek(0)
workbook = bio.read()

---->   pandas.ExcelWriter; DataFrame.to_excel

--------------------------------------
ID: 675 --> 2
# By setting the 'engine' in the DataFrame 'to_excel()' methods.
df.to_excel("path_to_file.xlsx", sheet_name="Sheet1", engine="xlsxwriter")

# By setting the 'engine' in the ExcelWriter constructor.
writer = pd.ExcelWriter("path_to_file.xlsx", engine="xlsxwriter")

# Or via pandas configuration.
from pandas import options  # noqa: E402

options.io.excel.xlsx.writer = "xlsxwriter"

df.to_excel("path_to_file.xlsx", sheet_name="Sheet1")

---->   DataFrame.to_excel; pandas.ExcelWriter

--------------------------------------
ID: 677 --> 1
# Writes DataFrame to a .ods file
df.to_excel("path_to_file.ods", engine="odf")

---->   DataFrame.to_excel

--------------------------------------
ID: 679 --> 1
>>> clipdf = pd.read_clipboard()
>>> clipdf
  A B C
x 1 4 p
y 2 5 q
z 3 6 r

---->   pandas.read_clipboard

--------------------------------------
ID: 680 --> 3
>>> df = pd.DataFrame(
...     {"A": [1, 2, 3], "B": [4, 5, 6], "C": ["p", "q", "r"]}, index=["x", "y", "z"]
... )

>>> df
  A B C
x 1 4 p
y 2 5 q
z 3 6 r
>>> df.to_clipboard()
>>> pd.read_clipboard()
  A B C
x 1 4 p
y 2 5 q
z 3 6 r

---->   pandas.DataFrame; DataFrame.to_clipboard; pandas.read_clipboard

--------------------------------------
ID: 681 --> 1
In [416]: df
Out[416]: 
c1         a   
c2         b  d
lvl1 lvl2      
a    c     1  5
     d     2  6
b    c     3  7
     d     4  8

In [417]: df.to_pickle("foo.pkl")

---->   DataFrame.to_pickle

--------------------------------------
ID: 682 --> 1
In [418]: pd.read_pickle("foo.pkl")
Out[418]: 
c1         a   
c2         b  d
lvl1 lvl2      
a    c     1  5
     d     2  6
b    c     3  7
     d     4  8

---->   pandas.read_pickle

--------------------------------------
ID: 683 --> 1
In [419]: df = pd.DataFrame(
   .....:     {
   .....:         "A": np.random.randn(1000),
   .....:         "B": "foo",
   .....:         "C": pd.date_range("20130101", periods=1000, freq="s"),
   .....:     }
   .....: )
   .....: 

In [420]: df
Out[420]: 
            A    B                   C
0   -0.317441  foo 2013-01-01 00:00:00
1   -1.236269  foo 2013-01-01 00:00:01
2    0.896171  foo 2013-01-01 00:00:02
3   -0.487602  foo 2013-01-01 00:00:03
4   -0.082240  foo 2013-01-01 00:00:04
..        ...  ...                 ...
995 -0.171092  foo 2013-01-01 00:16:35
996  1.786173  foo 2013-01-01 00:16:36
997 -0.575189  foo 2013-01-01 00:16:37
998  0.820750  foo 2013-01-01 00:16:38
999 -1.256530  foo 2013-01-01 00:16:39

[1000 rows x 3 columns]

---->   pandas.DataFrame

--------------------------------------
ID: 684 --> 2
In [421]: df.to_pickle("data.pkl.compress", compression="gzip")

In [422]: rt = pd.read_pickle("data.pkl.compress", compression="gzip")

In [423]: rt
Out[423]: 
            A    B                   C
0   -0.317441  foo 2013-01-01 00:00:00
1   -1.236269  foo 2013-01-01 00:00:01
2    0.896171  foo 2013-01-01 00:00:02
3   -0.487602  foo 2013-01-01 00:00:03
4   -0.082240  foo 2013-01-01 00:00:04
..        ...  ...                 ...
995 -0.171092  foo 2013-01-01 00:16:35
996  1.786173  foo 2013-01-01 00:16:36
997 -0.575189  foo 2013-01-01 00:16:37
998  0.820750  foo 2013-01-01 00:16:38
999 -1.256530  foo 2013-01-01 00:16:39

[1000 rows x 3 columns]

---->   DataFrame.to_pickle; pandas.read_pickle

--------------------------------------
ID: 685 --> 2
In [424]: df.to_pickle("data.pkl.xz", compression="infer")

In [425]: rt = pd.read_pickle("data.pkl.xz", compression="infer")

In [426]: rt
Out[426]: 
            A    B                   C
0   -0.317441  foo 2013-01-01 00:00:00
1   -1.236269  foo 2013-01-01 00:00:01
2    0.896171  foo 2013-01-01 00:00:02
3   -0.487602  foo 2013-01-01 00:00:03
4   -0.082240  foo 2013-01-01 00:00:04
..        ...  ...                 ...
995 -0.171092  foo 2013-01-01 00:16:35
996  1.786173  foo 2013-01-01 00:16:36
997 -0.575189  foo 2013-01-01 00:16:37
998  0.820750  foo 2013-01-01 00:16:38
999 -1.256530  foo 2013-01-01 00:16:39

[1000 rows x 3 columns]

---->   DataFrame.to_pickle; pandas.read_pickle

--------------------------------------
ID: 686 --> 2
In [427]: df.to_pickle("data.pkl.gz")

In [428]: rt = pd.read_pickle("data.pkl.gz")

In [429]: rt
Out[429]: 
            A    B                   C
0   -0.317441  foo 2013-01-01 00:00:00
1   -1.236269  foo 2013-01-01 00:00:01
2    0.896171  foo 2013-01-01 00:00:02
3   -0.487602  foo 2013-01-01 00:00:03
4   -0.082240  foo 2013-01-01 00:00:04
..        ...  ...                 ...
995 -0.171092  foo 2013-01-01 00:16:35
996  1.786173  foo 2013-01-01 00:16:36
997 -0.575189  foo 2013-01-01 00:16:37
998  0.820750  foo 2013-01-01 00:16:38
999 -1.256530  foo 2013-01-01 00:16:39

[1000 rows x 3 columns]

In [430]: df["A"].to_pickle("s1.pkl.bz2")

In [431]: rt = pd.read_pickle("s1.pkl.bz2")

In [432]: rt
Out[432]: 
0     -0.317441
1     -1.236269
2      0.896171
3     -0.487602
4     -0.082240
         ...   
995   -0.171092
996    1.786173
997   -0.575189
998    0.820750
999   -1.256530
Name: A, Length: 1000, dtype: float64

---->   DataFrame.to_pickle; pandas.read_pickle

--------------------------------------
ID: 687 --> 1
In [433]: df.to_pickle("data.pkl.gz", compression={"method": "gzip", "compresslevel": 1})

---->   DataFrame.to_pickle

--------------------------------------
ID: 689 --> 2
In [436]: index = pd.date_range("1/1/2000", periods=8)

In [437]: s = pd.Series(np.random.randn(5), index=["a", "b", "c", "d", "e"])

In [438]: df = pd.DataFrame(np.random.randn(8, 3), index=index, columns=["A", "B", "C"])

# store.put('s', s) is an equivalent method
In [439]: store["s"] = s

In [440]: store["df"] = df

In [441]: store
Out[441]: 

File path: store.h5

---->   pandas.Series; pandas.DataFrame

--------------------------------------
ID: 693 --> 3
In [450]: df_tl = pd.DataFrame({"A": list(range(5)), "B": list(range(5))})

In [451]: df_tl.to_hdf("store_tl.h5", "table", append=True)

In [452]: pd.read_hdf("store_tl.h5", "table", where=["index>2"])
Out[452]: 
   A  B
3  3  3
4  4  4

---->   pandas.DataFrame; DataFrame.to_hdf; pandas.read_hdf

--------------------------------------
ID: 694 --> 2
In [453]: df_with_missing = pd.DataFrame(
   .....:     {
   .....:         "col1": [0, np.nan, 2],
   .....:         "col2": [1, np.nan, np.nan],
   .....:     }
   .....: )
   .....: 

In [454]: df_with_missing
Out[454]: 
   col1  col2
0   0.0   1.0
1   NaN   NaN
2   2.0   NaN

In [455]: df_with_missing.to_hdf("file.h5", "df_with_missing", format="table", mode="w")

In [456]: pd.read_hdf("file.h5", "df_with_missing")
Out[456]: 
   col1  col2
0   0.0   1.0
1   NaN   NaN
2   2.0   NaN

In [457]: df_with_missing.to_hdf(
   .....:     "file.h5", "df_with_missing", format="table", mode="w", dropna=True
   .....: )
   .....: 

In [458]: pd.read_hdf("file.h5", "df_with_missing")
Out[458]: 
   col1  col2
0   0.0   1.0
2   2.0   NaN

---->   pandas.DataFrame; pandas.read_hdf

--------------------------------------
ID: 695 --> 2
>>> pd.DataFrame(np.random.randn(10, 2)).to_hdf("test_fixed.h5", "df")
>>> pd.read_hdf("test_fixed.h5", "df", where="index>5")
TypeError: cannot pass a where specification when reading a fixed format.
           this store must be selected in its entirety

---->   pandas.DataFrame; pandas.read_hdf

--------------------------------------
ID: 700 --> 1
In [476]: df_mixed = pd.DataFrame(
   .....:     {
   .....:         "A": np.random.randn(8),
   .....:         "B": np.random.randn(8),
   .....:         "C": np.array(np.random.randn(8), dtype="float32"),
   .....:         "string": "string",
   .....:         "int": 1,
   .....:         "bool": True,
   .....:         "datetime64": pd.Timestamp("20010102"),
   .....:     },
   .....:     index=list(range(8)),
   .....: )
   .....: 

In [477]: df_mixed.loc[df_mixed.index[3:5], ["A", "B", "string", "datetime64"]] = np.nan

In [478]: store.append("df_mixed", df_mixed, min_itemsize={"values": 50})

In [479]: df_mixed1 = store.select("df_mixed")

In [480]: df_mixed1
Out[480]: 
          A         B         C  string  int  bool datetime64
0  0.120106 -0.624406 -0.103317  string    1  True 2001-01-02
1 -1.814006 -1.217067  0.183764  string    1  True 2001-01-02
2  0.779275  0.992992  0.319368  string    1  True 2001-01-02
3       NaN       NaN  0.083662     NaN    1  True        NaT
4       NaN       NaN  0.013747     NaN    1  True        NaT
5 -0.243692  0.222892 -0.712009  string    1  True 2001-01-02
6  0.184544  0.057946 -0.645096  string    1  True 2001-01-02
7 -0.924273 -0.623319  1.347217  string    1  True 2001-01-02

In [481]: df_mixed1.dtypes.value_counts()
Out[481]: 
float64           2
float32           1
object            1
int64             1
bool              1
datetime64[ns]    1
Name: count, dtype: int64

# we have provided a minimum string column size
In [482]: store.root.df_mixed.table
Out[482]: 
/df_mixed/table (Table(8,)) ''
  description := {
  "index": Int64Col(shape=(), dflt=0, pos=0),
  "values_block_0": Float64Col(shape=(2,), dflt=0.0, pos=1),
  "values_block_1": Float32Col(shape=(1,), dflt=0.0, pos=2),
  "values_block_2": StringCol(itemsize=50, shape=(1,), dflt=b'', pos=3),
  "values_block_3": Int64Col(shape=(1,), dflt=0, pos=4),
  "values_block_4": BoolCol(shape=(1,), dflt=False, pos=5),
  "values_block_5": Int64Col(shape=(1,), dflt=0, pos=6)}
  byteorder := 'little'
  chunkshape := (689,)
  autoindex := True
  colindexes := {
    "index": Index(6, mediumshuffle, zlib(1)).is_csi=False}

---->   pandas.DataFrame

--------------------------------------
ID: 701 --> 2
In [483]: index = pd.MultiIndex(
   .....:     levels=[["foo", "bar", "baz", "qux"], ["one", "two", "three"]],
   .....:     codes=[[0, 0, 0, 1, 1, 2, 2, 3, 3, 3], [0, 1, 2, 0, 1, 1, 2, 0, 1, 2]],
   .....:     names=["foo", "bar"],
   .....: )
   .....: 

In [484]: df_mi = pd.DataFrame(np.random.randn(10, 3), index=index, columns=["A", "B", "C"])

In [485]: df_mi
Out[485]: 
                  A         B         C
foo bar                                
foo one    0.686219 -0.023202  2.359782
    two   -0.143428 -1.166078  0.247572
    three  1.687406  0.894559  1.215261
bar one    0.043702  0.088224 -0.813360
    two   -1.292080  1.526911  0.288504
baz two    0.097771  1.536408  0.926790
    three -0.676448 -0.179724 -1.303456
qux one   -0.642994 -0.649456  1.012694
    two    0.414147  1.950460  1.094544
    three -0.802899 -0.583343  0.410395

In [486]: store.append("df_mi", df_mi)

In [487]: store.select("df_mi")
Out[487]: 
                  A         B         C
foo bar                                
foo one    0.686219 -0.023202  2.359782
    two   -0.143428 -1.166078  0.247572
    three  1.687406  0.894559  1.215261
bar one    0.043702  0.088224 -0.813360
    two   -1.292080  1.526911  0.288504
baz two    0.097771  1.536408  0.926790
    three -0.676448 -0.179724 -1.303456
qux one   -0.642994 -0.649456  1.012694
    two    0.414147  1.950460  1.094544
    three -0.802899 -0.583343  0.410395

# the levels are automatically included as data columns
In [488]: store.select("df_mi", "foo=bar")
Out[488]: 
                A         B         C
foo bar                              
bar one  0.043702  0.088224 -0.813360
    two -1.292080  1.526911  0.288504

---->   pandas.MultiIndex; pandas.DataFrame

--------------------------------------
ID: 705 --> 1
In [489]: dfq = pd.DataFrame(
   .....:     np.random.randn(10, 4),
   .....:     columns=list("ABCD"),
   .....:     index=pd.date_range("20130101", periods=10),
   .....: )
   .....: 

In [490]: store.append("dfq", dfq, format="table", data_columns=True)

---->   pandas.DataFrame

--------------------------------------
ID: 709 --> 1
In [494]: from datetime import timedelta

In [495]: dftd = pd.DataFrame(
   .....:     {
   .....:         "A": pd.Timestamp("20130101"),
   .....:         "B": [
   .....:             pd.Timestamp("20130101") + timedelta(days=i, seconds=10)
   .....:             for i in range(10)
   .....:         ],
   .....:     }
   .....: )
   .....: 

In [496]: dftd["C"] = dftd["A"] - dftd["B"]

In [497]: dftd
Out[497]: 
           A                   B                  C
0 2013-01-01 2013-01-01 00:00:10  -1 days +23:59:50
1 2013-01-01 2013-01-02 00:00:10  -2 days +23:59:50
2 2013-01-01 2013-01-03 00:00:10  -3 days +23:59:50
3 2013-01-01 2013-01-04 00:00:10  -4 days +23:59:50
4 2013-01-01 2013-01-05 00:00:10  -5 days +23:59:50
5 2013-01-01 2013-01-06 00:00:10  -6 days +23:59:50
6 2013-01-01 2013-01-07 00:00:10  -7 days +23:59:50
7 2013-01-01 2013-01-08 00:00:10  -8 days +23:59:50
8 2013-01-01 2013-01-09 00:00:10  -9 days +23:59:50
9 2013-01-01 2013-01-10 00:00:10 -10 days +23:59:50

In [498]: store.append("dftd", dftd, data_columns=True)

In [499]: store.select("dftd", "C<'-3.5D'")
Out[499]: 
           A                   B                  C
4 2013-01-01 2013-01-05 00:00:10  -5 days +23:59:50
5 2013-01-01 2013-01-06 00:00:10  -6 days +23:59:50
6 2013-01-01 2013-01-07 00:00:10  -7 days +23:59:50
7 2013-01-01 2013-01-08 00:00:10  -8 days +23:59:50
8 2013-01-01 2013-01-09 00:00:10  -9 days +23:59:50
9 2013-01-01 2013-01-10 00:00:10 -10 days +23:59:50

---->   pandas.DataFrame

--------------------------------------
ID: 711 --> 2
In [502]: index = pd.MultiIndex(
   .....:     levels=[["foo", "bar", "baz", "qux"], ["one", "two", "three"]],
   .....:     codes=[[0, 0, 0, 1, 1, 2, 2, 3, 3, 3], [0, 1, 2, 0, 1, 1, 2, 0, 1, 2]],
   .....: )
   .....: 

In [503]: df_mi_2 = pd.DataFrame(np.random.randn(10, 3), index=index, columns=["A", "B", "C"])

In [504]: df_mi_2
Out[504]: 
                  A         B         C
foo one    0.431186  1.049421  0.383309
    two    0.595013  0.617509 -0.811230
    three -2.088563 -1.393500  0.947422
bar one   -0.671233 -0.847097 -1.187785
    two   -0.183798 -1.211230 -0.856833
baz two   -0.600575  0.361428  0.887304
    three  0.266457 -0.399641 -0.219582
qux one    1.186860 -1.437189  0.053768
    two    1.872644 -1.469813 -0.564201
    three  0.876341  0.407749 -0.232583

In [505]: store.append("df_mi_2", df_mi_2)

# the levels are automatically included as data columns with keyword level_n
In [506]: store.select("df_mi_2", "level_0=foo and level_1=two")
Out[506]: 
                A         B        C
foo two  0.595013  0.617509 -0.81123

---->   pandas.MultiIndex; pandas.DataFrame

--------------------------------------
ID: 713 --> 1
In [512]: df_1 = pd.DataFrame(np.random.randn(10, 2), columns=list("AB"))

In [513]: df_2 = pd.DataFrame(np.random.randn(10, 2), columns=list("AB"))

In [514]: st = pd.HDFStore("appends.h5", mode="w")

In [515]: st.append("df", df_1, data_columns=["B"], index=False)

In [516]: st.append("df", df_2, data_columns=["B"], index=False)

In [517]: st.get_storer("df").table
Out[517]: 
/df/table (Table(20,)) ''
  description := {
  "index": Int64Col(shape=(), dflt=0, pos=0),
  "values_block_0": Float64Col(shape=(1,), dflt=0.0, pos=1),
  "B": Float64Col(shape=(), dflt=0.0, pos=2)}
  byteorder := 'little'
  chunkshape := (2730,)

---->   pandas.DataFrame

--------------------------------------
ID: 715 --> 1
In [521]: df_dc = df.copy()

In [522]: df_dc["string"] = "foo"

In [523]: df_dc.loc[df_dc.index[4:6], "string"] = np.nan

In [524]: df_dc.loc[df_dc.index[7:9], "string"] = "bar"

In [525]: df_dc["string2"] = "cool"

In [526]: df_dc.loc[df_dc.index[1:3], ["B", "C"]] = 1.0

In [527]: df_dc
Out[527]: 
                   A         B         C string string2
2000-01-01  0.858644 -0.851236  1.058006    foo    cool
2000-01-02 -0.080372  1.000000  1.000000    foo    cool
2000-01-03  0.816983  1.000000  1.000000    foo    cool
2000-01-04  0.712795 -0.062433  0.736755    foo    cool
2000-01-05 -0.298721 -1.988045  1.475308    NaN    cool
2000-01-06  1.103675  1.382242 -0.650762    NaN    cool
2000-01-07 -0.729161 -0.142928 -1.063038    foo    cool
2000-01-08 -1.005977  0.465222 -0.094517    bar    cool

# on-disk operations
In [528]: store.append("df_dc", df_dc, data_columns=["B", "C", "string", "string2"])

In [529]: store.select("df_dc", where="B > 0")
Out[529]: 
                   A         B         C string string2
2000-01-02 -0.080372  1.000000  1.000000    foo    cool
2000-01-03  0.816983  1.000000  1.000000    foo    cool
2000-01-06  1.103675  1.382242 -0.650762    NaN    cool
2000-01-08 -1.005977  0.465222 -0.094517    bar    cool

# getting creative
In [530]: store.select("df_dc", "B > 0 & C > 0 & string == foo")
Out[530]: 
                   A    B    C string string2
2000-01-02 -0.080372  1.0  1.0    foo    cool
2000-01-03  0.816983  1.0  1.0    foo    cool

# this is in-memory version of this type of selection
In [531]: df_dc[(df_dc.B > 0) & (df_dc.C > 0) & (df_dc.string == "foo")]
Out[531]: 
                   A    B    C string string2
2000-01-02 -0.080372  1.0  1.0    foo    cool
2000-01-03  0.816983  1.0  1.0    foo    cool

# we have automagically created this index and the B/C/string/string2
# columns are stored separately as ``PyTables`` columns
In [532]: store.root.df_dc.table
Out[532]: 
/df_dc/table (Table(8,)) ''
  description := {
  "index": Int64Col(shape=(), dflt=0, pos=0),
  "values_block_0": Float64Col(shape=(1,), dflt=0.0, pos=1),
  "B": Float64Col(shape=(), dflt=0.0, pos=2),
  "C": Float64Col(shape=(), dflt=0.0, pos=3),
  "string": StringCol(itemsize=3, shape=(), dflt=b'', pos=4),
  "string2": StringCol(itemsize=4, shape=(), dflt=b'', pos=5)}
  byteorder := 'little'
  chunkshape := (1680,)
  autoindex := True
  colindexes := {
    "index": Index(6, mediumshuffle, zlib(1)).is_csi=False,
    "B": Index(6, mediumshuffle, zlib(1)).is_csi=False,
    "C": Index(6, mediumshuffle, zlib(1)).is_csi=False,
    "string": Index(6, mediumshuffle, zlib(1)).is_csi=False,
    "string2": Index(6, mediumshuffle, zlib(1)).is_csi=False}

---->   DataFrame.copy

--------------------------------------
ID: 717 --> 1
for df in pd.read_hdf("store.h5", "df", chunksize=3):
    print(df)

---->   pandas.read_hdf

--------------------------------------
ID: 718 --> 1
In [534]: dfeq = pd.DataFrame({"number": np.arange(1, 11)})

In [535]: dfeq
Out[535]: 
   number
0       1
1       2
2       3
3       4
4       5
5       6
6       7
7       8
8       9
9      10

In [536]: store.append("dfeq", dfeq, data_columns=["number"])

In [537]: def chunks(l, n):
   .....:     return [l[i: i + n] for i in range(0, len(l), n)]
   .....: 

In [538]: evens = [2, 4, 6, 8, 10]

In [539]: coordinates = store.select_as_coordinates("dfeq", "number=evens")

In [540]: for c in chunks(coordinates, 2):
   .....:     print(store.select("dfeq", where=c))
   .....: 
   number
1       2
3       4
   number
5       6
7       8
   number
9      10

---->   pandas.DataFrame

--------------------------------------
ID: 720 --> 1
In [543]: df_coord = pd.DataFrame(
   .....:     np.random.randn(1000, 2), index=pd.date_range("20000101", periods=1000)
   .....: )
   .....: 

In [544]: store.append("df_coord", df_coord)

In [545]: c = store.select_as_coordinates("df_coord", "index > 20020101")

In [546]: c
Out[546]: 
Index([732, 733, 734, 735, 736, 737, 738, 739, 740, 741,
       ...
       990, 991, 992, 993, 994, 995, 996, 997, 998, 999],
      dtype='int64', length=268)

In [547]: store.select("df_coord", where=c)
Out[547]: 
                   0         1
2002-01-02  0.241433  0.717260
2002-01-03  1.781878 -2.016130
2002-01-04  1.095589  0.935850
2002-01-05  0.944319  1.167204
2002-01-06  0.497867  0.308975
...              ...       ...
2002-09-22 -0.561327 -2.106554
2002-09-23 -1.080806 -0.862818
2002-09-24 -0.369663 -0.246194
2002-09-25  0.322358 -0.500547
2002-09-26  0.154552 -0.098948

[268 rows x 2 columns]

---->   pandas.DataFrame

--------------------------------------
ID: 721 --> 2
In [548]: df_mask = pd.DataFrame(
   .....:     np.random.randn(1000, 2), index=pd.date_range("20000101", periods=1000)
   .....: )
   .....: 

In [549]: store.append("df_mask", df_mask)

In [550]: c = store.select_column("df_mask", "index")

In [551]: where = c[pd.DatetimeIndex(c).month == 5].index

In [552]: store.select("df_mask", where=where)
Out[552]: 
                   0         1
2000-05-01  1.020434  0.148828
2000-05-02 -0.570048 -1.303235
2000-05-03  0.952743  0.099314
2000-05-04  0.448445  0.300635
2000-05-05 -1.563991  1.111575
...              ...       ...
2002-05-27 -0.637268 -1.590405
2002-05-28  0.176963  0.191694
2002-05-29 -0.228488 -1.162170
2002-05-30  0.344842 -0.963555
2002-05-31  0.956318  0.480412

[93 rows x 2 columns]

---->   pandas.DataFrame; pandas.DatetimeIndex

--------------------------------------
ID: 723 --> 1
In [554]: df_mt = pd.DataFrame(
   .....:     np.random.randn(8, 6),
   .....:     index=pd.date_range("1/1/2000", periods=8),
   .....:     columns=["A", "B", "C", "D", "E", "F"],
   .....: )
   .....: 

In [555]: df_mt["foo"] = "bar"

In [556]: df_mt.loc[df_mt.index[1], ("A", "B")] = np.nan

# you can also create the tables individually
In [557]: store.append_to_multiple(
   .....:     {"df1_mt": ["A", "B"], "df2_mt": None}, df_mt, selector="df1_mt"
   .....: )
   .....: 

In [558]: store
Out[558]: 

File path: store.h5

# individual tables were created
In [559]: store.select("df1_mt")
Out[559]: 
                   A         B
2000-01-01 -0.277446 -1.102896
2000-01-02       NaN       NaN
2000-01-03 -0.787062  0.651396
2000-01-04  1.095864 -0.200875
2000-01-05  0.460708  1.834518
2000-01-06  0.439872  0.506364
2000-01-07  0.116634 -1.772519
2000-01-08  0.748471 -0.943009

In [560]: store.select("df2_mt")
Out[560]: 
                   C         D         E         F  foo
2000-01-01  0.100307 -1.602814  0.920139 -0.643870  bar
2000-01-02 -0.494305  0.737973  0.451632  0.334124  bar
2000-01-03 -0.741919  1.193881 -2.395763 -0.199038  bar
2000-01-04  0.162291 -0.430489 -2.502042  0.668149  bar
2000-01-05  0.196782 -0.922321  0.130441 -0.608465  bar
2000-01-06  0.429207 -1.099274 -1.069546  1.236277  bar
2000-01-07  1.869081 -1.466039  0.137462  0.313939  bar
2000-01-08  0.092130 -1.726280  0.836517  2.049798  bar

# as a multiple
In [561]: store.select_as_multiple(
   .....:     ["df1_mt", "df2_mt"],
   .....:     where=["A>0", "B>0"],
   .....:     selector="df1_mt",
   .....: )
   .....: 
Out[561]: 
                   A         B         C         D         E         F  foo
2000-01-05  0.460708  1.834518  0.196782 -0.922321  0.130441 -0.608465  bar
2000-01-06  0.439872  0.506364  0.429207 -1.099274 -1.069546  1.236277  bar

---->   pandas.DataFrame

--------------------------------------
ID: 726 --> 2
In [562]: dfcat = pd.DataFrame(
   .....:     {"A": pd.Series(list("aabbcdba")).astype("category"), "B": np.random.randn(8)}
   .....: )
   .....: 

In [563]: dfcat
Out[563]: 
   A         B
0  a  0.562167
1  a  0.189952
2  b  0.266901
3  b -0.036854
4  c  1.112750
5  d -0.151596
6  b  1.503311
7  a  0.939470

In [564]: dfcat.dtypes
Out[564]: 
A    category
B     float64
dtype: object

In [565]: cstore = pd.HDFStore("cats.h5", mode="w")

In [566]: cstore.append("dfcat", dfcat, format="table", data_columns=["A"])

In [567]: result = cstore.select("dfcat", where="A in ['b', 'c']")

In [568]: result
Out[568]: 
   A         B
2  b  0.266901
3  b -0.036854
4  c  1.112750
6  b  1.503311

In [569]: result.dtypes
Out[569]: 
A    category
B     float64
dtype: object

---->   pandas.DataFrame; pandas.Series

--------------------------------------
ID: 727 --> 1
In [570]: dfs = pd.DataFrame({"A": "foo", "B": "bar"}, index=list(range(5)))

In [571]: dfs
Out[571]: 
     A    B
0  foo  bar
1  foo  bar
2  foo  bar
3  foo  bar
4  foo  bar

# A and B have a size of 30
In [572]: store.append("dfs", dfs, min_itemsize=30)

In [573]: store.get_storer("dfs").table
Out[573]: 
/dfs/table (Table(5,)) ''
  description := {
  "index": Int64Col(shape=(), dflt=0, pos=0),
  "values_block_0": StringCol(itemsize=30, shape=(2,), dflt=b'', pos=1)}
  byteorder := 'little'
  chunkshape := (963,)
  autoindex := True
  colindexes := {
    "index": Index(6, mediumshuffle, zlib(1)).is_csi=False}

# A is created as a data_column with a size of 30
# B is size is calculated
In [574]: store.append("dfs2", dfs, min_itemsize={"A": 30})

In [575]: store.get_storer("dfs2").table
Out[575]: 
/dfs2/table (Table(5,)) ''
  description := {
  "index": Int64Col(shape=(), dflt=0, pos=0),
  "values_block_0": StringCol(itemsize=3, shape=(1,), dflt=b'', pos=1),
  "A": StringCol(itemsize=30, shape=(), dflt=b'', pos=2)}
  byteorder := 'little'
  chunkshape := (1598,)
  autoindex := True
  colindexes := {
    "index": Index(6, mediumshuffle, zlib(1)).is_csi=False,
    "A": Index(6, mediumshuffle, zlib(1)).is_csi=False}

---->   pandas.DataFrame

--------------------------------------
ID: 728 --> 1
In [576]: dfss = pd.DataFrame({"A": ["foo", "bar", "nan"]})

In [577]: dfss
Out[577]: 
     A
0  foo
1  bar
2  nan

In [578]: store.append("dfss", dfss)

In [579]: store.select("dfss")
Out[579]: 
     A
0  foo
1  bar
2  NaN

# here you need to specify a different nan rep
In [580]: store.append("dfss2", dfss, nan_rep="_nan_")

In [581]: store.select("dfss2")
Out[581]: 
     A
0  foo
1  bar
2  nan

---->   pandas.DataFrame

--------------------------------------
ID: 729 --> 2
In [582]: df = pd.DataFrame(
   .....:     {
   .....:         "a": list("abc"),
   .....:         "b": list(range(1, 4)),
   .....:         "c": np.arange(3, 6).astype("u1"),
   .....:         "d": np.arange(4.0, 7.0, dtype="float64"),
   .....:         "e": [True, False, True],
   .....:         "f": pd.Categorical(list("abc")),
   .....:         "g": pd.date_range("20130101", periods=3),
   .....:         "h": pd.date_range("20130101", periods=3, tz="US/Eastern"),
   .....:         "i": pd.date_range("20130101", periods=3, freq="ns"),
   .....:     }
   .....: )
   .....: 

In [583]: df
Out[583]: 
   a  b  c  ...          g                         h                             i
0  a  1  3  ... 2013-01-01 2013-01-01 00:00:00-05:00 2013-01-01 00:00:00.000000000
1  b  2  4  ... 2013-01-02 2013-01-02 00:00:00-05:00 2013-01-01 00:00:00.000000001
2  c  3  5  ... 2013-01-03 2013-01-03 00:00:00-05:00 2013-01-01 00:00:00.000000002

[3 rows x 9 columns]

In [584]: df.dtypes
Out[584]: 
a                        object
b                         int64
c                         uint8
d                       float64
e                          bool
f                      category
g                datetime64[ns]
h    datetime64[ns, US/Eastern]
i                datetime64[ns]
dtype: object

---->   pandas.DataFrame; pandas.Categorical

--------------------------------------
ID: 730 --> 1
In [585]: df.to_feather("example.feather")

---->   DataFrame.to_feather

--------------------------------------
ID: 731 --> 1
In [586]: result = pd.read_feather("example.feather")

In [587]: result
Out[587]: 
   a  b  c  ...          g                         h                             i
0  a  1  3  ... 2013-01-01 2013-01-01 00:00:00-05:00 2013-01-01 00:00:00.000000000
1  b  2  4  ... 2013-01-02 2013-01-02 00:00:00-05:00 2013-01-01 00:00:00.000000001
2  c  3  5  ... 2013-01-03 2013-01-03 00:00:00-05:00 2013-01-01 00:00:00.000000002

[3 rows x 9 columns]

# we preserve dtypes
In [588]: result.dtypes
Out[588]: 
a                        object
b                         int64
c                         uint8
d                       float64
e                          bool
f                      category
g                datetime64[ns]
h    datetime64[ns, US/Eastern]
i                datetime64[ns]
dtype: object

---->   pandas.read_feather

--------------------------------------
ID: 732 --> 2
In [589]: df = pd.DataFrame(
   .....:     {
   .....:         "a": list("abc"),
   .....:         "b": list(range(1, 4)),
   .....:         "c": np.arange(3, 6).astype("u1"),
   .....:         "d": np.arange(4.0, 7.0, dtype="float64"),
   .....:         "e": [True, False, True],
   .....:         "f": pd.date_range("20130101", periods=3),
   .....:         "g": pd.date_range("20130101", periods=3, tz="US/Eastern"),
   .....:         "h": pd.Categorical(list("abc")),
   .....:         "i": pd.Categorical(list("abc"), ordered=True),
   .....:     }
   .....: )
   .....: 

In [590]: df
Out[590]: 
   a  b  c    d      e          f                         g  h  i
0  a  1  3  4.0   True 2013-01-01 2013-01-01 00:00:00-05:00  a  a
1  b  2  4  5.0  False 2013-01-02 2013-01-02 00:00:00-05:00  b  b
2  c  3  5  6.0   True 2013-01-03 2013-01-03 00:00:00-05:00  c  c

In [591]: df.dtypes
Out[591]: 
a                        object
b                         int64
c                         uint8
d                       float64
e                          bool
f                datetime64[ns]
g    datetime64[ns, US/Eastern]
h                      category
i                      category
dtype: object

---->   pandas.DataFrame; pandas.Categorical

--------------------------------------
ID: 733 --> 1
In [592]: df.to_parquet("example_pa.parquet", engine="pyarrow")

In [593]: df.to_parquet("example_fp.parquet", engine="fastparquet")

---->   DataFrame.to_parquet

--------------------------------------
ID: 734 --> 1
In [594]: result = pd.read_parquet("example_fp.parquet", engine="fastparquet")

In [595]: result = pd.read_parquet("example_pa.parquet", engine="pyarrow")

In [596]: result.dtypes
Out[596]: 
a                        object
b                         int64
c                         uint8
d                       float64
e                          bool
f                datetime64[ns]
g    datetime64[ns, US/Eastern]
h                      category
i                      category
dtype: object

---->   pandas.read_parquet

--------------------------------------
ID: 735 --> 1
In [597]: result = pd.read_parquet(
   .....:     "example_fp.parquet",
   .....:     engine="fastparquet",
   .....:     columns=["a", "b"],
   .....: )
   .....: 

In [598]: result = pd.read_parquet(
   .....:     "example_pa.parquet",
   .....:     engine="pyarrow",
   .....:     columns=["a", "b"],
   .....: )
   .....: 

In [599]: result.dtypes
Out[599]: 
a    object
b     int64
dtype: object

---->   pandas.read_parquet

--------------------------------------
ID: 736 --> 2
In [600]: df = pd.DataFrame({"a": [1, 2], "b": [3, 4]})

In [601]: df.to_parquet("test.parquet", engine="pyarrow")

---->   pandas.DataFrame; DataFrame.to_parquet

--------------------------------------
ID: 737 --> 1
In [602]: df.to_parquet("test.parquet", index=False)

---->   DataFrame.to_parquet

--------------------------------------
ID: 738 --> 2
In [603]: df = pd.DataFrame({"a": [0, 0, 1, 1], "b": [0, 1, 0, 1]})

In [604]: df.to_parquet(path="test", engine="pyarrow", partition_cols=["a"], compression=None)

---->   pandas.DataFrame; DataFrame.to_parquet

--------------------------------------
ID: 739 --> 1
In [605]: df = pd.DataFrame(
   .....:     {
   .....:         "a": list("abc"),
   .....:         "b": list(range(1, 4)),
   .....:         "c": np.arange(4.0, 7.0, dtype="float64"),
   .....:         "d": [True, False, True],
   .....:         "e": pd.date_range("20130101", periods=3),
   .....:     }
   .....: )
   .....: 

In [606]: df
Out[606]: 
   a  b    c      d          e
0  a  1  4.0   True 2013-01-01
1  b  2  5.0  False 2013-01-02
2  c  3  6.0   True 2013-01-03

In [607]: df.dtypes
Out[607]: 
a            object
b             int64
c           float64
d              bool
e    datetime64[ns]
dtype: object

---->   pandas.DataFrame

--------------------------------------
ID: 741 --> 1
In [609]: result = pd.read_orc("example_pa.orc")

In [610]: result.dtypes
Out[610]: 
a            object
b             int64
c           float64
d              bool
e    datetime64[ns]
dtype: object

---->   pandas.read_orc

--------------------------------------
ID: 742 --> 1
In [611]: result = pd.read_orc(
   .....:     "example_pa.orc",
   .....:     columns=["a", "b"],
   .....: )
   .....: 

In [612]: result.dtypes
Out[612]: 
a    object
b     int64
dtype: object

---->   pandas.read_orc

--------------------------------------
ID: 744 --> 1
with engine.connect() as conn, conn.begin():
    data = pd.read_sql_table("data", conn)

---->   pandas.read_sql_table

--------------------------------------
ID: 745 --> 2
In [615]: import datetime

In [616]: c = ["id", "Date", "Col_1", "Col_2", "Col_3"]

In [617]: d = [
   .....:     (26, datetime.datetime(2010, 10, 18), "X", 27.5, True),
   .....:     (42, datetime.datetime(2010, 10, 19), "Y", -12.5, False),
   .....:     (63, datetime.datetime(2010, 10, 20), "Z", 5.73, True),
   .....: ]
   .....: 

In [618]: data = pd.DataFrame(d, columns=c)

In [619]: data
Out[619]: 
   id       Date Col_1  Col_2  Col_3
0  26 2010-10-18     X  27.50   True
1  42 2010-10-19     Y -12.50  False
2  63 2010-10-20     Z   5.73   True

In [620]: data.to_sql("data", engine)
Out[620]: 3

---->   pandas.DataFrame; DataFrame.to_sql

--------------------------------------
ID: 746 --> 1
In [621]: data.to_sql("data_chunked", engine, chunksize=1000)
Out[621]: 3

---->   DataFrame.to_sql

--------------------------------------
ID: 747 --> 1
In [622]: from sqlalchemy.types import String

In [623]: data.to_sql("data_dtype", engine, dtype={"Col_1": String})
Out[623]: 3

---->   DataFrame.to_sql

--------------------------------------
ID: 749 --> 1
In [624]: pd.read_sql_table("data", engine)
Out[624]: 
   index  id       Date Col_1  Col_2  Col_3
0      0  26 2010-10-18     X  27.50   True
1      1  42 2010-10-19     Y -12.50  False
2      2  63 2010-10-20     Z   5.73   True

---->   pandas.read_sql_table

--------------------------------------
ID: 750 --> 1
In [625]: pd.read_sql_table("data", engine, index_col="id")
Out[625]: 
    index       Date Col_1  Col_2  Col_3
id                                      
26      0 2010-10-18     X  27.50   True
42      1 2010-10-19     Y -12.50  False
63      2 2010-10-20     Z   5.73   True

In [626]: pd.read_sql_table("data", engine, columns=["Col_1", "Col_2"])
Out[626]: 
  Col_1  Col_2
0     X  27.50
1     Y -12.50
2     Z   5.73

---->   pandas.read_sql_table

--------------------------------------
ID: 751 --> 1
In [627]: pd.read_sql_table("data", engine, parse_dates=["Date"])
Out[627]: 
   index  id       Date Col_1  Col_2  Col_3
0      0  26 2010-10-18     X  27.50   True
1      1  42 2010-10-19     Y -12.50  False
2      2  63 2010-10-20     Z   5.73   True

---->   pandas.read_sql_table

--------------------------------------
ID: 752 --> 1
pd.read_sql_table("data", engine, parse_dates={"Date": "%Y-%m-%d"})
pd.read_sql_table(
    "data",
    engine,
    parse_dates={"Date": {"format": "%Y-%m-%d %H:%M:%S"}},
)

---->   pandas.read_sql_table

--------------------------------------
ID: 753 --> 2
df.to_sql("table", engine, schema="other_schema")
pd.read_sql_table("table", engine, schema="other_schema")

---->   DataFrame.to_sql; pandas.read_sql_table

--------------------------------------
ID: 754 --> 1
In [628]: pd.read_sql_query("SELECT * FROM data", engine)
Out[628]: 
   index  id                        Date Col_1  Col_2  Col_3
0      0  26  2010-10-18 00:00:00.000000     X  27.50      1
1      1  42  2010-10-19 00:00:00.000000     Y -12.50      0
2      2  63  2010-10-20 00:00:00.000000     Z   5.73      1

---->   pandas.read_sql_query

--------------------------------------
ID: 755 --> 1
In [629]: pd.read_sql_query("SELECT id, Col_1, Col_2 FROM data WHERE id = 42;", engine)
Out[629]: 
   id Col_1  Col_2
0  42     Y  -12.5

---->   pandas.read_sql_query

--------------------------------------
ID: 756 --> 2
In [630]: df = pd.DataFrame(np.random.randn(20, 3), columns=list("abc"))

In [631]: df.to_sql("data_chunks", engine, index=False)
Out[631]: 20

---->   pandas.DataFrame; DataFrame.to_sql

--------------------------------------
ID: 757 --> 1
In [632]: for chunk in pd.read_sql_query("SELECT * FROM data_chunks", engine, chunksize=5):
   .....:     print(chunk)
   .....: 
          a         b         c
0 -0.517871 -0.990317 -0.294348
1  0.335844 -0.794159  1.495614
2 -0.231342  0.557402  0.860312
3 -0.538674 -0.541986 -1.759606
4 -1.520478 -1.069391 -0.551981
          a         b         c
0  0.452407  0.409257  0.301911
1 -0.640843 -2.253022 -0.395347
2 -0.822726 -0.363777  1.676124
3 -0.908102 -1.391346 -1.094269
4  0.278380  1.205899  1.503443
          a         b         c
0  0.932171 -0.709459 -0.645944
1 -1.351389  0.132023  0.210427
2  0.192202  0.661949  1.690629
3 -1.046044  0.618697 -0.013863
4  1.314289  1.951611 -1.485026
          a         b         c
0  0.304662  1.194757 -0.446717
1  0.528496 -0.657575 -0.876654
2  0.336252  0.172668  0.337684
3 -0.411202 -0.828394 -0.244413
4  1.094948  0.087183  1.125934

---->   pandas.read_sql_query

--------------------------------------
ID: 759 --> 1
In [633]: import sqlalchemy as sa

In [634]: pd.read_sql(
   .....:     sa.text("SELECT * FROM data where Col_1=:col1"), engine, params={"col1": "X"}
   .....: )
   .....: 
Out[634]: 
   index  id                        Date Col_1  Col_2  Col_3
0      0  26  2010-10-18 00:00:00.000000     X   27.5      1

---->   pandas.read_sql

--------------------------------------
ID: 760 --> 1
In [635]: metadata = sa.MetaData()

In [636]: data_table = sa.Table(
   .....:     "data",
   .....:     metadata,
   .....:     sa.Column("index", sa.Integer),
   .....:     sa.Column("Date", sa.DateTime),
   .....:     sa.Column("Col_1", sa.String),
   .....:     sa.Column("Col_2", sa.Float),
   .....:     sa.Column("Col_3", sa.Boolean),
   .....: )
   .....: 

In [637]: pd.read_sql(sa.select(data_table).where(data_table.c.Col_3 is True), engine)
Out[637]: 
Empty DataFrame
Columns: [index, Date, Col_1, Col_2, Col_3]
Index: []

---->   pandas.read_sql

--------------------------------------
ID: 761 --> 1
In [638]: import datetime as dt

In [639]: expr = sa.select(data_table).where(data_table.c.Date > sa.bindparam("date"))

In [640]: pd.read_sql(expr, engine, params={"date": dt.datetime(2010, 10, 18)})
Out[640]: 
   index       Date Col_1  Col_2  Col_3
0      1 2010-10-19     Y -12.50  False
1      2 2010-10-20     Z   5.73   True

---->   pandas.read_sql

--------------------------------------
ID: 763 --> 2
data.to_sql("data", con)
pd.read_sql_query("SELECT * FROM data", con)

---->   DataFrame.to_sql; pandas.read_sql_query

--------------------------------------
ID: 764 --> 1
In [641]: df = pd.DataFrame(np.random.randn(10, 2), columns=list("AB"))

In [642]: df.to_stata("stata.dta")

---->   pandas.DataFrame

--------------------------------------
ID: 770 --> 1
df = pd.read_spss("spss_data.sav")

---->   pandas.read_spss

--------------------------------------
ID: 771 --> 1
df = pd.read_spss(
    "spss_data.sav",
    usecols=["foo", "bar"],
    convert_categoricals=False,
)

---->   pandas.read_spss

--------------------------------------
ID: 772 --> 2
In [1]: sz = 1000000
In [2]: df = pd.DataFrame({'A': np.random.randn(sz), 'B': [1] * sz})

In [3]: df.info()

RangeIndex: 1000000 entries, 0 to 999999
Data columns (total 2 columns):
A    1000000 non-null float64
B    1000000 non-null int64
dtypes: float64(1), int64(1)
memory usage: 15.3 MB

---->   pandas.DataFrame; DataFrame.info

--------------------------------------
ID: 773 --> 12
import numpy as np

import os

sz = 1000000
df = pd.DataFrame({"A": np.random.randn(sz), "B": [1] * sz})

sz = 1000000
np.random.seed(42)
df = pd.DataFrame({"A": np.random.randn(sz), "B": [1] * sz})


def test_sql_write(df):
    if os.path.exists("test.sql"):
        os.remove("test.sql")
    sql_db = sqlite3.connect("test.sql")
    df.to_sql(name="test_table", con=sql_db)
    sql_db.close()


def test_sql_read():
    sql_db = sqlite3.connect("test.sql")
    pd.read_sql_query("select * from test_table", sql_db)
    sql_db.close()


def test_hdf_fixed_write(df):
    df.to_hdf("test_fixed.hdf", "test", mode="w")


def test_hdf_fixed_read():
    pd.read_hdf("test_fixed.hdf", "test")


def test_hdf_fixed_write_compress(df):
    df.to_hdf("test_fixed_compress.hdf", "test", mode="w", complib="blosc")


def test_hdf_fixed_read_compress():
    pd.read_hdf("test_fixed_compress.hdf", "test")


def test_hdf_table_write(df):
    df.to_hdf("test_table.hdf", "test", mode="w", format="table")


def test_hdf_table_read():
    pd.read_hdf("test_table.hdf", "test")


def test_hdf_table_write_compress(df):
    df.to_hdf(
        "test_table_compress.hdf", "test", mode="w", complib="blosc", format="table"
    )


def test_hdf_table_read_compress():
    pd.read_hdf("test_table_compress.hdf", "test")


def test_csv_write(df):
    df.to_csv("test.csv", mode="w")


def test_csv_read():
    pd.read_csv("test.csv", index_col=0)


def test_feather_write(df):
    df.to_feather("test.feather")


def test_feather_read():
    pd.read_feather("test.feather")


def test_pickle_write(df):
    df.to_pickle("test.pkl")


def test_pickle_read():
    pd.read_pickle("test.pkl")


def test_pickle_write_compress(df):
    df.to_pickle("test.pkl.compress", compression="xz")


def test_pickle_read_compress():
    pd.read_pickle("test.pkl.compress", compression="xz")


def test_parquet_write(df):
    df.to_parquet("test.parquet")


def test_parquet_read():
    pd.read_parquet("test.parquet")

---->   pandas.DataFrame; DataFrame.to_sql; pandas.read_sql_query; DataFrame.to_hdf; pandas.read_hdf; DataFrame.to_csv; DataFrame.to_feather; pandas.read_feather; DataFrame.to_pickle; pandas.read_pickle; DataFrame.to_parquet; pandas.read_parquet

--------------------------------------
ID: 776 --> 2
In [1]: dtypes = [
   ...:     "int64",
   ...:     "float64",
   ...:     "datetime64[ns]",
   ...:     "timedelta64[ns]",
   ...:     "complex128",
   ...:     "object",
   ...:     "bool",
   ...: ]
   ...: 

In [2]: n = 5000

In [3]: data = {t: np.random.randint(100, size=n).astype(t) for t in dtypes}

In [4]: df = pd.DataFrame(data)

In [5]: df["categorical"] = df["object"].astype("category")

In [6]: df.info()

RangeIndex: 5000 entries, 0 to 4999
Data columns (total 8 columns):
 #   Column           Non-Null Count  Dtype          
---  ------           --------------  -----          
 0   int64            5000 non-null   int64          
 1   float64          5000 non-null   float64        
 2   datetime64[ns]   5000 non-null   datetime64[ns] 
 3   timedelta64[ns]  5000 non-null   timedelta64[ns]
 4   complex128       5000 non-null   complex128     
 5   object           5000 non-null   object         
 6   bool             5000 non-null   bool           
 7   categorical      5000 non-null   category       
dtypes: bool(1), category(1), complex128(1), datetime64[ns](1), float64(1), int64(1), object(1), timedelta64[ns](1)
memory usage: 288.2+ KB

---->   pandas.DataFrame; DataFrame.info

--------------------------------------
ID: 777 --> 1
In [7]: df.info(memory_usage="deep")

RangeIndex: 5000 entries, 0 to 4999
Data columns (total 8 columns):
 #   Column           Non-Null Count  Dtype          
---  ------           --------------  -----          
 0   int64            5000 non-null   int64          
 1   float64          5000 non-null   float64        
 2   datetime64[ns]   5000 non-null   datetime64[ns] 
 3   timedelta64[ns]  5000 non-null   timedelta64[ns]
 4   complex128       5000 non-null   complex128     
 5   object           5000 non-null   object         
 6   bool             5000 non-null   bool           
 7   categorical      5000 non-null   category       
dtypes: bool(1), category(1), complex128(1), datetime64[ns](1), float64(1), int64(1), object(1), timedelta64[ns](1)
memory usage: 424.7 KB

---->   DataFrame.info

--------------------------------------
ID: 778 --> 1
In [8]: df.memory_usage()
Out[8]: 
Index                128
int64              40000
float64            40000
datetime64[ns]     40000
timedelta64[ns]    40000
complex128         80000
object             40000
bool                5000
categorical         9968
dtype: int64

# total memory usage of dataframe
In [9]: df.memory_usage().sum()
Out[9]: 295096

---->   DataFrame.memory_usage

--------------------------------------
ID: 779 --> 1
In [10]: df.memory_usage(index=False)
Out[10]: 
int64              40000
float64            40000
datetime64[ns]     40000
timedelta64[ns]    40000
complex128         80000
object             40000
bool                5000
categorical         9968
dtype: int64

---->   DataFrame.memory_usage

--------------------------------------
ID: 780 --> 1
>>> if pd.Series([False, True, False]):
...     pass

---->   pandas.Series

--------------------------------------
ID: 781 --> 4
In [11]: if pd.Series([False, True, False]):
   ....:     print("I was true")
   ....: 
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
 in ?()
----> 1 if pd.Series([False, True, False]):
      2     print("I was true")

~/work/pandas/pandas/pandas/core/generic.py in ?(self)
   1464     @final
   1465     def __nonzero__(self) -> NoReturn:
-> 1466         raise ValueError(
   1467             f"The truth value of a {type(self).__name__} is ambiguous. "
   1468             "Use a.empty, a.bool(), a.item(), a.any() or a.all()."
   1469         )

ValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().

---->   pandas.Series; Index.item; Index.any; Index.all

--------------------------------------
ID: 782 --> 1
In [12]: if pd.Series([False, True, False]) is not None:
   ....:     print("I was not None")
   ....: 
I was not None

---->   pandas.Series

--------------------------------------
ID: 783 --> 1
In [13]: if pd.Series([False, True, False]).any():
   ....:     print("I am any")
   ....: 
I am any

---->   pandas.Series

--------------------------------------
ID: 784 --> 2
In [14]: pd.Series([True]).bool()
Out[14]: True

In [15]: pd.Series([False]).bool()
Out[15]: False

In [16]: pd.DataFrame([[True]]).bool()
Out[16]: True

In [17]: pd.DataFrame([[False]]).bool()
Out[17]: False

---->   pandas.Series; pandas.DataFrame

--------------------------------------
ID: 785 --> 1
In [18]: s = pd.Series(range(5))

In [19]: s == 4
Out[19]: 
0    False
1    False
2    False
3    False
4     True
dtype: bool

---->   pandas.Series

--------------------------------------
ID: 786 --> 1
In [20]: s = pd.Series(range(5), index=list("abcde"))

In [21]: 2 in s
Out[21]: False

In [22]: 'b' in s
Out[22]: True

---->   pandas.Series

--------------------------------------
ID: 787 --> 1
In [23]: s.isin([2])
Out[23]: 
a    False
b    False
c     True
d    False
e    False
dtype: bool

In [24]: s.isin([2]).any()
Out[24]: True

---->   Series.isin

--------------------------------------
ID: 789 --> 2
In [29]: def f(s):
   ....:     s.pop("a")
   ....:     return s
   ....: 

In [30]: df = pd.DataFrame({"a": [1, 2, 3], "b": [4, 5, 6]})

In [31]: try:
   ....:     df.apply(f, axis="columns")
   ....: except Exception as err:
   ....:     print(repr(err))
   ....: 
KeyError('a')

---->   Series.pop; pandas.DataFrame

--------------------------------------
ID: 791 --> 3
In [36]: def f(s):
   ....:     s = s.copy()
   ....:     s.pop("a")
   ....:     return s
   ....: 

In [37]: df = pd.DataFrame({"a": [1, 2, 3], 'b': [4, 5, 6]})

In [38]: df.apply(f, axis="columns")
Out[38]: 
   b
0  4
1  5
2  6

---->   Series.copy; Series.pop; pandas.DataFrame

--------------------------------------
ID: 792 --> 1
In [39]: s = pd.Series([1, 2, 3, 4, 5], index=list("abcde"))

In [40]: s
Out[40]: 
a    1
b    2
c    3
d    4
e    5
dtype: int64

In [41]: s.dtype
Out[41]: dtype('int64')

In [42]: s2 = s.reindex(["a", "b", "c", "f", "u"])

In [43]: s2
Out[43]: 
a    1.0
b    2.0
c    3.0
f    NaN
u    NaN
dtype: float64

In [44]: s2.dtype
Out[44]: dtype('float64')

---->   pandas.Series

--------------------------------------
ID: 793 --> 2
In [45]: s_int = pd.Series([1, 2, 3, 4, 5], index=list("abcde"), dtype=pd.Int64Dtype())

In [46]: s_int
Out[46]: 
a    1
b    2
c    3
d    4
e    5
dtype: Int64

In [47]: s_int.dtype
Out[47]: Int64Dtype()

In [48]: s2_int = s_int.reindex(["a", "b", "c", "f", "u"])

In [49]: s2_int
Out[49]: 
a       1
b       2
c       3
f    
u    
dtype: Int64

In [50]: s2_int.dtype
Out[50]: Int64Dtype()

---->   pandas.Series; pandas.Int64Dtype

--------------------------------------
ID: 794 --> 1
In [51]: x = np.array(list(range(10)), ">i4")  # big endian

In [52]: newx = x.byteswap().newbyteorder()  # force native byteorder

In [53]: s = pd.Series(newx)

---->   pandas.Series

--------------------------------------
ID: 798 --> 1
In [17]: pd.to_timedelta("1 days 06:05:01.00003")
Out[17]: Timedelta('1 days 06:05:01.000030')

In [18]: pd.to_timedelta("15.5us")
Out[18]: Timedelta('0 days 00:00:00.000015500')

---->   pandas.to_timedelta

--------------------------------------
ID: 799 --> 1
In [19]: pd.to_timedelta(["1 days 06:05:01.00003", "15.5us", "nan"])
Out[19]: TimedeltaIndex(['1 days 06:05:01.000030', '0 days 00:00:00.000015500', NaT], dtype='timedelta64[ns]', freq=None)

---->   pandas.to_timedelta

--------------------------------------
ID: 800 --> 1
In [20]: pd.to_timedelta(np.arange(5), unit="s")
Out[20]: 
TimedeltaIndex(['0 days 00:00:00', '0 days 00:00:01', '0 days 00:00:02',
                '0 days 00:00:03', '0 days 00:00:04'],
               dtype='timedelta64[ns]', freq=None)

In [21]: pd.to_timedelta(np.arange(5), unit="d")
Out[21]: TimedeltaIndex(['0 days', '1 days', '2 days', '3 days', '4 days'], dtype='timedelta64[ns]', freq=None)

---->   pandas.to_timedelta

--------------------------------------
ID: 802 --> 3
In [24]: s = pd.Series(pd.date_range("2012-1-1", periods=3, freq="D"))

In [25]: td = pd.Series([pd.Timedelta(days=i) for i in range(3)])

In [26]: df = pd.DataFrame({"A": s, "B": td})

In [27]: df
Out[27]: 
           A      B
0 2012-01-01 0 days
1 2012-01-02 1 days
2 2012-01-03 2 days

In [28]: df["C"] = df["A"] + df["B"]

In [29]: df
Out[29]: 
           A      B          C
0 2012-01-01 0 days 2012-01-01
1 2012-01-02 1 days 2012-01-03
2 2012-01-03 2 days 2012-01-05

In [30]: df.dtypes
Out[30]: 
A     datetime64[ns]
B    timedelta64[ns]
C     datetime64[ns]
dtype: object

In [31]: s - s.max()
Out[31]: 
0   -2 days
1   -1 days
2    0 days
dtype: timedelta64[ns]

In [32]: s - datetime.datetime(2011, 1, 1, 3, 5)
Out[32]: 
0   364 days 20:55:00
1   365 days 20:55:00
2   366 days 20:55:00
dtype: timedelta64[ns]

In [33]: s + datetime.timedelta(minutes=5)
Out[33]: 
0   2012-01-01 00:05:00
1   2012-01-02 00:05:00
2   2012-01-03 00:05:00
dtype: datetime64[ns]

In [34]: s + pd.offsets.Minute(5)
Out[34]: 
0   2012-01-01 00:05:00
1   2012-01-02 00:05:00
2   2012-01-03 00:05:00
dtype: datetime64[ns]

In [35]: s + pd.offsets.Minute(5) + pd.offsets.Milli(5)
Out[35]: 
0   2012-01-01 00:05:00.005
1   2012-01-02 00:05:00.005
2   2012-01-03 00:05:00.005
dtype: datetime64[ns]

---->   pandas.Series; pandas.DataFrame; Series.max

--------------------------------------
ID: 803 --> 1
In [38]: y = s - s.shift()

In [39]: y
Out[39]: 
0      NaT
1   1 days
2   1 days
dtype: timedelta64[ns]

---->   Series.shift

--------------------------------------
ID: 804 --> 1
In [42]: s.max() - s
Out[42]: 
0   2 days
1   1 days
2   0 days
dtype: timedelta64[ns]

In [43]: datetime.datetime(2011, 1, 1, 3, 5) - s
Out[43]: 
0   -365 days +03:05:00
1   -366 days +03:05:00
2   -367 days +03:05:00
dtype: timedelta64[ns]

In [44]: datetime.timedelta(minutes=5) + s
Out[44]: 
0   2012-01-01 00:05:00
1   2012-01-02 00:05:00
2   2012-01-03 00:05:00
dtype: datetime64[ns]

---->   Series.max

--------------------------------------
ID: 805 --> 5
In [45]: A = s - pd.Timestamp("20120101") - pd.Timedelta("00:05:05")

In [46]: B = s - pd.Series(pd.date_range("2012-1-2", periods=3, freq="D"))

In [47]: df = pd.DataFrame({"A": A, "B": B})

In [48]: df
Out[48]: 
                  A       B
0 -1 days +23:54:55 -1 days
1   0 days 23:54:55 -1 days
2   1 days 23:54:55 -1 days

In [49]: df.min()
Out[49]: 
A   -1 days +23:54:55
B   -1 days +00:00:00
dtype: timedelta64[ns]

In [50]: df.min(axis=1)
Out[50]: 
0   -1 days
1   -1 days
2   -1 days
dtype: timedelta64[ns]

In [51]: df.idxmin()
Out[51]: 
A    0
B    0
dtype: int64

In [52]: df.idxmax()
Out[52]: 
A    2
B    0
dtype: int64

---->   pandas.Series; pandas.DataFrame; DataFrame.min; DataFrame.idxmin; DataFrame.idxmax

--------------------------------------
ID: 806 --> 1
In [53]: df.min().max()
Out[53]: Timedelta('-1 days +23:54:55')

In [54]: df.min(axis=1).min()
Out[54]: Timedelta('-1 days +00:00:00')

In [55]: df.min().idxmax()
Out[55]: 'A'

In [56]: df.min(axis=1).idxmin()
Out[56]: 0

---->   DataFrame.min

--------------------------------------
ID: 809 --> 2
In [65]: y2 = pd.Series(
   ....:     pd.to_timedelta(["-1 days +00:00:05", "nat", "-1 days +00:00:05", "1 days"])
   ....: )
   ....: 

In [66]: y2
Out[66]: 
0   -1 days +00:00:05
1                 NaT
2   -1 days +00:00:05
3     1 days 00:00:00
dtype: timedelta64[ns]

In [67]: y2.mean()
Out[67]: Timedelta('-1 days +16:00:03.333333334')

In [68]: y2.median()
Out[68]: Timedelta('-1 days +00:00:05')

In [69]: y2.quantile(0.1)
Out[69]: Timedelta('-1 days +00:00:05')

In [70]: y2.sum()
Out[70]: Timedelta('-1 days +00:00:10')

---->   pandas.Series; pandas.to_timedelta

--------------------------------------
ID: 810 --> 2
In [71]: december = pd.Series(pd.date_range("20121201", periods=4))

In [72]: january = pd.Series(pd.date_range("20130101", periods=4))

In [73]: td = january - december

In [74]: td[2] += datetime.timedelta(minutes=5, seconds=3)

In [75]: td[3] = np.nan

In [76]: td
Out[76]: 
0   31 days 00:00:00
1   31 days 00:00:00
2   31 days 00:05:03
3                NaT
dtype: timedelta64[ns]

# to seconds
In [77]: td.astype("timedelta64[s]")
Out[77]: 
0   31 days 00:00:00
1   31 days 00:00:00
2   31 days 00:05:03
3                NaT
dtype: timedelta64[s]

---->   pandas.Series; Series.astype

--------------------------------------
ID: 812 --> 1
In [80]: td * -1
Out[80]: 
0   -31 days +00:00:00
1   -31 days +00:00:00
2   -32 days +23:54:57
3                  NaT
dtype: timedelta64[ns]

In [81]: td * pd.Series([1, 2, 3, 4])
Out[81]: 
0   31 days 00:00:00
1   62 days 00:00:00
2   93 days 00:15:09
3                NaT
dtype: timedelta64[ns]

---->   pandas.Series

--------------------------------------
ID: 817 --> 1
In [96]: pd.TimedeltaIndex(
   ....:     [
   ....:         "1 days",
   ....:         "1 days, 00:00:05",
   ....:         np.timedelta64(2, "D"),
   ....:         datetime.timedelta(days=2, seconds=2),
   ....:     ]
   ....: )
   ....: 
Out[96]: 
TimedeltaIndex(['1 days 00:00:00', '1 days 00:00:05', '2 days 00:00:00',
                '2 days 00:00:02'],
               dtype='timedelta64[ns]', freq=None)

---->   pandas.TimedeltaIndex

--------------------------------------
ID: 818 --> 1
In [97]: pd.TimedeltaIndex(["0 days", "10 days", "20 days"], freq="infer")
Out[97]: TimedeltaIndex(['0 days', '10 days', '20 days'], dtype='timedelta64[ns]', freq='10D')

---->   pandas.TimedeltaIndex

--------------------------------------
ID: 823 --> 1
In [105]: s = pd.Series(
   .....:     np.arange(100),
   .....:     index=pd.timedelta_range("1 days", periods=100, freq="h"),
   .....: )
   .....: 

In [106]: s
Out[106]: 
1 days 00:00:00     0
1 days 01:00:00     1
1 days 02:00:00     2
1 days 03:00:00     3
1 days 04:00:00     4
                   ..
4 days 23:00:00    95
5 days 00:00:00    96
5 days 01:00:00    97
5 days 02:00:00    98
5 days 03:00:00    99
Freq: H, Length: 100, dtype: int64

---->   pandas.Series

--------------------------------------
ID: 825 --> 1
In [111]: tdi = pd.TimedeltaIndex(["1 days", pd.NaT, "2 days"])

In [112]: tdi.to_list()
Out[112]: [Timedelta('1 days 00:00:00'), NaT, Timedelta('2 days 00:00:00')]

In [113]: dti = pd.date_range("20130101", periods=3)

In [114]: dti.to_list()
Out[114]: 
[Timestamp('2013-01-01 00:00:00'),
 Timestamp('2013-01-02 00:00:00'),
 Timestamp('2013-01-03 00:00:00')]

In [115]: (dti + tdi).to_list()
Out[115]: [Timestamp('2013-01-02 00:00:00'), NaT, Timestamp('2013-01-05 00:00:00')]

In [116]: (dti - tdi).to_list()
Out[116]: [Timestamp('2012-12-31 00:00:00'), NaT, Timestamp('2013-01-01 00:00:00')]

---->   pandas.TimedeltaIndex

--------------------------------------
ID: 828 --> 1
In [124]: s.resample("D").mean()
Out[124]: 
1 days    11.5
2 days    35.5
3 days    59.5
4 days    83.5
5 days    97.5
Freq: D, dtype: float64

---->   Series.resample

--------------------------------------
ID: 829 --> 1
import pandas as pd
import numpy as np
import matplotlib as mpl

df = pd.DataFrame({
    "strings": ["Adam", "Mike"],
    "ints": [1, 3],
    "floats": [1.123, 1000.23]
})
df.style \
  .format(precision=3, thousands=".", decimal=",") \
  .format_index(str.upper, axis=1) \
  .relabel_index(["row 1", "row 2"], axis=0)

---->   pandas.DataFrame

--------------------------------------
ID: 830 --> 1
weather_df = pd.DataFrame(np.random.rand(10,2)*5,
                          index=pd.date_range(start="2021-01-01", periods=10),
                          columns=["Tokyo", "Beijing"])

def rain_condition(v):
    if v < 1.75:
        return "Dry"
    elif v < 2.75:
        return "Rain"
    return "Heavy Rain"

def make_pretty(styler):
    styler.set_caption("Weather Conditions")
    styler.format(rain_condition)
    styler.format_index(lambda v: v.strftime("%A"))
    styler.background_gradient(axis=None, vmin=1, vmax=5, cmap="YlGnBu")
    return styler

weather_df

---->   pandas.DataFrame

--------------------------------------
ID: 832 --> 1
df = pd.DataFrame(np.random.randn(5, 5))
df.style \
  .hide(subset=[0, 2, 4], axis=0) \
  .hide(subset=[0, 2, 4], axis=1)

---->   pandas.DataFrame

--------------------------------------
ID: 834 --> 1
summary_styler = df.agg(["sum", "mean"]).style \
                   .format(precision=3) \
                   .relabel_index(["Sum", "Average"])
df.style.format(precision=1).concat(summary_styler)

---->   DataFrame.agg

--------------------------------------
ID: 835 --> 3
df = pd.DataFrame([[38.0, 2.0, 18.0, 22.0, 21, np.nan],[19, 439, 6, 452, 226,232]],
                  index=pd.Index(['Tumour (Positive)', 'Non-Tumour (Negative)'], name='Actual Label:'),
                  columns=pd.MultiIndex.from_product([['Decision Tree', 'Regression', 'Random'],['Tumour', 'Non-Tumour']], names=['Model:', 'Predicted:']))
df.style

---->   pandas.DataFrame; pandas.Index; pandas.MultiIndex

--------------------------------------
ID: 841 --> 1
s.set_table_styles([  # create internal CSS classes
    {'selector': '.true', 'props': 'background-color: #e6ffe6;'},
    {'selector': '.false', 'props': 'background-color: #ffe6e6;'},
], overwrite=False)
cell_color = pd.DataFrame([['true ', 'false ', 'true ', 'false '],
                           ['false ', 'true ', 'false ', 'true ']],
                          index=df.index,
                          columns=df.columns[:4])
s.set_td_classes(cell_color)

---->   pandas.DataFrame

--------------------------------------
ID: 842 --> 1
np.random.seed(0)
df2 = pd.DataFrame(np.random.randn(10,4), columns=['A','B','C','D'])
df2.style

---->   pandas.DataFrame

--------------------------------------
ID: 846 --> 1
s2.applymap_index(lambda v: "color:pink;" if v>4 else "color:darkblue;", axis=0)
s2.apply_index(lambda s: np.where(s.isin(["A", "B"]), "color:pink;", "color:darkblue;"), axis=1)

---->   Series.isin

--------------------------------------
ID: 848 --> 1
tt = pd.DataFrame([['This model has a very strong true positive rate',
                    "This model's total number of false negatives is too high"]],
                  index=['Tumour (Positive)'], columns=df.columns[[0,3]])
s.set_tooltips(tt, props='visibility: hidden; position: absolute; z-index: 1; border: 1px solid #000066;'
                         'background-color: white; color: #000066; font-size: 0.8em;'
                         'transform: translate(0px, -24px); padding: 0.6em; border-radius: 0.5em;')

---->   pandas.DataFrame

--------------------------------------
ID: 849 --> 1
s.set_table_styles([  # create internal CSS classes
    {'selector': '.border-red', 'props': 'border: 2px dashed red;'},
    {'selector': '.border-green', 'props': 'border: 2px dashed green;'},
], overwrite=False)
cell_border = pd.DataFrame([['border-green ', ' ', ' ', 'border-red '],
                           [' ', ' ', ' ', ' ']],
                          index=df.index,
                          columns=df.columns[:4])
s.set_td_classes(cell_color + cell_border)

---->   pandas.DataFrame

--------------------------------------
ID: 850 --> 2
df3 = pd.DataFrame(np.random.randn(4,4),
                   pd.MultiIndex.from_product([['A', 'B'], ['r1', 'r2']]),
                   columns=['c1','c2','c3','c4'])
df3

---->   pandas.DataFrame; pandas.MultiIndex

--------------------------------------
ID: 856 --> 1
df4 = pd.DataFrame([[1,2],[3,4]])
s4 = df4.style

---->   pandas.DataFrame

--------------------------------------
ID: 861 --> 1
build = lambda x: pd.DataFrame(x, index=df2.index, columns=df2.columns)
cls1 = build(df2.apply(highlight_max, props='cls-1 ', axis=0))
cls2 = build(df2.apply(highlight_max, props='cls-2 ', axis=1, result_type='expand').values)
cls3 = build(highlight_max(df2, props='cls-3 '))
df2.style.set_table_styles([
    {'selector': '.cls-1', 'props': 'color:white;background-color:darkblue;'},
    {'selector': '.cls-2', 'props': 'color:white;background-color:pink;'},
    {'selector': '.cls-3', 'props': 'color:white;background-color:purple;'}
]).set_td_classes(cls1 + cls2 + cls3)

---->   pandas.DataFrame

--------------------------------------
ID: 865 --> 1
left = pd.Series([1.0, 0.0, 1.0], index=["A", "B", "D"])
df2.loc[:4].style.highlight_between(left=left, right=1.5, axis=1, props='color:white; background-color:purple;')

---->   pandas.Series

--------------------------------------
ID: 877 --> 1
np.random.seed(25)
cmap = cmap=sns.diverging_palette(5, 250, as_cmap=True)
bigdf = pd.DataFrame(np.random.randn(20, 25)).cumsum()

bigdf.style.background_gradient(cmap, axis=1)\
    .set_properties(**{'max-width': '80px', 'font-size': '1pt'})\
    .set_caption("Hover to magnify")\
    .format(precision=2)\
    .set_table_styles(magnify())

---->   pandas.DataFrame

--------------------------------------
ID: 878 --> 1
bigdf = pd.DataFrame(np.random.randn(16, 100))
bigdf.style.set_sticky(axis="index")

---->   pandas.DataFrame

--------------------------------------
ID: 879 --> 1
bigdf.index = pd.MultiIndex.from_product([["A","B"],[0,1],[0,1,2,3]])
bigdf.style.set_sticky(axis="index", pixel_size=18, levels=[1,2])

---->   pandas.MultiIndex

--------------------------------------
ID: 880 --> 1
df4 = pd.DataFrame([['', '"&other"', '']])
df4.style

---->   pandas.DataFrame

--------------------------------------
ID: 884 --> 1
print(pd.DataFrame([[1,2],[3,4]], index=['i1', 'i2'], columns=['c1', 'c2']).style.to_html())

---->   pandas.DataFrame

--------------------------------------
ID: 885 --> 1
df4 = pd.DataFrame([['text']])
df4.style.applymap(lambda x: 'color:green;')\
         .applymap(lambda x: 'color:red;')

---->   pandas.DataFrame

--------------------------------------
ID: 888 --> 1
df4.style.set_uuid('b_')\
         .set_table_styles([{'selector': 'td', 'props': 'color:red;'},
                            {'selector': '.cls-1', 'props': 'color:blue;'}])\
         .applymap(lambda x: 'color:green;')\
         .set_td_classes(pd.DataFrame([['cls-1']]))

---->   pandas.DataFrame

--------------------------------------
ID: 889 --> 1
df4.style.set_uuid('c_')\
         .set_table_styles([{'selector': 'td', 'props': 'color:red;'},
                            {'selector': '.cls-1', 'props': 'color:blue;'},
                            {'selector': 'td.data', 'props': 'color:yellow;'}])\
         .applymap(lambda x: 'color:green;')\
         .set_td_classes(pd.DataFrame([['cls-1']]))

---->   pandas.DataFrame

--------------------------------------
ID: 890 --> 1
df4.style.set_uuid('d_')\
         .set_table_styles([{'selector': 'td', 'props': 'color:red;'},
                            {'selector': '.cls-1', 'props': 'color:blue;'},
                            {'selector': 'td.data', 'props': 'color:yellow;'}])\
         .applymap(lambda x: 'color:green !important;')\
         .set_td_classes(pd.DataFrame([['cls-1']]))

---->   pandas.DataFrame

--------------------------------------
ID: 899 --> 2
In [1]: s = pd.Series([1, 2, 3])

In [2]: mask = pd.array([True, False, pd.NA], dtype="boolean")

In [3]: s[mask]
Out[3]: 
0    1
dtype: int64

---->   pandas.Series; pandas.array

--------------------------------------
ID: 901 --> 1
In [5]: pd.Series([True, False, np.nan], dtype="object") | True
Out[5]: 
0     True
1     True
2    False
dtype: bool

In [6]: pd.Series([True, False, np.nan], dtype="boolean") | True
Out[6]: 
0    True
1    True
2    True
dtype: boolean

---->   pandas.Series

--------------------------------------
ID: 902 --> 1
In [7]: pd.Series([True, False, np.nan], dtype="object") & True
Out[7]: 
0     True
1    False
2    False
dtype: bool

In [8]: pd.Series([True, False, np.nan], dtype="boolean") & True
Out[8]: 
0     True
1    False
2     
dtype: boolean

---->   pandas.Series

--------------------------------------
ID: 904 --> 1
In [1]: speeds = pd.DataFrame(
   ...:     [
   ...:         ("bird", "Falconiformes", 389.0),
   ...:         ("bird", "Psittaciformes", 24.0),
   ...:         ("mammal", "Carnivora", 80.2),
   ...:         ("mammal", "Primates", np.nan),
   ...:         ("mammal", "Carnivora", 58),
   ...:     ],
   ...:     index=["falcon", "parrot", "lion", "monkey", "leopard"],
   ...:     columns=("class", "order", "max_speed"),
   ...: )
   ...: 

In [2]: speeds
Out[2]: 
          class           order  max_speed
falcon     bird   Falconiformes      389.0
parrot     bird  Psittaciformes       24.0
lion     mammal       Carnivora       80.2
monkey   mammal        Primates        NaN
leopard  mammal       Carnivora       58.0

# default is axis=0
In [3]: grouped = speeds.groupby("class")

In [4]: grouped = speeds.groupby("order", axis="columns")

In [5]: grouped = speeds.groupby(["class", "order"])

---->   pandas.DataFrame

--------------------------------------
ID: 905 --> 1
In [6]: df = pd.DataFrame(
   ...:     {
   ...:         "A": ["foo", "bar", "foo", "bar", "foo", "bar", "foo", "foo"],
   ...:         "B": ["one", "one", "two", "three", "two", "two", "one", "three"],
   ...:         "C": np.random.randn(8),
   ...:         "D": np.random.randn(8),
   ...:     }
   ...: )
   ...: 

In [7]: df
Out[7]: 
     A      B         C         D
0  foo    one  0.469112 -0.861849
1  bar    one -0.282863 -2.104569
2  foo    two -1.509059 -0.494929
3  bar  three -1.135632  1.071804
4  foo    two  1.212112  0.721555
5  bar    two -0.173215 -0.706771
6  foo    one  0.119209 -1.039575
7  foo  three -1.044236  0.271860

---->   pandas.DataFrame

--------------------------------------
ID: 906 --> 1
In [8]: grouped = df.groupby("A")

In [9]: grouped = df.groupby(["A", "B"])

---->   DataFrame.groupby

--------------------------------------
ID: 907 --> 1
In [10]: df2 = df.set_index(["A", "B"])

In [11]: grouped = df2.groupby(level=df2.index.names.difference(["B"]))

In [12]: grouped.sum()
Out[12]: 
            C         D
A                      
bar -1.591710 -1.739537
foo -0.752861 -1.402938

---->   DataFrame.groupby

--------------------------------------
ID: 908 --> 1
In [13]: def get_letter_type(letter):
   ....:     if letter.lower() in 'aeiou':
   ....:         return 'vowel'
   ....:     else:
   ....:         return 'consonant'
   ....: 

In [14]: grouped = df.groupby(get_letter_type, axis=1)

---->   DataFrame.groupby

--------------------------------------
ID: 909 --> 2
In [15]: lst = [1, 2, 3, 1, 2, 3]

In [16]: s = pd.Series([1, 2, 3, 10, 20, 30], lst)

In [17]: grouped = s.groupby(level=0)

In [18]: grouped.first()
Out[18]: 
1    1
2    2
3    3
dtype: int64

In [19]: grouped.last()
Out[19]: 
1    10
2    20
3    30
dtype: int64

In [20]: grouped.sum()
Out[20]: 
1    11
2    22
3    33
dtype: int64

---->   pandas.Series; Series.groupby

--------------------------------------
ID: 910 --> 2
In [21]: df2 = pd.DataFrame({"X": ["B", "B", "A", "A"], "Y": [1, 2, 3, 4]})

In [22]: df2.groupby(["X"]).sum()
Out[22]: 
   Y
X   
A  7
B  3

In [23]: df2.groupby(["X"], sort=False).sum()
Out[23]: 
   Y
X   
B  3
A  7

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 911 --> 2
In [24]: df3 = pd.DataFrame({"X": ["A", "B", "A", "B"], "Y": [1, 4, 3, 2]})

In [25]: df3.groupby(["X"]).get_group("A")
Out[25]: 
   X  Y
0  A  1
2  A  3

In [26]: df3.groupby(["X"]).get_group("B")
Out[26]: 
   X  Y
1  B  4
3  B  2

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 912 --> 1
In [27]: df_list = [[1, 2, 3], [1, None, 4], [2, 1, 3], [1, 2, 2]]

In [28]: df_dropna = pd.DataFrame(df_list, columns=["a", "b", "c"])

In [29]: df_dropna
Out[29]: 
   a    b  c
0  1  2.0  3
1  1  NaN  4
2  2  1.0  3
3  1  2.0  2

---->   pandas.DataFrame

--------------------------------------
ID: 913 --> 1
# Default ``dropna`` is set to True, which will exclude NaNs in keys
In [30]: df_dropna.groupby(by=["b"], dropna=True).sum()
Out[30]: 
     a  c
b        
1.0  2  3
2.0  2  5

# In order to allow NaN in keys, set ``dropna`` to False
In [31]: df_dropna.groupby(by=["b"], dropna=False).sum()
Out[31]: 
     a  c
b        
1.0  2  3
2.0  2  5
NaN  1  4

---->   DataFrame.groupby

--------------------------------------
ID: 914 --> 1
In [32]: df.groupby("A").groups
Out[32]: {'bar': [1, 3, 5], 'foo': [0, 2, 4, 6, 7]}

In [33]: df.groupby(get_letter_type, axis=1).groups
Out[33]: {'consonant': ['B', 'C', 'D'], 'vowel': ['A']}

---->   DataFrame.groupby

--------------------------------------
ID: 915 --> 1
In [34]: grouped = df.groupby(["A", "B"])

In [35]: grouped.groups
Out[35]: {('bar', 'one'): [1], ('bar', 'three'): [3], ('bar', 'two'): [5], ('foo', 'one'): [0, 6], ('foo', 'three'): [7], ('foo', 'two'): [2, 4]}

In [36]: len(grouped)
Out[36]: 6

---->   DataFrame.groupby

--------------------------------------
ID: 916 --> 1
In [37]: df
Out[37]: 
               height      weight  gender
2000-01-01  42.849980  157.500553    male
2000-01-02  49.607315  177.340407    male
2000-01-03  56.293531  171.524640    male
2000-01-04  48.421077  144.251986  female
2000-01-05  46.556882  152.526206    male
2000-01-06  68.448851  168.272968  female
2000-01-07  70.757698  136.431469    male
2000-01-08  58.909500  176.499753  female
2000-01-09  76.435631  174.094104  female
2000-01-10  45.306120  177.540920    male

In [38]: gb = df.groupby("gender")

---->   DataFrame.groupby

--------------------------------------
ID: 917 --> 2
In [40]: arrays = [
   ....:     ["bar", "bar", "baz", "baz", "foo", "foo", "qux", "qux"],
   ....:     ["one", "two", "one", "two", "one", "two", "one", "two"],
   ....: ]
   ....: 

In [41]: index = pd.MultiIndex.from_arrays(arrays, names=["first", "second"])

In [42]: s = pd.Series(np.random.randn(8), index=index)

In [43]: s
Out[43]: 
first  second
bar    one      -0.919854
       two      -0.042379
baz    one       1.247642
       two      -0.009920
foo    one       0.290213
       two       0.495767
qux    one       0.362949
       two       1.548106
dtype: float64

---->   pandas.MultiIndex; pandas.Series

--------------------------------------
ID: 918 --> 1
In [44]: grouped = s.groupby(level=0)

In [45]: grouped.sum()
Out[45]: 
first
bar   -0.962232
baz    1.237723
foo    0.785980
qux    1.911055
dtype: float64

---->   Series.groupby

--------------------------------------
ID: 919 --> 1
In [46]: s.groupby(level="second").sum()
Out[46]: 
second
one    0.980950
two    1.991575
dtype: float64

---->   Series.groupby

--------------------------------------
ID: 920 --> 1
In [47]: s
Out[47]: 
first  second  third
bar    doo     one     -1.131345
               two     -0.089329
baz    bee     one      0.337863
               two     -0.945867
foo    bop     one     -0.932132
               two      1.956030
qux    bop     one      0.017587
               two     -0.016692
dtype: float64

In [48]: s.groupby(level=["first", "second"]).sum()
Out[48]: 
first  second
bar    doo      -1.220674
baz    bee      -0.608004
foo    bop       1.023898
qux    bop       0.000895
dtype: float64

---->   Series.groupby

--------------------------------------
ID: 921 --> 1
In [49]: s.groupby(["first", "second"]).sum()
Out[49]: 
first  second
bar    doo      -1.220674
baz    bee      -0.608004
foo    bop       1.023898
qux    bop       0.000895
dtype: float64

---->   Series.groupby

--------------------------------------
ID: 922 --> 2
In [50]: arrays = [
   ....:     ["bar", "bar", "baz", "baz", "foo", "foo", "qux", "qux"],
   ....:     ["one", "two", "one", "two", "one", "two", "one", "two"],
   ....: ]
   ....: 

In [51]: index = pd.MultiIndex.from_arrays(arrays, names=["first", "second"])

In [52]: df = pd.DataFrame({"A": [1, 1, 1, 1, 2, 2, 3, 3], "B": np.arange(8)}, index=index)

In [53]: df
Out[53]: 
              A  B
first second      
bar   one     1  0
      two     1  1
baz   one     1  2
      two     1  3
foo   one     2  4
      two     2  5
qux   one     3  6
      two     3  7

---->   pandas.MultiIndex; pandas.DataFrame

--------------------------------------
ID: 923 --> 2
In [54]: df.groupby([pd.Grouper(level=1), "A"]).sum()
Out[54]: 
          B
second A   
one    1  2
       2  4
       3  6
two    1  4
       2  5
       3  7

---->   DataFrame.groupby; pandas.Grouper

--------------------------------------
ID: 924 --> 2
In [55]: df.groupby([pd.Grouper(level="second"), "A"]).sum()
Out[55]: 
          B
second A   
one    1  2
       2  4
       3  6
two    1  4
       2  5
       3  7

---->   DataFrame.groupby; pandas.Grouper

--------------------------------------
ID: 925 --> 1
In [56]: df.groupby(["second", "A"]).sum()
Out[56]: 
          B
second A   
one    1  2
       2  4
       3  6
two    1  4
       2  5
       3  7

---->   DataFrame.groupby

--------------------------------------
ID: 926 --> 2
In [57]: df = pd.DataFrame(
   ....:     {
   ....:         "A": ["foo", "bar", "foo", "bar", "foo", "bar", "foo", "foo"],
   ....:         "B": ["one", "one", "two", "three", "two", "two", "one", "three"],
   ....:         "C": np.random.randn(8),
   ....:         "D": np.random.randn(8),
   ....:     }
   ....: )
   ....: 

In [58]: df
Out[58]: 
     A      B         C         D
0  foo    one -0.575247  1.346061
1  bar    one  0.254161  1.511763
2  foo    two -1.143704  1.627081
3  bar  three  0.215897 -0.990582
4  foo    two  1.193555 -0.441652
5  bar    two -0.077118  1.211526
6  foo    one -0.408530  0.268520
7  foo  three -0.862495  0.024580

In [59]: grouped = df.groupby(["A"])

In [60]: grouped_C = grouped["C"]

In [61]: grouped_D = grouped["D"]

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 928 --> 1
In [63]: grouped = df.groupby('A')

In [64]: for name, group in grouped:
   ....:     print(name)
   ....:     print(group)
   ....: 
bar
     A      B         C         D
1  bar    one  0.254161  1.511763
3  bar  three  0.215897 -0.990582
5  bar    two -0.077118  1.211526
foo
     A      B         C         D
0  foo    one -0.575247  1.346061
2  foo    two -1.143704  1.627081
4  foo    two  1.193555 -0.441652
6  foo    one -0.408530  0.268520
7  foo  three -0.862495  0.024580

---->   DataFrame.groupby

--------------------------------------
ID: 929 --> 1
In [65]: for name, group in df.groupby(['A', 'B']):
   ....:     print(name)
   ....:     print(group)
   ....: 
('bar', 'one')
     A    B         C         D
1  bar  one  0.254161  1.511763
('bar', 'three')
     A      B         C         D
3  bar  three  0.215897 -0.990582
('bar', 'two')
     A    B         C         D
5  bar  two -0.077118  1.211526
('foo', 'one')
     A    B         C         D
0  foo  one -0.575247  1.346061
6  foo  one -0.408530  0.268520
('foo', 'three')
     A      B         C        D
7  foo  three -0.862495  0.02458
('foo', 'two')
     A    B         C         D
2  foo  two -1.143704  1.627081
4  foo  two  1.193555 -0.441652

---->   DataFrame.groupby

--------------------------------------
ID: 931 --> 1
In [67]: df.groupby(["A", "B"]).get_group(("bar", "one"))
Out[67]: 
     A    B         C         D
1  bar  one  0.254161  1.511763

---->   DataFrame.groupby

--------------------------------------
ID: 932 --> 1
In [68]: animals = pd.DataFrame(
   ....:     {
   ....:         "kind": ["cat", "dog", "cat", "dog"],
   ....:         "height": [9.1, 6.0, 9.5, 34.0],
   ....:         "weight": [7.9, 7.5, 9.9, 198.0],
   ....:     }
   ....: )
   ....: 

In [69]: animals
Out[69]: 
  kind  height  weight
0  cat     9.1     7.9
1  dog     6.0     7.5
2  cat     9.5     9.9
3  dog    34.0   198.0

In [70]: animals.groupby("kind").sum()
Out[70]: 
      height  weight
kind                
cat     18.6    17.8
dog     40.0   205.5

---->   pandas.DataFrame

--------------------------------------
ID: 934 --> 1
In [72]: df.groupby("A")[["C", "D"]].max()
Out[72]: 
            C         D
A                      
bar  0.254161  1.511763
foo  1.193555  1.627081

In [73]: df.groupby(["A", "B"]).mean()
Out[73]: 
                  C         D
A   B                        
bar one    0.254161  1.511763
    three  0.215897 -0.990582
    two   -0.077118  1.211526
foo one   -0.491888  0.807291
    three -0.862495  0.024580
    two    0.024925  0.592714

---->   DataFrame.groupby

--------------------------------------
ID: 935 --> 1
In [74]: grouped = df.groupby(["A", "B"])

In [75]: grouped.size()
Out[75]: 
A    B    
bar  one      1
     three    1
     two      1
foo  one      2
     three    1
     two      2
dtype: int64

---->   DataFrame.groupby

--------------------------------------
ID: 937 --> 2
In [77]: ll = [['foo', 1], ['foo', 2], ['foo', 2], ['bar', 1], ['bar', 1]]

In [78]: df4 = pd.DataFrame(ll, columns=["A", "B"])

In [79]: df4
Out[79]: 
     A  B
0  foo  1
1  foo  2
2  foo  2
3  bar  1
4  bar  1

In [80]: df4.groupby("A")["B"].nunique()
Out[80]: 
A
bar    1
foo    2
Name: B, dtype: int64

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 938 --> 1
In [81]: grouped = df.groupby("A")

In [82]: grouped[["C", "D"]].aggregate("sum")
Out[82]: 
            C         D
A                      
bar  0.392940  1.732707
foo -1.796421  2.824590

In [83]: grouped = df.groupby(["A", "B"])

In [84]: grouped.agg("sum")
Out[84]: 
                  C         D
A   B                        
bar one    0.254161  1.511763
    three  0.215897 -0.990582
    two   -0.077118  1.211526
foo one   -0.983776  1.614581
    three -0.862495  0.024580
    two    0.049851  1.185429

---->   DataFrame.groupby

--------------------------------------
ID: 939 --> 1
In [85]: grouped = df.groupby(["A", "B"], as_index=False)

In [86]: grouped.agg("sum")
Out[86]: 
     A      B         C         D
0  bar    one  0.254161  1.511763
1  bar  three  0.215897 -0.990582
2  bar    two -0.077118  1.211526
3  foo    one -0.983776  1.614581
4  foo  three -0.862495  0.024580
5  foo    two  0.049851  1.185429

In [87]: df.groupby("A", as_index=False)[["C", "D"]].agg("sum")
Out[87]: 
     A         C         D
0  bar  0.392940  1.732707
1  foo -1.796421  2.824590

---->   DataFrame.groupby

--------------------------------------
ID: 940 --> 1
In [88]: df.groupby(["A", "B"]).agg("sum").reset_index()
Out[88]: 
     A      B         C         D
0  bar    one  0.254161  1.511763
1  bar  three  0.215897 -0.990582
2  bar    two -0.077118  1.211526
3  foo    one -0.983776  1.614581
4  foo  three -0.862495  0.024580
5  foo    two  0.049851  1.185429

---->   DataFrame.groupby

--------------------------------------
ID: 942 --> 1
In [91]: animals.groupby("kind")[["height"]].agg(lambda x: x.astype(int).sum())
Out[91]: 
      height
kind        
cat       18
dog       40

---->   DataFrame.astype

--------------------------------------
ID: 943 --> 1
In [92]: grouped = df.groupby("A")

In [93]: grouped["C"].agg(["sum", "mean", "std"])
Out[93]: 
          sum      mean       std
A                                
bar  0.392940  0.130980  0.181231
foo -1.796421 -0.359284  0.912265

---->   DataFrame.groupby

--------------------------------------
ID: 948 --> 4
In [98]: grouped["C"].agg([lambda x: x.max() - x.min(), lambda x: x.median() - x.mean()])
Out[98]: 
       
A                          
bar    0.331279    0.084917
foo    2.337259   -0.215962

---->   DataFrame.max; DataFrame.min; DataFrame.median; DataFrame.mean

--------------------------------------
ID: 949 --> 1
In [99]: animals
Out[99]: 
  kind  height  weight
0  cat     9.1     7.9
1  dog     6.0     7.5
2  cat     9.5     9.9
3  dog    34.0   198.0

In [100]: animals.groupby("kind").agg(
   .....:     min_height=pd.NamedAgg(column="height", aggfunc="min"),
   .....:     max_height=pd.NamedAgg(column="height", aggfunc="max"),
   .....:     average_weight=pd.NamedAgg(column="weight", aggfunc="mean"),
   .....: )
   .....: 
Out[100]: 
      min_height  max_height  average_weight
kind                                        
cat          9.1         9.5            8.90
dog          6.0        34.0          102.75

---->   pandas.NamedAgg

--------------------------------------
ID: 951 --> 1
In [102]: animals.groupby("kind").agg(
   .....:     **{
   .....:         "total weight": pd.NamedAgg(column="weight", aggfunc="sum")
   .....:     }
   .....: )
   .....: 
Out[102]: 
      total weight
kind              
cat           17.8
dog          205.5

---->   pandas.NamedAgg

--------------------------------------
ID: 958 --> 7
In [118]: index = pd.date_range("10/1/1999", periods=1100)

In [119]: ts = pd.Series(np.random.normal(0.5, 2, 1100), index)

In [120]: ts = ts.rolling(window=100, min_periods=100).mean().dropna()

In [121]: ts.head()
Out[121]: 
2000-01-08    0.779333
2000-01-09    0.778852
2000-01-10    0.786476
2000-01-11    0.782797
2000-01-12    0.798110
Freq: D, dtype: float64

In [122]: ts.tail()
Out[122]: 
2002-09-30    0.660294
2002-10-01    0.631095
2002-10-02    0.673601
2002-10-03    0.709213
2002-10-04    0.719369
Freq: D, dtype: float64

In [123]: transformed = ts.groupby(lambda x: x.year).transform(
   .....:     lambda x: (x - x.mean()) / x.std()
   .....: )
   .....: 

---->   pandas.Series; Series.rolling; Series.head; Series.tail; Series.groupby; DataFrame.mean; DataFrame.std

--------------------------------------
ID: 959 --> 1
# Original Data
In [124]: grouped = ts.groupby(lambda x: x.year)

In [125]: grouped.mean()
Out[125]: 
2000    0.442441
2001    0.526246
2002    0.459365
dtype: float64

In [126]: grouped.std()
Out[126]: 
2000    0.131752
2001    0.210945
2002    0.128753
dtype: float64

# Transformed Data
In [127]: grouped_trans = transformed.groupby(lambda x: x.year)

In [128]: grouped_trans.mean()
Out[128]: 
2000   -4.870756e-16
2001   -1.545187e-16
2002    4.136282e-16
dtype: float64

In [129]: grouped_trans.std()
Out[129]: 
2000    1.0
2001    1.0
2002    1.0
dtype: float64

---->   Series.groupby

--------------------------------------
ID: 960 --> 2
In [130]: compare = pd.DataFrame({"Original": ts, "Transformed": transformed})

In [131]: compare.plot()
Out[131]: 

---->   pandas.DataFrame; DataFrame.plot

--------------------------------------
ID: 961 --> 3
In [132]: ts.groupby(lambda x: x.year).transform(lambda x: x.max() - x.min())
Out[132]: 
2000-01-08    0.623893
2000-01-09    0.623893
2000-01-10    0.623893
2000-01-11    0.623893
2000-01-12    0.623893
                ...   
2002-09-30    0.558275
2002-10-01    0.558275
2002-10-02    0.558275
2002-10-03    0.558275
2002-10-04    0.558275
Freq: D, Length: 1001, dtype: float64

---->   Series.groupby; DataFrame.max; DataFrame.min

--------------------------------------
ID: 962 --> 1
In [133]: data_df
Out[133]: 
            A         B         C
0    1.539708 -1.166480  0.533026
1    1.302092 -0.505754       NaN
2   -0.371983  1.104803 -0.651520
3   -1.309622  1.118697 -1.161657
4   -1.924296  0.396437  0.812436
..        ...       ...       ...
995 -0.093110  0.683847 -0.774753
996 -0.185043  1.438572       NaN
997 -0.394469 -0.642343  0.011374
998 -1.174126  1.857148       NaN
999  0.234564  0.517098  0.393534

[1000 rows x 3 columns]

In [134]: countries = np.array(["US", "UK", "GR", "JP"])

In [135]: key = countries[np.random.randint(0, 4, 1000)]

In [136]: grouped = data_df.groupby(key)

# Non-NA count in each group
In [137]: grouped.count()
Out[137]: 
      A    B    C
GR  209  217  189
JP  240  255  217
UK  216  231  193
US  239  250  217

In [138]: transformed = grouped.transform(lambda x: x.fillna(x.mean()))

---->   DataFrame.mean

--------------------------------------
ID: 964 --> 5
# ts.groupby(lambda x: x.year).transform(
#     lambda x: (x - x.mean()) / x.std()
# )
In [145]: grouped = ts.groupby(lambda x: x.year)

In [146]: result = (ts - grouped.transform("mean")) / grouped.transform("std")

# ts.groupby(lambda x: x.year).transform(lambda x: x.max() - x.min())
In [147]: grouped = ts.groupby(lambda x: x.year)

In [148]: result = grouped.transform("max") - grouped.transform("min")

# grouped = data_df.groupby(key)
# grouped.transform(lambda x: x.fillna(x.mean()))
In [149]: grouped = data_df.groupby(key)

In [150]: result = data_df.fillna(grouped.transform("mean"))

---->   Series.groupby; DataFrame.mean; DataFrame.std; DataFrame.max; DataFrame.min

--------------------------------------
ID: 965 --> 2
In [151]: df_re = pd.DataFrame({"A": [1] * 10 + [5] * 10, "B": np.arange(20)})

In [152]: df_re
Out[152]: 
    A   B
0   1   0
1   1   1
2   1   2
3   1   3
4   1   4
.. ..  ..
15  5  15
16  5  16
17  5  17
18  5  18
19  5  19

[20 rows x 2 columns]

In [153]: df_re.groupby("A").rolling(4).B.mean()
Out[153]: 
A    
1  0      NaN
   1      NaN
   2      NaN
   3      1.5
   4      2.5
         ... 
5  15    13.5
   16    14.5
   17    15.5
   18    16.5
   19    17.5
Name: B, Length: 20, dtype: float64

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 966 --> 1
In [154]: df_re.groupby("A").expanding().sum()
Out[154]: 
          B
A          
1 0     0.0
  1     1.0
  2     3.0
  3     6.0
  4    10.0
...     ...
5 15   75.0
  16   91.0
  17  108.0
  18  126.0
  19  145.0

[20 rows x 1 columns]

---->   DataFrame.groupby

--------------------------------------
ID: 967 --> 2
In [155]: df_re = pd.DataFrame(
   .....:     {
   .....:         "date": pd.date_range(start="2016-01-01", periods=4, freq="W"),
   .....:         "group": [1, 1, 2, 2],
   .....:         "val": [5, 6, 7, 8],
   .....:     }
   .....: ).set_index("date")
   .....: 

In [156]: df_re
Out[156]: 
            group  val
date                  
2016-01-03      1    5
2016-01-10      1    6
2016-01-17      2    7
2016-01-24      2    8

In [157]: df_re.groupby("group").resample("1D").ffill()
Out[157]: 
                  group  val
group date                  
1     2016-01-03      1    5
      2016-01-04      1    5
      2016-01-05      1    5
      2016-01-06      1    5
      2016-01-07      1    5
...                 ...  ...
2     2016-01-20      2    7
      2016-01-21      2    7
      2016-01-22      2    7
      2016-01-23      2    7
      2016-01-24      2    8

[16 rows x 2 columns]

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 970 --> 1
In [161]: product_volumes = pd.DataFrame(
   .....:     {
   .....:         "group": list("xxxxyyy"),
   .....:         "product": list("abcdefg"),
   .....:         "volume": [10, 30, 20, 15, 40, 10, 20],
   .....:     }
   .....: )
   .....: 

In [162]: product_volumes
Out[162]: 
  group product  volume
0     x       a      10
1     x       b      30
2     x       c      20
3     x       d      15
4     y       e      40
5     y       f      10
6     y       g      20

# Sort by volume to select the largest products first
In [163]: product_volumes = product_volumes.sort_values("volume", ascending=False)

In [164]: grouped = product_volumes.groupby("group")["volume"]

In [165]: cumpct = grouped.cumsum() / grouped.transform("sum")

In [166]: cumpct
Out[166]: 
4    0.571429
1    0.400000
2    0.666667
6    0.857143
3    0.866667
0    1.000000
5    1.000000
Name: volume, dtype: float64

In [167]: significant_products = product_volumes[cumpct <= 0.9]

In [168]: significant_products.sort_values(["group", "product"])
Out[168]: 
  group product  volume
1     x       b      30
2     x       c      20
3     x       d      15
4     y       e      40
6     y       g      20

---->   pandas.DataFrame

--------------------------------------
ID: 971 --> 3
In [169]: sf = pd.Series([1, 1, 2, 3, 3, 3])

In [170]: sf.groupby(sf).filter(lambda x: x.sum() > 2)
Out[170]: 
3    3
4    3
5    3
dtype: int64

---->   pandas.Series; Series.groupby; DataFrame.sum

--------------------------------------
ID: 972 --> 2
In [171]: dff = pd.DataFrame({"A": np.arange(8), "B": list("aabbbbcc")})

In [172]: dff.groupby("B").filter(lambda x: len(x) > 2)
Out[172]: 
   A  B
2  2  b
3  3  b
4  4  b
5  5  b

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 973 --> 1
In [173]: dff.groupby("B").filter(lambda x: len(x) > 2, dropna=False)
Out[173]: 
     A    B
0  NaN  NaN
1  NaN  NaN
2  2.0    b
3  3.0    b
4  4.0    b
5  5.0    b
6  NaN  NaN
7  NaN  NaN

---->   DataFrame.groupby

--------------------------------------
ID: 974 --> 1
In [174]: dff["C"] = np.arange(8)

In [175]: dff.groupby("B").filter(lambda x: len(x["C"]) > 2)
Out[175]: 
   A  B  C
2  2  b  2
3  3  b  3
4  4  b  4
5  5  b  5

---->   DataFrame.groupby

--------------------------------------
ID: 975 --> 2
In [176]: df
Out[176]: 
     A      B         C         D
0  foo    one -0.575247  1.346061
1  bar    one  0.254161  1.511763
2  foo    two -1.143704  1.627081
3  bar  three  0.215897 -0.990582
4  foo    two  1.193555 -0.441652
5  bar    two -0.077118  1.211526
6  foo    one -0.408530  0.268520
7  foo  three -0.862495  0.024580

In [177]: grouped = df.groupby("A")

# could also just call .describe()
In [178]: grouped["C"].apply(lambda x: x.describe())
Out[178]: 
A         
bar  count    3.000000
     mean     0.130980
     std      0.181231
     min     -0.077118
     25%      0.069390
                ...   
foo  min     -1.143704
     25%     -0.862495
     50%     -0.575247
     75%     -0.408530
     max      1.193555
Name: C, Length: 16, dtype: float64

---->   DataFrame.groupby; DataFrame.describe

--------------------------------------
ID: 976 --> 2
In [179]: grouped = df.groupby('A')['C']

In [180]: def f(group):
   .....:     return pd.DataFrame({'original': group,
   .....:                          'demeaned': group - group.mean()})
   .....: 

In [181]: grouped.apply(f)
Out[181]: 
       original  demeaned
A                        
bar 1  0.254161  0.123181
    3  0.215897  0.084917
    5 -0.077118 -0.208098
foo 0 -0.575247 -0.215962
    2 -1.143704 -0.784420
    4  1.193555  1.552839
    6 -0.408530 -0.049245
    7 -0.862495 -0.503211

---->   DataFrame.groupby; pandas.DataFrame

--------------------------------------
ID: 977 --> 1
In [182]: def f(x):
   .....:     return pd.Series([x, x ** 2], index=["x", "x^2"])
   .....: 

In [183]: s = pd.Series(np.random.rand(5))

In [184]: s
Out[184]: 
0    0.582898
1    0.098352
2    0.001438
3    0.009420
4    0.815826
dtype: float64

In [185]: s.apply(f)
Out[185]: 
          x       x^2
0  0.582898  0.339770
1  0.098352  0.009673
2  0.001438  0.000002
3  0.009420  0.000089
4  0.815826  0.665572

---->   pandas.Series

--------------------------------------
ID: 978 --> 1
In [186]: df.groupby("A", group_keys=True).apply(lambda x: x)
Out[186]: 
         A      B         C         D
A                                    
bar 1  bar    one  0.254161  1.511763
    3  bar  three  0.215897 -0.990582
    5  bar    two -0.077118  1.211526
foo 0  foo    one -0.575247  1.346061
    2  foo    two -1.143704  1.627081
    4  foo    two  1.193555 -0.441652
    6  foo    one -0.408530  0.268520
    7  foo  three -0.862495  0.024580

---->   DataFrame.groupby

--------------------------------------
ID: 979 --> 1
In [187]: df.groupby("A", group_keys=False).apply(lambda x: x)
Out[187]: 
     A      B         C         D
0  foo    one -0.575247  1.346061
1  bar    one  0.254161  1.511763
2  foo    two -1.143704  1.627081
3  bar  three  0.215897 -0.990582
4  foo    two  1.193555 -0.441652
5  bar    two -0.077118  1.211526
6  foo    one -0.408530  0.268520
7  foo  three -0.862495  0.024580

---->   DataFrame.groupby

--------------------------------------
ID: 980 --> 1
In [189]: df.groupby("A").std(numeric_only=True)
Out[189]: 
            C         D
A                      
bar  0.181231  1.366330
foo  0.912265  0.884785

---->   DataFrame.groupby

--------------------------------------
ID: 981 --> 1
In [190]: from decimal import Decimal

In [191]: df_dec = pd.DataFrame(
   .....:     {
   .....:         "id": [1, 2, 1, 2],
   .....:         "int_column": [1, 2, 3, 4],
   .....:         "dec_column": [
   .....:             Decimal("0.50"),
   .....:             Decimal("0.15"),
   .....:             Decimal("0.25"),
   .....:             Decimal("0.40"),
   .....:         ],
   .....:     }
   .....: )
   .....: 

# Decimal columns can be sum'd explicitly by themselves...
In [192]: df_dec.groupby(["id"])[["dec_column"]].sum()
Out[192]: 
   dec_column
id           
1        0.75
2        0.55

# ...but cannot be combined with standard data types or they will be excluded
In [193]: df_dec.groupby(["id"])[["int_column", "dec_column"]].sum()
Out[193]: 
    int_column dec_column
id                       
1            4       0.75
2            6       0.55

# Use .agg function to aggregate over standard and "nuisance" data types
# at the same time
In [194]: df_dec.groupby(["id"]).agg({"int_column": "sum", "dec_column": "sum"})
Out[194]: 
    int_column dec_column
id                       
1            4       0.75
2            6       0.55

---->   pandas.DataFrame

--------------------------------------
ID: 982 --> 2
In [195]: pd.Series([1, 1, 1]).groupby(
   .....:     pd.Categorical(["a", "a", "a"], categories=["a", "b"]), observed=False
   .....: ).count()
   .....: 
Out[195]: 
a    3
b    0
dtype: int64

---->   pandas.Series; pandas.Categorical

--------------------------------------
ID: 983 --> 2
In [196]: pd.Series([1, 1, 1]).groupby(
   .....:     pd.Categorical(["a", "a", "a"], categories=["a", "b"]), observed=True
   .....: ).count()
   .....: 
Out[196]: 
a    3
dtype: int64

---->   pandas.Series; pandas.Categorical

--------------------------------------
ID: 984 --> 2
In [197]: s = (
   .....:     pd.Series([1, 1, 1])
   .....:     .groupby(pd.Categorical(["a", "a", "a"], categories=["a", "b"]), observed=False)
   .....:     .count()
   .....: )
   .....: 

In [198]: s.index.dtype
Out[198]: CategoricalDtype(categories=['a', 'b'], ordered=False)

---->   pandas.Series; pandas.Categorical

--------------------------------------
ID: 985 --> 3
In [199]: data = pd.Series(np.random.randn(100))

In [200]: factor = pd.qcut(data, [0, 0.25, 0.5, 0.75, 1.0])

In [201]: data.groupby(factor).mean()
Out[201]: 
(-2.784, -0.41]   -1.196181
(-0.41, 0.0754]   -0.127244
(0.0754, 0.795]    0.408266
(0.795, 2.821]     1.357293
dtype: float64

---->   pandas.Series; pandas.qcut; Series.groupby

--------------------------------------
ID: 986 --> 1
In [202]: import datetime

In [203]: df = pd.DataFrame(
   .....:     {
   .....:         "Branch": "A A A A A A A B".split(),
   .....:         "Buyer": "Carl Mark Carl Carl Joe Joe Joe Carl".split(),
   .....:         "Quantity": [1, 3, 5, 1, 8, 1, 9, 3],
   .....:         "Date": [
   .....:             datetime.datetime(2013, 1, 1, 13, 0),
   .....:             datetime.datetime(2013, 1, 1, 13, 5),
   .....:             datetime.datetime(2013, 10, 1, 20, 0),
   .....:             datetime.datetime(2013, 10, 2, 10, 0),
   .....:             datetime.datetime(2013, 10, 1, 20, 0),
   .....:             datetime.datetime(2013, 10, 2, 10, 0),
   .....:             datetime.datetime(2013, 12, 2, 12, 0),
   .....:             datetime.datetime(2013, 12, 2, 14, 0),
   .....:         ],
   .....:     }
   .....: )
   .....: 

In [204]: df
Out[204]: 
  Branch Buyer  Quantity                Date
0      A  Carl         1 2013-01-01 13:00:00
1      A  Mark         3 2013-01-01 13:05:00
2      A  Carl         5 2013-10-01 20:00:00
3      A  Carl         1 2013-10-02 10:00:00
4      A   Joe         8 2013-10-01 20:00:00
5      A   Joe         1 2013-10-02 10:00:00
6      A   Joe         9 2013-12-02 12:00:00
7      B  Carl         3 2013-12-02 14:00:00

---->   pandas.DataFrame

--------------------------------------
ID: 987 --> 2
In [205]: df.groupby([pd.Grouper(freq="1M", key="Date"), "Buyer"])[["Quantity"]].sum()
Out[205]: 
                  Quantity
Date       Buyer          
2013-01-31 Carl          1
           Mark          3
2013-10-31 Carl          6
           Joe           9
2013-12-31 Carl          3
           Joe           9

---->   DataFrame.groupby; pandas.Grouper

--------------------------------------
ID: 988 --> 2
In [206]: df = df.set_index("Date")

In [207]: df["Date"] = df.index + pd.offsets.MonthEnd(2)

In [208]: df.groupby([pd.Grouper(freq="6M", key="Date"), "Buyer"])[["Quantity"]].sum()
Out[208]: 
                  Quantity
Date       Buyer          
2013-02-28 Carl          1
           Mark          3
2014-02-28 Carl          9
           Joe          18

In [209]: df.groupby([pd.Grouper(freq="6M", level="Date"), "Buyer"])[["Quantity"]].sum()
Out[209]: 
                  Quantity
Date       Buyer          
2013-01-31 Carl          1
           Mark          3
2014-01-31 Carl          9
           Joe          18

---->   DataFrame.groupby; pandas.Grouper

--------------------------------------
ID: 989 --> 2
In [210]: df = pd.DataFrame([[1, 2], [1, 4], [5, 6]], columns=["A", "B"])

In [211]: df
Out[211]: 
   A  B
0  1  2
1  1  4
2  5  6

In [212]: g = df.groupby("A")

In [213]: g.head(1)
Out[213]: 
   A  B
0  1  2
2  5  6

In [214]: g.tail(1)
Out[214]: 
   A  B
1  1  4
2  5  6

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 990 --> 2
In [215]: df = pd.DataFrame([[1, np.nan], [1, 4], [5, 6]], columns=["A", "B"])

In [216]: g = df.groupby("A")

In [217]: g.nth(0)
Out[217]: 
   A    B
0  1  NaN
2  5  6.0

In [218]: g.nth(-1)
Out[218]: 
   A    B
1  1  4.0
2  5  6.0

In [219]: g.nth(1)
Out[219]: 
   A    B
1  1  4.0

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 993 --> 2
In [226]: business_dates = pd.date_range(start="4/1/2014", end="6/30/2014", freq="B")

In [227]: df = pd.DataFrame(1, index=business_dates, columns=["a", "b"])

# get the first, 4th, and last date index for each month
In [228]: df.groupby([df.index.year, df.index.month]).nth([0, 3, -1])
Out[228]: 
            a  b
2014-04-01  1  1
2014-04-04  1  1
2014-04-30  1  1
2014-05-01  1  1
2014-05-06  1  1
2014-05-30  1  1
2014-06-02  1  1
2014-06-05  1  1
2014-06-30  1  1

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 994 --> 1
In [229]: df.groupby([df.index.year, df.index.month]).nth[1:]
Out[229]: 
            a  b
2014-04-02  1  1
2014-04-03  1  1
2014-04-04  1  1
2014-04-07  1  1
2014-04-08  1  1
...        .. ..
2014-06-24  1  1
2014-06-25  1  1
2014-06-26  1  1
2014-06-27  1  1
2014-06-30  1  1

[62 rows x 2 columns]

In [230]: df.groupby([df.index.year, df.index.month]).nth[1:, :-1]
Out[230]: 
            a  b
2014-04-01  1  1
2014-04-02  1  1
2014-04-03  1  1
2014-04-04  1  1
2014-04-07  1  1
...        .. ..
2014-06-24  1  1
2014-06-25  1  1
2014-06-26  1  1
2014-06-27  1  1
2014-06-30  1  1

[65 rows x 2 columns]

---->   DataFrame.groupby

--------------------------------------
ID: 995 --> 2
In [231]: dfg = pd.DataFrame(list("aaabba"), columns=["A"])

In [232]: dfg
Out[232]: 
   A
0  a
1  a
2  a
3  b
4  b
5  a

In [233]: dfg.groupby("A").cumcount()
Out[233]: 
0    0
1    1
2    2
3    0
4    1
5    3
dtype: int64

In [234]: dfg.groupby("A").cumcount(ascending=False)
Out[234]: 
0    3
1    2
2    1
3    1
4    0
5    0
dtype: int64

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 996 --> 2
In [235]: dfg = pd.DataFrame(list("aaabba"), columns=["A"])

In [236]: dfg
Out[236]: 
   A
0  a
1  a
2  a
3  b
4  b
5  a

In [237]: dfg.groupby("A").ngroup()
Out[237]: 
0    0
1    0
2    0
3    1
4    1
5    0
dtype: int64

In [238]: dfg.groupby("A").ngroup(ascending=False)
Out[238]: 
0    1
1    1
2    1
3    0
4    0
5    1
dtype: int64

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 997 --> 1
In [239]: np.random.seed(1234)

In [240]: df = pd.DataFrame(np.random.randn(50, 2))

In [241]: df["g"] = np.random.choice(["A", "B"], size=50)

In [242]: df.loc[df["g"] == "B", 1] += 3

---->   pandas.DataFrame

--------------------------------------
ID: 998 --> 1
In [243]: df.groupby("g").boxplot()
Out[243]: 
A         AxesSubplot(0.1,0.15;0.363636x0.75)
B    AxesSubplot(0.536364,0.15;0.363636x0.75)
dtype: object

---->   DataFrame.groupby

--------------------------------------
ID: 999 --> 2
In [244]: n = 1000

In [245]: df = pd.DataFrame(
   .....:     {
   .....:         "Store": np.random.choice(["Store_1", "Store_2"], n),
   .....:         "Product": np.random.choice(["Product_1", "Product_2"], n),
   .....:         "Revenue": (np.random.random(n) * 50 + 10).round(2),
   .....:         "Quantity": np.random.randint(1, 10, size=n),
   .....:     }
   .....: )
   .....: 

In [246]: df.head(2)
Out[246]: 
     Store    Product  Revenue  Quantity
0  Store_2  Product_1    26.12         1
1  Store_2  Product_1    28.86         1

---->   pandas.DataFrame; DataFrame.head

--------------------------------------
ID: 1000 --> 1
In [247]: (
   .....:     df.groupby(["Store", "Product"])
   .....:     .pipe(lambda grp: grp.Revenue.sum() / grp.Quantity.sum())
   .....:     .unstack()
   .....:     .round(2)
   .....: )
   .....: 
Out[247]: 
Product  Product_1  Product_2
Store                        
Store_1       6.82       7.05
Store_2       6.30       6.64

---->   DataFrame.groupby

--------------------------------------
ID: 1001 --> 1
In [248]: def mean(groupby):
   .....:     return groupby.mean()
   .....: 

In [249]: df.groupby(["Store", "Product"]).pipe(mean)
Out[249]: 
                     Revenue  Quantity
Store   Product                       
Store_1 Product_1  34.622727  5.075758
        Product_2  35.482815  5.029630
Store_2 Product_1  32.972837  5.237589
        Product_2  34.684360  5.224000

---->   DataFrame.groupby

--------------------------------------
ID: 1002 --> 3
In [250]: df = pd.DataFrame({"a": [1, 0, 0], "b": [0, 1, 0], "c": [1, 0, 0], "d": [2, 3, 4]})

In [251]: df
Out[251]: 
   a  b  c  d
0  1  0  1  2
1  0  1  0  3
2  0  0  0  4

In [252]: df.groupby(df.sum(), axis=1).sum()
Out[252]: 
   1  9
0  2  2
1  1  3
2  0  4

---->   pandas.DataFrame; DataFrame.groupby; DataFrame.sum

--------------------------------------
ID: 1003 --> 2
In [253]: dfg = pd.DataFrame({"A": [1, 1, 2, 3, 2], "B": list("aaaba")})

In [254]: dfg
Out[254]: 
   A  B
0  1  a
1  1  a
2  2  a
3  3  b
4  2  a

In [255]: dfg.groupby(["A", "B"]).ngroup()
Out[255]: 
0    0
1    0
2    1
3    2
4    1
dtype: int64

In [256]: dfg.groupby(["A", [0, 0, 0, 1, 1]]).ngroup()
Out[256]: 
0    0
1    0
2    1
3    3
4    2
dtype: int64

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 1004 --> 2
In [257]: df = pd.DataFrame(np.random.randn(10, 2))

In [258]: df
Out[258]: 
          0         1
0 -0.793893  0.321153
1  0.342250  1.618906
2 -0.975807  1.918201
3 -0.810847 -1.405919
4 -1.977759  0.461659
5  0.730057 -1.316938
6 -0.751328  0.528290
7 -0.257759 -1.081009
8  0.505895 -1.701948
9 -1.006349  0.020208

In [259]: df.index // 5
Out[259]: Index([0, 0, 0, 0, 0, 1, 1, 1, 1, 1], dtype='int64')

In [260]: df.groupby(df.index // 5).std()
Out[260]: 
          0         1
0  0.823647  1.312912
1  0.760109  0.942941

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 1005 --> 3
In [261]: df = pd.DataFrame(
   .....:     {
   .....:         "a": [0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2],
   .....:         "b": [0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1],
   .....:         "c": [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0],
   .....:         "d": [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1],
   .....:     }
   .....: )
   .....: 

In [262]: def compute_metrics(x):
   .....:     result = {"b_sum": x["b"].sum(), "c_mean": x["c"].mean()}
   .....:     return pd.Series(result, name="metrics")
   .....: 

In [263]: result = df.groupby("a").apply(compute_metrics)

In [264]: result
Out[264]: 
metrics  b_sum  c_mean
a                     
0          2.0     0.5
1          2.0     0.5
2          2.0     0.5

In [265]: result.stack()
Out[265]: 
a  metrics
0  b_sum      2.0
   c_mean     0.5
1  b_sum      2.0
   c_mean     0.5
2  b_sum      2.0
   c_mean     0.5
dtype: float64

---->   pandas.DataFrame; pandas.Series; DataFrame.groupby

--------------------------------------
ID: 1006 --> 1
In [3]: s = pd.Series([1, 3, 5, np.nan, 6, 8])

In [4]: s
Out[4]: 
0    1.0
1    3.0
2    5.0
3    NaN
4    6.0
5    8.0
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 1007 --> 1
In [5]: dates = pd.date_range("20130101", periods=6)

In [6]: dates
Out[6]: 
DatetimeIndex(['2013-01-01', '2013-01-02', '2013-01-03', '2013-01-04',
               '2013-01-05', '2013-01-06'],
              dtype='datetime64[ns]', freq='D')

In [7]: df = pd.DataFrame(np.random.randn(6, 4), index=dates, columns=list("ABCD"))

In [8]: df
Out[8]: 
                   A         B         C         D
2013-01-01  0.469112 -0.282863 -1.509059 -1.135632
2013-01-02  1.212112 -0.173215  0.119209 -1.044236
2013-01-03 -0.861849 -2.104569 -0.494929  1.071804
2013-01-04  0.721555 -0.706771 -1.039575  0.271860
2013-01-05 -0.424972  0.567020  0.276232 -1.087401
2013-01-06 -0.673690  0.113648 -1.478427  0.524988

---->   pandas.DataFrame

--------------------------------------
ID: 1008 --> 3
In [9]: df2 = pd.DataFrame(
   ...:     {
   ...:         "A": 1.0,
   ...:         "B": pd.Timestamp("20130102"),
   ...:         "C": pd.Series(1, index=list(range(4)), dtype="float32"),
   ...:         "D": np.array([3] * 4, dtype="int32"),
   ...:         "E": pd.Categorical(["test", "train", "test", "train"]),
   ...:         "F": "foo",
   ...:     }
   ...: )
   ...: 

In [10]: df2
Out[10]: 
     A          B    C  D      E    F
0  1.0 2013-01-02  1.0  3   test  foo
1  1.0 2013-01-02  1.0  3  train  foo
2  1.0 2013-01-02  1.0  3   test  foo
3  1.0 2013-01-02  1.0  3  train  foo

---->   pandas.DataFrame; pandas.Series; pandas.Categorical

--------------------------------------
ID: 1009 --> 2
In [13]: df.head()
Out[13]: 
                   A         B         C         D
2013-01-01  0.469112 -0.282863 -1.509059 -1.135632
2013-01-02  1.212112 -0.173215  0.119209 -1.044236
2013-01-03 -0.861849 -2.104569 -0.494929  1.071804
2013-01-04  0.721555 -0.706771 -1.039575  0.271860
2013-01-05 -0.424972  0.567020  0.276232 -1.087401

In [14]: df.tail(3)
Out[14]: 
                   A         B         C         D
2013-01-04  0.721555 -0.706771 -1.039575  0.271860
2013-01-05 -0.424972  0.567020  0.276232 -1.087401
2013-01-06 -0.673690  0.113648 -1.478427  0.524988

---->   DataFrame.head; DataFrame.tail

--------------------------------------
ID: 1013 --> 1
In [19]: df.describe()
Out[19]: 
              A         B         C         D
count  6.000000  6.000000  6.000000  6.000000
mean   0.073711 -0.431125 -0.687758 -0.233103
std    0.843157  0.922818  0.779887  0.973118
min   -0.861849 -2.104569 -1.509059 -1.135632
25%   -0.611510 -0.600794 -1.368714 -1.076610
50%    0.022070 -0.228039 -0.767252 -0.386188
75%    0.658444  0.041933 -0.034326  0.461706
max    1.212112  0.567020  0.276232  1.071804

---->   DataFrame.describe

--------------------------------------
ID: 1016 --> 1
In [41]: df2 = df.copy()

In [42]: df2["E"] = ["one", "one", "two", "three", "four", "three"]

In [43]: df2
Out[43]: 
                   A         B         C         D      E
2013-01-01  0.469112 -0.282863 -1.509059 -1.135632    one
2013-01-02  1.212112 -0.173215  0.119209 -1.044236    one
2013-01-03 -0.861849 -2.104569 -0.494929  1.071804    two
2013-01-04  0.721555 -0.706771 -1.039575  0.271860  three
2013-01-05 -0.424972  0.567020  0.276232 -1.087401   four
2013-01-06 -0.673690  0.113648 -1.478427  0.524988  three

In [44]: df2[df2["E"].isin(["two", "four"])]
Out[44]: 
                   A         B         C         D     E
2013-01-03 -0.861849 -2.104569 -0.494929  1.071804   two
2013-01-05 -0.424972  0.567020  0.276232 -1.087401  four

---->   DataFrame.copy

--------------------------------------
ID: 1017 --> 1
In [45]: s1 = pd.Series([1, 2, 3, 4, 5, 6], index=pd.date_range("20130102", periods=6))

In [46]: s1
Out[46]: 
2013-01-02    1
2013-01-03    2
2013-01-04    3
2013-01-05    4
2013-01-06    5
2013-01-07    6
Freq: D, dtype: int64

In [47]: df["F"] = s1

---->   pandas.Series

--------------------------------------
ID: 1019 --> 1
In [52]: df2 = df.copy()

In [53]: df2[df2 > 0] = -df2

In [54]: df2
Out[54]: 
                   A         B         C    D    F
2013-01-01  0.000000  0.000000 -1.509059 -5.0  NaN
2013-01-02 -1.212112 -0.173215 -0.119209 -5.0 -1.0
2013-01-03 -0.861849 -2.104569 -0.494929 -5.0 -2.0
2013-01-04 -0.721555 -0.706771 -1.039575 -5.0 -3.0
2013-01-05 -0.424972 -0.567020 -0.276232 -5.0 -4.0
2013-01-06 -0.673690 -0.113648 -1.478427 -5.0 -5.0

---->   DataFrame.copy

--------------------------------------
ID: 1023 --> 1
In [60]: pd.isna(df1)
Out[60]: 
                A      B      C      D      F      E
2013-01-01  False  False  False  False   True  False
2013-01-02  False  False  False  False  False  False
2013-01-03  False  False  False  False  False   True
2013-01-04  False  False  False  False  False   True

---->   pandas.isna

--------------------------------------
ID: 1024 --> 1
In [61]: df.mean()
Out[61]: 
A   -0.004474
B   -0.383981
C   -0.687758
D    5.000000
F    3.000000
dtype: float64

---->   DataFrame.mean

--------------------------------------
ID: 1025 --> 1
In [62]: df.mean(1)
Out[62]: 
2013-01-01    0.872735
2013-01-02    1.431621
2013-01-03    0.707731
2013-01-04    1.395042
2013-01-05    1.883656
2013-01-06    1.592306
Freq: D, dtype: float64

---->   DataFrame.mean

--------------------------------------
ID: 1026 --> 2
In [63]: s = pd.Series([1, 3, 5, np.nan, 6, 8], index=dates).shift(2)

In [64]: s
Out[64]: 
2013-01-01    NaN
2013-01-02    NaN
2013-01-03    1.0
2013-01-04    3.0
2013-01-05    5.0
2013-01-06    NaN
Freq: D, dtype: float64

In [65]: df.sub(s, axis="index")
Out[65]: 
                   A         B         C    D    F
2013-01-01       NaN       NaN       NaN  NaN  NaN
2013-01-02       NaN       NaN       NaN  NaN  NaN
2013-01-03 -1.861849 -3.104569 -1.494929  4.0  1.0
2013-01-04 -2.278445 -3.706771 -4.039575  2.0  0.0
2013-01-05 -5.424972 -4.432980 -4.723768  0.0 -1.0
2013-01-06       NaN       NaN       NaN  NaN  NaN

---->   pandas.Series; DataFrame.sub

--------------------------------------
ID: 1027 --> 2
In [66]: df.apply(np.cumsum)
Out[66]: 
                   A         B         C     D     F
2013-01-01  0.000000  0.000000 -1.509059   5.0   NaN
2013-01-02  1.212112 -0.173215 -1.389850  10.0   1.0
2013-01-03  0.350263 -2.277784 -1.884779  15.0   3.0
2013-01-04  1.071818 -2.984555 -2.924354  20.0   6.0
2013-01-05  0.646846 -2.417535 -2.648122  25.0  10.0
2013-01-06 -0.026844 -2.303886 -4.126549  30.0  15.0

In [67]: df.apply(lambda x: x.max() - x.min())
Out[67]: 
A    2.073961
B    2.671590
C    1.785291
D    0.000000
F    4.000000
dtype: float64

---->   DataFrame.max; DataFrame.min

--------------------------------------
ID: 1028 --> 2
In [68]: s = pd.Series(np.random.randint(0, 7, size=10))

In [69]: s
Out[69]: 
0    4
1    2
2    1
3    2
4    6
5    4
6    4
7    6
8    4
9    4
dtype: int64

In [70]: s.value_counts()
Out[70]: 
4    5
2    2
6    2
1    1
Name: count, dtype: int64

---->   pandas.Series; Series.value_counts

--------------------------------------
ID: 1029 --> 1
In [71]: s = pd.Series(["A", "B", "C", "Aaba", "Baca", np.nan, "CABA", "dog", "cat"])

In [72]: s.str.lower()
Out[72]: 
0       a
1       b
2       c
3    aaba
4    baca
5     NaN
6    caba
7     dog
8     cat
dtype: object

---->   pandas.Series

--------------------------------------
ID: 1030 --> 1
In [73]: df = pd.DataFrame(np.random.randn(10, 4))

In [74]: df
Out[74]: 
          0         1         2         3
0 -0.548702  1.467327 -1.015962 -0.483075
1  1.637550 -1.217659 -0.291519 -1.745505
2 -0.263952  0.991460 -0.919069  0.266046
3 -0.709661  1.669052  1.037882 -1.705775
4 -0.919854 -0.042379  1.247642 -0.009920
5  0.290213  0.495767  0.362949  1.548106
6 -1.131345 -0.089329  0.337863 -0.945867
7 -0.932132  1.956030  0.017587 -0.016692
8 -0.575247  0.254161 -1.143704  0.215897
9  1.193555 -0.077118 -0.408530 -0.862495

# break it into pieces
In [75]: pieces = [df[:3], df[3:7], df[7:]]

In [76]: pd.concat(pieces)
Out[76]: 
          0         1         2         3
0 -0.548702  1.467327 -1.015962 -0.483075
1  1.637550 -1.217659 -0.291519 -1.745505
2 -0.263952  0.991460 -0.919069  0.266046
3 -0.709661  1.669052  1.037882 -1.705775
4 -0.919854 -0.042379  1.247642 -0.009920
5  0.290213  0.495767  0.362949  1.548106
6 -1.131345 -0.089329  0.337863 -0.945867
7 -0.932132  1.956030  0.017587 -0.016692
8 -0.575247  0.254161 -1.143704  0.215897
9  1.193555 -0.077118 -0.408530 -0.862495

---->   pandas.DataFrame

--------------------------------------
ID: 1031 --> 1
In [77]: left = pd.DataFrame({"key": ["foo", "foo"], "lval": [1, 2]})

In [78]: right = pd.DataFrame({"key": ["foo", "foo"], "rval": [4, 5]})

In [79]: left
Out[79]: 
   key  lval
0  foo     1
1  foo     2

In [80]: right
Out[80]: 
   key  rval
0  foo     4
1  foo     5

In [81]: pd.merge(left, right, on="key")
Out[81]: 
   key  lval  rval
0  foo     1     4
1  foo     1     5
2  foo     2     4
3  foo     2     5

---->   pandas.DataFrame

--------------------------------------
ID: 1032 --> 1
In [82]: left = pd.DataFrame({"key": ["foo", "bar"], "lval": [1, 2]})

In [83]: right = pd.DataFrame({"key": ["foo", "bar"], "rval": [4, 5]})

In [84]: left
Out[84]: 
   key  lval
0  foo     1
1  bar     2

In [85]: right
Out[85]: 
   key  rval
0  foo     4
1  bar     5

In [86]: pd.merge(left, right, on="key")
Out[86]: 
   key  lval  rval
0  foo     1     4
1  bar     2     5

---->   pandas.DataFrame

--------------------------------------
ID: 1033 --> 1
In [87]: df = pd.DataFrame(
   ....:     {
   ....:         "A": ["foo", "bar", "foo", "bar", "foo", "bar", "foo", "foo"],
   ....:         "B": ["one", "one", "two", "three", "two", "two", "one", "three"],
   ....:         "C": np.random.randn(8),
   ....:         "D": np.random.randn(8),
   ....:     }
   ....: )
   ....: 

In [88]: df
Out[88]: 
     A      B         C         D
0  foo    one  1.346061 -1.577585
1  bar    one  1.511763  0.396823
2  foo    two  1.627081 -0.105381
3  bar  three -0.990582 -0.532532
4  foo    two -0.441652  1.453749
5  bar    two  1.211526  1.208843
6  foo    one  0.268520 -0.080952
7  foo  three  0.024580 -0.264610

---->   pandas.DataFrame

--------------------------------------
ID: 1034 --> 1
In [89]: df.groupby("A")[["C", "D"]].sum()
Out[89]: 
            C         D
A                      
bar  1.732707  1.073134
foo  2.824590 -0.574779

---->   DataFrame.groupby

--------------------------------------
ID: 1035 --> 1
In [90]: df.groupby(["A", "B"]).sum()
Out[90]: 
                  C         D
A   B                        
bar one    1.511763  0.396823
    three -0.990582 -0.532532
    two    1.211526  1.208843
foo one    1.614581 -1.658537
    three  0.024580 -0.264610
    two    1.185429  1.348368

---->   DataFrame.groupby

--------------------------------------
ID: 1036 --> 2
In [91]: tuples = list(
   ....:     zip(
   ....:         ["bar", "bar", "baz", "baz", "foo", "foo", "qux", "qux"],
   ....:         ["one", "two", "one", "two", "one", "two", "one", "two"],
   ....:     )
   ....: )
   ....: 

In [92]: index = pd.MultiIndex.from_tuples(tuples, names=["first", "second"])

In [93]: df = pd.DataFrame(np.random.randn(8, 2), index=index, columns=["A", "B"])

In [94]: df2 = df[:4]

In [95]: df2
Out[95]: 
                     A         B
first second                    
bar   one    -0.727965 -0.589346
      two     0.339969 -0.693205
baz   one    -0.339355  0.593616
      two     0.884345  1.591431

---->   pandas.MultiIndex; pandas.DataFrame

--------------------------------------
ID: 1037 --> 1
In [96]: stacked = df2.stack()

In [97]: stacked
Out[97]: 
first  second   
bar    one     A   -0.727965
               B   -0.589346
       two     A    0.339969
               B   -0.693205
baz    one     A   -0.339355
               B    0.593616
       two     A    0.884345
               B    1.591431
dtype: float64

---->   DataFrame.stack

--------------------------------------
ID: 1039 --> 1
In [101]: df = pd.DataFrame(
   .....:     {
   .....:         "A": ["one", "one", "two", "three"] * 3,
   .....:         "B": ["A", "B", "C"] * 4,
   .....:         "C": ["foo", "foo", "foo", "bar", "bar", "bar"] * 2,
   .....:         "D": np.random.randn(12),
   .....:         "E": np.random.randn(12),
   .....:     }
   .....: )
   .....: 

In [102]: df
Out[102]: 
        A  B    C         D         E
0     one  A  foo -1.202872  0.047609
1     one  B  foo -1.814470 -0.136473
2     two  C  foo  1.018601 -0.561757
3   three  A  bar -0.595447 -1.623033
4     one  B  bar  1.395433  0.029399
5     one  C  bar -0.392670 -0.542108
6     two  A  foo  0.007207  0.282696
7   three  B  foo  1.928123 -0.087302
8     one  C  foo -0.055224 -1.575170
9     one  A  bar  2.395985  1.771208
10    two  B  bar  1.552825  0.816482
11  three  C  bar  0.166599  1.100230

---->   pandas.DataFrame

--------------------------------------
ID: 1040 --> 1
In [103]: pd.pivot_table(df, values="D", index=["A", "B"], columns=["C"])
Out[103]: 
C             bar       foo
A     B                    
one   A  2.395985 -1.202872
      B  1.395433 -1.814470
      C -0.392670 -0.055224
three A -0.595447       NaN
      B       NaN  1.928123
      C  0.166599       NaN
two   A       NaN  0.007207
      B  1.552825       NaN
      C       NaN  1.018601

---->   pandas.pivot_table

--------------------------------------
ID: 1041 --> 2
In [104]: rng = pd.date_range("1/1/2012", periods=100, freq="S")

In [105]: ts = pd.Series(np.random.randint(0, 500, len(rng)), index=rng)

In [106]: ts.resample("5Min").sum()
Out[106]: 
2012-01-01    24182
Freq: 5T, dtype: int64

---->   pandas.Series; Series.resample

--------------------------------------
ID: 1042 --> 2
In [107]: rng = pd.date_range("3/6/2012 00:00", periods=5, freq="D")

In [108]: ts = pd.Series(np.random.randn(len(rng)), rng)

In [109]: ts
Out[109]: 
2012-03-06    1.857704
2012-03-07   -1.193545
2012-03-08    0.677510
2012-03-09   -0.153931
2012-03-10    0.520091
Freq: D, dtype: float64

In [110]: ts_utc = ts.tz_localize("UTC")

In [111]: ts_utc
Out[111]: 
2012-03-06 00:00:00+00:00    1.857704
2012-03-07 00:00:00+00:00   -1.193545
2012-03-08 00:00:00+00:00    0.677510
2012-03-09 00:00:00+00:00   -0.153931
2012-03-10 00:00:00+00:00    0.520091
Freq: D, dtype: float64

---->   pandas.Series; Series.tz_localize

--------------------------------------
ID: 1044 --> 2
In [113]: rng = pd.date_range("1/1/2012", periods=5, freq="M")

In [114]: ts = pd.Series(np.random.randn(len(rng)), index=rng)

In [115]: ts
Out[115]: 
2012-01-31   -1.475051
2012-02-29    0.722570
2012-03-31   -0.322646
2012-04-30   -1.601631
2012-05-31    0.778033
Freq: M, dtype: float64

In [116]: ps = ts.to_period()

In [117]: ps
Out[117]: 
2012-01   -1.475051
2012-02    0.722570
2012-03   -0.322646
2012-04   -1.601631
2012-05    0.778033
Freq: M, dtype: float64

In [118]: ps.to_timestamp()
Out[118]: 
2012-01-01   -1.475051
2012-02-01    0.722570
2012-03-01   -0.322646
2012-04-01   -1.601631
2012-05-01    0.778033
Freq: MS, dtype: float64

---->   pandas.Series; Series.to_period

--------------------------------------
ID: 1045 --> 3
In [119]: prng = pd.period_range("1990Q1", "2000Q4", freq="Q-NOV")

In [120]: ts = pd.Series(np.random.randn(len(prng)), prng)

In [121]: ts.index = (prng.asfreq("M", "e") + 1).asfreq("H", "s") + 9

In [122]: ts.head()
Out[122]: 
1990-03-01 09:00   -0.289342
1990-06-01 09:00    0.233141
1990-09-01 09:00   -0.223540
1990-12-01 09:00    0.542054
1991-03-01 09:00   -0.688585
Freq: H, dtype: float64

---->   pandas.period_range; pandas.Series; Series.head

--------------------------------------
ID: 1046 --> 1
In [123]: df = pd.DataFrame(
   .....:     {"id": [1, 2, 3, 4, 5, 6], "raw_grade": ["a", "b", "b", "a", "a", "e"]}
   .....: )
   .....: 

---->   pandas.DataFrame

--------------------------------------
ID: 1051 --> 1
In [131]: df.groupby("grade").size()
Out[131]: 
grade
very bad     1
bad          0
medium       0
good         2
very good    3
dtype: int64

---->   DataFrame.groupby

--------------------------------------
ID: 1053 --> 3
In [134]: ts = pd.Series(np.random.randn(1000), index=pd.date_range("1/1/2000", periods=1000))

In [135]: ts = ts.cumsum()

In [136]: ts.plot();

---->   pandas.Series; Series.cumsum; Series.plot

--------------------------------------
ID: 1055 --> 3
In [138]: df = pd.DataFrame(
   .....:     np.random.randn(1000, 4), index=ts.index, columns=["A", "B", "C", "D"]
   .....: )
   .....: 

In [139]: df = df.cumsum()

In [140]: plt.figure();

In [141]: df.plot();

In [142]: plt.legend(loc='best');

---->   pandas.DataFrame; DataFrame.cumsum; DataFrame.plot

--------------------------------------
ID: 1056 --> 1
In [143]: df.to_csv("foo.csv")

---->   DataFrame.to_csv

--------------------------------------
ID: 1058 --> 1
In [145]: df.to_hdf("foo.h5", "df")

---->   DataFrame.to_hdf

--------------------------------------
ID: 1059 --> 1
In [146]: pd.read_hdf("foo.h5", "df")
Out[146]: 
                    A          B          C          D
2000-01-01   0.350262   0.843315   1.798556   0.782234
2000-01-02  -0.586873   0.034907   1.923792  -0.562651
2000-01-03  -1.245477  -0.963406   2.269575  -1.612566
2000-01-04  -0.252830  -0.498066   3.176886  -1.275581
2000-01-05  -1.044057   0.118042   2.768571   0.386039
...               ...        ...        ...        ...
2002-09-22 -48.017654  31.474551  69.146374 -47.541670
2002-09-23 -47.207912  32.627390  68.505254 -48.828331
2002-09-24 -48.907133  31.990402  67.310924 -49.391051
2002-09-25 -50.146062  33.716770  67.717434 -49.037577
2002-09-26 -49.724318  33.479952  68.108014 -48.822030

[1000 rows x 4 columns]

---->   pandas.read_hdf

--------------------------------------
ID: 1060 --> 1
In [147]: df.to_excel("foo.xlsx", sheet_name="Sheet1")

---->   DataFrame.to_excel

--------------------------------------
ID: 1062 --> 4
In [149]: if pd.Series([False, True, False]):
   .....:      print("I was true")
   .....: 
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
 in ?()
----> 1 if pd.Series([False, True, False]):
      2      print("I was true")

~/work/pandas/pandas/pandas/core/generic.py in ?(self)
   1464     @final
   1465     def __nonzero__(self) -> NoReturn:
-> 1466         raise ValueError(
   1467             f"The truth value of a {type(self).__name__} is ambiguous. "
   1468             "Use a.empty, a.bool(), a.item(), a.any() or a.all()."
   1469         )

ValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().

---->   pandas.Series; Index.item; Index.any; Index.all

--------------------------------------
ID: 1063 --> 3
In [1]: ser = pd.Series([-1.5, 0.2, None], dtype="float32[pyarrow]")

In [2]: ser
Out[2]: 
0    -1.5
1     0.2
2    
dtype: float[pyarrow]

In [3]: idx = pd.Index([True, None], dtype="bool[pyarrow]")

In [4]: idx
Out[4]: Index([True, ], dtype='bool[pyarrow]')

In [5]: df = pd.DataFrame([[1, 2], [3, 4]], dtype="uint64[pyarrow]")

In [6]: df
Out[6]: 
   0  1
0  1  2
1  3  4

---->   pandas.Series; pandas.Index; pandas.DataFrame

--------------------------------------
ID: 1064 --> 2
In [7]: import pyarrow as pa

In [8]: data = list("abc")

In [9]: ser_sd = pd.Series(data, dtype="string[pyarrow]")

In [10]: ser_ad = pd.Series(data, dtype=pd.ArrowDtype(pa.string()))

In [11]: ser_ad.dtype == ser_sd.dtype
Out[11]: False

In [12]: ser_sd.str.contains("a")
Out[12]: 
0     True
1    False
2    False
dtype: boolean

In [13]: ser_ad.str.contains("a")
Out[13]: 
0     True
1    False
2    False
dtype: bool[pyarrow]

---->   pandas.Series; pandas.ArrowDtype

--------------------------------------
ID: 1065 --> 2
In [14]: import pyarrow as pa

In [15]: list_str_type = pa.list_(pa.string())

In [16]: ser = pd.Series([["hello"], ["there"]], dtype=pd.ArrowDtype(list_str_type))

In [17]: ser
Out[17]: 
0    ['hello']
1    ['there']
dtype: list[pyarrow]

---->   pandas.Series; pandas.ArrowDtype

--------------------------------------
ID: 1066 --> 2
In [18]: from datetime import time

In [19]: idx = pd.Index([time(12, 30), None], dtype=pd.ArrowDtype(pa.time64("us")))

In [20]: idx
Out[20]: Index([12:30:00, ], dtype='time64[us][pyarrow]')

---->   pandas.Index; pandas.ArrowDtype

--------------------------------------
ID: 1067 --> 2
In [21]: from decimal import Decimal

In [22]: decimal_type = pd.ArrowDtype(pa.decimal128(3, scale=2))

In [23]: data = [[Decimal("3.19"), None], [None, Decimal("-1.23")]]

In [24]: df = pd.DataFrame(data, dtype=decimal_type)

In [25]: df
Out[25]: 
      0      1
0  3.19   
1    -1.23

---->   pandas.ArrowDtype; pandas.DataFrame

--------------------------------------
ID: 1068 --> 1
In [26]: pa_array = pa.array(
   ....:     [{"1": "2"}, {"10": "20"}, None],
   ....:     type=pa.map_(pa.string(), pa.string()),
   ....: )
   ....: 

In [27]: ser = pd.Series(pd.arrays.ArrowExtensionArray(pa_array))

In [28]: ser
Out[28]: 
0      [('1', '2')]
1    [('10', '20')]
2              
dtype: map[pyarrow]

---->   pandas.Series

--------------------------------------
ID: 1069 --> 2
In [29]: ser = pd.Series([1, 2, None], dtype="uint8[pyarrow]")

In [30]: pa.array(ser)
Out[30]: 

[
  1,
  2,
  null
]

In [31]: idx = pd.Index(ser)

In [32]: pa.array(idx)
Out[32]: 

[
  1,
  2,
  null
]

---->   pandas.Series; pandas.Index

--------------------------------------
ID: 1071 --> 3
In [37]: import pyarrow as pa

In [38]: ser = pd.Series([-1.545, 0.211, None], dtype="float32[pyarrow]")

In [39]: ser.mean()
Out[39]: -0.6669999808073044

In [40]: ser + ser
Out[40]: 
0    -3.09
1    0.422
2     
dtype: float[pyarrow]

In [41]: ser > (ser + 1)
Out[41]: 
0    False
1    False
2     
dtype: bool[pyarrow]

In [42]: ser.dropna()
Out[42]: 
0   -1.545
1    0.211
dtype: float[pyarrow]

In [43]: ser.isna()
Out[43]: 
0    False
1    False
2     True
dtype: bool

In [44]: ser.fillna(0)
Out[44]: 
0   -1.545
1    0.211
2    0.000
dtype: float[pyarrow]

---->   pandas.Series; Series.mean; Series.isna

--------------------------------------
ID: 1072 --> 2
In [45]: ser_str = pd.Series(["a", "b", None], dtype=pd.ArrowDtype(pa.string()))

In [46]: ser_str.str.startswith("a")
Out[46]: 
0     True
1    False
2     
dtype: bool[pyarrow]

---->   pandas.Series; pandas.ArrowDtype

--------------------------------------
ID: 1073 --> 2
In [47]: from datetime import datetime

In [48]: pa_type = pd.ArrowDtype(pa.timestamp("ns"))

In [49]: ser_dt = pd.Series([datetime(2022, 1, 1), None], dtype=pa_type)

In [50]: ser_dt.dt.strftime("%Y-%m")
Out[50]: 
0    2022-01
1       
dtype: string[pyarrow]

---->   pandas.ArrowDtype; pandas.Series

--------------------------------------
ID: 1076 --> 2
In [1]: dtypes = [
   ...:     "int64",
   ...:     "float64",
   ...:     "datetime64[ns]",
   ...:     "timedelta64[ns]",
   ...:     "complex128",
   ...:     "object",
   ...:     "bool",
   ...: ]
   ...: 

In [2]: n = 5000

In [3]: data = {t: np.random.randint(100, size=n).astype(t) for t in dtypes}

In [4]: df = pd.DataFrame(data)

In [5]: df["categorical"] = df["object"].astype("category")

In [6]: df.info()

RangeIndex: 5000 entries, 0 to 4999
Data columns (total 8 columns):
 #   Column           Non-Null Count  Dtype          
---  ------           --------------  -----          
 0   int64            5000 non-null   int64          
 1   float64          5000 non-null   float64        
 2   datetime64[ns]   5000 non-null   datetime64[ns] 
 3   timedelta64[ns]  5000 non-null   timedelta64[ns]
 4   complex128       5000 non-null   complex128     
 5   object           5000 non-null   object         
 6   bool             5000 non-null   bool           
 7   categorical      5000 non-null   category       
dtypes: bool(1), category(1), complex128(1), datetime64[ns](1), float64(1), int64(1), object(1), timedelta64[ns](1)
memory usage: 288.2+ KB

---->   pandas.DataFrame; DataFrame.info

--------------------------------------
ID: 1077 --> 1
In [7]: df.info(memory_usage="deep")

RangeIndex: 5000 entries, 0 to 4999
Data columns (total 8 columns):
 #   Column           Non-Null Count  Dtype          
---  ------           --------------  -----          
 0   int64            5000 non-null   int64          
 1   float64          5000 non-null   float64        
 2   datetime64[ns]   5000 non-null   datetime64[ns] 
 3   timedelta64[ns]  5000 non-null   timedelta64[ns]
 4   complex128       5000 non-null   complex128     
 5   object           5000 non-null   object         
 6   bool             5000 non-null   bool           
 7   categorical      5000 non-null   category       
dtypes: bool(1), category(1), complex128(1), datetime64[ns](1), float64(1), int64(1), object(1), timedelta64[ns](1)
memory usage: 424.7 KB

---->   DataFrame.info

--------------------------------------
ID: 1078 --> 1
In [8]: df.memory_usage()
Out[8]: 
Index                128
int64              40000
float64            40000
datetime64[ns]     40000
timedelta64[ns]    40000
complex128         80000
object             40000
bool                5000
categorical         9968
dtype: int64

# total memory usage of dataframe
In [9]: df.memory_usage().sum()
Out[9]: 295096

---->   DataFrame.memory_usage

--------------------------------------
ID: 1079 --> 1
In [10]: df.memory_usage(index=False)
Out[10]: 
int64              40000
float64            40000
datetime64[ns]     40000
timedelta64[ns]    40000
complex128         80000
object             40000
bool                5000
categorical         9968
dtype: int64

---->   DataFrame.memory_usage

--------------------------------------
ID: 1080 --> 1
>>> if pd.Series([False, True, False]):
...     pass

---->   pandas.Series

--------------------------------------
ID: 1081 --> 4
In [11]: if pd.Series([False, True, False]):
   ....:     print("I was true")
   ....: 
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
 in ?()
----> 1 if pd.Series([False, True, False]):
      2     print("I was true")

~/work/pandas/pandas/pandas/core/generic.py in ?(self)
   1464     @final
   1465     def __nonzero__(self) -> NoReturn:
-> 1466         raise ValueError(
   1467             f"The truth value of a {type(self).__name__} is ambiguous. "
   1468             "Use a.empty, a.bool(), a.item(), a.any() or a.all()."
   1469         )

ValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().

---->   pandas.Series; Index.item; Index.any; Index.all

--------------------------------------
ID: 1082 --> 1
In [12]: if pd.Series([False, True, False]) is not None:
   ....:     print("I was not None")
   ....: 
I was not None

---->   pandas.Series

--------------------------------------
ID: 1083 --> 1
In [13]: if pd.Series([False, True, False]).any():
   ....:     print("I am any")
   ....: 
I am any

---->   pandas.Series

--------------------------------------
ID: 1084 --> 2
In [14]: pd.Series([True]).bool()
Out[14]: True

In [15]: pd.Series([False]).bool()
Out[15]: False

In [16]: pd.DataFrame([[True]]).bool()
Out[16]: True

In [17]: pd.DataFrame([[False]]).bool()
Out[17]: False

---->   pandas.Series; pandas.DataFrame

--------------------------------------
ID: 1085 --> 1
In [18]: s = pd.Series(range(5))

In [19]: s == 4
Out[19]: 
0    False
1    False
2    False
3    False
4     True
dtype: bool

---->   pandas.Series

--------------------------------------
ID: 1086 --> 1
In [20]: s = pd.Series(range(5), index=list("abcde"))

In [21]: 2 in s
Out[21]: False

In [22]: 'b' in s
Out[22]: True

---->   pandas.Series

--------------------------------------
ID: 1087 --> 1
In [23]: s.isin([2])
Out[23]: 
a    False
b    False
c     True
d    False
e    False
dtype: bool

In [24]: s.isin([2]).any()
Out[24]: True

---->   Series.isin

--------------------------------------
ID: 1089 --> 2
In [29]: def f(s):
   ....:     s.pop("a")
   ....:     return s
   ....: 

In [30]: df = pd.DataFrame({"a": [1, 2, 3], "b": [4, 5, 6]})

In [31]: try:
   ....:     df.apply(f, axis="columns")
   ....: except Exception as err:
   ....:     print(repr(err))
   ....: 
KeyError('a')

---->   Series.pop; pandas.DataFrame

--------------------------------------
ID: 1091 --> 3
In [36]: def f(s):
   ....:     s = s.copy()
   ....:     s.pop("a")
   ....:     return s
   ....: 

In [37]: df = pd.DataFrame({"a": [1, 2, 3], 'b': [4, 5, 6]})

In [38]: df.apply(f, axis="columns")
Out[38]: 
   b
0  4
1  5
2  6

---->   Series.copy; Series.pop; pandas.DataFrame

--------------------------------------
ID: 1092 --> 1
In [39]: s = pd.Series([1, 2, 3, 4, 5], index=list("abcde"))

In [40]: s
Out[40]: 
a    1
b    2
c    3
d    4
e    5
dtype: int64

In [41]: s.dtype
Out[41]: dtype('int64')

In [42]: s2 = s.reindex(["a", "b", "c", "f", "u"])

In [43]: s2
Out[43]: 
a    1.0
b    2.0
c    3.0
f    NaN
u    NaN
dtype: float64

In [44]: s2.dtype
Out[44]: dtype('float64')

---->   pandas.Series

--------------------------------------
ID: 1093 --> 2
In [45]: s_int = pd.Series([1, 2, 3, 4, 5], index=list("abcde"), dtype=pd.Int64Dtype())

In [46]: s_int
Out[46]: 
a    1
b    2
c    3
d    4
e    5
dtype: Int64

In [47]: s_int.dtype
Out[47]: Int64Dtype()

In [48]: s2_int = s_int.reindex(["a", "b", "c", "f", "u"])

In [49]: s2_int
Out[49]: 
a       1
b       2
c       3
f    
u    
dtype: Int64

In [50]: s2_int.dtype
Out[50]: Int64Dtype()

---->   pandas.Series; pandas.Int64Dtype

--------------------------------------
ID: 1094 --> 1
In [51]: x = np.array(list(range(10)), ">i4")  # big endian

In [52]: newx = x.byteswap().newbyteorder()  # force native byteorder

In [53]: s = pd.Series(newx)

---->   pandas.Series

--------------------------------------
ID: 1095 --> 1
In [1]: pd.Series(["a", "b", "c"])
Out[1]: 
0    a
1    b
2    c
dtype: object

---->   pandas.Series

--------------------------------------
ID: 1096 --> 2
In [2]: pd.Series(["a", "b", "c"], dtype="string")
Out[2]: 
0    a
1    b
2    c
dtype: string

In [3]: pd.Series(["a", "b", "c"], dtype=pd.StringDtype())
Out[3]: 
0    a
1    b
2    c
dtype: string

---->   pandas.Series; pandas.StringDtype

--------------------------------------
ID: 1097 --> 2
In [4]: s = pd.Series(["a", "b", "c"])

In [5]: s
Out[5]: 
0    a
1    b
2    c
dtype: object

In [6]: s.astype("string")
Out[6]: 
0    a
1    b
2    c
dtype: string

---->   pandas.Series; Series.astype

--------------------------------------
ID: 1098 --> 1
In [7]: s = pd.Series(["a", 2, np.nan], dtype="string")

In [8]: s
Out[8]: 
0       a
1       2
2    
dtype: string

In [9]: type(s[1])
Out[9]: str

---->   pandas.Series

--------------------------------------
ID: 1099 --> 2
In [10]: s1 = pd.Series([1, 2, np.nan], dtype="Int64")

In [11]: s1
Out[11]: 
0       1
1       2
2    
dtype: Int64

In [12]: s2 = s1.astype("string")

In [13]: s2
Out[13]: 
0       1
1       2
2    
dtype: string

In [14]: type(s2[0])
Out[14]: str

---->   pandas.Series; Series.astype

--------------------------------------
ID: 1100 --> 1
In [15]: s = pd.Series(["a", None, "b"], dtype="string")

In [16]: s
Out[16]: 
0       a
1    
2       b
dtype: string

In [17]: s.str.count("a")
Out[17]: 
0       1
1    
2       0
dtype: Int64

In [18]: s.dropna().str.count("a")
Out[18]: 
0    1
2    0
dtype: Int64

---->   pandas.Series

--------------------------------------
ID: 1101 --> 1
In [19]: s2 = pd.Series(["a", None, "b"], dtype="object")

In [20]: s2.str.count("a")
Out[20]: 
0    1.0
1    NaN
2    0.0
dtype: float64

In [21]: s2.dropna().str.count("a")
Out[21]: 
0    1
2    0
dtype: int64

---->   pandas.Series

--------------------------------------
ID: 1103 --> 1
In [24]: s = pd.Series(
   ....:     ["A", "B", "C", "Aaba", "Baca", np.nan, "CABA", "dog", "cat"], dtype="string"
   ....: )
   ....: 

In [25]: s.str.lower()
Out[25]: 
0       a
1       b
2       c
3    aaba
4    baca
5    
6    caba
7     dog
8     cat
dtype: string

In [26]: s.str.upper()
Out[26]: 
0       A
1       B
2       C
3    AABA
4    BACA
5    
6    CABA
7     DOG
8     CAT
dtype: string

In [27]: s.str.len()
Out[27]: 
0       1
1       1
2       1
3       4
4       4
5    
6       4
7       3
8       3
dtype: Int64

---->   pandas.Series

--------------------------------------
ID: 1104 --> 1
In [28]: idx = pd.Index([" jack", "jill ", " jesse ", "frank"])

In [29]: idx.str.strip()
Out[29]: Index(['jack', 'jill', 'jesse', 'frank'], dtype='object')

In [30]: idx.str.lstrip()
Out[30]: Index(['jack', 'jill ', 'jesse ', 'frank'], dtype='object')

In [31]: idx.str.rstrip()
Out[31]: Index([' jack', 'jill', ' jesse', 'frank'], dtype='object')

---->   pandas.Index

--------------------------------------
ID: 1105 --> 1
In [32]: df = pd.DataFrame(
   ....:     np.random.randn(3, 2), columns=[" Column A ", " Column B "], index=range(3)
   ....: )
   ....: 

In [33]: df
Out[33]: 
    Column A    Column B 
0    0.469112   -0.282863
1   -1.509059   -1.135632
2    1.212112   -0.173215

---->   pandas.DataFrame

--------------------------------------
ID: 1108 --> 1
In [38]: s2 = pd.Series(["a_b_c", "c_d_e", np.nan, "f_g_h"], dtype="string")

In [39]: s2.str.split("_")
Out[39]: 
0    [a, b, c]
1    [c, d, e]
2         
3    [f, g, h]
dtype: object

---->   pandas.Series

--------------------------------------
ID: 1113 --> 1
In [45]: s3 = pd.Series(
   ....:     ["A", "B", "C", "Aaba", "Baca", "", np.nan, "CABA", "dog", "cat"],
   ....:     dtype="string",
   ....: )
   ....: 

In [46]: s3
Out[46]: 
0       A
1       B
2       C
3    Aaba
4    Baca
5        
6    
7    CABA
8     dog
9     cat
dtype: string

In [47]: s3.str.replace("^.a|dog", "XX-XX ", case=False, regex=True)
Out[47]: 
0           A
1           B
2           C
3    XX-XX ba
4    XX-XX ca
5            
6        
7    XX-XX BA
8      XX-XX 
9     XX-XX t
dtype: string

---->   pandas.Series

--------------------------------------
ID: 1114 --> 1
In [48]: s4 = pd.Series(["a.b", ".", "b", np.nan, ""], dtype="string")

In [49]: s4
Out[49]: 
0     a.b
1       .
2       b
3    
4        
dtype: string

In [50]: s4.str.replace(".", "a", regex=True)
Out[50]: 
0     aaa
1       a
2       a
3    
4        
dtype: string

---->   pandas.Series

--------------------------------------
ID: 1115 --> 1
In [51]: dollars = pd.Series(["12", "-$10", "$10,000"], dtype="string")

# These lines are equivalent
In [52]: dollars.str.replace(r"-\$", "-", regex=True)
Out[52]: 
0         12
1        -10
2    $10,000
dtype: string

In [53]: dollars.str.replace("-$", "-", regex=False)
Out[53]: 
0         12
1        -10
2    $10,000
dtype: string

---->   pandas.Series

--------------------------------------
ID: 1116 --> 1
# Reverse every lowercase alphabetic word
In [54]: pat = r"[a-z]+"

In [55]: def repl(m):
   ....:     return m.group(0)[::-1]
   ....: 

In [56]: pd.Series(["foo 123", "bar baz", np.nan], dtype="string").str.replace(
   ....:     pat, repl, regex=True
   ....: )
   ....: 
Out[56]: 
0    oof 123
1    rab zab
2       
dtype: string

# Using regex groups
In [57]: pat = r"(?P\w+) (?P\w+) (?P\w+)"

In [58]: def repl(m):
   ....:     return m.group("two").swapcase()
   ....: 

In [59]: pd.Series(["Foo Bar Baz", np.nan], dtype="string").str.replace(
   ....:     pat, repl, regex=True
   ....: )
   ....: 
Out[59]: 
0     bAR
1    
dtype: string

---->   pandas.Series

--------------------------------------
ID: 1119 --> 1
In [64]: s = pd.Series(["str_foo", "str_bar", "no_prefix"])

In [65]: s.str.removeprefix("str_")
Out[65]: 
0          foo
1          bar
2    no_prefix
dtype: object

In [66]: s = pd.Series(["foo_str", "bar_str", "no_suffix"])

In [67]: s.str.removesuffix("_str")
Out[67]: 
0          foo
1          bar
2    no_suffix
dtype: object

---->   pandas.Series

--------------------------------------
ID: 1120 --> 1
In [68]: s = pd.Series(["a", "b", "c", "d"], dtype="string")

In [69]: s.str.cat(sep=",")
Out[69]: 'a,b,c,d'

---->   pandas.Series

--------------------------------------
ID: 1122 --> 1
In [71]: t = pd.Series(["a", "b", np.nan, "d"], dtype="string")

In [72]: t.str.cat(sep=",")
Out[72]: 'a,b,d'

In [73]: t.str.cat(sep=",", na_rep="-")
Out[73]: 'a,b,-,d'

---->   pandas.Series

--------------------------------------
ID: 1126 --> 1
In [81]: u = pd.Series(["b", "d", "a", "c"], index=[1, 3, 0, 2], dtype="string")

In [82]: s
Out[82]: 
0    a
1    b
2    c
3    d
dtype: string

In [83]: u
Out[83]: 
1    b
3    d
0    a
2    c
dtype: string

In [84]: s.str.cat(u)
Out[84]: 
0    aa
1    bb
2    cc
3    dd
dtype: string

In [85]: s.str.cat(u, join="left")
Out[85]: 
0    aa
1    bb
2    cc
3    dd
dtype: string

---->   pandas.Series

--------------------------------------
ID: 1127 --> 1
In [86]: v = pd.Series(["z", "a", "b", "d", "e"], index=[-1, 0, 1, 3, 4], dtype="string")

In [87]: s
Out[87]: 
0    a
1    b
2    c
3    d
dtype: string

In [88]: v
Out[88]: 
-1    z
 0    a
 1    b
 3    d
 4    e
dtype: string

In [89]: s.str.cat(v, join="left", na_rep="-")
Out[89]: 
0    aa
1    bb
2    c-
3    dd
dtype: string

In [90]: s.str.cat(v, join="outer", na_rep="-")
Out[90]: 
-1    -z
 0    aa
 1    bb
 2    c-
 3    dd
 4    -e
dtype: string

---->   pandas.Series

--------------------------------------
ID: 1129 --> 1
In [95]: s
Out[95]: 
0    a
1    b
2    c
3    d
dtype: string

In [96]: u
Out[96]: 
1    b
3    d
0    a
2    c
dtype: string

In [97]: s.str.cat([u, u.to_numpy()], join="left")
Out[97]: 
0    aab
1    bbd
2    cca
3    ddc
dtype: string

---->   Series.to_numpy

--------------------------------------
ID: 1130 --> 1
In [98]: v
Out[98]: 
-1    z
 0    a
 1    b
 3    d
 4    e
dtype: string

In [99]: s.str.cat([v, u, u.to_numpy()], join="outer", na_rep="-")
Out[99]: 
-1    -z--
0     aaab
1     bbbd
2     c-ca
3     dddc
4     -e--
dtype: string

---->   Series.to_numpy

--------------------------------------
ID: 1132 --> 1
In [103]: s = pd.Series(
   .....:     ["A", "B", "C", "Aaba", "Baca", np.nan, "CABA", "dog", "cat"], dtype="string"
   .....: )
   .....: 

In [104]: s.str[0]
Out[104]: 
0       A
1       B
2       C
3       A
4       B
5    
6       C
7       d
8       c
dtype: string

In [105]: s.str[1]
Out[105]: 
0    
1    
2    
3       a
4       a
5    
6       A
7       o
8       a
dtype: string

---->   pandas.Series

--------------------------------------
ID: 1133 --> 1
In [106]: pd.Series(
   .....:     ["a1", "b2", "c3"],
   .....:     dtype="string",
   .....: ).str.extract(r"([ab])(\d)", expand=False)
   .....: 
Out[106]: 
      0     1
0     a     1
1     b     2
2    

---->   pandas.Series

--------------------------------------
ID: 1134 --> 1
In [107]: pd.Series(["a1", "b2", "c3"], dtype="string").str.extract(
   .....:     r"(?P[ab])(?P\d)", expand=False
   .....: )
   .....: 
Out[107]: 
  letter digit
0      a     1
1      b     2
2     

---->   pandas.Series

--------------------------------------
ID: 1135 --> 1
In [108]: pd.Series(
   .....:     ["a1", "b2", "3"],
   .....:     dtype="string",
   .....: ).str.extract(r"([ab])?(\d)", expand=False)
   .....: 
Out[108]: 
      0  1
0     a  1
1     b  2
2    3

---->   pandas.Series

--------------------------------------
ID: 1136 --> 1
In [109]: pd.Series(["a1", "b2", "c3"], dtype="string").str.extract(r"[ab](\d)", expand=True)
Out[109]: 
      0
0     1
1     2
2  

---->   pandas.Series

--------------------------------------
ID: 1137 --> 1
In [110]: pd.Series(["a1", "b2", "c3"], dtype="string").str.extract(r"[ab](\d)", expand=False)
Out[110]: 
0       1
1       2
2    
dtype: string

---->   pandas.Series

--------------------------------------
ID: 1138 --> 1
In [111]: s = pd.Series(["a1", "b2", "c3"], ["A11", "B22", "C33"], dtype="string")

In [112]: s
Out[112]: 
A11    a1
B22    b2
C33    c3
dtype: string

In [113]: s.index.str.extract("(?P[a-zA-Z])", expand=True)
Out[113]: 
  letter
0      A
1      B
2      C

---->   pandas.Series

--------------------------------------
ID: 1142 --> 1
In [116]: s = pd.Series(["a1a2", "b1", "c1"], index=["A", "B", "C"], dtype="string")

In [117]: s
Out[117]: 
A    a1a2
B      b1
C      c1
dtype: string

In [118]: two_groups = "(?P[a-z])(?P[0-9])"

In [119]: s.str.extract(two_groups, expand=True)
Out[119]: 
  letter digit
A      a     1
B      b     1
C      c     1

---->   pandas.Series

--------------------------------------
ID: 1144 --> 1
In [121]: s = pd.Series(["a3", "b3", "c2"], dtype="string")

In [122]: s
Out[122]: 
0    a3
1    b3
2    c2
dtype: string

---->   pandas.Series

--------------------------------------
ID: 1146 --> 2
In [128]: pd.Index(["a1a2", "b1", "c1"]).str.extractall(two_groups)
Out[128]: 
        letter digit
  match             
0 0          a     1
  1          a     2
1 0          b     1
2 0          c     1

In [129]: pd.Series(["a1a2", "b1", "c1"], dtype="string").str.extractall(two_groups)
Out[129]: 
        letter digit
  match             
0 0          a     1
  1          a     2
1 0          b     1
2 0          c     1

---->   pandas.Index; pandas.Series

--------------------------------------
ID: 1147 --> 1
In [130]: pattern = r"[0-9][a-z]"

In [131]: pd.Series(
   .....:     ["1", "2", "3a", "3b", "03c", "4dx"],
   .....:     dtype="string",
   .....: ).str.contains(pattern)
   .....: 
Out[131]: 
0    False
1    False
2     True
3     True
4     True
5     True
dtype: boolean

---->   pandas.Series

--------------------------------------
ID: 1148 --> 1
In [132]: pd.Series(
   .....:     ["1", "2", "3a", "3b", "03c", "4dx"],
   .....:     dtype="string",
   .....: ).str.match(pattern)
   .....: 
Out[132]: 
0    False
1    False
2     True
3     True
4    False
5     True
dtype: boolean

---->   pandas.Series

--------------------------------------
ID: 1149 --> 1
In [133]: pd.Series(
   .....:     ["1", "2", "3a", "3b", "03c", "4dx"],
   .....:     dtype="string",
   .....: ).str.fullmatch(pattern)
   .....: 
Out[133]: 
0    False
1    False
2     True
3     True
4    False
5    False
dtype: boolean

---->   pandas.Series

--------------------------------------
ID: 1150 --> 1
In [134]: s4 = pd.Series(
   .....:     ["A", "B", "C", "Aaba", "Baca", np.nan, "CABA", "dog", "cat"], dtype="string"
   .....: )
   .....: 

In [135]: s4.str.contains("A", na=False)
Out[135]: 
0     True
1    False
2    False
3     True
4    False
5    False
6     True
7    False
8    False
dtype: boolean

---->   pandas.Series

--------------------------------------
ID: 1151 --> 1
In [136]: s = pd.Series(["a", "a|b", np.nan, "a|c"], dtype="string")

In [137]: s.str.get_dummies(sep="|")
Out[137]: 
   a  b  c
0  1  0  0
1  1  1  0
2  0  0  0
3  1  0  1

---->   pandas.Series

--------------------------------------
ID: 1152 --> 1
In [138]: idx = pd.Index(["a", "a|b", np.nan, "a|c"])

In [139]: idx.str.get_dummies(sep="|")
Out[139]: 
MultiIndex([(1, 0, 0),
            (1, 1, 0),
            (0, 0, 0),
            (1, 0, 1)],
           names=['a', 'b', 'c'])

---->   pandas.Index

--------------------------------------
ID: 1155 --> 1
In [11]: pd.describe_option()
compute.use_bottleneck : bool
    Use the bottleneck library to accelerate if it is installed,
    the default is True
    Valid values: False,True
    [default: True] [currently: True]
compute.use_numba : bool
    Use the numba engine option for select operations if it is installed,
    the default is False
    Valid values: False,True
    [default: False] [currently: False]
compute.use_numexpr : bool
    Use the numexpr library to accelerate computation if it is installed,
    the default is True
    Valid values: False,True
    [default: True] [currently: True]
display.chop_threshold : float or None
    if set to a float value, all float values smaller than the given threshold
    will be displayed as exactly 0 by repr and friends.
    [default: None] [currently: None]
display.colheader_justify : 'left'/'right'
    Controls the justification of column headers. used by DataFrameFormatter.
    [default: right] [currently: right]
display.date_dayfirst : boolean
    When True, prints and parses dates with the day first, eg 20/01/2005
    [default: False] [currently: False]
display.date_yearfirst : boolean
    When True, prints and parses dates with the year first, eg 2005/01/20
    [default: False] [currently: False]
display.encoding : str/unicode
    Defaults to the detected encoding of the console.
    Specifies the encoding to be used for strings returned by to_string,
    these are generally strings meant to be displayed on the console.
    [default: utf-8] [currently: utf8]
display.expand_frame_repr : boolean
    Whether to print out the full DataFrame repr for wide DataFrames across
    multiple lines, `max_columns` is still respected, but the output will
    wrap-around across multiple "pages" if its width exceeds `display.width`.
    [default: True] [currently: True]
display.float_format : callable
    The callable should accept a floating point number and return
    a string with the desired format of the number. This is used
    in some places like SeriesFormatter.
    See formats.format.EngFormatter for an example.
    [default: None] [currently: None]
display.html.border : int
    A ``border=value`` attribute is inserted in the ```` tag
    for the DataFrame HTML repr.
    [default: 1] [currently: 1]
display.html.table_schema : boolean
    Whether to publish a Table Schema representation for frontends
    that support it.
    (default: False)
    [default: False] [currently: False]
display.html.use_mathjax : boolean
    When True, Jupyter notebook will process table contents using MathJax,
    rendering mathematical expressions enclosed by the dollar symbol.
    (default: True)
    [default: True] [currently: True]
display.large_repr : 'truncate'/'info'
    For DataFrames exceeding max_rows/max_cols, the repr (and HTML repr) can
    show a truncated table (the default from 0.13), or switch to the view from
    df.info() (the behaviour in earlier versions of pandas).
    [default: truncate] [currently: truncate]
display.max_categories : int
    This sets the maximum number of categories pandas should output when
    printing out a `Categorical` or a Series of dtype "category".
    [default: 8] [currently: 8]
display.max_columns : int
    If max_cols is exceeded, switch to truncate view. Depending on
    `large_repr`, objects are either centrally truncated or printed as
    a summary view. 'None' value means unlimited.

    In case python/IPython is running in a terminal and `large_repr`
    equals 'truncate' this can be set to 0 or None and pandas will auto-detect
    the width of the terminal and print a truncated object which fits
    the screen width. The IPython notebook, IPython qtconsole, or IDLE
    do not run in a terminal and hence it is not possible to do
    correct auto-detection and defaults to 20.
    [default: 0] [currently: 0]
display.max_colwidth : int or None
    The maximum width in characters of a column in the repr of
    a pandas data structure. When the column overflows, a "..."
    placeholder is embedded in the output. A 'None' value means unlimited.
    [default: 50] [currently: 50]
display.max_dir_items : int
    The number of items that will be added to `dir(...)`. 'None' value means
    unlimited. Because dir is cached, changing this option will not immediately
    affect already existing dataframes until a column is deleted or added.

    This is for instance used to suggest columns from a dataframe to tab
    completion.
    [default: 100] [currently: 100]
display.max_info_columns : int
    max_info_columns is used in DataFrame.info method to decide if
    per column information will be printed.
    [default: 100] [currently: 100]
display.max_info_rows : int or None
    df.info() will usually show null-counts for each column.
    For large frames this can be quite slow. max_info_rows and max_info_cols
    limit this null check only to frames with smaller dimensions than
    specified.
    [default: 1690785] [currently: 1690785]
display.max_rows : int
    If max_rows is exceeded, switch to truncate view. Depending on
    `large_repr`, objects are either centrally truncated or printed as
    a summary view. 'None' value means unlimited.

    In case python/IPython is running in a terminal and `large_repr`
    equals 'truncate' this can be set to 0 and pandas will auto-detect
    the height of the terminal and print a truncated object which fits
    the screen height. The IPython notebook, IPython qtconsole, or
    IDLE do not run in a terminal and hence it is not possible to do
    correct auto-detection.
    [default: 60] [currently: 60]
display.max_seq_items : int or None
    When pretty-printing a long sequence, no more then `max_seq_items`
    will be printed. If items are omitted, they will be denoted by the
    addition of "..." to the resulting string.

    If set to None, the number of items to be printed is unlimited.
    [default: 100] [currently: 100]
display.memory_usage : bool, string or None
    This specifies if the memory usage of a DataFrame should be displayed when
    df.info() is called. Valid values True,False,'deep'
    [default: True] [currently: True]
display.min_rows : int
    The numbers of rows to show in a truncated view (when `max_rows` is
    exceeded). Ignored when `max_rows` is set to None or 0. When set to
    None, follows the value of `max_rows`.
    [default: 10] [currently: 10]
display.multi_sparse : boolean
    "sparsify" MultiIndex display (don't display repeated
    elements in outer levels within groups)
    [default: True] [currently: True]
display.notebook_repr_html : boolean
    When True, IPython notebook will use html representation for
    pandas objects (if it is available).
    [default: True] [currently: True]
display.pprint_nest_depth : int
    Controls the number of nested levels to process when pretty-printing
    [default: 3] [currently: 3]
display.precision : int
    Floating point output precision in terms of number of places after the
    decimal, for regular formatting as well as scientific notation. Similar
    to ``precision`` in :meth:`numpy.set_printoptions`.
    [default: 6] [currently: 6]
display.show_dimensions : boolean or 'truncate'
    Whether to print out dimensions at the end of DataFrame repr.
    If 'truncate' is specified, only print out the dimensions if the
    frame is truncated (e.g. not display all rows and/or columns)
    [default: truncate] [currently: truncate]
display.unicode.ambiguous_as_wide : boolean
    Whether to use the Unicode East Asian Width to calculate the display text
    width.
    Enabling this may affect to the performance (default: False)
    [default: False] [currently: False]
display.unicode.east_asian_width : boolean
    Whether to use the Unicode East Asian Width to calculate the display text
    width.
    Enabling this may affect to the performance (default: False)
    [default: False] [currently: False]
display.width : int
    Width of the display in characters. In case python/IPython is running in
    a terminal this can be set to None and pandas will correctly auto-detect
    the width.
    Note that the IPython notebook, IPython qtconsole, or IDLE do not run in a
    terminal and hence it is not possible to correctly detect the width.
    [default: 80] [currently: 80]
io.excel.ods.reader : string
    The default Excel reader engine for 'ods' files. Available options:
    auto, odf.
    [default: auto] [currently: auto]
io.excel.ods.writer : string
    The default Excel writer engine for 'ods' files. Available options:
    auto, odf.
    [default: auto] [currently: auto]
io.excel.xls.reader : string
    The default Excel reader engine for 'xls' files. Available options:
    auto, xlrd.
    [default: auto] [currently: auto]
io.excel.xlsb.reader : string
    The default Excel reader engine for 'xlsb' files. Available options:
    auto, pyxlsb.
    [default: auto] [currently: auto]
io.excel.xlsm.reader : string
    The default Excel reader engine for 'xlsm' files. Available options:
    auto, xlrd, openpyxl.
    [default: auto] [currently: auto]
io.excel.xlsm.writer : string
    The default Excel writer engine for 'xlsm' files. Available options:
    auto, openpyxl.
    [default: auto] [currently: auto]
io.excel.xlsx.reader : string
    The default Excel reader engine for 'xlsx' files. Available options:
    auto, xlrd, openpyxl.
    [default: auto] [currently: auto]
io.excel.xlsx.writer : string
    The default Excel writer engine for 'xlsx' files. Available options:
    auto, openpyxl, xlsxwriter.
    [default: auto] [currently: auto]
io.hdf.default_format : format
    default format writing format, if None, then
    put will default to 'fixed' and append will default to 'table'
    [default: None] [currently: None]
io.hdf.dropna_table : boolean
    drop ALL nan rows when appending to a table
    [default: False] [currently: False]
io.parquet.engine : string
    The default parquet reader/writer engine. Available options:
    'auto', 'pyarrow', 'fastparquet', the default is 'auto'
    [default: auto] [currently: auto]
io.sql.engine : string
    The default sql reader/writer engine. Available options:
    'auto', 'sqlalchemy', the default is 'auto'
    [default: auto] [currently: auto]
mode.chained_assignment : string
    Raise an exception, warn, or no action if trying to use chained assignment,
    The default is warn
    [default: warn] [currently: warn]
mode.copy_on_write : bool
    Use new copy-view behaviour using Copy-on-Write. Defaults to False,
    unless overridden by the 'PANDAS_COPY_ON_WRITE' environment variable
    (if set to "1" for True, needs to be set before pandas is imported).
    [default: False] [currently: False]
mode.data_manager : string
    Internal data manager type; can be "block" or "array". Defaults to "block",
    unless overridden by the 'PANDAS_DATA_MANAGER' environment variable (needs
    to be set before pandas is imported).
    [default: block] [currently: block]
mode.sim_interactive : boolean
    Whether to simulate interactive mode for purposes of testing
    [default: False] [currently: False]
mode.string_storage : string
    The default storage for StringDtype.
    [default: python] [currently: python]
mode.use_inf_as_na : boolean
    True means treat None, NaN, INF, -INF as NA (old way),
    False means None and NaN are null, but INF, -INF are not NA
    (new way).
    [default: False] [currently: False]
plotting.backend : str
    The plotting backend to use. The default value is "matplotlib", the
    backend provided with pandas. Other backends can be specified by
    providing the name of the module that implements the backend.
    [default: matplotlib] [currently: matplotlib]
plotting.matplotlib.register_converters : bool or 'auto'.
    Whether to register converters with matplotlib's units registry for
    dates, times, datetimes, and Periods. Toggling to False will remove
    the converters, restoring any converters that pandas overwrote.
    [default: auto] [currently: auto]
styler.format.decimal : str
    The character representation for the decimal separator for floats and complex.
    [default: .] [currently: .]
styler.format.escape : str, optional
    Whether to escape certain characters according to the given context; html or latex.
    [default: None] [currently: None]
styler.format.formatter : str, callable, dict, optional
    A formatter object to be used as default within ``Styler.format``.
    [default: None] [currently: None]
styler.format.na_rep : str, optional
    The string representation for values identified as missing.
    [default: None] [currently: None]
styler.format.precision : int
    The precision for floats and complex numbers.
    [default: 6] [currently: 6]
styler.format.thousands : str, optional
    The character representation for thousands separator for floats, int and complex.
    [default: None] [currently: None]
styler.html.mathjax : bool
    If False will render special CSS classes to table attributes that indicate Mathjax
    will not be used in Jupyter Notebook.
    [default: True] [currently: True]
styler.latex.environment : str
    The environment to replace ``\begin{table}``. If "longtable" is used results
    in a specific longtable environment format.
    [default: None] [currently: None]
styler.latex.hrules : bool
    Whether to add horizontal rules on top and bottom and below the headers.
    [default: False] [currently: False]
styler.latex.multicol_align : {"r", "c", "l", "naive-l", "naive-r"}
    The specifier for horizontal alignment of sparsified LaTeX multicolumns. Pipe
    decorators can also be added to non-naive values to draw vertical
    rules, e.g. "\|r" will draw a rule on the left side of right aligned merged cells.
    [default: r] [currently: r]
styler.latex.multirow_align : {"c", "t", "b"}
    The specifier for vertical alignment of sparsified LaTeX multirows.
    [default: c] [currently: c]
styler.render.encoding : str
    The encoding used for output HTML and LaTeX files.
    [default: utf-8] [currently: utf-8]
styler.render.max_columns : int, optional
    The maximum number of columns that will be rendered. May still be reduced to
    satsify ``max_elements``, which takes precedence.
    [default: None] [currently: None]
styler.render.max_elements : int
    The maximum number of data-cell () elements that will be rendered before
    trimming will occur over columns, rows or both if needed.
    [default: 262144] [currently: 262144]
styler.render.max_rows : int, optional
    The maximum number of rows that will be rendered. May still be reduced to
    satsify ``max_elements``, which takes precedence.
    [default: None] [currently: None]
styler.render.repr : str
    Determine which output to use in Jupyter Notebook in {"html", "latex"}.
    [default: html] [currently: html]
styler.sparse.columns : bool
    Whether to sparsify the display of hierarchical columns. Setting to False will
    display each explicit level element in a hierarchical key for each column.
    [default: True] [currently: True]
styler.sparse.index : bool
    Whether to sparsify the display of a hierarchical index. Setting to False will
    display each explicit level element in a hierarchical key for each row.
    [default: True] [currently: True]

---->   DataFrame.info

--------------------------------------
ID: 1161 --> 1
In [24]: df = pd.DataFrame(np.random.randn(7, 2))

In [25]: pd.set_option("display.max_rows", 7)

In [26]: df
Out[26]: 
          0         1
0  0.469112 -0.282863
1 -1.509059 -1.135632
2  1.212112 -0.173215
3  0.119209 -1.044236
4 -0.861849 -2.104569
5 -0.494929  1.071804
6  0.721555 -0.706771

In [27]: pd.set_option("display.max_rows", 5)

In [28]: df
Out[28]: 
           0         1
0   0.469112 -0.282863
1  -1.509059 -1.135632
..       ...       ...
5  -0.494929  1.071804
6   0.721555 -0.706771

[7 rows x 2 columns]

In [29]: pd.reset_option("display.max_rows")

---->   pandas.DataFrame

--------------------------------------
ID: 1162 --> 1
In [30]: pd.set_option("display.max_rows", 8)

In [31]: pd.set_option("display.min_rows", 4)

# below max_rows -> all rows shown
In [32]: df = pd.DataFrame(np.random.randn(7, 2))

In [33]: df
Out[33]: 
          0         1
0 -1.039575  0.271860
1 -0.424972  0.567020
2  0.276232 -1.087401
3 -0.673690  0.113648
4 -1.478427  0.524988
5  0.404705  0.577046
6 -1.715002 -1.039268

# above max_rows -> only min_rows (4) rows shown
In [34]: df = pd.DataFrame(np.random.randn(9, 2))

In [35]: df
Out[35]: 
           0         1
0  -0.370647 -1.157892
1  -1.344312  0.844885
..       ...       ...
7   0.276662 -0.472035
8  -0.013960 -0.362543

[9 rows x 2 columns]

In [36]: pd.reset_option("display.max_rows")

In [37]: pd.reset_option("display.min_rows")

---->   pandas.DataFrame

--------------------------------------
ID: 1163 --> 1
In [38]: df = pd.DataFrame(np.random.randn(5, 10))

In [39]: pd.set_option("expand_frame_repr", True)

In [40]: df
Out[40]: 
          0         1         2  ...         7         8         9
0 -0.006154 -0.923061  0.895717  ...  1.340309 -1.170299 -0.226169
1  0.410835  0.813850  0.132003  ... -1.436737 -1.413681  1.607920
2  1.024180  0.569605  0.875906  ... -0.078638  0.545952 -1.219217
3 -1.226825  0.769804 -1.281247  ...  0.341734  0.959726 -1.110336
4 -0.619976  0.149748 -0.732339  ...  0.301624 -2.179861 -1.369849

[5 rows x 10 columns]

In [41]: pd.set_option("expand_frame_repr", False)

In [42]: df
Out[42]: 
          0         1         2         3         4         5         6         7         8         9
0 -0.006154 -0.923061  0.895717  0.805244 -1.206412  2.565646  1.431256  1.340309 -1.170299 -0.226169
1  0.410835  0.813850  0.132003 -0.827317 -0.076467 -1.187678  1.130127 -1.436737 -1.413681  1.607920
2  1.024180  0.569605  0.875906 -2.211372  0.974466 -2.006747 -0.410001 -0.078638  0.545952 -1.219217
3 -1.226825  0.769804 -1.281247 -0.727707 -0.121306 -0.097883  0.695775  0.341734  0.959726 -1.110336
4 -0.619976  0.149748 -0.732339  0.687738  0.176444  0.403310 -0.154951  0.301624 -2.179861 -1.369849

In [43]: pd.reset_option("expand_frame_repr")

---->   pandas.DataFrame

--------------------------------------
ID: 1164 --> 1
In [44]: df = pd.DataFrame(np.random.randn(10, 10))

In [45]: pd.set_option("display.max_rows", 5)

In [46]: pd.set_option("large_repr", "truncate")

In [47]: df
Out[47]: 
           0         1         2  ...         7         8         9
0  -0.954208  1.462696 -1.743161  ...  0.995761  2.396780  0.014871
1   3.357427 -0.317441 -1.236269  ...  0.380396  0.084844  0.432390
..       ...       ...       ...  ...       ...       ...       ...
8  -0.303421 -0.858447  0.306996  ...  0.476720  0.473424 -0.242861
9  -0.014805 -0.284319  0.650776  ...  1.613616  0.464000  0.227371

[10 rows x 10 columns]

In [48]: pd.set_option("large_repr", "info")

In [49]: df
Out[49]: 

RangeIndex: 10 entries, 0 to 9
Data columns (total 10 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       10 non-null     float64
 1   1       10 non-null     float64
 2   2       10 non-null     float64
 3   3       10 non-null     float64
 4   4       10 non-null     float64
 5   5       10 non-null     float64
 6   6       10 non-null     float64
 7   7       10 non-null     float64
 8   8       10 non-null     float64
 9   9       10 non-null     float64
dtypes: float64(10)
memory usage: 928.0 bytes

In [50]: pd.reset_option("large_repr")

In [51]: pd.reset_option("display.max_rows")

---->   pandas.DataFrame

--------------------------------------
ID: 1165 --> 1
In [52]: df = pd.DataFrame(
   ....:     np.array(
   ....:         [
   ....:             ["foo", "bar", "bim", "uncomfortably long string"],
   ....:             ["horse", "cow", "banana", "apple"],
   ....:         ]
   ....:     )
   ....: )
   ....: 

In [53]: pd.set_option("max_colwidth", 40)

In [54]: df
Out[54]: 
       0    1       2                          3
0    foo  bar     bim  uncomfortably long string
1  horse  cow  banana                      apple

In [55]: pd.set_option("max_colwidth", 6)

In [56]: df
Out[56]: 
       0    1      2      3
0    foo  bar    bim  un...
1  horse  cow  ba...  apple

In [57]: pd.reset_option("max_colwidth")

---->   pandas.DataFrame

--------------------------------------
ID: 1166 --> 2
In [58]: df = pd.DataFrame(np.random.randn(10, 10))

In [59]: pd.set_option("max_info_columns", 11)

In [60]: df.info()

RangeIndex: 10 entries, 0 to 9
Data columns (total 10 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       10 non-null     float64
 1   1       10 non-null     float64
 2   2       10 non-null     float64
 3   3       10 non-null     float64
 4   4       10 non-null     float64
 5   5       10 non-null     float64
 6   6       10 non-null     float64
 7   7       10 non-null     float64
 8   8       10 non-null     float64
 9   9       10 non-null     float64
dtypes: float64(10)
memory usage: 928.0 bytes

In [61]: pd.set_option("max_info_columns", 5)

In [62]: df.info()

RangeIndex: 10 entries, 0 to 9
Columns: 10 entries, 0 to 9
dtypes: float64(10)
memory usage: 928.0 bytes

In [63]: pd.reset_option("max_info_columns")

---->   pandas.DataFrame; DataFrame.info

--------------------------------------
ID: 1167 --> 2
In [64]: df = pd.DataFrame(np.random.choice([0, 1, np.nan], size=(10, 10)))

In [65]: df
Out[65]: 
     0    1    2    3    4    5    6    7    8    9
0  0.0  NaN  1.0  NaN  NaN  0.0  NaN  0.0  NaN  1.0
1  1.0  NaN  1.0  1.0  1.0  1.0  NaN  0.0  0.0  NaN
2  0.0  NaN  1.0  0.0  0.0  NaN  NaN  NaN  NaN  0.0
3  NaN  NaN  NaN  0.0  1.0  1.0  NaN  1.0  NaN  1.0
4  0.0  NaN  NaN  NaN  0.0  NaN  NaN  NaN  1.0  0.0
5  0.0  1.0  1.0  1.0  1.0  0.0  NaN  NaN  1.0  0.0
6  1.0  1.0  1.0  NaN  1.0  NaN  1.0  0.0  NaN  NaN
7  0.0  0.0  1.0  0.0  1.0  0.0  1.0  1.0  0.0  NaN
8  NaN  NaN  NaN  0.0  NaN  NaN  NaN  NaN  1.0  NaN
9  0.0  NaN  0.0  NaN  NaN  0.0  NaN  1.0  1.0  0.0

In [66]: pd.set_option("max_info_rows", 11)

In [67]: df.info()

RangeIndex: 10 entries, 0 to 9
Data columns (total 10 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       8 non-null      float64
 1   1       3 non-null      float64
 2   2       7 non-null      float64
 3   3       6 non-null      float64
 4   4       7 non-null      float64
 5   5       6 non-null      float64
 6   6       2 non-null      float64
 7   7       6 non-null      float64
 8   8       6 non-null      float64
 9   9       6 non-null      float64
dtypes: float64(10)
memory usage: 928.0 bytes

In [68]: pd.set_option("max_info_rows", 5)

In [69]: df.info()

RangeIndex: 10 entries, 0 to 9
Data columns (total 10 columns):
 #   Column  Dtype  
---  ------  -----  
 0   0       float64
 1   1       float64
 2   2       float64
 3   3       float64
 4   4       float64
 5   5       float64
 6   6       float64
 7   7       float64
 8   8       float64
 9   9       float64
dtypes: float64(10)
memory usage: 928.0 bytes

In [70]: pd.reset_option("max_info_rows")

---->   pandas.DataFrame; DataFrame.info

--------------------------------------
ID: 1168 --> 1
In [71]: df = pd.DataFrame(np.random.randn(5, 5))

In [72]: pd.set_option("display.precision", 7)

In [73]: df
Out[73]: 
           0          1          2          3          4
0 -1.1506406 -0.7983341 -0.5576966  0.3813531  1.3371217
1 -1.5310949  1.3314582 -0.5713290 -0.0266708 -1.0856630
2 -1.1147378 -0.0582158 -0.4867681  1.6851483  0.1125723
3 -1.4953086  0.8984347 -0.1482168 -1.5960698  0.1596530
4  0.2621358  0.0362196  0.1847350 -0.2550694 -0.2710197

In [74]: pd.set_option("display.precision", 4)

In [75]: df
Out[75]: 
        0       1       2       3       4
0 -1.1506 -0.7983 -0.5577  0.3814  1.3371
1 -1.5311  1.3315 -0.5713 -0.0267 -1.0857
2 -1.1147 -0.0582 -0.4868  1.6851  0.1126
3 -1.4953  0.8984 -0.1482 -1.5961  0.1597
4  0.2621  0.0362  0.1847 -0.2551 -0.2710

---->   pandas.DataFrame

--------------------------------------
ID: 1169 --> 1
In [76]: df = pd.DataFrame(np.random.randn(6, 6))

In [77]: pd.set_option("chop_threshold", 0)

In [78]: df
Out[78]: 
        0       1       2       3       4       5
0  1.2884  0.2946 -1.1658  0.8470 -0.6856  0.6091
1 -0.3040  0.6256 -0.0593  0.2497  1.1039 -1.0875
2  1.9980 -0.2445  0.1362  0.8863 -1.3507 -0.8863
3 -1.0133  1.9209 -0.3882 -2.3144  0.6655  0.4026
4  0.3996 -1.7660  0.8504  0.3881  0.9923  0.7441
5 -0.7398 -1.0549 -0.1796  0.6396  1.5850  1.9067

In [79]: pd.set_option("chop_threshold", 0.5)

In [80]: df
Out[80]: 
        0       1       2       3       4       5
0  1.2884  0.0000 -1.1658  0.8470 -0.6856  0.6091
1  0.0000  0.6256  0.0000  0.0000  1.1039 -1.0875
2  1.9980  0.0000  0.0000  0.8863 -1.3507 -0.8863
3 -1.0133  1.9209  0.0000 -2.3144  0.6655  0.0000
4  0.0000 -1.7660  0.8504  0.0000  0.9923  0.7441
5 -0.7398 -1.0549  0.0000  0.6396  1.5850  1.9067

In [81]: pd.reset_option("chop_threshold")

---->   pandas.DataFrame

--------------------------------------
ID: 1170 --> 1
In [82]: df = pd.DataFrame(
   ....:     np.array([np.random.randn(6), np.random.randint(1, 9, 6) * 0.1, np.zeros(6)]).T,
   ....:     columns=["A", "B", "C"],
   ....:     dtype="float",
   ....: )
   ....: 

In [83]: pd.set_option("colheader_justify", "right")

In [84]: df
Out[84]: 
        A    B    C
0  0.1040  0.1  0.0
1  0.1741  0.5  0.0
2 -0.4395  0.4  0.0
3 -0.7413  0.8  0.0
4 -0.0797  0.4  0.0
5 -0.9229  0.3  0.0

In [85]: pd.set_option("colheader_justify", "left")

In [86]: df
Out[86]: 
   A       B    C  
0  0.1040  0.1  0.0
1  0.1741  0.5  0.0
2 -0.4395  0.4  0.0
3 -0.7413  0.8  0.0
4 -0.0797  0.4  0.0
5 -0.9229  0.3  0.0

In [87]: pd.reset_option("colheader_justify")

---->   pandas.DataFrame

--------------------------------------
ID: 1171 --> 2
In [88]: import numpy as np

In [89]: pd.set_eng_float_format(accuracy=3, use_eng_prefix=True)

In [90]: s = pd.Series(np.random.randn(5), index=["a", "b", "c", "d", "e"])

In [91]: s / 1.0e3
Out[91]: 
a    303.638u
b   -721.084u
c   -622.696u
d    648.250u
e     -1.945m
dtype: float64

In [92]: s / 1.0e6
Out[92]: 
a    303.638n
b   -721.084n
c   -622.696n
d    648.250n
e     -1.945u
dtype: float64

---->   pandas.set_eng_float_format; pandas.Series

--------------------------------------
ID: 1172 --> 1
In [93]: df = pd.DataFrame({"国籍": ["UK", "日本"], "名前": ["Alice", "しのぶ"]})

In [94]: df
Out[94]: 
   国籍     名前
0  UK  Alice
1  日本    しのぶ

---->   pandas.DataFrame

--------------------------------------
ID: 1174 --> 1
In [97]: df = pd.DataFrame({"a": ["xxx", "¡¡"], "b": ["yyy", "¡¡"]})

In [98]: df
Out[98]: 
     a    b
0  xxx  yyy
1   ¡¡   ¡¡

---->   pandas.DataFrame

--------------------------------------
ID: 1177 --> 1
In [1]: import pandas._testing as tm

In [2]: def unpivot(frame):
   ...:     N, K = frame.shape
   ...:     data = {
   ...:         "value": frame.to_numpy().ravel("F"),
   ...:         "variable": np.asarray(frame.columns).repeat(N),
   ...:         "date": np.tile(np.asarray(frame.index), K),
   ...:     }
   ...:     return pd.DataFrame(data, columns=["date", "variable", "value"])
   ...: 

In [3]: df = unpivot(tm.makeTimeDataFrame(3))

In [4]: df
Out[4]: 
         date variable     value
0  2000-01-03        A  0.469112
1  2000-01-04        A -0.282863
2  2000-01-05        A -1.509059
3  2000-01-03        B -1.135632
4  2000-01-04        B  1.212112
5  2000-01-05        B -0.173215
6  2000-01-03        C  0.119209
7  2000-01-04        C -1.044236
8  2000-01-05        C -0.861849
9  2000-01-03        D -2.104569
10 2000-01-04        D -0.494929
11 2000-01-05        D  1.071804

---->   pandas.DataFrame

--------------------------------------
ID: 1180 --> 2
In [13]: tuples = list(
   ....:     zip(
   ....:         *[
   ....:             ["bar", "bar", "baz", "baz", "foo", "foo", "qux", "qux"],
   ....:             ["one", "two", "one", "two", "one", "two", "one", "two"],
   ....:         ]
   ....:     )
   ....: )
   ....: 

In [14]: index = pd.MultiIndex.from_tuples(tuples, names=["first", "second"])

In [15]: df = pd.DataFrame(np.random.randn(8, 2), index=index, columns=["A", "B"])

In [16]: df2 = df[:4]

In [17]: df2
Out[17]: 
                     A         B
first second                    
bar   one     0.721555 -0.706771
      two    -1.039575  0.271860
baz   one    -0.424972  0.567020
      two     0.276232 -1.087401

---->   pandas.MultiIndex; pandas.DataFrame

--------------------------------------
ID: 1181 --> 1
In [18]: stacked = df2.stack()

In [19]: stacked
Out[19]: 
first  second   
bar    one     A    0.721555
               B   -0.706771
       two     A   -1.039575
               B    0.271860
baz    one     A   -0.424972
               B    0.567020
       two     A    0.276232
               B   -1.087401
dtype: float64

---->   DataFrame.stack

--------------------------------------
ID: 1184 --> 3
In [24]: index = pd.MultiIndex.from_product([[2, 1], ["a", "b"]])

In [25]: df = pd.DataFrame(np.random.randn(4), index=index, columns=["A"])

In [26]: df
Out[26]: 
            A
2 a -0.370647
  b -1.157892
1 a -1.344312
  b  0.844885

In [27]: all(df.unstack().stack() == df.sort_index())
Out[27]: True

---->   pandas.MultiIndex; pandas.DataFrame; DataFrame.unstack

--------------------------------------
ID: 1185 --> 3
In [28]: columns = pd.MultiIndex.from_tuples(
   ....:     [
   ....:         ("A", "cat", "long"),
   ....:         ("B", "cat", "long"),
   ....:         ("A", "dog", "short"),
   ....:         ("B", "dog", "short"),
   ....:     ],
   ....:     names=["exp", "animal", "hair_length"],
   ....: )
   ....: 

In [29]: df = pd.DataFrame(np.random.randn(4, 4), columns=columns)

In [30]: df
Out[30]: 
exp                 A         B         A         B
animal            cat       cat       dog       dog
hair_length      long      long     short     short
0            1.075770 -0.109050  1.643563 -1.469388
1            0.357021 -0.674600 -1.776904 -0.968914
2           -1.294524  0.413738  0.276662 -0.472035
3           -0.013960 -0.362543 -0.006154 -0.923061

In [31]: df.stack(level=["animal", "hair_length"])
Out[31]: 
exp                          A         B
  animal hair_length                    
0 cat    long         1.075770 -0.109050
  dog    short        1.643563 -1.469388
1 cat    long         0.357021 -0.674600
  dog    short       -1.776904 -0.968914
2 cat    long        -1.294524  0.413738
  dog    short        0.276662 -0.472035
3 cat    long        -0.013960 -0.362543
  dog    short       -0.006154 -0.923061

---->   pandas.MultiIndex; pandas.DataFrame; DataFrame.stack

--------------------------------------
ID: 1186 --> 1
# df.stack(level=['animal', 'hair_length'])
# from above is equivalent to:
In [32]: df.stack(level=[1, 2])
Out[32]: 
exp                          A         B
  animal hair_length                    
0 cat    long         1.075770 -0.109050
  dog    short        1.643563 -1.469388
1 cat    long         0.357021 -0.674600
  dog    short       -1.776904 -0.968914
2 cat    long        -1.294524  0.413738
  dog    short        0.276662 -0.472035
3 cat    long        -0.013960 -0.362543
  dog    short       -0.006154 -0.923061

---->   DataFrame.stack

--------------------------------------
ID: 1187 --> 3
In [33]: columns = pd.MultiIndex.from_tuples(
   ....:     [
   ....:         ("A", "cat"),
   ....:         ("B", "dog"),
   ....:         ("B", "cat"),
   ....:         ("A", "dog"),
   ....:     ],
   ....:     names=["exp", "animal"],
   ....: )
   ....: 

In [34]: index = pd.MultiIndex.from_product(
   ....:     [("bar", "baz", "foo", "qux"), ("one", "two")], names=["first", "second"]
   ....: )
   ....: 

In [35]: df = pd.DataFrame(np.random.randn(8, 4), index=index, columns=columns)

In [36]: df2 = df.iloc[[0, 1, 2, 4, 5, 7]]

In [37]: df2
Out[37]: 
exp                  A         B                   A
animal             cat       dog       cat       dog
first second                                        
bar   one     0.895717  0.805244 -1.206412  2.565646
      two     1.431256  1.340309 -1.170299 -0.226169
baz   one     0.410835  0.813850  0.132003 -0.827317
foo   one    -1.413681  1.607920  1.024180  0.569605
      two     0.875906 -2.211372  0.974466 -2.006747
qux   two    -1.226825  0.769804 -1.281247 -0.727707

---->   pandas.MultiIndex; pandas.MultiIndex; pandas.DataFrame

--------------------------------------
ID: 1188 --> 1
In [38]: df2.stack("exp")
Out[38]: 
animal                 cat       dog
first second exp                    
bar   one    A    0.895717  2.565646
             B   -1.206412  0.805244
      two    A    1.431256 -0.226169
             B   -1.170299  1.340309
baz   one    A    0.410835 -0.827317
             B    0.132003  0.813850
foo   one    A   -1.413681  0.569605
             B    1.024180  1.607920
      two    A    0.875906 -2.006747
             B    0.974466 -2.211372
qux   two    A   -1.226825 -0.727707
             B   -1.281247  0.769804

In [39]: df2.stack("animal")
Out[39]: 
exp                         A         B
first second animal                    
bar   one    cat     0.895717 -1.206412
             dog     2.565646  0.805244
      two    cat     1.431256 -1.170299
             dog    -0.226169  1.340309
baz   one    cat     0.410835  0.132003
             dog    -0.827317  0.813850
foo   one    cat    -1.413681  1.024180
             dog     0.569605  1.607920
      two    cat     0.875906  0.974466
             dog    -2.006747 -2.211372
qux   two    cat    -1.226825 -1.281247
             dog    -0.727707  0.769804

---->   DataFrame.stack

--------------------------------------
ID: 1189 --> 1
In [40]: df3 = df.iloc[[0, 1, 4, 7], [1, 2]]

In [41]: df3
Out[41]: 
exp                  B          
animal             dog       cat
first second                    
bar   one     0.805244 -1.206412
      two     1.340309 -1.170299
foo   one     1.607920  1.024180
qux   two     0.769804 -1.281247

In [42]: df3.unstack()
Out[42]: 
exp            B                              
animal       dog                 cat          
second       one       two       one       two
first                                         
bar     0.805244  1.340309 -1.206412 -1.170299
foo     1.607920       NaN  1.024180       NaN
qux          NaN  0.769804       NaN -1.281247

---->   DataFrame.unstack

--------------------------------------
ID: 1190 --> 1
In [43]: df3.unstack(fill_value=-1e9)
Out[43]: 
exp                B                                          
animal           dog                         cat              
second           one           two           one           two
first                                                         
bar     8.052440e-01  1.340309e+00 -1.206412e+00 -1.170299e+00
foo     1.607920e+00 -1.000000e+09  1.024180e+00 -1.000000e+09
qux    -1.000000e+09  7.698036e-01 -1.000000e+09 -1.281247e+00

---->   DataFrame.unstack

--------------------------------------
ID: 1191 --> 1
In [44]: df[:3].unstack(0)
Out[44]: 
exp            A                   B  ...                   A          
animal       cat                 dog  ...       cat       dog          
first        bar       baz       bar  ...       baz       bar       baz
second                                ...                              
one     0.895717  0.410835  0.805244  ...  0.132003  2.565646 -0.827317
two     1.431256       NaN  1.340309  ...       NaN -0.226169       NaN

[2 rows x 8 columns]

In [45]: df2.unstack(1)
Out[45]: 
exp            A                   B  ...                   A          
animal       cat                 dog  ...       cat       dog          
second       one       two       one  ...       two       one       two
first                                 ...                              
bar     0.895717  1.431256  0.805244  ... -1.170299  2.565646 -0.226169
baz     0.410835       NaN  0.813850  ...       NaN -0.827317       NaN
foo    -1.413681  0.875906  1.607920  ...  0.974466  0.569605 -2.006747
qux          NaN -1.226825       NaN  ... -1.281247       NaN -0.727707

[4 rows x 8 columns]

---->   DataFrame.unstack

--------------------------------------
ID: 1192 --> 1
In [46]: cheese = pd.DataFrame(
   ....:     {
   ....:         "first": ["John", "Mary"],
   ....:         "last": ["Doe", "Bo"],
   ....:         "height": [5.5, 6.0],
   ....:         "weight": [130, 150],
   ....:     }
   ....: )
   ....: 

In [47]: cheese
Out[47]: 
  first last  height  weight
0  John  Doe     5.5     130
1  Mary   Bo     6.0     150

In [48]: cheese.melt(id_vars=["first", "last"])
Out[48]: 
  first last variable  value
0  John  Doe   height    5.5
1  Mary   Bo   height    6.0
2  John  Doe   weight  130.0
3  Mary   Bo   weight  150.0

In [49]: cheese.melt(id_vars=["first", "last"], var_name="quantity")
Out[49]: 
  first last quantity  value
0  John  Doe   height    5.5
1  Mary   Bo   height    6.0
2  John  Doe   weight  130.0
3  Mary   Bo   weight  150.0

---->   pandas.DataFrame

--------------------------------------
ID: 1193 --> 2
In [50]: index = pd.MultiIndex.from_tuples([("person", "A"), ("person", "B")])

In [51]: cheese = pd.DataFrame(
   ....:     {
   ....:         "first": ["John", "Mary"],
   ....:         "last": ["Doe", "Bo"],
   ....:         "height": [5.5, 6.0],
   ....:         "weight": [130, 150],
   ....:     },
   ....:     index=index,
   ....: )
   ....: 

In [52]: cheese
Out[52]: 
         first last  height  weight
person A  John  Doe     5.5     130
       B  Mary   Bo     6.0     150

In [53]: cheese.melt(id_vars=["first", "last"])
Out[53]: 
  first last variable  value
0  John  Doe   height    5.5
1  Mary   Bo   height    6.0
2  John  Doe   weight  130.0
3  Mary   Bo   weight  150.0

In [54]: cheese.melt(id_vars=["first", "last"], ignore_index=False)
Out[54]: 
         first last variable  value
person A  John  Doe   height    5.5
       B  Mary   Bo   height    6.0
       A  John  Doe   weight  130.0
       B  Mary   Bo   weight  150.0

---->   pandas.MultiIndex; pandas.DataFrame

--------------------------------------
ID: 1194 --> 2
In [55]: dft = pd.DataFrame(
   ....:     {
   ....:         "A1970": {0: "a", 1: "b", 2: "c"},
   ....:         "A1980": {0: "d", 1: "e", 2: "f"},
   ....:         "B1970": {0: 2.5, 1: 1.2, 2: 0.7},
   ....:         "B1980": {0: 3.2, 1: 1.3, 2: 0.1},
   ....:         "X": dict(zip(range(3), np.random.randn(3))),
   ....:     }
   ....: )
   ....: 

In [56]: dft["id"] = dft.index

In [57]: dft
Out[57]: 
  A1970 A1980  B1970  B1980         X  id
0     a     d    2.5    3.2 -0.121306   0
1     b     e    1.2    1.3 -0.097883   1
2     c     f    0.7    0.1  0.695775   2

In [58]: pd.wide_to_long(dft, ["A", "B"], i="id", j="year")
Out[58]: 
                X  A    B
id year                  
0  1970 -0.121306  a  2.5
1  1970 -0.097883  b  1.2
2  1970  0.695775  c  0.7
0  1980 -0.121306  d  3.2
1  1980 -0.097883  e  1.3
2  1980  0.695775  f  0.1

---->   pandas.DataFrame; pandas.wide_to_long

--------------------------------------
ID: 1195 --> 3
In [59]: df
Out[59]: 
exp                  A         B                   A
animal             cat       dog       cat       dog
first second                                        
bar   one     0.895717  0.805244 -1.206412  2.565646
      two     1.431256  1.340309 -1.170299 -0.226169
baz   one     0.410835  0.813850  0.132003 -0.827317
      two    -0.076467 -1.187678  1.130127 -1.436737
foo   one    -1.413681  1.607920  1.024180  0.569605
      two     0.875906 -2.211372  0.974466 -2.006747
qux   one    -0.410001 -0.078638  0.545952 -1.219217
      two    -1.226825  0.769804 -1.281247 -0.727707

In [60]: df.stack().mean(1).unstack()
Out[60]: 
animal             cat       dog
first second                    
bar   one    -0.155347  1.685445
      two     0.130479  0.557070
baz   one     0.271419 -0.006733
      two     0.526830 -1.312207
foo   one    -0.194750  1.088763
      two     0.925186 -2.109060
qux   one     0.067976 -0.648927
      two    -1.254036  0.021048

# same result, another way
In [61]: df.groupby(level=1, axis=1).mean()
Out[61]: 
animal             cat       dog
first second                    
bar   one    -0.155347  1.685445
      two     0.130479  0.557070
baz   one     0.271419 -0.006733
      two     0.526830 -1.312207
foo   one    -0.194750  1.088763
      two     0.925186 -2.109060
qux   one     0.067976 -0.648927
      two    -1.254036  0.021048

In [62]: df.stack().groupby(level=1).mean()
Out[62]: 
exp            A         B
second                    
one     0.071448  0.455513
two    -0.424186 -0.204486

In [63]: df.mean().unstack(0)
Out[63]: 
exp            A         B
animal                    
cat     0.060843  0.018596
dog    -0.413580  0.232430

---->   DataFrame.stack; DataFrame.groupby; DataFrame.mean

--------------------------------------
ID: 1196 --> 1
In [64]: import datetime

In [65]: df = pd.DataFrame(
   ....:     {
   ....:         "A": ["one", "one", "two", "three"] * 6,
   ....:         "B": ["A", "B", "C"] * 8,
   ....:         "C": ["foo", "foo", "foo", "bar", "bar", "bar"] * 4,
   ....:         "D": np.random.randn(24),
   ....:         "E": np.random.randn(24),
   ....:         "F": [datetime.datetime(2013, i, 1) for i in range(1, 13)]
   ....:         + [datetime.datetime(2013, i, 15) for i in range(1, 13)],
   ....:     }
   ....: )
   ....: 

In [66]: df
Out[66]: 
        A  B    C         D         E          F
0     one  A  foo  0.341734 -0.317441 2013-01-01
1     one  B  foo  0.959726 -1.236269 2013-02-01
2     two  C  foo -1.110336  0.896171 2013-03-01
3   three  A  bar -0.619976 -0.487602 2013-04-01
4     one  B  bar  0.149748 -0.082240 2013-05-01
..    ... ..  ...       ...       ...        ...
19  three  B  foo  0.690579 -2.213588 2013-08-15
20    one  C  foo  0.995761  1.063327 2013-09-15
21    one  A  bar  2.396780  1.266143 2013-10-15
22    two  B  bar  0.014871  0.299368 2013-11-15
23  three  C  bar  3.357427 -0.863838 2013-12-15

[24 rows x 6 columns]

---->   pandas.DataFrame

--------------------------------------
ID: 1197 --> 1
In [67]: pd.pivot_table(df, values="D", index=["A", "B"], columns=["C"])
Out[67]: 
C             bar       foo
A     B                    
one   A  1.120915 -0.514058
      B -0.338421  0.002759
      C -0.538846  0.699535
three A -1.181568       NaN
      B       NaN  0.433512
      C  0.588783       NaN
two   A       NaN  1.000985
      B  0.158248       NaN
      C       NaN  0.176180

In [68]: pd.pivot_table(df, values="D", index=["B"], columns=["A", "C"], aggfunc=np.sum)
Out[68]: 
A       one               three                 two          
C       bar       foo       bar       foo       bar       foo
B                                                            
A  2.241830 -1.028115 -2.363137       NaN       NaN  2.001971
B -0.676843  0.005518       NaN  0.867024  0.316495       NaN
C -1.077692  1.399070  1.177566       NaN       NaN  0.352360

In [69]: pd.pivot_table(
   ....:     df, values=["D", "E"],
   ....:     index=["B"],
   ....:     columns=["A", "C"],
   ....:     aggfunc=np.sum,
   ....: )
   ....: 
Out[69]: 
          D                      ...         E                    
A       one               three  ...     three       two          
C       bar       foo       bar  ...       foo       bar       foo
B                                ...                              
A  2.241830 -1.028115 -2.363137  ...       NaN       NaN  0.128491
B -0.676843  0.005518       NaN  ... -2.128743 -0.194294       NaN
C -1.077692  1.399070  1.177566  ...       NaN       NaN  0.872482

[3 rows x 12 columns]

---->   pandas.pivot_table

--------------------------------------
ID: 1198 --> 1
In [70]: pd.pivot_table(df[["A", "B", "C", "D", "E"]], index=["A", "B"], columns=["C"])
Out[70]: 
                D                   E          
C             bar       foo       bar       foo
A     B                                        
one   A  1.120915 -0.514058  1.393057 -0.021605
      B -0.338421  0.002759  0.684140 -0.551692
      C -0.538846  0.699535 -0.988442  0.747859
three A -1.181568       NaN  0.961289       NaN
      B       NaN  0.433512       NaN -1.064372
      C  0.588783       NaN -0.131830       NaN
two   A       NaN  1.000985       NaN  0.064245
      B  0.158248       NaN -0.097147       NaN
      C       NaN  0.176180       NaN  0.436241

---->   pandas.pivot_table

--------------------------------------
ID: 1199 --> 2
In [71]: pd.pivot_table(df, values="D", index=pd.Grouper(freq="M", key="F"), columns="C")
Out[71]: 
C                bar       foo
F                             
2013-01-31       NaN -0.514058
2013-02-28       NaN  0.002759
2013-03-31       NaN  0.176180
2013-04-30 -1.181568       NaN
2013-05-31 -0.338421       NaN
2013-06-30 -0.538846       NaN
2013-07-31       NaN  1.000985
2013-08-31       NaN  0.433512
2013-09-30       NaN  0.699535
2013-10-31  1.120915       NaN
2013-11-30  0.158248       NaN
2013-12-31  0.588783       NaN

---->   pandas.pivot_table; pandas.Grouper

--------------------------------------
ID: 1200 --> 1
In [72]: table = pd.pivot_table(df, index=["A", "B"], columns=["C"], values=["D", "E"])

In [73]: print(table.to_string(na_rep=""))
                D                   E          
C             bar       foo       bar       foo
A     B                                        
one   A  1.120915 -0.514058  1.393057 -0.021605
      B -0.338421  0.002759  0.684140 -0.551692
      C -0.538846  0.699535 -0.988442  0.747859
three A -1.181568            0.961289          
      B            0.433512           -1.064372
      C  0.588783           -0.131830          
two   A            1.000985            0.064245
      B  0.158248           -0.097147          
      C            0.176180            0.436241

---->   pandas.pivot_table

--------------------------------------
ID: 1201 --> 1
In [74]: table = df.pivot_table(
   ....:     index=["A", "B"],
   ....:     columns="C",
   ....:     values=["D", "E"],
   ....:     margins=True,
   ....:     aggfunc=np.std
   ....: )
   ....: 

In [75]: table
Out[75]: 
                D                             E                    
C             bar       foo       All       bar       foo       All
A     B                                                            
one   A  1.804346  1.210272  1.569879  0.179483  0.418374  0.858005
      B  0.690376  1.353355  0.898998  1.083825  0.968138  1.101401
      C  0.273641  0.418926  0.771139  1.689271  0.446140  1.422136
three A  0.794212       NaN  0.794212  2.049040       NaN  2.049040
      B       NaN  0.363548  0.363548       NaN  1.625237  1.625237
      C  3.915454       NaN  3.915454  1.035215       NaN  1.035215
two   A       NaN  0.442998  0.442998       NaN  0.447104  0.447104
      B  0.202765       NaN  0.202765  0.560757       NaN  0.560757
      C       NaN  1.819408  1.819408       NaN  0.650439  0.650439
All      1.556686  0.952552  1.246608  1.250924  0.899904  1.059389

---->   DataFrame.pivot_table

--------------------------------------
ID: 1203 --> 1
In [77]: foo, bar, dull, shiny, one, two = "foo", "bar", "dull", "shiny", "one", "two"

In [78]: a = np.array([foo, foo, bar, bar, foo, foo], dtype=object)

In [79]: b = np.array([one, one, two, one, two, one], dtype=object)

In [80]: c = np.array([dull, dull, shiny, dull, dull, shiny], dtype=object)

In [81]: pd.crosstab(a, [b, c], rownames=["a"], colnames=["b", "c"])
Out[81]: 
b    one        two      
c   dull shiny dull shiny
a                        
bar    1     0    0     1
foo    2     1    1     0

---->   pandas.crosstab

--------------------------------------
ID: 1204 --> 2
In [82]: df = pd.DataFrame(
   ....:     {"A": [1, 2, 2, 2, 2], "B": [3, 3, 4, 4, 4], "C": [1, 1, np.nan, 1, 1]}
   ....: )
   ....: 

In [83]: df
Out[83]: 
   A  B    C
0  1  3  1.0
1  2  3  1.0
2  2  4  NaN
3  2  4  1.0
4  2  4  1.0

In [84]: pd.crosstab(df["A"], df["B"])
Out[84]: 
B  3  4
A      
1  1  0
2  1  3

---->   pandas.DataFrame; pandas.crosstab

--------------------------------------
ID: 1205 --> 2
In [85]: foo = pd.Categorical(["a", "b"], categories=["a", "b", "c"])

In [86]: bar = pd.Categorical(["d", "e"], categories=["d", "e", "f"])

In [87]: pd.crosstab(foo, bar)
Out[87]: 
col_0  d  e
row_0      
a      1  0
b      0  1

---->   pandas.Categorical; pandas.crosstab

--------------------------------------
ID: 1206 --> 1
In [88]: pd.crosstab(foo, bar, dropna=False)
Out[88]: 
col_0  d  e  f
row_0         
a      1  0  0
b      0  1  0
c      0  0  0

---->   pandas.crosstab

--------------------------------------
ID: 1207 --> 1
In [89]: pd.crosstab(df["A"], df["B"], normalize=True)
Out[89]: 
B    3    4
A          
1  0.2  0.0
2  0.2  0.6

---->   pandas.crosstab

--------------------------------------
ID: 1208 --> 1
In [90]: pd.crosstab(df["A"], df["B"], normalize="columns")
Out[90]: 
B    3    4
A          
1  0.5  0.0
2  0.5  1.0

---->   pandas.crosstab

--------------------------------------
ID: 1209 --> 1
In [91]: pd.crosstab(df["A"], df["B"], values=df["C"], aggfunc=np.sum)
Out[91]: 
B    3    4
A          
1  1.0  NaN
2  1.0  2.0

---->   pandas.crosstab

--------------------------------------
ID: 1210 --> 1
In [92]: pd.crosstab(
   ....:     df["A"], df["B"], values=df["C"], aggfunc=np.sum, normalize=True, margins=True
   ....: )
   ....: 
Out[92]: 
B       3    4   All
A                   
1    0.25  0.0  0.25
2    0.25  0.5  0.75
All  0.50  0.5  1.00

---->   pandas.crosstab

--------------------------------------
ID: 1211 --> 1
In [93]: ages = np.array([10, 15, 13, 12, 23, 25, 28, 59, 60])

In [94]: pd.cut(ages, bins=3)
Out[94]: 
[(9.95, 26.667], (9.95, 26.667], (9.95, 26.667], (9.95, 26.667], (9.95, 26.667], (9.95, 26.667], (26.667, 43.333], (43.333, 60.0], (43.333, 60.0]]
Categories (3, interval[float64, right]): [(9.95, 26.667] < (26.667, 43.333] < (43.333, 60.0]]

---->   pandas.cut

--------------------------------------
ID: 1212 --> 1
In [95]: c = pd.cut(ages, bins=[0, 18, 35, 70])

In [96]: c
Out[96]: 
[(0, 18], (0, 18], (0, 18], (0, 18], (18, 35], (18, 35], (18, 35], (35, 70], (35, 70]]
Categories (3, interval[int64, right]): [(0, 18] < (18, 35] < (35, 70]]

---->   pandas.cut

--------------------------------------
ID: 1213 --> 1
pd.cut([25, 20, 50], bins=c.categories)

---->   pandas.cut

--------------------------------------
ID: 1214 --> 2
In [97]: df = pd.DataFrame({"key": list("bbacab"), "data1": range(6)})

In [98]: pd.get_dummies(df["key"])
Out[98]: 
       a      b      c
0  False   True  False
1  False   True  False
2   True  False  False
3  False  False   True
4   True  False  False
5  False   True  False

---->   pandas.DataFrame; pandas.get_dummies

--------------------------------------
ID: 1215 --> 1
In [99]: dummies = pd.get_dummies(df["key"], prefix="key")

In [100]: dummies
Out[100]: 
   key_a  key_b  key_c
0  False   True  False
1  False   True  False
2   True  False  False
3  False  False   True
4   True  False  False
5  False   True  False

In [101]: df[["data1"]].join(dummies)
Out[101]: 
   data1  key_a  key_b  key_c
0      0  False   True  False
1      1  False   True  False
2      2   True  False  False
3      3  False  False   True
4      4   True  False  False
5      5  False   True  False

---->   pandas.get_dummies

--------------------------------------
ID: 1216 --> 2
In [102]: values = np.random.randn(10)

In [103]: values
Out[103]: 
array([ 0.4082, -1.0481, -0.0257, -0.9884,  0.0941,  1.2627,  1.29  ,
        0.0824, -0.0558,  0.5366])

In [104]: bins = [0, 0.2, 0.4, 0.6, 0.8, 1]

In [105]: pd.get_dummies(pd.cut(values, bins))
Out[105]: 
   (0.0, 0.2]  (0.2, 0.4]  (0.4, 0.6]  (0.6, 0.8]  (0.8, 1.0]
0       False       False        True       False       False
1       False       False       False       False       False
2       False       False       False       False       False
3       False       False       False       False       False
4        True       False       False       False       False
5       False       False       False       False       False
6       False       False       False       False       False
7        True       False       False       False       False
8       False       False       False       False       False
9       False       False        True       False       False

---->   pandas.get_dummies; pandas.cut

--------------------------------------
ID: 1217 --> 2
In [106]: df = pd.DataFrame({"A": ["a", "b", "a"], "B": ["c", "c", "b"], "C": [1, 2, 3]})

In [107]: pd.get_dummies(df)
Out[107]: 
   C    A_a    A_b    B_b    B_c
0  1   True  False  False   True
1  2  False   True  False   True
2  3   True  False   True  False

---->   pandas.DataFrame; pandas.get_dummies

--------------------------------------
ID: 1218 --> 1
In [108]: pd.get_dummies(df, columns=["A"])
Out[108]: 
   B  C    A_a    A_b
0  c  1   True  False
1  c  2  False   True
2  b  3   True  False

---->   pandas.get_dummies

--------------------------------------
ID: 1219 --> 1
In [109]: simple = pd.get_dummies(df, prefix="new_prefix")

In [110]: simple
Out[110]: 
   C  new_prefix_a  new_prefix_b  new_prefix_b  new_prefix_c
0  1          True         False         False          True
1  2         False          True         False          True
2  3          True         False          True         False

In [111]: from_list = pd.get_dummies(df, prefix=["from_A", "from_B"])

In [112]: from_list
Out[112]: 
   C  from_A_a  from_A_b  from_B_b  from_B_c
0  1      True     False     False      True
1  2     False      True     False      True
2  3      True     False      True     False

In [113]: from_dict = pd.get_dummies(df, prefix={"B": "from_B", "A": "from_A"})

In [114]: from_dict
Out[114]: 
   C  from_A_a  from_A_b  from_B_b  from_B_c
0  1      True     False     False      True
1  2     False      True     False      True
2  3      True     False      True     False

---->   pandas.get_dummies

--------------------------------------
ID: 1220 --> 2
In [115]: s = pd.Series(list("abcaa"))

In [116]: pd.get_dummies(s)
Out[116]: 
       a      b      c
0   True  False  False
1  False   True  False
2  False  False   True
3   True  False  False
4   True  False  False

In [117]: pd.get_dummies(s, drop_first=True)
Out[117]: 
       b      c
0  False  False
1   True  False
2  False   True
3  False  False
4  False  False

---->   pandas.Series; pandas.get_dummies

--------------------------------------
ID: 1221 --> 2
In [118]: df = pd.DataFrame({"A": list("aaaaa"), "B": list("ababc")})

In [119]: pd.get_dummies(df)
Out[119]: 
    A_a    B_a    B_b    B_c
0  True   True  False  False
1  True  False   True  False
2  True   True  False  False
3  True  False   True  False
4  True  False  False   True

In [120]: pd.get_dummies(df, drop_first=True)
Out[120]: 
     B_b    B_c
0  False  False
1   True  False
2  False  False
3   True  False
4  False   True

---->   pandas.DataFrame; pandas.get_dummies

--------------------------------------
ID: 1222 --> 2
In [121]: df = pd.DataFrame({"A": list("abc"), "B": [1.1, 2.2, 3.3]})

In [122]: pd.get_dummies(df, dtype=bool).dtypes
Out[122]: 
B      float64
A_a       bool
A_b       bool
A_c       bool
dtype: object

---->   pandas.DataFrame; pandas.get_dummies

--------------------------------------
ID: 1223 --> 2
In [123]: df = pd.DataFrame({"prefix_a": [0, 1, 0], "prefix_b": [1, 0, 1]})

In [124]: df
Out[124]: 
   prefix_a  prefix_b
0         0         1
1         1         0
2         0         1

In [125]: pd.from_dummies(df, sep="_")
Out[125]: 
  prefix
0      b
1      a
2      b

---->   pandas.DataFrame; pandas.from_dummies

--------------------------------------
ID: 1224 --> 2
In [126]: df = pd.DataFrame({"prefix_a": [0, 1, 0]})

In [127]: df
Out[127]: 
   prefix_a
0         0
1         1
2         0

In [128]: pd.from_dummies(df, sep="_", default_category="b")
Out[128]: 
  prefix
0      b
1      a
2      b

---->   pandas.DataFrame; pandas.from_dummies

--------------------------------------
ID: 1225 --> 2
In [129]: x = pd.Series(["A", "A", np.nan, "B", 3.14, np.inf])

In [130]: x
Out[130]: 
0       A
1       A
2     NaN
3       B
4    3.14
5     inf
dtype: object

In [131]: labels, uniques = pd.factorize(x)

In [132]: labels
Out[132]: array([ 0,  0, -1,  1,  2,  3])

In [133]: uniques
Out[133]: Index(['A', 'B', 3.14, inf], dtype='object')

---->   pandas.Series; pandas.factorize

--------------------------------------
ID: 1226 --> 2
In [134]: ser = pd.Series(['A', 'A', np.nan, 'B', 3.14, np.inf])

In [135]: pd.factorize(ser, sort=True)
Out[135]: (array([ 2,  2, -1,  3,  0,  1]), Index([3.14, inf, 'A', 'B'], dtype='object'))

In [136]: np.unique(ser, return_inverse=True)[::-1]
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
Cell In[136], line 1
----> 1 np.unique(ser, return_inverse=True)[::-1]

File <__array_function__ internals>:200, in unique(*args, **kwargs)

File ~/micromamba-root/envs/test/lib/python3.8/site-packages/numpy/lib/arraysetops.py:274, in unique(ar, return_index, return_inverse, return_counts, axis, equal_nan)
    272 ar = np.asanyarray(ar)
    273 if axis is None:
--> 274     ret = _unique1d(ar, return_index, return_inverse, return_counts, 
    275                     equal_nan=equal_nan)
    276     return _unpack_tuple(ret)
    278 # axis was specified and not None

File ~/micromamba-root/envs/test/lib/python3.8/site-packages/numpy/lib/arraysetops.py:333, in _unique1d(ar, return_index, return_inverse, return_counts, equal_nan)
    330 optional_indices = return_index or return_inverse
    332 if optional_indices:
--> 333     perm = ar.argsort(kind='mergesort' if return_index else 'quicksort')
    334     aux = ar[perm]
    335 else:

TypeError: '<' not supported between instances of 'float' and 'str'

---->   pandas.Series; pandas.factorize

--------------------------------------
ID: 1227 --> 2
In [137]: np.random.seed([3, 1415])

In [138]: n = 20

In [139]: cols = np.array(["key", "row", "item", "col"])

In [140]: df = cols + pd.DataFrame(
   .....:     (np.random.randint(5, size=(n, 4)) // [2, 1, 2, 1]).astype(str)
   .....: )
   .....: 

In [141]: df.columns = cols

In [142]: df = df.join(pd.DataFrame(np.random.rand(n, 2).round(2)).add_prefix("val"))

In [143]: df
Out[143]: 
     key   row   item   col  val0  val1
0   key0  row3  item1  col3  0.81  0.04
1   key1  row2  item1  col2  0.44  0.07
2   key1  row0  item1  col0  0.77  0.01
3   key0  row4  item0  col2  0.15  0.59
4   key1  row0  item2  col1  0.81  0.64
..   ...   ...    ...   ...   ...   ...
15  key0  row3  item1  col1  0.31  0.23
16  key0  row0  item2  col3  0.86  0.01
17  key0  row4  item0  col3  0.64  0.21
18  key2  row2  item2  col0  0.13  0.45
19  key0  row2  item0  col4  0.37  0.70

[20 rows x 6 columns]

---->   pandas.DataFrame; DataFrame.join

--------------------------------------
ID: 1228 --> 1
In [144]: df.pivot_table(values="val0", index="row", columns="col", aggfunc="mean")
Out[144]: 
col   col0   col1   col2   col3  col4
row                                  
row0  0.77  0.605    NaN  0.860  0.65
row2  0.13    NaN  0.395  0.500  0.25
row3   NaN  0.310    NaN  0.545   NaN
row4   NaN  0.100  0.395  0.760  0.24

---->   DataFrame.pivot_table

--------------------------------------
ID: 1229 --> 1
In [145]: df.pivot_table(
   .....:     values="val0",
   .....:     index="row",
   .....:     columns="col",
   .....:     aggfunc="mean",
   .....:     fill_value=0,
   .....: )
   .....: 
Out[145]: 
col   col0   col1   col2   col3  col4
row                                  
row0  0.77  0.605  0.000  0.860  0.65
row2  0.13  0.000  0.395  0.500  0.25
row3  0.00  0.310  0.000  0.545  0.00
row4  0.00  0.100  0.395  0.760  0.24

---->   DataFrame.pivot_table

--------------------------------------
ID: 1230 --> 1
In [146]: df.pivot_table(
   .....:     values="val0",
   .....:     index="row",
   .....:     columns="col",
   .....:     aggfunc="sum",
   .....:     fill_value=0,
   .....: )
   .....: 
Out[146]: 
col   col0  col1  col2  col3  col4
row                               
row0  0.77  1.21  0.00  0.86  0.65
row2  0.13  0.00  0.79  0.50  0.50
row3  0.00  0.31  0.00  1.09  0.00
row4  0.00  0.10  0.79  1.52  0.24

---->   DataFrame.pivot_table

--------------------------------------
ID: 1231 --> 1
In [147]: df.pivot_table(index="row", columns="col", fill_value=0, aggfunc="size")
Out[147]: 
col   col0  col1  col2  col3  col4
row                               
row0     1     2     0     1     1
row2     1     0     2     1     2
row3     0     1     0     2     0
row4     0     1     2     2     1

---->   DataFrame.pivot_table

--------------------------------------
ID: 1232 --> 1
In [148]: df.pivot_table(
   .....:     values="val0",
   .....:     index="row",
   .....:     columns="col",
   .....:     aggfunc=["mean", "sum"],
   .....: )
   .....: 
Out[148]: 
      mean                              sum                        
col   col0   col1   col2   col3  col4  col0  col1  col2  col3  col4
row                                                                
row0  0.77  0.605    NaN  0.860  0.65  0.77  1.21   NaN  0.86  0.65
row2  0.13    NaN  0.395  0.500  0.25  0.13   NaN  0.79  0.50  0.50
row3   NaN  0.310    NaN  0.545   NaN   NaN  0.31   NaN  1.09   NaN
row4   NaN  0.100  0.395  0.760  0.24   NaN  0.10  0.79  1.52  0.24

---->   DataFrame.pivot_table

--------------------------------------
ID: 1233 --> 1
In [149]: df.pivot_table(
   .....:     values=["val0", "val1"],
   .....:     index="row",
   .....:     columns="col",
   .....:     aggfunc=["mean"],
   .....: )
   .....: 
Out[149]: 
      mean                                                           
      val0                             val1                          
col   col0   col1   col2   col3  col4  col0   col1  col2   col3  col4
row                                                                  
row0  0.77  0.605    NaN  0.860  0.65  0.01  0.745   NaN  0.010  0.02
row2  0.13    NaN  0.395  0.500  0.25  0.45    NaN  0.34  0.440  0.79
row3   NaN  0.310    NaN  0.545   NaN   NaN  0.230   NaN  0.075   NaN
row4   NaN  0.100  0.395  0.760  0.24   NaN  0.070  0.42  0.300  0.46

---->   DataFrame.pivot_table

--------------------------------------
ID: 1234 --> 1
In [150]: df.pivot_table(
   .....:     values=["val0"],
   .....:     index="row",
   .....:     columns=["item", "col"],
   .....:     aggfunc=["mean"],
   .....: )
   .....: 
Out[150]: 
      mean                                                                   
      val0                                                                   
item item0             item1                         item2                   
col   col2  col3  col4  col0  col1  col2  col3  col4  col0   col1  col3  col4
row                                                                          
row0   NaN   NaN   NaN  0.77   NaN   NaN   NaN   NaN   NaN  0.605  0.86  0.65
row2  0.35   NaN  0.37   NaN   NaN  0.44   NaN   NaN  0.13    NaN  0.50  0.13
row3   NaN   NaN   NaN   NaN  0.31   NaN  0.81   NaN   NaN    NaN  0.28   NaN
row4  0.15  0.64   NaN   NaN  0.10  0.64  0.88  0.24   NaN    NaN   NaN   NaN

---->   DataFrame.pivot_table

--------------------------------------
ID: 1235 --> 1
In [151]: keys = ["panda1", "panda2", "panda3"]

In [152]: values = [["eats", "shoots"], ["shoots", "leaves"], ["eats", "leaves"]]

In [153]: df = pd.DataFrame({"keys": keys, "values": values})

In [154]: df
Out[154]: 
     keys            values
0  panda1    [eats, shoots]
1  panda2  [shoots, leaves]
2  panda3    [eats, leaves]

---->   pandas.DataFrame

--------------------------------------
ID: 1237 --> 1
In [156]: df.explode("values")
Out[156]: 
     keys  values
0  panda1    eats
0  panda1  shoots
1  panda2  shoots
1  panda2  leaves
2  panda3    eats
2  panda3  leaves

---->   DataFrame.explode

--------------------------------------
ID: 1238 --> 2
In [157]: s = pd.Series([[1, 2, 3], "foo", [], ["a", "b"]])

In [158]: s
Out[158]: 
0    [1, 2, 3]
1          foo
2           []
3       [a, b]
dtype: object

In [159]: s.explode()
Out[159]: 
0      1
0      2
0      3
1    foo
2    NaN
3      a
3      b
dtype: object

---->   pandas.Series; Series.explode

--------------------------------------
ID: 1239 --> 1
In [160]: df = pd.DataFrame([{"var1": "a,b,c", "var2": 1}, {"var1": "d,e,f", "var2": 2}])

In [161]: df
Out[161]: 
    var1  var2
0  a,b,c     1
1  d,e,f     2

---->   pandas.DataFrame

--------------------------------------
ID: 1240 --> 1
In [162]: df.assign(var1=df.var1.str.split(",")).explode("var1")
Out[162]: 
  var1  var2
0    a     1
0    b     1
0    c     1
1    d     2
1    e     2
1    f     2

---->   DataFrame.assign

--------------------------------------
ID: 1241 --> 1
In [1]: arr = np.random.randn(10)

In [2]: arr[2:-2] = np.nan

In [3]: ts = pd.Series(pd.arrays.SparseArray(arr))

In [4]: ts
Out[4]: 
0    0.469112
1   -0.282863
2         NaN
3         NaN
4         NaN
5         NaN
6         NaN
7         NaN
8   -0.861849
9   -2.104569
dtype: Sparse[float64, nan]

---->   pandas.Series

--------------------------------------
ID: 1242 --> 2
In [5]: df = pd.DataFrame(np.random.randn(10000, 4))

In [6]: df.iloc[:9998] = np.nan

In [7]: sdf = df.astype(pd.SparseDtype("float", np.nan))

In [8]: sdf.head()
Out[8]: 
    0   1   2   3
0 NaN NaN NaN NaN
1 NaN NaN NaN NaN
2 NaN NaN NaN NaN
3 NaN NaN NaN NaN
4 NaN NaN NaN NaN

In [9]: sdf.dtypes
Out[9]: 
0    Sparse[float64, nan]
1    Sparse[float64, nan]
2    Sparse[float64, nan]
3    Sparse[float64, nan]
dtype: object

In [10]: sdf.sparse.density
Out[10]: 0.0002

---->   pandas.DataFrame; DataFrame.astype

--------------------------------------
ID: 1243 --> 1
In [11]: 'dense : {:0.2f} bytes'.format(df.memory_usage().sum() / 1e3)
Out[11]: 'dense : 320.13 bytes'

In [12]: 'sparse: {:0.2f} bytes'.format(sdf.memory_usage().sum() / 1e3)
Out[12]: 'sparse: 0.22 bytes'

---->   DataFrame.memory_usage

--------------------------------------
ID: 1248 --> 1
In [22]: pd.array([1, 0, 0, 2], dtype='Sparse[int]')
Out[22]: 
[1, 0, 0, 2]
Fill: 0
IntIndex
Indices: array([0, 3], dtype=int32)

---->   pandas.array

--------------------------------------
ID: 1249 --> 1
In [23]: s = pd.Series([0, 0, 1, 2], dtype="Sparse[int]")

In [24]: s.sparse.density
Out[24]: 0.5

In [25]: s.sparse.fill_value
Out[25]: 0

---->   pandas.Series

--------------------------------------
ID: 1253 --> 1
# New way
In [31]: pd.DataFrame({"A": pd.arrays.SparseArray([0, 1])})
Out[31]: 
   A
0  0
1  1

---->   pandas.DataFrame

--------------------------------------
ID: 1255 --> 1
# New way
In [32]: from scipy import sparse

In [33]: mat = sparse.eye(3)

In [34]: df = pd.DataFrame.sparse.from_spmatrix(mat, columns=['A', 'B', 'C'])

In [35]: df.dtypes
Out[35]: 
A    Sparse[float64, 0]
B    Sparse[float64, 0]
C    Sparse[float64, 0]
dtype: object

---->   pandas.DataFrame

--------------------------------------
ID: 1257 --> 2
In [38]: dense = pd.DataFrame({"A": [1, 0, 0, 1]})

In [39]: dtype = pd.SparseDtype(int, fill_value=0)

In [40]: dense.astype(dtype)
Out[40]: 
   A
0  1
1  0
2  0
3  1

---->   pandas.DataFrame; DataFrame.astype

--------------------------------------
ID: 1259 --> 1
In [42]: df = pd.DataFrame({"A": pd.arrays.SparseArray([0, 1])})

In [43]: df['B'] = [0, 0]  # remains dense

In [44]: df['B'].dtype
Out[44]: dtype('int64')

In [45]: df['B'] = pd.arrays.SparseArray([0, 0])

In [46]: df['B'].dtype
Out[46]: Sparse[int64, 0]

---->   pandas.DataFrame

--------------------------------------
ID: 1260 --> 1
In [47]: from scipy.sparse import csr_matrix

In [48]: arr = np.random.random(size=(1000, 5))

In [49]: arr[arr < .9] = 0

In [50]: sp_arr = csr_matrix(arr)

In [51]: sp_arr
Out[51]: 
<1000x5 sparse matrix of type ''
	with 517 stored elements in Compressed Sparse Row format>

In [52]: sdf = pd.DataFrame.sparse.from_spmatrix(sp_arr)

In [53]: sdf.head()
Out[53]: 
          0    1    2         3    4
0  0.956380  0.0  0.0  0.000000  0.0
1  0.000000  0.0  0.0  0.000000  0.0
2  0.000000  0.0  0.0  0.000000  0.0
3  0.000000  0.0  0.0  0.000000  0.0
4  0.999552  0.0  0.0  0.956153  0.0

In [54]: sdf.dtypes
Out[54]: 
0    Sparse[float64, 0]
1    Sparse[float64, 0]
2    Sparse[float64, 0]
3    Sparse[float64, 0]
4    Sparse[float64, 0]
dtype: object

---->   pandas.DataFrame

--------------------------------------
ID: 1262 --> 3
In [56]: s = pd.Series([3.0, np.nan, 1.0, 3.0, np.nan, np.nan])

In [57]: s.index = pd.MultiIndex.from_tuples(
   ....:     [
   ....:         (1, 2, "a", 0),
   ....:         (1, 2, "a", 1),
   ....:         (1, 1, "b", 0),
   ....:         (1, 1, "b", 1),
   ....:         (2, 1, "b", 0),
   ....:         (2, 1, "b", 1),
   ....:     ],
   ....:     names=["A", "B", "C", "D"],
   ....: )
   ....: 

In [58]: ss = s.astype('Sparse')

In [59]: ss
Out[59]: 
A  B  C  D
1  2  a  0    3.0
         1    NaN
   1  b  0    1.0
         1    3.0
2  1  b  0    NaN
         1    NaN
dtype: Sparse[float64, nan]

---->   pandas.Series; pandas.MultiIndex; Series.astype

--------------------------------------
ID: 1266 --> 1
In [74]: ss = pd.Series.sparse.from_coo(A)

In [75]: ss
Out[75]: 
0  2    1.0
   3    2.0
1  0    3.0
dtype: Sparse[float64, nan]

---->   pandas.Series

--------------------------------------
ID: 1267 --> 1
In [76]: ss_dense = pd.Series.sparse.from_coo(A, dense_index=True)

In [77]: ss_dense
Out[77]: 
1  0    3.0
   2    NaN
   3    NaN
0  0    NaN
   2    1.0
   3    2.0
   0    NaN
   2    1.0
   3    2.0
dtype: Sparse[float64, nan]

---->   pandas.Series

--------------------------------------
ID: 1270 --> 1
In [11]: pd.describe_option()
compute.use_bottleneck : bool
    Use the bottleneck library to accelerate if it is installed,
    the default is True
    Valid values: False,True
    [default: True] [currently: True]
compute.use_numba : bool
    Use the numba engine option for select operations if it is installed,
    the default is False
    Valid values: False,True
    [default: False] [currently: False]
compute.use_numexpr : bool
    Use the numexpr library to accelerate computation if it is installed,
    the default is True
    Valid values: False,True
    [default: True] [currently: True]
display.chop_threshold : float or None
    if set to a float value, all float values smaller than the given threshold
    will be displayed as exactly 0 by repr and friends.
    [default: None] [currently: None]
display.colheader_justify : 'left'/'right'
    Controls the justification of column headers. used by DataFrameFormatter.
    [default: right] [currently: right]
display.date_dayfirst : boolean
    When True, prints and parses dates with the day first, eg 20/01/2005
    [default: False] [currently: False]
display.date_yearfirst : boolean
    When True, prints and parses dates with the year first, eg 2005/01/20
    [default: False] [currently: False]
display.encoding : str/unicode
    Defaults to the detected encoding of the console.
    Specifies the encoding to be used for strings returned by to_string,
    these are generally strings meant to be displayed on the console.
    [default: utf-8] [currently: utf8]
display.expand_frame_repr : boolean
    Whether to print out the full DataFrame repr for wide DataFrames across
    multiple lines, `max_columns` is still respected, but the output will
    wrap-around across multiple "pages" if its width exceeds `display.width`.
    [default: True] [currently: True]
display.float_format : callable
    The callable should accept a floating point number and return
    a string with the desired format of the number. This is used
    in some places like SeriesFormatter.
    See formats.format.EngFormatter for an example.
    [default: None] [currently: None]
display.html.border : int
    A ``border=value`` attribute is inserted in the ```` tag
    for the DataFrame HTML repr.
    [default: 1] [currently: 1]
display.html.table_schema : boolean
    Whether to publish a Table Schema representation for frontends
    that support it.
    (default: False)
    [default: False] [currently: False]
display.html.use_mathjax : boolean
    When True, Jupyter notebook will process table contents using MathJax,
    rendering mathematical expressions enclosed by the dollar symbol.
    (default: True)
    [default: True] [currently: True]
display.large_repr : 'truncate'/'info'
    For DataFrames exceeding max_rows/max_cols, the repr (and HTML repr) can
    show a truncated table (the default from 0.13), or switch to the view from
    df.info() (the behaviour in earlier versions of pandas).
    [default: truncate] [currently: truncate]
display.max_categories : int
    This sets the maximum number of categories pandas should output when
    printing out a `Categorical` or a Series of dtype "category".
    [default: 8] [currently: 8]
display.max_columns : int
    If max_cols is exceeded, switch to truncate view. Depending on
    `large_repr`, objects are either centrally truncated or printed as
    a summary view. 'None' value means unlimited.

    In case python/IPython is running in a terminal and `large_repr`
    equals 'truncate' this can be set to 0 or None and pandas will auto-detect
    the width of the terminal and print a truncated object which fits
    the screen width. The IPython notebook, IPython qtconsole, or IDLE
    do not run in a terminal and hence it is not possible to do
    correct auto-detection and defaults to 20.
    [default: 0] [currently: 0]
display.max_colwidth : int or None
    The maximum width in characters of a column in the repr of
    a pandas data structure. When the column overflows, a "..."
    placeholder is embedded in the output. A 'None' value means unlimited.
    [default: 50] [currently: 50]
display.max_dir_items : int
    The number of items that will be added to `dir(...)`. 'None' value means
    unlimited. Because dir is cached, changing this option will not immediately
    affect already existing dataframes until a column is deleted or added.

    This is for instance used to suggest columns from a dataframe to tab
    completion.
    [default: 100] [currently: 100]
display.max_info_columns : int
    max_info_columns is used in DataFrame.info method to decide if
    per column information will be printed.
    [default: 100] [currently: 100]
display.max_info_rows : int or None
    df.info() will usually show null-counts for each column.
    For large frames this can be quite slow. max_info_rows and max_info_cols
    limit this null check only to frames with smaller dimensions than
    specified.
    [default: 1690785] [currently: 1690785]
display.max_rows : int
    If max_rows is exceeded, switch to truncate view. Depending on
    `large_repr`, objects are either centrally truncated or printed as
    a summary view. 'None' value means unlimited.

    In case python/IPython is running in a terminal and `large_repr`
    equals 'truncate' this can be set to 0 and pandas will auto-detect
    the height of the terminal and print a truncated object which fits
    the screen height. The IPython notebook, IPython qtconsole, or
    IDLE do not run in a terminal and hence it is not possible to do
    correct auto-detection.
    [default: 60] [currently: 60]
display.max_seq_items : int or None
    When pretty-printing a long sequence, no more then `max_seq_items`
    will be printed. If items are omitted, they will be denoted by the
    addition of "..." to the resulting string.

    If set to None, the number of items to be printed is unlimited.
    [default: 100] [currently: 100]
display.memory_usage : bool, string or None
    This specifies if the memory usage of a DataFrame should be displayed when
    df.info() is called. Valid values True,False,'deep'
    [default: True] [currently: True]
display.min_rows : int
    The numbers of rows to show in a truncated view (when `max_rows` is
    exceeded). Ignored when `max_rows` is set to None or 0. When set to
    None, follows the value of `max_rows`.
    [default: 10] [currently: 10]
display.multi_sparse : boolean
    "sparsify" MultiIndex display (don't display repeated
    elements in outer levels within groups)
    [default: True] [currently: True]
display.notebook_repr_html : boolean
    When True, IPython notebook will use html representation for
    pandas objects (if it is available).
    [default: True] [currently: True]
display.pprint_nest_depth : int
    Controls the number of nested levels to process when pretty-printing
    [default: 3] [currently: 3]
display.precision : int
    Floating point output precision in terms of number of places after the
    decimal, for regular formatting as well as scientific notation. Similar
    to ``precision`` in :meth:`numpy.set_printoptions`.
    [default: 6] [currently: 6]
display.show_dimensions : boolean or 'truncate'
    Whether to print out dimensions at the end of DataFrame repr.
    If 'truncate' is specified, only print out the dimensions if the
    frame is truncated (e.g. not display all rows and/or columns)
    [default: truncate] [currently: truncate]
display.unicode.ambiguous_as_wide : boolean
    Whether to use the Unicode East Asian Width to calculate the display text
    width.
    Enabling this may affect to the performance (default: False)
    [default: False] [currently: False]
display.unicode.east_asian_width : boolean
    Whether to use the Unicode East Asian Width to calculate the display text
    width.
    Enabling this may affect to the performance (default: False)
    [default: False] [currently: False]
display.width : int
    Width of the display in characters. In case python/IPython is running in
    a terminal this can be set to None and pandas will correctly auto-detect
    the width.
    Note that the IPython notebook, IPython qtconsole, or IDLE do not run in a
    terminal and hence it is not possible to correctly detect the width.
    [default: 80] [currently: 80]
io.excel.ods.reader : string
    The default Excel reader engine for 'ods' files. Available options:
    auto, odf.
    [default: auto] [currently: auto]
io.excel.ods.writer : string
    The default Excel writer engine for 'ods' files. Available options:
    auto, odf.
    [default: auto] [currently: auto]
io.excel.xls.reader : string
    The default Excel reader engine for 'xls' files. Available options:
    auto, xlrd.
    [default: auto] [currently: auto]
io.excel.xlsb.reader : string
    The default Excel reader engine for 'xlsb' files. Available options:
    auto, pyxlsb.
    [default: auto] [currently: auto]
io.excel.xlsm.reader : string
    The default Excel reader engine for 'xlsm' files. Available options:
    auto, xlrd, openpyxl.
    [default: auto] [currently: auto]
io.excel.xlsm.writer : string
    The default Excel writer engine for 'xlsm' files. Available options:
    auto, openpyxl.
    [default: auto] [currently: auto]
io.excel.xlsx.reader : string
    The default Excel reader engine for 'xlsx' files. Available options:
    auto, xlrd, openpyxl.
    [default: auto] [currently: auto]
io.excel.xlsx.writer : string
    The default Excel writer engine for 'xlsx' files. Available options:
    auto, openpyxl, xlsxwriter.
    [default: auto] [currently: auto]
io.hdf.default_format : format
    default format writing format, if None, then
    put will default to 'fixed' and append will default to 'table'
    [default: None] [currently: None]
io.hdf.dropna_table : boolean
    drop ALL nan rows when appending to a table
    [default: False] [currently: False]
io.parquet.engine : string
    The default parquet reader/writer engine. Available options:
    'auto', 'pyarrow', 'fastparquet', the default is 'auto'
    [default: auto] [currently: auto]
io.sql.engine : string
    The default sql reader/writer engine. Available options:
    'auto', 'sqlalchemy', the default is 'auto'
    [default: auto] [currently: auto]
mode.chained_assignment : string
    Raise an exception, warn, or no action if trying to use chained assignment,
    The default is warn
    [default: warn] [currently: warn]
mode.copy_on_write : bool
    Use new copy-view behaviour using Copy-on-Write. Defaults to False,
    unless overridden by the 'PANDAS_COPY_ON_WRITE' environment variable
    (if set to "1" for True, needs to be set before pandas is imported).
    [default: False] [currently: False]
mode.data_manager : string
    Internal data manager type; can be "block" or "array". Defaults to "block",
    unless overridden by the 'PANDAS_DATA_MANAGER' environment variable (needs
    to be set before pandas is imported).
    [default: block] [currently: block]
mode.sim_interactive : boolean
    Whether to simulate interactive mode for purposes of testing
    [default: False] [currently: False]
mode.string_storage : string
    The default storage for StringDtype.
    [default: python] [currently: python]
mode.use_inf_as_na : boolean
    True means treat None, NaN, INF, -INF as NA (old way),
    False means None and NaN are null, but INF, -INF are not NA
    (new way).
    [default: False] [currently: False]
plotting.backend : str
    The plotting backend to use. The default value is "matplotlib", the
    backend provided with pandas. Other backends can be specified by
    providing the name of the module that implements the backend.
    [default: matplotlib] [currently: matplotlib]
plotting.matplotlib.register_converters : bool or 'auto'.
    Whether to register converters with matplotlib's units registry for
    dates, times, datetimes, and Periods. Toggling to False will remove
    the converters, restoring any converters that pandas overwrote.
    [default: auto] [currently: auto]
styler.format.decimal : str
    The character representation for the decimal separator for floats and complex.
    [default: .] [currently: .]
styler.format.escape : str, optional
    Whether to escape certain characters according to the given context; html or latex.
    [default: None] [currently: None]
styler.format.formatter : str, callable, dict, optional
    A formatter object to be used as default within ``Styler.format``.
    [default: None] [currently: None]
styler.format.na_rep : str, optional
    The string representation for values identified as missing.
    [default: None] [currently: None]
styler.format.precision : int
    The precision for floats and complex numbers.
    [default: 6] [currently: 6]
styler.format.thousands : str, optional
    The character representation for thousands separator for floats, int and complex.
    [default: None] [currently: None]
styler.html.mathjax : bool
    If False will render special CSS classes to table attributes that indicate Mathjax
    will not be used in Jupyter Notebook.
    [default: True] [currently: True]
styler.latex.environment : str
    The environment to replace ``\begin{table}``. If "longtable" is used results
    in a specific longtable environment format.
    [default: None] [currently: None]
styler.latex.hrules : bool
    Whether to add horizontal rules on top and bottom and below the headers.
    [default: False] [currently: False]
styler.latex.multicol_align : {"r", "c", "l", "naive-l", "naive-r"}
    The specifier for horizontal alignment of sparsified LaTeX multicolumns. Pipe
    decorators can also be added to non-naive values to draw vertical
    rules, e.g. "\|r" will draw a rule on the left side of right aligned merged cells.
    [default: r] [currently: r]
styler.latex.multirow_align : {"c", "t", "b"}
    The specifier for vertical alignment of sparsified LaTeX multirows.
    [default: c] [currently: c]
styler.render.encoding : str
    The encoding used for output HTML and LaTeX files.
    [default: utf-8] [currently: utf-8]
styler.render.max_columns : int, optional
    The maximum number of columns that will be rendered. May still be reduced to
    satsify ``max_elements``, which takes precedence.
    [default: None] [currently: None]
styler.render.max_elements : int
    The maximum number of data-cell () elements that will be rendered before
    trimming will occur over columns, rows or both if needed.
    [default: 262144] [currently: 262144]
styler.render.max_rows : int, optional
    The maximum number of rows that will be rendered. May still be reduced to
    satsify ``max_elements``, which takes precedence.
    [default: None] [currently: None]
styler.render.repr : str
    Determine which output to use in Jupyter Notebook in {"html", "latex"}.
    [default: html] [currently: html]
styler.sparse.columns : bool
    Whether to sparsify the display of hierarchical columns. Setting to False will
    display each explicit level element in a hierarchical key for each column.
    [default: True] [currently: True]
styler.sparse.index : bool
    Whether to sparsify the display of a hierarchical index. Setting to False will
    display each explicit level element in a hierarchical key for each row.
    [default: True] [currently: True]

---->   DataFrame.info

--------------------------------------
ID: 1276 --> 1
In [24]: df = pd.DataFrame(np.random.randn(7, 2))

In [25]: pd.set_option("display.max_rows", 7)

In [26]: df
Out[26]: 
          0         1
0  0.469112 -0.282863
1 -1.509059 -1.135632
2  1.212112 -0.173215
3  0.119209 -1.044236
4 -0.861849 -2.104569
5 -0.494929  1.071804
6  0.721555 -0.706771

In [27]: pd.set_option("display.max_rows", 5)

In [28]: df
Out[28]: 
           0         1
0   0.469112 -0.282863
1  -1.509059 -1.135632
..       ...       ...
5  -0.494929  1.071804
6   0.721555 -0.706771

[7 rows x 2 columns]

In [29]: pd.reset_option("display.max_rows")

---->   pandas.DataFrame

--------------------------------------
ID: 1277 --> 1
In [30]: pd.set_option("display.max_rows", 8)

In [31]: pd.set_option("display.min_rows", 4)

# below max_rows -> all rows shown
In [32]: df = pd.DataFrame(np.random.randn(7, 2))

In [33]: df
Out[33]: 
          0         1
0 -1.039575  0.271860
1 -0.424972  0.567020
2  0.276232 -1.087401
3 -0.673690  0.113648
4 -1.478427  0.524988
5  0.404705  0.577046
6 -1.715002 -1.039268

# above max_rows -> only min_rows (4) rows shown
In [34]: df = pd.DataFrame(np.random.randn(9, 2))

In [35]: df
Out[35]: 
           0         1
0  -0.370647 -1.157892
1  -1.344312  0.844885
..       ...       ...
7   0.276662 -0.472035
8  -0.013960 -0.362543

[9 rows x 2 columns]

In [36]: pd.reset_option("display.max_rows")

In [37]: pd.reset_option("display.min_rows")

---->   pandas.DataFrame

--------------------------------------
ID: 1278 --> 1
In [38]: df = pd.DataFrame(np.random.randn(5, 10))

In [39]: pd.set_option("expand_frame_repr", True)

In [40]: df
Out[40]: 
          0         1         2  ...         7         8         9
0 -0.006154 -0.923061  0.895717  ...  1.340309 -1.170299 -0.226169
1  0.410835  0.813850  0.132003  ... -1.436737 -1.413681  1.607920
2  1.024180  0.569605  0.875906  ... -0.078638  0.545952 -1.219217
3 -1.226825  0.769804 -1.281247  ...  0.341734  0.959726 -1.110336
4 -0.619976  0.149748 -0.732339  ...  0.301624 -2.179861 -1.369849

[5 rows x 10 columns]

In [41]: pd.set_option("expand_frame_repr", False)

In [42]: df
Out[42]: 
          0         1         2         3         4         5         6         7         8         9
0 -0.006154 -0.923061  0.895717  0.805244 -1.206412  2.565646  1.431256  1.340309 -1.170299 -0.226169
1  0.410835  0.813850  0.132003 -0.827317 -0.076467 -1.187678  1.130127 -1.436737 -1.413681  1.607920
2  1.024180  0.569605  0.875906 -2.211372  0.974466 -2.006747 -0.410001 -0.078638  0.545952 -1.219217
3 -1.226825  0.769804 -1.281247 -0.727707 -0.121306 -0.097883  0.695775  0.341734  0.959726 -1.110336
4 -0.619976  0.149748 -0.732339  0.687738  0.176444  0.403310 -0.154951  0.301624 -2.179861 -1.369849

In [43]: pd.reset_option("expand_frame_repr")

---->   pandas.DataFrame

--------------------------------------
ID: 1279 --> 1
In [44]: df = pd.DataFrame(np.random.randn(10, 10))

In [45]: pd.set_option("display.max_rows", 5)

In [46]: pd.set_option("large_repr", "truncate")

In [47]: df
Out[47]: 
           0         1         2  ...         7         8         9
0  -0.954208  1.462696 -1.743161  ...  0.995761  2.396780  0.014871
1   3.357427 -0.317441 -1.236269  ...  0.380396  0.084844  0.432390
..       ...       ...       ...  ...       ...       ...       ...
8  -0.303421 -0.858447  0.306996  ...  0.476720  0.473424 -0.242861
9  -0.014805 -0.284319  0.650776  ...  1.613616  0.464000  0.227371

[10 rows x 10 columns]

In [48]: pd.set_option("large_repr", "info")

In [49]: df
Out[49]: 

RangeIndex: 10 entries, 0 to 9
Data columns (total 10 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       10 non-null     float64
 1   1       10 non-null     float64
 2   2       10 non-null     float64
 3   3       10 non-null     float64
 4   4       10 non-null     float64
 5   5       10 non-null     float64
 6   6       10 non-null     float64
 7   7       10 non-null     float64
 8   8       10 non-null     float64
 9   9       10 non-null     float64
dtypes: float64(10)
memory usage: 928.0 bytes

In [50]: pd.reset_option("large_repr")

In [51]: pd.reset_option("display.max_rows")

---->   pandas.DataFrame

--------------------------------------
ID: 1280 --> 1
In [52]: df = pd.DataFrame(
   ....:     np.array(
   ....:         [
   ....:             ["foo", "bar", "bim", "uncomfortably long string"],
   ....:             ["horse", "cow", "banana", "apple"],
   ....:         ]
   ....:     )
   ....: )
   ....: 

In [53]: pd.set_option("max_colwidth", 40)

In [54]: df
Out[54]: 
       0    1       2                          3
0    foo  bar     bim  uncomfortably long string
1  horse  cow  banana                      apple

In [55]: pd.set_option("max_colwidth", 6)

In [56]: df
Out[56]: 
       0    1      2      3
0    foo  bar    bim  un...
1  horse  cow  ba...  apple

In [57]: pd.reset_option("max_colwidth")

---->   pandas.DataFrame

--------------------------------------
ID: 1281 --> 2
In [58]: df = pd.DataFrame(np.random.randn(10, 10))

In [59]: pd.set_option("max_info_columns", 11)

In [60]: df.info()

RangeIndex: 10 entries, 0 to 9
Data columns (total 10 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       10 non-null     float64
 1   1       10 non-null     float64
 2   2       10 non-null     float64
 3   3       10 non-null     float64
 4   4       10 non-null     float64
 5   5       10 non-null     float64
 6   6       10 non-null     float64
 7   7       10 non-null     float64
 8   8       10 non-null     float64
 9   9       10 non-null     float64
dtypes: float64(10)
memory usage: 928.0 bytes

In [61]: pd.set_option("max_info_columns", 5)

In [62]: df.info()

RangeIndex: 10 entries, 0 to 9
Columns: 10 entries, 0 to 9
dtypes: float64(10)
memory usage: 928.0 bytes

In [63]: pd.reset_option("max_info_columns")

---->   pandas.DataFrame; DataFrame.info

--------------------------------------
ID: 1282 --> 2
In [64]: df = pd.DataFrame(np.random.choice([0, 1, np.nan], size=(10, 10)))

In [65]: df
Out[65]: 
     0    1    2    3    4    5    6    7    8    9
0  0.0  NaN  1.0  NaN  NaN  0.0  NaN  0.0  NaN  1.0
1  1.0  NaN  1.0  1.0  1.0  1.0  NaN  0.0  0.0  NaN
2  0.0  NaN  1.0  0.0  0.0  NaN  NaN  NaN  NaN  0.0
3  NaN  NaN  NaN  0.0  1.0  1.0  NaN  1.0  NaN  1.0
4  0.0  NaN  NaN  NaN  0.0  NaN  NaN  NaN  1.0  0.0
5  0.0  1.0  1.0  1.0  1.0  0.0  NaN  NaN  1.0  0.0
6  1.0  1.0  1.0  NaN  1.0  NaN  1.0  0.0  NaN  NaN
7  0.0  0.0  1.0  0.0  1.0  0.0  1.0  1.0  0.0  NaN
8  NaN  NaN  NaN  0.0  NaN  NaN  NaN  NaN  1.0  NaN
9  0.0  NaN  0.0  NaN  NaN  0.0  NaN  1.0  1.0  0.0

In [66]: pd.set_option("max_info_rows", 11)

In [67]: df.info()

RangeIndex: 10 entries, 0 to 9
Data columns (total 10 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       8 non-null      float64
 1   1       3 non-null      float64
 2   2       7 non-null      float64
 3   3       6 non-null      float64
 4   4       7 non-null      float64
 5   5       6 non-null      float64
 6   6       2 non-null      float64
 7   7       6 non-null      float64
 8   8       6 non-null      float64
 9   9       6 non-null      float64
dtypes: float64(10)
memory usage: 928.0 bytes

In [68]: pd.set_option("max_info_rows", 5)

In [69]: df.info()

RangeIndex: 10 entries, 0 to 9
Data columns (total 10 columns):
 #   Column  Dtype  
---  ------  -----  
 0   0       float64
 1   1       float64
 2   2       float64
 3   3       float64
 4   4       float64
 5   5       float64
 6   6       float64
 7   7       float64
 8   8       float64
 9   9       float64
dtypes: float64(10)
memory usage: 928.0 bytes

In [70]: pd.reset_option("max_info_rows")

---->   pandas.DataFrame; DataFrame.info

--------------------------------------
ID: 1283 --> 1
In [71]: df = pd.DataFrame(np.random.randn(5, 5))

In [72]: pd.set_option("display.precision", 7)

In [73]: df
Out[73]: 
           0          1          2          3          4
0 -1.1506406 -0.7983341 -0.5576966  0.3813531  1.3371217
1 -1.5310949  1.3314582 -0.5713290 -0.0266708 -1.0856630
2 -1.1147378 -0.0582158 -0.4867681  1.6851483  0.1125723
3 -1.4953086  0.8984347 -0.1482168 -1.5960698  0.1596530
4  0.2621358  0.0362196  0.1847350 -0.2550694 -0.2710197

In [74]: pd.set_option("display.precision", 4)

In [75]: df
Out[75]: 
        0       1       2       3       4
0 -1.1506 -0.7983 -0.5577  0.3814  1.3371
1 -1.5311  1.3315 -0.5713 -0.0267 -1.0857
2 -1.1147 -0.0582 -0.4868  1.6851  0.1126
3 -1.4953  0.8984 -0.1482 -1.5961  0.1597
4  0.2621  0.0362  0.1847 -0.2551 -0.2710

---->   pandas.DataFrame

--------------------------------------
ID: 1284 --> 1
In [76]: df = pd.DataFrame(np.random.randn(6, 6))

In [77]: pd.set_option("chop_threshold", 0)

In [78]: df
Out[78]: 
        0       1       2       3       4       5
0  1.2884  0.2946 -1.1658  0.8470 -0.6856  0.6091
1 -0.3040  0.6256 -0.0593  0.2497  1.1039 -1.0875
2  1.9980 -0.2445  0.1362  0.8863 -1.3507 -0.8863
3 -1.0133  1.9209 -0.3882 -2.3144  0.6655  0.4026
4  0.3996 -1.7660  0.8504  0.3881  0.9923  0.7441
5 -0.7398 -1.0549 -0.1796  0.6396  1.5850  1.9067

In [79]: pd.set_option("chop_threshold", 0.5)

In [80]: df
Out[80]: 
        0       1       2       3       4       5
0  1.2884  0.0000 -1.1658  0.8470 -0.6856  0.6091
1  0.0000  0.6256  0.0000  0.0000  1.1039 -1.0875
2  1.9980  0.0000  0.0000  0.8863 -1.3507 -0.8863
3 -1.0133  1.9209  0.0000 -2.3144  0.6655  0.0000
4  0.0000 -1.7660  0.8504  0.0000  0.9923  0.7441
5 -0.7398 -1.0549  0.0000  0.6396  1.5850  1.9067

In [81]: pd.reset_option("chop_threshold")

---->   pandas.DataFrame

--------------------------------------
ID: 1285 --> 1
In [82]: df = pd.DataFrame(
   ....:     np.array([np.random.randn(6), np.random.randint(1, 9, 6) * 0.1, np.zeros(6)]).T,
   ....:     columns=["A", "B", "C"],
   ....:     dtype="float",
   ....: )
   ....: 

In [83]: pd.set_option("colheader_justify", "right")

In [84]: df
Out[84]: 
        A    B    C
0  0.1040  0.1  0.0
1  0.1741  0.5  0.0
2 -0.4395  0.4  0.0
3 -0.7413  0.8  0.0
4 -0.0797  0.4  0.0
5 -0.9229  0.3  0.0

In [85]: pd.set_option("colheader_justify", "left")

In [86]: df
Out[86]: 
   A       B    C  
0  0.1040  0.1  0.0
1  0.1741  0.5  0.0
2 -0.4395  0.4  0.0
3 -0.7413  0.8  0.0
4 -0.0797  0.4  0.0
5 -0.9229  0.3  0.0

In [87]: pd.reset_option("colheader_justify")

---->   pandas.DataFrame

--------------------------------------
ID: 1286 --> 2
In [88]: import numpy as np

In [89]: pd.set_eng_float_format(accuracy=3, use_eng_prefix=True)

In [90]: s = pd.Series(np.random.randn(5), index=["a", "b", "c", "d", "e"])

In [91]: s / 1.0e3
Out[91]: 
a    303.638u
b   -721.084u
c   -622.696u
d    648.250u
e     -1.945m
dtype: float64

In [92]: s / 1.0e6
Out[92]: 
a    303.638n
b   -721.084n
c   -622.696n
d    648.250n
e     -1.945u
dtype: float64

---->   pandas.set_eng_float_format; pandas.Series

--------------------------------------
ID: 1287 --> 1
In [93]: df = pd.DataFrame({"国籍": ["UK", "日本"], "名前": ["Alice", "しのぶ"]})

In [94]: df
Out[94]: 
   国籍     名前
0  UK  Alice
1  日本    しのぶ

---->   pandas.DataFrame

--------------------------------------
ID: 1289 --> 1
In [97]: df = pd.DataFrame({"a": ["xxx", "¡¡"], "b": ["yyy", "¡¡"]})

In [98]: df
Out[98]: 
     a    b
0  xxx  yyy
1   ¡¡   ¡¡

---->   pandas.DataFrame

--------------------------------------
ID: 1293 --> 1
In [1]: speeds = pd.DataFrame(
   ...:     [
   ...:         ("bird", "Falconiformes", 389.0),
   ...:         ("bird", "Psittaciformes", 24.0),
   ...:         ("mammal", "Carnivora", 80.2),
   ...:         ("mammal", "Primates", np.nan),
   ...:         ("mammal", "Carnivora", 58),
   ...:     ],
   ...:     index=["falcon", "parrot", "lion", "monkey", "leopard"],
   ...:     columns=("class", "order", "max_speed"),
   ...: )
   ...: 

In [2]: speeds
Out[2]: 
          class           order  max_speed
falcon     bird   Falconiformes      389.0
parrot     bird  Psittaciformes       24.0
lion     mammal       Carnivora       80.2
monkey   mammal        Primates        NaN
leopard  mammal       Carnivora       58.0

# default is axis=0
In [3]: grouped = speeds.groupby("class")

In [4]: grouped = speeds.groupby("order", axis="columns")

In [5]: grouped = speeds.groupby(["class", "order"])

---->   pandas.DataFrame

--------------------------------------
ID: 1294 --> 1
In [6]: df = pd.DataFrame(
   ...:     {
   ...:         "A": ["foo", "bar", "foo", "bar", "foo", "bar", "foo", "foo"],
   ...:         "B": ["one", "one", "two", "three", "two", "two", "one", "three"],
   ...:         "C": np.random.randn(8),
   ...:         "D": np.random.randn(8),
   ...:     }
   ...: )
   ...: 

In [7]: df
Out[7]: 
     A      B         C         D
0  foo    one  0.469112 -0.861849
1  bar    one -0.282863 -2.104569
2  foo    two -1.509059 -0.494929
3  bar  three -1.135632  1.071804
4  foo    two  1.212112  0.721555
5  bar    two -0.173215 -0.706771
6  foo    one  0.119209 -1.039575
7  foo  three -1.044236  0.271860

---->   pandas.DataFrame

--------------------------------------
ID: 1295 --> 1
In [8]: grouped = df.groupby("A")

In [9]: grouped = df.groupby(["A", "B"])

---->   DataFrame.groupby

--------------------------------------
ID: 1296 --> 1
In [10]: df2 = df.set_index(["A", "B"])

In [11]: grouped = df2.groupby(level=df2.index.names.difference(["B"]))

In [12]: grouped.sum()
Out[12]: 
            C         D
A                      
bar -1.591710 -1.739537
foo -0.752861 -1.402938

---->   DataFrame.groupby

--------------------------------------
ID: 1297 --> 1
In [13]: def get_letter_type(letter):
   ....:     if letter.lower() in 'aeiou':
   ....:         return 'vowel'
   ....:     else:
   ....:         return 'consonant'
   ....: 

In [14]: grouped = df.groupby(get_letter_type, axis=1)

---->   DataFrame.groupby

--------------------------------------
ID: 1298 --> 2
In [15]: lst = [1, 2, 3, 1, 2, 3]

In [16]: s = pd.Series([1, 2, 3, 10, 20, 30], lst)

In [17]: grouped = s.groupby(level=0)

In [18]: grouped.first()
Out[18]: 
1    1
2    2
3    3
dtype: int64

In [19]: grouped.last()
Out[19]: 
1    10
2    20
3    30
dtype: int64

In [20]: grouped.sum()
Out[20]: 
1    11
2    22
3    33
dtype: int64

---->   pandas.Series; Series.groupby

--------------------------------------
ID: 1299 --> 2
In [21]: df2 = pd.DataFrame({"X": ["B", "B", "A", "A"], "Y": [1, 2, 3, 4]})

In [22]: df2.groupby(["X"]).sum()
Out[22]: 
   Y
X   
A  7
B  3

In [23]: df2.groupby(["X"], sort=False).sum()
Out[23]: 
   Y
X   
B  3
A  7

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 1300 --> 2
In [24]: df3 = pd.DataFrame({"X": ["A", "B", "A", "B"], "Y": [1, 4, 3, 2]})

In [25]: df3.groupby(["X"]).get_group("A")
Out[25]: 
   X  Y
0  A  1
2  A  3

In [26]: df3.groupby(["X"]).get_group("B")
Out[26]: 
   X  Y
1  B  4
3  B  2

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 1301 --> 1
In [27]: df_list = [[1, 2, 3], [1, None, 4], [2, 1, 3], [1, 2, 2]]

In [28]: df_dropna = pd.DataFrame(df_list, columns=["a", "b", "c"])

In [29]: df_dropna
Out[29]: 
   a    b  c
0  1  2.0  3
1  1  NaN  4
2  2  1.0  3
3  1  2.0  2

---->   pandas.DataFrame

--------------------------------------
ID: 1302 --> 1
# Default ``dropna`` is set to True, which will exclude NaNs in keys
In [30]: df_dropna.groupby(by=["b"], dropna=True).sum()
Out[30]: 
     a  c
b        
1.0  2  3
2.0  2  5

# In order to allow NaN in keys, set ``dropna`` to False
In [31]: df_dropna.groupby(by=["b"], dropna=False).sum()
Out[31]: 
     a  c
b        
1.0  2  3
2.0  2  5
NaN  1  4

---->   DataFrame.groupby

--------------------------------------
ID: 1303 --> 1
In [32]: df.groupby("A").groups
Out[32]: {'bar': [1, 3, 5], 'foo': [0, 2, 4, 6, 7]}

In [33]: df.groupby(get_letter_type, axis=1).groups
Out[33]: {'consonant': ['B', 'C', 'D'], 'vowel': ['A']}

---->   DataFrame.groupby

--------------------------------------
ID: 1304 --> 1
In [34]: grouped = df.groupby(["A", "B"])

In [35]: grouped.groups
Out[35]: {('bar', 'one'): [1], ('bar', 'three'): [3], ('bar', 'two'): [5], ('foo', 'one'): [0, 6], ('foo', 'three'): [7], ('foo', 'two'): [2, 4]}

In [36]: len(grouped)
Out[36]: 6

---->   DataFrame.groupby

--------------------------------------
ID: 1305 --> 1
In [37]: df
Out[37]: 
               height      weight  gender
2000-01-01  42.849980  157.500553    male
2000-01-02  49.607315  177.340407    male
2000-01-03  56.293531  171.524640    male
2000-01-04  48.421077  144.251986  female
2000-01-05  46.556882  152.526206    male
2000-01-06  68.448851  168.272968  female
2000-01-07  70.757698  136.431469    male
2000-01-08  58.909500  176.499753  female
2000-01-09  76.435631  174.094104  female
2000-01-10  45.306120  177.540920    male

In [38]: gb = df.groupby("gender")

---->   DataFrame.groupby

--------------------------------------
ID: 1306 --> 2
In [40]: arrays = [
   ....:     ["bar", "bar", "baz", "baz", "foo", "foo", "qux", "qux"],
   ....:     ["one", "two", "one", "two", "one", "two", "one", "two"],
   ....: ]
   ....: 

In [41]: index = pd.MultiIndex.from_arrays(arrays, names=["first", "second"])

In [42]: s = pd.Series(np.random.randn(8), index=index)

In [43]: s
Out[43]: 
first  second
bar    one      -0.919854
       two      -0.042379
baz    one       1.247642
       two      -0.009920
foo    one       0.290213
       two       0.495767
qux    one       0.362949
       two       1.548106
dtype: float64

---->   pandas.MultiIndex; pandas.Series

--------------------------------------
ID: 1307 --> 1
In [44]: grouped = s.groupby(level=0)

In [45]: grouped.sum()
Out[45]: 
first
bar   -0.962232
baz    1.237723
foo    0.785980
qux    1.911055
dtype: float64

---->   Series.groupby

--------------------------------------
ID: 1308 --> 1
In [46]: s.groupby(level="second").sum()
Out[46]: 
second
one    0.980950
two    1.991575
dtype: float64

---->   Series.groupby

--------------------------------------
ID: 1309 --> 1
In [47]: s
Out[47]: 
first  second  third
bar    doo     one     -1.131345
               two     -0.089329
baz    bee     one      0.337863
               two     -0.945867
foo    bop     one     -0.932132
               two      1.956030
qux    bop     one      0.017587
               two     -0.016692
dtype: float64

In [48]: s.groupby(level=["first", "second"]).sum()
Out[48]: 
first  second
bar    doo      -1.220674
baz    bee      -0.608004
foo    bop       1.023898
qux    bop       0.000895
dtype: float64

---->   Series.groupby

--------------------------------------
ID: 1310 --> 1
In [49]: s.groupby(["first", "second"]).sum()
Out[49]: 
first  second
bar    doo      -1.220674
baz    bee      -0.608004
foo    bop       1.023898
qux    bop       0.000895
dtype: float64

---->   Series.groupby

--------------------------------------
ID: 1311 --> 2
In [50]: arrays = [
   ....:     ["bar", "bar", "baz", "baz", "foo", "foo", "qux", "qux"],
   ....:     ["one", "two", "one", "two", "one", "two", "one", "two"],
   ....: ]
   ....: 

In [51]: index = pd.MultiIndex.from_arrays(arrays, names=["first", "second"])

In [52]: df = pd.DataFrame({"A": [1, 1, 1, 1, 2, 2, 3, 3], "B": np.arange(8)}, index=index)

In [53]: df
Out[53]: 
              A  B
first second      
bar   one     1  0
      two     1  1
baz   one     1  2
      two     1  3
foo   one     2  4
      two     2  5
qux   one     3  6
      two     3  7

---->   pandas.MultiIndex; pandas.DataFrame

--------------------------------------
ID: 1312 --> 2
In [54]: df.groupby([pd.Grouper(level=1), "A"]).sum()
Out[54]: 
          B
second A   
one    1  2
       2  4
       3  6
two    1  4
       2  5
       3  7

---->   DataFrame.groupby; pandas.Grouper

--------------------------------------
ID: 1313 --> 2
In [55]: df.groupby([pd.Grouper(level="second"), "A"]).sum()
Out[55]: 
          B
second A   
one    1  2
       2  4
       3  6
two    1  4
       2  5
       3  7

---->   DataFrame.groupby; pandas.Grouper

--------------------------------------
ID: 1314 --> 1
In [56]: df.groupby(["second", "A"]).sum()
Out[56]: 
          B
second A   
one    1  2
       2  4
       3  6
two    1  4
       2  5
       3  7

---->   DataFrame.groupby

--------------------------------------
ID: 1315 --> 2
In [57]: df = pd.DataFrame(
   ....:     {
   ....:         "A": ["foo", "bar", "foo", "bar", "foo", "bar", "foo", "foo"],
   ....:         "B": ["one", "one", "two", "three", "two", "two", "one", "three"],
   ....:         "C": np.random.randn(8),
   ....:         "D": np.random.randn(8),
   ....:     }
   ....: )
   ....: 

In [58]: df
Out[58]: 
     A      B         C         D
0  foo    one -0.575247  1.346061
1  bar    one  0.254161  1.511763
2  foo    two -1.143704  1.627081
3  bar  three  0.215897 -0.990582
4  foo    two  1.193555 -0.441652
5  bar    two -0.077118  1.211526
6  foo    one -0.408530  0.268520
7  foo  three -0.862495  0.024580

In [59]: grouped = df.groupby(["A"])

In [60]: grouped_C = grouped["C"]

In [61]: grouped_D = grouped["D"]

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 1317 --> 1
In [63]: grouped = df.groupby('A')

In [64]: for name, group in grouped:
   ....:     print(name)
   ....:     print(group)
   ....: 
bar
     A      B         C         D
1  bar    one  0.254161  1.511763
3  bar  three  0.215897 -0.990582
5  bar    two -0.077118  1.211526
foo
     A      B         C         D
0  foo    one -0.575247  1.346061
2  foo    two -1.143704  1.627081
4  foo    two  1.193555 -0.441652
6  foo    one -0.408530  0.268520
7  foo  three -0.862495  0.024580

---->   DataFrame.groupby

--------------------------------------
ID: 1318 --> 1
In [65]: for name, group in df.groupby(['A', 'B']):
   ....:     print(name)
   ....:     print(group)
   ....: 
('bar', 'one')
     A    B         C         D
1  bar  one  0.254161  1.511763
('bar', 'three')
     A      B         C         D
3  bar  three  0.215897 -0.990582
('bar', 'two')
     A    B         C         D
5  bar  two -0.077118  1.211526
('foo', 'one')
     A    B         C         D
0  foo  one -0.575247  1.346061
6  foo  one -0.408530  0.268520
('foo', 'three')
     A      B         C        D
7  foo  three -0.862495  0.02458
('foo', 'two')
     A    B         C         D
2  foo  two -1.143704  1.627081
4  foo  two  1.193555 -0.441652

---->   DataFrame.groupby

--------------------------------------
ID: 1320 --> 1
In [67]: df.groupby(["A", "B"]).get_group(("bar", "one"))
Out[67]: 
     A    B         C         D
1  bar  one  0.254161  1.511763

---->   DataFrame.groupby

--------------------------------------
ID: 1321 --> 1
In [68]: animals = pd.DataFrame(
   ....:     {
   ....:         "kind": ["cat", "dog", "cat", "dog"],
   ....:         "height": [9.1, 6.0, 9.5, 34.0],
   ....:         "weight": [7.9, 7.5, 9.9, 198.0],
   ....:     }
   ....: )
   ....: 

In [69]: animals
Out[69]: 
  kind  height  weight
0  cat     9.1     7.9
1  dog     6.0     7.5
2  cat     9.5     9.9
3  dog    34.0   198.0

In [70]: animals.groupby("kind").sum()
Out[70]: 
      height  weight
kind                
cat     18.6    17.8
dog     40.0   205.5

---->   pandas.DataFrame

--------------------------------------
ID: 1323 --> 1
In [72]: df.groupby("A")[["C", "D"]].max()
Out[72]: 
            C         D
A                      
bar  0.254161  1.511763
foo  1.193555  1.627081

In [73]: df.groupby(["A", "B"]).mean()
Out[73]: 
                  C         D
A   B                        
bar one    0.254161  1.511763
    three  0.215897 -0.990582
    two   -0.077118  1.211526
foo one   -0.491888  0.807291
    three -0.862495  0.024580
    two    0.024925  0.592714

---->   DataFrame.groupby

--------------------------------------
ID: 1324 --> 1
In [74]: grouped = df.groupby(["A", "B"])

In [75]: grouped.size()
Out[75]: 
A    B    
bar  one      1
     three    1
     two      1
foo  one      2
     three    1
     two      2
dtype: int64

---->   DataFrame.groupby

--------------------------------------
ID: 1326 --> 2
In [77]: ll = [['foo', 1], ['foo', 2], ['foo', 2], ['bar', 1], ['bar', 1]]

In [78]: df4 = pd.DataFrame(ll, columns=["A", "B"])

In [79]: df4
Out[79]: 
     A  B
0  foo  1
1  foo  2
2  foo  2
3  bar  1
4  bar  1

In [80]: df4.groupby("A")["B"].nunique()
Out[80]: 
A
bar    1
foo    2
Name: B, dtype: int64

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 1327 --> 1
In [81]: grouped = df.groupby("A")

In [82]: grouped[["C", "D"]].aggregate("sum")
Out[82]: 
            C         D
A                      
bar  0.392940  1.732707
foo -1.796421  2.824590

In [83]: grouped = df.groupby(["A", "B"])

In [84]: grouped.agg("sum")
Out[84]: 
                  C         D
A   B                        
bar one    0.254161  1.511763
    three  0.215897 -0.990582
    two   -0.077118  1.211526
foo one   -0.983776  1.614581
    three -0.862495  0.024580
    two    0.049851  1.185429

---->   DataFrame.groupby

--------------------------------------
ID: 1328 --> 1
In [85]: grouped = df.groupby(["A", "B"], as_index=False)

In [86]: grouped.agg("sum")
Out[86]: 
     A      B         C         D
0  bar    one  0.254161  1.511763
1  bar  three  0.215897 -0.990582
2  bar    two -0.077118  1.211526
3  foo    one -0.983776  1.614581
4  foo  three -0.862495  0.024580
5  foo    two  0.049851  1.185429

In [87]: df.groupby("A", as_index=False)[["C", "D"]].agg("sum")
Out[87]: 
     A         C         D
0  bar  0.392940  1.732707
1  foo -1.796421  2.824590

---->   DataFrame.groupby

--------------------------------------
ID: 1329 --> 1
In [88]: df.groupby(["A", "B"]).agg("sum").reset_index()
Out[88]: 
     A      B         C         D
0  bar    one  0.254161  1.511763
1  bar  three  0.215897 -0.990582
2  bar    two -0.077118  1.211526
3  foo    one -0.983776  1.614581
4  foo  three -0.862495  0.024580
5  foo    two  0.049851  1.185429

---->   DataFrame.groupby

--------------------------------------
ID: 1331 --> 1
In [91]: animals.groupby("kind")[["height"]].agg(lambda x: x.astype(int).sum())
Out[91]: 
      height
kind        
cat       18
dog       40

---->   Series.astype

--------------------------------------
ID: 1332 --> 1
In [92]: grouped = df.groupby("A")

In [93]: grouped["C"].agg(["sum", "mean", "std"])
Out[93]: 
          sum      mean       std
A                                
bar  0.392940  0.130980  0.181231
foo -1.796421 -0.359284  0.912265

---->   DataFrame.groupby

--------------------------------------
ID: 1337 --> 4
In [98]: grouped["C"].agg([lambda x: x.max() - x.min(), lambda x: x.median() - x.mean()])
Out[98]: 
       
A                          
bar    0.331279    0.084917
foo    2.337259   -0.215962

---->   Series.max; Series.min; Series.median; Series.mean

--------------------------------------
ID: 1338 --> 1
In [99]: animals
Out[99]: 
  kind  height  weight
0  cat     9.1     7.9
1  dog     6.0     7.5
2  cat     9.5     9.9
3  dog    34.0   198.0

In [100]: animals.groupby("kind").agg(
   .....:     min_height=pd.NamedAgg(column="height", aggfunc="min"),
   .....:     max_height=pd.NamedAgg(column="height", aggfunc="max"),
   .....:     average_weight=pd.NamedAgg(column="weight", aggfunc="mean"),
   .....: )
   .....: 
Out[100]: 
      min_height  max_height  average_weight
kind                                        
cat          9.1         9.5            8.90
dog          6.0        34.0          102.75

---->   pandas.NamedAgg

--------------------------------------
ID: 1340 --> 1
In [102]: animals.groupby("kind").agg(
   .....:     **{
   .....:         "total weight": pd.NamedAgg(column="weight", aggfunc="sum")
   .....:     }
   .....: )
   .....: 
Out[102]: 
      total weight
kind              
cat           17.8
dog          205.5

---->   pandas.NamedAgg

--------------------------------------
ID: 1347 --> 7
In [118]: index = pd.date_range("10/1/1999", periods=1100)

In [119]: ts = pd.Series(np.random.normal(0.5, 2, 1100), index)

In [120]: ts = ts.rolling(window=100, min_periods=100).mean().dropna()

In [121]: ts.head()
Out[121]: 
2000-01-08    0.779333
2000-01-09    0.778852
2000-01-10    0.786476
2000-01-11    0.782797
2000-01-12    0.798110
Freq: D, dtype: float64

In [122]: ts.tail()
Out[122]: 
2002-09-30    0.660294
2002-10-01    0.631095
2002-10-02    0.673601
2002-10-03    0.709213
2002-10-04    0.719369
Freq: D, dtype: float64

In [123]: transformed = ts.groupby(lambda x: x.year).transform(
   .....:     lambda x: (x - x.mean()) / x.std()
   .....: )
   .....: 

---->   pandas.Series; Series.rolling; Series.head; Series.tail; Series.groupby; Series.mean; Series.std

--------------------------------------
ID: 1348 --> 1
# Original Data
In [124]: grouped = ts.groupby(lambda x: x.year)

In [125]: grouped.mean()
Out[125]: 
2000    0.442441
2001    0.526246
2002    0.459365
dtype: float64

In [126]: grouped.std()
Out[126]: 
2000    0.131752
2001    0.210945
2002    0.128753
dtype: float64

# Transformed Data
In [127]: grouped_trans = transformed.groupby(lambda x: x.year)

In [128]: grouped_trans.mean()
Out[128]: 
2000   -4.870756e-16
2001   -1.545187e-16
2002    4.136282e-16
dtype: float64

In [129]: grouped_trans.std()
Out[129]: 
2000    1.0
2001    1.0
2002    1.0
dtype: float64

---->   Series.groupby

--------------------------------------
ID: 1349 --> 2
In [130]: compare = pd.DataFrame({"Original": ts, "Transformed": transformed})

In [131]: compare.plot()
Out[131]: 

---->   pandas.DataFrame; DataFrame.plot

--------------------------------------
ID: 1350 --> 3
In [132]: ts.groupby(lambda x: x.year).transform(lambda x: x.max() - x.min())
Out[132]: 
2000-01-08    0.623893
2000-01-09    0.623893
2000-01-10    0.623893
2000-01-11    0.623893
2000-01-12    0.623893
                ...   
2002-09-30    0.558275
2002-10-01    0.558275
2002-10-02    0.558275
2002-10-03    0.558275
2002-10-04    0.558275
Freq: D, Length: 1001, dtype: float64

---->   Series.groupby; Series.max; Series.min

--------------------------------------
ID: 1351 --> 1
In [133]: data_df
Out[133]: 
            A         B         C
0    1.539708 -1.166480  0.533026
1    1.302092 -0.505754       NaN
2   -0.371983  1.104803 -0.651520
3   -1.309622  1.118697 -1.161657
4   -1.924296  0.396437  0.812436
..        ...       ...       ...
995 -0.093110  0.683847 -0.774753
996 -0.185043  1.438572       NaN
997 -0.394469 -0.642343  0.011374
998 -1.174126  1.857148       NaN
999  0.234564  0.517098  0.393534

[1000 rows x 3 columns]

In [134]: countries = np.array(["US", "UK", "GR", "JP"])

In [135]: key = countries[np.random.randint(0, 4, 1000)]

In [136]: grouped = data_df.groupby(key)

# Non-NA count in each group
In [137]: grouped.count()
Out[137]: 
      A    B    C
GR  209  217  189
JP  240  255  217
UK  216  231  193
US  239  250  217

In [138]: transformed = grouped.transform(lambda x: x.fillna(x.mean()))

---->   Series.mean

--------------------------------------
ID: 1353 --> 5
# ts.groupby(lambda x: x.year).transform(
#     lambda x: (x - x.mean()) / x.std()
# )
In [145]: grouped = ts.groupby(lambda x: x.year)

In [146]: result = (ts - grouped.transform("mean")) / grouped.transform("std")

# ts.groupby(lambda x: x.year).transform(lambda x: x.max() - x.min())
In [147]: grouped = ts.groupby(lambda x: x.year)

In [148]: result = grouped.transform("max") - grouped.transform("min")

# grouped = data_df.groupby(key)
# grouped.transform(lambda x: x.fillna(x.mean()))
In [149]: grouped = data_df.groupby(key)

In [150]: result = data_df.fillna(grouped.transform("mean"))

---->   Series.groupby; Series.mean; Series.std; Series.max; Series.min

--------------------------------------
ID: 1354 --> 2
In [151]: df_re = pd.DataFrame({"A": [1] * 10 + [5] * 10, "B": np.arange(20)})

In [152]: df_re
Out[152]: 
    A   B
0   1   0
1   1   1
2   1   2
3   1   3
4   1   4
.. ..  ..
15  5  15
16  5  16
17  5  17
18  5  18
19  5  19

[20 rows x 2 columns]

In [153]: df_re.groupby("A").rolling(4).B.mean()
Out[153]: 
A    
1  0      NaN
   1      NaN
   2      NaN
   3      1.5
   4      2.5
         ... 
5  15    13.5
   16    14.5
   17    15.5
   18    16.5
   19    17.5
Name: B, Length: 20, dtype: float64

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 1355 --> 1
In [154]: df_re.groupby("A").expanding().sum()
Out[154]: 
          B
A          
1 0     0.0
  1     1.0
  2     3.0
  3     6.0
  4    10.0
...     ...
5 15   75.0
  16   91.0
  17  108.0
  18  126.0
  19  145.0

[20 rows x 1 columns]

---->   DataFrame.groupby

--------------------------------------
ID: 1356 --> 2
In [155]: df_re = pd.DataFrame(
   .....:     {
   .....:         "date": pd.date_range(start="2016-01-01", periods=4, freq="W"),
   .....:         "group": [1, 1, 2, 2],
   .....:         "val": [5, 6, 7, 8],
   .....:     }
   .....: ).set_index("date")
   .....: 

In [156]: df_re
Out[156]: 
            group  val
date                  
2016-01-03      1    5
2016-01-10      1    6
2016-01-17      2    7
2016-01-24      2    8

In [157]: df_re.groupby("group").resample("1D").ffill()
Out[157]: 
                  group  val
group date                  
1     2016-01-03      1    5
      2016-01-04      1    5
      2016-01-05      1    5
      2016-01-06      1    5
      2016-01-07      1    5
...                 ...  ...
2     2016-01-20      2    7
      2016-01-21      2    7
      2016-01-22      2    7
      2016-01-23      2    7
      2016-01-24      2    8

[16 rows x 2 columns]

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 1359 --> 1
In [161]: product_volumes = pd.DataFrame(
   .....:     {
   .....:         "group": list("xxxxyyy"),
   .....:         "product": list("abcdefg"),
   .....:         "volume": [10, 30, 20, 15, 40, 10, 20],
   .....:     }
   .....: )
   .....: 

In [162]: product_volumes
Out[162]: 
  group product  volume
0     x       a      10
1     x       b      30
2     x       c      20
3     x       d      15
4     y       e      40
5     y       f      10
6     y       g      20

# Sort by volume to select the largest products first
In [163]: product_volumes = product_volumes.sort_values("volume", ascending=False)

In [164]: grouped = product_volumes.groupby("group")["volume"]

In [165]: cumpct = grouped.cumsum() / grouped.transform("sum")

In [166]: cumpct
Out[166]: 
4    0.571429
1    0.400000
2    0.666667
6    0.857143
3    0.866667
0    1.000000
5    1.000000
Name: volume, dtype: float64

In [167]: significant_products = product_volumes[cumpct <= 0.9]

In [168]: significant_products.sort_values(["group", "product"])
Out[168]: 
  group product  volume
1     x       b      30
2     x       c      20
3     x       d      15
4     y       e      40
6     y       g      20

---->   pandas.DataFrame

--------------------------------------
ID: 1360 --> 3
In [169]: sf = pd.Series([1, 1, 2, 3, 3, 3])

In [170]: sf.groupby(sf).filter(lambda x: x.sum() > 2)
Out[170]: 
3    3
4    3
5    3
dtype: int64

---->   pandas.Series; Series.groupby; Series.sum

--------------------------------------
ID: 1361 --> 2
In [171]: dff = pd.DataFrame({"A": np.arange(8), "B": list("aabbbbcc")})

In [172]: dff.groupby("B").filter(lambda x: len(x) > 2)
Out[172]: 
   A  B
2  2  b
3  3  b
4  4  b
5  5  b

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 1362 --> 1
In [173]: dff.groupby("B").filter(lambda x: len(x) > 2, dropna=False)
Out[173]: 
     A    B
0  NaN  NaN
1  NaN  NaN
2  2.0    b
3  3.0    b
4  4.0    b
5  5.0    b
6  NaN  NaN
7  NaN  NaN

---->   DataFrame.groupby

--------------------------------------
ID: 1363 --> 1
In [174]: dff["C"] = np.arange(8)

In [175]: dff.groupby("B").filter(lambda x: len(x["C"]) > 2)
Out[175]: 
   A  B  C
2  2  b  2
3  3  b  3
4  4  b  4
5  5  b  5

---->   DataFrame.groupby

--------------------------------------
ID: 1364 --> 2
In [176]: df
Out[176]: 
     A      B         C         D
0  foo    one -0.575247  1.346061
1  bar    one  0.254161  1.511763
2  foo    two -1.143704  1.627081
3  bar  three  0.215897 -0.990582
4  foo    two  1.193555 -0.441652
5  bar    two -0.077118  1.211526
6  foo    one -0.408530  0.268520
7  foo  three -0.862495  0.024580

In [177]: grouped = df.groupby("A")

# could also just call .describe()
In [178]: grouped["C"].apply(lambda x: x.describe())
Out[178]: 
A         
bar  count    3.000000
     mean     0.130980
     std      0.181231
     min     -0.077118
     25%      0.069390
                ...   
foo  min     -1.143704
     25%     -0.862495
     50%     -0.575247
     75%     -0.408530
     max      1.193555
Name: C, Length: 16, dtype: float64

---->   DataFrame.groupby; Series.describe

--------------------------------------
ID: 1365 --> 2
In [179]: grouped = df.groupby('A')['C']

In [180]: def f(group):
   .....:     return pd.DataFrame({'original': group,
   .....:                          'demeaned': group - group.mean()})
   .....: 

In [181]: grouped.apply(f)
Out[181]: 
       original  demeaned
A                        
bar 1  0.254161  0.123181
    3  0.215897  0.084917
    5 -0.077118 -0.208098
foo 0 -0.575247 -0.215962
    2 -1.143704 -0.784420
    4  1.193555  1.552839
    6 -0.408530 -0.049245
    7 -0.862495 -0.503211

---->   DataFrame.groupby; pandas.DataFrame

--------------------------------------
ID: 1366 --> 1
In [182]: def f(x):
   .....:     return pd.Series([x, x ** 2], index=["x", "x^2"])
   .....: 

In [183]: s = pd.Series(np.random.rand(5))

In [184]: s
Out[184]: 
0    0.582898
1    0.098352
2    0.001438
3    0.009420
4    0.815826
dtype: float64

In [185]: s.apply(f)
Out[185]: 
          x       x^2
0  0.582898  0.339770
1  0.098352  0.009673
2  0.001438  0.000002
3  0.009420  0.000089
4  0.815826  0.665572

---->   pandas.Series

--------------------------------------
ID: 1367 --> 1
In [186]: df.groupby("A", group_keys=True).apply(lambda x: x)
Out[186]: 
         A      B         C         D
A                                    
bar 1  bar    one  0.254161  1.511763
    3  bar  three  0.215897 -0.990582
    5  bar    two -0.077118  1.211526
foo 0  foo    one -0.575247  1.346061
    2  foo    two -1.143704  1.627081
    4  foo    two  1.193555 -0.441652
    6  foo    one -0.408530  0.268520
    7  foo  three -0.862495  0.024580

---->   DataFrame.groupby

--------------------------------------
ID: 1368 --> 1
In [187]: df.groupby("A", group_keys=False).apply(lambda x: x)
Out[187]: 
     A      B         C         D
0  foo    one -0.575247  1.346061
1  bar    one  0.254161  1.511763
2  foo    two -1.143704  1.627081
3  bar  three  0.215897 -0.990582
4  foo    two  1.193555 -0.441652
5  bar    two -0.077118  1.211526
6  foo    one -0.408530  0.268520
7  foo  three -0.862495  0.024580

---->   DataFrame.groupby

--------------------------------------
ID: 1369 --> 1
In [189]: df.groupby("A").std(numeric_only=True)
Out[189]: 
            C         D
A                      
bar  0.181231  1.366330
foo  0.912265  0.884785

---->   DataFrame.groupby

--------------------------------------
ID: 1370 --> 1
In [190]: from decimal import Decimal

In [191]: df_dec = pd.DataFrame(
   .....:     {
   .....:         "id": [1, 2, 1, 2],
   .....:         "int_column": [1, 2, 3, 4],
   .....:         "dec_column": [
   .....:             Decimal("0.50"),
   .....:             Decimal("0.15"),
   .....:             Decimal("0.25"),
   .....:             Decimal("0.40"),
   .....:         ],
   .....:     }
   .....: )
   .....: 

# Decimal columns can be sum'd explicitly by themselves...
In [192]: df_dec.groupby(["id"])[["dec_column"]].sum()
Out[192]: 
   dec_column
id           
1        0.75
2        0.55

# ...but cannot be combined with standard data types or they will be excluded
In [193]: df_dec.groupby(["id"])[["int_column", "dec_column"]].sum()
Out[193]: 
    int_column dec_column
id                       
1            4       0.75
2            6       0.55

# Use .agg function to aggregate over standard and "nuisance" data types
# at the same time
In [194]: df_dec.groupby(["id"]).agg({"int_column": "sum", "dec_column": "sum"})
Out[194]: 
    int_column dec_column
id                       
1            4       0.75
2            6       0.55

---->   pandas.DataFrame

--------------------------------------
ID: 1371 --> 2
In [195]: pd.Series([1, 1, 1]).groupby(
   .....:     pd.Categorical(["a", "a", "a"], categories=["a", "b"]), observed=False
   .....: ).count()
   .....: 
Out[195]: 
a    3
b    0
dtype: int64

---->   pandas.Series; pandas.Categorical

--------------------------------------
ID: 1372 --> 2
In [196]: pd.Series([1, 1, 1]).groupby(
   .....:     pd.Categorical(["a", "a", "a"], categories=["a", "b"]), observed=True
   .....: ).count()
   .....: 
Out[196]: 
a    3
dtype: int64

---->   pandas.Series; pandas.Categorical

--------------------------------------
ID: 1373 --> 2
In [197]: s = (
   .....:     pd.Series([1, 1, 1])
   .....:     .groupby(pd.Categorical(["a", "a", "a"], categories=["a", "b"]), observed=False)
   .....:     .count()
   .....: )
   .....: 

In [198]: s.index.dtype
Out[198]: CategoricalDtype(categories=['a', 'b'], ordered=False)

---->   pandas.Series; pandas.Categorical

--------------------------------------
ID: 1374 --> 3
In [199]: data = pd.Series(np.random.randn(100))

In [200]: factor = pd.qcut(data, [0, 0.25, 0.5, 0.75, 1.0])

In [201]: data.groupby(factor).mean()
Out[201]: 
(-2.784, -0.41]   -1.196181
(-0.41, 0.0754]   -0.127244
(0.0754, 0.795]    0.408266
(0.795, 2.821]     1.357293
dtype: float64

---->   pandas.Series; pandas.qcut; Series.groupby

--------------------------------------
ID: 1375 --> 1
In [202]: import datetime

In [203]: df = pd.DataFrame(
   .....:     {
   .....:         "Branch": "A A A A A A A B".split(),
   .....:         "Buyer": "Carl Mark Carl Carl Joe Joe Joe Carl".split(),
   .....:         "Quantity": [1, 3, 5, 1, 8, 1, 9, 3],
   .....:         "Date": [
   .....:             datetime.datetime(2013, 1, 1, 13, 0),
   .....:             datetime.datetime(2013, 1, 1, 13, 5),
   .....:             datetime.datetime(2013, 10, 1, 20, 0),
   .....:             datetime.datetime(2013, 10, 2, 10, 0),
   .....:             datetime.datetime(2013, 10, 1, 20, 0),
   .....:             datetime.datetime(2013, 10, 2, 10, 0),
   .....:             datetime.datetime(2013, 12, 2, 12, 0),
   .....:             datetime.datetime(2013, 12, 2, 14, 0),
   .....:         ],
   .....:     }
   .....: )
   .....: 

In [204]: df
Out[204]: 
  Branch Buyer  Quantity                Date
0      A  Carl         1 2013-01-01 13:00:00
1      A  Mark         3 2013-01-01 13:05:00
2      A  Carl         5 2013-10-01 20:00:00
3      A  Carl         1 2013-10-02 10:00:00
4      A   Joe         8 2013-10-01 20:00:00
5      A   Joe         1 2013-10-02 10:00:00
6      A   Joe         9 2013-12-02 12:00:00
7      B  Carl         3 2013-12-02 14:00:00

---->   pandas.DataFrame

--------------------------------------
ID: 1376 --> 2
In [205]: df.groupby([pd.Grouper(freq="1M", key="Date"), "Buyer"])[["Quantity"]].sum()
Out[205]: 
                  Quantity
Date       Buyer          
2013-01-31 Carl          1
           Mark          3
2013-10-31 Carl          6
           Joe           9
2013-12-31 Carl          3
           Joe           9

---->   DataFrame.groupby; pandas.Grouper

--------------------------------------
ID: 1377 --> 2
In [206]: df = df.set_index("Date")

In [207]: df["Date"] = df.index + pd.offsets.MonthEnd(2)

In [208]: df.groupby([pd.Grouper(freq="6M", key="Date"), "Buyer"])[["Quantity"]].sum()
Out[208]: 
                  Quantity
Date       Buyer          
2013-02-28 Carl          1
           Mark          3
2014-02-28 Carl          9
           Joe          18

In [209]: df.groupby([pd.Grouper(freq="6M", level="Date"), "Buyer"])[["Quantity"]].sum()
Out[209]: 
                  Quantity
Date       Buyer          
2013-01-31 Carl          1
           Mark          3
2014-01-31 Carl          9
           Joe          18

---->   DataFrame.groupby; pandas.Grouper

--------------------------------------
ID: 1378 --> 2
In [210]: df = pd.DataFrame([[1, 2], [1, 4], [5, 6]], columns=["A", "B"])

In [211]: df
Out[211]: 
   A  B
0  1  2
1  1  4
2  5  6

In [212]: g = df.groupby("A")

In [213]: g.head(1)
Out[213]: 
   A  B
0  1  2
2  5  6

In [214]: g.tail(1)
Out[214]: 
   A  B
1  1  4
2  5  6

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 1379 --> 2
In [215]: df = pd.DataFrame([[1, np.nan], [1, 4], [5, 6]], columns=["A", "B"])

In [216]: g = df.groupby("A")

In [217]: g.nth(0)
Out[217]: 
   A    B
0  1  NaN
2  5  6.0

In [218]: g.nth(-1)
Out[218]: 
   A    B
1  1  4.0
2  5  6.0

In [219]: g.nth(1)
Out[219]: 
   A    B
1  1  4.0

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 1382 --> 2
In [226]: business_dates = pd.date_range(start="4/1/2014", end="6/30/2014", freq="B")

In [227]: df = pd.DataFrame(1, index=business_dates, columns=["a", "b"])

# get the first, 4th, and last date index for each month
In [228]: df.groupby([df.index.year, df.index.month]).nth([0, 3, -1])
Out[228]: 
            a  b
2014-04-01  1  1
2014-04-04  1  1
2014-04-30  1  1
2014-05-01  1  1
2014-05-06  1  1
2014-05-30  1  1
2014-06-02  1  1
2014-06-05  1  1
2014-06-30  1  1

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 1383 --> 1
In [229]: df.groupby([df.index.year, df.index.month]).nth[1:]
Out[229]: 
            a  b
2014-04-02  1  1
2014-04-03  1  1
2014-04-04  1  1
2014-04-07  1  1
2014-04-08  1  1
...        .. ..
2014-06-24  1  1
2014-06-25  1  1
2014-06-26  1  1
2014-06-27  1  1
2014-06-30  1  1

[62 rows x 2 columns]

In [230]: df.groupby([df.index.year, df.index.month]).nth[1:, :-1]
Out[230]: 
            a  b
2014-04-01  1  1
2014-04-02  1  1
2014-04-03  1  1
2014-04-04  1  1
2014-04-07  1  1
...        .. ..
2014-06-24  1  1
2014-06-25  1  1
2014-06-26  1  1
2014-06-27  1  1
2014-06-30  1  1

[65 rows x 2 columns]

---->   DataFrame.groupby

--------------------------------------
ID: 1384 --> 2
In [231]: dfg = pd.DataFrame(list("aaabba"), columns=["A"])

In [232]: dfg
Out[232]: 
   A
0  a
1  a
2  a
3  b
4  b
5  a

In [233]: dfg.groupby("A").cumcount()
Out[233]: 
0    0
1    1
2    2
3    0
4    1
5    3
dtype: int64

In [234]: dfg.groupby("A").cumcount(ascending=False)
Out[234]: 
0    3
1    2
2    1
3    1
4    0
5    0
dtype: int64

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 1385 --> 2
In [235]: dfg = pd.DataFrame(list("aaabba"), columns=["A"])

In [236]: dfg
Out[236]: 
   A
0  a
1  a
2  a
3  b
4  b
5  a

In [237]: dfg.groupby("A").ngroup()
Out[237]: 
0    0
1    0
2    0
3    1
4    1
5    0
dtype: int64

In [238]: dfg.groupby("A").ngroup(ascending=False)
Out[238]: 
0    1
1    1
2    1
3    0
4    0
5    1
dtype: int64

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 1386 --> 1
In [239]: np.random.seed(1234)

In [240]: df = pd.DataFrame(np.random.randn(50, 2))

In [241]: df["g"] = np.random.choice(["A", "B"], size=50)

In [242]: df.loc[df["g"] == "B", 1] += 3

---->   pandas.DataFrame

--------------------------------------
ID: 1387 --> 1
In [243]: df.groupby("g").boxplot()
Out[243]: 
A         AxesSubplot(0.1,0.15;0.363636x0.75)
B    AxesSubplot(0.536364,0.15;0.363636x0.75)
dtype: object

---->   DataFrame.groupby

--------------------------------------
ID: 1388 --> 2
In [244]: n = 1000

In [245]: df = pd.DataFrame(
   .....:     {
   .....:         "Store": np.random.choice(["Store_1", "Store_2"], n),
   .....:         "Product": np.random.choice(["Product_1", "Product_2"], n),
   .....:         "Revenue": (np.random.random(n) * 50 + 10).round(2),
   .....:         "Quantity": np.random.randint(1, 10, size=n),
   .....:     }
   .....: )
   .....: 

In [246]: df.head(2)
Out[246]: 
     Store    Product  Revenue  Quantity
0  Store_2  Product_1    26.12         1
1  Store_2  Product_1    28.86         1

---->   pandas.DataFrame; DataFrame.head

--------------------------------------
ID: 1389 --> 1
In [247]: (
   .....:     df.groupby(["Store", "Product"])
   .....:     .pipe(lambda grp: grp.Revenue.sum() / grp.Quantity.sum())
   .....:     .unstack()
   .....:     .round(2)
   .....: )
   .....: 
Out[247]: 
Product  Product_1  Product_2
Store                        
Store_1       6.82       7.05
Store_2       6.30       6.64

---->   DataFrame.groupby

--------------------------------------
ID: 1390 --> 1
In [248]: def mean(groupby):
   .....:     return groupby.mean()
   .....: 

In [249]: df.groupby(["Store", "Product"]).pipe(mean)
Out[249]: 
                     Revenue  Quantity
Store   Product                       
Store_1 Product_1  34.622727  5.075758
        Product_2  35.482815  5.029630
Store_2 Product_1  32.972837  5.237589
        Product_2  34.684360  5.224000

---->   DataFrame.groupby

--------------------------------------
ID: 1391 --> 3
In [250]: df = pd.DataFrame({"a": [1, 0, 0], "b": [0, 1, 0], "c": [1, 0, 0], "d": [2, 3, 4]})

In [251]: df
Out[251]: 
   a  b  c  d
0  1  0  1  2
1  0  1  0  3
2  0  0  0  4

In [252]: df.groupby(df.sum(), axis=1).sum()
Out[252]: 
   1  9
0  2  2
1  1  3
2  0  4

---->   pandas.DataFrame; DataFrame.groupby; DataFrame.sum

--------------------------------------
ID: 1392 --> 2
In [253]: dfg = pd.DataFrame({"A": [1, 1, 2, 3, 2], "B": list("aaaba")})

In [254]: dfg
Out[254]: 
   A  B
0  1  a
1  1  a
2  2  a
3  3  b
4  2  a

In [255]: dfg.groupby(["A", "B"]).ngroup()
Out[255]: 
0    0
1    0
2    1
3    2
4    1
dtype: int64

In [256]: dfg.groupby(["A", [0, 0, 0, 1, 1]]).ngroup()
Out[256]: 
0    0
1    0
2    1
3    3
4    2
dtype: int64

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 1393 --> 2
In [257]: df = pd.DataFrame(np.random.randn(10, 2))

In [258]: df
Out[258]: 
          0         1
0 -0.793893  0.321153
1  0.342250  1.618906
2 -0.975807  1.918201
3 -0.810847 -1.405919
4 -1.977759  0.461659
5  0.730057 -1.316938
6 -0.751328  0.528290
7 -0.257759 -1.081009
8  0.505895 -1.701948
9 -1.006349  0.020208

In [259]: df.index // 5
Out[259]: Index([0, 0, 0, 0, 0, 1, 1, 1, 1, 1], dtype='int64')

In [260]: df.groupby(df.index // 5).std()
Out[260]: 
          0         1
0  0.823647  1.312912
1  0.760109  0.942941

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 1394 --> 3
In [261]: df = pd.DataFrame(
   .....:     {
   .....:         "a": [0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2],
   .....:         "b": [0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1],
   .....:         "c": [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0],
   .....:         "d": [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1],
   .....:     }
   .....: )
   .....: 

In [262]: def compute_metrics(x):
   .....:     result = {"b_sum": x["b"].sum(), "c_mean": x["c"].mean()}
   .....:     return pd.Series(result, name="metrics")
   .....: 

In [263]: result = df.groupby("a").apply(compute_metrics)

In [264]: result
Out[264]: 
metrics  b_sum  c_mean
a                     
0          2.0     0.5
1          2.0     0.5
2          2.0     0.5

In [265]: result.stack()
Out[265]: 
a  metrics
0  b_sum      2.0
   c_mean     0.5
1  b_sum      2.0
   c_mean     0.5
2  b_sum      2.0
   c_mean     0.5
dtype: float64

---->   pandas.DataFrame; pandas.Series; DataFrame.groupby

--------------------------------------
ID: 1395 --> 1
In [1]: df = pd.DataFrame(
   ...:     np.random.randn(5, 3),
   ...:     index=["a", "c", "e", "f", "h"],
   ...:     columns=["one", "two", "three"],
   ...: )
   ...: 

In [2]: df["four"] = "bar"

In [3]: df["five"] = df["one"] > 0

In [4]: df
Out[4]: 
        one       two     three four   five
a  0.469112 -0.282863 -1.509059  bar   True
c -1.135632  1.212112 -0.173215  bar  False
e  0.119209 -1.044236 -0.861849  bar   True
f -2.104569 -0.494929  1.071804  bar  False
h  0.721555 -0.706771 -1.039575  bar   True

In [5]: df2 = df.reindex(["a", "b", "c", "d", "e", "f", "g", "h"])

In [6]: df2
Out[6]: 
        one       two     three four   five
a  0.469112 -0.282863 -1.509059  bar   True
b       NaN       NaN       NaN  NaN    NaN
c -1.135632  1.212112 -0.173215  bar  False
d       NaN       NaN       NaN  NaN    NaN
e  0.119209 -1.044236 -0.861849  bar   True
f -2.104569 -0.494929  1.071804  bar  False
g       NaN       NaN       NaN  NaN    NaN
h  0.721555 -0.706771 -1.039575  bar   True

---->   pandas.DataFrame

--------------------------------------
ID: 1396 --> 2
In [7]: df2["one"]
Out[7]: 
a    0.469112
b         NaN
c   -1.135632
d         NaN
e    0.119209
f   -2.104569
g         NaN
h    0.721555
Name: one, dtype: float64

In [8]: pd.isna(df2["one"])
Out[8]: 
a    False
b     True
c    False
d     True
e    False
f    False
g     True
h    False
Name: one, dtype: bool

In [9]: df2["four"].notna()
Out[9]: 
a     True
b    False
c     True
d    False
e     True
f     True
g    False
h     True
Name: four, dtype: bool

In [10]: df2.isna()
Out[10]: 
     one    two  three   four   five
a  False  False  False  False  False
b   True   True   True   True   True
c  False  False  False  False  False
d   True   True   True   True   True
e  False  False  False  False  False
f  False  False  False  False  False
g   True   True   True   True   True
h  False  False  False  False  False

---->   pandas.isna; DataFrame.isna

--------------------------------------
ID: 1397 --> 2
In [14]: pd.Series([1, 2, np.nan, 4], dtype=pd.Int64Dtype())
Out[14]: 
0       1
1       2
2    
3       4
dtype: Int64

---->   pandas.Series; pandas.Int64Dtype

--------------------------------------
ID: 1398 --> 1
In [15]: df2 = df.copy()

In [16]: df2["timestamp"] = pd.Timestamp("20120101")

In [17]: df2
Out[17]: 
        one       two     three four   five  timestamp
a  0.469112 -0.282863 -1.509059  bar   True 2012-01-01
c -1.135632  1.212112 -0.173215  bar  False 2012-01-01
e  0.119209 -1.044236 -0.861849  bar   True 2012-01-01
f -2.104569 -0.494929  1.071804  bar  False 2012-01-01
h  0.721555 -0.706771 -1.039575  bar   True 2012-01-01

In [18]: df2.loc[["a", "c", "h"], ["one", "timestamp"]] = np.nan

In [19]: df2
Out[19]: 
        one       two     three four   five  timestamp
a       NaN -0.282863 -1.509059  bar   True        NaT
c       NaN  1.212112 -0.173215  bar  False        NaT
e  0.119209 -1.044236 -0.861849  bar   True 2012-01-01
f -2.104569 -0.494929  1.071804  bar  False 2012-01-01
h       NaN -0.706771 -1.039575  bar   True        NaT

In [20]: df2.dtypes.value_counts()
Out[20]: 
float64           3
object            1
bool              1
datetime64[ns]    1
Name: count, dtype: int64

---->   DataFrame.copy

--------------------------------------
ID: 1399 --> 1
In [21]: s = pd.Series([1, 2, 3])

In [22]: s.loc[0] = None

In [23]: s
Out[23]: 
0    NaN
1    2.0
2    3.0
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 1400 --> 1
In [24]: s = pd.Series(["a", "b", "c"])

In [25]: s.loc[0] = None

In [26]: s.loc[1] = np.nan

In [27]: s
Out[27]: 
0    None
1     NaN
2       c
dtype: object

---->   pandas.Series

--------------------------------------
ID: 1401 --> 2
In [31]: df
Out[31]: 
        one       two     three
a       NaN -0.282863 -1.509059
c       NaN  1.212112 -0.173215
e  0.119209 -1.044236 -0.861849
f -2.104569 -0.494929  1.071804
h       NaN -0.706771 -1.039575

In [32]: df["one"].sum()
Out[32]: -1.9853605075978744

In [33]: df.mean(1)
Out[33]: 
a   -0.895961
c    0.519449
e   -0.595625
f   -0.509232
h   -0.873173
dtype: float64

In [34]: df.cumsum()
Out[34]: 
        one       two     three
a       NaN -0.282863 -1.509059
c       NaN  0.929249 -1.682273
e  0.119209 -0.114987 -2.544122
f -1.985361 -0.609917 -1.472318
h       NaN -1.316688 -2.511893

In [35]: df.cumsum(skipna=False)
Out[35]: 
   one       two     three
a  NaN -0.282863 -1.509059
c  NaN  0.929249 -1.682273
e  NaN -0.114987 -2.544122
f  NaN -0.609917 -1.472318
h  NaN -1.316688 -2.511893

---->   DataFrame.mean; DataFrame.cumsum

--------------------------------------
ID: 1402 --> 1
In [36]: pd.Series([np.nan]).sum()
Out[36]: 0.0

In [37]: pd.Series([], dtype="float64").sum()
Out[37]: 0.0

---->   pandas.Series

--------------------------------------
ID: 1403 --> 1
In [38]: pd.Series([np.nan]).prod()
Out[38]: 1.0

In [39]: pd.Series([], dtype="float64").prod()
Out[39]: 1.0

---->   pandas.Series

--------------------------------------
ID: 1404 --> 1
In [40]: df
Out[40]: 
        one       two     three
a       NaN -0.282863 -1.509059
c       NaN  1.212112 -0.173215
e  0.119209 -1.044236 -0.861849
f -2.104569 -0.494929  1.071804
h       NaN -0.706771 -1.039575

In [41]: df.groupby("one").mean()
Out[41]: 
                two     three
one                          
-2.104569 -0.494929  1.071804
 0.119209 -1.044236 -0.861849

---->   DataFrame.groupby

--------------------------------------
ID: 1408 --> 2
In [49]: dff = pd.DataFrame(np.random.randn(10, 3), columns=list("ABC"))

In [50]: dff.iloc[3:5, 0] = np.nan

In [51]: dff.iloc[4:6, 1] = np.nan

In [52]: dff.iloc[5:8, 2] = np.nan

In [53]: dff
Out[53]: 
          A         B         C
0  0.271860 -0.424972  0.567020
1  0.276232 -1.087401 -0.673690
2  0.113648 -1.478427  0.524988
3       NaN  0.577046 -1.715002
4       NaN       NaN -1.157892
5 -1.344312       NaN       NaN
6 -0.109050  1.643563       NaN
7  0.357021 -0.674600       NaN
8 -0.968914 -1.294524  0.413738
9  0.276662 -0.472035 -0.013960

In [54]: dff.fillna(dff.mean())
Out[54]: 
          A         B         C
0  0.271860 -0.424972  0.567020
1  0.276232 -1.087401 -0.673690
2  0.113648 -1.478427  0.524988
3 -0.140857  0.577046 -1.715002
4 -0.140857 -0.401419 -1.157892
5 -1.344312 -0.401419 -0.293543
6 -0.109050  1.643563 -0.293543
7  0.357021 -0.674600 -0.293543
8 -0.968914 -1.294524  0.413738
9  0.276662 -0.472035 -0.013960

In [55]: dff.fillna(dff.mean()["B":"C"])
Out[55]: 
          A         B         C
0  0.271860 -0.424972  0.567020
1  0.276232 -1.087401 -0.673690
2  0.113648 -1.478427  0.524988
3       NaN  0.577046 -1.715002
4       NaN -0.401419 -1.157892
5 -1.344312 -0.401419 -0.293543
6 -0.109050  1.643563 -0.293543
7  0.357021 -0.674600 -0.293543
8 -0.968914 -1.294524  0.413738
9  0.276662 -0.472035 -0.013960

---->   pandas.DataFrame; DataFrame.mean

--------------------------------------
ID: 1409 --> 2
In [56]: dff.where(pd.notna(dff), dff.mean(), axis="columns")
Out[56]: 
          A         B         C
0  0.271860 -0.424972  0.567020
1  0.276232 -1.087401 -0.673690
2  0.113648 -1.478427  0.524988
3 -0.140857  0.577046 -1.715002
4 -0.140857 -0.401419 -1.157892
5 -1.344312 -0.401419 -0.293543
6 -0.109050  1.643563 -0.293543
7  0.357021 -0.674600 -0.293543
8 -0.968914 -1.294524  0.413738
9  0.276662 -0.472035 -0.013960

---->   pandas.notna; DataFrame.mean

--------------------------------------
ID: 1411 --> 2
In [61]: ts
Out[61]: 
2000-01-31    0.469112
2000-02-29         NaN
2000-03-31         NaN
2000-04-28         NaN
2000-05-31         NaN
                ...   
2007-12-31   -6.950267
2008-01-31   -7.904475
2008-02-29   -6.441779
2008-03-31   -8.184940
2008-04-30   -9.011531
Freq: BM, Length: 100, dtype: float64

In [62]: ts.count()
Out[62]: 66

In [63]: ts.plot()
Out[63]: 

---->   Series.count; Series.plot

--------------------------------------
ID: 1415 --> 1
In [73]: df = pd.DataFrame(
   ....:     {
   ....:         "A": [1, 2.1, np.nan, 4.7, 5.6, 6.8],
   ....:         "B": [0.25, np.nan, np.nan, 4, 12.2, 14.4],
   ....:     }
   ....: )
   ....: 

In [74]: df
Out[74]: 
     A      B
0  1.0   0.25
1  2.1    NaN
2  NaN    NaN
3  4.7   4.00
4  5.6  12.20
5  6.8  14.40

In [75]: df.interpolate()
Out[75]: 
     A      B
0  1.0   0.25
1  2.1   1.50
2  3.4   2.75
3  4.7   4.00
4  5.6  12.20
5  6.8  14.40

---->   pandas.DataFrame

--------------------------------------
ID: 1418 --> 3
In [81]: np.random.seed(2)

In [82]: ser = pd.Series(np.arange(1, 10.1, 0.25) ** 2 + np.random.randn(37))

In [83]: missing = np.array([4, 13, 14, 15, 16, 17, 18, 20, 29])

In [84]: ser[missing] = np.nan

In [85]: methods = ["linear", "quadratic", "cubic"]

In [86]: df = pd.DataFrame({m: ser.interpolate(method=m) for m in methods})

In [87]: df.plot()
Out[87]: 

---->   pandas.Series; pandas.DataFrame; DataFrame.plot

--------------------------------------
ID: 1419 --> 2
In [88]: ser = pd.Series(np.sort(np.random.uniform(size=100)))

# interpolate at new_index
In [89]: new_index = ser.index.union(pd.Index([49.25, 49.5, 49.75, 50.25, 50.5, 50.75]))

In [90]: interp_s = ser.reindex(new_index).interpolate(method="pchip")

In [91]: interp_s[49:51]
Out[91]: 
49.00    0.471410
49.25    0.476841
49.50    0.481780
49.75    0.485998
50.00    0.489266
50.25    0.491814
50.50    0.493995
50.75    0.495763
51.00    0.497074
dtype: float64

---->   pandas.Series; pandas.Index

--------------------------------------
ID: 1420 --> 1
In [92]: ser = pd.Series([np.nan, np.nan, 5, np.nan, np.nan, np.nan, 13, np.nan, np.nan])

In [93]: ser
Out[93]: 
0     NaN
1     NaN
2     5.0
3     NaN
4     NaN
5     NaN
6    13.0
7     NaN
8     NaN
dtype: float64

# fill all consecutive values in a forward direction
In [94]: ser.interpolate()
Out[94]: 
0     NaN
1     NaN
2     5.0
3     7.0
4     9.0
5    11.0
6    13.0
7    13.0
8    13.0
dtype: float64

# fill one consecutive value in a forward direction
In [95]: ser.interpolate(limit=1)
Out[95]: 
0     NaN
1     NaN
2     5.0
3     7.0
4     NaN
5     NaN
6    13.0
7    13.0
8     NaN
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 1423 --> 1
In [102]: ser = pd.Series([0.0, 1.0, 2.0, 3.0, 4.0])

In [103]: ser.replace(0, 5)
Out[103]: 
0    5.0
1    1.0
2    2.0
3    3.0
4    4.0
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 1426 --> 1
In [106]: df = pd.DataFrame({"a": [0, 1, 2, 3, 4], "b": [5, 6, 7, 8, 9]})

In [107]: df.replace({"a": 0, "b": 5}, 100)
Out[107]: 
     a    b
0  100  100
1    1    6
2    2    7
3    3    8
4    4    9

---->   pandas.DataFrame

--------------------------------------
ID: 1428 --> 1
In [109]: d = {"a": list(range(4)), "b": list("ab.."), "c": ["a", "b", np.nan, "d"]}

In [110]: df = pd.DataFrame(d)

In [111]: df.replace(".", np.nan)
Out[111]: 
   a    b    c
0  0    a    a
1  1    b    b
2  2  NaN  NaN
3  3  NaN    d

---->   pandas.DataFrame

--------------------------------------
ID: 1439 --> 1
In [122]: df = pd.DataFrame(np.random.randn(10, 2))

In [123]: df[np.random.rand(df.shape[0]) > 0.5] = 1.5

In [124]: df.replace(1.5, np.nan)
Out[124]: 
          0         1
0 -0.844214 -1.021415
1  0.432396 -0.323580
2  0.423825  0.799180
3  1.262614  0.751965
4       NaN       NaN
5       NaN       NaN
6 -0.498174 -1.060799
7  0.591667 -0.183257
8  1.019855 -1.482465
9       NaN       NaN

---->   pandas.DataFrame

--------------------------------------
ID: 1441 --> 1
In [128]: s = pd.Series(np.random.randn(5), index=[0, 2, 4, 6, 7])

In [129]: s > 0
Out[129]: 
0    True
2    True
4    True
6    True
7    True
dtype: bool

In [130]: (s > 0).dtype
Out[130]: dtype('bool')

In [131]: crit = (s > 0).reindex(list(range(8)))

In [132]: crit
Out[132]: 
0    True
1     NaN
2    True
3     NaN
4    True
5     NaN
6    True
7    True
dtype: object

In [133]: crit.dtype
Out[133]: dtype('O')

---->   pandas.Series

--------------------------------------
ID: 1444 --> 1
In [138]: s = pd.Series([0, 1, np.nan, 3, 4], dtype="Int64")

In [139]: s
Out[139]: 
0       0
1       1
2    
3       3
4       4
dtype: Int64

---->   pandas.Series

--------------------------------------
ID: 1445 --> 1
In [140]: s = pd.Series([1, 2, None], dtype="Int64")

In [141]: s
Out[141]: 
0       1
1       2
2    
dtype: Int64

In [142]: s[2]
Out[142]: 

In [143]: s[2] is pd.NA
Out[143]: True

---->   pandas.Series

--------------------------------------
ID: 1446 --> 1
In [151]: pd.isna(pd.NA)
Out[151]: True

---->   pandas.isna

--------------------------------------
ID: 1452 --> 1
In [1]: df = pd.DataFrame(
   ...:     {"AAA": [4, 5, 6, 7], "BBB": [10, 20, 30, 40], "CCC": [100, 50, -30, -50]}
   ...: )
   ...: 

In [2]: df
Out[2]: 
   AAA  BBB  CCC
0    4   10  100
1    5   20   50
2    6   30  -30
3    7   40  -50

---->   pandas.DataFrame

--------------------------------------
ID: 1453 --> 1
In [9]: df_mask = pd.DataFrame(
   ...:     {"AAA": [True] * 4, "BBB": [False] * 4, "CCC": [True, False] * 2}
   ...: )
   ...: 

In [10]: df.where(df_mask, -1000)
Out[10]: 
   AAA   BBB   CCC
0    4 -1000  2000
1    5 -1000 -1000
2    6 -1000   555
3    7 -1000 -1000

---->   pandas.DataFrame

--------------------------------------
ID: 1454 --> 1
In [11]: df = pd.DataFrame(
   ....:     {"AAA": [4, 5, 6, 7], "BBB": [10, 20, 30, 40], "CCC": [100, 50, -30, -50]}
   ....: )
   ....: 

In [12]: df
Out[12]: 
   AAA  BBB  CCC
0    4   10  100
1    5   20   50
2    6   30  -30
3    7   40  -50

In [13]: df["logic"] = np.where(df["AAA"] > 5, "high", "low")

In [14]: df
Out[14]: 
   AAA  BBB  CCC logic
0    4   10  100   low
1    5   20   50   low
2    6   30  -30  high
3    7   40  -50  high

---->   pandas.DataFrame

--------------------------------------
ID: 1455 --> 1
In [15]: df = pd.DataFrame(
   ....:     {"AAA": [4, 5, 6, 7], "BBB": [10, 20, 30, 40], "CCC": [100, 50, -30, -50]}
   ....: )
   ....: 

In [16]: df
Out[16]: 
   AAA  BBB  CCC
0    4   10  100
1    5   20   50
2    6   30  -30
3    7   40  -50

In [17]: df[df.AAA <= 5]
Out[17]: 
   AAA  BBB  CCC
0    4   10  100
1    5   20   50

In [18]: df[df.AAA > 5]
Out[18]: 
   AAA  BBB  CCC
2    6   30  -30
3    7   40  -50

---->   pandas.DataFrame

--------------------------------------
ID: 1456 --> 1
In [19]: df = pd.DataFrame(
   ....:     {"AAA": [4, 5, 6, 7], "BBB": [10, 20, 30, 40], "CCC": [100, 50, -30, -50]}
   ....: )
   ....: 

In [20]: df
Out[20]: 
   AAA  BBB  CCC
0    4   10  100
1    5   20   50
2    6   30  -30
3    7   40  -50

---->   pandas.DataFrame

--------------------------------------
ID: 1460 --> 1
In [25]: df = pd.DataFrame(
   ....:     {"AAA": [4, 5, 6, 7], "BBB": [10, 20, 30, 40], "CCC": [100, 50, -30, -50]}
   ....: )
   ....: 

In [26]: df
Out[26]: 
   AAA  BBB  CCC
0    4   10  100
1    5   20   50
2    6   30  -30
3    7   40  -50

In [27]: aValue = 43.0

In [28]: df.loc[(df.CCC - aValue).abs().argsort()]
Out[28]: 
   AAA  BBB  CCC
1    5   20   50
0    4   10  100
2    6   30  -30
3    7   40  -50

---->   pandas.DataFrame

--------------------------------------
ID: 1461 --> 1
In [29]: df = pd.DataFrame(
   ....:     {"AAA": [4, 5, 6, 7], "BBB": [10, 20, 30, 40], "CCC": [100, 50, -30, -50]}
   ....: )
   ....: 

In [30]: df
Out[30]: 
   AAA  BBB  CCC
0    4   10  100
1    5   20   50
2    6   30  -30
3    7   40  -50

In [31]: Crit1 = df.AAA <= 5.5

In [32]: Crit2 = df.BBB == 10.0

In [33]: Crit3 = df.CCC > -40.0

---->   pandas.DataFrame

--------------------------------------
ID: 1463 --> 1
In [39]: df = pd.DataFrame(
   ....:     {"AAA": [4, 5, 6, 7], "BBB": [10, 20, 30, 40], "CCC": [100, 50, -30, -50]}
   ....: )
   ....: 

In [40]: df
Out[40]: 
   AAA  BBB  CCC
0    4   10  100
1    5   20   50
2    6   30  -30
3    7   40  -50

In [41]: df[(df.AAA <= 6) & (df.index.isin([0, 2, 4]))]
Out[41]: 
   AAA  BBB  CCC
0    4   10  100
2    6   30  -30

---->   pandas.DataFrame

--------------------------------------
ID: 1464 --> 1
In [42]: df = pd.DataFrame(
   ....:     {"AAA": [4, 5, 6, 7], "BBB": [10, 20, 30, 40], "CCC": [100, 50, -30, -50]},
   ....:     index=["foo", "bar", "boo", "kar"],
   ....: )
   ....: 

---->   pandas.DataFrame

--------------------------------------
ID: 1465 --> 1
In [46]: data = {"AAA": [4, 5, 6, 7], "BBB": [10, 20, 30, 40], "CCC": [100, 50, -30, -50]}

In [47]: df2 = pd.DataFrame(data=data, index=[1, 2, 3, 4])  # Note index starts at 1.

In [48]: df2.iloc[1:3]  # Position-oriented
Out[48]: 
   AAA  BBB  CCC
2    5   20   50
3    6   30  -30

In [49]: df2.loc[1:3]  # Label-oriented
Out[49]: 
   AAA  BBB  CCC
1    4   10  100
2    5   20   50
3    6   30  -30

---->   pandas.DataFrame

--------------------------------------
ID: 1466 --> 1
In [50]: df = pd.DataFrame(
   ....:     {"AAA": [4, 5, 6, 7], "BBB": [10, 20, 30, 40], "CCC": [100, 50, -30, -50]}
   ....: )
   ....: 

In [51]: df
Out[51]: 
   AAA  BBB  CCC
0    4   10  100
1    5   20   50
2    6   30  -30
3    7   40  -50

In [52]: df[~((df.AAA <= 6) & (df.index.isin([0, 2, 4])))]
Out[52]: 
   AAA  BBB  CCC
1    5   20   50
3    7   40  -50

---->   pandas.DataFrame

--------------------------------------
ID: 1467 --> 1
In [53]: df = pd.DataFrame({"AAA": [1, 2, 1, 3], "BBB": [1, 1, 2, 2], "CCC": [2, 1, 3, 1]})

In [54]: df
Out[54]: 
   AAA  BBB  CCC
0    1    1    2
1    2    1    1
2    1    2    3
3    3    2    1

In [55]: source_cols = df.columns  # Or some subset would work too

In [56]: new_cols = [str(x) + "_cat" for x in source_cols]

In [57]: categories = {1: "Alpha", 2: "Beta", 3: "Charlie"}

In [58]: df[new_cols] = df[source_cols].applymap(categories.get)

In [59]: df
Out[59]: 
   AAA  BBB  CCC  AAA_cat BBB_cat  CCC_cat
0    1    1    2    Alpha   Alpha     Beta
1    2    1    1     Beta   Alpha    Alpha
2    1    2    3    Alpha    Beta  Charlie
3    3    2    1  Charlie    Beta    Alpha

---->   pandas.DataFrame

--------------------------------------
ID: 1468 --> 1
In [60]: df = pd.DataFrame(
   ....:     {"AAA": [1, 1, 1, 2, 2, 2, 3, 3], "BBB": [2, 1, 3, 4, 5, 1, 2, 3]}
   ....: )
   ....: 

In [61]: df
Out[61]: 
   AAA  BBB
0    1    2
1    1    1
2    1    3
3    2    4
4    2    5
5    2    1
6    3    2
7    3    3

---->   pandas.DataFrame

--------------------------------------
ID: 1469 --> 1
In [62]: df.loc[df.groupby("AAA")["BBB"].idxmin()]
Out[62]: 
   AAA  BBB
1    1    1
5    2    1
6    3    2

---->   DataFrame.groupby

--------------------------------------
ID: 1471 --> 3
In [64]: df = pd.DataFrame(
   ....:     {
   ....:         "row": [0, 1, 2],
   ....:         "One_X": [1.1, 1.1, 1.1],
   ....:         "One_Y": [1.2, 1.2, 1.2],
   ....:         "Two_X": [1.11, 1.11, 1.11],
   ....:         "Two_Y": [1.22, 1.22, 1.22],
   ....:     }
   ....: )
   ....: 

In [65]: df
Out[65]: 
   row  One_X  One_Y  Two_X  Two_Y
0    0    1.1    1.2   1.11   1.22
1    1    1.1    1.2   1.11   1.22
2    2    1.1    1.2   1.11   1.22

# As Labelled Index
In [66]: df = df.set_index("row")

In [67]: df
Out[67]: 
     One_X  One_Y  Two_X  Two_Y
row                            
0      1.1    1.2   1.11   1.22
1      1.1    1.2   1.11   1.22
2      1.1    1.2   1.11   1.22

# With Hierarchical Columns
In [68]: df.columns = pd.MultiIndex.from_tuples([tuple(c.split("_")) for c in df.columns])

In [69]: df
Out[69]: 
     One        Two      
       X    Y     X     Y
row                      
0    1.1  1.2  1.11  1.22
1    1.1  1.2  1.11  1.22
2    1.1  1.2  1.11  1.22

# Now stack & Reset
In [70]: df = df.stack(0).reset_index(1)

In [71]: df
Out[71]: 
    level_1     X     Y
row                    
0       One  1.10  1.20
0       Two  1.11  1.22
1       One  1.10  1.20
1       Two  1.11  1.22
2       One  1.10  1.20
2       Two  1.11  1.22

# And fix the labels (Notice the label 'level_1' got added automatically)
In [72]: df.columns = ["Sample", "All_X", "All_Y"]

In [73]: df
Out[73]: 
    Sample  All_X  All_Y
row                     
0      One   1.10   1.20
0      Two   1.11   1.22
1      One   1.10   1.20
1      Two   1.11   1.22
2      One   1.10   1.20
2      Two   1.11   1.22

---->   pandas.DataFrame; pandas.MultiIndex; DataFrame.stack

--------------------------------------
ID: 1472 --> 3
In [74]: cols = pd.MultiIndex.from_tuples(
   ....:     [(x, y) for x in ["A", "B", "C"] for y in ["O", "I"]]
   ....: )
   ....: 

In [75]: df = pd.DataFrame(np.random.randn(2, 6), index=["n", "m"], columns=cols)

In [76]: df
Out[76]: 
          A                   B                   C          
          O         I         O         I         O         I
n  0.469112 -0.282863 -1.509059 -1.135632  1.212112 -0.173215
m  0.119209 -1.044236 -0.861849 -2.104569 -0.494929  1.071804

In [77]: df = df.div(df["C"], level=1)

In [78]: df
Out[78]: 
          A                   B              C     
          O         I         O         I    O    I
n  0.387021  1.633022 -1.244983  6.556214  1.0  1.0
m -0.240860 -0.974279  1.741358 -1.963577  1.0  1.0

---->   pandas.MultiIndex; pandas.DataFrame; DataFrame.div

--------------------------------------
ID: 1473 --> 2
In [79]: coords = [("AA", "one"), ("AA", "six"), ("BB", "one"), ("BB", "two"), ("BB", "six")]

In [80]: index = pd.MultiIndex.from_tuples(coords)

In [81]: df = pd.DataFrame([11, 22, 33, 44, 55], index, ["MyData"])

In [82]: df
Out[82]: 
        MyData
AA one      11
   six      22
BB one      33
   two      44
   six      55

---->   pandas.MultiIndex; pandas.DataFrame

--------------------------------------
ID: 1474 --> 1
# Note : level and axis are optional, and default to zero
In [83]: df.xs("BB", level=0, axis=0)
Out[83]: 
     MyData
one      33
two      44
six      55

---->   DataFrame.xs

--------------------------------------
ID: 1475 --> 1
In [84]: df.xs("six", level=1, axis=0)
Out[84]: 
    MyData
AA      22
BB      55

---->   DataFrame.xs

--------------------------------------
ID: 1476 --> 2
In [85]: import itertools

In [86]: index = list(itertools.product(["Ada", "Quinn", "Violet"], ["Comp", "Math", "Sci"]))

In [87]: headr = list(itertools.product(["Exams", "Labs"], ["I", "II"]))

In [88]: indx = pd.MultiIndex.from_tuples(index, names=["Student", "Course"])

In [89]: cols = pd.MultiIndex.from_tuples(headr)  # Notice these are un-named

In [90]: data = [[70 + x + y + (x * y) % 3 for x in range(4)] for y in range(9)]

In [91]: df = pd.DataFrame(data, indx, cols)

In [92]: df
Out[92]: 
               Exams     Labs    
                   I  II    I  II
Student Course                   
Ada     Comp      70  71   72  73
        Math      71  73   75  74
        Sci       72  75   75  75
Quinn   Comp      73  74   75  76
        Math      74  76   78  77
        Sci       75  78   78  78
Violet  Comp      76  77   78  79
        Math      77  79   81  80
        Sci       78  81   81  81

In [93]: All = slice(None)

In [94]: df.loc["Violet"]
Out[94]: 
       Exams     Labs    
           I  II    I  II
Course                   
Comp      76  77   78  79
Math      77  79   81  80
Sci       78  81   81  81

In [95]: df.loc[(All, "Math"), All]
Out[95]: 
               Exams     Labs    
                   I  II    I  II
Student Course                   
Ada     Math      71  73   75  74
Quinn   Math      74  76   78  77
Violet  Math      77  79   81  80

In [96]: df.loc[(slice("Ada", "Quinn"), "Math"), All]
Out[96]: 
               Exams     Labs    
                   I  II    I  II
Student Course                   
Ada     Math      71  73   75  74
Quinn   Math      74  76   78  77

In [97]: df.loc[(All, "Math"), ("Exams")]
Out[97]: 
                 I  II
Student Course        
Ada     Math    71  73
Quinn   Math    74  76
Violet  Math    77  79

In [98]: df.loc[(All, "Math"), (All, "II")]
Out[98]: 
               Exams Labs
                  II   II
Student Course           
Ada     Math      73   74
Quinn   Math      76   77
Violet  Math      79   80

---->   pandas.MultiIndex; pandas.DataFrame

--------------------------------------
ID: 1478 --> 1
In [100]: df = pd.DataFrame(
   .....:     np.random.randn(6, 1),
   .....:     index=pd.date_range("2013-08-01", periods=6, freq="B"),
   .....:     columns=list("A"),
   .....: )
   .....: 

In [101]: df.loc[df.index[3], "A"] = np.nan

In [102]: df
Out[102]: 
                   A
2013-08-01  0.721555
2013-08-02 -0.706771
2013-08-05 -1.039575
2013-08-06       NaN
2013-08-07 -0.424972
2013-08-08  0.567020

In [103]: df.bfill()
Out[103]: 
                   A
2013-08-01  0.721555
2013-08-02 -0.706771
2013-08-05 -1.039575
2013-08-06 -0.424972
2013-08-07 -0.424972
2013-08-08  0.567020

---->   pandas.DataFrame

--------------------------------------
ID: 1479 --> 2
In [104]: df = pd.DataFrame(
   .....:     {
   .....:         "animal": "cat dog cat fish dog cat cat".split(),
   .....:         "size": list("SSMMMLL"),
   .....:         "weight": [8, 10, 11, 1, 20, 12, 12],
   .....:         "adult": [False] * 5 + [True] * 2,
   .....:     }
   .....: )
   .....: 

In [105]: df
Out[105]: 
  animal size  weight  adult
0    cat    S       8  False
1    dog    S      10  False
2    cat    M      11  False
3   fish    M       1  False
4    dog    M      20  False
5    cat    L      12   True
6    cat    L      12   True

# List the size of the animals with the highest weight.
In [106]: df.groupby("animal").apply(lambda subf: subf["size"][subf["weight"].idxmax()])
Out[106]: 
animal
cat     L
dog     M
fish    M
dtype: object

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 1480 --> 1
In [107]: gb = df.groupby(["animal"])

In [108]: gb.get_group("cat")
Out[108]: 
  animal size  weight  adult
0    cat    S       8  False
2    cat    M      11  False
5    cat    L      12   True
6    cat    L      12   True

---->   DataFrame.groupby

--------------------------------------
ID: 1481 --> 1
In [109]: def GrowUp(x):
   .....:     avg_weight = sum(x[x["size"] == "S"].weight * 1.5)
   .....:     avg_weight += sum(x[x["size"] == "M"].weight * 1.25)
   .....:     avg_weight += sum(x[x["size"] == "L"].weight)
   .....:     avg_weight /= len(x)
   .....:     return pd.Series(["L", avg_weight, True], index=["size", "weight", "adult"])
   .....: 

In [110]: expected_df = gb.apply(GrowUp)

In [111]: expected_df
Out[111]: 
       size   weight  adult
animal                     
cat       L  12.4375   True
dog       L  20.0000   True
fish      L   1.2500   True

---->   pandas.Series

--------------------------------------
ID: 1482 --> 2
In [112]: S = pd.Series([i / 100.0 for i in range(1, 11)])

In [113]: def cum_ret(x, y):
   .....:     return x * (1 + y)
   .....: 

In [114]: def red(x):
   .....:     return functools.reduce(cum_ret, x, 1.0)
   .....: 

In [115]: S.expanding().apply(red, raw=True)
Out[115]: 
0    1.010000
1    1.030200
2    1.061106
3    1.103550
4    1.158728
5    1.228251
6    1.314229
7    1.419367
8    1.547110
9    1.701821
dtype: float64

---->   pandas.Series; Series.expanding

--------------------------------------
ID: 1483 --> 2
In [116]: df = pd.DataFrame({"A": [1, 1, 2, 2], "B": [1, -1, 1, 2]})

In [117]: gb = df.groupby("A")

In [118]: def replace(g):
   .....:     mask = g < 0
   .....:     return g.where(~mask, g[~mask].mean())
   .....: 

In [119]: gb.transform(replace)
Out[119]: 
   B
0  1
1  1
2  1
3  2

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 1484 --> 2
In [120]: df = pd.DataFrame(
   .....:     {
   .....:         "code": ["foo", "bar", "baz"] * 2,
   .....:         "data": [0.16, -0.21, 0.33, 0.45, -0.59, 0.62],
   .....:         "flag": [False, True] * 3,
   .....:     }
   .....: )
   .....: 

In [121]: code_groups = df.groupby("code")

In [122]: agg_n_sort_order = code_groups[["data"]].transform(sum).sort_values(by="data")

In [123]: sorted_df = df.loc[agg_n_sort_order.index]

In [124]: sorted_df
Out[124]: 
  code  data   flag
1  bar -0.21   True
4  bar -0.59  False
0  foo  0.16  False
3  foo  0.45   True
2  baz  0.33  False
5  baz  0.62   True

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 1485 --> 2
In [125]: rng = pd.date_range(start="2014-10-07", periods=10, freq="2min")

In [126]: ts = pd.Series(data=list(range(10)), index=rng)

In [127]: def MyCust(x):
   .....:     if len(x) > 2:
   .....:         return x[1] * 1.234
   .....:     return pd.NaT
   .....: 

In [128]: mhc = {"Mean": np.mean, "Max": np.max, "Custom": MyCust}

In [129]: ts.resample("5min").apply(mhc)
Out[129]: 
                     Mean  Max Custom
2014-10-07 00:00:00   1.0    2  1.234
2014-10-07 00:05:00   3.5    4    NaT
2014-10-07 00:10:00   6.0    7  7.404
2014-10-07 00:15:00   8.5    9    NaT

In [130]: ts
Out[130]: 
2014-10-07 00:00:00    0
2014-10-07 00:02:00    1
2014-10-07 00:04:00    2
2014-10-07 00:06:00    3
2014-10-07 00:08:00    4
2014-10-07 00:10:00    5
2014-10-07 00:12:00    6
2014-10-07 00:14:00    7
2014-10-07 00:16:00    8
2014-10-07 00:18:00    9
Freq: 2T, dtype: int64

---->   pandas.Series; Series.resample

--------------------------------------
ID: 1486 --> 2
In [131]: df = pd.DataFrame(
   .....:     {"Color": "Red Red Red Blue".split(), "Value": [100, 150, 50, 50]}
   .....: )
   .....: 

In [132]: df
Out[132]: 
  Color  Value
0   Red    100
1   Red    150
2   Red     50
3  Blue     50

In [133]: df["Counts"] = df.groupby(["Color"]).transform(len)

In [134]: df
Out[134]: 
  Color  Value  Counts
0   Red    100       3
1   Red    150       3
2   Red     50       3
3  Blue     50       1

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 1487 --> 2
In [135]: df = pd.DataFrame(
   .....:     {"line_race": [10, 10, 8, 10, 10, 8], "beyer": [99, 102, 103, 103, 88, 100]},
   .....:     index=[
   .....:         "Last Gunfighter",
   .....:         "Last Gunfighter",
   .....:         "Last Gunfighter",
   .....:         "Paynter",
   .....:         "Paynter",
   .....:         "Paynter",
   .....:     ],
   .....: )
   .....: 

In [136]: df
Out[136]: 
                 line_race  beyer
Last Gunfighter         10     99
Last Gunfighter         10    102
Last Gunfighter          8    103
Paynter                 10    103
Paynter                 10     88
Paynter                  8    100

In [137]: df["beyer_shifted"] = df.groupby(level=0)["beyer"].shift(1)

In [138]: df
Out[138]: 
                 line_race  beyer  beyer_shifted
Last Gunfighter         10     99            NaN
Last Gunfighter         10    102           99.0
Last Gunfighter          8    103          102.0
Paynter                 10    103            NaN
Paynter                 10     88          103.0
Paynter                  8    100           88.0

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 1488 --> 2
In [139]: df = pd.DataFrame(
   .....:     {
   .....:         "host": ["other", "other", "that", "this", "this"],
   .....:         "service": ["mail", "web", "mail", "mail", "web"],
   .....:         "no": [1, 2, 1, 2, 1],
   .....:     }
   .....: ).set_index(["host", "service"])
   .....: 

In [140]: mask = df.groupby(level=0).agg("idxmax")

In [141]: df_count = df.loc[mask["no"]].reset_index()

In [142]: df_count
Out[142]: 
    host service  no
0  other     web   2
1   that    mail   1
2   this    mail   2

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 1489 --> 1
In [143]: df = pd.DataFrame([0, 1, 0, 1, 1, 1, 0, 1, 1], columns=["A"])

In [144]: df["A"].groupby((df["A"] != df["A"].shift()).cumsum()).groups
Out[144]: {1: [0], 2: [1], 3: [2], 4: [3, 4, 5], 5: [6], 6: [7, 8]}

In [145]: df["A"].groupby((df["A"] != df["A"].shift()).cumsum()).cumsum()
Out[145]: 
0    0
1    1
2    0
3    1
4    2
5    3
6    0
7    1
8    2
Name: A, dtype: int64

---->   pandas.DataFrame

--------------------------------------
ID: 1490 --> 2
In [146]: df = pd.DataFrame(
   .....:     data={
   .....:         "Case": ["A", "A", "A", "B", "A", "A", "B", "A", "A"],
   .....:         "Data": np.random.randn(9),
   .....:     }
   .....: )
   .....: 

In [147]: dfs = list(
   .....:     zip(
   .....:         *df.groupby(
   .....:             (1 * (df["Case"] == "B"))
   .....:             .cumsum()
   .....:             .rolling(window=3, min_periods=1)
   .....:             .median()
   .....:         )
   .....:     )
   .....: )[-1]
   .....: 

In [148]: dfs[0]
Out[148]: 
  Case      Data
0    A  0.276232
1    A -1.087401
2    A -0.673690
3    B  0.113648

In [149]: dfs[1]
Out[149]: 
  Case      Data
4    A -1.478427
5    A  0.524988
6    B  0.404705

In [150]: dfs[2]
Out[150]: 
  Case      Data
7    A  0.577046
8    A -1.715002

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 1491 --> 2
In [151]: df = pd.DataFrame(
   .....:     data={
   .....:         "Province": ["ON", "QC", "BC", "AL", "AL", "MN", "ON"],
   .....:         "City": [
   .....:             "Toronto",
   .....:             "Montreal",
   .....:             "Vancouver",
   .....:             "Calgary",
   .....:             "Edmonton",
   .....:             "Winnipeg",
   .....:             "Windsor",
   .....:         ],
   .....:         "Sales": [13, 6, 16, 8, 4, 3, 1],
   .....:     }
   .....: )
   .....: 

In [152]: table = pd.pivot_table(
   .....:     df,
   .....:     values=["Sales"],
   .....:     index=["Province"],
   .....:     columns=["City"],
   .....:     aggfunc=np.sum,
   .....:     margins=True,
   .....: )
   .....: 

In [153]: table.stack("City")
Out[153]: 
                    Sales
Province City            
AL       All         12.0
         Calgary      8.0
         Edmonton     4.0
BC       All         16.0
         Vancouver   16.0
...                   ...
All      Montreal     6.0
         Toronto     13.0
         Vancouver   16.0
         Windsor      1.0
         Winnipeg     3.0

[20 rows x 1 columns]

---->   pandas.DataFrame; pandas.pivot_table

--------------------------------------
ID: 1492 --> 3
In [154]: grades = [48, 99, 75, 80, 42, 80, 72, 68, 36, 78]

In [155]: df = pd.DataFrame(
   .....:     {
   .....:         "ID": ["x%d" % r for r in range(10)],
   .....:         "Gender": ["F", "M", "F", "M", "F", "M", "F", "M", "M", "M"],
   .....:         "ExamYear": [
   .....:             "2007",
   .....:             "2007",
   .....:             "2007",
   .....:             "2008",
   .....:             "2008",
   .....:             "2008",
   .....:             "2008",
   .....:             "2009",
   .....:             "2009",
   .....:             "2009",
   .....:         ],
   .....:         "Class": [
   .....:             "algebra",
   .....:             "stats",
   .....:             "bio",
   .....:             "algebra",
   .....:             "algebra",
   .....:             "stats",
   .....:             "stats",
   .....:             "algebra",
   .....:             "bio",
   .....:             "bio",
   .....:         ],
   .....:         "Participated": [
   .....:             "yes",
   .....:             "yes",
   .....:             "yes",
   .....:             "yes",
   .....:             "no",
   .....:             "yes",
   .....:             "yes",
   .....:             "yes",
   .....:             "yes",
   .....:             "yes",
   .....:         ],
   .....:         "Passed": ["yes" if x > 50 else "no" for x in grades],
   .....:         "Employed": [
   .....:             True,
   .....:             True,
   .....:             True,
   .....:             False,
   .....:             False,
   .....:             False,
   .....:             False,
   .....:             True,
   .....:             True,
   .....:             False,
   .....:         ],
   .....:         "Grade": grades,
   .....:     }
   .....: )
   .....: 

In [156]: df.groupby("ExamYear").agg(
   .....:     {
   .....:         "Participated": lambda x: x.value_counts()["yes"],
   .....:         "Passed": lambda x: sum(x == "yes"),
   .....:         "Employed": lambda x: sum(x),
   .....:         "Grade": lambda x: sum(x) / len(x),
   .....:     }
   .....: )
   .....: 
Out[156]: 
          Participated  Passed  Employed      Grade
ExamYear                                           
2007                 3       2         3  74.000000
2008                 3       3         0  68.500000
2009                 3       2         2  60.666667

---->   pandas.DataFrame; DataFrame.groupby; Series.value_counts

--------------------------------------
ID: 1493 --> 2
In [157]: df = pd.DataFrame(
   .....:     {"value": np.random.randn(36)},
   .....:     index=pd.date_range("2011-01-01", freq="M", periods=36),
   .....: )
   .....: 

In [158]: pd.pivot_table(
   .....:     df, index=df.index.month, columns=df.index.year, values="value", aggfunc="sum"
   .....: )
   .....: 
Out[158]: 
        2011      2012      2013
1  -1.039268 -0.968914  2.565646
2  -0.370647 -1.294524  1.431256
3  -1.157892  0.413738  1.340309
4  -1.344312  0.276662 -1.170299
5   0.844885 -0.472035 -0.226169
6   1.075770 -0.013960  0.410835
7  -0.109050 -0.362543  0.813850
8   1.643563 -0.006154  0.132003
9  -1.469388 -0.923061 -0.827317
10  0.357021  0.895717 -0.076467
11 -0.674600  0.805244 -1.187678
12 -1.776904 -1.206412  1.130127

---->   pandas.DataFrame; pandas.pivot_table

--------------------------------------
ID: 1494 --> 3
In [159]: df = pd.DataFrame(
   .....:     data={
   .....:         "A": [[2, 4, 8, 16], [100, 200], [10, 20, 30]],
   .....:         "B": [["a", "b", "c"], ["jj", "kk"], ["ccc"]],
   .....:     },
   .....:     index=["I", "II", "III"],
   .....: )
   .....: 

In [160]: def SeriesFromSubList(aList):
   .....:     return pd.Series(aList)
   .....: 

In [161]: df_orgz = pd.concat(
   .....:     {ind: row.apply(SeriesFromSubList) for ind, row in df.iterrows()}
   .....: )
   .....: 

In [162]: df_orgz
Out[162]: 
         0     1     2     3
I   A    2     4     8  16.0
    B    a     b     c   NaN
II  A  100   200   NaN   NaN
    B   jj    kk   NaN   NaN
III A   10  20.0  30.0   NaN
    B  ccc   NaN   NaN   NaN

---->   pandas.DataFrame; pandas.Series; DataFrame.iterrows

--------------------------------------
ID: 1495 --> 2
In [163]: df = pd.DataFrame(
   .....:     data=np.random.randn(2000, 2) / 10000,
   .....:     index=pd.date_range("2001-01-01", periods=2000),
   .....:     columns=["A", "B"],
   .....: )
   .....: 

In [164]: df
Out[164]: 
                   A         B
2001-01-01 -0.000144 -0.000141
2001-01-02  0.000161  0.000102
2001-01-03  0.000057  0.000088
2001-01-04 -0.000221  0.000097
2001-01-05 -0.000201 -0.000041
...              ...       ...
2006-06-19  0.000040 -0.000235
2006-06-20 -0.000123 -0.000021
2006-06-21 -0.000113  0.000114
2006-06-22  0.000136  0.000109
2006-06-23  0.000027  0.000030

[2000 rows x 2 columns]

In [165]: def gm(df, const):
   .....:     v = ((((df["A"] + df["B"]) + 1).cumprod()) - 1) * const
   .....:     return v.iloc[-1]
   .....: 

In [166]: s = pd.Series(
   .....:     {
   .....:         df.index[i]: gm(df.iloc[i: min(i + 51, len(df) - 1)], 5)
   .....:         for i in range(len(df) - 50)
   .....:     }
   .....: )
   .....: 

In [167]: s
Out[167]: 
2001-01-01    0.000930
2001-01-02    0.002615
2001-01-03    0.001281
2001-01-04    0.001117
2001-01-05    0.002772
                ...   
2006-04-30    0.003296
2006-05-01    0.002629
2006-05-02    0.002081
2006-05-03    0.004247
2006-05-04    0.003928
Length: 1950, dtype: float64

---->   pandas.DataFrame; pandas.Series

--------------------------------------
ID: 1496 --> 3
In [168]: rng = pd.date_range(start="2014-01-01", periods=100)

In [169]: df = pd.DataFrame(
   .....:     {
   .....:         "Open": np.random.randn(len(rng)),
   .....:         "Close": np.random.randn(len(rng)),
   .....:         "Volume": np.random.randint(100, 2000, len(rng)),
   .....:     },
   .....:     index=rng,
   .....: )
   .....: 

In [170]: df
Out[170]: 
                Open     Close  Volume
2014-01-01 -1.611353 -0.492885    1219
2014-01-02 -3.000951  0.445794    1054
2014-01-03 -0.138359 -0.076081    1381
2014-01-04  0.301568  1.198259    1253
2014-01-05  0.276381 -0.669831    1728
...              ...       ...     ...
2014-04-06 -0.040338  0.937843    1188
2014-04-07  0.359661 -0.285908    1864
2014-04-08  0.060978  1.714814     941
2014-04-09  1.759055 -0.455942    1065
2014-04-10  0.138185 -1.147008    1453

[100 rows x 3 columns]

In [171]: def vwap(bars):
   .....:     return (bars.Close * bars.Volume).sum() / bars.Volume.sum()
   .....: 

In [172]: window = 5

In [173]: s = pd.concat(
   .....:     [
   .....:         (pd.Series(vwap(df.iloc[i: i + window]), index=[df.index[i + window]]))
   .....:         for i in range(len(df) - window)
   .....:     ]
   .....: )
   .....: 

In [174]: s.round(2)
Out[174]: 
2014-01-06    0.02
2014-01-07    0.11
2014-01-08    0.10
2014-01-09    0.07
2014-01-10   -0.29
              ... 
2014-04-06   -0.63
2014-04-07   -0.02
2014-04-08   -0.03
2014-04-09    0.34
2014-04-10    0.29
Length: 95, dtype: float64

---->   pandas.DataFrame; pandas.Series; Series.round

--------------------------------------
ID: 1498 --> 2
In [177]: rng = pd.date_range("2000-01-01", periods=6)

In [178]: df1 = pd.DataFrame(np.random.randn(6, 3), index=rng, columns=["A", "B", "C"])

In [179]: df2 = df1.copy()

---->   pandas.DataFrame; DataFrame.copy

--------------------------------------
ID: 1500 --> 1
In [182]: df = pd.DataFrame(
   .....:     data={
   .....:         "Area": ["A"] * 5 + ["C"] * 2,
   .....:         "Bins": [110] * 2 + [160] * 3 + [40] * 2,
   .....:         "Test_0": [0, 1, 0, 1, 2, 0, 1],
   .....:         "Data": np.random.randn(7),
   .....:     }
   .....: )
   .....: 

In [183]: df
Out[183]: 
  Area  Bins  Test_0      Data
0    A   110       0 -0.433937
1    A   110       1 -0.160552
2    A   160       0  0.744434
3    A   160       1  1.754213
4    A   160       2  0.000850
5    C    40       0  0.342243
6    C    40       1  1.070599

In [184]: df["Test_1"] = df["Test_0"] - 1

In [185]: pd.merge(
   .....:     df,
   .....:     df,
   .....:     left_on=["Bins", "Area", "Test_0"],
   .....:     right_on=["Bins", "Area", "Test_1"],
   .....:     suffixes=("_L", "_R"),
   .....: )
   .....: 
Out[185]: 
  Area  Bins  Test_0_L    Data_L  Test_1_L  Test_0_R    Data_R  Test_1_R
0    A   110         0 -0.433937        -1         1 -0.160552         0
1    A   160         0  0.744434        -1         1  1.754213         0
2    A   160         1  1.754213         0         2  0.000850         1
3    C    40         0  0.342243        -1         1  1.070599         0

---->   pandas.DataFrame

--------------------------------------
ID: 1501 --> 3
In [186]: df = pd.DataFrame(
   .....:     {
   .....:         "stratifying_var": np.random.uniform(0, 100, 20),
   .....:         "price": np.random.normal(100, 5, 20),
   .....:     }
   .....: )
   .....: 

In [187]: df["quartiles"] = pd.qcut(
   .....:     df["stratifying_var"], 4, labels=["0-25%", "25-50%", "50-75%", "75-100%"]
   .....: )
   .....: 

In [188]: df.boxplot(column="price", by="quartiles")
Out[188]: 

---->   pandas.DataFrame; pandas.qcut; DataFrame.boxplot

--------------------------------------
ID: 1502 --> 2
In [189]: for i in range(3):
   .....:     data = pd.DataFrame(np.random.randn(10, 4))
   .....:     data.to_csv("file_{}.csv".format(i))
   .....: 

In [190]: files = ["file_0.csv", "file_1.csv", "file_2.csv"]

In [191]: result = pd.concat([pd.read_csv(f) for f in files], ignore_index=True)

---->   pandas.DataFrame; Series.to_csv

--------------------------------------
ID: 1504 --> 3
In [196]: i = pd.date_range("20000101", periods=10000)

In [197]: df = pd.DataFrame({"year": i.year, "month": i.month, "day": i.day})

In [198]: df.head()
Out[198]: 
   year  month  day
0  2000      1    1
1  2000      1    2
2  2000      1    3
3  2000      1    4
4  2000      1    5

In [199]: %timeit pd.to_datetime(df.year * 10000 + df.month * 100 + df.day, format='%Y%m%d')
   .....: ds = df.apply(lambda x: "%04d%02d%02d" % (x["year"], x["month"], x["day"]), axis=1)
   .....: ds.head()
   .....: %timeit pd.to_datetime(ds)
   .....: 
5.03 ms +- 39.1 us per loop (mean +- std. dev. of 7 runs, 100 loops each)
2.16 ms +- 19.4 us per loop (mean +- std. dev. of 7 runs, 100 loops each)

---->   pandas.DataFrame; DataFrame.head; pandas.to_datetime

--------------------------------------
ID: 1507 --> 1
In [206]: df = pd.DataFrame(np.random.randn(8, 3))

In [207]: store = pd.HDFStore("test.h5")

In [208]: store.put("df", df)

# you can store an arbitrary Python object via pickle
In [209]: store.get_storer("df").attrs.my_attribute = {"A": 10}

In [210]: store.get_storer("df").attrs.my_attribute
Out[210]: {'A': 10}

---->   pandas.DataFrame

--------------------------------------
ID: 1508 --> 1
In [211]: store = pd.HDFStore("test.h5", "w", driver="H5FD_CORE")

In [212]: df = pd.DataFrame(np.random.randn(8, 3))

In [213]: store["test"] = df

# only after closing the store, data is written to disk:
In [214]: store.close()

---->   pandas.DataFrame

--------------------------------------
ID: 1510 --> 1
names = "count", "avg", "scale"

# note that the offsets are larger than the size of the type because of
# struct padding
offsets = 0, 8, 16
formats = "i4", "f8", "f4"
dt = np.dtype({"names": names, "offsets": offsets, "formats": formats}, align=True)
df = pd.DataFrame(np.fromfile("binary.dat", dt))

---->   pandas.DataFrame

--------------------------------------
ID: 1511 --> 2
In [215]: df = pd.DataFrame(np.random.random(size=(100, 5)))

In [216]: corr_mat = df.corr()

In [217]: mask = np.tril(np.ones_like(corr_mat, dtype=np.bool_), k=-1)

In [218]: corr_mat.where(mask)
Out[218]: 
          0         1         2        3   4
0       NaN       NaN       NaN      NaN NaN
1 -0.079861       NaN       NaN      NaN NaN
2 -0.236573  0.183801       NaN      NaN NaN
3 -0.013795 -0.051975  0.037235      NaN NaN
4 -0.031974  0.118342 -0.073499 -0.02063 NaN

---->   pandas.DataFrame; DataFrame.corr

--------------------------------------
ID: 1512 --> 2
In [219]: def distcorr(x, y):
   .....:     n = len(x)
   .....:     a = np.zeros(shape=(n, n))
   .....:     b = np.zeros(shape=(n, n))
   .....:     for i in range(n):
   .....:         for j in range(i + 1, n):
   .....:             a[i, j] = abs(x[i] - x[j])
   .....:             b[i, j] = abs(y[i] - y[j])
   .....:     a += a.T
   .....:     b += b.T
   .....:     a_bar = np.vstack([np.nanmean(a, axis=0)] * n)
   .....:     b_bar = np.vstack([np.nanmean(b, axis=0)] * n)
   .....:     A = a - a_bar - a_bar.T + np.full(shape=(n, n), fill_value=a_bar.mean())
   .....:     B = b - b_bar - b_bar.T + np.full(shape=(n, n), fill_value=b_bar.mean())
   .....:     cov_ab = np.sqrt(np.nansum(A * B)) / n
   .....:     std_a = np.sqrt(np.sqrt(np.nansum(A ** 2)) / n)
   .....:     std_b = np.sqrt(np.sqrt(np.nansum(B ** 2)) / n)
   .....:     return cov_ab / std_a / std_b
   .....: 

In [220]: df = pd.DataFrame(np.random.normal(size=(100, 3)))

In [221]: df.corr(method=distcorr)
Out[221]: 
          0         1         2
0  1.000000  0.197613  0.216328
1  0.197613  1.000000  0.208749
2  0.216328  0.208749  1.000000

---->   pandas.DataFrame; DataFrame.corr

--------------------------------------
ID: 1513 --> 2
In [222]: import datetime

In [223]: s = pd.Series(pd.date_range("2012-1-1", periods=3, freq="D"))

In [224]: s - s.max()
Out[224]: 
0   -2 days
1   -1 days
2    0 days
dtype: timedelta64[ns]

In [225]: s.max() - s
Out[225]: 
0   2 days
1   1 days
2   0 days
dtype: timedelta64[ns]

In [226]: s - datetime.datetime(2011, 1, 1, 3, 5)
Out[226]: 
0   364 days 20:55:00
1   365 days 20:55:00
2   366 days 20:55:00
dtype: timedelta64[ns]

In [227]: s + datetime.timedelta(minutes=5)
Out[227]: 
0   2012-01-01 00:05:00
1   2012-01-02 00:05:00
2   2012-01-03 00:05:00
dtype: datetime64[ns]

In [228]: datetime.datetime(2011, 1, 1, 3, 5) - s
Out[228]: 
0   -365 days +03:05:00
1   -366 days +03:05:00
2   -367 days +03:05:00
dtype: timedelta64[ns]

In [229]: datetime.timedelta(minutes=5) + s
Out[229]: 
0   2012-01-01 00:05:00
1   2012-01-02 00:05:00
2   2012-01-03 00:05:00
dtype: datetime64[ns]

---->   pandas.Series; Series.max

--------------------------------------
ID: 1514 --> 2
In [230]: deltas = pd.Series([datetime.timedelta(days=i) for i in range(3)])

In [231]: df = pd.DataFrame({"A": s, "B": deltas})

In [232]: df
Out[232]: 
           A      B
0 2012-01-01 0 days
1 2012-01-02 1 days
2 2012-01-03 2 days

In [233]: df["New Dates"] = df["A"] + df["B"]

In [234]: df["Delta"] = df["A"] - df["New Dates"]

In [235]: df
Out[235]: 
           A      B  New Dates   Delta
0 2012-01-01 0 days 2012-01-01  0 days
1 2012-01-02 1 days 2012-01-03 -1 days
2 2012-01-03 2 days 2012-01-05 -2 days

In [236]: df.dtypes
Out[236]: 
A             datetime64[ns]
B            timedelta64[ns]
New Dates     datetime64[ns]
Delta        timedelta64[ns]
dtype: object

---->   pandas.Series; pandas.DataFrame

--------------------------------------
ID: 1515 --> 1
In [237]: y = s - s.shift()

In [238]: y
Out[238]: 
0      NaT
1   1 days
2   1 days
dtype: timedelta64[ns]

In [239]: y[1] = np.nan

In [240]: y
Out[240]: 
0      NaT
1      NaT
2   1 days
dtype: timedelta64[ns]

---->   Series.shift

--------------------------------------
ID: 1516 --> 1
In [241]: def expand_grid(data_dict):
   .....:     rows = itertools.product(*data_dict.values())
   .....:     return pd.DataFrame.from_records(rows, columns=data_dict.keys())
   .....: 

In [242]: df = expand_grid(
   .....:     {"height": [60, 70], "weight": [100, 140, 180], "sex": ["Male", "Female"]}
   .....: )
   .....: 

In [243]: df
Out[243]: 
    height  weight     sex
0       60     100    Male
1       60     100  Female
2       60     140    Male
3       60     140  Female
4       60     180    Male
5       60     180  Female
6       70     100    Male
7       70     100  Female
8       70     140    Male
9       70     140  Female
10      70     180    Male
11      70     180  Female

---->   pandas.DataFrame

--------------------------------------
ID: 1517 --> 2
In [1]: s = pd.Series(range(5))

In [2]: s.rolling(window=2).sum()
Out[2]: 
0    NaN
1    1.0
2    3.0
3    5.0
4    7.0
dtype: float64

---->   pandas.Series; Series.rolling

--------------------------------------
ID: 1518 --> 1
In [3]: for window in s.rolling(window=2):
   ...:     print(window)
   ...: 
0    0
dtype: int64
0    0
1    1
dtype: int64
1    1
2    2
dtype: int64
2    2
3    3
dtype: int64
3    3
4    4
dtype: int64

---->   Series.rolling

--------------------------------------
ID: 1519 --> 2
In [4]: s = pd.Series(range(5), index=pd.date_range('2020-01-01', periods=5, freq='1D'))

In [5]: s.rolling(window='2D').sum()
Out[5]: 
2020-01-01    0.0
2020-01-02    1.0
2020-01-03    3.0
2020-01-04    5.0
2020-01-05    7.0
Freq: D, dtype: float64

---->   pandas.Series; Series.rolling

--------------------------------------
ID: 1520 --> 2
In [6]: df = pd.DataFrame({'A': ['a', 'b', 'a', 'b', 'a'], 'B': range(5)})

In [7]: df.groupby('A').expanding().sum()
Out[7]: 
       B
A       
a 0  0.0
  2  2.0
  4  6.0
b 1  1.0
  3  4.0

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 1521 --> 2
In [8]: def weighted_mean(x):
   ...:     arr = np.ones((1, x.shape[1]))
   ...:     arr[:, :2] = (x[:, :2] * x[:, 2]).sum(axis=0) / x[:, 2].sum()
   ...:     return arr
   ...: 

In [9]: df = pd.DataFrame([[1, 2, 0.6], [2, 3, 0.4], [3, 4, 0.2], [4, 5, 0.7]])

In [10]: df.rolling(2, method="table", min_periods=0).apply(weighted_mean, raw=True, engine="numba")  # noqa:E501
Out[10]: 
          0         1    2
0  1.000000  2.000000  1.0
1  1.800000  2.000000  1.0
2  3.333333  2.333333  1.0
3  1.555556  7.000000  1.0

---->   pandas.DataFrame; DataFrame.rolling

--------------------------------------
ID: 1522 --> 2
In [11]: df = pd.DataFrame([[1, 2, 0.6], [2, 3, 0.4], [3, 4, 0.2], [4, 5, 0.7]])

In [12]: df.ewm(0.5).mean()
Out[12]: 
          0         1         2
0  1.000000  2.000000  0.600000
1  1.750000  2.750000  0.450000
2  2.615385  3.615385  0.276923
3  3.550000  4.550000  0.562500

---->   pandas.DataFrame; DataFrame.ewm

--------------------------------------
ID: 1523 --> 2
In [13]: online_ewm = df.head(2).ewm(0.5).online()

In [14]: online_ewm.mean()
Out[14]: 
      0     1     2
0  1.00  2.00  0.60
1  1.75  2.75  0.45

In [15]: online_ewm.mean(update=df.tail(1))
Out[15]: 
          0         1         2
3  3.307692  4.307692  0.623077

---->   DataFrame.head; DataFrame.tail

--------------------------------------
ID: 1524 --> 2
In [16]: s = pd.Series([np.nan, 1, 2, np.nan, np.nan, 3])

In [17]: s.rolling(window=3, min_periods=1).sum()
Out[17]: 
0    NaN
1    1.0
2    3.0
3    3.0
4    2.0
5    3.0
dtype: float64

In [18]: s.rolling(window=3, min_periods=2).sum()
Out[18]: 
0    NaN
1    NaN
2    3.0
3    3.0
4    NaN
5    NaN
dtype: float64

# Equivalent to min_periods=3
In [19]: s.rolling(window=3, min_periods=None).sum()
Out[19]: 
0   NaN
1   NaN
2   NaN
3   NaN
4   NaN
5   NaN
dtype: float64

---->   pandas.Series; Series.rolling

--------------------------------------
ID: 1525 --> 2
In [20]: df = pd.DataFrame({"A": range(5), "B": range(10, 15)})

In [21]: df.expanding().agg([np.sum, np.mean, np.std])
Out[21]: 
      A                    B                
    sum mean       std   sum  mean       std
0   0.0  0.0       NaN  10.0  10.0       NaN
1   1.0  0.5  0.707107  21.0  10.5  0.707107
2   3.0  1.0  1.000000  33.0  11.0  1.000000
3   6.0  1.5  1.290994  46.0  11.5  1.290994
4  10.0  2.0  1.581139  60.0  12.0  1.581139

---->   pandas.DataFrame; DataFrame.expanding

--------------------------------------
ID: 1526 --> 3
In [22]: times = ['2020-01-01', '2020-01-03', '2020-01-04', '2020-01-05', '2020-01-29']

In [23]: s = pd.Series(range(5), index=pd.DatetimeIndex(times))

In [24]: s
Out[24]: 
2020-01-01    0
2020-01-03    1
2020-01-04    2
2020-01-05    3
2020-01-29    4
dtype: int64

# Window with 2 observations
In [25]: s.rolling(window=2).sum()
Out[25]: 
2020-01-01    NaN
2020-01-03    1.0
2020-01-04    3.0
2020-01-05    5.0
2020-01-29    7.0
dtype: float64

# Window with 2 days worth of observations
In [26]: s.rolling(window='2D').sum()
Out[26]: 
2020-01-01    0.0
2020-01-03    1.0
2020-01-04    3.0
2020-01-05    5.0
2020-01-29    4.0
dtype: float64

---->   pandas.Series; pandas.DatetimeIndex; Series.rolling

--------------------------------------
ID: 1527 --> 2
In [27]: s = pd.Series(range(10))

In [28]: s.rolling(window=5).mean()
Out[28]: 
0    NaN
1    NaN
2    NaN
3    NaN
4    2.0
5    3.0
6    4.0
7    5.0
8    6.0
9    7.0
dtype: float64

In [29]: s.rolling(window=5, center=True).mean()
Out[29]: 
0    NaN
1    NaN
2    2.0
3    3.0
4    4.0
5    5.0
6    6.0
7    7.0
8    NaN
9    NaN
dtype: float64

---->   pandas.Series; Series.rolling

--------------------------------------
ID: 1528 --> 2
In [30]: df = pd.DataFrame(
   ....:     {"A": [0, 1, 2, 3, 4]}, index=pd.date_range("2020", periods=5, freq="1D")
   ....: )
   ....: 

In [31]: df
Out[31]: 
            A
2020-01-01  0
2020-01-02  1
2020-01-03  2
2020-01-04  3
2020-01-05  4

In [32]: df.rolling("2D", center=False).mean()
Out[32]: 
              A
2020-01-01  0.0
2020-01-02  0.5
2020-01-03  1.5
2020-01-04  2.5
2020-01-05  3.5

In [33]: df.rolling("2D", center=True).mean()
Out[33]: 
              A
2020-01-01  0.5
2020-01-02  1.5
2020-01-03  2.5
2020-01-04  3.5
2020-01-05  4.0

---->   pandas.DataFrame; DataFrame.rolling

--------------------------------------
ID: 1529 --> 3
In [34]: df = pd.DataFrame(
   ....:     {"x": 1},
   ....:     index=[
   ....:         pd.Timestamp("20130101 09:00:01"),
   ....:         pd.Timestamp("20130101 09:00:02"),
   ....:         pd.Timestamp("20130101 09:00:03"),
   ....:         pd.Timestamp("20130101 09:00:04"),
   ....:         pd.Timestamp("20130101 09:00:06"),
   ....:     ],
   ....: )
   ....: 

In [35]: df["right"] = df.rolling("2s", closed="right").x.sum()  # default

In [36]: df["both"] = df.rolling("2s", closed="both").x.sum()

In [37]: df["left"] = df.rolling("2s", closed="left").x.sum()

In [38]: df["neither"] = df.rolling("2s", closed="neither").x.sum()

In [39]: df
Out[39]: 
                     x  right  both  left  neither
2013-01-01 09:00:01  1    1.0   1.0   NaN      NaN
2013-01-01 09:00:02  1    2.0   2.0   1.0      1.0
2013-01-01 09:00:03  1    2.0   3.0   2.0      1.0
2013-01-01 09:00:04  1    2.0   3.0   2.0      1.0
2013-01-01 09:00:06  1    1.0   2.0   1.0      NaN

---->   pandas.DataFrame; DataFrame.rolling; Series.sum

--------------------------------------
ID: 1530 --> 1
In [40]: use_expanding = [True, False, True, False, True]

In [41]: use_expanding
Out[41]: [True, False, True, False, True]

In [42]: df = pd.DataFrame({"values": range(5)})

In [43]: df
Out[43]: 
   values
0       0
1       1
2       2
3       3
4       4

---->   pandas.DataFrame

--------------------------------------
ID: 1531 --> 1
In [2]: from pandas.api.indexers import BaseIndexer

In [3]: class CustomIndexer(BaseIndexer):
   ...:     def get_window_bounds(self, num_values, min_periods, center, closed):
   ...:         start = np.empty(num_values, dtype=np.int64)
   ...:         end = np.empty(num_values, dtype=np.int64)
   ...:         for i in range(num_values):
   ...:             if self.use_expanding[i]:
   ...:                 start[i] = 0
   ...:                 end[i] = i + 1
   ...:             else:
   ...:                 start[i] = i
   ...:                 end[i] = i + self.window_size
   ...:         return start, end

In [4]: indexer = CustomIndexer(window_size=1, use_expanding=use_expanding)

In [5]: df.rolling(indexer).sum()
Out[5]:
    values
0     0.0
1     1.0
2     3.0
3     3.0
4    10.0

---->   DataFrame.rolling

--------------------------------------
ID: 1532 --> 2
In [44]: from pandas.api.indexers import VariableOffsetWindowIndexer

In [45]: df = pd.DataFrame(range(10), index=pd.date_range("2020", periods=10))

In [46]: offset = pd.offsets.BDay(1)

In [47]: indexer = VariableOffsetWindowIndexer(index=df.index, offset=offset)

In [48]: df
Out[48]: 
            0
2020-01-01  0
2020-01-02  1
2020-01-03  2
2020-01-04  3
2020-01-05  4
2020-01-06  5
2020-01-07  6
2020-01-08  7
2020-01-09  8
2020-01-10  9

In [49]: df.rolling(indexer).sum()
Out[49]: 
               0
2020-01-01   0.0
2020-01-02   1.0
2020-01-03   2.0
2020-01-04   3.0
2020-01-05   7.0
2020-01-06  12.0
2020-01-07   6.0
2020-01-08   7.0
2020-01-09   8.0
2020-01-10   9.0

---->   pandas.DataFrame; DataFrame.rolling

--------------------------------------
ID: 1533 --> 1
In [50]: from pandas.api.indexers import FixedForwardWindowIndexer

In [51]: indexer = FixedForwardWindowIndexer(window_size=2)

In [52]: df.rolling(indexer, min_periods=1).sum()
Out[52]: 
               0
2020-01-01   1.0
2020-01-02   3.0
2020-01-03   5.0
2020-01-04   7.0
2020-01-05   9.0
2020-01-06  11.0
2020-01-07  13.0
2020-01-08  15.0
2020-01-09  17.0
2020-01-10   9.0

---->   DataFrame.rolling

--------------------------------------
ID: 1534 --> 1
In [53]: df = pd.DataFrame(
   ....:     data=[
   ....:         [pd.Timestamp("2018-01-01 00:00:00"), 100],
   ....:         [pd.Timestamp("2018-01-01 00:00:01"), 101],
   ....:         [pd.Timestamp("2018-01-01 00:00:03"), 103],
   ....:         [pd.Timestamp("2018-01-01 00:00:04"), 111],
   ....:     ],
   ....:     columns=["time", "value"],
   ....: ).set_index("time")
   ....: 

In [54]: df
Out[54]: 
                     value
time                      
2018-01-01 00:00:00    100
2018-01-01 00:00:01    101
2018-01-01 00:00:03    103
2018-01-01 00:00:04    111

In [55]: reversed_df = df[::-1].rolling("2s").sum()[::-1]

In [56]: reversed_df
Out[56]: 
                     value
time                      
2018-01-01 00:00:00  201.0
2018-01-01 00:00:01  101.0
2018-01-01 00:00:03  214.0
2018-01-01 00:00:04  111.0

---->   pandas.DataFrame

--------------------------------------
ID: 1535 --> 3
In [57]: def mad(x):
   ....:     return np.fabs(x - x.mean()).mean()
   ....: 

In [58]: s = pd.Series(range(10))

In [59]: s.rolling(window=4).apply(mad, raw=True)
Out[59]: 
0    NaN
1    NaN
2    NaN
3    1.0
4    1.0
5    1.0
6    1.0
7    1.0
8    1.0
9    1.0
dtype: float64

---->   Series.mean; pandas.Series; Series.rolling

--------------------------------------
ID: 1536 --> 3
In [60]: df = pd.DataFrame(
   ....:     np.random.randn(10, 4),
   ....:     index=pd.date_range("2020-01-01", periods=10),
   ....:     columns=["A", "B", "C", "D"],
   ....: )
   ....: 

In [61]: df = df.cumsum()

In [62]: df2 = df[:4]

In [63]: df2.rolling(window=2).corr(df2["B"])
Out[63]: 
              A    B    C    D
2020-01-01  NaN  NaN  NaN  NaN
2020-01-02 -1.0  1.0 -1.0  1.0
2020-01-03  1.0  1.0  1.0 -1.0
2020-01-04 -1.0  1.0  1.0 -1.0

---->   pandas.DataFrame; DataFrame.cumsum; DataFrame.rolling

--------------------------------------
ID: 1538 --> 2
In [66]: s = pd.Series(range(10))

In [67]: s.rolling(window=5).mean()
Out[67]: 
0    NaN
1    NaN
2    NaN
3    NaN
4    2.0
5    3.0
6    4.0
7    5.0
8    6.0
9    7.0
dtype: float64

In [68]: s.rolling(window=5, win_type="triang").mean()
Out[68]: 
0    NaN
1    NaN
2    NaN
3    NaN
4    2.0
5    3.0
6    4.0
7    5.0
8    6.0
9    7.0
dtype: float64

# Supplementary Scipy arguments passed in the aggregation function
In [69]: s.rolling(window=5, win_type="gaussian").mean(std=0.1)
Out[69]: 
0    NaN
1    NaN
2    NaN
3    NaN
4    2.0
5    3.0
6    4.0
7    5.0
8    6.0
9    7.0
dtype: float64

---->   pandas.Series; Series.rolling

--------------------------------------
ID: 1539 --> 3
In [70]: df = pd.DataFrame(range(5))

In [71]: df.rolling(window=len(df), min_periods=1).mean()
Out[71]: 
     0
0  0.0
1  0.5
2  1.0
3  1.5
4  2.0

In [72]: df.expanding(min_periods=1).mean()
Out[72]: 
     0
0  0.0
1  0.5
2  1.0
3  1.5
4  2.0

---->   pandas.DataFrame; DataFrame.rolling; DataFrame.expanding

--------------------------------------
ID: 1540 --> 3
In [73]: df = pd.DataFrame({"B": [0, 1, 2, np.nan, 4]})

In [74]: df
Out[74]: 
     B
0  0.0
1  1.0
2  2.0
3  NaN
4  4.0

In [75]: times = ["2020-01-01", "2020-01-03", "2020-01-10", "2020-01-15", "2020-01-17"]

In [76]: df.ewm(halflife="4 days", times=pd.DatetimeIndex(times)).mean()
Out[76]: 
          B
0  0.000000
1  0.585786
2  1.523889
3  1.523889
4  3.233686

---->   pandas.DataFrame; DataFrame.ewm; pandas.DatetimeIndex

--------------------------------------
ID: 1541 --> 2
In [1]: arr = pd.array([1, 2, None], dtype=pd.Int64Dtype())

In [2]: arr
Out[2]: 

[1, 2, ]
Length: 3, dtype: Int64

---->   pandas.array; pandas.Int64Dtype

--------------------------------------
ID: 1542 --> 1
In [3]: pd.array([1, 2, np.nan], dtype="Int64")
Out[3]: 

[1, 2, ]
Length: 3, dtype: Int64

---->   pandas.array

--------------------------------------
ID: 1543 --> 1
In [4]: pd.array([1, 2, np.nan, None, pd.NA], dtype="Int64")
Out[4]: 

[1, 2, , , ]
Length: 5, dtype: Int64

---->   pandas.array

--------------------------------------
ID: 1544 --> 1
In [5]: pd.Series(arr)
Out[5]: 
0       1
1       2
2    
dtype: Int64

---->   pandas.Series

--------------------------------------
ID: 1545 --> 1
In [6]: pd.array([1, None])
Out[6]: 

[1, ]
Length: 2, dtype: Int64

In [7]: pd.array([1, 2])
Out[7]: 

[1, 2]
Length: 2, dtype: Int64

---->   pandas.array

--------------------------------------
ID: 1546 --> 1
In [8]: pd.Series([1, None])
Out[8]: 
0    1.0
1    NaN
dtype: float64

In [9]: pd.Series([1, 2])
Out[9]: 
0    1
1    2
dtype: int64

---->   pandas.Series

--------------------------------------
ID: 1547 --> 2
In [10]: pd.array([1, None], dtype="Int64")
Out[10]: 

[1, ]
Length: 2, dtype: Int64

In [11]: pd.Series([1, None], dtype="Int64")
Out[11]: 
0       1
1    
dtype: Int64

---->   pandas.array; pandas.Series

--------------------------------------
ID: 1548 --> 1
In [12]: s = pd.Series([1, 2, None], dtype="Int64")

# arithmetic
In [13]: s + 1
Out[13]: 
0       2
1       3
2    
dtype: Int64

# comparison
In [14]: s == 1
Out[14]: 
0     True
1    False
2     
dtype: boolean

# indexing
In [15]: s.iloc[1:3]
Out[15]: 
1       2
2    
dtype: Int64

# operate with other dtypes
In [16]: s + s.iloc[1:3].astype("Int8")
Out[16]: 
0    
1       4
2    
dtype: Int64

# coerce when needed
In [17]: s + 0.01
Out[17]: 
0    1.01
1    2.01
2    
dtype: Float64

---->   pandas.Series

--------------------------------------
ID: 1549 --> 1
In [18]: df = pd.DataFrame({"A": s, "B": [1, 1, 3], "C": list("aab")})

In [19]: df
Out[19]: 
      A  B  C
0     1  1  a
1     2  1  a
2    3  b

In [20]: df.dtypes
Out[20]: 
A     Int64
B     int64
C    object
dtype: object

---->   pandas.DataFrame

--------------------------------------
ID: 1551 --> 2
In [23]: df.sum()
Out[23]: 
A      3
B      5
C    aab
dtype: object

In [24]: df.groupby("B").A.sum()
Out[24]: 
B
1    3
3    0
Name: A, dtype: Int64

---->   DataFrame.sum; DataFrame.groupby

--------------------------------------
ID: 1552 --> 1
In [25]: a = pd.array([1, None], dtype="Int64")

In [26]: a[1]
Out[26]: 

---->   pandas.array

--------------------------------------
ID: 1553 --> 2
In [1]: arrays = [
   ...:     ["bar", "bar", "baz", "baz", "foo", "foo", "qux", "qux"],
   ...:     ["one", "two", "one", "two", "one", "two", "one", "two"],
   ...: ]
   ...: 

In [2]: tuples = list(zip(*arrays))

In [3]: tuples
Out[3]: 
[('bar', 'one'),
 ('bar', 'two'),
 ('baz', 'one'),
 ('baz', 'two'),
 ('foo', 'one'),
 ('foo', 'two'),
 ('qux', 'one'),
 ('qux', 'two')]

In [4]: index = pd.MultiIndex.from_tuples(tuples, names=["first", "second"])

In [5]: index
Out[5]: 
MultiIndex([('bar', 'one'),
            ('bar', 'two'),
            ('baz', 'one'),
            ('baz', 'two'),
            ('foo', 'one'),
            ('foo', 'two'),
            ('qux', 'one'),
            ('qux', 'two')],
           names=['first', 'second'])

In [6]: s = pd.Series(np.random.randn(8), index=index)

In [7]: s
Out[7]: 
first  second
bar    one       0.469112
       two      -0.282863
baz    one      -1.509059
       two      -1.135632
foo    one       1.212112
       two      -0.173215
qux    one       0.119209
       two      -1.044236
dtype: float64

---->   pandas.MultiIndex; pandas.Series

--------------------------------------
ID: 1554 --> 1
In [8]: iterables = [["bar", "baz", "foo", "qux"], ["one", "two"]]

In [9]: pd.MultiIndex.from_product(iterables, names=["first", "second"])
Out[9]: 
MultiIndex([('bar', 'one'),
            ('bar', 'two'),
            ('baz', 'one'),
            ('baz', 'two'),
            ('foo', 'one'),
            ('foo', 'two'),
            ('qux', 'one'),
            ('qux', 'two')],
           names=['first', 'second'])

---->   pandas.MultiIndex

--------------------------------------
ID: 1555 --> 2
In [10]: df = pd.DataFrame(
   ....:     [["bar", "one"], ["bar", "two"], ["foo", "one"], ["foo", "two"]],
   ....:     columns=["first", "second"],
   ....: )
   ....: 

In [11]: pd.MultiIndex.from_frame(df)
Out[11]: 
MultiIndex([('bar', 'one'),
            ('bar', 'two'),
            ('foo', 'one'),
            ('foo', 'two')],
           names=['first', 'second'])

---->   pandas.DataFrame; pandas.MultiIndex

--------------------------------------
ID: 1556 --> 2
In [12]: arrays = [
   ....:     np.array(["bar", "bar", "baz", "baz", "foo", "foo", "qux", "qux"]),
   ....:     np.array(["one", "two", "one", "two", "one", "two", "one", "two"]),
   ....: ]
   ....: 

In [13]: s = pd.Series(np.random.randn(8), index=arrays)

In [14]: s
Out[14]: 
bar  one   -0.861849
     two   -2.104569
baz  one   -0.494929
     two    1.071804
foo  one    0.721555
     two   -0.706771
qux  one   -1.039575
     two    0.271860
dtype: float64

In [15]: df = pd.DataFrame(np.random.randn(8, 4), index=arrays)

In [16]: df
Out[16]: 
                0         1         2         3
bar one -0.424972  0.567020  0.276232 -1.087401
    two -0.673690  0.113648 -1.478427  0.524988
baz one  0.404705  0.577046 -1.715002 -1.039268
    two -0.370647 -1.157892 -1.344312  0.844885
foo one  1.075770 -0.109050  1.643563 -1.469388
    two  0.357021 -0.674600 -1.776904 -0.968914
qux one -1.294524  0.413738  0.276662 -0.472035
    two -0.013960 -0.362543 -0.006154 -0.923061

---->   pandas.Series; pandas.DataFrame

--------------------------------------
ID: 1558 --> 1
In [18]: df = pd.DataFrame(np.random.randn(3, 8), index=["A", "B", "C"], columns=index)

In [19]: df
Out[19]: 
first        bar                 baz  ...       foo       qux          
second       one       two       one  ...       two       one       two
A       0.895717  0.805244 -1.206412  ...  1.340309 -1.170299 -0.226169
B       0.410835  0.813850  0.132003  ... -1.187678  1.130127 -1.436737
C      -1.413681  1.607920  1.024180  ... -2.211372  0.974466 -2.006747

[3 rows x 8 columns]

In [20]: pd.DataFrame(np.random.randn(6, 6), index=index[:6], columns=index[:6])
Out[20]: 
first              bar                 baz                 foo          
second             one       two       one       two       one       two
first second                                                            
bar   one    -0.410001 -0.078638  0.545952 -1.219217 -1.226825  0.769804
      two    -1.281247 -0.727707 -0.121306 -0.097883  0.695775  0.341734
baz   one     0.959726 -1.110336 -0.619976  0.149748 -0.732339  0.687738
      two     0.176444  0.403310 -0.154951  0.301624 -2.179861 -1.369849
foo   one    -0.954208  1.462696 -1.743161 -0.826591 -0.345352  1.314232
      two     0.690579  0.995761  2.396780  0.014871  3.357427 -0.317441

---->   pandas.DataFrame

--------------------------------------
ID: 1560 --> 1
In [22]: pd.Series(np.random.randn(8), index=tuples)
Out[22]: 
(bar, one)   -1.236269
(bar, two)    0.896171
(baz, one)   -0.487602
(baz, two)   -0.082240
(foo, one)   -2.182937
(foo, two)    0.380396
(qux, one)    0.084844
(qux, two)    0.432390
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 1561 --> 1
In [23]: index.get_level_values(0)
Out[23]: Index(['bar', 'bar', 'baz', 'baz', 'foo', 'foo', 'qux', 'qux'], dtype='object', name='first')

In [24]: index.get_level_values("second")
Out[24]: Index(['one', 'two', 'one', 'two', 'one', 'two', 'one', 'two'], dtype='object', name='second')

---->   Index.get_level_values

--------------------------------------
ID: 1564 --> 1
In [31]: df[["foo", "qux"]].columns.to_numpy()
Out[31]: 
array([('foo', 'one'), ('foo', 'two'), ('qux', 'one'), ('qux', 'two')],
      dtype=object)

# for a specific level
In [32]: df[["foo", "qux"]].columns.get_level_values(0)
Out[32]: Index(['foo', 'foo', 'qux', 'qux'], dtype='object', name='first')

---->   Index.get_level_values

--------------------------------------
ID: 1571 --> 2
In [48]: s = pd.Series(
   ....:     [1, 2, 3, 4, 5, 6],
   ....:     index=pd.MultiIndex.from_product([["A", "B"], ["c", "d", "e"]]),
   ....: )
   ....: 

In [49]: s.loc[[("A", "c"), ("B", "d")]]  # list of tuples
Out[49]: 
A  c    1
B  d    5
dtype: int64

In [50]: s.loc[(["A", "B"], ["c", "d"])]  # tuple of lists
Out[50]: 
A  c    1
   d    2
B  c    4
   d    5
dtype: int64

---->   pandas.Series; pandas.MultiIndex

--------------------------------------
ID: 1574 --> 3
In [51]: def mklbl(prefix, n):
   ....:     return ["%s%s" % (prefix, i) for i in range(n)]
   ....: 

In [52]: miindex = pd.MultiIndex.from_product(
   ....:     [mklbl("A", 4), mklbl("B", 2), mklbl("C", 4), mklbl("D", 2)]
   ....: )
   ....: 

In [53]: micolumns = pd.MultiIndex.from_tuples(
   ....:     [("a", "foo"), ("a", "bar"), ("b", "foo"), ("b", "bah")], names=["lvl0", "lvl1"]
   ....: )
   ....: 

In [54]: dfmi = (
   ....:     pd.DataFrame(
   ....:         np.arange(len(miindex) * len(micolumns)).reshape(
   ....:             (len(miindex), len(micolumns))
   ....:         ),
   ....:         index=miindex,
   ....:         columns=micolumns,
   ....:     )
   ....:     .sort_index()
   ....:     .sort_index(axis=1)
   ....: )
   ....: 

In [55]: dfmi
Out[55]: 
lvl0           a         b     
lvl1         bar  foo  bah  foo
A0 B0 C0 D0    1    0    3    2
         D1    5    4    7    6
      C1 D0    9    8   11   10
         D1   13   12   15   14
      C2 D0   17   16   19   18
...          ...  ...  ...  ...
A3 B1 C1 D1  237  236  239  238
      C2 D0  241  240  243  242
         D1  245  244  247  246
      C3 D0  249  248  251  250
         D1  253  252  255  254

[64 rows x 4 columns]

---->   pandas.MultiIndex; pandas.MultiIndex; pandas.DataFrame

--------------------------------------
ID: 1581 --> 1
In [70]: df
Out[70]: 
                     A         B         C
first second                              
bar   one     0.895717  0.410835 -1.413681
      two     0.805244  0.813850  1.607920
baz   one    -1.206412  0.132003  1.024180
      two     2.565646 -0.827317  0.569605
foo   one     1.431256 -0.076467  0.875906
      two     1.340309 -1.187678 -2.211372
qux   one    -1.170299  1.130127  0.974466
      two    -0.226169 -1.436737 -2.006747

In [71]: df.xs("one", level="second")
Out[71]: 
              A         B         C
first                              
bar    0.895717  0.410835 -1.413681
baz   -1.206412  0.132003  1.024180
foo    1.431256 -0.076467  0.875906
qux   -1.170299  1.130127  0.974466

---->   DataFrame.xs

--------------------------------------
ID: 1583 --> 1
In [73]: df = df.T

In [74]: df.xs("one", level="second", axis=1)
Out[74]: 
first       bar       baz       foo       qux
A      0.895717 -1.206412  1.431256 -1.170299
B      0.410835  0.132003 -0.076467  1.130127
C     -1.413681  1.024180  0.875906  0.974466

---->   DataFrame.xs

--------------------------------------
ID: 1585 --> 1
In [76]: df.xs(("one", "bar"), level=("second", "first"), axis=1)
Out[76]: 
first        bar
second       one
A       0.895717
B       0.410835
C      -1.413681

---->   DataFrame.xs

--------------------------------------
ID: 1587 --> 1
In [78]: df.xs("one", level="second", axis=1, drop_level=False)
Out[78]: 
first        bar       baz       foo       qux
second       one       one       one       one
A       0.895717 -1.206412  1.431256 -1.170299
B       0.410835  0.132003 -0.076467  1.130127
C      -1.413681  1.024180  0.875906  0.974466

---->   DataFrame.xs

--------------------------------------
ID: 1588 --> 1
In [79]: df.xs("one", level="second", axis=1, drop_level=True)
Out[79]: 
first       bar       baz       foo       qux
A      0.895717 -1.206412  1.431256 -1.170299
B      0.410835  0.132003 -0.076467  1.130127
C     -1.413681  1.024180  0.875906  0.974466

---->   DataFrame.xs

--------------------------------------
ID: 1589 --> 4
In [80]: midx = pd.MultiIndex(
   ....:     levels=[["zero", "one"], ["x", "y"]], codes=[[1, 1, 0, 0], [1, 0, 1, 0]]
   ....: )
   ....: 

In [81]: df = pd.DataFrame(np.random.randn(4, 2), index=midx)

In [82]: df
Out[82]: 
               0         1
one  y  1.519970 -0.493662
     x  0.600178  0.274230
zero y  0.132885 -0.023688
     x  2.410179  1.450520

In [83]: df2 = df.groupby(level=0).mean()

In [84]: df2
Out[84]: 
             0         1
one   1.060074 -0.109716
zero  1.271532  0.713416

In [85]: df2.reindex(df.index, level=0)
Out[85]: 
               0         1
one  y  1.060074 -0.109716
     x  1.060074 -0.109716
zero y  1.271532  0.713416
     x  1.271532  0.713416

# aligning
In [86]: df_aligned, df2_aligned = df.align(df2, level=0)

In [87]: df_aligned
Out[87]: 
               0         1
one  y  1.519970 -0.493662
     x  0.600178  0.274230
zero y  0.132885 -0.023688
     x  2.410179  1.450520

In [88]: df2_aligned
Out[88]: 
               0         1
one  y  1.060074 -0.109716
     x  1.060074 -0.109716
zero y  1.271532  0.713416
     x  1.271532  0.713416

---->   pandas.MultiIndex; pandas.DataFrame; DataFrame.groupby; DataFrame.align

--------------------------------------
ID: 1596 --> 1
In [96]: mi = pd.MultiIndex.from_product([[1, 2], ["a", "b"]], names=["x", "y"])

In [97]: mi.names
Out[97]: FrozenList(['x', 'y'])

In [98]: mi2 = mi.rename("new name", level=0)

In [99]: mi2
Out[99]: 
MultiIndex([(1, 'a'),
            (1, 'b'),
            (2, 'a'),
            (2, 'b')],
           names=['new name', 'y'])

---->   pandas.MultiIndex

--------------------------------------
ID: 1598 --> 2
In [101]: import random

In [102]: random.shuffle(tuples)

In [103]: s = pd.Series(np.random.randn(8), index=pd.MultiIndex.from_tuples(tuples))

In [104]: s
Out[104]: 
foo  two    0.206053
bar  two   -0.251905
baz  one   -2.213588
     two    1.063327
qux  one    1.266143
bar  one    0.299368
foo  one   -0.863838
qux  two    0.408204
dtype: float64

In [105]: s.sort_index()
Out[105]: 
bar  one    0.299368
     two   -0.251905
baz  one   -2.213588
     two    1.063327
foo  one   -0.863838
     two    0.206053
qux  one    1.266143
     two    0.408204
dtype: float64

In [106]: s.sort_index(level=0)
Out[106]: 
bar  one    0.299368
     two   -0.251905
baz  one   -2.213588
     two    1.063327
foo  one   -0.863838
     two    0.206053
qux  one    1.266143
     two    0.408204
dtype: float64

In [107]: s.sort_index(level=1)
Out[107]: 
bar  one    0.299368
baz  one   -2.213588
foo  one   -0.863838
qux  one    1.266143
bar  two   -0.251905
baz  two    1.063327
foo  two    0.206053
qux  two    0.408204
dtype: float64

---->   pandas.Series; pandas.MultiIndex

--------------------------------------
ID: 1601 --> 1
In [112]: dfm = pd.DataFrame(
   .....:     {"jim": [0, 0, 1, 1], "joe": ["x", "x", "z", "y"], "jolie": np.random.rand(4)}
   .....: )
   .....: 

In [113]: dfm = dfm.set_index(["jim", "joe"])

In [114]: dfm
Out[114]: 
            jolie
jim joe          
0   x    0.490671
    x    0.120248
1   z    0.537020
    y    0.110968

---->   pandas.DataFrame

--------------------------------------
ID: 1606 --> 4
In [120]: index = pd.Index(np.random.randint(0, 1000, 10))

In [121]: index
Out[121]: Index([214, 502, 712, 567, 786, 175, 993, 133, 758, 329], dtype='int64')

In [122]: positions = [0, 9, 3]

In [123]: index[positions]
Out[123]: Index([214, 329, 567], dtype='int64')

In [124]: index.take(positions)
Out[124]: Index([214, 329, 567], dtype='int64')

In [125]: ser = pd.Series(np.random.randn(10))

In [126]: ser.iloc[positions]
Out[126]: 
0   -0.179666
9    1.824375
3    0.392149
dtype: float64

In [127]: ser.take(positions)
Out[127]: 
0   -0.179666
9    1.824375
3    0.392149
dtype: float64

---->   pandas.Index; Index.take; pandas.Series; Series.take

--------------------------------------
ID: 1607 --> 2
In [128]: frm = pd.DataFrame(np.random.randn(5, 3))

In [129]: frm.take([1, 4, 3])
Out[129]: 
          0         1         2
1 -1.237881  0.106854 -1.276829
4  0.629675 -1.425966  1.857704
3  0.979542 -1.633678  0.615855

In [130]: frm.take([0, 2], axis=1)
Out[130]: 
          0         2
0  0.595974  0.601544
1 -1.237881 -1.276829
2 -0.767101  1.499591
3  0.979542  0.615855
4  0.629675  1.857704

---->   pandas.DataFrame; DataFrame.take

--------------------------------------
ID: 1608 --> 2
In [131]: arr = np.random.randn(10)

In [132]: arr.take([False, False, True, True])
Out[132]: array([-1.1935, -1.1935,  0.6775,  0.6775])

In [133]: arr[[0, 1]]
Out[133]: array([-1.1935,  0.6775])

In [134]: ser = pd.Series(np.random.randn(10))

In [135]: ser.take([False, False, True, True])
Out[135]: 
0    0.233141
0    0.233141
1   -0.223540
1   -0.223540
dtype: float64

In [136]: ser.iloc[[0, 1]]
Out[136]: 
0    0.233141
1   -0.223540
dtype: float64

---->   pandas.Series; Series.take

--------------------------------------
ID: 1610 --> 2
In [141]: ser = pd.Series(arr[:, 0])

In [142]: %timeit ser.iloc[indexer]
   .....: %timeit ser.take(indexer)
   .....: 
77.3 us +- 1.45 us per loop (mean +- std. dev. of 7 runs, 10,000 loops each)
64.1 us +- 155 ns per loop (mean +- std. dev. of 7 runs, 10,000 loops each)

---->   pandas.Series; Series.take

--------------------------------------
ID: 1611 --> 1
In [143]: from pandas.api.types import CategoricalDtype

In [144]: df = pd.DataFrame({"A": np.arange(6), "B": list("aabbca")})

In [145]: df["B"] = df["B"].astype(CategoricalDtype(list("cab")))

In [146]: df
Out[146]: 
   A  B
0  0  a
1  1  a
2  2  b
3  3  b
4  4  c
5  5  a

In [147]: df.dtypes
Out[147]: 
A       int64
B    category
dtype: object

In [148]: df["B"].cat.categories
Out[148]: Index(['c', 'a', 'b'], dtype='object')

---->   pandas.DataFrame

--------------------------------------
ID: 1615 --> 1
In [154]: df2.groupby(level=0).sum()
Out[154]: 
   A
B   
c  4
a  6
b  5

In [155]: df2.groupby(level=0).sum().index
Out[155]: CategoricalIndex(['c', 'a', 'b'], categories=['c', 'a', 'b'], ordered=False, dtype='category', name='B')

---->   DataFrame.groupby

--------------------------------------
ID: 1616 --> 2
In [156]: df3 = pd.DataFrame(
   .....:     {"A": np.arange(3), "B": pd.Series(list("abc")).astype("category")}
   .....: )
   .....: 

In [157]: df3 = df3.set_index("B")

In [158]: df3
Out[158]: 
   A
B   
a  0
b  1
c  2

---->   pandas.DataFrame; pandas.Series

--------------------------------------
ID: 1617 --> 1
In [159]: df3.reindex(["a", "e"])
Out[159]: 
     A
B     
a  0.0
e  NaN

In [160]: df3.reindex(["a", "e"]).index
Out[160]: Index(['a', 'e'], dtype='object', name='B')

In [161]: df3.reindex(pd.Categorical(["a", "e"], categories=list("abe")))
Out[161]: 
     A
B     
a  0.0
e  NaN

In [162]: df3.reindex(pd.Categorical(["a", "e"], categories=list("abe"))).index
Out[162]: CategoricalIndex(['a', 'e'], categories=['a', 'b', 'e'], ordered=False, dtype='category', name='B')

---->   pandas.Categorical

--------------------------------------
ID: 1618 --> 1
In [163]: df4 = pd.DataFrame({"A": np.arange(2), "B": list("ba")})

In [164]: df4["B"] = df4["B"].astype(CategoricalDtype(list("ab")))

In [165]: df4 = df4.set_index("B")

In [166]: df4.index
Out[166]: CategoricalIndex(['b', 'a'], categories=['a', 'b'], ordered=False, dtype='category', name='B')

In [167]: df5 = pd.DataFrame({"A": np.arange(2), "B": list("bc")})

In [168]: df5["B"] = df5["B"].astype(CategoricalDtype(list("bc")))

In [169]: df5 = df5.set_index("B")

In [170]: df5.index
Out[170]: CategoricalIndex(['b', 'c'], categories=['b', 'c'], ordered=False, dtype='category', name='B')

---->   pandas.DataFrame

--------------------------------------
ID: 1620 --> 1
In [171]: idx = pd.RangeIndex(5)

In [172]: idx
Out[172]: RangeIndex(start=0, stop=5, step=1)

---->   pandas.RangeIndex

--------------------------------------
ID: 1621 --> 2
In [173]: ser = pd.Series([1, 2, 3])

In [174]: ser.index
Out[174]: RangeIndex(start=0, stop=3, step=1)

In [175]: df = pd.DataFrame([[1, 2], [3, 4]])

In [176]: df.index
Out[176]: RangeIndex(start=0, stop=2, step=1)

In [177]: df.columns
Out[177]: RangeIndex(start=0, stop=2, step=1)

---->   pandas.Series; pandas.DataFrame

--------------------------------------
ID: 1623 --> 2
In [179]: df = pd.DataFrame(
   .....:     {"A": [1, 2, 3, 4]}, index=pd.IntervalIndex.from_breaks([0, 1, 2, 3, 4])
   .....: )
   .....: 

In [180]: df
Out[180]: 
        A
(0, 1]  1
(1, 2]  2
(2, 3]  3
(3, 4]  4

---->   pandas.DataFrame; pandas.IntervalIndex

--------------------------------------
ID: 1626 --> 1
In [185]: df.loc[pd.Interval(1, 2)]
Out[185]: 
A    2
Name: (1, 2], dtype: int64

---->   pandas.Interval

--------------------------------------
ID: 1627 --> 1
In [7]: df.loc[pd.Interval(0.5, 2.5)]
---------------------------------------------------------------------------
KeyError: Interval(0.5, 2.5, closed='right')

---->   pandas.Interval

--------------------------------------
ID: 1628 --> 1
In [186]: idxr = df.index.overlaps(pd.Interval(0.5, 2.5))

In [187]: idxr
Out[187]: array([ True,  True,  True, False])

In [188]: df[idxr]
Out[188]: 
        A
(0, 1]  1
(1, 2]  2
(2, 3]  3

---->   pandas.Interval

--------------------------------------
ID: 1629 --> 1
In [189]: c = pd.cut(range(4), bins=2)

In [190]: c
Out[190]: 
[(-0.003, 1.5], (-0.003, 1.5], (1.5, 3.0], (1.5, 3.0]]
Categories (2, interval[float64, right]): [(-0.003, 1.5] < (1.5, 3.0]]

In [191]: c.categories
Out[191]: IntervalIndex([(-0.003, 1.5], (1.5, 3.0]], dtype='interval[float64, right]')

---->   pandas.cut

--------------------------------------
ID: 1630 --> 1
In [192]: pd.cut([0, 3, 5, 1], bins=c.categories)
Out[192]: 
[(-0.003, 1.5], (1.5, 3.0], NaN, (-0.003, 1.5]]
Categories (2, interval[float64, right]): [(-0.003, 1.5] < (1.5, 3.0]]

---->   pandas.cut

--------------------------------------
ID: 1631 --> 1
In [193]: pd.interval_range(start=0, end=5)
Out[193]: IntervalIndex([(0, 1], (1, 2], (2, 3], (3, 4], (4, 5]], dtype='interval[int64, right]')

In [194]: pd.interval_range(start=pd.Timestamp("2017-01-01"), periods=4)
Out[194]: IntervalIndex([(2017-01-01, 2017-01-02], (2017-01-02, 2017-01-03], (2017-01-03, 2017-01-04], (2017-01-04, 2017-01-05]], dtype='interval[datetime64[ns], right]')

In [195]: pd.interval_range(end=pd.Timedelta("3 days"), periods=3)
Out[195]: IntervalIndex([(0 days 00:00:00, 1 days 00:00:00], (1 days 00:00:00, 2 days 00:00:00], (2 days 00:00:00, 3 days 00:00:00]], dtype='interval[timedelta64[ns], right]')

---->   pandas.interval_range

--------------------------------------
ID: 1632 --> 1
In [196]: pd.interval_range(start=0, periods=5, freq=1.5)
Out[196]: IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0], (6.0, 7.5]], dtype='interval[float64, right]')

In [197]: pd.interval_range(start=pd.Timestamp("2017-01-01"), periods=4, freq="W")
Out[197]: IntervalIndex([(2017-01-01, 2017-01-08], (2017-01-08, 2017-01-15], (2017-01-15, 2017-01-22], (2017-01-22, 2017-01-29]], dtype='interval[datetime64[ns], right]')

In [198]: pd.interval_range(start=pd.Timedelta("0 days"), periods=3, freq="9H")
Out[198]: IntervalIndex([(0 days 00:00:00, 0 days 09:00:00], (0 days 09:00:00, 0 days 18:00:00], (0 days 18:00:00, 1 days 03:00:00]], dtype='interval[timedelta64[ns], right]')

---->   pandas.interval_range

--------------------------------------
ID: 1633 --> 1
In [199]: pd.interval_range(start=0, end=4, closed="both")
Out[199]: IntervalIndex([[0, 1], [1, 2], [2, 3], [3, 4]], dtype='interval[int64, both]')

In [200]: pd.interval_range(start=0, end=4, closed="neither")
Out[200]: IntervalIndex([(0, 1), (1, 2), (2, 3), (3, 4)], dtype='interval[int64, neither]')

---->   pandas.interval_range

--------------------------------------
ID: 1634 --> 1
In [201]: pd.interval_range(start=0, end=6, periods=4)
Out[201]: IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]], dtype='interval[float64, right]')

In [202]: pd.interval_range(pd.Timestamp("2018-01-01"), pd.Timestamp("2018-02-28"), periods=3)
Out[202]: IntervalIndex([(2018-01-01, 2018-01-20 08:00:00], (2018-01-20 08:00:00, 2018-02-08 16:00:00], (2018-02-08 16:00:00, 2018-02-28]], dtype='interval[datetime64[ns], right]')

---->   pandas.interval_range

--------------------------------------
ID: 1635 --> 2
In [203]: s = pd.Series(range(5))

In [204]: s[-1]
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
File ~/work/pandas/pandas/pandas/core/indexes/range.py:345, in RangeIndex.get_loc(self, key)
    344 try:
--> 345     return self._range.index(new_key)
    346 except ValueError as err:

ValueError: -1 is not in range

The above exception was the direct cause of the following exception:

KeyError                                  Traceback (most recent call last)
Cell In[204], line 1
----> 1 s[-1]

File ~/work/pandas/pandas/pandas/core/series.py:1007, in Series.__getitem__(self, key)
   1004     return self._values[key]
   1006 elif key_is_scalar:
-> 1007     return self._get_value(key)
   1009 if is_hashable(key):
   1010     # Otherwise index.get_value will raise InvalidIndexError
   1011     try:
   1012         # For labels that don't resolve as scalars like tuples and frozensets

File ~/work/pandas/pandas/pandas/core/series.py:1116, in Series._get_value(self, label, takeable)
   1113     return self._values[label]
   1115 # Similar to Index.get_value, but we do not fall back to positional
-> 1116 loc = self.index.get_loc(label)
   1118 if is_integer(loc):
   1119     return self._values[loc]

File ~/work/pandas/pandas/pandas/core/indexes/range.py:347, in RangeIndex.get_loc(self, key)
    345         return self._range.index(new_key)
    346     except ValueError as err:
--> 347         raise KeyError(key) from err
    348 if isinstance(key, Hashable):
    349     raise KeyError(key)

KeyError: -1

In [205]: df = pd.DataFrame(np.random.randn(5, 4))

In [206]: df
Out[206]: 
          0         1         2         3
0 -0.435772 -1.188928 -0.808286 -0.284634
1 -1.815703  1.347213 -0.243487  0.514704
2  1.162969 -0.287725 -0.179734  0.993962
3 -0.212673  0.909872 -0.733333 -0.349893
4  0.456434 -0.306735  0.553396  0.166221

In [207]: df.loc[-2:]
Out[207]: 
          0         1         2         3
0 -0.435772 -1.188928 -0.808286 -0.284634
1 -1.815703  1.347213 -0.243487  0.514704
2  1.162969 -0.287725 -0.179734  0.993962
3 -0.212673  0.909872 -0.733333 -0.349893
4  0.456434 -0.306735  0.553396  0.166221

---->   pandas.Series; pandas.DataFrame

--------------------------------------
ID: 1636 --> 1
In [208]: df = pd.DataFrame(index=[2, 3, 3, 4, 5], columns=["data"], data=list(range(5)))

In [209]: df.index.is_monotonic_increasing
Out[209]: True

# no rows 0 or 1, but still returns rows 2, 3 (both of them), and 4:
In [210]: df.loc[0:4, :]
Out[210]: 
   data
2     0
3     1
3     2
4     3

# slice is are outside the index, so empty DataFrame is returned
In [211]: df.loc[13:15, :]
Out[211]: 
Empty DataFrame
Columns: [data]
Index: []

---->   pandas.DataFrame

--------------------------------------
ID: 1637 --> 1
In [212]: df = pd.DataFrame(index=[2, 3, 1, 4, 3, 5], columns=["data"], data=list(range(6)))

In [213]: df.index.is_monotonic_increasing
Out[213]: False

# OK because 2 and 4 are in the index
In [214]: df.loc[2:4, :]
Out[214]: 
   data
2     0
3     1
1     2
4     3

---->   pandas.DataFrame

--------------------------------------
ID: 1638 --> 1
In [215]: weakly_monotonic = pd.Index(["a", "b", "c", "c"])

In [216]: weakly_monotonic
Out[216]: Index(['a', 'b', 'c', 'c'], dtype='object')

In [217]: weakly_monotonic.is_monotonic_increasing
Out[217]: True

In [218]: weakly_monotonic.is_monotonic_increasing & weakly_monotonic.is_unique
Out[218]: False

---->   pandas.Index

--------------------------------------
ID: 1639 --> 1
In [219]: s = pd.Series(np.random.randn(6), index=list("abcdef"))

In [220]: s
Out[220]: 
a   -0.101684
b   -0.734907
c   -0.130121
d   -0.476046
e    0.759104
f    0.213379
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 1640 --> 1
In [223]: series1 = pd.Series([1, 2, 3])

In [224]: series1.dtype
Out[224]: dtype('int64')

In [225]: res = series1.reindex([0, 4])

In [226]: res.dtype
Out[226]: dtype('float64')

In [227]: res
Out[227]: 
0    1.0
4    NaN
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 1641 --> 2
In [228]: series2 = pd.Series([True])

In [229]: series2.dtype
Out[229]: dtype('bool')

In [230]: res = series2.reindex_like(series1)

In [231]: res.dtype
Out[231]: dtype('O')

In [232]: res
Out[232]: 
0    True
1     NaN
2     NaN
dtype: object

---->   pandas.Series; Series.reindex_like

--------------------------------------
ID: 1642 --> 2
In [1]: arr = pd.array([1, 2, None], dtype=pd.Int64Dtype())

In [2]: arr
Out[2]: 

[1, 2, ]
Length: 3, dtype: Int64

---->   pandas.array; pandas.Int64Dtype

--------------------------------------
ID: 1643 --> 1
In [3]: pd.array([1, 2, np.nan], dtype="Int64")
Out[3]: 

[1, 2, ]
Length: 3, dtype: Int64

---->   pandas.array

--------------------------------------
ID: 1644 --> 1
In [4]: pd.array([1, 2, np.nan, None, pd.NA], dtype="Int64")
Out[4]: 

[1, 2, , , ]
Length: 5, dtype: Int64

---->   pandas.array

--------------------------------------
ID: 1645 --> 1
In [5]: pd.Series(arr)
Out[5]: 
0       1
1       2
2    
dtype: Int64

---->   pandas.Series

--------------------------------------
ID: 1646 --> 1
In [6]: pd.array([1, None])
Out[6]: 

[1, ]
Length: 2, dtype: Int64

In [7]: pd.array([1, 2])
Out[7]: 

[1, 2]
Length: 2, dtype: Int64

---->   pandas.array

--------------------------------------
ID: 1647 --> 1
In [8]: pd.Series([1, None])
Out[8]: 
0    1.0
1    NaN
dtype: float64

In [9]: pd.Series([1, 2])
Out[9]: 
0    1
1    2
dtype: int64

---->   pandas.Series

--------------------------------------
ID: 1648 --> 2
In [10]: pd.array([1, None], dtype="Int64")
Out[10]: 

[1, ]
Length: 2, dtype: Int64

In [11]: pd.Series([1, None], dtype="Int64")
Out[11]: 
0       1
1    
dtype: Int64

---->   pandas.array; pandas.Series

--------------------------------------
ID: 1649 --> 1
In [12]: s = pd.Series([1, 2, None], dtype="Int64")

# arithmetic
In [13]: s + 1
Out[13]: 
0       2
1       3
2    
dtype: Int64

# comparison
In [14]: s == 1
Out[14]: 
0     True
1    False
2     
dtype: boolean

# indexing
In [15]: s.iloc[1:3]
Out[15]: 
1       2
2    
dtype: Int64

# operate with other dtypes
In [16]: s + s.iloc[1:3].astype("Int8")
Out[16]: 
0    
1       4
2    
dtype: Int64

# coerce when needed
In [17]: s + 0.01
Out[17]: 
0    1.01
1    2.01
2    
dtype: Float64

---->   pandas.Series

--------------------------------------
ID: 1650 --> 1
In [18]: df = pd.DataFrame({"A": s, "B": [1, 1, 3], "C": list("aab")})

In [19]: df
Out[19]: 
      A  B  C
0     1  1  a
1     2  1  a
2    3  b

In [20]: df.dtypes
Out[20]: 
A     Int64
B     int64
C    object
dtype: object

---->   pandas.DataFrame

--------------------------------------
ID: 1652 --> 2
In [23]: df.sum()
Out[23]: 
A      3
B      5
C    aab
dtype: object

In [24]: df.groupby("B").A.sum()
Out[24]: 
B
1    3
3    0
Name: A, dtype: Int64

---->   DataFrame.sum; DataFrame.groupby

--------------------------------------
ID: 1653 --> 1
In [25]: a = pd.array([1, None], dtype="Int64")

In [26]: a[1]
Out[26]: 

---->   pandas.array

--------------------------------------
ID: 1654 --> 2
In [1]: s = pd.Series([1, 2, 3])

In [2]: mask = pd.array([True, False, pd.NA], dtype="boolean")

In [3]: s[mask]
Out[3]: 
0    1
dtype: int64

---->   pandas.Series; pandas.array

--------------------------------------
ID: 1656 --> 1
In [5]: pd.Series([True, False, np.nan], dtype="object") | True
Out[5]: 
0     True
1     True
2    False
dtype: bool

In [6]: pd.Series([True, False, np.nan], dtype="boolean") | True
Out[6]: 
0    True
1    True
2    True
dtype: boolean

---->   pandas.Series

--------------------------------------
ID: 1657 --> 1
In [7]: pd.Series([True, False, np.nan], dtype="object") & True
Out[7]: 
0     True
1    False
2    False
dtype: bool

In [8]: pd.Series([True, False, np.nan], dtype="boolean") & True
Out[8]: 
0     True
1    False
2     
dtype: boolean

---->   pandas.Series

--------------------------------------
ID: 1658 --> 3
In [1]: ser = pd.Series([-1.5, 0.2, None], dtype="float32[pyarrow]")

In [2]: ser
Out[2]: 
0    -1.5
1     0.2
2    
dtype: float[pyarrow]

In [3]: idx = pd.Index([True, None], dtype="bool[pyarrow]")

In [4]: idx
Out[4]: Index([True, ], dtype='bool[pyarrow]')

In [5]: df = pd.DataFrame([[1, 2], [3, 4]], dtype="uint64[pyarrow]")

In [6]: df
Out[6]: 
   0  1
0  1  2
1  3  4

---->   pandas.Series; pandas.Index; pandas.DataFrame

--------------------------------------
ID: 1659 --> 2
In [7]: import pyarrow as pa

In [8]: data = list("abc")

In [9]: ser_sd = pd.Series(data, dtype="string[pyarrow]")

In [10]: ser_ad = pd.Series(data, dtype=pd.ArrowDtype(pa.string()))

In [11]: ser_ad.dtype == ser_sd.dtype
Out[11]: False

In [12]: ser_sd.str.contains("a")
Out[12]: 
0     True
1    False
2    False
dtype: boolean

In [13]: ser_ad.str.contains("a")
Out[13]: 
0     True
1    False
2    False
dtype: bool[pyarrow]

---->   pandas.Series; pandas.ArrowDtype

--------------------------------------
ID: 1660 --> 2
In [14]: import pyarrow as pa

In [15]: list_str_type = pa.list_(pa.string())

In [16]: ser = pd.Series([["hello"], ["there"]], dtype=pd.ArrowDtype(list_str_type))

In [17]: ser
Out[17]: 
0    ['hello']
1    ['there']
dtype: list[pyarrow]

---->   pandas.Series; pandas.ArrowDtype

--------------------------------------
ID: 1661 --> 2
In [18]: from datetime import time

In [19]: idx = pd.Index([time(12, 30), None], dtype=pd.ArrowDtype(pa.time64("us")))

In [20]: idx
Out[20]: Index([12:30:00, ], dtype='time64[us][pyarrow]')

---->   pandas.Index; pandas.ArrowDtype

--------------------------------------
ID: 1662 --> 2
In [21]: from decimal import Decimal

In [22]: decimal_type = pd.ArrowDtype(pa.decimal128(3, scale=2))

In [23]: data = [[Decimal("3.19"), None], [None, Decimal("-1.23")]]

In [24]: df = pd.DataFrame(data, dtype=decimal_type)

In [25]: df
Out[25]: 
      0      1
0  3.19   
1    -1.23

---->   pandas.ArrowDtype; pandas.DataFrame

--------------------------------------
ID: 1663 --> 1
In [26]: pa_array = pa.array(
   ....:     [{"1": "2"}, {"10": "20"}, None],
   ....:     type=pa.map_(pa.string(), pa.string()),
   ....: )
   ....: 

In [27]: ser = pd.Series(pd.arrays.ArrowExtensionArray(pa_array))

In [28]: ser
Out[28]: 
0      [('1', '2')]
1    [('10', '20')]
2              
dtype: map[pyarrow]

---->   pandas.Series

--------------------------------------
ID: 1664 --> 2
In [29]: ser = pd.Series([1, 2, None], dtype="uint8[pyarrow]")

In [30]: pa.array(ser)
Out[30]: 

[
  1,
  2,
  null
]

In [31]: idx = pd.Index(ser)

In [32]: pa.array(idx)
Out[32]: 

[
  1,
  2,
  null
]

---->   pandas.Series; pandas.Index

--------------------------------------
ID: 1666 --> 3
In [37]: import pyarrow as pa

In [38]: ser = pd.Series([-1.545, 0.211, None], dtype="float32[pyarrow]")

In [39]: ser.mean()
Out[39]: -0.6669999808073044

In [40]: ser + ser
Out[40]: 
0    -3.09
1    0.422
2     
dtype: float[pyarrow]

In [41]: ser > (ser + 1)
Out[41]: 
0    False
1    False
2     
dtype: bool[pyarrow]

In [42]: ser.dropna()
Out[42]: 
0   -1.545
1    0.211
dtype: float[pyarrow]

In [43]: ser.isna()
Out[43]: 
0    False
1    False
2     True
dtype: bool

In [44]: ser.fillna(0)
Out[44]: 
0   -1.545
1    0.211
2    0.000
dtype: float[pyarrow]

---->   pandas.Series; Series.mean; Series.isna

--------------------------------------
ID: 1667 --> 2
In [45]: ser_str = pd.Series(["a", "b", None], dtype=pd.ArrowDtype(pa.string()))

In [46]: ser_str.str.startswith("a")
Out[46]: 
0     True
1    False
2     
dtype: bool[pyarrow]

---->   pandas.Series; pandas.ArrowDtype

--------------------------------------
ID: 1668 --> 2
In [47]: from datetime import datetime

In [48]: pa_type = pd.ArrowDtype(pa.timestamp("ns"))

In [49]: ser_dt = pd.Series([datetime(2022, 1, 1), None], dtype=pa_type)

In [50]: ser_dt.dt.strftime("%Y-%m")
Out[50]: 
0    2022-01
1       
dtype: string[pyarrow]

---->   pandas.ArrowDtype; pandas.Series

--------------------------------------
ID: 1671 --> 1
In [1]: pd.Series(["a", "b", "c"])
Out[1]: 
0    a
1    b
2    c
dtype: object

---->   pandas.Series

--------------------------------------
ID: 1672 --> 2
In [2]: pd.Series(["a", "b", "c"], dtype="string")
Out[2]: 
0    a
1    b
2    c
dtype: string

In [3]: pd.Series(["a", "b", "c"], dtype=pd.StringDtype())
Out[3]: 
0    a
1    b
2    c
dtype: string

---->   pandas.Series; pandas.StringDtype

--------------------------------------
ID: 1673 --> 2
In [4]: s = pd.Series(["a", "b", "c"])

In [5]: s
Out[5]: 
0    a
1    b
2    c
dtype: object

In [6]: s.astype("string")
Out[6]: 
0    a
1    b
2    c
dtype: string

---->   pandas.Series; Series.astype

--------------------------------------
ID: 1674 --> 1
In [7]: s = pd.Series(["a", 2, np.nan], dtype="string")

In [8]: s
Out[8]: 
0       a
1       2
2    
dtype: string

In [9]: type(s[1])
Out[9]: str

---->   pandas.Series

--------------------------------------
ID: 1675 --> 2
In [10]: s1 = pd.Series([1, 2, np.nan], dtype="Int64")

In [11]: s1
Out[11]: 
0       1
1       2
2    
dtype: Int64

In [12]: s2 = s1.astype("string")

In [13]: s2
Out[13]: 
0       1
1       2
2    
dtype: string

In [14]: type(s2[0])
Out[14]: str

---->   pandas.Series; Series.astype

--------------------------------------
ID: 1676 --> 1
In [15]: s = pd.Series(["a", None, "b"], dtype="string")

In [16]: s
Out[16]: 
0       a
1    
2       b
dtype: string

In [17]: s.str.count("a")
Out[17]: 
0       1
1    
2       0
dtype: Int64

In [18]: s.dropna().str.count("a")
Out[18]: 
0    1
2    0
dtype: Int64

---->   pandas.Series

--------------------------------------
ID: 1677 --> 1
In [19]: s2 = pd.Series(["a", None, "b"], dtype="object")

In [20]: s2.str.count("a")
Out[20]: 
0    1.0
1    NaN
2    0.0
dtype: float64

In [21]: s2.dropna().str.count("a")
Out[21]: 
0    1
2    0
dtype: int64

---->   pandas.Series

--------------------------------------
ID: 1679 --> 1
In [24]: s = pd.Series(
   ....:     ["A", "B", "C", "Aaba", "Baca", np.nan, "CABA", "dog", "cat"], dtype="string"
   ....: )
   ....: 

In [25]: s.str.lower()
Out[25]: 
0       a
1       b
2       c
3    aaba
4    baca
5    
6    caba
7     dog
8     cat
dtype: string

In [26]: s.str.upper()
Out[26]: 
0       A
1       B
2       C
3    AABA
4    BACA
5    
6    CABA
7     DOG
8     CAT
dtype: string

In [27]: s.str.len()
Out[27]: 
0       1
1       1
2       1
3       4
4       4
5    
6       4
7       3
8       3
dtype: Int64

---->   pandas.Series

--------------------------------------
ID: 1680 --> 1
In [28]: idx = pd.Index([" jack", "jill ", " jesse ", "frank"])

In [29]: idx.str.strip()
Out[29]: Index(['jack', 'jill', 'jesse', 'frank'], dtype='object')

In [30]: idx.str.lstrip()
Out[30]: Index(['jack', 'jill ', 'jesse ', 'frank'], dtype='object')

In [31]: idx.str.rstrip()
Out[31]: Index([' jack', 'jill', ' jesse', 'frank'], dtype='object')

---->   pandas.Index

--------------------------------------
ID: 1681 --> 1
In [32]: df = pd.DataFrame(
   ....:     np.random.randn(3, 2), columns=[" Column A ", " Column B "], index=range(3)
   ....: )
   ....: 

In [33]: df
Out[33]: 
    Column A    Column B 
0    0.469112   -0.282863
1   -1.509059   -1.135632
2    1.212112   -0.173215

---->   pandas.DataFrame

--------------------------------------
ID: 1684 --> 1
In [38]: s2 = pd.Series(["a_b_c", "c_d_e", np.nan, "f_g_h"], dtype="string")

In [39]: s2.str.split("_")
Out[39]: 
0    [a, b, c]
1    [c, d, e]
2         
3    [f, g, h]
dtype: object

---->   pandas.Series

--------------------------------------
ID: 1689 --> 1
In [45]: s3 = pd.Series(
   ....:     ["A", "B", "C", "Aaba", "Baca", "", np.nan, "CABA", "dog", "cat"],
   ....:     dtype="string",
   ....: )
   ....: 

In [46]: s3
Out[46]: 
0       A
1       B
2       C
3    Aaba
4    Baca
5        
6    
7    CABA
8     dog
9     cat
dtype: string

In [47]: s3.str.replace("^.a|dog", "XX-XX ", case=False, regex=True)
Out[47]: 
0           A
1           B
2           C
3    XX-XX ba
4    XX-XX ca
5            
6        
7    XX-XX BA
8      XX-XX 
9     XX-XX t
dtype: string

---->   pandas.Series

--------------------------------------
ID: 1690 --> 1
In [48]: s4 = pd.Series(["a.b", ".", "b", np.nan, ""], dtype="string")

In [49]: s4
Out[49]: 
0     a.b
1       .
2       b
3    
4        
dtype: string

In [50]: s4.str.replace(".", "a", regex=True)
Out[50]: 
0     aaa
1       a
2       a
3    
4        
dtype: string

---->   pandas.Series

--------------------------------------
ID: 1691 --> 1
In [51]: dollars = pd.Series(["12", "-$10", "$10,000"], dtype="string")

# These lines are equivalent
In [52]: dollars.str.replace(r"-\$", "-", regex=True)
Out[52]: 
0         12
1        -10
2    $10,000
dtype: string

In [53]: dollars.str.replace("-$", "-", regex=False)
Out[53]: 
0         12
1        -10
2    $10,000
dtype: string

---->   pandas.Series

--------------------------------------
ID: 1692 --> 1
# Reverse every lowercase alphabetic word
In [54]: pat = r"[a-z]+"

In [55]: def repl(m):
   ....:     return m.group(0)[::-1]
   ....: 

In [56]: pd.Series(["foo 123", "bar baz", np.nan], dtype="string").str.replace(
   ....:     pat, repl, regex=True
   ....: )
   ....: 
Out[56]: 
0    oof 123
1    rab zab
2       
dtype: string

# Using regex groups
In [57]: pat = r"(?P\w+) (?P\w+) (?P\w+)"

In [58]: def repl(m):
   ....:     return m.group("two").swapcase()
   ....: 

In [59]: pd.Series(["Foo Bar Baz", np.nan], dtype="string").str.replace(
   ....:     pat, repl, regex=True
   ....: )
   ....: 
Out[59]: 
0     bAR
1    
dtype: string

---->   pandas.Series

--------------------------------------
ID: 1695 --> 1
In [64]: s = pd.Series(["str_foo", "str_bar", "no_prefix"])

In [65]: s.str.removeprefix("str_")
Out[65]: 
0          foo
1          bar
2    no_prefix
dtype: object

In [66]: s = pd.Series(["foo_str", "bar_str", "no_suffix"])

In [67]: s.str.removesuffix("_str")
Out[67]: 
0          foo
1          bar
2    no_suffix
dtype: object

---->   pandas.Series

--------------------------------------
ID: 1696 --> 1
In [68]: s = pd.Series(["a", "b", "c", "d"], dtype="string")

In [69]: s.str.cat(sep=",")
Out[69]: 'a,b,c,d'

---->   pandas.Series

--------------------------------------
ID: 1698 --> 1
In [71]: t = pd.Series(["a", "b", np.nan, "d"], dtype="string")

In [72]: t.str.cat(sep=",")
Out[72]: 'a,b,d'

In [73]: t.str.cat(sep=",", na_rep="-")
Out[73]: 'a,b,-,d'

---->   pandas.Series

--------------------------------------
ID: 1702 --> 1
In [81]: u = pd.Series(["b", "d", "a", "c"], index=[1, 3, 0, 2], dtype="string")

In [82]: s
Out[82]: 
0    a
1    b
2    c
3    d
dtype: string

In [83]: u
Out[83]: 
1    b
3    d
0    a
2    c
dtype: string

In [84]: s.str.cat(u)
Out[84]: 
0    aa
1    bb
2    cc
3    dd
dtype: string

In [85]: s.str.cat(u, join="left")
Out[85]: 
0    aa
1    bb
2    cc
3    dd
dtype: string

---->   pandas.Series

--------------------------------------
ID: 1703 --> 1
In [86]: v = pd.Series(["z", "a", "b", "d", "e"], index=[-1, 0, 1, 3, 4], dtype="string")

In [87]: s
Out[87]: 
0    a
1    b
2    c
3    d
dtype: string

In [88]: v
Out[88]: 
-1    z
 0    a
 1    b
 3    d
 4    e
dtype: string

In [89]: s.str.cat(v, join="left", na_rep="-")
Out[89]: 
0    aa
1    bb
2    c-
3    dd
dtype: string

In [90]: s.str.cat(v, join="outer", na_rep="-")
Out[90]: 
-1    -z
 0    aa
 1    bb
 2    c-
 3    dd
 4    -e
dtype: string

---->   pandas.Series

--------------------------------------
ID: 1705 --> 1
In [95]: s
Out[95]: 
0    a
1    b
2    c
3    d
dtype: string

In [96]: u
Out[96]: 
1    b
3    d
0    a
2    c
dtype: string

In [97]: s.str.cat([u, u.to_numpy()], join="left")
Out[97]: 
0    aab
1    bbd
2    cca
3    ddc
dtype: string

---->   Series.to_numpy

--------------------------------------
ID: 1706 --> 1
In [98]: v
Out[98]: 
-1    z
 0    a
 1    b
 3    d
 4    e
dtype: string

In [99]: s.str.cat([v, u, u.to_numpy()], join="outer", na_rep="-")
Out[99]: 
-1    -z--
0     aaab
1     bbbd
2     c-ca
3     dddc
4     -e--
dtype: string

---->   Series.to_numpy

--------------------------------------
ID: 1708 --> 1
In [103]: s = pd.Series(
   .....:     ["A", "B", "C", "Aaba", "Baca", np.nan, "CABA", "dog", "cat"], dtype="string"
   .....: )
   .....: 

In [104]: s.str[0]
Out[104]: 
0       A
1       B
2       C
3       A
4       B
5    
6       C
7       d
8       c
dtype: string

In [105]: s.str[1]
Out[105]: 
0    
1    
2    
3       a
4       a
5    
6       A
7       o
8       a
dtype: string

---->   pandas.Series

--------------------------------------
ID: 1709 --> 1
In [106]: pd.Series(
   .....:     ["a1", "b2", "c3"],
   .....:     dtype="string",
   .....: ).str.extract(r"([ab])(\d)", expand=False)
   .....: 
Out[106]: 
      0     1
0     a     1
1     b     2
2    

---->   pandas.Series

--------------------------------------
ID: 1710 --> 1
In [107]: pd.Series(["a1", "b2", "c3"], dtype="string").str.extract(
   .....:     r"(?P[ab])(?P\d)", expand=False
   .....: )
   .....: 
Out[107]: 
  letter digit
0      a     1
1      b     2
2     

---->   pandas.Series

--------------------------------------
ID: 1711 --> 1
In [108]: pd.Series(
   .....:     ["a1", "b2", "3"],
   .....:     dtype="string",
   .....: ).str.extract(r"([ab])?(\d)", expand=False)
   .....: 
Out[108]: 
      0  1
0     a  1
1     b  2
2    3

---->   pandas.Series

--------------------------------------
ID: 1712 --> 1
In [109]: pd.Series(["a1", "b2", "c3"], dtype="string").str.extract(r"[ab](\d)", expand=True)
Out[109]: 
      0
0     1
1     2
2  

---->   pandas.Series

--------------------------------------
ID: 1713 --> 1
In [110]: pd.Series(["a1", "b2", "c3"], dtype="string").str.extract(r"[ab](\d)", expand=False)
Out[110]: 
0       1
1       2
2    
dtype: string

---->   pandas.Series

--------------------------------------
ID: 1714 --> 1
In [111]: s = pd.Series(["a1", "b2", "c3"], ["A11", "B22", "C33"], dtype="string")

In [112]: s
Out[112]: 
A11    a1
B22    b2
C33    c3
dtype: string

In [113]: s.index.str.extract("(?P[a-zA-Z])", expand=True)
Out[113]: 
  letter
0      A
1      B
2      C

---->   pandas.Series

--------------------------------------
ID: 1718 --> 1
In [116]: s = pd.Series(["a1a2", "b1", "c1"], index=["A", "B", "C"], dtype="string")

In [117]: s
Out[117]: 
A    a1a2
B      b1
C      c1
dtype: string

In [118]: two_groups = "(?P[a-z])(?P[0-9])"

In [119]: s.str.extract(two_groups, expand=True)
Out[119]: 
  letter digit
A      a     1
B      b     1
C      c     1

---->   pandas.Series

--------------------------------------
ID: 1720 --> 1
In [121]: s = pd.Series(["a3", "b3", "c2"], dtype="string")

In [122]: s
Out[122]: 
0    a3
1    b3
2    c2
dtype: string

---->   pandas.Series

--------------------------------------
ID: 1722 --> 2
In [128]: pd.Index(["a1a2", "b1", "c1"]).str.extractall(two_groups)
Out[128]: 
        letter digit
  match             
0 0          a     1
  1          a     2
1 0          b     1
2 0          c     1

In [129]: pd.Series(["a1a2", "b1", "c1"], dtype="string").str.extractall(two_groups)
Out[129]: 
        letter digit
  match             
0 0          a     1
  1          a     2
1 0          b     1
2 0          c     1

---->   pandas.Index; pandas.Series

--------------------------------------
ID: 1723 --> 1
In [130]: pattern = r"[0-9][a-z]"

In [131]: pd.Series(
   .....:     ["1", "2", "3a", "3b", "03c", "4dx"],
   .....:     dtype="string",
   .....: ).str.contains(pattern)
   .....: 
Out[131]: 
0    False
1    False
2     True
3     True
4     True
5     True
dtype: boolean

---->   pandas.Series

--------------------------------------
ID: 1724 --> 1
In [132]: pd.Series(
   .....:     ["1", "2", "3a", "3b", "03c", "4dx"],
   .....:     dtype="string",
   .....: ).str.match(pattern)
   .....: 
Out[132]: 
0    False
1    False
2     True
3     True
4    False
5     True
dtype: boolean

---->   pandas.Series

--------------------------------------
ID: 1725 --> 1
In [133]: pd.Series(
   .....:     ["1", "2", "3a", "3b", "03c", "4dx"],
   .....:     dtype="string",
   .....: ).str.fullmatch(pattern)
   .....: 
Out[133]: 
0    False
1    False
2     True
3     True
4    False
5    False
dtype: boolean

---->   pandas.Series

--------------------------------------
ID: 1726 --> 1
In [134]: s4 = pd.Series(
   .....:     ["A", "B", "C", "Aaba", "Baca", np.nan, "CABA", "dog", "cat"], dtype="string"
   .....: )
   .....: 

In [135]: s4.str.contains("A", na=False)
Out[135]: 
0     True
1    False
2    False
3     True
4    False
5    False
6     True
7    False
8    False
dtype: boolean

---->   pandas.Series

--------------------------------------
ID: 1727 --> 1
In [136]: s = pd.Series(["a", "a|b", np.nan, "a|c"], dtype="string")

In [137]: s.str.get_dummies(sep="|")
Out[137]: 
   a  b  c
0  1  0  0
1  1  1  0
2  0  0  0
3  1  0  1

---->   pandas.Series

--------------------------------------
ID: 1728 --> 1
In [138]: idx = pd.Index(["a", "a|b", np.nan, "a|c"])

In [139]: idx.str.get_dummies(sep="|")
Out[139]: 
MultiIndex([(1, 0, 0),
            (1, 1, 0),
            (0, 0, 0),
            (1, 0, 1)],
           names=['a', 'b', 'c'])

---->   pandas.Index

--------------------------------------
ID: 1729 --> 1
In [1]: import pandas._testing as tm

In [2]: def unpivot(frame):
   ...:     N, K = frame.shape
   ...:     data = {
   ...:         "value": frame.to_numpy().ravel("F"),
   ...:         "variable": np.asarray(frame.columns).repeat(N),
   ...:         "date": np.tile(np.asarray(frame.index), K),
   ...:     }
   ...:     return pd.DataFrame(data, columns=["date", "variable", "value"])
   ...: 

In [3]: df = unpivot(tm.makeTimeDataFrame(3))

In [4]: df
Out[4]: 
         date variable     value
0  2000-01-03        A  0.469112
1  2000-01-04        A -0.282863
2  2000-01-05        A -1.509059
3  2000-01-03        B -1.135632
4  2000-01-04        B  1.212112
5  2000-01-05        B -0.173215
6  2000-01-03        C  0.119209
7  2000-01-04        C -1.044236
8  2000-01-05        C -0.861849
9  2000-01-03        D -2.104569
10 2000-01-04        D -0.494929
11 2000-01-05        D  1.071804

---->   pandas.DataFrame

--------------------------------------
ID: 1732 --> 2
In [13]: tuples = list(
   ....:     zip(
   ....:         *[
   ....:             ["bar", "bar", "baz", "baz", "foo", "foo", "qux", "qux"],
   ....:             ["one", "two", "one", "two", "one", "two", "one", "two"],
   ....:         ]
   ....:     )
   ....: )
   ....: 

In [14]: index = pd.MultiIndex.from_tuples(tuples, names=["first", "second"])

In [15]: df = pd.DataFrame(np.random.randn(8, 2), index=index, columns=["A", "B"])

In [16]: df2 = df[:4]

In [17]: df2
Out[17]: 
                     A         B
first second                    
bar   one     0.721555 -0.706771
      two    -1.039575  0.271860
baz   one    -0.424972  0.567020
      two     0.276232 -1.087401

---->   pandas.MultiIndex; pandas.DataFrame

--------------------------------------
ID: 1733 --> 1
In [18]: stacked = df2.stack()

In [19]: stacked
Out[19]: 
first  second   
bar    one     A    0.721555
               B   -0.706771
       two     A   -1.039575
               B    0.271860
baz    one     A   -0.424972
               B    0.567020
       two     A    0.276232
               B   -1.087401
dtype: float64

---->   DataFrame.stack

--------------------------------------
ID: 1736 --> 3
In [24]: index = pd.MultiIndex.from_product([[2, 1], ["a", "b"]])

In [25]: df = pd.DataFrame(np.random.randn(4), index=index, columns=["A"])

In [26]: df
Out[26]: 
            A
2 a -0.370647
  b -1.157892
1 a -1.344312
  b  0.844885

In [27]: all(df.unstack().stack() == df.sort_index())
Out[27]: True

---->   pandas.MultiIndex; pandas.DataFrame; DataFrame.unstack

--------------------------------------
ID: 1737 --> 3
In [28]: columns = pd.MultiIndex.from_tuples(
   ....:     [
   ....:         ("A", "cat", "long"),
   ....:         ("B", "cat", "long"),
   ....:         ("A", "dog", "short"),
   ....:         ("B", "dog", "short"),
   ....:     ],
   ....:     names=["exp", "animal", "hair_length"],
   ....: )
   ....: 

In [29]: df = pd.DataFrame(np.random.randn(4, 4), columns=columns)

In [30]: df
Out[30]: 
exp                 A         B         A         B
animal            cat       cat       dog       dog
hair_length      long      long     short     short
0            1.075770 -0.109050  1.643563 -1.469388
1            0.357021 -0.674600 -1.776904 -0.968914
2           -1.294524  0.413738  0.276662 -0.472035
3           -0.013960 -0.362543 -0.006154 -0.923061

In [31]: df.stack(level=["animal", "hair_length"])
Out[31]: 
exp                          A         B
  animal hair_length                    
0 cat    long         1.075770 -0.109050
  dog    short        1.643563 -1.469388
1 cat    long         0.357021 -0.674600
  dog    short       -1.776904 -0.968914
2 cat    long        -1.294524  0.413738
  dog    short        0.276662 -0.472035
3 cat    long        -0.013960 -0.362543
  dog    short       -0.006154 -0.923061

---->   pandas.MultiIndex; pandas.DataFrame; DataFrame.stack

--------------------------------------
ID: 1738 --> 1
# df.stack(level=['animal', 'hair_length'])
# from above is equivalent to:
In [32]: df.stack(level=[1, 2])
Out[32]: 
exp                          A         B
  animal hair_length                    
0 cat    long         1.075770 -0.109050
  dog    short        1.643563 -1.469388
1 cat    long         0.357021 -0.674600
  dog    short       -1.776904 -0.968914
2 cat    long        -1.294524  0.413738
  dog    short        0.276662 -0.472035
3 cat    long        -0.013960 -0.362543
  dog    short       -0.006154 -0.923061

---->   DataFrame.stack

--------------------------------------
ID: 1739 --> 3
In [33]: columns = pd.MultiIndex.from_tuples(
   ....:     [
   ....:         ("A", "cat"),
   ....:         ("B", "dog"),
   ....:         ("B", "cat"),
   ....:         ("A", "dog"),
   ....:     ],
   ....:     names=["exp", "animal"],
   ....: )
   ....: 

In [34]: index = pd.MultiIndex.from_product(
   ....:     [("bar", "baz", "foo", "qux"), ("one", "two")], names=["first", "second"]
   ....: )
   ....: 

In [35]: df = pd.DataFrame(np.random.randn(8, 4), index=index, columns=columns)

In [36]: df2 = df.iloc[[0, 1, 2, 4, 5, 7]]

In [37]: df2
Out[37]: 
exp                  A         B                   A
animal             cat       dog       cat       dog
first second                                        
bar   one     0.895717  0.805244 -1.206412  2.565646
      two     1.431256  1.340309 -1.170299 -0.226169
baz   one     0.410835  0.813850  0.132003 -0.827317
foo   one    -1.413681  1.607920  1.024180  0.569605
      two     0.875906 -2.211372  0.974466 -2.006747
qux   two    -1.226825  0.769804 -1.281247 -0.727707

---->   pandas.MultiIndex; pandas.MultiIndex; pandas.DataFrame

--------------------------------------
ID: 1740 --> 1
In [38]: df2.stack("exp")
Out[38]: 
animal                 cat       dog
first second exp                    
bar   one    A    0.895717  2.565646
             B   -1.206412  0.805244
      two    A    1.431256 -0.226169
             B   -1.170299  1.340309
baz   one    A    0.410835 -0.827317
             B    0.132003  0.813850
foo   one    A   -1.413681  0.569605
             B    1.024180  1.607920
      two    A    0.875906 -2.006747
             B    0.974466 -2.211372
qux   two    A   -1.226825 -0.727707
             B   -1.281247  0.769804

In [39]: df2.stack("animal")
Out[39]: 
exp                         A         B
first second animal                    
bar   one    cat     0.895717 -1.206412
             dog     2.565646  0.805244
      two    cat     1.431256 -1.170299
             dog    -0.226169  1.340309
baz   one    cat     0.410835  0.132003
             dog    -0.827317  0.813850
foo   one    cat    -1.413681  1.024180
             dog     0.569605  1.607920
      two    cat     0.875906  0.974466
             dog    -2.006747 -2.211372
qux   two    cat    -1.226825 -1.281247
             dog    -0.727707  0.769804

---->   DataFrame.stack

--------------------------------------
ID: 1741 --> 1
In [40]: df3 = df.iloc[[0, 1, 4, 7], [1, 2]]

In [41]: df3
Out[41]: 
exp                  B          
animal             dog       cat
first second                    
bar   one     0.805244 -1.206412
      two     1.340309 -1.170299
foo   one     1.607920  1.024180
qux   two     0.769804 -1.281247

In [42]: df3.unstack()
Out[42]: 
exp            B                              
animal       dog                 cat          
second       one       two       one       two
first                                         
bar     0.805244  1.340309 -1.206412 -1.170299
foo     1.607920       NaN  1.024180       NaN
qux          NaN  0.769804       NaN -1.281247

---->   DataFrame.unstack

--------------------------------------
ID: 1742 --> 1
In [43]: df3.unstack(fill_value=-1e9)
Out[43]: 
exp                B                                          
animal           dog                         cat              
second           one           two           one           two
first                                                         
bar     8.052440e-01  1.340309e+00 -1.206412e+00 -1.170299e+00
foo     1.607920e+00 -1.000000e+09  1.024180e+00 -1.000000e+09
qux    -1.000000e+09  7.698036e-01 -1.000000e+09 -1.281247e+00

---->   DataFrame.unstack

--------------------------------------
ID: 1743 --> 1
In [44]: df[:3].unstack(0)
Out[44]: 
exp            A                   B  ...                   A          
animal       cat                 dog  ...       cat       dog          
first        bar       baz       bar  ...       baz       bar       baz
second                                ...                              
one     0.895717  0.410835  0.805244  ...  0.132003  2.565646 -0.827317
two     1.431256       NaN  1.340309  ...       NaN -0.226169       NaN

[2 rows x 8 columns]

In [45]: df2.unstack(1)
Out[45]: 
exp            A                   B  ...                   A          
animal       cat                 dog  ...       cat       dog          
second       one       two       one  ...       two       one       two
first                                 ...                              
bar     0.895717  1.431256  0.805244  ... -1.170299  2.565646 -0.226169
baz     0.410835       NaN  0.813850  ...       NaN -0.827317       NaN
foo    -1.413681  0.875906  1.607920  ...  0.974466  0.569605 -2.006747
qux          NaN -1.226825       NaN  ... -1.281247       NaN -0.727707

[4 rows x 8 columns]

---->   DataFrame.unstack

--------------------------------------
ID: 1744 --> 1
In [46]: cheese = pd.DataFrame(
   ....:     {
   ....:         "first": ["John", "Mary"],
   ....:         "last": ["Doe", "Bo"],
   ....:         "height": [5.5, 6.0],
   ....:         "weight": [130, 150],
   ....:     }
   ....: )
   ....: 

In [47]: cheese
Out[47]: 
  first last  height  weight
0  John  Doe     5.5     130
1  Mary   Bo     6.0     150

In [48]: cheese.melt(id_vars=["first", "last"])
Out[48]: 
  first last variable  value
0  John  Doe   height    5.5
1  Mary   Bo   height    6.0
2  John  Doe   weight  130.0
3  Mary   Bo   weight  150.0

In [49]: cheese.melt(id_vars=["first", "last"], var_name="quantity")
Out[49]: 
  first last quantity  value
0  John  Doe   height    5.5
1  Mary   Bo   height    6.0
2  John  Doe   weight  130.0
3  Mary   Bo   weight  150.0

---->   pandas.DataFrame

--------------------------------------
ID: 1745 --> 2
In [50]: index = pd.MultiIndex.from_tuples([("person", "A"), ("person", "B")])

In [51]: cheese = pd.DataFrame(
   ....:     {
   ....:         "first": ["John", "Mary"],
   ....:         "last": ["Doe", "Bo"],
   ....:         "height": [5.5, 6.0],
   ....:         "weight": [130, 150],
   ....:     },
   ....:     index=index,
   ....: )
   ....: 

In [52]: cheese
Out[52]: 
         first last  height  weight
person A  John  Doe     5.5     130
       B  Mary   Bo     6.0     150

In [53]: cheese.melt(id_vars=["first", "last"])
Out[53]: 
  first last variable  value
0  John  Doe   height    5.5
1  Mary   Bo   height    6.0
2  John  Doe   weight  130.0
3  Mary   Bo   weight  150.0

In [54]: cheese.melt(id_vars=["first", "last"], ignore_index=False)
Out[54]: 
         first last variable  value
person A  John  Doe   height    5.5
       B  Mary   Bo   height    6.0
       A  John  Doe   weight  130.0
       B  Mary   Bo   weight  150.0

---->   pandas.MultiIndex; pandas.DataFrame

--------------------------------------
ID: 1746 --> 2
In [55]: dft = pd.DataFrame(
   ....:     {
   ....:         "A1970": {0: "a", 1: "b", 2: "c"},
   ....:         "A1980": {0: "d", 1: "e", 2: "f"},
   ....:         "B1970": {0: 2.5, 1: 1.2, 2: 0.7},
   ....:         "B1980": {0: 3.2, 1: 1.3, 2: 0.1},
   ....:         "X": dict(zip(range(3), np.random.randn(3))),
   ....:     }
   ....: )
   ....: 

In [56]: dft["id"] = dft.index

In [57]: dft
Out[57]: 
  A1970 A1980  B1970  B1980         X  id
0     a     d    2.5    3.2 -0.121306   0
1     b     e    1.2    1.3 -0.097883   1
2     c     f    0.7    0.1  0.695775   2

In [58]: pd.wide_to_long(dft, ["A", "B"], i="id", j="year")
Out[58]: 
                X  A    B
id year                  
0  1970 -0.121306  a  2.5
1  1970 -0.097883  b  1.2
2  1970  0.695775  c  0.7
0  1980 -0.121306  d  3.2
1  1980 -0.097883  e  1.3
2  1980  0.695775  f  0.1

---->   pandas.DataFrame; pandas.wide_to_long

--------------------------------------
ID: 1747 --> 3
In [59]: df
Out[59]: 
exp                  A         B                   A
animal             cat       dog       cat       dog
first second                                        
bar   one     0.895717  0.805244 -1.206412  2.565646
      two     1.431256  1.340309 -1.170299 -0.226169
baz   one     0.410835  0.813850  0.132003 -0.827317
      two    -0.076467 -1.187678  1.130127 -1.436737
foo   one    -1.413681  1.607920  1.024180  0.569605
      two     0.875906 -2.211372  0.974466 -2.006747
qux   one    -0.410001 -0.078638  0.545952 -1.219217
      two    -1.226825  0.769804 -1.281247 -0.727707

In [60]: df.stack().mean(1).unstack()
Out[60]: 
animal             cat       dog
first second                    
bar   one    -0.155347  1.685445
      two     0.130479  0.557070
baz   one     0.271419 -0.006733
      two     0.526830 -1.312207
foo   one    -0.194750  1.088763
      two     0.925186 -2.109060
qux   one     0.067976 -0.648927
      two    -1.254036  0.021048

# same result, another way
In [61]: df.groupby(level=1, axis=1).mean()
Out[61]: 
animal             cat       dog
first second                    
bar   one    -0.155347  1.685445
      two     0.130479  0.557070
baz   one     0.271419 -0.006733
      two     0.526830 -1.312207
foo   one    -0.194750  1.088763
      two     0.925186 -2.109060
qux   one     0.067976 -0.648927
      two    -1.254036  0.021048

In [62]: df.stack().groupby(level=1).mean()
Out[62]: 
exp            A         B
second                    
one     0.071448  0.455513
two    -0.424186 -0.204486

In [63]: df.mean().unstack(0)
Out[63]: 
exp            A         B
animal                    
cat     0.060843  0.018596
dog    -0.413580  0.232430

---->   DataFrame.stack; DataFrame.groupby; DataFrame.mean

--------------------------------------
ID: 1748 --> 1
In [64]: import datetime

In [65]: df = pd.DataFrame(
   ....:     {
   ....:         "A": ["one", "one", "two", "three"] * 6,
   ....:         "B": ["A", "B", "C"] * 8,
   ....:         "C": ["foo", "foo", "foo", "bar", "bar", "bar"] * 4,
   ....:         "D": np.random.randn(24),
   ....:         "E": np.random.randn(24),
   ....:         "F": [datetime.datetime(2013, i, 1) for i in range(1, 13)]
   ....:         + [datetime.datetime(2013, i, 15) for i in range(1, 13)],
   ....:     }
   ....: )
   ....: 

In [66]: df
Out[66]: 
        A  B    C         D         E          F
0     one  A  foo  0.341734 -0.317441 2013-01-01
1     one  B  foo  0.959726 -1.236269 2013-02-01
2     two  C  foo -1.110336  0.896171 2013-03-01
3   three  A  bar -0.619976 -0.487602 2013-04-01
4     one  B  bar  0.149748 -0.082240 2013-05-01
..    ... ..  ...       ...       ...        ...
19  three  B  foo  0.690579 -2.213588 2013-08-15
20    one  C  foo  0.995761  1.063327 2013-09-15
21    one  A  bar  2.396780  1.266143 2013-10-15
22    two  B  bar  0.014871  0.299368 2013-11-15
23  three  C  bar  3.357427 -0.863838 2013-12-15

[24 rows x 6 columns]

---->   pandas.DataFrame

--------------------------------------
ID: 1749 --> 1
In [67]: pd.pivot_table(df, values="D", index=["A", "B"], columns=["C"])
Out[67]: 
C             bar       foo
A     B                    
one   A  1.120915 -0.514058
      B -0.338421  0.002759
      C -0.538846  0.699535
three A -1.181568       NaN
      B       NaN  0.433512
      C  0.588783       NaN
two   A       NaN  1.000985
      B  0.158248       NaN
      C       NaN  0.176180

In [68]: pd.pivot_table(df, values="D", index=["B"], columns=["A", "C"], aggfunc=np.sum)
Out[68]: 
A       one               three                 two          
C       bar       foo       bar       foo       bar       foo
B                                                            
A  2.241830 -1.028115 -2.363137       NaN       NaN  2.001971
B -0.676843  0.005518       NaN  0.867024  0.316495       NaN
C -1.077692  1.399070  1.177566       NaN       NaN  0.352360

In [69]: pd.pivot_table(
   ....:     df, values=["D", "E"],
   ....:     index=["B"],
   ....:     columns=["A", "C"],
   ....:     aggfunc=np.sum,
   ....: )
   ....: 
Out[69]: 
          D                      ...         E                    
A       one               three  ...     three       two          
C       bar       foo       bar  ...       foo       bar       foo
B                                ...                              
A  2.241830 -1.028115 -2.363137  ...       NaN       NaN  0.128491
B -0.676843  0.005518       NaN  ... -2.128743 -0.194294       NaN
C -1.077692  1.399070  1.177566  ...       NaN       NaN  0.872482

[3 rows x 12 columns]

---->   pandas.pivot_table

--------------------------------------
ID: 1750 --> 1
In [70]: pd.pivot_table(df[["A", "B", "C", "D", "E"]], index=["A", "B"], columns=["C"])
Out[70]: 
                D                   E          
C             bar       foo       bar       foo
A     B                                        
one   A  1.120915 -0.514058  1.393057 -0.021605
      B -0.338421  0.002759  0.684140 -0.551692
      C -0.538846  0.699535 -0.988442  0.747859
three A -1.181568       NaN  0.961289       NaN
      B       NaN  0.433512       NaN -1.064372
      C  0.588783       NaN -0.131830       NaN
two   A       NaN  1.000985       NaN  0.064245
      B  0.158248       NaN -0.097147       NaN
      C       NaN  0.176180       NaN  0.436241

---->   pandas.pivot_table

--------------------------------------
ID: 1751 --> 2
In [71]: pd.pivot_table(df, values="D", index=pd.Grouper(freq="M", key="F"), columns="C")
Out[71]: 
C                bar       foo
F                             
2013-01-31       NaN -0.514058
2013-02-28       NaN  0.002759
2013-03-31       NaN  0.176180
2013-04-30 -1.181568       NaN
2013-05-31 -0.338421       NaN
2013-06-30 -0.538846       NaN
2013-07-31       NaN  1.000985
2013-08-31       NaN  0.433512
2013-09-30       NaN  0.699535
2013-10-31  1.120915       NaN
2013-11-30  0.158248       NaN
2013-12-31  0.588783       NaN

---->   pandas.pivot_table; pandas.Grouper

--------------------------------------
ID: 1752 --> 1
In [72]: table = pd.pivot_table(df, index=["A", "B"], columns=["C"], values=["D", "E"])

In [73]: print(table.to_string(na_rep=""))
                D                   E          
C             bar       foo       bar       foo
A     B                                        
one   A  1.120915 -0.514058  1.393057 -0.021605
      B -0.338421  0.002759  0.684140 -0.551692
      C -0.538846  0.699535 -0.988442  0.747859
three A -1.181568            0.961289          
      B            0.433512           -1.064372
      C  0.588783           -0.131830          
two   A            1.000985            0.064245
      B  0.158248           -0.097147          
      C            0.176180            0.436241

---->   pandas.pivot_table

--------------------------------------
ID: 1753 --> 1
In [74]: table = df.pivot_table(
   ....:     index=["A", "B"],
   ....:     columns="C",
   ....:     values=["D", "E"],
   ....:     margins=True,
   ....:     aggfunc=np.std
   ....: )
   ....: 

In [75]: table
Out[75]: 
                D                             E                    
C             bar       foo       All       bar       foo       All
A     B                                                            
one   A  1.804346  1.210272  1.569879  0.179483  0.418374  0.858005
      B  0.690376  1.353355  0.898998  1.083825  0.968138  1.101401
      C  0.273641  0.418926  0.771139  1.689271  0.446140  1.422136
three A  0.794212       NaN  0.794212  2.049040       NaN  2.049040
      B       NaN  0.363548  0.363548       NaN  1.625237  1.625237
      C  3.915454       NaN  3.915454  1.035215       NaN  1.035215
two   A       NaN  0.442998  0.442998       NaN  0.447104  0.447104
      B  0.202765       NaN  0.202765  0.560757       NaN  0.560757
      C       NaN  1.819408  1.819408       NaN  0.650439  0.650439
All      1.556686  0.952552  1.246608  1.250924  0.899904  1.059389

---->   DataFrame.pivot_table

--------------------------------------
ID: 1755 --> 1
In [77]: foo, bar, dull, shiny, one, two = "foo", "bar", "dull", "shiny", "one", "two"

In [78]: a = np.array([foo, foo, bar, bar, foo, foo], dtype=object)

In [79]: b = np.array([one, one, two, one, two, one], dtype=object)

In [80]: c = np.array([dull, dull, shiny, dull, dull, shiny], dtype=object)

In [81]: pd.crosstab(a, [b, c], rownames=["a"], colnames=["b", "c"])
Out[81]: 
b    one        two      
c   dull shiny dull shiny
a                        
bar    1     0    0     1
foo    2     1    1     0

---->   pandas.crosstab

--------------------------------------
ID: 1756 --> 2
In [82]: df = pd.DataFrame(
   ....:     {"A": [1, 2, 2, 2, 2], "B": [3, 3, 4, 4, 4], "C": [1, 1, np.nan, 1, 1]}
   ....: )
   ....: 

In [83]: df
Out[83]: 
   A  B    C
0  1  3  1.0
1  2  3  1.0
2  2  4  NaN
3  2  4  1.0
4  2  4  1.0

In [84]: pd.crosstab(df["A"], df["B"])
Out[84]: 
B  3  4
A      
1  1  0
2  1  3

---->   pandas.DataFrame; pandas.crosstab

--------------------------------------
ID: 1757 --> 2
In [85]: foo = pd.Categorical(["a", "b"], categories=["a", "b", "c"])

In [86]: bar = pd.Categorical(["d", "e"], categories=["d", "e", "f"])

In [87]: pd.crosstab(foo, bar)
Out[87]: 
col_0  d  e
row_0      
a      1  0
b      0  1

---->   pandas.Categorical; pandas.crosstab

--------------------------------------
ID: 1758 --> 1
In [88]: pd.crosstab(foo, bar, dropna=False)
Out[88]: 
col_0  d  e  f
row_0         
a      1  0  0
b      0  1  0
c      0  0  0

---->   pandas.crosstab

--------------------------------------
ID: 1759 --> 1
In [89]: pd.crosstab(df["A"], df["B"], normalize=True)
Out[89]: 
B    3    4
A          
1  0.2  0.0
2  0.2  0.6

---->   pandas.crosstab

--------------------------------------
ID: 1760 --> 1
In [90]: pd.crosstab(df["A"], df["B"], normalize="columns")
Out[90]: 
B    3    4
A          
1  0.5  0.0
2  0.5  1.0

---->   pandas.crosstab

--------------------------------------
ID: 1761 --> 1
In [91]: pd.crosstab(df["A"], df["B"], values=df["C"], aggfunc=np.sum)
Out[91]: 
B    3    4
A          
1  1.0  NaN
2  1.0  2.0

---->   pandas.crosstab

--------------------------------------
ID: 1762 --> 1
In [92]: pd.crosstab(
   ....:     df["A"], df["B"], values=df["C"], aggfunc=np.sum, normalize=True, margins=True
   ....: )
   ....: 
Out[92]: 
B       3    4   All
A                   
1    0.25  0.0  0.25
2    0.25  0.5  0.75
All  0.50  0.5  1.00

---->   pandas.crosstab

--------------------------------------
ID: 1763 --> 1
In [93]: ages = np.array([10, 15, 13, 12, 23, 25, 28, 59, 60])

In [94]: pd.cut(ages, bins=3)
Out[94]: 
[(9.95, 26.667], (9.95, 26.667], (9.95, 26.667], (9.95, 26.667], (9.95, 26.667], (9.95, 26.667], (26.667, 43.333], (43.333, 60.0], (43.333, 60.0]]
Categories (3, interval[float64, right]): [(9.95, 26.667] < (26.667, 43.333] < (43.333, 60.0]]

---->   pandas.cut

--------------------------------------
ID: 1764 --> 1
In [95]: c = pd.cut(ages, bins=[0, 18, 35, 70])

In [96]: c
Out[96]: 
[(0, 18], (0, 18], (0, 18], (0, 18], (18, 35], (18, 35], (18, 35], (35, 70], (35, 70]]
Categories (3, interval[int64, right]): [(0, 18] < (18, 35] < (35, 70]]

---->   pandas.cut

--------------------------------------
ID: 1765 --> 1
pd.cut([25, 20, 50], bins=c.categories)

---->   pandas.cut

--------------------------------------
ID: 1766 --> 2
In [97]: df = pd.DataFrame({"key": list("bbacab"), "data1": range(6)})

In [98]: pd.get_dummies(df["key"])
Out[98]: 
       a      b      c
0  False   True  False
1  False   True  False
2   True  False  False
3  False  False   True
4   True  False  False
5  False   True  False

---->   pandas.DataFrame; pandas.get_dummies

--------------------------------------
ID: 1767 --> 1
In [99]: dummies = pd.get_dummies(df["key"], prefix="key")

In [100]: dummies
Out[100]: 
   key_a  key_b  key_c
0  False   True  False
1  False   True  False
2   True  False  False
3  False  False   True
4   True  False  False
5  False   True  False

In [101]: df[["data1"]].join(dummies)
Out[101]: 
   data1  key_a  key_b  key_c
0      0  False   True  False
1      1  False   True  False
2      2   True  False  False
3      3  False  False   True
4      4   True  False  False
5      5  False   True  False

---->   pandas.get_dummies

--------------------------------------
ID: 1768 --> 2
In [102]: values = np.random.randn(10)

In [103]: values
Out[103]: 
array([ 0.4082, -1.0481, -0.0257, -0.9884,  0.0941,  1.2627,  1.29  ,
        0.0824, -0.0558,  0.5366])

In [104]: bins = [0, 0.2, 0.4, 0.6, 0.8, 1]

In [105]: pd.get_dummies(pd.cut(values, bins))
Out[105]: 
   (0.0, 0.2]  (0.2, 0.4]  (0.4, 0.6]  (0.6, 0.8]  (0.8, 1.0]
0       False       False        True       False       False
1       False       False       False       False       False
2       False       False       False       False       False
3       False       False       False       False       False
4        True       False       False       False       False
5       False       False       False       False       False
6       False       False       False       False       False
7        True       False       False       False       False
8       False       False       False       False       False
9       False       False        True       False       False

---->   pandas.get_dummies; pandas.cut

--------------------------------------
ID: 1769 --> 2
In [106]: df = pd.DataFrame({"A": ["a", "b", "a"], "B": ["c", "c", "b"], "C": [1, 2, 3]})

In [107]: pd.get_dummies(df)
Out[107]: 
   C    A_a    A_b    B_b    B_c
0  1   True  False  False   True
1  2  False   True  False   True
2  3   True  False   True  False

---->   pandas.DataFrame; pandas.get_dummies

--------------------------------------
ID: 1770 --> 1
In [108]: pd.get_dummies(df, columns=["A"])
Out[108]: 
   B  C    A_a    A_b
0  c  1   True  False
1  c  2  False   True
2  b  3   True  False

---->   pandas.get_dummies

--------------------------------------
ID: 1771 --> 1
In [109]: simple = pd.get_dummies(df, prefix="new_prefix")

In [110]: simple
Out[110]: 
   C  new_prefix_a  new_prefix_b  new_prefix_b  new_prefix_c
0  1          True         False         False          True
1  2         False          True         False          True
2  3          True         False          True         False

In [111]: from_list = pd.get_dummies(df, prefix=["from_A", "from_B"])

In [112]: from_list
Out[112]: 
   C  from_A_a  from_A_b  from_B_b  from_B_c
0  1      True     False     False      True
1  2     False      True     False      True
2  3      True     False      True     False

In [113]: from_dict = pd.get_dummies(df, prefix={"B": "from_B", "A": "from_A"})

In [114]: from_dict
Out[114]: 
   C  from_A_a  from_A_b  from_B_b  from_B_c
0  1      True     False     False      True
1  2     False      True     False      True
2  3      True     False      True     False

---->   pandas.get_dummies

--------------------------------------
ID: 1772 --> 2
In [115]: s = pd.Series(list("abcaa"))

In [116]: pd.get_dummies(s)
Out[116]: 
       a      b      c
0   True  False  False
1  False   True  False
2  False  False   True
3   True  False  False
4   True  False  False

In [117]: pd.get_dummies(s, drop_first=True)
Out[117]: 
       b      c
0  False  False
1   True  False
2  False   True
3  False  False
4  False  False

---->   pandas.Series; pandas.get_dummies

--------------------------------------
ID: 1773 --> 2
In [118]: df = pd.DataFrame({"A": list("aaaaa"), "B": list("ababc")})

In [119]: pd.get_dummies(df)
Out[119]: 
    A_a    B_a    B_b    B_c
0  True   True  False  False
1  True  False   True  False
2  True   True  False  False
3  True  False   True  False
4  True  False  False   True

In [120]: pd.get_dummies(df, drop_first=True)
Out[120]: 
     B_b    B_c
0  False  False
1   True  False
2  False  False
3   True  False
4  False   True

---->   pandas.DataFrame; pandas.get_dummies

--------------------------------------
ID: 1774 --> 2
In [121]: df = pd.DataFrame({"A": list("abc"), "B": [1.1, 2.2, 3.3]})

In [122]: pd.get_dummies(df, dtype=bool).dtypes
Out[122]: 
B      float64
A_a       bool
A_b       bool
A_c       bool
dtype: object

---->   pandas.DataFrame; pandas.get_dummies

--------------------------------------
ID: 1775 --> 2
In [123]: df = pd.DataFrame({"prefix_a": [0, 1, 0], "prefix_b": [1, 0, 1]})

In [124]: df
Out[124]: 
   prefix_a  prefix_b
0         0         1
1         1         0
2         0         1

In [125]: pd.from_dummies(df, sep="_")
Out[125]: 
  prefix
0      b
1      a
2      b

---->   pandas.DataFrame; pandas.from_dummies

--------------------------------------
ID: 1776 --> 2
In [126]: df = pd.DataFrame({"prefix_a": [0, 1, 0]})

In [127]: df
Out[127]: 
   prefix_a
0         0
1         1
2         0

In [128]: pd.from_dummies(df, sep="_", default_category="b")
Out[128]: 
  prefix
0      b
1      a
2      b

---->   pandas.DataFrame; pandas.from_dummies

--------------------------------------
ID: 1777 --> 2
In [129]: x = pd.Series(["A", "A", np.nan, "B", 3.14, np.inf])

In [130]: x
Out[130]: 
0       A
1       A
2     NaN
3       B
4    3.14
5     inf
dtype: object

In [131]: labels, uniques = pd.factorize(x)

In [132]: labels
Out[132]: array([ 0,  0, -1,  1,  2,  3])

In [133]: uniques
Out[133]: Index(['A', 'B', 3.14, inf], dtype='object')

---->   pandas.Series; pandas.factorize

--------------------------------------
ID: 1778 --> 2
In [134]: ser = pd.Series(['A', 'A', np.nan, 'B', 3.14, np.inf])

In [135]: pd.factorize(ser, sort=True)
Out[135]: (array([ 2,  2, -1,  3,  0,  1]), Index([3.14, inf, 'A', 'B'], dtype='object'))

In [136]: np.unique(ser, return_inverse=True)[::-1]
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
Cell In[136], line 1
----> 1 np.unique(ser, return_inverse=True)[::-1]

File <__array_function__ internals>:200, in unique(*args, **kwargs)

File ~/micromamba-root/envs/test/lib/python3.8/site-packages/numpy/lib/arraysetops.py:274, in unique(ar, return_index, return_inverse, return_counts, axis, equal_nan)
    272 ar = np.asanyarray(ar)
    273 if axis is None:
--> 274     ret = _unique1d(ar, return_index, return_inverse, return_counts, 
    275                     equal_nan=equal_nan)
    276     return _unpack_tuple(ret)
    278 # axis was specified and not None

File ~/micromamba-root/envs/test/lib/python3.8/site-packages/numpy/lib/arraysetops.py:333, in _unique1d(ar, return_index, return_inverse, return_counts, equal_nan)
    330 optional_indices = return_index or return_inverse
    332 if optional_indices:
--> 333     perm = ar.argsort(kind='mergesort' if return_index else 'quicksort')
    334     aux = ar[perm]
    335 else:

TypeError: '<' not supported between instances of 'float' and 'str'

---->   pandas.Series; pandas.factorize

--------------------------------------
ID: 1779 --> 2
In [137]: np.random.seed([3, 1415])

In [138]: n = 20

In [139]: cols = np.array(["key", "row", "item", "col"])

In [140]: df = cols + pd.DataFrame(
   .....:     (np.random.randint(5, size=(n, 4)) // [2, 1, 2, 1]).astype(str)
   .....: )
   .....: 

In [141]: df.columns = cols

In [142]: df = df.join(pd.DataFrame(np.random.rand(n, 2).round(2)).add_prefix("val"))

In [143]: df
Out[143]: 
     key   row   item   col  val0  val1
0   key0  row3  item1  col3  0.81  0.04
1   key1  row2  item1  col2  0.44  0.07
2   key1  row0  item1  col0  0.77  0.01
3   key0  row4  item0  col2  0.15  0.59
4   key1  row0  item2  col1  0.81  0.64
..   ...   ...    ...   ...   ...   ...
15  key0  row3  item1  col1  0.31  0.23
16  key0  row0  item2  col3  0.86  0.01
17  key0  row4  item0  col3  0.64  0.21
18  key2  row2  item2  col0  0.13  0.45
19  key0  row2  item0  col4  0.37  0.70

[20 rows x 6 columns]

---->   pandas.DataFrame; DataFrame.join

--------------------------------------
ID: 1780 --> 1
In [144]: df.pivot_table(values="val0", index="row", columns="col", aggfunc="mean")
Out[144]: 
col   col0   col1   col2   col3  col4
row                                  
row0  0.77  0.605    NaN  0.860  0.65
row2  0.13    NaN  0.395  0.500  0.25
row3   NaN  0.310    NaN  0.545   NaN
row4   NaN  0.100  0.395  0.760  0.24

---->   DataFrame.pivot_table

--------------------------------------
ID: 1781 --> 1
In [145]: df.pivot_table(
   .....:     values="val0",
   .....:     index="row",
   .....:     columns="col",
   .....:     aggfunc="mean",
   .....:     fill_value=0,
   .....: )
   .....: 
Out[145]: 
col   col0   col1   col2   col3  col4
row                                  
row0  0.77  0.605  0.000  0.860  0.65
row2  0.13  0.000  0.395  0.500  0.25
row3  0.00  0.310  0.000  0.545  0.00
row4  0.00  0.100  0.395  0.760  0.24

---->   DataFrame.pivot_table

--------------------------------------
ID: 1782 --> 1
In [146]: df.pivot_table(
   .....:     values="val0",
   .....:     index="row",
   .....:     columns="col",
   .....:     aggfunc="sum",
   .....:     fill_value=0,
   .....: )
   .....: 
Out[146]: 
col   col0  col1  col2  col3  col4
row                               
row0  0.77  1.21  0.00  0.86  0.65
row2  0.13  0.00  0.79  0.50  0.50
row3  0.00  0.31  0.00  1.09  0.00
row4  0.00  0.10  0.79  1.52  0.24

---->   DataFrame.pivot_table

--------------------------------------
ID: 1783 --> 1
In [147]: df.pivot_table(index="row", columns="col", fill_value=0, aggfunc="size")
Out[147]: 
col   col0  col1  col2  col3  col4
row                               
row0     1     2     0     1     1
row2     1     0     2     1     2
row3     0     1     0     2     0
row4     0     1     2     2     1

---->   DataFrame.pivot_table

--------------------------------------
ID: 1784 --> 1
In [148]: df.pivot_table(
   .....:     values="val0",
   .....:     index="row",
   .....:     columns="col",
   .....:     aggfunc=["mean", "sum"],
   .....: )
   .....: 
Out[148]: 
      mean                              sum                        
col   col0   col1   col2   col3  col4  col0  col1  col2  col3  col4
row                                                                
row0  0.77  0.605    NaN  0.860  0.65  0.77  1.21   NaN  0.86  0.65
row2  0.13    NaN  0.395  0.500  0.25  0.13   NaN  0.79  0.50  0.50
row3   NaN  0.310    NaN  0.545   NaN   NaN  0.31   NaN  1.09   NaN
row4   NaN  0.100  0.395  0.760  0.24   NaN  0.10  0.79  1.52  0.24

---->   DataFrame.pivot_table

--------------------------------------
ID: 1785 --> 1
In [149]: df.pivot_table(
   .....:     values=["val0", "val1"],
   .....:     index="row",
   .....:     columns="col",
   .....:     aggfunc=["mean"],
   .....: )
   .....: 
Out[149]: 
      mean                                                           
      val0                             val1                          
col   col0   col1   col2   col3  col4  col0   col1  col2   col3  col4
row                                                                  
row0  0.77  0.605    NaN  0.860  0.65  0.01  0.745   NaN  0.010  0.02
row2  0.13    NaN  0.395  0.500  0.25  0.45    NaN  0.34  0.440  0.79
row3   NaN  0.310    NaN  0.545   NaN   NaN  0.230   NaN  0.075   NaN
row4   NaN  0.100  0.395  0.760  0.24   NaN  0.070  0.42  0.300  0.46

---->   DataFrame.pivot_table

--------------------------------------
ID: 1786 --> 1
In [150]: df.pivot_table(
   .....:     values=["val0"],
   .....:     index="row",
   .....:     columns=["item", "col"],
   .....:     aggfunc=["mean"],
   .....: )
   .....: 
Out[150]: 
      mean                                                                   
      val0                                                                   
item item0             item1                         item2                   
col   col2  col3  col4  col0  col1  col2  col3  col4  col0   col1  col3  col4
row                                                                          
row0   NaN   NaN   NaN  0.77   NaN   NaN   NaN   NaN   NaN  0.605  0.86  0.65
row2  0.35   NaN  0.37   NaN   NaN  0.44   NaN   NaN  0.13    NaN  0.50  0.13
row3   NaN   NaN   NaN   NaN  0.31   NaN  0.81   NaN   NaN    NaN  0.28   NaN
row4  0.15  0.64   NaN   NaN  0.10  0.64  0.88  0.24   NaN    NaN   NaN   NaN

---->   DataFrame.pivot_table

--------------------------------------
ID: 1787 --> 1
In [151]: keys = ["panda1", "panda2", "panda3"]

In [152]: values = [["eats", "shoots"], ["shoots", "leaves"], ["eats", "leaves"]]

In [153]: df = pd.DataFrame({"keys": keys, "values": values})

In [154]: df
Out[154]: 
     keys            values
0  panda1    [eats, shoots]
1  panda2  [shoots, leaves]
2  panda3    [eats, leaves]

---->   pandas.DataFrame

--------------------------------------
ID: 1789 --> 1
In [156]: df.explode("values")
Out[156]: 
     keys  values
0  panda1    eats
0  panda1  shoots
1  panda2  shoots
1  panda2  leaves
2  panda3    eats
2  panda3  leaves

---->   DataFrame.explode

--------------------------------------
ID: 1790 --> 2
In [157]: s = pd.Series([[1, 2, 3], "foo", [], ["a", "b"]])

In [158]: s
Out[158]: 
0    [1, 2, 3]
1          foo
2           []
3       [a, b]
dtype: object

In [159]: s.explode()
Out[159]: 
0      1
0      2
0      3
1    foo
2    NaN
3      a
3      b
dtype: object

---->   pandas.Series; Series.explode

--------------------------------------
ID: 1791 --> 1
In [160]: df = pd.DataFrame([{"var1": "a,b,c", "var2": 1}, {"var1": "d,e,f", "var2": 2}])

In [161]: df
Out[161]: 
    var1  var2
0  a,b,c     1
1  d,e,f     2

---->   pandas.DataFrame

--------------------------------------
ID: 1792 --> 1
In [162]: df.assign(var1=df.var1.str.split(",")).explode("var1")
Out[162]: 
  var1  var2
0    a     1
0    b     1
0    c     1
1    d     2
1    e     2
1    f     2

---->   DataFrame.assign

--------------------------------------
ID: 1793 --> 2
In [1]: index = pd.date_range("1/1/2000", periods=8)

In [2]: s = pd.Series(np.random.randn(5), index=["a", "b", "c", "d", "e"])

In [3]: df = pd.DataFrame(np.random.randn(8, 3), index=index, columns=["A", "B", "C"])

---->   pandas.Series; pandas.DataFrame

--------------------------------------
ID: 1794 --> 3
In [4]: long_series = pd.Series(np.random.randn(1000))

In [5]: long_series.head()
Out[5]: 
0   -1.157892
1   -1.344312
2    0.844885
3    1.075770
4   -0.109050
dtype: float64

In [6]: long_series.tail(3)
Out[6]: 
997   -0.289388
998   -1.020544
999    0.589993
dtype: float64

---->   pandas.Series; Series.head; Series.tail

--------------------------------------
ID: 1796 --> 1
In [12]: s.to_numpy()
Out[12]: array([ 0.4691, -0.2829, -1.5091, -1.1356,  1.2121])

In [13]: np.asarray(s)
Out[13]: array([ 0.4691, -0.2829, -1.5091, -1.1356,  1.2121])

---->   Series.to_numpy

--------------------------------------
ID: 1797 --> 2
In [14]: ser = pd.Series(pd.date_range("2000", periods=2, tz="CET"))

In [15]: ser.to_numpy(dtype=object)
Out[15]: 
array([Timestamp('2000-01-01 00:00:00+0100', tz='CET'),
       Timestamp('2000-01-02 00:00:00+0100', tz='CET')], dtype=object)

---->   pandas.Series; Series.to_numpy

--------------------------------------
ID: 1798 --> 1
In [16]: ser.to_numpy(dtype="datetime64[ns]")
Out[16]: 
array(['1999-12-31T23:00:00.000000000', '2000-01-01T23:00:00.000000000'],
      dtype='datetime64[ns]')

---->   Series.to_numpy

--------------------------------------
ID: 1801 --> 3
In [18]: df = pd.DataFrame(
   ....:     {
   ....:         "one": pd.Series(np.random.randn(3), index=["a", "b", "c"]),
   ....:         "two": pd.Series(np.random.randn(4), index=["a", "b", "c", "d"]),
   ....:         "three": pd.Series(np.random.randn(3), index=["b", "c", "d"]),
   ....:     }
   ....: )
   ....: 

In [19]: df
Out[19]: 
        one       two     three
a  1.394981  1.772517       NaN
b  0.343054  1.912123 -0.050390
c  0.695246  1.478369  1.227435
d       NaN  0.279344 -0.613172

In [20]: row = df.iloc[1]

In [21]: column = df["two"]

In [22]: df.sub(row, axis="columns")
Out[22]: 
        one       two     three
a  1.051928 -0.139606       NaN
b  0.000000  0.000000  0.000000
c  0.352192 -0.433754  1.277825
d       NaN -1.632779 -0.562782

In [23]: df.sub(row, axis=1)
Out[23]: 
        one       two     three
a  1.051928 -0.139606       NaN
b  0.000000  0.000000  0.000000
c  0.352192 -0.433754  1.277825
d       NaN -1.632779 -0.562782

In [24]: df.sub(column, axis="index")
Out[24]: 
        one  two     three
a -0.377535  0.0       NaN
b -1.569069  0.0 -1.962513
c -0.783123  0.0 -0.250933
d       NaN  0.0 -0.892516

In [25]: df.sub(column, axis=0)
Out[25]: 
        one  two     three
a -0.377535  0.0       NaN
b -1.569069  0.0 -1.962513
c -0.783123  0.0 -0.250933
d       NaN  0.0 -0.892516

---->   pandas.DataFrame; pandas.Series; DataFrame.sub

--------------------------------------
ID: 1802 --> 2
In [26]: dfmi = df.copy()

In [27]: dfmi.index = pd.MultiIndex.from_tuples(
   ....:     [(1, "a"), (1, "b"), (1, "c"), (2, "a")], names=["first", "second"]
   ....: )
   ....: 

In [28]: dfmi.sub(column, axis=0, level="second")
Out[28]: 
                   one       two     three
first second                              
1     a      -0.377535  0.000000       NaN
      b      -1.569069  0.000000 -1.962513
      c      -0.783123  0.000000 -0.250933
2     a            NaN -1.493173 -2.385688

---->   DataFrame.copy; pandas.MultiIndex

--------------------------------------
ID: 1803 --> 2
In [29]: s = pd.Series(np.arange(10))

In [30]: s
Out[30]: 
0    0
1    1
2    2
3    3
4    4
5    5
6    6
7    7
8    8
9    9
dtype: int64

In [31]: div, rem = divmod(s, 3)

In [32]: div
Out[32]: 
0    0
1    0
2    0
3    1
4    1
5    1
6    2
7    2
8    2
9    3
dtype: int64

In [33]: rem
Out[33]: 
0    0
1    1
2    2
3    0
4    1
5    2
6    0
7    1
8    2
9    0
dtype: int64

In [34]: idx = pd.Index(np.arange(10))

In [35]: idx
Out[35]: Index([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype='int64')

In [36]: div, rem = divmod(idx, 3)

In [37]: div
Out[37]: Index([0, 0, 0, 1, 1, 1, 2, 2, 2, 3], dtype='int64')

In [38]: rem
Out[38]: Index([0, 1, 2, 0, 1, 2, 0, 1, 2, 0], dtype='int64')

---->   pandas.Series; pandas.Index

--------------------------------------
ID: 1805 --> 1
In [42]: df
Out[42]: 
        one       two     three
a  1.394981  1.772517       NaN
b  0.343054  1.912123 -0.050390
c  0.695246  1.478369  1.227435
d       NaN  0.279344 -0.613172

In [43]: df2
Out[43]: 
        one       two     three
a  1.394981  1.772517  1.000000
b  0.343054  1.912123 -0.050390
c  0.695246  1.478369  1.227435
d       NaN  0.279344 -0.613172

In [44]: df + df2
Out[44]: 
        one       two     three
a  2.789963  3.545034       NaN
b  0.686107  3.824246 -0.100780
c  1.390491  2.956737  2.454870
d       NaN  0.558688 -1.226343

In [45]: df.add(df2, fill_value=0)
Out[45]: 
        one       two     three
a  2.789963  3.545034  1.000000
b  0.686107  3.824246 -0.100780
c  1.390491  2.956737  2.454870
d       NaN  0.558688 -1.226343

---->   DataFrame.add

--------------------------------------
ID: 1806 --> 2
In [46]: df.gt(df2)
Out[46]: 
     one    two  three
a  False  False  False
b  False  False  False
c  False  False  False
d  False  False  False

In [47]: df2.ne(df)
Out[47]: 
     one    two  three
a  False  False   True
b  False  False  False
c  False  False  False
d   True  False  False

---->   DataFrame.gt; DataFrame.ne

--------------------------------------
ID: 1809 --> 1
In [51]: df.empty
Out[51]: False

In [52]: pd.DataFrame(columns=list("ABC")).empty
Out[52]: True

---->   pandas.DataFrame

--------------------------------------
ID: 1810 --> 2
In [53]: pd.Series([True]).bool()
Out[53]: True

In [54]: pd.Series([False]).bool()
Out[54]: False

In [55]: pd.DataFrame([[True]]).bool()
Out[55]: True

In [56]: pd.DataFrame([[False]]).bool()
Out[56]: False

---->   pandas.Series; pandas.DataFrame

--------------------------------------
ID: 1811 --> 2
ValueError: The truth value of an array is ambiguous. Use a.empty, a.any() or a.all().

---->   Index.any; Index.all

--------------------------------------
ID: 1814 --> 2
In [61]: df1 = pd.DataFrame({"col": ["foo", 0, np.nan]})

In [62]: df2 = pd.DataFrame({"col": [np.nan, 0, "foo"]}, index=[2, 1, 0])

In [63]: df1.equals(df2)
Out[63]: False

In [64]: df1.equals(df2.sort_index())
Out[64]: True

---->   pandas.DataFrame; DataFrame.equals

--------------------------------------
ID: 1815 --> 2
In [65]: pd.Series(["foo", "bar", "baz"]) == "foo"
Out[65]: 
0     True
1    False
2    False
dtype: bool

In [66]: pd.Index(["foo", "bar", "baz"]) == "foo"
Out[66]: array([ True, False, False])

---->   pandas.Series; pandas.Index

--------------------------------------
ID: 1816 --> 2
In [67]: pd.Series(["foo", "bar", "baz"]) == pd.Index(["foo", "bar", "qux"])
Out[67]: 
0     True
1     True
2    False
dtype: bool

In [68]: pd.Series(["foo", "bar", "baz"]) == np.array(["foo", "bar", "qux"])
Out[68]: 
0     True
1     True
2    False
dtype: bool

---->   pandas.Series; pandas.Index

--------------------------------------
ID: 1817 --> 1
In [55]: pd.Series(['foo', 'bar', 'baz']) == pd.Series(['foo', 'bar'])
ValueError: Series lengths must match to compare

In [56]: pd.Series(['foo', 'bar', 'baz']) == pd.Series(['foo'])
ValueError: Series lengths must match to compare

---->   pandas.Series

--------------------------------------
ID: 1820 --> 2
In [71]: df1 = pd.DataFrame(
   ....:     {"A": [1.0, np.nan, 3.0, 5.0, np.nan], "B": [np.nan, 2.0, 3.0, np.nan, 6.0]}
   ....: )
   ....: 

In [72]: df2 = pd.DataFrame(
   ....:     {
   ....:         "A": [5.0, 2.0, 4.0, np.nan, 3.0, 7.0],
   ....:         "B": [np.nan, np.nan, 3.0, 4.0, 6.0, 8.0],
   ....:     }
   ....: )
   ....: 

In [73]: df1
Out[73]: 
     A    B
0  1.0  NaN
1  NaN  2.0
2  3.0  3.0
3  5.0  NaN
4  NaN  6.0

In [74]: df2
Out[74]: 
     A    B
0  5.0  NaN
1  2.0  NaN
2  4.0  3.0
3  NaN  4.0
4  3.0  6.0
5  7.0  8.0

In [75]: df1.combine_first(df2)
Out[75]: 
     A    B
0  1.0  NaN
1  2.0  2.0
2  3.0  3.0
3  5.0  4.0
4  3.0  6.0
5  7.0  8.0

---->   pandas.DataFrame; DataFrame.combine_first

--------------------------------------
ID: 1821 --> 2
In [76]: def combiner(x, y):
   ....:     return np.where(pd.isna(x), y, x)
   ....: 

In [77]: df1.combine(df2, combiner)
Out[77]: 
     A    B
0  1.0  NaN
1  2.0  2.0
2  3.0  3.0
3  5.0  4.0
4  3.0  6.0
5  7.0  8.0

---->   pandas.isna; DataFrame.combine

--------------------------------------
ID: 1822 --> 1
In [78]: df
Out[78]: 
        one       two     three
a  1.394981  1.772517       NaN
b  0.343054  1.912123 -0.050390
c  0.695246  1.478369  1.227435
d       NaN  0.279344 -0.613172

In [79]: df.mean(0)
Out[79]: 
one      0.811094
two      1.360588
three    0.187958
dtype: float64

In [80]: df.mean(1)
Out[80]: 
a    1.583749
b    0.734929
c    1.133683
d   -0.166914
dtype: float64

---->   DataFrame.mean

--------------------------------------
ID: 1823 --> 1
In [81]: df.sum(0, skipna=False)
Out[81]: 
one           NaN
two      5.442353
three         NaN
dtype: float64

In [82]: df.sum(axis=1, skipna=True)
Out[82]: 
a    3.167498
b    2.204786
c    3.401050
d   -0.333828
dtype: float64

---->   DataFrame.sum

--------------------------------------
ID: 1824 --> 3
In [83]: ts_stand = (df - df.mean()) / df.std()

In [84]: ts_stand.std()
Out[84]: 
one      1.0
two      1.0
three    1.0
dtype: float64

In [85]: xs_stand = df.sub(df.mean(1), axis=0).div(df.std(1), axis=0)

In [86]: xs_stand.std(1)
Out[86]: 
a    1.0
b    1.0
c    1.0
d    1.0
dtype: float64

---->   DataFrame.mean; DataFrame.std; DataFrame.sub

--------------------------------------
ID: 1825 --> 1
In [87]: df.cumsum()
Out[87]: 
        one       two     three
a  1.394981  1.772517       NaN
b  1.738035  3.684640 -0.050390
c  2.433281  5.163008  1.177045
d       NaN  5.442353  0.563873

---->   DataFrame.cumsum

--------------------------------------
ID: 1827 --> 2
In [90]: series = pd.Series(np.random.randn(500))

In [91]: series[20:500] = np.nan

In [92]: series[10:20] = 5

In [93]: series.nunique()
Out[93]: 11

---->   pandas.Series; Series.nunique

--------------------------------------
ID: 1828 --> 4
In [94]: series = pd.Series(np.random.randn(1000))

In [95]: series[::2] = np.nan

In [96]: series.describe()
Out[96]: 
count    500.000000
mean      -0.021292
std        1.015906
min       -2.683763
25%       -0.699070
50%       -0.069718
75%        0.714483
max        3.160915
dtype: float64

In [97]: frame = pd.DataFrame(np.random.randn(1000, 5), columns=["a", "b", "c", "d", "e"])

In [98]: frame.iloc[::2] = np.nan

In [99]: frame.describe()
Out[99]: 
                a           b           c           d           e
count  500.000000  500.000000  500.000000  500.000000  500.000000
mean     0.033387    0.030045   -0.043719   -0.051686    0.005979
std      1.017152    0.978743    1.025270    1.015988    1.006695
min     -3.000951   -2.637901   -3.303099   -3.159200   -3.188821
25%     -0.647623   -0.576449   -0.712369   -0.691338   -0.691115
50%      0.047578   -0.021499   -0.023888   -0.032652   -0.025363
75%      0.729907    0.775880    0.618896    0.670047    0.649748
max      2.740139    2.752332    3.004229    2.728702    3.240991

---->   pandas.Series; Series.describe; pandas.DataFrame; DataFrame.describe

--------------------------------------
ID: 1829 --> 1
In [100]: series.describe(percentiles=[0.05, 0.25, 0.75, 0.95])
Out[100]: 
count    500.000000
mean      -0.021292
std        1.015906
min       -2.683763
5%        -1.645423
25%       -0.699070
50%       -0.069718
75%        0.714483
95%        1.711409
max        3.160915
dtype: float64

---->   Series.describe

--------------------------------------
ID: 1830 --> 2
In [101]: s = pd.Series(["a", "a", "b", "b", "a", "a", np.nan, "c", "d", "a"])

In [102]: s.describe()
Out[102]: 
count     9
unique    4
top       a
freq      5
dtype: object

---->   pandas.Series; Series.describe

--------------------------------------
ID: 1831 --> 2
In [103]: frame = pd.DataFrame({"a": ["Yes", "Yes", "No", "No"], "b": range(4)})

In [104]: frame.describe()
Out[104]: 
              b
count  4.000000
mean   1.500000
std    1.290994
min    0.000000
25%    0.750000
50%    1.500000
75%    2.250000
max    3.000000

---->   pandas.DataFrame; DataFrame.describe

--------------------------------------
ID: 1832 --> 1
In [105]: frame.describe(include=["object"])
Out[105]: 
          a
count     4
unique    2
top     Yes
freq      2

In [106]: frame.describe(include=["number"])
Out[106]: 
              b
count  4.000000
mean   1.500000
std    1.290994
min    0.000000
25%    0.750000
50%    1.500000
75%    2.250000
max    3.000000

In [107]: frame.describe(include="all")
Out[107]: 
          a         b
count     4  4.000000
unique    2       NaN
top     Yes       NaN
freq      2       NaN
mean    NaN  1.500000
std     NaN  1.290994
min     NaN  0.000000
25%     NaN  0.750000
50%     NaN  1.500000
75%     NaN  2.250000
max     NaN  3.000000

---->   DataFrame.describe

--------------------------------------
ID: 1833 --> 6
In [108]: s1 = pd.Series(np.random.randn(5))

In [109]: s1
Out[109]: 
0    1.118076
1   -0.352051
2   -1.242883
3   -1.277155
4   -0.641184
dtype: float64

In [110]: s1.idxmin(), s1.idxmax()
Out[110]: (3, 0)

In [111]: df1 = pd.DataFrame(np.random.randn(5, 3), columns=["A", "B", "C"])

In [112]: df1
Out[112]: 
          A         B         C
0 -0.327863 -0.946180 -0.137570
1 -0.186235 -0.257213 -0.486567
2 -0.507027 -0.871259 -0.111110
3  2.000339 -2.430505  0.089759
4 -0.321434 -0.033695  0.096271

In [113]: df1.idxmin(axis=0)
Out[113]: 
A    2
B    3
C    1
dtype: int64

In [114]: df1.idxmax(axis=1)
Out[114]: 
0    C
1    A
2    C
3    A
4    C
dtype: object

---->   pandas.Series; Series.idxmin; Series.idxmax; pandas.DataFrame; DataFrame.idxmin; DataFrame.idxmax

--------------------------------------
ID: 1834 --> 1
In [115]: df3 = pd.DataFrame([2, 1, 1, 3, np.nan], columns=["A"], index=list("edcba"))

In [116]: df3
Out[116]: 
     A
e  2.0
d  1.0
c  1.0
b  3.0
a  NaN

In [117]: df3["A"].idxmin()
Out[117]: 'd'

---->   pandas.DataFrame

--------------------------------------
ID: 1835 --> 2
In [118]: data = np.random.randint(0, 7, size=50)

In [119]: data
Out[119]: 
array([6, 6, 2, 3, 5, 3, 2, 5, 4, 5, 4, 3, 4, 5, 0, 2, 0, 4, 2, 0, 3, 2,
       2, 5, 6, 5, 3, 4, 6, 4, 3, 5, 6, 4, 3, 6, 2, 6, 6, 2, 3, 4, 2, 1,
       6, 2, 6, 1, 5, 4])

In [120]: s = pd.Series(data)

In [121]: s.value_counts()
Out[121]: 
6    10
2    10
4     9
3     8
5     8
0     3
1     2
Name: count, dtype: int64

In [122]: pd.value_counts(data)
Out[122]: 
6    10
2    10
4     9
3     8
5     8
0     3
1     2
Name: count, dtype: int64

---->   pandas.Series; Series.value_counts

--------------------------------------
ID: 1836 --> 2
In [123]: data = {"a": [1, 2, 3, 4], "b": ["x", "x", "y", "y"]}

In [124]: frame = pd.DataFrame(data)

In [125]: frame.value_counts()
Out[125]: 
a  b
1  x    1
2  x    1
3  y    1
4  y    1
Name: count, dtype: int64

---->   pandas.DataFrame; DataFrame.value_counts

--------------------------------------
ID: 1837 --> 4
In [126]: s5 = pd.Series([1, 1, 3, 3, 3, 5, 5, 7, 7, 7])

In [127]: s5.mode()
Out[127]: 
0    3
1    7
dtype: int64

In [128]: df5 = pd.DataFrame(
   .....:     {
   .....:         "A": np.random.randint(0, 7, size=50),
   .....:         "B": np.random.randint(-10, 15, size=50),
   .....:     }
   .....: )
   .....: 

In [129]: df5.mode()
Out[129]: 
     A   B
0  1.0  -9
1  NaN  10
2  NaN  13

---->   pandas.Series; Series.mode; pandas.DataFrame; DataFrame.mode

--------------------------------------
ID: 1838 --> 1
In [130]: arr = np.random.randn(20)

In [131]: factor = pd.cut(arr, 4)

In [132]: factor
Out[132]: 
[(-0.251, 0.464], (-0.968, -0.251], (0.464, 1.179], (-0.251, 0.464], (-0.968, -0.251], ..., (-0.251, 0.464], (-0.968, -0.251], (-0.968, -0.251], (-0.968, -0.251], (-0.968, -0.251]]
Length: 20
Categories (4, interval[float64, right]): [(-0.968, -0.251] < (-0.251, 0.464] < (0.464, 1.179] <
                                           (1.179, 1.893]]

In [133]: factor = pd.cut(arr, [-5, -1, 0, 1, 5])

In [134]: factor
Out[134]: 
[(0, 1], (-1, 0], (0, 1], (0, 1], (-1, 0], ..., (-1, 0], (-1, 0], (-1, 0], (-1, 0], (-1, 0]]
Length: 20
Categories (4, interval[int64, right]): [(-5, -1] < (-1, 0] < (0, 1] < (1, 5]]

---->   pandas.cut

--------------------------------------
ID: 1839 --> 1
In [135]: arr = np.random.randn(30)

In [136]: factor = pd.qcut(arr, [0, 0.25, 0.5, 0.75, 1])

In [137]: factor
Out[137]: 
[(0.569, 1.184], (-2.278, -0.301], (-2.278, -0.301], (0.569, 1.184], (0.569, 1.184], ..., (-0.301, 0.569], (1.184, 2.346], (1.184, 2.346], (-0.301, 0.569], (-2.278, -0.301]]
Length: 30
Categories (4, interval[float64, right]): [(-2.278, -0.301] < (-0.301, 0.569] < (0.569, 1.184] <
                                           (1.184, 2.346]]

In [138]: pd.value_counts(factor)
Out[138]: 
(-2.278, -0.301]    8
(1.184, 2.346]      8
(-0.301, 0.569]     7
(0.569, 1.184]      7
Name: count, dtype: int64

---->   pandas.qcut

--------------------------------------
ID: 1840 --> 1
In [139]: arr = np.random.randn(20)

In [140]: factor = pd.cut(arr, [-np.inf, 0, np.inf])

In [141]: factor
Out[141]: 
[(-inf, 0.0], (0.0, inf], (0.0, inf], (-inf, 0.0], (-inf, 0.0], ..., (-inf, 0.0], (-inf, 0.0], (-inf, 0.0], (0.0, inf], (0.0, inf]]
Length: 20
Categories (2, interval[float64, right]): [(-inf, 0.0] < (0.0, inf]]

---->   pandas.cut

--------------------------------------
ID: 1841 --> 1
In [142]: def extract_city_name(df):
   .....:     """
   .....:     Chicago, IL -> Chicago for city_name column
   .....:     """
   .....:     df["city_name"] = df["city_and_code"].str.split(",").str.get(0)
   .....:     return df
   .....: 

In [143]: def add_country_name(df, country_name=None):
   .....:     """
   .....:     Chicago -> Chicago-US for city_name column
   .....:     """
   .....:     col = "city_name"
   .....:     df["city_and_country"] = df[col] + country_name
   .....:     return df
   .....: 

In [144]: df_p = pd.DataFrame({"city_and_code": ["Chicago, IL"]})

---->   pandas.DataFrame

--------------------------------------
ID: 1843 --> 1
In [146]: df_p.pipe(extract_city_name).pipe(add_country_name, country_name="US")
Out[146]: 
  city_and_code city_name city_and_country
0   Chicago, IL   Chicago        ChicagoUS

---->   DataFrame.pipe

--------------------------------------
ID: 1845 --> 2
In [147]: df.apply(np.mean)
Out[147]: 
one      0.811094
two      1.360588
three    0.187958
dtype: float64

In [148]: df.apply(np.mean, axis=1)
Out[148]: 
a    1.583749
b    0.734929
c    1.133683
d   -0.166914
dtype: float64

In [149]: df.apply(lambda x: x.max() - x.min())
Out[149]: 
one      1.051928
two      1.632779
three    1.840607
dtype: float64

In [150]: df.apply(np.cumsum)
Out[150]: 
        one       two     three
a  1.394981  1.772517       NaN
b  1.738035  3.684640 -0.050390
c  2.433281  5.163008  1.177045
d       NaN  5.442353  0.563873

In [151]: df.apply(np.exp)
Out[151]: 
        one       two     three
a  4.034899  5.885648       NaN
b  1.409244  6.767440  0.950858
c  2.004201  4.385785  3.412466
d       NaN  1.322262  0.541630

---->   Series.max; Series.min

--------------------------------------
ID: 1847 --> 2
In [154]: tsdf = pd.DataFrame(
   .....:     np.random.randn(1000, 3),
   .....:     columns=["A", "B", "C"],
   .....:     index=pd.date_range("1/1/2000", periods=1000),
   .....: )
   .....: 

In [155]: tsdf.apply(lambda x: x.idxmax())
Out[155]: 
A   2000-08-06
B   2001-01-18
C   2001-07-18
dtype: datetime64[ns]

---->   pandas.DataFrame; Series.idxmax

--------------------------------------
ID: 1851 --> 1
In [158]: tsdf = pd.DataFrame(
   .....:     np.random.randn(10, 3),
   .....:     columns=["A", "B", "C"],
   .....:     index=pd.date_range("1/1/2000", periods=10),
   .....: )
   .....: 

In [159]: tsdf.iloc[3:7] = np.nan

In [160]: tsdf
Out[160]: 
                   A         B         C
2000-01-01  1.257606  1.004194  0.167574
2000-01-02 -0.749892  0.288112 -0.757304
2000-01-03 -0.207550 -0.298599  0.116018
2000-01-04       NaN       NaN       NaN
2000-01-05       NaN       NaN       NaN
2000-01-06       NaN       NaN       NaN
2000-01-07       NaN       NaN       NaN
2000-01-08  0.814347 -0.257623  0.869226
2000-01-09 -0.250663 -1.206601  0.896839
2000-01-10  2.169758 -1.333363  0.283157

---->   pandas.DataFrame

--------------------------------------
ID: 1857 --> 1
In [168]: tsdf["A"].agg(["sum", lambda x: x.mean()])
Out[168]: 
sum         3.033606
    0.505601
Name: A, dtype: float64

---->   Series.mean

--------------------------------------
ID: 1858 --> 1
In [169]: def mymean(x):
   .....:     return x.mean()
   .....: 

In [170]: tsdf["A"].agg(["sum", mymean])
Out[170]: 
sum       3.033606
mymean    0.505601
Name: A, dtype: float64

---->   Series.mean

--------------------------------------
ID: 1862 --> 1
In [179]: tsdf = pd.DataFrame(
   .....:     np.random.randn(10, 3),
   .....:     columns=["A", "B", "C"],
   .....:     index=pd.date_range("1/1/2000", periods=10),
   .....: )
   .....: 

In [180]: tsdf.iloc[3:7] = np.nan

In [181]: tsdf
Out[181]: 
                   A         B         C
2000-01-01 -0.428759 -0.864890 -0.675341
2000-01-02 -0.168731  1.338144 -1.279321
2000-01-03 -1.621034  0.438107  0.903794
2000-01-04       NaN       NaN       NaN
2000-01-05       NaN       NaN       NaN
2000-01-06       NaN       NaN       NaN
2000-01-07       NaN       NaN       NaN
2000-01-08  0.254374 -1.240447 -0.201052
2000-01-09 -0.157795  0.791197 -1.144209
2000-01-10 -0.030876  0.371900  0.061932

---->   pandas.DataFrame

--------------------------------------
ID: 1863 --> 1
In [182]: tsdf.transform(np.abs)
Out[182]: 
                   A         B         C
2000-01-01  0.428759  0.864890  0.675341
2000-01-02  0.168731  1.338144  1.279321
2000-01-03  1.621034  0.438107  0.903794
2000-01-04       NaN       NaN       NaN
2000-01-05       NaN       NaN       NaN
2000-01-06       NaN       NaN       NaN
2000-01-07       NaN       NaN       NaN
2000-01-08  0.254374  1.240447  0.201052
2000-01-09  0.157795  0.791197  1.144209
2000-01-10  0.030876  0.371900  0.061932

In [183]: tsdf.transform("abs")
Out[183]: 
                   A         B         C
2000-01-01  0.428759  0.864890  0.675341
2000-01-02  0.168731  1.338144  1.279321
2000-01-03  1.621034  0.438107  0.903794
2000-01-04       NaN       NaN       NaN
2000-01-05       NaN       NaN       NaN
2000-01-06       NaN       NaN       NaN
2000-01-07       NaN       NaN       NaN
2000-01-08  0.254374  1.240447  0.201052
2000-01-09  0.157795  0.791197  1.144209
2000-01-10  0.030876  0.371900  0.061932

In [184]: tsdf.transform(lambda x: x.abs())
Out[184]: 
                   A         B         C
2000-01-01  0.428759  0.864890  0.675341
2000-01-02  0.168731  1.338144  1.279321
2000-01-03  1.621034  0.438107  0.903794
2000-01-04       NaN       NaN       NaN
2000-01-05       NaN       NaN       NaN
2000-01-06       NaN       NaN       NaN
2000-01-07       NaN       NaN       NaN
2000-01-08  0.254374  1.240447  0.201052
2000-01-09  0.157795  0.791197  1.144209
2000-01-10  0.030876  0.371900  0.061932

---->   Series.abs

--------------------------------------
ID: 1870 --> 1
In [191]: df4
Out[191]: 
        one       two     three
a  1.394981  1.772517       NaN
b  0.343054  1.912123 -0.050390
c  0.695246  1.478369  1.227435
d       NaN  0.279344 -0.613172

In [192]: def f(x):
   .....:     return len(str(x))
   .....: 

In [193]: df4["one"].map(f)
Out[193]: 
a    18
b    19
c    18
d     3
Name: one, dtype: int64

In [194]: df4.applymap(f)
Out[194]: 
   one  two  three
a   18   17      3
b   19   18     20
c   18   18     16
d    3   19     19

---->   DataFrame.applymap

--------------------------------------
ID: 1871 --> 2
In [195]: s = pd.Series(
   .....:     ["six", "seven", "six", "seven", "six"], index=["a", "b", "c", "d", "e"]
   .....: )
   .....: 

In [196]: t = pd.Series({"six": 6.0, "seven": 7.0})

In [197]: s
Out[197]: 
a      six
b    seven
c      six
d    seven
e      six
dtype: object

In [198]: s.map(t)
Out[198]: 
a    6.0
b    7.0
c    6.0
d    7.0
e    6.0
dtype: float64

---->   pandas.Series; Series.map

--------------------------------------
ID: 1872 --> 1
In [199]: s = pd.Series(np.random.randn(5), index=["a", "b", "c", "d", "e"])

In [200]: s
Out[200]: 
a    1.695148
b    1.328614
c    1.234686
d   -0.385845
e   -1.326508
dtype: float64

In [201]: s.reindex(["e", "b", "f", "d"])
Out[201]: 
e   -1.326508
b    1.328614
f         NaN
d   -0.385845
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 1876 --> 1
In [209]: df2
Out[209]: 
        one       two
a  1.394981  1.772517
b  0.343054  1.912123
c  0.695246  1.478369

In [210]: df3
Out[210]: 
        one       two
a  0.583888  0.051514
b -0.468040  0.191120
c -0.115848 -0.242634

In [211]: df.reindex_like(df2)
Out[211]: 
        one       two
a  1.394981  1.772517
b  0.343054  1.912123
c  0.695246  1.478369

---->   DataFrame.reindex_like

--------------------------------------
ID: 1877 --> 2
In [212]: s = pd.Series(np.random.randn(5), index=["a", "b", "c", "d", "e"])

In [213]: s1 = s[:4]

In [214]: s2 = s[1:]

In [215]: s1.align(s2)
Out[215]: 
(a   -0.186646
 b   -1.692424
 c   -0.303893
 d   -1.425662
 e         NaN
 dtype: float64,
 a         NaN
 b   -1.692424
 c   -0.303893
 d   -1.425662
 e    1.114285
 dtype: float64)

In [216]: s1.align(s2, join="inner")
Out[216]: 
(b   -1.692424
 c   -0.303893
 d   -1.425662
 dtype: float64,
 b   -1.692424
 c   -0.303893
 d   -1.425662
 dtype: float64)

In [217]: s1.align(s2, join="left")
Out[217]: 
(a   -0.186646
 b   -1.692424
 c   -0.303893
 d   -1.425662
 dtype: float64,
 a         NaN
 b   -1.692424
 c   -0.303893
 d   -1.425662
 dtype: float64)

---->   pandas.Series; Series.align

--------------------------------------
ID: 1878 --> 1
In [218]: df.align(df2, join="inner")
Out[218]: 
(        one       two
 a  1.394981  1.772517
 b  0.343054  1.912123
 c  0.695246  1.478369,
         one       two
 a  1.394981  1.772517
 b  0.343054  1.912123
 c  0.695246  1.478369)

---->   DataFrame.align

--------------------------------------
ID: 1879 --> 1
In [219]: df.align(df2, join="inner", axis=0)
Out[219]: 
(        one       two     three
 a  1.394981  1.772517       NaN
 b  0.343054  1.912123 -0.050390
 c  0.695246  1.478369  1.227435,
         one       two
 a  1.394981  1.772517
 b  0.343054  1.912123
 c  0.695246  1.478369)

---->   DataFrame.align

--------------------------------------
ID: 1880 --> 1
In [220]: df.align(df2.iloc[0], axis=1)
Out[220]: 
(        one     three       two
 a  1.394981       NaN  1.772517
 b  0.343054 -0.050390  1.912123
 c  0.695246  1.227435  1.478369
 d       NaN -0.613172  0.279344,
 one      1.394981
 three         NaN
 two      1.772517
 Name: a, dtype: float64)

---->   DataFrame.align

--------------------------------------
ID: 1881 --> 1
In [221]: rng = pd.date_range("1/3/2000", periods=8)

In [222]: ts = pd.Series(np.random.randn(8), index=rng)

In [223]: ts2 = ts[[0, 3, 6]]

In [224]: ts
Out[224]: 
2000-01-03    0.183051
2000-01-04    0.400528
2000-01-05   -0.015083
2000-01-06    2.395489
2000-01-07    1.414806
2000-01-08    0.118428
2000-01-09    0.733639
2000-01-10   -0.936077
Freq: D, dtype: float64

In [225]: ts2
Out[225]: 
2000-01-03    0.183051
2000-01-06    2.395489
2000-01-09    0.733639
Freq: 3D, dtype: float64

In [226]: ts2.reindex(ts.index)
Out[226]: 
2000-01-03    0.183051
2000-01-04         NaN
2000-01-05         NaN
2000-01-06    2.395489
2000-01-07         NaN
2000-01-08         NaN
2000-01-09    0.733639
2000-01-10         NaN
Freq: D, dtype: float64

In [227]: ts2.reindex(ts.index, method="ffill")
Out[227]: 
2000-01-03    0.183051
2000-01-04    0.183051
2000-01-05    0.183051
2000-01-06    2.395489
2000-01-07    2.395489
2000-01-08    2.395489
2000-01-09    0.733639
2000-01-10    0.733639
Freq: D, dtype: float64

In [228]: ts2.reindex(ts.index, method="bfill")
Out[228]: 
2000-01-03    0.183051
2000-01-04    2.395489
2000-01-05    2.395489
2000-01-06    2.395489
2000-01-07    0.733639
2000-01-08    0.733639
2000-01-09    0.733639
2000-01-10         NaN
Freq: D, dtype: float64

In [229]: ts2.reindex(ts.index, method="nearest")
Out[229]: 
2000-01-03    0.183051
2000-01-04    0.183051
2000-01-05    2.395489
2000-01-06    2.395489
2000-01-07    2.395489
2000-01-08    0.733639
2000-01-09    0.733639
2000-01-10    0.733639
Freq: D, dtype: float64

---->   pandas.Series

--------------------------------------
ID: 1891 --> 2
In [243]: df = pd.DataFrame(
   .....:     {"x": [1, 2, 3, 4, 5, 6], "y": [10, 20, 30, 40, 50, 60]},
   .....:     index=pd.MultiIndex.from_product(
   .....:         [["a", "b", "c"], [1, 2]], names=["let", "num"]
   .....:     ),
   .....: )
   .....: 

In [244]: df
Out[244]: 
         x   y
let num       
a   1    1  10
    2    2  20
b   1    3  30
    2    4  40
c   1    5  50
    2    6  60

In [245]: df.rename_axis(index={"let": "abc"})
Out[245]: 
         x   y
abc num       
a   1    1  10
    2    2  20
b   1    3  30
    2    4  40
c   1    5  50
    2    6  60

In [246]: df.rename_axis(index=str.upper)
Out[246]: 
         x   y
LET NUM       
a   1    1  10
    2    2  20
b   1    3  30
    2    4  40
c   1    5  50
    2    6  60

---->   pandas.DataFrame; pandas.MultiIndex

--------------------------------------
ID: 1892 --> 1
In [247]: df = pd.DataFrame(
   .....:     {"col1": np.random.randn(3), "col2": np.random.randn(3)}, index=["a", "b", "c"]
   .....: )
   .....: 

In [248]: for col in df:
   .....:     print(col)
   .....: 
col1
col2

---->   pandas.DataFrame

--------------------------------------
ID: 1893 --> 2
In [249]: df = pd.DataFrame({"a": [1, 2, 3], "b": ["a", "b", "c"]})

In [250]: for index, row in df.iterrows():
   .....:     row["a"] = 10
   .....: 

In [251]: df
Out[251]: 
   a  b
0  1  a
1  2  b
2  3  c

---->   pandas.DataFrame; DataFrame.iterrows

--------------------------------------
ID: 1894 --> 1
In [252]: for label, ser in df.items():
   .....:     print(label)
   .....:     print(ser)
   .....: 
a
0    1
1    2
2    3
Name: a, dtype: int64
b
0    a
1    b
2    c
Name: b, dtype: object

---->   DataFrame.items

--------------------------------------
ID: 1895 --> 1
In [253]: for row_index, row in df.iterrows():
   .....:     print(row_index, row, sep="\n")
   .....: 
0
a    1
b    a
Name: 0, dtype: object
1
a    2
b    b
Name: 1, dtype: object
2
a    3
b    c
Name: 2, dtype: object

---->   DataFrame.iterrows

--------------------------------------
ID: 1896 --> 2
In [254]: df_orig = pd.DataFrame([[1, 1.5]], columns=["int", "float"])

In [255]: df_orig.dtypes
Out[255]: 
int        int64
float    float64
dtype: object

In [256]: row = next(df_orig.iterrows())[1]

In [257]: row
Out[257]: 
int      1.0
float    1.5
Name: 0, dtype: float64

---->   pandas.DataFrame; DataFrame.iterrows

--------------------------------------
ID: 1898 --> 2
In [260]: df2 = pd.DataFrame({"x": [1, 2, 3], "y": [4, 5, 6]})

In [261]: print(df2)
   x  y
0  1  4
1  2  5
2  3  6

In [262]: print(df2.T)
   0  1  2
x  1  2  3
y  4  5  6

In [263]: df2_t = pd.DataFrame({idx: values for idx, values in df2.iterrows()})

In [264]: print(df2_t)
   0  1  2
x  1  2  3
y  4  5  6

---->   pandas.DataFrame; DataFrame.iterrows

--------------------------------------
ID: 1899 --> 1
In [265]: for row in df.itertuples():
   .....:     print(row)
   .....: 
Pandas(Index=0, a=1, b='a')
Pandas(Index=1, a=2, b='b')
Pandas(Index=2, a=3, b='c')

---->   DataFrame.itertuples

--------------------------------------
ID: 1900 --> 1
# datetime
In [266]: s = pd.Series(pd.date_range("20130101 09:10:12", periods=4))

In [267]: s
Out[267]: 
0   2013-01-01 09:10:12
1   2013-01-02 09:10:12
2   2013-01-03 09:10:12
3   2013-01-04 09:10:12
dtype: datetime64[ns]

In [268]: s.dt.hour
Out[268]: 
0    9
1    9
2    9
3    9
dtype: int32

In [269]: s.dt.second
Out[269]: 
0    12
1    12
2    12
3    12
dtype: int32

In [270]: s.dt.day
Out[270]: 
0    1
1    2
2    3
3    4
dtype: int32

---->   pandas.Series

--------------------------------------
ID: 1903 --> 1
# DatetimeIndex
In [276]: s = pd.Series(pd.date_range("20130101", periods=4))

In [277]: s
Out[277]: 
0   2013-01-01
1   2013-01-02
2   2013-01-03
3   2013-01-04
dtype: datetime64[ns]

In [278]: s.dt.strftime("%Y/%m/%d")
Out[278]: 
0    2013/01/01
1    2013/01/02
2    2013/01/03
3    2013/01/04
dtype: object

---->   pandas.Series

--------------------------------------
ID: 1904 --> 2
# PeriodIndex
In [279]: s = pd.Series(pd.period_range("20130101", periods=4))

In [280]: s
Out[280]: 
0    2013-01-01
1    2013-01-02
2    2013-01-03
3    2013-01-04
dtype: period[D]

In [281]: s.dt.strftime("%Y/%m/%d")
Out[281]: 
0    2013/01/01
1    2013/01/02
2    2013/01/03
3    2013/01/04
dtype: object

---->   pandas.Series; pandas.period_range

--------------------------------------
ID: 1905 --> 2
# period
In [282]: s = pd.Series(pd.period_range("20130101", periods=4, freq="D"))

In [283]: s
Out[283]: 
0    2013-01-01
1    2013-01-02
2    2013-01-03
3    2013-01-04
dtype: period[D]

In [284]: s.dt.year
Out[284]: 
0    2013
1    2013
2    2013
3    2013
dtype: int64

In [285]: s.dt.day
Out[285]: 
0    1
1    2
2    3
3    4
dtype: int64

---->   pandas.Series; pandas.period_range

--------------------------------------
ID: 1906 --> 1
# timedelta
In [286]: s = pd.Series(pd.timedelta_range("1 day 00:00:05", periods=4, freq="s"))

In [287]: s
Out[287]: 
0   1 days 00:00:05
1   1 days 00:00:06
2   1 days 00:00:07
3   1 days 00:00:08
dtype: timedelta64[ns]

In [288]: s.dt.days
Out[288]: 
0    1
1    1
2    1
3    1
dtype: int64

In [289]: s.dt.seconds
Out[289]: 
0    5
1    6
2    7
3    8
dtype: int32

In [290]: s.dt.components
Out[290]: 
   days  hours  minutes  seconds  milliseconds  microseconds  nanoseconds
0     1      0        0        5             0             0            0
1     1      0        0        6             0             0            0
2     1      0        0        7             0             0            0
3     1      0        0        8             0             0            0

---->   pandas.Series

--------------------------------------
ID: 1907 --> 1
In [291]: s = pd.Series(
   .....:     ["A", "B", "C", "Aaba", "Baca", np.nan, "CABA", "dog", "cat"], dtype="string"
   .....: )
   .....: 

In [292]: s.str.lower()
Out[292]: 
0       a
1       b
2       c
3    aaba
4    baca
5    
6    caba
7     dog
8     cat
dtype: string

---->   pandas.Series

--------------------------------------
ID: 1908 --> 2
In [293]: df = pd.DataFrame(
   .....:     {
   .....:         "one": pd.Series(np.random.randn(3), index=["a", "b", "c"]),
   .....:         "two": pd.Series(np.random.randn(4), index=["a", "b", "c", "d"]),
   .....:         "three": pd.Series(np.random.randn(3), index=["b", "c", "d"]),
   .....:     }
   .....: )
   .....: 

In [294]: unsorted_df = df.reindex(
   .....:     index=["a", "d", "c", "b"], columns=["three", "two", "one"]
   .....: )
   .....: 

In [295]: unsorted_df
Out[295]: 
      three       two       one
a       NaN -1.152244  0.562973
d -0.252916 -0.109597       NaN
c  1.273388 -0.167123  0.640382
b -0.098217  0.009797 -1.299504

# DataFrame
In [296]: unsorted_df.sort_index()
Out[296]: 
      three       two       one
a       NaN -1.152244  0.562973
b -0.098217  0.009797 -1.299504
c  1.273388 -0.167123  0.640382
d -0.252916 -0.109597       NaN

In [297]: unsorted_df.sort_index(ascending=False)
Out[297]: 
      three       two       one
d -0.252916 -0.109597       NaN
c  1.273388 -0.167123  0.640382
b -0.098217  0.009797 -1.299504
a       NaN -1.152244  0.562973

In [298]: unsorted_df.sort_index(axis=1)
Out[298]: 
        one     three       two
a  0.562973       NaN -1.152244
d       NaN -0.252916 -0.109597
c  0.640382  1.273388 -0.167123
b -1.299504 -0.098217  0.009797

# Series
In [299]: unsorted_df["three"].sort_index()
Out[299]: 
a         NaN
b   -0.098217
c    1.273388
d   -0.252916
Name: three, dtype: float64

---->   pandas.DataFrame; pandas.Series

--------------------------------------
ID: 1909 --> 1
In [300]: s1 = pd.DataFrame({"a": ["B", "a", "C"], "b": [1, 2, 3], "c": [2, 3, 4]}).set_index(
   .....:     list("ab")
   .....: )
   .....: 

In [301]: s1
Out[301]: 
     c
a b   
B 1  2
a 2  3
C 3  4

---->   pandas.DataFrame

--------------------------------------
ID: 1911 --> 1
In [304]: df1 = pd.DataFrame(
   .....:     {"one": [2, 1, 1, 1], "two": [1, 3, 2, 4], "three": [5, 4, 3, 2]}
   .....: )
   .....: 

In [305]: df1.sort_values(by="two")
Out[305]: 
   one  two  three
0    2    1      5
2    1    2      3
1    1    3      4
3    1    4      2

---->   pandas.DataFrame

--------------------------------------
ID: 1914 --> 1
In [310]: s1 = pd.Series(["B", "a", "C"])

---->   pandas.Series

--------------------------------------
ID: 1916 --> 1
In [313]: df = pd.DataFrame({"a": ["B", "a", "C"], "b": [1, 2, 3]})

---->   pandas.DataFrame

--------------------------------------
ID: 1918 --> 2
# Build MultiIndex
In [316]: idx = pd.MultiIndex.from_tuples(
   .....:     [("a", 1), ("a", 2), ("a", 2), ("b", 2), ("b", 1), ("b", 1)]
   .....: )
   .....: 

In [317]: idx.names = ["first", "second"]

# Build DataFrame
In [318]: df_multi = pd.DataFrame({"A": np.arange(6, 0, -1)}, index=idx)

In [319]: df_multi
Out[319]: 
              A
first second   
a     1       6
      2       5
      2       4
b     2       3
      1       2
      1       1

---->   pandas.MultiIndex; pandas.DataFrame

--------------------------------------
ID: 1920 --> 2
In [321]: ser = pd.Series([1, 2, 3])

In [322]: ser.searchsorted([0, 3])
Out[322]: array([0, 2])

In [323]: ser.searchsorted([0, 4])
Out[323]: array([0, 3])

In [324]: ser.searchsorted([1, 3], side="right")
Out[324]: array([1, 3])

In [325]: ser.searchsorted([1, 3], side="left")
Out[325]: array([0, 2])

In [326]: ser = pd.Series([3, 1, 2])

In [327]: ser.searchsorted([0, 3], sorter=np.argsort(ser))
Out[327]: array([0, 2])

---->   pandas.Series; Series.searchsorted

--------------------------------------
ID: 1921 --> 3
In [328]: s = pd.Series(np.random.permutation(10))

In [329]: s
Out[329]: 
0    2
1    0
2    3
3    7
4    1
5    5
6    9
7    6
8    8
9    4
dtype: int64

In [330]: s.sort_values()
Out[330]: 
1    0
4    1
0    2
2    3
9    4
5    5
7    6
3    7
8    8
6    9
dtype: int64

In [331]: s.nsmallest(3)
Out[331]: 
1    0
4    1
0    2
dtype: int64

In [332]: s.nlargest(3)
Out[332]: 
6    9
8    8
3    7
dtype: int64

---->   pandas.Series; Series.nsmallest; Series.nlargest

--------------------------------------
ID: 1922 --> 3
In [333]: df = pd.DataFrame(
   .....:     {
   .....:         "a": [-2, -1, 1, 10, 8, 11, -1],
   .....:         "b": list("abdceff"),
   .....:         "c": [1.0, 2.0, 4.0, 3.2, np.nan, 3.0, 4.0],
   .....:     }
   .....: )
   .....: 

In [334]: df.nlargest(3, "a")
Out[334]: 
    a  b    c
5  11  f  3.0
3  10  c  3.2
4   8  e  NaN

In [335]: df.nlargest(5, ["a", "c"])
Out[335]: 
    a  b    c
5  11  f  3.0
3  10  c  3.2
4   8  e  NaN
2   1  d  4.0
6  -1  f  4.0

In [336]: df.nsmallest(3, "a")
Out[336]: 
   a  b    c
0 -2  a  1.0
1 -1  b  2.0
6 -1  f  4.0

In [337]: df.nsmallest(5, ["a", "c"])
Out[337]: 
   a  b    c
0 -2  a  1.0
1 -1  b  2.0
6 -1  f  4.0
2  1  d  4.0
4  8  e  NaN

---->   pandas.DataFrame; DataFrame.nlargest; DataFrame.nsmallest

--------------------------------------
ID: 1923 --> 1
In [338]: df1.columns = pd.MultiIndex.from_tuples(
   .....:     [("a", "one"), ("a", "two"), ("b", "three")]
   .....: )
   .....: 

In [339]: df1.sort_values(by=("a", "two"))
Out[339]: 
    a         b
  one two three
0   2   1     5
2   1   2     3
1   1   3     4
3   1   4     2

---->   pandas.MultiIndex

--------------------------------------
ID: 1924 --> 2
In [340]: dft = pd.DataFrame(
   .....:     {
   .....:         "A": np.random.rand(3),
   .....:         "B": 1,
   .....:         "C": "foo",
   .....:         "D": pd.Timestamp("20010102"),
   .....:         "E": pd.Series([1.0] * 3).astype("float32"),
   .....:         "F": False,
   .....:         "G": pd.Series([1] * 3, dtype="int8"),
   .....:     }
   .....: )
   .....: 

In [341]: dft
Out[341]: 
          A  B    C          D    E      F  G
0  0.035962  1  foo 2001-01-02  1.0  False  1
1  0.701379  1  foo 2001-01-02  1.0  False  1
2  0.281885  1  foo 2001-01-02  1.0  False  1

In [342]: dft.dtypes
Out[342]: 
A           float64
B             int64
C            object
D    datetime64[ns]
E           float32
F              bool
G              int8
dtype: object

---->   pandas.DataFrame; pandas.Series

--------------------------------------
ID: 1926 --> 1
# these ints are coerced to floats
In [344]: pd.Series([1, 2, 3, 4, 5, 6.0])
Out[344]: 
0    1.0
1    2.0
2    3.0
3    4.0
4    5.0
5    6.0
dtype: float64

# string data forces an ``object`` dtype
In [345]: pd.Series([1, 2, 3, 6.0, "foo"])
Out[345]: 
0      1
1      2
2      3
3    6.0
4    foo
dtype: object

---->   pandas.Series

--------------------------------------
ID: 1928 --> 2
In [347]: df1 = pd.DataFrame(np.random.randn(8, 1), columns=["A"], dtype="float32")

In [348]: df1
Out[348]: 
          A
0  0.224364
1  1.890546
2  0.182879
3  0.787847
4 -0.188449
5  0.667715
6 -0.011736
7 -0.399073

In [349]: df1.dtypes
Out[349]: 
A    float32
dtype: object

In [350]: df2 = pd.DataFrame(
   .....:     {
   .....:         "A": pd.Series(np.random.randn(8), dtype="float16"),
   .....:         "B": pd.Series(np.random.randn(8)),
   .....:         "C": pd.Series(np.random.randint(0, 255, size=8), dtype="uint8"),
   .....:     }
   .....: )
   .....: 

In [351]: df2
Out[351]: 
          A         B    C
0  0.823242  0.256090   26
1  1.607422  1.426469   86
2 -0.333740 -0.416203   46
3 -0.063477  1.139976  212
4 -1.014648 -1.193477   26
5  0.678711  0.096706    7
6 -0.040863 -1.956850  184
7 -0.357422 -0.714337  206

In [352]: df2.dtypes
Out[352]: 
A    float16
B    float64
C      uint8
dtype: object

---->   pandas.DataFrame; pandas.Series

--------------------------------------
ID: 1929 --> 1
In [353]: pd.DataFrame([1, 2], columns=["a"]).dtypes
Out[353]: 
a    int64
dtype: object

In [354]: pd.DataFrame({"a": [1, 2]}).dtypes
Out[354]: 
a    int64
dtype: object

In [355]: pd.DataFrame({"a": 1}, index=list(range(2))).dtypes
Out[355]: 
a    int64
dtype: object

---->   pandas.DataFrame

--------------------------------------
ID: 1930 --> 1
In [356]: frame = pd.DataFrame(np.array([1, 2]))

---->   pandas.DataFrame

--------------------------------------
ID: 1931 --> 1
In [357]: df3 = df1.reindex_like(df2).fillna(value=0.0) + df2

In [358]: df3
Out[358]: 
          A         B      C
0  1.047606  0.256090   26.0
1  3.497968  1.426469   86.0
2 -0.150862 -0.416203   46.0
3  0.724370  1.139976  212.0
4 -1.203098 -1.193477   26.0
5  1.346426  0.096706    7.0
6 -0.052599 -1.956850  184.0
7 -0.756495 -0.714337  206.0

In [359]: df3.dtypes
Out[359]: 
A    float32
B    float64
C    float64
dtype: object

---->   DataFrame.reindex_like

--------------------------------------
ID: 1933 --> 1
In [361]: df3
Out[361]: 
          A         B      C
0  1.047606  0.256090   26.0
1  3.497968  1.426469   86.0
2 -0.150862 -0.416203   46.0
3  0.724370  1.139976  212.0
4 -1.203098 -1.193477   26.0
5  1.346426  0.096706    7.0
6 -0.052599 -1.956850  184.0
7 -0.756495 -0.714337  206.0

In [362]: df3.dtypes
Out[362]: 
A    float32
B    float64
C    float64
dtype: object

# conversion of dtypes
In [363]: df3.astype("float32").dtypes
Out[363]: 
A    float32
B    float32
C    float32
dtype: object

---->   DataFrame.astype

--------------------------------------
ID: 1934 --> 1
In [364]: dft = pd.DataFrame({"a": [1, 2, 3], "b": [4, 5, 6], "c": [7, 8, 9]})

In [365]: dft[["a", "b"]] = dft[["a", "b"]].astype(np.uint8)

In [366]: dft
Out[366]: 
   a  b  c
0  1  4  7
1  2  5  8
2  3  6  9

In [367]: dft.dtypes
Out[367]: 
a    uint8
b    uint8
c    int64
dtype: object

---->   pandas.DataFrame

--------------------------------------
ID: 1935 --> 2
In [368]: dft1 = pd.DataFrame({"a": [1, 0, 1], "b": [4, 5, 6], "c": [7, 8, 9]})

In [369]: dft1 = dft1.astype({"a": np.bool_, "c": np.float64})

In [370]: dft1
Out[370]: 
       a  b    c
0   True  4  7.0
1  False  5  8.0
2   True  6  9.0

In [371]: dft1.dtypes
Out[371]: 
a       bool
b      int64
c    float64
dtype: object

---->   pandas.DataFrame; DataFrame.astype

--------------------------------------
ID: 1936 --> 1
In [372]: dft = pd.DataFrame({"a": [1, 2, 3], "b": [4, 5, 6], "c": [7, 8, 9]})

In [373]: dft.loc[:, ["a", "b"]].astype(np.uint8).dtypes
Out[373]: 
a    uint8
b    uint8
dtype: object

In [374]: dft.loc[:, ["a", "b"]] = dft.loc[:, ["a", "b"]].astype(np.uint8)

In [375]: dft.dtypes
Out[375]: 
a    int64
b    int64
c    int64
dtype: object

---->   pandas.DataFrame

--------------------------------------
ID: 1937 --> 1
In [376]: import datetime

In [377]: df = pd.DataFrame(
   .....:     [
   .....:         [1, 2],
   .....:         ["a", "b"],
   .....:         [datetime.datetime(2016, 3, 2), datetime.datetime(2016, 3, 2)],
   .....:     ]
   .....: )
   .....: 

In [378]: df = df.T

In [379]: df
Out[379]: 
   0  1          2
0  1  a 2016-03-02
1  2  b 2016-03-02

In [380]: df.dtypes
Out[380]: 
0            object
1            object
2    datetime64[ns]
dtype: object

---->   pandas.DataFrame

--------------------------------------
ID: 1938 --> 1
In [381]: df.infer_objects().dtypes
Out[381]: 
0             int64
1            object
2    datetime64[ns]
dtype: object

---->   DataFrame.infer_objects

--------------------------------------
ID: 1939 --> 1
In [382]: m = ["1.1", 2, 3]

In [383]: pd.to_numeric(m)
Out[383]: array([1.1, 2. , 3. ])

---->   pandas.to_numeric

--------------------------------------
ID: 1940 --> 1
In [384]: import datetime

In [385]: m = ["2016-07-09", datetime.datetime(2016, 3, 2)]

In [386]: pd.to_datetime(m)
Out[386]: DatetimeIndex(['2016-07-09', '2016-03-02'], dtype='datetime64[ns]', freq=None)

---->   pandas.to_datetime

--------------------------------------
ID: 1941 --> 1
In [387]: m = ["5us", pd.Timedelta("1day")]

In [388]: pd.to_timedelta(m)
Out[388]: TimedeltaIndex(['0 days 00:00:00.000005', '1 days 00:00:00'], dtype='timedelta64[ns]', freq=None)

---->   pandas.to_timedelta

--------------------------------------
ID: 1942 --> 3
In [389]: import datetime

In [390]: m = ["apple", datetime.datetime(2016, 3, 2)]

In [391]: pd.to_datetime(m, errors="coerce")
Out[391]: DatetimeIndex(['NaT', '2016-03-02'], dtype='datetime64[ns]', freq=None)

In [392]: m = ["apple", 2, 3]

In [393]: pd.to_numeric(m, errors="coerce")
Out[393]: array([nan,  2.,  3.])

In [394]: m = ["apple", pd.Timedelta("1day")]

In [395]: pd.to_timedelta(m, errors="coerce")
Out[395]: TimedeltaIndex([NaT, '1 days'], dtype='timedelta64[ns]', freq=None)

---->   pandas.to_datetime; pandas.to_numeric; pandas.to_timedelta

--------------------------------------
ID: 1943 --> 3
In [396]: import datetime

In [397]: m = ["apple", datetime.datetime(2016, 3, 2)]

In [398]: pd.to_datetime(m, errors="ignore")
Out[398]: Index(['apple', 2016-03-02 00:00:00], dtype='object')

In [399]: m = ["apple", 2, 3]

In [400]: pd.to_numeric(m, errors="ignore")
Out[400]: array(['apple', 2, 3], dtype=object)

In [401]: m = ["apple", pd.Timedelta("1day")]

In [402]: pd.to_timedelta(m, errors="ignore")
Out[402]: array(['apple', Timedelta('1 days 00:00:00')], dtype=object)

---->   pandas.to_datetime; pandas.to_numeric; pandas.to_timedelta

--------------------------------------
ID: 1944 --> 1
In [403]: m = ["1", 2, 3]

In [404]: pd.to_numeric(m, downcast="integer")  # smallest signed int dtype
Out[404]: array([1, 2, 3], dtype=int8)

In [405]: pd.to_numeric(m, downcast="signed")  # same as 'integer'
Out[405]: array([1, 2, 3], dtype=int8)

In [406]: pd.to_numeric(m, downcast="unsigned")  # smallest unsigned int dtype
Out[406]: array([1, 2, 3], dtype=uint8)

In [407]: pd.to_numeric(m, downcast="float")  # smallest float dtype
Out[407]: array([1., 2., 3.], dtype=float32)

---->   pandas.to_numeric

--------------------------------------
ID: 1945 --> 1
In [408]: import datetime

In [409]: df = pd.DataFrame([["2016-07-09", datetime.datetime(2016, 3, 2)]] * 2, dtype="O")

In [410]: df
Out[410]: 
            0                    1
0  2016-07-09  2016-03-02 00:00:00
1  2016-07-09  2016-03-02 00:00:00

In [411]: df.apply(pd.to_datetime)
Out[411]: 
           0          1
0 2016-07-09 2016-03-02
1 2016-07-09 2016-03-02

In [412]: df = pd.DataFrame([["1.1", 2, 3]] * 2, dtype="O")

In [413]: df
Out[413]: 
     0  1  2
0  1.1  2  3
1  1.1  2  3

In [414]: df.apply(pd.to_numeric)
Out[414]: 
     0  1  2
0  1.1  2  3
1  1.1  2  3

In [415]: df = pd.DataFrame([["5us", pd.Timedelta("1day")]] * 2, dtype="O")

In [416]: df
Out[416]: 
     0                1
0  5us  1 days 00:00:00
1  5us  1 days 00:00:00

In [417]: df.apply(pd.to_timedelta)
Out[417]: 
                       0      1
0 0 days 00:00:00.000005 1 days
1 0 days 00:00:00.000005 1 days

---->   pandas.DataFrame

--------------------------------------
ID: 1946 --> 1
In [418]: dfi = df3.astype("int32")

In [419]: dfi["E"] = 1

In [420]: dfi
Out[420]: 
   A  B    C  E
0  1  0   26  1
1  3  1   86  1
2  0  0   46  1
3  0  1  212  1
4 -1 -1   26  1
5  1  0    7  1
6  0 -1  184  1
7  0  0  206  1

In [421]: dfi.dtypes
Out[421]: 
A    int32
B    int32
C    int32
E    int64
dtype: object

In [422]: casted = dfi[dfi > 0]

In [423]: casted
Out[423]: 
     A    B    C  E
0  1.0  NaN   26  1
1  3.0  1.0   86  1
2  NaN  NaN   46  1
3  NaN  1.0  212  1
4  NaN  NaN   26  1
5  1.0  NaN    7  1
6  NaN  NaN  184  1
7  NaN  NaN  206  1

In [424]: casted.dtypes
Out[424]: 
A    float64
B    float64
C      int32
E      int64
dtype: object

---->   DataFrame.astype

--------------------------------------
ID: 1947 --> 1
In [425]: dfa = df3.copy()

In [426]: dfa["A"] = dfa["A"].astype("float32")

In [427]: dfa.dtypes
Out[427]: 
A    float32
B    float64
C    float64
dtype: object

In [428]: casted = dfa[df2 > 0]

In [429]: casted
Out[429]: 
          A         B      C
0  1.047606  0.256090   26.0
1  3.497968  1.426469   86.0
2       NaN       NaN   46.0
3       NaN  1.139976  212.0
4       NaN       NaN   26.0
5  1.346426  0.096706    7.0
6       NaN       NaN  184.0
7       NaN       NaN  206.0

In [430]: casted.dtypes
Out[430]: 
A    float32
B    float64
C    float64
dtype: object

---->   DataFrame.copy

--------------------------------------
ID: 1948 --> 2
In [431]: df = pd.DataFrame(
   .....:     {
   .....:         "string": list("abc"),
   .....:         "int64": list(range(1, 4)),
   .....:         "uint8": np.arange(3, 6).astype("u1"),
   .....:         "float64": np.arange(4.0, 7.0),
   .....:         "bool1": [True, False, True],
   .....:         "bool2": [False, True, False],
   .....:         "dates": pd.date_range("now", periods=3),
   .....:         "category": pd.Series(list("ABC")).astype("category"),
   .....:     }
   .....: )
   .....: 

In [432]: df["tdeltas"] = df.dates.diff()

In [433]: df["uint64"] = np.arange(3, 6).astype("u8")

In [434]: df["other_dates"] = pd.date_range("20130101", periods=3)

In [435]: df["tz_aware_dates"] = pd.date_range("20130101", periods=3, tz="US/Eastern")

In [436]: df
Out[436]: 
  string  int64  uint8  ...  uint64  other_dates            tz_aware_dates
0      a      1      3  ...       3   2013-01-01 2013-01-01 00:00:00-05:00
1      b      2      4  ...       4   2013-01-02 2013-01-02 00:00:00-05:00
2      c      3      5  ...       5   2013-01-03 2013-01-03 00:00:00-05:00

[3 rows x 12 columns]

---->   pandas.DataFrame; pandas.Series

--------------------------------------
ID: 1949 --> 1
In [438]: df.select_dtypes(include=[bool])
Out[438]: 
   bool1  bool2
0   True  False
1  False   True
2   True  False

---->   DataFrame.select_dtypes

--------------------------------------
ID: 1950 --> 1
In [439]: df.select_dtypes(include=["bool"])
Out[439]: 
   bool1  bool2
0   True  False
1  False   True
2   True  False

---->   DataFrame.select_dtypes

--------------------------------------
ID: 1951 --> 1
In [440]: df.select_dtypes(include=["number", "bool"], exclude=["unsignedinteger"])
Out[440]: 
   int64  float64  bool1  bool2 tdeltas
0      1      4.0   True  False     NaT
1      2      5.0  False   True  1 days
2      3      6.0   True  False  1 days

---->   DataFrame.select_dtypes

--------------------------------------
ID: 1952 --> 1
In [441]: df.select_dtypes(include=["object"])
Out[441]: 
  string
0      a
1      b
2      c

---->   DataFrame.select_dtypes

--------------------------------------
ID: 1955 --> 1
In [1]: df = pd.DataFrame({"foo": [1, 2, 3], "bar": [4, 5, 6]})

In [2]: subset = df["foo"]

In [3]: subset.iloc[0] = 100

In [4]: df
Out[4]: 
   foo  bar
0  100    4
1    2    5
2    3    6

---->   pandas.DataFrame

--------------------------------------
ID: 1956 --> 1
In [5]: pd.options.mode.copy_on_write = True

In [6]: df = pd.DataFrame({"foo": [1, 2, 3], "bar": [4, 5, 6]})

In [7]: subset = df["foo"]

In [8]: subset.iloc[0] = 100

In [9]: df
Out[9]: 
   foo  bar
0    1    4
1    2    5
2    3    6

---->   pandas.DataFrame

--------------------------------------
ID: 1957 --> 1
In [10]: df = pd.DataFrame({"foo": [1, 2, 3], "bar": [4, 5, 6]})

In [11]: df.iloc[0, 0] = 100

In [12]: df
Out[12]: 
   foo  bar
0  100    4
1    2    5
2    3    6

---->   pandas.DataFrame

--------------------------------------
ID: 1958 --> 1
In [13]: df = pd.DataFrame({"foo": [1, 2, 3], "bar": [4, 5, 6]})

In [14]: df2 = df.reset_index(drop=True)

In [15]: df2.iloc[0, 0] = 100

In [16]: df
Out[16]: 
   foo  bar
0    1    4
1    2    5
2    3    6

In [17]: df2
Out[17]: 
   foo  bar
0  100    4
1    2    5
2    3    6

---->   pandas.DataFrame

--------------------------------------
ID: 1959 --> 1
In [18]: df = pd.DataFrame({"foo": [1, 2, 3], "bar": [4, 5, 6]})

In [19]: df = df.reset_index(drop=True)

In [20]: df.iloc[0, 0] = 100

In [21]: df
Out[21]: 
   foo  bar
0  100    4
1    2    5
2    3    6

---->   pandas.DataFrame

--------------------------------------
ID: 1960 --> 1
In [22]: with pd.option_context("mode.copy_on_write", False):
   ....:     df = pd.DataFrame({"foo": [1, 2, 3], "bar": [4, 5, 6]})
   ....:     view = df[:]
   ....:     df.iloc[0, 0] = 100
   ....: 

In [23]: df
Out[23]: 
   foo  bar
0  100    4
1    2    5
2    3    6

In [24]: view
Out[24]: 
   foo  bar
0  100    4
1    2    5
2    3    6

---->   pandas.DataFrame

--------------------------------------
ID: 1961 --> 1
In [25]: df = pd.DataFrame({"foo": [1, 2, 3], "bar": [4, 5, 6]})

In [26]: view = df[:]

In [27]: df.iloc[0, 0] = 100

In [28]: df
Out[28]: 
   foo  bar
0  100    4
1    2    5
2    3    6

In [29]: view
Out[29]: 
   foo  bar
0    1    4
1    2    5
2    3    6

---->   pandas.DataFrame

--------------------------------------
ID: 1962 --> 1
In [30]: with pd.option_context("mode.copy_on_write", False):
   ....:     df = pd.DataFrame({"foo": [1, 2, 3], "bar": [4, 5, 6]})
   ....:     df["foo"][df["bar"] > 5] = 100
   ....:     df
   ....: 

---->   pandas.DataFrame

--------------------------------------
ID: 1963 --> 1
In [31]: df = pd.DataFrame({"foo": [1, 2, 3], "bar": [4, 5, 6]})

In [32]: df["foo"][df["bar"] > 5] = 100

---->   pandas.DataFrame

--------------------------------------
ID: 1965 --> 1
In [1]: df1 = pd.DataFrame(
   ...:     {
   ...:         "A": ["A0", "A1", "A2", "A3"],
   ...:         "B": ["B0", "B1", "B2", "B3"],
   ...:         "C": ["C0", "C1", "C2", "C3"],
   ...:         "D": ["D0", "D1", "D2", "D3"],
   ...:     },
   ...:     index=[0, 1, 2, 3],
   ...: )
   ...: 

In [2]: df2 = pd.DataFrame(
   ...:     {
   ...:         "A": ["A4", "A5", "A6", "A7"],
   ...:         "B": ["B4", "B5", "B6", "B7"],
   ...:         "C": ["C4", "C5", "C6", "C7"],
   ...:         "D": ["D4", "D5", "D6", "D7"],
   ...:     },
   ...:     index=[4, 5, 6, 7],
   ...: )
   ...: 

In [3]: df3 = pd.DataFrame(
   ...:     {
   ...:         "A": ["A8", "A9", "A10", "A11"],
   ...:         "B": ["B8", "B9", "B10", "B11"],
   ...:         "C": ["C8", "C9", "C10", "C11"],
   ...:         "D": ["D8", "D9", "D10", "D11"],
   ...:     },
   ...:     index=[8, 9, 10, 11],
   ...: )
   ...: 

In [4]: frames = [df1, df2, df3]

In [5]: result = pd.concat(frames)

---->   pandas.DataFrame

--------------------------------------
ID: 1969 --> 1
In [8]: df4 = pd.DataFrame(
   ...:     {
   ...:         "B": ["B2", "B3", "B6", "B7"],
   ...:         "D": ["D2", "D3", "D6", "D7"],
   ...:         "F": ["F2", "F3", "F6", "F7"],
   ...:     },
   ...:     index=[2, 3, 6, 7],
   ...: )
   ...: 

In [9]: result = pd.concat([df1, df4], axis=1)

---->   pandas.DataFrame

--------------------------------------
ID: 1974 --> 1
In [14]: s1 = pd.Series(["X0", "X1", "X2", "X3"], name="X")

In [15]: result = pd.concat([df1, s1], axis=1)

---->   pandas.Series

--------------------------------------
ID: 1975 --> 1
In [16]: s2 = pd.Series(["_0", "_1", "_2", "_3"])

In [17]: result = pd.concat([df1, s2, s2, s2], axis=1)

---->   pandas.Series

--------------------------------------
ID: 1977 --> 1
In [19]: s3 = pd.Series([0, 1, 2, 3], name="foo")

In [20]: s4 = pd.Series([0, 1, 2, 3])

In [21]: s5 = pd.Series([0, 1, 4, 5])

In [22]: pd.concat([s3, s4, s5], axis=1)
Out[22]: 
   foo  0  1
0    0  0  0
1    1  1  1
2    2  2  4
3    3  3  5

---->   pandas.Series

--------------------------------------
ID: 1985 --> 2
In [31]: s2 = pd.Series(["X0", "X1", "X2", "X3"], index=["A", "B", "C", "D"])

In [32]: result = pd.concat([df1, s2.to_frame().T], ignore_index=True)

---->   pandas.Series; Series.to_frame

--------------------------------------
ID: 1987 --> 1
In [33]: left = pd.DataFrame(
   ....:     {
   ....:         "key": ["K0", "K1", "K2", "K3"],
   ....:         "A": ["A0", "A1", "A2", "A3"],
   ....:         "B": ["B0", "B1", "B2", "B3"],
   ....:     }
   ....: )
   ....: 

In [34]: right = pd.DataFrame(
   ....:     {
   ....:         "key": ["K0", "K1", "K2", "K3"],
   ....:         "C": ["C0", "C1", "C2", "C3"],
   ....:         "D": ["D0", "D1", "D2", "D3"],
   ....:     }
   ....: )
   ....: 

In [35]: result = pd.merge(left, right, on="key")

---->   pandas.DataFrame

--------------------------------------
ID: 1988 --> 1
In [36]: left = pd.DataFrame(
   ....:     {
   ....:         "key1": ["K0", "K0", "K1", "K2"],
   ....:         "key2": ["K0", "K1", "K0", "K1"],
   ....:         "A": ["A0", "A1", "A2", "A3"],
   ....:         "B": ["B0", "B1", "B2", "B3"],
   ....:     }
   ....: )
   ....: 

In [37]: right = pd.DataFrame(
   ....:     {
   ....:         "key1": ["K0", "K1", "K1", "K2"],
   ....:         "key2": ["K0", "K0", "K0", "K0"],
   ....:         "C": ["C0", "C1", "C2", "C3"],
   ....:         "D": ["D0", "D1", "D2", "D3"],
   ....:     }
   ....: )
   ....: 

In [38]: result = pd.merge(left, right, on=["key1", "key2"])

---->   pandas.DataFrame

--------------------------------------
ID: 1994 --> 3
In [44]: df = pd.DataFrame({"Let": ["A", "B", "C"], "Num": [1, 2, 3]})

In [45]: df
Out[45]: 
  Let  Num
0   A    1
1   B    2
2   C    3

In [46]: ser = pd.Series(
   ....:     ["a", "b", "c", "d", "e", "f"],
   ....:     index=pd.MultiIndex.from_arrays(
   ....:         [["A", "B", "C"] * 2, [1, 2, 3, 4, 5, 6]], names=["Let", "Num"]
   ....:     ),
   ....: )
   ....: 

In [47]: ser
Out[47]: 
Let  Num
A    1      a
B    2      b
C    3      c
A    4      d
B    5      e
C    6      f
dtype: object

In [48]: pd.merge(df, ser.reset_index(), on=["Let", "Num"])
Out[48]: 
  Let  Num  0
0   A    1  a
1   B    2  b
2   C    3  c

---->   pandas.DataFrame; pandas.Series; pandas.MultiIndex

--------------------------------------
ID: 1995 --> 1
In [49]: left = pd.DataFrame({"A": [1, 2], "B": [2, 2]})

In [50]: right = pd.DataFrame({"A": [4, 5, 6], "B": [2, 2, 2]})

In [51]: result = pd.merge(left, right, on="B", how="outer")

---->   pandas.DataFrame

--------------------------------------
ID: 1996 --> 1
In [52]: left = pd.DataFrame({"A": [1, 2], "B": [1, 2]})

In [53]: right = pd.DataFrame({"A": [4, 5, 6], "B": [2, 2, 2]})

---->   pandas.DataFrame

--------------------------------------
ID: 1999 --> 1
In [55]: df1 = pd.DataFrame({"col1": [0, 1], "col_left": ["a", "b"]})

In [56]: df2 = pd.DataFrame({"col1": [1, 2, 2], "col_right": [2, 2, 2]})

In [57]: pd.merge(df1, df2, on="col1", how="outer", indicator=True)
Out[57]: 
   col1 col_left  col_right      _merge
0     0        a        NaN   left_only
1     1        b        2.0        both
2     2      NaN        2.0  right_only
3     2      NaN        2.0  right_only

---->   pandas.DataFrame

--------------------------------------
ID: 2001 --> 1
In [59]: left = pd.DataFrame({"key": [1], "v1": [10]})

In [60]: left
Out[60]: 
   key  v1
0    1  10

In [61]: right = pd.DataFrame({"key": [1, 2], "v1": [20, 30]})

In [62]: right
Out[62]: 
   key  v1
0    1  20
1    2  30

---->   pandas.DataFrame

--------------------------------------
ID: 2004 --> 3
In [67]: from pandas.api.types import CategoricalDtype

In [68]: X = pd.Series(np.random.choice(["foo", "bar"], size=(10,)))

In [69]: X = X.astype(CategoricalDtype(categories=["foo", "bar"]))

In [70]: left = pd.DataFrame(
   ....:     {"X": X, "Y": np.random.choice(["one", "two", "three"], size=(10,))}
   ....: )
   ....: 

In [71]: left
Out[71]: 
     X      Y
0  bar    one
1  foo    one
2  foo  three
3  bar  three
4  foo    one
5  bar    one
6  bar  three
7  bar  three
8  bar  three
9  foo  three

In [72]: left.dtypes
Out[72]: 
X    category
Y      object
dtype: object

---->   pandas.Series; Series.astype; pandas.DataFrame

--------------------------------------
ID: 2005 --> 2
In [73]: right = pd.DataFrame(
   ....:     {
   ....:         "X": pd.Series(["foo", "bar"], dtype=CategoricalDtype(["foo", "bar"])),
   ....:         "Z": [1, 2],
   ....:     }
   ....: )
   ....: 

In [74]: right
Out[74]: 
     X  Z
0  foo  1
1  bar  2

In [75]: right.dtypes
Out[75]: 
X    category
Z       int64
dtype: object

---->   pandas.DataFrame; pandas.Series

--------------------------------------
ID: 2007 --> 2
In [79]: left = pd.DataFrame(
   ....:     {"A": ["A0", "A1", "A2"], "B": ["B0", "B1", "B2"]}, index=["K0", "K1", "K2"]
   ....: )
   ....: 

In [80]: right = pd.DataFrame(
   ....:     {"C": ["C0", "C2", "C3"], "D": ["D0", "D2", "D3"]}, index=["K0", "K2", "K3"]
   ....: )
   ....: 

In [81]: result = left.join(right)

---->   pandas.DataFrame; DataFrame.join

--------------------------------------
ID: 2008 --> 1
In [82]: result = left.join(right, how="outer")

---->   DataFrame.join

--------------------------------------
ID: 2009 --> 1
In [83]: result = left.join(right, how="inner")

---->   DataFrame.join

--------------------------------------
ID: 2012 --> 1
left.join(right, on=key_or_keys)
pd.merge(
    left, right, left_on=key_or_keys, right_index=True, how="left", sort=False
)

---->   DataFrame.join

--------------------------------------
ID: 2013 --> 2
In [86]: left = pd.DataFrame(
   ....:     {
   ....:         "A": ["A0", "A1", "A2", "A3"],
   ....:         "B": ["B0", "B1", "B2", "B3"],
   ....:         "key": ["K0", "K1", "K0", "K1"],
   ....:     }
   ....: )
   ....: 

In [87]: right = pd.DataFrame({"C": ["C0", "C1"], "D": ["D0", "D1"]}, index=["K0", "K1"])

In [88]: result = left.join(right, on="key")

---->   pandas.DataFrame; DataFrame.join

--------------------------------------
ID: 2015 --> 2
In [90]: left = pd.DataFrame(
   ....:     {
   ....:         "A": ["A0", "A1", "A2", "A3"],
   ....:         "B": ["B0", "B1", "B2", "B3"],
   ....:         "key1": ["K0", "K0", "K1", "K2"],
   ....:         "key2": ["K0", "K1", "K0", "K1"],
   ....:     }
   ....: )
   ....: 

In [91]: index = pd.MultiIndex.from_tuples(
   ....:     [("K0", "K0"), ("K1", "K0"), ("K2", "K0"), ("K2", "K1")]
   ....: )
   ....: 

In [92]: right = pd.DataFrame(
   ....:     {"C": ["C0", "C1", "C2", "C3"], "D": ["D0", "D1", "D2", "D3"]}, index=index
   ....: )
   ....: 

---->   pandas.DataFrame; pandas.MultiIndex

--------------------------------------
ID: 2016 --> 1
In [93]: result = left.join(right, on=["key1", "key2"])

---->   DataFrame.join

--------------------------------------
ID: 2017 --> 1
In [94]: result = left.join(right, on=["key1", "key2"], how="inner")

---->   DataFrame.join

--------------------------------------
ID: 2018 --> 4
In [95]: left = pd.DataFrame(
   ....:     {"A": ["A0", "A1", "A2"], "B": ["B0", "B1", "B2"]},
   ....:     index=pd.Index(["K0", "K1", "K2"], name="key"),
   ....: )
   ....: 

In [96]: index = pd.MultiIndex.from_tuples(
   ....:     [("K0", "Y0"), ("K1", "Y1"), ("K2", "Y2"), ("K2", "Y3")],
   ....:     names=["key", "Y"],
   ....: )
   ....: 

In [97]: right = pd.DataFrame(
   ....:     {"C": ["C0", "C1", "C2", "C3"], "D": ["D0", "D1", "D2", "D3"]},
   ....:     index=index,
   ....: )
   ....: 

In [98]: result = left.join(right, how="inner")

---->   pandas.DataFrame; pandas.Index; pandas.MultiIndex; DataFrame.join

--------------------------------------
ID: 2020 --> 3
In [100]: leftindex = pd.MultiIndex.from_product(
   .....:     [list("abc"), list("xy"), [1, 2]], names=["abc", "xy", "num"]
   .....: )
   .....: 

In [101]: left = pd.DataFrame({"v1": range(12)}, index=leftindex)

In [102]: left
Out[102]: 
            v1
abc xy num    
a   x  1     0
       2     1
    y  1     2
       2     3
b   x  1     4
       2     5
    y  1     6
       2     7
c   x  1     8
       2     9
    y  1    10
       2    11

In [103]: rightindex = pd.MultiIndex.from_product(
   .....:     [list("abc"), list("xy")], names=["abc", "xy"]
   .....: )
   .....: 

In [104]: right = pd.DataFrame({"v2": [100 * i for i in range(1, 7)]}, index=rightindex)

In [105]: right
Out[105]: 
         v2
abc xy     
a   x   100
    y   200
b   x   300
    y   400
c   x   500
    y   600

In [106]: left.join(right, on=["abc", "xy"], how="inner")
Out[106]: 
            v1   v2
abc xy num         
a   x  1     0  100
       2     1  100
    y  1     2  200
       2     3  200
b   x  1     4  300
       2     5  300
    y  1     6  400
       2     7  400
c   x  1     8  500
       2     9  500
    y  1    10  600
       2    11  600

---->   pandas.MultiIndex; pandas.DataFrame; DataFrame.join

--------------------------------------
ID: 2021 --> 2
In [107]: leftindex = pd.MultiIndex.from_tuples(
   .....:     [("K0", "X0"), ("K0", "X1"), ("K1", "X2")], names=["key", "X"]
   .....: )
   .....: 

In [108]: left = pd.DataFrame(
   .....:     {"A": ["A0", "A1", "A2"], "B": ["B0", "B1", "B2"]}, index=leftindex
   .....: )
   .....: 

In [109]: rightindex = pd.MultiIndex.from_tuples(
   .....:     [("K0", "Y0"), ("K1", "Y1"), ("K2", "Y2"), ("K2", "Y3")], names=["key", "Y"]
   .....: )
   .....: 

In [110]: right = pd.DataFrame(
   .....:     {"C": ["C0", "C1", "C2", "C3"], "D": ["D0", "D1", "D2", "D3"]}, index=rightindex
   .....: )
   .....: 

In [111]: result = pd.merge(
   .....:     left.reset_index(), right.reset_index(), on=["key"], how="inner"
   .....: ).set_index(["key", "X", "Y"])
   .....: 

---->   pandas.MultiIndex; pandas.DataFrame

--------------------------------------
ID: 2022 --> 2
In [112]: left_index = pd.Index(["K0", "K0", "K1", "K2"], name="key1")

In [113]: left = pd.DataFrame(
   .....:     {
   .....:         "A": ["A0", "A1", "A2", "A3"],
   .....:         "B": ["B0", "B1", "B2", "B3"],
   .....:         "key2": ["K0", "K1", "K0", "K1"],
   .....:     },
   .....:     index=left_index,
   .....: )
   .....: 

In [114]: right_index = pd.Index(["K0", "K1", "K2", "K2"], name="key1")

In [115]: right = pd.DataFrame(
   .....:     {
   .....:         "C": ["C0", "C1", "C2", "C3"],
   .....:         "D": ["D0", "D1", "D2", "D3"],
   .....:         "key2": ["K0", "K0", "K0", "K1"],
   .....:     },
   .....:     index=right_index,
   .....: )
   .....: 

In [116]: result = left.merge(right, on=["key1", "key2"])

---->   pandas.Index; pandas.DataFrame

--------------------------------------
ID: 2023 --> 1
In [117]: left = pd.DataFrame({"k": ["K0", "K1", "K2"], "v": [1, 2, 3]})

In [118]: right = pd.DataFrame({"k": ["K0", "K0", "K3"], "v": [4, 5, 6]})

In [119]: result = pd.merge(left, right, on="k")

---->   pandas.DataFrame

--------------------------------------
ID: 2025 --> 1
In [121]: left = left.set_index("k")

In [122]: right = right.set_index("k")

In [123]: result = left.join(right, lsuffix="_l", rsuffix="_r")

---->   DataFrame.join

--------------------------------------
ID: 2026 --> 2
In [124]: right2 = pd.DataFrame({"v": [7, 8, 9]}, index=["K1", "K1", "K2"])

In [125]: result = left.join([right, right2])

---->   pandas.DataFrame; DataFrame.join

--------------------------------------
ID: 2027 --> 1
In [126]: df1 = pd.DataFrame(
   .....:     [[np.nan, 3.0, 5.0], [-4.6, np.nan, np.nan], [np.nan, 7.0, np.nan]]
   .....: )
   .....: 

In [127]: df2 = pd.DataFrame([[-42.6, np.nan, -8.2], [-5.0, 1.6, 4]], index=[1, 2])

---->   pandas.DataFrame

--------------------------------------
ID: 2028 --> 1
In [128]: result = df1.combine_first(df2)

---->   DataFrame.combine_first

--------------------------------------
ID: 2029 --> 1
In [129]: df1.update(df2)

---->   DataFrame.update

--------------------------------------
ID: 2030 --> 1
In [130]: left = pd.DataFrame(
   .....:     {"k": ["K0", "K1", "K1", "K2"], "lv": [1, 2, 3, 4], "s": ["a", "b", "c", "d"]}
   .....: )
   .....: 

In [131]: right = pd.DataFrame({"k": ["K1", "K2", "K4"], "rv": [1, 2, 3]})

In [132]: pd.merge_ordered(left, right, fill_method="ffill", left_by="s")
Out[132]: 
     k   lv  s   rv
0   K0  1.0  a  NaN
1   K1  1.0  a  1.0
2   K2  1.0  a  2.0
3   K4  1.0  a  3.0
4   K1  2.0  b  1.0
5   K2  2.0  b  2.0
6   K4  2.0  b  3.0
7   K1  3.0  c  1.0
8   K2  3.0  c  2.0
9   K4  3.0  c  3.0
10  K1  NaN  d  1.0
11  K2  4.0  d  2.0
12  K4  4.0  d  3.0

---->   pandas.DataFrame

--------------------------------------
ID: 2031 --> 2
In [133]: trades = pd.DataFrame(
   .....:     {
   .....:         "time": pd.to_datetime(
   .....:             [
   .....:                 "20160525 13:30:00.023",
   .....:                 "20160525 13:30:00.038",
   .....:                 "20160525 13:30:00.048",
   .....:                 "20160525 13:30:00.048",
   .....:                 "20160525 13:30:00.048",
   .....:             ]
   .....:         ),
   .....:         "ticker": ["MSFT", "MSFT", "GOOG", "GOOG", "AAPL"],
   .....:         "price": [51.95, 51.95, 720.77, 720.92, 98.00],
   .....:         "quantity": [75, 155, 100, 100, 100],
   .....:     },
   .....:     columns=["time", "ticker", "price", "quantity"],
   .....: )
   .....: 

In [134]: quotes = pd.DataFrame(
   .....:     {
   .....:         "time": pd.to_datetime(
   .....:             [
   .....:                 "20160525 13:30:00.023",
   .....:                 "20160525 13:30:00.023",
   .....:                 "20160525 13:30:00.030",
   .....:                 "20160525 13:30:00.041",
   .....:                 "20160525 13:30:00.048",
   .....:                 "20160525 13:30:00.049",
   .....:                 "20160525 13:30:00.072",
   .....:                 "20160525 13:30:00.075",
   .....:             ]
   .....:         ),
   .....:         "ticker": ["GOOG", "MSFT", "MSFT", "MSFT", "GOOG", "AAPL", "GOOG", "MSFT"],
   .....:         "bid": [720.50, 51.95, 51.97, 51.99, 720.50, 97.99, 720.50, 52.01],
   .....:         "ask": [720.93, 51.96, 51.98, 52.00, 720.93, 98.01, 720.88, 52.03],
   .....:     },
   .....:     columns=["time", "ticker", "bid", "ask"],
   .....: )
   .....: 

---->   pandas.DataFrame; pandas.to_datetime

--------------------------------------
ID: 2035 --> 1
In [140]: df = pd.DataFrame(
   .....:     {
   .....:         "col1": ["a", "a", "b", "b", "a"],
   .....:         "col2": [1.0, 2.0, 3.0, np.nan, 5.0],
   .....:         "col3": [1.0, 2.0, 3.0, 4.0, 5.0],
   .....:     },
   .....:     columns=["col1", "col2", "col3"],
   .....: )
   .....: 

In [141]: df
Out[141]: 
  col1  col2  col3
0    a   1.0   1.0
1    a   2.0   2.0
2    b   3.0   3.0
3    b   NaN   4.0
4    a   5.0   5.0

---->   pandas.DataFrame

--------------------------------------
ID: 2036 --> 1
In [142]: df2 = df.copy()

In [143]: df2.loc[0, "col1"] = "c"

In [144]: df2.loc[2, "col3"] = 4.0

In [145]: df2
Out[145]: 
  col1  col2  col3
0    c   1.0   1.0
1    a   2.0   2.0
2    b   3.0   4.0
3    b   NaN   4.0
4    a   5.0   5.0

---->   DataFrame.copy

--------------------------------------
ID: 2041 --> 1
In [1]: df = pd.DataFrame(
   ...:     {"AAA": [4, 5, 6, 7], "BBB": [10, 20, 30, 40], "CCC": [100, 50, -30, -50]}
   ...: )
   ...: 

In [2]: df
Out[2]: 
   AAA  BBB  CCC
0    4   10  100
1    5   20   50
2    6   30  -30
3    7   40  -50

---->   pandas.DataFrame

--------------------------------------
ID: 2042 --> 1
In [9]: df_mask = pd.DataFrame(
   ...:     {"AAA": [True] * 4, "BBB": [False] * 4, "CCC": [True, False] * 2}
   ...: )
   ...: 

In [10]: df.where(df_mask, -1000)
Out[10]: 
   AAA   BBB   CCC
0    4 -1000  2000
1    5 -1000 -1000
2    6 -1000   555
3    7 -1000 -1000

---->   pandas.DataFrame

--------------------------------------
ID: 2043 --> 1
In [11]: df = pd.DataFrame(
   ....:     {"AAA": [4, 5, 6, 7], "BBB": [10, 20, 30, 40], "CCC": [100, 50, -30, -50]}
   ....: )
   ....: 

In [12]: df
Out[12]: 
   AAA  BBB  CCC
0    4   10  100
1    5   20   50
2    6   30  -30
3    7   40  -50

In [13]: df["logic"] = np.where(df["AAA"] > 5, "high", "low")

In [14]: df
Out[14]: 
   AAA  BBB  CCC logic
0    4   10  100   low
1    5   20   50   low
2    6   30  -30  high
3    7   40  -50  high

---->   pandas.DataFrame

--------------------------------------
ID: 2044 --> 1
In [15]: df = pd.DataFrame(
   ....:     {"AAA": [4, 5, 6, 7], "BBB": [10, 20, 30, 40], "CCC": [100, 50, -30, -50]}
   ....: )
   ....: 

In [16]: df
Out[16]: 
   AAA  BBB  CCC
0    4   10  100
1    5   20   50
2    6   30  -30
3    7   40  -50

In [17]: df[df.AAA <= 5]
Out[17]: 
   AAA  BBB  CCC
0    4   10  100
1    5   20   50

In [18]: df[df.AAA > 5]
Out[18]: 
   AAA  BBB  CCC
2    6   30  -30
3    7   40  -50

---->   pandas.DataFrame

--------------------------------------
ID: 2045 --> 1
In [19]: df = pd.DataFrame(
   ....:     {"AAA": [4, 5, 6, 7], "BBB": [10, 20, 30, 40], "CCC": [100, 50, -30, -50]}
   ....: )
   ....: 

In [20]: df
Out[20]: 
   AAA  BBB  CCC
0    4   10  100
1    5   20   50
2    6   30  -30
3    7   40  -50

---->   pandas.DataFrame

--------------------------------------
ID: 2049 --> 1
In [25]: df = pd.DataFrame(
   ....:     {"AAA": [4, 5, 6, 7], "BBB": [10, 20, 30, 40], "CCC": [100, 50, -30, -50]}
   ....: )
   ....: 

In [26]: df
Out[26]: 
   AAA  BBB  CCC
0    4   10  100
1    5   20   50
2    6   30  -30
3    7   40  -50

In [27]: aValue = 43.0

In [28]: df.loc[(df.CCC - aValue).abs().argsort()]
Out[28]: 
   AAA  BBB  CCC
1    5   20   50
0    4   10  100
2    6   30  -30
3    7   40  -50

---->   pandas.DataFrame

--------------------------------------
ID: 2050 --> 1
In [29]: df = pd.DataFrame(
   ....:     {"AAA": [4, 5, 6, 7], "BBB": [10, 20, 30, 40], "CCC": [100, 50, -30, -50]}
   ....: )
   ....: 

In [30]: df
Out[30]: 
   AAA  BBB  CCC
0    4   10  100
1    5   20   50
2    6   30  -30
3    7   40  -50

In [31]: Crit1 = df.AAA <= 5.5

In [32]: Crit2 = df.BBB == 10.0

In [33]: Crit3 = df.CCC > -40.0

---->   pandas.DataFrame

--------------------------------------
ID: 2052 --> 1
In [39]: df = pd.DataFrame(
   ....:     {"AAA": [4, 5, 6, 7], "BBB": [10, 20, 30, 40], "CCC": [100, 50, -30, -50]}
   ....: )
   ....: 

In [40]: df
Out[40]: 
   AAA  BBB  CCC
0    4   10  100
1    5   20   50
2    6   30  -30
3    7   40  -50

In [41]: df[(df.AAA <= 6) & (df.index.isin([0, 2, 4]))]
Out[41]: 
   AAA  BBB  CCC
0    4   10  100
2    6   30  -30

---->   pandas.DataFrame

--------------------------------------
ID: 2053 --> 1
In [42]: df = pd.DataFrame(
   ....:     {"AAA": [4, 5, 6, 7], "BBB": [10, 20, 30, 40], "CCC": [100, 50, -30, -50]},
   ....:     index=["foo", "bar", "boo", "kar"],
   ....: )
   ....: 

---->   pandas.DataFrame

--------------------------------------
ID: 2054 --> 1
In [46]: data = {"AAA": [4, 5, 6, 7], "BBB": [10, 20, 30, 40], "CCC": [100, 50, -30, -50]}

In [47]: df2 = pd.DataFrame(data=data, index=[1, 2, 3, 4])  # Note index starts at 1.

In [48]: df2.iloc[1:3]  # Position-oriented
Out[48]: 
   AAA  BBB  CCC
2    5   20   50
3    6   30  -30

In [49]: df2.loc[1:3]  # Label-oriented
Out[49]: 
   AAA  BBB  CCC
1    4   10  100
2    5   20   50
3    6   30  -30

---->   pandas.DataFrame

--------------------------------------
ID: 2055 --> 1
In [50]: df = pd.DataFrame(
   ....:     {"AAA": [4, 5, 6, 7], "BBB": [10, 20, 30, 40], "CCC": [100, 50, -30, -50]}
   ....: )
   ....: 

In [51]: df
Out[51]: 
   AAA  BBB  CCC
0    4   10  100
1    5   20   50
2    6   30  -30
3    7   40  -50

In [52]: df[~((df.AAA <= 6) & (df.index.isin([0, 2, 4])))]
Out[52]: 
   AAA  BBB  CCC
1    5   20   50
3    7   40  -50

---->   pandas.DataFrame

--------------------------------------
ID: 2056 --> 1
In [53]: df = pd.DataFrame({"AAA": [1, 2, 1, 3], "BBB": [1, 1, 2, 2], "CCC": [2, 1, 3, 1]})

In [54]: df
Out[54]: 
   AAA  BBB  CCC
0    1    1    2
1    2    1    1
2    1    2    3
3    3    2    1

In [55]: source_cols = df.columns  # Or some subset would work too

In [56]: new_cols = [str(x) + "_cat" for x in source_cols]

In [57]: categories = {1: "Alpha", 2: "Beta", 3: "Charlie"}

In [58]: df[new_cols] = df[source_cols].applymap(categories.get)

In [59]: df
Out[59]: 
   AAA  BBB  CCC  AAA_cat BBB_cat  CCC_cat
0    1    1    2    Alpha   Alpha     Beta
1    2    1    1     Beta   Alpha    Alpha
2    1    2    3    Alpha    Beta  Charlie
3    3    2    1  Charlie    Beta    Alpha

---->   pandas.DataFrame

--------------------------------------
ID: 2057 --> 1
In [60]: df = pd.DataFrame(
   ....:     {"AAA": [1, 1, 1, 2, 2, 2, 3, 3], "BBB": [2, 1, 3, 4, 5, 1, 2, 3]}
   ....: )
   ....: 

In [61]: df
Out[61]: 
   AAA  BBB
0    1    2
1    1    1
2    1    3
3    2    4
4    2    5
5    2    1
6    3    2
7    3    3

---->   pandas.DataFrame

--------------------------------------
ID: 2058 --> 1
In [62]: df.loc[df.groupby("AAA")["BBB"].idxmin()]
Out[62]: 
   AAA  BBB
1    1    1
5    2    1
6    3    2

---->   DataFrame.groupby

--------------------------------------
ID: 2060 --> 3
In [64]: df = pd.DataFrame(
   ....:     {
   ....:         "row": [0, 1, 2],
   ....:         "One_X": [1.1, 1.1, 1.1],
   ....:         "One_Y": [1.2, 1.2, 1.2],
   ....:         "Two_X": [1.11, 1.11, 1.11],
   ....:         "Two_Y": [1.22, 1.22, 1.22],
   ....:     }
   ....: )
   ....: 

In [65]: df
Out[65]: 
   row  One_X  One_Y  Two_X  Two_Y
0    0    1.1    1.2   1.11   1.22
1    1    1.1    1.2   1.11   1.22
2    2    1.1    1.2   1.11   1.22

# As Labelled Index
In [66]: df = df.set_index("row")

In [67]: df
Out[67]: 
     One_X  One_Y  Two_X  Two_Y
row                            
0      1.1    1.2   1.11   1.22
1      1.1    1.2   1.11   1.22
2      1.1    1.2   1.11   1.22

# With Hierarchical Columns
In [68]: df.columns = pd.MultiIndex.from_tuples([tuple(c.split("_")) for c in df.columns])

In [69]: df
Out[69]: 
     One        Two      
       X    Y     X     Y
row                      
0    1.1  1.2  1.11  1.22
1    1.1  1.2  1.11  1.22
2    1.1  1.2  1.11  1.22

# Now stack & Reset
In [70]: df = df.stack(0).reset_index(1)

In [71]: df
Out[71]: 
    level_1     X     Y
row                    
0       One  1.10  1.20
0       Two  1.11  1.22
1       One  1.10  1.20
1       Two  1.11  1.22
2       One  1.10  1.20
2       Two  1.11  1.22

# And fix the labels (Notice the label 'level_1' got added automatically)
In [72]: df.columns = ["Sample", "All_X", "All_Y"]

In [73]: df
Out[73]: 
    Sample  All_X  All_Y
row                     
0      One   1.10   1.20
0      Two   1.11   1.22
1      One   1.10   1.20
1      Two   1.11   1.22
2      One   1.10   1.20
2      Two   1.11   1.22

---->   pandas.DataFrame; pandas.MultiIndex; DataFrame.stack

--------------------------------------
ID: 2061 --> 3
In [74]: cols = pd.MultiIndex.from_tuples(
   ....:     [(x, y) for x in ["A", "B", "C"] for y in ["O", "I"]]
   ....: )
   ....: 

In [75]: df = pd.DataFrame(np.random.randn(2, 6), index=["n", "m"], columns=cols)

In [76]: df
Out[76]: 
          A                   B                   C          
          O         I         O         I         O         I
n  0.469112 -0.282863 -1.509059 -1.135632  1.212112 -0.173215
m  0.119209 -1.044236 -0.861849 -2.104569 -0.494929  1.071804

In [77]: df = df.div(df["C"], level=1)

In [78]: df
Out[78]: 
          A                   B              C     
          O         I         O         I    O    I
n  0.387021  1.633022 -1.244983  6.556214  1.0  1.0
m -0.240860 -0.974279  1.741358 -1.963577  1.0  1.0

---->   pandas.MultiIndex; pandas.DataFrame; DataFrame.div

--------------------------------------
ID: 2062 --> 2
In [79]: coords = [("AA", "one"), ("AA", "six"), ("BB", "one"), ("BB", "two"), ("BB", "six")]

In [80]: index = pd.MultiIndex.from_tuples(coords)

In [81]: df = pd.DataFrame([11, 22, 33, 44, 55], index, ["MyData"])

In [82]: df
Out[82]: 
        MyData
AA one      11
   six      22
BB one      33
   two      44
   six      55

---->   pandas.MultiIndex; pandas.DataFrame

--------------------------------------
ID: 2063 --> 1
# Note : level and axis are optional, and default to zero
In [83]: df.xs("BB", level=0, axis=0)
Out[83]: 
     MyData
one      33
two      44
six      55

---->   DataFrame.xs

--------------------------------------
ID: 2064 --> 1
In [84]: df.xs("six", level=1, axis=0)
Out[84]: 
    MyData
AA      22
BB      55

---->   DataFrame.xs

--------------------------------------
ID: 2065 --> 2
In [85]: import itertools

In [86]: index = list(itertools.product(["Ada", "Quinn", "Violet"], ["Comp", "Math", "Sci"]))

In [87]: headr = list(itertools.product(["Exams", "Labs"], ["I", "II"]))

In [88]: indx = pd.MultiIndex.from_tuples(index, names=["Student", "Course"])

In [89]: cols = pd.MultiIndex.from_tuples(headr)  # Notice these are un-named

In [90]: data = [[70 + x + y + (x * y) % 3 for x in range(4)] for y in range(9)]

In [91]: df = pd.DataFrame(data, indx, cols)

In [92]: df
Out[92]: 
               Exams     Labs    
                   I  II    I  II
Student Course                   
Ada     Comp      70  71   72  73
        Math      71  73   75  74
        Sci       72  75   75  75
Quinn   Comp      73  74   75  76
        Math      74  76   78  77
        Sci       75  78   78  78
Violet  Comp      76  77   78  79
        Math      77  79   81  80
        Sci       78  81   81  81

In [93]: All = slice(None)

In [94]: df.loc["Violet"]
Out[94]: 
       Exams     Labs    
           I  II    I  II
Course                   
Comp      76  77   78  79
Math      77  79   81  80
Sci       78  81   81  81

In [95]: df.loc[(All, "Math"), All]
Out[95]: 
               Exams     Labs    
                   I  II    I  II
Student Course                   
Ada     Math      71  73   75  74
Quinn   Math      74  76   78  77
Violet  Math      77  79   81  80

In [96]: df.loc[(slice("Ada", "Quinn"), "Math"), All]
Out[96]: 
               Exams     Labs    
                   I  II    I  II
Student Course                   
Ada     Math      71  73   75  74
Quinn   Math      74  76   78  77

In [97]: df.loc[(All, "Math"), ("Exams")]
Out[97]: 
                 I  II
Student Course        
Ada     Math    71  73
Quinn   Math    74  76
Violet  Math    77  79

In [98]: df.loc[(All, "Math"), (All, "II")]
Out[98]: 
               Exams Labs
                  II   II
Student Course           
Ada     Math      73   74
Quinn   Math      76   77
Violet  Math      79   80

---->   pandas.MultiIndex; pandas.DataFrame

--------------------------------------
ID: 2067 --> 1
In [100]: df = pd.DataFrame(
   .....:     np.random.randn(6, 1),
   .....:     index=pd.date_range("2013-08-01", periods=6, freq="B"),
   .....:     columns=list("A"),
   .....: )
   .....: 

In [101]: df.loc[df.index[3], "A"] = np.nan

In [102]: df
Out[102]: 
                   A
2013-08-01  0.721555
2013-08-02 -0.706771
2013-08-05 -1.039575
2013-08-06       NaN
2013-08-07 -0.424972
2013-08-08  0.567020

In [103]: df.bfill()
Out[103]: 
                   A
2013-08-01  0.721555
2013-08-02 -0.706771
2013-08-05 -1.039575
2013-08-06 -0.424972
2013-08-07 -0.424972
2013-08-08  0.567020

---->   pandas.DataFrame

--------------------------------------
ID: 2068 --> 2
In [104]: df = pd.DataFrame(
   .....:     {
   .....:         "animal": "cat dog cat fish dog cat cat".split(),
   .....:         "size": list("SSMMMLL"),
   .....:         "weight": [8, 10, 11, 1, 20, 12, 12],
   .....:         "adult": [False] * 5 + [True] * 2,
   .....:     }
   .....: )
   .....: 

In [105]: df
Out[105]: 
  animal size  weight  adult
0    cat    S       8  False
1    dog    S      10  False
2    cat    M      11  False
3   fish    M       1  False
4    dog    M      20  False
5    cat    L      12   True
6    cat    L      12   True

# List the size of the animals with the highest weight.
In [106]: df.groupby("animal").apply(lambda subf: subf["size"][subf["weight"].idxmax()])
Out[106]: 
animal
cat     L
dog     M
fish    M
dtype: object

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 2069 --> 1
In [107]: gb = df.groupby(["animal"])

In [108]: gb.get_group("cat")
Out[108]: 
  animal size  weight  adult
0    cat    S       8  False
2    cat    M      11  False
5    cat    L      12   True
6    cat    L      12   True

---->   DataFrame.groupby

--------------------------------------
ID: 2070 --> 1
In [109]: def GrowUp(x):
   .....:     avg_weight = sum(x[x["size"] == "S"].weight * 1.5)
   .....:     avg_weight += sum(x[x["size"] == "M"].weight * 1.25)
   .....:     avg_weight += sum(x[x["size"] == "L"].weight)
   .....:     avg_weight /= len(x)
   .....:     return pd.Series(["L", avg_weight, True], index=["size", "weight", "adult"])
   .....: 

In [110]: expected_df = gb.apply(GrowUp)

In [111]: expected_df
Out[111]: 
       size   weight  adult
animal                     
cat       L  12.4375   True
dog       L  20.0000   True
fish      L   1.2500   True

---->   pandas.Series

--------------------------------------
ID: 2071 --> 2
In [112]: S = pd.Series([i / 100.0 for i in range(1, 11)])

In [113]: def cum_ret(x, y):
   .....:     return x * (1 + y)
   .....: 

In [114]: def red(x):
   .....:     return functools.reduce(cum_ret, x, 1.0)
   .....: 

In [115]: S.expanding().apply(red, raw=True)
Out[115]: 
0    1.010000
1    1.030200
2    1.061106
3    1.103550
4    1.158728
5    1.228251
6    1.314229
7    1.419367
8    1.547110
9    1.701821
dtype: float64

---->   pandas.Series; Series.expanding

--------------------------------------
ID: 2072 --> 2
In [116]: df = pd.DataFrame({"A": [1, 1, 2, 2], "B": [1, -1, 1, 2]})

In [117]: gb = df.groupby("A")

In [118]: def replace(g):
   .....:     mask = g < 0
   .....:     return g.where(~mask, g[~mask].mean())
   .....: 

In [119]: gb.transform(replace)
Out[119]: 
   B
0  1
1  1
2  1
3  2

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 2073 --> 2
In [120]: df = pd.DataFrame(
   .....:     {
   .....:         "code": ["foo", "bar", "baz"] * 2,
   .....:         "data": [0.16, -0.21, 0.33, 0.45, -0.59, 0.62],
   .....:         "flag": [False, True] * 3,
   .....:     }
   .....: )
   .....: 

In [121]: code_groups = df.groupby("code")

In [122]: agg_n_sort_order = code_groups[["data"]].transform(sum).sort_values(by="data")

In [123]: sorted_df = df.loc[agg_n_sort_order.index]

In [124]: sorted_df
Out[124]: 
  code  data   flag
1  bar -0.21   True
4  bar -0.59  False
0  foo  0.16  False
3  foo  0.45   True
2  baz  0.33  False
5  baz  0.62   True

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 2074 --> 2
In [125]: rng = pd.date_range(start="2014-10-07", periods=10, freq="2min")

In [126]: ts = pd.Series(data=list(range(10)), index=rng)

In [127]: def MyCust(x):
   .....:     if len(x) > 2:
   .....:         return x[1] * 1.234
   .....:     return pd.NaT
   .....: 

In [128]: mhc = {"Mean": np.mean, "Max": np.max, "Custom": MyCust}

In [129]: ts.resample("5min").apply(mhc)
Out[129]: 
                     Mean  Max Custom
2014-10-07 00:00:00   1.0    2  1.234
2014-10-07 00:05:00   3.5    4    NaT
2014-10-07 00:10:00   6.0    7  7.404
2014-10-07 00:15:00   8.5    9    NaT

In [130]: ts
Out[130]: 
2014-10-07 00:00:00    0
2014-10-07 00:02:00    1
2014-10-07 00:04:00    2
2014-10-07 00:06:00    3
2014-10-07 00:08:00    4
2014-10-07 00:10:00    5
2014-10-07 00:12:00    6
2014-10-07 00:14:00    7
2014-10-07 00:16:00    8
2014-10-07 00:18:00    9
Freq: 2T, dtype: int64

---->   pandas.Series; Series.resample

--------------------------------------
ID: 2075 --> 2
In [131]: df = pd.DataFrame(
   .....:     {"Color": "Red Red Red Blue".split(), "Value": [100, 150, 50, 50]}
   .....: )
   .....: 

In [132]: df
Out[132]: 
  Color  Value
0   Red    100
1   Red    150
2   Red     50
3  Blue     50

In [133]: df["Counts"] = df.groupby(["Color"]).transform(len)

In [134]: df
Out[134]: 
  Color  Value  Counts
0   Red    100       3
1   Red    150       3
2   Red     50       3
3  Blue     50       1

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 2076 --> 2
In [135]: df = pd.DataFrame(
   .....:     {"line_race": [10, 10, 8, 10, 10, 8], "beyer": [99, 102, 103, 103, 88, 100]},
   .....:     index=[
   .....:         "Last Gunfighter",
   .....:         "Last Gunfighter",
   .....:         "Last Gunfighter",
   .....:         "Paynter",
   .....:         "Paynter",
   .....:         "Paynter",
   .....:     ],
   .....: )
   .....: 

In [136]: df
Out[136]: 
                 line_race  beyer
Last Gunfighter         10     99
Last Gunfighter         10    102
Last Gunfighter          8    103
Paynter                 10    103
Paynter                 10     88
Paynter                  8    100

In [137]: df["beyer_shifted"] = df.groupby(level=0)["beyer"].shift(1)

In [138]: df
Out[138]: 
                 line_race  beyer  beyer_shifted
Last Gunfighter         10     99            NaN
Last Gunfighter         10    102           99.0
Last Gunfighter          8    103          102.0
Paynter                 10    103            NaN
Paynter                 10     88          103.0
Paynter                  8    100           88.0

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 2077 --> 2
In [139]: df = pd.DataFrame(
   .....:     {
   .....:         "host": ["other", "other", "that", "this", "this"],
   .....:         "service": ["mail", "web", "mail", "mail", "web"],
   .....:         "no": [1, 2, 1, 2, 1],
   .....:     }
   .....: ).set_index(["host", "service"])
   .....: 

In [140]: mask = df.groupby(level=0).agg("idxmax")

In [141]: df_count = df.loc[mask["no"]].reset_index()

In [142]: df_count
Out[142]: 
    host service  no
0  other     web   2
1   that    mail   1
2   this    mail   2

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 2078 --> 1
In [143]: df = pd.DataFrame([0, 1, 0, 1, 1, 1, 0, 1, 1], columns=["A"])

In [144]: df["A"].groupby((df["A"] != df["A"].shift()).cumsum()).groups
Out[144]: {1: [0], 2: [1], 3: [2], 4: [3, 4, 5], 5: [6], 6: [7, 8]}

In [145]: df["A"].groupby((df["A"] != df["A"].shift()).cumsum()).cumsum()
Out[145]: 
0    0
1    1
2    0
3    1
4    2
5    3
6    0
7    1
8    2
Name: A, dtype: int64

---->   pandas.DataFrame

--------------------------------------
ID: 2079 --> 2
In [146]: df = pd.DataFrame(
   .....:     data={
   .....:         "Case": ["A", "A", "A", "B", "A", "A", "B", "A", "A"],
   .....:         "Data": np.random.randn(9),
   .....:     }
   .....: )
   .....: 

In [147]: dfs = list(
   .....:     zip(
   .....:         *df.groupby(
   .....:             (1 * (df["Case"] == "B"))
   .....:             .cumsum()
   .....:             .rolling(window=3, min_periods=1)
   .....:             .median()
   .....:         )
   .....:     )
   .....: )[-1]
   .....: 

In [148]: dfs[0]
Out[148]: 
  Case      Data
0    A  0.276232
1    A -1.087401
2    A -0.673690
3    B  0.113648

In [149]: dfs[1]
Out[149]: 
  Case      Data
4    A -1.478427
5    A  0.524988
6    B  0.404705

In [150]: dfs[2]
Out[150]: 
  Case      Data
7    A  0.577046
8    A -1.715002

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 2080 --> 2
In [151]: df = pd.DataFrame(
   .....:     data={
   .....:         "Province": ["ON", "QC", "BC", "AL", "AL", "MN", "ON"],
   .....:         "City": [
   .....:             "Toronto",
   .....:             "Montreal",
   .....:             "Vancouver",
   .....:             "Calgary",
   .....:             "Edmonton",
   .....:             "Winnipeg",
   .....:             "Windsor",
   .....:         ],
   .....:         "Sales": [13, 6, 16, 8, 4, 3, 1],
   .....:     }
   .....: )
   .....: 

In [152]: table = pd.pivot_table(
   .....:     df,
   .....:     values=["Sales"],
   .....:     index=["Province"],
   .....:     columns=["City"],
   .....:     aggfunc=np.sum,
   .....:     margins=True,
   .....: )
   .....: 

In [153]: table.stack("City")
Out[153]: 
                    Sales
Province City            
AL       All         12.0
         Calgary      8.0
         Edmonton     4.0
BC       All         16.0
         Vancouver   16.0
...                   ...
All      Montreal     6.0
         Toronto     13.0
         Vancouver   16.0
         Windsor      1.0
         Winnipeg     3.0

[20 rows x 1 columns]

---->   pandas.DataFrame; pandas.pivot_table

--------------------------------------
ID: 2081 --> 3
In [154]: grades = [48, 99, 75, 80, 42, 80, 72, 68, 36, 78]

In [155]: df = pd.DataFrame(
   .....:     {
   .....:         "ID": ["x%d" % r for r in range(10)],
   .....:         "Gender": ["F", "M", "F", "M", "F", "M", "F", "M", "M", "M"],
   .....:         "ExamYear": [
   .....:             "2007",
   .....:             "2007",
   .....:             "2007",
   .....:             "2008",
   .....:             "2008",
   .....:             "2008",
   .....:             "2008",
   .....:             "2009",
   .....:             "2009",
   .....:             "2009",
   .....:         ],
   .....:         "Class": [
   .....:             "algebra",
   .....:             "stats",
   .....:             "bio",
   .....:             "algebra",
   .....:             "algebra",
   .....:             "stats",
   .....:             "stats",
   .....:             "algebra",
   .....:             "bio",
   .....:             "bio",
   .....:         ],
   .....:         "Participated": [
   .....:             "yes",
   .....:             "yes",
   .....:             "yes",
   .....:             "yes",
   .....:             "no",
   .....:             "yes",
   .....:             "yes",
   .....:             "yes",
   .....:             "yes",
   .....:             "yes",
   .....:         ],
   .....:         "Passed": ["yes" if x > 50 else "no" for x in grades],
   .....:         "Employed": [
   .....:             True,
   .....:             True,
   .....:             True,
   .....:             False,
   .....:             False,
   .....:             False,
   .....:             False,
   .....:             True,
   .....:             True,
   .....:             False,
   .....:         ],
   .....:         "Grade": grades,
   .....:     }
   .....: )
   .....: 

In [156]: df.groupby("ExamYear").agg(
   .....:     {
   .....:         "Participated": lambda x: x.value_counts()["yes"],
   .....:         "Passed": lambda x: sum(x == "yes"),
   .....:         "Employed": lambda x: sum(x),
   .....:         "Grade": lambda x: sum(x) / len(x),
   .....:     }
   .....: )
   .....: 
Out[156]: 
          Participated  Passed  Employed      Grade
ExamYear                                           
2007                 3       2         3  74.000000
2008                 3       3         0  68.500000
2009                 3       2         2  60.666667

---->   pandas.DataFrame; DataFrame.groupby; Series.value_counts

--------------------------------------
ID: 2082 --> 2
In [157]: df = pd.DataFrame(
   .....:     {"value": np.random.randn(36)},
   .....:     index=pd.date_range("2011-01-01", freq="M", periods=36),
   .....: )
   .....: 

In [158]: pd.pivot_table(
   .....:     df, index=df.index.month, columns=df.index.year, values="value", aggfunc="sum"
   .....: )
   .....: 
Out[158]: 
        2011      2012      2013
1  -1.039268 -0.968914  2.565646
2  -0.370647 -1.294524  1.431256
3  -1.157892  0.413738  1.340309
4  -1.344312  0.276662 -1.170299
5   0.844885 -0.472035 -0.226169
6   1.075770 -0.013960  0.410835
7  -0.109050 -0.362543  0.813850
8   1.643563 -0.006154  0.132003
9  -1.469388 -0.923061 -0.827317
10  0.357021  0.895717 -0.076467
11 -0.674600  0.805244 -1.187678
12 -1.776904 -1.206412  1.130127

---->   pandas.DataFrame; pandas.pivot_table

--------------------------------------
ID: 2083 --> 3
In [159]: df = pd.DataFrame(
   .....:     data={
   .....:         "A": [[2, 4, 8, 16], [100, 200], [10, 20, 30]],
   .....:         "B": [["a", "b", "c"], ["jj", "kk"], ["ccc"]],
   .....:     },
   .....:     index=["I", "II", "III"],
   .....: )
   .....: 

In [160]: def SeriesFromSubList(aList):
   .....:     return pd.Series(aList)
   .....: 

In [161]: df_orgz = pd.concat(
   .....:     {ind: row.apply(SeriesFromSubList) for ind, row in df.iterrows()}
   .....: )
   .....: 

In [162]: df_orgz
Out[162]: 
         0     1     2     3
I   A    2     4     8  16.0
    B    a     b     c   NaN
II  A  100   200   NaN   NaN
    B   jj    kk   NaN   NaN
III A   10  20.0  30.0   NaN
    B  ccc   NaN   NaN   NaN

---->   pandas.DataFrame; pandas.Series; DataFrame.iterrows

--------------------------------------
ID: 2084 --> 2
In [163]: df = pd.DataFrame(
   .....:     data=np.random.randn(2000, 2) / 10000,
   .....:     index=pd.date_range("2001-01-01", periods=2000),
   .....:     columns=["A", "B"],
   .....: )
   .....: 

In [164]: df
Out[164]: 
                   A         B
2001-01-01 -0.000144 -0.000141
2001-01-02  0.000161  0.000102
2001-01-03  0.000057  0.000088
2001-01-04 -0.000221  0.000097
2001-01-05 -0.000201 -0.000041
...              ...       ...
2006-06-19  0.000040 -0.000235
2006-06-20 -0.000123 -0.000021
2006-06-21 -0.000113  0.000114
2006-06-22  0.000136  0.000109
2006-06-23  0.000027  0.000030

[2000 rows x 2 columns]

In [165]: def gm(df, const):
   .....:     v = ((((df["A"] + df["B"]) + 1).cumprod()) - 1) * const
   .....:     return v.iloc[-1]
   .....: 

In [166]: s = pd.Series(
   .....:     {
   .....:         df.index[i]: gm(df.iloc[i: min(i + 51, len(df) - 1)], 5)
   .....:         for i in range(len(df) - 50)
   .....:     }
   .....: )
   .....: 

In [167]: s
Out[167]: 
2001-01-01    0.000930
2001-01-02    0.002615
2001-01-03    0.001281
2001-01-04    0.001117
2001-01-05    0.002772
                ...   
2006-04-30    0.003296
2006-05-01    0.002629
2006-05-02    0.002081
2006-05-03    0.004247
2006-05-04    0.003928
Length: 1950, dtype: float64

---->   pandas.DataFrame; pandas.Series

--------------------------------------
ID: 2085 --> 3
In [168]: rng = pd.date_range(start="2014-01-01", periods=100)

In [169]: df = pd.DataFrame(
   .....:     {
   .....:         "Open": np.random.randn(len(rng)),
   .....:         "Close": np.random.randn(len(rng)),
   .....:         "Volume": np.random.randint(100, 2000, len(rng)),
   .....:     },
   .....:     index=rng,
   .....: )
   .....: 

In [170]: df
Out[170]: 
                Open     Close  Volume
2014-01-01 -1.611353 -0.492885    1219
2014-01-02 -3.000951  0.445794    1054
2014-01-03 -0.138359 -0.076081    1381
2014-01-04  0.301568  1.198259    1253
2014-01-05  0.276381 -0.669831    1728
...              ...       ...     ...
2014-04-06 -0.040338  0.937843    1188
2014-04-07  0.359661 -0.285908    1864
2014-04-08  0.060978  1.714814     941
2014-04-09  1.759055 -0.455942    1065
2014-04-10  0.138185 -1.147008    1453

[100 rows x 3 columns]

In [171]: def vwap(bars):
   .....:     return (bars.Close * bars.Volume).sum() / bars.Volume.sum()
   .....: 

In [172]: window = 5

In [173]: s = pd.concat(
   .....:     [
   .....:         (pd.Series(vwap(df.iloc[i: i + window]), index=[df.index[i + window]]))
   .....:         for i in range(len(df) - window)
   .....:     ]
   .....: )
   .....: 

In [174]: s.round(2)
Out[174]: 
2014-01-06    0.02
2014-01-07    0.11
2014-01-08    0.10
2014-01-09    0.07
2014-01-10   -0.29
              ... 
2014-04-06   -0.63
2014-04-07   -0.02
2014-04-08   -0.03
2014-04-09    0.34
2014-04-10    0.29
Length: 95, dtype: float64

---->   pandas.DataFrame; pandas.Series; Series.round

--------------------------------------
ID: 2087 --> 2
In [177]: rng = pd.date_range("2000-01-01", periods=6)

In [178]: df1 = pd.DataFrame(np.random.randn(6, 3), index=rng, columns=["A", "B", "C"])

In [179]: df2 = df1.copy()

---->   pandas.DataFrame; DataFrame.copy

--------------------------------------
ID: 2089 --> 1
In [182]: df = pd.DataFrame(
   .....:     data={
   .....:         "Area": ["A"] * 5 + ["C"] * 2,
   .....:         "Bins": [110] * 2 + [160] * 3 + [40] * 2,
   .....:         "Test_0": [0, 1, 0, 1, 2, 0, 1],
   .....:         "Data": np.random.randn(7),
   .....:     }
   .....: )
   .....: 

In [183]: df
Out[183]: 
  Area  Bins  Test_0      Data
0    A   110       0 -0.433937
1    A   110       1 -0.160552
2    A   160       0  0.744434
3    A   160       1  1.754213
4    A   160       2  0.000850
5    C    40       0  0.342243
6    C    40       1  1.070599

In [184]: df["Test_1"] = df["Test_0"] - 1

In [185]: pd.merge(
   .....:     df,
   .....:     df,
   .....:     left_on=["Bins", "Area", "Test_0"],
   .....:     right_on=["Bins", "Area", "Test_1"],
   .....:     suffixes=("_L", "_R"),
   .....: )
   .....: 
Out[185]: 
  Area  Bins  Test_0_L    Data_L  Test_1_L  Test_0_R    Data_R  Test_1_R
0    A   110         0 -0.433937        -1         1 -0.160552         0
1    A   160         0  0.744434        -1         1  1.754213         0
2    A   160         1  1.754213         0         2  0.000850         1
3    C    40         0  0.342243        -1         1  1.070599         0

---->   pandas.DataFrame

--------------------------------------
ID: 2090 --> 3
In [186]: df = pd.DataFrame(
   .....:     {
   .....:         "stratifying_var": np.random.uniform(0, 100, 20),
   .....:         "price": np.random.normal(100, 5, 20),
   .....:     }
   .....: )
   .....: 

In [187]: df["quartiles"] = pd.qcut(
   .....:     df["stratifying_var"], 4, labels=["0-25%", "25-50%", "50-75%", "75-100%"]
   .....: )
   .....: 

In [188]: df.boxplot(column="price", by="quartiles")
Out[188]: 

---->   pandas.DataFrame; pandas.qcut; DataFrame.boxplot

--------------------------------------
ID: 2091 --> 2
In [189]: for i in range(3):
   .....:     data = pd.DataFrame(np.random.randn(10, 4))
   .....:     data.to_csv("file_{}.csv".format(i))
   .....: 

In [190]: files = ["file_0.csv", "file_1.csv", "file_2.csv"]

In [191]: result = pd.concat([pd.read_csv(f) for f in files], ignore_index=True)

---->   pandas.DataFrame; Series.to_csv

--------------------------------------
ID: 2093 --> 3
In [196]: i = pd.date_range("20000101", periods=10000)

In [197]: df = pd.DataFrame({"year": i.year, "month": i.month, "day": i.day})

In [198]: df.head()
Out[198]: 
   year  month  day
0  2000      1    1
1  2000      1    2
2  2000      1    3
3  2000      1    4
4  2000      1    5

In [199]: %timeit pd.to_datetime(df.year * 10000 + df.month * 100 + df.day, format='%Y%m%d')
   .....: ds = df.apply(lambda x: "%04d%02d%02d" % (x["year"], x["month"], x["day"]), axis=1)
   .....: ds.head()
   .....: %timeit pd.to_datetime(ds)
   .....: 
5.03 ms +- 39.1 us per loop (mean +- std. dev. of 7 runs, 100 loops each)
2.16 ms +- 19.4 us per loop (mean +- std. dev. of 7 runs, 100 loops each)

---->   pandas.DataFrame; DataFrame.head; pandas.to_datetime

--------------------------------------
ID: 2096 --> 1
In [206]: df = pd.DataFrame(np.random.randn(8, 3))

In [207]: store = pd.HDFStore("test.h5")

In [208]: store.put("df", df)

# you can store an arbitrary Python object via pickle
In [209]: store.get_storer("df").attrs.my_attribute = {"A": 10}

In [210]: store.get_storer("df").attrs.my_attribute
Out[210]: {'A': 10}

---->   pandas.DataFrame

--------------------------------------
ID: 2097 --> 1
In [211]: store = pd.HDFStore("test.h5", "w", driver="H5FD_CORE")

In [212]: df = pd.DataFrame(np.random.randn(8, 3))

In [213]: store["test"] = df

# only after closing the store, data is written to disk:
In [214]: store.close()

---->   pandas.DataFrame

--------------------------------------
ID: 2099 --> 1
names = "count", "avg", "scale"

# note that the offsets are larger than the size of the type because of
# struct padding
offsets = 0, 8, 16
formats = "i4", "f8", "f4"
dt = np.dtype({"names": names, "offsets": offsets, "formats": formats}, align=True)
df = pd.DataFrame(np.fromfile("binary.dat", dt))

---->   pandas.DataFrame

--------------------------------------
ID: 2100 --> 2
In [215]: df = pd.DataFrame(np.random.random(size=(100, 5)))

In [216]: corr_mat = df.corr()

In [217]: mask = np.tril(np.ones_like(corr_mat, dtype=np.bool_), k=-1)

In [218]: corr_mat.where(mask)
Out[218]: 
          0         1         2        3   4
0       NaN       NaN       NaN      NaN NaN
1 -0.079861       NaN       NaN      NaN NaN
2 -0.236573  0.183801       NaN      NaN NaN
3 -0.013795 -0.051975  0.037235      NaN NaN
4 -0.031974  0.118342 -0.073499 -0.02063 NaN

---->   pandas.DataFrame; DataFrame.corr

--------------------------------------
ID: 2101 --> 2
In [219]: def distcorr(x, y):
   .....:     n = len(x)
   .....:     a = np.zeros(shape=(n, n))
   .....:     b = np.zeros(shape=(n, n))
   .....:     for i in range(n):
   .....:         for j in range(i + 1, n):
   .....:             a[i, j] = abs(x[i] - x[j])
   .....:             b[i, j] = abs(y[i] - y[j])
   .....:     a += a.T
   .....:     b += b.T
   .....:     a_bar = np.vstack([np.nanmean(a, axis=0)] * n)
   .....:     b_bar = np.vstack([np.nanmean(b, axis=0)] * n)
   .....:     A = a - a_bar - a_bar.T + np.full(shape=(n, n), fill_value=a_bar.mean())
   .....:     B = b - b_bar - b_bar.T + np.full(shape=(n, n), fill_value=b_bar.mean())
   .....:     cov_ab = np.sqrt(np.nansum(A * B)) / n
   .....:     std_a = np.sqrt(np.sqrt(np.nansum(A ** 2)) / n)
   .....:     std_b = np.sqrt(np.sqrt(np.nansum(B ** 2)) / n)
   .....:     return cov_ab / std_a / std_b
   .....: 

In [220]: df = pd.DataFrame(np.random.normal(size=(100, 3)))

In [221]: df.corr(method=distcorr)
Out[221]: 
          0         1         2
0  1.000000  0.197613  0.216328
1  0.197613  1.000000  0.208749
2  0.216328  0.208749  1.000000

---->   pandas.DataFrame; DataFrame.corr

--------------------------------------
ID: 2102 --> 2
In [222]: import datetime

In [223]: s = pd.Series(pd.date_range("2012-1-1", periods=3, freq="D"))

In [224]: s - s.max()
Out[224]: 
0   -2 days
1   -1 days
2    0 days
dtype: timedelta64[ns]

In [225]: s.max() - s
Out[225]: 
0   2 days
1   1 days
2   0 days
dtype: timedelta64[ns]

In [226]: s - datetime.datetime(2011, 1, 1, 3, 5)
Out[226]: 
0   364 days 20:55:00
1   365 days 20:55:00
2   366 days 20:55:00
dtype: timedelta64[ns]

In [227]: s + datetime.timedelta(minutes=5)
Out[227]: 
0   2012-01-01 00:05:00
1   2012-01-02 00:05:00
2   2012-01-03 00:05:00
dtype: datetime64[ns]

In [228]: datetime.datetime(2011, 1, 1, 3, 5) - s
Out[228]: 
0   -365 days +03:05:00
1   -366 days +03:05:00
2   -367 days +03:05:00
dtype: timedelta64[ns]

In [229]: datetime.timedelta(minutes=5) + s
Out[229]: 
0   2012-01-01 00:05:00
1   2012-01-02 00:05:00
2   2012-01-03 00:05:00
dtype: datetime64[ns]

---->   pandas.Series; Series.max

--------------------------------------
ID: 2103 --> 2
In [230]: deltas = pd.Series([datetime.timedelta(days=i) for i in range(3)])

In [231]: df = pd.DataFrame({"A": s, "B": deltas})

In [232]: df
Out[232]: 
           A      B
0 2012-01-01 0 days
1 2012-01-02 1 days
2 2012-01-03 2 days

In [233]: df["New Dates"] = df["A"] + df["B"]

In [234]: df["Delta"] = df["A"] - df["New Dates"]

In [235]: df
Out[235]: 
           A      B  New Dates   Delta
0 2012-01-01 0 days 2012-01-01  0 days
1 2012-01-02 1 days 2012-01-03 -1 days
2 2012-01-03 2 days 2012-01-05 -2 days

In [236]: df.dtypes
Out[236]: 
A             datetime64[ns]
B            timedelta64[ns]
New Dates     datetime64[ns]
Delta        timedelta64[ns]
dtype: object

---->   pandas.Series; pandas.DataFrame

--------------------------------------
ID: 2104 --> 1
In [237]: y = s - s.shift()

In [238]: y
Out[238]: 
0      NaT
1   1 days
2   1 days
dtype: timedelta64[ns]

In [239]: y[1] = np.nan

In [240]: y
Out[240]: 
0      NaT
1      NaT
2   1 days
dtype: timedelta64[ns]

---->   Series.shift

--------------------------------------
ID: 2105 --> 1
In [241]: def expand_grid(data_dict):
   .....:     rows = itertools.product(*data_dict.values())
   .....:     return pd.DataFrame.from_records(rows, columns=data_dict.keys())
   .....: 

In [242]: df = expand_grid(
   .....:     {"height": [60, 70], "weight": [100, 140, 180], "sex": ["Male", "Female"]}
   .....: )
   .....: 

In [243]: df
Out[243]: 
    height  weight     sex
0       60     100    Male
1       60     100  Female
2       60     140    Male
3       60     140  Female
4       60     180    Male
5       60     180  Female
6       70     100    Male
7       70     100  Female
8       70     140    Male
9       70     140  Female
10      70     180    Male
11      70     180  Female

---->   pandas.DataFrame

--------------------------------------
ID: 2106 --> 1
>>> s = pd.Series(data, index=index)

---->   pandas.Series

--------------------------------------
ID: 2107 --> 1
In [3]: s = pd.Series(np.random.randn(5), index=["a", "b", "c", "d", "e"])

In [4]: s
Out[4]: 
a    0.469112
b   -0.282863
c   -1.509059
d   -1.135632
e    1.212112
dtype: float64

In [5]: s.index
Out[5]: Index(['a', 'b', 'c', 'd', 'e'], dtype='object')

In [6]: pd.Series(np.random.randn(5))
Out[6]: 
0   -0.173215
1    0.119209
2   -1.044236
3   -0.861849
4   -2.104569
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 2108 --> 1
In [7]: d = {"b": 1, "a": 0, "c": 2}

In [8]: pd.Series(d)
Out[8]: 
b    1
a    0
c    2
dtype: int64

---->   pandas.Series

--------------------------------------
ID: 2109 --> 1
In [9]: d = {"a": 0.0, "b": 1.0, "c": 2.0}

In [10]: pd.Series(d)
Out[10]: 
a    0.0
b    1.0
c    2.0
dtype: float64

In [11]: pd.Series(d, index=["b", "c", "d", "a"])
Out[11]: 
b    1.0
c    2.0
d    NaN
a    0.0
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 2110 --> 1
In [12]: pd.Series(5.0, index=["a", "b", "c", "d", "e"])
Out[12]: 
a    5.0
b    5.0
c    5.0
d    5.0
e    5.0
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 2111 --> 1
In [13]: s[0]
Out[13]: 0.4691122999071863

In [14]: s[:3]
Out[14]: 
a    0.469112
b   -0.282863
c   -1.509059
dtype: float64

In [15]: s[s > s.median()]
Out[15]: 
a    0.469112
e    1.212112
dtype: float64

In [16]: s[[4, 3, 1]]
Out[16]: 
e    1.212112
d   -1.135632
b   -0.282863
dtype: float64

In [17]: np.exp(s)
Out[17]: 
a    1.598575
b    0.753623
c    0.221118
d    0.321219
e    3.360575
dtype: float64

---->   Series.median

--------------------------------------
ID: 2113 --> 1
In [20]: s.to_numpy()
Out[20]: array([ 0.4691, -0.2829, -1.5091, -1.1356,  1.2121])

---->   Series.to_numpy

--------------------------------------
ID: 2114 --> 1
In [26]: s["f"]
---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
File ~/work/pandas/pandas/pandas/core/indexes/base.py:3653, in Index.get_loc(self, key)
   3652 try:
-> 3653     return self._engine.get_loc(casted_key)
   3654 except KeyError as err:

File ~/work/pandas/pandas/pandas/_libs/index.pyx:147, in pandas._libs.index.IndexEngine.get_loc()

File ~/work/pandas/pandas/pandas/_libs/index.pyx:176, in pandas._libs.index.IndexEngine.get_loc()

File ~/work/pandas/pandas/pandas/_libs/hashtable_class_helper.pxi:7080, in pandas._libs.hashtable.PyObjectHashTable.get_item()

File ~/work/pandas/pandas/pandas/_libs/hashtable_class_helper.pxi:7088, in pandas._libs.hashtable.PyObjectHashTable.get_item()

KeyError: 'f'

The above exception was the direct cause of the following exception:

KeyError                                  Traceback (most recent call last)
Cell In[26], line 1
----> 1 s["f"]

File ~/work/pandas/pandas/pandas/core/series.py:1007, in Series.__getitem__(self, key)
   1004     return self._values[key]
   1006 elif key_is_scalar:
-> 1007     return self._get_value(key)
   1009 if is_hashable(key):
   1010     # Otherwise index.get_value will raise InvalidIndexError
   1011     try:
   1012         # For labels that don't resolve as scalars like tuples and frozensets

File ~/work/pandas/pandas/pandas/core/series.py:1116, in Series._get_value(self, label, takeable)
   1113     return self._values[label]
   1115 # Similar to Index.get_value, but we do not fall back to positional
-> 1116 loc = self.index.get_loc(label)
   1118 if is_integer(loc):
   1119     return self._values[loc]

File ~/work/pandas/pandas/pandas/core/indexes/base.py:3655, in Index.get_loc(self, key)
   3653     return self._engine.get_loc(casted_key)
   3654 except KeyError as err:
-> 3655     raise KeyError(key) from err
   3656 except TypeError:
   3657     # If we have a listlike key, _check_indexing_error will raise
   3658     #  InvalidIndexError. Otherwise we fall through and re-raise
   3659     #  the TypeError.
   3660     self._check_indexing_error(key)

KeyError: 'f'

---->   Index.get_loc

--------------------------------------
ID: 2115 --> 1
In [27]: s.get("f")

In [28]: s.get("f", np.nan)
Out[28]: nan

---->   Series.get

--------------------------------------
ID: 2117 --> 1
In [33]: s = pd.Series(np.random.randn(5), name="something")

In [34]: s
Out[34]: 
0   -0.494929
1    1.071804
2    0.721555
3   -0.706771
4   -1.039575
Name: something, dtype: float64

In [35]: s.name
Out[35]: 'something'

---->   pandas.Series

--------------------------------------
ID: 2119 --> 2
In [38]: d = {
   ....:     "one": pd.Series([1.0, 2.0, 3.0], index=["a", "b", "c"]),
   ....:     "two": pd.Series([1.0, 2.0, 3.0, 4.0], index=["a", "b", "c", "d"]),
   ....: }
   ....: 

In [39]: df = pd.DataFrame(d)

In [40]: df
Out[40]: 
   one  two
a  1.0  1.0
b  2.0  2.0
c  3.0  3.0
d  NaN  4.0

In [41]: pd.DataFrame(d, index=["d", "b", "a"])
Out[41]: 
   one  two
d  NaN  4.0
b  2.0  2.0
a  1.0  1.0

In [42]: pd.DataFrame(d, index=["d", "b", "a"], columns=["two", "three"])
Out[42]: 
   two three
d  4.0   NaN
b  2.0   NaN
a  1.0   NaN

---->   pandas.Series; pandas.DataFrame

--------------------------------------
ID: 2121 --> 1
In [45]: d = {"one": [1.0, 2.0, 3.0, 4.0], "two": [4.0, 3.0, 2.0, 1.0]}

In [46]: pd.DataFrame(d)
Out[46]: 
   one  two
0  1.0  4.0
1  2.0  3.0
2  3.0  2.0
3  4.0  1.0

In [47]: pd.DataFrame(d, index=["a", "b", "c", "d"])
Out[47]: 
   one  two
a  1.0  4.0
b  2.0  3.0
c  3.0  2.0
d  4.0  1.0

---->   pandas.DataFrame

--------------------------------------
ID: 2122 --> 1
In [48]: data = np.zeros((2,), dtype=[("A", "i4"), ("B", "f4"), ("C", "a10")])

In [49]: data[:] = [(1, 2.0, "Hello"), (2, 3.0, "World")]

In [50]: pd.DataFrame(data)
Out[50]: 
   A    B         C
0  1  2.0  b'Hello'
1  2  3.0  b'World'

In [51]: pd.DataFrame(data, index=["first", "second"])
Out[51]: 
        A    B         C
first   1  2.0  b'Hello'
second  2  3.0  b'World'

In [52]: pd.DataFrame(data, columns=["C", "A", "B"])
Out[52]: 
          C  A    B
0  b'Hello'  1  2.0
1  b'World'  2  3.0

---->   pandas.DataFrame

--------------------------------------
ID: 2123 --> 1
In [53]: data2 = [{"a": 1, "b": 2}, {"a": 5, "b": 10, "c": 20}]

In [54]: pd.DataFrame(data2)
Out[54]: 
   a   b     c
0  1   2   NaN
1  5  10  20.0

In [55]: pd.DataFrame(data2, index=["first", "second"])
Out[55]: 
        a   b     c
first   1   2   NaN
second  5  10  20.0

In [56]: pd.DataFrame(data2, columns=["a", "b"])
Out[56]: 
   a   b
0  1   2
1  5  10

---->   pandas.DataFrame

--------------------------------------
ID: 2124 --> 1
In [57]: pd.DataFrame(
   ....:     {
   ....:         ("a", "b"): {("A", "B"): 1, ("A", "C"): 2},
   ....:         ("a", "a"): {("A", "C"): 3, ("A", "B"): 4},
   ....:         ("a", "c"): {("A", "B"): 5, ("A", "C"): 6},
   ....:         ("b", "a"): {("A", "C"): 7, ("A", "B"): 8},
   ....:         ("b", "b"): {("A", "D"): 9, ("A", "B"): 10},
   ....:     }
   ....: )
   ....: 
Out[57]: 
       a              b      
       b    a    c    a     b
A B  1.0  4.0  5.0  8.0  10.0
  C  2.0  3.0  6.0  7.0   NaN
  D  NaN  NaN  NaN  NaN   9.0

---->   pandas.DataFrame

--------------------------------------
ID: 2125 --> 2
In [58]: ser = pd.Series(range(3), index=list("abc"), name="ser")

In [59]: pd.DataFrame(ser)
Out[59]: 
   ser
a    0
b    1
c    2

---->   pandas.Series; pandas.DataFrame

--------------------------------------
ID: 2126 --> 1
In [60]: from collections import namedtuple

In [61]: Point = namedtuple("Point", "x y")

In [62]: pd.DataFrame([Point(0, 0), Point(0, 3), (2, 3)])
Out[62]: 
   x  y
0  0  0
1  0  3
2  2  3

In [63]: Point3D = namedtuple("Point3D", "x y z")

In [64]: pd.DataFrame([Point3D(0, 0, 0), Point3D(0, 3, 5), Point(2, 3)])
Out[64]: 
   x  y    z
0  0  0  0.0
1  0  3  5.0
2  2  3  NaN

---->   pandas.DataFrame

--------------------------------------
ID: 2127 --> 1
In [65]: from dataclasses import make_dataclass

In [66]: Point = make_dataclass("Point", [("x", int), ("y", int)])

In [67]: pd.DataFrame([Point(0, 0), Point(0, 3), Point(2, 3)])
Out[67]: 
   x  y
0  0  0
1  0  3
2  2  3

---->   pandas.DataFrame

--------------------------------------
ID: 2128 --> 1
In [68]: pd.DataFrame.from_dict(dict([("A", [1, 2, 3]), ("B", [4, 5, 6])]))
Out[68]: 
   A  B
0  1  4
1  2  5
2  3  6

---->   pandas.DataFrame

--------------------------------------
ID: 2129 --> 1
In [69]: pd.DataFrame.from_dict(
   ....:     dict([("A", [1, 2, 3]), ("B", [4, 5, 6])]),
   ....:     orient="index",
   ....:     columns=["one", "two", "three"],
   ....: )
   ....: 
Out[69]: 
   one  two  three
A    1    2      3
B    4    5      6

---->   pandas.DataFrame

--------------------------------------
ID: 2130 --> 1
In [70]: data
Out[70]: 
array([(1, 2., b'Hello'), (2, 3., b'World')],
      dtype=[('A', '

In [71]: pd.DataFrame.from_records(data, index="C")
Out[71]: 
          A    B
C               
b'Hello'  1  2.0
b'World'  2  3.0

---->   pandas.DataFrame

--------------------------------------
ID: 2131 --> 1
In [76]: del df["two"]

In [77]: three = df.pop("three")

In [78]: df
Out[78]: 
   one   flag
a  1.0  False
b  2.0  False
c  3.0   True
d  NaN  False

---->   DataFrame.pop

--------------------------------------
ID: 2132 --> 1
In [83]: df.insert(1, "bar", df["one"])

In [84]: df
Out[84]: 
   one  bar   flag  foo  one_trunc
a  1.0  1.0  False  bar        1.0
b  2.0  2.0  False  bar        2.0
c  3.0  3.0   True  bar        NaN
d  NaN  NaN  False  bar        NaN

---->   DataFrame.insert

--------------------------------------
ID: 2136 --> 2
In [90]: dfa = pd.DataFrame({"A": [1, 2, 3], "B": [4, 5, 6]})

In [91]: dfa.assign(C=lambda x: x["A"] + x["B"], D=lambda x: x["A"] + x["C"])
Out[91]: 
   A  B  C   D
0  1  4  5   6
1  2  5  7   9
2  3  6  9  12

---->   pandas.DataFrame; DataFrame.assign

--------------------------------------
ID: 2137 --> 1
In [94]: df = pd.DataFrame(np.random.randn(10, 4), columns=["A", "B", "C", "D"])

In [95]: df2 = pd.DataFrame(np.random.randn(7, 3), columns=["A", "B", "C"])

In [96]: df + df2
Out[96]: 
          A         B         C   D
0  0.045691 -0.014138  1.380871 NaN
1 -0.955398 -1.501007  0.037181 NaN
2 -0.662690  1.534833 -0.859691 NaN
3 -2.452949  1.237274 -0.133712 NaN
4  1.414490  1.951676 -2.320422 NaN
5 -0.494922 -1.649727 -1.084601 NaN
6 -1.047551 -0.748572 -0.805479 NaN
7       NaN       NaN       NaN NaN
8       NaN       NaN       NaN NaN
9       NaN       NaN       NaN NaN

---->   pandas.DataFrame

--------------------------------------
ID: 2138 --> 1
In [101]: df1 = pd.DataFrame({"a": [1, 0, 1], "b": [0, 1, 1]}, dtype=bool)

In [102]: df2 = pd.DataFrame({"a": [0, 1, 1], "b": [1, 1, 0]}, dtype=bool)

In [103]: df1 & df2
Out[103]: 
       a      b
0  False  False
1  False   True
2   True  False

In [104]: df1 | df2
Out[104]: 
      a     b
0  True  True
1  True  True
2  True  True

In [105]: df1 ^ df2
Out[105]: 
       a      b
0   True   True
1   True  False
2  False   True

In [106]: -df1
Out[106]: 
       a      b
0  False   True
1   True  False
2  False  False

---->   pandas.DataFrame

--------------------------------------
ID: 2140 --> 1
In [110]: ser = pd.Series([1, 2, 3, 4])

In [111]: np.exp(ser)
Out[111]: 
0     2.718282
1     7.389056
2    20.085537
3    54.598150
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 2141 --> 1
In [112]: ser1 = pd.Series([1, 2, 3], index=["a", "b", "c"])

In [113]: ser2 = pd.Series([1, 3, 5], index=["b", "a", "c"])

In [114]: ser1
Out[114]: 
a    1
b    2
c    3
dtype: int64

In [115]: ser2
Out[115]: 
b    1
a    3
c    5
dtype: int64

In [116]: np.remainder(ser1, ser2)
Out[116]: 
a    1
b    0
c    3
dtype: int64

---->   pandas.Series

--------------------------------------
ID: 2142 --> 1
In [117]: ser3 = pd.Series([2, 4, 6], index=["b", "c", "d"])

In [118]: ser3
Out[118]: 
b    2
c    4
d    6
dtype: int64

In [119]: np.remainder(ser1, ser3)
Out[119]: 
a    NaN
b    0.0
c    3.0
d    NaN
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 2143 --> 2
In [120]: ser = pd.Series([1, 2, 3])

In [121]: idx = pd.Index([4, 5, 6])

In [122]: np.maximum(ser, idx)
Out[122]: 
0    4
1    5
2    6
dtype: int64

---->   pandas.Series; pandas.Index

--------------------------------------
ID: 2146 --> 1
In [127]: pd.DataFrame(np.random.randn(3, 12))
Out[127]: 
         0         1         2   ...        9         10        11
0 -1.226825  0.769804 -1.281247  ... -1.110336 -0.619976  0.149748
1 -0.732339  0.687738  0.176444  ...  1.462696 -1.743161 -0.826591
2 -0.345352  1.314232  0.690579  ...  0.896171 -0.487602 -0.082240

[3 rows x 12 columns]

---->   pandas.DataFrame

--------------------------------------
ID: 2147 --> 1
In [128]: pd.set_option("display.width", 40)  # default is 80

In [129]: pd.DataFrame(np.random.randn(3, 12))
Out[129]: 
         0         1         2   ...        9         10        11
0 -2.182937  0.380396  0.084844  ... -0.023688  2.410179  1.450520
1  0.206053 -0.251905 -2.213588  ... -0.025747 -0.988387  0.094055
2  1.262731  1.289997  0.082423  ... -0.281461  0.030711  0.109121

[3 rows x 12 columns]

---->   pandas.DataFrame

--------------------------------------
ID: 2148 --> 1
In [130]: datafile = {
   .....:     "filename": ["filename_01", "filename_02"],
   .....:     "path": [
   .....:         "media/user_name/storage/folder_01/filename_01",
   .....:         "media/user_name/storage/folder_02/filename_02",
   .....:     ],
   .....: }
   .....: 

In [131]: pd.set_option("display.max_colwidth", 30)

In [132]: pd.DataFrame(datafile)
Out[132]: 
      filename                           path
0  filename_01  media/user_name/storage/fo...
1  filename_02  media/user_name/storage/fo...

In [133]: pd.set_option("display.max_colwidth", 100)

In [134]: pd.DataFrame(datafile)
Out[134]: 
      filename                                           path
0  filename_01  media/user_name/storage/folder_01/filename_01
1  filename_02  media/user_name/storage/folder_02/filename_02

---->   pandas.DataFrame

--------------------------------------
ID: 2149 --> 1
In [135]: df = pd.DataFrame({"foo1": np.random.randn(5), "foo2": np.random.randn(5)})

In [136]: df
Out[136]: 
       foo1      foo2
0  1.126203  0.781836
1 -0.977349 -1.071357
2  1.474071  0.441153
3 -0.064034  2.353925
4 -1.282782  0.583787

In [137]: df.foo1
Out[137]: 
0    1.126203
1   -0.977349
2    1.474071
3   -0.064034
4   -1.282782
Name: foo1, dtype: float64

---->   pandas.DataFrame

--------------------------------------
ID: 2150 --> 1
>>> s = pd.Series(data, index=index)

---->   pandas.Series

--------------------------------------
ID: 2151 --> 1
In [3]: s = pd.Series(np.random.randn(5), index=["a", "b", "c", "d", "e"])

In [4]: s
Out[4]: 
a    0.469112
b   -0.282863
c   -1.509059
d   -1.135632
e    1.212112
dtype: float64

In [5]: s.index
Out[5]: Index(['a', 'b', 'c', 'd', 'e'], dtype='object')

In [6]: pd.Series(np.random.randn(5))
Out[6]: 
0   -0.173215
1    0.119209
2   -1.044236
3   -0.861849
4   -2.104569
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 2152 --> 1
In [7]: d = {"b": 1, "a": 0, "c": 2}

In [8]: pd.Series(d)
Out[8]: 
b    1
a    0
c    2
dtype: int64

---->   pandas.Series

--------------------------------------
ID: 2153 --> 1
In [9]: d = {"a": 0.0, "b": 1.0, "c": 2.0}

In [10]: pd.Series(d)
Out[10]: 
a    0.0
b    1.0
c    2.0
dtype: float64

In [11]: pd.Series(d, index=["b", "c", "d", "a"])
Out[11]: 
b    1.0
c    2.0
d    NaN
a    0.0
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 2154 --> 1
In [12]: pd.Series(5.0, index=["a", "b", "c", "d", "e"])
Out[12]: 
a    5.0
b    5.0
c    5.0
d    5.0
e    5.0
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 2155 --> 1
In [13]: s[0]
Out[13]: 0.4691122999071863

In [14]: s[:3]
Out[14]: 
a    0.469112
b   -0.282863
c   -1.509059
dtype: float64

In [15]: s[s > s.median()]
Out[15]: 
a    0.469112
e    1.212112
dtype: float64

In [16]: s[[4, 3, 1]]
Out[16]: 
e    1.212112
d   -1.135632
b   -0.282863
dtype: float64

In [17]: np.exp(s)
Out[17]: 
a    1.598575
b    0.753623
c    0.221118
d    0.321219
e    3.360575
dtype: float64

---->   Series.median

--------------------------------------
ID: 2157 --> 1
In [20]: s.to_numpy()
Out[20]: array([ 0.4691, -0.2829, -1.5091, -1.1356,  1.2121])

---->   Series.to_numpy

--------------------------------------
ID: 2158 --> 1
In [26]: s["f"]
---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
File ~/work/pandas/pandas/pandas/core/indexes/base.py:3653, in Index.get_loc(self, key)
   3652 try:
-> 3653     return self._engine.get_loc(casted_key)
   3654 except KeyError as err:

File ~/work/pandas/pandas/pandas/_libs/index.pyx:147, in pandas._libs.index.IndexEngine.get_loc()

File ~/work/pandas/pandas/pandas/_libs/index.pyx:176, in pandas._libs.index.IndexEngine.get_loc()

File ~/work/pandas/pandas/pandas/_libs/hashtable_class_helper.pxi:7080, in pandas._libs.hashtable.PyObjectHashTable.get_item()

File ~/work/pandas/pandas/pandas/_libs/hashtable_class_helper.pxi:7088, in pandas._libs.hashtable.PyObjectHashTable.get_item()

KeyError: 'f'

The above exception was the direct cause of the following exception:

KeyError                                  Traceback (most recent call last)
Cell In[26], line 1
----> 1 s["f"]

File ~/work/pandas/pandas/pandas/core/series.py:1007, in Series.__getitem__(self, key)
   1004     return self._values[key]
   1006 elif key_is_scalar:
-> 1007     return self._get_value(key)
   1009 if is_hashable(key):
   1010     # Otherwise index.get_value will raise InvalidIndexError
   1011     try:
   1012         # For labels that don't resolve as scalars like tuples and frozensets

File ~/work/pandas/pandas/pandas/core/series.py:1116, in Series._get_value(self, label, takeable)
   1113     return self._values[label]
   1115 # Similar to Index.get_value, but we do not fall back to positional
-> 1116 loc = self.index.get_loc(label)
   1118 if is_integer(loc):
   1119     return self._values[loc]

File ~/work/pandas/pandas/pandas/core/indexes/base.py:3655, in Index.get_loc(self, key)
   3653     return self._engine.get_loc(casted_key)
   3654 except KeyError as err:
-> 3655     raise KeyError(key) from err
   3656 except TypeError:
   3657     # If we have a listlike key, _check_indexing_error will raise
   3658     #  InvalidIndexError. Otherwise we fall through and re-raise
   3659     #  the TypeError.
   3660     self._check_indexing_error(key)

KeyError: 'f'

---->   Index.get_loc

--------------------------------------
ID: 2159 --> 1
In [27]: s.get("f")

In [28]: s.get("f", np.nan)
Out[28]: nan

---->   Series.get

--------------------------------------
ID: 2161 --> 1
In [33]: s = pd.Series(np.random.randn(5), name="something")

In [34]: s
Out[34]: 
0   -0.494929
1    1.071804
2    0.721555
3   -0.706771
4   -1.039575
Name: something, dtype: float64

In [35]: s.name
Out[35]: 'something'

---->   pandas.Series

--------------------------------------
ID: 2163 --> 2
In [38]: d = {
   ....:     "one": pd.Series([1.0, 2.0, 3.0], index=["a", "b", "c"]),
   ....:     "two": pd.Series([1.0, 2.0, 3.0, 4.0], index=["a", "b", "c", "d"]),
   ....: }
   ....: 

In [39]: df = pd.DataFrame(d)

In [40]: df
Out[40]: 
   one  two
a  1.0  1.0
b  2.0  2.0
c  3.0  3.0
d  NaN  4.0

In [41]: pd.DataFrame(d, index=["d", "b", "a"])
Out[41]: 
   one  two
d  NaN  4.0
b  2.0  2.0
a  1.0  1.0

In [42]: pd.DataFrame(d, index=["d", "b", "a"], columns=["two", "three"])
Out[42]: 
   two three
d  4.0   NaN
b  2.0   NaN
a  1.0   NaN

---->   pandas.Series; pandas.DataFrame

--------------------------------------
ID: 2165 --> 1
In [45]: d = {"one": [1.0, 2.0, 3.0, 4.0], "two": [4.0, 3.0, 2.0, 1.0]}

In [46]: pd.DataFrame(d)
Out[46]: 
   one  two
0  1.0  4.0
1  2.0  3.0
2  3.0  2.0
3  4.0  1.0

In [47]: pd.DataFrame(d, index=["a", "b", "c", "d"])
Out[47]: 
   one  two
a  1.0  4.0
b  2.0  3.0
c  3.0  2.0
d  4.0  1.0

---->   pandas.DataFrame

--------------------------------------
ID: 2166 --> 1
In [48]: data = np.zeros((2,), dtype=[("A", "i4"), ("B", "f4"), ("C", "a10")])

In [49]: data[:] = [(1, 2.0, "Hello"), (2, 3.0, "World")]

In [50]: pd.DataFrame(data)
Out[50]: 
   A    B         C
0  1  2.0  b'Hello'
1  2  3.0  b'World'

In [51]: pd.DataFrame(data, index=["first", "second"])
Out[51]: 
        A    B         C
first   1  2.0  b'Hello'
second  2  3.0  b'World'

In [52]: pd.DataFrame(data, columns=["C", "A", "B"])
Out[52]: 
          C  A    B
0  b'Hello'  1  2.0
1  b'World'  2  3.0

---->   pandas.DataFrame

--------------------------------------
ID: 2167 --> 1
In [53]: data2 = [{"a": 1, "b": 2}, {"a": 5, "b": 10, "c": 20}]

In [54]: pd.DataFrame(data2)
Out[54]: 
   a   b     c
0  1   2   NaN
1  5  10  20.0

In [55]: pd.DataFrame(data2, index=["first", "second"])
Out[55]: 
        a   b     c
first   1   2   NaN
second  5  10  20.0

In [56]: pd.DataFrame(data2, columns=["a", "b"])
Out[56]: 
   a   b
0  1   2
1  5  10

---->   pandas.DataFrame

--------------------------------------
ID: 2168 --> 1
In [57]: pd.DataFrame(
   ....:     {
   ....:         ("a", "b"): {("A", "B"): 1, ("A", "C"): 2},
   ....:         ("a", "a"): {("A", "C"): 3, ("A", "B"): 4},
   ....:         ("a", "c"): {("A", "B"): 5, ("A", "C"): 6},
   ....:         ("b", "a"): {("A", "C"): 7, ("A", "B"): 8},
   ....:         ("b", "b"): {("A", "D"): 9, ("A", "B"): 10},
   ....:     }
   ....: )
   ....: 
Out[57]: 
       a              b      
       b    a    c    a     b
A B  1.0  4.0  5.0  8.0  10.0
  C  2.0  3.0  6.0  7.0   NaN
  D  NaN  NaN  NaN  NaN   9.0

---->   pandas.DataFrame

--------------------------------------
ID: 2169 --> 2
In [58]: ser = pd.Series(range(3), index=list("abc"), name="ser")

In [59]: pd.DataFrame(ser)
Out[59]: 
   ser
a    0
b    1
c    2

---->   pandas.Series; pandas.DataFrame

--------------------------------------
ID: 2170 --> 1
In [60]: from collections import namedtuple

In [61]: Point = namedtuple("Point", "x y")

In [62]: pd.DataFrame([Point(0, 0), Point(0, 3), (2, 3)])
Out[62]: 
   x  y
0  0  0
1  0  3
2  2  3

In [63]: Point3D = namedtuple("Point3D", "x y z")

In [64]: pd.DataFrame([Point3D(0, 0, 0), Point3D(0, 3, 5), Point(2, 3)])
Out[64]: 
   x  y    z
0  0  0  0.0
1  0  3  5.0
2  2  3  NaN

---->   pandas.DataFrame

--------------------------------------
ID: 2171 --> 1
In [65]: from dataclasses import make_dataclass

In [66]: Point = make_dataclass("Point", [("x", int), ("y", int)])

In [67]: pd.DataFrame([Point(0, 0), Point(0, 3), Point(2, 3)])
Out[67]: 
   x  y
0  0  0
1  0  3
2  2  3

---->   pandas.DataFrame

--------------------------------------
ID: 2172 --> 1
In [68]: pd.DataFrame.from_dict(dict([("A", [1, 2, 3]), ("B", [4, 5, 6])]))
Out[68]: 
   A  B
0  1  4
1  2  5
2  3  6

---->   pandas.DataFrame

--------------------------------------
ID: 2173 --> 1
In [69]: pd.DataFrame.from_dict(
   ....:     dict([("A", [1, 2, 3]), ("B", [4, 5, 6])]),
   ....:     orient="index",
   ....:     columns=["one", "two", "three"],
   ....: )
   ....: 
Out[69]: 
   one  two  three
A    1    2      3
B    4    5      6

---->   pandas.DataFrame

--------------------------------------
ID: 2174 --> 1
In [70]: data
Out[70]: 
array([(1, 2., b'Hello'), (2, 3., b'World')],
      dtype=[('A', '

In [71]: pd.DataFrame.from_records(data, index="C")
Out[71]: 
          A    B
C               
b'Hello'  1  2.0
b'World'  2  3.0

---->   pandas.DataFrame

--------------------------------------
ID: 2175 --> 1
In [76]: del df["two"]

In [77]: three = df.pop("three")

In [78]: df
Out[78]: 
   one   flag
a  1.0  False
b  2.0  False
c  3.0   True
d  NaN  False

---->   DataFrame.pop

--------------------------------------
ID: 2176 --> 1
In [83]: df.insert(1, "bar", df["one"])

In [84]: df
Out[84]: 
   one  bar   flag  foo  one_trunc
a  1.0  1.0  False  bar        1.0
b  2.0  2.0  False  bar        2.0
c  3.0  3.0   True  bar        NaN
d  NaN  NaN  False  bar        NaN

---->   DataFrame.insert

--------------------------------------
ID: 2180 --> 2
In [90]: dfa = pd.DataFrame({"A": [1, 2, 3], "B": [4, 5, 6]})

In [91]: dfa.assign(C=lambda x: x["A"] + x["B"], D=lambda x: x["A"] + x["C"])
Out[91]: 
   A  B  C   D
0  1  4  5   6
1  2  5  7   9
2  3  6  9  12

---->   pandas.DataFrame; DataFrame.assign

--------------------------------------
ID: 2181 --> 1
In [94]: df = pd.DataFrame(np.random.randn(10, 4), columns=["A", "B", "C", "D"])

In [95]: df2 = pd.DataFrame(np.random.randn(7, 3), columns=["A", "B", "C"])

In [96]: df + df2
Out[96]: 
          A         B         C   D
0  0.045691 -0.014138  1.380871 NaN
1 -0.955398 -1.501007  0.037181 NaN
2 -0.662690  1.534833 -0.859691 NaN
3 -2.452949  1.237274 -0.133712 NaN
4  1.414490  1.951676 -2.320422 NaN
5 -0.494922 -1.649727 -1.084601 NaN
6 -1.047551 -0.748572 -0.805479 NaN
7       NaN       NaN       NaN NaN
8       NaN       NaN       NaN NaN
9       NaN       NaN       NaN NaN

---->   pandas.DataFrame

--------------------------------------
ID: 2182 --> 1
In [101]: df1 = pd.DataFrame({"a": [1, 0, 1], "b": [0, 1, 1]}, dtype=bool)

In [102]: df2 = pd.DataFrame({"a": [0, 1, 1], "b": [1, 1, 0]}, dtype=bool)

In [103]: df1 & df2
Out[103]: 
       a      b
0  False  False
1  False   True
2   True  False

In [104]: df1 | df2
Out[104]: 
      a     b
0  True  True
1  True  True
2  True  True

In [105]: df1 ^ df2
Out[105]: 
       a      b
0   True   True
1   True  False
2  False   True

In [106]: -df1
Out[106]: 
       a      b
0  False   True
1   True  False
2  False  False

---->   pandas.DataFrame

--------------------------------------
ID: 2184 --> 1
In [110]: ser = pd.Series([1, 2, 3, 4])

In [111]: np.exp(ser)
Out[111]: 
0     2.718282
1     7.389056
2    20.085537
3    54.598150
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 2185 --> 1
In [112]: ser1 = pd.Series([1, 2, 3], index=["a", "b", "c"])

In [113]: ser2 = pd.Series([1, 3, 5], index=["b", "a", "c"])

In [114]: ser1
Out[114]: 
a    1
b    2
c    3
dtype: int64

In [115]: ser2
Out[115]: 
b    1
a    3
c    5
dtype: int64

In [116]: np.remainder(ser1, ser2)
Out[116]: 
a    1
b    0
c    3
dtype: int64

---->   pandas.Series

--------------------------------------
ID: 2186 --> 1
In [117]: ser3 = pd.Series([2, 4, 6], index=["b", "c", "d"])

In [118]: ser3
Out[118]: 
b    2
c    4
d    6
dtype: int64

In [119]: np.remainder(ser1, ser3)
Out[119]: 
a    NaN
b    0.0
c    3.0
d    NaN
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 2187 --> 2
In [120]: ser = pd.Series([1, 2, 3])

In [121]: idx = pd.Index([4, 5, 6])

In [122]: np.maximum(ser, idx)
Out[122]: 
0    4
1    5
2    6
dtype: int64

---->   pandas.Series; pandas.Index

--------------------------------------
ID: 2190 --> 1
In [127]: pd.DataFrame(np.random.randn(3, 12))
Out[127]: 
         0         1         2   ...        9         10        11
0 -1.226825  0.769804 -1.281247  ... -1.110336 -0.619976  0.149748
1 -0.732339  0.687738  0.176444  ...  1.462696 -1.743161 -0.826591
2 -0.345352  1.314232  0.690579  ...  0.896171 -0.487602 -0.082240

[3 rows x 12 columns]

---->   pandas.DataFrame

--------------------------------------
ID: 2191 --> 1
In [128]: pd.set_option("display.width", 40)  # default is 80

In [129]: pd.DataFrame(np.random.randn(3, 12))
Out[129]: 
         0         1         2   ...        9         10        11
0 -2.182937  0.380396  0.084844  ... -0.023688  2.410179  1.450520
1  0.206053 -0.251905 -2.213588  ... -0.025747 -0.988387  0.094055
2  1.262731  1.289997  0.082423  ... -0.281461  0.030711  0.109121

[3 rows x 12 columns]

---->   pandas.DataFrame

--------------------------------------
ID: 2192 --> 1
In [130]: datafile = {
   .....:     "filename": ["filename_01", "filename_02"],
   .....:     "path": [
   .....:         "media/user_name/storage/folder_01/filename_01",
   .....:         "media/user_name/storage/folder_02/filename_02",
   .....:     ],
   .....: }
   .....: 

In [131]: pd.set_option("display.max_colwidth", 30)

In [132]: pd.DataFrame(datafile)
Out[132]: 
      filename                           path
0  filename_01  media/user_name/storage/fo...
1  filename_02  media/user_name/storage/fo...

In [133]: pd.set_option("display.max_colwidth", 100)

In [134]: pd.DataFrame(datafile)
Out[134]: 
      filename                                           path
0  filename_01  media/user_name/storage/folder_01/filename_01
1  filename_02  media/user_name/storage/folder_02/filename_02

---->   pandas.DataFrame

--------------------------------------
ID: 2193 --> 1
In [135]: df = pd.DataFrame({"foo1": np.random.randn(5), "foo2": np.random.randn(5)})

In [136]: df
Out[136]: 
       foo1      foo2
0  1.126203  0.781836
1 -0.977349 -1.071357
2  1.474071  0.441153
3 -0.064034  2.353925
4 -1.282782  0.583787

In [137]: df.foo1
Out[137]: 
0    1.126203
1   -0.977349
2    1.474071
3   -0.064034
4   -1.282782
Name: foo1, dtype: float64

---->   pandas.DataFrame

--------------------------------------
ID: 2194 --> 1
In [3]: s = pd.Series([1, 3, 5, np.nan, 6, 8])

In [4]: s
Out[4]: 
0    1.0
1    3.0
2    5.0
3    NaN
4    6.0
5    8.0
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 2195 --> 1
In [5]: dates = pd.date_range("20130101", periods=6)

In [6]: dates
Out[6]: 
DatetimeIndex(['2013-01-01', '2013-01-02', '2013-01-03', '2013-01-04',
               '2013-01-05', '2013-01-06'],
              dtype='datetime64[ns]', freq='D')

In [7]: df = pd.DataFrame(np.random.randn(6, 4), index=dates, columns=list("ABCD"))

In [8]: df
Out[8]: 
                   A         B         C         D
2013-01-01  0.469112 -0.282863 -1.509059 -1.135632
2013-01-02  1.212112 -0.173215  0.119209 -1.044236
2013-01-03 -0.861849 -2.104569 -0.494929  1.071804
2013-01-04  0.721555 -0.706771 -1.039575  0.271860
2013-01-05 -0.424972  0.567020  0.276232 -1.087401
2013-01-06 -0.673690  0.113648 -1.478427  0.524988

---->   pandas.DataFrame

--------------------------------------
ID: 2196 --> 3
In [9]: df2 = pd.DataFrame(
   ...:     {
   ...:         "A": 1.0,
   ...:         "B": pd.Timestamp("20130102"),
   ...:         "C": pd.Series(1, index=list(range(4)), dtype="float32"),
   ...:         "D": np.array([3] * 4, dtype="int32"),
   ...:         "E": pd.Categorical(["test", "train", "test", "train"]),
   ...:         "F": "foo",
   ...:     }
   ...: )
   ...: 

In [10]: df2
Out[10]: 
     A          B    C  D      E    F
0  1.0 2013-01-02  1.0  3   test  foo
1  1.0 2013-01-02  1.0  3  train  foo
2  1.0 2013-01-02  1.0  3   test  foo
3  1.0 2013-01-02  1.0  3  train  foo

---->   pandas.DataFrame; pandas.Series; pandas.Categorical

--------------------------------------
ID: 2197 --> 2
In [13]: df.head()
Out[13]: 
                   A         B         C         D
2013-01-01  0.469112 -0.282863 -1.509059 -1.135632
2013-01-02  1.212112 -0.173215  0.119209 -1.044236
2013-01-03 -0.861849 -2.104569 -0.494929  1.071804
2013-01-04  0.721555 -0.706771 -1.039575  0.271860
2013-01-05 -0.424972  0.567020  0.276232 -1.087401

In [14]: df.tail(3)
Out[14]: 
                   A         B         C         D
2013-01-04  0.721555 -0.706771 -1.039575  0.271860
2013-01-05 -0.424972  0.567020  0.276232 -1.087401
2013-01-06 -0.673690  0.113648 -1.478427  0.524988

---->   DataFrame.head; DataFrame.tail

--------------------------------------
ID: 2201 --> 1
In [19]: df.describe()
Out[19]: 
              A         B         C         D
count  6.000000  6.000000  6.000000  6.000000
mean   0.073711 -0.431125 -0.687758 -0.233103
std    0.843157  0.922818  0.779887  0.973118
min   -0.861849 -2.104569 -1.509059 -1.135632
25%   -0.611510 -0.600794 -1.368714 -1.076610
50%    0.022070 -0.228039 -0.767252 -0.386188
75%    0.658444  0.041933 -0.034326  0.461706
max    1.212112  0.567020  0.276232  1.071804

---->   DataFrame.describe

--------------------------------------
ID: 2204 --> 1
In [41]: df2 = df.copy()

In [42]: df2["E"] = ["one", "one", "two", "three", "four", "three"]

In [43]: df2
Out[43]: 
                   A         B         C         D      E
2013-01-01  0.469112 -0.282863 -1.509059 -1.135632    one
2013-01-02  1.212112 -0.173215  0.119209 -1.044236    one
2013-01-03 -0.861849 -2.104569 -0.494929  1.071804    two
2013-01-04  0.721555 -0.706771 -1.039575  0.271860  three
2013-01-05 -0.424972  0.567020  0.276232 -1.087401   four
2013-01-06 -0.673690  0.113648 -1.478427  0.524988  three

In [44]: df2[df2["E"].isin(["two", "four"])]
Out[44]: 
                   A         B         C         D     E
2013-01-03 -0.861849 -2.104569 -0.494929  1.071804   two
2013-01-05 -0.424972  0.567020  0.276232 -1.087401  four

---->   DataFrame.copy

--------------------------------------
ID: 2205 --> 1
In [45]: s1 = pd.Series([1, 2, 3, 4, 5, 6], index=pd.date_range("20130102", periods=6))

In [46]: s1
Out[46]: 
2013-01-02    1
2013-01-03    2
2013-01-04    3
2013-01-05    4
2013-01-06    5
2013-01-07    6
Freq: D, dtype: int64

In [47]: df["F"] = s1

---->   pandas.Series

--------------------------------------
ID: 2207 --> 1
In [52]: df2 = df.copy()

In [53]: df2[df2 > 0] = -df2

In [54]: df2
Out[54]: 
                   A         B         C    D    F
2013-01-01  0.000000  0.000000 -1.509059 -5.0  NaN
2013-01-02 -1.212112 -0.173215 -0.119209 -5.0 -1.0
2013-01-03 -0.861849 -2.104569 -0.494929 -5.0 -2.0
2013-01-04 -0.721555 -0.706771 -1.039575 -5.0 -3.0
2013-01-05 -0.424972 -0.567020 -0.276232 -5.0 -4.0
2013-01-06 -0.673690 -0.113648 -1.478427 -5.0 -5.0

---->   DataFrame.copy

--------------------------------------
ID: 2211 --> 1
In [60]: pd.isna(df1)
Out[60]: 
                A      B      C      D      F      E
2013-01-01  False  False  False  False   True  False
2013-01-02  False  False  False  False  False  False
2013-01-03  False  False  False  False  False   True
2013-01-04  False  False  False  False  False   True

---->   pandas.isna

--------------------------------------
ID: 2212 --> 1
In [61]: df.mean()
Out[61]: 
A   -0.004474
B   -0.383981
C   -0.687758
D    5.000000
F    3.000000
dtype: float64

---->   DataFrame.mean

--------------------------------------
ID: 2213 --> 1
In [62]: df.mean(1)
Out[62]: 
2013-01-01    0.872735
2013-01-02    1.431621
2013-01-03    0.707731
2013-01-04    1.395042
2013-01-05    1.883656
2013-01-06    1.592306
Freq: D, dtype: float64

---->   DataFrame.mean

--------------------------------------
ID: 2214 --> 2
In [63]: s = pd.Series([1, 3, 5, np.nan, 6, 8], index=dates).shift(2)

In [64]: s
Out[64]: 
2013-01-01    NaN
2013-01-02    NaN
2013-01-03    1.0
2013-01-04    3.0
2013-01-05    5.0
2013-01-06    NaN
Freq: D, dtype: float64

In [65]: df.sub(s, axis="index")
Out[65]: 
                   A         B         C    D    F
2013-01-01       NaN       NaN       NaN  NaN  NaN
2013-01-02       NaN       NaN       NaN  NaN  NaN
2013-01-03 -1.861849 -3.104569 -1.494929  4.0  1.0
2013-01-04 -2.278445 -3.706771 -4.039575  2.0  0.0
2013-01-05 -5.424972 -4.432980 -4.723768  0.0 -1.0
2013-01-06       NaN       NaN       NaN  NaN  NaN

---->   pandas.Series; DataFrame.sub

--------------------------------------
ID: 2215 --> 2
In [66]: df.apply(np.cumsum)
Out[66]: 
                   A         B         C     D     F
2013-01-01  0.000000  0.000000 -1.509059   5.0   NaN
2013-01-02  1.212112 -0.173215 -1.389850  10.0   1.0
2013-01-03  0.350263 -2.277784 -1.884779  15.0   3.0
2013-01-04  1.071818 -2.984555 -2.924354  20.0   6.0
2013-01-05  0.646846 -2.417535 -2.648122  25.0  10.0
2013-01-06 -0.026844 -2.303886 -4.126549  30.0  15.0

In [67]: df.apply(lambda x: x.max() - x.min())
Out[67]: 
A    2.073961
B    2.671590
C    1.785291
D    0.000000
F    4.000000
dtype: float64

---->   Series.max; Series.min

--------------------------------------
ID: 2216 --> 2
In [68]: s = pd.Series(np.random.randint(0, 7, size=10))

In [69]: s
Out[69]: 
0    4
1    2
2    1
3    2
4    6
5    4
6    4
7    6
8    4
9    4
dtype: int64

In [70]: s.value_counts()
Out[70]: 
4    5
2    2
6    2
1    1
Name: count, dtype: int64

---->   pandas.Series; Series.value_counts

--------------------------------------
ID: 2217 --> 1
In [71]: s = pd.Series(["A", "B", "C", "Aaba", "Baca", np.nan, "CABA", "dog", "cat"])

In [72]: s.str.lower()
Out[72]: 
0       a
1       b
2       c
3    aaba
4    baca
5     NaN
6    caba
7     dog
8     cat
dtype: object

---->   pandas.Series

--------------------------------------
ID: 2218 --> 1
In [73]: df = pd.DataFrame(np.random.randn(10, 4))

In [74]: df
Out[74]: 
          0         1         2         3
0 -0.548702  1.467327 -1.015962 -0.483075
1  1.637550 -1.217659 -0.291519 -1.745505
2 -0.263952  0.991460 -0.919069  0.266046
3 -0.709661  1.669052  1.037882 -1.705775
4 -0.919854 -0.042379  1.247642 -0.009920
5  0.290213  0.495767  0.362949  1.548106
6 -1.131345 -0.089329  0.337863 -0.945867
7 -0.932132  1.956030  0.017587 -0.016692
8 -0.575247  0.254161 -1.143704  0.215897
9  1.193555 -0.077118 -0.408530 -0.862495

# break it into pieces
In [75]: pieces = [df[:3], df[3:7], df[7:]]

In [76]: pd.concat(pieces)
Out[76]: 
          0         1         2         3
0 -0.548702  1.467327 -1.015962 -0.483075
1  1.637550 -1.217659 -0.291519 -1.745505
2 -0.263952  0.991460 -0.919069  0.266046
3 -0.709661  1.669052  1.037882 -1.705775
4 -0.919854 -0.042379  1.247642 -0.009920
5  0.290213  0.495767  0.362949  1.548106
6 -1.131345 -0.089329  0.337863 -0.945867
7 -0.932132  1.956030  0.017587 -0.016692
8 -0.575247  0.254161 -1.143704  0.215897
9  1.193555 -0.077118 -0.408530 -0.862495

---->   pandas.DataFrame

--------------------------------------
ID: 2219 --> 1
In [77]: left = pd.DataFrame({"key": ["foo", "foo"], "lval": [1, 2]})

In [78]: right = pd.DataFrame({"key": ["foo", "foo"], "rval": [4, 5]})

In [79]: left
Out[79]: 
   key  lval
0  foo     1
1  foo     2

In [80]: right
Out[80]: 
   key  rval
0  foo     4
1  foo     5

In [81]: pd.merge(left, right, on="key")
Out[81]: 
   key  lval  rval
0  foo     1     4
1  foo     1     5
2  foo     2     4
3  foo     2     5

---->   pandas.DataFrame

--------------------------------------
ID: 2220 --> 1
In [82]: left = pd.DataFrame({"key": ["foo", "bar"], "lval": [1, 2]})

In [83]: right = pd.DataFrame({"key": ["foo", "bar"], "rval": [4, 5]})

In [84]: left
Out[84]: 
   key  lval
0  foo     1
1  bar     2

In [85]: right
Out[85]: 
   key  rval
0  foo     4
1  bar     5

In [86]: pd.merge(left, right, on="key")
Out[86]: 
   key  lval  rval
0  foo     1     4
1  bar     2     5

---->   pandas.DataFrame

--------------------------------------
ID: 2221 --> 1
In [87]: df = pd.DataFrame(
   ....:     {
   ....:         "A": ["foo", "bar", "foo", "bar", "foo", "bar", "foo", "foo"],
   ....:         "B": ["one", "one", "two", "three", "two", "two", "one", "three"],
   ....:         "C": np.random.randn(8),
   ....:         "D": np.random.randn(8),
   ....:     }
   ....: )
   ....: 

In [88]: df
Out[88]: 
     A      B         C         D
0  foo    one  1.346061 -1.577585
1  bar    one  1.511763  0.396823
2  foo    two  1.627081 -0.105381
3  bar  three -0.990582 -0.532532
4  foo    two -0.441652  1.453749
5  bar    two  1.211526  1.208843
6  foo    one  0.268520 -0.080952
7  foo  three  0.024580 -0.264610

---->   pandas.DataFrame

--------------------------------------
ID: 2222 --> 1
In [89]: df.groupby("A")[["C", "D"]].sum()
Out[89]: 
            C         D
A                      
bar  1.732707  1.073134
foo  2.824590 -0.574779

---->   DataFrame.groupby

--------------------------------------
ID: 2223 --> 1
In [90]: df.groupby(["A", "B"]).sum()
Out[90]: 
                  C         D
A   B                        
bar one    1.511763  0.396823
    three -0.990582 -0.532532
    two    1.211526  1.208843
foo one    1.614581 -1.658537
    three  0.024580 -0.264610
    two    1.185429  1.348368

---->   DataFrame.groupby

--------------------------------------
ID: 2224 --> 2
In [91]: tuples = list(
   ....:     zip(
   ....:         ["bar", "bar", "baz", "baz", "foo", "foo", "qux", "qux"],
   ....:         ["one", "two", "one", "two", "one", "two", "one", "two"],
   ....:     )
   ....: )
   ....: 

In [92]: index = pd.MultiIndex.from_tuples(tuples, names=["first", "second"])

In [93]: df = pd.DataFrame(np.random.randn(8, 2), index=index, columns=["A", "B"])

In [94]: df2 = df[:4]

In [95]: df2
Out[95]: 
                     A         B
first second                    
bar   one    -0.727965 -0.589346
      two     0.339969 -0.693205
baz   one    -0.339355  0.593616
      two     0.884345  1.591431

---->   pandas.MultiIndex; pandas.DataFrame

--------------------------------------
ID: 2225 --> 1
In [96]: stacked = df2.stack()

In [97]: stacked
Out[97]: 
first  second   
bar    one     A   -0.727965
               B   -0.589346
       two     A    0.339969
               B   -0.693205
baz    one     A   -0.339355
               B    0.593616
       two     A    0.884345
               B    1.591431
dtype: float64

---->   DataFrame.stack

--------------------------------------
ID: 2227 --> 1
In [101]: df = pd.DataFrame(
   .....:     {
   .....:         "A": ["one", "one", "two", "three"] * 3,
   .....:         "B": ["A", "B", "C"] * 4,
   .....:         "C": ["foo", "foo", "foo", "bar", "bar", "bar"] * 2,
   .....:         "D": np.random.randn(12),
   .....:         "E": np.random.randn(12),
   .....:     }
   .....: )
   .....: 

In [102]: df
Out[102]: 
        A  B    C         D         E
0     one  A  foo -1.202872  0.047609
1     one  B  foo -1.814470 -0.136473
2     two  C  foo  1.018601 -0.561757
3   three  A  bar -0.595447 -1.623033
4     one  B  bar  1.395433  0.029399
5     one  C  bar -0.392670 -0.542108
6     two  A  foo  0.007207  0.282696
7   three  B  foo  1.928123 -0.087302
8     one  C  foo -0.055224 -1.575170
9     one  A  bar  2.395985  1.771208
10    two  B  bar  1.552825  0.816482
11  three  C  bar  0.166599  1.100230

---->   pandas.DataFrame

--------------------------------------
ID: 2228 --> 1
In [103]: pd.pivot_table(df, values="D", index=["A", "B"], columns=["C"])
Out[103]: 
C             bar       foo
A     B                    
one   A  2.395985 -1.202872
      B  1.395433 -1.814470
      C -0.392670 -0.055224
three A -0.595447       NaN
      B       NaN  1.928123
      C  0.166599       NaN
two   A       NaN  0.007207
      B  1.552825       NaN
      C       NaN  1.018601

---->   pandas.pivot_table

--------------------------------------
ID: 2229 --> 2
In [104]: rng = pd.date_range("1/1/2012", periods=100, freq="S")

In [105]: ts = pd.Series(np.random.randint(0, 500, len(rng)), index=rng)

In [106]: ts.resample("5Min").sum()
Out[106]: 
2012-01-01    24182
Freq: 5T, dtype: int64

---->   pandas.Series; Series.resample

--------------------------------------
ID: 2230 --> 2
In [107]: rng = pd.date_range("3/6/2012 00:00", periods=5, freq="D")

In [108]: ts = pd.Series(np.random.randn(len(rng)), rng)

In [109]: ts
Out[109]: 
2012-03-06    1.857704
2012-03-07   -1.193545
2012-03-08    0.677510
2012-03-09   -0.153931
2012-03-10    0.520091
Freq: D, dtype: float64

In [110]: ts_utc = ts.tz_localize("UTC")

In [111]: ts_utc
Out[111]: 
2012-03-06 00:00:00+00:00    1.857704
2012-03-07 00:00:00+00:00   -1.193545
2012-03-08 00:00:00+00:00    0.677510
2012-03-09 00:00:00+00:00   -0.153931
2012-03-10 00:00:00+00:00    0.520091
Freq: D, dtype: float64

---->   pandas.Series; Series.tz_localize

--------------------------------------
ID: 2232 --> 2
In [113]: rng = pd.date_range("1/1/2012", periods=5, freq="M")

In [114]: ts = pd.Series(np.random.randn(len(rng)), index=rng)

In [115]: ts
Out[115]: 
2012-01-31   -1.475051
2012-02-29    0.722570
2012-03-31   -0.322646
2012-04-30   -1.601631
2012-05-31    0.778033
Freq: M, dtype: float64

In [116]: ps = ts.to_period()

In [117]: ps
Out[117]: 
2012-01   -1.475051
2012-02    0.722570
2012-03   -0.322646
2012-04   -1.601631
2012-05    0.778033
Freq: M, dtype: float64

In [118]: ps.to_timestamp()
Out[118]: 
2012-01-01   -1.475051
2012-02-01    0.722570
2012-03-01   -0.322646
2012-04-01   -1.601631
2012-05-01    0.778033
Freq: MS, dtype: float64

---->   pandas.Series; Series.to_period

--------------------------------------
ID: 2233 --> 3
In [119]: prng = pd.period_range("1990Q1", "2000Q4", freq="Q-NOV")

In [120]: ts = pd.Series(np.random.randn(len(prng)), prng)

In [121]: ts.index = (prng.asfreq("M", "e") + 1).asfreq("H", "s") + 9

In [122]: ts.head()
Out[122]: 
1990-03-01 09:00   -0.289342
1990-06-01 09:00    0.233141
1990-09-01 09:00   -0.223540
1990-12-01 09:00    0.542054
1991-03-01 09:00   -0.688585
Freq: H, dtype: float64

---->   pandas.period_range; pandas.Series; Series.head

--------------------------------------
ID: 2234 --> 1
In [123]: df = pd.DataFrame(
   .....:     {"id": [1, 2, 3, 4, 5, 6], "raw_grade": ["a", "b", "b", "a", "a", "e"]}
   .....: )
   .....: 

---->   pandas.DataFrame

--------------------------------------
ID: 2239 --> 1
In [131]: df.groupby("grade").size()
Out[131]: 
grade
very bad     1
bad          0
medium       0
good         2
very good    3
dtype: int64

---->   DataFrame.groupby

--------------------------------------
ID: 2241 --> 3
In [134]: ts = pd.Series(np.random.randn(1000), index=pd.date_range("1/1/2000", periods=1000))

In [135]: ts = ts.cumsum()

In [136]: ts.plot();

---->   pandas.Series; Series.cumsum; Series.plot

--------------------------------------
ID: 2243 --> 3
In [138]: df = pd.DataFrame(
   .....:     np.random.randn(1000, 4), index=ts.index, columns=["A", "B", "C", "D"]
   .....: )
   .....: 

In [139]: df = df.cumsum()

In [140]: plt.figure();

In [141]: df.plot();

In [142]: plt.legend(loc='best');

---->   pandas.DataFrame; DataFrame.cumsum; DataFrame.plot

--------------------------------------
ID: 2244 --> 1
In [143]: df.to_csv("foo.csv")

---->   DataFrame.to_csv

--------------------------------------
ID: 2246 --> 1
In [145]: df.to_hdf("foo.h5", "df")

---->   DataFrame.to_hdf

--------------------------------------
ID: 2247 --> 1
In [146]: pd.read_hdf("foo.h5", "df")
Out[146]: 
                    A          B          C          D
2000-01-01   0.350262   0.843315   1.798556   0.782234
2000-01-02  -0.586873   0.034907   1.923792  -0.562651
2000-01-03  -1.245477  -0.963406   2.269575  -1.612566
2000-01-04  -0.252830  -0.498066   3.176886  -1.275581
2000-01-05  -1.044057   0.118042   2.768571   0.386039
...               ...        ...        ...        ...
2002-09-22 -48.017654  31.474551  69.146374 -47.541670
2002-09-23 -47.207912  32.627390  68.505254 -48.828331
2002-09-24 -48.907133  31.990402  67.310924 -49.391051
2002-09-25 -50.146062  33.716770  67.717434 -49.037577
2002-09-26 -49.724318  33.479952  68.108014 -48.822030

[1000 rows x 4 columns]

---->   pandas.read_hdf

--------------------------------------
ID: 2248 --> 1
In [147]: df.to_excel("foo.xlsx", sheet_name="Sheet1")

---->   DataFrame.to_excel

--------------------------------------
ID: 2250 --> 4
In [149]: if pd.Series([False, True, False]):
   .....:      print("I was true")
   .....: 
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
 in ?()
----> 1 if pd.Series([False, True, False]):
      2      print("I was true")

~/work/pandas/pandas/pandas/core/generic.py in ?(self)
   1464     @final
   1465     def __nonzero__(self) -> NoReturn:
-> 1466         raise ValueError(
   1467             f"The truth value of a {type(self).__name__} is ambiguous. "
   1468             "Use a.empty, a.bool(), a.item(), a.any() or a.all()."
   1469         )

ValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().

---->   pandas.Series; Index.item; Index.any; Index.all

--------------------------------------
ID: 2251 --> 1
In [1]: df = pd.DataFrame({"foo": [1, 2, 3], "bar": [4, 5, 6]})

In [2]: subset = df["foo"]

In [3]: subset.iloc[0] = 100

In [4]: df
Out[4]: 
   foo  bar
0  100    4
1    2    5
2    3    6

---->   pandas.DataFrame

--------------------------------------
ID: 2252 --> 1
In [5]: pd.options.mode.copy_on_write = True

In [6]: df = pd.DataFrame({"foo": [1, 2, 3], "bar": [4, 5, 6]})

In [7]: subset = df["foo"]

In [8]: subset.iloc[0] = 100

In [9]: df
Out[9]: 
   foo  bar
0    1    4
1    2    5
2    3    6

---->   pandas.DataFrame

--------------------------------------
ID: 2253 --> 1
In [10]: df = pd.DataFrame({"foo": [1, 2, 3], "bar": [4, 5, 6]})

In [11]: df.iloc[0, 0] = 100

In [12]: df
Out[12]: 
   foo  bar
0  100    4
1    2    5
2    3    6

---->   pandas.DataFrame

--------------------------------------
ID: 2254 --> 1
In [13]: df = pd.DataFrame({"foo": [1, 2, 3], "bar": [4, 5, 6]})

In [14]: df2 = df.reset_index(drop=True)

In [15]: df2.iloc[0, 0] = 100

In [16]: df
Out[16]: 
   foo  bar
0    1    4
1    2    5
2    3    6

In [17]: df2
Out[17]: 
   foo  bar
0  100    4
1    2    5
2    3    6

---->   pandas.DataFrame

--------------------------------------
ID: 2255 --> 1
In [18]: df = pd.DataFrame({"foo": [1, 2, 3], "bar": [4, 5, 6]})

In [19]: df = df.reset_index(drop=True)

In [20]: df.iloc[0, 0] = 100

In [21]: df
Out[21]: 
   foo  bar
0  100    4
1    2    5
2    3    6

---->   pandas.DataFrame

--------------------------------------
ID: 2256 --> 1
In [22]: with pd.option_context("mode.copy_on_write", False):
   ....:     df = pd.DataFrame({"foo": [1, 2, 3], "bar": [4, 5, 6]})
   ....:     view = df[:]
   ....:     df.iloc[0, 0] = 100
   ....: 

In [23]: df
Out[23]: 
   foo  bar
0  100    4
1    2    5
2    3    6

In [24]: view
Out[24]: 
   foo  bar
0  100    4
1    2    5
2    3    6

---->   pandas.DataFrame

--------------------------------------
ID: 2257 --> 1
In [25]: df = pd.DataFrame({"foo": [1, 2, 3], "bar": [4, 5, 6]})

In [26]: view = df[:]

In [27]: df.iloc[0, 0] = 100

In [28]: df
Out[28]: 
   foo  bar
0  100    4
1    2    5
2    3    6

In [29]: view
Out[29]: 
   foo  bar
0    1    4
1    2    5
2    3    6

---->   pandas.DataFrame

--------------------------------------
ID: 2258 --> 1
In [30]: with pd.option_context("mode.copy_on_write", False):
   ....:     df = pd.DataFrame({"foo": [1, 2, 3], "bar": [4, 5, 6]})
   ....:     df["foo"][df["bar"] > 5] = 100
   ....:     df
   ....: 

---->   pandas.DataFrame

--------------------------------------
ID: 2259 --> 1
In [31]: df = pd.DataFrame({"foo": [1, 2, 3], "bar": [4, 5, 6]})

In [32]: df["foo"][df["bar"] > 5] = 100

---->   pandas.DataFrame

--------------------------------------
ID: 2264 --> 1
In [17]: pd.to_timedelta("1 days 06:05:01.00003")
Out[17]: Timedelta('1 days 06:05:01.000030')

In [18]: pd.to_timedelta("15.5us")
Out[18]: Timedelta('0 days 00:00:00.000015500')

---->   pandas.to_timedelta

--------------------------------------
ID: 2265 --> 1
In [19]: pd.to_timedelta(["1 days 06:05:01.00003", "15.5us", "nan"])
Out[19]: TimedeltaIndex(['1 days 06:05:01.000030', '0 days 00:00:00.000015500', NaT], dtype='timedelta64[ns]', freq=None)

---->   pandas.to_timedelta

--------------------------------------
ID: 2266 --> 1
In [20]: pd.to_timedelta(np.arange(5), unit="s")
Out[20]: 
TimedeltaIndex(['0 days 00:00:00', '0 days 00:00:01', '0 days 00:00:02',
                '0 days 00:00:03', '0 days 00:00:04'],
               dtype='timedelta64[ns]', freq=None)

In [21]: pd.to_timedelta(np.arange(5), unit="d")
Out[21]: TimedeltaIndex(['0 days', '1 days', '2 days', '3 days', '4 days'], dtype='timedelta64[ns]', freq=None)

---->   pandas.to_timedelta

--------------------------------------
ID: 2268 --> 3
In [24]: s = pd.Series(pd.date_range("2012-1-1", periods=3, freq="D"))

In [25]: td = pd.Series([pd.Timedelta(days=i) for i in range(3)])

In [26]: df = pd.DataFrame({"A": s, "B": td})

In [27]: df
Out[27]: 
           A      B
0 2012-01-01 0 days
1 2012-01-02 1 days
2 2012-01-03 2 days

In [28]: df["C"] = df["A"] + df["B"]

In [29]: df
Out[29]: 
           A      B          C
0 2012-01-01 0 days 2012-01-01
1 2012-01-02 1 days 2012-01-03
2 2012-01-03 2 days 2012-01-05

In [30]: df.dtypes
Out[30]: 
A     datetime64[ns]
B    timedelta64[ns]
C     datetime64[ns]
dtype: object

In [31]: s - s.max()
Out[31]: 
0   -2 days
1   -1 days
2    0 days
dtype: timedelta64[ns]

In [32]: s - datetime.datetime(2011, 1, 1, 3, 5)
Out[32]: 
0   364 days 20:55:00
1   365 days 20:55:00
2   366 days 20:55:00
dtype: timedelta64[ns]

In [33]: s + datetime.timedelta(minutes=5)
Out[33]: 
0   2012-01-01 00:05:00
1   2012-01-02 00:05:00
2   2012-01-03 00:05:00
dtype: datetime64[ns]

In [34]: s + pd.offsets.Minute(5)
Out[34]: 
0   2012-01-01 00:05:00
1   2012-01-02 00:05:00
2   2012-01-03 00:05:00
dtype: datetime64[ns]

In [35]: s + pd.offsets.Minute(5) + pd.offsets.Milli(5)
Out[35]: 
0   2012-01-01 00:05:00.005
1   2012-01-02 00:05:00.005
2   2012-01-03 00:05:00.005
dtype: datetime64[ns]

---->   pandas.Series; pandas.DataFrame; Series.max

--------------------------------------
ID: 2269 --> 1
In [38]: y = s - s.shift()

In [39]: y
Out[39]: 
0      NaT
1   1 days
2   1 days
dtype: timedelta64[ns]

---->   Series.shift

--------------------------------------
ID: 2270 --> 1
In [42]: s.max() - s
Out[42]: 
0   2 days
1   1 days
2   0 days
dtype: timedelta64[ns]

In [43]: datetime.datetime(2011, 1, 1, 3, 5) - s
Out[43]: 
0   -365 days +03:05:00
1   -366 days +03:05:00
2   -367 days +03:05:00
dtype: timedelta64[ns]

In [44]: datetime.timedelta(minutes=5) + s
Out[44]: 
0   2012-01-01 00:05:00
1   2012-01-02 00:05:00
2   2012-01-03 00:05:00
dtype: datetime64[ns]

---->   Series.max

--------------------------------------
ID: 2271 --> 5
In [45]: A = s - pd.Timestamp("20120101") - pd.Timedelta("00:05:05")

In [46]: B = s - pd.Series(pd.date_range("2012-1-2", periods=3, freq="D"))

In [47]: df = pd.DataFrame({"A": A, "B": B})

In [48]: df
Out[48]: 
                  A       B
0 -1 days +23:54:55 -1 days
1   0 days 23:54:55 -1 days
2   1 days 23:54:55 -1 days

In [49]: df.min()
Out[49]: 
A   -1 days +23:54:55
B   -1 days +00:00:00
dtype: timedelta64[ns]

In [50]: df.min(axis=1)
Out[50]: 
0   -1 days
1   -1 days
2   -1 days
dtype: timedelta64[ns]

In [51]: df.idxmin()
Out[51]: 
A    0
B    0
dtype: int64

In [52]: df.idxmax()
Out[52]: 
A    2
B    0
dtype: int64

---->   pandas.Series; pandas.DataFrame; DataFrame.min; DataFrame.idxmin; DataFrame.idxmax

--------------------------------------
ID: 2272 --> 1
In [53]: df.min().max()
Out[53]: Timedelta('-1 days +23:54:55')

In [54]: df.min(axis=1).min()
Out[54]: Timedelta('-1 days +00:00:00')

In [55]: df.min().idxmax()
Out[55]: 'A'

In [56]: df.min(axis=1).idxmin()
Out[56]: 0

---->   DataFrame.min

--------------------------------------
ID: 2275 --> 2
In [65]: y2 = pd.Series(
   ....:     pd.to_timedelta(["-1 days +00:00:05", "nat", "-1 days +00:00:05", "1 days"])
   ....: )
   ....: 

In [66]: y2
Out[66]: 
0   -1 days +00:00:05
1                 NaT
2   -1 days +00:00:05
3     1 days 00:00:00
dtype: timedelta64[ns]

In [67]: y2.mean()
Out[67]: Timedelta('-1 days +16:00:03.333333334')

In [68]: y2.median()
Out[68]: Timedelta('-1 days +00:00:05')

In [69]: y2.quantile(0.1)
Out[69]: Timedelta('-1 days +00:00:05')

In [70]: y2.sum()
Out[70]: Timedelta('-1 days +00:00:10')

---->   pandas.Series; pandas.to_timedelta

--------------------------------------
ID: 2276 --> 2
In [71]: december = pd.Series(pd.date_range("20121201", periods=4))

In [72]: january = pd.Series(pd.date_range("20130101", periods=4))

In [73]: td = january - december

In [74]: td[2] += datetime.timedelta(minutes=5, seconds=3)

In [75]: td[3] = np.nan

In [76]: td
Out[76]: 
0   31 days 00:00:00
1   31 days 00:00:00
2   31 days 00:05:03
3                NaT
dtype: timedelta64[ns]

# to seconds
In [77]: td.astype("timedelta64[s]")
Out[77]: 
0   31 days 00:00:00
1   31 days 00:00:00
2   31 days 00:05:03
3                NaT
dtype: timedelta64[s]

---->   pandas.Series; Series.astype

--------------------------------------
ID: 2278 --> 1
In [80]: td * -1
Out[80]: 
0   -31 days +00:00:00
1   -31 days +00:00:00
2   -32 days +23:54:57
3                  NaT
dtype: timedelta64[ns]

In [81]: td * pd.Series([1, 2, 3, 4])
Out[81]: 
0   31 days 00:00:00
1   62 days 00:00:00
2   93 days 00:15:09
3                NaT
dtype: timedelta64[ns]

---->   pandas.Series

--------------------------------------
ID: 2283 --> 1
In [96]: pd.TimedeltaIndex(
   ....:     [
   ....:         "1 days",
   ....:         "1 days, 00:00:05",
   ....:         np.timedelta64(2, "D"),
   ....:         datetime.timedelta(days=2, seconds=2),
   ....:     ]
   ....: )
   ....: 
Out[96]: 
TimedeltaIndex(['1 days 00:00:00', '1 days 00:00:05', '2 days 00:00:00',
                '2 days 00:00:02'],
               dtype='timedelta64[ns]', freq=None)

---->   pandas.TimedeltaIndex

--------------------------------------
ID: 2284 --> 1
In [97]: pd.TimedeltaIndex(["0 days", "10 days", "20 days"], freq="infer")
Out[97]: TimedeltaIndex(['0 days', '10 days', '20 days'], dtype='timedelta64[ns]', freq='10D')

---->   pandas.TimedeltaIndex

--------------------------------------
ID: 2289 --> 1
In [105]: s = pd.Series(
   .....:     np.arange(100),
   .....:     index=pd.timedelta_range("1 days", periods=100, freq="h"),
   .....: )
   .....: 

In [106]: s
Out[106]: 
1 days 00:00:00     0
1 days 01:00:00     1
1 days 02:00:00     2
1 days 03:00:00     3
1 days 04:00:00     4
                   ..
4 days 23:00:00    95
5 days 00:00:00    96
5 days 01:00:00    97
5 days 02:00:00    98
5 days 03:00:00    99
Freq: H, Length: 100, dtype: int64

---->   pandas.Series

--------------------------------------
ID: 2291 --> 1
In [111]: tdi = pd.TimedeltaIndex(["1 days", pd.NaT, "2 days"])

In [112]: tdi.to_list()
Out[112]: [Timedelta('1 days 00:00:00'), NaT, Timedelta('2 days 00:00:00')]

In [113]: dti = pd.date_range("20130101", periods=3)

In [114]: dti.to_list()
Out[114]: 
[Timestamp('2013-01-01 00:00:00'),
 Timestamp('2013-01-02 00:00:00'),
 Timestamp('2013-01-03 00:00:00')]

In [115]: (dti + tdi).to_list()
Out[115]: [Timestamp('2013-01-02 00:00:00'), NaT, Timestamp('2013-01-05 00:00:00')]

In [116]: (dti - tdi).to_list()
Out[116]: [Timestamp('2012-12-31 00:00:00'), NaT, Timestamp('2013-01-01 00:00:00')]

---->   pandas.TimedeltaIndex

--------------------------------------
ID: 2294 --> 1
In [124]: s.resample("D").mean()
Out[124]: 
1 days    11.5
2 days    35.5
3 days    59.5
4 days    83.5
5 days    97.5
Freq: D, dtype: float64

---->   Series.resample

--------------------------------------
ID: 2295 --> 1
In [1]: s = pd.Series(["a", "b", "c", "a"], dtype="category")

In [2]: s
Out[2]: 
0    a
1    b
2    c
3    a
dtype: category
Categories (3, object): ['a', 'b', 'c']

---->   pandas.Series

--------------------------------------
ID: 2296 --> 1
In [3]: df = pd.DataFrame({"A": ["a", "b", "c", "a"]})

In [4]: df["B"] = df["A"].astype("category")

In [5]: df
Out[5]: 
   A  B
0  a  a
1  b  b
2  c  c
3  a  a

---->   pandas.DataFrame

--------------------------------------
ID: 2297 --> 3
In [6]: df = pd.DataFrame({"value": np.random.randint(0, 100, 20)})

In [7]: labels = ["{0} - {1}".format(i, i + 9) for i in range(0, 100, 10)]

In [8]: df["group"] = pd.cut(df.value, range(0, 105, 10), right=False, labels=labels)

In [9]: df.head(10)
Out[9]: 
   value    group
0     65  60 - 69
1     49  40 - 49
2     56  50 - 59
3     43  40 - 49
4     43  40 - 49
5     91  90 - 99
6     32  30 - 39
7     87  80 - 89
8     36  30 - 39
9      8    0 - 9

---->   pandas.DataFrame; pandas.cut; DataFrame.head

--------------------------------------
ID: 2298 --> 3
In [10]: raw_cat = pd.Categorical(
   ....:     ["a", "b", "c", "a"], categories=["b", "c", "d"], ordered=False
   ....: )
   ....: 

In [11]: s = pd.Series(raw_cat)

In [12]: s
Out[12]: 
0    NaN
1      b
2      c
3    NaN
dtype: category
Categories (3, object): ['b', 'c', 'd']

In [13]: df = pd.DataFrame({"A": ["a", "b", "c", "a"]})

In [14]: df["B"] = raw_cat

In [15]: df
Out[15]: 
   A    B
0  a  NaN
1  b    b
2  c    c
3  a  NaN

---->   pandas.Categorical; pandas.Series; pandas.DataFrame

--------------------------------------
ID: 2299 --> 1
In [17]: df = pd.DataFrame({"A": list("abca"), "B": list("bccd")}, dtype="category")

In [18]: df.dtypes
Out[18]: 
A    category
B    category
dtype: object

---->   pandas.DataFrame

--------------------------------------
ID: 2301 --> 2
In [21]: df = pd.DataFrame({"A": list("abca"), "B": list("bccd")})

In [22]: df_cat = df.astype("category")

In [23]: df_cat.dtypes
Out[23]: 
A    category
B    category
dtype: object

---->   pandas.DataFrame; DataFrame.astype

--------------------------------------
ID: 2303 --> 2
In [26]: from pandas.api.types import CategoricalDtype

In [27]: s = pd.Series(["a", "b", "c", "a"])

In [28]: cat_type = CategoricalDtype(categories=["b", "c", "d"], ordered=True)

In [29]: s_cat = s.astype(cat_type)

In [30]: s_cat
Out[30]: 
0    NaN
1      b
2      c
3    NaN
dtype: category
Categories (3, object): ['b' < 'c' < 'd']

---->   pandas.Series; Series.astype

--------------------------------------
ID: 2304 --> 2
In [31]: from pandas.api.types import CategoricalDtype

In [32]: df = pd.DataFrame({"A": list("abca"), "B": list("bccd")})

In [33]: cat_type = CategoricalDtype(categories=list("abcd"), ordered=True)

In [34]: df_cat = df.astype(cat_type)

In [35]: df_cat["A"]
Out[35]: 
0    a
1    b
2    c
3    a
Name: A, dtype: category
Categories (4, object): ['a' < 'b' < 'c' < 'd']

In [36]: df_cat["B"]
Out[36]: 
0    b
1    c
2    c
3    d
Name: B, dtype: category
Categories (4, object): ['a' < 'b' < 'c' < 'd']

---->   pandas.DataFrame; DataFrame.astype

--------------------------------------
ID: 2305 --> 2
In [37]: splitter = np.random.choice([0, 1], 5, p=[0.5, 0.5])

In [38]: s = pd.Series(pd.Categorical.from_codes(splitter, categories=["train", "test"]))

---->   pandas.Series; pandas.Categorical

--------------------------------------
ID: 2306 --> 3
In [39]: s = pd.Series(["a", "b", "c", "a"])

In [40]: s
Out[40]: 
0    a
1    b
2    c
3    a
dtype: object

In [41]: s2 = s.astype("category")

In [42]: s2
Out[42]: 
0    a
1    b
2    c
3    a
dtype: category
Categories (3, object): ['a', 'b', 'c']

In [43]: s2.astype(str)
Out[43]: 
0    a
1    b
2    c
3    a
dtype: object

In [44]: np.asarray(s2)
Out[44]: array(['a', 'b', 'c', 'a'], dtype=object)

---->   pandas.Series; Series.astype; Series.astype

--------------------------------------
ID: 2309 --> 3
In [53]: cat = pd.Categorical(["a", "c", "c", np.nan], categories=["b", "a", "c"])

In [54]: df = pd.DataFrame({"cat": cat, "s": ["a", "c", "c", np.nan]})

In [55]: df.describe()
Out[55]: 
       cat  s
count    3  3
unique   2  2
top      c  c
freq     2  2

In [56]: df["cat"].describe()
Out[56]: 
count     3
unique    2
top       c
freq      2
Name: cat, dtype: object

---->   pandas.Categorical; pandas.DataFrame; DataFrame.describe

--------------------------------------
ID: 2310 --> 1
In [57]: s = pd.Series(["a", "b", "c", "a"], dtype="category")

In [58]: s.cat.categories
Out[58]: Index(['a', 'b', 'c'], dtype='object')

In [59]: s.cat.ordered
Out[59]: False

---->   pandas.Series

--------------------------------------
ID: 2311 --> 2
In [60]: s = pd.Series(pd.Categorical(["a", "b", "c", "a"], categories=["c", "b", "a"]))

In [61]: s.cat.categories
Out[61]: Index(['c', 'b', 'a'], dtype='object')

In [62]: s.cat.ordered
Out[62]: False

---->   pandas.Series; pandas.Categorical

--------------------------------------
ID: 2312 --> 2
In [63]: s = pd.Series(list("babc")).astype(CategoricalDtype(list("abcd")))

In [64]: s
Out[64]: 
0    b
1    a
2    b
3    c
dtype: category
Categories (4, object): ['a', 'b', 'c', 'd']

# categories
In [65]: s.cat.categories
Out[65]: Index(['a', 'b', 'c', 'd'], dtype='object')

# uniques
In [66]: s.unique()
Out[66]: 
['b', 'a', 'c']
Categories (4, object): ['a', 'b', 'c', 'd']

---->   pandas.Series; Series.unique

--------------------------------------
ID: 2313 --> 1
In [67]: s = pd.Series(["a", "b", "c", "a"], dtype="category")

In [68]: s
Out[68]: 
0    a
1    b
2    c
3    a
dtype: category
Categories (3, object): ['a', 'b', 'c']

In [69]: new_categories = ["Group %s" % g for g in s.cat.categories]

In [70]: s = s.cat.rename_categories(new_categories)

In [71]: s
Out[71]: 
0    Group a
1    Group b
2    Group c
3    Group a
dtype: category
Categories (3, object): ['Group a', 'Group b', 'Group c']

# You can also pass a dict-like object to map the renaming
In [72]: s = s.cat.rename_categories({1: "x", 2: "y", 3: "z"})

In [73]: s
Out[73]: 
0    Group a
1    Group b
2    Group c
3    Group a
dtype: category
Categories (3, object): ['Group a', 'Group b', 'Group c']

---->   pandas.Series

--------------------------------------
ID: 2318 --> 2
In [81]: s = pd.Series(pd.Categorical(["a", "b", "a"], categories=["a", "b", "c", "d"]))

In [82]: s
Out[82]: 
0    a
1    b
2    a
dtype: category
Categories (4, object): ['a', 'b', 'c', 'd']

In [83]: s.cat.remove_unused_categories()
Out[83]: 
0    a
1    b
2    a
dtype: category
Categories (2, object): ['a', 'b']

---->   pandas.Series; pandas.Categorical

--------------------------------------
ID: 2319 --> 1
In [84]: s = pd.Series(["one", "two", "four", "-"], dtype="category")

In [85]: s
Out[85]: 
0     one
1     two
2    four
3       -
dtype: category
Categories (4, object): ['-', 'four', 'one', 'two']

In [86]: s = s.cat.set_categories(["one", "two", "three", "four"])

In [87]: s
Out[87]: 
0     one
1     two
2    four
3     NaN
dtype: category
Categories (4, object): ['one', 'two', 'three', 'four']

---->   pandas.Series

--------------------------------------
ID: 2320 --> 4
In [88]: s = pd.Series(pd.Categorical(["a", "b", "c", "a"], ordered=False))

In [89]: s = s.sort_values()

In [90]: s = pd.Series(["a", "b", "c", "a"]).astype(CategoricalDtype(ordered=True))

In [91]: s = s.sort_values()

In [92]: s
Out[92]: 
0    a
3    a
1    b
2    c
dtype: category
Categories (3, object): ['a' < 'b' < 'c']

In [93]: s.min(), s.max()
Out[93]: ('a', 'c')

---->   pandas.Series; pandas.Categorical; Series.min; Series.max

--------------------------------------
ID: 2322 --> 3
In [96]: s = pd.Series([1, 2, 3, 1], dtype="category")

In [97]: s = s.cat.set_categories([2, 3, 1], ordered=True)

In [98]: s
Out[98]: 
0    1
1    2
2    3
3    1
dtype: category
Categories (3, int64): [2 < 3 < 1]

In [99]: s = s.sort_values()

In [100]: s
Out[100]: 
1    2
2    3
0    1
3    1
dtype: category
Categories (3, int64): [2 < 3 < 1]

In [101]: s.min(), s.max()
Out[101]: (2, 1)

---->   pandas.Series; Series.min; Series.max

--------------------------------------
ID: 2323 --> 3
In [102]: s = pd.Series([1, 2, 3, 1], dtype="category")

In [103]: s = s.cat.reorder_categories([2, 3, 1], ordered=True)

In [104]: s
Out[104]: 
0    1
1    2
2    3
3    1
dtype: category
Categories (3, int64): [2 < 3 < 1]

In [105]: s = s.sort_values()

In [106]: s
Out[106]: 
1    2
2    3
0    1
3    1
dtype: category
Categories (3, int64): [2 < 3 < 1]

In [107]: s.min(), s.max()
Out[107]: (2, 1)

---->   pandas.Series; Series.min; Series.max

--------------------------------------
ID: 2324 --> 2
In [108]: dfs = pd.DataFrame(
   .....:     {
   .....:         "A": pd.Categorical(
   .....:             list("bbeebbaa"),
   .....:             categories=["e", "a", "b"],
   .....:             ordered=True,
   .....:         ),
   .....:         "B": [1, 2, 1, 2, 2, 1, 2, 1],
   .....:     }
   .....: )
   .....: 

In [109]: dfs.sort_values(by=["A", "B"])
Out[109]: 
   A  B
2  e  1
3  e  2
7  a  1
6  a  2
0  b  1
5  b  1
1  b  2
4  b  2

---->   pandas.DataFrame; pandas.Categorical

--------------------------------------
ID: 2326 --> 1
In [112]: cat = pd.Series([1, 2, 3]).astype(CategoricalDtype([3, 2, 1], ordered=True))

In [113]: cat_base = pd.Series([2, 2, 2]).astype(CategoricalDtype([3, 2, 1], ordered=True))

In [114]: cat_base2 = pd.Series([2, 2, 2]).astype(CategoricalDtype(ordered=True))

In [115]: cat
Out[115]: 
0    1
1    2
2    3
dtype: category
Categories (3, int64): [3 < 2 < 1]

In [116]: cat_base
Out[116]: 
0    2
1    2
2    2
dtype: category
Categories (3, int64): [3 < 2 < 1]

In [117]: cat_base2
Out[117]: 
0    2
1    2
2    2
dtype: category
Categories (1, int64): [2]

---->   pandas.Series

--------------------------------------
ID: 2330 --> 1
In [127]: c1 = pd.Categorical(["a", "b"], categories=["a", "b"], ordered=False)

In [128]: c2 = pd.Categorical(["a", "b"], categories=["b", "a"], ordered=False)

In [129]: c1 == c2
Out[129]: array([ True,  True])

---->   pandas.Categorical

--------------------------------------
ID: 2331 --> 3
In [130]: s = pd.Series(pd.Categorical(["a", "b", "c", "c"], categories=["c", "a", "b", "d"]))

In [131]: s.value_counts()
Out[131]: 
c    2
a    1
b    1
d    0
Name: count, dtype: int64

---->   pandas.Series; pandas.Categorical; Series.value_counts

--------------------------------------
ID: 2332 --> 4
In [132]: columns = pd.Categorical(
   .....:     ["One", "One", "Two"], categories=["One", "Two", "Three"], ordered=True
   .....: )
   .....: 

In [133]: df = pd.DataFrame(
   .....:     data=[[1, 2, 3], [4, 5, 6]],
   .....:     columns=pd.MultiIndex.from_arrays([["A", "B", "B"], columns]),
   .....: )
   .....: 

In [134]: df.groupby(axis=1, level=1).sum()
Out[134]: 
   One  Two  Three
0    3    3      0
1    9    6      0

---->   pandas.Categorical; pandas.DataFrame; pandas.MultiIndex; DataFrame.groupby

--------------------------------------
ID: 2333 --> 4
In [135]: cats = pd.Categorical(
   .....:     ["a", "b", "b", "b", "c", "c", "c"], categories=["a", "b", "c", "d"]
   .....: )
   .....: 

In [136]: df = pd.DataFrame({"cats": cats, "values": [1, 2, 2, 2, 3, 4, 5]})

In [137]: df.groupby("cats").mean()
Out[137]: 
      values
cats        
a        1.0
b        2.0
c        4.0
d        NaN

In [138]: cats2 = pd.Categorical(["a", "a", "b", "b"], categories=["a", "b", "c"])

In [139]: df2 = pd.DataFrame(
   .....:     {
   .....:         "cats": cats2,
   .....:         "B": ["c", "d", "c", "d"],
   .....:         "values": [1, 2, 3, 4],
   .....:     }
   .....: )
   .....: 

In [140]: df2.groupby(["cats", "B"]).mean()
Out[140]: 
        values
cats B        
a    c     1.0
     d     2.0
b    c     3.0
     d     4.0
c    c     NaN
     d     NaN

---->   pandas.Categorical; pandas.DataFrame; DataFrame.groupby; DataFrame.groupby

--------------------------------------
ID: 2334 --> 3
In [141]: raw_cat = pd.Categorical(["a", "a", "b", "b"], categories=["a", "b", "c"])

In [142]: df = pd.DataFrame({"A": raw_cat, "B": ["c", "d", "c", "d"], "values": [1, 2, 3, 4]})

In [143]: pd.pivot_table(df, values="values", index=["A", "B"])
Out[143]: 
     values
A B        
a c       1
  d       2
b c       3
  d       4

---->   pandas.Categorical; pandas.DataFrame; pandas.pivot_table

--------------------------------------
ID: 2335 --> 3
In [144]: idx = pd.Index(["h", "i", "j", "k", "l", "m", "n"])

In [145]: cats = pd.Series(["a", "b", "b", "b", "c", "c", "c"], dtype="category", index=idx)

In [146]: values = [1, 2, 2, 2, 3, 4, 5]

In [147]: df = pd.DataFrame({"cats": cats, "values": values}, index=idx)

In [148]: df.iloc[2:4, :]
Out[148]: 
  cats  values
j    b       2
k    b       2

In [149]: df.iloc[2:4, :].dtypes
Out[149]: 
cats      category
values       int64
dtype: object

In [150]: df.loc["h":"j", "cats"]
Out[150]: 
h    a
i    b
j    b
Name: cats, dtype: category
Categories (3, object): ['a', 'b', 'c']

In [151]: df[df["cats"] == "b"]
Out[151]: 
  cats  values
i    b       2
j    b       2
k    b       2

---->   pandas.Index; pandas.Series; pandas.DataFrame

--------------------------------------
ID: 2338 --> 3
In [157]: str_s = pd.Series(list("aabb"))

In [158]: str_cat = str_s.astype("category")

In [159]: str_cat
Out[159]: 
0    a
1    a
2    b
3    b
dtype: category
Categories (2, object): ['a', 'b']

In [160]: str_cat.str.contains("a")
Out[160]: 
0     True
1     True
2    False
3    False
dtype: bool

In [161]: date_s = pd.Series(pd.date_range("1/1/2015", periods=5))

In [162]: date_cat = date_s.astype("category")

In [163]: date_cat
Out[163]: 
0   2015-01-01
1   2015-01-02
2   2015-01-03
3   2015-01-04
4   2015-01-05
dtype: category
Categories (5, datetime64[ns]): [2015-01-01, 2015-01-02, 2015-01-03, 2015-01-04, 2015-01-05]

In [164]: date_cat.dt.day
Out[164]: 
0    1
1    2
2    3
3    4
4    5
dtype: int32

---->   pandas.Series; Series.astype; Series.astype

--------------------------------------
ID: 2340 --> 3
In [169]: idx = pd.Index(["h", "i", "j", "k", "l", "m", "n"])

In [170]: cats = pd.Categorical(["a", "a", "a", "a", "a", "a", "a"], categories=["a", "b"])

In [171]: values = [1, 1, 1, 1, 1, 1, 1]

In [172]: df = pd.DataFrame({"cats": cats, "values": values}, index=idx)

In [173]: df.iloc[2:4, :] = [["b", 2], ["b", 2]]

In [174]: df
Out[174]: 
  cats  values
h    a       1
i    a       1
j    b       2
k    b       2
l    a       1
m    a       1
n    a       1

In [175]: try:
   .....:     df.iloc[2:4, :] = [["c", 3], ["c", 3]]
   .....: except TypeError as e:
   .....:     print("TypeError:", str(e))
   .....: 
TypeError: Cannot setitem on a Categorical with a new category, set the categories first

---->   pandas.Index; pandas.Categorical; pandas.DataFrame

--------------------------------------
ID: 2341 --> 1
In [176]: df.loc["j":"k", "cats"] = pd.Categorical(["a", "a"], categories=["a", "b"])

In [177]: df
Out[177]: 
  cats  values
h    a       1
i    a       1
j    a       2
k    a       2
l    a       1
m    a       1
n    a       1

In [178]: try:
   .....:     df.loc["j":"k", "cats"] = pd.Categorical(["b", "b"], categories=["a", "b", "c"])
   .....: except TypeError as e:
   .....:     print("TypeError:", str(e))
   .....: 
TypeError: Cannot set a Categorical with another, without identical categories

---->   pandas.Categorical

--------------------------------------
ID: 2342 --> 2
In [179]: df = pd.DataFrame({"a": [1, 1, 1, 1, 1], "b": ["a", "a", "a", "a", "a"]})

In [180]: df.loc[1:2, "a"] = pd.Categorical(["b", "b"], categories=["a", "b"])

In [181]: df.loc[2:3, "b"] = pd.Categorical(["b", "b"], categories=["a", "b"])

In [182]: df
Out[182]: 
   a  b
0  1  a
1  b  a
2  b  b
3  1  b
4  1  a

In [183]: df.dtypes
Out[183]: 
a    object
b    object
dtype: object

---->   pandas.DataFrame; pandas.Categorical

--------------------------------------
ID: 2343 --> 1
In [184]: from pandas.api.types import union_categoricals

# same categories
In [185]: s1 = pd.Series(["a", "b"], dtype="category")

In [186]: s2 = pd.Series(["a", "b", "a"], dtype="category")

In [187]: pd.concat([s1, s2])
Out[187]: 
0    a
1    b
0    a
1    b
2    a
dtype: category
Categories (2, object): ['a', 'b']

# different categories
In [188]: s3 = pd.Series(["b", "c"], dtype="category")

In [189]: pd.concat([s1, s3])
Out[189]: 
0    a
1    b
0    b
1    c
dtype: object

# Output dtype is inferred based on categories values
In [190]: int_cats = pd.Series([1, 2], dtype="category")

In [191]: float_cats = pd.Series([3.0, 4.0], dtype="category")

In [192]: pd.concat([int_cats, float_cats])
Out[192]: 
0    1.0
1    2.0
0    3.0
1    4.0
dtype: float64

In [193]: pd.concat([s1, s3]).astype("category")
Out[193]: 
0    a
1    b
0    b
1    c
dtype: category
Categories (3, object): ['a', 'b', 'c']

In [194]: union_categoricals([s1.array, s3.array])
Out[194]: 
['a', 'b', 'b', 'c']
Categories (3, object): ['a', 'b', 'c']

---->   pandas.Series

--------------------------------------
ID: 2344 --> 1
In [195]: from pandas.api.types import union_categoricals

In [196]: a = pd.Categorical(["b", "c"])

In [197]: b = pd.Categorical(["a", "b"])

In [198]: union_categoricals([a, b])
Out[198]: 
['b', 'c', 'a', 'b']
Categories (3, object): ['b', 'c', 'a']

---->   pandas.Categorical

--------------------------------------
ID: 2346 --> 1
In [200]: a = pd.Categorical(["a", "b"], ordered=True)

In [201]: b = pd.Categorical(["a", "b", "a"], ordered=True)

In [202]: union_categoricals([a, b])
Out[202]: 
['a', 'b', 'a', 'b', 'a']
Categories (2, object): ['a' < 'b']

---->   pandas.Categorical

--------------------------------------
ID: 2347 --> 1
In [1]: a = pd.Categorical(["a", "b"], ordered=True)
In [2]: b = pd.Categorical(["a", "b", "c"], ordered=True)
In [3]: union_categoricals([a, b])
Out[3]:
TypeError: to union ordered Categoricals, all categories must be the same

---->   pandas.Categorical

--------------------------------------
ID: 2348 --> 1
In [203]: a = pd.Categorical(["a", "b", "c"], ordered=True)

In [204]: b = pd.Categorical(["c", "b", "a"], ordered=True)

In [205]: union_categoricals([a, b], ignore_order=True)
Out[205]: 
['a', 'b', 'c', 'c', 'b', 'a']
Categories (3, object): ['a', 'b', 'c']

---->   pandas.Categorical

--------------------------------------
ID: 2349 --> 1
In [206]: a = pd.Series(["b", "c"], dtype="category")

In [207]: b = pd.Series(["a", "b"], dtype="category")

In [208]: union_categoricals([a, b])
Out[208]: 
['b', 'c', 'a', 'b']
Categories (3, object): ['b', 'c', 'a']

---->   pandas.Series

--------------------------------------
ID: 2350 --> 1
In [209]: c1 = pd.Categorical(["b", "c"])

In [210]: c2 = pd.Categorical(["a", "b"])

In [211]: c1
Out[211]: 
['b', 'c']
Categories (2, object): ['b', 'c']

# "b" is coded to 0
In [212]: c1.codes
Out[212]: array([0, 1], dtype=int8)

In [213]: c2
Out[213]: 
['a', 'b']
Categories (2, object): ['a', 'b']

# "b" is coded to 1
In [214]: c2.codes
Out[214]: array([0, 1], dtype=int8)

In [215]: c = union_categoricals([c1, c2])

In [216]: c
Out[216]: 
['b', 'c', 'a', 'b']
Categories (3, object): ['b', 'c', 'a']

# "b" is coded to 0 throughout, same as c1, different from c2
In [217]: c.codes
Out[217]: array([0, 1, 2, 0], dtype=int8)

---->   pandas.Categorical

--------------------------------------
ID: 2351 --> 4
In [218]: import io

In [219]: s = pd.Series(pd.Categorical(["a", "b", "b", "a", "a", "d"]))

# rename the categories
In [220]: s = s.cat.rename_categories(["very good", "good", "bad"])

# reorder the categories and add missing categories
In [221]: s = s.cat.set_categories(["very bad", "bad", "medium", "good", "very good"])

In [222]: df = pd.DataFrame({"cats": s, "vals": [1, 2, 3, 4, 5, 6]})

In [223]: csv = io.StringIO()

In [224]: df.to_csv(csv)

In [225]: df2 = pd.read_csv(io.StringIO(csv.getvalue()))

In [226]: df2.dtypes
Out[226]: 
Unnamed: 0     int64
cats          object
vals           int64
dtype: object

In [227]: df2["cats"]
Out[227]: 
0    very good
1         good
2         good
3    very good
4    very good
5          bad
Name: cats, dtype: object

# Redo the category
In [228]: df2["cats"] = df2["cats"].astype("category")

In [229]: df2["cats"] = df2["cats"].cat.set_categories(
   .....:     ["very bad", "bad", "medium", "good", "very good"]
   .....: )
   .....: 

In [230]: df2.dtypes
Out[230]: 
Unnamed: 0       int64
cats          category
vals             int64
dtype: object

In [231]: df2["cats"]
Out[231]: 
0    very good
1         good
2         good
3    very good
4    very good
5          bad
Name: cats, dtype: category
Categories (5, object): ['very bad', 'bad', 'medium', 'good', 'very good']

---->   pandas.Series; pandas.Categorical; pandas.DataFrame; DataFrame.to_csv

--------------------------------------
ID: 2352 --> 1
In [232]: s = pd.Series(["a", "b", np.nan, "a"], dtype="category")

# only two categories
In [233]: s
Out[233]: 
0      a
1      b
2    NaN
3      a
dtype: category
Categories (2, object): ['a', 'b']

In [234]: s.cat.codes
Out[234]: 
0    0
1    1
2   -1
3    0
dtype: int8

---->   pandas.Series

--------------------------------------
ID: 2353 --> 2
In [235]: s = pd.Series(["a", "b", np.nan], dtype="category")

In [236]: s
Out[236]: 
0      a
1      b
2    NaN
dtype: category
Categories (2, object): ['a', 'b']

In [237]: pd.isna(s)
Out[237]: 
0    False
1    False
2     True
dtype: bool

In [238]: s.fillna("a")
Out[238]: 
0    a
1    b
2    a
dtype: category
Categories (2, object): ['a', 'b']

---->   pandas.Series; pandas.isna

--------------------------------------
ID: 2354 --> 2
In [239]: s = pd.Series(["foo", "bar"] * 1000)

# object dtype
In [240]: s.nbytes
Out[240]: 16000

# category dtype
In [241]: s.astype("category").nbytes
Out[241]: 2016

---->   pandas.Series; Series.astype

--------------------------------------
ID: 2355 --> 2
In [242]: s = pd.Series(["foo%04d" % i for i in range(2000)])

# object dtype
In [243]: s.nbytes
Out[243]: 16000

# category dtype
In [244]: s.astype("category").nbytes
Out[244]: 20000

---->   pandas.Series; Series.astype

--------------------------------------
ID: 2356 --> 1
In [245]: try:
   .....:     np.dtype("category")
   .....: except TypeError as e:
   .....:     print("TypeError:", str(e))
   .....: 
TypeError: data type 'category' not understood

In [246]: dtype = pd.Categorical(["a"]).dtype

In [247]: try:
   .....:     np.dtype(dtype)
   .....: except TypeError as e:
   .....:     print("TypeError:", str(e))
   .....: 
TypeError: Cannot interpret 'CategoricalDtype(categories=['a'], ordered=False)' as a data type

---->   pandas.Categorical

--------------------------------------
ID: 2357 --> 1
In [250]: hasattr(pd.Series(["a"], dtype="category"), "cat")
Out[250]: True

In [251]: hasattr(pd.Series(["a"]), "cat")
Out[251]: False

---->   pandas.Series

--------------------------------------
ID: 2358 --> 2
In [252]: s = pd.Series(pd.Categorical([1, 2, 3, 4]))

In [253]: try:
   .....:     np.sum(s)
   .....: except TypeError as e:
   .....:     print("TypeError:", str(e))
   .....: 
TypeError: 'Categorical' with dtype category does not support reduction 'sum'

---->   pandas.Series; pandas.Categorical

--------------------------------------
ID: 2359 --> 2
In [254]: df = pd.DataFrame(
   .....:     {
   .....:         "a": [1, 2, 3, 4],
   .....:         "b": ["a", "b", "c", "d"],
   .....:         "cats": pd.Categorical([1, 2, 3, 2]),
   .....:     }
   .....: )
   .....: 

In [255]: df.apply(lambda row: type(row["cats"]), axis=1)
Out[255]: 
0    
1    
2    
3    
dtype: object

In [256]: df.apply(lambda col: col.dtype, axis=0)
Out[256]: 
a          int64
b         object
cats    category
dtype: object

---->   pandas.DataFrame; pandas.Categorical

--------------------------------------
ID: 2360 --> 2
In [257]: cats = pd.Categorical([1, 2, 3, 4], categories=[4, 2, 3, 1])

In [258]: strings = ["a", "b", "c", "d"]

In [259]: values = [4, 2, 3, 1]

In [260]: df = pd.DataFrame({"strings": strings, "values": values}, index=cats)

In [261]: df.index
Out[261]: CategoricalIndex([1, 2, 3, 4], categories=[4, 2, 3, 1], ordered=False, dtype='category')

# This now sorts by the categories order
In [262]: df.sort_index()
Out[262]: 
  strings  values
4       d       1
2       b       2
3       c       3
1       a       4

---->   pandas.Categorical; pandas.DataFrame

--------------------------------------
ID: 2361 --> 2
In [263]: cat = pd.Categorical([1, 2, 3, 10], categories=[1, 2, 3, 4, 10])

In [264]: s = pd.Series(cat, name="cat")

In [265]: cat
Out[265]: 
[1, 2, 3, 10]
Categories (5, int64): [1, 2, 3, 4, 10]

In [266]: s.iloc[0:2] = 10

In [267]: cat
Out[267]: 
[10, 10, 3, 10]
Categories (5, int64): [1, 2, 3, 4, 10]

---->   pandas.Categorical; pandas.Series

--------------------------------------
ID: 2362 --> 2
In [268]: cat = pd.Categorical([1, 2, 3, 10], categories=[1, 2, 3, 4, 10])

In [269]: s = pd.Series(cat, name="cat", copy=True)

In [270]: cat
Out[270]: 
[1, 2, 3, 10]
Categories (5, int64): [1, 2, 3, 4, 10]

In [271]: s.iloc[0:2] = 10

In [272]: cat
Out[272]: 
[1, 2, 3, 10]
Categories (5, int64): [1, 2, 3, 4, 10]

---->   pandas.Categorical; pandas.Series

--------------------------------------
ID: 2363 --> 2
In [1]: s = pd.Series(range(5))

In [2]: s.rolling(window=2).sum()
Out[2]: 
0    NaN
1    1.0
2    3.0
3    5.0
4    7.0
dtype: float64

---->   pandas.Series; Series.rolling

--------------------------------------
ID: 2364 --> 1
In [3]: for window in s.rolling(window=2):
   ...:     print(window)
   ...: 
0    0
dtype: int64
0    0
1    1
dtype: int64
1    1
2    2
dtype: int64
2    2
3    3
dtype: int64
3    3
4    4
dtype: int64

---->   Series.rolling

--------------------------------------
ID: 2365 --> 2
In [4]: s = pd.Series(range(5), index=pd.date_range('2020-01-01', periods=5, freq='1D'))

In [5]: s.rolling(window='2D').sum()
Out[5]: 
2020-01-01    0.0
2020-01-02    1.0
2020-01-03    3.0
2020-01-04    5.0
2020-01-05    7.0
Freq: D, dtype: float64

---->   pandas.Series; Series.rolling

--------------------------------------
ID: 2366 --> 2
In [6]: df = pd.DataFrame({'A': ['a', 'b', 'a', 'b', 'a'], 'B': range(5)})

In [7]: df.groupby('A').expanding().sum()
Out[7]: 
       B
A       
a 0  0.0
  2  2.0
  4  6.0
b 1  1.0
  3  4.0

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 2367 --> 2
In [8]: def weighted_mean(x):
   ...:     arr = np.ones((1, x.shape[1]))
   ...:     arr[:, :2] = (x[:, :2] * x[:, 2]).sum(axis=0) / x[:, 2].sum()
   ...:     return arr
   ...: 

In [9]: df = pd.DataFrame([[1, 2, 0.6], [2, 3, 0.4], [3, 4, 0.2], [4, 5, 0.7]])

In [10]: df.rolling(2, method="table", min_periods=0).apply(weighted_mean, raw=True, engine="numba")  # noqa:E501
Out[10]: 
          0         1    2
0  1.000000  2.000000  1.0
1  1.800000  2.000000  1.0
2  3.333333  2.333333  1.0
3  1.555556  7.000000  1.0

---->   pandas.DataFrame; DataFrame.rolling

--------------------------------------
ID: 2368 --> 2
In [11]: df = pd.DataFrame([[1, 2, 0.6], [2, 3, 0.4], [3, 4, 0.2], [4, 5, 0.7]])

In [12]: df.ewm(0.5).mean()
Out[12]: 
          0         1         2
0  1.000000  2.000000  0.600000
1  1.750000  2.750000  0.450000
2  2.615385  3.615385  0.276923
3  3.550000  4.550000  0.562500

---->   pandas.DataFrame; DataFrame.ewm

--------------------------------------
ID: 2369 --> 2
In [13]: online_ewm = df.head(2).ewm(0.5).online()

In [14]: online_ewm.mean()
Out[14]: 
      0     1     2
0  1.00  2.00  0.60
1  1.75  2.75  0.45

In [15]: online_ewm.mean(update=df.tail(1))
Out[15]: 
          0         1         2
3  3.307692  4.307692  0.623077

---->   DataFrame.head; DataFrame.tail

--------------------------------------
ID: 2370 --> 2
In [16]: s = pd.Series([np.nan, 1, 2, np.nan, np.nan, 3])

In [17]: s.rolling(window=3, min_periods=1).sum()
Out[17]: 
0    NaN
1    1.0
2    3.0
3    3.0
4    2.0
5    3.0
dtype: float64

In [18]: s.rolling(window=3, min_periods=2).sum()
Out[18]: 
0    NaN
1    NaN
2    3.0
3    3.0
4    NaN
5    NaN
dtype: float64

# Equivalent to min_periods=3
In [19]: s.rolling(window=3, min_periods=None).sum()
Out[19]: 
0   NaN
1   NaN
2   NaN
3   NaN
4   NaN
5   NaN
dtype: float64

---->   pandas.Series; Series.rolling

--------------------------------------
ID: 2371 --> 2
In [20]: df = pd.DataFrame({"A": range(5), "B": range(10, 15)})

In [21]: df.expanding().agg([np.sum, np.mean, np.std])
Out[21]: 
      A                    B                
    sum mean       std   sum  mean       std
0   0.0  0.0       NaN  10.0  10.0       NaN
1   1.0  0.5  0.707107  21.0  10.5  0.707107
2   3.0  1.0  1.000000  33.0  11.0  1.000000
3   6.0  1.5  1.290994  46.0  11.5  1.290994
4  10.0  2.0  1.581139  60.0  12.0  1.581139

---->   pandas.DataFrame; DataFrame.expanding

--------------------------------------
ID: 2372 --> 3
In [22]: times = ['2020-01-01', '2020-01-03', '2020-01-04', '2020-01-05', '2020-01-29']

In [23]: s = pd.Series(range(5), index=pd.DatetimeIndex(times))

In [24]: s
Out[24]: 
2020-01-01    0
2020-01-03    1
2020-01-04    2
2020-01-05    3
2020-01-29    4
dtype: int64

# Window with 2 observations
In [25]: s.rolling(window=2).sum()
Out[25]: 
2020-01-01    NaN
2020-01-03    1.0
2020-01-04    3.0
2020-01-05    5.0
2020-01-29    7.0
dtype: float64

# Window with 2 days worth of observations
In [26]: s.rolling(window='2D').sum()
Out[26]: 
2020-01-01    0.0
2020-01-03    1.0
2020-01-04    3.0
2020-01-05    5.0
2020-01-29    4.0
dtype: float64

---->   pandas.Series; pandas.DatetimeIndex; Series.rolling

--------------------------------------
ID: 2373 --> 2
In [27]: s = pd.Series(range(10))

In [28]: s.rolling(window=5).mean()
Out[28]: 
0    NaN
1    NaN
2    NaN
3    NaN
4    2.0
5    3.0
6    4.0
7    5.0
8    6.0
9    7.0
dtype: float64

In [29]: s.rolling(window=5, center=True).mean()
Out[29]: 
0    NaN
1    NaN
2    2.0
3    3.0
4    4.0
5    5.0
6    6.0
7    7.0
8    NaN
9    NaN
dtype: float64

---->   pandas.Series; Series.rolling

--------------------------------------
ID: 2374 --> 2
In [30]: df = pd.DataFrame(
   ....:     {"A": [0, 1, 2, 3, 4]}, index=pd.date_range("2020", periods=5, freq="1D")
   ....: )
   ....: 

In [31]: df
Out[31]: 
            A
2020-01-01  0
2020-01-02  1
2020-01-03  2
2020-01-04  3
2020-01-05  4

In [32]: df.rolling("2D", center=False).mean()
Out[32]: 
              A
2020-01-01  0.0
2020-01-02  0.5
2020-01-03  1.5
2020-01-04  2.5
2020-01-05  3.5

In [33]: df.rolling("2D", center=True).mean()
Out[33]: 
              A
2020-01-01  0.5
2020-01-02  1.5
2020-01-03  2.5
2020-01-04  3.5
2020-01-05  4.0

---->   pandas.DataFrame; DataFrame.rolling

--------------------------------------
ID: 2375 --> 3
In [34]: df = pd.DataFrame(
   ....:     {"x": 1},
   ....:     index=[
   ....:         pd.Timestamp("20130101 09:00:01"),
   ....:         pd.Timestamp("20130101 09:00:02"),
   ....:         pd.Timestamp("20130101 09:00:03"),
   ....:         pd.Timestamp("20130101 09:00:04"),
   ....:         pd.Timestamp("20130101 09:00:06"),
   ....:     ],
   ....: )
   ....: 

In [35]: df["right"] = df.rolling("2s", closed="right").x.sum()  # default

In [36]: df["both"] = df.rolling("2s", closed="both").x.sum()

In [37]: df["left"] = df.rolling("2s", closed="left").x.sum()

In [38]: df["neither"] = df.rolling("2s", closed="neither").x.sum()

In [39]: df
Out[39]: 
                     x  right  both  left  neither
2013-01-01 09:00:01  1    1.0   1.0   NaN      NaN
2013-01-01 09:00:02  1    2.0   2.0   1.0      1.0
2013-01-01 09:00:03  1    2.0   3.0   2.0      1.0
2013-01-01 09:00:04  1    2.0   3.0   2.0      1.0
2013-01-01 09:00:06  1    1.0   2.0   1.0      NaN

---->   pandas.DataFrame; DataFrame.rolling; Series.sum

--------------------------------------
ID: 2376 --> 1
In [40]: use_expanding = [True, False, True, False, True]

In [41]: use_expanding
Out[41]: [True, False, True, False, True]

In [42]: df = pd.DataFrame({"values": range(5)})

In [43]: df
Out[43]: 
   values
0       0
1       1
2       2
3       3
4       4

---->   pandas.DataFrame

--------------------------------------
ID: 2377 --> 1
In [2]: from pandas.api.indexers import BaseIndexer

In [3]: class CustomIndexer(BaseIndexer):
   ...:     def get_window_bounds(self, num_values, min_periods, center, closed):
   ...:         start = np.empty(num_values, dtype=np.int64)
   ...:         end = np.empty(num_values, dtype=np.int64)
   ...:         for i in range(num_values):
   ...:             if self.use_expanding[i]:
   ...:                 start[i] = 0
   ...:                 end[i] = i + 1
   ...:             else:
   ...:                 start[i] = i
   ...:                 end[i] = i + self.window_size
   ...:         return start, end

In [4]: indexer = CustomIndexer(window_size=1, use_expanding=use_expanding)

In [5]: df.rolling(indexer).sum()
Out[5]:
    values
0     0.0
1     1.0
2     3.0
3     3.0
4    10.0

---->   DataFrame.rolling

--------------------------------------
ID: 2378 --> 2
In [44]: from pandas.api.indexers import VariableOffsetWindowIndexer

In [45]: df = pd.DataFrame(range(10), index=pd.date_range("2020", periods=10))

In [46]: offset = pd.offsets.BDay(1)

In [47]: indexer = VariableOffsetWindowIndexer(index=df.index, offset=offset)

In [48]: df
Out[48]: 
            0
2020-01-01  0
2020-01-02  1
2020-01-03  2
2020-01-04  3
2020-01-05  4
2020-01-06  5
2020-01-07  6
2020-01-08  7
2020-01-09  8
2020-01-10  9

In [49]: df.rolling(indexer).sum()
Out[49]: 
               0
2020-01-01   0.0
2020-01-02   1.0
2020-01-03   2.0
2020-01-04   3.0
2020-01-05   7.0
2020-01-06  12.0
2020-01-07   6.0
2020-01-08   7.0
2020-01-09   8.0
2020-01-10   9.0

---->   pandas.DataFrame; DataFrame.rolling

--------------------------------------
ID: 2379 --> 1
In [50]: from pandas.api.indexers import FixedForwardWindowIndexer

In [51]: indexer = FixedForwardWindowIndexer(window_size=2)

In [52]: df.rolling(indexer, min_periods=1).sum()
Out[52]: 
               0
2020-01-01   1.0
2020-01-02   3.0
2020-01-03   5.0
2020-01-04   7.0
2020-01-05   9.0
2020-01-06  11.0
2020-01-07  13.0
2020-01-08  15.0
2020-01-09  17.0
2020-01-10   9.0

---->   DataFrame.rolling

--------------------------------------
ID: 2380 --> 1
In [53]: df = pd.DataFrame(
   ....:     data=[
   ....:         [pd.Timestamp("2018-01-01 00:00:00"), 100],
   ....:         [pd.Timestamp("2018-01-01 00:00:01"), 101],
   ....:         [pd.Timestamp("2018-01-01 00:00:03"), 103],
   ....:         [pd.Timestamp("2018-01-01 00:00:04"), 111],
   ....:     ],
   ....:     columns=["time", "value"],
   ....: ).set_index("time")
   ....: 

In [54]: df
Out[54]: 
                     value
time                      
2018-01-01 00:00:00    100
2018-01-01 00:00:01    101
2018-01-01 00:00:03    103
2018-01-01 00:00:04    111

In [55]: reversed_df = df[::-1].rolling("2s").sum()[::-1]

In [56]: reversed_df
Out[56]: 
                     value
time                      
2018-01-01 00:00:00  201.0
2018-01-01 00:00:01  101.0
2018-01-01 00:00:03  214.0
2018-01-01 00:00:04  111.0

---->   pandas.DataFrame

--------------------------------------
ID: 2381 --> 3
In [57]: def mad(x):
   ....:     return np.fabs(x - x.mean()).mean()
   ....: 

In [58]: s = pd.Series(range(10))

In [59]: s.rolling(window=4).apply(mad, raw=True)
Out[59]: 
0    NaN
1    NaN
2    NaN
3    1.0
4    1.0
5    1.0
6    1.0
7    1.0
8    1.0
9    1.0
dtype: float64

---->   Series.mean; pandas.Series; Series.rolling

--------------------------------------
ID: 2382 --> 3
In [60]: df = pd.DataFrame(
   ....:     np.random.randn(10, 4),
   ....:     index=pd.date_range("2020-01-01", periods=10),
   ....:     columns=["A", "B", "C", "D"],
   ....: )
   ....: 

In [61]: df = df.cumsum()

In [62]: df2 = df[:4]

In [63]: df2.rolling(window=2).corr(df2["B"])
Out[63]: 
              A    B    C    D
2020-01-01  NaN  NaN  NaN  NaN
2020-01-02 -1.0  1.0 -1.0  1.0
2020-01-03  1.0  1.0  1.0 -1.0
2020-01-04 -1.0  1.0  1.0 -1.0

---->   pandas.DataFrame; DataFrame.cumsum; DataFrame.rolling

--------------------------------------
ID: 2384 --> 2
In [66]: s = pd.Series(range(10))

In [67]: s.rolling(window=5).mean()
Out[67]: 
0    NaN
1    NaN
2    NaN
3    NaN
4    2.0
5    3.0
6    4.0
7    5.0
8    6.0
9    7.0
dtype: float64

In [68]: s.rolling(window=5, win_type="triang").mean()
Out[68]: 
0    NaN
1    NaN
2    NaN
3    NaN
4    2.0
5    3.0
6    4.0
7    5.0
8    6.0
9    7.0
dtype: float64

# Supplementary Scipy arguments passed in the aggregation function
In [69]: s.rolling(window=5, win_type="gaussian").mean(std=0.1)
Out[69]: 
0    NaN
1    NaN
2    NaN
3    NaN
4    2.0
5    3.0
6    4.0
7    5.0
8    6.0
9    7.0
dtype: float64

---->   pandas.Series; Series.rolling

--------------------------------------
ID: 2385 --> 3
In [70]: df = pd.DataFrame(range(5))

In [71]: df.rolling(window=len(df), min_periods=1).mean()
Out[71]: 
     0
0  0.0
1  0.5
2  1.0
3  1.5
4  2.0

In [72]: df.expanding(min_periods=1).mean()
Out[72]: 
     0
0  0.0
1  0.5
2  1.0
3  1.5
4  2.0

---->   pandas.DataFrame; DataFrame.rolling; DataFrame.expanding

--------------------------------------
ID: 2386 --> 3
In [73]: df = pd.DataFrame({"B": [0, 1, 2, np.nan, 4]})

In [74]: df
Out[74]: 
     B
0  0.0
1  1.0
2  2.0
3  NaN
4  4.0

In [75]: times = ["2020-01-01", "2020-01-03", "2020-01-10", "2020-01-15", "2020-01-17"]

In [76]: df.ewm(halflife="4 days", times=pd.DatetimeIndex(times)).mean()
Out[76]: 
          B
0  0.000000
1  0.585786
2  1.523889
3  1.523889
4  3.233686

---->   pandas.DataFrame; DataFrame.ewm; pandas.DatetimeIndex

--------------------------------------
ID: 2387 --> 2
In [1]: arrays = [
   ...:     ["bar", "bar", "baz", "baz", "foo", "foo", "qux", "qux"],
   ...:     ["one", "two", "one", "two", "one", "two", "one", "two"],
   ...: ]
   ...: 

In [2]: tuples = list(zip(*arrays))

In [3]: tuples
Out[3]: 
[('bar', 'one'),
 ('bar', 'two'),
 ('baz', 'one'),
 ('baz', 'two'),
 ('foo', 'one'),
 ('foo', 'two'),
 ('qux', 'one'),
 ('qux', 'two')]

In [4]: index = pd.MultiIndex.from_tuples(tuples, names=["first", "second"])

In [5]: index
Out[5]: 
MultiIndex([('bar', 'one'),
            ('bar', 'two'),
            ('baz', 'one'),
            ('baz', 'two'),
            ('foo', 'one'),
            ('foo', 'two'),
            ('qux', 'one'),
            ('qux', 'two')],
           names=['first', 'second'])

In [6]: s = pd.Series(np.random.randn(8), index=index)

In [7]: s
Out[7]: 
first  second
bar    one       0.469112
       two      -0.282863
baz    one      -1.509059
       two      -1.135632
foo    one       1.212112
       two      -0.173215
qux    one       0.119209
       two      -1.044236
dtype: float64

---->   pandas.MultiIndex; pandas.Series

--------------------------------------
ID: 2388 --> 1
In [8]: iterables = [["bar", "baz", "foo", "qux"], ["one", "two"]]

In [9]: pd.MultiIndex.from_product(iterables, names=["first", "second"])
Out[9]: 
MultiIndex([('bar', 'one'),
            ('bar', 'two'),
            ('baz', 'one'),
            ('baz', 'two'),
            ('foo', 'one'),
            ('foo', 'two'),
            ('qux', 'one'),
            ('qux', 'two')],
           names=['first', 'second'])

---->   pandas.MultiIndex

--------------------------------------
ID: 2389 --> 2
In [10]: df = pd.DataFrame(
   ....:     [["bar", "one"], ["bar", "two"], ["foo", "one"], ["foo", "two"]],
   ....:     columns=["first", "second"],
   ....: )
   ....: 

In [11]: pd.MultiIndex.from_frame(df)
Out[11]: 
MultiIndex([('bar', 'one'),
            ('bar', 'two'),
            ('foo', 'one'),
            ('foo', 'two')],
           names=['first', 'second'])

---->   pandas.DataFrame; pandas.MultiIndex

--------------------------------------
ID: 2390 --> 2
In [12]: arrays = [
   ....:     np.array(["bar", "bar", "baz", "baz", "foo", "foo", "qux", "qux"]),
   ....:     np.array(["one", "two", "one", "two", "one", "two", "one", "two"]),
   ....: ]
   ....: 

In [13]: s = pd.Series(np.random.randn(8), index=arrays)

In [14]: s
Out[14]: 
bar  one   -0.861849
     two   -2.104569
baz  one   -0.494929
     two    1.071804
foo  one    0.721555
     two   -0.706771
qux  one   -1.039575
     two    0.271860
dtype: float64

In [15]: df = pd.DataFrame(np.random.randn(8, 4), index=arrays)

In [16]: df
Out[16]: 
                0         1         2         3
bar one -0.424972  0.567020  0.276232 -1.087401
    two -0.673690  0.113648 -1.478427  0.524988
baz one  0.404705  0.577046 -1.715002 -1.039268
    two -0.370647 -1.157892 -1.344312  0.844885
foo one  1.075770 -0.109050  1.643563 -1.469388
    two  0.357021 -0.674600 -1.776904 -0.968914
qux one -1.294524  0.413738  0.276662 -0.472035
    two -0.013960 -0.362543 -0.006154 -0.923061

---->   pandas.Series; pandas.DataFrame

--------------------------------------
ID: 2392 --> 1
In [18]: df = pd.DataFrame(np.random.randn(3, 8), index=["A", "B", "C"], columns=index)

In [19]: df
Out[19]: 
first        bar                 baz  ...       foo       qux          
second       one       two       one  ...       two       one       two
A       0.895717  0.805244 -1.206412  ...  1.340309 -1.170299 -0.226169
B       0.410835  0.813850  0.132003  ... -1.187678  1.130127 -1.436737
C      -1.413681  1.607920  1.024180  ... -2.211372  0.974466 -2.006747

[3 rows x 8 columns]

In [20]: pd.DataFrame(np.random.randn(6, 6), index=index[:6], columns=index[:6])
Out[20]: 
first              bar                 baz                 foo          
second             one       two       one       two       one       two
first second                                                            
bar   one    -0.410001 -0.078638  0.545952 -1.219217 -1.226825  0.769804
      two    -1.281247 -0.727707 -0.121306 -0.097883  0.695775  0.341734
baz   one     0.959726 -1.110336 -0.619976  0.149748 -0.732339  0.687738
      two     0.176444  0.403310 -0.154951  0.301624 -2.179861 -1.369849
foo   one    -0.954208  1.462696 -1.743161 -0.826591 -0.345352  1.314232
      two     0.690579  0.995761  2.396780  0.014871  3.357427 -0.317441

---->   pandas.DataFrame

--------------------------------------
ID: 2394 --> 1
In [22]: pd.Series(np.random.randn(8), index=tuples)
Out[22]: 
(bar, one)   -1.236269
(bar, two)    0.896171
(baz, one)   -0.487602
(baz, two)   -0.082240
(foo, one)   -2.182937
(foo, two)    0.380396
(qux, one)    0.084844
(qux, two)    0.432390
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 2395 --> 1
In [23]: index.get_level_values(0)
Out[23]: Index(['bar', 'bar', 'baz', 'baz', 'foo', 'foo', 'qux', 'qux'], dtype='object', name='first')

In [24]: index.get_level_values("second")
Out[24]: Index(['one', 'two', 'one', 'two', 'one', 'two', 'one', 'two'], dtype='object', name='second')

---->   Index.get_level_values

--------------------------------------
ID: 2398 --> 1
In [31]: df[["foo", "qux"]].columns.to_numpy()
Out[31]: 
array([('foo', 'one'), ('foo', 'two'), ('qux', 'one'), ('qux', 'two')],
      dtype=object)

# for a specific level
In [32]: df[["foo", "qux"]].columns.get_level_values(0)
Out[32]: Index(['foo', 'foo', 'qux', 'qux'], dtype='object', name='first')

---->   Index.get_level_values

--------------------------------------
ID: 2405 --> 2
In [48]: s = pd.Series(
   ....:     [1, 2, 3, 4, 5, 6],
   ....:     index=pd.MultiIndex.from_product([["A", "B"], ["c", "d", "e"]]),
   ....: )
   ....: 

In [49]: s.loc[[("A", "c"), ("B", "d")]]  # list of tuples
Out[49]: 
A  c    1
B  d    5
dtype: int64

In [50]: s.loc[(["A", "B"], ["c", "d"])]  # tuple of lists
Out[50]: 
A  c    1
   d    2
B  c    4
   d    5
dtype: int64

---->   pandas.Series; pandas.MultiIndex

--------------------------------------
ID: 2408 --> 3
In [51]: def mklbl(prefix, n):
   ....:     return ["%s%s" % (prefix, i) for i in range(n)]
   ....: 

In [52]: miindex = pd.MultiIndex.from_product(
   ....:     [mklbl("A", 4), mklbl("B", 2), mklbl("C", 4), mklbl("D", 2)]
   ....: )
   ....: 

In [53]: micolumns = pd.MultiIndex.from_tuples(
   ....:     [("a", "foo"), ("a", "bar"), ("b", "foo"), ("b", "bah")], names=["lvl0", "lvl1"]
   ....: )
   ....: 

In [54]: dfmi = (
   ....:     pd.DataFrame(
   ....:         np.arange(len(miindex) * len(micolumns)).reshape(
   ....:             (len(miindex), len(micolumns))
   ....:         ),
   ....:         index=miindex,
   ....:         columns=micolumns,
   ....:     )
   ....:     .sort_index()
   ....:     .sort_index(axis=1)
   ....: )
   ....: 

In [55]: dfmi
Out[55]: 
lvl0           a         b     
lvl1         bar  foo  bah  foo
A0 B0 C0 D0    1    0    3    2
         D1    5    4    7    6
      C1 D0    9    8   11   10
         D1   13   12   15   14
      C2 D0   17   16   19   18
...          ...  ...  ...  ...
A3 B1 C1 D1  237  236  239  238
      C2 D0  241  240  243  242
         D1  245  244  247  246
      C3 D0  249  248  251  250
         D1  253  252  255  254

[64 rows x 4 columns]

---->   pandas.MultiIndex; pandas.MultiIndex; pandas.DataFrame

--------------------------------------
ID: 2415 --> 1
In [70]: df
Out[70]: 
                     A         B         C
first second                              
bar   one     0.895717  0.410835 -1.413681
      two     0.805244  0.813850  1.607920
baz   one    -1.206412  0.132003  1.024180
      two     2.565646 -0.827317  0.569605
foo   one     1.431256 -0.076467  0.875906
      two     1.340309 -1.187678 -2.211372
qux   one    -1.170299  1.130127  0.974466
      two    -0.226169 -1.436737 -2.006747

In [71]: df.xs("one", level="second")
Out[71]: 
              A         B         C
first                              
bar    0.895717  0.410835 -1.413681
baz   -1.206412  0.132003  1.024180
foo    1.431256 -0.076467  0.875906
qux   -1.170299  1.130127  0.974466

---->   DataFrame.xs

--------------------------------------
ID: 2417 --> 1
In [73]: df = df.T

In [74]: df.xs("one", level="second", axis=1)
Out[74]: 
first       bar       baz       foo       qux
A      0.895717 -1.206412  1.431256 -1.170299
B      0.410835  0.132003 -0.076467  1.130127
C     -1.413681  1.024180  0.875906  0.974466

---->   DataFrame.xs

--------------------------------------
ID: 2419 --> 1
In [76]: df.xs(("one", "bar"), level=("second", "first"), axis=1)
Out[76]: 
first        bar
second       one
A       0.895717
B       0.410835
C      -1.413681

---->   DataFrame.xs

--------------------------------------
ID: 2421 --> 1
In [78]: df.xs("one", level="second", axis=1, drop_level=False)
Out[78]: 
first        bar       baz       foo       qux
second       one       one       one       one
A       0.895717 -1.206412  1.431256 -1.170299
B       0.410835  0.132003 -0.076467  1.130127
C      -1.413681  1.024180  0.875906  0.974466

---->   DataFrame.xs

--------------------------------------
ID: 2422 --> 1
In [79]: df.xs("one", level="second", axis=1, drop_level=True)
Out[79]: 
first       bar       baz       foo       qux
A      0.895717 -1.206412  1.431256 -1.170299
B      0.410835  0.132003 -0.076467  1.130127
C     -1.413681  1.024180  0.875906  0.974466

---->   DataFrame.xs

--------------------------------------
ID: 2423 --> 4
In [80]: midx = pd.MultiIndex(
   ....:     levels=[["zero", "one"], ["x", "y"]], codes=[[1, 1, 0, 0], [1, 0, 1, 0]]
   ....: )
   ....: 

In [81]: df = pd.DataFrame(np.random.randn(4, 2), index=midx)

In [82]: df
Out[82]: 
               0         1
one  y  1.519970 -0.493662
     x  0.600178  0.274230
zero y  0.132885 -0.023688
     x  2.410179  1.450520

In [83]: df2 = df.groupby(level=0).mean()

In [84]: df2
Out[84]: 
             0         1
one   1.060074 -0.109716
zero  1.271532  0.713416

In [85]: df2.reindex(df.index, level=0)
Out[85]: 
               0         1
one  y  1.060074 -0.109716
     x  1.060074 -0.109716
zero y  1.271532  0.713416
     x  1.271532  0.713416

# aligning
In [86]: df_aligned, df2_aligned = df.align(df2, level=0)

In [87]: df_aligned
Out[87]: 
               0         1
one  y  1.519970 -0.493662
     x  0.600178  0.274230
zero y  0.132885 -0.023688
     x  2.410179  1.450520

In [88]: df2_aligned
Out[88]: 
               0         1
one  y  1.060074 -0.109716
     x  1.060074 -0.109716
zero y  1.271532  0.713416
     x  1.271532  0.713416

---->   pandas.MultiIndex; pandas.DataFrame; DataFrame.groupby; DataFrame.align

--------------------------------------
ID: 2430 --> 1
In [96]: mi = pd.MultiIndex.from_product([[1, 2], ["a", "b"]], names=["x", "y"])

In [97]: mi.names
Out[97]: FrozenList(['x', 'y'])

In [98]: mi2 = mi.rename("new name", level=0)

In [99]: mi2
Out[99]: 
MultiIndex([(1, 'a'),
            (1, 'b'),
            (2, 'a'),
            (2, 'b')],
           names=['new name', 'y'])

---->   pandas.MultiIndex

--------------------------------------
ID: 2432 --> 2
In [101]: import random

In [102]: random.shuffle(tuples)

In [103]: s = pd.Series(np.random.randn(8), index=pd.MultiIndex.from_tuples(tuples))

In [104]: s
Out[104]: 
foo  two    0.206053
bar  two   -0.251905
baz  one   -2.213588
     two    1.063327
qux  one    1.266143
bar  one    0.299368
foo  one   -0.863838
qux  two    0.408204
dtype: float64

In [105]: s.sort_index()
Out[105]: 
bar  one    0.299368
     two   -0.251905
baz  one   -2.213588
     two    1.063327
foo  one   -0.863838
     two    0.206053
qux  one    1.266143
     two    0.408204
dtype: float64

In [106]: s.sort_index(level=0)
Out[106]: 
bar  one    0.299368
     two   -0.251905
baz  one   -2.213588
     two    1.063327
foo  one   -0.863838
     two    0.206053
qux  one    1.266143
     two    0.408204
dtype: float64

In [107]: s.sort_index(level=1)
Out[107]: 
bar  one    0.299368
baz  one   -2.213588
foo  one   -0.863838
qux  one    1.266143
bar  two   -0.251905
baz  two    1.063327
foo  two    0.206053
qux  two    0.408204
dtype: float64

---->   pandas.Series; pandas.MultiIndex

--------------------------------------
ID: 2435 --> 1
In [112]: dfm = pd.DataFrame(
   .....:     {"jim": [0, 0, 1, 1], "joe": ["x", "x", "z", "y"], "jolie": np.random.rand(4)}
   .....: )
   .....: 

In [113]: dfm = dfm.set_index(["jim", "joe"])

In [114]: dfm
Out[114]: 
            jolie
jim joe          
0   x    0.490671
    x    0.120248
1   z    0.537020
    y    0.110968

---->   pandas.DataFrame

--------------------------------------
ID: 2440 --> 4
In [120]: index = pd.Index(np.random.randint(0, 1000, 10))

In [121]: index
Out[121]: Index([214, 502, 712, 567, 786, 175, 993, 133, 758, 329], dtype='int64')

In [122]: positions = [0, 9, 3]

In [123]: index[positions]
Out[123]: Index([214, 329, 567], dtype='int64')

In [124]: index.take(positions)
Out[124]: Index([214, 329, 567], dtype='int64')

In [125]: ser = pd.Series(np.random.randn(10))

In [126]: ser.iloc[positions]
Out[126]: 
0   -0.179666
9    1.824375
3    0.392149
dtype: float64

In [127]: ser.take(positions)
Out[127]: 
0   -0.179666
9    1.824375
3    0.392149
dtype: float64

---->   pandas.Index; Index.take; pandas.Series; Series.take

--------------------------------------
ID: 2441 --> 2
In [128]: frm = pd.DataFrame(np.random.randn(5, 3))

In [129]: frm.take([1, 4, 3])
Out[129]: 
          0         1         2
1 -1.237881  0.106854 -1.276829
4  0.629675 -1.425966  1.857704
3  0.979542 -1.633678  0.615855

In [130]: frm.take([0, 2], axis=1)
Out[130]: 
          0         2
0  0.595974  0.601544
1 -1.237881 -1.276829
2 -0.767101  1.499591
3  0.979542  0.615855
4  0.629675  1.857704

---->   pandas.DataFrame; DataFrame.take

--------------------------------------
ID: 2442 --> 2
In [131]: arr = np.random.randn(10)

In [132]: arr.take([False, False, True, True])
Out[132]: array([-1.1935, -1.1935,  0.6775,  0.6775])

In [133]: arr[[0, 1]]
Out[133]: array([-1.1935,  0.6775])

In [134]: ser = pd.Series(np.random.randn(10))

In [135]: ser.take([False, False, True, True])
Out[135]: 
0    0.233141
0    0.233141
1   -0.223540
1   -0.223540
dtype: float64

In [136]: ser.iloc[[0, 1]]
Out[136]: 
0    0.233141
1   -0.223540
dtype: float64

---->   pandas.Series; Series.take

--------------------------------------
ID: 2444 --> 2
In [141]: ser = pd.Series(arr[:, 0])

In [142]: %timeit ser.iloc[indexer]
   .....: %timeit ser.take(indexer)
   .....: 
77.3 us +- 1.45 us per loop (mean +- std. dev. of 7 runs, 10,000 loops each)
64.1 us +- 155 ns per loop (mean +- std. dev. of 7 runs, 10,000 loops each)

---->   pandas.Series; Series.take

--------------------------------------
ID: 2445 --> 1
In [143]: from pandas.api.types import CategoricalDtype

In [144]: df = pd.DataFrame({"A": np.arange(6), "B": list("aabbca")})

In [145]: df["B"] = df["B"].astype(CategoricalDtype(list("cab")))

In [146]: df
Out[146]: 
   A  B
0  0  a
1  1  a
2  2  b
3  3  b
4  4  c
5  5  a

In [147]: df.dtypes
Out[147]: 
A       int64
B    category
dtype: object

In [148]: df["B"].cat.categories
Out[148]: Index(['c', 'a', 'b'], dtype='object')

---->   pandas.DataFrame

--------------------------------------
ID: 2449 --> 1
In [154]: df2.groupby(level=0).sum()
Out[154]: 
   A
B   
c  4
a  6
b  5

In [155]: df2.groupby(level=0).sum().index
Out[155]: CategoricalIndex(['c', 'a', 'b'], categories=['c', 'a', 'b'], ordered=False, dtype='category', name='B')

---->   DataFrame.groupby

--------------------------------------
ID: 2450 --> 2
In [156]: df3 = pd.DataFrame(
   .....:     {"A": np.arange(3), "B": pd.Series(list("abc")).astype("category")}
   .....: )
   .....: 

In [157]: df3 = df3.set_index("B")

In [158]: df3
Out[158]: 
   A
B   
a  0
b  1
c  2

---->   pandas.DataFrame; pandas.Series

--------------------------------------
ID: 2451 --> 1
In [159]: df3.reindex(["a", "e"])
Out[159]: 
     A
B     
a  0.0
e  NaN

In [160]: df3.reindex(["a", "e"]).index
Out[160]: Index(['a', 'e'], dtype='object', name='B')

In [161]: df3.reindex(pd.Categorical(["a", "e"], categories=list("abe")))
Out[161]: 
     A
B     
a  0.0
e  NaN

In [162]: df3.reindex(pd.Categorical(["a", "e"], categories=list("abe"))).index
Out[162]: CategoricalIndex(['a', 'e'], categories=['a', 'b', 'e'], ordered=False, dtype='category', name='B')

---->   pandas.Categorical

--------------------------------------
ID: 2452 --> 1
In [163]: df4 = pd.DataFrame({"A": np.arange(2), "B": list("ba")})

In [164]: df4["B"] = df4["B"].astype(CategoricalDtype(list("ab")))

In [165]: df4 = df4.set_index("B")

In [166]: df4.index
Out[166]: CategoricalIndex(['b', 'a'], categories=['a', 'b'], ordered=False, dtype='category', name='B')

In [167]: df5 = pd.DataFrame({"A": np.arange(2), "B": list("bc")})

In [168]: df5["B"] = df5["B"].astype(CategoricalDtype(list("bc")))

In [169]: df5 = df5.set_index("B")

In [170]: df5.index
Out[170]: CategoricalIndex(['b', 'c'], categories=['b', 'c'], ordered=False, dtype='category', name='B')

---->   pandas.DataFrame

--------------------------------------
ID: 2454 --> 1
In [171]: idx = pd.RangeIndex(5)

In [172]: idx
Out[172]: RangeIndex(start=0, stop=5, step=1)

---->   pandas.RangeIndex

--------------------------------------
ID: 2455 --> 2
In [173]: ser = pd.Series([1, 2, 3])

In [174]: ser.index
Out[174]: RangeIndex(start=0, stop=3, step=1)

In [175]: df = pd.DataFrame([[1, 2], [3, 4]])

In [176]: df.index
Out[176]: RangeIndex(start=0, stop=2, step=1)

In [177]: df.columns
Out[177]: RangeIndex(start=0, stop=2, step=1)

---->   pandas.Series; pandas.DataFrame

--------------------------------------
ID: 2457 --> 2
In [179]: df = pd.DataFrame(
   .....:     {"A": [1, 2, 3, 4]}, index=pd.IntervalIndex.from_breaks([0, 1, 2, 3, 4])
   .....: )
   .....: 

In [180]: df
Out[180]: 
        A
(0, 1]  1
(1, 2]  2
(2, 3]  3
(3, 4]  4

---->   pandas.DataFrame; pandas.IntervalIndex

--------------------------------------
ID: 2460 --> 1
In [185]: df.loc[pd.Interval(1, 2)]
Out[185]: 
A    2
Name: (1, 2], dtype: int64

---->   pandas.Interval

--------------------------------------
ID: 2461 --> 1
In [7]: df.loc[pd.Interval(0.5, 2.5)]
---------------------------------------------------------------------------
KeyError: Interval(0.5, 2.5, closed='right')

---->   pandas.Interval

--------------------------------------
ID: 2462 --> 1
In [186]: idxr = df.index.overlaps(pd.Interval(0.5, 2.5))

In [187]: idxr
Out[187]: array([ True,  True,  True, False])

In [188]: df[idxr]
Out[188]: 
        A
(0, 1]  1
(1, 2]  2
(2, 3]  3

---->   pandas.Interval

--------------------------------------
ID: 2463 --> 1
In [189]: c = pd.cut(range(4), bins=2)

In [190]: c
Out[190]: 
[(-0.003, 1.5], (-0.003, 1.5], (1.5, 3.0], (1.5, 3.0]]
Categories (2, interval[float64, right]): [(-0.003, 1.5] < (1.5, 3.0]]

In [191]: c.categories
Out[191]: IntervalIndex([(-0.003, 1.5], (1.5, 3.0]], dtype='interval[float64, right]')

---->   pandas.cut

--------------------------------------
ID: 2464 --> 1
In [192]: pd.cut([0, 3, 5, 1], bins=c.categories)
Out[192]: 
[(-0.003, 1.5], (1.5, 3.0], NaN, (-0.003, 1.5]]
Categories (2, interval[float64, right]): [(-0.003, 1.5] < (1.5, 3.0]]

---->   pandas.cut

--------------------------------------
ID: 2465 --> 1
In [193]: pd.interval_range(start=0, end=5)
Out[193]: IntervalIndex([(0, 1], (1, 2], (2, 3], (3, 4], (4, 5]], dtype='interval[int64, right]')

In [194]: pd.interval_range(start=pd.Timestamp("2017-01-01"), periods=4)
Out[194]: IntervalIndex([(2017-01-01, 2017-01-02], (2017-01-02, 2017-01-03], (2017-01-03, 2017-01-04], (2017-01-04, 2017-01-05]], dtype='interval[datetime64[ns], right]')

In [195]: pd.interval_range(end=pd.Timedelta("3 days"), periods=3)
Out[195]: IntervalIndex([(0 days 00:00:00, 1 days 00:00:00], (1 days 00:00:00, 2 days 00:00:00], (2 days 00:00:00, 3 days 00:00:00]], dtype='interval[timedelta64[ns], right]')

---->   pandas.interval_range

--------------------------------------
ID: 2466 --> 1
In [196]: pd.interval_range(start=0, periods=5, freq=1.5)
Out[196]: IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0], (6.0, 7.5]], dtype='interval[float64, right]')

In [197]: pd.interval_range(start=pd.Timestamp("2017-01-01"), periods=4, freq="W")
Out[197]: IntervalIndex([(2017-01-01, 2017-01-08], (2017-01-08, 2017-01-15], (2017-01-15, 2017-01-22], (2017-01-22, 2017-01-29]], dtype='interval[datetime64[ns], right]')

In [198]: pd.interval_range(start=pd.Timedelta("0 days"), periods=3, freq="9H")
Out[198]: IntervalIndex([(0 days 00:00:00, 0 days 09:00:00], (0 days 09:00:00, 0 days 18:00:00], (0 days 18:00:00, 1 days 03:00:00]], dtype='interval[timedelta64[ns], right]')

---->   pandas.interval_range

--------------------------------------
ID: 2467 --> 1
In [199]: pd.interval_range(start=0, end=4, closed="both")
Out[199]: IntervalIndex([[0, 1], [1, 2], [2, 3], [3, 4]], dtype='interval[int64, both]')

In [200]: pd.interval_range(start=0, end=4, closed="neither")
Out[200]: IntervalIndex([(0, 1), (1, 2), (2, 3), (3, 4)], dtype='interval[int64, neither]')

---->   pandas.interval_range

--------------------------------------
ID: 2468 --> 1
In [201]: pd.interval_range(start=0, end=6, periods=4)
Out[201]: IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]], dtype='interval[float64, right]')

In [202]: pd.interval_range(pd.Timestamp("2018-01-01"), pd.Timestamp("2018-02-28"), periods=3)
Out[202]: IntervalIndex([(2018-01-01, 2018-01-20 08:00:00], (2018-01-20 08:00:00, 2018-02-08 16:00:00], (2018-02-08 16:00:00, 2018-02-28]], dtype='interval[datetime64[ns], right]')

---->   pandas.interval_range

--------------------------------------
ID: 2469 --> 2
In [203]: s = pd.Series(range(5))

In [204]: s[-1]
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
File ~/work/pandas/pandas/pandas/core/indexes/range.py:345, in RangeIndex.get_loc(self, key)
    344 try:
--> 345     return self._range.index(new_key)
    346 except ValueError as err:

ValueError: -1 is not in range

The above exception was the direct cause of the following exception:

KeyError                                  Traceback (most recent call last)
Cell In[204], line 1
----> 1 s[-1]

File ~/work/pandas/pandas/pandas/core/series.py:1007, in Series.__getitem__(self, key)
   1004     return self._values[key]
   1006 elif key_is_scalar:
-> 1007     return self._get_value(key)
   1009 if is_hashable(key):
   1010     # Otherwise index.get_value will raise InvalidIndexError
   1011     try:
   1012         # For labels that don't resolve as scalars like tuples and frozensets

File ~/work/pandas/pandas/pandas/core/series.py:1116, in Series._get_value(self, label, takeable)
   1113     return self._values[label]
   1115 # Similar to Index.get_value, but we do not fall back to positional
-> 1116 loc = self.index.get_loc(label)
   1118 if is_integer(loc):
   1119     return self._values[loc]

File ~/work/pandas/pandas/pandas/core/indexes/range.py:347, in RangeIndex.get_loc(self, key)
    345         return self._range.index(new_key)
    346     except ValueError as err:
--> 347         raise KeyError(key) from err
    348 if isinstance(key, Hashable):
    349     raise KeyError(key)

KeyError: -1

In [205]: df = pd.DataFrame(np.random.randn(5, 4))

In [206]: df
Out[206]: 
          0         1         2         3
0 -0.435772 -1.188928 -0.808286 -0.284634
1 -1.815703  1.347213 -0.243487  0.514704
2  1.162969 -0.287725 -0.179734  0.993962
3 -0.212673  0.909872 -0.733333 -0.349893
4  0.456434 -0.306735  0.553396  0.166221

In [207]: df.loc[-2:]
Out[207]: 
          0         1         2         3
0 -0.435772 -1.188928 -0.808286 -0.284634
1 -1.815703  1.347213 -0.243487  0.514704
2  1.162969 -0.287725 -0.179734  0.993962
3 -0.212673  0.909872 -0.733333 -0.349893
4  0.456434 -0.306735  0.553396  0.166221

---->   pandas.Series; pandas.DataFrame

--------------------------------------
ID: 2470 --> 1
In [208]: df = pd.DataFrame(index=[2, 3, 3, 4, 5], columns=["data"], data=list(range(5)))

In [209]: df.index.is_monotonic_increasing
Out[209]: True

# no rows 0 or 1, but still returns rows 2, 3 (both of them), and 4:
In [210]: df.loc[0:4, :]
Out[210]: 
   data
2     0
3     1
3     2
4     3

# slice is are outside the index, so empty DataFrame is returned
In [211]: df.loc[13:15, :]
Out[211]: 
Empty DataFrame
Columns: [data]
Index: []

---->   pandas.DataFrame

--------------------------------------
ID: 2471 --> 1
In [212]: df = pd.DataFrame(index=[2, 3, 1, 4, 3, 5], columns=["data"], data=list(range(6)))

In [213]: df.index.is_monotonic_increasing
Out[213]: False

# OK because 2 and 4 are in the index
In [214]: df.loc[2:4, :]
Out[214]: 
   data
2     0
3     1
1     2
4     3

---->   pandas.DataFrame

--------------------------------------
ID: 2472 --> 1
In [215]: weakly_monotonic = pd.Index(["a", "b", "c", "c"])

In [216]: weakly_monotonic
Out[216]: Index(['a', 'b', 'c', 'c'], dtype='object')

In [217]: weakly_monotonic.is_monotonic_increasing
Out[217]: True

In [218]: weakly_monotonic.is_monotonic_increasing & weakly_monotonic.is_unique
Out[218]: False

---->   pandas.Index

--------------------------------------
ID: 2473 --> 1
In [219]: s = pd.Series(np.random.randn(6), index=list("abcdef"))

In [220]: s
Out[220]: 
a   -0.101684
b   -0.734907
c   -0.130121
d   -0.476046
e    0.759104
f    0.213379
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 2474 --> 1
In [223]: series1 = pd.Series([1, 2, 3])

In [224]: series1.dtype
Out[224]: dtype('int64')

In [225]: res = series1.reindex([0, 4])

In [226]: res.dtype
Out[226]: dtype('float64')

In [227]: res
Out[227]: 
0    1.0
4    NaN
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 2475 --> 2
In [228]: series2 = pd.Series([True])

In [229]: series2.dtype
Out[229]: dtype('bool')

In [230]: res = series2.reindex_like(series1)

In [231]: res.dtype
Out[231]: dtype('O')

In [232]: res
Out[232]: 
0    True
1     NaN
2     NaN
dtype: object

---->   pandas.Series; Series.reindex_like

--------------------------------------
ID: 2476 --> 1
In [1]: import datetime

In [2]: dti = pd.to_datetime(
   ...:     ["1/1/2018", np.datetime64("2018-01-01"), datetime.datetime(2018, 1, 1)]
   ...: )
   ...: 

In [3]: dti
Out[3]: DatetimeIndex(['2018-01-01', '2018-01-01', '2018-01-01'], dtype='datetime64[ns]', freq=None)

---->   pandas.to_datetime

--------------------------------------
ID: 2479 --> 2
In [9]: idx = pd.date_range("2018-01-01", periods=5, freq="H")

In [10]: ts = pd.Series(range(len(idx)), index=idx)

In [11]: ts
Out[11]: 
2018-01-01 00:00:00    0
2018-01-01 01:00:00    1
2018-01-01 02:00:00    2
2018-01-01 03:00:00    3
2018-01-01 04:00:00    4
Freq: H, dtype: int64

In [12]: ts.resample("2H").mean()
Out[12]: 
2018-01-01 00:00:00    0.5
2018-01-01 02:00:00    2.5
2018-01-01 04:00:00    4.0
Freq: 2H, dtype: float64

---->   pandas.Series; Series.resample

--------------------------------------
ID: 2481 --> 1
In [19]: pd.Series(range(3), index=pd.date_range("2000", freq="D", periods=3))
Out[19]: 
2000-01-01    0
2000-01-02    1
2000-01-03    2
Freq: D, dtype: int64

---->   pandas.Series

--------------------------------------
ID: 2482 --> 1
In [20]: pd.Series(pd.date_range("2000", freq="D", periods=3))
Out[20]: 
0   2000-01-01
1   2000-01-02
2   2000-01-03
dtype: datetime64[ns]

---->   pandas.Series

--------------------------------------
ID: 2483 --> 2
In [21]: pd.Series(pd.period_range("1/1/2011", freq="M", periods=3))
Out[21]: 
0    2011-01
1    2011-02
2    2011-03
dtype: period[M]

In [22]: pd.Series([pd.DateOffset(1), pd.DateOffset(2)])
Out[22]: 
0         
1    <2 * DateOffsets>
dtype: object

In [23]: pd.Series(pd.date_range("1/1/2011", freq="M", periods=3))
Out[23]: 
0   2011-01-31
1   2011-02-28
2   2011-03-31
dtype: datetime64[ns]

---->   pandas.Series; pandas.period_range

--------------------------------------
ID: 2484 --> 1
In [24]: pd.Timestamp(pd.NaT)
Out[24]: NaT

In [25]: pd.Timedelta(pd.NaT)
Out[25]: NaT

In [26]: pd.Period(pd.NaT)
Out[26]: NaT

# Equality acts as np.nan would
In [27]: pd.NaT == pd.NaT
Out[27]: False

---->   pandas.Period

--------------------------------------
ID: 2486 --> 1
In [32]: pd.Period("2011-01")
Out[32]: Period('2011-01', 'M')

In [33]: pd.Period("2012-05", freq="D")
Out[33]: Period('2012-05-01', 'D')

---->   pandas.Period

--------------------------------------
ID: 2487 --> 2
In [34]: dates = [
   ....:     pd.Timestamp("2012-05-01"),
   ....:     pd.Timestamp("2012-05-02"),
   ....:     pd.Timestamp("2012-05-03"),
   ....: ]
   ....: 

In [35]: ts = pd.Series(np.random.randn(3), dates)

In [36]: type(ts.index)
Out[36]: pandas.core.indexes.datetimes.DatetimeIndex

In [37]: ts.index
Out[37]: DatetimeIndex(['2012-05-01', '2012-05-02', '2012-05-03'], dtype='datetime64[ns]', freq=None)

In [38]: ts
Out[38]: 
2012-05-01    0.469112
2012-05-02   -0.282863
2012-05-03   -1.509059
dtype: float64

In [39]: periods = [pd.Period("2012-01"), pd.Period("2012-02"), pd.Period("2012-03")]

In [40]: ts = pd.Series(np.random.randn(3), periods)

In [41]: type(ts.index)
Out[41]: pandas.core.indexes.period.PeriodIndex

In [42]: ts.index
Out[42]: PeriodIndex(['2012-01', '2012-02', '2012-03'], dtype='period[M]')

In [43]: ts
Out[43]: 
2012-01   -1.135632
2012-02    1.212112
2012-03   -0.173215
Freq: M, dtype: float64

---->   pandas.Series; pandas.Period

--------------------------------------
ID: 2488 --> 2
In [44]: pd.to_datetime(pd.Series(["Jul 31, 2009", "Jan 10, 2010", None]))
Out[44]: 
0   2009-07-31
1   2010-01-10
2          NaT
dtype: datetime64[ns]

In [45]: pd.to_datetime(["2005/11/23", "2010/12/31"])
Out[45]: DatetimeIndex(['2005-11-23', '2010-12-31'], dtype='datetime64[ns]', freq=None)

---->   pandas.to_datetime; pandas.Series

--------------------------------------
ID: 2489 --> 1
In [46]: pd.to_datetime(["04-01-2012 10:00"], dayfirst=True)
Out[46]: DatetimeIndex(['2012-01-04 10:00:00'], dtype='datetime64[ns]', freq=None)

In [47]: pd.to_datetime(["04-14-2012 10:00"], dayfirst=True)
Out[47]: DatetimeIndex(['2012-04-14 10:00:00'], dtype='datetime64[ns]', freq=None)

---->   pandas.to_datetime

--------------------------------------
ID: 2490 --> 1
In [48]: pd.to_datetime("2010/11/12")
Out[48]: Timestamp('2010-11-12 00:00:00')

In [49]: pd.Timestamp("2010/11/12")
Out[49]: Timestamp('2010-11-12 00:00:00')

---->   pandas.to_datetime

--------------------------------------
ID: 2491 --> 1
In [50]: pd.DatetimeIndex(["2018-01-01", "2018-01-03", "2018-01-05"])
Out[50]: DatetimeIndex(['2018-01-01', '2018-01-03', '2018-01-05'], dtype='datetime64[ns]', freq=None)

---->   pandas.DatetimeIndex

--------------------------------------
ID: 2492 --> 1
In [51]: pd.DatetimeIndex(["2018-01-01", "2018-01-03", "2018-01-05"], freq="infer")
Out[51]: DatetimeIndex(['2018-01-01', '2018-01-03', '2018-01-05'], dtype='datetime64[ns]', freq='2D')

---->   pandas.DatetimeIndex

--------------------------------------
ID: 2493 --> 1
In [52]: pd.to_datetime("2010/11/12", format="%Y/%m/%d")
Out[52]: Timestamp('2010-11-12 00:00:00')

In [53]: pd.to_datetime("12-11-2010 00:00", format="%d-%m-%Y %H:%M")
Out[53]: Timestamp('2010-11-12 00:00:00')

---->   pandas.to_datetime

--------------------------------------
ID: 2494 --> 2
In [54]: df = pd.DataFrame(
   ....:     {"year": [2015, 2016], "month": [2, 3], "day": [4, 5], "hour": [2, 3]}
   ....: )
   ....: 

In [55]: pd.to_datetime(df)
Out[55]: 
0   2015-02-04 02:00:00
1   2016-03-05 03:00:00
dtype: datetime64[ns]

---->   pandas.DataFrame; pandas.to_datetime

--------------------------------------
ID: 2495 --> 1
In [56]: pd.to_datetime(df[["year", "month", "day"]])
Out[56]: 
0   2015-02-04
1   2016-03-05
dtype: datetime64[ns]

---->   pandas.to_datetime

--------------------------------------
ID: 2496 --> 1
In [2]: pd.to_datetime(['2009/07/31', 'asd'], errors='raise')
ValueError: Unknown datetime string format

---->   pandas.to_datetime

--------------------------------------
ID: 2497 --> 1
In [57]: pd.to_datetime(["2009/07/31", "asd"], errors="ignore")
Out[57]: Index(['2009/07/31', 'asd'], dtype='object')

---->   pandas.to_datetime

--------------------------------------
ID: 2498 --> 1
In [58]: pd.to_datetime(["2009/07/31", "asd"], errors="coerce")
Out[58]: DatetimeIndex(['2009-07-31', 'NaT'], dtype='datetime64[ns]', freq=None)

---->   pandas.to_datetime

--------------------------------------
ID: 2499 --> 1
In [59]: pd.to_datetime(
   ....:     [1349720105, 1349806505, 1349892905, 1349979305, 1350065705], unit="s"
   ....: )
   ....: 
Out[59]: 
DatetimeIndex(['2012-10-08 18:15:05', '2012-10-09 18:15:05',
               '2012-10-10 18:15:05', '2012-10-11 18:15:05',
               '2012-10-12 18:15:05'],
              dtype='datetime64[ns]', freq=None)

In [60]: pd.to_datetime(
   ....:     [1349720105100, 1349720105200, 1349720105300, 1349720105400, 1349720105500],
   ....:     unit="ms",
   ....: )
   ....: 
Out[60]: 
DatetimeIndex(['2012-10-08 18:15:05.100000', '2012-10-08 18:15:05.200000',
               '2012-10-08 18:15:05.300000', '2012-10-08 18:15:05.400000',
               '2012-10-08 18:15:05.500000'],
              dtype='datetime64[ns]', freq=None)

---->   pandas.to_datetime

--------------------------------------
ID: 2500 --> 1
In [61]: pd.Timestamp(1262347200000000000).tz_localize("US/Pacific")
Out[61]: Timestamp('2010-01-01 12:00:00-0800', tz='US/Pacific')

In [62]: pd.DatetimeIndex([1262347200000000000]).tz_localize("US/Pacific")
Out[62]: DatetimeIndex(['2010-01-01 12:00:00-08:00'], dtype='datetime64[ns, US/Pacific]', freq=None)

---->   pandas.DatetimeIndex

--------------------------------------
ID: 2501 --> 1
In [63]: pd.to_datetime([1490195805.433, 1490195805.433502912], unit="s")
Out[63]: DatetimeIndex(['2017-03-22 15:16:45.433000088', '2017-03-22 15:16:45.433502913'], dtype='datetime64[ns]', freq=None)

In [64]: pd.to_datetime(1490195805433502912, unit="ns")
Out[64]: Timestamp('2017-03-22 15:16:45.433502912')

---->   pandas.to_datetime

--------------------------------------
ID: 2504 --> 1
In [68]: pd.to_datetime([1, 2, 3], unit="D", origin=pd.Timestamp("1960-01-01"))
Out[68]: DatetimeIndex(['1960-01-02', '1960-01-03', '1960-01-04'], dtype='datetime64[ns]', freq=None)

---->   pandas.to_datetime

--------------------------------------
ID: 2505 --> 1
In [69]: pd.to_datetime([1, 2, 3], unit="D")
Out[69]: DatetimeIndex(['1970-01-02', '1970-01-03', '1970-01-04'], dtype='datetime64[ns]', freq=None)

---->   pandas.to_datetime

--------------------------------------
ID: 2506 --> 2
In [70]: dates = [
   ....:     datetime.datetime(2012, 5, 1),
   ....:     datetime.datetime(2012, 5, 2),
   ....:     datetime.datetime(2012, 5, 3),
   ....: ]
   ....: 

# Note the frequency information
In [71]: index = pd.DatetimeIndex(dates)

In [72]: index
Out[72]: DatetimeIndex(['2012-05-01', '2012-05-02', '2012-05-03'], dtype='datetime64[ns]', freq=None)

# Automatically converted to DatetimeIndex
In [73]: index = pd.Index(dates)

In [74]: index
Out[74]: DatetimeIndex(['2012-05-01', '2012-05-02', '2012-05-03'], dtype='datetime64[ns]', freq=None)

---->   pandas.DatetimeIndex; pandas.Index

--------------------------------------
ID: 2507 --> 1
In [75]: start = datetime.datetime(2011, 1, 1)

In [76]: end = datetime.datetime(2012, 1, 1)

In [77]: index = pd.date_range(start, end)

In [78]: index
Out[78]: 
DatetimeIndex(['2011-01-01', '2011-01-02', '2011-01-03', '2011-01-04',
               '2011-01-05', '2011-01-06', '2011-01-07', '2011-01-08',
               '2011-01-09', '2011-01-10',
               ...
               '2011-12-23', '2011-12-24', '2011-12-25', '2011-12-26',
               '2011-12-27', '2011-12-28', '2011-12-29', '2011-12-30',
               '2011-12-31', '2012-01-01'],
              dtype='datetime64[ns]', length=366, freq='D')

In [79]: index = pd.bdate_range(start, end)

In [80]: index
Out[80]: 
DatetimeIndex(['2011-01-03', '2011-01-04', '2011-01-05', '2011-01-06',
               '2011-01-07', '2011-01-10', '2011-01-11', '2011-01-12',
               '2011-01-13', '2011-01-14',
               ...
               '2011-12-19', '2011-12-20', '2011-12-21', '2011-12-22',
               '2011-12-23', '2011-12-26', '2011-12-27', '2011-12-28',
               '2011-12-29', '2011-12-30'],
              dtype='datetime64[ns]', length=260, freq='B')

---->   pandas.bdate_range

--------------------------------------
ID: 2508 --> 1
In [81]: pd.date_range(start, periods=1000, freq="M")
Out[81]: 
DatetimeIndex(['2011-01-31', '2011-02-28', '2011-03-31', '2011-04-30',
               '2011-05-31', '2011-06-30', '2011-07-31', '2011-08-31',
               '2011-09-30', '2011-10-31',
               ...
               '2093-07-31', '2093-08-31', '2093-09-30', '2093-10-31',
               '2093-11-30', '2093-12-31', '2094-01-31', '2094-02-28',
               '2094-03-31', '2094-04-30'],
              dtype='datetime64[ns]', length=1000, freq='M')

In [82]: pd.bdate_range(start, periods=250, freq="BQS")
Out[82]: 
DatetimeIndex(['2011-01-03', '2011-04-01', '2011-07-01', '2011-10-03',
               '2012-01-02', '2012-04-02', '2012-07-02', '2012-10-01',
               '2013-01-01', '2013-04-01',
               ...
               '2071-01-01', '2071-04-01', '2071-07-01', '2071-10-01',
               '2072-01-01', '2072-04-01', '2072-07-01', '2072-10-03',
               '2073-01-02', '2073-04-03'],
              dtype='datetime64[ns]', length=250, freq='BQS-JAN')

---->   pandas.bdate_range

--------------------------------------
ID: 2509 --> 1
In [83]: pd.date_range(start, end, freq="BM")
Out[83]: 
DatetimeIndex(['2011-01-31', '2011-02-28', '2011-03-31', '2011-04-29',
               '2011-05-31', '2011-06-30', '2011-07-29', '2011-08-31',
               '2011-09-30', '2011-10-31', '2011-11-30', '2011-12-30'],
              dtype='datetime64[ns]', freq='BM')

In [84]: pd.date_range(start, end, freq="W")
Out[84]: 
DatetimeIndex(['2011-01-02', '2011-01-09', '2011-01-16', '2011-01-23',
               '2011-01-30', '2011-02-06', '2011-02-13', '2011-02-20',
               '2011-02-27', '2011-03-06', '2011-03-13', '2011-03-20',
               '2011-03-27', '2011-04-03', '2011-04-10', '2011-04-17',
               '2011-04-24', '2011-05-01', '2011-05-08', '2011-05-15',
               '2011-05-22', '2011-05-29', '2011-06-05', '2011-06-12',
               '2011-06-19', '2011-06-26', '2011-07-03', '2011-07-10',
               '2011-07-17', '2011-07-24', '2011-07-31', '2011-08-07',
               '2011-08-14', '2011-08-21', '2011-08-28', '2011-09-04',
               '2011-09-11', '2011-09-18', '2011-09-25', '2011-10-02',
               '2011-10-09', '2011-10-16', '2011-10-23', '2011-10-30',
               '2011-11-06', '2011-11-13', '2011-11-20', '2011-11-27',
               '2011-12-04', '2011-12-11', '2011-12-18', '2011-12-25',
               '2012-01-01'],
              dtype='datetime64[ns]', freq='W-SUN')

In [85]: pd.bdate_range(end=end, periods=20)
Out[85]: 
DatetimeIndex(['2011-12-05', '2011-12-06', '2011-12-07', '2011-12-08',
               '2011-12-09', '2011-12-12', '2011-12-13', '2011-12-14',
               '2011-12-15', '2011-12-16', '2011-12-19', '2011-12-20',
               '2011-12-21', '2011-12-22', '2011-12-23', '2011-12-26',
               '2011-12-27', '2011-12-28', '2011-12-29', '2011-12-30'],
              dtype='datetime64[ns]', freq='B')

In [86]: pd.bdate_range(start=start, periods=20)
Out[86]: 
DatetimeIndex(['2011-01-03', '2011-01-04', '2011-01-05', '2011-01-06',
               '2011-01-07', '2011-01-10', '2011-01-11', '2011-01-12',
               '2011-01-13', '2011-01-14', '2011-01-17', '2011-01-18',
               '2011-01-19', '2011-01-20', '2011-01-21', '2011-01-24',
               '2011-01-25', '2011-01-26', '2011-01-27', '2011-01-28'],
              dtype='datetime64[ns]', freq='B')

---->   pandas.bdate_range

--------------------------------------
ID: 2511 --> 1
In [89]: weekmask = "Mon Wed Fri"

In [90]: holidays = [datetime.datetime(2011, 1, 5), datetime.datetime(2011, 3, 14)]

In [91]: pd.bdate_range(start, end, freq="C", weekmask=weekmask, holidays=holidays)
Out[91]: 
DatetimeIndex(['2011-01-03', '2011-01-07', '2011-01-10', '2011-01-12',
               '2011-01-14', '2011-01-17', '2011-01-19', '2011-01-21',
               '2011-01-24', '2011-01-26',
               ...
               '2011-12-09', '2011-12-12', '2011-12-14', '2011-12-16',
               '2011-12-19', '2011-12-21', '2011-12-23', '2011-12-26',
               '2011-12-28', '2011-12-30'],
              dtype='datetime64[ns]', length=154, freq='C')

In [92]: pd.bdate_range(start, end, freq="CBMS", weekmask=weekmask)
Out[92]: 
DatetimeIndex(['2011-01-03', '2011-02-02', '2011-03-02', '2011-04-01',
               '2011-05-02', '2011-06-01', '2011-07-01', '2011-08-01',
               '2011-09-02', '2011-10-03', '2011-11-02', '2011-12-02'],
              dtype='datetime64[ns]', freq='CBMS')

---->   pandas.bdate_range

--------------------------------------
ID: 2513 --> 1
In [95]: rng = pd.date_range(start, end, freq="BM")

In [96]: ts = pd.Series(np.random.randn(len(rng)), index=rng)

In [97]: ts.index
Out[97]: 
DatetimeIndex(['2011-01-31', '2011-02-28', '2011-03-31', '2011-04-29',
               '2011-05-31', '2011-06-30', '2011-07-29', '2011-08-31',
               '2011-09-30', '2011-10-31', '2011-11-30', '2011-12-30'],
              dtype='datetime64[ns]', freq='BM')

In [98]: ts[:5].index
Out[98]: 
DatetimeIndex(['2011-01-31', '2011-02-28', '2011-03-31', '2011-04-29',
               '2011-05-31'],
              dtype='datetime64[ns]', freq='BM')

In [99]: ts[::2].index
Out[99]: 
DatetimeIndex(['2011-01-31', '2011-03-31', '2011-05-31', '2011-07-29',
               '2011-09-30', '2011-11-30'],
              dtype='datetime64[ns]', freq='2BM')

---->   pandas.Series

--------------------------------------
ID: 2515 --> 1
In [105]: dft = pd.DataFrame(
   .....:     np.random.randn(100000, 1),
   .....:     columns=["A"],
   .....:     index=pd.date_range("20130101", periods=100000, freq="T"),
   .....: )
   .....: 

In [106]: dft
Out[106]: 
                            A
2013-01-01 00:00:00  0.276232
2013-01-01 00:01:00 -1.087401
2013-01-01 00:02:00 -0.673690
2013-01-01 00:03:00  0.113648
2013-01-01 00:04:00 -1.478427
...                       ...
2013-03-11 10:35:00 -0.747967
2013-03-11 10:36:00 -0.034523
2013-03-11 10:37:00 -0.201754
2013-03-11 10:38:00 -1.509067
2013-03-11 10:39:00 -1.693043

[100000 rows x 1 columns]

In [107]: dft.loc["2013"]
Out[107]: 
                            A
2013-01-01 00:00:00  0.276232
2013-01-01 00:01:00 -1.087401
2013-01-01 00:02:00 -0.673690
2013-01-01 00:03:00  0.113648
2013-01-01 00:04:00 -1.478427
...                       ...
2013-03-11 10:35:00 -0.747967
2013-03-11 10:36:00 -0.034523
2013-03-11 10:37:00 -0.201754
2013-03-11 10:38:00 -1.509067
2013-03-11 10:39:00 -1.693043

[100000 rows x 1 columns]

---->   pandas.DataFrame

--------------------------------------
ID: 2516 --> 2
In [112]: dft2 = pd.DataFrame(
   .....:     np.random.randn(20, 1),
   .....:     columns=["A"],
   .....:     index=pd.MultiIndex.from_product(
   .....:         [pd.date_range("20130101", periods=10, freq="12H"), ["a", "b"]]
   .....:     ),
   .....: )
   .....: 

In [113]: dft2
Out[113]: 
                              A
2013-01-01 00:00:00 a -0.298694
                    b  0.823553
2013-01-01 12:00:00 a  0.943285
                    b -1.479399
2013-01-02 00:00:00 a -1.643342
...                         ...
2013-01-04 12:00:00 b  0.069036
2013-01-05 00:00:00 a  0.122297
                    b  1.422060
2013-01-05 12:00:00 a  0.370079
                    b  1.016331

[20 rows x 1 columns]

In [114]: dft2.loc["2013-01-05"]
Out[114]: 
                              A
2013-01-05 00:00:00 a  0.122297
                    b  1.422060
2013-01-05 12:00:00 a  0.370079
                    b  1.016331

In [115]: idx = pd.IndexSlice

In [116]: dft2 = dft2.swaplevel(0, 1).sort_index()

In [117]: dft2.loc[idx[:, "2013-01-05"], :]
Out[117]: 
                              A
a 2013-01-05 00:00:00  0.122297
  2013-01-05 12:00:00  0.370079
b 2013-01-05 00:00:00  1.422060
  2013-01-05 12:00:00  1.016331

---->   pandas.DataFrame; pandas.MultiIndex

--------------------------------------
ID: 2517 --> 2
In [118]: df = pd.DataFrame([0], index=pd.DatetimeIndex(["2019-01-01"], tz="US/Pacific"))

In [119]: df
Out[119]: 
                           0
2019-01-01 00:00:00-08:00  0

In [120]: df["2019-01-01 12:00:00+04:00":"2019-01-01 13:00:00+04:00"]
Out[120]: 
                           0
2019-01-01 00:00:00-08:00  0

---->   pandas.DataFrame; pandas.DatetimeIndex

--------------------------------------
ID: 2518 --> 2
In [121]: series_minute = pd.Series(
   .....:     [1, 2, 3],
   .....:     pd.DatetimeIndex(
   .....:         ["2011-12-31 23:59:00", "2012-01-01 00:00:00", "2012-01-01 00:02:00"]
   .....:     ),
   .....: )
   .....: 

In [122]: series_minute.index.resolution
Out[122]: 'minute'

---->   pandas.Series; pandas.DatetimeIndex

--------------------------------------
ID: 2519 --> 2
In [126]: series_second = pd.Series(
   .....:     [1, 2, 3],
   .....:     pd.DatetimeIndex(
   .....:         ["2011-12-31 23:59:59", "2012-01-01 00:00:00", "2012-01-01 00:00:01"]
   .....:     ),
   .....: )
   .....: 

In [127]: series_second.index.resolution
Out[127]: 'second'

In [128]: series_second["2011-12-31 23:59"]
Out[128]: 
2011-12-31 23:59:59    1
dtype: int64

---->   pandas.Series; pandas.DatetimeIndex

--------------------------------------
ID: 2520 --> 1
In [129]: dft_minute = pd.DataFrame(
   .....:     {"a": [1, 2, 3], "b": [4, 5, 6]}, index=series_minute.index
   .....: )
   .....: 

In [130]: dft_minute.loc["2011-12-31 23"]
Out[130]: 
                     a  b
2011-12-31 23:59:00  1  4

---->   pandas.DataFrame

--------------------------------------
ID: 2521 --> 2
In [132]: series_monthly = pd.Series(
   .....:     [1, 2, 3], pd.DatetimeIndex(["2011-12", "2012-01", "2012-02"])
   .....: )
   .....: 

In [133]: series_monthly.index.resolution
Out[133]: 'day'

In [134]: series_monthly["2011-12"]  # returns Series
Out[134]: 
2011-12-01    1
dtype: int64

---->   pandas.Series; pandas.DatetimeIndex

--------------------------------------
ID: 2524 --> 2
In [137]: rng2 = pd.date_range("2011-01-01", "2012-01-01", freq="W")

In [138]: ts2 = pd.Series(np.random.randn(len(rng2)), index=rng2)

In [139]: ts2.truncate(before="2011-11", after="2011-12")
Out[139]: 
2011-11-06    0.437823
2011-11-13   -0.293083
2011-11-20   -0.059881
2011-11-27    1.252450
Freq: W-SUN, dtype: float64

In [140]: ts2["2011-11":"2011-12"]
Out[140]: 
2011-11-06    0.437823
2011-11-13   -0.293083
2011-11-20   -0.059881
2011-11-27    1.252450
2011-12-04    0.046611
2011-12-11    0.059478
2011-12-18   -0.286539
2011-12-25    0.841669
Freq: W-SUN, dtype: float64

---->   pandas.Series; Series.truncate

--------------------------------------
ID: 2533 --> 1
In [177]: rng = pd.date_range("2012-01-01", "2012-01-03")

In [178]: s = pd.Series(rng)

In [179]: rng
Out[179]: DatetimeIndex(['2012-01-01', '2012-01-02', '2012-01-03'], dtype='datetime64[ns]', freq='D')

In [180]: rng + pd.DateOffset(months=2)
Out[180]: DatetimeIndex(['2012-03-01', '2012-03-02', '2012-03-03'], dtype='datetime64[ns]', freq=None)

In [181]: s + pd.DateOffset(months=2)
Out[181]: 
0   2012-03-01
1   2012-03-02
2   2012-03-03
dtype: datetime64[ns]

In [182]: s - pd.DateOffset(months=2)
Out[182]: 
0   2011-11-01
1   2011-11-02
2   2011-11-03
dtype: datetime64[ns]

---->   pandas.Series

--------------------------------------
ID: 2534 --> 1
In [183]: s - pd.offsets.Day(2)
Out[183]: 
0   2011-12-30
1   2011-12-31
2   2012-01-01
dtype: datetime64[ns]

In [184]: td = s - pd.Series(pd.date_range("2011-12-29", "2011-12-31"))

In [185]: td
Out[185]: 
0   3 days
1   3 days
2   3 days
dtype: timedelta64[ns]

In [186]: td + pd.offsets.Minute(15)
Out[186]: 
0   3 days 00:15:00
1   3 days 00:15:00
2   3 days 00:15:00
dtype: timedelta64[ns]

---->   pandas.Series

--------------------------------------
ID: 2537 --> 1
In [193]: dts = pd.date_range(dt, periods=5, freq=bday_egypt)

In [194]: pd.Series(dts.weekday, dts).map(pd.Series("Mon Tue Wed Thu Fri Sat Sun".split()))
Out[194]: 
2013-04-30    Tue
2013-05-02    Thu
2013-05-05    Sun
2013-05-06    Mon
2013-05-07    Tue
Freq: C, dtype: object

---->   pandas.Series

--------------------------------------
ID: 2557 --> 2
In [279]: ts = pd.Series(range(len(rng)), index=rng)

In [280]: ts = ts[:5]

In [281]: ts.shift(1)
Out[281]: 
2012-01-01    NaN
2012-01-02    0.0
2012-01-03    1.0
Freq: D, dtype: float64

---->   pandas.Series; Series.shift

--------------------------------------
ID: 2558 --> 1
In [282]: ts.shift(5, freq="D")
Out[282]: 
2012-01-06    0
2012-01-07    1
2012-01-08    2
Freq: D, dtype: int64

In [283]: ts.shift(5, freq=pd.offsets.BDay())
Out[283]: 
2012-01-06    0
2012-01-09    1
2012-01-10    2
dtype: int64

In [284]: ts.shift(5, freq="BM")
Out[284]: 
2012-05-31    0
2012-05-31    1
2012-05-31    2
dtype: int64

---->   Series.shift

--------------------------------------
ID: 2559 --> 2
In [285]: dr = pd.date_range("1/1/2010", periods=3, freq=3 * pd.offsets.BDay())

In [286]: ts = pd.Series(np.random.randn(3), index=dr)

In [287]: ts
Out[287]: 
2010-01-01    1.494522
2010-01-06   -0.778425
2010-01-11   -0.253355
Freq: 3B, dtype: float64

In [288]: ts.asfreq(pd.offsets.BDay())
Out[288]: 
2010-01-01    1.494522
2010-01-04         NaN
2010-01-05         NaN
2010-01-06   -0.778425
2010-01-07         NaN
2010-01-08         NaN
2010-01-11   -0.253355
Freq: B, dtype: float64

---->   pandas.Series; Series.asfreq

--------------------------------------
ID: 2560 --> 1
In [289]: ts.asfreq(pd.offsets.BDay(), method="pad")
Out[289]: 
2010-01-01    1.494522
2010-01-04    1.494522
2010-01-05    1.494522
2010-01-06   -0.778425
2010-01-07   -0.778425
2010-01-08   -0.778425
2010-01-11   -0.253355
Freq: B, dtype: float64

---->   Series.asfreq

--------------------------------------
ID: 2561 --> 2
In [290]: rng = pd.date_range("1/1/2012", periods=100, freq="S")

In [291]: ts = pd.Series(np.random.randint(0, 500, len(rng)), index=rng)

In [292]: ts.resample("5Min").sum()
Out[292]: 
2012-01-01    25103
Freq: 5T, dtype: int64

---->   pandas.Series; Series.resample

--------------------------------------
ID: 2562 --> 1
In [293]: ts.resample("5Min").mean()
Out[293]: 
2012-01-01    251.03
Freq: 5T, dtype: float64

In [294]: ts.resample("5Min").ohlc()
Out[294]: 
            open  high  low  close
2012-01-01   308   460    9    205

In [295]: ts.resample("5Min").max()
Out[295]: 
2012-01-01    460
Freq: 5T, dtype: int64

---->   Series.resample

--------------------------------------
ID: 2563 --> 1
In [296]: ts.resample("5Min", closed="right").mean()
Out[296]: 
2011-12-31 23:55:00    308.000000
2012-01-01 00:00:00    250.454545
Freq: 5T, dtype: float64

In [297]: ts.resample("5Min", closed="left").mean()
Out[297]: 
2012-01-01    251.03
Freq: 5T, dtype: float64

---->   Series.resample

--------------------------------------
ID: 2564 --> 1
In [298]: ts.resample("5Min").mean()  # by default label='left'
Out[298]: 
2012-01-01    251.03
Freq: 5T, dtype: float64

In [299]: ts.resample("5Min", label="left").mean()
Out[299]: 
2012-01-01    251.03
Freq: 5T, dtype: float64

---->   Series.resample

--------------------------------------
ID: 2565 --> 1
In [300]: s = pd.date_range("2000-01-01", "2000-01-05").to_series()

In [301]: s.iloc[2] = pd.NaT

In [302]: s.dt.day_name()
Out[302]: 
2000-01-01     Saturday
2000-01-02       Sunday
2000-01-03          NaN
2000-01-04      Tuesday
2000-01-05    Wednesday
Freq: D, dtype: object

# default: label='left', closed='left'
In [303]: s.resample("B").last().dt.day_name()
Out[303]: 
1999-12-31       Sunday
2000-01-03          NaN
2000-01-04      Tuesday
2000-01-05    Wednesday
Freq: B, dtype: object

---->   Series.resample

--------------------------------------
ID: 2566 --> 1
In [304]: s.resample("B", label="right", closed="right").last().dt.day_name()
Out[304]: 
2000-01-03       Sunday
2000-01-04      Tuesday
2000-01-05    Wednesday
Freq: B, dtype: object

---->   Series.resample

--------------------------------------
ID: 2568 --> 1
In [308]: rng = pd.date_range("2014-1-1", periods=100, freq="D") + pd.Timedelta("1s")

In [309]: ts = pd.Series(range(100), index=rng)

---->   pandas.Series

--------------------------------------
ID: 2569 --> 1
In [310]: ts.resample("3T").sum()
Out[310]: 
2014-01-01 00:00:00     0
2014-01-01 00:03:00     0
2014-01-01 00:06:00     0
2014-01-01 00:09:00     0
2014-01-01 00:12:00     0
                       ..
2014-04-09 23:48:00     0
2014-04-09 23:51:00     0
2014-04-09 23:54:00     0
2014-04-09 23:57:00     0
2014-04-10 00:00:00    99
Freq: 3T, Length: 47521, dtype: int64

---->   Series.resample

--------------------------------------
ID: 2570 --> 1
In [311]: from functools import partial

In [312]: from pandas.tseries.frequencies import to_offset

In [313]: def round(t, freq):
   .....:     freq = to_offset(freq)
   .....:     return pd.Timestamp((t.value // freq.delta.value) * freq.delta.value)
   .....: 

In [314]: ts.groupby(partial(round, freq="3T")).sum()
Out[314]: 
2014-01-01     0
2014-01-02     1
2014-01-03     2
2014-01-04     3
2014-01-05     4
              ..
2014-04-06    95
2014-04-07    96
2014-04-08    97
2014-04-09    98
2014-04-10    99
Length: 100, dtype: int64

---->   Series.groupby

--------------------------------------
ID: 2571 --> 2
In [315]: df = pd.DataFrame(
   .....:     np.random.randn(1000, 3),
   .....:     index=pd.date_range("1/1/2012", freq="S", periods=1000),
   .....:     columns=["A", "B", "C"],
   .....: )
   .....: 

In [316]: r = df.resample("3T")

In [317]: r.mean()
Out[317]: 
                            A         B         C
2012-01-01 00:00:00 -0.033823 -0.121514 -0.081447
2012-01-01 00:03:00  0.056909  0.146731 -0.024320
2012-01-01 00:06:00 -0.058837  0.047046 -0.052021
2012-01-01 00:09:00  0.063123 -0.026158 -0.066533
2012-01-01 00:12:00  0.186340 -0.003144  0.074752
2012-01-01 00:15:00 -0.085954 -0.016287 -0.050046

---->   pandas.DataFrame; DataFrame.resample

--------------------------------------
ID: 2578 --> 3
In [325]: df = pd.DataFrame(
   .....:     {"date": pd.date_range("2015-01-01", freq="W", periods=5), "a": np.arange(5)},
   .....:     index=pd.MultiIndex.from_arrays(
   .....:         [[1, 2, 3, 4, 5], pd.date_range("2015-01-01", freq="W", periods=5)],
   .....:         names=["v", "d"],
   .....:     ),
   .....: )
   .....: 

In [326]: df
Out[326]: 
                   date  a
v d                       
1 2015-01-04 2015-01-04  0
2 2015-01-11 2015-01-11  1
3 2015-01-18 2015-01-18  2
4 2015-01-25 2015-01-25  3
5 2015-02-01 2015-02-01  4

In [327]: df.resample("M", on="date")[["a"]].sum()
Out[327]: 
            a
date         
2015-01-31  6
2015-02-28  4

---->   pandas.DataFrame; pandas.MultiIndex; DataFrame.resample

--------------------------------------
ID: 2579 --> 1
In [328]: df.resample("M", level="d")[["a"]].sum()
Out[328]: 
            a
d            
2015-01-31  6
2015-02-28  4

---->   DataFrame.resample

--------------------------------------
ID: 2580 --> 2
In [329]: small = pd.Series(
   .....:     range(6),
   .....:     index=pd.to_datetime(
   .....:         [
   .....:             "2017-01-01T00:00:00",
   .....:             "2017-01-01T00:30:00",
   .....:             "2017-01-01T00:31:00",
   .....:             "2017-01-01T01:00:00",
   .....:             "2017-01-01T03:00:00",
   .....:             "2017-01-01T03:05:00",
   .....:         ]
   .....:     ),
   .....: )
   .....: 

In [330]: resampled = small.resample("H")

In [331]: for name, group in resampled:
   .....:     print("Group: ", name)
   .....:     print("-" * 27)
   .....:     print(group, end="\n\n")
   .....: 
Group:  2017-01-01 00:00:00
---------------------------
2017-01-01 00:00:00    0
2017-01-01 00:30:00    1
2017-01-01 00:31:00    2
dtype: int64

Group:  2017-01-01 01:00:00
---------------------------
2017-01-01 01:00:00    3
dtype: int64

Group:  2017-01-01 02:00:00
---------------------------
Series([], dtype: int64)

Group:  2017-01-01 03:00:00
---------------------------
2017-01-01 03:00:00    4
2017-01-01 03:05:00    5
dtype: int64

---->   pandas.Series; pandas.to_datetime

--------------------------------------
ID: 2581 --> 1
In [332]: start, end = "2000-10-01 23:30:00", "2000-10-02 00:30:00"

In [333]: middle = "2000-10-02 00:00:00"

In [334]: rng = pd.date_range(start, end, freq="7min")

In [335]: ts = pd.Series(np.arange(len(rng)) * 3, index=rng)

In [336]: ts
Out[336]: 
2000-10-01 23:30:00     0
2000-10-01 23:37:00     3
2000-10-01 23:44:00     6
2000-10-01 23:51:00     9
2000-10-01 23:58:00    12
2000-10-02 00:05:00    15
2000-10-02 00:12:00    18
2000-10-02 00:19:00    21
2000-10-02 00:26:00    24
Freq: 7T, dtype: int64

---->   pandas.Series

--------------------------------------
ID: 2582 --> 1
In [337]: ts.resample("17min", origin="start_day").sum()
Out[337]: 
2000-10-01 23:14:00     0
2000-10-01 23:31:00     9
2000-10-01 23:48:00    21
2000-10-02 00:05:00    54
2000-10-02 00:22:00    24
Freq: 17T, dtype: int64

In [338]: ts[middle:end].resample("17min", origin="start_day").sum()
Out[338]: 
2000-10-02 00:00:00    33
2000-10-02 00:17:00    45
Freq: 17T, dtype: int64

---->   Series.resample

--------------------------------------
ID: 2583 --> 1
In [339]: ts.resample("17min", origin="epoch").sum()
Out[339]: 
2000-10-01 23:18:00     0
2000-10-01 23:35:00    18
2000-10-01 23:52:00    27
2000-10-02 00:09:00    39
2000-10-02 00:26:00    24
Freq: 17T, dtype: int64

In [340]: ts[middle:end].resample("17min", origin="epoch").sum()
Out[340]: 
2000-10-01 23:52:00    15
2000-10-02 00:09:00    39
2000-10-02 00:26:00    24
Freq: 17T, dtype: int64

---->   Series.resample

--------------------------------------
ID: 2584 --> 1
In [341]: ts.resample("17min", origin="2001-01-01").sum()
Out[341]: 
2000-10-01 23:30:00     9
2000-10-01 23:47:00    21
2000-10-02 00:04:00    54
2000-10-02 00:21:00    24
Freq: 17T, dtype: int64

In [342]: ts[middle:end].resample("17min", origin=pd.Timestamp("2001-01-01")).sum()
Out[342]: 
2000-10-02 00:04:00    54
2000-10-02 00:21:00    24
Freq: 17T, dtype: int64

---->   Series.resample

--------------------------------------
ID: 2585 --> 1
In [343]: ts.resample("17min", origin="start").sum()
Out[343]: 
2000-10-01 23:30:00     9
2000-10-01 23:47:00    21
2000-10-02 00:04:00    54
2000-10-02 00:21:00    24
Freq: 17T, dtype: int64

In [344]: ts.resample("17min", offset="23h30min").sum()
Out[344]: 
2000-10-01 23:30:00     9
2000-10-01 23:47:00    21
2000-10-02 00:04:00    54
2000-10-02 00:21:00    24
Freq: 17T, dtype: int64

---->   Series.resample

--------------------------------------
ID: 2586 --> 1
In [345]: ts.resample('17min', origin='end').sum()
Out[345]: 
2000-10-01 23:35:00     0
2000-10-01 23:52:00    18
2000-10-02 00:09:00    27
2000-10-02 00:26:00    63
Freq: 17T, dtype: int64

---->   Series.resample

--------------------------------------
ID: 2587 --> 1
In [346]: ts.resample('17min', origin='end_day').sum()
Out[346]: 
2000-10-01 23:38:00     3
2000-10-01 23:55:00    15
2000-10-02 00:12:00    45
2000-10-02 00:29:00    45
Freq: 17T, dtype: int64

---->   Series.resample

--------------------------------------
ID: 2589 --> 1
In [351]: pd.Period("2012", freq="A-DEC")
Out[351]: Period('2012', 'A-DEC')

In [352]: pd.Period("2012-1-1", freq="D")
Out[352]: Period('2012-01-01', 'D')

In [353]: pd.Period("2012-1-1 19:00", freq="H")
Out[353]: Period('2012-01-01 19:00', 'H')

In [354]: pd.Period("2012-1-1 19:00", freq="5H")
Out[354]: Period('2012-01-01 19:00', '5H')

---->   pandas.Period

--------------------------------------
ID: 2590 --> 1
In [355]: p = pd.Period("2012", freq="A-DEC")

In [356]: p + 1
Out[356]: Period('2013', 'A-DEC')

In [357]: p - 3
Out[357]: Period('2009', 'A-DEC')

In [358]: p = pd.Period("2012-01", freq="2M")

In [359]: p + 2
Out[359]: Period('2012-05', '2M')

In [360]: p - 1
Out[360]: Period('2011-11', '2M')

In [361]: p == pd.Period("2012-01", freq="3M")
Out[361]: False

---->   pandas.Period

--------------------------------------
ID: 2591 --> 1
In [362]: p = pd.Period("2014-07-01 09:00", freq="H")

In [363]: p + pd.offsets.Hour(2)
Out[363]: Period('2014-07-01 11:00', 'H')

In [364]: p + datetime.timedelta(minutes=120)
Out[364]: Period('2014-07-01 11:00', 'H')

In [365]: p + np.timedelta64(7200, "s")
Out[365]: Period('2014-07-01 11:00', 'H')

---->   pandas.Period

--------------------------------------
ID: 2593 --> 1
In [366]: p = pd.Period("2014-07", freq="M")

In [367]: p + pd.offsets.MonthEnd(3)
Out[367]: Period('2014-10', 'M')

---->   pandas.Period

--------------------------------------
ID: 2595 --> 1
In [368]: pd.Period("2012", freq="A-DEC") - pd.Period("2002", freq="A-DEC")
Out[368]: <10 * YearEnds: month=12>

---->   pandas.Period

--------------------------------------
ID: 2596 --> 1
In [369]: prng = pd.period_range("1/1/2011", "1/1/2012", freq="M")

In [370]: prng
Out[370]: 
PeriodIndex(['2011-01', '2011-02', '2011-03', '2011-04', '2011-05', '2011-06',
             '2011-07', '2011-08', '2011-09', '2011-10', '2011-11', '2011-12',
             '2012-01'],
            dtype='period[M]')

---->   pandas.period_range

--------------------------------------
ID: 2597 --> 1
In [371]: pd.PeriodIndex(["2011-1", "2011-2", "2011-3"], freq="M")
Out[371]: PeriodIndex(['2011-01', '2011-02', '2011-03'], dtype='period[M]')

---->   pandas.PeriodIndex

--------------------------------------
ID: 2598 --> 1
In [372]: pd.period_range(start="2014-01", freq="3M", periods=4)
Out[372]: PeriodIndex(['2014-01', '2014-04', '2014-07', '2014-10'], dtype='period[3M]')

---->   pandas.period_range

--------------------------------------
ID: 2599 --> 2
In [373]: pd.period_range(
   .....:     start=pd.Period("2017Q1", freq="Q"), end=pd.Period("2017Q2", freq="Q"), freq="M"
   .....: )
   .....: 
Out[373]: PeriodIndex(['2017-03', '2017-04', '2017-05', '2017-06'], dtype='period[M]')

---->   pandas.period_range; pandas.Period

--------------------------------------
ID: 2600 --> 1
In [374]: ps = pd.Series(np.random.randn(len(prng)), prng)

In [375]: ps
Out[375]: 
2011-01   -2.916901
2011-02    0.514474
2011-03    1.346470
2011-04    0.816397
2011-05    2.258648
2011-06    0.494789
2011-07    0.301239
2011-08    0.464776
2011-09   -1.393581
2011-10    0.056780
2011-11    0.197035
2011-12    2.261385
2012-01   -0.329583
Freq: M, dtype: float64

---->   pandas.Series

--------------------------------------
ID: 2601 --> 1
In [376]: idx = pd.period_range("2014-07-01 09:00", periods=5, freq="H")

In [377]: idx
Out[377]: 
PeriodIndex(['2014-07-01 09:00', '2014-07-01 10:00', '2014-07-01 11:00',
             '2014-07-01 12:00', '2014-07-01 13:00'],
            dtype='period[H]')

In [378]: idx + pd.offsets.Hour(2)
Out[378]: 
PeriodIndex(['2014-07-01 11:00', '2014-07-01 12:00', '2014-07-01 13:00',
             '2014-07-01 14:00', '2014-07-01 15:00'],
            dtype='period[H]')

In [379]: idx = pd.period_range("2014-07", periods=5, freq="M")

In [380]: idx
Out[380]: PeriodIndex(['2014-07', '2014-08', '2014-09', '2014-10', '2014-11'], dtype='period[M]')

In [381]: idx + pd.offsets.MonthEnd(3)
Out[381]: PeriodIndex(['2014-10', '2014-11', '2014-12', '2015-01', '2015-02'], dtype='period[M]')

---->   pandas.period_range

--------------------------------------
ID: 2602 --> 1
In [382]: pi = pd.period_range("2016-01-01", periods=3, freq="M")

In [383]: pi
Out[383]: PeriodIndex(['2016-01', '2016-02', '2016-03'], dtype='period[M]')

In [384]: pi.dtype
Out[384]: period[M]

---->   pandas.period_range

--------------------------------------
ID: 2605 --> 2
In [393]: ps["2011"]
Out[393]: 
2011-01   -2.916901
2011-02    0.514474
2011-03    1.346470
2011-04    0.816397
2011-05    2.258648
2011-06    0.494789
2011-07    0.301239
2011-08    0.464776
2011-09   -1.393581
2011-10    0.056780
2011-11    0.197035
2011-12    2.261385
Freq: M, dtype: float64

In [394]: dfp = pd.DataFrame(
   .....:     np.random.randn(600, 1),
   .....:     columns=["A"],
   .....:     index=pd.period_range("2013-01-01 9:00", periods=600, freq="T"),
   .....: )
   .....: 

In [395]: dfp
Out[395]: 
                         A
2013-01-01 09:00 -0.538468
2013-01-01 09:01 -1.365819
2013-01-01 09:02 -0.969051
2013-01-01 09:03 -0.331152
2013-01-01 09:04 -0.245334
...                    ...
2013-01-01 18:55  0.522460
2013-01-01 18:56  0.118710
2013-01-01 18:57  0.167517
2013-01-01 18:58  0.922883
2013-01-01 18:59  1.721104

[600 rows x 1 columns]

In [396]: dfp.loc["2013-01-01 10H"]
Out[396]: 
                         A
2013-01-01 10:00 -0.308975
2013-01-01 10:01  0.542520
2013-01-01 10:02  1.061068
2013-01-01 10:03  0.754005
2013-01-01 10:04  0.352933
...                    ...
2013-01-01 10:55 -0.865621
2013-01-01 10:56 -1.167818
2013-01-01 10:57 -2.081748
2013-01-01 10:58 -0.527146
2013-01-01 10:59  0.802298

[60 rows x 1 columns]

---->   pandas.DataFrame; pandas.period_range

--------------------------------------
ID: 2606 --> 1
In [398]: p = pd.Period("2011", freq="A-DEC")

In [399]: p
Out[399]: Period('2011', 'A-DEC')

---->   pandas.Period

--------------------------------------
ID: 2607 --> 1
In [400]: p.asfreq("M", how="start")
Out[400]: Period('2011-01', 'M')

In [401]: p.asfreq("M", how="end")
Out[401]: Period('2011-12', 'M')

---->   Period.asfreq

--------------------------------------
ID: 2608 --> 1
In [402]: p.asfreq("M", "s")
Out[402]: Period('2011-01', 'M')

In [403]: p.asfreq("M", "e")
Out[403]: Period('2011-12', 'M')

---->   Period.asfreq

--------------------------------------
ID: 2609 --> 2
In [404]: p = pd.Period("2011-12", freq="M")

In [405]: p.asfreq("A-NOV")
Out[405]: Period('2012', 'A-NOV')

---->   pandas.Period; Period.asfreq

--------------------------------------
ID: 2610 --> 2
In [406]: p = pd.Period("2012Q1", freq="Q-DEC")

In [407]: p.asfreq("D", "s")
Out[407]: Period('2012-01-01', 'D')

In [408]: p.asfreq("D", "e")
Out[408]: Period('2012-03-31', 'D')

---->   pandas.Period; Period.asfreq

--------------------------------------
ID: 2611 --> 2
In [409]: p = pd.Period("2011Q4", freq="Q-MAR")

In [410]: p.asfreq("D", "s")
Out[410]: Period('2011-01-01', 'D')

In [411]: p.asfreq("D", "e")
Out[411]: Period('2011-03-31', 'D')

---->   pandas.Period; Period.asfreq

--------------------------------------
ID: 2612 --> 3
In [412]: rng = pd.date_range("1/1/2012", periods=5, freq="M")

In [413]: ts = pd.Series(np.random.randn(len(rng)), index=rng)

In [414]: ts
Out[414]: 
2012-01-31    1.931253
2012-02-29   -0.184594
2012-03-31    0.249656
2012-04-30   -0.978151
2012-05-31   -0.873389
Freq: M, dtype: float64

In [415]: ps = ts.to_period()

In [416]: ps
Out[416]: 
2012-01    1.931253
2012-02   -0.184594
2012-03    0.249656
2012-04   -0.978151
2012-05   -0.873389
Freq: M, dtype: float64

In [417]: ps.to_timestamp()
Out[417]: 
2012-01-01    1.931253
2012-02-01   -0.184594
2012-03-01    0.249656
2012-04-01   -0.978151
2012-05-01   -0.873389
Freq: MS, dtype: float64

---->   pandas.Series; Series.to_period; Series.to_timestamp

--------------------------------------
ID: 2613 --> 1
In [418]: ps.to_timestamp("D", how="s")
Out[418]: 
2012-01-01    1.931253
2012-02-01   -0.184594
2012-03-01    0.249656
2012-04-01   -0.978151
2012-05-01   -0.873389
Freq: MS, dtype: float64

---->   Series.to_timestamp

--------------------------------------
ID: 2614 --> 3
In [419]: prng = pd.period_range("1990Q1", "2000Q4", freq="Q-NOV")

In [420]: ts = pd.Series(np.random.randn(len(prng)), prng)

In [421]: ts.index = (prng.asfreq("M", "e") + 1).asfreq("H", "s") + 9

In [422]: ts.head()
Out[422]: 
1990-03-01 09:00   -0.109291
1990-06-01 09:00   -0.637235
1990-09-01 09:00   -1.735925
1990-12-01 09:00    2.096946
1991-03-01 09:00   -1.039926
Freq: H, dtype: float64

---->   pandas.period_range; pandas.Series; Series.head

--------------------------------------
ID: 2615 --> 1
In [423]: span = pd.period_range("1215-01-01", "1381-01-01", freq="D")

In [424]: span
Out[424]: 
PeriodIndex(['1215-01-01', '1215-01-02', '1215-01-03', '1215-01-04',
             '1215-01-05', '1215-01-06', '1215-01-07', '1215-01-08',
             '1215-01-09', '1215-01-10',
             ...
             '1380-12-23', '1380-12-24', '1380-12-25', '1380-12-26',
             '1380-12-27', '1380-12-28', '1380-12-29', '1380-12-30',
             '1380-12-31', '1381-01-01'],
            dtype='period[D]', length=60632)

---->   pandas.period_range

--------------------------------------
ID: 2616 --> 2
In [425]: s = pd.Series([20121231, 20141130, 99991231])

In [426]: s
Out[426]: 
0    20121231
1    20141130
2    99991231
dtype: int64

In [427]: def conv(x):
   .....:     return pd.Period(year=x // 10000, month=x // 100 % 100, day=x % 100, freq="D")
   .....: 

In [428]: s.apply(conv)
Out[428]: 
0    2012-12-31
1    2014-11-30
2    9999-12-31
dtype: period[D]

In [429]: s.apply(conv)[2]
Out[429]: Period('9999-12-31', 'D')

---->   pandas.Series; pandas.Period

--------------------------------------
ID: 2617 --> 1
In [430]: span = pd.PeriodIndex(s.apply(conv))

In [431]: span
Out[431]: PeriodIndex(['2012-12-31', '2014-11-30', '9999-12-31'], dtype='period[D]')

---->   pandas.PeriodIndex

--------------------------------------
ID: 2626 --> 2
In [467]: ts_utc = pd.Series(range(3), pd.date_range("20130101", periods=3, tz="UTC"))

In [468]: eastern = ts_utc.tz_convert("US/Eastern")

In [469]: berlin = ts_utc.tz_convert("Europe/Berlin")

In [470]: result = eastern + berlin

In [471]: result
Out[471]: 
2013-01-01 00:00:00+00:00    0
2013-01-02 00:00:00+00:00    2
2013-01-03 00:00:00+00:00    4
Freq: D, dtype: int64

In [472]: result.index
Out[472]: 
DatetimeIndex(['2013-01-01 00:00:00+00:00', '2013-01-02 00:00:00+00:00',
               '2013-01-03 00:00:00+00:00'],
              dtype='datetime64[ns, UTC]', freq='D')

---->   pandas.Series; Series.tz_convert

--------------------------------------
ID: 2629 --> 1
In [480]: rng_hourly = pd.DatetimeIndex(
   .....:     ["11/06/2011 00:00", "11/06/2011 01:00", "11/06/2011 01:00", "11/06/2011 02:00"]
   .....: )
   .....: 

---->   pandas.DatetimeIndex

--------------------------------------
ID: 2635 --> 1
In [490]: s_naive = pd.Series(pd.date_range("20130101", periods=3))

In [491]: s_naive
Out[491]: 
0   2013-01-01
1   2013-01-02
2   2013-01-03
dtype: datetime64[ns]

---->   pandas.Series

--------------------------------------
ID: 2636 --> 1
In [492]: s_aware = pd.Series(pd.date_range("20130101", periods=3, tz="US/Eastern"))

In [493]: s_aware
Out[493]: 
0   2013-01-01 00:00:00-05:00
1   2013-01-02 00:00:00-05:00
2   2013-01-03 00:00:00-05:00
dtype: datetime64[ns, US/Eastern]

---->   pandas.Series

--------------------------------------
ID: 2638 --> 1
# convert to a new time zone
In [495]: s_aware.astype("datetime64[ns, CET]")
Out[495]: 
0   2013-01-01 06:00:00+01:00
1   2013-01-02 06:00:00+01:00
2   2013-01-03 06:00:00+01:00
dtype: datetime64[ns, CET]

---->   Series.astype

--------------------------------------
ID: 2639 --> 2
In [496]: s_naive.to_numpy()
Out[496]: 
array(['2013-01-01T00:00:00.000000000', '2013-01-02T00:00:00.000000000',
       '2013-01-03T00:00:00.000000000'], dtype='datetime64[ns]')

In [497]: s_aware.to_numpy()
Out[497]: 
array([Timestamp('2013-01-01 00:00:00-0500', tz='US/Eastern'),
       Timestamp('2013-01-02 00:00:00-0500', tz='US/Eastern'),
       Timestamp('2013-01-03 00:00:00-0500', tz='US/Eastern')],
      dtype=object)

---->   Series.to_numpy; Series.to_numpy

--------------------------------------
ID: 2640 --> 2
In [498]: pd.Series(s_aware.to_numpy())
Out[498]: 
0   2013-01-01 00:00:00-05:00
1   2013-01-02 00:00:00-05:00
2   2013-01-03 00:00:00-05:00
dtype: datetime64[ns, US/Eastern]

---->   pandas.Series; Series.to_numpy

--------------------------------------
ID: 2641 --> 1
In [499]: s_aware.to_numpy(dtype="datetime64[ns]")
Out[499]: 
array(['2013-01-01T05:00:00.000000000', '2013-01-02T05:00:00.000000000',
       '2013-01-03T05:00:00.000000000'], dtype='datetime64[ns]')

---->   Series.to_numpy

--------------------------------------
ID: 2642 --> 1
In [1]: s = pd.Series(["a", "b", "c", "a"], dtype="category")

In [2]: s
Out[2]: 
0    a
1    b
2    c
3    a
dtype: category
Categories (3, object): ['a', 'b', 'c']

---->   pandas.Series

--------------------------------------
ID: 2643 --> 1
In [3]: df = pd.DataFrame({"A": ["a", "b", "c", "a"]})

In [4]: df["B"] = df["A"].astype("category")

In [5]: df
Out[5]: 
   A  B
0  a  a
1  b  b
2  c  c
3  a  a

---->   pandas.DataFrame

--------------------------------------
ID: 2644 --> 3
In [6]: df = pd.DataFrame({"value": np.random.randint(0, 100, 20)})

In [7]: labels = ["{0} - {1}".format(i, i + 9) for i in range(0, 100, 10)]

In [8]: df["group"] = pd.cut(df.value, range(0, 105, 10), right=False, labels=labels)

In [9]: df.head(10)
Out[9]: 
   value    group
0     65  60 - 69
1     49  40 - 49
2     56  50 - 59
3     43  40 - 49
4     43  40 - 49
5     91  90 - 99
6     32  30 - 39
7     87  80 - 89
8     36  30 - 39
9      8    0 - 9

---->   pandas.DataFrame; pandas.cut; DataFrame.head

--------------------------------------
ID: 2645 --> 3
In [10]: raw_cat = pd.Categorical(
   ....:     ["a", "b", "c", "a"], categories=["b", "c", "d"], ordered=False
   ....: )
   ....: 

In [11]: s = pd.Series(raw_cat)

In [12]: s
Out[12]: 
0    NaN
1      b
2      c
3    NaN
dtype: category
Categories (3, object): ['b', 'c', 'd']

In [13]: df = pd.DataFrame({"A": ["a", "b", "c", "a"]})

In [14]: df["B"] = raw_cat

In [15]: df
Out[15]: 
   A    B
0  a  NaN
1  b    b
2  c    c
3  a  NaN

---->   pandas.Categorical; pandas.Series; pandas.DataFrame

--------------------------------------
ID: 2646 --> 1
In [17]: df = pd.DataFrame({"A": list("abca"), "B": list("bccd")}, dtype="category")

In [18]: df.dtypes
Out[18]: 
A    category
B    category
dtype: object

---->   pandas.DataFrame

--------------------------------------
ID: 2648 --> 2
In [21]: df = pd.DataFrame({"A": list("abca"), "B": list("bccd")})

In [22]: df_cat = df.astype("category")

In [23]: df_cat.dtypes
Out[23]: 
A    category
B    category
dtype: object

---->   pandas.DataFrame; DataFrame.astype

--------------------------------------
ID: 2650 --> 2
In [26]: from pandas.api.types import CategoricalDtype

In [27]: s = pd.Series(["a", "b", "c", "a"])

In [28]: cat_type = CategoricalDtype(categories=["b", "c", "d"], ordered=True)

In [29]: s_cat = s.astype(cat_type)

In [30]: s_cat
Out[30]: 
0    NaN
1      b
2      c
3    NaN
dtype: category
Categories (3, object): ['b' < 'c' < 'd']

---->   pandas.Series; Series.astype

--------------------------------------
ID: 2651 --> 2
In [31]: from pandas.api.types import CategoricalDtype

In [32]: df = pd.DataFrame({"A": list("abca"), "B": list("bccd")})

In [33]: cat_type = CategoricalDtype(categories=list("abcd"), ordered=True)

In [34]: df_cat = df.astype(cat_type)

In [35]: df_cat["A"]
Out[35]: 
0    a
1    b
2    c
3    a
Name: A, dtype: category
Categories (4, object): ['a' < 'b' < 'c' < 'd']

In [36]: df_cat["B"]
Out[36]: 
0    b
1    c
2    c
3    d
Name: B, dtype: category
Categories (4, object): ['a' < 'b' < 'c' < 'd']

---->   pandas.DataFrame; DataFrame.astype

--------------------------------------
ID: 2652 --> 2
In [37]: splitter = np.random.choice([0, 1], 5, p=[0.5, 0.5])

In [38]: s = pd.Series(pd.Categorical.from_codes(splitter, categories=["train", "test"]))

---->   pandas.Series; pandas.Categorical

--------------------------------------
ID: 2653 --> 3
In [39]: s = pd.Series(["a", "b", "c", "a"])

In [40]: s
Out[40]: 
0    a
1    b
2    c
3    a
dtype: object

In [41]: s2 = s.astype("category")

In [42]: s2
Out[42]: 
0    a
1    b
2    c
3    a
dtype: category
Categories (3, object): ['a', 'b', 'c']

In [43]: s2.astype(str)
Out[43]: 
0    a
1    b
2    c
3    a
dtype: object

In [44]: np.asarray(s2)
Out[44]: array(['a', 'b', 'c', 'a'], dtype=object)

---->   pandas.Series; Series.astype; Series.astype

--------------------------------------
ID: 2656 --> 3
In [53]: cat = pd.Categorical(["a", "c", "c", np.nan], categories=["b", "a", "c"])

In [54]: df = pd.DataFrame({"cat": cat, "s": ["a", "c", "c", np.nan]})

In [55]: df.describe()
Out[55]: 
       cat  s
count    3  3
unique   2  2
top      c  c
freq     2  2

In [56]: df["cat"].describe()
Out[56]: 
count     3
unique    2
top       c
freq      2
Name: cat, dtype: object

---->   pandas.Categorical; pandas.DataFrame; DataFrame.describe

--------------------------------------
ID: 2657 --> 1
In [57]: s = pd.Series(["a", "b", "c", "a"], dtype="category")

In [58]: s.cat.categories
Out[58]: Index(['a', 'b', 'c'], dtype='object')

In [59]: s.cat.ordered
Out[59]: False

---->   pandas.Series

--------------------------------------
ID: 2658 --> 2
In [60]: s = pd.Series(pd.Categorical(["a", "b", "c", "a"], categories=["c", "b", "a"]))

In [61]: s.cat.categories
Out[61]: Index(['c', 'b', 'a'], dtype='object')

In [62]: s.cat.ordered
Out[62]: False

---->   pandas.Series; pandas.Categorical

--------------------------------------
ID: 2659 --> 2
In [63]: s = pd.Series(list("babc")).astype(CategoricalDtype(list("abcd")))

In [64]: s
Out[64]: 
0    b
1    a
2    b
3    c
dtype: category
Categories (4, object): ['a', 'b', 'c', 'd']

# categories
In [65]: s.cat.categories
Out[65]: Index(['a', 'b', 'c', 'd'], dtype='object')

# uniques
In [66]: s.unique()
Out[66]: 
['b', 'a', 'c']
Categories (4, object): ['a', 'b', 'c', 'd']

---->   pandas.Series; Series.unique

--------------------------------------
ID: 2660 --> 1
In [67]: s = pd.Series(["a", "b", "c", "a"], dtype="category")

In [68]: s
Out[68]: 
0    a
1    b
2    c
3    a
dtype: category
Categories (3, object): ['a', 'b', 'c']

In [69]: new_categories = ["Group %s" % g for g in s.cat.categories]

In [70]: s = s.cat.rename_categories(new_categories)

In [71]: s
Out[71]: 
0    Group a
1    Group b
2    Group c
3    Group a
dtype: category
Categories (3, object): ['Group a', 'Group b', 'Group c']

# You can also pass a dict-like object to map the renaming
In [72]: s = s.cat.rename_categories({1: "x", 2: "y", 3: "z"})

In [73]: s
Out[73]: 
0    Group a
1    Group b
2    Group c
3    Group a
dtype: category
Categories (3, object): ['Group a', 'Group b', 'Group c']

---->   pandas.Series

--------------------------------------
ID: 2665 --> 2
In [81]: s = pd.Series(pd.Categorical(["a", "b", "a"], categories=["a", "b", "c", "d"]))

In [82]: s
Out[82]: 
0    a
1    b
2    a
dtype: category
Categories (4, object): ['a', 'b', 'c', 'd']

In [83]: s.cat.remove_unused_categories()
Out[83]: 
0    a
1    b
2    a
dtype: category
Categories (2, object): ['a', 'b']

---->   pandas.Series; pandas.Categorical

--------------------------------------
ID: 2666 --> 1
In [84]: s = pd.Series(["one", "two", "four", "-"], dtype="category")

In [85]: s
Out[85]: 
0     one
1     two
2    four
3       -
dtype: category
Categories (4, object): ['-', 'four', 'one', 'two']

In [86]: s = s.cat.set_categories(["one", "two", "three", "four"])

In [87]: s
Out[87]: 
0     one
1     two
2    four
3     NaN
dtype: category
Categories (4, object): ['one', 'two', 'three', 'four']

---->   pandas.Series

--------------------------------------
ID: 2667 --> 4
In [88]: s = pd.Series(pd.Categorical(["a", "b", "c", "a"], ordered=False))

In [89]: s = s.sort_values()

In [90]: s = pd.Series(["a", "b", "c", "a"]).astype(CategoricalDtype(ordered=True))

In [91]: s = s.sort_values()

In [92]: s
Out[92]: 
0    a
3    a
1    b
2    c
dtype: category
Categories (3, object): ['a' < 'b' < 'c']

In [93]: s.min(), s.max()
Out[93]: ('a', 'c')

---->   pandas.Series; pandas.Categorical; Series.min; Series.max

--------------------------------------
ID: 2669 --> 3
In [96]: s = pd.Series([1, 2, 3, 1], dtype="category")

In [97]: s = s.cat.set_categories([2, 3, 1], ordered=True)

In [98]: s
Out[98]: 
0    1
1    2
2    3
3    1
dtype: category
Categories (3, int64): [2 < 3 < 1]

In [99]: s = s.sort_values()

In [100]: s
Out[100]: 
1    2
2    3
0    1
3    1
dtype: category
Categories (3, int64): [2 < 3 < 1]

In [101]: s.min(), s.max()
Out[101]: (2, 1)

---->   pandas.Series; Series.min; Series.max

--------------------------------------
ID: 2670 --> 3
In [102]: s = pd.Series([1, 2, 3, 1], dtype="category")

In [103]: s = s.cat.reorder_categories([2, 3, 1], ordered=True)

In [104]: s
Out[104]: 
0    1
1    2
2    3
3    1
dtype: category
Categories (3, int64): [2 < 3 < 1]

In [105]: s = s.sort_values()

In [106]: s
Out[106]: 
1    2
2    3
0    1
3    1
dtype: category
Categories (3, int64): [2 < 3 < 1]

In [107]: s.min(), s.max()
Out[107]: (2, 1)

---->   pandas.Series; Series.min; Series.max

--------------------------------------
ID: 2671 --> 2
In [108]: dfs = pd.DataFrame(
   .....:     {
   .....:         "A": pd.Categorical(
   .....:             list("bbeebbaa"),
   .....:             categories=["e", "a", "b"],
   .....:             ordered=True,
   .....:         ),
   .....:         "B": [1, 2, 1, 2, 2, 1, 2, 1],
   .....:     }
   .....: )
   .....: 

In [109]: dfs.sort_values(by=["A", "B"])
Out[109]: 
   A  B
2  e  1
3  e  2
7  a  1
6  a  2
0  b  1
5  b  1
1  b  2
4  b  2

---->   pandas.DataFrame; pandas.Categorical

--------------------------------------
ID: 2673 --> 1
In [112]: cat = pd.Series([1, 2, 3]).astype(CategoricalDtype([3, 2, 1], ordered=True))

In [113]: cat_base = pd.Series([2, 2, 2]).astype(CategoricalDtype([3, 2, 1], ordered=True))

In [114]: cat_base2 = pd.Series([2, 2, 2]).astype(CategoricalDtype(ordered=True))

In [115]: cat
Out[115]: 
0    1
1    2
2    3
dtype: category
Categories (3, int64): [3 < 2 < 1]

In [116]: cat_base
Out[116]: 
0    2
1    2
2    2
dtype: category
Categories (3, int64): [3 < 2 < 1]

In [117]: cat_base2
Out[117]: 
0    2
1    2
2    2
dtype: category
Categories (1, int64): [2]

---->   pandas.Series

--------------------------------------
ID: 2677 --> 1
In [127]: c1 = pd.Categorical(["a", "b"], categories=["a", "b"], ordered=False)

In [128]: c2 = pd.Categorical(["a", "b"], categories=["b", "a"], ordered=False)

In [129]: c1 == c2
Out[129]: array([ True,  True])

---->   pandas.Categorical

--------------------------------------
ID: 2678 --> 3
In [130]: s = pd.Series(pd.Categorical(["a", "b", "c", "c"], categories=["c", "a", "b", "d"]))

In [131]: s.value_counts()
Out[131]: 
c    2
a    1
b    1
d    0
Name: count, dtype: int64

---->   pandas.Series; pandas.Categorical; Series.value_counts

--------------------------------------
ID: 2679 --> 4
In [132]: columns = pd.Categorical(
   .....:     ["One", "One", "Two"], categories=["One", "Two", "Three"], ordered=True
   .....: )
   .....: 

In [133]: df = pd.DataFrame(
   .....:     data=[[1, 2, 3], [4, 5, 6]],
   .....:     columns=pd.MultiIndex.from_arrays([["A", "B", "B"], columns]),
   .....: )
   .....: 

In [134]: df.groupby(axis=1, level=1).sum()
Out[134]: 
   One  Two  Three
0    3    3      0
1    9    6      0

---->   pandas.Categorical; pandas.DataFrame; pandas.MultiIndex; DataFrame.groupby

--------------------------------------
ID: 2680 --> 4
In [135]: cats = pd.Categorical(
   .....:     ["a", "b", "b", "b", "c", "c", "c"], categories=["a", "b", "c", "d"]
   .....: )
   .....: 

In [136]: df = pd.DataFrame({"cats": cats, "values": [1, 2, 2, 2, 3, 4, 5]})

In [137]: df.groupby("cats").mean()
Out[137]: 
      values
cats        
a        1.0
b        2.0
c        4.0
d        NaN

In [138]: cats2 = pd.Categorical(["a", "a", "b", "b"], categories=["a", "b", "c"])

In [139]: df2 = pd.DataFrame(
   .....:     {
   .....:         "cats": cats2,
   .....:         "B": ["c", "d", "c", "d"],
   .....:         "values": [1, 2, 3, 4],
   .....:     }
   .....: )
   .....: 

In [140]: df2.groupby(["cats", "B"]).mean()
Out[140]: 
        values
cats B        
a    c     1.0
     d     2.0
b    c     3.0
     d     4.0
c    c     NaN
     d     NaN

---->   pandas.Categorical; pandas.DataFrame; DataFrame.groupby; DataFrame.groupby

--------------------------------------
ID: 2681 --> 3
In [141]: raw_cat = pd.Categorical(["a", "a", "b", "b"], categories=["a", "b", "c"])

In [142]: df = pd.DataFrame({"A": raw_cat, "B": ["c", "d", "c", "d"], "values": [1, 2, 3, 4]})

In [143]: pd.pivot_table(df, values="values", index=["A", "B"])
Out[143]: 
     values
A B        
a c       1
  d       2
b c       3
  d       4

---->   pandas.Categorical; pandas.DataFrame; pandas.pivot_table

--------------------------------------
ID: 2682 --> 3
In [144]: idx = pd.Index(["h", "i", "j", "k", "l", "m", "n"])

In [145]: cats = pd.Series(["a", "b", "b", "b", "c", "c", "c"], dtype="category", index=idx)

In [146]: values = [1, 2, 2, 2, 3, 4, 5]

In [147]: df = pd.DataFrame({"cats": cats, "values": values}, index=idx)

In [148]: df.iloc[2:4, :]
Out[148]: 
  cats  values
j    b       2
k    b       2

In [149]: df.iloc[2:4, :].dtypes
Out[149]: 
cats      category
values       int64
dtype: object

In [150]: df.loc["h":"j", "cats"]
Out[150]: 
h    a
i    b
j    b
Name: cats, dtype: category
Categories (3, object): ['a', 'b', 'c']

In [151]: df[df["cats"] == "b"]
Out[151]: 
  cats  values
i    b       2
j    b       2
k    b       2

---->   pandas.Index; pandas.Series; pandas.DataFrame

--------------------------------------
ID: 2685 --> 3
In [157]: str_s = pd.Series(list("aabb"))

In [158]: str_cat = str_s.astype("category")

In [159]: str_cat
Out[159]: 
0    a
1    a
2    b
3    b
dtype: category
Categories (2, object): ['a', 'b']

In [160]: str_cat.str.contains("a")
Out[160]: 
0     True
1     True
2    False
3    False
dtype: bool

In [161]: date_s = pd.Series(pd.date_range("1/1/2015", periods=5))

In [162]: date_cat = date_s.astype("category")

In [163]: date_cat
Out[163]: 
0   2015-01-01
1   2015-01-02
2   2015-01-03
3   2015-01-04
4   2015-01-05
dtype: category
Categories (5, datetime64[ns]): [2015-01-01, 2015-01-02, 2015-01-03, 2015-01-04, 2015-01-05]

In [164]: date_cat.dt.day
Out[164]: 
0    1
1    2
2    3
3    4
4    5
dtype: int32

---->   pandas.Series; Series.astype; Series.astype

--------------------------------------
ID: 2687 --> 3
In [169]: idx = pd.Index(["h", "i", "j", "k", "l", "m", "n"])

In [170]: cats = pd.Categorical(["a", "a", "a", "a", "a", "a", "a"], categories=["a", "b"])

In [171]: values = [1, 1, 1, 1, 1, 1, 1]

In [172]: df = pd.DataFrame({"cats": cats, "values": values}, index=idx)

In [173]: df.iloc[2:4, :] = [["b", 2], ["b", 2]]

In [174]: df
Out[174]: 
  cats  values
h    a       1
i    a       1
j    b       2
k    b       2
l    a       1
m    a       1
n    a       1

In [175]: try:
   .....:     df.iloc[2:4, :] = [["c", 3], ["c", 3]]
   .....: except TypeError as e:
   .....:     print("TypeError:", str(e))
   .....: 
TypeError: Cannot setitem on a Categorical with a new category, set the categories first

---->   pandas.Index; pandas.Categorical; pandas.DataFrame

--------------------------------------
ID: 2688 --> 1
In [176]: df.loc["j":"k", "cats"] = pd.Categorical(["a", "a"], categories=["a", "b"])

In [177]: df
Out[177]: 
  cats  values
h    a       1
i    a       1
j    a       2
k    a       2
l    a       1
m    a       1
n    a       1

In [178]: try:
   .....:     df.loc["j":"k", "cats"] = pd.Categorical(["b", "b"], categories=["a", "b", "c"])
   .....: except TypeError as e:
   .....:     print("TypeError:", str(e))
   .....: 
TypeError: Cannot set a Categorical with another, without identical categories

---->   pandas.Categorical

--------------------------------------
ID: 2689 --> 2
In [179]: df = pd.DataFrame({"a": [1, 1, 1, 1, 1], "b": ["a", "a", "a", "a", "a"]})

In [180]: df.loc[1:2, "a"] = pd.Categorical(["b", "b"], categories=["a", "b"])

In [181]: df.loc[2:3, "b"] = pd.Categorical(["b", "b"], categories=["a", "b"])

In [182]: df
Out[182]: 
   a  b
0  1  a
1  b  a
2  b  b
3  1  b
4  1  a

In [183]: df.dtypes
Out[183]: 
a    object
b    object
dtype: object

---->   pandas.DataFrame; pandas.Categorical

--------------------------------------
ID: 2690 --> 1
In [184]: from pandas.api.types import union_categoricals

# same categories
In [185]: s1 = pd.Series(["a", "b"], dtype="category")

In [186]: s2 = pd.Series(["a", "b", "a"], dtype="category")

In [187]: pd.concat([s1, s2])
Out[187]: 
0    a
1    b
0    a
1    b
2    a
dtype: category
Categories (2, object): ['a', 'b']

# different categories
In [188]: s3 = pd.Series(["b", "c"], dtype="category")

In [189]: pd.concat([s1, s3])
Out[189]: 
0    a
1    b
0    b
1    c
dtype: object

# Output dtype is inferred based on categories values
In [190]: int_cats = pd.Series([1, 2], dtype="category")

In [191]: float_cats = pd.Series([3.0, 4.0], dtype="category")

In [192]: pd.concat([int_cats, float_cats])
Out[192]: 
0    1.0
1    2.0
0    3.0
1    4.0
dtype: float64

In [193]: pd.concat([s1, s3]).astype("category")
Out[193]: 
0    a
1    b
0    b
1    c
dtype: category
Categories (3, object): ['a', 'b', 'c']

In [194]: union_categoricals([s1.array, s3.array])
Out[194]: 
['a', 'b', 'b', 'c']
Categories (3, object): ['a', 'b', 'c']

---->   pandas.Series

--------------------------------------
ID: 2691 --> 1
In [195]: from pandas.api.types import union_categoricals

In [196]: a = pd.Categorical(["b", "c"])

In [197]: b = pd.Categorical(["a", "b"])

In [198]: union_categoricals([a, b])
Out[198]: 
['b', 'c', 'a', 'b']
Categories (3, object): ['b', 'c', 'a']

---->   pandas.Categorical

--------------------------------------
ID: 2693 --> 1
In [200]: a = pd.Categorical(["a", "b"], ordered=True)

In [201]: b = pd.Categorical(["a", "b", "a"], ordered=True)

In [202]: union_categoricals([a, b])
Out[202]: 
['a', 'b', 'a', 'b', 'a']
Categories (2, object): ['a' < 'b']

---->   pandas.Categorical

--------------------------------------
ID: 2694 --> 1
In [1]: a = pd.Categorical(["a", "b"], ordered=True)
In [2]: b = pd.Categorical(["a", "b", "c"], ordered=True)
In [3]: union_categoricals([a, b])
Out[3]:
TypeError: to union ordered Categoricals, all categories must be the same

---->   pandas.Categorical

--------------------------------------
ID: 2695 --> 1
In [203]: a = pd.Categorical(["a", "b", "c"], ordered=True)

In [204]: b = pd.Categorical(["c", "b", "a"], ordered=True)

In [205]: union_categoricals([a, b], ignore_order=True)
Out[205]: 
['a', 'b', 'c', 'c', 'b', 'a']
Categories (3, object): ['a', 'b', 'c']

---->   pandas.Categorical

--------------------------------------
ID: 2696 --> 1
In [206]: a = pd.Series(["b", "c"], dtype="category")

In [207]: b = pd.Series(["a", "b"], dtype="category")

In [208]: union_categoricals([a, b])
Out[208]: 
['b', 'c', 'a', 'b']
Categories (3, object): ['b', 'c', 'a']

---->   pandas.Series

--------------------------------------
ID: 2697 --> 1
In [209]: c1 = pd.Categorical(["b", "c"])

In [210]: c2 = pd.Categorical(["a", "b"])

In [211]: c1
Out[211]: 
['b', 'c']
Categories (2, object): ['b', 'c']

# "b" is coded to 0
In [212]: c1.codes
Out[212]: array([0, 1], dtype=int8)

In [213]: c2
Out[213]: 
['a', 'b']
Categories (2, object): ['a', 'b']

# "b" is coded to 1
In [214]: c2.codes
Out[214]: array([0, 1], dtype=int8)

In [215]: c = union_categoricals([c1, c2])

In [216]: c
Out[216]: 
['b', 'c', 'a', 'b']
Categories (3, object): ['b', 'c', 'a']

# "b" is coded to 0 throughout, same as c1, different from c2
In [217]: c.codes
Out[217]: array([0, 1, 2, 0], dtype=int8)

---->   pandas.Categorical

--------------------------------------
ID: 2698 --> 4
In [218]: import io

In [219]: s = pd.Series(pd.Categorical(["a", "b", "b", "a", "a", "d"]))

# rename the categories
In [220]: s = s.cat.rename_categories(["very good", "good", "bad"])

# reorder the categories and add missing categories
In [221]: s = s.cat.set_categories(["very bad", "bad", "medium", "good", "very good"])

In [222]: df = pd.DataFrame({"cats": s, "vals": [1, 2, 3, 4, 5, 6]})

In [223]: csv = io.StringIO()

In [224]: df.to_csv(csv)

In [225]: df2 = pd.read_csv(io.StringIO(csv.getvalue()))

In [226]: df2.dtypes
Out[226]: 
Unnamed: 0     int64
cats          object
vals           int64
dtype: object

In [227]: df2["cats"]
Out[227]: 
0    very good
1         good
2         good
3    very good
4    very good
5          bad
Name: cats, dtype: object

# Redo the category
In [228]: df2["cats"] = df2["cats"].astype("category")

In [229]: df2["cats"] = df2["cats"].cat.set_categories(
   .....:     ["very bad", "bad", "medium", "good", "very good"]
   .....: )
   .....: 

In [230]: df2.dtypes
Out[230]: 
Unnamed: 0       int64
cats          category
vals             int64
dtype: object

In [231]: df2["cats"]
Out[231]: 
0    very good
1         good
2         good
3    very good
4    very good
5          bad
Name: cats, dtype: category
Categories (5, object): ['very bad', 'bad', 'medium', 'good', 'very good']

---->   pandas.Series; pandas.Categorical; pandas.DataFrame; DataFrame.to_csv

--------------------------------------
ID: 2699 --> 1
In [232]: s = pd.Series(["a", "b", np.nan, "a"], dtype="category")

# only two categories
In [233]: s
Out[233]: 
0      a
1      b
2    NaN
3      a
dtype: category
Categories (2, object): ['a', 'b']

In [234]: s.cat.codes
Out[234]: 
0    0
1    1
2   -1
3    0
dtype: int8

---->   pandas.Series

--------------------------------------
ID: 2700 --> 2
In [235]: s = pd.Series(["a", "b", np.nan], dtype="category")

In [236]: s
Out[236]: 
0      a
1      b
2    NaN
dtype: category
Categories (2, object): ['a', 'b']

In [237]: pd.isna(s)
Out[237]: 
0    False
1    False
2     True
dtype: bool

In [238]: s.fillna("a")
Out[238]: 
0    a
1    b
2    a
dtype: category
Categories (2, object): ['a', 'b']

---->   pandas.Series; pandas.isna

--------------------------------------
ID: 2701 --> 2
In [239]: s = pd.Series(["foo", "bar"] * 1000)

# object dtype
In [240]: s.nbytes
Out[240]: 16000

# category dtype
In [241]: s.astype("category").nbytes
Out[241]: 2016

---->   pandas.Series; Series.astype

--------------------------------------
ID: 2702 --> 2
In [242]: s = pd.Series(["foo%04d" % i for i in range(2000)])

# object dtype
In [243]: s.nbytes
Out[243]: 16000

# category dtype
In [244]: s.astype("category").nbytes
Out[244]: 20000

---->   pandas.Series; Series.astype

--------------------------------------
ID: 2703 --> 1
In [245]: try:
   .....:     np.dtype("category")
   .....: except TypeError as e:
   .....:     print("TypeError:", str(e))
   .....: 
TypeError: data type 'category' not understood

In [246]: dtype = pd.Categorical(["a"]).dtype

In [247]: try:
   .....:     np.dtype(dtype)
   .....: except TypeError as e:
   .....:     print("TypeError:", str(e))
   .....: 
TypeError: Cannot interpret 'CategoricalDtype(categories=['a'], ordered=False)' as a data type

---->   pandas.Categorical

--------------------------------------
ID: 2704 --> 1
In [250]: hasattr(pd.Series(["a"], dtype="category"), "cat")
Out[250]: True

In [251]: hasattr(pd.Series(["a"]), "cat")
Out[251]: False

---->   pandas.Series

--------------------------------------
ID: 2705 --> 2
In [252]: s = pd.Series(pd.Categorical([1, 2, 3, 4]))

In [253]: try:
   .....:     np.sum(s)
   .....: except TypeError as e:
   .....:     print("TypeError:", str(e))
   .....: 
TypeError: 'Categorical' with dtype category does not support reduction 'sum'

---->   pandas.Series; pandas.Categorical

--------------------------------------
ID: 2706 --> 2
In [254]: df = pd.DataFrame(
   .....:     {
   .....:         "a": [1, 2, 3, 4],
   .....:         "b": ["a", "b", "c", "d"],
   .....:         "cats": pd.Categorical([1, 2, 3, 2]),
   .....:     }
   .....: )
   .....: 

In [255]: df.apply(lambda row: type(row["cats"]), axis=1)
Out[255]: 
0    
1    
2    
3    
dtype: object

In [256]: df.apply(lambda col: col.dtype, axis=0)
Out[256]: 
a          int64
b         object
cats    category
dtype: object

---->   pandas.DataFrame; pandas.Categorical

--------------------------------------
ID: 2707 --> 2
In [257]: cats = pd.Categorical([1, 2, 3, 4], categories=[4, 2, 3, 1])

In [258]: strings = ["a", "b", "c", "d"]

In [259]: values = [4, 2, 3, 1]

In [260]: df = pd.DataFrame({"strings": strings, "values": values}, index=cats)

In [261]: df.index
Out[261]: CategoricalIndex([1, 2, 3, 4], categories=[4, 2, 3, 1], ordered=False, dtype='category')

# This now sorts by the categories order
In [262]: df.sort_index()
Out[262]: 
  strings  values
4       d       1
2       b       2
3       c       3
1       a       4

---->   pandas.Categorical; pandas.DataFrame

--------------------------------------
ID: 2708 --> 2
In [263]: cat = pd.Categorical([1, 2, 3, 10], categories=[1, 2, 3, 4, 10])

In [264]: s = pd.Series(cat, name="cat")

In [265]: cat
Out[265]: 
[1, 2, 3, 10]
Categories (5, int64): [1, 2, 3, 4, 10]

In [266]: s.iloc[0:2] = 10

In [267]: cat
Out[267]: 
[10, 10, 3, 10]
Categories (5, int64): [1, 2, 3, 4, 10]

---->   pandas.Categorical; pandas.Series

--------------------------------------
ID: 2709 --> 2
In [268]: cat = pd.Categorical([1, 2, 3, 10], categories=[1, 2, 3, 4, 10])

In [269]: s = pd.Series(cat, name="cat", copy=True)

In [270]: cat
Out[270]: 
[1, 2, 3, 10]
Categories (5, int64): [1, 2, 3, 4, 10]

In [271]: s.iloc[0:2] = 10

In [272]: cat
Out[272]: 
[1, 2, 3, 10]
Categories (5, int64): [1, 2, 3, 4, 10]

---->   pandas.Categorical; pandas.Series

--------------------------------------
ID: 2710 --> 1
In [1]: df = pd.DataFrame(
   ...:     np.random.randn(5, 3),
   ...:     index=["a", "c", "e", "f", "h"],
   ...:     columns=["one", "two", "three"],
   ...: )
   ...: 

In [2]: df["four"] = "bar"

In [3]: df["five"] = df["one"] > 0

In [4]: df
Out[4]: 
        one       two     three four   five
a  0.469112 -0.282863 -1.509059  bar   True
c -1.135632  1.212112 -0.173215  bar  False
e  0.119209 -1.044236 -0.861849  bar   True
f -2.104569 -0.494929  1.071804  bar  False
h  0.721555 -0.706771 -1.039575  bar   True

In [5]: df2 = df.reindex(["a", "b", "c", "d", "e", "f", "g", "h"])

In [6]: df2
Out[6]: 
        one       two     three four   five
a  0.469112 -0.282863 -1.509059  bar   True
b       NaN       NaN       NaN  NaN    NaN
c -1.135632  1.212112 -0.173215  bar  False
d       NaN       NaN       NaN  NaN    NaN
e  0.119209 -1.044236 -0.861849  bar   True
f -2.104569 -0.494929  1.071804  bar  False
g       NaN       NaN       NaN  NaN    NaN
h  0.721555 -0.706771 -1.039575  bar   True

---->   pandas.DataFrame

--------------------------------------
ID: 2711 --> 2
In [7]: df2["one"]
Out[7]: 
a    0.469112
b         NaN
c   -1.135632
d         NaN
e    0.119209
f   -2.104569
g         NaN
h    0.721555
Name: one, dtype: float64

In [8]: pd.isna(df2["one"])
Out[8]: 
a    False
b     True
c    False
d     True
e    False
f    False
g     True
h    False
Name: one, dtype: bool

In [9]: df2["four"].notna()
Out[9]: 
a     True
b    False
c     True
d    False
e     True
f     True
g    False
h     True
Name: four, dtype: bool

In [10]: df2.isna()
Out[10]: 
     one    two  three   four   five
a  False  False  False  False  False
b   True   True   True   True   True
c  False  False  False  False  False
d   True   True   True   True   True
e  False  False  False  False  False
f  False  False  False  False  False
g   True   True   True   True   True
h  False  False  False  False  False

---->   pandas.isna; DataFrame.isna

--------------------------------------
ID: 2712 --> 2
In [14]: pd.Series([1, 2, np.nan, 4], dtype=pd.Int64Dtype())
Out[14]: 
0       1
1       2
2    
3       4
dtype: Int64

---->   pandas.Series; pandas.Int64Dtype

--------------------------------------
ID: 2713 --> 1
In [15]: df2 = df.copy()

In [16]: df2["timestamp"] = pd.Timestamp("20120101")

In [17]: df2
Out[17]: 
        one       two     three four   five  timestamp
a  0.469112 -0.282863 -1.509059  bar   True 2012-01-01
c -1.135632  1.212112 -0.173215  bar  False 2012-01-01
e  0.119209 -1.044236 -0.861849  bar   True 2012-01-01
f -2.104569 -0.494929  1.071804  bar  False 2012-01-01
h  0.721555 -0.706771 -1.039575  bar   True 2012-01-01

In [18]: df2.loc[["a", "c", "h"], ["one", "timestamp"]] = np.nan

In [19]: df2
Out[19]: 
        one       two     three four   five  timestamp
a       NaN -0.282863 -1.509059  bar   True        NaT
c       NaN  1.212112 -0.173215  bar  False        NaT
e  0.119209 -1.044236 -0.861849  bar   True 2012-01-01
f -2.104569 -0.494929  1.071804  bar  False 2012-01-01
h       NaN -0.706771 -1.039575  bar   True        NaT

In [20]: df2.dtypes.value_counts()
Out[20]: 
float64           3
object            1
bool              1
datetime64[ns]    1
Name: count, dtype: int64

---->   DataFrame.copy

--------------------------------------
ID: 2714 --> 1
In [21]: s = pd.Series([1, 2, 3])

In [22]: s.loc[0] = None

In [23]: s
Out[23]: 
0    NaN
1    2.0
2    3.0
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 2715 --> 1
In [24]: s = pd.Series(["a", "b", "c"])

In [25]: s.loc[0] = None

In [26]: s.loc[1] = np.nan

In [27]: s
Out[27]: 
0    None
1     NaN
2       c
dtype: object

---->   pandas.Series

--------------------------------------
ID: 2716 --> 2
In [31]: df
Out[31]: 
        one       two     three
a       NaN -0.282863 -1.509059
c       NaN  1.212112 -0.173215
e  0.119209 -1.044236 -0.861849
f -2.104569 -0.494929  1.071804
h       NaN -0.706771 -1.039575

In [32]: df["one"].sum()
Out[32]: -1.9853605075978744

In [33]: df.mean(1)
Out[33]: 
a   -0.895961
c    0.519449
e   -0.595625
f   -0.509232
h   -0.873173
dtype: float64

In [34]: df.cumsum()
Out[34]: 
        one       two     three
a       NaN -0.282863 -1.509059
c       NaN  0.929249 -1.682273
e  0.119209 -0.114987 -2.544122
f -1.985361 -0.609917 -1.472318
h       NaN -1.316688 -2.511893

In [35]: df.cumsum(skipna=False)
Out[35]: 
   one       two     three
a  NaN -0.282863 -1.509059
c  NaN  0.929249 -1.682273
e  NaN -0.114987 -2.544122
f  NaN -0.609917 -1.472318
h  NaN -1.316688 -2.511893

---->   DataFrame.mean; DataFrame.cumsum

--------------------------------------
ID: 2717 --> 1
In [36]: pd.Series([np.nan]).sum()
Out[36]: 0.0

In [37]: pd.Series([], dtype="float64").sum()
Out[37]: 0.0

---->   pandas.Series

--------------------------------------
ID: 2718 --> 1
In [38]: pd.Series([np.nan]).prod()
Out[38]: 1.0

In [39]: pd.Series([], dtype="float64").prod()
Out[39]: 1.0

---->   pandas.Series

--------------------------------------
ID: 2719 --> 1
In [40]: df
Out[40]: 
        one       two     three
a       NaN -0.282863 -1.509059
c       NaN  1.212112 -0.173215
e  0.119209 -1.044236 -0.861849
f -2.104569 -0.494929  1.071804
h       NaN -0.706771 -1.039575

In [41]: df.groupby("one").mean()
Out[41]: 
                two     three
one                          
-2.104569 -0.494929  1.071804
 0.119209 -1.044236 -0.861849

---->   DataFrame.groupby

--------------------------------------
ID: 2723 --> 2
In [49]: dff = pd.DataFrame(np.random.randn(10, 3), columns=list("ABC"))

In [50]: dff.iloc[3:5, 0] = np.nan

In [51]: dff.iloc[4:6, 1] = np.nan

In [52]: dff.iloc[5:8, 2] = np.nan

In [53]: dff
Out[53]: 
          A         B         C
0  0.271860 -0.424972  0.567020
1  0.276232 -1.087401 -0.673690
2  0.113648 -1.478427  0.524988
3       NaN  0.577046 -1.715002
4       NaN       NaN -1.157892
5 -1.344312       NaN       NaN
6 -0.109050  1.643563       NaN
7  0.357021 -0.674600       NaN
8 -0.968914 -1.294524  0.413738
9  0.276662 -0.472035 -0.013960

In [54]: dff.fillna(dff.mean())
Out[54]: 
          A         B         C
0  0.271860 -0.424972  0.567020
1  0.276232 -1.087401 -0.673690
2  0.113648 -1.478427  0.524988
3 -0.140857  0.577046 -1.715002
4 -0.140857 -0.401419 -1.157892
5 -1.344312 -0.401419 -0.293543
6 -0.109050  1.643563 -0.293543
7  0.357021 -0.674600 -0.293543
8 -0.968914 -1.294524  0.413738
9  0.276662 -0.472035 -0.013960

In [55]: dff.fillna(dff.mean()["B":"C"])
Out[55]: 
          A         B         C
0  0.271860 -0.424972  0.567020
1  0.276232 -1.087401 -0.673690
2  0.113648 -1.478427  0.524988
3       NaN  0.577046 -1.715002
4       NaN -0.401419 -1.157892
5 -1.344312 -0.401419 -0.293543
6 -0.109050  1.643563 -0.293543
7  0.357021 -0.674600 -0.293543
8 -0.968914 -1.294524  0.413738
9  0.276662 -0.472035 -0.013960

---->   pandas.DataFrame; DataFrame.mean

--------------------------------------
ID: 2724 --> 2
In [56]: dff.where(pd.notna(dff), dff.mean(), axis="columns")
Out[56]: 
          A         B         C
0  0.271860 -0.424972  0.567020
1  0.276232 -1.087401 -0.673690
2  0.113648 -1.478427  0.524988
3 -0.140857  0.577046 -1.715002
4 -0.140857 -0.401419 -1.157892
5 -1.344312 -0.401419 -0.293543
6 -0.109050  1.643563 -0.293543
7  0.357021 -0.674600 -0.293543
8 -0.968914 -1.294524  0.413738
9  0.276662 -0.472035 -0.013960

---->   pandas.notna; DataFrame.mean

--------------------------------------
ID: 2726 --> 2
In [61]: ts
Out[61]: 
2000-01-31    0.469112
2000-02-29         NaN
2000-03-31         NaN
2000-04-28         NaN
2000-05-31         NaN
                ...   
2007-12-31   -6.950267
2008-01-31   -7.904475
2008-02-29   -6.441779
2008-03-31   -8.184940
2008-04-30   -9.011531
Freq: BM, Length: 100, dtype: float64

In [62]: ts.count()
Out[62]: 66

In [63]: ts.plot()
Out[63]: 

---->   Series.count; Series.plot

--------------------------------------
ID: 2730 --> 1
In [73]: df = pd.DataFrame(
   ....:     {
   ....:         "A": [1, 2.1, np.nan, 4.7, 5.6, 6.8],
   ....:         "B": [0.25, np.nan, np.nan, 4, 12.2, 14.4],
   ....:     }
   ....: )
   ....: 

In [74]: df
Out[74]: 
     A      B
0  1.0   0.25
1  2.1    NaN
2  NaN    NaN
3  4.7   4.00
4  5.6  12.20
5  6.8  14.40

In [75]: df.interpolate()
Out[75]: 
     A      B
0  1.0   0.25
1  2.1   1.50
2  3.4   2.75
3  4.7   4.00
4  5.6  12.20
5  6.8  14.40

---->   pandas.DataFrame

--------------------------------------
ID: 2733 --> 3
In [81]: np.random.seed(2)

In [82]: ser = pd.Series(np.arange(1, 10.1, 0.25) ** 2 + np.random.randn(37))

In [83]: missing = np.array([4, 13, 14, 15, 16, 17, 18, 20, 29])

In [84]: ser[missing] = np.nan

In [85]: methods = ["linear", "quadratic", "cubic"]

In [86]: df = pd.DataFrame({m: ser.interpolate(method=m) for m in methods})

In [87]: df.plot()
Out[87]: 

---->   pandas.Series; pandas.DataFrame; DataFrame.plot

--------------------------------------
ID: 2734 --> 2
In [88]: ser = pd.Series(np.sort(np.random.uniform(size=100)))

# interpolate at new_index
In [89]: new_index = ser.index.union(pd.Index([49.25, 49.5, 49.75, 50.25, 50.5, 50.75]))

In [90]: interp_s = ser.reindex(new_index).interpolate(method="pchip")

In [91]: interp_s[49:51]
Out[91]: 
49.00    0.471410
49.25    0.476841
49.50    0.481780
49.75    0.485998
50.00    0.489266
50.25    0.491814
50.50    0.493995
50.75    0.495763
51.00    0.497074
dtype: float64

---->   pandas.Series; pandas.Index

--------------------------------------
ID: 2735 --> 1
In [92]: ser = pd.Series([np.nan, np.nan, 5, np.nan, np.nan, np.nan, 13, np.nan, np.nan])

In [93]: ser
Out[93]: 
0     NaN
1     NaN
2     5.0
3     NaN
4     NaN
5     NaN
6    13.0
7     NaN
8     NaN
dtype: float64

# fill all consecutive values in a forward direction
In [94]: ser.interpolate()
Out[94]: 
0     NaN
1     NaN
2     5.0
3     7.0
4     9.0
5    11.0
6    13.0
7    13.0
8    13.0
dtype: float64

# fill one consecutive value in a forward direction
In [95]: ser.interpolate(limit=1)
Out[95]: 
0     NaN
1     NaN
2     5.0
3     7.0
4     NaN
5     NaN
6    13.0
7    13.0
8     NaN
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 2738 --> 1
In [102]: ser = pd.Series([0.0, 1.0, 2.0, 3.0, 4.0])

In [103]: ser.replace(0, 5)
Out[103]: 
0    5.0
1    1.0
2    2.0
3    3.0
4    4.0
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 2741 --> 1
In [106]: df = pd.DataFrame({"a": [0, 1, 2, 3, 4], "b": [5, 6, 7, 8, 9]})

In [107]: df.replace({"a": 0, "b": 5}, 100)
Out[107]: 
     a    b
0  100  100
1    1    6
2    2    7
3    3    8
4    4    9

---->   pandas.DataFrame

--------------------------------------
ID: 2743 --> 1
In [109]: d = {"a": list(range(4)), "b": list("ab.."), "c": ["a", "b", np.nan, "d"]}

In [110]: df = pd.DataFrame(d)

In [111]: df.replace(".", np.nan)
Out[111]: 
   a    b    c
0  0    a    a
1  1    b    b
2  2  NaN  NaN
3  3  NaN    d

---->   pandas.DataFrame

--------------------------------------
ID: 2754 --> 1
In [122]: df = pd.DataFrame(np.random.randn(10, 2))

In [123]: df[np.random.rand(df.shape[0]) > 0.5] = 1.5

In [124]: df.replace(1.5, np.nan)
Out[124]: 
          0         1
0 -0.844214 -1.021415
1  0.432396 -0.323580
2  0.423825  0.799180
3  1.262614  0.751965
4       NaN       NaN
5       NaN       NaN
6 -0.498174 -1.060799
7  0.591667 -0.183257
8  1.019855 -1.482465
9       NaN       NaN

---->   pandas.DataFrame

--------------------------------------
ID: 2756 --> 1
In [128]: s = pd.Series(np.random.randn(5), index=[0, 2, 4, 6, 7])

In [129]: s > 0
Out[129]: 
0    True
2    True
4    True
6    True
7    True
dtype: bool

In [130]: (s > 0).dtype
Out[130]: dtype('bool')

In [131]: crit = (s > 0).reindex(list(range(8)))

In [132]: crit
Out[132]: 
0    True
1     NaN
2    True
3     NaN
4    True
5     NaN
6    True
7    True
dtype: object

In [133]: crit.dtype
Out[133]: dtype('O')

---->   pandas.Series

--------------------------------------
ID: 2759 --> 1
In [138]: s = pd.Series([0, 1, np.nan, 3, 4], dtype="Int64")

In [139]: s
Out[139]: 
0       0
1       1
2    
3       3
4       4
dtype: Int64

---->   pandas.Series

--------------------------------------
ID: 2760 --> 1
In [140]: s = pd.Series([1, 2, None], dtype="Int64")

In [141]: s
Out[141]: 
0       1
1       2
2    
dtype: Int64

In [142]: s[2]
Out[142]: 

In [143]: s[2] is pd.NA
Out[143]: True

---->   pandas.Series

--------------------------------------
ID: 2761 --> 1
In [151]: pd.isna(pd.NA)
Out[151]: True

---->   pandas.isna

--------------------------------------
ID: 2767 --> 1
In [3]: s = pd.Series([1, 3, 5, np.nan, 6, 8])

In [4]: s
Out[4]: 
0    1.0
1    3.0
2    5.0
3    NaN
4    6.0
5    8.0
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 2768 --> 1
In [5]: dates = pd.date_range("20130101", periods=6)

In [6]: dates
Out[6]: 
DatetimeIndex(['2013-01-01', '2013-01-02', '2013-01-03', '2013-01-04',
               '2013-01-05', '2013-01-06'],
              dtype='datetime64[ns]', freq='D')

In [7]: df = pd.DataFrame(np.random.randn(6, 4), index=dates, columns=list("ABCD"))

In [8]: df
Out[8]: 
                   A         B         C         D
2013-01-01  0.469112 -0.282863 -1.509059 -1.135632
2013-01-02  1.212112 -0.173215  0.119209 -1.044236
2013-01-03 -0.861849 -2.104569 -0.494929  1.071804
2013-01-04  0.721555 -0.706771 -1.039575  0.271860
2013-01-05 -0.424972  0.567020  0.276232 -1.087401
2013-01-06 -0.673690  0.113648 -1.478427  0.524988

---->   pandas.DataFrame

--------------------------------------
ID: 2769 --> 3
In [9]: df2 = pd.DataFrame(
   ...:     {
   ...:         "A": 1.0,
   ...:         "B": pd.Timestamp("20130102"),
   ...:         "C": pd.Series(1, index=list(range(4)), dtype="float32"),
   ...:         "D": np.array([3] * 4, dtype="int32"),
   ...:         "E": pd.Categorical(["test", "train", "test", "train"]),
   ...:         "F": "foo",
   ...:     }
   ...: )
   ...: 

In [10]: df2
Out[10]: 
     A          B    C  D      E    F
0  1.0 2013-01-02  1.0  3   test  foo
1  1.0 2013-01-02  1.0  3  train  foo
2  1.0 2013-01-02  1.0  3   test  foo
3  1.0 2013-01-02  1.0  3  train  foo

---->   pandas.DataFrame; pandas.Series; pandas.Categorical

--------------------------------------
ID: 2770 --> 2
In [13]: df.head()
Out[13]: 
                   A         B         C         D
2013-01-01  0.469112 -0.282863 -1.509059 -1.135632
2013-01-02  1.212112 -0.173215  0.119209 -1.044236
2013-01-03 -0.861849 -2.104569 -0.494929  1.071804
2013-01-04  0.721555 -0.706771 -1.039575  0.271860
2013-01-05 -0.424972  0.567020  0.276232 -1.087401

In [14]: df.tail(3)
Out[14]: 
                   A         B         C         D
2013-01-04  0.721555 -0.706771 -1.039575  0.271860
2013-01-05 -0.424972  0.567020  0.276232 -1.087401
2013-01-06 -0.673690  0.113648 -1.478427  0.524988

---->   DataFrame.head; DataFrame.tail

--------------------------------------
ID: 2774 --> 1
In [19]: df.describe()
Out[19]: 
              A         B         C         D
count  6.000000  6.000000  6.000000  6.000000
mean   0.073711 -0.431125 -0.687758 -0.233103
std    0.843157  0.922818  0.779887  0.973118
min   -0.861849 -2.104569 -1.509059 -1.135632
25%   -0.611510 -0.600794 -1.368714 -1.076610
50%    0.022070 -0.228039 -0.767252 -0.386188
75%    0.658444  0.041933 -0.034326  0.461706
max    1.212112  0.567020  0.276232  1.071804

---->   DataFrame.describe

--------------------------------------
ID: 2777 --> 1
In [41]: df2 = df.copy()

In [42]: df2["E"] = ["one", "one", "two", "three", "four", "three"]

In [43]: df2
Out[43]: 
                   A         B         C         D      E
2013-01-01  0.469112 -0.282863 -1.509059 -1.135632    one
2013-01-02  1.212112 -0.173215  0.119209 -1.044236    one
2013-01-03 -0.861849 -2.104569 -0.494929  1.071804    two
2013-01-04  0.721555 -0.706771 -1.039575  0.271860  three
2013-01-05 -0.424972  0.567020  0.276232 -1.087401   four
2013-01-06 -0.673690  0.113648 -1.478427  0.524988  three

In [44]: df2[df2["E"].isin(["two", "four"])]
Out[44]: 
                   A         B         C         D     E
2013-01-03 -0.861849 -2.104569 -0.494929  1.071804   two
2013-01-05 -0.424972  0.567020  0.276232 -1.087401  four

---->   DataFrame.copy

--------------------------------------
ID: 2778 --> 1
In [45]: s1 = pd.Series([1, 2, 3, 4, 5, 6], index=pd.date_range("20130102", periods=6))

In [46]: s1
Out[46]: 
2013-01-02    1
2013-01-03    2
2013-01-04    3
2013-01-05    4
2013-01-06    5
2013-01-07    6
Freq: D, dtype: int64

In [47]: df["F"] = s1

---->   pandas.Series

--------------------------------------
ID: 2780 --> 1
In [52]: df2 = df.copy()

In [53]: df2[df2 > 0] = -df2

In [54]: df2
Out[54]: 
                   A         B         C    D    F
2013-01-01  0.000000  0.000000 -1.509059 -5.0  NaN
2013-01-02 -1.212112 -0.173215 -0.119209 -5.0 -1.0
2013-01-03 -0.861849 -2.104569 -0.494929 -5.0 -2.0
2013-01-04 -0.721555 -0.706771 -1.039575 -5.0 -3.0
2013-01-05 -0.424972 -0.567020 -0.276232 -5.0 -4.0
2013-01-06 -0.673690 -0.113648 -1.478427 -5.0 -5.0

---->   DataFrame.copy

--------------------------------------
ID: 2784 --> 1
In [60]: pd.isna(df1)
Out[60]: 
                A      B      C      D      F      E
2013-01-01  False  False  False  False   True  False
2013-01-02  False  False  False  False  False  False
2013-01-03  False  False  False  False  False   True
2013-01-04  False  False  False  False  False   True

---->   pandas.isna

--------------------------------------
ID: 2785 --> 1
In [61]: df.mean()
Out[61]: 
A   -0.004474
B   -0.383981
C   -0.687758
D    5.000000
F    3.000000
dtype: float64

---->   DataFrame.mean

--------------------------------------
ID: 2786 --> 1
In [62]: df.mean(1)
Out[62]: 
2013-01-01    0.872735
2013-01-02    1.431621
2013-01-03    0.707731
2013-01-04    1.395042
2013-01-05    1.883656
2013-01-06    1.592306
Freq: D, dtype: float64

---->   DataFrame.mean

--------------------------------------
ID: 2787 --> 2
In [63]: s = pd.Series([1, 3, 5, np.nan, 6, 8], index=dates).shift(2)

In [64]: s
Out[64]: 
2013-01-01    NaN
2013-01-02    NaN
2013-01-03    1.0
2013-01-04    3.0
2013-01-05    5.0
2013-01-06    NaN
Freq: D, dtype: float64

In [65]: df.sub(s, axis="index")
Out[65]: 
                   A         B         C    D    F
2013-01-01       NaN       NaN       NaN  NaN  NaN
2013-01-02       NaN       NaN       NaN  NaN  NaN
2013-01-03 -1.861849 -3.104569 -1.494929  4.0  1.0
2013-01-04 -2.278445 -3.706771 -4.039575  2.0  0.0
2013-01-05 -5.424972 -4.432980 -4.723768  0.0 -1.0
2013-01-06       NaN       NaN       NaN  NaN  NaN

---->   pandas.Series; DataFrame.sub

--------------------------------------
ID: 2788 --> 2
In [66]: df.apply(np.cumsum)
Out[66]: 
                   A         B         C     D     F
2013-01-01  0.000000  0.000000 -1.509059   5.0   NaN
2013-01-02  1.212112 -0.173215 -1.389850  10.0   1.0
2013-01-03  0.350263 -2.277784 -1.884779  15.0   3.0
2013-01-04  1.071818 -2.984555 -2.924354  20.0   6.0
2013-01-05  0.646846 -2.417535 -2.648122  25.0  10.0
2013-01-06 -0.026844 -2.303886 -4.126549  30.0  15.0

In [67]: df.apply(lambda x: x.max() - x.min())
Out[67]: 
A    2.073961
B    2.671590
C    1.785291
D    0.000000
F    4.000000
dtype: float64

---->   Series.max; Series.min

--------------------------------------
ID: 2789 --> 2
In [68]: s = pd.Series(np.random.randint(0, 7, size=10))

In [69]: s
Out[69]: 
0    4
1    2
2    1
3    2
4    6
5    4
6    4
7    6
8    4
9    4
dtype: int64

In [70]: s.value_counts()
Out[70]: 
4    5
2    2
6    2
1    1
Name: count, dtype: int64

---->   pandas.Series; Series.value_counts

--------------------------------------
ID: 2790 --> 1
In [71]: s = pd.Series(["A", "B", "C", "Aaba", "Baca", np.nan, "CABA", "dog", "cat"])

In [72]: s.str.lower()
Out[72]: 
0       a
1       b
2       c
3    aaba
4    baca
5     NaN
6    caba
7     dog
8     cat
dtype: object

---->   pandas.Series

--------------------------------------
ID: 2791 --> 1
In [73]: df = pd.DataFrame(np.random.randn(10, 4))

In [74]: df
Out[74]: 
          0         1         2         3
0 -0.548702  1.467327 -1.015962 -0.483075
1  1.637550 -1.217659 -0.291519 -1.745505
2 -0.263952  0.991460 -0.919069  0.266046
3 -0.709661  1.669052  1.037882 -1.705775
4 -0.919854 -0.042379  1.247642 -0.009920
5  0.290213  0.495767  0.362949  1.548106
6 -1.131345 -0.089329  0.337863 -0.945867
7 -0.932132  1.956030  0.017587 -0.016692
8 -0.575247  0.254161 -1.143704  0.215897
9  1.193555 -0.077118 -0.408530 -0.862495

# break it into pieces
In [75]: pieces = [df[:3], df[3:7], df[7:]]

In [76]: pd.concat(pieces)
Out[76]: 
          0         1         2         3
0 -0.548702  1.467327 -1.015962 -0.483075
1  1.637550 -1.217659 -0.291519 -1.745505
2 -0.263952  0.991460 -0.919069  0.266046
3 -0.709661  1.669052  1.037882 -1.705775
4 -0.919854 -0.042379  1.247642 -0.009920
5  0.290213  0.495767  0.362949  1.548106
6 -1.131345 -0.089329  0.337863 -0.945867
7 -0.932132  1.956030  0.017587 -0.016692
8 -0.575247  0.254161 -1.143704  0.215897
9  1.193555 -0.077118 -0.408530 -0.862495

---->   pandas.DataFrame

--------------------------------------
ID: 2792 --> 1
In [77]: left = pd.DataFrame({"key": ["foo", "foo"], "lval": [1, 2]})

In [78]: right = pd.DataFrame({"key": ["foo", "foo"], "rval": [4, 5]})

In [79]: left
Out[79]: 
   key  lval
0  foo     1
1  foo     2

In [80]: right
Out[80]: 
   key  rval
0  foo     4
1  foo     5

In [81]: pd.merge(left, right, on="key")
Out[81]: 
   key  lval  rval
0  foo     1     4
1  foo     1     5
2  foo     2     4
3  foo     2     5

---->   pandas.DataFrame

--------------------------------------
ID: 2793 --> 1
In [82]: left = pd.DataFrame({"key": ["foo", "bar"], "lval": [1, 2]})

In [83]: right = pd.DataFrame({"key": ["foo", "bar"], "rval": [4, 5]})

In [84]: left
Out[84]: 
   key  lval
0  foo     1
1  bar     2

In [85]: right
Out[85]: 
   key  rval
0  foo     4
1  bar     5

In [86]: pd.merge(left, right, on="key")
Out[86]: 
   key  lval  rval
0  foo     1     4
1  bar     2     5

---->   pandas.DataFrame

--------------------------------------
ID: 2794 --> 1
In [87]: df = pd.DataFrame(
   ....:     {
   ....:         "A": ["foo", "bar", "foo", "bar", "foo", "bar", "foo", "foo"],
   ....:         "B": ["one", "one", "two", "three", "two", "two", "one", "three"],
   ....:         "C": np.random.randn(8),
   ....:         "D": np.random.randn(8),
   ....:     }
   ....: )
   ....: 

In [88]: df
Out[88]: 
     A      B         C         D
0  foo    one  1.346061 -1.577585
1  bar    one  1.511763  0.396823
2  foo    two  1.627081 -0.105381
3  bar  three -0.990582 -0.532532
4  foo    two -0.441652  1.453749
5  bar    two  1.211526  1.208843
6  foo    one  0.268520 -0.080952
7  foo  three  0.024580 -0.264610

---->   pandas.DataFrame

--------------------------------------
ID: 2795 --> 1
In [89]: df.groupby("A")[["C", "D"]].sum()
Out[89]: 
            C         D
A                      
bar  1.732707  1.073134
foo  2.824590 -0.574779

---->   DataFrame.groupby

--------------------------------------
ID: 2796 --> 1
In [90]: df.groupby(["A", "B"]).sum()
Out[90]: 
                  C         D
A   B                        
bar one    1.511763  0.396823
    three -0.990582 -0.532532
    two    1.211526  1.208843
foo one    1.614581 -1.658537
    three  0.024580 -0.264610
    two    1.185429  1.348368

---->   DataFrame.groupby

--------------------------------------
ID: 2797 --> 2
In [91]: tuples = list(
   ....:     zip(
   ....:         ["bar", "bar", "baz", "baz", "foo", "foo", "qux", "qux"],
   ....:         ["one", "two", "one", "two", "one", "two", "one", "two"],
   ....:     )
   ....: )
   ....: 

In [92]: index = pd.MultiIndex.from_tuples(tuples, names=["first", "second"])

In [93]: df = pd.DataFrame(np.random.randn(8, 2), index=index, columns=["A", "B"])

In [94]: df2 = df[:4]

In [95]: df2
Out[95]: 
                     A         B
first second                    
bar   one    -0.727965 -0.589346
      two     0.339969 -0.693205
baz   one    -0.339355  0.593616
      two     0.884345  1.591431

---->   pandas.MultiIndex; pandas.DataFrame

--------------------------------------
ID: 2798 --> 1
In [96]: stacked = df2.stack()

In [97]: stacked
Out[97]: 
first  second   
bar    one     A   -0.727965
               B   -0.589346
       two     A    0.339969
               B   -0.693205
baz    one     A   -0.339355
               B    0.593616
       two     A    0.884345
               B    1.591431
dtype: float64

---->   DataFrame.stack

--------------------------------------
ID: 2800 --> 1
In [101]: df = pd.DataFrame(
   .....:     {
   .....:         "A": ["one", "one", "two", "three"] * 3,
   .....:         "B": ["A", "B", "C"] * 4,
   .....:         "C": ["foo", "foo", "foo", "bar", "bar", "bar"] * 2,
   .....:         "D": np.random.randn(12),
   .....:         "E": np.random.randn(12),
   .....:     }
   .....: )
   .....: 

In [102]: df
Out[102]: 
        A  B    C         D         E
0     one  A  foo -1.202872  0.047609
1     one  B  foo -1.814470 -0.136473
2     two  C  foo  1.018601 -0.561757
3   three  A  bar -0.595447 -1.623033
4     one  B  bar  1.395433  0.029399
5     one  C  bar -0.392670 -0.542108
6     two  A  foo  0.007207  0.282696
7   three  B  foo  1.928123 -0.087302
8     one  C  foo -0.055224 -1.575170
9     one  A  bar  2.395985  1.771208
10    two  B  bar  1.552825  0.816482
11  three  C  bar  0.166599  1.100230

---->   pandas.DataFrame

--------------------------------------
ID: 2801 --> 1
In [103]: pd.pivot_table(df, values="D", index=["A", "B"], columns=["C"])
Out[103]: 
C             bar       foo
A     B                    
one   A  2.395985 -1.202872
      B  1.395433 -1.814470
      C -0.392670 -0.055224
three A -0.595447       NaN
      B       NaN  1.928123
      C  0.166599       NaN
two   A       NaN  0.007207
      B  1.552825       NaN
      C       NaN  1.018601

---->   pandas.pivot_table

--------------------------------------
ID: 2802 --> 2
In [104]: rng = pd.date_range("1/1/2012", periods=100, freq="S")

In [105]: ts = pd.Series(np.random.randint(0, 500, len(rng)), index=rng)

In [106]: ts.resample("5Min").sum()
Out[106]: 
2012-01-01    24182
Freq: 5T, dtype: int64

---->   pandas.Series; Series.resample

--------------------------------------
ID: 2803 --> 2
In [107]: rng = pd.date_range("3/6/2012 00:00", periods=5, freq="D")

In [108]: ts = pd.Series(np.random.randn(len(rng)), rng)

In [109]: ts
Out[109]: 
2012-03-06    1.857704
2012-03-07   -1.193545
2012-03-08    0.677510
2012-03-09   -0.153931
2012-03-10    0.520091
Freq: D, dtype: float64

In [110]: ts_utc = ts.tz_localize("UTC")

In [111]: ts_utc
Out[111]: 
2012-03-06 00:00:00+00:00    1.857704
2012-03-07 00:00:00+00:00   -1.193545
2012-03-08 00:00:00+00:00    0.677510
2012-03-09 00:00:00+00:00   -0.153931
2012-03-10 00:00:00+00:00    0.520091
Freq: D, dtype: float64

---->   pandas.Series; Series.tz_localize

--------------------------------------
ID: 2804 --> 1
In [112]: ts_utc.tz_convert("US/Eastern")
Out[112]: 
2012-03-05 19:00:00-05:00    1.857704
2012-03-06 19:00:00-05:00   -1.193545
2012-03-07 19:00:00-05:00    0.677510
2012-03-08 19:00:00-05:00   -0.153931
2012-03-09 19:00:00-05:00    0.520091
Freq: D, dtype: float64

---->   Series.tz_convert

--------------------------------------
ID: 2805 --> 3
In [113]: rng = pd.date_range("1/1/2012", periods=5, freq="M")

In [114]: ts = pd.Series(np.random.randn(len(rng)), index=rng)

In [115]: ts
Out[115]: 
2012-01-31   -1.475051
2012-02-29    0.722570
2012-03-31   -0.322646
2012-04-30   -1.601631
2012-05-31    0.778033
Freq: M, dtype: float64

In [116]: ps = ts.to_period()

In [117]: ps
Out[117]: 
2012-01   -1.475051
2012-02    0.722570
2012-03   -0.322646
2012-04   -1.601631
2012-05    0.778033
Freq: M, dtype: float64

In [118]: ps.to_timestamp()
Out[118]: 
2012-01-01   -1.475051
2012-02-01    0.722570
2012-03-01   -0.322646
2012-04-01   -1.601631
2012-05-01    0.778033
Freq: MS, dtype: float64

---->   pandas.Series; Series.to_period; Series.to_timestamp

--------------------------------------
ID: 2806 --> 3
In [119]: prng = pd.period_range("1990Q1", "2000Q4", freq="Q-NOV")

In [120]: ts = pd.Series(np.random.randn(len(prng)), prng)

In [121]: ts.index = (prng.asfreq("M", "e") + 1).asfreq("H", "s") + 9

In [122]: ts.head()
Out[122]: 
1990-03-01 09:00   -0.289342
1990-06-01 09:00    0.233141
1990-09-01 09:00   -0.223540
1990-12-01 09:00    0.542054
1991-03-01 09:00   -0.688585
Freq: H, dtype: float64

---->   pandas.period_range; pandas.Series; Series.head

--------------------------------------
ID: 2807 --> 1
In [123]: df = pd.DataFrame(
   .....:     {"id": [1, 2, 3, 4, 5, 6], "raw_grade": ["a", "b", "b", "a", "a", "e"]}
   .....: )
   .....: 

---->   pandas.DataFrame

--------------------------------------
ID: 2812 --> 1
In [131]: df.groupby("grade").size()
Out[131]: 
grade
very bad     1
bad          0
medium       0
good         2
very good    3
dtype: int64

---->   DataFrame.groupby

--------------------------------------
ID: 2814 --> 3
In [134]: ts = pd.Series(np.random.randn(1000), index=pd.date_range("1/1/2000", periods=1000))

In [135]: ts = ts.cumsum()

In [136]: ts.plot();

---->   pandas.Series; Series.cumsum; Series.plot

--------------------------------------
ID: 2816 --> 3
In [138]: df = pd.DataFrame(
   .....:     np.random.randn(1000, 4), index=ts.index, columns=["A", "B", "C", "D"]
   .....: )
   .....: 

In [139]: df = df.cumsum()

In [140]: plt.figure();

In [141]: df.plot();

In [142]: plt.legend(loc='best');

---->   pandas.DataFrame; DataFrame.cumsum; DataFrame.plot

--------------------------------------
ID: 2817 --> 1
In [143]: df.to_csv("foo.csv")

---->   DataFrame.to_csv

--------------------------------------
ID: 2819 --> 1
In [145]: df.to_hdf("foo.h5", "df")

---->   DataFrame.to_hdf

--------------------------------------
ID: 2820 --> 1
In [146]: pd.read_hdf("foo.h5", "df")
Out[146]: 
                    A          B          C          D
2000-01-01   0.350262   0.843315   1.798556   0.782234
2000-01-02  -0.586873   0.034907   1.923792  -0.562651
2000-01-03  -1.245477  -0.963406   2.269575  -1.612566
2000-01-04  -0.252830  -0.498066   3.176886  -1.275581
2000-01-05  -1.044057   0.118042   2.768571   0.386039
...               ...        ...        ...        ...
2002-09-22 -48.017654  31.474551  69.146374 -47.541670
2002-09-23 -47.207912  32.627390  68.505254 -48.828331
2002-09-24 -48.907133  31.990402  67.310924 -49.391051
2002-09-25 -50.146062  33.716770  67.717434 -49.037577
2002-09-26 -49.724318  33.479952  68.108014 -48.822030

[1000 rows x 4 columns]

---->   pandas.read_hdf

--------------------------------------
ID: 2821 --> 1
In [147]: df.to_excel("foo.xlsx", sheet_name="Sheet1")

---->   DataFrame.to_excel

--------------------------------------
ID: 2823 --> 4
In [149]: if pd.Series([False, True, False]):
   .....:      print("I was true")
   .....: 
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
 in ?()
----> 1 if pd.Series([False, True, False]):
      2      print("I was true")

~/work/pandas/pandas/pandas/core/generic.py in ?(self)
   1464     @final
   1465     def __nonzero__(self) -> NoReturn:
-> 1466         raise ValueError(
   1467             f"The truth value of a {type(self).__name__} is ambiguous. "
   1468             "Use a.empty, a.bool(), a.item(), a.any() or a.all()."
   1469         )

ValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().

---->   pandas.Series; Series.bool; Series.item; Series.all

--------------------------------------
ID: 2827 --> 1
In [3]: df = pd.DataFrame({"x": [1, 3, 5], "y": [2, 4, 6]})

In [4]: df
Out[4]: 
   x  y
0  1  2
1  3  4
2  5  6

---->   pandas.DataFrame

--------------------------------------
ID: 2848 --> 1
In [36]: firstlast = pd.DataFrame({"String": ["John Smith", "Jane Cook"]})

In [37]: firstlast["First_Name"] = firstlast["String"].str.split(" ", expand=True)[0]

In [38]: firstlast["Last_Name"] = firstlast["String"].str.rsplit(" ", expand=True)[1]

In [39]: firstlast
Out[39]: 
       String First_Name Last_Name
0  John Smith       John     Smith
1   Jane Cook       Jane      Cook

---->   pandas.DataFrame

--------------------------------------
ID: 2850 --> 1
In [40]: firstlast = pd.DataFrame({"string": ["John Smith", "Jane Cook"]})

In [41]: firstlast["upper"] = firstlast["string"].str.upper()

In [42]: firstlast["lower"] = firstlast["string"].str.lower()

In [43]: firstlast["title"] = firstlast["string"].str.title()

In [44]: firstlast
Out[44]: 
       string       upper       lower       title
0  John Smith  JOHN SMITH  john smith  John Smith
1   Jane Cook   JANE COOK   jane cook   Jane Cook

---->   pandas.DataFrame

--------------------------------------
ID: 2851 --> 1
In [45]: df1 = pd.DataFrame({"key": ["A", "B", "C", "D"], "value": np.random.randn(4)})

In [46]: df1
Out[46]: 
  key     value
0   A  0.469112
1   B -0.282863
2   C -1.509059
3   D -1.135632

In [47]: df2 = pd.DataFrame({"key": ["B", "D", "D", "E"], "value": np.random.randn(4)})

In [48]: df2
Out[48]: 
  key     value
0   B  1.212112
1   D -0.173215
2   D  0.119209
3   E -1.044236

---->   pandas.DataFrame

--------------------------------------
ID: 2878 --> 1
>>> pd.test()
running: pytest --skip-slow --skip-network --skip-db /home/user/anaconda3/lib/python3.9/site-packages/pandas

============================= test session starts ==============================
platform linux -- Python 3.9.7, pytest-6.2.5, py-1.11.0, pluggy-1.0.0
rootdir: /home/user
plugins: dash-1.19.0, anyio-3.5.0, hypothesis-6.29.3
collected 154975 items / 4 skipped / 154971 selected
........................................................................ [  0%]
........................................................................ [ 99%]
.......................................                                  [100%]

==================================== ERRORS ====================================

=================================== FAILURES ===================================

=============================== warnings summary ===============================

=========================== short test summary info ============================

= 1 failed, 146194 passed, 7402 skipped, 1367 xfailed, 5 xpassed, 197 warnings, 10 errors in 1090.16s (0:18:10) =

---->   pandas.test

--------------------------------------
ID: 2879 --> 2
In [3]: s1 = pd.Series([0, 1, 2], index=["a", "b", "b"])

In [4]: s1.reindex(["a", "b", "c"])
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
Cell In[4], line 1
----> 1 s1.reindex(["a", "b", "c"])

File ~/work/pandas/pandas/pandas/core/series.py:4918, in Series.reindex(self, index, axis, method, copy, level, fill_value, limit, tolerance)
   4901 @doc(
   4902     NDFrame.reindex,  # type: ignore[has-type]
   4903     klass=_shared_doc_kwargs["klass"],
   (...)
   4916     tolerance=None,
   4917 ) -> Series:
-> 4918     return super().reindex(
   4919         index=index,
   4920         method=method,
   4921         copy=copy,
   4922         level=level,
   4923         fill_value=fill_value,
   4924         limit=limit,
   4925         tolerance=tolerance,
   4926     )

File ~/work/pandas/pandas/pandas/core/generic.py:5360, in NDFrame.reindex(self, labels, index, columns, axis, method, copy, level, fill_value, limit, tolerance)
   5357     return self._reindex_multi(axes, copy, fill_value)
   5359 # perform the reindex on the axes
-> 5360 return self._reindex_axes(
   5361     axes, level, limit, tolerance, method, fill_value, copy
   5362 ).__finalize__(self, method="reindex")

File ~/work/pandas/pandas/pandas/core/generic.py:5375, in NDFrame._reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy)
   5372     continue
   5374 ax = self._get_axis(a)
-> 5375 new_index, indexer = ax.reindex(
   5376     labels, level=level, limit=limit, tolerance=tolerance, method=method
   5377 )
   5379 axis = self._get_axis_number(a)
   5380 obj = obj._reindex_with_indexers(
   5381     {axis: [new_index, indexer]},
   5382     fill_value=fill_value,
   5383     copy=copy,
   5384     allow_dups=False,
   5385 )

File ~/work/pandas/pandas/pandas/core/indexes/base.py:4275, in Index.reindex(self, target, method, level, limit, tolerance)
   4272     raise ValueError("cannot handle a non-unique multi-index!")
   4273 elif not self.is_unique:
   4274     # GH#42568
-> 4275     raise ValueError("cannot reindex on an axis with duplicate labels")
   4276 else:
   4277     indexer, _ = self.get_indexer_non_unique(target)

ValueError: cannot reindex on an axis with duplicate labels

---->   pandas.Series; Index.reindex

--------------------------------------
ID: 2880 --> 1
In [5]: df1 = pd.DataFrame([[0, 1, 2], [3, 4, 5]], columns=["A", "A", "B"])

In [6]: df1
Out[6]: 
   A  A  B
0  0  1  2
1  3  4  5

---->   pandas.DataFrame

--------------------------------------
ID: 2881 --> 1
In [9]: df2 = pd.DataFrame({"A": [0, 1, 2]}, index=["a", "a", "b"])

In [10]: df2
Out[10]: 
   A
a  0
a  1
b  2

In [11]: df2.loc["b", "A"]  # a scalar
Out[11]: 2

In [12]: df2.loc["a", "A"]  # a Series
Out[12]: 
a    0
a    1
Name: A, dtype: int64

---->   pandas.DataFrame

--------------------------------------
ID: 2884 --> 1
In [18]: df2.groupby(level=0).mean()
Out[18]: 
     A
a  0.5
b  2.0

---->   DataFrame.groupby

--------------------------------------
ID: 2885 --> 1
In [19]: pd.Series([0, 1, 2], index=["a", "b", "b"]).set_flags(allows_duplicate_labels=False)
---------------------------------------------------------------------------
DuplicateLabelError                       Traceback (most recent call last)
Cell In[19], line 1
----> 1 pd.Series([0, 1, 2], index=["a", "b", "b"]).set_flags(allows_duplicate_labels=False)

File ~/work/pandas/pandas/pandas/core/generic.py:450, in NDFrame.set_flags(self, copy, allows_duplicate_labels)
    448 df = self.copy(deep=copy and not using_copy_on_write())
    449 if allows_duplicate_labels is not None:
--> 450     df.flags["allows_duplicate_labels"] = allows_duplicate_labels
    451 return df

File ~/work/pandas/pandas/pandas/core/flags.py:107, in Flags.__setitem__(self, key, value)
    105 if key not in self._keys:
    106     raise ValueError(f"Unknown flag {key}. Must be one of {self._keys}")
--> 107 setattr(self, key, value)

File ~/work/pandas/pandas/pandas/core/flags.py:94, in Flags.allows_duplicate_labels(self, value)
     92 if not value:
     93     for ax in obj.axes:
---> 94         ax._maybe_check_unique()
     96 self._allows_duplicate_labels = value

File ~/work/pandas/pandas/pandas/core/indexes/base.py:706, in Index._maybe_check_unique(self)
    703 duplicates = self._format_duplicate_message()
    704 msg += f"\n{duplicates}"
--> 706 raise DuplicateLabelError(msg)

DuplicateLabelError: Index has duplicates.
      positions
label          
b        [1, 2]

---->   pandas.Series

--------------------------------------
ID: 2886 --> 1
In [20]: pd.DataFrame([[0, 1, 2], [3, 4, 5]], columns=["A", "B", "C"],).set_flags(
   ....:     allows_duplicate_labels=False
   ....: )
   ....: 
Out[20]: 
   A  B  C
0  0  1  2
1  3  4  5

---->   pandas.DataFrame

--------------------------------------
ID: 2887 --> 1
In [21]: df = pd.DataFrame({"A": [0, 1, 2, 3]}, index=["x", "y", "X", "Y"]).set_flags(
   ....:     allows_duplicate_labels=False
   ....: )
   ....: 

In [22]: df
Out[22]: 
   A
x  0
y  1
X  2
Y  3

In [23]: df.flags.allows_duplicate_labels
Out[23]: False

---->   pandas.DataFrame

--------------------------------------
ID: 2891 --> 2
In [29]: s1 = pd.Series(0, index=["a", "b"]).set_flags(allows_duplicate_labels=False)

In [30]: s1
Out[30]: 
a    0
b    0
dtype: int64

In [31]: s1.head().rename({"a": "b"})
---------------------------------------------------------------------------
DuplicateLabelError                       Traceback (most recent call last)
Cell In[31], line 1
----> 1 s1.head().rename({"a": "b"})

File ~/work/pandas/pandas/pandas/core/series.py:4856, in Series.rename(self, index, axis, copy, inplace, level, errors)
   4849     axis = self._get_axis_number(axis)
   4851 if callable(index) or is_dict_like(index):
   4852     # error: Argument 1 to "_rename" of "NDFrame" has incompatible
   4853     # type "Union[Union[Mapping[Any, Hashable], Callable[[Any],
   4854     # Hashable]], Hashable, None]"; expected "Union[Mapping[Any,
   4855     # Hashable], Callable[[Any], Hashable], None]"
-> 4856     return super()._rename(
   4857         index,  # type: ignore[arg-type]
   4858         copy=copy,
   4859         inplace=inplace,
   4860         level=level,
   4861         errors=errors,
   4862     )
   4863 else:
   4864     return self._set_name(index, inplace=inplace, deep=copy)

File ~/work/pandas/pandas/pandas/core/generic.py:1042, in NDFrame._rename(self, mapper, index, columns, axis, copy, inplace, level, errors)
   1040     return None
   1041 else:
-> 1042     return result.__finalize__(self, method="rename")

File ~/work/pandas/pandas/pandas/core/generic.py:5955, in NDFrame.__finalize__(self, other, method, **kwargs)
   5952 for name in other.attrs:
   5953     self.attrs[name] = other.attrs[name]
-> 5955 self.flags.allows_duplicate_labels = other.flags.allows_duplicate_labels
   5956 # For subclasses using _metadata.
   5957 for name in set(self._metadata) & set(other._metadata):

File ~/work/pandas/pandas/pandas/core/flags.py:94, in Flags.allows_duplicate_labels(self, value)
     92 if not value:
     93     for ax in obj.axes:
---> 94         ax._maybe_check_unique()
     96 self._allows_duplicate_labels = value

File ~/work/pandas/pandas/pandas/core/indexes/base.py:706, in Index._maybe_check_unique(self)
    703 duplicates = self._format_duplicate_message()
    704 msg += f"\n{duplicates}"
--> 706 raise DuplicateLabelError(msg)

DuplicateLabelError: Index has duplicates.
      positions
label          
b        [0, 1]

---->   pandas.Series; Series.head

--------------------------------------
ID: 2892 --> 1
In [1]: df1 = pd.DataFrame(
   ...:     {
   ...:         "A": ["A0", "A1", "A2", "A3"],
   ...:         "B": ["B0", "B1", "B2", "B3"],
   ...:         "C": ["C0", "C1", "C2", "C3"],
   ...:         "D": ["D0", "D1", "D2", "D3"],
   ...:     },
   ...:     index=[0, 1, 2, 3],
   ...: )
   ...: 

In [2]: df2 = pd.DataFrame(
   ...:     {
   ...:         "A": ["A4", "A5", "A6", "A7"],
   ...:         "B": ["B4", "B5", "B6", "B7"],
   ...:         "C": ["C4", "C5", "C6", "C7"],
   ...:         "D": ["D4", "D5", "D6", "D7"],
   ...:     },
   ...:     index=[4, 5, 6, 7],
   ...: )
   ...: 

In [3]: df3 = pd.DataFrame(
   ...:     {
   ...:         "A": ["A8", "A9", "A10", "A11"],
   ...:         "B": ["B8", "B9", "B10", "B11"],
   ...:         "C": ["C8", "C9", "C10", "C11"],
   ...:         "D": ["D8", "D9", "D10", "D11"],
   ...:     },
   ...:     index=[8, 9, 10, 11],
   ...: )
   ...: 

In [4]: frames = [df1, df2, df3]

In [5]: result = pd.concat(frames)

---->   pandas.DataFrame

--------------------------------------
ID: 2896 --> 1
In [8]: df4 = pd.DataFrame(
   ...:     {
   ...:         "B": ["B2", "B3", "B6", "B7"],
   ...:         "D": ["D2", "D3", "D6", "D7"],
   ...:         "F": ["F2", "F3", "F6", "F7"],
   ...:     },
   ...:     index=[2, 3, 6, 7],
   ...: )
   ...: 

In [9]: result = pd.concat([df1, df4], axis=1)

---->   pandas.DataFrame

--------------------------------------
ID: 2901 --> 1
In [14]: s1 = pd.Series(["X0", "X1", "X2", "X3"], name="X")

In [15]: result = pd.concat([df1, s1], axis=1)

---->   pandas.Series

--------------------------------------
ID: 2902 --> 1
In [16]: s2 = pd.Series(["_0", "_1", "_2", "_3"])

In [17]: result = pd.concat([df1, s2, s2, s2], axis=1)

---->   pandas.Series

--------------------------------------
ID: 2904 --> 1
In [19]: s3 = pd.Series([0, 1, 2, 3], name="foo")

In [20]: s4 = pd.Series([0, 1, 2, 3])

In [21]: s5 = pd.Series([0, 1, 4, 5])

In [22]: pd.concat([s3, s4, s5], axis=1)
Out[22]: 
   foo  0  1
0    0  0  0
1    1  1  1
2    2  2  4
3    3  3  5

---->   pandas.Series

--------------------------------------
ID: 2912 --> 2
In [31]: s2 = pd.Series(["X0", "X1", "X2", "X3"], index=["A", "B", "C", "D"])

In [32]: result = pd.concat([df1, s2.to_frame().T], ignore_index=True)

---->   pandas.Series; Series.to_frame

--------------------------------------
ID: 2914 --> 1
In [33]: left = pd.DataFrame(
   ....:     {
   ....:         "key": ["K0", "K1", "K2", "K3"],
   ....:         "A": ["A0", "A1", "A2", "A3"],
   ....:         "B": ["B0", "B1", "B2", "B3"],
   ....:     }
   ....: )
   ....: 

In [34]: right = pd.DataFrame(
   ....:     {
   ....:         "key": ["K0", "K1", "K2", "K3"],
   ....:         "C": ["C0", "C1", "C2", "C3"],
   ....:         "D": ["D0", "D1", "D2", "D3"],
   ....:     }
   ....: )
   ....: 

In [35]: result = pd.merge(left, right, on="key")

---->   pandas.DataFrame

--------------------------------------
ID: 2915 --> 1
In [36]: left = pd.DataFrame(
   ....:     {
   ....:         "key1": ["K0", "K0", "K1", "K2"],
   ....:         "key2": ["K0", "K1", "K0", "K1"],
   ....:         "A": ["A0", "A1", "A2", "A3"],
   ....:         "B": ["B0", "B1", "B2", "B3"],
   ....:     }
   ....: )
   ....: 

In [37]: right = pd.DataFrame(
   ....:     {
   ....:         "key1": ["K0", "K1", "K1", "K2"],
   ....:         "key2": ["K0", "K0", "K0", "K0"],
   ....:         "C": ["C0", "C1", "C2", "C3"],
   ....:         "D": ["D0", "D1", "D2", "D3"],
   ....:     }
   ....: )
   ....: 

In [38]: result = pd.merge(left, right, on=["key1", "key2"])

---->   pandas.DataFrame

--------------------------------------
ID: 2921 --> 3
In [44]: df = pd.DataFrame({"Let": ["A", "B", "C"], "Num": [1, 2, 3]})

In [45]: df
Out[45]: 
  Let  Num
0   A    1
1   B    2
2   C    3

In [46]: ser = pd.Series(
   ....:     ["a", "b", "c", "d", "e", "f"],
   ....:     index=pd.MultiIndex.from_arrays(
   ....:         [["A", "B", "C"] * 2, [1, 2, 3, 4, 5, 6]], names=["Let", "Num"]
   ....:     ),
   ....: )
   ....: 

In [47]: ser
Out[47]: 
Let  Num
A    1      a
B    2      b
C    3      c
A    4      d
B    5      e
C    6      f
dtype: object

In [48]: pd.merge(df, ser.reset_index(), on=["Let", "Num"])
Out[48]: 
  Let  Num  0
0   A    1  a
1   B    2  b
2   C    3  c

---->   pandas.DataFrame; pandas.Series; pandas.MultiIndex

--------------------------------------
ID: 2922 --> 1
In [49]: left = pd.DataFrame({"A": [1, 2], "B": [2, 2]})

In [50]: right = pd.DataFrame({"A": [4, 5, 6], "B": [2, 2, 2]})

In [51]: result = pd.merge(left, right, on="B", how="outer")

---->   pandas.DataFrame

--------------------------------------
ID: 2923 --> 1
In [52]: left = pd.DataFrame({"A": [1, 2], "B": [1, 2]})

In [53]: right = pd.DataFrame({"A": [4, 5, 6], "B": [2, 2, 2]})

---->   pandas.DataFrame

--------------------------------------
ID: 2926 --> 1
In [55]: df1 = pd.DataFrame({"col1": [0, 1], "col_left": ["a", "b"]})

In [56]: df2 = pd.DataFrame({"col1": [1, 2, 2], "col_right": [2, 2, 2]})

In [57]: pd.merge(df1, df2, on="col1", how="outer", indicator=True)
Out[57]: 
   col1 col_left  col_right      _merge
0     0        a        NaN   left_only
1     1        b        2.0        both
2     2      NaN        2.0  right_only
3     2      NaN        2.0  right_only

---->   pandas.DataFrame

--------------------------------------
ID: 2928 --> 1
In [59]: left = pd.DataFrame({"key": [1], "v1": [10]})

In [60]: left
Out[60]: 
   key  v1
0    1  10

In [61]: right = pd.DataFrame({"key": [1, 2], "v1": [20, 30]})

In [62]: right
Out[62]: 
   key  v1
0    1  20
1    2  30

---->   pandas.DataFrame

--------------------------------------
ID: 2931 --> 3
In [67]: from pandas.api.types import CategoricalDtype

In [68]: X = pd.Series(np.random.choice(["foo", "bar"], size=(10,)))

In [69]: X = X.astype(CategoricalDtype(categories=["foo", "bar"]))

In [70]: left = pd.DataFrame(
   ....:     {"X": X, "Y": np.random.choice(["one", "two", "three"], size=(10,))}
   ....: )
   ....: 

In [71]: left
Out[71]: 
     X      Y
0  bar    one
1  foo    one
2  foo  three
3  bar  three
4  foo    one
5  bar    one
6  bar  three
7  bar  three
8  bar  three
9  foo  three

In [72]: left.dtypes
Out[72]: 
X    category
Y      object
dtype: object

---->   pandas.Series; Series.astype; pandas.DataFrame

--------------------------------------
ID: 2932 --> 2
In [73]: right = pd.DataFrame(
   ....:     {
   ....:         "X": pd.Series(["foo", "bar"], dtype=CategoricalDtype(["foo", "bar"])),
   ....:         "Z": [1, 2],
   ....:     }
   ....: )
   ....: 

In [74]: right
Out[74]: 
     X  Z
0  foo  1
1  bar  2

In [75]: right.dtypes
Out[75]: 
X    category
Z       int64
dtype: object

---->   pandas.DataFrame; pandas.Series

--------------------------------------
ID: 2934 --> 2
In [79]: left = pd.DataFrame(
   ....:     {"A": ["A0", "A1", "A2"], "B": ["B0", "B1", "B2"]}, index=["K0", "K1", "K2"]
   ....: )
   ....: 

In [80]: right = pd.DataFrame(
   ....:     {"C": ["C0", "C2", "C3"], "D": ["D0", "D2", "D3"]}, index=["K0", "K2", "K3"]
   ....: )
   ....: 

In [81]: result = left.join(right)

---->   pandas.DataFrame; DataFrame.join

--------------------------------------
ID: 2935 --> 1
In [82]: result = left.join(right, how="outer")

---->   DataFrame.join

--------------------------------------
ID: 2936 --> 1
In [83]: result = left.join(right, how="inner")

---->   DataFrame.join

--------------------------------------
ID: 2939 --> 1
left.join(right, on=key_or_keys)
pd.merge(
    left, right, left_on=key_or_keys, right_index=True, how="left", sort=False
)

---->   DataFrame.join

--------------------------------------
ID: 2940 --> 2
In [86]: left = pd.DataFrame(
   ....:     {
   ....:         "A": ["A0", "A1", "A2", "A3"],
   ....:         "B": ["B0", "B1", "B2", "B3"],
   ....:         "key": ["K0", "K1", "K0", "K1"],
   ....:     }
   ....: )
   ....: 

In [87]: right = pd.DataFrame({"C": ["C0", "C1"], "D": ["D0", "D1"]}, index=["K0", "K1"])

In [88]: result = left.join(right, on="key")

---->   pandas.DataFrame; DataFrame.join

--------------------------------------
ID: 2942 --> 2
In [90]: left = pd.DataFrame(
   ....:     {
   ....:         "A": ["A0", "A1", "A2", "A3"],
   ....:         "B": ["B0", "B1", "B2", "B3"],
   ....:         "key1": ["K0", "K0", "K1", "K2"],
   ....:         "key2": ["K0", "K1", "K0", "K1"],
   ....:     }
   ....: )
   ....: 

In [91]: index = pd.MultiIndex.from_tuples(
   ....:     [("K0", "K0"), ("K1", "K0"), ("K2", "K0"), ("K2", "K1")]
   ....: )
   ....: 

In [92]: right = pd.DataFrame(
   ....:     {"C": ["C0", "C1", "C2", "C3"], "D": ["D0", "D1", "D2", "D3"]}, index=index
   ....: )
   ....: 

---->   pandas.DataFrame; pandas.MultiIndex

--------------------------------------
ID: 2943 --> 1
In [93]: result = left.join(right, on=["key1", "key2"])

---->   DataFrame.join

--------------------------------------
ID: 2944 --> 1
In [94]: result = left.join(right, on=["key1", "key2"], how="inner")

---->   DataFrame.join

--------------------------------------
ID: 2945 --> 4
In [95]: left = pd.DataFrame(
   ....:     {"A": ["A0", "A1", "A2"], "B": ["B0", "B1", "B2"]},
   ....:     index=pd.Index(["K0", "K1", "K2"], name="key"),
   ....: )
   ....: 

In [96]: index = pd.MultiIndex.from_tuples(
   ....:     [("K0", "Y0"), ("K1", "Y1"), ("K2", "Y2"), ("K2", "Y3")],
   ....:     names=["key", "Y"],
   ....: )
   ....: 

In [97]: right = pd.DataFrame(
   ....:     {"C": ["C0", "C1", "C2", "C3"], "D": ["D0", "D1", "D2", "D3"]},
   ....:     index=index,
   ....: )
   ....: 

In [98]: result = left.join(right, how="inner")

---->   pandas.DataFrame; pandas.Index; pandas.MultiIndex; DataFrame.join

--------------------------------------
ID: 2947 --> 3
In [100]: leftindex = pd.MultiIndex.from_product(
   .....:     [list("abc"), list("xy"), [1, 2]], names=["abc", "xy", "num"]
   .....: )
   .....: 

In [101]: left = pd.DataFrame({"v1": range(12)}, index=leftindex)

In [102]: left
Out[102]: 
            v1
abc xy num    
a   x  1     0
       2     1
    y  1     2
       2     3
b   x  1     4
       2     5
    y  1     6
       2     7
c   x  1     8
       2     9
    y  1    10
       2    11

In [103]: rightindex = pd.MultiIndex.from_product(
   .....:     [list("abc"), list("xy")], names=["abc", "xy"]
   .....: )
   .....: 

In [104]: right = pd.DataFrame({"v2": [100 * i for i in range(1, 7)]}, index=rightindex)

In [105]: right
Out[105]: 
         v2
abc xy     
a   x   100
    y   200
b   x   300
    y   400
c   x   500
    y   600

In [106]: left.join(right, on=["abc", "xy"], how="inner")
Out[106]: 
            v1   v2
abc xy num         
a   x  1     0  100
       2     1  100
    y  1     2  200
       2     3  200
b   x  1     4  300
       2     5  300
    y  1     6  400
       2     7  400
c   x  1     8  500
       2     9  500
    y  1    10  600
       2    11  600

---->   pandas.MultiIndex; pandas.DataFrame; DataFrame.join

--------------------------------------
ID: 2948 --> 2
In [107]: leftindex = pd.MultiIndex.from_tuples(
   .....:     [("K0", "X0"), ("K0", "X1"), ("K1", "X2")], names=["key", "X"]
   .....: )
   .....: 

In [108]: left = pd.DataFrame(
   .....:     {"A": ["A0", "A1", "A2"], "B": ["B0", "B1", "B2"]}, index=leftindex
   .....: )
   .....: 

In [109]: rightindex = pd.MultiIndex.from_tuples(
   .....:     [("K0", "Y0"), ("K1", "Y1"), ("K2", "Y2"), ("K2", "Y3")], names=["key", "Y"]
   .....: )
   .....: 

In [110]: right = pd.DataFrame(
   .....:     {"C": ["C0", "C1", "C2", "C3"], "D": ["D0", "D1", "D2", "D3"]}, index=rightindex
   .....: )
   .....: 

In [111]: result = pd.merge(
   .....:     left.reset_index(), right.reset_index(), on=["key"], how="inner"
   .....: ).set_index(["key", "X", "Y"])
   .....: 

---->   pandas.MultiIndex; pandas.DataFrame

--------------------------------------
ID: 2949 --> 2
In [112]: left_index = pd.Index(["K0", "K0", "K1", "K2"], name="key1")

In [113]: left = pd.DataFrame(
   .....:     {
   .....:         "A": ["A0", "A1", "A2", "A3"],
   .....:         "B": ["B0", "B1", "B2", "B3"],
   .....:         "key2": ["K0", "K1", "K0", "K1"],
   .....:     },
   .....:     index=left_index,
   .....: )
   .....: 

In [114]: right_index = pd.Index(["K0", "K1", "K2", "K2"], name="key1")

In [115]: right = pd.DataFrame(
   .....:     {
   .....:         "C": ["C0", "C1", "C2", "C3"],
   .....:         "D": ["D0", "D1", "D2", "D3"],
   .....:         "key2": ["K0", "K0", "K0", "K1"],
   .....:     },
   .....:     index=right_index,
   .....: )
   .....: 

In [116]: result = left.merge(right, on=["key1", "key2"])

---->   pandas.Index; pandas.DataFrame

--------------------------------------
ID: 2950 --> 1
In [117]: left = pd.DataFrame({"k": ["K0", "K1", "K2"], "v": [1, 2, 3]})

In [118]: right = pd.DataFrame({"k": ["K0", "K0", "K3"], "v": [4, 5, 6]})

In [119]: result = pd.merge(left, right, on="k")

---->   pandas.DataFrame

--------------------------------------
ID: 2952 --> 1
In [121]: left = left.set_index("k")

In [122]: right = right.set_index("k")

In [123]: result = left.join(right, lsuffix="_l", rsuffix="_r")

---->   DataFrame.join

--------------------------------------
ID: 2953 --> 2
In [124]: right2 = pd.DataFrame({"v": [7, 8, 9]}, index=["K1", "K1", "K2"])

In [125]: result = left.join([right, right2])

---->   pandas.DataFrame; DataFrame.join

--------------------------------------
ID: 2954 --> 1
In [126]: df1 = pd.DataFrame(
   .....:     [[np.nan, 3.0, 5.0], [-4.6, np.nan, np.nan], [np.nan, 7.0, np.nan]]
   .....: )
   .....: 

In [127]: df2 = pd.DataFrame([[-42.6, np.nan, -8.2], [-5.0, 1.6, 4]], index=[1, 2])

---->   pandas.DataFrame

--------------------------------------
ID: 2955 --> 1
In [128]: result = df1.combine_first(df2)

---->   DataFrame.combine_first

--------------------------------------
ID: 2956 --> 1
In [129]: df1.update(df2)

---->   DataFrame.update

--------------------------------------
ID: 2957 --> 1
In [130]: left = pd.DataFrame(
   .....:     {"k": ["K0", "K1", "K1", "K2"], "lv": [1, 2, 3, 4], "s": ["a", "b", "c", "d"]}
   .....: )
   .....: 

In [131]: right = pd.DataFrame({"k": ["K1", "K2", "K4"], "rv": [1, 2, 3]})

In [132]: pd.merge_ordered(left, right, fill_method="ffill", left_by="s")
Out[132]: 
     k   lv  s   rv
0   K0  1.0  a  NaN
1   K1  1.0  a  1.0
2   K2  1.0  a  2.0
3   K4  1.0  a  3.0
4   K1  2.0  b  1.0
5   K2  2.0  b  2.0
6   K4  2.0  b  3.0
7   K1  3.0  c  1.0
8   K2  3.0  c  2.0
9   K4  3.0  c  3.0
10  K1  NaN  d  1.0
11  K2  4.0  d  2.0
12  K4  4.0  d  3.0

---->   pandas.DataFrame

--------------------------------------
ID: 2958 --> 2
In [133]: trades = pd.DataFrame(
   .....:     {
   .....:         "time": pd.to_datetime(
   .....:             [
   .....:                 "20160525 13:30:00.023",
   .....:                 "20160525 13:30:00.038",
   .....:                 "20160525 13:30:00.048",
   .....:                 "20160525 13:30:00.048",
   .....:                 "20160525 13:30:00.048",
   .....:             ]
   .....:         ),
   .....:         "ticker": ["MSFT", "MSFT", "GOOG", "GOOG", "AAPL"],
   .....:         "price": [51.95, 51.95, 720.77, 720.92, 98.00],
   .....:         "quantity": [75, 155, 100, 100, 100],
   .....:     },
   .....:     columns=["time", "ticker", "price", "quantity"],
   .....: )
   .....: 

In [134]: quotes = pd.DataFrame(
   .....:     {
   .....:         "time": pd.to_datetime(
   .....:             [
   .....:                 "20160525 13:30:00.023",
   .....:                 "20160525 13:30:00.023",
   .....:                 "20160525 13:30:00.030",
   .....:                 "20160525 13:30:00.041",
   .....:                 "20160525 13:30:00.048",
   .....:                 "20160525 13:30:00.049",
   .....:                 "20160525 13:30:00.072",
   .....:                 "20160525 13:30:00.075",
   .....:             ]
   .....:         ),
   .....:         "ticker": ["GOOG", "MSFT", "MSFT", "MSFT", "GOOG", "AAPL", "GOOG", "MSFT"],
   .....:         "bid": [720.50, 51.95, 51.97, 51.99, 720.50, 97.99, 720.50, 52.01],
   .....:         "ask": [720.93, 51.96, 51.98, 52.00, 720.93, 98.01, 720.88, 52.03],
   .....:     },
   .....:     columns=["time", "ticker", "bid", "ask"],
   .....: )
   .....: 

---->   pandas.DataFrame; pandas.to_datetime

--------------------------------------
ID: 2962 --> 1
In [140]: df = pd.DataFrame(
   .....:     {
   .....:         "col1": ["a", "a", "b", "b", "a"],
   .....:         "col2": [1.0, 2.0, 3.0, np.nan, 5.0],
   .....:         "col3": [1.0, 2.0, 3.0, 4.0, 5.0],
   .....:     },
   .....:     columns=["col1", "col2", "col3"],
   .....: )
   .....: 

In [141]: df
Out[141]: 
  col1  col2  col3
0    a   1.0   1.0
1    a   2.0   2.0
2    b   3.0   3.0
3    b   NaN   4.0
4    a   5.0   5.0

---->   pandas.DataFrame

--------------------------------------
ID: 2963 --> 1
In [142]: df2 = df.copy()

In [143]: df2.loc[0, "col1"] = "c"

In [144]: df2.loc[2, "col3"] = 4.0

In [145]: df2
Out[145]: 
  col1  col2  col3
0    c   1.0   1.0
1    a   2.0   2.0
2    b   3.0   4.0
3    b   NaN   4.0
4    a   5.0   5.0

---->   DataFrame.copy

--------------------------------------
ID: 2968 --> 1
import pandas as pd
import numpy as np
import matplotlib as mpl

df = pd.DataFrame({
    "strings": ["Adam", "Mike"],
    "ints": [1, 3],
    "floats": [1.123, 1000.23]
})
df.style \
  .format(precision=3, thousands=".", decimal=",") \
  .format_index(str.upper, axis=1) \
  .relabel_index(["row 1", "row 2"], axis=0)

---->   pandas.DataFrame

--------------------------------------
ID: 2969 --> 1
weather_df = pd.DataFrame(np.random.rand(10,2)*5,
                          index=pd.date_range(start="2021-01-01", periods=10),
                          columns=["Tokyo", "Beijing"])

def rain_condition(v):
    if v < 1.75:
        return "Dry"
    elif v < 2.75:
        return "Rain"
    return "Heavy Rain"

def make_pretty(styler):
    styler.set_caption("Weather Conditions")
    styler.format(rain_condition)
    styler.format_index(lambda v: v.strftime("%A"))
    styler.background_gradient(axis=None, vmin=1, vmax=5, cmap="YlGnBu")
    return styler

weather_df

---->   pandas.DataFrame

--------------------------------------
ID: 2971 --> 1
df = pd.DataFrame(np.random.randn(5, 5))
df.style \
  .hide(subset=[0, 2, 4], axis=0) \
  .hide(subset=[0, 2, 4], axis=1)

---->   pandas.DataFrame

--------------------------------------
ID: 2973 --> 1
summary_styler = df.agg(["sum", "mean"]).style \
                   .format(precision=3) \
                   .relabel_index(["Sum", "Average"])
df.style.format(precision=1).concat(summary_styler)

---->   DataFrame.agg

--------------------------------------
ID: 2974 --> 3
df = pd.DataFrame([[38.0, 2.0, 18.0, 22.0, 21, np.nan],[19, 439, 6, 452, 226,232]],
                  index=pd.Index(['Tumour (Positive)', 'Non-Tumour (Negative)'], name='Actual Label:'),
                  columns=pd.MultiIndex.from_product([['Decision Tree', 'Regression', 'Random'],['Tumour', 'Non-Tumour']], names=['Model:', 'Predicted:']))
df.style

---->   pandas.DataFrame; pandas.Index; pandas.MultiIndex

--------------------------------------
ID: 2980 --> 1
s.set_table_styles([  # create internal CSS classes
    {'selector': '.true', 'props': 'background-color: #e6ffe6;'},
    {'selector': '.false', 'props': 'background-color: #ffe6e6;'},
], overwrite=False)
cell_color = pd.DataFrame([['true ', 'false ', 'true ', 'false '],
                           ['false ', 'true ', 'false ', 'true ']],
                          index=df.index,
                          columns=df.columns[:4])
s.set_td_classes(cell_color)

---->   pandas.DataFrame

--------------------------------------
ID: 2981 --> 1
np.random.seed(0)
df2 = pd.DataFrame(np.random.randn(10,4), columns=['A','B','C','D'])
df2.style

---->   pandas.DataFrame

--------------------------------------
ID: 2985 --> 1
s2.applymap_index(lambda v: "color:pink;" if v>4 else "color:darkblue;", axis=0)
s2.apply_index(lambda s: np.where(s.isin(["A", "B"]), "color:pink;", "color:darkblue;"), axis=1)

---->   Series.isin

--------------------------------------
ID: 2987 --> 1
tt = pd.DataFrame([['This model has a very strong true positive rate',
                    "This model's total number of false negatives is too high"]],
                  index=['Tumour (Positive)'], columns=df.columns[[0,3]])
s.set_tooltips(tt, props='visibility: hidden; position: absolute; z-index: 1; border: 1px solid #000066;'
                         'background-color: white; color: #000066; font-size: 0.8em;'
                         'transform: translate(0px, -24px); padding: 0.6em; border-radius: 0.5em;')

---->   pandas.DataFrame

--------------------------------------
ID: 2988 --> 1
s.set_table_styles([  # create internal CSS classes
    {'selector': '.border-red', 'props': 'border: 2px dashed red;'},
    {'selector': '.border-green', 'props': 'border: 2px dashed green;'},
], overwrite=False)
cell_border = pd.DataFrame([['border-green ', ' ', ' ', 'border-red '],
                           [' ', ' ', ' ', ' ']],
                          index=df.index,
                          columns=df.columns[:4])
s.set_td_classes(cell_color + cell_border)

---->   pandas.DataFrame

--------------------------------------
ID: 2989 --> 2
df3 = pd.DataFrame(np.random.randn(4,4),
                   pd.MultiIndex.from_product([['A', 'B'], ['r1', 'r2']]),
                   columns=['c1','c2','c3','c4'])
df3

---->   pandas.DataFrame; pandas.MultiIndex

--------------------------------------
ID: 2995 --> 1
df4 = pd.DataFrame([[1,2],[3,4]])
s4 = df4.style

---->   pandas.DataFrame

--------------------------------------
ID: 3000 --> 1
build = lambda x: pd.DataFrame(x, index=df2.index, columns=df2.columns)
cls1 = build(df2.apply(highlight_max, props='cls-1 ', axis=0))
cls2 = build(df2.apply(highlight_max, props='cls-2 ', axis=1, result_type='expand').values)
cls3 = build(highlight_max(df2, props='cls-3 '))
df2.style.set_table_styles([
    {'selector': '.cls-1', 'props': 'color:white;background-color:darkblue;'},
    {'selector': '.cls-2', 'props': 'color:white;background-color:pink;'},
    {'selector': '.cls-3', 'props': 'color:white;background-color:purple;'}
]).set_td_classes(cls1 + cls2 + cls3)

---->   pandas.DataFrame

--------------------------------------
ID: 3004 --> 1
left = pd.Series([1.0, 0.0, 1.0], index=["A", "B", "D"])
df2.loc[:4].style.highlight_between(left=left, right=1.5, axis=1, props='color:white; background-color:purple;')

---->   pandas.Series

--------------------------------------
ID: 3016 --> 1
np.random.seed(25)
cmap = cmap=sns.diverging_palette(5, 250, as_cmap=True)
bigdf = pd.DataFrame(np.random.randn(20, 25)).cumsum()

bigdf.style.background_gradient(cmap, axis=1)\
    .set_properties(**{'max-width': '80px', 'font-size': '1pt'})\
    .set_caption("Hover to magnify")\
    .format(precision=2)\
    .set_table_styles(magnify())

---->   pandas.DataFrame

--------------------------------------
ID: 3017 --> 1
bigdf = pd.DataFrame(np.random.randn(16, 100))
bigdf.style.set_sticky(axis="index")

---->   pandas.DataFrame

--------------------------------------
ID: 3018 --> 1
bigdf.index = pd.MultiIndex.from_product([["A","B"],[0,1],[0,1,2,3]])
bigdf.style.set_sticky(axis="index", pixel_size=18, levels=[1,2])

---->   pandas.MultiIndex

--------------------------------------
ID: 3019 --> 1
df4 = pd.DataFrame([['', '"&other"', '']])
df4.style

---->   pandas.DataFrame

--------------------------------------
ID: 3023 --> 1
print(pd.DataFrame([[1,2],[3,4]], index=['i1', 'i2'], columns=['c1', 'c2']).style.to_html())

---->   pandas.DataFrame

--------------------------------------
ID: 3024 --> 1
df4 = pd.DataFrame([['text']])
df4.style.applymap(lambda x: 'color:green;')\
         .applymap(lambda x: 'color:red;')

---->   pandas.DataFrame

--------------------------------------
ID: 3027 --> 1
df4.style.set_uuid('b_')\
         .set_table_styles([{'selector': 'td', 'props': 'color:red;'},
                            {'selector': '.cls-1', 'props': 'color:blue;'}])\
         .applymap(lambda x: 'color:green;')\
         .set_td_classes(pd.DataFrame([['cls-1']]))

---->   pandas.DataFrame

--------------------------------------
ID: 3028 --> 1
df4.style.set_uuid('c_')\
         .set_table_styles([{'selector': 'td', 'props': 'color:red;'},
                            {'selector': '.cls-1', 'props': 'color:blue;'},
                            {'selector': 'td.data', 'props': 'color:yellow;'}])\
         .applymap(lambda x: 'color:green;')\
         .set_td_classes(pd.DataFrame([['cls-1']]))

---->   pandas.DataFrame

--------------------------------------
ID: 3029 --> 1
df4.style.set_uuid('d_')\
         .set_table_styles([{'selector': 'td', 'props': 'color:red;'},
                            {'selector': '.cls-1', 'props': 'color:blue;'},
                            {'selector': 'td.data', 'props': 'color:yellow;'}])\
         .applymap(lambda x: 'color:green !important;')\
         .set_td_classes(pd.DataFrame([['cls-1']]))

---->   pandas.DataFrame

--------------------------------------
ID: 3042 --> 1
In [21]: df2 = pd.read_csv(StringIO(data))

In [22]: df2["col_1"] = pd.to_numeric(df2["col_1"], errors="coerce")

In [23]: df2
Out[23]: 
   col_1
0   1.00
1   2.00
2    NaN
3   4.22

In [24]: df2["col_1"].apply(type).value_counts()
Out[24]: 
col_1
    4
Name: count, dtype: int64

---->   pandas.to_numeric

--------------------------------------
ID: 3043 --> 2
In [25]: col_1 = list(range(500000)) + ["a", "b"] + list(range(500000))

In [26]: df = pd.DataFrame({"col_1": col_1})

In [27]: df.to_csv("foo.csv")

In [28]: mixed_df = pd.read_csv("foo.csv")

In [29]: mixed_df["col_1"].apply(type).value_counts()
Out[29]: 
col_1
    737858
    262144
Name: count, dtype: int64

In [30]: mixed_df["col_1"].dtype
Out[30]: dtype('O')

---->   pandas.DataFrame; DataFrame.to_csv

--------------------------------------
ID: 3049 --> 1
In [45]: df = pd.read_csv(StringIO(data), dtype="category")

In [46]: df.dtypes
Out[46]: 
col1    category
col2    category
col3    category
dtype: object

In [47]: df["col3"]
Out[47]: 
0    1
1    2
2    3
Name: col3, dtype: category
Categories (3, object): ['1', '2', '3']

In [48]: new_categories = pd.to_numeric(df["col3"].cat.categories)

In [49]: df["col3"] = df["col3"].cat.rename_categories(new_categories)

In [50]: df["col3"]
Out[50]: 
0    1
1    2
2    3
Name: col3, dtype: category
Categories (3, int64): [1, 2, 3]

---->   pandas.to_numeric

--------------------------------------
ID: 3074 --> 1
In [121]: df = pd.read_csv(StringIO(content))

In [122]: df["a"] = pd.to_datetime(df["a"], utc=True)

In [123]: df["a"]
Out[123]: 
0   1999-12-31 19:00:00+00:00
1   1999-12-31 18:00:00+00:00
Name: a, dtype: datetime64[ns, UTC]

---->   pandas.to_datetime

--------------------------------------
ID: 3076 --> 1
In [126]: data = io.StringIO("date\n12 Jan 2000\n2000-01-13\n")

In [127]: df = pd.read_csv(data)

In [128]: df['date'] = pd.to_datetime(df['date'], format='mixed')

In [129]: df
Out[129]: 
        date
0 2000-01-12
1 2000-01-13

---->   pandas.to_datetime

--------------------------------------
ID: 3077 --> 1
In [130]: data = io.StringIO("date\n2020-01-01\n2020-01-01 03:00\n")

In [131]: df = pd.read_csv(data)

In [132]: df['date'] = pd.to_datetime(df['date'], format='ISO8601')

In [133]: df
Out[133]: 
                 date
0 2020-01-01 00:00:00
1 2020-01-01 03:00:00

---->   pandas.to_datetime

--------------------------------------
ID: 3079 --> 2
In [139]: import io

In [140]: data = pd.DataFrame([0, 1, 2])

In [141]: buffer = io.BytesIO()

In [142]: data.to_csv(buffer, encoding="utf-8", compression="gzip")

---->   pandas.DataFrame; DataFrame.to_csv

--------------------------------------
ID: 3109 --> 1
In [200]: from pandas._testing import makeCustomDataframe as mkdf

In [201]: df = mkdf(5, 3, r_idx_nlevels=2, c_idx_nlevels=4)

In [202]: df.to_csv("mi.csv")

In [203]: print(open("mi.csv").read())
C0,,C_l0_g0,C_l0_g1,C_l0_g2
C1,,C_l1_g0,C_l1_g1,C_l1_g2
C2,,C_l2_g0,C_l2_g1,C_l2_g2
C3,,C_l3_g0,C_l3_g1,C_l3_g2
R0,R1,,,
R_l0_g0,R_l1_g0,R0C0,R0C1,R0C2
R_l0_g1,R_l1_g1,R1C0,R1C1,R1C2
R_l0_g2,R_l1_g2,R2C0,R2C1,R2C2
R_l0_g3,R_l1_g3,R3C0,R3C1,R3C2
R_l0_g4,R_l1_g4,R4C0,R4C1,R4C2


In [204]: pd.read_csv("mi.csv", header=[0, 1, 2, 3], index_col=[0, 1])
Out[204]: 
C0              C_l0_g0 C_l0_g1 C_l0_g2
C1              C_l1_g0 C_l1_g1 C_l1_g2
C2              C_l2_g0 C_l2_g1 C_l2_g2
C3              C_l3_g0 C_l3_g1 C_l3_g2
R0      R1                             
R_l0_g0 R_l1_g0    R0C0    R0C1    R0C2
R_l0_g1 R_l1_g1    R1C0    R1C1    R1C2
R_l0_g2 R_l1_g2    R2C0    R2C1    R2C2
R_l0_g3 R_l1_g3    R3C0    R3C1    R3C2
R_l0_g4 R_l1_g4    R4C0    R4C1    R4C2

---->   DataFrame.to_csv

--------------------------------------
ID: 3111 --> 2
In [209]: df = pd.DataFrame(np.random.randn(10, 4))

In [210]: df.to_csv("tmp.csv", sep="|")

In [211]: df.to_csv("tmp2.csv", sep=":")

In [212]: pd.read_csv("tmp2.csv", sep=None, engine="python")
Out[212]: 
   Unnamed: 0         0         1         2         3
0           0  0.469112 -0.282863 -1.509059 -1.135632
1           1  1.212112 -0.173215  0.119209 -1.044236
2           2 -0.861849 -2.104569 -0.494929  1.071804
3           3  0.721555 -0.706771 -1.039575  0.271860
4           4 -0.424972  0.567020  0.276232 -1.087401
5           5 -0.673690  0.113648 -1.478427  0.524988
6           6  0.404705  0.577046 -1.715002 -1.039268
7           7 -0.370647 -1.157892 -1.344312  0.844885
8           8  1.075770 -0.109050  1.643563 -1.469388
9           9  0.357021 -0.674600 -1.776904 -0.968914

---->   pandas.DataFrame; DataFrame.to_csv

--------------------------------------
ID: 3112 --> 2
In [213]: df = pd.DataFrame(np.random.randn(10, 4))

In [214]: df.to_csv("tmp.csv", sep="|")

In [215]: table = pd.read_csv("tmp.csv", sep="|")

In [216]: table
Out[216]: 
   Unnamed: 0         0         1         2         3
0           0 -1.294524  0.413738  0.276662 -0.472035
1           1 -0.013960 -0.362543 -0.006154 -0.923061
2           2  0.895717  0.805244 -1.206412  2.565646
3           3  1.431256  1.340309 -1.170299 -0.226169
4           4  0.410835  0.813850  0.132003 -0.827317
5           5 -0.076467 -1.187678  1.130127 -1.436737
6           6 -1.413681  1.607920  1.024180  0.569605
7           7  0.875906 -2.211372  0.974466 -2.006747
8           8 -0.410001 -0.078638  0.545952 -1.219217
9           9 -1.226825  0.769804 -1.281247 -0.727707

---->   pandas.DataFrame; DataFrame.to_csv

--------------------------------------
ID: 3120 --> 2
In [219]: dfj = pd.DataFrame(np.random.randn(5, 2), columns=list("AB"))

In [220]: json = dfj.to_json()

In [221]: json
Out[221]: '{"A":{"0":-0.1213062281,"1":0.6957746499,"2":0.9597255933,"3":-0.6199759194,"4":-0.7323393705},"B":{"0":-0.0978826728,"1":0.3417343559,"2":-1.1103361029,"3":0.1497483186,"4":0.6877383895}}'

---->   pandas.DataFrame; DataFrame.to_json

--------------------------------------
ID: 3121 --> 2
In [222]: dfjo = pd.DataFrame(
   .....:     dict(A=range(1, 4), B=range(4, 7), C=range(7, 10)),
   .....:     columns=list("ABC"),
   .....:     index=list("xyz"),
   .....: )
   .....: 

In [223]: dfjo
Out[223]: 
   A  B  C
x  1  4  7
y  2  5  8
z  3  6  9

In [224]: sjo = pd.Series(dict(x=15, y=16, z=17), name="D")

In [225]: sjo
Out[225]: 
x    15
y    16
z    17
Name: D, dtype: int64

---->   pandas.DataFrame; pandas.Series

--------------------------------------
ID: 3123 --> 1
In [227]: dfjo.to_json(orient="index")
Out[227]: '{"x":{"A":1,"B":4,"C":7},"y":{"A":2,"B":5,"C":8},"z":{"A":3,"B":6,"C":9}}'

In [228]: sjo.to_json(orient="index")
Out[228]: '{"x":15,"y":16,"z":17}'

---->   Series.to_json

--------------------------------------
ID: 3124 --> 1
In [229]: dfjo.to_json(orient="records")
Out[229]: '[{"A":1,"B":4,"C":7},{"A":2,"B":5,"C":8},{"A":3,"B":6,"C":9}]'

In [230]: sjo.to_json(orient="records")
Out[230]: '[15,16,17]'

---->   Series.to_json

--------------------------------------
ID: 3126 --> 1
In [232]: dfjo.to_json(orient="split")
Out[232]: '{"columns":["A","B","C"],"index":["x","y","z"],"data":[[1,4,7],[2,5,8],[3,6,9]]}'

In [233]: sjo.to_json(orient="split")
Out[233]: '{"name":"D","index":["x","y","z"],"data":[15,16,17]}'

---->   Series.to_json

--------------------------------------
ID: 3127 --> 2
In [234]: dfd = pd.DataFrame(np.random.randn(5, 2), columns=list("AB"))

In [235]: dfd["date"] = pd.Timestamp("20130101")

In [236]: dfd = dfd.sort_index(axis=1, ascending=False)

In [237]: json = dfd.to_json(date_format="iso")

In [238]: json
Out[238]: '{"date":{"0":"2013-01-01T00:00:00.000","1":"2013-01-01T00:00:00.000","2":"2013-01-01T00:00:00.000","3":"2013-01-01T00:00:00.000","4":"2013-01-01T00:00:00.000"},"B":{"0":0.403309524,"1":0.3016244523,"2":-1.3698493577,"3":1.4626960492,"4":-0.8265909164},"A":{"0":0.1764443426,"1":-0.1549507744,"2":-2.1798606054,"3":-0.9542078401,"4":-1.7431609117}}'

---->   pandas.DataFrame; DataFrame.to_json

--------------------------------------
ID: 3128 --> 1
In [239]: json = dfd.to_json(date_format="iso", date_unit="us")

In [240]: json
Out[240]: '{"date":{"0":"2013-01-01T00:00:00.000000","1":"2013-01-01T00:00:00.000000","2":"2013-01-01T00:00:00.000000","3":"2013-01-01T00:00:00.000000","4":"2013-01-01T00:00:00.000000"},"B":{"0":0.403309524,"1":0.3016244523,"2":-1.3698493577,"3":1.4626960492,"4":-0.8265909164},"A":{"0":0.1764443426,"1":-0.1549507744,"2":-2.1798606054,"3":-0.9542078401,"4":-1.7431609117}}'

---->   DataFrame.to_json

--------------------------------------
ID: 3129 --> 1
In [241]: json = dfd.to_json(date_format="epoch", date_unit="s")

In [242]: json
Out[242]: '{"date":{"0":1356998400,"1":1356998400,"2":1356998400,"3":1356998400,"4":1356998400},"B":{"0":0.403309524,"1":0.3016244523,"2":-1.3698493577,"3":1.4626960492,"4":-0.8265909164},"A":{"0":0.1764443426,"1":-0.1549507744,"2":-2.1798606054,"3":-0.9542078401,"4":-1.7431609117}}'

---->   DataFrame.to_json

--------------------------------------
ID: 3130 --> 1
In [243]: dfj2 = dfj.copy()

In [244]: dfj2["date"] = pd.Timestamp("20130101")

In [245]: dfj2["ints"] = list(range(5))

In [246]: dfj2["bools"] = True

In [247]: dfj2.index = pd.date_range("20130101", periods=5)

In [248]: dfj2.to_json("test.json")

In [249]: with open("test.json") as fh:
   .....:     print(fh.read())
   .....: 
{"A":{"1356998400000":-0.1213062281,"1357084800000":0.6957746499,"1357171200000":0.9597255933,"1357257600000":-0.6199759194,"1357344000000":-0.7323393705},"B":{"1356998400000":-0.0978826728,"1357084800000":0.3417343559,"1357171200000":-1.1103361029,"1357257600000":0.1497483186,"1357344000000":0.6877383895},"date":{"1356998400000":1356998400000,"1357084800000":1356998400000,"1357171200000":1356998400000,"1357257600000":1356998400000,"1357344000000":1356998400000},"ints":{"1356998400000":0,"1357084800000":1,"1357171200000":2,"1357257600000":3,"1357344000000":4},"bools":{"1356998400000":true,"1357084800000":true,"1357171200000":true,"1357257600000":true,"1357344000000":true}}

---->   DataFrame.copy

--------------------------------------
ID: 3132 --> 1
In [250]: pd.DataFrame([1.0, 2.0, complex(1.0, 2.0)]).to_json(default_handler=str)
Out[250]: '{"0":{"0":"(1+0j)","1":"(2+0j)","2":"(1+2j)"}}'

---->   pandas.DataFrame

--------------------------------------
ID: 3137 --> 1
In [255]: si = pd.DataFrame(
   .....:     np.zeros((4, 4)), columns=list(range(4)), index=[str(i) for i in range(4)]
   .....: )
   .....: 

In [256]: si
Out[256]: 
     0    1    2    3
0  0.0  0.0  0.0  0.0
1  0.0  0.0  0.0  0.0
2  0.0  0.0  0.0  0.0
3  0.0  0.0  0.0  0.0

In [257]: si.index
Out[257]: Index(['0', '1', '2', '3'], dtype='object')

In [258]: si.columns
Out[258]: Index([0, 1, 2, 3], dtype='int64')

In [259]: json = si.to_json()

In [260]: sij = pd.read_json(json, convert_axes=False)

In [261]: sij
Out[261]: 
   0  1  2  3
0  0  0  0  0
1  0  0  0  0
2  0  0  0  0
3  0  0  0  0

In [262]: sij.index
Out[262]: Index(['0', '1', '2', '3'], dtype='object')

In [263]: sij.columns
Out[263]: Index(['0', '1', '2', '3'], dtype='object')

---->   pandas.DataFrame

--------------------------------------
ID: 3139 --> 1
In [271]: data = [
   .....:     {"id": 1, "name": {"first": "Coleen", "last": "Volk"}},
   .....:     {"name": {"given": "Mark", "family": "Regner"}},
   .....:     {"id": 2, "name": "Faye Raker"},
   .....: ]
   .....: 

In [272]: pd.json_normalize(data)
Out[272]: 
    id name.first name.last name.given name.family        name
0  1.0     Coleen      Volk        NaN         NaN         NaN
1  NaN        NaN       NaN       Mark      Regner         NaN
2  2.0        NaN       NaN        NaN         NaN  Faye Raker

---->   pandas.json_normalize

--------------------------------------
ID: 3140 --> 1
In [273]: data = [
   .....:     {
   .....:         "state": "Florida",
   .....:         "shortname": "FL",
   .....:         "info": {"governor": "Rick Scott"},
   .....:         "county": [
   .....:             {"name": "Dade", "population": 12345},
   .....:             {"name": "Broward", "population": 40000},
   .....:             {"name": "Palm Beach", "population": 60000},
   .....:         ],
   .....:     },
   .....:     {
   .....:         "state": "Ohio",
   .....:         "shortname": "OH",
   .....:         "info": {"governor": "John Kasich"},
   .....:         "county": [
   .....:             {"name": "Summit", "population": 1234},
   .....:             {"name": "Cuyahoga", "population": 1337},
   .....:         ],
   .....:     },
   .....: ]
   .....: 

In [274]: pd.json_normalize(data, "county", ["state", "shortname", ["info", "governor"]])
Out[274]: 
         name  population    state shortname info.governor
0        Dade       12345  Florida        FL    Rick Scott
1     Broward       40000  Florida        FL    Rick Scott
2  Palm Beach       60000  Florida        FL    Rick Scott
3      Summit        1234     Ohio        OH   John Kasich
4    Cuyahoga        1337     Ohio        OH   John Kasich

---->   pandas.json_normalize

--------------------------------------
ID: 3141 --> 1
In [275]: data = [
   .....:     {
   .....:         "CreatedBy": {"Name": "User001"},
   .....:         "Lookup": {
   .....:             "TextField": "Some text",
   .....:             "UserField": {"Id": "ID001", "Name": "Name001"},
   .....:         },
   .....:         "Image": {"a": "b"},
   .....:     }
   .....: ]
   .....: 

In [276]: pd.json_normalize(data, max_level=1)
Out[276]: 
  CreatedBy.Name Lookup.TextField                    Lookup.UserField Image.a
0        User001        Some text  {'Id': 'ID001', 'Name': 'Name001'}       b

---->   pandas.json_normalize

--------------------------------------
ID: 3142 --> 1
In [277]: jsonl = """
   .....:     {"a": 1, "b": 2}
   .....:     {"a": 3, "b": 4}
   .....: """
   .....: 

In [278]: df = pd.read_json(jsonl, lines=True)

In [279]: df
Out[279]: 
   a  b
0  1  2
1  3  4

In [280]: df.to_json(orient="records", lines=True)
Out[280]: '{"a":1,"b":2}\n{"a":3,"b":4}\n'

# reader is an iterator that returns ``chunksize`` lines each iteration
In [281]: with pd.read_json(StringIO(jsonl), lines=True, chunksize=1) as reader:
   .....:     reader
   .....:     for chunk in reader:
   .....:         print(chunk)
   .....: 
Empty DataFrame
Columns: []
Index: []
   a  b
0  1  2
   a  b
1  3  4

---->   DataFrame.to_json

--------------------------------------
ID: 3144 --> 3
In [285]: df = pd.DataFrame(
   .....:     {
   .....:         "A": [1, 2, 3],
   .....:         "B": ["a", "b", "c"],
   .....:         "C": pd.date_range("2016-01-01", freq="d", periods=3),
   .....:     },
   .....:     index=pd.Index(range(3), name="idx"),
   .....: )
   .....: 

In [286]: df
Out[286]: 
     A  B          C
idx                 
0    1  a 2016-01-01
1    2  b 2016-01-02
2    3  c 2016-01-03

In [287]: df.to_json(orient="table", date_format="iso")
Out[287]: '{"schema":{"fields":[{"name":"idx","type":"integer"},{"name":"A","type":"integer"},{"name":"B","type":"string"},{"name":"C","type":"datetime"}],"primaryKey":["idx"],"pandas_version":"1.4.0"},"data":[{"idx":0,"A":1,"B":"a","C":"2016-01-01T00:00:00.000"},{"idx":1,"A":2,"B":"b","C":"2016-01-02T00:00:00.000"},{"idx":2,"A":3,"B":"c","C":"2016-01-03T00:00:00.000"}]}'

---->   pandas.DataFrame; pandas.Index; DataFrame.to_json

--------------------------------------
ID: 3145 --> 1
In [288]: from pandas.io.json import build_table_schema

In [289]: s = pd.Series(pd.date_range("2016", periods=4))

In [290]: build_table_schema(s)
Out[290]: 
{'fields': [{'name': 'index', 'type': 'integer'},
  {'name': 'values', 'type': 'datetime'}],
 'primaryKey': ['index'],
 'pandas_version': '1.4.0'}

---->   pandas.Series

--------------------------------------
ID: 3146 --> 1
In [291]: s_tz = pd.Series(pd.date_range("2016", periods=12, tz="US/Central"))

In [292]: build_table_schema(s_tz)
Out[292]: 
{'fields': [{'name': 'index', 'type': 'integer'},
  {'name': 'values', 'type': 'datetime', 'tz': 'US/Central'}],
 'primaryKey': ['index'],
 'pandas_version': '1.4.0'}

---->   pandas.Series

--------------------------------------
ID: 3147 --> 2
In [293]: s_per = pd.Series(1, index=pd.period_range("2016", freq="A-DEC", periods=4))

In [294]: build_table_schema(s_per)
Out[294]: 
{'fields': [{'name': 'index', 'type': 'datetime', 'freq': 'A-DEC'},
  {'name': 'values', 'type': 'integer'}],
 'primaryKey': ['index'],
 'pandas_version': '1.4.0'}

---->   pandas.Series; pandas.period_range

--------------------------------------
ID: 3148 --> 2
In [295]: s_cat = pd.Series(pd.Categorical(["a", "b", "a"]))

In [296]: build_table_schema(s_cat)
Out[296]: 
{'fields': [{'name': 'index', 'type': 'integer'},
  {'name': 'values',
   'type': 'any',
   'constraints': {'enum': ['a', 'b']},
   'ordered': False}],
 'primaryKey': ['index'],
 'pandas_version': '1.4.0'}

---->   pandas.Series; pandas.Categorical

--------------------------------------
ID: 3149 --> 1
In [297]: s_dupe = pd.Series([1, 2], index=[1, 1])

In [298]: build_table_schema(s_dupe)
Out[298]: 
{'fields': [{'name': 'index', 'type': 'integer'},
  {'name': 'values', 'type': 'integer'}],
 'pandas_version': '1.4.0'}

---->   pandas.Series

--------------------------------------
ID: 3150 --> 2
In [299]: s_multi = pd.Series(1, index=pd.MultiIndex.from_product([("a", "b"), (0, 1)]))

In [300]: build_table_schema(s_multi)
Out[300]: 
{'fields': [{'name': 'level_0', 'type': 'string'},
  {'name': 'level_1', 'type': 'integer'},
  {'name': 'values', 'type': 'integer'}],
 'primaryKey': FrozenList(['level_0', 'level_1']),
 'pandas_version': '1.4.0'}

---->   pandas.Series; pandas.MultiIndex

--------------------------------------
ID: 3151 --> 4
In [301]: df = pd.DataFrame(
   .....:     {
   .....:         "foo": [1, 2, 3, 4],
   .....:         "bar": ["a", "b", "c", "d"],
   .....:         "baz": pd.date_range("2018-01-01", freq="d", periods=4),
   .....:         "qux": pd.Categorical(["a", "b", "c", "c"]),
   .....:     },
   .....:     index=pd.Index(range(4), name="idx"),
   .....: )
   .....: 

In [302]: df
Out[302]: 
     foo bar        baz qux
idx                        
0      1   a 2018-01-01   a
1      2   b 2018-01-02   b
2      3   c 2018-01-03   c
3      4   d 2018-01-04   c

In [303]: df.dtypes
Out[303]: 
foo             int64
bar            object
baz    datetime64[ns]
qux          category
dtype: object

In [304]: df.to_json("test.json", orient="table")

In [305]: new_df = pd.read_json("test.json", orient="table")

In [306]: new_df
Out[306]: 
     foo bar        baz qux
idx                        
0      1   a 2018-01-01   a
1      2   b 2018-01-02   b
2      3   c 2018-01-03   c
3      4   d 2018-01-04   c

In [307]: new_df.dtypes
Out[307]: 
foo             int64
bar            object
baz    datetime64[ns]
qux          category
dtype: object

---->   pandas.DataFrame; pandas.Categorical; pandas.Index; DataFrame.to_json

--------------------------------------
ID: 3152 --> 1
In [308]: df.index.name = "index"

In [309]: df.to_json("test.json", orient="table")

In [310]: new_df = pd.read_json("test.json", orient="table")

In [311]: print(new_df.index.name)
None

---->   DataFrame.to_json

--------------------------------------
ID: 3166 --> 1
df = pd.DataFrame(np.random.randn(2, 2))
s = df.to_html(float_format="{0:.40g}".format)
dfin = pd.read_html(s, index_col=0)

---->   pandas.DataFrame

--------------------------------------
ID: 3171 --> 1
In [323]: from IPython.display import display, HTML

In [324]: df = pd.DataFrame(np.random.randn(2, 2))

In [325]: df
Out[325]: 
          0         1
0 -0.345352  1.314232
1  0.690579  0.995761

In [326]: html = df.to_html()

In [327]: print(html)  # raw html

  
    
      
      0
      1
    
  
  
    
      0
      -0.345352
      1.314232
    
    
      1
      0.690579
      0.995761
    
  


In [328]: display(HTML(html))


---->   pandas.DataFrame

--------------------------------------
ID: 3176 --> 1
In [339]: url_df = pd.DataFrame(
   .....:     {
   .....:         "name": ["Python", "pandas"],
   .....:         "url": ["https://www.python.org/", "https://pandas.pydata.org"],
   .....:     }
   .....: )
   .....: 

In [340]: html = url_df.to_html(render_links=True)

In [341]: print(html)

  
    
      
      name
      url
    
  
  
    
      0
      Python
      https://www.python.org/
    
    
      1
      pandas
      https://pandas.pydata.org
    
  


In [342]: display(HTML(html))


---->   pandas.DataFrame

--------------------------------------
ID: 3177 --> 1
In [343]: df = pd.DataFrame({"a": list("&<>"), "b": np.random.randn(3)})

---->   pandas.DataFrame

--------------------------------------
ID: 3180 --> 1
In [350]: df = pd.DataFrame([[1, 2], [3, 4]], index=["a", "b"], columns=["c", "d"])

In [351]: print(df.style.to_latex())
\begin{tabular}{lrr}
 & c & d \\
a & 1 & 2 \\
b & 3 & 4 \\
\end{tabular}

---->   pandas.DataFrame

--------------------------------------
ID: 3196 --> 1
In [390]: geom_df = pd.DataFrame(
   .....:     {
   .....:         "shape": ["square", "circle", "triangle"],
   .....:         "degrees": [360, 360, 180],
   .....:         "sides": [4, np.nan, 3],
   .....:     }
   .....: )
   .....: 

In [391]: print(geom_df.to_xml())


  
    0
    square
    360
    4.0
  
  
    1
    circle
    360
    
  
  
    2
    triangle
    180
    3.0
  


---->   pandas.DataFrame

--------------------------------------
ID: 3200 --> 1
In [395]: ext_geom_df = pd.DataFrame(
   .....:     {
   .....:         "type": ["polygon", "other", "polygon"],
   .....:         "shape": ["square", "circle", "triangle"],
   .....:         "degrees": [360, 360, 180],
   .....:         "sides": [4, np.nan, 3],
   .....:     }
   .....: )
   .....: 

In [396]: pvt_df = ext_geom_df.pivot_table(index='shape',
   .....:                                  columns='type',
   .....:                                  values=['degrees', 'sides'],
   .....:                                  aggfunc='sum')
   .....: 

In [397]: pvt_df
Out[397]: 
         degrees         sides        
type       other polygon other polygon
shape                                 
circle     360.0     NaN   0.0     NaN
square       NaN   360.0   NaN     4.0
triangle     NaN   180.0   NaN     3.0

In [398]: print(pvt_df.to_xml())


  
    circle
    360.0
    
    0.0
    
  
  
    square
    
    360.0
    
    4.0
  
  
    triangle
    
    180.0
    
    3.0
  


---->   pandas.DataFrame

--------------------------------------
ID: 3206 --> 1
xlsx = pd.ExcelFile("path_to_file.xls")
df = pd.read_excel(xlsx, "Sheet1")

---->   pandas.ExcelFile

--------------------------------------
ID: 3207 --> 1
with pd.ExcelFile("path_to_file.xls") as xls:
    df1 = pd.read_excel(xls, "Sheet1")
    df2 = pd.read_excel(xls, "Sheet2")

---->   pandas.ExcelFile

--------------------------------------
ID: 3208 --> 1
data = {}
# For when Sheet1's format differs from Sheet2
with pd.ExcelFile("path_to_file.xls") as xls:
    data["Sheet1"] = pd.read_excel(xls, "Sheet1", index_col=None, na_values=["NA"])
    data["Sheet2"] = pd.read_excel(xls, "Sheet2", index_col=1)

---->   pandas.ExcelFile

--------------------------------------
ID: 3209 --> 1
# using the ExcelFile class
data = {}
with pd.ExcelFile("path_to_file.xls") as xls:
    data["Sheet1"] = pd.read_excel(xls, "Sheet1", index_col=None, na_values=["NA"])
    data["Sheet2"] = pd.read_excel(xls, "Sheet2", index_col=None, na_values=["NA"])

# equivalent using the read_excel function
data = pd.read_excel(
    "path_to_file.xls", ["Sheet1", "Sheet2"], index_col=None, na_values=["NA"]
)

---->   pandas.ExcelFile

--------------------------------------
ID: 3210 --> 1
import xlrd

xlrd_book = xlrd.open_workbook("path_to_file.xls", on_demand=True)
with pd.ExcelFile(xlrd_book) as xls:
    df1 = pd.read_excel(xls, "Sheet1")
    df2 = pd.read_excel(xls, "Sheet2")

---->   pandas.ExcelFile

--------------------------------------
ID: 3216 --> 3
In [404]: df = pd.DataFrame(
   .....:     {"a": [1, 2, 3, 4], "b": [5, 6, 7, 8]},
   .....:     index=pd.MultiIndex.from_product([["a", "b"], ["c", "d"]]),
   .....: )
   .....: 

In [405]: df.to_excel("path_to_file.xlsx")

In [406]: df = pd.read_excel("path_to_file.xlsx", index_col=[0, 1])

In [407]: df
Out[407]: 
     a  b
a c  1  5
  d  2  6
b c  3  7
  d  4  8

---->   pandas.DataFrame; pandas.MultiIndex; DataFrame.to_excel

--------------------------------------
ID: 3217 --> 1
In [408]: df.index = df.index.set_names(["lvl1", "lvl2"])

In [409]: df.to_excel("path_to_file.xlsx")

In [410]: df = pd.read_excel("path_to_file.xlsx", index_col=[0, 1])

In [411]: df
Out[411]: 
           a  b
lvl1 lvl2      
a    c     1  5
     d     2  6
b    c     3  7
     d     4  8

---->   DataFrame.to_excel

--------------------------------------
ID: 3218 --> 2
In [412]: df.columns = pd.MultiIndex.from_product([["a"], ["b", "d"]], names=["c1", "c2"])

In [413]: df.to_excel("path_to_file.xlsx")

In [414]: df = pd.read_excel("path_to_file.xlsx", index_col=[0, 1], header=[0, 1])

In [415]: df
Out[415]: 
c1         a   
c2         b  d
lvl1 lvl2      
a    c     1  5
     d     2  6
b    c     3  7
     d     4  8

---->   pandas.MultiIndex; DataFrame.to_excel

--------------------------------------
ID: 3227 --> 1
df.to_excel("path_to_file.xlsx", sheet_name="Sheet1")

---->   DataFrame.to_excel

--------------------------------------
ID: 3228 --> 1
df.to_excel("path_to_file.xlsx", index_label="label", merge_cells=False)

---->   DataFrame.to_excel

--------------------------------------
ID: 3229 --> 3
with pd.ExcelWriter("path_to_file.xlsx") as writer:
    df1.to_excel(writer, sheet_name="Sheet1")
    df2.to_excel(writer, sheet_name="Sheet2")

---->   pandas.ExcelWriter; DataFrame.to_excel; DataFrame.to_excel

--------------------------------------
ID: 3230 --> 2
from io import BytesIO

bio = BytesIO()

# By setting the 'engine' in the ExcelWriter constructor.
writer = pd.ExcelWriter(bio, engine="xlsxwriter")
df.to_excel(writer, sheet_name="Sheet1")

# Save the workbook
writer.save()

# Seek to the beginning and read to copy the workbook to a variable in memory
bio.seek(0)
workbook = bio.read()

---->   pandas.ExcelWriter; DataFrame.to_excel

--------------------------------------
ID: 3231 --> 2
# By setting the 'engine' in the DataFrame 'to_excel()' methods.
df.to_excel("path_to_file.xlsx", sheet_name="Sheet1", engine="xlsxwriter")

# By setting the 'engine' in the ExcelWriter constructor.
writer = pd.ExcelWriter("path_to_file.xlsx", engine="xlsxwriter")

# Or via pandas configuration.
from pandas import options  # noqa: E402

options.io.excel.xlsx.writer = "xlsxwriter"

df.to_excel("path_to_file.xlsx", sheet_name="Sheet1")

---->   DataFrame.to_excel; pandas.ExcelWriter

--------------------------------------
ID: 3233 --> 1
# Writes DataFrame to a .ods file
df.to_excel("path_to_file.ods", engine="odf")

---->   DataFrame.to_excel

--------------------------------------
ID: 3235 --> 1
>>> clipdf = pd.read_clipboard()
>>> clipdf
  A B C
x 1 4 p
y 2 5 q
z 3 6 r

---->   pandas.read_clipboard

--------------------------------------
ID: 3236 --> 3
>>> df = pd.DataFrame(
...     {"A": [1, 2, 3], "B": [4, 5, 6], "C": ["p", "q", "r"]}, index=["x", "y", "z"]
... )

>>> df
  A B C
x 1 4 p
y 2 5 q
z 3 6 r
>>> df.to_clipboard()
>>> pd.read_clipboard()
  A B C
x 1 4 p
y 2 5 q
z 3 6 r

---->   pandas.DataFrame; DataFrame.to_clipboard; pandas.read_clipboard

--------------------------------------
ID: 3237 --> 1
In [416]: df
Out[416]: 
c1         a   
c2         b  d
lvl1 lvl2      
a    c     1  5
     d     2  6
b    c     3  7
     d     4  8

In [417]: df.to_pickle("foo.pkl")

---->   DataFrame.to_pickle

--------------------------------------
ID: 3238 --> 1
In [418]: pd.read_pickle("foo.pkl")
Out[418]: 
c1         a   
c2         b  d
lvl1 lvl2      
a    c     1  5
     d     2  6
b    c     3  7
     d     4  8

---->   pandas.read_pickle

--------------------------------------
ID: 3239 --> 1
In [419]: df = pd.DataFrame(
   .....:     {
   .....:         "A": np.random.randn(1000),
   .....:         "B": "foo",
   .....:         "C": pd.date_range("20130101", periods=1000, freq="s"),
   .....:     }
   .....: )
   .....: 

In [420]: df
Out[420]: 
            A    B                   C
0   -0.317441  foo 2013-01-01 00:00:00
1   -1.236269  foo 2013-01-01 00:00:01
2    0.896171  foo 2013-01-01 00:00:02
3   -0.487602  foo 2013-01-01 00:00:03
4   -0.082240  foo 2013-01-01 00:00:04
..        ...  ...                 ...
995 -0.171092  foo 2013-01-01 00:16:35
996  1.786173  foo 2013-01-01 00:16:36
997 -0.575189  foo 2013-01-01 00:16:37
998  0.820750  foo 2013-01-01 00:16:38
999 -1.256530  foo 2013-01-01 00:16:39

[1000 rows x 3 columns]

---->   pandas.DataFrame

--------------------------------------
ID: 3240 --> 2
In [421]: df.to_pickle("data.pkl.compress", compression="gzip")

In [422]: rt = pd.read_pickle("data.pkl.compress", compression="gzip")

In [423]: rt
Out[423]: 
            A    B                   C
0   -0.317441  foo 2013-01-01 00:00:00
1   -1.236269  foo 2013-01-01 00:00:01
2    0.896171  foo 2013-01-01 00:00:02
3   -0.487602  foo 2013-01-01 00:00:03
4   -0.082240  foo 2013-01-01 00:00:04
..        ...  ...                 ...
995 -0.171092  foo 2013-01-01 00:16:35
996  1.786173  foo 2013-01-01 00:16:36
997 -0.575189  foo 2013-01-01 00:16:37
998  0.820750  foo 2013-01-01 00:16:38
999 -1.256530  foo 2013-01-01 00:16:39

[1000 rows x 3 columns]

---->   DataFrame.to_pickle; pandas.read_pickle

--------------------------------------
ID: 3241 --> 2
In [424]: df.to_pickle("data.pkl.xz", compression="infer")

In [425]: rt = pd.read_pickle("data.pkl.xz", compression="infer")

In [426]: rt
Out[426]: 
            A    B                   C
0   -0.317441  foo 2013-01-01 00:00:00
1   -1.236269  foo 2013-01-01 00:00:01
2    0.896171  foo 2013-01-01 00:00:02
3   -0.487602  foo 2013-01-01 00:00:03
4   -0.082240  foo 2013-01-01 00:00:04
..        ...  ...                 ...
995 -0.171092  foo 2013-01-01 00:16:35
996  1.786173  foo 2013-01-01 00:16:36
997 -0.575189  foo 2013-01-01 00:16:37
998  0.820750  foo 2013-01-01 00:16:38
999 -1.256530  foo 2013-01-01 00:16:39

[1000 rows x 3 columns]

---->   DataFrame.to_pickle; pandas.read_pickle

--------------------------------------
ID: 3242 --> 2
In [427]: df.to_pickle("data.pkl.gz")

In [428]: rt = pd.read_pickle("data.pkl.gz")

In [429]: rt
Out[429]: 
            A    B                   C
0   -0.317441  foo 2013-01-01 00:00:00
1   -1.236269  foo 2013-01-01 00:00:01
2    0.896171  foo 2013-01-01 00:00:02
3   -0.487602  foo 2013-01-01 00:00:03
4   -0.082240  foo 2013-01-01 00:00:04
..        ...  ...                 ...
995 -0.171092  foo 2013-01-01 00:16:35
996  1.786173  foo 2013-01-01 00:16:36
997 -0.575189  foo 2013-01-01 00:16:37
998  0.820750  foo 2013-01-01 00:16:38
999 -1.256530  foo 2013-01-01 00:16:39

[1000 rows x 3 columns]

In [430]: df["A"].to_pickle("s1.pkl.bz2")

In [431]: rt = pd.read_pickle("s1.pkl.bz2")

In [432]: rt
Out[432]: 
0     -0.317441
1     -1.236269
2      0.896171
3     -0.487602
4     -0.082240
         ...   
995   -0.171092
996    1.786173
997   -0.575189
998    0.820750
999   -1.256530
Name: A, Length: 1000, dtype: float64

---->   DataFrame.to_pickle; pandas.read_pickle

--------------------------------------
ID: 3243 --> 1
In [433]: df.to_pickle("data.pkl.gz", compression={"method": "gzip", "compresslevel": 1})

---->   DataFrame.to_pickle

--------------------------------------
ID: 3245 --> 2
In [436]: index = pd.date_range("1/1/2000", periods=8)

In [437]: s = pd.Series(np.random.randn(5), index=["a", "b", "c", "d", "e"])

In [438]: df = pd.DataFrame(np.random.randn(8, 3), index=index, columns=["A", "B", "C"])

# store.put('s', s) is an equivalent method
In [439]: store["s"] = s

In [440]: store["df"] = df

In [441]: store
Out[441]: 

File path: store.h5

---->   pandas.Series; pandas.DataFrame

--------------------------------------
ID: 3249 --> 3
In [450]: df_tl = pd.DataFrame({"A": list(range(5)), "B": list(range(5))})

In [451]: df_tl.to_hdf("store_tl.h5", "table", append=True)

In [452]: pd.read_hdf("store_tl.h5", "table", where=["index>2"])
Out[452]: 
   A  B
3  3  3
4  4  4

---->   pandas.DataFrame; DataFrame.to_hdf; pandas.read_hdf

--------------------------------------
ID: 3250 --> 2
In [453]: df_with_missing = pd.DataFrame(
   .....:     {
   .....:         "col1": [0, np.nan, 2],
   .....:         "col2": [1, np.nan, np.nan],
   .....:     }
   .....: )
   .....: 

In [454]: df_with_missing
Out[454]: 
   col1  col2
0   0.0   1.0
1   NaN   NaN
2   2.0   NaN

In [455]: df_with_missing.to_hdf("file.h5", "df_with_missing", format="table", mode="w")

In [456]: pd.read_hdf("file.h5", "df_with_missing")
Out[456]: 
   col1  col2
0   0.0   1.0
1   NaN   NaN
2   2.0   NaN

In [457]: df_with_missing.to_hdf(
   .....:     "file.h5", "df_with_missing", format="table", mode="w", dropna=True
   .....: )
   .....: 

In [458]: pd.read_hdf("file.h5", "df_with_missing")
Out[458]: 
   col1  col2
0   0.0   1.0
2   2.0   NaN

---->   pandas.DataFrame; pandas.read_hdf

--------------------------------------
ID: 3251 --> 2
>>> pd.DataFrame(np.random.randn(10, 2)).to_hdf("test_fixed.h5", "df")
>>> pd.read_hdf("test_fixed.h5", "df", where="index>5")
TypeError: cannot pass a where specification when reading a fixed format.
           this store must be selected in its entirety

---->   pandas.DataFrame; pandas.read_hdf

--------------------------------------
ID: 3256 --> 1
In [476]: df_mixed = pd.DataFrame(
   .....:     {
   .....:         "A": np.random.randn(8),
   .....:         "B": np.random.randn(8),
   .....:         "C": np.array(np.random.randn(8), dtype="float32"),
   .....:         "string": "string",
   .....:         "int": 1,
   .....:         "bool": True,
   .....:         "datetime64": pd.Timestamp("20010102"),
   .....:     },
   .....:     index=list(range(8)),
   .....: )
   .....: 

In [477]: df_mixed.loc[df_mixed.index[3:5], ["A", "B", "string", "datetime64"]] = np.nan

In [478]: store.append("df_mixed", df_mixed, min_itemsize={"values": 50})

In [479]: df_mixed1 = store.select("df_mixed")

In [480]: df_mixed1
Out[480]: 
          A         B         C  string  int  bool datetime64
0  0.120106 -0.624406 -0.103317  string    1  True 2001-01-02
1 -1.814006 -1.217067  0.183764  string    1  True 2001-01-02
2  0.779275  0.992992  0.319368  string    1  True 2001-01-02
3       NaN       NaN  0.083662     NaN    1  True        NaT
4       NaN       NaN  0.013747     NaN    1  True        NaT
5 -0.243692  0.222892 -0.712009  string    1  True 2001-01-02
6  0.184544  0.057946 -0.645096  string    1  True 2001-01-02
7 -0.924273 -0.623319  1.347217  string    1  True 2001-01-02

In [481]: df_mixed1.dtypes.value_counts()
Out[481]: 
float64           2
float32           1
object            1
int64             1
bool              1
datetime64[ns]    1
Name: count, dtype: int64

# we have provided a minimum string column size
In [482]: store.root.df_mixed.table
Out[482]: 
/df_mixed/table (Table(8,)) ''
  description := {
  "index": Int64Col(shape=(), dflt=0, pos=0),
  "values_block_0": Float64Col(shape=(2,), dflt=0.0, pos=1),
  "values_block_1": Float32Col(shape=(1,), dflt=0.0, pos=2),
  "values_block_2": StringCol(itemsize=50, shape=(1,), dflt=b'', pos=3),
  "values_block_3": Int64Col(shape=(1,), dflt=0, pos=4),
  "values_block_4": BoolCol(shape=(1,), dflt=False, pos=5),
  "values_block_5": Int64Col(shape=(1,), dflt=0, pos=6)}
  byteorder := 'little'
  chunkshape := (689,)
  autoindex := True
  colindexes := {
    "index": Index(6, mediumshuffle, zlib(1)).is_csi=False}

---->   pandas.DataFrame

--------------------------------------
ID: 3257 --> 2
In [483]: index = pd.MultiIndex(
   .....:     levels=[["foo", "bar", "baz", "qux"], ["one", "two", "three"]],
   .....:     codes=[[0, 0, 0, 1, 1, 2, 2, 3, 3, 3], [0, 1, 2, 0, 1, 1, 2, 0, 1, 2]],
   .....:     names=["foo", "bar"],
   .....: )
   .....: 

In [484]: df_mi = pd.DataFrame(np.random.randn(10, 3), index=index, columns=["A", "B", "C"])

In [485]: df_mi
Out[485]: 
                  A         B         C
foo bar                                
foo one    0.686219 -0.023202  2.359782
    two   -0.143428 -1.166078  0.247572
    three  1.687406  0.894559  1.215261
bar one    0.043702  0.088224 -0.813360
    two   -1.292080  1.526911  0.288504
baz two    0.097771  1.536408  0.926790
    three -0.676448 -0.179724 -1.303456
qux one   -0.642994 -0.649456  1.012694
    two    0.414147  1.950460  1.094544
    three -0.802899 -0.583343  0.410395

In [486]: store.append("df_mi", df_mi)

In [487]: store.select("df_mi")
Out[487]: 
                  A         B         C
foo bar                                
foo one    0.686219 -0.023202  2.359782
    two   -0.143428 -1.166078  0.247572
    three  1.687406  0.894559  1.215261
bar one    0.043702  0.088224 -0.813360
    two   -1.292080  1.526911  0.288504
baz two    0.097771  1.536408  0.926790
    three -0.676448 -0.179724 -1.303456
qux one   -0.642994 -0.649456  1.012694
    two    0.414147  1.950460  1.094544
    three -0.802899 -0.583343  0.410395

# the levels are automatically included as data columns
In [488]: store.select("df_mi", "foo=bar")
Out[488]: 
                A         B         C
foo bar                              
bar one  0.043702  0.088224 -0.813360
    two -1.292080  1.526911  0.288504

---->   pandas.MultiIndex; pandas.DataFrame

--------------------------------------
ID: 3261 --> 1
In [489]: dfq = pd.DataFrame(
   .....:     np.random.randn(10, 4),
   .....:     columns=list("ABCD"),
   .....:     index=pd.date_range("20130101", periods=10),
   .....: )
   .....: 

In [490]: store.append("dfq", dfq, format="table", data_columns=True)

---->   pandas.DataFrame

--------------------------------------
ID: 3265 --> 1
In [494]: from datetime import timedelta

In [495]: dftd = pd.DataFrame(
   .....:     {
   .....:         "A": pd.Timestamp("20130101"),
   .....:         "B": [
   .....:             pd.Timestamp("20130101") + timedelta(days=i, seconds=10)
   .....:             for i in range(10)
   .....:         ],
   .....:     }
   .....: )
   .....: 

In [496]: dftd["C"] = dftd["A"] - dftd["B"]

In [497]: dftd
Out[497]: 
           A                   B                  C
0 2013-01-01 2013-01-01 00:00:10  -1 days +23:59:50
1 2013-01-01 2013-01-02 00:00:10  -2 days +23:59:50
2 2013-01-01 2013-01-03 00:00:10  -3 days +23:59:50
3 2013-01-01 2013-01-04 00:00:10  -4 days +23:59:50
4 2013-01-01 2013-01-05 00:00:10  -5 days +23:59:50
5 2013-01-01 2013-01-06 00:00:10  -6 days +23:59:50
6 2013-01-01 2013-01-07 00:00:10  -7 days +23:59:50
7 2013-01-01 2013-01-08 00:00:10  -8 days +23:59:50
8 2013-01-01 2013-01-09 00:00:10  -9 days +23:59:50
9 2013-01-01 2013-01-10 00:00:10 -10 days +23:59:50

In [498]: store.append("dftd", dftd, data_columns=True)

In [499]: store.select("dftd", "C<'-3.5D'")
Out[499]: 
           A                   B                  C
4 2013-01-01 2013-01-05 00:00:10  -5 days +23:59:50
5 2013-01-01 2013-01-06 00:00:10  -6 days +23:59:50
6 2013-01-01 2013-01-07 00:00:10  -7 days +23:59:50
7 2013-01-01 2013-01-08 00:00:10  -8 days +23:59:50
8 2013-01-01 2013-01-09 00:00:10  -9 days +23:59:50
9 2013-01-01 2013-01-10 00:00:10 -10 days +23:59:50

---->   pandas.DataFrame

--------------------------------------
ID: 3267 --> 2
In [502]: index = pd.MultiIndex(
   .....:     levels=[["foo", "bar", "baz", "qux"], ["one", "two", "three"]],
   .....:     codes=[[0, 0, 0, 1, 1, 2, 2, 3, 3, 3], [0, 1, 2, 0, 1, 1, 2, 0, 1, 2]],
   .....: )
   .....: 

In [503]: df_mi_2 = pd.DataFrame(np.random.randn(10, 3), index=index, columns=["A", "B", "C"])

In [504]: df_mi_2
Out[504]: 
                  A         B         C
foo one    0.431186  1.049421  0.383309
    two    0.595013  0.617509 -0.811230
    three -2.088563 -1.393500  0.947422
bar one   -0.671233 -0.847097 -1.187785
    two   -0.183798 -1.211230 -0.856833
baz two   -0.600575  0.361428  0.887304
    three  0.266457 -0.399641 -0.219582
qux one    1.186860 -1.437189  0.053768
    two    1.872644 -1.469813 -0.564201
    three  0.876341  0.407749 -0.232583

In [505]: store.append("df_mi_2", df_mi_2)

# the levels are automatically included as data columns with keyword level_n
In [506]: store.select("df_mi_2", "level_0=foo and level_1=two")
Out[506]: 
                A         B        C
foo two  0.595013  0.617509 -0.81123

---->   pandas.MultiIndex; pandas.DataFrame

--------------------------------------
ID: 3269 --> 1
In [512]: df_1 = pd.DataFrame(np.random.randn(10, 2), columns=list("AB"))

In [513]: df_2 = pd.DataFrame(np.random.randn(10, 2), columns=list("AB"))

In [514]: st = pd.HDFStore("appends.h5", mode="w")

In [515]: st.append("df", df_1, data_columns=["B"], index=False)

In [516]: st.append("df", df_2, data_columns=["B"], index=False)

In [517]: st.get_storer("df").table
Out[517]: 
/df/table (Table(20,)) ''
  description := {
  "index": Int64Col(shape=(), dflt=0, pos=0),
  "values_block_0": Float64Col(shape=(1,), dflt=0.0, pos=1),
  "B": Float64Col(shape=(), dflt=0.0, pos=2)}
  byteorder := 'little'
  chunkshape := (2730,)

---->   pandas.DataFrame

--------------------------------------
ID: 3271 --> 1
In [521]: df_dc = df.copy()

In [522]: df_dc["string"] = "foo"

In [523]: df_dc.loc[df_dc.index[4:6], "string"] = np.nan

In [524]: df_dc.loc[df_dc.index[7:9], "string"] = "bar"

In [525]: df_dc["string2"] = "cool"

In [526]: df_dc.loc[df_dc.index[1:3], ["B", "C"]] = 1.0

In [527]: df_dc
Out[527]: 
                   A         B         C string string2
2000-01-01  0.858644 -0.851236  1.058006    foo    cool
2000-01-02 -0.080372  1.000000  1.000000    foo    cool
2000-01-03  0.816983  1.000000  1.000000    foo    cool
2000-01-04  0.712795 -0.062433  0.736755    foo    cool
2000-01-05 -0.298721 -1.988045  1.475308    NaN    cool
2000-01-06  1.103675  1.382242 -0.650762    NaN    cool
2000-01-07 -0.729161 -0.142928 -1.063038    foo    cool
2000-01-08 -1.005977  0.465222 -0.094517    bar    cool

# on-disk operations
In [528]: store.append("df_dc", df_dc, data_columns=["B", "C", "string", "string2"])

In [529]: store.select("df_dc", where="B > 0")
Out[529]: 
                   A         B         C string string2
2000-01-02 -0.080372  1.000000  1.000000    foo    cool
2000-01-03  0.816983  1.000000  1.000000    foo    cool
2000-01-06  1.103675  1.382242 -0.650762    NaN    cool
2000-01-08 -1.005977  0.465222 -0.094517    bar    cool

# getting creative
In [530]: store.select("df_dc", "B > 0 & C > 0 & string == foo")
Out[530]: 
                   A    B    C string string2
2000-01-02 -0.080372  1.0  1.0    foo    cool
2000-01-03  0.816983  1.0  1.0    foo    cool

# this is in-memory version of this type of selection
In [531]: df_dc[(df_dc.B > 0) & (df_dc.C > 0) & (df_dc.string == "foo")]
Out[531]: 
                   A    B    C string string2
2000-01-02 -0.080372  1.0  1.0    foo    cool
2000-01-03  0.816983  1.0  1.0    foo    cool

# we have automagically created this index and the B/C/string/string2
# columns are stored separately as ``PyTables`` columns
In [532]: store.root.df_dc.table
Out[532]: 
/df_dc/table (Table(8,)) ''
  description := {
  "index": Int64Col(shape=(), dflt=0, pos=0),
  "values_block_0": Float64Col(shape=(1,), dflt=0.0, pos=1),
  "B": Float64Col(shape=(), dflt=0.0, pos=2),
  "C": Float64Col(shape=(), dflt=0.0, pos=3),
  "string": StringCol(itemsize=3, shape=(), dflt=b'', pos=4),
  "string2": StringCol(itemsize=4, shape=(), dflt=b'', pos=5)}
  byteorder := 'little'
  chunkshape := (1680,)
  autoindex := True
  colindexes := {
    "index": Index(6, mediumshuffle, zlib(1)).is_csi=False,
    "B": Index(6, mediumshuffle, zlib(1)).is_csi=False,
    "C": Index(6, mediumshuffle, zlib(1)).is_csi=False,
    "string": Index(6, mediumshuffle, zlib(1)).is_csi=False,
    "string2": Index(6, mediumshuffle, zlib(1)).is_csi=False}

---->   DataFrame.copy

--------------------------------------
ID: 3273 --> 1
for df in pd.read_hdf("store.h5", "df", chunksize=3):
    print(df)

---->   pandas.read_hdf

--------------------------------------
ID: 3274 --> 1
In [534]: dfeq = pd.DataFrame({"number": np.arange(1, 11)})

In [535]: dfeq
Out[535]: 
   number
0       1
1       2
2       3
3       4
4       5
5       6
6       7
7       8
8       9
9      10

In [536]: store.append("dfeq", dfeq, data_columns=["number"])

In [537]: def chunks(l, n):
   .....:     return [l[i: i + n] for i in range(0, len(l), n)]
   .....: 

In [538]: evens = [2, 4, 6, 8, 10]

In [539]: coordinates = store.select_as_coordinates("dfeq", "number=evens")

In [540]: for c in chunks(coordinates, 2):
   .....:     print(store.select("dfeq", where=c))
   .....: 
   number
1       2
3       4
   number
5       6
7       8
   number
9      10

---->   pandas.DataFrame

--------------------------------------
ID: 3276 --> 1
In [543]: df_coord = pd.DataFrame(
   .....:     np.random.randn(1000, 2), index=pd.date_range("20000101", periods=1000)
   .....: )
   .....: 

In [544]: store.append("df_coord", df_coord)

In [545]: c = store.select_as_coordinates("df_coord", "index > 20020101")

In [546]: c
Out[546]: 
Index([732, 733, 734, 735, 736, 737, 738, 739, 740, 741,
       ...
       990, 991, 992, 993, 994, 995, 996, 997, 998, 999],
      dtype='int64', length=268)

In [547]: store.select("df_coord", where=c)
Out[547]: 
                   0         1
2002-01-02  0.241433  0.717260
2002-01-03  1.781878 -2.016130
2002-01-04  1.095589  0.935850
2002-01-05  0.944319  1.167204
2002-01-06  0.497867  0.308975
...              ...       ...
2002-09-22 -0.561327 -2.106554
2002-09-23 -1.080806 -0.862818
2002-09-24 -0.369663 -0.246194
2002-09-25  0.322358 -0.500547
2002-09-26  0.154552 -0.098948

[268 rows x 2 columns]

---->   pandas.DataFrame

--------------------------------------
ID: 3277 --> 2
In [548]: df_mask = pd.DataFrame(
   .....:     np.random.randn(1000, 2), index=pd.date_range("20000101", periods=1000)
   .....: )
   .....: 

In [549]: store.append("df_mask", df_mask)

In [550]: c = store.select_column("df_mask", "index")

In [551]: where = c[pd.DatetimeIndex(c).month == 5].index

In [552]: store.select("df_mask", where=where)
Out[552]: 
                   0         1
2000-05-01  1.020434  0.148828
2000-05-02 -0.570048 -1.303235
2000-05-03  0.952743  0.099314
2000-05-04  0.448445  0.300635
2000-05-05 -1.563991  1.111575
...              ...       ...
2002-05-27 -0.637268 -1.590405
2002-05-28  0.176963  0.191694
2002-05-29 -0.228488 -1.162170
2002-05-30  0.344842 -0.963555
2002-05-31  0.956318  0.480412

[93 rows x 2 columns]

---->   pandas.DataFrame; pandas.DatetimeIndex

--------------------------------------
ID: 3279 --> 1
In [554]: df_mt = pd.DataFrame(
   .....:     np.random.randn(8, 6),
   .....:     index=pd.date_range("1/1/2000", periods=8),
   .....:     columns=["A", "B", "C", "D", "E", "F"],
   .....: )
   .....: 

In [555]: df_mt["foo"] = "bar"

In [556]: df_mt.loc[df_mt.index[1], ("A", "B")] = np.nan

# you can also create the tables individually
In [557]: store.append_to_multiple(
   .....:     {"df1_mt": ["A", "B"], "df2_mt": None}, df_mt, selector="df1_mt"
   .....: )
   .....: 

In [558]: store
Out[558]: 

File path: store.h5

# individual tables were created
In [559]: store.select("df1_mt")
Out[559]: 
                   A         B
2000-01-01 -0.277446 -1.102896
2000-01-02       NaN       NaN
2000-01-03 -0.787062  0.651396
2000-01-04  1.095864 -0.200875
2000-01-05  0.460708  1.834518
2000-01-06  0.439872  0.506364
2000-01-07  0.116634 -1.772519
2000-01-08  0.748471 -0.943009

In [560]: store.select("df2_mt")
Out[560]: 
                   C         D         E         F  foo
2000-01-01  0.100307 -1.602814  0.920139 -0.643870  bar
2000-01-02 -0.494305  0.737973  0.451632  0.334124  bar
2000-01-03 -0.741919  1.193881 -2.395763 -0.199038  bar
2000-01-04  0.162291 -0.430489 -2.502042  0.668149  bar
2000-01-05  0.196782 -0.922321  0.130441 -0.608465  bar
2000-01-06  0.429207 -1.099274 -1.069546  1.236277  bar
2000-01-07  1.869081 -1.466039  0.137462  0.313939  bar
2000-01-08  0.092130 -1.726280  0.836517  2.049798  bar

# as a multiple
In [561]: store.select_as_multiple(
   .....:     ["df1_mt", "df2_mt"],
   .....:     where=["A>0", "B>0"],
   .....:     selector="df1_mt",
   .....: )
   .....: 
Out[561]: 
                   A         B         C         D         E         F  foo
2000-01-05  0.460708  1.834518  0.196782 -0.922321  0.130441 -0.608465  bar
2000-01-06  0.439872  0.506364  0.429207 -1.099274 -1.069546  1.236277  bar

---->   pandas.DataFrame

--------------------------------------
ID: 3282 --> 2
In [562]: dfcat = pd.DataFrame(
   .....:     {"A": pd.Series(list("aabbcdba")).astype("category"), "B": np.random.randn(8)}
   .....: )
   .....: 

In [563]: dfcat
Out[563]: 
   A         B
0  a  0.562167
1  a  0.189952
2  b  0.266901
3  b -0.036854
4  c  1.112750
5  d -0.151596
6  b  1.503311
7  a  0.939470

In [564]: dfcat.dtypes
Out[564]: 
A    category
B     float64
dtype: object

In [565]: cstore = pd.HDFStore("cats.h5", mode="w")

In [566]: cstore.append("dfcat", dfcat, format="table", data_columns=["A"])

In [567]: result = cstore.select("dfcat", where="A in ['b', 'c']")

In [568]: result
Out[568]: 
   A         B
2  b  0.266901
3  b -0.036854
4  c  1.112750
6  b  1.503311

In [569]: result.dtypes
Out[569]: 
A    category
B     float64
dtype: object

---->   pandas.DataFrame; pandas.Series

--------------------------------------
ID: 3283 --> 1
In [570]: dfs = pd.DataFrame({"A": "foo", "B": "bar"}, index=list(range(5)))

In [571]: dfs
Out[571]: 
     A    B
0  foo  bar
1  foo  bar
2  foo  bar
3  foo  bar
4  foo  bar

# A and B have a size of 30
In [572]: store.append("dfs", dfs, min_itemsize=30)

In [573]: store.get_storer("dfs").table
Out[573]: 
/dfs/table (Table(5,)) ''
  description := {
  "index": Int64Col(shape=(), dflt=0, pos=0),
  "values_block_0": StringCol(itemsize=30, shape=(2,), dflt=b'', pos=1)}
  byteorder := 'little'
  chunkshape := (963,)
  autoindex := True
  colindexes := {
    "index": Index(6, mediumshuffle, zlib(1)).is_csi=False}

# A is created as a data_column with a size of 30
# B is size is calculated
In [574]: store.append("dfs2", dfs, min_itemsize={"A": 30})

In [575]: store.get_storer("dfs2").table
Out[575]: 
/dfs2/table (Table(5,)) ''
  description := {
  "index": Int64Col(shape=(), dflt=0, pos=0),
  "values_block_0": StringCol(itemsize=3, shape=(1,), dflt=b'', pos=1),
  "A": StringCol(itemsize=30, shape=(), dflt=b'', pos=2)}
  byteorder := 'little'
  chunkshape := (1598,)
  autoindex := True
  colindexes := {
    "index": Index(6, mediumshuffle, zlib(1)).is_csi=False,
    "A": Index(6, mediumshuffle, zlib(1)).is_csi=False}

---->   pandas.DataFrame

--------------------------------------
ID: 3284 --> 1
In [576]: dfss = pd.DataFrame({"A": ["foo", "bar", "nan"]})

In [577]: dfss
Out[577]: 
     A
0  foo
1  bar
2  nan

In [578]: store.append("dfss", dfss)

In [579]: store.select("dfss")
Out[579]: 
     A
0  foo
1  bar
2  NaN

# here you need to specify a different nan rep
In [580]: store.append("dfss2", dfss, nan_rep="_nan_")

In [581]: store.select("dfss2")
Out[581]: 
     A
0  foo
1  bar
2  nan

---->   pandas.DataFrame

--------------------------------------
ID: 3285 --> 2
In [582]: df = pd.DataFrame(
   .....:     {
   .....:         "a": list("abc"),
   .....:         "b": list(range(1, 4)),
   .....:         "c": np.arange(3, 6).astype("u1"),
   .....:         "d": np.arange(4.0, 7.0, dtype="float64"),
   .....:         "e": [True, False, True],
   .....:         "f": pd.Categorical(list("abc")),
   .....:         "g": pd.date_range("20130101", periods=3),
   .....:         "h": pd.date_range("20130101", periods=3, tz="US/Eastern"),
   .....:         "i": pd.date_range("20130101", periods=3, freq="ns"),
   .....:     }
   .....: )
   .....: 

In [583]: df
Out[583]: 
   a  b  c  ...          g                         h                             i
0  a  1  3  ... 2013-01-01 2013-01-01 00:00:00-05:00 2013-01-01 00:00:00.000000000
1  b  2  4  ... 2013-01-02 2013-01-02 00:00:00-05:00 2013-01-01 00:00:00.000000001
2  c  3  5  ... 2013-01-03 2013-01-03 00:00:00-05:00 2013-01-01 00:00:00.000000002

[3 rows x 9 columns]

In [584]: df.dtypes
Out[584]: 
a                        object
b                         int64
c                         uint8
d                       float64
e                          bool
f                      category
g                datetime64[ns]
h    datetime64[ns, US/Eastern]
i                datetime64[ns]
dtype: object

---->   pandas.DataFrame; pandas.Categorical

--------------------------------------
ID: 3286 --> 1
In [585]: df.to_feather("example.feather")

---->   DataFrame.to_feather

--------------------------------------
ID: 3287 --> 1
In [586]: result = pd.read_feather("example.feather")

In [587]: result
Out[587]: 
   a  b  c  ...          g                         h                             i
0  a  1  3  ... 2013-01-01 2013-01-01 00:00:00-05:00 2013-01-01 00:00:00.000000000
1  b  2  4  ... 2013-01-02 2013-01-02 00:00:00-05:00 2013-01-01 00:00:00.000000001
2  c  3  5  ... 2013-01-03 2013-01-03 00:00:00-05:00 2013-01-01 00:00:00.000000002

[3 rows x 9 columns]

# we preserve dtypes
In [588]: result.dtypes
Out[588]: 
a                        object
b                         int64
c                         uint8
d                       float64
e                          bool
f                      category
g                datetime64[ns]
h    datetime64[ns, US/Eastern]
i                datetime64[ns]
dtype: object

---->   pandas.read_feather

--------------------------------------
ID: 3288 --> 2
In [589]: df = pd.DataFrame(
   .....:     {
   .....:         "a": list("abc"),
   .....:         "b": list(range(1, 4)),
   .....:         "c": np.arange(3, 6).astype("u1"),
   .....:         "d": np.arange(4.0, 7.0, dtype="float64"),
   .....:         "e": [True, False, True],
   .....:         "f": pd.date_range("20130101", periods=3),
   .....:         "g": pd.date_range("20130101", periods=3, tz="US/Eastern"),
   .....:         "h": pd.Categorical(list("abc")),
   .....:         "i": pd.Categorical(list("abc"), ordered=True),
   .....:     }
   .....: )
   .....: 

In [590]: df
Out[590]: 
   a  b  c    d      e          f                         g  h  i
0  a  1  3  4.0   True 2013-01-01 2013-01-01 00:00:00-05:00  a  a
1  b  2  4  5.0  False 2013-01-02 2013-01-02 00:00:00-05:00  b  b
2  c  3  5  6.0   True 2013-01-03 2013-01-03 00:00:00-05:00  c  c

In [591]: df.dtypes
Out[591]: 
a                        object
b                         int64
c                         uint8
d                       float64
e                          bool
f                datetime64[ns]
g    datetime64[ns, US/Eastern]
h                      category
i                      category
dtype: object

---->   pandas.DataFrame; pandas.Categorical

--------------------------------------
ID: 3289 --> 1
In [592]: df.to_parquet("example_pa.parquet", engine="pyarrow")

In [593]: df.to_parquet("example_fp.parquet", engine="fastparquet")

---->   DataFrame.to_parquet

--------------------------------------
ID: 3290 --> 1
In [594]: result = pd.read_parquet("example_fp.parquet", engine="fastparquet")

In [595]: result = pd.read_parquet("example_pa.parquet", engine="pyarrow")

In [596]: result.dtypes
Out[596]: 
a                        object
b                         int64
c                         uint8
d                       float64
e                          bool
f                datetime64[ns]
g    datetime64[ns, US/Eastern]
h                      category
i                      category
dtype: object

---->   pandas.read_parquet

--------------------------------------
ID: 3291 --> 1
In [597]: result = pd.read_parquet(
   .....:     "example_fp.parquet",
   .....:     engine="fastparquet",
   .....:     columns=["a", "b"],
   .....: )
   .....: 

In [598]: result = pd.read_parquet(
   .....:     "example_pa.parquet",
   .....:     engine="pyarrow",
   .....:     columns=["a", "b"],
   .....: )
   .....: 

In [599]: result.dtypes
Out[599]: 
a    object
b     int64
dtype: object

---->   pandas.read_parquet

--------------------------------------
ID: 3292 --> 2
In [600]: df = pd.DataFrame({"a": [1, 2], "b": [3, 4]})

In [601]: df.to_parquet("test.parquet", engine="pyarrow")

---->   pandas.DataFrame; DataFrame.to_parquet

--------------------------------------
ID: 3293 --> 1
In [602]: df.to_parquet("test.parquet", index=False)

---->   DataFrame.to_parquet

--------------------------------------
ID: 3294 --> 2
In [603]: df = pd.DataFrame({"a": [0, 0, 1, 1], "b": [0, 1, 0, 1]})

In [604]: df.to_parquet(path="test", engine="pyarrow", partition_cols=["a"], compression=None)

---->   pandas.DataFrame; DataFrame.to_parquet

--------------------------------------
ID: 3295 --> 1
In [605]: df = pd.DataFrame(
   .....:     {
   .....:         "a": list("abc"),
   .....:         "b": list(range(1, 4)),
   .....:         "c": np.arange(4.0, 7.0, dtype="float64"),
   .....:         "d": [True, False, True],
   .....:         "e": pd.date_range("20130101", periods=3),
   .....:     }
   .....: )
   .....: 

In [606]: df
Out[606]: 
   a  b    c      d          e
0  a  1  4.0   True 2013-01-01
1  b  2  5.0  False 2013-01-02
2  c  3  6.0   True 2013-01-03

In [607]: df.dtypes
Out[607]: 
a            object
b             int64
c           float64
d              bool
e    datetime64[ns]
dtype: object

---->   pandas.DataFrame

--------------------------------------
ID: 3297 --> 1
In [609]: result = pd.read_orc("example_pa.orc")

In [610]: result.dtypes
Out[610]: 
a            object
b             int64
c           float64
d              bool
e    datetime64[ns]
dtype: object

---->   pandas.read_orc

--------------------------------------
ID: 3298 --> 1
In [611]: result = pd.read_orc(
   .....:     "example_pa.orc",
   .....:     columns=["a", "b"],
   .....: )
   .....: 

In [612]: result.dtypes
Out[612]: 
a    object
b     int64
dtype: object

---->   pandas.read_orc

--------------------------------------
ID: 3300 --> 1
with engine.connect() as conn, conn.begin():
    data = pd.read_sql_table("data", conn)

---->   pandas.read_sql_table

--------------------------------------
ID: 3301 --> 2
In [615]: import datetime

In [616]: c = ["id", "Date", "Col_1", "Col_2", "Col_3"]

In [617]: d = [
   .....:     (26, datetime.datetime(2010, 10, 18), "X", 27.5, True),
   .....:     (42, datetime.datetime(2010, 10, 19), "Y", -12.5, False),
   .....:     (63, datetime.datetime(2010, 10, 20), "Z", 5.73, True),
   .....: ]
   .....: 

In [618]: data = pd.DataFrame(d, columns=c)

In [619]: data
Out[619]: 
   id       Date Col_1  Col_2  Col_3
0  26 2010-10-18     X  27.50   True
1  42 2010-10-19     Y -12.50  False
2  63 2010-10-20     Z   5.73   True

In [620]: data.to_sql("data", engine)
Out[620]: 3

---->   pandas.DataFrame; DataFrame.to_sql

--------------------------------------
ID: 3302 --> 1
In [621]: data.to_sql("data_chunked", engine, chunksize=1000)
Out[621]: 3

---->   DataFrame.to_sql

--------------------------------------
ID: 3303 --> 1
In [622]: from sqlalchemy.types import String

In [623]: data.to_sql("data_dtype", engine, dtype={"Col_1": String})
Out[623]: 3

---->   DataFrame.to_sql

--------------------------------------
ID: 3305 --> 1
In [624]: pd.read_sql_table("data", engine)
Out[624]: 
   index  id       Date Col_1  Col_2  Col_3
0      0  26 2010-10-18     X  27.50   True
1      1  42 2010-10-19     Y -12.50  False
2      2  63 2010-10-20     Z   5.73   True

---->   pandas.read_sql_table

--------------------------------------
ID: 3306 --> 1
In [625]: pd.read_sql_table("data", engine, index_col="id")
Out[625]: 
    index       Date Col_1  Col_2  Col_3
id                                      
26      0 2010-10-18     X  27.50   True
42      1 2010-10-19     Y -12.50  False
63      2 2010-10-20     Z   5.73   True

In [626]: pd.read_sql_table("data", engine, columns=["Col_1", "Col_2"])
Out[626]: 
  Col_1  Col_2
0     X  27.50
1     Y -12.50
2     Z   5.73

---->   pandas.read_sql_table

--------------------------------------
ID: 3307 --> 1
In [627]: pd.read_sql_table("data", engine, parse_dates=["Date"])
Out[627]: 
   index  id       Date Col_1  Col_2  Col_3
0      0  26 2010-10-18     X  27.50   True
1      1  42 2010-10-19     Y -12.50  False
2      2  63 2010-10-20     Z   5.73   True

---->   pandas.read_sql_table

--------------------------------------
ID: 3308 --> 1
pd.read_sql_table("data", engine, parse_dates={"Date": "%Y-%m-%d"})
pd.read_sql_table(
    "data",
    engine,
    parse_dates={"Date": {"format": "%Y-%m-%d %H:%M:%S"}},
)

---->   pandas.read_sql_table

--------------------------------------
ID: 3309 --> 2
df.to_sql("table", engine, schema="other_schema")
pd.read_sql_table("table", engine, schema="other_schema")

---->   DataFrame.to_sql; pandas.read_sql_table

--------------------------------------
ID: 3310 --> 1
In [628]: pd.read_sql_query("SELECT * FROM data", engine)
Out[628]: 
   index  id                        Date Col_1  Col_2  Col_3
0      0  26  2010-10-18 00:00:00.000000     X  27.50      1
1      1  42  2010-10-19 00:00:00.000000     Y -12.50      0
2      2  63  2010-10-20 00:00:00.000000     Z   5.73      1

---->   pandas.read_sql_query

--------------------------------------
ID: 3311 --> 1
In [629]: pd.read_sql_query("SELECT id, Col_1, Col_2 FROM data WHERE id = 42;", engine)
Out[629]: 
   id Col_1  Col_2
0  42     Y  -12.5

---->   pandas.read_sql_query

--------------------------------------
ID: 3312 --> 2
In [630]: df = pd.DataFrame(np.random.randn(20, 3), columns=list("abc"))

In [631]: df.to_sql("data_chunks", engine, index=False)
Out[631]: 20

---->   pandas.DataFrame; DataFrame.to_sql

--------------------------------------
ID: 3313 --> 1
In [632]: for chunk in pd.read_sql_query("SELECT * FROM data_chunks", engine, chunksize=5):
   .....:     print(chunk)
   .....: 
          a         b         c
0 -0.517871 -0.990317 -0.294348
1  0.335844 -0.794159  1.495614
2 -0.231342  0.557402  0.860312
3 -0.538674 -0.541986 -1.759606
4 -1.520478 -1.069391 -0.551981
          a         b         c
0  0.452407  0.409257  0.301911
1 -0.640843 -2.253022 -0.395347
2 -0.822726 -0.363777  1.676124
3 -0.908102 -1.391346 -1.094269
4  0.278380  1.205899  1.503443
          a         b         c
0  0.932171 -0.709459 -0.645944
1 -1.351389  0.132023  0.210427
2  0.192202  0.661949  1.690629
3 -1.046044  0.618697 -0.013863
4  1.314289  1.951611 -1.485026
          a         b         c
0  0.304662  1.194757 -0.446717
1  0.528496 -0.657575 -0.876654
2  0.336252  0.172668  0.337684
3 -0.411202 -0.828394 -0.244413
4  1.094948  0.087183  1.125934

---->   pandas.read_sql_query

--------------------------------------
ID: 3315 --> 1
In [633]: import sqlalchemy as sa

In [634]: pd.read_sql(
   .....:     sa.text("SELECT * FROM data where Col_1=:col1"), engine, params={"col1": "X"}
   .....: )
   .....: 
Out[634]: 
   index  id                        Date Col_1  Col_2  Col_3
0      0  26  2010-10-18 00:00:00.000000     X   27.5      1

---->   pandas.read_sql

--------------------------------------
ID: 3316 --> 1
In [635]: metadata = sa.MetaData()

In [636]: data_table = sa.Table(
   .....:     "data",
   .....:     metadata,
   .....:     sa.Column("index", sa.Integer),
   .....:     sa.Column("Date", sa.DateTime),
   .....:     sa.Column("Col_1", sa.String),
   .....:     sa.Column("Col_2", sa.Float),
   .....:     sa.Column("Col_3", sa.Boolean),
   .....: )
   .....: 

In [637]: pd.read_sql(sa.select(data_table).where(data_table.c.Col_3 is True), engine)
Out[637]: 
Empty DataFrame
Columns: [index, Date, Col_1, Col_2, Col_3]
Index: []

---->   pandas.read_sql

--------------------------------------
ID: 3317 --> 1
In [638]: import datetime as dt

In [639]: expr = sa.select(data_table).where(data_table.c.Date > sa.bindparam("date"))

In [640]: pd.read_sql(expr, engine, params={"date": dt.datetime(2010, 10, 18)})
Out[640]: 
   index       Date Col_1  Col_2  Col_3
0      1 2010-10-19     Y -12.50  False
1      2 2010-10-20     Z   5.73   True

---->   pandas.read_sql

--------------------------------------
ID: 3319 --> 2
data.to_sql("data", con)
pd.read_sql_query("SELECT * FROM data", con)

---->   DataFrame.to_sql; pandas.read_sql_query

--------------------------------------
ID: 3320 --> 1
In [641]: df = pd.DataFrame(np.random.randn(10, 2), columns=list("AB"))

In [642]: df.to_stata("stata.dta")

---->   pandas.DataFrame

--------------------------------------
ID: 3326 --> 1
df = pd.read_spss("spss_data.sav")

---->   pandas.read_spss

--------------------------------------
ID: 3327 --> 1
df = pd.read_spss(
    "spss_data.sav",
    usecols=["foo", "bar"],
    convert_categoricals=False,
)

---->   pandas.read_spss

--------------------------------------
ID: 3328 --> 2
In [1]: sz = 1000000
In [2]: df = pd.DataFrame({'A': np.random.randn(sz), 'B': [1] * sz})

In [3]: df.info()

RangeIndex: 1000000 entries, 0 to 999999
Data columns (total 2 columns):
A    1000000 non-null float64
B    1000000 non-null int64
dtypes: float64(1), int64(1)
memory usage: 15.3 MB

---->   pandas.DataFrame; DataFrame.info

--------------------------------------
ID: 3329 --> 12
import numpy as np

import os

sz = 1000000
df = pd.DataFrame({"A": np.random.randn(sz), "B": [1] * sz})

sz = 1000000
np.random.seed(42)
df = pd.DataFrame({"A": np.random.randn(sz), "B": [1] * sz})


def test_sql_write(df):
    if os.path.exists("test.sql"):
        os.remove("test.sql")
    sql_db = sqlite3.connect("test.sql")
    df.to_sql(name="test_table", con=sql_db)
    sql_db.close()


def test_sql_read():
    sql_db = sqlite3.connect("test.sql")
    pd.read_sql_query("select * from test_table", sql_db)
    sql_db.close()


def test_hdf_fixed_write(df):
    df.to_hdf("test_fixed.hdf", "test", mode="w")


def test_hdf_fixed_read():
    pd.read_hdf("test_fixed.hdf", "test")


def test_hdf_fixed_write_compress(df):
    df.to_hdf("test_fixed_compress.hdf", "test", mode="w", complib="blosc")


def test_hdf_fixed_read_compress():
    pd.read_hdf("test_fixed_compress.hdf", "test")


def test_hdf_table_write(df):
    df.to_hdf("test_table.hdf", "test", mode="w", format="table")


def test_hdf_table_read():
    pd.read_hdf("test_table.hdf", "test")


def test_hdf_table_write_compress(df):
    df.to_hdf(
        "test_table_compress.hdf", "test", mode="w", complib="blosc", format="table"
    )


def test_hdf_table_read_compress():
    pd.read_hdf("test_table_compress.hdf", "test")


def test_csv_write(df):
    df.to_csv("test.csv", mode="w")


def test_csv_read():
    pd.read_csv("test.csv", index_col=0)


def test_feather_write(df):
    df.to_feather("test.feather")


def test_feather_read():
    pd.read_feather("test.feather")


def test_pickle_write(df):
    df.to_pickle("test.pkl")


def test_pickle_read():
    pd.read_pickle("test.pkl")


def test_pickle_write_compress(df):
    df.to_pickle("test.pkl.compress", compression="xz")


def test_pickle_read_compress():
    pd.read_pickle("test.pkl.compress", compression="xz")


def test_parquet_write(df):
    df.to_parquet("test.parquet")


def test_parquet_read():
    pd.read_parquet("test.parquet")

---->   pandas.DataFrame; DataFrame.to_sql; pandas.read_sql_query; DataFrame.to_hdf; pandas.read_hdf; DataFrame.to_csv; DataFrame.to_feather; pandas.read_feather; DataFrame.to_pickle; pandas.read_pickle; DataFrame.to_parquet; pandas.read_parquet

--------------------------------------
ID: 3332 --> 1
In [1]: df = pd.DataFrame(
   ...:     {
   ...:         "a": np.random.randn(1000),
   ...:         "b": np.random.randn(1000),
   ...:         "N": np.random.randint(100, 1000, (1000)),
   ...:         "x": "x",
   ...:     }
   ...: )
   ...: 

In [2]: df
Out[2]: 
            a         b    N  x
0    0.469112 -0.218470  585  x
1   -0.282863 -0.061645  841  x
2   -1.509059 -0.723780  251  x
3   -1.135632  0.551225  972  x
4    1.212112 -0.497767  181  x
..        ...       ...  ... ..
995 -1.512743  0.874737  374  x
996  0.933753  1.120790  246  x
997 -0.308013  0.198768  157  x
998 -0.079915  1.757555  977  x
999 -1.010589 -1.115680  770  x

[1000 rows x 4 columns]

---->   pandas.DataFrame

--------------------------------------
ID: 3348 --> 2
In [1]: data = pd.Series(range(1_000_000))  # noqa: E225

In [2]: roll = data.rolling(10)

In [3]: def f(x):
   ...:     return np.sum(x) + 5
# Run the first time, compilation time will affect performance
In [4]: %timeit -r 1 -n 1 roll.apply(f, engine='numba', raw=True)
1.23 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)
# Function is cached and performance will improve
In [5]: %timeit roll.apply(f, engine='numba', raw=True)
188 ms ± 1.93 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)

In [6]: %timeit roll.apply(f, engine='cython', raw=True)
3.92 s ± 59 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)

---->   pandas.Series; Series.rolling

--------------------------------------
ID: 3349 --> 2
In [1]: import numba

In [2]: numba.set_num_threads(1)

In [3]: df = pd.DataFrame(np.random.randn(10_000, 100))

In [4]: roll = df.rolling(100)

In [5]: %timeit roll.mean(engine="numba", engine_kwargs={"parallel": True})
347 ms ± 26 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)

In [6]: numba.set_num_threads(2)

In [7]: %timeit roll.mean(engine="numba", engine_kwargs={"parallel": True})
201 ms ± 2.97 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)

---->   pandas.DataFrame; DataFrame.rolling

--------------------------------------
ID: 3350 --> 1
import numba


@numba.jit
def f_plain(x):
    return x * (x - 1)


@numba.jit
def integrate_f_numba(a, b, N):
    s = 0
    dx = (b - a) / N
    for i in range(N):
        s += f_plain(a + i * dx)
    return s * dx


@numba.jit
def apply_integrate_f_numba(col_a, col_b, col_N):
    n = len(col_N)
    result = np.empty(n, dtype="float64")
    assert len(col_a) == len(col_b) == n
    for i in range(n):
        result[i] = integrate_f_numba(col_a[i], col_b[i], col_N[i])
    return result


def compute_numba(df):
    result = apply_integrate_f_numba(
        df["a"].to_numpy(), df["b"].to_numpy(), df["N"].to_numpy()
    )
    return pd.Series(result, index=df.index, name="result")

---->   pandas.Series

--------------------------------------
ID: 3354 --> 1
In [18]: nrows, ncols = 20000, 100

In [19]: df1, df2, df3, df4 = [pd.DataFrame(np.random.randn(nrows, ncols)) for _ in range(4)]

---->   pandas.DataFrame

--------------------------------------
ID: 3359 --> 1
In [24]: s = pd.Series(np.random.randn(50))

In [25]: %timeit df1 + df2 + df3 + df4 + s
26.4 ms +- 416 us per loop (mean +- std. dev. of 7 runs, 10 loops each)

---->   pandas.Series

--------------------------------------
ID: 3361 --> 1
In [27]: df = pd.DataFrame(np.random.randn(5, 2), columns=["a", "b"])

In [28]: df.eval("a + b")
Out[28]: 
0   -0.246747
1    0.867786
2   -1.626063
3   -1.134978
4   -1.027798
dtype: float64

---->   pandas.DataFrame

--------------------------------------
ID: 3362 --> 1
In [29]: df = pd.DataFrame(dict(a=range(5), b=range(5, 10)))

In [30]: df = df.eval("c = a + b")

In [31]: df = df.eval("d = a + b + c")

In [32]: df = df.eval("a = 1")

In [33]: df
Out[33]: 
   a  b   c   d
0  1  5   5  10
1  1  6   7  14
2  1  7   9  18
3  1  8  11  22
4  1  9  13  26

---->   pandas.DataFrame

--------------------------------------
ID: 3365 --> 1
In [38]: df = pd.DataFrame(dict(a=range(5), b=range(5, 10)))

In [39]: df["c"] = df["a"] + df["b"]

In [40]: df["d"] = df["a"] + df["b"] + df["c"]

In [41]: df["a"] = 1

In [42]: df
Out[42]: 
   a  b   c   d
0  1  5   5  10
1  1  6   7  14
2  1  7   9  18
3  1  8  11  22
4  1  9  13  26

---->   pandas.DataFrame

--------------------------------------
ID: 3366 --> 1
In [43]: df = pd.DataFrame(np.random.randn(5, 2), columns=list("ab"))

In [44]: newcol = np.random.randn(len(df))

In [45]: df.eval("b + @newcol")
Out[45]: 
0   -0.173926
1    2.493083
2   -0.881831
3   -0.691045
4    1.334703
dtype: float64

In [46]: df.query("b < @newcol")
Out[46]: 
          a         b
0  0.863987 -0.115998
2 -2.621419 -1.297879

---->   pandas.DataFrame

--------------------------------------
ID: 3374 --> 1
In [65]: df = pd.DataFrame(
   ....:     {"strings": np.repeat(list("cba"), 3), "nums": np.repeat(range(3), 3)}
   ....: )
   ....: 

In [66]: df
Out[66]: 
  strings  nums
0       c     0
1       c     0
2       c     0
3       b     1
4       b     1
5       b     1
6       a     2
7       a     2
8       a     2

In [67]: df.query("strings == 'a' and nums == 1")
Out[67]: 
Empty DataFrame
Columns: [strings, nums]
Index: []

---->   pandas.DataFrame

--------------------------------------
ID: 3375 --> 1
In [1]: import pandas as pd

In [2]: import numpy as np

In [3]: def make_timeseries(start="2000-01-01", end="2000-12-31", freq="1D", seed=None):
   ...:     index = pd.date_range(start=start, end=end, freq=freq, name="timestamp")
   ...:     n = len(index)
   ...:     state = np.random.RandomState(seed)
   ...:     columns = {
   ...:         "name": state.choice(["Alice", "Bob", "Charlie"], size=n),
   ...:         "id": state.poisson(1000, size=n),
   ...:         "x": state.rand(n) * 2 - 1,
   ...:         "y": state.rand(n) * 2 - 1,
   ...:     }
   ...:     df = pd.DataFrame(columns, index=index, columns=sorted(columns))
   ...:     if df.index[-1] == end:
   ...:         df = df.iloc[:-1]
   ...:     return df
   ...: 

In [4]: timeseries = [
   ...:     make_timeseries(freq="1T", seed=i).rename(columns=lambda x: f"{x}_{i}")
   ...:     for i in range(10)
   ...: ]
   ...: 

In [5]: ts_wide = pd.concat(timeseries, axis=1)

In [6]: ts_wide.to_parquet("timeseries_wide.parquet")

---->   pandas.DataFrame

--------------------------------------
ID: 3376 --> 1
In [7]: columns = ["id_0", "name_0", "x_0", "y_0"]

In [8]: pd.read_parquet("timeseries_wide.parquet")[columns]
Out[8]: 
                     id_0 name_0       x_0       y_0
timestamp                                           
2000-01-01 00:00:00   977  Alice -0.821225  0.906222
2000-01-01 00:01:00  1018    Bob -0.219182  0.350855
2000-01-01 00:02:00   927  Alice  0.660908 -0.798511
2000-01-01 00:03:00   997    Bob -0.852458  0.735260
2000-01-01 00:04:00   965    Bob  0.717283  0.393391
...                   ...    ...       ...       ...
2000-12-30 23:56:00  1037    Bob -0.814321  0.612836
2000-12-30 23:57:00   980    Bob  0.232195 -0.618828
2000-12-30 23:58:00   965  Alice -0.231131  0.026310
2000-12-30 23:59:00   984  Alice  0.942819  0.853128
2000-12-31 00:00:00  1003  Alice  0.201125 -0.136655

[525601 rows x 4 columns]

---->   pandas.read_parquet

--------------------------------------
ID: 3377 --> 1
In [9]: pd.read_parquet("timeseries_wide.parquet", columns=columns)
Out[9]: 
                     id_0 name_0       x_0       y_0
timestamp                                           
2000-01-01 00:00:00   977  Alice -0.821225  0.906222
2000-01-01 00:01:00  1018    Bob -0.219182  0.350855
2000-01-01 00:02:00   927  Alice  0.660908 -0.798511
2000-01-01 00:03:00   997    Bob -0.852458  0.735260
2000-01-01 00:04:00   965    Bob  0.717283  0.393391
...                   ...    ...       ...       ...
2000-12-30 23:56:00  1037    Bob -0.814321  0.612836
2000-12-30 23:57:00   980    Bob  0.232195 -0.618828
2000-12-30 23:58:00   965  Alice -0.231131  0.026310
2000-12-30 23:59:00   984  Alice  0.942819  0.853128
2000-12-31 00:00:00  1003  Alice  0.201125 -0.136655

[525601 rows x 4 columns]

---->   pandas.read_parquet

--------------------------------------
ID: 3378 --> 1
In [10]: ts = make_timeseries(freq="30S", seed=0)

In [11]: ts.to_parquet("timeseries.parquet")

In [12]: ts = pd.read_parquet("timeseries.parquet")

In [13]: ts
Out[13]: 
                       id     name         x         y
timestamp                                             
2000-01-01 00:00:00  1041    Alice  0.889987  0.281011
2000-01-01 00:00:30   988      Bob -0.455299  0.488153
2000-01-01 00:01:00  1018    Alice  0.096061  0.580473
2000-01-01 00:01:30   992      Bob  0.142482  0.041665
2000-01-01 00:02:00   960      Bob -0.036235  0.802159
...                   ...      ...       ...       ...
2000-12-30 23:58:00  1022    Alice  0.266191  0.875579
2000-12-30 23:58:30   974    Alice -0.009826  0.413686
2000-12-30 23:59:00  1028  Charlie  0.307108 -0.656789
2000-12-30 23:59:30  1002    Alice  0.202602  0.541335
2000-12-31 00:00:00   987    Alice  0.200832  0.615972

[1051201 rows x 4 columns]

---->   pandas.read_parquet

--------------------------------------
ID: 3379 --> 1
In [15]: ts.memory_usage(deep=True)  # memory usage in bytes
Out[15]: 
Index     8409608
id        8409608
name     65176434
x         8409608
y         8409608
dtype: int64

---->   Series.memory_usage

--------------------------------------
ID: 3380 --> 2
In [16]: ts2 = ts.copy()

In [17]: ts2["name"] = ts2["name"].astype("category")

In [18]: ts2.memory_usage(deep=True)
Out[18]: 
Index    8409608
id       8409608
name     1051495
x        8409608
y        8409608
dtype: int64

---->   Series.copy; Series.memory_usage

--------------------------------------
ID: 3381 --> 1
In [19]: ts2["id"] = pd.to_numeric(ts2["id"], downcast="unsigned")

In [20]: ts2[["x", "y"]] = ts2[["x", "y"]].apply(pd.to_numeric, downcast="float")

In [21]: ts2.dtypes
Out[21]: 
id        uint16
name    category
x        float32
y        float32
dtype: object

---->   pandas.to_numeric

--------------------------------------
ID: 3382 --> 1
In [22]: ts2.memory_usage(deep=True)
Out[22]: 
Index    8409608
id       2102402
name     1051495
x        4204804
y        4204804
dtype: int64

---->   Series.memory_usage

--------------------------------------
ID: 3383 --> 2
In [23]: reduction = ts2.memory_usage(deep=True).sum() / ts.memory_usage(deep=True).sum()

In [24]: print(f"{reduction:0.2f}")
0.20

---->   Series.memory_usage; Series.memory_usage

--------------------------------------
ID: 3385 --> 2
In [31]: %%time
   ....: files = pathlib.Path("data/timeseries/").glob("ts*.parquet")
   ....: counts = pd.Series(dtype=int)
   ....: for path in files:
   ....:     df = pd.read_parquet(path)
   ....:     counts = counts.add(df["name"].value_counts(), fill_value=0)
   ....: counts.astype(int)
   ....: 
CPU times: user 910 ms, sys: 73 ms, total: 983 ms
Wall time: 771 ms
Out[31]: 
name
Alice      1994645
Bob        1993692
Charlie    1994875
dtype: int64

---->   pandas.Series; pandas.read_parquet

--------------------------------------
ID: 3392 --> 1
In [43]: N = 12

In [44]: starts = [f"20{i:>02d}-01-01" for i in range(N)]

In [45]: ends = [f"20{i:>02d}-12-13" for i in range(N)]

In [46]: divisions = tuple(pd.to_datetime(starts)) + (pd.Timestamp(ends[-1]),)

In [47]: ddf.divisions = divisions

In [48]: ddf
Out[48]: 
Dask DataFrame Structure:
                   id    name        x        y
npartitions=12                                 
2000-01-01      int64  object  float64  float64
2001-01-01        ...     ...      ...      ...
...               ...     ...      ...      ...
2011-01-01        ...     ...      ...      ...
2011-12-13        ...     ...      ...      ...
Dask Name: read-parquet, 1 graph layer

---->   pandas.to_datetime

--------------------------------------
ID: 3411 --> 1
>>> pd.test()
running: pytest --skip-slow --skip-network --skip-db /home/user/anaconda3/lib/python3.9/site-packages/pandas

============================= test session starts ==============================
platform linux -- Python 3.9.7, pytest-6.2.5, py-1.11.0, pluggy-1.0.0
rootdir: /home/user
plugins: dash-1.19.0, anyio-3.5.0, hypothesis-6.29.3
collected 154975 items / 4 skipped / 154971 selected
........................................................................ [  0%]
........................................................................ [ 99%]
.......................................                                  [100%]

==================================== ERRORS ====================================

=================================== FAILURES ===================================

=============================== warnings summary ===============================

=========================== short test summary info ============================

= 1 failed, 146194 passed, 7402 skipped, 1367 xfailed, 5 xpassed, 197 warnings, 10 errors in 1090.16s (0:18:10) =

---->   pandas.test

--------------------------------------
ID: 3418 --> 1
In [1]: import datetime

In [2]: dti = pd.to_datetime(
   ...:     ["1/1/2018", np.datetime64("2018-01-01"), datetime.datetime(2018, 1, 1)]
   ...: )
   ...: 

In [3]: dti
Out[3]: DatetimeIndex(['2018-01-01', '2018-01-01', '2018-01-01'], dtype='datetime64[ns]', freq=None)

---->   pandas.to_datetime

--------------------------------------
ID: 3421 --> 2
In [9]: idx = pd.date_range("2018-01-01", periods=5, freq="H")

In [10]: ts = pd.Series(range(len(idx)), index=idx)

In [11]: ts
Out[11]: 
2018-01-01 00:00:00    0
2018-01-01 01:00:00    1
2018-01-01 02:00:00    2
2018-01-01 03:00:00    3
2018-01-01 04:00:00    4
Freq: H, dtype: int64

In [12]: ts.resample("2H").mean()
Out[12]: 
2018-01-01 00:00:00    0.5
2018-01-01 02:00:00    2.5
2018-01-01 04:00:00    4.0
Freq: 2H, dtype: float64

---->   pandas.Series; Series.resample

--------------------------------------
ID: 3423 --> 1
In [19]: pd.Series(range(3), index=pd.date_range("2000", freq="D", periods=3))
Out[19]: 
2000-01-01    0
2000-01-02    1
2000-01-03    2
Freq: D, dtype: int64

---->   pandas.Series

--------------------------------------
ID: 3424 --> 1
In [20]: pd.Series(pd.date_range("2000", freq="D", periods=3))
Out[20]: 
0   2000-01-01
1   2000-01-02
2   2000-01-03
dtype: datetime64[ns]

---->   pandas.Series

--------------------------------------
ID: 3425 --> 2
In [21]: pd.Series(pd.period_range("1/1/2011", freq="M", periods=3))
Out[21]: 
0    2011-01
1    2011-02
2    2011-03
dtype: period[M]

In [22]: pd.Series([pd.DateOffset(1), pd.DateOffset(2)])
Out[22]: 
0         
1    <2 * DateOffsets>
dtype: object

In [23]: pd.Series(pd.date_range("1/1/2011", freq="M", periods=3))
Out[23]: 
0   2011-01-31
1   2011-02-28
2   2011-03-31
dtype: datetime64[ns]

---->   pandas.Series; pandas.period_range

--------------------------------------
ID: 3426 --> 1
In [24]: pd.Timestamp(pd.NaT)
Out[24]: NaT

In [25]: pd.Timedelta(pd.NaT)
Out[25]: NaT

In [26]: pd.Period(pd.NaT)
Out[26]: NaT

# Equality acts as np.nan would
In [27]: pd.NaT == pd.NaT
Out[27]: False

---->   pandas.Period

--------------------------------------
ID: 3428 --> 1
In [32]: pd.Period("2011-01")
Out[32]: Period('2011-01', 'M')

In [33]: pd.Period("2012-05", freq="D")
Out[33]: Period('2012-05-01', 'D')

---->   pandas.Period

--------------------------------------
ID: 3429 --> 2
In [34]: dates = [
   ....:     pd.Timestamp("2012-05-01"),
   ....:     pd.Timestamp("2012-05-02"),
   ....:     pd.Timestamp("2012-05-03"),
   ....: ]
   ....: 

In [35]: ts = pd.Series(np.random.randn(3), dates)

In [36]: type(ts.index)
Out[36]: pandas.core.indexes.datetimes.DatetimeIndex

In [37]: ts.index
Out[37]: DatetimeIndex(['2012-05-01', '2012-05-02', '2012-05-03'], dtype='datetime64[ns]', freq=None)

In [38]: ts
Out[38]: 
2012-05-01    0.469112
2012-05-02   -0.282863
2012-05-03   -1.509059
dtype: float64

In [39]: periods = [pd.Period("2012-01"), pd.Period("2012-02"), pd.Period("2012-03")]

In [40]: ts = pd.Series(np.random.randn(3), periods)

In [41]: type(ts.index)
Out[41]: pandas.core.indexes.period.PeriodIndex

In [42]: ts.index
Out[42]: PeriodIndex(['2012-01', '2012-02', '2012-03'], dtype='period[M]')

In [43]: ts
Out[43]: 
2012-01   -1.135632
2012-02    1.212112
2012-03   -0.173215
Freq: M, dtype: float64

---->   pandas.Series; pandas.Period

--------------------------------------
ID: 3430 --> 2
In [44]: pd.to_datetime(pd.Series(["Jul 31, 2009", "Jan 10, 2010", None]))
Out[44]: 
0   2009-07-31
1   2010-01-10
2          NaT
dtype: datetime64[ns]

In [45]: pd.to_datetime(["2005/11/23", "2010/12/31"])
Out[45]: DatetimeIndex(['2005-11-23', '2010-12-31'], dtype='datetime64[ns]', freq=None)

---->   pandas.to_datetime; pandas.Series

--------------------------------------
ID: 3431 --> 1
In [46]: pd.to_datetime(["04-01-2012 10:00"], dayfirst=True)
Out[46]: DatetimeIndex(['2012-01-04 10:00:00'], dtype='datetime64[ns]', freq=None)

In [47]: pd.to_datetime(["04-14-2012 10:00"], dayfirst=True)
Out[47]: DatetimeIndex(['2012-04-14 10:00:00'], dtype='datetime64[ns]', freq=None)

---->   pandas.to_datetime

--------------------------------------
ID: 3432 --> 1
In [48]: pd.to_datetime("2010/11/12")
Out[48]: Timestamp('2010-11-12 00:00:00')

In [49]: pd.Timestamp("2010/11/12")
Out[49]: Timestamp('2010-11-12 00:00:00')

---->   pandas.to_datetime

--------------------------------------
ID: 3433 --> 1
In [50]: pd.DatetimeIndex(["2018-01-01", "2018-01-03", "2018-01-05"])
Out[50]: DatetimeIndex(['2018-01-01', '2018-01-03', '2018-01-05'], dtype='datetime64[ns]', freq=None)

---->   pandas.DatetimeIndex

--------------------------------------
ID: 3434 --> 1
In [51]: pd.DatetimeIndex(["2018-01-01", "2018-01-03", "2018-01-05"], freq="infer")
Out[51]: DatetimeIndex(['2018-01-01', '2018-01-03', '2018-01-05'], dtype='datetime64[ns]', freq='2D')

---->   pandas.DatetimeIndex

--------------------------------------
ID: 3435 --> 1
In [52]: pd.to_datetime("2010/11/12", format="%Y/%m/%d")
Out[52]: Timestamp('2010-11-12 00:00:00')

In [53]: pd.to_datetime("12-11-2010 00:00", format="%d-%m-%Y %H:%M")
Out[53]: Timestamp('2010-11-12 00:00:00')

---->   pandas.to_datetime

--------------------------------------
ID: 3436 --> 2
In [54]: df = pd.DataFrame(
   ....:     {"year": [2015, 2016], "month": [2, 3], "day": [4, 5], "hour": [2, 3]}
   ....: )
   ....: 

In [55]: pd.to_datetime(df)
Out[55]: 
0   2015-02-04 02:00:00
1   2016-03-05 03:00:00
dtype: datetime64[ns]

---->   pandas.DataFrame; pandas.to_datetime

--------------------------------------
ID: 3437 --> 1
In [56]: pd.to_datetime(df[["year", "month", "day"]])
Out[56]: 
0   2015-02-04
1   2016-03-05
dtype: datetime64[ns]

---->   pandas.to_datetime

--------------------------------------
ID: 3438 --> 1
In [2]: pd.to_datetime(['2009/07/31', 'asd'], errors='raise')
ValueError: Unknown datetime string format

---->   pandas.to_datetime

--------------------------------------
ID: 3439 --> 1
In [57]: pd.to_datetime(["2009/07/31", "asd"], errors="ignore")
Out[57]: Index(['2009/07/31', 'asd'], dtype='object')

---->   pandas.to_datetime

--------------------------------------
ID: 3440 --> 1
In [58]: pd.to_datetime(["2009/07/31", "asd"], errors="coerce")
Out[58]: DatetimeIndex(['2009-07-31', 'NaT'], dtype='datetime64[ns]', freq=None)

---->   pandas.to_datetime

--------------------------------------
ID: 3441 --> 1
In [59]: pd.to_datetime(
   ....:     [1349720105, 1349806505, 1349892905, 1349979305, 1350065705], unit="s"
   ....: )
   ....: 
Out[59]: 
DatetimeIndex(['2012-10-08 18:15:05', '2012-10-09 18:15:05',
               '2012-10-10 18:15:05', '2012-10-11 18:15:05',
               '2012-10-12 18:15:05'],
              dtype='datetime64[ns]', freq=None)

In [60]: pd.to_datetime(
   ....:     [1349720105100, 1349720105200, 1349720105300, 1349720105400, 1349720105500],
   ....:     unit="ms",
   ....: )
   ....: 
Out[60]: 
DatetimeIndex(['2012-10-08 18:15:05.100000', '2012-10-08 18:15:05.200000',
               '2012-10-08 18:15:05.300000', '2012-10-08 18:15:05.400000',
               '2012-10-08 18:15:05.500000'],
              dtype='datetime64[ns]', freq=None)

---->   pandas.to_datetime

--------------------------------------
ID: 3442 --> 1
In [61]: pd.Timestamp(1262347200000000000).tz_localize("US/Pacific")
Out[61]: Timestamp('2010-01-01 12:00:00-0800', tz='US/Pacific')

In [62]: pd.DatetimeIndex([1262347200000000000]).tz_localize("US/Pacific")
Out[62]: DatetimeIndex(['2010-01-01 12:00:00-08:00'], dtype='datetime64[ns, US/Pacific]', freq=None)

---->   pandas.DatetimeIndex

--------------------------------------
ID: 3443 --> 1
In [63]: pd.to_datetime([1490195805.433, 1490195805.433502912], unit="s")
Out[63]: DatetimeIndex(['2017-03-22 15:16:45.433000088', '2017-03-22 15:16:45.433502913'], dtype='datetime64[ns]', freq=None)

In [64]: pd.to_datetime(1490195805433502912, unit="ns")
Out[64]: Timestamp('2017-03-22 15:16:45.433502912')

---->   pandas.to_datetime

--------------------------------------
ID: 3446 --> 1
In [68]: pd.to_datetime([1, 2, 3], unit="D", origin=pd.Timestamp("1960-01-01"))
Out[68]: DatetimeIndex(['1960-01-02', '1960-01-03', '1960-01-04'], dtype='datetime64[ns]', freq=None)

---->   pandas.to_datetime

--------------------------------------
ID: 3447 --> 1
In [69]: pd.to_datetime([1, 2, 3], unit="D")
Out[69]: DatetimeIndex(['1970-01-02', '1970-01-03', '1970-01-04'], dtype='datetime64[ns]', freq=None)

---->   pandas.to_datetime

--------------------------------------
ID: 3448 --> 2
In [70]: dates = [
   ....:     datetime.datetime(2012, 5, 1),
   ....:     datetime.datetime(2012, 5, 2),
   ....:     datetime.datetime(2012, 5, 3),
   ....: ]
   ....: 

# Note the frequency information
In [71]: index = pd.DatetimeIndex(dates)

In [72]: index
Out[72]: DatetimeIndex(['2012-05-01', '2012-05-02', '2012-05-03'], dtype='datetime64[ns]', freq=None)

# Automatically converted to DatetimeIndex
In [73]: index = pd.Index(dates)

In [74]: index
Out[74]: DatetimeIndex(['2012-05-01', '2012-05-02', '2012-05-03'], dtype='datetime64[ns]', freq=None)

---->   pandas.DatetimeIndex; pandas.Index

--------------------------------------
ID: 3449 --> 1
In [75]: start = datetime.datetime(2011, 1, 1)

In [76]: end = datetime.datetime(2012, 1, 1)

In [77]: index = pd.date_range(start, end)

In [78]: index
Out[78]: 
DatetimeIndex(['2011-01-01', '2011-01-02', '2011-01-03', '2011-01-04',
               '2011-01-05', '2011-01-06', '2011-01-07', '2011-01-08',
               '2011-01-09', '2011-01-10',
               ...
               '2011-12-23', '2011-12-24', '2011-12-25', '2011-12-26',
               '2011-12-27', '2011-12-28', '2011-12-29', '2011-12-30',
               '2011-12-31', '2012-01-01'],
              dtype='datetime64[ns]', length=366, freq='D')

In [79]: index = pd.bdate_range(start, end)

In [80]: index
Out[80]: 
DatetimeIndex(['2011-01-03', '2011-01-04', '2011-01-05', '2011-01-06',
               '2011-01-07', '2011-01-10', '2011-01-11', '2011-01-12',
               '2011-01-13', '2011-01-14',
               ...
               '2011-12-19', '2011-12-20', '2011-12-21', '2011-12-22',
               '2011-12-23', '2011-12-26', '2011-12-27', '2011-12-28',
               '2011-12-29', '2011-12-30'],
              dtype='datetime64[ns]', length=260, freq='B')

---->   pandas.bdate_range

--------------------------------------
ID: 3450 --> 1
In [81]: pd.date_range(start, periods=1000, freq="M")
Out[81]: 
DatetimeIndex(['2011-01-31', '2011-02-28', '2011-03-31', '2011-04-30',
               '2011-05-31', '2011-06-30', '2011-07-31', '2011-08-31',
               '2011-09-30', '2011-10-31',
               ...
               '2093-07-31', '2093-08-31', '2093-09-30', '2093-10-31',
               '2093-11-30', '2093-12-31', '2094-01-31', '2094-02-28',
               '2094-03-31', '2094-04-30'],
              dtype='datetime64[ns]', length=1000, freq='M')

In [82]: pd.bdate_range(start, periods=250, freq="BQS")
Out[82]: 
DatetimeIndex(['2011-01-03', '2011-04-01', '2011-07-01', '2011-10-03',
               '2012-01-02', '2012-04-02', '2012-07-02', '2012-10-01',
               '2013-01-01', '2013-04-01',
               ...
               '2071-01-01', '2071-04-01', '2071-07-01', '2071-10-01',
               '2072-01-01', '2072-04-01', '2072-07-01', '2072-10-03',
               '2073-01-02', '2073-04-03'],
              dtype='datetime64[ns]', length=250, freq='BQS-JAN')

---->   pandas.bdate_range

--------------------------------------
ID: 3451 --> 1
In [83]: pd.date_range(start, end, freq="BM")
Out[83]: 
DatetimeIndex(['2011-01-31', '2011-02-28', '2011-03-31', '2011-04-29',
               '2011-05-31', '2011-06-30', '2011-07-29', '2011-08-31',
               '2011-09-30', '2011-10-31', '2011-11-30', '2011-12-30'],
              dtype='datetime64[ns]', freq='BM')

In [84]: pd.date_range(start, end, freq="W")
Out[84]: 
DatetimeIndex(['2011-01-02', '2011-01-09', '2011-01-16', '2011-01-23',
               '2011-01-30', '2011-02-06', '2011-02-13', '2011-02-20',
               '2011-02-27', '2011-03-06', '2011-03-13', '2011-03-20',
               '2011-03-27', '2011-04-03', '2011-04-10', '2011-04-17',
               '2011-04-24', '2011-05-01', '2011-05-08', '2011-05-15',
               '2011-05-22', '2011-05-29', '2011-06-05', '2011-06-12',
               '2011-06-19', '2011-06-26', '2011-07-03', '2011-07-10',
               '2011-07-17', '2011-07-24', '2011-07-31', '2011-08-07',
               '2011-08-14', '2011-08-21', '2011-08-28', '2011-09-04',
               '2011-09-11', '2011-09-18', '2011-09-25', '2011-10-02',
               '2011-10-09', '2011-10-16', '2011-10-23', '2011-10-30',
               '2011-11-06', '2011-11-13', '2011-11-20', '2011-11-27',
               '2011-12-04', '2011-12-11', '2011-12-18', '2011-12-25',
               '2012-01-01'],
              dtype='datetime64[ns]', freq='W-SUN')

In [85]: pd.bdate_range(end=end, periods=20)
Out[85]: 
DatetimeIndex(['2011-12-05', '2011-12-06', '2011-12-07', '2011-12-08',
               '2011-12-09', '2011-12-12', '2011-12-13', '2011-12-14',
               '2011-12-15', '2011-12-16', '2011-12-19', '2011-12-20',
               '2011-12-21', '2011-12-22', '2011-12-23', '2011-12-26',
               '2011-12-27', '2011-12-28', '2011-12-29', '2011-12-30'],
              dtype='datetime64[ns]', freq='B')

In [86]: pd.bdate_range(start=start, periods=20)
Out[86]: 
DatetimeIndex(['2011-01-03', '2011-01-04', '2011-01-05', '2011-01-06',
               '2011-01-07', '2011-01-10', '2011-01-11', '2011-01-12',
               '2011-01-13', '2011-01-14', '2011-01-17', '2011-01-18',
               '2011-01-19', '2011-01-20', '2011-01-21', '2011-01-24',
               '2011-01-25', '2011-01-26', '2011-01-27', '2011-01-28'],
              dtype='datetime64[ns]', freq='B')

---->   pandas.bdate_range

--------------------------------------
ID: 3453 --> 1
In [89]: weekmask = "Mon Wed Fri"

In [90]: holidays = [datetime.datetime(2011, 1, 5), datetime.datetime(2011, 3, 14)]

In [91]: pd.bdate_range(start, end, freq="C", weekmask=weekmask, holidays=holidays)
Out[91]: 
DatetimeIndex(['2011-01-03', '2011-01-07', '2011-01-10', '2011-01-12',
               '2011-01-14', '2011-01-17', '2011-01-19', '2011-01-21',
               '2011-01-24', '2011-01-26',
               ...
               '2011-12-09', '2011-12-12', '2011-12-14', '2011-12-16',
               '2011-12-19', '2011-12-21', '2011-12-23', '2011-12-26',
               '2011-12-28', '2011-12-30'],
              dtype='datetime64[ns]', length=154, freq='C')

In [92]: pd.bdate_range(start, end, freq="CBMS", weekmask=weekmask)
Out[92]: 
DatetimeIndex(['2011-01-03', '2011-02-02', '2011-03-02', '2011-04-01',
               '2011-05-02', '2011-06-01', '2011-07-01', '2011-08-01',
               '2011-09-02', '2011-10-03', '2011-11-02', '2011-12-02'],
              dtype='datetime64[ns]', freq='CBMS')

---->   pandas.bdate_range

--------------------------------------
ID: 3455 --> 1
In [95]: rng = pd.date_range(start, end, freq="BM")

In [96]: ts = pd.Series(np.random.randn(len(rng)), index=rng)

In [97]: ts.index
Out[97]: 
DatetimeIndex(['2011-01-31', '2011-02-28', '2011-03-31', '2011-04-29',
               '2011-05-31', '2011-06-30', '2011-07-29', '2011-08-31',
               '2011-09-30', '2011-10-31', '2011-11-30', '2011-12-30'],
              dtype='datetime64[ns]', freq='BM')

In [98]: ts[:5].index
Out[98]: 
DatetimeIndex(['2011-01-31', '2011-02-28', '2011-03-31', '2011-04-29',
               '2011-05-31'],
              dtype='datetime64[ns]', freq='BM')

In [99]: ts[::2].index
Out[99]: 
DatetimeIndex(['2011-01-31', '2011-03-31', '2011-05-31', '2011-07-29',
               '2011-09-30', '2011-11-30'],
              dtype='datetime64[ns]', freq='2BM')

---->   pandas.Series

--------------------------------------
ID: 3457 --> 1
In [105]: dft = pd.DataFrame(
   .....:     np.random.randn(100000, 1),
   .....:     columns=["A"],
   .....:     index=pd.date_range("20130101", periods=100000, freq="T"),
   .....: )
   .....: 

In [106]: dft
Out[106]: 
                            A
2013-01-01 00:00:00  0.276232
2013-01-01 00:01:00 -1.087401
2013-01-01 00:02:00 -0.673690
2013-01-01 00:03:00  0.113648
2013-01-01 00:04:00 -1.478427
...                       ...
2013-03-11 10:35:00 -0.747967
2013-03-11 10:36:00 -0.034523
2013-03-11 10:37:00 -0.201754
2013-03-11 10:38:00 -1.509067
2013-03-11 10:39:00 -1.693043

[100000 rows x 1 columns]

In [107]: dft.loc["2013"]
Out[107]: 
                            A
2013-01-01 00:00:00  0.276232
2013-01-01 00:01:00 -1.087401
2013-01-01 00:02:00 -0.673690
2013-01-01 00:03:00  0.113648
2013-01-01 00:04:00 -1.478427
...                       ...
2013-03-11 10:35:00 -0.747967
2013-03-11 10:36:00 -0.034523
2013-03-11 10:37:00 -0.201754
2013-03-11 10:38:00 -1.509067
2013-03-11 10:39:00 -1.693043

[100000 rows x 1 columns]

---->   pandas.DataFrame

--------------------------------------
ID: 3458 --> 2
In [112]: dft2 = pd.DataFrame(
   .....:     np.random.randn(20, 1),
   .....:     columns=["A"],
   .....:     index=pd.MultiIndex.from_product(
   .....:         [pd.date_range("20130101", periods=10, freq="12H"), ["a", "b"]]
   .....:     ),
   .....: )
   .....: 

In [113]: dft2
Out[113]: 
                              A
2013-01-01 00:00:00 a -0.298694
                    b  0.823553
2013-01-01 12:00:00 a  0.943285
                    b -1.479399
2013-01-02 00:00:00 a -1.643342
...                         ...
2013-01-04 12:00:00 b  0.069036
2013-01-05 00:00:00 a  0.122297
                    b  1.422060
2013-01-05 12:00:00 a  0.370079
                    b  1.016331

[20 rows x 1 columns]

In [114]: dft2.loc["2013-01-05"]
Out[114]: 
                              A
2013-01-05 00:00:00 a  0.122297
                    b  1.422060
2013-01-05 12:00:00 a  0.370079
                    b  1.016331

In [115]: idx = pd.IndexSlice

In [116]: dft2 = dft2.swaplevel(0, 1).sort_index()

In [117]: dft2.loc[idx[:, "2013-01-05"], :]
Out[117]: 
                              A
a 2013-01-05 00:00:00  0.122297
  2013-01-05 12:00:00  0.370079
b 2013-01-05 00:00:00  1.422060
  2013-01-05 12:00:00  1.016331

---->   pandas.DataFrame; pandas.MultiIndex

--------------------------------------
ID: 3459 --> 2
In [118]: df = pd.DataFrame([0], index=pd.DatetimeIndex(["2019-01-01"], tz="US/Pacific"))

In [119]: df
Out[119]: 
                           0
2019-01-01 00:00:00-08:00  0

In [120]: df["2019-01-01 12:00:00+04:00":"2019-01-01 13:00:00+04:00"]
Out[120]: 
                           0
2019-01-01 00:00:00-08:00  0

---->   pandas.DataFrame; pandas.DatetimeIndex

--------------------------------------
ID: 3460 --> 2
In [121]: series_minute = pd.Series(
   .....:     [1, 2, 3],
   .....:     pd.DatetimeIndex(
   .....:         ["2011-12-31 23:59:00", "2012-01-01 00:00:00", "2012-01-01 00:02:00"]
   .....:     ),
   .....: )
   .....: 

In [122]: series_minute.index.resolution
Out[122]: 'minute'

---->   pandas.Series; pandas.DatetimeIndex

--------------------------------------
ID: 3461 --> 2
In [126]: series_second = pd.Series(
   .....:     [1, 2, 3],
   .....:     pd.DatetimeIndex(
   .....:         ["2011-12-31 23:59:59", "2012-01-01 00:00:00", "2012-01-01 00:00:01"]
   .....:     ),
   .....: )
   .....: 

In [127]: series_second.index.resolution
Out[127]: 'second'

In [128]: series_second["2011-12-31 23:59"]
Out[128]: 
2011-12-31 23:59:59    1
dtype: int64

---->   pandas.Series; pandas.DatetimeIndex

--------------------------------------
ID: 3462 --> 1
In [129]: dft_minute = pd.DataFrame(
   .....:     {"a": [1, 2, 3], "b": [4, 5, 6]}, index=series_minute.index
   .....: )
   .....: 

In [130]: dft_minute.loc["2011-12-31 23"]
Out[130]: 
                     a  b
2011-12-31 23:59:00  1  4

---->   pandas.DataFrame

--------------------------------------
ID: 3463 --> 2
In [132]: series_monthly = pd.Series(
   .....:     [1, 2, 3], pd.DatetimeIndex(["2011-12", "2012-01", "2012-02"])
   .....: )
   .....: 

In [133]: series_monthly.index.resolution
Out[133]: 'day'

In [134]: series_monthly["2011-12"]  # returns Series
Out[134]: 
2011-12-01    1
dtype: int64

---->   pandas.Series; pandas.DatetimeIndex

--------------------------------------
ID: 3466 --> 2
In [137]: rng2 = pd.date_range("2011-01-01", "2012-01-01", freq="W")

In [138]: ts2 = pd.Series(np.random.randn(len(rng2)), index=rng2)

In [139]: ts2.truncate(before="2011-11", after="2011-12")
Out[139]: 
2011-11-06    0.437823
2011-11-13   -0.293083
2011-11-20   -0.059881
2011-11-27    1.252450
Freq: W-SUN, dtype: float64

In [140]: ts2["2011-11":"2011-12"]
Out[140]: 
2011-11-06    0.437823
2011-11-13   -0.293083
2011-11-20   -0.059881
2011-11-27    1.252450
2011-12-04    0.046611
2011-12-11    0.059478
2011-12-18   -0.286539
2011-12-25    0.841669
Freq: W-SUN, dtype: float64

---->   pandas.Series; Series.truncate

--------------------------------------
ID: 3468 --> 1
In [142]: idx = pd.date_range(start="2019-12-29", freq="D", periods=4)

In [143]: idx.isocalendar()
Out[143]: 
            year  week  day
2019-12-29  2019    52    7
2019-12-30  2020     1    1
2019-12-31  2020     1    2
2020-01-01  2020     1    3

In [144]: idx.to_series().dt.isocalendar()
Out[144]: 
            year  week  day
2019-12-29  2019    52    7
2019-12-30  2020     1    1
2019-12-31  2020     1    2
2020-01-01  2020     1    3

---->   Index.to_series

--------------------------------------
ID: 3475 --> 1
In [177]: rng = pd.date_range("2012-01-01", "2012-01-03")

In [178]: s = pd.Series(rng)

In [179]: rng
Out[179]: DatetimeIndex(['2012-01-01', '2012-01-02', '2012-01-03'], dtype='datetime64[ns]', freq='D')

In [180]: rng + pd.DateOffset(months=2)
Out[180]: DatetimeIndex(['2012-03-01', '2012-03-02', '2012-03-03'], dtype='datetime64[ns]', freq=None)

In [181]: s + pd.DateOffset(months=2)
Out[181]: 
0   2012-03-01
1   2012-03-02
2   2012-03-03
dtype: datetime64[ns]

In [182]: s - pd.DateOffset(months=2)
Out[182]: 
0   2011-11-01
1   2011-11-02
2   2011-11-03
dtype: datetime64[ns]

---->   pandas.Series

--------------------------------------
ID: 3476 --> 1
In [183]: s - pd.offsets.Day(2)
Out[183]: 
0   2011-12-30
1   2011-12-31
2   2012-01-01
dtype: datetime64[ns]

In [184]: td = s - pd.Series(pd.date_range("2011-12-29", "2011-12-31"))

In [185]: td
Out[185]: 
0   3 days
1   3 days
2   3 days
dtype: timedelta64[ns]

In [186]: td + pd.offsets.Minute(15)
Out[186]: 
0   3 days 00:15:00
1   3 days 00:15:00
2   3 days 00:15:00
dtype: timedelta64[ns]

---->   pandas.Series

--------------------------------------
ID: 3479 --> 1
In [193]: dts = pd.date_range(dt, periods=5, freq=bday_egypt)

In [194]: pd.Series(dts.weekday, dts).map(pd.Series("Mon Tue Wed Thu Fri Sat Sun".split()))
Out[194]: 
2013-04-30    Tue
2013-05-02    Thu
2013-05-05    Sun
2013-05-06    Mon
2013-05-07    Tue
Freq: C, dtype: object

---->   pandas.Series

--------------------------------------
ID: 3499 --> 2
In [279]: ts = pd.Series(range(len(rng)), index=rng)

In [280]: ts = ts[:5]

In [281]: ts.shift(1)
Out[281]: 
2012-01-01    NaN
2012-01-02    0.0
2012-01-03    1.0
Freq: D, dtype: float64

---->   pandas.Series; Series.shift

--------------------------------------
ID: 3500 --> 1
In [282]: ts.shift(5, freq="D")
Out[282]: 
2012-01-06    0
2012-01-07    1
2012-01-08    2
Freq: D, dtype: int64

In [283]: ts.shift(5, freq=pd.offsets.BDay())
Out[283]: 
2012-01-06    0
2012-01-09    1
2012-01-10    2
dtype: int64

In [284]: ts.shift(5, freq="BM")
Out[284]: 
2012-05-31    0
2012-05-31    1
2012-05-31    2
dtype: int64

---->   Series.shift

--------------------------------------
ID: 3501 --> 2
In [285]: dr = pd.date_range("1/1/2010", periods=3, freq=3 * pd.offsets.BDay())

In [286]: ts = pd.Series(np.random.randn(3), index=dr)

In [287]: ts
Out[287]: 
2010-01-01    1.494522
2010-01-06   -0.778425
2010-01-11   -0.253355
Freq: 3B, dtype: float64

In [288]: ts.asfreq(pd.offsets.BDay())
Out[288]: 
2010-01-01    1.494522
2010-01-04         NaN
2010-01-05         NaN
2010-01-06   -0.778425
2010-01-07         NaN
2010-01-08         NaN
2010-01-11   -0.253355
Freq: B, dtype: float64

---->   pandas.Series; Series.asfreq

--------------------------------------
ID: 3502 --> 1
In [289]: ts.asfreq(pd.offsets.BDay(), method="pad")
Out[289]: 
2010-01-01    1.494522
2010-01-04    1.494522
2010-01-05    1.494522
2010-01-06   -0.778425
2010-01-07   -0.778425
2010-01-08   -0.778425
2010-01-11   -0.253355
Freq: B, dtype: float64

---->   Series.asfreq

--------------------------------------
ID: 3503 --> 2
In [290]: rng = pd.date_range("1/1/2012", periods=100, freq="S")

In [291]: ts = pd.Series(np.random.randint(0, 500, len(rng)), index=rng)

In [292]: ts.resample("5Min").sum()
Out[292]: 
2012-01-01    25103
Freq: 5T, dtype: int64

---->   pandas.Series; Series.resample

--------------------------------------
ID: 3504 --> 1
In [293]: ts.resample("5Min").mean()
Out[293]: 
2012-01-01    251.03
Freq: 5T, dtype: float64

In [294]: ts.resample("5Min").ohlc()
Out[294]: 
            open  high  low  close
2012-01-01   308   460    9    205

In [295]: ts.resample("5Min").max()
Out[295]: 
2012-01-01    460
Freq: 5T, dtype: int64

---->   Series.resample

--------------------------------------
ID: 3505 --> 1
In [296]: ts.resample("5Min", closed="right").mean()
Out[296]: 
2011-12-31 23:55:00    308.000000
2012-01-01 00:00:00    250.454545
Freq: 5T, dtype: float64

In [297]: ts.resample("5Min", closed="left").mean()
Out[297]: 
2012-01-01    251.03
Freq: 5T, dtype: float64

---->   Series.resample

--------------------------------------
ID: 3506 --> 1
In [298]: ts.resample("5Min").mean()  # by default label='left'
Out[298]: 
2012-01-01    251.03
Freq: 5T, dtype: float64

In [299]: ts.resample("5Min", label="left").mean()
Out[299]: 
2012-01-01    251.03
Freq: 5T, dtype: float64

---->   Series.resample

--------------------------------------
ID: 3507 --> 1
In [300]: s = pd.date_range("2000-01-01", "2000-01-05").to_series()

In [301]: s.iloc[2] = pd.NaT

In [302]: s.dt.day_name()
Out[302]: 
2000-01-01     Saturday
2000-01-02       Sunday
2000-01-03          NaN
2000-01-04      Tuesday
2000-01-05    Wednesday
Freq: D, dtype: object

# default: label='left', closed='left'
In [303]: s.resample("B").last().dt.day_name()
Out[303]: 
1999-12-31       Sunday
2000-01-03          NaN
2000-01-04      Tuesday
2000-01-05    Wednesday
Freq: B, dtype: object

---->   Series.resample

--------------------------------------
ID: 3508 --> 1
In [304]: s.resample("B", label="right", closed="right").last().dt.day_name()
Out[304]: 
2000-01-03       Sunday
2000-01-04      Tuesday
2000-01-05    Wednesday
Freq: B, dtype: object

---->   Series.resample

--------------------------------------
ID: 3510 --> 1
In [308]: rng = pd.date_range("2014-1-1", periods=100, freq="D") + pd.Timedelta("1s")

In [309]: ts = pd.Series(range(100), index=rng)

---->   pandas.Series

--------------------------------------
ID: 3511 --> 1
In [310]: ts.resample("3T").sum()
Out[310]: 
2014-01-01 00:00:00     0
2014-01-01 00:03:00     0
2014-01-01 00:06:00     0
2014-01-01 00:09:00     0
2014-01-01 00:12:00     0
                       ..
2014-04-09 23:48:00     0
2014-04-09 23:51:00     0
2014-04-09 23:54:00     0
2014-04-09 23:57:00     0
2014-04-10 00:00:00    99
Freq: 3T, Length: 47521, dtype: int64

---->   Series.resample

--------------------------------------
ID: 3512 --> 1
In [311]: from functools import partial

In [312]: from pandas.tseries.frequencies import to_offset

In [313]: def round(t, freq):
   .....:     freq = to_offset(freq)
   .....:     return pd.Timestamp((t.value // freq.delta.value) * freq.delta.value)
   .....: 

In [314]: ts.groupby(partial(round, freq="3T")).sum()
Out[314]: 
2014-01-01     0
2014-01-02     1
2014-01-03     2
2014-01-04     3
2014-01-05     4
              ..
2014-04-06    95
2014-04-07    96
2014-04-08    97
2014-04-09    98
2014-04-10    99
Length: 100, dtype: int64

---->   Series.groupby

--------------------------------------
ID: 3513 --> 2
In [315]: df = pd.DataFrame(
   .....:     np.random.randn(1000, 3),
   .....:     index=pd.date_range("1/1/2012", freq="S", periods=1000),
   .....:     columns=["A", "B", "C"],
   .....: )
   .....: 

In [316]: r = df.resample("3T")

In [317]: r.mean()
Out[317]: 
                            A         B         C
2012-01-01 00:00:00 -0.033823 -0.121514 -0.081447
2012-01-01 00:03:00  0.056909  0.146731 -0.024320
2012-01-01 00:06:00 -0.058837  0.047046 -0.052021
2012-01-01 00:09:00  0.063123 -0.026158 -0.066533
2012-01-01 00:12:00  0.186340 -0.003144  0.074752
2012-01-01 00:15:00 -0.085954 -0.016287 -0.050046

---->   pandas.DataFrame; DataFrame.resample

--------------------------------------
ID: 3520 --> 3
In [325]: df = pd.DataFrame(
   .....:     {"date": pd.date_range("2015-01-01", freq="W", periods=5), "a": np.arange(5)},
   .....:     index=pd.MultiIndex.from_arrays(
   .....:         [[1, 2, 3, 4, 5], pd.date_range("2015-01-01", freq="W", periods=5)],
   .....:         names=["v", "d"],
   .....:     ),
   .....: )
   .....: 

In [326]: df
Out[326]: 
                   date  a
v d                       
1 2015-01-04 2015-01-04  0
2 2015-01-11 2015-01-11  1
3 2015-01-18 2015-01-18  2
4 2015-01-25 2015-01-25  3
5 2015-02-01 2015-02-01  4

In [327]: df.resample("M", on="date")[["a"]].sum()
Out[327]: 
            a
date         
2015-01-31  6
2015-02-28  4

---->   pandas.DataFrame; pandas.MultiIndex; DataFrame.resample

--------------------------------------
ID: 3521 --> 1
In [328]: df.resample("M", level="d")[["a"]].sum()
Out[328]: 
            a
d            
2015-01-31  6
2015-02-28  4

---->   DataFrame.resample

--------------------------------------
ID: 3522 --> 2
In [329]: small = pd.Series(
   .....:     range(6),
   .....:     index=pd.to_datetime(
   .....:         [
   .....:             "2017-01-01T00:00:00",
   .....:             "2017-01-01T00:30:00",
   .....:             "2017-01-01T00:31:00",
   .....:             "2017-01-01T01:00:00",
   .....:             "2017-01-01T03:00:00",
   .....:             "2017-01-01T03:05:00",
   .....:         ]
   .....:     ),
   .....: )
   .....: 

In [330]: resampled = small.resample("H")

In [331]: for name, group in resampled:
   .....:     print("Group: ", name)
   .....:     print("-" * 27)
   .....:     print(group, end="\n\n")
   .....: 
Group:  2017-01-01 00:00:00
---------------------------
2017-01-01 00:00:00    0
2017-01-01 00:30:00    1
2017-01-01 00:31:00    2
dtype: int64

Group:  2017-01-01 01:00:00
---------------------------
2017-01-01 01:00:00    3
dtype: int64

Group:  2017-01-01 02:00:00
---------------------------
Series([], dtype: int64)

Group:  2017-01-01 03:00:00
---------------------------
2017-01-01 03:00:00    4
2017-01-01 03:05:00    5
dtype: int64

---->   pandas.Series; pandas.to_datetime

--------------------------------------
ID: 3523 --> 1
In [332]: start, end = "2000-10-01 23:30:00", "2000-10-02 00:30:00"

In [333]: middle = "2000-10-02 00:00:00"

In [334]: rng = pd.date_range(start, end, freq="7min")

In [335]: ts = pd.Series(np.arange(len(rng)) * 3, index=rng)

In [336]: ts
Out[336]: 
2000-10-01 23:30:00     0
2000-10-01 23:37:00     3
2000-10-01 23:44:00     6
2000-10-01 23:51:00     9
2000-10-01 23:58:00    12
2000-10-02 00:05:00    15
2000-10-02 00:12:00    18
2000-10-02 00:19:00    21
2000-10-02 00:26:00    24
Freq: 7T, dtype: int64

---->   pandas.Series

--------------------------------------
ID: 3524 --> 1
In [337]: ts.resample("17min", origin="start_day").sum()
Out[337]: 
2000-10-01 23:14:00     0
2000-10-01 23:31:00     9
2000-10-01 23:48:00    21
2000-10-02 00:05:00    54
2000-10-02 00:22:00    24
Freq: 17T, dtype: int64

In [338]: ts[middle:end].resample("17min", origin="start_day").sum()
Out[338]: 
2000-10-02 00:00:00    33
2000-10-02 00:17:00    45
Freq: 17T, dtype: int64

---->   Series.resample

--------------------------------------
ID: 3525 --> 1
In [339]: ts.resample("17min", origin="epoch").sum()
Out[339]: 
2000-10-01 23:18:00     0
2000-10-01 23:35:00    18
2000-10-01 23:52:00    27
2000-10-02 00:09:00    39
2000-10-02 00:26:00    24
Freq: 17T, dtype: int64

In [340]: ts[middle:end].resample("17min", origin="epoch").sum()
Out[340]: 
2000-10-01 23:52:00    15
2000-10-02 00:09:00    39
2000-10-02 00:26:00    24
Freq: 17T, dtype: int64

---->   Series.resample

--------------------------------------
ID: 3526 --> 1
In [341]: ts.resample("17min", origin="2001-01-01").sum()
Out[341]: 
2000-10-01 23:30:00     9
2000-10-01 23:47:00    21
2000-10-02 00:04:00    54
2000-10-02 00:21:00    24
Freq: 17T, dtype: int64

In [342]: ts[middle:end].resample("17min", origin=pd.Timestamp("2001-01-01")).sum()
Out[342]: 
2000-10-02 00:04:00    54
2000-10-02 00:21:00    24
Freq: 17T, dtype: int64

---->   Series.resample

--------------------------------------
ID: 3527 --> 1
In [343]: ts.resample("17min", origin="start").sum()
Out[343]: 
2000-10-01 23:30:00     9
2000-10-01 23:47:00    21
2000-10-02 00:04:00    54
2000-10-02 00:21:00    24
Freq: 17T, dtype: int64

In [344]: ts.resample("17min", offset="23h30min").sum()
Out[344]: 
2000-10-01 23:30:00     9
2000-10-01 23:47:00    21
2000-10-02 00:04:00    54
2000-10-02 00:21:00    24
Freq: 17T, dtype: int64

---->   Series.resample

--------------------------------------
ID: 3528 --> 1
In [345]: ts.resample('17min', origin='end').sum()
Out[345]: 
2000-10-01 23:35:00     0
2000-10-01 23:52:00    18
2000-10-02 00:09:00    27
2000-10-02 00:26:00    63
Freq: 17T, dtype: int64

---->   Series.resample

--------------------------------------
ID: 3529 --> 1
In [346]: ts.resample('17min', origin='end_day').sum()
Out[346]: 
2000-10-01 23:38:00     3
2000-10-01 23:55:00    15
2000-10-02 00:12:00    45
2000-10-02 00:29:00    45
Freq: 17T, dtype: int64

---->   Series.resample

--------------------------------------
ID: 3531 --> 1
In [351]: pd.Period("2012", freq="A-DEC")
Out[351]: Period('2012', 'A-DEC')

In [352]: pd.Period("2012-1-1", freq="D")
Out[352]: Period('2012-01-01', 'D')

In [353]: pd.Period("2012-1-1 19:00", freq="H")
Out[353]: Period('2012-01-01 19:00', 'H')

In [354]: pd.Period("2012-1-1 19:00", freq="5H")
Out[354]: Period('2012-01-01 19:00', '5H')

---->   pandas.Period

--------------------------------------
ID: 3532 --> 1
In [355]: p = pd.Period("2012", freq="A-DEC")

In [356]: p + 1
Out[356]: Period('2013', 'A-DEC')

In [357]: p - 3
Out[357]: Period('2009', 'A-DEC')

In [358]: p = pd.Period("2012-01", freq="2M")

In [359]: p + 2
Out[359]: Period('2012-05', '2M')

In [360]: p - 1
Out[360]: Period('2011-11', '2M')

In [361]: p == pd.Period("2012-01", freq="3M")
Out[361]: False

---->   pandas.Period

--------------------------------------
ID: 3533 --> 1
In [362]: p = pd.Period("2014-07-01 09:00", freq="H")

In [363]: p + pd.offsets.Hour(2)
Out[363]: Period('2014-07-01 11:00', 'H')

In [364]: p + datetime.timedelta(minutes=120)
Out[364]: Period('2014-07-01 11:00', 'H')

In [365]: p + np.timedelta64(7200, "s")
Out[365]: Period('2014-07-01 11:00', 'H')

---->   pandas.Period

--------------------------------------
ID: 3535 --> 1
In [366]: p = pd.Period("2014-07", freq="M")

In [367]: p + pd.offsets.MonthEnd(3)
Out[367]: Period('2014-10', 'M')

---->   pandas.Period

--------------------------------------
ID: 3537 --> 1
In [368]: pd.Period("2012", freq="A-DEC") - pd.Period("2002", freq="A-DEC")
Out[368]: <10 * YearEnds: month=12>

---->   pandas.Period

--------------------------------------
ID: 3538 --> 1
In [369]: prng = pd.period_range("1/1/2011", "1/1/2012", freq="M")

In [370]: prng
Out[370]: 
PeriodIndex(['2011-01', '2011-02', '2011-03', '2011-04', '2011-05', '2011-06',
             '2011-07', '2011-08', '2011-09', '2011-10', '2011-11', '2011-12',
             '2012-01'],
            dtype='period[M]')

---->   pandas.period_range

--------------------------------------
ID: 3539 --> 1
In [371]: pd.PeriodIndex(["2011-1", "2011-2", "2011-3"], freq="M")
Out[371]: PeriodIndex(['2011-01', '2011-02', '2011-03'], dtype='period[M]')

---->   pandas.PeriodIndex

--------------------------------------
ID: 3540 --> 1
In [372]: pd.period_range(start="2014-01", freq="3M", periods=4)
Out[372]: PeriodIndex(['2014-01', '2014-04', '2014-07', '2014-10'], dtype='period[3M]')

---->   pandas.period_range

--------------------------------------
ID: 3541 --> 2
In [373]: pd.period_range(
   .....:     start=pd.Period("2017Q1", freq="Q"), end=pd.Period("2017Q2", freq="Q"), freq="M"
   .....: )
   .....: 
Out[373]: PeriodIndex(['2017-03', '2017-04', '2017-05', '2017-06'], dtype='period[M]')

---->   pandas.period_range; pandas.Period

--------------------------------------
ID: 3542 --> 1
In [374]: ps = pd.Series(np.random.randn(len(prng)), prng)

In [375]: ps
Out[375]: 
2011-01   -2.916901
2011-02    0.514474
2011-03    1.346470
2011-04    0.816397
2011-05    2.258648
2011-06    0.494789
2011-07    0.301239
2011-08    0.464776
2011-09   -1.393581
2011-10    0.056780
2011-11    0.197035
2011-12    2.261385
2012-01   -0.329583
Freq: M, dtype: float64

---->   pandas.Series

--------------------------------------
ID: 3543 --> 1
In [376]: idx = pd.period_range("2014-07-01 09:00", periods=5, freq="H")

In [377]: idx
Out[377]: 
PeriodIndex(['2014-07-01 09:00', '2014-07-01 10:00', '2014-07-01 11:00',
             '2014-07-01 12:00', '2014-07-01 13:00'],
            dtype='period[H]')

In [378]: idx + pd.offsets.Hour(2)
Out[378]: 
PeriodIndex(['2014-07-01 11:00', '2014-07-01 12:00', '2014-07-01 13:00',
             '2014-07-01 14:00', '2014-07-01 15:00'],
            dtype='period[H]')

In [379]: idx = pd.period_range("2014-07", periods=5, freq="M")

In [380]: idx
Out[380]: PeriodIndex(['2014-07', '2014-08', '2014-09', '2014-10', '2014-11'], dtype='period[M]')

In [381]: idx + pd.offsets.MonthEnd(3)
Out[381]: PeriodIndex(['2014-10', '2014-11', '2014-12', '2015-01', '2015-02'], dtype='period[M]')

---->   pandas.period_range

--------------------------------------
ID: 3544 --> 1
In [382]: pi = pd.period_range("2016-01-01", periods=3, freq="M")

In [383]: pi
Out[383]: PeriodIndex(['2016-01', '2016-02', '2016-03'], dtype='period[M]')

In [384]: pi.dtype
Out[384]: period[M]

---->   pandas.period_range

--------------------------------------
ID: 3547 --> 2
In [393]: ps["2011"]
Out[393]: 
2011-01   -2.916901
2011-02    0.514474
2011-03    1.346470
2011-04    0.816397
2011-05    2.258648
2011-06    0.494789
2011-07    0.301239
2011-08    0.464776
2011-09   -1.393581
2011-10    0.056780
2011-11    0.197035
2011-12    2.261385
Freq: M, dtype: float64

In [394]: dfp = pd.DataFrame(
   .....:     np.random.randn(600, 1),
   .....:     columns=["A"],
   .....:     index=pd.period_range("2013-01-01 9:00", periods=600, freq="T"),
   .....: )
   .....: 

In [395]: dfp
Out[395]: 
                         A
2013-01-01 09:00 -0.538468
2013-01-01 09:01 -1.365819
2013-01-01 09:02 -0.969051
2013-01-01 09:03 -0.331152
2013-01-01 09:04 -0.245334
...                    ...
2013-01-01 18:55  0.522460
2013-01-01 18:56  0.118710
2013-01-01 18:57  0.167517
2013-01-01 18:58  0.922883
2013-01-01 18:59  1.721104

[600 rows x 1 columns]

In [396]: dfp.loc["2013-01-01 10H"]
Out[396]: 
                         A
2013-01-01 10:00 -0.308975
2013-01-01 10:01  0.542520
2013-01-01 10:02  1.061068
2013-01-01 10:03  0.754005
2013-01-01 10:04  0.352933
...                    ...
2013-01-01 10:55 -0.865621
2013-01-01 10:56 -1.167818
2013-01-01 10:57 -2.081748
2013-01-01 10:58 -0.527146
2013-01-01 10:59  0.802298

[60 rows x 1 columns]

---->   pandas.DataFrame; pandas.period_range

--------------------------------------
ID: 3548 --> 1
In [398]: p = pd.Period("2011", freq="A-DEC")

In [399]: p
Out[399]: Period('2011', 'A-DEC')

---->   pandas.Period

--------------------------------------
ID: 3549 --> 1
In [400]: p.asfreq("M", how="start")
Out[400]: Period('2011-01', 'M')

In [401]: p.asfreq("M", how="end")
Out[401]: Period('2011-12', 'M')

---->   Period.asfreq

--------------------------------------
ID: 3550 --> 1
In [402]: p.asfreq("M", "s")
Out[402]: Period('2011-01', 'M')

In [403]: p.asfreq("M", "e")
Out[403]: Period('2011-12', 'M')

---->   Period.asfreq

--------------------------------------
ID: 3551 --> 2
In [404]: p = pd.Period("2011-12", freq="M")

In [405]: p.asfreq("A-NOV")
Out[405]: Period('2012', 'A-NOV')

---->   pandas.Period; Period.asfreq

--------------------------------------
ID: 3552 --> 2
In [406]: p = pd.Period("2012Q1", freq="Q-DEC")

In [407]: p.asfreq("D", "s")
Out[407]: Period('2012-01-01', 'D')

In [408]: p.asfreq("D", "e")
Out[408]: Period('2012-03-31', 'D')

---->   pandas.Period; Period.asfreq

--------------------------------------
ID: 3553 --> 2
In [409]: p = pd.Period("2011Q4", freq="Q-MAR")

In [410]: p.asfreq("D", "s")
Out[410]: Period('2011-01-01', 'D')

In [411]: p.asfreq("D", "e")
Out[411]: Period('2011-03-31', 'D')

---->   pandas.Period; Period.asfreq

--------------------------------------
ID: 3554 --> 3
In [412]: rng = pd.date_range("1/1/2012", periods=5, freq="M")

In [413]: ts = pd.Series(np.random.randn(len(rng)), index=rng)

In [414]: ts
Out[414]: 
2012-01-31    1.931253
2012-02-29   -0.184594
2012-03-31    0.249656
2012-04-30   -0.978151
2012-05-31   -0.873389
Freq: M, dtype: float64

In [415]: ps = ts.to_period()

In [416]: ps
Out[416]: 
2012-01    1.931253
2012-02   -0.184594
2012-03    0.249656
2012-04   -0.978151
2012-05   -0.873389
Freq: M, dtype: float64

In [417]: ps.to_timestamp()
Out[417]: 
2012-01-01    1.931253
2012-02-01   -0.184594
2012-03-01    0.249656
2012-04-01   -0.978151
2012-05-01   -0.873389
Freq: MS, dtype: float64

---->   pandas.Series; Series.to_period; Series.to_timestamp

--------------------------------------
ID: 3555 --> 1
In [418]: ps.to_timestamp("D", how="s")
Out[418]: 
2012-01-01    1.931253
2012-02-01   -0.184594
2012-03-01    0.249656
2012-04-01   -0.978151
2012-05-01   -0.873389
Freq: MS, dtype: float64

---->   Series.to_timestamp

--------------------------------------
ID: 3556 --> 3
In [419]: prng = pd.period_range("1990Q1", "2000Q4", freq="Q-NOV")

In [420]: ts = pd.Series(np.random.randn(len(prng)), prng)

In [421]: ts.index = (prng.asfreq("M", "e") + 1).asfreq("H", "s") + 9

In [422]: ts.head()
Out[422]: 
1990-03-01 09:00   -0.109291
1990-06-01 09:00   -0.637235
1990-09-01 09:00   -1.735925
1990-12-01 09:00    2.096946
1991-03-01 09:00   -1.039926
Freq: H, dtype: float64

---->   pandas.period_range; pandas.Series; Series.head

--------------------------------------
ID: 3557 --> 1
In [423]: span = pd.period_range("1215-01-01", "1381-01-01", freq="D")

In [424]: span
Out[424]: 
PeriodIndex(['1215-01-01', '1215-01-02', '1215-01-03', '1215-01-04',
             '1215-01-05', '1215-01-06', '1215-01-07', '1215-01-08',
             '1215-01-09', '1215-01-10',
             ...
             '1380-12-23', '1380-12-24', '1380-12-25', '1380-12-26',
             '1380-12-27', '1380-12-28', '1380-12-29', '1380-12-30',
             '1380-12-31', '1381-01-01'],
            dtype='period[D]', length=60632)

---->   pandas.period_range

--------------------------------------
ID: 3558 --> 2
In [425]: s = pd.Series([20121231, 20141130, 99991231])

In [426]: s
Out[426]: 
0    20121231
1    20141130
2    99991231
dtype: int64

In [427]: def conv(x):
   .....:     return pd.Period(year=x // 10000, month=x // 100 % 100, day=x % 100, freq="D")
   .....: 

In [428]: s.apply(conv)
Out[428]: 
0    2012-12-31
1    2014-11-30
2    9999-12-31
dtype: period[D]

In [429]: s.apply(conv)[2]
Out[429]: Period('9999-12-31', 'D')

---->   pandas.Series; pandas.Period

--------------------------------------
ID: 3559 --> 1
In [430]: span = pd.PeriodIndex(s.apply(conv))

In [431]: span
Out[431]: PeriodIndex(['2012-12-31', '2014-11-30', '9999-12-31'], dtype='period[D]')

---->   pandas.PeriodIndex

--------------------------------------
ID: 3568 --> 2
In [467]: ts_utc = pd.Series(range(3), pd.date_range("20130101", periods=3, tz="UTC"))

In [468]: eastern = ts_utc.tz_convert("US/Eastern")

In [469]: berlin = ts_utc.tz_convert("Europe/Berlin")

In [470]: result = eastern + berlin

In [471]: result
Out[471]: 
2013-01-01 00:00:00+00:00    0
2013-01-02 00:00:00+00:00    2
2013-01-03 00:00:00+00:00    4
Freq: D, dtype: int64

In [472]: result.index
Out[472]: 
DatetimeIndex(['2013-01-01 00:00:00+00:00', '2013-01-02 00:00:00+00:00',
               '2013-01-03 00:00:00+00:00'],
              dtype='datetime64[ns, UTC]', freq='D')

---->   pandas.Series; Series.tz_convert

--------------------------------------
ID: 3571 --> 1
In [480]: rng_hourly = pd.DatetimeIndex(
   .....:     ["11/06/2011 00:00", "11/06/2011 01:00", "11/06/2011 01:00", "11/06/2011 02:00"]
   .....: )
   .....: 

---->   pandas.DatetimeIndex

--------------------------------------
ID: 3577 --> 1
In [490]: s_naive = pd.Series(pd.date_range("20130101", periods=3))

In [491]: s_naive
Out[491]: 
0   2013-01-01
1   2013-01-02
2   2013-01-03
dtype: datetime64[ns]

---->   pandas.Series

--------------------------------------
ID: 3578 --> 1
In [492]: s_aware = pd.Series(pd.date_range("20130101", periods=3, tz="US/Eastern"))

In [493]: s_aware
Out[493]: 
0   2013-01-01 00:00:00-05:00
1   2013-01-02 00:00:00-05:00
2   2013-01-03 00:00:00-05:00
dtype: datetime64[ns, US/Eastern]

---->   pandas.Series

--------------------------------------
ID: 3580 --> 1
# convert to a new time zone
In [495]: s_aware.astype("datetime64[ns, CET]")
Out[495]: 
0   2013-01-01 06:00:00+01:00
1   2013-01-02 06:00:00+01:00
2   2013-01-03 06:00:00+01:00
dtype: datetime64[ns, CET]

---->   Series.astype

--------------------------------------
ID: 3581 --> 2
In [496]: s_naive.to_numpy()
Out[496]: 
array(['2013-01-01T00:00:00.000000000', '2013-01-02T00:00:00.000000000',
       '2013-01-03T00:00:00.000000000'], dtype='datetime64[ns]')

In [497]: s_aware.to_numpy()
Out[497]: 
array([Timestamp('2013-01-01 00:00:00-0500', tz='US/Eastern'),
       Timestamp('2013-01-02 00:00:00-0500', tz='US/Eastern'),
       Timestamp('2013-01-03 00:00:00-0500', tz='US/Eastern')],
      dtype=object)

---->   Series.to_numpy; Series.to_numpy

--------------------------------------
ID: 3582 --> 2
In [498]: pd.Series(s_aware.to_numpy())
Out[498]: 
0   2013-01-01 00:00:00-05:00
1   2013-01-02 00:00:00-05:00
2   2013-01-03 00:00:00-05:00
dtype: datetime64[ns, US/Eastern]

---->   pandas.Series; Series.to_numpy

--------------------------------------
ID: 3583 --> 1
In [499]: s_aware.to_numpy(dtype="datetime64[ns]")
Out[499]: 
array(['2013-01-01T05:00:00.000000000', '2013-01-02T05:00:00.000000000',
       '2013-01-03T05:00:00.000000000'], dtype='datetime64[ns]')

---->   Series.to_numpy

--------------------------------------
ID: 3609 --> 1
In [1]: df = pd.DataFrame({"x": [1, 3, 5], "y": [2, 4, 6]})

In [2]: df
Out[2]: 
   x  y
0  1  2
1  3  4
2  5  6

---->   pandas.DataFrame

--------------------------------------
ID: 3629 --> 1
In [1]: firstlast = pd.DataFrame({"String": ["John Smith", "Jane Cook"]})

In [2]: firstlast["First_Name"] = firstlast["String"].str.split(" ", expand=True)[0]

In [3]: firstlast["Last_Name"] = firstlast["String"].str.rsplit(" ", expand=True)[1]

In [4]: firstlast
Out[4]: 
       String First_Name Last_Name
0  John Smith       John     Smith
1   Jane Cook       Jane      Cook

---->   pandas.DataFrame

--------------------------------------
ID: 3631 --> 1
In [1]: firstlast = pd.DataFrame({"string": ["John Smith", "Jane Cook"]})

In [2]: firstlast["upper"] = firstlast["string"].str.upper()

In [3]: firstlast["lower"] = firstlast["string"].str.lower()

In [4]: firstlast["title"] = firstlast["string"].str.title()

In [5]: firstlast
Out[5]: 
       string       upper       lower       title
0  John Smith  JOHN SMITH  john smith  John Smith
1   Jane Cook   JANE COOK   jane cook   Jane Cook

---->   pandas.DataFrame

--------------------------------------
ID: 3632 --> 1
In [1]: df1 = pd.DataFrame({"key": ["A", "B", "C", "D"], "value": np.random.randn(4)})

In [2]: df1
Out[2]: 
  key     value
0   A  0.469112
1   B -0.282863
2   C -1.509059
3   D -1.135632

In [3]: df2 = pd.DataFrame({"key": ["B", "D", "D", "E"], "value": np.random.randn(4)})

In [4]: df2
Out[4]: 
  key     value
0   B  1.212112
1   D -0.173215
2   D  0.119209
3   E -1.044236

---->   pandas.DataFrame

--------------------------------------
ID: 3648 --> 1
>>> pd.test()
running: pytest --skip-slow --skip-network --skip-db /home/user/anaconda3/lib/python3.9/site-packages/pandas

============================= test session starts ==============================
platform linux -- Python 3.9.7, pytest-6.2.5, py-1.11.0, pluggy-1.0.0
rootdir: /home/user
plugins: dash-1.19.0, anyio-3.5.0, hypothesis-6.29.3
collected 154975 items / 4 skipped / 154971 selected
........................................................................ [  0%]
........................................................................ [ 99%]
.......................................                                  [100%]

==================================== ERRORS ====================================

=================================== FAILURES ===================================

=============================== warnings summary ===============================

=========================== short test summary info ============================

= 1 failed, 146194 passed, 7402 skipped, 1367 xfailed, 5 xpassed, 197 warnings, 10 errors in 1090.16s (0:18:10) =

---->   pandas.test

--------------------------------------
ID: 3649 --> 1
In [2]: df = pd.DataFrame(
   ...:     {
   ...:         "Name": [
   ...:             "Braund, Mr. Owen Harris",
   ...:             "Allen, Mr. William Henry",
   ...:             "Bonnell, Miss. Elizabeth",
   ...:         ],
   ...:         "Age": [22, 35, 58],
   ...:         "Sex": ["male", "male", "female"],
   ...:     }
   ...: )
   ...: 

In [3]: df
Out[3]: 
                       Name  Age     Sex
0   Braund, Mr. Owen Harris   22    male
1  Allen, Mr. William Henry   35    male
2  Bonnell, Miss. Elizabeth   58  female

---->   pandas.DataFrame

--------------------------------------
ID: 3650 --> 1
In [5]: ages = pd.Series([22, 35, 58], name="Age")

In [6]: ages
Out[6]: 
0    22
1    35
2    58
Name: Age, dtype: int64

---->   pandas.Series

--------------------------------------
ID: 3652 --> 1
In [8]: ages.max()
Out[8]: 58

---->   Series.max

--------------------------------------
ID: 3653 --> 1
In [9]: df.describe()
Out[9]: 
             Age
count   3.000000
mean   38.333333
std    18.230012
min    22.000000
25%    28.500000
50%    35.000000
75%    46.500000
max    58.000000

---->   DataFrame.describe

--------------------------------------
ID: 3666 --> 2
In [1]: index = pd.date_range("1/1/2000", periods=8)

In [2]: s = pd.Series(np.random.randn(5), index=["a", "b", "c", "d", "e"])

In [3]: df = pd.DataFrame(np.random.randn(8, 3), index=index, columns=["A", "B", "C"])

---->   pandas.Series; pandas.DataFrame

--------------------------------------
ID: 3667 --> 3
In [4]: long_series = pd.Series(np.random.randn(1000))

In [5]: long_series.head()
Out[5]: 
0   -1.157892
1   -1.344312
2    0.844885
3    1.075770
4   -0.109050
dtype: float64

In [6]: long_series.tail(3)
Out[6]: 
997   -0.289388
998   -1.020544
999    0.589993
dtype: float64

---->   pandas.Series; Series.head; Series.tail

--------------------------------------
ID: 3669 --> 1
In [12]: s.to_numpy()
Out[12]: array([ 0.4691, -0.2829, -1.5091, -1.1356,  1.2121])

In [13]: np.asarray(s)
Out[13]: array([ 0.4691, -0.2829, -1.5091, -1.1356,  1.2121])

---->   Series.to_numpy

--------------------------------------
ID: 3670 --> 2
In [14]: ser = pd.Series(pd.date_range("2000", periods=2, tz="CET"))

In [15]: ser.to_numpy(dtype=object)
Out[15]: 
array([Timestamp('2000-01-01 00:00:00+0100', tz='CET'),
       Timestamp('2000-01-02 00:00:00+0100', tz='CET')], dtype=object)

---->   pandas.Series; Series.to_numpy

--------------------------------------
ID: 3671 --> 1
In [16]: ser.to_numpy(dtype="datetime64[ns]")
Out[16]: 
array(['1999-12-31T23:00:00.000000000', '2000-01-01T23:00:00.000000000'],
      dtype='datetime64[ns]')

---->   Series.to_numpy

--------------------------------------
ID: 3674 --> 3
In [18]: df = pd.DataFrame(
   ....:     {
   ....:         "one": pd.Series(np.random.randn(3), index=["a", "b", "c"]),
   ....:         "two": pd.Series(np.random.randn(4), index=["a", "b", "c", "d"]),
   ....:         "three": pd.Series(np.random.randn(3), index=["b", "c", "d"]),
   ....:     }
   ....: )
   ....: 

In [19]: df
Out[19]: 
        one       two     three
a  1.394981  1.772517       NaN
b  0.343054  1.912123 -0.050390
c  0.695246  1.478369  1.227435
d       NaN  0.279344 -0.613172

In [20]: row = df.iloc[1]

In [21]: column = df["two"]

In [22]: df.sub(row, axis="columns")
Out[22]: 
        one       two     three
a  1.051928 -0.139606       NaN
b  0.000000  0.000000  0.000000
c  0.352192 -0.433754  1.277825
d       NaN -1.632779 -0.562782

In [23]: df.sub(row, axis=1)
Out[23]: 
        one       two     three
a  1.051928 -0.139606       NaN
b  0.000000  0.000000  0.000000
c  0.352192 -0.433754  1.277825
d       NaN -1.632779 -0.562782

In [24]: df.sub(column, axis="index")
Out[24]: 
        one  two     three
a -0.377535  0.0       NaN
b -1.569069  0.0 -1.962513
c -0.783123  0.0 -0.250933
d       NaN  0.0 -0.892516

In [25]: df.sub(column, axis=0)
Out[25]: 
        one  two     three
a -0.377535  0.0       NaN
b -1.569069  0.0 -1.962513
c -0.783123  0.0 -0.250933
d       NaN  0.0 -0.892516

---->   pandas.DataFrame; pandas.Series; DataFrame.sub

--------------------------------------
ID: 3675 --> 2
In [26]: dfmi = df.copy()

In [27]: dfmi.index = pd.MultiIndex.from_tuples(
   ....:     [(1, "a"), (1, "b"), (1, "c"), (2, "a")], names=["first", "second"]
   ....: )
   ....: 

In [28]: dfmi.sub(column, axis=0, level="second")
Out[28]: 
                   one       two     three
first second                              
1     a      -0.377535  0.000000       NaN
      b      -1.569069  0.000000 -1.962513
      c      -0.783123  0.000000 -0.250933
2     a            NaN -1.493173 -2.385688

---->   DataFrame.copy; pandas.MultiIndex

--------------------------------------
ID: 3676 --> 2
In [29]: s = pd.Series(np.arange(10))

In [30]: s
Out[30]: 
0    0
1    1
2    2
3    3
4    4
5    5
6    6
7    7
8    8
9    9
dtype: int64

In [31]: div, rem = divmod(s, 3)

In [32]: div
Out[32]: 
0    0
1    0
2    0
3    1
4    1
5    1
6    2
7    2
8    2
9    3
dtype: int64

In [33]: rem
Out[33]: 
0    0
1    1
2    2
3    0
4    1
5    2
6    0
7    1
8    2
9    0
dtype: int64

In [34]: idx = pd.Index(np.arange(10))

In [35]: idx
Out[35]: Index([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype='int64')

In [36]: div, rem = divmod(idx, 3)

In [37]: div
Out[37]: Index([0, 0, 0, 1, 1, 1, 2, 2, 2, 3], dtype='int64')

In [38]: rem
Out[38]: Index([0, 1, 2, 0, 1, 2, 0, 1, 2, 0], dtype='int64')

---->   pandas.Series; pandas.Index

--------------------------------------
ID: 3678 --> 1
In [42]: df
Out[42]: 
        one       two     three
a  1.394981  1.772517       NaN
b  0.343054  1.912123 -0.050390
c  0.695246  1.478369  1.227435
d       NaN  0.279344 -0.613172

In [43]: df2
Out[43]: 
        one       two     three
a  1.394981  1.772517  1.000000
b  0.343054  1.912123 -0.050390
c  0.695246  1.478369  1.227435
d       NaN  0.279344 -0.613172

In [44]: df + df2
Out[44]: 
        one       two     three
a  2.789963  3.545034       NaN
b  0.686107  3.824246 -0.100780
c  1.390491  2.956737  2.454870
d       NaN  0.558688 -1.226343

In [45]: df.add(df2, fill_value=0)
Out[45]: 
        one       two     three
a  2.789963  3.545034  1.000000
b  0.686107  3.824246 -0.100780
c  1.390491  2.956737  2.454870
d       NaN  0.558688 -1.226343

---->   DataFrame.add

--------------------------------------
ID: 3679 --> 2
In [46]: df.gt(df2)
Out[46]: 
     one    two  three
a  False  False  False
b  False  False  False
c  False  False  False
d  False  False  False

In [47]: df2.ne(df)
Out[47]: 
     one    two  three
a  False  False   True
b  False  False  False
c  False  False  False
d   True  False  False

---->   DataFrame.gt; DataFrame.ne

--------------------------------------
ID: 3682 --> 1
In [51]: df.empty
Out[51]: False

In [52]: pd.DataFrame(columns=list("ABC")).empty
Out[52]: True

---->   pandas.DataFrame

--------------------------------------
ID: 3683 --> 2
In [53]: pd.Series([True]).bool()
Out[53]: True

In [54]: pd.Series([False]).bool()
Out[54]: False

In [55]: pd.DataFrame([[True]]).bool()
Out[55]: True

In [56]: pd.DataFrame([[False]]).bool()
Out[56]: False

---->   pandas.Series; pandas.DataFrame

--------------------------------------
ID: 3684 --> 1
ValueError: The truth value of an array is ambiguous. Use a.empty, a.any() or a.all().

---->   Series.all

--------------------------------------
ID: 3687 --> 2
In [61]: df1 = pd.DataFrame({"col": ["foo", 0, np.nan]})

In [62]: df2 = pd.DataFrame({"col": [np.nan, 0, "foo"]}, index=[2, 1, 0])

In [63]: df1.equals(df2)
Out[63]: False

In [64]: df1.equals(df2.sort_index())
Out[64]: True

---->   pandas.DataFrame; DataFrame.equals

--------------------------------------
ID: 3688 --> 2
In [65]: pd.Series(["foo", "bar", "baz"]) == "foo"
Out[65]: 
0     True
1    False
2    False
dtype: bool

In [66]: pd.Index(["foo", "bar", "baz"]) == "foo"
Out[66]: array([ True, False, False])

---->   pandas.Series; pandas.Index

--------------------------------------
ID: 3689 --> 2
In [67]: pd.Series(["foo", "bar", "baz"]) == pd.Index(["foo", "bar", "qux"])
Out[67]: 
0     True
1     True
2    False
dtype: bool

In [68]: pd.Series(["foo", "bar", "baz"]) == np.array(["foo", "bar", "qux"])
Out[68]: 
0     True
1     True
2    False
dtype: bool

---->   pandas.Series; pandas.Index

--------------------------------------
ID: 3690 --> 1
In [55]: pd.Series(['foo', 'bar', 'baz']) == pd.Series(['foo', 'bar'])
ValueError: Series lengths must match to compare

In [56]: pd.Series(['foo', 'bar', 'baz']) == pd.Series(['foo'])
ValueError: Series lengths must match to compare

---->   pandas.Series

--------------------------------------
ID: 3693 --> 2
In [71]: df1 = pd.DataFrame(
   ....:     {"A": [1.0, np.nan, 3.0, 5.0, np.nan], "B": [np.nan, 2.0, 3.0, np.nan, 6.0]}
   ....: )
   ....: 

In [72]: df2 = pd.DataFrame(
   ....:     {
   ....:         "A": [5.0, 2.0, 4.0, np.nan, 3.0, 7.0],
   ....:         "B": [np.nan, np.nan, 3.0, 4.0, 6.0, 8.0],
   ....:     }
   ....: )
   ....: 

In [73]: df1
Out[73]: 
     A    B
0  1.0  NaN
1  NaN  2.0
2  3.0  3.0
3  5.0  NaN
4  NaN  6.0

In [74]: df2
Out[74]: 
     A    B
0  5.0  NaN
1  2.0  NaN
2  4.0  3.0
3  NaN  4.0
4  3.0  6.0
5  7.0  8.0

In [75]: df1.combine_first(df2)
Out[75]: 
     A    B
0  1.0  NaN
1  2.0  2.0
2  3.0  3.0
3  5.0  4.0
4  3.0  6.0
5  7.0  8.0

---->   pandas.DataFrame; DataFrame.combine_first

--------------------------------------
ID: 3694 --> 2
In [76]: def combiner(x, y):
   ....:     return np.where(pd.isna(x), y, x)
   ....: 

In [77]: df1.combine(df2, combiner)
Out[77]: 
     A    B
0  1.0  NaN
1  2.0  2.0
2  3.0  3.0
3  5.0  4.0
4  3.0  6.0
5  7.0  8.0

---->   pandas.isna; DataFrame.combine

--------------------------------------
ID: 3695 --> 1
In [78]: df
Out[78]: 
        one       two     three
a  1.394981  1.772517       NaN
b  0.343054  1.912123 -0.050390
c  0.695246  1.478369  1.227435
d       NaN  0.279344 -0.613172

In [79]: df.mean(0)
Out[79]: 
one      0.811094
two      1.360588
three    0.187958
dtype: float64

In [80]: df.mean(1)
Out[80]: 
a    1.583749
b    0.734929
c    1.133683
d   -0.166914
dtype: float64

---->   DataFrame.mean

--------------------------------------
ID: 3696 --> 1
In [81]: df.sum(0, skipna=False)
Out[81]: 
one           NaN
two      5.442353
three         NaN
dtype: float64

In [82]: df.sum(axis=1, skipna=True)
Out[82]: 
a    3.167498
b    2.204786
c    3.401050
d   -0.333828
dtype: float64

---->   DataFrame.sum

--------------------------------------
ID: 3697 --> 3
In [83]: ts_stand = (df - df.mean()) / df.std()

In [84]: ts_stand.std()
Out[84]: 
one      1.0
two      1.0
three    1.0
dtype: float64

In [85]: xs_stand = df.sub(df.mean(1), axis=0).div(df.std(1), axis=0)

In [86]: xs_stand.std(1)
Out[86]: 
a    1.0
b    1.0
c    1.0
d    1.0
dtype: float64

---->   DataFrame.mean; DataFrame.std; DataFrame.sub

--------------------------------------
ID: 3698 --> 1
In [87]: df.cumsum()
Out[87]: 
        one       two     three
a  1.394981  1.772517       NaN
b  1.738035  3.684640 -0.050390
c  2.433281  5.163008  1.177045
d       NaN  5.442353  0.563873

---->   DataFrame.cumsum

--------------------------------------
ID: 3700 --> 2
In [90]: series = pd.Series(np.random.randn(500))

In [91]: series[20:500] = np.nan

In [92]: series[10:20] = 5

In [93]: series.nunique()
Out[93]: 11

---->   pandas.Series; Series.nunique

--------------------------------------
ID: 3701 --> 4
In [94]: series = pd.Series(np.random.randn(1000))

In [95]: series[::2] = np.nan

In [96]: series.describe()
Out[96]: 
count    500.000000
mean      -0.021292
std        1.015906
min       -2.683763
25%       -0.699070
50%       -0.069718
75%        0.714483
max        3.160915
dtype: float64

In [97]: frame = pd.DataFrame(np.random.randn(1000, 5), columns=["a", "b", "c", "d", "e"])

In [98]: frame.iloc[::2] = np.nan

In [99]: frame.describe()
Out[99]: 
                a           b           c           d           e
count  500.000000  500.000000  500.000000  500.000000  500.000000
mean     0.033387    0.030045   -0.043719   -0.051686    0.005979
std      1.017152    0.978743    1.025270    1.015988    1.006695
min     -3.000951   -2.637901   -3.303099   -3.159200   -3.188821
25%     -0.647623   -0.576449   -0.712369   -0.691338   -0.691115
50%      0.047578   -0.021499   -0.023888   -0.032652   -0.025363
75%      0.729907    0.775880    0.618896    0.670047    0.649748
max      2.740139    2.752332    3.004229    2.728702    3.240991

---->   pandas.Series; Series.describe; pandas.DataFrame; DataFrame.describe

--------------------------------------
ID: 3702 --> 1
In [100]: series.describe(percentiles=[0.05, 0.25, 0.75, 0.95])
Out[100]: 
count    500.000000
mean      -0.021292
std        1.015906
min       -2.683763
5%        -1.645423
25%       -0.699070
50%       -0.069718
75%        0.714483
95%        1.711409
max        3.160915
dtype: float64

---->   Series.describe

--------------------------------------
ID: 3703 --> 2
In [101]: s = pd.Series(["a", "a", "b", "b", "a", "a", np.nan, "c", "d", "a"])

In [102]: s.describe()
Out[102]: 
count     9
unique    4
top       a
freq      5
dtype: object

---->   pandas.Series; Series.describe

--------------------------------------
ID: 3704 --> 2
In [103]: frame = pd.DataFrame({"a": ["Yes", "Yes", "No", "No"], "b": range(4)})

In [104]: frame.describe()
Out[104]: 
              b
count  4.000000
mean   1.500000
std    1.290994
min    0.000000
25%    0.750000
50%    1.500000
75%    2.250000
max    3.000000

---->   pandas.DataFrame; DataFrame.describe

--------------------------------------
ID: 3705 --> 1
In [105]: frame.describe(include=["object"])
Out[105]: 
          a
count     4
unique    2
top     Yes
freq      2

In [106]: frame.describe(include=["number"])
Out[106]: 
              b
count  4.000000
mean   1.500000
std    1.290994
min    0.000000
25%    0.750000
50%    1.500000
75%    2.250000
max    3.000000

In [107]: frame.describe(include="all")
Out[107]: 
          a         b
count     4  4.000000
unique    2       NaN
top     Yes       NaN
freq      2       NaN
mean    NaN  1.500000
std     NaN  1.290994
min     NaN  0.000000
25%     NaN  0.750000
50%     NaN  1.500000
75%     NaN  2.250000
max     NaN  3.000000

---->   DataFrame.describe

--------------------------------------
ID: 3706 --> 6
In [108]: s1 = pd.Series(np.random.randn(5))

In [109]: s1
Out[109]: 
0    1.118076
1   -0.352051
2   -1.242883
3   -1.277155
4   -0.641184
dtype: float64

In [110]: s1.idxmin(), s1.idxmax()
Out[110]: (3, 0)

In [111]: df1 = pd.DataFrame(np.random.randn(5, 3), columns=["A", "B", "C"])

In [112]: df1
Out[112]: 
          A         B         C
0 -0.327863 -0.946180 -0.137570
1 -0.186235 -0.257213 -0.486567
2 -0.507027 -0.871259 -0.111110
3  2.000339 -2.430505  0.089759
4 -0.321434 -0.033695  0.096271

In [113]: df1.idxmin(axis=0)
Out[113]: 
A    2
B    3
C    1
dtype: int64

In [114]: df1.idxmax(axis=1)
Out[114]: 
0    C
1    A
2    C
3    A
4    C
dtype: object

---->   pandas.Series; Series.idxmin; Series.idxmax; pandas.DataFrame; DataFrame.idxmin; DataFrame.idxmax

--------------------------------------
ID: 3707 --> 1
In [115]: df3 = pd.DataFrame([2, 1, 1, 3, np.nan], columns=["A"], index=list("edcba"))

In [116]: df3
Out[116]: 
     A
e  2.0
d  1.0
c  1.0
b  3.0
a  NaN

In [117]: df3["A"].idxmin()
Out[117]: 'd'

---->   pandas.DataFrame

--------------------------------------
ID: 3708 --> 2
In [118]: data = np.random.randint(0, 7, size=50)

In [119]: data
Out[119]: 
array([6, 6, 2, 3, 5, 3, 2, 5, 4, 5, 4, 3, 4, 5, 0, 2, 0, 4, 2, 0, 3, 2,
       2, 5, 6, 5, 3, 4, 6, 4, 3, 5, 6, 4, 3, 6, 2, 6, 6, 2, 3, 4, 2, 1,
       6, 2, 6, 1, 5, 4])

In [120]: s = pd.Series(data)

In [121]: s.value_counts()
Out[121]: 
6    10
2    10
4     9
3     8
5     8
0     3
1     2
Name: count, dtype: int64

In [122]: pd.value_counts(data)
Out[122]: 
6    10
2    10
4     9
3     8
5     8
0     3
1     2
Name: count, dtype: int64

---->   pandas.Series; Series.value_counts

--------------------------------------
ID: 3709 --> 2
In [123]: data = {"a": [1, 2, 3, 4], "b": ["x", "x", "y", "y"]}

In [124]: frame = pd.DataFrame(data)

In [125]: frame.value_counts()
Out[125]: 
a  b
1  x    1
2  x    1
3  y    1
4  y    1
Name: count, dtype: int64

---->   pandas.DataFrame; DataFrame.value_counts

--------------------------------------
ID: 3710 --> 4
In [126]: s5 = pd.Series([1, 1, 3, 3, 3, 5, 5, 7, 7, 7])

In [127]: s5.mode()
Out[127]: 
0    3
1    7
dtype: int64

In [128]: df5 = pd.DataFrame(
   .....:     {
   .....:         "A": np.random.randint(0, 7, size=50),
   .....:         "B": np.random.randint(-10, 15, size=50),
   .....:     }
   .....: )
   .....: 

In [129]: df5.mode()
Out[129]: 
     A   B
0  1.0  -9
1  NaN  10
2  NaN  13

---->   pandas.Series; Series.mode; pandas.DataFrame; DataFrame.mode

--------------------------------------
ID: 3711 --> 1
In [130]: arr = np.random.randn(20)

In [131]: factor = pd.cut(arr, 4)

In [132]: factor
Out[132]: 
[(-0.251, 0.464], (-0.968, -0.251], (0.464, 1.179], (-0.251, 0.464], (-0.968, -0.251], ..., (-0.251, 0.464], (-0.968, -0.251], (-0.968, -0.251], (-0.968, -0.251], (-0.968, -0.251]]
Length: 20
Categories (4, interval[float64, right]): [(-0.968, -0.251] < (-0.251, 0.464] < (0.464, 1.179] <
                                           (1.179, 1.893]]

In [133]: factor = pd.cut(arr, [-5, -1, 0, 1, 5])

In [134]: factor
Out[134]: 
[(0, 1], (-1, 0], (0, 1], (0, 1], (-1, 0], ..., (-1, 0], (-1, 0], (-1, 0], (-1, 0], (-1, 0]]
Length: 20
Categories (4, interval[int64, right]): [(-5, -1] < (-1, 0] < (0, 1] < (1, 5]]

---->   pandas.cut

--------------------------------------
ID: 3712 --> 1
In [135]: arr = np.random.randn(30)

In [136]: factor = pd.qcut(arr, [0, 0.25, 0.5, 0.75, 1])

In [137]: factor
Out[137]: 
[(0.569, 1.184], (-2.278, -0.301], (-2.278, -0.301], (0.569, 1.184], (0.569, 1.184], ..., (-0.301, 0.569], (1.184, 2.346], (1.184, 2.346], (-0.301, 0.569], (-2.278, -0.301]]
Length: 30
Categories (4, interval[float64, right]): [(-2.278, -0.301] < (-0.301, 0.569] < (0.569, 1.184] <
                                           (1.184, 2.346]]

In [138]: pd.value_counts(factor)
Out[138]: 
(-2.278, -0.301]    8
(1.184, 2.346]      8
(-0.301, 0.569]     7
(0.569, 1.184]      7
Name: count, dtype: int64

---->   pandas.qcut

--------------------------------------
ID: 3713 --> 1
In [139]: arr = np.random.randn(20)

In [140]: factor = pd.cut(arr, [-np.inf, 0, np.inf])

In [141]: factor
Out[141]: 
[(-inf, 0.0], (0.0, inf], (0.0, inf], (-inf, 0.0], (-inf, 0.0], ..., (-inf, 0.0], (-inf, 0.0], (-inf, 0.0], (0.0, inf], (0.0, inf]]
Length: 20
Categories (2, interval[float64, right]): [(-inf, 0.0] < (0.0, inf]]

---->   pandas.cut

--------------------------------------
ID: 3714 --> 1
In [142]: def extract_city_name(df):
   .....:     """
   .....:     Chicago, IL -> Chicago for city_name column
   .....:     """
   .....:     df["city_name"] = df["city_and_code"].str.split(",").str.get(0)
   .....:     return df
   .....: 

In [143]: def add_country_name(df, country_name=None):
   .....:     """
   .....:     Chicago -> Chicago-US for city_name column
   .....:     """
   .....:     col = "city_name"
   .....:     df["city_and_country"] = df[col] + country_name
   .....:     return df
   .....: 

In [144]: df_p = pd.DataFrame({"city_and_code": ["Chicago, IL"]})

---->   pandas.DataFrame

--------------------------------------
ID: 3716 --> 1
In [146]: df_p.pipe(extract_city_name).pipe(add_country_name, country_name="US")
Out[146]: 
  city_and_code city_name city_and_country
0   Chicago, IL   Chicago        ChicagoUS

---->   DataFrame.pipe

--------------------------------------
ID: 3718 --> 2
In [147]: df.apply(np.mean)
Out[147]: 
one      0.811094
two      1.360588
three    0.187958
dtype: float64

In [148]: df.apply(np.mean, axis=1)
Out[148]: 
a    1.583749
b    0.734929
c    1.133683
d   -0.166914
dtype: float64

In [149]: df.apply(lambda x: x.max() - x.min())
Out[149]: 
one      1.051928
two      1.632779
three    1.840607
dtype: float64

In [150]: df.apply(np.cumsum)
Out[150]: 
        one       two     three
a  1.394981  1.772517       NaN
b  1.738035  3.684640 -0.050390
c  2.433281  5.163008  1.177045
d       NaN  5.442353  0.563873

In [151]: df.apply(np.exp)
Out[151]: 
        one       two     three
a  4.034899  5.885648       NaN
b  1.409244  6.767440  0.950858
c  2.004201  4.385785  3.412466
d       NaN  1.322262  0.541630

---->   Series.max; Series.min

--------------------------------------
ID: 3720 --> 2
In [154]: tsdf = pd.DataFrame(
   .....:     np.random.randn(1000, 3),
   .....:     columns=["A", "B", "C"],
   .....:     index=pd.date_range("1/1/2000", periods=1000),
   .....: )
   .....: 

In [155]: tsdf.apply(lambda x: x.idxmax())
Out[155]: 
A   2000-08-06
B   2001-01-18
C   2001-07-18
dtype: datetime64[ns]

---->   pandas.DataFrame; Series.idxmax

--------------------------------------
ID: 3724 --> 1
In [158]: tsdf = pd.DataFrame(
   .....:     np.random.randn(10, 3),
   .....:     columns=["A", "B", "C"],
   .....:     index=pd.date_range("1/1/2000", periods=10),
   .....: )
   .....: 

In [159]: tsdf.iloc[3:7] = np.nan

In [160]: tsdf
Out[160]: 
                   A         B         C
2000-01-01  1.257606  1.004194  0.167574
2000-01-02 -0.749892  0.288112 -0.757304
2000-01-03 -0.207550 -0.298599  0.116018
2000-01-04       NaN       NaN       NaN
2000-01-05       NaN       NaN       NaN
2000-01-06       NaN       NaN       NaN
2000-01-07       NaN       NaN       NaN
2000-01-08  0.814347 -0.257623  0.869226
2000-01-09 -0.250663 -1.206601  0.896839
2000-01-10  2.169758 -1.333363  0.283157

---->   pandas.DataFrame

--------------------------------------
ID: 3730 --> 1
In [168]: tsdf["A"].agg(["sum", lambda x: x.mean()])
Out[168]: 
sum         3.033606
    0.505601
Name: A, dtype: float64

---->   Series.mean

--------------------------------------
ID: 3731 --> 1
In [169]: def mymean(x):
   .....:     return x.mean()
   .....: 

In [170]: tsdf["A"].agg(["sum", mymean])
Out[170]: 
sum       3.033606
mymean    0.505601
Name: A, dtype: float64

---->   Series.mean

--------------------------------------
ID: 3735 --> 1
In [179]: tsdf = pd.DataFrame(
   .....:     np.random.randn(10, 3),
   .....:     columns=["A", "B", "C"],
   .....:     index=pd.date_range("1/1/2000", periods=10),
   .....: )
   .....: 

In [180]: tsdf.iloc[3:7] = np.nan

In [181]: tsdf
Out[181]: 
                   A         B         C
2000-01-01 -0.428759 -0.864890 -0.675341
2000-01-02 -0.168731  1.338144 -1.279321
2000-01-03 -1.621034  0.438107  0.903794
2000-01-04       NaN       NaN       NaN
2000-01-05       NaN       NaN       NaN
2000-01-06       NaN       NaN       NaN
2000-01-07       NaN       NaN       NaN
2000-01-08  0.254374 -1.240447 -0.201052
2000-01-09 -0.157795  0.791197 -1.144209
2000-01-10 -0.030876  0.371900  0.061932

---->   pandas.DataFrame

--------------------------------------
ID: 3736 --> 1
In [182]: tsdf.transform(np.abs)
Out[182]: 
                   A         B         C
2000-01-01  0.428759  0.864890  0.675341
2000-01-02  0.168731  1.338144  1.279321
2000-01-03  1.621034  0.438107  0.903794
2000-01-04       NaN       NaN       NaN
2000-01-05       NaN       NaN       NaN
2000-01-06       NaN       NaN       NaN
2000-01-07       NaN       NaN       NaN
2000-01-08  0.254374  1.240447  0.201052
2000-01-09  0.157795  0.791197  1.144209
2000-01-10  0.030876  0.371900  0.061932

In [183]: tsdf.transform("abs")
Out[183]: 
                   A         B         C
2000-01-01  0.428759  0.864890  0.675341
2000-01-02  0.168731  1.338144  1.279321
2000-01-03  1.621034  0.438107  0.903794
2000-01-04       NaN       NaN       NaN
2000-01-05       NaN       NaN       NaN
2000-01-06       NaN       NaN       NaN
2000-01-07       NaN       NaN       NaN
2000-01-08  0.254374  1.240447  0.201052
2000-01-09  0.157795  0.791197  1.144209
2000-01-10  0.030876  0.371900  0.061932

In [184]: tsdf.transform(lambda x: x.abs())
Out[184]: 
                   A         B         C
2000-01-01  0.428759  0.864890  0.675341
2000-01-02  0.168731  1.338144  1.279321
2000-01-03  1.621034  0.438107  0.903794
2000-01-04       NaN       NaN       NaN
2000-01-05       NaN       NaN       NaN
2000-01-06       NaN       NaN       NaN
2000-01-07       NaN       NaN       NaN
2000-01-08  0.254374  1.240447  0.201052
2000-01-09  0.157795  0.791197  1.144209
2000-01-10  0.030876  0.371900  0.061932

---->   Series.abs

--------------------------------------
ID: 3743 --> 1
In [191]: df4
Out[191]: 
        one       two     three
a  1.394981  1.772517       NaN
b  0.343054  1.912123 -0.050390
c  0.695246  1.478369  1.227435
d       NaN  0.279344 -0.613172

In [192]: def f(x):
   .....:     return len(str(x))
   .....: 

In [193]: df4["one"].map(f)
Out[193]: 
a    18
b    19
c    18
d     3
Name: one, dtype: int64

In [194]: df4.applymap(f)
Out[194]: 
   one  two  three
a   18   17      3
b   19   18     20
c   18   18     16
d    3   19     19

---->   DataFrame.applymap

--------------------------------------
ID: 3744 --> 2
In [195]: s = pd.Series(
   .....:     ["six", "seven", "six", "seven", "six"], index=["a", "b", "c", "d", "e"]
   .....: )
   .....: 

In [196]: t = pd.Series({"six": 6.0, "seven": 7.0})

In [197]: s
Out[197]: 
a      six
b    seven
c      six
d    seven
e      six
dtype: object

In [198]: s.map(t)
Out[198]: 
a    6.0
b    7.0
c    6.0
d    7.0
e    6.0
dtype: float64

---->   pandas.Series; Series.map

--------------------------------------
ID: 3745 --> 1
In [199]: s = pd.Series(np.random.randn(5), index=["a", "b", "c", "d", "e"])

In [200]: s
Out[200]: 
a    1.695148
b    1.328614
c    1.234686
d   -0.385845
e   -1.326508
dtype: float64

In [201]: s.reindex(["e", "b", "f", "d"])
Out[201]: 
e   -1.326508
b    1.328614
f         NaN
d   -0.385845
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 3749 --> 1
In [209]: df2
Out[209]: 
        one       two
a  1.394981  1.772517
b  0.343054  1.912123
c  0.695246  1.478369

In [210]: df3
Out[210]: 
        one       two
a  0.583888  0.051514
b -0.468040  0.191120
c -0.115848 -0.242634

In [211]: df.reindex_like(df2)
Out[211]: 
        one       two
a  1.394981  1.772517
b  0.343054  1.912123
c  0.695246  1.478369

---->   DataFrame.reindex_like

--------------------------------------
ID: 3750 --> 2
In [212]: s = pd.Series(np.random.randn(5), index=["a", "b", "c", "d", "e"])

In [213]: s1 = s[:4]

In [214]: s2 = s[1:]

In [215]: s1.align(s2)
Out[215]: 
(a   -0.186646
 b   -1.692424
 c   -0.303893
 d   -1.425662
 e         NaN
 dtype: float64,
 a         NaN
 b   -1.692424
 c   -0.303893
 d   -1.425662
 e    1.114285
 dtype: float64)

In [216]: s1.align(s2, join="inner")
Out[216]: 
(b   -1.692424
 c   -0.303893
 d   -1.425662
 dtype: float64,
 b   -1.692424
 c   -0.303893
 d   -1.425662
 dtype: float64)

In [217]: s1.align(s2, join="left")
Out[217]: 
(a   -0.186646
 b   -1.692424
 c   -0.303893
 d   -1.425662
 dtype: float64,
 a         NaN
 b   -1.692424
 c   -0.303893
 d   -1.425662
 dtype: float64)

---->   pandas.Series; Series.align

--------------------------------------
ID: 3751 --> 1
In [218]: df.align(df2, join="inner")
Out[218]: 
(        one       two
 a  1.394981  1.772517
 b  0.343054  1.912123
 c  0.695246  1.478369,
         one       two
 a  1.394981  1.772517
 b  0.343054  1.912123
 c  0.695246  1.478369)

---->   DataFrame.align

--------------------------------------
ID: 3752 --> 1
In [219]: df.align(df2, join="inner", axis=0)
Out[219]: 
(        one       two     three
 a  1.394981  1.772517       NaN
 b  0.343054  1.912123 -0.050390
 c  0.695246  1.478369  1.227435,
         one       two
 a  1.394981  1.772517
 b  0.343054  1.912123
 c  0.695246  1.478369)

---->   DataFrame.align

--------------------------------------
ID: 3753 --> 1
In [220]: df.align(df2.iloc[0], axis=1)
Out[220]: 
(        one     three       two
 a  1.394981       NaN  1.772517
 b  0.343054 -0.050390  1.912123
 c  0.695246  1.227435  1.478369
 d       NaN -0.613172  0.279344,
 one      1.394981
 three         NaN
 two      1.772517
 Name: a, dtype: float64)

---->   DataFrame.align

--------------------------------------
ID: 3754 --> 1
In [221]: rng = pd.date_range("1/3/2000", periods=8)

In [222]: ts = pd.Series(np.random.randn(8), index=rng)

In [223]: ts2 = ts[[0, 3, 6]]

In [224]: ts
Out[224]: 
2000-01-03    0.183051
2000-01-04    0.400528
2000-01-05   -0.015083
2000-01-06    2.395489
2000-01-07    1.414806
2000-01-08    0.118428
2000-01-09    0.733639
2000-01-10   -0.936077
Freq: D, dtype: float64

In [225]: ts2
Out[225]: 
2000-01-03    0.183051
2000-01-06    2.395489
2000-01-09    0.733639
Freq: 3D, dtype: float64

In [226]: ts2.reindex(ts.index)
Out[226]: 
2000-01-03    0.183051
2000-01-04         NaN
2000-01-05         NaN
2000-01-06    2.395489
2000-01-07         NaN
2000-01-08         NaN
2000-01-09    0.733639
2000-01-10         NaN
Freq: D, dtype: float64

In [227]: ts2.reindex(ts.index, method="ffill")
Out[227]: 
2000-01-03    0.183051
2000-01-04    0.183051
2000-01-05    0.183051
2000-01-06    2.395489
2000-01-07    2.395489
2000-01-08    2.395489
2000-01-09    0.733639
2000-01-10    0.733639
Freq: D, dtype: float64

In [228]: ts2.reindex(ts.index, method="bfill")
Out[228]: 
2000-01-03    0.183051
2000-01-04    2.395489
2000-01-05    2.395489
2000-01-06    2.395489
2000-01-07    0.733639
2000-01-08    0.733639
2000-01-09    0.733639
2000-01-10         NaN
Freq: D, dtype: float64

In [229]: ts2.reindex(ts.index, method="nearest")
Out[229]: 
2000-01-03    0.183051
2000-01-04    0.183051
2000-01-05    2.395489
2000-01-06    2.395489
2000-01-07    2.395489
2000-01-08    0.733639
2000-01-09    0.733639
2000-01-10    0.733639
Freq: D, dtype: float64

---->   pandas.Series

--------------------------------------
ID: 3764 --> 2
In [243]: df = pd.DataFrame(
   .....:     {"x": [1, 2, 3, 4, 5, 6], "y": [10, 20, 30, 40, 50, 60]},
   .....:     index=pd.MultiIndex.from_product(
   .....:         [["a", "b", "c"], [1, 2]], names=["let", "num"]
   .....:     ),
   .....: )
   .....: 

In [244]: df
Out[244]: 
         x   y
let num       
a   1    1  10
    2    2  20
b   1    3  30
    2    4  40
c   1    5  50
    2    6  60

In [245]: df.rename_axis(index={"let": "abc"})
Out[245]: 
         x   y
abc num       
a   1    1  10
    2    2  20
b   1    3  30
    2    4  40
c   1    5  50
    2    6  60

In [246]: df.rename_axis(index=str.upper)
Out[246]: 
         x   y
LET NUM       
a   1    1  10
    2    2  20
b   1    3  30
    2    4  40
c   1    5  50
    2    6  60

---->   pandas.DataFrame; pandas.MultiIndex

--------------------------------------
ID: 3765 --> 1
In [247]: df = pd.DataFrame(
   .....:     {"col1": np.random.randn(3), "col2": np.random.randn(3)}, index=["a", "b", "c"]
   .....: )
   .....: 

In [248]: for col in df:
   .....:     print(col)
   .....: 
col1
col2

---->   pandas.DataFrame

--------------------------------------
ID: 3766 --> 2
In [249]: df = pd.DataFrame({"a": [1, 2, 3], "b": ["a", "b", "c"]})

In [250]: for index, row in df.iterrows():
   .....:     row["a"] = 10
   .....: 

In [251]: df
Out[251]: 
   a  b
0  1  a
1  2  b
2  3  c

---->   pandas.DataFrame; DataFrame.iterrows

--------------------------------------
ID: 3767 --> 1
In [252]: for label, ser in df.items():
   .....:     print(label)
   .....:     print(ser)
   .....: 
a
0    1
1    2
2    3
Name: a, dtype: int64
b
0    a
1    b
2    c
Name: b, dtype: object

---->   DataFrame.items

--------------------------------------
ID: 3768 --> 1
In [253]: for row_index, row in df.iterrows():
   .....:     print(row_index, row, sep="\n")
   .....: 
0
a    1
b    a
Name: 0, dtype: object
1
a    2
b    b
Name: 1, dtype: object
2
a    3
b    c
Name: 2, dtype: object

---->   DataFrame.iterrows

--------------------------------------
ID: 3769 --> 2
In [254]: df_orig = pd.DataFrame([[1, 1.5]], columns=["int", "float"])

In [255]: df_orig.dtypes
Out[255]: 
int        int64
float    float64
dtype: object

In [256]: row = next(df_orig.iterrows())[1]

In [257]: row
Out[257]: 
int      1.0
float    1.5
Name: 0, dtype: float64

---->   pandas.DataFrame; DataFrame.iterrows

--------------------------------------
ID: 3771 --> 2
In [260]: df2 = pd.DataFrame({"x": [1, 2, 3], "y": [4, 5, 6]})

In [261]: print(df2)
   x  y
0  1  4
1  2  5
2  3  6

In [262]: print(df2.T)
   0  1  2
x  1  2  3
y  4  5  6

In [263]: df2_t = pd.DataFrame({idx: values for idx, values in df2.iterrows()})

In [264]: print(df2_t)
   0  1  2
x  1  2  3
y  4  5  6

---->   pandas.DataFrame; DataFrame.iterrows

--------------------------------------
ID: 3772 --> 1
In [265]: for row in df.itertuples():
   .....:     print(row)
   .....: 
Pandas(Index=0, a=1, b='a')
Pandas(Index=1, a=2, b='b')
Pandas(Index=2, a=3, b='c')

---->   DataFrame.itertuples

--------------------------------------
ID: 3773 --> 1
# datetime
In [266]: s = pd.Series(pd.date_range("20130101 09:10:12", periods=4))

In [267]: s
Out[267]: 
0   2013-01-01 09:10:12
1   2013-01-02 09:10:12
2   2013-01-03 09:10:12
3   2013-01-04 09:10:12
dtype: datetime64[ns]

In [268]: s.dt.hour
Out[268]: 
0    9
1    9
2    9
3    9
dtype: int32

In [269]: s.dt.second
Out[269]: 
0    12
1    12
2    12
3    12
dtype: int32

In [270]: s.dt.day
Out[270]: 
0    1
1    2
2    3
3    4
dtype: int32

---->   pandas.Series

--------------------------------------
ID: 3776 --> 1
# DatetimeIndex
In [276]: s = pd.Series(pd.date_range("20130101", periods=4))

In [277]: s
Out[277]: 
0   2013-01-01
1   2013-01-02
2   2013-01-03
3   2013-01-04
dtype: datetime64[ns]

In [278]: s.dt.strftime("%Y/%m/%d")
Out[278]: 
0    2013/01/01
1    2013/01/02
2    2013/01/03
3    2013/01/04
dtype: object

---->   pandas.Series

--------------------------------------
ID: 3777 --> 2
# PeriodIndex
In [279]: s = pd.Series(pd.period_range("20130101", periods=4))

In [280]: s
Out[280]: 
0    2013-01-01
1    2013-01-02
2    2013-01-03
3    2013-01-04
dtype: period[D]

In [281]: s.dt.strftime("%Y/%m/%d")
Out[281]: 
0    2013/01/01
1    2013/01/02
2    2013/01/03
3    2013/01/04
dtype: object

---->   pandas.Series; pandas.period_range

--------------------------------------
ID: 3778 --> 2
# period
In [282]: s = pd.Series(pd.period_range("20130101", periods=4, freq="D"))

In [283]: s
Out[283]: 
0    2013-01-01
1    2013-01-02
2    2013-01-03
3    2013-01-04
dtype: period[D]

In [284]: s.dt.year
Out[284]: 
0    2013
1    2013
2    2013
3    2013
dtype: int64

In [285]: s.dt.day
Out[285]: 
0    1
1    2
2    3
3    4
dtype: int64

---->   pandas.Series; pandas.period_range

--------------------------------------
ID: 3779 --> 1
# timedelta
In [286]: s = pd.Series(pd.timedelta_range("1 day 00:00:05", periods=4, freq="s"))

In [287]: s
Out[287]: 
0   1 days 00:00:05
1   1 days 00:00:06
2   1 days 00:00:07
3   1 days 00:00:08
dtype: timedelta64[ns]

In [288]: s.dt.days
Out[288]: 
0    1
1    1
2    1
3    1
dtype: int64

In [289]: s.dt.seconds
Out[289]: 
0    5
1    6
2    7
3    8
dtype: int32

In [290]: s.dt.components
Out[290]: 
   days  hours  minutes  seconds  milliseconds  microseconds  nanoseconds
0     1      0        0        5             0             0            0
1     1      0        0        6             0             0            0
2     1      0        0        7             0             0            0
3     1      0        0        8             0             0            0

---->   pandas.Series

--------------------------------------
ID: 3780 --> 1
In [291]: s = pd.Series(
   .....:     ["A", "B", "C", "Aaba", "Baca", np.nan, "CABA", "dog", "cat"], dtype="string"
   .....: )
   .....: 

In [292]: s.str.lower()
Out[292]: 
0       a
1       b
2       c
3    aaba
4    baca
5    
6    caba
7     dog
8     cat
dtype: string

---->   pandas.Series

--------------------------------------
ID: 3781 --> 2
In [293]: df = pd.DataFrame(
   .....:     {
   .....:         "one": pd.Series(np.random.randn(3), index=["a", "b", "c"]),
   .....:         "two": pd.Series(np.random.randn(4), index=["a", "b", "c", "d"]),
   .....:         "three": pd.Series(np.random.randn(3), index=["b", "c", "d"]),
   .....:     }
   .....: )
   .....: 

In [294]: unsorted_df = df.reindex(
   .....:     index=["a", "d", "c", "b"], columns=["three", "two", "one"]
   .....: )
   .....: 

In [295]: unsorted_df
Out[295]: 
      three       two       one
a       NaN -1.152244  0.562973
d -0.252916 -0.109597       NaN
c  1.273388 -0.167123  0.640382
b -0.098217  0.009797 -1.299504

# DataFrame
In [296]: unsorted_df.sort_index()
Out[296]: 
      three       two       one
a       NaN -1.152244  0.562973
b -0.098217  0.009797 -1.299504
c  1.273388 -0.167123  0.640382
d -0.252916 -0.109597       NaN

In [297]: unsorted_df.sort_index(ascending=False)
Out[297]: 
      three       two       one
d -0.252916 -0.109597       NaN
c  1.273388 -0.167123  0.640382
b -0.098217  0.009797 -1.299504
a       NaN -1.152244  0.562973

In [298]: unsorted_df.sort_index(axis=1)
Out[298]: 
        one     three       two
a  0.562973       NaN -1.152244
d       NaN -0.252916 -0.109597
c  0.640382  1.273388 -0.167123
b -1.299504 -0.098217  0.009797

# Series
In [299]: unsorted_df["three"].sort_index()
Out[299]: 
a         NaN
b   -0.098217
c    1.273388
d   -0.252916
Name: three, dtype: float64

---->   pandas.DataFrame; pandas.Series

--------------------------------------
ID: 3782 --> 1
In [300]: s1 = pd.DataFrame({"a": ["B", "a", "C"], "b": [1, 2, 3], "c": [2, 3, 4]}).set_index(
   .....:     list("ab")
   .....: )
   .....: 

In [301]: s1
Out[301]: 
     c
a b   
B 1  2
a 2  3
C 3  4

---->   pandas.DataFrame

--------------------------------------
ID: 3784 --> 1
In [304]: df1 = pd.DataFrame(
   .....:     {"one": [2, 1, 1, 1], "two": [1, 3, 2, 4], "three": [5, 4, 3, 2]}
   .....: )
   .....: 

In [305]: df1.sort_values(by="two")
Out[305]: 
   one  two  three
0    2    1      5
2    1    2      3
1    1    3      4
3    1    4      2

---->   pandas.DataFrame

--------------------------------------
ID: 3787 --> 1
In [310]: s1 = pd.Series(["B", "a", "C"])

---->   pandas.Series

--------------------------------------
ID: 3789 --> 1
In [313]: df = pd.DataFrame({"a": ["B", "a", "C"], "b": [1, 2, 3]})

---->   pandas.DataFrame

--------------------------------------
ID: 3791 --> 2
# Build MultiIndex
In [316]: idx = pd.MultiIndex.from_tuples(
   .....:     [("a", 1), ("a", 2), ("a", 2), ("b", 2), ("b", 1), ("b", 1)]
   .....: )
   .....: 

In [317]: idx.names = ["first", "second"]

# Build DataFrame
In [318]: df_multi = pd.DataFrame({"A": np.arange(6, 0, -1)}, index=idx)

In [319]: df_multi
Out[319]: 
              A
first second   
a     1       6
      2       5
      2       4
b     2       3
      1       2
      1       1

---->   pandas.MultiIndex; pandas.DataFrame

--------------------------------------
ID: 3793 --> 2
In [321]: ser = pd.Series([1, 2, 3])

In [322]: ser.searchsorted([0, 3])
Out[322]: array([0, 2])

In [323]: ser.searchsorted([0, 4])
Out[323]: array([0, 3])

In [324]: ser.searchsorted([1, 3], side="right")
Out[324]: array([1, 3])

In [325]: ser.searchsorted([1, 3], side="left")
Out[325]: array([0, 2])

In [326]: ser = pd.Series([3, 1, 2])

In [327]: ser.searchsorted([0, 3], sorter=np.argsort(ser))
Out[327]: array([0, 2])

---->   pandas.Series; Series.searchsorted

--------------------------------------
ID: 3794 --> 3
In [328]: s = pd.Series(np.random.permutation(10))

In [329]: s
Out[329]: 
0    2
1    0
2    3
3    7
4    1
5    5
6    9
7    6
8    8
9    4
dtype: int64

In [330]: s.sort_values()
Out[330]: 
1    0
4    1
0    2
2    3
9    4
5    5
7    6
3    7
8    8
6    9
dtype: int64

In [331]: s.nsmallest(3)
Out[331]: 
1    0
4    1
0    2
dtype: int64

In [332]: s.nlargest(3)
Out[332]: 
6    9
8    8
3    7
dtype: int64

---->   pandas.Series; Series.nsmallest; Series.nlargest

--------------------------------------
ID: 3795 --> 3
In [333]: df = pd.DataFrame(
   .....:     {
   .....:         "a": [-2, -1, 1, 10, 8, 11, -1],
   .....:         "b": list("abdceff"),
   .....:         "c": [1.0, 2.0, 4.0, 3.2, np.nan, 3.0, 4.0],
   .....:     }
   .....: )
   .....: 

In [334]: df.nlargest(3, "a")
Out[334]: 
    a  b    c
5  11  f  3.0
3  10  c  3.2
4   8  e  NaN

In [335]: df.nlargest(5, ["a", "c"])
Out[335]: 
    a  b    c
5  11  f  3.0
3  10  c  3.2
4   8  e  NaN
2   1  d  4.0
6  -1  f  4.0

In [336]: df.nsmallest(3, "a")
Out[336]: 
   a  b    c
0 -2  a  1.0
1 -1  b  2.0
6 -1  f  4.0

In [337]: df.nsmallest(5, ["a", "c"])
Out[337]: 
   a  b    c
0 -2  a  1.0
1 -1  b  2.0
6 -1  f  4.0
2  1  d  4.0
4  8  e  NaN

---->   pandas.DataFrame; DataFrame.nlargest; DataFrame.nsmallest

--------------------------------------
ID: 3796 --> 1
In [338]: df1.columns = pd.MultiIndex.from_tuples(
   .....:     [("a", "one"), ("a", "two"), ("b", "three")]
   .....: )
   .....: 

In [339]: df1.sort_values(by=("a", "two"))
Out[339]: 
    a         b
  one two three
0   2   1     5
2   1   2     3
1   1   3     4
3   1   4     2

---->   pandas.MultiIndex

--------------------------------------
ID: 3797 --> 2
In [340]: dft = pd.DataFrame(
   .....:     {
   .....:         "A": np.random.rand(3),
   .....:         "B": 1,
   .....:         "C": "foo",
   .....:         "D": pd.Timestamp("20010102"),
   .....:         "E": pd.Series([1.0] * 3).astype("float32"),
   .....:         "F": False,
   .....:         "G": pd.Series([1] * 3, dtype="int8"),
   .....:     }
   .....: )
   .....: 

In [341]: dft
Out[341]: 
          A  B    C          D    E      F  G
0  0.035962  1  foo 2001-01-02  1.0  False  1
1  0.701379  1  foo 2001-01-02  1.0  False  1
2  0.281885  1  foo 2001-01-02  1.0  False  1

In [342]: dft.dtypes
Out[342]: 
A           float64
B             int64
C            object
D    datetime64[ns]
E           float32
F              bool
G              int8
dtype: object

---->   pandas.DataFrame; pandas.Series

--------------------------------------
ID: 3799 --> 1
# these ints are coerced to floats
In [344]: pd.Series([1, 2, 3, 4, 5, 6.0])
Out[344]: 
0    1.0
1    2.0
2    3.0
3    4.0
4    5.0
5    6.0
dtype: float64

# string data forces an ``object`` dtype
In [345]: pd.Series([1, 2, 3, 6.0, "foo"])
Out[345]: 
0      1
1      2
2      3
3    6.0
4    foo
dtype: object

---->   pandas.Series

--------------------------------------
ID: 3801 --> 2
In [347]: df1 = pd.DataFrame(np.random.randn(8, 1), columns=["A"], dtype="float32")

In [348]: df1
Out[348]: 
          A
0  0.224364
1  1.890546
2  0.182879
3  0.787847
4 -0.188449
5  0.667715
6 -0.011736
7 -0.399073

In [349]: df1.dtypes
Out[349]: 
A    float32
dtype: object

In [350]: df2 = pd.DataFrame(
   .....:     {
   .....:         "A": pd.Series(np.random.randn(8), dtype="float16"),
   .....:         "B": pd.Series(np.random.randn(8)),
   .....:         "C": pd.Series(np.random.randint(0, 255, size=8), dtype="uint8"),
   .....:     }
   .....: )
   .....: 

In [351]: df2
Out[351]: 
          A         B    C
0  0.823242  0.256090   26
1  1.607422  1.426469   86
2 -0.333740 -0.416203   46
3 -0.063477  1.139976  212
4 -1.014648 -1.193477   26
5  0.678711  0.096706    7
6 -0.040863 -1.956850  184
7 -0.357422 -0.714337  206

In [352]: df2.dtypes
Out[352]: 
A    float16
B    float64
C      uint8
dtype: object

---->   pandas.DataFrame; pandas.Series

--------------------------------------
ID: 3802 --> 1
In [353]: pd.DataFrame([1, 2], columns=["a"]).dtypes
Out[353]: 
a    int64
dtype: object

In [354]: pd.DataFrame({"a": [1, 2]}).dtypes
Out[354]: 
a    int64
dtype: object

In [355]: pd.DataFrame({"a": 1}, index=list(range(2))).dtypes
Out[355]: 
a    int64
dtype: object

---->   pandas.DataFrame

--------------------------------------
ID: 3803 --> 1
In [356]: frame = pd.DataFrame(np.array([1, 2]))

---->   pandas.DataFrame

--------------------------------------
ID: 3804 --> 1
In [357]: df3 = df1.reindex_like(df2).fillna(value=0.0) + df2

In [358]: df3
Out[358]: 
          A         B      C
0  1.047606  0.256090   26.0
1  3.497968  1.426469   86.0
2 -0.150862 -0.416203   46.0
3  0.724370  1.139976  212.0
4 -1.203098 -1.193477   26.0
5  1.346426  0.096706    7.0
6 -0.052599 -1.956850  184.0
7 -0.756495 -0.714337  206.0

In [359]: df3.dtypes
Out[359]: 
A    float32
B    float64
C    float64
dtype: object

---->   DataFrame.reindex_like

--------------------------------------
ID: 3806 --> 1
In [361]: df3
Out[361]: 
          A         B      C
0  1.047606  0.256090   26.0
1  3.497968  1.426469   86.0
2 -0.150862 -0.416203   46.0
3  0.724370  1.139976  212.0
4 -1.203098 -1.193477   26.0
5  1.346426  0.096706    7.0
6 -0.052599 -1.956850  184.0
7 -0.756495 -0.714337  206.0

In [362]: df3.dtypes
Out[362]: 
A    float32
B    float64
C    float64
dtype: object

# conversion of dtypes
In [363]: df3.astype("float32").dtypes
Out[363]: 
A    float32
B    float32
C    float32
dtype: object

---->   DataFrame.astype

--------------------------------------
ID: 3807 --> 1
In [364]: dft = pd.DataFrame({"a": [1, 2, 3], "b": [4, 5, 6], "c": [7, 8, 9]})

In [365]: dft[["a", "b"]] = dft[["a", "b"]].astype(np.uint8)

In [366]: dft
Out[366]: 
   a  b  c
0  1  4  7
1  2  5  8
2  3  6  9

In [367]: dft.dtypes
Out[367]: 
a    uint8
b    uint8
c    int64
dtype: object

---->   pandas.DataFrame

--------------------------------------
ID: 3808 --> 2
In [368]: dft1 = pd.DataFrame({"a": [1, 0, 1], "b": [4, 5, 6], "c": [7, 8, 9]})

In [369]: dft1 = dft1.astype({"a": np.bool_, "c": np.float64})

In [370]: dft1
Out[370]: 
       a  b    c
0   True  4  7.0
1  False  5  8.0
2   True  6  9.0

In [371]: dft1.dtypes
Out[371]: 
a       bool
b      int64
c    float64
dtype: object

---->   pandas.DataFrame; DataFrame.astype

--------------------------------------
ID: 3809 --> 1
In [372]: dft = pd.DataFrame({"a": [1, 2, 3], "b": [4, 5, 6], "c": [7, 8, 9]})

In [373]: dft.loc[:, ["a", "b"]].astype(np.uint8).dtypes
Out[373]: 
a    uint8
b    uint8
dtype: object

In [374]: dft.loc[:, ["a", "b"]] = dft.loc[:, ["a", "b"]].astype(np.uint8)

In [375]: dft.dtypes
Out[375]: 
a    int64
b    int64
c    int64
dtype: object

---->   pandas.DataFrame

--------------------------------------
ID: 3810 --> 1
In [376]: import datetime

In [377]: df = pd.DataFrame(
   .....:     [
   .....:         [1, 2],
   .....:         ["a", "b"],
   .....:         [datetime.datetime(2016, 3, 2), datetime.datetime(2016, 3, 2)],
   .....:     ]
   .....: )
   .....: 

In [378]: df = df.T

In [379]: df
Out[379]: 
   0  1          2
0  1  a 2016-03-02
1  2  b 2016-03-02

In [380]: df.dtypes
Out[380]: 
0            object
1            object
2    datetime64[ns]
dtype: object

---->   pandas.DataFrame

--------------------------------------
ID: 3811 --> 1
In [381]: df.infer_objects().dtypes
Out[381]: 
0             int64
1            object
2    datetime64[ns]
dtype: object

---->   DataFrame.infer_objects

--------------------------------------
ID: 3812 --> 1
In [382]: m = ["1.1", 2, 3]

In [383]: pd.to_numeric(m)
Out[383]: array([1.1, 2. , 3. ])

---->   pandas.to_numeric

--------------------------------------
ID: 3813 --> 1
In [384]: import datetime

In [385]: m = ["2016-07-09", datetime.datetime(2016, 3, 2)]

In [386]: pd.to_datetime(m)
Out[386]: DatetimeIndex(['2016-07-09', '2016-03-02'], dtype='datetime64[ns]', freq=None)

---->   pandas.to_datetime

--------------------------------------
ID: 3814 --> 1
In [387]: m = ["5us", pd.Timedelta("1day")]

In [388]: pd.to_timedelta(m)
Out[388]: TimedeltaIndex(['0 days 00:00:00.000005', '1 days 00:00:00'], dtype='timedelta64[ns]', freq=None)

---->   pandas.to_timedelta

--------------------------------------
ID: 3815 --> 3
In [389]: import datetime

In [390]: m = ["apple", datetime.datetime(2016, 3, 2)]

In [391]: pd.to_datetime(m, errors="coerce")
Out[391]: DatetimeIndex(['NaT', '2016-03-02'], dtype='datetime64[ns]', freq=None)

In [392]: m = ["apple", 2, 3]

In [393]: pd.to_numeric(m, errors="coerce")
Out[393]: array([nan,  2.,  3.])

In [394]: m = ["apple", pd.Timedelta("1day")]

In [395]: pd.to_timedelta(m, errors="coerce")
Out[395]: TimedeltaIndex([NaT, '1 days'], dtype='timedelta64[ns]', freq=None)

---->   pandas.to_datetime; pandas.to_numeric; pandas.to_timedelta

--------------------------------------
ID: 3816 --> 3
In [396]: import datetime

In [397]: m = ["apple", datetime.datetime(2016, 3, 2)]

In [398]: pd.to_datetime(m, errors="ignore")
Out[398]: Index(['apple', 2016-03-02 00:00:00], dtype='object')

In [399]: m = ["apple", 2, 3]

In [400]: pd.to_numeric(m, errors="ignore")
Out[400]: array(['apple', 2, 3], dtype=object)

In [401]: m = ["apple", pd.Timedelta("1day")]

In [402]: pd.to_timedelta(m, errors="ignore")
Out[402]: array(['apple', Timedelta('1 days 00:00:00')], dtype=object)

---->   pandas.to_datetime; pandas.to_numeric; pandas.to_timedelta

--------------------------------------
ID: 3817 --> 1
In [403]: m = ["1", 2, 3]

In [404]: pd.to_numeric(m, downcast="integer")  # smallest signed int dtype
Out[404]: array([1, 2, 3], dtype=int8)

In [405]: pd.to_numeric(m, downcast="signed")  # same as 'integer'
Out[405]: array([1, 2, 3], dtype=int8)

In [406]: pd.to_numeric(m, downcast="unsigned")  # smallest unsigned int dtype
Out[406]: array([1, 2, 3], dtype=uint8)

In [407]: pd.to_numeric(m, downcast="float")  # smallest float dtype
Out[407]: array([1., 2., 3.], dtype=float32)

---->   pandas.to_numeric

--------------------------------------
ID: 3818 --> 1
In [408]: import datetime

In [409]: df = pd.DataFrame([["2016-07-09", datetime.datetime(2016, 3, 2)]] * 2, dtype="O")

In [410]: df
Out[410]: 
            0                    1
0  2016-07-09  2016-03-02 00:00:00
1  2016-07-09  2016-03-02 00:00:00

In [411]: df.apply(pd.to_datetime)
Out[411]: 
           0          1
0 2016-07-09 2016-03-02
1 2016-07-09 2016-03-02

In [412]: df = pd.DataFrame([["1.1", 2, 3]] * 2, dtype="O")

In [413]: df
Out[413]: 
     0  1  2
0  1.1  2  3
1  1.1  2  3

In [414]: df.apply(pd.to_numeric)
Out[414]: 
     0  1  2
0  1.1  2  3
1  1.1  2  3

In [415]: df = pd.DataFrame([["5us", pd.Timedelta("1day")]] * 2, dtype="O")

In [416]: df
Out[416]: 
     0                1
0  5us  1 days 00:00:00
1  5us  1 days 00:00:00

In [417]: df.apply(pd.to_timedelta)
Out[417]: 
                       0      1
0 0 days 00:00:00.000005 1 days
1 0 days 00:00:00.000005 1 days

---->   pandas.DataFrame

--------------------------------------
ID: 3819 --> 1
In [418]: dfi = df3.astype("int32")

In [419]: dfi["E"] = 1

In [420]: dfi
Out[420]: 
   A  B    C  E
0  1  0   26  1
1  3  1   86  1
2  0  0   46  1
3  0  1  212  1
4 -1 -1   26  1
5  1  0    7  1
6  0 -1  184  1
7  0  0  206  1

In [421]: dfi.dtypes
Out[421]: 
A    int32
B    int32
C    int32
E    int64
dtype: object

In [422]: casted = dfi[dfi > 0]

In [423]: casted
Out[423]: 
     A    B    C  E
0  1.0  NaN   26  1
1  3.0  1.0   86  1
2  NaN  NaN   46  1
3  NaN  1.0  212  1
4  NaN  NaN   26  1
5  1.0  NaN    7  1
6  NaN  NaN  184  1
7  NaN  NaN  206  1

In [424]: casted.dtypes
Out[424]: 
A    float64
B    float64
C      int32
E      int64
dtype: object

---->   DataFrame.astype

--------------------------------------
ID: 3820 --> 1
In [425]: dfa = df3.copy()

In [426]: dfa["A"] = dfa["A"].astype("float32")

In [427]: dfa.dtypes
Out[427]: 
A    float32
B    float64
C    float64
dtype: object

In [428]: casted = dfa[df2 > 0]

In [429]: casted
Out[429]: 
          A         B      C
0  1.047606  0.256090   26.0
1  3.497968  1.426469   86.0
2       NaN       NaN   46.0
3       NaN  1.139976  212.0
4       NaN       NaN   26.0
5  1.346426  0.096706    7.0
6       NaN       NaN  184.0
7       NaN       NaN  206.0

In [430]: casted.dtypes
Out[430]: 
A    float32
B    float64
C    float64
dtype: object

---->   DataFrame.copy

--------------------------------------
ID: 3821 --> 2
In [431]: df = pd.DataFrame(
   .....:     {
   .....:         "string": list("abc"),
   .....:         "int64": list(range(1, 4)),
   .....:         "uint8": np.arange(3, 6).astype("u1"),
   .....:         "float64": np.arange(4.0, 7.0),
   .....:         "bool1": [True, False, True],
   .....:         "bool2": [False, True, False],
   .....:         "dates": pd.date_range("now", periods=3),
   .....:         "category": pd.Series(list("ABC")).astype("category"),
   .....:     }
   .....: )
   .....: 

In [432]: df["tdeltas"] = df.dates.diff()

In [433]: df["uint64"] = np.arange(3, 6).astype("u8")

In [434]: df["other_dates"] = pd.date_range("20130101", periods=3)

In [435]: df["tz_aware_dates"] = pd.date_range("20130101", periods=3, tz="US/Eastern")

In [436]: df
Out[436]: 
  string  int64  uint8  ...  uint64  other_dates            tz_aware_dates
0      a      1      3  ...       3   2013-01-01 2013-01-01 00:00:00-05:00
1      b      2      4  ...       4   2013-01-02 2013-01-02 00:00:00-05:00
2      c      3      5  ...       5   2013-01-03 2013-01-03 00:00:00-05:00

[3 rows x 12 columns]

---->   pandas.DataFrame; pandas.Series

--------------------------------------
ID: 3822 --> 1
In [438]: df.select_dtypes(include=[bool])
Out[438]: 
   bool1  bool2
0   True  False
1  False   True
2   True  False

---->   DataFrame.select_dtypes

--------------------------------------
ID: 3823 --> 1
In [439]: df.select_dtypes(include=["bool"])
Out[439]: 
   bool1  bool2
0   True  False
1  False   True
2   True  False

---->   DataFrame.select_dtypes

--------------------------------------
ID: 3824 --> 1
In [440]: df.select_dtypes(include=["number", "bool"], exclude=["unsignedinteger"])
Out[440]: 
   int64  float64  bool1  bool2 tdeltas
0      1      4.0   True  False     NaT
1      2      5.0  False   True  1 days
2      3      6.0   True  False  1 days

---->   DataFrame.select_dtypes

--------------------------------------
ID: 3825 --> 1
In [441]: df.select_dtypes(include=["object"])
Out[441]: 
  string
0      a
1      b
2      c

---->   DataFrame.select_dtypes

--------------------------------------
ID: 3834 --> 1
import pandas as pd
import pandas._testing as tm

def test_getitem_listlike_of_ints():
    ser = pd.Series(range(5))

    result = ser[[3, 4]]
    expected = pd.Series([2, 3])
    tm.assert_series_equal(result, expected)

    result = ser.loc[[3, 4]]
    tm.assert_series_equal(result, expected)

---->   pandas.Series

--------------------------------------
ID: 3846 --> 2
import pytest
import numpy as np
import pandas as pd


@pytest.mark.parametrize('dtype', ['int8', 'int16', 'int32', 'int64'])
def test_dtypes(dtype):
    assert str(np.dtype(dtype)) == dtype


@pytest.mark.parametrize(
    'dtype', ['float32', pytest.param('int16', marks=pytest.mark.skip),
              pytest.param('int32', marks=pytest.mark.xfail(
                  reason='to show how it works'))])
def test_mark(dtype):
    assert str(np.dtype(dtype)) == 'float32'


@pytest.fixture
def series():
    return pd.Series([1, 2, 3])


@pytest.fixture(params=['int8', 'int16', 'int32', 'int64'])
def dtype(request):
    return request.param


def test_series(series, dtype):
    # GH 
    result = series.astype(dtype)
    assert result.dtype == dtype

    expected = pd.Series([1, 2, 3], dtype=dtype)
    tm.assert_series_equal(result, expected)

---->   pandas.Series; Series.astype

--------------------------------------
ID: 3850 --> 1
pd.test()

---->   pandas.test

--------------------------------------
ID: 3867 --> 2
class Series:

    def head(self, n=5):
        """
        Return the first elements of the Series.

        This function is mainly useful to preview the values of the
        Series without displaying all of it.

        Parameters
        ----------
        n : int
            Number of values to return.

        Return
        ------
        pandas.Series
            Subset of the original series with the n first values.

        See Also
        --------
        tail : Return the last n elements of the Series.

        Examples
        --------
        >>> s = pd.Series(['Ant', 'Bear', 'Cow', 'Dog', 'Falcon',
        ...                'Lion', 'Monkey', 'Rabbit', 'Zebra'])
        >>> s.head()
        0   Ant
        1   Bear
        2   Cow
        3   Dog
        4   Falcon
        dtype: object

        With the ``n`` parameter, we can change the number of returned rows:

        >>> s.head(n=3)
        0   Ant
        1   Bear
        2   Cow
        dtype: object
        """
        return self.iloc[:n]

---->   pandas.Series; Series.head

--------------------------------------
ID: 3868 --> 2
class Series:

    def mean(self):
        """
        Compute the mean of the input.

        Examples
        --------
        >>> s = pd.Series([1, 2, 3])
        >>> s.mean()
        2
        """
        pass


    def fillna(self, value):
        """
        Replace missing values by ``value``.

        Examples
        --------
        >>> s = pd.Series([1, np.nan, 3])
        >>> s.fillna(0)
        [1, 0, 3]
        """
        pass

    def groupby_mean(self):
        """
        Group by index and return mean.

        Examples
        --------
        >>> s = pd.Series([380., 370., 24., 26],
        ...               name='max_speed',
        ...               index=['falcon', 'falcon', 'parrot', 'parrot'])
        >>> s.groupby_mean()
        index
        falcon    375.0
        parrot     25.0
        Name: max_speed, dtype: float64
        """
        pass

    def contains(self, pattern, case_sensitive=True, na=numpy.nan):
        """
        Return whether each value contains ``pattern``.

        In this case, we are illustrating how to use sections, even
        if the example is simple enough and does not require them.

        Examples
        --------
        >>> s = pd.Series('Antelope', 'Lion', 'Zebra', np.nan)
        >>> s.contains(pattern='a')
        0    False
        1    False
        2     True
        3      NaN
        dtype: bool

        **Case sensitivity**

        With ``case_sensitive`` set to ``False`` we can match ``a`` with both
        ``a`` and ``A``:

        >>> s.contains(pattern='a', case_sensitive=False)
        0     True
        1    False
        2     True
        3      NaN
        dtype: bool

        **Missing values**

        We can fill missing values in the output using the ``na`` parameter:

        >>> s.contains(pattern='a', na=False)
        0    False
        1    False
        2     True
        3    False
        dtype: bool
        """
        pass

---->   pandas.Series; Series.mean

--------------------------------------
ID: 3869 --> 1
def method(foo=None, bar=None):
    """
    A sample DataFrame method.

    Do not import NumPy and pandas.

    Try to use meaningful data, when it makes the example easier
    to understand.

    Try to avoid positional arguments like in ``df.method(1)``. They
    can be all right if previously defined with a meaningful name,
    like in ``present_value(interest_rate)``, but avoid them otherwise.

    When presenting the behavior with different parameters, do not place
    all the calls one next to the other. Instead, add a short sentence
    explaining what the example shows.

    Examples
    --------
    >>> import numpy as np
    >>> import pandas as pd
    >>> df = pd.DataFrame(np.random.randn(3, 3),
    ...                   columns=('a', 'b', 'c'))
    >>> df.method(1)
    21
    >>> df.method(bar=14)
    123
    """
    pass

---->   pandas.DataFrame

--------------------------------------
ID: 3870 --> 1
>>> np.random.seed(42)
>>> df = pd.DataFrame({'normal': np.random.normal(100, 5, 20)})

---->   pandas.DataFrame

--------------------------------------
ID: 3871 --> 1
>>> df = pd.DataFrame([[1, 2, 3], [4, 5, 6]], index=['a', 'b', 'c'],
...                   columns=['A', 'B'])

---->   pandas.DataFrame

--------------------------------------
ID: 3872 --> 1
>>> pd.to_datetime(["712-01-01"])
Traceback (most recent call last):
OutOfBoundsDatetime: Out of bounds nanosecond timestamp: 712-01-01 00:00:00

---->   pandas.to_datetime

--------------------------------------
ID: 3873 --> 1
>>> s.plot()


---->   Series.plot

--------------------------------------
ID: 3874 --> 1
>>> s.plot()  


---->   Series.plot

--------------------------------------
ID: 3875 --> 2
class Series:
    def plot(self):
        """
        Generate a plot with the ``Series`` data.

        Examples
        --------

        .. plot::
            :context: close-figs

            >>> s = pd.Series([1, 2, 3])
            >>> s.plot()
        """
        pass

---->   pandas.Series; Series.plot

--------------------------------------
ID: 3881 --> 1
In [7]: air_quality["datetime"] = pd.to_datetime(air_quality["datetime"])

In [8]: air_quality["datetime"]
Out[8]: 
0      2019-06-21 00:00:00+00:00
1      2019-06-20 23:00:00+00:00
2      2019-06-20 22:00:00+00:00
3      2019-06-20 21:00:00+00:00
4      2019-06-20 20:00:00+00:00
                  ...           
2063   2019-05-07 06:00:00+00:00
2064   2019-05-07 04:00:00+00:00
2065   2019-05-07 03:00:00+00:00
2066   2019-05-07 02:00:00+00:00
2067   2019-05-07 01:00:00+00:00
Name: datetime, Length: 2068, dtype: datetime64[ns, UTC]

---->   pandas.to_datetime

--------------------------------------
ID: 3893 --> 1
In [1]: index = pd.MultiIndex.from_product(
   ...:     [range(3), ["one", "two"]], names=["first", "second"]
   ...: )
   ...: 

In [2]: index
Out[2]: 
MultiIndex([(0, 'one'),
            (0, 'two'),
            (1, 'one'),
            (1, 'two'),
            (2, 'one'),
            (2, 'two')],
           names=['first', 'second'])

In [3]: index.levels
Out[3]: FrozenList([[0, 1, 2], ['one', 'two']])

In [4]: index.codes
Out[4]: FrozenList([[0, 0, 1, 1, 2, 2], [0, 1, 0, 1, 0, 1]])

In [5]: index.names
Out[5]: FrozenList(['first', 'second'])

---->   pandas.MultiIndex

--------------------------------------
ID: 3911 --> 1
>>> import pandas as pd
>>> pd.show_versions()

---->   pandas.show_versions

--------------------------------------
ID: 3914 --> 1
>>> import pandas as pd
>>> pd.show_versions()

---->   pandas.show_versions

--------------------------------------
ID: 3919 --> 1
In [1]: df = pd.DataFrame(np.random.randn(10, 3), columns=list("abc"))

In [2]: df[["a", "c"]]
Out[2]: 
          a         c
0  0.469112 -1.509059
1 -1.135632 -0.173215
2  0.119209 -0.861849
3 -2.104569  1.071804
4  0.721555 -1.039575
5  0.271860  0.567020
6  0.276232 -0.673690
7  0.113648  0.524988
8  0.404705 -1.715002
9 -1.039268 -1.157892

In [3]: df.loc[:, ["a", "c"]]
Out[3]: 
          a         c
0  0.469112 -1.509059
1 -1.135632 -0.173215
2  0.119209 -0.861849
3 -2.104569  1.071804
4  0.721555 -1.039575
5  0.271860  0.567020
6  0.276232 -0.673690
7  0.113648  0.524988
8  0.404705 -1.715002
9 -1.039268 -1.157892

---->   pandas.DataFrame

--------------------------------------
ID: 3920 --> 1
In [4]: named = list("abcdefg")

In [5]: n = 30

In [6]: columns = named + np.arange(len(named), n).tolist()

In [7]: df = pd.DataFrame(np.random.randn(n, n), columns=columns)

In [8]: df.iloc[:, np.r_[:10, 24:30]]
Out[8]: 
           a         b         c  ...        27        28        29
0  -1.344312  0.844885  1.075770  ...  0.813850  0.132003 -0.827317
1  -0.076467 -1.187678  1.130127  ...  0.149748 -0.732339  0.687738
2   0.176444  0.403310 -0.154951  ... -0.493662  0.600178  0.274230
3   0.132885 -0.023688  2.410179  ...  0.109121  1.126203 -0.977349
4   1.474071 -0.064034 -1.282782  ... -0.858447  0.306996 -0.028665
..       ...       ...       ...  ...       ...       ...       ...
25  1.492125 -0.068190  0.681456  ...  0.428572  0.880609  0.487645
26  0.725238  0.624607 -0.141185  ...  1.008500  1.424017  0.717110
27  1.262419  1.950057  0.301038  ...  1.007824  2.826008  1.458383
28 -1.585746 -0.899734  0.921494  ...  0.577223 -1.088417  0.326687
29 -0.986248  0.169729 -1.158091  ... -2.013086 -1.602549  0.333109

[30 rows x 16 columns]

---->   pandas.DataFrame

--------------------------------------
ID: 3922 --> 2
In [9]: df = pd.DataFrame(
   ...:     {
   ...:         "v1": [1, 3, 5, 7, 8, 3, 5, np.nan, 4, 5, 7, 9],
   ...:         "v2": [11, 33, 55, 77, 88, 33, 55, np.nan, 44, 55, 77, 99],
   ...:         "by1": ["red", "blue", 1, 2, np.nan, "big", 1, 2, "red", 1, np.nan, 12],
   ...:         "by2": [
   ...:             "wet",
   ...:             "dry",
   ...:             99,
   ...:             95,
   ...:             np.nan,
   ...:             "damp",
   ...:             95,
   ...:             99,
   ...:             "red",
   ...:             99,
   ...:             np.nan,
   ...:             np.nan,
   ...:         ],
   ...:     }
   ...: )
   ...: 

In [10]: g = df.groupby(["by1", "by2"])

In [11]: g[["v1", "v2"]].mean()
Out[11]: 
            v1    v2
by1  by2            
1    95    5.0  55.0
     99    5.0  55.0
2    95    7.0  77.0
     99    NaN   NaN
big  damp  3.0  33.0
blue dry   3.0  33.0
red  red   4.0  44.0
     wet   1.0  11.0

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 3924 --> 2
In [12]: s = pd.Series(np.arange(5), dtype=np.float32)

In [13]: s.isin([2, 4])
Out[13]: 
0    False
1    False
2     True
3    False
4     True
dtype: bool

---->   pandas.Series; Series.isin

--------------------------------------
ID: 3927 --> 1
In [14]: import random

In [15]: import string

In [16]: baseball = pd.DataFrame(
   ....:     {
   ....:         "team": ["team %d" % (x + 1) for x in range(5)] * 5,
   ....:         "player": random.sample(list(string.ascii_lowercase), 25),
   ....:         "batting avg": np.random.uniform(0.200, 0.400, 25),
   ....:     }
   ....: )
   ....: 

In [17]: baseball.pivot_table(values="batting avg", columns="team", aggfunc=np.max)
Out[17]: 
team           team 1    team 2    team 3    team 4    team 5
batting avg  0.352134  0.295327  0.397191  0.394457  0.396194

---->   pandas.DataFrame

--------------------------------------
ID: 3929 --> 1
In [18]: df = pd.DataFrame({"a": np.random.randn(10), "b": np.random.randn(10)})

In [19]: df.query("a <= b")
Out[19]: 
          a         b
1  0.174950  0.552887
2 -0.023167  0.148084
3 -0.495291 -0.300218
4 -0.860736  0.197378
5 -1.134146  1.720780
7 -0.290098  0.083515
8  0.238636  0.946550

In [20]: df[df["a"] <= df["b"]]
Out[20]: 
          a         b
1  0.174950  0.552887
2 -0.023167  0.148084
3 -0.495291 -0.300218
4 -0.860736  0.197378
5 -1.134146  1.720780
7 -0.290098  0.083515
8  0.238636  0.946550

In [21]: df.loc[df["a"] <= df["b"]]
Out[21]: 
          a         b
1  0.174950  0.552887
2 -0.023167  0.148084
3 -0.495291 -0.300218
4 -0.860736  0.197378
5 -1.134146  1.720780
7 -0.290098  0.083515
8  0.238636  0.946550

---->   pandas.DataFrame

--------------------------------------
ID: 3931 --> 1
In [22]: df = pd.DataFrame({"a": np.random.randn(10), "b": np.random.randn(10)})

In [23]: df.eval("a + b")
Out[23]: 
0   -0.091430
1   -2.483890
2   -0.252728
3   -0.626444
4   -0.261740
5    2.149503
6   -0.332214
7    0.799331
8   -2.377245
9    2.104677
dtype: float64

In [24]: df["a"] + df["b"]  # same as the previous expression
Out[24]: 
0   -0.091430
1   -2.483890
2   -0.252728
3   -0.626444
4   -0.261740
5    2.149503
6   -0.332214
7    0.799331
8   -2.377245
9    2.104677
dtype: float64

---->   pandas.DataFrame

--------------------------------------
ID: 3933 --> 2
In [25]: df = pd.DataFrame(
   ....:     {
   ....:         "x": np.random.uniform(1.0, 168.0, 120),
   ....:         "y": np.random.uniform(7.0, 334.0, 120),
   ....:         "z": np.random.uniform(1.7, 20.7, 120),
   ....:         "month": [5, 6, 7, 8] * 30,
   ....:         "week": np.random.randint(1, 4, 120),
   ....:     }
   ....: )
   ....: 

In [26]: grouped = df.groupby(["month", "week"])

In [27]: grouped["x"].agg([np.mean, np.std])
Out[27]: 
                  mean        std
month week                       
5     1      63.653367  40.601965
      2      78.126605  53.342400
      3      92.091886  57.630110
6     1      81.747070  54.339218
      2      70.971205  54.687287
      3     100.968344  54.010081
7     1      61.576332  38.844274
      2      61.733510  48.209013
      3      71.688795  37.595638
8     1      62.741922  34.618153
      2      91.774627  49.790202
      3      73.936856  60.773900

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 3935 --> 1
In [28]: a = np.array(list(range(1, 24)) + [np.NAN]).reshape(2, 3, 4)

In [29]: pd.DataFrame([tuple(list(x) + [val]) for x, val in np.ndenumerate(a)])
Out[29]: 
    0  1  2     3
0   0  0  0   1.0
1   0  0  1   2.0
2   0  0  2   3.0
3   0  0  3   4.0
4   0  1  0   5.0
.. .. .. ..   ...
19  1  1  3  20.0
20  1  2  0  21.0
21  1  2  1  22.0
22  1  2  2  23.0
23  1  2  3   NaN

[24 rows x 4 columns]

---->   pandas.DataFrame

--------------------------------------
ID: 3937 --> 1
In [30]: a = list(enumerate(list(range(1, 5)) + [np.NAN]))

In [31]: pd.DataFrame(a)
Out[31]: 
   0    1
0  0  1.0
1  1  2.0
2  2  3.0
3  3  4.0
4  4  NaN

---->   pandas.DataFrame

--------------------------------------
ID: 3939 --> 2
In [32]: cheese = pd.DataFrame(
   ....:     {
   ....:         "first": ["John", "Mary"],
   ....:         "last": ["Doe", "Bo"],
   ....:         "height": [5.5, 6.0],
   ....:         "weight": [130, 150],
   ....:     }
   ....: )
   ....: 

In [33]: pd.melt(cheese, id_vars=["first", "last"])
Out[33]: 
  first last variable  value
0  John  Doe   height    5.5
1  Mary   Bo   height    6.0
2  John  Doe   weight  130.0
3  Mary   Bo   weight  150.0

In [34]: cheese.set_index(["first", "last"]).stack()  # alternative way
Out[34]: 
first  last        
John   Doe   height      5.5
             weight    130.0
Mary   Bo    height      6.0
             weight    150.0
dtype: float64

---->   pandas.DataFrame; pandas.melt

--------------------------------------
ID: 3941 --> 3
In [35]: df = pd.DataFrame(
   ....:     {
   ....:         "x": np.random.uniform(1.0, 168.0, 12),
   ....:         "y": np.random.uniform(7.0, 334.0, 12),
   ....:         "z": np.random.uniform(1.7, 20.7, 12),
   ....:         "month": [5, 6, 7] * 4,
   ....:         "week": [1, 2] * 6,
   ....:     }
   ....: )
   ....: 

In [36]: mdf = pd.melt(df, id_vars=["month", "week"])

In [37]: pd.pivot_table(
   ....:     mdf,
   ....:     values="value",
   ....:     index=["variable", "week"],
   ....:     columns=["month"],
   ....:     aggfunc=np.mean,
   ....: )
   ....: 
Out[37]: 
month                  5           6           7
variable week                                   
x        1     93.888747   98.762034   55.219673
         2     94.391427   38.112932   83.942781
y        1     94.306912  279.454811  227.840449
         2     87.392662  193.028166  173.899260
z        1     11.016009   10.079307   16.170549
         2      8.476111   17.638509   19.003494

---->   pandas.DataFrame; pandas.melt; pandas.pivot_table

--------------------------------------
ID: 3943 --> 2
In [38]: df = pd.DataFrame(
   ....:     {
   ....:         "Animal": [
   ....:             "Animal1",
   ....:             "Animal2",
   ....:             "Animal3",
   ....:             "Animal2",
   ....:             "Animal1",
   ....:             "Animal2",
   ....:             "Animal3",
   ....:         ],
   ....:         "FeedType": ["A", "B", "A", "A", "B", "B", "A"],
   ....:         "Amount": [10, 7, 4, 2, 5, 6, 2],
   ....:     }
   ....: )
   ....: 

In [39]: df.pivot_table(values="Amount", index="Animal", columns="FeedType", aggfunc="sum")
Out[39]: 
FeedType     A     B
Animal              
Animal1   10.0   5.0
Animal2    2.0  13.0
Animal3    6.0   NaN

---->   pandas.DataFrame; DataFrame.pivot_table

--------------------------------------
ID: 3944 --> 1
In [40]: df.groupby(["Animal", "FeedType"])["Amount"].sum()
Out[40]: 
Animal   FeedType
Animal1  A           10
         B            5
Animal2  A            2
         B           13
Animal3  A            6
Name: Amount, dtype: int64

---->   DataFrame.groupby

--------------------------------------
ID: 3946 --> 2
In [41]: pd.cut(pd.Series([1, 2, 3, 4, 5, 6]), 3)
Out[41]: 
0    (0.995, 2.667]
1    (0.995, 2.667]
2    (2.667, 4.333]
3    (2.667, 4.333]
4      (4.333, 6.0]
5      (4.333, 6.0]
dtype: category
Categories (3, interval[float64, right]): [(0.995, 2.667] < (2.667, 4.333] < (4.333, 6.0]]

In [42]: pd.Series([1, 2, 3, 2, 2, 3]).astype("category")
Out[42]: 
0    1
1    2
2    3
3    2
4    2
5    3
dtype: category
Categories (3, int64): [1, 2, 3]

---->   pandas.cut; pandas.Series

--------------------------------------
ID: 3953 --> 1
import pandas as pd
import pandas._testing as tm

def test_getitem_listlike_of_ints():
    ser = pd.Series(range(5))

    result = ser[[3, 4]]
    expected = pd.Series([2, 3])
    tm.assert_series_equal(result, expected)

    result = ser.loc[[3, 4]]
    tm.assert_series_equal(result, expected)

---->   pandas.Series

--------------------------------------
ID: 3965 --> 2
import pytest
import numpy as np
import pandas as pd


@pytest.mark.parametrize('dtype', ['int8', 'int16', 'int32', 'int64'])
def test_dtypes(dtype):
    assert str(np.dtype(dtype)) == dtype


@pytest.mark.parametrize(
    'dtype', ['float32', pytest.param('int16', marks=pytest.mark.skip),
              pytest.param('int32', marks=pytest.mark.xfail(
                  reason='to show how it works'))])
def test_mark(dtype):
    assert str(np.dtype(dtype)) == 'float32'


@pytest.fixture
def series():
    return pd.Series([1, 2, 3])


@pytest.fixture(params=['int8', 'int16', 'int32', 'int64'])
def dtype(request):
    return request.param


def test_series(series, dtype):
    # GH 
    result = series.astype(dtype)
    assert result.dtype == dtype

    expected = pd.Series([1, 2, 3], dtype=dtype)
    tm.assert_series_equal(result, expected)

---->   pandas.Series; Series.astype

--------------------------------------
ID: 3969 --> 1
pd.test()

---->   pandas.test

--------------------------------------
ID: 3973 --> 1
In [3]: df = pd.DataFrame({"x": [1, 3, 5], "y": [2, 4, 6]})

In [4]: df
Out[4]: 
   x  y
0  1  2
1  3  4
2  5  6

---->   pandas.DataFrame

--------------------------------------
ID: 3990 --> 1
In [36]: firstlast = pd.DataFrame({"String": ["John Smith", "Jane Cook"]})

In [37]: firstlast["First_Name"] = firstlast["String"].str.split(" ", expand=True)[0]

In [38]: firstlast["Last_Name"] = firstlast["String"].str.rsplit(" ", expand=True)[1]

In [39]: firstlast
Out[39]: 
       String First_Name Last_Name
0  John Smith       John     Smith
1   Jane Cook       Jane      Cook

---->   pandas.DataFrame

--------------------------------------
ID: 3991 --> 1
In [40]: firstlast = pd.DataFrame({"string": ["John Smith", "Jane Cook"]})

In [41]: firstlast["upper"] = firstlast["string"].str.upper()

In [42]: firstlast["lower"] = firstlast["string"].str.lower()

In [43]: firstlast["title"] = firstlast["string"].str.title()

In [44]: firstlast
Out[44]: 
       string       upper       lower       title
0  John Smith  JOHN SMITH  john smith  John Smith
1   Jane Cook   JANE COOK   jane cook   Jane Cook

---->   pandas.DataFrame

--------------------------------------
ID: 3992 --> 1
In [45]: df1 = pd.DataFrame({"key": ["A", "B", "C", "D"], "value": np.random.randn(4)})

In [46]: df1
Out[46]: 
  key     value
0   A  0.469112
1   B -0.282863
2   C -1.509059
3   D -1.135632

In [47]: df2 = pd.DataFrame({"key": ["B", "D", "D", "E"], "value": np.random.randn(4)})

In [48]: df2
Out[48]: 
  key     value
0   B  1.212112
1   D -0.173215
2   D  0.119209
3   E -1.044236

---->   pandas.DataFrame

--------------------------------------
ID: 3994 --> 1
In [57]: df = pd.DataFrame({"AAA": [1] * 8, "BBB": list(range(0, 8))})

In [58]: df
Out[58]: 
   AAA  BBB
0    1    0
1    1    1
2    1    2
3    1    3
4    1    4
5    1    5
6    1    6
7    1    7

In [59]: series = list(range(1, 5))

In [60]: series
Out[60]: [1, 2, 3, 4]

In [61]: df.loc[2:5, "AAA"] = series

In [62]: df
Out[62]: 
   AAA  BBB
0    1    0
1    1    1
2    1    2
3    2    3
4    3    4
5    4    5
6    1    6
7    1    7

---->   pandas.DataFrame

--------------------------------------
ID: 3995 --> 1
In [63]: df = pd.DataFrame(
   ....:     {
   ....:         "class": ["A", "A", "A", "B", "C", "D"],
   ....:         "student_count": [42, 35, 42, 50, 47, 45],
   ....:         "all_pass": ["Yes", "Yes", "Yes", "No", "No", "Yes"],
   ....:     }
   ....: )
   ....: 

In [64]: df.drop_duplicates()
Out[64]: 
  class  student_count all_pass
0     A             42      Yes
1     A             35      Yes
3     B             50       No
4     C             47       No
5     D             45      Yes

In [65]: df.drop_duplicates(["class", "student_count"])
Out[65]: 
  class  student_count all_pass
0     A             42      Yes
1     A             35      Yes
3     B             50       No
4     C             47       No
5     D             45      Yes

---->   pandas.DataFrame

--------------------------------------
ID: 3996 --> 1
In [66]: pd.pivot_table(
   ....:     tips, values="tip", index=["size"], columns=["sex"], aggfunc=np.average
   ....: )
   ....: 
Out[66]: 
sex     Female      Male
size                    
1     1.276667  1.920000
2     2.528448  2.614184
3     3.250000  3.476667
4     4.021111  4.172143
5     5.140000  3.750000
6     4.600000  5.850000

---->   pandas.pivot_table

--------------------------------------
ID: 3997 --> 1
In [67]: df
Out[67]: 
  class  student_count all_pass
0     A             42      Yes
1     A             35      Yes
2     A             42      Yes
3     B             50       No
4     C             47       No
5     D             45      Yes

In [68]: new_row = pd.DataFrame([["E", 51, True]],
   ....:                        columns=["class", "student_count", "all_pass"])
   ....: 

In [69]: pd.concat([df, new_row])
Out[69]: 
  class  student_count all_pass
0     A             42      Yes
1     A             35      Yes
2     A             42      Yes
3     B             50       No
4     C             47       No
5     D             45      Yes
0     E             51     True

---->   pandas.DataFrame

--------------------------------------
ID: 4001 --> 1
import pandas as pd
assert pd.Series([1, 1]).sum() == 2

---->   pandas.Series

--------------------------------------
ID: 4003 --> 1
>>> import pandas as pd
>>> pd.show_versions()

---->   pandas.show_versions

--------------------------------------
ID: 4013 --> 1
In [15]: frame = pd.DataFrame(
   ....:     {"col1": ["A", "B", np.NaN, "C", "D"], "col2": ["F", np.NaN, "G", "H", "I"]}
   ....: )
   ....: 

In [16]: frame
Out[16]: 
  col1 col2
0    A    F
1    B  NaN
2  NaN    G
3    C    H
4    D    I

---->   pandas.DataFrame

--------------------------------------
ID: 4024 --> 1
In [24]: df1 = pd.DataFrame({"key": ["A", "B", "C", "D"], "value": np.random.randn(4)})

In [25]: df2 = pd.DataFrame({"key": ["B", "D", "D", "E"], "value": np.random.randn(4)})

---->   pandas.DataFrame

--------------------------------------
ID: 4030 --> 1
In [32]: df1 = pd.DataFrame(
   ....:     {"city": ["Chicago", "San Francisco", "New York City"], "rank": range(1, 4)}
   ....: )
   ....: 

In [33]: df2 = pd.DataFrame(
   ....:     {"city": ["Chicago", "Boston", "Los Angeles"], "rank": [1, 4, 5]}
   ....: )
   ....: 

---->   pandas.DataFrame

--------------------------------------
ID: 4040 --> 1
import pandas as pd

pd.DataFrame([[1, 2]]).to_json()

---->   pandas.DataFrame

--------------------------------------
ID: 4044 --> 1
import pandas as pd

pd.DataFrame([[1, 2]]).to_json()

---->   pandas.DataFrame

--------------------------------------
ID: 4048 --> 1
index = pd.RangeIndex(0, 10, 2)
{
    "kind": "range",
    "name": index.name,
    "start": index.start,
    "stop": index.stop,
    "step": index.step,
}

---->   pandas.RangeIndex

--------------------------------------
ID: 4049 --> 1
index = pd.RangeIndex(0, 10, 2)
{
    "kind": "range",
    "name": index.name,
    "start": index.start,
    "stop": index.stop,
    "step": index.step,
}

---->   pandas.RangeIndex

--------------------------------------
ID: 4050 --> 1
import pandas as pd
assert pd.Series([1, 1]).sum() == 2

---->   pandas.Series

--------------------------------------
ID: 4051 --> 1
In [1]: index = pd.MultiIndex.from_product(
   ...:     [range(3), ["one", "two"]], names=["first", "second"]
   ...: )
   ...: 

In [2]: index
Out[2]: 
MultiIndex([(0, 'one'),
            (0, 'two'),
            (1, 'one'),
            (1, 'two'),
            (2, 'one'),
            (2, 'two')],
           names=['first', 'second'])

In [3]: index.levels
Out[3]: FrozenList([[0, 1, 2], ['one', 'two']])

In [4]: index.codes
Out[4]: FrozenList([[0, 0, 1, 1, 2, 2], [0, 1, 0, 1, 0, 1]])

In [5]: index.names
Out[5]: FrozenList(['first', 'second'])

---->   pandas.MultiIndex

--------------------------------------
ID: 4053 --> 1
>>> ds = pd.DataFrame(
...     {"longitude": np.linspace(0, 10), "latitude": np.linspace(0, 20)}
... )
>>> ds.geo.center
(5.0, 10.0)
>>> ds.geo.plot()
# plots data on a map

---->   pandas.DataFrame

--------------------------------------
ID: 4059 --> 1
>>> s = SubclassedSeries([1, 2, 3])
>>> type(s)


>>> to_framed = s.to_frame()
>>> type(to_framed)


>>> df = SubclassedDataFrame({"A": [1, 2, 3], "B": [4, 5, 6], "C": [7, 8, 9]})
>>> df
   A  B  C
0  1  4  7
1  2  5  8
2  3  6  9

>>> type(df)


>>> sliced1 = df[["A", "B"]]
>>> sliced1
   A  B
0  1  4
1  2  5
2  3  6

>>> type(sliced1)


>>> sliced2 = df["A"]
>>> sliced2
0    1
1    2
2    3
Name: A, dtype: int64

>>> type(sliced2)


---->   Series.to_frame

--------------------------------------
ID: 4062 --> 1
>>> pd.set_option("plotting.backend", "backend.module")
>>> pd.Series([1, 2, 3]).plot()

---->   pandas.Series

--------------------------------------
ID: 4063 --> 1
>>> import backend.module
>>> backend.module.plot(pd.Series([1, 2, 3]))

---->   pandas.Series

--------------------------------------
ID: 4066 --> 1
>>> ds = pd.DataFrame(
...     {"longitude": np.linspace(0, 10), "latitude": np.linspace(0, 20)}
... )
>>> ds.geo.center
(5.0, 10.0)
>>> ds.geo.plot()
# plots data on a map

---->   pandas.DataFrame

--------------------------------------
ID: 4072 --> 1
>>> s = SubclassedSeries([1, 2, 3])
>>> type(s)


>>> to_framed = s.to_frame()
>>> type(to_framed)


>>> df = SubclassedDataFrame({"A": [1, 2, 3], "B": [4, 5, 6], "C": [7, 8, 9]})
>>> df
   A  B  C
0  1  4  7
1  2  5  8
2  3  6  9

>>> type(df)


>>> sliced1 = df[["A", "B"]]
>>> sliced1
   A  B
0  1  4
1  2  5
2  3  6

>>> type(sliced1)


>>> sliced2 = df["A"]
>>> sliced2
0    1
1    2
2    3
Name: A, dtype: int64

>>> type(sliced2)


---->   Series.to_frame

--------------------------------------
ID: 4075 --> 1
>>> pd.set_option("plotting.backend", "backend.module")
>>> pd.Series([1, 2, 3]).plot()

---->   pandas.Series

--------------------------------------
ID: 4076 --> 1
>>> import backend.module
>>> backend.module.plot(pd.Series([1, 2, 3]))

---->   pandas.Series

--------------------------------------
ID: 4078 --> 1
>>> s = pd.Series(np.random.uniform(size=100))
>>> pd.plotting.bootstrap_plot(s)


---->   pandas.Series

--------------------------------------
ID: 4080 --> 1
>>> df = pd.DataFrame(
...     {
...         'SepalLength': [6.5, 7.7, 5.1, 5.8, 7.6, 5.0, 5.4, 4.6, 6.7, 4.6],
...         'SepalWidth': [3.0, 3.8, 3.8, 2.7, 3.0, 2.3, 3.0, 3.2, 3.3, 3.6],
...         'PetalLength': [5.5, 6.7, 1.9, 5.1, 6.6, 3.3, 4.5, 1.4, 5.7, 1.0],
...         'PetalWidth': [1.8, 2.2, 0.4, 1.9, 2.1, 1.0, 1.5, 0.2, 2.1, 0.2],
...         'Category': [
...             'virginica',
...             'virginica',
...             'setosa',
...             'virginica',
...             'virginica',
...             'versicolor',
...             'versicolor',
...             'setosa',
...             'virginica',
...             'setosa'
...         ]
...     }
... )
>>> pd.plotting.radviz(df, 'Category')


---->   pandas.DataFrame

--------------------------------------
ID: 4081 --> 2
>>> np.random.seed(5)
>>> x = np.cumsum(np.random.normal(loc=1, scale=5, size=50))
>>> s = pd.Series(x)
>>> s.plot()


---->   pandas.Series; Series.plot

--------------------------------------
ID: 4090 --> 1
>>> df = pd.DataFrame(np.random.randn(1000, 4), columns=['A','B','C','D'])
>>> pd.plotting.scatter_matrix(df, alpha=0.2)
array([[,
    ,
    ,
    ],
   [,
    ,
    ,
    ],
   [,
    ,
    ,
    ],
   [,
    ,
    ,
    ]], dtype=object)

---->   pandas.DataFrame

--------------------------------------
ID: 4092 --> 1
>>> mask = pd.array([True, False])
>>> arr = pd.array([1, 2])
>>> pd.api.indexers.check_array_indexer(arr, mask)
array([ True, False])

---->   pandas.array

--------------------------------------
ID: 4093 --> 1
>>> mask = pd.array([True, False, True])
>>> pd.api.indexers.check_array_indexer(arr, mask)
Traceback (most recent call last):
...
IndexError: Boolean index has wrong length: 3 instead of 2.

---->   pandas.array

--------------------------------------
ID: 4094 --> 1
>>> mask = pd.array([True, pd.NA])
>>> pd.api.indexers.check_array_indexer(arr, mask)
array([ True, False])

---->   pandas.array

--------------------------------------
ID: 4096 --> 1
>>> indexer = pd.array([0, 2], dtype="Int64")
>>> arr = pd.array([1, 2, 3])
>>> pd.api.indexers.check_array_indexer(arr, indexer)
array([0, 2])

---->   pandas.array

--------------------------------------
ID: 4097 --> 1
>>> indexer = pd.array([0, pd.NA], dtype="Int64")
>>> pd.api.indexers.check_array_indexer(arr, indexer)
Traceback (most recent call last):
...
ValueError: Cannot index with an integer indexer containing NA values

---->   pandas.array

--------------------------------------
ID: 4100 --> 1
>>> pd.Series(['a', 'b']).dt
Traceback (most recent call last):
...
AttributeError: Can only use .dt accessor with datetimelike values

---->   pandas.Series

--------------------------------------
ID: 4102 --> 1
In [1]: ds = pd.DataFrame({"longitude": np.linspace(0, 10),
   ...:                    "latitude": np.linspace(0, 20)})
In [2]: ds.geo.center
Out[2]: (5.0, 10.0)
In [3]: ds.geo.plot()  # plots data on a map

---->   pandas.DataFrame

--------------------------------------
ID: 4104 --> 2
>>> np.random.seed(1234)
>>> df = pd.DataFrame(np.random.randn(10, 4),
...                   columns=['Col1', 'Col2', 'Col3', 'Col4'])
>>> boxplot = df.boxplot(column=['Col1', 'Col2', 'Col3'])  

---->   pandas.DataFrame; DataFrame.boxplot

--------------------------------------
ID: 4105 --> 3
>>> df = pd.DataFrame(np.random.randn(10, 2),
...                   columns=['Col1', 'Col2'])
>>> df['X'] = pd.Series(['A', 'A', 'A', 'A', 'A',
...                      'B', 'B', 'B', 'B', 'B'])
>>> boxplot = df.boxplot(by='X')

---->   pandas.DataFrame; pandas.Series; DataFrame.boxplot

--------------------------------------
ID: 4106 --> 3
>>> df = pd.DataFrame(np.random.randn(10, 3),
...                   columns=['Col1', 'Col2', 'Col3'])
>>> df['X'] = pd.Series(['A', 'A', 'A', 'A', 'A',
...                      'B', 'B', 'B', 'B', 'B'])
>>> df['Y'] = pd.Series(['A', 'B', 'A', 'B', 'A',
...                      'B', 'A', 'B', 'A', 'B'])
>>> boxplot = df.boxplot(column=['Col1', 'Col2'], by=['X', 'Y'])

---->   pandas.DataFrame; pandas.Series; DataFrame.boxplot

--------------------------------------
ID: 4107 --> 1
>>> boxplot = df.boxplot(column=['Col1', 'Col2'], by='X',
...                      layout=(2, 1))

---->   DataFrame.boxplot

--------------------------------------
ID: 4108 --> 1
>>> boxplot = df.boxplot(grid=False, rot=45, fontsize=15)  

---->   DataFrame.boxplot

--------------------------------------
ID: 4109 --> 1
>>> boxplot = df.boxplot(column=['Col1', 'Col2'], return_type='axes')
>>> type(boxplot)


---->   DataFrame.boxplot

--------------------------------------
ID: 4110 --> 1
>>> boxplot = df.boxplot(column=['Col1', 'Col2'], by='X',
...                      return_type='axes')
>>> type(boxplot)


---->   DataFrame.boxplot

--------------------------------------
ID: 4111 --> 1
>>> boxplot = df.boxplot(column=['Col1', 'Col2'], by='X',
...                      return_type=None)
>>> type(boxplot)


---->   DataFrame.boxplot

--------------------------------------
ID: 4113 --> 1
>>> pd.Series(['a', 'b']).dt
Traceback (most recent call last):
...
AttributeError: Can only use .dt accessor with datetimelike values

---->   pandas.Series

--------------------------------------
ID: 4115 --> 1
In [1]: ds = pd.DataFrame({"longitude": np.linspace(0, 10),
   ...:                    "latitude": np.linspace(0, 20)})
In [2]: ds.geo.center
Out[2]: (5.0, 10.0)
In [3]: ds.geo.plot()  # plots data on a map

---->   pandas.DataFrame

--------------------------------------
ID: 4117 --> 1
>>> pd.Series(['a', 'b']).dt
Traceback (most recent call last):
...
AttributeError: Can only use .dt accessor with datetimelike values

---->   pandas.Series

--------------------------------------
ID: 4119 --> 1
In [1]: ds = pd.DataFrame({"longitude": np.linspace(0, 10),
   ...:                    "latitude": np.linspace(0, 20)})
In [2]: ds.geo.center
Out[2]: (5.0, 10.0)
In [3]: ds.geo.plot()  # plots data on a map

---->   pandas.DataFrame

--------------------------------------
ID: 4120 --> 1
>>> spacing = np.linspace(-9 * np.pi, 9 * np.pi, num=1000)
>>> s = pd.Series(0.7 * np.random.rand(1000) + 0.3 * np.sin(spacing))
>>> pd.plotting.autocorrelation_plot(s)


---->   pandas.Series

--------------------------------------
ID: 4121 --> 1
import pandas as pd
import numpy as np
import matplotlib as mpl

df = pd.DataFrame({
    "strings": ["Adam", "Mike"],
    "ints": [1, 3],
    "floats": [1.123, 1000.23]
})
df.style \
  .format(precision=3, thousands=".", decimal=",") \
  .format_index(str.upper, axis=1) \
  .relabel_index(["row 1", "row 2"], axis=0)

---->   pandas.DataFrame

--------------------------------------
ID: 4122 --> 1
weather_df = pd.DataFrame(np.random.rand(10,2)*5,
                          index=pd.date_range(start="2021-01-01", periods=10),
                          columns=["Tokyo", "Beijing"])

def rain_condition(v):
    if v < 1.75:
        return "Dry"
    elif v < 2.75:
        return "Rain"
    return "Heavy Rain"

def make_pretty(styler):
    styler.set_caption("Weather Conditions")
    styler.format(rain_condition)
    styler.format_index(lambda v: v.strftime("%A"))
    styler.background_gradient(axis=None, vmin=1, vmax=5, cmap="YlGnBu")
    return styler

weather_df

---->   pandas.DataFrame

--------------------------------------
ID: 4124 --> 1
df = pd.DataFrame(np.random.randn(5, 5))
df.style \
  .hide(subset=[0, 2, 4], axis=0) \
  .hide(subset=[0, 2, 4], axis=1)

---->   pandas.DataFrame

--------------------------------------
ID: 4126 --> 1
summary_styler = df.agg(["sum", "mean"]).style \
                   .format(precision=3) \
                   .relabel_index(["Sum", "Average"])
df.style.format(precision=1).concat(summary_styler)

---->   DataFrame.agg

--------------------------------------
ID: 4127 --> 3
df = pd.DataFrame([[38.0, 2.0, 18.0, 22.0, 21, np.nan],[19, 439, 6, 452, 226,232]],
                  index=pd.Index(['Tumour (Positive)', 'Non-Tumour (Negative)'], name='Actual Label:'),
                  columns=pd.MultiIndex.from_product([['Decision Tree', 'Regression', 'Random'],['Tumour', 'Non-Tumour']], names=['Model:', 'Predicted:']))
df.style

---->   pandas.DataFrame; pandas.Index; pandas.MultiIndex

--------------------------------------
ID: 4133 --> 1
s.set_table_styles([  # create internal CSS classes
    {'selector': '.true', 'props': 'background-color: #e6ffe6;'},
    {'selector': '.false', 'props': 'background-color: #ffe6e6;'},
], overwrite=False)
cell_color = pd.DataFrame([['true ', 'false ', 'true ', 'false '],
                           ['false ', 'true ', 'false ', 'true ']],
                          index=df.index,
                          columns=df.columns[:4])
s.set_td_classes(cell_color)

---->   pandas.DataFrame

--------------------------------------
ID: 4134 --> 1
np.random.seed(0)
df2 = pd.DataFrame(np.random.randn(10,4), columns=['A','B','C','D'])
df2.style

---->   pandas.DataFrame

--------------------------------------
ID: 4138 --> 1
s2.applymap_index(lambda v: "color:pink;" if v>4 else "color:darkblue;", axis=0)
s2.apply_index(lambda s: np.where(s.isin(["A", "B"]), "color:pink;", "color:darkblue;"), axis=1)

---->   Series.isin

--------------------------------------
ID: 4140 --> 1
tt = pd.DataFrame([['This model has a very strong true positive rate',
                    "This model's total number of false negatives is too high"]],
                  index=['Tumour (Positive)'], columns=df.columns[[0,3]])
s.set_tooltips(tt, props='visibility: hidden; position: absolute; z-index: 1; border: 1px solid #000066;'
                         'background-color: white; color: #000066; font-size: 0.8em;'
                         'transform: translate(0px, -24px); padding: 0.6em; border-radius: 0.5em;')

---->   pandas.DataFrame

--------------------------------------
ID: 4141 --> 1
s.set_table_styles([  # create internal CSS classes
    {'selector': '.border-red', 'props': 'border: 2px dashed red;'},
    {'selector': '.border-green', 'props': 'border: 2px dashed green;'},
], overwrite=False)
cell_border = pd.DataFrame([['border-green ', ' ', ' ', 'border-red '],
                           [' ', ' ', ' ', ' ']],
                          index=df.index,
                          columns=df.columns[:4])
s.set_td_classes(cell_color + cell_border)

---->   pandas.DataFrame

--------------------------------------
ID: 4142 --> 2
df3 = pd.DataFrame(np.random.randn(4,4),
                   pd.MultiIndex.from_product([['A', 'B'], ['r1', 'r2']]),
                   columns=['c1','c2','c3','c4'])
df3

---->   pandas.DataFrame; pandas.MultiIndex

--------------------------------------
ID: 4148 --> 1
df4 = pd.DataFrame([[1,2],[3,4]])
s4 = df4.style

---->   pandas.DataFrame

--------------------------------------
ID: 4153 --> 1
build = lambda x: pd.DataFrame(x, index=df2.index, columns=df2.columns)
cls1 = build(df2.apply(highlight_max, props='cls-1 ', axis=0))
cls2 = build(df2.apply(highlight_max, props='cls-2 ', axis=1, result_type='expand').values)
cls3 = build(highlight_max(df2, props='cls-3 '))
df2.style.set_table_styles([
    {'selector': '.cls-1', 'props': 'color:white;background-color:darkblue;'},
    {'selector': '.cls-2', 'props': 'color:white;background-color:pink;'},
    {'selector': '.cls-3', 'props': 'color:white;background-color:purple;'}
]).set_td_classes(cls1 + cls2 + cls3)

---->   pandas.DataFrame

--------------------------------------
ID: 4157 --> 1
left = pd.Series([1.0, 0.0, 1.0], index=["A", "B", "D"])
df2.loc[:4].style.highlight_between(left=left, right=1.5, axis=1, props='color:white; background-color:purple;')

---->   pandas.Series

--------------------------------------
ID: 4169 --> 1
np.random.seed(25)
cmap = cmap=sns.diverging_palette(5, 250, as_cmap=True)
bigdf = pd.DataFrame(np.random.randn(20, 25)).cumsum()

bigdf.style.background_gradient(cmap, axis=1)\
    .set_properties(**{'max-width': '80px', 'font-size': '1pt'})\
    .set_caption("Hover to magnify")\
    .format(precision=2)\
    .set_table_styles(magnify())

---->   pandas.DataFrame

--------------------------------------
ID: 4170 --> 1
bigdf = pd.DataFrame(np.random.randn(16, 100))
bigdf.style.set_sticky(axis="index")

---->   pandas.DataFrame

--------------------------------------
ID: 4171 --> 1
bigdf.index = pd.MultiIndex.from_product([["A","B"],[0,1],[0,1,2,3]])
bigdf.style.set_sticky(axis="index", pixel_size=18, levels=[1,2])

---->   pandas.MultiIndex

--------------------------------------
ID: 4172 --> 1
df4 = pd.DataFrame([['', '"&other"', '']])
df4.style

---->   pandas.DataFrame

--------------------------------------
ID: 4176 --> 1
print(pd.DataFrame([[1,2],[3,4]], index=['i1', 'i2'], columns=['c1', 'c2']).style.to_html())

---->   pandas.DataFrame

--------------------------------------
ID: 4177 --> 1
df4 = pd.DataFrame([['text']])
df4.style.applymap(lambda x: 'color:green;')\
         .applymap(lambda x: 'color:red;')

---->   pandas.DataFrame

--------------------------------------
ID: 4180 --> 1
df4.style.set_uuid('b_')\
         .set_table_styles([{'selector': 'td', 'props': 'color:red;'},
                            {'selector': '.cls-1', 'props': 'color:blue;'}])\
         .applymap(lambda x: 'color:green;')\
         .set_td_classes(pd.DataFrame([['cls-1']]))

---->   pandas.DataFrame

--------------------------------------
ID: 4181 --> 1
df4.style.set_uuid('c_')\
         .set_table_styles([{'selector': 'td', 'props': 'color:red;'},
                            {'selector': '.cls-1', 'props': 'color:blue;'},
                            {'selector': 'td.data', 'props': 'color:yellow;'}])\
         .applymap(lambda x: 'color:green;')\
         .set_td_classes(pd.DataFrame([['cls-1']]))

---->   pandas.DataFrame

--------------------------------------
ID: 4182 --> 1
df4.style.set_uuid('d_')\
         .set_table_styles([{'selector': 'td', 'props': 'color:red;'},
                            {'selector': '.cls-1', 'props': 'color:blue;'},
                            {'selector': 'td.data', 'props': 'color:yellow;'}])\
         .applymap(lambda x: 'color:green !important;')\
         .set_td_classes(pd.DataFrame([['cls-1']]))

---->   pandas.DataFrame

--------------------------------------
ID: 4191 --> 1
In [1]: import pandas as pd

In [2]: import numpy as np

In [3]: def make_timeseries(start="2000-01-01", end="2000-12-31", freq="1D", seed=None):
   ...:     index = pd.date_range(start=start, end=end, freq=freq, name="timestamp")
   ...:     n = len(index)
   ...:     state = np.random.RandomState(seed)
   ...:     columns = {
   ...:         "name": state.choice(["Alice", "Bob", "Charlie"], size=n),
   ...:         "id": state.poisson(1000, size=n),
   ...:         "x": state.rand(n) * 2 - 1,
   ...:         "y": state.rand(n) * 2 - 1,
   ...:     }
   ...:     df = pd.DataFrame(columns, index=index, columns=sorted(columns))
   ...:     if df.index[-1] == end:
   ...:         df = df.iloc[:-1]
   ...:     return df
   ...: 

In [4]: timeseries = [
   ...:     make_timeseries(freq="1T", seed=i).rename(columns=lambda x: f"{x}_{i}")
   ...:     for i in range(10)
   ...: ]
   ...: 

In [5]: ts_wide = pd.concat(timeseries, axis=1)

In [6]: ts_wide.to_parquet("timeseries_wide.parquet")

---->   pandas.DataFrame

--------------------------------------
ID: 4192 --> 1
In [7]: columns = ["id_0", "name_0", "x_0", "y_0"]

In [8]: pd.read_parquet("timeseries_wide.parquet")[columns]
Out[8]: 
                     id_0 name_0       x_0       y_0
timestamp                                           
2000-01-01 00:00:00   977  Alice -0.821225  0.906222
2000-01-01 00:01:00  1018    Bob -0.219182  0.350855
2000-01-01 00:02:00   927  Alice  0.660908 -0.798511
2000-01-01 00:03:00   997    Bob -0.852458  0.735260
2000-01-01 00:04:00   965    Bob  0.717283  0.393391
...                   ...    ...       ...       ...
2000-12-30 23:56:00  1037    Bob -0.814321  0.612836
2000-12-30 23:57:00   980    Bob  0.232195 -0.618828
2000-12-30 23:58:00   965  Alice -0.231131  0.026310
2000-12-30 23:59:00   984  Alice  0.942819  0.853128
2000-12-31 00:00:00  1003  Alice  0.201125 -0.136655

[525601 rows x 4 columns]

---->   pandas.read_parquet

--------------------------------------
ID: 4193 --> 1
In [9]: pd.read_parquet("timeseries_wide.parquet", columns=columns)
Out[9]: 
                     id_0 name_0       x_0       y_0
timestamp                                           
2000-01-01 00:00:00   977  Alice -0.821225  0.906222
2000-01-01 00:01:00  1018    Bob -0.219182  0.350855
2000-01-01 00:02:00   927  Alice  0.660908 -0.798511
2000-01-01 00:03:00   997    Bob -0.852458  0.735260
2000-01-01 00:04:00   965    Bob  0.717283  0.393391
...                   ...    ...       ...       ...
2000-12-30 23:56:00  1037    Bob -0.814321  0.612836
2000-12-30 23:57:00   980    Bob  0.232195 -0.618828
2000-12-30 23:58:00   965  Alice -0.231131  0.026310
2000-12-30 23:59:00   984  Alice  0.942819  0.853128
2000-12-31 00:00:00  1003  Alice  0.201125 -0.136655

[525601 rows x 4 columns]

---->   pandas.read_parquet

--------------------------------------
ID: 4194 --> 1
In [10]: ts = make_timeseries(freq="30S", seed=0)

In [11]: ts.to_parquet("timeseries.parquet")

In [12]: ts = pd.read_parquet("timeseries.parquet")

In [13]: ts
Out[13]: 
                       id     name         x         y
timestamp                                             
2000-01-01 00:00:00  1041    Alice  0.889987  0.281011
2000-01-01 00:00:30   988      Bob -0.455299  0.488153
2000-01-01 00:01:00  1018    Alice  0.096061  0.580473
2000-01-01 00:01:30   992      Bob  0.142482  0.041665
2000-01-01 00:02:00   960      Bob -0.036235  0.802159
...                   ...      ...       ...       ...
2000-12-30 23:58:00  1022    Alice  0.266191  0.875579
2000-12-30 23:58:30   974    Alice -0.009826  0.413686
2000-12-30 23:59:00  1028  Charlie  0.307108 -0.656789
2000-12-30 23:59:30  1002    Alice  0.202602  0.541335
2000-12-31 00:00:00   987    Alice  0.200832  0.615972

[1051201 rows x 4 columns]

---->   pandas.read_parquet

--------------------------------------
ID: 4195 --> 1
In [15]: ts.memory_usage(deep=True)  # memory usage in bytes
Out[15]: 
Index     8409608
id        8409608
name     65176434
x         8409608
y         8409608
dtype: int64

---->   Series.memory_usage

--------------------------------------
ID: 4196 --> 2
In [16]: ts2 = ts.copy()

In [17]: ts2["name"] = ts2["name"].astype("category")

In [18]: ts2.memory_usage(deep=True)
Out[18]: 
Index    8409608
id       8409608
name     1051495
x        8409608
y        8409608
dtype: int64

---->   Series.copy; Series.memory_usage

--------------------------------------
ID: 4197 --> 1
In [19]: ts2["id"] = pd.to_numeric(ts2["id"], downcast="unsigned")

In [20]: ts2[["x", "y"]] = ts2[["x", "y"]].apply(pd.to_numeric, downcast="float")

In [21]: ts2.dtypes
Out[21]: 
id        uint16
name    category
x        float32
y        float32
dtype: object

---->   pandas.to_numeric

--------------------------------------
ID: 4198 --> 1
In [22]: ts2.memory_usage(deep=True)
Out[22]: 
Index    8409608
id       2102402
name     1051495
x        4204804
y        4204804
dtype: int64

---->   Series.memory_usage

--------------------------------------
ID: 4199 --> 2
In [23]: reduction = ts2.memory_usage(deep=True).sum() / ts.memory_usage(deep=True).sum()

In [24]: print(f"{reduction:0.2f}")
0.20

---->   Series.memory_usage; Series.memory_usage

--------------------------------------
ID: 4201 --> 2
In [31]: %%time
   ....: files = pathlib.Path("data/timeseries/").glob("ts*.parquet")
   ....: counts = pd.Series(dtype=int)
   ....: for path in files:
   ....:     df = pd.read_parquet(path)
   ....:     counts = counts.add(df["name"].value_counts(), fill_value=0)
   ....: counts.astype(int)
   ....: 
CPU times: user 910 ms, sys: 73 ms, total: 983 ms
Wall time: 771 ms
Out[31]: 
name
Alice      1994645
Bob        1993692
Charlie    1994875
dtype: int64

---->   pandas.Series; pandas.read_parquet

--------------------------------------
ID: 4208 --> 1
In [43]: N = 12

In [44]: starts = [f"20{i:>02d}-01-01" for i in range(N)]

In [45]: ends = [f"20{i:>02d}-12-13" for i in range(N)]

In [46]: divisions = tuple(pd.to_datetime(starts)) + (pd.Timestamp(ends[-1]),)

In [47]: ddf.divisions = divisions

In [48]: ddf
Out[48]: 
Dask DataFrame Structure:
                   id    name        x        y
npartitions=12                                 
2000-01-01      int64  object  float64  float64
2001-01-01        ...     ...      ...      ...
...               ...     ...      ...      ...
2011-01-01        ...     ...      ...      ...
2011-12-13        ...     ...      ...      ...
Dask Name: read-parquet, 1 graph layer

---->   pandas.to_datetime

--------------------------------------
ID: 4213 --> 1
In [11]: pd.describe_option()
compute.use_bottleneck : bool
    Use the bottleneck library to accelerate if it is installed,
    the default is True
    Valid values: False,True
    [default: True] [currently: True]
compute.use_numba : bool
    Use the numba engine option for select operations if it is installed,
    the default is False
    Valid values: False,True
    [default: False] [currently: False]
compute.use_numexpr : bool
    Use the numexpr library to accelerate computation if it is installed,
    the default is True
    Valid values: False,True
    [default: True] [currently: True]
display.chop_threshold : float or None
    if set to a float value, all float values smaller than the given threshold
    will be displayed as exactly 0 by repr and friends.
    [default: None] [currently: None]
display.colheader_justify : 'left'/'right'
    Controls the justification of column headers. used by DataFrameFormatter.
    [default: right] [currently: right]
display.date_dayfirst : boolean
    When True, prints and parses dates with the day first, eg 20/01/2005
    [default: False] [currently: False]
display.date_yearfirst : boolean
    When True, prints and parses dates with the year first, eg 2005/01/20
    [default: False] [currently: False]
display.encoding : str/unicode
    Defaults to the detected encoding of the console.
    Specifies the encoding to be used for strings returned by to_string,
    these are generally strings meant to be displayed on the console.
    [default: utf-8] [currently: utf8]
display.expand_frame_repr : boolean
    Whether to print out the full DataFrame repr for wide DataFrames across
    multiple lines, `max_columns` is still respected, but the output will
    wrap-around across multiple "pages" if its width exceeds `display.width`.
    [default: True] [currently: True]
display.float_format : callable
    The callable should accept a floating point number and return
    a string with the desired format of the number. This is used
    in some places like SeriesFormatter.
    See formats.format.EngFormatter for an example.
    [default: None] [currently: None]
display.html.border : int
    A ``border=value`` attribute is inserted in the ```` tag
    for the DataFrame HTML repr.
    [default: 1] [currently: 1]
display.html.table_schema : boolean
    Whether to publish a Table Schema representation for frontends
    that support it.
    (default: False)
    [default: False] [currently: False]
display.html.use_mathjax : boolean
    When True, Jupyter notebook will process table contents using MathJax,
    rendering mathematical expressions enclosed by the dollar symbol.
    (default: True)
    [default: True] [currently: True]
display.large_repr : 'truncate'/'info'
    For DataFrames exceeding max_rows/max_cols, the repr (and HTML repr) can
    show a truncated table (the default from 0.13), or switch to the view from
    df.info() (the behaviour in earlier versions of pandas).
    [default: truncate] [currently: truncate]
display.max_categories : int
    This sets the maximum number of categories pandas should output when
    printing out a `Categorical` or a Series of dtype "category".
    [default: 8] [currently: 8]
display.max_columns : int
    If max_cols is exceeded, switch to truncate view. Depending on
    `large_repr`, objects are either centrally truncated or printed as
    a summary view. 'None' value means unlimited.

    In case python/IPython is running in a terminal and `large_repr`
    equals 'truncate' this can be set to 0 or None and pandas will auto-detect
    the width of the terminal and print a truncated object which fits
    the screen width. The IPython notebook, IPython qtconsole, or IDLE
    do not run in a terminal and hence it is not possible to do
    correct auto-detection and defaults to 20.
    [default: 0] [currently: 0]
display.max_colwidth : int or None
    The maximum width in characters of a column in the repr of
    a pandas data structure. When the column overflows, a "..."
    placeholder is embedded in the output. A 'None' value means unlimited.
    [default: 50] [currently: 50]
display.max_dir_items : int
    The number of items that will be added to `dir(...)`. 'None' value means
    unlimited. Because dir is cached, changing this option will not immediately
    affect already existing dataframes until a column is deleted or added.

    This is for instance used to suggest columns from a dataframe to tab
    completion.
    [default: 100] [currently: 100]
display.max_info_columns : int
    max_info_columns is used in DataFrame.info method to decide if
    per column information will be printed.
    [default: 100] [currently: 100]
display.max_info_rows : int or None
    df.info() will usually show null-counts for each column.
    For large frames this can be quite slow. max_info_rows and max_info_cols
    limit this null check only to frames with smaller dimensions than
    specified.
    [default: 1690785] [currently: 1690785]
display.max_rows : int
    If max_rows is exceeded, switch to truncate view. Depending on
    `large_repr`, objects are either centrally truncated or printed as
    a summary view. 'None' value means unlimited.

    In case python/IPython is running in a terminal and `large_repr`
    equals 'truncate' this can be set to 0 and pandas will auto-detect
    the height of the terminal and print a truncated object which fits
    the screen height. The IPython notebook, IPython qtconsole, or
    IDLE do not run in a terminal and hence it is not possible to do
    correct auto-detection.
    [default: 60] [currently: 60]
display.max_seq_items : int or None
    When pretty-printing a long sequence, no more then `max_seq_items`
    will be printed. If items are omitted, they will be denoted by the
    addition of "..." to the resulting string.

    If set to None, the number of items to be printed is unlimited.
    [default: 100] [currently: 100]
display.memory_usage : bool, string or None
    This specifies if the memory usage of a DataFrame should be displayed when
    df.info() is called. Valid values True,False,'deep'
    [default: True] [currently: True]
display.min_rows : int
    The numbers of rows to show in a truncated view (when `max_rows` is
    exceeded). Ignored when `max_rows` is set to None or 0. When set to
    None, follows the value of `max_rows`.
    [default: 10] [currently: 10]
display.multi_sparse : boolean
    "sparsify" MultiIndex display (don't display repeated
    elements in outer levels within groups)
    [default: True] [currently: True]
display.notebook_repr_html : boolean
    When True, IPython notebook will use html representation for
    pandas objects (if it is available).
    [default: True] [currently: True]
display.pprint_nest_depth : int
    Controls the number of nested levels to process when pretty-printing
    [default: 3] [currently: 3]
display.precision : int
    Floating point output precision in terms of number of places after the
    decimal, for regular formatting as well as scientific notation. Similar
    to ``precision`` in :meth:`numpy.set_printoptions`.
    [default: 6] [currently: 6]
display.show_dimensions : boolean or 'truncate'
    Whether to print out dimensions at the end of DataFrame repr.
    If 'truncate' is specified, only print out the dimensions if the
    frame is truncated (e.g. not display all rows and/or columns)
    [default: truncate] [currently: truncate]
display.unicode.ambiguous_as_wide : boolean
    Whether to use the Unicode East Asian Width to calculate the display text
    width.
    Enabling this may affect to the performance (default: False)
    [default: False] [currently: False]
display.unicode.east_asian_width : boolean
    Whether to use the Unicode East Asian Width to calculate the display text
    width.
    Enabling this may affect to the performance (default: False)
    [default: False] [currently: False]
display.width : int
    Width of the display in characters. In case python/IPython is running in
    a terminal this can be set to None and pandas will correctly auto-detect
    the width.
    Note that the IPython notebook, IPython qtconsole, or IDLE do not run in a
    terminal and hence it is not possible to correctly detect the width.
    [default: 80] [currently: 80]
io.excel.ods.reader : string
    The default Excel reader engine for 'ods' files. Available options:
    auto, odf.
    [default: auto] [currently: auto]
io.excel.ods.writer : string
    The default Excel writer engine for 'ods' files. Available options:
    auto, odf.
    [default: auto] [currently: auto]
io.excel.xls.reader : string
    The default Excel reader engine for 'xls' files. Available options:
    auto, xlrd.
    [default: auto] [currently: auto]
io.excel.xlsb.reader : string
    The default Excel reader engine for 'xlsb' files. Available options:
    auto, pyxlsb.
    [default: auto] [currently: auto]
io.excel.xlsm.reader : string
    The default Excel reader engine for 'xlsm' files. Available options:
    auto, xlrd, openpyxl.
    [default: auto] [currently: auto]
io.excel.xlsm.writer : string
    The default Excel writer engine for 'xlsm' files. Available options:
    auto, openpyxl.
    [default: auto] [currently: auto]
io.excel.xlsx.reader : string
    The default Excel reader engine for 'xlsx' files. Available options:
    auto, xlrd, openpyxl.
    [default: auto] [currently: auto]
io.excel.xlsx.writer : string
    The default Excel writer engine for 'xlsx' files. Available options:
    auto, openpyxl, xlsxwriter.
    [default: auto] [currently: auto]
io.hdf.default_format : format
    default format writing format, if None, then
    put will default to 'fixed' and append will default to 'table'
    [default: None] [currently: None]
io.hdf.dropna_table : boolean
    drop ALL nan rows when appending to a table
    [default: False] [currently: False]
io.parquet.engine : string
    The default parquet reader/writer engine. Available options:
    'auto', 'pyarrow', 'fastparquet', the default is 'auto'
    [default: auto] [currently: auto]
io.sql.engine : string
    The default sql reader/writer engine. Available options:
    'auto', 'sqlalchemy', the default is 'auto'
    [default: auto] [currently: auto]
mode.chained_assignment : string
    Raise an exception, warn, or no action if trying to use chained assignment,
    The default is warn
    [default: warn] [currently: warn]
mode.copy_on_write : bool
    Use new copy-view behaviour using Copy-on-Write. Defaults to False,
    unless overridden by the 'PANDAS_COPY_ON_WRITE' environment variable
    (if set to "1" for True, needs to be set before pandas is imported).
    [default: False] [currently: False]
mode.data_manager : string
    Internal data manager type; can be "block" or "array". Defaults to "block",
    unless overridden by the 'PANDAS_DATA_MANAGER' environment variable (needs
    to be set before pandas is imported).
    [default: block] [currently: block]
mode.sim_interactive : boolean
    Whether to simulate interactive mode for purposes of testing
    [default: False] [currently: False]
mode.string_storage : string
    The default storage for StringDtype.
    [default: python] [currently: python]
mode.use_inf_as_na : boolean
    True means treat None, NaN, INF, -INF as NA (old way),
    False means None and NaN are null, but INF, -INF are not NA
    (new way).
    [default: False] [currently: False]
plotting.backend : str
    The plotting backend to use. The default value is "matplotlib", the
    backend provided with pandas. Other backends can be specified by
    providing the name of the module that implements the backend.
    [default: matplotlib] [currently: matplotlib]
plotting.matplotlib.register_converters : bool or 'auto'.
    Whether to register converters with matplotlib's units registry for
    dates, times, datetimes, and Periods. Toggling to False will remove
    the converters, restoring any converters that pandas overwrote.
    [default: auto] [currently: auto]
styler.format.decimal : str
    The character representation for the decimal separator for floats and complex.
    [default: .] [currently: .]
styler.format.escape : str, optional
    Whether to escape certain characters according to the given context; html or latex.
    [default: None] [currently: None]
styler.format.formatter : str, callable, dict, optional
    A formatter object to be used as default within ``Styler.format``.
    [default: None] [currently: None]
styler.format.na_rep : str, optional
    The string representation for values identified as missing.
    [default: None] [currently: None]
styler.format.precision : int
    The precision for floats and complex numbers.
    [default: 6] [currently: 6]
styler.format.thousands : str, optional
    The character representation for thousands separator for floats, int and complex.
    [default: None] [currently: None]
styler.html.mathjax : bool
    If False will render special CSS classes to table attributes that indicate Mathjax
    will not be used in Jupyter Notebook.
    [default: True] [currently: True]
styler.latex.environment : str
    The environment to replace ``\begin{table}``. If "longtable" is used results
    in a specific longtable environment format.
    [default: None] [currently: None]
styler.latex.hrules : bool
    Whether to add horizontal rules on top and bottom and below the headers.
    [default: False] [currently: False]
styler.latex.multicol_align : {"r", "c", "l", "naive-l", "naive-r"}
    The specifier for horizontal alignment of sparsified LaTeX multicolumns. Pipe
    decorators can also be added to non-naive values to draw vertical
    rules, e.g. "\|r" will draw a rule on the left side of right aligned merged cells.
    [default: r] [currently: r]
styler.latex.multirow_align : {"c", "t", "b"}
    The specifier for vertical alignment of sparsified LaTeX multirows.
    [default: c] [currently: c]
styler.render.encoding : str
    The encoding used for output HTML and LaTeX files.
    [default: utf-8] [currently: utf-8]
styler.render.max_columns : int, optional
    The maximum number of columns that will be rendered. May still be reduced to
    satsify ``max_elements``, which takes precedence.
    [default: None] [currently: None]
styler.render.max_elements : int
    The maximum number of data-cell () elements that will be rendered before
    trimming will occur over columns, rows or both if needed.
    [default: 262144] [currently: 262144]
styler.render.max_rows : int, optional
    The maximum number of rows that will be rendered. May still be reduced to
    satsify ``max_elements``, which takes precedence.
    [default: None] [currently: None]
styler.render.repr : str
    Determine which output to use in Jupyter Notebook in {"html", "latex"}.
    [default: html] [currently: html]
styler.sparse.columns : bool
    Whether to sparsify the display of hierarchical columns. Setting to False will
    display each explicit level element in a hierarchical key for each column.
    [default: True] [currently: True]
styler.sparse.index : bool
    Whether to sparsify the display of a hierarchical index. Setting to False will
    display each explicit level element in a hierarchical key for each row.
    [default: True] [currently: True]

---->   DataFrame.info

--------------------------------------
ID: 4219 --> 1
In [24]: df = pd.DataFrame(np.random.randn(7, 2))

In [25]: pd.set_option("display.max_rows", 7)

In [26]: df
Out[26]: 
          0         1
0  0.469112 -0.282863
1 -1.509059 -1.135632
2  1.212112 -0.173215
3  0.119209 -1.044236
4 -0.861849 -2.104569
5 -0.494929  1.071804
6  0.721555 -0.706771

In [27]: pd.set_option("display.max_rows", 5)

In [28]: df
Out[28]: 
           0         1
0   0.469112 -0.282863
1  -1.509059 -1.135632
..       ...       ...
5  -0.494929  1.071804
6   0.721555 -0.706771

[7 rows x 2 columns]

In [29]: pd.reset_option("display.max_rows")

---->   pandas.DataFrame

--------------------------------------
ID: 4220 --> 1
In [30]: pd.set_option("display.max_rows", 8)

In [31]: pd.set_option("display.min_rows", 4)

# below max_rows -> all rows shown
In [32]: df = pd.DataFrame(np.random.randn(7, 2))

In [33]: df
Out[33]: 
          0         1
0 -1.039575  0.271860
1 -0.424972  0.567020
2  0.276232 -1.087401
3 -0.673690  0.113648
4 -1.478427  0.524988
5  0.404705  0.577046
6 -1.715002 -1.039268

# above max_rows -> only min_rows (4) rows shown
In [34]: df = pd.DataFrame(np.random.randn(9, 2))

In [35]: df
Out[35]: 
           0         1
0  -0.370647 -1.157892
1  -1.344312  0.844885
..       ...       ...
7   0.276662 -0.472035
8  -0.013960 -0.362543

[9 rows x 2 columns]

In [36]: pd.reset_option("display.max_rows")

In [37]: pd.reset_option("display.min_rows")

---->   pandas.DataFrame

--------------------------------------
ID: 4221 --> 1
In [38]: df = pd.DataFrame(np.random.randn(5, 10))

In [39]: pd.set_option("expand_frame_repr", True)

In [40]: df
Out[40]: 
          0         1         2  ...         7         8         9
0 -0.006154 -0.923061  0.895717  ...  1.340309 -1.170299 -0.226169
1  0.410835  0.813850  0.132003  ... -1.436737 -1.413681  1.607920
2  1.024180  0.569605  0.875906  ... -0.078638  0.545952 -1.219217
3 -1.226825  0.769804 -1.281247  ...  0.341734  0.959726 -1.110336
4 -0.619976  0.149748 -0.732339  ...  0.301624 -2.179861 -1.369849

[5 rows x 10 columns]

In [41]: pd.set_option("expand_frame_repr", False)

In [42]: df
Out[42]: 
          0         1         2         3         4         5         6         7         8         9
0 -0.006154 -0.923061  0.895717  0.805244 -1.206412  2.565646  1.431256  1.340309 -1.170299 -0.226169
1  0.410835  0.813850  0.132003 -0.827317 -0.076467 -1.187678  1.130127 -1.436737 -1.413681  1.607920
2  1.024180  0.569605  0.875906 -2.211372  0.974466 -2.006747 -0.410001 -0.078638  0.545952 -1.219217
3 -1.226825  0.769804 -1.281247 -0.727707 -0.121306 -0.097883  0.695775  0.341734  0.959726 -1.110336
4 -0.619976  0.149748 -0.732339  0.687738  0.176444  0.403310 -0.154951  0.301624 -2.179861 -1.369849

In [43]: pd.reset_option("expand_frame_repr")

---->   pandas.DataFrame

--------------------------------------
ID: 4222 --> 1
In [44]: df = pd.DataFrame(np.random.randn(10, 10))

In [45]: pd.set_option("display.max_rows", 5)

In [46]: pd.set_option("large_repr", "truncate")

In [47]: df
Out[47]: 
           0         1         2  ...         7         8         9
0  -0.954208  1.462696 -1.743161  ...  0.995761  2.396780  0.014871
1   3.357427 -0.317441 -1.236269  ...  0.380396  0.084844  0.432390
..       ...       ...       ...  ...       ...       ...       ...
8  -0.303421 -0.858447  0.306996  ...  0.476720  0.473424 -0.242861
9  -0.014805 -0.284319  0.650776  ...  1.613616  0.464000  0.227371

[10 rows x 10 columns]

In [48]: pd.set_option("large_repr", "info")

In [49]: df
Out[49]: 

RangeIndex: 10 entries, 0 to 9
Data columns (total 10 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       10 non-null     float64
 1   1       10 non-null     float64
 2   2       10 non-null     float64
 3   3       10 non-null     float64
 4   4       10 non-null     float64
 5   5       10 non-null     float64
 6   6       10 non-null     float64
 7   7       10 non-null     float64
 8   8       10 non-null     float64
 9   9       10 non-null     float64
dtypes: float64(10)
memory usage: 928.0 bytes

In [50]: pd.reset_option("large_repr")

In [51]: pd.reset_option("display.max_rows")

---->   pandas.DataFrame

--------------------------------------
ID: 4223 --> 1
In [52]: df = pd.DataFrame(
   ....:     np.array(
   ....:         [
   ....:             ["foo", "bar", "bim", "uncomfortably long string"],
   ....:             ["horse", "cow", "banana", "apple"],
   ....:         ]
   ....:     )
   ....: )
   ....: 

In [53]: pd.set_option("max_colwidth", 40)

In [54]: df
Out[54]: 
       0    1       2                          3
0    foo  bar     bim  uncomfortably long string
1  horse  cow  banana                      apple

In [55]: pd.set_option("max_colwidth", 6)

In [56]: df
Out[56]: 
       0    1      2      3
0    foo  bar    bim  un...
1  horse  cow  ba...  apple

In [57]: pd.reset_option("max_colwidth")

---->   pandas.DataFrame

--------------------------------------
ID: 4224 --> 2
In [58]: df = pd.DataFrame(np.random.randn(10, 10))

In [59]: pd.set_option("max_info_columns", 11)

In [60]: df.info()

RangeIndex: 10 entries, 0 to 9
Data columns (total 10 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       10 non-null     float64
 1   1       10 non-null     float64
 2   2       10 non-null     float64
 3   3       10 non-null     float64
 4   4       10 non-null     float64
 5   5       10 non-null     float64
 6   6       10 non-null     float64
 7   7       10 non-null     float64
 8   8       10 non-null     float64
 9   9       10 non-null     float64
dtypes: float64(10)
memory usage: 928.0 bytes

In [61]: pd.set_option("max_info_columns", 5)

In [62]: df.info()

RangeIndex: 10 entries, 0 to 9
Columns: 10 entries, 0 to 9
dtypes: float64(10)
memory usage: 928.0 bytes

In [63]: pd.reset_option("max_info_columns")

---->   pandas.DataFrame; DataFrame.info

--------------------------------------
ID: 4225 --> 2
In [64]: df = pd.DataFrame(np.random.choice([0, 1, np.nan], size=(10, 10)))

In [65]: df
Out[65]: 
     0    1    2    3    4    5    6    7    8    9
0  0.0  NaN  1.0  NaN  NaN  0.0  NaN  0.0  NaN  1.0
1  1.0  NaN  1.0  1.0  1.0  1.0  NaN  0.0  0.0  NaN
2  0.0  NaN  1.0  0.0  0.0  NaN  NaN  NaN  NaN  0.0
3  NaN  NaN  NaN  0.0  1.0  1.0  NaN  1.0  NaN  1.0
4  0.0  NaN  NaN  NaN  0.0  NaN  NaN  NaN  1.0  0.0
5  0.0  1.0  1.0  1.0  1.0  0.0  NaN  NaN  1.0  0.0
6  1.0  1.0  1.0  NaN  1.0  NaN  1.0  0.0  NaN  NaN
7  0.0  0.0  1.0  0.0  1.0  0.0  1.0  1.0  0.0  NaN
8  NaN  NaN  NaN  0.0  NaN  NaN  NaN  NaN  1.0  NaN
9  0.0  NaN  0.0  NaN  NaN  0.0  NaN  1.0  1.0  0.0

In [66]: pd.set_option("max_info_rows", 11)

In [67]: df.info()

RangeIndex: 10 entries, 0 to 9
Data columns (total 10 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       8 non-null      float64
 1   1       3 non-null      float64
 2   2       7 non-null      float64
 3   3       6 non-null      float64
 4   4       7 non-null      float64
 5   5       6 non-null      float64
 6   6       2 non-null      float64
 7   7       6 non-null      float64
 8   8       6 non-null      float64
 9   9       6 non-null      float64
dtypes: float64(10)
memory usage: 928.0 bytes

In [68]: pd.set_option("max_info_rows", 5)

In [69]: df.info()

RangeIndex: 10 entries, 0 to 9
Data columns (total 10 columns):
 #   Column  Dtype  
---  ------  -----  
 0   0       float64
 1   1       float64
 2   2       float64
 3   3       float64
 4   4       float64
 5   5       float64
 6   6       float64
 7   7       float64
 8   8       float64
 9   9       float64
dtypes: float64(10)
memory usage: 928.0 bytes

In [70]: pd.reset_option("max_info_rows")

---->   pandas.DataFrame; DataFrame.info

--------------------------------------
ID: 4226 --> 1
In [71]: df = pd.DataFrame(np.random.randn(5, 5))

In [72]: pd.set_option("display.precision", 7)

In [73]: df
Out[73]: 
           0          1          2          3          4
0 -1.1506406 -0.7983341 -0.5576966  0.3813531  1.3371217
1 -1.5310949  1.3314582 -0.5713290 -0.0266708 -1.0856630
2 -1.1147378 -0.0582158 -0.4867681  1.6851483  0.1125723
3 -1.4953086  0.8984347 -0.1482168 -1.5960698  0.1596530
4  0.2621358  0.0362196  0.1847350 -0.2550694 -0.2710197

In [74]: pd.set_option("display.precision", 4)

In [75]: df
Out[75]: 
        0       1       2       3       4
0 -1.1506 -0.7983 -0.5577  0.3814  1.3371
1 -1.5311  1.3315 -0.5713 -0.0267 -1.0857
2 -1.1147 -0.0582 -0.4868  1.6851  0.1126
3 -1.4953  0.8984 -0.1482 -1.5961  0.1597
4  0.2621  0.0362  0.1847 -0.2551 -0.2710

---->   pandas.DataFrame

--------------------------------------
ID: 4227 --> 1
In [76]: df = pd.DataFrame(np.random.randn(6, 6))

In [77]: pd.set_option("chop_threshold", 0)

In [78]: df
Out[78]: 
        0       1       2       3       4       5
0  1.2884  0.2946 -1.1658  0.8470 -0.6856  0.6091
1 -0.3040  0.6256 -0.0593  0.2497  1.1039 -1.0875
2  1.9980 -0.2445  0.1362  0.8863 -1.3507 -0.8863
3 -1.0133  1.9209 -0.3882 -2.3144  0.6655  0.4026
4  0.3996 -1.7660  0.8504  0.3881  0.9923  0.7441
5 -0.7398 -1.0549 -0.1796  0.6396  1.5850  1.9067

In [79]: pd.set_option("chop_threshold", 0.5)

In [80]: df
Out[80]: 
        0       1       2       3       4       5
0  1.2884  0.0000 -1.1658  0.8470 -0.6856  0.6091
1  0.0000  0.6256  0.0000  0.0000  1.1039 -1.0875
2  1.9980  0.0000  0.0000  0.8863 -1.3507 -0.8863
3 -1.0133  1.9209  0.0000 -2.3144  0.6655  0.0000
4  0.0000 -1.7660  0.8504  0.0000  0.9923  0.7441
5 -0.7398 -1.0549  0.0000  0.6396  1.5850  1.9067

In [81]: pd.reset_option("chop_threshold")

---->   pandas.DataFrame

--------------------------------------
ID: 4228 --> 1
In [82]: df = pd.DataFrame(
   ....:     np.array([np.random.randn(6), np.random.randint(1, 9, 6) * 0.1, np.zeros(6)]).T,
   ....:     columns=["A", "B", "C"],
   ....:     dtype="float",
   ....: )
   ....: 

In [83]: pd.set_option("colheader_justify", "right")

In [84]: df
Out[84]: 
        A    B    C
0  0.1040  0.1  0.0
1  0.1741  0.5  0.0
2 -0.4395  0.4  0.0
3 -0.7413  0.8  0.0
4 -0.0797  0.4  0.0
5 -0.9229  0.3  0.0

In [85]: pd.set_option("colheader_justify", "left")

In [86]: df
Out[86]: 
   A       B    C  
0  0.1040  0.1  0.0
1  0.1741  0.5  0.0
2 -0.4395  0.4  0.0
3 -0.7413  0.8  0.0
4 -0.0797  0.4  0.0
5 -0.9229  0.3  0.0

In [87]: pd.reset_option("colheader_justify")

---->   pandas.DataFrame

--------------------------------------
ID: 4229 --> 2
In [88]: import numpy as np

In [89]: pd.set_eng_float_format(accuracy=3, use_eng_prefix=True)

In [90]: s = pd.Series(np.random.randn(5), index=["a", "b", "c", "d", "e"])

In [91]: s / 1.0e3
Out[91]: 
a    303.638u
b   -721.084u
c   -622.696u
d    648.250u
e     -1.945m
dtype: float64

In [92]: s / 1.0e6
Out[92]: 
a    303.638n
b   -721.084n
c   -622.696n
d    648.250n
e     -1.945u
dtype: float64

---->   pandas.set_eng_float_format; pandas.Series

--------------------------------------
ID: 4230 --> 1
In [93]: df = pd.DataFrame({"国籍": ["UK", "日本"], "名前": ["Alice", "しのぶ"]})

In [94]: df
Out[94]: 
   国籍     名前
0  UK  Alice
1  日本    しのぶ

---->   pandas.DataFrame

--------------------------------------
ID: 4232 --> 1
In [97]: df = pd.DataFrame({"a": ["xxx", "¡¡"], "b": ["yyy", "¡¡"]})

In [98]: df
Out[98]: 
     a    b
0  xxx  yyy
1   ¡¡   ¡¡

---->   pandas.DataFrame

--------------------------------------
ID: 4235 --> 1
import pandas as pd
import numpy as np
import matplotlib as mpl

df = pd.DataFrame({
    "strings": ["Adam", "Mike"],
    "ints": [1, 3],
    "floats": [1.123, 1000.23]
})
df.style \
  .format(precision=3, thousands=".", decimal=",") \
  .format_index(str.upper, axis=1) \
  .relabel_index(["row 1", "row 2"], axis=0)

---->   pandas.DataFrame

--------------------------------------
ID: 4236 --> 1
weather_df = pd.DataFrame(np.random.rand(10,2)*5,
                          index=pd.date_range(start="2021-01-01", periods=10),
                          columns=["Tokyo", "Beijing"])

def rain_condition(v):
    if v < 1.75:
        return "Dry"
    elif v < 2.75:
        return "Rain"
    return "Heavy Rain"

def make_pretty(styler):
    styler.set_caption("Weather Conditions")
    styler.format(rain_condition)
    styler.format_index(lambda v: v.strftime("%A"))
    styler.background_gradient(axis=None, vmin=1, vmax=5, cmap="YlGnBu")
    return styler

weather_df

---->   pandas.DataFrame

--------------------------------------
ID: 4238 --> 1
df = pd.DataFrame(np.random.randn(5, 5))
df.style \
  .hide(subset=[0, 2, 4], axis=0) \
  .hide(subset=[0, 2, 4], axis=1)

---->   pandas.DataFrame

--------------------------------------
ID: 4240 --> 1
summary_styler = df.agg(["sum", "mean"]).style \
                   .format(precision=3) \
                   .relabel_index(["Sum", "Average"])
df.style.format(precision=1).concat(summary_styler)

---->   DataFrame.agg

--------------------------------------
ID: 4241 --> 3
df = pd.DataFrame([[38.0, 2.0, 18.0, 22.0, 21, np.nan],[19, 439, 6, 452, 226,232]],
                  index=pd.Index(['Tumour (Positive)', 'Non-Tumour (Negative)'], name='Actual Label:'),
                  columns=pd.MultiIndex.from_product([['Decision Tree', 'Regression', 'Random'],['Tumour', 'Non-Tumour']], names=['Model:', 'Predicted:']))
df.style

---->   pandas.DataFrame; pandas.Index; pandas.MultiIndex

--------------------------------------
ID: 4247 --> 1
s.set_table_styles([  # create internal CSS classes
    {'selector': '.true', 'props': 'background-color: #e6ffe6;'},
    {'selector': '.false', 'props': 'background-color: #ffe6e6;'},
], overwrite=False)
cell_color = pd.DataFrame([['true ', 'false ', 'true ', 'false '],
                           ['false ', 'true ', 'false ', 'true ']],
                          index=df.index,
                          columns=df.columns[:4])
s.set_td_classes(cell_color)

---->   pandas.DataFrame

--------------------------------------
ID: 4248 --> 1
np.random.seed(0)
df2 = pd.DataFrame(np.random.randn(10,4), columns=['A','B','C','D'])
df2.style

---->   pandas.DataFrame

--------------------------------------
ID: 4252 --> 1
s2.applymap_index(lambda v: "color:pink;" if v>4 else "color:darkblue;", axis=0)
s2.apply_index(lambda s: np.where(s.isin(["A", "B"]), "color:pink;", "color:darkblue;"), axis=1)

---->   Series.isin

--------------------------------------
ID: 4254 --> 1
tt = pd.DataFrame([['This model has a very strong true positive rate',
                    "This model's total number of false negatives is too high"]],
                  index=['Tumour (Positive)'], columns=df.columns[[0,3]])
s.set_tooltips(tt, props='visibility: hidden; position: absolute; z-index: 1; border: 1px solid #000066;'
                         'background-color: white; color: #000066; font-size: 0.8em;'
                         'transform: translate(0px, -24px); padding: 0.6em; border-radius: 0.5em;')

---->   pandas.DataFrame

--------------------------------------
ID: 4255 --> 1
s.set_table_styles([  # create internal CSS classes
    {'selector': '.border-red', 'props': 'border: 2px dashed red;'},
    {'selector': '.border-green', 'props': 'border: 2px dashed green;'},
], overwrite=False)
cell_border = pd.DataFrame([['border-green ', ' ', ' ', 'border-red '],
                           [' ', ' ', ' ', ' ']],
                          index=df.index,
                          columns=df.columns[:4])
s.set_td_classes(cell_color + cell_border)

---->   pandas.DataFrame

--------------------------------------
ID: 4256 --> 2
df3 = pd.DataFrame(np.random.randn(4,4),
                   pd.MultiIndex.from_product([['A', 'B'], ['r1', 'r2']]),
                   columns=['c1','c2','c3','c4'])
df3

---->   pandas.DataFrame; pandas.MultiIndex

--------------------------------------
ID: 4262 --> 1
df4 = pd.DataFrame([[1,2],[3,4]])
s4 = df4.style

---->   pandas.DataFrame

--------------------------------------
ID: 4267 --> 1
build = lambda x: pd.DataFrame(x, index=df2.index, columns=df2.columns)
cls1 = build(df2.apply(highlight_max, props='cls-1 ', axis=0))
cls2 = build(df2.apply(highlight_max, props='cls-2 ', axis=1, result_type='expand').values)
cls3 = build(highlight_max(df2, props='cls-3 '))
df2.style.set_table_styles([
    {'selector': '.cls-1', 'props': 'color:white;background-color:darkblue;'},
    {'selector': '.cls-2', 'props': 'color:white;background-color:pink;'},
    {'selector': '.cls-3', 'props': 'color:white;background-color:purple;'}
]).set_td_classes(cls1 + cls2 + cls3)

---->   pandas.DataFrame

--------------------------------------
ID: 4271 --> 1
left = pd.Series([1.0, 0.0, 1.0], index=["A", "B", "D"])
df2.loc[:4].style.highlight_between(left=left, right=1.5, axis=1, props='color:white; background-color:purple;')

---->   pandas.Series

--------------------------------------
ID: 4283 --> 1
np.random.seed(25)
cmap = cmap=sns.diverging_palette(5, 250, as_cmap=True)
bigdf = pd.DataFrame(np.random.randn(20, 25)).cumsum()

bigdf.style.background_gradient(cmap, axis=1)\
    .set_properties(**{'max-width': '80px', 'font-size': '1pt'})\
    .set_caption("Hover to magnify")\
    .format(precision=2)\
    .set_table_styles(magnify())

---->   pandas.DataFrame

--------------------------------------
ID: 4284 --> 1
bigdf = pd.DataFrame(np.random.randn(16, 100))
bigdf.style.set_sticky(axis="index")

---->   pandas.DataFrame

--------------------------------------
ID: 4285 --> 1
bigdf.index = pd.MultiIndex.from_product([["A","B"],[0,1],[0,1,2,3]])
bigdf.style.set_sticky(axis="index", pixel_size=18, levels=[1,2])

---->   pandas.MultiIndex

--------------------------------------
ID: 4286 --> 1
df4 = pd.DataFrame([['', '"&other"', '']])
df4.style

---->   pandas.DataFrame

--------------------------------------
ID: 4290 --> 1
print(pd.DataFrame([[1,2],[3,4]], index=['i1', 'i2'], columns=['c1', 'c2']).style.to_html())

---->   pandas.DataFrame

--------------------------------------
ID: 4291 --> 1
df4 = pd.DataFrame([['text']])
df4.style.applymap(lambda x: 'color:green;')\
         .applymap(lambda x: 'color:red;')

---->   pandas.DataFrame

--------------------------------------
ID: 4294 --> 1
df4.style.set_uuid('b_')\
         .set_table_styles([{'selector': 'td', 'props': 'color:red;'},
                            {'selector': '.cls-1', 'props': 'color:blue;'}])\
         .applymap(lambda x: 'color:green;')\
         .set_td_classes(pd.DataFrame([['cls-1']]))

---->   pandas.DataFrame

--------------------------------------
ID: 4295 --> 1
df4.style.set_uuid('c_')\
         .set_table_styles([{'selector': 'td', 'props': 'color:red;'},
                            {'selector': '.cls-1', 'props': 'color:blue;'},
                            {'selector': 'td.data', 'props': 'color:yellow;'}])\
         .applymap(lambda x: 'color:green;')\
         .set_td_classes(pd.DataFrame([['cls-1']]))

---->   pandas.DataFrame

--------------------------------------
ID: 4296 --> 1
df4.style.set_uuid('d_')\
         .set_table_styles([{'selector': 'td', 'props': 'color:red;'},
                            {'selector': '.cls-1', 'props': 'color:blue;'},
                            {'selector': 'td.data', 'props': 'color:yellow;'}])\
         .applymap(lambda x: 'color:green !important;')\
         .set_td_classes(pd.DataFrame([['cls-1']]))

---->   pandas.DataFrame

--------------------------------------
ID: 4305 --> 2
In [1]: s = pd.Series([1, 2, 3])

In [2]: mask = pd.array([True, False, pd.NA], dtype="boolean")

In [3]: s[mask]
Out[3]: 
0    1
dtype: int64

---->   pandas.Series; pandas.array

--------------------------------------
ID: 4307 --> 1
In [5]: pd.Series([True, False, np.nan], dtype="object") | True
Out[5]: 
0     True
1     True
2    False
dtype: bool

In [6]: pd.Series([True, False, np.nan], dtype="boolean") | True
Out[6]: 
0    True
1    True
2    True
dtype: boolean

---->   pandas.Series

--------------------------------------
ID: 4308 --> 1
In [7]: pd.Series([True, False, np.nan], dtype="object") & True
Out[7]: 
0     True
1    False
2    False
dtype: bool

In [8]: pd.Series([True, False, np.nan], dtype="boolean") & True
Out[8]: 
0     True
1    False
2     
dtype: boolean

---->   pandas.Series

--------------------------------------
ID: 4309 --> 1
In [1]: df = pd.DataFrame(
   ...:     np.random.randn(5, 3),
   ...:     index=["a", "c", "e", "f", "h"],
   ...:     columns=["one", "two", "three"],
   ...: )
   ...: 

In [2]: df["four"] = "bar"

In [3]: df["five"] = df["one"] > 0

In [4]: df
Out[4]: 
        one       two     three four   five
a  0.469112 -0.282863 -1.509059  bar   True
c -1.135632  1.212112 -0.173215  bar  False
e  0.119209 -1.044236 -0.861849  bar   True
f -2.104569 -0.494929  1.071804  bar  False
h  0.721555 -0.706771 -1.039575  bar   True

In [5]: df2 = df.reindex(["a", "b", "c", "d", "e", "f", "g", "h"])

In [6]: df2
Out[6]: 
        one       two     three four   five
a  0.469112 -0.282863 -1.509059  bar   True
b       NaN       NaN       NaN  NaN    NaN
c -1.135632  1.212112 -0.173215  bar  False
d       NaN       NaN       NaN  NaN    NaN
e  0.119209 -1.044236 -0.861849  bar   True
f -2.104569 -0.494929  1.071804  bar  False
g       NaN       NaN       NaN  NaN    NaN
h  0.721555 -0.706771 -1.039575  bar   True

---->   pandas.DataFrame

--------------------------------------
ID: 4310 --> 2
In [7]: df2["one"]
Out[7]: 
a    0.469112
b         NaN
c   -1.135632
d         NaN
e    0.119209
f   -2.104569
g         NaN
h    0.721555
Name: one, dtype: float64

In [8]: pd.isna(df2["one"])
Out[8]: 
a    False
b     True
c    False
d     True
e    False
f    False
g     True
h    False
Name: one, dtype: bool

In [9]: df2["four"].notna()
Out[9]: 
a     True
b    False
c     True
d    False
e     True
f     True
g    False
h     True
Name: four, dtype: bool

In [10]: df2.isna()
Out[10]: 
     one    two  three   four   five
a  False  False  False  False  False
b   True   True   True   True   True
c  False  False  False  False  False
d   True   True   True   True   True
e  False  False  False  False  False
f  False  False  False  False  False
g   True   True   True   True   True
h  False  False  False  False  False

---->   pandas.isna; DataFrame.isna

--------------------------------------
ID: 4311 --> 2
In [14]: pd.Series([1, 2, np.nan, 4], dtype=pd.Int64Dtype())
Out[14]: 
0       1
1       2
2    
3       4
dtype: Int64

---->   pandas.Series; pandas.Int64Dtype

--------------------------------------
ID: 4312 --> 1
In [15]: df2 = df.copy()

In [16]: df2["timestamp"] = pd.Timestamp("20120101")

In [17]: df2
Out[17]: 
        one       two     three four   five  timestamp
a  0.469112 -0.282863 -1.509059  bar   True 2012-01-01
c -1.135632  1.212112 -0.173215  bar  False 2012-01-01
e  0.119209 -1.044236 -0.861849  bar   True 2012-01-01
f -2.104569 -0.494929  1.071804  bar  False 2012-01-01
h  0.721555 -0.706771 -1.039575  bar   True 2012-01-01

In [18]: df2.loc[["a", "c", "h"], ["one", "timestamp"]] = np.nan

In [19]: df2
Out[19]: 
        one       two     three four   five  timestamp
a       NaN -0.282863 -1.509059  bar   True        NaT
c       NaN  1.212112 -0.173215  bar  False        NaT
e  0.119209 -1.044236 -0.861849  bar   True 2012-01-01
f -2.104569 -0.494929  1.071804  bar  False 2012-01-01
h       NaN -0.706771 -1.039575  bar   True        NaT

In [20]: df2.dtypes.value_counts()
Out[20]: 
float64           3
object            1
bool              1
datetime64[ns]    1
Name: count, dtype: int64

---->   DataFrame.copy

--------------------------------------
ID: 4313 --> 1
In [21]: s = pd.Series([1, 2, 3])

In [22]: s.loc[0] = None

In [23]: s
Out[23]: 
0    NaN
1    2.0
2    3.0
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 4314 --> 1
In [24]: s = pd.Series(["a", "b", "c"])

In [25]: s.loc[0] = None

In [26]: s.loc[1] = np.nan

In [27]: s
Out[27]: 
0    None
1     NaN
2       c
dtype: object

---->   pandas.Series

--------------------------------------
ID: 4315 --> 2
In [31]: df
Out[31]: 
        one       two     three
a       NaN -0.282863 -1.509059
c       NaN  1.212112 -0.173215
e  0.119209 -1.044236 -0.861849
f -2.104569 -0.494929  1.071804
h       NaN -0.706771 -1.039575

In [32]: df["one"].sum()
Out[32]: -1.9853605075978744

In [33]: df.mean(1)
Out[33]: 
a   -0.895961
c    0.519449
e   -0.595625
f   -0.509232
h   -0.873173
dtype: float64

In [34]: df.cumsum()
Out[34]: 
        one       two     three
a       NaN -0.282863 -1.509059
c       NaN  0.929249 -1.682273
e  0.119209 -0.114987 -2.544122
f -1.985361 -0.609917 -1.472318
h       NaN -1.316688 -2.511893

In [35]: df.cumsum(skipna=False)
Out[35]: 
   one       two     three
a  NaN -0.282863 -1.509059
c  NaN  0.929249 -1.682273
e  NaN -0.114987 -2.544122
f  NaN -0.609917 -1.472318
h  NaN -1.316688 -2.511893

---->   DataFrame.mean; DataFrame.cumsum

--------------------------------------
ID: 4316 --> 1
In [36]: pd.Series([np.nan]).sum()
Out[36]: 0.0

In [37]: pd.Series([], dtype="float64").sum()
Out[37]: 0.0

---->   pandas.Series

--------------------------------------
ID: 4317 --> 1
In [38]: pd.Series([np.nan]).prod()
Out[38]: 1.0

In [39]: pd.Series([], dtype="float64").prod()
Out[39]: 1.0

---->   pandas.Series

--------------------------------------
ID: 4318 --> 1
In [40]: df
Out[40]: 
        one       two     three
a       NaN -0.282863 -1.509059
c       NaN  1.212112 -0.173215
e  0.119209 -1.044236 -0.861849
f -2.104569 -0.494929  1.071804
h       NaN -0.706771 -1.039575

In [41]: df.groupby("one").mean()
Out[41]: 
                two     three
one                          
-2.104569 -0.494929  1.071804
 0.119209 -1.044236 -0.861849

---->   DataFrame.groupby

--------------------------------------
ID: 4322 --> 2
In [49]: dff = pd.DataFrame(np.random.randn(10, 3), columns=list("ABC"))

In [50]: dff.iloc[3:5, 0] = np.nan

In [51]: dff.iloc[4:6, 1] = np.nan

In [52]: dff.iloc[5:8, 2] = np.nan

In [53]: dff
Out[53]: 
          A         B         C
0  0.271860 -0.424972  0.567020
1  0.276232 -1.087401 -0.673690
2  0.113648 -1.478427  0.524988
3       NaN  0.577046 -1.715002
4       NaN       NaN -1.157892
5 -1.344312       NaN       NaN
6 -0.109050  1.643563       NaN
7  0.357021 -0.674600       NaN
8 -0.968914 -1.294524  0.413738
9  0.276662 -0.472035 -0.013960

In [54]: dff.fillna(dff.mean())
Out[54]: 
          A         B         C
0  0.271860 -0.424972  0.567020
1  0.276232 -1.087401 -0.673690
2  0.113648 -1.478427  0.524988
3 -0.140857  0.577046 -1.715002
4 -0.140857 -0.401419 -1.157892
5 -1.344312 -0.401419 -0.293543
6 -0.109050  1.643563 -0.293543
7  0.357021 -0.674600 -0.293543
8 -0.968914 -1.294524  0.413738
9  0.276662 -0.472035 -0.013960

In [55]: dff.fillna(dff.mean()["B":"C"])
Out[55]: 
          A         B         C
0  0.271860 -0.424972  0.567020
1  0.276232 -1.087401 -0.673690
2  0.113648 -1.478427  0.524988
3       NaN  0.577046 -1.715002
4       NaN -0.401419 -1.157892
5 -1.344312 -0.401419 -0.293543
6 -0.109050  1.643563 -0.293543
7  0.357021 -0.674600 -0.293543
8 -0.968914 -1.294524  0.413738
9  0.276662 -0.472035 -0.013960

---->   pandas.DataFrame; DataFrame.mean

--------------------------------------
ID: 4323 --> 2
In [56]: dff.where(pd.notna(dff), dff.mean(), axis="columns")
Out[56]: 
          A         B         C
0  0.271860 -0.424972  0.567020
1  0.276232 -1.087401 -0.673690
2  0.113648 -1.478427  0.524988
3 -0.140857  0.577046 -1.715002
4 -0.140857 -0.401419 -1.157892
5 -1.344312 -0.401419 -0.293543
6 -0.109050  1.643563 -0.293543
7  0.357021 -0.674600 -0.293543
8 -0.968914 -1.294524  0.413738
9  0.276662 -0.472035 -0.013960

---->   pandas.notna; DataFrame.mean

--------------------------------------
ID: 4325 --> 2
In [61]: ts
Out[61]: 
2000-01-31    0.469112
2000-02-29         NaN
2000-03-31         NaN
2000-04-28         NaN
2000-05-31         NaN
                ...   
2007-12-31   -6.950267
2008-01-31   -7.904475
2008-02-29   -6.441779
2008-03-31   -8.184940
2008-04-30   -9.011531
Freq: BM, Length: 100, dtype: float64

In [62]: ts.count()
Out[62]: 66

In [63]: ts.plot()
Out[63]: 

---->   Series.count; Series.plot

--------------------------------------
ID: 4329 --> 1
In [73]: df = pd.DataFrame(
   ....:     {
   ....:         "A": [1, 2.1, np.nan, 4.7, 5.6, 6.8],
   ....:         "B": [0.25, np.nan, np.nan, 4, 12.2, 14.4],
   ....:     }
   ....: )
   ....: 

In [74]: df
Out[74]: 
     A      B
0  1.0   0.25
1  2.1    NaN
2  NaN    NaN
3  4.7   4.00
4  5.6  12.20
5  6.8  14.40

In [75]: df.interpolate()
Out[75]: 
     A      B
0  1.0   0.25
1  2.1   1.50
2  3.4   2.75
3  4.7   4.00
4  5.6  12.20
5  6.8  14.40

---->   pandas.DataFrame

--------------------------------------
ID: 4332 --> 3
In [81]: np.random.seed(2)

In [82]: ser = pd.Series(np.arange(1, 10.1, 0.25) ** 2 + np.random.randn(37))

In [83]: missing = np.array([4, 13, 14, 15, 16, 17, 18, 20, 29])

In [84]: ser[missing] = np.nan

In [85]: methods = ["linear", "quadratic", "cubic"]

In [86]: df = pd.DataFrame({m: ser.interpolate(method=m) for m in methods})

In [87]: df.plot()
Out[87]: 

---->   pandas.Series; pandas.DataFrame; DataFrame.plot

--------------------------------------
ID: 4333 --> 2
In [88]: ser = pd.Series(np.sort(np.random.uniform(size=100)))

# interpolate at new_index
In [89]: new_index = ser.index.union(pd.Index([49.25, 49.5, 49.75, 50.25, 50.5, 50.75]))

In [90]: interp_s = ser.reindex(new_index).interpolate(method="pchip")

In [91]: interp_s[49:51]
Out[91]: 
49.00    0.471410
49.25    0.476841
49.50    0.481780
49.75    0.485998
50.00    0.489266
50.25    0.491814
50.50    0.493995
50.75    0.495763
51.00    0.497074
dtype: float64

---->   pandas.Series; pandas.Index

--------------------------------------
ID: 4334 --> 1
In [92]: ser = pd.Series([np.nan, np.nan, 5, np.nan, np.nan, np.nan, 13, np.nan, np.nan])

In [93]: ser
Out[93]: 
0     NaN
1     NaN
2     5.0
3     NaN
4     NaN
5     NaN
6    13.0
7     NaN
8     NaN
dtype: float64

# fill all consecutive values in a forward direction
In [94]: ser.interpolate()
Out[94]: 
0     NaN
1     NaN
2     5.0
3     7.0
4     9.0
5    11.0
6    13.0
7    13.0
8    13.0
dtype: float64

# fill one consecutive value in a forward direction
In [95]: ser.interpolate(limit=1)
Out[95]: 
0     NaN
1     NaN
2     5.0
3     7.0
4     NaN
5     NaN
6    13.0
7    13.0
8     NaN
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 4337 --> 1
In [102]: ser = pd.Series([0.0, 1.0, 2.0, 3.0, 4.0])

In [103]: ser.replace(0, 5)
Out[103]: 
0    5.0
1    1.0
2    2.0
3    3.0
4    4.0
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 4340 --> 1
In [106]: df = pd.DataFrame({"a": [0, 1, 2, 3, 4], "b": [5, 6, 7, 8, 9]})

In [107]: df.replace({"a": 0, "b": 5}, 100)
Out[107]: 
     a    b
0  100  100
1    1    6
2    2    7
3    3    8
4    4    9

---->   pandas.DataFrame

--------------------------------------
ID: 4342 --> 1
In [109]: d = {"a": list(range(4)), "b": list("ab.."), "c": ["a", "b", np.nan, "d"]}

In [110]: df = pd.DataFrame(d)

In [111]: df.replace(".", np.nan)
Out[111]: 
   a    b    c
0  0    a    a
1  1    b    b
2  2  NaN  NaN
3  3  NaN    d

---->   pandas.DataFrame

--------------------------------------
ID: 4353 --> 1
In [122]: df = pd.DataFrame(np.random.randn(10, 2))

In [123]: df[np.random.rand(df.shape[0]) > 0.5] = 1.5

In [124]: df.replace(1.5, np.nan)
Out[124]: 
          0         1
0 -0.844214 -1.021415
1  0.432396 -0.323580
2  0.423825  0.799180
3  1.262614  0.751965
4       NaN       NaN
5       NaN       NaN
6 -0.498174 -1.060799
7  0.591667 -0.183257
8  1.019855 -1.482465
9       NaN       NaN

---->   pandas.DataFrame

--------------------------------------
ID: 4355 --> 1
In [128]: s = pd.Series(np.random.randn(5), index=[0, 2, 4, 6, 7])

In [129]: s > 0
Out[129]: 
0    True
2    True
4    True
6    True
7    True
dtype: bool

In [130]: (s > 0).dtype
Out[130]: dtype('bool')

In [131]: crit = (s > 0).reindex(list(range(8)))

In [132]: crit
Out[132]: 
0    True
1     NaN
2    True
3     NaN
4    True
5     NaN
6    True
7    True
dtype: object

In [133]: crit.dtype
Out[133]: dtype('O')

---->   pandas.Series

--------------------------------------
ID: 4358 --> 1
In [138]: s = pd.Series([0, 1, np.nan, 3, 4], dtype="Int64")

In [139]: s
Out[139]: 
0       0
1       1
2    
3       3
4       4
dtype: Int64

---->   pandas.Series

--------------------------------------
ID: 4359 --> 1
In [140]: s = pd.Series([1, 2, None], dtype="Int64")

In [141]: s
Out[141]: 
0       1
1       2
2    
dtype: Int64

In [142]: s[2]
Out[142]: 

In [143]: s[2] is pd.NA
Out[143]: True

---->   pandas.Series

--------------------------------------
ID: 4360 --> 1
In [151]: pd.isna(pd.NA)
Out[151]: True

---->   pandas.isna

--------------------------------------
ID: 4366 --> 2
In [1]: dtypes = [
   ...:     "int64",
   ...:     "float64",
   ...:     "datetime64[ns]",
   ...:     "timedelta64[ns]",
   ...:     "complex128",
   ...:     "object",
   ...:     "bool",
   ...: ]
   ...: 

In [2]: n = 5000

In [3]: data = {t: np.random.randint(100, size=n).astype(t) for t in dtypes}

In [4]: df = pd.DataFrame(data)

In [5]: df["categorical"] = df["object"].astype("category")

In [6]: df.info()

RangeIndex: 5000 entries, 0 to 4999
Data columns (total 8 columns):
 #   Column           Non-Null Count  Dtype          
---  ------           --------------  -----          
 0   int64            5000 non-null   int64          
 1   float64          5000 non-null   float64        
 2   datetime64[ns]   5000 non-null   datetime64[ns] 
 3   timedelta64[ns]  5000 non-null   timedelta64[ns]
 4   complex128       5000 non-null   complex128     
 5   object           5000 non-null   object         
 6   bool             5000 non-null   bool           
 7   categorical      5000 non-null   category       
dtypes: bool(1), category(1), complex128(1), datetime64[ns](1), float64(1), int64(1), object(1), timedelta64[ns](1)
memory usage: 288.2+ KB

---->   pandas.DataFrame; DataFrame.info

--------------------------------------
ID: 4367 --> 1
In [7]: df.info(memory_usage="deep")

RangeIndex: 5000 entries, 0 to 4999
Data columns (total 8 columns):
 #   Column           Non-Null Count  Dtype          
---  ------           --------------  -----          
 0   int64            5000 non-null   int64          
 1   float64          5000 non-null   float64        
 2   datetime64[ns]   5000 non-null   datetime64[ns] 
 3   timedelta64[ns]  5000 non-null   timedelta64[ns]
 4   complex128       5000 non-null   complex128     
 5   object           5000 non-null   object         
 6   bool             5000 non-null   bool           
 7   categorical      5000 non-null   category       
dtypes: bool(1), category(1), complex128(1), datetime64[ns](1), float64(1), int64(1), object(1), timedelta64[ns](1)
memory usage: 424.7 KB

---->   DataFrame.info

--------------------------------------
ID: 4368 --> 1
In [8]: df.memory_usage()
Out[8]: 
Index                128
int64              40000
float64            40000
datetime64[ns]     40000
timedelta64[ns]    40000
complex128         80000
object             40000
bool                5000
categorical         9968
dtype: int64

# total memory usage of dataframe
In [9]: df.memory_usage().sum()
Out[9]: 295096

---->   DataFrame.memory_usage

--------------------------------------
ID: 4369 --> 1
In [10]: df.memory_usage(index=False)
Out[10]: 
int64              40000
float64            40000
datetime64[ns]     40000
timedelta64[ns]    40000
complex128         80000
object             40000
bool                5000
categorical         9968
dtype: int64

---->   DataFrame.memory_usage

--------------------------------------
ID: 4370 --> 1
>>> if pd.Series([False, True, False]):
...     pass

---->   pandas.Series

--------------------------------------
ID: 4371 --> 4
In [11]: if pd.Series([False, True, False]):
   ....:     print("I was true")
   ....: 
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
 in ?()
----> 1 if pd.Series([False, True, False]):
      2     print("I was true")

~/work/pandas/pandas/pandas/core/generic.py in ?(self)
   1464     @final
   1465     def __nonzero__(self) -> NoReturn:
-> 1466         raise ValueError(
   1467             f"The truth value of a {type(self).__name__} is ambiguous. "
   1468             "Use a.empty, a.bool(), a.item(), a.any() or a.all()."
   1469         )

ValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().

---->   pandas.Series; Series.bool; Series.item; Series.all

--------------------------------------
ID: 4372 --> 1
In [12]: if pd.Series([False, True, False]) is not None:
   ....:     print("I was not None")
   ....: 
I was not None

---->   pandas.Series

--------------------------------------
ID: 4373 --> 1
In [13]: if pd.Series([False, True, False]).any():
   ....:     print("I am any")
   ....: 
I am any

---->   pandas.Series

--------------------------------------
ID: 4374 --> 2
In [14]: pd.Series([True]).bool()
Out[14]: True

In [15]: pd.Series([False]).bool()
Out[15]: False

In [16]: pd.DataFrame([[True]]).bool()
Out[16]: True

In [17]: pd.DataFrame([[False]]).bool()
Out[17]: False

---->   pandas.Series; pandas.DataFrame

--------------------------------------
ID: 4375 --> 1
In [18]: s = pd.Series(range(5))

In [19]: s == 4
Out[19]: 
0    False
1    False
2    False
3    False
4     True
dtype: bool

---->   pandas.Series

--------------------------------------
ID: 4376 --> 1
In [20]: s = pd.Series(range(5), index=list("abcde"))

In [21]: 2 in s
Out[21]: False

In [22]: 'b' in s
Out[22]: True

---->   pandas.Series

--------------------------------------
ID: 4377 --> 1
In [23]: s.isin([2])
Out[23]: 
a    False
b    False
c     True
d    False
e    False
dtype: bool

In [24]: s.isin([2]).any()
Out[24]: True

---->   Series.isin

--------------------------------------
ID: 4379 --> 2
In [29]: def f(s):
   ....:     s.pop("a")
   ....:     return s
   ....: 

In [30]: df = pd.DataFrame({"a": [1, 2, 3], "b": [4, 5, 6]})

In [31]: try:
   ....:     df.apply(f, axis="columns")
   ....: except Exception as err:
   ....:     print(repr(err))
   ....: 
KeyError('a')

---->   Series.pop; pandas.DataFrame

--------------------------------------
ID: 4381 --> 3
In [36]: def f(s):
   ....:     s = s.copy()
   ....:     s.pop("a")
   ....:     return s
   ....: 

In [37]: df = pd.DataFrame({"a": [1, 2, 3], 'b': [4, 5, 6]})

In [38]: df.apply(f, axis="columns")
Out[38]: 
   b
0  4
1  5
2  6

---->   Series.copy; Series.pop; pandas.DataFrame

--------------------------------------
ID: 4382 --> 1
In [39]: s = pd.Series([1, 2, 3, 4, 5], index=list("abcde"))

In [40]: s
Out[40]: 
a    1
b    2
c    3
d    4
e    5
dtype: int64

In [41]: s.dtype
Out[41]: dtype('int64')

In [42]: s2 = s.reindex(["a", "b", "c", "f", "u"])

In [43]: s2
Out[43]: 
a    1.0
b    2.0
c    3.0
f    NaN
u    NaN
dtype: float64

In [44]: s2.dtype
Out[44]: dtype('float64')

---->   pandas.Series

--------------------------------------
ID: 4383 --> 2
In [45]: s_int = pd.Series([1, 2, 3, 4, 5], index=list("abcde"), dtype=pd.Int64Dtype())

In [46]: s_int
Out[46]: 
a    1
b    2
c    3
d    4
e    5
dtype: Int64

In [47]: s_int.dtype
Out[47]: Int64Dtype()

In [48]: s2_int = s_int.reindex(["a", "b", "c", "f", "u"])

In [49]: s2_int
Out[49]: 
a       1
b       2
c       3
f    
u    
dtype: Int64

In [50]: s2_int.dtype
Out[50]: Int64Dtype()

---->   pandas.Series; pandas.Int64Dtype

--------------------------------------
ID: 4384 --> 1
In [51]: x = np.array(list(range(10)), ">i4")  # big endian

In [52]: newx = x.byteswap().newbyteorder()  # force native byteorder

In [53]: s = pd.Series(newx)

---->   pandas.Series

--------------------------------------
ID: 4385 --> 1
In [1]: s = pd.Series(["a", "b", "c", "a"], dtype="category")

In [2]: s
Out[2]: 
0    a
1    b
2    c
3    a
dtype: category
Categories (3, object): ['a', 'b', 'c']

---->   pandas.Series

--------------------------------------
ID: 4386 --> 1
In [3]: df = pd.DataFrame({"A": ["a", "b", "c", "a"]})

In [4]: df["B"] = df["A"].astype("category")

In [5]: df
Out[5]: 
   A  B
0  a  a
1  b  b
2  c  c
3  a  a

---->   pandas.DataFrame

--------------------------------------
ID: 4387 --> 3
In [6]: df = pd.DataFrame({"value": np.random.randint(0, 100, 20)})

In [7]: labels = ["{0} - {1}".format(i, i + 9) for i in range(0, 100, 10)]

In [8]: df["group"] = pd.cut(df.value, range(0, 105, 10), right=False, labels=labels)

In [9]: df.head(10)
Out[9]: 
   value    group
0     65  60 - 69
1     49  40 - 49
2     56  50 - 59
3     43  40 - 49
4     43  40 - 49
5     91  90 - 99
6     32  30 - 39
7     87  80 - 89
8     36  30 - 39
9      8    0 - 9

---->   pandas.DataFrame; pandas.cut; DataFrame.head

--------------------------------------
ID: 4388 --> 3
In [10]: raw_cat = pd.Categorical(
   ....:     ["a", "b", "c", "a"], categories=["b", "c", "d"], ordered=False
   ....: )
   ....: 

In [11]: s = pd.Series(raw_cat)

In [12]: s
Out[12]: 
0    NaN
1      b
2      c
3    NaN
dtype: category
Categories (3, object): ['b', 'c', 'd']

In [13]: df = pd.DataFrame({"A": ["a", "b", "c", "a"]})

In [14]: df["B"] = raw_cat

In [15]: df
Out[15]: 
   A    B
0  a  NaN
1  b    b
2  c    c
3  a  NaN

---->   pandas.Categorical; pandas.Series; pandas.DataFrame

--------------------------------------
ID: 4389 --> 1
In [17]: df = pd.DataFrame({"A": list("abca"), "B": list("bccd")}, dtype="category")

In [18]: df.dtypes
Out[18]: 
A    category
B    category
dtype: object

---->   pandas.DataFrame

--------------------------------------
ID: 4391 --> 2
In [21]: df = pd.DataFrame({"A": list("abca"), "B": list("bccd")})

In [22]: df_cat = df.astype("category")

In [23]: df_cat.dtypes
Out[23]: 
A    category
B    category
dtype: object

---->   pandas.DataFrame; DataFrame.astype

--------------------------------------
ID: 4393 --> 2
In [26]: from pandas.api.types import CategoricalDtype

In [27]: s = pd.Series(["a", "b", "c", "a"])

In [28]: cat_type = CategoricalDtype(categories=["b", "c", "d"], ordered=True)

In [29]: s_cat = s.astype(cat_type)

In [30]: s_cat
Out[30]: 
0    NaN
1      b
2      c
3    NaN
dtype: category
Categories (3, object): ['b' < 'c' < 'd']

---->   pandas.Series; Series.astype

--------------------------------------
ID: 4394 --> 2
In [31]: from pandas.api.types import CategoricalDtype

In [32]: df = pd.DataFrame({"A": list("abca"), "B": list("bccd")})

In [33]: cat_type = CategoricalDtype(categories=list("abcd"), ordered=True)

In [34]: df_cat = df.astype(cat_type)

In [35]: df_cat["A"]
Out[35]: 
0    a
1    b
2    c
3    a
Name: A, dtype: category
Categories (4, object): ['a' < 'b' < 'c' < 'd']

In [36]: df_cat["B"]
Out[36]: 
0    b
1    c
2    c
3    d
Name: B, dtype: category
Categories (4, object): ['a' < 'b' < 'c' < 'd']

---->   pandas.DataFrame; DataFrame.astype

--------------------------------------
ID: 4395 --> 2
In [37]: splitter = np.random.choice([0, 1], 5, p=[0.5, 0.5])

In [38]: s = pd.Series(pd.Categorical.from_codes(splitter, categories=["train", "test"]))

---->   pandas.Series; pandas.Categorical

--------------------------------------
ID: 4396 --> 3
In [39]: s = pd.Series(["a", "b", "c", "a"])

In [40]: s
Out[40]: 
0    a
1    b
2    c
3    a
dtype: object

In [41]: s2 = s.astype("category")

In [42]: s2
Out[42]: 
0    a
1    b
2    c
3    a
dtype: category
Categories (3, object): ['a', 'b', 'c']

In [43]: s2.astype(str)
Out[43]: 
0    a
1    b
2    c
3    a
dtype: object

In [44]: np.asarray(s2)
Out[44]: array(['a', 'b', 'c', 'a'], dtype=object)

---->   pandas.Series; Series.astype; Series.astype

--------------------------------------
ID: 4399 --> 3
In [53]: cat = pd.Categorical(["a", "c", "c", np.nan], categories=["b", "a", "c"])

In [54]: df = pd.DataFrame({"cat": cat, "s": ["a", "c", "c", np.nan]})

In [55]: df.describe()
Out[55]: 
       cat  s
count    3  3
unique   2  2
top      c  c
freq     2  2

In [56]: df["cat"].describe()
Out[56]: 
count     3
unique    2
top       c
freq      2
Name: cat, dtype: object

---->   pandas.Categorical; pandas.DataFrame; DataFrame.describe

--------------------------------------
ID: 4400 --> 1
In [57]: s = pd.Series(["a", "b", "c", "a"], dtype="category")

In [58]: s.cat.categories
Out[58]: Index(['a', 'b', 'c'], dtype='object')

In [59]: s.cat.ordered
Out[59]: False

---->   pandas.Series

--------------------------------------
ID: 4401 --> 2
In [60]: s = pd.Series(pd.Categorical(["a", "b", "c", "a"], categories=["c", "b", "a"]))

In [61]: s.cat.categories
Out[61]: Index(['c', 'b', 'a'], dtype='object')

In [62]: s.cat.ordered
Out[62]: False

---->   pandas.Series; pandas.Categorical

--------------------------------------
ID: 4402 --> 2
In [63]: s = pd.Series(list("babc")).astype(CategoricalDtype(list("abcd")))

In [64]: s
Out[64]: 
0    b
1    a
2    b
3    c
dtype: category
Categories (4, object): ['a', 'b', 'c', 'd']

# categories
In [65]: s.cat.categories
Out[65]: Index(['a', 'b', 'c', 'd'], dtype='object')

# uniques
In [66]: s.unique()
Out[66]: 
['b', 'a', 'c']
Categories (4, object): ['a', 'b', 'c', 'd']

---->   pandas.Series; Series.unique

--------------------------------------
ID: 4403 --> 1
In [67]: s = pd.Series(["a", "b", "c", "a"], dtype="category")

In [68]: s
Out[68]: 
0    a
1    b
2    c
3    a
dtype: category
Categories (3, object): ['a', 'b', 'c']

In [69]: new_categories = ["Group %s" % g for g in s.cat.categories]

In [70]: s = s.cat.rename_categories(new_categories)

In [71]: s
Out[71]: 
0    Group a
1    Group b
2    Group c
3    Group a
dtype: category
Categories (3, object): ['Group a', 'Group b', 'Group c']

# You can also pass a dict-like object to map the renaming
In [72]: s = s.cat.rename_categories({1: "x", 2: "y", 3: "z"})

In [73]: s
Out[73]: 
0    Group a
1    Group b
2    Group c
3    Group a
dtype: category
Categories (3, object): ['Group a', 'Group b', 'Group c']

---->   pandas.Series

--------------------------------------
ID: 4408 --> 2
In [81]: s = pd.Series(pd.Categorical(["a", "b", "a"], categories=["a", "b", "c", "d"]))

In [82]: s
Out[82]: 
0    a
1    b
2    a
dtype: category
Categories (4, object): ['a', 'b', 'c', 'd']

In [83]: s.cat.remove_unused_categories()
Out[83]: 
0    a
1    b
2    a
dtype: category
Categories (2, object): ['a', 'b']

---->   pandas.Series; pandas.Categorical

--------------------------------------
ID: 4409 --> 1
In [84]: s = pd.Series(["one", "two", "four", "-"], dtype="category")

In [85]: s
Out[85]: 
0     one
1     two
2    four
3       -
dtype: category
Categories (4, object): ['-', 'four', 'one', 'two']

In [86]: s = s.cat.set_categories(["one", "two", "three", "four"])

In [87]: s
Out[87]: 
0     one
1     two
2    four
3     NaN
dtype: category
Categories (4, object): ['one', 'two', 'three', 'four']

---->   pandas.Series

--------------------------------------
ID: 4410 --> 4
In [88]: s = pd.Series(pd.Categorical(["a", "b", "c", "a"], ordered=False))

In [89]: s = s.sort_values()

In [90]: s = pd.Series(["a", "b", "c", "a"]).astype(CategoricalDtype(ordered=True))

In [91]: s = s.sort_values()

In [92]: s
Out[92]: 
0    a
3    a
1    b
2    c
dtype: category
Categories (3, object): ['a' < 'b' < 'c']

In [93]: s.min(), s.max()
Out[93]: ('a', 'c')

---->   pandas.Series; pandas.Categorical; Series.min; Series.max

--------------------------------------
ID: 4412 --> 3
In [96]: s = pd.Series([1, 2, 3, 1], dtype="category")

In [97]: s = s.cat.set_categories([2, 3, 1], ordered=True)

In [98]: s
Out[98]: 
0    1
1    2
2    3
3    1
dtype: category
Categories (3, int64): [2 < 3 < 1]

In [99]: s = s.sort_values()

In [100]: s
Out[100]: 
1    2
2    3
0    1
3    1
dtype: category
Categories (3, int64): [2 < 3 < 1]

In [101]: s.min(), s.max()
Out[101]: (2, 1)

---->   pandas.Series; Series.min; Series.max

--------------------------------------
ID: 4413 --> 3
In [102]: s = pd.Series([1, 2, 3, 1], dtype="category")

In [103]: s = s.cat.reorder_categories([2, 3, 1], ordered=True)

In [104]: s
Out[104]: 
0    1
1    2
2    3
3    1
dtype: category
Categories (3, int64): [2 < 3 < 1]

In [105]: s = s.sort_values()

In [106]: s
Out[106]: 
1    2
2    3
0    1
3    1
dtype: category
Categories (3, int64): [2 < 3 < 1]

In [107]: s.min(), s.max()
Out[107]: (2, 1)

---->   pandas.Series; Series.min; Series.max

--------------------------------------
ID: 4414 --> 2
In [108]: dfs = pd.DataFrame(
   .....:     {
   .....:         "A": pd.Categorical(
   .....:             list("bbeebbaa"),
   .....:             categories=["e", "a", "b"],
   .....:             ordered=True,
   .....:         ),
   .....:         "B": [1, 2, 1, 2, 2, 1, 2, 1],
   .....:     }
   .....: )
   .....: 

In [109]: dfs.sort_values(by=["A", "B"])
Out[109]: 
   A  B
2  e  1
3  e  2
7  a  1
6  a  2
0  b  1
5  b  1
1  b  2
4  b  2

---->   pandas.DataFrame; pandas.Categorical

--------------------------------------
ID: 4416 --> 1
In [112]: cat = pd.Series([1, 2, 3]).astype(CategoricalDtype([3, 2, 1], ordered=True))

In [113]: cat_base = pd.Series([2, 2, 2]).astype(CategoricalDtype([3, 2, 1], ordered=True))

In [114]: cat_base2 = pd.Series([2, 2, 2]).astype(CategoricalDtype(ordered=True))

In [115]: cat
Out[115]: 
0    1
1    2
2    3
dtype: category
Categories (3, int64): [3 < 2 < 1]

In [116]: cat_base
Out[116]: 
0    2
1    2
2    2
dtype: category
Categories (3, int64): [3 < 2 < 1]

In [117]: cat_base2
Out[117]: 
0    2
1    2
2    2
dtype: category
Categories (1, int64): [2]

---->   pandas.Series

--------------------------------------
ID: 4420 --> 1
In [127]: c1 = pd.Categorical(["a", "b"], categories=["a", "b"], ordered=False)

In [128]: c2 = pd.Categorical(["a", "b"], categories=["b", "a"], ordered=False)

In [129]: c1 == c2
Out[129]: array([ True,  True])

---->   pandas.Categorical

--------------------------------------
ID: 4421 --> 3
In [130]: s = pd.Series(pd.Categorical(["a", "b", "c", "c"], categories=["c", "a", "b", "d"]))

In [131]: s.value_counts()
Out[131]: 
c    2
a    1
b    1
d    0
Name: count, dtype: int64

---->   pandas.Series; pandas.Categorical; Series.value_counts

--------------------------------------
ID: 4422 --> 4
In [132]: columns = pd.Categorical(
   .....:     ["One", "One", "Two"], categories=["One", "Two", "Three"], ordered=True
   .....: )
   .....: 

In [133]: df = pd.DataFrame(
   .....:     data=[[1, 2, 3], [4, 5, 6]],
   .....:     columns=pd.MultiIndex.from_arrays([["A", "B", "B"], columns]),
   .....: )
   .....: 

In [134]: df.groupby(axis=1, level=1).sum()
Out[134]: 
   One  Two  Three
0    3    3      0
1    9    6      0

---->   pandas.Categorical; pandas.DataFrame; pandas.MultiIndex; DataFrame.groupby

--------------------------------------
ID: 4423 --> 4
In [135]: cats = pd.Categorical(
   .....:     ["a", "b", "b", "b", "c", "c", "c"], categories=["a", "b", "c", "d"]
   .....: )
   .....: 

In [136]: df = pd.DataFrame({"cats": cats, "values": [1, 2, 2, 2, 3, 4, 5]})

In [137]: df.groupby("cats").mean()
Out[137]: 
      values
cats        
a        1.0
b        2.0
c        4.0
d        NaN

In [138]: cats2 = pd.Categorical(["a", "a", "b", "b"], categories=["a", "b", "c"])

In [139]: df2 = pd.DataFrame(
   .....:     {
   .....:         "cats": cats2,
   .....:         "B": ["c", "d", "c", "d"],
   .....:         "values": [1, 2, 3, 4],
   .....:     }
   .....: )
   .....: 

In [140]: df2.groupby(["cats", "B"]).mean()
Out[140]: 
        values
cats B        
a    c     1.0
     d     2.0
b    c     3.0
     d     4.0
c    c     NaN
     d     NaN

---->   pandas.Categorical; pandas.DataFrame; DataFrame.groupby; DataFrame.groupby

--------------------------------------
ID: 4424 --> 3
In [141]: raw_cat = pd.Categorical(["a", "a", "b", "b"], categories=["a", "b", "c"])

In [142]: df = pd.DataFrame({"A": raw_cat, "B": ["c", "d", "c", "d"], "values": [1, 2, 3, 4]})

In [143]: pd.pivot_table(df, values="values", index=["A", "B"])
Out[143]: 
     values
A B        
a c       1
  d       2
b c       3
  d       4

---->   pandas.Categorical; pandas.DataFrame; pandas.pivot_table

--------------------------------------
ID: 4425 --> 3
In [144]: idx = pd.Index(["h", "i", "j", "k", "l", "m", "n"])

In [145]: cats = pd.Series(["a", "b", "b", "b", "c", "c", "c"], dtype="category", index=idx)

In [146]: values = [1, 2, 2, 2, 3, 4, 5]

In [147]: df = pd.DataFrame({"cats": cats, "values": values}, index=idx)

In [148]: df.iloc[2:4, :]
Out[148]: 
  cats  values
j    b       2
k    b       2

In [149]: df.iloc[2:4, :].dtypes
Out[149]: 
cats      category
values       int64
dtype: object

In [150]: df.loc["h":"j", "cats"]
Out[150]: 
h    a
i    b
j    b
Name: cats, dtype: category
Categories (3, object): ['a', 'b', 'c']

In [151]: df[df["cats"] == "b"]
Out[151]: 
  cats  values
i    b       2
j    b       2
k    b       2

---->   pandas.Index; pandas.Series; pandas.DataFrame

--------------------------------------
ID: 4428 --> 3
In [157]: str_s = pd.Series(list("aabb"))

In [158]: str_cat = str_s.astype("category")

In [159]: str_cat
Out[159]: 
0    a
1    a
2    b
3    b
dtype: category
Categories (2, object): ['a', 'b']

In [160]: str_cat.str.contains("a")
Out[160]: 
0     True
1     True
2    False
3    False
dtype: bool

In [161]: date_s = pd.Series(pd.date_range("1/1/2015", periods=5))

In [162]: date_cat = date_s.astype("category")

In [163]: date_cat
Out[163]: 
0   2015-01-01
1   2015-01-02
2   2015-01-03
3   2015-01-04
4   2015-01-05
dtype: category
Categories (5, datetime64[ns]): [2015-01-01, 2015-01-02, 2015-01-03, 2015-01-04, 2015-01-05]

In [164]: date_cat.dt.day
Out[164]: 
0    1
1    2
2    3
3    4
4    5
dtype: int32

---->   pandas.Series; Series.astype; Series.astype

--------------------------------------
ID: 4430 --> 3
In [169]: idx = pd.Index(["h", "i", "j", "k", "l", "m", "n"])

In [170]: cats = pd.Categorical(["a", "a", "a", "a", "a", "a", "a"], categories=["a", "b"])

In [171]: values = [1, 1, 1, 1, 1, 1, 1]

In [172]: df = pd.DataFrame({"cats": cats, "values": values}, index=idx)

In [173]: df.iloc[2:4, :] = [["b", 2], ["b", 2]]

In [174]: df
Out[174]: 
  cats  values
h    a       1
i    a       1
j    b       2
k    b       2
l    a       1
m    a       1
n    a       1

In [175]: try:
   .....:     df.iloc[2:4, :] = [["c", 3], ["c", 3]]
   .....: except TypeError as e:
   .....:     print("TypeError:", str(e))
   .....: 
TypeError: Cannot setitem on a Categorical with a new category, set the categories first

---->   pandas.Index; pandas.Categorical; pandas.DataFrame

--------------------------------------
ID: 4431 --> 1
In [176]: df.loc["j":"k", "cats"] = pd.Categorical(["a", "a"], categories=["a", "b"])

In [177]: df
Out[177]: 
  cats  values
h    a       1
i    a       1
j    a       2
k    a       2
l    a       1
m    a       1
n    a       1

In [178]: try:
   .....:     df.loc["j":"k", "cats"] = pd.Categorical(["b", "b"], categories=["a", "b", "c"])
   .....: except TypeError as e:
   .....:     print("TypeError:", str(e))
   .....: 
TypeError: Cannot set a Categorical with another, without identical categories

---->   pandas.Categorical

--------------------------------------
ID: 4432 --> 2
In [179]: df = pd.DataFrame({"a": [1, 1, 1, 1, 1], "b": ["a", "a", "a", "a", "a"]})

In [180]: df.loc[1:2, "a"] = pd.Categorical(["b", "b"], categories=["a", "b"])

In [181]: df.loc[2:3, "b"] = pd.Categorical(["b", "b"], categories=["a", "b"])

In [182]: df
Out[182]: 
   a  b
0  1  a
1  b  a
2  b  b
3  1  b
4  1  a

In [183]: df.dtypes
Out[183]: 
a    object
b    object
dtype: object

---->   pandas.DataFrame; pandas.Categorical

--------------------------------------
ID: 4433 --> 1
In [184]: from pandas.api.types import union_categoricals

# same categories
In [185]: s1 = pd.Series(["a", "b"], dtype="category")

In [186]: s2 = pd.Series(["a", "b", "a"], dtype="category")

In [187]: pd.concat([s1, s2])
Out[187]: 
0    a
1    b
0    a
1    b
2    a
dtype: category
Categories (2, object): ['a', 'b']

# different categories
In [188]: s3 = pd.Series(["b", "c"], dtype="category")

In [189]: pd.concat([s1, s3])
Out[189]: 
0    a
1    b
0    b
1    c
dtype: object

# Output dtype is inferred based on categories values
In [190]: int_cats = pd.Series([1, 2], dtype="category")

In [191]: float_cats = pd.Series([3.0, 4.0], dtype="category")

In [192]: pd.concat([int_cats, float_cats])
Out[192]: 
0    1.0
1    2.0
0    3.0
1    4.0
dtype: float64

In [193]: pd.concat([s1, s3]).astype("category")
Out[193]: 
0    a
1    b
0    b
1    c
dtype: category
Categories (3, object): ['a', 'b', 'c']

In [194]: union_categoricals([s1.array, s3.array])
Out[194]: 
['a', 'b', 'b', 'c']
Categories (3, object): ['a', 'b', 'c']

---->   pandas.Series

--------------------------------------
ID: 4434 --> 1
In [195]: from pandas.api.types import union_categoricals

In [196]: a = pd.Categorical(["b", "c"])

In [197]: b = pd.Categorical(["a", "b"])

In [198]: union_categoricals([a, b])
Out[198]: 
['b', 'c', 'a', 'b']
Categories (3, object): ['b', 'c', 'a']

---->   pandas.Categorical

--------------------------------------
ID: 4436 --> 1
In [200]: a = pd.Categorical(["a", "b"], ordered=True)

In [201]: b = pd.Categorical(["a", "b", "a"], ordered=True)

In [202]: union_categoricals([a, b])
Out[202]: 
['a', 'b', 'a', 'b', 'a']
Categories (2, object): ['a' < 'b']

---->   pandas.Categorical

--------------------------------------
ID: 4437 --> 1
In [1]: a = pd.Categorical(["a", "b"], ordered=True)
In [2]: b = pd.Categorical(["a", "b", "c"], ordered=True)
In [3]: union_categoricals([a, b])
Out[3]:
TypeError: to union ordered Categoricals, all categories must be the same

---->   pandas.Categorical

--------------------------------------
ID: 4438 --> 1
In [203]: a = pd.Categorical(["a", "b", "c"], ordered=True)

In [204]: b = pd.Categorical(["c", "b", "a"], ordered=True)

In [205]: union_categoricals([a, b], ignore_order=True)
Out[205]: 
['a', 'b', 'c', 'c', 'b', 'a']
Categories (3, object): ['a', 'b', 'c']

---->   pandas.Categorical

--------------------------------------
ID: 4439 --> 1
In [206]: a = pd.Series(["b", "c"], dtype="category")

In [207]: b = pd.Series(["a", "b"], dtype="category")

In [208]: union_categoricals([a, b])
Out[208]: 
['b', 'c', 'a', 'b']
Categories (3, object): ['b', 'c', 'a']

---->   pandas.Series

--------------------------------------
ID: 4440 --> 1
In [209]: c1 = pd.Categorical(["b", "c"])

In [210]: c2 = pd.Categorical(["a", "b"])

In [211]: c1
Out[211]: 
['b', 'c']
Categories (2, object): ['b', 'c']

# "b" is coded to 0
In [212]: c1.codes
Out[212]: array([0, 1], dtype=int8)

In [213]: c2
Out[213]: 
['a', 'b']
Categories (2, object): ['a', 'b']

# "b" is coded to 1
In [214]: c2.codes
Out[214]: array([0, 1], dtype=int8)

In [215]: c = union_categoricals([c1, c2])

In [216]: c
Out[216]: 
['b', 'c', 'a', 'b']
Categories (3, object): ['b', 'c', 'a']

# "b" is coded to 0 throughout, same as c1, different from c2
In [217]: c.codes
Out[217]: array([0, 1, 2, 0], dtype=int8)

---->   pandas.Categorical

--------------------------------------
ID: 4441 --> 4
In [218]: import io

In [219]: s = pd.Series(pd.Categorical(["a", "b", "b", "a", "a", "d"]))

# rename the categories
In [220]: s = s.cat.rename_categories(["very good", "good", "bad"])

# reorder the categories and add missing categories
In [221]: s = s.cat.set_categories(["very bad", "bad", "medium", "good", "very good"])

In [222]: df = pd.DataFrame({"cats": s, "vals": [1, 2, 3, 4, 5, 6]})

In [223]: csv = io.StringIO()

In [224]: df.to_csv(csv)

In [225]: df2 = pd.read_csv(io.StringIO(csv.getvalue()))

In [226]: df2.dtypes
Out[226]: 
Unnamed: 0     int64
cats          object
vals           int64
dtype: object

In [227]: df2["cats"]
Out[227]: 
0    very good
1         good
2         good
3    very good
4    very good
5          bad
Name: cats, dtype: object

# Redo the category
In [228]: df2["cats"] = df2["cats"].astype("category")

In [229]: df2["cats"] = df2["cats"].cat.set_categories(
   .....:     ["very bad", "bad", "medium", "good", "very good"]
   .....: )
   .....: 

In [230]: df2.dtypes
Out[230]: 
Unnamed: 0       int64
cats          category
vals             int64
dtype: object

In [231]: df2["cats"]
Out[231]: 
0    very good
1         good
2         good
3    very good
4    very good
5          bad
Name: cats, dtype: category
Categories (5, object): ['very bad', 'bad', 'medium', 'good', 'very good']

---->   pandas.Series; pandas.Categorical; pandas.DataFrame; DataFrame.to_csv

--------------------------------------
ID: 4442 --> 1
In [232]: s = pd.Series(["a", "b", np.nan, "a"], dtype="category")

# only two categories
In [233]: s
Out[233]: 
0      a
1      b
2    NaN
3      a
dtype: category
Categories (2, object): ['a', 'b']

In [234]: s.cat.codes
Out[234]: 
0    0
1    1
2   -1
3    0
dtype: int8

---->   pandas.Series

--------------------------------------
ID: 4443 --> 2
In [235]: s = pd.Series(["a", "b", np.nan], dtype="category")

In [236]: s
Out[236]: 
0      a
1      b
2    NaN
dtype: category
Categories (2, object): ['a', 'b']

In [237]: pd.isna(s)
Out[237]: 
0    False
1    False
2     True
dtype: bool

In [238]: s.fillna("a")
Out[238]: 
0    a
1    b
2    a
dtype: category
Categories (2, object): ['a', 'b']

---->   pandas.Series; pandas.isna

--------------------------------------
ID: 4444 --> 2
In [239]: s = pd.Series(["foo", "bar"] * 1000)

# object dtype
In [240]: s.nbytes
Out[240]: 16000

# category dtype
In [241]: s.astype("category").nbytes
Out[241]: 2016

---->   pandas.Series; Series.astype

--------------------------------------
ID: 4445 --> 2
In [242]: s = pd.Series(["foo%04d" % i for i in range(2000)])

# object dtype
In [243]: s.nbytes
Out[243]: 16000

# category dtype
In [244]: s.astype("category").nbytes
Out[244]: 20000

---->   pandas.Series; Series.astype

--------------------------------------
ID: 4446 --> 1
In [245]: try:
   .....:     np.dtype("category")
   .....: except TypeError as e:
   .....:     print("TypeError:", str(e))
   .....: 
TypeError: data type 'category' not understood

In [246]: dtype = pd.Categorical(["a"]).dtype

In [247]: try:
   .....:     np.dtype(dtype)
   .....: except TypeError as e:
   .....:     print("TypeError:", str(e))
   .....: 
TypeError: Cannot interpret 'CategoricalDtype(categories=['a'], ordered=False)' as a data type

---->   pandas.Categorical

--------------------------------------
ID: 4447 --> 1
In [250]: hasattr(pd.Series(["a"], dtype="category"), "cat")
Out[250]: True

In [251]: hasattr(pd.Series(["a"]), "cat")
Out[251]: False

---->   pandas.Series

--------------------------------------
ID: 4448 --> 2
In [252]: s = pd.Series(pd.Categorical([1, 2, 3, 4]))

In [253]: try:
   .....:     np.sum(s)
   .....: except TypeError as e:
   .....:     print("TypeError:", str(e))
   .....: 
TypeError: 'Categorical' with dtype category does not support reduction 'sum'

---->   pandas.Series; pandas.Categorical

--------------------------------------
ID: 4449 --> 2
In [254]: df = pd.DataFrame(
   .....:     {
   .....:         "a": [1, 2, 3, 4],
   .....:         "b": ["a", "b", "c", "d"],
   .....:         "cats": pd.Categorical([1, 2, 3, 2]),
   .....:     }
   .....: )
   .....: 

In [255]: df.apply(lambda row: type(row["cats"]), axis=1)
Out[255]: 
0    
1    
2    
3    
dtype: object

In [256]: df.apply(lambda col: col.dtype, axis=0)
Out[256]: 
a          int64
b         object
cats    category
dtype: object

---->   pandas.DataFrame; pandas.Categorical

--------------------------------------
ID: 4450 --> 2
In [257]: cats = pd.Categorical([1, 2, 3, 4], categories=[4, 2, 3, 1])

In [258]: strings = ["a", "b", "c", "d"]

In [259]: values = [4, 2, 3, 1]

In [260]: df = pd.DataFrame({"strings": strings, "values": values}, index=cats)

In [261]: df.index
Out[261]: CategoricalIndex([1, 2, 3, 4], categories=[4, 2, 3, 1], ordered=False, dtype='category')

# This now sorts by the categories order
In [262]: df.sort_index()
Out[262]: 
  strings  values
4       d       1
2       b       2
3       c       3
1       a       4

---->   pandas.Categorical; pandas.DataFrame

--------------------------------------
ID: 4451 --> 2
In [263]: cat = pd.Categorical([1, 2, 3, 10], categories=[1, 2, 3, 4, 10])

In [264]: s = pd.Series(cat, name="cat")

In [265]: cat
Out[265]: 
[1, 2, 3, 10]
Categories (5, int64): [1, 2, 3, 4, 10]

In [266]: s.iloc[0:2] = 10

In [267]: cat
Out[267]: 
[10, 10, 3, 10]
Categories (5, int64): [1, 2, 3, 4, 10]

---->   pandas.Categorical; pandas.Series

--------------------------------------
ID: 4452 --> 2
In [268]: cat = pd.Categorical([1, 2, 3, 10], categories=[1, 2, 3, 4, 10])

In [269]: s = pd.Series(cat, name="cat", copy=True)

In [270]: cat
Out[270]: 
[1, 2, 3, 10]
Categories (5, int64): [1, 2, 3, 4, 10]

In [271]: s.iloc[0:2] = 10

In [272]: cat
Out[272]: 
[1, 2, 3, 10]
Categories (5, int64): [1, 2, 3, 4, 10]

---->   pandas.Categorical; pandas.Series

--------------------------------------
ID: 4453 --> 3
In [1]: ser = pd.Series([-1.5, 0.2, None], dtype="float32[pyarrow]")

In [2]: ser
Out[2]: 
0    -1.5
1     0.2
2    
dtype: float[pyarrow]

In [3]: idx = pd.Index([True, None], dtype="bool[pyarrow]")

In [4]: idx
Out[4]: Index([True, ], dtype='bool[pyarrow]')

In [5]: df = pd.DataFrame([[1, 2], [3, 4]], dtype="uint64[pyarrow]")

In [6]: df
Out[6]: 
   0  1
0  1  2
1  3  4

---->   pandas.Series; pandas.Index; pandas.DataFrame

--------------------------------------
ID: 4454 --> 2
In [7]: import pyarrow as pa

In [8]: data = list("abc")

In [9]: ser_sd = pd.Series(data, dtype="string[pyarrow]")

In [10]: ser_ad = pd.Series(data, dtype=pd.ArrowDtype(pa.string()))

In [11]: ser_ad.dtype == ser_sd.dtype
Out[11]: False

In [12]: ser_sd.str.contains("a")
Out[12]: 
0     True
1    False
2    False
dtype: boolean

In [13]: ser_ad.str.contains("a")
Out[13]: 
0     True
1    False
2    False
dtype: bool[pyarrow]

---->   pandas.Series; pandas.ArrowDtype

--------------------------------------
ID: 4455 --> 2
In [14]: import pyarrow as pa

In [15]: list_str_type = pa.list_(pa.string())

In [16]: ser = pd.Series([["hello"], ["there"]], dtype=pd.ArrowDtype(list_str_type))

In [17]: ser
Out[17]: 
0    ['hello']
1    ['there']
dtype: list[pyarrow]

---->   pandas.Series; pandas.ArrowDtype

--------------------------------------
ID: 4456 --> 2
In [18]: from datetime import time

In [19]: idx = pd.Index([time(12, 30), None], dtype=pd.ArrowDtype(pa.time64("us")))

In [20]: idx
Out[20]: Index([12:30:00, ], dtype='time64[us][pyarrow]')

---->   pandas.Index; pandas.ArrowDtype

--------------------------------------
ID: 4457 --> 2
In [21]: from decimal import Decimal

In [22]: decimal_type = pd.ArrowDtype(pa.decimal128(3, scale=2))

In [23]: data = [[Decimal("3.19"), None], [None, Decimal("-1.23")]]

In [24]: df = pd.DataFrame(data, dtype=decimal_type)

In [25]: df
Out[25]: 
      0      1
0  3.19   
1    -1.23

---->   pandas.ArrowDtype; pandas.DataFrame

--------------------------------------
ID: 4458 --> 1
In [26]: pa_array = pa.array(
   ....:     [{"1": "2"}, {"10": "20"}, None],
   ....:     type=pa.map_(pa.string(), pa.string()),
   ....: )
   ....: 

In [27]: ser = pd.Series(pd.arrays.ArrowExtensionArray(pa_array))

In [28]: ser
Out[28]: 
0      [('1', '2')]
1    [('10', '20')]
2              
dtype: map[pyarrow]

---->   pandas.Series

--------------------------------------
ID: 4459 --> 2
In [29]: ser = pd.Series([1, 2, None], dtype="uint8[pyarrow]")

In [30]: pa.array(ser)
Out[30]: 

[
  1,
  2,
  null
]

In [31]: idx = pd.Index(ser)

In [32]: pa.array(idx)
Out[32]: 

[
  1,
  2,
  null
]

---->   pandas.Series; pandas.Index

--------------------------------------
ID: 4461 --> 3
In [37]: import pyarrow as pa

In [38]: ser = pd.Series([-1.545, 0.211, None], dtype="float32[pyarrow]")

In [39]: ser.mean()
Out[39]: -0.6669999808073044

In [40]: ser + ser
Out[40]: 
0    -3.09
1    0.422
2     
dtype: float[pyarrow]

In [41]: ser > (ser + 1)
Out[41]: 
0    False
1    False
2     
dtype: bool[pyarrow]

In [42]: ser.dropna()
Out[42]: 
0   -1.545
1    0.211
dtype: float[pyarrow]

In [43]: ser.isna()
Out[43]: 
0    False
1    False
2     True
dtype: bool

In [44]: ser.fillna(0)
Out[44]: 
0   -1.545
1    0.211
2    0.000
dtype: float[pyarrow]

---->   pandas.Series; Series.mean; Series.isna

--------------------------------------
ID: 4462 --> 2
In [45]: ser_str = pd.Series(["a", "b", None], dtype=pd.ArrowDtype(pa.string()))

In [46]: ser_str.str.startswith("a")
Out[46]: 
0     True
1    False
2     
dtype: bool[pyarrow]

---->   pandas.Series; pandas.ArrowDtype

--------------------------------------
ID: 4463 --> 2
In [47]: from datetime import datetime

In [48]: pa_type = pd.ArrowDtype(pa.timestamp("ns"))

In [49]: ser_dt = pd.Series([datetime(2022, 1, 1), None], dtype=pa_type)

In [50]: ser_dt.dt.strftime("%Y-%m")
Out[50]: 
0    2022-01
1       
dtype: string[pyarrow]

---->   pandas.ArrowDtype; pandas.Series

--------------------------------------
ID: 4466 --> 1
In [1]: import pandas as pd

In [2]: import numpy as np

In [3]: def make_timeseries(start="2000-01-01", end="2000-12-31", freq="1D", seed=None):
   ...:     index = pd.date_range(start=start, end=end, freq=freq, name="timestamp")
   ...:     n = len(index)
   ...:     state = np.random.RandomState(seed)
   ...:     columns = {
   ...:         "name": state.choice(["Alice", "Bob", "Charlie"], size=n),
   ...:         "id": state.poisson(1000, size=n),
   ...:         "x": state.rand(n) * 2 - 1,
   ...:         "y": state.rand(n) * 2 - 1,
   ...:     }
   ...:     df = pd.DataFrame(columns, index=index, columns=sorted(columns))
   ...:     if df.index[-1] == end:
   ...:         df = df.iloc[:-1]
   ...:     return df
   ...: 

In [4]: timeseries = [
   ...:     make_timeseries(freq="1T", seed=i).rename(columns=lambda x: f"{x}_{i}")
   ...:     for i in range(10)
   ...: ]
   ...: 

In [5]: ts_wide = pd.concat(timeseries, axis=1)

In [6]: ts_wide.to_parquet("timeseries_wide.parquet")

---->   pandas.DataFrame

--------------------------------------
ID: 4467 --> 1
In [7]: columns = ["id_0", "name_0", "x_0", "y_0"]

In [8]: pd.read_parquet("timeseries_wide.parquet")[columns]
Out[8]: 
                     id_0 name_0       x_0       y_0
timestamp                                           
2000-01-01 00:00:00   977  Alice -0.821225  0.906222
2000-01-01 00:01:00  1018    Bob -0.219182  0.350855
2000-01-01 00:02:00   927  Alice  0.660908 -0.798511
2000-01-01 00:03:00   997    Bob -0.852458  0.735260
2000-01-01 00:04:00   965    Bob  0.717283  0.393391
...                   ...    ...       ...       ...
2000-12-30 23:56:00  1037    Bob -0.814321  0.612836
2000-12-30 23:57:00   980    Bob  0.232195 -0.618828
2000-12-30 23:58:00   965  Alice -0.231131  0.026310
2000-12-30 23:59:00   984  Alice  0.942819  0.853128
2000-12-31 00:00:00  1003  Alice  0.201125 -0.136655

[525601 rows x 4 columns]

---->   pandas.read_parquet

--------------------------------------
ID: 4468 --> 1
In [9]: pd.read_parquet("timeseries_wide.parquet", columns=columns)
Out[9]: 
                     id_0 name_0       x_0       y_0
timestamp                                           
2000-01-01 00:00:00   977  Alice -0.821225  0.906222
2000-01-01 00:01:00  1018    Bob -0.219182  0.350855
2000-01-01 00:02:00   927  Alice  0.660908 -0.798511
2000-01-01 00:03:00   997    Bob -0.852458  0.735260
2000-01-01 00:04:00   965    Bob  0.717283  0.393391
...                   ...    ...       ...       ...
2000-12-30 23:56:00  1037    Bob -0.814321  0.612836
2000-12-30 23:57:00   980    Bob  0.232195 -0.618828
2000-12-30 23:58:00   965  Alice -0.231131  0.026310
2000-12-30 23:59:00   984  Alice  0.942819  0.853128
2000-12-31 00:00:00  1003  Alice  0.201125 -0.136655

[525601 rows x 4 columns]

---->   pandas.read_parquet

--------------------------------------
ID: 4469 --> 1
In [10]: ts = make_timeseries(freq="30S", seed=0)

In [11]: ts.to_parquet("timeseries.parquet")

In [12]: ts = pd.read_parquet("timeseries.parquet")

In [13]: ts
Out[13]: 
                       id     name         x         y
timestamp                                             
2000-01-01 00:00:00  1041    Alice  0.889987  0.281011
2000-01-01 00:00:30   988      Bob -0.455299  0.488153
2000-01-01 00:01:00  1018    Alice  0.096061  0.580473
2000-01-01 00:01:30   992      Bob  0.142482  0.041665
2000-01-01 00:02:00   960      Bob -0.036235  0.802159
...                   ...      ...       ...       ...
2000-12-30 23:58:00  1022    Alice  0.266191  0.875579
2000-12-30 23:58:30   974    Alice -0.009826  0.413686
2000-12-30 23:59:00  1028  Charlie  0.307108 -0.656789
2000-12-30 23:59:30  1002    Alice  0.202602  0.541335
2000-12-31 00:00:00   987    Alice  0.200832  0.615972

[1051201 rows x 4 columns]

---->   pandas.read_parquet

--------------------------------------
ID: 4470 --> 1
In [15]: ts.memory_usage(deep=True)  # memory usage in bytes
Out[15]: 
Index     8409608
id        8409608
name     65176434
x         8409608
y         8409608
dtype: int64

---->   Series.memory_usage

--------------------------------------
ID: 4471 --> 2
In [16]: ts2 = ts.copy()

In [17]: ts2["name"] = ts2["name"].astype("category")

In [18]: ts2.memory_usage(deep=True)
Out[18]: 
Index    8409608
id       8409608
name     1051495
x        8409608
y        8409608
dtype: int64

---->   Series.copy; Series.memory_usage

--------------------------------------
ID: 4472 --> 1
In [19]: ts2["id"] = pd.to_numeric(ts2["id"], downcast="unsigned")

In [20]: ts2[["x", "y"]] = ts2[["x", "y"]].apply(pd.to_numeric, downcast="float")

In [21]: ts2.dtypes
Out[21]: 
id        uint16
name    category
x        float32
y        float32
dtype: object

---->   pandas.to_numeric

--------------------------------------
ID: 4473 --> 1
In [22]: ts2.memory_usage(deep=True)
Out[22]: 
Index    8409608
id       2102402
name     1051495
x        4204804
y        4204804
dtype: int64

---->   Series.memory_usage

--------------------------------------
ID: 4474 --> 2
In [23]: reduction = ts2.memory_usage(deep=True).sum() / ts.memory_usage(deep=True).sum()

In [24]: print(f"{reduction:0.2f}")
0.20

---->   Series.memory_usage; Series.memory_usage

--------------------------------------
ID: 4476 --> 2
In [31]: %%time
   ....: files = pathlib.Path("data/timeseries/").glob("ts*.parquet")
   ....: counts = pd.Series(dtype=int)
   ....: for path in files:
   ....:     df = pd.read_parquet(path)
   ....:     counts = counts.add(df["name"].value_counts(), fill_value=0)
   ....: counts.astype(int)
   ....: 
CPU times: user 910 ms, sys: 73 ms, total: 983 ms
Wall time: 771 ms
Out[31]: 
name
Alice      1994645
Bob        1993692
Charlie    1994875
dtype: int64

---->   pandas.Series; pandas.read_parquet

--------------------------------------
ID: 4483 --> 1
In [43]: N = 12

In [44]: starts = [f"20{i:>02d}-01-01" for i in range(N)]

In [45]: ends = [f"20{i:>02d}-12-13" for i in range(N)]

In [46]: divisions = tuple(pd.to_datetime(starts)) + (pd.Timestamp(ends[-1]),)

In [47]: ddf.divisions = divisions

In [48]: ddf
Out[48]: 
Dask DataFrame Structure:
                   id    name        x        y
npartitions=12                                 
2000-01-01      int64  object  float64  float64
2001-01-01        ...     ...      ...      ...
...               ...     ...      ...      ...
2011-01-01        ...     ...      ...      ...
2011-12-13        ...     ...      ...      ...
Dask Name: read-parquet, 1 graph layer

---->   pandas.to_datetime

--------------------------------------
ID: 4486 --> 2
In [1]: arrays = [
   ...:     ["bar", "bar", "baz", "baz", "foo", "foo", "qux", "qux"],
   ...:     ["one", "two", "one", "two", "one", "two", "one", "two"],
   ...: ]
   ...: 

In [2]: tuples = list(zip(*arrays))

In [3]: tuples
Out[3]: 
[('bar', 'one'),
 ('bar', 'two'),
 ('baz', 'one'),
 ('baz', 'two'),
 ('foo', 'one'),
 ('foo', 'two'),
 ('qux', 'one'),
 ('qux', 'two')]

In [4]: index = pd.MultiIndex.from_tuples(tuples, names=["first", "second"])

In [5]: index
Out[5]: 
MultiIndex([('bar', 'one'),
            ('bar', 'two'),
            ('baz', 'one'),
            ('baz', 'two'),
            ('foo', 'one'),
            ('foo', 'two'),
            ('qux', 'one'),
            ('qux', 'two')],
           names=['first', 'second'])

In [6]: s = pd.Series(np.random.randn(8), index=index)

In [7]: s
Out[7]: 
first  second
bar    one       0.469112
       two      -0.282863
baz    one      -1.509059
       two      -1.135632
foo    one       1.212112
       two      -0.173215
qux    one       0.119209
       two      -1.044236
dtype: float64

---->   pandas.MultiIndex; pandas.Series

--------------------------------------
ID: 4487 --> 1
In [8]: iterables = [["bar", "baz", "foo", "qux"], ["one", "two"]]

In [9]: pd.MultiIndex.from_product(iterables, names=["first", "second"])
Out[9]: 
MultiIndex([('bar', 'one'),
            ('bar', 'two'),
            ('baz', 'one'),
            ('baz', 'two'),
            ('foo', 'one'),
            ('foo', 'two'),
            ('qux', 'one'),
            ('qux', 'two')],
           names=['first', 'second'])

---->   pandas.MultiIndex

--------------------------------------
ID: 4488 --> 2
In [10]: df = pd.DataFrame(
   ....:     [["bar", "one"], ["bar", "two"], ["foo", "one"], ["foo", "two"]],
   ....:     columns=["first", "second"],
   ....: )
   ....: 

In [11]: pd.MultiIndex.from_frame(df)
Out[11]: 
MultiIndex([('bar', 'one'),
            ('bar', 'two'),
            ('foo', 'one'),
            ('foo', 'two')],
           names=['first', 'second'])

---->   pandas.DataFrame; pandas.MultiIndex

--------------------------------------
ID: 4489 --> 2
In [12]: arrays = [
   ....:     np.array(["bar", "bar", "baz", "baz", "foo", "foo", "qux", "qux"]),
   ....:     np.array(["one", "two", "one", "two", "one", "two", "one", "two"]),
   ....: ]
   ....: 

In [13]: s = pd.Series(np.random.randn(8), index=arrays)

In [14]: s
Out[14]: 
bar  one   -0.861849
     two   -2.104569
baz  one   -0.494929
     two    1.071804
foo  one    0.721555
     two   -0.706771
qux  one   -1.039575
     two    0.271860
dtype: float64

In [15]: df = pd.DataFrame(np.random.randn(8, 4), index=arrays)

In [16]: df
Out[16]: 
                0         1         2         3
bar one -0.424972  0.567020  0.276232 -1.087401
    two -0.673690  0.113648 -1.478427  0.524988
baz one  0.404705  0.577046 -1.715002 -1.039268
    two -0.370647 -1.157892 -1.344312  0.844885
foo one  1.075770 -0.109050  1.643563 -1.469388
    two  0.357021 -0.674600 -1.776904 -0.968914
qux one -1.294524  0.413738  0.276662 -0.472035
    two -0.013960 -0.362543 -0.006154 -0.923061

---->   pandas.Series; pandas.DataFrame

--------------------------------------
ID: 4491 --> 1
In [18]: df = pd.DataFrame(np.random.randn(3, 8), index=["A", "B", "C"], columns=index)

In [19]: df
Out[19]: 
first        bar                 baz  ...       foo       qux          
second       one       two       one  ...       two       one       two
A       0.895717  0.805244 -1.206412  ...  1.340309 -1.170299 -0.226169
B       0.410835  0.813850  0.132003  ... -1.187678  1.130127 -1.436737
C      -1.413681  1.607920  1.024180  ... -2.211372  0.974466 -2.006747

[3 rows x 8 columns]

In [20]: pd.DataFrame(np.random.randn(6, 6), index=index[:6], columns=index[:6])
Out[20]: 
first              bar                 baz                 foo          
second             one       two       one       two       one       two
first second                                                            
bar   one    -0.410001 -0.078638  0.545952 -1.219217 -1.226825  0.769804
      two    -1.281247 -0.727707 -0.121306 -0.097883  0.695775  0.341734
baz   one     0.959726 -1.110336 -0.619976  0.149748 -0.732339  0.687738
      two     0.176444  0.403310 -0.154951  0.301624 -2.179861 -1.369849
foo   one    -0.954208  1.462696 -1.743161 -0.826591 -0.345352  1.314232
      two     0.690579  0.995761  2.396780  0.014871  3.357427 -0.317441

---->   pandas.DataFrame

--------------------------------------
ID: 4493 --> 1
In [22]: pd.Series(np.random.randn(8), index=tuples)
Out[22]: 
(bar, one)   -1.236269
(bar, two)    0.896171
(baz, one)   -0.487602
(baz, two)   -0.082240
(foo, one)   -2.182937
(foo, two)    0.380396
(qux, one)    0.084844
(qux, two)    0.432390
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 4494 --> 1
In [23]: index.get_level_values(0)
Out[23]: Index(['bar', 'bar', 'baz', 'baz', 'foo', 'foo', 'qux', 'qux'], dtype='object', name='first')

In [24]: index.get_level_values("second")
Out[24]: Index(['one', 'two', 'one', 'two', 'one', 'two', 'one', 'two'], dtype='object', name='second')

---->   Index.get_level_values

--------------------------------------
ID: 4497 --> 1
In [31]: df[["foo", "qux"]].columns.to_numpy()
Out[31]: 
array([('foo', 'one'), ('foo', 'two'), ('qux', 'one'), ('qux', 'two')],
      dtype=object)

# for a specific level
In [32]: df[["foo", "qux"]].columns.get_level_values(0)
Out[32]: Index(['foo', 'foo', 'qux', 'qux'], dtype='object', name='first')

---->   Index.get_level_values

--------------------------------------
ID: 4504 --> 2
In [48]: s = pd.Series(
   ....:     [1, 2, 3, 4, 5, 6],
   ....:     index=pd.MultiIndex.from_product([["A", "B"], ["c", "d", "e"]]),
   ....: )
   ....: 

In [49]: s.loc[[("A", "c"), ("B", "d")]]  # list of tuples
Out[49]: 
A  c    1
B  d    5
dtype: int64

In [50]: s.loc[(["A", "B"], ["c", "d"])]  # tuple of lists
Out[50]: 
A  c    1
   d    2
B  c    4
   d    5
dtype: int64

---->   pandas.Series; pandas.MultiIndex

--------------------------------------
ID: 4507 --> 3
In [51]: def mklbl(prefix, n):
   ....:     return ["%s%s" % (prefix, i) for i in range(n)]
   ....: 

In [52]: miindex = pd.MultiIndex.from_product(
   ....:     [mklbl("A", 4), mklbl("B", 2), mklbl("C", 4), mklbl("D", 2)]
   ....: )
   ....: 

In [53]: micolumns = pd.MultiIndex.from_tuples(
   ....:     [("a", "foo"), ("a", "bar"), ("b", "foo"), ("b", "bah")], names=["lvl0", "lvl1"]
   ....: )
   ....: 

In [54]: dfmi = (
   ....:     pd.DataFrame(
   ....:         np.arange(len(miindex) * len(micolumns)).reshape(
   ....:             (len(miindex), len(micolumns))
   ....:         ),
   ....:         index=miindex,
   ....:         columns=micolumns,
   ....:     )
   ....:     .sort_index()
   ....:     .sort_index(axis=1)
   ....: )
   ....: 

In [55]: dfmi
Out[55]: 
lvl0           a         b     
lvl1         bar  foo  bah  foo
A0 B0 C0 D0    1    0    3    2
         D1    5    4    7    6
      C1 D0    9    8   11   10
         D1   13   12   15   14
      C2 D0   17   16   19   18
...          ...  ...  ...  ...
A3 B1 C1 D1  237  236  239  238
      C2 D0  241  240  243  242
         D1  245  244  247  246
      C3 D0  249  248  251  250
         D1  253  252  255  254

[64 rows x 4 columns]

---->   pandas.MultiIndex; pandas.MultiIndex; pandas.DataFrame

--------------------------------------
ID: 4514 --> 1
In [70]: df
Out[70]: 
                     A         B         C
first second                              
bar   one     0.895717  0.410835 -1.413681
      two     0.805244  0.813850  1.607920
baz   one    -1.206412  0.132003  1.024180
      two     2.565646 -0.827317  0.569605
foo   one     1.431256 -0.076467  0.875906
      two     1.340309 -1.187678 -2.211372
qux   one    -1.170299  1.130127  0.974466
      two    -0.226169 -1.436737 -2.006747

In [71]: df.xs("one", level="second")
Out[71]: 
              A         B         C
first                              
bar    0.895717  0.410835 -1.413681
baz   -1.206412  0.132003  1.024180
foo    1.431256 -0.076467  0.875906
qux   -1.170299  1.130127  0.974466

---->   DataFrame.xs

--------------------------------------
ID: 4516 --> 1
In [73]: df = df.T

In [74]: df.xs("one", level="second", axis=1)
Out[74]: 
first       bar       baz       foo       qux
A      0.895717 -1.206412  1.431256 -1.170299
B      0.410835  0.132003 -0.076467  1.130127
C     -1.413681  1.024180  0.875906  0.974466

---->   DataFrame.xs

--------------------------------------
ID: 4518 --> 1
In [76]: df.xs(("one", "bar"), level=("second", "first"), axis=1)
Out[76]: 
first        bar
second       one
A       0.895717
B       0.410835
C      -1.413681

---->   DataFrame.xs

--------------------------------------
ID: 4520 --> 1
In [78]: df.xs("one", level="second", axis=1, drop_level=False)
Out[78]: 
first        bar       baz       foo       qux
second       one       one       one       one
A       0.895717 -1.206412  1.431256 -1.170299
B       0.410835  0.132003 -0.076467  1.130127
C      -1.413681  1.024180  0.875906  0.974466

---->   DataFrame.xs

--------------------------------------
ID: 4521 --> 1
In [79]: df.xs("one", level="second", axis=1, drop_level=True)
Out[79]: 
first       bar       baz       foo       qux
A      0.895717 -1.206412  1.431256 -1.170299
B      0.410835  0.132003 -0.076467  1.130127
C     -1.413681  1.024180  0.875906  0.974466

---->   DataFrame.xs

--------------------------------------
ID: 4522 --> 4
In [80]: midx = pd.MultiIndex(
   ....:     levels=[["zero", "one"], ["x", "y"]], codes=[[1, 1, 0, 0], [1, 0, 1, 0]]
   ....: )
   ....: 

In [81]: df = pd.DataFrame(np.random.randn(4, 2), index=midx)

In [82]: df
Out[82]: 
               0         1
one  y  1.519970 -0.493662
     x  0.600178  0.274230
zero y  0.132885 -0.023688
     x  2.410179  1.450520

In [83]: df2 = df.groupby(level=0).mean()

In [84]: df2
Out[84]: 
             0         1
one   1.060074 -0.109716
zero  1.271532  0.713416

In [85]: df2.reindex(df.index, level=0)
Out[85]: 
               0         1
one  y  1.060074 -0.109716
     x  1.060074 -0.109716
zero y  1.271532  0.713416
     x  1.271532  0.713416

# aligning
In [86]: df_aligned, df2_aligned = df.align(df2, level=0)

In [87]: df_aligned
Out[87]: 
               0         1
one  y  1.519970 -0.493662
     x  0.600178  0.274230
zero y  0.132885 -0.023688
     x  2.410179  1.450520

In [88]: df2_aligned
Out[88]: 
               0         1
one  y  1.060074 -0.109716
     x  1.060074 -0.109716
zero y  1.271532  0.713416
     x  1.271532  0.713416

---->   pandas.MultiIndex; pandas.DataFrame; DataFrame.groupby; DataFrame.align

--------------------------------------
ID: 4529 --> 1
In [96]: mi = pd.MultiIndex.from_product([[1, 2], ["a", "b"]], names=["x", "y"])

In [97]: mi.names
Out[97]: FrozenList(['x', 'y'])

In [98]: mi2 = mi.rename("new name", level=0)

In [99]: mi2
Out[99]: 
MultiIndex([(1, 'a'),
            (1, 'b'),
            (2, 'a'),
            (2, 'b')],
           names=['new name', 'y'])

---->   pandas.MultiIndex

--------------------------------------
ID: 4531 --> 2
In [101]: import random

In [102]: random.shuffle(tuples)

In [103]: s = pd.Series(np.random.randn(8), index=pd.MultiIndex.from_tuples(tuples))

In [104]: s
Out[104]: 
foo  two    0.206053
bar  two   -0.251905
baz  one   -2.213588
     two    1.063327
qux  one    1.266143
bar  one    0.299368
foo  one   -0.863838
qux  two    0.408204
dtype: float64

In [105]: s.sort_index()
Out[105]: 
bar  one    0.299368
     two   -0.251905
baz  one   -2.213588
     two    1.063327
foo  one   -0.863838
     two    0.206053
qux  one    1.266143
     two    0.408204
dtype: float64

In [106]: s.sort_index(level=0)
Out[106]: 
bar  one    0.299368
     two   -0.251905
baz  one   -2.213588
     two    1.063327
foo  one   -0.863838
     two    0.206053
qux  one    1.266143
     two    0.408204
dtype: float64

In [107]: s.sort_index(level=1)
Out[107]: 
bar  one    0.299368
baz  one   -2.213588
foo  one   -0.863838
qux  one    1.266143
bar  two   -0.251905
baz  two    1.063327
foo  two    0.206053
qux  two    0.408204
dtype: float64

---->   pandas.Series; pandas.MultiIndex

--------------------------------------
ID: 4534 --> 1
In [112]: dfm = pd.DataFrame(
   .....:     {"jim": [0, 0, 1, 1], "joe": ["x", "x", "z", "y"], "jolie": np.random.rand(4)}
   .....: )
   .....: 

In [113]: dfm = dfm.set_index(["jim", "joe"])

In [114]: dfm
Out[114]: 
            jolie
jim joe          
0   x    0.490671
    x    0.120248
1   z    0.537020
    y    0.110968

---->   pandas.DataFrame

--------------------------------------
ID: 4539 --> 4
In [120]: index = pd.Index(np.random.randint(0, 1000, 10))

In [121]: index
Out[121]: Index([214, 502, 712, 567, 786, 175, 993, 133, 758, 329], dtype='int64')

In [122]: positions = [0, 9, 3]

In [123]: index[positions]
Out[123]: Index([214, 329, 567], dtype='int64')

In [124]: index.take(positions)
Out[124]: Index([214, 329, 567], dtype='int64')

In [125]: ser = pd.Series(np.random.randn(10))

In [126]: ser.iloc[positions]
Out[126]: 
0   -0.179666
9    1.824375
3    0.392149
dtype: float64

In [127]: ser.take(positions)
Out[127]: 
0   -0.179666
9    1.824375
3    0.392149
dtype: float64

---->   pandas.Index; Index.take; pandas.Series; Series.take

--------------------------------------
ID: 4540 --> 2
In [128]: frm = pd.DataFrame(np.random.randn(5, 3))

In [129]: frm.take([1, 4, 3])
Out[129]: 
          0         1         2
1 -1.237881  0.106854 -1.276829
4  0.629675 -1.425966  1.857704
3  0.979542 -1.633678  0.615855

In [130]: frm.take([0, 2], axis=1)
Out[130]: 
          0         2
0  0.595974  0.601544
1 -1.237881 -1.276829
2 -0.767101  1.499591
3  0.979542  0.615855
4  0.629675  1.857704

---->   pandas.DataFrame; DataFrame.take

--------------------------------------
ID: 4541 --> 2
In [131]: arr = np.random.randn(10)

In [132]: arr.take([False, False, True, True])
Out[132]: array([-1.1935, -1.1935,  0.6775,  0.6775])

In [133]: arr[[0, 1]]
Out[133]: array([-1.1935,  0.6775])

In [134]: ser = pd.Series(np.random.randn(10))

In [135]: ser.take([False, False, True, True])
Out[135]: 
0    0.233141
0    0.233141
1   -0.223540
1   -0.223540
dtype: float64

In [136]: ser.iloc[[0, 1]]
Out[136]: 
0    0.233141
1   -0.223540
dtype: float64

---->   pandas.Series; Series.take

--------------------------------------
ID: 4543 --> 2
In [141]: ser = pd.Series(arr[:, 0])

In [142]: %timeit ser.iloc[indexer]
   .....: %timeit ser.take(indexer)
   .....: 
77.3 us +- 1.45 us per loop (mean +- std. dev. of 7 runs, 10,000 loops each)
64.1 us +- 155 ns per loop (mean +- std. dev. of 7 runs, 10,000 loops each)

---->   pandas.Series; Series.take

--------------------------------------
ID: 4544 --> 1
In [143]: from pandas.api.types import CategoricalDtype

In [144]: df = pd.DataFrame({"A": np.arange(6), "B": list("aabbca")})

In [145]: df["B"] = df["B"].astype(CategoricalDtype(list("cab")))

In [146]: df
Out[146]: 
   A  B
0  0  a
1  1  a
2  2  b
3  3  b
4  4  c
5  5  a

In [147]: df.dtypes
Out[147]: 
A       int64
B    category
dtype: object

In [148]: df["B"].cat.categories
Out[148]: Index(['c', 'a', 'b'], dtype='object')

---->   pandas.DataFrame

--------------------------------------
ID: 4548 --> 1
In [154]: df2.groupby(level=0).sum()
Out[154]: 
   A
B   
c  4
a  6
b  5

In [155]: df2.groupby(level=0).sum().index
Out[155]: CategoricalIndex(['c', 'a', 'b'], categories=['c', 'a', 'b'], ordered=False, dtype='category', name='B')

---->   DataFrame.groupby

--------------------------------------
ID: 4549 --> 2
In [156]: df3 = pd.DataFrame(
   .....:     {"A": np.arange(3), "B": pd.Series(list("abc")).astype("category")}
   .....: )
   .....: 

In [157]: df3 = df3.set_index("B")

In [158]: df3
Out[158]: 
   A
B   
a  0
b  1
c  2

---->   pandas.DataFrame; pandas.Series

--------------------------------------
ID: 4550 --> 1
In [159]: df3.reindex(["a", "e"])
Out[159]: 
     A
B     
a  0.0
e  NaN

In [160]: df3.reindex(["a", "e"]).index
Out[160]: Index(['a', 'e'], dtype='object', name='B')

In [161]: df3.reindex(pd.Categorical(["a", "e"], categories=list("abe")))
Out[161]: 
     A
B     
a  0.0
e  NaN

In [162]: df3.reindex(pd.Categorical(["a", "e"], categories=list("abe"))).index
Out[162]: CategoricalIndex(['a', 'e'], categories=['a', 'b', 'e'], ordered=False, dtype='category', name='B')

---->   pandas.Categorical

--------------------------------------
ID: 4551 --> 1
In [163]: df4 = pd.DataFrame({"A": np.arange(2), "B": list("ba")})

In [164]: df4["B"] = df4["B"].astype(CategoricalDtype(list("ab")))

In [165]: df4 = df4.set_index("B")

In [166]: df4.index
Out[166]: CategoricalIndex(['b', 'a'], categories=['a', 'b'], ordered=False, dtype='category', name='B')

In [167]: df5 = pd.DataFrame({"A": np.arange(2), "B": list("bc")})

In [168]: df5["B"] = df5["B"].astype(CategoricalDtype(list("bc")))

In [169]: df5 = df5.set_index("B")

In [170]: df5.index
Out[170]: CategoricalIndex(['b', 'c'], categories=['b', 'c'], ordered=False, dtype='category', name='B')

---->   pandas.DataFrame

--------------------------------------
ID: 4553 --> 1
In [171]: idx = pd.RangeIndex(5)

In [172]: idx
Out[172]: RangeIndex(start=0, stop=5, step=1)

---->   pandas.RangeIndex

--------------------------------------
ID: 4554 --> 2
In [173]: ser = pd.Series([1, 2, 3])

In [174]: ser.index
Out[174]: RangeIndex(start=0, stop=3, step=1)

In [175]: df = pd.DataFrame([[1, 2], [3, 4]])

In [176]: df.index
Out[176]: RangeIndex(start=0, stop=2, step=1)

In [177]: df.columns
Out[177]: RangeIndex(start=0, stop=2, step=1)

---->   pandas.Series; pandas.DataFrame

--------------------------------------
ID: 4556 --> 2
In [179]: df = pd.DataFrame(
   .....:     {"A": [1, 2, 3, 4]}, index=pd.IntervalIndex.from_breaks([0, 1, 2, 3, 4])
   .....: )
   .....: 

In [180]: df
Out[180]: 
        A
(0, 1]  1
(1, 2]  2
(2, 3]  3
(3, 4]  4

---->   pandas.DataFrame; pandas.IntervalIndex

--------------------------------------
ID: 4559 --> 1
In [185]: df.loc[pd.Interval(1, 2)]
Out[185]: 
A    2
Name: (1, 2], dtype: int64

---->   pandas.Interval

--------------------------------------
ID: 4560 --> 1
In [7]: df.loc[pd.Interval(0.5, 2.5)]
---------------------------------------------------------------------------
KeyError: Interval(0.5, 2.5, closed='right')

---->   pandas.Interval

--------------------------------------
ID: 4561 --> 1
In [186]: idxr = df.index.overlaps(pd.Interval(0.5, 2.5))

In [187]: idxr
Out[187]: array([ True,  True,  True, False])

In [188]: df[idxr]
Out[188]: 
        A
(0, 1]  1
(1, 2]  2
(2, 3]  3

---->   pandas.Interval

--------------------------------------
ID: 4562 --> 1
In [189]: c = pd.cut(range(4), bins=2)

In [190]: c
Out[190]: 
[(-0.003, 1.5], (-0.003, 1.5], (1.5, 3.0], (1.5, 3.0]]
Categories (2, interval[float64, right]): [(-0.003, 1.5] < (1.5, 3.0]]

In [191]: c.categories
Out[191]: IntervalIndex([(-0.003, 1.5], (1.5, 3.0]], dtype='interval[float64, right]')

---->   pandas.cut

--------------------------------------
ID: 4563 --> 1
In [192]: pd.cut([0, 3, 5, 1], bins=c.categories)
Out[192]: 
[(-0.003, 1.5], (1.5, 3.0], NaN, (-0.003, 1.5]]
Categories (2, interval[float64, right]): [(-0.003, 1.5] < (1.5, 3.0]]

---->   pandas.cut

--------------------------------------
ID: 4564 --> 1
In [193]: pd.interval_range(start=0, end=5)
Out[193]: IntervalIndex([(0, 1], (1, 2], (2, 3], (3, 4], (4, 5]], dtype='interval[int64, right]')

In [194]: pd.interval_range(start=pd.Timestamp("2017-01-01"), periods=4)
Out[194]: IntervalIndex([(2017-01-01, 2017-01-02], (2017-01-02, 2017-01-03], (2017-01-03, 2017-01-04], (2017-01-04, 2017-01-05]], dtype='interval[datetime64[ns], right]')

In [195]: pd.interval_range(end=pd.Timedelta("3 days"), periods=3)
Out[195]: IntervalIndex([(0 days 00:00:00, 1 days 00:00:00], (1 days 00:00:00, 2 days 00:00:00], (2 days 00:00:00, 3 days 00:00:00]], dtype='interval[timedelta64[ns], right]')

---->   pandas.interval_range

--------------------------------------
ID: 4565 --> 1
In [196]: pd.interval_range(start=0, periods=5, freq=1.5)
Out[196]: IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0], (6.0, 7.5]], dtype='interval[float64, right]')

In [197]: pd.interval_range(start=pd.Timestamp("2017-01-01"), periods=4, freq="W")
Out[197]: IntervalIndex([(2017-01-01, 2017-01-08], (2017-01-08, 2017-01-15], (2017-01-15, 2017-01-22], (2017-01-22, 2017-01-29]], dtype='interval[datetime64[ns], right]')

In [198]: pd.interval_range(start=pd.Timedelta("0 days"), periods=3, freq="9H")
Out[198]: IntervalIndex([(0 days 00:00:00, 0 days 09:00:00], (0 days 09:00:00, 0 days 18:00:00], (0 days 18:00:00, 1 days 03:00:00]], dtype='interval[timedelta64[ns], right]')

---->   pandas.interval_range

--------------------------------------
ID: 4566 --> 1
In [199]: pd.interval_range(start=0, end=4, closed="both")
Out[199]: IntervalIndex([[0, 1], [1, 2], [2, 3], [3, 4]], dtype='interval[int64, both]')

In [200]: pd.interval_range(start=0, end=4, closed="neither")
Out[200]: IntervalIndex([(0, 1), (1, 2), (2, 3), (3, 4)], dtype='interval[int64, neither]')

---->   pandas.interval_range

--------------------------------------
ID: 4567 --> 1
In [201]: pd.interval_range(start=0, end=6, periods=4)
Out[201]: IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]], dtype='interval[float64, right]')

In [202]: pd.interval_range(pd.Timestamp("2018-01-01"), pd.Timestamp("2018-02-28"), periods=3)
Out[202]: IntervalIndex([(2018-01-01, 2018-01-20 08:00:00], (2018-01-20 08:00:00, 2018-02-08 16:00:00], (2018-02-08 16:00:00, 2018-02-28]], dtype='interval[datetime64[ns], right]')

---->   pandas.interval_range

--------------------------------------
ID: 4568 --> 2
In [203]: s = pd.Series(range(5))

In [204]: s[-1]
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
File ~/work/pandas/pandas/pandas/core/indexes/range.py:345, in RangeIndex.get_loc(self, key)
    344 try:
--> 345     return self._range.index(new_key)
    346 except ValueError as err:

ValueError: -1 is not in range

The above exception was the direct cause of the following exception:

KeyError                                  Traceback (most recent call last)
Cell In[204], line 1
----> 1 s[-1]

File ~/work/pandas/pandas/pandas/core/series.py:1007, in Series.__getitem__(self, key)
   1004     return self._values[key]
   1006 elif key_is_scalar:
-> 1007     return self._get_value(key)
   1009 if is_hashable(key):
   1010     # Otherwise index.get_value will raise InvalidIndexError
   1011     try:
   1012         # For labels that don't resolve as scalars like tuples and frozensets

File ~/work/pandas/pandas/pandas/core/series.py:1116, in Series._get_value(self, label, takeable)
   1113     return self._values[label]
   1115 # Similar to Index.get_value, but we do not fall back to positional
-> 1116 loc = self.index.get_loc(label)
   1118 if is_integer(loc):
   1119     return self._values[loc]

File ~/work/pandas/pandas/pandas/core/indexes/range.py:347, in RangeIndex.get_loc(self, key)
    345         return self._range.index(new_key)
    346     except ValueError as err:
--> 347         raise KeyError(key) from err
    348 if isinstance(key, Hashable):
    349     raise KeyError(key)

KeyError: -1

In [205]: df = pd.DataFrame(np.random.randn(5, 4))

In [206]: df
Out[206]: 
          0         1         2         3
0 -0.435772 -1.188928 -0.808286 -0.284634
1 -1.815703  1.347213 -0.243487  0.514704
2  1.162969 -0.287725 -0.179734  0.993962
3 -0.212673  0.909872 -0.733333 -0.349893
4  0.456434 -0.306735  0.553396  0.166221

In [207]: df.loc[-2:]
Out[207]: 
          0         1         2         3
0 -0.435772 -1.188928 -0.808286 -0.284634
1 -1.815703  1.347213 -0.243487  0.514704
2  1.162969 -0.287725 -0.179734  0.993962
3 -0.212673  0.909872 -0.733333 -0.349893
4  0.456434 -0.306735  0.553396  0.166221

---->   pandas.Series; pandas.DataFrame

--------------------------------------
ID: 4569 --> 1
In [208]: df = pd.DataFrame(index=[2, 3, 3, 4, 5], columns=["data"], data=list(range(5)))

In [209]: df.index.is_monotonic_increasing
Out[209]: True

# no rows 0 or 1, but still returns rows 2, 3 (both of them), and 4:
In [210]: df.loc[0:4, :]
Out[210]: 
   data
2     0
3     1
3     2
4     3

# slice is are outside the index, so empty DataFrame is returned
In [211]: df.loc[13:15, :]
Out[211]: 
Empty DataFrame
Columns: [data]
Index: []

---->   pandas.DataFrame

--------------------------------------
ID: 4570 --> 1
In [212]: df = pd.DataFrame(index=[2, 3, 1, 4, 3, 5], columns=["data"], data=list(range(6)))

In [213]: df.index.is_monotonic_increasing
Out[213]: False

# OK because 2 and 4 are in the index
In [214]: df.loc[2:4, :]
Out[214]: 
   data
2     0
3     1
1     2
4     3

---->   pandas.DataFrame

--------------------------------------
ID: 4571 --> 1
In [215]: weakly_monotonic = pd.Index(["a", "b", "c", "c"])

In [216]: weakly_monotonic
Out[216]: Index(['a', 'b', 'c', 'c'], dtype='object')

In [217]: weakly_monotonic.is_monotonic_increasing
Out[217]: True

In [218]: weakly_monotonic.is_monotonic_increasing & weakly_monotonic.is_unique
Out[218]: False

---->   pandas.Index

--------------------------------------
ID: 4572 --> 1
In [219]: s = pd.Series(np.random.randn(6), index=list("abcdef"))

In [220]: s
Out[220]: 
a   -0.101684
b   -0.734907
c   -0.130121
d   -0.476046
e    0.759104
f    0.213379
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 4573 --> 1
In [223]: series1 = pd.Series([1, 2, 3])

In [224]: series1.dtype
Out[224]: dtype('int64')

In [225]: res = series1.reindex([0, 4])

In [226]: res.dtype
Out[226]: dtype('float64')

In [227]: res
Out[227]: 
0    1.0
4    NaN
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 4574 --> 2
In [228]: series2 = pd.Series([True])

In [229]: series2.dtype
Out[229]: dtype('bool')

In [230]: res = series2.reindex_like(series1)

In [231]: res.dtype
Out[231]: dtype('O')

In [232]: res
Out[232]: 
0    True
1     NaN
2     NaN
dtype: object

---->   pandas.Series; Series.reindex_like

--------------------------------------
ID: 4575 --> 1
In [1]: df = pd.DataFrame(
   ...:     {"AAA": [4, 5, 6, 7], "BBB": [10, 20, 30, 40], "CCC": [100, 50, -30, -50]}
   ...: )
   ...: 

In [2]: df
Out[2]: 
   AAA  BBB  CCC
0    4   10  100
1    5   20   50
2    6   30  -30
3    7   40  -50

---->   pandas.DataFrame

--------------------------------------
ID: 4576 --> 1
In [9]: df_mask = pd.DataFrame(
   ...:     {"AAA": [True] * 4, "BBB": [False] * 4, "CCC": [True, False] * 2}
   ...: )
   ...: 

In [10]: df.where(df_mask, -1000)
Out[10]: 
   AAA   BBB   CCC
0    4 -1000  2000
1    5 -1000 -1000
2    6 -1000   555
3    7 -1000 -1000

---->   pandas.DataFrame

--------------------------------------
ID: 4577 --> 1
In [11]: df = pd.DataFrame(
   ....:     {"AAA": [4, 5, 6, 7], "BBB": [10, 20, 30, 40], "CCC": [100, 50, -30, -50]}
   ....: )
   ....: 

In [12]: df
Out[12]: 
   AAA  BBB  CCC
0    4   10  100
1    5   20   50
2    6   30  -30
3    7   40  -50

In [13]: df["logic"] = np.where(df["AAA"] > 5, "high", "low")

In [14]: df
Out[14]: 
   AAA  BBB  CCC logic
0    4   10  100   low
1    5   20   50   low
2    6   30  -30  high
3    7   40  -50  high

---->   pandas.DataFrame

--------------------------------------
ID: 4578 --> 1
In [15]: df = pd.DataFrame(
   ....:     {"AAA": [4, 5, 6, 7], "BBB": [10, 20, 30, 40], "CCC": [100, 50, -30, -50]}
   ....: )
   ....: 

In [16]: df
Out[16]: 
   AAA  BBB  CCC
0    4   10  100
1    5   20   50
2    6   30  -30
3    7   40  -50

In [17]: df[df.AAA <= 5]
Out[17]: 
   AAA  BBB  CCC
0    4   10  100
1    5   20   50

In [18]: df[df.AAA > 5]
Out[18]: 
   AAA  BBB  CCC
2    6   30  -30
3    7   40  -50

---->   pandas.DataFrame

--------------------------------------
ID: 4579 --> 1
In [19]: df = pd.DataFrame(
   ....:     {"AAA": [4, 5, 6, 7], "BBB": [10, 20, 30, 40], "CCC": [100, 50, -30, -50]}
   ....: )
   ....: 

In [20]: df
Out[20]: 
   AAA  BBB  CCC
0    4   10  100
1    5   20   50
2    6   30  -30
3    7   40  -50

---->   pandas.DataFrame

--------------------------------------
ID: 4583 --> 1
In [25]: df = pd.DataFrame(
   ....:     {"AAA": [4, 5, 6, 7], "BBB": [10, 20, 30, 40], "CCC": [100, 50, -30, -50]}
   ....: )
   ....: 

In [26]: df
Out[26]: 
   AAA  BBB  CCC
0    4   10  100
1    5   20   50
2    6   30  -30
3    7   40  -50

In [27]: aValue = 43.0

In [28]: df.loc[(df.CCC - aValue).abs().argsort()]
Out[28]: 
   AAA  BBB  CCC
1    5   20   50
0    4   10  100
2    6   30  -30
3    7   40  -50

---->   pandas.DataFrame

--------------------------------------
ID: 4584 --> 1
In [29]: df = pd.DataFrame(
   ....:     {"AAA": [4, 5, 6, 7], "BBB": [10, 20, 30, 40], "CCC": [100, 50, -30, -50]}
   ....: )
   ....: 

In [30]: df
Out[30]: 
   AAA  BBB  CCC
0    4   10  100
1    5   20   50
2    6   30  -30
3    7   40  -50

In [31]: Crit1 = df.AAA <= 5.5

In [32]: Crit2 = df.BBB == 10.0

In [33]: Crit3 = df.CCC > -40.0

---->   pandas.DataFrame

--------------------------------------
ID: 4586 --> 1
In [39]: df = pd.DataFrame(
   ....:     {"AAA": [4, 5, 6, 7], "BBB": [10, 20, 30, 40], "CCC": [100, 50, -30, -50]}
   ....: )
   ....: 

In [40]: df
Out[40]: 
   AAA  BBB  CCC
0    4   10  100
1    5   20   50
2    6   30  -30
3    7   40  -50

In [41]: df[(df.AAA <= 6) & (df.index.isin([0, 2, 4]))]
Out[41]: 
   AAA  BBB  CCC
0    4   10  100
2    6   30  -30

---->   pandas.DataFrame

--------------------------------------
ID: 4587 --> 1
In [42]: df = pd.DataFrame(
   ....:     {"AAA": [4, 5, 6, 7], "BBB": [10, 20, 30, 40], "CCC": [100, 50, -30, -50]},
   ....:     index=["foo", "bar", "boo", "kar"],
   ....: )
   ....: 

---->   pandas.DataFrame

--------------------------------------
ID: 4588 --> 1
In [46]: data = {"AAA": [4, 5, 6, 7], "BBB": [10, 20, 30, 40], "CCC": [100, 50, -30, -50]}

In [47]: df2 = pd.DataFrame(data=data, index=[1, 2, 3, 4])  # Note index starts at 1.

In [48]: df2.iloc[1:3]  # Position-oriented
Out[48]: 
   AAA  BBB  CCC
2    5   20   50
3    6   30  -30

In [49]: df2.loc[1:3]  # Label-oriented
Out[49]: 
   AAA  BBB  CCC
1    4   10  100
2    5   20   50
3    6   30  -30

---->   pandas.DataFrame

--------------------------------------
ID: 4589 --> 1
In [50]: df = pd.DataFrame(
   ....:     {"AAA": [4, 5, 6, 7], "BBB": [10, 20, 30, 40], "CCC": [100, 50, -30, -50]}
   ....: )
   ....: 

In [51]: df
Out[51]: 
   AAA  BBB  CCC
0    4   10  100
1    5   20   50
2    6   30  -30
3    7   40  -50

In [52]: df[~((df.AAA <= 6) & (df.index.isin([0, 2, 4])))]
Out[52]: 
   AAA  BBB  CCC
1    5   20   50
3    7   40  -50

---->   pandas.DataFrame

--------------------------------------
ID: 4590 --> 1
In [53]: df = pd.DataFrame({"AAA": [1, 2, 1, 3], "BBB": [1, 1, 2, 2], "CCC": [2, 1, 3, 1]})

In [54]: df
Out[54]: 
   AAA  BBB  CCC
0    1    1    2
1    2    1    1
2    1    2    3
3    3    2    1

In [55]: source_cols = df.columns  # Or some subset would work too

In [56]: new_cols = [str(x) + "_cat" for x in source_cols]

In [57]: categories = {1: "Alpha", 2: "Beta", 3: "Charlie"}

In [58]: df[new_cols] = df[source_cols].applymap(categories.get)

In [59]: df
Out[59]: 
   AAA  BBB  CCC  AAA_cat BBB_cat  CCC_cat
0    1    1    2    Alpha   Alpha     Beta
1    2    1    1     Beta   Alpha    Alpha
2    1    2    3    Alpha    Beta  Charlie
3    3    2    1  Charlie    Beta    Alpha

---->   pandas.DataFrame

--------------------------------------
ID: 4591 --> 1
In [60]: df = pd.DataFrame(
   ....:     {"AAA": [1, 1, 1, 2, 2, 2, 3, 3], "BBB": [2, 1, 3, 4, 5, 1, 2, 3]}
   ....: )
   ....: 

In [61]: df
Out[61]: 
   AAA  BBB
0    1    2
1    1    1
2    1    3
3    2    4
4    2    5
5    2    1
6    3    2
7    3    3

---->   pandas.DataFrame

--------------------------------------
ID: 4592 --> 1
In [62]: df.loc[df.groupby("AAA")["BBB"].idxmin()]
Out[62]: 
   AAA  BBB
1    1    1
5    2    1
6    3    2

---->   DataFrame.groupby

--------------------------------------
ID: 4594 --> 3
In [64]: df = pd.DataFrame(
   ....:     {
   ....:         "row": [0, 1, 2],
   ....:         "One_X": [1.1, 1.1, 1.1],
   ....:         "One_Y": [1.2, 1.2, 1.2],
   ....:         "Two_X": [1.11, 1.11, 1.11],
   ....:         "Two_Y": [1.22, 1.22, 1.22],
   ....:     }
   ....: )
   ....: 

In [65]: df
Out[65]: 
   row  One_X  One_Y  Two_X  Two_Y
0    0    1.1    1.2   1.11   1.22
1    1    1.1    1.2   1.11   1.22
2    2    1.1    1.2   1.11   1.22

# As Labelled Index
In [66]: df = df.set_index("row")

In [67]: df
Out[67]: 
     One_X  One_Y  Two_X  Two_Y
row                            
0      1.1    1.2   1.11   1.22
1      1.1    1.2   1.11   1.22
2      1.1    1.2   1.11   1.22

# With Hierarchical Columns
In [68]: df.columns = pd.MultiIndex.from_tuples([tuple(c.split("_")) for c in df.columns])

In [69]: df
Out[69]: 
     One        Two      
       X    Y     X     Y
row                      
0    1.1  1.2  1.11  1.22
1    1.1  1.2  1.11  1.22
2    1.1  1.2  1.11  1.22

# Now stack & Reset
In [70]: df = df.stack(0).reset_index(1)

In [71]: df
Out[71]: 
    level_1     X     Y
row                    
0       One  1.10  1.20
0       Two  1.11  1.22
1       One  1.10  1.20
1       Two  1.11  1.22
2       One  1.10  1.20
2       Two  1.11  1.22

# And fix the labels (Notice the label 'level_1' got added automatically)
In [72]: df.columns = ["Sample", "All_X", "All_Y"]

In [73]: df
Out[73]: 
    Sample  All_X  All_Y
row                     
0      One   1.10   1.20
0      Two   1.11   1.22
1      One   1.10   1.20
1      Two   1.11   1.22
2      One   1.10   1.20
2      Two   1.11   1.22

---->   pandas.DataFrame; pandas.MultiIndex; DataFrame.stack

--------------------------------------
ID: 4595 --> 3
In [74]: cols = pd.MultiIndex.from_tuples(
   ....:     [(x, y) for x in ["A", "B", "C"] for y in ["O", "I"]]
   ....: )
   ....: 

In [75]: df = pd.DataFrame(np.random.randn(2, 6), index=["n", "m"], columns=cols)

In [76]: df
Out[76]: 
          A                   B                   C          
          O         I         O         I         O         I
n  0.469112 -0.282863 -1.509059 -1.135632  1.212112 -0.173215
m  0.119209 -1.044236 -0.861849 -2.104569 -0.494929  1.071804

In [77]: df = df.div(df["C"], level=1)

In [78]: df
Out[78]: 
          A                   B              C     
          O         I         O         I    O    I
n  0.387021  1.633022 -1.244983  6.556214  1.0  1.0
m -0.240860 -0.974279  1.741358 -1.963577  1.0  1.0

---->   pandas.MultiIndex; pandas.DataFrame; DataFrame.div

--------------------------------------
ID: 4596 --> 2
In [79]: coords = [("AA", "one"), ("AA", "six"), ("BB", "one"), ("BB", "two"), ("BB", "six")]

In [80]: index = pd.MultiIndex.from_tuples(coords)

In [81]: df = pd.DataFrame([11, 22, 33, 44, 55], index, ["MyData"])

In [82]: df
Out[82]: 
        MyData
AA one      11
   six      22
BB one      33
   two      44
   six      55

---->   pandas.MultiIndex; pandas.DataFrame

--------------------------------------
ID: 4597 --> 1
# Note : level and axis are optional, and default to zero
In [83]: df.xs("BB", level=0, axis=0)
Out[83]: 
     MyData
one      33
two      44
six      55

---->   DataFrame.xs

--------------------------------------
ID: 4598 --> 1
In [84]: df.xs("six", level=1, axis=0)
Out[84]: 
    MyData
AA      22
BB      55

---->   DataFrame.xs

--------------------------------------
ID: 4599 --> 2
In [85]: import itertools

In [86]: index = list(itertools.product(["Ada", "Quinn", "Violet"], ["Comp", "Math", "Sci"]))

In [87]: headr = list(itertools.product(["Exams", "Labs"], ["I", "II"]))

In [88]: indx = pd.MultiIndex.from_tuples(index, names=["Student", "Course"])

In [89]: cols = pd.MultiIndex.from_tuples(headr)  # Notice these are un-named

In [90]: data = [[70 + x + y + (x * y) % 3 for x in range(4)] for y in range(9)]

In [91]: df = pd.DataFrame(data, indx, cols)

In [92]: df
Out[92]: 
               Exams     Labs    
                   I  II    I  II
Student Course                   
Ada     Comp      70  71   72  73
        Math      71  73   75  74
        Sci       72  75   75  75
Quinn   Comp      73  74   75  76
        Math      74  76   78  77
        Sci       75  78   78  78
Violet  Comp      76  77   78  79
        Math      77  79   81  80
        Sci       78  81   81  81

In [93]: All = slice(None)

In [94]: df.loc["Violet"]
Out[94]: 
       Exams     Labs    
           I  II    I  II
Course                   
Comp      76  77   78  79
Math      77  79   81  80
Sci       78  81   81  81

In [95]: df.loc[(All, "Math"), All]
Out[95]: 
               Exams     Labs    
                   I  II    I  II
Student Course                   
Ada     Math      71  73   75  74
Quinn   Math      74  76   78  77
Violet  Math      77  79   81  80

In [96]: df.loc[(slice("Ada", "Quinn"), "Math"), All]
Out[96]: 
               Exams     Labs    
                   I  II    I  II
Student Course                   
Ada     Math      71  73   75  74
Quinn   Math      74  76   78  77

In [97]: df.loc[(All, "Math"), ("Exams")]
Out[97]: 
                 I  II
Student Course        
Ada     Math    71  73
Quinn   Math    74  76
Violet  Math    77  79

In [98]: df.loc[(All, "Math"), (All, "II")]
Out[98]: 
               Exams Labs
                  II   II
Student Course           
Ada     Math      73   74
Quinn   Math      76   77
Violet  Math      79   80

---->   pandas.MultiIndex; pandas.DataFrame

--------------------------------------
ID: 4601 --> 1
In [100]: df = pd.DataFrame(
   .....:     np.random.randn(6, 1),
   .....:     index=pd.date_range("2013-08-01", periods=6, freq="B"),
   .....:     columns=list("A"),
   .....: )
   .....: 

In [101]: df.loc[df.index[3], "A"] = np.nan

In [102]: df
Out[102]: 
                   A
2013-08-01  0.721555
2013-08-02 -0.706771
2013-08-05 -1.039575
2013-08-06       NaN
2013-08-07 -0.424972
2013-08-08  0.567020

In [103]: df.bfill()
Out[103]: 
                   A
2013-08-01  0.721555
2013-08-02 -0.706771
2013-08-05 -1.039575
2013-08-06 -0.424972
2013-08-07 -0.424972
2013-08-08  0.567020

---->   pandas.DataFrame

--------------------------------------
ID: 4602 --> 2
In [104]: df = pd.DataFrame(
   .....:     {
   .....:         "animal": "cat dog cat fish dog cat cat".split(),
   .....:         "size": list("SSMMMLL"),
   .....:         "weight": [8, 10, 11, 1, 20, 12, 12],
   .....:         "adult": [False] * 5 + [True] * 2,
   .....:     }
   .....: )
   .....: 

In [105]: df
Out[105]: 
  animal size  weight  adult
0    cat    S       8  False
1    dog    S      10  False
2    cat    M      11  False
3   fish    M       1  False
4    dog    M      20  False
5    cat    L      12   True
6    cat    L      12   True

# List the size of the animals with the highest weight.
In [106]: df.groupby("animal").apply(lambda subf: subf["size"][subf["weight"].idxmax()])
Out[106]: 
animal
cat     L
dog     M
fish    M
dtype: object

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 4603 --> 1
In [107]: gb = df.groupby(["animal"])

In [108]: gb.get_group("cat")
Out[108]: 
  animal size  weight  adult
0    cat    S       8  False
2    cat    M      11  False
5    cat    L      12   True
6    cat    L      12   True

---->   DataFrame.groupby

--------------------------------------
ID: 4604 --> 1
In [109]: def GrowUp(x):
   .....:     avg_weight = sum(x[x["size"] == "S"].weight * 1.5)
   .....:     avg_weight += sum(x[x["size"] == "M"].weight * 1.25)
   .....:     avg_weight += sum(x[x["size"] == "L"].weight)
   .....:     avg_weight /= len(x)
   .....:     return pd.Series(["L", avg_weight, True], index=["size", "weight", "adult"])
   .....: 

In [110]: expected_df = gb.apply(GrowUp)

In [111]: expected_df
Out[111]: 
       size   weight  adult
animal                     
cat       L  12.4375   True
dog       L  20.0000   True
fish      L   1.2500   True

---->   pandas.Series

--------------------------------------
ID: 4605 --> 2
In [112]: S = pd.Series([i / 100.0 for i in range(1, 11)])

In [113]: def cum_ret(x, y):
   .....:     return x * (1 + y)
   .....: 

In [114]: def red(x):
   .....:     return functools.reduce(cum_ret, x, 1.0)
   .....: 

In [115]: S.expanding().apply(red, raw=True)
Out[115]: 
0    1.010000
1    1.030200
2    1.061106
3    1.103550
4    1.158728
5    1.228251
6    1.314229
7    1.419367
8    1.547110
9    1.701821
dtype: float64

---->   pandas.Series; Series.expanding

--------------------------------------
ID: 4606 --> 2
In [116]: df = pd.DataFrame({"A": [1, 1, 2, 2], "B": [1, -1, 1, 2]})

In [117]: gb = df.groupby("A")

In [118]: def replace(g):
   .....:     mask = g < 0
   .....:     return g.where(~mask, g[~mask].mean())
   .....: 

In [119]: gb.transform(replace)
Out[119]: 
   B
0  1
1  1
2  1
3  2

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 4607 --> 2
In [120]: df = pd.DataFrame(
   .....:     {
   .....:         "code": ["foo", "bar", "baz"] * 2,
   .....:         "data": [0.16, -0.21, 0.33, 0.45, -0.59, 0.62],
   .....:         "flag": [False, True] * 3,
   .....:     }
   .....: )
   .....: 

In [121]: code_groups = df.groupby("code")

In [122]: agg_n_sort_order = code_groups[["data"]].transform(sum).sort_values(by="data")

In [123]: sorted_df = df.loc[agg_n_sort_order.index]

In [124]: sorted_df
Out[124]: 
  code  data   flag
1  bar -0.21   True
4  bar -0.59  False
0  foo  0.16  False
3  foo  0.45   True
2  baz  0.33  False
5  baz  0.62   True

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 4608 --> 2
In [125]: rng = pd.date_range(start="2014-10-07", periods=10, freq="2min")

In [126]: ts = pd.Series(data=list(range(10)), index=rng)

In [127]: def MyCust(x):
   .....:     if len(x) > 2:
   .....:         return x[1] * 1.234
   .....:     return pd.NaT
   .....: 

In [128]: mhc = {"Mean": np.mean, "Max": np.max, "Custom": MyCust}

In [129]: ts.resample("5min").apply(mhc)
Out[129]: 
                     Mean  Max Custom
2014-10-07 00:00:00   1.0    2  1.234
2014-10-07 00:05:00   3.5    4    NaT
2014-10-07 00:10:00   6.0    7  7.404
2014-10-07 00:15:00   8.5    9    NaT

In [130]: ts
Out[130]: 
2014-10-07 00:00:00    0
2014-10-07 00:02:00    1
2014-10-07 00:04:00    2
2014-10-07 00:06:00    3
2014-10-07 00:08:00    4
2014-10-07 00:10:00    5
2014-10-07 00:12:00    6
2014-10-07 00:14:00    7
2014-10-07 00:16:00    8
2014-10-07 00:18:00    9
Freq: 2T, dtype: int64

---->   pandas.Series; Series.resample

--------------------------------------
ID: 4609 --> 2
In [131]: df = pd.DataFrame(
   .....:     {"Color": "Red Red Red Blue".split(), "Value": [100, 150, 50, 50]}
   .....: )
   .....: 

In [132]: df
Out[132]: 
  Color  Value
0   Red    100
1   Red    150
2   Red     50
3  Blue     50

In [133]: df["Counts"] = df.groupby(["Color"]).transform(len)

In [134]: df
Out[134]: 
  Color  Value  Counts
0   Red    100       3
1   Red    150       3
2   Red     50       3
3  Blue     50       1

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 4610 --> 2
In [135]: df = pd.DataFrame(
   .....:     {"line_race": [10, 10, 8, 10, 10, 8], "beyer": [99, 102, 103, 103, 88, 100]},
   .....:     index=[
   .....:         "Last Gunfighter",
   .....:         "Last Gunfighter",
   .....:         "Last Gunfighter",
   .....:         "Paynter",
   .....:         "Paynter",
   .....:         "Paynter",
   .....:     ],
   .....: )
   .....: 

In [136]: df
Out[136]: 
                 line_race  beyer
Last Gunfighter         10     99
Last Gunfighter         10    102
Last Gunfighter          8    103
Paynter                 10    103
Paynter                 10     88
Paynter                  8    100

In [137]: df["beyer_shifted"] = df.groupby(level=0)["beyer"].shift(1)

In [138]: df
Out[138]: 
                 line_race  beyer  beyer_shifted
Last Gunfighter         10     99            NaN
Last Gunfighter         10    102           99.0
Last Gunfighter          8    103          102.0
Paynter                 10    103            NaN
Paynter                 10     88          103.0
Paynter                  8    100           88.0

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 4611 --> 2
In [139]: df = pd.DataFrame(
   .....:     {
   .....:         "host": ["other", "other", "that", "this", "this"],
   .....:         "service": ["mail", "web", "mail", "mail", "web"],
   .....:         "no": [1, 2, 1, 2, 1],
   .....:     }
   .....: ).set_index(["host", "service"])
   .....: 

In [140]: mask = df.groupby(level=0).agg("idxmax")

In [141]: df_count = df.loc[mask["no"]].reset_index()

In [142]: df_count
Out[142]: 
    host service  no
0  other     web   2
1   that    mail   1
2   this    mail   2

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 4612 --> 1
In [143]: df = pd.DataFrame([0, 1, 0, 1, 1, 1, 0, 1, 1], columns=["A"])

In [144]: df["A"].groupby((df["A"] != df["A"].shift()).cumsum()).groups
Out[144]: {1: [0], 2: [1], 3: [2], 4: [3, 4, 5], 5: [6], 6: [7, 8]}

In [145]: df["A"].groupby((df["A"] != df["A"].shift()).cumsum()).cumsum()
Out[145]: 
0    0
1    1
2    0
3    1
4    2
5    3
6    0
7    1
8    2
Name: A, dtype: int64

---->   pandas.DataFrame

--------------------------------------
ID: 4613 --> 2
In [146]: df = pd.DataFrame(
   .....:     data={
   .....:         "Case": ["A", "A", "A", "B", "A", "A", "B", "A", "A"],
   .....:         "Data": np.random.randn(9),
   .....:     }
   .....: )
   .....: 

In [147]: dfs = list(
   .....:     zip(
   .....:         *df.groupby(
   .....:             (1 * (df["Case"] == "B"))
   .....:             .cumsum()
   .....:             .rolling(window=3, min_periods=1)
   .....:             .median()
   .....:         )
   .....:     )
   .....: )[-1]
   .....: 

In [148]: dfs[0]
Out[148]: 
  Case      Data
0    A  0.276232
1    A -1.087401
2    A -0.673690
3    B  0.113648

In [149]: dfs[1]
Out[149]: 
  Case      Data
4    A -1.478427
5    A  0.524988
6    B  0.404705

In [150]: dfs[2]
Out[150]: 
  Case      Data
7    A  0.577046
8    A -1.715002

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 4614 --> 2
In [151]: df = pd.DataFrame(
   .....:     data={
   .....:         "Province": ["ON", "QC", "BC", "AL", "AL", "MN", "ON"],
   .....:         "City": [
   .....:             "Toronto",
   .....:             "Montreal",
   .....:             "Vancouver",
   .....:             "Calgary",
   .....:             "Edmonton",
   .....:             "Winnipeg",
   .....:             "Windsor",
   .....:         ],
   .....:         "Sales": [13, 6, 16, 8, 4, 3, 1],
   .....:     }
   .....: )
   .....: 

In [152]: table = pd.pivot_table(
   .....:     df,
   .....:     values=["Sales"],
   .....:     index=["Province"],
   .....:     columns=["City"],
   .....:     aggfunc=np.sum,
   .....:     margins=True,
   .....: )
   .....: 

In [153]: table.stack("City")
Out[153]: 
                    Sales
Province City            
AL       All         12.0
         Calgary      8.0
         Edmonton     4.0
BC       All         16.0
         Vancouver   16.0
...                   ...
All      Montreal     6.0
         Toronto     13.0
         Vancouver   16.0
         Windsor      1.0
         Winnipeg     3.0

[20 rows x 1 columns]

---->   pandas.DataFrame; pandas.pivot_table

--------------------------------------
ID: 4615 --> 3
In [154]: grades = [48, 99, 75, 80, 42, 80, 72, 68, 36, 78]

In [155]: df = pd.DataFrame(
   .....:     {
   .....:         "ID": ["x%d" % r for r in range(10)],
   .....:         "Gender": ["F", "M", "F", "M", "F", "M", "F", "M", "M", "M"],
   .....:         "ExamYear": [
   .....:             "2007",
   .....:             "2007",
   .....:             "2007",
   .....:             "2008",
   .....:             "2008",
   .....:             "2008",
   .....:             "2008",
   .....:             "2009",
   .....:             "2009",
   .....:             "2009",
   .....:         ],
   .....:         "Class": [
   .....:             "algebra",
   .....:             "stats",
   .....:             "bio",
   .....:             "algebra",
   .....:             "algebra",
   .....:             "stats",
   .....:             "stats",
   .....:             "algebra",
   .....:             "bio",
   .....:             "bio",
   .....:         ],
   .....:         "Participated": [
   .....:             "yes",
   .....:             "yes",
   .....:             "yes",
   .....:             "yes",
   .....:             "no",
   .....:             "yes",
   .....:             "yes",
   .....:             "yes",
   .....:             "yes",
   .....:             "yes",
   .....:         ],
   .....:         "Passed": ["yes" if x > 50 else "no" for x in grades],
   .....:         "Employed": [
   .....:             True,
   .....:             True,
   .....:             True,
   .....:             False,
   .....:             False,
   .....:             False,
   .....:             False,
   .....:             True,
   .....:             True,
   .....:             False,
   .....:         ],
   .....:         "Grade": grades,
   .....:     }
   .....: )
   .....: 

In [156]: df.groupby("ExamYear").agg(
   .....:     {
   .....:         "Participated": lambda x: x.value_counts()["yes"],
   .....:         "Passed": lambda x: sum(x == "yes"),
   .....:         "Employed": lambda x: sum(x),
   .....:         "Grade": lambda x: sum(x) / len(x),
   .....:     }
   .....: )
   .....: 
Out[156]: 
          Participated  Passed  Employed      Grade
ExamYear                                           
2007                 3       2         3  74.000000
2008                 3       3         0  68.500000
2009                 3       2         2  60.666667

---->   pandas.DataFrame; DataFrame.groupby; Series.value_counts

--------------------------------------
ID: 4616 --> 2
In [157]: df = pd.DataFrame(
   .....:     {"value": np.random.randn(36)},
   .....:     index=pd.date_range("2011-01-01", freq="M", periods=36),
   .....: )
   .....: 

In [158]: pd.pivot_table(
   .....:     df, index=df.index.month, columns=df.index.year, values="value", aggfunc="sum"
   .....: )
   .....: 
Out[158]: 
        2011      2012      2013
1  -1.039268 -0.968914  2.565646
2  -0.370647 -1.294524  1.431256
3  -1.157892  0.413738  1.340309
4  -1.344312  0.276662 -1.170299
5   0.844885 -0.472035 -0.226169
6   1.075770 -0.013960  0.410835
7  -0.109050 -0.362543  0.813850
8   1.643563 -0.006154  0.132003
9  -1.469388 -0.923061 -0.827317
10  0.357021  0.895717 -0.076467
11 -0.674600  0.805244 -1.187678
12 -1.776904 -1.206412  1.130127

---->   pandas.DataFrame; pandas.pivot_table

--------------------------------------
ID: 4617 --> 3
In [159]: df = pd.DataFrame(
   .....:     data={
   .....:         "A": [[2, 4, 8, 16], [100, 200], [10, 20, 30]],
   .....:         "B": [["a", "b", "c"], ["jj", "kk"], ["ccc"]],
   .....:     },
   .....:     index=["I", "II", "III"],
   .....: )
   .....: 

In [160]: def SeriesFromSubList(aList):
   .....:     return pd.Series(aList)
   .....: 

In [161]: df_orgz = pd.concat(
   .....:     {ind: row.apply(SeriesFromSubList) for ind, row in df.iterrows()}
   .....: )
   .....: 

In [162]: df_orgz
Out[162]: 
         0     1     2     3
I   A    2     4     8  16.0
    B    a     b     c   NaN
II  A  100   200   NaN   NaN
    B   jj    kk   NaN   NaN
III A   10  20.0  30.0   NaN
    B  ccc   NaN   NaN   NaN

---->   pandas.DataFrame; pandas.Series; DataFrame.iterrows

--------------------------------------
ID: 4618 --> 2
In [163]: df = pd.DataFrame(
   .....:     data=np.random.randn(2000, 2) / 10000,
   .....:     index=pd.date_range("2001-01-01", periods=2000),
   .....:     columns=["A", "B"],
   .....: )
   .....: 

In [164]: df
Out[164]: 
                   A         B
2001-01-01 -0.000144 -0.000141
2001-01-02  0.000161  0.000102
2001-01-03  0.000057  0.000088
2001-01-04 -0.000221  0.000097
2001-01-05 -0.000201 -0.000041
...              ...       ...
2006-06-19  0.000040 -0.000235
2006-06-20 -0.000123 -0.000021
2006-06-21 -0.000113  0.000114
2006-06-22  0.000136  0.000109
2006-06-23  0.000027  0.000030

[2000 rows x 2 columns]

In [165]: def gm(df, const):
   .....:     v = ((((df["A"] + df["B"]) + 1).cumprod()) - 1) * const
   .....:     return v.iloc[-1]
   .....: 

In [166]: s = pd.Series(
   .....:     {
   .....:         df.index[i]: gm(df.iloc[i: min(i + 51, len(df) - 1)], 5)
   .....:         for i in range(len(df) - 50)
   .....:     }
   .....: )
   .....: 

In [167]: s
Out[167]: 
2001-01-01    0.000930
2001-01-02    0.002615
2001-01-03    0.001281
2001-01-04    0.001117
2001-01-05    0.002772
                ...   
2006-04-30    0.003296
2006-05-01    0.002629
2006-05-02    0.002081
2006-05-03    0.004247
2006-05-04    0.003928
Length: 1950, dtype: float64

---->   pandas.DataFrame; pandas.Series

--------------------------------------
ID: 4619 --> 3
In [168]: rng = pd.date_range(start="2014-01-01", periods=100)

In [169]: df = pd.DataFrame(
   .....:     {
   .....:         "Open": np.random.randn(len(rng)),
   .....:         "Close": np.random.randn(len(rng)),
   .....:         "Volume": np.random.randint(100, 2000, len(rng)),
   .....:     },
   .....:     index=rng,
   .....: )
   .....: 

In [170]: df
Out[170]: 
                Open     Close  Volume
2014-01-01 -1.611353 -0.492885    1219
2014-01-02 -3.000951  0.445794    1054
2014-01-03 -0.138359 -0.076081    1381
2014-01-04  0.301568  1.198259    1253
2014-01-05  0.276381 -0.669831    1728
...              ...       ...     ...
2014-04-06 -0.040338  0.937843    1188
2014-04-07  0.359661 -0.285908    1864
2014-04-08  0.060978  1.714814     941
2014-04-09  1.759055 -0.455942    1065
2014-04-10  0.138185 -1.147008    1453

[100 rows x 3 columns]

In [171]: def vwap(bars):
   .....:     return (bars.Close * bars.Volume).sum() / bars.Volume.sum()
   .....: 

In [172]: window = 5

In [173]: s = pd.concat(
   .....:     [
   .....:         (pd.Series(vwap(df.iloc[i: i + window]), index=[df.index[i + window]]))
   .....:         for i in range(len(df) - window)
   .....:     ]
   .....: )
   .....: 

In [174]: s.round(2)
Out[174]: 
2014-01-06    0.02
2014-01-07    0.11
2014-01-08    0.10
2014-01-09    0.07
2014-01-10   -0.29
              ... 
2014-04-06   -0.63
2014-04-07   -0.02
2014-04-08   -0.03
2014-04-09    0.34
2014-04-10    0.29
Length: 95, dtype: float64

---->   pandas.DataFrame; pandas.Series; Series.round

--------------------------------------
ID: 4621 --> 2
In [177]: rng = pd.date_range("2000-01-01", periods=6)

In [178]: df1 = pd.DataFrame(np.random.randn(6, 3), index=rng, columns=["A", "B", "C"])

In [179]: df2 = df1.copy()

---->   pandas.DataFrame; DataFrame.copy

--------------------------------------
ID: 4623 --> 1
In [182]: df = pd.DataFrame(
   .....:     data={
   .....:         "Area": ["A"] * 5 + ["C"] * 2,
   .....:         "Bins": [110] * 2 + [160] * 3 + [40] * 2,
   .....:         "Test_0": [0, 1, 0, 1, 2, 0, 1],
   .....:         "Data": np.random.randn(7),
   .....:     }
   .....: )
   .....: 

In [183]: df
Out[183]: 
  Area  Bins  Test_0      Data
0    A   110       0 -0.433937
1    A   110       1 -0.160552
2    A   160       0  0.744434
3    A   160       1  1.754213
4    A   160       2  0.000850
5    C    40       0  0.342243
6    C    40       1  1.070599

In [184]: df["Test_1"] = df["Test_0"] - 1

In [185]: pd.merge(
   .....:     df,
   .....:     df,
   .....:     left_on=["Bins", "Area", "Test_0"],
   .....:     right_on=["Bins", "Area", "Test_1"],
   .....:     suffixes=("_L", "_R"),
   .....: )
   .....: 
Out[185]: 
  Area  Bins  Test_0_L    Data_L  Test_1_L  Test_0_R    Data_R  Test_1_R
0    A   110         0 -0.433937        -1         1 -0.160552         0
1    A   160         0  0.744434        -1         1  1.754213         0
2    A   160         1  1.754213         0         2  0.000850         1
3    C    40         0  0.342243        -1         1  1.070599         0

---->   pandas.DataFrame

--------------------------------------
ID: 4624 --> 3
In [186]: df = pd.DataFrame(
   .....:     {
   .....:         "stratifying_var": np.random.uniform(0, 100, 20),
   .....:         "price": np.random.normal(100, 5, 20),
   .....:     }
   .....: )
   .....: 

In [187]: df["quartiles"] = pd.qcut(
   .....:     df["stratifying_var"], 4, labels=["0-25%", "25-50%", "50-75%", "75-100%"]
   .....: )
   .....: 

In [188]: df.boxplot(column="price", by="quartiles")
Out[188]: 

---->   pandas.DataFrame; pandas.qcut; DataFrame.boxplot

--------------------------------------
ID: 4625 --> 2
In [189]: for i in range(3):
   .....:     data = pd.DataFrame(np.random.randn(10, 4))
   .....:     data.to_csv("file_{}.csv".format(i))
   .....: 

In [190]: files = ["file_0.csv", "file_1.csv", "file_2.csv"]

In [191]: result = pd.concat([pd.read_csv(f) for f in files], ignore_index=True)

---->   pandas.DataFrame; Series.to_csv

--------------------------------------
ID: 4627 --> 3
In [196]: i = pd.date_range("20000101", periods=10000)

In [197]: df = pd.DataFrame({"year": i.year, "month": i.month, "day": i.day})

In [198]: df.head()
Out[198]: 
   year  month  day
0  2000      1    1
1  2000      1    2
2  2000      1    3
3  2000      1    4
4  2000      1    5

In [199]: %timeit pd.to_datetime(df.year * 10000 + df.month * 100 + df.day, format='%Y%m%d')
   .....: ds = df.apply(lambda x: "%04d%02d%02d" % (x["year"], x["month"], x["day"]), axis=1)
   .....: ds.head()
   .....: %timeit pd.to_datetime(ds)
   .....: 
5.03 ms +- 39.1 us per loop (mean +- std. dev. of 7 runs, 100 loops each)
2.16 ms +- 19.4 us per loop (mean +- std. dev. of 7 runs, 100 loops each)

---->   pandas.DataFrame; DataFrame.head; pandas.to_datetime

--------------------------------------
ID: 4630 --> 1
In [206]: df = pd.DataFrame(np.random.randn(8, 3))

In [207]: store = pd.HDFStore("test.h5")

In [208]: store.put("df", df)

# you can store an arbitrary Python object via pickle
In [209]: store.get_storer("df").attrs.my_attribute = {"A": 10}

In [210]: store.get_storer("df").attrs.my_attribute
Out[210]: {'A': 10}

---->   pandas.DataFrame

--------------------------------------
ID: 4631 --> 1
In [211]: store = pd.HDFStore("test.h5", "w", driver="H5FD_CORE")

In [212]: df = pd.DataFrame(np.random.randn(8, 3))

In [213]: store["test"] = df

# only after closing the store, data is written to disk:
In [214]: store.close()

---->   pandas.DataFrame

--------------------------------------
ID: 4633 --> 1
names = "count", "avg", "scale"

# note that the offsets are larger than the size of the type because of
# struct padding
offsets = 0, 8, 16
formats = "i4", "f8", "f4"
dt = np.dtype({"names": names, "offsets": offsets, "formats": formats}, align=True)
df = pd.DataFrame(np.fromfile("binary.dat", dt))

---->   pandas.DataFrame

--------------------------------------
ID: 4634 --> 2
In [215]: df = pd.DataFrame(np.random.random(size=(100, 5)))

In [216]: corr_mat = df.corr()

In [217]: mask = np.tril(np.ones_like(corr_mat, dtype=np.bool_), k=-1)

In [218]: corr_mat.where(mask)
Out[218]: 
          0         1         2        3   4
0       NaN       NaN       NaN      NaN NaN
1 -0.079861       NaN       NaN      NaN NaN
2 -0.236573  0.183801       NaN      NaN NaN
3 -0.013795 -0.051975  0.037235      NaN NaN
4 -0.031974  0.118342 -0.073499 -0.02063 NaN

---->   pandas.DataFrame; DataFrame.corr

--------------------------------------
ID: 4635 --> 2
In [219]: def distcorr(x, y):
   .....:     n = len(x)
   .....:     a = np.zeros(shape=(n, n))
   .....:     b = np.zeros(shape=(n, n))
   .....:     for i in range(n):
   .....:         for j in range(i + 1, n):
   .....:             a[i, j] = abs(x[i] - x[j])
   .....:             b[i, j] = abs(y[i] - y[j])
   .....:     a += a.T
   .....:     b += b.T
   .....:     a_bar = np.vstack([np.nanmean(a, axis=0)] * n)
   .....:     b_bar = np.vstack([np.nanmean(b, axis=0)] * n)
   .....:     A = a - a_bar - a_bar.T + np.full(shape=(n, n), fill_value=a_bar.mean())
   .....:     B = b - b_bar - b_bar.T + np.full(shape=(n, n), fill_value=b_bar.mean())
   .....:     cov_ab = np.sqrt(np.nansum(A * B)) / n
   .....:     std_a = np.sqrt(np.sqrt(np.nansum(A ** 2)) / n)
   .....:     std_b = np.sqrt(np.sqrt(np.nansum(B ** 2)) / n)
   .....:     return cov_ab / std_a / std_b
   .....: 

In [220]: df = pd.DataFrame(np.random.normal(size=(100, 3)))

In [221]: df.corr(method=distcorr)
Out[221]: 
          0         1         2
0  1.000000  0.197613  0.216328
1  0.197613  1.000000  0.208749
2  0.216328  0.208749  1.000000

---->   pandas.DataFrame; DataFrame.corr

--------------------------------------
ID: 4636 --> 2
In [222]: import datetime

In [223]: s = pd.Series(pd.date_range("2012-1-1", periods=3, freq="D"))

In [224]: s - s.max()
Out[224]: 
0   -2 days
1   -1 days
2    0 days
dtype: timedelta64[ns]

In [225]: s.max() - s
Out[225]: 
0   2 days
1   1 days
2   0 days
dtype: timedelta64[ns]

In [226]: s - datetime.datetime(2011, 1, 1, 3, 5)
Out[226]: 
0   364 days 20:55:00
1   365 days 20:55:00
2   366 days 20:55:00
dtype: timedelta64[ns]

In [227]: s + datetime.timedelta(minutes=5)
Out[227]: 
0   2012-01-01 00:05:00
1   2012-01-02 00:05:00
2   2012-01-03 00:05:00
dtype: datetime64[ns]

In [228]: datetime.datetime(2011, 1, 1, 3, 5) - s
Out[228]: 
0   -365 days +03:05:00
1   -366 days +03:05:00
2   -367 days +03:05:00
dtype: timedelta64[ns]

In [229]: datetime.timedelta(minutes=5) + s
Out[229]: 
0   2012-01-01 00:05:00
1   2012-01-02 00:05:00
2   2012-01-03 00:05:00
dtype: datetime64[ns]

---->   pandas.Series; Series.max

--------------------------------------
ID: 4637 --> 2
In [230]: deltas = pd.Series([datetime.timedelta(days=i) for i in range(3)])

In [231]: df = pd.DataFrame({"A": s, "B": deltas})

In [232]: df
Out[232]: 
           A      B
0 2012-01-01 0 days
1 2012-01-02 1 days
2 2012-01-03 2 days

In [233]: df["New Dates"] = df["A"] + df["B"]

In [234]: df["Delta"] = df["A"] - df["New Dates"]

In [235]: df
Out[235]: 
           A      B  New Dates   Delta
0 2012-01-01 0 days 2012-01-01  0 days
1 2012-01-02 1 days 2012-01-03 -1 days
2 2012-01-03 2 days 2012-01-05 -2 days

In [236]: df.dtypes
Out[236]: 
A             datetime64[ns]
B            timedelta64[ns]
New Dates     datetime64[ns]
Delta        timedelta64[ns]
dtype: object

---->   pandas.Series; pandas.DataFrame

--------------------------------------
ID: 4638 --> 1
In [237]: y = s - s.shift()

In [238]: y
Out[238]: 
0      NaT
1   1 days
2   1 days
dtype: timedelta64[ns]

In [239]: y[1] = np.nan

In [240]: y
Out[240]: 
0      NaT
1      NaT
2   1 days
dtype: timedelta64[ns]

---->   Series.shift

--------------------------------------
ID: 4639 --> 1
In [241]: def expand_grid(data_dict):
   .....:     rows = itertools.product(*data_dict.values())
   .....:     return pd.DataFrame.from_records(rows, columns=data_dict.keys())
   .....: 

In [242]: df = expand_grid(
   .....:     {"height": [60, 70], "weight": [100, 140, 180], "sex": ["Male", "Female"]}
   .....: )
   .....: 

In [243]: df
Out[243]: 
    height  weight     sex
0       60     100    Male
1       60     100  Female
2       60     140    Male
3       60     140  Female
4       60     180    Male
5       60     180  Female
6       70     100    Male
7       70     100  Female
8       70     140    Male
9       70     140  Female
10      70     180    Male
11      70     180  Female

---->   pandas.DataFrame

--------------------------------------
ID: 4642 --> 1
In [11]: pd.describe_option()
compute.use_bottleneck : bool
    Use the bottleneck library to accelerate if it is installed,
    the default is True
    Valid values: False,True
    [default: True] [currently: True]
compute.use_numba : bool
    Use the numba engine option for select operations if it is installed,
    the default is False
    Valid values: False,True
    [default: False] [currently: False]
compute.use_numexpr : bool
    Use the numexpr library to accelerate computation if it is installed,
    the default is True
    Valid values: False,True
    [default: True] [currently: True]
display.chop_threshold : float or None
    if set to a float value, all float values smaller than the given threshold
    will be displayed as exactly 0 by repr and friends.
    [default: None] [currently: None]
display.colheader_justify : 'left'/'right'
    Controls the justification of column headers. used by DataFrameFormatter.
    [default: right] [currently: right]
display.date_dayfirst : boolean
    When True, prints and parses dates with the day first, eg 20/01/2005
    [default: False] [currently: False]
display.date_yearfirst : boolean
    When True, prints and parses dates with the year first, eg 2005/01/20
    [default: False] [currently: False]
display.encoding : str/unicode
    Defaults to the detected encoding of the console.
    Specifies the encoding to be used for strings returned by to_string,
    these are generally strings meant to be displayed on the console.
    [default: utf-8] [currently: utf8]
display.expand_frame_repr : boolean
    Whether to print out the full DataFrame repr for wide DataFrames across
    multiple lines, `max_columns` is still respected, but the output will
    wrap-around across multiple "pages" if its width exceeds `display.width`.
    [default: True] [currently: True]
display.float_format : callable
    The callable should accept a floating point number and return
    a string with the desired format of the number. This is used
    in some places like SeriesFormatter.
    See formats.format.EngFormatter for an example.
    [default: None] [currently: None]
display.html.border : int
    A ``border=value`` attribute is inserted in the ```` tag
    for the DataFrame HTML repr.
    [default: 1] [currently: 1]
display.html.table_schema : boolean
    Whether to publish a Table Schema representation for frontends
    that support it.
    (default: False)
    [default: False] [currently: False]
display.html.use_mathjax : boolean
    When True, Jupyter notebook will process table contents using MathJax,
    rendering mathematical expressions enclosed by the dollar symbol.
    (default: True)
    [default: True] [currently: True]
display.large_repr : 'truncate'/'info'
    For DataFrames exceeding max_rows/max_cols, the repr (and HTML repr) can
    show a truncated table (the default from 0.13), or switch to the view from
    df.info() (the behaviour in earlier versions of pandas).
    [default: truncate] [currently: truncate]
display.max_categories : int
    This sets the maximum number of categories pandas should output when
    printing out a `Categorical` or a Series of dtype "category".
    [default: 8] [currently: 8]
display.max_columns : int
    If max_cols is exceeded, switch to truncate view. Depending on
    `large_repr`, objects are either centrally truncated or printed as
    a summary view. 'None' value means unlimited.

    In case python/IPython is running in a terminal and `large_repr`
    equals 'truncate' this can be set to 0 or None and pandas will auto-detect
    the width of the terminal and print a truncated object which fits
    the screen width. The IPython notebook, IPython qtconsole, or IDLE
    do not run in a terminal and hence it is not possible to do
    correct auto-detection and defaults to 20.
    [default: 0] [currently: 0]
display.max_colwidth : int or None
    The maximum width in characters of a column in the repr of
    a pandas data structure. When the column overflows, a "..."
    placeholder is embedded in the output. A 'None' value means unlimited.
    [default: 50] [currently: 50]
display.max_dir_items : int
    The number of items that will be added to `dir(...)`. 'None' value means
    unlimited. Because dir is cached, changing this option will not immediately
    affect already existing dataframes until a column is deleted or added.

    This is for instance used to suggest columns from a dataframe to tab
    completion.
    [default: 100] [currently: 100]
display.max_info_columns : int
    max_info_columns is used in DataFrame.info method to decide if
    per column information will be printed.
    [default: 100] [currently: 100]
display.max_info_rows : int or None
    df.info() will usually show null-counts for each column.
    For large frames this can be quite slow. max_info_rows and max_info_cols
    limit this null check only to frames with smaller dimensions than
    specified.
    [default: 1690785] [currently: 1690785]
display.max_rows : int
    If max_rows is exceeded, switch to truncate view. Depending on
    `large_repr`, objects are either centrally truncated or printed as
    a summary view. 'None' value means unlimited.

    In case python/IPython is running in a terminal and `large_repr`
    equals 'truncate' this can be set to 0 and pandas will auto-detect
    the height of the terminal and print a truncated object which fits
    the screen height. The IPython notebook, IPython qtconsole, or
    IDLE do not run in a terminal and hence it is not possible to do
    correct auto-detection.
    [default: 60] [currently: 60]
display.max_seq_items : int or None
    When pretty-printing a long sequence, no more then `max_seq_items`
    will be printed. If items are omitted, they will be denoted by the
    addition of "..." to the resulting string.

    If set to None, the number of items to be printed is unlimited.
    [default: 100] [currently: 100]
display.memory_usage : bool, string or None
    This specifies if the memory usage of a DataFrame should be displayed when
    df.info() is called. Valid values True,False,'deep'
    [default: True] [currently: True]
display.min_rows : int
    The numbers of rows to show in a truncated view (when `max_rows` is
    exceeded). Ignored when `max_rows` is set to None or 0. When set to
    None, follows the value of `max_rows`.
    [default: 10] [currently: 10]
display.multi_sparse : boolean
    "sparsify" MultiIndex display (don't display repeated
    elements in outer levels within groups)
    [default: True] [currently: True]
display.notebook_repr_html : boolean
    When True, IPython notebook will use html representation for
    pandas objects (if it is available).
    [default: True] [currently: True]
display.pprint_nest_depth : int
    Controls the number of nested levels to process when pretty-printing
    [default: 3] [currently: 3]
display.precision : int
    Floating point output precision in terms of number of places after the
    decimal, for regular formatting as well as scientific notation. Similar
    to ``precision`` in :meth:`numpy.set_printoptions`.
    [default: 6] [currently: 6]
display.show_dimensions : boolean or 'truncate'
    Whether to print out dimensions at the end of DataFrame repr.
    If 'truncate' is specified, only print out the dimensions if the
    frame is truncated (e.g. not display all rows and/or columns)
    [default: truncate] [currently: truncate]
display.unicode.ambiguous_as_wide : boolean
    Whether to use the Unicode East Asian Width to calculate the display text
    width.
    Enabling this may affect to the performance (default: False)
    [default: False] [currently: False]
display.unicode.east_asian_width : boolean
    Whether to use the Unicode East Asian Width to calculate the display text
    width.
    Enabling this may affect to the performance (default: False)
    [default: False] [currently: False]
display.width : int
    Width of the display in characters. In case python/IPython is running in
    a terminal this can be set to None and pandas will correctly auto-detect
    the width.
    Note that the IPython notebook, IPython qtconsole, or IDLE do not run in a
    terminal and hence it is not possible to correctly detect the width.
    [default: 80] [currently: 80]
io.excel.ods.reader : string
    The default Excel reader engine for 'ods' files. Available options:
    auto, odf.
    [default: auto] [currently: auto]
io.excel.ods.writer : string
    The default Excel writer engine for 'ods' files. Available options:
    auto, odf.
    [default: auto] [currently: auto]
io.excel.xls.reader : string
    The default Excel reader engine for 'xls' files. Available options:
    auto, xlrd.
    [default: auto] [currently: auto]
io.excel.xlsb.reader : string
    The default Excel reader engine for 'xlsb' files. Available options:
    auto, pyxlsb.
    [default: auto] [currently: auto]
io.excel.xlsm.reader : string
    The default Excel reader engine for 'xlsm' files. Available options:
    auto, xlrd, openpyxl.
    [default: auto] [currently: auto]
io.excel.xlsm.writer : string
    The default Excel writer engine for 'xlsm' files. Available options:
    auto, openpyxl.
    [default: auto] [currently: auto]
io.excel.xlsx.reader : string
    The default Excel reader engine for 'xlsx' files. Available options:
    auto, xlrd, openpyxl.
    [default: auto] [currently: auto]
io.excel.xlsx.writer : string
    The default Excel writer engine for 'xlsx' files. Available options:
    auto, openpyxl, xlsxwriter.
    [default: auto] [currently: auto]
io.hdf.default_format : format
    default format writing format, if None, then
    put will default to 'fixed' and append will default to 'table'
    [default: None] [currently: None]
io.hdf.dropna_table : boolean
    drop ALL nan rows when appending to a table
    [default: False] [currently: False]
io.parquet.engine : string
    The default parquet reader/writer engine. Available options:
    'auto', 'pyarrow', 'fastparquet', the default is 'auto'
    [default: auto] [currently: auto]
io.sql.engine : string
    The default sql reader/writer engine. Available options:
    'auto', 'sqlalchemy', the default is 'auto'
    [default: auto] [currently: auto]
mode.chained_assignment : string
    Raise an exception, warn, or no action if trying to use chained assignment,
    The default is warn
    [default: warn] [currently: warn]
mode.copy_on_write : bool
    Use new copy-view behaviour using Copy-on-Write. Defaults to False,
    unless overridden by the 'PANDAS_COPY_ON_WRITE' environment variable
    (if set to "1" for True, needs to be set before pandas is imported).
    [default: False] [currently: False]
mode.data_manager : string
    Internal data manager type; can be "block" or "array". Defaults to "block",
    unless overridden by the 'PANDAS_DATA_MANAGER' environment variable (needs
    to be set before pandas is imported).
    [default: block] [currently: block]
mode.sim_interactive : boolean
    Whether to simulate interactive mode for purposes of testing
    [default: False] [currently: False]
mode.string_storage : string
    The default storage for StringDtype.
    [default: python] [currently: python]
mode.use_inf_as_na : boolean
    True means treat None, NaN, INF, -INF as NA (old way),
    False means None and NaN are null, but INF, -INF are not NA
    (new way).
    [default: False] [currently: False]
plotting.backend : str
    The plotting backend to use. The default value is "matplotlib", the
    backend provided with pandas. Other backends can be specified by
    providing the name of the module that implements the backend.
    [default: matplotlib] [currently: matplotlib]
plotting.matplotlib.register_converters : bool or 'auto'.
    Whether to register converters with matplotlib's units registry for
    dates, times, datetimes, and Periods. Toggling to False will remove
    the converters, restoring any converters that pandas overwrote.
    [default: auto] [currently: auto]
styler.format.decimal : str
    The character representation for the decimal separator for floats and complex.
    [default: .] [currently: .]
styler.format.escape : str, optional
    Whether to escape certain characters according to the given context; html or latex.
    [default: None] [currently: None]
styler.format.formatter : str, callable, dict, optional
    A formatter object to be used as default within ``Styler.format``.
    [default: None] [currently: None]
styler.format.na_rep : str, optional
    The string representation for values identified as missing.
    [default: None] [currently: None]
styler.format.precision : int
    The precision for floats and complex numbers.
    [default: 6] [currently: 6]
styler.format.thousands : str, optional
    The character representation for thousands separator for floats, int and complex.
    [default: None] [currently: None]
styler.html.mathjax : bool
    If False will render special CSS classes to table attributes that indicate Mathjax
    will not be used in Jupyter Notebook.
    [default: True] [currently: True]
styler.latex.environment : str
    The environment to replace ``\begin{table}``. If "longtable" is used results
    in a specific longtable environment format.
    [default: None] [currently: None]
styler.latex.hrules : bool
    Whether to add horizontal rules on top and bottom and below the headers.
    [default: False] [currently: False]
styler.latex.multicol_align : {"r", "c", "l", "naive-l", "naive-r"}
    The specifier for horizontal alignment of sparsified LaTeX multicolumns. Pipe
    decorators can also be added to non-naive values to draw vertical
    rules, e.g. "\|r" will draw a rule on the left side of right aligned merged cells.
    [default: r] [currently: r]
styler.latex.multirow_align : {"c", "t", "b"}
    The specifier for vertical alignment of sparsified LaTeX multirows.
    [default: c] [currently: c]
styler.render.encoding : str
    The encoding used for output HTML and LaTeX files.
    [default: utf-8] [currently: utf-8]
styler.render.max_columns : int, optional
    The maximum number of columns that will be rendered. May still be reduced to
    satsify ``max_elements``, which takes precedence.
    [default: None] [currently: None]
styler.render.max_elements : int
    The maximum number of data-cell () elements that will be rendered before
    trimming will occur over columns, rows or both if needed.
    [default: 262144] [currently: 262144]
styler.render.max_rows : int, optional
    The maximum number of rows that will be rendered. May still be reduced to
    satsify ``max_elements``, which takes precedence.
    [default: None] [currently: None]
styler.render.repr : str
    Determine which output to use in Jupyter Notebook in {"html", "latex"}.
    [default: html] [currently: html]
styler.sparse.columns : bool
    Whether to sparsify the display of hierarchical columns. Setting to False will
    display each explicit level element in a hierarchical key for each column.
    [default: True] [currently: True]
styler.sparse.index : bool
    Whether to sparsify the display of a hierarchical index. Setting to False will
    display each explicit level element in a hierarchical key for each row.
    [default: True] [currently: True]

---->   DataFrame.info

--------------------------------------
ID: 4648 --> 1
In [24]: df = pd.DataFrame(np.random.randn(7, 2))

In [25]: pd.set_option("display.max_rows", 7)

In [26]: df
Out[26]: 
          0         1
0  0.469112 -0.282863
1 -1.509059 -1.135632
2  1.212112 -0.173215
3  0.119209 -1.044236
4 -0.861849 -2.104569
5 -0.494929  1.071804
6  0.721555 -0.706771

In [27]: pd.set_option("display.max_rows", 5)

In [28]: df
Out[28]: 
           0         1
0   0.469112 -0.282863
1  -1.509059 -1.135632
..       ...       ...
5  -0.494929  1.071804
6   0.721555 -0.706771

[7 rows x 2 columns]

In [29]: pd.reset_option("display.max_rows")

---->   pandas.DataFrame

--------------------------------------
ID: 4649 --> 1
In [30]: pd.set_option("display.max_rows", 8)

In [31]: pd.set_option("display.min_rows", 4)

# below max_rows -> all rows shown
In [32]: df = pd.DataFrame(np.random.randn(7, 2))

In [33]: df
Out[33]: 
          0         1
0 -1.039575  0.271860
1 -0.424972  0.567020
2  0.276232 -1.087401
3 -0.673690  0.113648
4 -1.478427  0.524988
5  0.404705  0.577046
6 -1.715002 -1.039268

# above max_rows -> only min_rows (4) rows shown
In [34]: df = pd.DataFrame(np.random.randn(9, 2))

In [35]: df
Out[35]: 
           0         1
0  -0.370647 -1.157892
1  -1.344312  0.844885
..       ...       ...
7   0.276662 -0.472035
8  -0.013960 -0.362543

[9 rows x 2 columns]

In [36]: pd.reset_option("display.max_rows")

In [37]: pd.reset_option("display.min_rows")

---->   pandas.DataFrame

--------------------------------------
ID: 4650 --> 1
In [38]: df = pd.DataFrame(np.random.randn(5, 10))

In [39]: pd.set_option("expand_frame_repr", True)

In [40]: df
Out[40]: 
          0         1         2  ...         7         8         9
0 -0.006154 -0.923061  0.895717  ...  1.340309 -1.170299 -0.226169
1  0.410835  0.813850  0.132003  ... -1.436737 -1.413681  1.607920
2  1.024180  0.569605  0.875906  ... -0.078638  0.545952 -1.219217
3 -1.226825  0.769804 -1.281247  ...  0.341734  0.959726 -1.110336
4 -0.619976  0.149748 -0.732339  ...  0.301624 -2.179861 -1.369849

[5 rows x 10 columns]

In [41]: pd.set_option("expand_frame_repr", False)

In [42]: df
Out[42]: 
          0         1         2         3         4         5         6         7         8         9
0 -0.006154 -0.923061  0.895717  0.805244 -1.206412  2.565646  1.431256  1.340309 -1.170299 -0.226169
1  0.410835  0.813850  0.132003 -0.827317 -0.076467 -1.187678  1.130127 -1.436737 -1.413681  1.607920
2  1.024180  0.569605  0.875906 -2.211372  0.974466 -2.006747 -0.410001 -0.078638  0.545952 -1.219217
3 -1.226825  0.769804 -1.281247 -0.727707 -0.121306 -0.097883  0.695775  0.341734  0.959726 -1.110336
4 -0.619976  0.149748 -0.732339  0.687738  0.176444  0.403310 -0.154951  0.301624 -2.179861 -1.369849

In [43]: pd.reset_option("expand_frame_repr")

---->   pandas.DataFrame

--------------------------------------
ID: 4651 --> 1
In [44]: df = pd.DataFrame(np.random.randn(10, 10))

In [45]: pd.set_option("display.max_rows", 5)

In [46]: pd.set_option("large_repr", "truncate")

In [47]: df
Out[47]: 
           0         1         2  ...         7         8         9
0  -0.954208  1.462696 -1.743161  ...  0.995761  2.396780  0.014871
1   3.357427 -0.317441 -1.236269  ...  0.380396  0.084844  0.432390
..       ...       ...       ...  ...       ...       ...       ...
8  -0.303421 -0.858447  0.306996  ...  0.476720  0.473424 -0.242861
9  -0.014805 -0.284319  0.650776  ...  1.613616  0.464000  0.227371

[10 rows x 10 columns]

In [48]: pd.set_option("large_repr", "info")

In [49]: df
Out[49]: 

RangeIndex: 10 entries, 0 to 9
Data columns (total 10 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       10 non-null     float64
 1   1       10 non-null     float64
 2   2       10 non-null     float64
 3   3       10 non-null     float64
 4   4       10 non-null     float64
 5   5       10 non-null     float64
 6   6       10 non-null     float64
 7   7       10 non-null     float64
 8   8       10 non-null     float64
 9   9       10 non-null     float64
dtypes: float64(10)
memory usage: 928.0 bytes

In [50]: pd.reset_option("large_repr")

In [51]: pd.reset_option("display.max_rows")

---->   pandas.DataFrame

--------------------------------------
ID: 4652 --> 1
In [52]: df = pd.DataFrame(
   ....:     np.array(
   ....:         [
   ....:             ["foo", "bar", "bim", "uncomfortably long string"],
   ....:             ["horse", "cow", "banana", "apple"],
   ....:         ]
   ....:     )
   ....: )
   ....: 

In [53]: pd.set_option("max_colwidth", 40)

In [54]: df
Out[54]: 
       0    1       2                          3
0    foo  bar     bim  uncomfortably long string
1  horse  cow  banana                      apple

In [55]: pd.set_option("max_colwidth", 6)

In [56]: df
Out[56]: 
       0    1      2      3
0    foo  bar    bim  un...
1  horse  cow  ba...  apple

In [57]: pd.reset_option("max_colwidth")

---->   pandas.DataFrame

--------------------------------------
ID: 4653 --> 2
In [58]: df = pd.DataFrame(np.random.randn(10, 10))

In [59]: pd.set_option("max_info_columns", 11)

In [60]: df.info()

RangeIndex: 10 entries, 0 to 9
Data columns (total 10 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       10 non-null     float64
 1   1       10 non-null     float64
 2   2       10 non-null     float64
 3   3       10 non-null     float64
 4   4       10 non-null     float64
 5   5       10 non-null     float64
 6   6       10 non-null     float64
 7   7       10 non-null     float64
 8   8       10 non-null     float64
 9   9       10 non-null     float64
dtypes: float64(10)
memory usage: 928.0 bytes

In [61]: pd.set_option("max_info_columns", 5)

In [62]: df.info()

RangeIndex: 10 entries, 0 to 9
Columns: 10 entries, 0 to 9
dtypes: float64(10)
memory usage: 928.0 bytes

In [63]: pd.reset_option("max_info_columns")

---->   pandas.DataFrame; DataFrame.info

--------------------------------------
ID: 4654 --> 2
In [64]: df = pd.DataFrame(np.random.choice([0, 1, np.nan], size=(10, 10)))

In [65]: df
Out[65]: 
     0    1    2    3    4    5    6    7    8    9
0  0.0  NaN  1.0  NaN  NaN  0.0  NaN  0.0  NaN  1.0
1  1.0  NaN  1.0  1.0  1.0  1.0  NaN  0.0  0.0  NaN
2  0.0  NaN  1.0  0.0  0.0  NaN  NaN  NaN  NaN  0.0
3  NaN  NaN  NaN  0.0  1.0  1.0  NaN  1.0  NaN  1.0
4  0.0  NaN  NaN  NaN  0.0  NaN  NaN  NaN  1.0  0.0
5  0.0  1.0  1.0  1.0  1.0  0.0  NaN  NaN  1.0  0.0
6  1.0  1.0  1.0  NaN  1.0  NaN  1.0  0.0  NaN  NaN
7  0.0  0.0  1.0  0.0  1.0  0.0  1.0  1.0  0.0  NaN
8  NaN  NaN  NaN  0.0  NaN  NaN  NaN  NaN  1.0  NaN
9  0.0  NaN  0.0  NaN  NaN  0.0  NaN  1.0  1.0  0.0

In [66]: pd.set_option("max_info_rows", 11)

In [67]: df.info()

RangeIndex: 10 entries, 0 to 9
Data columns (total 10 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       8 non-null      float64
 1   1       3 non-null      float64
 2   2       7 non-null      float64
 3   3       6 non-null      float64
 4   4       7 non-null      float64
 5   5       6 non-null      float64
 6   6       2 non-null      float64
 7   7       6 non-null      float64
 8   8       6 non-null      float64
 9   9       6 non-null      float64
dtypes: float64(10)
memory usage: 928.0 bytes

In [68]: pd.set_option("max_info_rows", 5)

In [69]: df.info()

RangeIndex: 10 entries, 0 to 9
Data columns (total 10 columns):
 #   Column  Dtype  
---  ------  -----  
 0   0       float64
 1   1       float64
 2   2       float64
 3   3       float64
 4   4       float64
 5   5       float64
 6   6       float64
 7   7       float64
 8   8       float64
 9   9       float64
dtypes: float64(10)
memory usage: 928.0 bytes

In [70]: pd.reset_option("max_info_rows")

---->   pandas.DataFrame; DataFrame.info

--------------------------------------
ID: 4655 --> 1
In [71]: df = pd.DataFrame(np.random.randn(5, 5))

In [72]: pd.set_option("display.precision", 7)

In [73]: df
Out[73]: 
           0          1          2          3          4
0 -1.1506406 -0.7983341 -0.5576966  0.3813531  1.3371217
1 -1.5310949  1.3314582 -0.5713290 -0.0266708 -1.0856630
2 -1.1147378 -0.0582158 -0.4867681  1.6851483  0.1125723
3 -1.4953086  0.8984347 -0.1482168 -1.5960698  0.1596530
4  0.2621358  0.0362196  0.1847350 -0.2550694 -0.2710197

In [74]: pd.set_option("display.precision", 4)

In [75]: df
Out[75]: 
        0       1       2       3       4
0 -1.1506 -0.7983 -0.5577  0.3814  1.3371
1 -1.5311  1.3315 -0.5713 -0.0267 -1.0857
2 -1.1147 -0.0582 -0.4868  1.6851  0.1126
3 -1.4953  0.8984 -0.1482 -1.5961  0.1597
4  0.2621  0.0362  0.1847 -0.2551 -0.2710

---->   pandas.DataFrame

--------------------------------------
ID: 4656 --> 1
In [76]: df = pd.DataFrame(np.random.randn(6, 6))

In [77]: pd.set_option("chop_threshold", 0)

In [78]: df
Out[78]: 
        0       1       2       3       4       5
0  1.2884  0.2946 -1.1658  0.8470 -0.6856  0.6091
1 -0.3040  0.6256 -0.0593  0.2497  1.1039 -1.0875
2  1.9980 -0.2445  0.1362  0.8863 -1.3507 -0.8863
3 -1.0133  1.9209 -0.3882 -2.3144  0.6655  0.4026
4  0.3996 -1.7660  0.8504  0.3881  0.9923  0.7441
5 -0.7398 -1.0549 -0.1796  0.6396  1.5850  1.9067

In [79]: pd.set_option("chop_threshold", 0.5)

In [80]: df
Out[80]: 
        0       1       2       3       4       5
0  1.2884  0.0000 -1.1658  0.8470 -0.6856  0.6091
1  0.0000  0.6256  0.0000  0.0000  1.1039 -1.0875
2  1.9980  0.0000  0.0000  0.8863 -1.3507 -0.8863
3 -1.0133  1.9209  0.0000 -2.3144  0.6655  0.0000
4  0.0000 -1.7660  0.8504  0.0000  0.9923  0.7441
5 -0.7398 -1.0549  0.0000  0.6396  1.5850  1.9067

In [81]: pd.reset_option("chop_threshold")

---->   pandas.DataFrame

--------------------------------------
ID: 4657 --> 1
In [82]: df = pd.DataFrame(
   ....:     np.array([np.random.randn(6), np.random.randint(1, 9, 6) * 0.1, np.zeros(6)]).T,
   ....:     columns=["A", "B", "C"],
   ....:     dtype="float",
   ....: )
   ....: 

In [83]: pd.set_option("colheader_justify", "right")

In [84]: df
Out[84]: 
        A    B    C
0  0.1040  0.1  0.0
1  0.1741  0.5  0.0
2 -0.4395  0.4  0.0
3 -0.7413  0.8  0.0
4 -0.0797  0.4  0.0
5 -0.9229  0.3  0.0

In [85]: pd.set_option("colheader_justify", "left")

In [86]: df
Out[86]: 
   A       B    C  
0  0.1040  0.1  0.0
1  0.1741  0.5  0.0
2 -0.4395  0.4  0.0
3 -0.7413  0.8  0.0
4 -0.0797  0.4  0.0
5 -0.9229  0.3  0.0

In [87]: pd.reset_option("colheader_justify")

---->   pandas.DataFrame

--------------------------------------
ID: 4658 --> 2
In [88]: import numpy as np

In [89]: pd.set_eng_float_format(accuracy=3, use_eng_prefix=True)

In [90]: s = pd.Series(np.random.randn(5), index=["a", "b", "c", "d", "e"])

In [91]: s / 1.0e3
Out[91]: 
a    303.638u
b   -721.084u
c   -622.696u
d    648.250u
e     -1.945m
dtype: float64

In [92]: s / 1.0e6
Out[92]: 
a    303.638n
b   -721.084n
c   -622.696n
d    648.250n
e     -1.945u
dtype: float64

---->   pandas.set_eng_float_format; pandas.Series

--------------------------------------
ID: 4659 --> 1
In [93]: df = pd.DataFrame({"国籍": ["UK", "日本"], "名前": ["Alice", "しのぶ"]})

In [94]: df
Out[94]: 
   国籍     名前
0  UK  Alice
1  日本    しのぶ

---->   pandas.DataFrame

--------------------------------------
ID: 4661 --> 1
In [97]: df = pd.DataFrame({"a": ["xxx", "¡¡"], "b": ["yyy", "¡¡"]})

In [98]: df
Out[98]: 
     a    b
0  xxx  yyy
1   ¡¡   ¡¡

---->   pandas.DataFrame

--------------------------------------
ID: 4664 --> 1
In [1]: import datetime

In [2]: dti = pd.to_datetime(
   ...:     ["1/1/2018", np.datetime64("2018-01-01"), datetime.datetime(2018, 1, 1)]
   ...: )
   ...: 

In [3]: dti
Out[3]: DatetimeIndex(['2018-01-01', '2018-01-01', '2018-01-01'], dtype='datetime64[ns]', freq=None)

---->   pandas.to_datetime

--------------------------------------
ID: 4667 --> 2
In [9]: idx = pd.date_range("2018-01-01", periods=5, freq="H")

In [10]: ts = pd.Series(range(len(idx)), index=idx)

In [11]: ts
Out[11]: 
2018-01-01 00:00:00    0
2018-01-01 01:00:00    1
2018-01-01 02:00:00    2
2018-01-01 03:00:00    3
2018-01-01 04:00:00    4
Freq: H, dtype: int64

In [12]: ts.resample("2H").mean()
Out[12]: 
2018-01-01 00:00:00    0.5
2018-01-01 02:00:00    2.5
2018-01-01 04:00:00    4.0
Freq: 2H, dtype: float64

---->   pandas.Series; Series.resample

--------------------------------------
ID: 4669 --> 1
In [19]: pd.Series(range(3), index=pd.date_range("2000", freq="D", periods=3))
Out[19]: 
2000-01-01    0
2000-01-02    1
2000-01-03    2
Freq: D, dtype: int64

---->   pandas.Series

--------------------------------------
ID: 4670 --> 1
In [20]: pd.Series(pd.date_range("2000", freq="D", periods=3))
Out[20]: 
0   2000-01-01
1   2000-01-02
2   2000-01-03
dtype: datetime64[ns]

---->   pandas.Series

--------------------------------------
ID: 4671 --> 2
In [21]: pd.Series(pd.period_range("1/1/2011", freq="M", periods=3))
Out[21]: 
0    2011-01
1    2011-02
2    2011-03
dtype: period[M]

In [22]: pd.Series([pd.DateOffset(1), pd.DateOffset(2)])
Out[22]: 
0         
1    <2 * DateOffsets>
dtype: object

In [23]: pd.Series(pd.date_range("1/1/2011", freq="M", periods=3))
Out[23]: 
0   2011-01-31
1   2011-02-28
2   2011-03-31
dtype: datetime64[ns]

---->   pandas.Series; pandas.period_range

--------------------------------------
ID: 4672 --> 1
In [24]: pd.Timestamp(pd.NaT)
Out[24]: NaT

In [25]: pd.Timedelta(pd.NaT)
Out[25]: NaT

In [26]: pd.Period(pd.NaT)
Out[26]: NaT

# Equality acts as np.nan would
In [27]: pd.NaT == pd.NaT
Out[27]: False

---->   pandas.Period

--------------------------------------
ID: 4674 --> 1
In [32]: pd.Period("2011-01")
Out[32]: Period('2011-01', 'M')

In [33]: pd.Period("2012-05", freq="D")
Out[33]: Period('2012-05-01', 'D')

---->   pandas.Period

--------------------------------------
ID: 4675 --> 2
In [34]: dates = [
   ....:     pd.Timestamp("2012-05-01"),
   ....:     pd.Timestamp("2012-05-02"),
   ....:     pd.Timestamp("2012-05-03"),
   ....: ]
   ....: 

In [35]: ts = pd.Series(np.random.randn(3), dates)

In [36]: type(ts.index)
Out[36]: pandas.core.indexes.datetimes.DatetimeIndex

In [37]: ts.index
Out[37]: DatetimeIndex(['2012-05-01', '2012-05-02', '2012-05-03'], dtype='datetime64[ns]', freq=None)

In [38]: ts
Out[38]: 
2012-05-01    0.469112
2012-05-02   -0.282863
2012-05-03   -1.509059
dtype: float64

In [39]: periods = [pd.Period("2012-01"), pd.Period("2012-02"), pd.Period("2012-03")]

In [40]: ts = pd.Series(np.random.randn(3), periods)

In [41]: type(ts.index)
Out[41]: pandas.core.indexes.period.PeriodIndex

In [42]: ts.index
Out[42]: PeriodIndex(['2012-01', '2012-02', '2012-03'], dtype='period[M]')

In [43]: ts
Out[43]: 
2012-01   -1.135632
2012-02    1.212112
2012-03   -0.173215
Freq: M, dtype: float64

---->   pandas.Series; pandas.Period

--------------------------------------
ID: 4676 --> 2
In [44]: pd.to_datetime(pd.Series(["Jul 31, 2009", "Jan 10, 2010", None]))
Out[44]: 
0   2009-07-31
1   2010-01-10
2          NaT
dtype: datetime64[ns]

In [45]: pd.to_datetime(["2005/11/23", "2010/12/31"])
Out[45]: DatetimeIndex(['2005-11-23', '2010-12-31'], dtype='datetime64[ns]', freq=None)

---->   pandas.to_datetime; pandas.Series

--------------------------------------
ID: 4677 --> 1
In [46]: pd.to_datetime(["04-01-2012 10:00"], dayfirst=True)
Out[46]: DatetimeIndex(['2012-01-04 10:00:00'], dtype='datetime64[ns]', freq=None)

In [47]: pd.to_datetime(["04-14-2012 10:00"], dayfirst=True)
Out[47]: DatetimeIndex(['2012-04-14 10:00:00'], dtype='datetime64[ns]', freq=None)

---->   pandas.to_datetime

--------------------------------------
ID: 4678 --> 1
In [48]: pd.to_datetime("2010/11/12")
Out[48]: Timestamp('2010-11-12 00:00:00')

In [49]: pd.Timestamp("2010/11/12")
Out[49]: Timestamp('2010-11-12 00:00:00')

---->   pandas.to_datetime

--------------------------------------
ID: 4679 --> 1
In [50]: pd.DatetimeIndex(["2018-01-01", "2018-01-03", "2018-01-05"])
Out[50]: DatetimeIndex(['2018-01-01', '2018-01-03', '2018-01-05'], dtype='datetime64[ns]', freq=None)

---->   pandas.DatetimeIndex

--------------------------------------
ID: 4680 --> 1
In [51]: pd.DatetimeIndex(["2018-01-01", "2018-01-03", "2018-01-05"], freq="infer")
Out[51]: DatetimeIndex(['2018-01-01', '2018-01-03', '2018-01-05'], dtype='datetime64[ns]', freq='2D')

---->   pandas.DatetimeIndex

--------------------------------------
ID: 4681 --> 1
In [52]: pd.to_datetime("2010/11/12", format="%Y/%m/%d")
Out[52]: Timestamp('2010-11-12 00:00:00')

In [53]: pd.to_datetime("12-11-2010 00:00", format="%d-%m-%Y %H:%M")
Out[53]: Timestamp('2010-11-12 00:00:00')

---->   pandas.to_datetime

--------------------------------------
ID: 4682 --> 2
In [54]: df = pd.DataFrame(
   ....:     {"year": [2015, 2016], "month": [2, 3], "day": [4, 5], "hour": [2, 3]}
   ....: )
   ....: 

In [55]: pd.to_datetime(df)
Out[55]: 
0   2015-02-04 02:00:00
1   2016-03-05 03:00:00
dtype: datetime64[ns]

---->   pandas.DataFrame; pandas.to_datetime

--------------------------------------
ID: 4683 --> 1
In [56]: pd.to_datetime(df[["year", "month", "day"]])
Out[56]: 
0   2015-02-04
1   2016-03-05
dtype: datetime64[ns]

---->   pandas.to_datetime

--------------------------------------
ID: 4684 --> 1
In [2]: pd.to_datetime(['2009/07/31', 'asd'], errors='raise')
ValueError: Unknown datetime string format

---->   pandas.to_datetime

--------------------------------------
ID: 4685 --> 1
In [57]: pd.to_datetime(["2009/07/31", "asd"], errors="ignore")
Out[57]: Index(['2009/07/31', 'asd'], dtype='object')

---->   pandas.to_datetime

--------------------------------------
ID: 4686 --> 1
In [58]: pd.to_datetime(["2009/07/31", "asd"], errors="coerce")
Out[58]: DatetimeIndex(['2009-07-31', 'NaT'], dtype='datetime64[ns]', freq=None)

---->   pandas.to_datetime

--------------------------------------
ID: 4687 --> 1
In [59]: pd.to_datetime(
   ....:     [1349720105, 1349806505, 1349892905, 1349979305, 1350065705], unit="s"
   ....: )
   ....: 
Out[59]: 
DatetimeIndex(['2012-10-08 18:15:05', '2012-10-09 18:15:05',
               '2012-10-10 18:15:05', '2012-10-11 18:15:05',
               '2012-10-12 18:15:05'],
              dtype='datetime64[ns]', freq=None)

In [60]: pd.to_datetime(
   ....:     [1349720105100, 1349720105200, 1349720105300, 1349720105400, 1349720105500],
   ....:     unit="ms",
   ....: )
   ....: 
Out[60]: 
DatetimeIndex(['2012-10-08 18:15:05.100000', '2012-10-08 18:15:05.200000',
               '2012-10-08 18:15:05.300000', '2012-10-08 18:15:05.400000',
               '2012-10-08 18:15:05.500000'],
              dtype='datetime64[ns]', freq=None)

---->   pandas.to_datetime

--------------------------------------
ID: 4688 --> 1
In [61]: pd.Timestamp(1262347200000000000).tz_localize("US/Pacific")
Out[61]: Timestamp('2010-01-01 12:00:00-0800', tz='US/Pacific')

In [62]: pd.DatetimeIndex([1262347200000000000]).tz_localize("US/Pacific")
Out[62]: DatetimeIndex(['2010-01-01 12:00:00-08:00'], dtype='datetime64[ns, US/Pacific]', freq=None)

---->   pandas.DatetimeIndex

--------------------------------------
ID: 4689 --> 1
In [63]: pd.to_datetime([1490195805.433, 1490195805.433502912], unit="s")
Out[63]: DatetimeIndex(['2017-03-22 15:16:45.433000088', '2017-03-22 15:16:45.433502913'], dtype='datetime64[ns]', freq=None)

In [64]: pd.to_datetime(1490195805433502912, unit="ns")
Out[64]: Timestamp('2017-03-22 15:16:45.433502912')

---->   pandas.to_datetime

--------------------------------------
ID: 4692 --> 1
In [68]: pd.to_datetime([1, 2, 3], unit="D", origin=pd.Timestamp("1960-01-01"))
Out[68]: DatetimeIndex(['1960-01-02', '1960-01-03', '1960-01-04'], dtype='datetime64[ns]', freq=None)

---->   pandas.to_datetime

--------------------------------------
ID: 4693 --> 1
In [69]: pd.to_datetime([1, 2, 3], unit="D")
Out[69]: DatetimeIndex(['1970-01-02', '1970-01-03', '1970-01-04'], dtype='datetime64[ns]', freq=None)

---->   pandas.to_datetime

--------------------------------------
ID: 4694 --> 2
In [70]: dates = [
   ....:     datetime.datetime(2012, 5, 1),
   ....:     datetime.datetime(2012, 5, 2),
   ....:     datetime.datetime(2012, 5, 3),
   ....: ]
   ....: 

# Note the frequency information
In [71]: index = pd.DatetimeIndex(dates)

In [72]: index
Out[72]: DatetimeIndex(['2012-05-01', '2012-05-02', '2012-05-03'], dtype='datetime64[ns]', freq=None)

# Automatically converted to DatetimeIndex
In [73]: index = pd.Index(dates)

In [74]: index
Out[74]: DatetimeIndex(['2012-05-01', '2012-05-02', '2012-05-03'], dtype='datetime64[ns]', freq=None)

---->   pandas.DatetimeIndex; pandas.Index

--------------------------------------
ID: 4695 --> 1
In [75]: start = datetime.datetime(2011, 1, 1)

In [76]: end = datetime.datetime(2012, 1, 1)

In [77]: index = pd.date_range(start, end)

In [78]: index
Out[78]: 
DatetimeIndex(['2011-01-01', '2011-01-02', '2011-01-03', '2011-01-04',
               '2011-01-05', '2011-01-06', '2011-01-07', '2011-01-08',
               '2011-01-09', '2011-01-10',
               ...
               '2011-12-23', '2011-12-24', '2011-12-25', '2011-12-26',
               '2011-12-27', '2011-12-28', '2011-12-29', '2011-12-30',
               '2011-12-31', '2012-01-01'],
              dtype='datetime64[ns]', length=366, freq='D')

In [79]: index = pd.bdate_range(start, end)

In [80]: index
Out[80]: 
DatetimeIndex(['2011-01-03', '2011-01-04', '2011-01-05', '2011-01-06',
               '2011-01-07', '2011-01-10', '2011-01-11', '2011-01-12',
               '2011-01-13', '2011-01-14',
               ...
               '2011-12-19', '2011-12-20', '2011-12-21', '2011-12-22',
               '2011-12-23', '2011-12-26', '2011-12-27', '2011-12-28',
               '2011-12-29', '2011-12-30'],
              dtype='datetime64[ns]', length=260, freq='B')

---->   pandas.bdate_range

--------------------------------------
ID: 4696 --> 1
In [81]: pd.date_range(start, periods=1000, freq="M")
Out[81]: 
DatetimeIndex(['2011-01-31', '2011-02-28', '2011-03-31', '2011-04-30',
               '2011-05-31', '2011-06-30', '2011-07-31', '2011-08-31',
               '2011-09-30', '2011-10-31',
               ...
               '2093-07-31', '2093-08-31', '2093-09-30', '2093-10-31',
               '2093-11-30', '2093-12-31', '2094-01-31', '2094-02-28',
               '2094-03-31', '2094-04-30'],
              dtype='datetime64[ns]', length=1000, freq='M')

In [82]: pd.bdate_range(start, periods=250, freq="BQS")
Out[82]: 
DatetimeIndex(['2011-01-03', '2011-04-01', '2011-07-01', '2011-10-03',
               '2012-01-02', '2012-04-02', '2012-07-02', '2012-10-01',
               '2013-01-01', '2013-04-01',
               ...
               '2071-01-01', '2071-04-01', '2071-07-01', '2071-10-01',
               '2072-01-01', '2072-04-01', '2072-07-01', '2072-10-03',
               '2073-01-02', '2073-04-03'],
              dtype='datetime64[ns]', length=250, freq='BQS-JAN')

---->   pandas.bdate_range

--------------------------------------
ID: 4697 --> 1
In [83]: pd.date_range(start, end, freq="BM")
Out[83]: 
DatetimeIndex(['2011-01-31', '2011-02-28', '2011-03-31', '2011-04-29',
               '2011-05-31', '2011-06-30', '2011-07-29', '2011-08-31',
               '2011-09-30', '2011-10-31', '2011-11-30', '2011-12-30'],
              dtype='datetime64[ns]', freq='BM')

In [84]: pd.date_range(start, end, freq="W")
Out[84]: 
DatetimeIndex(['2011-01-02', '2011-01-09', '2011-01-16', '2011-01-23',
               '2011-01-30', '2011-02-06', '2011-02-13', '2011-02-20',
               '2011-02-27', '2011-03-06', '2011-03-13', '2011-03-20',
               '2011-03-27', '2011-04-03', '2011-04-10', '2011-04-17',
               '2011-04-24', '2011-05-01', '2011-05-08', '2011-05-15',
               '2011-05-22', '2011-05-29', '2011-06-05', '2011-06-12',
               '2011-06-19', '2011-06-26', '2011-07-03', '2011-07-10',
               '2011-07-17', '2011-07-24', '2011-07-31', '2011-08-07',
               '2011-08-14', '2011-08-21', '2011-08-28', '2011-09-04',
               '2011-09-11', '2011-09-18', '2011-09-25', '2011-10-02',
               '2011-10-09', '2011-10-16', '2011-10-23', '2011-10-30',
               '2011-11-06', '2011-11-13', '2011-11-20', '2011-11-27',
               '2011-12-04', '2011-12-11', '2011-12-18', '2011-12-25',
               '2012-01-01'],
              dtype='datetime64[ns]', freq='W-SUN')

In [85]: pd.bdate_range(end=end, periods=20)
Out[85]: 
DatetimeIndex(['2011-12-05', '2011-12-06', '2011-12-07', '2011-12-08',
               '2011-12-09', '2011-12-12', '2011-12-13', '2011-12-14',
               '2011-12-15', '2011-12-16', '2011-12-19', '2011-12-20',
               '2011-12-21', '2011-12-22', '2011-12-23', '2011-12-26',
               '2011-12-27', '2011-12-28', '2011-12-29', '2011-12-30'],
              dtype='datetime64[ns]', freq='B')

In [86]: pd.bdate_range(start=start, periods=20)
Out[86]: 
DatetimeIndex(['2011-01-03', '2011-01-04', '2011-01-05', '2011-01-06',
               '2011-01-07', '2011-01-10', '2011-01-11', '2011-01-12',
               '2011-01-13', '2011-01-14', '2011-01-17', '2011-01-18',
               '2011-01-19', '2011-01-20', '2011-01-21', '2011-01-24',
               '2011-01-25', '2011-01-26', '2011-01-27', '2011-01-28'],
              dtype='datetime64[ns]', freq='B')

---->   pandas.bdate_range

--------------------------------------
ID: 4699 --> 1
In [89]: weekmask = "Mon Wed Fri"

In [90]: holidays = [datetime.datetime(2011, 1, 5), datetime.datetime(2011, 3, 14)]

In [91]: pd.bdate_range(start, end, freq="C", weekmask=weekmask, holidays=holidays)
Out[91]: 
DatetimeIndex(['2011-01-03', '2011-01-07', '2011-01-10', '2011-01-12',
               '2011-01-14', '2011-01-17', '2011-01-19', '2011-01-21',
               '2011-01-24', '2011-01-26',
               ...
               '2011-12-09', '2011-12-12', '2011-12-14', '2011-12-16',
               '2011-12-19', '2011-12-21', '2011-12-23', '2011-12-26',
               '2011-12-28', '2011-12-30'],
              dtype='datetime64[ns]', length=154, freq='C')

In [92]: pd.bdate_range(start, end, freq="CBMS", weekmask=weekmask)
Out[92]: 
DatetimeIndex(['2011-01-03', '2011-02-02', '2011-03-02', '2011-04-01',
               '2011-05-02', '2011-06-01', '2011-07-01', '2011-08-01',
               '2011-09-02', '2011-10-03', '2011-11-02', '2011-12-02'],
              dtype='datetime64[ns]', freq='CBMS')

---->   pandas.bdate_range

--------------------------------------
ID: 4701 --> 1
In [95]: rng = pd.date_range(start, end, freq="BM")

In [96]: ts = pd.Series(np.random.randn(len(rng)), index=rng)

In [97]: ts.index
Out[97]: 
DatetimeIndex(['2011-01-31', '2011-02-28', '2011-03-31', '2011-04-29',
               '2011-05-31', '2011-06-30', '2011-07-29', '2011-08-31',
               '2011-09-30', '2011-10-31', '2011-11-30', '2011-12-30'],
              dtype='datetime64[ns]', freq='BM')

In [98]: ts[:5].index
Out[98]: 
DatetimeIndex(['2011-01-31', '2011-02-28', '2011-03-31', '2011-04-29',
               '2011-05-31'],
              dtype='datetime64[ns]', freq='BM')

In [99]: ts[::2].index
Out[99]: 
DatetimeIndex(['2011-01-31', '2011-03-31', '2011-05-31', '2011-07-29',
               '2011-09-30', '2011-11-30'],
              dtype='datetime64[ns]', freq='2BM')

---->   pandas.Series

--------------------------------------
ID: 4703 --> 1
In [105]: dft = pd.DataFrame(
   .....:     np.random.randn(100000, 1),
   .....:     columns=["A"],
   .....:     index=pd.date_range("20130101", periods=100000, freq="T"),
   .....: )
   .....: 

In [106]: dft
Out[106]: 
                            A
2013-01-01 00:00:00  0.276232
2013-01-01 00:01:00 -1.087401
2013-01-01 00:02:00 -0.673690
2013-01-01 00:03:00  0.113648
2013-01-01 00:04:00 -1.478427
...                       ...
2013-03-11 10:35:00 -0.747967
2013-03-11 10:36:00 -0.034523
2013-03-11 10:37:00 -0.201754
2013-03-11 10:38:00 -1.509067
2013-03-11 10:39:00 -1.693043

[100000 rows x 1 columns]

In [107]: dft.loc["2013"]
Out[107]: 
                            A
2013-01-01 00:00:00  0.276232
2013-01-01 00:01:00 -1.087401
2013-01-01 00:02:00 -0.673690
2013-01-01 00:03:00  0.113648
2013-01-01 00:04:00 -1.478427
...                       ...
2013-03-11 10:35:00 -0.747967
2013-03-11 10:36:00 -0.034523
2013-03-11 10:37:00 -0.201754
2013-03-11 10:38:00 -1.509067
2013-03-11 10:39:00 -1.693043

[100000 rows x 1 columns]

---->   pandas.DataFrame

--------------------------------------
ID: 4704 --> 2
In [112]: dft2 = pd.DataFrame(
   .....:     np.random.randn(20, 1),
   .....:     columns=["A"],
   .....:     index=pd.MultiIndex.from_product(
   .....:         [pd.date_range("20130101", periods=10, freq="12H"), ["a", "b"]]
   .....:     ),
   .....: )
   .....: 

In [113]: dft2
Out[113]: 
                              A
2013-01-01 00:00:00 a -0.298694
                    b  0.823553
2013-01-01 12:00:00 a  0.943285
                    b -1.479399
2013-01-02 00:00:00 a -1.643342
...                         ...
2013-01-04 12:00:00 b  0.069036
2013-01-05 00:00:00 a  0.122297
                    b  1.422060
2013-01-05 12:00:00 a  0.370079
                    b  1.016331

[20 rows x 1 columns]

In [114]: dft2.loc["2013-01-05"]
Out[114]: 
                              A
2013-01-05 00:00:00 a  0.122297
                    b  1.422060
2013-01-05 12:00:00 a  0.370079
                    b  1.016331

In [115]: idx = pd.IndexSlice

In [116]: dft2 = dft2.swaplevel(0, 1).sort_index()

In [117]: dft2.loc[idx[:, "2013-01-05"], :]
Out[117]: 
                              A
a 2013-01-05 00:00:00  0.122297
  2013-01-05 12:00:00  0.370079
b 2013-01-05 00:00:00  1.422060
  2013-01-05 12:00:00  1.016331

---->   pandas.DataFrame; pandas.MultiIndex

--------------------------------------
ID: 4705 --> 2
In [118]: df = pd.DataFrame([0], index=pd.DatetimeIndex(["2019-01-01"], tz="US/Pacific"))

In [119]: df
Out[119]: 
                           0
2019-01-01 00:00:00-08:00  0

In [120]: df["2019-01-01 12:00:00+04:00":"2019-01-01 13:00:00+04:00"]
Out[120]: 
                           0
2019-01-01 00:00:00-08:00  0

---->   pandas.DataFrame; pandas.DatetimeIndex

--------------------------------------
ID: 4706 --> 2
In [121]: series_minute = pd.Series(
   .....:     [1, 2, 3],
   .....:     pd.DatetimeIndex(
   .....:         ["2011-12-31 23:59:00", "2012-01-01 00:00:00", "2012-01-01 00:02:00"]
   .....:     ),
   .....: )
   .....: 

In [122]: series_minute.index.resolution
Out[122]: 'minute'

---->   pandas.Series; pandas.DatetimeIndex

--------------------------------------
ID: 4707 --> 2
In [126]: series_second = pd.Series(
   .....:     [1, 2, 3],
   .....:     pd.DatetimeIndex(
   .....:         ["2011-12-31 23:59:59", "2012-01-01 00:00:00", "2012-01-01 00:00:01"]
   .....:     ),
   .....: )
   .....: 

In [127]: series_second.index.resolution
Out[127]: 'second'

In [128]: series_second["2011-12-31 23:59"]
Out[128]: 
2011-12-31 23:59:59    1
dtype: int64

---->   pandas.Series; pandas.DatetimeIndex

--------------------------------------
ID: 4708 --> 1
In [129]: dft_minute = pd.DataFrame(
   .....:     {"a": [1, 2, 3], "b": [4, 5, 6]}, index=series_minute.index
   .....: )
   .....: 

In [130]: dft_minute.loc["2011-12-31 23"]
Out[130]: 
                     a  b
2011-12-31 23:59:00  1  4

---->   pandas.DataFrame

--------------------------------------
ID: 4709 --> 2
In [132]: series_monthly = pd.Series(
   .....:     [1, 2, 3], pd.DatetimeIndex(["2011-12", "2012-01", "2012-02"])
   .....: )
   .....: 

In [133]: series_monthly.index.resolution
Out[133]: 'day'

In [134]: series_monthly["2011-12"]  # returns Series
Out[134]: 
2011-12-01    1
dtype: int64

---->   pandas.Series; pandas.DatetimeIndex

--------------------------------------
ID: 4712 --> 2
In [137]: rng2 = pd.date_range("2011-01-01", "2012-01-01", freq="W")

In [138]: ts2 = pd.Series(np.random.randn(len(rng2)), index=rng2)

In [139]: ts2.truncate(before="2011-11", after="2011-12")
Out[139]: 
2011-11-06    0.437823
2011-11-13   -0.293083
2011-11-20   -0.059881
2011-11-27    1.252450
Freq: W-SUN, dtype: float64

In [140]: ts2["2011-11":"2011-12"]
Out[140]: 
2011-11-06    0.437823
2011-11-13   -0.293083
2011-11-20   -0.059881
2011-11-27    1.252450
2011-12-04    0.046611
2011-12-11    0.059478
2011-12-18   -0.286539
2011-12-25    0.841669
Freq: W-SUN, dtype: float64

---->   pandas.Series; Series.truncate

--------------------------------------
ID: 4721 --> 1
In [177]: rng = pd.date_range("2012-01-01", "2012-01-03")

In [178]: s = pd.Series(rng)

In [179]: rng
Out[179]: DatetimeIndex(['2012-01-01', '2012-01-02', '2012-01-03'], dtype='datetime64[ns]', freq='D')

In [180]: rng + pd.DateOffset(months=2)
Out[180]: DatetimeIndex(['2012-03-01', '2012-03-02', '2012-03-03'], dtype='datetime64[ns]', freq=None)

In [181]: s + pd.DateOffset(months=2)
Out[181]: 
0   2012-03-01
1   2012-03-02
2   2012-03-03
dtype: datetime64[ns]

In [182]: s - pd.DateOffset(months=2)
Out[182]: 
0   2011-11-01
1   2011-11-02
2   2011-11-03
dtype: datetime64[ns]

---->   pandas.Series

--------------------------------------
ID: 4722 --> 1
In [183]: s - pd.offsets.Day(2)
Out[183]: 
0   2011-12-30
1   2011-12-31
2   2012-01-01
dtype: datetime64[ns]

In [184]: td = s - pd.Series(pd.date_range("2011-12-29", "2011-12-31"))

In [185]: td
Out[185]: 
0   3 days
1   3 days
2   3 days
dtype: timedelta64[ns]

In [186]: td + pd.offsets.Minute(15)
Out[186]: 
0   3 days 00:15:00
1   3 days 00:15:00
2   3 days 00:15:00
dtype: timedelta64[ns]

---->   pandas.Series

--------------------------------------
ID: 4725 --> 1
In [193]: dts = pd.date_range(dt, periods=5, freq=bday_egypt)

In [194]: pd.Series(dts.weekday, dts).map(pd.Series("Mon Tue Wed Thu Fri Sat Sun".split()))
Out[194]: 
2013-04-30    Tue
2013-05-02    Thu
2013-05-05    Sun
2013-05-06    Mon
2013-05-07    Tue
Freq: C, dtype: object

---->   pandas.Series

--------------------------------------
ID: 4745 --> 2
In [279]: ts = pd.Series(range(len(rng)), index=rng)

In [280]: ts = ts[:5]

In [281]: ts.shift(1)
Out[281]: 
2012-01-01    NaN
2012-01-02    0.0
2012-01-03    1.0
Freq: D, dtype: float64

---->   pandas.Series; Series.shift

--------------------------------------
ID: 4746 --> 1
In [282]: ts.shift(5, freq="D")
Out[282]: 
2012-01-06    0
2012-01-07    1
2012-01-08    2
Freq: D, dtype: int64

In [283]: ts.shift(5, freq=pd.offsets.BDay())
Out[283]: 
2012-01-06    0
2012-01-09    1
2012-01-10    2
dtype: int64

In [284]: ts.shift(5, freq="BM")
Out[284]: 
2012-05-31    0
2012-05-31    1
2012-05-31    2
dtype: int64

---->   Series.shift

--------------------------------------
ID: 4747 --> 2
In [285]: dr = pd.date_range("1/1/2010", periods=3, freq=3 * pd.offsets.BDay())

In [286]: ts = pd.Series(np.random.randn(3), index=dr)

In [287]: ts
Out[287]: 
2010-01-01    1.494522
2010-01-06   -0.778425
2010-01-11   -0.253355
Freq: 3B, dtype: float64

In [288]: ts.asfreq(pd.offsets.BDay())
Out[288]: 
2010-01-01    1.494522
2010-01-04         NaN
2010-01-05         NaN
2010-01-06   -0.778425
2010-01-07         NaN
2010-01-08         NaN
2010-01-11   -0.253355
Freq: B, dtype: float64

---->   pandas.Series; Series.asfreq

--------------------------------------
ID: 4748 --> 1
In [289]: ts.asfreq(pd.offsets.BDay(), method="pad")
Out[289]: 
2010-01-01    1.494522
2010-01-04    1.494522
2010-01-05    1.494522
2010-01-06   -0.778425
2010-01-07   -0.778425
2010-01-08   -0.778425
2010-01-11   -0.253355
Freq: B, dtype: float64

---->   Series.asfreq

--------------------------------------
ID: 4749 --> 2
In [290]: rng = pd.date_range("1/1/2012", periods=100, freq="S")

In [291]: ts = pd.Series(np.random.randint(0, 500, len(rng)), index=rng)

In [292]: ts.resample("5Min").sum()
Out[292]: 
2012-01-01    25103
Freq: 5T, dtype: int64

---->   pandas.Series; Series.resample

--------------------------------------
ID: 4750 --> 1
In [293]: ts.resample("5Min").mean()
Out[293]: 
2012-01-01    251.03
Freq: 5T, dtype: float64

In [294]: ts.resample("5Min").ohlc()
Out[294]: 
            open  high  low  close
2012-01-01   308   460    9    205

In [295]: ts.resample("5Min").max()
Out[295]: 
2012-01-01    460
Freq: 5T, dtype: int64

---->   Series.resample

--------------------------------------
ID: 4751 --> 1
In [296]: ts.resample("5Min", closed="right").mean()
Out[296]: 
2011-12-31 23:55:00    308.000000
2012-01-01 00:00:00    250.454545
Freq: 5T, dtype: float64

In [297]: ts.resample("5Min", closed="left").mean()
Out[297]: 
2012-01-01    251.03
Freq: 5T, dtype: float64

---->   Series.resample

--------------------------------------
ID: 4752 --> 1
In [298]: ts.resample("5Min").mean()  # by default label='left'
Out[298]: 
2012-01-01    251.03
Freq: 5T, dtype: float64

In [299]: ts.resample("5Min", label="left").mean()
Out[299]: 
2012-01-01    251.03
Freq: 5T, dtype: float64

---->   Series.resample

--------------------------------------
ID: 4753 --> 1
In [300]: s = pd.date_range("2000-01-01", "2000-01-05").to_series()

In [301]: s.iloc[2] = pd.NaT

In [302]: s.dt.day_name()
Out[302]: 
2000-01-01     Saturday
2000-01-02       Sunday
2000-01-03          NaN
2000-01-04      Tuesday
2000-01-05    Wednesday
Freq: D, dtype: object

# default: label='left', closed='left'
In [303]: s.resample("B").last().dt.day_name()
Out[303]: 
1999-12-31       Sunday
2000-01-03          NaN
2000-01-04      Tuesday
2000-01-05    Wednesday
Freq: B, dtype: object

---->   Series.resample

--------------------------------------
ID: 4754 --> 1
In [304]: s.resample("B", label="right", closed="right").last().dt.day_name()
Out[304]: 
2000-01-03       Sunday
2000-01-04      Tuesday
2000-01-05    Wednesday
Freq: B, dtype: object

---->   Series.resample

--------------------------------------
ID: 4756 --> 1
In [308]: rng = pd.date_range("2014-1-1", periods=100, freq="D") + pd.Timedelta("1s")

In [309]: ts = pd.Series(range(100), index=rng)

---->   pandas.Series

--------------------------------------
ID: 4757 --> 1
In [310]: ts.resample("3T").sum()
Out[310]: 
2014-01-01 00:00:00     0
2014-01-01 00:03:00     0
2014-01-01 00:06:00     0
2014-01-01 00:09:00     0
2014-01-01 00:12:00     0
                       ..
2014-04-09 23:48:00     0
2014-04-09 23:51:00     0
2014-04-09 23:54:00     0
2014-04-09 23:57:00     0
2014-04-10 00:00:00    99
Freq: 3T, Length: 47521, dtype: int64

---->   Series.resample

--------------------------------------
ID: 4758 --> 1
In [311]: from functools import partial

In [312]: from pandas.tseries.frequencies import to_offset

In [313]: def round(t, freq):
   .....:     freq = to_offset(freq)
   .....:     return pd.Timestamp((t.value // freq.delta.value) * freq.delta.value)
   .....: 

In [314]: ts.groupby(partial(round, freq="3T")).sum()
Out[314]: 
2014-01-01     0
2014-01-02     1
2014-01-03     2
2014-01-04     3
2014-01-05     4
              ..
2014-04-06    95
2014-04-07    96
2014-04-08    97
2014-04-09    98
2014-04-10    99
Length: 100, dtype: int64

---->   Series.groupby

--------------------------------------
ID: 4759 --> 2
In [315]: df = pd.DataFrame(
   .....:     np.random.randn(1000, 3),
   .....:     index=pd.date_range("1/1/2012", freq="S", periods=1000),
   .....:     columns=["A", "B", "C"],
   .....: )
   .....: 

In [316]: r = df.resample("3T")

In [317]: r.mean()
Out[317]: 
                            A         B         C
2012-01-01 00:00:00 -0.033823 -0.121514 -0.081447
2012-01-01 00:03:00  0.056909  0.146731 -0.024320
2012-01-01 00:06:00 -0.058837  0.047046 -0.052021
2012-01-01 00:09:00  0.063123 -0.026158 -0.066533
2012-01-01 00:12:00  0.186340 -0.003144  0.074752
2012-01-01 00:15:00 -0.085954 -0.016287 -0.050046

---->   pandas.DataFrame; DataFrame.resample

--------------------------------------
ID: 4766 --> 3
In [325]: df = pd.DataFrame(
   .....:     {"date": pd.date_range("2015-01-01", freq="W", periods=5), "a": np.arange(5)},
   .....:     index=pd.MultiIndex.from_arrays(
   .....:         [[1, 2, 3, 4, 5], pd.date_range("2015-01-01", freq="W", periods=5)],
   .....:         names=["v", "d"],
   .....:     ),
   .....: )
   .....: 

In [326]: df
Out[326]: 
                   date  a
v d                       
1 2015-01-04 2015-01-04  0
2 2015-01-11 2015-01-11  1
3 2015-01-18 2015-01-18  2
4 2015-01-25 2015-01-25  3
5 2015-02-01 2015-02-01  4

In [327]: df.resample("M", on="date")[["a"]].sum()
Out[327]: 
            a
date         
2015-01-31  6
2015-02-28  4

---->   pandas.DataFrame; pandas.MultiIndex; DataFrame.resample

--------------------------------------
ID: 4767 --> 1
In [328]: df.resample("M", level="d")[["a"]].sum()
Out[328]: 
            a
d            
2015-01-31  6
2015-02-28  4

---->   DataFrame.resample

--------------------------------------
ID: 4768 --> 2
In [329]: small = pd.Series(
   .....:     range(6),
   .....:     index=pd.to_datetime(
   .....:         [
   .....:             "2017-01-01T00:00:00",
   .....:             "2017-01-01T00:30:00",
   .....:             "2017-01-01T00:31:00",
   .....:             "2017-01-01T01:00:00",
   .....:             "2017-01-01T03:00:00",
   .....:             "2017-01-01T03:05:00",
   .....:         ]
   .....:     ),
   .....: )
   .....: 

In [330]: resampled = small.resample("H")

In [331]: for name, group in resampled:
   .....:     print("Group: ", name)
   .....:     print("-" * 27)
   .....:     print(group, end="\n\n")
   .....: 
Group:  2017-01-01 00:00:00
---------------------------
2017-01-01 00:00:00    0
2017-01-01 00:30:00    1
2017-01-01 00:31:00    2
dtype: int64

Group:  2017-01-01 01:00:00
---------------------------
2017-01-01 01:00:00    3
dtype: int64

Group:  2017-01-01 02:00:00
---------------------------
Series([], dtype: int64)

Group:  2017-01-01 03:00:00
---------------------------
2017-01-01 03:00:00    4
2017-01-01 03:05:00    5
dtype: int64

---->   pandas.Series; pandas.to_datetime

--------------------------------------
ID: 4769 --> 1
In [332]: start, end = "2000-10-01 23:30:00", "2000-10-02 00:30:00"

In [333]: middle = "2000-10-02 00:00:00"

In [334]: rng = pd.date_range(start, end, freq="7min")

In [335]: ts = pd.Series(np.arange(len(rng)) * 3, index=rng)

In [336]: ts
Out[336]: 
2000-10-01 23:30:00     0
2000-10-01 23:37:00     3
2000-10-01 23:44:00     6
2000-10-01 23:51:00     9
2000-10-01 23:58:00    12
2000-10-02 00:05:00    15
2000-10-02 00:12:00    18
2000-10-02 00:19:00    21
2000-10-02 00:26:00    24
Freq: 7T, dtype: int64

---->   pandas.Series

--------------------------------------
ID: 4770 --> 1
In [337]: ts.resample("17min", origin="start_day").sum()
Out[337]: 
2000-10-01 23:14:00     0
2000-10-01 23:31:00     9
2000-10-01 23:48:00    21
2000-10-02 00:05:00    54
2000-10-02 00:22:00    24
Freq: 17T, dtype: int64

In [338]: ts[middle:end].resample("17min", origin="start_day").sum()
Out[338]: 
2000-10-02 00:00:00    33
2000-10-02 00:17:00    45
Freq: 17T, dtype: int64

---->   Series.resample

--------------------------------------
ID: 4771 --> 1
In [339]: ts.resample("17min", origin="epoch").sum()
Out[339]: 
2000-10-01 23:18:00     0
2000-10-01 23:35:00    18
2000-10-01 23:52:00    27
2000-10-02 00:09:00    39
2000-10-02 00:26:00    24
Freq: 17T, dtype: int64

In [340]: ts[middle:end].resample("17min", origin="epoch").sum()
Out[340]: 
2000-10-01 23:52:00    15
2000-10-02 00:09:00    39
2000-10-02 00:26:00    24
Freq: 17T, dtype: int64

---->   Series.resample

--------------------------------------
ID: 4772 --> 1
In [341]: ts.resample("17min", origin="2001-01-01").sum()
Out[341]: 
2000-10-01 23:30:00     9
2000-10-01 23:47:00    21
2000-10-02 00:04:00    54
2000-10-02 00:21:00    24
Freq: 17T, dtype: int64

In [342]: ts[middle:end].resample("17min", origin=pd.Timestamp("2001-01-01")).sum()
Out[342]: 
2000-10-02 00:04:00    54
2000-10-02 00:21:00    24
Freq: 17T, dtype: int64

---->   Series.resample

--------------------------------------
ID: 4773 --> 1
In [343]: ts.resample("17min", origin="start").sum()
Out[343]: 
2000-10-01 23:30:00     9
2000-10-01 23:47:00    21
2000-10-02 00:04:00    54
2000-10-02 00:21:00    24
Freq: 17T, dtype: int64

In [344]: ts.resample("17min", offset="23h30min").sum()
Out[344]: 
2000-10-01 23:30:00     9
2000-10-01 23:47:00    21
2000-10-02 00:04:00    54
2000-10-02 00:21:00    24
Freq: 17T, dtype: int64

---->   Series.resample

--------------------------------------
ID: 4774 --> 1
In [345]: ts.resample('17min', origin='end').sum()
Out[345]: 
2000-10-01 23:35:00     0
2000-10-01 23:52:00    18
2000-10-02 00:09:00    27
2000-10-02 00:26:00    63
Freq: 17T, dtype: int64

---->   Series.resample

--------------------------------------
ID: 4775 --> 1
In [346]: ts.resample('17min', origin='end_day').sum()
Out[346]: 
2000-10-01 23:38:00     3
2000-10-01 23:55:00    15
2000-10-02 00:12:00    45
2000-10-02 00:29:00    45
Freq: 17T, dtype: int64

---->   Series.resample

--------------------------------------
ID: 4777 --> 1
In [351]: pd.Period("2012", freq="A-DEC")
Out[351]: Period('2012', 'A-DEC')

In [352]: pd.Period("2012-1-1", freq="D")
Out[352]: Period('2012-01-01', 'D')

In [353]: pd.Period("2012-1-1 19:00", freq="H")
Out[353]: Period('2012-01-01 19:00', 'H')

In [354]: pd.Period("2012-1-1 19:00", freq="5H")
Out[354]: Period('2012-01-01 19:00', '5H')

---->   pandas.Period

--------------------------------------
ID: 4778 --> 1
In [355]: p = pd.Period("2012", freq="A-DEC")

In [356]: p + 1
Out[356]: Period('2013', 'A-DEC')

In [357]: p - 3
Out[357]: Period('2009', 'A-DEC')

In [358]: p = pd.Period("2012-01", freq="2M")

In [359]: p + 2
Out[359]: Period('2012-05', '2M')

In [360]: p - 1
Out[360]: Period('2011-11', '2M')

In [361]: p == pd.Period("2012-01", freq="3M")
Out[361]: False

---->   pandas.Period

--------------------------------------
ID: 4779 --> 1
In [362]: p = pd.Period("2014-07-01 09:00", freq="H")

In [363]: p + pd.offsets.Hour(2)
Out[363]: Period('2014-07-01 11:00', 'H')

In [364]: p + datetime.timedelta(minutes=120)
Out[364]: Period('2014-07-01 11:00', 'H')

In [365]: p + np.timedelta64(7200, "s")
Out[365]: Period('2014-07-01 11:00', 'H')

---->   pandas.Period

--------------------------------------
ID: 4781 --> 1
In [366]: p = pd.Period("2014-07", freq="M")

In [367]: p + pd.offsets.MonthEnd(3)
Out[367]: Period('2014-10', 'M')

---->   pandas.Period

--------------------------------------
ID: 4783 --> 1
In [368]: pd.Period("2012", freq="A-DEC") - pd.Period("2002", freq="A-DEC")
Out[368]: <10 * YearEnds: month=12>

---->   pandas.Period

--------------------------------------
ID: 4784 --> 1
In [369]: prng = pd.period_range("1/1/2011", "1/1/2012", freq="M")

In [370]: prng
Out[370]: 
PeriodIndex(['2011-01', '2011-02', '2011-03', '2011-04', '2011-05', '2011-06',
             '2011-07', '2011-08', '2011-09', '2011-10', '2011-11', '2011-12',
             '2012-01'],
            dtype='period[M]')

---->   pandas.period_range

--------------------------------------
ID: 4785 --> 1
In [371]: pd.PeriodIndex(["2011-1", "2011-2", "2011-3"], freq="M")
Out[371]: PeriodIndex(['2011-01', '2011-02', '2011-03'], dtype='period[M]')

---->   pandas.PeriodIndex

--------------------------------------
ID: 4786 --> 1
In [372]: pd.period_range(start="2014-01", freq="3M", periods=4)
Out[372]: PeriodIndex(['2014-01', '2014-04', '2014-07', '2014-10'], dtype='period[3M]')

---->   pandas.period_range

--------------------------------------
ID: 4787 --> 2
In [373]: pd.period_range(
   .....:     start=pd.Period("2017Q1", freq="Q"), end=pd.Period("2017Q2", freq="Q"), freq="M"
   .....: )
   .....: 
Out[373]: PeriodIndex(['2017-03', '2017-04', '2017-05', '2017-06'], dtype='period[M]')

---->   pandas.period_range; pandas.Period

--------------------------------------
ID: 4788 --> 1
In [374]: ps = pd.Series(np.random.randn(len(prng)), prng)

In [375]: ps
Out[375]: 
2011-01   -2.916901
2011-02    0.514474
2011-03    1.346470
2011-04    0.816397
2011-05    2.258648
2011-06    0.494789
2011-07    0.301239
2011-08    0.464776
2011-09   -1.393581
2011-10    0.056780
2011-11    0.197035
2011-12    2.261385
2012-01   -0.329583
Freq: M, dtype: float64

---->   pandas.Series

--------------------------------------
ID: 4789 --> 1
In [376]: idx = pd.period_range("2014-07-01 09:00", periods=5, freq="H")

In [377]: idx
Out[377]: 
PeriodIndex(['2014-07-01 09:00', '2014-07-01 10:00', '2014-07-01 11:00',
             '2014-07-01 12:00', '2014-07-01 13:00'],
            dtype='period[H]')

In [378]: idx + pd.offsets.Hour(2)
Out[378]: 
PeriodIndex(['2014-07-01 11:00', '2014-07-01 12:00', '2014-07-01 13:00',
             '2014-07-01 14:00', '2014-07-01 15:00'],
            dtype='period[H]')

In [379]: idx = pd.period_range("2014-07", periods=5, freq="M")

In [380]: idx
Out[380]: PeriodIndex(['2014-07', '2014-08', '2014-09', '2014-10', '2014-11'], dtype='period[M]')

In [381]: idx + pd.offsets.MonthEnd(3)
Out[381]: PeriodIndex(['2014-10', '2014-11', '2014-12', '2015-01', '2015-02'], dtype='period[M]')

---->   pandas.period_range

--------------------------------------
ID: 4790 --> 1
In [382]: pi = pd.period_range("2016-01-01", periods=3, freq="M")

In [383]: pi
Out[383]: PeriodIndex(['2016-01', '2016-02', '2016-03'], dtype='period[M]')

In [384]: pi.dtype
Out[384]: period[M]

---->   pandas.period_range

--------------------------------------
ID: 4793 --> 2
In [393]: ps["2011"]
Out[393]: 
2011-01   -2.916901
2011-02    0.514474
2011-03    1.346470
2011-04    0.816397
2011-05    2.258648
2011-06    0.494789
2011-07    0.301239
2011-08    0.464776
2011-09   -1.393581
2011-10    0.056780
2011-11    0.197035
2011-12    2.261385
Freq: M, dtype: float64

In [394]: dfp = pd.DataFrame(
   .....:     np.random.randn(600, 1),
   .....:     columns=["A"],
   .....:     index=pd.period_range("2013-01-01 9:00", periods=600, freq="T"),
   .....: )
   .....: 

In [395]: dfp
Out[395]: 
                         A
2013-01-01 09:00 -0.538468
2013-01-01 09:01 -1.365819
2013-01-01 09:02 -0.969051
2013-01-01 09:03 -0.331152
2013-01-01 09:04 -0.245334
...                    ...
2013-01-01 18:55  0.522460
2013-01-01 18:56  0.118710
2013-01-01 18:57  0.167517
2013-01-01 18:58  0.922883
2013-01-01 18:59  1.721104

[600 rows x 1 columns]

In [396]: dfp.loc["2013-01-01 10H"]
Out[396]: 
                         A
2013-01-01 10:00 -0.308975
2013-01-01 10:01  0.542520
2013-01-01 10:02  1.061068
2013-01-01 10:03  0.754005
2013-01-01 10:04  0.352933
...                    ...
2013-01-01 10:55 -0.865621
2013-01-01 10:56 -1.167818
2013-01-01 10:57 -2.081748
2013-01-01 10:58 -0.527146
2013-01-01 10:59  0.802298

[60 rows x 1 columns]

---->   pandas.DataFrame; pandas.period_range

--------------------------------------
ID: 4794 --> 1
In [398]: p = pd.Period("2011", freq="A-DEC")

In [399]: p
Out[399]: Period('2011', 'A-DEC')

---->   pandas.Period

--------------------------------------
ID: 4795 --> 1
In [400]: p.asfreq("M", how="start")
Out[400]: Period('2011-01', 'M')

In [401]: p.asfreq("M", how="end")
Out[401]: Period('2011-12', 'M')

---->   Period.asfreq

--------------------------------------
ID: 4796 --> 1
In [402]: p.asfreq("M", "s")
Out[402]: Period('2011-01', 'M')

In [403]: p.asfreq("M", "e")
Out[403]: Period('2011-12', 'M')

---->   Period.asfreq

--------------------------------------
ID: 4797 --> 2
In [404]: p = pd.Period("2011-12", freq="M")

In [405]: p.asfreq("A-NOV")
Out[405]: Period('2012', 'A-NOV')

---->   pandas.Period; Period.asfreq

--------------------------------------
ID: 4798 --> 2
In [406]: p = pd.Period("2012Q1", freq="Q-DEC")

In [407]: p.asfreq("D", "s")
Out[407]: Period('2012-01-01', 'D')

In [408]: p.asfreq("D", "e")
Out[408]: Period('2012-03-31', 'D')

---->   pandas.Period; Period.asfreq

--------------------------------------
ID: 4799 --> 2
In [409]: p = pd.Period("2011Q4", freq="Q-MAR")

In [410]: p.asfreq("D", "s")
Out[410]: Period('2011-01-01', 'D')

In [411]: p.asfreq("D", "e")
Out[411]: Period('2011-03-31', 'D')

---->   pandas.Period; Period.asfreq

--------------------------------------
ID: 4800 --> 3
In [412]: rng = pd.date_range("1/1/2012", periods=5, freq="M")

In [413]: ts = pd.Series(np.random.randn(len(rng)), index=rng)

In [414]: ts
Out[414]: 
2012-01-31    1.931253
2012-02-29   -0.184594
2012-03-31    0.249656
2012-04-30   -0.978151
2012-05-31   -0.873389
Freq: M, dtype: float64

In [415]: ps = ts.to_period()

In [416]: ps
Out[416]: 
2012-01    1.931253
2012-02   -0.184594
2012-03    0.249656
2012-04   -0.978151
2012-05   -0.873389
Freq: M, dtype: float64

In [417]: ps.to_timestamp()
Out[417]: 
2012-01-01    1.931253
2012-02-01   -0.184594
2012-03-01    0.249656
2012-04-01   -0.978151
2012-05-01   -0.873389
Freq: MS, dtype: float64

---->   pandas.Series; Series.to_period; Series.to_timestamp

--------------------------------------
ID: 4801 --> 1
In [418]: ps.to_timestamp("D", how="s")
Out[418]: 
2012-01-01    1.931253
2012-02-01   -0.184594
2012-03-01    0.249656
2012-04-01   -0.978151
2012-05-01   -0.873389
Freq: MS, dtype: float64

---->   Series.to_timestamp

--------------------------------------
ID: 4802 --> 3
In [419]: prng = pd.period_range("1990Q1", "2000Q4", freq="Q-NOV")

In [420]: ts = pd.Series(np.random.randn(len(prng)), prng)

In [421]: ts.index = (prng.asfreq("M", "e") + 1).asfreq("H", "s") + 9

In [422]: ts.head()
Out[422]: 
1990-03-01 09:00   -0.109291
1990-06-01 09:00   -0.637235
1990-09-01 09:00   -1.735925
1990-12-01 09:00    2.096946
1991-03-01 09:00   -1.039926
Freq: H, dtype: float64

---->   pandas.period_range; pandas.Series; Series.head

--------------------------------------
ID: 4803 --> 1
In [423]: span = pd.period_range("1215-01-01", "1381-01-01", freq="D")

In [424]: span
Out[424]: 
PeriodIndex(['1215-01-01', '1215-01-02', '1215-01-03', '1215-01-04',
             '1215-01-05', '1215-01-06', '1215-01-07', '1215-01-08',
             '1215-01-09', '1215-01-10',
             ...
             '1380-12-23', '1380-12-24', '1380-12-25', '1380-12-26',
             '1380-12-27', '1380-12-28', '1380-12-29', '1380-12-30',
             '1380-12-31', '1381-01-01'],
            dtype='period[D]', length=60632)

---->   pandas.period_range

--------------------------------------
ID: 4804 --> 2
In [425]: s = pd.Series([20121231, 20141130, 99991231])

In [426]: s
Out[426]: 
0    20121231
1    20141130
2    99991231
dtype: int64

In [427]: def conv(x):
   .....:     return pd.Period(year=x // 10000, month=x // 100 % 100, day=x % 100, freq="D")
   .....: 

In [428]: s.apply(conv)
Out[428]: 
0    2012-12-31
1    2014-11-30
2    9999-12-31
dtype: period[D]

In [429]: s.apply(conv)[2]
Out[429]: Period('9999-12-31', 'D')

---->   pandas.Series; pandas.Period

--------------------------------------
ID: 4805 --> 1
In [430]: span = pd.PeriodIndex(s.apply(conv))

In [431]: span
Out[431]: PeriodIndex(['2012-12-31', '2014-11-30', '9999-12-31'], dtype='period[D]')

---->   pandas.PeriodIndex

--------------------------------------
ID: 4814 --> 2
In [467]: ts_utc = pd.Series(range(3), pd.date_range("20130101", periods=3, tz="UTC"))

In [468]: eastern = ts_utc.tz_convert("US/Eastern")

In [469]: berlin = ts_utc.tz_convert("Europe/Berlin")

In [470]: result = eastern + berlin

In [471]: result
Out[471]: 
2013-01-01 00:00:00+00:00    0
2013-01-02 00:00:00+00:00    2
2013-01-03 00:00:00+00:00    4
Freq: D, dtype: int64

In [472]: result.index
Out[472]: 
DatetimeIndex(['2013-01-01 00:00:00+00:00', '2013-01-02 00:00:00+00:00',
               '2013-01-03 00:00:00+00:00'],
              dtype='datetime64[ns, UTC]', freq='D')

---->   pandas.Series; Series.tz_convert

--------------------------------------
ID: 4817 --> 1
In [480]: rng_hourly = pd.DatetimeIndex(
   .....:     ["11/06/2011 00:00", "11/06/2011 01:00", "11/06/2011 01:00", "11/06/2011 02:00"]
   .....: )
   .....: 

---->   pandas.DatetimeIndex

--------------------------------------
ID: 4823 --> 1
In [490]: s_naive = pd.Series(pd.date_range("20130101", periods=3))

In [491]: s_naive
Out[491]: 
0   2013-01-01
1   2013-01-02
2   2013-01-03
dtype: datetime64[ns]

---->   pandas.Series

--------------------------------------
ID: 4824 --> 1
In [492]: s_aware = pd.Series(pd.date_range("20130101", periods=3, tz="US/Eastern"))

In [493]: s_aware
Out[493]: 
0   2013-01-01 00:00:00-05:00
1   2013-01-02 00:00:00-05:00
2   2013-01-03 00:00:00-05:00
dtype: datetime64[ns, US/Eastern]

---->   pandas.Series

--------------------------------------
ID: 4826 --> 1
# convert to a new time zone
In [495]: s_aware.astype("datetime64[ns, CET]")
Out[495]: 
0   2013-01-01 06:00:00+01:00
1   2013-01-02 06:00:00+01:00
2   2013-01-03 06:00:00+01:00
dtype: datetime64[ns, CET]

---->   Series.astype

--------------------------------------
ID: 4827 --> 2
In [496]: s_naive.to_numpy()
Out[496]: 
array(['2013-01-01T00:00:00.000000000', '2013-01-02T00:00:00.000000000',
       '2013-01-03T00:00:00.000000000'], dtype='datetime64[ns]')

In [497]: s_aware.to_numpy()
Out[497]: 
array([Timestamp('2013-01-01 00:00:00-0500', tz='US/Eastern'),
       Timestamp('2013-01-02 00:00:00-0500', tz='US/Eastern'),
       Timestamp('2013-01-03 00:00:00-0500', tz='US/Eastern')],
      dtype=object)

---->   Series.to_numpy; Series.to_numpy

--------------------------------------
ID: 4828 --> 2
In [498]: pd.Series(s_aware.to_numpy())
Out[498]: 
0   2013-01-01 00:00:00-05:00
1   2013-01-02 00:00:00-05:00
2   2013-01-03 00:00:00-05:00
dtype: datetime64[ns, US/Eastern]

---->   pandas.Series; Series.to_numpy

--------------------------------------
ID: 4829 --> 1
In [499]: s_aware.to_numpy(dtype="datetime64[ns]")
Out[499]: 
array(['2013-01-01T05:00:00.000000000', '2013-01-02T05:00:00.000000000',
       '2013-01-03T05:00:00.000000000'], dtype='datetime64[ns]')

---->   Series.to_numpy

--------------------------------------
ID: 4830 --> 3
In [1]: ser = pd.Series([-1.5, 0.2, None], dtype="float32[pyarrow]")

In [2]: ser
Out[2]: 
0    -1.5
1     0.2
2    
dtype: float[pyarrow]

In [3]: idx = pd.Index([True, None], dtype="bool[pyarrow]")

In [4]: idx
Out[4]: Index([True, ], dtype='bool[pyarrow]')

In [5]: df = pd.DataFrame([[1, 2], [3, 4]], dtype="uint64[pyarrow]")

In [6]: df
Out[6]: 
   0  1
0  1  2
1  3  4

---->   pandas.Series; pandas.Index; pandas.DataFrame

--------------------------------------
ID: 4831 --> 2
In [7]: import pyarrow as pa

In [8]: data = list("abc")

In [9]: ser_sd = pd.Series(data, dtype="string[pyarrow]")

In [10]: ser_ad = pd.Series(data, dtype=pd.ArrowDtype(pa.string()))

In [11]: ser_ad.dtype == ser_sd.dtype
Out[11]: False

In [12]: ser_sd.str.contains("a")
Out[12]: 
0     True
1    False
2    False
dtype: boolean

In [13]: ser_ad.str.contains("a")
Out[13]: 
0     True
1    False
2    False
dtype: bool[pyarrow]

---->   pandas.Series; pandas.ArrowDtype

--------------------------------------
ID: 4832 --> 2
In [14]: import pyarrow as pa

In [15]: list_str_type = pa.list_(pa.string())

In [16]: ser = pd.Series([["hello"], ["there"]], dtype=pd.ArrowDtype(list_str_type))

In [17]: ser
Out[17]: 
0    ['hello']
1    ['there']
dtype: list[pyarrow]

---->   pandas.Series; pandas.ArrowDtype

--------------------------------------
ID: 4833 --> 2
In [18]: from datetime import time

In [19]: idx = pd.Index([time(12, 30), None], dtype=pd.ArrowDtype(pa.time64("us")))

In [20]: idx
Out[20]: Index([12:30:00, ], dtype='time64[us][pyarrow]')

---->   pandas.Index; pandas.ArrowDtype

--------------------------------------
ID: 4834 --> 2
In [21]: from decimal import Decimal

In [22]: decimal_type = pd.ArrowDtype(pa.decimal128(3, scale=2))

In [23]: data = [[Decimal("3.19"), None], [None, Decimal("-1.23")]]

In [24]: df = pd.DataFrame(data, dtype=decimal_type)

In [25]: df
Out[25]: 
      0      1
0  3.19   
1    -1.23

---->   pandas.ArrowDtype; pandas.DataFrame

--------------------------------------
ID: 4835 --> 1
In [26]: pa_array = pa.array(
   ....:     [{"1": "2"}, {"10": "20"}, None],
   ....:     type=pa.map_(pa.string(), pa.string()),
   ....: )
   ....: 

In [27]: ser = pd.Series(pd.arrays.ArrowExtensionArray(pa_array))

In [28]: ser
Out[28]: 
0      [('1', '2')]
1    [('10', '20')]
2              
dtype: map[pyarrow]

---->   pandas.Series

--------------------------------------
ID: 4836 --> 2
In [29]: ser = pd.Series([1, 2, None], dtype="uint8[pyarrow]")

In [30]: pa.array(ser)
Out[30]: 

[
  1,
  2,
  null
]

In [31]: idx = pd.Index(ser)

In [32]: pa.array(idx)
Out[32]: 

[
  1,
  2,
  null
]

---->   pandas.Series; pandas.Index

--------------------------------------
ID: 4838 --> 3
In [37]: import pyarrow as pa

In [38]: ser = pd.Series([-1.545, 0.211, None], dtype="float32[pyarrow]")

In [39]: ser.mean()
Out[39]: -0.6669999808073044

In [40]: ser + ser
Out[40]: 
0    -3.09
1    0.422
2     
dtype: float[pyarrow]

In [41]: ser > (ser + 1)
Out[41]: 
0    False
1    False
2     
dtype: bool[pyarrow]

In [42]: ser.dropna()
Out[42]: 
0   -1.545
1    0.211
dtype: float[pyarrow]

In [43]: ser.isna()
Out[43]: 
0    False
1    False
2     True
dtype: bool

In [44]: ser.fillna(0)
Out[44]: 
0   -1.545
1    0.211
2    0.000
dtype: float[pyarrow]

---->   pandas.Series; Series.mean; Series.isna

--------------------------------------
ID: 4839 --> 2
In [45]: ser_str = pd.Series(["a", "b", None], dtype=pd.ArrowDtype(pa.string()))

In [46]: ser_str.str.startswith("a")
Out[46]: 
0     True
1    False
2     
dtype: bool[pyarrow]

---->   pandas.Series; pandas.ArrowDtype

--------------------------------------
ID: 4840 --> 2
In [47]: from datetime import datetime

In [48]: pa_type = pd.ArrowDtype(pa.timestamp("ns"))

In [49]: ser_dt = pd.Series([datetime(2022, 1, 1), None], dtype=pa_type)

In [50]: ser_dt.dt.strftime("%Y-%m")
Out[50]: 
0    2022-01
1       
dtype: string[pyarrow]

---->   pandas.ArrowDtype; pandas.Series

--------------------------------------
ID: 4843 --> 1
In [1]: import pandas._testing as tm

In [2]: def unpivot(frame):
   ...:     N, K = frame.shape
   ...:     data = {
   ...:         "value": frame.to_numpy().ravel("F"),
   ...:         "variable": np.asarray(frame.columns).repeat(N),
   ...:         "date": np.tile(np.asarray(frame.index), K),
   ...:     }
   ...:     return pd.DataFrame(data, columns=["date", "variable", "value"])
   ...: 

In [3]: df = unpivot(tm.makeTimeDataFrame(3))

In [4]: df
Out[4]: 
         date variable     value
0  2000-01-03        A  0.469112
1  2000-01-04        A -0.282863
2  2000-01-05        A -1.509059
3  2000-01-03        B -1.135632
4  2000-01-04        B  1.212112
5  2000-01-05        B -0.173215
6  2000-01-03        C  0.119209
7  2000-01-04        C -1.044236
8  2000-01-05        C -0.861849
9  2000-01-03        D -2.104569
10 2000-01-04        D -0.494929
11 2000-01-05        D  1.071804

---->   pandas.DataFrame

--------------------------------------
ID: 4846 --> 2
In [13]: tuples = list(
   ....:     zip(
   ....:         *[
   ....:             ["bar", "bar", "baz", "baz", "foo", "foo", "qux", "qux"],
   ....:             ["one", "two", "one", "two", "one", "two", "one", "two"],
   ....:         ]
   ....:     )
   ....: )
   ....: 

In [14]: index = pd.MultiIndex.from_tuples(tuples, names=["first", "second"])

In [15]: df = pd.DataFrame(np.random.randn(8, 2), index=index, columns=["A", "B"])

In [16]: df2 = df[:4]

In [17]: df2
Out[17]: 
                     A         B
first second                    
bar   one     0.721555 -0.706771
      two    -1.039575  0.271860
baz   one    -0.424972  0.567020
      two     0.276232 -1.087401

---->   pandas.MultiIndex; pandas.DataFrame

--------------------------------------
ID: 4847 --> 1
In [18]: stacked = df2.stack()

In [19]: stacked
Out[19]: 
first  second   
bar    one     A    0.721555
               B   -0.706771
       two     A   -1.039575
               B    0.271860
baz    one     A   -0.424972
               B    0.567020
       two     A    0.276232
               B   -1.087401
dtype: float64

---->   DataFrame.stack

--------------------------------------
ID: 4850 --> 3
In [24]: index = pd.MultiIndex.from_product([[2, 1], ["a", "b"]])

In [25]: df = pd.DataFrame(np.random.randn(4), index=index, columns=["A"])

In [26]: df
Out[26]: 
            A
2 a -0.370647
  b -1.157892
1 a -1.344312
  b  0.844885

In [27]: all(df.unstack().stack() == df.sort_index())
Out[27]: True

---->   pandas.MultiIndex; pandas.DataFrame; DataFrame.unstack

--------------------------------------
ID: 4851 --> 3
In [28]: columns = pd.MultiIndex.from_tuples(
   ....:     [
   ....:         ("A", "cat", "long"),
   ....:         ("B", "cat", "long"),
   ....:         ("A", "dog", "short"),
   ....:         ("B", "dog", "short"),
   ....:     ],
   ....:     names=["exp", "animal", "hair_length"],
   ....: )
   ....: 

In [29]: df = pd.DataFrame(np.random.randn(4, 4), columns=columns)

In [30]: df
Out[30]: 
exp                 A         B         A         B
animal            cat       cat       dog       dog
hair_length      long      long     short     short
0            1.075770 -0.109050  1.643563 -1.469388
1            0.357021 -0.674600 -1.776904 -0.968914
2           -1.294524  0.413738  0.276662 -0.472035
3           -0.013960 -0.362543 -0.006154 -0.923061

In [31]: df.stack(level=["animal", "hair_length"])
Out[31]: 
exp                          A         B
  animal hair_length                    
0 cat    long         1.075770 -0.109050
  dog    short        1.643563 -1.469388
1 cat    long         0.357021 -0.674600
  dog    short       -1.776904 -0.968914
2 cat    long        -1.294524  0.413738
  dog    short        0.276662 -0.472035
3 cat    long        -0.013960 -0.362543
  dog    short       -0.006154 -0.923061

---->   pandas.MultiIndex; pandas.DataFrame; DataFrame.stack

--------------------------------------
ID: 4852 --> 1
# df.stack(level=['animal', 'hair_length'])
# from above is equivalent to:
In [32]: df.stack(level=[1, 2])
Out[32]: 
exp                          A         B
  animal hair_length                    
0 cat    long         1.075770 -0.109050
  dog    short        1.643563 -1.469388
1 cat    long         0.357021 -0.674600
  dog    short       -1.776904 -0.968914
2 cat    long        -1.294524  0.413738
  dog    short        0.276662 -0.472035
3 cat    long        -0.013960 -0.362543
  dog    short       -0.006154 -0.923061

---->   DataFrame.stack

--------------------------------------
ID: 4853 --> 3
In [33]: columns = pd.MultiIndex.from_tuples(
   ....:     [
   ....:         ("A", "cat"),
   ....:         ("B", "dog"),
   ....:         ("B", "cat"),
   ....:         ("A", "dog"),
   ....:     ],
   ....:     names=["exp", "animal"],
   ....: )
   ....: 

In [34]: index = pd.MultiIndex.from_product(
   ....:     [("bar", "baz", "foo", "qux"), ("one", "two")], names=["first", "second"]
   ....: )
   ....: 

In [35]: df = pd.DataFrame(np.random.randn(8, 4), index=index, columns=columns)

In [36]: df2 = df.iloc[[0, 1, 2, 4, 5, 7]]

In [37]: df2
Out[37]: 
exp                  A         B                   A
animal             cat       dog       cat       dog
first second                                        
bar   one     0.895717  0.805244 -1.206412  2.565646
      two     1.431256  1.340309 -1.170299 -0.226169
baz   one     0.410835  0.813850  0.132003 -0.827317
foo   one    -1.413681  1.607920  1.024180  0.569605
      two     0.875906 -2.211372  0.974466 -2.006747
qux   two    -1.226825  0.769804 -1.281247 -0.727707

---->   pandas.MultiIndex; pandas.MultiIndex; pandas.DataFrame

--------------------------------------
ID: 4854 --> 1
In [38]: df2.stack("exp")
Out[38]: 
animal                 cat       dog
first second exp                    
bar   one    A    0.895717  2.565646
             B   -1.206412  0.805244
      two    A    1.431256 -0.226169
             B   -1.170299  1.340309
baz   one    A    0.410835 -0.827317
             B    0.132003  0.813850
foo   one    A   -1.413681  0.569605
             B    1.024180  1.607920
      two    A    0.875906 -2.006747
             B    0.974466 -2.211372
qux   two    A   -1.226825 -0.727707
             B   -1.281247  0.769804

In [39]: df2.stack("animal")
Out[39]: 
exp                         A         B
first second animal                    
bar   one    cat     0.895717 -1.206412
             dog     2.565646  0.805244
      two    cat     1.431256 -1.170299
             dog    -0.226169  1.340309
baz   one    cat     0.410835  0.132003
             dog    -0.827317  0.813850
foo   one    cat    -1.413681  1.024180
             dog     0.569605  1.607920
      two    cat     0.875906  0.974466
             dog    -2.006747 -2.211372
qux   two    cat    -1.226825 -1.281247
             dog    -0.727707  0.769804

---->   DataFrame.stack

--------------------------------------
ID: 4855 --> 1
In [40]: df3 = df.iloc[[0, 1, 4, 7], [1, 2]]

In [41]: df3
Out[41]: 
exp                  B          
animal             dog       cat
first second                    
bar   one     0.805244 -1.206412
      two     1.340309 -1.170299
foo   one     1.607920  1.024180
qux   two     0.769804 -1.281247

In [42]: df3.unstack()
Out[42]: 
exp            B                              
animal       dog                 cat          
second       one       two       one       two
first                                         
bar     0.805244  1.340309 -1.206412 -1.170299
foo     1.607920       NaN  1.024180       NaN
qux          NaN  0.769804       NaN -1.281247

---->   DataFrame.unstack

--------------------------------------
ID: 4856 --> 1
In [43]: df3.unstack(fill_value=-1e9)
Out[43]: 
exp                B                                          
animal           dog                         cat              
second           one           two           one           two
first                                                         
bar     8.052440e-01  1.340309e+00 -1.206412e+00 -1.170299e+00
foo     1.607920e+00 -1.000000e+09  1.024180e+00 -1.000000e+09
qux    -1.000000e+09  7.698036e-01 -1.000000e+09 -1.281247e+00

---->   DataFrame.unstack

--------------------------------------
ID: 4857 --> 1
In [44]: df[:3].unstack(0)
Out[44]: 
exp            A                   B  ...                   A          
animal       cat                 dog  ...       cat       dog          
first        bar       baz       bar  ...       baz       bar       baz
second                                ...                              
one     0.895717  0.410835  0.805244  ...  0.132003  2.565646 -0.827317
two     1.431256       NaN  1.340309  ...       NaN -0.226169       NaN

[2 rows x 8 columns]

In [45]: df2.unstack(1)
Out[45]: 
exp            A                   B  ...                   A          
animal       cat                 dog  ...       cat       dog          
second       one       two       one  ...       two       one       two
first                                 ...                              
bar     0.895717  1.431256  0.805244  ... -1.170299  2.565646 -0.226169
baz     0.410835       NaN  0.813850  ...       NaN -0.827317       NaN
foo    -1.413681  0.875906  1.607920  ...  0.974466  0.569605 -2.006747
qux          NaN -1.226825       NaN  ... -1.281247       NaN -0.727707

[4 rows x 8 columns]

---->   DataFrame.unstack

--------------------------------------
ID: 4858 --> 1
In [46]: cheese = pd.DataFrame(
   ....:     {
   ....:         "first": ["John", "Mary"],
   ....:         "last": ["Doe", "Bo"],
   ....:         "height": [5.5, 6.0],
   ....:         "weight": [130, 150],
   ....:     }
   ....: )
   ....: 

In [47]: cheese
Out[47]: 
  first last  height  weight
0  John  Doe     5.5     130
1  Mary   Bo     6.0     150

In [48]: cheese.melt(id_vars=["first", "last"])
Out[48]: 
  first last variable  value
0  John  Doe   height    5.5
1  Mary   Bo   height    6.0
2  John  Doe   weight  130.0
3  Mary   Bo   weight  150.0

In [49]: cheese.melt(id_vars=["first", "last"], var_name="quantity")
Out[49]: 
  first last quantity  value
0  John  Doe   height    5.5
1  Mary   Bo   height    6.0
2  John  Doe   weight  130.0
3  Mary   Bo   weight  150.0

---->   pandas.DataFrame

--------------------------------------
ID: 4859 --> 2
In [50]: index = pd.MultiIndex.from_tuples([("person", "A"), ("person", "B")])

In [51]: cheese = pd.DataFrame(
   ....:     {
   ....:         "first": ["John", "Mary"],
   ....:         "last": ["Doe", "Bo"],
   ....:         "height": [5.5, 6.0],
   ....:         "weight": [130, 150],
   ....:     },
   ....:     index=index,
   ....: )
   ....: 

In [52]: cheese
Out[52]: 
         first last  height  weight
person A  John  Doe     5.5     130
       B  Mary   Bo     6.0     150

In [53]: cheese.melt(id_vars=["first", "last"])
Out[53]: 
  first last variable  value
0  John  Doe   height    5.5
1  Mary   Bo   height    6.0
2  John  Doe   weight  130.0
3  Mary   Bo   weight  150.0

In [54]: cheese.melt(id_vars=["first", "last"], ignore_index=False)
Out[54]: 
         first last variable  value
person A  John  Doe   height    5.5
       B  Mary   Bo   height    6.0
       A  John  Doe   weight  130.0
       B  Mary   Bo   weight  150.0

---->   pandas.MultiIndex; pandas.DataFrame

--------------------------------------
ID: 4860 --> 2
In [55]: dft = pd.DataFrame(
   ....:     {
   ....:         "A1970": {0: "a", 1: "b", 2: "c"},
   ....:         "A1980": {0: "d", 1: "e", 2: "f"},
   ....:         "B1970": {0: 2.5, 1: 1.2, 2: 0.7},
   ....:         "B1980": {0: 3.2, 1: 1.3, 2: 0.1},
   ....:         "X": dict(zip(range(3), np.random.randn(3))),
   ....:     }
   ....: )
   ....: 

In [56]: dft["id"] = dft.index

In [57]: dft
Out[57]: 
  A1970 A1980  B1970  B1980         X  id
0     a     d    2.5    3.2 -0.121306   0
1     b     e    1.2    1.3 -0.097883   1
2     c     f    0.7    0.1  0.695775   2

In [58]: pd.wide_to_long(dft, ["A", "B"], i="id", j="year")
Out[58]: 
                X  A    B
id year                  
0  1970 -0.121306  a  2.5
1  1970 -0.097883  b  1.2
2  1970  0.695775  c  0.7
0  1980 -0.121306  d  3.2
1  1980 -0.097883  e  1.3
2  1980  0.695775  f  0.1

---->   pandas.DataFrame; pandas.wide_to_long

--------------------------------------
ID: 4861 --> 3
In [59]: df
Out[59]: 
exp                  A         B                   A
animal             cat       dog       cat       dog
first second                                        
bar   one     0.895717  0.805244 -1.206412  2.565646
      two     1.431256  1.340309 -1.170299 -0.226169
baz   one     0.410835  0.813850  0.132003 -0.827317
      two    -0.076467 -1.187678  1.130127 -1.436737
foo   one    -1.413681  1.607920  1.024180  0.569605
      two     0.875906 -2.211372  0.974466 -2.006747
qux   one    -0.410001 -0.078638  0.545952 -1.219217
      two    -1.226825  0.769804 -1.281247 -0.727707

In [60]: df.stack().mean(1).unstack()
Out[60]: 
animal             cat       dog
first second                    
bar   one    -0.155347  1.685445
      two     0.130479  0.557070
baz   one     0.271419 -0.006733
      two     0.526830 -1.312207
foo   one    -0.194750  1.088763
      two     0.925186 -2.109060
qux   one     0.067976 -0.648927
      two    -1.254036  0.021048

# same result, another way
In [61]: df.groupby(level=1, axis=1).mean()
Out[61]: 
animal             cat       dog
first second                    
bar   one    -0.155347  1.685445
      two     0.130479  0.557070
baz   one     0.271419 -0.006733
      two     0.526830 -1.312207
foo   one    -0.194750  1.088763
      two     0.925186 -2.109060
qux   one     0.067976 -0.648927
      two    -1.254036  0.021048

In [62]: df.stack().groupby(level=1).mean()
Out[62]: 
exp            A         B
second                    
one     0.071448  0.455513
two    -0.424186 -0.204486

In [63]: df.mean().unstack(0)
Out[63]: 
exp            A         B
animal                    
cat     0.060843  0.018596
dog    -0.413580  0.232430

---->   DataFrame.stack; DataFrame.groupby; DataFrame.mean

--------------------------------------
ID: 4862 --> 1
In [64]: import datetime

In [65]: df = pd.DataFrame(
   ....:     {
   ....:         "A": ["one", "one", "two", "three"] * 6,
   ....:         "B": ["A", "B", "C"] * 8,
   ....:         "C": ["foo", "foo", "foo", "bar", "bar", "bar"] * 4,
   ....:         "D": np.random.randn(24),
   ....:         "E": np.random.randn(24),
   ....:         "F": [datetime.datetime(2013, i, 1) for i in range(1, 13)]
   ....:         + [datetime.datetime(2013, i, 15) for i in range(1, 13)],
   ....:     }
   ....: )
   ....: 

In [66]: df
Out[66]: 
        A  B    C         D         E          F
0     one  A  foo  0.341734 -0.317441 2013-01-01
1     one  B  foo  0.959726 -1.236269 2013-02-01
2     two  C  foo -1.110336  0.896171 2013-03-01
3   three  A  bar -0.619976 -0.487602 2013-04-01
4     one  B  bar  0.149748 -0.082240 2013-05-01
..    ... ..  ...       ...       ...        ...
19  three  B  foo  0.690579 -2.213588 2013-08-15
20    one  C  foo  0.995761  1.063327 2013-09-15
21    one  A  bar  2.396780  1.266143 2013-10-15
22    two  B  bar  0.014871  0.299368 2013-11-15
23  three  C  bar  3.357427 -0.863838 2013-12-15

[24 rows x 6 columns]

---->   pandas.DataFrame

--------------------------------------
ID: 4863 --> 1
In [67]: pd.pivot_table(df, values="D", index=["A", "B"], columns=["C"])
Out[67]: 
C             bar       foo
A     B                    
one   A  1.120915 -0.514058
      B -0.338421  0.002759
      C -0.538846  0.699535
three A -1.181568       NaN
      B       NaN  0.433512
      C  0.588783       NaN
two   A       NaN  1.000985
      B  0.158248       NaN
      C       NaN  0.176180

In [68]: pd.pivot_table(df, values="D", index=["B"], columns=["A", "C"], aggfunc=np.sum)
Out[68]: 
A       one               three                 two          
C       bar       foo       bar       foo       bar       foo
B                                                            
A  2.241830 -1.028115 -2.363137       NaN       NaN  2.001971
B -0.676843  0.005518       NaN  0.867024  0.316495       NaN
C -1.077692  1.399070  1.177566       NaN       NaN  0.352360

In [69]: pd.pivot_table(
   ....:     df, values=["D", "E"],
   ....:     index=["B"],
   ....:     columns=["A", "C"],
   ....:     aggfunc=np.sum,
   ....: )
   ....: 
Out[69]: 
          D                      ...         E                    
A       one               three  ...     three       two          
C       bar       foo       bar  ...       foo       bar       foo
B                                ...                              
A  2.241830 -1.028115 -2.363137  ...       NaN       NaN  0.128491
B -0.676843  0.005518       NaN  ... -2.128743 -0.194294       NaN
C -1.077692  1.399070  1.177566  ...       NaN       NaN  0.872482

[3 rows x 12 columns]

---->   pandas.pivot_table

--------------------------------------
ID: 4864 --> 1
In [70]: pd.pivot_table(df[["A", "B", "C", "D", "E"]], index=["A", "B"], columns=["C"])
Out[70]: 
                D                   E          
C             bar       foo       bar       foo
A     B                                        
one   A  1.120915 -0.514058  1.393057 -0.021605
      B -0.338421  0.002759  0.684140 -0.551692
      C -0.538846  0.699535 -0.988442  0.747859
three A -1.181568       NaN  0.961289       NaN
      B       NaN  0.433512       NaN -1.064372
      C  0.588783       NaN -0.131830       NaN
two   A       NaN  1.000985       NaN  0.064245
      B  0.158248       NaN -0.097147       NaN
      C       NaN  0.176180       NaN  0.436241

---->   pandas.pivot_table

--------------------------------------
ID: 4865 --> 2
In [71]: pd.pivot_table(df, values="D", index=pd.Grouper(freq="M", key="F"), columns="C")
Out[71]: 
C                bar       foo
F                             
2013-01-31       NaN -0.514058
2013-02-28       NaN  0.002759
2013-03-31       NaN  0.176180
2013-04-30 -1.181568       NaN
2013-05-31 -0.338421       NaN
2013-06-30 -0.538846       NaN
2013-07-31       NaN  1.000985
2013-08-31       NaN  0.433512
2013-09-30       NaN  0.699535
2013-10-31  1.120915       NaN
2013-11-30  0.158248       NaN
2013-12-31  0.588783       NaN

---->   pandas.pivot_table; pandas.Grouper

--------------------------------------
ID: 4866 --> 1
In [72]: table = pd.pivot_table(df, index=["A", "B"], columns=["C"], values=["D", "E"])

In [73]: print(table.to_string(na_rep=""))
                D                   E          
C             bar       foo       bar       foo
A     B                                        
one   A  1.120915 -0.514058  1.393057 -0.021605
      B -0.338421  0.002759  0.684140 -0.551692
      C -0.538846  0.699535 -0.988442  0.747859
three A -1.181568            0.961289          
      B            0.433512           -1.064372
      C  0.588783           -0.131830          
two   A            1.000985            0.064245
      B  0.158248           -0.097147          
      C            0.176180            0.436241

---->   pandas.pivot_table

--------------------------------------
ID: 4867 --> 1
In [74]: table = df.pivot_table(
   ....:     index=["A", "B"],
   ....:     columns="C",
   ....:     values=["D", "E"],
   ....:     margins=True,
   ....:     aggfunc=np.std
   ....: )
   ....: 

In [75]: table
Out[75]: 
                D                             E                    
C             bar       foo       All       bar       foo       All
A     B                                                            
one   A  1.804346  1.210272  1.569879  0.179483  0.418374  0.858005
      B  0.690376  1.353355  0.898998  1.083825  0.968138  1.101401
      C  0.273641  0.418926  0.771139  1.689271  0.446140  1.422136
three A  0.794212       NaN  0.794212  2.049040       NaN  2.049040
      B       NaN  0.363548  0.363548       NaN  1.625237  1.625237
      C  3.915454       NaN  3.915454  1.035215       NaN  1.035215
two   A       NaN  0.442998  0.442998       NaN  0.447104  0.447104
      B  0.202765       NaN  0.202765  0.560757       NaN  0.560757
      C       NaN  1.819408  1.819408       NaN  0.650439  0.650439
All      1.556686  0.952552  1.246608  1.250924  0.899904  1.059389

---->   DataFrame.pivot_table

--------------------------------------
ID: 4869 --> 1
In [77]: foo, bar, dull, shiny, one, two = "foo", "bar", "dull", "shiny", "one", "two"

In [78]: a = np.array([foo, foo, bar, bar, foo, foo], dtype=object)

In [79]: b = np.array([one, one, two, one, two, one], dtype=object)

In [80]: c = np.array([dull, dull, shiny, dull, dull, shiny], dtype=object)

In [81]: pd.crosstab(a, [b, c], rownames=["a"], colnames=["b", "c"])
Out[81]: 
b    one        two      
c   dull shiny dull shiny
a                        
bar    1     0    0     1
foo    2     1    1     0

---->   pandas.crosstab

--------------------------------------
ID: 4870 --> 2
In [82]: df = pd.DataFrame(
   ....:     {"A": [1, 2, 2, 2, 2], "B": [3, 3, 4, 4, 4], "C": [1, 1, np.nan, 1, 1]}
   ....: )
   ....: 

In [83]: df
Out[83]: 
   A  B    C
0  1  3  1.0
1  2  3  1.0
2  2  4  NaN
3  2  4  1.0
4  2  4  1.0

In [84]: pd.crosstab(df["A"], df["B"])
Out[84]: 
B  3  4
A      
1  1  0
2  1  3

---->   pandas.DataFrame; pandas.crosstab

--------------------------------------
ID: 4871 --> 2
In [85]: foo = pd.Categorical(["a", "b"], categories=["a", "b", "c"])

In [86]: bar = pd.Categorical(["d", "e"], categories=["d", "e", "f"])

In [87]: pd.crosstab(foo, bar)
Out[87]: 
col_0  d  e
row_0      
a      1  0
b      0  1

---->   pandas.Categorical; pandas.crosstab

--------------------------------------
ID: 4872 --> 1
In [88]: pd.crosstab(foo, bar, dropna=False)
Out[88]: 
col_0  d  e  f
row_0         
a      1  0  0
b      0  1  0
c      0  0  0

---->   pandas.crosstab

--------------------------------------
ID: 4873 --> 1
In [89]: pd.crosstab(df["A"], df["B"], normalize=True)
Out[89]: 
B    3    4
A          
1  0.2  0.0
2  0.2  0.6

---->   pandas.crosstab

--------------------------------------
ID: 4874 --> 1
In [90]: pd.crosstab(df["A"], df["B"], normalize="columns")
Out[90]: 
B    3    4
A          
1  0.5  0.0
2  0.5  1.0

---->   pandas.crosstab

--------------------------------------
ID: 4875 --> 1
In [91]: pd.crosstab(df["A"], df["B"], values=df["C"], aggfunc=np.sum)
Out[91]: 
B    3    4
A          
1  1.0  NaN
2  1.0  2.0

---->   pandas.crosstab

--------------------------------------
ID: 4876 --> 1
In [92]: pd.crosstab(
   ....:     df["A"], df["B"], values=df["C"], aggfunc=np.sum, normalize=True, margins=True
   ....: )
   ....: 
Out[92]: 
B       3    4   All
A                   
1    0.25  0.0  0.25
2    0.25  0.5  0.75
All  0.50  0.5  1.00

---->   pandas.crosstab

--------------------------------------
ID: 4877 --> 1
In [93]: ages = np.array([10, 15, 13, 12, 23, 25, 28, 59, 60])

In [94]: pd.cut(ages, bins=3)
Out[94]: 
[(9.95, 26.667], (9.95, 26.667], (9.95, 26.667], (9.95, 26.667], (9.95, 26.667], (9.95, 26.667], (26.667, 43.333], (43.333, 60.0], (43.333, 60.0]]
Categories (3, interval[float64, right]): [(9.95, 26.667] < (26.667, 43.333] < (43.333, 60.0]]

---->   pandas.cut

--------------------------------------
ID: 4878 --> 1
In [95]: c = pd.cut(ages, bins=[0, 18, 35, 70])

In [96]: c
Out[96]: 
[(0, 18], (0, 18], (0, 18], (0, 18], (18, 35], (18, 35], (18, 35], (35, 70], (35, 70]]
Categories (3, interval[int64, right]): [(0, 18] < (18, 35] < (35, 70]]

---->   pandas.cut

--------------------------------------
ID: 4879 --> 1
pd.cut([25, 20, 50], bins=c.categories)

---->   pandas.cut

--------------------------------------
ID: 4880 --> 2
In [97]: df = pd.DataFrame({"key": list("bbacab"), "data1": range(6)})

In [98]: pd.get_dummies(df["key"])
Out[98]: 
       a      b      c
0  False   True  False
1  False   True  False
2   True  False  False
3  False  False   True
4   True  False  False
5  False   True  False

---->   pandas.DataFrame; pandas.get_dummies

--------------------------------------
ID: 4881 --> 1
In [99]: dummies = pd.get_dummies(df["key"], prefix="key")

In [100]: dummies
Out[100]: 
   key_a  key_b  key_c
0  False   True  False
1  False   True  False
2   True  False  False
3  False  False   True
4   True  False  False
5  False   True  False

In [101]: df[["data1"]].join(dummies)
Out[101]: 
   data1  key_a  key_b  key_c
0      0  False   True  False
1      1  False   True  False
2      2   True  False  False
3      3  False  False   True
4      4   True  False  False
5      5  False   True  False

---->   pandas.get_dummies

--------------------------------------
ID: 4882 --> 2
In [102]: values = np.random.randn(10)

In [103]: values
Out[103]: 
array([ 0.4082, -1.0481, -0.0257, -0.9884,  0.0941,  1.2627,  1.29  ,
        0.0824, -0.0558,  0.5366])

In [104]: bins = [0, 0.2, 0.4, 0.6, 0.8, 1]

In [105]: pd.get_dummies(pd.cut(values, bins))
Out[105]: 
   (0.0, 0.2]  (0.2, 0.4]  (0.4, 0.6]  (0.6, 0.8]  (0.8, 1.0]
0       False       False        True       False       False
1       False       False       False       False       False
2       False       False       False       False       False
3       False       False       False       False       False
4        True       False       False       False       False
5       False       False       False       False       False
6       False       False       False       False       False
7        True       False       False       False       False
8       False       False       False       False       False
9       False       False        True       False       False

---->   pandas.get_dummies; pandas.cut

--------------------------------------
ID: 4883 --> 2
In [106]: df = pd.DataFrame({"A": ["a", "b", "a"], "B": ["c", "c", "b"], "C": [1, 2, 3]})

In [107]: pd.get_dummies(df)
Out[107]: 
   C    A_a    A_b    B_b    B_c
0  1   True  False  False   True
1  2  False   True  False   True
2  3   True  False   True  False

---->   pandas.DataFrame; pandas.get_dummies

--------------------------------------
ID: 4884 --> 1
In [108]: pd.get_dummies(df, columns=["A"])
Out[108]: 
   B  C    A_a    A_b
0  c  1   True  False
1  c  2  False   True
2  b  3   True  False

---->   pandas.get_dummies

--------------------------------------
ID: 4885 --> 1
In [109]: simple = pd.get_dummies(df, prefix="new_prefix")

In [110]: simple
Out[110]: 
   C  new_prefix_a  new_prefix_b  new_prefix_b  new_prefix_c
0  1          True         False         False          True
1  2         False          True         False          True
2  3          True         False          True         False

In [111]: from_list = pd.get_dummies(df, prefix=["from_A", "from_B"])

In [112]: from_list
Out[112]: 
   C  from_A_a  from_A_b  from_B_b  from_B_c
0  1      True     False     False      True
1  2     False      True     False      True
2  3      True     False      True     False

In [113]: from_dict = pd.get_dummies(df, prefix={"B": "from_B", "A": "from_A"})

In [114]: from_dict
Out[114]: 
   C  from_A_a  from_A_b  from_B_b  from_B_c
0  1      True     False     False      True
1  2     False      True     False      True
2  3      True     False      True     False

---->   pandas.get_dummies

--------------------------------------
ID: 4886 --> 2
In [115]: s = pd.Series(list("abcaa"))

In [116]: pd.get_dummies(s)
Out[116]: 
       a      b      c
0   True  False  False
1  False   True  False
2  False  False   True
3   True  False  False
4   True  False  False

In [117]: pd.get_dummies(s, drop_first=True)
Out[117]: 
       b      c
0  False  False
1   True  False
2  False   True
3  False  False
4  False  False

---->   pandas.Series; pandas.get_dummies

--------------------------------------
ID: 4887 --> 2
In [118]: df = pd.DataFrame({"A": list("aaaaa"), "B": list("ababc")})

In [119]: pd.get_dummies(df)
Out[119]: 
    A_a    B_a    B_b    B_c
0  True   True  False  False
1  True  False   True  False
2  True   True  False  False
3  True  False   True  False
4  True  False  False   True

In [120]: pd.get_dummies(df, drop_first=True)
Out[120]: 
     B_b    B_c
0  False  False
1   True  False
2  False  False
3   True  False
4  False   True

---->   pandas.DataFrame; pandas.get_dummies

--------------------------------------
ID: 4888 --> 2
In [121]: df = pd.DataFrame({"A": list("abc"), "B": [1.1, 2.2, 3.3]})

In [122]: pd.get_dummies(df, dtype=bool).dtypes
Out[122]: 
B      float64
A_a       bool
A_b       bool
A_c       bool
dtype: object

---->   pandas.DataFrame; pandas.get_dummies

--------------------------------------
ID: 4889 --> 2
In [123]: df = pd.DataFrame({"prefix_a": [0, 1, 0], "prefix_b": [1, 0, 1]})

In [124]: df
Out[124]: 
   prefix_a  prefix_b
0         0         1
1         1         0
2         0         1

In [125]: pd.from_dummies(df, sep="_")
Out[125]: 
  prefix
0      b
1      a
2      b

---->   pandas.DataFrame; pandas.from_dummies

--------------------------------------
ID: 4890 --> 2
In [126]: df = pd.DataFrame({"prefix_a": [0, 1, 0]})

In [127]: df
Out[127]: 
   prefix_a
0         0
1         1
2         0

In [128]: pd.from_dummies(df, sep="_", default_category="b")
Out[128]: 
  prefix
0      b
1      a
2      b

---->   pandas.DataFrame; pandas.from_dummies

--------------------------------------
ID: 4891 --> 2
In [129]: x = pd.Series(["A", "A", np.nan, "B", 3.14, np.inf])

In [130]: x
Out[130]: 
0       A
1       A
2     NaN
3       B
4    3.14
5     inf
dtype: object

In [131]: labels, uniques = pd.factorize(x)

In [132]: labels
Out[132]: array([ 0,  0, -1,  1,  2,  3])

In [133]: uniques
Out[133]: Index(['A', 'B', 3.14, inf], dtype='object')

---->   pandas.Series; pandas.factorize

--------------------------------------
ID: 4892 --> 2
In [134]: ser = pd.Series(['A', 'A', np.nan, 'B', 3.14, np.inf])

In [135]: pd.factorize(ser, sort=True)
Out[135]: (array([ 2,  2, -1,  3,  0,  1]), Index([3.14, inf, 'A', 'B'], dtype='object'))

In [136]: np.unique(ser, return_inverse=True)[::-1]
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
Cell In[136], line 1
----> 1 np.unique(ser, return_inverse=True)[::-1]

File <__array_function__ internals>:200, in unique(*args, **kwargs)

File ~/micromamba-root/envs/test/lib/python3.8/site-packages/numpy/lib/arraysetops.py:274, in unique(ar, return_index, return_inverse, return_counts, axis, equal_nan)
    272 ar = np.asanyarray(ar)
    273 if axis is None:
--> 274     ret = _unique1d(ar, return_index, return_inverse, return_counts, 
    275                     equal_nan=equal_nan)
    276     return _unpack_tuple(ret)
    278 # axis was specified and not None

File ~/micromamba-root/envs/test/lib/python3.8/site-packages/numpy/lib/arraysetops.py:333, in _unique1d(ar, return_index, return_inverse, return_counts, equal_nan)
    330 optional_indices = return_index or return_inverse
    332 if optional_indices:
--> 333     perm = ar.argsort(kind='mergesort' if return_index else 'quicksort')
    334     aux = ar[perm]
    335 else:

TypeError: '<' not supported between instances of 'float' and 'str'

---->   pandas.Series; pandas.factorize

--------------------------------------
ID: 4893 --> 2
In [137]: np.random.seed([3, 1415])

In [138]: n = 20

In [139]: cols = np.array(["key", "row", "item", "col"])

In [140]: df = cols + pd.DataFrame(
   .....:     (np.random.randint(5, size=(n, 4)) // [2, 1, 2, 1]).astype(str)
   .....: )
   .....: 

In [141]: df.columns = cols

In [142]: df = df.join(pd.DataFrame(np.random.rand(n, 2).round(2)).add_prefix("val"))

In [143]: df
Out[143]: 
     key   row   item   col  val0  val1
0   key0  row3  item1  col3  0.81  0.04
1   key1  row2  item1  col2  0.44  0.07
2   key1  row0  item1  col0  0.77  0.01
3   key0  row4  item0  col2  0.15  0.59
4   key1  row0  item2  col1  0.81  0.64
..   ...   ...    ...   ...   ...   ...
15  key0  row3  item1  col1  0.31  0.23
16  key0  row0  item2  col3  0.86  0.01
17  key0  row4  item0  col3  0.64  0.21
18  key2  row2  item2  col0  0.13  0.45
19  key0  row2  item0  col4  0.37  0.70

[20 rows x 6 columns]

---->   pandas.DataFrame; DataFrame.join

--------------------------------------
ID: 4894 --> 1
In [144]: df.pivot_table(values="val0", index="row", columns="col", aggfunc="mean")
Out[144]: 
col   col0   col1   col2   col3  col4
row                                  
row0  0.77  0.605    NaN  0.860  0.65
row2  0.13    NaN  0.395  0.500  0.25
row3   NaN  0.310    NaN  0.545   NaN
row4   NaN  0.100  0.395  0.760  0.24

---->   DataFrame.pivot_table

--------------------------------------
ID: 4895 --> 1
In [145]: df.pivot_table(
   .....:     values="val0",
   .....:     index="row",
   .....:     columns="col",
   .....:     aggfunc="mean",
   .....:     fill_value=0,
   .....: )
   .....: 
Out[145]: 
col   col0   col1   col2   col3  col4
row                                  
row0  0.77  0.605  0.000  0.860  0.65
row2  0.13  0.000  0.395  0.500  0.25
row3  0.00  0.310  0.000  0.545  0.00
row4  0.00  0.100  0.395  0.760  0.24

---->   DataFrame.pivot_table

--------------------------------------
ID: 4896 --> 1
In [146]: df.pivot_table(
   .....:     values="val0",
   .....:     index="row",
   .....:     columns="col",
   .....:     aggfunc="sum",
   .....:     fill_value=0,
   .....: )
   .....: 
Out[146]: 
col   col0  col1  col2  col3  col4
row                               
row0  0.77  1.21  0.00  0.86  0.65
row2  0.13  0.00  0.79  0.50  0.50
row3  0.00  0.31  0.00  1.09  0.00
row4  0.00  0.10  0.79  1.52  0.24

---->   DataFrame.pivot_table

--------------------------------------
ID: 4897 --> 1
In [147]: df.pivot_table(index="row", columns="col", fill_value=0, aggfunc="size")
Out[147]: 
col   col0  col1  col2  col3  col4
row                               
row0     1     2     0     1     1
row2     1     0     2     1     2
row3     0     1     0     2     0
row4     0     1     2     2     1

---->   DataFrame.pivot_table

--------------------------------------
ID: 4898 --> 1
In [148]: df.pivot_table(
   .....:     values="val0",
   .....:     index="row",
   .....:     columns="col",
   .....:     aggfunc=["mean", "sum"],
   .....: )
   .....: 
Out[148]: 
      mean                              sum                        
col   col0   col1   col2   col3  col4  col0  col1  col2  col3  col4
row                                                                
row0  0.77  0.605    NaN  0.860  0.65  0.77  1.21   NaN  0.86  0.65
row2  0.13    NaN  0.395  0.500  0.25  0.13   NaN  0.79  0.50  0.50
row3   NaN  0.310    NaN  0.545   NaN   NaN  0.31   NaN  1.09   NaN
row4   NaN  0.100  0.395  0.760  0.24   NaN  0.10  0.79  1.52  0.24

---->   DataFrame.pivot_table

--------------------------------------
ID: 4899 --> 1
In [149]: df.pivot_table(
   .....:     values=["val0", "val1"],
   .....:     index="row",
   .....:     columns="col",
   .....:     aggfunc=["mean"],
   .....: )
   .....: 
Out[149]: 
      mean                                                           
      val0                             val1                          
col   col0   col1   col2   col3  col4  col0   col1  col2   col3  col4
row                                                                  
row0  0.77  0.605    NaN  0.860  0.65  0.01  0.745   NaN  0.010  0.02
row2  0.13    NaN  0.395  0.500  0.25  0.45    NaN  0.34  0.440  0.79
row3   NaN  0.310    NaN  0.545   NaN   NaN  0.230   NaN  0.075   NaN
row4   NaN  0.100  0.395  0.760  0.24   NaN  0.070  0.42  0.300  0.46

---->   DataFrame.pivot_table

--------------------------------------
ID: 4900 --> 1
In [150]: df.pivot_table(
   .....:     values=["val0"],
   .....:     index="row",
   .....:     columns=["item", "col"],
   .....:     aggfunc=["mean"],
   .....: )
   .....: 
Out[150]: 
      mean                                                                   
      val0                                                                   
item item0             item1                         item2                   
col   col2  col3  col4  col0  col1  col2  col3  col4  col0   col1  col3  col4
row                                                                          
row0   NaN   NaN   NaN  0.77   NaN   NaN   NaN   NaN   NaN  0.605  0.86  0.65
row2  0.35   NaN  0.37   NaN   NaN  0.44   NaN   NaN  0.13    NaN  0.50  0.13
row3   NaN   NaN   NaN   NaN  0.31   NaN  0.81   NaN   NaN    NaN  0.28   NaN
row4  0.15  0.64   NaN   NaN  0.10  0.64  0.88  0.24   NaN    NaN   NaN   NaN

---->   DataFrame.pivot_table

--------------------------------------
ID: 4901 --> 1
In [151]: keys = ["panda1", "panda2", "panda3"]

In [152]: values = [["eats", "shoots"], ["shoots", "leaves"], ["eats", "leaves"]]

In [153]: df = pd.DataFrame({"keys": keys, "values": values})

In [154]: df
Out[154]: 
     keys            values
0  panda1    [eats, shoots]
1  panda2  [shoots, leaves]
2  panda3    [eats, leaves]

---->   pandas.DataFrame

--------------------------------------
ID: 4903 --> 1
In [156]: df.explode("values")
Out[156]: 
     keys  values
0  panda1    eats
0  panda1  shoots
1  panda2  shoots
1  panda2  leaves
2  panda3    eats
2  panda3  leaves

---->   DataFrame.explode

--------------------------------------
ID: 4904 --> 2
In [157]: s = pd.Series([[1, 2, 3], "foo", [], ["a", "b"]])

In [158]: s
Out[158]: 
0    [1, 2, 3]
1          foo
2           []
3       [a, b]
dtype: object

In [159]: s.explode()
Out[159]: 
0      1
0      2
0      3
1    foo
2    NaN
3      a
3      b
dtype: object

---->   pandas.Series; Series.explode

--------------------------------------
ID: 4905 --> 1
In [160]: df = pd.DataFrame([{"var1": "a,b,c", "var2": 1}, {"var1": "d,e,f", "var2": 2}])

In [161]: df
Out[161]: 
    var1  var2
0  a,b,c     1
1  d,e,f     2

---->   pandas.DataFrame

--------------------------------------
ID: 4906 --> 1
In [162]: df.assign(var1=df.var1.str.split(",")).explode("var1")
Out[162]: 
  var1  var2
0    a     1
0    b     1
0    c     1
1    d     2
1    e     2
1    f     2

---->   DataFrame.assign

--------------------------------------
ID: 4907 --> 1
>>> s = pd.Series(data, index=index)

---->   pandas.Series

--------------------------------------
ID: 4908 --> 1
In [3]: s = pd.Series(np.random.randn(5), index=["a", "b", "c", "d", "e"])

In [4]: s
Out[4]: 
a    0.469112
b   -0.282863
c   -1.509059
d   -1.135632
e    1.212112
dtype: float64

In [5]: s.index
Out[5]: Index(['a', 'b', 'c', 'd', 'e'], dtype='object')

In [6]: pd.Series(np.random.randn(5))
Out[6]: 
0   -0.173215
1    0.119209
2   -1.044236
3   -0.861849
4   -2.104569
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 4909 --> 1
In [7]: d = {"b": 1, "a": 0, "c": 2}

In [8]: pd.Series(d)
Out[8]: 
b    1
a    0
c    2
dtype: int64

---->   pandas.Series

--------------------------------------
ID: 4910 --> 1
In [9]: d = {"a": 0.0, "b": 1.0, "c": 2.0}

In [10]: pd.Series(d)
Out[10]: 
a    0.0
b    1.0
c    2.0
dtype: float64

In [11]: pd.Series(d, index=["b", "c", "d", "a"])
Out[11]: 
b    1.0
c    2.0
d    NaN
a    0.0
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 4911 --> 1
In [12]: pd.Series(5.0, index=["a", "b", "c", "d", "e"])
Out[12]: 
a    5.0
b    5.0
c    5.0
d    5.0
e    5.0
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 4912 --> 1
In [13]: s[0]
Out[13]: 0.4691122999071863

In [14]: s[:3]
Out[14]: 
a    0.469112
b   -0.282863
c   -1.509059
dtype: float64

In [15]: s[s > s.median()]
Out[15]: 
a    0.469112
e    1.212112
dtype: float64

In [16]: s[[4, 3, 1]]
Out[16]: 
e    1.212112
d   -1.135632
b   -0.282863
dtype: float64

In [17]: np.exp(s)
Out[17]: 
a    1.598575
b    0.753623
c    0.221118
d    0.321219
e    3.360575
dtype: float64

---->   Series.median

--------------------------------------
ID: 4914 --> 1
In [20]: s.to_numpy()
Out[20]: array([ 0.4691, -0.2829, -1.5091, -1.1356,  1.2121])

---->   Series.to_numpy

--------------------------------------
ID: 4915 --> 1
In [26]: s["f"]
---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
File ~/work/pandas/pandas/pandas/core/indexes/base.py:3653, in Index.get_loc(self, key)
   3652 try:
-> 3653     return self._engine.get_loc(casted_key)
   3654 except KeyError as err:

File ~/work/pandas/pandas/pandas/_libs/index.pyx:147, in pandas._libs.index.IndexEngine.get_loc()

File ~/work/pandas/pandas/pandas/_libs/index.pyx:176, in pandas._libs.index.IndexEngine.get_loc()

File ~/work/pandas/pandas/pandas/_libs/hashtable_class_helper.pxi:7080, in pandas._libs.hashtable.PyObjectHashTable.get_item()

File ~/work/pandas/pandas/pandas/_libs/hashtable_class_helper.pxi:7088, in pandas._libs.hashtable.PyObjectHashTable.get_item()

KeyError: 'f'

The above exception was the direct cause of the following exception:

KeyError                                  Traceback (most recent call last)
Cell In[26], line 1
----> 1 s["f"]

File ~/work/pandas/pandas/pandas/core/series.py:1007, in Series.__getitem__(self, key)
   1004     return self._values[key]
   1006 elif key_is_scalar:
-> 1007     return self._get_value(key)
   1009 if is_hashable(key):
   1010     # Otherwise index.get_value will raise InvalidIndexError
   1011     try:
   1012         # For labels that don't resolve as scalars like tuples and frozensets

File ~/work/pandas/pandas/pandas/core/series.py:1116, in Series._get_value(self, label, takeable)
   1113     return self._values[label]
   1115 # Similar to Index.get_value, but we do not fall back to positional
-> 1116 loc = self.index.get_loc(label)
   1118 if is_integer(loc):
   1119     return self._values[loc]

File ~/work/pandas/pandas/pandas/core/indexes/base.py:3655, in Index.get_loc(self, key)
   3653     return self._engine.get_loc(casted_key)
   3654 except KeyError as err:
-> 3655     raise KeyError(key) from err
   3656 except TypeError:
   3657     # If we have a listlike key, _check_indexing_error will raise
   3658     #  InvalidIndexError. Otherwise we fall through and re-raise
   3659     #  the TypeError.
   3660     self._check_indexing_error(key)

KeyError: 'f'

---->   Index.get_loc

--------------------------------------
ID: 4916 --> 1
In [27]: s.get("f")

In [28]: s.get("f", np.nan)
Out[28]: nan

---->   Series.get

--------------------------------------
ID: 4918 --> 1
In [33]: s = pd.Series(np.random.randn(5), name="something")

In [34]: s
Out[34]: 
0   -0.494929
1    1.071804
2    0.721555
3   -0.706771
4   -1.039575
Name: something, dtype: float64

In [35]: s.name
Out[35]: 'something'

---->   pandas.Series

--------------------------------------
ID: 4920 --> 2
In [38]: d = {
   ....:     "one": pd.Series([1.0, 2.0, 3.0], index=["a", "b", "c"]),
   ....:     "two": pd.Series([1.0, 2.0, 3.0, 4.0], index=["a", "b", "c", "d"]),
   ....: }
   ....: 

In [39]: df = pd.DataFrame(d)

In [40]: df
Out[40]: 
   one  two
a  1.0  1.0
b  2.0  2.0
c  3.0  3.0
d  NaN  4.0

In [41]: pd.DataFrame(d, index=["d", "b", "a"])
Out[41]: 
   one  two
d  NaN  4.0
b  2.0  2.0
a  1.0  1.0

In [42]: pd.DataFrame(d, index=["d", "b", "a"], columns=["two", "three"])
Out[42]: 
   two three
d  4.0   NaN
b  2.0   NaN
a  1.0   NaN

---->   pandas.Series; pandas.DataFrame

--------------------------------------
ID: 4922 --> 1
In [45]: d = {"one": [1.0, 2.0, 3.0, 4.0], "two": [4.0, 3.0, 2.0, 1.0]}

In [46]: pd.DataFrame(d)
Out[46]: 
   one  two
0  1.0  4.0
1  2.0  3.0
2  3.0  2.0
3  4.0  1.0

In [47]: pd.DataFrame(d, index=["a", "b", "c", "d"])
Out[47]: 
   one  two
a  1.0  4.0
b  2.0  3.0
c  3.0  2.0
d  4.0  1.0

---->   pandas.DataFrame

--------------------------------------
ID: 4923 --> 1
In [48]: data = np.zeros((2,), dtype=[("A", "i4"), ("B", "f4"), ("C", "a10")])

In [49]: data[:] = [(1, 2.0, "Hello"), (2, 3.0, "World")]

In [50]: pd.DataFrame(data)
Out[50]: 
   A    B         C
0  1  2.0  b'Hello'
1  2  3.0  b'World'

In [51]: pd.DataFrame(data, index=["first", "second"])
Out[51]: 
        A    B         C
first   1  2.0  b'Hello'
second  2  3.0  b'World'

In [52]: pd.DataFrame(data, columns=["C", "A", "B"])
Out[52]: 
          C  A    B
0  b'Hello'  1  2.0
1  b'World'  2  3.0

---->   pandas.DataFrame

--------------------------------------
ID: 4924 --> 1
In [53]: data2 = [{"a": 1, "b": 2}, {"a": 5, "b": 10, "c": 20}]

In [54]: pd.DataFrame(data2)
Out[54]: 
   a   b     c
0  1   2   NaN
1  5  10  20.0

In [55]: pd.DataFrame(data2, index=["first", "second"])
Out[55]: 
        a   b     c
first   1   2   NaN
second  5  10  20.0

In [56]: pd.DataFrame(data2, columns=["a", "b"])
Out[56]: 
   a   b
0  1   2
1  5  10

---->   pandas.DataFrame

--------------------------------------
ID: 4925 --> 1
In [57]: pd.DataFrame(
   ....:     {
   ....:         ("a", "b"): {("A", "B"): 1, ("A", "C"): 2},
   ....:         ("a", "a"): {("A", "C"): 3, ("A", "B"): 4},
   ....:         ("a", "c"): {("A", "B"): 5, ("A", "C"): 6},
   ....:         ("b", "a"): {("A", "C"): 7, ("A", "B"): 8},
   ....:         ("b", "b"): {("A", "D"): 9, ("A", "B"): 10},
   ....:     }
   ....: )
   ....: 
Out[57]: 
       a              b      
       b    a    c    a     b
A B  1.0  4.0  5.0  8.0  10.0
  C  2.0  3.0  6.0  7.0   NaN
  D  NaN  NaN  NaN  NaN   9.0

---->   pandas.DataFrame

--------------------------------------
ID: 4926 --> 2
In [58]: ser = pd.Series(range(3), index=list("abc"), name="ser")

In [59]: pd.DataFrame(ser)
Out[59]: 
   ser
a    0
b    1
c    2

---->   pandas.Series; pandas.DataFrame

--------------------------------------
ID: 4927 --> 1
In [60]: from collections import namedtuple

In [61]: Point = namedtuple("Point", "x y")

In [62]: pd.DataFrame([Point(0, 0), Point(0, 3), (2, 3)])
Out[62]: 
   x  y
0  0  0
1  0  3
2  2  3

In [63]: Point3D = namedtuple("Point3D", "x y z")

In [64]: pd.DataFrame([Point3D(0, 0, 0), Point3D(0, 3, 5), Point(2, 3)])
Out[64]: 
   x  y    z
0  0  0  0.0
1  0  3  5.0
2  2  3  NaN

---->   pandas.DataFrame

--------------------------------------
ID: 4928 --> 1
In [65]: from dataclasses import make_dataclass

In [66]: Point = make_dataclass("Point", [("x", int), ("y", int)])

In [67]: pd.DataFrame([Point(0, 0), Point(0, 3), Point(2, 3)])
Out[67]: 
   x  y
0  0  0
1  0  3
2  2  3

---->   pandas.DataFrame

--------------------------------------
ID: 4929 --> 1
In [68]: pd.DataFrame.from_dict(dict([("A", [1, 2, 3]), ("B", [4, 5, 6])]))
Out[68]: 
   A  B
0  1  4
1  2  5
2  3  6

---->   pandas.DataFrame

--------------------------------------
ID: 4930 --> 1
In [69]: pd.DataFrame.from_dict(
   ....:     dict([("A", [1, 2, 3]), ("B", [4, 5, 6])]),
   ....:     orient="index",
   ....:     columns=["one", "two", "three"],
   ....: )
   ....: 
Out[69]: 
   one  two  three
A    1    2      3
B    4    5      6

---->   pandas.DataFrame

--------------------------------------
ID: 4931 --> 1
In [70]: data
Out[70]: 
array([(1, 2., b'Hello'), (2, 3., b'World')],
      dtype=[('A', '

In [71]: pd.DataFrame.from_records(data, index="C")
Out[71]: 
          A    B
C               
b'Hello'  1  2.0
b'World'  2  3.0

---->   pandas.DataFrame

--------------------------------------
ID: 4932 --> 1
In [76]: del df["two"]

In [77]: three = df.pop("three")

In [78]: df
Out[78]: 
   one   flag
a  1.0  False
b  2.0  False
c  3.0   True
d  NaN  False

---->   DataFrame.pop

--------------------------------------
ID: 4933 --> 1
In [83]: df.insert(1, "bar", df["one"])

In [84]: df
Out[84]: 
   one  bar   flag  foo  one_trunc
a  1.0  1.0  False  bar        1.0
b  2.0  2.0  False  bar        2.0
c  3.0  3.0   True  bar        NaN
d  NaN  NaN  False  bar        NaN

---->   DataFrame.insert

--------------------------------------
ID: 4937 --> 2
In [90]: dfa = pd.DataFrame({"A": [1, 2, 3], "B": [4, 5, 6]})

In [91]: dfa.assign(C=lambda x: x["A"] + x["B"], D=lambda x: x["A"] + x["C"])
Out[91]: 
   A  B  C   D
0  1  4  5   6
1  2  5  7   9
2  3  6  9  12

---->   pandas.DataFrame; DataFrame.assign

--------------------------------------
ID: 4938 --> 1
In [94]: df = pd.DataFrame(np.random.randn(10, 4), columns=["A", "B", "C", "D"])

In [95]: df2 = pd.DataFrame(np.random.randn(7, 3), columns=["A", "B", "C"])

In [96]: df + df2
Out[96]: 
          A         B         C   D
0  0.045691 -0.014138  1.380871 NaN
1 -0.955398 -1.501007  0.037181 NaN
2 -0.662690  1.534833 -0.859691 NaN
3 -2.452949  1.237274 -0.133712 NaN
4  1.414490  1.951676 -2.320422 NaN
5 -0.494922 -1.649727 -1.084601 NaN
6 -1.047551 -0.748572 -0.805479 NaN
7       NaN       NaN       NaN NaN
8       NaN       NaN       NaN NaN
9       NaN       NaN       NaN NaN

---->   pandas.DataFrame

--------------------------------------
ID: 4939 --> 1
In [101]: df1 = pd.DataFrame({"a": [1, 0, 1], "b": [0, 1, 1]}, dtype=bool)

In [102]: df2 = pd.DataFrame({"a": [0, 1, 1], "b": [1, 1, 0]}, dtype=bool)

In [103]: df1 & df2
Out[103]: 
       a      b
0  False  False
1  False   True
2   True  False

In [104]: df1 | df2
Out[104]: 
      a     b
0  True  True
1  True  True
2  True  True

In [105]: df1 ^ df2
Out[105]: 
       a      b
0   True   True
1   True  False
2  False   True

In [106]: -df1
Out[106]: 
       a      b
0  False   True
1   True  False
2  False  False

---->   pandas.DataFrame

--------------------------------------
ID: 4941 --> 1
In [110]: ser = pd.Series([1, 2, 3, 4])

In [111]: np.exp(ser)
Out[111]: 
0     2.718282
1     7.389056
2    20.085537
3    54.598150
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 4942 --> 1
In [112]: ser1 = pd.Series([1, 2, 3], index=["a", "b", "c"])

In [113]: ser2 = pd.Series([1, 3, 5], index=["b", "a", "c"])

In [114]: ser1
Out[114]: 
a    1
b    2
c    3
dtype: int64

In [115]: ser2
Out[115]: 
b    1
a    3
c    5
dtype: int64

In [116]: np.remainder(ser1, ser2)
Out[116]: 
a    1
b    0
c    3
dtype: int64

---->   pandas.Series

--------------------------------------
ID: 4943 --> 1
In [117]: ser3 = pd.Series([2, 4, 6], index=["b", "c", "d"])

In [118]: ser3
Out[118]: 
b    2
c    4
d    6
dtype: int64

In [119]: np.remainder(ser1, ser3)
Out[119]: 
a    NaN
b    0.0
c    3.0
d    NaN
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 4944 --> 2
In [120]: ser = pd.Series([1, 2, 3])

In [121]: idx = pd.Index([4, 5, 6])

In [122]: np.maximum(ser, idx)
Out[122]: 
0    4
1    5
2    6
dtype: int64

---->   pandas.Series; pandas.Index

--------------------------------------
ID: 4947 --> 1
In [127]: pd.DataFrame(np.random.randn(3, 12))
Out[127]: 
         0         1         2   ...        9         10        11
0 -1.226825  0.769804 -1.281247  ... -1.110336 -0.619976  0.149748
1 -0.732339  0.687738  0.176444  ...  1.462696 -1.743161 -0.826591
2 -0.345352  1.314232  0.690579  ...  0.896171 -0.487602 -0.082240

[3 rows x 12 columns]

---->   pandas.DataFrame

--------------------------------------
ID: 4948 --> 1
In [128]: pd.set_option("display.width", 40)  # default is 80

In [129]: pd.DataFrame(np.random.randn(3, 12))
Out[129]: 
         0         1         2   ...        9         10        11
0 -2.182937  0.380396  0.084844  ... -0.023688  2.410179  1.450520
1  0.206053 -0.251905 -2.213588  ... -0.025747 -0.988387  0.094055
2  1.262731  1.289997  0.082423  ... -0.281461  0.030711  0.109121

[3 rows x 12 columns]

---->   pandas.DataFrame

--------------------------------------
ID: 4949 --> 1
In [130]: datafile = {
   .....:     "filename": ["filename_01", "filename_02"],
   .....:     "path": [
   .....:         "media/user_name/storage/folder_01/filename_01",
   .....:         "media/user_name/storage/folder_02/filename_02",
   .....:     ],
   .....: }
   .....: 

In [131]: pd.set_option("display.max_colwidth", 30)

In [132]: pd.DataFrame(datafile)
Out[132]: 
      filename                           path
0  filename_01  media/user_name/storage/fo...
1  filename_02  media/user_name/storage/fo...

In [133]: pd.set_option("display.max_colwidth", 100)

In [134]: pd.DataFrame(datafile)
Out[134]: 
      filename                                           path
0  filename_01  media/user_name/storage/folder_01/filename_01
1  filename_02  media/user_name/storage/folder_02/filename_02

---->   pandas.DataFrame

--------------------------------------
ID: 4950 --> 1
In [135]: df = pd.DataFrame({"foo1": np.random.randn(5), "foo2": np.random.randn(5)})

In [136]: df
Out[136]: 
       foo1      foo2
0  1.126203  0.781836
1 -0.977349 -1.071357
2  1.474071  0.441153
3 -0.064034  2.353925
4 -1.282782  0.583787

In [137]: df.foo1
Out[137]: 
0    1.126203
1   -0.977349
2    1.474071
3   -0.064034
4   -1.282782
Name: foo1, dtype: float64

---->   pandas.DataFrame

--------------------------------------
ID: 4952 --> 1
In [1]: speeds = pd.DataFrame(
   ...:     [
   ...:         ("bird", "Falconiformes", 389.0),
   ...:         ("bird", "Psittaciformes", 24.0),
   ...:         ("mammal", "Carnivora", 80.2),
   ...:         ("mammal", "Primates", np.nan),
   ...:         ("mammal", "Carnivora", 58),
   ...:     ],
   ...:     index=["falcon", "parrot", "lion", "monkey", "leopard"],
   ...:     columns=("class", "order", "max_speed"),
   ...: )
   ...: 

In [2]: speeds
Out[2]: 
          class           order  max_speed
falcon     bird   Falconiformes      389.0
parrot     bird  Psittaciformes       24.0
lion     mammal       Carnivora       80.2
monkey   mammal        Primates        NaN
leopard  mammal       Carnivora       58.0

# default is axis=0
In [3]: grouped = speeds.groupby("class")

In [4]: grouped = speeds.groupby("order", axis="columns")

In [5]: grouped = speeds.groupby(["class", "order"])

---->   pandas.DataFrame

--------------------------------------
ID: 4953 --> 1
In [6]: df = pd.DataFrame(
   ...:     {
   ...:         "A": ["foo", "bar", "foo", "bar", "foo", "bar", "foo", "foo"],
   ...:         "B": ["one", "one", "two", "three", "two", "two", "one", "three"],
   ...:         "C": np.random.randn(8),
   ...:         "D": np.random.randn(8),
   ...:     }
   ...: )
   ...: 

In [7]: df
Out[7]: 
     A      B         C         D
0  foo    one  0.469112 -0.861849
1  bar    one -0.282863 -2.104569
2  foo    two -1.509059 -0.494929
3  bar  three -1.135632  1.071804
4  foo    two  1.212112  0.721555
5  bar    two -0.173215 -0.706771
6  foo    one  0.119209 -1.039575
7  foo  three -1.044236  0.271860

---->   pandas.DataFrame

--------------------------------------
ID: 4954 --> 1
In [8]: grouped = df.groupby("A")

In [9]: grouped = df.groupby(["A", "B"])

---->   DataFrame.groupby

--------------------------------------
ID: 4955 --> 1
In [10]: df2 = df.set_index(["A", "B"])

In [11]: grouped = df2.groupby(level=df2.index.names.difference(["B"]))

In [12]: grouped.sum()
Out[12]: 
            C         D
A                      
bar -1.591710 -1.739537
foo -0.752861 -1.402938

---->   DataFrame.groupby

--------------------------------------
ID: 4956 --> 1
In [13]: def get_letter_type(letter):
   ....:     if letter.lower() in 'aeiou':
   ....:         return 'vowel'
   ....:     else:
   ....:         return 'consonant'
   ....: 

In [14]: grouped = df.groupby(get_letter_type, axis=1)

---->   DataFrame.groupby

--------------------------------------
ID: 4957 --> 2
In [15]: lst = [1, 2, 3, 1, 2, 3]

In [16]: s = pd.Series([1, 2, 3, 10, 20, 30], lst)

In [17]: grouped = s.groupby(level=0)

In [18]: grouped.first()
Out[18]: 
1    1
2    2
3    3
dtype: int64

In [19]: grouped.last()
Out[19]: 
1    10
2    20
3    30
dtype: int64

In [20]: grouped.sum()
Out[20]: 
1    11
2    22
3    33
dtype: int64

---->   pandas.Series; Series.groupby

--------------------------------------
ID: 4958 --> 2
In [21]: df2 = pd.DataFrame({"X": ["B", "B", "A", "A"], "Y": [1, 2, 3, 4]})

In [22]: df2.groupby(["X"]).sum()
Out[22]: 
   Y
X   
A  7
B  3

In [23]: df2.groupby(["X"], sort=False).sum()
Out[23]: 
   Y
X   
B  3
A  7

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 4959 --> 2
In [24]: df3 = pd.DataFrame({"X": ["A", "B", "A", "B"], "Y": [1, 4, 3, 2]})

In [25]: df3.groupby(["X"]).get_group("A")
Out[25]: 
   X  Y
0  A  1
2  A  3

In [26]: df3.groupby(["X"]).get_group("B")
Out[26]: 
   X  Y
1  B  4
3  B  2

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 4960 --> 1
In [27]: df_list = [[1, 2, 3], [1, None, 4], [2, 1, 3], [1, 2, 2]]

In [28]: df_dropna = pd.DataFrame(df_list, columns=["a", "b", "c"])

In [29]: df_dropna
Out[29]: 
   a    b  c
0  1  2.0  3
1  1  NaN  4
2  2  1.0  3
3  1  2.0  2

---->   pandas.DataFrame

--------------------------------------
ID: 4961 --> 1
# Default ``dropna`` is set to True, which will exclude NaNs in keys
In [30]: df_dropna.groupby(by=["b"], dropna=True).sum()
Out[30]: 
     a  c
b        
1.0  2  3
2.0  2  5

# In order to allow NaN in keys, set ``dropna`` to False
In [31]: df_dropna.groupby(by=["b"], dropna=False).sum()
Out[31]: 
     a  c
b        
1.0  2  3
2.0  2  5
NaN  1  4

---->   DataFrame.groupby

--------------------------------------
ID: 4962 --> 1
In [32]: df.groupby("A").groups
Out[32]: {'bar': [1, 3, 5], 'foo': [0, 2, 4, 6, 7]}

In [33]: df.groupby(get_letter_type, axis=1).groups
Out[33]: {'consonant': ['B', 'C', 'D'], 'vowel': ['A']}

---->   DataFrame.groupby

--------------------------------------
ID: 4963 --> 1
In [34]: grouped = df.groupby(["A", "B"])

In [35]: grouped.groups
Out[35]: {('bar', 'one'): [1], ('bar', 'three'): [3], ('bar', 'two'): [5], ('foo', 'one'): [0, 6], ('foo', 'three'): [7], ('foo', 'two'): [2, 4]}

In [36]: len(grouped)
Out[36]: 6

---->   DataFrame.groupby

--------------------------------------
ID: 4964 --> 1
In [37]: df
Out[37]: 
               height      weight  gender
2000-01-01  42.849980  157.500553    male
2000-01-02  49.607315  177.340407    male
2000-01-03  56.293531  171.524640    male
2000-01-04  48.421077  144.251986  female
2000-01-05  46.556882  152.526206    male
2000-01-06  68.448851  168.272968  female
2000-01-07  70.757698  136.431469    male
2000-01-08  58.909500  176.499753  female
2000-01-09  76.435631  174.094104  female
2000-01-10  45.306120  177.540920    male

In [38]: gb = df.groupby("gender")

---->   DataFrame.groupby

--------------------------------------
ID: 4965 --> 2
In [40]: arrays = [
   ....:     ["bar", "bar", "baz", "baz", "foo", "foo", "qux", "qux"],
   ....:     ["one", "two", "one", "two", "one", "two", "one", "two"],
   ....: ]
   ....: 

In [41]: index = pd.MultiIndex.from_arrays(arrays, names=["first", "second"])

In [42]: s = pd.Series(np.random.randn(8), index=index)

In [43]: s
Out[43]: 
first  second
bar    one      -0.919854
       two      -0.042379
baz    one       1.247642
       two      -0.009920
foo    one       0.290213
       two       0.495767
qux    one       0.362949
       two       1.548106
dtype: float64

---->   pandas.MultiIndex; pandas.Series

--------------------------------------
ID: 4966 --> 1
In [44]: grouped = s.groupby(level=0)

In [45]: grouped.sum()
Out[45]: 
first
bar   -0.962232
baz    1.237723
foo    0.785980
qux    1.911055
dtype: float64

---->   Series.groupby

--------------------------------------
ID: 4967 --> 1
In [46]: s.groupby(level="second").sum()
Out[46]: 
second
one    0.980950
two    1.991575
dtype: float64

---->   Series.groupby

--------------------------------------
ID: 4968 --> 1
In [47]: s
Out[47]: 
first  second  third
bar    doo     one     -1.131345
               two     -0.089329
baz    bee     one      0.337863
               two     -0.945867
foo    bop     one     -0.932132
               two      1.956030
qux    bop     one      0.017587
               two     -0.016692
dtype: float64

In [48]: s.groupby(level=["first", "second"]).sum()
Out[48]: 
first  second
bar    doo      -1.220674
baz    bee      -0.608004
foo    bop       1.023898
qux    bop       0.000895
dtype: float64

---->   Series.groupby

--------------------------------------
ID: 4969 --> 1
In [49]: s.groupby(["first", "second"]).sum()
Out[49]: 
first  second
bar    doo      -1.220674
baz    bee      -0.608004
foo    bop       1.023898
qux    bop       0.000895
dtype: float64

---->   Series.groupby

--------------------------------------
ID: 4970 --> 2
In [50]: arrays = [
   ....:     ["bar", "bar", "baz", "baz", "foo", "foo", "qux", "qux"],
   ....:     ["one", "two", "one", "two", "one", "two", "one", "two"],
   ....: ]
   ....: 

In [51]: index = pd.MultiIndex.from_arrays(arrays, names=["first", "second"])

In [52]: df = pd.DataFrame({"A": [1, 1, 1, 1, 2, 2, 3, 3], "B": np.arange(8)}, index=index)

In [53]: df
Out[53]: 
              A  B
first second      
bar   one     1  0
      two     1  1
baz   one     1  2
      two     1  3
foo   one     2  4
      two     2  5
qux   one     3  6
      two     3  7

---->   pandas.MultiIndex; pandas.DataFrame

--------------------------------------
ID: 4971 --> 2
In [54]: df.groupby([pd.Grouper(level=1), "A"]).sum()
Out[54]: 
          B
second A   
one    1  2
       2  4
       3  6
two    1  4
       2  5
       3  7

---->   DataFrame.groupby; pandas.Grouper

--------------------------------------
ID: 4972 --> 2
In [55]: df.groupby([pd.Grouper(level="second"), "A"]).sum()
Out[55]: 
          B
second A   
one    1  2
       2  4
       3  6
two    1  4
       2  5
       3  7

---->   DataFrame.groupby; pandas.Grouper

--------------------------------------
ID: 4973 --> 1
In [56]: df.groupby(["second", "A"]).sum()
Out[56]: 
          B
second A   
one    1  2
       2  4
       3  6
two    1  4
       2  5
       3  7

---->   DataFrame.groupby

--------------------------------------
ID: 4974 --> 2
In [57]: df = pd.DataFrame(
   ....:     {
   ....:         "A": ["foo", "bar", "foo", "bar", "foo", "bar", "foo", "foo"],
   ....:         "B": ["one", "one", "two", "three", "two", "two", "one", "three"],
   ....:         "C": np.random.randn(8),
   ....:         "D": np.random.randn(8),
   ....:     }
   ....: )
   ....: 

In [58]: df
Out[58]: 
     A      B         C         D
0  foo    one -0.575247  1.346061
1  bar    one  0.254161  1.511763
2  foo    two -1.143704  1.627081
3  bar  three  0.215897 -0.990582
4  foo    two  1.193555 -0.441652
5  bar    two -0.077118  1.211526
6  foo    one -0.408530  0.268520
7  foo  three -0.862495  0.024580

In [59]: grouped = df.groupby(["A"])

In [60]: grouped_C = grouped["C"]

In [61]: grouped_D = grouped["D"]

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 4976 --> 1
In [63]: grouped = df.groupby('A')

In [64]: for name, group in grouped:
   ....:     print(name)
   ....:     print(group)
   ....: 
bar
     A      B         C         D
1  bar    one  0.254161  1.511763
3  bar  three  0.215897 -0.990582
5  bar    two -0.077118  1.211526
foo
     A      B         C         D
0  foo    one -0.575247  1.346061
2  foo    two -1.143704  1.627081
4  foo    two  1.193555 -0.441652
6  foo    one -0.408530  0.268520
7  foo  three -0.862495  0.024580

---->   DataFrame.groupby

--------------------------------------
ID: 4977 --> 1
In [65]: for name, group in df.groupby(['A', 'B']):
   ....:     print(name)
   ....:     print(group)
   ....: 
('bar', 'one')
     A    B         C         D
1  bar  one  0.254161  1.511763
('bar', 'three')
     A      B         C         D
3  bar  three  0.215897 -0.990582
('bar', 'two')
     A    B         C         D
5  bar  two -0.077118  1.211526
('foo', 'one')
     A    B         C         D
0  foo  one -0.575247  1.346061
6  foo  one -0.408530  0.268520
('foo', 'three')
     A      B         C        D
7  foo  three -0.862495  0.02458
('foo', 'two')
     A    B         C         D
2  foo  two -1.143704  1.627081
4  foo  two  1.193555 -0.441652

---->   DataFrame.groupby

--------------------------------------
ID: 4979 --> 1
In [67]: df.groupby(["A", "B"]).get_group(("bar", "one"))
Out[67]: 
     A    B         C         D
1  bar  one  0.254161  1.511763

---->   DataFrame.groupby

--------------------------------------
ID: 4980 --> 1
In [68]: animals = pd.DataFrame(
   ....:     {
   ....:         "kind": ["cat", "dog", "cat", "dog"],
   ....:         "height": [9.1, 6.0, 9.5, 34.0],
   ....:         "weight": [7.9, 7.5, 9.9, 198.0],
   ....:     }
   ....: )
   ....: 

In [69]: animals
Out[69]: 
  kind  height  weight
0  cat     9.1     7.9
1  dog     6.0     7.5
2  cat     9.5     9.9
3  dog    34.0   198.0

In [70]: animals.groupby("kind").sum()
Out[70]: 
      height  weight
kind                
cat     18.6    17.8
dog     40.0   205.5

---->   pandas.DataFrame

--------------------------------------
ID: 4982 --> 1
In [72]: df.groupby("A")[["C", "D"]].max()
Out[72]: 
            C         D
A                      
bar  0.254161  1.511763
foo  1.193555  1.627081

In [73]: df.groupby(["A", "B"]).mean()
Out[73]: 
                  C         D
A   B                        
bar one    0.254161  1.511763
    three  0.215897 -0.990582
    two   -0.077118  1.211526
foo one   -0.491888  0.807291
    three -0.862495  0.024580
    two    0.024925  0.592714

---->   DataFrame.groupby

--------------------------------------
ID: 4983 --> 1
In [74]: grouped = df.groupby(["A", "B"])

In [75]: grouped.size()
Out[75]: 
A    B    
bar  one      1
     three    1
     two      1
foo  one      2
     three    1
     two      2
dtype: int64

---->   DataFrame.groupby

--------------------------------------
ID: 4985 --> 2
In [77]: ll = [['foo', 1], ['foo', 2], ['foo', 2], ['bar', 1], ['bar', 1]]

In [78]: df4 = pd.DataFrame(ll, columns=["A", "B"])

In [79]: df4
Out[79]: 
     A  B
0  foo  1
1  foo  2
2  foo  2
3  bar  1
4  bar  1

In [80]: df4.groupby("A")["B"].nunique()
Out[80]: 
A
bar    1
foo    2
Name: B, dtype: int64

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 4986 --> 1
In [81]: grouped = df.groupby("A")

In [82]: grouped[["C", "D"]].aggregate("sum")
Out[82]: 
            C         D
A                      
bar  0.392940  1.732707
foo -1.796421  2.824590

In [83]: grouped = df.groupby(["A", "B"])

In [84]: grouped.agg("sum")
Out[84]: 
                  C         D
A   B                        
bar one    0.254161  1.511763
    three  0.215897 -0.990582
    two   -0.077118  1.211526
foo one   -0.983776  1.614581
    three -0.862495  0.024580
    two    0.049851  1.185429

---->   DataFrame.groupby

--------------------------------------
ID: 4987 --> 1
In [85]: grouped = df.groupby(["A", "B"], as_index=False)

In [86]: grouped.agg("sum")
Out[86]: 
     A      B         C         D
0  bar    one  0.254161  1.511763
1  bar  three  0.215897 -0.990582
2  bar    two -0.077118  1.211526
3  foo    one -0.983776  1.614581
4  foo  three -0.862495  0.024580
5  foo    two  0.049851  1.185429

In [87]: df.groupby("A", as_index=False)[["C", "D"]].agg("sum")
Out[87]: 
     A         C         D
0  bar  0.392940  1.732707
1  foo -1.796421  2.824590

---->   DataFrame.groupby

--------------------------------------
ID: 4988 --> 1
In [88]: df.groupby(["A", "B"]).agg("sum").reset_index()
Out[88]: 
     A      B         C         D
0  bar    one  0.254161  1.511763
1  bar  three  0.215897 -0.990582
2  bar    two -0.077118  1.211526
3  foo    one -0.983776  1.614581
4  foo  three -0.862495  0.024580
5  foo    two  0.049851  1.185429

---->   DataFrame.groupby

--------------------------------------
ID: 4990 --> 1
In [91]: animals.groupby("kind")[["height"]].agg(lambda x: x.astype(int).sum())
Out[91]: 
      height
kind        
cat       18
dog       40

---->   Series.astype

--------------------------------------
ID: 4991 --> 1
In [92]: grouped = df.groupby("A")

In [93]: grouped["C"].agg(["sum", "mean", "std"])
Out[93]: 
          sum      mean       std
A                                
bar  0.392940  0.130980  0.181231
foo -1.796421 -0.359284  0.912265

---->   DataFrame.groupby

--------------------------------------
ID: 4996 --> 4
In [98]: grouped["C"].agg([lambda x: x.max() - x.min(), lambda x: x.median() - x.mean()])
Out[98]: 
       
A                          
bar    0.331279    0.084917
foo    2.337259   -0.215962

---->   Series.max; Series.min; Series.median; Series.mean

--------------------------------------
ID: 4997 --> 1
In [99]: animals
Out[99]: 
  kind  height  weight
0  cat     9.1     7.9
1  dog     6.0     7.5
2  cat     9.5     9.9
3  dog    34.0   198.0

In [100]: animals.groupby("kind").agg(
   .....:     min_height=pd.NamedAgg(column="height", aggfunc="min"),
   .....:     max_height=pd.NamedAgg(column="height", aggfunc="max"),
   .....:     average_weight=pd.NamedAgg(column="weight", aggfunc="mean"),
   .....: )
   .....: 
Out[100]: 
      min_height  max_height  average_weight
kind                                        
cat          9.1         9.5            8.90
dog          6.0        34.0          102.75

---->   pandas.NamedAgg

--------------------------------------
ID: 4999 --> 1
In [102]: animals.groupby("kind").agg(
   .....:     **{
   .....:         "total weight": pd.NamedAgg(column="weight", aggfunc="sum")
   .....:     }
   .....: )
   .....: 
Out[102]: 
      total weight
kind              
cat           17.8
dog          205.5

---->   pandas.NamedAgg

--------------------------------------
ID: 5006 --> 7
In [118]: index = pd.date_range("10/1/1999", periods=1100)

In [119]: ts = pd.Series(np.random.normal(0.5, 2, 1100), index)

In [120]: ts = ts.rolling(window=100, min_periods=100).mean().dropna()

In [121]: ts.head()
Out[121]: 
2000-01-08    0.779333
2000-01-09    0.778852
2000-01-10    0.786476
2000-01-11    0.782797
2000-01-12    0.798110
Freq: D, dtype: float64

In [122]: ts.tail()
Out[122]: 
2002-09-30    0.660294
2002-10-01    0.631095
2002-10-02    0.673601
2002-10-03    0.709213
2002-10-04    0.719369
Freq: D, dtype: float64

In [123]: transformed = ts.groupby(lambda x: x.year).transform(
   .....:     lambda x: (x - x.mean()) / x.std()
   .....: )
   .....: 

---->   pandas.Series; Series.rolling; Series.head; Series.tail; Series.groupby; Series.mean; Series.std

--------------------------------------
ID: 5007 --> 1
# Original Data
In [124]: grouped = ts.groupby(lambda x: x.year)

In [125]: grouped.mean()
Out[125]: 
2000    0.442441
2001    0.526246
2002    0.459365
dtype: float64

In [126]: grouped.std()
Out[126]: 
2000    0.131752
2001    0.210945
2002    0.128753
dtype: float64

# Transformed Data
In [127]: grouped_trans = transformed.groupby(lambda x: x.year)

In [128]: grouped_trans.mean()
Out[128]: 
2000   -4.870756e-16
2001   -1.545187e-16
2002    4.136282e-16
dtype: float64

In [129]: grouped_trans.std()
Out[129]: 
2000    1.0
2001    1.0
2002    1.0
dtype: float64

---->   Series.groupby

--------------------------------------
ID: 5008 --> 2
In [130]: compare = pd.DataFrame({"Original": ts, "Transformed": transformed})

In [131]: compare.plot()
Out[131]: 

---->   pandas.DataFrame; DataFrame.plot

--------------------------------------
ID: 5009 --> 3
In [132]: ts.groupby(lambda x: x.year).transform(lambda x: x.max() - x.min())
Out[132]: 
2000-01-08    0.623893
2000-01-09    0.623893
2000-01-10    0.623893
2000-01-11    0.623893
2000-01-12    0.623893
                ...   
2002-09-30    0.558275
2002-10-01    0.558275
2002-10-02    0.558275
2002-10-03    0.558275
2002-10-04    0.558275
Freq: D, Length: 1001, dtype: float64

---->   Series.groupby; Series.max; Series.min

--------------------------------------
ID: 5010 --> 1
In [133]: data_df
Out[133]: 
            A         B         C
0    1.539708 -1.166480  0.533026
1    1.302092 -0.505754       NaN
2   -0.371983  1.104803 -0.651520
3   -1.309622  1.118697 -1.161657
4   -1.924296  0.396437  0.812436
..        ...       ...       ...
995 -0.093110  0.683847 -0.774753
996 -0.185043  1.438572       NaN
997 -0.394469 -0.642343  0.011374
998 -1.174126  1.857148       NaN
999  0.234564  0.517098  0.393534

[1000 rows x 3 columns]

In [134]: countries = np.array(["US", "UK", "GR", "JP"])

In [135]: key = countries[np.random.randint(0, 4, 1000)]

In [136]: grouped = data_df.groupby(key)

# Non-NA count in each group
In [137]: grouped.count()
Out[137]: 
      A    B    C
GR  209  217  189
JP  240  255  217
UK  216  231  193
US  239  250  217

In [138]: transformed = grouped.transform(lambda x: x.fillna(x.mean()))

---->   Series.mean

--------------------------------------
ID: 5012 --> 5
# ts.groupby(lambda x: x.year).transform(
#     lambda x: (x - x.mean()) / x.std()
# )
In [145]: grouped = ts.groupby(lambda x: x.year)

In [146]: result = (ts - grouped.transform("mean")) / grouped.transform("std")

# ts.groupby(lambda x: x.year).transform(lambda x: x.max() - x.min())
In [147]: grouped = ts.groupby(lambda x: x.year)

In [148]: result = grouped.transform("max") - grouped.transform("min")

# grouped = data_df.groupby(key)
# grouped.transform(lambda x: x.fillna(x.mean()))
In [149]: grouped = data_df.groupby(key)

In [150]: result = data_df.fillna(grouped.transform("mean"))

---->   Series.groupby; Series.mean; Series.std; Series.max; Series.min

--------------------------------------
ID: 5013 --> 2
In [151]: df_re = pd.DataFrame({"A": [1] * 10 + [5] * 10, "B": np.arange(20)})

In [152]: df_re
Out[152]: 
    A   B
0   1   0
1   1   1
2   1   2
3   1   3
4   1   4
.. ..  ..
15  5  15
16  5  16
17  5  17
18  5  18
19  5  19

[20 rows x 2 columns]

In [153]: df_re.groupby("A").rolling(4).B.mean()
Out[153]: 
A    
1  0      NaN
   1      NaN
   2      NaN
   3      1.5
   4      2.5
         ... 
5  15    13.5
   16    14.5
   17    15.5
   18    16.5
   19    17.5
Name: B, Length: 20, dtype: float64

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 5014 --> 1
In [154]: df_re.groupby("A").expanding().sum()
Out[154]: 
          B
A          
1 0     0.0
  1     1.0
  2     3.0
  3     6.0
  4    10.0
...     ...
5 15   75.0
  16   91.0
  17  108.0
  18  126.0
  19  145.0

[20 rows x 1 columns]

---->   DataFrame.groupby

--------------------------------------
ID: 5015 --> 2
In [155]: df_re = pd.DataFrame(
   .....:     {
   .....:         "date": pd.date_range(start="2016-01-01", periods=4, freq="W"),
   .....:         "group": [1, 1, 2, 2],
   .....:         "val": [5, 6, 7, 8],
   .....:     }
   .....: ).set_index("date")
   .....: 

In [156]: df_re
Out[156]: 
            group  val
date                  
2016-01-03      1    5
2016-01-10      1    6
2016-01-17      2    7
2016-01-24      2    8

In [157]: df_re.groupby("group").resample("1D").ffill()
Out[157]: 
                  group  val
group date                  
1     2016-01-03      1    5
      2016-01-04      1    5
      2016-01-05      1    5
      2016-01-06      1    5
      2016-01-07      1    5
...                 ...  ...
2     2016-01-20      2    7
      2016-01-21      2    7
      2016-01-22      2    7
      2016-01-23      2    7
      2016-01-24      2    8

[16 rows x 2 columns]

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 5018 --> 1
In [161]: product_volumes = pd.DataFrame(
   .....:     {
   .....:         "group": list("xxxxyyy"),
   .....:         "product": list("abcdefg"),
   .....:         "volume": [10, 30, 20, 15, 40, 10, 20],
   .....:     }
   .....: )
   .....: 

In [162]: product_volumes
Out[162]: 
  group product  volume
0     x       a      10
1     x       b      30
2     x       c      20
3     x       d      15
4     y       e      40
5     y       f      10
6     y       g      20

# Sort by volume to select the largest products first
In [163]: product_volumes = product_volumes.sort_values("volume", ascending=False)

In [164]: grouped = product_volumes.groupby("group")["volume"]

In [165]: cumpct = grouped.cumsum() / grouped.transform("sum")

In [166]: cumpct
Out[166]: 
4    0.571429
1    0.400000
2    0.666667
6    0.857143
3    0.866667
0    1.000000
5    1.000000
Name: volume, dtype: float64

In [167]: significant_products = product_volumes[cumpct <= 0.9]

In [168]: significant_products.sort_values(["group", "product"])
Out[168]: 
  group product  volume
1     x       b      30
2     x       c      20
3     x       d      15
4     y       e      40
6     y       g      20

---->   pandas.DataFrame

--------------------------------------
ID: 5019 --> 3
In [169]: sf = pd.Series([1, 1, 2, 3, 3, 3])

In [170]: sf.groupby(sf).filter(lambda x: x.sum() > 2)
Out[170]: 
3    3
4    3
5    3
dtype: int64

---->   pandas.Series; Series.groupby; Series.sum

--------------------------------------
ID: 5020 --> 2
In [171]: dff = pd.DataFrame({"A": np.arange(8), "B": list("aabbbbcc")})

In [172]: dff.groupby("B").filter(lambda x: len(x) > 2)
Out[172]: 
   A  B
2  2  b
3  3  b
4  4  b
5  5  b

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 5021 --> 1
In [173]: dff.groupby("B").filter(lambda x: len(x) > 2, dropna=False)
Out[173]: 
     A    B
0  NaN  NaN
1  NaN  NaN
2  2.0    b
3  3.0    b
4  4.0    b
5  5.0    b
6  NaN  NaN
7  NaN  NaN

---->   DataFrame.groupby

--------------------------------------
ID: 5022 --> 1
In [174]: dff["C"] = np.arange(8)

In [175]: dff.groupby("B").filter(lambda x: len(x["C"]) > 2)
Out[175]: 
   A  B  C
2  2  b  2
3  3  b  3
4  4  b  4
5  5  b  5

---->   DataFrame.groupby

--------------------------------------
ID: 5023 --> 2
In [176]: df
Out[176]: 
     A      B         C         D
0  foo    one -0.575247  1.346061
1  bar    one  0.254161  1.511763
2  foo    two -1.143704  1.627081
3  bar  three  0.215897 -0.990582
4  foo    two  1.193555 -0.441652
5  bar    two -0.077118  1.211526
6  foo    one -0.408530  0.268520
7  foo  three -0.862495  0.024580

In [177]: grouped = df.groupby("A")

# could also just call .describe()
In [178]: grouped["C"].apply(lambda x: x.describe())
Out[178]: 
A         
bar  count    3.000000
     mean     0.130980
     std      0.181231
     min     -0.077118
     25%      0.069390
                ...   
foo  min     -1.143704
     25%     -0.862495
     50%     -0.575247
     75%     -0.408530
     max      1.193555
Name: C, Length: 16, dtype: float64

---->   DataFrame.groupby; Series.describe

--------------------------------------
ID: 5024 --> 2
In [179]: grouped = df.groupby('A')['C']

In [180]: def f(group):
   .....:     return pd.DataFrame({'original': group,
   .....:                          'demeaned': group - group.mean()})
   .....: 

In [181]: grouped.apply(f)
Out[181]: 
       original  demeaned
A                        
bar 1  0.254161  0.123181
    3  0.215897  0.084917
    5 -0.077118 -0.208098
foo 0 -0.575247 -0.215962
    2 -1.143704 -0.784420
    4  1.193555  1.552839
    6 -0.408530 -0.049245
    7 -0.862495 -0.503211

---->   DataFrame.groupby; pandas.DataFrame

--------------------------------------
ID: 5025 --> 1
In [182]: def f(x):
   .....:     return pd.Series([x, x ** 2], index=["x", "x^2"])
   .....: 

In [183]: s = pd.Series(np.random.rand(5))

In [184]: s
Out[184]: 
0    0.582898
1    0.098352
2    0.001438
3    0.009420
4    0.815826
dtype: float64

In [185]: s.apply(f)
Out[185]: 
          x       x^2
0  0.582898  0.339770
1  0.098352  0.009673
2  0.001438  0.000002
3  0.009420  0.000089
4  0.815826  0.665572

---->   pandas.Series

--------------------------------------
ID: 5026 --> 1
In [186]: df.groupby("A", group_keys=True).apply(lambda x: x)
Out[186]: 
         A      B         C         D
A                                    
bar 1  bar    one  0.254161  1.511763
    3  bar  three  0.215897 -0.990582
    5  bar    two -0.077118  1.211526
foo 0  foo    one -0.575247  1.346061
    2  foo    two -1.143704  1.627081
    4  foo    two  1.193555 -0.441652
    6  foo    one -0.408530  0.268520
    7  foo  three -0.862495  0.024580

---->   DataFrame.groupby

--------------------------------------
ID: 5027 --> 1
In [187]: df.groupby("A", group_keys=False).apply(lambda x: x)
Out[187]: 
     A      B         C         D
0  foo    one -0.575247  1.346061
1  bar    one  0.254161  1.511763
2  foo    two -1.143704  1.627081
3  bar  three  0.215897 -0.990582
4  foo    two  1.193555 -0.441652
5  bar    two -0.077118  1.211526
6  foo    one -0.408530  0.268520
7  foo  three -0.862495  0.024580

---->   DataFrame.groupby

--------------------------------------
ID: 5028 --> 1
In [189]: df.groupby("A").std(numeric_only=True)
Out[189]: 
            C         D
A                      
bar  0.181231  1.366330
foo  0.912265  0.884785

---->   DataFrame.groupby

--------------------------------------
ID: 5029 --> 1
In [190]: from decimal import Decimal

In [191]: df_dec = pd.DataFrame(
   .....:     {
   .....:         "id": [1, 2, 1, 2],
   .....:         "int_column": [1, 2, 3, 4],
   .....:         "dec_column": [
   .....:             Decimal("0.50"),
   .....:             Decimal("0.15"),
   .....:             Decimal("0.25"),
   .....:             Decimal("0.40"),
   .....:         ],
   .....:     }
   .....: )
   .....: 

# Decimal columns can be sum'd explicitly by themselves...
In [192]: df_dec.groupby(["id"])[["dec_column"]].sum()
Out[192]: 
   dec_column
id           
1        0.75
2        0.55

# ...but cannot be combined with standard data types or they will be excluded
In [193]: df_dec.groupby(["id"])[["int_column", "dec_column"]].sum()
Out[193]: 
    int_column dec_column
id                       
1            4       0.75
2            6       0.55

# Use .agg function to aggregate over standard and "nuisance" data types
# at the same time
In [194]: df_dec.groupby(["id"]).agg({"int_column": "sum", "dec_column": "sum"})
Out[194]: 
    int_column dec_column
id                       
1            4       0.75
2            6       0.55

---->   pandas.DataFrame

--------------------------------------
ID: 5030 --> 2
In [195]: pd.Series([1, 1, 1]).groupby(
   .....:     pd.Categorical(["a", "a", "a"], categories=["a", "b"]), observed=False
   .....: ).count()
   .....: 
Out[195]: 
a    3
b    0
dtype: int64

---->   pandas.Series; pandas.Categorical

--------------------------------------
ID: 5031 --> 2
In [196]: pd.Series([1, 1, 1]).groupby(
   .....:     pd.Categorical(["a", "a", "a"], categories=["a", "b"]), observed=True
   .....: ).count()
   .....: 
Out[196]: 
a    3
dtype: int64

---->   pandas.Series; pandas.Categorical

--------------------------------------
ID: 5032 --> 2
In [197]: s = (
   .....:     pd.Series([1, 1, 1])
   .....:     .groupby(pd.Categorical(["a", "a", "a"], categories=["a", "b"]), observed=False)
   .....:     .count()
   .....: )
   .....: 

In [198]: s.index.dtype
Out[198]: CategoricalDtype(categories=['a', 'b'], ordered=False)

---->   pandas.Series; pandas.Categorical

--------------------------------------
ID: 5033 --> 3
In [199]: data = pd.Series(np.random.randn(100))

In [200]: factor = pd.qcut(data, [0, 0.25, 0.5, 0.75, 1.0])

In [201]: data.groupby(factor).mean()
Out[201]: 
(-2.784, -0.41]   -1.196181
(-0.41, 0.0754]   -0.127244
(0.0754, 0.795]    0.408266
(0.795, 2.821]     1.357293
dtype: float64

---->   pandas.Series; pandas.qcut; Series.groupby

--------------------------------------
ID: 5034 --> 1
In [202]: import datetime

In [203]: df = pd.DataFrame(
   .....:     {
   .....:         "Branch": "A A A A A A A B".split(),
   .....:         "Buyer": "Carl Mark Carl Carl Joe Joe Joe Carl".split(),
   .....:         "Quantity": [1, 3, 5, 1, 8, 1, 9, 3],
   .....:         "Date": [
   .....:             datetime.datetime(2013, 1, 1, 13, 0),
   .....:             datetime.datetime(2013, 1, 1, 13, 5),
   .....:             datetime.datetime(2013, 10, 1, 20, 0),
   .....:             datetime.datetime(2013, 10, 2, 10, 0),
   .....:             datetime.datetime(2013, 10, 1, 20, 0),
   .....:             datetime.datetime(2013, 10, 2, 10, 0),
   .....:             datetime.datetime(2013, 12, 2, 12, 0),
   .....:             datetime.datetime(2013, 12, 2, 14, 0),
   .....:         ],
   .....:     }
   .....: )
   .....: 

In [204]: df
Out[204]: 
  Branch Buyer  Quantity                Date
0      A  Carl         1 2013-01-01 13:00:00
1      A  Mark         3 2013-01-01 13:05:00
2      A  Carl         5 2013-10-01 20:00:00
3      A  Carl         1 2013-10-02 10:00:00
4      A   Joe         8 2013-10-01 20:00:00
5      A   Joe         1 2013-10-02 10:00:00
6      A   Joe         9 2013-12-02 12:00:00
7      B  Carl         3 2013-12-02 14:00:00

---->   pandas.DataFrame

--------------------------------------
ID: 5035 --> 2
In [205]: df.groupby([pd.Grouper(freq="1M", key="Date"), "Buyer"])[["Quantity"]].sum()
Out[205]: 
                  Quantity
Date       Buyer          
2013-01-31 Carl          1
           Mark          3
2013-10-31 Carl          6
           Joe           9
2013-12-31 Carl          3
           Joe           9

---->   DataFrame.groupby; pandas.Grouper

--------------------------------------
ID: 5036 --> 2
In [206]: df = df.set_index("Date")

In [207]: df["Date"] = df.index + pd.offsets.MonthEnd(2)

In [208]: df.groupby([pd.Grouper(freq="6M", key="Date"), "Buyer"])[["Quantity"]].sum()
Out[208]: 
                  Quantity
Date       Buyer          
2013-02-28 Carl          1
           Mark          3
2014-02-28 Carl          9
           Joe          18

In [209]: df.groupby([pd.Grouper(freq="6M", level="Date"), "Buyer"])[["Quantity"]].sum()
Out[209]: 
                  Quantity
Date       Buyer          
2013-01-31 Carl          1
           Mark          3
2014-01-31 Carl          9
           Joe          18

---->   DataFrame.groupby; pandas.Grouper

--------------------------------------
ID: 5037 --> 2
In [210]: df = pd.DataFrame([[1, 2], [1, 4], [5, 6]], columns=["A", "B"])

In [211]: df
Out[211]: 
   A  B
0  1  2
1  1  4
2  5  6

In [212]: g = df.groupby("A")

In [213]: g.head(1)
Out[213]: 
   A  B
0  1  2
2  5  6

In [214]: g.tail(1)
Out[214]: 
   A  B
1  1  4
2  5  6

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 5038 --> 2
In [215]: df = pd.DataFrame([[1, np.nan], [1, 4], [5, 6]], columns=["A", "B"])

In [216]: g = df.groupby("A")

In [217]: g.nth(0)
Out[217]: 
   A    B
0  1  NaN
2  5  6.0

In [218]: g.nth(-1)
Out[218]: 
   A    B
1  1  4.0
2  5  6.0

In [219]: g.nth(1)
Out[219]: 
   A    B
1  1  4.0

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 5041 --> 2
In [226]: business_dates = pd.date_range(start="4/1/2014", end="6/30/2014", freq="B")

In [227]: df = pd.DataFrame(1, index=business_dates, columns=["a", "b"])

# get the first, 4th, and last date index for each month
In [228]: df.groupby([df.index.year, df.index.month]).nth([0, 3, -1])
Out[228]: 
            a  b
2014-04-01  1  1
2014-04-04  1  1
2014-04-30  1  1
2014-05-01  1  1
2014-05-06  1  1
2014-05-30  1  1
2014-06-02  1  1
2014-06-05  1  1
2014-06-30  1  1

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 5042 --> 1
In [229]: df.groupby([df.index.year, df.index.month]).nth[1:]
Out[229]: 
            a  b
2014-04-02  1  1
2014-04-03  1  1
2014-04-04  1  1
2014-04-07  1  1
2014-04-08  1  1
...        .. ..
2014-06-24  1  1
2014-06-25  1  1
2014-06-26  1  1
2014-06-27  1  1
2014-06-30  1  1

[62 rows x 2 columns]

In [230]: df.groupby([df.index.year, df.index.month]).nth[1:, :-1]
Out[230]: 
            a  b
2014-04-01  1  1
2014-04-02  1  1
2014-04-03  1  1
2014-04-04  1  1
2014-04-07  1  1
...        .. ..
2014-06-24  1  1
2014-06-25  1  1
2014-06-26  1  1
2014-06-27  1  1
2014-06-30  1  1

[65 rows x 2 columns]

---->   DataFrame.groupby

--------------------------------------
ID: 5043 --> 2
In [231]: dfg = pd.DataFrame(list("aaabba"), columns=["A"])

In [232]: dfg
Out[232]: 
   A
0  a
1  a
2  a
3  b
4  b
5  a

In [233]: dfg.groupby("A").cumcount()
Out[233]: 
0    0
1    1
2    2
3    0
4    1
5    3
dtype: int64

In [234]: dfg.groupby("A").cumcount(ascending=False)
Out[234]: 
0    3
1    2
2    1
3    1
4    0
5    0
dtype: int64

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 5044 --> 2
In [235]: dfg = pd.DataFrame(list("aaabba"), columns=["A"])

In [236]: dfg
Out[236]: 
   A
0  a
1  a
2  a
3  b
4  b
5  a

In [237]: dfg.groupby("A").ngroup()
Out[237]: 
0    0
1    0
2    0
3    1
4    1
5    0
dtype: int64

In [238]: dfg.groupby("A").ngroup(ascending=False)
Out[238]: 
0    1
1    1
2    1
3    0
4    0
5    1
dtype: int64

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 5045 --> 1
In [239]: np.random.seed(1234)

In [240]: df = pd.DataFrame(np.random.randn(50, 2))

In [241]: df["g"] = np.random.choice(["A", "B"], size=50)

In [242]: df.loc[df["g"] == "B", 1] += 3

---->   pandas.DataFrame

--------------------------------------
ID: 5046 --> 1
In [243]: df.groupby("g").boxplot()
Out[243]: 
A         AxesSubplot(0.1,0.15;0.363636x0.75)
B    AxesSubplot(0.536364,0.15;0.363636x0.75)
dtype: object

---->   DataFrame.groupby

--------------------------------------
ID: 5047 --> 2
In [244]: n = 1000

In [245]: df = pd.DataFrame(
   .....:     {
   .....:         "Store": np.random.choice(["Store_1", "Store_2"], n),
   .....:         "Product": np.random.choice(["Product_1", "Product_2"], n),
   .....:         "Revenue": (np.random.random(n) * 50 + 10).round(2),
   .....:         "Quantity": np.random.randint(1, 10, size=n),
   .....:     }
   .....: )
   .....: 

In [246]: df.head(2)
Out[246]: 
     Store    Product  Revenue  Quantity
0  Store_2  Product_1    26.12         1
1  Store_2  Product_1    28.86         1

---->   pandas.DataFrame; DataFrame.head

--------------------------------------
ID: 5048 --> 1
In [247]: (
   .....:     df.groupby(["Store", "Product"])
   .....:     .pipe(lambda grp: grp.Revenue.sum() / grp.Quantity.sum())
   .....:     .unstack()
   .....:     .round(2)
   .....: )
   .....: 
Out[247]: 
Product  Product_1  Product_2
Store                        
Store_1       6.82       7.05
Store_2       6.30       6.64

---->   DataFrame.groupby

--------------------------------------
ID: 5049 --> 1
In [248]: def mean(groupby):
   .....:     return groupby.mean()
   .....: 

In [249]: df.groupby(["Store", "Product"]).pipe(mean)
Out[249]: 
                     Revenue  Quantity
Store   Product                       
Store_1 Product_1  34.622727  5.075758
        Product_2  35.482815  5.029630
Store_2 Product_1  32.972837  5.237589
        Product_2  34.684360  5.224000

---->   DataFrame.groupby

--------------------------------------
ID: 5050 --> 3
In [250]: df = pd.DataFrame({"a": [1, 0, 0], "b": [0, 1, 0], "c": [1, 0, 0], "d": [2, 3, 4]})

In [251]: df
Out[251]: 
   a  b  c  d
0  1  0  1  2
1  0  1  0  3
2  0  0  0  4

In [252]: df.groupby(df.sum(), axis=1).sum()
Out[252]: 
   1  9
0  2  2
1  1  3
2  0  4

---->   pandas.DataFrame; DataFrame.groupby; DataFrame.sum

--------------------------------------
ID: 5051 --> 2
In [253]: dfg = pd.DataFrame({"A": [1, 1, 2, 3, 2], "B": list("aaaba")})

In [254]: dfg
Out[254]: 
   A  B
0  1  a
1  1  a
2  2  a
3  3  b
4  2  a

In [255]: dfg.groupby(["A", "B"]).ngroup()
Out[255]: 
0    0
1    0
2    1
3    2
4    1
dtype: int64

In [256]: dfg.groupby(["A", [0, 0, 0, 1, 1]]).ngroup()
Out[256]: 
0    0
1    0
2    1
3    3
4    2
dtype: int64

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 5052 --> 2
In [257]: df = pd.DataFrame(np.random.randn(10, 2))

In [258]: df
Out[258]: 
          0         1
0 -0.793893  0.321153
1  0.342250  1.618906
2 -0.975807  1.918201
3 -0.810847 -1.405919
4 -1.977759  0.461659
5  0.730057 -1.316938
6 -0.751328  0.528290
7 -0.257759 -1.081009
8  0.505895 -1.701948
9 -1.006349  0.020208

In [259]: df.index // 5
Out[259]: Index([0, 0, 0, 0, 0, 1, 1, 1, 1, 1], dtype='int64')

In [260]: df.groupby(df.index // 5).std()
Out[260]: 
          0         1
0  0.823647  1.312912
1  0.760109  0.942941

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 5053 --> 3
In [261]: df = pd.DataFrame(
   .....:     {
   .....:         "a": [0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2],
   .....:         "b": [0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1],
   .....:         "c": [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0],
   .....:         "d": [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1],
   .....:     }
   .....: )
   .....: 

In [262]: def compute_metrics(x):
   .....:     result = {"b_sum": x["b"].sum(), "c_mean": x["c"].mean()}
   .....:     return pd.Series(result, name="metrics")
   .....: 

In [263]: result = df.groupby("a").apply(compute_metrics)

In [264]: result
Out[264]: 
metrics  b_sum  c_mean
a                     
0          2.0     0.5
1          2.0     0.5
2          2.0     0.5

In [265]: result.stack()
Out[265]: 
a  metrics
0  b_sum      2.0
   c_mean     0.5
1  b_sum      2.0
   c_mean     0.5
2  b_sum      2.0
   c_mean     0.5
dtype: float64

---->   pandas.DataFrame; pandas.Series; DataFrame.groupby

--------------------------------------
ID: 5054 --> 1
In [1]: df = pd.DataFrame(
   ...:     np.random.randn(5, 3),
   ...:     index=["a", "c", "e", "f", "h"],
   ...:     columns=["one", "two", "three"],
   ...: )
   ...: 

In [2]: df["four"] = "bar"

In [3]: df["five"] = df["one"] > 0

In [4]: df
Out[4]: 
        one       two     three four   five
a  0.469112 -0.282863 -1.509059  bar   True
c -1.135632  1.212112 -0.173215  bar  False
e  0.119209 -1.044236 -0.861849  bar   True
f -2.104569 -0.494929  1.071804  bar  False
h  0.721555 -0.706771 -1.039575  bar   True

In [5]: df2 = df.reindex(["a", "b", "c", "d", "e", "f", "g", "h"])

In [6]: df2
Out[6]: 
        one       two     three four   five
a  0.469112 -0.282863 -1.509059  bar   True
b       NaN       NaN       NaN  NaN    NaN
c -1.135632  1.212112 -0.173215  bar  False
d       NaN       NaN       NaN  NaN    NaN
e  0.119209 -1.044236 -0.861849  bar   True
f -2.104569 -0.494929  1.071804  bar  False
g       NaN       NaN       NaN  NaN    NaN
h  0.721555 -0.706771 -1.039575  bar   True

---->   pandas.DataFrame

--------------------------------------
ID: 5055 --> 2
In [7]: df2["one"]
Out[7]: 
a    0.469112
b         NaN
c   -1.135632
d         NaN
e    0.119209
f   -2.104569
g         NaN
h    0.721555
Name: one, dtype: float64

In [8]: pd.isna(df2["one"])
Out[8]: 
a    False
b     True
c    False
d     True
e    False
f    False
g     True
h    False
Name: one, dtype: bool

In [9]: df2["four"].notna()
Out[9]: 
a     True
b    False
c     True
d    False
e     True
f     True
g    False
h     True
Name: four, dtype: bool

In [10]: df2.isna()
Out[10]: 
     one    two  three   four   five
a  False  False  False  False  False
b   True   True   True   True   True
c  False  False  False  False  False
d   True   True   True   True   True
e  False  False  False  False  False
f  False  False  False  False  False
g   True   True   True   True   True
h  False  False  False  False  False

---->   pandas.isna; DataFrame.isna

--------------------------------------
ID: 5056 --> 2
In [14]: pd.Series([1, 2, np.nan, 4], dtype=pd.Int64Dtype())
Out[14]: 
0       1
1       2
2    
3       4
dtype: Int64

---->   pandas.Series; pandas.Int64Dtype

--------------------------------------
ID: 5057 --> 1
In [15]: df2 = df.copy()

In [16]: df2["timestamp"] = pd.Timestamp("20120101")

In [17]: df2
Out[17]: 
        one       two     three four   five  timestamp
a  0.469112 -0.282863 -1.509059  bar   True 2012-01-01
c -1.135632  1.212112 -0.173215  bar  False 2012-01-01
e  0.119209 -1.044236 -0.861849  bar   True 2012-01-01
f -2.104569 -0.494929  1.071804  bar  False 2012-01-01
h  0.721555 -0.706771 -1.039575  bar   True 2012-01-01

In [18]: df2.loc[["a", "c", "h"], ["one", "timestamp"]] = np.nan

In [19]: df2
Out[19]: 
        one       two     three four   five  timestamp
a       NaN -0.282863 -1.509059  bar   True        NaT
c       NaN  1.212112 -0.173215  bar  False        NaT
e  0.119209 -1.044236 -0.861849  bar   True 2012-01-01
f -2.104569 -0.494929  1.071804  bar  False 2012-01-01
h       NaN -0.706771 -1.039575  bar   True        NaT

In [20]: df2.dtypes.value_counts()
Out[20]: 
float64           3
object            1
bool              1
datetime64[ns]    1
Name: count, dtype: int64

---->   DataFrame.copy

--------------------------------------
ID: 5058 --> 1
In [21]: s = pd.Series([1, 2, 3])

In [22]: s.loc[0] = None

In [23]: s
Out[23]: 
0    NaN
1    2.0
2    3.0
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 5059 --> 1
In [24]: s = pd.Series(["a", "b", "c"])

In [25]: s.loc[0] = None

In [26]: s.loc[1] = np.nan

In [27]: s
Out[27]: 
0    None
1     NaN
2       c
dtype: object

---->   pandas.Series

--------------------------------------
ID: 5060 --> 2
In [31]: df
Out[31]: 
        one       two     three
a       NaN -0.282863 -1.509059
c       NaN  1.212112 -0.173215
e  0.119209 -1.044236 -0.861849
f -2.104569 -0.494929  1.071804
h       NaN -0.706771 -1.039575

In [32]: df["one"].sum()
Out[32]: -1.9853605075978744

In [33]: df.mean(1)
Out[33]: 
a   -0.895961
c    0.519449
e   -0.595625
f   -0.509232
h   -0.873173
dtype: float64

In [34]: df.cumsum()
Out[34]: 
        one       two     three
a       NaN -0.282863 -1.509059
c       NaN  0.929249 -1.682273
e  0.119209 -0.114987 -2.544122
f -1.985361 -0.609917 -1.472318
h       NaN -1.316688 -2.511893

In [35]: df.cumsum(skipna=False)
Out[35]: 
   one       two     three
a  NaN -0.282863 -1.509059
c  NaN  0.929249 -1.682273
e  NaN -0.114987 -2.544122
f  NaN -0.609917 -1.472318
h  NaN -1.316688 -2.511893

---->   DataFrame.mean; DataFrame.cumsum

--------------------------------------
ID: 5061 --> 1
In [36]: pd.Series([np.nan]).sum()
Out[36]: 0.0

In [37]: pd.Series([], dtype="float64").sum()
Out[37]: 0.0

---->   pandas.Series

--------------------------------------
ID: 5062 --> 1
In [38]: pd.Series([np.nan]).prod()
Out[38]: 1.0

In [39]: pd.Series([], dtype="float64").prod()
Out[39]: 1.0

---->   pandas.Series

--------------------------------------
ID: 5063 --> 1
In [40]: df
Out[40]: 
        one       two     three
a       NaN -0.282863 -1.509059
c       NaN  1.212112 -0.173215
e  0.119209 -1.044236 -0.861849
f -2.104569 -0.494929  1.071804
h       NaN -0.706771 -1.039575

In [41]: df.groupby("one").mean()
Out[41]: 
                two     three
one                          
-2.104569 -0.494929  1.071804
 0.119209 -1.044236 -0.861849

---->   DataFrame.groupby

--------------------------------------
ID: 5067 --> 2
In [49]: dff = pd.DataFrame(np.random.randn(10, 3), columns=list("ABC"))

In [50]: dff.iloc[3:5, 0] = np.nan

In [51]: dff.iloc[4:6, 1] = np.nan

In [52]: dff.iloc[5:8, 2] = np.nan

In [53]: dff
Out[53]: 
          A         B         C
0  0.271860 -0.424972  0.567020
1  0.276232 -1.087401 -0.673690
2  0.113648 -1.478427  0.524988
3       NaN  0.577046 -1.715002
4       NaN       NaN -1.157892
5 -1.344312       NaN       NaN
6 -0.109050  1.643563       NaN
7  0.357021 -0.674600       NaN
8 -0.968914 -1.294524  0.413738
9  0.276662 -0.472035 -0.013960

In [54]: dff.fillna(dff.mean())
Out[54]: 
          A         B         C
0  0.271860 -0.424972  0.567020
1  0.276232 -1.087401 -0.673690
2  0.113648 -1.478427  0.524988
3 -0.140857  0.577046 -1.715002
4 -0.140857 -0.401419 -1.157892
5 -1.344312 -0.401419 -0.293543
6 -0.109050  1.643563 -0.293543
7  0.357021 -0.674600 -0.293543
8 -0.968914 -1.294524  0.413738
9  0.276662 -0.472035 -0.013960

In [55]: dff.fillna(dff.mean()["B":"C"])
Out[55]: 
          A         B         C
0  0.271860 -0.424972  0.567020
1  0.276232 -1.087401 -0.673690
2  0.113648 -1.478427  0.524988
3       NaN  0.577046 -1.715002
4       NaN -0.401419 -1.157892
5 -1.344312 -0.401419 -0.293543
6 -0.109050  1.643563 -0.293543
7  0.357021 -0.674600 -0.293543
8 -0.968914 -1.294524  0.413738
9  0.276662 -0.472035 -0.013960

---->   pandas.DataFrame; DataFrame.mean

--------------------------------------
ID: 5068 --> 2
In [56]: dff.where(pd.notna(dff), dff.mean(), axis="columns")
Out[56]: 
          A         B         C
0  0.271860 -0.424972  0.567020
1  0.276232 -1.087401 -0.673690
2  0.113648 -1.478427  0.524988
3 -0.140857  0.577046 -1.715002
4 -0.140857 -0.401419 -1.157892
5 -1.344312 -0.401419 -0.293543
6 -0.109050  1.643563 -0.293543
7  0.357021 -0.674600 -0.293543
8 -0.968914 -1.294524  0.413738
9  0.276662 -0.472035 -0.013960

---->   pandas.notna; DataFrame.mean

--------------------------------------
ID: 5070 --> 2
In [61]: ts
Out[61]: 
2000-01-31    0.469112
2000-02-29         NaN
2000-03-31         NaN
2000-04-28         NaN
2000-05-31         NaN
                ...   
2007-12-31   -6.950267
2008-01-31   -7.904475
2008-02-29   -6.441779
2008-03-31   -8.184940
2008-04-30   -9.011531
Freq: BM, Length: 100, dtype: float64

In [62]: ts.count()
Out[62]: 66

In [63]: ts.plot()
Out[63]: 

---->   Series.count; Series.plot

--------------------------------------
ID: 5074 --> 1
In [73]: df = pd.DataFrame(
   ....:     {
   ....:         "A": [1, 2.1, np.nan, 4.7, 5.6, 6.8],
   ....:         "B": [0.25, np.nan, np.nan, 4, 12.2, 14.4],
   ....:     }
   ....: )
   ....: 

In [74]: df
Out[74]: 
     A      B
0  1.0   0.25
1  2.1    NaN
2  NaN    NaN
3  4.7   4.00
4  5.6  12.20
5  6.8  14.40

In [75]: df.interpolate()
Out[75]: 
     A      B
0  1.0   0.25
1  2.1   1.50
2  3.4   2.75
3  4.7   4.00
4  5.6  12.20
5  6.8  14.40

---->   pandas.DataFrame

--------------------------------------
ID: 5077 --> 3
In [81]: np.random.seed(2)

In [82]: ser = pd.Series(np.arange(1, 10.1, 0.25) ** 2 + np.random.randn(37))

In [83]: missing = np.array([4, 13, 14, 15, 16, 17, 18, 20, 29])

In [84]: ser[missing] = np.nan

In [85]: methods = ["linear", "quadratic", "cubic"]

In [86]: df = pd.DataFrame({m: ser.interpolate(method=m) for m in methods})

In [87]: df.plot()
Out[87]: 

---->   pandas.Series; pandas.DataFrame; DataFrame.plot

--------------------------------------
ID: 5078 --> 2
In [88]: ser = pd.Series(np.sort(np.random.uniform(size=100)))

# interpolate at new_index
In [89]: new_index = ser.index.union(pd.Index([49.25, 49.5, 49.75, 50.25, 50.5, 50.75]))

In [90]: interp_s = ser.reindex(new_index).interpolate(method="pchip")

In [91]: interp_s[49:51]
Out[91]: 
49.00    0.471410
49.25    0.476841
49.50    0.481780
49.75    0.485998
50.00    0.489266
50.25    0.491814
50.50    0.493995
50.75    0.495763
51.00    0.497074
dtype: float64

---->   pandas.Series; pandas.Index

--------------------------------------
ID: 5079 --> 1
In [92]: ser = pd.Series([np.nan, np.nan, 5, np.nan, np.nan, np.nan, 13, np.nan, np.nan])

In [93]: ser
Out[93]: 
0     NaN
1     NaN
2     5.0
3     NaN
4     NaN
5     NaN
6    13.0
7     NaN
8     NaN
dtype: float64

# fill all consecutive values in a forward direction
In [94]: ser.interpolate()
Out[94]: 
0     NaN
1     NaN
2     5.0
3     7.0
4     9.0
5    11.0
6    13.0
7    13.0
8    13.0
dtype: float64

# fill one consecutive value in a forward direction
In [95]: ser.interpolate(limit=1)
Out[95]: 
0     NaN
1     NaN
2     5.0
3     7.0
4     NaN
5     NaN
6    13.0
7    13.0
8     NaN
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 5082 --> 1
In [102]: ser = pd.Series([0.0, 1.0, 2.0, 3.0, 4.0])

In [103]: ser.replace(0, 5)
Out[103]: 
0    5.0
1    1.0
2    2.0
3    3.0
4    4.0
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 5085 --> 1
In [106]: df = pd.DataFrame({"a": [0, 1, 2, 3, 4], "b": [5, 6, 7, 8, 9]})

In [107]: df.replace({"a": 0, "b": 5}, 100)
Out[107]: 
     a    b
0  100  100
1    1    6
2    2    7
3    3    8
4    4    9

---->   pandas.DataFrame

--------------------------------------
ID: 5087 --> 1
In [109]: d = {"a": list(range(4)), "b": list("ab.."), "c": ["a", "b", np.nan, "d"]}

In [110]: df = pd.DataFrame(d)

In [111]: df.replace(".", np.nan)
Out[111]: 
   a    b    c
0  0    a    a
1  1    b    b
2  2  NaN  NaN
3  3  NaN    d

---->   pandas.DataFrame

--------------------------------------
ID: 5098 --> 1
In [122]: df = pd.DataFrame(np.random.randn(10, 2))

In [123]: df[np.random.rand(df.shape[0]) > 0.5] = 1.5

In [124]: df.replace(1.5, np.nan)
Out[124]: 
          0         1
0 -0.844214 -1.021415
1  0.432396 -0.323580
2  0.423825  0.799180
3  1.262614  0.751965
4       NaN       NaN
5       NaN       NaN
6 -0.498174 -1.060799
7  0.591667 -0.183257
8  1.019855 -1.482465
9       NaN       NaN

---->   pandas.DataFrame

--------------------------------------
ID: 5100 --> 1
In [128]: s = pd.Series(np.random.randn(5), index=[0, 2, 4, 6, 7])

In [129]: s > 0
Out[129]: 
0    True
2    True
4    True
6    True
7    True
dtype: bool

In [130]: (s > 0).dtype
Out[130]: dtype('bool')

In [131]: crit = (s > 0).reindex(list(range(8)))

In [132]: crit
Out[132]: 
0    True
1     NaN
2    True
3     NaN
4    True
5     NaN
6    True
7    True
dtype: object

In [133]: crit.dtype
Out[133]: dtype('O')

---->   pandas.Series

--------------------------------------
ID: 5103 --> 1
In [138]: s = pd.Series([0, 1, np.nan, 3, 4], dtype="Int64")

In [139]: s
Out[139]: 
0       0
1       1
2    
3       3
4       4
dtype: Int64

---->   pandas.Series

--------------------------------------
ID: 5104 --> 1
In [140]: s = pd.Series([1, 2, None], dtype="Int64")

In [141]: s
Out[141]: 
0       1
1       2
2    
dtype: Int64

In [142]: s[2]
Out[142]: 

In [143]: s[2] is pd.NA
Out[143]: True

---->   pandas.Series

--------------------------------------
ID: 5105 --> 1
In [151]: pd.isna(pd.NA)
Out[151]: True

---->   pandas.isna

--------------------------------------
ID: 5111 --> 2
In [1]: arr = pd.array([1, 2, None], dtype=pd.Int64Dtype())

In [2]: arr
Out[2]: 

[1, 2, ]
Length: 3, dtype: Int64

---->   pandas.array; pandas.Int64Dtype

--------------------------------------
ID: 5112 --> 1
In [3]: pd.array([1, 2, np.nan], dtype="Int64")
Out[3]: 

[1, 2, ]
Length: 3, dtype: Int64

---->   pandas.array

--------------------------------------
ID: 5113 --> 1
In [4]: pd.array([1, 2, np.nan, None, pd.NA], dtype="Int64")
Out[4]: 

[1, 2, , , ]
Length: 5, dtype: Int64

---->   pandas.array

--------------------------------------
ID: 5114 --> 1
In [5]: pd.Series(arr)
Out[5]: 
0       1
1       2
2    
dtype: Int64

---->   pandas.Series

--------------------------------------
ID: 5115 --> 1
In [6]: pd.array([1, None])
Out[6]: 

[1, ]
Length: 2, dtype: Int64

In [7]: pd.array([1, 2])
Out[7]: 

[1, 2]
Length: 2, dtype: Int64

---->   pandas.array

--------------------------------------
ID: 5116 --> 1
In [8]: pd.Series([1, None])
Out[8]: 
0    1.0
1    NaN
dtype: float64

In [9]: pd.Series([1, 2])
Out[9]: 
0    1
1    2
dtype: int64

---->   pandas.Series

--------------------------------------
ID: 5117 --> 2
In [10]: pd.array([1, None], dtype="Int64")
Out[10]: 

[1, ]
Length: 2, dtype: Int64

In [11]: pd.Series([1, None], dtype="Int64")
Out[11]: 
0       1
1    
dtype: Int64

---->   pandas.array; pandas.Series

--------------------------------------
ID: 5118 --> 1
In [12]: s = pd.Series([1, 2, None], dtype="Int64")

# arithmetic
In [13]: s + 1
Out[13]: 
0       2
1       3
2    
dtype: Int64

# comparison
In [14]: s == 1
Out[14]: 
0     True
1    False
2     
dtype: boolean

# indexing
In [15]: s.iloc[1:3]
Out[15]: 
1       2
2    
dtype: Int64

# operate with other dtypes
In [16]: s + s.iloc[1:3].astype("Int8")
Out[16]: 
0    
1       4
2    
dtype: Int64

# coerce when needed
In [17]: s + 0.01
Out[17]: 
0    1.01
1    2.01
2    
dtype: Float64

---->   pandas.Series

--------------------------------------
ID: 5119 --> 1
In [18]: df = pd.DataFrame({"A": s, "B": [1, 1, 3], "C": list("aab")})

In [19]: df
Out[19]: 
      A  B  C
0     1  1  a
1     2  1  a
2    3  b

In [20]: df.dtypes
Out[20]: 
A     Int64
B     int64
C    object
dtype: object

---->   pandas.DataFrame

--------------------------------------
ID: 5121 --> 2
In [23]: df.sum()
Out[23]: 
A      3
B      5
C    aab
dtype: object

In [24]: df.groupby("B").A.sum()
Out[24]: 
B
1    3
3    0
Name: A, dtype: Int64

---->   DataFrame.sum; DataFrame.groupby

--------------------------------------
ID: 5122 --> 1
In [25]: a = pd.array([1, None], dtype="Int64")

In [26]: a[1]
Out[26]: 

---->   pandas.array

--------------------------------------
ID: 5123 --> 2
In [1]: index = pd.date_range("1/1/2000", periods=8)

In [2]: s = pd.Series(np.random.randn(5), index=["a", "b", "c", "d", "e"])

In [3]: df = pd.DataFrame(np.random.randn(8, 3), index=index, columns=["A", "B", "C"])

---->   pandas.Series; pandas.DataFrame

--------------------------------------
ID: 5124 --> 3
In [4]: long_series = pd.Series(np.random.randn(1000))

In [5]: long_series.head()
Out[5]: 
0   -1.157892
1   -1.344312
2    0.844885
3    1.075770
4   -0.109050
dtype: float64

In [6]: long_series.tail(3)
Out[6]: 
997   -0.289388
998   -1.020544
999    0.589993
dtype: float64

---->   pandas.Series; Series.head; Series.tail

--------------------------------------
ID: 5126 --> 1
In [12]: s.to_numpy()
Out[12]: array([ 0.4691, -0.2829, -1.5091, -1.1356,  1.2121])

In [13]: np.asarray(s)
Out[13]: array([ 0.4691, -0.2829, -1.5091, -1.1356,  1.2121])

---->   Series.to_numpy

--------------------------------------
ID: 5127 --> 2
In [14]: ser = pd.Series(pd.date_range("2000", periods=2, tz="CET"))

In [15]: ser.to_numpy(dtype=object)
Out[15]: 
array([Timestamp('2000-01-01 00:00:00+0100', tz='CET'),
       Timestamp('2000-01-02 00:00:00+0100', tz='CET')], dtype=object)

---->   pandas.Series; Series.to_numpy

--------------------------------------
ID: 5128 --> 1
In [16]: ser.to_numpy(dtype="datetime64[ns]")
Out[16]: 
array(['1999-12-31T23:00:00.000000000', '2000-01-01T23:00:00.000000000'],
      dtype='datetime64[ns]')

---->   Series.to_numpy

--------------------------------------
ID: 5131 --> 3
In [18]: df = pd.DataFrame(
   ....:     {
   ....:         "one": pd.Series(np.random.randn(3), index=["a", "b", "c"]),
   ....:         "two": pd.Series(np.random.randn(4), index=["a", "b", "c", "d"]),
   ....:         "three": pd.Series(np.random.randn(3), index=["b", "c", "d"]),
   ....:     }
   ....: )
   ....: 

In [19]: df
Out[19]: 
        one       two     three
a  1.394981  1.772517       NaN
b  0.343054  1.912123 -0.050390
c  0.695246  1.478369  1.227435
d       NaN  0.279344 -0.613172

In [20]: row = df.iloc[1]

In [21]: column = df["two"]

In [22]: df.sub(row, axis="columns")
Out[22]: 
        one       two     three
a  1.051928 -0.139606       NaN
b  0.000000  0.000000  0.000000
c  0.352192 -0.433754  1.277825
d       NaN -1.632779 -0.562782

In [23]: df.sub(row, axis=1)
Out[23]: 
        one       two     three
a  1.051928 -0.139606       NaN
b  0.000000  0.000000  0.000000
c  0.352192 -0.433754  1.277825
d       NaN -1.632779 -0.562782

In [24]: df.sub(column, axis="index")
Out[24]: 
        one  two     three
a -0.377535  0.0       NaN
b -1.569069  0.0 -1.962513
c -0.783123  0.0 -0.250933
d       NaN  0.0 -0.892516

In [25]: df.sub(column, axis=0)
Out[25]: 
        one  two     three
a -0.377535  0.0       NaN
b -1.569069  0.0 -1.962513
c -0.783123  0.0 -0.250933
d       NaN  0.0 -0.892516

---->   pandas.DataFrame; pandas.Series; DataFrame.sub

--------------------------------------
ID: 5132 --> 2
In [26]: dfmi = df.copy()

In [27]: dfmi.index = pd.MultiIndex.from_tuples(
   ....:     [(1, "a"), (1, "b"), (1, "c"), (2, "a")], names=["first", "second"]
   ....: )
   ....: 

In [28]: dfmi.sub(column, axis=0, level="second")
Out[28]: 
                   one       two     three
first second                              
1     a      -0.377535  0.000000       NaN
      b      -1.569069  0.000000 -1.962513
      c      -0.783123  0.000000 -0.250933
2     a            NaN -1.493173 -2.385688

---->   DataFrame.copy; pandas.MultiIndex

--------------------------------------
ID: 5133 --> 2
In [29]: s = pd.Series(np.arange(10))

In [30]: s
Out[30]: 
0    0
1    1
2    2
3    3
4    4
5    5
6    6
7    7
8    8
9    9
dtype: int64

In [31]: div, rem = divmod(s, 3)

In [32]: div
Out[32]: 
0    0
1    0
2    0
3    1
4    1
5    1
6    2
7    2
8    2
9    3
dtype: int64

In [33]: rem
Out[33]: 
0    0
1    1
2    2
3    0
4    1
5    2
6    0
7    1
8    2
9    0
dtype: int64

In [34]: idx = pd.Index(np.arange(10))

In [35]: idx
Out[35]: Index([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype='int64')

In [36]: div, rem = divmod(idx, 3)

In [37]: div
Out[37]: Index([0, 0, 0, 1, 1, 1, 2, 2, 2, 3], dtype='int64')

In [38]: rem
Out[38]: Index([0, 1, 2, 0, 1, 2, 0, 1, 2, 0], dtype='int64')

---->   pandas.Series; pandas.Index

--------------------------------------
ID: 5135 --> 1
In [42]: df
Out[42]: 
        one       two     three
a  1.394981  1.772517       NaN
b  0.343054  1.912123 -0.050390
c  0.695246  1.478369  1.227435
d       NaN  0.279344 -0.613172

In [43]: df2
Out[43]: 
        one       two     three
a  1.394981  1.772517  1.000000
b  0.343054  1.912123 -0.050390
c  0.695246  1.478369  1.227435
d       NaN  0.279344 -0.613172

In [44]: df + df2
Out[44]: 
        one       two     three
a  2.789963  3.545034       NaN
b  0.686107  3.824246 -0.100780
c  1.390491  2.956737  2.454870
d       NaN  0.558688 -1.226343

In [45]: df.add(df2, fill_value=0)
Out[45]: 
        one       two     three
a  2.789963  3.545034  1.000000
b  0.686107  3.824246 -0.100780
c  1.390491  2.956737  2.454870
d       NaN  0.558688 -1.226343

---->   DataFrame.add

--------------------------------------
ID: 5136 --> 2
In [46]: df.gt(df2)
Out[46]: 
     one    two  three
a  False  False  False
b  False  False  False
c  False  False  False
d  False  False  False

In [47]: df2.ne(df)
Out[47]: 
     one    two  three
a  False  False   True
b  False  False  False
c  False  False  False
d   True  False  False

---->   DataFrame.gt; DataFrame.ne

--------------------------------------
ID: 5139 --> 1
In [51]: df.empty
Out[51]: False

In [52]: pd.DataFrame(columns=list("ABC")).empty
Out[52]: True

---->   pandas.DataFrame

--------------------------------------
ID: 5140 --> 2
In [53]: pd.Series([True]).bool()
Out[53]: True

In [54]: pd.Series([False]).bool()
Out[54]: False

In [55]: pd.DataFrame([[True]]).bool()
Out[55]: True

In [56]: pd.DataFrame([[False]]).bool()
Out[56]: False

---->   pandas.Series; pandas.DataFrame

--------------------------------------
ID: 5141 --> 1
ValueError: The truth value of an array is ambiguous. Use a.empty, a.any() or a.all().

---->   Series.all

--------------------------------------
ID: 5144 --> 2
In [61]: df1 = pd.DataFrame({"col": ["foo", 0, np.nan]})

In [62]: df2 = pd.DataFrame({"col": [np.nan, 0, "foo"]}, index=[2, 1, 0])

In [63]: df1.equals(df2)
Out[63]: False

In [64]: df1.equals(df2.sort_index())
Out[64]: True

---->   pandas.DataFrame; DataFrame.equals

--------------------------------------
ID: 5145 --> 2
In [65]: pd.Series(["foo", "bar", "baz"]) == "foo"
Out[65]: 
0     True
1    False
2    False
dtype: bool

In [66]: pd.Index(["foo", "bar", "baz"]) == "foo"
Out[66]: array([ True, False, False])

---->   pandas.Series; pandas.Index

--------------------------------------
ID: 5146 --> 2
In [67]: pd.Series(["foo", "bar", "baz"]) == pd.Index(["foo", "bar", "qux"])
Out[67]: 
0     True
1     True
2    False
dtype: bool

In [68]: pd.Series(["foo", "bar", "baz"]) == np.array(["foo", "bar", "qux"])
Out[68]: 
0     True
1     True
2    False
dtype: bool

---->   pandas.Series; pandas.Index

--------------------------------------
ID: 5147 --> 1
In [55]: pd.Series(['foo', 'bar', 'baz']) == pd.Series(['foo', 'bar'])
ValueError: Series lengths must match to compare

In [56]: pd.Series(['foo', 'bar', 'baz']) == pd.Series(['foo'])
ValueError: Series lengths must match to compare

---->   pandas.Series

--------------------------------------
ID: 5150 --> 2
In [71]: df1 = pd.DataFrame(
   ....:     {"A": [1.0, np.nan, 3.0, 5.0, np.nan], "B": [np.nan, 2.0, 3.0, np.nan, 6.0]}
   ....: )
   ....: 

In [72]: df2 = pd.DataFrame(
   ....:     {
   ....:         "A": [5.0, 2.0, 4.0, np.nan, 3.0, 7.0],
   ....:         "B": [np.nan, np.nan, 3.0, 4.0, 6.0, 8.0],
   ....:     }
   ....: )
   ....: 

In [73]: df1
Out[73]: 
     A    B
0  1.0  NaN
1  NaN  2.0
2  3.0  3.0
3  5.0  NaN
4  NaN  6.0

In [74]: df2
Out[74]: 
     A    B
0  5.0  NaN
1  2.0  NaN
2  4.0  3.0
3  NaN  4.0
4  3.0  6.0
5  7.0  8.0

In [75]: df1.combine_first(df2)
Out[75]: 
     A    B
0  1.0  NaN
1  2.0  2.0
2  3.0  3.0
3  5.0  4.0
4  3.0  6.0
5  7.0  8.0

---->   pandas.DataFrame; DataFrame.combine_first

--------------------------------------
ID: 5151 --> 2
In [76]: def combiner(x, y):
   ....:     return np.where(pd.isna(x), y, x)
   ....: 

In [77]: df1.combine(df2, combiner)
Out[77]: 
     A    B
0  1.0  NaN
1  2.0  2.0
2  3.0  3.0
3  5.0  4.0
4  3.0  6.0
5  7.0  8.0

---->   pandas.isna; DataFrame.combine

--------------------------------------
ID: 5152 --> 1
In [78]: df
Out[78]: 
        one       two     three
a  1.394981  1.772517       NaN
b  0.343054  1.912123 -0.050390
c  0.695246  1.478369  1.227435
d       NaN  0.279344 -0.613172

In [79]: df.mean(0)
Out[79]: 
one      0.811094
two      1.360588
three    0.187958
dtype: float64

In [80]: df.mean(1)
Out[80]: 
a    1.583749
b    0.734929
c    1.133683
d   -0.166914
dtype: float64

---->   DataFrame.mean

--------------------------------------
ID: 5153 --> 1
In [81]: df.sum(0, skipna=False)
Out[81]: 
one           NaN
two      5.442353
three         NaN
dtype: float64

In [82]: df.sum(axis=1, skipna=True)
Out[82]: 
a    3.167498
b    2.204786
c    3.401050
d   -0.333828
dtype: float64

---->   DataFrame.sum

--------------------------------------
ID: 5154 --> 3
In [83]: ts_stand = (df - df.mean()) / df.std()

In [84]: ts_stand.std()
Out[84]: 
one      1.0
two      1.0
three    1.0
dtype: float64

In [85]: xs_stand = df.sub(df.mean(1), axis=0).div(df.std(1), axis=0)

In [86]: xs_stand.std(1)
Out[86]: 
a    1.0
b    1.0
c    1.0
d    1.0
dtype: float64

---->   DataFrame.mean; DataFrame.std; DataFrame.sub

--------------------------------------
ID: 5155 --> 1
In [87]: df.cumsum()
Out[87]: 
        one       two     three
a  1.394981  1.772517       NaN
b  1.738035  3.684640 -0.050390
c  2.433281  5.163008  1.177045
d       NaN  5.442353  0.563873

---->   DataFrame.cumsum

--------------------------------------
ID: 5157 --> 2
In [90]: series = pd.Series(np.random.randn(500))

In [91]: series[20:500] = np.nan

In [92]: series[10:20] = 5

In [93]: series.nunique()
Out[93]: 11

---->   pandas.Series; Series.nunique

--------------------------------------
ID: 5158 --> 4
In [94]: series = pd.Series(np.random.randn(1000))

In [95]: series[::2] = np.nan

In [96]: series.describe()
Out[96]: 
count    500.000000
mean      -0.021292
std        1.015906
min       -2.683763
25%       -0.699070
50%       -0.069718
75%        0.714483
max        3.160915
dtype: float64

In [97]: frame = pd.DataFrame(np.random.randn(1000, 5), columns=["a", "b", "c", "d", "e"])

In [98]: frame.iloc[::2] = np.nan

In [99]: frame.describe()
Out[99]: 
                a           b           c           d           e
count  500.000000  500.000000  500.000000  500.000000  500.000000
mean     0.033387    0.030045   -0.043719   -0.051686    0.005979
std      1.017152    0.978743    1.025270    1.015988    1.006695
min     -3.000951   -2.637901   -3.303099   -3.159200   -3.188821
25%     -0.647623   -0.576449   -0.712369   -0.691338   -0.691115
50%      0.047578   -0.021499   -0.023888   -0.032652   -0.025363
75%      0.729907    0.775880    0.618896    0.670047    0.649748
max      2.740139    2.752332    3.004229    2.728702    3.240991

---->   pandas.Series; Series.describe; pandas.DataFrame; DataFrame.describe

--------------------------------------
ID: 5159 --> 1
In [100]: series.describe(percentiles=[0.05, 0.25, 0.75, 0.95])
Out[100]: 
count    500.000000
mean      -0.021292
std        1.015906
min       -2.683763
5%        -1.645423
25%       -0.699070
50%       -0.069718
75%        0.714483
95%        1.711409
max        3.160915
dtype: float64

---->   Series.describe

--------------------------------------
ID: 5160 --> 2
In [101]: s = pd.Series(["a", "a", "b", "b", "a", "a", np.nan, "c", "d", "a"])

In [102]: s.describe()
Out[102]: 
count     9
unique    4
top       a
freq      5
dtype: object

---->   pandas.Series; Series.describe

--------------------------------------
ID: 5161 --> 2
In [103]: frame = pd.DataFrame({"a": ["Yes", "Yes", "No", "No"], "b": range(4)})

In [104]: frame.describe()
Out[104]: 
              b
count  4.000000
mean   1.500000
std    1.290994
min    0.000000
25%    0.750000
50%    1.500000
75%    2.250000
max    3.000000

---->   pandas.DataFrame; DataFrame.describe

--------------------------------------
ID: 5162 --> 1
In [105]: frame.describe(include=["object"])
Out[105]: 
          a
count     4
unique    2
top     Yes
freq      2

In [106]: frame.describe(include=["number"])
Out[106]: 
              b
count  4.000000
mean   1.500000
std    1.290994
min    0.000000
25%    0.750000
50%    1.500000
75%    2.250000
max    3.000000

In [107]: frame.describe(include="all")
Out[107]: 
          a         b
count     4  4.000000
unique    2       NaN
top     Yes       NaN
freq      2       NaN
mean    NaN  1.500000
std     NaN  1.290994
min     NaN  0.000000
25%     NaN  0.750000
50%     NaN  1.500000
75%     NaN  2.250000
max     NaN  3.000000

---->   DataFrame.describe

--------------------------------------
ID: 5163 --> 6
In [108]: s1 = pd.Series(np.random.randn(5))

In [109]: s1
Out[109]: 
0    1.118076
1   -0.352051
2   -1.242883
3   -1.277155
4   -0.641184
dtype: float64

In [110]: s1.idxmin(), s1.idxmax()
Out[110]: (3, 0)

In [111]: df1 = pd.DataFrame(np.random.randn(5, 3), columns=["A", "B", "C"])

In [112]: df1
Out[112]: 
          A         B         C
0 -0.327863 -0.946180 -0.137570
1 -0.186235 -0.257213 -0.486567
2 -0.507027 -0.871259 -0.111110
3  2.000339 -2.430505  0.089759
4 -0.321434 -0.033695  0.096271

In [113]: df1.idxmin(axis=0)
Out[113]: 
A    2
B    3
C    1
dtype: int64

In [114]: df1.idxmax(axis=1)
Out[114]: 
0    C
1    A
2    C
3    A
4    C
dtype: object

---->   pandas.Series; Series.idxmin; Series.idxmax; pandas.DataFrame; DataFrame.idxmin; DataFrame.idxmax

--------------------------------------
ID: 5164 --> 1
In [115]: df3 = pd.DataFrame([2, 1, 1, 3, np.nan], columns=["A"], index=list("edcba"))

In [116]: df3
Out[116]: 
     A
e  2.0
d  1.0
c  1.0
b  3.0
a  NaN

In [117]: df3["A"].idxmin()
Out[117]: 'd'

---->   pandas.DataFrame

--------------------------------------
ID: 5165 --> 2
In [118]: data = np.random.randint(0, 7, size=50)

In [119]: data
Out[119]: 
array([6, 6, 2, 3, 5, 3, 2, 5, 4, 5, 4, 3, 4, 5, 0, 2, 0, 4, 2, 0, 3, 2,
       2, 5, 6, 5, 3, 4, 6, 4, 3, 5, 6, 4, 3, 6, 2, 6, 6, 2, 3, 4, 2, 1,
       6, 2, 6, 1, 5, 4])

In [120]: s = pd.Series(data)

In [121]: s.value_counts()
Out[121]: 
6    10
2    10
4     9
3     8
5     8
0     3
1     2
Name: count, dtype: int64

In [122]: pd.value_counts(data)
Out[122]: 
6    10
2    10
4     9
3     8
5     8
0     3
1     2
Name: count, dtype: int64

---->   pandas.Series; Series.value_counts

--------------------------------------
ID: 5166 --> 2
In [123]: data = {"a": [1, 2, 3, 4], "b": ["x", "x", "y", "y"]}

In [124]: frame = pd.DataFrame(data)

In [125]: frame.value_counts()
Out[125]: 
a  b
1  x    1
2  x    1
3  y    1
4  y    1
Name: count, dtype: int64

---->   pandas.DataFrame; DataFrame.value_counts

--------------------------------------
ID: 5167 --> 4
In [126]: s5 = pd.Series([1, 1, 3, 3, 3, 5, 5, 7, 7, 7])

In [127]: s5.mode()
Out[127]: 
0    3
1    7
dtype: int64

In [128]: df5 = pd.DataFrame(
   .....:     {
   .....:         "A": np.random.randint(0, 7, size=50),
   .....:         "B": np.random.randint(-10, 15, size=50),
   .....:     }
   .....: )
   .....: 

In [129]: df5.mode()
Out[129]: 
     A   B
0  1.0  -9
1  NaN  10
2  NaN  13

---->   pandas.Series; Series.mode; pandas.DataFrame; DataFrame.mode

--------------------------------------
ID: 5168 --> 1
In [130]: arr = np.random.randn(20)

In [131]: factor = pd.cut(arr, 4)

In [132]: factor
Out[132]: 
[(-0.251, 0.464], (-0.968, -0.251], (0.464, 1.179], (-0.251, 0.464], (-0.968, -0.251], ..., (-0.251, 0.464], (-0.968, -0.251], (-0.968, -0.251], (-0.968, -0.251], (-0.968, -0.251]]
Length: 20
Categories (4, interval[float64, right]): [(-0.968, -0.251] < (-0.251, 0.464] < (0.464, 1.179] <
                                           (1.179, 1.893]]

In [133]: factor = pd.cut(arr, [-5, -1, 0, 1, 5])

In [134]: factor
Out[134]: 
[(0, 1], (-1, 0], (0, 1], (0, 1], (-1, 0], ..., (-1, 0], (-1, 0], (-1, 0], (-1, 0], (-1, 0]]
Length: 20
Categories (4, interval[int64, right]): [(-5, -1] < (-1, 0] < (0, 1] < (1, 5]]

---->   pandas.cut

--------------------------------------
ID: 5169 --> 1
In [135]: arr = np.random.randn(30)

In [136]: factor = pd.qcut(arr, [0, 0.25, 0.5, 0.75, 1])

In [137]: factor
Out[137]: 
[(0.569, 1.184], (-2.278, -0.301], (-2.278, -0.301], (0.569, 1.184], (0.569, 1.184], ..., (-0.301, 0.569], (1.184, 2.346], (1.184, 2.346], (-0.301, 0.569], (-2.278, -0.301]]
Length: 30
Categories (4, interval[float64, right]): [(-2.278, -0.301] < (-0.301, 0.569] < (0.569, 1.184] <
                                           (1.184, 2.346]]

In [138]: pd.value_counts(factor)
Out[138]: 
(-2.278, -0.301]    8
(1.184, 2.346]      8
(-0.301, 0.569]     7
(0.569, 1.184]      7
Name: count, dtype: int64

---->   pandas.qcut

--------------------------------------
ID: 5170 --> 1
In [139]: arr = np.random.randn(20)

In [140]: factor = pd.cut(arr, [-np.inf, 0, np.inf])

In [141]: factor
Out[141]: 
[(-inf, 0.0], (0.0, inf], (0.0, inf], (-inf, 0.0], (-inf, 0.0], ..., (-inf, 0.0], (-inf, 0.0], (-inf, 0.0], (0.0, inf], (0.0, inf]]
Length: 20
Categories (2, interval[float64, right]): [(-inf, 0.0] < (0.0, inf]]

---->   pandas.cut

--------------------------------------
ID: 5171 --> 1
In [142]: def extract_city_name(df):
   .....:     """
   .....:     Chicago, IL -> Chicago for city_name column
   .....:     """
   .....:     df["city_name"] = df["city_and_code"].str.split(",").str.get(0)
   .....:     return df
   .....: 

In [143]: def add_country_name(df, country_name=None):
   .....:     """
   .....:     Chicago -> Chicago-US for city_name column
   .....:     """
   .....:     col = "city_name"
   .....:     df["city_and_country"] = df[col] + country_name
   .....:     return df
   .....: 

In [144]: df_p = pd.DataFrame({"city_and_code": ["Chicago, IL"]})

---->   pandas.DataFrame

--------------------------------------
ID: 5173 --> 1
In [146]: df_p.pipe(extract_city_name).pipe(add_country_name, country_name="US")
Out[146]: 
  city_and_code city_name city_and_country
0   Chicago, IL   Chicago        ChicagoUS

---->   DataFrame.pipe

--------------------------------------
ID: 5175 --> 2
In [147]: df.apply(np.mean)
Out[147]: 
one      0.811094
two      1.360588
three    0.187958
dtype: float64

In [148]: df.apply(np.mean, axis=1)
Out[148]: 
a    1.583749
b    0.734929
c    1.133683
d   -0.166914
dtype: float64

In [149]: df.apply(lambda x: x.max() - x.min())
Out[149]: 
one      1.051928
two      1.632779
three    1.840607
dtype: float64

In [150]: df.apply(np.cumsum)
Out[150]: 
        one       two     three
a  1.394981  1.772517       NaN
b  1.738035  3.684640 -0.050390
c  2.433281  5.163008  1.177045
d       NaN  5.442353  0.563873

In [151]: df.apply(np.exp)
Out[151]: 
        one       two     three
a  4.034899  5.885648       NaN
b  1.409244  6.767440  0.950858
c  2.004201  4.385785  3.412466
d       NaN  1.322262  0.541630

---->   Series.max; Series.min

--------------------------------------
ID: 5177 --> 2
In [154]: tsdf = pd.DataFrame(
   .....:     np.random.randn(1000, 3),
   .....:     columns=["A", "B", "C"],
   .....:     index=pd.date_range("1/1/2000", periods=1000),
   .....: )
   .....: 

In [155]: tsdf.apply(lambda x: x.idxmax())
Out[155]: 
A   2000-08-06
B   2001-01-18
C   2001-07-18
dtype: datetime64[ns]

---->   pandas.DataFrame; Series.idxmax

--------------------------------------
ID: 5181 --> 1
In [158]: tsdf = pd.DataFrame(
   .....:     np.random.randn(10, 3),
   .....:     columns=["A", "B", "C"],
   .....:     index=pd.date_range("1/1/2000", periods=10),
   .....: )
   .....: 

In [159]: tsdf.iloc[3:7] = np.nan

In [160]: tsdf
Out[160]: 
                   A         B         C
2000-01-01  1.257606  1.004194  0.167574
2000-01-02 -0.749892  0.288112 -0.757304
2000-01-03 -0.207550 -0.298599  0.116018
2000-01-04       NaN       NaN       NaN
2000-01-05       NaN       NaN       NaN
2000-01-06       NaN       NaN       NaN
2000-01-07       NaN       NaN       NaN
2000-01-08  0.814347 -0.257623  0.869226
2000-01-09 -0.250663 -1.206601  0.896839
2000-01-10  2.169758 -1.333363  0.283157

---->   pandas.DataFrame

--------------------------------------
ID: 5187 --> 1
In [168]: tsdf["A"].agg(["sum", lambda x: x.mean()])
Out[168]: 
sum         3.033606
    0.505601
Name: A, dtype: float64

---->   Series.mean

--------------------------------------
ID: 5188 --> 1
In [169]: def mymean(x):
   .....:     return x.mean()
   .....: 

In [170]: tsdf["A"].agg(["sum", mymean])
Out[170]: 
sum       3.033606
mymean    0.505601
Name: A, dtype: float64

---->   Series.mean

--------------------------------------
ID: 5192 --> 1
In [179]: tsdf = pd.DataFrame(
   .....:     np.random.randn(10, 3),
   .....:     columns=["A", "B", "C"],
   .....:     index=pd.date_range("1/1/2000", periods=10),
   .....: )
   .....: 

In [180]: tsdf.iloc[3:7] = np.nan

In [181]: tsdf
Out[181]: 
                   A         B         C
2000-01-01 -0.428759 -0.864890 -0.675341
2000-01-02 -0.168731  1.338144 -1.279321
2000-01-03 -1.621034  0.438107  0.903794
2000-01-04       NaN       NaN       NaN
2000-01-05       NaN       NaN       NaN
2000-01-06       NaN       NaN       NaN
2000-01-07       NaN       NaN       NaN
2000-01-08  0.254374 -1.240447 -0.201052
2000-01-09 -0.157795  0.791197 -1.144209
2000-01-10 -0.030876  0.371900  0.061932

---->   pandas.DataFrame

--------------------------------------
ID: 5193 --> 1
In [182]: tsdf.transform(np.abs)
Out[182]: 
                   A         B         C
2000-01-01  0.428759  0.864890  0.675341
2000-01-02  0.168731  1.338144  1.279321
2000-01-03  1.621034  0.438107  0.903794
2000-01-04       NaN       NaN       NaN
2000-01-05       NaN       NaN       NaN
2000-01-06       NaN       NaN       NaN
2000-01-07       NaN       NaN       NaN
2000-01-08  0.254374  1.240447  0.201052
2000-01-09  0.157795  0.791197  1.144209
2000-01-10  0.030876  0.371900  0.061932

In [183]: tsdf.transform("abs")
Out[183]: 
                   A         B         C
2000-01-01  0.428759  0.864890  0.675341
2000-01-02  0.168731  1.338144  1.279321
2000-01-03  1.621034  0.438107  0.903794
2000-01-04       NaN       NaN       NaN
2000-01-05       NaN       NaN       NaN
2000-01-06       NaN       NaN       NaN
2000-01-07       NaN       NaN       NaN
2000-01-08  0.254374  1.240447  0.201052
2000-01-09  0.157795  0.791197  1.144209
2000-01-10  0.030876  0.371900  0.061932

In [184]: tsdf.transform(lambda x: x.abs())
Out[184]: 
                   A         B         C
2000-01-01  0.428759  0.864890  0.675341
2000-01-02  0.168731  1.338144  1.279321
2000-01-03  1.621034  0.438107  0.903794
2000-01-04       NaN       NaN       NaN
2000-01-05       NaN       NaN       NaN
2000-01-06       NaN       NaN       NaN
2000-01-07       NaN       NaN       NaN
2000-01-08  0.254374  1.240447  0.201052
2000-01-09  0.157795  0.791197  1.144209
2000-01-10  0.030876  0.371900  0.061932

---->   Series.abs

--------------------------------------
ID: 5200 --> 1
In [191]: df4
Out[191]: 
        one       two     three
a  1.394981  1.772517       NaN
b  0.343054  1.912123 -0.050390
c  0.695246  1.478369  1.227435
d       NaN  0.279344 -0.613172

In [192]: def f(x):
   .....:     return len(str(x))
   .....: 

In [193]: df4["one"].map(f)
Out[193]: 
a    18
b    19
c    18
d     3
Name: one, dtype: int64

In [194]: df4.applymap(f)
Out[194]: 
   one  two  three
a   18   17      3
b   19   18     20
c   18   18     16
d    3   19     19

---->   DataFrame.applymap

--------------------------------------
ID: 5201 --> 2
In [195]: s = pd.Series(
   .....:     ["six", "seven", "six", "seven", "six"], index=["a", "b", "c", "d", "e"]
   .....: )
   .....: 

In [196]: t = pd.Series({"six": 6.0, "seven": 7.0})

In [197]: s
Out[197]: 
a      six
b    seven
c      six
d    seven
e      six
dtype: object

In [198]: s.map(t)
Out[198]: 
a    6.0
b    7.0
c    6.0
d    7.0
e    6.0
dtype: float64

---->   pandas.Series; Series.map

--------------------------------------
ID: 5202 --> 1
In [199]: s = pd.Series(np.random.randn(5), index=["a", "b", "c", "d", "e"])

In [200]: s
Out[200]: 
a    1.695148
b    1.328614
c    1.234686
d   -0.385845
e   -1.326508
dtype: float64

In [201]: s.reindex(["e", "b", "f", "d"])
Out[201]: 
e   -1.326508
b    1.328614
f         NaN
d   -0.385845
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 5206 --> 1
In [209]: df2
Out[209]: 
        one       two
a  1.394981  1.772517
b  0.343054  1.912123
c  0.695246  1.478369

In [210]: df3
Out[210]: 
        one       two
a  0.583888  0.051514
b -0.468040  0.191120
c -0.115848 -0.242634

In [211]: df.reindex_like(df2)
Out[211]: 
        one       two
a  1.394981  1.772517
b  0.343054  1.912123
c  0.695246  1.478369

---->   DataFrame.reindex_like

--------------------------------------
ID: 5207 --> 2
In [212]: s = pd.Series(np.random.randn(5), index=["a", "b", "c", "d", "e"])

In [213]: s1 = s[:4]

In [214]: s2 = s[1:]

In [215]: s1.align(s2)
Out[215]: 
(a   -0.186646
 b   -1.692424
 c   -0.303893
 d   -1.425662
 e         NaN
 dtype: float64,
 a         NaN
 b   -1.692424
 c   -0.303893
 d   -1.425662
 e    1.114285
 dtype: float64)

In [216]: s1.align(s2, join="inner")
Out[216]: 
(b   -1.692424
 c   -0.303893
 d   -1.425662
 dtype: float64,
 b   -1.692424
 c   -0.303893
 d   -1.425662
 dtype: float64)

In [217]: s1.align(s2, join="left")
Out[217]: 
(a   -0.186646
 b   -1.692424
 c   -0.303893
 d   -1.425662
 dtype: float64,
 a         NaN
 b   -1.692424
 c   -0.303893
 d   -1.425662
 dtype: float64)

---->   pandas.Series; Series.align

--------------------------------------
ID: 5208 --> 1
In [218]: df.align(df2, join="inner")
Out[218]: 
(        one       two
 a  1.394981  1.772517
 b  0.343054  1.912123
 c  0.695246  1.478369,
         one       two
 a  1.394981  1.772517
 b  0.343054  1.912123
 c  0.695246  1.478369)

---->   DataFrame.align

--------------------------------------
ID: 5209 --> 1
In [219]: df.align(df2, join="inner", axis=0)
Out[219]: 
(        one       two     three
 a  1.394981  1.772517       NaN
 b  0.343054  1.912123 -0.050390
 c  0.695246  1.478369  1.227435,
         one       two
 a  1.394981  1.772517
 b  0.343054  1.912123
 c  0.695246  1.478369)

---->   DataFrame.align

--------------------------------------
ID: 5210 --> 1
In [220]: df.align(df2.iloc[0], axis=1)
Out[220]: 
(        one     three       two
 a  1.394981       NaN  1.772517
 b  0.343054 -0.050390  1.912123
 c  0.695246  1.227435  1.478369
 d       NaN -0.613172  0.279344,
 one      1.394981
 three         NaN
 two      1.772517
 Name: a, dtype: float64)

---->   DataFrame.align

--------------------------------------
ID: 5211 --> 1
In [221]: rng = pd.date_range("1/3/2000", periods=8)

In [222]: ts = pd.Series(np.random.randn(8), index=rng)

In [223]: ts2 = ts[[0, 3, 6]]

In [224]: ts
Out[224]: 
2000-01-03    0.183051
2000-01-04    0.400528
2000-01-05   -0.015083
2000-01-06    2.395489
2000-01-07    1.414806
2000-01-08    0.118428
2000-01-09    0.733639
2000-01-10   -0.936077
Freq: D, dtype: float64

In [225]: ts2
Out[225]: 
2000-01-03    0.183051
2000-01-06    2.395489
2000-01-09    0.733639
Freq: 3D, dtype: float64

In [226]: ts2.reindex(ts.index)
Out[226]: 
2000-01-03    0.183051
2000-01-04         NaN
2000-01-05         NaN
2000-01-06    2.395489
2000-01-07         NaN
2000-01-08         NaN
2000-01-09    0.733639
2000-01-10         NaN
Freq: D, dtype: float64

In [227]: ts2.reindex(ts.index, method="ffill")
Out[227]: 
2000-01-03    0.183051
2000-01-04    0.183051
2000-01-05    0.183051
2000-01-06    2.395489
2000-01-07    2.395489
2000-01-08    2.395489
2000-01-09    0.733639
2000-01-10    0.733639
Freq: D, dtype: float64

In [228]: ts2.reindex(ts.index, method="bfill")
Out[228]: 
2000-01-03    0.183051
2000-01-04    2.395489
2000-01-05    2.395489
2000-01-06    2.395489
2000-01-07    0.733639
2000-01-08    0.733639
2000-01-09    0.733639
2000-01-10         NaN
Freq: D, dtype: float64

In [229]: ts2.reindex(ts.index, method="nearest")
Out[229]: 
2000-01-03    0.183051
2000-01-04    0.183051
2000-01-05    2.395489
2000-01-06    2.395489
2000-01-07    2.395489
2000-01-08    0.733639
2000-01-09    0.733639
2000-01-10    0.733639
Freq: D, dtype: float64

---->   pandas.Series

--------------------------------------
ID: 5221 --> 2
In [243]: df = pd.DataFrame(
   .....:     {"x": [1, 2, 3, 4, 5, 6], "y": [10, 20, 30, 40, 50, 60]},
   .....:     index=pd.MultiIndex.from_product(
   .....:         [["a", "b", "c"], [1, 2]], names=["let", "num"]
   .....:     ),
   .....: )
   .....: 

In [244]: df
Out[244]: 
         x   y
let num       
a   1    1  10
    2    2  20
b   1    3  30
    2    4  40
c   1    5  50
    2    6  60

In [245]: df.rename_axis(index={"let": "abc"})
Out[245]: 
         x   y
abc num       
a   1    1  10
    2    2  20
b   1    3  30
    2    4  40
c   1    5  50
    2    6  60

In [246]: df.rename_axis(index=str.upper)
Out[246]: 
         x   y
LET NUM       
a   1    1  10
    2    2  20
b   1    3  30
    2    4  40
c   1    5  50
    2    6  60

---->   pandas.DataFrame; pandas.MultiIndex

--------------------------------------
ID: 5222 --> 1
In [247]: df = pd.DataFrame(
   .....:     {"col1": np.random.randn(3), "col2": np.random.randn(3)}, index=["a", "b", "c"]
   .....: )
   .....: 

In [248]: for col in df:
   .....:     print(col)
   .....: 
col1
col2

---->   pandas.DataFrame

--------------------------------------
ID: 5223 --> 2
In [249]: df = pd.DataFrame({"a": [1, 2, 3], "b": ["a", "b", "c"]})

In [250]: for index, row in df.iterrows():
   .....:     row["a"] = 10
   .....: 

In [251]: df
Out[251]: 
   a  b
0  1  a
1  2  b
2  3  c

---->   pandas.DataFrame; DataFrame.iterrows

--------------------------------------
ID: 5224 --> 1
In [252]: for label, ser in df.items():
   .....:     print(label)
   .....:     print(ser)
   .....: 
a
0    1
1    2
2    3
Name: a, dtype: int64
b
0    a
1    b
2    c
Name: b, dtype: object

---->   DataFrame.items

--------------------------------------
ID: 5225 --> 1
In [253]: for row_index, row in df.iterrows():
   .....:     print(row_index, row, sep="\n")
   .....: 
0
a    1
b    a
Name: 0, dtype: object
1
a    2
b    b
Name: 1, dtype: object
2
a    3
b    c
Name: 2, dtype: object

---->   DataFrame.iterrows

--------------------------------------
ID: 5226 --> 2
In [254]: df_orig = pd.DataFrame([[1, 1.5]], columns=["int", "float"])

In [255]: df_orig.dtypes
Out[255]: 
int        int64
float    float64
dtype: object

In [256]: row = next(df_orig.iterrows())[1]

In [257]: row
Out[257]: 
int      1.0
float    1.5
Name: 0, dtype: float64

---->   pandas.DataFrame; DataFrame.iterrows

--------------------------------------
ID: 5228 --> 2
In [260]: df2 = pd.DataFrame({"x": [1, 2, 3], "y": [4, 5, 6]})

In [261]: print(df2)
   x  y
0  1  4
1  2  5
2  3  6

In [262]: print(df2.T)
   0  1  2
x  1  2  3
y  4  5  6

In [263]: df2_t = pd.DataFrame({idx: values for idx, values in df2.iterrows()})

In [264]: print(df2_t)
   0  1  2
x  1  2  3
y  4  5  6

---->   pandas.DataFrame; DataFrame.iterrows

--------------------------------------
ID: 5229 --> 1
In [265]: for row in df.itertuples():
   .....:     print(row)
   .....: 
Pandas(Index=0, a=1, b='a')
Pandas(Index=1, a=2, b='b')
Pandas(Index=2, a=3, b='c')

---->   DataFrame.itertuples

--------------------------------------
ID: 5230 --> 1
# datetime
In [266]: s = pd.Series(pd.date_range("20130101 09:10:12", periods=4))

In [267]: s
Out[267]: 
0   2013-01-01 09:10:12
1   2013-01-02 09:10:12
2   2013-01-03 09:10:12
3   2013-01-04 09:10:12
dtype: datetime64[ns]

In [268]: s.dt.hour
Out[268]: 
0    9
1    9
2    9
3    9
dtype: int32

In [269]: s.dt.second
Out[269]: 
0    12
1    12
2    12
3    12
dtype: int32

In [270]: s.dt.day
Out[270]: 
0    1
1    2
2    3
3    4
dtype: int32

---->   pandas.Series

--------------------------------------
ID: 5233 --> 1
# DatetimeIndex
In [276]: s = pd.Series(pd.date_range("20130101", periods=4))

In [277]: s
Out[277]: 
0   2013-01-01
1   2013-01-02
2   2013-01-03
3   2013-01-04
dtype: datetime64[ns]

In [278]: s.dt.strftime("%Y/%m/%d")
Out[278]: 
0    2013/01/01
1    2013/01/02
2    2013/01/03
3    2013/01/04
dtype: object

---->   pandas.Series

--------------------------------------
ID: 5234 --> 2
# PeriodIndex
In [279]: s = pd.Series(pd.period_range("20130101", periods=4))

In [280]: s
Out[280]: 
0    2013-01-01
1    2013-01-02
2    2013-01-03
3    2013-01-04
dtype: period[D]

In [281]: s.dt.strftime("%Y/%m/%d")
Out[281]: 
0    2013/01/01
1    2013/01/02
2    2013/01/03
3    2013/01/04
dtype: object

---->   pandas.Series; pandas.period_range

--------------------------------------
ID: 5235 --> 2
# period
In [282]: s = pd.Series(pd.period_range("20130101", periods=4, freq="D"))

In [283]: s
Out[283]: 
0    2013-01-01
1    2013-01-02
2    2013-01-03
3    2013-01-04
dtype: period[D]

In [284]: s.dt.year
Out[284]: 
0    2013
1    2013
2    2013
3    2013
dtype: int64

In [285]: s.dt.day
Out[285]: 
0    1
1    2
2    3
3    4
dtype: int64

---->   pandas.Series; pandas.period_range

--------------------------------------
ID: 5236 --> 1
# timedelta
In [286]: s = pd.Series(pd.timedelta_range("1 day 00:00:05", periods=4, freq="s"))

In [287]: s
Out[287]: 
0   1 days 00:00:05
1   1 days 00:00:06
2   1 days 00:00:07
3   1 days 00:00:08
dtype: timedelta64[ns]

In [288]: s.dt.days
Out[288]: 
0    1
1    1
2    1
3    1
dtype: int64

In [289]: s.dt.seconds
Out[289]: 
0    5
1    6
2    7
3    8
dtype: int32

In [290]: s.dt.components
Out[290]: 
   days  hours  minutes  seconds  milliseconds  microseconds  nanoseconds
0     1      0        0        5             0             0            0
1     1      0        0        6             0             0            0
2     1      0        0        7             0             0            0
3     1      0        0        8             0             0            0

---->   pandas.Series

--------------------------------------
ID: 5237 --> 1
In [291]: s = pd.Series(
   .....:     ["A", "B", "C", "Aaba", "Baca", np.nan, "CABA", "dog", "cat"], dtype="string"
   .....: )
   .....: 

In [292]: s.str.lower()
Out[292]: 
0       a
1       b
2       c
3    aaba
4    baca
5    
6    caba
7     dog
8     cat
dtype: string

---->   pandas.Series

--------------------------------------
ID: 5238 --> 2
In [293]: df = pd.DataFrame(
   .....:     {
   .....:         "one": pd.Series(np.random.randn(3), index=["a", "b", "c"]),
   .....:         "two": pd.Series(np.random.randn(4), index=["a", "b", "c", "d"]),
   .....:         "three": pd.Series(np.random.randn(3), index=["b", "c", "d"]),
   .....:     }
   .....: )
   .....: 

In [294]: unsorted_df = df.reindex(
   .....:     index=["a", "d", "c", "b"], columns=["three", "two", "one"]
   .....: )
   .....: 

In [295]: unsorted_df
Out[295]: 
      three       two       one
a       NaN -1.152244  0.562973
d -0.252916 -0.109597       NaN
c  1.273388 -0.167123  0.640382
b -0.098217  0.009797 -1.299504

# DataFrame
In [296]: unsorted_df.sort_index()
Out[296]: 
      three       two       one
a       NaN -1.152244  0.562973
b -0.098217  0.009797 -1.299504
c  1.273388 -0.167123  0.640382
d -0.252916 -0.109597       NaN

In [297]: unsorted_df.sort_index(ascending=False)
Out[297]: 
      three       two       one
d -0.252916 -0.109597       NaN
c  1.273388 -0.167123  0.640382
b -0.098217  0.009797 -1.299504
a       NaN -1.152244  0.562973

In [298]: unsorted_df.sort_index(axis=1)
Out[298]: 
        one     three       two
a  0.562973       NaN -1.152244
d       NaN -0.252916 -0.109597
c  0.640382  1.273388 -0.167123
b -1.299504 -0.098217  0.009797

# Series
In [299]: unsorted_df["three"].sort_index()
Out[299]: 
a         NaN
b   -0.098217
c    1.273388
d   -0.252916
Name: three, dtype: float64

---->   pandas.DataFrame; pandas.Series

--------------------------------------
ID: 5239 --> 1
In [300]: s1 = pd.DataFrame({"a": ["B", "a", "C"], "b": [1, 2, 3], "c": [2, 3, 4]}).set_index(
   .....:     list("ab")
   .....: )
   .....: 

In [301]: s1
Out[301]: 
     c
a b   
B 1  2
a 2  3
C 3  4

---->   pandas.DataFrame

--------------------------------------
ID: 5241 --> 1
In [304]: df1 = pd.DataFrame(
   .....:     {"one": [2, 1, 1, 1], "two": [1, 3, 2, 4], "three": [5, 4, 3, 2]}
   .....: )
   .....: 

In [305]: df1.sort_values(by="two")
Out[305]: 
   one  two  three
0    2    1      5
2    1    2      3
1    1    3      4
3    1    4      2

---->   pandas.DataFrame

--------------------------------------
ID: 5244 --> 1
In [310]: s1 = pd.Series(["B", "a", "C"])

---->   pandas.Series

--------------------------------------
ID: 5246 --> 1
In [313]: df = pd.DataFrame({"a": ["B", "a", "C"], "b": [1, 2, 3]})

---->   pandas.DataFrame

--------------------------------------
ID: 5248 --> 2
# Build MultiIndex
In [316]: idx = pd.MultiIndex.from_tuples(
   .....:     [("a", 1), ("a", 2), ("a", 2), ("b", 2), ("b", 1), ("b", 1)]
   .....: )
   .....: 

In [317]: idx.names = ["first", "second"]

# Build DataFrame
In [318]: df_multi = pd.DataFrame({"A": np.arange(6, 0, -1)}, index=idx)

In [319]: df_multi
Out[319]: 
              A
first second   
a     1       6
      2       5
      2       4
b     2       3
      1       2
      1       1

---->   pandas.MultiIndex; pandas.DataFrame

--------------------------------------
ID: 5250 --> 2
In [321]: ser = pd.Series([1, 2, 3])

In [322]: ser.searchsorted([0, 3])
Out[322]: array([0, 2])

In [323]: ser.searchsorted([0, 4])
Out[323]: array([0, 3])

In [324]: ser.searchsorted([1, 3], side="right")
Out[324]: array([1, 3])

In [325]: ser.searchsorted([1, 3], side="left")
Out[325]: array([0, 2])

In [326]: ser = pd.Series([3, 1, 2])

In [327]: ser.searchsorted([0, 3], sorter=np.argsort(ser))
Out[327]: array([0, 2])

---->   pandas.Series; Series.searchsorted

--------------------------------------
ID: 5251 --> 3
In [328]: s = pd.Series(np.random.permutation(10))

In [329]: s
Out[329]: 
0    2
1    0
2    3
3    7
4    1
5    5
6    9
7    6
8    8
9    4
dtype: int64

In [330]: s.sort_values()
Out[330]: 
1    0
4    1
0    2
2    3
9    4
5    5
7    6
3    7
8    8
6    9
dtype: int64

In [331]: s.nsmallest(3)
Out[331]: 
1    0
4    1
0    2
dtype: int64

In [332]: s.nlargest(3)
Out[332]: 
6    9
8    8
3    7
dtype: int64

---->   pandas.Series; Series.nsmallest; Series.nlargest

--------------------------------------
ID: 5252 --> 3
In [333]: df = pd.DataFrame(
   .....:     {
   .....:         "a": [-2, -1, 1, 10, 8, 11, -1],
   .....:         "b": list("abdceff"),
   .....:         "c": [1.0, 2.0, 4.0, 3.2, np.nan, 3.0, 4.0],
   .....:     }
   .....: )
   .....: 

In [334]: df.nlargest(3, "a")
Out[334]: 
    a  b    c
5  11  f  3.0
3  10  c  3.2
4   8  e  NaN

In [335]: df.nlargest(5, ["a", "c"])
Out[335]: 
    a  b    c
5  11  f  3.0
3  10  c  3.2
4   8  e  NaN
2   1  d  4.0
6  -1  f  4.0

In [336]: df.nsmallest(3, "a")
Out[336]: 
   a  b    c
0 -2  a  1.0
1 -1  b  2.0
6 -1  f  4.0

In [337]: df.nsmallest(5, ["a", "c"])
Out[337]: 
   a  b    c
0 -2  a  1.0
1 -1  b  2.0
6 -1  f  4.0
2  1  d  4.0
4  8  e  NaN

---->   pandas.DataFrame; DataFrame.nlargest; DataFrame.nsmallest

--------------------------------------
ID: 5253 --> 1
In [338]: df1.columns = pd.MultiIndex.from_tuples(
   .....:     [("a", "one"), ("a", "two"), ("b", "three")]
   .....: )
   .....: 

In [339]: df1.sort_values(by=("a", "two"))
Out[339]: 
    a         b
  one two three
0   2   1     5
2   1   2     3
1   1   3     4
3   1   4     2

---->   pandas.MultiIndex

--------------------------------------
ID: 5254 --> 2
In [340]: dft = pd.DataFrame(
   .....:     {
   .....:         "A": np.random.rand(3),
   .....:         "B": 1,
   .....:         "C": "foo",
   .....:         "D": pd.Timestamp("20010102"),
   .....:         "E": pd.Series([1.0] * 3).astype("float32"),
   .....:         "F": False,
   .....:         "G": pd.Series([1] * 3, dtype="int8"),
   .....:     }
   .....: )
   .....: 

In [341]: dft
Out[341]: 
          A  B    C          D    E      F  G
0  0.035962  1  foo 2001-01-02  1.0  False  1
1  0.701379  1  foo 2001-01-02  1.0  False  1
2  0.281885  1  foo 2001-01-02  1.0  False  1

In [342]: dft.dtypes
Out[342]: 
A           float64
B             int64
C            object
D    datetime64[ns]
E           float32
F              bool
G              int8
dtype: object

---->   pandas.DataFrame; pandas.Series

--------------------------------------
ID: 5256 --> 1
# these ints are coerced to floats
In [344]: pd.Series([1, 2, 3, 4, 5, 6.0])
Out[344]: 
0    1.0
1    2.0
2    3.0
3    4.0
4    5.0
5    6.0
dtype: float64

# string data forces an ``object`` dtype
In [345]: pd.Series([1, 2, 3, 6.0, "foo"])
Out[345]: 
0      1
1      2
2      3
3    6.0
4    foo
dtype: object

---->   pandas.Series

--------------------------------------
ID: 5258 --> 2
In [347]: df1 = pd.DataFrame(np.random.randn(8, 1), columns=["A"], dtype="float32")

In [348]: df1
Out[348]: 
          A
0  0.224364
1  1.890546
2  0.182879
3  0.787847
4 -0.188449
5  0.667715
6 -0.011736
7 -0.399073

In [349]: df1.dtypes
Out[349]: 
A    float32
dtype: object

In [350]: df2 = pd.DataFrame(
   .....:     {
   .....:         "A": pd.Series(np.random.randn(8), dtype="float16"),
   .....:         "B": pd.Series(np.random.randn(8)),
   .....:         "C": pd.Series(np.random.randint(0, 255, size=8), dtype="uint8"),
   .....:     }
   .....: )
   .....: 

In [351]: df2
Out[351]: 
          A         B    C
0  0.823242  0.256090   26
1  1.607422  1.426469   86
2 -0.333740 -0.416203   46
3 -0.063477  1.139976  212
4 -1.014648 -1.193477   26
5  0.678711  0.096706    7
6 -0.040863 -1.956850  184
7 -0.357422 -0.714337  206

In [352]: df2.dtypes
Out[352]: 
A    float16
B    float64
C      uint8
dtype: object

---->   pandas.DataFrame; pandas.Series

--------------------------------------
ID: 5259 --> 1
In [353]: pd.DataFrame([1, 2], columns=["a"]).dtypes
Out[353]: 
a    int64
dtype: object

In [354]: pd.DataFrame({"a": [1, 2]}).dtypes
Out[354]: 
a    int64
dtype: object

In [355]: pd.DataFrame({"a": 1}, index=list(range(2))).dtypes
Out[355]: 
a    int64
dtype: object

---->   pandas.DataFrame

--------------------------------------
ID: 5260 --> 1
In [356]: frame = pd.DataFrame(np.array([1, 2]))

---->   pandas.DataFrame

--------------------------------------
ID: 5261 --> 1
In [357]: df3 = df1.reindex_like(df2).fillna(value=0.0) + df2

In [358]: df3
Out[358]: 
          A         B      C
0  1.047606  0.256090   26.0
1  3.497968  1.426469   86.0
2 -0.150862 -0.416203   46.0
3  0.724370  1.139976  212.0
4 -1.203098 -1.193477   26.0
5  1.346426  0.096706    7.0
6 -0.052599 -1.956850  184.0
7 -0.756495 -0.714337  206.0

In [359]: df3.dtypes
Out[359]: 
A    float32
B    float64
C    float64
dtype: object

---->   DataFrame.reindex_like

--------------------------------------
ID: 5263 --> 1
In [361]: df3
Out[361]: 
          A         B      C
0  1.047606  0.256090   26.0
1  3.497968  1.426469   86.0
2 -0.150862 -0.416203   46.0
3  0.724370  1.139976  212.0
4 -1.203098 -1.193477   26.0
5  1.346426  0.096706    7.0
6 -0.052599 -1.956850  184.0
7 -0.756495 -0.714337  206.0

In [362]: df3.dtypes
Out[362]: 
A    float32
B    float64
C    float64
dtype: object

# conversion of dtypes
In [363]: df3.astype("float32").dtypes
Out[363]: 
A    float32
B    float32
C    float32
dtype: object

---->   DataFrame.astype

--------------------------------------
ID: 5264 --> 1
In [364]: dft = pd.DataFrame({"a": [1, 2, 3], "b": [4, 5, 6], "c": [7, 8, 9]})

In [365]: dft[["a", "b"]] = dft[["a", "b"]].astype(np.uint8)

In [366]: dft
Out[366]: 
   a  b  c
0  1  4  7
1  2  5  8
2  3  6  9

In [367]: dft.dtypes
Out[367]: 
a    uint8
b    uint8
c    int64
dtype: object

---->   pandas.DataFrame

--------------------------------------
ID: 5265 --> 2
In [368]: dft1 = pd.DataFrame({"a": [1, 0, 1], "b": [4, 5, 6], "c": [7, 8, 9]})

In [369]: dft1 = dft1.astype({"a": np.bool_, "c": np.float64})

In [370]: dft1
Out[370]: 
       a  b    c
0   True  4  7.0
1  False  5  8.0
2   True  6  9.0

In [371]: dft1.dtypes
Out[371]: 
a       bool
b      int64
c    float64
dtype: object

---->   pandas.DataFrame; DataFrame.astype

--------------------------------------
ID: 5266 --> 1
In [372]: dft = pd.DataFrame({"a": [1, 2, 3], "b": [4, 5, 6], "c": [7, 8, 9]})

In [373]: dft.loc[:, ["a", "b"]].astype(np.uint8).dtypes
Out[373]: 
a    uint8
b    uint8
dtype: object

In [374]: dft.loc[:, ["a", "b"]] = dft.loc[:, ["a", "b"]].astype(np.uint8)

In [375]: dft.dtypes
Out[375]: 
a    int64
b    int64
c    int64
dtype: object

---->   pandas.DataFrame

--------------------------------------
ID: 5267 --> 1
In [376]: import datetime

In [377]: df = pd.DataFrame(
   .....:     [
   .....:         [1, 2],
   .....:         ["a", "b"],
   .....:         [datetime.datetime(2016, 3, 2), datetime.datetime(2016, 3, 2)],
   .....:     ]
   .....: )
   .....: 

In [378]: df = df.T

In [379]: df
Out[379]: 
   0  1          2
0  1  a 2016-03-02
1  2  b 2016-03-02

In [380]: df.dtypes
Out[380]: 
0            object
1            object
2    datetime64[ns]
dtype: object

---->   pandas.DataFrame

--------------------------------------
ID: 5268 --> 1
In [381]: df.infer_objects().dtypes
Out[381]: 
0             int64
1            object
2    datetime64[ns]
dtype: object

---->   DataFrame.infer_objects

--------------------------------------
ID: 5269 --> 1
In [382]: m = ["1.1", 2, 3]

In [383]: pd.to_numeric(m)
Out[383]: array([1.1, 2. , 3. ])

---->   pandas.to_numeric

--------------------------------------
ID: 5270 --> 1
In [384]: import datetime

In [385]: m = ["2016-07-09", datetime.datetime(2016, 3, 2)]

In [386]: pd.to_datetime(m)
Out[386]: DatetimeIndex(['2016-07-09', '2016-03-02'], dtype='datetime64[ns]', freq=None)

---->   pandas.to_datetime

--------------------------------------
ID: 5271 --> 1
In [387]: m = ["5us", pd.Timedelta("1day")]

In [388]: pd.to_timedelta(m)
Out[388]: TimedeltaIndex(['0 days 00:00:00.000005', '1 days 00:00:00'], dtype='timedelta64[ns]', freq=None)

---->   pandas.to_timedelta

--------------------------------------
ID: 5272 --> 3
In [389]: import datetime

In [390]: m = ["apple", datetime.datetime(2016, 3, 2)]

In [391]: pd.to_datetime(m, errors="coerce")
Out[391]: DatetimeIndex(['NaT', '2016-03-02'], dtype='datetime64[ns]', freq=None)

In [392]: m = ["apple", 2, 3]

In [393]: pd.to_numeric(m, errors="coerce")
Out[393]: array([nan,  2.,  3.])

In [394]: m = ["apple", pd.Timedelta("1day")]

In [395]: pd.to_timedelta(m, errors="coerce")
Out[395]: TimedeltaIndex([NaT, '1 days'], dtype='timedelta64[ns]', freq=None)

---->   pandas.to_datetime; pandas.to_numeric; pandas.to_timedelta

--------------------------------------
ID: 5273 --> 3
In [396]: import datetime

In [397]: m = ["apple", datetime.datetime(2016, 3, 2)]

In [398]: pd.to_datetime(m, errors="ignore")
Out[398]: Index(['apple', 2016-03-02 00:00:00], dtype='object')

In [399]: m = ["apple", 2, 3]

In [400]: pd.to_numeric(m, errors="ignore")
Out[400]: array(['apple', 2, 3], dtype=object)

In [401]: m = ["apple", pd.Timedelta("1day")]

In [402]: pd.to_timedelta(m, errors="ignore")
Out[402]: array(['apple', Timedelta('1 days 00:00:00')], dtype=object)

---->   pandas.to_datetime; pandas.to_numeric; pandas.to_timedelta

--------------------------------------
ID: 5274 --> 1
In [403]: m = ["1", 2, 3]

In [404]: pd.to_numeric(m, downcast="integer")  # smallest signed int dtype
Out[404]: array([1, 2, 3], dtype=int8)

In [405]: pd.to_numeric(m, downcast="signed")  # same as 'integer'
Out[405]: array([1, 2, 3], dtype=int8)

In [406]: pd.to_numeric(m, downcast="unsigned")  # smallest unsigned int dtype
Out[406]: array([1, 2, 3], dtype=uint8)

In [407]: pd.to_numeric(m, downcast="float")  # smallest float dtype
Out[407]: array([1., 2., 3.], dtype=float32)

---->   pandas.to_numeric

--------------------------------------
ID: 5275 --> 1
In [408]: import datetime

In [409]: df = pd.DataFrame([["2016-07-09", datetime.datetime(2016, 3, 2)]] * 2, dtype="O")

In [410]: df
Out[410]: 
            0                    1
0  2016-07-09  2016-03-02 00:00:00
1  2016-07-09  2016-03-02 00:00:00

In [411]: df.apply(pd.to_datetime)
Out[411]: 
           0          1
0 2016-07-09 2016-03-02
1 2016-07-09 2016-03-02

In [412]: df = pd.DataFrame([["1.1", 2, 3]] * 2, dtype="O")

In [413]: df
Out[413]: 
     0  1  2
0  1.1  2  3
1  1.1  2  3

In [414]: df.apply(pd.to_numeric)
Out[414]: 
     0  1  2
0  1.1  2  3
1  1.1  2  3

In [415]: df = pd.DataFrame([["5us", pd.Timedelta("1day")]] * 2, dtype="O")

In [416]: df
Out[416]: 
     0                1
0  5us  1 days 00:00:00
1  5us  1 days 00:00:00

In [417]: df.apply(pd.to_timedelta)
Out[417]: 
                       0      1
0 0 days 00:00:00.000005 1 days
1 0 days 00:00:00.000005 1 days

---->   pandas.DataFrame

--------------------------------------
ID: 5276 --> 1
In [418]: dfi = df3.astype("int32")

In [419]: dfi["E"] = 1

In [420]: dfi
Out[420]: 
   A  B    C  E
0  1  0   26  1
1  3  1   86  1
2  0  0   46  1
3  0  1  212  1
4 -1 -1   26  1
5  1  0    7  1
6  0 -1  184  1
7  0  0  206  1

In [421]: dfi.dtypes
Out[421]: 
A    int32
B    int32
C    int32
E    int64
dtype: object

In [422]: casted = dfi[dfi > 0]

In [423]: casted
Out[423]: 
     A    B    C  E
0  1.0  NaN   26  1
1  3.0  1.0   86  1
2  NaN  NaN   46  1
3  NaN  1.0  212  1
4  NaN  NaN   26  1
5  1.0  NaN    7  1
6  NaN  NaN  184  1
7  NaN  NaN  206  1

In [424]: casted.dtypes
Out[424]: 
A    float64
B    float64
C      int32
E      int64
dtype: object

---->   DataFrame.astype

--------------------------------------
ID: 5277 --> 1
In [425]: dfa = df3.copy()

In [426]: dfa["A"] = dfa["A"].astype("float32")

In [427]: dfa.dtypes
Out[427]: 
A    float32
B    float64
C    float64
dtype: object

In [428]: casted = dfa[df2 > 0]

In [429]: casted
Out[429]: 
          A         B      C
0  1.047606  0.256090   26.0
1  3.497968  1.426469   86.0
2       NaN       NaN   46.0
3       NaN  1.139976  212.0
4       NaN       NaN   26.0
5  1.346426  0.096706    7.0
6       NaN       NaN  184.0
7       NaN       NaN  206.0

In [430]: casted.dtypes
Out[430]: 
A    float32
B    float64
C    float64
dtype: object

---->   DataFrame.copy

--------------------------------------
ID: 5278 --> 2
In [431]: df = pd.DataFrame(
   .....:     {
   .....:         "string": list("abc"),
   .....:         "int64": list(range(1, 4)),
   .....:         "uint8": np.arange(3, 6).astype("u1"),
   .....:         "float64": np.arange(4.0, 7.0),
   .....:         "bool1": [True, False, True],
   .....:         "bool2": [False, True, False],
   .....:         "dates": pd.date_range("now", periods=3),
   .....:         "category": pd.Series(list("ABC")).astype("category"),
   .....:     }
   .....: )
   .....: 

In [432]: df["tdeltas"] = df.dates.diff()

In [433]: df["uint64"] = np.arange(3, 6).astype("u8")

In [434]: df["other_dates"] = pd.date_range("20130101", periods=3)

In [435]: df["tz_aware_dates"] = pd.date_range("20130101", periods=3, tz="US/Eastern")

In [436]: df
Out[436]: 
  string  int64  uint8  ...  uint64  other_dates            tz_aware_dates
0      a      1      3  ...       3   2013-01-01 2013-01-01 00:00:00-05:00
1      b      2      4  ...       4   2013-01-02 2013-01-02 00:00:00-05:00
2      c      3      5  ...       5   2013-01-03 2013-01-03 00:00:00-05:00

[3 rows x 12 columns]

---->   pandas.DataFrame; pandas.Series

--------------------------------------
ID: 5279 --> 1
In [438]: df.select_dtypes(include=[bool])
Out[438]: 
   bool1  bool2
0   True  False
1  False   True
2   True  False

---->   DataFrame.select_dtypes

--------------------------------------
ID: 5280 --> 1
In [439]: df.select_dtypes(include=["bool"])
Out[439]: 
   bool1  bool2
0   True  False
1  False   True
2   True  False

---->   DataFrame.select_dtypes

--------------------------------------
ID: 5281 --> 1
In [440]: df.select_dtypes(include=["number", "bool"], exclude=["unsignedinteger"])
Out[440]: 
   int64  float64  bool1  bool2 tdeltas
0      1      4.0   True  False     NaT
1      2      5.0  False   True  1 days
2      3      6.0   True  False  1 days

---->   DataFrame.select_dtypes

--------------------------------------
ID: 5282 --> 1
In [441]: df.select_dtypes(include=["object"])
Out[441]: 
  string
0      a
1      b
2      c

---->   DataFrame.select_dtypes

--------------------------------------
ID: 5289 --> 1
from pycylon import read_csv, DataFrame, CylonEnv
from pycylon.net import MPIConfig

# Initialize Cylon distributed environment
config: MPIConfig = MPIConfig()
env: CylonEnv = CylonEnv(config=config, distributed=True)

df1: DataFrame = read_csv('/tmp/csv1.csv')
df2: DataFrame = read_csv('/tmp/csv2.csv')

# Using 1000s of cores across the cluster to compute the join
df3: Table = df1.join(other=df2, on=[0], algorithm="hash", env=env)

print(df3)

---->   DataFrame.join

--------------------------------------
ID: 5292 --> 1
In [1]: s = pd.Series(range(5))

In [2]: s.rolling(window=2).sum()
Out[2]: 
0    NaN
1    1.0
2    3.0
3    5.0
4    7.0
dtype: float64

---->   Series.rolling

--------------------------------------
ID: 5293 --> 1
In [3]: for window in s.rolling(window=2):
   ...:     print(window)
   ...: 
0    0
dtype: int64
0    0
1    1
dtype: int64
1    1
2    2
dtype: int64
2    2
3    3
dtype: int64
3    3
4    4
dtype: int64

---->   Series.rolling

--------------------------------------
ID: 5294 --> 1
In [4]: s = pd.Series(range(5), index=pd.date_range('2020-01-01', periods=5, freq='1D'))

In [5]: s.rolling(window='2D').sum()
Out[5]: 
2020-01-01    0.0
2020-01-02    1.0
2020-01-03    3.0
2020-01-04    5.0
2020-01-05    7.0
Freq: D, dtype: float64

---->   Series.rolling

--------------------------------------
ID: 5295 --> 1
In [6]: df = pd.DataFrame({'A': ['a', 'b', 'a', 'b', 'a'], 'B': range(5)})

In [7]: df.groupby('A').expanding().sum()
Out[7]: 
       B
A       
a 0  0.0
  2  2.0
  4  6.0
b 1  1.0
  3  4.0

---->   DataFrame.groupby

--------------------------------------
ID: 5296 --> 1
In [8]: def weighted_mean(x):
   ...:     arr = np.ones((1, x.shape[1]))
   ...:     arr[:, :2] = (x[:, :2] * x[:, 2]).sum(axis=0) / x[:, 2].sum()
   ...:     return arr
   ...: 

In [9]: df = pd.DataFrame([[1, 2, 0.6], [2, 3, 0.4], [3, 4, 0.2], [4, 5, 0.7]])

In [10]: df.rolling(2, method="table", min_periods=0).apply(weighted_mean, raw=True, engine="numba")  # noqa:E501
Out[10]: 
          0         1    2
0  1.000000  2.000000  1.0
1  1.800000  2.000000  1.0
2  3.333333  2.333333  1.0
3  1.555556  7.000000  1.0

---->   DataFrame.rolling

--------------------------------------
ID: 5297 --> 1
In [11]: df = pd.DataFrame([[1, 2, 0.6], [2, 3, 0.4], [3, 4, 0.2], [4, 5, 0.7]])

In [12]: df.ewm(0.5).mean()
Out[12]: 
          0         1         2
0  1.000000  2.000000  0.600000
1  1.750000  2.750000  0.450000
2  2.615385  3.615385  0.276923
3  3.550000  4.550000  0.562500

---->   DataFrame.ewm

--------------------------------------
ID: 5298 --> 2
In [13]: online_ewm = df.head(2).ewm(0.5).online()

In [14]: online_ewm.mean()
Out[14]: 
      0     1     2
0  1.00  2.00  0.60
1  1.75  2.75  0.45

In [15]: online_ewm.mean(update=df.tail(1))
Out[15]: 
          0         1         2
3  3.307692  4.307692  0.623077

---->   DataFrame.head; DataFrame.tail

--------------------------------------
ID: 5299 --> 1
In [16]: s = pd.Series([np.nan, 1, 2, np.nan, np.nan, 3])

In [17]: s.rolling(window=3, min_periods=1).sum()
Out[17]: 
0    NaN
1    1.0
2    3.0
3    3.0
4    2.0
5    3.0
dtype: float64

In [18]: s.rolling(window=3, min_periods=2).sum()
Out[18]: 
0    NaN
1    NaN
2    3.0
3    3.0
4    NaN
5    NaN
dtype: float64

# Equivalent to min_periods=3
In [19]: s.rolling(window=3, min_periods=None).sum()
Out[19]: 
0   NaN
1   NaN
2   NaN
3   NaN
4   NaN
5   NaN
dtype: float64

---->   Series.rolling

--------------------------------------
ID: 5300 --> 1
In [20]: df = pd.DataFrame({"A": range(5), "B": range(10, 15)})

In [21]: df.expanding().agg([np.sum, np.mean, np.std])
Out[21]: 
      A                    B                
    sum mean       std   sum  mean       std
0   0.0  0.0       NaN  10.0  10.0       NaN
1   1.0  0.5  0.707107  21.0  10.5  0.707107
2   3.0  1.0  1.000000  33.0  11.0  1.000000
3   6.0  1.5  1.290994  46.0  11.5  1.290994
4  10.0  2.0  1.581139  60.0  12.0  1.581139

---->   DataFrame.expanding

--------------------------------------
ID: 5301 --> 1
In [22]: times = ['2020-01-01', '2020-01-03', '2020-01-04', '2020-01-05', '2020-01-29']

In [23]: s = pd.Series(range(5), index=pd.DatetimeIndex(times))

In [24]: s
Out[24]: 
2020-01-01    0
2020-01-03    1
2020-01-04    2
2020-01-05    3
2020-01-29    4
dtype: int64

# Window with 2 observations
In [25]: s.rolling(window=2).sum()
Out[25]: 
2020-01-01    NaN
2020-01-03    1.0
2020-01-04    3.0
2020-01-05    5.0
2020-01-29    7.0
dtype: float64

# Window with 2 days worth of observations
In [26]: s.rolling(window='2D').sum()
Out[26]: 
2020-01-01    0.0
2020-01-03    1.0
2020-01-04    3.0
2020-01-05    5.0
2020-01-29    4.0
dtype: float64

---->   Series.rolling

--------------------------------------
ID: 5302 --> 1
In [27]: s = pd.Series(range(10))

In [28]: s.rolling(window=5).mean()
Out[28]: 
0    NaN
1    NaN
2    NaN
3    NaN
4    2.0
5    3.0
6    4.0
7    5.0
8    6.0
9    7.0
dtype: float64

In [29]: s.rolling(window=5, center=True).mean()
Out[29]: 
0    NaN
1    NaN
2    2.0
3    3.0
4    4.0
5    5.0
6    6.0
7    7.0
8    NaN
9    NaN
dtype: float64

---->   Series.rolling

--------------------------------------
ID: 5303 --> 1
In [30]: df = pd.DataFrame(
   ....:     {"A": [0, 1, 2, 3, 4]}, index=pd.date_range("2020", periods=5, freq="1D")
   ....: )
   ....: 

In [31]: df
Out[31]: 
            A
2020-01-01  0
2020-01-02  1
2020-01-03  2
2020-01-04  3
2020-01-05  4

In [32]: df.rolling("2D", center=False).mean()
Out[32]: 
              A
2020-01-01  0.0
2020-01-02  0.5
2020-01-03  1.5
2020-01-04  2.5
2020-01-05  3.5

In [33]: df.rolling("2D", center=True).mean()
Out[33]: 
              A
2020-01-01  0.5
2020-01-02  1.5
2020-01-03  2.5
2020-01-04  3.5
2020-01-05  4.0

---->   DataFrame.rolling

--------------------------------------
ID: 5304 --> 2
In [34]: df = pd.DataFrame(
   ....:     {"x": 1},
   ....:     index=[
   ....:         pd.Timestamp("20130101 09:00:01"),
   ....:         pd.Timestamp("20130101 09:00:02"),
   ....:         pd.Timestamp("20130101 09:00:03"),
   ....:         pd.Timestamp("20130101 09:00:04"),
   ....:         pd.Timestamp("20130101 09:00:06"),
   ....:     ],
   ....: )
   ....: 

In [35]: df["right"] = df.rolling("2s", closed="right").x.sum()  # default

In [36]: df["both"] = df.rolling("2s", closed="both").x.sum()

In [37]: df["left"] = df.rolling("2s", closed="left").x.sum()

In [38]: df["neither"] = df.rolling("2s", closed="neither").x.sum()

In [39]: df
Out[39]: 
                     x  right  both  left  neither
2013-01-01 09:00:01  1    1.0   1.0   NaN      NaN
2013-01-01 09:00:02  1    2.0   2.0   1.0      1.0
2013-01-01 09:00:03  1    2.0   3.0   2.0      1.0
2013-01-01 09:00:04  1    2.0   3.0   2.0      1.0
2013-01-01 09:00:06  1    1.0   2.0   1.0      NaN

---->   DataFrame.rolling; Series.sum

--------------------------------------
ID: 5306 --> 1
In [2]: from pandas.api.indexers import BaseIndexer

In [3]: class CustomIndexer(BaseIndexer):
   ...:     def get_window_bounds(self, num_values, min_periods, center, closed):
   ...:         start = np.empty(num_values, dtype=np.int64)
   ...:         end = np.empty(num_values, dtype=np.int64)
   ...:         for i in range(num_values):
   ...:             if self.use_expanding[i]:
   ...:                 start[i] = 0
   ...:                 end[i] = i + 1
   ...:             else:
   ...:                 start[i] = i
   ...:                 end[i] = i + self.window_size
   ...:         return start, end

In [4]: indexer = CustomIndexer(window_size=1, use_expanding=use_expanding)

In [5]: df.rolling(indexer).sum()
Out[5]:
    values
0     0.0
1     1.0
2     3.0
3     3.0
4    10.0

---->   DataFrame.rolling

--------------------------------------
ID: 5307 --> 1
In [44]: from pandas.api.indexers import VariableOffsetWindowIndexer

In [45]: df = pd.DataFrame(range(10), index=pd.date_range("2020", periods=10))

In [46]: offset = pd.offsets.BDay(1)

In [47]: indexer = VariableOffsetWindowIndexer(index=df.index, offset=offset)

In [48]: df
Out[48]: 
            0
2020-01-01  0
2020-01-02  1
2020-01-03  2
2020-01-04  3
2020-01-05  4
2020-01-06  5
2020-01-07  6
2020-01-08  7
2020-01-09  8
2020-01-10  9

In [49]: df.rolling(indexer).sum()
Out[49]: 
               0
2020-01-01   0.0
2020-01-02   1.0
2020-01-03   2.0
2020-01-04   3.0
2020-01-05   7.0
2020-01-06  12.0
2020-01-07   6.0
2020-01-08   7.0
2020-01-09   8.0
2020-01-10   9.0

---->   DataFrame.rolling

--------------------------------------
ID: 5308 --> 1
In [50]: from pandas.api.indexers import FixedForwardWindowIndexer

In [51]: indexer = FixedForwardWindowIndexer(window_size=2)

In [52]: df.rolling(indexer, min_periods=1).sum()
Out[52]: 
               0
2020-01-01   1.0
2020-01-02   3.0
2020-01-03   5.0
2020-01-04   7.0
2020-01-05   9.0
2020-01-06  11.0
2020-01-07  13.0
2020-01-08  15.0
2020-01-09  17.0
2020-01-10   9.0

---->   DataFrame.rolling

--------------------------------------
ID: 5310 --> 2
In [57]: def mad(x):
   ....:     return np.fabs(x - x.mean()).mean()
   ....: 

In [58]: s = pd.Series(range(10))

In [59]: s.rolling(window=4).apply(mad, raw=True)
Out[59]: 
0    NaN
1    NaN
2    NaN
3    1.0
4    1.0
5    1.0
6    1.0
7    1.0
8    1.0
9    1.0
dtype: float64

---->   Series.mean; Series.rolling

--------------------------------------
ID: 5311 --> 2
In [60]: df = pd.DataFrame(
   ....:     np.random.randn(10, 4),
   ....:     index=pd.date_range("2020-01-01", periods=10),
   ....:     columns=["A", "B", "C", "D"],
   ....: )
   ....: 

In [61]: df = df.cumsum()

In [62]: df2 = df[:4]

In [63]: df2.rolling(window=2).corr(df2["B"])
Out[63]: 
              A    B    C    D
2020-01-01  NaN  NaN  NaN  NaN
2020-01-02 -1.0  1.0 -1.0  1.0
2020-01-03  1.0  1.0  1.0 -1.0
2020-01-04 -1.0  1.0  1.0 -1.0

---->   DataFrame.cumsum; DataFrame.rolling

--------------------------------------
ID: 5313 --> 1
In [66]: s = pd.Series(range(10))

In [67]: s.rolling(window=5).mean()
Out[67]: 
0    NaN
1    NaN
2    NaN
3    NaN
4    2.0
5    3.0
6    4.0
7    5.0
8    6.0
9    7.0
dtype: float64

In [68]: s.rolling(window=5, win_type="triang").mean()
Out[68]: 
0    NaN
1    NaN
2    NaN
3    NaN
4    2.0
5    3.0
6    4.0
7    5.0
8    6.0
9    7.0
dtype: float64

# Supplementary Scipy arguments passed in the aggregation function
In [69]: s.rolling(window=5, win_type="gaussian").mean(std=0.1)
Out[69]: 
0    NaN
1    NaN
2    NaN
3    NaN
4    2.0
5    3.0
6    4.0
7    5.0
8    6.0
9    7.0
dtype: float64

---->   Series.rolling

--------------------------------------
ID: 5314 --> 2
In [70]: df = pd.DataFrame(range(5))

In [71]: df.rolling(window=len(df), min_periods=1).mean()
Out[71]: 
     0
0  0.0
1  0.5
2  1.0
3  1.5
4  2.0

In [72]: df.expanding(min_periods=1).mean()
Out[72]: 
     0
0  0.0
1  0.5
2  1.0
3  1.5
4  2.0

---->   DataFrame.rolling; DataFrame.expanding

--------------------------------------
ID: 5315 --> 1
In [73]: df = pd.DataFrame({"B": [0, 1, 2, np.nan, 4]})

In [74]: df
Out[74]: 
     B
0  0.0
1  1.0
2  2.0
3  NaN
4  4.0

In [75]: times = ["2020-01-01", "2020-01-03", "2020-01-10", "2020-01-15", "2020-01-17"]

In [76]: df.ewm(halflife="4 days", times=pd.DatetimeIndex(times)).mean()
Out[76]: 
          B
0  0.000000
1  0.585786
2  1.523889
3  1.523889
4  3.233686

---->   DataFrame.ewm

--------------------------------------
ID: 5321 --> 1
In [13]: s[0]
Out[13]: 0.4691122999071863

In [14]: s[:3]
Out[14]: 
a    0.469112
b   -0.282863
c   -1.509059
dtype: float64

In [15]: s[s > s.median()]
Out[15]: 
a    0.469112
e    1.212112
dtype: float64

In [16]: s[[4, 3, 1]]
Out[16]: 
e    1.212112
d   -1.135632
b   -0.282863
dtype: float64

In [17]: np.exp(s)
Out[17]: 
a    1.598575
b    0.753623
c    0.221118
d    0.321219
e    3.360575
dtype: float64

---->   Series.median

--------------------------------------
ID: 5323 --> 1
In [20]: s.to_numpy()
Out[20]: array([ 0.4691, -0.2829, -1.5091, -1.1356,  1.2121])

---->   Series.to_numpy

--------------------------------------
ID: 5324 --> 1
In [26]: s["f"]
---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
File ~/work/pandas/pandas/pandas/core/indexes/base.py:3653, in Index.get_loc(self, key)
   3652 try:
-> 3653     return self._engine.get_loc(casted_key)
   3654 except KeyError as err:

File ~/work/pandas/pandas/pandas/_libs/index.pyx:147, in pandas._libs.index.IndexEngine.get_loc()

File ~/work/pandas/pandas/pandas/_libs/index.pyx:176, in pandas._libs.index.IndexEngine.get_loc()

File ~/work/pandas/pandas/pandas/_libs/hashtable_class_helper.pxi:7080, in pandas._libs.hashtable.PyObjectHashTable.get_item()

File ~/work/pandas/pandas/pandas/_libs/hashtable_class_helper.pxi:7088, in pandas._libs.hashtable.PyObjectHashTable.get_item()

KeyError: 'f'

The above exception was the direct cause of the following exception:

KeyError                                  Traceback (most recent call last)
Cell In[26], line 1
----> 1 s["f"]

File ~/work/pandas/pandas/pandas/core/series.py:1007, in Series.__getitem__(self, key)
   1004     return self._values[key]
   1006 elif key_is_scalar:
-> 1007     return self._get_value(key)
   1009 if is_hashable(key):
   1010     # Otherwise index.get_value will raise InvalidIndexError
   1011     try:
   1012         # For labels that don't resolve as scalars like tuples and frozensets

File ~/work/pandas/pandas/pandas/core/series.py:1116, in Series._get_value(self, label, takeable)
   1113     return self._values[label]
   1115 # Similar to Index.get_value, but we do not fall back to positional
-> 1116 loc = self.index.get_loc(label)
   1118 if is_integer(loc):
   1119     return self._values[loc]

File ~/work/pandas/pandas/pandas/core/indexes/base.py:3655, in Index.get_loc(self, key)
   3653     return self._engine.get_loc(casted_key)
   3654 except KeyError as err:
-> 3655     raise KeyError(key) from err
   3656 except TypeError:
   3657     # If we have a listlike key, _check_indexing_error will raise
   3658     #  InvalidIndexError. Otherwise we fall through and re-raise
   3659     #  the TypeError.
   3660     self._check_indexing_error(key)

KeyError: 'f'

---->   Index.get_loc

--------------------------------------
ID: 5325 --> 1
In [27]: s.get("f")

In [28]: s.get("f", np.nan)
Out[28]: nan

---->   Series.get

--------------------------------------
ID: 5341 --> 1
In [76]: del df["two"]

In [77]: three = df.pop("three")

In [78]: df
Out[78]: 
   one   flag
a  1.0  False
b  2.0  False
c  3.0   True
d  NaN  False

---->   DataFrame.pop

--------------------------------------
ID: 5342 --> 1
In [83]: df.insert(1, "bar", df["one"])

In [84]: df
Out[84]: 
   one  bar   flag  foo  one_trunc
a  1.0  1.0  False  bar        1.0
b  2.0  2.0  False  bar        2.0
c  3.0  3.0   True  bar        NaN
d  NaN  NaN  False  bar        NaN

---->   DataFrame.insert

--------------------------------------
ID: 5346 --> 1
In [90]: dfa = pd.DataFrame({"A": [1, 2, 3], "B": [4, 5, 6]})

In [91]: dfa.assign(C=lambda x: x["A"] + x["B"], D=lambda x: x["A"] + x["C"])
Out[91]: 
   A  B  C   D
0  1  4  5   6
1  2  5  7   9
2  3  6  9  12

---->   DataFrame.assign

--------------------------------------
ID: 5362 --> 1
In [6]: df = pd.DataFrame({"value": np.random.randint(0, 100, 20)})

In [7]: labels = ["{0} - {1}".format(i, i + 9) for i in range(0, 100, 10)]

In [8]: df["group"] = pd.cut(df.value, range(0, 105, 10), right=False, labels=labels)

In [9]: df.head(10)
Out[9]: 
   value    group
0     65  60 - 69
1     49  40 - 49
2     56  50 - 59
3     43  40 - 49
4     43  40 - 49
5     91  90 - 99
6     32  30 - 39
7     87  80 - 89
8     36  30 - 39
9      8    0 - 9

---->   DataFrame.head

--------------------------------------
ID: 5366 --> 1
In [21]: df = pd.DataFrame({"A": list("abca"), "B": list("bccd")})

In [22]: df_cat = df.astype("category")

In [23]: df_cat.dtypes
Out[23]: 
A    category
B    category
dtype: object

---->   DataFrame.astype

--------------------------------------
ID: 5368 --> 1
In [26]: from pandas.api.types import CategoricalDtype

In [27]: s = pd.Series(["a", "b", "c", "a"])

In [28]: cat_type = CategoricalDtype(categories=["b", "c", "d"], ordered=True)

In [29]: s_cat = s.astype(cat_type)

In [30]: s_cat
Out[30]: 
0    NaN
1      b
2      c
3    NaN
dtype: category
Categories (3, object): ['b' < 'c' < 'd']

---->   Series.astype

--------------------------------------
ID: 5369 --> 1
In [31]: from pandas.api.types import CategoricalDtype

In [32]: df = pd.DataFrame({"A": list("abca"), "B": list("bccd")})

In [33]: cat_type = CategoricalDtype(categories=list("abcd"), ordered=True)

In [34]: df_cat = df.astype(cat_type)

In [35]: df_cat["A"]
Out[35]: 
0    a
1    b
2    c
3    a
Name: A, dtype: category
Categories (4, object): ['a' < 'b' < 'c' < 'd']

In [36]: df_cat["B"]
Out[36]: 
0    b
1    c
2    c
3    d
Name: B, dtype: category
Categories (4, object): ['a' < 'b' < 'c' < 'd']

---->   DataFrame.astype

--------------------------------------
ID: 5371 --> 2
In [39]: s = pd.Series(["a", "b", "c", "a"])

In [40]: s
Out[40]: 
0    a
1    b
2    c
3    a
dtype: object

In [41]: s2 = s.astype("category")

In [42]: s2
Out[42]: 
0    a
1    b
2    c
3    a
dtype: category
Categories (3, object): ['a', 'b', 'c']

In [43]: s2.astype(str)
Out[43]: 
0    a
1    b
2    c
3    a
dtype: object

In [44]: np.asarray(s2)
Out[44]: array(['a', 'b', 'c', 'a'], dtype=object)

---->   Series.astype; Series.astype

--------------------------------------
ID: 5374 --> 1
In [53]: cat = pd.Categorical(["a", "c", "c", np.nan], categories=["b", "a", "c"])

In [54]: df = pd.DataFrame({"cat": cat, "s": ["a", "c", "c", np.nan]})

In [55]: df.describe()
Out[55]: 
       cat  s
count    3  3
unique   2  2
top      c  c
freq     2  2

In [56]: df["cat"].describe()
Out[56]: 
count     3
unique    2
top       c
freq      2
Name: cat, dtype: object

---->   DataFrame.describe

--------------------------------------
ID: 5377 --> 1
In [63]: s = pd.Series(list("babc")).astype(CategoricalDtype(list("abcd")))

In [64]: s
Out[64]: 
0    b
1    a
2    b
3    c
dtype: category
Categories (4, object): ['a', 'b', 'c', 'd']

# categories
In [65]: s.cat.categories
Out[65]: Index(['a', 'b', 'c', 'd'], dtype='object')

# uniques
In [66]: s.unique()
Out[66]: 
['b', 'a', 'c']
Categories (4, object): ['a', 'b', 'c', 'd']

---->   Series.unique

--------------------------------------
ID: 5385 --> 2
In [88]: s = pd.Series(pd.Categorical(["a", "b", "c", "a"], ordered=False))

In [89]: s = s.sort_values()

In [90]: s = pd.Series(["a", "b", "c", "a"]).astype(CategoricalDtype(ordered=True))

In [91]: s = s.sort_values()

In [92]: s
Out[92]: 
0    a
3    a
1    b
2    c
dtype: category
Categories (3, object): ['a' < 'b' < 'c']

In [93]: s.min(), s.max()
Out[93]: ('a', 'c')

---->   Series.min; Series.max

--------------------------------------
ID: 5387 --> 2
In [96]: s = pd.Series([1, 2, 3, 1], dtype="category")

In [97]: s = s.cat.set_categories([2, 3, 1], ordered=True)

In [98]: s
Out[98]: 
0    1
1    2
2    3
3    1
dtype: category
Categories (3, int64): [2 < 3 < 1]

In [99]: s = s.sort_values()

In [100]: s
Out[100]: 
1    2
2    3
0    1
3    1
dtype: category
Categories (3, int64): [2 < 3 < 1]

In [101]: s.min(), s.max()
Out[101]: (2, 1)

---->   Series.min; Series.max

--------------------------------------
ID: 5388 --> 2
In [102]: s = pd.Series([1, 2, 3, 1], dtype="category")

In [103]: s = s.cat.reorder_categories([2, 3, 1], ordered=True)

In [104]: s
Out[104]: 
0    1
1    2
2    3
3    1
dtype: category
Categories (3, int64): [2 < 3 < 1]

In [105]: s = s.sort_values()

In [106]: s
Out[106]: 
1    2
2    3
0    1
3    1
dtype: category
Categories (3, int64): [2 < 3 < 1]

In [107]: s.min(), s.max()
Out[107]: (2, 1)

---->   Series.min; Series.max

--------------------------------------
ID: 5396 --> 1
In [130]: s = pd.Series(pd.Categorical(["a", "b", "c", "c"], categories=["c", "a", "b", "d"]))

In [131]: s.value_counts()
Out[131]: 
c    2
a    1
b    1
d    0
Name: count, dtype: int64

---->   Series.value_counts

--------------------------------------
ID: 5397 --> 1
In [132]: columns = pd.Categorical(
   .....:     ["One", "One", "Two"], categories=["One", "Two", "Three"], ordered=True
   .....: )
   .....: 

In [133]: df = pd.DataFrame(
   .....:     data=[[1, 2, 3], [4, 5, 6]],
   .....:     columns=pd.MultiIndex.from_arrays([["A", "B", "B"], columns]),
   .....: )
   .....: 

In [134]: df.groupby(axis=1, level=1).sum()
Out[134]: 
   One  Two  Three
0    3    3      0
1    9    6      0

---->   DataFrame.groupby

--------------------------------------
ID: 5398 --> 2
In [135]: cats = pd.Categorical(
   .....:     ["a", "b", "b", "b", "c", "c", "c"], categories=["a", "b", "c", "d"]
   .....: )
   .....: 

In [136]: df = pd.DataFrame({"cats": cats, "values": [1, 2, 2, 2, 3, 4, 5]})

In [137]: df.groupby("cats").mean()
Out[137]: 
      values
cats        
a        1.0
b        2.0
c        4.0
d        NaN

In [138]: cats2 = pd.Categorical(["a", "a", "b", "b"], categories=["a", "b", "c"])

In [139]: df2 = pd.DataFrame(
   .....:     {
   .....:         "cats": cats2,
   .....:         "B": ["c", "d", "c", "d"],
   .....:         "values": [1, 2, 3, 4],
   .....:     }
   .....: )
   .....: 

In [140]: df2.groupby(["cats", "B"]).mean()
Out[140]: 
        values
cats B        
a    c     1.0
     d     2.0
b    c     3.0
     d     4.0
c    c     NaN
     d     NaN

---->   DataFrame.groupby; DataFrame.groupby

--------------------------------------
ID: 5403 --> 2
In [157]: str_s = pd.Series(list("aabb"))

In [158]: str_cat = str_s.astype("category")

In [159]: str_cat
Out[159]: 
0    a
1    a
2    b
3    b
dtype: category
Categories (2, object): ['a', 'b']

In [160]: str_cat.str.contains("a")
Out[160]: 
0     True
1     True
2    False
3    False
dtype: bool

In [161]: date_s = pd.Series(pd.date_range("1/1/2015", periods=5))

In [162]: date_cat = date_s.astype("category")

In [163]: date_cat
Out[163]: 
0   2015-01-01
1   2015-01-02
2   2015-01-03
3   2015-01-04
4   2015-01-05
dtype: category
Categories (5, datetime64[ns]): [2015-01-01, 2015-01-02, 2015-01-03, 2015-01-04, 2015-01-05]

In [164]: date_cat.dt.day
Out[164]: 
0    1
1    2
2    3
3    4
4    5
dtype: int32

---->   Series.astype; Series.astype

--------------------------------------
ID: 5416 --> 1
In [218]: import io

In [219]: s = pd.Series(pd.Categorical(["a", "b", "b", "a", "a", "d"]))

# rename the categories
In [220]: s = s.cat.rename_categories(["very good", "good", "bad"])

# reorder the categories and add missing categories
In [221]: s = s.cat.set_categories(["very bad", "bad", "medium", "good", "very good"])

In [222]: df = pd.DataFrame({"cats": s, "vals": [1, 2, 3, 4, 5, 6]})

In [223]: csv = io.StringIO()

In [224]: df.to_csv(csv)

In [225]: df2 = pd.read_csv(io.StringIO(csv.getvalue()))

In [226]: df2.dtypes
Out[226]: 
Unnamed: 0     int64
cats          object
vals           int64
dtype: object

In [227]: df2["cats"]
Out[227]: 
0    very good
1         good
2         good
3    very good
4    very good
5          bad
Name: cats, dtype: object

# Redo the category
In [228]: df2["cats"] = df2["cats"].astype("category")

In [229]: df2["cats"] = df2["cats"].cat.set_categories(
   .....:     ["very bad", "bad", "medium", "good", "very good"]
   .....: )
   .....: 

In [230]: df2.dtypes
Out[230]: 
Unnamed: 0       int64
cats          category
vals             int64
dtype: object

In [231]: df2["cats"]
Out[231]: 
0    very good
1         good
2         good
3    very good
4    very good
5          bad
Name: cats, dtype: category
Categories (5, object): ['very bad', 'bad', 'medium', 'good', 'very good']

---->   DataFrame.to_csv

--------------------------------------
ID: 5419 --> 1
In [239]: s = pd.Series(["foo", "bar"] * 1000)

# object dtype
In [240]: s.nbytes
Out[240]: 16000

# category dtype
In [241]: s.astype("category").nbytes
Out[241]: 2016

---->   Series.astype

--------------------------------------
ID: 5420 --> 1
In [242]: s = pd.Series(["foo%04d" % i for i in range(2000)])

# object dtype
In [243]: s.nbytes
Out[243]: 16000

# category dtype
In [244]: s.astype("category").nbytes
Out[244]: 20000

---->   Series.astype

--------------------------------------
ID: 5448 --> 1
In [31]: s2 = pd.Series(["X0", "X1", "X2", "X3"], index=["A", "B", "C", "D"])

In [32]: result = pd.concat([df1, s2.to_frame().T], ignore_index=True)

---->   Series.to_frame

--------------------------------------
ID: 5467 --> 1
In [67]: from pandas.api.types import CategoricalDtype

In [68]: X = pd.Series(np.random.choice(["foo", "bar"], size=(10,)))

In [69]: X = X.astype(CategoricalDtype(categories=["foo", "bar"]))

In [70]: left = pd.DataFrame(
   ....:     {"X": X, "Y": np.random.choice(["one", "two", "three"], size=(10,))}
   ....: )
   ....: 

In [71]: left
Out[71]: 
     X      Y
0  bar    one
1  foo    one
2  foo  three
3  bar  three
4  foo    one
5  bar    one
6  bar  three
7  bar  three
8  bar  three
9  foo  three

In [72]: left.dtypes
Out[72]: 
X    category
Y      object
dtype: object

---->   Series.astype

--------------------------------------
ID: 5470 --> 1
In [79]: left = pd.DataFrame(
   ....:     {"A": ["A0", "A1", "A2"], "B": ["B0", "B1", "B2"]}, index=["K0", "K1", "K2"]
   ....: )
   ....: 

In [80]: right = pd.DataFrame(
   ....:     {"C": ["C0", "C2", "C3"], "D": ["D0", "D2", "D3"]}, index=["K0", "K2", "K3"]
   ....: )
   ....: 

In [81]: result = left.join(right)

---->   DataFrame.join

--------------------------------------
ID: 5471 --> 1
In [82]: result = left.join(right, how="outer")

---->   DataFrame.join

--------------------------------------
ID: 5472 --> 1
In [83]: result = left.join(right, how="inner")

---->   DataFrame.join

--------------------------------------
ID: 5475 --> 1
left.join(right, on=key_or_keys)
pd.merge(
    left, right, left_on=key_or_keys, right_index=True, how="left", sort=False
)

---->   DataFrame.join

--------------------------------------
ID: 5476 --> 1
In [86]: left = pd.DataFrame(
   ....:     {
   ....:         "A": ["A0", "A1", "A2", "A3"],
   ....:         "B": ["B0", "B1", "B2", "B3"],
   ....:         "key": ["K0", "K1", "K0", "K1"],
   ....:     }
   ....: )
   ....: 

In [87]: right = pd.DataFrame({"C": ["C0", "C1"], "D": ["D0", "D1"]}, index=["K0", "K1"])

In [88]: result = left.join(right, on="key")

---->   DataFrame.join

--------------------------------------
ID: 5479 --> 1
In [93]: result = left.join(right, on=["key1", "key2"])

---->   DataFrame.join

--------------------------------------
ID: 5480 --> 1
In [94]: result = left.join(right, on=["key1", "key2"], how="inner")

---->   DataFrame.join

--------------------------------------
ID: 5481 --> 1
In [95]: left = pd.DataFrame(
   ....:     {"A": ["A0", "A1", "A2"], "B": ["B0", "B1", "B2"]},
   ....:     index=pd.Index(["K0", "K1", "K2"], name="key"),
   ....: )
   ....: 

In [96]: index = pd.MultiIndex.from_tuples(
   ....:     [("K0", "Y0"), ("K1", "Y1"), ("K2", "Y2"), ("K2", "Y3")],
   ....:     names=["key", "Y"],
   ....: )
   ....: 

In [97]: right = pd.DataFrame(
   ....:     {"C": ["C0", "C1", "C2", "C3"], "D": ["D0", "D1", "D2", "D3"]},
   ....:     index=index,
   ....: )
   ....: 

In [98]: result = left.join(right, how="inner")

---->   DataFrame.join

--------------------------------------
ID: 5483 --> 1
In [100]: leftindex = pd.MultiIndex.from_product(
   .....:     [list("abc"), list("xy"), [1, 2]], names=["abc", "xy", "num"]
   .....: )
   .....: 

In [101]: left = pd.DataFrame({"v1": range(12)}, index=leftindex)

In [102]: left
Out[102]: 
            v1
abc xy num    
a   x  1     0
       2     1
    y  1     2
       2     3
b   x  1     4
       2     5
    y  1     6
       2     7
c   x  1     8
       2     9
    y  1    10
       2    11

In [103]: rightindex = pd.MultiIndex.from_product(
   .....:     [list("abc"), list("xy")], names=["abc", "xy"]
   .....: )
   .....: 

In [104]: right = pd.DataFrame({"v2": [100 * i for i in range(1, 7)]}, index=rightindex)

In [105]: right
Out[105]: 
         v2
abc xy     
a   x   100
    y   200
b   x   300
    y   400
c   x   500
    y   600

In [106]: left.join(right, on=["abc", "xy"], how="inner")
Out[106]: 
            v1   v2
abc xy num         
a   x  1     0  100
       2     1  100
    y  1     2  200
       2     3  200
b   x  1     4  300
       2     5  300
    y  1     6  400
       2     7  400
c   x  1     8  500
       2     9  500
    y  1    10  600
       2    11  600

---->   DataFrame.join

--------------------------------------
ID: 5488 --> 1
In [121]: left = left.set_index("k")

In [122]: right = right.set_index("k")

In [123]: result = left.join(right, lsuffix="_l", rsuffix="_r")

---->   DataFrame.join

--------------------------------------
ID: 5489 --> 1
In [124]: right2 = pd.DataFrame({"v": [7, 8, 9]}, index=["K1", "K1", "K2"])

In [125]: result = left.join([right, right2])

---->   DataFrame.join

--------------------------------------
ID: 5491 --> 1
In [128]: result = df1.combine_first(df2)

---->   DataFrame.combine_first

--------------------------------------
ID: 5492 --> 1
In [129]: df1.update(df2)

---->   DataFrame.update

--------------------------------------
ID: 5499 --> 1
In [142]: df2 = df.copy()

In [143]: df2.loc[0, "col1"] = "c"

In [144]: df2.loc[2, "col3"] = 4.0

In [145]: df2
Out[145]: 
  col1  col2  col3
0    c   1.0   1.0
1    a   2.0   2.0
2    b   3.0   4.0
3    b   NaN   4.0
4    a   5.0   5.0

---->   DataFrame.copy

--------------------------------------
ID: 5514 --> 2
In [23]: df.sum()
Out[23]: 
A      3
B      5
C    aab
dtype: object

In [24]: df.groupby("B").A.sum()
Out[24]: 
B
1    3
3    0
Name: A, dtype: Int64

---->   DataFrame.sum; DataFrame.groupby

--------------------------------------
ID: 5536 --> 1
In [31]: s2 = pd.Series(["X0", "X1", "X2", "X3"], index=["A", "B", "C", "D"])

In [32]: result = pd.concat([df1, s2.to_frame().T], ignore_index=True)

---->   Series.to_frame

--------------------------------------
ID: 5555 --> 1
In [67]: from pandas.api.types import CategoricalDtype

In [68]: X = pd.Series(np.random.choice(["foo", "bar"], size=(10,)))

In [69]: X = X.astype(CategoricalDtype(categories=["foo", "bar"]))

In [70]: left = pd.DataFrame(
   ....:     {"X": X, "Y": np.random.choice(["one", "two", "three"], size=(10,))}
   ....: )
   ....: 

In [71]: left
Out[71]: 
     X      Y
0  bar    one
1  foo    one
2  foo  three
3  bar  three
4  foo    one
5  bar    one
6  bar  three
7  bar  three
8  bar  three
9  foo  three

In [72]: left.dtypes
Out[72]: 
X    category
Y      object
dtype: object

---->   Series.astype

--------------------------------------
ID: 5558 --> 1
In [79]: left = pd.DataFrame(
   ....:     {"A": ["A0", "A1", "A2"], "B": ["B0", "B1", "B2"]}, index=["K0", "K1", "K2"]
   ....: )
   ....: 

In [80]: right = pd.DataFrame(
   ....:     {"C": ["C0", "C2", "C3"], "D": ["D0", "D2", "D3"]}, index=["K0", "K2", "K3"]
   ....: )
   ....: 

In [81]: result = left.join(right)

---->   DataFrame.join

--------------------------------------
ID: 5559 --> 1
In [82]: result = left.join(right, how="outer")

---->   DataFrame.join

--------------------------------------
ID: 5560 --> 1
In [83]: result = left.join(right, how="inner")

---->   DataFrame.join

--------------------------------------
ID: 5563 --> 1
left.join(right, on=key_or_keys)
pd.merge(
    left, right, left_on=key_or_keys, right_index=True, how="left", sort=False
)

---->   DataFrame.join

--------------------------------------
ID: 5564 --> 1
In [86]: left = pd.DataFrame(
   ....:     {
   ....:         "A": ["A0", "A1", "A2", "A3"],
   ....:         "B": ["B0", "B1", "B2", "B3"],
   ....:         "key": ["K0", "K1", "K0", "K1"],
   ....:     }
   ....: )
   ....: 

In [87]: right = pd.DataFrame({"C": ["C0", "C1"], "D": ["D0", "D1"]}, index=["K0", "K1"])

In [88]: result = left.join(right, on="key")

---->   DataFrame.join

--------------------------------------
ID: 5567 --> 1
In [93]: result = left.join(right, on=["key1", "key2"])

---->   DataFrame.join

--------------------------------------
ID: 5568 --> 1
In [94]: result = left.join(right, on=["key1", "key2"], how="inner")

---->   DataFrame.join

--------------------------------------
ID: 5569 --> 1
In [95]: left = pd.DataFrame(
   ....:     {"A": ["A0", "A1", "A2"], "B": ["B0", "B1", "B2"]},
   ....:     index=pd.Index(["K0", "K1", "K2"], name="key"),
   ....: )
   ....: 

In [96]: index = pd.MultiIndex.from_tuples(
   ....:     [("K0", "Y0"), ("K1", "Y1"), ("K2", "Y2"), ("K2", "Y3")],
   ....:     names=["key", "Y"],
   ....: )
   ....: 

In [97]: right = pd.DataFrame(
   ....:     {"C": ["C0", "C1", "C2", "C3"], "D": ["D0", "D1", "D2", "D3"]},
   ....:     index=index,
   ....: )
   ....: 

In [98]: result = left.join(right, how="inner")

---->   DataFrame.join

--------------------------------------
ID: 5571 --> 1
In [100]: leftindex = pd.MultiIndex.from_product(
   .....:     [list("abc"), list("xy"), [1, 2]], names=["abc", "xy", "num"]
   .....: )
   .....: 

In [101]: left = pd.DataFrame({"v1": range(12)}, index=leftindex)

In [102]: left
Out[102]: 
            v1
abc xy num    
a   x  1     0
       2     1
    y  1     2
       2     3
b   x  1     4
       2     5
    y  1     6
       2     7
c   x  1     8
       2     9
    y  1    10
       2    11

In [103]: rightindex = pd.MultiIndex.from_product(
   .....:     [list("abc"), list("xy")], names=["abc", "xy"]
   .....: )
   .....: 

In [104]: right = pd.DataFrame({"v2": [100 * i for i in range(1, 7)]}, index=rightindex)

In [105]: right
Out[105]: 
         v2
abc xy     
a   x   100
    y   200
b   x   300
    y   400
c   x   500
    y   600

In [106]: left.join(right, on=["abc", "xy"], how="inner")
Out[106]: 
            v1   v2
abc xy num         
a   x  1     0  100
       2     1  100
    y  1     2  200
       2     3  200
b   x  1     4  300
       2     5  300
    y  1     6  400
       2     7  400
c   x  1     8  500
       2     9  500
    y  1    10  600
       2    11  600

---->   DataFrame.join

--------------------------------------
ID: 5576 --> 1
In [121]: left = left.set_index("k")

In [122]: right = right.set_index("k")

In [123]: result = left.join(right, lsuffix="_l", rsuffix="_r")

---->   DataFrame.join

--------------------------------------
ID: 5577 --> 1
In [124]: right2 = pd.DataFrame({"v": [7, 8, 9]}, index=["K1", "K1", "K2"])

In [125]: result = left.join([right, right2])

---->   DataFrame.join

--------------------------------------
ID: 5579 --> 1
In [128]: result = df1.combine_first(df2)

---->   DataFrame.combine_first

--------------------------------------
ID: 5580 --> 1
In [129]: df1.update(df2)

---->   DataFrame.update

--------------------------------------
ID: 5587 --> 1
In [142]: df2 = df.copy()

In [143]: df2.loc[0, "col1"] = "c"

In [144]: df2.loc[2, "col3"] = 4.0

In [145]: df2
Out[145]: 
  col1  col2  col3
0    c   1.0   1.0
1    a   2.0   2.0
2    b   3.0   4.0
3    b   NaN   4.0
4    a   5.0   5.0

---->   DataFrame.copy

--------------------------------------
ID: 5776 --> 1
In [8]: ages.max()
Out[8]: 58

---->   Series.max

--------------------------------------
ID: 5777 --> 1
In [9]: df.describe()
Out[9]: 
             Age
count   3.000000
mean   38.333333
std    18.230012
min    22.000000
25%    28.500000
50%    35.000000
75%    46.500000
max    58.000000

---->   DataFrame.describe

--------------------------------------
ID: 5783 --> 1
In [9]: df = pd.DataFrame(
   ...:     {
   ...:         "v1": [1, 3, 5, 7, 8, 3, 5, np.nan, 4, 5, 7, 9],
   ...:         "v2": [11, 33, 55, 77, 88, 33, 55, np.nan, 44, 55, 77, 99],
   ...:         "by1": ["red", "blue", 1, 2, np.nan, "big", 1, 2, "red", 1, np.nan, 12],
   ...:         "by2": [
   ...:             "wet",
   ...:             "dry",
   ...:             99,
   ...:             95,
   ...:             np.nan,
   ...:             "damp",
   ...:             95,
   ...:             99,
   ...:             "red",
   ...:             99,
   ...:             np.nan,
   ...:             np.nan,
   ...:         ],
   ...:     }
   ...: )
   ...: 

In [10]: g = df.groupby(["by1", "by2"])

In [11]: g[["v1", "v2"]].mean()
Out[11]: 
            v1    v2
by1  by2            
1    95    5.0  55.0
     99    5.0  55.0
2    95    7.0  77.0
     99    NaN   NaN
big  damp  3.0  33.0
blue dry   3.0  33.0
red  red   4.0  44.0
     wet   1.0  11.0

---->   DataFrame.groupby

--------------------------------------
ID: 5785 --> 1
In [12]: s = pd.Series(np.arange(5), dtype=np.float32)

In [13]: s.isin([2, 4])
Out[13]: 
0    False
1    False
2     True
3    False
4     True
dtype: bool

---->   Series.isin

--------------------------------------
ID: 5794 --> 1
In [25]: df = pd.DataFrame(
   ....:     {
   ....:         "x": np.random.uniform(1.0, 168.0, 120),
   ....:         "y": np.random.uniform(7.0, 334.0, 120),
   ....:         "z": np.random.uniform(1.7, 20.7, 120),
   ....:         "month": [5, 6, 7, 8] * 30,
   ....:         "week": np.random.randint(1, 4, 120),
   ....:     }
   ....: )
   ....: 

In [26]: grouped = df.groupby(["month", "week"])

In [27]: grouped["x"].agg([np.mean, np.std])
Out[27]: 
                  mean        std
month week                       
5     1      63.653367  40.601965
      2      78.126605  53.342400
      3      92.091886  57.630110
6     1      81.747070  54.339218
      2      70.971205  54.687287
      3     100.968344  54.010081
7     1      61.576332  38.844274
      2      61.733510  48.209013
      3      71.688795  37.595638
8     1      62.741922  34.618153
      2      91.774627  49.790202
      3      73.936856  60.773900

---->   DataFrame.groupby

--------------------------------------
ID: 5804 --> 1
In [38]: df = pd.DataFrame(
   ....:     {
   ....:         "Animal": [
   ....:             "Animal1",
   ....:             "Animal2",
   ....:             "Animal3",
   ....:             "Animal2",
   ....:             "Animal1",
   ....:             "Animal2",
   ....:             "Animal3",
   ....:         ],
   ....:         "FeedType": ["A", "B", "A", "A", "B", "B", "A"],
   ....:         "Amount": [10, 7, 4, 2, 5, 6, 2],
   ....:     }
   ....: )
   ....: 

In [39]: df.pivot_table(values="Amount", index="Animal", columns="FeedType", aggfunc="sum")
Out[39]: 
FeedType     A     B
Animal              
Animal1   10.0   5.0
Animal2    2.0  13.0
Animal3    6.0   NaN

---->   DataFrame.pivot_table

--------------------------------------
ID: 5805 --> 1
In [40]: df.groupby(["Animal", "FeedType"])["Amount"].sum()
Out[40]: 
Animal   FeedType
Animal1  A           10
         B            5
Animal2  A            2
         B           13
Animal3  A            6
Name: Amount, dtype: int64

---->   DataFrame.groupby

--------------------------------------
ID: 5860 --> 1
In [9]: idx = pd.date_range("2018-01-01", periods=5, freq="H")

In [10]: ts = pd.Series(range(len(idx)), index=idx)

In [11]: ts
Out[11]: 
2018-01-01 00:00:00    0
2018-01-01 01:00:00    1
2018-01-01 02:00:00    2
2018-01-01 03:00:00    3
2018-01-01 04:00:00    4
Freq: H, dtype: int64

In [12]: ts.resample("2H").mean()
Out[12]: 
2018-01-01 00:00:00    0.5
2018-01-01 02:00:00    2.5
2018-01-01 04:00:00    4.0
Freq: 2H, dtype: float64

---->   Series.resample

--------------------------------------
ID: 5905 --> 1
In [137]: rng2 = pd.date_range("2011-01-01", "2012-01-01", freq="W")

In [138]: ts2 = pd.Series(np.random.randn(len(rng2)), index=rng2)

In [139]: ts2.truncate(before="2011-11", after="2011-12")
Out[139]: 
2011-11-06    0.437823
2011-11-13   -0.293083
2011-11-20   -0.059881
2011-11-27    1.252450
Freq: W-SUN, dtype: float64

In [140]: ts2["2011-11":"2011-12"]
Out[140]: 
2011-11-06    0.437823
2011-11-13   -0.293083
2011-11-20   -0.059881
2011-11-27    1.252450
2011-12-04    0.046611
2011-12-11    0.059478
2011-12-18   -0.286539
2011-12-25    0.841669
Freq: W-SUN, dtype: float64

---->   Series.truncate

--------------------------------------
ID: 5907 --> 1
In [142]: idx = pd.date_range(start="2019-12-29", freq="D", periods=4)

In [143]: idx.isocalendar()
Out[143]: 
            year  week  day
2019-12-29  2019    52    7
2019-12-30  2020     1    1
2019-12-31  2020     1    2
2020-01-01  2020     1    3

In [144]: idx.to_series().dt.isocalendar()
Out[144]: 
            year  week  day
2019-12-29  2019    52    7
2019-12-30  2020     1    1
2019-12-31  2020     1    2
2020-01-01  2020     1    3

---->   Index.to_series

--------------------------------------
ID: 5938 --> 1
In [279]: ts = pd.Series(range(len(rng)), index=rng)

In [280]: ts = ts[:5]

In [281]: ts.shift(1)
Out[281]: 
2012-01-01    NaN
2012-01-02    0.0
2012-01-03    1.0
Freq: D, dtype: float64

---->   Series.shift

--------------------------------------
ID: 5939 --> 1
In [282]: ts.shift(5, freq="D")
Out[282]: 
2012-01-06    0
2012-01-07    1
2012-01-08    2
Freq: D, dtype: int64

In [283]: ts.shift(5, freq=pd.offsets.BDay())
Out[283]: 
2012-01-06    0
2012-01-09    1
2012-01-10    2
dtype: int64

In [284]: ts.shift(5, freq="BM")
Out[284]: 
2012-05-31    0
2012-05-31    1
2012-05-31    2
dtype: int64

---->   Series.shift

--------------------------------------
ID: 5940 --> 1
In [285]: dr = pd.date_range("1/1/2010", periods=3, freq=3 * pd.offsets.BDay())

In [286]: ts = pd.Series(np.random.randn(3), index=dr)

In [287]: ts
Out[287]: 
2010-01-01    1.494522
2010-01-06   -0.778425
2010-01-11   -0.253355
Freq: 3B, dtype: float64

In [288]: ts.asfreq(pd.offsets.BDay())
Out[288]: 
2010-01-01    1.494522
2010-01-04         NaN
2010-01-05         NaN
2010-01-06   -0.778425
2010-01-07         NaN
2010-01-08         NaN
2010-01-11   -0.253355
Freq: B, dtype: float64

---->   Series.asfreq

--------------------------------------
ID: 5941 --> 1
In [289]: ts.asfreq(pd.offsets.BDay(), method="pad")
Out[289]: 
2010-01-01    1.494522
2010-01-04    1.494522
2010-01-05    1.494522
2010-01-06   -0.778425
2010-01-07   -0.778425
2010-01-08   -0.778425
2010-01-11   -0.253355
Freq: B, dtype: float64

---->   Series.asfreq

--------------------------------------
ID: 5942 --> 1
In [290]: rng = pd.date_range("1/1/2012", periods=100, freq="S")

In [291]: ts = pd.Series(np.random.randint(0, 500, len(rng)), index=rng)

In [292]: ts.resample("5Min").sum()
Out[292]: 
2012-01-01    25103
Freq: 5T, dtype: int64

---->   Series.resample

--------------------------------------
ID: 5943 --> 1
In [293]: ts.resample("5Min").mean()
Out[293]: 
2012-01-01    251.03
Freq: 5T, dtype: float64

In [294]: ts.resample("5Min").ohlc()
Out[294]: 
            open  high  low  close
2012-01-01   308   460    9    205

In [295]: ts.resample("5Min").max()
Out[295]: 
2012-01-01    460
Freq: 5T, dtype: int64

---->   Series.resample

--------------------------------------
ID: 5944 --> 1
In [296]: ts.resample("5Min", closed="right").mean()
Out[296]: 
2011-12-31 23:55:00    308.000000
2012-01-01 00:00:00    250.454545
Freq: 5T, dtype: float64

In [297]: ts.resample("5Min", closed="left").mean()
Out[297]: 
2012-01-01    251.03
Freq: 5T, dtype: float64

---->   Series.resample

--------------------------------------
ID: 5945 --> 1
In [298]: ts.resample("5Min").mean()  # by default label='left'
Out[298]: 
2012-01-01    251.03
Freq: 5T, dtype: float64

In [299]: ts.resample("5Min", label="left").mean()
Out[299]: 
2012-01-01    251.03
Freq: 5T, dtype: float64

---->   Series.resample

--------------------------------------
ID: 5946 --> 1
In [300]: s = pd.date_range("2000-01-01", "2000-01-05").to_series()

In [301]: s.iloc[2] = pd.NaT

In [302]: s.dt.day_name()
Out[302]: 
2000-01-01     Saturday
2000-01-02       Sunday
2000-01-03          NaN
2000-01-04      Tuesday
2000-01-05    Wednesday
Freq: D, dtype: object

# default: label='left', closed='left'
In [303]: s.resample("B").last().dt.day_name()
Out[303]: 
1999-12-31       Sunday
2000-01-03          NaN
2000-01-04      Tuesday
2000-01-05    Wednesday
Freq: B, dtype: object

---->   Series.resample

--------------------------------------
ID: 5947 --> 1
In [304]: s.resample("B", label="right", closed="right").last().dt.day_name()
Out[304]: 
2000-01-03       Sunday
2000-01-04      Tuesday
2000-01-05    Wednesday
Freq: B, dtype: object

---->   Series.resample

--------------------------------------
ID: 5950 --> 1
In [310]: ts.resample("3T").sum()
Out[310]: 
2014-01-01 00:00:00     0
2014-01-01 00:03:00     0
2014-01-01 00:06:00     0
2014-01-01 00:09:00     0
2014-01-01 00:12:00     0
                       ..
2014-04-09 23:48:00     0
2014-04-09 23:51:00     0
2014-04-09 23:54:00     0
2014-04-09 23:57:00     0
2014-04-10 00:00:00    99
Freq: 3T, Length: 47521, dtype: int64

---->   Series.resample

--------------------------------------
ID: 5951 --> 1
In [311]: from functools import partial

In [312]: from pandas.tseries.frequencies import to_offset

In [313]: def round(t, freq):
   .....:     freq = to_offset(freq)
   .....:     return pd.Timestamp((t.value // freq.delta.value) * freq.delta.value)
   .....: 

In [314]: ts.groupby(partial(round, freq="3T")).sum()
Out[314]: 
2014-01-01     0
2014-01-02     1
2014-01-03     2
2014-01-04     3
2014-01-05     4
              ..
2014-04-06    95
2014-04-07    96
2014-04-08    97
2014-04-09    98
2014-04-10    99
Length: 100, dtype: int64

---->   Series.groupby

--------------------------------------
ID: 5952 --> 1
In [315]: df = pd.DataFrame(
   .....:     np.random.randn(1000, 3),
   .....:     index=pd.date_range("1/1/2012", freq="S", periods=1000),
   .....:     columns=["A", "B", "C"],
   .....: )
   .....: 

In [316]: r = df.resample("3T")

In [317]: r.mean()
Out[317]: 
                            A         B         C
2012-01-01 00:00:00 -0.033823 -0.121514 -0.081447
2012-01-01 00:03:00  0.056909  0.146731 -0.024320
2012-01-01 00:06:00 -0.058837  0.047046 -0.052021
2012-01-01 00:09:00  0.063123 -0.026158 -0.066533
2012-01-01 00:12:00  0.186340 -0.003144  0.074752
2012-01-01 00:15:00 -0.085954 -0.016287 -0.050046

---->   DataFrame.resample

--------------------------------------
ID: 5959 --> 1
In [325]: df = pd.DataFrame(
   .....:     {"date": pd.date_range("2015-01-01", freq="W", periods=5), "a": np.arange(5)},
   .....:     index=pd.MultiIndex.from_arrays(
   .....:         [[1, 2, 3, 4, 5], pd.date_range("2015-01-01", freq="W", periods=5)],
   .....:         names=["v", "d"],
   .....:     ),
   .....: )
   .....: 

In [326]: df
Out[326]: 
                   date  a
v d                       
1 2015-01-04 2015-01-04  0
2 2015-01-11 2015-01-11  1
3 2015-01-18 2015-01-18  2
4 2015-01-25 2015-01-25  3
5 2015-02-01 2015-02-01  4

In [327]: df.resample("M", on="date")[["a"]].sum()
Out[327]: 
            a
date         
2015-01-31  6
2015-02-28  4

---->   DataFrame.resample

--------------------------------------
ID: 5960 --> 1
In [328]: df.resample("M", level="d")[["a"]].sum()
Out[328]: 
            a
d            
2015-01-31  6
2015-02-28  4

---->   DataFrame.resample

--------------------------------------
ID: 5963 --> 1
In [337]: ts.resample("17min", origin="start_day").sum()
Out[337]: 
2000-10-01 23:14:00     0
2000-10-01 23:31:00     9
2000-10-01 23:48:00    21
2000-10-02 00:05:00    54
2000-10-02 00:22:00    24
Freq: 17T, dtype: int64

In [338]: ts[middle:end].resample("17min", origin="start_day").sum()
Out[338]: 
2000-10-02 00:00:00    33
2000-10-02 00:17:00    45
Freq: 17T, dtype: int64

---->   Series.resample

--------------------------------------
ID: 5964 --> 1
In [339]: ts.resample("17min", origin="epoch").sum()
Out[339]: 
2000-10-01 23:18:00     0
2000-10-01 23:35:00    18
2000-10-01 23:52:00    27
2000-10-02 00:09:00    39
2000-10-02 00:26:00    24
Freq: 17T, dtype: int64

In [340]: ts[middle:end].resample("17min", origin="epoch").sum()
Out[340]: 
2000-10-01 23:52:00    15
2000-10-02 00:09:00    39
2000-10-02 00:26:00    24
Freq: 17T, dtype: int64

---->   Series.resample

--------------------------------------
ID: 5965 --> 1
In [341]: ts.resample("17min", origin="2001-01-01").sum()
Out[341]: 
2000-10-01 23:30:00     9
2000-10-01 23:47:00    21
2000-10-02 00:04:00    54
2000-10-02 00:21:00    24
Freq: 17T, dtype: int64

In [342]: ts[middle:end].resample("17min", origin=pd.Timestamp("2001-01-01")).sum()
Out[342]: 
2000-10-02 00:04:00    54
2000-10-02 00:21:00    24
Freq: 17T, dtype: int64

---->   Series.resample

--------------------------------------
ID: 5966 --> 1
In [343]: ts.resample("17min", origin="start").sum()
Out[343]: 
2000-10-01 23:30:00     9
2000-10-01 23:47:00    21
2000-10-02 00:04:00    54
2000-10-02 00:21:00    24
Freq: 17T, dtype: int64

In [344]: ts.resample("17min", offset="23h30min").sum()
Out[344]: 
2000-10-01 23:30:00     9
2000-10-01 23:47:00    21
2000-10-02 00:04:00    54
2000-10-02 00:21:00    24
Freq: 17T, dtype: int64

---->   Series.resample

--------------------------------------
ID: 5967 --> 1
In [345]: ts.resample('17min', origin='end').sum()
Out[345]: 
2000-10-01 23:35:00     0
2000-10-01 23:52:00    18
2000-10-02 00:09:00    27
2000-10-02 00:26:00    63
Freq: 17T, dtype: int64

---->   Series.resample

--------------------------------------
ID: 5968 --> 1
In [346]: ts.resample('17min', origin='end_day').sum()
Out[346]: 
2000-10-01 23:38:00     3
2000-10-01 23:55:00    15
2000-10-02 00:12:00    45
2000-10-02 00:29:00    45
Freq: 17T, dtype: int64

---->   Series.resample

--------------------------------------
ID: 5988 --> 1
In [400]: p.asfreq("M", how="start")
Out[400]: Period('2011-01', 'M')

In [401]: p.asfreq("M", how="end")
Out[401]: Period('2011-12', 'M')

---->   Period.asfreq

--------------------------------------
ID: 5989 --> 1
In [402]: p.asfreq("M", "s")
Out[402]: Period('2011-01', 'M')

In [403]: p.asfreq("M", "e")
Out[403]: Period('2011-12', 'M')

---->   Period.asfreq

--------------------------------------
ID: 5990 --> 1
In [404]: p = pd.Period("2011-12", freq="M")

In [405]: p.asfreq("A-NOV")
Out[405]: Period('2012', 'A-NOV')

---->   Period.asfreq

--------------------------------------
ID: 5991 --> 1
In [406]: p = pd.Period("2012Q1", freq="Q-DEC")

In [407]: p.asfreq("D", "s")
Out[407]: Period('2012-01-01', 'D')

In [408]: p.asfreq("D", "e")
Out[408]: Period('2012-03-31', 'D')

---->   Period.asfreq

--------------------------------------
ID: 5992 --> 1
In [409]: p = pd.Period("2011Q4", freq="Q-MAR")

In [410]: p.asfreq("D", "s")
Out[410]: Period('2011-01-01', 'D')

In [411]: p.asfreq("D", "e")
Out[411]: Period('2011-03-31', 'D')

---->   Period.asfreq

--------------------------------------
ID: 5993 --> 2
In [412]: rng = pd.date_range("1/1/2012", periods=5, freq="M")

In [413]: ts = pd.Series(np.random.randn(len(rng)), index=rng)

In [414]: ts
Out[414]: 
2012-01-31    1.931253
2012-02-29   -0.184594
2012-03-31    0.249656
2012-04-30   -0.978151
2012-05-31   -0.873389
Freq: M, dtype: float64

In [415]: ps = ts.to_period()

In [416]: ps
Out[416]: 
2012-01    1.931253
2012-02   -0.184594
2012-03    0.249656
2012-04   -0.978151
2012-05   -0.873389
Freq: M, dtype: float64

In [417]: ps.to_timestamp()
Out[417]: 
2012-01-01    1.931253
2012-02-01   -0.184594
2012-03-01    0.249656
2012-04-01   -0.978151
2012-05-01   -0.873389
Freq: MS, dtype: float64

---->   Series.to_period; Series.to_timestamp

--------------------------------------
ID: 5994 --> 1
In [418]: ps.to_timestamp("D", how="s")
Out[418]: 
2012-01-01    1.931253
2012-02-01   -0.184594
2012-03-01    0.249656
2012-04-01   -0.978151
2012-05-01   -0.873389
Freq: MS, dtype: float64

---->   Series.to_timestamp

--------------------------------------
ID: 5995 --> 1
In [419]: prng = pd.period_range("1990Q1", "2000Q4", freq="Q-NOV")

In [420]: ts = pd.Series(np.random.randn(len(prng)), prng)

In [421]: ts.index = (prng.asfreq("M", "e") + 1).asfreq("H", "s") + 9

In [422]: ts.head()
Out[422]: 
1990-03-01 09:00   -0.109291
1990-06-01 09:00   -0.637235
1990-09-01 09:00   -1.735925
1990-12-01 09:00    2.096946
1991-03-01 09:00   -1.039926
Freq: H, dtype: float64

---->   Series.head

--------------------------------------
ID: 6007 --> 1
In [467]: ts_utc = pd.Series(range(3), pd.date_range("20130101", periods=3, tz="UTC"))

In [468]: eastern = ts_utc.tz_convert("US/Eastern")

In [469]: berlin = ts_utc.tz_convert("Europe/Berlin")

In [470]: result = eastern + berlin

In [471]: result
Out[471]: 
2013-01-01 00:00:00+00:00    0
2013-01-02 00:00:00+00:00    2
2013-01-03 00:00:00+00:00    4
Freq: D, dtype: int64

In [472]: result.index
Out[472]: 
DatetimeIndex(['2013-01-01 00:00:00+00:00', '2013-01-02 00:00:00+00:00',
               '2013-01-03 00:00:00+00:00'],
              dtype='datetime64[ns, UTC]', freq='D')

---->   Series.tz_convert

--------------------------------------
ID: 6019 --> 1
# convert to a new time zone
In [495]: s_aware.astype("datetime64[ns, CET]")
Out[495]: 
0   2013-01-01 06:00:00+01:00
1   2013-01-02 06:00:00+01:00
2   2013-01-03 06:00:00+01:00
dtype: datetime64[ns, CET]

---->   Series.astype

--------------------------------------
ID: 6020 --> 2
In [496]: s_naive.to_numpy()
Out[496]: 
array(['2013-01-01T00:00:00.000000000', '2013-01-02T00:00:00.000000000',
       '2013-01-03T00:00:00.000000000'], dtype='datetime64[ns]')

In [497]: s_aware.to_numpy()
Out[497]: 
array([Timestamp('2013-01-01 00:00:00-0500', tz='US/Eastern'),
       Timestamp('2013-01-02 00:00:00-0500', tz='US/Eastern'),
       Timestamp('2013-01-03 00:00:00-0500', tz='US/Eastern')],
      dtype=object)

---->   Series.to_numpy; Series.to_numpy

--------------------------------------
ID: 6021 --> 1
In [498]: pd.Series(s_aware.to_numpy())
Out[498]: 
0   2013-01-01 00:00:00-05:00
1   2013-01-02 00:00:00-05:00
2   2013-01-03 00:00:00-05:00
dtype: datetime64[ns, US/Eastern]

---->   Series.to_numpy

--------------------------------------
ID: 6022 --> 1
In [499]: s_aware.to_numpy(dtype="datetime64[ns]")
Out[499]: 
array(['2013-01-01T05:00:00.000000000', '2013-01-02T05:00:00.000000000',
       '2013-01-03T05:00:00.000000000'], dtype='datetime64[ns]')

---->   Series.to_numpy

--------------------------------------
ID: 6030 --> 1
In [4]: ages = titanic["Age"]

In [5]: ages.head()
Out[5]: 
0    22.0
1    38.0
2    26.0
3    35.0
4    35.0
Name: Age, dtype: float64

---->   Series.head

--------------------------------------
ID: 6057 --> 1
In [4]: ages = titanic["Age"]

In [5]: ages.head()
Out[5]: 
0    22.0
1    38.0
2    26.0
3    35.0
4    35.0
Name: Age, dtype: float64

---->   Series.head

--------------------------------------
ID: 6101 --> 1
In [8]: ages.max()
Out[8]: 58

---->   Series.max

--------------------------------------
ID: 6102 --> 1
In [9]: df.describe()
Out[9]: 
             Age
count   3.000000
mean   38.333333
std    18.230012
min    22.000000
25%    28.500000
50%    35.000000
75%    46.500000
max    58.000000

---->   DataFrame.describe

--------------------------------------
ID: 6131 --> 1
In [8]: ages.max()
Out[8]: 58

---->   Series.max

--------------------------------------
ID: 6132 --> 1
In [9]: df.describe()
Out[9]: 
             Age
count   3.000000
mean   38.333333
std    18.230012
min    22.000000
25%    28.500000
50%    35.000000
75%    46.500000
max    58.000000

---->   DataFrame.describe

--------------------------------------
ID: 6177 --> 1
class Series:

    def head(self, n=5):
        """
        Return the first elements of the Series.

        This function is mainly useful to preview the values of the
        Series without displaying all of it.

        Parameters
        ----------
        n : int
            Number of values to return.

        Return
        ------
        pandas.Series
            Subset of the original series with the n first values.

        See Also
        --------
        tail : Return the last n elements of the Series.

        Examples
        --------
        >>> s = pd.Series(['Ant', 'Bear', 'Cow', 'Dog', 'Falcon',
        ...                'Lion', 'Monkey', 'Rabbit', 'Zebra'])
        >>> s.head()
        0   Ant
        1   Bear
        2   Cow
        3   Dog
        4   Falcon
        dtype: object

        With the ``n`` parameter, we can change the number of returned rows:

        >>> s.head(n=3)
        0   Ant
        1   Bear
        2   Cow
        dtype: object
        """
        return self.iloc[:n]

---->   Series.head

--------------------------------------
ID: 6178 --> 1
class Series:

    def mean(self):
        """
        Compute the mean of the input.

        Examples
        --------
        >>> s = pd.Series([1, 2, 3])
        >>> s.mean()
        2
        """
        pass


    def fillna(self, value):
        """
        Replace missing values by ``value``.

        Examples
        --------
        >>> s = pd.Series([1, np.nan, 3])
        >>> s.fillna(0)
        [1, 0, 3]
        """
        pass

    def groupby_mean(self):
        """
        Group by index and return mean.

        Examples
        --------
        >>> s = pd.Series([380., 370., 24., 26],
        ...               name='max_speed',
        ...               index=['falcon', 'falcon', 'parrot', 'parrot'])
        >>> s.groupby_mean()
        index
        falcon    375.0
        parrot     25.0
        Name: max_speed, dtype: float64
        """
        pass

    def contains(self, pattern, case_sensitive=True, na=numpy.nan):
        """
        Return whether each value contains ``pattern``.

        In this case, we are illustrating how to use sections, even
        if the example is simple enough and does not require them.

        Examples
        --------
        >>> s = pd.Series('Antelope', 'Lion', 'Zebra', np.nan)
        >>> s.contains(pattern='a')
        0    False
        1    False
        2     True
        3      NaN
        dtype: bool

        **Case sensitivity**

        With ``case_sensitive`` set to ``False`` we can match ``a`` with both
        ``a`` and ``A``:

        >>> s.contains(pattern='a', case_sensitive=False)
        0     True
        1    False
        2     True
        3      NaN
        dtype: bool

        **Missing values**

        We can fill missing values in the output using the ``na`` parameter:

        >>> s.contains(pattern='a', na=False)
        0    False
        1    False
        2     True
        3    False
        dtype: bool
        """
        pass

---->   Series.mean

--------------------------------------
ID: 6183 --> 1
>>> s.plot()


---->   Series.plot

--------------------------------------
ID: 6184 --> 1
>>> s.plot()  


---->   Series.plot

--------------------------------------
ID: 6185 --> 1
class Series:
    def plot(self):
        """
        Generate a plot with the ``Series`` data.

        Examples
        --------

        .. plot::
            :context: close-figs

            >>> s = pd.Series([1, 2, 3])
            >>> s.plot()
        """
        pass

---->   Series.plot

--------------------------------------
ID: 6199 --> 1
import pandas as pd
assert pd.Series([1, 1]).sum() == 2

---->   pandas.Series

--------------------------------------
ID: 6214 --> 1
In [3]: df = pd.DataFrame({"x": [1, 3, 5], "y": [2, 4, 6]})

In [4]: df
Out[4]: 
   x  y
0  1  2
1  3  4
2  5  6

---->   pandas.DataFrame

--------------------------------------
ID: 6231 --> 1
In [36]: firstlast = pd.DataFrame({"String": ["John Smith", "Jane Cook"]})

In [37]: firstlast["First_Name"] = firstlast["String"].str.split(" ", expand=True)[0]

In [38]: firstlast["Last_Name"] = firstlast["String"].str.rsplit(" ", expand=True)[1]

In [39]: firstlast
Out[39]: 
       String First_Name Last_Name
0  John Smith       John     Smith
1   Jane Cook       Jane      Cook

---->   pandas.DataFrame

--------------------------------------
ID: 6232 --> 1
In [40]: firstlast = pd.DataFrame({"string": ["John Smith", "Jane Cook"]})

In [41]: firstlast["upper"] = firstlast["string"].str.upper()

In [42]: firstlast["lower"] = firstlast["string"].str.lower()

In [43]: firstlast["title"] = firstlast["string"].str.title()

In [44]: firstlast
Out[44]: 
       string       upper       lower       title
0  John Smith  JOHN SMITH  john smith  John Smith
1   Jane Cook   JANE COOK   jane cook   Jane Cook

---->   pandas.DataFrame

--------------------------------------
ID: 6233 --> 1
In [45]: df1 = pd.DataFrame({"key": ["A", "B", "C", "D"], "value": np.random.randn(4)})

In [46]: df1
Out[46]: 
  key     value
0   A  0.469112
1   B -0.282863
2   C -1.509059
3   D -1.135632

In [47]: df2 = pd.DataFrame({"key": ["B", "D", "D", "E"], "value": np.random.randn(4)})

In [48]: df2
Out[48]: 
  key     value
0   B  1.212112
1   D -0.173215
2   D  0.119209
3   E -1.044236

---->   pandas.DataFrame

--------------------------------------
ID: 6235 --> 1
In [57]: df = pd.DataFrame({"AAA": [1] * 8, "BBB": list(range(0, 8))})

In [58]: df
Out[58]: 
   AAA  BBB
0    1    0
1    1    1
2    1    2
3    1    3
4    1    4
5    1    5
6    1    6
7    1    7

In [59]: series = list(range(1, 5))

In [60]: series
Out[60]: [1, 2, 3, 4]

In [61]: df.loc[2:5, "AAA"] = series

In [62]: df
Out[62]: 
   AAA  BBB
0    1    0
1    1    1
2    1    2
3    2    3
4    3    4
5    4    5
6    1    6
7    1    7

---->   pandas.DataFrame

--------------------------------------
ID: 6236 --> 1
In [63]: df = pd.DataFrame(
   ....:     {
   ....:         "class": ["A", "A", "A", "B", "C", "D"],
   ....:         "student_count": [42, 35, 42, 50, 47, 45],
   ....:         "all_pass": ["Yes", "Yes", "Yes", "No", "No", "Yes"],
   ....:     }
   ....: )
   ....: 

In [64]: df.drop_duplicates()
Out[64]: 
  class  student_count all_pass
0     A             42      Yes
1     A             35      Yes
3     B             50       No
4     C             47       No
5     D             45      Yes

In [65]: df.drop_duplicates(["class", "student_count"])
Out[65]: 
  class  student_count all_pass
0     A             42      Yes
1     A             35      Yes
3     B             50       No
4     C             47       No
5     D             45      Yes

---->   pandas.DataFrame

--------------------------------------
ID: 6237 --> 1
In [66]: pd.pivot_table(
   ....:     tips, values="tip", index=["size"], columns=["sex"], aggfunc=np.average
   ....: )
   ....: 
Out[66]: 
sex     Female      Male
size                    
1     1.276667  1.920000
2     2.528448  2.614184
3     3.250000  3.476667
4     4.021111  4.172143
5     5.140000  3.750000
6     4.600000  5.850000

---->   pandas.pivot_table

--------------------------------------
ID: 6238 --> 1
In [67]: df
Out[67]: 
  class  student_count all_pass
0     A             42      Yes
1     A             35      Yes
2     A             42      Yes
3     B             50       No
4     C             47       No
5     D             45      Yes

In [68]: new_row = pd.DataFrame([["E", 51, True]],
   ....:                        columns=["class", "student_count", "all_pass"])
   ....: 

In [69]: pd.concat([df, new_row])
Out[69]: 
  class  student_count all_pass
0     A             42      Yes
1     A             35      Yes
2     A             42      Yes
3     B             50       No
4     C             47       No
5     D             45      Yes
0     E             51     True

---->   pandas.DataFrame

--------------------------------------
ID: 6253 --> 1
In [3]: df = pd.DataFrame({"x": [1, 3, 5], "y": [2, 4, 6]})

In [4]: df
Out[4]: 
   x  y
0  1  2
1  3  4
2  5  6

---->   pandas.DataFrame

--------------------------------------
ID: 6270 --> 1
In [36]: firstlast = pd.DataFrame({"String": ["John Smith", "Jane Cook"]})

In [37]: firstlast["First_Name"] = firstlast["String"].str.split(" ", expand=True)[0]

In [38]: firstlast["Last_Name"] = firstlast["String"].str.rsplit(" ", expand=True)[1]

In [39]: firstlast
Out[39]: 
       String First_Name Last_Name
0  John Smith       John     Smith
1   Jane Cook       Jane      Cook

---->   pandas.DataFrame

--------------------------------------
ID: 6271 --> 1
In [40]: firstlast = pd.DataFrame({"string": ["John Smith", "Jane Cook"]})

In [41]: firstlast["upper"] = firstlast["string"].str.upper()

In [42]: firstlast["lower"] = firstlast["string"].str.lower()

In [43]: firstlast["title"] = firstlast["string"].str.title()

In [44]: firstlast
Out[44]: 
       string       upper       lower       title
0  John Smith  JOHN SMITH  john smith  John Smith
1   Jane Cook   JANE COOK   jane cook   Jane Cook

---->   pandas.DataFrame

--------------------------------------
ID: 6272 --> 1
In [45]: df1 = pd.DataFrame({"key": ["A", "B", "C", "D"], "value": np.random.randn(4)})

In [46]: df1
Out[46]: 
  key     value
0   A  0.469112
1   B -0.282863
2   C -1.509059
3   D -1.135632

In [47]: df2 = pd.DataFrame({"key": ["B", "D", "D", "E"], "value": np.random.randn(4)})

In [48]: df2
Out[48]: 
  key     value
0   B  1.212112
1   D -0.173215
2   D  0.119209
3   E -1.044236

---->   pandas.DataFrame

--------------------------------------
ID: 6274 --> 1
In [57]: df = pd.DataFrame({"AAA": [1] * 8, "BBB": list(range(0, 8))})

In [58]: df
Out[58]: 
   AAA  BBB
0    1    0
1    1    1
2    1    2
3    1    3
4    1    4
5    1    5
6    1    6
7    1    7

In [59]: series = list(range(1, 5))

In [60]: series
Out[60]: [1, 2, 3, 4]

In [61]: df.loc[2:5, "AAA"] = series

In [62]: df
Out[62]: 
   AAA  BBB
0    1    0
1    1    1
2    1    2
3    2    3
4    3    4
5    4    5
6    1    6
7    1    7

---->   pandas.DataFrame

--------------------------------------
ID: 6275 --> 1
In [63]: df = pd.DataFrame(
   ....:     {
   ....:         "class": ["A", "A", "A", "B", "C", "D"],
   ....:         "student_count": [42, 35, 42, 50, 47, 45],
   ....:         "all_pass": ["Yes", "Yes", "Yes", "No", "No", "Yes"],
   ....:     }
   ....: )
   ....: 

In [64]: df.drop_duplicates()
Out[64]: 
  class  student_count all_pass
0     A             42      Yes
1     A             35      Yes
3     B             50       No
4     C             47       No
5     D             45      Yes

In [65]: df.drop_duplicates(["class", "student_count"])
Out[65]: 
  class  student_count all_pass
0     A             42      Yes
1     A             35      Yes
3     B             50       No
4     C             47       No
5     D             45      Yes

---->   pandas.DataFrame

--------------------------------------
ID: 6276 --> 1
In [66]: pd.pivot_table(
   ....:     tips, values="tip", index=["size"], columns=["sex"], aggfunc=np.average
   ....: )
   ....: 
Out[66]: 
sex     Female      Male
size                    
1     1.276667  1.920000
2     2.528448  2.614184
3     3.250000  3.476667
4     4.021111  4.172143
5     5.140000  3.750000
6     4.600000  5.850000

---->   pandas.pivot_table

--------------------------------------
ID: 6277 --> 1
In [67]: df
Out[67]: 
  class  student_count all_pass
0     A             42      Yes
1     A             35      Yes
2     A             42      Yes
3     B             50       No
4     C             47       No
5     D             45      Yes

In [68]: new_row = pd.DataFrame([["E", 51, True]],
   ....:                        columns=["class", "student_count", "all_pass"])
   ....: 

In [69]: pd.concat([df, new_row])
Out[69]: 
  class  student_count all_pass
0     A             42      Yes
1     A             35      Yes
2     A             42      Yes
3     B             50       No
4     C             47       No
5     D             45      Yes
0     E             51     True

---->   pandas.DataFrame

--------------------------------------
ID: 6297 --> 1
import pandas as pd
assert pd.Series([1, 1]).sum() == 2

---->   pandas.Series

--------------------------------------
ID: 6306 --> 1
In [15]: frame = pd.DataFrame(
   ....:     {"col1": ["A", "B", np.NaN, "C", "D"], "col2": ["F", np.NaN, "G", "H", "I"]}
   ....: )
   ....: 

In [16]: frame
Out[16]: 
  col1 col2
0    A    F
1    B  NaN
2  NaN    G
3    C    H
4    D    I

---->   pandas.DataFrame

--------------------------------------
ID: 6317 --> 1
In [24]: df1 = pd.DataFrame({"key": ["A", "B", "C", "D"], "value": np.random.randn(4)})

In [25]: df2 = pd.DataFrame({"key": ["B", "D", "D", "E"], "value": np.random.randn(4)})

---->   pandas.DataFrame

--------------------------------------
ID: 6323 --> 1
In [32]: df1 = pd.DataFrame(
   ....:     {"city": ["Chicago", "San Francisco", "New York City"], "rank": range(1, 4)}
   ....: )
   ....: 

In [33]: df2 = pd.DataFrame(
   ....:     {"city": ["Chicago", "Boston", "Los Angeles"], "rank": [1, 4, 5]}
   ....: )
   ....: 

---->   pandas.DataFrame

--------------------------------------
ID: 6335 --> 1
In [1]: df = pd.DataFrame(np.random.randn(10, 3), columns=list("abc"))

In [2]: df[["a", "c"]]
Out[2]: 
          a         c
0  0.469112 -1.509059
1 -1.135632 -0.173215
2  0.119209 -0.861849
3 -2.104569  1.071804
4  0.721555 -1.039575
5  0.271860  0.567020
6  0.276232 -0.673690
7  0.113648  0.524988
8  0.404705 -1.715002
9 -1.039268 -1.157892

In [3]: df.loc[:, ["a", "c"]]
Out[3]: 
          a         c
0  0.469112 -1.509059
1 -1.135632 -0.173215
2  0.119209 -0.861849
3 -2.104569  1.071804
4  0.721555 -1.039575
5  0.271860  0.567020
6  0.276232 -0.673690
7  0.113648  0.524988
8  0.404705 -1.715002
9 -1.039268 -1.157892

---->   pandas.DataFrame

--------------------------------------
ID: 6336 --> 1
In [4]: named = list("abcdefg")

In [5]: n = 30

In [6]: columns = named + np.arange(len(named), n).tolist()

In [7]: df = pd.DataFrame(np.random.randn(n, n), columns=columns)

In [8]: df.iloc[:, np.r_[:10, 24:30]]
Out[8]: 
           a         b         c  ...        27        28        29
0  -1.344312  0.844885  1.075770  ...  0.813850  0.132003 -0.827317
1  -0.076467 -1.187678  1.130127  ...  0.149748 -0.732339  0.687738
2   0.176444  0.403310 -0.154951  ... -0.493662  0.600178  0.274230
3   0.132885 -0.023688  2.410179  ...  0.109121  1.126203 -0.977349
4   1.474071 -0.064034 -1.282782  ... -0.858447  0.306996 -0.028665
..       ...       ...       ...  ...       ...       ...       ...
25  1.492125 -0.068190  0.681456  ...  0.428572  0.880609  0.487645
26  0.725238  0.624607 -0.141185  ...  1.008500  1.424017  0.717110
27  1.262419  1.950057  0.301038  ...  1.007824  2.826008  1.458383
28 -1.585746 -0.899734  0.921494  ...  0.577223 -1.088417  0.326687
29 -0.986248  0.169729 -1.158091  ... -2.013086 -1.602549  0.333109

[30 rows x 16 columns]

---->   pandas.DataFrame

--------------------------------------
ID: 6338 --> 2
In [9]: df = pd.DataFrame(
   ...:     {
   ...:         "v1": [1, 3, 5, 7, 8, 3, 5, np.nan, 4, 5, 7, 9],
   ...:         "v2": [11, 33, 55, 77, 88, 33, 55, np.nan, 44, 55, 77, 99],
   ...:         "by1": ["red", "blue", 1, 2, np.nan, "big", 1, 2, "red", 1, np.nan, 12],
   ...:         "by2": [
   ...:             "wet",
   ...:             "dry",
   ...:             99,
   ...:             95,
   ...:             np.nan,
   ...:             "damp",
   ...:             95,
   ...:             99,
   ...:             "red",
   ...:             99,
   ...:             np.nan,
   ...:             np.nan,
   ...:         ],
   ...:     }
   ...: )
   ...: 

In [10]: g = df.groupby(["by1", "by2"])

In [11]: g[["v1", "v2"]].mean()
Out[11]: 
            v1    v2
by1  by2            
1    95    5.0  55.0
     99    5.0  55.0
2    95    7.0  77.0
     99    NaN   NaN
big  damp  3.0  33.0
blue dry   3.0  33.0
red  red   4.0  44.0
     wet   1.0  11.0

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 6340 --> 2
In [12]: s = pd.Series(np.arange(5), dtype=np.float32)

In [13]: s.isin([2, 4])
Out[13]: 
0    False
1    False
2     True
3    False
4     True
dtype: bool

---->   pandas.Series; Series.isin

--------------------------------------
ID: 6343 --> 1
In [14]: import random

In [15]: import string

In [16]: baseball = pd.DataFrame(
   ....:     {
   ....:         "team": ["team %d" % (x + 1) for x in range(5)] * 5,
   ....:         "player": random.sample(list(string.ascii_lowercase), 25),
   ....:         "batting avg": np.random.uniform(0.200, 0.400, 25),
   ....:     }
   ....: )
   ....: 

In [17]: baseball.pivot_table(values="batting avg", columns="team", aggfunc=np.max)
Out[17]: 
team           team 1    team 2    team 3    team 4    team 5
batting avg  0.352134  0.295327  0.397191  0.394457  0.396194

---->   pandas.DataFrame

--------------------------------------
ID: 6345 --> 1
In [18]: df = pd.DataFrame({"a": np.random.randn(10), "b": np.random.randn(10)})

In [19]: df.query("a <= b")
Out[19]: 
          a         b
1  0.174950  0.552887
2 -0.023167  0.148084
3 -0.495291 -0.300218
4 -0.860736  0.197378
5 -1.134146  1.720780
7 -0.290098  0.083515
8  0.238636  0.946550

In [20]: df[df["a"] <= df["b"]]
Out[20]: 
          a         b
1  0.174950  0.552887
2 -0.023167  0.148084
3 -0.495291 -0.300218
4 -0.860736  0.197378
5 -1.134146  1.720780
7 -0.290098  0.083515
8  0.238636  0.946550

In [21]: df.loc[df["a"] <= df["b"]]
Out[21]: 
          a         b
1  0.174950  0.552887
2 -0.023167  0.148084
3 -0.495291 -0.300218
4 -0.860736  0.197378
5 -1.134146  1.720780
7 -0.290098  0.083515
8  0.238636  0.946550

---->   pandas.DataFrame

--------------------------------------
ID: 6347 --> 1
In [22]: df = pd.DataFrame({"a": np.random.randn(10), "b": np.random.randn(10)})

In [23]: df.eval("a + b")
Out[23]: 
0   -0.091430
1   -2.483890
2   -0.252728
3   -0.626444
4   -0.261740
5    2.149503
6   -0.332214
7    0.799331
8   -2.377245
9    2.104677
dtype: float64

In [24]: df["a"] + df["b"]  # same as the previous expression
Out[24]: 
0   -0.091430
1   -2.483890
2   -0.252728
3   -0.626444
4   -0.261740
5    2.149503
6   -0.332214
7    0.799331
8   -2.377245
9    2.104677
dtype: float64

---->   pandas.DataFrame

--------------------------------------
ID: 6349 --> 2
In [25]: df = pd.DataFrame(
   ....:     {
   ....:         "x": np.random.uniform(1.0, 168.0, 120),
   ....:         "y": np.random.uniform(7.0, 334.0, 120),
   ....:         "z": np.random.uniform(1.7, 20.7, 120),
   ....:         "month": [5, 6, 7, 8] * 30,
   ....:         "week": np.random.randint(1, 4, 120),
   ....:     }
   ....: )
   ....: 

In [26]: grouped = df.groupby(["month", "week"])

In [27]: grouped["x"].agg([np.mean, np.std])
Out[27]: 
                  mean        std
month week                       
5     1      63.653367  40.601965
      2      78.126605  53.342400
      3      92.091886  57.630110
6     1      81.747070  54.339218
      2      70.971205  54.687287
      3     100.968344  54.010081
7     1      61.576332  38.844274
      2      61.733510  48.209013
      3      71.688795  37.595638
8     1      62.741922  34.618153
      2      91.774627  49.790202
      3      73.936856  60.773900

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 6351 --> 1
In [28]: a = np.array(list(range(1, 24)) + [np.NAN]).reshape(2, 3, 4)

In [29]: pd.DataFrame([tuple(list(x) + [val]) for x, val in np.ndenumerate(a)])
Out[29]: 
    0  1  2     3
0   0  0  0   1.0
1   0  0  1   2.0
2   0  0  2   3.0
3   0  0  3   4.0
4   0  1  0   5.0
.. .. .. ..   ...
19  1  1  3  20.0
20  1  2  0  21.0
21  1  2  1  22.0
22  1  2  2  23.0
23  1  2  3   NaN

[24 rows x 4 columns]

---->   pandas.DataFrame

--------------------------------------
ID: 6353 --> 1
In [30]: a = list(enumerate(list(range(1, 5)) + [np.NAN]))

In [31]: pd.DataFrame(a)
Out[31]: 
   0    1
0  0  1.0
1  1  2.0
2  2  3.0
3  3  4.0
4  4  NaN

---->   pandas.DataFrame

--------------------------------------
ID: 6355 --> 2
In [32]: cheese = pd.DataFrame(
   ....:     {
   ....:         "first": ["John", "Mary"],
   ....:         "last": ["Doe", "Bo"],
   ....:         "height": [5.5, 6.0],
   ....:         "weight": [130, 150],
   ....:     }
   ....: )
   ....: 

In [33]: pd.melt(cheese, id_vars=["first", "last"])
Out[33]: 
  first last variable  value
0  John  Doe   height    5.5
1  Mary   Bo   height    6.0
2  John  Doe   weight  130.0
3  Mary   Bo   weight  150.0

In [34]: cheese.set_index(["first", "last"]).stack()  # alternative way
Out[34]: 
first  last        
John   Doe   height      5.5
             weight    130.0
Mary   Bo    height      6.0
             weight    150.0
dtype: float64

---->   pandas.DataFrame; pandas.melt

--------------------------------------
ID: 6357 --> 3
In [35]: df = pd.DataFrame(
   ....:     {
   ....:         "x": np.random.uniform(1.0, 168.0, 12),
   ....:         "y": np.random.uniform(7.0, 334.0, 12),
   ....:         "z": np.random.uniform(1.7, 20.7, 12),
   ....:         "month": [5, 6, 7] * 4,
   ....:         "week": [1, 2] * 6,
   ....:     }
   ....: )
   ....: 

In [36]: mdf = pd.melt(df, id_vars=["month", "week"])

In [37]: pd.pivot_table(
   ....:     mdf,
   ....:     values="value",
   ....:     index=["variable", "week"],
   ....:     columns=["month"],
   ....:     aggfunc=np.mean,
   ....: )
   ....: 
Out[37]: 
month                  5           6           7
variable week                                   
x        1     93.888747   98.762034   55.219673
         2     94.391427   38.112932   83.942781
y        1     94.306912  279.454811  227.840449
         2     87.392662  193.028166  173.899260
z        1     11.016009   10.079307   16.170549
         2      8.476111   17.638509   19.003494

---->   pandas.DataFrame; pandas.melt; pandas.pivot_table

--------------------------------------
ID: 6359 --> 2
In [38]: df = pd.DataFrame(
   ....:     {
   ....:         "Animal": [
   ....:             "Animal1",
   ....:             "Animal2",
   ....:             "Animal3",
   ....:             "Animal2",
   ....:             "Animal1",
   ....:             "Animal2",
   ....:             "Animal3",
   ....:         ],
   ....:         "FeedType": ["A", "B", "A", "A", "B", "B", "A"],
   ....:         "Amount": [10, 7, 4, 2, 5, 6, 2],
   ....:     }
   ....: )
   ....: 

In [39]: df.pivot_table(values="Amount", index="Animal", columns="FeedType", aggfunc="sum")
Out[39]: 
FeedType     A     B
Animal              
Animal1   10.0   5.0
Animal2    2.0  13.0
Animal3    6.0   NaN

---->   pandas.DataFrame; DataFrame.pivot_table

--------------------------------------
ID: 6360 --> 1
In [40]: df.groupby(["Animal", "FeedType"])["Amount"].sum()
Out[40]: 
Animal   FeedType
Animal1  A           10
         B            5
Animal2  A            2
         B           13
Animal3  A            6
Name: Amount, dtype: int64

---->   DataFrame.groupby

--------------------------------------
ID: 6362 --> 2
In [41]: pd.cut(pd.Series([1, 2, 3, 4, 5, 6]), 3)
Out[41]: 
0    (0.995, 2.667]
1    (0.995, 2.667]
2    (2.667, 4.333]
3    (2.667, 4.333]
4      (4.333, 6.0]
5      (4.333, 6.0]
dtype: category
Categories (3, interval[float64, right]): [(0.995, 2.667] < (2.667, 4.333] < (4.333, 6.0]]

In [42]: pd.Series([1, 2, 3, 2, 2, 3]).astype("category")
Out[42]: 
0    1
1    2
2    3
3    2
4    2
5    3
dtype: category
Categories (3, int64): [1, 2, 3]

---->   pandas.cut; pandas.Series

--------------------------------------
ID: 6364 --> 1
>>> ds = pd.DataFrame(
...     {"longitude": np.linspace(0, 10), "latitude": np.linspace(0, 20)}
... )
>>> ds.geo.center
(5.0, 10.0)
>>> ds.geo.plot()
# plots data on a map

---->   pandas.DataFrame

--------------------------------------
ID: 6370 --> 1
>>> s = SubclassedSeries([1, 2, 3])
>>> type(s)


>>> to_framed = s.to_frame()
>>> type(to_framed)


>>> df = SubclassedDataFrame({"A": [1, 2, 3], "B": [4, 5, 6], "C": [7, 8, 9]})
>>> df
   A  B  C
0  1  4  7
1  2  5  8
2  3  6  9

>>> type(df)


>>> sliced1 = df[["A", "B"]]
>>> sliced1
   A  B
0  1  4
1  2  5
2  3  6

>>> type(sliced1)


>>> sliced2 = df["A"]
>>> sliced2
0    1
1    2
2    3
Name: A, dtype: int64

>>> type(sliced2)


---->   Series.to_frame

--------------------------------------
ID: 6373 --> 1
>>> pd.set_option("plotting.backend", "backend.module")
>>> pd.Series([1, 2, 3]).plot()

---->   pandas.Series

--------------------------------------
ID: 6374 --> 1
>>> import backend.module
>>> backend.module.plot(pd.Series([1, 2, 3]))

---->   pandas.Series

--------------------------------------
ID: 6384 --> 1
In [15]: frame = pd.DataFrame(
   ....:     {"col1": ["A", "B", np.NaN, "C", "D"], "col2": ["F", np.NaN, "G", "H", "I"]}
   ....: )
   ....: 

In [16]: frame
Out[16]: 
  col1 col2
0    A    F
1    B  NaN
2  NaN    G
3    C    H
4    D    I

---->   pandas.DataFrame

--------------------------------------
ID: 6395 --> 1
In [24]: df1 = pd.DataFrame({"key": ["A", "B", "C", "D"], "value": np.random.randn(4)})

In [25]: df2 = pd.DataFrame({"key": ["B", "D", "D", "E"], "value": np.random.randn(4)})

---->   pandas.DataFrame

--------------------------------------
ID: 6401 --> 1
In [32]: df1 = pd.DataFrame(
   ....:     {"city": ["Chicago", "San Francisco", "New York City"], "rank": range(1, 4)}
   ....: )
   ....: 

In [33]: df2 = pd.DataFrame(
   ....:     {"city": ["Chicago", "Boston", "Los Angeles"], "rank": [1, 4, 5]}
   ....: )
   ....: 

---->   pandas.DataFrame

--------------------------------------
ID: 6419 --> 1
In [15]: frame = pd.DataFrame(
   ....:     {"col1": ["A", "B", np.NaN, "C", "D"], "col2": ["F", np.NaN, "G", "H", "I"]}
   ....: )
   ....: 

In [16]: frame
Out[16]: 
  col1 col2
0    A    F
1    B  NaN
2  NaN    G
3    C    H
4    D    I

---->   pandas.DataFrame

--------------------------------------
ID: 6430 --> 1
In [24]: df1 = pd.DataFrame({"key": ["A", "B", "C", "D"], "value": np.random.randn(4)})

In [25]: df2 = pd.DataFrame({"key": ["B", "D", "D", "E"], "value": np.random.randn(4)})

---->   pandas.DataFrame

--------------------------------------
ID: 6436 --> 1
In [32]: df1 = pd.DataFrame(
   ....:     {"city": ["Chicago", "San Francisco", "New York City"], "rank": range(1, 4)}
   ....: )
   ....: 

In [33]: df2 = pd.DataFrame(
   ....:     {"city": ["Chicago", "Boston", "Los Angeles"], "rank": [1, 4, 5]}
   ....: )
   ....: 

---->   pandas.DataFrame

--------------------------------------
ID: 6449 --> 1
In [1]: df = pd.DataFrame(np.random.randn(10, 3), columns=list("abc"))

In [2]: df[["a", "c"]]
Out[2]: 
          a         c
0  0.469112 -1.509059
1 -1.135632 -0.173215
2  0.119209 -0.861849
3 -2.104569  1.071804
4  0.721555 -1.039575
5  0.271860  0.567020
6  0.276232 -0.673690
7  0.113648  0.524988
8  0.404705 -1.715002
9 -1.039268 -1.157892

In [3]: df.loc[:, ["a", "c"]]
Out[3]: 
          a         c
0  0.469112 -1.509059
1 -1.135632 -0.173215
2  0.119209 -0.861849
3 -2.104569  1.071804
4  0.721555 -1.039575
5  0.271860  0.567020
6  0.276232 -0.673690
7  0.113648  0.524988
8  0.404705 -1.715002
9 -1.039268 -1.157892

---->   pandas.DataFrame

--------------------------------------
ID: 6450 --> 1
In [4]: named = list("abcdefg")

In [5]: n = 30

In [6]: columns = named + np.arange(len(named), n).tolist()

In [7]: df = pd.DataFrame(np.random.randn(n, n), columns=columns)

In [8]: df.iloc[:, np.r_[:10, 24:30]]
Out[8]: 
           a         b         c  ...        27        28        29
0  -1.344312  0.844885  1.075770  ...  0.813850  0.132003 -0.827317
1  -0.076467 -1.187678  1.130127  ...  0.149748 -0.732339  0.687738
2   0.176444  0.403310 -0.154951  ... -0.493662  0.600178  0.274230
3   0.132885 -0.023688  2.410179  ...  0.109121  1.126203 -0.977349
4   1.474071 -0.064034 -1.282782  ... -0.858447  0.306996 -0.028665
..       ...       ...       ...  ...       ...       ...       ...
25  1.492125 -0.068190  0.681456  ...  0.428572  0.880609  0.487645
26  0.725238  0.624607 -0.141185  ...  1.008500  1.424017  0.717110
27  1.262419  1.950057  0.301038  ...  1.007824  2.826008  1.458383
28 -1.585746 -0.899734  0.921494  ...  0.577223 -1.088417  0.326687
29 -0.986248  0.169729 -1.158091  ... -2.013086 -1.602549  0.333109

[30 rows x 16 columns]

---->   pandas.DataFrame

--------------------------------------
ID: 6452 --> 2
In [9]: df = pd.DataFrame(
   ...:     {
   ...:         "v1": [1, 3, 5, 7, 8, 3, 5, np.nan, 4, 5, 7, 9],
   ...:         "v2": [11, 33, 55, 77, 88, 33, 55, np.nan, 44, 55, 77, 99],
   ...:         "by1": ["red", "blue", 1, 2, np.nan, "big", 1, 2, "red", 1, np.nan, 12],
   ...:         "by2": [
   ...:             "wet",
   ...:             "dry",
   ...:             99,
   ...:             95,
   ...:             np.nan,
   ...:             "damp",
   ...:             95,
   ...:             99,
   ...:             "red",
   ...:             99,
   ...:             np.nan,
   ...:             np.nan,
   ...:         ],
   ...:     }
   ...: )
   ...: 

In [10]: g = df.groupby(["by1", "by2"])

In [11]: g[["v1", "v2"]].mean()
Out[11]: 
            v1    v2
by1  by2            
1    95    5.0  55.0
     99    5.0  55.0
2    95    7.0  77.0
     99    NaN   NaN
big  damp  3.0  33.0
blue dry   3.0  33.0
red  red   4.0  44.0
     wet   1.0  11.0

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 6454 --> 2
In [12]: s = pd.Series(np.arange(5), dtype=np.float32)

In [13]: s.isin([2, 4])
Out[13]: 
0    False
1    False
2     True
3    False
4     True
dtype: bool

---->   pandas.Series; Series.isin

--------------------------------------
ID: 6457 --> 1
In [14]: import random

In [15]: import string

In [16]: baseball = pd.DataFrame(
   ....:     {
   ....:         "team": ["team %d" % (x + 1) for x in range(5)] * 5,
   ....:         "player": random.sample(list(string.ascii_lowercase), 25),
   ....:         "batting avg": np.random.uniform(0.200, 0.400, 25),
   ....:     }
   ....: )
   ....: 

In [17]: baseball.pivot_table(values="batting avg", columns="team", aggfunc=np.max)
Out[17]: 
team           team 1    team 2    team 3    team 4    team 5
batting avg  0.352134  0.295327  0.397191  0.394457  0.396194

---->   pandas.DataFrame

--------------------------------------
ID: 6459 --> 1
In [18]: df = pd.DataFrame({"a": np.random.randn(10), "b": np.random.randn(10)})

In [19]: df.query("a <= b")
Out[19]: 
          a         b
1  0.174950  0.552887
2 -0.023167  0.148084
3 -0.495291 -0.300218
4 -0.860736  0.197378
5 -1.134146  1.720780
7 -0.290098  0.083515
8  0.238636  0.946550

In [20]: df[df["a"] <= df["b"]]
Out[20]: 
          a         b
1  0.174950  0.552887
2 -0.023167  0.148084
3 -0.495291 -0.300218
4 -0.860736  0.197378
5 -1.134146  1.720780
7 -0.290098  0.083515
8  0.238636  0.946550

In [21]: df.loc[df["a"] <= df["b"]]
Out[21]: 
          a         b
1  0.174950  0.552887
2 -0.023167  0.148084
3 -0.495291 -0.300218
4 -0.860736  0.197378
5 -1.134146  1.720780
7 -0.290098  0.083515
8  0.238636  0.946550

---->   pandas.DataFrame

--------------------------------------
ID: 6461 --> 1
In [22]: df = pd.DataFrame({"a": np.random.randn(10), "b": np.random.randn(10)})

In [23]: df.eval("a + b")
Out[23]: 
0   -0.091430
1   -2.483890
2   -0.252728
3   -0.626444
4   -0.261740
5    2.149503
6   -0.332214
7    0.799331
8   -2.377245
9    2.104677
dtype: float64

In [24]: df["a"] + df["b"]  # same as the previous expression
Out[24]: 
0   -0.091430
1   -2.483890
2   -0.252728
3   -0.626444
4   -0.261740
5    2.149503
6   -0.332214
7    0.799331
8   -2.377245
9    2.104677
dtype: float64

---->   pandas.DataFrame

--------------------------------------
ID: 6463 --> 2
In [25]: df = pd.DataFrame(
   ....:     {
   ....:         "x": np.random.uniform(1.0, 168.0, 120),
   ....:         "y": np.random.uniform(7.0, 334.0, 120),
   ....:         "z": np.random.uniform(1.7, 20.7, 120),
   ....:         "month": [5, 6, 7, 8] * 30,
   ....:         "week": np.random.randint(1, 4, 120),
   ....:     }
   ....: )
   ....: 

In [26]: grouped = df.groupby(["month", "week"])

In [27]: grouped["x"].agg([np.mean, np.std])
Out[27]: 
                  mean        std
month week                       
5     1      63.653367  40.601965
      2      78.126605  53.342400
      3      92.091886  57.630110
6     1      81.747070  54.339218
      2      70.971205  54.687287
      3     100.968344  54.010081
7     1      61.576332  38.844274
      2      61.733510  48.209013
      3      71.688795  37.595638
8     1      62.741922  34.618153
      2      91.774627  49.790202
      3      73.936856  60.773900

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 6465 --> 1
In [28]: a = np.array(list(range(1, 24)) + [np.NAN]).reshape(2, 3, 4)

In [29]: pd.DataFrame([tuple(list(x) + [val]) for x, val in np.ndenumerate(a)])
Out[29]: 
    0  1  2     3
0   0  0  0   1.0
1   0  0  1   2.0
2   0  0  2   3.0
3   0  0  3   4.0
4   0  1  0   5.0
.. .. .. ..   ...
19  1  1  3  20.0
20  1  2  0  21.0
21  1  2  1  22.0
22  1  2  2  23.0
23  1  2  3   NaN

[24 rows x 4 columns]

---->   pandas.DataFrame

--------------------------------------
ID: 6467 --> 1
In [30]: a = list(enumerate(list(range(1, 5)) + [np.NAN]))

In [31]: pd.DataFrame(a)
Out[31]: 
   0    1
0  0  1.0
1  1  2.0
2  2  3.0
3  3  4.0
4  4  NaN

---->   pandas.DataFrame

--------------------------------------
ID: 6469 --> 2
In [32]: cheese = pd.DataFrame(
   ....:     {
   ....:         "first": ["John", "Mary"],
   ....:         "last": ["Doe", "Bo"],
   ....:         "height": [5.5, 6.0],
   ....:         "weight": [130, 150],
   ....:     }
   ....: )
   ....: 

In [33]: pd.melt(cheese, id_vars=["first", "last"])
Out[33]: 
  first last variable  value
0  John  Doe   height    5.5
1  Mary   Bo   height    6.0
2  John  Doe   weight  130.0
3  Mary   Bo   weight  150.0

In [34]: cheese.set_index(["first", "last"]).stack()  # alternative way
Out[34]: 
first  last        
John   Doe   height      5.5
             weight    130.0
Mary   Bo    height      6.0
             weight    150.0
dtype: float64

---->   pandas.DataFrame; pandas.melt

--------------------------------------
ID: 6471 --> 3
In [35]: df = pd.DataFrame(
   ....:     {
   ....:         "x": np.random.uniform(1.0, 168.0, 12),
   ....:         "y": np.random.uniform(7.0, 334.0, 12),
   ....:         "z": np.random.uniform(1.7, 20.7, 12),
   ....:         "month": [5, 6, 7] * 4,
   ....:         "week": [1, 2] * 6,
   ....:     }
   ....: )
   ....: 

In [36]: mdf = pd.melt(df, id_vars=["month", "week"])

In [37]: pd.pivot_table(
   ....:     mdf,
   ....:     values="value",
   ....:     index=["variable", "week"],
   ....:     columns=["month"],
   ....:     aggfunc=np.mean,
   ....: )
   ....: 
Out[37]: 
month                  5           6           7
variable week                                   
x        1     93.888747   98.762034   55.219673
         2     94.391427   38.112932   83.942781
y        1     94.306912  279.454811  227.840449
         2     87.392662  193.028166  173.899260
z        1     11.016009   10.079307   16.170549
         2      8.476111   17.638509   19.003494

---->   pandas.DataFrame; pandas.melt; pandas.pivot_table

--------------------------------------
ID: 6473 --> 2
In [38]: df = pd.DataFrame(
   ....:     {
   ....:         "Animal": [
   ....:             "Animal1",
   ....:             "Animal2",
   ....:             "Animal3",
   ....:             "Animal2",
   ....:             "Animal1",
   ....:             "Animal2",
   ....:             "Animal3",
   ....:         ],
   ....:         "FeedType": ["A", "B", "A", "A", "B", "B", "A"],
   ....:         "Amount": [10, 7, 4, 2, 5, 6, 2],
   ....:     }
   ....: )
   ....: 

In [39]: df.pivot_table(values="Amount", index="Animal", columns="FeedType", aggfunc="sum")
Out[39]: 
FeedType     A     B
Animal              
Animal1   10.0   5.0
Animal2    2.0  13.0
Animal3    6.0   NaN

---->   pandas.DataFrame; DataFrame.pivot_table

--------------------------------------
ID: 6474 --> 1
In [40]: df.groupby(["Animal", "FeedType"])["Amount"].sum()
Out[40]: 
Animal   FeedType
Animal1  A           10
         B            5
Animal2  A            2
         B           13
Animal3  A            6
Name: Amount, dtype: int64

---->   DataFrame.groupby

--------------------------------------
ID: 6476 --> 2
In [41]: pd.cut(pd.Series([1, 2, 3, 4, 5, 6]), 3)
Out[41]: 
0    (0.995, 2.667]
1    (0.995, 2.667]
2    (2.667, 4.333]
3    (2.667, 4.333]
4      (4.333, 6.0]
5      (4.333, 6.0]
dtype: category
Categories (3, interval[float64, right]): [(0.995, 2.667] < (2.667, 4.333] < (4.333, 6.0]]

In [42]: pd.Series([1, 2, 3, 2, 2, 3]).astype("category")
Out[42]: 
0    1
1    2
2    3
3    2
4    2
5    3
dtype: category
Categories (3, int64): [1, 2, 3]

---->   pandas.cut; pandas.Series

--------------------------------------
ID: 6477 --> 1
>>> spacing = np.linspace(-9 * np.pi, 9 * np.pi, num=1000)
>>> s = pd.Series(0.7 * np.random.rand(1000) + 0.3 * np.sin(spacing))
>>> pd.plotting.autocorrelation_plot(s)


---->   pandas.Series

--------------------------------------
ID: 6480 --> 1
>>> import pandas as pd
>>> pd.show_versions()

---->   pandas.show_versions

--------------------------------------
ID: 6482 --> 1
>>> df = pd.DataFrame(
...     {
...         'SepalLength': [6.5, 7.7, 5.1, 5.8, 7.6, 5.0, 5.4, 4.6, 6.7, 4.6],
...         'SepalWidth': [3.0, 3.8, 3.8, 2.7, 3.0, 2.3, 3.0, 3.2, 3.3, 3.6],
...         'PetalLength': [5.5, 6.7, 1.9, 5.1, 6.6, 3.3, 4.5, 1.4, 5.7, 1.0],
...         'PetalWidth': [1.8, 2.2, 0.4, 1.9, 2.1, 1.0, 1.5, 0.2, 2.1, 0.2],
...         'Category': [
...             'virginica',
...             'virginica',
...             'setosa',
...             'virginica',
...             'virginica',
...             'versicolor',
...             'versicolor',
...             'setosa',
...             'virginica',
...             'setosa'
...         ]
...     }
... )
>>> pd.plotting.radviz(df, 'Category')


---->   pandas.DataFrame

--------------------------------------
ID: 6483 --> 2
>>> np.random.seed(1234)
>>> df = pd.DataFrame(np.random.randn(10, 4),
...                   columns=['Col1', 'Col2', 'Col3', 'Col4'])
>>> boxplot = df.boxplot(column=['Col1', 'Col2', 'Col3'])  

---->   pandas.DataFrame; DataFrame.boxplot

--------------------------------------
ID: 6484 --> 3
>>> df = pd.DataFrame(np.random.randn(10, 2),
...                   columns=['Col1', 'Col2'])
>>> df['X'] = pd.Series(['A', 'A', 'A', 'A', 'A',
...                      'B', 'B', 'B', 'B', 'B'])
>>> boxplot = df.boxplot(by='X')

---->   pandas.DataFrame; pandas.Series; DataFrame.boxplot

--------------------------------------
ID: 6485 --> 3
>>> df = pd.DataFrame(np.random.randn(10, 3),
...                   columns=['Col1', 'Col2', 'Col3'])
>>> df['X'] = pd.Series(['A', 'A', 'A', 'A', 'A',
...                      'B', 'B', 'B', 'B', 'B'])
>>> df['Y'] = pd.Series(['A', 'B', 'A', 'B', 'A',
...                      'B', 'A', 'B', 'A', 'B'])
>>> boxplot = df.boxplot(column=['Col1', 'Col2'], by=['X', 'Y'])

---->   pandas.DataFrame; pandas.Series; DataFrame.boxplot

--------------------------------------
ID: 6486 --> 1
>>> boxplot = df.boxplot(column=['Col1', 'Col2'], by='X',
...                      layout=(2, 1))

---->   DataFrame.boxplot

--------------------------------------
ID: 6487 --> 1
>>> boxplot = df.boxplot(grid=False, rot=45, fontsize=15)  

---->   DataFrame.boxplot

--------------------------------------
ID: 6488 --> 1
>>> boxplot = df.boxplot(column=['Col1', 'Col2'], return_type='axes')
>>> type(boxplot)


---->   DataFrame.boxplot

--------------------------------------
ID: 6489 --> 1
>>> boxplot = df.boxplot(column=['Col1', 'Col2'], by='X',
...                      return_type='axes')
>>> type(boxplot)


---->   DataFrame.boxplot

--------------------------------------
ID: 6490 --> 1
>>> boxplot = df.boxplot(column=['Col1', 'Col2'], by='X',
...                      return_type=None)
>>> type(boxplot)


---->   DataFrame.boxplot

--------------------------------------
ID: 6493 --> 1
In [7]: air_quality["datetime"] = pd.to_datetime(air_quality["datetime"])

In [8]: air_quality["datetime"]
Out[8]: 
0      2019-06-21 00:00:00+00:00
1      2019-06-20 23:00:00+00:00
2      2019-06-20 22:00:00+00:00
3      2019-06-20 21:00:00+00:00
4      2019-06-20 20:00:00+00:00
                  ...           
2063   2019-05-07 06:00:00+00:00
2064   2019-05-07 04:00:00+00:00
2065   2019-05-07 03:00:00+00:00
2066   2019-05-07 02:00:00+00:00
2067   2019-05-07 01:00:00+00:00
Name: datetime, Length: 2068, dtype: datetime64[ns, UTC]

---->   pandas.to_datetime

--------------------------------------
ID: 6506 --> 2
>>> np.random.seed(5)
>>> x = np.cumsum(np.random.normal(loc=1, scale=5, size=50))
>>> s = pd.Series(x)
>>> s.plot()


---->   pandas.Series; Series.plot

--------------------------------------
ID: 6508 --> 1
>>> s = pd.Series(np.random.uniform(size=100))
>>> pd.plotting.bootstrap_plot(s)


---->   pandas.Series

--------------------------------------
ID: 6509 --> 1
>>> mask = pd.array([True, False])
>>> arr = pd.array([1, 2])
>>> pd.api.indexers.check_array_indexer(arr, mask)
array([ True, False])

---->   pandas.array

--------------------------------------
ID: 6510 --> 1
>>> mask = pd.array([True, False, True])
>>> pd.api.indexers.check_array_indexer(arr, mask)
Traceback (most recent call last):
...
IndexError: Boolean index has wrong length: 3 instead of 2.

---->   pandas.array

--------------------------------------
ID: 6511 --> 1
>>> mask = pd.array([True, pd.NA])
>>> pd.api.indexers.check_array_indexer(arr, mask)
array([ True, False])

---->   pandas.array

--------------------------------------
ID: 6513 --> 1
>>> indexer = pd.array([0, 2], dtype="Int64")
>>> arr = pd.array([1, 2, 3])
>>> pd.api.indexers.check_array_indexer(arr, indexer)
array([0, 2])

---->   pandas.array

--------------------------------------
ID: 6514 --> 1
>>> indexer = pd.array([0, pd.NA], dtype="Int64")
>>> pd.api.indexers.check_array_indexer(arr, indexer)
Traceback (most recent call last):
...
ValueError: Cannot index with an integer indexer containing NA values

---->   pandas.array

--------------------------------------
ID: 6516 --> 1
>>> df = pd.DataFrame(np.random.randn(1000, 4), columns=['A','B','C','D'])
>>> pd.plotting.scatter_matrix(df, alpha=0.2)
array([[,
    ,
    ,
    ],
   [,
    ,
    ,
    ],
   [,
    ,
    ,
    ],
   [,
    ,
    ,
    ]], dtype=object)

---->   pandas.DataFrame

--------------------------------------
ID: 6519 --> 1
>>> pd.Series(['a', 'b']).dt
Traceback (most recent call last):
...
AttributeError: Can only use .dt accessor with datetimelike values

---->   pandas.Series

--------------------------------------
ID: 6521 --> 1
In [1]: ds = pd.DataFrame({"longitude": np.linspace(0, 10),
   ...:                    "latitude": np.linspace(0, 20)})
In [2]: ds.geo.center
Out[2]: (5.0, 10.0)
In [3]: ds.geo.plot()  # plots data on a map

---->   pandas.DataFrame

--------------------------------------
ID: 6523 --> 1
>>> ds = pd.DataFrame(
...     {"longitude": np.linspace(0, 10), "latitude": np.linspace(0, 20)}
... )
>>> ds.geo.center
(5.0, 10.0)
>>> ds.geo.plot()
# plots data on a map

---->   pandas.DataFrame

--------------------------------------
ID: 6529 --> 1
>>> s = SubclassedSeries([1, 2, 3])
>>> type(s)


>>> to_framed = s.to_frame()
>>> type(to_framed)


>>> df = SubclassedDataFrame({"A": [1, 2, 3], "B": [4, 5, 6], "C": [7, 8, 9]})
>>> df
   A  B  C
0  1  4  7
1  2  5  8
2  3  6  9

>>> type(df)


>>> sliced1 = df[["A", "B"]]
>>> sliced1
   A  B
0  1  4
1  2  5
2  3  6

>>> type(sliced1)


>>> sliced2 = df["A"]
>>> sliced2
0    1
1    2
2    3
Name: A, dtype: int64

>>> type(sliced2)


---->   Series.to_frame

--------------------------------------
ID: 6532 --> 1
>>> pd.set_option("plotting.backend", "backend.module")
>>> pd.Series([1, 2, 3]).plot()

---->   pandas.Series

--------------------------------------
ID: 6533 --> 1
>>> import backend.module
>>> backend.module.plot(pd.Series([1, 2, 3]))

---->   pandas.Series

--------------------------------------
ID: 6536 --> 1
>>> mask = pd.array([True, False])
>>> arr = pd.array([1, 2])
>>> pd.api.indexers.check_array_indexer(arr, mask)
array([ True, False])

---->   pandas.array

--------------------------------------
ID: 6537 --> 1
>>> mask = pd.array([True, False, True])
>>> pd.api.indexers.check_array_indexer(arr, mask)
Traceback (most recent call last):
...
IndexError: Boolean index has wrong length: 3 instead of 2.

---->   pandas.array

--------------------------------------
ID: 6538 --> 1
>>> mask = pd.array([True, pd.NA])
>>> pd.api.indexers.check_array_indexer(arr, mask)
array([ True, False])

---->   pandas.array

--------------------------------------
ID: 6540 --> 1
>>> indexer = pd.array([0, 2], dtype="Int64")
>>> arr = pd.array([1, 2, 3])
>>> pd.api.indexers.check_array_indexer(arr, indexer)
array([0, 2])

---->   pandas.array

--------------------------------------
ID: 6541 --> 1
>>> indexer = pd.array([0, pd.NA], dtype="Int64")
>>> pd.api.indexers.check_array_indexer(arr, indexer)
Traceback (most recent call last):
...
ValueError: Cannot index with an integer indexer containing NA values

---->   pandas.array

--------------------------------------
ID: 6544 --> 1
>>> period = pd.Period('2012-1-1', freq='D')
>>> period
Period('2012-01-01', 'D')

---->   pandas.Period

--------------------------------------
ID: 6548 --> 1
>>> pd.Series(['a', 'b']).dt
Traceback (most recent call last):
...
AttributeError: Can only use .dt accessor with datetimelike values

---->   pandas.Series

--------------------------------------
ID: 6550 --> 1
In [1]: ds = pd.DataFrame({"longitude": np.linspace(0, 10),
   ...:                    "latitude": np.linspace(0, 20)})
In [2]: ds.geo.center
Out[2]: (5.0, 10.0)
In [3]: ds.geo.plot()  # plots data on a map

---->   pandas.DataFrame

--------------------------------------
ID: 6552 --> 1
>>> pd.Series(['a', 'b']).dt
Traceback (most recent call last):
...
AttributeError: Can only use .dt accessor with datetimelike values

---->   pandas.Series

--------------------------------------
ID: 6554 --> 1
In [1]: ds = pd.DataFrame({"longitude": np.linspace(0, 10),
   ...:                    "latitude": np.linspace(0, 20)})
In [2]: ds.geo.center
Out[2]: (5.0, 10.0)
In [3]: ds.geo.plot()  # plots data on a map

---->   pandas.DataFrame

--------------------------------------
ID: 6558 --> 1
>>> a = pd.Categorical(["b", "c"])
>>> b = pd.Categorical(["a", "b"])
>>> pd.api.types.union_categoricals([a, b])
['b', 'c', 'a', 'b']
Categories (3, object): ['b', 'c', 'a']

---->   pandas.Categorical

--------------------------------------
ID: 6560 --> 1
>>> a = pd.Categorical(["a", "b"], ordered=True)
>>> b = pd.Categorical(["a", "b", "a"], ordered=True)
>>> pd.api.types.union_categoricals([a, b])
['a', 'b', 'a', 'b', 'a']
Categories (2, object): ['a' < 'b']

---->   pandas.Categorical

--------------------------------------
ID: 6561 --> 1
>>> a = pd.Categorical(["a", "b"], ordered=True)
>>> b = pd.Categorical(["a", "b", "c"], ordered=True)
>>> pd.api.types.union_categoricals([a, b])
Traceback (most recent call last):
    ...
TypeError: to union ordered Categoricals, all categories must be the same

---->   pandas.Categorical

--------------------------------------
ID: 6562 --> 1
>>> a = pd.Categorical(["a", "b", "c"], ordered=True)
>>> b = pd.Categorical(["c", "b", "a"], ordered=True)
>>> pd.api.types.union_categoricals([a, b], ignore_order=True)
['a', 'b', 'c', 'c', 'b', 'a']
Categories (3, object): ['a', 'b', 'c']

---->   pandas.Categorical

--------------------------------------
ID: 6563 --> 1
>>> a = pd.Series(["b", "c"], dtype='category')
>>> b = pd.Series(["a", "b"], dtype='category')
>>> pd.api.types.union_categoricals([a, b])
['b', 'c', 'a', 'b']
Categories (3, object): ['b', 'c', 'a']

---->   pandas.Series

--------------------------------------
ID: 6564 --> 2
>>> from pandas.api.types import is_float_dtype
>>> is_float_dtype(str)
False
>>> is_float_dtype(int)
False
>>> is_float_dtype(float)
True
>>> is_float_dtype(np.array(['a', 'b']))
False
>>> is_float_dtype(pd.Series([1, 2]))
False
>>> is_float_dtype(pd.Index([1, 2.]))
True

---->   pandas.Series; pandas.Index

--------------------------------------
ID: 6565 --> 1
>>> pd.array([1, 1, None], dtype="int64[pyarrow]")

[1, 1, ]
Length: 3, dtype: int64[pyarrow]

---->   pandas.array

--------------------------------------
ID: 6566 --> 1
>>> p = pd.Period("2018-03-11", "H")
>>> p.week
10

---->   pandas.Period

--------------------------------------
ID: 6567 --> 1
>>> p = pd.Period("2018-02-01", "D")
>>> p.week
5

---->   pandas.Period

--------------------------------------
ID: 6568 --> 1
>>> p = pd.Period("2018-01-06", "D")
>>> p.week
1

---->   pandas.Period

--------------------------------------
ID: 6571 --> 2
>>> from pandas.api.types import is_categorical_dtype
>>> from pandas import CategoricalDtype
>>> is_categorical_dtype(object)
False
>>> is_categorical_dtype(CategoricalDtype())
True
>>> is_categorical_dtype([1, 2, 3])
False
>>> is_categorical_dtype(pd.Categorical([1, 2, 3]))
True
>>> is_categorical_dtype(pd.CategoricalIndex([1, 2, 3]))
True

---->   pandas.Categorical; pandas.CategoricalIndex

--------------------------------------
ID: 6572 --> 1
>>> period = pd.Period("2015-10-23", freq='H')
>>> period.day_of_year
296
>>> period = pd.Period("2012-12-31", freq='D')
>>> period.day_of_year
366
>>> period = pd.Period("2013-01-01", freq='D')
>>> period.day_of_year
1

---->   pandas.Period

--------------------------------------
ID: 6581 --> 1
>>> ts.tz_convert(tz='Asia/Tokyo')
Timestamp('2020-03-15 00:32:52.192548651+0900', tz='Asia/Tokyo')

---->   Series.tz_convert

--------------------------------------
ID: 6584 --> 2
>>> is_integer_dtype(str)
False
>>> is_integer_dtype(int)
True
>>> is_integer_dtype(float)
False
>>> is_integer_dtype(np.uint64)
True
>>> is_integer_dtype('int8')
True
>>> is_integer_dtype('Int8')
True
>>> is_integer_dtype(pd.Int8Dtype)
True
>>> is_integer_dtype(np.datetime64)
False
>>> is_integer_dtype(np.timedelta64)
False
>>> is_integer_dtype(np.array(['a', 'b']))
False
>>> is_integer_dtype(pd.Series([1, 2]))
True
>>> is_integer_dtype(np.array([], dtype=np.timedelta64))
False
>>> is_integer_dtype(pd.Index([1, 2.]))  # float
False

---->   pandas.Series; pandas.Index

--------------------------------------
ID: 6590 --> 1
>>> ts.round(freq='H') # hour
Timestamp('2020-03-14 16:00:00')

---->   Series.round

--------------------------------------
ID: 6591 --> 1
>>> ts.round(freq='T') # minute
Timestamp('2020-03-14 15:33:00')

---->   Series.round

--------------------------------------
ID: 6592 --> 1
>>> ts.round(freq='S') # seconds
Timestamp('2020-03-14 15:32:52')

---->   Series.round

--------------------------------------
ID: 6593 --> 1
>>> ts.round(freq='L') # milliseconds
Timestamp('2020-03-14 15:32:52.193000')

---->   Series.round

--------------------------------------
ID: 6594 --> 1
>>> ts.round(freq='5T')
Timestamp('2020-03-14 15:35:00')

---->   Series.round

--------------------------------------
ID: 6595 --> 1
>>> ts.round(freq='1H30T')
Timestamp('2020-03-14 15:00:00')

---->   Series.round

--------------------------------------
ID: 6600 --> 1
>>> iv = pd.Interval(0, 5, closed='left')
>>> iv.open_right
True

---->   pandas.Interval

--------------------------------------
ID: 6601 --> 1
>>> iv = pd.Interval(0, 5)
>>> iv.open_right
False

---->   pandas.Interval

--------------------------------------
ID: 6607 --> 2
>>> i1 = pd.Interval(0, 2)
>>> i2 = pd.Interval(1, 3)
>>> i1.overlaps(i2)
True
>>> i3 = pd.Interval(4, 5)
>>> i1.overlaps(i3)
False

---->   pandas.Interval; Interval.overlaps

--------------------------------------
ID: 6608 --> 2
>>> i4 = pd.Interval(0, 1, closed='both')
>>> i5 = pd.Interval(1, 2, closed='both')
>>> i4.overlaps(i5)
True

---->   pandas.Interval; Interval.overlaps

--------------------------------------
ID: 6609 --> 2
>>> i6 = pd.Interval(1, 2, closed='neither')
>>> i4.overlaps(i6)
False

---->   pandas.Interval; Interval.overlaps

--------------------------------------
ID: 6611 --> 1
>>> p = pd.Period("2018-03-11 13:03:12.050000")
>>> p.second
12

---->   pandas.Period

--------------------------------------
ID: 6613 --> 1
>>> pd.BooleanDtype()
BooleanDtype

---->   pandas.BooleanDtype

--------------------------------------
ID: 6619 --> 1
>>> import pyarrow as pa
>>> pd.ArrowDtype(pa.int64())
int64[pyarrow]

---->   pandas.ArrowDtype

--------------------------------------
ID: 6620 --> 1
>>> pd.ArrowDtype(pa.timestamp("s", tz="America/New_York"))
timestamp[s, tz=America/New_York][pyarrow]
>>> pd.ArrowDtype(pa.list_(pa.int64()))
list[pyarrow]

---->   pandas.ArrowDtype

--------------------------------------
ID: 6621 --> 1
>>> pd.Interval(0, 1, closed='right').is_empty
False

---->   pandas.Interval

--------------------------------------
ID: 6622 --> 1
>>> pd.Interval(0, 0, closed='right').is_empty
True
>>> pd.Interval(0, 0, closed='left').is_empty
True
>>> pd.Interval(0, 0, closed='neither').is_empty
True

---->   pandas.Interval

--------------------------------------
ID: 6623 --> 1
>>> pd.Interval(0, 0, closed='both').is_empty
False

---->   pandas.Interval

--------------------------------------
ID: 6624 --> 1
>>> ivs = [pd.Interval(0, 0, closed='neither'),
...        pd.Interval(1, 2, closed='neither')]
>>> pd.arrays.IntervalArray(ivs).is_empty
array([ True, False])

---->   pandas.Interval

--------------------------------------
ID: 6625 --> 2
>>> ivs = [pd.Interval(0, 0, closed='neither'), np.nan]
>>> pd.IntervalIndex(ivs).is_empty
array([ True, False])

---->   pandas.Interval; pandas.IntervalIndex

--------------------------------------
ID: 6626 --> 2
>>> dtype = pd.CategoricalDtype(['a', 'b'], ordered=True)
>>> pd.Categorical.from_codes(codes=[0, 1, 0, 1], dtype=dtype)
['a', 'b', 'a', 'b']
Categories (2, object): ['a' < 'b']

---->   pandas.CategoricalDtype; pandas.Categorical

--------------------------------------
ID: 6628 --> 1
>>> ts.tz_localize(tz='Europe/Stockholm')
Timestamp('2020-03-14 15:32:52.192548651+0100', tz='Europe/Stockholm')

---->   Series.tz_localize

--------------------------------------
ID: 6645 --> 1
>>> infer_dtype(pd.Series(list('aabc')).astype('category'))
'categorical'

---->   pandas.Series

--------------------------------------
ID: 6646 --> 1
>>> pd.array([True, False, None], dtype="boolean")

[True, False, ]
Length: 3, dtype: boolean

---->   pandas.array

--------------------------------------
ID: 6647 --> 1
>>> per = pd.Period('2018Q1', freq='Q')
>>> per.qyear
2018
>>> per.year
2018

---->   pandas.Period

--------------------------------------
ID: 6648 --> 1
>>> per = pd.Period('2018Q1', freq='Q-MAR')
>>> per.start_time
Timestamp('2017-04-01 00:00:00')
>>> per.qyear
2018
>>> per.year
2017

---->   pandas.Period

--------------------------------------
ID: 6649 --> 1
>>> from pandas.api.types import is_extension_array_dtype
>>> arr = pd.Categorical(['a', 'b'])
>>> is_extension_array_dtype(arr)
True
>>> is_extension_array_dtype(arr.dtype)
True

---->   pandas.Categorical

--------------------------------------
ID: 6651 --> 1
>>> per = pd.Period('2017-12-31 22:00', 'H')
>>> per.day_of_week
6

---->   pandas.Period

--------------------------------------
ID: 6652 --> 1
>>> per = pd.Period('2017-12-31 22:00', '4H')
>>> per.day_of_week
6
>>> per.start_time.day_of_week
6

---->   pandas.Period

--------------------------------------
ID: 6653 --> 1
>>> per = pd.Period('2018-01', 'M')
>>> per.day_of_week
2
>>> per.end_time.day_of_week
2

---->   pandas.Period

--------------------------------------
ID: 6654 --> 2
>>> is_period_dtype(object)
False
>>> is_period_dtype(PeriodDtype(freq="D"))
True
>>> is_period_dtype([1, 2, 3])
False
>>> is_period_dtype(pd.Period("2017-01-01"))
False
>>> is_period_dtype(pd.PeriodIndex([], freq="A"))
True

---->   pandas.Period; pandas.PeriodIndex

--------------------------------------
ID: 6655 --> 1
>>> ts = pd.Timestamp('2020-03-14T15:32:52.192548651')
>>> ts.to_numpy()
numpy.datetime64('2020-03-14T15:32:52.192548651')

---->   Series.to_numpy

--------------------------------------
ID: 6659 --> 1
>>> p = pd.Period("2018-03-11 13:03:12.050000")
>>> p.hour
13

---->   pandas.Period

--------------------------------------
ID: 6660 --> 1
>>> p = pd.Period("2018-03-11", freq="M")
>>> p.hour
0

---->   pandas.Period

--------------------------------------
ID: 6663 --> 1
>>> pd.arrays.IntervalArray([pd.Interval(0, 1), pd.Interval(1, 5)])

[(0, 1], (1, 5]]
Length: 2, dtype: interval[int64, right]

---->   pandas.Interval

--------------------------------------
ID: 6664 --> 2
>>> pd.array([0.1, None, 0.3], dtype=pd.Float32Dtype())

[0.1, , 0.3]
Length: 3, dtype: Float32

---->   pandas.array; pandas.Float32Dtype

--------------------------------------
ID: 6665 --> 1
>>> pd.array([0.1, None, 0.3], dtype="Float32")

[0.1, , 0.3]
Length: 3, dtype: Float32

---->   pandas.array

--------------------------------------
ID: 6668 --> 1
>>> p = pd.Period("2018-03-11", freq='H')
>>> p.day
11

---->   pandas.Period

--------------------------------------
ID: 6676 --> 1
>>> pd.array(['This is', 'some text', None, 'data.'], dtype="string")

['This is', 'some text', , 'data.']
Length: 4, dtype: string

---->   pandas.array

--------------------------------------
ID: 6677 --> 1
>>> pd.array(['1', 1], dtype="object")

['1', 1]
Length: 2, dtype: object
>>> pd.array(['1', 1], dtype="string")

['1', '1']
Length: 2, dtype: string

---->   pandas.array

--------------------------------------
ID: 6678 --> 1
>>> pd.array(["a", None, "c"], dtype="string") == "a"

[True, , False]
Length: 3, dtype: boolean

---->   pandas.array

--------------------------------------
ID: 6682 --> 1
>>> is_datetime64_ns_dtype(str)
False
>>> is_datetime64_ns_dtype(int)
False
>>> is_datetime64_ns_dtype(np.datetime64)  # no unit
False
>>> is_datetime64_ns_dtype(DatetimeTZDtype("ns", "US/Eastern"))
True
>>> is_datetime64_ns_dtype(np.array(['a', 'b']))
False
>>> is_datetime64_ns_dtype(np.array([1, 2]))
False
>>> is_datetime64_ns_dtype(np.array([], dtype="datetime64"))  # no unit
False
>>> is_datetime64_ns_dtype(np.array([], dtype="datetime64[ps]"))  # wrong unit
False
>>> is_datetime64_ns_dtype(pd.DatetimeIndex([1, 2, 3], dtype="datetime64[ns]"))
True

---->   pandas.DatetimeIndex

--------------------------------------
ID: 6683 --> 1
>>> from pandas.core.dtypes.common import is_timedelta64_dtype
>>> is_timedelta64_dtype(object)
False
>>> is_timedelta64_dtype(np.timedelta64)
True
>>> is_timedelta64_dtype([1, 2, 3])
False
>>> is_timedelta64_dtype(pd.Series([], dtype="timedelta64[ns]"))
True
>>> is_timedelta64_dtype('0 days')
False

---->   pandas.Series

--------------------------------------
ID: 6685 --> 1
>>> p = pd.Period("2018-03-11", freq='H')
>>> p.daysinmonth
31

---->   pandas.Period

--------------------------------------
ID: 6686 --> 2
>>> t = pd.CategoricalDtype(categories=['b', 'a'], ordered=True)
>>> pd.Series(['a', 'b', 'a', 'c'], dtype=t)
0      a
1      b
2      a
3    NaN
dtype: category
Categories (2, object): ['b' < 'a']

---->   pandas.CategoricalDtype; pandas.Series

--------------------------------------
ID: 6687 --> 2
>>> pd.CategoricalDtype(pd.DatetimeIndex([])).categories.dtype
dtype('

---->   pandas.CategoricalDtype; pandas.DatetimeIndex

--------------------------------------
ID: 6688 --> 1
>>> pd.array(['This is', 'some text', None, 'data.'], dtype="string[pyarrow]")

['This is', 'some text', , 'data.']
Length: 4, dtype: string

---->   pandas.array

--------------------------------------
ID: 6691 --> 1
>>> iv = pd.Interval(0, 5, closed='both')
>>> iv.closed_right
True

---->   pandas.Interval

--------------------------------------
ID: 6692 --> 1
>>> iv = pd.Interval(0, 5, closed='left')
>>> iv.closed_right
False

---->   pandas.Interval

--------------------------------------
ID: 6693 --> 1
>>> is_datetime64_any_dtype(str)
False
>>> is_datetime64_any_dtype(int)
False
>>> is_datetime64_any_dtype(np.datetime64)  # can be tz-naive
True
>>> is_datetime64_any_dtype(DatetimeTZDtype("ns", "US/Eastern"))
True
>>> is_datetime64_any_dtype(np.array(['a', 'b']))
False
>>> is_datetime64_any_dtype(np.array([1, 2]))
False
>>> is_datetime64_any_dtype(np.array([], dtype="datetime64[ns]"))
True
>>> is_datetime64_any_dtype(pd.DatetimeIndex([1, 2, 3], dtype="datetime64[ns]"))
True

---->   pandas.DatetimeIndex

--------------------------------------
ID: 6697 --> 1
>>> p = pd.Period("2018-03-11 13:03:12.050000")
>>> p.minute
3

---->   pandas.Period

--------------------------------------
ID: 6698 --> 2
>>> period = pd.Period('2023-1-1', freq='D')
>>> timestamp = period.to_timestamp()
>>> timestamp
Timestamp('2023-01-01 00:00:00')

---->   pandas.Period; Period.to_timestamp

--------------------------------------
ID: 6702 --> 1
>>> pd.DatetimeTZDtype(tz='UTC')
datetime64[ns, UTC]

---->   pandas.DatetimeTZDtype

--------------------------------------
ID: 6703 --> 1
>>> pd.DatetimeTZDtype(tz='dateutil/US/Central')
datetime64[ns, tzfile('/usr/share/zoneinfo/US/Central')]

---->   pandas.DatetimeTZDtype

--------------------------------------
ID: 6705 --> 2
>>> is_unsigned_integer_dtype(str)
False
>>> is_unsigned_integer_dtype(int)  # signed
False
>>> is_unsigned_integer_dtype(float)
False
>>> is_unsigned_integer_dtype(np.uint64)
True
>>> is_unsigned_integer_dtype('uint8')
True
>>> is_unsigned_integer_dtype('UInt8')
True
>>> is_unsigned_integer_dtype(pd.UInt8Dtype)
True
>>> is_unsigned_integer_dtype(np.array(['a', 'b']))
False
>>> is_unsigned_integer_dtype(pd.Series([1, 2]))  # signed
False
>>> is_unsigned_integer_dtype(pd.Index([1, 2.]))  # float
False
>>> is_unsigned_integer_dtype(np.array([1, 2], dtype=np.uint32))
True

---->   pandas.Series; pandas.Index

--------------------------------------
ID: 6706 --> 1
>>> pd.array(['a', 'b'], dtype=str)

['a', 'b']
Length: 2, dtype: str32

---->   pandas.array

--------------------------------------
ID: 6707 --> 1
>>> pd.array(['a', 'b'], dtype=np.dtype("))

['a', 'b']
Length: 2, dtype: str32

---->   pandas.array

--------------------------------------
ID: 6708 --> 1
>>> pd.array(['2015', '2016'], dtype='datetime64[ns]')

['2015-01-01 00:00:00', '2016-01-01 00:00:00']
Length: 2, dtype: datetime64[ns]

---->   pandas.array

--------------------------------------
ID: 6709 --> 1
>>> pd.array(["1H", "2H"], dtype='timedelta64[ns]')

['0 days 01:00:00', '0 days 02:00:00']
Length: 2, dtype: timedelta64[ns]

---->   pandas.array

--------------------------------------
ID: 6710 --> 1
>>> pd.array([1, 2])

[1, 2]
Length: 2, dtype: Int64

---->   pandas.array

--------------------------------------
ID: 6711 --> 1
>>> pd.array([1, 2, np.nan])

[1, 2, ]
Length: 3, dtype: Int64

---->   pandas.array

--------------------------------------
ID: 6712 --> 1
>>> pd.array([1.1, 2.2])

[1.1, 2.2]
Length: 2, dtype: Float64

---->   pandas.array

--------------------------------------
ID: 6713 --> 1
>>> pd.array(["a", None, "c"])

['a', , 'c']
Length: 3, dtype: string

---->   pandas.array

--------------------------------------
ID: 6714 --> 1
>>> with pd.option_context("string_storage", "pyarrow"):
...     arr = pd.array(["a", None, "c"])
...
>>> arr

['a', , 'c']
Length: 3, dtype: string

---->   pandas.array

--------------------------------------
ID: 6715 --> 2
>>> pd.array([pd.Period('2000', freq="D"), pd.Period("2000", freq="D")])

['2000-01-01', '2000-01-01']
Length: 2, dtype: period[D]

---->   pandas.array; pandas.Period

--------------------------------------
ID: 6716 --> 1
>>> pd.array(['a', 'b', 'a'], dtype='category')
['a', 'b', 'a']
Categories (2, object): ['a', 'b']

---->   pandas.array

--------------------------------------
ID: 6717 --> 2
>>> pd.array(['a', 'b', 'a'],
...          dtype=pd.CategoricalDtype(['a', 'b', 'c'], ordered=True))
['a', 'b', 'a']
Categories (3, object): ['a' < 'b' < 'c']

---->   pandas.array; pandas.CategoricalDtype

--------------------------------------
ID: 6718 --> 1
>>> pd.array([1 + 1j, 3 + 2j])

[(1+1j), (3+2j)]
Length: 2, dtype: complex128

---->   pandas.array

--------------------------------------
ID: 6719 --> 1
>>> pd.array([1, 2], dtype=np.dtype("int32"))

[1, 2]
Length: 2, dtype: int32

---->   pandas.array

--------------------------------------
ID: 6720 --> 1
>>> pd.array(1)
Traceback (most recent call last):
  ...
ValueError: Cannot pass scalar '1' to 'pandas.array'.

---->   pandas.array

--------------------------------------
ID: 6723 --> 1
>>> is_sparse(pd.arrays.SparseArray([0, 0, 1, 0]))
True
>>> is_sparse(pd.Series(pd.arrays.SparseArray([0, 0, 1, 0])))
True

---->   pandas.Series

--------------------------------------
ID: 6724 --> 1
>>> is_sparse(np.array([0, 0, 1, 0]))
False
>>> is_sparse(pd.Series([0, 1, 0, 0]))
False

---->   pandas.Series

--------------------------------------
ID: 6739 --> 2
>>> from pandas.api.types import is_numeric_dtype
>>> is_numeric_dtype(str)
False
>>> is_numeric_dtype(int)
True
>>> is_numeric_dtype(float)
True
>>> is_numeric_dtype(np.uint64)
True
>>> is_numeric_dtype(np.datetime64)
False
>>> is_numeric_dtype(np.timedelta64)
False
>>> is_numeric_dtype(np.array(['a', 'b']))
False
>>> is_numeric_dtype(pd.Series([1, 2]))
True
>>> is_numeric_dtype(pd.Index([1, 2.]))
True
>>> is_numeric_dtype(np.array([], dtype=np.timedelta64))
False

---->   pandas.Series; pandas.Index

--------------------------------------
ID: 6756 --> 2
>>> is_interval_dtype(object)
False
>>> is_interval_dtype(IntervalDtype())
True
>>> is_interval_dtype([1, 2, 3])
False
>>>
>>> interval = pd.Interval(1, 2, closed="right")
>>> is_interval_dtype(interval)
False
>>> is_interval_dtype(pd.IntervalIndex([interval]))
True

---->   pandas.Interval; pandas.IntervalIndex

--------------------------------------
ID: 6758 --> 1
>>> ts.tz_convert(tz='Asia/Tokyo')
Timestamp('2020-03-15 00:32:52.192548651+0900', tz='Asia/Tokyo')

---->   Series.tz_convert

--------------------------------------
ID: 6761 --> 1
>>> pd.StringDtype()
string[python]

---->   pandas.StringDtype

--------------------------------------
ID: 6762 --> 1
>>> pd.StringDtype(storage="pyarrow")
string[pyarrow]

---->   pandas.StringDtype

--------------------------------------
ID: 6763 --> 2
>>> from pandas.api.types import is_bool_dtype
>>> is_bool_dtype(str)
False
>>> is_bool_dtype(int)
False
>>> is_bool_dtype(bool)
True
>>> is_bool_dtype(np.bool_)
True
>>> is_bool_dtype(np.array(['a', 'b']))
False
>>> is_bool_dtype(pd.Series([1, 2]))
False
>>> is_bool_dtype(np.array([True, False]))
True
>>> is_bool_dtype(pd.Categorical([True, False]))
True
>>> is_bool_dtype(pd.arrays.SparseArray([True, False]))
True

---->   pandas.Series; pandas.Categorical

--------------------------------------
ID: 6764 --> 1
>>> per = pd.Period('2017-12-31 22:00', 'H')
>>> per.dayofweek
6

---->   pandas.Period

--------------------------------------
ID: 6765 --> 1
>>> per = pd.Period('2017-12-31 22:00', '4H')
>>> per.dayofweek
6
>>> per.start_time.dayofweek
6

---->   pandas.Period

--------------------------------------
ID: 6766 --> 1
>>> per = pd.Period('2018-01', 'M')
>>> per.dayofweek
2
>>> per.end_time.dayofweek
2

---->   pandas.Period

--------------------------------------
ID: 6770 --> 1
>>> from pandas.api.types import is_complex_dtype
>>> is_complex_dtype(str)
False
>>> is_complex_dtype(int)
False
>>> is_complex_dtype(np.complex_)
True
>>> is_complex_dtype(np.array(['a', 'b']))
False
>>> is_complex_dtype(pd.Series([1, 2]))
False
>>> is_complex_dtype(np.array([1 + 1j, 5]))
True

---->   pandas.Series

--------------------------------------
ID: 6772 --> 1
>>> pd.array(['a', 'b'], dtype=str)

['a', 'b']
Length: 2, dtype: str32

---->   pandas.array

--------------------------------------
ID: 6773 --> 1
>>> pd.array(['a', 'b'], dtype=np.dtype("))

['a', 'b']
Length: 2, dtype: str32

---->   pandas.array

--------------------------------------
ID: 6774 --> 1
>>> pd.array(['2015', '2016'], dtype='datetime64[ns]')

['2015-01-01 00:00:00', '2016-01-01 00:00:00']
Length: 2, dtype: datetime64[ns]

---->   pandas.array

--------------------------------------
ID: 6775 --> 1
>>> pd.array(["1H", "2H"], dtype='timedelta64[ns]')

['0 days 01:00:00', '0 days 02:00:00']
Length: 2, dtype: timedelta64[ns]

---->   pandas.array

--------------------------------------
ID: 6776 --> 1
>>> pd.array([1, 2])

[1, 2]
Length: 2, dtype: Int64

---->   pandas.array

--------------------------------------
ID: 6777 --> 1
>>> pd.array([1, 2, np.nan])

[1, 2, ]
Length: 3, dtype: Int64

---->   pandas.array

--------------------------------------
ID: 6778 --> 1
>>> pd.array([1.1, 2.2])

[1.1, 2.2]
Length: 2, dtype: Float64

---->   pandas.array

--------------------------------------
ID: 6779 --> 1
>>> pd.array(["a", None, "c"])

['a', , 'c']
Length: 3, dtype: string

---->   pandas.array

--------------------------------------
ID: 6780 --> 1
>>> with pd.option_context("string_storage", "pyarrow"):
...     arr = pd.array(["a", None, "c"])
...
>>> arr

['a', , 'c']
Length: 3, dtype: string

---->   pandas.array

--------------------------------------
ID: 6781 --> 2
>>> pd.array([pd.Period('2000', freq="D"), pd.Period("2000", freq="D")])

['2000-01-01', '2000-01-01']
Length: 2, dtype: period[D]

---->   pandas.array; pandas.Period

--------------------------------------
ID: 6782 --> 1
>>> pd.array(['a', 'b', 'a'], dtype='category')
['a', 'b', 'a']
Categories (2, object): ['a', 'b']

---->   pandas.array

--------------------------------------
ID: 6783 --> 2
>>> pd.array(['a', 'b', 'a'],
...          dtype=pd.CategoricalDtype(['a', 'b', 'c'], ordered=True))
['a', 'b', 'a']
Categories (3, object): ['a' < 'b' < 'c']

---->   pandas.array; pandas.CategoricalDtype

--------------------------------------
ID: 6784 --> 1
>>> pd.array([1 + 1j, 3 + 2j])

[(1+1j), (3+2j)]
Length: 2, dtype: complex128

---->   pandas.array

--------------------------------------
ID: 6785 --> 1
>>> pd.array([1, 2], dtype=np.dtype("int32"))

[1, 2]
Length: 2, dtype: int32

---->   pandas.array

--------------------------------------
ID: 6786 --> 1
>>> pd.array(1)
Traceback (most recent call last):
  ...
ValueError: Cannot pass scalar '1' to 'pandas.array'.

---->   pandas.array

--------------------------------------
ID: 6787 --> 2
>>> is_signed_integer_dtype(str)
False
>>> is_signed_integer_dtype(int)
True
>>> is_signed_integer_dtype(float)
False
>>> is_signed_integer_dtype(np.uint64)  # unsigned
False
>>> is_signed_integer_dtype('int8')
True
>>> is_signed_integer_dtype('Int8')
True
>>> is_signed_integer_dtype(pd.Int8Dtype)
True
>>> is_signed_integer_dtype(np.datetime64)
False
>>> is_signed_integer_dtype(np.timedelta64)
False
>>> is_signed_integer_dtype(np.array(['a', 'b']))
False
>>> is_signed_integer_dtype(pd.Series([1, 2]))
True
>>> is_signed_integer_dtype(np.array([], dtype=np.timedelta64))
False
>>> is_signed_integer_dtype(pd.Index([1, 2.]))  # float
False
>>> is_signed_integer_dtype(np.array([1, 2], dtype=np.uint32))  # unsigned
False

---->   pandas.Series; pandas.Index

--------------------------------------
ID: 6790 --> 1
>>> iv = pd.Interval(0, 5, closed='neither')
>>> iv.open_left
True

---->   pandas.Interval

--------------------------------------
ID: 6791 --> 1
>>> iv = pd.Interval(0, 5, closed='both')
>>> iv.open_left
False

---->   pandas.Interval

--------------------------------------
ID: 6794 --> 1
>>> iv = pd.Interval(left=0, right=5)
>>> iv
Interval(0, 5, closed='right')

---->   pandas.Interval

--------------------------------------
ID: 6795 --> 1
>>> 2.5 in iv
True
>>> pd.Interval(left=2, right=5, closed='both') in iv
True

---->   pandas.Interval

--------------------------------------
ID: 6797 --> 1
>>> year_2017 = pd.Interval(pd.Timestamp('2017-01-01 00:00:00'),
...                         pd.Timestamp('2018-01-01 00:00:00'),
...                         closed='left')
>>> pd.Timestamp('2017-01-01 00:00') in year_2017
True
>>> year_2017.length
Timedelta('365 days 00:00:00')

---->   pandas.Interval

--------------------------------------
ID: 6798 --> 1
>>> from pandas.api.types import is_int64_dtype
>>> is_int64_dtype(str)
False
>>> is_int64_dtype(np.int32)
False
>>> is_int64_dtype(np.int64)
True
>>> is_int64_dtype('int8')
False
>>> is_int64_dtype('Int8')
False
>>> is_int64_dtype(pd.Int64Dtype)
True
>>> is_int64_dtype(float)
False
>>> is_int64_dtype(np.uint64)  # unsigned
False
>>> is_int64_dtype(np.array(['a', 'b']))
False
>>> is_int64_dtype(np.array([1, 2], dtype=np.int64))
True
>>> is_int64_dtype(pd.Index([1, 2.]))  # float
False
>>> is_int64_dtype(np.array([1, 2], dtype=np.uint32))  # unsigned
False

---->   pandas.Index

--------------------------------------
ID: 6799 --> 1
>>> is_string_dtype(str)
True
>>> is_string_dtype(object)
True
>>> is_string_dtype(int)
False
>>> is_string_dtype(np.array(['a', 'b']))
True
>>> is_string_dtype(pd.Series([1, 2]))
False
>>> is_string_dtype(pd.Series([1, 2], dtype=object))
False

---->   pandas.Series

--------------------------------------
ID: 6800 --> 1
>>> pd.IntervalDtype(subtype='int64', closed='both')
interval[int64, both]

---->   pandas.IntervalDtype

--------------------------------------
ID: 6801 --> 1
>>> per = pd.Period('2017-12-31 22:00', 'H')
>>> per.day_of_week
6

---->   pandas.Period

--------------------------------------
ID: 6802 --> 1
>>> per = pd.Period('2017-12-31 22:00', '4H')
>>> per.day_of_week
6
>>> per.start_time.day_of_week
6

---->   pandas.Period

--------------------------------------
ID: 6803 --> 1
>>> per = pd.Period('2018-01', 'M')
>>> per.day_of_week
2
>>> per.end_time.day_of_week
2

---->   pandas.Period

--------------------------------------
ID: 6807 --> 1
>>> p = pd.Period("2018-03-11", "H")
>>> p.weekofyear
10

---->   pandas.Period

--------------------------------------
ID: 6808 --> 1
>>> p = pd.Period("2018-02-01", "D")
>>> p.weekofyear
5

---->   pandas.Period

--------------------------------------
ID: 6809 --> 1
>>> p = pd.Period("2018-01-06", "D")
>>> p.weekofyear
1

---->   pandas.Period

--------------------------------------
ID: 6812 --> 1
>>> iv = pd.Interval(0, 5, closed='left')
>>> iv.closed_left
True

---->   pandas.Interval

--------------------------------------
ID: 6813 --> 1
>>> iv = pd.Interval(0, 5, closed='right')
>>> iv.closed_left
False

---->   pandas.Interval

--------------------------------------
ID: 6826 --> 1
>>> p = pd.Period('2018-2-17')
>>> p.days_in_month
28

---->   pandas.Period

--------------------------------------
ID: 6827 --> 1
>>> pd.Period('2018-03-01').days_in_month
31

---->   pandas.Period

--------------------------------------
ID: 6828 --> 1
>>> p = pd.Period('2016-2-17')
>>> p.days_in_month
29

---->   pandas.Period

--------------------------------------
ID: 6829 --> 1
>>> is_datetime64tz_dtype(object)
False
>>> is_datetime64tz_dtype([1, 2, 3])
False
>>> is_datetime64tz_dtype(pd.DatetimeIndex([1, 2, 3]))  # tz-naive
False
>>> is_datetime64tz_dtype(pd.DatetimeIndex([1, 2, 3], tz="US/Eastern"))
True

---->   pandas.DatetimeIndex

--------------------------------------
ID: 6830 --> 1
>>> dtype = DatetimeTZDtype("ns", tz="US/Eastern")
>>> s = pd.Series([], dtype=dtype)
>>> is_datetime64tz_dtype(dtype)
True
>>> is_datetime64tz_dtype(s)
True

---->   pandas.Series

--------------------------------------
ID: 6831 --> 2
>>> int_array = pd.array([1, None, 3], dtype=pd.Int32Dtype())
>>> int_array

[1, , 3]
Length: 3, dtype: Int32

---->   pandas.array; pandas.Int32Dtype

--------------------------------------
ID: 6832 --> 1
>>> pd.array([1, None, 3], dtype='Int32')

[1, , 3]
Length: 3, dtype: Int32

---->   pandas.array

--------------------------------------
ID: 6833 --> 1
>>> pd.array([1, None, 3], dtype='UInt16')

[1, , 3]
Length: 3, dtype: UInt16

---->   pandas.array

--------------------------------------
ID: 6838 --> 1
>>> pd.PeriodDtype(freq='D')
period[D]

---->   pandas.PeriodDtype

--------------------------------------
ID: 6839 --> 1
>>> pd.PeriodDtype(freq=pd.offsets.MonthEnd())
period[M]

---->   pandas.PeriodDtype

--------------------------------------
ID: 6841 --> 1
>>> pd.Categorical([1, 2, 3, 1, 2, 3])
[1, 2, 3, 1, 2, 3]
Categories (3, int64): [1, 2, 3]

---->   pandas.Categorical

--------------------------------------
ID: 6842 --> 1
>>> pd.Categorical(['a', 'b', 'c', 'a', 'b', 'c'])
['a', 'b', 'c', 'a', 'b', 'c']
Categories (3, object): ['a', 'b', 'c']

---->   pandas.Categorical

--------------------------------------
ID: 6843 --> 1
>>> c = pd.Categorical([1, 2, 3, 1, 2, 3, np.nan])
>>> c
[1, 2, 3, 1, 2, 3, NaN]
Categories (3, int64): [1, 2, 3]

---->   pandas.Categorical

--------------------------------------
ID: 6845 --> 1
>>> c = pd.Categorical(['a', 'b', 'c', 'a', 'b', 'c'], ordered=True,
...                    categories=['c', 'b', 'a'])
>>> c
['a', 'b', 'c', 'a', 'b', 'c']
Categories (3, object): ['c' < 'b' < 'a']
>>> c.min()
'c'

---->   pandas.Categorical

--------------------------------------
ID: 6847 --> 1
>>> ts = pd.Timestamp('2020-03-14T15:32:52.192548651')
>>> # Year end frequency
>>> ts.to_period(freq='Y')
Period('2020', 'A-DEC')

---->   Series.to_period

--------------------------------------
ID: 6848 --> 1
>>> # Month end frequency
>>> ts.to_period(freq='M')
Period('2020-03', 'M')

---->   Series.to_period

--------------------------------------
ID: 6849 --> 1
>>> # Weekly frequency
>>> ts.to_period(freq='W')
Period('2020-03-09/2020-03-15', 'W-SUN')

---->   Series.to_period

--------------------------------------
ID: 6850 --> 1
>>> # Quarter end frequency
>>> ts.to_period(freq='Q')
Period('2020Q1', 'Q-DEC')

---->   Series.to_period

--------------------------------------
ID: 6851 --> 1
>>> period = pd.Period('2012-1-1', freq='D')
>>> period
Period('2012-01-01', 'D')

---->   pandas.Period

--------------------------------------
ID: 6852 --> 1
>>> mask = pd.array([True, False])
>>> arr = pd.array([1, 2])
>>> pd.api.indexers.check_array_indexer(arr, mask)
array([ True, False])

---->   pandas.array

--------------------------------------
ID: 6853 --> 1
>>> mask = pd.array([True, False, True])
>>> pd.api.indexers.check_array_indexer(arr, mask)
Traceback (most recent call last):
...
IndexError: Boolean index has wrong length: 3 instead of 2.

---->   pandas.array

--------------------------------------
ID: 6854 --> 1
>>> mask = pd.array([True, pd.NA])
>>> pd.api.indexers.check_array_indexer(arr, mask)
array([ True, False])

---->   pandas.array

--------------------------------------
ID: 6856 --> 1
>>> indexer = pd.array([0, 2], dtype="Int64")
>>> arr = pd.array([1, 2, 3])
>>> pd.api.indexers.check_array_indexer(arr, indexer)
array([0, 2])

---->   pandas.array

--------------------------------------
ID: 6857 --> 1
>>> indexer = pd.array([0, pd.NA], dtype="Int64")
>>> pd.api.indexers.check_array_indexer(arr, indexer)
Traceback (most recent call last):
...
ValueError: Cannot index with an integer indexer containing NA values

---->   pandas.array

--------------------------------------
ID: 6859 --> 1
>>> iv = pd.Interval(0, 5)
>>> iv.mid
2.5

---->   pandas.Interval

--------------------------------------
ID: 6862 --> 1
>>> pd.Series(['a', 'b']).dt
Traceback (most recent call last):
...
AttributeError: Can only use .dt accessor with datetimelike values

---->   pandas.Series

--------------------------------------
ID: 6864 --> 1
In [1]: ds = pd.DataFrame({"longitude": np.linspace(0, 10),
   ...:                    "latitude": np.linspace(0, 20)})
In [2]: ds.geo.center
Out[2]: (5.0, 10.0)
In [3]: ds.geo.plot()  # plots data on a map

---->   pandas.DataFrame

--------------------------------------
ID: 6866 --> 1
>>> pd.Series(['a', 'b']).dt
Traceback (most recent call last):
...
AttributeError: Can only use .dt accessor with datetimelike values

---->   pandas.Series

--------------------------------------
ID: 6868 --> 1
In [1]: ds = pd.DataFrame({"longitude": np.linspace(0, 10),
   ...:                    "latitude": np.linspace(0, 20)})
In [2]: ds.geo.center
Out[2]: (5.0, 10.0)
In [3]: ds.geo.plot()  # plots data on a map

---->   pandas.DataFrame

--------------------------------------
ID: 6869 --> 1
>>> df = pd.DataFrame([1e-9, 1e-3, 1, 1e3, 1e6])
>>> df
              0
0  1.000000e-09
1  1.000000e-03
2  1.000000e+00
3  1.000000e+03
4  1.000000e+06

---->   pandas.DataFrame

--------------------------------------
ID: 6870 --> 1
>>> pd.set_eng_float_format(accuracy=1)
>>> df
         0
0  1.0E-09
1  1.0E-03
2  1.0E+00
3  1.0E+03
4  1.0E+06

---->   pandas.set_eng_float_format

--------------------------------------
ID: 6871 --> 1
>>> pd.set_eng_float_format(use_eng_prefix=True)
>>> df
        0
0  1.000n
1  1.000m
2   1.000
3  1.000k
4  1.000M

---->   pandas.set_eng_float_format

--------------------------------------
ID: 6872 --> 1
>>> pd.set_eng_float_format(accuracy=1, use_eng_prefix=True)
>>> df
      0
0  1.0n
1  1.0m
2   1.0
3  1.0k
4  1.0M

---->   pandas.set_eng_float_format

--------------------------------------
ID: 6874 --> 2
>>> np.random.seed(1234)
>>> df = pd.DataFrame(np.random.randn(10, 4),
...                   columns=['Col1', 'Col2', 'Col3', 'Col4'])
>>> boxplot = df.boxplot(column=['Col1', 'Col2', 'Col3'])  

---->   pandas.DataFrame; DataFrame.boxplot

--------------------------------------
ID: 6875 --> 3
>>> df = pd.DataFrame(np.random.randn(10, 2),
...                   columns=['Col1', 'Col2'])
>>> df['X'] = pd.Series(['A', 'A', 'A', 'A', 'A',
...                      'B', 'B', 'B', 'B', 'B'])
>>> boxplot = df.boxplot(by='X')

---->   pandas.DataFrame; pandas.Series; DataFrame.boxplot

--------------------------------------
ID: 6876 --> 3
>>> df = pd.DataFrame(np.random.randn(10, 3),
...                   columns=['Col1', 'Col2', 'Col3'])
>>> df['X'] = pd.Series(['A', 'A', 'A', 'A', 'A',
...                      'B', 'B', 'B', 'B', 'B'])
>>> df['Y'] = pd.Series(['A', 'B', 'A', 'B', 'A',
...                      'B', 'A', 'B', 'A', 'B'])
>>> boxplot = df.boxplot(column=['Col1', 'Col2'], by=['X', 'Y'])

---->   pandas.DataFrame; pandas.Series; DataFrame.boxplot

--------------------------------------
ID: 6877 --> 1
>>> boxplot = df.boxplot(column=['Col1', 'Col2'], by='X',
...                      layout=(2, 1))

---->   DataFrame.boxplot

--------------------------------------
ID: 6878 --> 1
>>> boxplot = df.boxplot(grid=False, rot=45, fontsize=15)  

---->   DataFrame.boxplot

--------------------------------------
ID: 6879 --> 1
>>> boxplot = df.boxplot(column=['Col1', 'Col2'], return_type='axes')
>>> type(boxplot)


---->   DataFrame.boxplot

--------------------------------------
ID: 6880 --> 1
>>> boxplot = df.boxplot(column=['Col1', 'Col2'], by='X',
...                      return_type='axes')
>>> type(boxplot)


---->   DataFrame.boxplot

--------------------------------------
ID: 6881 --> 1
>>> boxplot = df.boxplot(column=['Col1', 'Col2'], by='X',
...                      return_type=None)
>>> type(boxplot)


---->   DataFrame.boxplot

--------------------------------------
ID: 6883 --> 1
>>> period = pd.Period("2015-10-23", freq='H')
>>> period.day_of_year
296
>>> period = pd.Period("2012-12-31", freq='D')
>>> period.day_of_year
366
>>> period = pd.Period("2013-01-01", freq='D')
>>> period.day_of_year
1

---->   pandas.Period

--------------------------------------
ID: 6886 --> 1
>>> pd.Series(['a', 'b']).dt
Traceback (most recent call last):
...
AttributeError: Can only use .dt accessor with datetimelike values

---->   pandas.Series

--------------------------------------
ID: 6888 --> 1
In [1]: ds = pd.DataFrame({"longitude": np.linspace(0, 10),
   ...:                    "latitude": np.linspace(0, 20)})
In [2]: ds.geo.center
Out[2]: (5.0, 10.0)
In [3]: ds.geo.plot()  # plots data on a map

---->   pandas.DataFrame

--------------------------------------
ID: 6889 --> 1
>>> df = pd.DataFrame(np.random.randn(1000, 4), columns=['A','B','C','D'])
>>> pd.plotting.scatter_matrix(df, alpha=0.2)
array([[,
    ,
    ,
    ],
   [,
    ,
    ,
    ],
   [,
    ,
    ,
    ],
   [,
    ,
    ,
    ]], dtype=object)

---->   pandas.DataFrame

--------------------------------------
ID: 6890 --> 1
>>> df = pd.DataFrame(
...     {
...         'SepalLength': [6.5, 7.7, 5.1, 5.8, 7.6, 5.0, 5.4, 4.6, 6.7, 4.6],
...         'SepalWidth': [3.0, 3.8, 3.8, 2.7, 3.0, 2.3, 3.0, 3.2, 3.3, 3.6],
...         'PetalLength': [5.5, 6.7, 1.9, 5.1, 6.6, 3.3, 4.5, 1.4, 5.7, 1.0],
...         'PetalWidth': [1.8, 2.2, 0.4, 1.9, 2.1, 1.0, 1.5, 0.2, 2.1, 0.2],
...         'Category': [
...             'virginica',
...             'virginica',
...             'setosa',
...             'virginica',
...             'virginica',
...             'versicolor',
...             'versicolor',
...             'setosa',
...             'virginica',
...             'setosa'
...         ]
...     }
... )
>>> pd.plotting.radviz(df, 'Category')


---->   pandas.DataFrame

--------------------------------------
ID: 6892 --> 2
>>> np.random.seed(5)
>>> x = np.cumsum(np.random.normal(loc=1, scale=5, size=50))
>>> s = pd.Series(x)
>>> s.plot()


---->   pandas.Series; Series.plot

--------------------------------------
ID: 6894 --> 2
>>> np.random.seed(1234)
>>> df = pd.DataFrame(np.random.randn(10, 4),
...                   columns=['Col1', 'Col2', 'Col3', 'Col4'])
>>> boxplot = df.boxplot(column=['Col1', 'Col2', 'Col3'])  

---->   pandas.DataFrame; DataFrame.boxplot

--------------------------------------
ID: 6895 --> 3
>>> df = pd.DataFrame(np.random.randn(10, 2),
...                   columns=['Col1', 'Col2'])
>>> df['X'] = pd.Series(['A', 'A', 'A', 'A', 'A',
...                      'B', 'B', 'B', 'B', 'B'])
>>> boxplot = df.boxplot(by='X')

---->   pandas.DataFrame; pandas.Series; DataFrame.boxplot

--------------------------------------
ID: 6896 --> 3
>>> df = pd.DataFrame(np.random.randn(10, 3),
...                   columns=['Col1', 'Col2', 'Col3'])
>>> df['X'] = pd.Series(['A', 'A', 'A', 'A', 'A',
...                      'B', 'B', 'B', 'B', 'B'])
>>> df['Y'] = pd.Series(['A', 'B', 'A', 'B', 'A',
...                      'B', 'A', 'B', 'A', 'B'])
>>> boxplot = df.boxplot(column=['Col1', 'Col2'], by=['X', 'Y'])

---->   pandas.DataFrame; pandas.Series; DataFrame.boxplot

--------------------------------------
ID: 6897 --> 1
>>> boxplot = df.boxplot(column=['Col1', 'Col2'], by='X',
...                      layout=(2, 1))

---->   DataFrame.boxplot

--------------------------------------
ID: 6898 --> 1
>>> boxplot = df.boxplot(grid=False, rot=45, fontsize=15)  

---->   DataFrame.boxplot

--------------------------------------
ID: 6899 --> 1
>>> boxplot = df.boxplot(column=['Col1', 'Col2'], return_type='axes')
>>> type(boxplot)


---->   DataFrame.boxplot

--------------------------------------
ID: 6900 --> 1
>>> boxplot = df.boxplot(column=['Col1', 'Col2'], by='X',
...                      return_type='axes')
>>> type(boxplot)


---->   DataFrame.boxplot

--------------------------------------
ID: 6901 --> 1
>>> boxplot = df.boxplot(column=['Col1', 'Col2'], by='X',
...                      return_type=None)
>>> type(boxplot)


---->   DataFrame.boxplot

--------------------------------------
ID: 6903 --> 1
>>> s1 = pd.Series(['a', 'b'])
>>> s2 = pd.Series(['c', 'd'])
>>> pd.concat([s1, s2])
0    a
1    b
0    c
1    d
dtype: object

---->   pandas.Series

--------------------------------------
ID: 6907 --> 1
>>> df1 = pd.DataFrame([['a', 1], ['b', 2]],
...                    columns=['letter', 'number'])
>>> df1
  letter  number
0      a       1
1      b       2
>>> df2 = pd.DataFrame([['c', 3], ['d', 4]],
...                    columns=['letter', 'number'])
>>> df2
  letter  number
0      c       3
1      d       4
>>> pd.concat([df1, df2])
  letter  number
0      a       1
1      b       2
0      c       3
1      d       4

---->   pandas.DataFrame

--------------------------------------
ID: 6908 --> 1
>>> df3 = pd.DataFrame([['c', 3, 'cat'], ['d', 4, 'dog']],
...                    columns=['letter', 'number', 'animal'])
>>> df3
  letter  number animal
0      c       3    cat
1      d       4    dog
>>> pd.concat([df1, df3], sort=False)
  letter  number animal
0      a       1    NaN
1      b       2    NaN
0      c       3    cat
1      d       4    dog

---->   pandas.DataFrame

--------------------------------------
ID: 6910 --> 1
>>> df4 = pd.DataFrame([['bird', 'polly'], ['monkey', 'george']],
...                    columns=['animal', 'name'])
>>> pd.concat([df1, df4], axis=1)
  letter  number  animal    name
0      a       1    bird   polly
1      b       2  monkey  george

---->   pandas.DataFrame

--------------------------------------
ID: 6911 --> 1
>>> df5 = pd.DataFrame([1], index=['a'])
>>> df5
   0
a  1
>>> df6 = pd.DataFrame([2], index=['a'])
>>> df6
   0
a  2
>>> pd.concat([df5, df6], verify_integrity=True)
Traceback (most recent call last):
    ...
ValueError: Indexes have overlapping values: ['a']

---->   pandas.DataFrame

--------------------------------------
ID: 6912 --> 3
>>> df7 = pd.DataFrame({'a': 1, 'b': 2}, index=[0])
>>> df7
    a   b
0   1   2
>>> new_row = pd.Series({'a': 3, 'b': 4})
>>> new_row
a    3
b    4
dtype: int64
>>> pd.concat([df7, new_row.to_frame().T], ignore_index=True)
    a   b
0   1   2
1   3   4

---->   pandas.DataFrame; pandas.Series; Series.to_frame

--------------------------------------
ID: 6913 --> 1
>>> spacing = np.linspace(-9 * np.pi, 9 * np.pi, num=1000)
>>> s = pd.Series(0.7 * np.random.rand(1000) + 0.3 * np.sin(spacing))
>>> pd.plotting.autocorrelation_plot(s)


---->   pandas.Series

--------------------------------------
ID: 6914 --> 1
>>> a = np.array(["foo", "foo", "foo", "foo", "bar", "bar",
...               "bar", "bar", "foo", "foo", "foo"], dtype=object)
>>> b = np.array(["one", "one", "one", "two", "one", "one",
...               "one", "two", "two", "two", "one"], dtype=object)
>>> c = np.array(["dull", "dull", "shiny", "dull", "dull", "shiny",
...               "shiny", "dull", "shiny", "shiny", "shiny"],
...              dtype=object)
>>> pd.crosstab(a, [b, c], rownames=['a'], colnames=['b', 'c'])
b   one        two
c   dull shiny dull shiny
a
bar    1     2    1     0
foo    2     2    1     2

---->   pandas.crosstab

--------------------------------------
ID: 6915 --> 2
>>> foo = pd.Categorical(['a', 'b'], categories=['a', 'b', 'c'])
>>> bar = pd.Categorical(['d', 'e'], categories=['d', 'e', 'f'])
>>> pd.crosstab(foo, bar)
col_0  d  e
row_0
a      1  0
b      0  1
>>> pd.crosstab(foo, bar, dropna=False)
col_0  d  e  f
row_0
a      1  0  0
b      0  1  0
c      0  0  0

---->   pandas.Categorical; pandas.crosstab

--------------------------------------
ID: 6916 --> 1
>>> df = pd.DataFrame(
...     {
...         'SepalLength': [6.5, 7.7, 5.1, 5.8, 7.6, 5.0, 5.4, 4.6, 6.7, 4.6],
...         'SepalWidth': [3.0, 3.8, 3.8, 2.7, 3.0, 2.3, 3.0, 3.2, 3.3, 3.6],
...         'PetalLength': [5.5, 6.7, 1.9, 5.1, 6.6, 3.3, 4.5, 1.4, 5.7, 1.0],
...         'PetalWidth': [1.8, 2.2, 0.4, 1.9, 2.1, 1.0, 1.5, 0.2, 2.1, 0.2],
...         'Category': [
...             'virginica',
...             'virginica',
...             'setosa',
...             'virginica',
...             'virginica',
...             'versicolor',
...             'versicolor',
...             'setosa',
...             'virginica',
...             'setosa'
...         ]
...     }
... )
>>> pd.plotting.radviz(df, 'Category')


---->   pandas.DataFrame

--------------------------------------
ID: 6917 --> 1
>>> data = pd.DataFrame({'hr1': [514, 573], 'hr2': [545, 526],
...                      'team': ['Red Sox', 'Yankees'],
...                      'year1': [2007, 2007], 'year2': [2008, 2008]})
>>> data
   hr1  hr2     team  year1  year2
0  514  545  Red Sox   2007   2008
1  573  526  Yankees   2007   2008

---->   pandas.DataFrame

--------------------------------------
ID: 6918 --> 1
>>> pd.lreshape(data, {'year': ['year1', 'year2'], 'hr': ['hr1', 'hr2']})
      team  year   hr
0  Red Sox  2007  514
1  Yankees  2007  573
2  Red Sox  2008  545
3  Yankees  2008  526

---->   pandas.lreshape

--------------------------------------
ID: 6919 --> 1
>>> from pandas import merge_ordered
>>> df1 = pd.DataFrame(
...     {
...         "key": ["a", "c", "e", "a", "c", "e"],
...         "lvalue": [1, 2, 3, 1, 2, 3],
...         "group": ["a", "a", "a", "b", "b", "b"]
...     }
... )
>>> df1
      key  lvalue group
0   a       1     a
1   c       2     a
2   e       3     a
3   a       1     b
4   c       2     b
5   e       3     b

---->   pandas.DataFrame

--------------------------------------
ID: 6920 --> 1
>>> df2 = pd.DataFrame({"key": ["b", "c", "d"], "rvalue": [1, 2, 3]})
>>> df2
      key  rvalue
0   b       1
1   c       2
2   d       3

---->   pandas.DataFrame

--------------------------------------
ID: 6922 --> 1
>>> pd.interval_range(start=0, end=5)
IntervalIndex([(0, 1], (1, 2], (2, 3], (3, 4], (4, 5]],
              dtype='interval[int64, right]')

---->   pandas.interval_range

--------------------------------------
ID: 6923 --> 1
>>> pd.interval_range(start=pd.Timestamp('2017-01-01'),
...                   end=pd.Timestamp('2017-01-04'))
IntervalIndex([(2017-01-01, 2017-01-02], (2017-01-02, 2017-01-03],
               (2017-01-03, 2017-01-04]],
              dtype='interval[datetime64[ns], right]')

---->   pandas.interval_range

--------------------------------------
ID: 6924 --> 1
>>> pd.interval_range(start=0, periods=4, freq=1.5)
IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]],
              dtype='interval[float64, right]')

---->   pandas.interval_range

--------------------------------------
ID: 6925 --> 1
>>> pd.interval_range(start=pd.Timestamp('2017-01-01'),
...                   periods=3, freq='MS')
IntervalIndex([(2017-01-01, 2017-02-01], (2017-02-01, 2017-03-01],
               (2017-03-01, 2017-04-01]],
              dtype='interval[datetime64[ns], right]')

---->   pandas.interval_range

--------------------------------------
ID: 6926 --> 1
>>> pd.interval_range(start=0, end=6, periods=4)
IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]],
          dtype='interval[float64, right]')

---->   pandas.interval_range

--------------------------------------
ID: 6927 --> 1
>>> pd.interval_range(end=5, periods=4, closed='both')
IntervalIndex([[1, 2], [2, 3], [3, 4], [4, 5]],
              dtype='interval[int64, both]')

---->   pandas.interval_range

--------------------------------------
ID: 6928 --> 1
>>> pd.cut(np.array([1, 7, 5, 4, 6, 3]), 3)
... 
[(0.994, 3.0], (5.0, 7.0], (3.0, 5.0], (3.0, 5.0], (5.0, 7.0], ...
Categories (3, interval[float64, right]): [(0.994, 3.0] < (3.0, 5.0] ...

---->   pandas.cut

--------------------------------------
ID: 6929 --> 1
>>> pd.cut(np.array([1, 7, 5, 4, 6, 3]), 3, retbins=True)
... 
([(0.994, 3.0], (5.0, 7.0], (3.0, 5.0], (3.0, 5.0], (5.0, 7.0], ...
Categories (3, interval[float64, right]): [(0.994, 3.0] < (3.0, 5.0] ...
array([0.994, 3.   , 5.   , 7.   ]))

---->   pandas.cut

--------------------------------------
ID: 6930 --> 1
>>> pd.cut(np.array([1, 7, 5, 4, 6, 3]),
...        3, labels=["bad", "medium", "good"])
['bad', 'good', 'medium', 'medium', 'good', 'bad']
Categories (3, object): ['bad' < 'medium' < 'good']

---->   pandas.cut

--------------------------------------
ID: 6931 --> 1
>>> pd.cut(np.array([1, 7, 5, 4, 6, 3]), 3,
...        labels=["B", "A", "B"], ordered=False)
['B', 'B', 'A', 'A', 'B', 'B']
Categories (2, object): ['A', 'B']

---->   pandas.cut

--------------------------------------
ID: 6932 --> 1
>>> pd.cut([0, 1, 1, 2], bins=4, labels=False)
array([0, 1, 1, 3])

---->   pandas.cut

--------------------------------------
ID: 6933 --> 2
>>> s = pd.Series(np.array([2, 4, 6, 8, 10]),
...               index=['a', 'b', 'c', 'd', 'e'])
>>> pd.cut(s, 3)
... 
a    (1.992, 4.667]
b    (1.992, 4.667]
c    (4.667, 7.333]
d     (7.333, 10.0]
e     (7.333, 10.0]
dtype: category
Categories (3, interval[float64, right]): [(1.992, 4.667] < (4.667, ...

---->   pandas.Series; pandas.cut

--------------------------------------
ID: 6934 --> 2
>>> s = pd.Series(np.array([2, 4, 6, 8, 10]),
...               index=['a', 'b', 'c', 'd', 'e'])
>>> pd.cut(s, [0, 2, 4, 6, 8, 10], labels=False, retbins=True, right=False)
... 
(a    1.0
 b    2.0
 c    3.0
 d    4.0
 e    NaN
 dtype: float64,
 array([ 0,  2,  4,  6,  8, 10]))

---->   pandas.Series; pandas.cut

--------------------------------------
ID: 6935 --> 1
>>> pd.cut(s, [0, 2, 4, 6, 10, 10], labels=False, retbins=True,
...        right=False, duplicates='drop')
... 
(a    1.0
 b    2.0
 c    3.0
 d    3.0
 e    NaN
 dtype: float64,
 array([ 0,  2,  4,  6, 10]))

---->   pandas.cut

--------------------------------------
ID: 6936 --> 2
>>> bins = pd.IntervalIndex.from_tuples([(0, 1), (2, 3), (4, 5)])
>>> pd.cut([0, 0.5, 1.5, 2.5, 4.5], bins)
[NaN, (0.0, 1.0], NaN, (2.0, 3.0], (4.0, 5.0]]
Categories (3, interval[int64, right]): [(0, 1] < (2, 3] < (4, 5]]

---->   pandas.IntervalIndex; pandas.cut

--------------------------------------
ID: 6937 --> 1
>>> s = pd.Series(np.random.uniform(size=100))
>>> pd.plotting.bootstrap_plot(s)


---->   pandas.Series

--------------------------------------
ID: 6938 --> 1
>>> pd.to_timedelta('1 days 06:05:01.00003')
Timedelta('1 days 06:05:01.000030')
>>> pd.to_timedelta('15.5us')
Timedelta('0 days 00:00:00.000015500')

---->   pandas.to_timedelta

--------------------------------------
ID: 6939 --> 1
>>> pd.to_timedelta(['1 days 06:05:01.00003', '15.5us', 'nan'])
TimedeltaIndex(['1 days 06:05:01.000030', '0 days 00:00:00.000015500', NaT],
               dtype='timedelta64[ns]', freq=None)

---->   pandas.to_timedelta

--------------------------------------
ID: 6940 --> 1
>>> pd.to_timedelta(np.arange(5), unit='s')
TimedeltaIndex(['0 days 00:00:00', '0 days 00:00:01', '0 days 00:00:02',
                '0 days 00:00:03', '0 days 00:00:04'],
               dtype='timedelta64[ns]', freq=None)
>>> pd.to_timedelta(np.arange(5), unit='d')
TimedeltaIndex(['0 days', '1 days', '2 days', '3 days', '4 days'],
               dtype='timedelta64[ns]', freq=None)

---->   pandas.to_timedelta

--------------------------------------
ID: 6941 --> 1
>>> pd.qcut(range(5), 4)
... 
[(-0.001, 1.0], (-0.001, 1.0], (1.0, 2.0], (2.0, 3.0], (3.0, 4.0]]
Categories (4, interval[float64, right]): [(-0.001, 1.0] < (1.0, 2.0] ...

---->   pandas.qcut

--------------------------------------
ID: 6942 --> 1
>>> pd.qcut(range(5), 3, labels=["good", "medium", "bad"])
... 
[good, good, medium, bad, bad]
Categories (3, object): [good < medium < bad]

---->   pandas.qcut

--------------------------------------
ID: 6943 --> 1
>>> pd.qcut(range(5), 4, labels=False)
array([0, 0, 1, 2, 3])

---->   pandas.qcut

--------------------------------------
ID: 6944 --> 2
>>> np.random.seed(123)
>>> df = pd.DataFrame({"A1970" : {0 : "a", 1 : "b", 2 : "c"},
...                    "A1980" : {0 : "d", 1 : "e", 2 : "f"},
...                    "B1970" : {0 : 2.5, 1 : 1.2, 2 : .7},
...                    "B1980" : {0 : 3.2, 1 : 1.3, 2 : .1},
...                    "X"     : dict(zip(range(3), np.random.randn(3)))
...                   })
>>> df["id"] = df.index
>>> df
  A1970 A1980  B1970  B1980         X  id
0     a     d    2.5    3.2 -1.085631   0
1     b     e    1.2    1.3  0.997345   1
2     c     f    0.7    0.1  0.282978   2
>>> pd.wide_to_long(df, ["A", "B"], i="id", j="year")
... 
                X  A    B
id year
0  1970 -1.085631  a  2.5
1  1970  0.997345  b  1.2
2  1970  0.282978  c  0.7
0  1980 -1.085631  d  3.2
1  1980  0.997345  e  1.3
2  1980  0.282978  f  0.1

---->   pandas.DataFrame; pandas.wide_to_long

--------------------------------------
ID: 6945 --> 2
>>> df = pd.DataFrame({
...     'famid': [1, 1, 1, 2, 2, 2, 3, 3, 3],
...     'birth': [1, 2, 3, 1, 2, 3, 1, 2, 3],
...     'ht1': [2.8, 2.9, 2.2, 2, 1.8, 1.9, 2.2, 2.3, 2.1],
...     'ht2': [3.4, 3.8, 2.9, 3.2, 2.8, 2.4, 3.3, 3.4, 2.9]
... })
>>> df
   famid  birth  ht1  ht2
0      1      1  2.8  3.4
1      1      2  2.9  3.8
2      1      3  2.2  2.9
3      2      1  2.0  3.2
4      2      2  1.8  2.8
5      2      3  1.9  2.4
6      3      1  2.2  3.3
7      3      2  2.3  3.4
8      3      3  2.1  2.9
>>> l = pd.wide_to_long(df, stubnames='ht', i=['famid', 'birth'], j='age')
>>> l
... 
                  ht
famid birth age
1     1     1    2.8
            2    3.4
      2     1    2.9
            2    3.8
      3     1    2.2
            2    2.9
2     1     1    2.0
            2    3.2
      2     1    1.8
            2    2.8
      3     1    1.9
            2    2.4
3     1     1    2.2
            2    3.3
      2     1    2.3
            2    3.4
      3     1    2.1
            2    2.9

---->   pandas.DataFrame; pandas.wide_to_long

--------------------------------------
ID: 6947 --> 1
>>> np.random.seed(0)
>>> df = pd.DataFrame({'A(weekly)-2010': np.random.rand(3),
...                    'A(weekly)-2011': np.random.rand(3),
...                    'B(weekly)-2010': np.random.rand(3),
...                    'B(weekly)-2011': np.random.rand(3),
...                    'X' : np.random.randint(3, size=3)})
>>> df['id'] = df.index
>>> df 
   A(weekly)-2010  A(weekly)-2011  B(weekly)-2010  B(weekly)-2011  X  id
0        0.548814        0.544883        0.437587        0.383442  0   0
1        0.715189        0.423655        0.891773        0.791725  1   1
2        0.602763        0.645894        0.963663        0.528895  1   2

---->   pandas.DataFrame

--------------------------------------
ID: 6948 --> 1
>>> pd.wide_to_long(df, ['A(weekly)', 'B(weekly)'], i='id',
...                 j='year', sep='-')
... 
         X  A(weekly)  B(weekly)
id year
0  2010  0   0.548814   0.437587
1  2010  1   0.715189   0.891773
2  2010  1   0.602763   0.963663
0  2011  0   0.544883   0.383442
1  2011  1   0.423655   0.791725
2  2011  1   0.645894   0.528895

---->   pandas.wide_to_long

--------------------------------------
ID: 6950 --> 1
>>> df = pd.DataFrame({
...     'famid': [1, 1, 1, 2, 2, 2, 3, 3, 3],
...     'birth': [1, 2, 3, 1, 2, 3, 1, 2, 3],
...     'ht_one': [2.8, 2.9, 2.2, 2, 1.8, 1.9, 2.2, 2.3, 2.1],
...     'ht_two': [3.4, 3.8, 2.9, 3.2, 2.8, 2.4, 3.3, 3.4, 2.9]
... })
>>> df
   famid  birth  ht_one  ht_two
0      1      1     2.8     3.4
1      1      2     2.9     3.8
2      1      3     2.2     2.9
3      2      1     2.0     3.2
4      2      2     1.8     2.8
5      2      3     1.9     2.4
6      3      1     2.2     3.3
7      3      2     2.3     3.4
8      3      3     2.1     2.9

---->   pandas.DataFrame

--------------------------------------
ID: 6951 --> 1
>>> l = pd.wide_to_long(df, stubnames='ht', i=['famid', 'birth'], j='age',
...                     sep='_', suffix=r'\w+')
>>> l
... 
                  ht
famid birth age
1     1     one  2.8
            two  3.4
      2     one  2.9
            two  3.8
      3     one  2.2
            two  2.9
2     1     one  2.0
            two  3.2
      2     one  1.8
            two  2.8
      3     one  1.9
            two  2.4
3     1     one  2.2
            two  3.3
      2     one  2.3
            two  3.4
      3     one  2.1
            two  2.9

---->   pandas.wide_to_long

--------------------------------------
ID: 6952 --> 1
>>> df = pd.DataFrame({"A": ["foo", "foo", "foo", "foo", "foo",
...                          "bar", "bar", "bar", "bar"],
...                    "B": ["one", "one", "one", "two", "two",
...                          "one", "one", "two", "two"],
...                    "C": ["small", "large", "large", "small",
...                          "small", "large", "small", "small",
...                          "large"],
...                    "D": [1, 2, 2, 3, 3, 4, 5, 6, 7],
...                    "E": [2, 4, 5, 5, 6, 6, 8, 9, 9]})
>>> df
     A    B      C  D  E
0  foo  one  small  1  2
1  foo  one  large  2  4
2  foo  one  large  2  5
3  foo  two  small  3  5
4  foo  two  small  3  6
5  bar  one  large  4  6
6  bar  one  small  5  8
7  bar  two  small  6  9
8  bar  two  large  7  9

---->   pandas.DataFrame

--------------------------------------
ID: 6953 --> 1
>>> table = pd.pivot_table(df, values='D', index=['A', 'B'],
...                        columns=['C'], aggfunc=np.sum)
>>> table
C        large  small
A   B
bar one    4.0    5.0
    two    7.0    6.0
foo one    4.0    1.0
    two    NaN    6.0

---->   pandas.pivot_table

--------------------------------------
ID: 6954 --> 1
>>> table = pd.pivot_table(df, values='D', index=['A', 'B'],
...                        columns=['C'], aggfunc=np.sum, fill_value=0)
>>> table
C        large  small
A   B
bar one      4      5
    two      7      6
foo one      4      1
    two      0      6

---->   pandas.pivot_table

--------------------------------------
ID: 6955 --> 1
>>> table = pd.pivot_table(df, values=['D', 'E'], index=['A', 'C'],
...                        aggfunc={'D': np.mean, 'E': np.mean})
>>> table
                D         E
A   C
bar large  5.500000  7.500000
    small  5.500000  8.500000
foo large  2.000000  4.500000
    small  2.333333  4.333333

---->   pandas.pivot_table

--------------------------------------
ID: 6956 --> 1
>>> table = pd.pivot_table(df, values=['D', 'E'], index=['A', 'C'],
...                        aggfunc={'D': np.mean,
...                                 'E': [min, max, np.mean]})
>>> table
                  D   E
               mean max      mean  min
A   C
bar large  5.500000   9  7.500000    6
    small  5.500000   9  8.500000    8
foo large  2.000000   5  4.500000    4
    small  2.333333   6  4.333333    2

---->   pandas.pivot_table

--------------------------------------
ID: 6958 --> 1
>>> df = pd.DataFrame({'foo': ['one', 'one', 'one', 'two', 'two',
...                            'two'],
...                    'bar': ['A', 'B', 'C', 'A', 'B', 'C'],
...                    'baz': [1, 2, 3, 4, 5, 6],
...                    'zoo': ['x', 'y', 'z', 'q', 'w', 't']})
>>> df
    foo   bar  baz  zoo
0   one   A    1    x
1   one   B    2    y
2   one   C    3    z
3   two   A    4    q
4   two   B    5    w
5   two   C    6    t

---->   pandas.DataFrame

--------------------------------------
ID: 6962 --> 1
>>> df = pd.DataFrame({
...        "lev1": [1, 1, 1, 2, 2, 2],
...        "lev2": [1, 1, 2, 1, 1, 2],
...        "lev3": [1, 2, 1, 2, 1, 2],
...        "lev4": [1, 2, 3, 4, 5, 6],
...        "values": [0, 1, 2, 3, 4, 5]})
>>> df
    lev1 lev2 lev3 lev4 values
0   1    1    1    1    0
1   1    1    2    2    1
2   1    2    1    3    2
3   2    1    2    4    3
4   2    1    1    5    4
5   2    2    2    6    5

---->   pandas.DataFrame

--------------------------------------
ID: 6965 --> 1
>>> df = pd.DataFrame({"foo": ['one', 'one', 'two', 'two'],
...                    "bar": ['A', 'A', 'B', 'C'],
...                    "baz": [1, 2, 3, 4]})
>>> df
   foo bar  baz
0  one   A    1
1  one   A    2
2  two   B    3
3  two   C    4

---->   pandas.DataFrame

--------------------------------------
ID: 6967 --> 1
>>> pd.isna('dog')
False

---->   pandas.isna

--------------------------------------
ID: 6968 --> 1
>>> pd.isna(pd.NA)
True

---->   pandas.isna

--------------------------------------
ID: 6969 --> 1
>>> pd.isna(np.nan)
True

---->   pandas.isna

--------------------------------------
ID: 6970 --> 1
>>> array = np.array([[1, np.nan, 3], [4, 5, np.nan]])
>>> array
array([[ 1., nan,  3.],
       [ 4.,  5., nan]])
>>> pd.isna(array)
array([[False,  True, False],
       [False, False,  True]])

---->   pandas.isna

--------------------------------------
ID: 6971 --> 2
>>> index = pd.DatetimeIndex(["2017-07-05", "2017-07-06", None,
...                           "2017-07-08"])
>>> index
DatetimeIndex(['2017-07-05', '2017-07-06', 'NaT', '2017-07-08'],
              dtype='datetime64[ns]', freq=None)
>>> pd.isna(index)
array([False, False,  True, False])

---->   pandas.DatetimeIndex; pandas.isna

--------------------------------------
ID: 6972 --> 2
>>> df = pd.DataFrame([['ant', 'bee', 'cat'], ['dog', None, 'fly']])
>>> df
     0     1    2
0  ant   bee  cat
1  dog  None  fly
>>> pd.isna(df)
       0      1      2
0  False  False  False
1  False   True  False

---->   pandas.DataFrame; pandas.isna

--------------------------------------
ID: 6973 --> 1
>>> pd.isna(df[1])
0    False
1     True
Name: 1, dtype: bool

---->   pandas.isna

--------------------------------------
ID: 6974 --> 1
>>> s = pd.Series(list('abca'))

---->   pandas.Series

--------------------------------------
ID: 6975 --> 1
>>> pd.get_dummies(s)
       a      b      c
0   True  False  False
1  False   True  False
2  False  False   True
3   True  False  False

---->   pandas.get_dummies

--------------------------------------
ID: 6976 --> 1
>>> pd.get_dummies(s1)
       a      b
0   True  False
1  False   True
2  False  False

---->   pandas.get_dummies

--------------------------------------
ID: 6977 --> 1
>>> pd.get_dummies(s1, dummy_na=True)
       a      b    NaN
0   True  False  False
1  False   True  False
2  False  False   True

---->   pandas.get_dummies

--------------------------------------
ID: 6978 --> 1
>>> df = pd.DataFrame({'A': ['a', 'b', 'a'], 'B': ['b', 'a', 'c'],
...                    'C': [1, 2, 3]})

---->   pandas.DataFrame

--------------------------------------
ID: 6979 --> 1
>>> pd.get_dummies(df, prefix=['col1', 'col2'])
   C  col1_a  col1_b  col2_a  col2_b  col2_c
0  1    True   False   False    True   False
1  2   False    True    True   False   False
2  3    True   False   False   False    True

---->   pandas.get_dummies

--------------------------------------
ID: 6980 --> 2
>>> pd.get_dummies(pd.Series(list('abcaa')))
       a      b      c
0   True  False  False
1  False   True  False
2  False  False   True
3   True  False  False
4   True  False  False

---->   pandas.get_dummies; pandas.Series

--------------------------------------
ID: 6981 --> 2
>>> pd.get_dummies(pd.Series(list('abcaa')), drop_first=True)
       b      c
0  False  False
1   True  False
2  False   True
3  False  False
4  False  False

---->   pandas.get_dummies; pandas.Series

--------------------------------------
ID: 6982 --> 2
>>> pd.get_dummies(pd.Series(list('abc')), dtype=float)
     a    b    c
0  1.0  0.0  0.0
1  0.0  1.0  0.0
2  0.0  0.0  1.0

---->   pandas.get_dummies; pandas.Series

--------------------------------------
ID: 6983 --> 1
>>> df = pd.DataFrame({'A': {0: 'a', 1: 'b', 2: 'c'},
...                    'B': {0: 1, 1: 3, 2: 5},
...                    'C': {0: 2, 1: 4, 2: 6}})
>>> df
   A  B  C
0  a  1  2
1  b  3  4
2  c  5  6

---->   pandas.DataFrame

--------------------------------------
ID: 6984 --> 1
>>> pd.melt(df, id_vars=['A'], value_vars=['B'])
   A variable  value
0  a        B      1
1  b        B      3
2  c        B      5

---->   pandas.melt

--------------------------------------
ID: 6985 --> 1
>>> pd.melt(df, id_vars=['A'], value_vars=['B', 'C'])
   A variable  value
0  a        B      1
1  b        B      3
2  c        B      5
3  a        C      2
4  b        C      4
5  c        C      6

---->   pandas.melt

--------------------------------------
ID: 6986 --> 1
>>> pd.melt(df, id_vars=['A'], value_vars=['B'],
...         var_name='myVarname', value_name='myValname')
   A myVarname  myValname
0  a         B          1
1  b         B          3
2  c         B          5

---->   pandas.melt

--------------------------------------
ID: 6987 --> 1
>>> pd.melt(df, id_vars=['A'], value_vars=['B', 'C'], ignore_index=False)
   A variable  value
0  a        B      1
1  b        B      3
2  c        B      5
0  a        C      2
1  b        C      4
2  c        C      6

---->   pandas.melt

--------------------------------------
ID: 6989 --> 1
>>> pd.melt(df, col_level=0, id_vars=['A'], value_vars=['B'])
   A variable  value
0  a        B      1
1  b        B      3
2  c        B      5

---->   pandas.melt

--------------------------------------
ID: 6990 --> 1
>>> pd.melt(df, id_vars=[('A', 'D')], value_vars=[('B', 'E')])
  (A, D) variable_0 variable_1  value
0      a          B          E      1
1      b          B          E      3
2      c          B          E      5

---->   pandas.melt

--------------------------------------
ID: 6991 --> 1
>>> codes, uniques = pd.factorize(['b', 'b', 'a', 'c', 'b'])
>>> codes
array([0, 0, 1, 2, 0])
>>> uniques
array(['b', 'a', 'c'], dtype=object)

---->   pandas.factorize

--------------------------------------
ID: 6992 --> 1
>>> codes, uniques = pd.factorize(['b', 'b', 'a', 'c', 'b'], sort=True)
>>> codes
array([1, 1, 0, 2, 1])
>>> uniques
array(['a', 'b', 'c'], dtype=object)

---->   pandas.factorize

--------------------------------------
ID: 6993 --> 1
>>> codes, uniques = pd.factorize(['b', None, 'a', 'c', 'b'])
>>> codes
array([ 0, -1,  1,  2,  0])
>>> uniques
array(['b', 'a', 'c'], dtype=object)

---->   pandas.factorize

--------------------------------------
ID: 6994 --> 2
>>> cat = pd.Categorical(['a', 'a', 'c'], categories=['a', 'b', 'c'])
>>> codes, uniques = pd.factorize(cat)
>>> codes
array([0, 0, 1])
>>> uniques
['a', 'c']
Categories (3, object): ['a', 'b', 'c']

---->   pandas.Categorical; pandas.factorize

--------------------------------------
ID: 6995 --> 2
>>> cat = pd.Series(['a', 'a', 'c'])
>>> codes, uniques = pd.factorize(cat)
>>> codes
array([0, 0, 1])
>>> uniques
Index(['a', 'c'], dtype='object')

---->   pandas.Series; pandas.factorize

--------------------------------------
ID: 6996 --> 1
>>> values = np.array([1, 2, 1, np.nan])
>>> codes, uniques = pd.factorize(values)  # default: use_na_sentinel=True
>>> codes
array([ 0,  1,  0, -1])
>>> uniques
array([1., 2.])

---->   pandas.factorize

--------------------------------------
ID: 6997 --> 1
>>> codes, uniques = pd.factorize(values, use_na_sentinel=False)
>>> codes
array([0, 1, 0, 2])
>>> uniques
array([ 1.,  2., nan])

---->   pandas.factorize

--------------------------------------
ID: 6998 --> 1
>>> idx = pd.date_range(start='2020/12/01', end='2020/12/30', periods=30)
>>> pd.infer_freq(idx)
'D'

---->   pandas.infer_freq

--------------------------------------
ID: 6999 --> 1
>>> left = pd.DataFrame({"a": [1, 5, 10], "left_val": ["a", "b", "c"]})
>>> left
    a left_val
0   1        a
1   5        b
2  10        c

---->   pandas.DataFrame

--------------------------------------
ID: 7000 --> 1
>>> right = pd.DataFrame({"a": [1, 2, 3, 6, 7], "right_val": [1, 2, 3, 6, 7]})
>>> right
   a  right_val
0  1          1
1  2          2
2  3          3
3  6          6
4  7          7

---->   pandas.DataFrame

--------------------------------------
ID: 7005 --> 1
>>> left = pd.DataFrame({"left_val": ["a", "b", "c"]}, index=[1, 5, 10])
>>> left
   left_val
1         a
5         b
10        c

---->   pandas.DataFrame

--------------------------------------
ID: 7006 --> 1
>>> right = pd.DataFrame({"right_val": [1, 2, 3, 6, 7]}, index=[1, 2, 3, 6, 7])
>>> right
   right_val
1          1
2          2
3          3
6          6
7          7

---->   pandas.DataFrame

--------------------------------------
ID: 7008 --> 1
>>> quotes = pd.DataFrame(
...     {
...         "time": [
...             pd.Timestamp("2016-05-25 13:30:00.023"),
...             pd.Timestamp("2016-05-25 13:30:00.023"),
...             pd.Timestamp("2016-05-25 13:30:00.030"),
...             pd.Timestamp("2016-05-25 13:30:00.041"),
...             pd.Timestamp("2016-05-25 13:30:00.048"),
...             pd.Timestamp("2016-05-25 13:30:00.049"),
...             pd.Timestamp("2016-05-25 13:30:00.072"),
...             pd.Timestamp("2016-05-25 13:30:00.075")
...         ],
...         "ticker": [
...                "GOOG",
...                "MSFT",
...                "MSFT",
...                "MSFT",
...                "GOOG",
...                "AAPL",
...                "GOOG",
...                "MSFT"
...            ],
...            "bid": [720.50, 51.95, 51.97, 51.99, 720.50, 97.99, 720.50, 52.01],
...            "ask": [720.93, 51.96, 51.98, 52.00, 720.93, 98.01, 720.88, 52.03]
...     }
... )
>>> quotes
                     time ticker     bid     ask
0 2016-05-25 13:30:00.023   GOOG  720.50  720.93
1 2016-05-25 13:30:00.023   MSFT   51.95   51.96
2 2016-05-25 13:30:00.030   MSFT   51.97   51.98
3 2016-05-25 13:30:00.041   MSFT   51.99   52.00
4 2016-05-25 13:30:00.048   GOOG  720.50  720.93
5 2016-05-25 13:30:00.049   AAPL   97.99   98.01
6 2016-05-25 13:30:00.072   GOOG  720.50  720.88
7 2016-05-25 13:30:00.075   MSFT   52.01   52.03

---->   pandas.DataFrame

--------------------------------------
ID: 7009 --> 1
>>> trades = pd.DataFrame(
...        {
...            "time": [
...                pd.Timestamp("2016-05-25 13:30:00.023"),
...                pd.Timestamp("2016-05-25 13:30:00.038"),
...                pd.Timestamp("2016-05-25 13:30:00.048"),
...                pd.Timestamp("2016-05-25 13:30:00.048"),
...                pd.Timestamp("2016-05-25 13:30:00.048")
...            ],
...            "ticker": ["MSFT", "MSFT", "GOOG", "GOOG", "AAPL"],
...            "price": [51.95, 51.95, 720.77, 720.92, 98.0],
...            "quantity": [75, 155, 100, 100, 100]
...        }
...    )
>>> trades
                     time ticker   price  quantity
0 2016-05-25 13:30:00.023   MSFT   51.95        75
1 2016-05-25 13:30:00.038   MSFT   51.95       155
2 2016-05-25 13:30:00.048   GOOG  720.77       100
3 2016-05-25 13:30:00.048   GOOG  720.92       100
4 2016-05-25 13:30:00.048   AAPL   98.00       100

---->   pandas.DataFrame

--------------------------------------
ID: 7013 --> 1
>>> pd.notna('dog')
True

---->   pandas.notna

--------------------------------------
ID: 7014 --> 1
>>> pd.notna(pd.NA)
False

---->   pandas.notna

--------------------------------------
ID: 7015 --> 1
>>> pd.notna(np.nan)
False

---->   pandas.notna

--------------------------------------
ID: 7016 --> 1
>>> array = np.array([[1, np.nan, 3], [4, 5, np.nan]])
>>> array
array([[ 1., nan,  3.],
       [ 4.,  5., nan]])
>>> pd.notna(array)
array([[ True, False,  True],
       [ True,  True, False]])

---->   pandas.notna

--------------------------------------
ID: 7017 --> 2
>>> index = pd.DatetimeIndex(["2017-07-05", "2017-07-06", None,
...                          "2017-07-08"])
>>> index
DatetimeIndex(['2017-07-05', '2017-07-06', 'NaT', '2017-07-08'],
              dtype='datetime64[ns]', freq=None)
>>> pd.notna(index)
array([ True,  True, False,  True])

---->   pandas.DatetimeIndex; pandas.notna

--------------------------------------
ID: 7018 --> 2
>>> df = pd.DataFrame([['ant', 'bee', 'cat'], ['dog', None, 'fly']])
>>> df
     0     1    2
0  ant   bee  cat
1  dog  None  fly
>>> pd.notna(df)
      0      1     2
0  True   True  True
1  True  False  True

---->   pandas.DataFrame; pandas.notna

--------------------------------------
ID: 7019 --> 1
>>> pd.notna(df[1])
0     True
1    False
Name: 1, dtype: bool

---->   pandas.notna

--------------------------------------
ID: 7020 --> 1
>>> pd.period_range(start='2017-01-01', end='2018-01-01', freq='M')
PeriodIndex(['2017-01', '2017-02', '2017-03', '2017-04', '2017-05', '2017-06',
         '2017-07', '2017-08', '2017-09', '2017-10', '2017-11', '2017-12',
         '2018-01'],
        dtype='period[M]')

---->   pandas.period_range

--------------------------------------
ID: 7021 --> 2
>>> pd.period_range(start=pd.Period('2017Q1', freq='Q'),
...                 end=pd.Period('2017Q2', freq='Q'), freq='M')
PeriodIndex(['2017-03', '2017-04', '2017-05', '2017-06'],
            dtype='period[M]')

---->   pandas.period_range; pandas.Period

--------------------------------------
ID: 7022 --> 1
>>> df1 = pd.DataFrame({'lkey': ['foo', 'bar', 'baz', 'foo'],
...                     'value': [1, 2, 3, 5]})
>>> df2 = pd.DataFrame({'rkey': ['foo', 'bar', 'baz', 'foo'],
...                     'value': [5, 6, 7, 8]})
>>> df1
    lkey value
0   foo      1
1   bar      2
2   baz      3
3   foo      5
>>> df2
    rkey value
0   foo      5
1   bar      6
2   baz      7
3   foo      8

---->   pandas.DataFrame

--------------------------------------
ID: 7026 --> 1
>>> df1 = pd.DataFrame({'a': ['foo', 'bar'], 'b': [1, 2]})
>>> df2 = pd.DataFrame({'a': ['foo', 'baz'], 'c': [3, 4]})
>>> df1
      a  b
0   foo  1
1   bar  2
>>> df2
      a  c
0   foo  3
1   baz  4

---->   pandas.DataFrame

--------------------------------------
ID: 7029 --> 1
>>> df1 = pd.DataFrame({'left': ['foo', 'bar']})
>>> df2 = pd.DataFrame({'right': [7, 8]})
>>> df1
    left
0   foo
1   bar
>>> df2
    right
0   7
1   8

---->   pandas.DataFrame

--------------------------------------
ID: 7031 --> 1
>>> df = pd.DataFrame({"animal": ["dog", "pig"], "age": [10, 20]})
>>> df
  animal  age
0    dog   10
1    pig   20

---->   pandas.DataFrame

--------------------------------------
ID: 7033 --> 1
>>> pd.notna('dog')
True

---->   pandas.notna

--------------------------------------
ID: 7034 --> 1
>>> pd.notna(pd.NA)
False

---->   pandas.notna

--------------------------------------
ID: 7035 --> 1
>>> pd.notna(np.nan)
False

---->   pandas.notna

--------------------------------------
ID: 7036 --> 1
>>> array = np.array([[1, np.nan, 3], [4, 5, np.nan]])
>>> array
array([[ 1., nan,  3.],
       [ 4.,  5., nan]])
>>> pd.notna(array)
array([[ True, False,  True],
       [ True,  True, False]])

---->   pandas.notna

--------------------------------------
ID: 7037 --> 2
>>> index = pd.DatetimeIndex(["2017-07-05", "2017-07-06", None,
...                          "2017-07-08"])
>>> index
DatetimeIndex(['2017-07-05', '2017-07-06', 'NaT', '2017-07-08'],
              dtype='datetime64[ns]', freq=None)
>>> pd.notna(index)
array([ True,  True, False,  True])

---->   pandas.DatetimeIndex; pandas.notna

--------------------------------------
ID: 7038 --> 2
>>> df = pd.DataFrame([['ant', 'bee', 'cat'], ['dog', None, 'fly']])
>>> df
     0     1    2
0  ant   bee  cat
1  dog  None  fly
>>> pd.notna(df)
      0      1     2
0  True   True  True
1  True  False  True

---->   pandas.DataFrame; pandas.notna

--------------------------------------
ID: 7039 --> 1
>>> pd.notna(df[1])
0     True
1    False
Name: 1, dtype: bool

---->   pandas.notna

--------------------------------------
ID: 7045 --> 2
>>> df = pd.DataFrame({'year': [2015, 2016],
...                    'month': [2, 3],
...                    'day': [4, 5]})
>>> pd.to_datetime(df)
0   2015-02-04
1   2016-03-05
dtype: datetime64[ns]

---->   pandas.DataFrame; pandas.to_datetime

--------------------------------------
ID: 7046 --> 1
>>> pd.to_datetime(1490195805, unit='s')
Timestamp('2017-03-22 15:16:45')
>>> pd.to_datetime(1490195805433502912, unit='ns')
Timestamp('2017-03-22 15:16:45.433502912')

---->   pandas.to_datetime

--------------------------------------
ID: 7047 --> 1
>>> pd.to_datetime([1, 2, 3], unit='D',
...                origin=pd.Timestamp('1960-01-01'))
DatetimeIndex(['1960-01-02', '1960-01-03', '1960-01-04'],
              dtype='datetime64[ns]', freq=None)

---->   pandas.to_datetime

--------------------------------------
ID: 7048 --> 1
>>> pd.to_datetime('2018-10-26 12:00:00.0000000011',
...                format='%Y-%m-%d %H:%M:%S.%f')
Timestamp('2018-10-26 12:00:00.000000001')

---->   pandas.to_datetime

--------------------------------------
ID: 7049 --> 1
>>> pd.to_datetime('13000101', format='%Y%m%d', errors='ignore')
'13000101'
>>> pd.to_datetime('13000101', format='%Y%m%d', errors='coerce')
NaT

---->   pandas.to_datetime

--------------------------------------
ID: 7050 --> 1
>>> pd.to_datetime(['2018-10-26 12:00:00', '2018-10-26 13:00:15'])
DatetimeIndex(['2018-10-26 12:00:00', '2018-10-26 13:00:15'],
              dtype='datetime64[ns]', freq=None)

---->   pandas.to_datetime

--------------------------------------
ID: 7051 --> 1
>>> pd.to_datetime(['2018-10-26 12:00 -0500', '2018-10-26 13:00 -0500'])
DatetimeIndex(['2018-10-26 12:00:00-05:00', '2018-10-26 13:00:00-05:00'],
              dtype='datetime64[ns, UTC-05:00]', freq=None)

---->   pandas.to_datetime

--------------------------------------
ID: 7052 --> 1
>>> pd.to_datetime(['2020-10-25 02:00 +0200', '2020-10-25 04:00 +0100'])
Index([2020-10-25 02:00:00+02:00, 2020-10-25 04:00:00+01:00],
      dtype='object')

---->   pandas.to_datetime

--------------------------------------
ID: 7053 --> 1
>>> from datetime import datetime
>>> pd.to_datetime(["2020-01-01 01:00:00-01:00", datetime(2020, 1, 1, 3, 0)])
Index([2020-01-01 01:00:00-01:00, 2020-01-01 03:00:00], dtype='object')

---->   pandas.to_datetime

--------------------------------------
ID: 7054 --> 1
>>> pd.to_datetime(['2018-10-26 12:00', '2018-10-26 13:00'], utc=True)
DatetimeIndex(['2018-10-26 12:00:00+00:00', '2018-10-26 13:00:00+00:00'],
              dtype='datetime64[ns, UTC]', freq=None)

---->   pandas.to_datetime

--------------------------------------
ID: 7055 --> 1
>>> pd.to_datetime(['2018-10-26 12:00 -0530', '2018-10-26 12:00 -0500'],
...                utc=True)
DatetimeIndex(['2018-10-26 17:30:00+00:00', '2018-10-26 17:00:00+00:00'],
              dtype='datetime64[ns, UTC]', freq=None)

---->   pandas.to_datetime

--------------------------------------
ID: 7056 --> 1
>>> pd.to_datetime(['2018-10-26 12:00', datetime(2020, 1, 1, 18)], utc=True)
DatetimeIndex(['2018-10-26 12:00:00+00:00', '2020-01-01 18:00:00+00:00'],
              dtype='datetime64[ns, UTC]', freq=None)

---->   pandas.to_datetime

--------------------------------------
ID: 7057 --> 1
>>> pd.bdate_range(start='1/1/2018', end='1/08/2018')
DatetimeIndex(['2018-01-01', '2018-01-02', '2018-01-03', '2018-01-04',
           '2018-01-05', '2018-01-08'],
          dtype='datetime64[ns]', freq='B')

---->   pandas.bdate_range

--------------------------------------
ID: 7059 --> 1
>>> pd.date_range(
...     start=pd.to_datetime("1/1/2018").tz_localize("Europe/Berlin"),
...     end=pd.to_datetime("1/08/2018").tz_localize("Europe/Berlin"),
... )
DatetimeIndex(['2018-01-01 00:00:00+01:00', '2018-01-02 00:00:00+01:00',
               '2018-01-03 00:00:00+01:00', '2018-01-04 00:00:00+01:00',
               '2018-01-05 00:00:00+01:00', '2018-01-06 00:00:00+01:00',
               '2018-01-07 00:00:00+01:00', '2018-01-08 00:00:00+01:00'],
              dtype='datetime64[ns, Europe/Berlin]', freq='D')

---->   pandas.to_datetime

--------------------------------------
ID: 7071 --> 1
>>> pd.isna('dog')
False

---->   pandas.isna

--------------------------------------
ID: 7072 --> 1
>>> pd.isna(pd.NA)
True

---->   pandas.isna

--------------------------------------
ID: 7073 --> 1
>>> pd.isna(np.nan)
True

---->   pandas.isna

--------------------------------------
ID: 7074 --> 1
>>> array = np.array([[1, np.nan, 3], [4, 5, np.nan]])
>>> array
array([[ 1., nan,  3.],
       [ 4.,  5., nan]])
>>> pd.isna(array)
array([[False,  True, False],
       [False, False,  True]])

---->   pandas.isna

--------------------------------------
ID: 7075 --> 2
>>> index = pd.DatetimeIndex(["2017-07-05", "2017-07-06", None,
...                           "2017-07-08"])
>>> index
DatetimeIndex(['2017-07-05', '2017-07-06', 'NaT', '2017-07-08'],
              dtype='datetime64[ns]', freq=None)
>>> pd.isna(index)
array([False, False,  True, False])

---->   pandas.DatetimeIndex; pandas.isna

--------------------------------------
ID: 7076 --> 2
>>> df = pd.DataFrame([['ant', 'bee', 'cat'], ['dog', None, 'fly']])
>>> df
     0     1    2
0  ant   bee  cat
1  dog  None  fly
>>> pd.isna(df)
       0      1      2
0  False  False  False
1  False   True  False

---->   pandas.DataFrame; pandas.isna

--------------------------------------
ID: 7077 --> 1
>>> pd.isna(df[1])
0    False
1     True
Name: 1, dtype: bool

---->   pandas.isna

--------------------------------------
ID: 7078 --> 2
>>> np.random.seed(5)
>>> x = np.cumsum(np.random.normal(loc=1, scale=5, size=50))
>>> s = pd.Series(x)
>>> s.plot()


---->   pandas.Series; Series.plot

--------------------------------------
ID: 7080 --> 1
>>> spacing = np.linspace(-9 * np.pi, 9 * np.pi, num=1000)
>>> s = pd.Series(0.7 * np.random.rand(1000) + 0.3 * np.sin(spacing))
>>> pd.plotting.autocorrelation_plot(s)


---->   pandas.Series

--------------------------------------
ID: 7081 --> 1
>>> df = pd.DataFrame({"a": [1, 0, 0, 1], "b": [0, 1, 0, 0],
...                    "c": [0, 0, 1, 0]})

---->   pandas.DataFrame

--------------------------------------
ID: 7082 --> 1
>>> pd.from_dummies(df)
0     a
1     b
2     c
3     a

---->   pandas.from_dummies

--------------------------------------
ID: 7083 --> 1
>>> df = pd.DataFrame({"col1_a": [1, 0, 1], "col1_b": [0, 1, 0],
...                    "col2_a": [0, 1, 0], "col2_b": [1, 0, 0],
...                    "col2_c": [0, 0, 1]})

---->   pandas.DataFrame

--------------------------------------
ID: 7084 --> 1
>>> pd.from_dummies(df, sep="_")
    col1    col2
0    a       b
1    b       a
2    a       c

---->   pandas.from_dummies

--------------------------------------
ID: 7085 --> 1
>>> df = pd.DataFrame({"col1_a": [1, 0, 0], "col1_b": [0, 1, 0],
...                    "col2_a": [0, 1, 0], "col2_b": [1, 0, 0],
...                    "col2_c": [0, 0, 0]})

---->   pandas.DataFrame

--------------------------------------
ID: 7086 --> 1
>>> pd.from_dummies(df, sep="_", default_category={"col1": "d", "col2": "e"})
    col1    col2
0    a       b
1    b       a
2    d       e

---->   pandas.from_dummies

--------------------------------------
ID: 7087 --> 1
>>> df = pd.DataFrame({'A': {0: 'a', 1: 'b', 2: 'c'},
...                    'B': {0: 1, 1: 3, 2: 5},
...                    'C': {0: 2, 1: 4, 2: 6}})
>>> df
   A  B  C
0  a  1  2
1  b  3  4
2  c  5  6

---->   pandas.DataFrame

--------------------------------------
ID: 7088 --> 1
>>> pd.melt(df, id_vars=['A'], value_vars=['B'])
   A variable  value
0  a        B      1
1  b        B      3
2  c        B      5

---->   pandas.melt

--------------------------------------
ID: 7089 --> 1
>>> pd.melt(df, id_vars=['A'], value_vars=['B', 'C'])
   A variable  value
0  a        B      1
1  b        B      3
2  c        B      5
3  a        C      2
4  b        C      4
5  c        C      6

---->   pandas.melt

--------------------------------------
ID: 7090 --> 1
>>> pd.melt(df, id_vars=['A'], value_vars=['B'],
...         var_name='myVarname', value_name='myValname')
   A myVarname  myValname
0  a         B          1
1  b         B          3
2  c         B          5

---->   pandas.melt

--------------------------------------
ID: 7091 --> 1
>>> pd.melt(df, id_vars=['A'], value_vars=['B', 'C'], ignore_index=False)
   A variable  value
0  a        B      1
1  b        B      3
2  c        B      5
0  a        C      2
1  b        C      4
2  c        C      6

---->   pandas.melt

--------------------------------------
ID: 7093 --> 1
>>> pd.melt(df, col_level=0, id_vars=['A'], value_vars=['B'])
   A variable  value
0  a        B      1
1  b        B      3
2  c        B      5

---->   pandas.melt

--------------------------------------
ID: 7094 --> 1
>>> pd.melt(df, id_vars=[('A', 'D')], value_vars=[('B', 'E')])
  (A, D) variable_0 variable_1  value
0      a          B          E      1
1      b          B          E      3
2      c          B          E      5

---->   pandas.melt

--------------------------------------
ID: 7095 --> 2
>>> s = pd.Series(['1.0', '2', -3])
>>> pd.to_numeric(s)
0    1.0
1    2.0
2   -3.0
dtype: float64
>>> pd.to_numeric(s, downcast='float')
0    1.0
1    2.0
2   -3.0
dtype: float32
>>> pd.to_numeric(s, downcast='signed')
0    1
1    2
2   -3
dtype: int8
>>> s = pd.Series(['apple', '1.0', '2', -3])
>>> pd.to_numeric(s, errors='ignore')
0    apple
1      1.0
2        2
3       -3
dtype: object
>>> pd.to_numeric(s, errors='coerce')
0    NaN
1    1.0
2    2.0
3   -3.0
dtype: float64

---->   pandas.Series; pandas.to_numeric

--------------------------------------
ID: 7096 --> 2
>>> s = pd.Series([1, 2, 3], dtype="Int64")
>>> pd.to_numeric(s, downcast="integer")
0    1
1    2
2    3
dtype: Int8
>>> s = pd.Series([1.0, 2.1, 3.0], dtype="Float64")
>>> pd.to_numeric(s, downcast="float")
0    1.0
1    2.1
2    3.0
dtype: Float32

---->   pandas.Series; pandas.to_numeric

--------------------------------------
ID: 7097 --> 2
>>> pd.unique(pd.Series([2, 1, 3, 3]))
array([2, 1, 3])

---->   pandas.unique; pandas.Series

--------------------------------------
ID: 7098 --> 2
>>> pd.unique(pd.Series([2] + [1] * 5))
array([2, 1])

---->   pandas.unique; pandas.Series

--------------------------------------
ID: 7099 --> 2
>>> pd.unique(pd.Series([pd.Timestamp("20160101"), pd.Timestamp("20160101")]))
array(['2016-01-01T00:00:00.000000000'], dtype='datetime64[ns]')

---->   pandas.unique; pandas.Series

--------------------------------------
ID: 7100 --> 2
>>> pd.unique(
...     pd.Series(
...         [
...             pd.Timestamp("20160101", tz="US/Eastern"),
...             pd.Timestamp("20160101", tz="US/Eastern"),
...         ]
...     )
... )

['2016-01-01 00:00:00-05:00']
Length: 1, dtype: datetime64[ns, US/Eastern]

---->   pandas.unique; pandas.Series

--------------------------------------
ID: 7101 --> 2
>>> pd.unique(
...     pd.Index(
...         [
...             pd.Timestamp("20160101", tz="US/Eastern"),
...             pd.Timestamp("20160101", tz="US/Eastern"),
...         ]
...     )
... )
DatetimeIndex(['2016-01-01 00:00:00-05:00'],
        dtype='datetime64[ns, US/Eastern]',
        freq=None)

---->   pandas.unique; pandas.Index

--------------------------------------
ID: 7102 --> 1
>>> pd.unique(list("baabc"))
array(['b', 'a', 'c'], dtype=object)

---->   pandas.unique

--------------------------------------
ID: 7103 --> 3
>>> pd.unique(pd.Series(pd.Categorical(list("baabc"))))
['b', 'a', 'c']
Categories (3, object): ['a', 'b', 'c']

---->   pandas.unique; pandas.Series; pandas.Categorical

--------------------------------------
ID: 7104 --> 3
>>> pd.unique(pd.Series(pd.Categorical(list("baabc"), categories=list("abc"))))
['b', 'a', 'c']
Categories (3, object): ['a', 'b', 'c']

---->   pandas.unique; pandas.Series; pandas.Categorical

--------------------------------------
ID: 7105 --> 3
>>> pd.unique(
...     pd.Series(
...         pd.Categorical(list("baabc"), categories=list("abc"), ordered=True)
...     )
... )
['b', 'a', 'c']
Categories (3, object): ['a' < 'b' < 'c']

---->   pandas.unique; pandas.Series; pandas.Categorical

--------------------------------------
ID: 7106 --> 1
>>> pd.unique([("a", "b"), ("b", "a"), ("a", "c"), ("b", "a")])
array([('a', 'b'), ('b', 'a'), ('a', 'c')], dtype=object)

---->   pandas.unique

--------------------------------------
ID: 7108 --> 1
>>> df = pd.DataFrame([[1,2], [3,4]], index=["A", "B"])
>>> def color_b(s):
...     return "background-color: yellow;" if v == "B" else None
>>> df.style.applymap_index(color_b)  

---->   pandas.DataFrame

--------------------------------------
ID: 7109 --> 2
>>> midx = pd.MultiIndex.from_product([['ix', 'jy'], [0, 1], ['x3', 'z4']])
>>> df = pd.DataFrame([np.arange(8)], columns=midx)
>>> def highlight_x(v):
...     return "background-color: yellow;" if "x" in v else None
>>> df.style.applymap_index(highlight_x, axis="columns", level=[0, 2])
...  

---->   pandas.MultiIndex; pandas.DataFrame

--------------------------------------
ID: 7112 --> 1
>>> def some_highlights(styler, min_color="red", max_color="blue"):
...      styler.highlight_min(color=min_color, axis=None)
...      styler.highlight_max(color=max_color, axis=None)
...      styler.highlight_null()
...      return styler
>>> df = pd.DataFrame([[1, 2, 3, pd.NA], [pd.NA, 4, 5, 6]], dtype="Int64")
>>> df.style.pipe(some_highlights, min_color="green")  

---->   pandas.DataFrame

--------------------------------------
ID: 7114 --> 1
>>> def highlight_last_level(styler):
...     return styler.apply_index(
...         lambda v: "background-color: pink; color: yellow", axis="columns",
...         level=styler.columns.nlevels-1
...     )  
>>> df.columns = pd.MultiIndex.from_product([["A", "B"], ["X", "Y"]])
>>> df.style.pipe(highlight_last_level)  

---->   pandas.MultiIndex

--------------------------------------
ID: 7116 --> 1
>>> df = pd.DataFrame([[np.nan, 1.0, 'A'], [2.0, np.nan, 3.0]])
>>> df.style.format(na_rep='MISS', precision=3)  
        0       1       2
0    MISS   1.000       A
1   2.000    MISS   3.000

---->   pandas.DataFrame

--------------------------------------
ID: 7121 --> 1
>>> df = pd.DataFrame([['', '"A&B"', None]])
>>> s = df.style.format(
...     '{0}">{0}', escape="html", na_rep="NA"
...     )
>>> s.to_html()  
...
<div></div>
"A&B"
NA
...

---->   pandas.DataFrame

--------------------------------------
ID: 7122 --> 1
>>> df = pd.DataFrame([["123"], ["~ ^"], ["$%#"]])
>>> df.style.format("\\textbf{{{}}}", escape="latex").to_latex()
...  
\begin{tabular}{ll}
{} & {0} \\
0 & \textbf{123} \\
1 & \textbf{\textasciitilde \space \textasciicircum } \\
2 & \textbf{\$\%\#} \\
\end{tabular}

---->   pandas.DataFrame

--------------------------------------
ID: 7123 --> 1
>>> df = pd.DataFrame({"A": [1, 0, -1]})
>>> pseudo_css = "number-format: 0§[Red](0)§-§@;"
>>> filename = "formatted_file.xlsx"
>>> df.style.applymap(lambda v: pseudo_css).to_excel(filename) 

---->   pandas.DataFrame

--------------------------------------
ID: 7124 --> 2
>>> def highlight_max(x, color):
...     return np.where(x == np.nanmax(x.to_numpy()), f"color: {color};", None)
>>> df = pd.DataFrame(np.random.randn(5, 2), columns=["A", "B"])
>>> df.style.apply(highlight_max, color='red')  
>>> df.style.apply(highlight_max, color='blue', axis=1)  
>>> df.style.apply(highlight_max, color='green', axis=None)  

---->   Series.to_numpy; pandas.DataFrame

--------------------------------------
ID: 7127 --> 2
>>> df = pd.DataFrame([[1, 2], [3, 4], [4, 6]], index=["A1", "A2", "Total"])
>>> total_style = pd.Series("font-weight: bold;", index=["Total"])
>>> df.style.apply(lambda s: total_style)  

---->   pandas.DataFrame; pandas.Series

--------------------------------------
ID: 7128 --> 1
>>> df = pd.DataFrame([[1, 2, 3]], columns=[2.0, np.nan, 4.0])
>>> df.style.format_index(axis=1, na_rep='MISS', precision=3)  
    2.000    MISS   4.000
0       1       2       3

---->   pandas.DataFrame

--------------------------------------
ID: 7130 --> 2
>>> df = pd.DataFrame([[1, 2, 3]],
...     columns=pd.MultiIndex.from_arrays([["a", "a", "b"],[2, np.nan, 4]]))
>>> df.style.format_index({0: lambda v: upper(v)}, axis=1, precision=1)
...  
               A       B
      2.0    nan     4.0
0       1      2       3

---->   pandas.DataFrame; pandas.MultiIndex

--------------------------------------
ID: 7132 --> 1
>>> df = pd.DataFrame([[1, 2, 3]], columns=['"A"', 'A&B', None])
>>> s = df.style.format_index('$ {0}', axis=1, escape="html", na_rep="NA")
...  
$ "A"
$ A&B
NA
...

---->   pandas.DataFrame

--------------------------------------
ID: 7133 --> 1
>>> df = pd.DataFrame([[1, 2, 3]], columns=["123", "~", "$%#"])
>>> df.style.format_index("\\textbf{{{}}}", escape="latex", axis=1).to_latex()
...  
\begin{tabular}{lrrr}
{} & {\textbf{123}} & {\textbf{\textasciitilde }} & {\textbf{\$\%\#}} \\
0 & 1 & 2 & 3 \\
\end{tabular}

---->   pandas.DataFrame

--------------------------------------
ID: 7134 --> 1
# relabel first, then hide
df = pd.DataFrame({"col": ["a", "b", "c"]})
df.style.relabel_index(["A", "B", "C"]).hide([0,1])
# hide first, then relabel
df = pd.DataFrame({"col": ["a", "b", "c"]})
df.style.hide([0,1]).relabel_index(["C"])

---->   pandas.DataFrame

--------------------------------------
ID: 7135 --> 1
>>> df = pd.DataFrame({"col": ["a", "b", "c"]})
>>> df.style.relabel_index(["A", "B", "C"])  
     col
A      a
B      b
C      c

---->   pandas.DataFrame

--------------------------------------
ID: 7137 --> 2
>>> midx = pd.MultiIndex.from_product([[0, 1], [0, 1], [0, 1]])
>>> df = pd.DataFrame({"col": list(range(8))}, index=midx)
>>> styler = df.style  
          col
0  0  0     0
      1     1
   1  0     2
      1     3
1  0  0     4
      1     5
   1  0     6
      1     7
>>> styler.hide((midx.get_level_values(0)==0)|(midx.get_level_values(1)==0))
...  
>>> styler.hide(level=[0,1])  
>>> styler.relabel_index(["binary6", "binary7"])  
          col
binary6     6
binary7     7

---->   pandas.MultiIndex; pandas.DataFrame

--------------------------------------
ID: 7139 --> 1
>>> df = pd.DataFrame({"samples": np.random.rand(10)})
>>> styler = df.loc[np.random.randint(0,10,3)].style
>>> styler.relabel_index([f"sample{i+1} ({{}})" for i in range(3)])
...  
                 samples
sample1 (5)     0.315811
sample2 (0)     0.495941
sample3 (2)     0.067946

---->   pandas.DataFrame

--------------------------------------
ID: 7140 --> 1
>>> df = pd.DataFrame([[1,2], [3,4]], index=["A", "B"])
>>> def color_b(s):
...     return np.where(s == "B", "background-color: yellow;", "")
>>> df.style.apply_index(color_b)  

---->   pandas.DataFrame

--------------------------------------
ID: 7141 --> 2
>>> midx = pd.MultiIndex.from_product([['ix', 'jy'], [0, 1], ['x3', 'z4']])
>>> df = pd.DataFrame([np.arange(8)], columns=midx)
>>> def highlight_x(s):
...     return ["background-color: yellow;" if "x" in v else "" for v in s]
>>> df.style.apply_index(highlight_x, axis="columns", level=[0, 2])
...  

---->   pandas.MultiIndex; pandas.DataFrame

--------------------------------------
ID: 7142 --> 1
>>> df = pd.DataFrame([[1,2], [3,4]])
>>> s = df.style.highlight_max(axis=None,
...                            props='background-color:red; font-weight:bold;')
>>> s.to_html()  

---->   pandas.DataFrame

--------------------------------------
ID: 7143 --> 1
>>> s = df.style.highlight_max(axis=None,
...                            props='cellcolor:{red}; bfseries: ;')
>>> s.to_latex()  

---->   Series.to_latex

--------------------------------------
ID: 7144 --> 2
>>> df = pd.DataFrame([[1, 2.2, "dogs"], [3, 4.4, "cats"], [2, 6.6, "cows"]],
...                   index=["ix1", "ix2", "ix3"],
...                   columns=["Integers", "Floats", "Strings"])
>>> s = df.style.highlight_max(
...     props='cellcolor:[HTML]{FFFF00}; color:{red};'
...           'textit:--rwrap; textbf:--rwrap;'
... )
>>> s.to_latex()  

---->   pandas.DataFrame; Series.to_latex

--------------------------------------
ID: 7148 --> 2
>>> df.columns = pd.MultiIndex.from_tuples([
...     ("Numeric", "Integers"),
...     ("Numeric", "Floats"),
...     ("Non-Numeric", "Strings")
... ])
>>> df.index = pd.MultiIndex.from_tuples([
...     ("L0", "ix1"), ("L0", "ix2"), ("L1", "ix3")
... ])
>>> s = df.style.highlight_max(
...     props='cellcolor:[HTML]{FFFF00}; color:{red}; itshape:; bfseries:;'
... )
>>> s.to_latex(
...     column_format="rrrrr", position="h", position_float="centering",
...     hrules=True, label="table:5", caption="Styled LaTeX Table",
...     multirow_align="t", multicol_align="r"
... )  

---->   pandas.MultiIndex; Series.to_latex

--------------------------------------
ID: 7150 --> 1
>>> s.to_latex()  
\begin{tabular}{llrrl}
{} & {} & \multicolumn{2}{r}{Numeric} & {Non-Numeric} \\
{} & {} & {Integers} & {Floats} & {Strings} \\
\multirow[c]{2}{*}{L0} & ix1 & \\$1 & 2.200 & DOGS \\
 & ix2 & \$3 & 4.400 & CATS \\
L1 & ix3 & \$2 & 6.600 & COWS \\
\end{tabular}

---->   Series.to_latex

--------------------------------------
ID: 7151 --> 1
>>> df = pd.DataFrame([[1]])
>>> df.style.set_properties(
...     **{"font-weight": "bold /* --dwrap */", "Huge": "--latex--rwrap"}
... ).to_latex(convert_css=True)  
\begin{tabular}{lr}
{} & {0} \\
0 & {\bfseries}{\Huge{1}} \\
\end{tabular}

---->   pandas.DataFrame

--------------------------------------
ID: 7152 --> 2
>>> cidx = pd.MultiIndex.from_arrays([
...     ["Equity", "Equity", "Equity", "Equity",
...      "Stats", "Stats", "Stats", "Stats", "Rating"],
...     ["Energy", "Energy", "Consumer", "Consumer", "", "", "", "", ""],
...     ["BP", "Shell", "H&M", "Unilever",
...      "Std Dev", "Variance", "52w High", "52w Low", ""]
... ])
>>> iidx = pd.MultiIndex.from_arrays([
...     ["Equity", "Equity", "Equity", "Equity"],
...     ["Energy", "Energy", "Consumer", "Consumer"],
...     ["BP", "Shell", "H&M", "Unilever"]
... ])
>>> styler = pd.DataFrame([
...     [1, 0.8, 0.66, 0.72, 32.1678, 32.1678**2, 335.12, 240.89, "Buy"],
...     [0.8, 1.0, 0.69, 0.79, 1.876, 1.876**2, 14.12, 19.78, "Hold"],
...     [0.66, 0.69, 1.0, 0.86, 7, 7**2, 210.9, 140.6, "Buy"],
...     [0.72, 0.79, 0.86, 1.0, 213.76, 213.76**2, 2807, 3678, "Sell"],
... ], columns=cidx, index=iidx).style

---->   pandas.MultiIndex; pandas.DataFrame

--------------------------------------
ID: 7157 --> 1
>>> df = pd.DataFrame(data=[[0, 1], [2, 3]])
>>> ttips = pd.DataFrame(
...    data=[["Min", ""], [np.nan, "Max"]], columns=df.columns, index=df.index
... )
>>> s = df.style.set_tooltips(ttips).to_html()

---->   pandas.DataFrame

--------------------------------------
ID: 7159 --> 1
>>> df = pd.DataFrame(columns=["City", "Temp (c)", "Rain (mm)", "Wind (m/s)"],
...                   data=[["Stockholm", 21.6, 5.0, 3.2],
...                         ["Oslo", 22.4, 13.3, 3.1],
...                         ["Copenhagen", 24.5, 0.0, 6.7]])

---->   pandas.DataFrame

--------------------------------------
ID: 7166 --> 1
>>> df = DataFrame([[4, 6], [1, 9], [3, 4], [5, 5], [9,6]],
...                columns=["Mike", "Jim"],
...                index=["Mon", "Tue", "Wed", "Thurs", "Fri"])
>>> styler = df.style.concat(df.agg(["sum"]).style)  

---->   DataFrame.agg

--------------------------------------
ID: 7167 --> 1
>>> descriptors = df.agg(["sum", "mean", lambda s: s.dtype])
>>> descriptors.index = ["Total", "Average", "dtype"]
>>> other = (descriptors.style
...          .highlight_max(axis=1, subset=(["Total", "Average"], slice(None)))
...          .format(subset=("Average", slice(None)), precision=2, decimal=",")
...          .applymap(lambda v: "font-weight: bold;"))
>>> styler = (df.style
...             .highlight_max(color="salmon")
...             .set_table_styles([{"selector": ".foot_row0",
...                                 "props": "border-top: 1px solid black;"}]))
>>> styler.concat(other)  

---->   DataFrame.agg

--------------------------------------
ID: 7168 --> 2
>>> df = DataFrame([[1], [2]], index=pd.MultiIndex.from_product([[0], [1, 2]]))
>>> descriptors = df.agg(["sum"])
>>> descriptors.index = pd.MultiIndex.from_product([[""], descriptors.index])
>>> df.style.concat(descriptors.style)  

---->   pandas.MultiIndex; DataFrame.agg

--------------------------------------
ID: 7169 --> 1
>>> df = pd.DataFrame(columns=["City", "Temp (c)", "Rain (mm)", "Wind (m/s)"],
...                   data=[["Stockholm", 21.6, 5.0, 3.2],
...                         ["Oslo", 22.4, 13.3, 3.1],
...                         ["Copenhagen", 24.5, 0.0, 6.7]])

---->   pandas.DataFrame

--------------------------------------
ID: 7176 --> 2
>>> np.random.seed(5)
>>> x = np.cumsum(np.random.normal(loc=1, scale=5, size=50))
>>> s = pd.Series(x)
>>> s.plot()


---->   pandas.Series; Series.plot

--------------------------------------
ID: 7178 --> 1
>>> df = pd.DataFrame({
...     'One': [1.2, 1.6, 1.5],
...     'Two': [2.9, 2.1, 2.5],
...     'Three': [3.1, 3.2, 3.8],
... })
>>> df.style.highlight_between(left=2.1, right=2.9)  

---->   pandas.DataFrame

--------------------------------------
ID: 7182 --> 2
>>> np.random.seed(1234)
>>> df = pd.DataFrame(np.random.randn(10, 4),
...                   columns=['Col1', 'Col2', 'Col3', 'Col4'])
>>> boxplot = df.boxplot(column=['Col1', 'Col2', 'Col3'])  

---->   pandas.DataFrame; DataFrame.boxplot

--------------------------------------
ID: 7183 --> 3
>>> df = pd.DataFrame(np.random.randn(10, 2),
...                   columns=['Col1', 'Col2'])
>>> df['X'] = pd.Series(['A', 'A', 'A', 'A', 'A',
...                      'B', 'B', 'B', 'B', 'B'])
>>> boxplot = df.boxplot(by='X')

---->   pandas.DataFrame; pandas.Series; DataFrame.boxplot

--------------------------------------
ID: 7184 --> 3
>>> df = pd.DataFrame(np.random.randn(10, 3),
...                   columns=['Col1', 'Col2', 'Col3'])
>>> df['X'] = pd.Series(['A', 'A', 'A', 'A', 'A',
...                      'B', 'B', 'B', 'B', 'B'])
>>> df['Y'] = pd.Series(['A', 'B', 'A', 'B', 'A',
...                      'B', 'A', 'B', 'A', 'B'])
>>> boxplot = df.boxplot(column=['Col1', 'Col2'], by=['X', 'Y'])

---->   pandas.DataFrame; pandas.Series; DataFrame.boxplot

--------------------------------------
ID: 7185 --> 1
>>> boxplot = df.boxplot(column=['Col1', 'Col2'], by='X',
...                      layout=(2, 1))

---->   DataFrame.boxplot

--------------------------------------
ID: 7186 --> 1
>>> boxplot = df.boxplot(grid=False, rot=45, fontsize=15)  

---->   DataFrame.boxplot

--------------------------------------
ID: 7187 --> 1
>>> boxplot = df.boxplot(column=['Col1', 'Col2'], return_type='axes')
>>> type(boxplot)


---->   DataFrame.boxplot

--------------------------------------
ID: 7188 --> 1
>>> boxplot = df.boxplot(column=['Col1', 'Col2'], by='X',
...                      return_type='axes')
>>> type(boxplot)


---->   DataFrame.boxplot

--------------------------------------
ID: 7189 --> 1
>>> boxplot = df.boxplot(column=['Col1', 'Col2'], by='X',
...                      return_type=None)
>>> type(boxplot)


---->   DataFrame.boxplot

--------------------------------------
ID: 7190 --> 1
>>> df = pd.DataFrame(np.random.randn(10, 4))
>>> df.style.set_properties(color="white", align="right")  
>>> df.style.set_properties(**{'background-color': 'yellow'})  

---->   pandas.DataFrame

--------------------------------------
ID: 7191 --> 1
>>> df = pd.DataFrame([[1,2], [3,4], [5,6]], index=["a", "b", "c"])
>>> df.style.hide(["a", "b"])  
     0    1
c    5    6

---->   pandas.DataFrame

--------------------------------------
ID: 7192 --> 2
>>> midx = pd.MultiIndex.from_product([["x", "y"], ["a", "b", "c"]])
>>> df = pd.DataFrame(np.random.randn(6,6), index=midx, columns=midx)
>>> df.style.format("{:.1f}").hide()  
                 x                    y
   a      b      c      a      b      c
 0.1    0.0    0.4    1.3    0.6   -1.4
 0.7    1.0    1.3    1.5   -0.0   -0.2
 1.4   -0.8    1.6   -0.2   -0.4   -0.3
 0.4    1.0   -0.2   -0.8   -1.2    1.1
-0.6    1.2    1.8    1.9    0.3    0.3
 0.8    0.5   -0.3    1.2    2.2   -0.8

---->   pandas.MultiIndex; pandas.DataFrame

--------------------------------------
ID: 7198 --> 2
>>> df1 = pd.DataFrame([['a', 'b'], ['c', 'd']],
...                    index=['row 1', 'row 2'],
...                    columns=['col 1', 'col 2'])
>>> df1.to_excel("output.xlsx")  

---->   pandas.DataFrame; DataFrame.to_excel

--------------------------------------
ID: 7199 --> 1
>>> df1.to_excel("output.xlsx",
...              sheet_name='Sheet_name_1')  

---->   DataFrame.to_excel

--------------------------------------
ID: 7200 --> 4
>>> df2 = df1.copy()
>>> with pd.ExcelWriter('output.xlsx') as writer:  
...     df1.to_excel(writer, sheet_name='Sheet_name_1')
...     df2.to_excel(writer, sheet_name='Sheet_name_2')

---->   DataFrame.copy; pandas.ExcelWriter; DataFrame.to_excel; DataFrame.to_excel

--------------------------------------
ID: 7201 --> 2
>>> with pd.ExcelWriter('output.xlsx',
...                     mode='a') as writer:  
...     df.to_excel(writer, sheet_name='Sheet_name_3')

---->   pandas.ExcelWriter; DataFrame.to_excel

--------------------------------------
ID: 7202 --> 1
>>> df1.to_excel('output1.xlsx', engine='xlsxwriter')  

---->   DataFrame.to_excel

--------------------------------------
ID: 7205 --> 3
>>> df = pd.DataFrame(data={'col1': [1, 2], 'col2': [3, 4]})
>>> df.to_parquet('df.parquet.gzip',
...               compression='gzip')  
>>> pd.read_parquet('df.parquet.gzip')  
   col1  col2
0     1     3
1     2     4

---->   pandas.DataFrame; DataFrame.to_parquet; pandas.read_parquet

--------------------------------------
ID: 7206 --> 1
>>> import io
>>> f = io.BytesIO()
>>> df.to_parquet(f)
>>> f.seek(0)
0
>>> content = f.read()

---->   DataFrame.to_parquet

--------------------------------------
ID: 7207 --> 2
>>> from pandas.io.json._table_schema import build_table_schema
>>> df = pd.DataFrame(
...     {'A': [1, 2, 3],
...      'B': ['a', 'b', 'c'],
...      'C': pd.date_range('2016-01-01', freq='d', periods=3),
...     }, index=pd.Index(range(3), name='idx'))
>>> build_table_schema(df)
{'fields': [{'name': 'idx', 'type': 'integer'}, {'name': 'A', 'type': 'integer'}, {'name': 'B', 'type': 'string'}, {'name': 'C', 'type': 'datetime'}], 'primaryKey': ['idx'], 'pandas_version': '1.4.0'}

---->   pandas.DataFrame; pandas.Index

--------------------------------------
ID: 7208 --> 1
>>> df = pd.DataFrame(np.arange(10).reshape(2,5) + 1)
>>> df.style.highlight_quantile(axis=None, q_left=0.8, color="#fffd75")
...  

---->   pandas.DataFrame

--------------------------------------
ID: 7211 --> 1
>>> def color_negative(v, color):
...     return f"color: {color};" if v < 0 else None
>>> df = pd.DataFrame(np.random.randn(5, 2), columns=["A", "B"])
>>> df.style.applymap(color_negative, color='red')  

---->   pandas.DataFrame

--------------------------------------
ID: 7214 --> 1
>>> original_df = pd.DataFrame({"foo": range(5), "bar": range(5, 10)})  
>>> original_df  
   foo  bar
0    0    5
1    1    6
2    2    7
3    3    8
4    4    9
>>> original_df.to_pickle("./dummy.pkl")  

---->   pandas.DataFrame

--------------------------------------
ID: 7215 --> 1
>>> unpickled_df = pd.read_pickle("./dummy.pkl")  
>>> unpickled_df  
   foo  bar
0    0    5
1    1    6
2    2    7
3    3    8
4    4    9

---->   pandas.read_pickle

--------------------------------------
ID: 7216 --> 1
>>> from json import loads, dumps
>>> df = pd.DataFrame(
...     [["a", "b"], ["c", "d"]],
...     index=["row 1", "row 2"],
...     columns=["col 1", "col 2"],
... )

---->   pandas.DataFrame

--------------------------------------
ID: 7217 --> 1
>>> result = df.to_json(orient="split")
>>> parsed = loads(result)
>>> dumps(parsed, indent=4)  
{
    "columns": [
        "col 1",
        "col 2"
    ],
    "index": [
        "row 1",
        "row 2"
    ],
    "data": [
        [
            "a",
            "b"
        ],
        [
            "c",
            "d"
        ]
    ]
}

---->   DataFrame.to_json

--------------------------------------
ID: 7218 --> 1
>>> result = df.to_json(orient="records")
>>> parsed = loads(result)
>>> dumps(parsed, indent=4)  
[
    {
        "col 1": "a",
        "col 2": "b"
    },
    {
        "col 1": "c",
        "col 2": "d"
    }
]

---->   DataFrame.to_json

--------------------------------------
ID: 7219 --> 1
>>> result = df.to_json(orient="index")
>>> parsed = loads(result)
>>> dumps(parsed, indent=4)  
{
    "row 1": {
        "col 1": "a",
        "col 2": "b"
    },
    "row 2": {
        "col 1": "c",
        "col 2": "d"
    }
}

---->   DataFrame.to_json

--------------------------------------
ID: 7220 --> 1
>>> result = df.to_json(orient="columns")
>>> parsed = loads(result)
>>> dumps(parsed, indent=4)  
{
    "col 1": {
        "row 1": "a",
        "row 2": "c"
    },
    "col 2": {
        "row 1": "b",
        "row 2": "d"
    }
}

---->   DataFrame.to_json

--------------------------------------
ID: 7221 --> 1
>>> result = df.to_json(orient="values")
>>> parsed = loads(result)
>>> dumps(parsed, indent=4)  
[
    [
        "a",
        "b"
    ],
    [
        "c",
        "d"
    ]
]

---->   DataFrame.to_json

--------------------------------------
ID: 7222 --> 1
>>> result = df.to_json(orient="table")
>>> parsed = loads(result)
>>> dumps(parsed, indent=4)  
{
    "schema": {
        "fields": [
            {
                "name": "index",
                "type": "string"
            },
            {
                "name": "col 1",
                "type": "string"
            },
            {
                "name": "col 2",
                "type": "string"
            }
        ],
        "primaryKey": [
            "index"
        ],
        "pandas_version": "1.4.0"
    },
    "data": [
        {
            "index": "row 1",
            "col 1": "a",
            "col 2": "b"
        },
        {
            "index": "row 2",
            "col 1": "c",
            "col 2": "d"
        }
    ]
}

---->   DataFrame.to_json

--------------------------------------
ID: 7227 --> 2
>>> df = pd.DataFrame(data={'col1': [1, 2], 'col2': [4, 3]})
>>> df.to_orc('df.orc')  
>>> pd.read_orc('df.orc')  
   col1  col2
0     1     4
1     2     3

---->   pandas.DataFrame; pandas.read_orc

--------------------------------------
ID: 7228 --> 1
>>> df = pd.DataFrame({'animal': ['falcon', 'parrot', 'falcon', 'parrot'],
...                     'speed': [350, 18, 361, 15]})  
>>> df.to_stata('animals.dta')  

---->   pandas.DataFrame

--------------------------------------
ID: 7230 --> 1
>>> values = np.random.randint(0, 10, size=(20_000, 1), dtype="uint8")  
>>> df = pd.DataFrame(values, columns=["i"])  
>>> df.to_stata('filename.dta')  

---->   pandas.DataFrame

--------------------------------------
ID: 7232 --> 2
>>> df = pd.DataFrame({'name': ['Raphael', 'Donatello'],
...                    'mask': ['red', 'purple'],
...                    'weapon': ['sai', 'bo staff']})
>>> df.to_csv(index=False)
'name,mask,weapon\nRaphael,red,sai\nDonatello,purple,bo staff\n'

---->   pandas.DataFrame; DataFrame.to_csv

--------------------------------------
ID: 7233 --> 1
>>> compression_opts = dict(method='zip',
...                         archive_name='out.csv')  
>>> df.to_csv('out.zip', index=False,
...           compression=compression_opts)  

---->   DataFrame.to_csv

--------------------------------------
ID: 7234 --> 1
>>> from pathlib import Path  
>>> filepath = Path('folder/subfolder/out.csv')  
>>> filepath.parent.mkdir(parents=True, exist_ok=True)  
>>> df.to_csv(filepath)  

---->   DataFrame.to_csv

--------------------------------------
ID: 7235 --> 1
>>> import os  
>>> os.makedirs('folder/subfolder', exist_ok=True)  
>>> df.to_csv('folder/subfolder/out.csv')  

---->   DataFrame.to_csv

--------------------------------------
ID: 7236 --> 1
>>> df = pd.DataFrame({'animal': ['falcon', 'parrot', 'falcon',
...                               'parrot'],
...                    'speed': [350, 18, 361, 15]})
>>> df.to_stata('animals.dta')  

---->   pandas.DataFrame

--------------------------------------
ID: 7237 --> 1
>>> original_df = pd.DataFrame(
...     {"foo": range(5), "bar": range(5, 10)}
...    )  
>>> original_df  
   foo  bar
0    0    5
1    1    6
2    2    7
3    3    8
4    4    9
>>> pd.to_pickle(original_df, "./dummy.pkl")  

---->   pandas.DataFrame

--------------------------------------
ID: 7238 --> 1
>>> unpickled_df = pd.read_pickle("./dummy.pkl")  
>>> unpickled_df  
   foo  bar
0    0    5
1    1    6
2    2    7
3    3    8
4    4    9

---->   pandas.read_pickle

--------------------------------------
ID: 7239 --> 1
>>> data = [
...     {"id": 1, "name": {"first": "Coleen", "last": "Volk"}},
...     {"name": {"given": "Mark", "family": "Regner"}},
...     {"id": 2, "name": "Faye Raker"},
... ]
>>> pd.json_normalize(data)
    id name.first name.last name.given name.family        name
0  1.0     Coleen      Volk        NaN         NaN         NaN
1  NaN        NaN       NaN       Mark      Regner         NaN
2  2.0        NaN       NaN        NaN         NaN  Faye Raker

---->   pandas.json_normalize

--------------------------------------
ID: 7240 --> 1
>>> data = [
...     {
...         "id": 1,
...         "name": "Cole Volk",
...         "fitness": {"height": 130, "weight": 60},
...     },
...     {"name": "Mark Reg", "fitness": {"height": 130, "weight": 60}},
...     {
...         "id": 2,
...         "name": "Faye Raker",
...         "fitness": {"height": 130, "weight": 60},
...     },
... ]
>>> pd.json_normalize(data, max_level=0)
    id        name                        fitness
0  1.0   Cole Volk  {'height': 130, 'weight': 60}
1  NaN    Mark Reg  {'height': 130, 'weight': 60}
2  2.0  Faye Raker  {'height': 130, 'weight': 60}

---->   pandas.json_normalize

--------------------------------------
ID: 7241 --> 1
>>> data = [
...     {
...         "id": 1,
...         "name": "Cole Volk",
...         "fitness": {"height": 130, "weight": 60},
...     },
...     {"name": "Mark Reg", "fitness": {"height": 130, "weight": 60}},
...     {
...         "id": 2,
...         "name": "Faye Raker",
...         "fitness": {"height": 130, "weight": 60},
...     },
... ]
>>> pd.json_normalize(data, max_level=1)
    id        name  fitness.height  fitness.weight
0  1.0   Cole Volk             130              60
1  NaN    Mark Reg             130              60
2  2.0  Faye Raker             130              60

---->   pandas.json_normalize

--------------------------------------
ID: 7242 --> 1
>>> data = [
...     {
...         "state": "Florida",
...         "shortname": "FL",
...         "info": {"governor": "Rick Scott"},
...         "counties": [
...             {"name": "Dade", "population": 12345},
...             {"name": "Broward", "population": 40000},
...             {"name": "Palm Beach", "population": 60000},
...         ],
...     },
...     {
...         "state": "Ohio",
...         "shortname": "OH",
...         "info": {"governor": "John Kasich"},
...         "counties": [
...             {"name": "Summit", "population": 1234},
...             {"name": "Cuyahoga", "population": 1337},
...         ],
...     },
... ]
>>> result = pd.json_normalize(
...     data, "counties", ["state", "shortname", ["info", "governor"]]
... )
>>> result
         name  population    state shortname info.governor
0        Dade       12345   Florida    FL    Rick Scott
1     Broward       40000   Florida    FL    Rick Scott
2  Palm Beach       60000   Florida    FL    Rick Scott
3      Summit        1234   Ohio       OH    John Kasich
4    Cuyahoga        1337   Ohio       OH    John Kasich

---->   pandas.json_normalize

--------------------------------------
ID: 7243 --> 1
>>> data = {"A": [1, 2]}
>>> pd.json_normalize(data, "A", record_prefix="Prefix.")
    Prefix.0
0          1
1          2

---->   pandas.json_normalize

--------------------------------------
ID: 7244 --> 3
>>> df = pd.DataFrame([[1, 1.0, 'a']], columns=['x', 'y', 'z'])  
>>> df.to_hdf('./store.h5', 'data')  
>>> reread = pd.read_hdf('./store.h5')  

---->   pandas.DataFrame; DataFrame.to_hdf; pandas.read_hdf

--------------------------------------
ID: 7251 --> 1
>>> df = pd.DataFrame([[1, 2, 3], [4, 5, 6]], columns=['A', 'B', 'C'])

---->   pandas.DataFrame

--------------------------------------
ID: 7252 --> 1
>>> df.to_clipboard(sep=',')  
... # Wrote the following to the system clipboard:
... # ,A,B,C
... # 0,1,2,3
... # 1,4,5,6

---->   DataFrame.to_clipboard

--------------------------------------
ID: 7253 --> 1
>>> df.to_clipboard(sep=',', index=False)  
... # Wrote the following to the system clipboard:
... # A,B,C
... # 1,2,3
... # 4,5,6

---->   DataFrame.to_clipboard

--------------------------------------
ID: 7256 --> 1
>>> df = pd.DataFrame({'name' : ['User 1', 'User 2', 'User 3']})
>>> df
     name
0  User 1
1  User 2
2  User 3

---->   pandas.DataFrame

--------------------------------------
ID: 7257 --> 1
>>> df.to_sql('users', con=engine)
3
>>> from sqlalchemy import text
>>> with engine.connect() as conn:
...    conn.execute(text("SELECT * FROM users")).fetchall()
[(0, 'User 1'), (1, 'User 2'), (2, 'User 3')]

---->   DataFrame.to_sql

--------------------------------------
ID: 7258 --> 2
>>> with engine.begin() as connection:
...     df1 = pd.DataFrame({'name' : ['User 4', 'User 5']})
...     df1.to_sql('users', con=connection, if_exists='append')
2

---->   pandas.DataFrame; DataFrame.to_sql

--------------------------------------
ID: 7259 --> 2
>>> df2 = pd.DataFrame({'name' : ['User 6', 'User 7']})
>>> df2.to_sql('users', con=engine, if_exists='append')
2
>>> with engine.connect() as conn:
...    conn.execute(text("SELECT * FROM users")).fetchall()
[(0, 'User 1'), (1, 'User 2'), (2, 'User 3'),
 (0, 'User 4'), (1, 'User 5'), (0, 'User 6'),
 (1, 'User 7')]

---->   pandas.DataFrame; DataFrame.to_sql

--------------------------------------
ID: 7260 --> 1
>>> df2.to_sql('users', con=engine, if_exists='replace',
...            index_label='id')
2
>>> with engine.connect() as conn:
...    conn.execute(text("SELECT * FROM users")).fetchall()
[(0, 'User 6'), (1, 'User 7')]

---->   DataFrame.to_sql

--------------------------------------
ID: 7261 --> 1
>>> df = pd.DataFrame({"A": [1, None, 2]})
>>> df
     A
0  1.0
1  NaN
2  2.0

---->   pandas.DataFrame

--------------------------------------
ID: 7262 --> 1
>>> from sqlalchemy.types import Integer
>>> df.to_sql('integers', con=engine, index=False,
...           dtype={"A": Integer()})
3

---->   DataFrame.to_sql

--------------------------------------
ID: 7264 --> 1
>>> df = pd.DataFrame({'shape': ['square', 'circle', 'triangle'],
...                    'degrees': [360, 360, 180],
...                    'sides': [4, np.nan, 3]})

---->   pandas.DataFrame

--------------------------------------
ID: 7265 --> 1
>>> df.to_xml()  


  
    0
    square
    360
    4.0
  
  
    1
    circle
    360
    
  
  
    2
    triangle
    180
    3.0
  


---->   DataFrame.to_xml

--------------------------------------
ID: 7266 --> 1
>>> df.to_xml(attr_cols=[
...           'index', 'shape', 'degrees', 'sides'
...           ])  


  
  
  


---->   DataFrame.to_xml

--------------------------------------
ID: 7267 --> 1
>>> df.to_xml(namespaces={"doc": "https://example.com"},
...           prefix="doc")  


  
    0
    square
    360
    4.0
  
  
    1
    circle
    360
    
  
  
    2
    triangle
    180
    3.0
  


---->   DataFrame.to_xml

--------------------------------------
ID: 7268 --> 1
>>> pd.read_sql_table('table_name', 'postgres:///db_name')  

---->   pandas.read_sql_table

--------------------------------------
ID: 7269 --> 2
>>> df = pd.DataFrame(dict(name=['Raphael', 'Donatello'],
...                        age=[26, 45],
...                        height=[181.23, 177.65]))
>>> print(df.to_latex(index=False,
...                   formatters={"name": str.upper},
...                   float_format="{:.1f}".format,
... ))  
\begin{tabular}{lrr}
\toprule
name & age & height \\
\midrule
RAPHAEL & 26 & 181.2 \\
DONATELLO & 45 & 177.7 \\
\bottomrule
\end{tabular}

---->   pandas.DataFrame; DataFrame.to_latex

--------------------------------------
ID: 7270 --> 1
>>> original_df = pd.DataFrame(
...     {"foo": range(5), "bar": range(5, 10)}
...    )  
>>> original_df  
   foo  bar
0    0    5
1    1    6
2    2    7
3    3    8
4    4    9
>>> pd.to_pickle(original_df, "./dummy.pkl")  

---->   pandas.DataFrame

--------------------------------------
ID: 7271 --> 1
>>> unpickled_df = pd.read_pickle("./dummy.pkl")  
>>> unpickled_df  
   foo  bar
0    0    5
1    1    6
2    2    7
3    3    8
4    4    9

---->   pandas.read_pickle

--------------------------------------
ID: 7272 --> 2
>>> df1 = pd.DataFrame([['a', 'b'], ['c', 'd']],
...                    index=['row 1', 'row 2'],
...                    columns=['col 1', 'col 2'])
>>> df1.to_excel("output.xlsx")  

---->   pandas.DataFrame; DataFrame.to_excel

--------------------------------------
ID: 7273 --> 1
>>> df1.to_excel("output.xlsx",
...              sheet_name='Sheet_name_1')  

---->   DataFrame.to_excel

--------------------------------------
ID: 7274 --> 4
>>> df2 = df1.copy()
>>> with pd.ExcelWriter('output.xlsx') as writer:  
...     df1.to_excel(writer, sheet_name='Sheet_name_1')
...     df2.to_excel(writer, sheet_name='Sheet_name_2')

---->   DataFrame.copy; pandas.ExcelWriter; DataFrame.to_excel; DataFrame.to_excel

--------------------------------------
ID: 7275 --> 2
>>> with pd.ExcelWriter('output.xlsx',
...                     mode='a') as writer:  
...     df.to_excel(writer, sheet_name='Sheet_name_3')

---->   pandas.ExcelWriter; DataFrame.to_excel

--------------------------------------
ID: 7276 --> 1
>>> df1.to_excel('output1.xlsx', engine='xlsxwriter')  

---->   DataFrame.to_excel

--------------------------------------
ID: 7277 --> 1
>>> df = pd.DataFrame([['a', 'b'], ['c', 'd']],
...                   index=['row 1', 'row 2'],
...                   columns=['col 1', 'col 2'])

---->   pandas.DataFrame

--------------------------------------
ID: 7278 --> 1
>>> df.to_json(orient='split')
    '{"columns":["col 1","col 2"],"index":["row 1","row 2"],"data":[["a","b"],["c","d"]]}'
>>> pd.read_json(_, orient='split')
      col 1 col 2
row 1     a     b
row 2     c     d

---->   DataFrame.to_json

--------------------------------------
ID: 7279 --> 1
>>> df.to_json(orient='index')
'{"row 1":{"col 1":"a","col 2":"b"},"row 2":{"col 1":"c","col 2":"d"}}'

---->   DataFrame.to_json

--------------------------------------
ID: 7281 --> 1
>>> df.to_json(orient='records')
'[{"col 1":"a","col 2":"b"},{"col 1":"c","col 2":"d"}]'
>>> pd.read_json(_, orient='records')
  col 1 col 2
0     a     b
1     c     d

---->   DataFrame.to_json

--------------------------------------
ID: 7282 --> 1
>>> df.to_json(orient='table')
    '{"schema":{"fields":[{"name":"index","type":"string"},{"name":"col 1","type":"string"},{"name":"col 2","type":"string"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":[{"index":"row 1","col 1":"a","col 2":"b"},{"index":"row 2","col 1":"c","col 2":"d"}]}'

---->   DataFrame.to_json

--------------------------------------
ID: 7283 --> 2
>>> from sqlite3 import connect
>>> conn = connect(':memory:')
>>> df = pd.DataFrame(data=[[0, '10/11/12'], [1, '12/11/10']],
...                   columns=['int_column', 'date_column'])
>>> df.to_sql('test_data', conn)
2

---->   pandas.DataFrame; DataFrame.to_sql

--------------------------------------
ID: 7284 --> 1
>>> pd.read_sql('SELECT int_column, date_column FROM test_data', conn)
   int_column date_column
0           0    10/11/12
1           1    12/11/10

---->   pandas.read_sql

--------------------------------------
ID: 7285 --> 1
>>> pd.read_sql('test_data', 'postgres:///db_name')  

---->   pandas.read_sql

--------------------------------------
ID: 7286 --> 1
>>> pd.read_sql('SELECT int_column, date_column FROM test_data',
...             conn,
...             parse_dates={"date_column": {"format": "%d/%m/%y"}})
   int_column date_column
0           0  2012-11-10
1           1  2010-11-12

---->   pandas.read_sql

--------------------------------------
ID: 7287 --> 1
>>> s = pd.Series([0, 1, 2, 3])

---->   pandas.Series

--------------------------------------
ID: 7288 --> 1
>>> s.expanding().sem()
0         NaN
1    0.707107
2    0.707107
3    0.745356
dtype: float64

---->   Series.expanding

--------------------------------------
ID: 7289 --> 3
>>> df = pd.DataFrame([["ABC", "XYZ"]], columns=["Foo", "Bar"])  
>>> with pd.ExcelWriter("path_to_file.xlsx") as writer:
...     df.to_excel(writer)  

---->   pandas.DataFrame; pandas.ExcelWriter; DataFrame.to_excel

--------------------------------------
ID: 7290 --> 4
>>> df1 = pd.DataFrame([["AAA", "BBB"]], columns=["Spam", "Egg"])  
>>> df2 = pd.DataFrame([["ABC", "XYZ"]], columns=["Foo", "Bar"])  
>>> with pd.ExcelWriter("path_to_file.xlsx") as writer:
...     df1.to_excel(writer, sheet_name="Sheet1")  
...     df2.to_excel(writer, sheet_name="Sheet2")  

---->   pandas.DataFrame; pandas.ExcelWriter; DataFrame.to_excel; DataFrame.to_excel

--------------------------------------
ID: 7291 --> 3
>>> from datetime import date, datetime  
>>> df = pd.DataFrame(
...     [
...         [date(2014, 1, 31), date(1999, 9, 24)],
...         [datetime(1998, 5, 26, 23, 33, 4), datetime(2014, 2, 28, 13, 5, 13)],
...     ],
...     index=["Date", "Datetime"],
...     columns=["X", "Y"],
... )  
>>> with pd.ExcelWriter(
...     "path_to_file.xlsx",
...     date_format="YYYY-MM-DD",
...     datetime_format="YYYY-MM-DD HH:MM:SS"
... ) as writer:
...     df.to_excel(writer)  

---->   pandas.DataFrame; pandas.ExcelWriter; DataFrame.to_excel

--------------------------------------
ID: 7292 --> 2
>>> with pd.ExcelWriter("path_to_file.xlsx", mode="a", engine="openpyxl") as writer:
...     df.to_excel(writer, sheet_name="Sheet3")  

---->   pandas.ExcelWriter; DataFrame.to_excel

--------------------------------------
ID: 7293 --> 1
>>> with ExcelWriter(
...     "path_to_file.xlsx",
...     mode="a",
...     engine="openpyxl",
...     if_sheet_exists="replace",
... ) as writer:
...     df.to_excel(writer, sheet_name="Sheet1")  

---->   DataFrame.to_excel

--------------------------------------
ID: 7294 --> 2
>>> with ExcelWriter("path_to_file.xlsx",
...     mode="a",
...     engine="openpyxl",
...     if_sheet_exists="overlay",
... ) as writer:
...     df1.to_excel(writer, sheet_name="Sheet1")
...     df2.to_excel(writer, sheet_name="Sheet1", startcol=3)  

---->   DataFrame.to_excel; DataFrame.to_excel

--------------------------------------
ID: 7295 --> 3
>>> import io
>>> df = pd.DataFrame([["ABC", "XYZ"]], columns=["Foo", "Bar"])
>>> buffer = io.BytesIO()
>>> with pd.ExcelWriter(buffer) as writer:
...     df.to_excel(writer)

---->   pandas.DataFrame; pandas.ExcelWriter; DataFrame.to_excel

--------------------------------------
ID: 7296 --> 3
>>> import zipfile  
>>> df = pd.DataFrame([["ABC", "XYZ"]], columns=["Foo", "Bar"])  
>>> with zipfile.ZipFile("path_to_file.zip", "w") as zf:
...     with zf.open("filename.xlsx", "w") as buffer:
...         with pd.ExcelWriter(buffer) as writer:
...             df.to_excel(writer)  

---->   pandas.DataFrame; pandas.ExcelWriter; DataFrame.to_excel

--------------------------------------
ID: 7297 --> 2
>>> with pd.ExcelWriter(
...     "path_to_file.xlsx",
...     engine="xlsxwriter",
...     engine_kwargs={"options": {"nan_inf_to_errors": True}}
... ) as writer:
...     df.to_excel(writer)  

---->   pandas.ExcelWriter; DataFrame.to_excel

--------------------------------------
ID: 7298 --> 2
>>> with pd.ExcelWriter(
...     "path_to_file.xlsx",
...     engine="openpyxl",
...     mode="a",
...     engine_kwargs={"keep_vba": True}
... ) as writer:
...     df.to_excel(writer, sheet_name="Sheet2")  

---->   pandas.ExcelWriter; DataFrame.to_excel

--------------------------------------
ID: 7299 --> 2
>>> arr = [1, 2, 3, 4, 999]
>>> import scipy.stats
>>> print(f"{scipy.stats.kurtosis(arr[:-1], bias=False):.6f}")
-1.200000
>>> print(f"{scipy.stats.kurtosis(arr[1:], bias=False):.6f}")
3.999946
>>> s = pd.Series(arr)
>>> s.rolling(4).kurt()
0         NaN
1         NaN
2         NaN
3   -1.200000
4    3.999946
dtype: float64

---->   pandas.Series; Series.rolling

--------------------------------------
ID: 7300 --> 2
>>> arr = [1, 2, 3, 4, 999]
>>> import scipy.stats
>>> print(f"{scipy.stats.kurtosis(arr[:-1], bias=False):.6f}")
-1.200000
>>> print(f"{scipy.stats.kurtosis(arr, bias=False):.6f}")
4.999874
>>> s = pd.Series(arr)
>>> s.expanding(4).kurt()
0         NaN
1         NaN
2         NaN
3   -1.200000
4    4.999874
dtype: float64

---->   pandas.Series; Series.expanding

--------------------------------------
ID: 7301 --> 1
>>> s = pd.Series([5, 5, 6, 7, 5, 5, 5])

---->   pandas.Series

--------------------------------------
ID: 7302 --> 1
>>> s.expanding(3).std()
0         NaN
1         NaN
2    0.577350
3    0.957427
4    0.894427
5    0.836660
6    0.786796
dtype: float64

---->   Series.expanding

--------------------------------------
ID: 7303 --> 1
>>> s = pd.Series([5, 5, 6, 7, 5, 5, 5])

---->   pandas.Series

--------------------------------------
ID: 7304 --> 1
>>> s.expanding(3).var()
0         NaN
1         NaN
2    0.333333
3    0.916667
4    0.800000
5    0.700000
6    0.619048
dtype: float64

---->   Series.expanding

--------------------------------------
ID: 7305 --> 2
>>> s = pd.Series([2, 3, np.nan, 10])
>>> s.rolling(2).count()
0    NaN
1    2.0
2    1.0
3    1.0
dtype: float64
>>> s.rolling(3).count()
0    NaN
1    NaN
2    2.0
3    2.0
dtype: float64
>>> s.rolling(4).count()
0    NaN
1    NaN
2    NaN
3    3.0
dtype: float64

---->   pandas.Series; Series.rolling

--------------------------------------
ID: 7306 --> 2
>>> s = pd.Series([1, 2, 3, 4])
>>> s.rolling(2).mean()
0    NaN
1    1.5
2    2.5
3    3.5
dtype: float64

---->   pandas.Series; Series.rolling

--------------------------------------
ID: 7307 --> 1
>>> s.rolling(3).mean()
0    NaN
1    NaN
2    2.0
3    3.0
dtype: float64

---->   Series.rolling

--------------------------------------
ID: 7308 --> 2
>>> s = pd.Series([2, 3, np.nan, 10])
>>> s.rolling(2).count()
0    NaN
1    2.0
2    1.0
3    1.0
dtype: float64
>>> s.rolling(3).count()
0    NaN
1    NaN
2    2.0
3    2.0
dtype: float64
>>> s.rolling(4).count()
0    NaN
1    NaN
2    NaN
3    3.0
dtype: float64

---->   pandas.Series; Series.rolling

--------------------------------------
ID: 7309 --> 2
>>> s = pd.Series([5, 5, 6, 7, 5, 5, 5])
>>> s.rolling(3).std()
0         NaN
1         NaN
2    0.577350
3    1.000000
4    1.000000
5    1.154701
6    0.000000
dtype: float64

---->   pandas.Series; Series.rolling

--------------------------------------
ID: 7316 --> 2
>>> s = pd.Series([1, 4, 2, 3, 5, 3])
>>> s.expanding().rank()
0    1.0
1    2.0
2    2.0
3    3.0
4    5.0
5    3.5
dtype: float64

---->   pandas.Series; Series.expanding

--------------------------------------
ID: 7317 --> 1
>>> s.expanding().rank(method="max")
0    1.0
1    2.0
2    2.0
3    3.0
4    5.0
5    4.0
dtype: float64

---->   Series.expanding

--------------------------------------
ID: 7318 --> 1
>>> s.expanding().rank(method="min")
0    1.0
1    2.0
2    2.0
3    3.0
4    5.0
5    3.0
dtype: float64

---->   Series.expanding

--------------------------------------
ID: 7319 --> 2
>>> s = pd.Series([5, 5, 6, 7, 5, 5, 5])
>>> s.rolling(3).var()
0         NaN
1         NaN
2    0.333333
3    1.000000
4    1.000000
5    1.333333
6    0.000000
dtype: float64

---->   pandas.Series; Series.rolling

--------------------------------------
ID: 7320 --> 2
>>> s = pd.Series([0, 1, 2, 3])
>>> s.rolling(2, min_periods=1).sem()
0         NaN
1    0.707107
2    0.707107
3    0.707107
dtype: float64

---->   pandas.Series; Series.rolling

--------------------------------------
ID: 7321 --> 2
>>> s = pd.Series([1, 2, 3, 4])
>>> s.rolling(2).quantile(.4, interpolation='lower')
0    NaN
1    1.0
2    2.0
3    3.0
dtype: float64

---->   pandas.Series; Series.rolling

--------------------------------------
ID: 7322 --> 1
>>> s.rolling(2).quantile(.4, interpolation='midpoint')
0    NaN
1    1.5
2    2.5
3    3.5
dtype: float64

---->   Series.rolling

--------------------------------------
ID: 7323 --> 2
>>> s = pd.Series([1, 4, 2, 3, 5, 3])
>>> s.rolling(3).rank()
0    NaN
1    NaN
2    2.0
3    2.0
4    3.0
5    1.5
dtype: float64

---->   pandas.Series; Series.rolling

--------------------------------------
ID: 7324 --> 1
>>> s.rolling(3).rank(method="max")
0    NaN
1    NaN
2    2.0
3    2.0
4    3.0
5    2.0
dtype: float64

---->   Series.rolling

--------------------------------------
ID: 7325 --> 1
>>> s.rolling(3).rank(method="min")
0    NaN
1    NaN
2    2.0
3    2.0
4    3.0
5    1.0
dtype: float64

---->   Series.rolling

--------------------------------------
ID: 7326 --> 1
>>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]})
>>> df
     B
0  0.0
1  1.0
2  2.0
3  NaN
4  4.0

---->   pandas.DataFrame

--------------------------------------
ID: 7327 --> 1
>>> indexer = pd.api.indexers.FixedForwardWindowIndexer(window_size=2)
>>> df.rolling(window=indexer, min_periods=1).sum()
     B
0  1.0
1  3.0
2  2.0
3  4.0
4  4.0

---->   DataFrame.rolling

--------------------------------------
ID: 7328 --> 1
>>> df = pd.DataFrame({"A": [1, 2, 3], "B": [4, 5, 6], "C": [7, 8, 9]})
>>> df
   A  B  C
0  1  4  7
1  2  5  8
2  3  6  9

---->   pandas.DataFrame

--------------------------------------
ID: 7329 --> 1
>>> df.rolling(2).sum()
     A     B     C
0  NaN   NaN   NaN
1  3.0   9.0  15.0
2  5.0  11.0  17.0

---->   DataFrame.rolling

--------------------------------------
ID: 7330 --> 1
>>> df.rolling(2).agg({"A": "sum", "B": "min"})
     A    B
0  NaN  NaN
1  3.0  4.0
2  5.0  5.0

---->   DataFrame.rolling

--------------------------------------
ID: 7332 --> 1
>>> df = pd.DataFrame({"A": [1, 2, 3], "B": [4, 5, 6], "C": [7, 8, 9]})
>>> df
   A  B  C
0  1  4  7
1  2  5  8
2  3  6  9

---->   pandas.DataFrame

--------------------------------------
ID: 7333 --> 1
>>> df.ewm(alpha=0.5).mean()
          A         B         C
0  1.000000  4.000000  7.000000
1  1.666667  4.666667  7.666667
2  2.428571  5.428571  8.428571

---->   DataFrame.ewm

--------------------------------------
ID: 7334 --> 2
>>> s = pd.Series([4, 3, 5, 2, 6])
>>> s.rolling(3).min()
0    NaN
1    NaN
2    3.0
3    2.0
4    2.0
dtype: float64

---->   pandas.Series; Series.rolling

--------------------------------------
ID: 7335 --> 1
>>> s = pd.Series([1, 2, 3, 4, 5])
>>> s
0    1
1    2
2    3
3    4
4    5
dtype: int64

---->   pandas.Series

--------------------------------------
ID: 7336 --> 1
>>> s.rolling(3).sum()
0     NaN
1     NaN
2     6.0
3     9.0
4    12.0
dtype: float64

---->   Series.rolling

--------------------------------------
ID: 7337 --> 1
>>> s.rolling(3, center=True).sum()
0     NaN
1     6.0
2     9.0
3    12.0
4     NaN
dtype: float64

---->   Series.rolling

--------------------------------------
ID: 7338 --> 1
>>> df = pd.DataFrame({"A": s, "B": s ** 2})
>>> df
   A   B
0  1   1
1  2   4
2  3   9
3  4  16
4  5  25

---->   pandas.DataFrame

--------------------------------------
ID: 7339 --> 1
>>> df.rolling(3).sum()
      A     B
0   NaN   NaN
1   NaN   NaN
2   6.0  14.0
3   9.0  29.0
4  12.0  50.0

---->   DataFrame.rolling

--------------------------------------
ID: 7340 --> 2
>>> df = pd.DataFrame({"0categories": pd.Series([2, 2])})
>>> df.to_stata('test') 
... # InvalidColumnName: Not all pandas column names were valid Stata variable...

---->   pandas.DataFrame; pandas.Series

--------------------------------------
ID: 7341 --> 3
>>> df = pd.DataFrame({'A': [1, 1, 1]})
>>> df.loc[..., ..., 'A'] 
... # IndexingError: indexer may only contain one '...' entry
>>> df = pd.DataFrame({'A': [1, 1, 1]})
>>> df.loc[1, ..., ...] 
... # IndexingError: Too many indexers
>>> df[pd.Series([True], dtype=bool)] 
... # IndexingError: Unalignable boolean Series provided as indexer...
>>> s = pd.Series(range(2),
...               index = pd.MultiIndex.from_product([["a", "b"], ["c"]]))
>>> s.loc["a", "c", "d"] 
... # IndexingError: Too many indexers

---->   pandas.DataFrame; pandas.Series; pandas.MultiIndex

--------------------------------------
ID: 7342 --> 2
>>> v1 = [3, 3, 3, 5, 8]
>>> v2 = [3, 4, 4, 4, 8]
>>> # numpy returns a 2X2 array, the correlation coefficient
>>> # is the number at entry [0][1]
>>> print(f"{np.corrcoef(v1[:-1], v2[:-1])[0][1]:.6f}")
0.333333
>>> print(f"{np.corrcoef(v1[1:], v2[1:])[0][1]:.6f}")
0.916949
>>> s1 = pd.Series(v1)
>>> s2 = pd.Series(v2)
>>> s1.rolling(4).corr(s2)
0         NaN
1         NaN
2         NaN
3    0.333333
4    0.916949
dtype: float64

---->   pandas.Series; Series.rolling

--------------------------------------
ID: 7343 --> 2
>>> matrix = np.array([[51., 35.], [49., 30.], [47., 32.],        [46., 31.], [50., 36.]])
>>> print(np.corrcoef(matrix[:-1,0], matrix[:-1,1]).round(7))
[[1.         0.6263001]
 [0.6263001  1.       ]]
>>> print(np.corrcoef(matrix[1:,0], matrix[1:,1]).round(7))
[[1.         0.5553681]
 [0.5553681  1.        ]]
>>> df = pd.DataFrame(matrix, columns=['X','Y'])
>>> df
      X     Y
0  51.0  35.0
1  49.0  30.0
2  47.0  32.0
3  46.0  31.0
4  50.0  36.0
>>> df.rolling(4).corr(pairwise=True)
            X         Y
0 X       NaN       NaN
  Y       NaN       NaN
1 X       NaN       NaN
  Y       NaN       NaN
2 X       NaN       NaN
  Y       NaN       NaN
3 X  1.000000  0.626300
  Y  0.626300  1.000000
4 X  1.000000  0.555368
  Y  0.555368  1.000000

---->   pandas.DataFrame; DataFrame.rolling

--------------------------------------
ID: 7344 --> 1
>>> df = pd.DataFrame({'abs': [1, 1, 1]})
>>> df.query("abs > 2") 
... # NumExprClobberingError: Variables in expression "(abs) > (2)" overlap...
>>> sin, a = 1, 2
>>> pd.eval("sin + a", engine='numexpr') 
... # NumExprClobberingError: Variables in expression "(sin) + (a)" overlap...

---->   pandas.DataFrame

--------------------------------------
ID: 7345 --> 1
>>> df = pd.DataFrame({'A': [1, 1, 1, 2, 2]}, columns=['A'])
>>> df.loc[0:3]['A'] = 'a' 
... # SettingWithCopyWarning: A value is trying to be set on a copy of a...

---->   pandas.DataFrame

--------------------------------------
ID: 7346 --> 1
>>> from sqlite3 import connect
>>> conn = connect(':memory:')
>>> pd.read_sql('select * test', conn) 
... # DatabaseError: Execution failed on sql 'test': near "test": syntax error

---->   pandas.read_sql

--------------------------------------
ID: 7347 --> 2
>>> s = pd.Series([0, 1, 2, 3, 4])
>>> s.rolling(3).median()
0    NaN
1    NaN
2    1.0
3    2.0
4    3.0
dtype: float64

---->   pandas.Series; Series.rolling

--------------------------------------
ID: 7348 --> 1
>>> from pandas.testing import assert_frame_equal
>>> df1 = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})
>>> df2 = pd.DataFrame({'a': [1, 2], 'b': [3.0, 4.0]})

---->   pandas.DataFrame

--------------------------------------
ID: 7352 --> 2
>>> df = pd.DataFrame({"s": pd.Series([1, 2**53], dtype=np.int64)})
>>> df.to_stata('test') 
... # PossiblePrecisionLoss: Column converted from int64 to float64...

---->   pandas.DataFrame; pandas.Series

--------------------------------------
ID: 7353 --> 1
>>> pd.options.mode.chained_assignment = 'raise'
>>> df = pd.DataFrame({'A': [1, 1, 1, 2, 2]}, columns=['A'])
>>> df.loc[0:3]['A'] = 'a' 
... # SettingWithCopyError: A value is trying to be set on a copy of a...

---->   pandas.DataFrame

--------------------------------------
ID: 7354 --> 1
>>> df = pd.DataFrame({'A': [1, 1, 1]})
>>> df.query("A > x") 
... # UndefinedVariableError: name 'x' is not defined
>>> df.query("A > @y") 
... # UndefinedVariableError: local variable 'y' is not defined
>>> pd.eval('x + 1') 
... # UndefinedVariableError: name 'x' is not defined

---->   pandas.DataFrame

--------------------------------------
ID: 7357 --> 1
>>> from pandas import testing as tm
>>> a = pd.Series([1, 2, 3, 4])
>>> b = pd.Series([1, 2, 3, 4])
>>> tm.assert_series_equal(a, b)

---->   pandas.Series

--------------------------------------
ID: 7358 --> 2
>>> df = pd.DataFrame({'A': [1, 1, 1, 2, 2],
...                    'B': range(5),
...                    'C': range(5)})
>>> df.groupby('A').B.agg({'foo': 'count'}) 
... # SpecificationError: nested renamer is not supported

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 7359 --> 1
>>> df.groupby('A').agg({'B': {'foo': ['sum', 'max']}}) 
... # SpecificationError: nested renamer is not supported

---->   DataFrame.groupby

--------------------------------------
ID: 7360 --> 1
>>> df.groupby('A').agg(['min', 'min']) 
... # SpecificationError: nested renamer is not supported

---->   DataFrame.groupby

--------------------------------------
ID: 7361 --> 1
>>> from pandas import testing as tm
>>> a = pd.Index([1, 2, 3])
>>> b = pd.Index([1, 2, 3])
>>> tm.assert_index_equal(a, b)

---->   pandas.Index

--------------------------------------
ID: 7362 --> 1
>>> pd.options.mode.copy_on_write = True
>>> df = pd.DataFrame({'A': [1, 1, 1, 2, 2]}, columns=['A'])
>>> df["A"][0:3] = 10 
... # ChainedAssignmentError: ...
>>> pd.options.mode.copy_on_write = False

---->   pandas.DataFrame

--------------------------------------
ID: 7363 --> 2
>>> df = pd.DataFrame({"categories": pd.Series(["a", 2], dtype="category")})
>>> df.to_stata('test') 
... # ValueLabelTypeMismatch: Stata value labels (pandas categories) must be str...

---->   pandas.DataFrame; pandas.Series

--------------------------------------
ID: 7364 --> 1
>>> from pandas import testing as tm
>>> a = pd.Series([1, 2, 3, 4])
>>> b, c = a.array, a.array
>>> tm.assert_extension_array_equal(b, c)

---->   pandas.Series

--------------------------------------
ID: 7365 --> 1
>>> s = pd.Series([0, 1, 2], index=['a', 'b', 'c']).set_flags(
...     allows_duplicate_labels=False
... )
>>> s.reindex(['a', 'a', 'b'])
Traceback (most recent call last):
   ...
DuplicateLabelError: Index has duplicates.
      positions
label
a        [0, 1]

---->   pandas.Series

--------------------------------------
ID: 7366 --> 1
>>> mask = pd.array([True, False])
>>> arr = pd.array([1, 2])
>>> pd.api.indexers.check_array_indexer(arr, mask)
array([ True, False])

---->   pandas.array

--------------------------------------
ID: 7367 --> 1
>>> mask = pd.array([True, False, True])
>>> pd.api.indexers.check_array_indexer(arr, mask)
Traceback (most recent call last):
...
IndexError: Boolean index has wrong length: 3 instead of 2.

---->   pandas.array

--------------------------------------
ID: 7368 --> 1
>>> mask = pd.array([True, pd.NA])
>>> pd.api.indexers.check_array_indexer(arr, mask)
array([ True, False])

---->   pandas.array

--------------------------------------
ID: 7370 --> 1
>>> indexer = pd.array([0, 2], dtype="Int64")
>>> arr = pd.array([1, 2, 3])
>>> pd.api.indexers.check_array_indexer(arr, indexer)
array([0, 2])

---->   pandas.array

--------------------------------------
ID: 7371 --> 1
>>> indexer = pd.array([0, pd.NA], dtype="Int64")
>>> pd.api.indexers.check_array_indexer(arr, indexer)
Traceback (most recent call last):
...
ValueError: Cannot index with an integer indexer containing NA values

---->   pandas.array

--------------------------------------
ID: 7374 --> 1
>>> df = pd.DataFrame({'A': [1, 1, 1]})
>>> (df.style.applymap(lambda x: 'background-color: blueGreenRed;')
...         .to_excel('styled.xlsx')) 
... # CSSWarning: Unhandled color format: 'blueGreenRed'
>>> (df.style.applymap(lambda x: 'border: 1px solid red red;')
...         .to_excel('styled.xlsx')) 
... # CSSWarning: Too many tokens provided to "border" (expected 1-3)

---->   pandas.DataFrame

--------------------------------------
ID: 7375 --> 2
>>> ser = pd.Series([390., 350., 357., np.nan, 22., 20., 30.],
...                 index=['Falcon', 'Falcon', 'Falcon', 'Falcon',
...                        'Parrot', 'Parrot', 'Parrot'],
...                 name="Max Speed")
>>> ser
Falcon    390.0
Falcon    350.0
Falcon    357.0
Falcon      NaN
Parrot     22.0
Parrot     20.0
Parrot     30.0
Name: Max Speed, dtype: float64
>>> ser.groupby(level=0).skew()
Falcon    1.525174
Parrot    1.457863
Name: Max Speed, dtype: float64
>>> ser.groupby(level=0).skew(skipna=False)
Falcon         NaN
Parrot    1.457863
Name: Max Speed, dtype: float64

---->   pandas.Series; Series.groupby

--------------------------------------
ID: 7377 --> 1
>>> idx = pd.date_range('1/1/2000', periods=4, freq='T')
>>> df = pd.DataFrame(data=4 * [range(2)],
...                   index=idx,
...                   columns=['a', 'b'])
>>> df.iloc[2, 0] = 5
>>> df
                    a  b
2000-01-01 00:00:00  0  1
2000-01-01 00:01:00  0  1
2000-01-01 00:02:00  5  1
2000-01-01 00:03:00  0  1

---->   pandas.DataFrame

--------------------------------------
ID: 7378 --> 1
>>> df.groupby('a').resample('3T').sum()
                         a  b
a
0   2000-01-01 00:00:00  0  2
    2000-01-01 00:03:00  0  1
5   2000-01-01 00:00:00  5  1

---->   DataFrame.groupby

--------------------------------------
ID: 7379 --> 1
>>> df.groupby('a').resample('30S').sum()
                    a  b
a
0   2000-01-01 00:00:00  0  1
    2000-01-01 00:00:30  0  0
    2000-01-01 00:01:00  0  1
    2000-01-01 00:01:30  0  0
    2000-01-01 00:02:00  0  0
    2000-01-01 00:02:30  0  0
    2000-01-01 00:03:00  0  1
5   2000-01-01 00:02:00  5  1

---->   DataFrame.groupby

--------------------------------------
ID: 7380 --> 1
>>> df.groupby('a').resample('M').sum()
            a  b
a
0   2000-01-31  0  3
5   2000-01-31  5  1

---->   DataFrame.groupby

--------------------------------------
ID: 7381 --> 1
>>> df.groupby('a').resample('3T', closed='right').sum()
                         a  b
a
0   1999-12-31 23:57:00  0  1
    2000-01-01 00:00:00  0  2
5   2000-01-01 00:00:00  5  1

---->   DataFrame.groupby

--------------------------------------
ID: 7382 --> 1
>>> df.groupby('a').resample('3T', closed='right', label='right').sum()
                         a  b
a
0   2000-01-01 00:00:00  0  1
    2000-01-01 00:03:00  0  2
5   2000-01-01 00:03:00  5  1

---->   DataFrame.groupby

--------------------------------------
ID: 7383 --> 1
>>> from pandas.testing import assert_frame_equal
>>> df1 = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})
>>> df2 = pd.DataFrame({'a': [1, 2], 'b': [3.0, 4.0]})

---->   pandas.DataFrame

--------------------------------------
ID: 7387 --> 2
>>> df = pd.DataFrame({'a': (['1'] * 100000 + ['X'] * 100000 +
...                          ['1'] * 100000),
...                    'b': ['b'] * 300000})  
>>> df.to_csv('test.csv', index=False)  
>>> df2 = pd.read_csv('test.csv')  
... # DtypeWarning: Columns (0) have mixed types

---->   pandas.DataFrame; DataFrame.to_csv

--------------------------------------
ID: 7390 --> 1
>>> df = pd.DataFrame({'consumption': [10.51, 103.11, 55.48],
...                    'co2_emissions': [37.2, 19.66, 1712]},
...                    index=['Pork', 'Wheat Products', 'Beef'])

---->   pandas.DataFrame

--------------------------------------
ID: 7391 --> 1
>>> df.idxmin()
consumption                Pork
co2_emissions    Wheat Products
dtype: object

---->   DataFrame.idxmin

--------------------------------------
ID: 7392 --> 1
>>> df.idxmin(axis="columns")
Pork                consumption
Wheat Products    co2_emissions
Beef                consumption
dtype: object

---->   DataFrame.idxmin

--------------------------------------
ID: 7393 --> 2
>>> s = pd.Series([0, 1, 2], index='a a b'.split())
>>> g1 = s.groupby(s.index, group_keys=False)
>>> g2 = s.groupby(s.index, group_keys=True)

---->   pandas.Series; Series.groupby

--------------------------------------
ID: 7396 --> 2
>>> g1.apply(lambda x: x.max() - x.min())
a    1
b    0
dtype: int64

---->   Series.max; Series.min

--------------------------------------
ID: 7397 --> 2
>>> g2.apply(lambda x: x.max() - x.min())
a    1
b    0
dtype: int64

---->   Series.max; Series.min

--------------------------------------
ID: 7398 --> 1
>>> s = pd.Series([1, 2, 3, 4])

---->   pandas.Series

--------------------------------------
ID: 7399 --> 1
>>> s.groupby([1, 1, 2, 2]).min()
1    1
2    3
dtype: int64

---->   Series.groupby

--------------------------------------
ID: 7400 --> 1
>>> s.groupby([1, 1, 2, 2]).agg('min')
1    1
2    3
dtype: int64

---->   Series.groupby

--------------------------------------
ID: 7401 --> 1
>>> s.groupby([1, 1, 2, 2]).agg(['min', 'max'])
   min  max
1    1    2
2    3    4

---->   Series.groupby

--------------------------------------
ID: 7402 --> 1
>>> s.groupby([1, 1, 2, 2]).agg(
...     minimum='min',
...     maximum='max',
... )
   minimum  maximum
1        1        2
2        3        4

---->   Series.groupby

--------------------------------------
ID: 7403 --> 2
>>> s.groupby([1, 1, 2, 2]).agg(lambda x: x.astype(float).min())
1    1.0
2    3.0
dtype: float64

---->   Series.groupby; Series.astype

--------------------------------------
ID: 7404 --> 2
>>> df = pd.DataFrame({'A': 'a a b'.split(),
...                    'B': [1,2,3],
...                    'C': [4,6,5]})
>>> g1 = df.groupby('A', group_keys=False)
>>> g2 = df.groupby('A', group_keys=True)

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 7405 --> 1
>>> g1[['B', 'C']].apply(lambda x: x / x.sum())
          B    C
0  0.333333  0.4
1  0.666667  0.6
2  1.000000  1.0

---->   Series.sum

--------------------------------------
ID: 7406 --> 1
>>> g2[['B', 'C']].apply(lambda x: x / x.sum())
            B    C
A
a 0  0.333333  0.4
  1  0.666667  0.6
b 2  1.000000  1.0

---->   Series.sum

--------------------------------------
ID: 7407 --> 2
>>> g1[['B', 'C']].apply(lambda x: x.astype(float).max() - x.min())
     B    C
A
a  1.0  2.0
b  0.0  0.0

---->   Series.astype; Series.min

--------------------------------------
ID: 7408 --> 2
>>> g2[['B', 'C']].apply(lambda x: x.astype(float).max() - x.min())
     B    C
A
a  1.0  2.0
b  0.0  0.0

---->   Series.astype; Series.min

--------------------------------------
ID: 7410 --> 2
>>> df = pd.DataFrame({'A': [1, 1, 2, 1, 2],
...                    'B': [np.nan, 2, 3, 4, 5]}, columns=['A', 'B'])
>>> g = df.groupby('A')
>>> g.nth(0)
   A   B
0  1 NaN
2  2 3.0
>>> g.nth(1)
   A   B
1  1 2.0
4  2 5.0
>>> g.nth(-1)
   A   B
3  1 4.0
4  2 5.0
>>> g.nth([0, 1])
   A   B
0  1 NaN
1  1 2.0
2  2 3.0
4  2 5.0
>>> g.nth(slice(None, -1))
   A   B
0  1 NaN
1  1 2.0
2  2 3.0

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 7413 --> 1
self.apply(lambda x: pd.Series(np.arange(len(x)), x.index))

---->   pandas.Series

--------------------------------------
ID: 7414 --> 2
>>> df = pd.DataFrame([['a'], ['a'], ['a'], ['b'], ['b'], ['a']],
...                   columns=['A'])
>>> df
   A
0  a
1  a
2  a
3  b
4  b
5  a
>>> df.groupby('A').cumcount()
0    0
1    1
2    2
3    0
4    1
5    3
dtype: int64
>>> df.groupby('A').cumcount(ascending=False)
0    3
1    2
2    1
3    1
4    0
5    0
dtype: int64

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 7415 --> 1
>>> df = pd.DataFrame({'A': [1, 1, 2, 1, 2],
...                    'B': [np.nan, 2, 3, 4, 5],
...                    'C': [1, 2, 1, 1, 2]}, columns=['A', 'B', 'C'])

---->   pandas.DataFrame

--------------------------------------
ID: 7416 --> 1
>>> df.groupby('A').mean()
     B         C
A
1  3.0  1.333333
2  4.0  1.500000

---->   DataFrame.groupby

--------------------------------------
ID: 7417 --> 1
>>> df.groupby(['A', 'B']).mean()
         C
A B
1 2.0  2.0
  4.0  1.0
2 3.0  1.0
  5.0  2.0

---->   DataFrame.groupby

--------------------------------------
ID: 7418 --> 1
>>> df.groupby('A')['B'].mean()
A
1    3.0
2    4.0
Name: B, dtype: float64

---->   DataFrame.groupby

--------------------------------------
ID: 7419 --> 2
>>> df = pd.DataFrame(dict(A=[1, 1, 3], B=[5, None, 6], C=[1, 2, 3]))
>>> df.groupby("A").last()
     B  C
A
1  5.0  2
3  6.0  3

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 7420 --> 3
>>> df = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar',
...                           'foo', 'bar'],
...                    'B' : [1, 2, 3, 4, 5, 6],
...                    'C' : [2.0, 5., 8., 1., 2., 9.]})
>>> grouped = df.groupby('A')
>>> df.groupby('A').B.filter(lambda x: x.mean() > 3.)
1    2
3    4
5    6
Name: B, dtype: int64

---->   pandas.DataFrame; DataFrame.groupby; Series.mean

--------------------------------------
ID: 7421 --> 1
>>> df = pd.DataFrame({
...    'gender': ['male', 'male', 'female', 'male', 'female', 'male'],
...    'education': ['low', 'medium', 'high', 'low', 'high', 'low'],
...    'country': ['US', 'FR', 'US', 'FR', 'FR', 'FR']
... })

---->   pandas.DataFrame

--------------------------------------
ID: 7422 --> 1
>>> df.groupby('gender').value_counts()
gender  education  country
female  high       FR         1
                   US         1
male    low        FR         2
                   US         1
        medium     FR         1
Name: count, dtype: int64

---->   DataFrame.groupby

--------------------------------------
ID: 7423 --> 1
>>> df.groupby('gender').value_counts(ascending=True)
gender  education  country
female  high       FR         1
                   US         1
male    low        US         1
        medium     FR         1
        low        FR         2
Name: count, dtype: int64

---->   DataFrame.groupby

--------------------------------------
ID: 7424 --> 1
>>> df.groupby('gender').value_counts(normalize=True)
gender  education  country
female  high       FR         0.50
                   US         0.50
male    low        FR         0.50
                   US         0.25
        medium     FR         0.25
Name: proportion, dtype: float64

---->   DataFrame.groupby

--------------------------------------
ID: 7425 --> 1
>>> df.groupby('gender', as_index=False).value_counts()
   gender education country  count
0  female      high      FR      1
1  female      high      US      1
2    male       low      FR      2
3    male       low      US      1
4    male    medium      FR      1

---->   DataFrame.groupby

--------------------------------------
ID: 7426 --> 1
>>> df.groupby('gender', as_index=False).value_counts(normalize=True)
   gender education country  proportion
0  female      high      FR        0.50
1  female      high      US        0.50
2    male       low      FR        0.50
3    male       low      US        0.25
4    male    medium      FR        0.25

---->   DataFrame.groupby

--------------------------------------
ID: 7427 --> 1
>>> df = pd.DataFrame({'id': ['spam', 'egg', 'egg', 'spam',
...                           'ham', 'ham'],
...                    'value1': [1, 5, 5, 2, 5, 5],
...                    'value2': list('abbaxy')})
>>> df
     id  value1 value2
0  spam       1      a
1   egg       5      b
2   egg       5      b
3  spam       2      a
4   ham       5      x
5   ham       5      y

---->   pandas.DataFrame

--------------------------------------
ID: 7428 --> 1
>>> df.groupby('id').nunique()
      value1  value2
id
egg        1       1
ham        1       2
spam       2       1

---->   DataFrame.groupby

--------------------------------------
ID: 7429 --> 1
>>> df.groupby('id').filter(lambda g: (g.nunique() > 1).any())
     id  value1 value2
0  spam       1      a
3  spam       2      a
4   ham       5      x
5   ham       5      y

---->   DataFrame.groupby

--------------------------------------
ID: 7430 --> 3
>>> df = pd.DataFrame(
...     {
...         "Animal": ["Falcon", "Parrot", "Falcon", "Falcon", "Parrot"],
...         "Speed": [100, 5, 200, 300, 15],
...     }
... )
>>> df
   Animal  Speed
0  Falcon    100
1  Parrot      5
2  Falcon    200
3  Falcon    300
4  Parrot     15
>>> df.groupby(pd.Grouper(key="Animal")).mean()
        Speed
Animal
Falcon  200.0
Parrot   10.0

---->   pandas.DataFrame; DataFrame.groupby; pandas.Grouper

--------------------------------------
ID: 7431 --> 3
>>> df = pd.DataFrame(
...    {
...        "Publish date": [
...             pd.Timestamp("2000-01-02"),
...             pd.Timestamp("2000-01-02"),
...             pd.Timestamp("2000-01-09"),
...             pd.Timestamp("2000-01-16")
...         ],
...         "ID": [0, 1, 2, 3],
...         "Price": [10, 20, 30, 40]
...     }
... )
>>> df
  Publish date  ID  Price
0   2000-01-02   0     10
1   2000-01-02   1     20
2   2000-01-09   2     30
3   2000-01-16   3     40
>>> df.groupby(pd.Grouper(key="Publish date", freq="1W")).mean()
               ID  Price
Publish date
2000-01-02    0.5   15.0
2000-01-09    2.0   30.0
2000-01-16    3.0   40.0

---->   pandas.DataFrame; DataFrame.groupby; pandas.Grouper

--------------------------------------
ID: 7432 --> 1
>>> start, end = '2000-10-01 23:30:00', '2000-10-02 00:30:00'
>>> rng = pd.date_range(start, end, freq='7min')
>>> ts = pd.Series(np.arange(len(rng)) * 3, index=rng)
>>> ts
2000-10-01 23:30:00     0
2000-10-01 23:37:00     3
2000-10-01 23:44:00     6
2000-10-01 23:51:00     9
2000-10-01 23:58:00    12
2000-10-02 00:05:00    15
2000-10-02 00:12:00    18
2000-10-02 00:19:00    21
2000-10-02 00:26:00    24
Freq: 7T, dtype: int64

---->   pandas.Series

--------------------------------------
ID: 7433 --> 2
>>> ts.groupby(pd.Grouper(freq='17min')).sum()
2000-10-01 23:14:00     0
2000-10-01 23:31:00     9
2000-10-01 23:48:00    21
2000-10-02 00:05:00    54
2000-10-02 00:22:00    24
Freq: 17T, dtype: int64

---->   Series.groupby; pandas.Grouper

--------------------------------------
ID: 7434 --> 2
>>> ts.groupby(pd.Grouper(freq='17min', origin='epoch')).sum()
2000-10-01 23:18:00     0
2000-10-01 23:35:00    18
2000-10-01 23:52:00    27
2000-10-02 00:09:00    39
2000-10-02 00:26:00    24
Freq: 17T, dtype: int64

---->   Series.groupby; pandas.Grouper

--------------------------------------
ID: 7435 --> 2
>>> ts.groupby(pd.Grouper(freq='17min', origin='2000-01-01')).sum()
2000-10-01 23:24:00     3
2000-10-01 23:41:00    15
2000-10-01 23:58:00    45
2000-10-02 00:15:00    45
Freq: 17T, dtype: int64

---->   Series.groupby; pandas.Grouper

--------------------------------------
ID: 7436 --> 2
>>> ts.groupby(pd.Grouper(freq='17min', origin='start')).sum()
2000-10-01 23:30:00     9
2000-10-01 23:47:00    21
2000-10-02 00:04:00    54
2000-10-02 00:21:00    24
Freq: 17T, dtype: int64

---->   Series.groupby; pandas.Grouper

--------------------------------------
ID: 7437 --> 2
>>> ts.groupby(pd.Grouper(freq='17min', offset='23h30min')).sum()
2000-10-01 23:30:00     9
2000-10-01 23:47:00    21
2000-10-02 00:04:00    54
2000-10-02 00:21:00    24
Freq: 17T, dtype: int64

---->   Series.groupby; pandas.Grouper

--------------------------------------
ID: 7438 --> 2
>>> ts.groupby(pd.Grouper(freq='17min', offset='2min')).sum()
2000-10-01 23:16:00     0
2000-10-01 23:33:00     9
2000-10-01 23:50:00    36
2000-10-02 00:07:00    39
2000-10-02 00:24:00    24
Freq: 17T, dtype: int64

---->   Series.groupby; pandas.Grouper

--------------------------------------
ID: 7439 --> 3
>>> df = pd.DataFrame(dict(A=[1, 1, 3], B=[None, 5, 6], C=[1, 2, 3],
...                        D=['3/11/2000', '3/12/2000', '3/13/2000']))
>>> df['D'] = pd.to_datetime(df['D'])
>>> df.groupby("A").first()
     B  C          D
A
1  5.0  1 2000-03-11
3  6.0  3 2000-03-13
>>> df.groupby("A").first(min_count=2)
    B    C          D
A
1 NaN  1.0 2000-03-11
3 NaN  NaN        NaT
>>> df.groupby("A").first(numeric_only=True)
     B  C
A
1  5.0  1
3  6.0  3

---->   pandas.DataFrame; pandas.to_datetime; DataFrame.groupby

--------------------------------------
ID: 7440 --> 1
>>> ser = pd.Series([np.nan, np.nan, 2, 3, np.nan, np.nan])
>>> ser
0    NaN
1    NaN
2    2.0
3    3.0
4    NaN
5    NaN
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 7441 --> 1
>>> ser.groupby([0, 0, 0, 1, 1, 1]).fillna(method="ffill")
0    NaN
1    NaN
2    2.0
3    3.0
4    3.0
5    3.0
dtype: float64

---->   Series.groupby

--------------------------------------
ID: 7442 --> 1
>>> ser.groupby([0, 0, 0, 1, 1, 1]).fillna(method="bfill")
0    2.0
1    2.0
2    2.0
3    3.0
4    NaN
5    NaN
dtype: float64

---->   Series.groupby

--------------------------------------
ID: 7443 --> 1
>>> ser.groupby([0, 0, 0, 1, 1, 1]).fillna(method="ffill", limit=1)
0    NaN
1    NaN
2    2.0
3    3.0
4    3.0
5    NaN
dtype: float64

---->   Series.groupby

--------------------------------------
ID: 7444 --> 2
>>> index = ["a", "b", "c", "d", "e"]
>>> columns = ["one", "two", "three", "four"]
>>> df1 = pd.DataFrame(np.arange(20).reshape(5, 4), index=index, columns=columns)
>>> df2 = pd.DataFrame(np.arange(16).reshape(4, 4), index=index[:4], columns=columns)
>>> df1.corrwith(df2)
one      1.0
two      1.0
three    1.0
four     1.0
dtype: float64

---->   pandas.DataFrame; DataFrame.corrwith

--------------------------------------
ID: 7445 --> 1
>>> df2.corrwith(df1, axis=1)
a    1.0
b    1.0
c    1.0
d    1.0
e    NaN
dtype: float64

---->   DataFrame.corrwith

--------------------------------------
ID: 7446 --> 2
>>> s1 = pd.Series([0.90010907, 0.13484424, 0.62036035])
>>> s2 = pd.Series([0.12528585, 0.26962463, 0.51111198])
>>> s1.cov(s2)
-0.01685762652715874

---->   pandas.Series; Series.cov

--------------------------------------
ID: 7447 --> 3
>>> import itertools
>>> tuples = [t for t in itertools.product(range(1000), range(4))]
>>> index = pd.MultiIndex.from_tuples(tuples, names=['lvl0', 'lvl1'])
>>> data = np.random.randn(len(index),4)
>>> df = pd.DataFrame(data, columns=list('ABCD'), index=index)
>>> grouped = df.groupby(level='lvl1')
>>> grouped.boxplot(rot=45, fontsize=12, figsize=(8,10))  

---->   pandas.MultiIndex; pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 7449 --> 1
>>> countries_population = {"Italy": 59000000, "France": 65000000,
...                         "Brunei": 434000, "Malta": 434000,
...                         "Maldives": 434000, "Iceland": 337000,
...                         "Nauru": 11300, "Tuvalu": 11300,
...                         "Anguilla": 11300, "Montserrat": 5200}
>>> s = pd.Series(countries_population)
>>> s
Italy       59000000
France      65000000
Brunei        434000
Malta         434000
Maldives      434000
Iceland       337000
Nauru          11300
Tuvalu         11300
Anguilla       11300
Montserrat      5200
dtype: int64

---->   pandas.Series

--------------------------------------
ID: 7450 --> 1
>>> s.nsmallest()
Montserrat    5200
Nauru        11300
Tuvalu       11300
Anguilla     11300
Iceland     337000
dtype: int64

---->   Series.nsmallest

--------------------------------------
ID: 7451 --> 1
>>> s.nsmallest(3)
Montserrat   5200
Nauru       11300
Tuvalu      11300
dtype: int64

---->   Series.nsmallest

--------------------------------------
ID: 7452 --> 1
>>> s.nsmallest(3, keep='last')
Montserrat   5200
Anguilla    11300
Tuvalu      11300
dtype: int64

---->   Series.nsmallest

--------------------------------------
ID: 7453 --> 1
>>> s.nsmallest(3, keep='all')
Montserrat   5200
Nauru       11300
Tuvalu      11300
Anguilla    11300
dtype: int64

---->   Series.nsmallest

--------------------------------------
ID: 7454 --> 2
>>> s = pd.Series([1, 2, 3])
>>> s.describe()
count    3.0
mean     2.0
std      1.0
min      1.0
25%      1.5
50%      2.0
75%      2.5
max      3.0
dtype: float64

---->   pandas.Series; Series.describe

--------------------------------------
ID: 7455 --> 2
>>> s = pd.Series(['a', 'a', 'b', 'c'])
>>> s.describe()
count     4
unique    3
top       a
freq      2
dtype: object

---->   pandas.Series; Series.describe

--------------------------------------
ID: 7456 --> 2
>>> s = pd.Series([
...     np.datetime64("2000-01-01"),
...     np.datetime64("2010-01-01"),
...     np.datetime64("2010-01-01")
... ])
>>> s.describe()
count                      3
mean     2006-09-01 08:00:00
min      2000-01-01 00:00:00
25%      2004-12-31 12:00:00
50%      2010-01-01 00:00:00
75%      2010-01-01 00:00:00
max      2010-01-01 00:00:00
dtype: object

---->   pandas.Series; Series.describe

--------------------------------------
ID: 7457 --> 3
>>> df = pd.DataFrame({'categorical': pd.Categorical(['d','e','f']),
...                    'numeric': [1, 2, 3],
...                    'object': ['a', 'b', 'c']
...                   })
>>> df.describe()
       numeric
count      3.0
mean       2.0
std        1.0
min        1.0
25%        1.5
50%        2.0
75%        2.5
max        3.0

---->   pandas.DataFrame; pandas.Categorical; DataFrame.describe

--------------------------------------
ID: 7458 --> 1
>>> df.describe(include='all')  
       categorical  numeric object
count            3      3.0      3
unique           3      NaN      3
top              f      NaN      a
freq             1      NaN      1
mean           NaN      2.0    NaN
std            NaN      1.0    NaN
min            NaN      1.0    NaN
25%            NaN      1.5    NaN
50%            NaN      2.0    NaN
75%            NaN      2.5    NaN
max            NaN      3.0    NaN

---->   DataFrame.describe

--------------------------------------
ID: 7460 --> 1
>>> df.describe(include=[np.number])
       numeric
count      3.0
mean       2.0
std        1.0
min        1.0
25%        1.5
50%        2.0
75%        2.5
max        3.0

---->   DataFrame.describe

--------------------------------------
ID: 7461 --> 1
>>> df.describe(include=[object])  
       object
count       3
unique      3
top         a
freq        1

---->   DataFrame.describe

--------------------------------------
ID: 7462 --> 1
>>> df.describe(include=['category'])
       categorical
count            3
unique           3
top              d
freq             1

---->   DataFrame.describe

--------------------------------------
ID: 7463 --> 1
>>> df.describe(exclude=[np.number])  
       categorical object
count            3      3
unique           3      3
top              f      a
freq             1      1

---->   DataFrame.describe

--------------------------------------
ID: 7464 --> 1
>>> df.describe(exclude=[object])  
       categorical  numeric
count            3      3.0
unique           3      NaN
top              f      NaN
freq             1      NaN
mean           NaN      2.0
std            NaN      1.0
min            NaN      1.0
25%            NaN      1.5
50%            NaN      2.0
75%            NaN      2.5
max            NaN      3.0

---->   DataFrame.describe

--------------------------------------
ID: 7465 --> 2
>>> def histogram_intersection(a, b):
...     v = np.minimum(a, b).sum().round(decimals=1)
...     return v
>>> s1 = pd.Series([.2, .0, .6, .2])
>>> s2 = pd.Series([.3, .6, .0, .1])
>>> s1.corr(s2, method=histogram_intersection)
0.3

---->   pandas.Series; Series.corr

--------------------------------------
ID: 7466 --> 2
>>> df = pd.DataFrame(
...     {
...         "group": ["a", "a", "a", "a", "a", "b", "b", "b", "b", "b"],
...         "value": [2, 4, 2, 3, 5, 1, 2, 4, 1, 5],
...     }
... )
>>> df
  group  value
0     a      2
1     a      4
2     a      2
3     a      3
4     a      5
5     b      1
6     b      2
7     b      4
8     b      1
9     b      5
>>> for method in ['average', 'min', 'max', 'dense', 'first']:
...     df[f'{method}_rank'] = df.groupby('group')['value'].rank(method)
>>> df
  group  value  average_rank  min_rank  max_rank  dense_rank  first_rank
0     a      2           1.5       1.0       2.0         1.0         1.0
1     a      4           4.0       4.0       4.0         3.0         4.0
2     a      2           1.5       1.0       2.0         1.0         2.0
3     a      3           3.0       3.0       3.0         2.0         3.0
4     a      5           5.0       5.0       5.0         4.0         5.0
5     b      1           1.5       1.0       2.0         1.0         1.0
6     b      2           3.0       3.0       3.0         2.0         3.0
7     b      4           4.0       4.0       4.0         3.0         4.0
8     b      1           1.5       1.0       2.0         1.0         2.0
9     b      5           5.0       5.0       5.0         4.0         5.0

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 7467 --> 1
>>> df = pd.DataFrame(
...     {"a": ["red"] * 2 + ["blue"] * 2 + ["black"] * 2, "b": range(6)}
... )
>>> df
       a  b
0    red  0
1    red  1
2   blue  2
3   blue  3
4  black  4
5  black  5

---->   pandas.DataFrame

--------------------------------------
ID: 7468 --> 1
>>> df.groupby("a").sample(n=1, random_state=1)
       a  b
4  black  4
2   blue  2
1    red  1

---->   DataFrame.groupby

--------------------------------------
ID: 7469 --> 1
>>> df.groupby("a")["b"].sample(frac=0.5, random_state=2)
5    5
2    2
0    0
Name: b, dtype: int64

---->   DataFrame.groupby

--------------------------------------
ID: 7470 --> 1
>>> df.groupby("a").sample(
...     n=1,
...     weights=[1, 1, 1, 0, 0, 1],
...     random_state=1,
... )
       a  b
5  black  5
2   blue  2
0    red  0

---->   DataFrame.groupby

--------------------------------------
ID: 7471 --> 1
>>> df = pd.DataFrame([('falcon', 'bird', 389.0),
...                    ('parrot', 'bird', 24.0),
...                    ('lion', 'mammal', 80.5),
...                    ('monkey', 'mammal', np.nan),
...                    ('rabbit', 'mammal', 15.0)],
...                   columns=['name', 'class', 'max_speed'],
...                   index=[4, 3, 2, 1, 0])
>>> df
     name   class  max_speed
4  falcon    bird      389.0
3  parrot    bird       24.0
2    lion  mammal       80.5
1  monkey  mammal        NaN
0  rabbit  mammal       15.0
>>> gb = df["name"].groupby([1, 1, 2, 2, 2])

---->   pandas.DataFrame

--------------------------------------
ID: 7474 --> 1
>>> countries_population = {"Italy": 59000000, "France": 65000000,
...                         "Malta": 434000, "Maldives": 434000,
...                         "Brunei": 434000, "Iceland": 337000,
...                         "Nauru": 11300, "Tuvalu": 11300,
...                         "Anguilla": 11300, "Montserrat": 5200}
>>> s = pd.Series(countries_population)
>>> s
Italy       59000000
France      65000000
Malta         434000
Maldives      434000
Brunei        434000
Iceland       337000
Nauru          11300
Tuvalu         11300
Anguilla       11300
Montserrat      5200
dtype: int64

---->   pandas.Series

--------------------------------------
ID: 7475 --> 1
>>> s.nlargest()
France      65000000
Italy       59000000
Malta         434000
Maldives      434000
Brunei        434000
dtype: int64

---->   Series.nlargest

--------------------------------------
ID: 7476 --> 1
>>> s.nlargest(3)
France    65000000
Italy     59000000
Malta       434000
dtype: int64

---->   Series.nlargest

--------------------------------------
ID: 7477 --> 1
>>> s.nlargest(3, keep='last')
France      65000000
Italy       59000000
Brunei        434000
dtype: int64

---->   Series.nlargest

--------------------------------------
ID: 7478 --> 1
>>> s.nlargest(3, keep='all')
France      65000000
Italy       59000000
Malta         434000
Maldives      434000
Brunei        434000
dtype: int64

---->   Series.nlargest

--------------------------------------
ID: 7479 --> 1
>>> h(g(f(df.groupby('group')), arg1=a), arg2=b, arg3=c)  

---->   DataFrame.groupby

--------------------------------------
ID: 7480 --> 1
>>> (df.groupby('group')
...    .pipe(f)
...    .pipe(g, arg1=a)
...    .pipe(h, arg2=b, arg3=c))  

---->   DataFrame.groupby

--------------------------------------
ID: 7481 --> 1
>>> df = pd.DataFrame({'A': 'a b a b'.split(), 'B': [1, 2, 3, 4]})
>>> df
   A  B
0  a  1
1  b  2
2  a  3
3  b  4

---->   pandas.DataFrame

--------------------------------------
ID: 7482 --> 3
>>> df.groupby('A').pipe(lambda x: x.max() - x.min())
   B
A
a  2
b  2

---->   DataFrame.groupby; Series.max; Series.min

--------------------------------------
ID: 7483 --> 2
>>> df = pd.DataFrame({
...     'length': [1.5, 0.5, 1.2, 0.9, 3],
...     'width': [0.7, 0.2, 0.15, 0.2, 1.1]
...     }, index=['pig', 'rabbit', 'duck', 'chicken', 'horse'])
>>> hist = df.hist(bins=3)

---->   pandas.DataFrame; DataFrame.hist

--------------------------------------
ID: 7484 --> 2
>>> df = pd.DataFrame([['a', 1], ['a', 2], ['b', 1], ['b', 2]],
...                   columns=['A', 'B'])
>>> df.groupby('A').tail(1)
   A  B
1  a  2
3  b  2
>>> df.groupby('A').tail(-1)
   A  B
1  a  2
3  b  2

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 7485 --> 2
>>> df = pd.DataFrame({'A': [1, 1, 2, 1, 2],
...                    'B': [np.nan, 2, 3, 4, 5]}, columns=['A', 'B'])
>>> g = df.groupby('A')
>>> g.nth(0)
   A   B
0  1 NaN
2  2 3.0
>>> g.nth(1)
   A   B
1  1 2.0
4  2 5.0
>>> g.nth(-1)
   A   B
3  1 4.0
4  2 5.0
>>> g.nth([0, 1])
   A   B
0  1 NaN
1  1 2.0
2  2 3.0
4  2 5.0
>>> g.nth(slice(None, -1))
   A   B
0  1 NaN
1  1 2.0
2  2 3.0

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 7488 --> 2
>>> def histogram_intersection(a, b):
...     v = np.minimum(a, b).sum().round(decimals=1)
...     return v
>>> df = pd.DataFrame([(.2, .3), (.0, .6), (.6, .0), (.2, .1)],
...                   columns=['dogs', 'cats'])
>>> df.corr(method=histogram_intersection)
      dogs  cats
dogs   1.0   0.3
cats   0.3   1.0

---->   pandas.DataFrame; DataFrame.corr

--------------------------------------
ID: 7489 --> 2
>>> df = pd.DataFrame([(1, 1), (2, np.nan), (np.nan, 3), (4, 4)],
...                   columns=['dogs', 'cats'])
>>> df.corr(min_periods=3)
      dogs  cats
dogs   1.0   NaN
cats   NaN   1.0

---->   pandas.DataFrame; DataFrame.corr

--------------------------------------
ID: 7490 --> 1
>>> pd.Series([2, 1, 3, 3], name='A').unique()
array([2, 1, 3])

---->   pandas.Series

--------------------------------------
ID: 7491 --> 1
>>> pd.Series([pd.Timestamp('2016-01-01') for _ in range(3)]).unique()

['2016-01-01 00:00:00']
Length: 1, dtype: datetime64[ns]

---->   pandas.Series

--------------------------------------
ID: 7492 --> 1
>>> pd.Series([pd.Timestamp('2016-01-01', tz='US/Eastern')
...            for _ in range(3)]).unique()

['2016-01-01 00:00:00-05:00']
Length: 1, dtype: datetime64[ns, US/Eastern]

---->   pandas.Series

--------------------------------------
ID: 7493 --> 2
>>> pd.Series(pd.Categorical(list('baabc'))).unique()
['b', 'a', 'c']
Categories (3, object): ['a', 'b', 'c']
>>> pd.Series(pd.Categorical(list('baabc'), categories=list('abc'),
...                          ordered=True)).unique()
['b', 'a', 'c']
Categories (3, object): ['a' < 'b' < 'c']

---->   pandas.Series; pandas.Categorical

--------------------------------------
ID: 7494 --> 4
>>> ser = pd.Series(
...    [390.0, 350.0, 30.0, 20.0],
...    index=["Falcon", "Falcon", "Parrot", "Parrot"],
...    name="Max Speed")
>>> grouped = ser.groupby([1, 1, 2, 2])
>>> grouped.transform(lambda x: (x - x.mean()) / x.std())
    Falcon    0.707107
    Falcon   -0.707107
    Parrot    0.707107
    Parrot   -0.707107
    Name: Max Speed, dtype: float64

---->   pandas.Series; Series.groupby; Series.mean; Series.std

--------------------------------------
ID: 7495 --> 2
>>> grouped.transform(lambda x: x.max() - x.min())
Falcon    40.0
Falcon    40.0
Parrot    10.0
Parrot    10.0
Name: Max Speed, dtype: float64

---->   Series.max; Series.min

--------------------------------------
ID: 7497 --> 1
>>> grouped.transform(lambda x: x.astype(int).max())
Falcon    390
Falcon    390
Parrot     30
Parrot     30
Name: Max Speed, dtype: int64

---->   Series.astype

--------------------------------------
ID: 7498 --> 2
>>> df = pd.DataFrame([
...     ['a', 1], ['a', 2], ['a', 3],
...     ['b', 1], ['b', 3], ['b', 5]
... ], columns=['key', 'val'])
>>> df.groupby('key').quantile()
    val
key
a    2.0
b    3.0

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 7499 --> 1
>>> idx = pd.date_range('1/1/2000', periods=4, freq='T')
>>> df = pd.DataFrame(data=4 * [range(2)],
...                   index=idx,
...                   columns=['a', 'b'])
>>> df.iloc[2, 0] = 5
>>> df
                    a  b
2000-01-01 00:00:00  0  1
2000-01-01 00:01:00  0  1
2000-01-01 00:02:00  5  1
2000-01-01 00:03:00  0  1

---->   pandas.DataFrame

--------------------------------------
ID: 7500 --> 1
>>> df.groupby('a').resample('3T').sum()
                         a  b
a
0   2000-01-01 00:00:00  0  2
    2000-01-01 00:03:00  0  1
5   2000-01-01 00:00:00  5  1

---->   DataFrame.groupby

--------------------------------------
ID: 7501 --> 1
>>> df.groupby('a').resample('30S').sum()
                    a  b
a
0   2000-01-01 00:00:00  0  1
    2000-01-01 00:00:30  0  0
    2000-01-01 00:01:00  0  1
    2000-01-01 00:01:30  0  0
    2000-01-01 00:02:00  0  0
    2000-01-01 00:02:30  0  0
    2000-01-01 00:03:00  0  1
5   2000-01-01 00:02:00  5  1

---->   DataFrame.groupby

--------------------------------------
ID: 7502 --> 1
>>> df.groupby('a').resample('M').sum()
            a  b
a
0   2000-01-31  0  3
5   2000-01-31  5  1

---->   DataFrame.groupby

--------------------------------------
ID: 7503 --> 1
>>> df.groupby('a').resample('3T', closed='right').sum()
                         a  b
a
0   1999-12-31 23:57:00  0  1
    2000-01-01 00:00:00  0  2
5   2000-01-01 00:00:00  5  1

---->   DataFrame.groupby

--------------------------------------
ID: 7504 --> 1
>>> df.groupby('a').resample('3T', closed='right', label='right').sum()
                         a  b
a
0   2000-01-01 00:00:00  0  1
    2000-01-01 00:03:00  0  2
5   2000-01-01 00:03:00  5  1

---->   DataFrame.groupby

--------------------------------------
ID: 7505 --> 2
>>> df = pd.DataFrame([['a', 1], ['a', 2], ['b', 1], ['b', 2]],
...                   columns=['A', 'B'])
>>> df.groupby('A').tail(1)
   A  B
1  a  2
3  b  2
>>> df.groupby('A').tail(-1)
   A  B
1  a  2
3  b  2

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 7506 --> 1
>>> df = pd.DataFrame(
...     {
...         "A": [1, 1, 2, 2],
...         "B": [1, 2, 3, 4],
...         "C": [0.362838, 0.227877, 1.267767, -0.562860],
...     }
... )

---->   pandas.DataFrame

--------------------------------------
ID: 7507 --> 1
>>> df.groupby('A').agg('min')
   B         C
A
1  1  0.227877
2  3 -0.562860

---->   DataFrame.groupby

--------------------------------------
ID: 7508 --> 1
>>> df.groupby('A').agg(['min', 'max'])
    B             C
  min max       min       max
A
1   1   2  0.227877  0.362838
2   3   4 -0.562860  1.267767

---->   DataFrame.groupby

--------------------------------------
ID: 7509 --> 1
>>> df.groupby('A').B.agg(['min', 'max'])
   min  max
A
1    1    2
2    3    4

---->   DataFrame.groupby

--------------------------------------
ID: 7510 --> 1
>>> df.groupby('A').agg(lambda x: sum(x) + 2)
    B          C
A
1       5       2.590715
2       9       2.704907

---->   DataFrame.groupby

--------------------------------------
ID: 7511 --> 1
>>> df.groupby('A').agg({'B': ['min', 'max'], 'C': 'sum'})
    B             C
  min max       sum
A
1   1   2  0.590715
2   3   4  0.704907

---->   DataFrame.groupby

--------------------------------------
ID: 7512 --> 2
>>> df.groupby("A").agg(
...     b_min=pd.NamedAgg(column="B", aggfunc="min"),
...     c_sum=pd.NamedAgg(column="C", aggfunc="sum"))
   b_min     c_sum
A
1      1  0.590715
2      3  0.704907

---->   DataFrame.groupby; pandas.NamedAgg

--------------------------------------
ID: 7513 --> 2
>>> df.groupby("A")[["B"]].agg(lambda x: x.astype(float).min())
      B
A
1   1.0
2   3.0

---->   DataFrame.groupby; Series.astype

--------------------------------------
ID: 7514 --> 1
>>> df = pd.DataFrame({'A': [1, 1, 2, 2],
...                    'B': [1, 2, 3, 4],
...                    'C': [0.362, 0.227, 1.267, -0.562]})
>>> df
      A  B      C
0     1  1  0.362
1     1  2  0.227
2     2  3  1.267
3     2  4 -0.562

---->   pandas.DataFrame

--------------------------------------
ID: 7515 --> 1
>>> df.groupby('A').rolling(2).sum()
    B      C
A
1 0  NaN    NaN
  1  3.0  0.589
2 2  NaN    NaN
  3  7.0  0.705

---->   DataFrame.groupby

--------------------------------------
ID: 7516 --> 1
>>> df.groupby('A').rolling(2, min_periods=1).sum()
    B      C
A
1 0  1.0  0.362
  1  3.0  0.589
2 2  3.0  1.267
  3  7.0  0.705

---->   DataFrame.groupby

--------------------------------------
ID: 7517 --> 1
>>> df.groupby('A').rolling(2, on='B').sum()
    B      C
A
1 0  1    NaN
  1  2  0.589
2 2  3    NaN
  3  4  0.705

---->   DataFrame.groupby

--------------------------------------
ID: 7518 --> 1
>>> s = pd.Series(data=[1, None, 4, 3, 4],
...               index=['A', 'B', 'C', 'D', 'E'])
>>> s
A    1.0
B    NaN
C    4.0
D    3.0
E    4.0
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 7519 --> 1
>>> s.idxmax()
'C'

---->   Series.idxmax

--------------------------------------
ID: 7520 --> 1
>>> s.idxmax(skipna=False)
nan

---->   Series.idxmax

--------------------------------------
ID: 7521 --> 3
>>> arrays = [['falcon', 'parrot', 'cockatoo', 'kiwi',
...            'lion', 'monkey', 'rabbit'],
...           ['bird', 'bird', 'bird', 'bird',
...            'mammal', 'mammal', 'mammal']]
>>> index = pd.MultiIndex.from_arrays(arrays, names=('name', 'class'))
>>> df = pd.DataFrame({'max_speed': [389.0, 24.0, 70.0, np.nan,
...                                  80.5, 21.5, 15.0]},
...                   index=index)
>>> df
                max_speed
name     class
falcon   bird        389.0
parrot   bird         24.0
cockatoo bird         70.0
kiwi     bird          NaN
lion     mammal       80.5
monkey   mammal       21.5
rabbit   mammal       15.0
>>> gb = df.groupby(["class"])
>>> gb.skew()
        max_speed
class
bird     1.628296
mammal   1.669046
>>> gb.skew(skipna=False)
        max_speed
class
bird          NaN
mammal   1.669046

---->   pandas.MultiIndex; pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 7522 --> 2
>>> df = pd.DataFrame(
...     {
...         "group": ["a", "a", "a", "a", "a", "b", "b", "b", "b", "b"],
...         "value": [2, 4, 2, 3, 5, 1, 2, 4, 1, 5],
...     }
... )
>>> df
  group  value
0     a      2
1     a      4
2     a      2
3     a      3
4     a      5
5     b      1
6     b      2
7     b      4
8     b      1
9     b      5
>>> for method in ['average', 'min', 'max', 'dense', 'first']:
...     df[f'{method}_rank'] = df.groupby('group')['value'].rank(method)
>>> df
  group  value  average_rank  min_rank  max_rank  dense_rank  first_rank
0     a      2           1.5       1.0       2.0         1.0         1.0
1     a      4           4.0       4.0       4.0         3.0         4.0
2     a      2           1.5       1.0       2.0         1.0         2.0
3     a      3           3.0       3.0       3.0         2.0         3.0
4     a      5           5.0       5.0       5.0         4.0         5.0
5     b      1           1.5       1.0       2.0         1.0         1.0
6     b      2           3.0       3.0       3.0         2.0         3.0
7     b      4           4.0       4.0       4.0         3.0         4.0
8     b      1           1.5       1.0       2.0         1.0         2.0
9     b      5           5.0       5.0       5.0         4.0         5.0

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 7523 --> 2
>>> df = pd.DataFrame([
...     ['a', 1], ['a', 2], ['a', 3],
...     ['b', 1], ['b', 3], ['b', 5]
... ], columns=['key', 'val'])
>>> df.groupby('key').quantile()
    val
key
a    2.0
b    3.0

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 7524 --> 1
self.apply(lambda x: pd.Series(np.arange(len(x)), x.index))

---->   pandas.Series

--------------------------------------
ID: 7525 --> 2
>>> df = pd.DataFrame([['a'], ['a'], ['a'], ['b'], ['b'], ['a']],
...                   columns=['A'])
>>> df
   A
0  a
1  a
2  a
3  b
4  b
5  a
>>> df.groupby('A').cumcount()
0    0
1    1
2    2
3    0
4    1
5    3
dtype: int64
>>> df.groupby('A').cumcount(ascending=False)
0    3
1    2
2    1
3    1
4    0
5    0
dtype: int64

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 7526 --> 2
>>> df = pd.DataFrame([[1, 2], [1, 4], [5, 6]],
...                   columns=['A', 'B'])
>>> df.groupby('A').head(1)
   A  B
0  1  2
2  5  6
>>> df.groupby('A').head(-1)
   A  B
0  1  2

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 7527 --> 1
>>> df = pd.DataFrame(
...     {"a": ["red"] * 2 + ["blue"] * 2 + ["black"] * 2, "b": range(6)}
... )
>>> df
       a  b
0    red  0
1    red  1
2   blue  2
3   blue  3
4  black  4
5  black  5

---->   pandas.DataFrame

--------------------------------------
ID: 7528 --> 1
>>> df.groupby("a").sample(n=1, random_state=1)
       a  b
4  black  4
2   blue  2
1    red  1

---->   DataFrame.groupby

--------------------------------------
ID: 7529 --> 1
>>> df.groupby("a")["b"].sample(frac=0.5, random_state=2)
5    5
2    2
0    0
Name: b, dtype: int64

---->   DataFrame.groupby

--------------------------------------
ID: 7530 --> 1
>>> df.groupby("a").sample(
...     n=1,
...     weights=[1, 1, 1, 0, 0, 1],
...     random_state=1,
... )
       a  b
5  black  5
2   blue  2
0    red  0

---->   DataFrame.groupby

--------------------------------------
ID: 7531 --> 2
>>> df = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar',
...                           'foo', 'bar'],
...                    'B' : [1, 2, 3, 4, 5, 6],
...                    'C' : [2.0, 5., 8., 1., 2., 9.]})
>>> grouped = df.groupby('A')
>>> grouped.filter(lambda x: x['B'].mean() > 3.)
     A  B    C
1  bar  2  5.0
3  bar  4  1.0
5  bar  6  9.0

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 7532 --> 2
>>> df = pd.DataFrame([(1, 2), (0, 3), (2, 0), (1, 1)],
...                   columns=['dogs', 'cats'])
>>> df.cov()
          dogs      cats
dogs  0.666667 -1.000000
cats -1.000000  1.666667

---->   pandas.DataFrame; DataFrame.cov

--------------------------------------
ID: 7533 --> 2
>>> np.random.seed(42)
>>> df = pd.DataFrame(np.random.randn(1000, 5),
...                   columns=['a', 'b', 'c', 'd', 'e'])
>>> df.cov()
          a         b         c         d         e
a  0.998438 -0.020161  0.059277 -0.008943  0.014144
b -0.020161  1.059352 -0.008543 -0.024738  0.009826
c  0.059277 -0.008543  1.010670 -0.001486 -0.000271
d -0.008943 -0.024738 -0.001486  0.921297 -0.013692
e  0.014144  0.009826 -0.000271 -0.013692  0.977795

---->   pandas.DataFrame; DataFrame.cov

--------------------------------------
ID: 7534 --> 2
>>> np.random.seed(42)
>>> df = pd.DataFrame(np.random.randn(20, 3),
...                   columns=['a', 'b', 'c'])
>>> df.loc[df.index[:5], 'a'] = np.nan
>>> df.loc[df.index[5:10], 'b'] = np.nan
>>> df.cov(min_periods=12)
          a         b         c
a  0.316741       NaN -0.150812
b       NaN  1.248003  0.191417
c -0.150812  0.191417  0.895202

---->   pandas.DataFrame; DataFrame.cov

--------------------------------------
ID: 7535 --> 3
>>> df = pd.DataFrame(dict(A=[1, 1, 3], B=[None, 5, 6], C=[1, 2, 3],
...                        D=['3/11/2000', '3/12/2000', '3/13/2000']))
>>> df['D'] = pd.to_datetime(df['D'])
>>> df.groupby("A").first()
     B  C          D
A
1  5.0  1 2000-03-11
3  6.0  3 2000-03-13
>>> df.groupby("A").first(min_count=2)
    B    C          D
A
1 NaN  1.0 2000-03-11
3 NaN  NaN        NaT
>>> df.groupby("A").first(numeric_only=True)
     B  C
A
1  5.0  1
3  6.0  3

---->   pandas.DataFrame; pandas.to_datetime; DataFrame.groupby

--------------------------------------
ID: 7536 --> 1
>>> s = pd.Series(data=[1, None, 4, 1],
...               index=['A', 'B', 'C', 'D'])
>>> s
A    1.0
B    NaN
C    4.0
D    1.0
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 7537 --> 1
>>> s.idxmin()
'A'

---->   Series.idxmin

--------------------------------------
ID: 7538 --> 1
>>> s.idxmin(skipna=False)
nan

---->   Series.idxmin

--------------------------------------
ID: 7539 --> 1
>>> df = pd.DataFrame(
...     {
...         "A": [1, 1, 2, 2],
...         "B": [1, 2, 3, 4],
...         "C": [0.362838, 0.227877, 1.267767, -0.562860],
...     }
... )

---->   pandas.DataFrame

--------------------------------------
ID: 7540 --> 1
>>> df.groupby('A').agg('min')
   B         C
A
1  1  0.227877
2  3 -0.562860

---->   DataFrame.groupby

--------------------------------------
ID: 7541 --> 1
>>> df.groupby('A').agg(['min', 'max'])
    B             C
  min max       min       max
A
1   1   2  0.227877  0.362838
2   3   4 -0.562860  1.267767

---->   DataFrame.groupby

--------------------------------------
ID: 7542 --> 1
>>> df.groupby('A').B.agg(['min', 'max'])
   min  max
A
1    1    2
2    3    4

---->   DataFrame.groupby

--------------------------------------
ID: 7543 --> 1
>>> df.groupby('A').agg(lambda x: sum(x) + 2)
    B          C
A
1       5       2.590715
2       9       2.704907

---->   DataFrame.groupby

--------------------------------------
ID: 7544 --> 1
>>> df.groupby('A').agg({'B': ['min', 'max'], 'C': 'sum'})
    B             C
  min max       sum
A
1   1   2  0.590715
2   3   4  0.704907

---->   DataFrame.groupby

--------------------------------------
ID: 7545 --> 2
>>> df.groupby("A").agg(
...     b_min=pd.NamedAgg(column="B", aggfunc="min"),
...     c_sum=pd.NamedAgg(column="C", aggfunc="sum"))
   b_min     c_sum
A
1      1  0.590715
2      3  0.704907

---->   DataFrame.groupby; pandas.NamedAgg

--------------------------------------
ID: 7546 --> 2
>>> df.groupby("A")[["B"]].agg(lambda x: x.astype(float).min())
      B
A
1   1.0
2   3.0

---->   DataFrame.groupby; Series.astype

--------------------------------------
ID: 7547 --> 2
>>> df = pd.DataFrame({"color": ["red", None, "red", "blue", "blue", "red"]})
>>> df
   color
0    red
1   None
2    red
3   blue
4   blue
5    red
>>> df.groupby("color").ngroup()
0    1.0
1    NaN
2    1.0
3    0.0
4    0.0
5    1.0
dtype: float64
>>> df.groupby("color", dropna=False).ngroup()
0    1
1    2
2    1
3    0
4    0
5    1
dtype: int64
>>> df.groupby("color", dropna=False).ngroup(ascending=False)
0    1
1    0
2    1
3    2
4    2
5    1
dtype: int64

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 7548 --> 2
>>> df = pd.DataFrame({"color": ["red", None, "red", "blue", "blue", "red"]})
>>> df
   color
0    red
1   None
2    red
3   blue
4   blue
5    red
>>> df.groupby("color").ngroup()
0    1.0
1    NaN
2    1.0
3    0.0
4    0.0
5    1.0
dtype: float64
>>> df.groupby("color", dropna=False).ngroup()
0    1
1    2
2    1
3    0
4    0
5    1
dtype: int64
>>> df.groupby("color", dropna=False).ngroup(ascending=False)
0    1
1    0
2    1
3    2
4    2
5    1
dtype: int64

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 7549 --> 2
>>> s = pd.Series([1, 2, 3])
>>> s.describe()
count    3.0
mean     2.0
std      1.0
min      1.0
25%      1.5
50%      2.0
75%      2.5
max      3.0
dtype: float64

---->   pandas.Series; Series.describe

--------------------------------------
ID: 7550 --> 2
>>> s = pd.Series(['a', 'a', 'b', 'c'])
>>> s.describe()
count     4
unique    3
top       a
freq      2
dtype: object

---->   pandas.Series; Series.describe

--------------------------------------
ID: 7551 --> 2
>>> s = pd.Series([
...     np.datetime64("2000-01-01"),
...     np.datetime64("2010-01-01"),
...     np.datetime64("2010-01-01")
... ])
>>> s.describe()
count                      3
mean     2006-09-01 08:00:00
min      2000-01-01 00:00:00
25%      2004-12-31 12:00:00
50%      2010-01-01 00:00:00
75%      2010-01-01 00:00:00
max      2010-01-01 00:00:00
dtype: object

---->   pandas.Series; Series.describe

--------------------------------------
ID: 7552 --> 3
>>> df = pd.DataFrame({'categorical': pd.Categorical(['d','e','f']),
...                    'numeric': [1, 2, 3],
...                    'object': ['a', 'b', 'c']
...                   })
>>> df.describe()
       numeric
count      3.0
mean       2.0
std        1.0
min        1.0
25%        1.5
50%        2.0
75%        2.5
max        3.0

---->   pandas.DataFrame; pandas.Categorical; DataFrame.describe

--------------------------------------
ID: 7553 --> 1
>>> df.describe(include='all')  
       categorical  numeric object
count            3      3.0      3
unique           3      NaN      3
top              f      NaN      a
freq             1      NaN      1
mean           NaN      2.0    NaN
std            NaN      1.0    NaN
min            NaN      1.0    NaN
25%            NaN      1.5    NaN
50%            NaN      2.0    NaN
75%            NaN      2.5    NaN
max            NaN      3.0    NaN

---->   DataFrame.describe

--------------------------------------
ID: 7555 --> 1
>>> df.describe(include=[np.number])
       numeric
count      3.0
mean       2.0
std        1.0
min        1.0
25%        1.5
50%        2.0
75%        2.5
max        3.0

---->   DataFrame.describe

--------------------------------------
ID: 7556 --> 1
>>> df.describe(include=[object])  
       object
count       3
unique      3
top         a
freq        1

---->   DataFrame.describe

--------------------------------------
ID: 7557 --> 1
>>> df.describe(include=['category'])
       categorical
count            3
unique           3
top              d
freq             1

---->   DataFrame.describe

--------------------------------------
ID: 7558 --> 1
>>> df.describe(exclude=[np.number])  
       categorical object
count            3      3
unique           3      3
top              f      a
freq             1      1

---->   DataFrame.describe

--------------------------------------
ID: 7559 --> 1
>>> df.describe(exclude=[object])  
       categorical  numeric
count            3      3.0
unique           3      NaN
top              f      NaN
freq             1      NaN
mean           NaN      2.0
std            NaN      1.0
min            NaN      1.0
25%            NaN      1.5
50%            NaN      2.0
75%            NaN      2.5
max            NaN      3.0

---->   DataFrame.describe

--------------------------------------
ID: 7560 --> 2
>>> df = pd.DataFrame([[1, 2], [1, 4], [5, 6]],
...                   columns=['A', 'B'])
>>> df.groupby('A').head(1)
   A  B
0  1  2
2  5  6
>>> df.groupby('A').head(-1)
   A  B
0  1  2

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 7561 --> 1
>>> h(g(f(df.groupby('group')), arg1=a), arg2=b, arg3=c)  

---->   DataFrame.groupby

--------------------------------------
ID: 7562 --> 1
>>> (df.groupby('group')
...    .pipe(f)
...    .pipe(g, arg1=a)
...    .pipe(h, arg2=b, arg3=c))  

---->   DataFrame.groupby

--------------------------------------
ID: 7563 --> 1
>>> df = pd.DataFrame({'A': 'a b a b'.split(), 'B': [1, 2, 3, 4]})
>>> df
   A  B
0  a  1
1  b  2
2  a  3
3  b  4

---->   pandas.DataFrame

--------------------------------------
ID: 7564 --> 3
>>> df.groupby('A').pipe(lambda x: x.max() - x.min())
   B
A
a  2
b  2

---->   DataFrame.groupby; Series.max; Series.min

--------------------------------------
ID: 7565 --> 2
>>> df = pd.DataFrame([('falcon', 'bird', 389.0),
...                    ('parrot', 'bird', 24.0),
...                    ('lion', 'mammal', 80.5),
...                    ('monkey', 'mammal', np.nan),
...                    ('rabbit', 'mammal', 15.0)],
...                   columns=['name', 'class', 'max_speed'],
...                   index=[4, 3, 2, 1, 0])
>>> df
     name   class  max_speed
4  falcon    bird      389.0
3  parrot    bird       24.0
2    lion  mammal       80.5
1  monkey  mammal        NaN
0  rabbit  mammal       15.0
>>> gb = df.groupby([1, 1, 2, 2, 2])

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 7569 --> 1
>>> s = pd.Series([1, 2, 3, 4])

---->   pandas.Series

--------------------------------------
ID: 7570 --> 1
>>> s.groupby([1, 1, 2, 2]).min()
1    1
2    3
dtype: int64

---->   Series.groupby

--------------------------------------
ID: 7571 --> 1
>>> s.groupby([1, 1, 2, 2]).agg('min')
1    1
2    3
dtype: int64

---->   Series.groupby

--------------------------------------
ID: 7572 --> 1
>>> s.groupby([1, 1, 2, 2]).agg(['min', 'max'])
   min  max
1    1    2
2    3    4

---->   Series.groupby

--------------------------------------
ID: 7573 --> 1
>>> s.groupby([1, 1, 2, 2]).agg(
...     minimum='min',
...     maximum='max',
... )
   minimum  maximum
1        1        2
2        3        4

---->   Series.groupby

--------------------------------------
ID: 7574 --> 2
>>> s.groupby([1, 1, 2, 2]).agg(lambda x: x.astype(float).min())
1    1.0
2    3.0
dtype: float64

---->   Series.groupby; Series.astype

--------------------------------------
ID: 7575 --> 1
>>> df = pd.DataFrame({'consumption': [10.51, 103.11, 55.48],
...                    'co2_emissions': [37.2, 19.66, 1712]},
...                    index=['Pork', 'Wheat Products', 'Beef'])

---->   pandas.DataFrame

--------------------------------------
ID: 7576 --> 1
>>> df.idxmax()
consumption     Wheat Products
co2_emissions             Beef
dtype: object

---->   DataFrame.idxmax

--------------------------------------
ID: 7577 --> 1
>>> df.idxmax(axis="columns")
Pork              co2_emissions
Wheat Products     consumption
Beef              co2_emissions
dtype: object

---->   DataFrame.idxmax

--------------------------------------
ID: 7578 --> 2
>>> df = pd.DataFrame(dict(A=[1, 1, 3], B=[5, None, 6], C=[1, 2, 3]))
>>> df.groupby("A").last()
     B  C
A
1  5.0  2
3  6.0  3

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 7579 --> 1
>>> df = pd.DataFrame(
...     {
...         "key": [0, 0, 1, 1, 1],
...         "A": [np.nan, 2, np.nan, 3, np.nan],
...         "B": [2, 3, np.nan, np.nan, np.nan],
...         "C": [np.nan, np.nan, 2, np.nan, np.nan],
...     }
... )
>>> df
   key    A    B   C
0    0  NaN  2.0 NaN
1    0  2.0  3.0 NaN
2    1  NaN  NaN 2.0
3    1  3.0  NaN NaN
4    1  NaN  NaN NaN

---->   pandas.DataFrame

--------------------------------------
ID: 7580 --> 1
>>> df.groupby("key").fillna(method="ffill")
     A    B   C
0  NaN  2.0 NaN
1  2.0  3.0 NaN
2  NaN  NaN 2.0
3  3.0  NaN 2.0
4  3.0  NaN 2.0

---->   DataFrame.groupby

--------------------------------------
ID: 7581 --> 1
>>> df.groupby("key").fillna(method="bfill")
     A    B   C
0  2.0  2.0 NaN
1  2.0  3.0 NaN
2  3.0  NaN 2.0
3  3.0  NaN NaN
4  NaN  NaN NaN

---->   DataFrame.groupby

--------------------------------------
ID: 7582 --> 1
>>> df.groupby([0, 0, 1, 1], axis=1).fillna(method="ffill")
   key    A    B    C
0  0.0  0.0  2.0  2.0
1  0.0  2.0  3.0  3.0
2  1.0  1.0  NaN  2.0
3  1.0  3.0  NaN  NaN
4  1.0  1.0  NaN  NaN

---->   DataFrame.groupby

--------------------------------------
ID: 7583 --> 1
>>> df.groupby([0, 0, 1, 1], axis=1).fillna(method="bfill")
   key    A    B    C
0  0.0  NaN  2.0  NaN
1  0.0  2.0  3.0  NaN
2  1.0  NaN  2.0  2.0
3  1.0  3.0  NaN  NaN
4  1.0  NaN  NaN  NaN

---->   DataFrame.groupby

--------------------------------------
ID: 7584 --> 1
>>> df.groupby("key").fillna(method="ffill", limit=1)
     A    B    C
0  NaN  2.0  NaN
1  2.0  3.0  NaN
2  NaN  NaN  2.0
3  3.0  NaN  2.0
4  3.0  NaN  NaN

---->   DataFrame.groupby

--------------------------------------
ID: 7585 --> 3
>>> df = pd.DataFrame({"key": [1, 1, 2], "a": [-1, 0, 1], 1: [10, 11, 12]})
>>> agg_a = pd.NamedAgg(column="a", aggfunc="min")
>>> agg_1 = pd.NamedAgg(column=1, aggfunc=np.mean)
>>> df.groupby("key").agg(result_a=agg_a, result_1=agg_1)
     result_a  result_1
key
1          -1      10.5
2           1      12.0

---->   pandas.DataFrame; pandas.NamedAgg; DataFrame.groupby

--------------------------------------
ID: 7586 --> 1
>>> df = pd.DataFrame({'A': [1, 1, 2, 1, 2],
...                    'B': [np.nan, 2, 3, 4, 5],
...                    'C': [1, 2, 1, 1, 2]}, columns=['A', 'B', 'C'])

---->   pandas.DataFrame

--------------------------------------
ID: 7587 --> 1
>>> df.groupby('A').mean()
     B         C
A
1  3.0  1.333333
2  4.0  1.500000

---->   DataFrame.groupby

--------------------------------------
ID: 7588 --> 1
>>> df.groupby(['A', 'B']).mean()
         C
A B
1 2.0  2.0
  4.0  1.0
2 3.0  1.0
  5.0  2.0

---->   DataFrame.groupby

--------------------------------------
ID: 7589 --> 1
>>> df.groupby('A')['B'].mean()
A
1    3.0
2    4.0
Name: B, dtype: float64

---->   DataFrame.groupby

--------------------------------------
ID: 7590 --> 1
>>> df = pd.DataFrame({'A': [1, 1, 2, 2],
...                    'B': [1, 2, 3, 4],
...                    'C': [0.362, 0.227, 1.267, -0.562]})
>>> df
      A  B      C
0     1  1  0.362
1     1  2  0.227
2     2  3  1.267
3     2  4 -0.562

---->   pandas.DataFrame

--------------------------------------
ID: 7591 --> 1
>>> df.groupby('A').rolling(2).sum()
    B      C
A
1 0  NaN    NaN
  1  3.0  0.589
2 2  NaN    NaN
  3  7.0  0.705

---->   DataFrame.groupby

--------------------------------------
ID: 7592 --> 1
>>> df.groupby('A').rolling(2, min_periods=1).sum()
    B      C
A
1 0  1.0  0.362
  1  3.0  0.589
2 2  3.0  1.267
  3  7.0  0.705

---->   DataFrame.groupby

--------------------------------------
ID: 7593 --> 1
>>> df.groupby('A').rolling(2, on='B').sum()
    B      C
A
1 0  1    NaN
  1  2  0.589
2 2  3    NaN
  3  4  0.705

---->   DataFrame.groupby

--------------------------------------
ID: 7594 --> 4
>>> df = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar',
...                           'foo', 'bar'],
...                    'B' : ['one', 'one', 'two', 'three',
...                           'two', 'two'],
...                    'C' : [1, 5, 5, 2, 5, 5],
...                    'D' : [2.0, 5., 8., 1., 2., 9.]})
>>> grouped = df.groupby('A')[['C', 'D']]
>>> grouped.transform(lambda x: (x - x.mean()) / x.std())
        C         D
0 -1.154701 -0.577350
1  0.577350  0.000000
2  0.577350  1.154701
3 -1.154701 -1.000000
4  0.577350 -0.577350
5  0.577350  1.000000

---->   pandas.DataFrame; DataFrame.groupby; Series.mean; Series.std

--------------------------------------
ID: 7595 --> 2
>>> grouped.transform(lambda x: x.max() - x.min())
    C    D
0  4.0  6.0
1  3.0  8.0
2  4.0  6.0
3  3.0  8.0
4  4.0  6.0
5  3.0  8.0

---->   Series.max; Series.min

--------------------------------------
ID: 7597 --> 1
>>> grouped.transform(lambda x: x.astype(int).max())
C  D
0  5  8
1  5  9
2  5  8
3  5  9
4  5  8
5  5  9

---->   Series.astype

--------------------------------------
ID: 7598 --> 2
>>> n = 10000
>>> df = pd.DataFrame({'x': np.random.randn(n),
...                    'y': np.random.randn(n)})
>>> ax = df.plot.hexbin(x='x', y='y', gridsize=20)

---->   pandas.DataFrame; DataFrame.plot

--------------------------------------
ID: 7599 --> 2
>>> n = 500
>>> df = pd.DataFrame({
...     'coord_x': np.random.uniform(-3, 3, size=n),
...     'coord_y': np.random.uniform(30, 50, size=n),
...     'observations': np.random.randint(1,5, size=n)
...     })
>>> ax = df.plot.hexbin(x='coord_x',
...                     y='coord_y',
...                     C='observations',
...                     reduce_C_function=np.sum,
...                     gridsize=10,
...                     cmap="viridis")

---->   pandas.DataFrame; DataFrame.plot

--------------------------------------
ID: 7600 --> 1
>>> df = pd.DataFrame([1, 2, 3, 4, 5], index=[100, 29, 234, 1, 150],
...                   columns=['A'])
>>> df.sort_index()
     A
1    4
29   2
100  1
150  5
234  3

---->   pandas.DataFrame

--------------------------------------
ID: 7602 --> 1
>>> df = pd.DataFrame({"a": [1, 2, 3, 4]}, index=['A', 'b', 'C', 'd'])
>>> df.sort_index(key=lambda x: x.str.lower())
   a
A  1
b  2
C  3
d  4

---->   pandas.DataFrame

--------------------------------------
ID: 7603 --> 1
>>> df = pd.DataFrame([[0, 2, 3], [0, 4, 1], [10, 20, 30]],
...                   columns=['A', 'B', 'C'])
>>> df
    A   B   C
0   0   2   3
1   0   4   1
2  10  20  30

---->   pandas.DataFrame

--------------------------------------
ID: 7604 --> 2
>>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})
>>> df
   col1  col2
0     1     3
1     2     4
>>> df.insert(1, "newcol", [99, 99])
>>> df
   col1  newcol  col2
0     1      99     3
1     2      99     4
>>> df.insert(0, "col1", [100, 100], allow_duplicates=True)
>>> df
   col1  col1  newcol  col2
0   100     1      99     3
1   100     2      99     4

---->   pandas.DataFrame; DataFrame.insert

--------------------------------------
ID: 7605 --> 2
>>> df.insert(0, "col0", pd.Series([5, 6], index=[1, 2]))
>>> df
   col0  col1  col1  newcol  col2
0   NaN   100     1      99     3
1   5.0   100     2      99     4

---->   DataFrame.insert; pandas.Series

--------------------------------------
ID: 7606 --> 1
>>> index = ['Firefox', 'Chrome', 'Safari', 'IE10', 'Konqueror']
>>> df = pd.DataFrame({'http_status': [200, 200, 404, 404, 301],
...                   'response_time': [0.04, 0.02, 0.07, 0.08, 1.0]},
...                   index=index)
>>> df
           http_status  response_time
Firefox            200           0.04
Chrome             200           0.02
Safari             404           0.07
IE10               404           0.08
Konqueror          301           1.00

---->   pandas.DataFrame

--------------------------------------
ID: 7612 --> 1
>>> date_index = pd.date_range('1/1/2010', periods=6, freq='D')
>>> df2 = pd.DataFrame({"prices": [100, 101, np.nan, 100, 89, 88]},
...                    index=date_index)
>>> df2
            prices
2010-01-01   100.0
2010-01-02   101.0
2010-01-03     NaN
2010-01-04   100.0
2010-01-05    89.0
2010-01-06    88.0

---->   pandas.DataFrame

--------------------------------------
ID: 7615 --> 1
>>> df = pd.DataFrame({'cost': [250, 150, 100],
...                    'revenue': [100, 250, 300]},
...                   index=['A', 'B', 'C'])
>>> df
   cost  revenue
A   250      100
B   150      250
C   100      300

---->   pandas.DataFrame

--------------------------------------
ID: 7616 --> 1
>>> df.eq(100)
    cost  revenue
A  False     True
B  False    False
C   True    False

---->   DataFrame.eq

--------------------------------------
ID: 7617 --> 1
>>> df != pd.Series([100, 250], index=["cost", "revenue"])
    cost  revenue
A   True     True
B   True    False
C  False     True

---->   pandas.Series

--------------------------------------
ID: 7618 --> 2
>>> df.ne(pd.Series([100, 300], index=["A", "D"]), axis='index')
   cost  revenue
A  True    False
B  True     True
C  True     True
D  True     True

---->   DataFrame.ne; pandas.Series

--------------------------------------
ID: 7619 --> 1
>>> df.eq([250, 250, 100], axis='index')
    cost  revenue
A   True    False
B  False     True
C   True    False

---->   DataFrame.eq

--------------------------------------
ID: 7620 --> 1
>>> other = pd.DataFrame({'revenue': [300, 250, 100, 150]},
...                      index=['A', 'B', 'C', 'D'])
>>> other
   revenue
A      300
B      250
C      100
D      150

---->   pandas.DataFrame

--------------------------------------
ID: 7621 --> 1
>>> df.gt(other)
    cost  revenue
A  False    False
B  False    False
C  False     True
D  False    False

---->   DataFrame.gt

--------------------------------------
ID: 7622 --> 1
>>> df_multindex = pd.DataFrame({'cost': [250, 150, 100, 150, 300, 220],
...                              'revenue': [100, 250, 300, 200, 175, 225]},
...                             index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'],
...                                    ['A', 'B', 'C', 'A', 'B', 'C']])
>>> df_multindex
      cost  revenue
Q1 A   250      100
   B   150      250
   C   100      300
Q2 A   150      200
   B   300      175
   C   220      225

---->   pandas.DataFrame

--------------------------------------
ID: 7623 --> 1
>>> df.le(df_multindex, level=1)
       cost  revenue
Q1 A   True     True
   B   True     True
   C   True     True
Q2 A  False     True
   B   True    False
   C   True    False

---->   DataFrame.le

--------------------------------------
ID: 7624 --> 1
>>> df = pd.DataFrame({'angles': [0, 3, 4],
...                    'degrees': [360, 180, 360]},
...                   index=['circle', 'triangle', 'rectangle'])
>>> df
           angles  degrees
circle          0      360
triangle        3      180
rectangle       4      360

---->   pandas.DataFrame

--------------------------------------
ID: 7625 --> 1
>>> df.add(1)
           angles  degrees
circle          1      361
triangle        4      181
rectangle       5      361

---->   DataFrame.add

--------------------------------------
ID: 7626 --> 1
>>> df.div(10)
           angles  degrees
circle        0.0     36.0
triangle      0.3     18.0
rectangle     0.4     36.0

---->   DataFrame.div

--------------------------------------
ID: 7627 --> 1
>>> df.rdiv(10)
             angles   degrees
circle          inf  0.027778
triangle   3.333333  0.055556
rectangle  2.500000  0.027778

---->   DataFrame.rdiv

--------------------------------------
ID: 7628 --> 1
>>> df.sub([1, 2], axis='columns')
           angles  degrees
circle         -1      358
triangle        2      178
rectangle       3      358

---->   DataFrame.sub

--------------------------------------
ID: 7629 --> 2
>>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),
...        axis='index')
           angles  degrees
circle         -1      359
triangle        2      179
rectangle       3      359

---->   DataFrame.sub; pandas.Series

--------------------------------------
ID: 7630 --> 1
>>> df.mul({'angles': 0, 'degrees': 2})
            angles  degrees
circle           0      720
triangle         0      360
rectangle        0      720

---->   DataFrame.mul

--------------------------------------
ID: 7631 --> 1
>>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')
            angles  degrees
circle           0        0
triangle         6      360
rectangle       12     1080

---->   DataFrame.mul

--------------------------------------
ID: 7632 --> 1
>>> other = pd.DataFrame({'angles': [0, 3, 4]},
...                      index=['circle', 'triangle', 'rectangle'])
>>> other
           angles
circle          0
triangle        3
rectangle       4

---->   pandas.DataFrame

--------------------------------------
ID: 7633 --> 1
>>> df.mul(other, fill_value=0)
           angles  degrees
circle          0      0.0
triangle        9      0.0
rectangle      16      0.0

---->   DataFrame.mul

--------------------------------------
ID: 7634 --> 1
>>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],
...                              'degrees': [360, 180, 360, 360, 540, 720]},
...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],
...                                    ['circle', 'triangle', 'rectangle',
...                                     'square', 'pentagon', 'hexagon']])
>>> df_multindex
             angles  degrees
A circle          0      360
  triangle        3      180
  rectangle       4      360
B square          4      360
  pentagon        5      540
  hexagon         6      720

---->   pandas.DataFrame

--------------------------------------
ID: 7635 --> 1
>>> df.div(df_multindex, level=1, fill_value=0)
             angles  degrees
A circle        NaN      1.0
  triangle      1.0      1.0
  rectangle     1.0      1.0
B square        0.0      0.0
  pentagon      0.0      0.0
  hexagon       0.0      0.0

---->   DataFrame.div

--------------------------------------
ID: 7636 --> 1
>>> df = pd.DataFrame({"A": [1, 2]})
>>> df.flags.allows_duplicate_labels
True
>>> df2 = df.set_flags(allows_duplicate_labels=False)
>>> df2.flags.allows_duplicate_labels
False

---->   pandas.DataFrame

--------------------------------------
ID: 7637 --> 2
>>> df = pd.DataFrame({'A': [1, 2], 'B': [0.5, 0.75]},
...                   index=['a', 'b'])
>>> df
   A     B
a  1  0.50
b  2  0.75
>>> df.to_records()
rec.array([('a', 1, 0.5 ), ('b', 2, 0.75)],
          dtype=[('index', 'O'), ('A', '

---->   pandas.DataFrame; DataFrame.to_records

--------------------------------------
ID: 7638 --> 1
>>> df.index = df.index.rename("I")
>>> df.to_records()
rec.array([('a', 1, 0.5 ), ('b', 2, 0.75)],
          dtype=[('I', 'O'), ('A', '

---->   DataFrame.to_records

--------------------------------------
ID: 7639 --> 1
>>> df.to_records(index=False)
rec.array([(1, 0.5 ), (2, 0.75)],
          dtype=[('A', '

---->   DataFrame.to_records

--------------------------------------
ID: 7640 --> 1
>>> df.to_records(column_dtypes={"A": "int32"})
rec.array([('a', 1, 0.5 ), ('b', 2, 0.75)],
          dtype=[('I', 'O'), ('A', '

---->   DataFrame.to_records

--------------------------------------
ID: 7641 --> 1
>>> df.to_records(index_dtypes=")
rec.array([(b'a', 1, 0.5 ), (b'b', 2, 0.75)],
          dtype=[('I', 'S2'), ('A', '

---->   DataFrame.to_records

--------------------------------------
ID: 7642 --> 1
>>> index_dtypes = f"{df.index.str.len().max()}"
>>> df.to_records(index_dtypes=index_dtypes)
rec.array([(b'a', 1, 0.5 ), (b'b', 2, 0.75)],
          dtype=[('I', 'S1'), ('A', '

---->   DataFrame.to_records

--------------------------------------
ID: 7643 --> 1
>>> df = pd.DataFrame([(.21, .32), (.01, .67), (.66, .03), (.21, .18)],
...                   columns=['dogs', 'cats'])
>>> df
    dogs  cats
0  0.21  0.32
1  0.01  0.67
2  0.66  0.03
3  0.21  0.18

---->   pandas.DataFrame

--------------------------------------
ID: 7644 --> 1
>>> df.round(1)
    dogs  cats
0   0.2   0.3
1   0.0   0.7
2   0.7   0.0
3   0.2   0.2

---->   DataFrame.round

--------------------------------------
ID: 7645 --> 1
>>> df.round({'dogs': 1, 'cats': 0})
    dogs  cats
0   0.2   0.0
1   0.0   1.0
2   0.7   0.0
3   0.2   0.0

---->   DataFrame.round

--------------------------------------
ID: 7646 --> 2
>>> decimals = pd.Series([0, 1], index=['cats', 'dogs'])
>>> df.round(decimals)
    dogs  cats
0   0.2   0.0
1   0.0   1.0
2   0.7   0.0
3   0.2   0.0

---->   pandas.Series; DataFrame.round

--------------------------------------
ID: 7647 --> 1
>>> df = pd.DataFrame({'cost': [250, 150, 100],
...                    'revenue': [100, 250, 300]},
...                   index=['A', 'B', 'C'])
>>> df
   cost  revenue
A   250      100
B   150      250
C   100      300

---->   pandas.DataFrame

--------------------------------------
ID: 7648 --> 1
>>> df.eq(100)
    cost  revenue
A  False     True
B  False    False
C   True    False

---->   DataFrame.eq

--------------------------------------
ID: 7649 --> 1
>>> df != pd.Series([100, 250], index=["cost", "revenue"])
    cost  revenue
A   True     True
B   True    False
C  False     True

---->   pandas.Series

--------------------------------------
ID: 7650 --> 2
>>> df.ne(pd.Series([100, 300], index=["A", "D"]), axis='index')
   cost  revenue
A  True    False
B  True     True
C  True     True
D  True     True

---->   DataFrame.ne; pandas.Series

--------------------------------------
ID: 7651 --> 1
>>> df.eq([250, 250, 100], axis='index')
    cost  revenue
A   True    False
B  False     True
C   True    False

---->   DataFrame.eq

--------------------------------------
ID: 7652 --> 1
>>> other = pd.DataFrame({'revenue': [300, 250, 100, 150]},
...                      index=['A', 'B', 'C', 'D'])
>>> other
   revenue
A      300
B      250
C      100
D      150

---->   pandas.DataFrame

--------------------------------------
ID: 7653 --> 1
>>> df.gt(other)
    cost  revenue
A  False    False
B  False    False
C  False     True
D  False    False

---->   DataFrame.gt

--------------------------------------
ID: 7654 --> 1
>>> df_multindex = pd.DataFrame({'cost': [250, 150, 100, 150, 300, 220],
...                              'revenue': [100, 250, 300, 200, 175, 225]},
...                             index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'],
...                                    ['A', 'B', 'C', 'A', 'B', 'C']])
>>> df_multindex
      cost  revenue
Q1 A   250      100
   B   150      250
   C   100      300
Q2 A   150      200
   B   300      175
   C   220      225

---->   pandas.DataFrame

--------------------------------------
ID: 7655 --> 1
>>> df.le(df_multindex, level=1)
       cost  revenue
Q1 A   True     True
   B   True     True
   C   True     True
Q2 A  False     True
   B   True    False
   C   True    False

---->   DataFrame.le

--------------------------------------
ID: 7656 --> 1
>>> s = pd.Series([2, np.nan, 5, -1, 0])
>>> s
0    2.0
1    NaN
2    5.0
3   -1.0
4    0.0
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 7657 --> 1
>>> s.cumprod()
0     2.0
1     NaN
2    10.0
3   -10.0
4    -0.0
dtype: float64

---->   Series.cumprod

--------------------------------------
ID: 7658 --> 1
>>> s.cumprod(skipna=False)
0    2.0
1    NaN
2    NaN
3    NaN
4    NaN
dtype: float64

---->   Series.cumprod

--------------------------------------
ID: 7659 --> 1
>>> df = pd.DataFrame([[2.0, 1.0],
...                    [3.0, np.nan],
...                    [1.0, 0.0]],
...                   columns=list('AB'))
>>> df
     A    B
0  2.0  1.0
1  3.0  NaN
2  1.0  0.0

---->   pandas.DataFrame

--------------------------------------
ID: 7660 --> 1
>>> df.cumprod()
     A    B
0  2.0  1.0
1  6.0  NaN
2  6.0  0.0

---->   DataFrame.cumprod

--------------------------------------
ID: 7661 --> 1
>>> df.cumprod(axis=1)
     A    B
0  2.0  2.0
1  3.0  NaN
2  1.0  0.0

---->   DataFrame.cumprod

--------------------------------------
ID: 7662 --> 1
>>> s = pd.Series({'a': 1, 'b': 2, 'c': 3})
>>> s.ndim
1

---->   pandas.Series

--------------------------------------
ID: 7663 --> 1
>>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})
>>> df.ndim
2

---->   pandas.DataFrame

--------------------------------------
ID: 7664 --> 1
>>> i = pd.date_range('2018-04-09', periods=4, freq='2D')
>>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)
>>> ts
            A
2018-04-09  1
2018-04-11  2
2018-04-13  3
2018-04-15  4

---->   pandas.DataFrame

--------------------------------------
ID: 7665 --> 1
>>> ts.last('3D')
            A
2018-04-13  3
2018-04-15  4

---->   DataFrame.last

--------------------------------------
ID: 7666 --> 1
>>> df = pd.DataFrame(dict(age=[5, 6, np.NaN],
...                        born=[pd.NaT, pd.Timestamp('1939-05-27'),
...                              pd.Timestamp('1940-04-25')],
...                        name=['Alfred', 'Batman', ''],
...                        toy=[None, 'Batmobile', 'Joker']))
>>> df
   age       born    name        toy
0  5.0        NaT  Alfred       None
1  6.0 1939-05-27  Batman  Batmobile
2  NaN 1940-04-25              Joker

---->   pandas.DataFrame

--------------------------------------
ID: 7667 --> 1
>>> df.isna()
     age   born   name    toy
0  False   True  False   True
1  False  False  False  False
2   True  False  False  False

---->   DataFrame.isna

--------------------------------------
ID: 7668 --> 1
>>> ser = pd.Series([5, 6, np.NaN])
>>> ser
0    5.0
1    6.0
2    NaN
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 7669 --> 1
>>> ser.isna()
0    False
1    False
2     True
dtype: bool

---->   Series.isna

--------------------------------------
ID: 7670 --> 1
>>> df = pd.DataFrame({'angles': [0, 3, 4],
...                    'degrees': [360, 180, 360]},
...                   index=['circle', 'triangle', 'rectangle'])
>>> df
           angles  degrees
circle          0      360
triangle        3      180
rectangle       4      360

---->   pandas.DataFrame

--------------------------------------
ID: 7671 --> 1
>>> df.add(1)
           angles  degrees
circle          1      361
triangle        4      181
rectangle       5      361

---->   DataFrame.add

--------------------------------------
ID: 7672 --> 1
>>> df.div(10)
           angles  degrees
circle        0.0     36.0
triangle      0.3     18.0
rectangle     0.4     36.0

---->   DataFrame.div

--------------------------------------
ID: 7673 --> 1
>>> df.rdiv(10)
             angles   degrees
circle          inf  0.027778
triangle   3.333333  0.055556
rectangle  2.500000  0.027778

---->   DataFrame.rdiv

--------------------------------------
ID: 7674 --> 1
>>> df.sub([1, 2], axis='columns')
           angles  degrees
circle         -1      358
triangle        2      178
rectangle       3      358

---->   DataFrame.sub

--------------------------------------
ID: 7675 --> 2
>>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),
...        axis='index')
           angles  degrees
circle         -1      359
triangle        2      179
rectangle       3      359

---->   DataFrame.sub; pandas.Series

--------------------------------------
ID: 7676 --> 1
>>> df.mul({'angles': 0, 'degrees': 2})
            angles  degrees
circle           0      720
triangle         0      360
rectangle        0      720

---->   DataFrame.mul

--------------------------------------
ID: 7677 --> 1
>>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')
            angles  degrees
circle           0        0
triangle         6      360
rectangle       12     1080

---->   DataFrame.mul

--------------------------------------
ID: 7678 --> 1
>>> other = pd.DataFrame({'angles': [0, 3, 4]},
...                      index=['circle', 'triangle', 'rectangle'])
>>> other
           angles
circle          0
triangle        3
rectangle       4

---->   pandas.DataFrame

--------------------------------------
ID: 7679 --> 1
>>> df.mul(other, fill_value=0)
           angles  degrees
circle          0      0.0
triangle        9      0.0
rectangle      16      0.0

---->   DataFrame.mul

--------------------------------------
ID: 7680 --> 1
>>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],
...                              'degrees': [360, 180, 360, 360, 540, 720]},
...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],
...                                    ['circle', 'triangle', 'rectangle',
...                                     'square', 'pentagon', 'hexagon']])
>>> df_multindex
             angles  degrees
A circle          0      360
  triangle        3      180
  rectangle       4      360
B square          4      360
  pentagon        5      540
  hexagon         6      720

---->   pandas.DataFrame

--------------------------------------
ID: 7681 --> 1
>>> df.div(df_multindex, level=1, fill_value=0)
             angles  degrees
A circle        NaN      1.0
  triangle      1.0      1.0
  rectangle     1.0      1.0
B square        0.0      0.0
  pentagon      0.0      0.0
  hexagon       0.0      0.0

---->   DataFrame.div

--------------------------------------
ID: 7682 --> 1
>>> pd.Series([], dtype="float64").prod()
1.0

---->   pandas.Series

--------------------------------------
ID: 7683 --> 1
>>> pd.Series([], dtype="float64").prod(min_count=1)
nan

---->   pandas.Series

--------------------------------------
ID: 7684 --> 1
>>> pd.Series([np.nan]).prod()
1.0

---->   pandas.Series

--------------------------------------
ID: 7685 --> 1
>>> pd.Series([np.nan]).prod(min_count=1)
nan

---->   pandas.Series

--------------------------------------
ID: 7686 --> 2
>>> df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]},
...                   index=['a', 'b', 'c'])  
>>> df.to_hdf('data.h5', key='df', mode='w')  

---->   pandas.DataFrame; DataFrame.to_hdf

--------------------------------------
ID: 7687 --> 2
>>> s = pd.Series([1, 2, 3, 4])  
>>> s.to_hdf('data.h5', key='s')  

---->   pandas.Series; Series.to_hdf

--------------------------------------
ID: 7688 --> 1
>>> pd.read_hdf('data.h5', 'df')  
A  B
a  1  4
b  2  5
c  3  6
>>> pd.read_hdf('data.h5', 's')  
0    1
1    2
2    3
3    4
dtype: int64

---->   pandas.read_hdf

--------------------------------------
ID: 7689 --> 2
>>> df = pd.DataFrame({'mass': [0.330, 4.87 , 5.97],
...                    'radius': [2439.7, 6051.8, 6378.1]},
...                   index=['Mercury', 'Venus', 'Earth'])
>>> plot = df.plot.pie(y='mass', figsize=(5, 5))

---->   pandas.DataFrame; DataFrame.plot

--------------------------------------
ID: 7690 --> 1
>>> plot = df.plot.pie(subplots=True, figsize=(11, 6))

---->   DataFrame.plot

--------------------------------------
ID: 7691 --> 1
>>> df = pd.DataFrame({'animal': ['alligator', 'bee', 'falcon', 'lion',
...                    'monkey', 'parrot', 'shark', 'whale', 'zebra']})
>>> df
      animal
0  alligator
1        bee
2     falcon
3       lion
4     monkey
5     parrot
6      shark
7      whale
8      zebra

---->   pandas.DataFrame

--------------------------------------
ID: 7692 --> 1
>>> df.tail()
   animal
4  monkey
5  parrot
6   shark
7   whale
8   zebra

---->   DataFrame.tail

--------------------------------------
ID: 7693 --> 1
>>> df.tail(3)
  animal
6  shark
7  whale
8  zebra

---->   DataFrame.tail

--------------------------------------
ID: 7694 --> 1
>>> df.tail(-3)
   animal
3    lion
4  monkey
5  parrot
6   shark
7   whale
8   zebra

---->   DataFrame.tail

--------------------------------------
ID: 7695 --> 1
>>> df = pd.DataFrame({'a': [1, 2] * 3,
...                    'b': [True, False] * 3,
...                    'c': [1.0, 2.0] * 3})
>>> df
        a      b  c
0       1   True  1.0
1       2  False  2.0
2       1   True  1.0
3       2  False  2.0
4       1   True  1.0
5       2  False  2.0

---->   pandas.DataFrame

--------------------------------------
ID: 7696 --> 1
>>> df.select_dtypes(include='bool')
   b
0  True
1  False
2  True
3  False
4  True
5  False

---->   DataFrame.select_dtypes

--------------------------------------
ID: 7697 --> 1
>>> df.select_dtypes(include=['float64'])
   c
0  1.0
1  2.0
2  1.0
3  2.0
4  1.0
5  2.0

---->   DataFrame.select_dtypes

--------------------------------------
ID: 7698 --> 1
>>> df.select_dtypes(exclude=['int64'])
       b    c
0   True  1.0
1  False  2.0
2   True  1.0
3  False  2.0
4   True  1.0
5  False  2.0

---->   DataFrame.select_dtypes

--------------------------------------
ID: 7699 --> 1
>>> df = pd.DataFrame({'angles': [0, 3, 4],
...                    'degrees': [360, 180, 360]},
...                   index=['circle', 'triangle', 'rectangle'])
>>> df
           angles  degrees
circle          0      360
triangle        3      180
rectangle       4      360

---->   pandas.DataFrame

--------------------------------------
ID: 7700 --> 1
>>> df.add(1)
           angles  degrees
circle          1      361
triangle        4      181
rectangle       5      361

---->   DataFrame.add

--------------------------------------
ID: 7701 --> 1
>>> df.div(10)
           angles  degrees
circle        0.0     36.0
triangle      0.3     18.0
rectangle     0.4     36.0

---->   DataFrame.div

--------------------------------------
ID: 7702 --> 1
>>> df.rdiv(10)
             angles   degrees
circle          inf  0.027778
triangle   3.333333  0.055556
rectangle  2.500000  0.027778

---->   DataFrame.rdiv

--------------------------------------
ID: 7703 --> 1
>>> df.sub([1, 2], axis='columns')
           angles  degrees
circle         -1      358
triangle        2      178
rectangle       3      358

---->   DataFrame.sub

--------------------------------------
ID: 7704 --> 2
>>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),
...        axis='index')
           angles  degrees
circle         -1      359
triangle        2      179
rectangle       3      359

---->   DataFrame.sub; pandas.Series

--------------------------------------
ID: 7705 --> 1
>>> df.mul({'angles': 0, 'degrees': 2})
            angles  degrees
circle           0      720
triangle         0      360
rectangle        0      720

---->   DataFrame.mul

--------------------------------------
ID: 7706 --> 1
>>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')
            angles  degrees
circle           0        0
triangle         6      360
rectangle       12     1080

---->   DataFrame.mul

--------------------------------------
ID: 7707 --> 1
>>> other = pd.DataFrame({'angles': [0, 3, 4]},
...                      index=['circle', 'triangle', 'rectangle'])
>>> other
           angles
circle          0
triangle        3
rectangle       4

---->   pandas.DataFrame

--------------------------------------
ID: 7708 --> 1
>>> df.mul(other, fill_value=0)
           angles  degrees
circle          0      0.0
triangle        9      0.0
rectangle      16      0.0

---->   DataFrame.mul

--------------------------------------
ID: 7709 --> 1
>>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],
...                              'degrees': [360, 180, 360, 360, 540, 720]},
...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],
...                                    ['circle', 'triangle', 'rectangle',
...                                     'square', 'pentagon', 'hexagon']])
>>> df_multindex
             angles  degrees
A circle          0      360
  triangle        3      180
  rectangle       4      360
B square          4      360
  pentagon        5      540
  hexagon         6      720

---->   pandas.DataFrame

--------------------------------------
ID: 7710 --> 1
>>> df.div(df_multindex, level=1, fill_value=0)
             angles  degrees
A circle        NaN      1.0
  triangle      1.0      1.0
  rectangle     1.0      1.0
B square        0.0      0.0
  pentagon      0.0      0.0
  hexagon       0.0      0.0

---->   DataFrame.div

--------------------------------------
ID: 7711 --> 1
>>> d = {'num_legs': [4, 4, 2, 2],
...      'num_wings': [0, 0, 2, 2],
...      'class': ['mammal', 'mammal', 'mammal', 'bird'],
...      'animal': ['cat', 'dog', 'bat', 'penguin'],
...      'locomotion': ['walks', 'walks', 'flies', 'walks']}
>>> df = pd.DataFrame(data=d)
>>> df = df.set_index(['class', 'animal', 'locomotion'])
>>> df
                           num_legs  num_wings
class  animal  locomotion
mammal cat     walks              4          0
       dog     walks              4          0
       bat     flies              2          2
bird   penguin walks              2          2

---->   pandas.DataFrame

--------------------------------------
ID: 7712 --> 1
>>> df.xs('mammal')
                   num_legs  num_wings
animal locomotion
cat    walks              4          0
dog    walks              4          0
bat    flies              2          2

---->   DataFrame.xs

--------------------------------------
ID: 7713 --> 1
>>> df.xs(('mammal', 'dog', 'walks'))
num_legs     4
num_wings    0
Name: (mammal, dog, walks), dtype: int64

---->   DataFrame.xs

--------------------------------------
ID: 7714 --> 1
>>> df.xs('cat', level=1)
                   num_legs  num_wings
class  locomotion
mammal walks              4          0

---->   DataFrame.xs

--------------------------------------
ID: 7715 --> 1
>>> df.xs(('bird', 'walks'),
...       level=[0, 'locomotion'])
         num_legs  num_wings
animal
penguin         2          2

---->   DataFrame.xs

--------------------------------------
ID: 7716 --> 1
>>> df.xs('num_wings', axis=1)
class   animal   locomotion
mammal  cat      walks         0
        dog      walks         0
        bat      flies         2
bird    penguin  walks         2
Name: num_wings, dtype: int64

---->   DataFrame.xs

--------------------------------------
ID: 7717 --> 2
>>> df = pd.DataFrame(
...     np.random.randint(1, 7, 6000),
...     columns = ['one'])
>>> df['two'] = df['one'] + np.random.randint(1, 7, 6000)
>>> ax = df.plot.hist(bins=12, alpha=0.5)

---->   pandas.DataFrame; DataFrame.plot

--------------------------------------
ID: 7718 --> 2
>>> age_list = [8, 10, 12, 14, 72, 74, 76, 78, 20, 25, 30, 35, 60, 85]
>>> df = pd.DataFrame({"gender": list("MMMMMMMMFFFFFF"), "age": age_list})
>>> ax = df.plot.hist(column=["age"], by="gender", figsize=(10, 8))

---->   pandas.DataFrame; DataFrame.plot

--------------------------------------
ID: 7719 --> 1
>>> df = pd.DataFrame({'cost': [250, 150, 100],
...                    'revenue': [100, 250, 300]},
...                   index=['A', 'B', 'C'])
>>> df
   cost  revenue
A   250      100
B   150      250
C   100      300

---->   pandas.DataFrame

--------------------------------------
ID: 7720 --> 1
>>> df.eq(100)
    cost  revenue
A  False     True
B  False    False
C   True    False

---->   DataFrame.eq

--------------------------------------
ID: 7721 --> 1
>>> df != pd.Series([100, 250], index=["cost", "revenue"])
    cost  revenue
A   True     True
B   True    False
C  False     True

---->   pandas.Series

--------------------------------------
ID: 7722 --> 2
>>> df.ne(pd.Series([100, 300], index=["A", "D"]), axis='index')
   cost  revenue
A  True    False
B  True     True
C  True     True
D  True     True

---->   DataFrame.ne; pandas.Series

--------------------------------------
ID: 7723 --> 1
>>> df.eq([250, 250, 100], axis='index')
    cost  revenue
A   True    False
B  False     True
C   True    False

---->   DataFrame.eq

--------------------------------------
ID: 7724 --> 1
>>> other = pd.DataFrame({'revenue': [300, 250, 100, 150]},
...                      index=['A', 'B', 'C', 'D'])
>>> other
   revenue
A      300
B      250
C      100
D      150

---->   pandas.DataFrame

--------------------------------------
ID: 7725 --> 1
>>> df.gt(other)
    cost  revenue
A  False    False
B  False    False
C  False     True
D  False    False

---->   DataFrame.gt

--------------------------------------
ID: 7726 --> 1
>>> df_multindex = pd.DataFrame({'cost': [250, 150, 100, 150, 300, 220],
...                              'revenue': [100, 250, 300, 200, 175, 225]},
...                             index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'],
...                                    ['A', 'B', 'C', 'A', 'B', 'C']])
>>> df_multindex
      cost  revenue
Q1 A   250      100
   B   150      250
   C   100      300
Q2 A   150      200
   B   300      175
   C   220      225

---->   pandas.DataFrame

--------------------------------------
ID: 7727 --> 1
>>> df.le(df_multindex, level=1)
       cost  revenue
Q1 A   True     True
   B   True     True
   C   True     True
Q2 A  False     True
   B   True    False
   C   True    False

---->   DataFrame.le

--------------------------------------
ID: 7728 --> 1
>>> df = pd.DataFrame(data={'Animal': ['cat', 'penguin', 'dog',
...                                    'spider', 'snake'],
...                         'Number_legs': [4, 2, 4, 8, np.nan]})
>>> df
    Animal  Number_legs
0      cat          4.0
1  penguin          2.0
2      dog          4.0
3   spider          8.0
4    snake          NaN

---->   pandas.DataFrame

--------------------------------------
ID: 7729 --> 2
>>> s = pd.Series(range(5), index=list("abcde"))
>>> s["d"] = s["b"]
>>> s.rank()
a    1.0
b    2.5
c    4.0
d    2.5
e    5.0
dtype: float64

---->   pandas.Series; Series.rank

--------------------------------------
ID: 7731 --> 1
>>> data = np.array([(3, 'a'), (2, 'b'), (1, 'c'), (0, 'd')],
...                 dtype=[('col_1', 'i4'), ('col_2', 'U1')])
>>> pd.DataFrame.from_records(data)
   col_1 col_2
0      3     a
1      2     b
2      1     c
3      0     d

---->   pandas.DataFrame

--------------------------------------
ID: 7732 --> 1
>>> data = [{'col_1': 3, 'col_2': 'a'},
...         {'col_1': 2, 'col_2': 'b'},
...         {'col_1': 1, 'col_2': 'c'},
...         {'col_1': 0, 'col_2': 'd'}]
>>> pd.DataFrame.from_records(data)
   col_1 col_2
0      3     a
1      2     b
2      1     c
3      0     d

---->   pandas.DataFrame

--------------------------------------
ID: 7733 --> 1
>>> data = [(3, 'a'), (2, 'b'), (1, 'c'), (0, 'd')]
>>> pd.DataFrame.from_records(data, columns=['col_1', 'col_2'])
   col_1 col_2
0      3     a
1      2     b
2      1     c
3      0     d

---->   pandas.DataFrame

--------------------------------------
ID: 7734 --> 2
>>> data = np.random.randn(25, 4)
>>> df = pd.DataFrame(data, columns=list('ABCD'))
>>> ax = df.plot.box()

---->   pandas.DataFrame; DataFrame.plot

--------------------------------------
ID: 7735 --> 2
>>> age_list = [8, 10, 12, 14, 72, 74, 76, 78, 20, 25, 30, 35, 60, 85]
>>> df = pd.DataFrame({"gender": list("MMMMMMMMFFFFFF"), "age": age_list})
>>> ax = df.plot.box(column="age", by="gender", figsize=(10, 8))

---->   pandas.DataFrame; DataFrame.plot

--------------------------------------
ID: 7736 --> 1
>>> df = pd.DataFrame()
>>> df.flags

>>> df.flags.allows_duplicate_labels = False
>>> df.flags


---->   pandas.DataFrame

--------------------------------------
ID: 7737 --> 1
>>> df = pd.DataFrame(
...     {"Grade": ["A", "B", "A", "C"]},
...     index=[
...         ["Final exam", "Final exam", "Coursework", "Coursework"],
...         ["History", "Geography", "History", "Geography"],
...         ["January", "February", "March", "April"],
...     ],
... )
>>> df
                                    Grade
Final exam  History     January      A
            Geography   February     B
Coursework  History     March        A
            Geography   April        C

---->   pandas.DataFrame

--------------------------------------
ID: 7738 --> 1
>>> df.swaplevel()
                                    Grade
Final exam  January     History         A
            February    Geography       B
Coursework  March       History         A
            April       Geography       C

---->   DataFrame.swaplevel

--------------------------------------
ID: 7739 --> 1
>>> df.swaplevel(0)
                                    Grade
January     History     Final exam      A
February    Geography   Final exam      B
March       History     Coursework      A
April       Geography   Coursework      C

---->   DataFrame.swaplevel

--------------------------------------
ID: 7740 --> 1
>>> df.swaplevel(0, 1)
                                    Grade
History     Final exam  January         A
Geography   Final exam  February        B
History     Coursework  March           A
Geography   Coursework  April           C

---->   DataFrame.swaplevel

--------------------------------------
ID: 7741 --> 1
>>> df = pd.DataFrame({'angles': [0, 3, 4],
...                    'degrees': [360, 180, 360]},
...                   index=['circle', 'triangle', 'rectangle'])
>>> df
           angles  degrees
circle          0      360
triangle        3      180
rectangle       4      360

---->   pandas.DataFrame

--------------------------------------
ID: 7742 --> 1
>>> df.add(1)
           angles  degrees
circle          1      361
triangle        4      181
rectangle       5      361

---->   DataFrame.add

--------------------------------------
ID: 7743 --> 1
>>> df.div(10)
           angles  degrees
circle        0.0     36.0
triangle      0.3     18.0
rectangle     0.4     36.0

---->   DataFrame.div

--------------------------------------
ID: 7744 --> 1
>>> df.rdiv(10)
             angles   degrees
circle          inf  0.027778
triangle   3.333333  0.055556
rectangle  2.500000  0.027778

---->   DataFrame.rdiv

--------------------------------------
ID: 7745 --> 1
>>> df.sub([1, 2], axis='columns')
           angles  degrees
circle         -1      358
triangle        2      178
rectangle       3      358

---->   DataFrame.sub

--------------------------------------
ID: 7746 --> 2
>>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),
...        axis='index')
           angles  degrees
circle         -1      359
triangle        2      179
rectangle       3      359

---->   DataFrame.sub; pandas.Series

--------------------------------------
ID: 7747 --> 1
>>> df.mul({'angles': 0, 'degrees': 2})
            angles  degrees
circle           0      720
triangle         0      360
rectangle        0      720

---->   DataFrame.mul

--------------------------------------
ID: 7748 --> 1
>>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')
            angles  degrees
circle           0        0
triangle         6      360
rectangle       12     1080

---->   DataFrame.mul

--------------------------------------
ID: 7749 --> 1
>>> other = pd.DataFrame({'angles': [0, 3, 4]},
...                      index=['circle', 'triangle', 'rectangle'])
>>> other
           angles
circle          0
triangle        3
rectangle       4

---->   pandas.DataFrame

--------------------------------------
ID: 7750 --> 1
>>> df.mul(other, fill_value=0)
           angles  degrees
circle          0      0.0
triangle        9      0.0
rectangle      16      0.0

---->   DataFrame.mul

--------------------------------------
ID: 7751 --> 1
>>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],
...                              'degrees': [360, 180, 360, 360, 540, 720]},
...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],
...                                    ['circle', 'triangle', 'rectangle',
...                                     'square', 'pentagon', 'hexagon']])
>>> df_multindex
             angles  degrees
A circle          0      360
  triangle        3      180
  rectangle       4      360
B square          4      360
  pentagon        5      540
  hexagon         6      720

---->   pandas.DataFrame

--------------------------------------
ID: 7752 --> 1
>>> df.div(df_multindex, level=1, fill_value=0)
             angles  degrees
A circle        NaN      1.0
  triangle      1.0      1.0
  rectangle     1.0      1.0
B square        0.0      0.0
  pentagon      0.0      0.0
  hexagon       0.0      0.0

---->   DataFrame.div

--------------------------------------
ID: 7753 --> 1
>>> df = pd.DataFrame([('falcon', 'bird', 389.0),
...                    ('parrot', 'bird', 24.0),
...                    ('lion', 'mammal', 80.5),
...                    ('monkey', 'mammal', np.nan)],
...                   columns=['name', 'class', 'max_speed'],
...                   index=[0, 2, 3, 1])
>>> df
     name   class  max_speed
0  falcon    bird      389.0
2  parrot    bird       24.0
3    lion  mammal       80.5
1  monkey  mammal        NaN

---->   pandas.DataFrame

--------------------------------------
ID: 7754 --> 1
>>> df.take([0, 3])
     name   class  max_speed
0  falcon    bird      389.0
1  monkey  mammal        NaN

---->   DataFrame.take

--------------------------------------
ID: 7755 --> 1
>>> df.take([1, 2], axis=1)
    class  max_speed
0    bird      389.0
2    bird       24.0
3  mammal       80.5
1  mammal        NaN

---->   DataFrame.take

--------------------------------------
ID: 7756 --> 1
>>> df.take([-1, -2])
     name   class  max_speed
1  monkey  mammal        NaN
3    lion  mammal       80.5

---->   DataFrame.take

--------------------------------------
ID: 7757 --> 1
>>> df = pd.DataFrame({'angles': [0, 3, 4],
...                    'degrees': [360, 180, 360]},
...                   index=['circle', 'triangle', 'rectangle'])
>>> df
           angles  degrees
circle          0      360
triangle        3      180
rectangle       4      360

---->   pandas.DataFrame

--------------------------------------
ID: 7758 --> 1
>>> df.add(1)
           angles  degrees
circle          1      361
triangle        4      181
rectangle       5      361

---->   DataFrame.add

--------------------------------------
ID: 7759 --> 1
>>> df.div(10)
           angles  degrees
circle        0.0     36.0
triangle      0.3     18.0
rectangle     0.4     36.0

---->   DataFrame.div

--------------------------------------
ID: 7760 --> 1
>>> df.rdiv(10)
             angles   degrees
circle          inf  0.027778
triangle   3.333333  0.055556
rectangle  2.500000  0.027778

---->   DataFrame.rdiv

--------------------------------------
ID: 7761 --> 1
>>> df.sub([1, 2], axis='columns')
           angles  degrees
circle         -1      358
triangle        2      178
rectangle       3      358

---->   DataFrame.sub

--------------------------------------
ID: 7762 --> 2
>>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),
...        axis='index')
           angles  degrees
circle         -1      359
triangle        2      179
rectangle       3      359

---->   DataFrame.sub; pandas.Series

--------------------------------------
ID: 7763 --> 1
>>> df.mul({'angles': 0, 'degrees': 2})
            angles  degrees
circle           0      720
triangle         0      360
rectangle        0      720

---->   DataFrame.mul

--------------------------------------
ID: 7764 --> 1
>>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')
            angles  degrees
circle           0        0
triangle         6      360
rectangle       12     1080

---->   DataFrame.mul

--------------------------------------
ID: 7765 --> 1
>>> other = pd.DataFrame({'angles': [0, 3, 4]},
...                      index=['circle', 'triangle', 'rectangle'])
>>> other
           angles
circle          0
triangle        3
rectangle       4

---->   pandas.DataFrame

--------------------------------------
ID: 7766 --> 1
>>> df.mul(other, fill_value=0)
           angles  degrees
circle          0      0.0
triangle        9      0.0
rectangle      16      0.0

---->   DataFrame.mul

--------------------------------------
ID: 7767 --> 1
>>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],
...                              'degrees': [360, 180, 360, 360, 540, 720]},
...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],
...                                    ['circle', 'triangle', 'rectangle',
...                                     'square', 'pentagon', 'hexagon']])
>>> df_multindex
             angles  degrees
A circle          0      360
  triangle        3      180
  rectangle       4      360
B square          4      360
  pentagon        5      540
  hexagon         6      720

---->   pandas.DataFrame

--------------------------------------
ID: 7768 --> 1
>>> df.div(df_multindex, level=1, fill_value=0)
             angles  degrees
A circle        NaN      1.0
  triangle      1.0      1.0
  rectangle     1.0      1.0
B square        0.0      0.0
  pentagon      0.0      0.0
  hexagon       0.0      0.0

---->   DataFrame.div

--------------------------------------
ID: 7769 --> 1
>>> primes = pd.Series([2, 3, 5, 7])

---->   pandas.Series

--------------------------------------
ID: 7772 --> 1
>>> df = pd.DataFrame([[1, 2], [3, 4]], columns=['a', 'b'])
>>> df
   a  b
0  1  2
1  3  4

---->   pandas.DataFrame

--------------------------------------
ID: 7776 --> 2
>>> df = pd.DataFrame({'A': [1, 2, 3],
...                    'B': [400, 500, 600]})
>>> new_df = pd.DataFrame({'B': [4, 5, 6],
...                        'C': [7, 8, 9]})
>>> df.update(new_df)
>>> df
   A  B
0  1  4
1  2  5
2  3  6

---->   pandas.DataFrame; DataFrame.update

--------------------------------------
ID: 7777 --> 2
>>> df = pd.DataFrame({'A': ['a', 'b', 'c'],
...                    'B': ['x', 'y', 'z']})
>>> new_df = pd.DataFrame({'B': ['d', 'e', 'f', 'g', 'h', 'i']})
>>> df.update(new_df)
>>> df
   A  B
0  a  d
1  b  e
2  c  f

---->   pandas.DataFrame; DataFrame.update

--------------------------------------
ID: 7778 --> 3
>>> df = pd.DataFrame({'A': ['a', 'b', 'c'],
...                    'B': ['x', 'y', 'z']})
>>> new_column = pd.Series(['d', 'e'], name='B', index=[0, 2])
>>> df.update(new_column)
>>> df
   A  B
0  a  d
1  b  y
2  c  e
>>> df = pd.DataFrame({'A': ['a', 'b', 'c'],
...                    'B': ['x', 'y', 'z']})
>>> new_df = pd.DataFrame({'B': ['d', 'e']}, index=[1, 2])
>>> df.update(new_df)
>>> df
   A  B
0  a  x
1  b  d
2  c  e

---->   pandas.DataFrame; pandas.Series; DataFrame.update

--------------------------------------
ID: 7779 --> 2
>>> df = pd.DataFrame({'A': [1, 2, 3],
...                    'B': [400, 500, 600]})
>>> new_df = pd.DataFrame({'B': [4, np.nan, 6]})
>>> df.update(new_df)
>>> df
   A    B
0  1    4
1  2  500
2  3    6

---->   pandas.DataFrame; DataFrame.update

--------------------------------------
ID: 7780 --> 1
>>> df = pd.DataFrame({'population': [59000000, 65000000, 434000,
...                                   434000, 434000, 337000, 11300,
...                                   11300, 11300],
...                    'GDP': [1937894, 2583560 , 12011, 4520, 12128,
...                            17036, 182, 38, 311],
...                    'alpha-2': ["IT", "FR", "MT", "MV", "BN",
...                                "IS", "NR", "TV", "AI"]},
...                   index=["Italy", "France", "Malta",
...                          "Maldives", "Brunei", "Iceland",
...                          "Nauru", "Tuvalu", "Anguilla"])
>>> df
          population      GDP alpha-2
Italy       59000000  1937894      IT
France      65000000  2583560      FR
Malta         434000    12011      MT
Maldives      434000     4520      MV
Brunei        434000    12128      BN
Iceland       337000    17036      IS
Nauru          11300      182      NR
Tuvalu         11300       38      TV
Anguilla       11300      311      AI

---->   pandas.DataFrame

--------------------------------------
ID: 7781 --> 1
>>> df.nlargest(3, 'population')
        population      GDP alpha-2
France    65000000  2583560      FR
Italy     59000000  1937894      IT
Malta       434000    12011      MT

---->   DataFrame.nlargest

--------------------------------------
ID: 7782 --> 1
>>> df.nlargest(3, 'population', keep='last')
        population      GDP alpha-2
France    65000000  2583560      FR
Italy     59000000  1937894      IT
Brunei      434000    12128      BN

---->   DataFrame.nlargest

--------------------------------------
ID: 7783 --> 1
>>> df.nlargest(3, 'population', keep='all')
          population      GDP alpha-2
France      65000000  2583560      FR
Italy       59000000  1937894      IT
Malta         434000    12011      MT
Maldives      434000     4520      MV
Brunei        434000    12128      BN

---->   DataFrame.nlargest

--------------------------------------
ID: 7784 --> 1
>>> df.nlargest(3, ['population', 'GDP'])
        population      GDP alpha-2
France    65000000  2583560      FR
Italy     59000000  1937894      IT
Brunei      434000    12128      BN

---->   DataFrame.nlargest

--------------------------------------
ID: 7785 --> 1
>>> int_values = [1, 2, 3, 4, 5]
>>> text_values = ['alpha', 'beta', 'gamma', 'delta', 'epsilon']
>>> float_values = [0.0, 0.25, 0.5, 0.75, 1.0]
>>> df = pd.DataFrame({"int_col": int_values, "text_col": text_values,
...                   "float_col": float_values})
>>> df
    int_col text_col  float_col
0        1    alpha       0.00
1        2     beta       0.25
2        3    gamma       0.50
3        4    delta       0.75
4        5  epsilon       1.00

---->   pandas.DataFrame

--------------------------------------
ID: 7786 --> 1
>>> df.info(verbose=True)

RangeIndex: 5 entries, 0 to 4
Data columns (total 3 columns):
 #   Column     Non-Null Count  Dtype
---  ------     --------------  -----
 0   int_col    5 non-null      int64
 1   text_col   5 non-null      object
 2   float_col  5 non-null      float64
dtypes: float64(1), int64(1), object(1)
memory usage: 248.0+ bytes

---->   DataFrame.info

--------------------------------------
ID: 7787 --> 1
>>> df.info(verbose=False)

RangeIndex: 5 entries, 0 to 4
Columns: 3 entries, int_col to float_col
dtypes: float64(1), int64(1), object(1)
memory usage: 248.0+ bytes

---->   DataFrame.info

--------------------------------------
ID: 7788 --> 1
>>> import io
>>> buffer = io.StringIO()
>>> df.info(buf=buffer)
>>> s = buffer.getvalue()
>>> with open("df_info.txt", "w",
...           encoding="utf-8") as f:  
...     f.write(s)
260

---->   DataFrame.info

--------------------------------------
ID: 7789 --> 2
>>> random_strings_array = np.random.choice(['a', 'b', 'c'], 10 ** 6)
>>> df = pd.DataFrame({
...     'column_1': np.random.choice(['a', 'b', 'c'], 10 ** 6),
...     'column_2': np.random.choice(['a', 'b', 'c'], 10 ** 6),
...     'column_3': np.random.choice(['a', 'b', 'c'], 10 ** 6)
... })
>>> df.info()

RangeIndex: 1000000 entries, 0 to 999999
Data columns (total 3 columns):
 #   Column    Non-Null Count    Dtype
---  ------    --------------    -----
 0   column_1  1000000 non-null  object
 1   column_2  1000000 non-null  object
 2   column_3  1000000 non-null  object
dtypes: object(3)
memory usage: 22.9+ MB

---->   pandas.DataFrame; DataFrame.info

--------------------------------------
ID: 7790 --> 1
>>> df.info(memory_usage='deep')

RangeIndex: 1000000 entries, 0 to 999999
Data columns (total 3 columns):
 #   Column    Non-Null Count    Dtype
---  ------    --------------    -----
 0   column_1  1000000 non-null  object
 1   column_2  1000000 non-null  object
 2   column_3  1000000 non-null  object
dtypes: object(3)
memory usage: 165.9 MB

---->   DataFrame.info

--------------------------------------
ID: 7791 --> 1
>>> data = {'col_1': [3, 2, 1, 0], 'col_2': ['a', 'b', 'c', 'd']}
>>> pd.DataFrame.from_dict(data)
   col_1 col_2
0      3     a
1      2     b
2      1     c
3      0     d

---->   pandas.DataFrame

--------------------------------------
ID: 7792 --> 1
>>> data = {'row_1': [3, 2, 1, 0], 'row_2': ['a', 'b', 'c', 'd']}
>>> pd.DataFrame.from_dict(data, orient='index')
       0  1  2  3
row_1  3  2  1  0
row_2  a  b  c  d

---->   pandas.DataFrame

--------------------------------------
ID: 7793 --> 1
>>> pd.DataFrame.from_dict(data, orient='index',
...                        columns=['A', 'B', 'C', 'D'])
       A  B  C  D
row_1  3  2  1  0
row_2  a  b  c  d

---->   pandas.DataFrame

--------------------------------------
ID: 7794 --> 1
>>> data = {'index': [('a', 'b'), ('a', 'c')],
...         'columns': [('x', 1), ('y', 2)],
...         'data': [[1, 3], [2, 4]],
...         'index_names': ['n1', 'n2'],
...         'column_names': ['z1', 'z2']}
>>> pd.DataFrame.from_dict(data, orient='tight')
z1     x  y
z2     1  2
n1 n2
a  b   1  3
   c   2  4

---->   pandas.DataFrame

--------------------------------------
ID: 7795 --> 1
>>> df = pd.DataFrame([
...     [1, 2, 3, 4],
...     [5, 6, 7, 8],
...     [9, 10, 11, 12]
... ]).set_index([0, 1]).rename_axis(['a', 'b'])

---->   pandas.DataFrame

--------------------------------------
ID: 7796 --> 1
>>> df.columns = pd.MultiIndex.from_tuples([
...     ('c', 'e'), ('d', 'f')
... ], names=['level_1', 'level_2'])

---->   pandas.MultiIndex

--------------------------------------
ID: 7797 --> 1
>>> df.droplevel('a')
level_1   c   d
level_2   e   f
b
2        3   4
6        7   8
10      11  12

---->   DataFrame.droplevel

--------------------------------------
ID: 7798 --> 1
>>> df.droplevel('level_2', axis=1)
level_1   c   d
a b
1 2      3   4
5 6      7   8
9 10    11  12

---->   DataFrame.droplevel

--------------------------------------
ID: 7799 --> 1
>>> df = pd.DataFrame({'float': [1.0],
...                    'int': [1],
...                    'datetime': [pd.Timestamp('20180310')],
...                    'string': ['foo']})
>>> df.dtypes
float              float64
int                  int64
datetime    datetime64[ns]
string              object
dtype: object

---->   pandas.DataFrame

--------------------------------------
ID: 7800 --> 1
>>> df = pd.DataFrame({'month': [1, 4, 7, 10],
...                    'year': [2012, 2014, 2013, 2014],
...                    'sale': [55, 40, 84, 31]})
>>> df
   month  year  sale
0      1  2012    55
1      4  2014    40
2      7  2013    84
3     10  2014    31

---->   pandas.DataFrame

--------------------------------------
ID: 7803 --> 1
>>> df.set_index([pd.Index([1, 2, 3, 4]), 'year'])
         month  sale
   year
1  2012  1      55
2  2014  4      40
3  2013  7      84
4  2014  10     31

---->   pandas.Index

--------------------------------------
ID: 7804 --> 1
>>> s = pd.Series([1, 2, 3, 4])
>>> df.set_index([s, s**2])
      month  year  sale
1 1       1  2012    55
2 4       4  2014    40
3 9       7  2013    84
4 16     10  2014    31

---->   pandas.Series

--------------------------------------
ID: 7805 --> 2
>>> df = pd.DataFrame({'species': ['bear', 'bear', 'marsupial'],
...                   'population': [1864, 22000, 80000]},
...                   index=['panda', 'polar', 'koala'])
>>> df
        species   population
panda   bear      1864
polar   bear      22000
koala   marsupial 80000
>>> for label, content in df.items():
...     print(f'label: {label}')
...     print(f'content: {content}', sep='\n')
...
label: species
content:
panda         bear
polar         bear
koala    marsupial
Name: species, dtype: object
label: population
content:
panda     1864
polar    22000
koala    80000
Name: population, dtype: int64

---->   pandas.DataFrame; DataFrame.items

--------------------------------------
ID: 7806 --> 1
>>> df = pd.DataFrame(np.array(([1, 2, 3], [4, 5, 6])),
...                   index=['mouse', 'rabbit'],
...                   columns=['one', 'two', 'three'])
>>> df
        one  two  three
mouse     1    2      3
rabbit    4    5      6

---->   pandas.DataFrame

--------------------------------------
ID: 7807 --> 1
>>> # select columns by name
>>> df.filter(items=['one', 'three'])
         one  three
mouse     1      3
rabbit    4      6

---->   DataFrame.filter

--------------------------------------
ID: 7808 --> 1
>>> # select columns by regular expression
>>> df.filter(regex='e$', axis=1)
         one  three
mouse     1      3
rabbit    4      6

---->   DataFrame.filter

--------------------------------------
ID: 7809 --> 1
>>> # select rows containing 'bbi'
>>> df.filter(like='bbi', axis=0)
         one  two  three
rabbit    4    5      6

---->   DataFrame.filter

--------------------------------------
ID: 7810 --> 1
>>> df = pd.DataFrame({"name": ['Alfred', 'Batman', 'Catwoman'],
...                    "toy": [np.nan, 'Batmobile', 'Bullwhip'],
...                    "born": [pd.NaT, pd.Timestamp("1940-04-25"),
...                             pd.NaT]})
>>> df
       name        toy       born
0    Alfred        NaN        NaT
1    Batman  Batmobile 1940-04-25
2  Catwoman   Bullwhip        NaT

---->   pandas.DataFrame

--------------------------------------
ID: 7816 --> 2
>>> s = pd.Series([1, 2, 2.5, 3, 3.5, 4, 5])
>>> ax = s.plot.kde()

---->   pandas.Series; Series.plot

--------------------------------------
ID: 7817 --> 1
>>> ax = s.plot.kde(bw_method=0.3)

---->   Series.plot

--------------------------------------
ID: 7818 --> 1
>>> ax = s.plot.kde(bw_method=3)

---->   Series.plot

--------------------------------------
ID: 7819 --> 1
>>> ax = s.plot.kde(ind=[1, 2, 3, 4, 5])

---->   Series.plot

--------------------------------------
ID: 7820 --> 2
>>> df = pd.DataFrame({
...     'x': [1, 2, 2.5, 3, 3.5, 4, 5],
...     'y': [4, 4, 4.5, 5, 5.5, 6, 6],
... })
>>> ax = df.plot.kde()

---->   pandas.DataFrame; DataFrame.plot

--------------------------------------
ID: 7821 --> 1
>>> ax = df.plot.kde(bw_method=0.3)

---->   DataFrame.plot

--------------------------------------
ID: 7822 --> 1
>>> ax = df.plot.kde(bw_method=3)

---->   DataFrame.plot

--------------------------------------
ID: 7823 --> 1
>>> ax = df.plot.kde(ind=[1, 2, 3, 4, 5, 6])

---->   DataFrame.plot

--------------------------------------
ID: 7824 --> 1
>>> df = pd.DataFrame({"A": [1, 2, 3], "B": [4, 5, 6]})
>>> df.rename(columns={"A": "a", "B": "c"})
   a  c
0  1  4
1  2  5
2  3  6

---->   pandas.DataFrame

--------------------------------------
ID: 7830 --> 1
>>> s = pd.Series([2, np.nan, 5, -1, 0])
>>> s
0    2.0
1    NaN
2    5.0
3   -1.0
4    0.0
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 7831 --> 1
>>> s.cumsum()
0    2.0
1    NaN
2    7.0
3    6.0
4    6.0
dtype: float64

---->   Series.cumsum

--------------------------------------
ID: 7832 --> 1
>>> s.cumsum(skipna=False)
0    2.0
1    NaN
2    NaN
3    NaN
4    NaN
dtype: float64

---->   Series.cumsum

--------------------------------------
ID: 7833 --> 1
>>> df = pd.DataFrame([[2.0, 1.0],
...                    [3.0, np.nan],
...                    [1.0, 0.0]],
...                   columns=list('AB'))
>>> df
     A    B
0  2.0  1.0
1  3.0  NaN
2  1.0  0.0

---->   pandas.DataFrame

--------------------------------------
ID: 7834 --> 1
>>> df.cumsum()
     A    B
0  2.0  1.0
1  5.0  NaN
2  6.0  1.0

---->   DataFrame.cumsum

--------------------------------------
ID: 7835 --> 1
>>> df.cumsum(axis=1)
     A    B
0  2.0  3.0
1  3.0  NaN
2  1.0  1.0

---->   DataFrame.cumsum

--------------------------------------
ID: 7836 --> 1
>>> df = pd.DataFrame({'angles': [0, 3, 4],
...                    'degrees': [360, 180, 360]},
...                   index=['circle', 'triangle', 'rectangle'])
>>> df
           angles  degrees
circle          0      360
triangle        3      180
rectangle       4      360

---->   pandas.DataFrame

--------------------------------------
ID: 7837 --> 1
>>> df.add(1)
           angles  degrees
circle          1      361
triangle        4      181
rectangle       5      361

---->   DataFrame.add

--------------------------------------
ID: 7838 --> 1
>>> df.div(10)
           angles  degrees
circle        0.0     36.0
triangle      0.3     18.0
rectangle     0.4     36.0

---->   DataFrame.div

--------------------------------------
ID: 7839 --> 1
>>> df.rdiv(10)
             angles   degrees
circle          inf  0.027778
triangle   3.333333  0.055556
rectangle  2.500000  0.027778

---->   DataFrame.rdiv

--------------------------------------
ID: 7840 --> 1
>>> df.sub([1, 2], axis='columns')
           angles  degrees
circle         -1      358
triangle        2      178
rectangle       3      358

---->   DataFrame.sub

--------------------------------------
ID: 7841 --> 2
>>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),
...        axis='index')
           angles  degrees
circle         -1      359
triangle        2      179
rectangle       3      359

---->   DataFrame.sub; pandas.Series

--------------------------------------
ID: 7842 --> 1
>>> df.mul({'angles': 0, 'degrees': 2})
            angles  degrees
circle           0      720
triangle         0      360
rectangle        0      720

---->   DataFrame.mul

--------------------------------------
ID: 7843 --> 1
>>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')
            angles  degrees
circle           0        0
triangle         6      360
rectangle       12     1080

---->   DataFrame.mul

--------------------------------------
ID: 7844 --> 1
>>> other = pd.DataFrame({'angles': [0, 3, 4]},
...                      index=['circle', 'triangle', 'rectangle'])
>>> other
           angles
circle          0
triangle        3
rectangle       4

---->   pandas.DataFrame

--------------------------------------
ID: 7845 --> 1
>>> df.mul(other, fill_value=0)
           angles  degrees
circle          0      0.0
triangle        9      0.0
rectangle      16      0.0

---->   DataFrame.mul

--------------------------------------
ID: 7846 --> 1
>>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],
...                              'degrees': [360, 180, 360, 360, 540, 720]},
...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],
...                                    ['circle', 'triangle', 'rectangle',
...                                     'square', 'pentagon', 'hexagon']])
>>> df_multindex
             angles  degrees
A circle          0      360
  triangle        3      180
  rectangle       4      360
B square          4      360
  pentagon        5      540
  hexagon         6      720

---->   pandas.DataFrame

--------------------------------------
ID: 7847 --> 1
>>> df.div(df_multindex, level=1, fill_value=0)
             angles  degrees
A circle        NaN      1.0
  triangle      1.0      1.0
  rectangle     1.0      1.0
B square        0.0      0.0
  pentagon      0.0      0.0
  hexagon       0.0      0.0

---->   DataFrame.div

--------------------------------------
ID: 7848 --> 1
>>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})
>>> df.axes
[RangeIndex(start=0, stop=2, step=1), Index(['col1', 'col2'],
dtype='object')]

---->   pandas.DataFrame

--------------------------------------
ID: 7849 --> 1
>>> df = pd.DataFrame({'angles': [0, 3, 4],
...                    'degrees': [360, 180, 360]},
...                   index=['circle', 'triangle', 'rectangle'])
>>> df
           angles  degrees
circle          0      360
triangle        3      180
rectangle       4      360

---->   pandas.DataFrame

--------------------------------------
ID: 7850 --> 1
>>> df.add(1)
           angles  degrees
circle          1      361
triangle        4      181
rectangle       5      361

---->   DataFrame.add

--------------------------------------
ID: 7851 --> 1
>>> df.div(10)
           angles  degrees
circle        0.0     36.0
triangle      0.3     18.0
rectangle     0.4     36.0

---->   DataFrame.div

--------------------------------------
ID: 7852 --> 1
>>> df.rdiv(10)
             angles   degrees
circle          inf  0.027778
triangle   3.333333  0.055556
rectangle  2.500000  0.027778

---->   DataFrame.rdiv

--------------------------------------
ID: 7853 --> 1
>>> df.sub([1, 2], axis='columns')
           angles  degrees
circle         -1      358
triangle        2      178
rectangle       3      358

---->   DataFrame.sub

--------------------------------------
ID: 7854 --> 2
>>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),
...        axis='index')
           angles  degrees
circle         -1      359
triangle        2      179
rectangle       3      359

---->   DataFrame.sub; pandas.Series

--------------------------------------
ID: 7855 --> 1
>>> df.mul({'angles': 0, 'degrees': 2})
            angles  degrees
circle           0      720
triangle         0      360
rectangle        0      720

---->   DataFrame.mul

--------------------------------------
ID: 7856 --> 1
>>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')
            angles  degrees
circle           0        0
triangle         6      360
rectangle       12     1080

---->   DataFrame.mul

--------------------------------------
ID: 7857 --> 1
>>> other = pd.DataFrame({'angles': [0, 3, 4]},
...                      index=['circle', 'triangle', 'rectangle'])
>>> other
           angles
circle          0
triangle        3
rectangle       4

---->   pandas.DataFrame

--------------------------------------
ID: 7858 --> 1
>>> df.mul(other, fill_value=0)
           angles  degrees
circle          0      0.0
triangle        9      0.0
rectangle      16      0.0

---->   DataFrame.mul

--------------------------------------
ID: 7859 --> 1
>>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],
...                              'degrees': [360, 180, 360, 360, 540, 720]},
...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],
...                                    ['circle', 'triangle', 'rectangle',
...                                     'square', 'pentagon', 'hexagon']])
>>> df_multindex
             angles  degrees
A circle          0      360
  triangle        3      180
  rectangle       4      360
B square          4      360
  pentagon        5      540
  hexagon         6      720

---->   pandas.DataFrame

--------------------------------------
ID: 7860 --> 1
>>> df.div(df_multindex, level=1, fill_value=0)
             angles  degrees
A circle        NaN      1.0
  triangle      1.0      1.0
  rectangle     1.0      1.0
B square        0.0      0.0
  pentagon      0.0      0.0
  hexagon       0.0      0.0

---->   DataFrame.div

--------------------------------------
ID: 7861 --> 1
>>> df = pd.DataFrame({'cost': [250, 150, 100],
...                    'revenue': [100, 250, 300]},
...                   index=['A', 'B', 'C'])
>>> df
   cost  revenue
A   250      100
B   150      250
C   100      300

---->   pandas.DataFrame

--------------------------------------
ID: 7862 --> 1
>>> df.eq(100)
    cost  revenue
A  False     True
B  False    False
C   True    False

---->   DataFrame.eq

--------------------------------------
ID: 7863 --> 1
>>> df != pd.Series([100, 250], index=["cost", "revenue"])
    cost  revenue
A   True     True
B   True    False
C  False     True

---->   pandas.Series

--------------------------------------
ID: 7864 --> 2
>>> df.ne(pd.Series([100, 300], index=["A", "D"]), axis='index')
   cost  revenue
A  True    False
B  True     True
C  True     True
D  True     True

---->   DataFrame.ne; pandas.Series

--------------------------------------
ID: 7865 --> 1
>>> df.eq([250, 250, 100], axis='index')
    cost  revenue
A   True    False
B  False     True
C   True    False

---->   DataFrame.eq

--------------------------------------
ID: 7866 --> 1
>>> other = pd.DataFrame({'revenue': [300, 250, 100, 150]},
...                      index=['A', 'B', 'C', 'D'])
>>> other
   revenue
A      300
B      250
C      100
D      150

---->   pandas.DataFrame

--------------------------------------
ID: 7867 --> 1
>>> df.gt(other)
    cost  revenue
A  False    False
B  False    False
C  False     True
D  False    False

---->   DataFrame.gt

--------------------------------------
ID: 7868 --> 1
>>> df_multindex = pd.DataFrame({'cost': [250, 150, 100, 150, 300, 220],
...                              'revenue': [100, 250, 300, 200, 175, 225]},
...                             index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'],
...                                    ['A', 'B', 'C', 'A', 'B', 'C']])
>>> df_multindex
      cost  revenue
Q1 A   250      100
   B   150      250
   C   100      300
Q2 A   150      200
   B   300      175
   C   220      225

---->   pandas.DataFrame

--------------------------------------
ID: 7869 --> 1
>>> df.le(df_multindex, level=1)
       cost  revenue
Q1 A   True     True
   B   True     True
   C   True     True
Q2 A  False     True
   B   True    False
   C   True    False

---->   DataFrame.le

--------------------------------------
ID: 7870 --> 1
>>> df = pd.DataFrame({'angles': [0, 3, 4],
...                    'degrees': [360, 180, 360]},
...                   index=['circle', 'triangle', 'rectangle'])
>>> df
           angles  degrees
circle          0      360
triangle        3      180
rectangle       4      360

---->   pandas.DataFrame

--------------------------------------
ID: 7871 --> 1
>>> df.add(1)
           angles  degrees
circle          1      361
triangle        4      181
rectangle       5      361

---->   DataFrame.add

--------------------------------------
ID: 7872 --> 1
>>> df.div(10)
           angles  degrees
circle        0.0     36.0
triangle      0.3     18.0
rectangle     0.4     36.0

---->   DataFrame.div

--------------------------------------
ID: 7873 --> 1
>>> df.rdiv(10)
             angles   degrees
circle          inf  0.027778
triangle   3.333333  0.055556
rectangle  2.500000  0.027778

---->   DataFrame.rdiv

--------------------------------------
ID: 7874 --> 1
>>> df.sub([1, 2], axis='columns')
           angles  degrees
circle         -1      358
triangle        2      178
rectangle       3      358

---->   DataFrame.sub

--------------------------------------
ID: 7875 --> 2
>>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),
...        axis='index')
           angles  degrees
circle         -1      359
triangle        2      179
rectangle       3      359

---->   DataFrame.sub; pandas.Series

--------------------------------------
ID: 7876 --> 1
>>> df.mul({'angles': 0, 'degrees': 2})
            angles  degrees
circle           0      720
triangle         0      360
rectangle        0      720

---->   DataFrame.mul

--------------------------------------
ID: 7877 --> 1
>>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')
            angles  degrees
circle           0        0
triangle         6      360
rectangle       12     1080

---->   DataFrame.mul

--------------------------------------
ID: 7878 --> 1
>>> other = pd.DataFrame({'angles': [0, 3, 4]},
...                      index=['circle', 'triangle', 'rectangle'])
>>> other
           angles
circle          0
triangle        3
rectangle       4

---->   pandas.DataFrame

--------------------------------------
ID: 7879 --> 1
>>> df.mul(other, fill_value=0)
           angles  degrees
circle          0      0.0
triangle        9      0.0
rectangle      16      0.0

---->   DataFrame.mul

--------------------------------------
ID: 7880 --> 1
>>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],
...                              'degrees': [360, 180, 360, 360, 540, 720]},
...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],
...                                    ['circle', 'triangle', 'rectangle',
...                                     'square', 'pentagon', 'hexagon']])
>>> df_multindex
             angles  degrees
A circle          0      360
  triangle        3      180
  rectangle       4      360
B square          4      360
  pentagon        5      540
  hexagon         6      720

---->   pandas.DataFrame

--------------------------------------
ID: 7881 --> 1
>>> df.div(df_multindex, level=1, fill_value=0)
             angles  degrees
A circle        NaN      1.0
  triangle      1.0      1.0
  rectangle     1.0      1.0
B square        0.0      0.0
  pentagon      0.0      0.0
  hexagon       0.0      0.0

---->   DataFrame.div

--------------------------------------
ID: 7882 --> 2
>>> index = pd.date_range('1/1/2000', periods=4, freq='T')
>>> series = pd.Series([0.0, None, 2.0, 3.0], index=index)
>>> df = pd.DataFrame({'s': series})
>>> df
                       s
2000-01-01 00:00:00    0.0
2000-01-01 00:01:00    NaN
2000-01-01 00:02:00    2.0
2000-01-01 00:03:00    3.0

---->   pandas.Series; pandas.DataFrame

--------------------------------------
ID: 7883 --> 1
>>> df.asfreq(freq='30S')
                       s
2000-01-01 00:00:00    0.0
2000-01-01 00:00:30    NaN
2000-01-01 00:01:00    NaN
2000-01-01 00:01:30    NaN
2000-01-01 00:02:00    2.0
2000-01-01 00:02:30    NaN
2000-01-01 00:03:00    3.0

---->   DataFrame.asfreq

--------------------------------------
ID: 7884 --> 1
>>> df.asfreq(freq='30S', fill_value=9.0)
                       s
2000-01-01 00:00:00    0.0
2000-01-01 00:00:30    9.0
2000-01-01 00:01:00    NaN
2000-01-01 00:01:30    9.0
2000-01-01 00:02:00    2.0
2000-01-01 00:02:30    9.0
2000-01-01 00:03:00    3.0

---->   DataFrame.asfreq

--------------------------------------
ID: 7885 --> 1
>>> df.asfreq(freq='30S', method='bfill')
                       s
2000-01-01 00:00:00    0.0
2000-01-01 00:00:30    NaN
2000-01-01 00:01:00    NaN
2000-01-01 00:01:30    2.0
2000-01-01 00:02:00    2.0
2000-01-01 00:02:30    3.0
2000-01-01 00:03:00    3.0

---->   DataFrame.asfreq

--------------------------------------
ID: 7886 --> 1
>>> s = pd.Series([1, 2, 3, 4])
>>> s
0    1
1    2
2    3
3    4
dtype: int64

---->   pandas.Series

--------------------------------------
ID: 7887 --> 1
>>> s.add_prefix('item_')
item_0    1
item_1    2
item_2    3
item_3    4
dtype: int64

---->   Series.add_prefix

--------------------------------------
ID: 7888 --> 1
>>> df = pd.DataFrame({'A': [1, 2, 3, 4], 'B': [3, 4, 5, 6]})
>>> df
   A  B
0  1  3
1  2  4
2  3  5
3  4  6

---->   pandas.DataFrame

--------------------------------------
ID: 7889 --> 1
>>> df.add_prefix('col_')
     col_A  col_B
0       1       3
1       2       4
2       3       5
3       4       6

---->   DataFrame.add_prefix

--------------------------------------
ID: 7890 --> 1
>>> df = pd.DataFrame({"Col1": [10, 20, 15, 30, 45],
...                    "Col2": [13, 23, 18, 33, 48],
...                    "Col3": [17, 27, 22, 37, 52]},
...                   index=pd.date_range("2020-01-01", "2020-01-05"))
>>> df
            Col1  Col2  Col3
2020-01-01    10    13    17
2020-01-02    20    23    27
2020-01-03    15    18    22
2020-01-04    30    33    37
2020-01-05    45    48    52

---->   pandas.DataFrame

--------------------------------------
ID: 7891 --> 1
>>> df.shift(periods=3)
            Col1  Col2  Col3
2020-01-01   NaN   NaN   NaN
2020-01-02   NaN   NaN   NaN
2020-01-03   NaN   NaN   NaN
2020-01-04  10.0  13.0  17.0
2020-01-05  20.0  23.0  27.0

---->   DataFrame.shift

--------------------------------------
ID: 7892 --> 1
>>> df.shift(periods=1, axis="columns")
            Col1  Col2  Col3
2020-01-01   NaN    10    13
2020-01-02   NaN    20    23
2020-01-03   NaN    15    18
2020-01-04   NaN    30    33
2020-01-05   NaN    45    48

---->   DataFrame.shift

--------------------------------------
ID: 7893 --> 1
>>> df.shift(periods=3, fill_value=0)
            Col1  Col2  Col3
2020-01-01     0     0     0
2020-01-02     0     0     0
2020-01-03     0     0     0
2020-01-04    10    13    17
2020-01-05    20    23    27

---->   DataFrame.shift

--------------------------------------
ID: 7894 --> 1
>>> df.shift(periods=3, freq="D")
            Col1  Col2  Col3
2020-01-04    10    13    17
2020-01-05    20    23    27
2020-01-06    15    18    22
2020-01-07    30    33    37
2020-01-08    45    48    52

---->   DataFrame.shift

--------------------------------------
ID: 7895 --> 1
>>> df.shift(periods=3, freq="infer")
            Col1  Col2  Col3
2020-01-04    10    13    17
2020-01-05    20    23    27
2020-01-06    15    18    22
2020-01-07    30    33    37
2020-01-08    45    48    52

---->   DataFrame.shift

--------------------------------------
ID: 7896 --> 1
>>> df = pd.DataFrame({
...     'brand': ['Yum Yum', 'Yum Yum', 'Indomie', 'Indomie', 'Indomie'],
...     'style': ['cup', 'cup', 'cup', 'pack', 'pack'],
...     'rating': [4, 4, 3.5, 15, 5]
... })
>>> df
    brand style  rating
0  Yum Yum   cup     4.0
1  Yum Yum   cup     4.0
2  Indomie   cup     3.5
3  Indomie  pack    15.0
4  Indomie  pack     5.0

---->   pandas.DataFrame

--------------------------------------
ID: 7897 --> 1
>>> df.duplicated()
0    False
1     True
2    False
3    False
4    False
dtype: bool

---->   DataFrame.duplicated

--------------------------------------
ID: 7898 --> 1
>>> df.duplicated(keep='last')
0     True
1    False
2    False
3    False
4    False
dtype: bool

---->   DataFrame.duplicated

--------------------------------------
ID: 7899 --> 1
>>> df.duplicated(keep=False)
0     True
1     True
2    False
3    False
4    False
dtype: bool

---->   DataFrame.duplicated

--------------------------------------
ID: 7900 --> 1
>>> df.duplicated(subset=['brand'])
0    False
1     True
2    False
3     True
4     True
dtype: bool

---->   DataFrame.duplicated

--------------------------------------
ID: 7901 --> 2
>>> df = pd.DataFrame(np.array([[1, 1], [2, 10], [3, 100], [4, 100]]),
...                   columns=['a', 'b'])
>>> df.quantile(.1)
a    1.3
b    3.7
Name: 0.1, dtype: float64
>>> df.quantile([.1, .5])
       a     b
0.1  1.3   3.7
0.5  2.5  55.0

---->   pandas.DataFrame; DataFrame.quantile

--------------------------------------
ID: 7902 --> 1
>>> df.quantile(.1, method="table", interpolation="nearest")
a    1
b    1
Name: 0.1, dtype: int64
>>> df.quantile([.1, .5], method="table", interpolation="nearest")
     a    b
0.1  1    1
0.5  3  100

---->   DataFrame.quantile

--------------------------------------
ID: 7903 --> 2
>>> df = pd.DataFrame({'A': [1, 2],
...                    'B': [pd.Timestamp('2010'),
...                          pd.Timestamp('2011')],
...                    'C': [pd.Timedelta('1 days'),
...                          pd.Timedelta('2 days')]})
>>> df.quantile(0.5, numeric_only=False)
A                    1.5
B    2010-07-02 12:00:00
C        1 days 12:00:00
Name: 0.5, dtype: object

---->   pandas.DataFrame; DataFrame.quantile

--------------------------------------
ID: 7904 --> 2
>>> idx = pd.PeriodIndex(['2023', '2024'], freq='Y')
>>> d = {'col1': [1, 2], 'col2': [3, 4]}
>>> df1 = pd.DataFrame(data=d, index=idx)
>>> df1
      col1   col2
2023     1      3
2024     2      4

---->   pandas.PeriodIndex; pandas.DataFrame

--------------------------------------
ID: 7905 --> 1
>>> df1 = df1.to_timestamp()
>>> df1
            col1   col2
2023-01-01     1      3
2024-01-01     2      4
>>> df1.index
DatetimeIndex(['2023-01-01', '2024-01-01'], dtype='datetime64[ns]', freq=None)

---->   DataFrame.to_timestamp

--------------------------------------
ID: 7906 --> 2
>>> df2 = pd.DataFrame(data=d, index=idx)
>>> df2 = df2.to_timestamp(freq='M')
>>> df2
            col1   col2
2023-01-31     1      3
2024-01-31     2      4
>>> df2.index
DatetimeIndex(['2023-01-31', '2024-01-31'], dtype='datetime64[ns]', freq=None)

---->   pandas.DataFrame; DataFrame.to_timestamp

--------------------------------------
ID: 7907 --> 2
>>> np.random.seed(1234)
>>> df = pd.DataFrame(np.random.randn(10, 4),
...                   columns=['Col1', 'Col2', 'Col3', 'Col4'])
>>> boxplot = df.boxplot(column=['Col1', 'Col2', 'Col3'])  

---->   pandas.DataFrame; DataFrame.boxplot

--------------------------------------
ID: 7908 --> 3
>>> df = pd.DataFrame(np.random.randn(10, 2),
...                   columns=['Col1', 'Col2'])
>>> df['X'] = pd.Series(['A', 'A', 'A', 'A', 'A',
...                      'B', 'B', 'B', 'B', 'B'])
>>> boxplot = df.boxplot(by='X')

---->   pandas.DataFrame; pandas.Series; DataFrame.boxplot

--------------------------------------
ID: 7909 --> 3
>>> df = pd.DataFrame(np.random.randn(10, 3),
...                   columns=['Col1', 'Col2', 'Col3'])
>>> df['X'] = pd.Series(['A', 'A', 'A', 'A', 'A',
...                      'B', 'B', 'B', 'B', 'B'])
>>> df['Y'] = pd.Series(['A', 'B', 'A', 'B', 'A',
...                      'B', 'A', 'B', 'A', 'B'])
>>> boxplot = df.boxplot(column=['Col1', 'Col2'], by=['X', 'Y'])

---->   pandas.DataFrame; pandas.Series; DataFrame.boxplot

--------------------------------------
ID: 7910 --> 1
>>> boxplot = df.boxplot(column=['Col1', 'Col2'], by='X',
...                      layout=(2, 1))

---->   DataFrame.boxplot

--------------------------------------
ID: 7911 --> 1
>>> boxplot = df.boxplot(grid=False, rot=45, fontsize=15)  

---->   DataFrame.boxplot

--------------------------------------
ID: 7912 --> 1
>>> boxplot = df.boxplot(column=['Col1', 'Col2'], return_type='axes')
>>> type(boxplot)


---->   DataFrame.boxplot

--------------------------------------
ID: 7913 --> 1
>>> boxplot = df.boxplot(column=['Col1', 'Col2'], by='X',
...                      return_type='axes')
>>> type(boxplot)


---->   DataFrame.boxplot

--------------------------------------
ID: 7914 --> 1
>>> boxplot = df.boxplot(column=['Col1', 'Col2'], by='X',
...                      return_type=None)
>>> type(boxplot)


---->   DataFrame.boxplot

--------------------------------------
ID: 7915 --> 2
>>> s = pd.Series([1, 3, 2])
>>> s.plot.line()


---->   pandas.Series; Series.plot

--------------------------------------
ID: 7916 --> 2
>>> df = pd.DataFrame({
...    'pig': [20, 18, 489, 675, 1776],
...    'horse': [4, 25, 281, 600, 1900]
...    }, index=[1990, 1997, 2003, 2009, 2014])
>>> lines = df.plot.line()

---->   pandas.DataFrame; DataFrame.plot

--------------------------------------
ID: 7917 --> 1
>>> axes = df.plot.line(subplots=True)
>>> type(axes)


---->   DataFrame.plot

--------------------------------------
ID: 7918 --> 1
>>> axes = df.plot.line(
...     subplots=True, color={"pig": "pink", "horse": "#742802"}
... )

---->   DataFrame.plot

--------------------------------------
ID: 7919 --> 1
>>> lines = df.plot.line(x='pig', y='horse')

---->   DataFrame.plot

--------------------------------------
ID: 7920 --> 1
>>> df = pd.DataFrame({'population': [59000000, 65000000, 434000,
...                                   434000, 434000, 337000, 337000,
...                                   11300, 11300],
...                    'GDP': [1937894, 2583560 , 12011, 4520, 12128,
...                            17036, 182, 38, 311],
...                    'alpha-2': ["IT", "FR", "MT", "MV", "BN",
...                                "IS", "NR", "TV", "AI"]},
...                   index=["Italy", "France", "Malta",
...                          "Maldives", "Brunei", "Iceland",
...                          "Nauru", "Tuvalu", "Anguilla"])
>>> df
          population      GDP alpha-2
Italy       59000000  1937894      IT
France      65000000  2583560      FR
Malta         434000    12011      MT
Maldives      434000     4520      MV
Brunei        434000    12128      BN
Iceland       337000    17036      IS
Nauru         337000      182      NR
Tuvalu         11300       38      TV
Anguilla       11300      311      AI

---->   pandas.DataFrame

--------------------------------------
ID: 7921 --> 1
>>> df.nsmallest(3, 'population')
          population    GDP alpha-2
Tuvalu         11300     38      TV
Anguilla       11300    311      AI
Iceland       337000  17036      IS

---->   DataFrame.nsmallest

--------------------------------------
ID: 7922 --> 1
>>> df.nsmallest(3, 'population', keep='last')
          population  GDP alpha-2
Anguilla       11300  311      AI
Tuvalu         11300   38      TV
Nauru         337000  182      NR

---->   DataFrame.nsmallest

--------------------------------------
ID: 7923 --> 1
>>> df.nsmallest(3, 'population', keep='all')
          population    GDP alpha-2
Tuvalu         11300     38      TV
Anguilla       11300    311      AI
Iceland       337000  17036      IS
Nauru         337000    182      NR

---->   DataFrame.nsmallest

--------------------------------------
ID: 7924 --> 1
>>> df.nsmallest(3, ['population', 'GDP'])
          population  GDP alpha-2
Tuvalu         11300   38      TV
Anguilla       11300  311      AI
Nauru         337000  182      NR

---->   DataFrame.nsmallest

--------------------------------------
ID: 7925 --> 1
>>> df = pd.DataFrame(
...     [[1, 2, 3, 4], [6, 7, 8, 9]], columns=["D", "B", "E", "A"], index=[1, 2]
... )
>>> other = pd.DataFrame(
...     [[10, 20, 30, 40], [60, 70, 80, 90], [600, 700, 800, 900]],
...     columns=["A", "B", "C", "D"],
...     index=[2, 3, 4],
... )
>>> df
   D  B  E  A
1  1  2  3  4
2  6  7  8  9
>>> other
    A    B    C    D
2   10   20   30   40
3   60   70   80   90
4  600  700  800  900

---->   pandas.DataFrame

--------------------------------------
ID: 7926 --> 1
>>> left, right = df.align(other, join="outer", axis=1)
>>> left
   A  B   C  D  E
1  4  2 NaN  1  3
2  9  7 NaN  6  8
>>> right
    A    B    C    D   E
2   10   20   30   40 NaN
3   60   70   80   90 NaN
4  600  700  800  900 NaN

---->   DataFrame.align

--------------------------------------
ID: 7927 --> 1
>>> left, right = df.align(other, join="outer", axis=0)
>>> left
    D    B    E    A
1  1.0  2.0  3.0  4.0
2  6.0  7.0  8.0  9.0
3  NaN  NaN  NaN  NaN
4  NaN  NaN  NaN  NaN
>>> right
    A      B      C      D
1    NaN    NaN    NaN    NaN
2   10.0   20.0   30.0   40.0
3   60.0   70.0   80.0   90.0
4  600.0  700.0  800.0  900.0

---->   DataFrame.align

--------------------------------------
ID: 7928 --> 1
>>> left, right = df.align(other, join="outer", axis=None)
>>> left
     A    B   C    D    E
1  4.0  2.0 NaN  1.0  3.0
2  9.0  7.0 NaN  6.0  8.0
3  NaN  NaN NaN  NaN  NaN
4  NaN  NaN NaN  NaN  NaN
>>> right
       A      B      C      D   E
1    NaN    NaN    NaN    NaN NaN
2   10.0   20.0   30.0   40.0 NaN
3   60.0   70.0   80.0   90.0 NaN
4  600.0  700.0  800.0  900.0 NaN

---->   DataFrame.align

--------------------------------------
ID: 7930 --> 1
>>> (df.pipe(h)
...    .pipe(g, arg1=a)
...    .pipe(func, arg2=b, arg3=c)
... )  

---->   DataFrame.pipe

--------------------------------------
ID: 7931 --> 1
>>> (df.pipe(h)
...    .pipe(g, arg1=a)
...    .pipe((func, 'arg2'), arg1=a, arg3=c)
...  )  

---->   DataFrame.pipe

--------------------------------------
ID: 7932 --> 1
>>> df = pd.DataFrame({'angles': [0, 3, 4],
...                    'degrees': [360, 180, 360]},
...                   index=['circle', 'triangle', 'rectangle'])
>>> df
           angles  degrees
circle          0      360
triangle        3      180
rectangle       4      360

---->   pandas.DataFrame

--------------------------------------
ID: 7933 --> 1
>>> df.add(1)
           angles  degrees
circle          1      361
triangle        4      181
rectangle       5      361

---->   DataFrame.add

--------------------------------------
ID: 7934 --> 1
>>> df.div(10)
           angles  degrees
circle        0.0     36.0
triangle      0.3     18.0
rectangle     0.4     36.0

---->   DataFrame.div

--------------------------------------
ID: 7935 --> 1
>>> df.rdiv(10)
             angles   degrees
circle          inf  0.027778
triangle   3.333333  0.055556
rectangle  2.500000  0.027778

---->   DataFrame.rdiv

--------------------------------------
ID: 7936 --> 1
>>> df.sub([1, 2], axis='columns')
           angles  degrees
circle         -1      358
triangle        2      178
rectangle       3      358

---->   DataFrame.sub

--------------------------------------
ID: 7937 --> 2
>>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),
...        axis='index')
           angles  degrees
circle         -1      359
triangle        2      179
rectangle       3      359

---->   DataFrame.sub; pandas.Series

--------------------------------------
ID: 7938 --> 1
>>> df.mul({'angles': 0, 'degrees': 2})
            angles  degrees
circle           0      720
triangle         0      360
rectangle        0      720

---->   DataFrame.mul

--------------------------------------
ID: 7939 --> 1
>>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')
            angles  degrees
circle           0        0
triangle         6      360
rectangle       12     1080

---->   DataFrame.mul

--------------------------------------
ID: 7940 --> 1
>>> other = pd.DataFrame({'angles': [0, 3, 4]},
...                      index=['circle', 'triangle', 'rectangle'])
>>> other
           angles
circle          0
triangle        3
rectangle       4

---->   pandas.DataFrame

--------------------------------------
ID: 7941 --> 1
>>> df.mul(other, fill_value=0)
           angles  degrees
circle          0      0.0
triangle        9      0.0
rectangle      16      0.0

---->   DataFrame.mul

--------------------------------------
ID: 7942 --> 1
>>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],
...                              'degrees': [360, 180, 360, 360, 540, 720]},
...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],
...                                    ['circle', 'triangle', 'rectangle',
...                                     'square', 'pentagon', 'hexagon']])
>>> df_multindex
             angles  degrees
A circle          0      360
  triangle        3      180
  rectangle       4      360
B square          4      360
  pentagon        5      540
  hexagon         6      720

---->   pandas.DataFrame

--------------------------------------
ID: 7943 --> 1
>>> df.div(df_multindex, level=1, fill_value=0)
             angles  degrees
A circle        NaN      1.0
  triangle      1.0      1.0
  rectangle     1.0      1.0
B square        0.0      0.0
  pentagon      0.0      0.0
  hexagon       0.0      0.0

---->   DataFrame.div

--------------------------------------
ID: 7944 --> 1
>>> df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],
...      index=['cobra', 'viper', 'sidewinder'],
...      columns=['max_speed', 'shield'])
>>> df
            max_speed  shield
cobra               1       2
viper               4       5
sidewinder          7       8

---->   pandas.DataFrame

--------------------------------------
ID: 7945 --> 1
>>> df.loc[pd.Series([False, True, False],
...        index=['viper', 'sidewinder', 'cobra'])]
            max_speed  shield
sidewinder          7       8

---->   pandas.Series

--------------------------------------
ID: 7946 --> 1
>>> df.loc[pd.Index(["cobra", "viper"], name="foo")]
       max_speed  shield
foo
cobra          1       2
viper          4       5

---->   pandas.Index

--------------------------------------
ID: 7947 --> 1
>>> df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],
...      index=[7, 8, 9], columns=['max_speed', 'shield'])
>>> df
   max_speed  shield
7          1       2
8          4       5
9          7       8

---->   pandas.DataFrame

--------------------------------------
ID: 7948 --> 2
>>> tuples = [
...    ('cobra', 'mark i'), ('cobra', 'mark ii'),
...    ('sidewinder', 'mark i'), ('sidewinder', 'mark ii'),
...    ('viper', 'mark ii'), ('viper', 'mark iii')
... ]
>>> index = pd.MultiIndex.from_tuples(tuples)
>>> values = [[12, 2], [0, 4], [10, 20],
...         [1, 4], [7, 1], [16, 36]]
>>> df = pd.DataFrame(values, columns=['max_speed', 'shield'], index=index)
>>> df
                     max_speed  shield
cobra      mark i           12       2
           mark ii           0       4
sidewinder mark i           10      20
           mark ii           1       4
viper      mark ii           7       1
           mark iii         16      36

---->   pandas.MultiIndex; pandas.DataFrame

--------------------------------------
ID: 7955 --> 2
>>> df = pd.DataFrame({'lab': ['A', 'B', 'C'], 'val': [10, 30, 20]})
>>> ax = df.plot.barh(x='lab', y='val')

---->   pandas.DataFrame; DataFrame.plot

--------------------------------------
ID: 7956 --> 2
>>> speed = [0.1, 17.5, 40, 48, 52, 69, 88]
>>> lifespan = [2, 8, 70, 1.5, 25, 12, 28]
>>> index = ['snail', 'pig', 'elephant',
...          'rabbit', 'giraffe', 'coyote', 'horse']
>>> df = pd.DataFrame({'speed': speed,
...                    'lifespan': lifespan}, index=index)
>>> ax = df.plot.barh()

---->   pandas.DataFrame; DataFrame.plot

--------------------------------------
ID: 7957 --> 1
>>> ax = df.plot.barh(stacked=True)

---->   DataFrame.plot

--------------------------------------
ID: 7958 --> 1
>>> ax = df.plot.barh(color={"speed": "red", "lifespan": "green"})

---->   DataFrame.plot

--------------------------------------
ID: 7959 --> 2
>>> speed = [0.1, 17.5, 40, 48, 52, 69, 88]
>>> lifespan = [2, 8, 70, 1.5, 25, 12, 28]
>>> index = ['snail', 'pig', 'elephant',
...          'rabbit', 'giraffe', 'coyote', 'horse']
>>> df = pd.DataFrame({'speed': speed,
...                    'lifespan': lifespan}, index=index)
>>> ax = df.plot.barh(y='speed')

---->   pandas.DataFrame; DataFrame.plot

--------------------------------------
ID: 7960 --> 2
>>> speed = [0.1, 17.5, 40, 48, 52, 69, 88]
>>> lifespan = [2, 8, 70, 1.5, 25, 12, 28]
>>> index = ['snail', 'pig', 'elephant',
...          'rabbit', 'giraffe', 'coyote', 'horse']
>>> df = pd.DataFrame({'speed': speed,
...                    'lifespan': lifespan}, index=index)
>>> ax = df.plot.barh(x='lifespan')

---->   pandas.DataFrame; DataFrame.plot

--------------------------------------
ID: 7961 --> 1
>>> df = pd.DataFrame({'A': {0: 'a', 1: 'b', 2: 'c'},
...                    'B': {0: 1, 1: 3, 2: 5},
...                    'C': {0: 2, 1: 4, 2: 6}})
>>> df
   A  B  C
0  a  1  2
1  b  3  4
2  c  5  6

---->   pandas.DataFrame

--------------------------------------
ID: 7962 --> 1
>>> df.melt(id_vars=['A'], value_vars=['B'])
   A variable  value
0  a        B      1
1  b        B      3
2  c        B      5

---->   DataFrame.melt

--------------------------------------
ID: 7963 --> 1
>>> df.melt(id_vars=['A'], value_vars=['B', 'C'])
   A variable  value
0  a        B      1
1  b        B      3
2  c        B      5
3  a        C      2
4  b        C      4
5  c        C      6

---->   DataFrame.melt

--------------------------------------
ID: 7964 --> 1
>>> df.melt(id_vars=['A'], value_vars=['B'],
...         var_name='myVarname', value_name='myValname')
   A myVarname  myValname
0  a         B          1
1  b         B          3
2  c         B          5

---->   DataFrame.melt

--------------------------------------
ID: 7965 --> 1
>>> df.melt(id_vars=['A'], value_vars=['B', 'C'], ignore_index=False)
   A variable  value
0  a        B      1
1  b        B      3
2  c        B      5
0  a        C      2
1  b        C      4
2  c        C      6

---->   DataFrame.melt

--------------------------------------
ID: 7967 --> 1
>>> df.melt(col_level=0, id_vars=['A'], value_vars=['B'])
   A variable  value
0  a        B      1
1  b        B      3
2  c        B      5

---->   DataFrame.melt

--------------------------------------
ID: 7968 --> 1
>>> df.melt(id_vars=[('A', 'D')], value_vars=[('B', 'E')])
  (A, D) variable_0 variable_1  value
0      a          B          E      1
1      b          B          E      3
2      c          B          E      5

---->   DataFrame.melt

--------------------------------------
ID: 7969 --> 2
>>> d = {'col1': [1, 2, 3], 'col2': [4, 5, 6]}
>>> df = pd.DataFrame(d)
>>> print(df.to_string())
   col1  col2
0     1     4
1     2     5
2     3     6

---->   pandas.DataFrame; DataFrame.to_string

--------------------------------------
ID: 7970 --> 1
>>> df = pd.DataFrame([[4, 9]] * 3, columns=['A', 'B'])
>>> df
   A  B
0  4  9
1  4  9
2  4  9

---->   pandas.DataFrame

--------------------------------------
ID: 7976 --> 1
>>> df.apply(lambda x: pd.Series([1, 2], index=['foo', 'bar']), axis=1)
   foo  bar
0    1    2
1    1    2
2    1    2

---->   pandas.Series

--------------------------------------
ID: 7978 --> 1
>>> df = pd.DataFrame({'A': range(1, 6), 'B': range(10, 0, -2)})
>>> df
   A   B
0  1  10
1  2   8
2  3   6
3  4   4
4  5   2
>>> df.eval('A + B')
0    11
1    10
2     9
3     8
4     7
dtype: int64

---->   pandas.DataFrame

--------------------------------------
ID: 7981 --> 1
>>> df = pd.DataFrame({1: [10], 2: [20]})
>>> df
    1   2
0  10  20

---->   pandas.DataFrame

--------------------------------------
ID: 7982 --> 2
>>> exactly_equal = pd.DataFrame({1: [10], 2: [20]})
>>> exactly_equal
    1   2
0  10  20
>>> df.equals(exactly_equal)
True

---->   pandas.DataFrame; DataFrame.equals

--------------------------------------
ID: 7983 --> 2
>>> different_column_type = pd.DataFrame({1.0: [10], 2.0: [20]})
>>> different_column_type
   1.0  2.0
0   10   20
>>> df.equals(different_column_type)
True

---->   pandas.DataFrame; DataFrame.equals

--------------------------------------
ID: 7984 --> 2
>>> different_data_type = pd.DataFrame({1: [10.0], 2: [20.0]})
>>> different_data_type
      1     2
0  10.0  20.0
>>> df.equals(different_data_type)
False

---->   pandas.DataFrame; DataFrame.equals

--------------------------------------
ID: 7985 --> 1
>>> df = pd.DataFrame({'person_id': [0, 1, 2, 3],
...                    'age': [21, 25, 62, 43],
...                    'height': [1.61, 1.87, 1.49, 2.01]}
...                   ).set_index('person_id')
>>> df
           age  height
person_id
0           21    1.61
1           25    1.87
2           62    1.49
3           43    2.01

---->   pandas.DataFrame

--------------------------------------
ID: 7986 --> 1
>>> df.std()
age       18.786076
height     0.237417
dtype: float64

---->   DataFrame.std

--------------------------------------
ID: 7987 --> 1
>>> df.std(ddof=0)
age       16.269219
height     0.205609
dtype: float64

---->   DataFrame.std

--------------------------------------
ID: 7988 --> 1
>>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]})
>>> df
     B
0  0.0
1  1.0
2  2.0
3  NaN
4  4.0

---->   pandas.DataFrame

--------------------------------------
ID: 7989 --> 1
>>> df.rolling(2).sum()
     B
0  NaN
1  1.0
2  3.0
3  NaN
4  NaN

---->   DataFrame.rolling

--------------------------------------
ID: 7990 --> 1
>>> df_time = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]},
...                        index = [pd.Timestamp('20130101 09:00:00'),
...                                 pd.Timestamp('20130101 09:00:02'),
...                                 pd.Timestamp('20130101 09:00:03'),
...                                 pd.Timestamp('20130101 09:00:05'),
...                                 pd.Timestamp('20130101 09:00:06')])

---->   pandas.DataFrame

--------------------------------------
ID: 7992 --> 1
>>> indexer = pd.api.indexers.FixedForwardWindowIndexer(window_size=2)
>>> df.rolling(window=indexer, min_periods=1).sum()
     B
0  1.0
1  3.0
2  2.0
3  4.0
4  4.0

---->   DataFrame.rolling

--------------------------------------
ID: 7993 --> 1
>>> df.rolling(2, min_periods=1).sum()
     B
0  0.0
1  1.0
2  3.0
3  2.0
4  4.0

---->   DataFrame.rolling

--------------------------------------
ID: 7994 --> 1
>>> df.rolling(3, min_periods=1, center=True).sum()
     B
0  1.0
1  3.0
2  3.0
3  6.0
4  4.0

---->   DataFrame.rolling

--------------------------------------
ID: 7995 --> 1
>>> df.rolling(3, min_periods=1, center=False).sum()
     B
0  0.0
1  1.0
2  3.0
3  3.0
4  6.0

---->   DataFrame.rolling

--------------------------------------
ID: 7996 --> 1
>>> df.rolling(2, min_periods=1, step=2).sum()
     B
0  0.0
2  3.0
4  4.0

---->   DataFrame.rolling

--------------------------------------
ID: 7997 --> 1
>>> df.rolling(2, win_type='gaussian').sum(std=3)
          B
0       NaN
1  0.986207
2  2.958621
3       NaN
4       NaN

---->   DataFrame.rolling

--------------------------------------
ID: 7998 --> 2
>>> df = pd.DataFrame({
...     'A': [pd.to_datetime('2020-01-01'),
...           pd.to_datetime('2020-01-01'),
...           pd.to_datetime('2020-01-02'),],
...     'B': [1, 2, 3], },
...     index=pd.date_range('2020', periods=3))

---->   pandas.DataFrame; pandas.to_datetime

--------------------------------------
ID: 7999 --> 1
>>> df.rolling('2D', on='A').sum()
                    A    B
2020-01-01 2020-01-01  1.0
2020-01-02 2020-01-01  3.0
2020-01-03 2020-01-02  6.0

---->   DataFrame.rolling

--------------------------------------
ID: 8000 --> 1
>>> df = pd.DataFrame([[1, 2.12], [3.356, 4.567]])
>>> df
       0      1
0  1.000  2.120
1  3.356  4.567

---->   pandas.DataFrame

--------------------------------------
ID: 8001 --> 1
>>> df.applymap(lambda x: len(str(x)))
   0  1
0  3  4
1  5  5

---->   DataFrame.applymap

--------------------------------------
ID: 8002 --> 1
>>> df_copy = df.copy()
>>> df_copy.iloc[0, 0] = pd.NA
>>> df_copy.applymap(lambda x: len(str(x)), na_action='ignore')
     0  1
0  NaN  4
1  5.0  5

---->   DataFrame.copy

--------------------------------------
ID: 8003 --> 1
>>> df.applymap(lambda x: x**2)
           0          1
0   1.000000   4.494400
1  11.262736  20.857489

---->   DataFrame.applymap

--------------------------------------
ID: 8004 --> 1
>>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]})
>>> df
     B
0  0.0
1  1.0
2  2.0
3  NaN
4  4.0

---->   pandas.DataFrame

--------------------------------------
ID: 8005 --> 1
>>> df.ewm(com=0.5).mean()
          B
0  0.000000
1  0.750000
2  1.615385
3  1.615385
4  3.670213
>>> df.ewm(alpha=2 / 3).mean()
          B
0  0.000000
1  0.750000
2  1.615385
3  1.615385
4  3.670213

---->   DataFrame.ewm

--------------------------------------
ID: 8006 --> 1
>>> df.ewm(com=0.5, adjust=True).mean()
          B
0  0.000000
1  0.750000
2  1.615385
3  1.615385
4  3.670213
>>> df.ewm(com=0.5, adjust=False).mean()
          B
0  0.000000
1  0.666667
2  1.555556
3  1.555556
4  3.650794

---->   DataFrame.ewm

--------------------------------------
ID: 8007 --> 1
>>> df.ewm(com=0.5, ignore_na=True).mean()
          B
0  0.000000
1  0.750000
2  1.615385
3  1.615385
4  3.225000
>>> df.ewm(com=0.5, ignore_na=False).mean()
          B
0  0.000000
1  0.750000
2  1.615385
3  1.615385
4  3.670213

---->   DataFrame.ewm

--------------------------------------
ID: 8008 --> 2
>>> times = ['2020-01-01', '2020-01-03', '2020-01-10', '2020-01-15', '2020-01-17']
>>> df.ewm(halflife='4 days', times=pd.DatetimeIndex(times)).mean()
          B
0  0.000000
1  0.585786
2  1.523889
3  1.523889
4  3.233686

---->   DataFrame.ewm; pandas.DatetimeIndex

--------------------------------------
ID: 8009 --> 1
>>> df = pd.DataFrame(dict(age=[5, 6, np.NaN],
...                        born=[pd.NaT, pd.Timestamp('1939-05-27'),
...                              pd.Timestamp('1940-04-25')],
...                        name=['Alfred', 'Batman', ''],
...                        toy=[None, 'Batmobile', 'Joker']))
>>> df
   age       born    name        toy
0  5.0        NaT  Alfred       None
1  6.0 1939-05-27  Batman  Batmobile
2  NaN 1940-04-25              Joker

---->   pandas.DataFrame

--------------------------------------
ID: 8010 --> 1
>>> df.isna()
     age   born   name    toy
0  False   True  False   True
1  False  False  False  False
2   True  False  False  False

---->   DataFrame.isna

--------------------------------------
ID: 8011 --> 1
>>> ser = pd.Series([5, 6, np.NaN])
>>> ser
0    5.0
1    6.0
2    NaN
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 8012 --> 1
>>> ser.isna()
0    False
1    False
2     True
dtype: bool

---->   Series.isna

--------------------------------------
ID: 8013 --> 1
>>> df = pd.DataFrame({"A": pd.arrays.SparseArray([0, 1, 0])})
>>> df.sparse.to_dense()
   A
0  0
1  1
2  0

---->   pandas.DataFrame

--------------------------------------
ID: 8014 --> 1
>>> df = pd.DataFrame({"A": ["foo", "foo", "foo", "foo", "foo",
...                          "bar", "bar", "bar", "bar"],
...                    "B": ["one", "one", "one", "two", "two",
...                          "one", "one", "two", "two"],
...                    "C": ["small", "large", "large", "small",
...                          "small", "large", "small", "small",
...                          "large"],
...                    "D": [1, 2, 2, 3, 3, 4, 5, 6, 7],
...                    "E": [2, 4, 5, 5, 6, 6, 8, 9, 9]})
>>> df
     A    B      C  D  E
0  foo  one  small  1  2
1  foo  one  large  2  4
2  foo  one  large  2  5
3  foo  two  small  3  5
4  foo  two  small  3  6
5  bar  one  large  4  6
6  bar  one  small  5  8
7  bar  two  small  6  9
8  bar  two  large  7  9

---->   pandas.DataFrame

--------------------------------------
ID: 8015 --> 1
>>> table = pd.pivot_table(df, values='D', index=['A', 'B'],
...                        columns=['C'], aggfunc=np.sum)
>>> table
C        large  small
A   B
bar one    4.0    5.0
    two    7.0    6.0
foo one    4.0    1.0
    two    NaN    6.0

---->   pandas.pivot_table

--------------------------------------
ID: 8016 --> 1
>>> table = pd.pivot_table(df, values='D', index=['A', 'B'],
...                        columns=['C'], aggfunc=np.sum, fill_value=0)
>>> table
C        large  small
A   B
bar one      4      5
    two      7      6
foo one      4      1
    two      0      6

---->   pandas.pivot_table

--------------------------------------
ID: 8017 --> 1
>>> table = pd.pivot_table(df, values=['D', 'E'], index=['A', 'C'],
...                        aggfunc={'D': np.mean, 'E': np.mean})
>>> table
                D         E
A   C
bar large  5.500000  7.500000
    small  5.500000  8.500000
foo large  2.000000  4.500000
    small  2.333333  4.333333

---->   pandas.pivot_table

--------------------------------------
ID: 8018 --> 1
>>> table = pd.pivot_table(df, values=['D', 'E'], index=['A', 'C'],
...                        aggfunc={'D': np.mean,
...                                 'E': [min, max, np.mean]})
>>> table
                  D   E
               mean max      mean  min
A   C
bar large  5.500000   9  7.500000    6
    small  5.500000   9  8.500000    8
foo large  2.000000   5  4.500000    4
    small  2.333333   6  4.333333    2

---->   pandas.pivot_table

--------------------------------------
ID: 8019 --> 1
>>> df = pd.DataFrame({'col1': [1, 2],
...                    'col2': [0.5, 0.75]},
...                   index=['row1', 'row2'])
>>> df
      col1  col2
row1     1  0.50
row2     2  0.75
>>> df.to_dict()
{'col1': {'row1': 1, 'row2': 2}, 'col2': {'row1': 0.5, 'row2': 0.75}}

---->   pandas.DataFrame

--------------------------------------
ID: 8027 --> 1
>>> s = pd.Series([1, 2, np.nan, 4], index=[10, 20, 30, 40])
>>> s
10    1.0
20    2.0
30    NaN
40    4.0
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 8028 --> 1
>>> s.asof(20)
2.0

---->   Series.asof

--------------------------------------
ID: 8029 --> 1
>>> s.asof([5, 20])
5     NaN
20    2.0
dtype: float64

---->   Series.asof

--------------------------------------
ID: 8030 --> 1
>>> s.asof(30)
2.0

---->   Series.asof

--------------------------------------
ID: 8031 --> 3
>>> df = pd.DataFrame({'a': [10, 20, 30, 40, 50],
...                    'b': [None, None, None, None, 500]},
...                   index=pd.DatetimeIndex(['2018-02-27 09:01:00',
...                                           '2018-02-27 09:02:00',
...                                           '2018-02-27 09:03:00',
...                                           '2018-02-27 09:04:00',
...                                           '2018-02-27 09:05:00']))
>>> df.asof(pd.DatetimeIndex(['2018-02-27 09:03:30',
...                           '2018-02-27 09:04:30']))
                      a   b
2018-02-27 09:03:30 NaN NaN
2018-02-27 09:04:30 NaN NaN

---->   pandas.DataFrame; pandas.DatetimeIndex; DataFrame.asof

--------------------------------------
ID: 8032 --> 2
>>> df.asof(pd.DatetimeIndex(['2018-02-27 09:03:30',
...                           '2018-02-27 09:04:30']),
...         subset=['a'])
                      a   b
2018-02-27 09:03:30  30 NaN
2018-02-27 09:04:30  40 NaN

---->   DataFrame.asof; pandas.DatetimeIndex

--------------------------------------
ID: 8033 --> 1
>>> s = pd.Series(range(5))
>>> s.where(s > 0)
0    NaN
1    1.0
2    2.0
3    3.0
4    4.0
dtype: float64
>>> s.mask(s > 0)
0    0.0
1    NaN
2    NaN
3    NaN
4    NaN
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 8034 --> 1
>>> s = pd.Series(range(5))
>>> t = pd.Series([True, False])
>>> s.where(t, 99)
0     0
1    99
2    99
3    99
4    99
dtype: int64
>>> s.mask(t, 99)
0    99
1     1
2    99
3    99
4    99
dtype: int64

---->   pandas.Series

--------------------------------------
ID: 8036 --> 1
>>> df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=['A', 'B'])
>>> df
   A  B
0  0  1
1  2  3
2  4  5
3  6  7
4  8  9
>>> m = df % 3 == 0
>>> df.where(m, -df)
   A  B
0  0 -1
1 -2  3
2 -4 -5
3  6 -7
4 -8  9
>>> df.where(m, -df) == np.where(m, df, -df)
      A     B
0  True  True
1  True  True
2  True  True
3  True  True
4  True  True
>>> df.where(m, -df) == df.mask(~m, -df)
      A     B
0  True  True
1  True  True
2  True  True
3  True  True
4  True  True

---->   pandas.DataFrame

--------------------------------------
ID: 8037 --> 4
>>> df1 = pd.DataFrame({'A': [0, 0], 'B': [4, 4]})
>>> df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})
>>> take_smaller = lambda s1, s2: s1 if s1.sum() < s2.sum() else s2
>>> df1.combine(df2, take_smaller)
   A  B
0  0  3
1  0  3

---->   pandas.DataFrame; Series.sum; Series.sum; DataFrame.combine

--------------------------------------
ID: 8038 --> 2
>>> df1 = pd.DataFrame({'A': [5, 0], 'B': [2, 4]})
>>> df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})
>>> df1.combine(df2, np.minimum)
   A  B
0  1  2
1  0  3

---->   pandas.DataFrame; DataFrame.combine

--------------------------------------
ID: 8039 --> 2
>>> df1 = pd.DataFrame({'A': [0, 0], 'B': [None, 4]})
>>> df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})
>>> df1.combine(df2, take_smaller, fill_value=-5)
   A    B
0  0 -5.0
1  0  4.0

---->   pandas.DataFrame; DataFrame.combine

--------------------------------------
ID: 8040 --> 2
>>> df1 = pd.DataFrame({'A': [0, 0], 'B': [None, 4]})
>>> df2 = pd.DataFrame({'A': [1, 1], 'B': [None, 3]})
>>> df1.combine(df2, take_smaller, fill_value=-5)
    A    B
0  0 -5.0
1  0  3.0

---->   pandas.DataFrame; DataFrame.combine

--------------------------------------
ID: 8041 --> 2
>>> df1 = pd.DataFrame({'A': [0, 0], 'B': [4, 4]})
>>> df2 = pd.DataFrame({'B': [3, 3], 'C': [-10, 1], }, index=[1, 2])
>>> df1.combine(df2, take_smaller)
     A    B     C
0  NaN  NaN   NaN
1  NaN  3.0 -10.0
2  NaN  3.0   1.0

---->   pandas.DataFrame; DataFrame.combine

--------------------------------------
ID: 8042 --> 1
>>> df1.combine(df2, take_smaller, overwrite=False)
     A    B     C
0  0.0  NaN   NaN
1  0.0  3.0 -10.0
2  NaN  3.0   1.0

---->   DataFrame.combine

--------------------------------------
ID: 8043 --> 2
>>> df2 = pd.DataFrame({'B': [3, 3], 'C': [1, 1], }, index=[1, 2])
>>> df2.combine(df1, take_smaller)
   A    B   C
0  0.0  NaN NaN
1  0.0  3.0 NaN
2  NaN  3.0 NaN

---->   pandas.DataFrame; DataFrame.combine

--------------------------------------
ID: 8044 --> 1
>>> df2.combine(df1, take_smaller, overwrite=False)
     A    B   C
0  0.0  NaN NaN
1  0.0  3.0 1.0
2  NaN  3.0 1.0

---->   DataFrame.combine

--------------------------------------
ID: 8045 --> 1
>>> df = pd.DataFrame({'angles': [0, 3, 4],
...                    'degrees': [360, 180, 360]},
...                   index=['circle', 'triangle', 'rectangle'])
>>> df
           angles  degrees
circle          0      360
triangle        3      180
rectangle       4      360

---->   pandas.DataFrame

--------------------------------------
ID: 8046 --> 1
>>> df.add(1)
           angles  degrees
circle          1      361
triangle        4      181
rectangle       5      361

---->   DataFrame.add

--------------------------------------
ID: 8047 --> 1
>>> df.div(10)
           angles  degrees
circle        0.0     36.0
triangle      0.3     18.0
rectangle     0.4     36.0

---->   DataFrame.div

--------------------------------------
ID: 8048 --> 1
>>> df.rdiv(10)
             angles   degrees
circle          inf  0.027778
triangle   3.333333  0.055556
rectangle  2.500000  0.027778

---->   DataFrame.rdiv

--------------------------------------
ID: 8049 --> 1
>>> df.sub([1, 2], axis='columns')
           angles  degrees
circle         -1      358
triangle        2      178
rectangle       3      358

---->   DataFrame.sub

--------------------------------------
ID: 8050 --> 2
>>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),
...        axis='index')
           angles  degrees
circle         -1      359
triangle        2      179
rectangle       3      359

---->   DataFrame.sub; pandas.Series

--------------------------------------
ID: 8051 --> 1
>>> df.mul({'angles': 0, 'degrees': 2})
            angles  degrees
circle           0      720
triangle         0      360
rectangle        0      720

---->   DataFrame.mul

--------------------------------------
ID: 8052 --> 1
>>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')
            angles  degrees
circle           0        0
triangle         6      360
rectangle       12     1080

---->   DataFrame.mul

--------------------------------------
ID: 8053 --> 1
>>> other = pd.DataFrame({'angles': [0, 3, 4]},
...                      index=['circle', 'triangle', 'rectangle'])
>>> other
           angles
circle          0
triangle        3
rectangle       4

---->   pandas.DataFrame

--------------------------------------
ID: 8054 --> 1
>>> df.mul(other, fill_value=0)
           angles  degrees
circle          0      0.0
triangle        9      0.0
rectangle      16      0.0

---->   DataFrame.mul

--------------------------------------
ID: 8055 --> 1
>>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],
...                              'degrees': [360, 180, 360, 360, 540, 720]},
...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],
...                                    ['circle', 'triangle', 'rectangle',
...                                     'square', 'pentagon', 'hexagon']])
>>> df_multindex
             angles  degrees
A circle          0      360
  triangle        3      180
  rectangle       4      360
B square          4      360
  pentagon        5      540
  hexagon         6      720

---->   pandas.DataFrame

--------------------------------------
ID: 8056 --> 1
>>> df.div(df_multindex, level=1, fill_value=0)
             angles  degrees
A circle        NaN      1.0
  triangle      1.0      1.0
  rectangle     1.0      1.0
B square        0.0      0.0
  pentagon      0.0      0.0
  hexagon       0.0      0.0

---->   DataFrame.div

--------------------------------------
ID: 8057 --> 1
>>> s = pd.Series(["dog", "cat", "monkey"])
>>> s
0       dog
1       cat
2    monkey
dtype: object
>>> s.rename_axis("animal")
animal
0    dog
1    cat
2    monkey
dtype: object

---->   pandas.Series

--------------------------------------
ID: 8058 --> 1
>>> df = pd.DataFrame({"num_legs": [4, 4, 2],
...                    "num_arms": [0, 0, 2]},
...                   ["dog", "cat", "monkey"])
>>> df
        num_legs  num_arms
dog            4         0
cat            4         0
monkey         2         2
>>> df = df.rename_axis("animal")
>>> df
        num_legs  num_arms
animal
dog            4         0
cat            4         0
monkey         2         2
>>> df = df.rename_axis("limbs", axis="columns")
>>> df
limbs   num_legs  num_arms
animal
dog            4         0
cat            4         0
monkey         2         2

---->   pandas.DataFrame

--------------------------------------
ID: 8059 --> 1
>>> df.index = pd.MultiIndex.from_product([['mammal'],
...                                        ['dog', 'cat', 'monkey']],
...                                       names=['type', 'name'])
>>> df
limbs          num_legs  num_arms
type   name
mammal dog            4         0
       cat            4         0
       monkey         2         2

---->   pandas.MultiIndex

--------------------------------------
ID: 8062 --> 1
>>> i = pd.date_range('2018-04-09', periods=4, freq='1D20min')
>>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)
>>> ts
                     A
2018-04-09 00:00:00  1
2018-04-10 00:20:00  2
2018-04-11 00:40:00  3
2018-04-12 01:00:00  4

---->   pandas.DataFrame

--------------------------------------
ID: 8063 --> 1
>>> ts.between_time('0:15', '0:45')
                     A
2018-04-10 00:20:00  2
2018-04-11 00:40:00  3

---->   DataFrame.between_time

--------------------------------------
ID: 8064 --> 1
>>> ts.between_time('0:45', '0:15')
                     A
2018-04-09 00:00:00  1
2018-04-12 01:00:00  4

---->   DataFrame.between_time

--------------------------------------
ID: 8065 --> 1
>>> df = pd.DataFrame({"A": [1, 2, 3], "B": [4, 5, 6]})

---->   pandas.DataFrame

--------------------------------------
ID: 8068 --> 1
>>> data = {'col_0': [9, -3, 0, -1, 5], 'col_1': [-2, -7, 6, 8, -5]}
>>> df = pd.DataFrame(data)
>>> df
   col_0  col_1
0      9     -2
1     -3     -7
2      0      6
3     -1      8
4      5     -5

---->   pandas.DataFrame

--------------------------------------
ID: 8070 --> 1
>>> t = pd.Series([2, -4, -1, 6, 3])
>>> t
0    2
1   -4
2   -1
3    6
4    3
dtype: int64

---->   pandas.Series

--------------------------------------
ID: 8072 --> 1
>>> t = pd.Series([2, -4, np.NaN, 6, 3])
>>> t
0    2.0
1   -4.0
2    NaN
3    6.0
4    3.0
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 8074 --> 2
>>> df = pd.DataFrame([[1, 1.5]], columns=['int', 'float'])
>>> row = next(df.iterrows())[1]
>>> row
int      1.0
float    1.5
Name: 0, dtype: float64
>>> print(row['int'].dtype)
float64
>>> print(df['int'].dtype)
int64

---->   pandas.DataFrame; DataFrame.iterrows

--------------------------------------
ID: 8075 --> 1
>>> df = pd.DataFrame([('falcon', 'bird', 389.0, 2),
...                    ('parrot', 'bird', 24.0, 2),
...                    ('lion', 'mammal', 80.5, 4),
...                    ('monkey', 'mammal', np.nan, 4)],
...                   columns=['name', 'class', 'max_speed',
...                            'num_legs'])
>>> df
     name   class  max_speed  num_legs
0  falcon    bird      389.0         2
1  parrot    bird       24.0         2
2    lion  mammal       80.5         4
3  monkey  mammal        NaN         4

---->   pandas.DataFrame

--------------------------------------
ID: 8076 --> 1
>>> df.to_xarray()

Dimensions:    (index: 4)
Coordinates:
  * index      (index) int64 0 1 2 3
Data variables:
    name       (index) object 'falcon' 'parrot' 'lion' 'monkey'
    class      (index) object 'bird' 'bird' 'mammal' 'mammal'
    max_speed  (index) float64 389.0 24.0 80.5 nan
    num_legs   (index) int64 2 2 4 4

---->   DataFrame.to_xarray

--------------------------------------
ID: 8078 --> 2
>>> dates = pd.to_datetime(['2018-01-01', '2018-01-01',
...                         '2018-01-02', '2018-01-02'])
>>> df_multiindex = pd.DataFrame({'date': dates,
...                               'animal': ['falcon', 'parrot',
...                                          'falcon', 'parrot'],
...                               'speed': [350, 18, 361, 15]})
>>> df_multiindex = df_multiindex.set_index(['date', 'animal'])

---->   pandas.to_datetime; pandas.DataFrame

--------------------------------------
ID: 8080 --> 1
>>> df = pd.DataFrame([('falcon', 'bird', 389.0),
...                    ('parrot', 'bird', 24.0),
...                    ('lion', 'mammal', 80.5),
...                    ('monkey', 'mammal', np.nan)],
...                   columns=('name', 'class', 'max_speed'))
>>> df
     name   class  max_speed
0  falcon    bird      389.0
1  parrot    bird       24.0
2    lion  mammal       80.5
3  monkey  mammal        NaN

---->   pandas.DataFrame

--------------------------------------
ID: 8081 --> 1
>>> df.pop('class')
0      bird
1      bird
2    mammal
3    mammal
Name: class, dtype: object

---->   DataFrame.pop

--------------------------------------
ID: 8082 --> 1
>>> df = pd.DataFrame({'height': [1.5, 2.6], 'weight': [500, 800]},
...                   index=['elk', 'moose'])
>>> df
       height  weight
elk       1.5     500
moose     2.6     800

---->   pandas.DataFrame

--------------------------------------
ID: 8083 --> 1
>>> s1 = pd.Series([0.5, 1.5], index=['weight', 'height'])
>>> df[['height', 'weight']] + s1
       height  weight
elk       3.0   500.5
moose     4.1   800.5

---->   pandas.Series

--------------------------------------
ID: 8084 --> 1
>>> s2 = pd.Series([0.5, 1.5], index=['elk', 'moose'])
>>> df[['height', 'weight']] + s2
       elk  height  moose  weight
elk    NaN     NaN    NaN     NaN
moose  NaN     NaN    NaN     NaN

---->   pandas.Series

--------------------------------------
ID: 8086 --> 1
>>> other = pd.DataFrame({'height': [0.2, 0.4, 0.6]},
...                      index=['elk', 'moose', 'deer'])
>>> df[['height', 'weight']] + other
       height  weight
deer      NaN     NaN
elk       1.7     NaN
moose     3.0     NaN

---->   pandas.DataFrame

--------------------------------------
ID: 8087 --> 1
>>> df = pd.DataFrame(
...     {
...         "col1": ["a", "a", "b", "b", "a"],
...         "col2": [1.0, 2.0, 3.0, np.nan, 5.0],
...         "col3": [1.0, 2.0, 3.0, 4.0, 5.0]
...     },
...     columns=["col1", "col2", "col3"],
... )
>>> df
  col1  col2  col3
0    a   1.0   1.0
1    a   2.0   2.0
2    b   3.0   3.0
3    b   NaN   4.0
4    a   5.0   5.0

---->   pandas.DataFrame

--------------------------------------
ID: 8088 --> 1
>>> df2 = df.copy()
>>> df2.loc[0, 'col1'] = 'c'
>>> df2.loc[2, 'col3'] = 4.0
>>> df2
  col1  col2  col3
0    c   1.0   1.0
1    a   2.0   2.0
2    b   3.0   4.0
3    b   NaN   4.0
4    a   5.0   5.0

---->   DataFrame.copy

--------------------------------------
ID: 8095 --> 1
>>> d = {'col1': [1, 2], 'col2': [3, 4]}
>>> df = pd.DataFrame(data=d)
>>> df
   col1  col2
0     1     3
1     2     4

---->   pandas.DataFrame

--------------------------------------
ID: 8096 --> 1
>>> df = pd.DataFrame(data=d, dtype=np.int8)
>>> df.dtypes
col1    int8
col2    int8
dtype: object

---->   pandas.DataFrame

--------------------------------------
ID: 8097 --> 2
>>> d = {'col1': [0, 1, 2, 3], 'col2': pd.Series([2, 3], index=[2, 3])}
>>> pd.DataFrame(data=d, index=[0, 1, 2, 3])
   col1  col2
0     0   NaN
1     1   NaN
2     2   2.0
3     3   3.0

---->   pandas.Series; pandas.DataFrame

--------------------------------------
ID: 8098 --> 1
>>> df2 = pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]),
...                    columns=['a', 'b', 'c'])
>>> df2
   a  b  c
0  1  2  3
1  4  5  6
2  7  8  9

---->   pandas.DataFrame

--------------------------------------
ID: 8099 --> 1
>>> data = np.array([(1, 2, 3), (4, 5, 6), (7, 8, 9)],
...                 dtype=[("a", "i4"), ("b", "i4"), ("c", "i4")])
>>> df3 = pd.DataFrame(data, columns=['c', 'a'])
...
>>> df3
   c  a
0  3  1
1  6  4
2  9  7

---->   pandas.DataFrame

--------------------------------------
ID: 8100 --> 1
>>> from dataclasses import make_dataclass
>>> Point = make_dataclass("Point", [("x", int), ("y", int)])
>>> pd.DataFrame([Point(0, 0), Point(0, 3), Point(2, 3)])
   x  y
0  0  0
1  0  3
2  2  3

---->   pandas.DataFrame

--------------------------------------
ID: 8101 --> 2
>>> ser = pd.Series([1, 2, 3], index=["a", "b", "c"])
>>> df = pd.DataFrame(data=ser, index=["a", "c"])
>>> df
   0
a  1
c  3

---->   pandas.Series; pandas.DataFrame

--------------------------------------
ID: 8102 --> 1
>>> df1 = pd.DataFrame([1, 2, 3], index=["a", "b", "c"], columns=["x"])
>>> df2 = pd.DataFrame(data=df1, index=["a", "c"])
>>> df2
   x
a  1
c  3

---->   pandas.DataFrame

--------------------------------------
ID: 8103 --> 1
>>> df = pd.DataFrame([[1, 2, 3],
...                    [4, 5, 6],
...                    [7, 8, 9],
...                    [np.nan, np.nan, np.nan]],
...                   columns=['A', 'B', 'C'])

---->   pandas.DataFrame

--------------------------------------
ID: 8104 --> 1
>>> df.agg(['sum', 'min'])
        A     B     C
sum  12.0  15.0  18.0
min   1.0   2.0   3.0

---->   DataFrame.agg

--------------------------------------
ID: 8105 --> 1
>>> df.agg({'A' : ['sum', 'min'], 'B' : ['min', 'max']})
        A    B
sum  12.0  NaN
min   1.0  2.0
max   NaN  8.0

---->   DataFrame.agg

--------------------------------------
ID: 8106 --> 1
>>> df.agg(x=('A', max), y=('B', 'min'), z=('C', np.mean))
     A    B    C
x  7.0  NaN  NaN
y  NaN  2.0  NaN
z  NaN  NaN  6.0

---->   DataFrame.agg

--------------------------------------
ID: 8107 --> 1
>>> df.agg("mean", axis="columns")
0    2.0
1    5.0
2    8.0
3    NaN
dtype: float64

---->   DataFrame.agg

--------------------------------------
ID: 8108 --> 1
>>> pd.Series([True]).bool()
True
>>> pd.Series([False]).bool()
False

---->   pandas.Series

--------------------------------------
ID: 8109 --> 1
>>> pd.DataFrame({'col': [True]}).bool()
True
>>> pd.DataFrame({'col': [False]}).bool()
False

---->   pandas.DataFrame

--------------------------------------
ID: 8110 --> 2
>>> index = pd.MultiIndex.from_tuples([('one', 'a'), ('one', 'b'),
...                                    ('two', 'a'), ('two', 'b')])
>>> s = pd.Series(np.arange(1.0, 5.0), index=index)
>>> s
one  a   1.0
     b   2.0
two  a   3.0
     b   4.0
dtype: float64

---->   pandas.MultiIndex; pandas.Series

--------------------------------------
ID: 8111 --> 1
>>> s.unstack(level=-1)
     a   b
one  1.0  2.0
two  3.0  4.0

---->   Series.unstack

--------------------------------------
ID: 8112 --> 1
>>> s.unstack(level=0)
   one  two
a  1.0   3.0
b  2.0   4.0

---->   Series.unstack

--------------------------------------
ID: 8113 --> 2
>>> df = s.unstack(level=0)
>>> df.unstack()
one  a  1.0
     b  2.0
two  a  3.0
     b  4.0
dtype: float64

---->   Series.unstack; DataFrame.unstack

--------------------------------------
ID: 8114 --> 1
>>> data = {
...     "class": ["Mammals", "Mammals", "Reptiles"],
...     "diet": ["Omnivore", "Carnivore", "Carnivore"],
...     "species": ["Humans", "Dogs", "Snakes"],
... }
>>> df = pd.DataFrame(data, columns=["class", "diet", "species"])
>>> df = df.set_index(["class", "diet"])
>>> df
                                  species
class      diet
Mammals    Omnivore                Humans
           Carnivore                 Dogs
Reptiles   Carnivore               Snakes

---->   pandas.DataFrame

--------------------------------------
ID: 8115 --> 1
>>> df.reorder_levels(["diet", "class"])
                                  species
diet      class
Omnivore  Mammals                  Humans
Carnivore Mammals                    Dogs
          Reptiles                 Snakes

---->   DataFrame.reorder_levels

--------------------------------------
ID: 8116 --> 1
>>> df = pd.DataFrame([('bird', 389.0),
...                    ('bird', 24.0),
...                    ('mammal', 80.5),
...                    ('mammal', np.nan)],
...                   index=['falcon', 'parrot', 'lion', 'monkey'],
...                   columns=('class', 'max_speed'))
>>> df
         class  max_speed
falcon    bird      389.0
parrot    bird       24.0
lion    mammal       80.5
monkey  mammal        NaN

---->   pandas.DataFrame

--------------------------------------
ID: 8119 --> 2
>>> index = pd.MultiIndex.from_tuples([('bird', 'falcon'),
...                                    ('bird', 'parrot'),
...                                    ('mammal', 'lion'),
...                                    ('mammal', 'monkey')],
...                                   names=['class', 'name'])
>>> columns = pd.MultiIndex.from_tuples([('speed', 'max'),
...                                      ('species', 'type')])
>>> df = pd.DataFrame([(389.0, 'fly'),
...                    (24.0, 'fly'),
...                    (80.5, 'run'),
...                    (np.nan, 'jump')],
...                   index=index,
...                   columns=columns)
>>> df
               speed species
                 max    type
class  name
bird   falcon  389.0     fly
       parrot   24.0     fly
mammal lion     80.5     run
       monkey    NaN    jump

---->   pandas.MultiIndex; pandas.DataFrame

--------------------------------------
ID: 8125 --> 2
>>> s = pd.Series([-1.10, 2, -3.33, 4])
>>> s.abs()
0    1.10
1    2.00
2    3.33
3    4.00
dtype: float64

---->   pandas.Series; Series.abs

--------------------------------------
ID: 8126 --> 2
>>> s = pd.Series([1.2 + 1j])
>>> s.abs()
0    1.56205
dtype: float64

---->   pandas.Series; Series.abs

--------------------------------------
ID: 8127 --> 2
>>> s = pd.Series([pd.Timedelta('1 days')])
>>> s.abs()
0   1 days
dtype: timedelta64[ns]

---->   pandas.Series; Series.abs

--------------------------------------
ID: 8128 --> 1
>>> df = pd.DataFrame({
...     'a': [4, 5, 6, 7],
...     'b': [10, 20, 30, 40],
...     'c': [100, 50, -30, -50]
... })
>>> df
     a    b    c
0    4   10  100
1    5   20   50
2    6   30  -30
3    7   40  -50
>>> df.loc[(df.c - 43).abs().argsort()]
     a    b    c
1    5   20   50
0    4   10  100
2    6   30  -30
3    7   40  -50

---->   pandas.DataFrame

--------------------------------------
ID: 8129 --> 2
>>> s = pd.Series([1, 2, 3])
>>> s.describe()
count    3.0
mean     2.0
std      1.0
min      1.0
25%      1.5
50%      2.0
75%      2.5
max      3.0
dtype: float64

---->   pandas.Series; Series.describe

--------------------------------------
ID: 8130 --> 2
>>> s = pd.Series(['a', 'a', 'b', 'c'])
>>> s.describe()
count     4
unique    3
top       a
freq      2
dtype: object

---->   pandas.Series; Series.describe

--------------------------------------
ID: 8131 --> 2
>>> s = pd.Series([
...     np.datetime64("2000-01-01"),
...     np.datetime64("2010-01-01"),
...     np.datetime64("2010-01-01")
... ])
>>> s.describe()
count                      3
mean     2006-09-01 08:00:00
min      2000-01-01 00:00:00
25%      2004-12-31 12:00:00
50%      2010-01-01 00:00:00
75%      2010-01-01 00:00:00
max      2010-01-01 00:00:00
dtype: object

---->   pandas.Series; Series.describe

--------------------------------------
ID: 8132 --> 3
>>> df = pd.DataFrame({'categorical': pd.Categorical(['d','e','f']),
...                    'numeric': [1, 2, 3],
...                    'object': ['a', 'b', 'c']
...                   })
>>> df.describe()
       numeric
count      3.0
mean       2.0
std        1.0
min        1.0
25%        1.5
50%        2.0
75%        2.5
max        3.0

---->   pandas.DataFrame; pandas.Categorical; DataFrame.describe

--------------------------------------
ID: 8133 --> 1
>>> df.describe(include='all')  
       categorical  numeric object
count            3      3.0      3
unique           3      NaN      3
top              f      NaN      a
freq             1      NaN      1
mean           NaN      2.0    NaN
std            NaN      1.0    NaN
min            NaN      1.0    NaN
25%            NaN      1.5    NaN
50%            NaN      2.0    NaN
75%            NaN      2.5    NaN
max            NaN      3.0    NaN

---->   DataFrame.describe

--------------------------------------
ID: 8135 --> 1
>>> df.describe(include=[np.number])
       numeric
count      3.0
mean       2.0
std        1.0
min        1.0
25%        1.5
50%        2.0
75%        2.5
max        3.0

---->   DataFrame.describe

--------------------------------------
ID: 8136 --> 1
>>> df.describe(include=[object])  
       object
count       3
unique      3
top         a
freq        1

---->   DataFrame.describe

--------------------------------------
ID: 8137 --> 1
>>> df.describe(include=['category'])
       categorical
count            3
unique           3
top              d
freq             1

---->   DataFrame.describe

--------------------------------------
ID: 8138 --> 1
>>> df.describe(exclude=[np.number])  
       categorical object
count            3      3
unique           3      3
top              f      a
freq             1      1

---->   DataFrame.describe

--------------------------------------
ID: 8139 --> 1
>>> df.describe(exclude=[object])  
       categorical  numeric
count            3      3.0
unique           3      NaN
top              f      NaN
freq             1      NaN
mean           NaN      2.0
std            NaN      1.0
min            NaN      1.0
25%            NaN      1.5
50%            NaN      2.0
75%            NaN      2.5
max            NaN      3.0

---->   DataFrame.describe

--------------------------------------
ID: 8140 --> 1
>>> d1 = {'col1': [1, 2], 'col2': [3, 4]}
>>> df1 = pd.DataFrame(data=d1)
>>> df1
   col1  col2
0     1     3
1     2     4

---->   pandas.DataFrame

--------------------------------------
ID: 8141 --> 1
>>> df1_transposed = df1.T  # or df1.transpose()
>>> df1_transposed
      0  1
col1  1  2
col2  3  4

---->   DataFrame.transpose

--------------------------------------
ID: 8142 --> 1
>>> d2 = {'name': ['Alice', 'Bob'],
...       'score': [9.5, 8],
...       'employed': [False, True],
...       'kids': [0, 0]}
>>> df2 = pd.DataFrame(data=d2)
>>> df2
    name  score  employed  kids
0  Alice    9.5     False     0
1    Bob    8.0      True     0

---->   pandas.DataFrame

--------------------------------------
ID: 8143 --> 1
>>> df2_transposed = df2.T  # or df2.transpose()
>>> df2_transposed
              0     1
name      Alice   Bob
score       9.5   8.0
employed  False  True
kids          0     0

---->   DataFrame.transpose

--------------------------------------
ID: 8144 --> 1
>>> s = pd.Series(range(5))
>>> s.where(s > 0)
0    NaN
1    1.0
2    2.0
3    3.0
4    4.0
dtype: float64
>>> s.mask(s > 0)
0    0.0
1    NaN
2    NaN
3    NaN
4    NaN
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 8145 --> 1
>>> s = pd.Series(range(5))
>>> t = pd.Series([True, False])
>>> s.where(t, 99)
0     0
1    99
2    99
3    99
4    99
dtype: int64
>>> s.mask(t, 99)
0    99
1     1
2    99
3    99
4    99
dtype: int64

---->   pandas.Series

--------------------------------------
ID: 8147 --> 1
>>> df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=['A', 'B'])
>>> df
   A  B
0  0  1
1  2  3
2  4  5
3  6  7
4  8  9
>>> m = df % 3 == 0
>>> df.where(m, -df)
   A  B
0  0 -1
1 -2  3
2 -4 -5
3  6 -7
4 -8  9
>>> df.where(m, -df) == np.where(m, df, -df)
      A     B
0  True  True
1  True  True
2  True  True
3  True  True
4  True  True
>>> df.where(m, -df) == df.mask(~m, -df)
      A     B
0  True  True
1  True  True
2  True  True
3  True  True
4  True  True

---->   pandas.DataFrame

--------------------------------------
ID: 8148 --> 1
>>> s = pd.Series([1, 2, 3, 4, 5])
>>> s.replace(1, 5)
0    5
1    2
2    3
3    4
4    5
dtype: int64

---->   pandas.Series

--------------------------------------
ID: 8149 --> 1
>>> df = pd.DataFrame({'A': [0, 1, 2, 3, 4],
...                    'B': [5, 6, 7, 8, 9],
...                    'C': ['a', 'b', 'c', 'd', 'e']})
>>> df.replace(0, 5)
    A  B  C
0  5  5  a
1  1  6  b
2  2  7  c
3  3  8  d
4  4  9  e

---->   pandas.DataFrame

--------------------------------------
ID: 8156 --> 1
>>> df = pd.DataFrame({'A': ['bat', 'foo', 'bait'],
...                    'B': ['abc', 'bar', 'xyz']})
>>> df.replace(to_replace=r'^ba.$', value='new', regex=True)
        A    B
0   new  abc
1   foo  new
2  bait  xyz

---->   pandas.DataFrame

--------------------------------------
ID: 8161 --> 1
>>> s = pd.Series([10, 'a', 'a', 'b', 'a'])

---->   pandas.Series

--------------------------------------
ID: 8165 --> 1
>>> df = pd.DataFrame({'a': [1, 2, 3, 4, 5, 6],
...                    'b': [1, 1, 2, 3, 5, 8],
...                    'c': [1, 4, 9, 16, 25, 36]})
>>> df
   a  b   c
0  1  1   1
1  2  1   4
2  3  2   9
3  4  3  16
4  5  5  25
5  6  8  36

---->   pandas.DataFrame

--------------------------------------
ID: 8166 --> 1
>>> df.diff()
     a    b     c
0  NaN  NaN   NaN
1  1.0  0.0   3.0
2  1.0  1.0   5.0
3  1.0  1.0   7.0
4  1.0  2.0   9.0
5  1.0  3.0  11.0

---->   DataFrame.diff

--------------------------------------
ID: 8167 --> 1
>>> df.diff(axis=1)
    a  b   c
0 NaN  0   0
1 NaN -1   3
2 NaN -1   7
3 NaN -1  13
4 NaN  0  20
5 NaN  2  28

---->   DataFrame.diff

--------------------------------------
ID: 8168 --> 1
>>> df.diff(periods=3)
     a    b     c
0  NaN  NaN   NaN
1  NaN  NaN   NaN
2  NaN  NaN   NaN
3  3.0  2.0  15.0
4  3.0  4.0  21.0
5  3.0  6.0  27.0

---->   DataFrame.diff

--------------------------------------
ID: 8169 --> 1
>>> df.diff(periods=-1)
     a    b     c
0 -1.0  0.0  -3.0
1 -1.0 -1.0  -5.0
2 -1.0 -1.0  -7.0
3 -1.0 -2.0  -9.0
4 -1.0 -3.0 -11.0
5  NaN  NaN   NaN

---->   DataFrame.diff

--------------------------------------
ID: 8170 --> 2
>>> df = pd.DataFrame({'a': [1, 0]}, dtype=np.uint8)
>>> df.diff()
       a
0    NaN
1  255.0

---->   pandas.DataFrame; DataFrame.diff

--------------------------------------
ID: 8171 --> 2
>>> dtypes = ['int64', 'float64', 'complex128', 'object', 'bool']
>>> data = dict([(t, np.ones(shape=5000, dtype=int).astype(t))
...              for t in dtypes])
>>> df = pd.DataFrame(data)
>>> df.head()
   int64  float64            complex128  object  bool
0      1      1.0              1.0+0.0j       1  True
1      1      1.0              1.0+0.0j       1  True
2      1      1.0              1.0+0.0j       1  True
3      1      1.0              1.0+0.0j       1  True
4      1      1.0              1.0+0.0j       1  True

---->   pandas.DataFrame; DataFrame.head

--------------------------------------
ID: 8172 --> 1
>>> df.memory_usage()
Index           128
int64         40000
float64       40000
complex128    80000
object        40000
bool           5000
dtype: int64

---->   DataFrame.memory_usage

--------------------------------------
ID: 8173 --> 1
>>> df.memory_usage(index=False)
int64         40000
float64       40000
complex128    80000
object        40000
bool           5000
dtype: int64

---->   DataFrame.memory_usage

--------------------------------------
ID: 8174 --> 1
>>> df.memory_usage(deep=True)
Index            128
int64          40000
float64        40000
complex128     80000
object        180000
bool            5000
dtype: int64

---->   DataFrame.memory_usage

--------------------------------------
ID: 8176 --> 1
>>> df = pd.DataFrame({'num_legs': [2, 4, 8, 0],
...                    'num_wings': [2, 0, 0, 0],
...                    'num_specimen_seen': [10, 2, 1, 8]},
...                   index=['falcon', 'dog', 'spider', 'fish'])
>>> df
        num_legs  num_wings  num_specimen_seen
falcon         2          2                 10
dog            4          0                  2
spider         8          0                  1
fish           0          0                  8

---->   pandas.DataFrame

--------------------------------------
ID: 8178 --> 1
>>> df.sample(frac=0.5, replace=True, random_state=1)
      num_legs  num_wings  num_specimen_seen
dog          4          0                  2
fish         0          0                  8

---->   DataFrame.sample

--------------------------------------
ID: 8179 --> 1
>>> df.sample(frac=2, replace=True, random_state=1)
        num_legs  num_wings  num_specimen_seen
dog            4          0                  2
fish           0          0                  8
falcon         2          2                 10
falcon         2          2                 10
fish           0          0                  8
dog            4          0                  2
fish           0          0                  8
dog            4          0                  2

---->   DataFrame.sample

--------------------------------------
ID: 8180 --> 1
>>> df.sample(n=2, weights='num_specimen_seen', random_state=1)
        num_legs  num_wings  num_specimen_seen
falcon         2          2                 10
fish           0          0                  8

---->   DataFrame.sample

--------------------------------------
ID: 8181 --> 1
>>> df = pd.DataFrame({'consumption': [10.51, 103.11, 55.48],
...                     'co2_emissions': [37.2, 19.66, 1712]},
...                   index=['Pork', 'Wheat Products', 'Beef'])

---->   pandas.DataFrame

--------------------------------------
ID: 8182 --> 1
>>> df.idxmin()
consumption                Pork
co2_emissions    Wheat Products
dtype: object

---->   DataFrame.idxmin

--------------------------------------
ID: 8183 --> 1
>>> df.idxmin(axis="columns")
Pork                consumption
Wheat Products    co2_emissions
Beef                consumption
dtype: object

---->   DataFrame.idxmin

--------------------------------------
ID: 8184 --> 2
>>> df = pd.DataFrame([[5.1, 3.5, 0], [4.9, 3.0, 0], [7.0, 3.2, 1],
...                    [6.4, 3.2, 1], [5.9, 3.0, 2]],
...                   columns=['length', 'width', 'species'])
>>> ax1 = df.plot.scatter(x='length',
...                       y='width',
...                       c='DarkBlue')

---->   pandas.DataFrame; DataFrame.plot

--------------------------------------
ID: 8185 --> 1
>>> ax2 = df.plot.scatter(x='length',
...                       y='width',
...                       c='species',
...                       colormap='viridis')

---->   DataFrame.plot

--------------------------------------
ID: 8186 --> 3
>>> df = pd.DataFrame([[0, 1, -2, -1], [1, 1, 1, 1]])
>>> s = pd.Series([1, 1, 2, 1])
>>> df.dot(s)
0    -4
1     5
dtype: int64

---->   pandas.DataFrame; pandas.Series; DataFrame.dot

--------------------------------------
ID: 8187 --> 2
>>> other = pd.DataFrame([[0, 1], [1, 2], [-1, -1], [2, 0]])
>>> df.dot(other)
    0   1
0   1   4
1   2   2

---->   pandas.DataFrame; DataFrame.dot

--------------------------------------
ID: 8188 --> 1
>>> arr = np.array([[0, 1], [1, 2], [-1, -1], [2, 0]])
>>> df.dot(arr)
    0   1
0   1   4
1   2   2

---->   DataFrame.dot

--------------------------------------
ID: 8189 --> 1
>>> s2 = s.reindex([1, 0, 2, 3])
>>> df.dot(s2)
0    -4
1     5
dtype: int64

---->   DataFrame.dot

--------------------------------------
ID: 8190 --> 2
>>> df = pd.DataFrame(
...     {
...         "a": pd.Series([1, 2, 3], dtype=np.dtype("int32")),
...         "b": pd.Series(["x", "y", "z"], dtype=np.dtype("O")),
...         "c": pd.Series([True, False, np.nan], dtype=np.dtype("O")),
...         "d": pd.Series(["h", "i", np.nan], dtype=np.dtype("O")),
...         "e": pd.Series([10, np.nan, 20], dtype=np.dtype("float")),
...         "f": pd.Series([np.nan, 100.5, 200], dtype=np.dtype("float")),
...     }
... )

---->   pandas.DataFrame; pandas.Series

--------------------------------------
ID: 8191 --> 1
>>> dfn = df.convert_dtypes()
>>> dfn
   a  b      c     d     e      f
0  1  x   True     h    10   
1  2  y  False     i    100.5
2  3  z         20  200.0

---->   DataFrame.convert_dtypes

--------------------------------------
ID: 8192 --> 1
>>> s = pd.Series(["a", "b", np.nan])
>>> s
0      a
1      b
2    NaN
dtype: object

---->   pandas.Series

--------------------------------------
ID: 8193 --> 1
>>> s.convert_dtypes()
0       a
1       b
2    
dtype: string

---->   Series.convert_dtypes

--------------------------------------
ID: 8194 --> 1
>>> df = pd.DataFrame({'angles': [0, 3, 4],
...                    'degrees': [360, 180, 360]},
...                   index=['circle', 'triangle', 'rectangle'])
>>> df
           angles  degrees
circle          0      360
triangle        3      180
rectangle       4      360

---->   pandas.DataFrame

--------------------------------------
ID: 8195 --> 1
>>> df.add(1)
           angles  degrees
circle          1      361
triangle        4      181
rectangle       5      361

---->   DataFrame.add

--------------------------------------
ID: 8196 --> 1
>>> df.div(10)
           angles  degrees
circle        0.0     36.0
triangle      0.3     18.0
rectangle     0.4     36.0

---->   DataFrame.div

--------------------------------------
ID: 8197 --> 1
>>> df.rdiv(10)
             angles   degrees
circle          inf  0.027778
triangle   3.333333  0.055556
rectangle  2.500000  0.027778

---->   DataFrame.rdiv

--------------------------------------
ID: 8198 --> 1
>>> df.sub([1, 2], axis='columns')
           angles  degrees
circle         -1      358
triangle        2      178
rectangle       3      358

---->   DataFrame.sub

--------------------------------------
ID: 8199 --> 2
>>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),
...        axis='index')
           angles  degrees
circle         -1      359
triangle        2      179
rectangle       3      359

---->   DataFrame.sub; pandas.Series

--------------------------------------
ID: 8200 --> 1
>>> df.mul({'angles': 0, 'degrees': 2})
            angles  degrees
circle           0      720
triangle         0      360
rectangle        0      720

---->   DataFrame.mul

--------------------------------------
ID: 8201 --> 1
>>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')
            angles  degrees
circle           0        0
triangle         6      360
rectangle       12     1080

---->   DataFrame.mul

--------------------------------------
ID: 8202 --> 1
>>> other = pd.DataFrame({'angles': [0, 3, 4]},
...                      index=['circle', 'triangle', 'rectangle'])
>>> other
           angles
circle          0
triangle        3
rectangle       4

---->   pandas.DataFrame

--------------------------------------
ID: 8203 --> 1
>>> df.mul(other, fill_value=0)
           angles  degrees
circle          0      0.0
triangle        9      0.0
rectangle      16      0.0

---->   DataFrame.mul

--------------------------------------
ID: 8204 --> 1
>>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],
...                              'degrees': [360, 180, 360, 360, 540, 720]},
...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],
...                                    ['circle', 'triangle', 'rectangle',
...                                     'square', 'pentagon', 'hexagon']])
>>> df_multindex
             angles  degrees
A circle          0      360
  triangle        3      180
  rectangle       4      360
B square          4      360
  pentagon        5      540
  hexagon         6      720

---->   pandas.DataFrame

--------------------------------------
ID: 8205 --> 1
>>> df.div(df_multindex, level=1, fill_value=0)
             angles  degrees
A circle        NaN      1.0
  triangle      1.0      1.0
  rectangle     1.0      1.0
B square        0.0      0.0
  pentagon      0.0      0.0
  hexagon       0.0      0.0

---->   DataFrame.div

--------------------------------------
ID: 8206 --> 1
>>> s = pd.Series([1, 2], index=["a", "b"])
>>> s
a    1
b    2
dtype: int64

---->   pandas.Series

--------------------------------------
ID: 8207 --> 1
>>> s_copy = s.copy()
>>> s_copy
a    1
b    2
dtype: int64

---->   Series.copy

--------------------------------------
ID: 8208 --> 2
>>> s = pd.Series([1, 2], index=["a", "b"])
>>> deep = s.copy()
>>> shallow = s.copy(deep=False)

---->   pandas.Series; Series.copy

--------------------------------------
ID: 8209 --> 2
>>> s = pd.Series([[1, 2], [3, 4]])
>>> deep = s.copy()
>>> s[0][0] = 10
>>> s
0    [10, 2]
1     [3, 4]
dtype: object
>>> deep
0    [10, 2]
1     [3, 4]
dtype: object

---->   pandas.Series; Series.copy

--------------------------------------
ID: 8210 --> 1
>>> d = {'col1': [1, 2], 'col2': [3, 4]}
>>> df = pd.DataFrame(data=d)
>>> df.dtypes
col1    int64
col2    int64
dtype: object

---->   pandas.DataFrame

--------------------------------------
ID: 8211 --> 1
>>> df.astype('int32').dtypes
col1    int32
col2    int32
dtype: object

---->   DataFrame.astype

--------------------------------------
ID: 8212 --> 1
>>> df.astype({'col1': 'int32'}).dtypes
col1    int32
col2    int64
dtype: object

---->   DataFrame.astype

--------------------------------------
ID: 8213 --> 2
>>> ser = pd.Series([1, 2], dtype='int32')
>>> ser
0    1
1    2
dtype: int32
>>> ser.astype('int64')
0    1
1    2
dtype: int64

---->   pandas.Series; Series.astype

--------------------------------------
ID: 8214 --> 1
>>> ser.astype('category')
0    1
1    2
dtype: category
Categories (2, int32): [1, 2]

---->   Series.astype

--------------------------------------
ID: 8215 --> 1
>>> from pandas.api.types import CategoricalDtype
>>> cat_dtype = CategoricalDtype(
...     categories=[2, 1], ordered=True)
>>> ser.astype(cat_dtype)
0    1
1    2
dtype: category
Categories (2, int64): [2 < 1]

---->   Series.astype

--------------------------------------
ID: 8216 --> 1
>>> ser_date = pd.Series(pd.date_range('20200101', periods=3))
>>> ser_date
0   2020-01-01
1   2020-01-02
2   2020-01-03
dtype: datetime64[ns]

---->   pandas.Series

--------------------------------------
ID: 8217 --> 2
>>> idx = pd.MultiIndex.from_arrays([
...     ['warm', 'warm', 'cold', 'cold'],
...     ['dog', 'falcon', 'fish', 'spider']],
...     names=['blooded', 'animal'])
>>> s = pd.Series([4, 2, 0, 8], name='legs', index=idx)
>>> s
blooded  animal
warm     dog       4
         falcon    2
cold     fish      0
         spider    8
Name: legs, dtype: int64

---->   pandas.MultiIndex; pandas.Series

--------------------------------------
ID: 8218 --> 1
>>> s.sum()
14

---->   Series.sum

--------------------------------------
ID: 8219 --> 1
>>> pd.Series([], dtype="float64").sum()  # min_count=0 is the default
0.0

---->   pandas.Series

--------------------------------------
ID: 8220 --> 1
>>> pd.Series([], dtype="float64").sum(min_count=1)
nan

---->   pandas.Series

--------------------------------------
ID: 8221 --> 1
>>> pd.Series([np.nan]).sum()
0.0

---->   pandas.Series

--------------------------------------
ID: 8222 --> 1
>>> pd.Series([np.nan]).sum(min_count=1)
nan

---->   pandas.Series

--------------------------------------
ID: 8223 --> 1
>>> df = pd.DataFrame({'num_legs': [2, 4, 4, 6],
...                    'num_wings': [2, 0, 0, 0]},
...                   index=['falcon', 'dog', 'cat', 'ant'])
>>> df
        num_legs  num_wings
falcon         2          2
dog            4          0
cat            4          0
ant            6          0

---->   pandas.DataFrame

--------------------------------------
ID: 8224 --> 1
>>> df.value_counts()
num_legs  num_wings
4         0            2
2         2            1
6         0            1
Name: count, dtype: int64

---->   DataFrame.value_counts

--------------------------------------
ID: 8225 --> 1
>>> df.value_counts(sort=False)
num_legs  num_wings
2         2            1
4         0            2
6         0            1
Name: count, dtype: int64

---->   DataFrame.value_counts

--------------------------------------
ID: 8226 --> 1
>>> df.value_counts(ascending=True)
num_legs  num_wings
2         2            1
6         0            1
4         0            2
Name: count, dtype: int64

---->   DataFrame.value_counts

--------------------------------------
ID: 8227 --> 1
>>> df.value_counts(normalize=True)
num_legs  num_wings
4         0            0.50
2         2            0.25
6         0            0.25
Name: proportion, dtype: float64

---->   DataFrame.value_counts

--------------------------------------
ID: 8228 --> 1
>>> df = pd.DataFrame({'first_name': ['John', 'Anne', 'John', 'Beth'],
...                    'middle_name': ['Smith', pd.NA, pd.NA, 'Louise']})
>>> df
  first_name middle_name
0       John       Smith
1       Anne        
2       John        
3       Beth      Louise

---->   pandas.DataFrame

--------------------------------------
ID: 8229 --> 1
>>> df.value_counts()
first_name  middle_name
Beth        Louise         1
John        Smith          1
Name: count, dtype: int64

---->   DataFrame.value_counts

--------------------------------------
ID: 8230 --> 1
>>> df.value_counts(dropna=False)
first_name  middle_name
Anne        NaN            1
Beth        Louise         1
John        Smith          1
            NaN            1
Name: count, dtype: int64

---->   DataFrame.value_counts

--------------------------------------
ID: 8231 --> 1
>>> df.value_counts("first_name")
first_name
John    2
Anne    1
Beth    1
Name: count, dtype: int64

---->   DataFrame.value_counts

--------------------------------------
ID: 8232 --> 2
>>> idx = pd.MultiIndex.from_arrays([
...     ['warm', 'warm', 'cold', 'cold'],
...     ['dog', 'falcon', 'fish', 'spider']],
...     names=['blooded', 'animal'])
>>> s = pd.Series([4, 2, 0, 8], name='legs', index=idx)
>>> s
blooded  animal
warm     dog       4
         falcon    2
cold     fish      0
         spider    8
Name: legs, dtype: int64

---->   pandas.MultiIndex; pandas.Series

--------------------------------------
ID: 8233 --> 1
>>> s.min()
0

---->   Series.min

--------------------------------------
ID: 8234 --> 2
>>> df = pd.DataFrame([(1, 2), (0, 3), (2, 0), (1, 1)],
...                   columns=['dogs', 'cats'])
>>> df.cov()
          dogs      cats
dogs  0.666667 -1.000000
cats -1.000000  1.666667

---->   pandas.DataFrame; DataFrame.cov

--------------------------------------
ID: 8235 --> 2
>>> np.random.seed(42)
>>> df = pd.DataFrame(np.random.randn(1000, 5),
...                   columns=['a', 'b', 'c', 'd', 'e'])
>>> df.cov()
          a         b         c         d         e
a  0.998438 -0.020161  0.059277 -0.008943  0.014144
b -0.020161  1.059352 -0.008543 -0.024738  0.009826
c  0.059277 -0.008543  1.010670 -0.001486 -0.000271
d -0.008943 -0.024738 -0.001486  0.921297 -0.013692
e  0.014144  0.009826 -0.000271 -0.013692  0.977795

---->   pandas.DataFrame; DataFrame.cov

--------------------------------------
ID: 8236 --> 2
>>> np.random.seed(42)
>>> df = pd.DataFrame(np.random.randn(20, 3),
...                   columns=['a', 'b', 'c'])
>>> df.loc[df.index[:5], 'a'] = np.nan
>>> df.loc[df.index[5:10], 'b'] = np.nan
>>> df.cov(min_periods=12)
          a         b         c
a  0.316741       NaN -0.150812
b       NaN  1.248003  0.191417
c -0.150812  0.191417  0.895202

---->   pandas.DataFrame; DataFrame.cov

--------------------------------------
ID: 8237 --> 1
>>> s = pd.Series([90, 91, 85])
>>> s
0    90
1    91
2    85
dtype: int64

---->   pandas.Series

--------------------------------------
ID: 8238 --> 1
>>> s.pct_change()
0         NaN
1    0.011111
2   -0.065934
dtype: float64

---->   Series.pct_change

--------------------------------------
ID: 8239 --> 1
>>> s.pct_change(periods=2)
0         NaN
1         NaN
2   -0.055556
dtype: float64

---->   Series.pct_change

--------------------------------------
ID: 8240 --> 1
>>> s = pd.Series([90, 91, None, 85])
>>> s
0    90.0
1    91.0
2     NaN
3    85.0
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 8241 --> 1
>>> s.pct_change(fill_method='ffill')
0         NaN
1    0.011111
2    0.000000
3   -0.065934
dtype: float64

---->   Series.pct_change

--------------------------------------
ID: 8242 --> 1
>>> df = pd.DataFrame({
...     'FR': [4.0405, 4.0963, 4.3149],
...     'GR': [1.7246, 1.7482, 1.8519],
...     'IT': [804.74, 810.01, 860.13]},
...     index=['1980-01-01', '1980-02-01', '1980-03-01'])
>>> df
                FR      GR      IT
1980-01-01  4.0405  1.7246  804.74
1980-02-01  4.0963  1.7482  810.01
1980-03-01  4.3149  1.8519  860.13

---->   pandas.DataFrame

--------------------------------------
ID: 8243 --> 1
>>> df.pct_change()
                  FR        GR        IT
1980-01-01       NaN       NaN       NaN
1980-02-01  0.013810  0.013684  0.006549
1980-03-01  0.053365  0.059318  0.061876

---->   DataFrame.pct_change

--------------------------------------
ID: 8244 --> 1
>>> df = pd.DataFrame({
...     '2016': [1769950, 30586265],
...     '2015': [1500923, 40912316],
...     '2014': [1371819, 41403351]},
...     index=['GOOG', 'APPL'])
>>> df
          2016      2015      2014
GOOG   1769950   1500923   1371819
APPL  30586265  40912316  41403351

---->   pandas.DataFrame

--------------------------------------
ID: 8245 --> 1
>>> df.pct_change(axis='columns', periods=-1)
          2016      2015  2014
GOOG  0.179241  0.094112   NaN
APPL -0.252395 -0.011860   NaN

---->   DataFrame.pct_change

--------------------------------------
ID: 8246 --> 1
>>> df = pd.DataFrame([[1, 2, 3],
...                    [4, 5, 6],
...                    [7, 8, 9],
...                    [np.nan, np.nan, np.nan]],
...                   columns=['A', 'B', 'C'])

---->   pandas.DataFrame

--------------------------------------
ID: 8247 --> 1
>>> df.agg(['sum', 'min'])
        A     B     C
sum  12.0  15.0  18.0
min   1.0   2.0   3.0

---->   DataFrame.agg

--------------------------------------
ID: 8248 --> 1
>>> df.agg({'A' : ['sum', 'min'], 'B' : ['min', 'max']})
        A    B
sum  12.0  NaN
min   1.0  2.0
max   NaN  8.0

---->   DataFrame.agg

--------------------------------------
ID: 8249 --> 1
>>> df.agg(x=('A', max), y=('B', 'min'), z=('C', np.mean))
     A    B    C
x  7.0  NaN  NaN
y  NaN  2.0  NaN
z  NaN  NaN  6.0

---->   DataFrame.agg

--------------------------------------
ID: 8250 --> 1
>>> df.agg("mean", axis="columns")
0    2.0
1    5.0
2    8.0
3    NaN
dtype: float64

---->   DataFrame.agg

--------------------------------------
ID: 8251 --> 1
>>> df = pd.DataFrame({'angles': [0, 3, 4],
...                    'degrees': [360, 180, 360]},
...                   index=['circle', 'triangle', 'rectangle'])
>>> df
           angles  degrees
circle          0      360
triangle        3      180
rectangle       4      360

---->   pandas.DataFrame

--------------------------------------
ID: 8252 --> 1
>>> df.add(1)
           angles  degrees
circle          1      361
triangle        4      181
rectangle       5      361

---->   DataFrame.add

--------------------------------------
ID: 8253 --> 1
>>> df.div(10)
           angles  degrees
circle        0.0     36.0
triangle      0.3     18.0
rectangle     0.4     36.0

---->   DataFrame.div

--------------------------------------
ID: 8254 --> 1
>>> df.rdiv(10)
             angles   degrees
circle          inf  0.027778
triangle   3.333333  0.055556
rectangle  2.500000  0.027778

---->   DataFrame.rdiv

--------------------------------------
ID: 8255 --> 1
>>> df.sub([1, 2], axis='columns')
           angles  degrees
circle         -1      358
triangle        2      178
rectangle       3      358

---->   DataFrame.sub

--------------------------------------
ID: 8256 --> 2
>>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),
...        axis='index')
           angles  degrees
circle         -1      359
triangle        2      179
rectangle       3      359

---->   DataFrame.sub; pandas.Series

--------------------------------------
ID: 8257 --> 1
>>> df.mul({'angles': 0, 'degrees': 2})
            angles  degrees
circle           0      720
triangle         0      360
rectangle        0      720

---->   DataFrame.mul

--------------------------------------
ID: 8258 --> 1
>>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')
            angles  degrees
circle           0        0
triangle         6      360
rectangle       12     1080

---->   DataFrame.mul

--------------------------------------
ID: 8259 --> 1
>>> other = pd.DataFrame({'angles': [0, 3, 4]},
...                      index=['circle', 'triangle', 'rectangle'])
>>> other
           angles
circle          0
triangle        3
rectangle       4

---->   pandas.DataFrame

--------------------------------------
ID: 8260 --> 1
>>> df.mul(other, fill_value=0)
           angles  degrees
circle          0      0.0
triangle        9      0.0
rectangle      16      0.0

---->   DataFrame.mul

--------------------------------------
ID: 8261 --> 1
>>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],
...                              'degrees': [360, 180, 360, 360, 540, 720]},
...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],
...                                    ['circle', 'triangle', 'rectangle',
...                                     'square', 'pentagon', 'hexagon']])
>>> df_multindex
             angles  degrees
A circle          0      360
  triangle        3      180
  rectangle       4      360
B square          4      360
  pentagon        5      540
  hexagon         6      720

---->   pandas.DataFrame

--------------------------------------
ID: 8262 --> 1
>>> df.div(df_multindex, level=1, fill_value=0)
             angles  degrees
A circle        NaN      1.0
  triangle      1.0      1.0
  rectangle     1.0      1.0
B square        0.0      0.0
  pentagon      0.0      0.0
  hexagon       0.0      0.0

---->   DataFrame.div

--------------------------------------
ID: 8263 --> 1
>>> index = pd.date_range('1/1/2000', periods=9, freq='T')
>>> series = pd.Series(range(9), index=index)
>>> series
2000-01-01 00:00:00    0
2000-01-01 00:01:00    1
2000-01-01 00:02:00    2
2000-01-01 00:03:00    3
2000-01-01 00:04:00    4
2000-01-01 00:05:00    5
2000-01-01 00:06:00    6
2000-01-01 00:07:00    7
2000-01-01 00:08:00    8
Freq: T, dtype: int64

---->   pandas.Series

--------------------------------------
ID: 8264 --> 1
>>> series.resample('3T').sum()
2000-01-01 00:00:00     3
2000-01-01 00:03:00    12
2000-01-01 00:06:00    21
Freq: 3T, dtype: int64

---->   Series.resample

--------------------------------------
ID: 8265 --> 1
>>> series.resample('3T', label='right').sum()
2000-01-01 00:03:00     3
2000-01-01 00:06:00    12
2000-01-01 00:09:00    21
Freq: 3T, dtype: int64

---->   Series.resample

--------------------------------------
ID: 8266 --> 1
>>> series.resample('3T', label='right', closed='right').sum()
2000-01-01 00:00:00     0
2000-01-01 00:03:00     6
2000-01-01 00:06:00    15
2000-01-01 00:09:00    15
Freq: 3T, dtype: int64

---->   Series.resample

--------------------------------------
ID: 8267 --> 1
>>> series.resample('30S').asfreq()[0:5]   # Select first 5 rows
2000-01-01 00:00:00   0.0
2000-01-01 00:00:30   NaN
2000-01-01 00:01:00   1.0
2000-01-01 00:01:30   NaN
2000-01-01 00:02:00   2.0
Freq: 30S, dtype: float64

---->   Series.resample

--------------------------------------
ID: 8268 --> 1
>>> series.resample('30S').ffill()[0:5]
2000-01-01 00:00:00    0
2000-01-01 00:00:30    0
2000-01-01 00:01:00    1
2000-01-01 00:01:30    1
2000-01-01 00:02:00    2
Freq: 30S, dtype: int64

---->   Series.resample

--------------------------------------
ID: 8269 --> 1
>>> series.resample('30S').bfill()[0:5]
2000-01-01 00:00:00    0
2000-01-01 00:00:30    1
2000-01-01 00:01:00    1
2000-01-01 00:01:30    2
2000-01-01 00:02:00    2
Freq: 30S, dtype: int64

---->   Series.resample

--------------------------------------
ID: 8270 --> 1
>>> def custom_resampler(arraylike):
...     return np.sum(arraylike) + 5
...
>>> series.resample('3T').apply(custom_resampler)
2000-01-01 00:00:00     8
2000-01-01 00:03:00    17
2000-01-01 00:06:00    26
Freq: 3T, dtype: int64

---->   Series.resample

--------------------------------------
ID: 8271 --> 3
>>> s = pd.Series([1, 2], index=pd.period_range('2012-01-01',
...                                             freq='A',
...                                             periods=2))
>>> s
2012    1
2013    2
Freq: A-DEC, dtype: int64
>>> s.resample('Q', convention='start').asfreq()
2012Q1    1.0
2012Q2    NaN
2012Q3    NaN
2012Q4    NaN
2013Q1    2.0
2013Q2    NaN
2013Q3    NaN
2013Q4    NaN
Freq: Q-DEC, dtype: float64

---->   pandas.Series; pandas.period_range; Series.resample

--------------------------------------
ID: 8272 --> 2
>>> q = pd.Series([1, 2, 3, 4], index=pd.period_range('2018-01-01',
...                                                   freq='Q',
...                                                   periods=4))
>>> q
2018Q1    1
2018Q2    2
2018Q3    3
2018Q4    4
Freq: Q-DEC, dtype: int64
>>> q.resample('M', convention='end').asfreq()
2018-03    1.0
2018-04    NaN
2018-05    NaN
2018-06    2.0
2018-07    NaN
2018-08    NaN
2018-09    3.0
2018-10    NaN
2018-11    NaN
2018-12    4.0
Freq: M, dtype: float64

---->   pandas.Series; pandas.period_range

--------------------------------------
ID: 8273 --> 2
>>> d = {'price': [10, 11, 9, 13, 14, 18, 17, 19],
...      'volume': [50, 60, 40, 100, 50, 100, 40, 50]}
>>> df = pd.DataFrame(d)
>>> df['week_starting'] = pd.date_range('01/01/2018',
...                                     periods=8,
...                                     freq='W')
>>> df
   price  volume week_starting
0     10      50    2018-01-07
1     11      60    2018-01-14
2      9      40    2018-01-21
3     13     100    2018-01-28
4     14      50    2018-02-04
5     18     100    2018-02-11
6     17      40    2018-02-18
7     19      50    2018-02-25
>>> df.resample('M', on='week_starting').mean()
               price  volume
week_starting
2018-01-31     10.75    62.5
2018-02-28     17.00    60.0

---->   pandas.DataFrame; DataFrame.resample

--------------------------------------
ID: 8274 --> 3
>>> days = pd.date_range('1/1/2000', periods=4, freq='D')
>>> d2 = {'price': [10, 11, 9, 13, 14, 18, 17, 19],
...       'volume': [50, 60, 40, 100, 50, 100, 40, 50]}
>>> df2 = pd.DataFrame(
...     d2,
...     index=pd.MultiIndex.from_product(
...         [days, ['morning', 'afternoon']]
...     )
... )
>>> df2
                      price  volume
2000-01-01 morning       10      50
           afternoon     11      60
2000-01-02 morning        9      40
           afternoon     13     100
2000-01-03 morning       14      50
           afternoon     18     100
2000-01-04 morning       17      40
           afternoon     19      50
>>> df2.resample('D', level=0).sum()
            price  volume
2000-01-01     21     110
2000-01-02     22     140
2000-01-03     32     150
2000-01-04     36      90

---->   pandas.DataFrame; pandas.MultiIndex; DataFrame.resample

--------------------------------------
ID: 8275 --> 1
>>> start, end = '2000-10-01 23:30:00', '2000-10-02 00:30:00'
>>> rng = pd.date_range(start, end, freq='7min')
>>> ts = pd.Series(np.arange(len(rng)) * 3, index=rng)
>>> ts
2000-10-01 23:30:00     0
2000-10-01 23:37:00     3
2000-10-01 23:44:00     6
2000-10-01 23:51:00     9
2000-10-01 23:58:00    12
2000-10-02 00:05:00    15
2000-10-02 00:12:00    18
2000-10-02 00:19:00    21
2000-10-02 00:26:00    24
Freq: 7T, dtype: int64

---->   pandas.Series

--------------------------------------
ID: 8276 --> 1
>>> ts.resample('17min').sum()
2000-10-01 23:14:00     0
2000-10-01 23:31:00     9
2000-10-01 23:48:00    21
2000-10-02 00:05:00    54
2000-10-02 00:22:00    24
Freq: 17T, dtype: int64

---->   Series.resample

--------------------------------------
ID: 8277 --> 1
>>> ts.resample('17min', origin='epoch').sum()
2000-10-01 23:18:00     0
2000-10-01 23:35:00    18
2000-10-01 23:52:00    27
2000-10-02 00:09:00    39
2000-10-02 00:26:00    24
Freq: 17T, dtype: int64

---->   Series.resample

--------------------------------------
ID: 8278 --> 1
>>> ts.resample('17min', origin='2000-01-01').sum()
2000-10-01 23:24:00     3
2000-10-01 23:41:00    15
2000-10-01 23:58:00    45
2000-10-02 00:15:00    45
Freq: 17T, dtype: int64

---->   Series.resample

--------------------------------------
ID: 8279 --> 1
>>> ts.resample('17min', origin='start').sum()
2000-10-01 23:30:00     9
2000-10-01 23:47:00    21
2000-10-02 00:04:00    54
2000-10-02 00:21:00    24
Freq: 17T, dtype: int64

---->   Series.resample

--------------------------------------
ID: 8280 --> 1
>>> ts.resample('17min', offset='23h30min').sum()
2000-10-01 23:30:00     9
2000-10-01 23:47:00    21
2000-10-02 00:04:00    54
2000-10-02 00:21:00    24
Freq: 17T, dtype: int64

---->   Series.resample

--------------------------------------
ID: 8281 --> 1
>>> ts.resample('17min', origin='end').sum()
2000-10-01 23:35:00     0
2000-10-01 23:52:00    18
2000-10-02 00:09:00    27
2000-10-02 00:26:00    63
Freq: 17T, dtype: int64

---->   Series.resample

--------------------------------------
ID: 8282 --> 1
>>> ts.resample('17min', origin='end_day').sum()
2000-10-01 23:38:00     3
2000-10-01 23:55:00    15
2000-10-02 00:12:00    45
2000-10-02 00:29:00    45
Freq: 17T, dtype: int64

---->   Series.resample

--------------------------------------
ID: 8283 --> 1
>>> df = pd.DataFrame({'angles': [0, 3, 4],
...                    'degrees': [360, 180, 360]},
...                   index=['circle', 'triangle', 'rectangle'])
>>> df
           angles  degrees
circle          0      360
triangle        3      180
rectangle       4      360

---->   pandas.DataFrame

--------------------------------------
ID: 8284 --> 1
>>> df.add(1)
           angles  degrees
circle          1      361
triangle        4      181
rectangle       5      361

---->   DataFrame.add

--------------------------------------
ID: 8285 --> 1
>>> df.div(10)
           angles  degrees
circle        0.0     36.0
triangle      0.3     18.0
rectangle     0.4     36.0

---->   DataFrame.div

--------------------------------------
ID: 8286 --> 1
>>> df.rdiv(10)
             angles   degrees
circle          inf  0.027778
triangle   3.333333  0.055556
rectangle  2.500000  0.027778

---->   DataFrame.rdiv

--------------------------------------
ID: 8287 --> 1
>>> df.sub([1, 2], axis='columns')
           angles  degrees
circle         -1      358
triangle        2      178
rectangle       3      358

---->   DataFrame.sub

--------------------------------------
ID: 8288 --> 2
>>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),
...        axis='index')
           angles  degrees
circle         -1      359
triangle        2      179
rectangle       3      359

---->   DataFrame.sub; pandas.Series

--------------------------------------
ID: 8289 --> 1
>>> df.mul({'angles': 0, 'degrees': 2})
            angles  degrees
circle           0      720
triangle         0      360
rectangle        0      720

---->   DataFrame.mul

--------------------------------------
ID: 8290 --> 1
>>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')
            angles  degrees
circle           0        0
triangle         6      360
rectangle       12     1080

---->   DataFrame.mul

--------------------------------------
ID: 8291 --> 1
>>> other = pd.DataFrame({'angles': [0, 3, 4]},
...                      index=['circle', 'triangle', 'rectangle'])
>>> other
           angles
circle          0
triangle        3
rectangle       4

---->   pandas.DataFrame

--------------------------------------
ID: 8292 --> 1
>>> df.mul(other, fill_value=0)
           angles  degrees
circle          0      0.0
triangle        9      0.0
rectangle      16      0.0

---->   DataFrame.mul

--------------------------------------
ID: 8293 --> 1
>>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],
...                              'degrees': [360, 180, 360, 360, 540, 720]},
...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],
...                                    ['circle', 'triangle', 'rectangle',
...                                     'square', 'pentagon', 'hexagon']])
>>> df_multindex
             angles  degrees
A circle          0      360
  triangle        3      180
  rectangle       4      360
B square          4      360
  pentagon        5      540
  hexagon         6      720

---->   pandas.DataFrame

--------------------------------------
ID: 8294 --> 1
>>> df.div(df_multindex, level=1, fill_value=0)
             angles  degrees
A circle        NaN      1.0
  triangle      1.0      1.0
  rectangle     1.0      1.0
B square        0.0      0.0
  pentagon      0.0      0.0
  hexagon       0.0      0.0

---->   DataFrame.div

--------------------------------------
ID: 8295 --> 1
>>> idx = pd.to_datetime(
...     [
...         "2001-03-31 00:00:00",
...         "2002-05-31 00:00:00",
...         "2003-08-31 00:00:00",
...     ]
... )

---->   pandas.to_datetime

--------------------------------------
ID: 8299 --> 1
>>> df = pd.DataFrame({'cost': [250, 150, 100],
...                    'revenue': [100, 250, 300]},
...                   index=['A', 'B', 'C'])
>>> df
   cost  revenue
A   250      100
B   150      250
C   100      300

---->   pandas.DataFrame

--------------------------------------
ID: 8300 --> 1
>>> df.eq(100)
    cost  revenue
A  False     True
B  False    False
C   True    False

---->   DataFrame.eq

--------------------------------------
ID: 8301 --> 1
>>> df != pd.Series([100, 250], index=["cost", "revenue"])
    cost  revenue
A   True     True
B   True    False
C  False     True

---->   pandas.Series

--------------------------------------
ID: 8302 --> 2
>>> df.ne(pd.Series([100, 300], index=["A", "D"]), axis='index')
   cost  revenue
A  True    False
B  True     True
C  True     True
D  True     True

---->   DataFrame.ne; pandas.Series

--------------------------------------
ID: 8303 --> 1
>>> df.eq([250, 250, 100], axis='index')
    cost  revenue
A   True    False
B  False     True
C   True    False

---->   DataFrame.eq

--------------------------------------
ID: 8304 --> 1
>>> other = pd.DataFrame({'revenue': [300, 250, 100, 150]},
...                      index=['A', 'B', 'C', 'D'])
>>> other
   revenue
A      300
B      250
C      100
D      150

---->   pandas.DataFrame

--------------------------------------
ID: 8305 --> 1
>>> df.gt(other)
    cost  revenue
A  False    False
B  False    False
C  False     True
D  False    False

---->   DataFrame.gt

--------------------------------------
ID: 8306 --> 1
>>> df_multindex = pd.DataFrame({'cost': [250, 150, 100, 150, 300, 220],
...                              'revenue': [100, 250, 300, 200, 175, 225]},
...                             index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'],
...                                    ['A', 'B', 'C', 'A', 'B', 'C']])
>>> df_multindex
      cost  revenue
Q1 A   250      100
   B   150      250
   C   100      300
Q2 A   150      200
   B   300      175
   C   220      225

---->   pandas.DataFrame

--------------------------------------
ID: 8307 --> 1
>>> df.le(df_multindex, level=1)
       cost  revenue
Q1 A   True     True
   B   True     True
   C   True     True
Q2 A  False     True
   B   True    False
   C   True    False

---->   DataFrame.le

--------------------------------------
ID: 8308 --> 1
>>> df = pd.DataFrame({
...     'brand': ['Yum Yum', 'Yum Yum', 'Indomie', 'Indomie', 'Indomie'],
...     'style': ['cup', 'cup', 'cup', 'pack', 'pack'],
...     'rating': [4, 4, 3.5, 15, 5]
... })
>>> df
    brand style  rating
0  Yum Yum   cup     4.0
1  Yum Yum   cup     4.0
2  Indomie   cup     3.5
3  Indomie  pack    15.0
4  Indomie  pack     5.0

---->   pandas.DataFrame

--------------------------------------
ID: 8312 --> 1
>>> df1 = pd.DataFrame([[24.3, 75.7, 'high'],
...                     [31, 87.8, 'high'],
...                     [22, 71.6, 'medium'],
...                     [35, 95, 'medium']],
...                    columns=['temp_celsius', 'temp_fahrenheit',
...                             'windspeed'],
...                    index=pd.date_range(start='2014-02-12',
...                                        end='2014-02-15', freq='D'))

---->   pandas.DataFrame

--------------------------------------
ID: 8313 --> 2
>>> df2 = pd.DataFrame([[28, 'low'],
...                     [30, 'low'],
...                     [35.1, 'medium']],
...                    columns=['temp_celsius', 'windspeed'],
...                    index=pd.DatetimeIndex(['2014-02-12', '2014-02-13',
...                                            '2014-02-15']))

---->   pandas.DataFrame; pandas.DatetimeIndex

--------------------------------------
ID: 8314 --> 1
>>> df2.reindex_like(df1)
            temp_celsius  temp_fahrenheit windspeed
2014-02-12          28.0              NaN       low
2014-02-13          30.0              NaN       low
2014-02-14           NaN              NaN       NaN
2014-02-15          35.1              NaN    medium

---->   DataFrame.reindex_like

--------------------------------------
ID: 8315 --> 1
>>> df = pd.DataFrame({'A': [[0, 1, 2], 'foo', [], [3, 4]],
...                    'B': 1,
...                    'C': [['a', 'b', 'c'], np.nan, [], ['d', 'e']]})
>>> df
           A  B          C
0  [0, 1, 2]  1  [a, b, c]
1        foo  1        NaN
2         []  1         []
3     [3, 4]  1     [d, e]

---->   pandas.DataFrame

--------------------------------------
ID: 8316 --> 1
>>> df.explode('A')
     A  B          C
0    0  1  [a, b, c]
0    1  1  [a, b, c]
0    2  1  [a, b, c]
1  foo  1        NaN
2  NaN  1         []
3    3  1     [d, e]
3    4  1     [d, e]

---->   DataFrame.explode

--------------------------------------
ID: 8317 --> 1
>>> df.explode(list('AC'))
     A  B    C
0    0  1    a
0    1  1    b
0    2  1    c
1  foo  1  NaN
2  NaN  1  NaN
3    3  1    d
3    4  1    e

---->   DataFrame.explode

--------------------------------------
ID: 8318 --> 1
>>> i = pd.date_range('2018-04-09', periods=4, freq='12H')
>>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)
>>> ts
                     A
2018-04-09 00:00:00  1
2018-04-09 12:00:00  2
2018-04-10 00:00:00  3
2018-04-10 12:00:00  4

---->   pandas.DataFrame

--------------------------------------
ID: 8319 --> 1
>>> ts.at_time('12:00')
                     A
2018-04-09 12:00:00  2
2018-04-10 12:00:00  4

---->   DataFrame.at_time

--------------------------------------
ID: 8320 --> 3
>>> s = pd.Series(
...     [1],
...     index=pd.DatetimeIndex(['2018-09-15 01:30:00+02:00']),
... )
>>> s.tz_convert('Asia/Shanghai')
2018-09-15 07:30:00+08:00    1
dtype: int64

---->   pandas.Series; pandas.DatetimeIndex; Series.tz_convert

--------------------------------------
ID: 8321 --> 3
>>> s = pd.Series([1],
...     index=pd.DatetimeIndex(['2018-09-15 01:30:00+02:00']))
>>> s.tz_convert(None)
2018-09-14 23:30:00    1
dtype: int64

---->   pandas.Series; pandas.DatetimeIndex; Series.tz_convert

--------------------------------------
ID: 8322 --> 2
>>> df = pd.DataFrame(
...     data={"animal_1": ["elk", "pig"], "animal_2": ["dog", "quetzal"]}
... )
>>> print(df.to_markdown())
|    | animal_1   | animal_2   |
|---:|:-----------|:-----------|
|  0 | elk        | dog        |
|  1 | pig        | quetzal    |

---->   pandas.DataFrame; DataFrame.to_markdown

--------------------------------------
ID: 8323 --> 1
>>> print(df.to_markdown(tablefmt="grid"))
+----+------------+------------+
|    | animal_1   | animal_2   |
+====+============+============+
|  0 | elk        | dog        |
+----+------------+------------+
|  1 | pig        | quetzal    |
+----+------------+------------+

---->   DataFrame.to_markdown

--------------------------------------
ID: 8324 --> 1
>>> df = pd.DataFrame({'person_id': [0, 1, 2, 3],
...                   'age': [21, 25, 62, 43],
...                   'height': [1.61, 1.87, 1.49, 2.01]}
...                  ).set_index('person_id')
>>> df
           age  height
person_id
0           21    1.61
1           25    1.87
2           62    1.49
3           43    2.01

---->   pandas.DataFrame

--------------------------------------
ID: 8325 --> 1
>>> df.var()
age       352.916667
height      0.056367
dtype: float64

---->   DataFrame.var

--------------------------------------
ID: 8326 --> 1
>>> df.var(ddof=0)
age       264.687500
height      0.042275
dtype: float64

---->   DataFrame.var

--------------------------------------
ID: 8327 --> 1
>>> df = pd.DataFrame({"B": [0, 1, 2, np.nan, 4]})
>>> df
     B
0  0.0
1  1.0
2  2.0
3  NaN
4  4.0

---->   pandas.DataFrame

--------------------------------------
ID: 8328 --> 1
>>> df.expanding(1).sum()
     B
0  0.0
1  1.0
2  3.0
3  3.0
4  7.0
>>> df.expanding(3).sum()
     B
0  NaN
1  NaN
2  3.0
3  3.0
4  7.0

---->   DataFrame.expanding

--------------------------------------
ID: 8329 --> 2
>>> df = pd.DataFrame({'lab':['A', 'B', 'C'], 'val':[10, 30, 20]})
>>> ax = df.plot.bar(x='lab', y='val', rot=0)

---->   pandas.DataFrame; DataFrame.plot

--------------------------------------
ID: 8330 --> 2
>>> speed = [0.1, 17.5, 40, 48, 52, 69, 88]
>>> lifespan = [2, 8, 70, 1.5, 25, 12, 28]
>>> index = ['snail', 'pig', 'elephant',
...          'rabbit', 'giraffe', 'coyote', 'horse']
>>> df = pd.DataFrame({'speed': speed,
...                    'lifespan': lifespan}, index=index)
>>> ax = df.plot.bar(rot=0)

---->   pandas.DataFrame; DataFrame.plot

--------------------------------------
ID: 8331 --> 1
>>> ax = df.plot.bar(stacked=True)

---->   DataFrame.plot

--------------------------------------
ID: 8332 --> 1
>>> axes = df.plot.bar(rot=0, subplots=True)
>>> axes[1].legend(loc=2)  

---->   DataFrame.plot

--------------------------------------
ID: 8333 --> 1
>>> axes = df.plot.bar(
...     rot=0, subplots=True, color={"speed": "red", "lifespan": "green"}
... )
>>> axes[1].legend(loc=2)  

---->   DataFrame.plot

--------------------------------------
ID: 8334 --> 1
>>> ax = df.plot.bar(y='speed', rot=0)

---->   DataFrame.plot

--------------------------------------
ID: 8335 --> 1
>>> ax = df.plot.bar(x='lifespan', rot=0)

---->   DataFrame.plot

--------------------------------------
ID: 8336 --> 1
>>> df = pd.DataFrame({"A": ["a", 1, 2, 3]})
>>> df = df.iloc[1:]
>>> df
   A
1  1
2  2
3  3

---->   pandas.DataFrame

--------------------------------------
ID: 8337 --> 1
>>> df.infer_objects().dtypes
A    int64
dtype: object

---->   DataFrame.infer_objects

--------------------------------------
ID: 8338 --> 1
>>> df = pd.DataFrame(np.arange(12).reshape(3, 4),
...                   columns=['A', 'B', 'C', 'D'])
>>> df
   A  B   C   D
0  0  1   2   3
1  4  5   6   7
2  8  9  10  11

---->   pandas.DataFrame

--------------------------------------
ID: 8342 --> 2
>>> midx = pd.MultiIndex(levels=[['lama', 'cow', 'falcon'],
...                              ['speed', 'weight', 'length']],
...                      codes=[[0, 0, 0, 1, 1, 1, 2, 2, 2],
...                             [0, 1, 2, 0, 1, 2, 0, 1, 2]])
>>> df = pd.DataFrame(index=midx, columns=['big', 'small'],
...                   data=[[45, 30], [200, 100], [1.5, 1], [30, 20],
...                         [250, 150], [1.5, 0.8], [320, 250],
...                         [1, 0.8], [0.3, 0.2]])
>>> df
                big     small
lama    speed   45.0    30.0
        weight  200.0   100.0
        length  1.5     1.0
cow     speed   30.0    20.0
        weight  250.0   150.0
        length  1.5     0.8
falcon  speed   320.0   250.0
        weight  1.0     0.8
        length  0.3     0.2

---->   pandas.MultiIndex; pandas.DataFrame

--------------------------------------
ID: 8346 --> 1
>>> s = pd.Series([2, np.nan, 5, -1, 0])
>>> s
0    2.0
1    NaN
2    5.0
3   -1.0
4    0.0
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 8347 --> 1
>>> s.cummin()
0    2.0
1    NaN
2    2.0
3   -1.0
4   -1.0
dtype: float64

---->   Series.cummin

--------------------------------------
ID: 8348 --> 1
>>> s.cummin(skipna=False)
0    2.0
1    NaN
2    NaN
3    NaN
4    NaN
dtype: float64

---->   Series.cummin

--------------------------------------
ID: 8349 --> 1
>>> df = pd.DataFrame([[2.0, 1.0],
...                    [3.0, np.nan],
...                    [1.0, 0.0]],
...                   columns=list('AB'))
>>> df
     A    B
0  2.0  1.0
1  3.0  NaN
2  1.0  0.0

---->   pandas.DataFrame

--------------------------------------
ID: 8350 --> 1
>>> df.cummin()
     A    B
0  2.0  1.0
1  2.0  NaN
2  1.0  0.0

---->   DataFrame.cummin

--------------------------------------
ID: 8351 --> 1
>>> df.cummin(axis=1)
     A    B
0  2.0  1.0
1  3.0  NaN
2  1.0  0.0

---->   DataFrame.cummin

--------------------------------------
ID: 8352 --> 1
>>> s = pd.Series({'a': 1, 'b': 2, 'c': 3})
>>> s.size
3

---->   pandas.Series

--------------------------------------
ID: 8353 --> 1
>>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})
>>> df.size
4

---->   pandas.DataFrame

--------------------------------------
ID: 8354 --> 1
>>> df = pd.DataFrame([('bird', 2, 2),
...                    ('mammal', 4, np.nan),
...                    ('arthropod', 8, 0),
...                    ('bird', 2, np.nan)],
...                   index=('falcon', 'horse', 'spider', 'ostrich'),
...                   columns=('species', 'legs', 'wings'))
>>> df
           species  legs  wings
falcon        bird     2    2.0
horse       mammal     4    NaN
spider   arthropod     8    0.0
ostrich       bird     2    NaN

---->   pandas.DataFrame

--------------------------------------
ID: 8355 --> 1
>>> df.mode()
  species  legs  wings
0    bird   2.0    0.0
1     NaN   NaN    2.0

---->   DataFrame.mode

--------------------------------------
ID: 8356 --> 1
>>> df.mode(dropna=False)
  species  legs  wings
0    bird     2    NaN

---->   DataFrame.mode

--------------------------------------
ID: 8357 --> 1
>>> df.mode(numeric_only=True)
   legs  wings
0   2.0    0.0
1   NaN    2.0

---->   DataFrame.mode

--------------------------------------
ID: 8358 --> 1
>>> df.mode(axis='columns', numeric_only=True)
           0    1
falcon   2.0  NaN
horse    4.0  NaN
spider   0.0  8.0
ostrich  2.0  NaN

---->   DataFrame.mode

--------------------------------------
ID: 8359 --> 1
>>> df = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3', 'K4', 'K5'],
...                    'A': ['A0', 'A1', 'A2', 'A3', 'A4', 'A5']})

---->   pandas.DataFrame

--------------------------------------
ID: 8360 --> 1
>>> other = pd.DataFrame({'key': ['K0', 'K1', 'K2'],
...                       'B': ['B0', 'B1', 'B2']})

---->   pandas.DataFrame

--------------------------------------
ID: 8361 --> 1
>>> df.join(other, lsuffix='_caller', rsuffix='_other')
  key_caller   A key_other    B
0         K0  A0        K0   B0
1         K1  A1        K1   B1
2         K2  A2        K2   B2
3         K3  A3       NaN  NaN
4         K4  A4       NaN  NaN
5         K5  A5       NaN  NaN

---->   DataFrame.join

--------------------------------------
ID: 8363 --> 1
>>> df.join(other.set_index('key'), on='key')
  key   A    B
0  K0  A0   B0
1  K1  A1   B1
2  K2  A2   B2
3  K3  A3  NaN
4  K4  A4  NaN
5  K5  A5  NaN

---->   DataFrame.join

--------------------------------------
ID: 8364 --> 1
>>> df = pd.DataFrame({'key': ['K0', 'K1', 'K1', 'K3', 'K0', 'K1'],
...                    'A': ['A0', 'A1', 'A2', 'A3', 'A4', 'A5']})

---->   pandas.DataFrame

--------------------------------------
ID: 8365 --> 1
>>> df.join(other.set_index('key'), on='key', validate='m:1')
  key   A    B
0  K0  A0   B0
1  K1  A1   B1
2  K1  A2   B1
3  K3  A3  NaN
4  K0  A4   B0
5  K1  A5   B1

---->   DataFrame.join

--------------------------------------
ID: 8366 --> 1
>>> s = pd.Series([0, 1, np.nan, 3])
>>> s
0    0.0
1    1.0
2    NaN
3    3.0
dtype: float64
>>> s.interpolate()
0    0.0
1    1.0
2    2.0
3    3.0
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 8367 --> 1
>>> s = pd.Series([np.nan, "single_one", np.nan,
...                "fill_two_more", np.nan, np.nan, np.nan,
...                4.71, np.nan])
>>> s
0              NaN
1       single_one
2              NaN
3    fill_two_more
4              NaN
5              NaN
6              NaN
7             4.71
8              NaN
dtype: object
>>> s.interpolate(method='pad', limit=2)
0              NaN
1       single_one
2       single_one
3    fill_two_more
4    fill_two_more
5    fill_two_more
6              NaN
7             4.71
8             4.71
dtype: object

---->   pandas.Series

--------------------------------------
ID: 8368 --> 1
>>> s = pd.Series([0, 2, np.nan, 8])
>>> s.interpolate(method='polynomial', order=2)
0    0.000000
1    2.000000
2    4.666667
3    8.000000
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 8369 --> 1
>>> df = pd.DataFrame([(0.0, np.nan, -1.0, 1.0),
...                    (np.nan, 2.0, np.nan, np.nan),
...                    (2.0, 3.0, np.nan, 9.0),
...                    (np.nan, 4.0, -4.0, 16.0)],
...                   columns=list('abcd'))
>>> df
     a    b    c     d
0  0.0  NaN -1.0   1.0
1  NaN  2.0  NaN   NaN
2  2.0  3.0  NaN   9.0
3  NaN  4.0 -4.0  16.0
>>> df.interpolate(method='linear', limit_direction='forward', axis=0)
     a    b    c     d
0  0.0  NaN -1.0   1.0
1  1.0  2.0 -2.0   5.0
2  2.0  3.0 -3.0   9.0
3  2.0  4.0 -4.0  16.0

---->   pandas.DataFrame

--------------------------------------
ID: 8371 --> 1
>>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})
>>> df
   col1  col2
0     1     3
1     2     4

---->   pandas.DataFrame

--------------------------------------
ID: 8372 --> 1
>>> df = pd.DataFrame({'angles': [0, 3, 4],
...                    'degrees': [360, 180, 360]},
...                   index=['circle', 'triangle', 'rectangle'])
>>> df
           angles  degrees
circle          0      360
triangle        3      180
rectangle       4      360

---->   pandas.DataFrame

--------------------------------------
ID: 8373 --> 1
>>> df.add(1)
           angles  degrees
circle          1      361
triangle        4      181
rectangle       5      361

---->   DataFrame.add

--------------------------------------
ID: 8374 --> 1
>>> df.div(10)
           angles  degrees
circle        0.0     36.0
triangle      0.3     18.0
rectangle     0.4     36.0

---->   DataFrame.div

--------------------------------------
ID: 8375 --> 1
>>> df.rdiv(10)
             angles   degrees
circle          inf  0.027778
triangle   3.333333  0.055556
rectangle  2.500000  0.027778

---->   DataFrame.rdiv

--------------------------------------
ID: 8376 --> 1
>>> df.sub([1, 2], axis='columns')
           angles  degrees
circle         -1      358
triangle        2      178
rectangle       3      358

---->   DataFrame.sub

--------------------------------------
ID: 8377 --> 2
>>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),
...        axis='index')
           angles  degrees
circle         -1      359
triangle        2      179
rectangle       3      359

---->   DataFrame.sub; pandas.Series

--------------------------------------
ID: 8378 --> 1
>>> df.mul({'angles': 0, 'degrees': 2})
            angles  degrees
circle           0      720
triangle         0      360
rectangle        0      720

---->   DataFrame.mul

--------------------------------------
ID: 8379 --> 1
>>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')
            angles  degrees
circle           0        0
triangle         6      360
rectangle       12     1080

---->   DataFrame.mul

--------------------------------------
ID: 8380 --> 1
>>> other = pd.DataFrame({'angles': [0, 3, 4]},
...                      index=['circle', 'triangle', 'rectangle'])
>>> other
           angles
circle          0
triangle        3
rectangle       4

---->   pandas.DataFrame

--------------------------------------
ID: 8381 --> 1
>>> df.mul(other, fill_value=0)
           angles  degrees
circle          0      0.0
triangle        9      0.0
rectangle      16      0.0

---->   DataFrame.mul

--------------------------------------
ID: 8382 --> 1
>>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],
...                              'degrees': [360, 180, 360, 360, 540, 720]},
...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],
...                                    ['circle', 'triangle', 'rectangle',
...                                     'square', 'pentagon', 'hexagon']])
>>> df_multindex
             angles  degrees
A circle          0      360
  triangle        3      180
  rectangle       4      360
B square          4      360
  pentagon        5      540
  hexagon         6      720

---->   pandas.DataFrame

--------------------------------------
ID: 8383 --> 1
>>> df.div(df_multindex, level=1, fill_value=0)
             angles  degrees
A circle        NaN      1.0
  triangle      1.0      1.0
  rectangle     1.0      1.0
B square        0.0      0.0
  pentagon      0.0      0.0
  hexagon       0.0      0.0

---->   DataFrame.div

--------------------------------------
ID: 8384 --> 1
>>> d = {'col1': [1, 2], 'col2': [3, 4]}
>>> df = pd.DataFrame(data=d)
>>> df
   col1  col2
0     1     3
1     2     4

---->   pandas.DataFrame

--------------------------------------
ID: 8385 --> 1
>>> df = pd.DataFrame(data=d, dtype=np.int8)
>>> df.dtypes
col1    int8
col2    int8
dtype: object

---->   pandas.DataFrame

--------------------------------------
ID: 8386 --> 2
>>> d = {'col1': [0, 1, 2, 3], 'col2': pd.Series([2, 3], index=[2, 3])}
>>> pd.DataFrame(data=d, index=[0, 1, 2, 3])
   col1  col2
0     0   NaN
1     1   NaN
2     2   2.0
3     3   3.0

---->   pandas.Series; pandas.DataFrame

--------------------------------------
ID: 8387 --> 1
>>> df2 = pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]),
...                    columns=['a', 'b', 'c'])
>>> df2
   a  b  c
0  1  2  3
1  4  5  6
2  7  8  9

---->   pandas.DataFrame

--------------------------------------
ID: 8388 --> 1
>>> data = np.array([(1, 2, 3), (4, 5, 6), (7, 8, 9)],
...                 dtype=[("a", "i4"), ("b", "i4"), ("c", "i4")])
>>> df3 = pd.DataFrame(data, columns=['c', 'a'])
...
>>> df3
   c  a
0  3  1
1  6  4
2  9  7

---->   pandas.DataFrame

--------------------------------------
ID: 8389 --> 1
>>> from dataclasses import make_dataclass
>>> Point = make_dataclass("Point", [("x", int), ("y", int)])
>>> pd.DataFrame([Point(0, 0), Point(0, 3), Point(2, 3)])
   x  y
0  0  0
1  0  3
2  2  3

---->   pandas.DataFrame

--------------------------------------
ID: 8390 --> 2
>>> ser = pd.Series([1, 2, 3], index=["a", "b", "c"])
>>> df = pd.DataFrame(data=ser, index=["a", "c"])
>>> df
   0
a  1
c  3

---->   pandas.Series; pandas.DataFrame

--------------------------------------
ID: 8391 --> 1
>>> df1 = pd.DataFrame([1, 2, 3], index=["a", "b", "c"], columns=["x"])
>>> df2 = pd.DataFrame(data=df1, index=["a", "c"])
>>> df2
   x
a  1
c  3

---->   pandas.DataFrame

--------------------------------------
ID: 8392 --> 1
>>> pd.Series([True, True]).all()
True
>>> pd.Series([True, False]).all()
False
>>> pd.Series([], dtype="float64").all()
True
>>> pd.Series([np.nan]).all()
True
>>> pd.Series([np.nan]).all(skipna=False)
True

---->   pandas.Series

--------------------------------------
ID: 8393 --> 1
>>> df = pd.DataFrame({'col1': [True, True], 'col2': [True, False]})
>>> df
   col1   col2
0  True   True
1  True  False

---->   pandas.DataFrame

--------------------------------------
ID: 8394 --> 1
>>> df.all()
col1     True
col2    False
dtype: bool

---->   DataFrame.all

--------------------------------------
ID: 8395 --> 1
>>> df.all(axis='columns')
0     True
1    False
dtype: bool

---->   DataFrame.all

--------------------------------------
ID: 8396 --> 1
>>> df.all(axis=None)
False

---->   DataFrame.all

--------------------------------------
ID: 8397 --> 1
>>> mydict = [{'a': 1, 'b': 2, 'c': 3, 'd': 4},
...           {'a': 100, 'b': 200, 'c': 300, 'd': 400},
...           {'a': 1000, 'b': 2000, 'c': 3000, 'd': 4000 }]
>>> df = pd.DataFrame(mydict)
>>> df
      a     b     c     d
0     1     2     3     4
1   100   200   300   400
2  1000  2000  3000  4000

---->   pandas.DataFrame

--------------------------------------
ID: 8400 --> 1
>>> df = pd.DataFrame(
...     [
...         [24.3, 75.7, "high"],
...         [31, 87.8, "high"],
...         [22, 71.6, "medium"],
...         [35, 95, "medium"],
...     ],
...     columns=["temp_celsius", "temp_fahrenheit", "windspeed"],
...     index=pd.date_range(start="2014-02-12", end="2014-02-15", freq="D"),
... )

---->   pandas.DataFrame

--------------------------------------
ID: 8401 --> 1
>>> df.get(["temp_celsius", "windspeed"])
            temp_celsius windspeed
2014-02-12          24.3      high
2014-02-13          31.0      high
2014-02-14          22.0    medium
2014-02-15          35.0    medium

---->   DataFrame.get

--------------------------------------
ID: 8402 --> 1
>>> ser = df['windspeed']
>>> ser.get('2014-02-13')
'high'

---->   Series.get

--------------------------------------
ID: 8403 --> 1
>>> df.get(["temp_celsius", "temp_kelvin"], default="default_value")
'default_value'

---->   DataFrame.get

--------------------------------------
ID: 8404 --> 1
>>> ser.get('2014-02-10', '[unknown]')
'[unknown]'

---->   Series.get

--------------------------------------
ID: 8405 --> 2
>>> df = pd.DataFrame({'mass': [0.330, 4.87 , 5.97],
...                    'radius': [2439.7, 6051.8, 6378.1]},
...                   index=['Mercury', 'Venus', 'Earth'])
>>> plot = df.plot.pie(y='mass', figsize=(5, 5))

---->   pandas.DataFrame; DataFrame.plot

--------------------------------------
ID: 8406 --> 1
>>> plot = df.plot.pie(subplots=True, figsize=(11, 6))

---->   DataFrame.plot

--------------------------------------
ID: 8407 --> 1
>>> df = pd.DataFrame([[np.nan, 2, np.nan, 0],
...                    [3, 4, np.nan, 1],
...                    [np.nan, np.nan, np.nan, np.nan],
...                    [np.nan, 3, np.nan, 4]],
...                   columns=list("ABCD"))
>>> df
     A    B   C    D
0  NaN  2.0 NaN  0.0
1  3.0  4.0 NaN  1.0
2  NaN  NaN NaN  NaN
3  NaN  3.0 NaN  4.0

---->   pandas.DataFrame

--------------------------------------
ID: 8412 --> 1
>>> df2 = pd.DataFrame(np.zeros((4, 4)), columns=list("ABCE"))
>>> df.fillna(df2)
     A    B    C    D
0  0.0  2.0  0.0  0.0
1  3.0  4.0  0.0  1.0
2  0.0  0.0  0.0  NaN
3  0.0  3.0  0.0  4.0

---->   pandas.DataFrame

--------------------------------------
ID: 8413 --> 2
>>> def histogram_intersection(a, b):
...     v = np.minimum(a, b).sum().round(decimals=1)
...     return v
>>> df = pd.DataFrame([(.2, .3), (.0, .6), (.6, .0), (.2, .1)],
...                   columns=['dogs', 'cats'])
>>> df.corr(method=histogram_intersection)
      dogs  cats
dogs   1.0   0.3
cats   0.3   1.0

---->   pandas.DataFrame; DataFrame.corr

--------------------------------------
ID: 8414 --> 2
>>> df = pd.DataFrame([(1, 1), (2, np.nan), (np.nan, 3), (4, 4)],
...                   columns=['dogs', 'cats'])
>>> df.corr(min_periods=3)
      dogs  cats
dogs   1.0   NaN
cats   NaN   1.0

---->   pandas.DataFrame; DataFrame.corr

--------------------------------------
ID: 8415 --> 1
>>> pd.Series([False, False]).any()
False
>>> pd.Series([True, False]).any()
True
>>> pd.Series([], dtype="float64").any()
False
>>> pd.Series([np.nan]).any()
False
>>> pd.Series([np.nan]).any(skipna=False)
True

---->   pandas.Series

--------------------------------------
ID: 8416 --> 1
>>> df = pd.DataFrame({"A": [1, 2], "B": [0, 2], "C": [0, 0]})
>>> df
   A  B  C
0  1  0  0
1  2  2  0

---->   pandas.DataFrame

--------------------------------------
ID: 8418 --> 1
>>> df = pd.DataFrame({"A": [True, False], "B": [1, 2]})
>>> df
       A  B
0   True  1
1  False  2

---->   pandas.DataFrame

--------------------------------------
ID: 8420 --> 1
>>> df = pd.DataFrame({"A": [True, False], "B": [1, 0]})
>>> df
       A  B
0   True  1
1  False  0

---->   pandas.DataFrame

--------------------------------------
ID: 8423 --> 1
>>> pd.DataFrame([]).any()
Series([], dtype: bool)

---->   pandas.DataFrame

--------------------------------------
ID: 8424 --> 1
>>> df = pd.DataFrame({'animal': ['alligator', 'bee', 'falcon', 'lion',
...                    'monkey', 'parrot', 'shark', 'whale', 'zebra']})
>>> df
      animal
0  alligator
1        bee
2     falcon
3       lion
4     monkey
5     parrot
6      shark
7      whale
8      zebra

---->   pandas.DataFrame

--------------------------------------
ID: 8425 --> 1
>>> df.head()
      animal
0  alligator
1        bee
2     falcon
3       lion
4     monkey

---->   DataFrame.head

--------------------------------------
ID: 8426 --> 1
>>> df.head(3)
      animal
0  alligator
1        bee
2     falcon

---->   DataFrame.head

--------------------------------------
ID: 8427 --> 1
>>> df.head(-3)
      animal
0  alligator
1        bee
2     falcon
3       lion
4     monkey
5     parrot

---->   DataFrame.head

--------------------------------------
ID: 8428 --> 1
>>> s = pd.Series([2, np.nan, 5, -1, 0])
>>> s
0    2.0
1    NaN
2    5.0
3   -1.0
4    0.0
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 8429 --> 1
>>> s.cummax()
0    2.0
1    NaN
2    5.0
3    5.0
4    5.0
dtype: float64

---->   Series.cummax

--------------------------------------
ID: 8430 --> 1
>>> s.cummax(skipna=False)
0    2.0
1    NaN
2    NaN
3    NaN
4    NaN
dtype: float64

---->   Series.cummax

--------------------------------------
ID: 8431 --> 1
>>> df = pd.DataFrame([[2.0, 1.0],
...                    [3.0, np.nan],
...                    [1.0, 0.0]],
...                   columns=list('AB'))
>>> df
     A    B
0  2.0  1.0
1  3.0  NaN
2  1.0  0.0

---->   pandas.DataFrame

--------------------------------------
ID: 8432 --> 1
>>> df.cummax()
     A    B
0  2.0  1.0
1  3.0  NaN
2  3.0  1.0

---->   DataFrame.cummax

--------------------------------------
ID: 8433 --> 1
>>> df.cummax(axis=1)
     A    B
0  2.0  2.0
1  3.0  NaN
2  1.0  1.0

---->   DataFrame.cummax

--------------------------------------
ID: 8434 --> 1
>>> df_single_level_cols = pd.DataFrame([[0, 1], [2, 3]],
...                                     index=['cat', 'dog'],
...                                     columns=['weight', 'height'])

---->   pandas.DataFrame

--------------------------------------
ID: 8436 --> 2
>>> multicol1 = pd.MultiIndex.from_tuples([('weight', 'kg'),
...                                        ('weight', 'pounds')])
>>> df_multi_level_cols1 = pd.DataFrame([[1, 2], [2, 4]],
...                                     index=['cat', 'dog'],
...                                     columns=multicol1)

---->   pandas.MultiIndex; pandas.DataFrame

--------------------------------------
ID: 8438 --> 2
>>> multicol2 = pd.MultiIndex.from_tuples([('weight', 'kg'),
...                                        ('height', 'm')])
>>> df_multi_level_cols2 = pd.DataFrame([[1.0, 2.0], [3.0, 4.0]],
...                                     index=['cat', 'dog'],
...                                     columns=multicol2)

---->   pandas.MultiIndex; pandas.DataFrame

--------------------------------------
ID: 8441 --> 1
>>> df_multi_level_cols3 = pd.DataFrame([[None, 1.0], [2.0, 3.0]],
...                                     index=['cat', 'dog'],
...                                     columns=multicol2)

---->   pandas.DataFrame

--------------------------------------
ID: 8443 --> 1
>>> df_empty = pd.DataFrame({'A' : []})
>>> df_empty
Empty DataFrame
Columns: [A]
Index: []
>>> df_empty.empty
True

---->   pandas.DataFrame

--------------------------------------
ID: 8444 --> 1
>>> df = pd.DataFrame({'A' : [np.nan]})
>>> df
    A
0 NaN
>>> df.empty
False
>>> df.dropna().empty
True

---->   pandas.DataFrame

--------------------------------------
ID: 8445 --> 1
>>> ser_empty = pd.Series({'A' : []})
>>> ser_empty
A    []
dtype: object
>>> ser_empty.empty
False
>>> ser_empty = pd.Series()
>>> ser_empty.empty
True

---->   pandas.Series

--------------------------------------
ID: 8446 --> 1
>>> df = pd.DataFrame(dict(age=[5, 6, np.NaN],
...                        born=[pd.NaT, pd.Timestamp('1939-05-27'),
...                              pd.Timestamp('1940-04-25')],
...                        name=['Alfred', 'Batman', ''],
...                        toy=[None, 'Batmobile', 'Joker']))
>>> df
   age       born    name        toy
0  5.0        NaT  Alfred       None
1  6.0 1939-05-27  Batman  Batmobile
2  NaN 1940-04-25              Joker

---->   pandas.DataFrame

--------------------------------------
ID: 8447 --> 1
>>> df.notna()
     age   born  name    toy
0   True  False  True  False
1   True   True  True   True
2  False   True  True   True

---->   DataFrame.notna

--------------------------------------
ID: 8448 --> 1
>>> ser = pd.Series([5, 6, np.NaN])
>>> ser
0    5.0
1    6.0
2    NaN
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 8449 --> 1
>>> ser.notna()
0     True
1     True
2    False
dtype: bool

---->   Series.notna

--------------------------------------
ID: 8450 --> 2
>>> df = pd.DataFrame({'num_legs': [4, 2], 'num_wings': [0, 2]},
...                   index=['dog', 'hawk'])
>>> df
      num_legs  num_wings
dog          4          0
hawk         2          2
>>> for row in df.itertuples():
...     print(row)
...
Pandas(Index='dog', num_legs=4, num_wings=0)
Pandas(Index='hawk', num_legs=2, num_wings=2)

---->   pandas.DataFrame; DataFrame.itertuples

--------------------------------------
ID: 8451 --> 1
>>> for row in df.itertuples(index=False):
...     print(row)
...
Pandas(num_legs=4, num_wings=0)
Pandas(num_legs=2, num_wings=2)

---->   DataFrame.itertuples

--------------------------------------
ID: 8452 --> 1
>>> for row in df.itertuples(name='Animal'):
...     print(row)
...
Animal(Index='dog', num_legs=4, num_wings=0)
Animal(Index='hawk', num_legs=2, num_wings=2)

---->   DataFrame.itertuples

--------------------------------------
ID: 8453 --> 1
>>> df = pd.DataFrame({'temp_c': [17.0, 25.0]},
...                   index=['Portland', 'Berkeley'])
>>> df
          temp_c
Portland    17.0
Berkeley    25.0

---->   pandas.DataFrame

--------------------------------------
ID: 8454 --> 1
>>> df.assign(temp_f=lambda x: x.temp_c * 9 / 5 + 32)
          temp_c  temp_f
Portland    17.0    62.6
Berkeley    25.0    77.0

---->   DataFrame.assign

--------------------------------------
ID: 8455 --> 1
>>> df.assign(temp_f=df['temp_c'] * 9 / 5 + 32)
          temp_c  temp_f
Portland    17.0    62.6
Berkeley    25.0    77.0

---->   DataFrame.assign

--------------------------------------
ID: 8456 --> 1
>>> df.assign(temp_f=lambda x: x['temp_c'] * 9 / 5 + 32,
...           temp_k=lambda x: (x['temp_f'] + 459.67) * 5 / 9)
          temp_c  temp_f  temp_k
Portland    17.0    62.6  290.15
Berkeley    25.0    77.0  298.15

---->   DataFrame.assign

--------------------------------------
ID: 8457 --> 1
>>> s = pd.Series([1, 2, 3, 4])
>>> s
0    1
1    2
2    3
3    4
dtype: int64

---->   pandas.Series

--------------------------------------
ID: 8458 --> 1
>>> s.add_suffix('_item')
0_item    1
1_item    2
2_item    3
3_item    4
dtype: int64

---->   Series.add_suffix

--------------------------------------
ID: 8459 --> 1
>>> df = pd.DataFrame({'A': [1, 2, 3, 4], 'B': [3, 4, 5, 6]})
>>> df
   A  B
0  1  3
1  2  4
2  3  5
3  4  6

---->   pandas.DataFrame

--------------------------------------
ID: 8460 --> 1
>>> df.add_suffix('_col')
     A_col  B_col
0       1       3
1       2       4
2       3       5
3       4       6

---->   DataFrame.add_suffix

--------------------------------------
ID: 8461 --> 2
>>> df = pd.DataFrame({
...     'length': [1.5, 0.5, 1.2, 0.9, 3],
...     'width': [0.7, 0.2, 0.15, 0.2, 1.1]
...     }, index=['pig', 'rabbit', 'duck', 'chicken', 'horse'])
>>> hist = df.hist(bins=3)

---->   pandas.DataFrame; DataFrame.hist

--------------------------------------
ID: 8462 --> 1
>>> pd.Series([], dtype="float64").prod()
1.0

---->   pandas.Series

--------------------------------------
ID: 8463 --> 1
>>> pd.Series([], dtype="float64").prod(min_count=1)
nan

---->   pandas.Series

--------------------------------------
ID: 8464 --> 1
>>> pd.Series([np.nan]).prod()
1.0

---->   pandas.Series

--------------------------------------
ID: 8465 --> 1
>>> pd.Series([np.nan]).prod(min_count=1)
nan

---->   pandas.Series

--------------------------------------
ID: 8466 --> 1
>>> df = pd.DataFrame({'A': ['a', 'b', 'c', 'd', 'e'],
...                    'B': ['f', 'g', 'h', 'i', 'j'],
...                    'C': ['k', 'l', 'm', 'n', 'o']},
...                   index=[1, 2, 3, 4, 5])
>>> df
   A  B  C
1  a  f  k
2  b  g  l
3  c  h  m
4  d  i  n
5  e  j  o

---->   pandas.DataFrame

--------------------------------------
ID: 8467 --> 1
>>> df.truncate(before=2, after=4)
   A  B  C
2  b  g  l
3  c  h  m
4  d  i  n

---->   DataFrame.truncate

--------------------------------------
ID: 8468 --> 1
>>> df.truncate(before="A", after="B", axis="columns")
   A  B
1  a  f
2  b  g
3  c  h
4  d  i
5  e  j

---->   DataFrame.truncate

--------------------------------------
ID: 8470 --> 2
>>> dates = pd.date_range('2016-01-01', '2016-02-01', freq='s')
>>> df = pd.DataFrame(index=dates, data={'A': 1})
>>> df.tail()
                     A
2016-01-31 23:59:56  1
2016-01-31 23:59:57  1
2016-01-31 23:59:58  1
2016-01-31 23:59:59  1
2016-02-01 00:00:00  1

---->   pandas.DataFrame; DataFrame.tail

--------------------------------------
ID: 8471 --> 1
>>> df.truncate(before=pd.Timestamp('2016-01-05'),
...             after=pd.Timestamp('2016-01-10')).tail()
                     A
2016-01-09 23:59:56  1
2016-01-09 23:59:57  1
2016-01-09 23:59:58  1
2016-01-09 23:59:59  1
2016-01-10 00:00:00  1

---->   DataFrame.truncate

--------------------------------------
ID: 8472 --> 1
>>> df.truncate('2016-01-05', '2016-01-10').tail()
                     A
2016-01-09 23:59:56  1
2016-01-09 23:59:57  1
2016-01-09 23:59:58  1
2016-01-09 23:59:59  1
2016-01-10 00:00:00  1

---->   DataFrame.truncate

--------------------------------------
ID: 8474 --> 1
>>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})
>>> df.shape
(2, 2)

---->   pandas.DataFrame

--------------------------------------
ID: 8475 --> 1
>>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4],
...                    'col3': [5, 6]})
>>> df.shape
(2, 3)

---->   pandas.DataFrame

--------------------------------------
ID: 8476 --> 1
>>> df = pd.DataFrame({'cost': [250, 150, 100],
...                    'revenue': [100, 250, 300]},
...                   index=['A', 'B', 'C'])
>>> df
   cost  revenue
A   250      100
B   150      250
C   100      300

---->   pandas.DataFrame

--------------------------------------
ID: 8477 --> 1
>>> df.eq(100)
    cost  revenue
A  False     True
B  False    False
C   True    False

---->   DataFrame.eq

--------------------------------------
ID: 8478 --> 1
>>> df != pd.Series([100, 250], index=["cost", "revenue"])
    cost  revenue
A   True     True
B   True    False
C  False     True

---->   pandas.Series

--------------------------------------
ID: 8479 --> 2
>>> df.ne(pd.Series([100, 300], index=["A", "D"]), axis='index')
   cost  revenue
A  True    False
B  True     True
C  True     True
D  True     True

---->   DataFrame.ne; pandas.Series

--------------------------------------
ID: 8480 --> 1
>>> df.eq([250, 250, 100], axis='index')
    cost  revenue
A   True    False
B  False     True
C   True    False

---->   DataFrame.eq

--------------------------------------
ID: 8481 --> 1
>>> other = pd.DataFrame({'revenue': [300, 250, 100, 150]},
...                      index=['A', 'B', 'C', 'D'])
>>> other
   revenue
A      300
B      250
C      100
D      150

---->   pandas.DataFrame

--------------------------------------
ID: 8482 --> 1
>>> df.gt(other)
    cost  revenue
A  False    False
B  False    False
C  False     True
D  False    False

---->   DataFrame.gt

--------------------------------------
ID: 8483 --> 1
>>> df_multindex = pd.DataFrame({'cost': [250, 150, 100, 150, 300, 220],
...                              'revenue': [100, 250, 300, 200, 175, 225]},
...                             index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'],
...                                    ['A', 'B', 'C', 'A', 'B', 'C']])
>>> df_multindex
      cost  revenue
Q1 A   250      100
   B   150      250
   C   100      300
Q2 A   150      200
   B   300      175
   C   220      225

---->   pandas.DataFrame

--------------------------------------
ID: 8484 --> 1
>>> df.le(df_multindex, level=1)
       cost  revenue
Q1 A   True     True
   B   True     True
   C   True     True
Q2 A  False     True
   B   True    False
   C   True    False

---->   DataFrame.le

--------------------------------------
ID: 8485 --> 1
>>> df = pd.DataFrame({"Person":
...                    ["John", "Myla", "Lewis", "John", "Myla"],
...                    "Age": [24., np.nan, 21., 33, 26],
...                    "Single": [False, True, True, True, False]})
>>> df
   Person   Age  Single
0    John  24.0   False
1    Myla   NaN    True
2   Lewis  21.0    True
3    John  33.0    True
4    Myla  26.0   False

---->   pandas.DataFrame

--------------------------------------
ID: 8486 --> 1
>>> df.count()
Person    5
Age       4
Single    5
dtype: int64

---->   DataFrame.count

--------------------------------------
ID: 8487 --> 1
>>> df.count(axis='columns')
0    3
1    2
2    3
3    3
4    3
dtype: int64

---->   DataFrame.count

--------------------------------------
ID: 8488 --> 2
>>> idx = pd.MultiIndex.from_arrays([
...     ['warm', 'warm', 'cold', 'cold'],
...     ['dog', 'falcon', 'fish', 'spider']],
...     names=['blooded', 'animal'])
>>> s = pd.Series([4, 2, 0, 8], name='legs', index=idx)
>>> s
blooded  animal
warm     dog       4
         falcon    2
cold     fish      0
         spider    8
Name: legs, dtype: int64

---->   pandas.MultiIndex; pandas.Series

--------------------------------------
ID: 8489 --> 1
>>> s.max()
8

---->   Series.max

--------------------------------------
ID: 8490 --> 1
>>> i = pd.date_range('2018-04-09', periods=4, freq='2D')
>>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)
>>> ts
            A
2018-04-09  1
2018-04-11  2
2018-04-13  3
2018-04-15  4

---->   pandas.DataFrame

--------------------------------------
ID: 8491 --> 1
>>> ts.first('3D')
            A
2018-04-09  1
2018-04-11  2

---->   DataFrame.first

--------------------------------------
ID: 8492 --> 1
>>> df = pd.DataFrame([[0, 2, 3], [0, 4, 1], [10, 20, 30]],
...                   index=[4, 5, 6], columns=['A', 'B', 'C'])
>>> df
    A   B   C
4   0   2   3
5   0   4   1
6  10  20  30

---->   pandas.DataFrame

--------------------------------------
ID: 8493 --> 1
>>> df = pd.DataFrame({'angles': [0, 3, 4],
...                    'degrees': [360, 180, 360]},
...                   index=['circle', 'triangle', 'rectangle'])
>>> df
           angles  degrees
circle          0      360
triangle        3      180
rectangle       4      360

---->   pandas.DataFrame

--------------------------------------
ID: 8494 --> 1
>>> df.add(1)
           angles  degrees
circle          1      361
triangle        4      181
rectangle       5      361

---->   DataFrame.add

--------------------------------------
ID: 8495 --> 1
>>> df.div(10)
           angles  degrees
circle        0.0     36.0
triangle      0.3     18.0
rectangle     0.4     36.0

---->   DataFrame.div

--------------------------------------
ID: 8496 --> 1
>>> df.rdiv(10)
             angles   degrees
circle          inf  0.027778
triangle   3.333333  0.055556
rectangle  2.500000  0.027778

---->   DataFrame.rdiv

--------------------------------------
ID: 8497 --> 1
>>> df.sub([1, 2], axis='columns')
           angles  degrees
circle         -1      358
triangle        2      178
rectangle       3      358

---->   DataFrame.sub

--------------------------------------
ID: 8498 --> 2
>>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),
...        axis='index')
           angles  degrees
circle         -1      359
triangle        2      179
rectangle       3      359

---->   DataFrame.sub; pandas.Series

--------------------------------------
ID: 8499 --> 1
>>> df.mul({'angles': 0, 'degrees': 2})
            angles  degrees
circle           0      720
triangle         0      360
rectangle        0      720

---->   DataFrame.mul

--------------------------------------
ID: 8500 --> 1
>>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')
            angles  degrees
circle           0        0
triangle         6      360
rectangle       12     1080

---->   DataFrame.mul

--------------------------------------
ID: 8501 --> 1
>>> other = pd.DataFrame({'angles': [0, 3, 4]},
...                      index=['circle', 'triangle', 'rectangle'])
>>> other
           angles
circle          0
triangle        3
rectangle       4

---->   pandas.DataFrame

--------------------------------------
ID: 8502 --> 1
>>> df.mul(other, fill_value=0)
           angles  degrees
circle          0      0.0
triangle        9      0.0
rectangle      16      0.0

---->   DataFrame.mul

--------------------------------------
ID: 8503 --> 1
>>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],
...                              'degrees': [360, 180, 360, 360, 540, 720]},
...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],
...                                    ['circle', 'triangle', 'rectangle',
...                                     'square', 'pentagon', 'hexagon']])
>>> df_multindex
             angles  degrees
A circle          0      360
  triangle        3      180
  rectangle       4      360
B square          4      360
  pentagon        5      540
  hexagon         6      720

---->   pandas.DataFrame

--------------------------------------
ID: 8504 --> 1
>>> df.div(df_multindex, level=1, fill_value=0)
             angles  degrees
A circle        NaN      1.0
  triangle      1.0      1.0
  rectangle     1.0      1.0
B square        0.0      0.0
  pentagon      0.0      0.0
  hexagon       0.0      0.0

---->   DataFrame.div

--------------------------------------
ID: 8505 --> 1
>>> df = pd.DataFrame(dict(age=[5, 6, np.NaN],
...                        born=[pd.NaT, pd.Timestamp('1939-05-27'),
...                              pd.Timestamp('1940-04-25')],
...                        name=['Alfred', 'Batman', ''],
...                        toy=[None, 'Batmobile', 'Joker']))
>>> df
   age       born    name        toy
0  5.0        NaT  Alfred       None
1  6.0 1939-05-27  Batman  Batmobile
2  NaN 1940-04-25              Joker

---->   pandas.DataFrame

--------------------------------------
ID: 8506 --> 1
>>> df.notna()
     age   born  name    toy
0   True  False  True  False
1   True   True  True   True
2  False   True  True   True

---->   DataFrame.notna

--------------------------------------
ID: 8507 --> 1
>>> ser = pd.Series([5, 6, np.NaN])
>>> ser
0    5.0
1    6.0
2    NaN
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 8508 --> 1
>>> ser.notna()
0     True
1     True
2    False
dtype: bool

---->   Series.notna

--------------------------------------
ID: 8509 --> 2
>>> index = ["a", "b", "c", "d", "e"]
>>> columns = ["one", "two", "three", "four"]
>>> df1 = pd.DataFrame(np.arange(20).reshape(5, 4), index=index, columns=columns)
>>> df2 = pd.DataFrame(np.arange(16).reshape(4, 4), index=index[:4], columns=columns)
>>> df1.corrwith(df2)
one      1.0
two      1.0
three    1.0
four     1.0
dtype: float64

---->   pandas.DataFrame; DataFrame.corrwith

--------------------------------------
ID: 8510 --> 1
>>> df2.corrwith(df1, axis=1)
a    1.0
b    1.0
c    1.0
d    1.0
e    NaN
dtype: float64

---->   DataFrame.corrwith

--------------------------------------
ID: 8511 --> 1
>>> df = pd.DataFrame({'A': range(1, 6),
...                    'B': range(10, 0, -2),
...                    'C C': range(10, 5, -1)})
>>> df
   A   B  C C
0  1  10   10
1  2   8    9
2  3   6    8
3  4   4    7
4  5   2    6
>>> df.query('A > B')
   A  B  C C
4  5  2    6

---->   pandas.DataFrame

--------------------------------------
ID: 8513 --> 1
>>> df = pd.DataFrame({'age':    [ 3,  29],
...                    'height': [94, 170],
...                    'weight': [31, 115]})
>>> df
   age  height  weight
0    3      94      31
1   29     170     115
>>> df.dtypes
age       int64
height    int64
weight    int64
dtype: object
>>> df.values
array([[  3,  94,  31],
       [ 29, 170, 115]])

---->   pandas.DataFrame

--------------------------------------
ID: 8514 --> 1
>>> df2 = pd.DataFrame([('parrot',   24.0, 'second'),
...                     ('lion',     80.5, 1),
...                     ('monkey', np.nan, None)],
...                   columns=('name', 'max_speed', 'rank'))
>>> df2.dtypes
name          object
max_speed    float64
rank          object
dtype: object
>>> df2.values
array([['parrot', 24.0, 'second'],
       ['lion', 80.5, 1],
       ['monkey', nan, None]], dtype=object)

---->   pandas.DataFrame

--------------------------------------
ID: 8515 --> 3
>>> s = pd.Series(
...     [1],
...     index=pd.DatetimeIndex(['2018-09-15 01:30:00']),
... )
>>> s.tz_localize('CET')
2018-09-15 01:30:00+02:00    1
dtype: int64

---->   pandas.Series; pandas.DatetimeIndex; Series.tz_localize

--------------------------------------
ID: 8516 --> 3
>>> s = pd.Series([1],
...     index=pd.DatetimeIndex(['2018-09-15 01:30:00+02:00']))
>>> s.tz_localize(None)
2018-09-15 01:30:00    1
dtype: int64

---->   pandas.Series; pandas.DatetimeIndex; Series.tz_localize

--------------------------------------
ID: 8517 --> 3
>>> s = pd.Series(range(7),
...               index=pd.DatetimeIndex(['2018-10-28 01:30:00',
...                                       '2018-10-28 02:00:00',
...                                       '2018-10-28 02:30:00',
...                                       '2018-10-28 02:00:00',
...                                       '2018-10-28 02:30:00',
...                                       '2018-10-28 03:00:00',
...                                       '2018-10-28 03:30:00']))
>>> s.tz_localize('CET', ambiguous='infer')
2018-10-28 01:30:00+02:00    0
2018-10-28 02:00:00+02:00    1
2018-10-28 02:30:00+02:00    2
2018-10-28 02:00:00+01:00    3
2018-10-28 02:30:00+01:00    4
2018-10-28 03:00:00+01:00    5
2018-10-28 03:30:00+01:00    6
dtype: int64

---->   pandas.Series; pandas.DatetimeIndex; Series.tz_localize

--------------------------------------
ID: 8518 --> 3
>>> s = pd.Series(range(3),
...               index=pd.DatetimeIndex(['2018-10-28 01:20:00',
...                                       '2018-10-28 02:36:00',
...                                       '2018-10-28 03:46:00']))
>>> s.tz_localize('CET', ambiguous=np.array([True, True, False]))
2018-10-28 01:20:00+02:00    0
2018-10-28 02:36:00+02:00    1
2018-10-28 03:46:00+01:00    2
dtype: int64

---->   pandas.Series; pandas.DatetimeIndex; Series.tz_localize

--------------------------------------
ID: 8519 --> 3
>>> s = pd.Series(range(2),
...               index=pd.DatetimeIndex(['2015-03-29 02:30:00',
...                                       '2015-03-29 03:30:00']))
>>> s.tz_localize('Europe/Warsaw', nonexistent='shift_forward')
2015-03-29 03:00:00+02:00    0
2015-03-29 03:30:00+02:00    1
dtype: int64
>>> s.tz_localize('Europe/Warsaw', nonexistent='shift_backward')
2015-03-29 01:59:59.999999999+01:00    0
2015-03-29 03:30:00+02:00              1
dtype: int64
>>> s.tz_localize('Europe/Warsaw', nonexistent=pd.Timedelta('1H'))
2015-03-29 03:30:00+02:00    0
2015-03-29 03:30:00+02:00    1
dtype: int64

---->   pandas.Series; pandas.DatetimeIndex; Series.tz_localize

--------------------------------------
ID: 8520 --> 1
>>> df = pd.DataFrame({'num_legs': [2, 4], 'num_wings': [2, 0]},
...                   index=['falcon', 'dog'])
>>> df
        num_legs  num_wings
falcon         2          2
dog            4          0

---->   pandas.DataFrame

--------------------------------------
ID: 8521 --> 1
>>> df.isin([0, 2])
        num_legs  num_wings
falcon      True       True
dog        False       True

---->   DataFrame.isin

--------------------------------------
ID: 8522 --> 1
>>> ~df.isin([0, 2])
        num_legs  num_wings
falcon     False      False
dog         True      False

---->   DataFrame.isin

--------------------------------------
ID: 8523 --> 1
>>> df.isin({'num_wings': [0, 3]})
        num_legs  num_wings
falcon     False      False
dog        False       True

---->   DataFrame.isin

--------------------------------------
ID: 8524 --> 2
>>> other = pd.DataFrame({'num_legs': [8, 3], 'num_wings': [0, 2]},
...                      index=['spider', 'falcon'])
>>> df.isin(other)
        num_legs  num_wings
falcon     False       True
dog        False      False

---->   pandas.DataFrame; DataFrame.isin

--------------------------------------
ID: 8525 --> 2
>>> df = pd.DataFrame({'A': range(3), 'B': range(1, 4)})
>>> df
   A  B
0  0  1
1  1  2
2  2  3
>>> df.transform(lambda x: x + 1)
   A  B
0  1  2
1  2  3
2  3  4

---->   pandas.DataFrame; DataFrame.transform

--------------------------------------
ID: 8526 --> 2
>>> s = pd.Series(range(3))
>>> s
0    0
1    1
2    2
dtype: int64
>>> s.transform([np.sqrt, np.exp])
       sqrt        exp
0  0.000000   1.000000
1  1.000000   2.718282
2  1.414214   7.389056

---->   pandas.Series; Series.transform

--------------------------------------
ID: 8527 --> 2
>>> df = pd.DataFrame({
...     "Date": [
...         "2015-05-08", "2015-05-07", "2015-05-06", "2015-05-05",
...         "2015-05-08", "2015-05-07", "2015-05-06", "2015-05-05"],
...     "Data": [5, 8, 6, 1, 50, 100, 60, 120],
... })
>>> df
         Date  Data
0  2015-05-08     5
1  2015-05-07     8
2  2015-05-06     6
3  2015-05-05     1
4  2015-05-08    50
5  2015-05-07   100
6  2015-05-06    60
7  2015-05-05   120
>>> df.groupby('Date')['Data'].transform('sum')
0     55
1    108
2     66
3    121
4     55
5    108
6     66
7    121
Name: Data, dtype: int64

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 8528 --> 2
>>> df = pd.DataFrame({
...     "c": [1, 1, 1, 2, 2, 2, 2],
...     "type": ["m", "n", "o", "m", "m", "n", "n"]
... })
>>> df
   c type
0  1    m
1  1    n
2  1    o
3  2    m
4  2    m
5  2    n
6  2    n
>>> df['size'] = df.groupby('c')['type'].transform(len)
>>> df
   c type size
0  1    m    3
1  1    n    3
2  1    o    3
3  2    m    4
4  2    m    4
5  2    n    4
6  2    n    4

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 8529 --> 1
>>> df = pd.DataFrame({'consumption': [10.51, 103.11, 55.48],
...                     'co2_emissions': [37.2, 19.66, 1712]},
...                   index=['Pork', 'Wheat Products', 'Beef'])

---->   pandas.DataFrame

--------------------------------------
ID: 8530 --> 1
>>> df.idxmax()
consumption     Wheat Products
co2_emissions             Beef
dtype: object

---->   DataFrame.idxmax

--------------------------------------
ID: 8531 --> 1
>>> df.idxmax(axis="columns")
Pork              co2_emissions
Wheat Products     consumption
Beef              co2_emissions
dtype: object

---->   DataFrame.idxmax

--------------------------------------
ID: 8532 --> 2
>>> df = pd.DataFrame({
...     'sales': [3, 2, 3, 9, 10, 6],
...     'signups': [5, 5, 6, 12, 14, 13],
...     'visits': [20, 42, 28, 62, 81, 50],
... }, index=pd.date_range(start='2018/01/01', end='2018/07/01',
...                        freq='M'))
>>> ax = df.plot.area()

---->   pandas.DataFrame; DataFrame.plot

--------------------------------------
ID: 8533 --> 1
>>> ax = df.plot.area(stacked=False)

---->   DataFrame.plot

--------------------------------------
ID: 8534 --> 1
>>> ax = df.plot.area(y='sales')

---->   DataFrame.plot

--------------------------------------
ID: 8535 --> 2
>>> df = pd.DataFrame({
...     'sales': [3, 2, 3],
...     'visits': [20, 42, 28],
...     'day': [1, 2, 3],
... })
>>> ax = df.plot.area(x='day')

---->   pandas.DataFrame; DataFrame.plot

--------------------------------------
ID: 8536 --> 2
>>> df = pd.DataFrame({'A': [4, 5, 6], 'B': [4, 1, 1]})
>>> df.nunique()
A    3
B    2
dtype: int64

---->   pandas.DataFrame; DataFrame.nunique

--------------------------------------
ID: 8537 --> 1
>>> df.nunique(axis=1)
0    1
1    2
2    2
dtype: int64

---->   DataFrame.nunique

--------------------------------------
ID: 8538 --> 1
>>> df = pd.DataFrame({
...     'col1': ['A', 'A', 'B', np.nan, 'D', 'C'],
...     'col2': [2, 1, 9, 8, 7, 4],
...     'col3': [0, 1, 9, 4, 2, 3],
...     'col4': ['a', 'B', 'c', 'D', 'e', 'F']
... })
>>> df
  col1  col2  col3 col4
0    A     2     0    a
1    A     1     1    B
2    B     9     9    c
3  NaN     8     4    D
4    D     7     2    e
5    C     4     3    F

---->   pandas.DataFrame

--------------------------------------
ID: 8544 --> 1
>>> df = pd.DataFrame({
...    "time": ['0hr', '128hr', '72hr', '48hr', '96hr'],
...    "value": [10, 20, 30, 40, 50]
... })
>>> df
    time  value
0    0hr     10
1  128hr     20
2   72hr     30
3   48hr     40
4   96hr     50
>>> from natsort import index_natsorted
>>> df.sort_values(
...     by="time",
...     key=lambda x: np.argsort(index_natsorted(df["time"]))
... )
    time  value
0    0hr     10
3   48hr     40
2   72hr     30
4   96hr     50
1  128hr     20

---->   pandas.DataFrame

--------------------------------------
ID: 8545 --> 2
>>> df1 = pd.DataFrame({'A': [None, 0], 'B': [None, 4]})
>>> df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})
>>> df1.combine_first(df2)
     A    B
0  1.0  3.0
1  0.0  4.0

---->   pandas.DataFrame; DataFrame.combine_first

--------------------------------------
ID: 8546 --> 2
>>> df1 = pd.DataFrame({'A': [None, 0], 'B': [4, None]})
>>> df2 = pd.DataFrame({'B': [3, 3], 'C': [1, 1]}, index=[1, 2])
>>> df1.combine_first(df2)
     A    B    C
0  NaN  4.0  NaN
1  0.0  3.0  1.0
2  NaN  3.0  1.0

---->   pandas.DataFrame; DataFrame.combine_first

--------------------------------------
ID: 8547 --> 2
>>> df = pd.DataFrame({'Animal': ['Falcon', 'Falcon',
...                               'Parrot', 'Parrot'],
...                    'Max Speed': [380., 370., 24., 26.]})
>>> df
   Animal  Max Speed
0  Falcon      380.0
1  Falcon      370.0
2  Parrot       24.0
3  Parrot       26.0
>>> df.groupby(['Animal']).mean()
        Max Speed
Animal
Falcon      375.0
Parrot       25.0

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 8548 --> 3
>>> arrays = [['Falcon', 'Falcon', 'Parrot', 'Parrot'],
...           ['Captive', 'Wild', 'Captive', 'Wild']]
>>> index = pd.MultiIndex.from_arrays(arrays, names=('Animal', 'Type'))
>>> df = pd.DataFrame({'Max Speed': [390., 350., 30., 20.]},
...                   index=index)
>>> df
                Max Speed
Animal Type
Falcon Captive      390.0
       Wild         350.0
Parrot Captive       30.0
       Wild          20.0
>>> df.groupby(level=0).mean()
        Max Speed
Animal
Falcon      370.0
Parrot       25.0
>>> df.groupby(level="Type").mean()
         Max Speed
Type
Captive      210.0
Wild         185.0

---->   pandas.MultiIndex; pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 8549 --> 1
>>> l = [[1, 2, 3], [1, None, 4], [2, 1, 3], [1, 2, 2]]
>>> df = pd.DataFrame(l, columns=["a", "b", "c"])

---->   pandas.DataFrame

--------------------------------------
ID: 8550 --> 1
>>> df.groupby(by=["b"]).sum()
    a   c
b
1.0 2   3
2.0 2   5

---->   DataFrame.groupby

--------------------------------------
ID: 8551 --> 1
>>> df.groupby(by=["b"], dropna=False).sum()
    a   c
b
1.0 2   3
2.0 2   5
NaN 1   4

---->   DataFrame.groupby

--------------------------------------
ID: 8552 --> 1
>>> l = [["a", 12, 12], [None, 12.3, 33.], ["b", 12.3, 123], ["a", 1, 1]]
>>> df = pd.DataFrame(l, columns=["a", "b", "c"])

---->   pandas.DataFrame

--------------------------------------
ID: 8553 --> 1
>>> df.groupby(by="a").sum()
    b     c
a
a   13.0   13.0
b   12.3  123.0

---->   DataFrame.groupby

--------------------------------------
ID: 8554 --> 1
>>> df.groupby(by="a", dropna=False).sum()
    b     c
a
a   13.0   13.0
b   12.3  123.0
NaN 12.3   33.0

---->   DataFrame.groupby

--------------------------------------
ID: 8555 --> 2
>>> df = pd.DataFrame({'Animal': ['Falcon', 'Falcon',
...                               'Parrot', 'Parrot'],
...                    'Max Speed': [380., 370., 24., 26.]})
>>> df.groupby("Animal", group_keys=True).apply(lambda x: x)
          Animal  Max Speed
Animal
Falcon 0  Falcon      380.0
       1  Falcon      370.0
Parrot 2  Parrot       24.0
       3  Parrot       26.0

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 8556 --> 1
>>> df.groupby("Animal", group_keys=False).apply(lambda x: x)
   Animal  Max Speed
0  Falcon      380.0
1  Falcon      370.0
2  Parrot       24.0
3  Parrot       26.0

---->   DataFrame.groupby

--------------------------------------
ID: 8557 --> 2
>>> s = pd.Series([1, 2, 2.5, 3, 3.5, 4, 5])
>>> ax = s.plot.kde()

---->   pandas.Series; Series.plot

--------------------------------------
ID: 8558 --> 1
>>> ax = s.plot.kde(bw_method=0.3)

---->   Series.plot

--------------------------------------
ID: 8559 --> 1
>>> ax = s.plot.kde(bw_method=3)

---->   Series.plot

--------------------------------------
ID: 8560 --> 1
>>> ax = s.plot.kde(ind=[1, 2, 3, 4, 5])

---->   Series.plot

--------------------------------------
ID: 8561 --> 2
>>> df = pd.DataFrame({
...     'x': [1, 2, 2.5, 3, 3.5, 4, 5],
...     'y': [4, 4, 4.5, 5, 5.5, 6, 6],
... })
>>> ax = df.plot.kde()

---->   pandas.DataFrame; DataFrame.plot

--------------------------------------
ID: 8562 --> 1
>>> ax = df.plot.kde(bw_method=0.3)

---->   DataFrame.plot

--------------------------------------
ID: 8563 --> 1
>>> ax = df.plot.kde(bw_method=3)

---->   DataFrame.plot

--------------------------------------
ID: 8564 --> 1
>>> ax = df.plot.kde(ind=[1, 2, 3, 4, 5, 6])

---->   DataFrame.plot

--------------------------------------
ID: 8565 --> 1
>>> df = pd.DataFrame({'angles': [0, 3, 4],
...                    'degrees': [360, 180, 360]},
...                   index=['circle', 'triangle', 'rectangle'])
>>> df
           angles  degrees
circle          0      360
triangle        3      180
rectangle       4      360

---->   pandas.DataFrame

--------------------------------------
ID: 8566 --> 1
>>> df.add(1)
           angles  degrees
circle          1      361
triangle        4      181
rectangle       5      361

---->   DataFrame.add

--------------------------------------
ID: 8567 --> 1
>>> df.div(10)
           angles  degrees
circle        0.0     36.0
triangle      0.3     18.0
rectangle     0.4     36.0

---->   DataFrame.div

--------------------------------------
ID: 8568 --> 1
>>> df.rdiv(10)
             angles   degrees
circle          inf  0.027778
triangle   3.333333  0.055556
rectangle  2.500000  0.027778

---->   DataFrame.rdiv

--------------------------------------
ID: 8569 --> 1
>>> df.sub([1, 2], axis='columns')
           angles  degrees
circle         -1      358
triangle        2      178
rectangle       3      358

---->   DataFrame.sub

--------------------------------------
ID: 8570 --> 2
>>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),
...        axis='index')
           angles  degrees
circle         -1      359
triangle        2      179
rectangle       3      359

---->   DataFrame.sub; pandas.Series

--------------------------------------
ID: 8571 --> 1
>>> df.mul({'angles': 0, 'degrees': 2})
            angles  degrees
circle           0      720
triangle         0      360
rectangle        0      720

---->   DataFrame.mul

--------------------------------------
ID: 8572 --> 1
>>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')
            angles  degrees
circle           0        0
triangle         6      360
rectangle       12     1080

---->   DataFrame.mul

--------------------------------------
ID: 8573 --> 1
>>> other = pd.DataFrame({'angles': [0, 3, 4]},
...                      index=['circle', 'triangle', 'rectangle'])
>>> other
           angles
circle          0
triangle        3
rectangle       4

---->   pandas.DataFrame

--------------------------------------
ID: 8574 --> 1
>>> df.mul(other, fill_value=0)
           angles  degrees
circle          0      0.0
triangle        9      0.0
rectangle      16      0.0

---->   DataFrame.mul

--------------------------------------
ID: 8575 --> 1
>>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],
...                              'degrees': [360, 180, 360, 360, 540, 720]},
...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],
...                                    ['circle', 'triangle', 'rectangle',
...                                     'square', 'pentagon', 'hexagon']])
>>> df_multindex
             angles  degrees
A circle          0      360
  triangle        3      180
  rectangle       4      360
B square          4      360
  pentagon        5      540
  hexagon         6      720

---->   pandas.DataFrame

--------------------------------------
ID: 8576 --> 1
>>> df.div(df_multindex, level=1, fill_value=0)
             angles  degrees
A circle        NaN      1.0
  triangle      1.0      1.0
  rectangle     1.0      1.0
B square        0.0      0.0
  pentagon      0.0      0.0
  hexagon       0.0      0.0

---->   DataFrame.div

--------------------------------------
ID: 8577 --> 1
>>> import scipy.sparse
>>> mat = scipy.sparse.eye(3)
>>> pd.DataFrame.sparse.from_spmatrix(mat)
     0    1    2
0  1.0  0.0  0.0
1  0.0  1.0  0.0
2  0.0  0.0  1.0

---->   pandas.DataFrame

--------------------------------------
ID: 8578 --> 1
>>> df = pd.DataFrame({'foo': ['one', 'one', 'one', 'two', 'two',
...                            'two'],
...                    'bar': ['A', 'B', 'C', 'A', 'B', 'C'],
...                    'baz': [1, 2, 3, 4, 5, 6],
...                    'zoo': ['x', 'y', 'z', 'q', 'w', 't']})
>>> df
    foo   bar  baz  zoo
0   one   A    1    x
1   one   B    2    y
2   one   C    3    z
3   two   A    4    q
4   two   B    5    w
5   two   C    6    t

---->   pandas.DataFrame

--------------------------------------
ID: 8582 --> 1
>>> df = pd.DataFrame({
...        "lev1": [1, 1, 1, 2, 2, 2],
...        "lev2": [1, 1, 2, 1, 1, 2],
...        "lev3": [1, 2, 1, 2, 1, 2],
...        "lev4": [1, 2, 3, 4, 5, 6],
...        "values": [0, 1, 2, 3, 4, 5]})
>>> df
    lev1 lev2 lev3 lev4 values
0   1    1    1    1    0
1   1    1    2    2    1
2   1    2    1    3    2
3   2    1    2    4    3
4   2    1    1    5    4
5   2    2    2    6    5

---->   pandas.DataFrame

--------------------------------------
ID: 8585 --> 1
>>> df = pd.DataFrame({"foo": ['one', 'one', 'two', 'two'],
...                    "bar": ['A', 'A', 'B', 'C'],
...                    "baz": [1, 2, 3, 4]})
>>> df
   foo bar  baz
0  one   A    1
1  one   A    2
2  two   B    3
3  two   C    4

---->   pandas.DataFrame

--------------------------------------
ID: 8587 --> 1
>>> df1 = pd.DataFrame({'lkey': ['foo', 'bar', 'baz', 'foo'],
...                     'value': [1, 2, 3, 5]})
>>> df2 = pd.DataFrame({'rkey': ['foo', 'bar', 'baz', 'foo'],
...                     'value': [5, 6, 7, 8]})
>>> df1
    lkey value
0   foo      1
1   bar      2
2   baz      3
3   foo      5
>>> df2
    rkey value
0   foo      5
1   bar      6
2   baz      7
3   foo      8

---->   pandas.DataFrame

--------------------------------------
ID: 8591 --> 1
>>> df1 = pd.DataFrame({'a': ['foo', 'bar'], 'b': [1, 2]})
>>> df2 = pd.DataFrame({'a': ['foo', 'baz'], 'c': [3, 4]})
>>> df1
      a  b
0   foo  1
1   bar  2
>>> df2
      a  c
0   foo  3
1   baz  4

---->   pandas.DataFrame

--------------------------------------
ID: 8594 --> 1
>>> df1 = pd.DataFrame({'left': ['foo', 'bar']})
>>> df2 = pd.DataFrame({'right': [7, 8]})
>>> df1
    left
0   foo
1   bar
>>> df2
    right
0   7
1   8

---->   pandas.DataFrame

--------------------------------------
ID: 8596 --> 2
>>> df = pd.DataFrame(dict(A=[1, 1, 3], B=[5, None, 6], C=[1, 2, 3]))
>>> df.groupby("A").last()
     B  C
A
1  5.0  2
3  6.0  3

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 8597 --> 1
>>> s = pd.Series([1, 2, 3, 4, 5],
...               index=pd.date_range('20130101', periods=5, freq='s'))
>>> s
2013-01-01 00:00:00    1
2013-01-01 00:00:01    2
2013-01-01 00:00:02    3
2013-01-01 00:00:03    4
2013-01-01 00:00:04    5
Freq: S, dtype: int64

---->   pandas.Series

--------------------------------------
ID: 8598 --> 1
>>> r = s.resample('2s')

---->   Series.resample

--------------------------------------
ID: 8601 --> 2
>>> r.agg({'result': lambda x: x.mean() / x.std(),
...        'total': np.sum})
                       result  total
2013-01-01 00:00:00  2.121320      3
2013-01-01 00:00:02  4.949747      7
2013-01-01 00:00:04       NaN      5

---->   Series.mean; Series.std

--------------------------------------
ID: 8603 --> 1
>>> s = pd.Series([1, 2],
...               index=pd.date_range('20180101',
...                                   periods=2,
...                                   freq='1h'))
>>> s
2018-01-01 00:00:00    1
2018-01-01 01:00:00    2
Freq: H, dtype: int64

---->   pandas.Series

--------------------------------------
ID: 8604 --> 3
>>> resampled = s.resample('15min')
>>> resampled.transform(lambda x: (x - x.mean()) / x.std())
2018-01-01 00:00:00   NaN
2018-01-01 01:00:00   NaN
Freq: H, dtype: float64

---->   Series.resample; Series.mean; Series.std

--------------------------------------
ID: 8605 --> 1
>>> h(g(f(df.groupby('group')), arg1=a), arg2=b, arg3=c)  

---->   DataFrame.groupby

--------------------------------------
ID: 8606 --> 1
>>> (df.groupby('group')
...    .pipe(f)
...    .pipe(g, arg1=a)
...    .pipe(h, arg2=b, arg3=c))  

---->   DataFrame.groupby

--------------------------------------
ID: 8607 --> 1
>>> df = pd.DataFrame({'A': [1, 2, 3, 4]},
...                   index=pd.date_range('2012-08-02', periods=4))
>>> df
            A
2012-08-02  1
2012-08-03  2
2012-08-04  3
2012-08-05  4

---->   pandas.DataFrame

--------------------------------------
ID: 8608 --> 3
>>> df.resample('2D').pipe(lambda x: x.max() - x.min())
            A
2012-08-02  1
2012-08-04  1

---->   DataFrame.resample; Series.max; Series.min

--------------------------------------
ID: 8609 --> 3
>>> df = pd.DataFrame(dict(A=[1, 1, 3], B=[None, 5, 6], C=[1, 2, 3],
...                        D=['3/11/2000', '3/12/2000', '3/13/2000']))
>>> df['D'] = pd.to_datetime(df['D'])
>>> df.groupby("A").first()
     B  C          D
A
1  5.0  1 2000-03-11
3  6.0  3 2000-03-13
>>> df.groupby("A").first(min_count=2)
    B    C          D
A
1 NaN  1.0 2000-03-11
3 NaN  NaN        NaT
>>> df.groupby("A").first(numeric_only=True)
     B  C
A
1  5.0  1
3  6.0  3

---->   pandas.DataFrame; pandas.to_datetime; DataFrame.groupby

--------------------------------------
ID: 8610 --> 1
>>> s = pd.Series([1, 2, 3],
...               index=pd.date_range('20180101', periods=3, freq='h'))
>>> s
2018-01-01 00:00:00    1
2018-01-01 01:00:00    2
2018-01-01 02:00:00    3
Freq: H, dtype: int64

---->   pandas.Series

--------------------------------------
ID: 8611 --> 1
>>> s.resample('30min').bfill()
2018-01-01 00:00:00    1
2018-01-01 00:30:00    2
2018-01-01 01:00:00    2
2018-01-01 01:30:00    3
2018-01-01 02:00:00    3
Freq: 30T, dtype: int64

---->   Series.resample

--------------------------------------
ID: 8612 --> 1
>>> s.resample('15min').bfill(limit=2)
2018-01-01 00:00:00    1.0
2018-01-01 00:15:00    NaN
2018-01-01 00:30:00    2.0
2018-01-01 00:45:00    2.0
2018-01-01 01:00:00    2.0
2018-01-01 01:15:00    NaN
2018-01-01 01:30:00    3.0
2018-01-01 01:45:00    3.0
2018-01-01 02:00:00    3.0
Freq: 15T, dtype: float64

---->   Series.resample

--------------------------------------
ID: 8613 --> 1
>>> df = pd.DataFrame({'a': [2, np.nan, 6], 'b': [1, 3, 5]},
...                   index=pd.date_range('20180101', periods=3,
...                                       freq='h'))
>>> df
                       a  b
2018-01-01 00:00:00  2.0  1
2018-01-01 01:00:00  NaN  3
2018-01-01 02:00:00  6.0  5

---->   pandas.DataFrame

--------------------------------------
ID: 8614 --> 1
>>> df.resample('30min').bfill()
                       a  b
2018-01-01 00:00:00  2.0  1
2018-01-01 00:30:00  NaN  3
2018-01-01 01:00:00  NaN  3
2018-01-01 01:30:00  6.0  5
2018-01-01 02:00:00  6.0  5

---->   DataFrame.resample

--------------------------------------
ID: 8615 --> 1
>>> df.resample('15min').bfill(limit=2)
                       a    b
2018-01-01 00:00:00  2.0  1.0
2018-01-01 00:15:00  NaN  NaN
2018-01-01 00:30:00  NaN  3.0
2018-01-01 00:45:00  NaN  3.0
2018-01-01 01:00:00  NaN  3.0
2018-01-01 01:15:00  NaN  NaN
2018-01-01 01:30:00  6.0  5.0
2018-01-01 01:45:00  6.0  5.0
2018-01-01 02:00:00  6.0  5.0

---->   DataFrame.resample

--------------------------------------
ID: 8616 --> 1
>>> s = pd.Series([1, 2, 3],
...               index=pd.date_range('20180101', periods=3, freq='h'))
>>> s
2018-01-01 00:00:00    1
2018-01-01 01:00:00    2
2018-01-01 02:00:00    3
Freq: H, dtype: int64

---->   pandas.Series

--------------------------------------
ID: 8617 --> 1
>>> s.resample("30min").asfreq()
2018-01-01 00:00:00    1.0
2018-01-01 00:30:00    NaN
2018-01-01 01:00:00    2.0
2018-01-01 01:30:00    NaN
2018-01-01 02:00:00    3.0
Freq: 30T, dtype: float64

---->   Series.resample

--------------------------------------
ID: 8618 --> 1
>>> s.resample('30min').fillna("backfill")
2018-01-01 00:00:00    1
2018-01-01 00:30:00    2
2018-01-01 01:00:00    2
2018-01-01 01:30:00    3
2018-01-01 02:00:00    3
Freq: 30T, dtype: int64

---->   Series.resample

--------------------------------------
ID: 8619 --> 1
>>> s.resample('15min').fillna("backfill", limit=2)
2018-01-01 00:00:00    1.0
2018-01-01 00:15:00    NaN
2018-01-01 00:30:00    2.0
2018-01-01 00:45:00    2.0
2018-01-01 01:00:00    2.0
2018-01-01 01:15:00    NaN
2018-01-01 01:30:00    3.0
2018-01-01 01:45:00    3.0
2018-01-01 02:00:00    3.0
Freq: 15T, dtype: float64

---->   Series.resample

--------------------------------------
ID: 8620 --> 1
>>> s.resample('30min').fillna("pad")
2018-01-01 00:00:00    1
2018-01-01 00:30:00    1
2018-01-01 01:00:00    2
2018-01-01 01:30:00    2
2018-01-01 02:00:00    3
Freq: 30T, dtype: int64

---->   Series.resample

--------------------------------------
ID: 8621 --> 1
>>> s.resample('30min').fillna("nearest")
2018-01-01 00:00:00    1
2018-01-01 00:30:00    2
2018-01-01 01:00:00    2
2018-01-01 01:30:00    3
2018-01-01 02:00:00    3
Freq: 30T, dtype: int64

---->   Series.resample

--------------------------------------
ID: 8622 --> 1
>>> sm = pd.Series([1, None, 3],
...               index=pd.date_range('20180101', periods=3, freq='h'))
>>> sm
2018-01-01 00:00:00    1.0
2018-01-01 01:00:00    NaN
2018-01-01 02:00:00    3.0
Freq: H, dtype: float64

---->   pandas.Series

--------------------------------------
ID: 8626 --> 1
>>> df = pd.DataFrame({'a': [2, np.nan, 6], 'b': [1, 3, 5]},
...                   index=pd.date_range('20180101', periods=3,
...                                       freq='h'))
>>> df
                       a  b
2018-01-01 00:00:00  2.0  1
2018-01-01 01:00:00  NaN  3
2018-01-01 02:00:00  6.0  5

---->   pandas.DataFrame

--------------------------------------
ID: 8627 --> 1
>>> df.resample('30min').fillna("bfill")
                       a  b
2018-01-01 00:00:00  2.0  1
2018-01-01 00:30:00  NaN  3
2018-01-01 01:00:00  NaN  3
2018-01-01 01:30:00  6.0  5
2018-01-01 02:00:00  6.0  5

---->   DataFrame.resample

--------------------------------------
ID: 8628 --> 1
>>> s = pd.Series([1, 2, 3, 4, 5],
...               index=pd.date_range('20130101', periods=5, freq='s'))
>>> s
2013-01-01 00:00:00    1
2013-01-01 00:00:01    2
2013-01-01 00:00:02    3
2013-01-01 00:00:03    4
2013-01-01 00:00:04    5
Freq: S, dtype: int64

---->   pandas.Series

--------------------------------------
ID: 8629 --> 1
>>> r = s.resample('2s')

---->   Series.resample

--------------------------------------
ID: 8632 --> 2
>>> r.agg({'result': lambda x: x.mean() / x.std(),
...        'total': np.sum})
                       result  total
2013-01-01 00:00:00  2.121320      3
2013-01-01 00:00:02  4.949747      7
2013-01-01 00:00:04       NaN      5

---->   Series.mean; Series.std

--------------------------------------
ID: 8634 --> 1
>>> s = pd.Series([1, 2],
...               index=pd.date_range('20180101',
...                                   periods=2,
...                                   freq='1h'))
>>> s
2018-01-01 00:00:00    1
2018-01-01 01:00:00    2
Freq: H, dtype: int64

---->   pandas.Series

--------------------------------------
ID: 8635 --> 1
>>> s.resample('15min').nearest()
2018-01-01 00:00:00    1
2018-01-01 00:15:00    1
2018-01-01 00:30:00    2
2018-01-01 00:45:00    2
2018-01-01 01:00:00    2
Freq: 15T, dtype: int64

---->   Series.resample

--------------------------------------
ID: 8636 --> 1
>>> s.resample('15min').nearest(limit=1)
2018-01-01 00:00:00    1.0
2018-01-01 00:15:00    1.0
2018-01-01 00:30:00    NaN
2018-01-01 00:45:00    2.0
2018-01-01 01:00:00    2.0
Freq: 15T, dtype: float64

---->   Series.resample

--------------------------------------
ID: 8637 --> 1
>>> s = pd.Series([0, 1, np.nan, 3])
>>> s
0    0.0
1    1.0
2    NaN
3    3.0
dtype: float64
>>> s.interpolate()
0    0.0
1    1.0
2    2.0
3    3.0
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 8638 --> 1
>>> s = pd.Series([np.nan, "single_one", np.nan,
...                "fill_two_more", np.nan, np.nan, np.nan,
...                4.71, np.nan])
>>> s
0              NaN
1       single_one
2              NaN
3    fill_two_more
4              NaN
5              NaN
6              NaN
7             4.71
8              NaN
dtype: object
>>> s.interpolate(method='pad', limit=2)
0              NaN
1       single_one
2       single_one
3    fill_two_more
4    fill_two_more
5    fill_two_more
6              NaN
7             4.71
8             4.71
dtype: object

---->   pandas.Series

--------------------------------------
ID: 8639 --> 1
>>> s = pd.Series([0, 2, np.nan, 8])
>>> s.interpolate(method='polynomial', order=2)
0    0.000000
1    2.000000
2    4.666667
3    8.000000
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 8640 --> 1
>>> df = pd.DataFrame([(0.0, np.nan, -1.0, 1.0),
...                    (np.nan, 2.0, np.nan, np.nan),
...                    (2.0, 3.0, np.nan, 9.0),
...                    (np.nan, 4.0, -4.0, 16.0)],
...                   columns=list('abcd'))
>>> df
     a    b    c     d
0  0.0  NaN -1.0   1.0
1  NaN  2.0  NaN   NaN
2  2.0  3.0  NaN   9.0
3  NaN  4.0 -4.0  16.0
>>> df.interpolate(method='linear', limit_direction='forward', axis=0)
     a    b    c     d
0  0.0  NaN -1.0   1.0
1  1.0  2.0 -2.0   5.0
2  2.0  3.0 -3.0   9.0
3  2.0  4.0 -4.0  16.0

---->   pandas.DataFrame

--------------------------------------
ID: 9339 --> 1
>>> pd.Series(['a', 'b']).dt
Traceback (most recent call last):
...
AttributeError: Can only use .dt accessor with datetimelike values

---->   pandas.Series

--------------------------------------
ID: 9341 --> 1
In [1]: ds = pd.DataFrame({"longitude": np.linspace(0, 10),
   ...:                    "latitude": np.linspace(0, 20)})
In [2]: ds.geo.center
Out[2]: (5.0, 10.0)
In [3]: ds.geo.plot()  # plots data on a map

---->   pandas.DataFrame

--------------------------------------
ID: 9342 --> 1
>>> spacing = np.linspace(-9 * np.pi, 9 * np.pi, num=1000)
>>> s = pd.Series(0.7 * np.random.rand(1000) + 0.3 * np.sin(spacing))
>>> pd.plotting.autocorrelation_plot(s)


---->   pandas.Series

--------------------------------------
ID: 9349 --> 1
>>> pd.IntervalIndex.from_breaks([0, 1, 2, 3])
IntervalIndex([(0, 1], (1, 2], (2, 3]],
              dtype='interval[int64, right]')

---->   pandas.IntervalIndex

--------------------------------------
ID: 9350 --> 1
>>> arrays = [[1, 1, 2, 2], ['red', 'blue', 'red', 'blue']]
>>> pd.MultiIndex.from_arrays(arrays, names=('number', 'color'))
MultiIndex([(1,  'red'),
            (1, 'blue'),
            (2,  'red'),
            (2, 'blue')],
           names=['number', 'color'])

---->   pandas.MultiIndex

--------------------------------------
ID: 9351 --> 3
>>> idx = pd.Index(['car', 'bike', 'train', 'tractor'])
>>> idx
Index(['car', 'bike', 'train', 'tractor'], dtype='object')
>>> idx.where(idx.isin(['car', 'train']), 'other')
Index(['car', 'other', 'train', 'other'], dtype='object')

---->   pandas.Index; Index.where; Index.isin

--------------------------------------
ID: 9352 --> 1
>>> mi = pd.MultiIndex.from_arrays(
... [[1, 2], [3, 4], [5, 6]], names=['x', 'y', 'z'])
>>> mi
MultiIndex([(1, 3, 5),
            (2, 4, 6)],
           names=['x', 'y', 'z'])

---->   pandas.MultiIndex

--------------------------------------
ID: 9357 --> 1
>>> c = pd.Categorical(['c', 'b', 'c'])
>>> c
['c', 'b', 'c']
Categories (2, object): ['b', 'c']

---->   pandas.Categorical

--------------------------------------
ID: 9359 --> 1
>>> idx = pd.Index(['Ant', 'Bear', 'Cow'], name='animal')

---->   pandas.Index

--------------------------------------
ID: 9360 --> 1
>>> idx.to_series()
animal
Ant      Ant
Bear    Bear
Cow      Cow
Name: animal, dtype: object

---->   Index.to_series

--------------------------------------
ID: 9361 --> 1
>>> idx.to_series(index=[0, 1, 2])
0     Ant
1    Bear
2     Cow
Name: animal, dtype: object

---->   Index.to_series

--------------------------------------
ID: 9362 --> 1
>>> idx.to_series(name='zoo')
animal
Ant      Ant
Bear    Bear
Cow      Cow
Name: zoo, dtype: object

---->   Index.to_series

--------------------------------------
ID: 9363 --> 2
>>> idx = pd.Index([5.2, 6.0, np.NaN])
>>> idx
Index([5.2, 6.0, nan], dtype='float64')
>>> idx.isna()
array([False, False,  True])

---->   pandas.Index; Index.isna

--------------------------------------
ID: 9364 --> 2
>>> idx = pd.Index(['black', '', 'red', None])
>>> idx
Index(['black', '', 'red', None], dtype='object')
>>> idx.isna()
array([False, False, False,  True])

---->   pandas.Index; Index.isna

--------------------------------------
ID: 9365 --> 2
>>> idx = pd.DatetimeIndex([pd.Timestamp('1940-04-25'),
...                         pd.Timestamp(''), None, pd.NaT])
>>> idx
DatetimeIndex(['1940-04-25', 'NaT', 'NaT', 'NaT'],
              dtype='datetime64[ns]', freq=None)
>>> idx.isna()
array([False,  True,  True,  True])

---->   pandas.DatetimeIndex; Index.isna

--------------------------------------
ID: 9366 --> 2
>>> idx = pd.Index(list('abcd'))
>>> idx.slice_indexer(start='b', end='c')
slice(1, 3, None)

---->   pandas.Index; Index.slice_indexer

--------------------------------------
ID: 9367 --> 2
>>> idx = pd.MultiIndex.from_arrays([list('abcd'), list('efgh')])
>>> idx.slice_indexer(start='b', end=('c', 'g'))
slice(1, 3, None)

---->   pandas.MultiIndex; Index.slice_indexer

--------------------------------------
ID: 9368 --> 1
>>> ser = pd.Series([1, 2, 3])
>>> ser
0    1
1    2
2    3
dtype: int64

---->   pandas.Series

--------------------------------------
ID: 9369 --> 1
>>> ser.searchsorted(4)
3

---->   Series.searchsorted

--------------------------------------
ID: 9370 --> 1
>>> ser.searchsorted([0, 4])
array([0, 3])

---->   Series.searchsorted

--------------------------------------
ID: 9371 --> 1
>>> ser.searchsorted([1, 3], side='left')
array([0, 2])

---->   Series.searchsorted

--------------------------------------
ID: 9372 --> 1
>>> ser.searchsorted([1, 3], side='right')
array([1, 3])

---->   Series.searchsorted

--------------------------------------
ID: 9373 --> 2
>>> ser = pd.Series(pd.to_datetime(['3/11/2000', '3/12/2000', '3/13/2000']))
>>> ser
0   2000-03-11
1   2000-03-12
2   2000-03-13
dtype: datetime64[ns]

---->   pandas.Series; pandas.to_datetime

--------------------------------------
ID: 9374 --> 1
>>> ser.searchsorted('3/14/2000')
3

---->   Series.searchsorted

--------------------------------------
ID: 9375 --> 1
>>> ser = pd.Categorical(
...     ['apple', 'bread', 'bread', 'cheese', 'milk'], ordered=True
... )
>>> ser
['apple', 'bread', 'bread', 'cheese', 'milk']
Categories (4, object): ['apple' < 'bread' < 'cheese' < 'milk']

---->   pandas.Categorical

--------------------------------------
ID: 9376 --> 1
>>> ser.searchsorted('bread')
1

---->   Series.searchsorted

--------------------------------------
ID: 9377 --> 1
>>> ser.searchsorted(['bread'], side='right')
array([3])

---->   Series.searchsorted

--------------------------------------
ID: 9378 --> 1
>>> ser = pd.Series([2, 1, 3])
>>> ser
0    2
1    1
2    3
dtype: int64

---->   pandas.Series

--------------------------------------
ID: 9379 --> 1
>>> ser.searchsorted(1)  
0  # wrong result, correct would be 1

---->   Series.searchsorted

--------------------------------------
ID: 9380 --> 2
>>> df = pd.DataFrame({'dates': pd.date_range("2017-03-30",
...                    periods=4)})
>>> df.assign(quarter=df.dates.dt.quarter,
...           is_quarter_end=df.dates.dt.is_quarter_end)
       dates  quarter    is_quarter_end
0 2017-03-30        1             False
1 2017-03-31        1              True
2 2017-04-01        2             False
3 2017-04-02        2             False

---->   pandas.DataFrame; DataFrame.assign

--------------------------------------
ID: 9384 --> 1
>>> index = pd.IntervalIndex.from_tuples([(0, 2), (1, 3), (4, 5)])
>>> index
IntervalIndex([(0, 2], (1, 3], (4, 5]],
      dtype='interval[int64, right]')
>>> index.is_overlapping
True

---->   pandas.IntervalIndex

--------------------------------------
ID: 9385 --> 1
>>> index = pd.interval_range(0, 3, closed='both')
>>> index
IntervalIndex([[0, 1], [1, 2], [2, 3]],
      dtype='interval[int64, both]')
>>> index.is_overlapping
True

---->   pandas.interval_range

--------------------------------------
ID: 9386 --> 1
>>> index = pd.interval_range(0, 3, closed='left')
>>> index
IntervalIndex([[0, 1), [1, 2), [2, 3)],
      dtype='interval[int64, left]')
>>> index.is_overlapping
False

---->   pandas.interval_range

--------------------------------------
ID: 9387 --> 2
>>> index = pd.Index([0, 1, 2])
>>> index.any()
True

---->   pandas.Index; Index.any

--------------------------------------
ID: 9388 --> 2
>>> index = pd.Index([0, 0, 0])
>>> index.any()
False

---->   pandas.Index; Index.any

--------------------------------------
ID: 9389 --> 1
>>> pd.Index([3, 2, 1]).is_monotonic_decreasing
True
>>> pd.Index([3, 2, 2]).is_monotonic_decreasing
True
>>> pd.Index([3, 1, 2]).is_monotonic_decreasing
False

---->   pandas.Index

--------------------------------------
ID: 9390 --> 1
>>> mi = pd.MultiIndex.from_arrays([[1, 2], [3, 4]], names=['x', 'y'])
>>> mi
MultiIndex([(1, 3),
            (2, 4)],
           names=['x', 'y'])

---->   pandas.MultiIndex

--------------------------------------
ID: 9394 --> 1
>>> pd.Series(rng).dt.ceil("H")
0   2018-01-01 12:00:00
1   2018-01-01 12:00:00
2   2018-01-01 13:00:00
dtype: datetime64[ns]

---->   pandas.Series

--------------------------------------
ID: 9395 --> 1
>>> rng_tz = pd.DatetimeIndex(["2021-10-31 01:30:00"], tz="Europe/Amsterdam")

---->   pandas.DatetimeIndex

--------------------------------------
ID: 9396 --> 1
>>> rng_tz.ceil("H", ambiguous=False)
DatetimeIndex(['2021-10-31 02:00:00+01:00'],
              dtype='datetime64[ns, Europe/Amsterdam]', freq=None)

---->   DatetimeIndex.ceil

--------------------------------------
ID: 9397 --> 1
>>> rng_tz.ceil("H", ambiguous=True)
DatetimeIndex(['2021-10-31 02:00:00+02:00'],
              dtype='datetime64[ns, Europe/Amsterdam]', freq=None)

---->   DatetimeIndex.ceil

--------------------------------------
ID: 9398 --> 1
>>> s = pd.Series([1, 3, 5, 7, 7])
>>> s
0    1
1    3
2    5
3    7
4    7
dtype: int64

---->   pandas.Series

--------------------------------------
ID: 9399 --> 1
>>> s.nunique()
4

---->   Series.nunique

--------------------------------------
ID: 9400 --> 2
>>> idx = pd.Index(['2013-12-31', '2014-01-02', '2014-01-03'])
>>> idx.asof('2014-01-01')
'2013-12-31'

---->   pandas.Index; Index.asof

--------------------------------------
ID: 9401 --> 1
>>> idx.asof('2014-01-02')
'2014-01-02'

---->   Index.asof

--------------------------------------
ID: 9402 --> 1
>>> idx.asof('1999-01-02')
nan

---->   Index.asof

--------------------------------------
ID: 9403 --> 1
>>> idx_not_sorted = pd.Index(['2013-12-31', '2015-01-02',
...                            '2014-01-03'])
>>> idx_not_sorted.asof('2013-12-31')
Traceback (most recent call last):
ValueError: index must be monotonic increasing or decreasing

---->   pandas.Index

--------------------------------------
ID: 9404 --> 1
>>> c = pd.Categorical(['a', 'c', 'b', 'c', 'd'])
>>> c
['a', 'c', 'b', 'c', 'd']
Categories (4, object): ['a', 'b', 'c', 'd']

---->   pandas.Categorical

--------------------------------------
ID: 9407 --> 1
>>> pd.Index([1, 2, 3])
Index([1, 2, 3], dtype='int64')

---->   pandas.Index

--------------------------------------
ID: 9408 --> 1
>>> pd.Index(list('abc'))
Index(['a', 'b', 'c'], dtype='object')

---->   pandas.Index

--------------------------------------
ID: 9409 --> 1
>>> pd.Index([1, 2, 3], dtype="uint8")
Index([1, 2, 3], dtype='uint8')

---->   pandas.Index

--------------------------------------
ID: 9410 --> 1
>>> numbers = [0, 1, 2]
>>> colors = ['green', 'purple']
>>> pd.MultiIndex.from_product([numbers, colors],
...                            names=['number', 'color'])
MultiIndex([(0,  'green'),
            (0, 'purple'),
            (1,  'green'),
            (1, 'purple'),
            (2,  'green'),
            (2, 'purple')],
           names=['number', 'color'])

---->   pandas.MultiIndex

--------------------------------------
ID: 9411 --> 1
>>> mi = pd.MultiIndex.from_arrays([['a'], ['b']])
>>> mi
MultiIndex([('a', 'b')],
           )
>>> mi.append(mi)
MultiIndex([('a', 'b'), ('a', 'b')],
           )

---->   pandas.MultiIndex

--------------------------------------
ID: 9412 --> 2
>>> index = pd.Index(['c', 'a', 'b'])
>>> index.get_indexer(['a', 'b', 'x'])
array([ 1,  2, -1])

---->   pandas.Index; Index.get_indexer

--------------------------------------
ID: 9413 --> 1
>>> arrays = [[1, 1, 2, 2], ['red', 'blue', 'red', 'blue']]
>>> pd.MultiIndex.from_arrays(arrays, names=('number', 'color'))
MultiIndex([(1,  'red'),
            (1, 'blue'),
            (2,  'red'),
            (2, 'blue')],
           names=['number', 'color'])

---->   pandas.MultiIndex

--------------------------------------
ID: 9414 --> 1
>>> mi = pd.MultiIndex.from_arrays((list('abc'), list('def')))
>>> mi.names = ['level_1', 'level_2']

---->   pandas.MultiIndex

--------------------------------------
ID: 9416 --> 1
>>> pd.MultiIndex.from_arrays([[1, None, 2], [3, 4, 5]]).dtypes
level_0    int64
level_1    int64
dtype: object
>>> pd.MultiIndex.from_arrays([[1, None, 2], [3, 4, 5]]).get_level_values(0)
Index([1.0, nan, 2.0], dtype='float64')

---->   pandas.MultiIndex

--------------------------------------
ID: 9417 --> 1
>>> mi = pd.MultiIndex.from_arrays([list('abb'), list('def')])

---->   pandas.MultiIndex

--------------------------------------
ID: 9421 --> 2
>>> idx1 = pd.Index([2, 1, 3, 4])
>>> idx2 = pd.Index([3, 4, 5, 6])
>>> idx1.difference(idx2)
Index([1, 2], dtype='int64')
>>> idx1.difference(idx2, sort=False)
Index([2, 1], dtype='int64')

---->   pandas.Index; Index.difference

--------------------------------------
ID: 9422 --> 1
>>> dates = pd.Series(pd.date_range("2017-12-30", periods=3))
>>> dates
0   2017-12-30
1   2017-12-31
2   2018-01-01
dtype: datetime64[ns]

---->   pandas.Series

--------------------------------------
ID: 9425 --> 1
>>> datetime_series = pd.Series(
...     pd.date_range("2000-01-01", periods=3, freq="ns")
... )
>>> datetime_series
0   2000-01-01 00:00:00.000000000
1   2000-01-01 00:00:00.000000001
2   2000-01-01 00:00:00.000000002
dtype: datetime64[ns]
>>> datetime_series.dt.nanosecond
0       0
1       1
2       2
dtype: int32

---->   pandas.Series

--------------------------------------
ID: 9426 --> 1
>>> pd.CategoricalIndex(["a", "b", "c", "a", "b", "c"])
CategoricalIndex(['a', 'b', 'c', 'a', 'b', 'c'],
                 categories=['a', 'b', 'c'], ordered=False, dtype='category')

---->   pandas.CategoricalIndex

--------------------------------------
ID: 9427 --> 2
>>> c = pd.Categorical(["a", "b", "c", "a", "b", "c"])
>>> pd.CategoricalIndex(c)
CategoricalIndex(['a', 'b', 'c', 'a', 'b', 'c'],
                 categories=['a', 'b', 'c'], ordered=False, dtype='category')

---->   pandas.Categorical; pandas.CategoricalIndex

--------------------------------------
ID: 9428 --> 1
>>> ci = pd.CategoricalIndex(
...     ["a", "b", "c", "a", "b", "c"], ordered=True, categories=["c", "b", "a"]
... )
>>> ci
CategoricalIndex(['a', 'b', 'c', 'a', 'b', 'c'],
                 categories=['c', 'b', 'a'], ordered=True, dtype='category')
>>> ci.min()
'c'

---->   pandas.CategoricalIndex

--------------------------------------
ID: 9432 --> 2
>>> s = pd.to_datetime(pd.Series(['2018-10-28 01:30:00',
...                               '2018-10-28 02:00:00',
...                               '2018-10-28 02:30:00',
...                               '2018-10-28 02:00:00',
...                               '2018-10-28 02:30:00',
...                               '2018-10-28 03:00:00',
...                               '2018-10-28 03:30:00']))
>>> s.dt.tz_localize('CET', ambiguous='infer')
0   2018-10-28 01:30:00+02:00
1   2018-10-28 02:00:00+02:00
2   2018-10-28 02:30:00+02:00
3   2018-10-28 02:00:00+01:00
4   2018-10-28 02:30:00+01:00
5   2018-10-28 03:00:00+01:00
6   2018-10-28 03:30:00+01:00
dtype: datetime64[ns, CET]

---->   pandas.to_datetime; pandas.Series

--------------------------------------
ID: 9433 --> 2
>>> s = pd.to_datetime(pd.Series(['2018-10-28 01:20:00',
...                               '2018-10-28 02:36:00',
...                               '2018-10-28 03:46:00']))
>>> s.dt.tz_localize('CET', ambiguous=np.array([True, True, False]))
0   2018-10-28 01:20:00+02:00
1   2018-10-28 02:36:00+02:00
2   2018-10-28 03:46:00+01:00
dtype: datetime64[ns, CET]

---->   pandas.to_datetime; pandas.Series

--------------------------------------
ID: 9434 --> 2
>>> s = pd.to_datetime(pd.Series(['2015-03-29 02:30:00',
...                               '2015-03-29 03:30:00']))
>>> s.dt.tz_localize('Europe/Warsaw', nonexistent='shift_forward')
0   2015-03-29 03:00:00+02:00
1   2015-03-29 03:30:00+02:00
dtype: datetime64[ns, Europe/Warsaw]

---->   pandas.to_datetime; pandas.Series

--------------------------------------
ID: 9437 --> 1
>>> pd.Index([1, 2, 3]).all()
True

---->   pandas.Index

--------------------------------------
ID: 9438 --> 1
>>> pd.Index([0, 1, 2]).all()
False

---->   pandas.Index

--------------------------------------
ID: 9439 --> 2
>>> idx1 = pd.Index([1, 2, 3, 4])
>>> idx2 = pd.Index([3, 4, 5, 6])
>>> idx1.intersection(idx2)
Index([3, 4], dtype='int64')

---->   pandas.Index; Index.intersection

--------------------------------------
ID: 9440 --> 1
>>> c = pd.Categorical(['a', 'c', 'b', 'c', 'd'])
>>> c
['a', 'c', 'b', 'c', 'd']
Categories (4, object): ['a', 'b', 'c', 'd']

---->   pandas.Categorical

--------------------------------------
ID: 9442 --> 2
>>> idx1 = pd.Index([1, 2, 3])
>>> idx1
Index([1, 2, 3], dtype='int64')
>>> idx1.equals(pd.Index([1, 2, 3]))
True

---->   pandas.Index; Index.equals

--------------------------------------
ID: 9443 --> 1
>>> idx2 = pd.Index(["1", "2", "3"])
>>> idx2
Index(['1', '2', '3'], dtype='object')

---->   pandas.Index

--------------------------------------
ID: 9444 --> 1
>>> idx1.equals(idx2)
False

---->   Index.equals

--------------------------------------
ID: 9445 --> 2
>>> ascending_idx = pd.Index([1, 2, 3])
>>> ascending_idx
Index([1, 2, 3], dtype='int64')
>>> descending_idx = pd.Index([3, 2, 1])
>>> descending_idx
Index([3, 2, 1], dtype='int64')
>>> ascending_idx.equals(descending_idx)
False

---->   pandas.Index; Index.equals

--------------------------------------
ID: 9446 --> 2
>>> int64_idx = pd.Index([1, 2, 3], dtype='int64')
>>> int64_idx
Index([1, 2, 3], dtype='int64')
>>> uint64_idx = pd.Index([1, 2, 3], dtype='uint64')
>>> uint64_idx
Index([1, 2, 3], dtype='uint64')
>>> int64_idx.equals(uint64_idx)
True

---->   pandas.Index; Index.equals

--------------------------------------
ID: 9448 --> 1
>>> pd.Series(rng).dt.round("H")
0   2018-01-01 12:00:00
1   2018-01-01 12:00:00
2   2018-01-01 12:00:00
dtype: datetime64[ns]

---->   pandas.Series

--------------------------------------
ID: 9449 --> 1
>>> rng_tz = pd.DatetimeIndex(["2021-10-31 03:30:00"], tz="Europe/Amsterdam")

---->   pandas.DatetimeIndex

--------------------------------------
ID: 9450 --> 1
>>> rng_tz.floor("2H", ambiguous=False)
DatetimeIndex(['2021-10-31 02:00:00+01:00'],
              dtype='datetime64[ns, Europe/Amsterdam]', freq=None)

---->   DatetimeIndex.floor

--------------------------------------
ID: 9451 --> 1
>>> rng_tz.floor("2H", ambiguous=True)
DatetimeIndex(['2021-10-31 02:00:00+02:00'],
              dtype='datetime64[ns, Europe/Amsterdam]', freq=None)

---->   DatetimeIndex.floor

--------------------------------------
ID: 9452 --> 2
>>> idx = pd.Index(['Ant', 'Bear', 'Cow'], name='animal')
>>> idx.to_frame()
       animal
animal
Ant       Ant
Bear     Bear
Cow       Cow

---->   pandas.Index; Index.to_frame

--------------------------------------
ID: 9453 --> 1
>>> idx.to_frame(index=False)
    animal
0   Ant
1  Bear
2   Cow

---->   Index.to_frame

--------------------------------------
ID: 9454 --> 1
>>> idx.to_frame(index=False, name='zoo')
    zoo
0   Ant
1  Bear
2   Cow

---->   Index.to_frame

--------------------------------------
ID: 9455 --> 2
>>> idx = pd.Index(list('abcd'))
>>> idx.slice_locs(start='b', end='c')
(1, 3)

---->   pandas.Index; Index.slice_locs

--------------------------------------
ID: 9456 --> 1
>>> s = pd.Series(pd.date_range(start='2018-01', freq='M', periods=3))
>>> s
0   2018-01-31
1   2018-02-28
2   2018-03-31
dtype: datetime64[ns]
>>> s.dt.month_name()
0     January
1    February
2       March
dtype: object

---->   pandas.Series

--------------------------------------
ID: 9459 --> 1
>>> idx = pd.MultiIndex.from_tuples(
...     [
...         (1, "one"),
...         (1, "two"),
...         (2, "one"),
...         (2, "two"),
...         (3, "one"),
...         (3, "two")
...     ],
...     names=["foo", "bar"]
... )
>>> idx
MultiIndex([(1, 'one'),
    (1, 'two'),
    (2, 'one'),
    (2, 'two'),
    (3, 'one'),
    (3, 'two')],
   names=['foo', 'bar'])

---->   pandas.MultiIndex

--------------------------------------
ID: 9462 --> 1
>>> mi = pd.MultiIndex.from_arrays([['a'], ['b'], ['c']])
>>> mi
MultiIndex([('a', 'b', 'c')],
           )
>>> mi.levshape
(1, 1, 1)

---->   pandas.MultiIndex

--------------------------------------
ID: 9463 --> 2
>>> idx = pd.Index(['a', 'b', 'c'])
>>> idx.delete(1)
Index(['a', 'c'], dtype='object')

---->   pandas.Index; Index.delete

--------------------------------------
ID: 9464 --> 2
>>> idx = pd.Index(['a', 'b', 'c'])
>>> idx.delete([0, 2])
Index(['b'], dtype='object')

---->   pandas.Index; Index.delete

--------------------------------------
ID: 9465 --> 1
>>> mi = pd.MultiIndex(levels=[['a', 'b'], ['bb', 'aa']],
...                    codes=[[0, 0, 1, 1], [0, 1, 0, 1]])
>>> mi
MultiIndex([('a', 'bb'),
            ('a', 'aa'),
            ('b', 'bb'),
            ('b', 'aa')],
           )
>>> mi.swaplevel(0, 1)
MultiIndex([('bb', 'a'),
            ('aa', 'a'),
            ('bb', 'b'),
            ('aa', 'b')],
           )

---->   pandas.MultiIndex

--------------------------------------
ID: 9466 --> 1
>>> s = pd.Series(pd.date_range("2018-02-27", periods=3))
>>> s
0   2018-02-27
1   2018-02-28
2   2018-03-01
dtype: datetime64[ns]
>>> s.dt.is_month_start
0    False
1    False
2    True
dtype: bool
>>> s.dt.is_month_end
0    False
1    True
2    False
dtype: bool

---->   pandas.Series

--------------------------------------
ID: 9468 --> 1
>>> idx = pd.Index([1, 5, 7, 7])
>>> idx.is_unique
False

---->   pandas.Index

--------------------------------------
ID: 9469 --> 1
>>> idx = pd.Index([1, 5, 7])
>>> idx.is_unique
True

---->   pandas.Index

--------------------------------------
ID: 9470 --> 1
>>> idx = pd.Index(["Watermelon", "Orange", "Apple",
...                 "Watermelon"]).astype("category")
>>> idx.is_unique
False

---->   pandas.Index

--------------------------------------
ID: 9471 --> 1
>>> idx = pd.Index(["Orange", "Apple",
...                 "Watermelon"]).astype("category")
>>> idx.is_unique
True

---->   pandas.Index

--------------------------------------
ID: 9472 --> 2
>>> index = pd.Index(['c', 'b', 'a', 'b', 'b'])
>>> index.get_indexer_non_unique(['b', 'b'])
(array([1, 3, 4, 1, 3, 4]), array([], dtype=int64))

---->   pandas.Index; Index.get_indexer_non_unique

--------------------------------------
ID: 9473 --> 2
>>> index = pd.Index(['c', 'b', 'a', 'b', 'b'])
>>> index.get_indexer_non_unique(['q', 'r', 't'])
(array([-1, -1, -1]), array([0, 1, 2]))

---->   pandas.Index; Index.get_indexer_non_unique

--------------------------------------
ID: 9474 --> 2
>>> index = pd.Index(['c', 'b', 'a', 'b', 'b'])
>>> index.get_indexer_non_unique(['f', 'b', 's'])
(array([-1,  1,  3,  4, -1]), array([0, 2]))

---->   pandas.Index; Index.get_indexer_non_unique

--------------------------------------
ID: 9475 --> 2
>>> idx1 = pd.Index([1, 2, 3, 4])
>>> idx2 = pd.Index([2, 3, 4, 5])
>>> idx1.symmetric_difference(idx2)
Index([1, 5], dtype='int64')

---->   pandas.Index; Index.symmetric_difference

--------------------------------------
ID: 9476 --> 1
>>> pidx = pd.period_range('2010-01-01', '2015-01-01', freq='A')
>>> pidx
PeriodIndex(['2010', '2011', '2012', '2013', '2014', '2015'],
dtype='period[A-DEC]')

---->   pandas.period_range

--------------------------------------
ID: 9479 --> 2
>>> index = pd.Index(['c', 'a', 'b'])
>>> index.get_indexer(['a', 'b', 'x'])
array([ 1,  2, -1])

---->   pandas.Index; Index.get_indexer

--------------------------------------
ID: 9480 --> 1
>>> datetime_series = pd.Series(
...     pd.date_range("2000-01-01", periods=3, freq="us")
... )
>>> datetime_series
0   2000-01-01 00:00:00.000000
1   2000-01-01 00:00:00.000001
2   2000-01-01 00:00:00.000002
dtype: datetime64[ns]
>>> datetime_series.dt.microsecond
0       0
1       1
2       2
dtype: int32

---->   pandas.Series

--------------------------------------
ID: 9481 --> 2
>>> idx = pd.Index(['car', 'bike', 'train', 'tractor'])
>>> idx
Index(['car', 'bike', 'train', 'tractor'], dtype='object')
>>> idx.reindex(['car', 'bike'])
(Index(['car', 'bike'], dtype='object'), array([0, 1]))

---->   pandas.Index; Index.reindex

--------------------------------------
ID: 9482 --> 1
>>> idx = pd.Index(['Ant', 'Bear', 'Cow'], name='animal')

---->   pandas.Index

--------------------------------------
ID: 9483 --> 1
>>> idx.to_series()
animal
Ant      Ant
Bear    Bear
Cow      Cow
Name: animal, dtype: object

---->   Index.to_series

--------------------------------------
ID: 9484 --> 1
>>> idx.to_series(index=[0, 1, 2])
0     Ant
1    Bear
2     Cow
Name: animal, dtype: object

---->   Index.to_series

--------------------------------------
ID: 9485 --> 1
>>> idx.to_series(name='zoo')
animal
Ant      Ant
Bear    Bear
Cow      Cow
Name: zoo, dtype: object

---->   Index.to_series

--------------------------------------
ID: 9486 --> 2
>>> midx = pd.MultiIndex.from_product([['A0','A1'], ['B0','B1','B2','B3']])
>>> columns = ['foo', 'bar']
>>> dfmi = pd.DataFrame(np.arange(16).reshape((len(midx), len(columns))),
...                     index=midx, columns=columns)

---->   pandas.MultiIndex; pandas.DataFrame

--------------------------------------
ID: 9488 --> 1
>>> idx = pd.Index([1, 5, 7, 7])
>>> idx.has_duplicates
True

---->   pandas.Index

--------------------------------------
ID: 9489 --> 1
>>> idx = pd.Index([1, 5, 7])
>>> idx.has_duplicates
False

---->   pandas.Index

--------------------------------------
ID: 9490 --> 1
>>> idx = pd.Index(["Watermelon", "Orange", "Apple",
...                 "Watermelon"]).astype("category")
>>> idx.has_duplicates
True

---->   pandas.Index

--------------------------------------
ID: 9491 --> 1
>>> idx = pd.Index(["Orange", "Apple",
...                 "Watermelon"]).astype("category")
>>> idx.has_duplicates
False

---->   pandas.Index

--------------------------------------
ID: 9492 --> 1
>>> df = pd.DataFrame([['HI', 'Temp'], ['HI', 'Precip'],
...                    ['NJ', 'Temp'], ['NJ', 'Precip']],
...                   columns=['a', 'b'])
>>> df
      a       b
0    HI    Temp
1    HI  Precip
2    NJ    Temp
3    NJ  Precip

---->   pandas.DataFrame

--------------------------------------
ID: 9493 --> 1
>>> pd.MultiIndex.from_frame(df)
MultiIndex([('HI',   'Temp'),
            ('HI', 'Precip'),
            ('NJ',   'Temp'),
            ('NJ', 'Precip')],
           names=['a', 'b'])

---->   pandas.MultiIndex

--------------------------------------
ID: 9494 --> 1
>>> pd.MultiIndex.from_frame(df, names=['state', 'observation'])
MultiIndex([('HI',   'Temp'),
            ('HI', 'Precip'),
            ('NJ',   'Temp'),
            ('NJ', 'Precip')],
           names=['state', 'observation'])

---->   pandas.MultiIndex

--------------------------------------
ID: 9495 --> 1
>>> pd.Index([1, 2, 3]).is_monotonic_increasing
True
>>> pd.Index([1, 2, 2]).is_monotonic_increasing
True
>>> pd.Index([1, 3, 2]).is_monotonic_increasing
False

---->   pandas.Index

--------------------------------------
ID: 9496 --> 1
>>> mi = pd.MultiIndex.from_arrays([['a', 'b', 'c'], ['x', 'y', 'z']])
>>> mi
MultiIndex([('a', 'x'), ('b', 'y'), ('c', 'z')],
           )
>>> mi.truncate(before='a', after='b')
MultiIndex([('a', 'x'), ('b', 'y')],
           )

---->   pandas.MultiIndex

--------------------------------------
ID: 9497 --> 2
>>> idx = pd.Index([1.0, 2.0, 3.0, 4.0])
>>> idx.is_numeric()  
True

---->   pandas.Index; Index.is_numeric

--------------------------------------
ID: 9498 --> 2
>>> idx = pd.Index([1, 2, 3, 4.0])
>>> idx.is_numeric()  
True

---->   pandas.Index; Index.is_numeric

--------------------------------------
ID: 9499 --> 2
>>> idx = pd.Index([1, 2, 3, 4])
>>> idx.is_numeric()  
True

---->   pandas.Index; Index.is_numeric

--------------------------------------
ID: 9500 --> 2
>>> idx = pd.Index([1, 2, 3, 4.0, np.nan])
>>> idx.is_numeric()  
True

---->   pandas.Index; Index.is_numeric

--------------------------------------
ID: 9501 --> 2
>>> idx = pd.Index([1, 2, 3, 4.0, np.nan, "Apple"])
>>> idx.is_numeric()  
False

---->   pandas.Index; Index.is_numeric

--------------------------------------
ID: 9502 --> 1
>>> mi = pd.MultiIndex.from_arrays(
... [[1, 2], [3, 4], [5, 6]], names=['x', 'y', 'z'])
>>> mi
MultiIndex([(1, 3, 5),
            (2, 4, 6)],
           names=['x', 'y', 'z'])
>>> mi.names
FrozenList(['x', 'y', 'z'])

---->   pandas.MultiIndex

--------------------------------------
ID: 9503 --> 2
>>> idx1 = pd.Index([1, 2, 3, 4])
>>> idx2 = pd.Index([3, 4, 5, 6])
>>> idx1.union(idx2)
Index([1, 2, 3, 4, 5, 6], dtype='int64')

---->   pandas.Index; Index.union

--------------------------------------
ID: 9504 --> 2
>>> idx1 = pd.Index(['a', 'b', 'c', 'd'])
>>> idx2 = pd.Index([1, 2, 3, 4])
>>> idx1.union(idx2)
Index(['a', 'b', 'c', 'd', 1, 2, 3, 4], dtype='object')

---->   pandas.Index; Index.union

--------------------------------------
ID: 9505 --> 2
>>> idx1 = pd.MultiIndex.from_arrays(
...     [[1, 1, 2, 2], ["Red", "Blue", "Red", "Blue"]]
... )
>>> idx1
MultiIndex([(1,  'Red'),
    (1, 'Blue'),
    (2,  'Red'),
    (2, 'Blue')],
   )
>>> idx2 = pd.MultiIndex.from_arrays(
...     [[3, 3, 2, 2], ["Red", "Green", "Red", "Green"]]
... )
>>> idx2
MultiIndex([(3,   'Red'),
    (3, 'Green'),
    (2,   'Red'),
    (2, 'Green')],
   )
>>> idx1.union(idx2)
MultiIndex([(1,  'Blue'),
    (1,   'Red'),
    (2,  'Blue'),
    (2, 'Green'),
    (2,   'Red'),
    (3, 'Green'),
    (3,   'Red')],
   )
>>> idx1.union(idx2, sort=False)
MultiIndex([(1,   'Red'),
    (1,  'Blue'),
    (2,   'Red'),
    (2,  'Blue'),
    (3,   'Red'),
    (3, 'Green'),
    (2, 'Green')],
   )

---->   pandas.MultiIndex; Index.union

--------------------------------------
ID: 9506 --> 2
>>> df = pd.DataFrame({"y": [1, 2, 3]},
...                   index=pd.to_datetime(["2000-03-31 00:00:00",
...                                         "2000-05-31 00:00:00",
...                                         "2000-08-31 00:00:00"]))
>>> df.index.to_period("M")
PeriodIndex(['2000-03', '2000-05', '2000-08'],
            dtype='period[M]')

---->   pandas.DataFrame; pandas.to_datetime

--------------------------------------
ID: 9508 --> 2
>>> idx = pd.Index(['Ant', 'Bear', 'Cow'], name='animal')
>>> idx.to_frame()
       animal
animal
Ant       Ant
Bear     Bear
Cow       Cow

---->   pandas.Index; Index.to_frame

--------------------------------------
ID: 9509 --> 1
>>> idx.to_frame(index=False)
    animal
0   Ant
1  Bear
2   Cow

---->   Index.to_frame

--------------------------------------
ID: 9510 --> 1
>>> idx.to_frame(index=False, name='zoo')
    zoo
0   Ant
1  Bear
2   Cow

---->   Index.to_frame

--------------------------------------
ID: 9511 --> 1
>>> mi = pd.MultiIndex.from_arrays(
... [[1, 2], [3, 4], [5, 6]], names=['x', 'y', 'z'])
>>> mi
MultiIndex([(1, 3, 5),
            (2, 4, 6)],
           names=['x', 'y', 'z'])

---->   pandas.MultiIndex

--------------------------------------
ID: 9516 --> 2
>>> idx = pd.Index(['A', 'C', 'A', 'B'], name='score')
>>> idx.rename('grade')
Index(['A', 'C', 'A', 'B'], dtype='object', name='grade')

---->   pandas.Index; Index.rename

--------------------------------------
ID: 9517 --> 2
>>> idx = pd.MultiIndex.from_product([['python', 'cobra'],
...                                   [2018, 2019]],
...                                   names=['kind', 'year'])
>>> idx
MultiIndex([('python', 2018),
            ('python', 2019),
            ( 'cobra', 2018),
            ( 'cobra', 2019)],
           names=['kind', 'year'])
>>> idx.rename(['species', 'year'])
MultiIndex([('python', 2018),
            ('python', 2019),
            ( 'cobra', 2018),
            ( 'cobra', 2019)],
           names=['species', 'year'])
>>> idx.rename('species')
Traceback (most recent call last):
TypeError: Must pass list-like as `names`.

---->   pandas.MultiIndex; Index.rename

--------------------------------------
ID: 9518 --> 3
>>> idx = pd.Index([pd.Interval(left=0, right=5),
...                 pd.Interval(left=5, right=10)])
>>> idx.is_interval()  
True

---->   pandas.Index; pandas.Interval; Index.is_interval

--------------------------------------
ID: 9519 --> 2
>>> idx = pd.Index([1, 3, 5, 7])
>>> idx.is_interval()  
False

---->   pandas.Index; Index.is_interval

--------------------------------------
ID: 9521 --> 1
>>> pd.Series(rng).dt.round("H")
0   2018-01-01 12:00:00
1   2018-01-01 12:00:00
2   2018-01-01 12:00:00
dtype: datetime64[ns]

---->   pandas.Series

--------------------------------------
ID: 9522 --> 1
>>> rng_tz = pd.DatetimeIndex(["2021-10-31 03:30:00"], tz="Europe/Amsterdam")

---->   pandas.DatetimeIndex

--------------------------------------
ID: 9523 --> 1
>>> rng_tz.floor("2H", ambiguous=False)
DatetimeIndex(['2021-10-31 02:00:00+01:00'],
              dtype='datetime64[ns, Europe/Amsterdam]', freq=None)

---->   DatetimeIndex.floor

--------------------------------------
ID: 9524 --> 1
>>> rng_tz.floor("2H", ambiguous=True)
DatetimeIndex(['2021-10-31 02:00:00+02:00'],
              dtype='datetime64[ns, Europe/Amsterdam]', freq=None)

---->   DatetimeIndex.floor

--------------------------------------
ID: 9526 --> 1
>>> pd.Series(rng).dt.floor("H")
0   2018-01-01 11:00:00
1   2018-01-01 12:00:00
2   2018-01-01 12:00:00
dtype: datetime64[ns]

---->   pandas.Series

--------------------------------------
ID: 9527 --> 1
>>> rng_tz = pd.DatetimeIndex(["2021-10-31 03:30:00"], tz="Europe/Amsterdam")

---->   pandas.DatetimeIndex

--------------------------------------
ID: 9528 --> 1
>>> rng_tz.floor("2H", ambiguous=False)
DatetimeIndex(['2021-10-31 02:00:00+01:00'],
             dtype='datetime64[ns, Europe/Amsterdam]', freq=None)

---->   DatetimeIndex.floor

--------------------------------------
ID: 9529 --> 1
>>> rng_tz.floor("2H", ambiguous=True)
DatetimeIndex(['2021-10-31 02:00:00+02:00'],
              dtype='datetime64[ns, Europe/Amsterdam]', freq=None)

---->   DatetimeIndex.floor

--------------------------------------
ID: 9531 --> 1
>>> intervals.overlaps(pd.Interval(0.5, 1.5))
array([ True,  True, False])

---->   pandas.Interval

--------------------------------------
ID: 9532 --> 1
>>> intervals.overlaps(pd.Interval(1, 3, closed='left'))
array([ True,  True, True])

---->   pandas.Interval

--------------------------------------
ID: 9533 --> 1
>>> intervals.overlaps(pd.Interval(1, 2, closed='right'))
array([False,  True, False])

---->   pandas.Interval

--------------------------------------
ID: 9534 --> 1
>>> mi = pd.MultiIndex.from_arrays([['a'], ['b'], ['c']])
>>> mi
MultiIndex([('a', 'b', 'c')],
           )
>>> mi.copy()
MultiIndex([('a', 'b', 'c')],
           )

---->   pandas.MultiIndex

--------------------------------------
ID: 9535 --> 1
>>> s = pd.Series(pd.date_range("2018-02-27", periods=3))
>>> s
0   2018-02-27
1   2018-02-28
2   2018-03-01
dtype: datetime64[ns]
>>> s.dt.is_month_start
0    False
1    False
2    True
dtype: bool
>>> s.dt.is_month_end
0    False
1    True
2    False
dtype: bool

---->   pandas.Series

--------------------------------------
ID: 9537 --> 1
>>> mi = pd.MultiIndex.from_arrays([['a'], ['b'], ['c']])
>>> mi
MultiIndex([('a', 'b', 'c')],
           )
>>> mi.nlevels
3

---->   pandas.MultiIndex

--------------------------------------
ID: 9538 --> 1
>>> idx = pd.PeriodIndex(year=[2000, 2002], quarter=[1, 3])
>>> idx
PeriodIndex(['2000Q1', '2002Q3'], dtype='period[Q-DEC]')

---->   pandas.PeriodIndex

--------------------------------------
ID: 9539 --> 1
>>> tuples = [(1, 'red'), (1, 'blue'),
...           (2, 'red'), (2, 'blue')]
>>> pd.MultiIndex.from_tuples(tuples, names=('number', 'color'))
MultiIndex([(1,  'red'),
            (1, 'blue'),
            (2,  'red'),
            (2, 'blue')],
           names=['number', 'color'])

---->   pandas.MultiIndex

--------------------------------------
ID: 9541 --> 1
>>> idx = pd.Index(['lama', 'cow', 'lama', 'beetle', 'lama', 'hippo'])

---->   pandas.Index

--------------------------------------
ID: 9545 --> 2
>>> idx = pd.Index(['Ant', 'Bear', 'Cow'], name='animal')
>>> idx.to_frame()
       animal
animal
Ant       Ant
Bear     Bear
Cow       Cow

---->   pandas.Index; Index.to_frame

--------------------------------------
ID: 9546 --> 1
>>> idx.to_frame(index=False)
    animal
0   Ant
1  Bear
2   Cow

---->   Index.to_frame

--------------------------------------
ID: 9547 --> 1
>>> idx.to_frame(index=False, name='zoo')
    zoo
0   Ant
1  Bear
2   Cow

---->   Index.to_frame

--------------------------------------
ID: 9551 --> 2
>>> idx = pd.Index(["Apple", "Mango", "Watermelon"])
>>> idx.is_object()  
True

---->   pandas.Index; Index.is_object

--------------------------------------
ID: 9552 --> 2
>>> idx = pd.Index(["Apple", "Mango", 2.0])
>>> idx.is_object()  
True

---->   pandas.Index; Index.is_object

--------------------------------------
ID: 9553 --> 2
>>> idx = pd.Index(["Watermelon", "Orange", "Apple",
...                 "Watermelon"]).astype("category")
>>> idx.is_object()  
False

---->   pandas.Index; Index.is_object

--------------------------------------
ID: 9554 --> 2
>>> idx = pd.Index([1.0, 2.0, 3.0, 4.0])
>>> idx.is_object()  
False

---->   pandas.Index; Index.is_object

--------------------------------------
ID: 9555 --> 1
>>> codes, uniques = pd.factorize(['b', 'b', 'a', 'c', 'b'])
>>> codes
array([0, 0, 1, 2, 0])
>>> uniques
array(['b', 'a', 'c'], dtype=object)

---->   pandas.factorize

--------------------------------------
ID: 9556 --> 1
>>> codes, uniques = pd.factorize(['b', 'b', 'a', 'c', 'b'], sort=True)
>>> codes
array([1, 1, 0, 2, 1])
>>> uniques
array(['a', 'b', 'c'], dtype=object)

---->   pandas.factorize

--------------------------------------
ID: 9557 --> 1
>>> codes, uniques = pd.factorize(['b', None, 'a', 'c', 'b'])
>>> codes
array([ 0, -1,  1,  2,  0])
>>> uniques
array(['b', 'a', 'c'], dtype=object)

---->   pandas.factorize

--------------------------------------
ID: 9558 --> 2
>>> cat = pd.Categorical(['a', 'a', 'c'], categories=['a', 'b', 'c'])
>>> codes, uniques = pd.factorize(cat)
>>> codes
array([0, 0, 1])
>>> uniques
['a', 'c']
Categories (3, object): ['a', 'b', 'c']

---->   pandas.Categorical; pandas.factorize

--------------------------------------
ID: 9559 --> 2
>>> cat = pd.Series(['a', 'a', 'c'])
>>> codes, uniques = pd.factorize(cat)
>>> codes
array([0, 0, 1])
>>> uniques
Index(['a', 'c'], dtype='object')

---->   pandas.Series; pandas.factorize

--------------------------------------
ID: 9560 --> 1
>>> values = np.array([1, 2, 1, np.nan])
>>> codes, uniques = pd.factorize(values)  # default: use_na_sentinel=True
>>> codes
array([ 0,  1,  0, -1])
>>> uniques
array([1., 2.])

---->   pandas.factorize

--------------------------------------
ID: 9561 --> 1
>>> codes, uniques = pd.factorize(values, use_na_sentinel=False)
>>> codes
array([0, 1, 0, 2])
>>> uniques
array([ 1.,  2., nan])

---->   pandas.factorize

--------------------------------------
ID: 9562 --> 1
>>> pd.interval_range(start=0, end=5)
IntervalIndex([(0, 1], (1, 2], (2, 3], (3, 4], (4, 5]],
              dtype='interval[int64, right]')

---->   pandas.interval_range

--------------------------------------
ID: 9563 --> 2
>>> idx = pd.Index([True, False, True])
>>> idx.is_boolean()  
True

---->   pandas.Index; Index.is_boolean

--------------------------------------
ID: 9564 --> 2
>>> idx = pd.Index(["True", "False", "True"])
>>> idx.is_boolean()  
False

---->   pandas.Index; Index.is_boolean

--------------------------------------
ID: 9565 --> 2
>>> idx = pd.Index([True, False, "True"])
>>> idx.is_boolean()  
False

---->   pandas.Index; Index.is_boolean

--------------------------------------
ID: 9566 --> 1
>>> datetime_series = pd.Series(
...     pd.date_range("2000-01-01", periods=3, freq="h")
... )
>>> datetime_series
0   2000-01-01 00:00:00
1   2000-01-01 01:00:00
2   2000-01-01 02:00:00
dtype: datetime64[ns]
>>> datetime_series.dt.hour
0    0
1    1
2    2
dtype: int32

---->   pandas.Series

--------------------------------------
ID: 9567 --> 2
>>> idx = pd.Index([3, 2, 1])
>>> idx.max()
3

---->   pandas.Index; Index.max

--------------------------------------
ID: 9568 --> 2
>>> idx = pd.Index(['c', 'b', 'a'])
>>> idx.max()
'c'

---->   pandas.Index; Index.max

--------------------------------------
ID: 9569 --> 2
>>> idx = pd.MultiIndex.from_product([('a', 'b'), (2, 1)])
>>> idx.max()
('b', 2)

---->   pandas.MultiIndex; Index.max

--------------------------------------
ID: 9570 --> 1
>>> datetime_series = pd.Series(
...     pd.date_range("2000-01-01", periods=3, freq="s")
... )
>>> datetime_series
0   2000-01-01 00:00:00
1   2000-01-01 00:00:01
2   2000-01-01 00:00:02
dtype: datetime64[ns]
>>> datetime_series.dt.second
0    0
1    1
2    2
dtype: int32

---->   pandas.Series

--------------------------------------
ID: 9572 --> 1
>>> idx = pd.Index([1,2,3])
>>> idx
Index([1, 2, 3], dtype='int64')

---->   pandas.Index

--------------------------------------
ID: 9573 --> 1
>>> idx.isin([1, 4])
array([ True, False, False])

---->   Index.isin

--------------------------------------
ID: 9574 --> 1
>>> midx = pd.MultiIndex.from_arrays([[1,2,3],
...                                  ['red', 'blue', 'green']],
...                                  names=('number', 'color'))
>>> midx
MultiIndex([(1,   'red'),
            (2,  'blue'),
            (3, 'green')],
           names=['number', 'color'])

---->   pandas.MultiIndex

--------------------------------------
ID: 9577 --> 1
>>> dates = ['2000-03-11', '2000-03-12', '2000-03-13']
>>> dti = pd.to_datetime(dates)
>>> dti
DatetimeIndex(['2000-03-11', '2000-03-12', '2000-03-13'],
dtype='datetime64[ns]', freq=None)

---->   pandas.to_datetime

--------------------------------------
ID: 9579 --> 1
>>> mi = pd.MultiIndex.from_arrays([list('abb'), list('def')],
...                                names=['A', 'B'])

---->   pandas.MultiIndex

--------------------------------------
ID: 9583 --> 2
>>> idx = pd.Index([1, 2, 3, 4])
>>> idx.is_integer()  
True

---->   pandas.Index; Index.is_integer

--------------------------------------
ID: 9584 --> 2
>>> idx = pd.Index([1.0, 2.0, 3.0, 4.0])
>>> idx.is_integer()  
False

---->   pandas.Index; Index.is_integer

--------------------------------------
ID: 9585 --> 2
>>> idx = pd.Index(["Apple", "Mango", "Watermelon"])
>>> idx.is_integer()  
False

---->   pandas.Index; Index.is_integer

--------------------------------------
ID: 9586 --> 1
>>> mi = pd.MultiIndex.from_arrays([[0, 0], [2, 1]])
>>> mi
MultiIndex([(0, 2),
            (0, 1)],
           )

---->   pandas.MultiIndex

--------------------------------------
ID: 9591 --> 2
>>> df = pd.DataFrame({'dates': pd.date_range("2017-03-30",
...                   periods=4)})
>>> df.assign(quarter=df.dates.dt.quarter,
...           is_quarter_start=df.dates.dt.is_quarter_start)
       dates  quarter  is_quarter_start
0 2017-03-30        1             False
1 2017-03-31        1             False
2 2017-04-01        2              True
3 2017-04-02        2             False

---->   pandas.DataFrame; DataFrame.assign

--------------------------------------
ID: 9594 --> 2
>>> idx = pd.Index(['a', 'b', 'c'])
>>> idx
Index(['a', 'b', 'c'], dtype='object')
>>> idx.repeat(2)
Index(['a', 'a', 'b', 'b', 'c', 'c'], dtype='object')
>>> idx.repeat([1, 2, 3])
Index(['a', 'b', 'b', 'c', 'c', 'c'], dtype='object')

---->   pandas.Index; Index.repeat

--------------------------------------
ID: 9595 --> 1
>>> mi = pd.MultiIndex.from_product([range(2), list('ab')])
>>> mi
MultiIndex([(0, 'a'),
            (0, 'b'),
            (1, 'a'),
            (1, 'b')],
           )

---->   pandas.MultiIndex

--------------------------------------
ID: 9599 --> 1
>>> pd.Series(rng).dt.ceil("H")
0   2018-01-01 12:00:00
1   2018-01-01 12:00:00
2   2018-01-01 13:00:00
dtype: datetime64[ns]

---->   pandas.Series

--------------------------------------
ID: 9600 --> 1
>>> rng_tz = pd.DatetimeIndex(["2021-10-31 01:30:00"], tz="Europe/Amsterdam")

---->   pandas.DatetimeIndex

--------------------------------------
ID: 9601 --> 1
>>> rng_tz.ceil("H", ambiguous=False)
DatetimeIndex(['2021-10-31 02:00:00+01:00'],
              dtype='datetime64[ns, Europe/Amsterdam]', freq=None)

---->   DatetimeIndex.ceil

--------------------------------------
ID: 9602 --> 1
>>> rng_tz.ceil("H", ambiguous=True)
DatetimeIndex(['2021-10-31 02:00:00+02:00'],
              dtype='datetime64[ns, Europe/Amsterdam]', freq=None)

---->   DatetimeIndex.ceil

--------------------------------------
ID: 9603 --> 2
>>> idx = pd.Index([5.2, 6.0, np.NaN])
>>> idx
Index([5.2, 6.0, nan], dtype='float64')
>>> idx.notna()
array([ True,  True, False])

---->   pandas.Index; Index.notna

--------------------------------------
ID: 9604 --> 2
>>> idx = pd.Index(['black', '', 'red', None])
>>> idx
Index(['black', '', 'red', None], dtype='object')
>>> idx.notna()
array([ True,  True,  True, False])

---->   pandas.Index; Index.notna

--------------------------------------
ID: 9605 --> 1
>>> dates = pd.Series(pd.date_range("2017-12-30", periods=3))
>>> dates
0   2017-12-30
1   2017-12-31
2   2018-01-01
dtype: datetime64[ns]

---->   pandas.Series

--------------------------------------
ID: 9608 --> 2
>>> idx = pd.Index([1.0, 2.0, 3.0, 4.0])
>>> idx.is_floating()  
True

---->   pandas.Index; Index.is_floating

--------------------------------------
ID: 9609 --> 2
>>> idx = pd.Index([1.0, 2.0, np.nan, 4.0])
>>> idx.is_floating()  
True

---->   pandas.Index; Index.is_floating

--------------------------------------
ID: 9610 --> 2
>>> idx = pd.Index([1, 2, 3, 4, np.nan])
>>> idx.is_floating()  
True

---->   pandas.Index; Index.is_floating

--------------------------------------
ID: 9611 --> 2
>>> idx = pd.Index([1, 2, 3, 4])
>>> idx.is_floating()  
False

---->   pandas.Index; Index.is_floating

--------------------------------------
ID: 9612 --> 1
>>> pd.Index([1, 2, 3])
Index([1, 2, 3], dtype='int64')

---->   pandas.Index

--------------------------------------
ID: 9613 --> 1
>>> pd.Index(list('abc'))
Index(['a', 'b', 'c'], dtype='object')

---->   pandas.Index

--------------------------------------
ID: 9614 --> 1
>>> pd.Index([1, 2, 3], dtype="uint8")
Index([1, 2, 3], dtype='uint8')

---->   pandas.Index

--------------------------------------
ID: 9615 --> 1
>>> s = pd.Series({'Corn Flakes': 100.0, 'Almond Delight': 110.0,
...                'Cinnamon Toast Crunch': 120.0, 'Cocoa Puff': 110.0})
>>> s
Corn Flakes              100.0
Almond Delight           110.0
Cinnamon Toast Crunch    120.0
Cocoa Puff               110.0
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 9616 --> 2
>>> s.argmax()
2
>>> s.argmin()
0

---->   Series.argmax; Series.argmin

--------------------------------------
ID: 9617 --> 1
>>> datetime_series = pd.Series(
...     pd.date_range("2000-01-01", periods=3, freq="D")
... )
>>> datetime_series
0   2000-01-01
1   2000-01-02
2   2000-01-03
dtype: datetime64[ns]
>>> datetime_series.dt.day
0    1
1    2
2    3
dtype: int32

---->   pandas.Series

--------------------------------------
ID: 9619 --> 2
>>> unique_index = pd.Index(list('abc'))
>>> unique_index.get_loc('b')
1

---->   pandas.Index; Index.get_loc

--------------------------------------
ID: 9620 --> 2
>>> monotonic_index = pd.Index(list('abbc'))
>>> monotonic_index.get_loc('b')
slice(1, 3, None)

---->   pandas.Index; Index.get_loc

--------------------------------------
ID: 9621 --> 2
>>> non_monotonic_index = pd.Index(list('abcb'))
>>> non_monotonic_index.get_loc('b')
array([False,  True, False,  True])

---->   pandas.Index; Index.get_loc

--------------------------------------
ID: 9622 --> 2
>>> idx = pd.Index(["Watermelon", "Orange", "Apple",
...                 "Watermelon"]).astype("category")
>>> idx.is_categorical()  
True

---->   pandas.Index; Index.is_categorical

--------------------------------------
ID: 9623 --> 2
>>> idx = pd.Index([1, 3, 5, 7])
>>> idx.is_categorical()  
False

---->   pandas.Index; Index.is_categorical

--------------------------------------
ID: 9624 --> 1
>>> s = pd.Series(["Peter", "Victor", "Elisabeth", "Mar"])
>>> s
0        Peter
1       Victor
2    Elisabeth
3          Mar
dtype: object
>>> s.index.is_categorical()  
False

---->   pandas.Series

--------------------------------------
ID: 9625 --> 1
>>> datetime_series = pd.Series(
...     pd.date_range("2000-01-01", periods=3, freq="T")
... )
>>> datetime_series
0   2000-01-01 00:00:00
1   2000-01-01 00:01:00
2   2000-01-01 00:02:00
dtype: datetime64[ns]
>>> datetime_series.dt.minute
0    0
1    1
2    2
dtype: int32

---->   pandas.Series

--------------------------------------
ID: 9626 --> 1
>>> idx = pd.Index([10, 100, 1, 1000])
>>> idx
Index([10, 100, 1, 1000], dtype='int64')

---->   pandas.Index

--------------------------------------
ID: 9627 --> 1
>>> idx.sort_values()
Index([1, 10, 100, 1000], dtype='int64')

---->   Index.sort_values

--------------------------------------
ID: 9628 --> 1
>>> idx.sort_values(ascending=False, return_indexer=True)
(Index([1000, 100, 10, 1], dtype='int64'), array([3, 1, 0, 2]))

---->   Index.sort_values

--------------------------------------
ID: 9630 --> 2
>>> idx = pd.Index([3, 2, 1])
>>> idx.min()
1

---->   pandas.Index; Index.min

--------------------------------------
ID: 9631 --> 2
>>> idx = pd.Index(['c', 'b', 'a'])
>>> idx.min()
'a'

---->   pandas.Index; Index.min

--------------------------------------
ID: 9632 --> 2
>>> idx = pd.MultiIndex.from_product([('a', 'b'), (2, 1)])
>>> idx.min()
('a', 1)

---->   pandas.MultiIndex; Index.min

--------------------------------------
ID: 9633 --> 1
>>> mi = pd.MultiIndex.from_arrays([list('abb'), list('def')])

---->   pandas.MultiIndex

--------------------------------------
ID: 9636 --> 2
>>> idx = pd.Index(['lama', 'cow', 'lama', 'beetle', 'lama'])
>>> idx.duplicated()
array([False, False,  True, False,  True])

---->   pandas.Index; Index.duplicated

--------------------------------------
ID: 9637 --> 1
>>> idx.duplicated(keep='first')
array([False, False,  True, False,  True])

---->   Index.duplicated

--------------------------------------
ID: 9638 --> 1
>>> idx.duplicated(keep='last')
array([ True, False,  True, False, False])

---->   Index.duplicated

--------------------------------------
ID: 9639 --> 1
>>> idx.duplicated(keep=False)
array([ True, False,  True, False,  True])

---->   Index.duplicated

--------------------------------------
ID: 9640 --> 1
>>> pd.IntervalIndex.from_tuples([(0, 1), (1, 2)])
IntervalIndex([(0, 1], (1, 2]],
               dtype='interval[int64, right]')

---->   pandas.IntervalIndex

--------------------------------------
ID: 9642 --> 1
>>> pd.Series(rng).dt.floor("H")
0   2018-01-01 11:00:00
1   2018-01-01 12:00:00
2   2018-01-01 12:00:00
dtype: datetime64[ns]

---->   pandas.Series

--------------------------------------
ID: 9643 --> 1
>>> rng_tz = pd.DatetimeIndex(["2021-10-31 03:30:00"], tz="Europe/Amsterdam")

---->   pandas.DatetimeIndex

--------------------------------------
ID: 9644 --> 1
>>> rng_tz.floor("2H", ambiguous=False)
DatetimeIndex(['2021-10-31 02:00:00+01:00'],
             dtype='datetime64[ns, Europe/Amsterdam]', freq=None)

---->   DatetimeIndex.floor

--------------------------------------
ID: 9645 --> 1
>>> rng_tz.floor("2H", ambiguous=True)
DatetimeIndex(['2021-10-31 02:00:00+02:00'],
              dtype='datetime64[ns, Europe/Amsterdam]', freq=None)

---->   DatetimeIndex.floor

--------------------------------------
ID: 9651 --> 1
>>> idx = pd.Index(['b', 'a', 'd', 'c'])
>>> idx
Index(['b', 'a', 'd', 'c'], dtype='object')

---->   pandas.Index

--------------------------------------
ID: 9652 --> 1
>>> order = idx.argsort()
>>> order
array([1, 0, 3, 2])

---->   Index.argsort

--------------------------------------
ID: 9654 --> 1
>>> pd.IntervalIndex.from_arrays([0, 1, 2], [1, 2, 3])
IntervalIndex([(0, 1], (1, 2], (2, 3]],
              dtype='interval[int64, right]')

---->   pandas.IntervalIndex

--------------------------------------
ID: 9655 --> 1
>>> idx = pd.Index(list('abc'))
>>> idx
Index(['a', 'b', 'c'], dtype='object')

---->   pandas.Index

--------------------------------------
ID: 9656 --> 1
>>> idx.get_level_values(0)
Index(['a', 'b', 'c'], dtype='object')

---->   Index.get_level_values

--------------------------------------
ID: 9657 --> 1
>>> c = pd.Categorical(['a', 'a', 'b'])
>>> c.rename_categories([0, 1])
[0, 0, 1]
Categories (2, int64): [0, 1]

---->   pandas.Categorical

--------------------------------------
ID: 9660 --> 1
>>> datetime_series = pd.Series(
...     pd.date_range("2000-01-01", periods=3, freq="M")
... )
>>> datetime_series
0   2000-01-31
1   2000-02-29
2   2000-03-31
dtype: datetime64[ns]
>>> datetime_series.dt.month
0    1
1    2
2    3
dtype: int32

---->   pandas.Series

--------------------------------------
ID: 9661 --> 1
>>> idx = pd.Index(['Ant', 'Bear', 'Cow'], name='animal')

---->   pandas.Index

--------------------------------------
ID: 9662 --> 1
>>> idx.to_series()
animal
Ant      Ant
Bear    Bear
Cow      Cow
Name: animal, dtype: object

---->   Index.to_series

--------------------------------------
ID: 9663 --> 1
>>> idx.to_series(index=[0, 1, 2])
0     Ant
1    Bear
2     Cow
Name: animal, dtype: object

---->   Index.to_series

--------------------------------------
ID: 9664 --> 1
>>> idx.to_series(name='zoo')
animal
Ant      Ant
Bear    Bear
Cow      Cow
Name: zoo, dtype: object

---->   Index.to_series

--------------------------------------
ID: 9666 --> 1
>>> s = pd.Series({'Corn Flakes': 100.0, 'Almond Delight': 110.0,
...                'Cinnamon Toast Crunch': 120.0, 'Cocoa Puff': 110.0})
>>> s
Corn Flakes              100.0
Almond Delight           110.0
Cinnamon Toast Crunch    120.0
Cocoa Puff               110.0
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 9667 --> 2
>>> s.argmax()
2
>>> s.argmin()
0

---->   Series.argmax; Series.argmin

--------------------------------------
ID: 9668 --> 2
>>> idx = pd.CategoricalIndex(['a', 'b', 'c'])
>>> idx
CategoricalIndex(['a', 'b', 'c'], categories=['a', 'b', 'c'],
                  ordered=False, dtype='category')
>>> idx.map(lambda x: x.upper())
CategoricalIndex(['A', 'B', 'C'], categories=['A', 'B', 'C'],
                 ordered=False, dtype='category')
>>> idx.map({'a': 'first', 'b': 'second', 'c': 'third'})
CategoricalIndex(['first', 'second', 'third'], categories=['first',
                 'second', 'third'], ordered=False, dtype='category')

---->   pandas.CategoricalIndex; CategoricalIndex.map

--------------------------------------
ID: 9669 --> 2
>>> idx = pd.CategoricalIndex(['a', 'b', 'c'], ordered=True)
>>> idx
CategoricalIndex(['a', 'b', 'c'], categories=['a', 'b', 'c'],
                 ordered=True, dtype='category')
>>> idx.map({'a': 3, 'b': 2, 'c': 1})
CategoricalIndex([3, 2, 1], categories=[3, 2, 1], ordered=True,
                 dtype='category')

---->   pandas.CategoricalIndex; CategoricalIndex.map

--------------------------------------
ID: 9670 --> 1
>>> idx.map({'a': 'first', 'b': 'second', 'c': 'first'})
Index(['first', 'second', 'first'], dtype='object')

---->   CategoricalIndex.map

--------------------------------------
ID: 9671 --> 1
>>> idx.map({'a': 'first', 'b': 'second'})
Index(['first', 'second', nan], dtype='object')

---->   CategoricalIndex.map

--------------------------------------
ID: 9672 --> 1
>>> idx = pd.MultiIndex.from_tuples(
...     [(1, "one"), (1, "two"), (2, "one"), (2, "two")], names=["foo", "bar"]
... )
>>> idx
MultiIndex([(1, 'one'),
    (1, 'two'),
    (2, 'one'),
    (2, 'two')],
   names=['foo', 'bar'])

---->   pandas.MultiIndex

--------------------------------------
ID: 9674 --> 1
>>> datetime_series = pd.Series(
...     pd.date_range("2000-01-01", periods=3, freq="Y")
... )
>>> datetime_series
0   2000-12-31
1   2001-12-31
2   2002-12-31
dtype: datetime64[ns]
>>> datetime_series.dt.year
0    2000
1    2001
2    2002
dtype: int32

---->   pandas.Series

--------------------------------------
ID: 9675 --> 2
>>> idx = pd.Index([np.nan, 'var1', np.nan])
>>> idx.get_indexer_for([np.nan])
array([0, 2])

---->   pandas.Index; Index.get_indexer_for

--------------------------------------
ID: 9677 --> 1
>>> mi = pd.MultiIndex.from_arrays([['a', 'b'], ['c', 'd']])
>>> mi
MultiIndex([('a', 'c'),
            ('b', 'd')],
           )

---->   pandas.MultiIndex

--------------------------------------
ID: 9681 --> 1
>>> index = pd.MultiIndex.from_product(
...     [['foo', 'bar'], ['baz', 'qux']],
...     names=['a', 'b'])
>>> index.to_flat_index()
Index([('foo', 'baz'), ('foo', 'qux'),
       ('bar', 'baz'), ('bar', 'qux')],
      dtype='object')

---->   pandas.MultiIndex

--------------------------------------
ID: 9683 --> 1
>>> dates_series = pd.Series(idx)
>>> dates_series
0   2012-12-31
1   2013-12-31
2   2014-12-31
dtype: datetime64[ns]
>>> dates_series.dt.is_leap_year
0     True
1    False
2    False
dtype: bool

---->   pandas.Series

--------------------------------------
ID: 9686 --> 3
>>> i1, i2 = pd.Interval(0, 1), pd.Interval(1, 2)
>>> index = pd.IntervalIndex([i1, i2])
>>> index.get_loc(1)
0

---->   pandas.Interval; pandas.IntervalIndex; IntervalIndex.get_loc

--------------------------------------
ID: 9687 --> 1
>>> index.get_loc(1.5)
1

---->   IntervalIndex.get_loc

--------------------------------------
ID: 9688 --> 3
>>> i3 = pd.Interval(0, 2)
>>> overlapping_index = pd.IntervalIndex([i1, i2, i3])
>>> overlapping_index.get_loc(0.5)
array([ True, False,  True])

---->   pandas.Interval; pandas.IntervalIndex; IntervalIndex.get_loc

--------------------------------------
ID: 9689 --> 2
>>> index.get_loc(pd.Interval(0, 1))
0

---->   IntervalIndex.get_loc; pandas.Interval

--------------------------------------
ID: 9690 --> 1
>>> s = pd.Series(pd.date_range(start='2018-01-01', freq='D', periods=3))
>>> s
0   2018-01-01
1   2018-01-02
2   2018-01-03
dtype: datetime64[ns]
>>> s.dt.day_name()
0       Monday
1      Tuesday
2    Wednesday
dtype: object

---->   pandas.Series

--------------------------------------
ID: 9693 --> 1
>>> idx = pd.Index([1, 2, 3, 4])
>>> idx
Index([1, 2, 3, 4], dtype='int64')
>>> idx.set_names('quarter')
Index([1, 2, 3, 4], dtype='int64', name='quarter')

---->   pandas.Index

--------------------------------------
ID: 9694 --> 1
>>> idx = pd.MultiIndex.from_product([['python', 'cobra'],
...                                   [2018, 2019]])
>>> idx
MultiIndex([('python', 2018),
            ('python', 2019),
            ( 'cobra', 2018),
            ( 'cobra', 2019)],
           )
>>> idx = idx.set_names(['kind', 'year'])
>>> idx.set_names('species', level=0)
MultiIndex([('python', 2018),
            ('python', 2019),
            ( 'cobra', 2018),
            ( 'cobra', 2019)],
           names=['species', 'year'])

---->   pandas.MultiIndex

--------------------------------------
ID: 9697 --> 1
>>> pd.Series(['a', 'b']).dt
Traceback (most recent call last):
...
AttributeError: Can only use .dt accessor with datetimelike values

---->   pandas.Series

--------------------------------------
ID: 9699 --> 1
In [1]: ds = pd.DataFrame({"longitude": np.linspace(0, 10),
   ...:                    "latitude": np.linspace(0, 20)})
In [2]: ds.geo.center
Out[2]: (5.0, 10.0)
In [3]: ds.geo.plot()  # plots data on a map

---->   pandas.DataFrame

--------------------------------------
ID: 9700 --> 1
>>> period = pd.Period('2012-1-1', freq='D')
>>> period
Period('2012-01-01', 'D')

---->   pandas.Period

--------------------------------------
ID: 9703 --> 1
>>> pd.Interval(0, 1, closed='right').is_empty
False

---->   pandas.Interval

--------------------------------------
ID: 9704 --> 1
>>> pd.Interval(0, 0, closed='right').is_empty
True
>>> pd.Interval(0, 0, closed='left').is_empty
True
>>> pd.Interval(0, 0, closed='neither').is_empty
True

---->   pandas.Interval

--------------------------------------
ID: 9705 --> 1
>>> pd.Interval(0, 0, closed='both').is_empty
False

---->   pandas.Interval

--------------------------------------
ID: 9706 --> 1
>>> ivs = [pd.Interval(0, 0, closed='neither'),
...        pd.Interval(1, 2, closed='neither')]
>>> pd.arrays.IntervalArray(ivs).is_empty
array([ True, False])

---->   pandas.Interval

--------------------------------------
ID: 9707 --> 2
>>> ivs = [pd.Interval(0, 0, closed='neither'), np.nan]
>>> pd.IntervalIndex(ivs).is_empty
array([ True, False])

---->   pandas.Interval; pandas.IntervalIndex

--------------------------------------
ID: 9708 --> 1
>>> s = pd.Series([90, 91, 85])
>>> s
0    90
1    91
2    85
dtype: int64

---->   pandas.Series

--------------------------------------
ID: 9709 --> 1
>>> s.pct_change()
0         NaN
1    0.011111
2   -0.065934
dtype: float64

---->   Series.pct_change

--------------------------------------
ID: 9710 --> 1
>>> s.pct_change(periods=2)
0         NaN
1         NaN
2   -0.055556
dtype: float64

---->   Series.pct_change

--------------------------------------
ID: 9711 --> 1
>>> s = pd.Series([90, 91, None, 85])
>>> s
0    90.0
1    91.0
2     NaN
3    85.0
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 9712 --> 1
>>> s.pct_change(fill_method='ffill')
0         NaN
1    0.011111
2    0.000000
3   -0.065934
dtype: float64

---->   Series.pct_change

--------------------------------------
ID: 9713 --> 1
>>> df = pd.DataFrame({
...     'FR': [4.0405, 4.0963, 4.3149],
...     'GR': [1.7246, 1.7482, 1.8519],
...     'IT': [804.74, 810.01, 860.13]},
...     index=['1980-01-01', '1980-02-01', '1980-03-01'])
>>> df
                FR      GR      IT
1980-01-01  4.0405  1.7246  804.74
1980-02-01  4.0963  1.7482  810.01
1980-03-01  4.3149  1.8519  860.13

---->   pandas.DataFrame

--------------------------------------
ID: 9714 --> 1
>>> df.pct_change()
                  FR        GR        IT
1980-01-01       NaN       NaN       NaN
1980-02-01  0.013810  0.013684  0.006549
1980-03-01  0.053365  0.059318  0.061876

---->   DataFrame.pct_change

--------------------------------------
ID: 9715 --> 1
>>> df = pd.DataFrame({
...     '2016': [1769950, 30586265],
...     '2015': [1500923, 40912316],
...     '2014': [1371819, 41403351]},
...     index=['GOOG', 'APPL'])
>>> df
          2016      2015      2014
GOOG   1769950   1500923   1371819
APPL  30586265  40912316  41403351

---->   pandas.DataFrame

--------------------------------------
ID: 9716 --> 1
>>> df.pct_change(axis='columns', periods=-1)
          2016      2015  2014
GOOG  0.179241  0.094112   NaN
APPL -0.252395 -0.011860   NaN

---->   DataFrame.pct_change

--------------------------------------
ID: 9718 --> 2
>>> index = pd.Index([3, 1, 2, 3, 4, np.nan])
>>> index.value_counts()
3.0    2
1.0    1
2.0    1
4.0    1
Name: count, dtype: int64

---->   pandas.Index; Index.value_counts

--------------------------------------
ID: 9719 --> 2
>>> s = pd.Series([3, 1, 2, 3, 4, np.nan])
>>> s.value_counts(normalize=True)
3.0    0.4
1.0    0.2
2.0    0.2
4.0    0.2
Name: proportion, dtype: float64

---->   pandas.Series; Series.value_counts

--------------------------------------
ID: 9720 --> 1
>>> s.value_counts(bins=3)
(0.996, 2.0]    2
(2.0, 3.0]      2
(3.0, 4.0]      1
Name: count, dtype: int64

---->   Series.value_counts

--------------------------------------
ID: 9721 --> 1
>>> s.value_counts(dropna=False)
3.0    2
1.0    1
2.0    1
4.0    1
NaN    1
Name: count, dtype: int64

---->   Series.value_counts

--------------------------------------
ID: 9722 --> 1
>>> s = pd.Series([1, 2, 3])
>>> s.dtype
dtype('int64')

---->   pandas.Series

--------------------------------------
ID: 9723 --> 2
>>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])
>>> a
a    1.0
b    1.0
c    1.0
d    NaN
dtype: float64
>>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])
>>> b
a    1.0
b    NaN
d    1.0
e    NaN
dtype: float64
>>> a.pow(b, fill_value=0)
a    1.0
b    1.0
c    1.0
d    0.0
e    NaN
dtype: float64

---->   pandas.Series; Series.pow

--------------------------------------
ID: 9724 --> 1
>>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])
>>> a
a    1.0
b    1.0
c    1.0
d    NaN
dtype: float64
>>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])
>>> b
a    1.0
b    NaN
d    1.0
e    NaN
dtype: float64
>>> a.multiply(b, fill_value=0)
a    1.0
b    0.0
c    0.0
d    0.0
e    NaN
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 9725 --> 1
>>> s = pd.Series([1, 2, 3, 4])
>>> s
0    1
1    2
2    3
3    4
dtype: int64

---->   pandas.Series

--------------------------------------
ID: 9726 --> 1
>>> s.agg('min')
1

---->   Series.agg

--------------------------------------
ID: 9727 --> 1
>>> s.agg(['min', 'max'])
min   1
max   4
dtype: int64

---->   Series.agg

--------------------------------------
ID: 9728 --> 1
>>> s = pd.Series(['a1', 'b2', 'c3'])
>>> s.str.extract(r'([ab])(\d)')
    0    1
0    a    1
1    b    2
2  NaN  NaN

---->   pandas.Series

--------------------------------------
ID: 9733 --> 2
>>> index = pd.Index(['c', 'a', 'b'])
>>> index.get_indexer(['a', 'b', 'x'])
array([ 1,  2, -1])

---->   pandas.Index; Index.get_indexer

--------------------------------------
ID: 9734 --> 2
>>> df = pd.DataFrame({'dates': pd.date_range("2017-03-30",
...                    periods=4)})
>>> df.assign(quarter=df.dates.dt.quarter,
...           is_quarter_end=df.dates.dt.is_quarter_end)
       dates  quarter    is_quarter_end
0 2017-03-30        1             False
1 2017-03-31        1              True
2 2017-04-01        2             False
3 2017-04-02        2             False

---->   pandas.DataFrame; DataFrame.assign

--------------------------------------
ID: 9737 --> 1
>>> s = pd.Series([1, 2], index=["a", "b"])
>>> s
a    1
b    2
dtype: int64

---->   pandas.Series

--------------------------------------
ID: 9738 --> 1
>>> s_copy = s.copy()
>>> s_copy
a    1
b    2
dtype: int64

---->   Series.copy

--------------------------------------
ID: 9739 --> 2
>>> s = pd.Series([1, 2], index=["a", "b"])
>>> deep = s.copy()
>>> shallow = s.copy(deep=False)

---->   pandas.Series; Series.copy

--------------------------------------
ID: 9740 --> 2
>>> s = pd.Series([[1, 2], [3, 4]])
>>> deep = s.copy()
>>> s[0][0] = 10
>>> s
0    [10, 2]
1     [3, 4]
dtype: object
>>> deep
0    [10, 2]
1     [3, 4]
dtype: object

---->   pandas.Series; Series.copy

--------------------------------------
ID: 9741 --> 1
>>> s = pd.Series(['Lion', 'Monkey', 'Rabbit'])

---->   pandas.Series

--------------------------------------
ID: 9748 --> 2
>>> s = pd.Series(['a', 'b', 'c'])
>>> s
0    a
1    b
2    c
dtype: object
>>> s.repeat(2)
0    a
0    a
1    b
1    b
2    c
2    c
dtype: object
>>> s.repeat([1, 2, 3])
0    a
1    b
1    b
2    c
2    c
2    c
dtype: object

---->   pandas.Series; Series.repeat

--------------------------------------
ID: 9749 --> 1
>>> s = pd.Series(['A', 'B', 'Aaba', 'Baca', np.nan, 'CABA', 'cat'])
>>> s.str.count('a')
0    0.0
1    0.0
2    2.0
3    2.0
4    NaN
5    0.0
6    1.0
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 9750 --> 1
>>> s = pd.Series(['$', 'B', 'Aab$', '$$ca', 'C$B$', 'cat'])
>>> s.str.count('\\$')
0    1
1    0
2    1
3    2
4    2
5    0
dtype: int64

---->   pandas.Series

--------------------------------------
ID: 9751 --> 1
>>> pd.Index(['A', 'A', 'Aaba', 'cat']).str.count('a')
Index([0, 0, 2, 1], dtype='int64')

---->   pandas.Index

--------------------------------------
ID: 9752 --> 1
>>> s = pd.Series([1, 2, 3])
>>> s.shape
(3,)

---->   pandas.Series

--------------------------------------
ID: 9753 --> 1
>>> df = pd.DataFrame([[1, 2, 3], [4, 5, 6]], columns=['A', 'B', 'C'])

---->   pandas.DataFrame

--------------------------------------
ID: 9754 --> 1
>>> df.to_clipboard(sep=',')  
... # Wrote the following to the system clipboard:
... # ,A,B,C
... # 0,1,2,3
... # 1,4,5,6

---->   DataFrame.to_clipboard

--------------------------------------
ID: 9755 --> 1
>>> df.to_clipboard(sep=',', index=False)  
... # Wrote the following to the system clipboard:
... # A,B,C
... # 1,2,3
... # 4,5,6

---->   DataFrame.to_clipboard

--------------------------------------
ID: 9757 --> 1
>>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])
>>> a
a    1.0
b    1.0
c    1.0
d    NaN
dtype: float64
>>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])
>>> b
a    1.0
b    NaN
d    1.0
e    NaN
dtype: float64
>>> a.multiply(b, fill_value=0)
a    1.0
b    0.0
c    0.0
d    0.0
e    NaN
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 9758 --> 2
>>> s = pd.Series([1, 2, 3])
>>> s.update(pd.Series([4, 5, 6]))
>>> s
0    4
1    5
2    6
dtype: int64

---->   pandas.Series; Series.update

--------------------------------------
ID: 9759 --> 2
>>> s = pd.Series(['a', 'b', 'c'])
>>> s.update(pd.Series(['d', 'e'], index=[0, 2]))
>>> s
0    d
1    b
2    e
dtype: object

---->   pandas.Series; Series.update

--------------------------------------
ID: 9760 --> 2
>>> s = pd.Series([1, 2, 3])
>>> s.update(pd.Series([4, 5, 6, 7, 8]))
>>> s
0    4
1    5
2    6
dtype: int64

---->   pandas.Series; Series.update

--------------------------------------
ID: 9761 --> 2
>>> s = pd.Series([1, 2, 3])
>>> s.update(pd.Series([4, np.nan, 6]))
>>> s
0    4
1    2
2    6
dtype: int64

---->   pandas.Series; Series.update

--------------------------------------
ID: 9762 --> 2
>>> s = pd.Series([1, 2, 3])
>>> s.update([4, np.nan, 6])
>>> s
0    4
1    2
2    6
dtype: int64

---->   pandas.Series; Series.update

--------------------------------------
ID: 9763 --> 2
>>> s = pd.Series([1, 2, 3])
>>> s.update({1: 9})
>>> s
0    1
1    9
2    3
dtype: int64

---->   pandas.Series; Series.update

--------------------------------------
ID: 9764 --> 1
>>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])
>>> a
a    1.0
b    1.0
c    1.0
d    NaN
dtype: float64
>>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])
>>> b
a    1.0
b    NaN
d    1.0
e    NaN
dtype: float64
>>> a.subtract(b, fill_value=0)
a    0.0
b    1.0
c    1.0
d   -1.0
e    NaN
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 9765 --> 2
>>> animals = pd.Series(['lama', 'cow', 'lama', 'beetle', 'lama'])
>>> animals.duplicated()
0    False
1    False
2     True
3    False
4     True
dtype: bool

---->   pandas.Series; Series.duplicated

--------------------------------------
ID: 9766 --> 1
>>> animals.duplicated(keep='first')
0    False
1    False
2     True
3    False
4     True
dtype: bool

---->   Series.duplicated

--------------------------------------
ID: 9767 --> 1
>>> animals.duplicated(keep='last')
0     True
1    False
2     True
3    False
4    False
dtype: bool

---->   Series.duplicated

--------------------------------------
ID: 9768 --> 1
>>> animals.duplicated(keep=False)
0     True
1    False
2     True
3    False
4     True
dtype: bool

---->   Series.duplicated

--------------------------------------
ID: 9769 --> 1
>>> s1 = pd.Series(['Mouse', 'dog', 'house and parrot', '23', np.NaN])
>>> s1.str.contains('og', regex=False)
0    False
1     True
2    False
3    False
4      NaN
dtype: object

---->   pandas.Series

--------------------------------------
ID: 9770 --> 1
>>> ind = pd.Index(['Mouse', 'dog', 'house and parrot', '23.0', np.NaN])
>>> ind.str.contains('23', regex=False)
Index([False, False, False, True, nan], dtype='object')

---->   pandas.Index

--------------------------------------
ID: 9776 --> 1
>>> s2 = pd.Series(['40', '40.0', '41', '41.0', '35'])
>>> s2.str.contains('.0', regex=True)
0     True
1     True
2    False
3     True
4    False
dtype: bool

---->   pandas.Series

--------------------------------------
ID: 9777 --> 2
>>> df = pd.DataFrame({'name': ['Raphael', 'Donatello'],
...                    'mask': ['red', 'purple'],
...                    'weapon': ['sai', 'bo staff']})
>>> df.to_csv(index=False)
'name,mask,weapon\nRaphael,red,sai\nDonatello,purple,bo staff\n'

---->   pandas.DataFrame; DataFrame.to_csv

--------------------------------------
ID: 9778 --> 1
>>> compression_opts = dict(method='zip',
...                         archive_name='out.csv')  
>>> df.to_csv('out.zip', index=False,
...           compression=compression_opts)  

---->   DataFrame.to_csv

--------------------------------------
ID: 9779 --> 1
>>> from pathlib import Path  
>>> filepath = Path('folder/subfolder/out.csv')  
>>> filepath.parent.mkdir(parents=True, exist_ok=True)  
>>> df.to_csv(filepath)  

---->   DataFrame.to_csv

--------------------------------------
ID: 9780 --> 1
>>> import os  
>>> os.makedirs('folder/subfolder', exist_ok=True)  
>>> df.to_csv('folder/subfolder/out.csv')  

---->   DataFrame.to_csv

--------------------------------------
ID: 9781 --> 1
>>> s1 = pd.Series(['one', 'one1', '1', ''])

---->   pandas.Series

--------------------------------------
ID: 9785 --> 1
>>> s2 = pd.Series(['A B', '1.5', '3,000'])
>>> s2.str.isalnum()
0    False
1    False
2    False
dtype: bool

---->   pandas.Series

--------------------------------------
ID: 9786 --> 1
>>> s3 = pd.Series(['23', '³', '⅕', ''])

---->   pandas.Series

--------------------------------------
ID: 9790 --> 1
>>> s4 = pd.Series([' ', '\t\r\n ', ''])
>>> s4.str.isspace()
0     True
1     True
2    False
dtype: bool

---->   pandas.Series

--------------------------------------
ID: 9791 --> 1
>>> s5 = pd.Series(['leopard', 'Golden Eagle', 'SNAKE', ''])

---->   pandas.Series

--------------------------------------
ID: 9795 --> 1
>>> s = pd.Series([1, 3, 5, 7, 7])
>>> s
0    1
1    3
2    5
3    7
4    7
dtype: int64

---->   pandas.Series

--------------------------------------
ID: 9796 --> 1
>>> s.nunique()
4

---->   Series.nunique

--------------------------------------
ID: 9797 --> 1
>>> s1 = pd.Series({'falcon': 330.0, 'eagle': 160.0})
>>> s1
falcon    330.0
eagle     160.0
dtype: float64
>>> s2 = pd.Series({'falcon': 345.0, 'eagle': 200.0, 'duck': 30.0})
>>> s2
falcon    345.0
eagle     200.0
duck       30.0
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 9798 --> 1
>>> s1.combine(s2, max)
duck        NaN
eagle     200.0
falcon    345.0
dtype: float64

---->   Series.combine

--------------------------------------
ID: 9799 --> 1
>>> s1.combine(s2, max, fill_value=0)
duck       30.0
eagle     200.0
falcon    345.0
dtype: float64

---->   Series.combine

--------------------------------------
ID: 9800 --> 1
>>> s = pd.Series([np.nan, 1, 3, 10, 5])
>>> s
0     NaN
1     1.0
2     3.0
3     10.0
4     5.0
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 9804 --> 1
>>> s = pd.Series(['z', 'b', 'd', 'a', 'c'])
>>> s
0    z
1    b
2    d
3    a
4    c
dtype: object

---->   pandas.Series

--------------------------------------
ID: 9806 --> 1
>>> s = pd.Series(['a', 'B', 'c', 'D', 'e'])
>>> s.sort_values()
1    B
3    D
0    a
2    c
4    e
dtype: object
>>> s.sort_values(key=lambda x: x.str.lower())
0    a
1    B
2    c
3    D
4    e
dtype: object

---->   pandas.Series

--------------------------------------
ID: 9807 --> 1
>>> s = pd.Series([-4, -2, 0, 2, 4])
>>> s.sort_values(key=np.sin)
1   -2
4    4
2    0
0   -4
3    2
dtype: int64

---->   pandas.Series

--------------------------------------
ID: 9808 --> 1
>>> s.sort_values(key=lambda x: (np.tan(x.cumsum())))
0   -4
3    2
4    4
1   -2
2    0
dtype: int64

---->   Series.cumsum

--------------------------------------
ID: 9809 --> 1
>>> df = pd.DataFrame({"Col1": [10, 20, 15, 30, 45],
...                    "Col2": [13, 23, 18, 33, 48],
...                    "Col3": [17, 27, 22, 37, 52]},
...                   index=pd.date_range("2020-01-01", "2020-01-05"))
>>> df
            Col1  Col2  Col3
2020-01-01    10    13    17
2020-01-02    20    23    27
2020-01-03    15    18    22
2020-01-04    30    33    37
2020-01-05    45    48    52

---->   pandas.DataFrame

--------------------------------------
ID: 9810 --> 1
>>> df.shift(periods=3)
            Col1  Col2  Col3
2020-01-01   NaN   NaN   NaN
2020-01-02   NaN   NaN   NaN
2020-01-03   NaN   NaN   NaN
2020-01-04  10.0  13.0  17.0
2020-01-05  20.0  23.0  27.0

---->   DataFrame.shift

--------------------------------------
ID: 9811 --> 1
>>> df.shift(periods=1, axis="columns")
            Col1  Col2  Col3
2020-01-01   NaN    10    13
2020-01-02   NaN    20    23
2020-01-03   NaN    15    18
2020-01-04   NaN    30    33
2020-01-05   NaN    45    48

---->   DataFrame.shift

--------------------------------------
ID: 9812 --> 1
>>> df.shift(periods=3, fill_value=0)
            Col1  Col2  Col3
2020-01-01     0     0     0
2020-01-02     0     0     0
2020-01-03     0     0     0
2020-01-04    10    13    17
2020-01-05    20    23    27

---->   DataFrame.shift

--------------------------------------
ID: 9813 --> 1
>>> df.shift(periods=3, freq="D")
            Col1  Col2  Col3
2020-01-04    10    13    17
2020-01-05    20    23    27
2020-01-06    15    18    22
2020-01-07    30    33    37
2020-01-08    45    48    52

---->   DataFrame.shift

--------------------------------------
ID: 9814 --> 1
>>> df.shift(periods=3, freq="infer")
            Col1  Col2  Col3
2020-01-04    10    13    17
2020-01-05    20    23    27
2020-01-06    15    18    22
2020-01-07    30    33    37
2020-01-08    45    48    52

---->   DataFrame.shift

--------------------------------------
ID: 9815 --> 1
>>> countries_population = {"Italy": 59000000, "France": 65000000,
...                         "Malta": 434000, "Maldives": 434000,
...                         "Brunei": 434000, "Iceland": 337000,
...                         "Nauru": 11300, "Tuvalu": 11300,
...                         "Anguilla": 11300, "Montserrat": 5200}
>>> s = pd.Series(countries_population)
>>> s
Italy       59000000
France      65000000
Malta         434000
Maldives      434000
Brunei        434000
Iceland       337000
Nauru          11300
Tuvalu         11300
Anguilla       11300
Montserrat      5200
dtype: int64

---->   pandas.Series

--------------------------------------
ID: 9816 --> 1
>>> s.nlargest()
France      65000000
Italy       59000000
Malta         434000
Maldives      434000
Brunei        434000
dtype: int64

---->   Series.nlargest

--------------------------------------
ID: 9817 --> 1
>>> s.nlargest(3)
France    65000000
Italy     59000000
Malta       434000
dtype: int64

---->   Series.nlargest

--------------------------------------
ID: 9818 --> 1
>>> s.nlargest(3, keep='last')
France      65000000
Italy       59000000
Brunei        434000
dtype: int64

---->   Series.nlargest

--------------------------------------
ID: 9819 --> 1
>>> s.nlargest(3, keep='all')
France      65000000
Italy       59000000
Malta         434000
Maldives      434000
Brunei        434000
dtype: int64

---->   Series.nlargest

--------------------------------------
ID: 9820 --> 2
>>> idx = pd.MultiIndex.from_arrays([
...     ['warm', 'warm', 'cold', 'cold'],
...     ['dog', 'falcon', 'fish', 'spider']],
...     names=['blooded', 'animal'])
>>> s = pd.Series([4, 2, 0, 8], name='legs', index=idx)
>>> s
blooded  animal
warm     dog       4
         falcon    2
cold     fish      0
         spider    8
Name: legs, dtype: int64

---->   pandas.MultiIndex; pandas.Series

--------------------------------------
ID: 9821 --> 1
>>> s.sum()
14

---->   Series.sum

--------------------------------------
ID: 9822 --> 1
>>> pd.Series([], dtype="float64").sum()  # min_count=0 is the default
0.0

---->   pandas.Series

--------------------------------------
ID: 9823 --> 1
>>> pd.Series([], dtype="float64").sum(min_count=1)
nan

---->   pandas.Series

--------------------------------------
ID: 9824 --> 1
>>> pd.Series([np.nan]).sum()
0.0

---->   pandas.Series

--------------------------------------
ID: 9825 --> 1
>>> pd.Series([np.nan]).sum(min_count=1)
nan

---->   pandas.Series

--------------------------------------
ID: 9826 --> 1
>>> s = pd.Series([20, 21, 12],
...               index=['London', 'New York', 'Helsinki'])
>>> s
London      20
New York    21
Helsinki    12
dtype: int64

---->   pandas.Series

--------------------------------------
ID: 9834 --> 1
>>> s = pd.Series([1, 2, 3])
>>> s.dtypes
dtype('int64')

---->   pandas.Series

--------------------------------------
ID: 9835 --> 2
>>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])
>>> a
a    1.0
b    1.0
c    1.0
d    NaN
dtype: float64
>>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])
>>> b
a    1.0
b    NaN
d    1.0
e    NaN
dtype: float64
>>> a.floordiv(b, fill_value=0)
a    1.0
b    inf
c    inf
d    0.0
e    NaN
dtype: float64

---->   pandas.Series; Series.floordiv

--------------------------------------
ID: 9836 --> 2
>>> s = pd.Series([1, 3, 2])
>>> s.plot.line()


---->   pandas.Series; Series.plot

--------------------------------------
ID: 9837 --> 2
>>> df = pd.DataFrame({
...    'pig': [20, 18, 489, 675, 1776],
...    'horse': [4, 25, 281, 600, 1900]
...    }, index=[1990, 1997, 2003, 2009, 2014])
>>> lines = df.plot.line()

---->   pandas.DataFrame; DataFrame.plot

--------------------------------------
ID: 9838 --> 1
>>> axes = df.plot.line(subplots=True)
>>> type(axes)


---->   DataFrame.plot

--------------------------------------
ID: 9839 --> 1
>>> axes = df.plot.line(
...     subplots=True, color={"pig": "pink", "horse": "#742802"}
... )

---->   DataFrame.plot

--------------------------------------
ID: 9840 --> 1
>>> lines = df.plot.line(x='pig', y='horse')

---->   DataFrame.plot

--------------------------------------
ID: 9841 --> 1
>>> s = pd.Series(
...     [
...         "this is a regular sentence",
...         "https://docs.python.org/3/tutorial/index.html",
...         np.nan
...     ]
... )
>>> s
0                       this is a regular sentence
1    https://docs.python.org/3/tutorial/index.html
2                                              NaN
dtype: object

---->   pandas.Series

--------------------------------------
ID: 9849 --> 1
>>> s = pd.Series(["foo and bar plus baz"])
>>> s.str.split(r"and|plus", expand=True)
    0   1   2
0 foo bar baz

---->   pandas.Series

--------------------------------------
ID: 9850 --> 1
>>> s = pd.Series(['foojpgbar.jpg'])
>>> s.str.split(r".", expand=True)
           0    1
0  foojpgbar  jpg

---->   pandas.Series

--------------------------------------
ID: 9855 --> 1
>>> s = pd.Series(['Linda van der Berg', 'George Pitt-Rivers'])
>>> s
0    Linda van der Berg
1    George Pitt-Rivers
dtype: object

---->   pandas.Series

--------------------------------------
ID: 9860 --> 1
>>> idx = pd.Index(['X 123', 'Y 999'])
>>> idx
Index(['X 123', 'Y 999'], dtype='object')

---->   pandas.Index

--------------------------------------
ID: 9863 --> 1
>>> df = pd.DataFrame({'animal': ['alligator', 'bee', 'falcon', 'lion',
...                    'monkey', 'parrot', 'shark', 'whale', 'zebra']})
>>> df
      animal
0  alligator
1        bee
2     falcon
3       lion
4     monkey
5     parrot
6      shark
7      whale
8      zebra

---->   pandas.DataFrame

--------------------------------------
ID: 9864 --> 1
>>> df.tail()
   animal
4  monkey
5  parrot
6   shark
7   whale
8   zebra

---->   DataFrame.tail

--------------------------------------
ID: 9865 --> 1
>>> df.tail(3)
  animal
6  shark
7  whale
8  zebra

---->   DataFrame.tail

--------------------------------------
ID: 9866 --> 1
>>> df.tail(-3)
   animal
3    lion
4  monkey
5  parrot
6   shark
7   whale
8   zebra

---->   DataFrame.tail

--------------------------------------
ID: 9867 --> 2
>>> s = pd.Series([1, 2, 3, 4],
...               index=pd.MultiIndex.from_product([['one', 'two'],
...                                                 ['a', 'b']]))
>>> s
one  a    1
     b    2
two  a    3
     b    4
dtype: int64

---->   pandas.Series; pandas.MultiIndex

--------------------------------------
ID: 9868 --> 1
>>> s.unstack(level=-1)
     a  b
one  1  2
two  3  4

---->   Series.unstack

--------------------------------------
ID: 9869 --> 1
>>> s.unstack(level=0)
   one  two
a    1    3
b    2    4

---->   Series.unstack

--------------------------------------
ID: 9870 --> 2
>>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])
>>> a
a    1.0
b    1.0
c    1.0
d    NaN
dtype: float64
>>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])
>>> b
a    1.0
b    NaN
d    1.0
e    NaN
dtype: float64
>>> a.mod(b, fill_value=0)
a    0.0
b    NaN
c    NaN
d    0.0
e    NaN
dtype: float64

---->   pandas.Series; Series.mod

--------------------------------------
ID: 9871 --> 1
>>> df = pd.DataFrame(dict(age=[5, 6, np.NaN],
...                        born=[pd.NaT, pd.Timestamp('1939-05-27'),
...                              pd.Timestamp('1940-04-25')],
...                        name=['Alfred', 'Batman', ''],
...                        toy=[None, 'Batmobile', 'Joker']))
>>> df
   age       born    name        toy
0  5.0        NaT  Alfred       None
1  6.0 1939-05-27  Batman  Batmobile
2  NaN 1940-04-25              Joker

---->   pandas.DataFrame

--------------------------------------
ID: 9872 --> 1
>>> df.notna()
     age   born  name    toy
0   True  False  True  False
1   True   True  True   True
2  False   True  True   True

---->   DataFrame.notna

--------------------------------------
ID: 9873 --> 1
>>> ser = pd.Series([5, 6, np.NaN])
>>> ser
0    5.0
1    6.0
2    NaN
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 9874 --> 1
>>> ser.notna()
0     True
1     True
2    False
dtype: bool

---->   Series.notna

--------------------------------------
ID: 9875 --> 2
>>> s = pd.Series([0.0, 1.0, np.nan])
>>> s.count()
2

---->   pandas.Series; Series.count

--------------------------------------
ID: 9876 --> 2
>>> idx = pd.MultiIndex.from_arrays([
...     ['warm', 'warm', 'cold', 'cold'],
...     ['dog', 'falcon', 'fish', 'spider']],
...     names=['blooded', 'animal'])
>>> s = pd.Series([4, 2, 0, 8], name='legs', index=idx)
>>> s
blooded  animal
warm     dog       4
         falcon    2
cold     fish      0
         spider    8
Name: legs, dtype: int64

---->   pandas.MultiIndex; pandas.Series

--------------------------------------
ID: 9877 --> 1
>>> s.min()
0

---->   Series.min

--------------------------------------
ID: 9878 --> 2
>>> s = pd.Series([1, 2, 2.5, 3, 3.5, 4, 5])
>>> ax = s.plot.kde()

---->   pandas.Series; Series.plot

--------------------------------------
ID: 9879 --> 1
>>> ax = s.plot.kde(bw_method=0.3)

---->   Series.plot

--------------------------------------
ID: 9880 --> 1
>>> ax = s.plot.kde(bw_method=3)

---->   Series.plot

--------------------------------------
ID: 9881 --> 1
>>> ax = s.plot.kde(ind=[1, 2, 3, 4, 5])

---->   Series.plot

--------------------------------------
ID: 9882 --> 2
>>> df = pd.DataFrame({
...     'x': [1, 2, 2.5, 3, 3.5, 4, 5],
...     'y': [4, 4, 4.5, 5, 5.5, 6, 6],
... })
>>> ax = df.plot.kde()

---->   pandas.DataFrame; DataFrame.plot

--------------------------------------
ID: 9883 --> 1
>>> ax = df.plot.kde(bw_method=0.3)

---->   DataFrame.plot

--------------------------------------
ID: 9884 --> 1
>>> ax = df.plot.kde(bw_method=3)

---->   DataFrame.plot

--------------------------------------
ID: 9885 --> 1
>>> ax = df.plot.kde(ind=[1, 2, 3, 4, 5, 6])

---->   DataFrame.plot

--------------------------------------
ID: 9886 --> 1
>>> df = pd.DataFrame(dict(age=[5, 6, np.NaN],
...                        born=[pd.NaT, pd.Timestamp('1939-05-27'),
...                              pd.Timestamp('1940-04-25')],
...                        name=['Alfred', 'Batman', ''],
...                        toy=[None, 'Batmobile', 'Joker']))
>>> df
   age       born    name        toy
0  5.0        NaT  Alfred       None
1  6.0 1939-05-27  Batman  Batmobile
2  NaN 1940-04-25              Joker

---->   pandas.DataFrame

--------------------------------------
ID: 9887 --> 1
>>> df.isna()
     age   born   name    toy
0  False   True  False   True
1  False  False  False  False
2   True  False  False  False

---->   DataFrame.isna

--------------------------------------
ID: 9888 --> 1
>>> ser = pd.Series([5, 6, np.NaN])
>>> ser
0    5.0
1    6.0
2    NaN
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 9889 --> 1
>>> ser.isna()
0    False
1    False
2     True
dtype: bool

---->   Series.isna

--------------------------------------
ID: 9890 --> 1
>>> c = pd.Categorical(['c', 'b', 'c'])
>>> c
['c', 'b', 'c']
Categories (2, object): ['b', 'c']

---->   pandas.Categorical

--------------------------------------
ID: 9892 --> 1
>>> period = pd.Period('2012-1-1', freq='D')
>>> period
Period('2012-01-01', 'D')

---->   pandas.Period

--------------------------------------
ID: 9895 --> 1
>>> countries_population = {"Italy": 59000000, "France": 65000000,
...                         "Brunei": 434000, "Malta": 434000,
...                         "Maldives": 434000, "Iceland": 337000,
...                         "Nauru": 11300, "Tuvalu": 11300,
...                         "Anguilla": 11300, "Montserrat": 5200}
>>> s = pd.Series(countries_population)
>>> s
Italy       59000000
France      65000000
Brunei        434000
Malta         434000
Maldives      434000
Iceland       337000
Nauru          11300
Tuvalu         11300
Anguilla       11300
Montserrat      5200
dtype: int64

---->   pandas.Series

--------------------------------------
ID: 9896 --> 1
>>> s.nsmallest()
Montserrat    5200
Nauru        11300
Tuvalu       11300
Anguilla     11300
Iceland     337000
dtype: int64

---->   Series.nsmallest

--------------------------------------
ID: 9897 --> 1
>>> s.nsmallest(3)
Montserrat   5200
Nauru       11300
Tuvalu      11300
dtype: int64

---->   Series.nsmallest

--------------------------------------
ID: 9898 --> 1
>>> s.nsmallest(3, keep='last')
Montserrat   5200
Anguilla    11300
Tuvalu      11300
dtype: int64

---->   Series.nsmallest

--------------------------------------
ID: 9899 --> 1
>>> s.nsmallest(3, keep='all')
Montserrat   5200
Nauru       11300
Tuvalu      11300
Anguilla    11300
dtype: int64

---->   Series.nsmallest

--------------------------------------
ID: 9900 --> 2
>>> df1 = pd.DataFrame([['a', 'b'], ['c', 'd']],
...                    index=['row 1', 'row 2'],
...                    columns=['col 1', 'col 2'])
>>> df1.to_excel("output.xlsx")  

---->   pandas.DataFrame; DataFrame.to_excel

--------------------------------------
ID: 9901 --> 1
>>> df1.to_excel("output.xlsx",
...              sheet_name='Sheet_name_1')  

---->   DataFrame.to_excel

--------------------------------------
ID: 9902 --> 4
>>> df2 = df1.copy()
>>> with pd.ExcelWriter('output.xlsx') as writer:  
...     df1.to_excel(writer, sheet_name='Sheet_name_1')
...     df2.to_excel(writer, sheet_name='Sheet_name_2')

---->   DataFrame.copy; pandas.ExcelWriter; DataFrame.to_excel; DataFrame.to_excel

--------------------------------------
ID: 9903 --> 2
>>> with pd.ExcelWriter('output.xlsx',
...                     mode='a') as writer:  
...     df.to_excel(writer, sheet_name='Sheet_name_3')

---->   pandas.ExcelWriter; DataFrame.to_excel

--------------------------------------
ID: 9904 --> 1
>>> df1.to_excel('output1.xlsx', engine='xlsxwriter')  

---->   DataFrame.to_excel

--------------------------------------
ID: 9905 --> 1
>>> primes = pd.Series([2, 3, 5, 7])

---->   pandas.Series

--------------------------------------
ID: 9908 --> 1
>>> df = pd.DataFrame([[1, 2], [3, 4]], columns=['a', 'b'])
>>> df
   a  b
0  1  2
1  3  4

---->   pandas.DataFrame

--------------------------------------
ID: 9912 --> 1
>>> s1 = pd.Series(['one', 'one1', '1', ''])

---->   pandas.Series

--------------------------------------
ID: 9916 --> 1
>>> s2 = pd.Series(['A B', '1.5', '3,000'])
>>> s2.str.isalnum()
0    False
1    False
2    False
dtype: bool

---->   pandas.Series

--------------------------------------
ID: 9917 --> 1
>>> s3 = pd.Series(['23', '³', '⅕', ''])

---->   pandas.Series

--------------------------------------
ID: 9921 --> 1
>>> s4 = pd.Series([' ', '\t\r\n ', ''])
>>> s4.str.isspace()
0     True
1     True
2    False
dtype: bool

---->   pandas.Series

--------------------------------------
ID: 9922 --> 1
>>> s5 = pd.Series(['leopard', 'Golden Eagle', 'SNAKE', ''])

---->   pandas.Series

--------------------------------------
ID: 9926 --> 1
>>> df = pd.DataFrame(
...     [
...         [24.3, 75.7, "high"],
...         [31, 87.8, "high"],
...         [22, 71.6, "medium"],
...         [35, 95, "medium"],
...     ],
...     columns=["temp_celsius", "temp_fahrenheit", "windspeed"],
...     index=pd.date_range(start="2014-02-12", end="2014-02-15", freq="D"),
... )

---->   pandas.DataFrame

--------------------------------------
ID: 9927 --> 1
>>> df.get(["temp_celsius", "windspeed"])
            temp_celsius windspeed
2014-02-12          24.3      high
2014-02-13          31.0      high
2014-02-14          22.0    medium
2014-02-15          35.0    medium

---->   DataFrame.get

--------------------------------------
ID: 9928 --> 1
>>> ser = df['windspeed']
>>> ser.get('2014-02-13')
'high'

---->   Series.get

--------------------------------------
ID: 9929 --> 1
>>> df.get(["temp_celsius", "temp_kelvin"], default="default_value")
'default_value'

---->   DataFrame.get

--------------------------------------
ID: 9930 --> 1
>>> ser.get('2014-02-10', '[unknown]')
'[unknown]'

---->   Series.get

--------------------------------------
ID: 9931 --> 1
>>> df = pd.DataFrame([[0, 2, 3], [0, 4, 1], [10, 20, 30]],
...                   index=[4, 5, 6], columns=['A', 'B', 'C'])
>>> df
    A   B   C
4   0   2   3
5   0   4   1
6  10  20  30

---->   pandas.DataFrame

--------------------------------------
ID: 9932 --> 1
>>> df = pd.DataFrame([[np.nan, 2, np.nan, 0],
...                    [3, 4, np.nan, 1],
...                    [np.nan, np.nan, np.nan, np.nan],
...                    [np.nan, 3, np.nan, 4]],
...                   columns=list("ABCD"))
>>> df
     A    B   C    D
0  NaN  2.0 NaN  0.0
1  3.0  4.0 NaN  1.0
2  NaN  NaN NaN  NaN
3  NaN  3.0 NaN  4.0

---->   pandas.DataFrame

--------------------------------------
ID: 9937 --> 1
>>> df2 = pd.DataFrame(np.zeros((4, 4)), columns=list("ABCE"))
>>> df.fillna(df2)
     A    B    C    D
0  0.0  2.0  0.0  0.0
1  3.0  4.0  0.0  1.0
2  0.0  0.0  0.0  NaN
3  0.0  3.0  0.0  4.0

---->   pandas.DataFrame

--------------------------------------
ID: 9938 --> 1
>>> data = {'col_0': [9, -3, 0, -1, 5], 'col_1': [-2, -7, 6, 8, -5]}
>>> df = pd.DataFrame(data)
>>> df
   col_0  col_1
0      9     -2
1     -3     -7
2      0      6
3     -1      8
4      5     -5

---->   pandas.DataFrame

--------------------------------------
ID: 9940 --> 1
>>> t = pd.Series([2, -4, -1, 6, 3])
>>> t
0    2
1   -4
2   -1
3    6
4    3
dtype: int64

---->   pandas.Series

--------------------------------------
ID: 9942 --> 1
>>> t = pd.Series([2, -4, np.NaN, 6, 3])
>>> t
0    2.0
1   -4.0
2    NaN
3    6.0
4    3.0
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 9944 --> 1
>>> df = pd.DataFrame(data={'Animal': ['cat', 'penguin', 'dog',
...                                    'spider', 'snake'],
...                         'Number_legs': [4, 2, 4, 8, np.nan]})
>>> df
    Animal  Number_legs
0      cat          4.0
1  penguin          2.0
2      dog          4.0
3   spider          8.0
4    snake          NaN

---->   pandas.DataFrame

--------------------------------------
ID: 9945 --> 2
>>> s = pd.Series(range(5), index=list("abcde"))
>>> s["d"] = s["b"]
>>> s.rank()
a    1.0
b    2.5
c    4.0
d    2.5
e    5.0
dtype: float64

---->   pandas.Series; Series.rank

--------------------------------------
ID: 9947 --> 2
>>> idx = pd.PeriodIndex(['2023', '2024', '2025'], freq='Y')
>>> s1 = pd.Series([1, 2, 3], index=idx)
>>> s1
2023    1
2024    2
2025    3
Freq: A-DEC, dtype: int64

---->   pandas.PeriodIndex; pandas.Series

--------------------------------------
ID: 9948 --> 1
>>> s1 = s1.to_timestamp()
>>> s1
2023-01-01    1
2024-01-01    2
2025-01-01    3
Freq: AS-JAN, dtype: int64

---->   Series.to_timestamp

--------------------------------------
ID: 9949 --> 2
>>> s2 = pd.Series([1, 2, 3], index=idx)
>>> s2 = s2.to_timestamp(freq='M')
>>> s2
2023-01-31    1
2024-01-31    2
2025-01-31    3
Freq: A-JAN, dtype: int64

---->   pandas.Series; Series.to_timestamp

--------------------------------------
ID: 9950 --> 1
>>> s = pd.Series([1, 2, 3], dtype=np.int64, name='Numbers')
>>> s
0    1
1    2
2    3
Name: Numbers, dtype: int64
>>> s.name = "Integers"
>>> s
0    1
1    2
2    3
Name: Integers, dtype: int64

---->   pandas.Series

--------------------------------------
ID: 9951 --> 1
>>> df = pd.DataFrame([[1, 2], [3, 4], [5, 6]],
...                   columns=["Odd Numbers", "Even Numbers"])
>>> df
   Odd Numbers  Even Numbers
0            1             2
1            3             4
2            5             6
>>> df["Even Numbers"].name
'Even Numbers'

---->   pandas.DataFrame

--------------------------------------
ID: 9952 --> 2
>>> index = pd.Index([3, 1, 2, 3, 4, np.nan])
>>> index.value_counts()
3.0    2
1.0    1
2.0    1
4.0    1
Name: count, dtype: int64

---->   pandas.Index; Index.value_counts

--------------------------------------
ID: 9953 --> 2
>>> s = pd.Series([3, 1, 2, 3, 4, np.nan])
>>> s.value_counts(normalize=True)
3.0    0.4
1.0    0.2
2.0    0.2
4.0    0.2
Name: proportion, dtype: float64

---->   pandas.Series; Series.value_counts

--------------------------------------
ID: 9954 --> 1
>>> s.value_counts(bins=3)
(0.996, 2.0]    2
(2.0, 3.0]      2
(3.0, 4.0]      1
Name: count, dtype: int64

---->   Series.value_counts

--------------------------------------
ID: 9955 --> 1
>>> s.value_counts(dropna=False)
3.0    2
1.0    1
2.0    1
4.0    1
NaN    1
Name: count, dtype: int64

---->   Series.value_counts

--------------------------------------
ID: 9956 --> 1
>>> s1 = pd.Series(['one', 'one1', '1', ''])

---->   pandas.Series

--------------------------------------
ID: 9960 --> 1
>>> s2 = pd.Series(['A B', '1.5', '3,000'])
>>> s2.str.isalnum()
0    False
1    False
2    False
dtype: bool

---->   pandas.Series

--------------------------------------
ID: 9961 --> 1
>>> s3 = pd.Series(['23', '³', '⅕', ''])

---->   pandas.Series

--------------------------------------
ID: 9965 --> 1
>>> s4 = pd.Series([' ', '\t\r\n ', ''])
>>> s4.str.isspace()
0     True
1     True
2    False
dtype: bool

---->   pandas.Series

--------------------------------------
ID: 9966 --> 1
>>> s5 = pd.Series(['leopard', 'Golden Eagle', 'SNAKE', ''])

---->   pandas.Series

--------------------------------------
ID: 9976 --> 1
>>> pd.Series([False, False]).any()
False
>>> pd.Series([True, False]).any()
True
>>> pd.Series([], dtype="float64").any()
False
>>> pd.Series([np.nan]).any()
False
>>> pd.Series([np.nan]).any(skipna=False)
True

---->   pandas.Series

--------------------------------------
ID: 9977 --> 1
>>> df = pd.DataFrame({"A": [1, 2], "B": [0, 2], "C": [0, 0]})
>>> df
   A  B  C
0  1  0  0
1  2  2  0

---->   pandas.DataFrame

--------------------------------------
ID: 9979 --> 1
>>> df = pd.DataFrame({"A": [True, False], "B": [1, 2]})
>>> df
       A  B
0   True  1
1  False  2

---->   pandas.DataFrame

--------------------------------------
ID: 9981 --> 1
>>> df = pd.DataFrame({"A": [True, False], "B": [1, 0]})
>>> df
       A  B
0   True  1
1  False  0

---->   pandas.DataFrame

--------------------------------------
ID: 9984 --> 1
>>> pd.DataFrame([]).any()
Series([], dtype: bool)

---->   pandas.DataFrame

--------------------------------------
ID: 9985 --> 1
>>> datetime_series = pd.Series(
...     pd.date_range("2000-01-01", periods=3, freq="Y")
... )
>>> datetime_series
0   2000-12-31
1   2001-12-31
2   2002-12-31
dtype: datetime64[ns]
>>> datetime_series.dt.year
0    2000
1    2001
2    2002
dtype: int32

---->   pandas.Series

--------------------------------------
ID: 9986 --> 1
>>> s = pd.Series([1, 2, 3])
>>> s
0    1
1    2
2    3
dtype: int64
>>> s.rename("my_name")  # scalar, changes Series.name
0    1
1    2
2    3
Name: my_name, dtype: int64
>>> s.rename(lambda x: x ** 2)  # function, changes labels
0    1
1    2
4    3
dtype: int64
>>> s.rename({1: 3, 2: 5})  # mapping, changes labels
0    1
3    2
5    3
dtype: int64

---->   pandas.Series

--------------------------------------
ID: 9987 --> 1
>>> df_empty = pd.DataFrame({'A' : []})
>>> df_empty
Empty DataFrame
Columns: [A]
Index: []
>>> df_empty.empty
True

---->   pandas.DataFrame

--------------------------------------
ID: 9988 --> 1
>>> df = pd.DataFrame({'A' : [np.nan]})
>>> df
    A
0 NaN
>>> df.empty
False
>>> df.dropna().empty
True

---->   pandas.DataFrame

--------------------------------------
ID: 9989 --> 1
>>> ser_empty = pd.Series({'A' : []})
>>> ser_empty
A    []
dtype: object
>>> ser_empty.empty
False
>>> ser_empty = pd.Series()
>>> ser_empty.empty
True

---->   pandas.Series

--------------------------------------
ID: 9990 --> 2
>>> a = pd.Series([1, 1, 1, np.nan, 1], index=['a', 'b', 'c', 'd', 'e'])
>>> a
a    1.0
b    1.0
c    1.0
d    NaN
e    1.0
dtype: float64
>>> b = pd.Series([0, 1, 2, np.nan, 1], index=['a', 'b', 'c', 'd', 'f'])
>>> b
a    0.0
b    1.0
c    2.0
d    NaN
f    1.0
dtype: float64
>>> a.le(b, fill_value=0)
a    False
b     True
c     True
d    False
e    False
f     True
dtype: bool

---->   pandas.Series; Series.le

--------------------------------------
ID: 9991 --> 2
>>> s = pd.Series([1, 1, 2, 3, 5, 8])
>>> s.diff()
0    NaN
1    0.0
2    1.0
3    1.0
4    2.0
5    3.0
dtype: float64

---->   pandas.Series; Series.diff

--------------------------------------
ID: 9992 --> 1
>>> s.diff(periods=3)
0    NaN
1    NaN
2    NaN
3    2.0
4    4.0
5    6.0
dtype: float64

---->   Series.diff

--------------------------------------
ID: 9993 --> 1
>>> s.diff(periods=-1)
0    0.0
1   -1.0
2   -1.0
3   -2.0
4   -3.0
5    NaN
dtype: float64

---->   Series.diff

--------------------------------------
ID: 9994 --> 2
>>> s = pd.Series([1, 0], dtype=np.uint8)
>>> s.diff()
0      NaN
1    255.0
dtype: float64

---->   pandas.Series; Series.diff

--------------------------------------
ID: 9995 --> 1
>>> from json import loads, dumps
>>> df = pd.DataFrame(
...     [["a", "b"], ["c", "d"]],
...     index=["row 1", "row 2"],
...     columns=["col 1", "col 2"],
... )

---->   pandas.DataFrame

--------------------------------------
ID: 9996 --> 1
>>> result = df.to_json(orient="split")
>>> parsed = loads(result)
>>> dumps(parsed, indent=4)  
{
    "columns": [
        "col 1",
        "col 2"
    ],
    "index": [
        "row 1",
        "row 2"
    ],
    "data": [
        [
            "a",
            "b"
        ],
        [
            "c",
            "d"
        ]
    ]
}

---->   DataFrame.to_json

--------------------------------------
ID: 9997 --> 1
>>> result = df.to_json(orient="records")
>>> parsed = loads(result)
>>> dumps(parsed, indent=4)  
[
    {
        "col 1": "a",
        "col 2": "b"
    },
    {
        "col 1": "c",
        "col 2": "d"
    }
]

---->   DataFrame.to_json

--------------------------------------
ID: 9998 --> 1
>>> result = df.to_json(orient="index")
>>> parsed = loads(result)
>>> dumps(parsed, indent=4)  
{
    "row 1": {
        "col 1": "a",
        "col 2": "b"
    },
    "row 2": {
        "col 1": "c",
        "col 2": "d"
    }
}

---->   DataFrame.to_json

--------------------------------------
ID: 9999 --> 1
>>> result = df.to_json(orient="columns")
>>> parsed = loads(result)
>>> dumps(parsed, indent=4)  
{
    "col 1": {
        "row 1": "a",
        "row 2": "c"
    },
    "col 2": {
        "row 1": "b",
        "row 2": "d"
    }
}

---->   DataFrame.to_json

--------------------------------------
ID: 10000 --> 1
>>> result = df.to_json(orient="values")
>>> parsed = loads(result)
>>> dumps(parsed, indent=4)  
[
    [
        "a",
        "b"
    ],
    [
        "c",
        "d"
    ]
]

---->   DataFrame.to_json

--------------------------------------
ID: 10001 --> 1
>>> result = df.to_json(orient="table")
>>> parsed = loads(result)
>>> dumps(parsed, indent=4)  
{
    "schema": {
        "fields": [
            {
                "name": "index",
                "type": "string"
            },
            {
                "name": "col 1",
                "type": "string"
            },
            {
                "name": "col 2",
                "type": "string"
            }
        ],
        "primaryKey": [
            "index"
        ],
        "pandas_version": "1.4.0"
    },
    "data": [
        {
            "index": "row 1",
            "col 1": "a",
            "col 2": "b"
        },
        {
            "index": "row 2",
            "col 1": "c",
            "col 2": "d"
        }
    ]
}

---->   DataFrame.to_json

--------------------------------------
ID: 10002 --> 2
>>> s = pd.Series([1, 2, 2.5, 3, 3.5, 4, 5])
>>> ax = s.plot.kde()

---->   pandas.Series; Series.plot

--------------------------------------
ID: 10003 --> 1
>>> ax = s.plot.kde(bw_method=0.3)

---->   Series.plot

--------------------------------------
ID: 10004 --> 1
>>> ax = s.plot.kde(bw_method=3)

---->   Series.plot

--------------------------------------
ID: 10005 --> 1
>>> ax = s.plot.kde(ind=[1, 2, 3, 4, 5])

---->   Series.plot

--------------------------------------
ID: 10006 --> 2
>>> df = pd.DataFrame({
...     'x': [1, 2, 2.5, 3, 3.5, 4, 5],
...     'y': [4, 4, 4.5, 5, 5.5, 6, 6],
... })
>>> ax = df.plot.kde()

---->   pandas.DataFrame; DataFrame.plot

--------------------------------------
ID: 10007 --> 1
>>> ax = df.plot.kde(bw_method=0.3)

---->   DataFrame.plot

--------------------------------------
ID: 10008 --> 1
>>> ax = df.plot.kde(bw_method=3)

---->   DataFrame.plot

--------------------------------------
ID: 10009 --> 1
>>> ax = df.plot.kde(ind=[1, 2, 3, 4, 5, 6])

---->   DataFrame.plot

--------------------------------------
ID: 10010 --> 1
>>> s1 = pd.Series(['one', 'one1', '1', ''])

---->   pandas.Series

--------------------------------------
ID: 10014 --> 1
>>> s2 = pd.Series(['A B', '1.5', '3,000'])
>>> s2.str.isalnum()
0    False
1    False
2    False
dtype: bool

---->   pandas.Series

--------------------------------------
ID: 10015 --> 1
>>> s3 = pd.Series(['23', '³', '⅕', ''])

---->   pandas.Series

--------------------------------------
ID: 10019 --> 1
>>> s4 = pd.Series([' ', '\t\r\n ', ''])
>>> s4.str.isspace()
0     True
1     True
2    False
dtype: bool

---->   pandas.Series

--------------------------------------
ID: 10020 --> 1
>>> s5 = pd.Series(['leopard', 'Golden Eagle', 'SNAKE', ''])

---->   pandas.Series

--------------------------------------
ID: 10024 --> 1
>>> s = pd.Series(['a', 'b', 'c', 'd'], index=[3, 2, 1, 4])
>>> s.sort_index()
1    c
2    b
3    a
4    d
dtype: object

---->   pandas.Series

--------------------------------------
ID: 10026 --> 1
>>> s = pd.Series(['a', 'b', 'c', 'd'], index=[3, 2, 1, np.nan])
>>> s.sort_index(na_position='first')
NaN     d
 1.0    c
 2.0    b
 3.0    a
dtype: object

---->   pandas.Series

--------------------------------------
ID: 10027 --> 1
>>> arrays = [np.array(['qux', 'qux', 'foo', 'foo',
...                     'baz', 'baz', 'bar', 'bar']),
...           np.array(['two', 'one', 'two', 'one',
...                     'two', 'one', 'two', 'one'])]
>>> s = pd.Series([1, 2, 3, 4, 5, 6, 7, 8], index=arrays)
>>> s.sort_index(level=1)
bar  one    8
baz  one    6
foo  one    4
qux  one    2
bar  two    7
baz  two    5
foo  two    3
qux  two    1
dtype: int64

---->   pandas.Series

--------------------------------------
ID: 10029 --> 1
>>> s = pd.Series([1, 2, 3, 4], index=['A', 'b', 'C', 'd'])
>>> s.sort_index(key=lambda x : x.str.lower())
A    1
b    2
C    3
d    4
dtype: int64

---->   pandas.Series

--------------------------------------
ID: 10030 --> 1
>>> df = pd.DataFrame(np.array(([1, 2, 3], [4, 5, 6])),
...                   index=['mouse', 'rabbit'],
...                   columns=['one', 'two', 'three'])
>>> df
        one  two  three
mouse     1    2      3
rabbit    4    5      6

---->   pandas.DataFrame

--------------------------------------
ID: 10031 --> 1
>>> # select columns by name
>>> df.filter(items=['one', 'three'])
         one  three
mouse     1      3
rabbit    4      6

---->   DataFrame.filter

--------------------------------------
ID: 10032 --> 1
>>> # select columns by regular expression
>>> df.filter(regex='e$', axis=1)
         one  three
mouse     1      3
rabbit    4      6

---->   DataFrame.filter

--------------------------------------
ID: 10033 --> 1
>>> # select rows containing 'bbi'
>>> df.filter(like='bbi', axis=0)
         one  two  three
rabbit    4    5      6

---->   DataFrame.filter

--------------------------------------
ID: 10034 --> 1
>>> df = pd.DataFrame([('falcon', 'bird', 389.0, 2),
...                    ('parrot', 'bird', 24.0, 2),
...                    ('lion', 'mammal', 80.5, 4),
...                    ('monkey', 'mammal', np.nan, 4)],
...                   columns=['name', 'class', 'max_speed',
...                            'num_legs'])
>>> df
     name   class  max_speed  num_legs
0  falcon    bird      389.0         2
1  parrot    bird       24.0         2
2    lion  mammal       80.5         4
3  monkey  mammal        NaN         4

---->   pandas.DataFrame

--------------------------------------
ID: 10035 --> 1
>>> df.to_xarray()

Dimensions:    (index: 4)
Coordinates:
  * index      (index) int64 0 1 2 3
Data variables:
    name       (index) object 'falcon' 'parrot' 'lion' 'monkey'
    class      (index) object 'bird' 'bird' 'mammal' 'mammal'
    max_speed  (index) float64 389.0 24.0 80.5 nan
    num_legs   (index) int64 2 2 4 4

---->   DataFrame.to_xarray

--------------------------------------
ID: 10037 --> 2
>>> dates = pd.to_datetime(['2018-01-01', '2018-01-01',
...                         '2018-01-02', '2018-01-02'])
>>> df_multiindex = pd.DataFrame({'date': dates,
...                               'animal': ['falcon', 'parrot',
...                                          'falcon', 'parrot'],
...                               'speed': [350, 18, 361, 15]})
>>> df_multiindex = df_multiindex.set_index(['date', 'animal'])

---->   pandas.to_datetime; pandas.DataFrame

--------------------------------------
ID: 10039 --> 1
>>> s = pd.Series(['lama', 'cow', 'lama', 'beetle', 'lama', 'hippo'],
...               name='animal')
>>> s
0      lama
1       cow
2      lama
3    beetle
4      lama
5     hippo
Name: animal, dtype: object

---->   pandas.Series

--------------------------------------
ID: 10043 --> 1
>>> datetime_series = pd.Series(
...     pd.date_range("2000-01-01", periods=3, freq="M")
... )
>>> datetime_series
0   2000-01-31
1   2000-02-29
2   2000-03-31
dtype: datetime64[ns]
>>> datetime_series.dt.month
0    1
1    2
2    3
dtype: int32

---->   pandas.Series

--------------------------------------
ID: 10044 --> 2
>>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])
>>> a
a    1.0
b    1.0
c    1.0
d    NaN
dtype: float64
>>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])
>>> b
a    1.0
b    NaN
d    1.0
e    NaN
dtype: float64
>>> a.ne(b, fill_value=0)
a    False
b     True
c     True
d     True
e     True
dtype: bool

---->   pandas.Series; Series.ne

--------------------------------------
ID: 10045 --> 2
>>> s = pd.Series([3.0, np.nan, 1.0, 3.0, np.nan, np.nan])
>>> s.index = pd.MultiIndex.from_tuples(
...     [
...         (1, 2, "a", 0),
...         (1, 2, "a", 1),
...         (1, 1, "b", 0),
...         (1, 1, "b", 1),
...         (2, 1, "b", 0),
...         (2, 1, "b", 1)
...     ],
...     names=["A", "B", "C", "D"],
... )
>>> s
A  B  C  D
1  2  a  0    3.0
         1    NaN
   1  b  0    1.0
         1    3.0
2  1  b  0    NaN
         1    NaN
dtype: float64

---->   pandas.Series; pandas.MultiIndex

--------------------------------------
ID: 10046 --> 1
>>> ss = s.astype("Sparse")
>>> ss
A  B  C  D
1  2  a  0    3.0
         1    NaN
   1  b  0    1.0
         1    3.0
2  1  b  0    NaN
         1    NaN
dtype: Sparse[float64, nan]

---->   Series.astype

--------------------------------------
ID: 10049 --> 2
>>> df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]},
...                   index=['a', 'b', 'c'])  
>>> df.to_hdf('data.h5', key='df', mode='w')  

---->   pandas.DataFrame; DataFrame.to_hdf

--------------------------------------
ID: 10050 --> 2
>>> s = pd.Series([1, 2, 3, 4])  
>>> s.to_hdf('data.h5', key='s')  

---->   pandas.Series; Series.to_hdf

--------------------------------------
ID: 10051 --> 1
>>> pd.read_hdf('data.h5', 'df')  
A  B
a  1  4
b  2  5
c  3  6
>>> pd.read_hdf('data.h5', 's')  
0    1
1    2
2    3
3    4
dtype: int64

---->   pandas.read_hdf

--------------------------------------
ID: 10052 --> 1
>>> s = pd.Series(["a1a2", "b1", "c1"], index=["A", "B", "C"])
>>> s.str.extractall(r"[ab](\d)")
        0
match
A 0      1
  1      2
B 0      1

---->   pandas.Series

--------------------------------------
ID: 10056 --> 1
>>> s = pd.Series(pd.date_range("2018-02-27", periods=3))
>>> s
0   2018-02-27
1   2018-02-28
2   2018-03-01
dtype: datetime64[ns]
>>> s.dt.is_month_start
0    False
1    False
2    True
dtype: bool
>>> s.dt.is_month_end
0    False
1    True
2    False
dtype: bool

---->   pandas.Series

--------------------------------------
ID: 10058 --> 2
>>> df = pd.DataFrame({'lab': ['A', 'B', 'C'], 'val': [10, 30, 20]})
>>> ax = df.plot.barh(x='lab', y='val')

---->   pandas.DataFrame; DataFrame.plot

--------------------------------------
ID: 10059 --> 2
>>> speed = [0.1, 17.5, 40, 48, 52, 69, 88]
>>> lifespan = [2, 8, 70, 1.5, 25, 12, 28]
>>> index = ['snail', 'pig', 'elephant',
...          'rabbit', 'giraffe', 'coyote', 'horse']
>>> df = pd.DataFrame({'speed': speed,
...                    'lifespan': lifespan}, index=index)
>>> ax = df.plot.barh()

---->   pandas.DataFrame; DataFrame.plot

--------------------------------------
ID: 10060 --> 1
>>> ax = df.plot.barh(stacked=True)

---->   DataFrame.plot

--------------------------------------
ID: 10061 --> 1
>>> ax = df.plot.barh(color={"speed": "red", "lifespan": "green"})

---->   DataFrame.plot

--------------------------------------
ID: 10062 --> 2
>>> speed = [0.1, 17.5, 40, 48, 52, 69, 88]
>>> lifespan = [2, 8, 70, 1.5, 25, 12, 28]
>>> index = ['snail', 'pig', 'elephant',
...          'rabbit', 'giraffe', 'coyote', 'horse']
>>> df = pd.DataFrame({'speed': speed,
...                    'lifespan': lifespan}, index=index)
>>> ax = df.plot.barh(y='speed')

---->   pandas.DataFrame; DataFrame.plot

--------------------------------------
ID: 10063 --> 2
>>> speed = [0.1, 17.5, 40, 48, 52, 69, 88]
>>> lifespan = [2, 8, 70, 1.5, 25, 12, 28]
>>> index = ['snail', 'pig', 'elephant',
...          'rabbit', 'giraffe', 'coyote', 'horse']
>>> df = pd.DataFrame({'speed': speed,
...                    'lifespan': lifespan}, index=index)
>>> ax = df.plot.barh(x='lifespan')

---->   pandas.DataFrame; DataFrame.plot

--------------------------------------
ID: 10064 --> 1
>>> s = pd.Series([1, 2, 3])
>>> s
0    1
1    2
2    3
dtype: int64

---->   pandas.Series

--------------------------------------
ID: 10066 --> 1
>>> c = pd.Categorical(['a', 'a', 'b'])
>>> c.rename_categories([0, 1])
[0, 0, 1]
Categories (2, int64): [0, 1]

---->   pandas.Categorical

--------------------------------------
ID: 10069 --> 2
>>> s1 = pd.Series([0.90010907, 0.13484424, 0.62036035])
>>> s2 = pd.Series([0.12528585, 0.26962463, 0.51111198])
>>> s1.cov(s2)
-0.01685762652715874

---->   pandas.Series; Series.cov

--------------------------------------
ID: 10070 --> 1
>>> pd.Series([True, True]).all()
True
>>> pd.Series([True, False]).all()
False
>>> pd.Series([], dtype="float64").all()
True
>>> pd.Series([np.nan]).all()
True
>>> pd.Series([np.nan]).all(skipna=False)
True

---->   pandas.Series

--------------------------------------
ID: 10071 --> 1
>>> df = pd.DataFrame({'col1': [True, True], 'col2': [True, False]})
>>> df
   col1   col2
0  True   True
1  True  False

---->   pandas.DataFrame

--------------------------------------
ID: 10072 --> 1
>>> df.all()
col1     True
col2    False
dtype: bool

---->   DataFrame.all

--------------------------------------
ID: 10073 --> 1
>>> df.all(axis='columns')
0     True
1    False
dtype: bool

---->   DataFrame.all

--------------------------------------
ID: 10074 --> 1
>>> df.all(axis=None)
False

---->   DataFrame.all

--------------------------------------
ID: 10075 --> 1
>>> df = pd.DataFrame({'person_id': [0, 1, 2, 3],
...                    'age': [21, 25, 62, 43],
...                    'height': [1.61, 1.87, 1.49, 2.01]}
...                   ).set_index('person_id')
>>> df
           age  height
person_id
0           21    1.61
1           25    1.87
2           62    1.49
3           43    2.01

---->   pandas.DataFrame

--------------------------------------
ID: 10076 --> 1
>>> df.std()
age       18.786076
height     0.237417
dtype: float64

---->   DataFrame.std

--------------------------------------
ID: 10077 --> 1
>>> df.std(ddof=0)
age       16.269219
height     0.205609
dtype: float64

---->   DataFrame.std

--------------------------------------
ID: 10078 --> 1
>>> df = pd.DataFrame({'num_legs': [2, 4, 8, 0],
...                    'num_wings': [2, 0, 0, 0],
...                    'num_specimen_seen': [10, 2, 1, 8]},
...                   index=['falcon', 'dog', 'spider', 'fish'])
>>> df
        num_legs  num_wings  num_specimen_seen
falcon         2          2                 10
dog            4          0                  2
spider         8          0                  1
fish           0          0                  8

---->   pandas.DataFrame

--------------------------------------
ID: 10080 --> 1
>>> df.sample(frac=0.5, replace=True, random_state=1)
      num_legs  num_wings  num_specimen_seen
dog          4          0                  2
fish         0          0                  8

---->   DataFrame.sample

--------------------------------------
ID: 10081 --> 1
>>> df.sample(frac=2, replace=True, random_state=1)
        num_legs  num_wings  num_specimen_seen
dog            4          0                  2
fish           0          0                  8
falcon         2          2                 10
falcon         2          2                 10
fish           0          0                  8
dog            4          0                  2
fish           0          0                  8
dog            4          0                  2

---->   DataFrame.sample

--------------------------------------
ID: 10082 --> 1
>>> df.sample(n=2, weights='num_specimen_seen', random_state=1)
        num_legs  num_wings  num_specimen_seen
falcon         2          2                 10
fish           0          0                  8

---->   DataFrame.sample

--------------------------------------
ID: 10083 --> 1
>>> d = {'col1': [1, 2], 'col2': [3, 4]}
>>> df = pd.DataFrame(data=d)
>>> df.dtypes
col1    int64
col2    int64
dtype: object

---->   pandas.DataFrame

--------------------------------------
ID: 10084 --> 1
>>> df.astype('int32').dtypes
col1    int32
col2    int32
dtype: object

---->   DataFrame.astype

--------------------------------------
ID: 10085 --> 1
>>> df.astype({'col1': 'int32'}).dtypes
col1    int32
col2    int64
dtype: object

---->   DataFrame.astype

--------------------------------------
ID: 10086 --> 2
>>> ser = pd.Series([1, 2], dtype='int32')
>>> ser
0    1
1    2
dtype: int32
>>> ser.astype('int64')
0    1
1    2
dtype: int64

---->   pandas.Series; Series.astype

--------------------------------------
ID: 10087 --> 1
>>> ser.astype('category')
0    1
1    2
dtype: category
Categories (2, int32): [1, 2]

---->   Series.astype

--------------------------------------
ID: 10088 --> 1
>>> from pandas.api.types import CategoricalDtype
>>> cat_dtype = CategoricalDtype(
...     categories=[2, 1], ordered=True)
>>> ser.astype(cat_dtype)
0    1
1    2
dtype: category
Categories (2, int64): [2 < 1]

---->   Series.astype

--------------------------------------
ID: 10089 --> 1
>>> ser_date = pd.Series(pd.date_range('20200101', periods=3))
>>> ser_date
0   2020-01-01
1   2020-01-02
2   2020-01-03
dtype: datetime64[ns]

---->   pandas.Series

--------------------------------------
ID: 10090 --> 1
>>> s = pd.Series([1, 2, 3, 4])
>>> s
0    1
1    2
2    3
3    4
dtype: int64

---->   pandas.Series

--------------------------------------
ID: 10091 --> 1
>>> s.agg('min')
1

---->   Series.agg

--------------------------------------
ID: 10092 --> 1
>>> s.agg(['min', 'max'])
min   1
max   4
dtype: int64

---->   Series.agg

--------------------------------------
ID: 10093 --> 2
>>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])
>>> a
a    1.0
b    1.0
c    1.0
d    NaN
dtype: float64
>>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])
>>> b
a    1.0
b    NaN
d    1.0
e    NaN
dtype: float64
>>> a.add(b, fill_value=0)
a    2.0
b    1.0
c    1.0
d    1.0
e    NaN
dtype: float64

---->   pandas.Series; Series.add

--------------------------------------
ID: 10095 --> 3
>>> s = pd.Series(
...     [1],
...     index=pd.DatetimeIndex(['2018-09-15 01:30:00+02:00']),
... )
>>> s.tz_convert('Asia/Shanghai')
2018-09-15 07:30:00+08:00    1
dtype: int64

---->   pandas.Series; pandas.DatetimeIndex; Series.tz_convert

--------------------------------------
ID: 10096 --> 3
>>> s = pd.Series([1],
...     index=pd.DatetimeIndex(['2018-09-15 01:30:00+02:00']))
>>> s.tz_convert(None)
2018-09-14 23:30:00    1
dtype: int64

---->   pandas.Series; pandas.DatetimeIndex; Series.tz_convert

--------------------------------------
ID: 10097 --> 1
>>> pd.Series([], dtype="float64").prod()
1.0

---->   pandas.Series

--------------------------------------
ID: 10098 --> 1
>>> pd.Series([], dtype="float64").prod(min_count=1)
nan

---->   pandas.Series

--------------------------------------
ID: 10099 --> 1
>>> pd.Series([np.nan]).prod()
1.0

---->   pandas.Series

--------------------------------------
ID: 10100 --> 1
>>> pd.Series([np.nan]).prod(min_count=1)
nan

---->   pandas.Series

--------------------------------------
ID: 10101 --> 1
>>> s = pd.Series(pd.date_range(start='2018-01-01', freq='D', periods=3))
>>> s
0   2018-01-01
1   2018-01-02
2   2018-01-03
dtype: datetime64[ns]
>>> s.dt.day_name()
0       Monday
1      Tuesday
2    Wednesday
dtype: object

---->   pandas.Series

--------------------------------------
ID: 10104 --> 1
>>> s1 = pd.Series(['one', 'one1', '1', ''])

---->   pandas.Series

--------------------------------------
ID: 10108 --> 1
>>> s2 = pd.Series(['A B', '1.5', '3,000'])
>>> s2.str.isalnum()
0    False
1    False
2    False
dtype: bool

---->   pandas.Series

--------------------------------------
ID: 10109 --> 1
>>> s3 = pd.Series(['23', '³', '⅕', ''])

---->   pandas.Series

--------------------------------------
ID: 10113 --> 1
>>> s4 = pd.Series([' ', '\t\r\n ', ''])
>>> s4.str.isspace()
0     True
1     True
2    False
dtype: bool

---->   pandas.Series

--------------------------------------
ID: 10114 --> 1
>>> s5 = pd.Series(['leopard', 'Golden Eagle', 'SNAKE', ''])

---->   pandas.Series

--------------------------------------
ID: 10118 --> 2
>>> df = pd.DataFrame({"y": [1, 2, 3]},
...                   index=pd.to_datetime(["2000-03-31 00:00:00",
...                                         "2000-05-31 00:00:00",
...                                         "2000-08-31 00:00:00"]))
>>> df.index.to_period("M")
PeriodIndex(['2000-03', '2000-05', '2000-08'],
            dtype='period[M]')

---->   pandas.DataFrame; pandas.to_datetime

--------------------------------------
ID: 10120 --> 1
>>> i = pd.date_range('2018-04-09', periods=4, freq='2D')
>>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)
>>> ts
            A
2018-04-09  1
2018-04-11  2
2018-04-13  3
2018-04-15  4

---->   pandas.DataFrame

--------------------------------------
ID: 10121 --> 1
>>> ts.last('3D')
            A
2018-04-13  3
2018-04-15  4

---->   DataFrame.last

--------------------------------------
ID: 10125 --> 2
>>> s = pd.to_datetime(pd.Series(['2018-10-28 01:30:00',
...                               '2018-10-28 02:00:00',
...                               '2018-10-28 02:30:00',
...                               '2018-10-28 02:00:00',
...                               '2018-10-28 02:30:00',
...                               '2018-10-28 03:00:00',
...                               '2018-10-28 03:30:00']))
>>> s.dt.tz_localize('CET', ambiguous='infer')
0   2018-10-28 01:30:00+02:00
1   2018-10-28 02:00:00+02:00
2   2018-10-28 02:30:00+02:00
3   2018-10-28 02:00:00+01:00
4   2018-10-28 02:30:00+01:00
5   2018-10-28 03:00:00+01:00
6   2018-10-28 03:30:00+01:00
dtype: datetime64[ns, CET]

---->   pandas.to_datetime; pandas.Series

--------------------------------------
ID: 10126 --> 2
>>> s = pd.to_datetime(pd.Series(['2018-10-28 01:20:00',
...                               '2018-10-28 02:36:00',
...                               '2018-10-28 03:46:00']))
>>> s.dt.tz_localize('CET', ambiguous=np.array([True, True, False]))
0   2018-10-28 01:20:00+02:00
1   2018-10-28 02:36:00+02:00
2   2018-10-28 03:46:00+01:00
dtype: datetime64[ns, CET]

---->   pandas.to_datetime; pandas.Series

--------------------------------------
ID: 10127 --> 2
>>> s = pd.to_datetime(pd.Series(['2015-03-29 02:30:00',
...                               '2015-03-29 03:30:00']))
>>> s.dt.tz_localize('Europe/Warsaw', nonexistent='shift_forward')
0   2015-03-29 03:00:00+02:00
1   2015-03-29 03:30:00+02:00
dtype: datetime64[ns, Europe/Warsaw]

---->   pandas.to_datetime; pandas.Series

--------------------------------------
ID: 10130 --> 2
>>> s = pd.Series([1, 2, 3])
>>> s.describe()
count    3.0
mean     2.0
std      1.0
min      1.0
25%      1.5
50%      2.0
75%      2.5
max      3.0
dtype: float64

---->   pandas.Series; Series.describe

--------------------------------------
ID: 10131 --> 2
>>> s = pd.Series(['a', 'a', 'b', 'c'])
>>> s.describe()
count     4
unique    3
top       a
freq      2
dtype: object

---->   pandas.Series; Series.describe

--------------------------------------
ID: 10132 --> 2
>>> s = pd.Series([
...     np.datetime64("2000-01-01"),
...     np.datetime64("2010-01-01"),
...     np.datetime64("2010-01-01")
... ])
>>> s.describe()
count                      3
mean     2006-09-01 08:00:00
min      2000-01-01 00:00:00
25%      2004-12-31 12:00:00
50%      2010-01-01 00:00:00
75%      2010-01-01 00:00:00
max      2010-01-01 00:00:00
dtype: object

---->   pandas.Series; Series.describe

--------------------------------------
ID: 10133 --> 3
>>> df = pd.DataFrame({'categorical': pd.Categorical(['d','e','f']),
...                    'numeric': [1, 2, 3],
...                    'object': ['a', 'b', 'c']
...                   })
>>> df.describe()
       numeric
count      3.0
mean       2.0
std        1.0
min        1.0
25%        1.5
50%        2.0
75%        2.5
max        3.0

---->   pandas.DataFrame; pandas.Categorical; DataFrame.describe

--------------------------------------
ID: 10134 --> 1
>>> df.describe(include='all')  
       categorical  numeric object
count            3      3.0      3
unique           3      NaN      3
top              f      NaN      a
freq             1      NaN      1
mean           NaN      2.0    NaN
std            NaN      1.0    NaN
min            NaN      1.0    NaN
25%            NaN      1.5    NaN
50%            NaN      2.0    NaN
75%            NaN      2.5    NaN
max            NaN      3.0    NaN

---->   DataFrame.describe

--------------------------------------
ID: 10136 --> 1
>>> df.describe(include=[np.number])
       numeric
count      3.0
mean       2.0
std        1.0
min        1.0
25%        1.5
50%        2.0
75%        2.5
max        3.0

---->   DataFrame.describe

--------------------------------------
ID: 10137 --> 1
>>> df.describe(include=[object])  
       object
count       3
unique      3
top         a
freq        1

---->   DataFrame.describe

--------------------------------------
ID: 10138 --> 1
>>> df.describe(include=['category'])
       categorical
count            3
unique           3
top              d
freq             1

---->   DataFrame.describe

--------------------------------------
ID: 10139 --> 1
>>> df.describe(exclude=[np.number])  
       categorical object
count            3      3
unique           3      3
top              f      a
freq             1      1

---->   DataFrame.describe

--------------------------------------
ID: 10140 --> 1
>>> df.describe(exclude=[object])  
       categorical  numeric
count            3      3.0
unique           3      NaN
top              f      NaN
freq             1      NaN
mean           NaN      2.0
std            NaN      1.0
min            NaN      1.0
25%            NaN      1.5
50%            NaN      2.0
75%            NaN      2.5
max            NaN      3.0

---->   DataFrame.describe

--------------------------------------
ID: 10141 --> 1
>>> s = pd.Series(['lower', 'CAPITALS', 'this is a sentence', 'SwApCaSe'])
>>> s
0                 lower
1              CAPITALS
2    this is a sentence
3              SwApCaSe
dtype: object

---->   pandas.Series

--------------------------------------
ID: 10147 --> 1
>>> dates = pd.Series(pd.date_range("2017-12-30", periods=3))
>>> dates
0   2017-12-30
1   2017-12-31
2   2018-01-01
dtype: datetime64[ns]

---->   pandas.Series

--------------------------------------
ID: 10151 --> 1
>>> s = pd.Series(["String",
...               (1, 2, 3),
...               ["a", "b", "c"],
...               123,
...               -456,
...               {1: "Hello", "2": "World"}])
>>> s
0                        String
1                     (1, 2, 3)
2                     [a, b, c]
3                           123
4                          -456
5    {1: 'Hello', '2': 'World'}
dtype: object

---->   pandas.Series

--------------------------------------
ID: 10154 --> 1
>>> s = pd.Series([{"name": "Hello", "value": "World"},
...               {"name": "Goodbye", "value": "Planet"}])
>>> s.str.get('name')
0      Hello
1    Goodbye
dtype: object

---->   pandas.Series

--------------------------------------
ID: 10155 --> 2
>>> df = pd.DataFrame(
...     np.random.randint(1, 7, 6000),
...     columns = ['one'])
>>> df['two'] = df['one'] + np.random.randint(1, 7, 6000)
>>> ax = df.plot.hist(bins=12, alpha=0.5)

---->   pandas.DataFrame; DataFrame.plot

--------------------------------------
ID: 10156 --> 2
>>> age_list = [8, 10, 12, 14, 72, 74, 76, 78, 20, 25, 30, 35, 60, 85]
>>> df = pd.DataFrame({"gender": list("MMMMMMMMFFFFFF"), "age": age_list})
>>> ax = df.plot.hist(column=["age"], by="gender", figsize=(10, 8))

---->   pandas.DataFrame; DataFrame.plot

--------------------------------------
ID: 10157 --> 1
>>> s = pd.Series(["caribou", "tiger"])
>>> s
0    caribou
1      tiger
dtype: object

---->   pandas.Series

--------------------------------------
ID: 10161 --> 2
>>> df = pd.DataFrame({'dates': pd.date_range("2017-03-30",
...                   periods=4)})
>>> df.assign(quarter=df.dates.dt.quarter,
...           is_quarter_start=df.dates.dt.is_quarter_start)
       dates  quarter  is_quarter_start
0 2017-03-30        1             False
1 2017-03-31        1             False
2 2017-04-01        2              True
3 2017-04-02        2             False

---->   pandas.DataFrame; DataFrame.assign

--------------------------------------
ID: 10164 --> 2
>>> s = pd.Series([1, 2, 3, 4], name='foo',
...               index=pd.Index(['a', 'b', 'c', 'd'], name='idx'))

---->   pandas.Series; pandas.Index

--------------------------------------
ID: 10168 --> 2
>>> arrays = [np.array(['bar', 'bar', 'baz', 'baz']),
...           np.array(['one', 'two', 'one', 'two'])]
>>> s2 = pd.Series(
...     range(4), name='foo',
...     index=pd.MultiIndex.from_arrays(arrays,
...                                     names=['a', 'b']))

---->   pandas.Series; pandas.MultiIndex

--------------------------------------
ID: 10171 --> 1
>>> mydict = [{'a': 1, 'b': 2, 'c': 3, 'd': 4},
...           {'a': 100, 'b': 200, 'c': 300, 'd': 400},
...           {'a': 1000, 'b': 2000, 'c': 3000, 'd': 4000 }]
>>> df = pd.DataFrame(mydict)
>>> df
      a     b     c     d
0     1     2     3     4
1   100   200   300   400
2  1000  2000  3000  4000

---->   pandas.DataFrame

--------------------------------------
ID: 10174 --> 3
>>> s = pd.Series([0, 1, 2, 3])
>>> other = pd.Series([-1, 2, -3, 4])
>>> s.dot(other)
8
>>> s @ other
8
>>> df = pd.DataFrame([[0, 1], [-2, 3], [4, -5], [6, 7]])
>>> s.dot(df)
0    24
1    14
dtype: int64
>>> arr = np.array([[0, 1], [-2, 3], [4, -5], [6, 7]])
>>> s.dot(arr)
array([24, 14])

---->   pandas.Series; Series.dot; pandas.DataFrame

--------------------------------------
ID: 10175 --> 1
>>> s = pd.Series(
...     ["A", "B", "A", "C"],
...     index=[
...         ["Final exam", "Final exam", "Coursework", "Coursework"],
...         ["History", "Geography", "History", "Geography"],
...         ["January", "February", "March", "April"],
...     ],
... )
>>> s
Final exam  History     January      A
            Geography   February     B
Coursework  History     March        A
            Geography   April        C
dtype: object

---->   pandas.Series

--------------------------------------
ID: 10176 --> 1
>>> s.swaplevel()
Final exam  January     History         A
            February    Geography       B
Coursework  March       History         A
            April       Geography       C
dtype: object

---->   Series.swaplevel

--------------------------------------
ID: 10177 --> 1
>>> s.swaplevel(0)
January     History     Final exam      A
February    Geography   Final exam      B
March       History     Coursework      A
April       Geography   Coursework      C
dtype: object

---->   Series.swaplevel

--------------------------------------
ID: 10178 --> 1
>>> s.swaplevel(0, 1)
History     Final exam  January         A
Geography   Final exam  February        B
History     Coursework  March           A
Geography   Coursework  April           C
dtype: object

---->   Series.swaplevel

--------------------------------------
ID: 10179 --> 2
>>> index = pd.date_range('1/1/2000', periods=4, freq='T')
>>> series = pd.Series([0.0, None, 2.0, 3.0], index=index)
>>> df = pd.DataFrame({'s': series})
>>> df
                       s
2000-01-01 00:00:00    0.0
2000-01-01 00:01:00    NaN
2000-01-01 00:02:00    2.0
2000-01-01 00:03:00    3.0

---->   pandas.Series; pandas.DataFrame

--------------------------------------
ID: 10180 --> 1
>>> df.asfreq(freq='30S')
                       s
2000-01-01 00:00:00    0.0
2000-01-01 00:00:30    NaN
2000-01-01 00:01:00    NaN
2000-01-01 00:01:30    NaN
2000-01-01 00:02:00    2.0
2000-01-01 00:02:30    NaN
2000-01-01 00:03:00    3.0

---->   DataFrame.asfreq

--------------------------------------
ID: 10181 --> 1
>>> df.asfreq(freq='30S', fill_value=9.0)
                       s
2000-01-01 00:00:00    0.0
2000-01-01 00:00:30    9.0
2000-01-01 00:01:00    NaN
2000-01-01 00:01:30    9.0
2000-01-01 00:02:00    2.0
2000-01-01 00:02:30    9.0
2000-01-01 00:03:00    3.0

---->   DataFrame.asfreq

--------------------------------------
ID: 10182 --> 1
>>> df.asfreq(freq='30S', method='bfill')
                       s
2000-01-01 00:00:00    0.0
2000-01-01 00:00:30    NaN
2000-01-01 00:01:00    NaN
2000-01-01 00:01:30    2.0
2000-01-01 00:02:00    2.0
2000-01-01 00:02:30    3.0
2000-01-01 00:03:00    3.0

---->   DataFrame.asfreq

--------------------------------------
ID: 10184 --> 1
>>> pd.Series(rng).dt.round("H")
0   2018-01-01 12:00:00
1   2018-01-01 12:00:00
2   2018-01-01 12:00:00
dtype: datetime64[ns]

---->   pandas.Series

--------------------------------------
ID: 10185 --> 1
>>> rng_tz = pd.DatetimeIndex(["2021-10-31 03:30:00"], tz="Europe/Amsterdam")

---->   pandas.DatetimeIndex

--------------------------------------
ID: 10186 --> 1
>>> rng_tz.floor("2H", ambiguous=False)
DatetimeIndex(['2021-10-31 02:00:00+01:00'],
              dtype='datetime64[ns, Europe/Amsterdam]', freq=None)

---->   DatetimeIndex.floor

--------------------------------------
ID: 10187 --> 1
>>> rng_tz.floor("2H", ambiguous=True)
DatetimeIndex(['2021-10-31 02:00:00+02:00'],
              dtype='datetime64[ns, Europe/Amsterdam]', freq=None)

---->   DatetimeIndex.floor

--------------------------------------
ID: 10190 --> 1
>>> ss = pd.Series.sparse.from_coo(A)
>>> ss
0  2    1.0
   3    2.0
1  0    3.0
dtype: Sparse[float64, nan]

---->   pandas.Series

--------------------------------------
ID: 10191 --> 1
>>> s = pd.Series(pd.date_range('20180310', periods=2))
>>> s
0   2018-03-10
1   2018-03-11
dtype: datetime64[ns]

---->   pandas.Series

--------------------------------------
ID: 10193 --> 1
>>> s = pd.Series(pd.date_range('20180310', periods=2, freq='ns'))
>>> s
0   2018-03-10 00:00:00.000000000
1   2018-03-10 00:00:00.000000001
dtype: datetime64[ns]

---->   pandas.Series

--------------------------------------
ID: 10195 --> 2
>>> a = pd.Series([1, 1, 1, np.nan, 1], index=['a', 'b', 'c', 'd', 'e'])
>>> a
a    1.0
b    1.0
c    1.0
d    NaN
e    1.0
dtype: float64
>>> b = pd.Series([0, 1, 2, np.nan, 1], index=['a', 'b', 'c', 'd', 'f'])
>>> b
a    0.0
b    1.0
c    2.0
d    NaN
f    1.0
dtype: float64
>>> a.ge(b, fill_value=0)
a     True
b     True
c    False
d    False
e     True
f    False
dtype: bool

---->   pandas.Series; Series.ge

--------------------------------------
ID: 10196 --> 2
>>> df = pd.DataFrame({'mass': [0.330, 4.87 , 5.97],
...                    'radius': [2439.7, 6051.8, 6378.1]},
...                   index=['Mercury', 'Venus', 'Earth'])
>>> plot = df.plot.pie(y='mass', figsize=(5, 5))

---->   pandas.DataFrame; DataFrame.plot

--------------------------------------
ID: 10197 --> 1
>>> plot = df.plot.pie(subplots=True, figsize=(11, 6))

---->   DataFrame.plot

--------------------------------------
ID: 10199 --> 1
>>> pd.Series(rng).dt.floor("H")
0   2018-01-01 11:00:00
1   2018-01-01 12:00:00
2   2018-01-01 12:00:00
dtype: datetime64[ns]

---->   pandas.Series

--------------------------------------
ID: 10200 --> 1
>>> rng_tz = pd.DatetimeIndex(["2021-10-31 03:30:00"], tz="Europe/Amsterdam")

---->   pandas.DatetimeIndex

--------------------------------------
ID: 10201 --> 1
>>> rng_tz.floor("2H", ambiguous=False)
DatetimeIndex(['2021-10-31 02:00:00+01:00'],
             dtype='datetime64[ns, Europe/Amsterdam]', freq=None)

---->   DatetimeIndex.floor

--------------------------------------
ID: 10202 --> 1
>>> rng_tz.floor("2H", ambiguous=True)
DatetimeIndex(['2021-10-31 02:00:00+02:00'],
              dtype='datetime64[ns, Europe/Amsterdam]', freq=None)

---->   DatetimeIndex.floor

--------------------------------------
ID: 10203 --> 3
>>> ser = pd.Series(pd.Categorical(['a', 'b', 'a']))
>>> ser.to_numpy()
array(['a', 'b', 'a'], dtype=object)

---->   pandas.Series; pandas.Categorical; Series.to_numpy

--------------------------------------
ID: 10204 --> 2
>>> ser = pd.Series(pd.date_range('2000', periods=2, tz="CET"))
>>> ser.to_numpy(dtype=object)
array([Timestamp('2000-01-01 00:00:00+0100', tz='CET'),
       Timestamp('2000-01-02 00:00:00+0100', tz='CET')],
      dtype=object)

---->   pandas.Series; Series.to_numpy

--------------------------------------
ID: 10205 --> 1
>>> ser.to_numpy(dtype="datetime64[ns]")
... 
array(['1999-12-31T23:00:00.000000000', '2000-01-01T23:00:00...'],
      dtype='datetime64[ns]')

---->   Series.to_numpy

--------------------------------------
ID: 10206 --> 1
>>> s = pd.Series({'Corn Flakes': 100.0, 'Almond Delight': 110.0,
...                'Cinnamon Toast Crunch': 120.0, 'Cocoa Puff': 110.0})
>>> s
Corn Flakes              100.0
Almond Delight           110.0
Cinnamon Toast Crunch    120.0
Cocoa Puff               110.0
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 10207 --> 2
>>> s.argmax()
2
>>> s.argmin()
0

---->   Series.argmax; Series.argmin

--------------------------------------
ID: 10208 --> 1
>>> c = pd.Categorical(['a', 'c', 'b', 'c', 'd'])
>>> c
['a', 'c', 'b', 'c', 'd']
Categories (4, object): ['a', 'b', 'c', 'd']

---->   pandas.Categorical

--------------------------------------
ID: 10211 --> 1
>>> pd.Series(rng).dt.ceil("H")
0   2018-01-01 12:00:00
1   2018-01-01 12:00:00
2   2018-01-01 13:00:00
dtype: datetime64[ns]

---->   pandas.Series

--------------------------------------
ID: 10212 --> 1
>>> rng_tz = pd.DatetimeIndex(["2021-10-31 01:30:00"], tz="Europe/Amsterdam")

---->   pandas.DatetimeIndex

--------------------------------------
ID: 10213 --> 1
>>> rng_tz.ceil("H", ambiguous=False)
DatetimeIndex(['2021-10-31 02:00:00+01:00'],
              dtype='datetime64[ns, Europe/Amsterdam]', freq=None)

---->   DatetimeIndex.ceil

--------------------------------------
ID: 10214 --> 1
>>> rng_tz.ceil("H", ambiguous=True)
DatetimeIndex(['2021-10-31 02:00:00+02:00'],
              dtype='datetime64[ns, Europe/Amsterdam]', freq=None)

---->   DatetimeIndex.ceil

--------------------------------------
ID: 10215 --> 1
>>> s = pd.Series(["dog", "cat", "monkey"])
>>> s
0       dog
1       cat
2    monkey
dtype: object
>>> s.rename_axis("animal")
animal
0    dog
1    cat
2    monkey
dtype: object

---->   pandas.Series

--------------------------------------
ID: 10216 --> 1
>>> df = pd.DataFrame({"num_legs": [4, 4, 2],
...                    "num_arms": [0, 0, 2]},
...                   ["dog", "cat", "monkey"])
>>> df
        num_legs  num_arms
dog            4         0
cat            4         0
monkey         2         2
>>> df = df.rename_axis("animal")
>>> df
        num_legs  num_arms
animal
dog            4         0
cat            4         0
monkey         2         2
>>> df = df.rename_axis("limbs", axis="columns")
>>> df
limbs   num_legs  num_arms
animal
dog            4         0
cat            4         0
monkey         2         2

---->   pandas.DataFrame

--------------------------------------
ID: 10217 --> 1
>>> df.index = pd.MultiIndex.from_product([['mammal'],
...                                        ['dog', 'cat', 'monkey']],
...                                       names=['type', 'name'])
>>> df
limbs          num_legs  num_arms
type   name
mammal dog            4         0
       cat            4         0
       monkey         2         2

---->   pandas.MultiIndex

--------------------------------------
ID: 10220 --> 2
>>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])
>>> a
a    1.0
b    1.0
c    1.0
d    NaN
dtype: float64
>>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])
>>> b
a    1.0
b    NaN
d    1.0
e    NaN
dtype: float64
>>> a.add(b, fill_value=0)
a    2.0
b    1.0
c    1.0
d    1.0
e    NaN
dtype: float64

---->   pandas.Series; Series.add

--------------------------------------
ID: 10222 --> 1
>>> (df.pipe(h)
...    .pipe(g, arg1=a)
...    .pipe(func, arg2=b, arg3=c)
... )  

---->   DataFrame.pipe

--------------------------------------
ID: 10223 --> 1
>>> (df.pipe(h)
...    .pipe(g, arg1=a)
...    .pipe((func, 'arg2'), arg1=a, arg3=c)
...  )  

---->   DataFrame.pipe

--------------------------------------
ID: 10224 --> 1
>>> datetime_series = pd.Series(
...     pd.date_range("2000-01-01", periods=3, freq="D")
... )
>>> datetime_series
0   2000-01-01
1   2000-01-02
2   2000-01-03
dtype: datetime64[ns]
>>> datetime_series.dt.day
0    1
1    2
2    3
dtype: int32

---->   pandas.Series

--------------------------------------
ID: 10225 --> 1
>>> s = pd.Series(['a', 'ab', 'abc', 'abdc', 'abcde'])
>>> s
0        a
1       ab
2      abc
3     abdc
4    abcde
dtype: object

---->   pandas.Series

--------------------------------------
ID: 10229 --> 1
>>> s = pd.Series([2, 0, 4, 8, np.nan])

---->   pandas.Series

--------------------------------------
ID: 10230 --> 1
>>> s.between(1, 4)
0     True
1    False
2     True
3    False
4    False
dtype: bool

---->   Series.between

--------------------------------------
ID: 10231 --> 1
>>> s.between(1, 4, inclusive="neither")
0     True
1    False
2    False
3    False
4    False
dtype: bool

---->   Series.between

--------------------------------------
ID: 10232 --> 2
>>> s = pd.Series(['Alice', 'Bob', 'Carol', 'Eve'])
>>> s.between('Anna', 'Daniel')
0    False
1     True
2     True
3    False
dtype: bool

---->   pandas.Series; Series.between

--------------------------------------
ID: 10233 --> 1
>>> s = pd.Series({'Corn Flakes': 100.0, 'Almond Delight': 110.0,
...                'Cinnamon Toast Crunch': 120.0, 'Cocoa Puff': 110.0})
>>> s
Corn Flakes              100.0
Almond Delight           110.0
Cinnamon Toast Crunch    120.0
Cocoa Puff               110.0
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 10234 --> 2
>>> s.argmax()
2
>>> s.argmin()
0

---->   Series.argmax; Series.argmin

--------------------------------------
ID: 10235 --> 3
>>> s = pd.Series(
...     [1],
...     index=pd.DatetimeIndex(['2018-09-15 01:30:00']),
... )
>>> s.tz_localize('CET')
2018-09-15 01:30:00+02:00    1
dtype: int64

---->   pandas.Series; pandas.DatetimeIndex; Series.tz_localize

--------------------------------------
ID: 10236 --> 3
>>> s = pd.Series([1],
...     index=pd.DatetimeIndex(['2018-09-15 01:30:00+02:00']))
>>> s.tz_localize(None)
2018-09-15 01:30:00    1
dtype: int64

---->   pandas.Series; pandas.DatetimeIndex; Series.tz_localize

--------------------------------------
ID: 10237 --> 3
>>> s = pd.Series(range(7),
...               index=pd.DatetimeIndex(['2018-10-28 01:30:00',
...                                       '2018-10-28 02:00:00',
...                                       '2018-10-28 02:30:00',
...                                       '2018-10-28 02:00:00',
...                                       '2018-10-28 02:30:00',
...                                       '2018-10-28 03:00:00',
...                                       '2018-10-28 03:30:00']))
>>> s.tz_localize('CET', ambiguous='infer')
2018-10-28 01:30:00+02:00    0
2018-10-28 02:00:00+02:00    1
2018-10-28 02:30:00+02:00    2
2018-10-28 02:00:00+01:00    3
2018-10-28 02:30:00+01:00    4
2018-10-28 03:00:00+01:00    5
2018-10-28 03:30:00+01:00    6
dtype: int64

---->   pandas.Series; pandas.DatetimeIndex; Series.tz_localize

--------------------------------------
ID: 10238 --> 3
>>> s = pd.Series(range(3),
...               index=pd.DatetimeIndex(['2018-10-28 01:20:00',
...                                       '2018-10-28 02:36:00',
...                                       '2018-10-28 03:46:00']))
>>> s.tz_localize('CET', ambiguous=np.array([True, True, False]))
2018-10-28 01:20:00+02:00    0
2018-10-28 02:36:00+02:00    1
2018-10-28 03:46:00+01:00    2
dtype: int64

---->   pandas.Series; pandas.DatetimeIndex; Series.tz_localize

--------------------------------------
ID: 10239 --> 3
>>> s = pd.Series(range(2),
...               index=pd.DatetimeIndex(['2015-03-29 02:30:00',
...                                       '2015-03-29 03:30:00']))
>>> s.tz_localize('Europe/Warsaw', nonexistent='shift_forward')
2015-03-29 03:00:00+02:00    0
2015-03-29 03:30:00+02:00    1
dtype: int64
>>> s.tz_localize('Europe/Warsaw', nonexistent='shift_backward')
2015-03-29 01:59:59.999999999+01:00    0
2015-03-29 03:30:00+02:00              1
dtype: int64
>>> s.tz_localize('Europe/Warsaw', nonexistent=pd.Timedelta('1H'))
2015-03-29 03:30:00+02:00    0
2015-03-29 03:30:00+02:00    1
dtype: int64

---->   pandas.Series; pandas.DatetimeIndex; Series.tz_localize

--------------------------------------
ID: 10240 --> 1
>>> df = pd.DataFrame(dict(age=[5, 6, np.NaN],
...                        born=[pd.NaT, pd.Timestamp('1939-05-27'),
...                              pd.Timestamp('1940-04-25')],
...                        name=['Alfred', 'Batman', ''],
...                        toy=[None, 'Batmobile', 'Joker']))
>>> df
   age       born    name        toy
0  5.0        NaT  Alfred       None
1  6.0 1939-05-27  Batman  Batmobile
2  NaN 1940-04-25              Joker

---->   pandas.DataFrame

--------------------------------------
ID: 10241 --> 1
>>> df.isna()
     age   born   name    toy
0  False   True  False   True
1  False  False  False  False
2   True  False  False  False

---->   DataFrame.isna

--------------------------------------
ID: 10242 --> 1
>>> ser = pd.Series([5, 6, np.NaN])
>>> ser
0    5.0
1    6.0
2    NaN
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 10243 --> 1
>>> ser.isna()
0    False
1    False
2     True
dtype: bool

---->   Series.isna

--------------------------------------
ID: 10244 --> 1
>>> s = pd.Series([2, np.nan, 5, -1, 0])
>>> s
0    2.0
1    NaN
2    5.0
3   -1.0
4    0.0
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 10245 --> 1
>>> s.cummax()
0    2.0
1    NaN
2    5.0
3    5.0
4    5.0
dtype: float64

---->   Series.cummax

--------------------------------------
ID: 10246 --> 1
>>> s.cummax(skipna=False)
0    2.0
1    NaN
2    NaN
3    NaN
4    NaN
dtype: float64

---->   Series.cummax

--------------------------------------
ID: 10247 --> 1
>>> df = pd.DataFrame([[2.0, 1.0],
...                    [3.0, np.nan],
...                    [1.0, 0.0]],
...                   columns=list('AB'))
>>> df
     A    B
0  2.0  1.0
1  3.0  NaN
2  1.0  0.0

---->   pandas.DataFrame

--------------------------------------
ID: 10248 --> 1
>>> df.cummax()
     A    B
0  2.0  1.0
1  3.0  NaN
2  3.0  1.0

---->   DataFrame.cummax

--------------------------------------
ID: 10249 --> 1
>>> df.cummax(axis=1)
     A    B
0  2.0  2.0
1  3.0  NaN
2  1.0  1.0

---->   DataFrame.cummax

--------------------------------------
ID: 10250 --> 1
>>> s1 = pd.Series(['one', 'one1', '1', ''])

---->   pandas.Series

--------------------------------------
ID: 10254 --> 1
>>> s2 = pd.Series(['A B', '1.5', '3,000'])
>>> s2.str.isalnum()
0    False
1    False
2    False
dtype: bool

---->   pandas.Series

--------------------------------------
ID: 10255 --> 1
>>> s3 = pd.Series(['23', '³', '⅕', ''])

---->   pandas.Series

--------------------------------------
ID: 10259 --> 1
>>> s4 = pd.Series([' ', '\t\r\n ', ''])
>>> s4.str.isspace()
0     True
1     True
2    False
dtype: bool

---->   pandas.Series

--------------------------------------
ID: 10260 --> 1
>>> s5 = pd.Series(['leopard', 'Golden Eagle', 'SNAKE', ''])

---->   pandas.Series

--------------------------------------
ID: 10264 --> 1
>>> s = pd.Series(['lower', 'CAPITALS', 'this is a sentence', 'SwApCaSe'])
>>> s
0                 lower
1              CAPITALS
2    this is a sentence
3              SwApCaSe
dtype: object

---->   pandas.Series

--------------------------------------
ID: 10271 --> 1
>>> s = pd.Series(['a', 'b', 'c'])
>>> s
0    a
1    b
2    c
dtype: object

---->   pandas.Series

--------------------------------------
ID: 10274 --> 1
>>> pd.Series(['a|b', 'a', 'a|c']).str.get_dummies()
   a  b  c
0  1  1  0
1  1  0  0
2  1  0  1

---->   pandas.Series

--------------------------------------
ID: 10275 --> 1
>>> pd.Series(['a|b', np.nan, 'a|c']).str.get_dummies()
   a  b  c
0  1  1  0
1  0  0  0
2  1  0  1

---->   pandas.Series

--------------------------------------
ID: 10276 --> 1
>>> s = pd.Series(['line to be wrapped', 'another line to be wrapped'])
>>> s.str.wrap(12)
0             line to be\nwrapped
1    another line\nto be\nwrapped
dtype: object

---->   pandas.Series

--------------------------------------
ID: 10277 --> 2
>>> s = pd.Series(["a", "b", "c"],
...               name="vals")
>>> s.to_frame()
  vals
0    a
1    b
2    c

---->   pandas.Series; Series.to_frame

--------------------------------------
ID: 10278 --> 2
>>> s = pd.Series(pd.to_timedelta(np.arange(5), unit='s'))
>>> s
0   0 days 00:00:00
1   0 days 00:00:01
2   0 days 00:00:02
3   0 days 00:00:03
4   0 days 00:00:04
dtype: timedelta64[ns]
>>> s.dt.components
   days  hours  minutes  seconds  milliseconds  microseconds  nanoseconds
0     0      0        0        0             0             0            0
1     0      0        0        1             0             0            0
2     0      0        0        2             0             0            0
3     0      0        0        3             0             0            0
4     0      0        0        4             0             0            0

---->   pandas.Series; pandas.to_timedelta

--------------------------------------
ID: 10279 --> 1
>>> df = pd.DataFrame([('falcon', 'bird', 389.0),
...                    ('parrot', 'bird', 24.0),
...                    ('lion', 'mammal', 80.5),
...                    ('monkey', 'mammal', np.nan)],
...                   columns=['name', 'class', 'max_speed'],
...                   index=[0, 2, 3, 1])
>>> df
     name   class  max_speed
0  falcon    bird      389.0
2  parrot    bird       24.0
3    lion  mammal       80.5
1  monkey  mammal        NaN

---->   pandas.DataFrame

--------------------------------------
ID: 10280 --> 1
>>> df.take([0, 3])
     name   class  max_speed
0  falcon    bird      389.0
1  monkey  mammal        NaN

---->   DataFrame.take

--------------------------------------
ID: 10281 --> 1
>>> df.take([1, 2], axis=1)
    class  max_speed
0    bird      389.0
2    bird       24.0
3  mammal       80.5
1  mammal        NaN

---->   DataFrame.take

--------------------------------------
ID: 10282 --> 1
>>> df.take([-1, -2])
     name   class  max_speed
1  monkey  mammal        NaN
3    lion  mammal       80.5

---->   DataFrame.take

--------------------------------------
ID: 10283 --> 2
>>> a = pd.Series([1, 1, 1, np.nan, 1], index=['a', 'b', 'c', 'd', 'e'])
>>> a
a    1.0
b    1.0
c    1.0
d    NaN
e    1.0
dtype: float64
>>> b = pd.Series([0, 1, 2, np.nan, 1], index=['a', 'b', 'c', 'd', 'f'])
>>> b
a    0.0
b    1.0
c    2.0
d    NaN
f    1.0
dtype: float64
>>> a.lt(b, fill_value=0)
a    False
b    False
c     True
d    False
e    False
f     True
dtype: bool

---->   pandas.Series; Series.lt

--------------------------------------
ID: 10285 --> 1
>>> dates_series = pd.Series(idx)
>>> dates_series
0   2012-12-31
1   2013-12-31
2   2014-12-31
dtype: datetime64[ns]
>>> dates_series.dt.is_leap_year
0     True
1    False
2    False
dtype: bool

---->   pandas.Series

--------------------------------------
ID: 10286 --> 1
>>> s = pd.Series(['cat', 'dog', np.nan, 'rabbit'])
>>> s
0      cat
1      dog
2      NaN
3   rabbit
dtype: object

---->   pandas.Series

--------------------------------------
ID: 10287 --> 1
>>> s.map({'cat': 'kitten', 'dog': 'puppy'})
0   kitten
1    puppy
2      NaN
3      NaN
dtype: object

---->   Series.map

--------------------------------------
ID: 10288 --> 1
>>> s.map('I am a {}'.format)
0       I am a cat
1       I am a dog
2       I am a nan
3    I am a rabbit
dtype: object

---->   Series.map

--------------------------------------
ID: 10289 --> 1
>>> s.map('I am a {}'.format, na_action='ignore')
0     I am a cat
1     I am a dog
2            NaN
3  I am a rabbit
dtype: object

---->   Series.map

--------------------------------------
ID: 10290 --> 1
>>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])
>>> a
a    1.0
b    1.0
c    1.0
d    NaN
dtype: float64
>>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])
>>> b
a    1.0
b    NaN
d    1.0
e    NaN
dtype: float64
>>> a.subtract(b, fill_value=0)
a    0.0
b    1.0
c    1.0
d   -1.0
e    NaN
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 10291 --> 1
>>> df = pd.DataFrame({"B": [0, 1, 2, np.nan, 4]})
>>> df
     B
0  0.0
1  1.0
2  2.0
3  NaN
4  4.0

---->   pandas.DataFrame

--------------------------------------
ID: 10292 --> 1
>>> df.expanding(1).sum()
     B
0  0.0
1  1.0
2  3.0
3  3.0
4  7.0
>>> df.expanding(3).sum()
     B
0  NaN
1  NaN
2  3.0
3  3.0
4  7.0

---->   DataFrame.expanding

--------------------------------------
ID: 10293 --> 1
>>> s1 = pd.Series(["a", "b", "c", "d", "e"])
>>> s2 = pd.Series(["a", "a", "c", "b", "e"])

---->   pandas.Series

--------------------------------------
ID: 10298 --> 1
>>> s = pd.Series(pd.date_range(start='2018-01', freq='M', periods=3))
>>> s
0   2018-01-31
1   2018-02-28
2   2018-03-31
dtype: datetime64[ns]
>>> s.dt.month_name()
0     January
1    February
2       March
dtype: object

---->   pandas.Series

--------------------------------------
ID: 10301 --> 1
>>> df = pd.DataFrame({"A": [1, 2]})
>>> df.flags.allows_duplicate_labels
True
>>> df2 = df.set_flags(allows_duplicate_labels=False)
>>> df2.flags.allows_duplicate_labels
False

---->   pandas.DataFrame

--------------------------------------
ID: 10302 --> 1
>>> s = pd.Series(['lower', 'CAPITALS', 'this is a sentence', 'SwApCaSe'])
>>> s
0                 lower
1              CAPITALS
2    this is a sentence
3              SwApCaSe
dtype: object

---->   pandas.Series

--------------------------------------
ID: 10308 --> 2
>>> s = pd.Series(['A', 'B', 'C'])
>>> for index, value in s.items():
...     print(f"Index : {index}, Value : {value}")
Index : 0, Value : A
Index : 1, Value : B
Index : 2, Value : C

---->   pandas.Series; Series.items

--------------------------------------
ID: 10309 --> 1
>>> ser = pd.Series([1, 2, 3])
>>> np.asarray(ser)
array([1, 2, 3])

---->   pandas.Series

--------------------------------------
ID: 10310 --> 1
>>> tzser = pd.Series(pd.date_range('2000', periods=2, tz="CET"))
>>> np.asarray(tzser, dtype="object")
array([Timestamp('2000-01-01 00:00:00+0100', tz='CET'),
       Timestamp('2000-01-02 00:00:00+0100', tz='CET')],
      dtype=object)

---->   pandas.Series

--------------------------------------
ID: 10312 --> 1
>>> df = pd.DataFrame(dict(age=[5, 6, np.NaN],
...                        born=[pd.NaT, pd.Timestamp('1939-05-27'),
...                              pd.Timestamp('1940-04-25')],
...                        name=['Alfred', 'Batman', ''],
...                        toy=[None, 'Batmobile', 'Joker']))
>>> df
   age       born    name        toy
0  5.0        NaT  Alfred       None
1  6.0 1939-05-27  Batman  Batmobile
2  NaN 1940-04-25              Joker

---->   pandas.DataFrame

--------------------------------------
ID: 10313 --> 1
>>> df.notna()
     age   born  name    toy
0   True  False  True  False
1   True   True  True   True
2  False   True  True   True

---->   DataFrame.notna

--------------------------------------
ID: 10314 --> 1
>>> ser = pd.Series([5, 6, np.NaN])
>>> ser
0    5.0
1    6.0
2    NaN
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 10315 --> 1
>>> ser.notna()
0     True
1     True
2    False
dtype: bool

---->   Series.notna

--------------------------------------
ID: 10316 --> 1
>>> index = ['Firefox', 'Chrome', 'Safari', 'IE10', 'Konqueror']
>>> df = pd.DataFrame({'http_status': [200, 200, 404, 404, 301],
...                   'response_time': [0.04, 0.02, 0.07, 0.08, 1.0]},
...                   index=index)
>>> df
           http_status  response_time
Firefox            200           0.04
Chrome             200           0.02
Safari             404           0.07
IE10               404           0.08
Konqueror          301           1.00

---->   pandas.DataFrame

--------------------------------------
ID: 10322 --> 1
>>> date_index = pd.date_range('1/1/2010', periods=6, freq='D')
>>> df2 = pd.DataFrame({"prices": [100, 101, np.nan, 100, 89, 88]},
...                    index=date_index)
>>> df2
            prices
2010-01-01   100.0
2010-01-02   101.0
2010-01-03     NaN
2010-01-04   100.0
2010-01-05    89.0
2010-01-06    88.0

---->   pandas.DataFrame

--------------------------------------
ID: 10325 --> 1
>>> ser = pd.Series([1., 2., np.nan])
>>> ser
0    1.0
1    2.0
2    NaN
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 10327 --> 1
>>> ser = pd.Series([np.NaN, 2, pd.NaT, '', None, 'I stay'])
>>> ser
0       NaN
1         2
2       NaT
3
4      None
5    I stay
dtype: object
>>> ser.dropna()
1         2
3
5    I stay
dtype: object

---->   pandas.Series

--------------------------------------
ID: 10328 --> 1
>>> df = pd.DataFrame([[0, 2, 3], [0, 4, 1], [10, 20, 30]],
...                   columns=['A', 'B', 'C'])
>>> df
    A   B   C
0   0   2   3
1   0   4   1
2  10  20  30

---->   pandas.DataFrame

--------------------------------------
ID: 10329 --> 1
>>> s1 = pd.Series(['one', 'one1', '1', ''])

---->   pandas.Series

--------------------------------------
ID: 10333 --> 1
>>> s2 = pd.Series(['A B', '1.5', '3,000'])
>>> s2.str.isalnum()
0    False
1    False
2    False
dtype: bool

---->   pandas.Series

--------------------------------------
ID: 10334 --> 1
>>> s3 = pd.Series(['23', '³', '⅕', ''])

---->   pandas.Series

--------------------------------------
ID: 10338 --> 1
>>> s4 = pd.Series([' ', '\t\r\n ', ''])
>>> s4.str.isspace()
0     True
1     True
2    False
dtype: bool

---->   pandas.Series

--------------------------------------
ID: 10339 --> 1
>>> s5 = pd.Series(['leopard', 'Golden Eagle', 'SNAKE', ''])

---->   pandas.Series

--------------------------------------
ID: 10343 --> 2
>>> idx = pd.MultiIndex.from_arrays([
...     ['warm', 'warm', 'cold', 'cold'],
...     ['dog', 'falcon', 'fish', 'spider']],
...     names=['blooded', 'animal'])
>>> s = pd.Series([4, 2, 0, 8], name='legs', index=idx)
>>> s
blooded  animal
warm     dog       4
         falcon    2
cold     fish      0
         spider    8
Name: legs, dtype: int64

---->   pandas.MultiIndex; pandas.Series

--------------------------------------
ID: 10344 --> 1
>>> s.max()
8

---->   Series.max

--------------------------------------
ID: 10345 --> 1
>>> df = pd.DataFrame({"A": [1, 2]})
>>> df.flags


---->   pandas.DataFrame

--------------------------------------
ID: 10346 --> 1
>>> s1 = pd.Series(['one', 'one1', '1', ''])

---->   pandas.Series

--------------------------------------
ID: 10350 --> 1
>>> s2 = pd.Series(['A B', '1.5', '3,000'])
>>> s2.str.isalnum()
0    False
1    False
2    False
dtype: bool

---->   pandas.Series

--------------------------------------
ID: 10351 --> 1
>>> s3 = pd.Series(['23', '³', '⅕', ''])

---->   pandas.Series

--------------------------------------
ID: 10355 --> 1
>>> s4 = pd.Series([' ', '\t\r\n ', ''])
>>> s4.str.isspace()
0     True
1     True
2    False
dtype: bool

---->   pandas.Series

--------------------------------------
ID: 10356 --> 1
>>> s5 = pd.Series(['leopard', 'Golden Eagle', 'SNAKE', ''])

---->   pandas.Series

--------------------------------------
ID: 10360 --> 1
>>> s = pd.Series([1, 2, 3, 4])
>>> s.to_dict()
{0: 1, 1: 2, 2: 3, 3: 4}
>>> from collections import OrderedDict, defaultdict
>>> s.to_dict(OrderedDict)
OrderedDict([(0, 1), (1, 2), (2, 3), (3, 4)])
>>> dd = defaultdict(list)
>>> s.to_dict(dd)
defaultdict(, {0: 1, 1: 2, 2: 3, 3: 4})

---->   pandas.Series

--------------------------------------
ID: 10361 --> 1
>>> i = pd.date_range('2018-04-09', periods=4, freq='1D20min')
>>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)
>>> ts
                     A
2018-04-09 00:00:00  1
2018-04-10 00:20:00  2
2018-04-11 00:40:00  3
2018-04-12 01:00:00  4

---->   pandas.DataFrame

--------------------------------------
ID: 10362 --> 1
>>> ts.between_time('0:15', '0:45')
                     A
2018-04-10 00:20:00  2
2018-04-11 00:40:00  3

---->   DataFrame.between_time

--------------------------------------
ID: 10363 --> 1
>>> ts.between_time('0:45', '0:15')
                     A
2018-04-09 00:00:00  1
2018-04-12 01:00:00  4

---->   DataFrame.between_time

--------------------------------------
ID: 10364 --> 2
>>> df = pd.DataFrame(dict(name=['Raphael', 'Donatello'],
...                        age=[26, 45],
...                        height=[181.23, 177.65]))
>>> print(df.to_latex(index=False,
...                   formatters={"name": str.upper},
...                   float_format="{:.1f}".format,
... ))  
\begin{tabular}{lrr}
\toprule
name & age & height \\
\midrule
RAPHAEL & 26 & 181.2 \\
DONATELLO & 45 & 177.7 \\
\bottomrule
\end{tabular}

---->   pandas.DataFrame; DataFrame.to_latex

--------------------------------------
ID: 10365 --> 1
>>> s = pd.Series([2, np.nan, 5, -1, 0])
>>> s
0    2.0
1    NaN
2    5.0
3   -1.0
4    0.0
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 10366 --> 1
>>> s.cumsum()
0    2.0
1    NaN
2    7.0
3    6.0
4    6.0
dtype: float64

---->   Series.cumsum

--------------------------------------
ID: 10367 --> 1
>>> s.cumsum(skipna=False)
0    2.0
1    NaN
2    NaN
3    NaN
4    NaN
dtype: float64

---->   Series.cumsum

--------------------------------------
ID: 10368 --> 1
>>> df = pd.DataFrame([[2.0, 1.0],
...                    [3.0, np.nan],
...                    [1.0, 0.0]],
...                   columns=list('AB'))
>>> df
     A    B
0  2.0  1.0
1  3.0  NaN
2  1.0  0.0

---->   pandas.DataFrame

--------------------------------------
ID: 10369 --> 1
>>> df.cumsum()
     A    B
0  2.0  1.0
1  5.0  NaN
2  6.0  1.0

---->   DataFrame.cumsum

--------------------------------------
ID: 10370 --> 1
>>> df.cumsum(axis=1)
     A    B
0  2.0  3.0
1  3.0  NaN
2  1.0  1.0

---->   DataFrame.cumsum

--------------------------------------
ID: 10371 --> 1
>>> s = pd.Series([0, 1, np.nan, 3])
>>> s
0    0.0
1    1.0
2    NaN
3    3.0
dtype: float64
>>> s.interpolate()
0    0.0
1    1.0
2    2.0
3    3.0
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 10372 --> 1
>>> s = pd.Series([np.nan, "single_one", np.nan,
...                "fill_two_more", np.nan, np.nan, np.nan,
...                4.71, np.nan])
>>> s
0              NaN
1       single_one
2              NaN
3    fill_two_more
4              NaN
5              NaN
6              NaN
7             4.71
8              NaN
dtype: object
>>> s.interpolate(method='pad', limit=2)
0              NaN
1       single_one
2       single_one
3    fill_two_more
4    fill_two_more
5    fill_two_more
6              NaN
7             4.71
8             4.71
dtype: object

---->   pandas.Series

--------------------------------------
ID: 10373 --> 1
>>> s = pd.Series([0, 2, np.nan, 8])
>>> s.interpolate(method='polynomial', order=2)
0    0.000000
1    2.000000
2    4.666667
3    8.000000
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 10374 --> 1
>>> df = pd.DataFrame([(0.0, np.nan, -1.0, 1.0),
...                    (np.nan, 2.0, np.nan, np.nan),
...                    (2.0, 3.0, np.nan, 9.0),
...                    (np.nan, 4.0, -4.0, 16.0)],
...                   columns=list('abcd'))
>>> df
     a    b    c     d
0  0.0  NaN -1.0   1.0
1  NaN  2.0  NaN   NaN
2  2.0  3.0  NaN   9.0
3  NaN  4.0 -4.0  16.0
>>> df.interpolate(method='linear', limit_direction='forward', axis=0)
     a    b    c     d
0  0.0  NaN -1.0   1.0
1  1.0  2.0 -2.0   5.0
2  2.0  3.0 -3.0   9.0
3  2.0  4.0 -4.0  16.0

---->   pandas.DataFrame

--------------------------------------
ID: 10376 --> 1
>>> pd.Series([1, 2, 3]).values
array([1, 2, 3])

---->   pandas.Series

--------------------------------------
ID: 10377 --> 1
>>> pd.Series(list('aabc')).values
array(['a', 'a', 'b', 'c'], dtype=object)

---->   pandas.Series

--------------------------------------
ID: 10378 --> 1
>>> pd.Series(list('aabc')).astype('category').values
['a', 'a', 'b', 'c']
Categories (3, object): ['a', 'b', 'c']

---->   pandas.Series

--------------------------------------
ID: 10379 --> 1
>>> pd.Series(pd.date_range('20130101', periods=3,
...                         tz='US/Eastern')).values
array(['2013-01-01T05:00:00.000000000',
       '2013-01-02T05:00:00.000000000',
       '2013-01-03T05:00:00.000000000'], dtype='datetime64[ns]')

---->   pandas.Series

--------------------------------------
ID: 10380 --> 1
>>> original_df = pd.DataFrame({"foo": range(5), "bar": range(5, 10)})  
>>> original_df  
   foo  bar
0    0    5
1    1    6
2    2    7
3    3    8
4    4    9
>>> original_df.to_pickle("./dummy.pkl")  

---->   pandas.DataFrame

--------------------------------------
ID: 10381 --> 1
>>> unpickled_df = pd.read_pickle("./dummy.pkl")  
>>> unpickled_df  
   foo  bar
0    0    5
1    1    6
2    2    7
3    3    8
4    4    9

---->   pandas.read_pickle

--------------------------------------
ID: 10382 --> 1
>>> s = pd.Series(['a', 'b', np.nan, 'd'])
>>> s.str.cat(sep=' ')
'a b d'

---->   pandas.Series

--------------------------------------
ID: 10387 --> 1
>>> t = pd.Series(['d', 'a', 'e', 'c'], index=[3, 0, 4, 2])
>>> s.str.cat(t, join='left', na_rep='-')
0    aa
1    b-
2    -c
3    dd
dtype: object
>>>
>>> s.str.cat(t, join='outer', na_rep='-')
0    aa
1    b-
2    -c
3    dd
4    -e
dtype: object
>>>
>>> s.str.cat(t, join='inner', na_rep='-')
0    aa
2    -c
3    dd
dtype: object
>>>
>>> s.str.cat(t, join='right', na_rep='-')
3    dd
0    aa
4    -e
2    -c
dtype: object

---->   pandas.Series

--------------------------------------
ID: 10388 --> 1
>>> df = pd.DataFrame({'animal': ['alligator', 'bee', 'falcon', 'lion',
...                    'monkey', 'parrot', 'shark', 'whale', 'zebra']})
>>> df
      animal
0  alligator
1        bee
2     falcon
3       lion
4     monkey
5     parrot
6      shark
7      whale
8      zebra

---->   pandas.DataFrame

--------------------------------------
ID: 10389 --> 1
>>> df.head()
      animal
0  alligator
1        bee
2     falcon
3       lion
4     monkey

---->   DataFrame.head

--------------------------------------
ID: 10390 --> 1
>>> df.head(3)
      animal
0  alligator
1        bee
2     falcon

---->   DataFrame.head

--------------------------------------
ID: 10391 --> 1
>>> df.head(-3)
      animal
0  alligator
1        bee
2     falcon
3       lion
4     monkey
5     parrot

---->   DataFrame.head

--------------------------------------
ID: 10392 --> 1
>>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])
>>> a
a    1.0
b    1.0
c    1.0
d    NaN
dtype: float64
>>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])
>>> b
a    1.0
b    NaN
d    1.0
e    NaN
dtype: float64
>>> a.divide(b, fill_value=0)
a    1.0
b    inf
c    inf
d    0.0
e    NaN
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 10393 --> 1
>>> s = pd.Series(['1. Ant.  ', '2. Bee!\n', '3. Cat?\t', np.nan, 10, True])
>>> s
0    1. Ant.
1    2. Bee!\n
2    3. Cat?\t
3          NaN
4           10
5         True
dtype: object

---->   pandas.Series

--------------------------------------
ID: 10398 --> 2
>>> s = pd.Series(pd.to_timedelta(np.arange(5), unit='d'))
>>> s
0   0 days
1   1 days
2   2 days
3   3 days
4   4 days
dtype: timedelta64[ns]

---->   pandas.Series; pandas.to_timedelta

--------------------------------------
ID: 10400 --> 1
>>> idx = pd.to_timedelta(np.arange(5), unit='d')
>>> idx
TimedeltaIndex(['0 days', '1 days', '2 days', '3 days', '4 days'],
               dtype='timedelta64[ns]', freq=None)

---->   pandas.to_timedelta

--------------------------------------
ID: 10402 --> 1
>>> df = pd.DataFrame({'A': ['a', 'b', 'c', 'd', 'e'],
...                    'B': ['f', 'g', 'h', 'i', 'j'],
...                    'C': ['k', 'l', 'm', 'n', 'o']},
...                   index=[1, 2, 3, 4, 5])
>>> df
   A  B  C
1  a  f  k
2  b  g  l
3  c  h  m
4  d  i  n
5  e  j  o

---->   pandas.DataFrame

--------------------------------------
ID: 10403 --> 1
>>> df.truncate(before=2, after=4)
   A  B  C
2  b  g  l
3  c  h  m
4  d  i  n

---->   DataFrame.truncate

--------------------------------------
ID: 10404 --> 1
>>> df.truncate(before="A", after="B", axis="columns")
   A  B
1  a  f
2  b  g
3  c  h
4  d  i
5  e  j

---->   DataFrame.truncate

--------------------------------------
ID: 10406 --> 2
>>> dates = pd.date_range('2016-01-01', '2016-02-01', freq='s')
>>> df = pd.DataFrame(index=dates, data={'A': 1})
>>> df.tail()
                     A
2016-01-31 23:59:56  1
2016-01-31 23:59:57  1
2016-01-31 23:59:58  1
2016-01-31 23:59:59  1
2016-02-01 00:00:00  1

---->   pandas.DataFrame; DataFrame.tail

--------------------------------------
ID: 10407 --> 1
>>> df.truncate(before=pd.Timestamp('2016-01-05'),
...             after=pd.Timestamp('2016-01-10')).tail()
                     A
2016-01-09 23:59:56  1
2016-01-09 23:59:57  1
2016-01-09 23:59:58  1
2016-01-09 23:59:59  1
2016-01-10 00:00:00  1

---->   DataFrame.truncate

--------------------------------------
ID: 10408 --> 1
>>> df.truncate('2016-01-05', '2016-01-10').tail()
                     A
2016-01-09 23:59:56  1
2016-01-09 23:59:57  1
2016-01-09 23:59:58  1
2016-01-09 23:59:59  1
2016-01-10 00:00:00  1

---->   DataFrame.truncate

--------------------------------------
ID: 10410 --> 2
>>> s = pd.Series([0.25, 0.5, 0.2, -0.05])
>>> s.autocorr()  
0.10355...
>>> s.autocorr(lag=2)  
-0.99999...

---->   pandas.Series; Series.autocorr

--------------------------------------
ID: 10411 --> 2
>>> s = pd.Series([1, 0, 0, 0])
>>> s.autocorr()
nan

---->   pandas.Series; Series.autocorr

--------------------------------------
ID: 10412 --> 1
>>> s = pd.Series(["str_foo", "str_bar", "no_prefix"])
>>> s
0    str_foo
1    str_bar
2    no_prefix
dtype: object
>>> s.str.removeprefix("str_")
0    foo
1    bar
2    no_prefix
dtype: object

---->   pandas.Series

--------------------------------------
ID: 10413 --> 1
>>> s = pd.Series(["foo_str", "bar_str", "no_suffix"])
>>> s
0    foo_str
1    bar_str
2    no_suffix
dtype: object
>>> s.str.removesuffix("_str")
0    foo
1    bar
2    no_suffix
dtype: object

---->   pandas.Series

--------------------------------------
ID: 10414 --> 1
>>> s = pd.Series([2, np.nan, 5, -1, 0])
>>> s
0    2.0
1    NaN
2    5.0
3   -1.0
4    0.0
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 10415 --> 1
>>> s.cummin()
0    2.0
1    NaN
2    2.0
3   -1.0
4   -1.0
dtype: float64

---->   Series.cummin

--------------------------------------
ID: 10416 --> 1
>>> s.cummin(skipna=False)
0    2.0
1    NaN
2    NaN
3    NaN
4    NaN
dtype: float64

---->   Series.cummin

--------------------------------------
ID: 10417 --> 1
>>> df = pd.DataFrame([[2.0, 1.0],
...                    [3.0, np.nan],
...                    [1.0, 0.0]],
...                   columns=list('AB'))
>>> df
     A    B
0  2.0  1.0
1  3.0  NaN
2  1.0  0.0

---->   pandas.DataFrame

--------------------------------------
ID: 10418 --> 1
>>> df.cummin()
     A    B
0  2.0  1.0
1  2.0  NaN
2  1.0  0.0

---->   DataFrame.cummin

--------------------------------------
ID: 10419 --> 1
>>> df.cummin(axis=1)
     A    B
0  2.0  1.0
1  3.0  NaN
2  1.0  0.0

---->   DataFrame.cummin

--------------------------------------
ID: 10420 --> 1
>>> df = pd.DataFrame({"A": ["a", 1, 2, 3]})
>>> df = df.iloc[1:]
>>> df
   A
1  1
2  2
3  3

---->   pandas.DataFrame

--------------------------------------
ID: 10421 --> 1
>>> df.infer_objects().dtypes
A    int64
dtype: object

---->   DataFrame.infer_objects

--------------------------------------
ID: 10422 --> 1
>>> d = {'num_legs': [4, 4, 2, 2],
...      'num_wings': [0, 0, 2, 2],
...      'class': ['mammal', 'mammal', 'mammal', 'bird'],
...      'animal': ['cat', 'dog', 'bat', 'penguin'],
...      'locomotion': ['walks', 'walks', 'flies', 'walks']}
>>> df = pd.DataFrame(data=d)
>>> df = df.set_index(['class', 'animal', 'locomotion'])
>>> df
                           num_legs  num_wings
class  animal  locomotion
mammal cat     walks              4          0
       dog     walks              4          0
       bat     flies              2          2
bird   penguin walks              2          2

---->   pandas.DataFrame

--------------------------------------
ID: 10423 --> 1
>>> df.xs('mammal')
                   num_legs  num_wings
animal locomotion
cat    walks              4          0
dog    walks              4          0
bat    flies              2          2

---->   DataFrame.xs

--------------------------------------
ID: 10424 --> 1
>>> df.xs(('mammal', 'dog', 'walks'))
num_legs     4
num_wings    0
Name: (mammal, dog, walks), dtype: int64

---->   DataFrame.xs

--------------------------------------
ID: 10425 --> 1
>>> df.xs('cat', level=1)
                   num_legs  num_wings
class  locomotion
mammal walks              4          0

---->   DataFrame.xs

--------------------------------------
ID: 10426 --> 1
>>> df.xs(('bird', 'walks'),
...       level=[0, 'locomotion'])
         num_legs  num_wings
animal
penguin         2          2

---->   DataFrame.xs

--------------------------------------
ID: 10427 --> 1
>>> df.xs('num_wings', axis=1)
class   animal   locomotion
mammal  cat      walks         0
        dog      walks         0
        bat      flies         2
bird    penguin  walks         2
Name: num_wings, dtype: int64

---->   DataFrame.xs

--------------------------------------
ID: 10428 --> 1
>>> df = pd.DataFrame({1: [10], 2: [20]})
>>> df
    1   2
0  10  20

---->   pandas.DataFrame

--------------------------------------
ID: 10429 --> 2
>>> exactly_equal = pd.DataFrame({1: [10], 2: [20]})
>>> exactly_equal
    1   2
0  10  20
>>> df.equals(exactly_equal)
True

---->   pandas.DataFrame; DataFrame.equals

--------------------------------------
ID: 10430 --> 2
>>> different_column_type = pd.DataFrame({1.0: [10], 2.0: [20]})
>>> different_column_type
   1.0  2.0
0   10   20
>>> df.equals(different_column_type)
True

---->   pandas.DataFrame; DataFrame.equals

--------------------------------------
ID: 10431 --> 2
>>> different_data_type = pd.DataFrame({1: [10.0], 2: [20.0]})
>>> different_data_type
      1     2
0  10.0  20.0
>>> df.equals(different_data_type)
False

---->   pandas.DataFrame; DataFrame.equals

--------------------------------------
ID: 10432 --> 1
>>> datetime_series = pd.Series(
...     pd.date_range("2000-01-01", periods=3, freq="us")
... )
>>> datetime_series
0   2000-01-01 00:00:00.000000
1   2000-01-01 00:00:00.000001
2   2000-01-01 00:00:00.000002
dtype: datetime64[ns]
>>> datetime_series.dt.microsecond
0       0
1       1
2       2
dtype: int32

---->   pandas.Series

--------------------------------------
ID: 10433 --> 1
>>> s = pd.Series(["str_foo", "str_bar", "no_prefix"])
>>> s
0    str_foo
1    str_bar
2    no_prefix
dtype: object
>>> s.str.removeprefix("str_")
0    foo
1    bar
2    no_prefix
dtype: object

---->   pandas.Series

--------------------------------------
ID: 10434 --> 1
>>> s = pd.Series(["foo_str", "bar_str", "no_suffix"])
>>> s
0    foo_str
1    bar_str
2    no_suffix
dtype: object
>>> s.str.removesuffix("_str")
0    foo
1    bar
2    no_suffix
dtype: object

---->   pandas.Series

--------------------------------------
ID: 10435 --> 1
>>> ser = pd.Series([1, 2, 3])
>>> ser
0    1
1    2
2    3
dtype: int64

---->   pandas.Series

--------------------------------------
ID: 10436 --> 1
>>> ser.searchsorted(4)
3

---->   Series.searchsorted

--------------------------------------
ID: 10437 --> 1
>>> ser.searchsorted([0, 4])
array([0, 3])

---->   Series.searchsorted

--------------------------------------
ID: 10438 --> 1
>>> ser.searchsorted([1, 3], side='left')
array([0, 2])

---->   Series.searchsorted

--------------------------------------
ID: 10439 --> 1
>>> ser.searchsorted([1, 3], side='right')
array([1, 3])

---->   Series.searchsorted

--------------------------------------
ID: 10440 --> 2
>>> ser = pd.Series(pd.to_datetime(['3/11/2000', '3/12/2000', '3/13/2000']))
>>> ser
0   2000-03-11
1   2000-03-12
2   2000-03-13
dtype: datetime64[ns]

---->   pandas.Series; pandas.to_datetime

--------------------------------------
ID: 10441 --> 1
>>> ser.searchsorted('3/14/2000')
3

---->   Series.searchsorted

--------------------------------------
ID: 10442 --> 1
>>> ser = pd.Categorical(
...     ['apple', 'bread', 'bread', 'cheese', 'milk'], ordered=True
... )
>>> ser
['apple', 'bread', 'bread', 'cheese', 'milk']
Categories (4, object): ['apple' < 'bread' < 'cheese' < 'milk']

---->   pandas.Categorical

--------------------------------------
ID: 10443 --> 1
>>> ser.searchsorted('bread')
1

---->   Series.searchsorted

--------------------------------------
ID: 10444 --> 1
>>> ser.searchsorted(['bread'], side='right')
array([3])

---->   Series.searchsorted

--------------------------------------
ID: 10445 --> 1
>>> ser = pd.Series([2, 1, 3])
>>> ser
0    2
1    1
2    3
dtype: int64

---->   pandas.Series

--------------------------------------
ID: 10446 --> 1
>>> ser.searchsorted(1)  
0  # wrong result, correct would be 1

---->   Series.searchsorted

--------------------------------------
ID: 10447 --> 1
>>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]})
>>> df
     B
0  0.0
1  1.0
2  2.0
3  NaN
4  4.0

---->   pandas.DataFrame

--------------------------------------
ID: 10448 --> 1
>>> df.ewm(com=0.5).mean()
          B
0  0.000000
1  0.750000
2  1.615385
3  1.615385
4  3.670213
>>> df.ewm(alpha=2 / 3).mean()
          B
0  0.000000
1  0.750000
2  1.615385
3  1.615385
4  3.670213

---->   DataFrame.ewm

--------------------------------------
ID: 10449 --> 1
>>> df.ewm(com=0.5, adjust=True).mean()
          B
0  0.000000
1  0.750000
2  1.615385
3  1.615385
4  3.670213
>>> df.ewm(com=0.5, adjust=False).mean()
          B
0  0.000000
1  0.666667
2  1.555556
3  1.555556
4  3.650794

---->   DataFrame.ewm

--------------------------------------
ID: 10450 --> 1
>>> df.ewm(com=0.5, ignore_na=True).mean()
          B
0  0.000000
1  0.750000
2  1.615385
3  1.615385
4  3.225000
>>> df.ewm(com=0.5, ignore_na=False).mean()
          B
0  0.000000
1  0.750000
2  1.615385
3  1.615385
4  3.670213

---->   DataFrame.ewm

--------------------------------------
ID: 10451 --> 2
>>> times = ['2020-01-01', '2020-01-03', '2020-01-10', '2020-01-15', '2020-01-17']
>>> df.ewm(halflife='4 days', times=pd.DatetimeIndex(times)).mean()
          B
0  0.000000
1  0.585786
2  1.523889
3  1.523889
4  3.233686

---->   DataFrame.ewm; pandas.DatetimeIndex

--------------------------------------
ID: 10452 --> 1
>>> s = pd.Series(data=np.arange(3), index=['A', 'B', 'C'])
>>> s
A  0
B  1
C  2
dtype: int64

---->   pandas.Series

--------------------------------------
ID: 10454 --> 2
>>> midx = pd.MultiIndex(levels=[['lama', 'cow', 'falcon'],
...                              ['speed', 'weight', 'length']],
...                      codes=[[0, 0, 0, 1, 1, 1, 2, 2, 2],
...                             [0, 1, 2, 0, 1, 2, 0, 1, 2]])
>>> s = pd.Series([45, 200, 1.2, 30, 250, 1.5, 320, 1, 0.3],
...               index=midx)
>>> s
lama    speed      45.0
        weight    200.0
        length      1.2
cow     speed      30.0
        weight    250.0
        length      1.5
falcon  speed     320.0
        weight      1.0
        length      0.3
dtype: float64

---->   pandas.MultiIndex; pandas.Series

--------------------------------------
ID: 10456 --> 1
>>> d = {'a': 1, 'b': 2, 'c': 3}
>>> ser = pd.Series(data=d, index=['a', 'b', 'c'])
>>> ser
a   1
b   2
c   3
dtype: int64

---->   pandas.Series

--------------------------------------
ID: 10457 --> 1
>>> d = {'a': 1, 'b': 2, 'c': 3}
>>> ser = pd.Series(data=d, index=['x', 'y', 'z'])
>>> ser
x   NaN
y   NaN
z   NaN
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 10458 --> 1
>>> r = [1, 2]
>>> ser = pd.Series(r, copy=False)
>>> ser.iloc[0] = 999
>>> r
[1, 2]
>>> ser
0    999
1      2
dtype: int64

---->   pandas.Series

--------------------------------------
ID: 10459 --> 1
>>> r = np.array([1, 2])
>>> ser = pd.Series(r, copy=False)
>>> ser.iloc[0] = 999
>>> r
array([999,   2])
>>> ser
0    999
1      2
dtype: int64

---->   pandas.Series

--------------------------------------
ID: 10460 --> 1
>>> index = pd.date_range('1/1/2000', periods=9, freq='T')
>>> series = pd.Series(range(9), index=index)
>>> series
2000-01-01 00:00:00    0
2000-01-01 00:01:00    1
2000-01-01 00:02:00    2
2000-01-01 00:03:00    3
2000-01-01 00:04:00    4
2000-01-01 00:05:00    5
2000-01-01 00:06:00    6
2000-01-01 00:07:00    7
2000-01-01 00:08:00    8
Freq: T, dtype: int64

---->   pandas.Series

--------------------------------------
ID: 10461 --> 1
>>> series.resample('3T').sum()
2000-01-01 00:00:00     3
2000-01-01 00:03:00    12
2000-01-01 00:06:00    21
Freq: 3T, dtype: int64

---->   Series.resample

--------------------------------------
ID: 10462 --> 1
>>> series.resample('3T', label='right').sum()
2000-01-01 00:03:00     3
2000-01-01 00:06:00    12
2000-01-01 00:09:00    21
Freq: 3T, dtype: int64

---->   Series.resample

--------------------------------------
ID: 10463 --> 1
>>> series.resample('3T', label='right', closed='right').sum()
2000-01-01 00:00:00     0
2000-01-01 00:03:00     6
2000-01-01 00:06:00    15
2000-01-01 00:09:00    15
Freq: 3T, dtype: int64

---->   Series.resample

--------------------------------------
ID: 10464 --> 1
>>> series.resample('30S').asfreq()[0:5]   # Select first 5 rows
2000-01-01 00:00:00   0.0
2000-01-01 00:00:30   NaN
2000-01-01 00:01:00   1.0
2000-01-01 00:01:30   NaN
2000-01-01 00:02:00   2.0
Freq: 30S, dtype: float64

---->   Series.resample

--------------------------------------
ID: 10465 --> 1
>>> series.resample('30S').ffill()[0:5]
2000-01-01 00:00:00    0
2000-01-01 00:00:30    0
2000-01-01 00:01:00    1
2000-01-01 00:01:30    1
2000-01-01 00:02:00    2
Freq: 30S, dtype: int64

---->   Series.resample

--------------------------------------
ID: 10466 --> 1
>>> series.resample('30S').bfill()[0:5]
2000-01-01 00:00:00    0
2000-01-01 00:00:30    1
2000-01-01 00:01:00    1
2000-01-01 00:01:30    2
2000-01-01 00:02:00    2
Freq: 30S, dtype: int64

---->   Series.resample

--------------------------------------
ID: 10467 --> 1
>>> def custom_resampler(arraylike):
...     return np.sum(arraylike) + 5
...
>>> series.resample('3T').apply(custom_resampler)
2000-01-01 00:00:00     8
2000-01-01 00:03:00    17
2000-01-01 00:06:00    26
Freq: 3T, dtype: int64

---->   Series.resample

--------------------------------------
ID: 10468 --> 3
>>> s = pd.Series([1, 2], index=pd.period_range('2012-01-01',
...                                             freq='A',
...                                             periods=2))
>>> s
2012    1
2013    2
Freq: A-DEC, dtype: int64
>>> s.resample('Q', convention='start').asfreq()
2012Q1    1.0
2012Q2    NaN
2012Q3    NaN
2012Q4    NaN
2013Q1    2.0
2013Q2    NaN
2013Q3    NaN
2013Q4    NaN
Freq: Q-DEC, dtype: float64

---->   pandas.Series; pandas.period_range; Series.resample

--------------------------------------
ID: 10469 --> 2
>>> q = pd.Series([1, 2, 3, 4], index=pd.period_range('2018-01-01',
...                                                   freq='Q',
...                                                   periods=4))
>>> q
2018Q1    1
2018Q2    2
2018Q3    3
2018Q4    4
Freq: Q-DEC, dtype: int64
>>> q.resample('M', convention='end').asfreq()
2018-03    1.0
2018-04    NaN
2018-05    NaN
2018-06    2.0
2018-07    NaN
2018-08    NaN
2018-09    3.0
2018-10    NaN
2018-11    NaN
2018-12    4.0
Freq: M, dtype: float64

---->   pandas.Series; pandas.period_range

--------------------------------------
ID: 10470 --> 2
>>> d = {'price': [10, 11, 9, 13, 14, 18, 17, 19],
...      'volume': [50, 60, 40, 100, 50, 100, 40, 50]}
>>> df = pd.DataFrame(d)
>>> df['week_starting'] = pd.date_range('01/01/2018',
...                                     periods=8,
...                                     freq='W')
>>> df
   price  volume week_starting
0     10      50    2018-01-07
1     11      60    2018-01-14
2      9      40    2018-01-21
3     13     100    2018-01-28
4     14      50    2018-02-04
5     18     100    2018-02-11
6     17      40    2018-02-18
7     19      50    2018-02-25
>>> df.resample('M', on='week_starting').mean()
               price  volume
week_starting
2018-01-31     10.75    62.5
2018-02-28     17.00    60.0

---->   pandas.DataFrame; DataFrame.resample

--------------------------------------
ID: 10471 --> 3
>>> days = pd.date_range('1/1/2000', periods=4, freq='D')
>>> d2 = {'price': [10, 11, 9, 13, 14, 18, 17, 19],
...       'volume': [50, 60, 40, 100, 50, 100, 40, 50]}
>>> df2 = pd.DataFrame(
...     d2,
...     index=pd.MultiIndex.from_product(
...         [days, ['morning', 'afternoon']]
...     )
... )
>>> df2
                      price  volume
2000-01-01 morning       10      50
           afternoon     11      60
2000-01-02 morning        9      40
           afternoon     13     100
2000-01-03 morning       14      50
           afternoon     18     100
2000-01-04 morning       17      40
           afternoon     19      50
>>> df2.resample('D', level=0).sum()
            price  volume
2000-01-01     21     110
2000-01-02     22     140
2000-01-03     32     150
2000-01-04     36      90

---->   pandas.DataFrame; pandas.MultiIndex; DataFrame.resample

--------------------------------------
ID: 10472 --> 1
>>> start, end = '2000-10-01 23:30:00', '2000-10-02 00:30:00'
>>> rng = pd.date_range(start, end, freq='7min')
>>> ts = pd.Series(np.arange(len(rng)) * 3, index=rng)
>>> ts
2000-10-01 23:30:00     0
2000-10-01 23:37:00     3
2000-10-01 23:44:00     6
2000-10-01 23:51:00     9
2000-10-01 23:58:00    12
2000-10-02 00:05:00    15
2000-10-02 00:12:00    18
2000-10-02 00:19:00    21
2000-10-02 00:26:00    24
Freq: 7T, dtype: int64

---->   pandas.Series

--------------------------------------
ID: 10473 --> 1
>>> ts.resample('17min').sum()
2000-10-01 23:14:00     0
2000-10-01 23:31:00     9
2000-10-01 23:48:00    21
2000-10-02 00:05:00    54
2000-10-02 00:22:00    24
Freq: 17T, dtype: int64

---->   Series.resample

--------------------------------------
ID: 10474 --> 1
>>> ts.resample('17min', origin='epoch').sum()
2000-10-01 23:18:00     0
2000-10-01 23:35:00    18
2000-10-01 23:52:00    27
2000-10-02 00:09:00    39
2000-10-02 00:26:00    24
Freq: 17T, dtype: int64

---->   Series.resample

--------------------------------------
ID: 10475 --> 1
>>> ts.resample('17min', origin='2000-01-01').sum()
2000-10-01 23:24:00     3
2000-10-01 23:41:00    15
2000-10-01 23:58:00    45
2000-10-02 00:15:00    45
Freq: 17T, dtype: int64

---->   Series.resample

--------------------------------------
ID: 10476 --> 1
>>> ts.resample('17min', origin='start').sum()
2000-10-01 23:30:00     9
2000-10-01 23:47:00    21
2000-10-02 00:04:00    54
2000-10-02 00:21:00    24
Freq: 17T, dtype: int64

---->   Series.resample

--------------------------------------
ID: 10477 --> 1
>>> ts.resample('17min', offset='23h30min').sum()
2000-10-01 23:30:00     9
2000-10-01 23:47:00    21
2000-10-02 00:04:00    54
2000-10-02 00:21:00    24
Freq: 17T, dtype: int64

---->   Series.resample

--------------------------------------
ID: 10478 --> 1
>>> ts.resample('17min', origin='end').sum()
2000-10-01 23:35:00     0
2000-10-01 23:52:00    18
2000-10-02 00:09:00    27
2000-10-02 00:26:00    63
Freq: 17T, dtype: int64

---->   Series.resample

--------------------------------------
ID: 10479 --> 1
>>> ts.resample('17min', origin='end_day').sum()
2000-10-01 23:38:00     3
2000-10-01 23:55:00    15
2000-10-02 00:12:00    45
2000-10-02 00:29:00    45
Freq: 17T, dtype: int64

---->   Series.resample

--------------------------------------
ID: 10481 --> 1
>>> s = pd.Series(data=[1, None, 4, 3, 4],
...               index=['A', 'B', 'C', 'D', 'E'])
>>> s
A    1.0
B    NaN
C    4.0
D    3.0
E    4.0
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 10482 --> 1
>>> s.idxmax()
'C'

---->   Series.idxmax

--------------------------------------
ID: 10483 --> 1
>>> s.idxmax(skipna=False)
nan

---->   Series.idxmax

--------------------------------------
ID: 10484 --> 1
>>> s = pd.Series(pd.date_range("2018-02-27", periods=3))
>>> s
0   2018-02-27
1   2018-02-28
2   2018-03-01
dtype: datetime64[ns]
>>> s.dt.is_month_start
0    False
1    False
2    True
dtype: bool
>>> s.dt.is_month_end
0    False
1    True
2    False
dtype: bool

---->   pandas.Series

--------------------------------------
ID: 10486 --> 1
>>> i = pd.date_range('2018-04-09', periods=4, freq='12H')
>>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)
>>> ts
                     A
2018-04-09 00:00:00  1
2018-04-09 12:00:00  2
2018-04-10 00:00:00  3
2018-04-10 12:00:00  4

---->   pandas.DataFrame

--------------------------------------
ID: 10487 --> 1
>>> ts.at_time('12:00')
                     A
2018-04-09 12:00:00  2
2018-04-10 12:00:00  4

---->   DataFrame.at_time

--------------------------------------
ID: 10488 --> 1
>>> df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],
...      index=['cobra', 'viper', 'sidewinder'],
...      columns=['max_speed', 'shield'])
>>> df
            max_speed  shield
cobra               1       2
viper               4       5
sidewinder          7       8

---->   pandas.DataFrame

--------------------------------------
ID: 10489 --> 1
>>> df.loc[pd.Series([False, True, False],
...        index=['viper', 'sidewinder', 'cobra'])]
            max_speed  shield
sidewinder          7       8

---->   pandas.Series

--------------------------------------
ID: 10490 --> 1
>>> df.loc[pd.Index(["cobra", "viper"], name="foo")]
       max_speed  shield
foo
cobra          1       2
viper          4       5

---->   pandas.Index

--------------------------------------
ID: 10491 --> 1
>>> df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],
...      index=[7, 8, 9], columns=['max_speed', 'shield'])
>>> df
   max_speed  shield
7          1       2
8          4       5
9          7       8

---->   pandas.DataFrame

--------------------------------------
ID: 10492 --> 2
>>> tuples = [
...    ('cobra', 'mark i'), ('cobra', 'mark ii'),
...    ('sidewinder', 'mark i'), ('sidewinder', 'mark ii'),
...    ('viper', 'mark ii'), ('viper', 'mark iii')
... ]
>>> index = pd.MultiIndex.from_tuples(tuples)
>>> values = [[12, 2], [0, 4], [10, 20],
...         [1, 4], [7, 1], [16, 36]]
>>> df = pd.DataFrame(values, columns=['max_speed', 'shield'], index=index)
>>> df
                     max_speed  shield
cobra      mark i           12       2
           mark ii           0       4
sidewinder mark i           10      20
           mark ii           1       4
viper      mark ii           7       1
           mark iii         16      36

---->   pandas.MultiIndex; pandas.DataFrame

--------------------------------------
ID: 10499 --> 1
>>> i = pd.date_range('2018-04-09', periods=4, freq='2D')
>>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)
>>> ts
            A
2018-04-09  1
2018-04-11  2
2018-04-13  3
2018-04-15  4

---->   pandas.DataFrame

--------------------------------------
ID: 10500 --> 1
>>> ts.first('3D')
            A
2018-04-09  1
2018-04-11  2

---->   DataFrame.first

--------------------------------------
ID: 10501 --> 1
>>> s = pd.Series(["koala", "dog", "chameleon"])
>>> s
0        koala
1          dog
2    chameleon
dtype: object

---->   pandas.Series

--------------------------------------
ID: 10507 --> 2
>>> df = pd.DataFrame({
...     'sales': [3, 2, 3, 9, 10, 6],
...     'signups': [5, 5, 6, 12, 14, 13],
...     'visits': [20, 42, 28, 62, 81, 50],
... }, index=pd.date_range(start='2018/01/01', end='2018/07/01',
...                        freq='M'))
>>> ax = df.plot.area()

---->   pandas.DataFrame; DataFrame.plot

--------------------------------------
ID: 10508 --> 1
>>> ax = df.plot.area(stacked=False)

---->   DataFrame.plot

--------------------------------------
ID: 10509 --> 1
>>> ax = df.plot.area(y='sales')

---->   DataFrame.plot

--------------------------------------
ID: 10510 --> 2
>>> df = pd.DataFrame({
...     'sales': [3, 2, 3],
...     'visits': [20, 42, 28],
...     'day': [1, 2, 3],
... })
>>> ax = df.plot.area(x='day')

---->   pandas.DataFrame; DataFrame.plot

--------------------------------------
ID: 10511 --> 2
>>> ser = pd.Series([390., 350., 30., 20.],
...                 index=['Falcon', 'Falcon', 'Parrot', 'Parrot'], name="Max Speed")
>>> ser
Falcon    390.0
Falcon    350.0
Parrot     30.0
Parrot     20.0
Name: Max Speed, dtype: float64
>>> ser.groupby(["a", "b", "a", "b"]).mean()
a    210.0
b    185.0
Name: Max Speed, dtype: float64
>>> ser.groupby(level=0).mean()
Falcon    370.0
Parrot     25.0
Name: Max Speed, dtype: float64
>>> ser.groupby(ser > 100).mean()
Max Speed
False     25.0
True     370.0
Name: Max Speed, dtype: float64

---->   pandas.Series; Series.groupby

--------------------------------------
ID: 10512 --> 3
>>> arrays = [['Falcon', 'Falcon', 'Parrot', 'Parrot'],
...           ['Captive', 'Wild', 'Captive', 'Wild']]
>>> index = pd.MultiIndex.from_arrays(arrays, names=('Animal', 'Type'))
>>> ser = pd.Series([390., 350., 30., 20.], index=index, name="Max Speed")
>>> ser
Animal  Type
Falcon  Captive    390.0
        Wild       350.0
Parrot  Captive     30.0
        Wild        20.0
Name: Max Speed, dtype: float64
>>> ser.groupby(level=0).mean()
Animal
Falcon    370.0
Parrot     25.0
Name: Max Speed, dtype: float64
>>> ser.groupby(level="Type").mean()
Type
Captive    210.0
Wild       185.0
Name: Max Speed, dtype: float64

---->   pandas.MultiIndex; pandas.Series; Series.groupby

--------------------------------------
ID: 10513 --> 2
>>> ser = pd.Series([1, 2, 3, 3], index=["a", 'a', 'b', np.nan])
>>> ser.groupby(level=0).sum()
a    3
b    3
dtype: int64

---->   pandas.Series; Series.groupby

--------------------------------------
ID: 10514 --> 1
>>> ser.groupby(level=0, dropna=False).sum()
a    3
b    3
NaN  3
dtype: int64

---->   Series.groupby

--------------------------------------
ID: 10515 --> 2
>>> arrays = ['Falcon', 'Falcon', 'Parrot', 'Parrot']
>>> ser = pd.Series([390., 350., 30., 20.], index=arrays, name="Max Speed")
>>> ser.groupby(["a", "b", "a", np.nan]).mean()
a    210.0
b    350.0
Name: Max Speed, dtype: float64

---->   pandas.Series; Series.groupby

--------------------------------------
ID: 10516 --> 1
>>> ser.groupby(["a", "b", "a", np.nan], dropna=False).mean()
a    210.0
b    350.0
NaN   20.0
Name: Max Speed, dtype: float64

---->   Series.groupby

--------------------------------------
ID: 10517 --> 1
>>> ser = pd.Series([1,2,3])

---->   pandas.Series

--------------------------------------
ID: 10518 --> 1
>>> ser.pop(0)
1

---->   Series.pop

--------------------------------------
ID: 10519 --> 2
>>> data = np.random.randn(25, 4)
>>> df = pd.DataFrame(data, columns=list('ABCD'))
>>> ax = df.plot.box()

---->   pandas.DataFrame; DataFrame.plot

--------------------------------------
ID: 10520 --> 2
>>> age_list = [8, 10, 12, 14, 72, 74, 76, 78, 20, 25, 30, 35, 60, 85]
>>> df = pd.DataFrame({"gender": list("MMMMMMMMFFFFFF"), "age": age_list})
>>> ax = df.plot.box(column="age", by="gender", figsize=(10, 8))

---->   pandas.DataFrame; DataFrame.plot

--------------------------------------
ID: 10521 --> 1
>>> pd.Series([1, 2, 3]).array

[1, 2, 3]
Length: 3, dtype: int64

---->   pandas.Series

--------------------------------------
ID: 10522 --> 2
>>> ser = pd.Series(pd.Categorical(['a', 'b', 'a']))
>>> ser.array
['a', 'b', 'a']
Categories (2, object): ['a', 'b']

---->   pandas.Series; pandas.Categorical

--------------------------------------
ID: 10523 --> 1
>>> pd.Series([True]).bool()
True
>>> pd.Series([False]).bool()
False

---->   pandas.Series

--------------------------------------
ID: 10524 --> 1
>>> pd.DataFrame({'col': [True]}).bool()
True
>>> pd.DataFrame({'col': [False]}).bool()
False

---->   pandas.DataFrame

--------------------------------------
ID: 10525 --> 1
>>> s = pd.Series([2, np.nan, 5, -1, 0])
>>> s
0    2.0
1    NaN
2    5.0
3   -1.0
4    0.0
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 10526 --> 1
>>> s.cumprod()
0     2.0
1     NaN
2    10.0
3   -10.0
4    -0.0
dtype: float64

---->   Series.cumprod

--------------------------------------
ID: 10527 --> 1
>>> s.cumprod(skipna=False)
0    2.0
1    NaN
2    NaN
3    NaN
4    NaN
dtype: float64

---->   Series.cumprod

--------------------------------------
ID: 10528 --> 1
>>> df = pd.DataFrame([[2.0, 1.0],
...                    [3.0, np.nan],
...                    [1.0, 0.0]],
...                   columns=list('AB'))
>>> df
     A    B
0  2.0  1.0
1  3.0  NaN
2  1.0  0.0

---->   pandas.DataFrame

--------------------------------------
ID: 10529 --> 1
>>> df.cumprod()
     A    B
0  2.0  1.0
1  6.0  NaN
2  6.0  0.0

---->   DataFrame.cumprod

--------------------------------------
ID: 10530 --> 1
>>> df.cumprod(axis=1)
     A    B
0  2.0  2.0
1  3.0  NaN
2  1.0  0.0

---->   DataFrame.cumprod

--------------------------------------
ID: 10531 --> 1
>>> s = pd.Series([1, 2, 3, 4, 5])
>>> s.replace(1, 5)
0    5
1    2
2    3
3    4
4    5
dtype: int64

---->   pandas.Series

--------------------------------------
ID: 10532 --> 1
>>> df = pd.DataFrame({'A': [0, 1, 2, 3, 4],
...                    'B': [5, 6, 7, 8, 9],
...                    'C': ['a', 'b', 'c', 'd', 'e']})
>>> df.replace(0, 5)
    A  B  C
0  5  5  a
1  1  6  b
2  2  7  c
3  3  8  d
4  4  9  e

---->   pandas.DataFrame

--------------------------------------
ID: 10539 --> 1
>>> df = pd.DataFrame({'A': ['bat', 'foo', 'bait'],
...                    'B': ['abc', 'bar', 'xyz']})
>>> df.replace(to_replace=r'^ba.$', value='new', regex=True)
        A    B
0   new  abc
1   foo  new
2  bait  xyz

---->   pandas.DataFrame

--------------------------------------
ID: 10544 --> 1
>>> s = pd.Series([10, 'a', 'a', 'b', 'a'])

---->   pandas.Series

--------------------------------------
ID: 10548 --> 1
>>> s = pd.Series([1, 2, 3, 4])
>>> s
0    1
1    2
2    3
3    4
dtype: int64

---->   pandas.Series

--------------------------------------
ID: 10549 --> 1
>>> s.add_suffix('_item')
0_item    1
1_item    2
2_item    3
3_item    4
dtype: int64

---->   Series.add_suffix

--------------------------------------
ID: 10550 --> 1
>>> df = pd.DataFrame({'A': [1, 2, 3, 4], 'B': [3, 4, 5, 6]})
>>> df
   A  B
0  1  3
1  2  4
2  3  5
3  4  6

---->   pandas.DataFrame

--------------------------------------
ID: 10551 --> 1
>>> df.add_suffix('_col')
     A_col  B_col
0       1       3
1       2       4
2       3       5
3       4       6

---->   DataFrame.add_suffix

--------------------------------------
ID: 10552 --> 2
>>> df = pd.DataFrame(
...     {
...         "a": pd.Series([1, 2, 3], dtype=np.dtype("int32")),
...         "b": pd.Series(["x", "y", "z"], dtype=np.dtype("O")),
...         "c": pd.Series([True, False, np.nan], dtype=np.dtype("O")),
...         "d": pd.Series(["h", "i", np.nan], dtype=np.dtype("O")),
...         "e": pd.Series([10, np.nan, 20], dtype=np.dtype("float")),
...         "f": pd.Series([np.nan, 100.5, 200], dtype=np.dtype("float")),
...     }
... )

---->   pandas.DataFrame; pandas.Series

--------------------------------------
ID: 10553 --> 1
>>> dfn = df.convert_dtypes()
>>> dfn
   a  b      c     d     e      f
0  1  x   True     h    10   
1  2  y  False     i    100.5
2  3  z         20  200.0

---->   DataFrame.convert_dtypes

--------------------------------------
ID: 10554 --> 1
>>> s = pd.Series(["a", "b", np.nan])
>>> s
0      a
1      b
2    NaN
dtype: object

---->   pandas.Series

--------------------------------------
ID: 10555 --> 1
>>> s.convert_dtypes()
0       a
1       b
2    
dtype: string

---->   Series.convert_dtypes

--------------------------------------
ID: 10556 --> 1
>>> s = pd.Series([1, 2, 3, 4])
>>> s
0    1
1    2
2    3
3    4
dtype: int64

---->   pandas.Series

--------------------------------------
ID: 10557 --> 1
>>> s.add_prefix('item_')
item_0    1
item_1    2
item_2    3
item_3    4
dtype: int64

---->   Series.add_prefix

--------------------------------------
ID: 10558 --> 1
>>> df = pd.DataFrame({'A': [1, 2, 3, 4], 'B': [3, 4, 5, 6]})
>>> df
   A  B
0  1  3
1  2  4
2  3  5
3  4  6

---->   pandas.DataFrame

--------------------------------------
ID: 10559 --> 1
>>> df.add_prefix('col_')
     col_A  col_B
0       1       3
1       2       4
2       3       5
3       4       6

---->   DataFrame.add_prefix

--------------------------------------
ID: 10560 --> 1
>>> dates = pd.Series(pd.date_range("2017-12-30", periods=3))
>>> dates
0   2017-12-30
1   2017-12-31
2   2018-01-01
dtype: datetime64[ns]

---->   pandas.Series

--------------------------------------
ID: 10563 --> 1
>>> datetime_series = pd.Series(
...     pd.date_range("2000-01-01", periods=3, freq="ns")
... )
>>> datetime_series
0   2000-01-01 00:00:00.000000000
1   2000-01-01 00:00:00.000000001
2   2000-01-01 00:00:00.000000002
dtype: datetime64[ns]
>>> datetime_series.dt.nanosecond
0       0
1       1
2       2
dtype: int32

---->   pandas.Series

--------------------------------------
ID: 10564 --> 1
>>> s = pd.Series(['lower', 'CAPITALS', 'this is a sentence', 'SwApCaSe'])
>>> s
0                 lower
1              CAPITALS
2    this is a sentence
3              SwApCaSe
dtype: object

---->   pandas.Series

--------------------------------------
ID: 10570 --> 1
>>> s = pd.Series(['bat', 'bear', 'caT', np.nan])
>>> s
0     bat
1    bear
2     caT
3     NaN
dtype: object

---->   pandas.Series

--------------------------------------
ID: 10574 --> 2
>>> s = pd.Series(pd.to_timedelta(np.arange(5), unit="d"))
>>> s
0   0 days
1   1 days
2   2 days
3   3 days
4   4 days
dtype: timedelta64[ns]

---->   pandas.Series; pandas.to_timedelta

--------------------------------------
ID: 10577 --> 1
>>> df = pd.DataFrame({'name' : ['User 1', 'User 2', 'User 3']})
>>> df
     name
0  User 1
1  User 2
2  User 3

---->   pandas.DataFrame

--------------------------------------
ID: 10578 --> 1
>>> df.to_sql('users', con=engine)
3
>>> from sqlalchemy import text
>>> with engine.connect() as conn:
...    conn.execute(text("SELECT * FROM users")).fetchall()
[(0, 'User 1'), (1, 'User 2'), (2, 'User 3')]

---->   DataFrame.to_sql

--------------------------------------
ID: 10579 --> 2
>>> with engine.begin() as connection:
...     df1 = pd.DataFrame({'name' : ['User 4', 'User 5']})
...     df1.to_sql('users', con=connection, if_exists='append')
2

---->   pandas.DataFrame; DataFrame.to_sql

--------------------------------------
ID: 10580 --> 2
>>> df2 = pd.DataFrame({'name' : ['User 6', 'User 7']})
>>> df2.to_sql('users', con=engine, if_exists='append')
2
>>> with engine.connect() as conn:
...    conn.execute(text("SELECT * FROM users")).fetchall()
[(0, 'User 1'), (1, 'User 2'), (2, 'User 3'),
 (0, 'User 4'), (1, 'User 5'), (0, 'User 6'),
 (1, 'User 7')]

---->   pandas.DataFrame; DataFrame.to_sql

--------------------------------------
ID: 10581 --> 1
>>> df2.to_sql('users', con=engine, if_exists='replace',
...            index_label='id')
2
>>> with engine.connect() as conn:
...    conn.execute(text("SELECT * FROM users")).fetchall()
[(0, 'User 6'), (1, 'User 7')]

---->   DataFrame.to_sql

--------------------------------------
ID: 10582 --> 1
>>> df = pd.DataFrame({"A": [1, None, 2]})
>>> df
     A
0  1.0
1  NaN
2  2.0

---->   pandas.DataFrame

--------------------------------------
ID: 10583 --> 1
>>> from sqlalchemy.types import Integer
>>> df.to_sql('integers', con=engine, index=False,
...           dtype={"A": Integer()})
3

---->   DataFrame.to_sql

--------------------------------------
ID: 10585 --> 2
>>> ser = pd.to_datetime(pd.Series(["2010-01-01", pd.NaT]))
>>> ser.dt.isocalendar()
   year  week  day
0  2009    53     5
1      
>>> ser.dt.isocalendar().week
0      53
1    
Name: week, dtype: UInt32

---->   pandas.to_datetime; pandas.Series

--------------------------------------
ID: 10586 --> 2
>>> s1 = pd.Series([1, np.nan])
>>> s2 = pd.Series([3, 4, 5])
>>> s1.combine_first(s2)
0    1.0
1    4.0
2    5.0
dtype: float64

---->   pandas.Series; Series.combine_first

--------------------------------------
ID: 10587 --> 2
>>> s1 = pd.Series({'falcon': np.nan, 'eagle': 160.0})
>>> s2 = pd.Series({'eagle': 200.0, 'duck': 30.0})
>>> s1.combine_first(s2)
duck       30.0
eagle     160.0
falcon      NaN
dtype: float64

---->   pandas.Series; Series.combine_first

--------------------------------------
ID: 10588 --> 2
>>> df = pd.DataFrame({'lab':['A', 'B', 'C'], 'val':[10, 30, 20]})
>>> ax = df.plot.bar(x='lab', y='val', rot=0)

---->   pandas.DataFrame; DataFrame.plot

--------------------------------------
ID: 10589 --> 2
>>> speed = [0.1, 17.5, 40, 48, 52, 69, 88]
>>> lifespan = [2, 8, 70, 1.5, 25, 12, 28]
>>> index = ['snail', 'pig', 'elephant',
...          'rabbit', 'giraffe', 'coyote', 'horse']
>>> df = pd.DataFrame({'speed': speed,
...                    'lifespan': lifespan}, index=index)
>>> ax = df.plot.bar(rot=0)

---->   pandas.DataFrame; DataFrame.plot

--------------------------------------
ID: 10590 --> 1
>>> ax = df.plot.bar(stacked=True)

---->   DataFrame.plot

--------------------------------------
ID: 10591 --> 1
>>> axes = df.plot.bar(rot=0, subplots=True)
>>> axes[1].legend(loc=2)  

---->   DataFrame.plot

--------------------------------------
ID: 10592 --> 1
>>> axes = df.plot.bar(
...     rot=0, subplots=True, color={"speed": "red", "lifespan": "green"}
... )
>>> axes[1].legend(loc=2)  

---->   DataFrame.plot

--------------------------------------
ID: 10593 --> 1
>>> ax = df.plot.bar(y='speed', rot=0)

---->   DataFrame.plot

--------------------------------------
ID: 10594 --> 1
>>> ax = df.plot.bar(x='lifespan', rot=0)

---->   DataFrame.plot

--------------------------------------
ID: 10595 --> 1
>>> df1 = pd.DataFrame([[24.3, 75.7, 'high'],
...                     [31, 87.8, 'high'],
...                     [22, 71.6, 'medium'],
...                     [35, 95, 'medium']],
...                    columns=['temp_celsius', 'temp_fahrenheit',
...                             'windspeed'],
...                    index=pd.date_range(start='2014-02-12',
...                                        end='2014-02-15', freq='D'))

---->   pandas.DataFrame

--------------------------------------
ID: 10596 --> 2
>>> df2 = pd.DataFrame([[28, 'low'],
...                     [30, 'low'],
...                     [35.1, 'medium']],
...                    columns=['temp_celsius', 'windspeed'],
...                    index=pd.DatetimeIndex(['2014-02-12', '2014-02-13',
...                                            '2014-02-15']))

---->   pandas.DataFrame; pandas.DatetimeIndex

--------------------------------------
ID: 10597 --> 1
>>> df2.reindex_like(df1)
            temp_celsius  temp_fahrenheit windspeed
2014-02-12          28.0              NaN       low
2014-02-13          30.0              NaN       low
2014-02-14           NaN              NaN       NaN
2014-02-15          35.1              NaN    medium

---->   DataFrame.reindex_like

--------------------------------------
ID: 10598 --> 1
>>> datetime_series = pd.Series(
...     pd.date_range("2000-01-01", periods=3, freq="h")
... )
>>> datetime_series
0   2000-01-01 00:00:00
1   2000-01-01 01:00:00
2   2000-01-01 02:00:00
dtype: datetime64[ns]
>>> datetime_series.dt.hour
0    0
1    1
2    2
dtype: int32

---->   pandas.Series

--------------------------------------
ID: 10599 --> 1
>>> df = pd.DataFrame(
...     [[1, 2, 3, 4], [6, 7, 8, 9]], columns=["D", "B", "E", "A"], index=[1, 2]
... )
>>> other = pd.DataFrame(
...     [[10, 20, 30, 40], [60, 70, 80, 90], [600, 700, 800, 900]],
...     columns=["A", "B", "C", "D"],
...     index=[2, 3, 4],
... )
>>> df
   D  B  E  A
1  1  2  3  4
2  6  7  8  9
>>> other
    A    B    C    D
2   10   20   30   40
3   60   70   80   90
4  600  700  800  900

---->   pandas.DataFrame

--------------------------------------
ID: 10600 --> 1
>>> left, right = df.align(other, join="outer", axis=1)
>>> left
   A  B   C  D  E
1  4  2 NaN  1  3
2  9  7 NaN  6  8
>>> right
    A    B    C    D   E
2   10   20   30   40 NaN
3   60   70   80   90 NaN
4  600  700  800  900 NaN

---->   DataFrame.align

--------------------------------------
ID: 10601 --> 1
>>> left, right = df.align(other, join="outer", axis=0)
>>> left
    D    B    E    A
1  1.0  2.0  3.0  4.0
2  6.0  7.0  8.0  9.0
3  NaN  NaN  NaN  NaN
4  NaN  NaN  NaN  NaN
>>> right
    A      B      C      D
1    NaN    NaN    NaN    NaN
2   10.0   20.0   30.0   40.0
3   60.0   70.0   80.0   90.0
4  600.0  700.0  800.0  900.0

---->   DataFrame.align

--------------------------------------
ID: 10602 --> 1
>>> left, right = df.align(other, join="outer", axis=None)
>>> left
     A    B   C    D    E
1  4.0  2.0 NaN  1.0  3.0
2  9.0  7.0 NaN  6.0  8.0
3  NaN  NaN NaN  NaN  NaN
4  NaN  NaN NaN  NaN  NaN
>>> right
       A      B      C      D   E
1    NaN    NaN    NaN    NaN NaN
2   10.0   20.0   30.0   40.0 NaN
3   60.0   70.0   80.0   90.0 NaN
4  600.0  700.0  800.0  900.0 NaN

---->   DataFrame.align

--------------------------------------
ID: 10603 --> 1
>>> s = pd.Series(['1. Ant.  ', '2. Bee!\n', '3. Cat?\t', np.nan, 10, True])
>>> s
0    1. Ant.
1    2. Bee!\n
2    3. Cat?\t
3          NaN
4           10
5         True
dtype: object

---->   pandas.Series

--------------------------------------
ID: 10608 --> 1
>>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]})
>>> df
     B
0  0.0
1  1.0
2  2.0
3  NaN
4  4.0

---->   pandas.DataFrame

--------------------------------------
ID: 10609 --> 1
>>> df.rolling(2).sum()
     B
0  NaN
1  1.0
2  3.0
3  NaN
4  NaN

---->   DataFrame.rolling

--------------------------------------
ID: 10610 --> 1
>>> df_time = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]},
...                        index = [pd.Timestamp('20130101 09:00:00'),
...                                 pd.Timestamp('20130101 09:00:02'),
...                                 pd.Timestamp('20130101 09:00:03'),
...                                 pd.Timestamp('20130101 09:00:05'),
...                                 pd.Timestamp('20130101 09:00:06')])

---->   pandas.DataFrame

--------------------------------------
ID: 10612 --> 1
>>> indexer = pd.api.indexers.FixedForwardWindowIndexer(window_size=2)
>>> df.rolling(window=indexer, min_periods=1).sum()
     B
0  1.0
1  3.0
2  2.0
3  4.0
4  4.0

---->   DataFrame.rolling

--------------------------------------
ID: 10613 --> 1
>>> df.rolling(2, min_periods=1).sum()
     B
0  0.0
1  1.0
2  3.0
3  2.0
4  4.0

---->   DataFrame.rolling

--------------------------------------
ID: 10614 --> 1
>>> df.rolling(3, min_periods=1, center=True).sum()
     B
0  1.0
1  3.0
2  3.0
3  6.0
4  4.0

---->   DataFrame.rolling

--------------------------------------
ID: 10615 --> 1
>>> df.rolling(3, min_periods=1, center=False).sum()
     B
0  0.0
1  1.0
2  3.0
3  3.0
4  6.0

---->   DataFrame.rolling

--------------------------------------
ID: 10616 --> 1
>>> df.rolling(2, min_periods=1, step=2).sum()
     B
0  0.0
2  3.0
4  4.0

---->   DataFrame.rolling

--------------------------------------
ID: 10617 --> 1
>>> df.rolling(2, win_type='gaussian').sum(std=3)
          B
0       NaN
1  0.986207
2  2.958621
3       NaN
4       NaN

---->   DataFrame.rolling

--------------------------------------
ID: 10618 --> 2
>>> df = pd.DataFrame({
...     'A': [pd.to_datetime('2020-01-01'),
...           pd.to_datetime('2020-01-01'),
...           pd.to_datetime('2020-01-02'),],
...     'B': [1, 2, 3], },
...     index=pd.date_range('2020', periods=3))

---->   pandas.DataFrame; pandas.to_datetime

--------------------------------------
ID: 10619 --> 1
>>> df.rolling('2D', on='A').sum()
                    A    B
2020-01-01 2020-01-01  1.0
2020-01-02 2020-01-01  3.0
2020-01-03 2020-01-02  6.0

---->   DataFrame.rolling

--------------------------------------
ID: 10620 --> 1
>>> s = pd.Series(['-1', '1', '1000', 10, np.nan])
>>> s
0      -1
1       1
2    1000
3      10
4     NaN
dtype: object

---->   pandas.Series

--------------------------------------
ID: 10624 --> 1
>>> s = pd.Series(['dog',
...                 '',
...                 5,
...                 {'foo' : 'bar'},
...                 [2, 3, 5, 7],
...                 ('one', 'two', 'three')])
>>> s
0                  dog
1
2                    5
3       {'foo': 'bar'}
4         [2, 3, 5, 7]
5    (one, two, three)
dtype: object
>>> s.str.len()
0    3.0
1    0.0
2    NaN
3    1.0
4    4.0
5    3.0
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 10625 --> 1
>>> s = pd.Series([['lion', 'elephant', 'zebra'],
...                [1.1, 2.2, 3.3],
...                ['cat', np.nan, 'dog'],
...                ['cow', 4.5, 'goat'],
...                ['duck', ['swan', 'fish'], 'guppy']])
>>> s
0        [lion, elephant, zebra]
1                [1.1, 2.2, 3.3]
2                [cat, nan, dog]
3               [cow, 4.5, goat]
4    [duck, [swan, fish], guppy]
dtype: object

---->   pandas.Series

--------------------------------------
ID: 10627 --> 2
>>> a = pd.Series([1, 1, 1, np.nan, 1], index=['a', 'b', 'c', 'd', 'e'])
>>> a
a    1.0
b    1.0
c    1.0
d    NaN
e    1.0
dtype: float64
>>> b = pd.Series([0, 1, 2, np.nan, 1], index=['a', 'b', 'c', 'd', 'f'])
>>> b
a    0.0
b    1.0
c    2.0
d    NaN
f    1.0
dtype: float64
>>> a.gt(b, fill_value=0)
a     True
b    False
c    False
d    False
e     True
f    False
dtype: bool

---->   pandas.Series; Series.gt

--------------------------------------
ID: 10628 --> 1
>>> s = pd.Series([-2, -1, 0, 1, 2], dtype='int8')
>>> s
0   -2
1   -1
2    0
3    1
4    2
dtype: int8

---->   pandas.Series

--------------------------------------
ID: 10629 --> 1
>>> us = s.view('uint8')
>>> us
0    254
1    255
2      0
3      1
4      2
dtype: uint8

---->   Series.view

--------------------------------------
ID: 10631 --> 1
>>> s = pd.Series(['bat', 'Bear', 'cat', np.nan])
>>> s
0     bat
1    Bear
2     cat
3     NaN
dtype: object

---->   pandas.Series

--------------------------------------
ID: 10635 --> 1
>>> pd.Series([2, 1, 3, 3], name='A').unique()
array([2, 1, 3])

---->   pandas.Series

--------------------------------------
ID: 10636 --> 1
>>> pd.Series([pd.Timestamp('2016-01-01') for _ in range(3)]).unique()

['2016-01-01 00:00:00']
Length: 1, dtype: datetime64[ns]

---->   pandas.Series

--------------------------------------
ID: 10637 --> 1
>>> pd.Series([pd.Timestamp('2016-01-01', tz='US/Eastern')
...            for _ in range(3)]).unique()

['2016-01-01 00:00:00-05:00']
Length: 1, dtype: datetime64[ns, US/Eastern]

---->   pandas.Series

--------------------------------------
ID: 10638 --> 2
>>> pd.Series(pd.Categorical(list('baabc'))).unique()
['b', 'a', 'c']
Categories (3, object): ['a', 'b', 'c']
>>> pd.Series(pd.Categorical(list('baabc'), categories=list('abc'),
...                          ordered=True)).unique()
['b', 'a', 'c']
Categories (3, object): ['a' < 'b' < 'c']

---->   pandas.Series; pandas.Categorical

--------------------------------------
ID: 10639 --> 1
>>> s = pd.Series(['Linda van der Berg', 'George Pitt-Rivers'])
>>> s
0    Linda van der Berg
1    George Pitt-Rivers
dtype: object

---->   pandas.Series

--------------------------------------
ID: 10644 --> 1
>>> idx = pd.Index(['X 123', 'Y 999'])
>>> idx
Index(['X 123', 'Y 999'], dtype='object')

---->   pandas.Index

--------------------------------------
ID: 10647 --> 1
>>> s = pd.Series(['1. Ant.  ', '2. Bee!\n', '3. Cat?\t', np.nan, 10, True])
>>> s
0    1. Ant.
1    2. Bee!\n
2    3. Cat?\t
3          NaN
4           10
5         True
dtype: object

---->   pandas.Series

--------------------------------------
ID: 10652 --> 2
>>> s = pd.Series([0.1, 1.3, 2.7])
>>> s.round()
0    0.0
1    1.0
2    3.0
dtype: float64

---->   pandas.Series; Series.round

--------------------------------------
ID: 10653 --> 1
>>> d = {'a': 1, 'b': 2, 'c': 3}
>>> ser = pd.Series(data=d, index=['a', 'b', 'c'])
>>> ser
a   1
b   2
c   3
dtype: int64

---->   pandas.Series

--------------------------------------
ID: 10654 --> 1
>>> d = {'a': 1, 'b': 2, 'c': 3}
>>> ser = pd.Series(data=d, index=['x', 'y', 'z'])
>>> ser
x   NaN
y   NaN
z   NaN
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 10655 --> 1
>>> r = [1, 2]
>>> ser = pd.Series(r, copy=False)
>>> ser.iloc[0] = 999
>>> r
[1, 2]
>>> ser
0    999
1      2
dtype: int64

---->   pandas.Series

--------------------------------------
ID: 10656 --> 1
>>> r = np.array([1, 2])
>>> ser = pd.Series(r, copy=False)
>>> ser.iloc[0] = 999
>>> r
array([999,   2])
>>> ser
0    999
1      2
dtype: int64

---->   pandas.Series

--------------------------------------
ID: 10657 --> 2
>>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])
>>> a
a    1.0
b    1.0
c    1.0
d    NaN
dtype: float64
>>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])
>>> b
a    1.0
b    NaN
d    1.0
e    NaN
dtype: float64
>>> a.floordiv(b, fill_value=0)
a    1.0
b    inf
c    inf
d    0.0
e    NaN
dtype: float64

---->   pandas.Series; Series.floordiv

--------------------------------------
ID: 10658 --> 2
>>> s = pd.Series(['lama', 'cow', 'lama', 'beetle', 'lama',
...                'hippo'], name='animal')
>>> s.isin(['cow', 'lama'])
0     True
1     True
2     True
3    False
4     True
5    False
Name: animal, dtype: bool

---->   pandas.Series; Series.isin

--------------------------------------
ID: 10659 --> 1
>>> ~s.isin(['cow', 'lama'])
0    False
1    False
2    False
3     True
4    False
5     True
Name: animal, dtype: bool

---->   Series.isin

--------------------------------------
ID: 10660 --> 1
>>> s.isin(['lama'])
0     True
1    False
2     True
3    False
4     True
5    False
Name: animal, dtype: bool

---->   Series.isin

--------------------------------------
ID: 10661 --> 1
>>> pd.Series([1]).isin(['1'])
0    False
dtype: bool
>>> pd.Series([1.1]).isin(['1.1'])
0    False
dtype: bool

---->   pandas.Series

--------------------------------------
ID: 10662 --> 2
>>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])
>>> a
a    1.0
b    1.0
c    1.0
d    NaN
dtype: float64
>>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])
>>> b
a    1.0
b    NaN
d    1.0
e    NaN
dtype: float64
>>> a.pow(b, fill_value=0)
a    1.0
b    1.0
c    1.0
d    0.0
e    NaN
dtype: float64

---->   pandas.Series; Series.pow

--------------------------------------
ID: 10663 --> 1
>>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])
>>> a
a    1.0
b    1.0
c    1.0
d    NaN
dtype: float64
>>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])
>>> b
a    1.0
b    NaN
d    1.0
e    NaN
dtype: float64
>>> a.divide(b, fill_value=0)
a    1.0
b    inf
c    inf
d    0.0
e    NaN
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 10664 --> 1
>>> c = pd.Categorical(['a', 'c', 'b', 'c', 'd'])
>>> c
['a', 'c', 'b', 'c', 'd']
Categories (4, object): ['a', 'b', 'c', 'd']

---->   pandas.Categorical

--------------------------------------
ID: 10667 --> 1
>>> s = pd.Series(range(5))
>>> s.where(s > 0)
0    NaN
1    1.0
2    2.0
3    3.0
4    4.0
dtype: float64
>>> s.mask(s > 0)
0    0.0
1    NaN
2    NaN
3    NaN
4    NaN
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 10668 --> 1
>>> s = pd.Series(range(5))
>>> t = pd.Series([True, False])
>>> s.where(t, 99)
0     0
1    99
2    99
3    99
4    99
dtype: int64
>>> s.mask(t, 99)
0    99
1     1
2    99
3    99
4    99
dtype: int64

---->   pandas.Series

--------------------------------------
ID: 10670 --> 1
>>> df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=['A', 'B'])
>>> df
   A  B
0  0  1
1  2  3
2  4  5
3  6  7
4  8  9
>>> m = df % 3 == 0
>>> df.where(m, -df)
   A  B
0  0 -1
1 -2  3
2 -4 -5
3  6 -7
4 -8  9
>>> df.where(m, -df) == np.where(m, df, -df)
      A     B
0  True  True
1  True  True
2  True  True
3  True  True
4  True  True
>>> df.where(m, -df) == df.mask(~m, -df)
      A     B
0  True  True
1  True  True
2  True  True
3  True  True
4  True  True

---->   pandas.DataFrame

--------------------------------------
ID: 10672 --> 2
>>> def histogram_intersection(a, b):
...     v = np.minimum(a, b).sum().round(decimals=1)
...     return v
>>> s1 = pd.Series([.2, .0, .6, .2])
>>> s2 = pd.Series([.3, .6, .0, .1])
>>> s1.corr(s2, method=histogram_intersection)
0.3

---->   pandas.Series; Series.corr

--------------------------------------
ID: 10673 --> 3
>>> idx = pd.DatetimeIndex(['2023', '2024', '2025'])
>>> s = pd.Series([1, 2, 3], index=idx)
>>> s = s.to_period()
>>> s
2023    1
2024    2
2025    3
Freq: A-DEC, dtype: int64

---->   pandas.DatetimeIndex; pandas.Series; Series.to_period

--------------------------------------
ID: 10675 --> 2
>>> s = pd.Series([1, 2, 3, 4])
>>> s.quantile(.5)
2.5
>>> s.quantile([.25, .5, .75])
0.25    1.75
0.50    2.50
0.75    3.25
dtype: float64

---->   pandas.Series; Series.quantile

--------------------------------------
ID: 10676 --> 1
>>> pd.Series([], dtype="float64").prod()
1.0

---->   pandas.Series

--------------------------------------
ID: 10677 --> 1
>>> pd.Series([], dtype="float64").prod(min_count=1)
nan

---->   pandas.Series

--------------------------------------
ID: 10678 --> 1
>>> pd.Series([np.nan]).prod()
1.0

---->   pandas.Series

--------------------------------------
ID: 10679 --> 1
>>> pd.Series([np.nan]).prod(min_count=1)
nan

---->   pandas.Series

--------------------------------------
ID: 10680 --> 1
>>> s = pd.Series([1, 2, np.nan, 4], index=[10, 20, 30, 40])
>>> s
10    1.0
20    2.0
30    NaN
40    4.0
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 10681 --> 1
>>> s.asof(20)
2.0

---->   Series.asof

--------------------------------------
ID: 10682 --> 1
>>> s.asof([5, 20])
5     NaN
20    2.0
dtype: float64

---->   Series.asof

--------------------------------------
ID: 10683 --> 1
>>> s.asof(30)
2.0

---->   Series.asof

--------------------------------------
ID: 10684 --> 3
>>> df = pd.DataFrame({'a': [10, 20, 30, 40, 50],
...                    'b': [None, None, None, None, 500]},
...                   index=pd.DatetimeIndex(['2018-02-27 09:01:00',
...                                           '2018-02-27 09:02:00',
...                                           '2018-02-27 09:03:00',
...                                           '2018-02-27 09:04:00',
...                                           '2018-02-27 09:05:00']))
>>> df.asof(pd.DatetimeIndex(['2018-02-27 09:03:30',
...                           '2018-02-27 09:04:30']))
                      a   b
2018-02-27 09:03:30 NaN NaN
2018-02-27 09:04:30 NaN NaN

---->   pandas.DataFrame; pandas.DatetimeIndex; DataFrame.asof

--------------------------------------
ID: 10685 --> 2
>>> df.asof(pd.DatetimeIndex(['2018-02-27 09:03:30',
...                           '2018-02-27 09:04:30']),
...         subset=['a'])
                      a   b
2018-02-27 09:03:30  30 NaN
2018-02-27 09:04:30  40 NaN

---->   DataFrame.asof; pandas.DatetimeIndex

--------------------------------------
ID: 10686 --> 2
>>> df = pd.DataFrame({'A': range(3), 'B': range(1, 4)})
>>> df
   A  B
0  0  1
1  1  2
2  2  3
>>> df.transform(lambda x: x + 1)
   A  B
0  1  2
1  2  3
2  3  4

---->   pandas.DataFrame; DataFrame.transform

--------------------------------------
ID: 10687 --> 2
>>> s = pd.Series(range(3))
>>> s
0    0
1    1
2    2
dtype: int64
>>> s.transform([np.sqrt, np.exp])
       sqrt        exp
0  0.000000   1.000000
1  1.000000   2.718282
2  1.414214   7.389056

---->   pandas.Series; Series.transform

--------------------------------------
ID: 10688 --> 2
>>> df = pd.DataFrame({
...     "Date": [
...         "2015-05-08", "2015-05-07", "2015-05-06", "2015-05-05",
...         "2015-05-08", "2015-05-07", "2015-05-06", "2015-05-05"],
...     "Data": [5, 8, 6, 1, 50, 100, 60, 120],
... })
>>> df
         Date  Data
0  2015-05-08     5
1  2015-05-07     8
2  2015-05-06     6
3  2015-05-05     1
4  2015-05-08    50
5  2015-05-07   100
6  2015-05-06    60
7  2015-05-05   120
>>> df.groupby('Date')['Data'].transform('sum')
0     55
1    108
2     66
3    121
4     55
5    108
6     66
7    121
Name: Data, dtype: int64

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 10689 --> 2
>>> df = pd.DataFrame({
...     "c": [1, 1, 1, 2, 2, 2, 2],
...     "type": ["m", "n", "o", "m", "m", "n", "n"]
... })
>>> df
   c type
0  1    m
1  1    n
2  1    o
3  2    m
4  2    m
5  2    n
6  2    n
>>> df['size'] = df.groupby('c')['type'].transform(len)
>>> df
   c type size
0  1    m    3
1  1    n    3
2  1    o    3
3  2    m    4
4  2    m    4
5  2    n    4
6  2    n    4

---->   pandas.DataFrame; DataFrame.groupby

--------------------------------------
ID: 10690 --> 1
>>> s = pd.Series(['lower', 'CAPITALS', 'this is a sentence', 'SwApCaSe'])
>>> s
0                 lower
1              CAPITALS
2    this is a sentence
3              SwApCaSe
dtype: object

---->   pandas.Series

--------------------------------------
ID: 10696 --> 1
>>> pd.Series(['foo', 'fuz', np.nan]).str.replace('f.', 'ba', regex=True)
0    bao
1    baz
2    NaN
dtype: object

---->   pandas.Series

--------------------------------------
ID: 10697 --> 1
>>> pd.Series(['f.o', 'fuz', np.nan]).str.replace('f.', 'ba', regex=False)
0    bao
1    fuz
2    NaN
dtype: object

---->   pandas.Series

--------------------------------------
ID: 10698 --> 1
>>> pd.Series(['foo', 'fuz', np.nan]).str.replace('f', repr, regex=True)
0    oo
1    uz
2                                            NaN
dtype: object

---->   pandas.Series

--------------------------------------
ID: 10699 --> 1
>>> repl = lambda m: m.group(0)[::-1]
>>> ser = pd.Series(['foo 123', 'bar baz', np.nan])
>>> ser.str.replace(r'[a-z]+', repl, regex=True)
0    oof 123
1    rab zab
2        NaN
dtype: object

---->   pandas.Series

--------------------------------------
ID: 10700 --> 1
>>> pat = r"(?P\w+) (?P\w+) (?P\w+)"
>>> repl = lambda m: m.group('two').swapcase()
>>> ser = pd.Series(['One Two Three', 'Foo Bar Baz'])
>>> ser.str.replace(pat, repl, regex=True)
0    tWO
1    bAR
dtype: object

---->   pandas.Series

--------------------------------------
ID: 10701 --> 1
>>> import re
>>> regex_pat = re.compile(r'FUZ', flags=re.IGNORECASE)
>>> pd.Series(['foo', 'fuz', np.nan]).str.replace(regex_pat, 'bar', regex=True)
0    foo
1    bar
2    NaN
dtype: object

---->   pandas.Series

--------------------------------------
ID: 10702 --> 1
>>> df = pd.DataFrame([
...     [1, 2, 3, 4],
...     [5, 6, 7, 8],
...     [9, 10, 11, 12]
... ]).set_index([0, 1]).rename_axis(['a', 'b'])

---->   pandas.DataFrame

--------------------------------------
ID: 10703 --> 1
>>> df.columns = pd.MultiIndex.from_tuples([
...     ('c', 'e'), ('d', 'f')
... ], names=['level_1', 'level_2'])

---->   pandas.MultiIndex

--------------------------------------
ID: 10704 --> 1
>>> df.droplevel('a')
level_1   c   d
level_2   e   f
b
2        3   4
6        7   8
10      11  12

---->   DataFrame.droplevel

--------------------------------------
ID: 10705 --> 1
>>> df.droplevel('level_2', axis=1)
level_1   c   d
a b
1 2      3   4
5 6      7   8
9 10    11  12

---->   DataFrame.droplevel

--------------------------------------
ID: 10706 --> 1
>>> s = pd.Series(range(5))
>>> s.where(s > 0)
0    NaN
1    1.0
2    2.0
3    3.0
4    4.0
dtype: float64
>>> s.mask(s > 0)
0    0.0
1    NaN
2    NaN
3    NaN
4    NaN
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 10707 --> 1
>>> s = pd.Series(range(5))
>>> t = pd.Series([True, False])
>>> s.where(t, 99)
0     0
1    99
2    99
3    99
4    99
dtype: int64
>>> s.mask(t, 99)
0    99
1     1
2    99
3    99
4    99
dtype: int64

---->   pandas.Series

--------------------------------------
ID: 10709 --> 1
>>> df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=['A', 'B'])
>>> df
   A  B
0  0  1
1  2  3
2  4  5
3  6  7
4  8  9
>>> m = df % 3 == 0
>>> df.where(m, -df)
   A  B
0  0 -1
1 -2  3
2 -4 -5
3  6 -7
4 -8  9
>>> df.where(m, -df) == np.where(m, df, -df)
      A     B
0  True  True
1  True  True
2  True  True
3  True  True
4  True  True
>>> df.where(m, -df) == df.mask(~m, -df)
      A     B
0  True  True
1  True  True
2  True  True
3  True  True
4  True  True

---->   pandas.DataFrame

--------------------------------------
ID: 10710 --> 1
>>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])
>>> a
a    1.0
b    1.0
c    1.0
d    NaN
dtype: float64
>>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])
>>> b
a    1.0
b    NaN
d    1.0
e    NaN
dtype: float64
>>> a.divide(b, fill_value=0)
a    1.0
b    inf
c    inf
d    0.0
e    NaN
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 10711 --> 2
>>> s = pd.Series(["elk", "pig", "dog", "quetzal"], name="animal")
>>> print(s.to_markdown())
|    | animal   |
|---:|:---------|
|  0 | elk      |
|  1 | pig      |
|  2 | dog      |
|  3 | quetzal  |

---->   pandas.Series; Series.to_markdown

--------------------------------------
ID: 10712 --> 1
>>> print(s.to_markdown(tablefmt="grid"))
+----+----------+
|    | animal   |
+====+==========+
|  0 | elk      |
+----+----------+
|  1 | pig      |
+----+----------+
|  2 | dog      |
+----+----------+
|  3 | quetzal  |
+----+----------+

---->   Series.to_markdown

--------------------------------------
ID: 10713 --> 1
>>> s = pd.Series([[1, 2, 3], 'foo', [], [3, 4]])
>>> s
0    [1, 2, 3]
1          foo
2           []
3       [3, 4]
dtype: object

---->   pandas.Series

--------------------------------------
ID: 10714 --> 1
>>> s.explode()
0      1
0      2
0      3
1    foo
2    NaN
3      3
3      4
dtype: object

---->   Series.explode

--------------------------------------
ID: 10715 --> 1
>>> datetime_series = pd.Series(
...     pd.date_range("2000-01-01", periods=3, freq="T")
... )
>>> datetime_series
0   2000-01-01 00:00:00
1   2000-01-01 00:01:00
2   2000-01-01 00:02:00
dtype: datetime64[ns]
>>> datetime_series.dt.minute
0    0
1    1
2    2
dtype: int32

---->   pandas.Series

--------------------------------------
ID: 10716 --> 2
>>> s = pd.Series([-1.10, 2, -3.33, 4])
>>> s.abs()
0    1.10
1    2.00
2    3.33
3    4.00
dtype: float64

---->   pandas.Series; Series.abs

--------------------------------------
ID: 10717 --> 2
>>> s = pd.Series([1.2 + 1j])
>>> s.abs()
0    1.56205
dtype: float64

---->   pandas.Series; Series.abs

--------------------------------------
ID: 10718 --> 2
>>> s = pd.Series([pd.Timedelta('1 days')])
>>> s.abs()
0   1 days
dtype: timedelta64[ns]

---->   pandas.Series; Series.abs

--------------------------------------
ID: 10719 --> 1
>>> df = pd.DataFrame({
...     'a': [4, 5, 6, 7],
...     'b': [10, 20, 30, 40],
...     'c': [100, 50, -30, -50]
... })
>>> df
     a    b    c
0    4   10  100
1    5   20   50
2    6   30  -30
3    7   40  -50
>>> df.loc[(df.c - 43).abs().argsort()]
     a    b    c
1    5   20   50
0    4   10  100
2    6   30  -30
3    7   40  -50

---->   pandas.DataFrame

--------------------------------------
ID: 10720 --> 1
>>> datetime_series = pd.Series(
...     pd.date_range("2000-01-01", periods=3, freq="s")
... )
>>> datetime_series
0   2000-01-01 00:00:00
1   2000-01-01 00:00:01
2   2000-01-01 00:00:02
dtype: datetime64[ns]
>>> datetime_series.dt.second
0    0
1    1
2    2
dtype: int32

---->   pandas.Series

--------------------------------------
ID: 10721 --> 1
>>> codes, uniques = pd.factorize(['b', 'b', 'a', 'c', 'b'])
>>> codes
array([0, 0, 1, 2, 0])
>>> uniques
array(['b', 'a', 'c'], dtype=object)

---->   pandas.factorize

--------------------------------------
ID: 10722 --> 1
>>> codes, uniques = pd.factorize(['b', 'b', 'a', 'c', 'b'], sort=True)
>>> codes
array([1, 1, 0, 2, 1])
>>> uniques
array(['a', 'b', 'c'], dtype=object)

---->   pandas.factorize

--------------------------------------
ID: 10723 --> 1
>>> codes, uniques = pd.factorize(['b', None, 'a', 'c', 'b'])
>>> codes
array([ 0, -1,  1,  2,  0])
>>> uniques
array(['b', 'a', 'c'], dtype=object)

---->   pandas.factorize

--------------------------------------
ID: 10724 --> 2
>>> cat = pd.Categorical(['a', 'a', 'c'], categories=['a', 'b', 'c'])
>>> codes, uniques = pd.factorize(cat)
>>> codes
array([0, 0, 1])
>>> uniques
['a', 'c']
Categories (3, object): ['a', 'b', 'c']

---->   pandas.Categorical; pandas.factorize

--------------------------------------
ID: 10725 --> 2
>>> cat = pd.Series(['a', 'a', 'c'])
>>> codes, uniques = pd.factorize(cat)
>>> codes
array([0, 0, 1])
>>> uniques
Index(['a', 'c'], dtype='object')

---->   pandas.Series; pandas.factorize

--------------------------------------
ID: 10726 --> 1
>>> values = np.array([1, 2, 1, np.nan])
>>> codes, uniques = pd.factorize(values)  # default: use_na_sentinel=True
>>> codes
array([ 0,  1,  0, -1])
>>> uniques
array([1., 2.])

---->   pandas.factorize

--------------------------------------
ID: 10727 --> 1
>>> codes, uniques = pd.factorize(values, use_na_sentinel=False)
>>> codes
array([0, 1, 0, 2])
>>> uniques
array([ 1.,  2., nan])

---->   pandas.factorize

--------------------------------------
ID: 10728 --> 2
>>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])
>>> a
a    1.0
b    1.0
c    1.0
d    NaN
dtype: float64
>>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])
>>> b
a    1.0
b    NaN
d    1.0
e    NaN
dtype: float64
>>> a.mod(b, fill_value=0)
a    0.0
b    NaN
c    NaN
d    0.0
e    NaN
dtype: float64

---->   pandas.Series; Series.mod

--------------------------------------
ID: 10729 --> 1
>>> s1 = pd.Series(['one', 'one1', '1', ''])

---->   pandas.Series

--------------------------------------
ID: 10733 --> 1
>>> s2 = pd.Series(['A B', '1.5', '3,000'])
>>> s2.str.isalnum()
0    False
1    False
2    False
dtype: bool

---->   pandas.Series

--------------------------------------
ID: 10734 --> 1
>>> s3 = pd.Series(['23', '³', '⅕', ''])

---->   pandas.Series

--------------------------------------
ID: 10738 --> 1
>>> s4 = pd.Series([' ', '\t\r\n ', ''])
>>> s4.str.isspace()
0     True
1     True
2    False
dtype: bool

---->   pandas.Series

--------------------------------------
ID: 10739 --> 1
>>> s5 = pd.Series(['leopard', 'Golden Eagle', 'SNAKE', ''])

---->   pandas.Series

--------------------------------------
ID: 10743 --> 2
>>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])
>>> a
a    1.0
b    1.0
c    1.0
d    NaN
dtype: float64
>>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])
>>> b
a    1.0
b    NaN
d    1.0
e    NaN
dtype: float64
>>> a.eq(b, fill_value=0)
a     True
b    False
c    False
d    False
e    False
dtype: bool

---->   pandas.Series; Series.eq

--------------------------------------
ID: 10744 --> 1
>>> s = pd.Series(
...     [
...         "this is a regular sentence",
...         "https://docs.python.org/3/tutorial/index.html",
...         np.nan
...     ]
... )
>>> s
0                       this is a regular sentence
1    https://docs.python.org/3/tutorial/index.html
2                                              NaN
dtype: object

---->   pandas.Series

--------------------------------------
ID: 10752 --> 1
>>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])
>>> a
a    1.0
b    1.0
c    1.0
d    NaN
dtype: float64
>>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])
>>> b
a    1.0
b    NaN
d    1.0
e    NaN
dtype: float64
>>> a.divide(b, fill_value=0)
a    1.0
b    inf
c    inf
d    0.0
e    NaN
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 10753 --> 1
>>> s = pd.Series(data=[1, None, 4, 1],
...               index=['A', 'B', 'C', 'D'])
>>> s
A    1.0
B    NaN
C    4.0
D    1.0
dtype: float64

---->   pandas.Series

--------------------------------------
ID: 10754 --> 1
>>> s.idxmin()
'A'

---->   Series.idxmin

--------------------------------------
ID: 10755 --> 1
>>> s.idxmin(skipna=False)
nan

---->   Series.idxmin

--------------------------------------
ID: 10756 --> 1
>>> df = pd.DataFrame({'person_id': [0, 1, 2, 3],
...                   'age': [21, 25, 62, 43],
...                   'height': [1.61, 1.87, 1.49, 2.01]}
...                  ).set_index('person_id')
>>> df
           age  height
person_id
0           21    1.61
1           25    1.87
2           62    1.49
3           43    2.01

---->   pandas.DataFrame

--------------------------------------
ID: 10757 --> 1
>>> df.var()
age       352.916667
height      0.056367
dtype: float64

---->   DataFrame.var

--------------------------------------
ID: 10758 --> 1
>>> df.var(ddof=0)
age       264.687500
height      0.042275
dtype: float64

---->   DataFrame.var

--------------------------------------
ID: 10759 --> 2
>>> s = pd.Series(range(3))
>>> s.memory_usage()
152

---->   pandas.Series; Series.memory_usage

--------------------------------------
ID: 10760 --> 1
>>> s.memory_usage(index=False)
24

---->   Series.memory_usage

--------------------------------------
ID: 10761 --> 2
>>> s = pd.Series(["a", "b"])
>>> s.values
array(['a', 'b'], dtype=object)
>>> s.memory_usage()
144
>>> s.memory_usage(deep=True)
244

---->   pandas.Series; Series.memory_usage

--------------------------------------
ID: 10762 --> 1
>>> s = pd.Series(['lower', 'CAPITALS', 'this is a sentence', 'SwApCaSe'])
>>> s
0                 lower
1              CAPITALS
2    this is a sentence
3              SwApCaSe
dtype: object

---->   pandas.Series

--------------------------------------
ID: 10768 --> 1
>>> cat = pd.Categorical(['a', 'b', 'c'])
>>> cat
['a', 'b', 'c']
Categories (3, object): ['a', 'b', 'c']
>>> cat.repeat(2)
['a', 'a', 'b', 'b', 'c', 'c']
Categories (3, object): ['a', 'b', 'c']
>>> cat.repeat([1, 2, 3])
['a', 'b', 'b', 'c', 'c', 'c']
Categories (3, object): ['a', 'b', 'c']

---->   pandas.Categorical

--------------------------------------
ID: 10771 --> 1
>>> pd.Series(['a', 'b']).dt
Traceback (most recent call last):
...
AttributeError: Can only use .dt accessor with datetimelike values

---->   pandas.Series

--------------------------------------
ID: 10773 --> 1
In [1]: ds = pd.DataFrame({"longitude": np.linspace(0, 10),
   ...:                    "latitude": np.linspace(0, 20)})
In [2]: ds.geo.center
Out[2]: (5.0, 10.0)
In [3]: ds.geo.plot()  # plots data on a map

---->   pandas.DataFrame

--------------------------------------
