Examples,Henry's paragraphs,Sarah's paragraphs,Conflict?,Resolved paragraphs,Notes,Program,Has paragraphs,Updated program,Paragraph count,Program count,Program correct,Updated program count,Updated program correct
"# tags: LOCATION, ORGANIZATION, PERSON
edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz
# tags: DATE, LOCATION, MONEY, ORGANIZATION, PERCENT, PERSON, TIME
edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz
# LOCATION, MISC, ORGANIZATION, PERSON
edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz",These are the default models that are run:,These are the default models that are run:,0,These are the default models that are run:,,These are the default models that are run:,TRUE,During this phase a series of trained CRFâ€™s will be run on each sentence. These CRFâ€™s are trained on large tagged data sets. They evaluate the entire sequence and pick the optimal tag sequence.,1,1,1,1,0
"CAUSE_OF_DEATH, CITY, COUNTRY, CRIMINAL_CHARGE, EMAIL, HANDLE,
IDEOLOGY, NATIONALITY, RELIGION, STATE_OR_PROVINCE, TITLE, URL",The tags set by this phase include:,The tags set by this phase include:,0,The tags set by this phase include:,Wasn't sure about this one. It needs like the whole 4 paragraphs to make sense but instrcutsions said one paragraph only marked by a <p> tag,NOTE: applying these rules will significantly slow down the tagging process.,FALSE,"At this point, a series of rules used for the KBP 2017 competition will be run to create more fine-grained NER tags. These rules are applied using a TokensRegexNERAnnotator sub-annotator. That is the main NERCombinerAnnotator builds a TokensRegexNERAnnotator as a sub-annotator and runs it on all sentences as part of itâ€™s entire tagging process. The purpose of these rules is give tokens more specific tags. So for instance California would be tagged as a STATE_OR_PROVINCE rather than just a LOCATION.",1,1,0,1,0
"Los Angeles	CITY	LOCATION,MISC	1.0","means to match the token “Los” followed by the token “Angeles”, and label them both as CITY, provided they have a current NER tag of O, LOCATION, or MISC.","means to match the token “Los” followed by the token “Angeles”, and label them both as CITY, provided they have a current NER tag of O, LOCATION, or MISC.",0,"means to match the token “Los” followed by the token “Angeles”, and label them both as CITY, provided they have a current NER tag of O, LOCATION, or MISC.",,"The first column is the tokens pattern, the second column is the NER tag to apply, the third is the types of NER tags that can be overwritten, and the fourth is a priority used for tie-breaking if two rules match a sequence.",TRUE,,1,1,0,0,0
Bachelor of (Arts|Science)	DEGREE	MISC	1.0,"means to match the token “Bachelor”, then the token “of”, and finally either the token “Arts” or “Science”.","means to match the token “Bachelor”, then the token “of”, and finally either the token “Arts” or “Science”.",0,"means to match the token “Bachelor”, then the token “of”, and finally either the token “Arts” or “Science”.",,"means to match the token “Los” followed by the token “Angeles”, and label them both as CITY, provided they have a current NER tag of O, LOCATION, or MISC.",FALSE,,1,1,0,0,0
"ignorecase=true,validpospattern=^(NN|JJ).*,edu/stanford/nlp/models/kbp/english/gazetteers/regexner_caseless.tab;edu/stanford/nlp/models/kbp/english/gazetteers/regexner_cased.tab","As an example, this is the default ner.fine.regexner.mapping setting:","As an example, this is the default ner.fine.regexner.mapping setting:",0,"As an example, this is the default ner.fine.regexner.mapping setting:",,The ner.fine.regexner.mapping property allows one to specify a set of rules files and additional properties for each rules file.,FALSE,The ner.fine.regexner.mapping property allows one to specify a set of rules files and additional properties for each rules file.,1,1,0,1,0
"edu/stanford/nlp/models/kbp/english/gazetteers/regexner_caseless.tab
edu/stanford/nlp/models/kbp/english/gazetteers/regexner_cased.tab",The two rules files are:,The two rules files are:,0,The two rules files are:,Again a bit tricky,The ner.fine.regexner.mapping property allows one to specify a set of rules files and additional properties for each rules file.,FALSE,The ner.fine.regexner.mapping property allows one to specify a set of rules files and additional properties for each rules file.,1,1,0,1,0
"Boston Red Sox       SPORTS_TEAM     ORGANIZATION,MISC       1
Denver Broncos       SPORTS_TEAM     ORGANIZATION,MISC       1
Detroit Red Wings    SPORTS_TEAM     ORGANIZATION,MISC       1
Los Angeles Lakers   SPORTS_TEAM     ORGANIZATION,MISC       1
",Your rules file might look like this /path/to/sports_teams.rules,"For instance, suppose you want to match sports teams after the previous NER steps have been run.",1,"For instance, suppose you want to match sports teams after the previous NER steps have been run.",Multiple paragraphs too but I took the more meaningful one,,TRUE,This second TokensRegexNERAnnotator sub-annotator has the name ner.additional.regexner and is customized in the same manner. This is for the case when users want to run their own rules after the standard rules we provide.,1,0,0,1,0
"java -Xmx5g edu.stanford.nlp.pipeline.StanfordCoreNLP -annotators tokenize,ssplit,pos,lemma,ner -ner.additional.tokensregex.rules example.rules -file example.txt -outputFormat text","If you want to run a series of TokensRegex rules before entity building, you can also specify a set of TokensRegex rules. A TokensRegexAnnotator sub-annotator will be called. It has the name ner.additional.tokensregex.","If you want to run a series of TokensRegex rules before entity building, you can also specify a set of TokensRegex rules. A TokensRegexAnnotator sub-annotator will be called. It has the name ner.additional.tokensregex.",0,"If you want to run a series of TokensRegex rules before entity building, you can also specify a set of TokensRegex rules. A TokensRegexAnnotator sub-annotator will be called. It has the name ner.additional.tokensregex.",,"If you want to run a series of TokensRegex rules before entity building, you can also specify a set of TokensRegex rules. A TokensRegexAnnotator sub-annotator will be called. It has the name ner.additional.tokensregex.",TRUE,"If you want to run a series of TokensRegex rules before entity building, you can also specify a set of TokensRegex rules. A TokensRegexAnnotator sub-annotator will be called. It has the name ner.additional.tokensregex.",1,1,1,1,1
"# run default NER
java -Xmx4g -cp ""*"" edu.stanford.nlp.pipeline.StanfordCoreNLP -annotators tokenize,ssplit,pos,lemma,ner -file example.txt -outputFormat text",There a variety of ways to customize an NER pipeline. Below are some example commands.,There a variety of ways to customize an NER pipeline. Below are some example commands.,0,There a variety of ways to customize an NER pipeline. Below are some example commands.,,There a variety of ways to customize an NER pipeline. Below are some example commands.,FALSE,,1,1,1,0,0
"# only run rules based NER (numeric classifiers, SUTime, TokensRegexNER, TokensRegex)
java -Xmx4g -cp ""*"" edu.stanford.nlp.pipeline.StanfordCoreNLP -annotators tokenize,ssplit,pos,lemma,ner -ner.rulesOnly -file example.txt ",There a variety of ways to customize an NER pipeline. Below are some example commands.,There a variety of ways to customize an NER pipeline. Below are some example commands.,0,There a variety of ways to customize an NER pipeline. Below are some example commands.,,,FALSE,,1,0,0,0,0
"# only run statistical NER
java -Xmx4g -cp ""*"" edu.stanford.nlp.pipeline.StanfordCoreNLP -annotators tokenize,ssplit,pos,lemma,ner -ner.statisticalOnly -file example.txt ",There a variety of ways to customize an NER pipeline. Below are some example commands.,There a variety of ways to customize an NER pipeline. Below are some example commands.,0,There a variety of ways to customize an NER pipeline. Below are some example commands.,,,FALSE,,1,0,0,0,0
"# shut off numeric classifiers
# note that in this case ner no longer requires pos or lemma
java -Xmx4g -cp ""*"" edu.stanford.nlp.pipeline.StanfordCoreNLP -annotators tokenize,ssplit,ner -ner.applyNumericClassifiers false -file example.txt -outputFormat text",There a variety of ways to customize an NER pipeline. Below are some example commands.,There a variety of ways to customize an NER pipeline. Below are some example commands.,0,There a variety of ways to customize an NER pipeline. Below are some example commands.,,There a variety of ways to customize an NER pipeline. Below are some example commands.,FALSE,,1,1,1,0,0
"# shut off SUTime
java -Xmx4g -cp ""*"" edu.stanford.nlp.pipeline.StanfordCoreNLP -annotators tokenize,ssplit,pos,lemma,ner -ner.useSUTime false -file example.txt -outputFormat text",There a variety of ways to customize an NER pipeline. Below are some example commands.,There a variety of ways to customize an NER pipeline. Below are some example commands.,0,There a variety of ways to customize an NER pipeline. Below are some example commands.,,There a variety of ways to customize an NER pipeline. Below are some example commands.,FALSE,,1,1,1,0,0
"# specify doc date for each document to be 2019-01-01
# other options for setting doc date specified below
java -Xmx4g -cp ""*"" edu.stanford.nlp.pipeline.StanfordCoreNLP -annotators tokenize,ssplit,pos,lemma,ner -ner.docdate.useFixedDate 2019-01-01 -file example.txt",There a variety of ways to customize an NER pipeline. Below are some example commands.,There a variety of ways to customize an NER pipeline. Below are some example commands.,0,There a variety of ways to customize an NER pipeline. Below are some example commands.,,There a variety of ways to customize an NER pipeline. Below are some example commands.,FALSE,,1,1,1,0,0
"# shut off fine grained NER
java -Xmx4g -cp ""*"" edu.stanford.nlp.pipeline.StanfordCoreNLP -annotators tokenize,ssplit,pos,lemma,ner -ner.applyFineGrained false -file example.txt -outputFormat text",There a variety of ways to customize an NER pipeline. Below are some example commands.,There a variety of ways to customize an NER pipeline. Below are some example commands.,0,There a variety of ways to customize an NER pipeline. Below are some example commands.,,There a variety of ways to customize an NER pipeline. Below are some example commands.,FALSE,,1,1,1,0,0
"# run fine-grained NER with a custom rules file
java -Xmx4g -cp ""*"" edu.stanford.nlp.pipeline.StanfordCoreNLP -annotators tokenize,ssplit,pos,lemma,ner -ner.fine.regexner.mapping custom.rules -file example.txt -outputFormat text",There a variety of ways to customize an NER pipeline. Below are some example commands.,There a variety of ways to customize an NER pipeline. Below are some example commands.,0,There a variety of ways to customize an NER pipeline. Below are some example commands.,,There a variety of ways to customize an NER pipeline. Below are some example commands.,FALSE,,1,1,1,0,0
"# run fine-grained NER with two custom rules files
# the first rules file caseless.rules should be case-insensitive, the second rules file uses default options
java -Xmx4g -cp ""*"" edu.stanford.nlp.pipeline.StanfordCoreNLP -annotators tokenize,ssplit,pos,lemma,ner -ner.fine.regexner.mapping ""ignorecase=true,caseless.rules;cased.rules"" -file example.txt -outputFormat text",There a variety of ways to customize an NER pipeline. Below are some example commands.,There a variety of ways to customize an NER pipeline. Below are some example commands.,0,There a variety of ways to customize an NER pipeline. Below are some example commands.,,There a variety of ways to customize an NER pipeline. Below are some example commands.,FALSE,,1,1,1,0,0
"# add additional rules to run after fine-grained NER
java -Xmx4g -cp ""*"" edu.stanford.nlp.pipeline.StanfordCoreNLP -annotators tokenize,ssplit,pos,lemma,ner -ner.additional.regexner.mapping additional.rules -file example.txt -outputFormat text",There a variety of ways to customize an NER pipeline. Below are some example commands.,There a variety of ways to customize an NER pipeline. Below are some example commands.,0,There a variety of ways to customize an NER pipeline. Below are some example commands.,,There a variety of ways to customize an NER pipeline. Below are some example commands.,FALSE,,1,1,1,0,0
"# run tokens regex rules
java -Xmx5g edu.stanford.nlp.pipeline.StanfordCoreNLP -annotators tokenize,ssplit,pos,lemma,ner -ner.additional.tokensregex.rules example.rules -file example.txt -outputFormat text",There a variety of ways to customize an NER pipeline. Below are some example commands.,There a variety of ways to customize an NER pipeline. Below are some example commands.,0,There a variety of ways to customize an NER pipeline. Below are some example commands.,,There a variety of ways to customize an NER pipeline. Below are some example commands.,FALSE,,1,1,1,0,0
"# don't build entity mentions
java -Xmx4g -cp ""*"" edu.stanford.nlp.pipeline.StanfordCoreNLP -annotators tokenize,ssplit,pos,lemma,ner -ner.buildEntityMentions false -file example.txt -outputFormat text",There a variety of ways to customize an NER pipeline. Below are some example commands.,There a variety of ways to customize an NER pipeline. Below are some example commands.,0,There a variety of ways to customize an NER pipeline. Below are some example commands.,,There a variety of ways to customize an NER pipeline. Below are some example commands.,FALSE,,1,1,1,0,0
"package edu.stanford.nlp.examples;

import edu.stanford.nlp.pipeline.*;

import java.util.Properties;
import java.util.stream.Collectors;

public class NERPipelineDemo {

  public static void main(String[] args) {
    // set up pipeline properties
    Properties props = new Properties();
    props.setProperty(""annotators"", ""tokenize,ssplit,pos,lemma,ner"");
    // example customizations (these are commented out but you can uncomment them to see the results

    // disable fine grained ner
    // props.setProperty(""ner.applyFineGrained"", ""false"");

    // customize fine grained ner
    // props.setProperty(""ner.fine.regexner.mapping"", ""example.rules"");
    // props.setProperty(""ner.fine.regexner.ignorecase"", ""true"");

    // add additional rules, customize TokensRegexNER annotator
    // props.setProperty(""ner.additional.regexner.mapping"", ""example.rules"");
    // props.setProperty(""ner.additional.regexner.ignorecase"", ""true"");

    // add 2 additional rules files ; set the first one to be case-insensitive
    // props.setProperty(""ner.additional.regexner.mapping"", ""ignorecase=true,example_one.rules;example_two.rules"");

    // set document date to be a specific date (other options are explained in the document date section)
    // props.setProperty(""ner.docdate.useFixedDate"", ""2019-01-01"");

    // only run rules based NER
    // props.setProperty(""ner.rulesOnly"", ""true"");

    // only run statistical NER
    // props.setProperty(""ner.statisticalOnly"", ""true"");

    // set up pipeline
    StanfordCoreNLP pipeline = new StanfordCoreNLP(props);
    // make an example document
    CoreDocument doc = new CoreDocument(""Joe Smith is from Seattle."");
    // annotate the document
    pipeline.annotate(doc);
    // view results
    System.out.println(""---"");
    System.out.println(""entities found"");
    for (CoreEntityMention em : doc.entityMentions())
      System.out.println(""\tdetected entity: \t""+em.text()+""\t""+em.entityType());
    System.out.println(""---"");
    System.out.println(""tokens and ner tags"");
    String tokensAndNERTags = doc.tokens().stream().map(token -> ""(""+token.word()+"",""+token.ner()+"")"").collect(
        Collectors.joining("" ""));
    System.out.println(tokensAndNERTags);
  }

}
",,Java API Example,1,Java API Example,,,FALSE,,1,1,0,0,0
"{word: 'Los', 'tag': 'LOCATION', 'prob': .992} 
{word: 'Angeles', 'tag': 'LOCATION', 'prob': .999}",the entity Los Angeles would be assigned the LOCATION tag with a confidence of .992.,The following example shows how to access label confidences for tokens and entities. Each token stores the probability of its NER label given by the CRF that was used to assign the label in the CoreAnnotations.NamedEntityTagProbsAnnotation.class. Each entity mention contains the probability of the token with the lowest label probability in its span. For example if Los Angeles had the following probabilities:,1,The following example shows how to access label confidences for tokens and entities. Each token stores the probability of its NER label given by the CRF that was used to assign the label in the CoreAnnotations.NamedEntityTagProbsAnnotation.class. Each entity mention contains the probability of the token with the lowest label probability in its span. For example if Los Angeles had the following probabilities:,,The following example shows how to access label confidences for tokens and entities. Each token stores the probability of its NER label given by the CRF that was used to assign the label in the CoreAnnotations.NamedEntityTagProbsAnnotation.class. Each entity mention contains the probability of the token with the lowest label probability in its span. For example if Los Angeles had the following probabilities:,TRUE,The following example shows how to access label confidences for tokens and entities. Each token stores the probability of its NER label given by the CRF that was used to assign the label in the CoreAnnotations.NamedEntityTagProbsAnnotation.class. Each entity mention contains the probability of the token with the lowest label probability in its span. For example if Los Angeles had the following probabilities:,1,1,1,1,1
"package edu.stanford.nlp.examples;

import edu.stanford.nlp.ling.*;
import edu.stanford.nlp.pipeline.*;
import java.util.*;

public class NERConfidenceExample {

    public static void main(String[] args) {
        String exampleText = ""Joe Smith lives in California."";
        Properties props = new Properties();
        props.setProperty(""annotators"", ""tokenize,ssplit,pos,lemma,ner"");
        StanfordCoreNLP pipeline = new StanfordCoreNLP(props);
        CoreDocument document = new CoreDocument(exampleText);
        pipeline.annotate(document);
        // get confidences for entities
        for (CoreEntityMention em : document.entityMentions()) {
            System.out.println(em.text() + ""\t"" + em.entityTypeConfidences());
        }
        // get confidences for tokens
        for (CoreLabel token : document.tokens()) {
            System.out.println(token.word() + ""\t"" + token.get(CoreAnnotations.NamedEntityTagProbsAnnotation.class));
        }
    }
}",Below is code for accessing these confidences.,Below is code for accessing these confidences.,0,Below is code for accessing these confidences.,,Below is code for accessing these confidences.,TRUE,Below is code for accessing these confidences.,1,1,1,1,1
"Joe    PERSON
Smith  PERSON
lives  O
in     O
California    LOCATION
.    O

He    O
used    O
to    O
live    O
in    O
Oregon    LOCATION
.    O
",The train/dev/test data files should be in the following format:,"In this example, each line is a token, followed by a tab, followed by the NER tag. A blank line represents a sentence break. The model that we release is trained on over a million tokens. The more training data you have, the more accurate your model should be.",1,Training or retraining new models,,,FALSE,,1,1,0,0,0
"java -Xmx2g -cp ""*"" edu.stanford.nlp.ie.crf.CRFClassifier -prop ner.model.props",Here is the command for starting the training process (make sure your CLASSPATH is set up to include all of the Stanford CoreNLP jars):,Here is the command for starting the training process (make sure your CLASSPATH is set up to include all of the Stanford CoreNLP jars):,0,Here is the command for starting the training process (make sure your CLASSPATH is set up to include all of the Stanford CoreNLP jars):,,"The standard training data sets used for PERSON/LOCATION/ORGANIZATION/MISC must be purchased from the LDC, we do not distribute them.",FALSE,,1,1,0,0,0
"# location of training data
trainFileList = /path/to/conll.3class.train
# location of test data
testFile = /path/to/all.3class.test
# where to store the saved model
serializeTo = ner.model.ser.gz

type = crf

wordFunction = edu.stanford.nlp.process.AmericanizeFunction

useDistSim = false

# establish the data file format
map = word=0,answer=1

saveFeatureIndexToDisk = true

useClassFeature=true
useWord=true
useNGrams=true
noMidNGrams=true
maxNGramLeng=6
usePrev=true
useNext=true
useLongSequences=true
useSequences=true
usePrevSequences=true
maxLeft=1
useTypeSeqs=true
useTypeSeqs2=true
useTypeySequences=true
useOccurrencePatterns=true
useLastRealWord=true
useNextRealWord=true
normalize=true
wordShape=chris2useLC
useDisjunctive=true
disjunctionWidth=5

readerAndWriter=edu.stanford.nlp.sequences.ColumnDocumentReaderAndWriter

useObservedSequencesOnly=true

useQN = true
QNsize = 25

# makes it go faster
featureDiffThresh=0.05",The training process can be customized using a properties file. Here is an example properties file for training an English model(ner.model.props):,The training process can be customized using a properties file. Here is an example properties file for training an English model(ner.model.props):,0,The training process can be customized using a properties file. Here is an example properties file for training an English model(ner.model.props):,,The training process can be customized using a properties file. Here is an example properties file for training an English model(ner.model.props):,TRUE,,1,1,1,0,0
,,,,,,,,,,,,,
,,,,,,Program,Has paragraphs,Updated program,26,23,15,8,3
,,,,Precision,,65.22%,,37.50%,,,,,
,,,,Recall,,57.69%,,11.54%,,,,,