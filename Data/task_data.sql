-- MySQL dump 10.13  Distrib 8.0.32, for Linux (x86_64)
--
-- Host: localhost    Database: task_data
-- ------------------------------------------------------
-- Server version	8.0.32-0ubuntu0.20.04.2

/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;
/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;
/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;
/*!50503 SET NAMES utf8mb4 */;
/*!40103 SET @OLD_TIME_ZONE=@@TIME_ZONE */;
/*!40103 SET TIME_ZONE='+00:00' */;
/*!40014 SET @OLD_UNIQUE_CHECKS=@@UNIQUE_CHECKS, UNIQUE_CHECKS=0 */;
/*!40014 SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS=0 */;
/*!40101 SET @OLD_SQL_MODE=@@SQL_MODE, SQL_MODE='NO_AUTO_VALUE_ON_ZERO' */;
/*!40111 SET @OLD_SQL_NOTES=@@SQL_NOTES, SQL_NOTES=0 */;

--
-- Table structure for table `auth_group`
--

DROP TABLE IF EXISTS `auth_group`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!50503 SET character_set_client = utf8mb4 */;
CREATE TABLE `auth_group` (
  `id` int NOT NULL AUTO_INCREMENT,
  `name` varchar(150) NOT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `name` (`name`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `auth_group`
--

LOCK TABLES `auth_group` WRITE;
/*!40000 ALTER TABLE `auth_group` DISABLE KEYS */;
/*!40000 ALTER TABLE `auth_group` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `auth_group_permissions`
--

DROP TABLE IF EXISTS `auth_group_permissions`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!50503 SET character_set_client = utf8mb4 */;
CREATE TABLE `auth_group_permissions` (
  `id` bigint NOT NULL AUTO_INCREMENT,
  `group_id` int NOT NULL,
  `permission_id` int NOT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `auth_group_permissions_group_id_permission_id_0cd325b0_uniq` (`group_id`,`permission_id`),
  KEY `auth_group_permissio_permission_id_84c5c92e_fk_auth_perm` (`permission_id`),
  CONSTRAINT `auth_group_permissio_permission_id_84c5c92e_fk_auth_perm` FOREIGN KEY (`permission_id`) REFERENCES `auth_permission` (`id`),
  CONSTRAINT `auth_group_permissions_group_id_b120cbf9_fk_auth_group_id` FOREIGN KEY (`group_id`) REFERENCES `auth_group` (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `auth_group_permissions`
--

LOCK TABLES `auth_group_permissions` WRITE;
/*!40000 ALTER TABLE `auth_group_permissions` DISABLE KEYS */;
/*!40000 ALTER TABLE `auth_group_permissions` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `auth_permission`
--

DROP TABLE IF EXISTS `auth_permission`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!50503 SET character_set_client = utf8mb4 */;
CREATE TABLE `auth_permission` (
  `id` int NOT NULL AUTO_INCREMENT,
  `name` varchar(255) NOT NULL,
  `content_type_id` int NOT NULL,
  `codename` varchar(100) NOT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `auth_permission_content_type_id_codename_01ab375a_uniq` (`content_type_id`,`codename`),
  CONSTRAINT `auth_permission_content_type_id_2f476e4b_fk_django_co` FOREIGN KEY (`content_type_id`) REFERENCES `django_content_type` (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=37 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `auth_permission`
--

LOCK TABLES `auth_permission` WRITE;
/*!40000 ALTER TABLE `auth_permission` DISABLE KEYS */;
INSERT INTO `auth_permission` VALUES (1,'Can add library',1,'add_library'),(2,'Can change library',1,'change_library'),(3,'Can delete library',1,'delete_library'),(4,'Can view library',1,'view_library'),(5,'Can add response',2,'add_response'),(6,'Can change response',2,'change_response'),(7,'Can delete response',2,'delete_response'),(8,'Can view response',2,'view_response'),(9,'Can add task',3,'add_task'),(10,'Can change task',3,'change_task'),(11,'Can delete task',3,'delete_task'),(12,'Can view task',3,'view_task'),(13,'Can add log entry',4,'add_logentry'),(14,'Can change log entry',4,'change_logentry'),(15,'Can delete log entry',4,'delete_logentry'),(16,'Can view log entry',4,'view_logentry'),(17,'Can add permission',5,'add_permission'),(18,'Can change permission',5,'change_permission'),(19,'Can delete permission',5,'delete_permission'),(20,'Can view permission',5,'view_permission'),(21,'Can add group',6,'add_group'),(22,'Can change group',6,'change_group'),(23,'Can delete group',6,'delete_group'),(24,'Can view group',6,'view_group'),(25,'Can add user',7,'add_user'),(26,'Can change user',7,'change_user'),(27,'Can delete user',7,'delete_user'),(28,'Can view user',7,'view_user'),(29,'Can add content type',8,'add_contenttype'),(30,'Can change content type',8,'change_contenttype'),(31,'Can delete content type',8,'delete_contenttype'),(32,'Can view content type',8,'view_contenttype'),(33,'Can add session',9,'add_session'),(34,'Can change session',9,'change_session'),(35,'Can delete session',9,'delete_session'),(36,'Can view session',9,'view_session');
/*!40000 ALTER TABLE `auth_permission` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `auth_user`
--

DROP TABLE IF EXISTS `auth_user`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!50503 SET character_set_client = utf8mb4 */;
CREATE TABLE `auth_user` (
  `id` int NOT NULL AUTO_INCREMENT,
  `password` varchar(128) NOT NULL,
  `last_login` datetime(6) DEFAULT NULL,
  `is_superuser` tinyint(1) NOT NULL,
  `username` varchar(150) NOT NULL,
  `first_name` varchar(150) NOT NULL,
  `last_name` varchar(150) NOT NULL,
  `email` varchar(254) NOT NULL,
  `is_staff` tinyint(1) NOT NULL,
  `is_active` tinyint(1) NOT NULL,
  `date_joined` datetime(6) NOT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `username` (`username`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `auth_user`
--

LOCK TABLES `auth_user` WRITE;
/*!40000 ALTER TABLE `auth_user` DISABLE KEYS */;
/*!40000 ALTER TABLE `auth_user` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `auth_user_groups`
--

DROP TABLE IF EXISTS `auth_user_groups`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!50503 SET character_set_client = utf8mb4 */;
CREATE TABLE `auth_user_groups` (
  `id` bigint NOT NULL AUTO_INCREMENT,
  `user_id` int NOT NULL,
  `group_id` int NOT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `auth_user_groups_user_id_group_id_94350c0c_uniq` (`user_id`,`group_id`),
  KEY `auth_user_groups_group_id_97559544_fk_auth_group_id` (`group_id`),
  CONSTRAINT `auth_user_groups_group_id_97559544_fk_auth_group_id` FOREIGN KEY (`group_id`) REFERENCES `auth_group` (`id`),
  CONSTRAINT `auth_user_groups_user_id_6a12ed8b_fk_auth_user_id` FOREIGN KEY (`user_id`) REFERENCES `auth_user` (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `auth_user_groups`
--

LOCK TABLES `auth_user_groups` WRITE;
/*!40000 ALTER TABLE `auth_user_groups` DISABLE KEYS */;
/*!40000 ALTER TABLE `auth_user_groups` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `auth_user_user_permissions`
--

DROP TABLE IF EXISTS `auth_user_user_permissions`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!50503 SET character_set_client = utf8mb4 */;
CREATE TABLE `auth_user_user_permissions` (
  `id` bigint NOT NULL AUTO_INCREMENT,
  `user_id` int NOT NULL,
  `permission_id` int NOT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `auth_user_user_permissions_user_id_permission_id_14a6b632_uniq` (`user_id`,`permission_id`),
  KEY `auth_user_user_permi_permission_id_1fbb5f2c_fk_auth_perm` (`permission_id`),
  CONSTRAINT `auth_user_user_permi_permission_id_1fbb5f2c_fk_auth_perm` FOREIGN KEY (`permission_id`) REFERENCES `auth_permission` (`id`),
  CONSTRAINT `auth_user_user_permissions_user_id_a95ead1b_fk_auth_user_id` FOREIGN KEY (`user_id`) REFERENCES `auth_user` (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `auth_user_user_permissions`
--

LOCK TABLES `auth_user_user_permissions` WRITE;
/*!40000 ALTER TABLE `auth_user_user_permissions` DISABLE KEYS */;
/*!40000 ALTER TABLE `auth_user_user_permissions` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `django_admin_log`
--

DROP TABLE IF EXISTS `django_admin_log`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!50503 SET character_set_client = utf8mb4 */;
CREATE TABLE `django_admin_log` (
  `id` int NOT NULL AUTO_INCREMENT,
  `action_time` datetime(6) NOT NULL,
  `object_id` longtext,
  `object_repr` varchar(200) NOT NULL,
  `action_flag` smallint unsigned NOT NULL,
  `change_message` longtext NOT NULL,
  `content_type_id` int DEFAULT NULL,
  `user_id` int NOT NULL,
  PRIMARY KEY (`id`),
  KEY `django_admin_log_content_type_id_c4bce8eb_fk_django_co` (`content_type_id`),
  KEY `django_admin_log_user_id_c564eba6_fk_auth_user_id` (`user_id`),
  CONSTRAINT `django_admin_log_content_type_id_c4bce8eb_fk_django_co` FOREIGN KEY (`content_type_id`) REFERENCES `django_content_type` (`id`),
  CONSTRAINT `django_admin_log_user_id_c564eba6_fk_auth_user_id` FOREIGN KEY (`user_id`) REFERENCES `auth_user` (`id`),
  CONSTRAINT `django_admin_log_chk_1` CHECK ((`action_flag` >= 0))
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `django_admin_log`
--

LOCK TABLES `django_admin_log` WRITE;
/*!40000 ALTER TABLE `django_admin_log` DISABLE KEYS */;
/*!40000 ALTER TABLE `django_admin_log` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `django_content_type`
--

DROP TABLE IF EXISTS `django_content_type`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!50503 SET character_set_client = utf8mb4 */;
CREATE TABLE `django_content_type` (
  `id` int NOT NULL AUTO_INCREMENT,
  `app_label` varchar(100) NOT NULL,
  `model` varchar(100) NOT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `django_content_type_app_label_model_76bd3d3b_uniq` (`app_label`,`model`)
) ENGINE=InnoDB AUTO_INCREMENT=10 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `django_content_type`
--

LOCK TABLES `django_content_type` WRITE;
/*!40000 ALTER TABLE `django_content_type` DISABLE KEYS */;
INSERT INTO `django_content_type` VALUES (4,'admin','logentry'),(6,'auth','group'),(5,'auth','permission'),(7,'auth','user'),(8,'contenttypes','contenttype'),(1,'overview','library'),(2,'overview','response'),(3,'overview','task'),(9,'sessions','session');
/*!40000 ALTER TABLE `django_content_type` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `django_migrations`
--

DROP TABLE IF EXISTS `django_migrations`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!50503 SET character_set_client = utf8mb4 */;
CREATE TABLE `django_migrations` (
  `id` bigint NOT NULL AUTO_INCREMENT,
  `app` varchar(255) NOT NULL,
  `name` varchar(255) NOT NULL,
  `applied` datetime(6) NOT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=22 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `django_migrations`
--

LOCK TABLES `django_migrations` WRITE;
/*!40000 ALTER TABLE `django_migrations` DISABLE KEYS */;
INSERT INTO `django_migrations` VALUES (1,'contenttypes','0001_initial','2022-09-24 21:23:14.530364'),(2,'auth','0001_initial','2022-09-24 21:23:15.172991'),(3,'admin','0001_initial','2022-09-24 21:23:15.299672'),(4,'admin','0002_logentry_remove_auto_add','2022-09-24 21:23:15.352755'),(5,'admin','0003_logentry_add_action_flag_choices','2022-09-24 21:23:15.360438'),(6,'contenttypes','0002_remove_content_type_name','2022-09-24 21:23:15.461093'),(7,'auth','0002_alter_permission_name_max_length','2022-09-24 21:23:15.519794'),(8,'auth','0003_alter_user_email_max_length','2022-09-24 21:23:15.542232'),(9,'auth','0004_alter_user_username_opts','2022-09-24 21:23:15.548796'),(10,'auth','0005_alter_user_last_login_null','2022-09-24 21:23:15.678472'),(11,'auth','0006_require_contenttypes_0002','2022-09-24 21:23:15.686237'),(12,'auth','0007_alter_validators_add_error_messages','2022-09-24 21:23:15.695925'),(13,'auth','0008_alter_user_username_max_length','2022-09-24 21:23:15.805278'),(14,'auth','0009_alter_user_last_name_max_length','2022-09-24 21:23:15.902572'),(15,'auth','0010_alter_group_name_max_length','2022-09-24 21:23:15.920453'),(16,'auth','0011_update_proxy_permissions','2022-09-24 21:23:15.926928'),(17,'auth','0012_alter_user_first_name_max_length','2022-09-24 21:23:15.985836'),(19,'sessions','0001_initial','2022-09-24 21:23:16.103024'),(21,'overview','0001_initial','2022-10-18 22:44:38.852712');
/*!40000 ALTER TABLE `django_migrations` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `django_session`
--

DROP TABLE IF EXISTS `django_session`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!50503 SET character_set_client = utf8mb4 */;
CREATE TABLE `django_session` (
  `session_key` varchar(40) NOT NULL,
  `session_data` longtext NOT NULL,
  `expire_date` datetime(6) NOT NULL,
  PRIMARY KEY (`session_key`),
  KEY `django_session_expire_date_a5c62663` (`expire_date`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `django_session`
--

LOCK TABLES `django_session` WRITE;
/*!40000 ALTER TABLE `django_session` DISABLE KEYS */;
/*!40000 ALTER TABLE `django_session` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `overview_library`
--

DROP TABLE IF EXISTS `overview_library`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!50503 SET character_set_client = utf8mb4 */;
CREATE TABLE `overview_library` (
  `id` bigint NOT NULL AUTO_INCREMENT,
  `library_name` varchar(50) NOT NULL,
  `language` varchar(20) NOT NULL,
  `domain` varchar(50) DEFAULT NULL,
  `description` varchar(1000) NOT NULL,
  `gh_url` varchar(100) DEFAULT NULL,
  `doc_url` varchar(100) NOT NULL,
  `task_list_done` tinyint(1) NOT NULL,
  `method_examples` int DEFAULT NULL,
  `methods` int DEFAULT NULL,
  `class_examples` int DEFAULT NULL,
  `classes` int DEFAULT NULL,
  `signature_methods` int DEFAULT NULL,
  `signature_classes` int DEFAULT NULL,
  `text_readability_score` decimal(5,2) DEFAULT NULL,
  `text_readability_rating` varchar(20) DEFAULT NULL,
  `code_readability_score` decimal(5,2) DEFAULT NULL,
  `code_readability_rating` varchar(20) DEFAULT NULL,
  `navigability` varchar(500) DEFAULT NULL,
  `last_updated` datetime(6) NOT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=43 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `overview_library`
--

LOCK TABLES `overview_library` WRITE;
/*!40000 ALTER TABLE `overview_library` DISABLE KEYS */;
INSERT INTO `overview_library` VALUES (1,'orjson','Python',NULL,'orjson is a fast, correct JSON library for Python. It benchmarks as the fastest Python library for JSON and is more correct than the standard json library or other third-party libraries. It serializes dataclass, datetime, numpy, and UUID instances natively.','https://github.com/ijl/orjson.git','https://github.com/ijl/orjson',1,2,2,1,1,1,1,53.07,'fairly_difficult',NULL,NULL,'{\"has_search\": true, \"has_toc\": true, \"links_correct\": true}','2022-11-01 22:50:20.306321'),(2,'requests','Python',NULL,'Requests is an elegant and simple HTTP library for Python, built for human beings.','https://github.com/psf/requests.git','https://requests.readthedocs.io/en/latest/',1,8,216,1,22,57,8,53.28,'fairly_difficult',NULL,NULL,'{\"has_search\": true, \"has_toc\": true, \"links_correct\": true}','2022-10-26 21:26:28.221033'),(3,'JSON-java','Java',NULL,'The JSON-Java package is a reference implementation that demonstrates how to parse JSON documents into Java objects and how to generate new JSON documents from the Java classes.','https://github.com/stleary/JSON-java.git','https://github.com/stleary/JSON-java',1,0,175,0,16,2,2,53.73,'fairly_difficult',81.37,'easy','{\"has_search\": true, \"has_toc\": true, \"links_correct\": true}','2022-10-26 21:59:15.685793'),(4,'NLTK','Python',NULL,'The Natural Language Toolkit (NLTK) is an open source Python library  for Natural Language Processing.  A free online book is available.  (If you use the library for academic research, please cite the book.)','https://github.com/nltk/nltk.git','https://www.nltk.org/api/nltk.html',1,0,0,0,0,0,0,62.41,'standard',NULL,NULL,'{\"has_search\": true, \"has_toc\": true, \"links_correct\": true}','2022-10-26 22:00:52.843891'),(5,'CoreNLP','Java',NULL,'CoreNLP is your one stop shop for natural language processing in Java! CoreNLP enables users to derive linguistic annotations for text, including token and sentence boundaries, parts of speech, named entities, numeric and time values, dependency and constituency parses, coreference, sentiment, quote attributions, and relations. CoreNLP currently supports 8 languages: Arabic, Chinese, English, French, German, Hungarian, Italian, and Spanish.','https://github.com/stanfordnlp/CoreNLP.git','https://stanfordnlp.github.io/CoreNLP/',1,0,11041,0,1406,27,11,65.37,'standard',49.40,'difficult','{\"has_search\": true, \"has_toc\": true, \"links_correct\": true}','2022-10-26 22:46:40.230796'),(6,'jQuery','Javascript',NULL,'jQuery is a fast, small, and feature-rich JavaScript library. It makes things like HTML document traversal and manipulation, event handling, animation, and Ajax much simpler with an easy-to-use API that works across a multitude of browsers. If you\'re new to jQuery, we recommend that you check out the jQuery Learning Center.','https://github.com/jquery/jquery.git','https://api.jquery.com/',1,4,82,1,1,0,0,57.48,'fairly_difficult',NULL,NULL,'{\"has_search\": true, \"has_toc\": true, \"links_correct\": true}','2022-10-19 21:05:25.278027'),(7,'React','Javascript',NULL,'React is a JavaScript library for building user interfaces. Learn what React is all about on our homepage or in the tutorial.','https://github.com/facebook/react.git','https://reactjs.org/docs/getting-started.html',1,0,0,0,0,0,0,63.70,'standard',NULL,NULL,'{\"has_search\": true, \"has_toc\": true, \"links_correct\": true}','2022-11-14 18:46:53.387898'),(8,'QUnit','Javascript',NULL,'QUnit is a powerful, easy-to-use JavaScript unit test suite.','https://github.com/qunitjs/qunit.git','https://api.qunitjs.com/',1,4,64,1,2,1,0,49.56,'difficult',NULL,NULL,'{\"has_search\": true, \"has_toc\": true, \"links_correct\": true}','2022-10-19 19:30:08.781077'),(9,'jBinary','Javascript',NULL,'jBinary makes it easy to work with binary files in JavaScript.','https://github.com/jDataView/jBinary.git','https://github.com/jDataView/jBinary/wiki',1,0,22,0,1,0,0,43.54,'difficult',NULL,NULL,'{\"has_search\": true, \"has_toc\": true, \"links_correct\": true}','2022-10-19 18:18:24.648382'),(10,'memfs','Javascript',NULL,'Use memfs together with unionfs to create one filesystem from your in-memory volumes and the real disk filesystem:','https://github.com/streamich/memfs.git','https://github.com/streamich/memfs',1,0,0,0,0,0,0,68.84,'standard',NULL,NULL,'{\"has_search\": true, \"has_toc\": true, \"links_correct\": true}','2022-10-20 20:40:53.845242'),(11,'GitPython','Python',NULL,'GitPython is a python library used to interact with Git repositories.','https://github.com/gitpython-developers/GitPython.git','https://gitpython.readthedocs.io/en/stable/',1,0,3,0,3,0,0,40.09,'difficult',NULL,NULL,'{\"has_search\": true, \"has_toc\": true, \"links_correct\": true}','2022-10-24 21:29:05.312240'),(12,'netty','Java',NULL,'Netty project - an event-driven asynchronous network application framework','https://github.com/netty/netty.git','https://netty.io/wiki/',1,0,0,0,0,0,0,70.61,'fairly_easy',66.86,'standard','{\"has_search\": true, \"has_toc\": true, \"links_correct\": true}','2022-10-20 22:07:09.672252'),(13,'Bpmn-visualization','Javascript',NULL,'bpmn-visualization is a TypeScript library for visualizing process execution data on BPMN diagrams with:','https://github.com/process-analytics/bpmn-visualization-js.git','https://github.com/process-analytics/bpmn-visualization-js',1,0,0,0,0,0,0,63.01,'standard',NULL,NULL,'{\"has_search\": true, \"has_toc\": true, \"links_correct\": true}','2022-10-24 18:03:26.557193'),(14,'Ivy','Python',NULL,' Ivy is a static website generator built in Python. It\'s small, elegant, and simple to use. ','https://github.com/dmulholl/ivy.git','http://www.dmulholl.com/docs/ivy/main/',1,0,0,0,0,0,0,61.20,'standard',NULL,NULL,'{\"has_search\": false, \"has_toc\": true, \"links_correct\": true}','2022-10-24 22:59:33.303232'),(15,'Numba','Python',NULL,'This is the Numba documentation.  Unless you are already acquainted with Numba, we suggest you start with the User manual.','https://github.com/numba/numba.git','https://numba.readthedocs.io',1,0,28,0,7,0,0,60.27,'standard',NULL,NULL,'{\"has_search\": true, \"has_toc\": true, \"links_correct\": true}','2022-10-24 09:59:25.144451'),(16,'scanpy','Python',NULL,'Scanpy is a scalable toolkit for analyzing single-cell gene expression data built jointly with anndata.  It includes preprocessing, visualization, clustering, trajectory inference and differential expression testing.  The Python-based implementation efficiently deals with datasets of more than one million cells.','https://github.com/scverse/scanpy','https://scanpy.readthedocs.io/en/stable/',1,0,379,0,22,1,1,47.74,'difficult',NULL,NULL,'{\"has_search\": true, \"has_toc\": true, \"links_correct\": true}','2022-10-24 13:01:30.931982'),(17,'numpy','Python',NULL,'NumPy is the fundamental package for scientific computing in Python. It is a Python library that provides a multidimensional array object, various derived objects (such as masked arrays and matrices), and an assortment of routines for fast operations on arrays, including mathematical, logical, shape manipulation, sorting, selecting, I/O, discrete Fourier transforms, basic linear algebra, basic statistical operations, random simulation and much more.','https://github.com/numpy/numpy.git','https://numpy.org/doc/stable/',1,0,3315,0,326,0,0,58.83,'fairly_difficult',NULL,NULL,'{\"has_search\": true, \"has_toc\": true, \"links_correct\": true}','2022-10-24 13:59:38.330967'),(19,'pyAFQ','Python',NULL,'pyAFQ is a software package focused on automated delineation of the major fiber tracts in individual human brains, and quantification of the tissue properties within the tracts. To learn more about the software please refer to the Table of Contents.','https://github.com/yeatmanlab/pyAFQ','http://yeatmanlab.github.io/pyAFQ',1,0,1,0,1,0,0,51.16,'fairly_difficult',NULL,NULL,'{\"has_search\": true, \"has_toc\": true, \"links_correct\": true}','2022-10-24 14:08:12.477157'),(20,'ibis-project','Python',NULL,'Expressive analytics in Python at any scale.','https://github.com/ibis-project/ibis','https://ibis-project.org/docs/',1,0,3,0,1,0,0,NULL,NULL,NULL,NULL,'{\"has_search\": false, \"has_toc\": false, \"links_correct\": false}','2022-10-24 14:14:39.838153'),(21,'rcdesign','Python',NULL,'A Python package to analyze and design reinforced concrete sections - by the limit state method as per IS 456:2000, the Indian Standard code of practice for plain and reinforced concrete.','https://github.com/satish-annigeri/rcdesign','https://rcdesign.readthedocs.io/en/latest/',1,0,137,0,17,0,0,63.75,'standard',NULL,NULL,'{\"has_search\": true, \"has_toc\": true, \"links_correct\": true}','2022-10-25 15:36:26.751637'),(22,'testrun','Python',NULL,'No description, website, or topics provided.','https://github.com/bionumpy/bionumpy','https://bionumpy.github.io/bionumpy/',1,0,0,0,0,0,0,103.04,'confusing',NULL,NULL,'{\"has_search\": true, \"has_toc\": true, \"links_correct\": true}','2022-10-25 08:46:45.573019'),(23,'PyOpenGL','Python',NULL,'This document collects OpenGLContext-specific documentation.          The main PyOpenGL documentation           collection includes links to both PyOpenGL and OpenGL         documentation which will be of use to the OpenGLContext programmer as         well.','https://github.com/mcfletch/pyopengl.git','https://pyopengl.sourceforge.net/context/documentation.html',1,0,109,0,21,0,0,41.67,'difficult',NULL,NULL,'{\"has_search\": false, \"has_toc\": true, \"links_correct\": true}','2022-10-25 15:46:46.176415'),(24,'twilio','Javascript',NULL,'Node.js helper library','https://github.com/twilio/twilio-node','https://www.twilio.com/docs/libraries/reference/twilio-node/',1,0,0,0,0,0,0,50.25,'fairly_difficult',NULL,NULL,'{\"has_search\": false, \"has_toc\": true, \"links_correct\": true}','2022-11-01 19:09:53.110308'),(25,'Meyda','Javascript',NULL,'Meyda is a JavaScript audio feature extraction library. It works with the Web Audio API (or plain old JavaScript arrays) to expose information about the timbre and perceived qualities of sound. Meyda supports both offline feature extraction as well as real-time feature extraction using the Web Audio API. We wrote a paper about it, which is available here.','https://github.com/meyda/meyda.git','https://meyda.js.org/',1,0,1,0,0,0,0,54.32,'fairly_difficult',NULL,NULL,'{\"has_search\": false, \"has_toc\": false, \"links_correct\": true}','2022-10-26 09:54:16.828136'),(26,'Tensorflow','Python',NULL,'An Open Source Machine Learning Framework for Everyone','https://github.com/tensorflow/docs.git','https://www.tensorflow.org/api_docs/python/tf/all_symbols',0,0,0,0,0,0,0,54.47,'fairly_difficult',NULL,NULL,'{\"has_search\": true, \"has_toc\": true, \"links_correct\": true}','2022-11-01 19:04:21.127063'),(27,'Wikidata','Python',NULL,'This package provides easy APIs to use Wikidata for Python.','https://github.com/dahlia/wikidata.git','https://wikidata.readthedocs.io/en/stable/',1,0,0,0,0,0,0,70.49,'fairly_easy',NULL,NULL,'{\"has_search\": true, \"has_toc\": true, \"links_correct\": true}','2022-10-27 18:55:21.758690'),(28,'Typescript','Javascript',NULL,'TypeScript is a superset of JavaScript that compiles to clean JavaScript output.','https://github.com/microsoft/TypeScript','https://www.typescriptlang.org/docs/',1,0,0,0,0,0,0,47.36,'difficult',NULL,NULL,'{\"has_search\": true, \"has_toc\": true, \"links_correct\": true}','2022-11-01 18:55:48.455958'),(29,'python-socketio','Python',NULL,'Python Socket.IO server and client','https://github.com/miguelgrinberg/python-socketio','https://python-socketio.readthedocs.io/en/latest/',1,1,115,1,25,31,5,47.63,'difficult',NULL,NULL,'{\"has_search\": true, \"has_toc\": true, \"links_correct\": true}','2022-11-07 18:47:46.901848'),(30,'Astro','Javascript',NULL,'Astro is an all-in-one web framework for building fast, content-focused websites.','https://github.com/withastro/docs.git','https://docs.astro.build/en/getting-started/',1,0,0,0,0,0,0,63.79,'standard',NULL,NULL,'{\"has_search\": false, \"has_toc\": true, \"links_correct\": true}','2022-11-07 20:18:29.068970'),(31,'Mockito','Java',NULL,'Most popular Mocking framework for unit tests written in Java','https://github.com/mockito/mockito','https://javadoc.io/doc/org.mockito/mockito-core/latest/org/mockito/Mockito.html',1,0,1239,0,250,0,0,NULL,NULL,NULL,NULL,'{\"has_search\": false, \"has_toc\": true, \"links_correct\": true}','2022-11-08 00:28:28.866761'),(32,'zoo-web-components','Javascript',NULL,'Web-components library.','https://github.com/zooplus/zoo-web-components.git','https://zooplus.github.io/zoo-web-components-docs/index.html',1,0,1,0,0,0,0,53.72,'fairly_difficult',NULL,NULL,'{\"has_search\": false, \"has_toc\": true, \"links_correct\": true}','2022-11-08 08:46:54.036110'),(33,'axios','Javascript',NULL,'Axios is a promise-based HTTP Client for node.js and the browser. It is isomorphic (= it can run in the browser and nodejs with the same codebase). On the server-side it uses the native node.js http module, while on the client (browser) it uses XMLHttpRequests.','https://github.com/axios/axios.git','https://axios-http.com/docs/intro',1,0,3,0,0,0,0,81.86,'easy',NULL,NULL,'{\"has_search\": false, \"has_toc\": true, \"links_correct\": true}','2022-11-08 18:36:48.003209'),(34,'soot','Java',NULL,'Soot - A Java optimization framework','https://github.com/soot-oss/soot','https://www.sable.mcgill.ca/soot/doc/index.html',1,0,23306,0,2177,0,0,64.15,'standard',NULL,NULL,'{\"has_search\": false, \"has_toc\": false, \"links_correct\": false}','2022-11-08 21:26:14.722716'),(35,'React-query','Javascript',NULL,'🤖 Powerful asynchronous state management, server-state utilities and data fetching for the web. TS/JS, React Query, Solid Query, Svelte Query and Vue Query.','https://github.com/tanstack/query','https://tanstack.com/query/v4/docs/overview',1,NULL,NULL,NULL,NULL,NULL,NULL,45.85,'difficult',NULL,NULL,'{\"has_search\": false, \"has_toc\": true, \"has_start\": false, \"links_correct\": true}','2023-01-10 18:33:17.847318'),(36,'Pytorch','Python',NULL,'Tensors and Dynamic neural networks in Python with strong GPU acceleration','https://github.com/pytorch/pytorch.git','https://pytorch.org/docs/stable/index.html',1,0,21,0,6,0,0,41.36,'difficult',NULL,NULL,'{\"has_search\": true, \"has_toc\": true, \"links_correct\": true}','2022-11-14 17:51:12.903002'),(37,'pyppeteer','Python',NULL,'','https://github.com/pyppeteer','https://github.com/pyppeteer/pyppeteer.git',1,NULL,NULL,NULL,NULL,NULL,NULL,62.56,'standard',NULL,NULL,'{\"has_search\": true, \"has_toc\": true, \"links_correct\": true}','2022-11-18 17:49:11.778536'),(38,'scikit-learn','Python',NULL,'                   scikit-learn development and maintenance are financially supported by                 ','https://github.com/scikit-learn/scikit-learn.git','https://scikit-learn.org/stable/index.html',1,0,9,0,3,0,0,61.55,'standard',NULL,NULL,'{\"has_search\": true, \"has_toc\": true, \"links_correct\": true}','2022-11-18 22:07:59.619527'),(39,'GraphQL compiler','Python',NULL,'To use GraphQL compiler the first thing one needs to do is to generate the schema info from the underlying database as in the example below. Even though the example targets an OrientDB database, it is meant as a generic schema info generation example. See the homepage of your target database for more instructions on how to generate the necessary schema info.','https://github.com/kensho-technologies/graphql-compiler','https://graphql-compiler.readthedocs.io/',1,0,4,0,1,0,0,42.39,'difficult',NULL,NULL,'{\"has_search\": true, \"has_toc\": true, \"links_correct\": true}','2022-11-19 05:23:58.168383'),(40,'Flask','Python',NULL,'The Python micro framework for building web applications.','https://github.com/pallets/flask','https://flask.palletsprojects.com/en/2.2.x/',1,1,302,1,44,94,8,59.76,'fairly_difficult',NULL,NULL,'{\"has_search\": true, \"has_toc\": true, \"links_correct\": true}','2022-11-21 12:55:09.532920'),(41,'pytest','Python',NULL,'The pytest framework makes it easy to write small tests, yet scales to support complex functional testing','https://github.com/pytest-dev/pytest/','https://docs.pytest.org/en/7.2.x/',1,NULL,NULL,NULL,NULL,NULL,NULL,41.43,'difficult',NULL,NULL,'{\"has_search\": true, \"has_toc\": true, \"has_start\": false, \"links_correct\": true}','2022-11-25 14:04:44.250499'),(42,'pandas','Python',NULL,'pandas is an open source, BSD-licensed library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language.','https://github.com/pandas-dev/pandas','https://pandas.pydata.org/docs/',1,0,4473,0,467,0,0,40.34,'difficult',NULL,NULL,'{\"has_search\": true, \"has_toc\": true, \"has_start\": true, \"links_correct\": true}','2023-02-09 08:38:02.492815');
/*!40000 ALTER TABLE `overview_library` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `overview_response`
--

DROP TABLE IF EXISTS `overview_response`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!50503 SET character_set_client = utf8mb4 */;
CREATE TABLE `overview_response` (
  `id` bigint NOT NULL AUTO_INCREMENT,
  `session_key` varchar(64) NOT NULL,
  `library_name` varchar(100) NOT NULL,
  `years_experience` int unsigned DEFAULT NULL,
  `familiar` tinyint(1) DEFAULT NULL,
  `general_rating` varchar(100) DEFAULT NULL,
  `task_list` varchar(100) DEFAULT NULL,
  `code_examples_methods` varchar(100) DEFAULT NULL,
  `code_examples_classes` varchar(100) DEFAULT NULL,
  `text_readability` varchar(100) DEFAULT NULL,
  `code_readability` varchar(100) DEFAULT NULL,
  `consistency` varchar(100) DEFAULT NULL,
  `navigability` varchar(100) DEFAULT NULL,
  `usefulness` varchar(100) DEFAULT NULL,
  `where_see` varchar(100) DEFAULT NULL,
  `matching` varchar(100) DEFAULT NULL,
  `general_feedback` varchar(500) DEFAULT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `unique_session_library_combination` (`session_key`,`library_name`),
  CONSTRAINT `overview_response_chk_1` CHECK ((`years_experience` >= 0))
) ENGINE=InnoDB AUTO_INCREMENT=183 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `overview_response`
--

LOCK TABLES `overview_response` WRITE;
/*!40000 ALTER TABLE `overview_response` DISABLE KEYS */;
INSERT INTO `overview_response` VALUES (1,'bqhhtq06a7rgijwdrdylt3ls0aaytwcy','GitPython',4,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(2,'ppdvs47kv6n4gszdnrn5eaoqeilfr494','orjson',2,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(3,'b3lyejd5a90q52unjdldmgzthkcavi57','GitPython',10,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(4,'e89uyeo1tp99qdo26ro3u8h7sxtl0hx0','Requests',15,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(5,'km8qrcu63rsml0b717rnvhal6z25q5vi','NLTK',0,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(6,'g0lg1oav4ush6p56c4rk3kizm9y1oxf8','Requests',12,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(7,'ufp5ludc7w9fd94sie1wse5761lt2ux5','Bpmn-visualization',12,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(8,'fp6qrhsy2m3g9npaw56tx7y5quo5iuyx','orjson',6,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(9,'fp6qrhsy2m3g9npaw56tx7y5quo5iuyx','CoreNLP',6,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(10,'fp6qrhsy2m3g9npaw56tx7y5quo5iuyx','netty',6,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(11,'fp6qrhsy2m3g9npaw56tx7y5quo5iuyx','memfs',6,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(12,'3imxyv49vuf5xywhzqai65qtshbwlhov','GitPython',5,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(13,'wo8z7r4b542idku3gorlvq2z40dijebw','orjson',10,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(14,'2sl7zhl1cpiuzpaqxsti1xwcjz5hbq6c','orjson',3,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(15,'hevprqwjqt683fns27nezrctscjwxxrq','orjson',5,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(16,'aool7k0a6zknt79vd9juu7aywyz0csl1','Ivy',40,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(17,'6tdipjz7ael3a8aa2ok3kf3fo7jq3e2m','NLTK',5,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(18,'w7katoxghlvqavj42f4u9e5kofec749f','Bpmn-visualization',4,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(19,'xpbd7vsx61j2kuii8i34hmskomqugw90','Numba',15,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(20,'f7hxlx3b3xm3n8wlwizo6qbhrh8erpib','Requests',8,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(21,'4tyxkls58920lty14iv82758estafgd0','Ivy',0,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(22,'79m7qolpxes6gx99ousjucx40u8b6182','Ivy',5,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(23,'c0j6fae5m3fidvte9np5s1hlqqs6jtdx','Ivy',20,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(24,'c7oalpwsv3kizwda7xsdwjjiefd2ckv7','scanpy',8,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(25,'xsgwawvmsl0i94sxidbfrebz8qc7moy8','jQuery',30,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(26,'5bj5kdjzjlkuc80p5cl875ukwfx4ecy0','Ivy',10,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(27,'g2rqyqdw7sh5y9gp9kbui9nti7020ro3','Ivy',10,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(28,'j9heqeafrnebnqn00dyt2r7n4b2m8zha','jQuery',20,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(29,'lurz1f1t96eept36m9tbjsqzpxnazi2x','orjson',7,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(30,'35itjweymf3u7uwsmyvwjm2xwz9o1lvb','numpy',23,1,'2','1','1','3','4','3','3','4','1','None','1','numpy\'s documentation is large. It\'s possible that your crawling just didn\'t find relevant portions. There is no way for me to tell from the summary what your crawler actually saw.\r\nThere does not seem to be any relationship between the overall star summary (4/5) and the individual quality metrics (mostly 0/5).'),(31,'9cc2xb4larwcbv7jint7uwyimj7aug3t','scanpy',4,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(32,'dflrtlqmdcw8i61y4uvd8tny4drj3z7f','scanpy',6,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(33,'3vcia1pfmnc7svoynz4oza4xih44fuus','PyOpenGL',40,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(34,'vwk1qtxh9ohuablkefrzcmlc8c6s6atc','pyAFQ',11,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(35,'zrd7w1f9dc3epua2ullphx94662iya38','Requests',15,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(36,'j0sku2yxa17dxxeijvbl3e4jp758wuc6','ibis-project',0,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(37,'xsuu6vu67aeqk3mvsy8t0we8qgq95xgz','scanpy',5,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(38,'ethay63h9oe7muwcm0nsbkqvku9x7adv','scanpy',5,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(39,'5z9yvhf8ciwjxxaka9pttnyudkq2zu2v','orjson',1,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(40,'zuafd92w6ujg3dvrc7cdz93r84up9jwm','Ivy',2,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(41,'c8tcx4wjzxc25cs7tid07hpd1hynssir','numpy',100,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(42,'t064vi9gicadcync3h422dfr1238gmef','numpy',25,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(43,'t064vi9gicadcync3h422dfr1238gmef','rcdesign',25,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(44,'g3r2g54tb7lid96mqo059vwuxqks65w6','numpy',4,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(45,'ripj7ub7c68jsd7u5qmf23dppgia8uya','Ivy',22,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(46,'zo3hew7xqyvw1d61chzdlkr12qusul94','orjson',18,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(47,'5rjmiitmq5q7vapws15g2srjie4mjvcy','Ivy',0,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(48,'ripj7ub7c68jsd7u5qmf23dppgia8uya','jQuery',22,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(49,'7rvbdanqp1om5p7g1lzy5dasbhbl7xyu','GitPython',0,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(50,'viv74m16eyyakhonebz6044rfvemx14h','ibis-project',0,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(51,'chpgy8idu7jurwyzpjsnmszhjq6b7xix','orjson',18,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(52,'0ocbdl0w7df6tfsc4ygkus1q9rjepts1','orjson',3,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(53,'5tfu21izmytxukoqy9auw68ly5q22axv','numpy',10,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(54,'e28x2ev6r8ndnd7ct1q3701hiknastq9','React',20,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(55,'nltjf523al86z4tmmajzg2xxq8b7xn4j','Ivy',10,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(56,'g3dvly15jflbtzjvvyz1eduwj44bpu9d','Ivy',30,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(57,'xjgbq8ocu6ooc8orl7qfttochavajkpf','numpy',3,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(58,'rasbv5okxr34t6gvkav8aupjgxv7bs78','numpy',4,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(59,'rasbv5okxr34t6gvkav8aupjgxv7bs78','Ivy',3,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(60,'rasbv5okxr34t6gvkav8aupjgxv7bs78','orjson',2,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(61,'4ga84340ch77qq0zte3ft6g5wyrlwsz0','JSON-java',16,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(62,'8l23li55mjx2kxeuihm35sbi4c8wmh1b','scanpy',4,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(63,'2nr01w9ob1zs6tr5cisa27rqz0qrv99y','numpy',2,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(64,'2nr01w9ob1zs6tr5cisa27rqz0qrv99y','NLTK',2,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(65,'2nr01w9ob1zs6tr5cisa27rqz0qrv99y','React',2,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(66,'2nr01w9ob1zs6tr5cisa27rqz0qrv99y','orjson',3,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(67,'2nr01w9ob1zs6tr5cisa27rqz0qrv99y','scanpy',2,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(68,'2nr01w9ob1zs6tr5cisa27rqz0qrv99y','jQuery',2,0,'4','5','4','4','4','2','2','5','4','package_manager',NULL,'Since jQuery is a popular package, documenting some security practices/well-known issues might be helpful too. I am not sure how feasible this is, though.'),(69,'zhfswu6l8lil7sszofkpo22pbl54emx0','twilio',10,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(70,'0mkmtlwmdxman0uvyyzp9lul6ns77nrf','PyOpenGL',40,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(71,'spz7zr7ygxbr54of811r2z4yiluiim4a','orjson',1,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(72,'pdogwt9h40nen4cx142pk9lsu1x5cs2n','twilio',11,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(73,'pdogwt9h40nen4cx142pk9lsu1x5cs2n','Meyda',11,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(74,'9evc6jyjy3dpsvjpw63nrvhrv6n5w7mt','NLTK',2,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(75,'9evc6jyjy3dpsvjpw63nrvhrv6n5w7mt','Tensorflow',2,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(76,'1bo6bkzr1d5bec48l8winsxd180jv387','NLTK',5,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(77,'mifyal8jgh777krs7washvsrkuleho8t','Meyda',11,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(78,'thuw5yjur211imskbe1lvy60892dhn04','React',3,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(79,'gvlg3ee5772qoer2j512iqc9nh0vrg7z','orjson',5,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(80,'gvlg3ee5772qoer2j512iqc9nh0vrg7z','Typescript',5,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(81,'pli0u67ti04pscktnzlgifom6aii0552','orjson',23,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(82,'l7r9nejouaprzsaeizvf65hpt1pntv9b','numpy',13,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(83,'e9c1wdsteasedzov3l3j0xrsf3lpkvnq','Typescript',0,1,'4','4','4','4','4','4','4','4','3','readme','4',NULL),(84,'ia0wwi9y0yyq0atp4y1otmptxhorlign','jQuery',1000,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(85,'i6sudelzamjbt5k213xcr4cgtz1rechw','jQuery',5,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(86,'wzsdnz1s15qy8wucf3beho3dx8jalkiv','orjson',2,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(87,'rnlws9e0hfsvhl1fvbwb751orfiyjy05','twilio',10,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(88,'7pydn5qq8au0qew8975ugusm02j477kd','React',6,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(89,'ruxilks1ugyp5pa6xos2kljhn237htly','netty',5,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(90,'bttzlviofjb63fe0cv40yu7z84q14hew','jBinary',25,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(91,'4uy3nm1jv8q0cldfm89euxig51ob6n3a','twilio',3,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(92,'te54suy84afax90wcz8zk0jsxkr32l9e','JSON-java',7,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(93,'kax8x5zs47tqinuxckehu7y9bquoexqn','twilio',4,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(94,'gob9uagk8srvxa44hjuelyvd3txx66kk','Numba',1,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(95,'wtxrr0f6e5ucven8t2ulh22pfrfj8iwz','numpy',7,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(96,'yij8zqp3h9lzg3zfl46geyo6vgjwyj2n','twilio',20,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(97,'lrbnx7ypi9g47govaefse3o8ntw5hro6','python-socketio',30,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(98,'3zzjr64s7djq33d5k1uf3dml2jxgl5ol','requests',6,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(99,'vkh2yzqtujcmm67xumn4c3y2vu7nqsoe','numpy',1,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(100,'hs5pc27s5zn8e3tk7c8fqgh5ayism6vo','twilio',20,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(101,'knqsgp8pvfagrrek3c4s3xj4jnil7ikx','twilio',8,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(102,'vrti08ht6qsyga4w2i0es4q5jtv8o30f','React',3,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(103,'gxahtcyqp741xoyg8vcbowa8e9kcc2qm','orjson',5,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(104,'81jkz0fby88qyyqjv0e8os1mumxnmakf','numpy',3,1,'5','4','4','4','5','4','3','3','5','readme','4',NULL),(105,'5f9ouv72rwb8xw1aihw8r2cb90j2vkdv','twilio',30,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(106,'i6bng41sb6z5a2ug4boak0vro0tw6rg8','Mockito',22,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(107,'3w49yz9kapgq34kzftr8qq1gmcogth7d','twilio',9,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(108,'0rdntkjh9ciwltb2t8c5lo9mq05pzl6y','zoo-web-components',8,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(109,'9zmwljgjrt8nt1mi0ttg8sk64ska7d1s','Mockito',6,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,'1','readme','4',NULL),(110,'dyv1p3tzifi1by3ve4ye67wd1u9oy75j','axios',10,1,'3','3','3','3','3','3','1','3','1','None','1','Doesn\'t seem to have discovered anything other than installation instructions'),(111,'6hqg2hg4ae7zizm44smsislauct79xj2','orjson',6,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(112,'iwo5w4ywdxwm6ih4z3d0ub5om2rbpnxe','orjson',8,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(113,'iwo5w4ywdxwm6ih4z3d0ub5om2rbpnxe','requests',8,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(114,'iwo5w4ywdxwm6ih4z3d0ub5om2rbpnxe','jQuery',8,1,'4','4','1','1','5','5','1','5','5','Both readme and package manager page',NULL,NULL),(115,'iwo5w4ywdxwm6ih4z3d0ub5om2rbpnxe','Typescript',8,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(116,'znia3481w6iwzj01yc5duiqe3xllqdy4','numpy',4,1,'4','4','3','3','5','3','3','5','4','readme','4','I don\'t know whether I am interested in methods examples and class examples (at least for Python).'),(119,'znia3481w6iwzj01yc5duiqe3xllqdy4','NLTK',2,1,'4','4','4','4','3','1','4','5','3','readme','4',NULL),(120,'0ya0a675oqthpmleng3z9fct5l1gciar','requests',2,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(121,'i16fgzwgytlcnntlc0jqs02rzarpia7r','react-query',12,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(122,'d3njj2391vkq5ed0hcc9xotazwket4bo','numpy',3,1,'4','4','5','5','4','5','5','5','4','readme','2',NULL),(123,'n3b9mdkledz2nzhbz82urx5g57pasv0t','numpy',2,1,'4','4','5','5','4','5','4','3','5','readme','4',NULL),(124,'t8r2s4fhilpd0ai8v17pybe1t9fciy8b','twilio',25,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(125,'4yo374bfnxm2as4l9020yvuu1cn22dx8','Tensorflow',4,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(126,'4yo374bfnxm2as4l9020yvuu1cn22dx8','Pytorch',4,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(127,'4yo374bfnxm2as4l9020yvuu1cn22dx8','numpy',2,1,'5','4','4','4','5','4','4','2','4','readme','3','It feels like some of the sections should have much higher important or scores than they do. It is not clear why readability of code examples is crossed out.'),(128,'1cpv1spnavuhw26voa5vatgvgnjxf9in','React',2,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(129,'1cpv1spnavuhw26voa5vatgvgnjxf9in','numpy',4,1,'5','4','4','3','5','5','5','5','4','package_manager','5',NULL),(130,'1cpv1spnavuhw26voa5vatgvgnjxf9in','Tensorflow',4,1,'4','4','4','3','5','5','5','5','4','package_manager','5',NULL),(131,'mydl197mcss0jok602gp4ldlhsrii4qp','orjson',10,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(132,'e2k0vtl5t8w0oi4ssenme9a0bo51nu35','React',4,1,'4','4','5','5','4','5','2','5','2','package_manager','2',NULL),(133,'jggj6d98g35s3herlv3oqs5d5ixrrgv3','numpy',5,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(134,'ln0dmq7cyu4p67dka179fctrlakangd1','React',4,1,'5','5','4','4','5','5','5','5','5','readme','5',NULL),(135,'ryz9qo7lctczknsse9uwq2r6gmhahkhh','numpy',1,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(136,'owh1koq1br45ciuczqjsjgkixu5lh3pe','React',9,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(137,'aetuwu7ph3fktiwjn63chsba3996ztuy','orjson',0,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(138,'22s26kqkauu472gr7wrge8hf95aj3gof','NLTK',4,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(139,'eajby9qahsj48kwswxl9kz3t7l02ztvl','React',3,1,'4','1','5','5','5','5','3','4','5','package_manager','2','My experience with React\'s documentation has been overall pleasant. While I agree with the navigation rating, I disagree with the documentation quality metric for \"Readability of text\" and \"Readability of code examples\" - I think the text and code examples are very easy to understand and easy to read.'),(140,'2gwp6erpcm6tl6oxe57egbbs3zc2gd1u','Typescript',8,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(141,'zgxyx3tazwi1xfaat6m9srtlh9vwyqfo','requests',15,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(142,'7s2921tjo988ea0uquz8krc00ztwcpq7','Pytorch',5,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(143,'7cuvwi9smvam4jb3q8wcbs2zips8u6pq','pyppeteer',2,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(144,'p7rkx9lg518fad8ziclwfn0f4zdq4cgm','pyppeteer',1,1,'2','2','5','4','4','5','5','2','3','readme','2',NULL),(145,'tccpklnzpw8lto91f8hikzaxqdnq3ugg','Mockito',5,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(146,'d2cmszmgsprwayng3f5x6tp0nmd3i2ct','scikit-learn',6,1,'3','4','5','4','3','4','4','4','4','package_manager','2','More difficult to properly assess the documentation quality given that the link for official documentation is more of a map for relevant documentation of methods rather than an all-encompassing page.'),(147,'d2cmszmgsprwayng3f5x6tp0nmd3i2ct','numpy',6,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(148,'qjkfbswvl0irmqmos74dmf5nkd75n0dv','soot',36,1,'4','2','4','4','4','4','4','4','4','readme','5',NULL),(149,'fbt858dedcht9by3mifau7iiocf468am','testrun',10,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(150,'5r4ylonz9dikkvs5a7d0e1iilspn6v6m','jQuery',12,1,'4','2','4','4','2','2','1','2','4','readme','1','I find it difficult to understand how the metrics are actually populated: what data are they based on? How were they calculated? Based on what data? Which version of jQuery? jQuery is a very bizarre library, since most the functionality is exposed on the $(selector) object. How are code examples extracted?\r\n\r\nI just find it difficult to draw a conclusion from jQuery\'s documentation to these metrics.'),(151,'5r4ylonz9dikkvs5a7d0e1iilspn6v6m','Flask',12,1,'2','3','2','2','2','2','2','4','4','readme','2','The Flask project starts with a tutorial that teaches you how to use it from the start up. This is a good documentation, and it is unclear how these metrics account for solid tutorials. That said, it\'s sometimes difficult to find Flask API methods and types. These metrics do not reflect many of the practical considerations of Flask\'s documentation quality.'),(152,'5r4ylonz9dikkvs5a7d0e1iilspn6v6m','JSON-java',12,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(153,'5r4ylonz9dikkvs5a7d0e1iilspn6v6m','CoreNLP',12,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(154,'ap2wn4dwehshb098l5vdjfcdmysw1loa','react-query',10,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(155,'3imvdn7kxvoqldq8ano5l6c1kfhkvpme','scikit-learn',15,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(156,'zc4jooq0j0fes3howcswd5mg3unrnim6','orjson',4,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(157,'zc4jooq0j0fes3howcswd5mg3unrnim6','requests',4,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(158,'zc4jooq0j0fes3howcswd5mg3unrnim6','Mockito',4,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(159,'zc4jooq0j0fes3howcswd5mg3unrnim6','soot',4,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(160,'zc4jooq0j0fes3howcswd5mg3unrnim6','React',4,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(161,'b671lwz4pbsjhcrveym50vz6slvk0fcn','Typescript',4,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(162,'sfulpjgrbxgu4enoyucykrn5og47x95m','requests',10,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(163,'sfulpjgrbxgu4enoyucykrn5og47x95m','Typescript',10,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(164,'9cgsyftwal22z7je6vfux9exdc8hfps8','requests',1,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(165,'sfulpjgrbxgu4enoyucykrn5og47x95m','pytest',10,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(166,'sw7f2cgu8zlrmnynqfldfuwuk9gko6ch','numpy',3,1,'2','2','2','2','2','2','1','2','2','readme','1','Most of the documentation quality metrics are 0 star, which seems pretty strange and inaccurate to me. The documented library tasks section also seems quite limited and I feel a google search would be more effective.'),(167,'sw7f2cgu8zlrmnynqfldfuwuk9gko6ch','pytest',3,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(168,'hzgw50xg17yrxlasbbqrx2h8d67u30tv','React',3,0,'5','2','5','5','3','4','3','2','4','readme',NULL,NULL),(169,'hzgw50xg17yrxlasbbqrx2h8d67u30tv','numpy',3,0,'4','5','5','5','2','5','4','1','4','readme',NULL,NULL),(170,'0xq9lkjnur4i59lekyqccdbaw365kmdg','JSON-java',3,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(171,'vb3d8pxid37izghrk60b9fpufalp4q6u','numpy',NULL,NULL,'4','5','5','4','4','4','4','4','5','readme',NULL,NULL),(172,'tys67a58krqhgfw6oadq8lbf5uq01lfn','JSON-java',1,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(173,'bxev19qq07htoobqcnchuq6hpauo4s4w','requests',1,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(174,'2cqcltzgqlyeis2hht41mwg2td9mk03m','requests',2,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(175,'r833esheg5hdwim6v4migrpepszpkxlh','numpy',1,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(176,'6om7pp544hfuxanncoute12au6doqzow','Pytorch',300000000,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(177,'6om7pp544hfuxanncoute12au6doqzow','requests',1,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(178,'6om7pp544hfuxanncoute12au6doqzow','pandas',3,1,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(179,'6om7pp544hfuxanncoute12au6doqzow','numpy',1,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(180,'6b4hxm1ij4ygjjag2gt2afk5408gobu5','orjson',5,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(181,'xpjw7nb91ugmh78ddia8orzjr123c7zz','NLTK',0,0,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL),(182,'tmongpzztdm7ss0cqf4j8up8s3nx9y37','orjson',NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,'None',NULL,NULL);
/*!40000 ALTER TABLE `overview_response` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `overview_task`
--

DROP TABLE IF EXISTS `overview_task`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!50503 SET character_set_client = utf8mb4 */;
CREATE TABLE `overview_task` (
  `id` bigint NOT NULL AUTO_INCREMENT,
  `library_name` varchar(50) NOT NULL,
  `paragraph` varchar(5000) NOT NULL,
  `task` varchar(100) NOT NULL,
  `has_example` tinyint(1) NOT NULL,
  `example_page` varchar(100) NOT NULL,
  `html_id` varchar(500) NOT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=14014 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `overview_task`
--

LOCK TABLES `overview_task` WRITE;
/*!40000 ALTER TABLE `overview_task` DISABLE KEYS */;
INSERT INTO `overview_task` VALUES (1,'React','React has been designed from the start for gradual adoption, and you can use as little or as much React as you need. Whether you want to get a taste of React, add some interactivity to a simple HTML page, or start a complex React-powered app, the links in this section will help you get started.','design react from start',0,'',''),(2,'React','React has been designed from the start for gradual adoption, and you can use as little or as much React as you need. Whether you want to get a taste of React, add some interactivity to a simple HTML page, or start a complex React-powered app, the links in this section will help you get started.','get taste of react',0,'',''),(3,'React','If you prefer to use your own text editor, you can also download this HTML file, edit it, and open it from the local filesystem in your browser. It does a slow runtime code transformation, so we’d only recommend using this for simple demos.','download HTML file',0,'',''),(4,'React','If you prefer to use your own text editor, you can also download this HTML file, edit it, and open it from the local filesystem in your browser. It does a slow runtime code transformation, so we’d only recommend using this for simple demos.','open  from local filesystem',0,'',''),(5,'React','You can add React to an HTML page in one minute. You can then either gradually expand its presence, or keep it contained to a few dynamic widgets.','expand presence',0,'',''),(6,'React','Like any unfamiliar technology, React does have a learning curve. With practice and some patience, you will get the hang of it.','get hang with practice',0,'',''),(7,'React','Like any unfamiliar technology, React does have a learning curve. With practice and some patience, you will get the hang of it.','get hang with patience',0,'',''),(8,'React','We recommend going through this JavaScript overview to check your knowledge level. It will take you between 30 minutes and an hour but you will feel more confident learning React.','check knowledge level',0,'',''),(9,'React','Whenever you get confused by something in JavaScript, MDN and javascript.info are great websites to check. There are also community support forums where you can ask for help.','ask community support forums for help',0,'',''),(10,'React','Many React users credit reading Thinking in React as the moment React finally “clicked” for them. It’s probably the oldest React walkthrough but it’s still just as relevant.','read thinking as moment React',0,'',''),(11,'React','Many React users credit reading Thinking in React as the moment React finally “clicked” for them. It’s probably the oldest React walkthrough but it’s still just as relevant.','read thinking in React',0,'',''),(12,'React','Once you’re comfortable with the main concepts and played with React a little bit, you might be interested in more advanced topics. This section will introduce you to the powerful, but less commonly used React features like context and refs.','play  with React',0,'',''),(13,'React','This documentation section is useful when you want to learn more details about a particular React API. For example, React.Component API reference can provide you with details on how setState() works, and what different lifecycle methods are useful for.','provide  with details',0,'',''),(14,'React','You can also follow the @reactjs account on Twitter, but you won’t miss anything essential if you only read the blog.','read blog',0,'',''),(15,'JSON-java','Should the documentation be updated?\nYes - check the FAQ','check FAQ',0,'',''),(16,'JSON-java','Does it break the unit tests?\nN/A','break unit tests',0,'',''),(17,'JSON-java','Was any code refactored in this commit?\nN/A','refactor code in commit',0,'',''),(18,'JSON-java','This feature was requested some time ago on #593, there are now methods that allow users to pass an indentFactorto the toString methods in the XML class and this will return a Pretty Printer XML String with spaces based on indentFactor.','pass indentFactor to toString methods',1,'https://github.com/stleary/JSON-java/pull/694',''),(19,'JSON-java','This feature was requested some time ago on #593, there are now methods that allow users to pass an indentFactorto the toString methods in the XML class and this will return a Pretty Printer XML String with spaces based on indentFactor.','request feature',1,'https://github.com/stleary/JSON-java/pull/694',''),(20,'JSON-java','This feature was requested some time ago on #593, there are now methods that allow users to pass an indentFactorto the toString methods in the XML class and this will return a Pretty Printer XML String with spaces based on indentFactor.','return feature',1,'https://github.com/stleary/JSON-java/pull/694',''),(21,'JSON-java','You can currently call toString three different ways so I thought three new public methods that can also take an indent factor were appropriate.','call different ways',1,'https://github.com/stleary/JSON-java/pull/694',''),(22,'JSON-java','Point 3: I have altered test three to use the resource, I was aware it was very long so very happy to make that change.','use resource',0,'',''),(23,'JSON-java','@DeaneOC Thanks for the update. Yes, please add Javadocs to all new methods, not just the public ones.','add Javadocs to new methods',0,'',''),(24,'JSON-java','Changes look good, but one of the new unit tests is failing when run from a Windows box:\norg.json.junit.XMLTest > testIndentComplicatedJsonObjectWithArrayAndWithConfig FAILED org.junit.ComparisonFailure at XMLTest.java:1235','run  from Windows box',0,'',''),(25,'JSON-java','Changes look good, but one of the new unit tests is failing when run from a Windows box: org.json.junit.XMLTest > testIndentComplicatedJsonObjectWithArrayAndWithConfig FAILED org.junit.ComparisonFailure at XMLTest.java:1235','run  from Windows box',0,'',''),(26,'JSON-java','What problem does this code solve?\nAdd support for XML pretty print','add support for XML pretty print',0,'',''),(27,'JSON-java','Does it break the unit tests?\nNo. Unit tests were added.','break unit tests',0,'',''),(28,'JSON-java','Does it break the unit tests?\nNo. Unit tests were added.','add unit tests',0,'',''),(29,'JSON-java','Was any code refactored in this commit?\nNo','refactor code in commit',0,'',''),(30,'JSON-java','There was a problem hiding this comment.','hide comment',0,'',''),(31,'JSON-java','The test fails at JSONPointerTest.queryByEmptyKeySubObject:75 with a comparison error while comparing an expected string and the result from org.json.junit.JSONPointerTest.query function after converting it into String. The toString function of the Object class makes no guarantees as to the iteration order of the attributes in the object. This makes the test outcome non-deterministic and the test fails whenever the toString changes the order of the properties. To fix this, the expected and actual values should be checked in a more deterministic way so that the assertions do not fail.','convert  into string',0,'',''),(32,'JSON-java','The test fails at JSONPointerTest.queryByEmptyKeySubObject:75 with a comparison error while comparing an expected string and the result from org.json.junit.JSONPointerTest.query function after converting it into String. The toString function of the Object class makes no guarantees as to the iteration order of the attributes in the object. This makes the test outcome non-deterministic and the test fails whenever the toString changes the order of the properties. To fix this, the expected and actual values should be checked in a more deterministic way so that the assertions do not fail.','check expected actual values in deterministic way',0,'',''),(33,'JSON-java','Expected and Actual values can be converted into JSONObject and the similar can be used to compare these objects. As this function compares the values inside the JSONObjects without needing order, the test becomes deterministic and ensures that the flakiness from the test is removed.','convert expected Actual values into JSONObject',0,'',''),(34,'JSON-java','What problem does this code solve?\nFixes a unit test that is broken when running with Nondex','fix unit test',0,'',''),(35,'JSON-java','What problem does this code solve?\nFixes a unit test that is broken when running with Nondex','break unit test',0,'',''),(36,'JSON-java','Does it break the unit tests?\nNo','break unit tests',0,'',''),(37,'JSON-java','If you discover an issue you would like to work on, you can add a new issue to the list. If it meets our criteria, a hacktoberfest label will be added.','add new issue to list',0,'',''),(38,'JSON-java','If you discover an issue you would like to work on, you can add a new issue to the list. If it meets our criteria, a hacktoberfest label will be added.','add hacktoberfest label',0,'',''),(39,'JSON-java','My change fixes a bug. Why won\'t you accept it?','fix bug',0,'',''),(40,'JSON-java','I want to add an external lib to the project','add external lib to project',0,'',''),(41,'JSON-java','Anyone can submit pull requests. Please read the rest of this FAQ page for guidelines about what kinds of changes are being accepted.','read rest of FAQ page',0,'',''),(42,'JSON-java','If you think you have found a vulnerability - a weakness in the code that could be subject to attack - please open a public issue in the repository. This allows the entire community to understand the scope and come up with the best way to address the problem.','find vulnerability',0,'',''),(43,'JSON-java','When this app was first written, there was not a single universally agreed upon build tool. This still seems to be the case. Periodically, Maven Repository releases are built and distributed here: http://mvnrepository.com/artifact/org.json/json','write app',0,'',''),(44,'JSON-java','To build this project you can simply run javac *.java. If you want to make your own JAR file for redistribution, you can execute the following commands from the project directory:','execute following commands from project directory',0,'',''),(45,'JSON-java','Support for ordering is one of the most popular requests, along with adding some type of build support. However, from the JSON spec RFC 8259: \"An object is an unordered collection of zero or more name/value pairs\".  As a reference app, the design is required to stay as close to the spec as possible, so ordering in JSONObjects is not supported.','add type',0,'',''),(46,'JSON-java','Support for ordering is one of the most popular requests, along with adding some type of build support. However, from the JSON spec RFC 8259: \"An object is an unordered collection of zero or more name/value pairs\".  As a reference app, the design is required to stay as close to the spec as possible, so ordering in JSONObjects is not supported.','order  in JSONObjects',0,'',''),(47,'JSON-java','The unit tests can be found in https://github.com/stleary/JSON-Java-unit-test, along with instructions for combining the tests with this app. They are not included in the project for the sake of developers who just want the library code and nothing more. It is not expected that this will ever change. Instructions to quickly and easily clone the 2 projects and execute the tests are included in the unit test project.','combine tests with app',0,'',''),(48,'JSON-java','The unit tests can be found in https://github.com/stleary/JSON-Java-unit-test, along with instructions for combining the tests with this app. They are not included in the project for the sake of developers who just want the library code and nothing more. It is not expected that this will ever change. Instructions to quickly and easily clone the 2 projects and execute the tests are included in the unit test project.','find unit tests along_with instructions',0,'',''),(49,'JSON-java','The unit tests can be found in https://github.com/stleary/JSON-Java-unit-test, along with instructions for combining the tests with this app. They are not included in the project for the sake of developers who just want the library code and nothing more. It is not expected that this will ever change. Instructions to quickly and easily clone the 2 projects and execute the tests are included in the unit test project.','find unit tests in https://github.com/stleary/JSON-Java-unit-test',0,'',''),(50,'JSON-java','The unit tests can be found in https://github.com/stleary/JSON-Java-unit-test, along with instructions for combining the tests with this app. They are not included in the project for the sake of developers who just want the library code and nothing more. It is not expected that this will ever change. Instructions to quickly and easily clone the 2 projects and execute the tests are included in the unit test project.','clone projects',0,'',''),(51,'JSON-java','The unit tests can be found in https://github.com/stleary/JSON-Java-unit-test, along with instructions for combining the tests with this app. They are not included in the project for the sake of developers who just want the library code and nothing more. It is not expected that this will ever change. Instructions to quickly and easily clone the 2 projects and execute the tests are included in the unit test project.','execute tests',0,'',''),(52,'JSON-java','Per design, the JSONObject and JSONArray constructors are more forgiving than required by the spec. However, the toString() methods produce text that is strictly conforming. For example, some strings do not need to be surrounded by quotes when creating a JSONObject, but those strings will be surrounded by quotes when emitted from toString(). This behavior appears to have been part of the lib from the start, and will not be changed. More information about what is allowed can be found in the class-level comments for JSONObject and JSONArray.','produce text',0,'',''),(53,'JSON-java','Per design, the JSONObject and JSONArray constructors are more forgiving than required by the spec. However, the toString() methods produce text that is strictly conforming. For example, some strings do not need to be surrounded by quotes when creating a JSONObject, but those strings will be surrounded by quotes when emitted from toString(). This behavior appears to have been part of the lib from the start, and will not be changed. More information about what is allowed can be found in the class-level comments for JSONObject and JSONArray.','surround strings',0,'',''),(54,'JSON-java','Per design, the JSONObject and JSONArray constructors are more forgiving than required by the spec. However, the toString() methods produce text that is strictly conforming. For example, some strings do not need to be surrounded by quotes when creating a JSONObject, but those strings will be surrounded by quotes when emitted from toString(). This behavior appears to have been part of the lib from the start, and will not be changed. More information about what is allowed can be found in the class-level comments for JSONObject and JSONArray.','find more information in class-level comments',0,'',''),(55,'JSON-java','It can be found on maven central. You can download the release version you like from here or here','find  on maven central',0,'',''),(56,'JSON-java','It can be found on maven central. You can download the release version you like from here or here','download release version',0,'',''),(57,'JSON-java','The most common reason for not accepting a valid bug fix is when it will result in a change\nto the API or behavior of the code. We want to fix as many bugs as possible, but we also\ndon\'t want existing users\' code to break just because they upgraded to a newer version of\nthe library. Changes to existing behavior will only be accepted in the case of bugs\nwhere the existing behavior is clearly worse than the fix.','fix  as many bugs possible',0,'',''),(58,'JSON-java','One of the strengths of this library is that it has no external dependencies, making it easy\nto include in a project, or on a limited resource platform. There are no plans now, and none\nare expected in the future, to introduce 3rd party libraries.','introduce 3rd party libraries',0,'',''),(59,'JSON-java','The library author specified this license, and is the only person authorized to change it.','specify license',0,'',''),(60,'JSON-java','If you are considering changing the API, the best place to start is to look at what changes have been accepted in the past. As a rule, we maintain 100% backwards compatibility. Since the project reached maturity, only one public API method has been removed, and that was probably an oversight. Occasionally an argument can be made for adding a new API, or adding capabilities to an existing API.','reach maturity',0,'',''),(61,'JSON-java','If you are considering changing the API, the best place to start is to look at what changes have been accepted in the past. As a rule, we maintain 100% backwards compatibility. Since the project reached maturity, only one public API method has been removed, and that was probably an oversight. Occasionally an argument can be made for adding a new API, or adding capabilities to an existing API.','add new API',0,'',''),(62,'JSON-java','If you are considering changing the API, the best place to start is to look at what changes have been accepted in the past. As a rule, we maintain 100% backwards compatibility. Since the project reached maturity, only one public API method has been removed, and that was probably an oversight. Occasionally an argument can be made for adding a new API, or adding capabilities to an existing API.','add capabilities to existing API',0,'',''),(63,'JSON-java','Support for the following types has been added:','add support for following types',0,'',''),(64,'JSON-java','XML conversions are supported in the JSONML and XML library components. Conversions can be problematic because there is no natural mapping between JSON and XML. There will probably always be requests to change how particular conversions are performed. Some additional latitude in customizing the library is allowed for these cases, as long as the existing default behavior is kept. The preferred implementation is to provide a configuration class to allow overriding certain custom conversions. See for example #412.','perform particular conversions',0,'',''),(65,'JSON-java','XML conversions are supported in the JSONML and XML library components. Conversions can be problematic because there is no natural mapping between JSON and XML. There will probably always be requests to change how particular conversions are performed. Some additional latitude in customizing the library is allowed for these cases, as long as the existing default behavior is kept. The preferred implementation is to provide a configuration class to allow overriding certain custom conversions. See for example #412.','customize library',0,'',''),(66,'JSON-java','JSONObject.java: The JSONObject can parse text from a String or a JSONTokener\nto produce a map-like object. The object provides methods for manipulating its\ncontents, and for producing a JSON compliant object serialization.','parse text from string',0,'',''),(67,'JSON-java','JSONObject.java: The JSONObject can parse text from a String or a JSONTokener\nto produce a map-like object. The object provides methods for manipulating its\ncontents, and for producing a JSON compliant object serialization.','parse text from JSONTokener',0,'',''),(68,'JSON-java','JSONObject.java: The JSONObject can parse text from a String or a JSONTokener\nto produce a map-like object. The object provides methods for manipulating its\ncontents, and for producing a JSON compliant object serialization.','produce map-like object',0,'',''),(69,'JSON-java','JSONObject.java: The JSONObject can parse text from a String or a JSONTokener\nto produce a map-like object. The object provides methods for manipulating its\ncontents, and for producing a JSON compliant object serialization.','manipulate contents',0,'',''),(70,'JSON-java','JSONObject.java: The JSONObject can parse text from a String or a JSONTokener\nto produce a map-like object. The object provides methods for manipulating its\ncontents, and for producing a JSON compliant object serialization.','produce JSON compliant object serialization',0,'',''),(71,'JSON-java','JSONArray.java: The JSONArray can parse text from a String or a JSONTokener\nto produce a vector-like object. The object provides methods for manipulating\nits contents, and for producing a JSON compliant array serialization.','parse text from String',0,'',''),(72,'JSON-java','JSONArray.java: The JSONArray can parse text from a String or a JSONTokener\nto produce a vector-like object. The object provides methods for manipulating\nits contents, and for producing a JSON compliant array serialization.','parse text from JSONTokener',0,'',''),(73,'JSON-java','JSONArray.java: The JSONArray can parse text from a String or a JSONTokener\nto produce a vector-like object. The object provides methods for manipulating\nits contents, and for producing a JSON compliant array serialization.','produce vector-like object',0,'',''),(74,'JSON-java','JSONArray.java: The JSONArray can parse text from a String or a JSONTokener\nto produce a vector-like object. The object provides methods for manipulating\nits contents, and for producing a JSON compliant array serialization.','manipulate contents',0,'',''),(75,'JSON-java','JSONArray.java: The JSONArray can parse text from a String or a JSONTokener\nto produce a vector-like object. The object provides methods for manipulating\nits contents, and for producing a JSON compliant array serialization.','produce JSON compliant array serialization',0,'',''),(76,'JSON-java','JSONTokener.java: The JSONTokener breaks a text into a sequence of individual\ntokens. It can be constructed from a String, Reader, or InputStream. It also can\nparse text from a String, Number, Boolean or null like \"hello\", 42, true,\nnull to produce a simple json object.','break text into sequence',0,'',''),(77,'JSON-java','JSONTokener.java: The JSONTokener breaks a text into a sequence of individual\ntokens. It can be constructed from a String, Reader, or InputStream. It also can\nparse text from a String, Number, Boolean or null like \"hello\", 42, true,\nnull to produce a simple json object.','parse text like hello',0,'',''),(78,'JSON-java','JSONTokener.java: The JSONTokener breaks a text into a sequence of individual\ntokens. It can be constructed from a String, Reader, or InputStream. It also can\nparse text from a String, Number, Boolean or null like \"hello\", 42, true,\nnull to produce a simple json object.','parse text from string',0,'',''),(79,'JSON-java','JSONTokener.java: The JSONTokener breaks a text into a sequence of individual\ntokens. It can be constructed from a String, Reader, or InputStream. It also can\nparse text from a String, Number, Boolean or null like \"hello\", 42, true,\nnull to produce a simple json object.','parse text from number',0,'',''),(80,'JSON-java','JSONTokener.java: The JSONTokener breaks a text into a sequence of individual\ntokens. It can be constructed from a String, Reader, or InputStream. It also can\nparse text from a String, Number, Boolean or null like \"hello\", 42, true,\nnull to produce a simple json object.','parse text from boolean',0,'',''),(81,'JSON-java','JSONTokener.java: The JSONTokener breaks a text into a sequence of individual\ntokens. It can be constructed from a String, Reader, or InputStream. It also can\nparse text from a String, Number, Boolean or null like \"hello\", 42, true,\nnull to produce a simple json object.','parse text from null',0,'',''),(82,'JSON-java','JSONTokener.java: The JSONTokener breaks a text into a sequence of individual\ntokens. It can be constructed from a String, Reader, or InputStream. It also can\nparse text from a String, Number, Boolean or null like \"hello\", 42, true,\nnull to produce a simple json object.','produce simple json object',0,'',''),(83,'JSON-java','JSONPropertyIgnore.java: Annotation class that can be used on Java Bean getter methods.\nWhen used on a bean method that would normally be serialized into a JSONObject, it\noverrides the getter-to-key-name logic and forces the property to be excluded from the\nresulting JSONObject.','override getter-to-key-name logic',0,'',''),(84,'JSON-java','JSONPropertyIgnore.java: Annotation class that can be used on Java Bean getter methods.\nWhen used on a bean method that would normally be serialized into a JSONObject, it\noverrides the getter-to-key-name logic and forces the property to be excluded from the\nresulting JSONObject.','force property',0,'',''),(85,'JSON-java','JSONPropertyIgnore.java: Annotation class that can be used on Java Bean getter methods.\nWhen used on a bean method that would normally be serialized into a JSONObject, it\noverrides the getter-to-key-name logic and forces the property to be excluded from the\nresulting JSONObject.','serialize bean method into JSONObject',0,'',''),(86,'JSON-java','JSONPropertyIgnore.java: Annotation class that can be used on Java Bean getter methods.\nWhen used on a bean method that would normally be serialized into a JSONObject, it\noverrides the getter-to-key-name logic and forces the property to be excluded from the\nresulting JSONObject.','exclude  from resulting JSONObject',0,'',''),(87,'JSON-java','JSONPropertyName.java: Annotation class that can be used on Java Bean getter methods.\nWhen used on a bean method that would normally be serialized into a JSONObject, it\noverrides the getter-to-key-name logic and uses the value of the annotation. The Bean\nprocessor will look through the class hierarchy. This means you can use the annotation on\na base class or interface and the value of the annotation will be used even if the getter\nis overridden in a child class.','override getter-to-key-name logic',0,'',''),(88,'JSON-java','JSONPropertyName.java: Annotation class that can be used on Java Bean getter methods.\nWhen used on a bean method that would normally be serialized into a JSONObject, it\noverrides the getter-to-key-name logic and uses the value of the annotation. The Bean\nprocessor will look through the class hierarchy. This means you can use the annotation on\na base class or interface and the value of the annotation will be used even if the getter\nis overridden in a child class.','serialize bean method into JSONObject',0,'',''),(89,'JSON-java','JSONPropertyName.java: Annotation class that can be used on Java Bean getter methods.\nWhen used on a bean method that would normally be serialized into a JSONObject, it\noverrides the getter-to-key-name logic and uses the value of the annotation. The Bean\nprocessor will look through the class hierarchy. This means you can use the annotation on\na base class or interface and the value of the annotation will be used even if the getter\nis overridden in a child class.','override getter in child class',0,'',''),(90,'JSON-java','CDL.java: CDL provides support for converting between JSON and comma\ndelimited lists.','convert  between JSON comma delimited lists',0,'',''),(91,'JSON-java','Cookie.java: Cookie provides support for converting between JSON and cookies.','convert  between JSON',0,'',''),(92,'JSON-java','Cookie.java: Cookie provides support for converting between JSON and cookies.','convert  between cookies',0,'',''),(93,'JSON-java','CookieList.java: CookieList provides support for converting between JSON and\ncookie lists.','convert  between JSON cookie lists',0,'',''),(94,'JSON-java','HTTP.java: HTTP provides support for converting between JSON and HTTP headers.','convert  between JSON HTTP headers',0,'',''),(95,'JSON-java','HTTPTokener.java: HTTPTokener extends JSONTokener for parsing HTTP headers.','extend JSONTokener for parsing HTTP headers',0,'',''),(96,'JSON-java','XML.java: XML provides support for converting between JSON and XML.','convert  between JSON',0,'',''),(97,'JSON-java','XML.java: XML provides support for converting between JSON and XML.','convert  between XML',0,'',''),(98,'JSON-java','JSONML.java: JSONML provides support for converting between JSONML and XML.','convert  between JSONML',0,'',''),(99,'JSON-java','JSONML.java: JSONML provides support for converting between JSONML and XML.','convert  between XML',0,'',''),(100,'JSON-java','XMLTokener.java: XMLTokener extends JSONTokener for parsing XML text.','extend JSONTokener for parsing',0,'',''),(101,'JSON-java','XMLTokener.java: XMLTokener extends JSONTokener for parsing XML text.','parse XML text',0,'',''),(102,'JSON-java','The JSON-Java package is a reference implementation that demonstrates how to parse JSON documents into Java objects and how to generate new JSON documents from the Java classes.','parse JSON documents into Java objects',0,'',''),(103,'JSON-java','The JSON-Java package is a reference implementation that demonstrates how to parse JSON documents into Java objects and how to generate new JSON documents from the Java classes.','generate new JSON documents from Java classes',0,'',''),(104,'JSON-java','The files in this package implement JSON encoders and decoders. The package can also convert between JSON and XML, HTTP headers, Cookies, and CDL.','convert  between CDL',0,'',''),(105,'JSON-java','The files in this package implement JSON encoders and decoders. The package can also convert between JSON and XML, HTTP headers, Cookies, and CDL.','convert  between JSON',0,'',''),(106,'JSON-java','The files in this package implement JSON encoders and decoders. The package can also convert between JSON and XML, HTTP headers, Cookies, and CDL.','convert  between XML',0,'',''),(107,'JSON-java','The files in this package implement JSON encoders and decoders. The package can also convert between JSON and XML, HTTP headers, Cookies, and CDL.','convert  between HTTP headers',0,'',''),(108,'JSON-java','The files in this package implement JSON encoders and decoders. The package can also convert between JSON and XML, HTTP headers, Cookies, and CDL.','convert  between cookies',0,'',''),(109,'JSON-java','Bug fixes, code improvements, and unit test coverage changes are welcome! Because this project is currently in the maintenance phase, the kinds of changes that can be accepted are limited. For more information, please read the FAQ.','read FAQ for more information',0,'',''),(110,'JSON-java','The org.json package can be built from the command line, Maven, and Gradle. The unit tests can be executed from Maven, Gradle, or individually in an IDE e.g. Eclipse.','execute unit tests from e.g. eclipse',1,'https://github.com/stleary/JSON-java','user-content-build-instructions'),(111,'JSON-java','The org.json package can be built from the command line, Maven, and Gradle. The unit tests can be executed from Maven, Gradle, or individually in an IDE e.g. Eclipse.','execute unit tests from maven',1,'https://github.com/stleary/JSON-java','user-content-build-instructions'),(112,'JSON-java','The org.json package can be built from the command line, Maven, and Gradle. The unit tests can be executed from Maven, Gradle, or individually in an IDE e.g. Eclipse.','execute unit tests from gradle',1,'https://github.com/stleary/JSON-java','user-content-build-instructions'),(113,'JSON-java','Compile a program that uses the jar (see example code below)','compile program',1,'https://github.com/stleary/JSON-java','user-content-build-instructions'),(114,'JSON-java','Execute the Test file','execute Test file',1,'https://github.com/stleary/JSON-java','user-content-build-instructions'),(115,'JSON-java','Tools to build the package and execute the unit tests','execute unit',0,'',''),(116,'JSON-java','Execute the test suite with Maven:','execute test suite with maven',1,'https://github.com/stleary/JSON-java','user-content-build-instructions'),(117,'JSON-java','Execute the test suite with Gradlew:','execute test suite with gradlew',1,'https://github.com/stleary/JSON-java','user-content-build-instructions'),(118,'JSON-java','In compliance with RFC8259 page 10 section 9, the parser is more lax with what is valid\nJSON then the Generator. For Example, the tab character (U+0009) is allowed when reading\nJSON Text strings, but when output by the Generator, the tab is properly converted to 	 in\nthe string. Other instances may occur where reading invalid JSON text does not cause an\nerror to be generated. Malformed JSON Texts such as missing end \" (quote) on strings or\ninvalid number formats (1.2e6.3) will cause errors as such documents can not be read\nreliably.','read JSON text strings',0,'',''),(119,'JSON-java','In compliance with RFC8259 page 10 section 9, the parser is more lax with what is valid\nJSON then the Generator. For Example, the tab character (U+0009) is allowed when reading\nJSON Text strings, but when output by the Generator, the tab is properly converted to 	 in\nthe string. Other instances may occur where reading invalid JSON text does not cause an\nerror to be generated. Malformed JSON Texts such as missing end \" (quote) on strings or\ninvalid number formats (1.2e6.3) will cause errors as such documents can not be read\nreliably.','convert output by generator',0,'',''),(120,'JSON-java','In compliance with RFC8259 page 10 section 9, the parser is more lax with what is valid\nJSON then the Generator. For Example, the tab character (U+0009) is allowed when reading\nJSON Text strings, but when output by the Generator, the tab is properly converted to 	 in\nthe string. Other instances may occur where reading invalid JSON text does not cause an\nerror to be generated. Malformed JSON Texts such as missing end \" (quote) on strings or\ninvalid number formats (1.2e6.3) will cause errors as such documents can not be read\nreliably.','read invalid JSON text',0,'',''),(121,'JSON-java','Recent pull requests added a new method putAll on the JSONArray. The putAll method\nworks similarly to other put methods in that it does not call JSONObject.wrap for items\nadded. This can lead to inconsistent object representation in JSONArray structures.','add new method putAll on JSONArray',1,'https://github.com/stleary/JSON-java/blob/master/docs/NOTES.md','user-content-notes'),(122,'JSON-java','JSON-java releases can be found by searching the Maven repository for groupId \"org.json\"\nand artifactId \"json\". For example:\nhttps://search.maven.org/search?q=g:org.json%20AND%20a:json&core=gav','search Maven repository for artifactId json',1,'https://github.com/stleary/JSON-java/blob/master/docs/RELEASES.md','user-content-release-history'),(123,'JSON-java','JSON-java releases can be found by searching the Maven repository for groupId \"org.json\"\nand artifactId \"json\". For example:\nhttps://search.maven.org/search?q=g:org.json%20AND%20a:json&core=gav','search Maven repository for groupId org.json',1,'https://github.com/stleary/JSON-java/blob/master/docs/RELEASES.md','user-content-release-history'),(124,'JSON-java','JSON-java releases can be found by searching the Maven repository for groupId \"org.json\"\nand artifactId \"json\". For example:\nhttps://search.maven.org/search?q=g:org.json%20AND%20a:json&core=gav','find JSON-java releases',1,'https://github.com/stleary/JSON-java/blob/master/docs/RELEASES.md','user-content-release-history'),(125,'jBinary','This tool works thanks to a feature that is not in the JavaScript specification: When you iterate over an object keys, the keys will be listed in their order of insertion. Note that Chrome and Opera do not respect this implicit rule for keys that are numbers.','list keys',0,'',''),(126,'jBinary','Debugging reading/writing of binary types implemented with declarative syntax is always tricky, so starting from version 2.1, jBinary allows you to see named type descriptors, structure property names and byte offsets in stack of Safari, Chrome and Firefox Developer Tools making it more meaningful so you can easily find place where [de]serializing error had occured and fix it.','find place',0,'',''),(127,'jBinary','Debugging reading/writing of binary types implemented with declarative syntax is always tricky, so starting from version 2.1, jBinary allows you to see named type descriptors, structure property names and byte offsets in stack of Safari, Chrome and Firefox Developer Tools making it more meaningful so you can easily find place where [de]serializing error had occured and fix it.','implement  with declarative syntax',0,'',''),(128,'jBinary','Base type for template should be specified using one of the following methods:','specify base type for template',0,'',''),(129,'jBinary','First two cases are preferred if possible since they will automatically resolve and cache underlying type.','resolve underlying type',0,'',''),(130,'jBinary','First two cases are preferred if possible since they will automatically resolve and cache underlying type.','cache underlying type',0,'',''),(131,'jBinary','jBinary.Template instance has following extra methods compared to jBinary.Type that you can use in your implementations:','use  in implementations',0,'',''),(132,'jBinary','When you need extra functionality that you can\'t achieve using declarative syntax, you are able to create and reuse your own types in the same way standard types are used.','use declarative syntax',0,'',''),(133,'jBinary','When you need extra functionality that you can\'t achieve using declarative syntax, you are able to create and reuse your own types in the same way standard types are used.','create own types in same way',0,'',''),(134,'jBinary','When you need extra functionality that you can\'t achieve using declarative syntax, you are able to create and reuse your own types in the same way standard types are used.','reuse own types in same way',0,'',''),(135,'jBinary','When you need extra functionality that you can\'t achieve using declarative syntax, you are able to create and reuse your own types in the same way standard types are used.','use standard types',0,'',''),(136,'jBinary','When you need extra functionality that you can\'t achieve using declarative syntax, you are able to create and reuse your own types in the same way standard types are used.','use same way',0,'',''),(137,'jBinary','In property instances, you can access this.binary for accessing jBinary instance this property belongs to.','access this.binary in property instances',0,'',''),(138,'jBinary','In property instances, you can access this.binary for accessing jBinary instance this property belongs to.','access this.binary for accessing',0,'',''),(139,'jBinary','In property instances, you can access this.binary for accessing jBinary instance this property belongs to.','access jBinary instance',0,'',''),(140,'jBinary','All following methods (except toValue) you wouldn\'t need to call nor override in most cases since it may break basic type functionality, so before using them make sure you really need that and are doing that right.','break basic type',0,'',''),(141,'jBinary','All following methods (except toValue) you wouldn\'t need to call nor override in most cases since it may break basic type functionality, so before using them make sure you really need that and are doing that right.','override  in most cases',0,'',''),(142,'jBinary','So you need to get this data from some external source and show result when you are done.','get data from external source',0,'',''),(143,'jBinary','So you need to get this data from some external source and show result when you are done.','get data from show result',0,'',''),(144,'jBinary','And jBinary provides following handy methods for those operations.','provide  following handy methods',0,'',''),(145,'jBinary','Loads data from given source using jBinary.loadData, detects typeset using Repo associations if it\'s not specified explicitly, creates jBinary instance on this data and typeset and returns it in Promise or Node.js-like callback(error, data) if specified.','use jBinary.loadData',0,'',''),(146,'jBinary','Loads data from given source using jBinary.loadData, detects typeset using Repo associations if it\'s not specified explicitly, creates jBinary instance on this data and typeset and returns it in Promise or Node.js-like callback(error, data) if specified.','use Repo associations',0,'',''),(147,'jBinary','Loads data from given source using jBinary.loadData, detects typeset using Repo associations if it\'s not specified explicitly, creates jBinary instance on this data and typeset and returns it in Promise or Node.js-like callback(error, data) if specified.','create jBinary instance on data',0,'',''),(148,'jBinary','Loads data from given source using jBinary.loadData, detects typeset using Repo associations if it\'s not specified explicitly, creates jBinary instance on this data and typeset and returns it in Promise or Node.js-like callback(error, data) if specified.','create jBinary instance on typeset',0,'',''),(149,'jBinary','Loads data from given source using jBinary.loadData, detects typeset using Repo associations if it\'s not specified explicitly, creates jBinary instance on this data and typeset and returns it in Promise or Node.js-like callback(error, data) if specified.','return  in promise',0,'',''),(150,'jBinary','Loads data from given source using jBinary.loadData, detects typeset using Repo associations if it\'s not specified explicitly, creates jBinary instance on this data and typeset and returns it in Promise or Node.js-like callback(error, data) if specified.','return  in Node.js-like callback(error, data)',0,'',''),(151,'jBinary','Saves data to given destination and returns Promise or calls Node.js-like callback(error, data) if specified.','save promise calls Node.js-like callback(error, data)',0,'',''),(152,'jBinary','mimeType is set from given argument, typeSet[\'jBinary.mimeType\'] directive or default to \'application/octet-stream\' in order of precedence.','set  from given argument',0,'',''),(153,'jBinary','Please note that jBinary does not polyfill Promise in browsers but expects ES6 window.Promise or compliant polyfill (i.e., https://github.com/jakearchibald/es6-promise) to be available. In the case it\'s not, asynchronous methods (when called without Node.js-like callback) return simple object that just contains then(onFulfill, onReject) method and so can be used for handling result but can\'t be composed with another promises without corresponding cast operation supported by your library of choise (Promise.from(...), Q(...), etc.).','return simple object',0,'',''),(154,'jBinary','Please note that jBinary does not polyfill Promise in browsers but expects ES6 window.Promise or compliant polyfill (i.e., https://github.com/jakearchibald/es6-promise) to be available. In the case it\'s not, asynchronous methods (when called without Node.js-like callback) return simple object that just contains then(onFulfill, onReject) method and so can be used for handling result but can\'t be composed with another promises without corresponding cast operation supported by your library of choise (Promise.from(...), Q(...), etc.).','handle result',0,'',''),(155,'jBinary','Please note that jBinary does not polyfill Promise in browsers but expects ES6 window.Promise or compliant polyfill (i.e., https://github.com/jakearchibald/es6-promise) to be available. In the case it\'s not, asynchronous methods (when called without Node.js-like callback) return simple object that just contains then(onFulfill, onReject) method and so can be used for handling result but can\'t be composed with another promises without corresponding cast operation supported by your library of choise (Promise.from(...), Q(...), etc.).','use simple object for handling',0,'',''),(156,'jBinary','See info about encoding in jDataView documentation.','encode  in jDataView documentation',0,'',''),(157,'jBinary','All the arguments marked with @(references) can be passed not only as direct values, but also as getter functions callback(context) or string property names inside current context chain.','pass @ as getter functions callback(context)',1,'https://github.com/jDataView/jBinary/wiki/Standard-types','user-content-references'),(158,'jBinary','All the arguments marked with @(references) can be passed not only as direct values, but also as getter functions callback(context) or string property names inside current context chain.','pass @ as direct values',1,'https://github.com/jDataView/jBinary/wiki/Standard-types','user-content-references'),(159,'jBinary','All the arguments marked with @(references) can be passed not only as direct values, but also as getter functions callback(context) or string property names inside current context chain.','pass @ inside current context chain',1,'https://github.com/jDataView/jBinary/wiki/Standard-types','user-content-references'),(160,'jBinary','Usually, in-built types are not enough for handling complicated structures since you might want to create and re-use some own types built on top of standard ones. For such cases, you might want to have look at jBinary.Type.','handle complicated structures',0,'',''),(161,'jBinary','Usually, in-built types are not enough for handling complicated structures since you might want to create and re-use some own types built on top of standard ones. For such cases, you might want to have look at jBinary.Type.','create own types',0,'',''),(162,'jBinary','jBinary provides special Repo for popular file formats and corresponding demos.','provide special repo for popular file formats',0,'',''),(163,'jBinary','jBinary provides special Repo for popular file formats and corresponding demos.','provide special repo for corresponding demos',0,'',''),(164,'jBinary','Using standard typesets is easy - just make require-like call to jBinary.Repo async loader method.','use standard typesets',0,'',''),(165,'jBinary','You can call it with one typeset name:','call  with typeset name',1,'https://github.com/jDataView/jBinary/wiki/The-Repo',''),(166,'jBinary','All the typesets that are already loaded, are stored inside jBinary.Repo itself with upper-case names of typesets used as keys (like jBinary.Repo.BMP).','store typesets with upper-case names',0,'',''),(167,'jBinary','All the typesets that are already loaded, are stored inside jBinary.Repo itself with upper-case names of typesets used as keys (like jBinary.Repo.BMP).','store typesets inside jBinary.Repo',0,'',''),(168,'jBinary','All the typesets that are already loaded, are stored inside jBinary.Repo itself with upper-case names of typesets used as keys (like jBinary.Repo.BMP).','use  as keys',0,'',''),(169,'jBinary','All the typesets that are already loaded, are stored inside jBinary.Repo itself with upper-case names of typesets used as keys (like jBinary.Repo.BMP).','load typesets',0,'',''),(170,'jBinary','If you know some popular format structure and can write own typeset, you\'re welcome to contribute!','write own typeset',0,'',''),(171,'jBinary','Types can be used in any of the following forms:','use types',0,'',''),(172,'jBinary','Inside the Repo, there is also associations.js file which provides associations between typesets and corresponding file name extensions & mime types.','provide corresponding file name extensions between typesets',0,'',''),(173,'jBinary','Inside the Repo, there is also associations.js file which provides associations between typesets and corresponding file name extensions & mime types.','provide associations between typesets',0,'',''),(174,'jBinary','Inside the Repo, there is also associations.js file which provides associations between typesets and corresponding file name extensions & mime types.','provide associations.js file between typesets',0,'',''),(175,'jBinary','jBinary uses those associations for loading data from external sources when typeset is not specified explicitly.','use associations for loading',1,'https://github.com/jDataView/jBinary/wiki/Typeset-associations',''),(176,'jBinary','jBinary uses those associations for loading data from external sources when typeset is not specified explicitly.','load data from external sources',1,'https://github.com/jDataView/jBinary/wiki/Typeset-associations',''),(177,'jBinary','Typesets normally are just object dictionaries of typeName => type pairs with types that can refer to each other and completely describe some data structure format:','describe data structure format',1,'https://github.com/jDataView/jBinary/wiki/Typesets',''),(178,'jBinary','Typesets normally are just object dictionaries of typeName => type pairs with types that can refer to each other and completely describe some data structure format:','describe types',1,'https://github.com/jDataView/jBinary/wiki/Typesets',''),(179,'jBinary','As was shown above, typesets may also contain special config values that set some global options for entire typeset.','set global options for entire typeset',0,'',''),(180,'jBinary','As was shown above, typesets may also contain special config values that set some global options for entire typeset.','set special config values for entire typeset',0,'',''),(181,'jBinary','Recommended way is to install library with Component as jDataView/jBinary or with Bower as jbinary.','install library with bower',0,'',''),(182,'jBinary','Recommended way is to install library with Component as jDataView/jBinary or with Bower as jbinary.','install library with component',0,'',''),(183,'jBinary','Recommended way is to install library with Component as jDataView/jBinary or with Bower as jbinary.','install library as jbinary',0,'',''),(184,'jBinary','If you don\'t use any of those, include scripts for jDataView and jBinary like in following sample:','include scripts in following sample',1,'https://github.com/jDataView/jBinary/wiki/Usage-in-Browser',''),(185,'jBinary','If you don\'t use any of those, include scripts for jDataView and jBinary like in following sample:','include scripts for jDataView',1,'https://github.com/jDataView/jBinary/wiki/Usage-in-Browser',''),(186,'jBinary','If you don\'t use any of those, include scripts for jDataView and jBinary like in following sample:','include scripts for jBinary',1,'https://github.com/jDataView/jBinary/wiki/Usage-in-Browser',''),(187,'jBinary','Just use npm to install jBinary and you are set :)','install jBinary',1,'https://github.com/jDataView/jBinary/wiki/Usage-in-Node.js',''),(188,'jBinary','jBinary supports dynamic loading via AMD too:','support dynamic loading via AMD',1,'https://github.com/jDataView/jBinary/wiki/Usage-with-AMD',''),(189,'jQuery','jQuery is a JavaScript library. Consider also adding the JavaScript tag. \r\n\r\njQuery is a popular cross-browser JavaScript library that facilitates Document Object Model (DOM) traversal, event handling, animations and AJAX interactions by minimizing the discrepancies across browsers. A question tagged jQuery should be related to jQuery, so jQuery should be used by the code in question, and at least jQuery usage-related elements must be in the question.','add JavaScript tag',0,'',''),(190,'jQuery','jQuery is a JavaScript library. Consider also adding the JavaScript tag. \r\n\r\njQuery is a popular cross-browser JavaScript library that facilitates Document Object Model (DOM) traversal, event handling, animations and AJAX interactions by minimizing the discrepancies across browsers. A question tagged jQuery should be related to jQuery, so jQuery should be used by the code in question, and at least jQuery usage-related elements must be in the question.','use jQuery',0,'',''),(191,'jQuery','jQuery (Core) is a cross-browser JavaScript library (created by John Resig) that provides abstractions for common client-side tasks such as DOM traversal, DOM manipulation, event handling, animation and AJAX.','provide abstractions for common client-side tasks',0,'',''),(192,'jQuery','jQuery (Core) is a cross-browser JavaScript library (created by John Resig) that provides abstractions for common client-side tasks such as DOM traversal, DOM manipulation, event handling, animation and AJAX.','provide cross-browser JavaScript library for common client-side tasks',0,'',''),(193,'jQuery','jQuery provides a platform to create plugins that extend its capabilities beyond those already provided by the library. The development of jQuery and related projects is coordinated by the jQuery Foundation.','provide platform',0,'',''),(194,'jQuery','jQuery provides a platform to create plugins that extend its capabilities beyond those already provided by the library. The development of jQuery and related projects is coordinated by the jQuery Foundation.','create plugins',0,'',''),(195,'jQuery','jQuery provides a platform to create plugins that extend its capabilities beyond those already provided by the library. The development of jQuery and related projects is coordinated by the jQuery Foundation.','extend capabilities',0,'',''),(196,'jQuery','jQuery provides a platform to create plugins that extend its capabilities beyond those already provided by the library. The development of jQuery and related projects is coordinated by the jQuery Foundation.','extend plugins',0,'',''),(197,'jQuery','jQuery includes the following features:','include following features',0,'',''),(198,'jQuery','jQuery supports the current stable version and the preceding version or \"current - 1 version\" of Chrome, Edge, Firefox, and Safari. It also supports the current stable version of Opera.','support version of chrome',0,'',''),(199,'jQuery','jQuery supports the current stable version and the preceding version or \"current - 1 version\" of Chrome, Edge, Firefox, and Safari. It also supports the current stable version of Opera.','support version of edge',0,'',''),(200,'jQuery','jQuery supports the current stable version and the preceding version or \"current - 1 version\" of Chrome, Edge, Firefox, and Safari. It also supports the current stable version of Opera.','support version of firefox',0,'',''),(201,'jQuery','jQuery supports the current stable version and the preceding version or \"current - 1 version\" of Chrome, Edge, Firefox, and Safari. It also supports the current stable version of Opera.','support version of safari',0,'',''),(202,'jQuery','jQuery supports the current stable version and the preceding version or \"current - 1 version\" of Chrome, Edge, Firefox, and Safari. It also supports the current stable version of Opera.','support current stable version of chrome',0,'',''),(203,'jQuery','jQuery supports the current stable version and the preceding version or \"current - 1 version\" of Chrome, Edge, Firefox, and Safari. It also supports the current stable version of Opera.','support current stable version of edge',0,'',''),(204,'jQuery','jQuery supports the current stable version and the preceding version or \"current - 1 version\" of Chrome, Edge, Firefox, and Safari. It also supports the current stable version of Opera.','support current stable version of firefox',0,'',''),(205,'jQuery','jQuery supports the current stable version and the preceding version or \"current - 1 version\" of Chrome, Edge, Firefox, and Safari. It also supports the current stable version of Opera.','support current stable version of safari',0,'',''),(206,'jQuery','jQuery supports the current stable version and the preceding version or \"current - 1 version\" of Chrome, Edge, Firefox, and Safari. It also supports the current stable version of Opera.','support preceding version of chrome',0,'',''),(207,'jQuery','jQuery supports the current stable version and the preceding version or \"current - 1 version\" of Chrome, Edge, Firefox, and Safari. It also supports the current stable version of Opera.','support preceding version of edge',0,'',''),(208,'jQuery','jQuery supports the current stable version and the preceding version or \"current - 1 version\" of Chrome, Edge, Firefox, and Safari. It also supports the current stable version of Opera.','support preceding version of firefox',0,'',''),(209,'jQuery','jQuery supports the current stable version and the preceding version or \"current - 1 version\" of Chrome, Edge, Firefox, and Safari. It also supports the current stable version of Opera.','support preceding version of safari',0,'',''),(210,'jQuery','jQuery supports the current stable version and the preceding version or \"current - 1 version\" of Chrome, Edge, Firefox, and Safari. It also supports the current stable version of Opera.','support current stable version of opera',0,'',''),(211,'jQuery','In addition, jQuery 1.x supports Internet Explorer version 6 or higher. However, support for IE 6-8 was dropped by jQuery 2.x and by jQuery 3.x, which support only IE 9 or higher.','support Internet explorer version 6 higher',0,'',''),(212,'jQuery','In addition, jQuery 1.x supports Internet Explorer version 6 or higher. However, support for IE 6-8 was dropped by jQuery 2.x and by jQuery 3.x, which support only IE 9 or higher.','support only IE 9 higher',0,'',''),(213,'jQuery','Finally, jQuery supports the stock mobile browser on Android 4.0 and higher and Safari on iOS 7 and higher.','support stock mobile browser on iOS 7 higher',0,'',''),(214,'jQuery','Finally, jQuery supports the stock mobile browser on Android 4.0 and higher and Safari on iOS 7 and higher.','support stock mobile browser on Android 4.0',0,'',''),(215,'jQuery','Finally, jQuery supports the stock mobile browser on Android 4.0 and higher and Safari on iOS 7 and higher.','support Safari on iOS 7 higher',0,'',''),(216,'jQuery','Finally, jQuery supports the stock mobile browser on Android 4.0 and higher and Safari on iOS 7 and higher.','support Safari on Android 4.0',0,'',''),(217,'jQuery','jQuery is updated frequently, so the library should be used carefully. Some functions become deprecated with newer versions of jQuery. Follow the release notes to be on track with the features.','use library',0,'',''),(218,'jQuery','The jQuery CDN provides download links for all versions of jQuery, including the latest stable versions of each branch.','provide download links for versions',0,'',''),(219,'jQuery','This shows \"Hello world!\" in the alert box on each link click after the DOM is ready (JSFiddle):','show world',1,'https://stackoverflow.com/tags/jquery/info','wiki-excerpt'),(220,'jQuery','If your code is somehow manipulating the DOM, you must ensure that it is run after the DOM finishes loading.','manipulate DOM',1,'https://stackoverflow.com/tags/jquery/info','wiki-excerpt'),(221,'jQuery','If your code is somehow manipulating the DOM, you must ensure that it is run after the DOM finishes loading.','run  after DOM finishes loading',1,'https://stackoverflow.com/tags/jquery/info','wiki-excerpt'),(222,'jQuery','These are alternatives to placing the JavaScript code or script tag in the HTML right before the closing','place JavaScript code before closing',0,'',''),(223,'jQuery','These are alternatives to placing the JavaScript code or script tag in the HTML right before the closing','place JavaScript code in HTML right',0,'',''),(224,'jQuery','These are alternatives to placing the JavaScript code or script tag in the HTML right before the closing','place script tag before closing',0,'',''),(225,'jQuery','These are alternatives to placing the JavaScript code or script tag in the HTML right before the closing','place script tag in HTML right',0,'',''),(226,'jQuery','In jQuery 3.x, the recommended way to add a ready handler is $(function () {}), while other forms such as $(document).ready(function () {}) are deprecated. Also, jQuery 3.x removes the ability to use .on(\"ready\", function () {}) to run a function on the \"ready\" event.','remove ability',0,'',''),(227,'jQuery','In jQuery 3.x, the recommended way to add a ready handler is $(function () {}), while other forms such as $(document).ready(function () {}) are deprecated. Also, jQuery 3.x removes the ability to use .on(\"ready\", function () {}) to run a function on the \"ready\" event.','run function on ready event',0,'',''),(228,'jQuery','If your jQuery code conflicts with another library that also uses the $ sign as an alias, then use the noConflict() method:','use library',1,'https://stackoverflow.com/tags/jquery/info','content'),(229,'jQuery','If your jQuery code conflicts with another library that also uses the $ sign as an alias, then use the noConflict() method:','use noConflict() method',1,'https://stackoverflow.com/tags/jquery/info','content'),(230,'jQuery','Then you can safely use $ as an alias for the other library while using the name jQuery itself for jQuery functions.','use name jQuery',1,'https://stackoverflow.com/tags/jquery/info','content'),(231,'jQuery','And use $jq as an alias for jQuery. For example:','use $jq as alias',1,'https://stackoverflow.com/tags/jquery/info','content'),(232,'jQuery','It is also possible to assign jQuery to $ within a certain scope:','assign jQuery',1,'https://stackoverflow.com/tags/jquery/info','content'),(233,'jQuery','Then you can use $ as an alias for jQuery inside that function block without worrying about conflicts with other libraries.','use  without worrying',0,'',''),(234,'jQuery','Calling the jQuery function $() is expensive. Calling it repeatedly is extremely inefficient. Avoid doing this:','call jQuery function $',1,'https://stackoverflow.com/tags/jquery/info','content'),(235,'jQuery','Also, remember that many functions can perform multiple changes in one call by grouping all the values into an object. Instead of:','perform multiple changes in call',1,'https://stackoverflow.com/tags/jquery/info','content'),(236,'jQuery','Also, remember that many functions can perform multiple changes in one call by grouping all the values into an object. Instead of:','perform multiple changes by grouping',1,'https://stackoverflow.com/tags/jquery/info','content'),(237,'jQuery','Also, remember that many functions can perform multiple changes in one call by grouping all the values into an object. Instead of:','group values into object',1,'https://stackoverflow.com/tags/jquery/info','content'),(238,'jQuery','While one of the goals of jQuery is to abstract away the DOM, knowing DOM properties can be beneficial. One of the most commonly made mistakes by those who learn jQuery without learning about the DOM is to utilize jQuery to access the properties of an element:','learn jQuery without learning',1,'https://stackoverflow.com/tags/jquery/info','content'),(239,'jQuery','While one of the goals of jQuery is to abstract away the DOM, knowing DOM properties can be beneficial. One of the most commonly made mistakes by those who learn jQuery without learning about the DOM is to utilize jQuery to access the properties of an element:','access properties of element',1,'https://stackoverflow.com/tags/jquery/info','content'),(240,'jQuery','While one of the goals of jQuery is to abstract away the DOM, knowing DOM properties can be beneficial. One of the most commonly made mistakes by those who learn jQuery without learning about the DOM is to utilize jQuery to access the properties of an element:','learn  about DOM',1,'https://stackoverflow.com/tags/jquery/info','content'),(241,'jQuery','jQuery in Action, Third Edition, is a fast-paced and complete guide to jQuery, focused on the tasks you\'ll face in nearly any web dev project. Written for readers with minimal JavaScript experience, this revised edition adds new examples and exercises, along with the deep and practical coverage you expect from an In Action book. You\'ll learn how to traverse HTML documents, handle events, perform animations, write plugins, and even unit test your code. The unique lab pages anchor each concept with real-world code. Several new chapters teach you how to interact with other tools and frameworks to build modern single-page web applications.','add new examples',0,'',''),(242,'jQuery','jQuery in Action, Third Edition, is a fast-paced and complete guide to jQuery, focused on the tasks you\'ll face in nearly any web dev project. Written for readers with minimal JavaScript experience, this revised edition adds new examples and exercises, along with the deep and practical coverage you expect from an In Action book. You\'ll learn how to traverse HTML documents, handle events, perform animations, write plugins, and even unit test your code. The unique lab pages anchor each concept with real-world code. Several new chapters teach you how to interact with other tools and frameworks to build modern single-page web applications.','write  for readers',0,'',''),(243,'jQuery','jQuery in Action, Third Edition, is a fast-paced and complete guide to jQuery, focused on the tasks you\'ll face in nearly any web dev project. Written for readers with minimal JavaScript experience, this revised edition adds new examples and exercises, along with the deep and practical coverage you expect from an In Action book. You\'ll learn how to traverse HTML documents, handle events, perform animations, write plugins, and even unit test your code. The unique lab pages anchor each concept with real-world code. Several new chapters teach you how to interact with other tools and frameworks to build modern single-page web applications.','handle events',0,'',''),(244,'jQuery','jQuery in Action, Third Edition, is a fast-paced and complete guide to jQuery, focused on the tasks you\'ll face in nearly any web dev project. Written for readers with minimal JavaScript experience, this revised edition adds new examples and exercises, along with the deep and practical coverage you expect from an In Action book. You\'ll learn how to traverse HTML documents, handle events, perform animations, write plugins, and even unit test your code. The unique lab pages anchor each concept with real-world code. Several new chapters teach you how to interact with other tools and frameworks to build modern single-page web applications.','perform animations',0,'',''),(245,'jQuery','jQuery in Action, Third Edition, is a fast-paced and complete guide to jQuery, focused on the tasks you\'ll face in nearly any web dev project. Written for readers with minimal JavaScript experience, this revised edition adds new examples and exercises, along with the deep and practical coverage you expect from an In Action book. You\'ll learn how to traverse HTML documents, handle events, perform animations, write plugins, and even unit test your code. The unique lab pages anchor each concept with real-world code. Several new chapters teach you how to interact with other tools and frameworks to build modern single-page web applications.','write plugins',0,'',''),(246,'jQuery','jQuery in Action, Third Edition, is a fast-paced and complete guide to jQuery, focused on the tasks you\'ll face in nearly any web dev project. Written for readers with minimal JavaScript experience, this revised edition adds new examples and exercises, along with the deep and practical coverage you expect from an In Action book. You\'ll learn how to traverse HTML documents, handle events, perform animations, write plugins, and even unit test your code. The unique lab pages anchor each concept with real-world code. Several new chapters teach you how to interact with other tools and frameworks to build modern single-page web applications.','test code',0,'',''),(247,'jQuery','Thanks to jQuery, no one remembers the bad old days when programmers manually managed browser inconsistencies, CSS selectors support, and DOM navigation, and when every animation was a frustrating exercise in raw JavaScript. The elegant, intuitive jQuery library beautifully manages these concerns, and jQuery 3 adds even more features to make your life as a web developer smooth and productive.','manage browser inconsistencies',0,'',''),(248,'jQuery','Thanks to jQuery, no one remembers the bad old days when programmers manually managed browser inconsistencies, CSS selectors support, and DOM navigation, and when every animation was a frustrating exercise in raw JavaScript. The elegant, intuitive jQuery library beautifully manages these concerns, and jQuery 3 adds even more features to make your life as a web developer smooth and productive.','manage CSS selectors support',0,'',''),(249,'jQuery','Thanks to jQuery, no one remembers the bad old days when programmers manually managed browser inconsistencies, CSS selectors support, and DOM navigation, and when every animation was a frustrating exercise in raw JavaScript. The elegant, intuitive jQuery library beautifully manages these concerns, and jQuery 3 adds even more features to make your life as a web developer smooth and productive.','manage DOM navigation',0,'',''),(250,'jQuery','Thanks to jQuery, no one remembers the bad old days when programmers manually managed browser inconsistencies, CSS selectors support, and DOM navigation, and when every animation was a frustrating exercise in raw JavaScript. The elegant, intuitive jQuery library beautifully manages these concerns, and jQuery 3 adds even more features to make your life as a web developer smooth and productive.','manage concerns',0,'',''),(251,'jQuery','Thanks to jQuery, no one remembers the bad old days when programmers manually managed browser inconsistencies, CSS selectors support, and DOM navigation, and when every animation was a frustrating exercise in raw JavaScript. The elegant, intuitive jQuery library beautifully manages these concerns, and jQuery 3 adds even more features to make your life as a web developer smooth and productive.','add concerns',0,'',''),(252,'jQuery','jQuery in Action, Third Edition, is a fast-paced guide to jQuery, focused on the tasks you\'ll face in nearly any web dev project. In it, you\'ll learn how to traverse the DOM, handle events, perform animations, write jQuery plugins, perform Ajax requests, and even unit test your code. Its unique Lab Pages anchor each concept in real-world code. This expanded Third Edition adds new chapters that teach you how to interact with other tools and frameworks and build modern single-page web applications.','handle events',0,'',''),(253,'jQuery','jQuery in Action, Third Edition, is a fast-paced guide to jQuery, focused on the tasks you\'ll face in nearly any web dev project. In it, you\'ll learn how to traverse the DOM, handle events, perform animations, write jQuery plugins, perform Ajax requests, and even unit test your code. Its unique Lab Pages anchor each concept in real-world code. This expanded Third Edition adds new chapters that teach you how to interact with other tools and frameworks and build modern single-page web applications.','perform animations',0,'',''),(254,'jQuery','jQuery in Action, Third Edition, is a fast-paced guide to jQuery, focused on the tasks you\'ll face in nearly any web dev project. In it, you\'ll learn how to traverse the DOM, handle events, perform animations, write jQuery plugins, perform Ajax requests, and even unit test your code. Its unique Lab Pages anchor each concept in real-world code. This expanded Third Edition adds new chapters that teach you how to interact with other tools and frameworks and build modern single-page web applications.','write jQuery plugins',0,'',''),(255,'jQuery','jQuery in Action, Third Edition, is a fast-paced guide to jQuery, focused on the tasks you\'ll face in nearly any web dev project. In it, you\'ll learn how to traverse the DOM, handle events, perform animations, write jQuery plugins, perform Ajax requests, and even unit test your code. Its unique Lab Pages anchor each concept in real-world code. This expanded Third Edition adds new chapters that teach you how to interact with other tools and frameworks and build modern single-page web applications.','perform Ajax requests',0,'',''),(256,'jQuery','jQuery in Action, Third Edition, is a fast-paced guide to jQuery, focused on the tasks you\'ll face in nearly any web dev project. In it, you\'ll learn how to traverse the DOM, handle events, perform animations, write jQuery plugins, perform Ajax requests, and even unit test your code. Its unique Lab Pages anchor each concept in real-world code. This expanded Third Edition adds new chapters that teach you how to interact with other tools and frameworks and build modern single-page web applications.','test code',0,'',''),(257,'jQuery','jQuery in Action, Third Edition, is a fast-paced guide to jQuery, focused on the tasks you\'ll face in nearly any web dev project. In it, you\'ll learn how to traverse the DOM, handle events, perform animations, write jQuery plugins, perform Ajax requests, and even unit test your code. Its unique Lab Pages anchor each concept in real-world code. This expanded Third Edition adds new chapters that teach you how to interact with other tools and frameworks and build modern single-page web applications.','add new chapters',0,'',''),(258,'jQuery','FREE domestic shipping on orders of three or more print books','print books',0,'',''),(259,'jQuery','If you\'re updating to a newer version of jQuery, be sure to read the release notes published on our blog. If you\'re coming from a version prior 1.9, you should check out the 1.9 Upgrade Guide as well.','read release notes',0,'',''),(260,'jQuery','If you\'re updating to a newer version of jQuery, be sure to read the release notes published on our blog. If you\'re coming from a version prior 1.9, you should check out the 1.9 Upgrade Guide as well.','update  to newer version',0,'',''),(261,'jQuery','Register a handler to be called when Ajax requests complete with an error. This is an Ajax Event.','complete  with error',0,'',''),(262,'jQuery','Attach a function to be executed before an Ajax request is sent. This is an Ajax Event.','attach function',0,'',''),(263,'jQuery','Attach a function to be executed before an Ajax request is sent. This is an Ajax Event.','send Ajax request',0,'',''),(264,'jQuery','Attach a function to be executed whenever an Ajax request completes successfully. This is an Ajax Event.','attach function',0,'',''),(265,'jQuery','Perform a custom animation of a set of CSS properties.','perform custom animation of set',0,'',''),(266,'jQuery','Select all elements that are in the progress of an animation at the time the selector is run.','run selector select elements',0,'',''),(267,'jQuery','Get the value of an attribute for the first element in the set of matched elements or set one or more attributes for every matched element.','get value in set',0,'',''),(268,'jQuery','Get the value of an attribute for the first element in the set of matched elements or set one or more attributes for every matched element.','get value of attribute',0,'',''),(269,'jQuery','Get the value of an attribute for the first element in the set of matched elements or set one or more attributes for every matched element.','set attributes for matched element',0,'',''),(270,'jQuery','Attach a handler to an event for the elements.','attach handler to event',0,'',''),(271,'jQuery','Bind an event handler to the “blur” JavaScript event, or trigger that event on an element.','bind event handler to blur JavaScript event',0,'',''),(272,'jQuery','Bind an event handler to the “blur” JavaScript event, or trigger that event on an element.','trigger event on element',0,'',''),(273,'jQuery','Determine whether or not the list has any callbacks attached. If a callback is provided as an argument, determine whether it is in a list.','provide callback as argument',0,'',''),(274,'jQuery','Bind an event handler to the “change” JavaScript event, or trigger that event on an element.','bind event handler to change JavaScript event',0,'',''),(275,'jQuery','Bind an event handler to the “change” JavaScript event, or trigger that event on an element.','trigger event on element',0,'',''),(276,'jQuery','Matches all elements that are checked or selected.','match elements',0,'',''),(277,'jQuery','Matches all elements that are checked or selected.','check elements',0,'',''),(278,'jQuery','Matches all elements that are checked or selected.','select elements',0,'',''),(279,'jQuery','Get the children of each element in the set of matched elements, optionally filtered by a selector.','get children of element',0,'',''),(280,'jQuery','Selects all elements with the given class.','select elements with given class',0,'',''),(281,'jQuery','Bind an event handler to the “click” JavaScript event, or trigger that event on an element.','bind event handler to click JavaScript event',0,'',''),(282,'jQuery','Bind an event handler to the “click” JavaScript event, or trigger that event on an element.','trigger event on element',0,'',''),(283,'jQuery','For each element in the set, get the first element that matches the selector by testing the element itself and traversing up through its ancestors in the DOM tree.','get first element for element',0,'',''),(284,'jQuery','For each element in the set, get the first element that matches the selector by testing the element itself and traversing up through its ancestors in the DOM tree.','match selector by testing',0,'',''),(285,'jQuery','For each element in the set, get the first element that matches the selector by testing the element itself and traversing up through its ancestors in the DOM tree.','match selector by traversing',0,'',''),(286,'jQuery','For each element in the set, get the first element that matches the selector by testing the element itself and traversing up through its ancestors in the DOM tree.','match first element by testing',0,'',''),(287,'jQuery','For each element in the set, get the first element that matches the selector by testing the element itself and traversing up through its ancestors in the DOM tree.','match first element by traversing',0,'',''),(288,'jQuery','Select all elements that contain the specified text.','select elements',0,'',''),(289,'jQuery','Get the children of each element in the set of matched elements, including text and comment nodes.','get children of element',0,'',''),(290,'jQuery','The DOM node context originally passed to jQuery(); if none was passed then context will likely be the document.','pass  to jQuery()',0,'',''),(291,'jQuery','The DOM node context originally passed to jQuery(); if none was passed then context will likely be the document.','pass none',0,'',''),(292,'jQuery','Bind an event handler to the “contextmenu” JavaScript event, or trigger that event on an element.','bind event handler to contextmenu JavaScript event',0,'',''),(293,'jQuery','Bind an event handler to the “contextmenu” JavaScript event, or trigger that event on an element.','trigger event on element',0,'',''),(294,'jQuery','Get the value of a computed style property for the first element in the set of matched elements or set one or more CSS properties for every matched element.','get value in set',0,'',''),(295,'jQuery','Get the value of a computed style property for the first element in the set of matched elements or set one or more CSS properties for every matched element.','get value of computed style property',0,'',''),(296,'jQuery','Get the value of a computed style property for the first element in the set of matched elements or set one or more CSS properties for every matched element.','set CSS properties for matched element',0,'',''),(297,'jQuery','Bind an event handler to the “dblclick” JavaScript event, or trigger that event on an element.','bind event handler to dblclick JavaScript event',0,'',''),(298,'jQuery','Bind an event handler to the “dblclick” JavaScript event, or trigger that event on an element.','trigger event on element',0,'',''),(299,'jQuery','Add handlers to be called when the Deferred object is either resolved or rejected.','resolve Deferred object',0,'',''),(300,'jQuery','Add handlers to be called when the Deferred object is resolved.','resolve Deferred object',0,'',''),(301,'jQuery','Determine whether a Deferred object has been resolved.','resolve Deferred object',0,'',''),(302,'jQuery','Add handlers to be called when the Deferred object generates progress notifications.','generate progress notifications',0,'',''),(303,'jQuery','Determine the current state of a Deferred object.','determine current state of Deferred object',0,'',''),(304,'jQuery','Add handlers to be called when the Deferred object is resolved, rejected, or still in progress.','resolve Deferred object',0,'',''),(305,'jQuery','Set a timer to delay execution of subsequent items in the queue.','set timer',0,'',''),(306,'jQuery','Attach a handler to one or more events for all elements that match the selector, now or in the future, based on a specific set of root elements.','attach handler in future',0,'',''),(307,'jQuery','Attach a handler to one or more events for all elements that match the selector, now or in the future, based on a specific set of root elements.','attach handler to events',0,'',''),(308,'jQuery','Attach a handler to one or more events for all elements that match the selector, now or in the future, based on a specific set of root elements.','match selector',0,'',''),(309,'jQuery','Attach a handler to one or more events for all elements that match the selector, now or in the future, based on a specific set of root elements.','match elements',0,'',''),(310,'jQuery','Execute the next function on the queue for the matched elements.','execute next function on queue',0,'',''),(311,'jQuery','Selects all elements that are descendants of a given ancestor.','select elements',0,'',''),(312,'jQuery','Selects all elements that are disabled.','select elements',0,'',''),(313,'jQuery','Iterate over a jQuery object, executing a function for each matched element.','execute function for matched element',0,'',''),(314,'jQuery','Selects all elements with the given tag name.','select elements with given tag name',0,'',''),(315,'jQuery','Select all elements that have no children (including text nodes).','select elements',0,'',''),(316,'jQuery','Selects all elements that are enabled.','select elements',0,'',''),(317,'jQuery','Selects all elements that are enabled.','enable elements',0,'',''),(318,'jQuery','Select the element at index n within the matched set.','select element at index n',0,'',''),(319,'jQuery','Bind an event handler to the “error” JavaScript event.','bind event handler to error JavaScript event',0,'',''),(320,'jQuery','An optional object of data passed to an event method when the current executing handler is bound.','pass  to event method',0,'',''),(321,'jQuery','An optional object of data passed to an event method when the current executing handler is bound.','bind current executing handler',0,'',''),(322,'jQuery','The element where the currently-called jQuery event handler was attached.','attach element',0,'',''),(323,'jQuery','The namespace specified when the event was triggered.','trigger event',0,'',''),(324,'jQuery','The last value returned by an event handler that was triggered by this event, unless the value was undefined.','trigger event handler',0,'',''),(325,'jQuery','Keeps the rest of the handlers from being executed and prevents the event from bubbling up the DOM tree.','prevent event from bubbling',0,'',''),(326,'jQuery','Prevents the event from bubbling up the DOM tree, preventing any parent handlers from being notified of the event.','prevent event from bubbling',0,'',''),(327,'jQuery','Prevents the event from bubbling up the DOM tree, preventing any parent handlers from being notified of the event.','prevent parent handlers',0,'',''),(328,'jQuery','Display the matched elements by fading them to opaque.','display matched elements by fading',0,'',''),(329,'jQuery','Hide the matched elements by fading them to transparent.','hide matched elements by fading',0,'',''),(330,'jQuery','Adjust the opacity of the matched elements.','adjust opacity of matched elements',0,'',''),(331,'jQuery','Display or hide the matched elements by animating their opacity.','hide matched elements by animating',0,'',''),(332,'jQuery','Reduce the set of matched elements to those that match the selector or pass the function’s test.','match selector',0,'',''),(333,'jQuery','Reduce the set of matched elements to those that match the selector or pass the function’s test.','pass test',0,'',''),(334,'jQuery','Get the descendants of each element in the current set of matched elements, filtered by a selector, jQuery object, or element.','get descendants of element',0,'',''),(335,'jQuery','Stop the currently-running animation, remove all queued animations, and complete all animations for the matched elements.','complete animations for matched elements',0,'',''),(336,'jQuery','Selects all elements that are the first child of their parent.','select elements',0,'',''),(337,'jQuery','Selects all elements that are the first among siblings of the same element name.','select elements',0,'',''),(338,'jQuery','Selects the first matched DOM element.','select first matched DOM element',0,'',''),(339,'jQuery','Bind an event handler to the “focus” JavaScript event, or trigger that event on an element.','bind event handler to focus JavaScript event',0,'',''),(340,'jQuery','Bind an event handler to the “focus” JavaScript event, or trigger that event on an element.','trigger event on element',0,'',''),(341,'jQuery','Bind an event handler to the “focusin” event.','bind event handler to focusin event',0,'',''),(342,'jQuery','Bind an event handler to the “focusout” JavaScript event.','bind event handler to focusout JavaScript event',0,'',''),(343,'jQuery','Retrieve the DOM elements matched by the jQuery object.','match  by jQuery object',0,'',''),(344,'jQuery','Reduce the set of matched elements to those that have a descendant that matches the selector or DOM element.','match selector DOM element',0,'',''),(345,'jQuery','Reduce the set of matched elements to those that have a descendant that matches the selector or DOM element.','match descendant',0,'',''),(346,'jQuery','Selects elements that have the specified attribute, with any value.','select elements',0,'',''),(347,'jQuery','Selects elements which contain at least one element that matches the specified selector.','match specified selector',0,'',''),(348,'jQuery','Selects all elements that are headers, like h1, h2, h3 and so on.','select elements',0,'',''),(349,'jQuery','Get the current computed height for the first element in the set of matched elements or set the height of every matched element.','get current computed height in set',0,'',''),(350,'jQuery','Get the current computed height for the first element in the set of matched elements or set the height of every matched element.','get current computed height for first element',0,'',''),(351,'jQuery','Get the current computed height for the first element in the set of matched elements or set the height of every matched element.','set height of matched element',0,'',''),(352,'jQuery','Selects all elements that are hidden.','select elements',0,'',''),(353,'jQuery','Selects all elements that are hidden.','hide elements',0,'',''),(354,'jQuery','Hide the matched elements.','hide matched elements',0,'',''),(355,'jQuery','Bind one or two handlers to the matched elements, to be executed when the mouse pointer enters and leaves the elements.','bind one two handlers to matched elements',0,'',''),(356,'jQuery','Bind one or two handlers to the matched elements, to be executed when the mouse pointer enters and leaves the elements.','enter elements',0,'',''),(357,'jQuery','Get the HTML contents of the first element in the set of matched elements or set the HTML contents of every matched element.','get contents of first element',0,'',''),(358,'jQuery','Get the HTML contents of the first element in the set of matched elements or set the HTML contents of every matched element.','set HTML contents of matched element',0,'',''),(359,'jQuery','Selects a single element with the given id attribute.','select single element with given id attribute',0,'',''),(360,'jQuery','Search for a given element from among the matched elements.','search  among matched elements',0,'',''),(361,'jQuery','Search for a given element from among the matched elements.','search  for given element',0,'',''),(362,'jQuery','Get the current computed inner height (including padding but not border) for the first element in the set of matched elements or set the inner height of every matched element.','get current computed inner height in set',0,'',''),(363,'jQuery','Get the current computed inner height (including padding but not border) for the first element in the set of matched elements or set the inner height of every matched element.','get current computed inner height for first element',0,'',''),(364,'jQuery','Get the current computed inner height (including padding but not border) for the first element in the set of matched elements or set the inner height of every matched element.','set inner height of matched element',0,'',''),(365,'jQuery','Get the current computed inner width (including padding but not border) for the first element in the set of matched elements or set the inner width of every matched element.','get current computed inner width in set',0,'',''),(366,'jQuery','Get the current computed inner width (including padding but not border) for the first element in the set of matched elements or set the inner width of every matched element.','get current computed inner width for first element',0,'',''),(367,'jQuery','Get the current computed inner width (including padding but not border) for the first element in the set of matched elements or set the inner width of every matched element.','set inner width of matched element',0,'',''),(368,'jQuery','Check the current matched set of elements against a selector, element, or jQuery object and return true if at least one of these elements matches the given arguments.','check current matched set of elements',0,'',''),(369,'jQuery','Check the current matched set of elements against a selector, element, or jQuery object and return true if at least one of these elements matches the given arguments.','match given arguments',0,'',''),(370,'jQuery','Return a collection of matched elements either found in the DOM based on passed argument(s) or created by passing an HTML string.','pass HTML string',0,'',''),(371,'jQuery','Perform an asynchronous HTTP (Ajax) request.','perform asynchronous HTTP request',0,'',''),(372,'jQuery','Handle custom Ajax options or modify existing options before each request is sent and before they are processed by $.ajax().','modify existing options',0,'',''),(373,'jQuery','Handle custom Ajax options or modify existing options before each request is sent and before they are processed by $.ajax().','send request',0,'',''),(374,'jQuery','Set default values for future Ajax requests. Its use is not recommended.','set default values for future Ajax requests',0,'',''),(375,'jQuery','Contains flags for the useragent, read from navigator.userAgent. This property was removed in jQuery 1.9 and is available only through the jQuery.migrate plugin. Please try to use feature detection instead.','read  from navigator.userAgent.',0,'',''),(376,'jQuery','A multi-purpose callbacks list object that provides a powerful way to manage callback lists.','provide powerful way',0,'',''),(377,'jQuery','A multi-purpose callbacks list object that provides a powerful way to manage callback lists.','manage callback lists',0,'',''),(378,'jQuery','Hook directly into jQuery to override how particular CSS properties are retrieved or set, normalize CSS property naming, or create custom properties.','retrieve particular CSS properties',0,'',''),(379,'jQuery','Hook directly into jQuery to override how particular CSS properties are retrieved or set, normalize CSS property naming, or create custom properties.','set particular CSS properties',0,'',''),(380,'jQuery','An object containing all CSS properties that may be used without a unit. The .css() method uses this object to see if it may append px to unitless values.','append px to unitless values',0,'',''),(381,'jQuery','Store arbitrary data associated with the specified element and/or return the value that was set.','set value',0,'',''),(382,'jQuery','Execute the next function on the queue for the matched element.','execute next function on queue',0,'',''),(383,'jQuery','A generic iterator function, which can be used to seamlessly iterate over both objects and arrays. Arrays and array-like objects with a length property (such as a function’s arguments object) are iterated by numeric index, from 0 to length-1. Other objects are iterated via their named properties.','iterate  over arrays',0,'',''),(384,'jQuery','A generic iterator function, which can be used to seamlessly iterate over both objects and arrays. Arrays and array-like objects with a length property (such as a function’s arguments object) are iterated by numeric index, from 0 to length-1. Other objects are iterated via their named properties.','iterate  over objects',0,'',''),(385,'jQuery','A generic iterator function, which can be used to seamlessly iterate over both objects and arrays. Arrays and array-like objects with a length property (such as a function’s arguments object) are iterated by numeric index, from 0 to length-1. Other objects are iterated via their named properties.','iterate arrays with length property',0,'',''),(386,'jQuery','A generic iterator function, which can be used to seamlessly iterate over both objects and arrays. Arrays and array-like objects with a length property (such as a function’s arguments object) are iterated by numeric index, from 0 to length-1. Other objects are iterated via their named properties.','iterate array-like objects with length property',0,'',''),(387,'jQuery','A generic iterator function, which can be used to seamlessly iterate over both objects and arrays. Arrays and array-like objects with a length property (such as a function’s arguments object) are iterated by numeric index, from 0 to length-1. Other objects are iterated via their named properties.','iterate other objects via named properties',0,'',''),(388,'jQuery','Takes a string and throws an exception containing it.','throw exception',0,'',''),(389,'jQuery','Merge the contents of an object onto the jQuery prototype to provide new jQuery instance methods.','provide new jQuery instance methods',0,'',''),(390,'jQuery','Load a JavaScript file from the server using a GET HTTP request, then execute it.','load JavaScript file from server',0,'',''),(391,'jQuery','Execute some JavaScript code globally.','execute JavaScript code',0,'',''),(392,'jQuery','Modify and filter HTML strings passed through jQuery manipulation methods.','pass  through jQuery manipulation methods',0,'',''),(393,'jQuery','Search for a specified value within an array and return its index (or -1 if not found).','search  for specified value',0,'',''),(394,'jQuery','Convert an array-like object into a true JavaScript array.','convert array-like object into true JavaScript array',0,'',''),(395,'jQuery','Translate all items in an array or object to new array of items.','translate items in array',0,'',''),(396,'jQuery','Create a serialized representation of an array, a plain object, or a jQuery object suitable for use in a URL query string or Ajax request. In case a jQuery object is passed, it should contain input elements with name/value properties.','pass jQuery object in case',0,'',''),(397,'jQuery','Show or manipulate the queue of functions to be executed on the matched element.','manipulate queue of functions',0,'',''),(398,'jQuery','Show or manipulate the queue of functions to be executed on the matched element.','execute  on matched element',0,'',''),(399,'jQuery','Handles errors thrown synchronously in functions wrapped in jQuery().','throw  in functions',0,'',''),(400,'jQuery','Handles errors thrown synchronously in functions wrapped in jQuery().','wrap  in jQuery()',0,'',''),(401,'jQuery','Creates a new copy of jQuery whose properties and methods can be modified without affecting the original jQuery object.','modify properties of jQuery',0,'',''),(402,'jQuery','Creates a new copy of jQuery whose properties and methods can be modified without affecting the original jQuery object.','modify properties without affecting',0,'',''),(403,'jQuery','Creates a new copy of jQuery whose properties and methods can be modified without affecting the original jQuery object.','modify methods of jQuery',0,'',''),(404,'jQuery','Creates a new copy of jQuery whose properties and methods can be modified without affecting the original jQuery object.','modify methods without affecting',0,'',''),(405,'jQuery','Creates a new copy of jQuery whose properties and methods can be modified without affecting the original jQuery object.','modify new copy of jQuery',0,'',''),(406,'jQuery','Creates a new copy of jQuery whose properties and methods can be modified without affecting the original jQuery object.','modify new copy without affecting',0,'',''),(407,'jQuery','Sorts an array of DOM elements, in place, with the duplicates removed. Note that this only works on arrays of DOM elements, not strings or numbers.','sort array with duplicates',0,'',''),(408,'jQuery','Sorts an array of DOM elements, in place, with the duplicates removed. Note that this only works on arrays of DOM elements, not strings or numbers.','sort array in place',0,'',''),(409,'jQuery','Sorts an array of DOM elements, in place, with the duplicates removed. Note that this only works on arrays of DOM elements, not strings or numbers.','sort array of DOM elements',0,'',''),(410,'jQuery','Provides a way to execute callback functions based on zero or more Thenable objects, usually Deferred objects that represent asynchronous events.','provide way',0,'',''),(411,'jQuery','Provides a way to execute callback functions based on zero or more Thenable objects, usually Deferred objects that represent asynchronous events.','execute callback functions',0,'',''),(412,'jQuery','Bind an event handler to the “keydown” JavaScript event, or trigger that event on an element.','bind event handler to keydown JavaScript event',0,'',''),(413,'jQuery','Bind an event handler to the “keydown” JavaScript event, or trigger that event on an element.','trigger event on element',0,'',''),(414,'jQuery','Bind an event handler to the “keypress” JavaScript event, or trigger that event on an element.','bind event handler to keypress JavaScript event',0,'',''),(415,'jQuery','Bind an event handler to the “keypress” JavaScript event, or trigger that event on an element.','trigger event on element',0,'',''),(416,'jQuery','Bind an event handler to the “keyup” JavaScript event, or trigger that event on an element.','bind event handler to keyup JavaScript event',0,'',''),(417,'jQuery','Bind an event handler to the “keyup” JavaScript event, or trigger that event on an element.','trigger event on element',0,'',''),(418,'jQuery','Selects all elements of the specified language.','select elements of specified language',0,'',''),(419,'jQuery','Selects all elements that are the last child of their parent.','select elements',0,'',''),(420,'jQuery','Selects all elements that are the last among siblings of the same element name.','select elements',0,'',''),(421,'jQuery','Selects the last matched element.','select last matched element',0,'',''),(422,'jQuery','Attach an event handler for all elements which match the current selector, now and in the future.','attach event handler for elements',0,'',''),(423,'jQuery','Attach an event handler for all elements which match the current selector, now and in the future.','match current selector',0,'',''),(424,'jQuery','Attach an event handler for all elements which match the current selector, now and in the future.','match elements',0,'',''),(425,'jQuery','Bind an event handler to the “load” JavaScript event.','bind event handler to load JavaScript event',0,'',''),(426,'jQuery','Select all elements at an index less than index within the matched set.','select elements at index',0,'',''),(427,'jQuery','Select all elements at an index less than index within the matched set.','select elements within matched set',0,'',''),(428,'jQuery','Select all elements at an index less than index within the matched set.','select elements than index',0,'',''),(429,'jQuery','Pass each element in the current matched set through a function, producing a new jQuery object containing the return values.','produce new jQuery',0,'',''),(430,'jQuery','Bind an event handler to the “mousedown” JavaScript event, or trigger that event on an element.','bind event handler to mousedown JavaScript event',0,'',''),(431,'jQuery','Bind an event handler to the “mousedown” JavaScript event, or trigger that event on an element.','trigger event on element',0,'',''),(432,'jQuery','Bind an event handler to be fired when the mouse enters an element, or trigger that handler on an element.','enter element',0,'',''),(433,'jQuery','Bind an event handler to the “mousemove” JavaScript event, or trigger that event on an element.','bind event handler to mousemove JavaScript event',0,'',''),(434,'jQuery','Bind an event handler to the “mousemove” JavaScript event, or trigger that event on an element.','trigger event on element',0,'',''),(435,'jQuery','Bind an event handler to the “mouseout” JavaScript event, or trigger that event on an element.','bind event handler to mouseout JavaScript event',0,'',''),(436,'jQuery','Bind an event handler to the “mouseout” JavaScript event, or trigger that event on an element.','trigger event on element',0,'',''),(437,'jQuery','Bind an event handler to the “mouseover” JavaScript event, or trigger that event on an element.','bind event handler to mouseover JavaScript event',0,'',''),(438,'jQuery','Bind an event handler to the “mouseover” JavaScript event, or trigger that event on an element.','trigger event on element',0,'',''),(439,'jQuery','Bind an event handler to the “mouseup” JavaScript event, or trigger that event on an element.','bind event handler to mouseup JavaScript event',0,'',''),(440,'jQuery','Bind an event handler to the “mouseup” JavaScript event, or trigger that event on an element.','trigger event on element',0,'',''),(441,'jQuery','Matches elements that match all of the specified attribute filters.','match matches elements',0,'',''),(442,'jQuery','Get the immediately following sibling of each element in the set of matched elements. If a selector is provided, it retrieves the next sibling only if it matches that selector.','get following sibling of element',0,'',''),(443,'jQuery','Get the immediately following sibling of each element in the set of matched elements. If a selector is provided, it retrieves the next sibling only if it matches that selector.','retrieve next sibling',0,'',''),(444,'jQuery','Get the immediately following sibling of each element in the set of matched elements. If a selector is provided, it retrieves the next sibling only if it matches that selector.','match selector',0,'',''),(445,'jQuery','Get the immediately following sibling of each element in the set of matched elements. If a selector is provided, it retrieves the next sibling only if it matches that selector.','provide selector',0,'',''),(446,'jQuery','Selects all next elements matching “next” that are immediately preceded by a sibling “prev”.','select next elements',0,'',''),(447,'jQuery','Selects all sibling elements that follow after the “prev” element, have the same parent, and match the filtering “siblings” selector.','select sibling elements',0,'',''),(448,'jQuery','Selects all sibling elements that follow after the “prev” element, have the same parent, and match the filtering “siblings” selector.','match filtering siblings selector',0,'',''),(449,'jQuery','Get all following siblings of each element in the set of matched elements, optionally filtered by a selector.','get following siblings of element',0,'',''),(450,'jQuery','Selects all elements that do not match the given selector.','select elements',0,'',''),(451,'jQuery','Selects all elements that are the nth-child of their parent.','select elements',0,'',''),(452,'jQuery','Selects all elements that are the nth-child of their parent, counting from the last element to the first.','select elements',0,'',''),(453,'jQuery','Selects all elements that are the nth-child of their parent, counting from the last element to the first.','count  from last element',0,'',''),(454,'jQuery','Selects all the elements that are the nth-child of their parent in relation to siblings with the same element name, counting from the last element to the first.','select elements',0,'',''),(455,'jQuery','Selects all the elements that are the nth-child of their parent in relation to siblings with the same element name, counting from the last element to the first.','count elements from last element',0,'',''),(456,'jQuery','Selects all the elements that are the nth-child of their parent in relation to siblings with the same element name, counting from the last element to the first.','count elements to siblings',0,'',''),(457,'jQuery','Selects all elements that are the nth child of their parent in relation to siblings with the same element name.','select elements',0,'',''),(458,'jQuery','Get the current coordinates of the first element, or set the coordinates of every element, in the set of matched elements, relative to the document.','get current coordinates of first element',0,'',''),(459,'jQuery','Get the current coordinates of the first element, or set the coordinates of every element, in the set of matched elements, relative to the document.','set coordinates in set',0,'',''),(460,'jQuery','Get the current coordinates of the first element, or set the coordinates of every element, in the set of matched elements, relative to the document.','set coordinates of element',0,'',''),(461,'jQuery','Get the closest ancestor element that is positioned.','get closest ancestor element',0,'',''),(462,'jQuery','Attach an event handler function for one or more events to the selected elements.','attach event handler function for events',0,'',''),(463,'jQuery','Attach an event handler function for one or more events to the selected elements.','attach event handler function to selected elements',0,'',''),(464,'jQuery','Attach a handler to an event for the elements. The handler is executed at most once per element per event type.','attach handler to event',0,'',''),(465,'jQuery','Attach a handler to an event for the elements. The handler is executed at most once per element per event type.','execute handler',0,'',''),(466,'jQuery','Selects all elements that are the only child of their parent.','select elements',0,'',''),(467,'jQuery','Selects all elements that have no siblings with the same element name.','select elements',0,'',''),(468,'jQuery','Get the current computed outer height (including padding, border, and optionally margin) for the first element in the set of matched elements or set the outer height of every matched element.','get current computed outer height in set',0,'',''),(469,'jQuery','Get the current computed outer height (including padding, border, and optionally margin) for the first element in the set of matched elements or set the outer height of every matched element.','get current computed outer height for first element',0,'',''),(470,'jQuery','Get the current computed outer height (including padding, border, and optionally margin) for the first element in the set of matched elements or set the outer height of every matched element.','set outer height of matched element',0,'',''),(471,'jQuery','Get the current computed outer width (including padding, border, and optionally margin) for the first element in the set of matched elements or set the outer width of every matched element.','get current computed outer width in set',0,'',''),(472,'jQuery','Get the current computed outer width (including padding, border, and optionally margin) for the first element in the set of matched elements or set the outer width of every matched element.','get current computed outer width for first element',0,'',''),(473,'jQuery','Get the current computed outer width (including padding, border, and optionally margin) for the first element in the set of matched elements or set the outer width of every matched element.','set outer width of matched element',0,'',''),(474,'jQuery','Get the parent of each element in the current set of matched elements, optionally filtered by a selector.','get parent of element',0,'',''),(475,'jQuery','Select all elements that have at least one child node (either an element or text).','select elements',0,'',''),(476,'jQuery','Get the ancestors of each element in the current set of matched elements, optionally filtered by a selector.','get ancestors of element',0,'',''),(477,'jQuery','Get the current coordinates of the first element in the set of matched elements, relative to the offset parent.','get current coordinates of first element',0,'',''),(478,'jQuery','Get the immediately preceding sibling of each element in the set of matched elements. If a selector is provided, it retrieves the previous sibling only if it matches that selector.','get preceding sibling of element',0,'',''),(479,'jQuery','Get the immediately preceding sibling of each element in the set of matched elements. If a selector is provided, it retrieves the previous sibling only if it matches that selector.','retrieve previous sibling',0,'',''),(480,'jQuery','Get the immediately preceding sibling of each element in the set of matched elements. If a selector is provided, it retrieves the previous sibling only if it matches that selector.','match selector',0,'',''),(481,'jQuery','Get the immediately preceding sibling of each element in the set of matched elements. If a selector is provided, it retrieves the previous sibling only if it matches that selector.','provide selector',0,'',''),(482,'jQuery','Get all preceding siblings of each element in the set of matched elements, optionally filtered by a selector.','get preceding siblings of element',0,'',''),(483,'jQuery','Return a Promise object to observe when all actions of a certain type bound to the collection, queued or not, have finished.','bind  to collection',0,'',''),(484,'jQuery','Get the value of a property for the first element in the set of matched elements or set one or more properties for every matched element.','get value in set',0,'',''),(485,'jQuery','Get the value of a property for the first element in the set of matched elements or set one or more properties for every matched element.','get value of property',0,'',''),(486,'jQuery','Get the value of a property for the first element in the set of matched elements or set one or more properties for every matched element.','set properties for matched element',0,'',''),(487,'jQuery','Show or manipulate the queue of functions to be executed on the matched elements.','manipulate queue of functions',0,'',''),(488,'jQuery','Show or manipulate the queue of functions to be executed on the matched elements.','execute  on matched elements',0,'',''),(489,'jQuery','Specify a function to execute when the DOM is fully loaded.','load DOM',0,'',''),(490,'jQuery','Replace each target element with the set of matched elements.','replace target element with set',0,'',''),(491,'jQuery','Replace each element in the set of matched elements with the provided new content and return the set of elements that was removed.','replace element in set',0,'',''),(492,'jQuery','Bind an event handler to the “resize” JavaScript event, or trigger that event on an element.','bind event handler to resize JavaScript event',0,'',''),(493,'jQuery','Bind an event handler to the “resize” JavaScript event, or trigger that event on an element.','trigger event on element',0,'',''),(494,'jQuery','Bind an event handler to the “scroll” JavaScript event, or trigger that event on an element.','bind event handler to scroll JavaScript event',0,'',''),(495,'jQuery','Bind an event handler to the “scroll” JavaScript event, or trigger that event on an element.','trigger event on element',0,'',''),(496,'jQuery','Get the current horizontal position of the scroll bar for the first element in the set of matched elements or set the horizontal position of the scroll bar for every matched element.','get current horizontal position in set',0,'',''),(497,'jQuery','Get the current horizontal position of the scroll bar for the first element in the set of matched elements or set the horizontal position of the scroll bar for every matched element.','get current horizontal position of scroll bar',0,'',''),(498,'jQuery','Get the current horizontal position of the scroll bar for the first element in the set of matched elements or set the horizontal position of the scroll bar for every matched element.','set horizontal position of scroll bar',0,'',''),(499,'jQuery','Get the current vertical position of the scroll bar for the first element in the set of matched elements or set the vertical position of the scroll bar for every matched element.','get current vertical position in set',0,'',''),(500,'jQuery','Get the current vertical position of the scroll bar for the first element in the set of matched elements or set the vertical position of the scroll bar for every matched element.','get current vertical position of scroll bar',0,'',''),(501,'jQuery','Get the current vertical position of the scroll bar for the first element in the set of matched elements or set the vertical position of the scroll bar for every matched element.','set vertical position of scroll bar',0,'',''),(502,'jQuery','Bind an event handler to the “select” JavaScript event, or trigger that event on an element.','bind event handler to select JavaScript event',0,'',''),(503,'jQuery','Bind an event handler to the “select” JavaScript event, or trigger that event on an element.','trigger event on element',0,'',''),(504,'jQuery','Selects all elements that are selected.','select elements',0,'',''),(505,'jQuery','Selects all elements that are selected.','select elements',0,'',''),(506,'jQuery','A selector representing selector passed to jQuery(), if any, when creating the original set.','pass  to jQuery()',0,'',''),(507,'jQuery','Encode a set of form elements as a string for submission.','encode set as string',0,'',''),(508,'jQuery','Encode a set of form elements as a string for submission.','encode set of form elements',0,'',''),(509,'jQuery','Encode a set of form elements as an array of names and values.','encode set as array',0,'',''),(510,'jQuery','Encode a set of form elements as an array of names and values.','encode set of form elements',0,'',''),(511,'jQuery','Display the matched elements.','display matched elements',0,'',''),(512,'jQuery','Get the siblings of each element in the set of matched elements, optionally filtered by a selector.','get siblings of element',0,'',''),(513,'jQuery','Display the matched elements with a sliding motion.','match elements with sliding motion',0,'',''),(514,'jQuery','Display or hide the matched elements with a sliding motion.','hide matched elements with sliding motion',0,'',''),(515,'jQuery','Hide the matched elements with a sliding motion.','hide matched elements with sliding motion',0,'',''),(516,'jQuery','Bind an event handler to the “submit” JavaScript event, or trigger that event on an element.','bind event handler to submit JavaScript event',0,'',''),(517,'jQuery','Bind an event handler to the “submit” JavaScript event, or trigger that event on an element.','trigger event on element',0,'',''),(518,'jQuery','Get the combined text contents of each element in the set of matched elements, including their descendants, or set the text contents of the matched elements.','get contents of element',0,'',''),(519,'jQuery','Get the combined text contents of each element in the set of matched elements, including their descendants, or set the text contents of the matched elements.','set text contents of matched elements',0,'',''),(520,'jQuery','Display or hide the matched elements.','hide matched elements',0,'',''),(521,'jQuery','Bind two or more handlers to the matched elements, to be executed on alternate clicks.','bind handlers to matched elements',0,'',''),(522,'jQuery','Bind two or more handlers to the matched elements, to be executed on alternate clicks.','execute  on alternate clicks',0,'',''),(523,'jQuery','Execute all handlers and behaviors attached to the matched elements for the given event type.','execute handlers',0,'',''),(524,'jQuery','Execute all handlers and behaviors attached to the matched elements for the given event type.','execute behaviors',0,'',''),(525,'jQuery','Execute all handlers and behaviors attached to the matched elements for the given event type.','attach  to matched elements',0,'',''),(526,'jQuery','Execute all handlers attached to an element for an event.','attach  for event',0,'',''),(527,'jQuery','Execute all handlers attached to an element for an event.','attach  to element',0,'',''),(528,'jQuery','Remove a handler from the event for all elements which match the current selector, based upon a specific set of root elements.','match current selector',0,'',''),(529,'jQuery','Remove a handler from the event for all elements which match the current selector, based upon a specific set of root elements.','match elements',0,'',''),(530,'jQuery','Bind an event handler to the “unload” JavaScript event.','bind event handler to unload JavaScript event',0,'',''),(531,'jQuery','Get the current value of the first element in the set of matched elements or set the value of every matched element.','get current value in set',0,'',''),(532,'jQuery','Get the current value of the first element in the set of matched elements or set the value of every matched element.','get current value of first element',0,'',''),(533,'jQuery','Get the current value of the first element in the set of matched elements or set the value of every matched element.','set value of matched element',0,'',''),(534,'jQuery','Selects all elements that are visible.','select elements',0,'',''),(535,'jQuery','Get the current computed width for the first element in the set of matched elements or set the width of every matched element.','get current computed width in set',0,'',''),(536,'jQuery','Get the current computed width for the first element in the set of matched elements or set the width of every matched element.','get current computed width for first element',0,'',''),(537,'jQuery','Get the current computed width for the first element in the set of matched elements or set the width of every matched element.','set width of matched element',0,'',''),(538,'jQuery','Wrap an HTML structure around each element in the set of matched elements.','wrap HTML structure around element',0,'',''),(539,'jQuery','Wrap an HTML structure around all elements in the set of matched elements.','wrap HTML structure around elements',0,'',''),(540,'jQuery','Wrap an HTML structure around the content of each element in the set of matched elements.','wrap HTML structure around content',0,'',''),(541,'orjson','History is littered with hundreds of conflicts over the future of a community, group, location or business that were \"resolved\" when one of the parties stepped ahead and destroyed what was there. With the original point of contention destroyed, the debates would fall to the wayside. Archive Team believes that by duplicated condemned data, the conversation and debate can continue, as well as the richness and insight gained by keeping the materials. Our projects have ranged in size from a single volunteer downloading the data to a small-but-critical site, to over 100 volunteers stepping forward to acquire terabytes of user-created data to save for future generations.\n\nThe main site for Archive Team is at archiveteam.org and contains up to the date information on various projects, manifestos, plans and walkthroughs.\n\nThis collection contains the output of many Archive Team projects, both ongoing and completed. Thanks to the generous providing of disk space by the Internet Archive, multi-terabyte datasets can be made available, as well as in use by the Wayback Machine, providing a path back to lost websites and work. \n\nOur collection has grown to the point of having sub-collections for the type of data we acquire. If you are seeking to browse the contents of these collections, the Wayback Machine is the best first stop. Otherwise, you are free to dig into the stacks to see what you may find.\n\nThe Archive Team Panic Downloads are full pulldowns of currently extant websites, meant to serve as emergency backups for needed sites that are in danger of closing, or which will be missed dearly if suddenly lost due to hard drive crashes or server failures.','resolve community',0,'',''),(542,'orjson','History is littered with hundreds of conflicts over the future of a community, group, location or business that were \"resolved\" when one of the parties stepped ahead and destroyed what was there. With the original point of contention destroyed, the debates would fall to the wayside. Archive Team believes that by duplicated condemned data, the conversation and debate can continue, as well as the richness and insight gained by keeping the materials. Our projects have ranged in size from a single volunteer downloading the data to a small-but-critical site, to over 100 volunteers stepping forward to acquire terabytes of user-created data to save for future generations.\n\nThe main site for Archive Team is at archiveteam.org and contains up to the date information on various projects, manifestos, plans and walkthroughs.\n\nThis collection contains the output of many Archive Team projects, both ongoing and completed. Thanks to the generous providing of disk space by the Internet Archive, multi-terabyte datasets can be made available, as well as in use by the Wayback Machine, providing a path back to lost websites and work. \n\nOur collection has grown to the point of having sub-collections for the type of data we acquire. If you are seeking to browse the contents of these collections, the Wayback Machine is the best first stop. Otherwise, you are free to dig into the stacks to see what you may find.\n\nThe Archive Team Panic Downloads are full pulldowns of currently extant websites, meant to serve as emergency backups for needed sites that are in danger of closing, or which will be missed dearly if suddenly lost due to hard drive crashes or server failures.','resolve location',0,'',''),(543,'orjson','History is littered with hundreds of conflicts over the future of a community, group, location or business that were \"resolved\" when one of the parties stepped ahead and destroyed what was there. With the original point of contention destroyed, the debates would fall to the wayside. Archive Team believes that by duplicated condemned data, the conversation and debate can continue, as well as the richness and insight gained by keeping the materials. Our projects have ranged in size from a single volunteer downloading the data to a small-but-critical site, to over 100 volunteers stepping forward to acquire terabytes of user-created data to save for future generations.\n\nThe main site for Archive Team is at archiveteam.org and contains up to the date information on various projects, manifestos, plans and walkthroughs.\n\nThis collection contains the output of many Archive Team projects, both ongoing and completed. Thanks to the generous providing of disk space by the Internet Archive, multi-terabyte datasets can be made available, as well as in use by the Wayback Machine, providing a path back to lost websites and work. \n\nOur collection has grown to the point of having sub-collections for the type of data we acquire. If you are seeking to browse the contents of these collections, the Wayback Machine is the best first stop. Otherwise, you are free to dig into the stacks to see what you may find.\n\nThe Archive Team Panic Downloads are full pulldowns of currently extant websites, meant to serve as emergency backups for needed sites that are in danger of closing, or which will be missed dearly if suddenly lost due to hard drive crashes or server failures.','resolve business',0,'',''),(544,'orjson','History is littered with hundreds of conflicts over the future of a community, group, location or business that were \"resolved\" when one of the parties stepped ahead and destroyed what was there. With the original point of contention destroyed, the debates would fall to the wayside. Archive Team believes that by duplicated condemned data, the conversation and debate can continue, as well as the richness and insight gained by keeping the materials. Our projects have ranged in size from a single volunteer downloading the data to a small-but-critical site, to over 100 volunteers stepping forward to acquire terabytes of user-created data to save for future generations.\n\nThe main site for Archive Team is at archiveteam.org and contains up to the date information on various projects, manifestos, plans and walkthroughs.\n\nThis collection contains the output of many Archive Team projects, both ongoing and completed. Thanks to the generous providing of disk space by the Internet Archive, multi-terabyte datasets can be made available, as well as in use by the Wayback Machine, providing a path back to lost websites and work. \n\nOur collection has grown to the point of having sub-collections for the type of data we acquire. If you are seeking to browse the contents of these collections, the Wayback Machine is the best first stop. Otherwise, you are free to dig into the stacks to see what you may find.\n\nThe Archive Team Panic Downloads are full pulldowns of currently extant websites, meant to serve as emergency backups for needed sites that are in danger of closing, or which will be missed dearly if suddenly lost due to hard drive crashes or server failures.','resolve group',0,'',''),(545,'orjson','History is littered with hundreds of conflicts over the future of a community, group, location or business that were \"resolved\" when one of the parties stepped ahead and destroyed what was there. With the original point of contention destroyed, the debates would fall to the wayside. Archive Team believes that by duplicated condemned data, the conversation and debate can continue, as well as the richness and insight gained by keeping the materials. Our projects have ranged in size from a single volunteer downloading the data to a small-but-critical site, to over 100 volunteers stepping forward to acquire terabytes of user-created data to save for future generations.\n\nThe main site for Archive Team is at archiveteam.org and contains up to the date information on various projects, manifestos, plans and walkthroughs.\n\nThis collection contains the output of many Archive Team projects, both ongoing and completed. Thanks to the generous providing of disk space by the Internet Archive, multi-terabyte datasets can be made available, as well as in use by the Wayback Machine, providing a path back to lost websites and work. \n\nOur collection has grown to the point of having sub-collections for the type of data we acquire. If you are seeking to browse the contents of these collections, the Wayback Machine is the best first stop. Otherwise, you are free to dig into the stacks to see what you may find.\n\nThe Archive Team Panic Downloads are full pulldowns of currently extant websites, meant to serve as emergency backups for needed sites that are in danger of closing, or which will be missed dearly if suddenly lost due to hard drive crashes or server failures.','download data to small-but-critical site',0,'',''),(546,'orjson','History is littered with hundreds of conflicts over the future of a community, group, location or business that were \"resolved\" when one of the parties stepped ahead and destroyed what was there. With the original point of contention destroyed, the debates would fall to the wayside. Archive Team believes that by duplicated condemned data, the conversation and debate can continue, as well as the richness and insight gained by keeping the materials. Our projects have ranged in size from a single volunteer downloading the data to a small-but-critical site, to over 100 volunteers stepping forward to acquire terabytes of user-created data to save for future generations.\n\nThe main site for Archive Team is at archiveteam.org and contains up to the date information on various projects, manifestos, plans and walkthroughs.\n\nThis collection contains the output of many Archive Team projects, both ongoing and completed. Thanks to the generous providing of disk space by the Internet Archive, multi-terabyte datasets can be made available, as well as in use by the Wayback Machine, providing a path back to lost websites and work. \n\nOur collection has grown to the point of having sub-collections for the type of data we acquire. If you are seeking to browse the contents of these collections, the Wayback Machine is the best first stop. Otherwise, you are free to dig into the stacks to see what you may find.\n\nThe Archive Team Panic Downloads are full pulldowns of currently extant websites, meant to serve as emergency backups for needed sites that are in danger of closing, or which will be missed dearly if suddenly lost due to hard drive crashes or server failures.','acquire terabytes of user-created data',0,'',''),(547,'orjson','History is littered with hundreds of conflicts over the future of a community, group, location or business that were \"resolved\" when one of the parties stepped ahead and destroyed what was there. With the original point of contention destroyed, the debates would fall to the wayside. Archive Team believes that by duplicated condemned data, the conversation and debate can continue, as well as the richness and insight gained by keeping the materials. Our projects have ranged in size from a single volunteer downloading the data to a small-but-critical site, to over 100 volunteers stepping forward to acquire terabytes of user-created data to save for future generations.\n\nThe main site for Archive Team is at archiveteam.org and contains up to the date information on various projects, manifestos, plans and walkthroughs.\n\nThis collection contains the output of many Archive Team projects, both ongoing and completed. Thanks to the generous providing of disk space by the Internet Archive, multi-terabyte datasets can be made available, as well as in use by the Wayback Machine, providing a path back to lost websites and work. \n\nOur collection has grown to the point of having sub-collections for the type of data we acquire. If you are seeking to browse the contents of these collections, the Wayback Machine is the best first stop. Otherwise, you are free to dig into the stacks to see what you may find.\n\nThe Archive Team Panic Downloads are full pulldowns of currently extant websites, meant to serve as emergency backups for needed sites that are in danger of closing, or which will be missed dearly if suddenly lost due to hard drive crashes or server failures.','save  for future generations',0,'',''),(548,'orjson','History is littered with hundreds of conflicts over the future of a community, group, location or business that were \"resolved\" when one of the parties stepped ahead and destroyed what was there. With the original point of contention destroyed, the debates would fall to the wayside. Archive Team believes that by duplicated condemned data, the conversation and debate can continue, as well as the richness and insight gained by keeping the materials. Our projects have ranged in size from a single volunteer downloading the data to a small-but-critical site, to over 100 volunteers stepping forward to acquire terabytes of user-created data to save for future generations.\n\nThe main site for Archive Team is at archiveteam.org and contains up to the date information on various projects, manifestos, plans and walkthroughs.\n\nThis collection contains the output of many Archive Team projects, both ongoing and completed. Thanks to the generous providing of disk space by the Internet Archive, multi-terabyte datasets can be made available, as well as in use by the Wayback Machine, providing a path back to lost websites and work. \n\nOur collection has grown to the point of having sub-collections for the type of data we acquire. If you are seeking to browse the contents of these collections, the Wayback Machine is the best first stop. Otherwise, you are free to dig into the stacks to see what you may find.\n\nThe Archive Team Panic Downloads are full pulldowns of currently extant websites, meant to serve as emergency backups for needed sites that are in danger of closing, or which will be missed dearly if suddenly lost due to hard drive crashes or server failures.','acquire data',0,'',''),(549,'orjson','The main site for Archive Team is at archiveteam.org and contains up to the date information on various projects, manifestos, plans and walkthroughs.\n\nThis collection contains the output of many Archive Team projects, both ongoing and completed. Thanks to the generous providing of disk space by the Internet Archive, multi-terabyte datasets can be made available, as well as in use by the Wayback Machine, providing a path back to lost websites and work. \n\nOur collection has grown to the point of having sub-collections for the type of data we acquire. If you are seeking to browse the contents of these collections, the Wayback Machine is the best first stop. Otherwise, you are free to dig into the stacks to see what you may find.\n\nThe Archive Team Panic Downloads are full pulldowns of currently extant websites, meant to serve as emergency backups for needed sites that are in danger of closing, or which will be missed dearly if suddenly lost due to hard drive crashes or server failures.','acquire data',0,'',''),(550,'orjson','This collection contains the output of many Archive Team projects, both ongoing and completed. Thanks to the generous providing of disk space by the Internet Archive, multi-terabyte datasets can be made available, as well as in use by the Wayback Machine, providing a path back to lost websites and work. \n\nOur collection has grown to the point of having sub-collections for the type of data we acquire. If you are seeking to browse the contents of these collections, the Wayback Machine is the best first stop. Otherwise, you are free to dig into the stacks to see what you may find.\n\nThe Archive Team Panic Downloads are full pulldowns of currently extant websites, meant to serve as emergency backups for needed sites that are in danger of closing, or which will be missed dearly if suddenly lost due to hard drive crashes or server failures.','acquire data',0,'',''),(551,'orjson','Our collection has grown to the point of having sub-collections for the type of data we acquire. If you are seeking to browse the contents of these collections, the Wayback Machine is the best first stop. Otherwise, you are free to dig into the stacks to see what you may find.\n\nThe Archive Team Panic Downloads are full pulldowns of currently extant websites, meant to serve as emergency backups for needed sites that are in danger of closing, or which will be missed dearly if suddenly lost due to hard drive crashes or server failures.','acquire data',0,'',''),(552,'orjson','orjson is a fast, correct JSON library for Python. It\nbenchmarks as the fastest Python\nlibrary for JSON and is more correct than the standard json library or other\nthird-party libraries. It serializes\ndataclass,\ndatetime,\nnumpy, and\nUUID instances natively.','serialize dataclass',0,'',''),(553,'orjson','orjson is a fast, correct JSON library for Python. It\nbenchmarks as the fastest Python\nlibrary for JSON and is more correct than the standard json library or other\nthird-party libraries. It serializes\ndataclass,\ndatetime,\nnumpy, and\nUUID instances natively.','serialize datetime',0,'',''),(554,'orjson','orjson is a fast, correct JSON library for Python. It\nbenchmarks as the fastest Python\nlibrary for JSON and is more correct than the standard json library or other\nthird-party libraries. It serializes\ndataclass,\ndatetime,\nnumpy, and\nUUID instances natively.','serialize numpy',0,'',''),(555,'orjson','orjson is a fast, correct JSON library for Python. It\nbenchmarks as the fastest Python\nlibrary for JSON and is more correct than the standard json library or other\nthird-party libraries. It serializes\ndataclass,\ndatetime,\nnumpy, and\nUUID instances natively.','serialize UUID instances',0,'',''),(556,'orjson','To install a wheel from PyPI:','install wheel from pypi',1,'http://web.archive.org/web/20220903063155/https://github.com/ijl/orjson','user-content-install'),(557,'orjson','This is an example of serializing, with options specified, and deserializing:','serialize  with options',1,'http://web.archive.org/web/20220903063155/https://github.com/ijl/orjson','user-content-quickstart'),(558,'orjson','This is an example of serializing, with options specified, and deserializing:','deserialize  with options',1,'http://web.archive.org/web/20220903063155/https://github.com/ijl/orjson','user-content-quickstart'),(559,'orjson','orjson version 3 serializes more types than version 2. Subclasses of str,\nint, dict, and list are now serialized. This is faster and more similar\nto the standard library. It can be disabled with\norjson.OPT_PASSTHROUGH_SUBCLASS.dataclasses.dataclass instances\nare now serialized by default and cannot be customized in a\ndefault function unless option=orjson.OPT_PASSTHROUGH_DATACLASS is\nspecified. uuid.UUID instances are serialized by default.\nFor any type that is now serialized,\nimplementations in a default function and options enabling them can be\nremoved but do not need to be. There was no change in deserialization.','serialize more types than version',0,'',''),(560,'orjson','orjson version 3 serializes more types than version 2. Subclasses of str,\nint, dict, and list are now serialized. This is faster and more similar\nto the standard library. It can be disabled with\norjson.OPT_PASSTHROUGH_SUBCLASS.dataclasses.dataclass instances\nare now serialized by default and cannot be customized in a\ndefault function unless option=orjson.OPT_PASSTHROUGH_DATACLASS is\nspecified. uuid.UUID instances are serialized by default.\nFor any type that is now serialized,\nimplementations in a default function and options enabling them can be\nremoved but do not need to be. There was no change in deserialization.','serialize subclasses of str',0,'',''),(561,'nltk','Strangely, python don\'t seem to provide a quick/easy way to get mathematical combinations/choose (nCr). It\'s sort of essential for the RIBES algorithms and most rank-based Machine Translation metrics.','provide quick/easy way to get mathematical combinations/choose',0,'',''),(562,'orjson','orjson version 3 serializes more types than version 2. Subclasses of str,\nint, dict, and list are now serialized. This is faster and more similar\nto the standard library. It can be disabled with\norjson.OPT_PASSTHROUGH_SUBCLASS.dataclasses.dataclass instances\nare now serialized by default and cannot be customized in a\ndefault function unless option=orjson.OPT_PASSTHROUGH_DATACLASS is\nspecified. uuid.UUID instances are serialized by default.\nFor any type that is now serialized,\nimplementations in a default function and options enabling them can be\nremoved but do not need to be. There was no change in deserialization.','serialize dataclasses.dataclass instances',0,'',''),(563,'nltk','Would it be okay to add this function to NLTK? It seems to be the fastest computation of combinations.','add function to NLTK',1,'https://web.archive.org/web/20210415060141/https://github.com/nltk/nltk/issues/1181',''),(564,'orjson','orjson version 3 serializes more types than version 2. Subclasses of str,\nint, dict, and list are now serialized. This is faster and more similar\nto the standard library. It can be disabled with\norjson.OPT_PASSTHROUGH_SUBCLASS.dataclasses.dataclass instances\nare now serialized by default and cannot be customized in a\ndefault function unless option=orjson.OPT_PASSTHROUGH_DATACLASS is\nspecified. uuid.UUID instances are serialized by default.\nFor any type that is now serialized,\nimplementations in a default function and options enabling them can be\nremoved but do not need to be. There was no change in deserialization.','specify option = orjson.OPT_PASSTHROUGH_DATACLASS',0,'',''),(565,'nltk','If it\'s alright to add the combination calculation function to NLTK where should it go? nltk.util? Or should there be a nltk.math?','add combination calculation function to NLTK',0,'',''),(566,'orjson','orjson version 3 serializes more types than version 2. Subclasses of str,\nint, dict, and list are now serialized. This is faster and more similar\nto the standard library. It can be disabled with\norjson.OPT_PASSTHROUGH_SUBCLASS.dataclasses.dataclass instances\nare now serialized by default and cannot be customized in a\ndefault function unless option=orjson.OPT_PASSTHROUGH_DATACLASS is\nspecified. uuid.UUID instances are serialized by default.\nFor any type that is now serialized,\nimplementations in a default function and options enabling them can be\nremoved but do not need to be. There was no change in deserialization.','serialize uuid.UUID instances',0,'',''),(567,'nltk','+1 for nCr function. I wonder if any of the external packages used in nltk already have that.','use  in nltk',0,'',''),(568,'orjson','To migrate from the standard library, the largest difference is that\norjson.dumps returns bytes and json.dumps returns a str. Users with\ndict objects using non-str keys should specify\noption=orjson.OPT_NON_STR_KEYS. sort_keys is replaced by\noption=orjson.OPT_SORT_KEYS. indent is replaced by\noption=orjson.OPT_INDENT_2 and other levels of indentation are not\nsupported.','replace sort_keys',0,'',''),(569,'nltk','That\'s surprising. It might be worth mentioning that to them. Anyway, I\'m happy for us to include nCr. It probably belongs in nltk.util.','include nCr',0,'',''),(570,'orjson','To migrate from the standard library, the largest difference is that\norjson.dumps returns bytes and json.dumps returns a str. Users with\ndict objects using non-str keys should specify\noption=orjson.OPT_NON_STR_KEYS. sort_keys is replaced by\noption=orjson.OPT_SORT_KEYS. indent is replaced by\noption=orjson.OPT_INDENT_2 and other levels of indentation are not\nsupported.','replace indent',0,'',''),(571,'nltk','This version of the NLTK book is updated for Python 3 and NLTK 3.\r\n  The first edition of the book, published by O\'Reilly, is available at\r\n  http://nltk.org/book_1ed/.\r\n  (There are currently no plans for a second edition of the book.)','update  for Python',0,'',''),(572,'orjson','dumps() serializes Python objects to JSON.','serialize Python objects to JSON',0,'',''),(573,'nltk','This version of the NLTK book is updated for Python 3 and NLTK 3.\r\n  The first edition of the book, published by O\'Reilly, is available at\r\n  http://nltk.org/book_1ed/.\r\n  (There are currently no plans for a second edition of the book.)','update  for NLTK',0,'',''),(574,'orjson','It natively serializes\nstr, dict, list, tuple, int, float, bool,\ndataclasses.dataclass, typing.TypedDict, datetime.datetime,\ndatetime.date, datetime.time, uuid.UUID, numpy.ndarray, and\nNone instances. It supports arbitrary types through default. It\nserializes subclasses of str, int, dict, list,\ndataclasses.dataclass, and enum.Enum. It does not serialize subclasses\nof tuple to avoid serializing namedtuple objects as arrays. To avoid\nserializing subclasses, specify the option orjson.OPT_PASSTHROUGH_SUBCLASS.','serialize none',0,'',''),(575,'nltk','History is littered with hundreds of conflicts over the future of a community, group, location or business that were \"resolved\" when one of the parties stepped ahead and destroyed what was there. With the original point of contention destroyed, the debates would fall to the wayside. Archive Team believes that by duplicated condemned data, the conversation and debate can continue, as well as the richness and insight gained by keeping the materials. Our projects have ranged in size from a single volunteer downloading the data to a small-but-critical site, to over 100 volunteers stepping forward to acquire terabytes of user-created data to save for future generations.\r\n\r\nThe main site for Archive Team is at archiveteam.org and contains up to the date information on various projects, manifestos, plans and walkthroughs.\r\n\r\nThis collection contains the output of many Archive Team projects, both ongoing and completed. Thanks to the generous providing of disk space by the Internet Archive, multi-terabyte datasets can be made available, as well as in use by the Wayback Machine, providing a path back to lost websites and work. \r\n\r\nOur collection has grown to the point of having sub-collections for the type of data we acquire. If you are seeking to browse the contents of these collections, the Wayback Machine is the best first stop. Otherwise, you are free to dig into the stacks to see what you may find.\r\n\r\nThe Archive Team Panic Downloads are full pulldowns of currently extant websites, meant to serve as emergency backups for needed sites that are in danger of closing, or which will be missed dearly if suddenly lost due to hard drive crashes or server failures.','resolve community',0,'',''),(576,'orjson','It natively serializes\nstr, dict, list, tuple, int, float, bool,\ndataclasses.dataclass, typing.TypedDict, datetime.datetime,\ndatetime.date, datetime.time, uuid.UUID, numpy.ndarray, and\nNone instances. It supports arbitrary types through default. It\nserializes subclasses of str, int, dict, list,\ndataclasses.dataclass, and enum.Enum. It does not serialize subclasses\nof tuple to avoid serializing namedtuple objects as arrays. To avoid\nserializing subclasses, specify the option orjson.OPT_PASSTHROUGH_SUBCLASS.','serialize str',0,'',''),(577,'nltk','History is littered with hundreds of conflicts over the future of a community, group, location or business that were \"resolved\" when one of the parties stepped ahead and destroyed what was there. With the original point of contention destroyed, the debates would fall to the wayside. Archive Team believes that by duplicated condemned data, the conversation and debate can continue, as well as the richness and insight gained by keeping the materials. Our projects have ranged in size from a single volunteer downloading the data to a small-but-critical site, to over 100 volunteers stepping forward to acquire terabytes of user-created data to save for future generations.\r\n\r\nThe main site for Archive Team is at archiveteam.org and contains up to the date information on various projects, manifestos, plans and walkthroughs.\r\n\r\nThis collection contains the output of many Archive Team projects, both ongoing and completed. Thanks to the generous providing of disk space by the Internet Archive, multi-terabyte datasets can be made available, as well as in use by the Wayback Machine, providing a path back to lost websites and work. \r\n\r\nOur collection has grown to the point of having sub-collections for the type of data we acquire. If you are seeking to browse the contents of these collections, the Wayback Machine is the best first stop. Otherwise, you are free to dig into the stacks to see what you may find.\r\n\r\nThe Archive Team Panic Downloads are full pulldowns of currently extant websites, meant to serve as emergency backups for needed sites that are in danger of closing, or which will be missed dearly if suddenly lost due to hard drive crashes or server failures.','resolve location',0,'',''),(578,'orjson','It natively serializes\nstr, dict, list, tuple, int, float, bool,\ndataclasses.dataclass, typing.TypedDict, datetime.datetime,\ndatetime.date, datetime.time, uuid.UUID, numpy.ndarray, and\nNone instances. It supports arbitrary types through default. It\nserializes subclasses of str, int, dict, list,\ndataclasses.dataclass, and enum.Enum. It does not serialize subclasses\nof tuple to avoid serializing namedtuple objects as arrays. To avoid\nserializing subclasses, specify the option orjson.OPT_PASSTHROUGH_SUBCLASS.','serialize dict',0,'',''),(579,'nltk','History is littered with hundreds of conflicts over the future of a community, group, location or business that were \"resolved\" when one of the parties stepped ahead and destroyed what was there. With the original point of contention destroyed, the debates would fall to the wayside. Archive Team believes that by duplicated condemned data, the conversation and debate can continue, as well as the richness and insight gained by keeping the materials. Our projects have ranged in size from a single volunteer downloading the data to a small-but-critical site, to over 100 volunteers stepping forward to acquire terabytes of user-created data to save for future generations.\r\n\r\nThe main site for Archive Team is at archiveteam.org and contains up to the date information on various projects, manifestos, plans and walkthroughs.\r\n\r\nThis collection contains the output of many Archive Team projects, both ongoing and completed. Thanks to the generous providing of disk space by the Internet Archive, multi-terabyte datasets can be made available, as well as in use by the Wayback Machine, providing a path back to lost websites and work. \r\n\r\nOur collection has grown to the point of having sub-collections for the type of data we acquire. If you are seeking to browse the contents of these collections, the Wayback Machine is the best first stop. Otherwise, you are free to dig into the stacks to see what you may find.\r\n\r\nThe Archive Team Panic Downloads are full pulldowns of currently extant websites, meant to serve as emergency backups for needed sites that are in danger of closing, or which will be missed dearly if suddenly lost due to hard drive crashes or server failures.','resolve business',0,'',''),(580,'orjson','It natively serializes\nstr, dict, list, tuple, int, float, bool,\ndataclasses.dataclass, typing.TypedDict, datetime.datetime,\ndatetime.date, datetime.time, uuid.UUID, numpy.ndarray, and\nNone instances. It supports arbitrary types through default. It\nserializes subclasses of str, int, dict, list,\ndataclasses.dataclass, and enum.Enum. It does not serialize subclasses\nof tuple to avoid serializing namedtuple objects as arrays. To avoid\nserializing subclasses, specify the option orjson.OPT_PASSTHROUGH_SUBCLASS.','serialize list',0,'',''),(581,'nltk','History is littered with hundreds of conflicts over the future of a community, group, location or business that were \"resolved\" when one of the parties stepped ahead and destroyed what was there. With the original point of contention destroyed, the debates would fall to the wayside. Archive Team believes that by duplicated condemned data, the conversation and debate can continue, as well as the richness and insight gained by keeping the materials. Our projects have ranged in size from a single volunteer downloading the data to a small-but-critical site, to over 100 volunteers stepping forward to acquire terabytes of user-created data to save for future generations.\r\n\r\nThe main site for Archive Team is at archiveteam.org and contains up to the date information on various projects, manifestos, plans and walkthroughs.\r\n\r\nThis collection contains the output of many Archive Team projects, both ongoing and completed. Thanks to the generous providing of disk space by the Internet Archive, multi-terabyte datasets can be made available, as well as in use by the Wayback Machine, providing a path back to lost websites and work. \r\n\r\nOur collection has grown to the point of having sub-collections for the type of data we acquire. If you are seeking to browse the contents of these collections, the Wayback Machine is the best first stop. Otherwise, you are free to dig into the stacks to see what you may find.\r\n\r\nThe Archive Team Panic Downloads are full pulldowns of currently extant websites, meant to serve as emergency backups for needed sites that are in danger of closing, or which will be missed dearly if suddenly lost due to hard drive crashes or server failures.','resolve group',0,'',''),(582,'orjson','It natively serializes\nstr, dict, list, tuple, int, float, bool,\ndataclasses.dataclass, typing.TypedDict, datetime.datetime,\ndatetime.date, datetime.time, uuid.UUID, numpy.ndarray, and\nNone instances. It supports arbitrary types through default. It\nserializes subclasses of str, int, dict, list,\ndataclasses.dataclass, and enum.Enum. It does not serialize subclasses\nof tuple to avoid serializing namedtuple objects as arrays. To avoid\nserializing subclasses, specify the option orjson.OPT_PASSTHROUGH_SUBCLASS.','serialize tuple',0,'',''),(583,'nltk','History is littered with hundreds of conflicts over the future of a community, group, location or business that were \"resolved\" when one of the parties stepped ahead and destroyed what was there. With the original point of contention destroyed, the debates would fall to the wayside. Archive Team believes that by duplicated condemned data, the conversation and debate can continue, as well as the richness and insight gained by keeping the materials. Our projects have ranged in size from a single volunteer downloading the data to a small-but-critical site, to over 100 volunteers stepping forward to acquire terabytes of user-created data to save for future generations.\r\n\r\nThe main site for Archive Team is at archiveteam.org and contains up to the date information on various projects, manifestos, plans and walkthroughs.\r\n\r\nThis collection contains the output of many Archive Team projects, both ongoing and completed. Thanks to the generous providing of disk space by the Internet Archive, multi-terabyte datasets can be made available, as well as in use by the Wayback Machine, providing a path back to lost websites and work. \r\n\r\nOur collection has grown to the point of having sub-collections for the type of data we acquire. If you are seeking to browse the contents of these collections, the Wayback Machine is the best first stop. Otherwise, you are free to dig into the stacks to see what you may find.\r\n\r\nThe Archive Team Panic Downloads are full pulldowns of currently extant websites, meant to serve as emergency backups for needed sites that are in danger of closing, or which will be missed dearly if suddenly lost due to hard drive crashes or server failures.','download data to small-but-critical site',0,'',''),(584,'orjson','It natively serializes\nstr, dict, list, tuple, int, float, bool,\ndataclasses.dataclass, typing.TypedDict, datetime.datetime,\ndatetime.date, datetime.time, uuid.UUID, numpy.ndarray, and\nNone instances. It supports arbitrary types through default. It\nserializes subclasses of str, int, dict, list,\ndataclasses.dataclass, and enum.Enum. It does not serialize subclasses\nof tuple to avoid serializing namedtuple objects as arrays. To avoid\nserializing subclasses, specify the option orjson.OPT_PASSTHROUGH_SUBCLASS.','serialize int',0,'',''),(585,'nltk','History is littered with hundreds of conflicts over the future of a community, group, location or business that were \"resolved\" when one of the parties stepped ahead and destroyed what was there. With the original point of contention destroyed, the debates would fall to the wayside. Archive Team believes that by duplicated condemned data, the conversation and debate can continue, as well as the richness and insight gained by keeping the materials. Our projects have ranged in size from a single volunteer downloading the data to a small-but-critical site, to over 100 volunteers stepping forward to acquire terabytes of user-created data to save for future generations.\r\n\r\nThe main site for Archive Team is at archiveteam.org and contains up to the date information on various projects, manifestos, plans and walkthroughs.\r\n\r\nThis collection contains the output of many Archive Team projects, both ongoing and completed. Thanks to the generous providing of disk space by the Internet Archive, multi-terabyte datasets can be made available, as well as in use by the Wayback Machine, providing a path back to lost websites and work. \r\n\r\nOur collection has grown to the point of having sub-collections for the type of data we acquire. If you are seeking to browse the contents of these collections, the Wayback Machine is the best first stop. Otherwise, you are free to dig into the stacks to see what you may find.\r\n\r\nThe Archive Team Panic Downloads are full pulldowns of currently extant websites, meant to serve as emergency backups for needed sites that are in danger of closing, or which will be missed dearly if suddenly lost due to hard drive crashes or server failures.','acquire terabytes of user-created data',0,'',''),(586,'orjson','It natively serializes\nstr, dict, list, tuple, int, float, bool,\ndataclasses.dataclass, typing.TypedDict, datetime.datetime,\ndatetime.date, datetime.time, uuid.UUID, numpy.ndarray, and\nNone instances. It supports arbitrary types through default. It\nserializes subclasses of str, int, dict, list,\ndataclasses.dataclass, and enum.Enum. It does not serialize subclasses\nof tuple to avoid serializing namedtuple objects as arrays. To avoid\nserializing subclasses, specify the option orjson.OPT_PASSTHROUGH_SUBCLASS.','serialize float',0,'',''),(587,'nltk','History is littered with hundreds of conflicts over the future of a community, group, location or business that were \"resolved\" when one of the parties stepped ahead and destroyed what was there. With the original point of contention destroyed, the debates would fall to the wayside. Archive Team believes that by duplicated condemned data, the conversation and debate can continue, as well as the richness and insight gained by keeping the materials. Our projects have ranged in size from a single volunteer downloading the data to a small-but-critical site, to over 100 volunteers stepping forward to acquire terabytes of user-created data to save for future generations.\r\n\r\nThe main site for Archive Team is at archiveteam.org and contains up to the date information on various projects, manifestos, plans and walkthroughs.\r\n\r\nThis collection contains the output of many Archive Team projects, both ongoing and completed. Thanks to the generous providing of disk space by the Internet Archive, multi-terabyte datasets can be made available, as well as in use by the Wayback Machine, providing a path back to lost websites and work. \r\n\r\nOur collection has grown to the point of having sub-collections for the type of data we acquire. If you are seeking to browse the contents of these collections, the Wayback Machine is the best first stop. Otherwise, you are free to dig into the stacks to see what you may find.\r\n\r\nThe Archive Team Panic Downloads are full pulldowns of currently extant websites, meant to serve as emergency backups for needed sites that are in danger of closing, or which will be missed dearly if suddenly lost due to hard drive crashes or server failures.','save  for future generations',0,'',''),(588,'orjson','It natively serializes\nstr, dict, list, tuple, int, float, bool,\ndataclasses.dataclass, typing.TypedDict, datetime.datetime,\ndatetime.date, datetime.time, uuid.UUID, numpy.ndarray, and\nNone instances. It supports arbitrary types through default. It\nserializes subclasses of str, int, dict, list,\ndataclasses.dataclass, and enum.Enum. It does not serialize subclasses\nof tuple to avoid serializing namedtuple objects as arrays. To avoid\nserializing subclasses, specify the option orjson.OPT_PASSTHROUGH_SUBCLASS.','serialize bool',0,'',''),(589,'nltk','History is littered with hundreds of conflicts over the future of a community, group, location or business that were \"resolved\" when one of the parties stepped ahead and destroyed what was there. With the original point of contention destroyed, the debates would fall to the wayside. Archive Team believes that by duplicated condemned data, the conversation and debate can continue, as well as the richness and insight gained by keeping the materials. Our projects have ranged in size from a single volunteer downloading the data to a small-but-critical site, to over 100 volunteers stepping forward to acquire terabytes of user-created data to save for future generations.\r\n\r\nThe main site for Archive Team is at archiveteam.org and contains up to the date information on various projects, manifestos, plans and walkthroughs.\r\n\r\nThis collection contains the output of many Archive Team projects, both ongoing and completed. Thanks to the generous providing of disk space by the Internet Archive, multi-terabyte datasets can be made available, as well as in use by the Wayback Machine, providing a path back to lost websites and work. \r\n\r\nOur collection has grown to the point of having sub-collections for the type of data we acquire. If you are seeking to browse the contents of these collections, the Wayback Machine is the best first stop. Otherwise, you are free to dig into the stacks to see what you may find.\r\n\r\nThe Archive Team Panic Downloads are full pulldowns of currently extant websites, meant to serve as emergency backups for needed sites that are in danger of closing, or which will be missed dearly if suddenly lost due to hard drive crashes or server failures.','provide path to lost websites',0,'',''),(590,'orjson','It natively serializes\nstr, dict, list, tuple, int, float, bool,\ndataclasses.dataclass, typing.TypedDict, datetime.datetime,\ndatetime.date, datetime.time, uuid.UUID, numpy.ndarray, and\nNone instances. It supports arbitrary types through default. It\nserializes subclasses of str, int, dict, list,\ndataclasses.dataclass, and enum.Enum. It does not serialize subclasses\nof tuple to avoid serializing namedtuple objects as arrays. To avoid\nserializing subclasses, specify the option orjson.OPT_PASSTHROUGH_SUBCLASS.','serialize dataclasses.dataclass',0,'',''),(591,'nltk','History is littered with hundreds of conflicts over the future of a community, group, location or business that were \"resolved\" when one of the parties stepped ahead and destroyed what was there. With the original point of contention destroyed, the debates would fall to the wayside. Archive Team believes that by duplicated condemned data, the conversation and debate can continue, as well as the richness and insight gained by keeping the materials. Our projects have ranged in size from a single volunteer downloading the data to a small-but-critical site, to over 100 volunteers stepping forward to acquire terabytes of user-created data to save for future generations.\r\n\r\nThe main site for Archive Team is at archiveteam.org and contains up to the date information on various projects, manifestos, plans and walkthroughs.\r\n\r\nThis collection contains the output of many Archive Team projects, both ongoing and completed. Thanks to the generous providing of disk space by the Internet Archive, multi-terabyte datasets can be made available, as well as in use by the Wayback Machine, providing a path back to lost websites and work. \r\n\r\nOur collection has grown to the point of having sub-collections for the type of data we acquire. If you are seeking to browse the contents of these collections, the Wayback Machine is the best first stop. Otherwise, you are free to dig into the stacks to see what you may find.\r\n\r\nThe Archive Team Panic Downloads are full pulldowns of currently extant websites, meant to serve as emergency backups for needed sites that are in danger of closing, or which will be missed dearly if suddenly lost due to hard drive crashes or server failures.','provide path to work',0,'',''),(592,'orjson','It natively serializes\nstr, dict, list, tuple, int, float, bool,\ndataclasses.dataclass, typing.TypedDict, datetime.datetime,\ndatetime.date, datetime.time, uuid.UUID, numpy.ndarray, and\nNone instances. It supports arbitrary types through default. It\nserializes subclasses of str, int, dict, list,\ndataclasses.dataclass, and enum.Enum. It does not serialize subclasses\nof tuple to avoid serializing namedtuple objects as arrays. To avoid\nserializing subclasses, specify the option orjson.OPT_PASSTHROUGH_SUBCLASS.','serialize typing.TypedDict',0,'',''),(593,'nltk','History is littered with hundreds of conflicts over the future of a community, group, location or business that were \"resolved\" when one of the parties stepped ahead and destroyed what was there. With the original point of contention destroyed, the debates would fall to the wayside. Archive Team believes that by duplicated condemned data, the conversation and debate can continue, as well as the richness and insight gained by keeping the materials. Our projects have ranged in size from a single volunteer downloading the data to a small-but-critical site, to over 100 volunteers stepping forward to acquire terabytes of user-created data to save for future generations.\r\n\r\nThe main site for Archive Team is at archiveteam.org and contains up to the date information on various projects, manifestos, plans and walkthroughs.\r\n\r\nThis collection contains the output of many Archive Team projects, both ongoing and completed. Thanks to the generous providing of disk space by the Internet Archive, multi-terabyte datasets can be made available, as well as in use by the Wayback Machine, providing a path back to lost websites and work. \r\n\r\nOur collection has grown to the point of having sub-collections for the type of data we acquire. If you are seeking to browse the contents of these collections, the Wayback Machine is the best first stop. Otherwise, you are free to dig into the stacks to see what you may find.\r\n\r\nThe Archive Team Panic Downloads are full pulldowns of currently extant websites, meant to serve as emergency backups for needed sites that are in danger of closing, or which will be missed dearly if suddenly lost due to hard drive crashes or server failures.','acquire data',0,'',''),(594,'orjson','It natively serializes\nstr, dict, list, tuple, int, float, bool,\ndataclasses.dataclass, typing.TypedDict, datetime.datetime,\ndatetime.date, datetime.time, uuid.UUID, numpy.ndarray, and\nNone instances. It supports arbitrary types through default. It\nserializes subclasses of str, int, dict, list,\ndataclasses.dataclass, and enum.Enum. It does not serialize subclasses\nof tuple to avoid serializing namedtuple objects as arrays. To avoid\nserializing subclasses, specify the option orjson.OPT_PASSTHROUGH_SUBCLASS.','serialize datetime.datetime',0,'',''),(595,'nltk','The main site for Archive Team is at archiveteam.org and contains up to the date information on various projects, manifestos, plans and walkthroughs.\r\n\r\nThis collection contains the output of many Archive Team projects, both ongoing and completed. Thanks to the generous providing of disk space by the Internet Archive, multi-terabyte datasets can be made available, as well as in use by the Wayback Machine, providing a path back to lost websites and work. \r\n\r\nOur collection has grown to the point of having sub-collections for the type of data we acquire. If you are seeking to browse the contents of these collections, the Wayback Machine is the best first stop. Otherwise, you are free to dig into the stacks to see what you may find.\r\n\r\nThe Archive Team Panic Downloads are full pulldowns of currently extant websites, meant to serve as emergency backups for needed sites that are in danger of closing, or which will be missed dearly if suddenly lost due to hard drive crashes or server failures.','provide path to lost websites',0,'',''),(596,'orjson','It natively serializes\nstr, dict, list, tuple, int, float, bool,\ndataclasses.dataclass, typing.TypedDict, datetime.datetime,\ndatetime.date, datetime.time, uuid.UUID, numpy.ndarray, and\nNone instances. It supports arbitrary types through default. It\nserializes subclasses of str, int, dict, list,\ndataclasses.dataclass, and enum.Enum. It does not serialize subclasses\nof tuple to avoid serializing namedtuple objects as arrays. To avoid\nserializing subclasses, specify the option orjson.OPT_PASSTHROUGH_SUBCLASS.','serialize datetime.date',0,'',''),(597,'nltk','The main site for Archive Team is at archiveteam.org and contains up to the date information on various projects, manifestos, plans and walkthroughs.\r\n\r\nThis collection contains the output of many Archive Team projects, both ongoing and completed. Thanks to the generous providing of disk space by the Internet Archive, multi-terabyte datasets can be made available, as well as in use by the Wayback Machine, providing a path back to lost websites and work. \r\n\r\nOur collection has grown to the point of having sub-collections for the type of data we acquire. If you are seeking to browse the contents of these collections, the Wayback Machine is the best first stop. Otherwise, you are free to dig into the stacks to see what you may find.\r\n\r\nThe Archive Team Panic Downloads are full pulldowns of currently extant websites, meant to serve as emergency backups for needed sites that are in danger of closing, or which will be missed dearly if suddenly lost due to hard drive crashes or server failures.','provide path to work',0,'',''),(598,'orjson','It natively serializes\nstr, dict, list, tuple, int, float, bool,\ndataclasses.dataclass, typing.TypedDict, datetime.datetime,\ndatetime.date, datetime.time, uuid.UUID, numpy.ndarray, and\nNone instances. It supports arbitrary types through default. It\nserializes subclasses of str, int, dict, list,\ndataclasses.dataclass, and enum.Enum. It does not serialize subclasses\nof tuple to avoid serializing namedtuple objects as arrays. To avoid\nserializing subclasses, specify the option orjson.OPT_PASSTHROUGH_SUBCLASS.','serialize datetime.time',0,'',''),(599,'nltk','The main site for Archive Team is at archiveteam.org and contains up to the date information on various projects, manifestos, plans and walkthroughs.\r\n\r\nThis collection contains the output of many Archive Team projects, both ongoing and completed. Thanks to the generous providing of disk space by the Internet Archive, multi-terabyte datasets can be made available, as well as in use by the Wayback Machine, providing a path back to lost websites and work. \r\n\r\nOur collection has grown to the point of having sub-collections for the type of data we acquire. If you are seeking to browse the contents of these collections, the Wayback Machine is the best first stop. Otherwise, you are free to dig into the stacks to see what you may find.\r\n\r\nThe Archive Team Panic Downloads are full pulldowns of currently extant websites, meant to serve as emergency backups for needed sites that are in danger of closing, or which will be missed dearly if suddenly lost due to hard drive crashes or server failures.','acquire data',0,'',''),(600,'orjson','It natively serializes\nstr, dict, list, tuple, int, float, bool,\ndataclasses.dataclass, typing.TypedDict, datetime.datetime,\ndatetime.date, datetime.time, uuid.UUID, numpy.ndarray, and\nNone instances. It supports arbitrary types through default. It\nserializes subclasses of str, int, dict, list,\ndataclasses.dataclass, and enum.Enum. It does not serialize subclasses\nof tuple to avoid serializing namedtuple objects as arrays. To avoid\nserializing subclasses, specify the option orjson.OPT_PASSTHROUGH_SUBCLASS.','serialize uuid.UUID',0,'',''),(601,'nltk','This collection contains the output of many Archive Team projects, both ongoing and completed. Thanks to the generous providing of disk space by the Internet Archive, multi-terabyte datasets can be made available, as well as in use by the Wayback Machine, providing a path back to lost websites and work. \r\n\r\nOur collection has grown to the point of having sub-collections for the type of data we acquire. If you are seeking to browse the contents of these collections, the Wayback Machine is the best first stop. Otherwise, you are free to dig into the stacks to see what you may find.\r\n\r\nThe Archive Team Panic Downloads are full pulldowns of currently extant websites, meant to serve as emergency backups for needed sites that are in danger of closing, or which will be missed dearly if suddenly lost due to hard drive crashes or server failures.','provide path to lost websites',0,'',''),(602,'orjson','It natively serializes\nstr, dict, list, tuple, int, float, bool,\ndataclasses.dataclass, typing.TypedDict, datetime.datetime,\ndatetime.date, datetime.time, uuid.UUID, numpy.ndarray, and\nNone instances. It supports arbitrary types through default. It\nserializes subclasses of str, int, dict, list,\ndataclasses.dataclass, and enum.Enum. It does not serialize subclasses\nof tuple to avoid serializing namedtuple objects as arrays. To avoid\nserializing subclasses, specify the option orjson.OPT_PASSTHROUGH_SUBCLASS.','serialize numpy.ndarray',0,'',''),(603,'nltk','This collection contains the output of many Archive Team projects, both ongoing and completed. Thanks to the generous providing of disk space by the Internet Archive, multi-terabyte datasets can be made available, as well as in use by the Wayback Machine, providing a path back to lost websites and work. \r\n\r\nOur collection has grown to the point of having sub-collections for the type of data we acquire. If you are seeking to browse the contents of these collections, the Wayback Machine is the best first stop. Otherwise, you are free to dig into the stacks to see what you may find.\r\n\r\nThe Archive Team Panic Downloads are full pulldowns of currently extant websites, meant to serve as emergency backups for needed sites that are in danger of closing, or which will be missed dearly if suddenly lost due to hard drive crashes or server failures.','provide path to work',0,'',''),(604,'orjson','It natively serializes\nstr, dict, list, tuple, int, float, bool,\ndataclasses.dataclass, typing.TypedDict, datetime.datetime,\ndatetime.date, datetime.time, uuid.UUID, numpy.ndarray, and\nNone instances. It supports arbitrary types through default. It\nserializes subclasses of str, int, dict, list,\ndataclasses.dataclass, and enum.Enum. It does not serialize subclasses\nof tuple to avoid serializing namedtuple objects as arrays. To avoid\nserializing subclasses, specify the option orjson.OPT_PASSTHROUGH_SUBCLASS.','serialize subclasses of str',0,'',''),(605,'nltk','This collection contains the output of many Archive Team projects, both ongoing and completed. Thanks to the generous providing of disk space by the Internet Archive, multi-terabyte datasets can be made available, as well as in use by the Wayback Machine, providing a path back to lost websites and work. \r\n\r\nOur collection has grown to the point of having sub-collections for the type of data we acquire. If you are seeking to browse the contents of these collections, the Wayback Machine is the best first stop. Otherwise, you are free to dig into the stacks to see what you may find.\r\n\r\nThe Archive Team Panic Downloads are full pulldowns of currently extant websites, meant to serve as emergency backups for needed sites that are in danger of closing, or which will be missed dearly if suddenly lost due to hard drive crashes or server failures.','acquire data',0,'',''),(606,'orjson','It natively serializes\nstr, dict, list, tuple, int, float, bool,\ndataclasses.dataclass, typing.TypedDict, datetime.datetime,\ndatetime.date, datetime.time, uuid.UUID, numpy.ndarray, and\nNone instances. It supports arbitrary types through default. It\nserializes subclasses of str, int, dict, list,\ndataclasses.dataclass, and enum.Enum. It does not serialize subclasses\nof tuple to avoid serializing namedtuple objects as arrays. To avoid\nserializing subclasses, specify the option orjson.OPT_PASSTHROUGH_SUBCLASS.','serialize namedtuple objects as arrays',0,'',''),(607,'nltk','Our collection has grown to the point of having sub-collections for the type of data we acquire. If you are seeking to browse the contents of these collections, the Wayback Machine is the best first stop. Otherwise, you are free to dig into the stacks to see what you may find.\r\n\r\nThe Archive Team Panic Downloads are full pulldowns of currently extant websites, meant to serve as emergency backups for needed sites that are in danger of closing, or which will be missed dearly if suddenly lost due to hard drive crashes or server failures.','acquire data',0,'',''),(608,'orjson','It natively serializes\nstr, dict, list, tuple, int, float, bool,\ndataclasses.dataclass, typing.TypedDict, datetime.datetime,\ndatetime.date, datetime.time, uuid.UUID, numpy.ndarray, and\nNone instances. It supports arbitrary types through default. It\nserializes subclasses of str, int, dict, list,\ndataclasses.dataclass, and enum.Enum. It does not serialize subclasses\nof tuple to avoid serializing namedtuple objects as arrays. To avoid\nserializing subclasses, specify the option orjson.OPT_PASSTHROUGH_SUBCLASS.','specify option orjson.OPT_PASSTHROUGH_SUBCLASS',0,'',''),(609,'nltk','Answers to Frequently Asked Questions about NLTK','ask Questions about NLTK',1,'https://web.archive.org/web/20210415060141/https://github.com/nltk/nltk/wiki/FAQ',''),(610,'orjson','It raises JSONEncodeError on an unsupported type. This exception message\ndescribes the invalid object with the error message\nType is not JSON serializable: .... To fix this, specify\ndefault.','specify default',0,'',''),(611,'nltk','Finding collocations requires first calculating the frequencies of words and\ntheir appearance in the context of other words. Often the collection of words\nwill then requiring filtering to only retain useful content terms. Each ngram\nof words may then be scored according to some association measure, in order\nto determine the relative likelihood of each ngram being a collocation.','calculate frequencies in context',0,'',''),(612,'orjson','It raises JSONEncodeError if a dict has a key of a type other than str,\nunless OPT_NON_STR_KEYS is specified.','specify OPT_NON_STR_KEYS',0,'',''),(613,'nltk','Finding collocations requires first calculating the frequencies of words and\ntheir appearance in the context of other words. Often the collection of words\nwill then requiring filtering to only retain useful content terms. Each ngram\nof words may then be scored according to some association measure, in order\nto determine the relative likelihood of each ngram being a collocation.','calculate frequencies of words',0,'',''),(614,'orjson','To serialize a subclass or arbitrary types, specify default as a\ncallable that returns a supported type. default may be a function,\nlambda, or callable class instance. To specify that a type was not\nhandled by default, raise an exception such as TypeError.','serialize subclass arbitrary types specify default as callable',1,'http://web.archive.org/web/20220903063155/https://github.com/ijl/orjson','user-content-default'),(615,'nltk','Finding collocations requires first calculating the frequencies of words and\ntheir appearance in the context of other words. Often the collection of words\nwill then requiring filtering to only retain useful content terms. Each ngram\nof words may then be scored according to some association measure, in order\nto determine the relative likelihood of each ngram being a collocation.','calculate frequencies of appearance',0,'',''),(616,'orjson','It is important that default raise an exception if a type cannot be handled.\nPython otherwise implicitly returns None, which appears to the caller\nlike a legitimate value and is serialized:','serialize none',1,'http://web.archive.org/web/20220903063155/https://github.com/ijl/orjson','user-content-default'),(617,'nltk','Finding collocations requires first calculating the frequencies of words and\ntheir appearance in the context of other words. Often the collection of words\nwill then requiring filtering to only retain useful content terms. Each ngram\nof words may then be scored according to some association measure, in order\nto determine the relative likelihood of each ngram being a collocation.','determine relative likelihood of ngram',0,'',''),(618,'orjson','To modify how data is serialized, specify option. Each option is an integer\nconstant in orjson. To specify multiple options, mask them together, e.g.,\noption=orjson.OPT_STRICT_INTEGER | orjson.OPT_NAIVE_UTC.','specify option',0,'',''),(619,'nltk','The BigramCollocationFinder and TrigramCollocationFinder classes provide\nthese functionalities, dependent on being provided a function which scores a\nngram given appropriate frequency counts. A number of standard association\nmeasures are provided in bigram_measures and trigram_measures.','provide functionalities dependent',0,'',''),(620,'orjson','To modify how data is serialized, specify option. Each option is an integer\nconstant in orjson. To specify multiple options, mask them together, e.g.,\noption=orjson.OPT_STRICT_INTEGER | orjson.OPT_NAIVE_UTC.','serialize data',0,'',''),(621,'nltk','The BigramCollocationFinder and TrigramCollocationFinder classes provide\nthese functionalities, dependent on being provided a function which scores a\nngram given appropriate frequency counts. A number of standard association\nmeasures are provided in bigram_measures and trigram_measures.','provide function',0,'',''),(622,'orjson','To modify how data is serialized, specify option. Each option is an integer\nconstant in orjson. To specify multiple options, mask them together, e.g.,\noption=orjson.OPT_STRICT_INTEGER | orjson.OPT_NAIVE_UTC.','specify multiple options',0,'',''),(623,'nltk','The BigramCollocationFinder and TrigramCollocationFinder classes provide\nthese functionalities, dependent on being provided a function which scores a\nngram given appropriate frequency counts. A number of standard association\nmeasures are provided in bigram_measures and trigram_measures.','provide number in bigram_measures',0,'',''),(624,'orjson','This measures serializing the github.json fixture as compact (52KiB) or\npretty (64KiB):','serialize github.json fixture',0,'',''),(625,'nltk','The BigramCollocationFinder and TrigramCollocationFinder classes provide\nthese functionalities, dependent on being provided a function which scores a\nngram given appropriate frequency counts. A number of standard association\nmeasures are provided in bigram_measures and trigram_measures.','provide number in trigram_measures',0,'',''),(626,'orjson','Serialize datetime.datetime objects without a tzinfo as UTC. This\nhas no effect on datetime.datetime objects that have tzinfo set.','serialize datetime.datetime objects without tzinfo',1,'http://web.archive.org/web/20220903063155/https://github.com/ijl/orjson','user-content-opt_naive_utc'),(627,'nltk','The BigramCollocationFinder and TrigramCollocationFinder classes provide\nthese functionalities, dependent on being provided a function which scores a\nngram given appropriate frequency counts. A number of standard association\nmeasures are provided in bigram_measures and trigram_measures.','provide number of standard association measures',0,'',''),(628,'orjson','Serialize dict keys of type other than str. This allows dict keys\nto be one of str, int, float, bool, None, datetime.datetime,\ndatetime.date, datetime.time, enum.Enum, and uuid.UUID. For comparison,\nthe standard library serializes str, int, float, bool or None by\ndefault. orjson benchmarks as being faster at serializing non-str keys\nthan other libraries. This option is slower for str keys than the default.','serialize none by default',1,'http://web.archive.org/web/20220903063155/https://github.com/ijl/orjson','user-content-opt_non_str_keys'),(629,'nltk','Returns the score for a given bigram using the given scoring\nfunction.  Following Church and Hanks (1990), counts are scaled by\na factor of 1/(window_size - 1).','return score for given bigram',0,'',''),(630,'orjson','Serialize dict keys of type other than str. This allows dict keys\nto be one of str, int, float, bool, None, datetime.datetime,\ndatetime.date, datetime.time, enum.Enum, and uuid.UUID. For comparison,\nthe standard library serializes str, int, float, bool or None by\ndefault. orjson benchmarks as being faster at serializing non-str keys\nthan other libraries. This option is slower for str keys than the default.','serialize none for comparison',1,'http://web.archive.org/web/20220903063155/https://github.com/ijl/orjson','user-content-opt_non_str_keys'),(631,'nltk','Returns the score for a given bigram using the given scoring\nfunction.  Following Church and Hanks (1990), counts are scaled by\na factor of 1/(window_size - 1).','scale counts following Church',0,'',''),(632,'orjson','Serialize dict keys of type other than str. This allows dict keys\nto be one of str, int, float, bool, None, datetime.datetime,\ndatetime.date, datetime.time, enum.Enum, and uuid.UUID. For comparison,\nthe standard library serializes str, int, float, bool or None by\ndefault. orjson benchmarks as being faster at serializing non-str keys\nthan other libraries. This option is slower for str keys than the default.','serialize str by default',1,'http://web.archive.org/web/20220903063155/https://github.com/ijl/orjson','user-content-opt_non_str_keys'),(633,'nltk','Returns the score for a given bigram using the given scoring\nfunction.  Following Church and Hanks (1990), counts are scaled by\na factor of 1/(window_size - 1).','scale counts following Hanks',0,'',''),(634,'orjson','Serialize dict keys of type other than str. This allows dict keys\nto be one of str, int, float, bool, None, datetime.datetime,\ndatetime.date, datetime.time, enum.Enum, and uuid.UUID. For comparison,\nthe standard library serializes str, int, float, bool or None by\ndefault. orjson benchmarks as being faster at serializing non-str keys\nthan other libraries. This option is slower for str keys than the default.','serialize str for comparison',1,'http://web.archive.org/web/20220903063155/https://github.com/ijl/orjson','user-content-opt_non_str_keys'),(635,'nltk','Returns the score for a given trigram using the given scoring\nfunction.','return score for given trigram',0,'',''),(636,'orjson','Serialize dict keys of type other than str. This allows dict keys\nto be one of str, int, float, bool, None, datetime.datetime,\ndatetime.date, datetime.time, enum.Enum, and uuid.UUID. For comparison,\nthe standard library serializes str, int, float, bool or None by\ndefault. orjson benchmarks as being faster at serializing non-str keys\nthan other libraries. This option is slower for str keys than the default.','serialize int by default',1,'http://web.archive.org/web/20220903063155/https://github.com/ijl/orjson','user-content-opt_non_str_keys'),(637,'nltk','Functions to find and load NLTK resource files, such as corpora,\ngrammars, and saved processing objects.  Resource files are identified\nusing URLs, such as nltk:corpora/abc/rural.txt or\nhttp://nltk.org/sample/toy.cfg.  The following URL protocols are\nsupported:','save processing objects',0,'',''),(638,'orjson','Serialize dict keys of type other than str. This allows dict keys\nto be one of str, int, float, bool, None, datetime.datetime,\ndatetime.date, datetime.time, enum.Enum, and uuid.UUID. For comparison,\nthe standard library serializes str, int, float, bool or None by\ndefault. orjson benchmarks as being faster at serializing non-str keys\nthan other libraries. This option is slower for str keys than the default.','serialize int for comparison',1,'http://web.archive.org/web/20220903063155/https://github.com/ijl/orjson','user-content-opt_non_str_keys'),(639,'nltk','Functions to find and load NLTK resource files, such as corpora,\ngrammars, and saved processing objects.  Resource files are identified\nusing URLs, such as nltk:corpora/abc/rural.txt or\nhttp://nltk.org/sample/toy.cfg.  The following URL protocols are\nsupported:','identify resource files',0,'',''),(640,'orjson','Serialize dict keys of type other than str. This allows dict keys\nto be one of str, int, float, bool, None, datetime.datetime,\ndatetime.date, datetime.time, enum.Enum, and uuid.UUID. For comparison,\nthe standard library serializes str, int, float, bool or None by\ndefault. orjson benchmarks as being faster at serializing non-str keys\nthan other libraries. This option is slower for str keys than the default.','serialize float by default',1,'http://web.archive.org/web/20220903063155/https://github.com/ijl/orjson','user-content-opt_non_str_keys'),(641,'nltk','Functions to find and load NLTK resource files, such as corpora,\ngrammars, and saved processing objects.  Resource files are identified\nusing URLs, such as nltk:corpora/abc/rural.txt or\nhttp://nltk.org/sample/toy.cfg.  The following URL protocols are\nsupported:','support following URL protocols',0,'',''),(642,'orjson','Serialize dict keys of type other than str. This allows dict keys\nto be one of str, int, float, bool, None, datetime.datetime,\ndatetime.date, datetime.time, enum.Enum, and uuid.UUID. For comparison,\nthe standard library serializes str, int, float, bool or None by\ndefault. orjson benchmarks as being faster at serializing non-str keys\nthan other libraries. This option is slower for str keys than the default.','serialize float for comparison',1,'http://web.archive.org/web/20220903063155/https://github.com/ijl/orjson','user-content-opt_non_str_keys'),(643,'nltk','If no protocol is specified, then the default protocol nltk: will\nbe used.','specify protocol',0,'',''),(644,'orjson','Serialize dict keys of type other than str. This allows dict keys\nto be one of str, int, float, bool, None, datetime.datetime,\ndatetime.date, datetime.time, enum.Enum, and uuid.UUID. For comparison,\nthe standard library serializes str, int, float, bool or None by\ndefault. orjson benchmarks as being faster at serializing non-str keys\nthan other libraries. This option is slower for str keys than the default.','serialize bool by default',1,'http://web.archive.org/web/20220903063155/https://github.com/ijl/orjson','user-content-opt_non_str_keys'),(645,'nltk','This module provides to functions that can be used to access a\nresource file, given its URL: load() loads a given resource, and\nadds it to a resource cache; and retrieve() copies a given resource\nto a local file.','access load() to local file',0,'',''),(646,'orjson','Serialize dict keys of type other than str. This allows dict keys\nto be one of str, int, float, bool, None, datetime.datetime,\ndatetime.date, datetime.time, enum.Enum, and uuid.UUID. For comparison,\nthe standard library serializes str, int, float, bool or None by\ndefault. orjson benchmarks as being faster at serializing non-str keys\nthan other libraries. This option is slower for str keys than the default.','serialize bool for comparison',1,'http://web.archive.org/web/20220903063155/https://github.com/ijl/orjson','user-content-opt_non_str_keys'),(647,'nltk','This module provides to functions that can be used to access a\nresource file, given its URL: load() loads a given resource, and\nadds it to a resource cache; and retrieve() copies a given resource\nto a local file.','access retrieve() copies to local file',0,'',''),(648,'orjson','Serialize dict keys of type other than str. This allows dict keys\nto be one of str, int, float, bool, None, datetime.datetime,\ndatetime.date, datetime.time, enum.Enum, and uuid.UUID. For comparison,\nthe standard library serializes str, int, float, bool or None by\ndefault. orjson benchmarks as being faster at serializing non-str keys\nthan other libraries. This option is slower for str keys than the default.','serialize non',1,'http://web.archive.org/web/20220903063155/https://github.com/ijl/orjson','user-content-opt_non_str_keys'),(649,'nltk','This module provides to functions that can be used to access a\nresource file, given its URL: load() loads a given resource, and\nadds it to a resource cache; and retrieve() copies a given resource\nto a local file.','access resource file to local file',0,'',''),(650,'orjson','These types are generally serialized how they would be as\nvalues, e.g., datetime.datetime is still an RFC 3339 string and respects\noptions affecting it. The exception is that int serialization does not\nrespect OPT_STRICT_INTEGER.','serialize types',0,'',''),(651,'nltk','This module provides to functions that can be used to access a\nresource file, given its URL: load() loads a given resource, and\nadds it to a resource cache; and retrieve() copies a given resource\nto a local file.','load given resource',0,'',''),(652,'orjson','This option has the risk of creating duplicate keys. This is because non-str\nobjects may serialize to the same str as an existing key, e.g.,\n{\"1\": true, 1: false}. The last key to be inserted to the dict will be\nserialized last and a JSON deserializer will presumably take the last\noccurrence of a key (in the above, false). The first value will be lost.','serialize  to same str',1,'http://web.archive.org/web/20220903063155/https://github.com/ijl/orjson','user-content-opt_non_str_keys'),(653,'nltk','This module provides to functions that can be used to access a\nresource file, given its URL: load() loads a given resource, and\nadds it to a resource cache; and retrieve() copies a given resource\nto a local file.','load load()',0,'',''),(654,'orjson','This option has the risk of creating duplicate keys. This is because non-str\nobjects may serialize to the same str as an existing key, e.g.,\n{\"1\": true, 1: false}. The last key to be inserted to the dict will be\nserialized last and a JSON deserializer will presumably take the last\noccurrence of a key (in the above, false). The first value will be lost.','insert  to dict',1,'http://web.archive.org/web/20220903063155/https://github.com/ijl/orjson','user-content-opt_non_str_keys'),(655,'nltk','This module provides to functions that can be used to access a\nresource file, given its URL: load() loads a given resource, and\nadds it to a resource cache; and retrieve() copies a given resource\nto a local file.','add load() to resource cache',0,'',''),(656,'orjson','This option has the risk of creating duplicate keys. This is because non-str\nobjects may serialize to the same str as an existing key, e.g.,\n{\"1\": true, 1: false}. The last key to be inserted to the dict will be\nserialized last and a JSON deserializer will presumably take the last\noccurrence of a key (in the above, false). The first value will be lost.','serialize last key',1,'http://web.archive.org/web/20220903063155/https://github.com/ijl/orjson','user-content-opt_non_str_keys'),(657,'nltk','This module provides to functions that can be used to access a\nresource file, given its URL: load() loads a given resource, and\nadds it to a resource cache; and retrieve() copies a given resource\nto a local file.','provide  to functions',0,'',''),(658,'orjson','This measures serializing 589KiB of JSON comprising a list of 100 dict\nin which each dict has both 365 randomly-sorted int keys representing epoch\ntimestamps as well as one str key and the value for each key is a\nsingle integer. In \"str keys\", the keys were converted to str before\nserialization, and orjson still specifes option=orjson.OPT_NON_STR_KEYS\n(which is always somewhat slower).','serialize 589KiB of JSON',0,'',''),(659,'nltk','Use GzipFile directly as it also buffers in all supported\nPython versions.','support Python versions',0,'',''),(660,'orjson','This measures serializing 589KiB of JSON comprising a list of 100 dict\nin which each dict has both 365 randomly-sorted int keys representing epoch\ntimestamps as well as one str key and the value for each key is a\nsingle integer. In \"str keys\", the keys were converted to str before\nserialization, and orjson still specifes option=orjson.OPT_NON_STR_KEYS\n(which is always somewhat slower).','convert keys in str keys',0,'',''),(661,'nltk','A dictionary describing the formats that are supported by NLTK’s\nload() method.  Keys are format names, and values are format\ndescriptions.','support formats',0,'',''),(662,'orjson','ujson is blank for sorting because it segfaults. json is blank because it\nraises TypeError on attempting to sort before converting all keys to str.\nrapidjson is blank because it does not support non-str keys. This can\nbe reproduced using the pynonstr script.','convert keys to str',0,'',''),(663,'nltk','A path pointer that identifies a file which can be accessed\ndirectly via a given absolute path.','identify file via given absolute path',0,'',''),(664,'orjson','ujson is blank for sorting because it segfaults. json is blank because it\nraises TypeError on attempting to sort before converting all keys to str.\nrapidjson is blank because it does not support non-str keys. This can\nbe reproduced using the pynonstr script.','sort  before converting',0,'',''),(665,'nltk','A path pointer that identifies a file which can be accessed\ndirectly via a given absolute path.','identify path pointer via given absolute path',0,'',''),(666,'orjson','Passthrough dataclasses.dataclass instances to default. This allows\ncustomizing their output but is much slower.','customize output',1,'http://web.archive.org/web/20220903063155/https://github.com/ijl/orjson','user-content-opt_passthrough_dataclass'),(667,'nltk','A path pointer that identifies a file which can be accessed\ndirectly via a given absolute path.','access file',0,'',''),(668,'orjson','Passthrough datetime.datetime, datetime.date, and datetime.time instances\nto default. This allows serializing datetimes to a custom format, e.g.,\nHTTP dates:','serialize datetimes to custom format',1,'http://web.archive.org/web/20220903063155/https://github.com/ijl/orjson','user-content-opt_passthrough_datetime'),(669,'nltk','Return a new path pointer formed by starting at the path\nidentified by this pointer, and then following the relative\npath given by fileid.  The path components of fileid\nshould be separated by forward slashes, regardless of\nthe underlying file system’s path seperator character.','return new path pointer',0,'',''),(670,'orjson','This is deprecated and has no effect in version 3. In version 2 this was\nrequired to serialize  dataclasses.dataclass instances. For more, see\ndataclass.','serialize dataclasses.dataclass instances',0,'',''),(671,'nltk','Return a seekable read-only stream that can be used to read\nthe contents of the file identified by this path pointer.','return seekable read-only stream',0,'',''),(672,'orjson','Serialize numpy.ndarray instances. For more, see\nnumpy.','serialize numpy.ndarray instances',0,'',''),(673,'nltk','The absolute path identified by this path pointer.','identify  by path pointer',0,'',''),(674,'orjson','This is deprecated and has no effect in version 3. In version 2 this was\nrequired to serialize uuid.UUID instances. For more, see\nUUID.','serialize uuid.UUID instances',0,'',''),(675,'nltk','A subclass of FileSystemPathPointer that identifies a gzip-compressed\nfile located at a given absolute path.  GzipFileSystemPathPointer is\nappropriate for loading large gzip-compressed pickle objects efficiently.','identify gzip-compressed file',0,'',''),(676,'orjson','Serialize dict keys in sorted order. The default is to serialize in an\nunspecified order. This is equivalent to sort_keys=True in the standard\nlibrary.','serialize dict keys',1,'http://web.archive.org/web/20220903063155/https://github.com/ijl/orjson','user-content-opt_sort_keys'),(677,'nltk','A subclass of FileSystemPathPointer that identifies a gzip-compressed\nfile located at a given absolute path.  GzipFileSystemPathPointer is\nappropriate for loading large gzip-compressed pickle objects efficiently.','identify FileSystemPathPointer',0,'',''),(678,'orjson','This measures serializing the twitter.json fixture unsorted and sorted:','serialize twitter.json fixture',1,'http://web.archive.org/web/20220903063155/https://github.com/ijl/orjson','user-content-opt_sort_keys'),(679,'nltk','A subclass of FileSystemPathPointer that identifies a gzip-compressed\nfile located at a given absolute path.  GzipFileSystemPathPointer is\nappropriate for loading large gzip-compressed pickle objects efficiently.','load large gzip-compressed pickle',0,'',''),(680,'orjson','dataclass also serialize as maps but this has no effect on them.','serialize  as maps',0,'',''),(681,'nltk','A subclass of zipfile.ZipFile that closes its file pointer\nwhenever it is not using it; and re-opens it when it needs to read\ndata from the zipfile.  This is useful for reducing the number of\nopen file handles when many zip files are being accessed at once.\nOpenOnDemandZipFile must be constructed from a filename, not a\nfile-like object (to allow re-opening).  OpenOnDemandZipFile is\nread-only (i.e. write() and writestr() are disabled.','access many zip files',0,'',''),(682,'orjson','Serialize a UTC timezone on datetime.datetime instances as Z instead\nof +00:00.','serialize UTC timezone on datetime.datetime instances',1,'http://web.archive.org/web/20220903063155/https://github.com/ijl/orjson','user-content-opt_utc_z'),(683,'nltk','An abstract base class for ‘path pointers,’ used by NLTK’s data\npackage to identify specific paths.  Two subclasses exist:\nFileSystemPathPointer identifies a file that can be accessed\ndirectly via a given absolute path.  ZipFilePathPointer\nidentifies a file contained within a zipfile, that can be accessed\nby reading that zipfile.','identify specific paths',0,'',''),(684,'orjson','loads() deserializes JSON to Python objects. It deserializes to dict,\nlist, int, float, str, bool, and None objects.','deserialize JSON to Python objects',0,'',''),(685,'nltk','An abstract base class for ‘path pointers,’ used by NLTK’s data\npackage to identify specific paths.  Two subclasses exist:\nFileSystemPathPointer identifies a file that can be accessed\ndirectly via a given absolute path.  ZipFilePathPointer\nidentifies a file contained within a zipfile, that can be accessed\nby reading that zipfile.','identify file',0,'',''),(686,'orjson','loads() deserializes JSON to Python objects. It deserializes to dict,\nlist, int, float, str, bool, and None objects.','deserialize  to none objects',0,'',''),(687,'nltk','An abstract base class for ‘path pointers,’ used by NLTK’s data\npackage to identify specific paths.  Two subclasses exist:\nFileSystemPathPointer identifies a file that can be accessed\ndirectly via a given absolute path.  ZipFilePathPointer\nidentifies a file contained within a zipfile, that can be accessed\nby reading that zipfile.','access file via given absolute path',0,'',''),(688,'orjson','loads() deserializes JSON to Python objects. It deserializes to dict,\nlist, int, float, str, bool, and None objects.','deserialize  to dict bool',0,'',''),(689,'nltk','An abstract base class for ‘path pointers,’ used by NLTK’s data\npackage to identify specific paths.  Two subclasses exist:\nFileSystemPathPointer identifies a file that can be accessed\ndirectly via a given absolute path.  ZipFilePathPointer\nidentifies a file contained within a zipfile, that can be accessed\nby reading that zipfile.','identify file',0,'',''),(690,'orjson','orjson serializes instances of dataclasses.dataclass natively. It serializes\ninstances 40-50x as fast as other libraries and avoids a severe slowdown seen\nin other libraries compared to serializing dict.','serialize instances of dataclasses.dataclass natively',0,'',''),(691,'nltk','An abstract base class for ‘path pointers,’ used by NLTK’s data\npackage to identify specific paths.  Two subclasses exist:\nFileSystemPathPointer identifies a file that can be accessed\ndirectly via a given absolute path.  ZipFilePathPointer\nidentifies a file contained within a zipfile, that can be accessed\nby reading that zipfile.','access zipfile',0,'',''),(692,'orjson','orjson serializes instances of dataclasses.dataclass natively. It serializes\ninstances 40-50x as fast as other libraries and avoids a severe slowdown seen\nin other libraries compared to serializing dict.','serialize instances',0,'',''),(693,'nltk','A stream reader that automatically encodes the source byte stream\ninto unicode (like codecs.StreamReader); but still supports the\nseek() and tell() operations correctly.  This is in contrast\nto codecs.StreamReader, which provide broken seek() and\ntell() methods.','support seek() tell() operations',0,'',''),(694,'orjson','This measures serializing 555KiB of JSON, orjson natively and other libraries\nusing default to serialize the output of dataclasses.asdict(). This can be\nreproduced using the pydataclass script.','serialize 555KiB of JSON natively',0,'',''),(695,'nltk','A stream reader that automatically encodes the source byte stream\ninto unicode (like codecs.StreamReader); but still supports the\nseek() and tell() operations correctly.  This is in contrast\nto codecs.StreamReader, which provide broken seek() and\ntell() methods.','encode stream reader',0,'',''),(696,'orjson','This measures serializing 555KiB of JSON, orjson natively and other libraries\nusing default to serialize the output of dataclasses.asdict(). This can be\nreproduced using the pydataclass script.','serialize 555KiB of other libraries',0,'',''),(697,'nltk','A stream reader that automatically encodes the source byte stream\ninto unicode (like codecs.StreamReader); but still supports the\nseek() and tell() operations correctly.  This is in contrast\nto codecs.StreamReader, which provide broken seek() and\ntell() methods.','provide broken seek()',0,'',''),(698,'orjson','This measures serializing 555KiB of JSON, orjson natively and other libraries\nusing default to serialize the output of dataclasses.asdict(). This can be\nreproduced using the pydataclass script.','serialize output of dataclasses.asdict()',0,'',''),(699,'nltk','A stream reader that automatically encodes the source byte stream\ninto unicode (like codecs.StreamReader); but still supports the\nseek() and tell() operations correctly.  This is in contrast\nto codecs.StreamReader, which provide broken seek() and\ntell() methods.','provide tell() methods',0,'',''),(700,'orjson','Dataclasses are serialized as maps, with every attribute serialized and in\nthe order given on class definition:','serialize dataclasses with attribute',1,'http://web.archive.org/web/20220903063155/https://github.com/ijl/orjson','user-content-dataclass'),(701,'nltk','A stream reader that automatically encodes the source byte stream\ninto unicode (like codecs.StreamReader); but still supports the\nseek() and tell() operations correctly.  This is in contrast\nto codecs.StreamReader, which provide broken seek() and\ntell() methods.','provide codecs.StreamReader',0,'',''),(702,'orjson','Dataclasses are serialized as maps, with every attribute serialized and in\nthe order given on class definition:','serialize dataclasses as maps',1,'http://web.archive.org/web/20220903063155/https://github.com/ijl/orjson','user-content-dataclass'),(703,'nltk','This class was motivated by StreamBackedCorpusView, which\nmakes extensive use of seek() and tell(), and needs to be\nable to handle unicode-encoded files.','handle unicode-encoded files',0,'',''),(704,'orjson','orjson serializes datetime.datetime objects to\nRFC 3339 format,\ne.g., \"1970-01-01T00:00:00+00:00\". This is a subset of ISO 8601 and is\ncompatible with isoformat() in the standard library.','serialize datetime.datetime objects to RFC',1,'http://web.archive.org/web/20220903063155/https://github.com/ijl/orjson','user-content-datetime'),(705,'nltk','Move the read pointer forward by offset characters.','move read pointer by offset characters',0,'',''),(706,'orjson','It is faster to have orjson serialize datetime objects than to do so\nbefore calling dumps(). If using an unsupported type such as\npendulum.datetime, use default.','call dumps()',0,'',''),(707,'nltk','The name of the encoding that should be used to encode the\nunderlying stream.','encode underlying stream',0,'',''),(708,'orjson','To disable serialization of datetime objects specify the option\norjson.OPT_PASSTHROUGH_DATETIME.','specify option orjson.OPT_PASSTHROUGH_DATETIME',0,'',''),(709,'nltk','A buffer used by readline() to hold characters that have\nbeen read, but have not yet been returned by read() or\nreadline().  This buffer consists of a list of unicode\nstrings, where each string corresponds to a single line.\nThe final element of the list may or may not be a complete\nline.  Note that the existence of a linebuffer makes the\ntell() operation more complex, because it must backtrack\nto the beginning of the buffer to determine the correct\nfile position in the underlying byte stream.','determine correct file position in underlying byte stream',0,'',''),(710,'orjson','Enums with members that are not supported types can be serialized using\ndefault:','serialize types',1,'http://web.archive.org/web/20220903063155/https://github.com/ijl/orjson','user-content-enum'),(711,'nltk','Read up to size bytes, decode them using this reader’s\nencoding, and return the resulting unicode string.','return resulting unicode string',0,'',''),(712,'orjson','orjson serializes and deserializes 64-bit integers by default. The range\nsupported is a signed 64-bit integer\'s minimum (-9223372036854775807) to\nan unsigned 64-bit integer\'s maximum (18446744073709551615). This\nis widely compatible, but there are implementations\nthat only support 53-bits for integers, e.g.,\nweb browsers. For those implementations, dumps() can be configured to\nraise a JSONEncodeError on values exceeding the 53-bit range.','serialize 64-bit integers by default',1,'http://web.archive.org/web/20220903063155/https://github.com/ijl/orjson','user-content-int'),(713,'nltk','Read a line of text, decode it using this reader’s encoding,\nand return the resulting unicode string.','return resulting unicode string',0,'',''),(714,'orjson','orjson serializes and deserializes 64-bit integers by default. The range\nsupported is a signed 64-bit integer\'s minimum (-9223372036854775807) to\nan unsigned 64-bit integer\'s maximum (18446744073709551615). This\nis widely compatible, but there are implementations\nthat only support 53-bits for integers, e.g.,\nweb browsers. For those implementations, dumps() can be configured to\nraise a JSONEncodeError on values exceeding the 53-bit range.','deserialize 64-bit integers by default',1,'http://web.archive.org/web/20220903063155/https://github.com/ijl/orjson','user-content-int'),(715,'nltk','Read this file’s contents, decode them using this reader’s\nencoding, and return it as a list of unicode lines.','return  as list',0,'',''),(716,'orjson','orjson serializes and deserializes 64-bit integers by default. The range\nsupported is a signed 64-bit integer\'s minimum (-9223372036854775807) to\nan unsigned 64-bit integer\'s maximum (18446744073709551615). This\nis widely compatible, but there are implementations\nthat only support 53-bits for integers, e.g.,\nweb browsers. For those implementations, dumps() can be configured to\nraise a JSONEncodeError on values exceeding the 53-bit range.','configure dumps() for implementations',1,'http://web.archive.org/web/20220903063155/https://github.com/ijl/orjson','user-content-int'),(717,'nltk','Move the stream to a new file position.  If the reader is\nmaintaining any buffers, then they will be cleared.','move stream to new file position',0,'',''),(718,'orjson','orjson natively serializes numpy.ndarray and individual numpy.float64,\nnumpy.float32, numpy.int64, numpy.int32, numpy.int16, numpy.int8, numpy.uint64,\nnumpy.uint32, numpy.uint16, numpy.uint8, numpy.uintp, or numpy.intp, and\nnumpy.datetime64 instances.','serialize numpy.datetime64 instances',0,'',''),(719,'nltk','Return the current file position on the underlying byte\nstream.  If this reader is maintaining any buffers, then the\nreturned file position will be the position of the beginning\nof those buffers.','return current file position on underlying byte stream',0,'',''),(720,'orjson','orjson natively serializes numpy.ndarray and individual numpy.float64,\nnumpy.float32, numpy.int64, numpy.int32, numpy.int16, numpy.int8, numpy.uint64,\nnumpy.uint32, numpy.uint16, numpy.uint8, numpy.uintp, or numpy.intp, and\nnumpy.datetime64 instances.','serialize numpy.ndarray individual numpy.float64',0,'',''),(721,'nltk','Remove all objects from the resource cache.\n:see: load()','remove objects from resource cache',0,'',''),(722,'orjson','orjson natively serializes numpy.ndarray and individual numpy.float64,\nnumpy.float32, numpy.int64, numpy.int32, numpy.int16, numpy.int8, numpy.uint64,\nnumpy.uint32, numpy.uint16, numpy.uint8, numpy.uintp, or numpy.intp, and\nnumpy.datetime64 instances.','serialize numpy.float32 numpy.uintp',0,'',''),(723,'nltk','Find the given resource by searching through the directories and\nzip files in paths, where a None or empty string specifies an absolute path.\nReturns a corresponding path name.  If the given resource is not\nfound, raise a LookupError, whose message gives a pointer to\nthe installation instructions for the NLTK downloader.','specify absolute path',0,'',''),(724,'orjson','orjson natively serializes numpy.ndarray and individual numpy.float64,\nnumpy.float32, numpy.int64, numpy.int32, numpy.int16, numpy.int8, numpy.uint64,\nnumpy.uint32, numpy.uint16, numpy.uint8, numpy.uintp, or numpy.intp, and\nnumpy.datetime64 instances.','serialize numpy.intp',0,'',''),(725,'nltk','Find the given resource by searching through the directories and\nzip files in paths, where a None or empty string specifies an absolute path.\nReturns a corresponding path name.  If the given resource is not\nfound, raise a LookupError, whose message gives a pointer to\nthe installation instructions for the NLTK downloader.','specify paths',0,'',''),(726,'orjson','orjson is faster than all compared libraries at serializing\nnumpy instances. Serializing numpy data requires specifying\noption=orjson.OPT_SERIALIZE_NUMPY.','serialize numpy instances',1,'http://web.archive.org/web/20220903063155/https://github.com/ijl/orjson','user-content-numpy'),(727,'nltk','Find the given resource by searching through the directories and\nzip files in paths, where a None or empty string specifies an absolute path.\nReturns a corresponding path name.  If the given resource is not\nfound, raise a LookupError, whose message gives a pointer to\nthe installation instructions for the NLTK downloader.','raise LookupError',0,'',''),(728,'orjson','numpy.datetime64 instances are serialized as RFC 3339 strings and\ndatetime options affect them.','serialize numpy.datetime64 instances as RFC',1,'http://web.archive.org/web/20220903063155/https://github.com/ijl/orjson','user-content-numpy'),(729,'nltk','If a given resource name that does not contain any zipfile\ncomponent is not found initially, then find() will make a\nsecond attempt to find that resource, by replacing each\ncomponent p in the path with p.zip/p.  For example, this\nallows find() to map the resource name\ncorpora/chat80/cities.pl to a zip file path pointer to\ncorpora/chat80.zip/chat80/cities.pl.','replace component p in path',0,'',''),(730,'orjson','If an array is not a contiguous C array, contains an supported datatype,\nor contains a numpy.datetime64 using an unsupported representation\n(e.g., picoseconds), orjson falls through to default. In default,\nobj.tolist() can be specified. If an array is malformed, which\nis not expected, orjson.JSONEncodeError is raised.','specify obj.tolist() in default',0,'',''),(731,'nltk','If a given resource name that does not contain any zipfile\ncomponent is not found initially, then find() will make a\nsecond attempt to find that resource, by replacing each\ncomponent p in the path with p.zip/p.  For example, this\nallows find() to map the resource name\ncorpora/chat80/cities.pl to a zip file path pointer to\ncorpora/chat80.zip/chat80/cities.pl.','replace component p to zip file path pointer',0,'',''),(732,'orjson','This measures serializing 92MiB of JSON from an numpy.ndarray with\ndimensions of (50000, 100) and numpy.float64 values:','serialize 92MiB of JSON',0,'',''),(733,'nltk','resource_name (str or unicode) – The name of the resource to search for.\nResource names are posix-style relative path names, such as\ncorpora/brown.  Directory names will be\nautomatically converted to a platform-appropriate path separator.','convert directory names to platform-appropriate path separator',0,'',''),(734,'orjson','This measures serializing 92MiB of JSON from an numpy.ndarray with\ndimensions of (50000, 100) and numpy.float64 values:','serialize 92MiB from numpy.ndarray',0,'',''),(735,'nltk','Load a given resource from the NLTK data package.  The following\nresource formats are currently supported:','load given resource from NLTK data package',0,'',''),(736,'orjson','This measures serializing 100MiB of JSON from an numpy.ndarray with\ndimensions of (100000, 100) and numpy.int32 values:','serialize 100MiB of JSON',0,'',''),(737,'nltk','Load a given resource from the NLTK data package.  The following\nresource formats are currently supported:','support following resource formats',0,'',''),(738,'orjson','This measures serializing 100MiB of JSON from an numpy.ndarray with\ndimensions of (100000, 100) and numpy.int32 values:','serialize 100MiB from numpy.ndarray',0,'',''),(739,'nltk','If no format is specified, load() will attempt to determine a\nformat based on the resource name’s file extension.  If that\nfails, load() will raise a ValueError exception.','determine format',0,'',''),(740,'orjson','This measures serializing 105MiB of JSON from an numpy.ndarray with\ndimensions of (100000, 200) and numpy.bool values:','serialize 105MiB of JSON',0,'',''),(741,'nltk','If no format is specified, load() will attempt to determine a\nformat based on the resource name’s file extension.  If that\nfails, load() will raise a ValueError exception.','specify format',0,'',''),(742,'orjson','This measures serializing 105MiB of JSON from an numpy.ndarray with\ndimensions of (100000, 200) and numpy.bool values:','serialize 105MiB from numpy.ndarray',0,'',''),(743,'nltk','If no format is specified, load() will attempt to determine a\nformat based on the resource name’s file extension.  If that\nfails, load() will raise a ValueError exception.','raise ValueError exception',0,'',''),(744,'orjson','In these benchmarks, orjson serializes natively, ujson is blank because it\ndoes not support a default parameter, and the other libraries serialize\nndarray.tolist() via default. The RSS column measures peak memory\nusage during serialization. This can be reproduced using the pynumpy script.','serialize ndarray.tolist() via default',0,'',''),(745,'nltk','For all text formats (everything except pickle, json, yaml and raw),\nit tries to decode the raw contents using UTF-8, and if that doesn’t\nwork, it tries with ISO-8859-1 (Latin-1), unless the encoding\nis specified.','specify encoding',0,'',''),(746,'orjson','orjson is strict about UTF-8 conformance. This is stricter than the standard\nlibrary\'s json module, which will serialize and deserialize UTF-16 surrogates,\ne.g., \"ud800\", that are invalid UTF-8.','serialize UTF-16 surrogates',1,'http://web.archive.org/web/20220903063155/https://github.com/ijl/orjson','user-content-str'),(747,'nltk','resource_url (str) – A URL specifying where the resource should be\nloaded from.  The default protocol is “nltk:”, which searches\nfor the file in the the NLTK data package.','load resource',0,'',''),(748,'orjson','orjson is strict about UTF-8 conformance. This is stricter than the standard\nlibrary\'s json module, which will serialize and deserialize UTF-16 surrogates,\ne.g., \"ud800\", that are invalid UTF-8.','serialize json module',1,'http://web.archive.org/web/20220903063155/https://github.com/ijl/orjson','user-content-str'),(749,'nltk','cache (bool) – If true, add this resource to a cache.  If load()\nfinds a resource in its cache, then it will return it from the\ncache rather than loading it.','add resource to cache',0,'',''),(750,'orjson','orjson is strict about UTF-8 conformance. This is stricter than the standard\nlibrary\'s json module, which will serialize and deserialize UTF-16 surrogates,\ne.g., \"ud800\", that are invalid UTF-8.','deserialize json module',1,'http://web.archive.org/web/20220903063155/https://github.com/ijl/orjson','user-content-str'),(751,'nltk','cache (bool) – If true, add this resource to a cache.  If load()\nfinds a resource in its cache, then it will return it from the\ncache rather than loading it.','return  from cache',0,'',''),(752,'orjson','To make a best effort at deserializing bad input, first decode bytes using\nthe replace or lossy argument for errors:','deserialize bad input',1,'http://web.archive.org/web/20220903063155/https://github.com/ijl/orjson','user-content-str'),(753,'nltk','verbose (bool) – If true, print a message when loading a resource.\nMessages are not displayed when a resource is retrieved from\nthe cache.','print message',0,'',''),(754,'orjson','orjson serializes uuid.UUID instances to\nRFC 4122 format, e.g.,\n\"f81d4fae-7dec-11d0-a765-00a0c91e6bf6\".','serialize uuid.UUID instances to RFC',1,'http://web.archive.org/web/20220903063155/https://github.com/ijl/orjson','user-content-uuid'),(755,'nltk','verbose (bool) – If true, print a message when loading a resource.\nMessages are not displayed when a resource is retrieved from\nthe cache.','load resource',0,'',''),(756,'orjson','This shows that all libraries deserialize valid JSON but only orjson\ncorrectly rejects the given invalid JSON fixtures. Errors are largely due to\naccepting invalid strings and numbers.','deserialize valid JSON',0,'',''),(757,'nltk','verbose (bool) – If true, print a message when loading a resource.\nMessages are not displayed when a resource is retrieved from\nthe cache.','retrieve resource from cache',0,'',''),(758,'orjson','This measures, in the first column, RSS after importing a library and reading\nthe fixture, and in the second column, increases in RSS after repeatedly\ncalling loads() on the fixture.','import library',0,'',''),(759,'nltk','logic_parser (LogicParser) – The parser that will be used to parse logical\nexpressions.','parse logical expressions',0,'',''),(760,'orjson','This measures, in the first column, RSS after importing a library and reading\nthe fixture, and in the second column, increases in RSS after repeatedly\ncalling loads() on the fixture.','read fixture',0,'',''),(761,'nltk','fstruct_reader (FeatStructReader) – The parser that will be used to parse the\nfeature structure of an fcfg.','parse feature structure of fcfg',0,'',''),(762,'orjson','This measures, in the first column, RSS after importing a library and reading\nthe fixture, and in the second column, increases in RSS after repeatedly\ncalling loads() on the fixture.','call loads() on fixture',0,'',''),(763,'nltk','A list of directories where the NLTK data package might reside.\nThese directories will be checked in order when looking for a\nresource in the data package.  Note that this allows users to\nsubstitute in their own versions of resources, if they have them\n(e.g., in their home directory under ~/nltk_data).','check directories',0,'',''),(764,'orjson','This happens when there are no binary wheels (like manylinux) for your\nplatform on PyPI. You can install Rust through\nrustup or a package manager and then it will compile.','install rust through rustup',0,'',''),(765,'nltk','Copy the given resource to a local file.  If no filename is\nspecified, then use the URL’s filename.  If there is already a\nfile named filename, then raise a ValueError.','specify filename',0,'',''),(766,'orjson','This happens when there are no binary wheels (like manylinux) for your\nplatform on PyPI. You can install Rust through\nrustup or a package manager and then it will compile.','install rust through package manager',0,'',''),(767,'nltk','Copy the given resource to a local file.  If no filename is\nspecified, then use the URL’s filename.  If there is already a\nfile named filename, then raise a ValueError.','raise ValueError',0,'',''),(768,'orjson','It benefits from also having a C build environment to compile a faster\ndeserialization backend. See this project\'s manylinux_2_28 builds for an\nexample using clang and LTO.','compile faster deserialization backend',0,'',''),(769,'nltk','Write out a grammar file, ignoring escaped and empty lines.','ignore escaped empty lines',0,'',''),(770,'orjson','The project\'s own CI tests against nightly-2022-08-26 and stable 1.57. It\nis prudent to pin the nightly version because that channel can introduce\nbreaking changes.','introduce breaking changes',0,'',''),(771,'nltk','escape (str) – Prepended string that signals lines to be ignored','ignore lines',0,'',''),(772,'orjson','orjson\'s tests are included in the source distribution on PyPI. The\nrequirements to run the tests are specified in test/requirements.txt. The\ntests should be run as part of the build. It can be run with\npytest -q test.','specify requirements in test/requirements.txt',0,'',''),(773,'nltk','The NLTK corpus and module downloader.  This module defines several\ninterfaces which can be used to download corpora, models, and other\ndata packages that can be used with NLTK.','define several interfaces',0,'',''),(774,'orjson','orjson was written by ijl <ijl@mailbox.org>, copyright 2018 - 2022, licensed\nunder both the Apache 2 and MIT licenses.','write orjson',0,'',''),(775,'nltk','If called with no arguments, download() will display an interactive\ninterface which can be used to download and install new packages.\nIf Tkinter is available, then a graphical interface will be shown,\notherwise a simple text interface will be provided.','display interactive interface',0,'',''),(776,'orjson','Requests allows you to send HTTP/1.1 requests extremely easily. There’s no need to manually add query strings to your URLs, or to form-encode your PUT & POST data — but nowadays, just use the json method!','send requests',0,'',''),(777,'nltk','If called with no arguments, download() will display an interactive\ninterface which can be used to download and install new packages.\nIf Tkinter is available, then a graphical interface will be shown,\notherwise a simple text interface will be provided.','install new packages',0,'',''),(778,'orjson','Requests allows you to send HTTP/1.1 requests extremely easily. There’s no need to manually add query strings to your URLs, or to form-encode your PUT & POST data — but nowadays, just use the json method!','add query strings to urls',0,'',''),(779,'nltk','If called with no arguments, download() will display an interactive\ninterface which can be used to download and install new packages.\nIf Tkinter is available, then a graphical interface will be shown,\notherwise a simple text interface will be provided.','call  with arguments',0,'',''),(780,'orjson','Requests allows you to send HTTP/1.1 requests extremely easily. There’s no need to manually add query strings to your URLs, or to form-encode your PUT & POST data — but nowadays, just use the json method!','use json method',0,'',''),(781,'nltk','If called with no arguments, download() will display an interactive\ninterface which can be used to download and install new packages.\nIf Tkinter is available, then a graphical interface will be shown,\notherwise a simple text interface will be provided.','show graphical interface',0,'',''),(782,'orjson','Requests officially supports Python 3.7+.','support Python +',0,'',''),(783,'nltk','If called with no arguments, download() will display an interactive\ninterface which can be used to download and install new packages.\nIf Tkinter is available, then a graphical interface will be shown,\notherwise a simple text interface will be provided.','provide simple text interface',0,'',''),(784,'orjson','When cloning the Requests repository, you may need to add the -c fetch.fsck.badTimezone=ignore flag to avoid an error about a bad commit (see\nthis issue for more background):','clone Requests repository',1,'https://github.com/psf/requests','user-content-cloning-the-repository'),(785,'nltk','Individual packages can be downloaded by calling the download()\nfunction with a single argument, giving the package identifier for the\npackage that should be downloaded:','call download() function with single argument',0,'',''),(786,'orjson','When cloning the Requests repository, you may need to add the -c fetch.fsck.badTimezone=ignore flag to avoid an error about a bad commit (see\nthis issue for more background):','add flag',1,'https://github.com/psf/requests','user-content-cloning-the-repository'),(787,'nltk','NLTK also provides a number of “package collections”, consisting of\na group of related packages.  To download all packages in a\ncolleciton, simply call download() with the collection’s\nidentifier:','provide number of package collections',0,'',''),(788,'orjson','You can also apply this setting to your global Git config:','apply setting to global git config',1,'https://github.com/psf/requests','user-content-cloning-the-repository'),(789,'nltk','NLTK also provides a number of “package collections”, consisting of\na group of related packages.  To download all packages in a\ncolleciton, simply call download() with the collection’s\nidentifier:','call download() with identifier',0,'',''),(790,'nltk','By default, packages are installed in either a system-wide directory\n(if Python has sufficient access to write to it); or in the current\nuser’s home directory.  However, the download_dir argument may be\nused to specify a different installation target, if desired.','install packages in home directory',0,'',''),(791,'nltk','By default, packages are installed in either a system-wide directory\n(if Python has sufficient access to write to it); or in the current\nuser’s home directory.  However, the download_dir argument may be\nused to specify a different installation target, if desired.','specify different installation target',0,'',''),(792,'nltk','See Downloader.default_download_dir() for more a detailed\ndescription of how the default download directory is chosen.','choose default download directory',0,'',''),(793,'nltk','Before downloading any packages, the corpus and module downloader\ncontacts the NLTK download server, to retrieve an index file\ndescribing the available packages.  By default, this index file is\nloaded from https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml.\nIf necessary, it is possible to create a new Downloader object,\nspecifying a different URL for the package index file.','retrieve index file',0,'',''),(794,'nltk','Before downloading any packages, the corpus and module downloader\ncontacts the NLTK download server, to retrieve an index file\ndescribing the available packages.  By default, this index file is\nloaded from https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml.\nIf necessary, it is possible to create a new Downloader object,\nspecifying a different URL for the package index file.','load index file from https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml',0,'',''),(795,'nltk','Before downloading any packages, the corpus and module downloader\ncontacts the NLTK download server, to retrieve an index file\ndescribing the available packages.  By default, this index file is\nloaded from https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml.\nIf necessary, it is possible to create a new Downloader object,\nspecifying a different URL for the package index file.','create new downloader object',0,'',''),(796,'nltk','Before downloading any packages, the corpus and module downloader\ncontacts the NLTK download server, to retrieve an index file\ndescribing the available packages.  By default, this index file is\nloaded from https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml.\nIf necessary, it is possible to create a new Downloader object,\nspecifying a different URL for the package index file.','specify different URL for package index file',0,'',''),(797,'nltk','A directory entry for a collection of downloadable packages.\nThese entries are extracted from the XML index file that is\ndownloaded by Downloader.','extract entries from XML index file',0,'',''),(798,'nltk','A class used to access the NLTK data server, which can be used to\ndownload corpora and other data packages.','access NLTK data server',0,'',''),(799,'nltk','The default URL for the NLTK data server’s index.  An\nalternative URL can be specified when creating a new\nDownloader object.','create new downloader',0,'',''),(800,'nltk','The default URL for the NLTK data server’s index.  An\nalternative URL can be specified when creating a new\nDownloader object.','specify alternative URL',0,'',''),(801,'nltk','A status string indicating that a collection is partially\ninstalled (i.e., only some of its packages are installed.)','install collection',0,'',''),(802,'nltk','Return the directory to which packages will be downloaded by\ndefault.  This value can be overridden using the constructor,\nor on a case-by-case basis using the download_dir argument when\ncalling download().','call download()',0,'',''),(803,'nltk','On all other platforms, the default directory is the first of\nthe following which exists or which can be created with write\npermission: /usr/share/nltk_data, /usr/local/share/nltk_data,\n/usr/lib/nltk_data, /usr/local/lib/nltk_data, ~/nltk_data.','create following with write permission',0,'',''),(804,'nltk','The default directory to which packages will be downloaded.\nThis defaults to the value returned by default_download_dir().\nTo override this default on a case-by-case basis, use the\ndownload_dir argument when calling download().','override default on case-by-case basis',0,'',''),(805,'nltk','The default directory to which packages will be downloaded.\nThis defaults to the value returned by default_download_dir().\nTo override this default on a case-by-case basis, use the\ndownload_dir argument when calling download().','call download()',0,'',''),(806,'nltk','Return the Package or Collection record for the\ngiven item.','return package collection record for given item',0,'',''),(807,'nltk','Return the XML info record for the given item','return XML info record for given item',0,'',''),(808,'nltk','A dictionary specifying how wide each column should be, in\ncharacters.  The default width (for columns not explicitly\nlisted) is specified by DEFAULT_COLUMN_WIDTH.','specify  in characters',0,'',''),(809,'nltk','A dictionary specifying how wide each column should be, in\ncharacters.  The default width (for columns not explicitly\nlisted) is specified by DEFAULT_COLUMN_WIDTH.','specify default width',0,'',''),(810,'nltk','The set of columns that should be displayed by default.','display columns',0,'',''),(811,'nltk','A directory entry for a downloadable package.  These entries are\nextracted from the XML index file that is downloaded by\nDownloader.  Each package consists of a single file; but if\nthat file is a zip file, then it can be automatically decompressed\nwhen the package is installed.','extract entries from XML index file',0,'',''),(812,'nltk','A directory entry for a downloadable package.  These entries are\nextracted from the XML index file that is downloaded by\nDownloader.  Each package consists of a single file; but if\nthat file is a zip file, then it can be automatically decompressed\nwhen the package is installed.','install package',0,'',''),(813,'nltk','The subdirectory where this package should be installed.\nE.g., \'corpora\' or \'taggers\'.','install package',0,'',''),(814,'nltk','Create a new data.xml index file, by combining the xml description\nfiles for various packages and collections.  root should be the\npath to a directory containing the package xml and zip files; and\nthe collection xml files.  The root directory is expected to\nhave the following subdirectories:','create new data.xml index file by combining',0,'',''),(815,'nltk','For each package, there should be two files: package.zip\n(where package is the package name)\nwhich contains the package itself as a compressed zip file; and\npackage.xml, which is an xml description of the package.  The\nzipfile package.zip should expand to a single subdirectory\nnamed package/.  The base filename package must match\nthe identifier given in the package’s xml file.','expand  to single subdirectory',0,'',''),(816,'nltk','Calculate and return the MD5 checksum for a given file.\nfile may either be a filename or an open stream.','return md5 checksum for given file',0,'',''),(817,'nltk','Extract the contents of the zip file filename into the\ndirectory root.','extract contents into directory root',0,'',''),(818,'nltk','Extract the contents of the zip file filename into the\ndirectory root.','extract contents of zip file filename',0,'',''),(819,'nltk','Basic data classes for representing feature structures, and for\nperforming basic operations on those feature structures.  A feature\nstructure is a mapping from feature identifiers to feature values,\nwhere each feature value is either a basic value (such as a string or\nan integer), or a nested feature structure.  There are two types of\nfeature structure, implemented by two subclasses of FeatStruct:','perform basic operations',0,'',''),(820,'nltk','Features can be specified using “feature paths”, or tuples of feature\nidentifiers that specify path through the nested feature structures to\na value.  Feature structures may contain reentrant feature values.  A\n“reentrant feature value” is a single feature value that can be\naccessed via multiple feature paths.  Unification preserves the\nreentrance relations imposed by both of the unified feature\nstructures.  In the feature structure resulting from unification, any\nmodifications to a reentrant feature value will be visible using any\nof its feature paths.','specify path through nested feature structures',0,'',''),(821,'nltk','Features can be specified using “feature paths”, or tuples of feature\nidentifiers that specify path through the nested feature structures to\na value.  Feature structures may contain reentrant feature values.  A\n“reentrant feature value” is a single feature value that can be\naccessed via multiple feature paths.  Unification preserves the\nreentrance relations imposed by both of the unified feature\nstructures.  In the feature structure resulting from unification, any\nmodifications to a reentrant feature value will be visible using any\nof its feature paths.','specify features',0,'',''),(822,'nltk','Features can be specified using “feature paths”, or tuples of feature\nidentifiers that specify path through the nested feature structures to\na value.  Feature structures may contain reentrant feature values.  A\n“reentrant feature value” is a single feature value that can be\naccessed via multiple feature paths.  Unification preserves the\nreentrance relations imposed by both of the unified feature\nstructures.  In the feature structure resulting from unification, any\nmodifications to a reentrant feature value will be visible using any\nof its feature paths.','access single feature value via multiple feature paths',0,'',''),(823,'nltk','Feature structure variables are encoded using the nltk.sem.Variable\nclass.  The variables’ values are tracked using a bindings\ndictionary, which maps variables to their values.  When two feature\nstructures are unified, a fresh bindings dictionary is created to\ntrack their values; and before unification completes, all bound\nvariables are replaced by their values.  Thus, the bindings\ndictionaries are usually strictly internal to the unification process.\nHowever, it is possible to track the bindings of variables if you\nchoose to, by supplying your own initial bindings dictionary to the\nunify() function.','encode feature structure variables',0,'',''),(824,'nltk','Feature structure variables are encoded using the nltk.sem.Variable\nclass.  The variables’ values are tracked using a bindings\ndictionary, which maps variables to their values.  When two feature\nstructures are unified, a fresh bindings dictionary is created to\ntrack their values; and before unification completes, all bound\nvariables are replaced by their values.  Thus, the bindings\ndictionaries are usually strictly internal to the unification process.\nHowever, it is possible to track the bindings of variables if you\nchoose to, by supplying your own initial bindings dictionary to the\nunify() function.','track values',0,'',''),(825,'nltk','Feature structure variables are encoded using the nltk.sem.Variable\nclass.  The variables’ values are tracked using a bindings\ndictionary, which maps variables to their values.  When two feature\nstructures are unified, a fresh bindings dictionary is created to\ntrack their values; and before unification completes, all bound\nvariables are replaced by their values.  Thus, the bindings\ndictionaries are usually strictly internal to the unification process.\nHowever, it is possible to track the bindings of variables if you\nchoose to, by supplying your own initial bindings dictionary to the\nunify() function.','track values',0,'',''),(826,'nltk','Feature structure variables are encoded using the nltk.sem.Variable\nclass.  The variables’ values are tracked using a bindings\ndictionary, which maps variables to their values.  When two feature\nstructures are unified, a fresh bindings dictionary is created to\ntrack their values; and before unification completes, all bound\nvariables are replaced by their values.  Thus, the bindings\ndictionaries are usually strictly internal to the unification process.\nHowever, it is possible to track the bindings of variables if you\nchoose to, by supplying your own initial bindings dictionary to the\nunify() function.','replace bound variables',0,'',''),(827,'nltk','Feature structure variables are encoded using the nltk.sem.Variable\nclass.  The variables’ values are tracked using a bindings\ndictionary, which maps variables to their values.  When two feature\nstructures are unified, a fresh bindings dictionary is created to\ntrack their values; and before unification completes, all bound\nvariables are replaced by their values.  Thus, the bindings\ndictionaries are usually strictly internal to the unification process.\nHowever, it is possible to track the bindings of variables if you\nchoose to, by supplying your own initial bindings dictionary to the\nunify() function.','create fresh bindings dictionary',0,'',''),(828,'nltk','Feature structure variables are encoded using the nltk.sem.Variable\nclass.  The variables’ values are tracked using a bindings\ndictionary, which maps variables to their values.  When two feature\nstructures are unified, a fresh bindings dictionary is created to\ntrack their values; and before unification completes, all bound\nvariables are replaced by their values.  Thus, the bindings\ndictionaries are usually strictly internal to the unification process.\nHowever, it is possible to track the bindings of variables if you\nchoose to, by supplying your own initial bindings dictionary to the\nunify() function.','track bindings of variables',0,'',''),(829,'nltk','Feature structure variables are encoded using the nltk.sem.Variable\nclass.  The variables’ values are tracked using a bindings\ndictionary, which maps variables to their values.  When two feature\nstructures are unified, a fresh bindings dictionary is created to\ntrack their values; and before unification completes, all bound\nvariables are replaced by their values.  Thus, the bindings\ndictionaries are usually strictly internal to the unification process.\nHowever, it is possible to track the bindings of variables if you\nchoose to, by supplying your own initial bindings dictionary to the\nunify() function.','choose  by supplying',0,'',''),(830,'nltk','Python dictionaries & lists ignore reentrance when checking for\nequality between values.  But two FeatStructs with different\nreentrances are considered nonequal, even if all their base\nvalues are equal.','check  for equality',0,'',''),(831,'nltk','FeatStructs provide a number of useful methods, such as walk()\nand cyclic(), which are not available for Python dicts and lists.','provide number of useful methods',0,'',''),(832,'nltk','FeatStructs provide a number of useful methods, such as walk()\nand cyclic(), which are not available for Python dicts and lists.','provide number such_as walk()',0,'',''),(833,'nltk','FeatStructs provide a number of useful methods, such as walk()\nand cyclic(), which are not available for Python dicts and lists.','provide number such_as cyclic()',0,'',''),(834,'nltk','A feature structure that acts like a Python dictionary.  I.e., a\nmapping from feature identifiers to feature values, where a feature\nidentifier can be a string or a Feature; and where a feature value\ncan be either a basic value (such as a string or an integer), or a nested\nfeature structure.  A feature identifiers for a FeatDict is\nsometimes called a “feature name”.','call feature name for FeatDict',0,'',''),(835,'nltk','A feature structure that acts like a Python dictionary.  I.e., a\nmapping from feature identifiers to feature values, where a feature\nidentifier can be a string or a Feature; and where a feature value\ncan be either a basic value (such as a string or an integer), or a nested\nfeature structure.  A feature identifiers for a FeatDict is\nsometimes called a “feature name”.','call feature identifiers for FeatDict',0,'',''),(836,'nltk','Two feature dicts are considered equal if they assign the same\nvalues to all features, and have the same reentrances.','assign same values to features',0,'',''),(837,'nltk','If self is frozen, raise ValueError.','raise ValueError',0,'',''),(838,'nltk','If the feature with the given name or path exists, return its\nvalue; otherwise, return default.','return value',0,'',''),(839,'nltk','If the feature with the given name or path exists, return its\nvalue; otherwise, return default.','return default',0,'',''),(840,'nltk','If key is not found, d is returned if given, otherwise KeyError is raised\nIf self is frozen, raise ValueError.','raise ValueError',0,'',''),(841,'nltk','If key is not found, d is returned if given, otherwise KeyError is raised\nIf self is frozen, raise ValueError.','raise KeyError',0,'',''),(842,'nltk','Remove and return a (key, value) pair as a 2-tuple.','remove pair',0,'',''),(843,'nltk','Remove and return a (key, value) pair as a 2-tuple.','return pair',0,'',''),(844,'nltk','Pairs are returned in LIFO (last-in, first-out) order.\nRaises KeyError if the dict is empty.\nIf self is frozen, raise ValueError.','return pairs',0,'',''),(845,'nltk','Pairs are returned in LIFO (last-in, first-out) order.\nRaises KeyError if the dict is empty.\nIf self is frozen, raise ValueError.','raise KeyError',0,'',''),(846,'nltk','Pairs are returned in LIFO (last-in, first-out) order.\nRaises KeyError if the dict is empty.\nIf self is frozen, raise ValueError.','raise ValueError',0,'',''),(847,'nltk','Return the value for key if key is in the dictionary, else default.\nIf self is frozen, raise ValueError.','return value for key',0,'',''),(848,'nltk','Return the value for key if key is in the dictionary, else default.\nIf self is frozen, raise ValueError.','raise ValueError',0,'',''),(849,'nltk','Feature lists may contain reentrant feature values.  A “reentrant\nfeature value” is a single feature value that can be accessed via\nmultiple feature paths.  Feature lists may also be cyclic.','access single feature value via multiple feature paths',0,'',''),(850,'nltk','Two feature lists are considered equal if they assign the same\nvalues to all features, and have the same reentrances.','assign same values to features',0,'',''),(851,'nltk','Append object to the end of the list.\nIf self is frozen, raise ValueError.','raise ValueError',0,'',''),(852,'nltk','Extend list by appending elements from the iterable.\nIf self is frozen, raise ValueError.','append elements from iterable',0,'',''),(853,'nltk','Extend list by appending elements from the iterable.\nIf self is frozen, raise ValueError.','raise ValueError',0,'',''),(854,'nltk','Insert object before index.\nIf self is frozen, raise ValueError.','raise ValueError',0,'',''),(855,'nltk','Remove and return item at index (default last).','remove item at index',0,'',''),(856,'nltk','Remove and return item at index (default last).','return item at index',0,'',''),(857,'nltk','Raises IndexError if list is empty or index is out of range.\nIf self is frozen, raise ValueError.','raise ValueError',0,'',''),(858,'nltk','Remove first occurrence of value.','remove first occurrence of value',0,'',''),(859,'nltk','Raises ValueError if the value is not present.\nIf self is frozen, raise ValueError.','raise ValueError',0,'',''),(860,'nltk','Raises ValueError if the value is not present.\nIf self is frozen, raise ValueError.','raise ValueError',0,'',''),(861,'nltk','Reverse IN PLACE.\nIf self is frozen, raise ValueError.','raise ValueError',0,'',''),(862,'nltk','Sort the list in ascending order and return None.','sort list in ascending',0,'',''),(863,'nltk','The reverse flag can be set to sort in descending order.\nIf self is frozen, raise ValueError.','set reverse flag',0,'',''),(864,'nltk','The reverse flag can be set to sort in descending order.\nIf self is frozen, raise ValueError.','raise ValueError',0,'',''),(865,'nltk','Feature structures may contain reentrant feature structures.  A\n“reentrant feature structure” is a single feature structure\nobject that can be accessed via multiple feature paths.  Feature\nstructures may also be cyclic.  A feature structure is “cyclic”\nif there is any feature path from the feature structure to itself.','access single feature structure object via multiple feature paths',0,'',''),(866,'nltk','Two feature structures are considered equal if they assign the\nsame values to all features, and have the same reentrancies.','assign same values to features',0,'',''),(867,'nltk','deep – If true, create a deep copy; if false, create\na shallow copy.','create deep copy if false',0,'',''),(868,'nltk','deep – If true, create a deep copy; if false, create\na shallow copy.','create shallow copy',0,'',''),(869,'nltk','Return True if self and other assign the same value to\nto every feature.  In particular, return true if\nself[p]==other[p] for every feature path p such\nthat self[p] or other[p] is a base value (i.e.,\nnot a nested feature structure).','assign same value',0,'',''),(870,'nltk','check_reentrance – If True, then also return False if\nthere is any difference between the reentrances of self\nand other.','return False',0,'',''),(871,'nltk','Return True if this feature structure is immutable.  Feature\nstructures can be made immutable with the freeze() method.\nImmutable feature structures may not be made mutable again,\nbut new mutable copies can be produced with the copy() method.','produce new mutable copies with copy() method',0,'',''),(872,'nltk','Return the feature structure that is obtained by deleting\nany feature whose value is a Variable.','return feature structure',0,'',''),(873,'nltk','Return the feature structure that is obtained by deleting\nany feature whose value is a Variable.','delete feature',0,'',''),(874,'nltk','Return the feature structure that is obtained by deleting\nany feature whose value is a Variable.','obtain feature structure',0,'',''),(875,'nltk','Return True if self subsumes other.  I.e., return true\nIf unifying self with other would result in a feature\nstructure equal to other.','return true',0,'',''),(876,'nltk','Return an iterator that generates this feature structure, and\neach feature structure it contains.  Each feature structure will\nbe generated exactly once.','return iterator',0,'',''),(877,'nltk','Return an iterator that generates this feature structure, and\neach feature structure it contains.  Each feature structure will\nbe generated exactly once.','return feature structure',0,'',''),(878,'nltk','and should return a tuple (value, position), where position is\nthe string position where the value ended.  (n.b.: order is\nimportant here!)','return tuple',0,'',''),(879,'nltk','Convert a string representation of a feature structure (as\ndisplayed by repr) into a FeatStruct.  This process\nimposes the following restrictions on the string\nrepresentation:','convert string representation into FeatStruct',0,'',''),(880,'nltk','Convert a string representation of a feature structure (as\ndisplayed by repr) into a FeatStruct.  This process\nimposes the following restrictions on the string\nrepresentation:','convert string representation of feature structure',0,'',''),(881,'nltk','Only the following basic feature value are supported:\nstrings, integers, variables, None, and unquoted\nalphanumeric strings.','support following basic feature value',0,'',''),(882,'nltk','For reentrant values, the first mention must specify\na reentrance identifier and a value; and any subsequent\nmentions must use arrows (\'->\') to reference the\nreentrance identifier.','specify reentrance identifier for reentrant values',0,'',''),(883,'nltk','For reentrant values, the first mention must specify\na reentrance identifier and a value; and any subsequent\nmentions must use arrows (\'->\') to reference the\nreentrance identifier.','specify value for reentrant values',0,'',''),(884,'nltk','For reentrant values, the first mention must specify\na reentrance identifier and a value; and any subsequent\nmentions must use arrows (\'->\') to reference the\nreentrance identifier.','reference reentrance identifier',0,'',''),(885,'nltk','A tuple (val, pos) of the feature structure created by\nparsing and the position where the parsed feature structure ends.','create  by parsing',0,'',''),(886,'nltk','A tuple (val, pos) of the feature structure created by\nparsing and the position where the parsed feature structure ends.','create  by position',0,'',''),(887,'nltk','If possible, return a single value..  If not, return\nthe value UnificationFailure.','return single value',0,'',''),(888,'nltk','If possible, return a single value..  If not, return\nthe value UnificationFailure.','return value UnificationFailure',0,'',''),(889,'nltk','Return a list of the feature paths of all features which are\nassigned incompatible values by fstruct1 and fstruct2.','return list of feature paths',0,'',''),(890,'nltk','Return a list of the feature paths of all features which are\nassigned incompatible values by fstruct1 and fstruct2.','assign incompatible values of feature paths',0,'',''),(891,'nltk','Return a list of the feature paths of all features which are\nassigned incompatible values by fstruct1 and fstruct2.','assign list of feature paths',0,'',''),(892,'nltk','Unify fstruct1 with fstruct2, and return the resulting feature\nstructure.  This unified feature structure is the minimal\nfeature structure that contains all feature value assignments from both\nfstruct1 and fstruct2, and that preserves all reentrancies.','return resulting feature structure',0,'',''),(893,'nltk','If no such feature structure exists (because fstruct1 and\nfstruct2 specify incompatible values for some feature), then\nunification fails, and unify returns None.','return none',0,'',''),(894,'nltk','Bound variables are replaced by their values.  Aliased\nvariables are replaced by their representative variable\n(if unbound) or the value of their representative variable\n(if bound).  I.e., if variable v is in bindings,\nthen v is replaced by bindings[v].  This will\nbe repeated until the variable is replaced by an unbound\nvariable or a non-variable value.','replace bound variables',0,'',''),(895,'nltk','Bound variables are replaced by their values.  Aliased\nvariables are replaced by their representative variable\n(if unbound) or the value of their representative variable\n(if bound).  I.e., if variable v is in bindings,\nthen v is replaced by bindings[v].  This will\nbe repeated until the variable is replaced by an unbound\nvariable or a non-variable value.','replace aliased variables',0,'',''),(896,'nltk','Bound variables are replaced by their values.  Aliased\nvariables are replaced by their representative variable\n(if unbound) or the value of their representative variable\n(if bound).  I.e., if variable v is in bindings,\nthen v is replaced by bindings[v].  This will\nbe repeated until the variable is replaced by an unbound\nvariable or a non-variable value.','replace v',0,'',''),(897,'nltk','Bound variables are replaced by their values.  Aliased\nvariables are replaced by their representative variable\n(if unbound) or the value of their representative variable\n(if bound).  I.e., if variable v is in bindings,\nthen v is replaced by bindings[v].  This will\nbe repeated until the variable is replaced by an unbound\nvariable or a non-variable value.','replace variable',0,'',''),(898,'nltk','Unbound variables are bound when they are unified with\nvalues; and aliased when they are unified with variables.\nI.e., if variable v is not in bindings, and is\nunified with a variable or value x, then\nbindings[v] is set to x.','bind unbound variables',0,'',''),(899,'nltk','Unbound variables are bound when they are unified with\nvalues; and aliased when they are unified with variables.\nI.e., if variable v is not in bindings, and is\nunified with a variable or value x, then\nbindings[v] is set to x.','set  v',0,'',''),(900,'nltk','bindings (dict(Variable -> any)) – A set of variable bindings to be used and\nupdated during unification.','update set of variable bindings',0,'',''),(901,'nltk','rename_vars (bool) – If True, then rename any variables in\nfstruct2 that are also used in fstruct1, in order to\navoid collisions on variable names.','rename variables',0,'',''),(902,'nltk','Basic data classes for representing context free grammars.  A\n“grammar” specifies which trees can represent the structure of a\ngiven text.  Each of these trees is called a “parse tree” for the\ntext (or simply a “parse”).  In a “context free” grammar, the set of\nparse trees for any piece of a text can depend only on that piece, and\nnot on the rest of the text (i.e., the piece’s context).  Context free\ngrammars are often used to find possible syntactic structures for\nsentences.  In this context, the leaves of a parse tree are word\ntokens; and the node values are phrasal categories, such as NP\nand VP.','call parse tree for text',0,'',''),(903,'nltk','The CFG class is used to encode context free grammars.  Each\nCFG consists of a start symbol and a set of productions.\nThe “start symbol” specifies the root node value for parse trees.  For example,\nthe start symbol for syntactic parsing is usually S.  Start\nsymbols are encoded using the Nonterminal class, which is discussed\nbelow.','encode context free grammars',0,'',''),(904,'nltk','The CFG class is used to encode context free grammars.  Each\nCFG consists of a start symbol and a set of productions.\nThe “start symbol” specifies the root node value for parse trees.  For example,\nthe start symbol for syntactic parsing is usually S.  Start\nsymbols are encoded using the Nonterminal class, which is discussed\nbelow.','specify root node value for parse trees',0,'',''),(905,'nltk','The CFG class is used to encode context free grammars.  Each\nCFG consists of a start symbol and a set of productions.\nThe “start symbol” specifies the root node value for parse trees.  For example,\nthe start symbol for syntactic parsing is usually S.  Start\nsymbols are encoded using the Nonterminal class, which is discussed\nbelow.','encode start symbols',0,'',''),(906,'nltk','Grammar productions are implemented by the Production class.\nEach Production consists of a left hand side and a right hand\nside.  The “left hand side” is a Nonterminal that specifies the\nnode type for a potential parent; and the “right hand side” is a list\nthat specifies allowable children for that parent.  This lists\nconsists of Nonterminals and text types: each Nonterminal\nindicates that the corresponding child may be a TreeToken with the\nspecified node type; and each text type indicates that the\ncorresponding child may be a Token with the with that type.','specify node type for potential parent',0,'',''),(907,'nltk','Grammar productions are implemented by the Production class.\nEach Production consists of a left hand side and a right hand\nside.  The “left hand side” is a Nonterminal that specifies the\nnode type for a potential parent; and the “right hand side” is a list\nthat specifies allowable children for that parent.  This lists\nconsists of Nonterminals and text types: each Nonterminal\nindicates that the corresponding child may be a TreeToken with the\nspecified node type; and each text type indicates that the\ncorresponding child may be a Token with the with that type.','specify nonterminal for potential parent',0,'',''),(908,'nltk','Grammar productions are implemented by the Production class.\nEach Production consists of a left hand side and a right hand\nside.  The “left hand side” is a Nonterminal that specifies the\nnode type for a potential parent; and the “right hand side” is a list\nthat specifies allowable children for that parent.  This lists\nconsists of Nonterminals and text types: each Nonterminal\nindicates that the corresponding child may be a TreeToken with the\nspecified node type; and each text type indicates that the\ncorresponding child may be a Token with the with that type.','specify list for potential parent',0,'',''),(909,'nltk','Grammar productions are implemented by the Production class.\nEach Production consists of a left hand side and a right hand\nside.  The “left hand side” is a Nonterminal that specifies the\nnode type for a potential parent; and the “right hand side” is a list\nthat specifies allowable children for that parent.  This lists\nconsists of Nonterminals and text types: each Nonterminal\nindicates that the corresponding child may be a TreeToken with the\nspecified node type; and each text type indicates that the\ncorresponding child may be a Token with the with that type.','specify allowable children for parent',0,'',''),(910,'nltk','Grammar productions are implemented by the Production class.\nEach Production consists of a left hand side and a right hand\nside.  The “left hand side” is a Nonterminal that specifies the\nnode type for a potential parent; and the “right hand side” is a list\nthat specifies allowable children for that parent.  This lists\nconsists of Nonterminals and text types: each Nonterminal\nindicates that the corresponding child may be a TreeToken with the\nspecified node type; and each text type indicates that the\ncorresponding child may be a Token with the with that type.','specify list for parent',0,'',''),(911,'nltk','The Nonterminal class is used to distinguish node values from leaf\nvalues.  This prevents the grammar from accidentally using a leaf\nvalue (such as the English word “A”) as the node of a subtree.  Within\na CFG, all node values are wrapped in the Nonterminal\nclass. Note, however, that the trees that are specified by the grammar do\nnot include these Nonterminal wrappers.','prevent grammar',0,'',''),(912,'nltk','The Nonterminal class is used to distinguish node values from leaf\nvalues.  This prevents the grammar from accidentally using a leaf\nvalue (such as the English word “A”) as the node of a subtree.  Within\na CFG, all node values are wrapped in the Nonterminal\nclass. Note, however, that the trees that are specified by the grammar do\nnot include these Nonterminal wrappers.','wrap node values within CFG',0,'',''),(913,'nltk','The Nonterminal class is used to distinguish node values from leaf\nvalues.  This prevents the grammar from accidentally using a leaf\nvalue (such as the English word “A”) as the node of a subtree.  Within\na CFG, all node values are wrapped in the Nonterminal\nclass. Note, however, that the trees that are specified by the grammar do\nnot include these Nonterminal wrappers.','wrap node values in nonterminal class',0,'',''),(914,'nltk','The Nonterminal class is used to distinguish node values from leaf\nvalues.  This prevents the grammar from accidentally using a leaf\nvalue (such as the English word “A”) as the node of a subtree.  Within\na CFG, all node values are wrapped in the Nonterminal\nclass. Note, however, that the trees that are specified by the grammar do\nnot include these Nonterminal wrappers.','specify trees',0,'',''),(915,'nltk','Grammars can also be given a more procedural interpretation.  According to\nthis interpretation, a Grammar specifies any tree structure tree that\ncan be produced by the following procedure:','specify tree structure tree',0,'',''),(916,'nltk','Grammars can also be given a more procedural interpretation.  According to\nthis interpretation, a Grammar specifies any tree structure tree that\ncan be produced by the following procedure:','produce tree structure tree',0,'',''),(917,'nltk','The operation of replacing the left hand side (lhs) of a production\nwith the right hand side (rhs) in a tree (tree) is known as\n“expanding” lhs to rhs in tree.','replace left hand side with right hand side',0,'',''),(918,'nltk','The operation of replacing the left hand side (lhs) of a production\nwith the right hand side (rhs) in a tree (tree) is known as\n“expanding” lhs to rhs in tree.','replace left hand side of production',0,'',''),(919,'nltk','The operation of replacing the left hand side (lhs) of a production\nwith the right hand side (rhs) in a tree (tree) is known as\n“expanding” lhs to rhs in tree.','expand lhs',0,'',''),(920,'nltk','A context-free grammar.  A grammar consists of a start state and\na set of productions.  The set of terminals and nonterminals is\nimplicitly specified by the productions.','specify set of terminals',0,'',''),(921,'nltk','A context-free grammar.  A grammar consists of a start state and\na set of productions.  The set of terminals and nonterminals is\nimplicitly specified by the productions.','specify set of nonterminals',0,'',''),(922,'nltk','Convert all non-binary rules into binary by introducing\nnew tokens.\nExample::\nOriginal:','convert non-binary rules into binary',0,'',''),(923,'nltk','Convert all non-binary rules into binary by introducing\nnew tokens.\nExample::\nOriginal:','convert non-binary rules by introducing',0,'',''),(924,'nltk','Convert all non-binary rules into binary by introducing\nnew tokens.\nExample::\nOriginal:','introduce new tokens',0,'',''),(925,'nltk','Check whether the grammar rules cover the given list of tokens.\nIf not, then raise an exception.','raise exception',0,'',''),(926,'nltk','Returns a new Grammer that is in chomsky normal\n:param: new_token_padding','return new Grammer',0,'',''),(927,'nltk','Eliminate start rule in case it appears on RHS\nExample: S -> S0 S1 and S0 -> S1 S\nThen another rule S0_Sigma -> S is added','add eliminate start rule in case',0,'',''),(928,'nltk','Return the grammar instance corresponding to the input string(s).','return grammar instance corresponding to input string',0,'',''),(929,'nltk','Return the set of all nonterminals for which the given category\nis a left corner. This is the inverse of the leftcorner relation.','return set of nonterminals',0,'',''),(930,'nltk','Return the set of all nonterminals that the given nonterminal\ncan start with, including itself.','return set of nonterminals',0,'',''),(931,'nltk','Return the grammar productions, filtered by the left-hand side\nor the first item in the right-hand side.','filter  in right-hand side',0,'',''),(932,'nltk','Return the grammar productions, filtered by the left-hand side\nor the first item in the right-hand side.','filter  by left-hand side',0,'',''),(933,'nltk','Return the grammar productions, filtered by the left-hand side\nor the first item in the right-hand side.','filter  by first item',0,'',''),(934,'nltk','Return the grammar productions, filtered by the left-hand side\nor the first item in the right-hand side.','filter  return grammar productions',0,'',''),(935,'nltk','Remove nonlexical unitary rules and convert them to\nlexical','remove nonlexical unitary rules',0,'',''),(936,'nltk','Remove nonlexical unitary rules and convert them to\nlexical','convert nonlexical unitary rules',0,'',''),(937,'nltk','A dependency grammar.  A DependencyGrammar consists of a set of\nproductions.  Each production specifies a head/modifier relationship\nbetween a pair of words.','specify head/modifier relationship between pair',0,'',''),(938,'nltk','A non-terminal symbol for a context free grammar.  Nonterminal\nis a wrapper class for node values; it is used by Production\nobjects to distinguish node values from leaf values.\nThe node value that is wrapped by a Nonterminal is known as its\n“symbol”.  Symbols are typically strings representing phrasal\ncategories (such as \"NP\" or \"VP\").  However, more complex\nsymbol types are sometimes used (e.g., for lexicalized grammars).\nSince symbols are node values, they must be immutable and\nhashable.  Two Nonterminals are considered equal if their\nsymbols are equal.','wrap node value',0,'',''),(939,'nltk','Return the node value corresponding to this Nonterminal.','return node value corresponding to nonterminal',0,'',''),(940,'nltk','A probabilistic context-free grammar.  A PCFG consists of a\nstart state and a set of productions with probabilities.  The set of\nterminals and nonterminals is implicitly specified by the productions.','specify set of terminals',0,'',''),(941,'nltk','A probabilistic context-free grammar.  A PCFG consists of a\nstart state and a set of productions with probabilities.  The set of\nterminals and nonterminals is implicitly specified by the productions.','specify set of nonterminals',0,'',''),(942,'nltk','productions (list(Production)) – The list of productions that defines the grammar','define grammar',0,'',''),(943,'nltk','productions (list(Production)) – The list of productions that defines the grammar','define productions',0,'',''),(944,'nltk','Given a string containing a list of symbol names, return a list of\nNonterminals constructed from those symbols.','return list of nonterminals',0,'',''),(945,'nltk','A list of Nonterminals constructed from the symbol\nnames given in symbols.  The Nonterminals are sorted\nin the same order as the symbols names.','sort nonterminals',0,'',''),(946,'nltk','Return a pair consisting of a starting category and a list of\nProductions.','return pair',0,'',''),(947,'nltk','nonterm_parser – a function for parsing nonterminals.\nIt should take a (string, position) as argument and\nreturn a (nonterminal, position) as result.','return as result',0,'',''),(948,'nltk','Provide structured access to documentation.','provide structured access to documentation',0,'',''),(949,'nltk','The FreqDist class is used to encode “frequency distributions”,\nwhich count the number of times that each outcome of an experiment\noccurs.','encode frequency distributions',0,'',''),(950,'nltk','The ProbDistI class defines a standard interface for “probability\ndistributions”, which encode the probability of each outcome for an\nexperiment.  There are two types of probability distribution:','define standard interface for probability distributions',0,'',''),(951,'nltk','The ProbDistI class defines a standard interface for “probability\ndistributions”, which encode the probability of each outcome for an\nexperiment.  There are two types of probability distribution:','encode probability of outcome',0,'',''),(952,'nltk','The ProbDistI class defines a standard interface for “probability\ndistributions”, which encode the probability of each outcome for an\nexperiment.  There are two types of probability distribution:','encode probability distributions of outcome',0,'',''),(953,'nltk','“derived probability distributions” are created from frequency\ndistributions.  They attempt to model the probability distribution\nthat generated the frequency distribution.','create derived probability distributions from frequency distributions',0,'',''),(954,'nltk','“analytic probability distributions” are created directly from\nparameters (such as variance).','create analytic probability distributions from parameters',0,'',''),(955,'nltk','The ConditionalFreqDist class and ConditionalProbDistI interface\nare used to encode conditional distributions.  Conditional probability\ndistributions can be derived or analytic; but currently the only\nimplementation of the ConditionalProbDistI interface is\nConditionalProbDist, a derived distribution.','encode conditional distributions',0,'',''),(956,'nltk','A collection of frequency distributions for a single experiment\nrun under different conditions.  Conditional frequency\ndistributions are used to record the number of times each sample\noccurred, given the condition under which the experiment was run.\nFor example, a conditional frequency distribution could be used to\nrecord the frequency of each word (type) in a document, given its\nlength.  Formally, a conditional frequency distribution can be\ndefined as a function that maps from each condition to the\nFreqDist for the experiment under that condition.','define conditional frequency distribution as function',0,'',''),(957,'nltk','Conditional frequency distributions are typically constructed by\nrepeatedly running an experiment under a variety of conditions,\nand incrementing the sample outcome counts for the appropriate\nconditions.  For example, the following code will produce a\nconditional frequency distribution that encodes how often each\nword type occurs, given the length of that word type:','produce conditional frequency distribution',0,'',''),(958,'nltk','Conditional frequency distributions are typically constructed by\nrepeatedly running an experiment under a variety of conditions,\nand incrementing the sample outcome counts for the appropriate\nconditions.  For example, the following code will produce a\nconditional frequency distribution that encodes how often each\nword type occurs, given the length of that word type:','encode conditional frequency distribution',0,'',''),(959,'nltk','The frequency distribution for each condition is accessed using\nthe indexing operator:','access frequency distribution for condition',0,'',''),(960,'nltk','When the indexing operator is used to access the frequency\ndistribution for a condition that has not been accessed before,\nConditionalFreqDist creates a new empty FreqDist for that\ncondition.','access frequency distribution for condition',0,'',''),(961,'nltk','When the indexing operator is used to access the frequency\ndistribution for a condition that has not been accessed before,\nConditionalFreqDist creates a new empty FreqDist for that\ncondition.','create new empty FreqDist for condition',0,'',''),(962,'nltk','Return the total number of sample outcomes that have been\nrecorded by this ConditionalFreqDist.','return total number of sample outcomes',0,'',''),(963,'nltk','Return a list of the conditions that have been accessed for\nthis ConditionalFreqDist.  Use the indexing operator to\naccess the frequency distribution for a given condition.\nNote that the frequency distributions for some conditions\nmay contain zero sample outcomes.','return list of conditions',0,'',''),(964,'nltk','Return a list of the conditions that have been accessed for\nthis ConditionalFreqDist.  Use the indexing operator to\naccess the frequency distribution for a given condition.\nNote that the frequency distributions for some conditions\nmay contain zero sample outcomes.','access conditions for ConditionalFreqDist',0,'',''),(965,'nltk','Return a list of the conditions that have been accessed for\nthis ConditionalFreqDist.  Use the indexing operator to\naccess the frequency distribution for a given condition.\nNote that the frequency distributions for some conditions\nmay contain zero sample outcomes.','access frequency distribution for given condition',0,'',''),(966,'nltk','Plot the given samples from the conditional frequency distribution.\nFor a cumulative plot, specify cumulative=True.\n(Requires Matplotlib to be installed.)','specify  for cumulative plot',0,'',''),(967,'nltk','The ConditionalFreqDist specifies the frequency\ndistribution for each condition.','specify frequency distribution for condition',0,'',''),(968,'nltk','The ProbDist factory is a function that takes a\ncondition’s frequency distribution, and returns its\nprobability distribution.  A ProbDist class’s name (such as\nMLEProbDist or HeldoutProbDist) can be used to specify\nthat class’s constructor.','return probability distribution',0,'',''),(969,'nltk','The ProbDist factory is a function that takes a\ncondition’s frequency distribution, and returns its\nprobability distribution.  A ProbDist class’s name (such as\nMLEProbDist or HeldoutProbDist) can be used to specify\nthat class’s constructor.','return function',0,'',''),(970,'nltk','The ProbDist factory is a function that takes a\ncondition’s frequency distribution, and returns its\nprobability distribution.  A ProbDist class’s name (such as\nMLEProbDist or HeldoutProbDist) can be used to specify\nthat class’s constructor.','specify constructor',0,'',''),(971,'nltk','The first argument to the ProbDist factory is the frequency\ndistribution that it should model; and the remaining arguments are\nspecified by the factory_args parameter to the\nConditionalProbDist constructor.  For example, the following\ncode constructs a ConditionalProbDist, where the probability\ndistribution for each condition is an ELEProbDist with 10 bins:','specify remaining arguments to ConditionalProbDist constructor',0,'',''),(972,'nltk','A collection of probability distributions for a single experiment\nrun under different conditions.  Conditional probability\ndistributions are used to estimate the likelihood of each sample,\ngiven the condition under which the experiment was run.  For\nexample, a conditional probability distribution could be used to\nestimate the probability of each word type in a document, given\nthe length of the word type.  Formally, a conditional probability\ndistribution can be defined as a function that maps from each\ncondition to the ProbDist for the experiment under that\ncondition.','define conditional probability distribution as function',0,'',''),(973,'nltk','Return a list of the conditions that are represented by\nthis ConditionalProbDist.  Use the indexing operator to\naccess the probability distribution for a given condition.','return list of conditions',0,'',''),(974,'nltk','Return a list of the conditions that are represented by\nthis ConditionalProbDist.  Use the indexing operator to\naccess the probability distribution for a given condition.','access probability distribution for given condition',0,'',''),(975,'nltk','Return the ratio by which counts are discounted on average: c*/c','return ratio',0,'',''),(976,'nltk','Return the list of frequency distributions that this ProbDist is based on.','return list of frequency distributions',0,'',''),(977,'nltk','Return the probability for a given sample.  Probabilities\nare always real numbers in the range [0, 1].','return probability for given sample',0,'',''),(978,'nltk','sample (any) – The sample whose probability\nshould be returned.','return probability',0,'',''),(979,'nltk','sample (any) – The sample whose probability\nshould be returned.','return sample',0,'',''),(980,'nltk','Return a list of all samples that have nonzero probabilities.\nUse prob to find the probability of each sample.','return list of samples',0,'',''),(981,'nltk','An alternative ConditionalProbDist that simply wraps a dictionary of\nProbDists rather than creating these from FreqDists.','wrap dictionary of ProbDists',0,'',''),(982,'nltk','An alternative ConditionalProbDist that simply wraps a dictionary of\nProbDists rather than creating these from FreqDists.','create  from FreqDists',0,'',''),(983,'nltk','A probability distribution whose probabilities are directly\nspecified by a given dictionary.  The given dictionary maps\nsamples to probabilities.','specify  by given dictionary',0,'',''),(984,'nltk','Return the base 2 logarithm of the probability for a given sample.','return base logarithm of probability',0,'',''),(985,'nltk','Return the sample with the greatest probability.  If two or\nmore samples have the same probability, return one of them;\nwhich sample is returned is undefined.','return sample',0,'',''),(986,'nltk','The expected likelihood estimate for the probability distribution\nof the experiment used to generate a frequency distribution.  The\n“expected likelihood estimate” approximates the probability of a\nsample with count c from an experiment with N outcomes and\nB bins as (c+0.5)/(N+B/2).  This is equivalent to adding 0.5\nto the count for each bin, and taking the maximum likelihood\nestimate of the resulting frequency distribution.','add  to count',0,'',''),(987,'nltk','A frequency distribution for the outcomes of an experiment.  A\nfrequency distribution records the number of times each outcome of\nan experiment has occurred.  For example, a frequency distribution\ncould be used to record the frequency of each word type in a\ndocument.  Formally, a frequency distribution can be defined as a\nfunction mapping from each sample to the number of times that\nsample occurred as an outcome.','define frequency distribution as function mapping',0,'',''),(988,'nltk','A frequency distribution for the outcomes of an experiment.  A\nfrequency distribution records the number of times each outcome of\nan experiment has occurred.  For example, a frequency distribution\ncould be used to record the frequency of each word type in a\ndocument.  Formally, a frequency distribution can be defined as a\nfunction mapping from each sample to the number of times that\nsample occurred as an outcome.','define frequency distribution to number',0,'',''),(989,'nltk','Frequency distributions are generally constructed by running a\nnumber of experiments, and incrementing the count for a sample\nevery time it is an outcome of an experiment.  For example, the\nfollowing code will produce a frequency distribution that encodes\nhow often each word occurs in a text:','produce frequency distribution',0,'',''),(990,'nltk','Frequency distributions are generally constructed by running a\nnumber of experiments, and incrementing the count for a sample\nevery time it is an outcome of an experiment.  For example, the\nfollowing code will produce a frequency distribution that encodes\nhow often each word occurs in a text:','encode frequency distribution',0,'',''),(991,'nltk','Return the total number of sample values (or “bins”) that\nhave counts greater than zero.  For the total\nnumber of sample outcomes recorded, use FreqDist.N().\n(FreqDist.B() is the same as len(FreqDist).)','return total number of sample values',0,'',''),(992,'nltk','Return the total number of sample outcomes that have been\nrecorded by this FreqDist.  For the number of unique\nsample values (or bins) with counts greater than zero, use\nFreqDist.B().','return total number of sample outcomes',0,'',''),(993,'nltk','Create a copy of this frequency distribution.','create copy of frequency distribution',0,'',''),(994,'nltk','Return the frequency of a given sample.  The frequency of a\nsample is defined as the count of that sample divided by the\ntotal number of sample outcomes that have been recorded by\nthis FreqDist.  The count of a sample is defined as the\nnumber of times that sample outcome was recorded by this\nFreqDist.  Frequencies are always real numbers in the range\n[0, 1].','return frequency of given sample',0,'',''),(995,'nltk','Return the frequency of a given sample.  The frequency of a\nsample is defined as the count of that sample divided by the\ntotal number of sample outcomes that have been recorded by\nthis FreqDist.  The count of a sample is defined as the\nnumber of times that sample outcome was recorded by this\nFreqDist.  Frequencies are always real numbers in the range\n[0, 1].','define frequency as count',0,'',''),(996,'nltk','Return the frequency of a given sample.  The frequency of a\nsample is defined as the count of that sample divided by the\ntotal number of sample outcomes that have been recorded by\nthis FreqDist.  The count of a sample is defined as the\nnumber of times that sample outcome was recorded by this\nFreqDist.  Frequencies are always real numbers in the range\n[0, 1].','define frequency of sample',0,'',''),(997,'nltk','Return the frequency of a given sample.  The frequency of a\nsample is defined as the count of that sample divided by the\ntotal number of sample outcomes that have been recorded by\nthis FreqDist.  The count of a sample is defined as the\nnumber of times that sample outcome was recorded by this\nFreqDist.  Frequencies are always real numbers in the range\n[0, 1].','define count as number',0,'',''),(998,'nltk','Return the frequency of a given sample.  The frequency of a\nsample is defined as the count of that sample divided by the\ntotal number of sample outcomes that have been recorded by\nthis FreqDist.  The count of a sample is defined as the\nnumber of times that sample outcome was recorded by this\nFreqDist.  Frequencies are always real numbers in the range\n[0, 1].','define count of sample',0,'',''),(999,'nltk','sample (any) – the sample whose frequency\nshould be returned.','return frequency',0,'',''),(1000,'nltk','sample (any) – the sample whose frequency\nshould be returned.','return sample',0,'',''),(1001,'nltk','Return a list of all samples that occur once (hapax legomena)','return list of samples',0,'',''),(1002,'nltk','Return the sample with the greatest number of outcomes in this\nfrequency distribution.  If two or more samples have the same\nnumber of outcomes, return one of them; which sample is\nreturned is undefined.  If no outcomes have occurred in this\nfrequency distribution, return None.','return sample',0,'',''),(1003,'nltk','Return the sample with the greatest number of outcomes in this\nfrequency distribution.  If two or more samples have the same\nnumber of outcomes, return one of them; which sample is\nreturned is undefined.  If no outcomes have occurred in this\nfrequency distribution, return None.','return none',0,'',''),(1004,'nltk','Plot samples from the frequency distribution\ndisplaying the most frequent sample first.  If an integer\nparameter is supplied, stop after this many samples have been\nplotted.  For a cumulative plot, specify cumulative=True.\n(Requires Matplotlib to be installed.)','display frequent sample',0,'',''),(1005,'nltk','Plot samples from the frequency distribution\ndisplaying the most frequent sample first.  If an integer\nparameter is supplied, stop after this many samples have been\nplotted.  For a cumulative plot, specify cumulative=True.\n(Requires Matplotlib to be installed.)','specify  for cumulative plot',0,'',''),(1006,'nltk','Print a string representation of this FreqDist to ‘stream’','print string representation of FreqDist',0,'',''),(1007,'nltk','Print a string representation of this FreqDist to ‘stream’','print string representation to stream',0,'',''),(1008,'nltk','Return the dictionary mapping r to Nr, the number of samples with frequency r, where Nr > 0.','return dictionary mapping r of samples',0,'',''),(1009,'nltk','Return the dictionary mapping r to Nr, the number of samples with frequency r, where Nr > 0.','return dictionary mapping r to nr',0,'',''),(1010,'nltk','Return the dictionary mapping r to Nr, the number of samples with frequency r, where Nr > 0.','return number of samples',0,'',''),(1011,'nltk','Return the dictionary mapping r to Nr, the number of samples with frequency r, where Nr > 0.','return number to nr',0,'',''),(1012,'nltk','bins (int) – The number of possible sample outcomes.  bins\nis used to calculate Nr(0).  In particular, Nr(0) is\nbins-self.B().  If bins is not specified, it\ndefaults to self.B() (so Nr(0) will be 0).','calculate Nr(0)',0,'',''),(1013,'nltk','Override Counter.setdefault() to invalidate the cached N','override Counter.setdefault()',0,'',''),(1014,'nltk','Tabulate the given samples from the frequency distribution (cumulative),\ndisplaying the most frequent sample first.  If an integer\nparameter is supplied, stop after this many samples have been\nplotted.','display frequent sample',0,'',''),(1015,'nltk','Override Counter.update() to invalidate the cached N','override Counter.update()',0,'',''),(1016,'nltk','The heldout estimate for the probability distribution of the\nexperiment used to generate two frequency distributions.  These\ntwo frequency distributions are called the “heldout frequency\ndistribution” and the “base frequency distribution.”  The\n“heldout estimate” uses uses the “heldout frequency\ndistribution” to predict the probability of each sample, given its\nfrequency in the “base frequency distribution”.','call heldout frequency distribution',0,'',''),(1017,'nltk','The heldout estimate for the probability distribution of the\nexperiment used to generate two frequency distributions.  These\ntwo frequency distributions are called the “heldout frequency\ndistribution” and the “base frequency distribution.”  The\n“heldout estimate” uses uses the “heldout frequency\ndistribution” to predict the probability of each sample, given its\nfrequency in the “base frequency distribution”.','call base frequency distribution',0,'',''),(1018,'nltk','The heldout estimate for the probability distribution of the\nexperiment used to generate two frequency distributions.  These\ntwo frequency distributions are called the “heldout frequency\ndistribution” and the “base frequency distribution.”  The\n“heldout estimate” uses uses the “heldout frequency\ndistribution” to predict the probability of each sample, given its\nfrequency in the “base frequency distribution”.','call frequency distributions',0,'',''),(1019,'nltk','The heldout estimate for the probability distribution of the\nexperiment used to generate two frequency distributions.  These\ntwo frequency distributions are called the “heldout frequency\ndistribution” and the “base frequency distribution.”  The\n“heldout estimate” uses uses the “heldout frequency\ndistribution” to predict the probability of each sample, given its\nfrequency in the “base frequency distribution”.','predict probability of sample',0,'',''),(1020,'nltk','In order to increase the efficiency of the prob member\nfunction, Tr[r]/(Nr[r].N) is precomputed for each value of r\nwhen the HeldoutProbDist is created.','create HeldoutProbDist',0,'',''),(1021,'nltk','_estimate – A list mapping from r, the number of\ntimes that a sample occurs in the base distribution, to the\nprobability estimate for that sample.  _estimate[r] is\ncalculated by finding the average frequency in the heldout\ndistribution of all samples that occur r times in the base\ndistribution.  In particular, _estimate[r] =\nTr[r]/(Nr[r].N).','calculate  r',0,'',''),(1022,'nltk','Return the base frequency distribution that this probability\ndistribution is based on.','return base frequency distribution',0,'',''),(1023,'nltk','Return the heldout frequency distribution that this\nprobability distribution is based on.','return heldout frequency distribution',0,'',''),(1024,'nltk','Set the log probability associated with this object to\nlogprob.  I.e., set the probability associated with this\nobject to 2**(logprob).','set log probability',0,'',''),(1025,'nltk','Set the log probability associated with this object to\nlogprob.  I.e., set the probability associated with this\nobject to 2**(logprob).','set probability',0,'',''),(1026,'nltk','Set the probability associated with this object to prob.','set probability',0,'',''),(1027,'nltk','Kneser-Ney estimate of a probability distribution. This is a version of\nback-off that counts how likely an n-gram is provided the n-1-gram had\nbeen seen in training. Extends the ProbDistI interface, requires a trigram\nFreqDist instance to train on. Optionally, a different from default discount\nvalue can be specified. The default discount is set to 0.75.','specify different value',0,'',''),(1028,'nltk','Kneser-Ney estimate of a probability distribution. This is a version of\nback-off that counts how likely an n-gram is provided the n-1-gram had\nbeen seen in training. Extends the ProbDistI interface, requires a trigram\nFreqDist instance to train on. Optionally, a different from default discount\nvalue can be specified. The default discount is set to 0.75.','set default discount',0,'',''),(1029,'nltk','Set the value by which counts are discounted to the value of discount.','set value',0,'',''),(1030,'nltk','The Laplace estimate for the probability distribution of the\nexperiment used to generate a frequency distribution.  The\n“Laplace estimate” approximates the probability of a sample with\ncount c from an experiment with N outcomes and B bins as\n(c+1)/(N+B).  This is equivalent to adding one to the count for\neach bin, and taking the maximum likelihood estimate of the\nresulting frequency distribution.','add  to count',0,'',''),(1031,'nltk','The Lidstone estimate for the probability distribution of the\nexperiment used to generate a frequency distribution.  The\n“Lidstone estimate” is parameterized by a real number gamma,\nwhich typically ranges from 0 to 1.  The Lidstone estimate\napproximates the probability of a sample with count c from an\nexperiment with N outcomes and B bins as\nc+gamma)/(N+B*gamma).  This is equivalent to adding\ngamma to the count for each bin, and taking the maximum\nlikelihood estimate of the resulting frequency distribution.','add gamma to count',0,'',''),(1032,'nltk','Return the frequency distribution that this probability\ndistribution is based on.','return frequency distribution',0,'',''),(1033,'nltk','An mutable probdist where the probabilities may be easily modified. This\nsimply copies an existing probdist, storing the probability values in a\nmutable dictionary and providing an update method.','modify probabilities',0,'',''),(1034,'nltk','An mutable probdist where the probabilities may be easily modified. This\nsimply copies an existing probdist, storing the probability values in a\nmutable dictionary and providing an update method.','provide update method',0,'',''),(1035,'nltk','Update the probability for the given sample. This may cause the object\nto stop being the valid probability distribution - the user must\nensure that they update the sample probabilities such that all samples\nhave probabilities between 0 and 1 and that all probabilities sum to\none.','update probability for given sample',0,'',''),(1036,'nltk','sample (any) – the sample for which to update the probability','update probability',0,'',''),(1037,'nltk','A probability distribution for the outcomes of an experiment.  A\nprobability distribution specifies how likely it is that an\nexperiment will have any given outcome.  For example, a\nprobability distribution could be used to predict the probability\nthat a token in a document will have a given type.  Formally, a\nprobability distribution can be defined as a function mapping from\nsamples to nonnegative real numbers, such that the sum of every\nnumber in the function’s range is 1.0.  A ProbDist is often\nused to model the probability distribution of the experiment used\nto generate a frequency distribution.','predict probability',0,'',''),(1038,'nltk','A probability distribution for the outcomes of an experiment.  A\nprobability distribution specifies how likely it is that an\nexperiment will have any given outcome.  For example, a\nprobability distribution could be used to predict the probability\nthat a token in a document will have a given type.  Formally, a\nprobability distribution can be defined as a function mapping from\nsamples to nonnegative real numbers, such that the sum of every\nnumber in the function’s range is 1.0.  A ProbDist is often\nused to model the probability distribution of the experiment used\nto generate a frequency distribution.','define probability distribution as function mapping',0,'',''),(1039,'nltk','A probability distribution for the outcomes of an experiment.  A\nprobability distribution specifies how likely it is that an\nexperiment will have any given outcome.  For example, a\nprobability distribution could be used to predict the probability\nthat a token in a document will have a given type.  Formally, a\nprobability distribution can be defined as a function mapping from\nsamples to nonnegative real numbers, such that the sum of every\nnumber in the function’s range is 1.0.  A ProbDist is often\nused to model the probability distribution of the experiment used\nto generate a frequency distribution.','define probability distribution from samples',0,'',''),(1040,'nltk','Return a randomly selected sample from this probability distribution.\nThe probability of returning each sample samp is equal to\nself.prob(samp).','return selected sample from probability distribution',0,'',''),(1041,'nltk','Return a randomly selected sample from this probability distribution.\nThe probability of returning each sample samp is equal to\nself.prob(samp).','return sample samp',0,'',''),(1042,'nltk','A mix-in class to associate probabilities with other classes\n(trees, rules, etc.).  To use the ProbabilisticMixIn class,\ndefine a new class that derives from an existing class and from\nProbabilisticMixIn.  You will need to define a new constructor for\nthe new class, which explicitly calls the constructors of both its\nparent classes.  For example:','define new class',0,'',''),(1043,'nltk','A mix-in class to associate probabilities with other classes\n(trees, rules, etc.).  To use the ProbabilisticMixIn class,\ndefine a new class that derives from an existing class and from\nProbabilisticMixIn.  You will need to define a new constructor for\nthe new class, which explicitly calls the constructors of both its\nparent classes.  For example:','define new constructor for new class',0,'',''),(1044,'nltk','A mix-in class to associate probabilities with other classes\n(trees, rules, etc.).  To use the ProbabilisticMixIn class,\ndefine a new class that derives from an existing class and from\nProbabilisticMixIn.  You will need to define a new constructor for\nthe new class, which explicitly calls the constructors of both its\nparent classes.  For example:','call constructors of parent classes',0,'',''),(1045,'nltk','A mix-in class to associate probabilities with other classes\n(trees, rules, etc.).  To use the ProbabilisticMixIn class,\ndefine a new class that derives from an existing class and from\nProbabilisticMixIn.  You will need to define a new constructor for\nthe new class, which explicitly calls the constructors of both its\nparent classes.  For example:','call new class of parent classes',0,'',''),(1046,'nltk','You should generally also redefine the string representation\nmethods, the comparison methods, and the hashing method.','redefine hashing method',0,'',''),(1047,'nltk','You should generally also redefine the string representation\nmethods, the comparison methods, and the hashing method.','redefine string representation methods',0,'',''),(1048,'nltk','You should generally also redefine the string representation\nmethods, the comparison methods, and the hashing method.','redefine comparison methods',0,'',''),(1049,'nltk','This function returns the total mass of probability transfers from the\nseen samples to the unseen samples.','return total mass of probability transfers',0,'',''),(1050,'nltk','This function returns the total mass of probability transfers from the\nseen samples to the unseen samples.','return total mass from seen samples',0,'',''),(1051,'nltk','Return the sample’s probability.','return probability',0,'',''),(1052,'nltk','A probability distribution that assigns equal probability to each\nsample in a given set; and a zero probability to all other\nsamples.','assign probability distribution',0,'',''),(1053,'nltk','Given two numbers logx = log(x) and logy = log(y), return\nlog(x+y).  Conceptually, this is the same as returning\nlog(2**(logx)+2**(logy)), but the actual implementation\navoids overflow errors that could result from direct computation.','return log(x+y)',0,'',''),(1054,'nltk','Given two numbers logx = log(x) and logy = log(y), return\nlog(x+y).  Conceptually, this is the same as returning\nlog(2**(logx)+2**(logy)), but the actual implementation\navoids overflow errors that could result from direct computation.','return log',0,'',''),(1055,'nltk','This module brings together a variety of NLTK functionality for\ntext analysis, and provides simple, interactive interfaces.\nFunctionality includes: concordancing, collocation discovery,\nregular expression search over tokenized strings, and\ndistributional similarity.','provide simple interactive interfaces',0,'',''),(1056,'nltk','Provided with a list of words, these will be found as a phrase.','provide  with list',0,'',''),(1057,'nltk','A list of the offset positions at which the given\nword occurs.  If a key function was specified for the\nindex, then given word’s key will be looked up.','specify key function for index',0,'',''),(1058,'nltk','Print concordance lines given the query word.\n:param word: The target word or phrase (a list of strings)\n:type word: str or list\n:param lines: The number of lines to display (default=25)\n:type lines: int\n:param width: The width of each line, in characters (default=80)\n:type width: int\n:param save: The option to save the concordance.\n:type save: bool','save concordance',0,'',''),(1059,'nltk','The document that this concordance index was\ncreated from.','create document that concordance index',0,'',''),(1060,'nltk','A bidirectional index between words and their ‘contexts’ in a text.\nThe context of a word is usually defined to be the words that occur\nin a fixed window around the word; but other definitions may also\nbe used by providing a custom context function.','provide custom context function',0,'',''),(1061,'nltk','A bidirectional index between words and their ‘contexts’ in a text.\nThe context of a word is usually defined to be the words that occur\nin a fixed window around the word; but other definitions may also\nbe used by providing a custom context function.','define context of word',0,'',''),(1062,'nltk','fail_on_unknown – If true, then raise a value error if\nany of the given words do not occur at all in the index.','raise value error if true',0,'',''),(1063,'nltk','The document that this context index was\ncreated from.','create context index',0,'',''),(1064,'nltk','Return a dictionary mapping from words to ‘similarity scores,’\nindicating how often these two words occur in the same\ncontext.','return dictionary mapping from indicating',0,'',''),(1065,'nltk','A wrapper around a sequence of simple (string) tokens, which is\nintended to support initial exploration of texts (via the\ninteractive console).  Its methods perform a variety of analyses\non the text’s contexts (e.g., counting, concordancing, collocation\ndiscovery), and display the results.  If you wish to write a\nprogram which makes use of these analyses, then you should bypass\nthe Text class, and use the appropriate analysis function or\nclass directly instead.','support initial exploration of texts',0,'',''),(1066,'nltk','A wrapper around a sequence of simple (string) tokens, which is\nintended to support initial exploration of texts (via the\ninteractive console).  Its methods perform a variety of analyses\non the text’s contexts (e.g., counting, concordancing, collocation\ndiscovery), and display the results.  If you wish to write a\nprogram which makes use of these analyses, then you should bypass\nthe Text class, and use the appropriate analysis function or\nclass directly instead.','perform variety of analyses',0,'',''),(1067,'nltk','A Text is typically initialized from a given document or\ncorpus.  E.g.:','initialize text from given document',0,'',''),(1068,'nltk','Return collocations derived from the text, ignoring stopwords.','ignore stopwords',1,'https://web.archive.org/web/20200414120240/http://www.nltk.org/api/nltk.html',''),(1069,'nltk','Print collocations derived from the text, ignoring stopwords.','ignore stopwords',1,'https://web.archive.org/web/20200414120240/http://www.nltk.org/api/nltk.html',''),(1070,'nltk','Prints a concordance for word with the specified context window.\nWord matching is not case-sensitive.','print concordance for word',0,'',''),(1071,'nltk','Produce a plot showing the distribution of the words through the text.\nRequires pylab to be installed.','produce plot',0,'',''),(1072,'nltk','Produce a plot showing the distribution of the words through the text.\nRequires pylab to be installed.','show distribution through text',0,'',''),(1073,'nltk','Produce a plot showing the distribution of the words through the text.\nRequires pylab to be installed.','show distribution of words',0,'',''),(1074,'nltk','Find instances of the regular expression in the text.\nThe text is a list of tokens, and a regexp pattern to match\na single token must be surrounded by angle brackets.  E.g.','surround regexp pattern',0,'',''),(1075,'nltk','A collection of texts, which can be loaded with list of texts, or\nwith a corpus consisting of one or more texts, and which supports\ncounting, concordancing, collocation discovery, etc.  Initialize a\nTextCollection as follows:','support counting discovery of texts',0,'',''),(1076,'nltk','A collection of texts, which can be loaded with list of texts, or\nwith a corpus consisting of one or more texts, and which supports\ncounting, concordancing, collocation discovery, etc.  Initialize a\nTextCollection as follows:','support collection of texts',0,'',''),(1077,'nltk','A collection of texts, which can be loaded with list of texts, or\nwith a corpus consisting of one or more texts, and which supports\ncounting, concordancing, collocation discovery, etc.  Initialize a\nTextCollection as follows:','load collection with corpus',0,'',''),(1078,'nltk','A collection of texts, which can be loaded with list of texts, or\nwith a corpus consisting of one or more texts, and which supports\ncounting, concordancing, collocation discovery, etc.  Initialize a\nTextCollection as follows:','load collection with list',0,'',''),(1079,'nltk','A collection of texts, which can be loaded with list of texts, or\nwith a corpus consisting of one or more texts, and which supports\ncounting, concordancing, collocation discovery, etc.  Initialize a\nTextCollection as follows:','load collection of texts',0,'',''),(1080,'nltk','Iterating over a TextCollection produces all the tokens of all the\ntexts in order.','produce tokens of texts',0,'',''),(1081,'nltk','The number of texts in the corpus divided by the\nnumber of texts that the term appears in.\nIf a term does not appear in the corpus, 0.0 is returned.','divide  by number',0,'',''),(1082,'nltk','A class that makes it easier to use regular expressions to search\nover tokenized strings.  The tokenized string is converted to a\nstring where tokens are marked with angle brackets – e.g.,\n\'\'.  The regular expression\npassed to the findall() method is modified to treat angle\nbrackets as non-capturing parentheses, in addition to matching the\ntoken boundaries; and to have \'.\' not match the angle brackets.','tokenize strings',0,'',''),(1083,'nltk','A class that makes it easier to use regular expressions to search\nover tokenized strings.  The tokenized string is converted to a\nstring where tokens are marked with angle brackets – e.g.,\n\'\'.  The regular expression\npassed to the findall() method is modified to treat angle\nbrackets as non-capturing parentheses, in addition to matching the\ntoken boundaries; and to have \'.\' not match the angle brackets.','convert tokenized string to string',0,'',''),(1084,'nltk','A class that makes it easier to use regular expressions to search\nover tokenized strings.  The tokenized string is converted to a\nstring where tokens are marked with angle brackets – e.g.,\n\'\'.  The regular expression\npassed to the findall() method is modified to treat angle\nbrackets as non-capturing parentheses, in addition to matching the\ntoken boundaries; and to have \'.\' not match the angle brackets.','mark tokens with angle brackets',0,'',''),(1085,'nltk','A class that makes it easier to use regular expressions to search\nover tokenized strings.  The tokenized string is converted to a\nstring where tokens are marked with angle brackets – e.g.,\n\'\'.  The regular expression\npassed to the findall() method is modified to treat angle\nbrackets as non-capturing parentheses, in addition to matching the\ntoken boundaries; and to have \'.\' not match the angle brackets.','mark string with angle brackets',0,'',''),(1086,'nltk','A class that makes it easier to use regular expressions to search\nover tokenized strings.  The tokenized string is converted to a\nstring where tokens are marked with angle brackets – e.g.,\n\'\'.  The regular expression\npassed to the findall() method is modified to treat angle\nbrackets as non-capturing parentheses, in addition to matching the\ntoken boundaries; and to have \'.\' not match the angle brackets.','modify regular expression',0,'',''),(1087,'nltk','Close a previously opened standard format marker file or string.','open standard format marker file',0,'',''),(1088,'nltk','Close a previously opened standard format marker file or string.','open string',0,'',''),(1089,'nltk','Return an iterator that returns the next field in a (marker, value)\ntuple, where marker and value are unicode strings if an encoding\nwas specified in the fields() method. Otherwise they are non-unicode strings.','return next field in tuple',0,'',''),(1090,'nltk','Return an iterator that returns the next field in a (marker, value)\ntuple, where marker and value are unicode strings if an encoding\nwas specified in the fields() method. Otherwise they are non-unicode strings.','specify encoding in fields() method',0,'',''),(1091,'nltk','encoding (str or None) – Name of an encoding to use. If it is specified then\nthe fields() method returns unicode strings rather than non\nunicode strings.','return non unicode strings',0,'',''),(1092,'nltk','encoding (str or None) – Name of an encoding to use. If it is specified then\nthe fields() method returns unicode strings rather than non\nunicode strings.','return unicode strings',0,'',''),(1093,'nltk','unicode_fields (sequence) – Set of marker names whose values are UTF-8 encoded.\nIgnored if encoding is None. If the whole file is UTF-8 encoded set\nencoding=\'utf8\' and leave unicode_fields with its default\nvalue of None.','encode utf8',0,'',''),(1094,'nltk','Open a standard format marker file for sequential reading.','open standard format marker file for sequential reading',0,'',''),(1095,'nltk','Open a standard format marker string for sequential reading.','open standard format marker string for sequential reading',0,'',''),(1096,'nltk','s (str) – string to parse as a standard format marker input file','parse  as standard format marker input file',0,'',''),(1097,'nltk','Return an iterator that returns the next field in a (marker, value)\ntuple. Linebreaks and trailing white space are preserved except\nfor the final newline in each field.','return next field in tuple',0,'',''),(1098,'nltk','kwargs (dict) – Keyword arguments passed to StandardFormat.fields()','pass  to StandardFormat.fields()',0,'',''),(1099,'nltk','Add blank lines before all elements and subelements specified in blank_before.','add blank lines before elements',0,'',''),(1100,'nltk','Add blank lines before all elements and subelements specified in blank_before.','add blank lines before subelements',0,'',''),(1101,'nltk','Add blank lines before all elements and subelements specified in blank_before.','specify  in blank_before',0,'',''),(1102,'nltk','blank_before (dict(tuple)) – elements and subelements to add blank lines before','add blank lines',0,'',''),(1103,'nltk','Add blank elements and subelements specified in default_fields.','add blank elements',0,'',''),(1104,'nltk','Add blank elements and subelements specified in default_fields.','add subelements',0,'',''),(1105,'nltk','Add blank elements and subelements specified in default_fields.','specify  in default_fields',0,'',''),(1106,'nltk','default_fields (dict(tuple)) – fields to add to each type of element and subelement','add  to type',0,'',''),(1107,'nltk','Remove all elements and subelements with no text and no child elements.','remove elements with text',0,'',''),(1108,'nltk','Remove all elements and subelements with no text and no child elements.','remove elements with child elements',0,'',''),(1109,'nltk','Remove all elements and subelements with no text and no child elements.','remove subelements with text',0,'',''),(1110,'nltk','Remove all elements and subelements with no text and no child elements.','remove subelements with child elements',0,'',''),(1111,'nltk','Sort the elements and subelements in order specified in field_orders.','sort elements',0,'',''),(1112,'nltk','Sort the elements and subelements in order specified in field_orders.','sort subelements',0,'',''),(1113,'nltk','Sort the elements and subelements in order specified in field_orders.','specify  in field_orders',0,'',''),(1114,'nltk','Convert a tree between different subtypes of Tree.  cls determines\nwhich class will be used to encode the new tree.','convert tree between different subtypes',0,'',''),(1115,'nltk','Convert a tree between different subtypes of Tree.  cls determines\nwhich class will be used to encode the new tree.','encode new tree',0,'',''),(1116,'nltk','tree (Tree) – The tree that should be converted.','convert tree',0,'',''),(1117,'nltk','Extend list by appending elements from the iterable.','append elements from iterable',0,'',''),(1118,'nltk','Raises ValueError if the value is not present.','raise ValueError',0,'',''),(1119,'nltk','Set the node label.  This will only succeed the first time the\nnode label is set, which should occur in ImmutableTree.__init__().','set node label',0,'',''),(1120,'nltk','Set the node label.  This will only succeed the first time the\nnode label is set, which should occur in ImmutableTree.__init__().','set node label',0,'',''),(1121,'nltk','Set the node label.  This will only succeed the first time the\nnode label is set, which should occur in ImmutableTree.__init__().','set first time',0,'',''),(1122,'nltk','The reverse flag can be set to sort in descending order.','set reverse flag',0,'',''),(1123,'nltk','Each MultiParentedTree may have zero or more parents.  In\nparticular, subtrees may be shared.  If a single\nMultiParentedTree is used as multiple children of the same\nparent, then that parent will appear multiple times in its\nparents() method.','share subtrees',0,'',''),(1124,'nltk','Return a list of the indices where this tree occurs as a child\nof parent.  If this child does not occur as a child of\nparent, then the empty list is returned.  The following is\nalways true:','return list of indices',0,'',''),(1125,'nltk','Return a list of the indices where this tree occurs as a child\nof parent.  If this child does not occur as a child of\nparent, then the empty list is returned.  The following is\nalways true:','return empty list',0,'',''),(1126,'nltk','Return a list of all tree positions that can be used to reach\nthis multi-parented tree starting from root.  I.e., the\nfollowing is always true:','return list of tree positions',0,'',''),(1127,'nltk','Return a list of all tree positions that can be used to reach\nthis multi-parented tree starting from root.  I.e., the\nfollowing is always true:','reach multi-parented tree',0,'',''),(1128,'nltk','Each ParentedTree may have at most one parent.  In\nparticular, subtrees may not be shared.  Any attempt to reuse a\nsingle ParentedTree as a child of more than one parent (or\nas multiple children of the same parent) will cause a\nValueError exception to be raised.','reuse single ParentedTree as child',0,'',''),(1129,'nltk','The index of this tree in its parent.  I.e.,\nptree.parent()[ptree.parent_index()] is ptree.  Note that\nptree.parent_index() is not necessarily equal to\nptree.parent.index(ptree), since the index() method\nreturns the first child that is equal to its argument.','return first child',0,'',''),(1130,'nltk','A tree’s children are encoded as a list of leaves and subtrees,\nwhere a leaf is a basic (non-tree) value; and a subtree is a\nnested Tree.','encode children as list',0,'',''),(1131,'nltk','The set_label() and label() methods allow individual constituents\nto be labeled.  For example, syntax trees use this label to specify\nphrase tags, such as “NP” and “VP”.','specify phrase tags such_as NP',0,'',''),(1132,'nltk','The set_label() and label() methods allow individual constituents\nto be labeled.  For example, syntax trees use this label to specify\nphrase tags, such as “NP” and “VP”.','specify phrase tags such_as VP',0,'',''),(1133,'nltk','Several Tree methods use “tree positions” to specify\nchildren or descendants of a tree.  Tree positions are defined as\nfollows:','specify children of tree',0,'',''),(1134,'nltk','Several Tree methods use “tree positions” to specify\nchildren or descendants of a tree.  Tree positions are defined as\nfollows:','specify descendants of tree',0,'',''),(1135,'nltk','Several Tree methods use “tree positions” to specify\nchildren or descendants of a tree.  Tree positions are defined as\nfollows:','define tree positions',0,'',''),(1136,'nltk','The tree position i specifies a Tree’s ith child.','specify i th child',0,'',''),(1137,'nltk','If p is the tree position of descendant d, then\np+i specifies the ith child of d.','specify i th child of d',0,'',''),(1138,'nltk','Construct a new tree.  This constructor can be called in one\nof two ways:','call constructor',0,'',''),(1139,'nltk','This method can modify a tree in three ways:','modify tree in ways',0,'',''),(1140,'nltk','Convert a tree into its Chomsky Normal Form (CNF)\nequivalent – Every subtree has either two non-terminals\nor one terminal as its children.  This process requires\nthe creation of more”artificial” non-terminal nodes.','convert tree into Chomsky normal Form equivalent',0,'',''),(1141,'nltk','Collapse subtrees with a single child (ie. unary productions)\ninto a new non-terminal (Tree node) joined by ‘joinChar’.\nThis is useful when working with algorithms that do not allow\nunary productions, and completely removing the unary productions\nwould require loss of useful information.  The Tree is modified\ndirectly (since it is passed by reference) and no value is returned.','remove unary productions',0,'',''),(1142,'nltk','Collapse subtrees with a single child (ie. unary productions)\ninto a new non-terminal (Tree node) joined by ‘joinChar’.\nThis is useful when working with algorithms that do not allow\nunary productions, and completely removing the unary productions\nwould require loss of useful information.  The Tree is modified\ndirectly (since it is passed by reference) and no value is returned.','modify Tree',0,'',''),(1143,'nltk','Collapse subtrees with a single child (ie. unary productions)\ninto a new non-terminal (Tree node) joined by ‘joinChar’.\nThis is useful when working with algorithms that do not allow\nunary productions, and completely removing the unary productions\nwould require loss of useful information.  The Tree is modified\ndirectly (since it is passed by reference) and no value is returned.','return value',0,'',''),(1144,'nltk','Open a new window containing a graphical diagram of this tree.','open new window',0,'',''),(1145,'nltk','Return a flat version of the tree, with all non-root non-terminals removed.','return flat version with non-root non-terminals',1,'https://web.archive.org/web/20200414120240/http://www.nltk.org/api/nltk.html',''),(1146,'nltk','Return a flat version of the tree, with all non-root non-terminals removed.','return flat version of tree',1,'https://web.archive.org/web/20200414120240/http://www.nltk.org/api/nltk.html',''),(1147,'nltk','Read a bracketed tree string and return the resulting tree.\nTrees are represented as nested brackettings, such as:','return resulting tree',0,'',''),(1148,'nltk','brackets (str (length=2)) – The bracket characters used to mark the\nbeginning and end of trees and subtrees.','mark beginning of subtrees',0,'',''),(1149,'nltk','brackets (str (length=2)) – The bracket characters used to mark the\nbeginning and end of trees and subtrees.','mark beginning of trees',0,'',''),(1150,'nltk','brackets (str (length=2)) – The bracket characters used to mark the\nbeginning and end of trees and subtrees.','mark end of subtrees',0,'',''),(1151,'nltk','brackets (str (length=2)) – The bracket characters used to mark the\nbeginning and end of trees and subtrees.','mark end of trees',0,'',''),(1152,'nltk','read_leaf (read_node,) – If specified, these functions\nare applied to the substrings of s corresponding to\nnodes and leaves (respectively) to obtain the values for\nthose nodes and leaves.  They should have the following\nsignature:\n\nread_node(str) -> value\n\nFor example, these functions could be used to process nodes\nand leaves whose values should be some type other than\nstring (such as FeatStruct).\nNote that by default, node strings and leaf strings are\ndelimited by whitespace and brackets; to override this\ndefault, use the node_pattern and leaf_pattern\narguments.','obtain values for nodes',0,'',''),(1153,'nltk','read_leaf (read_node,) – If specified, these functions\nare applied to the substrings of s corresponding to\nnodes and leaves (respectively) to obtain the values for\nthose nodes and leaves.  They should have the following\nsignature:\n\nread_node(str) -> value\n\nFor example, these functions could be used to process nodes\nand leaves whose values should be some type other than\nstring (such as FeatStruct).\nNote that by default, node strings and leaf strings are\ndelimited by whitespace and brackets; to override this\ndefault, use the node_pattern and leaf_pattern\narguments.','override default',0,'',''),(1154,'nltk','If specified, these functions\nare applied to the substrings of s corresponding to\nnodes and leaves (respectively) to obtain the values for\nthose nodes and leaves.  They should have the following\nsignature:','obtain values for nodes',0,'',''),(1155,'nltk','For example, these functions could be used to process nodes\nand leaves whose values should be some type other than\nstring (such as FeatStruct).\nNote that by default, node strings and leaf strings are\ndelimited by whitespace and brackets; to override this\ndefault, use the node_pattern and leaf_pattern\narguments.','override default',0,'',''),(1156,'nltk','leaf_pattern (node_pattern,) – Regular expression patterns\nused to find node and leaf substrings in s.  By\ndefault, both nodes patterns are defined to match any\nsequence of non-whitespace non-bracket characters.','define nodes patterns',0,'',''),(1157,'nltk','remove_empty_top_bracketing (bool) – If the resulting tree has\nan empty node label, and is length one, then return its\nsingle child instead.  This is useful for treebank trees,\nwhich sometimes contain an extra level of bracketing.','return single child',0,'',''),(1158,'nltk','A tree corresponding to the string representation s.\nIf this class method is called using a subclass of Tree,\nthen it will return a tree of that type.','return tree of type',0,'',''),(1159,'nltk','A tree corresponding to the string representation s.\nIf this class method is called using a subclass of Tree,\nthen it will return a tree of that type.','call class method',0,'',''),(1160,'nltk','indent (int) – The indentation level at which printing\nbegins.  This number is used to decide how far to indent\nsubsequent lines.','indent subsequent lines',0,'',''),(1161,'nltk','Return a sequence of pos-tagged words extracted from the tree.','return sequence of pos-tagged words',1,'https://web.archive.org/web/20200414120240/http://www.nltk.org/api/nltk.html',''),(1162,'nltk','Return a sequence of pos-tagged words extracted from the tree.','extract  from tree',1,'https://web.archive.org/web/20200414120240/http://www.nltk.org/api/nltk.html',''),(1163,'nltk','Print a string representation of this Tree to ‘stream’','print string representation of Tree',0,'',''),(1164,'nltk','Print a string representation of this Tree to ‘stream’','print string representation to stream',0,'',''),(1165,'nltk','Generate the productions that correspond to the non-terminal nodes of the tree.\nFor each subtree of the form (P: C1 C2 … Cn) this produces a production of the\nform P -> C1 C2 … Cn.','produce production of form p',0,'',''),(1166,'nltk','Generate the productions that correspond to the non-terminal nodes of the tree.\nFor each subtree of the form (P: C1 C2 … Cn) this produces a production of the\nform P -> C1 C2 … Cn.','produce production for subtree',0,'',''),(1167,'nltk','Set the node label of the tree.','set node label of tree',1,'https://web.archive.org/web/20200414120240/http://www.nltk.org/api/nltk.html',''),(1168,'nltk','filter (function) – the function to filter all local trees','filter local trees',0,'',''),(1169,'nltk','This method modifies the tree in three ways:','modify tree in ways',0,'',''),(1170,'nltk','Parse a Sinica Treebank string and return a tree.  Trees are represented as nested brackettings,\nas shown in the following example (X represents a Chinese character):\nS(goal:NP(Head:Nep:XX)|theme:NP(Head:Nhaa:X)|quantity:Dab:X|Head:VL2:X)#0(PERIODCATEGORY)','parse Sinica treebank string',0,'',''),(1171,'nltk','Parse a Sinica Treebank string and return a tree.  Trees are represented as nested brackettings,\nas shown in the following example (X represents a Chinese character):\nS(goal:NP(Head:Nep:XX)|theme:NP(Head:Nhaa:X)|quantity:Dab:X|Head:VL2:X)#0(PERIODCATEGORY)','return tree',0,'',''),(1172,'nltk','A collection of methods for tree (grammar) transformations used\nin parsing natural language.','parse natural language',0,'',''),(1173,'nltk','It is well known that any grammar has a Chomsky Normal Form (CNF)\nequivalent grammar where CNF is defined by every production having\neither two non-terminals or one terminal on its right hand side.\nWhen we have hierarchically structured data (ie. a treebank), it is\nnatural to view this in terms of productions where the root of every\nsubtree is the head (left hand side) of the production and all of\nits children are the right hand side constituents.  In order to\nconvert a tree into CNF, we simply need to ensure that every subtree\nhas either two subtrees as children (binarization), or one leaf node\n(non-terminal).  In order to binarize a subtree with more than two\nchildren, we must introduce artificial nodes.','define CNF',0,'',''),(1174,'nltk','It is well known that any grammar has a Chomsky Normal Form (CNF)\nequivalent grammar where CNF is defined by every production having\neither two non-terminals or one terminal on its right hand side.\nWhen we have hierarchically structured data (ie. a treebank), it is\nnatural to view this in terms of productions where the root of every\nsubtree is the head (left hand side) of the production and all of\nits children are the right hand side constituents.  In order to\nconvert a tree into CNF, we simply need to ensure that every subtree\nhas either two subtrees as children (binarization), or one leaf node\n(non-terminal).  In order to binarize a subtree with more than two\nchildren, we must introduce artificial nodes.','define Chomsky normal Form equivalent grammar',0,'',''),(1175,'nltk','It is well known that any grammar has a Chomsky Normal Form (CNF)\nequivalent grammar where CNF is defined by every production having\neither two non-terminals or one terminal on its right hand side.\nWhen we have hierarchically structured data (ie. a treebank), it is\nnatural to view this in terms of productions where the root of every\nsubtree is the head (left hand side) of the production and all of\nits children are the right hand side constituents.  In order to\nconvert a tree into CNF, we simply need to ensure that every subtree\nhas either two subtrees as children (binarization), or one leaf node\n(non-terminal).  In order to binarize a subtree with more than two\nchildren, we must introduce artificial nodes.','convert tree into CNF',0,'',''),(1176,'nltk','It is well known that any grammar has a Chomsky Normal Form (CNF)\nequivalent grammar where CNF is defined by every production having\neither two non-terminals or one terminal on its right hand side.\nWhen we have hierarchically structured data (ie. a treebank), it is\nnatural to view this in terms of productions where the root of every\nsubtree is the head (left hand side) of the production and all of\nits children are the right hand side constituents.  In order to\nconvert a tree into CNF, we simply need to ensure that every subtree\nhas either two subtrees as children (binarization), or one leaf node\n(non-terminal).  In order to binarize a subtree with more than two\nchildren, we must introduce artificial nodes.','introduce artificial nodes',0,'',''),(1177,'nltk','There are two popular methods to convert a tree into CNF: left\nfactoring and right factoring.  The following example demonstrates\nthe difference between them.  Example:','convert tree into CNF',0,'',''),(1178,'nltk','The purpose of parent annotation is to refine the probabilities of\nproductions by adding a small amount of context.  With this simple\naddition, a CYK (inside-outside, dynamic programming chart parse)\ncan improve from 74% to 79% accuracy.  A natural generalization from\nparent annotation is to grandparent annotation and beyond.  The\ntradeoff becomes accuracy gain vs. computational complexity.  We\nmust also keep in mind data sparcity issues.  Example:','add small amount of context',0,'',''),(1179,'nltk','Markov smoothing combats data sparcity issues as well as decreasing\ncomputational requirements by limiting the number of children\nincluded in artificial nodes.  In practice, most people use an order\n2 grammar.  Example:','limit number of children',0,'',''),(1180,'nltk','Annotation decisions can be thought about in the vertical direction\n(parent, grandparent, etc) and the horizontal direction (number of\nsiblings to keep).  Parameters to the following functions specify\nthese values.  For more information see:','specify values',0,'',''),(1181,'nltk','Traverse the nodes of a tree in depth-first order,\ndiscarding eventual cycles within the same branch,\nbut keep duplicate pathes in different branches.\nAdd cut_mark (when defined) if cycles were truncated.','add cut_mark',0,'',''),(1182,'nltk','The first argument should be the tree root;\nchildren should be a function taking as argument a tree node\nand returning an iterator of the node’s children.','return iterator of children',0,'',''),(1183,'nltk','Catches only only cycles within the same branch,\nbut keeping cycles from different branches:','catch cycles within same branch',0,'',''),(1184,'nltk','Catches only only cycles within the same branch,\nbut keeping cycles from different branches:','catch cycles from different branches',0,'',''),(1185,'nltk','Catches only only cycles within the same branch,\nbut keeping cycles from different branches:','catch keeping cycles within same branch',0,'',''),(1186,'nltk','Catches only only cycles within the same branch,\nbut keeping cycles from different branches:','catch keeping cycles from different branches',0,'',''),(1187,'nltk','Traverse the nodes of a tree in depth-first order,\ndiscarding eventual cycles within any branch,\nadding cut_mark (when specified) if cycles were truncated.','add cut_mark',0,'',''),(1188,'nltk','sequence (sequence or iter) – the source data to be converted into bigrams','convert  into bigrams',0,'',''),(1189,'nltk','Return the line from the file with first word key.\nSearches through a sorted file using the binary search algorithm.','return line from file',0,'',''),(1190,'nltk','Traverse the nodes of a tree in breadth-first order.\n(No check for cycles.)\nThe first argument should be the tree root;\nchildren should be a function taking as argument a tree node\nand returning an iterator of the node’s children.','return iterator of children',0,'',''),(1191,'nltk','This function is a fast way to calculate binomial coefficients, commonly\nknown as nCk, i.e. the number of combinations of n things taken k at a time.\n(https://en.wikipedia.org/wiki/Binomial_coefficient).','calculate binomial coefficients',0,'',''),(1192,'nltk','Recursive function to indent an ElementTree._ElementInterface\nused for pretty printing. Run indent on elem and then output\nin the normal way.','indent ElementTree._ElementInterface',0,'',''),(1193,'nltk','Recursive function to indent an ElementTree._ElementInterface\nused for pretty printing. Run indent on elem and then output\nin the normal way.','indent output in normal way',0,'',''),(1194,'nltk','sequence (sequence or iter) – the source data to be converted into ngrams. If max_len is\nnot provided, this sequence will be loaded into memory','convert  into ngrams',0,'',''),(1195,'nltk','sequence (sequence or iter) – the source data to be converted into ngrams. If max_len is\nnot provided, this sequence will be loaded into memory','load sequence into memory',0,'',''),(1196,'nltk','If successful it returns (decoded_unicode, successful_encoding).\nIf unsuccessful it raises a UnicodeError.','raise UnicodeError',0,'',''),(1197,'nltk','This function works by checking sys.stdin.  If the\nuser has modified sys.stdin, then it may return incorrect\nresults.','modify sys.stdin',0,'',''),(1198,'nltk','This function works by checking sys.stdin.  If the\nuser has modified sys.stdin, then it may return incorrect\nresults.','return incorrect results',0,'',''),(1199,'nltk','Wrap with list for a list version of this function.  Set pad_left\nor pad_right to true in order to get additional ngrams:','set pad_left to true',0,'',''),(1200,'nltk','Wrap with list for a list version of this function.  Set pad_left\nor pad_right to true in order to get additional ngrams:','set pad_right to true',0,'',''),(1201,'nltk','Wrap with list for a list version of this function.  Set pad_left\nor pad_right to true in order to get additional ngrams:','get additional ngrams',0,'',''),(1202,'nltk','sequence (sequence or iter) – the source data to be converted into ngrams','convert  into ngrams',0,'',''),(1203,'nltk','Returns a padded sequence of items before ngram extraction.','return padded sequence before ngram extraction',1,'https://web.archive.org/web/20200414120240/http://www.nltk.org/api/nltk.html',''),(1204,'nltk','Returns a padded sequence of items before ngram extraction.','return padded sequence of items',1,'https://web.archive.org/web/20200414120240/http://www.nltk.org/api/nltk.html',''),(1205,'nltk','Pretty print a sequence of data items','print sequence of data items',0,'',''),(1206,'nltk','Pretty print a string, breaking lines on whitespace','print string',0,'',''),(1207,'nltk','Pretty print a string, breaking lines on whitespace','break lines on whitespace',0,'',''),(1208,'nltk','Return a string with markers surrounding the matched substrings.\nSearch str for substrings matching regexp and wrap the matches\nwith braces.  This is convenient for learning about regular expressions.','return string with markers',0,'',''),(1209,'nltk','Return a string with markers surrounding the matched substrings.\nSearch str for substrings matching regexp and wrap the matches\nwith braces.  This is convenient for learning about regular expressions.','surround matched substrings',0,'',''),(1210,'nltk','Return a string with markers surrounding the matched substrings.\nSearch str for substrings matching regexp and wrap the matches\nwith braces.  This is convenient for learning about regular expressions.','wrap matches with braces',0,'',''),(1211,'nltk','Set the HTTP proxy for Python to download through.','set HTTP proxy for Python',0,'',''),(1212,'nltk','If proxy is None then tries to set proxy from environment or system\nsettings.','set proxy from environment system settings',0,'',''),(1213,'nltk','sequence (sequence or iter) – the source data to be converted into trigrams','convert  into trigrams',0,'',''),(1214,'nltk','Pretty print a list of text tokens, breaking lines on whitespace','print list of text tokens',0,'',''),(1215,'nltk','Pretty print a list of text tokens, breaking lines on whitespace','break lines on whitespace',0,'',''),(1216,'nltk','Calculate the transitive closure of a directed graph,\noptionally the reflexive transitive closure.','calculate transitive closure of directed graph',0,'',''),(1217,'nltk','context_sentence (iter) – The context sentence where the ambiguous word\noccurs, passed as an iterable of words.','pass  as iterable',0,'',''),(1218,'CoreNLP','While every annotator can technically be run as a top-level component, in some cases it makes sense for one annotator to run another as a sub-annotator. For instance the coref annotator runs the coref.mention annotator (which identifies coref mentions) as a sub-annotator by default. So instead of supplying an annotator list of tokenize,parse,coref.mention,coref the list can just be tokenize,parse,coref. Another example is the ner annotator running the entitymentions annotator to detect full entities. Below is a table summarizing the annotator/sub-annotator relationships that currently exist in the pipeline. By default annotators will generally run their sub-annotators.','summarize annotator/sub-annotator relationships',0,'',''),(1219,'CoreNLP','It uses new wrapper classes that have been developed for Stanford CoreNLP 3.9.0 to make it easier to work with annotations.','develop new wrapper classes for Stanford CoreNLP 3.9.0',1,'https://stanfordnlp.github.io/CoreNLP/api.html','quickstart-with-convenience-wrappers'),(1220,'CoreNLP','The backbone of the CoreNLP package is formed by two classes: Annotation and Annotator. Annotations are the data structure which hold the results of annotators. Annotations are basically maps, from keys to bits of the annotation, such as the parse, the part-of-speech tags, or named entity tags. Annotators are a lot like functions, except that they operate over Annotations instead of Objects. They do things like tokenize, parse, or NER tag sentences. Annotators and Annotations are integrated by AnnotationPipelines, which create sequences of generic Annotators. Stanford CoreNLP inherits from the AnnotationPipeline class, and is customized with NLP Annotators.','create sequences of generic annotators',0,'',''),(1221,'CoreNLP','The backbone of the CoreNLP package is formed by two classes: Annotation and Annotator. Annotations are the data structure which hold the results of annotators. Annotations are basically maps, from keys to bits of the annotation, such as the parse, the part-of-speech tags, or named entity tags. Annotators are a lot like functions, except that they operate over Annotations instead of Objects. They do things like tokenize, parse, or NER tag sentences. Annotators and Annotations are integrated by AnnotationPipelines, which create sequences of generic Annotators. Stanford CoreNLP inherits from the AnnotationPipeline class, and is customized with NLP Annotators.','create AnnotationPipelines of generic annotators',0,'',''),(1222,'CoreNLP','The backbone of the CoreNLP package is formed by two classes: Annotation and Annotator. Annotations are the data structure which hold the results of annotators. Annotations are basically maps, from keys to bits of the annotation, such as the parse, the part-of-speech tags, or named entity tags. Annotators are a lot like functions, except that they operate over Annotations instead of Objects. They do things like tokenize, parse, or NER tag sentences. Annotators and Annotations are integrated by AnnotationPipelines, which create sequences of generic Annotators. Stanford CoreNLP inherits from the AnnotationPipeline class, and is customized with NLP Annotators.','integrate annotators',0,'',''),(1223,'CoreNLP','The backbone of the CoreNLP package is formed by two classes: Annotation and Annotator. Annotations are the data structure which hold the results of annotators. Annotations are basically maps, from keys to bits of the annotation, such as the parse, the part-of-speech tags, or named entity tags. Annotators are a lot like functions, except that they operate over Annotations instead of Objects. They do things like tokenize, parse, or NER tag sentences. Annotators and Annotations are integrated by AnnotationPipelines, which create sequences of generic Annotators. Stanford CoreNLP inherits from the AnnotationPipeline class, and is customized with NLP Annotators.','integrate Annotations',0,'',''),(1224,'CoreNLP','The backbone of the CoreNLP package is formed by two classes: Annotation and Annotator. Annotations are the data structure which hold the results of annotators. Annotations are basically maps, from keys to bits of the annotation, such as the parse, the part-of-speech tags, or named entity tags. Annotators are a lot like functions, except that they operate over Annotations instead of Objects. They do things like tokenize, parse, or NER tag sentences. Annotators and Annotations are integrated by AnnotationPipelines, which create sequences of generic Annotators. Stanford CoreNLP inherits from the AnnotationPipeline class, and is customized with NLP Annotators.','inherit  from AnnotationPipeline class',0,'',''),(1225,'CoreNLP','To construct a Stanford CoreNLP object from a given set of properties, use StanfordCoreNLP(Properties props). This method creates the pipeline using the annotators given in the “annotators” property (see below for an example setting). The complete list of accepted annotator names is listed in the first column of the table here. To parse an arbitrary text, use the annotate(Annotation document) method.','create pipeline',1,'https://stanfordnlp.github.io/CoreNLP/api.html','generating-annotations'),(1226,'CoreNLP','To construct a Stanford CoreNLP object from a given set of properties, use StanfordCoreNLP(Properties props). This method creates the pipeline using the annotators given in the “annotators” property (see below for an example setting). The complete list of accepted annotator names is listed in the first column of the table here. To parse an arbitrary text, use the annotate(Annotation document) method.','parse arbitrary text',1,'https://stanfordnlp.github.io/CoreNLP/api.html','generating-annotations'),(1227,'CoreNLP','You can give other properties to CoreNLP by building a Properties object with more stuff in it. There are some overall properties like \"annotators\" but most properties apply to one annotator and are written as annotator.property. Note that the value of a property is always a String. In our documentation of individual annotators, we variously refer to their Type as “boolean”, “file, classpath, or URL” or “List(String)”. This means that the String value will be interpreted as objects of this type by using String parsing methods. The value itself in the Properties object is always a String. If you want to set several properties, you might find it conventient to use our PropertiesUtils.asProperties(String ...) method which will take a list of Strings that are alternately keys and values and build a Properties object:','build Properties object with more stuff',1,'https://stanfordnlp.github.io/CoreNLP/api.html','generating-annotations'),(1228,'CoreNLP','You can give other properties to CoreNLP by building a Properties object with more stuff in it. There are some overall properties like \"annotators\" but most properties apply to one annotator and are written as annotator.property. Note that the value of a property is always a String. In our documentation of individual annotators, we variously refer to their Type as “boolean”, “file, classpath, or URL” or “List(String)”. This means that the String value will be interpreted as objects of this type by using String parsing methods. The value itself in the Properties object is always a String. If you want to set several properties, you might find it conventient to use our PropertiesUtils.asProperties(String ...) method which will take a list of Strings that are alternately keys and values and build a Properties object:','set several properties',1,'https://stanfordnlp.github.io/CoreNLP/api.html','generating-annotations'),(1229,'CoreNLP','You can give other properties to CoreNLP by building a Properties object with more stuff in it. There are some overall properties like \"annotators\" but most properties apply to one annotator and are written as annotator.property. Note that the value of a property is always a String. In our documentation of individual annotators, we variously refer to their Type as “boolean”, “file, classpath, or URL” or “List(String)”. This means that the String value will be interpreted as objects of this type by using String parsing methods. The value itself in the Properties object is always a String. If you want to set several properties, you might find it conventient to use our PropertiesUtils.asProperties(String ...) method which will take a list of Strings that are alternately keys and values and build a Properties object:','build Properties object',1,'https://stanfordnlp.github.io/CoreNLP/api.html','generating-annotations'),(1230,'CoreNLP','You can give other properties to CoreNLP by building a Properties object with more stuff in it. There are some overall properties like \"annotators\" but most properties apply to one annotator and are written as annotator.property. Note that the value of a property is always a String. In our documentation of individual annotators, we variously refer to their Type as “boolean”, “file, classpath, or URL” or “List(String)”. This means that the String value will be interpreted as objects of this type by using String parsing methods. The value itself in the Properties object is always a String. If you want to set several properties, you might find it conventient to use our PropertiesUtils.asProperties(String ...) method which will take a list of Strings that are alternately keys and values and build a Properties object:','build PropertiesUtils.asProperties(String ...) method',1,'https://stanfordnlp.github.io/CoreNLP/api.html','generating-annotations'),(1231,'CoreNLP','If you want to do funkier things with CoreNLP, such as to use a second StanfordCoreNLP object to add additional analyses to an existing Annotation object, then you need to include the property enforceRequirements = false to avoid complaints about required earlier annotators not being present in the pipeline.','add additional analyses to existing annotation object',0,'',''),(1232,'CoreNLP','The output of the Annotators is accessed using the data structures CoreMap and CoreLabel.','access output of Annotators',1,'https://stanfordnlp.github.io/CoreNLP/api.html','interpreting-the-output'),(1233,'CoreNLP','The GATE folk made an English POS tagger model trained on twitter text. You can get it from the extensions page.','get  from extensions page',0,'',''),(1234,'CoreNLP','We have made slightly different Stanford CoreNLP models for the tagger, parser, and NER that ignore capitalization. We have only trained such models for English, but the same method could be used for other languages.','ignore capitalization',0,'',''),(1235,'CoreNLP','We have made slightly different Stanford CoreNLP models for the tagger, parser, and NER that ignore capitalization. We have only trained such models for English, but the same method could be used for other languages.','ignore tagger',0,'',''),(1236,'CoreNLP','We have made slightly different Stanford CoreNLP models for the tagger, parser, and NER that ignore capitalization. We have only trained such models for English, but the same method could be used for other languages.','ignore NER',0,'',''),(1237,'CoreNLP','We have made slightly different Stanford CoreNLP models for the tagger, parser, and NER that ignore capitalization. We have only trained such models for English, but the same method could be used for other languages.','ignore parser',0,'',''),(1238,'CoreNLP','Be sure to include the path to the case-insensitive models jar in the -cp classpath flag and then you can ask for these models to be used like this:','ask  for models',1,'https://stanfordnlp.github.io/CoreNLP/caseless.html',''),(1239,'CoreNLP','However, if we ask to use the caseless models, then we’re doing pretty well: All the name words are now recognized as proper nouns, and the two person names are recognized. However, the team name is still missed. Correct named entity recognition is just harder for caseless English than for well-edited English!','recognize name words as proper nouns',1,'https://stanfordnlp.github.io/CoreNLP/caseless.html','an-example'),(1240,'CoreNLP','However, if we ask to use the caseless models, then we’re doing pretty well: All the name words are now recognized as proper nouns, and the two person names are recognized. However, the team name is still missed. Correct named entity recognition is just harder for caseless English than for well-edited English!','recognize person names',1,'https://stanfordnlp.github.io/CoreNLP/caseless.html','an-example'),(1241,'CoreNLP','To train your own caseless models, you need one additional property, which asks for a function to be called before a token is processed which leads to the case of all words being ignored. We use by default a function that also Americanizes the spelling of certain words:','ask additional property for function',1,'https://stanfordnlp.github.io/CoreNLP/caseless.html','training-caseless-models'),(1242,'CoreNLP','The caseless NER model edu/stanford/nlp/models/ner/english.all.3class.caseless.distsim.crf.ser.gz released with version 3.6.0 was defective and has very poor performance. Sorry! Stuff happens. If you want good caseless NER, you should either run with caseless models from a 3.5.x series release (all of which are compatible with version 3.6.0) or download the new fixed model from version 3.7.0 or a later version. Since the version 3.5.x releases have a separate caseless jar, it is easy to also specify an additional jar as a dependency; you just have to make sure that it appears on your classpath before other jars which contain models with the same name.','release  with version 3.6.0',0,'',''),(1243,'CoreNLP','The caseless NER model edu/stanford/nlp/models/ner/english.all.3class.caseless.distsim.crf.ser.gz released with version 3.6.0 was defective and has very poor performance. Sorry! Stuff happens. If you want good caseless NER, you should either run with caseless models from a 3.5.x series release (all of which are compatible with version 3.6.0) or download the new fixed model from version 3.7.0 or a later version. Since the version 3.5.x releases have a separate caseless jar, it is easy to also specify an additional jar as a dependency; you just have to make sure that it appears on your classpath before other jars which contain models with the same name.','specify additional jar as dependency',0,'',''),(1244,'CoreNLP','This annotator removes XML tags from an input document. Stanford CoreNLP has the ability to remove all or most XML tags from a document before processing it. This functionality is provided by a finite automaton. It works fine for typical, simple XML, but complex constructions and CDATA sections will not be correctly handled. If you want full and correct handling of XML, then you should run XML documents through an XML parser (such as the one included standard in Java) before passing appropriate text nodes to Stanford CoreNLP. However, then you are unable to recover character offsets in the original XML text file.','remove XML tags from input document',0,'',''),(1245,'CoreNLP','This annotator removes XML tags from an input document. Stanford CoreNLP has the ability to remove all or most XML tags from a document before processing it. This functionality is provided by a finite automaton. It works fine for typical, simple XML, but complex constructions and CDATA sections will not be correctly handled. If you want full and correct handling of XML, then you should run XML documents through an XML parser (such as the one included standard in Java) before passing appropriate text nodes to Stanford CoreNLP. However, then you are unable to recover character offsets in the original XML text file.','remove most XML tags before processing',0,'',''),(1246,'CoreNLP','This annotator removes XML tags from an input document. Stanford CoreNLP has the ability to remove all or most XML tags from a document before processing it. This functionality is provided by a finite automaton. It works fine for typical, simple XML, but complex constructions and CDATA sections will not be correctly handled. If you want full and correct handling of XML, then you should run XML documents through an XML parser (such as the one included standard in Java) before passing appropriate text nodes to Stanford CoreNLP. However, then you are unable to recover character offsets in the original XML text file.','remove most XML tags from document',0,'',''),(1247,'CoreNLP','This annotator removes XML tags from an input document. Stanford CoreNLP has the ability to remove all or most XML tags from a document before processing it. This functionality is provided by a finite automaton. It works fine for typical, simple XML, but complex constructions and CDATA sections will not be correctly handled. If you want full and correct handling of XML, then you should run XML documents through an XML parser (such as the one included standard in Java) before passing appropriate text nodes to Stanford CoreNLP. However, then you are unable to recover character offsets in the original XML text file.','pass appropriate text nodes to Stanford CoreNLP',0,'',''),(1248,'CoreNLP','The cleanxml annotator supports many complex processing options: You can choose to only delete some XML tags, to treat certain XML tags as sentence ending, as marking the speaker in a dialog, etc. You can also extract document metadata from XML attributes. The cleanxml annotator can be placed after tokenize in processing order.','support many complex processing options',1,'https://stanfordnlp.github.io/CoreNLP/cleanxml.html','description'),(1249,'CoreNLP','The cleanxml annotator supports many complex processing options: You can choose to only delete some XML tags, to treat certain XML tags as sentence ending, as marking the speaker in a dialog, etc. You can also extract document metadata from XML attributes. The cleanxml annotator can be placed after tokenize in processing order.','delete XML tags',1,'https://stanfordnlp.github.io/CoreNLP/cleanxml.html','description'),(1250,'CoreNLP','The cleanxml annotator supports many complex processing options: You can choose to only delete some XML tags, to treat certain XML tags as sentence ending, as marking the speaker in a dialog, etc. You can also extract document metadata from XML attributes. The cleanxml annotator can be placed after tokenize in processing order.','mark speaker in dialog',1,'https://stanfordnlp.github.io/CoreNLP/cleanxml.html','description'),(1251,'CoreNLP','The cleanxml annotator supports many complex processing options: You can choose to only delete some XML tags, to treat certain XML tags as sentence ending, as marking the speaker in a dialog, etc. You can also extract document metadata from XML attributes. The cleanxml annotator can be placed after tokenize in processing order.','extract document metadata from XML attributes',1,'https://stanfordnlp.github.io/CoreNLP/cleanxml.html','description'),(1252,'CoreNLP','Stanford CoreNLP deletes the XML tags and generates output that is basically the same as for the default input.txt example. The only difference between this and the original output is a change in CharacterOffsets.','delete XML tags',1,'https://stanfordnlp.github.io/CoreNLP/cleanxml.html','description'),(1253,'CoreNLP','Note that although the annotator is called “cleanxml” in the annotators list, the prefix for options is just “clean”. We should probably regularize this at some point…. Also, the option names are case sensitive, so get them right!','call annotator in annotators list',0,'',''),(1254,'CoreNLP','Here is an example of setting many of these options in order to access information from an XML file that is similar to the LDC MPDF (multi-post discussion forum) XML format.','set  from XML file',1,'https://stanfordnlp.github.io/CoreNLP/cleanxml.html','ENG_DF_sample_101'),(1255,'CoreNLP','Here is an example of setting many of these options in order to access information from an XML file that is similar to the LDC MPDF (multi-post discussion forum) XML format.','set  to access information',1,'https://stanfordnlp.github.io/CoreNLP/cleanxml.html','ENG_DF_sample_101'),(1256,'CoreNLP','Here is the part of the JSON file output by that command, showing the section information. Information about quotes is not (yet) in out JSON output.','show section information',1,'https://stanfordnlp.github.io/CoreNLP/cleanxml.html','ENG_DF_sample_101'),(1257,'CoreNLP','Note: Stanford CoreNLP v.3.5+ requires Java 8, but works with Java 9/10/11 as well. If using Java 9/10/11, you need to add this Java flag to avoid errors (a CoreNLP library dependency uses the JAXB module that was deleted from the default libraries for Java 9+):','add Java flag',1,'https://stanfordnlp.github.io/CoreNLP/cmdline.html','quick-start'),(1258,'CoreNLP','If this command is run from the distribution directory, it processes the included sample file input.txt. We use a wildcard \"*\" after -cp to load all jar files in the current directory – it needs to be in quotes. This command writes the output to an XML file named input.txt.xml in the same directory.','load jar files in current directory',0,'',''),(1259,'CoreNLP','Your command line has to load the code, libraries, and model jars that CoreNLP uses. These are all contained in JAR files (compressed archives with extension “.jar”) which come in the CoreNLP download or which can be downloaded on demand from Maven Central. The easiest way to make them available is with a command line like this, where /Users/me/corenlp/ should be changed to the path where you put CoreNLP:','load code',1,'https://stanfordnlp.github.io/CoreNLP/cmdline.html','classpath'),(1260,'CoreNLP','Your command line has to load the code, libraries, and model jars that CoreNLP uses. These are all contained in JAR files (compressed archives with extension “.jar”) which come in the CoreNLP download or which can be downloaded on demand from Maven Central. The easiest way to make them available is with a command line like this, where /Users/me/corenlp/ should be changed to the path where you put CoreNLP:','load libraries',1,'https://stanfordnlp.github.io/CoreNLP/cmdline.html','classpath'),(1261,'CoreNLP','Your command line has to load the code, libraries, and model jars that CoreNLP uses. These are all contained in JAR files (compressed archives with extension “.jar”) which come in the CoreNLP download or which can be downloaded on demand from Maven Central. The easiest way to make them available is with a command line like this, where /Users/me/corenlp/ should be changed to the path where you put CoreNLP:','load model jars',1,'https://stanfordnlp.github.io/CoreNLP/cmdline.html','classpath'),(1262,'CoreNLP','Your command line has to load the code, libraries, and model jars that CoreNLP uses. These are all contained in JAR files (compressed archives with extension “.jar”) which come in the CoreNLP download or which can be downloaded on demand from Maven Central. The easiest way to make them available is with a command line like this, where /Users/me/corenlp/ should be changed to the path where you put CoreNLP:','change /Users/me/corenlp/ to path',1,'https://stanfordnlp.github.io/CoreNLP/cmdline.html','classpath'),(1263,'CoreNLP','Alternatively, you can [add this path to your CLASSPATH environment variable](https://en.wikipedia.org/wiki/Classpath_(Java%29), so these libraries are always available.','add path to CLASSPATH environment variable',0,'',''),(1264,'CoreNLP','The “*” (which must be enclosed in quotes) says to add all JAR files in the given directory to the classpath. You can also individually specify the needed jar files. Use the following sort of command line, adjusting the JAR file date extensions VV to your downloaded release.','add JAR files in given directory',1,'https://stanfordnlp.github.io/CoreNLP/cmdline.html','classpath'),(1265,'CoreNLP','The “*” (which must be enclosed in quotes) says to add all JAR files in the given directory to the classpath. You can also individually specify the needed jar files. Use the following sort of command line, adjusting the JAR file date extensions VV to your downloaded release.','specify needed jar files',1,'https://stanfordnlp.github.io/CoreNLP/cmdline.html','classpath'),(1266,'CoreNLP','Before using Stanford CoreNLP, it is usual to create a configuration file (a Java Properties file). Minimally, this file should contain the “annotators” property, which contains a comma-separated list of Annotators to use. For example, the setting below enables: tokenization, sentence splitting (required by most Annotators), POS tagging, lemmatization, NER, (constituency) parsing, and (rule-based) coreference resolution.','create configuration file',1,'https://stanfordnlp.github.io/CoreNLP/cmdline.html','configuring-corenlp-properties'),(1267,'CoreNLP','Before using Stanford CoreNLP, it is usual to create a configuration file (a Java Properties file). Minimally, this file should contain the “annotators” property, which contains a comma-separated list of Annotators to use. For example, the setting below enables: tokenization, sentence splitting (required by most Annotators), POS tagging, lemmatization, NER, (constituency) parsing, and (rule-based) coreference resolution.','enable lemmatization',1,'https://stanfordnlp.github.io/CoreNLP/cmdline.html','configuring-corenlp-properties'),(1268,'CoreNLP','Before using Stanford CoreNLP, it is usual to create a configuration file (a Java Properties file). Minimally, this file should contain the “annotators” property, which contains a comma-separated list of Annotators to use. For example, the setting below enables: tokenization, sentence splitting (required by most Annotators), POS tagging, lemmatization, NER, (constituency) parsing, and (rule-based) coreference resolution.','enable NER',1,'https://stanfordnlp.github.io/CoreNLP/cmdline.html','configuring-corenlp-properties'),(1269,'CoreNLP','Before using Stanford CoreNLP, it is usual to create a configuration file (a Java Properties file). Minimally, this file should contain the “annotators” property, which contains a comma-separated list of Annotators to use. For example, the setting below enables: tokenization, sentence splitting (required by most Annotators), POS tagging, lemmatization, NER, (constituency) parsing, and (rule-based) coreference resolution.','enable parsing',1,'https://stanfordnlp.github.io/CoreNLP/cmdline.html','configuring-corenlp-properties'),(1270,'CoreNLP','Before using Stanford CoreNLP, it is usual to create a configuration file (a Java Properties file). Minimally, this file should contain the “annotators” property, which contains a comma-separated list of Annotators to use. For example, the setting below enables: tokenization, sentence splitting (required by most Annotators), POS tagging, lemmatization, NER, (constituency) parsing, and (rule-based) coreference resolution.','enable tokenization',1,'https://stanfordnlp.github.io/CoreNLP/cmdline.html','configuring-corenlp-properties'),(1271,'CoreNLP','Before using Stanford CoreNLP, it is usual to create a configuration file (a Java Properties file). Minimally, this file should contain the “annotators” property, which contains a comma-separated list of Annotators to use. For example, the setting below enables: tokenization, sentence splitting (required by most Annotators), POS tagging, lemmatization, NER, (constituency) parsing, and (rule-based) coreference resolution.','enable coreference resolution',1,'https://stanfordnlp.github.io/CoreNLP/cmdline.html','configuring-corenlp-properties'),(1272,'CoreNLP','Before using Stanford CoreNLP, it is usual to create a configuration file (a Java Properties file). Minimally, this file should contain the “annotators” property, which contains a comma-separated list of Annotators to use. For example, the setting below enables: tokenization, sentence splitting (required by most Annotators), POS tagging, lemmatization, NER, (constituency) parsing, and (rule-based) coreference resolution.','enable sentence splitting',1,'https://stanfordnlp.github.io/CoreNLP/cmdline.html','configuring-corenlp-properties'),(1273,'CoreNLP','Before using Stanford CoreNLP, it is usual to create a configuration file (a Java Properties file). Minimally, this file should contain the “annotators” property, which contains a comma-separated list of Annotators to use. For example, the setting below enables: tokenization, sentence splitting (required by most Annotators), POS tagging, lemmatization, NER, (constituency) parsing, and (rule-based) coreference resolution.','enable POS tagging',1,'https://stanfordnlp.github.io/CoreNLP/cmdline.html','configuring-corenlp-properties'),(1274,'CoreNLP','However, if you just want to specify a few properties, you can instead place them on the command line. For example, we can specify annotators and the output format with:','specify few properties',1,'https://stanfordnlp.github.io/CoreNLP/cmdline.html','configuring-corenlp-properties'),(1275,'CoreNLP','However, if you just want to specify a few properties, you can instead place them on the command line. For example, we can specify annotators and the output format with:','specify annotators',1,'https://stanfordnlp.github.io/CoreNLP/cmdline.html','configuring-corenlp-properties'),(1276,'CoreNLP','However, if you just want to specify a few properties, you can instead place them on the command line. For example, we can specify annotators and the output format with:','specify output format',1,'https://stanfordnlp.github.io/CoreNLP/cmdline.html','configuring-corenlp-properties'),(1277,'CoreNLP','The -annotators argument is also optional. If you leave it out, the code uses a built in properties file, which enables the following annotators: tokenization and sentence splitting, POS tagging, lemmatization, NER, dependency parsing, and statistical coreference resolution: annotators = tokenize, ssplit, pos, lemma, ner, depparse, coref.','build  in properties',0,'',''),(1278,'CoreNLP','The -annotators argument is also optional. If you leave it out, the code uses a built in properties file, which enables the following annotators: tokenization and sentence splitting, POS tagging, lemmatization, NER, dependency parsing, and statistical coreference resolution: annotators = tokenize, ssplit, pos, lemma, ner, depparse, coref.','enable built file',0,'',''),(1279,'CoreNLP','If you have a lot of text but all you want to do is to, say, get part-of-speech (POS) tags, then you should definitely specify an annotators list, as above, since you can then omit later annotators which invoke much more expensive processing that you don’t need. For example, you might give the command:','get part-of-speech tags',1,'https://stanfordnlp.github.io/CoreNLP/cmdline.html','configuring-corenlp-properties'),(1280,'CoreNLP','If you have a lot of text but all you want to do is to, say, get part-of-speech (POS) tags, then you should definitely specify an annotators list, as above, since you can then omit later annotators which invoke much more expensive processing that you don’t need. For example, you might give the command:','specify annotators list',1,'https://stanfordnlp.github.io/CoreNLP/cmdline.html','configuring-corenlp-properties'),(1281,'CoreNLP','We provide a small shell script corenlp.sh. On Linux or OS X, this may be useful in allowing you to type shorter command lines to invoke CoreNLP. For example, you can instead say:','provide small shell script corenlp.sh',1,'https://stanfordnlp.github.io/CoreNLP/cmdline.html','configuring-corenlp-properties'),(1282,'CoreNLP','You first have to have available a models jar file for the language you wish to use. You can download it from this site or you can use the models file on Maven Central. If using Maven, you add it to your pom file like this:','add  to pom file',1,'https://stanfordnlp.github.io/CoreNLP/cmdline.html','languages-other-than-english'),(1283,'CoreNLP','Our examples assume that you are in the root directory of CoreNLP and that these extra jar files are also available there. Each language jar contains a default properties file for the appropriate language. Working with text in another language is then as easy as specifying this properties file. For example, for Chinese:','specify properties file',1,'https://stanfordnlp.github.io/CoreNLP/cmdline.html','languages-other-than-english'),(1284,'CoreNLP','You can as usual specify details on the annotators and properties:','specify details on annotators',1,'https://stanfordnlp.github.io/CoreNLP/cmdline.html','languages-other-than-english'),(1285,'CoreNLP','You can as usual specify details on the annotators and properties:','specify details on properties',1,'https://stanfordnlp.github.io/CoreNLP/cmdline.html','languages-other-than-english'),(1286,'CoreNLP','If your input files have XML tags in them, you may wish to add the cleanxml annotator to preprocess it. Place it immediately after tokenize.','add cleanxml annotator',0,'',''),(1287,'CoreNLP','If (and only if) the input filename ends with “.ser.gz” then CoreNLP will interpret the file as the output of a previous annotation run, to which you presumably want to add on further annotations. CoreNLP will read these Annotations using the class specified in the inputSerializer property. The options for this are the same as for outputSerializer below. Note: To successfully load a pipeline for layering on additional annotations, you need to include the property enforceRequirements = false to avoid complaints about required earlier annotators not being present in the pipeline.','add  on further annotations',0,'',''),(1288,'CoreNLP','If (and only if) the input filename ends with “.ser.gz” then CoreNLP will interpret the file as the output of a previous annotation run, to which you presumably want to add on further annotations. CoreNLP will read these Annotations using the class specified in the inputSerializer property. The options for this are the same as for outputSerializer below. Note: To successfully load a pipeline for layering on additional annotations, you need to include the property enforceRequirements = false to avoid complaints about required earlier annotators not being present in the pipeline.','specify  in inputSerializer property',0,'',''),(1289,'CoreNLP','If (and only if) the input filename ends with “.ser.gz” then CoreNLP will interpret the file as the output of a previous annotation run, to which you presumably want to add on further annotations. CoreNLP will read these Annotations using the class specified in the inputSerializer property. The options for this are the same as for outputSerializer below. Note: To successfully load a pipeline for layering on additional annotations, you need to include the property enforceRequirements = false to avoid complaints about required earlier annotators not being present in the pipeline.','load pipeline for layering',0,'',''),(1290,'CoreNLP','For each input file, Stanford CoreNLP generates one output file, with a name that adds an extra extension to the input filename. (If reading input from stdin, then it will send output to stdout.) The output may contain the output of all annotations that were done, or just a subset of them. For the first example under Quick Start above, with input.txt containing the text below:','add extra extension to input filename',0,'',''),(1291,'CoreNLP','For each input file, Stanford CoreNLP generates one output file, with a name that adds an extra extension to the input filename. (If reading input from stdin, then it will send output to stdout.) The output may contain the output of all annotations that were done, or just a subset of them. For the first example under Quick Start above, with input.txt containing the text below:','add name to input filename',0,'',''),(1292,'CoreNLP','Note that this XML output can use the CoreNLP-to-HTML.xsl stylesheet file, which comes with the CoreNLP download or can be downloaded from here. This stylesheet enables human-readable display of the above XML content. For example, this example should display like this.','enable human-readable display of above XML content',0,'',''),(1293,'CoreNLP','The ProtobufAnnotationSerializer is a non-lossy annotation serialization. It uses the Java methods writeDelimitedTo() and parseDelimitedFrom(), which allow sending several length-prefixed messages in one stream. Unfortunately, Google has declined to implement these methods for Python or C++. You can get information from Stack Overflow and other places on how to roll your own version for C++ or Python. Probably the best place is here but there are many other sources of information including: here, here, here, and here. This Stack Overflow question explicitly addresses the issue for CoreNLP.','send several length-prefixed messages in stream',0,'',''),(1294,'CoreNLP','The ProtobufAnnotationSerializer is a non-lossy annotation serialization. It uses the Java methods writeDelimitedTo() and parseDelimitedFrom(), which allow sending several length-prefixed messages in one stream. Unfortunately, Google has declined to implement these methods for Python or C++. You can get information from Stack Overflow and other places on how to roll your own version for C++ or Python. Probably the best place is here but there are many other sources of information including: here, here, here, and here. This Stack Overflow question explicitly addresses the issue for CoreNLP.','get information from Stack overflow',0,'',''),(1295,'CoreNLP','The ProtobufAnnotationSerializer is a non-lossy annotation serialization. It uses the Java methods writeDelimitedTo() and parseDelimitedFrom(), which allow sending several length-prefixed messages in one stream. Unfortunately, Google has declined to implement these methods for Python or C++. You can get information from Stack Overflow and other places on how to roll your own version for C++ or Python. Probably the best place is here but there are many other sources of information including: here, here, here, and here. This Stack Overflow question explicitly addresses the issue for CoreNLP.','get information from other places',0,'',''),(1296,'CoreNLP','In all output formats (and in our code), we number sentences and character offsets from 0 and we number tokens from 1. We realize that this is inconsistent! However, it seemed to be the best thing to do. Numbering character offsets from 0 is the only good choice, given how the Java String class and most modern programming languages work, following Dijkstra’s arguments for indexing from 0 (which were influential at the time if not necessarily so water-tight). Numbering tokens from 1 not only corresponds to the human-natural convention (“the first word of the sentence”) but most importantly is consistent with common NLP standards, such as the CoNLL formats used from CoNLL-X through CoNLL 2009, etc., and in CoNLL-U, which number tokens starting from 1. For sentences, we could then choose to be consistent with either but not both of the above. We went with 0-indexing.','choose  for sentences',0,'',''),(1297,'CoreNLP','CoreNLP’s default character encoding is Unicode’s UTF-8. You can change the encoding used by supplying the program with the command line flag -encoding FOO (or including the corresponding property in a properties file that you are using). We’ve done a lot of careful work to make sure CoreNLP works with any character encoding supported by Java. Want to use ISO-8859-15 or GB18030? Be our guest!','change encoding',0,'',''),(1298,'CoreNLP','CoreNLP’s default character encoding is Unicode’s UTF-8. You can change the encoding used by supplying the program with the command line flag -encoding FOO (or including the corresponding property in a properties file that you are using). We’ve done a lot of careful work to make sure CoreNLP works with any character encoding supported by Java. Want to use ISO-8859-15 or GB18030? Be our guest!','encode FOO',0,'',''),(1299,'CoreNLP','Have a support question? Please create an issue on github','create issue on github',0,'',''),(1300,'CoreNLP','We have 3 mailing lists for Stanford CoreNLP, all of which are shared with other JavaNLP tools (with the exclusion of the parser). Each address is at @lists.stanford.edu:','share Stanford CoreNLP with other JavaNLP tools',0,'',''),(1301,'CoreNLP','java-nlp-user This is the best list to post to in order to send feature requests, make announcements, or for discussion among JavaNLP users. (Please ask support questions on github.) You have to subscribe to be able to use this list. Join the list via this webpage or by emailing java-nlp-user-join@lists.stanford.edu. (Leave the subject and message body empty.) You can also look at the list archives.','send feature requests',0,'',''),(1302,'CoreNLP','The CorefAnnotator finds mentions of the same entity in a text, such as when “Theresa May” and “she” refer to the same person. The annotator implements both pronominal and nominal coreference resolution. The entire coreference graph (with head words of mentions as nodes) is saved as a CorefChainAnnotation.','save entire coreference graph as CorefChainAnnotation',0,'',''),(1303,'CoreNLP','Statistical: Machine-learning-based coreference resolution for English. Unlike the other systems, this one only requires dependency parses, which are faster to produce than constituency parses.','produce  than constituency parses',0,'',''),(1304,'CoreNLP','The F1 scores are on the CoNLL 2012 evaluation data. Numbers are lower than reported in the associated papers because these models are designed for general-purpose use, not getting a high CoNLL score (see Running on CoNLL 2012).','design models for general-purpose use',0,'',''),(1305,'CoreNLP','The speed measurements show the average time for processing a document in the CoNLL 2012 test set using a 2013 Macbook Pro with a 2.4 GHz Intel Core i7 processor. Preprocessing speed measures the time required for POS tagging, syntax parsing, mention detection, etc., while coref speed refers to the time spent by the coreference system.','show average time for processing',0,'',''),(1306,'CoreNLP','Alternatively, the properties can be set manually. For example, to run the neural system on English:','set properties',1,'https://stanfordnlp.github.io/CoreNLP/coref.html','command-line-usage'),(1307,'CoreNLP','The following example shows how to access coref and mention information from an Annotation:','access coref',1,'https://stanfordnlp.github.io/CoreNLP/coref.html','api'),(1308,'CoreNLP','This is a mention-ranking model using a large set of features. It operates by iterating through each mention in the document, possibly adding a coreference link between the current one and a preceding mention at each step. Some relevant options:','add coreference link between preceding mention',0,'',''),(1309,'CoreNLP','coref.maxMentionDistanceWithStringMatch: The system will consider linking the current mention to a preceding one further than coref.maxMentionDistance away if they share a noun or proper noun. In this case, it looks coref.maxMentionDistanceWithStringMatch away instead. The default value is 500.','link current mention',0,'',''),(1310,'CoreNLP','coref.maxMentionDistanceWithStringMatch: The system will consider linking the current mention to a preceding one further than coref.maxMentionDistance away if they share a noun or proper noun. In this case, it looks coref.maxMentionDistanceWithStringMatch away instead. The default value is 500.','share noun',0,'',''),(1311,'CoreNLP','coref.maxMentionDistanceWithStringMatch: The system will consider linking the current mention to a preceding one further than coref.maxMentionDistance away if they share a noun or proper noun. In this case, it looks coref.maxMentionDistanceWithStringMatch away instead. The default value is 500.','share proper noun',0,'',''),(1312,'CoreNLP','coref.statisical.pairwiseScoreThresholds: A number between 0 and 1 determining how greedy the model is about making coreference decisions. A value of 0 causes the system to add no coreference links and a value of 1 causes the system to link every pair of mentions, combining them all into a single coreference cluster. The default value is 0.35. The value can also be a comma-separated list of 4 numbers, in which case there are separate thresholds for when both mentions are pronouns, only the first mention is a pronoun, only the last mention is a pronoun, and neither mention is a pronoun.','add coreference links',0,'',''),(1313,'CoreNLP','coref.statisical.pairwiseScoreThresholds: A number between 0 and 1 determining how greedy the model is about making coreference decisions. A value of 0 causes the system to add no coreference links and a value of 1 causes the system to link every pair of mentions, combining them all into a single coreference cluster. The default value is 0.35. The value can also be a comma-separated list of 4 numbers, in which case there are separate thresholds for when both mentions are pronouns, only the first mention is a pronoun, only the last mention is a pronoun, and neither mention is a pronoun.','link pair of mentions',0,'',''),(1314,'CoreNLP','Because of this, we train models with a few extra features for running on this dataset. We configure these models for accuracy over speed (e.g., by not having a maximum mention distance for the mention-ranking models). These models can be run using the -conll properties files (e.g., neural-english-conll.properties). Note that the CoNLL-specific models for English are in the English models jar, not the default CoreNLP models jar.','configure models for accuracy',0,'',''),(1315,'CoreNLP','As a rule-based system, there is nothing to train, but there are various data files for demonyms and to indicate noun gender, animacy, and plurality, which can be edited. See the Stanford Deterministic Coreference Resolution System page.','edit plurality',0,'',''),(1316,'CoreNLP','See here for an example properties file. Training over the full CoNLL 2012 training set requires a large amount of memory. To reduce the memory footprint and runtime of training, the following options can be added to the properties file:','add following options to properties file',0,'',''),(1317,'CoreNLP','CoreNLP includes a simple web API server for servicing your human language understanding needs (starting with version 3.6.0). This page describes how to set it up. CoreNLP server provides both a convenient graphical way to interface with your installation of CoreNLP and an API with which to call CoreNLP using any programming language. If you’re writing a new wrapper of CoreNLP for using it in another language, you’re advised to do it using the CoreNLP Server.','call CoreNLP',0,'',''),(1318,'CoreNLP','If no value for port is provided, port 9000 will be used by default. You can then test your server by visiting','provide value for port',1,'https://stanfordnlp.github.io/CoreNLP/corenlp-server.html','getting-started'),(1319,'CoreNLP','If no value for port is provided, port 9000 will be used by default. You can then test your server by visiting','test server by visiting',1,'https://stanfordnlp.github.io/CoreNLP/corenlp-server.html','getting-started'),(1320,'CoreNLP','You should see a website similar to corenlp.run, with an input box for text and a list of annotators you can run. From this interface, you can test out each of the annotators by adding/removing them from this list. (Note: The first use will be slow to respond while models are loaded – it might take 30 seconds or so, but after that the server should run quite quickly.) You can test out the API by sending a POST request to the server with the appropriate properties. An easy way to do this is with wget. The following will annotate the sentence “the quick brown fox jumped over the lazy dog” with part of speech tags:','send POST request to server',1,'https://stanfordnlp.github.io/CoreNLP/corenlp-server.html','getting-started'),(1321,'CoreNLP','NOTE: Please do not make API calls against corenlp.run. It is not set up to handle a large volume of requests. Instructions for setting up your own server can be found in the Dedicated Server section.','handle large volume of requests',0,'',''),(1322,'CoreNLP','NOTE: Please do not make API calls against corenlp.run. It is not set up to handle a large volume of requests. Instructions for setting up your own server can be found in the Dedicated Server section.','set up own server',0,'',''),(1323,'CoreNLP','This endpoint takes as input a JSON-formatted properties string under the key properties=, and as POSTdata text to annotate. The properties should mirror the properties file passed into the CoreNLP command line, except formatted as a JSON object. The POST data should be percent-encoded (otherwise known as URL encoded). In particular, you shoud esapce a % sign as %25. (Interfaces calling CoreNLP via the web service should do this escaping for their users.)','pass  into CoreNLP command line',0,'',''),(1324,'CoreNLP','This endpoint takes as input a JSON-formatted properties string under the key properties=, and as POSTdata text to annotate. The properties should mirror the properties file passed into the CoreNLP command line, except formatted as a JSON object. The POST data should be percent-encoded (otherwise known as URL encoded). In particular, you shoud esapce a % sign as %25. (Interfaces calling CoreNLP via the web service should do this escaping for their users.)','format  as JSON object',0,'',''),(1325,'CoreNLP','For example, the following command will tokenize the input text, run part of speech tagging, and output the result as JSON to standard out:','tokenize output as JSON',1,'https://stanfordnlp.github.io/CoreNLP/corenlp-server.html','annotate-with-corenlp-'),(1326,'CoreNLP','For example, the following command will tokenize the input text, run part of speech tagging, and output the result as JSON to standard out:','tokenize output of speech tagging',1,'https://stanfordnlp.github.io/CoreNLP/corenlp-server.html','annotate-with-corenlp-'),(1327,'CoreNLP','For example, the following command will tokenize the input text, run part of speech tagging, and output the result as JSON to standard out:','tokenize output to standard out',1,'https://stanfordnlp.github.io/CoreNLP/corenlp-server.html','annotate-with-corenlp-'),(1328,'CoreNLP','For example, the following command will tokenize the input text, run part of speech tagging, and output the result as JSON to standard out:','tokenize input text as JSON',1,'https://stanfordnlp.github.io/CoreNLP/corenlp-server.html','annotate-with-corenlp-'),(1329,'CoreNLP','For example, the following command will tokenize the input text, run part of speech tagging, and output the result as JSON to standard out:','tokenize input text of speech tagging',1,'https://stanfordnlp.github.io/CoreNLP/corenlp-server.html','annotate-with-corenlp-'),(1330,'CoreNLP','For example, the following command will tokenize the input text, run part of speech tagging, and output the result as JSON to standard out:','tokenize input text to standard out',1,'https://stanfordnlp.github.io/CoreNLP/corenlp-server.html','annotate-with-corenlp-'),(1331,'CoreNLP','For example, the following command will tokenize the input text, run part of speech tagging, and output the result as JSON to standard out:','tokenize run part as JSON',1,'https://stanfordnlp.github.io/CoreNLP/corenlp-server.html','annotate-with-corenlp-'),(1332,'CoreNLP','For example, the following command will tokenize the input text, run part of speech tagging, and output the result as JSON to standard out:','tokenize run part of speech tagging',1,'https://stanfordnlp.github.io/CoreNLP/corenlp-server.html','annotate-with-corenlp-'),(1333,'CoreNLP','For example, the following command will tokenize the input text, run part of speech tagging, and output the result as JSON to standard out:','tokenize run part to standard out',1,'https://stanfordnlp.github.io/CoreNLP/corenlp-server.html','annotate-with-corenlp-'),(1334,'CoreNLP','A common property to set is the output format of the API. The server supports all output formats provided by CoreNLP. These are listed below, along with their relevant properties:','support output formats',0,'',''),(1335,'CoreNLP','The server also accepts input in a variety of formats. By default, it takes input as raw text sent as POST data to the server. However, it can also be configured to read the POST data using one of the CoreNLP serializers. This can be set up by setting the properties inputFormat and inputSerializer. For example, to read the data as a protocol buffer (useful if, e.g., it is already partially annotated), simply include the following in your url parameter properties={...}:','send  as POST data',1,'https://stanfordnlp.github.io/CoreNLP/corenlp-server.html','annotate-with-corenlp-'),(1336,'CoreNLP','The server also accepts input in a variety of formats. By default, it takes input as raw text sent as POST data to the server. However, it can also be configured to read the POST data using one of the CoreNLP serializers. This can be set up by setting the properties inputFormat and inputSerializer. For example, to read the data as a protocol buffer (useful if, e.g., it is already partially annotated), simply include the following in your url parameter properties={...}:','send  to server',1,'https://stanfordnlp.github.io/CoreNLP/corenlp-server.html','annotate-with-corenlp-'),(1337,'CoreNLP','The server also accepts input in a variety of formats. By default, it takes input as raw text sent as POST data to the server. However, it can also be configured to read the POST data using one of the CoreNLP serializers. This can be set up by setting the properties inputFormat and inputSerializer. For example, to read the data as a protocol buffer (useful if, e.g., it is already partially annotated), simply include the following in your url parameter properties={...}:','set properties inputFormat',1,'https://stanfordnlp.github.io/CoreNLP/corenlp-server.html','annotate-with-corenlp-'),(1338,'CoreNLP','The server also accepts input in a variety of formats. By default, it takes input as raw text sent as POST data to the server. However, it can also be configured to read the POST data using one of the CoreNLP serializers. This can be set up by setting the properties inputFormat and inputSerializer. For example, to read the data as a protocol buffer (useful if, e.g., it is already partially annotated), simply include the following in your url parameter properties={...}:','set inputSerializer',1,'https://stanfordnlp.github.io/CoreNLP/corenlp-server.html','annotate-with-corenlp-'),(1339,'CoreNLP','A complete call to the server, taking as input a protobuf serialized document at path /path/to/file.proto and returning as a response a protobuf for the document annotated for part of speech and named entity tags (to the file /path/to/annotated_file.proto could be:','return  as response',1,'https://stanfordnlp.github.io/CoreNLP/corenlp-server.html','annotate-with-corenlp-'),(1340,'CoreNLP','Similar to the CoreNLP target, /tokensregex takes a block of data (e.g., text) as POST data, and a series of url parameters. Currently, only plain-text POST data is supported. The two relevant url parameters are:','support plain-text POST data',1,'https://stanfordnlp.github.io/CoreNLP/corenlp-server.html','query-tokensregex-tokensregex'),(1341,'CoreNLP','Similar to the CoreNLP target, and nearly identical to TokensRegex, /semgrex takes a block of data (e.g., text) as POST data, and a series of url parameters. Currently, only plain-text POST data is supported. The two relevant url parameters are:','support plain-text POST data',0,'',''),(1342,'CoreNLP','The response is always in JSON, formatted identically to the tokensregex output, with the exception that all spans are single words (only the root of the match is returned):','format  to tokensregex output',1,'https://stanfordnlp.github.io/CoreNLP/corenlp-server.html','query-semgrex-semgrex'),(1343,'CoreNLP','You can also run the client from the command line, and get an interface similar to the command line usage for the local CoreNLP program. The following will annotate a file input.txt with part-of-speech, lemmas, named entities, constituency parses, and coreference:','get interface similar usage for local CoreNLP program',1,'https://stanfordnlp.github.io/CoreNLP/corenlp-server.html','java-client'),(1344,'CoreNLP','NOTE: Again, please do not make API calls against http://corenlp.run. It is not set up to handle a large volume of requests. Instructions for setting up your own server can be found in the Dedicated Server section.','handle large volume of requests',0,'',''),(1345,'CoreNLP','NOTE: Again, please do not make API calls against http://corenlp.run. It is not set up to handle a large volume of requests. Instructions for setting up your own server can be found in the Dedicated Server section.','set up own server',0,'',''),(1346,'CoreNLP','You specify one or more back-end servers in a comma-separated list as the arguments of the -backends option. Each is specified as host:port.','specify back-end servers in comma-separated list',0,'',''),(1347,'CoreNLP','You specify one or more back-end servers in a comma-separated list as the arguments of the -backends option. Each is specified as host:port.','specify  as host:port',0,'',''),(1348,'CoreNLP','Providing that the server has foreign language models available on its classpath, you can ask for it to work with texts in other languages. If you have the French properties file and a file called french.txt in your current directory, then you should be able to successfully give a command like this:','call french.txt in current directory',1,'https://stanfordnlp.github.io/CoreNLP/corenlp-server.html','java-client'),(1349,'CoreNLP','The server is started directly though calling it with java. For example, the following will start the server in the background on port 1337, assuming your classpath is set properly:','call  with java',1,'https://stanfordnlp.github.io/CoreNLP/corenlp-server.html','starting-the-server'),(1350,'CoreNLP','The server is started directly though calling it with java. For example, the following will start the server in the background on port 1337, assuming your classpath is set properly:','set classpath',1,'https://stanfordnlp.github.io/CoreNLP/corenlp-server.html','starting-the-server'),(1351,'CoreNLP','The classpath must include all of the CoreNLP dependencies. The memory requirements of the server are the same as that of CoreNLP, though it will grow as you load more models (e.g., memory increases if you load both the PCFG and Shift-Reduce constituency parser models). A safe minimum is 4gb; 8gb is recommended if you can spare it.','load more models',0,'',''),(1352,'CoreNLP','If running the server under docker, the container’s port 9000 has to be published to the host. Give a command like: docker run -p 9000:9000 --name coreNLP --rm -i -t frnkenstien/corenlp. If, when going to localhost:9000/, you see the error This site can’t be reached. localhost refused to connect, then this is what you failed to do!','reach site',0,'',''),(1353,'CoreNLP','If running the server under docker, the container’s port 9000 has to be published to the host. Give a command like: docker run -p 9000:9000 --name coreNLP --rm -i -t frnkenstien/corenlp. If, when going to localhost:9000/, you see the error This site can’t be reached. localhost refused to connect, then this is what you failed to do!','reach error',0,'',''),(1354,'CoreNLP','The server can be stopped programmatically by making a call to the /shutdown endpoint with an appropriate shutdown key. This key is saved to the file corenlp.shutdown in the directory specified by System.getProperty(\"java.io.tmpdir\"); when the server starts. Typically this will be /tmp/corenlp.shutdown, though it can vary, especially on macOS. An example command to shut down the server would be:','save key in directory',1,'https://stanfordnlp.github.io/CoreNLP/corenlp-server.html','stopping-the-server'),(1355,'CoreNLP','The server can be stopped programmatically by making a call to the /shutdown endpoint with an appropriate shutdown key. This key is saved to the file corenlp.shutdown in the directory specified by System.getProperty(\"java.io.tmpdir\"); when the server starts. Typically this will be /tmp/corenlp.shutdown, though it can vary, especially on macOS. An example command to shut down the server would be:','save key to file corenlp.shutdown',1,'https://stanfordnlp.github.io/CoreNLP/corenlp-server.html','stopping-the-server'),(1356,'CoreNLP','If you start the server with -server_id SERVER_NAME it will store the shutdown key in a file called corenlp.shutdown.SERVER_NAME.','call corenlp.shutdown.SERVER_NAME',0,'',''),(1357,'CoreNLP','This section describes how to set up a dedicated CoreNLP server on a fresh Linux install. These instructions are definitely okay on a CentOS 6 system, which is what our demo server runs on. We include a couple of notes of variations below. As always, make sure you understand the commands being run below, as they largely require root permissions:','set up dedicated CoreNLP server on fresh Linux',1,'https://stanfordnlp.github.io/CoreNLP/corenlp-server.html','dedicated-server'),(1358,'CoreNLP','Create a user nlp with permissions to read the directory /opt/corenlp. Allow the user to bind to port 80:','create user nlp with permissions',1,'https://stanfordnlp.github.io/CoreNLP/corenlp-server.html',''),(1359,'CoreNLP','Link the script to /etc/rc.d/: ln -s /etc/init.d/corenlp /etc/rc.d/rc2.d/S75corenlp','link script',0,'',''),(1360,'CoreNLP','This section documents some of the subtle quirks of the server, and the motivations behind them.','document motivations',0,'',''),(1361,'CoreNLP','The official HTTP 1.1 specification recommends ISO-8859-1 as the encoding of a request, unless a different encoding is explicitly set by using the Content-Type header. However, for most NLP applications this is an unintuitive default, and so the server instead defaults to UTF-8. To enable the ISO-8859-1 default, pass in the -strict flag to the server at startup.','set different encoding',0,'',''),(1362,'CoreNLP','The official HTTP 1.1 specification recommends ISO-8859-1 as the encoding of a request, unless a different encoding is explicitly set by using the Content-Type header. However, for most NLP applications this is an unintuitive default, and so the server instead defaults to UTF-8. To enable the ISO-8859-1 default, pass in the -strict flag to the server at startup.','enable ISO-8859-1 default',0,'',''),(1363,'CoreNLP','CoreNLP is your one stop shop for natural language processing in Java! CoreNLP enables users to derive linguistic annotations for text, including token and sentence boundaries, parts of speech, named entities, numeric and time values, dependency and constituency parses, coreference, sentiment, quote attributions, and relations. CoreNLP currently supports 8 languages: Arabic, Chinese, English, French, German, Hungarian, Italian, and Spanish.','support languages',0,'',''),(1364,'CoreNLP','The centerpiece of CoreNLP is the pipeline. Pipelines take in raw text, run a series of NLP annotators on the text, and produce a final set of annotations.','produce final set of annotations',0,'',''),(1365,'CoreNLP','Pipelines produce CoreDocuments, data objects that contain all of the annotation information, accessible with a simple API, and serializable to a Google Protocol Buffer.','produce CoreDocuments',0,'',''),(1366,'CoreNLP','Download model jars for the language you want to work on and move the jars to the distribution directory. Jars are available directly from us, from Maven, and from Hugging Face.','move jars to distribution directory',0,'',''),(1367,'CoreNLP','The full Stanford CoreNLP is licensed under the GNU General Public License v3 or later. More precisely, all the Stanford NLP code is GPL v2+, but CoreNLP uses some Apache-licensed libraries, and so our understanding is that the the composite is correctly licensed as v3+. You can run almost all of CoreNLP under GPL v2; you simply need to omit the time-related libraries, and then you lose the functionality of SUTime. Note that the license is the full GPL, which allows many free uses, but not its use in proprietary software which is distributed to others. For distributors of proprietary software, CoreNLP is also available from Stanford under a commercial licensing You can contact us at java-nlp-support@lists.stanford.edu. If you don’t need a commercial license, but would like to support maintenance of these tools, we welcome gift funding: use this form and write “Stanford NLP Group open source software” in the Special Instructions.','support maintenance of tools',0,'',''),(1368,'CoreNLP','Provides a fast syntactic dependency parser. We generate three dependency-based outputs, as follows: basic, uncollapsed dependencies, saved in BasicDependenciesAnnotation; enhanced dependencies saved in EnhancedDependenciesAnnotation; and enhanced++ dependencies in EnhancedPlusPlusDependenciesAnnotation. Most users of our parser will prefer the latter representation.','provide fast syntactic dependency parser',0,'',''),(1369,'CoreNLP','Provides a fast syntactic dependency parser. We generate three dependency-based outputs, as follows: basic, uncollapsed dependencies, saved in BasicDependenciesAnnotation; enhanced dependencies saved in EnhancedDependenciesAnnotation; and enhanced++ dependencies in EnhancedPlusPlusDependenciesAnnotation. Most users of our parser will prefer the latter representation.','save  in basicdependenciesannotation',0,'',''),(1370,'CoreNLP','Provides a fast syntactic dependency parser. We generate three dependency-based outputs, as follows: basic, uncollapsed dependencies, saved in BasicDependenciesAnnotation; enhanced dependencies saved in EnhancedDependenciesAnnotation; and enhanced++ dependencies in EnhancedPlusPlusDependenciesAnnotation. Most users of our parser will prefer the latter representation.','save  in enhanceddependenciesannotation',0,'',''),(1371,'CoreNLP','For details about the dependency software, see this page. For more details about dependency parsing in general, see this page.','parse  in general',0,'',''),(1372,'CoreNLP','Stanford CoreNLP can be downloaded via the link below. This will download a large (482 MB) zip file containing (1) the CoreNLP code jar, (2) the CoreNLP models jar (required in your classpath for most tasks) (3) the libraries required to run CoreNLP, and (4) documentation / source code for the project. This is everything for getting going on English! Unzip this file, open the folder that results and you’re ready to use it.','open folder',0,'',''),(1373,'CoreNLP','If you want to change the source code and recompile the files, see these instructions. Previous releases can be found on the release history page.','change source code',0,'',''),(1374,'CoreNLP','If you want to change the source code and recompile the files, see these instructions. Previous releases can be found on the release history page.','recompile files',0,'',''),(1375,'CoreNLP','Maven: You can find Stanford CoreNLP on Maven Central. The crucial thing to know is that CoreNLP needs its models to run (most parts beyond the tokenizer and sentence splitter) and so you need to specify both the code jar and the models jar in your pom.xml, as follows: (Note: Maven releases are usually made several days after a release on the website.)','specify code jar in pom.xml',1,'https://stanfordnlp.github.io/CoreNLP/download.html','getting-a-copy'),(1376,'CoreNLP','Maven: You can find Stanford CoreNLP on Maven Central. The crucial thing to know is that CoreNLP needs its models to run (most parts beyond the tokenizer and sentence splitter) and so you need to specify both the code jar and the models jar in your pom.xml, as follows: (Note: Maven releases are usually made several days after a release on the website.)','specify models jar in pom.xml',1,'https://stanfordnlp.github.io/CoreNLP/download.html','getting-a-copy'),(1377,'CoreNLP','If you want to get a language models jar off of Maven for Arabic, Chinese, German, or Spanish, also add this inside dependencies to your pom.xml:','get language models jar off_of Maven',1,'https://stanfordnlp.github.io/CoreNLP/download.html','getting-a-copy'),(1378,'CoreNLP','If you want to get a language models jar off of Maven for Arabic, Chinese, German, or Spanish, also add this inside dependencies to your pom.xml:','add inside dependencies to pom.xml',1,'https://stanfordnlp.github.io/CoreNLP/download.html','getting-a-copy'),(1379,'CoreNLP','You can build the project with this command:','build project with command',1,'https://stanfordnlp.github.io/CoreNLP/download.html','getting-a-copy'),(1380,'CoreNLP','This example goes over how to set up CoreNLP from the latest official release. This example will take you through downloading the package, and running a simple command-line invocation of CoreNLP.','set up CoreNLP from latest official release',0,'',''),(1381,'CoreNLP','We’re happy to list other models and annotators that work with Stanford CoreNLP. If you have something, please get in touch!','get  in touch',0,'',''),(1382,'CoreNLP','We’ve moved this information to the page on other human languages','move information to page',0,'',''),(1383,'CoreNLP','We’ve moved this information to the page on other human languages','move information on other human languages',0,'',''),(1384,'CoreNLP','We’ve moved this information to the page on other languages and packages.','move information to page',0,'',''),(1385,'CoreNLP','We’ve moved this information to the page on other languages and packages.','move information on other languages',0,'',''),(1386,'CoreNLP','We’ve moved this information to the page on other languages and packages.','move information on packages',0,'',''),(1387,'CoreNLP','The most likely cause of these errors is that one or more of the important jar files is missing. If it occurs when loading the models, make sure the current models file is in the classpath. The basic models file has a name like stanford-corenlp-V.V.V-models.jar, depending on the version. For other language models, you may also need additional models jars, which will have the language name in them. If you encounter this exception when trying to produce XML output, make sure xom.jar is included. Finally, if it seems to occur when loading SUTime, be sure to include joda-time.jar, etc.','load models',0,'',''),(1388,'CoreNLP','The most likely cause of these errors is that one or more of the important jar files is missing. If it occurs when loading the models, make sure the current models file is in the classpath. The basic models file has a name like stanford-corenlp-V.V.V-models.jar, depending on the version. For other language models, you may also need additional models jars, which will have the language name in them. If you encounter this exception when trying to produce XML output, make sure xom.jar is included. Finally, if it seems to occur when loading SUTime, be sure to include joda-time.jar, etc.','produce XML output',0,'',''),(1389,'CoreNLP','The most likely cause of these errors is that one or more of the important jar files is missing. If it occurs when loading the models, make sure the current models file is in the classpath. The basic models file has a name like stanford-corenlp-V.V.V-models.jar, depending on the version. For other language models, you may also need additional models jars, which will have the language name in them. If you encounter this exception when trying to produce XML output, make sure xom.jar is included. Finally, if it seems to occur when loading SUTime, be sure to include joda-time.jar, etc.','load SUTime',0,'',''),(1390,'CoreNLP','A brief demo program included with the download will demonstrate how to load the tool and start processing text. When using this demo program, be sure to include all of the appropriate jar files in the classpath.','load tool',0,'',''),(1391,'CoreNLP','Once you have tried this, there is quite a bit of information on the CoreNLP home page describing what Annotators are available, what annotations they add to the text, and what options they support.','support options',0,'',''),(1392,'CoreNLP','Once you have tried this, there is quite a bit of information on the CoreNLP home page describing what Annotators are available, what annotations they add to the text, and what options they support.','add  to text',0,'',''),(1393,'CoreNLP','By default, it uses Unicode’s UTF-8. You can change the encoding used when reading files by either setting the Java encoding property or more simply by supplying the program with the command line flag -encoding FOO (or including the corresponding property in a properties file that you are using).','change encoding',0,'',''),(1394,'CoreNLP','By default, it uses Unicode’s UTF-8. You can change the encoding used when reading files by either setting the Java encoding property or more simply by supplying the program with the command line flag -encoding FOO (or including the corresponding property in a properties file that you are using).','set Java encoding property by supplying',0,'',''),(1395,'CoreNLP','By default, it uses Unicode’s UTF-8. You can change the encoding used when reading files by either setting the Java encoding property or more simply by supplying the program with the command line flag -encoding FOO (or including the corresponding property in a properties file that you are using).','encode FOO',0,'',''),(1396,'CoreNLP','Either give CoreNLP more memory, use fewer annotators, or give CoreNLP smaller documents. Nearly all our annotators load large model files which use lots of memory. Running the full CoreNLP pipeline requires the sum of all these memory requirements. Typically, this means that CoreNLP needs about 2GB to run the entire pipeline. Additionally, the coreference module operates over an entire document. Unless things are size-limited, as either sentence length or document size increases, processing time and space increase without bound.','load large model files',0,'',''),(1397,'CoreNLP','On recent versions of Java, it should not be necessary to specify a memory flag. On older versions, when Java running from the command line, you need to supply a flag like -Xmx2g.','specify memory flag',0,'',''),(1398,'CoreNLP','This is part of SUTime. It applies to repeating events such as “every other week” or “every two weeks”. SET is not the best name for such an event, but it matches the TIMEX3 standard (see section 2.3 of the linked document)','repeat events such_as other week',0,'',''),(1399,'CoreNLP','This is part of SUTime. It applies to repeating events such as “every other week” or “every two weeks”. SET is not the best name for such an event, but it matches the TIMEX3 standard (see section 2.3 of the linked document)','repeat events such_as weeks',0,'',''),(1400,'CoreNLP','Other than English, we currently provide trained CoreNLP models for Chinese. To run CoreNLP on Chinese text, you first have to download the models, which can be found in our release history. Include this .jar in your classpath, and use the StanfordCoreNLP-chinese.properties file it contains to process Chinese. For example, if you put the .jar in your distribution directory, you could run (adjusting the .jar version file extensions to your current release): java -cp stanford-corenlp-VV.jar:stanford-chinese-corenlp-VV-models.jar edu.stanford.nlp.pipeline.StanfordCoreNLP -props StanfordCoreNLP-chinese.properties -file your-chinese-file.txt','provide trained CoreNLP models for chinese',0,'',''),(1401,'CoreNLP','The straightforward case is if you have an older version of a Stanford NLP tool. For example, you may still have a version of Stanford NER on your classpath that was released in 2009. In this case, you should upgrade, or at least use matching versions. For any releases from 2011 on, just use tools released at the same time – such as the most recent version of everything :) – and they will all be compatible and play nicely together.','release version of Stanford NER',0,'',''),(1402,'CoreNLP','The straightforward case is if you have an older version of a Stanford NLP tool. For example, you may still have a version of Stanford NER on your classpath that was released in 2009. In this case, you should upgrade, or at least use matching versions. For any releases from 2011 on, just use tools released at the same time – such as the most recent version of everything :) – and they will all be compatible and play nicely together.','release  at same time',0,'',''),(1403,'CoreNLP','The straightforward case is if you have an older version of a Stanford NLP tool. For example, you may still have a version of Stanford NER on your classpath that was released in 2009. In this case, you should upgrade, or at least use matching versions. For any releases from 2011 on, just use tools released at the same time – such as the most recent version of everything :) – and they will all be compatible and play nicely together.','release  for releases',0,'',''),(1404,'CoreNLP','The straightforward case is if you have an older version of a Stanford NLP tool. For example, you may still have a version of Stanford NER on your classpath that was released in 2009. In this case, you should upgrade, or at least use matching versions. For any releases from 2011 on, just use tools released at the same time – such as the most recent version of everything :) – and they will all be compatible and play nicely together.','play  at same time',0,'',''),(1405,'CoreNLP','The straightforward case is if you have an older version of a Stanford NLP tool. For example, you may still have a version of Stanford NER on your classpath that was released in 2009. In this case, you should upgrade, or at least use matching versions. For any releases from 2011 on, just use tools released at the same time – such as the most recent version of everything :) – and they will all be compatible and play nicely together.','play  for releases',0,'',''),(1406,'CoreNLP','The tricky case of this is when people distribute jar files that hide other people’s classes inside them. People think this will make it easy for users, since they can distribute one jar that has everything you need, but, in practice, as soon as people are building applications using multiple components, this results in a particular bad form of jar hell. People just shouldn’t do this. The only way to check that other jar files do not contain conflicting versions of Stanford tools is to look at what is inside them (for example, with the jar -tf command).','hide classes',0,'',''),(1407,'CoreNLP','The tricky case of this is when people distribute jar files that hide other people’s classes inside them. People think this will make it easy for users, since they can distribute one jar that has everything you need, but, in practice, as soon as people are building applications using multiple components, this results in a particular bad form of jar hell. People just shouldn’t do this. The only way to check that other jar files do not contain conflicting versions of Stanford tools is to look at what is inside them (for example, with the jar -tf command).','hide jar files',0,'',''),(1408,'CoreNLP','The tricky case of this is when people distribute jar files that hide other people’s classes inside them. People think this will make it easy for users, since they can distribute one jar that has everything you need, but, in practice, as soon as people are building applications using multiple components, this results in a particular bad form of jar hell. People just shouldn’t do this. The only way to check that other jar files do not contain conflicting versions of Stanford tools is to look at what is inside them (for example, with the jar -tf command).','build applications',0,'',''),(1409,'CoreNLP','In practice, if you’re having problems, the most common cause (in 2013-2014) is that you have ark-tweet-nlp on your classpath. The jar file in their github download hides old versions of many other people’s jar files, including Apache commons-codec (v1.4), commons-lang, commons-math, commons-io, Lucene; Twitter commons; Google Guava (v10); Jackson; Berkeley NLP code; Percy Liang’s fig; GNU trove; and an outdated version of the Stanford POS tagger (from 2011). You should complain to them for creating you and us grief. But you can then fix the problem by using their jar file from Maven Central. It doesn’t have all those other libraries stuffed inside.','hide old versions including twitter commons',0,'',''),(1410,'CoreNLP','In practice, if you’re having problems, the most common cause (in 2013-2014) is that you have ark-tweet-nlp on your classpath. The jar file in their github download hides old versions of many other people’s jar files, including Apache commons-codec (v1.4), commons-lang, commons-math, commons-io, Lucene; Twitter commons; Google Guava (v10); Jackson; Berkeley NLP code; Percy Liang’s fig; GNU trove; and an outdated version of the Stanford POS tagger (from 2011). You should complain to them for creating you and us grief. But you can then fix the problem by using their jar file from Maven Central. It doesn’t have all those other libraries stuffed inside.','hide old versions including GNU trove',0,'',''),(1411,'CoreNLP','In practice, if you’re having problems, the most common cause (in 2013-2014) is that you have ark-tweet-nlp on your classpath. The jar file in their github download hides old versions of many other people’s jar files, including Apache commons-codec (v1.4), commons-lang, commons-math, commons-io, Lucene; Twitter commons; Google Guava (v10); Jackson; Berkeley NLP code; Percy Liang’s fig; GNU trove; and an outdated version of the Stanford POS tagger (from 2011). You should complain to them for creating you and us grief. But you can then fix the problem by using their jar file from Maven Central. It doesn’t have all those other libraries stuffed inside.','hide old versions including google Guava',0,'',''),(1412,'CoreNLP','In practice, if you’re having problems, the most common cause (in 2013-2014) is that you have ark-tweet-nlp on your classpath. The jar file in their github download hides old versions of many other people’s jar files, including Apache commons-codec (v1.4), commons-lang, commons-math, commons-io, Lucene; Twitter commons; Google Guava (v10); Jackson; Berkeley NLP code; Percy Liang’s fig; GNU trove; and an outdated version of the Stanford POS tagger (from 2011). You should complain to them for creating you and us grief. But you can then fix the problem by using their jar file from Maven Central. It doesn’t have all those other libraries stuffed inside.','hide old versions including Apache lucene',0,'',''),(1413,'CoreNLP','In practice, if you’re having problems, the most common cause (in 2013-2014) is that you have ark-tweet-nlp on your classpath. The jar file in their github download hides old versions of many other people’s jar files, including Apache commons-codec (v1.4), commons-lang, commons-math, commons-io, Lucene; Twitter commons; Google Guava (v10); Jackson; Berkeley NLP code; Percy Liang’s fig; GNU trove; and an outdated version of the Stanford POS tagger (from 2011). You should complain to them for creating you and us grief. But you can then fix the problem by using their jar file from Maven Central. It doesn’t have all those other libraries stuffed inside.','hide old versions including jackson',0,'',''),(1414,'CoreNLP','In practice, if you’re having problems, the most common cause (in 2013-2014) is that you have ark-tweet-nlp on your classpath. The jar file in their github download hides old versions of many other people’s jar files, including Apache commons-codec (v1.4), commons-lang, commons-math, commons-io, Lucene; Twitter commons; Google Guava (v10); Jackson; Berkeley NLP code; Percy Liang’s fig; GNU trove; and an outdated version of the Stanford POS tagger (from 2011). You should complain to them for creating you and us grief. But you can then fix the problem by using their jar file from Maven Central. It doesn’t have all those other libraries stuffed inside.','hide old versions including outdated version',0,'',''),(1415,'CoreNLP','In practice, if you’re having problems, the most common cause (in 2013-2014) is that you have ark-tweet-nlp on your classpath. The jar file in their github download hides old versions of many other people’s jar files, including Apache commons-codec (v1.4), commons-lang, commons-math, commons-io, Lucene; Twitter commons; Google Guava (v10); Jackson; Berkeley NLP code; Percy Liang’s fig; GNU trove; and an outdated version of the Stanford POS tagger (from 2011). You should complain to them for creating you and us grief. But you can then fix the problem by using their jar file from Maven Central. It doesn’t have all those other libraries stuffed inside.','hide old versions including berkeley NLP code',0,'',''),(1416,'CoreNLP','In practice, if you’re having problems, the most common cause (in 2013-2014) is that you have ark-tweet-nlp on your classpath. The jar file in their github download hides old versions of many other people’s jar files, including Apache commons-codec (v1.4), commons-lang, commons-math, commons-io, Lucene; Twitter commons; Google Guava (v10); Jackson; Berkeley NLP code; Percy Liang’s fig; GNU trove; and an outdated version of the Stanford POS tagger (from 2011). You should complain to them for creating you and us grief. But you can then fix the problem by using their jar file from Maven Central. It doesn’t have all those other libraries stuffed inside.','hide old versions including percy liang s fig',0,'',''),(1417,'CoreNLP','In practice, if you’re having problems, the most common cause (in 2013-2014) is that you have ark-tweet-nlp on your classpath. The jar file in their github download hides old versions of many other people’s jar files, including Apache commons-codec (v1.4), commons-lang, commons-math, commons-io, Lucene; Twitter commons; Google Guava (v10); Jackson; Berkeley NLP code; Percy Liang’s fig; GNU trove; and an outdated version of the Stanford POS tagger (from 2011). You should complain to them for creating you and us grief. But you can then fix the problem by using their jar file from Maven Central. It doesn’t have all those other libraries stuffed inside.','hide old versions of jar files',0,'',''),(1418,'CoreNLP','You need to add the flag -parse.flags \"\" (or the corresponding property parse.flags:   ). It’s sort of a misfeature/bug that the default properties of CoreNLP turn this option on by default, because it is useful for English, but it isn’t defined for other languages, and so you get an error.)','add flag -parse.flags',0,'',''),(1419,'CoreNLP','You need to add the flag -parse.flags \"\" (or the corresponding property parse.flags:   ). It’s sort of a misfeature/bug that the default properties of CoreNLP turn this option on by default, because it is useful for English, but it isn’t defined for other languages, and so you get an error.)','get error',0,'',''),(1420,'CoreNLP','You need to add the flag -parse.flags \"\" (or the corresponding property parse.flags:   ). It’s sort of a misfeature/bug that the default properties of CoreNLP turn this option on by default, because it is useful for English, but it isn’t defined for other languages, and so you get an error.)','define  for other languages',0,'',''),(1421,'CoreNLP','The parser can be instructed to keep certain sets of tokens together as a single constituent. If you do this, it will try to make a parse which contains a subtree where the exact set of tokens in that subtree are the ones specified in the constraint.','specify  in constraint',0,'',''),(1422,'CoreNLP','For any sentence where you want to add constraints, attach the ParserAnnotations.ConstraintAnnotation to that sentence. This annotation is a List, where ParserConstraint specifies the start (inclusive) and end (exclusive) of the range and a pattern which the enclosing constituent must match. However, there is a bug in the way patterns are handled in the parser, so it is strongly recommended to use .* for the matching pattern.','add constraints',0,'',''),(1423,'CoreNLP','For any sentence where you want to add constraints, attach the ParserAnnotations.ConstraintAnnotation to that sentence. This annotation is a List, where ParserConstraint specifies the start (inclusive) and end (exclusive) of the range and a pattern which the enclosing constituent must match. However, there is a bug in the way patterns are handled in the parser, so it is strongly recommended to use .* for the matching pattern.','attach ParserAnnotations.ConstraintAnnotation for sentence',0,'',''),(1424,'CoreNLP','For any sentence where you want to add constraints, attach the ParserAnnotations.ConstraintAnnotation to that sentence. This annotation is a List, where ParserConstraint specifies the start (inclusive) and end (exclusive) of the range and a pattern which the enclosing constituent must match. However, there is a bug in the way patterns are handled in the parser, so it is strongly recommended to use .* for the matching pattern.','attach ParserAnnotations.ConstraintAnnotation to sentence',0,'',''),(1425,'CoreNLP','For any sentence where you want to add constraints, attach the ParserAnnotations.ConstraintAnnotation to that sentence. This annotation is a List, where ParserConstraint specifies the start (inclusive) and end (exclusive) of the range and a pattern which the enclosing constituent must match. However, there is a bug in the way patterns are handled in the parser, so it is strongly recommended to use .* for the matching pattern.','specify start of range',0,'',''),(1426,'CoreNLP','For any sentence where you want to add constraints, attach the ParserAnnotations.ConstraintAnnotation to that sentence. This annotation is a List, where ParserConstraint specifies the start (inclusive) and end (exclusive) of the range and a pattern which the enclosing constituent must match. However, there is a bug in the way patterns are handled in the parser, so it is strongly recommended to use .* for the matching pattern.','specify start of pattern',0,'',''),(1427,'CoreNLP','For any sentence where you want to add constraints, attach the ParserAnnotations.ConstraintAnnotation to that sentence. This annotation is a List, where ParserConstraint specifies the start (inclusive) and end (exclusive) of the range and a pattern which the enclosing constituent must match. However, there is a bug in the way patterns are handled in the parser, so it is strongly recommended to use .* for the matching pattern.','specify end of range',0,'',''),(1428,'CoreNLP','For any sentence where you want to add constraints, attach the ParserAnnotations.ConstraintAnnotation to that sentence. This annotation is a List, where ParserConstraint specifies the start (inclusive) and end (exclusive) of the range and a pattern which the enclosing constituent must match. However, there is a bug in the way patterns are handled in the parser, so it is strongly recommended to use .* for the matching pattern.','specify end of pattern',0,'',''),(1429,'CoreNLP','For any sentence where you want to add constraints, attach the ParserAnnotations.ConstraintAnnotation to that sentence. This annotation is a List, where ParserConstraint specifies the start (inclusive) and end (exclusive) of the range and a pattern which the enclosing constituent must match. However, there is a bug in the way patterns are handled in the parser, so it is strongly recommended to use .* for the matching pattern.','specify list of range',0,'',''),(1430,'CoreNLP','For any sentence where you want to add constraints, attach the ParserAnnotations.ConstraintAnnotation to that sentence. This annotation is a List, where ParserConstraint specifies the start (inclusive) and end (exclusive) of the range and a pattern which the enclosing constituent must match. However, there is a bug in the way patterns are handled in the parser, so it is strongly recommended to use .* for the matching pattern.','specify list of pattern',0,'',''),(1431,'CoreNLP','For any sentence where you want to add constraints, attach the ParserAnnotations.ConstraintAnnotation to that sentence. This annotation is a List, where ParserConstraint specifies the start (inclusive) and end (exclusive) of the range and a pattern which the enclosing constituent must match. However, there is a bug in the way patterns are handled in the parser, so it is strongly recommended to use .* for the matching pattern.','handle patterns in parser',0,'',''),(1432,'CoreNLP','For any sentence where you want to add constraints, attach the ParserAnnotations.ConstraintAnnotation to that sentence. This annotation is a List, where ParserConstraint specifies the start (inclusive) and end (exclusive) of the range and a pattern which the enclosing constituent must match. However, there is a bug in the way patterns are handled in the parser, so it is strongly recommended to use .* for the matching pattern.','handle way in parser',0,'',''),(1433,'CoreNLP','If you want CoreNLP to output the original Stanford Dependencies instead of the new Universal Dependencies, simply add the option -parse.originalDependencies or the property (\"parse.originalDependencies\", true) to your command or code, respectively.','add option -parse.originalDependencies to command',0,'',''),(1434,'CoreNLP','If you want CoreNLP to output the original Stanford Dependencies instead of the new Universal Dependencies, simply add the option -parse.originalDependencies or the property (\"parse.originalDependencies\", true) to your command or code, respectively.','add option -parse.originalDependencies to code',0,'',''),(1435,'CoreNLP','If you want CoreNLP to output the original Stanford Dependencies instead of the new Universal Dependencies, simply add the option -parse.originalDependencies or the property (\"parse.originalDependencies\", true) to your command or code, respectively.','add property to command',0,'',''),(1436,'CoreNLP','If you want CoreNLP to output the original Stanford Dependencies instead of the new Universal Dependencies, simply add the option -parse.originalDependencies or the property (\"parse.originalDependencies\", true) to your command or code, respectively.','add property to code',0,'',''),(1437,'CoreNLP','Note, however, that some annotators that use dependencies such as natlog might not function properly if you use this option. In case you are using the Neural Network Dependency Parser, use the following model to get Stanford Dependencies:','get Stanford dependencies',1,'https://stanfordnlp.github.io/CoreNLP/faq.html','how-can-i-get-original-stanford-dependencies-instead-of-universal-dependencies'),(1438,'CoreNLP','Out-of-the-box, Stanford CoreNLP expects and processes English language text. But, Stanford CoreNLP was designed from the start to work with multiple human languages and it is careful about things like different character encodings. We have developed components for several major languages, and make language packs (jar files) available for some of them. The table below summarizes our current first party foreign language support. Other people have developed models for other languages.','design stanford CoreNLP from start',0,'',''),(1439,'CoreNLP','Out-of-the-box, Stanford CoreNLP expects and processes English language text. But, Stanford CoreNLP was designed from the start to work with multiple human languages and it is careful about things like different character encodings. We have developed components for several major languages, and make language packs (jar files) available for some of them. The table below summarizes our current first party foreign language support. Other people have developed models for other languages.','develop components for several major languages',0,'',''),(1440,'CoreNLP','Out-of-the-box, Stanford CoreNLP expects and processes English language text. But, Stanford CoreNLP was designed from the start to work with multiple human languages and it is careful about things like different character encodings. We have developed components for several major languages, and make language packs (jar files) available for some of them. The table below summarizes our current first party foreign language support. Other people have developed models for other languages.','summarize current first party foreign language support',0,'',''),(1441,'CoreNLP','Out-of-the-box, Stanford CoreNLP expects and processes English language text. But, Stanford CoreNLP was designed from the start to work with multiple human languages and it is careful about things like different character encodings. We have developed components for several major languages, and make language packs (jar files) available for some of them. The table below summarizes our current first party foreign language support. Other people have developed models for other languages.','develop models for other languages',0,'',''),(1442,'CoreNLP','For instance, to run a Spanish pipeline, one could execute this command from the command line:','execute command for instance',1,'https://stanfordnlp.github.io/CoreNLP/human-languages.html','running-pipelines'),(1443,'CoreNLP','For instance, to run a Spanish pipeline, one could execute this command from the command line:','execute command from command line',1,'https://stanfordnlp.github.io/CoreNLP/human-languages.html','running-pipelines'),(1444,'CoreNLP','Or build and run a pipeline in Java in this manner:','build pipeline in Java',1,'https://stanfordnlp.github.io/CoreNLP/human-languages.html','running-pipelines'),(1445,'CoreNLP','Currently French (UD 2.2), German (UD 2.2), and Spanish (AnCora UD 2.0) work off of the UD 2.0 tokenization standard. This means among other things that words are split into multiword tokens. For instance the French word \"des\" will be tokenized in some circumstances as \"de\" \"les\". All tagging, parsing, and named entity recognition models rely on that tokenization standard, so it is necessary to use the mwt annotator which performs the multiword tokenization. For instance, in Spanish, the annotators required to run dependency parsing would be tokenize,mwt,pos,lemma,depparse. The part of speech tags and dependency labels are from the UD 2.0 sets for each language.','split words into multiword tokens',0,'',''),(1446,'CoreNLP','Currently French (UD 2.2), German (UD 2.2), and Spanish (AnCora UD 2.0) work off of the UD 2.0 tokenization standard. This means among other things that words are split into multiword tokens. For instance the French word \"des\" will be tokenized in some circumstances as \"de\" \"les\". All tagging, parsing, and named entity recognition models rely on that tokenization standard, so it is necessary to use the mwt annotator which performs the multiword tokenization. For instance, in Spanish, the annotators required to run dependency parsing would be tokenize,mwt,pos,lemma,depparse. The part of speech tags and dependency labels are from the UD 2.0 sets for each language.','tokenize French word in circumstances',0,'',''),(1447,'CoreNLP','Currently French (UD 2.2), German (UD 2.2), and Spanish (AnCora UD 2.0) work off of the UD 2.0 tokenization standard. This means among other things that words are split into multiword tokens. For instance the French word \"des\" will be tokenized in some circumstances as \"de\" \"les\". All tagging, parsing, and named entity recognition models rely on that tokenization standard, so it is necessary to use the mwt annotator which performs the multiword tokenization. For instance, in Spanish, the annotators required to run dependency parsing would be tokenize,mwt,pos,lemma,depparse. The part of speech tags and dependency labels are from the UD 2.0 sets for each language.','tokenize French word for instance',0,'',''),(1448,'CoreNLP','Currently French (UD 2.2), German (UD 2.2), and Spanish (AnCora UD 2.0) work off of the UD 2.0 tokenization standard. This means among other things that words are split into multiword tokens. For instance the French word \"des\" will be tokenized in some circumstances as \"de\" \"les\". All tagging, parsing, and named entity recognition models rely on that tokenization standard, so it is necessary to use the mwt annotator which performs the multiword tokenization. For instance, in Spanish, the annotators required to run dependency parsing would be tokenize,mwt,pos,lemma,depparse. The part of speech tags and dependency labels are from the UD 2.0 sets for each language.','perform multiword tokenization',0,'',''),(1449,'CoreNLP','Currently French (UD 2.2), German (UD 2.2), and Spanish (AnCora UD 2.0) work off of the UD 2.0 tokenization standard. This means among other things that words are split into multiword tokens. For instance the French word \"des\" will be tokenized in some circumstances as \"de\" \"les\". All tagging, parsing, and named entity recognition models rely on that tokenization standard, so it is necessary to use the mwt annotator which performs the multiword tokenization. For instance, in Spanish, the annotators required to run dependency parsing would be tokenize,mwt,pos,lemma,depparse. The part of speech tags and dependency labels are from the UD 2.0 sets for each language.','perform mwt annotator',0,'',''),(1450,'CoreNLP','Other people have developed models using or compatible with CoreNLP for several further languages. They may or may not be compatible with the most recent release of CoreNLP that we provide.','develop models',0,'',''),(1451,'CoreNLP','People not infrequently complain that Stanford CoreNLP is slow or takes a ton of memory. In some configurations this is true. In other configurations, this is not true. This section tries to help you understand what you can or can’t do about speed and memory usage. The advice applies regardless of whether you are running CoreNLP from the command-line, from the Java API, from the web service, or from other languages. We show command-line examples here, but the principles are true of all ways of invoking CoreNLP. You will just need to pass in the appropriate properties in different ways. For these examples we will work with chapter 13 of Ulysses by James Joyce. You can download it if you want to follow along.','show command-line examples',0,'',''),(1452,'CoreNLP','People not infrequently complain that Stanford CoreNLP is slow or takes a ton of memory. In some configurations this is true. In other configurations, this is not true. This section tries to help you understand what you can or can’t do about speed and memory usage. The advice applies regardless of whether you are running CoreNLP from the command-line, from the Java API, from the web service, or from other languages. We show command-line examples here, but the principles are true of all ways of invoking CoreNLP. You will just need to pass in the appropriate properties in different ways. For these examples we will work with chapter 13 of Ulysses by James Joyce. You can download it if you want to follow along.','pass  in appropriate properties',0,'',''),(1453,'CoreNLP','How slow and memory intensive CoreNLP is depends on the annotators you choose. This is the first rule. In practice many people who have issues are just running CoreNLP out of the box with its default annotators. Not making any explicit choices about annotators or parameters is itself a choice. This page helps you make these choices wisely. Of course, sometimes the choices that are fast and memory efficient aren’t the choices that produce the highest quality annotations. Sometimes you have to make trade-offs.','produce highest quality annotations of course',0,'',''),(1454,'CoreNLP','How slow and memory intensive CoreNLP is depends on the annotators you choose. This is the first rule. In practice many people who have issues are just running CoreNLP out of the box with its default annotators. Not making any explicit choices about annotators or parameters is itself a choice. This page helps you make these choices wisely. Of course, sometimes the choices that are fast and memory efficient aren’t the choices that produce the highest quality annotations. Sometimes you have to make trade-offs.','produce choices of course',0,'',''),(1455,'CoreNLP','So, the first thing to know is that CoreNLP will be slow and take a lot of memory if and only if you choose annotators and annotation options that are slow and use a lot of memory.','choose annotators',0,'',''),(1456,'CoreNLP','So, the first thing to know is that CoreNLP will be slow and take a lot of memory if and only if you choose annotators and annotation options that are slow and use a lot of memory.','choose annotation options',0,'',''),(1457,'CoreNLP','If you’re using lots of annotators, CoreNLP can easily spend 10–40 seconds just loading an annotation pipeline. Pipeline loading time can easily dominate actual annotation time. So, if you load a new pipeline frequently, such as for every sentence, then CoreNLP will be painfully slow. You should load an annotation pipleline – what you get when you call new StanfordCoreNLP(props) in code – as infrequently as possible. Usually you can and should just load one pipeline and use it for everything. You only need to use multiple pipelines if you simultaneously need different configurations, such as working with multiple human languages or doing processing with different options or annotators.','load annotation pipeline',0,'',''),(1458,'CoreNLP','If you’re using lots of annotators, CoreNLP can easily spend 10–40 seconds just loading an annotation pipeline. Pipeline loading time can easily dominate actual annotation time. So, if you load a new pipeline frequently, such as for every sentence, then CoreNLP will be painfully slow. You should load an annotation pipleline – what you get when you call new StanfordCoreNLP(props) in code – as infrequently as possible. Usually you can and should just load one pipeline and use it for everything. You only need to use multiple pipelines if you simultaneously need different configurations, such as working with multiple human languages or doing processing with different options or annotators.','load new pipeline',0,'',''),(1459,'CoreNLP','If you’re using lots of annotators, CoreNLP can easily spend 10–40 seconds just loading an annotation pipeline. Pipeline loading time can easily dominate actual annotation time. So, if you load a new pipeline frequently, such as for every sentence, then CoreNLP will be painfully slow. You should load an annotation pipleline – what you get when you call new StanfordCoreNLP(props) in code – as infrequently as possible. Usually you can and should just load one pipeline and use it for everything. You only need to use multiple pipelines if you simultaneously need different configurations, such as working with multiple human languages or doing processing with different options or annotators.','load annotation pipleline',0,'',''),(1460,'CoreNLP','If you’re using lots of annotators, CoreNLP can easily spend 10–40 seconds just loading an annotation pipeline. Pipeline loading time can easily dominate actual annotation time. So, if you load a new pipeline frequently, such as for every sentence, then CoreNLP will be painfully slow. You should load an annotation pipleline – what you get when you call new StanfordCoreNLP(props) in code – as infrequently as possible. Usually you can and should just load one pipeline and use it for everything. You only need to use multiple pipelines if you simultaneously need different configurations, such as working with multiple human languages or doing processing with different options or annotators.','call new StanfordCoreNLP(props) in code',0,'',''),(1461,'CoreNLP','If you’re using lots of annotators, CoreNLP can easily spend 10–40 seconds just loading an annotation pipeline. Pipeline loading time can easily dominate actual annotation time. So, if you load a new pipeline frequently, such as for every sentence, then CoreNLP will be painfully slow. You should load an annotation pipleline – what you get when you call new StanfordCoreNLP(props) in code – as infrequently as possible. Usually you can and should just load one pipeline and use it for everything. You only need to use multiple pipelines if you simultaneously need different configurations, such as working with multiple human languages or doing processing with different options or annotators.','load pipeline',0,'',''),(1462,'CoreNLP','Beware that some old interfaces to CoreNLP from other programming languages fork a new CoreNLP process every time they are called. Look for a library that either talks to the CoreNLP web service API or directly calls into the Java code and so can avoid creating new annotation pipelines.','create new annotation pipelines',0,'',''),(1463,'CoreNLP','Beware that some old interfaces to CoreNLP from other programming languages fork a new CoreNLP process every time they are called. Look for a library that either talks to the CoreNLP web service API or directly calls into the Java code and so can avoid creating new annotation pipelines.','call  into Java code',0,'',''),(1464,'CoreNLP','Even at the command-line, if you have one thousand paragraph-long files named para1.txt, para2.txt, … then you will get much faster processing by doing this:','get faster processing by doing',1,'https://stanfordnlp.github.io/CoreNLP/memory-time.html','avoid-creating-lots-of-pipelines'),(1465,'CoreNLP','However, the default runs a lot of annotators, some of them very expensive. This is a great command if you want to have your text parsed and coreference run on it. However, if really the only things that you are going to use are parts of speech and named entities, you can get your processing done an order of magnitude more quickly by turning off expensive annotators like parsing and coreference.','get processing',0,'',''),(1466,'CoreNLP','If you run the above command in CoreNLP v.3.7.0 or later, your annotation speed is probably about 200 tokens per second. That’s 3 orders of magnitude slower than just tokenizing and sentence splitting, but actually this is the new good news for this version. We’ve changed the default annotator pipeline to make things faster.','change default annotator pipeline',1,'https://stanfordnlp.github.io/CoreNLP/memory-time.html','dont-run-annotators-that-you-dont-need'),(1467,'CoreNLP','Returning to v.3.7.0 and continuing with turning annotators off, if all you need are parts of speech and named entities, you should run a pipeline like this:','return  to v.3.7.0',1,'https://stanfordnlp.github.io/CoreNLP/memory-time.html','dont-run-annotators-that-you-dont-need'),(1468,'CoreNLP','and the annotation speed is about 6500 tokens per second – another 5 times faster. Limiting the number of annotators run can improve speed by orders of magnitude.','limit number of annotators',0,'',''),(1469,'CoreNLP','For 1., you should avoid having documents that are too large. Don’t try to parse a whole novel as one CoreNLP document. Parse each chapter as a separate document. This has already been covered above.','parse whole novel as CoreNLP document',0,'',''),(1470,'CoreNLP','For 1., you should avoid having documents that are too large. Don’t try to parse a whole novel as one CoreNLP document. Parse each chapter as a separate document. This has already been covered above.','parse chapter as separate document',0,'',''),(1471,'CoreNLP','For 2., the only thing you can do is to either remove annotators that you do not need or to make choices for smaller annotators. These models are what fills the large models jar. They are even larger when they are uncompressed and represented in memory. Here are some examples.','remove annotators',1,'https://stanfordnlp.github.io/CoreNLP/memory-time.html','where-does-all-the-memory-go'),(1472,'CoreNLP','For 2., the only thing you can do is to either remove annotators that you do not need or to make choices for smaller annotators. These models are what fills the large models jar. They are even larger when they are uncompressed and represented in memory. Here are some examples.','fill large models jar',1,'https://stanfordnlp.github.io/CoreNLP/memory-time.html','where-does-all-the-memory-go'),(1473,'CoreNLP','For 3., the classic problem case is parsing long sentences with dynamic programmed parsers like the traditional englishPCFG.ser.gz constituency parsing. This takes space proportional to the square of the longest sentence length, with a large constant factor. Parsing sentences that are hundreds of words long will take additional gigabytes of memory just for the parser data structures. The easiest fix for that is just to not parse super-long sentences. You can do that with a property like: -parse.maxlen 70. This can be a fine solution for something like web pages or newswire, where anything over 70 words is likely a table or list or something that isn’t a real sentence. However, it is unappealing for James Joyce: Several of the sentences in Chapter 13 are over 100 words but are well-formed, proper sentences. For example, here is one of the longer sentences in the chapter:','parse long sentences with dynamic programmed parsers',0,'',''),(1474,'CoreNLP','Alternatively, if you do not require constituency parses but can make do with dependency parses (perhaps then using components like coreference algorithms that work with dependency parses), then things are much better again: The neural dependency parser is compact and much faster again than the shift-reduce constituency parser. You invoke it by choosing the annotator depparse instead of parse.','choose annotator depparse instead_of parse',0,'',''),(1475,'CoreNLP','Nevertheless, in general, very long sentences blow out processing time and memory. One thing to be aware of is that CoreNLP currently uses simple, heuristic sentence splitting on sentence terminators like ‘.’ and ‘?’. If you are parsing “noisy” text without explicit sentence breaks – this often happens if you parse things like tables or web pages – you can end up with “sentences” more than 500 words long, which it isn’t even useful to try to parse. You should either clean these up in data preprocessing or limit the sentence length that annotators try to process. Several annotators support a maximum sentence length property and will simply skip processing of longer sentence. The most commonly useful of these is parse.maxlen but there is also kbp.maxlen, ner.maxlen, and pos.maxlen.','parse noisy text without explicit sentence breaks',0,'',''),(1476,'CoreNLP','Nevertheless, in general, very long sentences blow out processing time and memory. One thing to be aware of is that CoreNLP currently uses simple, heuristic sentence splitting on sentence terminators like ‘.’ and ‘?’. If you are parsing “noisy” text without explicit sentence breaks – this often happens if you parse things like tables or web pages – you can end up with “sentences” more than 500 words long, which it isn’t even useful to try to parse. You should either clean these up in data preprocessing or limit the sentence length that annotators try to process. Several annotators support a maximum sentence length property and will simply skip processing of longer sentence. The most commonly useful of these is parse.maxlen but there is also kbp.maxlen, ner.maxlen, and pos.maxlen.','parse things like tables',0,'',''),(1477,'CoreNLP','Nevertheless, in general, very long sentences blow out processing time and memory. One thing to be aware of is that CoreNLP currently uses simple, heuristic sentence splitting on sentence terminators like ‘.’ and ‘?’. If you are parsing “noisy” text without explicit sentence breaks – this often happens if you parse things like tables or web pages – you can end up with “sentences” more than 500 words long, which it isn’t even useful to try to parse. You should either clean these up in data preprocessing or limit the sentence length that annotators try to process. Several annotators support a maximum sentence length property and will simply skip processing of longer sentence. The most commonly useful of these is parse.maxlen but there is also kbp.maxlen, ner.maxlen, and pos.maxlen.','parse things like web pages',0,'',''),(1478,'CoreNLP','Nevertheless, in general, very long sentences blow out processing time and memory. One thing to be aware of is that CoreNLP currently uses simple, heuristic sentence splitting on sentence terminators like ‘.’ and ‘?’. If you are parsing “noisy” text without explicit sentence breaks – this often happens if you parse things like tables or web pages – you can end up with “sentences” more than 500 words long, which it isn’t even useful to try to parse. You should either clean these up in data preprocessing or limit the sentence length that annotators try to process. Several annotators support a maximum sentence length property and will simply skip processing of longer sentence. The most commonly useful of these is parse.maxlen but there is also kbp.maxlen, ner.maxlen, and pos.maxlen.','clean preprocessing',0,'',''),(1479,'CoreNLP','Nevertheless, in general, very long sentences blow out processing time and memory. One thing to be aware of is that CoreNLP currently uses simple, heuristic sentence splitting on sentence terminators like ‘.’ and ‘?’. If you are parsing “noisy” text without explicit sentence breaks – this often happens if you parse things like tables or web pages – you can end up with “sentences” more than 500 words long, which it isn’t even useful to try to parse. You should either clean these up in data preprocessing or limit the sentence length that annotators try to process. Several annotators support a maximum sentence length property and will simply skip processing of longer sentence. The most commonly useful of these is parse.maxlen but there is also kbp.maxlen, ner.maxlen, and pos.maxlen.','limit sentence length',0,'',''),(1480,'CoreNLP','Nevertheless, in general, very long sentences blow out processing time and memory. One thing to be aware of is that CoreNLP currently uses simple, heuristic sentence splitting on sentence terminators like ‘.’ and ‘?’. If you are parsing “noisy” text without explicit sentence breaks – this often happens if you parse things like tables or web pages – you can end up with “sentences” more than 500 words long, which it isn’t even useful to try to parse. You should either clean these up in data preprocessing or limit the sentence length that annotators try to process. Several annotators support a maximum sentence length property and will simply skip processing of longer sentence. The most commonly useful of these is parse.maxlen but there is also kbp.maxlen, ner.maxlen, and pos.maxlen.','support maximum sentence length property',0,'',''),(1481,'CoreNLP','Nevertheless, in general, very long sentences blow out processing time and memory. One thing to be aware of is that CoreNLP currently uses simple, heuristic sentence splitting on sentence terminators like ‘.’ and ‘?’. If you are parsing “noisy” text without explicit sentence breaks – this often happens if you parse things like tables or web pages – you can end up with “sentences” more than 500 words long, which it isn’t even useful to try to parse. You should either clean these up in data preprocessing or limit the sentence length that annotators try to process. Several annotators support a maximum sentence length property and will simply skip processing of longer sentence. The most commonly useful of these is parse.maxlen but there is also kbp.maxlen, ner.maxlen, and pos.maxlen.','skip processing of longer sentence',0,'',''),(1482,'CoreNLP','The slowest annotators are coreference and parsing. Many coreference methods are especially sensitive to the total document length, since they are quadratic or cubic in the number of mentions in the document. The parsing annotators, particularly dynamic-programming constituency parsing, is especially sensitive to maximum sentence length. Your processing will be much faster if you either leave out these annotators or choose options that make them as fast as possible. In v.3.7.0, the fastest, most memory-efficient models are the default: neural network dependency parsing followed by statistical coreference. In earlier versions, you should choose non-default options to maximize speed and memory efficiency. Again, the most time and memory efficient options are neural network dependency parsing followed by statistical coreference if you only need dependency parses, or shift-reduce constituency parsing followed by deterministic coreference if you do need constituency parses.','choose options',0,'',''),(1483,'CoreNLP','The slowest annotators are coreference and parsing. Many coreference methods are especially sensitive to the total document length, since they are quadratic or cubic in the number of mentions in the document. The parsing annotators, particularly dynamic-programming constituency parsing, is especially sensitive to maximum sentence length. Your processing will be much faster if you either leave out these annotators or choose options that make them as fast as possible. In v.3.7.0, the fastest, most memory-efficient models are the default: neural network dependency parsing followed by statistical coreference. In earlier versions, you should choose non-default options to maximize speed and memory efficiency. Again, the most time and memory efficient options are neural network dependency parsing followed by statistical coreference if you only need dependency parses, or shift-reduce constituency parsing followed by deterministic coreference if you do need constituency parses.','choose non-default options in earlier versions',0,'',''),(1484,'CoreNLP','The POS tagger does support a pos.maxlen flag, but this should rarely be needed, since the POS tagger uses memory and time linearly with sentence length. The default english-left3words-distsim.tagger is much faster than the english-bidirectional-distsim.tagger. (That is, about 10 times faster.)','support pos.maxlen flag',0,'',''),(1485,'CoreNLP','Until v.3.6.0, the default parser was englishPCFG.ser.gz. It was small and quick to load, but takes quadratic space and cubic time with sentence length. Bad news! If you have long sentences, you should either limit the maximum length parsed with a flag like -parse.maxlen 70 or choose a different parser.','limit maximum length',0,'',''),(1486,'CoreNLP','Until v.3.6.0, the default parser was englishPCFG.ser.gz. It was small and quick to load, but takes quadratic space and cubic time with sentence length. Bad news! If you have long sentences, you should either limit the maximum length parsed with a flag like -parse.maxlen 70 or choose a different parser.','choose different parser',0,'',''),(1487,'CoreNLP','Until v.3.6.0, the default parser was englishPCFG.ser.gz. It was small and quick to load, but takes quadratic space and cubic time with sentence length. Bad news! If you have long sentences, you should either limit the maximum length parsed with a flag like -parse.maxlen 70 or choose a different parser.','parse  with flag',0,'',''),(1488,'CoreNLP','The shift-reduce constituency parser takes space and time linear in sentence length. It still supports parse.maxlen, though. If you only need dependency parses, you can get even faster and more memory efficient parsing by using the depparse annotator instead.','support parse.maxlen',0,'',''),(1489,'CoreNLP','The shift-reduce constituency parser takes space and time linear in sentence length. It still supports parse.maxlen, though. If you only need dependency parses, you can get even faster and more memory efficient parsing by using the depparse annotator instead.','get faster more memory parsing',0,'',''),(1490,'CoreNLP','The dependency parser (depparse) annotator is faster and uses less space than even the shift-reduce constituency parser. It should be your tool of choice for parsing large amounts of data, unless you need constituency parses, of course. It does not at present support any options to limit parsing time or sentence length.','parse large amounts of course',0,'',''),(1491,'CoreNLP','The dependency parser (depparse) annotator is faster and uses less space than even the shift-reduce constituency parser. It should be your tool of choice for parsing large amounts of data, unless you need constituency parses, of course. It does not at present support any options to limit parsing time or sentence length.','parse large amounts of data',0,'',''),(1492,'CoreNLP','The dependency parser (depparse) annotator is faster and uses less space than even the shift-reduce constituency parser. It should be your tool of choice for parsing large amounts of data, unless you need constituency parses, of course. It does not at present support any options to limit parsing time or sentence length.','limit parsing time',0,'',''),(1493,'CoreNLP','The dependency parser (depparse) annotator is faster and uses less space than even the shift-reduce constituency parser. It should be your tool of choice for parsing large amounts of data, unless you need constituency parses, of course. It does not at present support any options to limit parsing time or sentence length.','limit sentence length',0,'',''),(1494,'CoreNLP','The neural models for English, French, German, and Spanish have been retrained with UD 2.0 dependencies, this will change several labels for the dependency parses. Info about UD 2.0 can be found here.','change several labels for dependency parses',0,'',''),(1495,'CoreNLP','Annotators, models, and rules for English, French, German, and Spanish now work with UD 2.0 tokenization by default. This includes models for tagging, parsing, named entity recognition (with an important exception), and KBP relation extraction. For example, the English tokenizer now splits most hyphenated tokens, does not normalize parentheses (e.g. turn ( into -LRB-), and does not normalize quotation marks.','split hyphenated tokens',0,'',''),(1496,'CoreNLP','The tokenization process for these languages has been designed to maximize F1 on dev/test sets from the CoNLL 2018 shared task, similar to Stanza.','design tokenization process for languages',0,'',''),(1497,'CoreNLP','A complication is that the UD 2.0 standard for English and German says to split tokens on hyphen, but this can lead to diminished performance. Consider the example of double barrel names such as Daniel Day-Lewis or hyphenated place names such as Bergen-Enkheim. It was found that splitting on hyphen dropped F1 score, so the hyphen splitting is mostly deactivated for named entity recognition. The only exceptions are the following key words: based, area, registered, headquartered, native, born, raised, backed, controlled, owned, resident, trained, educated. So Chicago-based WILL be split into Chicago - based to allow for the token Chicago to be recognized as a CITY.','split tokens on hyphen',0,'',''),(1498,'CoreNLP','A complication is that the UD 2.0 standard for English and German says to split tokens on hyphen, but this can lead to diminished performance. Consider the example of double barrel names such as Daniel Day-Lewis or hyphenated place names such as Bergen-Enkheim. It was found that splitting on hyphen dropped F1 score, so the hyphen splitting is mostly deactivated for named entity recognition. The only exceptions are the following key words: based, area, registered, headquartered, native, born, raised, backed, controlled, owned, resident, trained, educated. So Chicago-based WILL be split into Chicago - based to allow for the token Chicago to be recognized as a CITY.','deactivate hyphen splitting for named entity recognition',0,'',''),(1499,'CoreNLP','A complication is that the UD 2.0 standard for English and German says to split tokens on hyphen, but this can lead to diminished performance. Consider the example of double barrel names such as Daniel Day-Lewis or hyphenated place names such as Bergen-Enkheim. It was found that splitting on hyphen dropped F1 score, so the hyphen splitting is mostly deactivated for named entity recognition. The only exceptions are the following key words: based, area, registered, headquartered, native, born, raised, backed, controlled, owned, resident, trained, educated. So Chicago-based WILL be split into Chicago - based to allow for the token Chicago to be recognized as a CITY.','split chicago-based WILL into chicago',0,'',''),(1500,'CoreNLP','A complication is that the UD 2.0 standard for English and German says to split tokens on hyphen, but this can lead to diminished performance. Consider the example of double barrel names such as Daniel Day-Lewis or hyphenated place names such as Bergen-Enkheim. It was found that splitting on hyphen dropped F1 score, so the hyphen splitting is mostly deactivated for named entity recognition. The only exceptions are the following key words: based, area, registered, headquartered, native, born, raised, backed, controlled, owned, resident, trained, educated. So Chicago-based WILL be split into Chicago - based to allow for the token Chicago to be recognized as a CITY.','recognize  as CITY',0,'',''),(1501,'CoreNLP','The NERAnnotator by default takes in UD 2.0 tokens, and then merges all tokens that were originally joined by a hyphen in the text (except for cases like Chicago-based). The model is run on the modified tokens list, and the labels are finally applied to the original UD 2.0 tokens. This behavior can be turned off by setting ner.useNERSpecificTokenization to false.','set ner.useNERSpecificTokenization to false',0,'',''),(1502,'CoreNLP','Related to the tokenization change, French, German, and Spanish now require the use of the MWTAnnotator which splits some tokens into multiple words with rules and statistical models. For instance the French token “des” is sometimes split into the words “de” and “les”.','split tokens into multiple words',0,'',''),(1503,'CoreNLP','Related to the tokenization change, French, German, and Spanish now require the use of the MWTAnnotator which splits some tokens into multiple words with rules and statistical models. For instance the French token “des” is sometimes split into the words “de” and “les”.','split MWTAnnotator into multiple words',0,'',''),(1504,'CoreNLP','Related to the tokenization change, French, German, and Spanish now require the use of the MWTAnnotator which splits some tokens into multiple words with rules and statistical models. For instance the French token “des” is sometimes split into the words “de” and “les”.','split French token des into words',0,'',''),(1505,'CoreNLP','Related to the tokenization change, French, German, and Spanish now require the use of the MWTAnnotator which splits some tokens into multiple words with rules and statistical models. For instance the French token “des” is sometimes split into the words “de” and “les”.','split French token des for instance',0,'',''),(1506,'CoreNLP','Some multi-word token splitting for these languages used to occur in the tokenize annotator, but now this annotator focuses on creating tokens, and the mwt annotator is used to make token splitting decisions, sometimes via a dictionary and other times via a statistical model.','create tokens',1,'https://stanfordnlp.github.io/CoreNLP/migration.html','mwt-annotator-required-for-french-german-and-spanish'),(1507,'CoreNLP','The ner, coref, and quote annotators will run some of the annotators themselves as sub-annotators. This means for instance that the ner annotator will run a combination of CRF classifiers (adding ner tags to tokens), then the TokensRegex based regexner to produce fine-grained annotations (“LOCATION” -> “COUNTRY”), and then finally it will annotate the full entity mentions (“Joe”, “Smith” –> “Joe Smith”) with its internal entitymentions annotator.','produce fine-grained annotations',1,'https://stanfordnlp.github.io/CoreNLP/migration.html','several-annotators-have-been-enhanced-to-run-other-annotators'),(1508,'CoreNLP','If you wish to set parameters for the ner annotator’s internal regexner annotator set ner.fine.regexner properties. For instance:','set parameters for internal regexner annotator',0,'',''),(1509,'CoreNLP','If you wish to set parameters for the ner annotator’s internal regexner annotator set ner.fine.regexner properties. For instance:','set ner.fine.regexner properties',0,'',''),(1510,'CoreNLP','Likewise to set the ner annotator’s internal entitymentions annotator, set ner.entitymentions properties. For instance:','set internal entitymentions annotator',1,'https://stanfordnlp.github.io/CoreNLP/migration.html','several-annotators-have-been-enhanced-to-run-other-annotators'),(1511,'CoreNLP','Likewise to set the ner annotator’s internal entitymentions annotator, set ner.entitymentions properties. For instance:','set ner.entitymentions properties',1,'https://stanfordnlp.github.io/CoreNLP/migration.html','several-annotators-have-been-enhanced-to-run-other-annotators'),(1512,'CoreNLP','And for quote annotation, quote attribution can be deactivated with','deactivate quote attribution for quote annotation',1,'https://stanfordnlp.github.io/CoreNLP/migration.html','several-annotators-have-been-enhanced-to-run-other-annotators'),(1513,'CoreNLP','A variety of third-party groups have created extensions for Stanford CoreNLP.','create extensions for Stanford CoreNLP',0,'',''),(1514,'CoreNLP','In the table below we provide access to their work. By simply adding the jar for an entry to your classpath, you can begin using the extension.','provide access to work',1,'https://stanfordnlp.github.io/CoreNLP/model-zoo.html',''),(1515,'CoreNLP','In the table below we provide access to their work. By simply adding the jar for an entry to your classpath, you can begin using the extension.','add jar for entry',1,'https://stanfordnlp.github.io/CoreNLP/model-zoo.html',''),(1516,'CoreNLP','In the table below we provide access to their work. By simply adding the jar for an entry to your classpath, you can begin using the extension.','add jar to classpath',1,'https://stanfordnlp.github.io/CoreNLP/model-zoo.html',''),(1517,'CoreNLP','Multi Word Token Expansion is the process of splitting tokens into syntactic words which are used by downstream tasks such as part of speech tagging and dependency parsing. In CoreNLP, MWT expansion is only performed for French, German, and Spanish. The expansions are designed to be consistent with the UD 2.0 standard.','tag parsing',0,'',''),(1518,'CoreNLP','Multi Word Token Expansion is the process of splitting tokens into syntactic words which are used by downstream tasks such as part of speech tagging and dependency parsing. In CoreNLP, MWT expansion is only performed for French, German, and Spanish. The expansions are designed to be consistent with the UD 2.0 standard.','perform MWT expansion in CoreNLP',0,'',''),(1519,'CoreNLP','Multi Word Token Expansion is the process of splitting tokens into syntactic words which are used by downstream tasks such as part of speech tagging and dependency parsing. In CoreNLP, MWT expansion is only performed for French, German, and Spanish. The expansions are designed to be consistent with the UD 2.0 standard.','perform MWT expansion for french',0,'',''),(1520,'CoreNLP','Multi Word Token Expansion is the process of splitting tokens into syntactic words which are used by downstream tasks such as part of speech tagging and dependency parsing. In CoreNLP, MWT expansion is only performed for French, German, and Spanish. The expansions are designed to be consistent with the UD 2.0 standard.','perform MWT expansion for german',0,'',''),(1521,'CoreNLP','Multi Word Token Expansion is the process of splitting tokens into syntactic words which are used by downstream tasks such as part of speech tagging and dependency parsing. In CoreNLP, MWT expansion is only performed for French, German, and Spanish. The expansions are designed to be consistent with the UD 2.0 standard.','perform MWT expansion for spanish',0,'',''),(1522,'CoreNLP','Multi Word Token Expansion is the process of splitting tokens into syntactic words which are used by downstream tasks such as part of speech tagging and dependency parsing. In CoreNLP, MWT expansion is only performed for French, German, and Spanish. The expansions are designed to be consistent with the UD 2.0 standard.','design expansions',0,'',''),(1523,'CoreNLP','Each language has different rules for MWT expansion. For instance consider the Spanish sentence Pude haber querido escribirlo.. This sentence contains an example of an enclitic pronoun, which is split off from the verb by MWT expansion. So escribirlo is split into escribir and lo.','split escribirlo into escribir',0,'',''),(1524,'CoreNLP','Each language has different rules for MWT expansion. For instance consider the Spanish sentence Pude haber querido escribirlo.. This sentence contains an example of an enclitic pronoun, which is split off from the verb by MWT expansion. So escribirlo is split into escribir and lo.','split escribirlo into lo',0,'',''),(1525,'CoreNLP','In French, the word “des” is only split in certain circumstances. Thus, a statistical model is needed to make decisions on when to split “des” into “de” and “les”. First a part of speech tag model for MWT expansion is applied (mwt.pos.model). This model applies special tags to words that should be split. For French, it applies the tag “ADP_DET” to the word “des” in cases where “des” should be split. A corresponding dictionary is provided via mwt.statisticalMappingFile which maps word-tag pairs to splits. In the case of French, “des-ADP_DET” is mapped to “de,les”. Mapping files should consist of 2 tab separated columns. The first column contains the word and tag (e.g. “des-ADP_DET”), and the second column should consist of a comma separated list of multi word tokens (e.g. “de,les”).','split word des in french',1,'https://stanfordnlp.github.io/CoreNLP/mwt.html','statistical-multi-word-expansion'),(1526,'CoreNLP','In French, the word “des” is only split in certain circumstances. Thus, a statistical model is needed to make decisions on when to split “des” into “de” and “les”. First a part of speech tag model for MWT expansion is applied (mwt.pos.model). This model applies special tags to words that should be split. For French, it applies the tag “ADP_DET” to the word “des” in cases where “des” should be split. A corresponding dictionary is provided via mwt.statisticalMappingFile which maps word-tag pairs to splits. In the case of French, “des-ADP_DET” is mapped to “de,les”. Mapping files should consist of 2 tab separated columns. The first column contains the word and tag (e.g. “des-ADP_DET”), and the second column should consist of a comma separated list of multi word tokens (e.g. “de,les”).','split word des in certain circumstances',1,'https://stanfordnlp.github.io/CoreNLP/mwt.html','statistical-multi-word-expansion'),(1527,'CoreNLP','In French, the word “des” is only split in certain circumstances. Thus, a statistical model is needed to make decisions on when to split “des” into “de” and “les”. First a part of speech tag model for MWT expansion is applied (mwt.pos.model). This model applies special tags to words that should be split. For French, it applies the tag “ADP_DET” to the word “des” in cases where “des” should be split. A corresponding dictionary is provided via mwt.statisticalMappingFile which maps word-tag pairs to splits. In the case of French, “des-ADP_DET” is mapped to “de,les”. Mapping files should consist of 2 tab separated columns. The first column contains the word and tag (e.g. “des-ADP_DET”), and the second column should consist of a comma separated list of multi word tokens (e.g. “de,les”).','split words',1,'https://stanfordnlp.github.io/CoreNLP/mwt.html','statistical-multi-word-expansion'),(1528,'CoreNLP','In French, the word “des” is only split in certain circumstances. Thus, a statistical model is needed to make decisions on when to split “des” into “de” and “les”. First a part of speech tag model for MWT expansion is applied (mwt.pos.model). This model applies special tags to words that should be split. For French, it applies the tag “ADP_DET” to the word “des” in cases where “des” should be split. A corresponding dictionary is provided via mwt.statisticalMappingFile which maps word-tag pairs to splits. In the case of French, “des-ADP_DET” is mapped to “de,les”. Mapping files should consist of 2 tab separated columns. The first column contains the word and tag (e.g. “des-ADP_DET”), and the second column should consist of a comma separated list of multi word tokens (e.g. “de,les”).','provide corresponding dictionary via mwt.statisticalMappingFile',1,'https://stanfordnlp.github.io/CoreNLP/mwt.html','statistical-multi-word-expansion'),(1529,'CoreNLP','This command will take in the text of the file input.txt (assumed to be French in this example) and produce a human readable output of the sentences, with MWT expansion applied.','produce human readable output with MWT expansion',1,'https://stanfordnlp.github.io/CoreNLP/mwt.html','multi-word-token-expansion-from-the-command-line'),(1530,'CoreNLP','This command will take in the text of the file input.txt (assumed to be French in this example) and produce a human readable output of the sentences, with MWT expansion applied.','produce human readable output of sentences',1,'https://stanfordnlp.github.io/CoreNLP/mwt.html','multi-word-token-expansion-from-the-command-line'),(1531,'CoreNLP','This demo code will produce this output, which shows the enclitic pronoun being split from the verb:','produce output',1,'https://stanfordnlp.github.io/CoreNLP/mwt.html','multi-word-token-expansion-from-java'),(1532,'CoreNLP','This demo code will produce this output, which shows the enclitic pronoun being split from the verb:','show enclitic pronoun',1,'https://stanfordnlp.github.io/CoreNLP/mwt.html','multi-word-token-expansion-from-java'),(1533,'CoreNLP','This demo code will produce this output, which shows the enclitic pronoun being split from the verb:','show output',1,'https://stanfordnlp.github.io/CoreNLP/mwt.html','multi-word-token-expansion-from-java'),(1534,'CoreNLP','This demo code will produce this output, which shows the enclitic pronoun being split from the verb:','split  from verb',1,'https://stanfordnlp.github.io/CoreNLP/mwt.html','multi-word-token-expansion-from-java'),(1535,'CoreNLP','Recognizes named entities (person and company names, etc.) in text. Principally, this annotator uses one or more machine learning sequence models to label entities, but it may also call specialist rule-based components, such as for labeling and interpreting times and dates. Numerical entities that require normalization, e.g., dates, have their normalized value stored in NormalizedNamedEntityTagAnnotation. For more extensive support for rule-based NER, you may also want to look at the RegexNER annotator. The set of entities recognized is language-dependent, and the recognized set of entities is frequently more limited for other languages than what is described below for English. As the name “NERClassifierCombiner” implies, commonly this annotator will run several named entity recognizers and then combine their results but it can run just a single annotator or only rule-based quantity NER.','call specialist rule-based components',0,'',''),(1536,'CoreNLP','For English, by default, this annotator recognizes named (PERSON, LOCATION, ORGANIZATION, MISC), numerical (MONEY, NUMBER, ORDINAL, PERCENT), and temporal (DATE, TIME, DURATION, SET) entities (12 classes). Adding the regexner annotator and using the supplied RegexNER pattern files adds support for the fine-grained and additional entity classes EMAIL, URL, CITY, STATE_OR_PROVINCE, COUNTRY, NATIONALITY, RELIGION, (job) TITLE, IDEOLOGY, CRIMINAL_CHARGE, CAUSE_OF_DEATH, (Twitter, etc.) HANDLE (12 classes) for a total of 24 classes. Named entities are recognized using a combination of three CRF sequence taggers trained on various corpora, including CoNLL, ACE, MUC, and ERE corpora. Numerical entities are recognized using a rule-based system.','recognize temporal entities by default',0,'',''),(1537,'CoreNLP','For English, by default, this annotator recognizes named (PERSON, LOCATION, ORGANIZATION, MISC), numerical (MONEY, NUMBER, ORDINAL, PERCENT), and temporal (DATE, TIME, DURATION, SET) entities (12 classes). Adding the regexner annotator and using the supplied RegexNER pattern files adds support for the fine-grained and additional entity classes EMAIL, URL, CITY, STATE_OR_PROVINCE, COUNTRY, NATIONALITY, RELIGION, (job) TITLE, IDEOLOGY, CRIMINAL_CHARGE, CAUSE_OF_DEATH, (Twitter, etc.) HANDLE (12 classes) for a total of 24 classes. Named entities are recognized using a combination of three CRF sequence taggers trained on various corpora, including CoNLL, ACE, MUC, and ERE corpora. Numerical entities are recognized using a rule-based system.','recognize temporal entities for english',0,'',''),(1538,'CoreNLP','For English, by default, this annotator recognizes named (PERSON, LOCATION, ORGANIZATION, MISC), numerical (MONEY, NUMBER, ORDINAL, PERCENT), and temporal (DATE, TIME, DURATION, SET) entities (12 classes). Adding the regexner annotator and using the supplied RegexNER pattern files adds support for the fine-grained and additional entity classes EMAIL, URL, CITY, STATE_OR_PROVINCE, COUNTRY, NATIONALITY, RELIGION, (job) TITLE, IDEOLOGY, CRIMINAL_CHARGE, CAUSE_OF_DEATH, (Twitter, etc.) HANDLE (12 classes) for a total of 24 classes. Named entities are recognized using a combination of three CRF sequence taggers trained on various corpora, including CoNLL, ACE, MUC, and ERE corpora. Numerical entities are recognized using a rule-based system.','add regexner annotator',0,'',''),(1539,'CoreNLP','For English, by default, this annotator recognizes named (PERSON, LOCATION, ORGANIZATION, MISC), numerical (MONEY, NUMBER, ORDINAL, PERCENT), and temporal (DATE, TIME, DURATION, SET) entities (12 classes). Adding the regexner annotator and using the supplied RegexNER pattern files adds support for the fine-grained and additional entity classes EMAIL, URL, CITY, STATE_OR_PROVINCE, COUNTRY, NATIONALITY, RELIGION, (job) TITLE, IDEOLOGY, CRIMINAL_CHARGE, CAUSE_OF_DEATH, (Twitter, etc.) HANDLE (12 classes) for a total of 24 classes. Named entities are recognized using a combination of three CRF sequence taggers trained on various corpora, including CoNLL, ACE, MUC, and ERE corpora. Numerical entities are recognized using a rule-based system.','add support for additional entity classes',0,'',''),(1540,'CoreNLP','For English, by default, this annotator recognizes named (PERSON, LOCATION, ORGANIZATION, MISC), numerical (MONEY, NUMBER, ORDINAL, PERCENT), and temporal (DATE, TIME, DURATION, SET) entities (12 classes). Adding the regexner annotator and using the supplied RegexNER pattern files adds support for the fine-grained and additional entity classes EMAIL, URL, CITY, STATE_OR_PROVINCE, COUNTRY, NATIONALITY, RELIGION, (job) TITLE, IDEOLOGY, CRIMINAL_CHARGE, CAUSE_OF_DEATH, (Twitter, etc.) HANDLE (12 classes) for a total of 24 classes. Named entities are recognized using a combination of three CRF sequence taggers trained on various corpora, including CoNLL, ACE, MUC, and ERE corpora. Numerical entities are recognized using a rule-based system.','recognize named entities',0,'',''),(1541,'CoreNLP','For English, by default, this annotator recognizes named (PERSON, LOCATION, ORGANIZATION, MISC), numerical (MONEY, NUMBER, ORDINAL, PERCENT), and temporal (DATE, TIME, DURATION, SET) entities (12 classes). Adding the regexner annotator and using the supplied RegexNER pattern files adds support for the fine-grained and additional entity classes EMAIL, URL, CITY, STATE_OR_PROVINCE, COUNTRY, NATIONALITY, RELIGION, (job) TITLE, IDEOLOGY, CRIMINAL_CHARGE, CAUSE_OF_DEATH, (Twitter, etc.) HANDLE (12 classes) for a total of 24 classes. Named entities are recognized using a combination of three CRF sequence taggers trained on various corpora, including CoNLL, ACE, MUC, and ERE corpora. Numerical entities are recognized using a rule-based system.','recognize numerical entities',0,'',''),(1542,'CoreNLP','During this phase a series of trained CRF’s will be run on each sentence. These CRF’s are trained on large tagged data sets. They evaluate the entire sequence and pick the optimal tag sequence.','evaluate entire sequence',1,'https://stanfordnlp.github.io/CoreNLP/ner.html','statistical-models'),(1543,'CoreNLP','There are two options for how the models are combined. These are selected with the ner.combinationMode property.','select  with ner.combinationMode property',0,'',''),(1544,'CoreNLP','So for example, if the ner.combinationMode is set to NORMAL, only the 3-class model’s ORGANIZATION tags will be applied. If it is set to HIGH_RECALL, the 7-class and 4-class models’ ORGANIZATION tags will also be applied.','set ner.combinationMode to NORMAL',0,'',''),(1545,'CoreNLP','So for example, if the ner.combinationMode is set to NORMAL, only the 3-class model’s ORGANIZATION tags will be applied. If it is set to HIGH_RECALL, the 7-class and 4-class models’ ORGANIZATION tags will also be applied.','set  to HIGH_RECALL',0,'',''),(1546,'CoreNLP','If you do not want to run any statistical models, set ner.model to the empty string.','set ner.model to empty string',0,'',''),(1547,'CoreNLP','Next a series of rule based systems are run to recognize and tag numeric sequences and time related sequences.','recognize time related sequences',0,'',''),(1548,'CoreNLP','Next a series of rule based systems are run to recognize and tag numeric sequences and time related sequences.','recognize numeric sequences',0,'',''),(1549,'CoreNLP','Next a series of rule based systems are run to recognize and tag numeric sequences and time related sequences.','tag time related sequences',0,'',''),(1550,'CoreNLP','Next a series of rule based systems are run to recognize and tag numeric sequences and time related sequences.','tag numeric sequences',0,'',''),(1551,'CoreNLP','This phase runs by default, but can be deactivated by setting ner.applyNumericClassifiers to false.','set ner.applyNumericClassifiers to false',0,'',''),(1552,'CoreNLP','This phase runs by default, but can be deactivated by setting ner.applyNumericClassifiers to false.','deactivate phase',0,'',''),(1553,'CoreNLP','This produces tags such as NUMBER, ORDINAL, MONEY, DATE, and TIME','produce tags such_as NUMBER',0,'',''),(1554,'CoreNLP','SUTime (described in more detail below) is also used by default. You can deactivate this by setting ner.useSUTime to false.','deactivate  by setting',0,'',''),(1555,'CoreNLP','SUTime (described in more detail below) is also used by default. You can deactivate this by setting ner.useSUTime to false.','set ner.useSUTime to false',0,'',''),(1556,'CoreNLP','At this point, a series of rules used for the KBP 2017 competition will be run to create more fine-grained NER tags. These rules are applied using a TokensRegexNERAnnotator sub-annotator. That is the main NERCombinerAnnotator builds a TokensRegexNERAnnotator as a sub-annotator and runs it on all sentences as part of it’s entire tagging process. The purpose of these rules is give tokens more specific tags. So for instance California would be tagged as a STATE_OR_PROVINCE rather than just a LOCATION.','create more fine-grained NER tags',1,'https://stanfordnlp.github.io/CoreNLP/ner.html','fine-grained-ner'),(1557,'CoreNLP','At this point, a series of rules used for the KBP 2017 competition will be run to create more fine-grained NER tags. These rules are applied using a TokensRegexNERAnnotator sub-annotator. That is the main NERCombinerAnnotator builds a TokensRegexNERAnnotator as a sub-annotator and runs it on all sentences as part of it’s entire tagging process. The purpose of these rules is give tokens more specific tags. So for instance California would be tagged as a STATE_OR_PROVINCE rather than just a LOCATION.','build TokensRegexNERAnnotator as sub-annotator',1,'https://stanfordnlp.github.io/CoreNLP/ner.html','fine-grained-ner'),(1558,'CoreNLP','At this point, a series of rules used for the KBP 2017 competition will be run to create more fine-grained NER tags. These rules are applied using a TokensRegexNERAnnotator sub-annotator. That is the main NERCombinerAnnotator builds a TokensRegexNERAnnotator as a sub-annotator and runs it on all sentences as part of it’s entire tagging process. The purpose of these rules is give tokens more specific tags. So for instance California would be tagged as a STATE_OR_PROVINCE rather than just a LOCATION.','build main NERCombinerAnnotator as sub-annotator',1,'https://stanfordnlp.github.io/CoreNLP/ner.html','fine-grained-ner'),(1559,'CoreNLP','At this point, a series of rules used for the KBP 2017 competition will be run to create more fine-grained NER tags. These rules are applied using a TokensRegexNERAnnotator sub-annotator. That is the main NERCombinerAnnotator builds a TokensRegexNERAnnotator as a sub-annotator and runs it on all sentences as part of it’s entire tagging process. The purpose of these rules is give tokens more specific tags. So for instance California would be tagged as a STATE_OR_PROVINCE rather than just a LOCATION.','tag california as STATE_OR_PROVINCE',1,'https://stanfordnlp.github.io/CoreNLP/ner.html','fine-grained-ner'),(1560,'CoreNLP','At this point, a series of rules used for the KBP 2017 competition will be run to create more fine-grained NER tags. These rules are applied using a TokensRegexNERAnnotator sub-annotator. That is the main NERCombinerAnnotator builds a TokensRegexNERAnnotator as a sub-annotator and runs it on all sentences as part of it’s entire tagging process. The purpose of these rules is give tokens more specific tags. So for instance California would be tagged as a STATE_OR_PROVINCE rather than just a LOCATION.','tag california as LOCATION',1,'https://stanfordnlp.github.io/CoreNLP/ner.html','fine-grained-ner'),(1561,'CoreNLP','At this point, a series of rules used for the KBP 2017 competition will be run to create more fine-grained NER tags. These rules are applied using a TokensRegexNERAnnotator sub-annotator. That is the main NERCombinerAnnotator builds a TokensRegexNERAnnotator as a sub-annotator and runs it on all sentences as part of it’s entire tagging process. The purpose of these rules is give tokens more specific tags. So for instance California would be tagged as a STATE_OR_PROVINCE rather than just a LOCATION.','tag california for instance',1,'https://stanfordnlp.github.io/CoreNLP/ner.html','fine-grained-ner'),(1562,'CoreNLP','If you do not want to run the fine-grained rules, set ner.applyFineGrained to false.','set ner.applyFineGrained to false',0,'',''),(1563,'CoreNLP','Here is a breakdown of how to customize the fine-grained NER. The overall ner annotator creates a sub-annotator called ner.fine.regexner which is an instance of a TokensRegexNERAnnotator.','call ner.fine.regexner',0,'',''),(1564,'CoreNLP','The ner.fine.regexner.mapping property allows one to specify a set of rules files and additional properties for each rules file.','specify set of rules files',1,'https://stanfordnlp.github.io/CoreNLP/ner.html','customizing-the-fine-grained-ner'),(1565,'CoreNLP','The ner.fine.regexner.mapping property allows one to specify a set of rules files and additional properties for each rules file.','specify set for rules file',1,'https://stanfordnlp.github.io/CoreNLP/ner.html','customizing-the-fine-grained-ner'),(1566,'CoreNLP','The ner.fine.regexner.mapping property allows one to specify a set of rules files and additional properties for each rules file.','specify additional properties of rules files',1,'https://stanfordnlp.github.io/CoreNLP/ner.html','customizing-the-fine-grained-ner'),(1567,'CoreNLP','The ner.fine.regexner.mapping property allows one to specify a set of rules files and additional properties for each rules file.','specify additional properties for rules file',1,'https://stanfordnlp.github.io/CoreNLP/ner.html','customizing-the-fine-grained-ner'),(1568,'CoreNLP','while there are no options set for edu/stanford/nlp/models/kbp/english/gazetteers/regexner_cased.tab in this example.','set  for edu/stanford/nlp/models/kbp/english/gazetteers/regexner_cased.tab',0,'',''),(1569,'CoreNLP','If you want to set global settings that will apply for all rules files, remember to use ner.fine.regexner.ignorecase and ner.fine.regexner.validpospattern. If you are setting options for a specific rules file with the ner.fine.regexner.mapping option, follow the pattern from above.','set global settings',0,'',''),(1570,'CoreNLP','If you want to set global settings that will apply for all rules files, remember to use ner.fine.regexner.ignorecase and ner.fine.regexner.validpospattern. If you are setting options for a specific rules file with the ner.fine.regexner.mapping option, follow the pattern from above.','set options for specific rules file',0,'',''),(1571,'CoreNLP','After the fine-grained rules are run, there is also an option for a user to specify additional rules they would like to have run after the fine-grained NER phase.','specify additional rules',0,'',''),(1572,'CoreNLP','This second TokensRegexNERAnnotator sub-annotator has the name ner.additional.regexner and is customized in the same manner. This is for the case when users want to run their own rules after the standard rules we provide.','provide standard rules',1,'https://stanfordnlp.github.io/CoreNLP/ner.html','additional-tokensregexner-rules'),(1573,'CoreNLP','You could integrate this into the entire NER process by setting ner.additional.regexner.mapping to /path/to/sports_teams.rules','integrate  into entire NER process',0,'',''),(1574,'CoreNLP','You could integrate this into the entire NER process by setting ner.additional.regexner.mapping to /path/to/sports_teams.rules','integrate  by setting',0,'',''),(1575,'CoreNLP','You could integrate this into the entire NER process by setting ner.additional.regexner.mapping to /path/to/sports_teams.rules','set ner.additional.regexner.mapping to /path/to/sports_teams.rules',0,'',''),(1576,'CoreNLP','If you want to run a series of TokensRegex rules before entity building, you can also specify a set of TokensRegex rules. A TokensRegexAnnotator sub-annotator will be called. It has the name ner.additional.tokensregex.','specify set of TokensRegex rules',1,'https://stanfordnlp.github.io/CoreNLP/ner.html','additional-tokensregex-rules'),(1577,'CoreNLP','If you want to run a series of TokensRegex rules before entity building, you can also specify a set of TokensRegex rules. A TokensRegexAnnotator sub-annotator will be called. It has the name ner.additional.tokensregex.','call TokensRegexAnnotator sub-annotator',1,'https://stanfordnlp.github.io/CoreNLP/ner.html','additional-tokensregex-rules'),(1578,'CoreNLP','If a basic IO tagging scheme (example: PERSON, ORGANIZATION, LOCATION) is used, all contiguous sequences of tokens with the same tag will be marked as an entity.','mark contiguous sequences as entity',0,'',''),(1579,'CoreNLP','If a basic IO tagging scheme (example: PERSON, ORGANIZATION, LOCATION) is used, all contiguous sequences of tokens with the same tag will be marked as an entity.','mark contiguous sequences of tokens',0,'',''),(1580,'CoreNLP','All of our models and rule files use a basic tagging scheme, but you could create your own models and rules that use BIO.','create own models',0,'',''),(1581,'CoreNLP','All of our models and rule files use a basic tagging scheme, but you could create your own models and rules that use BIO.','create rules',0,'',''),(1582,'CoreNLP','For instance (Joe PERSON) (Smith PERSON) (Jane PERSON) (Smith PERSON) will create the entity Joe Smith Jane Smith.','create entity for instance',0,'',''),(1583,'CoreNLP','On the other hand (Joe B-PERSON) (Smith I-PERSON) (Jane B-PERSON) (Smith I-PERSON) will create two entities: Joe Smith and Jane Smith.','create entities on other hand',0,'',''),(1584,'CoreNLP','You can deactivate this with ner.buildEntityMentions being set to false.','deactivate  with ner.buildEntityMentions',0,'',''),(1585,'CoreNLP','You can deactivate this with ner.buildEntityMentions being set to false.','set  to false',0,'',''),(1586,'CoreNLP','At this point the NER process will be finished, having tagged tokens with NER tags and created entities.','tag tokens with NER tags',0,'',''),(1587,'CoreNLP','At this point the NER process will be finished, having tagged tokens with NER tags and created entities.','tag tokens with created entities',0,'',''),(1588,'CoreNLP','Stanford CoreNLP includes SUTime, Stanford’s temporal expression recognizer. SUTime is transparently called from the “ner” annotator, so no configuration is necessary. Furthermore, the “cleanxml” annotator can extract the reference date for a given XML document, so relative dates, e.g., “yesterday”, are transparently normalized with no configuration necessary.','call  from ner annotator',0,'',''),(1589,'CoreNLP','Stanford CoreNLP includes SUTime, Stanford’s temporal expression recognizer. SUTime is transparently called from the “ner” annotator, so no configuration is necessary. Furthermore, the “cleanxml” annotator can extract the reference date for a given XML document, so relative dates, e.g., “yesterday”, are transparently normalized with no configuration necessary.','extract reference date for given XML document',0,'',''),(1590,'CoreNLP','SUTime supports the same annotations as before, i.e., NamedEntityTagAnnotation is set with the label of the numeric entity (DATE, TIME, DURATION, MONEY, PERCENT, or NUMBER) and NormalizedNamedEntityTagAnnotation is set to the value of the normalized temporal expression.','support same annotations',0,'',''),(1591,'CoreNLP','SUTime supports the same annotations as before, i.e., NamedEntityTagAnnotation is set with the label of the numeric entity (DATE, TIME, DURATION, MONEY, PERCENT, or NUMBER) and NormalizedNamedEntityTagAnnotation is set to the value of the normalized temporal expression.','set NamedEntityTagAnnotation with label',0,'',''),(1592,'CoreNLP','SUTime supports the same annotations as before, i.e., NamedEntityTagAnnotation is set with the label of the numeric entity (DATE, TIME, DURATION, MONEY, PERCENT, or NUMBER) and NormalizedNamedEntityTagAnnotation is set to the value of the normalized temporal expression.','set NormalizedNamedEntityTagAnnotation to value',0,'',''),(1593,'CoreNLP','Also, SUTime sets the TimexAnnotation key to an edu.stanford.nlp.time.Timex object, which contains the complete list of TIMEX3 fields for the corresponding expressions, such as “val”, “alt_val”, “type”, “tid”. This might be useful to developers interested in recovering complete TIMEX3 expressions.','set TimexAnnotation key to edu.stanford.nlp.time.Timex object',0,'',''),(1594,'CoreNLP','Reference dates are by default extracted from the “datetime” and “date” tags in an xml document. To set a different set of tags to use, use the clean.datetags property. When using the API, reference dates can be added to an Annotation via edu.stanford.nlp.ling.CoreAnnotations.DocDateAnnotation, although note that when processing an xml document, the cleanxml annotator will overwrite the DocDateAnnotation if “datetime” or “date” are specified in the document.','extract  in xml document',0,'',''),(1595,'CoreNLP','Reference dates are by default extracted from the “datetime” and “date” tags in an xml document. To set a different set of tags to use, use the clean.datetags property. When using the API, reference dates can be added to an Annotation via edu.stanford.nlp.ling.CoreAnnotations.DocDateAnnotation, although note that when processing an xml document, the cleanxml annotator will overwrite the DocDateAnnotation if “datetime” or “date” are specified in the document.','extract  from datetime date tags',0,'',''),(1596,'CoreNLP','Reference dates are by default extracted from the “datetime” and “date” tags in an xml document. To set a different set of tags to use, use the clean.datetags property. When using the API, reference dates can be added to an Annotation via edu.stanford.nlp.ling.CoreAnnotations.DocDateAnnotation, although note that when processing an xml document, the cleanxml annotator will overwrite the DocDateAnnotation if “datetime” or “date” are specified in the document.','set different set of tags',0,'',''),(1597,'CoreNLP','Reference dates are by default extracted from the “datetime” and “date” tags in an xml document. To set a different set of tags to use, use the clean.datetags property. When using the API, reference dates can be added to an Annotation via edu.stanford.nlp.ling.CoreAnnotations.DocDateAnnotation, although note that when processing an xml document, the cleanxml annotator will overwrite the DocDateAnnotation if “datetime” or “date” are specified in the document.','overwrite DocDateAnnotation',0,'',''),(1598,'CoreNLP','Reference dates are by default extracted from the “datetime” and “date” tags in an xml document. To set a different set of tags to use, use the clean.datetags property. When using the API, reference dates can be added to an Annotation via edu.stanford.nlp.ling.CoreAnnotations.DocDateAnnotation, although note that when processing an xml document, the cleanxml annotator will overwrite the DocDateAnnotation if “datetime” or “date” are specified in the document.','add reference dates to annotation',0,'',''),(1599,'CoreNLP','Reference dates are by default extracted from the “datetime” and “date” tags in an xml document. To set a different set of tags to use, use the clean.datetags property. When using the API, reference dates can be added to an Annotation via edu.stanford.nlp.ling.CoreAnnotations.DocDateAnnotation, although note that when processing an xml document, the cleanxml annotator will overwrite the DocDateAnnotation if “datetime” or “date” are specified in the document.','specify datetime in document',0,'',''),(1600,'CoreNLP','Reference dates are by default extracted from the “datetime” and “date” tags in an xml document. To set a different set of tags to use, use the clean.datetags property. When using the API, reference dates can be added to an Annotation via edu.stanford.nlp.ling.CoreAnnotations.DocDateAnnotation, although note that when processing an xml document, the cleanxml annotator will overwrite the DocDateAnnotation if “datetime” or “date” are specified in the document.','specify date in document',0,'',''),(1601,'CoreNLP','The DocDateAnnotator provides a variety of options for setting the document date. The ner annotator will run this annotator as a sub-annotator. These can be specified by setting properties for the ner.docdate sub-annotator.','provide variety of options',0,'',''),(1602,'CoreNLP','The DocDateAnnotator provides a variety of options for setting the document date. The ner annotator will run this annotator as a sub-annotator. These can be specified by setting properties for the ner.docdate sub-annotator.','set document date',0,'',''),(1603,'CoreNLP','The DocDateAnnotator provides a variety of options for setting the document date. The ner annotator will run this annotator as a sub-annotator. These can be specified by setting properties for the ner.docdate sub-annotator.','set properties for ner.docdate sub-annotator',0,'',''),(1604,'CoreNLP','The following example shows how to access label confidences for tokens and entities. Each token stores the probability of its NER label given by the CRF that was used to assign the label in the CoreAnnotations.NamedEntityTagProbsAnnotation.class. Each entity mention contains the probability of the token with the lowest label probability in its span. For example if Los Angeles had the following probabilities:','access label confidences for tokens',1,'https://stanfordnlp.github.io/CoreNLP/ner.html','accessing-entity-confidences'),(1605,'CoreNLP','The following example shows how to access label confidences for tokens and entities. Each token stores the probability of its NER label given by the CRF that was used to assign the label in the CoreAnnotations.NamedEntityTagProbsAnnotation.class. Each entity mention contains the probability of the token with the lowest label probability in its span. For example if Los Angeles had the following probabilities:','access label confidences for entities',1,'https://stanfordnlp.github.io/CoreNLP/ner.html','accessing-entity-confidences'),(1606,'CoreNLP','The following example shows how to access label confidences for tokens and entities. Each token stores the probability of its NER label given by the CRF that was used to assign the label in the CoreAnnotations.NamedEntityTagProbsAnnotation.class. Each entity mention contains the probability of the token with the lowest label probability in its span. For example if Los Angeles had the following probabilities:','assign label in CoreAnnotations.NamedEntityTagProbsAnnotation.class',1,'https://stanfordnlp.github.io/CoreNLP/ner.html','accessing-entity-confidences'),(1607,'CoreNLP','the entity Los Angeles would be assigned the LOCATION tag with a confidence of .992.','assign LOCATION tag with confidence',0,'',''),(1608,'CoreNLP','the entity Los Angeles would be assigned the LOCATION tag with a confidence of .992.','assign entity los Angeles with confidence',0,'',''),(1609,'CoreNLP','Below is code for accessing these confidences.','access confidences',1,'https://stanfordnlp.github.io/CoreNLP/ner.html','accessing-entity-confidences'),(1610,'CoreNLP','It is possible to run Stanford CoreNLP with NER models that ignore capitalization. We have trained models like this for English. You can find details on the Caseless models page.','ignore capitalization',0,'',''),(1611,'CoreNLP','It is possible to run Stanford CoreNLP with NER models that ignore capitalization. We have trained models like this for English. You can find details on the Caseless models page.','ignore NER models',0,'',''),(1612,'CoreNLP','SUTime rules can be changed by modifying its included TokensRegex rule files. Changing other rule-based components (money, etc.) requires changes to the Java source code.','modify included TokensRegex rule files',0,'',''),(1613,'CoreNLP','SUTime rules can be changed by modifying its included TokensRegex rule files. Changing other rule-based components (money, etc.) requires changes to the Java source code.','change SUTime rules',0,'',''),(1614,'CoreNLP','SUTime rules can be changed by modifying its included TokensRegex rule files. Changing other rule-based components (money, etc.) requires changes to the Java source code.','change other rule-based components',0,'',''),(1615,'CoreNLP','Users can add custom annotators to StanfordCoreNLP.','add custom annotators to StanfordCoreNLP',1,'https://stanfordnlp.github.io/CoreNLP/new_annotator.html',''),(1616,'CoreNLP','Then produce a properties file which allows Stanford CoreNLP to use your custom annotator:','produce properties',1,'https://stanfordnlp.github.io/CoreNLP/new_annotator.html',''),(1617,'CoreNLP','The Open Information Extraction (OpenIE) annotator extracts open-domain relation triples, representing a subject, a relation, and the object of the relation. For example, born-in(Barack Obama, Hawaii). This is useful for (1) relation extraction tasks where there is limited or no training data, and it is easy to extract the information required from such open domain triples; and, (2) when speed is essential. The system can process around 100 sentences per second per CPU core. The Collection of extracted relation triples are stored under the RelationTriplesAnnotation key of a CoreMap (i.e., sentence). The OpenIE annotator (openie) requires the natural logic annotation (natlog).','extract open-domain relation triples',0,'',''),(1618,'CoreNLP','The Open Information Extraction (OpenIE) annotator extracts open-domain relation triples, representing a subject, a relation, and the object of the relation. For example, born-in(Barack Obama, Hawaii). This is useful for (1) relation extraction tasks where there is limited or no training data, and it is easy to extract the information required from such open domain triples; and, (2) when speed is essential. The system can process around 100 sentences per second per CPU core. The Collection of extracted relation triples are stored under the RelationTriplesAnnotation key of a CoreMap (i.e., sentence). The OpenIE annotator (openie) requires the natural logic annotation (natlog).','extract information',0,'',''),(1619,'CoreNLP','In addition to extracting relation triples, the annotator produces a number of sentence fragments corresponding to entailed fragments from the given original sentence. These are stored on the EntailedSentencesAnnotation key of a CoreMap (i.e., sentence).','extract relation triples',0,'',''),(1620,'CoreNLP','In addition to extracting relation triples, the annotator produces a number of sentence fragments corresponding to entailed fragments from the given original sentence. These are stored on the EntailedSentencesAnnotation key of a CoreMap (i.e., sentence).','produce  in_addition_to extracting',0,'',''),(1621,'CoreNLP','All option are specified as Properties. The value of a property is always a String. The type referred to here is how the String will be interpreted/parsed.','specify option as properties',0,'',''),(1622,'CoreNLP','The final group of options for specifying models are provided to fine-tune the inner workings of the OpenIE system. These should be changed only in very rare situations; for example, if you are developing extensions to the system itself.','specify models',0,'',''),(1623,'CoreNLP','The final group of options for specifying models are provided to fine-tune the inner workings of the OpenIE system. These should be changed only in very rare situations; for example, if you are developing extensions to the system itself.','provide final group of options',0,'',''),(1624,'CoreNLP','The final group of options for specifying models are provided to fine-tune the inner workings of the OpenIE system. These should be changed only in very rare situations; for example, if you are developing extensions to the system itself.','develop extensions to system',0,'',''),(1625,'CoreNLP','The final group of options for specifying models are provided to fine-tune the inner workings of the OpenIE system. These should be changed only in very rare situations; for example, if you are developing extensions to the system itself.','change  in rare situations',0,'',''),(1626,'CoreNLP','In addition, the program can be run on a collection of files either by passing the files directly as command-line arguments:','pass files as command-line arguments',1,'https://stanfordnlp.github.io/CoreNLP/openie.html','command-line'),(1627,'CoreNLP','or by setting the -filelist argument to a file containing a list of files to annotate, one per line:','set filelist argument to file',1,'https://stanfordnlp.github.io/CoreNLP/openie.html','command-line'),(1628,'CoreNLP','Relation triples can be accessed through the CoreNLP API using the standard annotation pipeline. An example class which does this is given below:','access relation triples through CoreNLP API',1,'https://stanfordnlp.github.io/CoreNLP/openie.html','api'),(1629,'CoreNLP','Note on running the CoreNLP server under docker: The container’s port 9000 has to be published to the host. For example, give a command like: docker run -p 9000:9000 --name coreNLP --rm -i -t motiz88/corenlp. If, when going to localhost:9000/, you see the error This site can’t be reached. localhost refused to connect, then this is what you failed to do!','reach site',0,'',''),(1630,'CoreNLP','Note on running the CoreNLP server under docker: The container’s port 9000 has to be published to the host. For example, give a command like: docker run -p 9000:9000 --name coreNLP --rm -i -t motiz88/corenlp. If, when going to localhost:9000/, you see the error This site can’t be reached. localhost refused to connect, then this is what you failed to do!','reach error',0,'',''),(1631,'CoreNLP','And there are many others – it’s not so hard to build a dockerfile. Here are a few more:','build dockerfile',0,'',''),(1632,'CoreNLP','We are actively developing a Python package called Stanza, with state-of-the-art NLP performance enabled by deep learning. Besides, this package also includes an API for starting and making requests to a Stanford CoreNLP server. It is the recommended way to use Stanford CoreNLP in Python.','develop Python package',0,'',''),(1633,'CoreNLP','We are actively developing a Python package called Stanza, with state-of-the-art NLP performance enabled by deep learning. Besides, this package also includes an API for starting and making requests to a Stanford CoreNLP server. It is the recommended way to use Stanford CoreNLP in Python.','call stanza with state-of-the-art NLP performance',0,'',''),(1634,'CoreNLP','These packages use the Stanford CoreNLP server that we’ve developed over the last couple of years.','develop  over last couple',0,'',''),(1635,'CoreNLP','CoreNLP wrapper for Apache Spark by Xiangrui Meng of Databricks. Last we checked it was at version 0.41 supporting version 3.9.1 of CoreNLP.','support version 3.9.1 of CoreNLP',0,'',''),(1636,'CoreNLP','The parser code is dual licensed (in a similar manner to MySQL, etc.). Open source licensing is under the full GPL, which allows many free uses. For distributors of proprietary software, commercial licensing is available. (Fine print: The traditional (dynamic programmed) Stanford Parser does part-of-speech tagging as it works, but the newer constituency and neural network dependency shift-reduce parsers require pre-tagged input. For convenience, we include the part-of-speech tagger code, but not models with the parser download. However, if you want to use these parsers under a commercial license, then you need a license to both the Stanford Parser and the Stanford POS tagger. Or you can get the whole bundle of Stanford CoreNLP.) If you don’t need a commercial license, but would like to support maintenance of these tools, we welcome gift funding: use this form and write “Stanford NLP Group open source software” in the Special Instructions.','support maintenance of tools',0,'',''),(1637,'CoreNLP','Provides full syntactic analysis, minimally a constituency (phrase-structure tree) parse of sentences. If a rule-based conversion from constituency parses to dependency parses is available (this is currently the case for English and Chinese, only), then a dependency representation is also generated using this conversion. The constituent-based output is saved in TreeAnnotation. We generate three dependency-based outputs, as follows: basic dependencies, saved in BasicDependenciesAnnotation; enhanced dependencies saved in EnhancedDependenciesAnnotation; and enhanced++ dependencies in EnhancedPlusPlusDependenciesAnnotation. Most users of our parser will prefer the latter representation. Constituency parsers internally generate binary parse trees, which can also be saved.','provide full syntactic analysis',0,'',''),(1638,'CoreNLP','Provides full syntactic analysis, minimally a constituency (phrase-structure tree) parse of sentences. If a rule-based conversion from constituency parses to dependency parses is available (this is currently the case for English and Chinese, only), then a dependency representation is also generated using this conversion. The constituent-based output is saved in TreeAnnotation. We generate three dependency-based outputs, as follows: basic dependencies, saved in BasicDependenciesAnnotation; enhanced dependencies saved in EnhancedDependenciesAnnotation; and enhanced++ dependencies in EnhancedPlusPlusDependenciesAnnotation. Most users of our parser will prefer the latter representation. Constituency parsers internally generate binary parse trees, which can also be saved.','save constituent-based output in TreeAnnotation',0,'',''),(1639,'CoreNLP','Provides full syntactic analysis, minimally a constituency (phrase-structure tree) parse of sentences. If a rule-based conversion from constituency parses to dependency parses is available (this is currently the case for English and Chinese, only), then a dependency representation is also generated using this conversion. The constituent-based output is saved in TreeAnnotation. We generate three dependency-based outputs, as follows: basic dependencies, saved in BasicDependenciesAnnotation; enhanced dependencies saved in EnhancedDependenciesAnnotation; and enhanced++ dependencies in EnhancedPlusPlusDependenciesAnnotation. Most users of our parser will prefer the latter representation. Constituency parsers internally generate binary parse trees, which can also be saved.','save  in basicdependenciesannotation',0,'',''),(1640,'CoreNLP','Provides full syntactic analysis, minimally a constituency (phrase-structure tree) parse of sentences. If a rule-based conversion from constituency parses to dependency parses is available (this is currently the case for English and Chinese, only), then a dependency representation is also generated using this conversion. The constituent-based output is saved in TreeAnnotation. We generate three dependency-based outputs, as follows: basic dependencies, saved in BasicDependenciesAnnotation; enhanced dependencies saved in EnhancedDependenciesAnnotation; and enhanced++ dependencies in EnhancedPlusPlusDependenciesAnnotation. Most users of our parser will prefer the latter representation. Constituency parsers internally generate binary parse trees, which can also be saved.','save  in enhanceddependenciesannotation',0,'',''),(1641,'CoreNLP','Provides full syntactic analysis, minimally a constituency (phrase-structure tree) parse of sentences. If a rule-based conversion from constituency parses to dependency parses is available (this is currently the case for English and Chinese, only), then a dependency representation is also generated using this conversion. The constituent-based output is saved in TreeAnnotation. We generate three dependency-based outputs, as follows: basic dependencies, saved in BasicDependenciesAnnotation; enhanced dependencies saved in EnhancedDependenciesAnnotation; and enhanced++ dependencies in EnhancedPlusPlusDependenciesAnnotation. Most users of our parser will prefer the latter representation. Constituency parsers internally generate binary parse trees, which can also be saved.','save parse trees',0,'',''),(1642,'CoreNLP','Note: The values of all options, in a Properties object or on the command-line, are of type String. The listed type says what kinds of values are appropriate and hence how the String will be parsed.','parse String',0,'',''),(1643,'CoreNLP','It is possible to run StanfordCoreNLP with a parser model that ignores capitalization. We have trained models like this for English. You can find details on the Caseless models page.','ignore capitalization',0,'',''),(1644,'CoreNLP','It is possible to run StanfordCoreNLP with a parser model that ignores capitalization. We have trained models like this for English. You can find details on the Caseless models page.','ignore parser model',0,'',''),(1645,'CoreNLP','All of our parsers make use of parts of speech. Some of the models (e.g., neural dependency parser and shift-reduce parser) require an external PoS tagger; you must specify the pos annotator. Other parsers, such as the PCFG and Factored parsers can either do their own PoS tagging or use an external PoS tagger as a preprocessor. If you want to use a parser as the PoS tagger, make sure you do not include pos in the list of annotators and position the annotator parse prior to any other annotator that requires part-of-speech information (such as lemma):','specify pos annotator',1,'https://stanfordnlp.github.io/CoreNLP/parse.html','pos-tagging'),(1646,'CoreNLP','For more details on the original parsers, please see this page. There is also a page on the shift reduce parser. For more details about Stanford dependencies, please refer to this page. A separate site documents Universal Dependencies.','document universal Dependencies',0,'',''),(1647,'CoreNLP','CoreNLP implements an annotation pipeline. An Annotation object is used that stores analyses of a piece of text. It is a Map. Initially, the text of a document is added to the Annotation as its only contents. Then, an AnnotationPipeline is run on the Annotation. An AnnotationPipeline is essentially a List of Annotators, each of which is run in turn. (And an AnnotationPipeline is itself an Annotator, so you can actually nest AnnotationPipelines inside each other.) Each Annotator reads the value of one or more keys from the Annotation, does some natural language analysis, and then writes the results back to the Annotation. Typically, each Annotator stores its analyses under different keys, so that the information stored in an Annotation is cumulative rather than things being overwritten. The overall picture is given in this picture.','add text as only contents',0,'',''),(1648,'CoreNLP','CoreNLP implements an annotation pipeline. An Annotation object is used that stores analyses of a piece of text. It is a Map. Initially, the text of a document is added to the Annotation as its only contents. Then, an AnnotationPipeline is run on the Annotation. An AnnotationPipeline is essentially a List of Annotators, each of which is run in turn. (And an AnnotationPipeline is itself an Annotator, so you can actually nest AnnotationPipelines inside each other.) Each Annotator reads the value of one or more keys from the Annotation, does some natural language analysis, and then writes the results back to the Annotation. Typically, each Annotator stores its analyses under different keys, so that the information stored in an Annotation is cumulative rather than things being overwritten. The overall picture is given in this picture.','add text of document',0,'',''),(1649,'CoreNLP','CoreNLP implements an annotation pipeline. An Annotation object is used that stores analyses of a piece of text. It is a Map. Initially, the text of a document is added to the Annotation as its only contents. Then, an AnnotationPipeline is run on the Annotation. An AnnotationPipeline is essentially a List of Annotators, each of which is run in turn. (And an AnnotationPipeline is itself an Annotator, so you can actually nest AnnotationPipelines inside each other.) Each Annotator reads the value of one or more keys from the Annotation, does some natural language analysis, and then writes the results back to the Annotation. Typically, each Annotator stores its analyses under different keys, so that the information stored in an Annotation is cumulative rather than things being overwritten. The overall picture is given in this picture.','add text to annotation',0,'',''),(1650,'CoreNLP','Around this basic skeleton, StanfordCoreNLP adds a lot of stuff, for processing options, caching Annotators, writing output in different formats, and all the other modcons of life. Normally, this stuff is convenient to have. However, if it is getting in your way, you can actually fairly easily make your own AnnotationPipeline using either or both the various Annotators provided with CoreNLP or additional implementations of Annotator that you write. In Java code, creating an AnnotationPipeline looks something like this:','add lot of stuff',1,'https://stanfordnlp.github.io/CoreNLP/pipelines.html','annotations-and-annotators'),(1651,'CoreNLP','Around this basic skeleton, StanfordCoreNLP adds a lot of stuff, for processing options, caching Annotators, writing output in different formats, and all the other modcons of life. Normally, this stuff is convenient to have. However, if it is getting in your way, you can actually fairly easily make your own AnnotationPipeline using either or both the various Annotators provided with CoreNLP or additional implementations of Annotator that you write. In Java code, creating an AnnotationPipeline looks something like this:','add lot for processing options',1,'https://stanfordnlp.github.io/CoreNLP/pipelines.html','annotations-and-annotators'),(1652,'CoreNLP','Around this basic skeleton, StanfordCoreNLP adds a lot of stuff, for processing options, caching Annotators, writing output in different formats, and all the other modcons of life. Normally, this stuff is convenient to have. However, if it is getting in your way, you can actually fairly easily make your own AnnotationPipeline using either or both the various Annotators provided with CoreNLP or additional implementations of Annotator that you write. In Java code, creating an AnnotationPipeline looks something like this:','add lot around basic skeleton',1,'https://stanfordnlp.github.io/CoreNLP/pipelines.html','annotations-and-annotators'),(1653,'CoreNLP','Around this basic skeleton, StanfordCoreNLP adds a lot of stuff, for processing options, caching Annotators, writing output in different formats, and all the other modcons of life. Normally, this stuff is convenient to have. However, if it is getting in your way, you can actually fairly easily make your own AnnotationPipeline using either or both the various Annotators provided with CoreNLP or additional implementations of Annotator that you write. In Java code, creating an AnnotationPipeline looks something like this:','cache annotator s',1,'https://stanfordnlp.github.io/CoreNLP/pipelines.html','annotations-and-annotators'),(1654,'CoreNLP','Around this basic skeleton, StanfordCoreNLP adds a lot of stuff, for processing options, caching Annotators, writing output in different formats, and all the other modcons of life. Normally, this stuff is convenient to have. However, if it is getting in your way, you can actually fairly easily make your own AnnotationPipeline using either or both the various Annotators provided with CoreNLP or additional implementations of Annotator that you write. In Java code, creating an AnnotationPipeline looks something like this:','get  in way',1,'https://stanfordnlp.github.io/CoreNLP/pipelines.html','annotations-and-annotators'),(1655,'CoreNLP','Around this basic skeleton, StanfordCoreNLP adds a lot of stuff, for processing options, caching Annotators, writing output in different formats, and all the other modcons of life. Normally, this stuff is convenient to have. However, if it is getting in your way, you can actually fairly easily make your own AnnotationPipeline using either or both the various Annotators provided with CoreNLP or additional implementations of Annotator that you write. In Java code, creating an AnnotationPipeline looks something like this:','provide various annotator with CoreNLP additional implementations',1,'https://stanfordnlp.github.io/CoreNLP/pipelines.html','annotations-and-annotators'),(1656,'CoreNLP','With a custom analysis pipeline, only the first method is used. The other two methods are used in StanfordCoreNLP to check for dependencies between Annotators.','check  for dependencies',0,'',''),(1657,'CoreNLP','A new thing provided with v.3.9 of CoreNLP is a default WebServiceAnnotator. This is an abstract implementation of an Annotator that makes it relatively easy to tie external webservices into a CoreNLP AnnotationPipeline. You simply have to provide a class that extends this class and which specifies three methods which say how to call your webservice, how to check if it’s running, and (optionally) how to start the webservice.','provide  with v.3.9',0,'',''),(1658,'CoreNLP','A new thing provided with v.3.9 of CoreNLP is a default WebServiceAnnotator. This is an abstract implementation of an Annotator that makes it relatively easy to tie external webservices into a CoreNLP AnnotationPipeline. You simply have to provide a class that extends this class and which specifies three methods which say how to call your webservice, how to check if it’s running, and (optionally) how to start the webservice.','provide class',0,'',''),(1659,'CoreNLP','A new thing provided with v.3.9 of CoreNLP is a default WebServiceAnnotator. This is an abstract implementation of an Annotator that makes it relatively easy to tie external webservices into a CoreNLP AnnotationPipeline. You simply have to provide a class that extends this class and which specifies three methods which say how to call your webservice, how to check if it’s running, and (optionally) how to start the webservice.','specify methods',0,'',''),(1660,'CoreNLP','A new thing provided with v.3.9 of CoreNLP is a default WebServiceAnnotator. This is an abstract implementation of an Annotator that makes it relatively easy to tie external webservices into a CoreNLP AnnotationPipeline. You simply have to provide a class that extends this class and which specifies three methods which say how to call your webservice, how to check if it’s running, and (optionally) how to start the webservice.','call webservice',0,'',''),(1661,'CoreNLP','Pipelines are constructed with Properties objects which provide specifications for what annotators to run and how to customize the annotators.','provide specifications',0,'',''),(1662,'CoreNLP','Pipelines are constructed with Properties objects which provide specifications for what annotators to run and how to customize the annotators.','provide Properties objects',0,'',''),(1663,'CoreNLP','You can customize your pipeline by providing properties in a properties file.','provide properties in properties file',1,'https://stanfordnlp.github.io/CoreNLP/pipeline.html','running-a-pipeline-from-the-command-line'),(1664,'CoreNLP','Of course all of those properties could be specified at the command line as well:','specify properties at command line',1,'https://stanfordnlp.github.io/CoreNLP/pipeline.html','running-a-pipeline-from-the-command-line'),(1665,'CoreNLP','If you want to run a non-English language pipeline, you can just specify the name of one of the CoreNLP supported languages:','specify name of CoreNLP',1,'https://stanfordnlp.github.io/CoreNLP/pipeline.html','running-a-pipeline-from-the-command-line'),(1666,'CoreNLP','If you want to run a non-English language pipeline, you can just specify the name of one of the CoreNLP supported languages:','support languages',1,'https://stanfordnlp.github.io/CoreNLP/pipeline.html','running-a-pipeline-from-the-command-line'),(1667,'CoreNLP','To customize pipelines in Java, add properties to the Properties object in the same way the annotators property is set in the code example.','add properties to Properties object',0,'',''),(1668,'CoreNLP','To customize pipelines in Java, add properties to the Properties object in the same way the annotators property is set in the code example.','set annotators property',0,'',''),(1669,'CoreNLP','Part of speech tagging assigns part of speech labels to tokens, such as whether they are verbs or nouns. Every token in a sentence is applied a tag. For instance, in the sentence Marie was born in Paris. the word Marie is assigned the tag NNP.','assign part of speech labels',0,'',''),(1670,'CoreNLP','Part of speech tagging assigns part of speech labels to tokens, such as whether they are verbs or nouns. Every token in a sentence is applied a tag. For instance, in the sentence Marie was born in Paris. the word Marie is assigned the tag NNP.','assign part to tokens',0,'',''),(1671,'CoreNLP','Part of speech tagging assigns part of speech labels to tokens, such as whether they are verbs or nouns. Every token in a sentence is applied a tag. For instance, in the sentence Marie was born in Paris. the word Marie is assigned the tag NNP.','assign part such_as verbs',0,'',''),(1672,'CoreNLP','Part of speech tagging assigns part of speech labels to tokens, such as whether they are verbs or nouns. Every token in a sentence is applied a tag. For instance, in the sentence Marie was born in Paris. the word Marie is assigned the tag NNP.','assign part such_as nouns',0,'',''),(1673,'CoreNLP','Part of speech tagging assigns part of speech labels to tokens, such as whether they are verbs or nouns. Every token in a sentence is applied a tag. For instance, in the sentence Marie was born in Paris. the word Marie is assigned the tag NNP.','assign tag NNP',0,'',''),(1674,'CoreNLP','Part of speech tagging assigns part of speech labels to tokens, such as whether they are verbs or nouns. Every token in a sentence is applied a tag. For instance, in the sentence Marie was born in Paris. the word Marie is assigned the tag NNP.','assign word marie',0,'',''),(1675,'CoreNLP','CoreNLP dependency parser models are trained with a PyTorch system for speed considerations. The PyTorch models can be converted to the format CoreNLP’s dependency parser expects.','convert PyTorch models to format',0,'',''),(1676,'CoreNLP','Note that the above command will automatically tag the input data with the CoreNLP tagger. Thus you need to have CoreNLP and the Italian models (for this example) in your CLASSPATH, and you need the latest version of Stanza installed.','tag input data with CoreNLP tagger',0,'',''),(1677,'CoreNLP','After the model is trained, it can be converted to a format usable by CoreNLP:','convert  to format usable',1,'https://stanfordnlp.github.io/CoreNLP/pytorch-depparse.html','example-usage'),(1678,'CoreNLP','This will save a CoreNLP useable model at /path/to/italian-corenlp-parser.txt.','save CoreNLP useable model at /path/to/italian-corenlp-parser.txt',0,'',''),(1679,'CoreNLP','Deterministically picks out quotes from a text. All top-level quotes, are supplied by the top level annotation for a text. If a QuotationAnnotation corresponds to a quote that contains embedded quotes, these quotes will appear as embedded QuotationAnnotations that can be accessed from the QuotationAnnotation that they are embedded in. The QuoteAnnotator can handle multi-line and cross-paragraph quotes, but any embedded quotes must be delimited by a different kind of quotation mark than its parents.','access embedded QuotationAnnotations from QuotationAnnotation',0,'',''),(1680,'CoreNLP','Deterministically picks out quotes from a text. All top-level quotes, are supplied by the top level annotation for a text. If a QuotationAnnotation corresponds to a quote that contains embedded quotes, these quotes will appear as embedded QuotationAnnotations that can be accessed from the QuotationAnnotation that they are embedded in. The QuoteAnnotator can handle multi-line and cross-paragraph quotes, but any embedded quotes must be delimited by a different kind of quotation mark than its parents.','handle multi-line cross-paragraph quotes',0,'',''),(1681,'CoreNLP','This can be deactivated by setting the quote.attributeQuotes property to false.','set quote.attributeQuotes property to false',0,'',''),(1682,'CoreNLP','You should get this output for the quote in the text:','get output for quote',1,'https://stanfordnlp.github.io/CoreNLP/quote.html','sample-command-line'),(1683,'CoreNLP','If you didn’t want to run quote attribution, you would add -quote.attributeQuotes false to your command.','add -quote.attributeQuotes false to command',0,'',''),(1684,'CoreNLP','You can use interactive mode with either StanfordCoreNLP or the combination of running StanfordCoreNLPServer and StanfordCoreNLPClient. You can specify whatever annotators and other properties that you want.','specify other properties',0,'',''),(1685,'CoreNLP','If you do not specify any flag that directs CoreNLP to process text from a particular file, then after the pipeline is loaded, you will be placed into an interactive loop. (That is, if you don’t specify either -file or -filelist.)','load pipeline',1,'https://stanfordnlp.github.io/CoreNLP/repl.html','built-in-interactive-mode'),(1686,'CoreNLP','StanfordCoreNLP includes the sentiment tool and various programs which support it. The model can be used to analyze text as part of StanfordCoreNLP by adding “sentiment” to the list of annotators. There is also command line support and model training support.','support various programs',0,'',''),(1687,'CoreNLP','StanfordCoreNLP includes the sentiment tool and various programs which support it. The model can be used to analyze text as part of StanfordCoreNLP by adding “sentiment” to the list of annotators. There is also command line support and model training support.','add sentiment to list',0,'',''),(1688,'CoreNLP','In addition to the fully-featured annotator pipeline interface to CoreNLP, Stanford provides a simple API for users who do not need a lot of customization. The intended audience of this package is users of CoreNLP who want “import nlp” to work as fast and easily as possible, and do not care about the details of the behaviors of the algorithms.','provide simple API for users',1,'https://stanfordnlp.github.io/CoreNLP/simple.html','simple-corenlp'),(1689,'CoreNLP','In addition to the fully-featured annotator pipeline interface to CoreNLP, Stanford provides a simple API for users who do not need a lot of customization. The intended audience of this package is users of CoreNLP who want “import nlp” to work as fast and easily as possible, and do not care about the details of the behaviors of the algorithms.','provide simple API in_addition_to fully-featured annotator pipeline interface',1,'https://stanfordnlp.github.io/CoreNLP/simple.html','simple-corenlp'),(1690,'CoreNLP','This interface offers a number of advantages (and a few disadvantages – see below) over the default annotator pipeline:','offer number of advantages',0,'',''),(1691,'CoreNLP','Lazy Computation Annotations are run as needed only when requested. This allows you to “change your mind” later in a program and request new annotations.','change mind in program',0,'',''),(1692,'CoreNLP','Lazy Computation Annotations are run as needed only when requested. This allows you to “change your mind” later in a program and request new annotations.','request new annotations',0,'',''),(1693,'CoreNLP','No NullPointerExceptions Lazy computation allows us to ensure that no function will ever return null. Items which may not exist are wrapped inside of an Optional to clearly mark that they may be empty.','return null',0,'',''),(1694,'CoreNLP','No NullPointerExceptions Lazy computation allows us to ensure that no function will ever return null. Items which may not exist are wrapped inside of an Optional to clearly mark that they may be empty.','wrap items inside_of optional',0,'',''),(1695,'CoreNLP','Less Customizability Although the ability to pass properties to annotators is supported, it is significantly more clunky than the annotation pipeline interface, and is generally discouraged.','pass properties to annotators',0,'',''),(1696,'CoreNLP','Less Customizability Although the ability to pass properties to annotators is supported, it is significantly more clunky than the annotation pipeline interface, and is generally discouraged.','support ability',0,'',''),(1697,'CoreNLP','Possible Nondeterminism There is no guarantee that the same algorithm will be used to compute the requested function on each invocation. For example, if a dependency parse is requested, followed by a constituency parse, we will compute the dependency parse with the Neural Dependency Parser, and then use the Stanford Parser for the constituency parse. If, however, you request the constituency parse before the dependency parse, we will use the Stanford Parser for both.','compute requested function on invocation',0,'',''),(1698,'CoreNLP','Possible Nondeterminism There is no guarantee that the same algorithm will be used to compute the requested function on each invocation. For example, if a dependency parse is requested, followed by a constituency parse, we will compute the dependency parse with the Neural Dependency Parser, and then use the Stanford Parser for the constituency parse. If, however, you request the constituency parse before the dependency parse, we will use the Stanford Parser for both.','compute dependency parse with neural Dependency parser',0,'',''),(1699,'CoreNLP','Possible Nondeterminism There is no guarantee that the same algorithm will be used to compute the requested function on each invocation. For example, if a dependency parse is requested, followed by a constituency parse, we will compute the dependency parse with the Neural Dependency Parser, and then use the Stanford Parser for the constituency parse. If, however, you request the constituency parse before the dependency parse, we will use the Stanford Parser for both.','request dependency parse',0,'',''),(1700,'CoreNLP','Possible Nondeterminism There is no guarantee that the same algorithm will be used to compute the requested function on each invocation. For example, if a dependency parse is requested, followed by a constituency parse, we will compute the dependency parse with the Neural Dependency Parser, and then use the Stanford Parser for the constituency parse. If, however, you request the constituency parse before the dependency parse, we will use the Stanford Parser for both.','request constituency parse before dependency parse',0,'',''),(1701,'CoreNLP','There are two main classes in the interface: Document and Sentence. Tokens are represented as array elements in a sentence; e.g., to get the lemma of a token, get the lemmas array from the sentence and index it at the appropriate index. A constructor is provided for both the Document and Sentence class. For the former, the text is treated as an entire document containing potentially multiple sentences. For the latter, the text is forced to be interpreted as a single sentence.','get lemma',1,'https://stanfordnlp.github.io/CoreNLP/simple.html','usage'),(1702,'CoreNLP','There are two main classes in the interface: Document and Sentence. Tokens are represented as array elements in a sentence; e.g., to get the lemma of a token, get the lemmas array from the sentence and index it at the appropriate index. A constructor is provided for both the Document and Sentence class. For the former, the text is treated as an entire document containing potentially multiple sentences. For the latter, the text is forced to be interpreted as a single sentence.','get  at appropriate index',1,'https://stanfordnlp.github.io/CoreNLP/simple.html','usage'),(1703,'CoreNLP','There are two main classes in the interface: Document and Sentence. Tokens are represented as array elements in a sentence; e.g., to get the lemma of a token, get the lemmas array from the sentence and index it at the appropriate index. A constructor is provided for both the Document and Sentence class. For the former, the text is treated as an entire document containing potentially multiple sentences. For the latter, the text is forced to be interpreted as a single sentence.','provide constructor for sentence class',1,'https://stanfordnlp.github.io/CoreNLP/simple.html','usage'),(1704,'CoreNLP','There are two main classes in the interface: Document and Sentence. Tokens are represented as array elements in a sentence; e.g., to get the lemma of a token, get the lemmas array from the sentence and index it at the appropriate index. A constructor is provided for both the Document and Sentence class. For the former, the text is treated as an entire document containing potentially multiple sentences. For the latter, the text is forced to be interpreted as a single sentence.','force text for latter',1,'https://stanfordnlp.github.io/CoreNLP/simple.html','usage'),(1705,'CoreNLP','The interface is not guaranteed to support all of the annotators in the CoreNLP pipeline. However, most common annotators are supported. A list of these, and their invocation, is given below. Functionality is the plain-english description of the task to be performed. The second column lists the analogous CoreNLP annotator for that task. The implementing class and function describe the class and function used in this wrapper to perform the same tasks.','support common annotators',0,'',''),(1706,'CoreNLP','The interface is not guaranteed to support all of the annotators in the CoreNLP pipeline. However, most common annotators are supported. A list of these, and their invocation, is given below. Functionality is the plain-english description of the task to be performed. The second column lists the analogous CoreNLP annotator for that task. The implementing class and function describe the class and function used in this wrapper to perform the same tasks.','perform same tasks',0,'',''),(1707,'CoreNLP','Some potentially useful utility functions are implemented in the SentenceAlgorithms class. These can be called from a Sentence object with, e.g.:','call  from sentence object',1,'https://stanfordnlp.github.io/CoreNLP/simple.html','miscellaneous-extras'),(1708,'CoreNLP','headOfSpan(Span) Finds the index of the head word of the given span. So, for example, United States president Barack Obama would return Obama.','return obama',0,'',''),(1709,'CoreNLP','dependencyPathBetween(int, int) Returns the dependency path between the words at the given two indices. This is returned as a list of String objects, meant primarily as an input to a featurizer.','return  as list',0,'',''),(1710,'CoreNLP','Sentence splitting is the process of dividing text into sentences. For instance the document Hello world. Hello world again. would be split into the sentences Hello world. and Hello world again. CoreNLP splits documents into sentences via a set of rules.','divide text into sentences',0,'',''),(1711,'CoreNLP','Sentence splitting is the process of dividing text into sentences. For instance the document Hello world. Hello world again. would be split into the sentences Hello world. and Hello world again. CoreNLP splits documents into sentences via a set of rules.','split  into sentences hello world',0,'',''),(1712,'CoreNLP','Sentence splitting is the process of dividing text into sentences. For instance the document Hello world. Hello world again. would be split into the sentences Hello world. and Hello world again. CoreNLP splits documents into sentences via a set of rules.','split documents into sentences',0,'',''),(1713,'CoreNLP','As of 4.5.0, the ssplit annotator is automatically included as part of the tokenize annotator. It is no longer necessary to specify ssplit as part of the annotators list. If using an older version, it would still be necessary to incude ssplit in the annotators list.','specify ssplit as part',0,'',''),(1714,'CoreNLP','This command will take in the text of the file input.txt and produce a human readable output of the sentences:','produce human readable output of sentences',1,'https://stanfordnlp.github.io/CoreNLP/ssplit.html','sentence-splitting-from-the-command-line'),(1715,'CoreNLP','This demo code will produce this output:','produce output',1,'https://stanfordnlp.github.io/CoreNLP/ssplit.html','sentence-splitting-from-java'),(1716,'CoreNLP','StanfordCoreNLP includes SUTime, a library for processing temporal expressions such as February 4th, 2019. SUTime is built on top of TokensRegex.','build SUTime on_top_of TokensRegex',0,'',''),(1717,'CoreNLP','SUTime will match a variety of temporal expressions and link them to a TIMEX3 object.','link  to timex3 object',0,'',''),(1718,'CoreNLP','4 types of temporal expression can be recognized.','recognize types of temporal expression',0,'',''),(1719,'CoreNLP','Phrases are recognized and linked based on a set of TokensRegex rules.','recognize phrases',1,'https://stanfordnlp.github.io/CoreNLP/sutime.html','high-level-overview'),(1720,'CoreNLP','Phrases are recognized and linked based on a set of TokensRegex rules.','link phrases',1,'https://stanfordnlp.github.io/CoreNLP/sutime.html','high-level-overview'),(1721,'CoreNLP','Recognized temporal expressions can be resolved relative to the document date. For instance, the expression this Wednesday will be resolved to the Wednesday that is closest to the document date, be it the current date or any other date. The document date can be set in several ways as will be documented below.','resolve recognized temporal expressions to document date',0,'',''),(1722,'CoreNLP','Recognized temporal expressions can be resolved relative to the document date. For instance, the expression this Wednesday will be resolved to the Wednesday that is closest to the document date, be it the current date or any other date. The document date can be set in several ways as will be documented below.','resolve expression for instance',0,'',''),(1723,'CoreNLP','Recognized temporal expressions can be resolved relative to the document date. For instance, the expression this Wednesday will be resolved to the Wednesday that is closest to the document date, be it the current date or any other date. The document date can be set in several ways as will be documented below.','resolve expression to Wednesday',0,'',''),(1724,'CoreNLP','Recognized temporal expressions can be resolved relative to the document date. For instance, the expression this Wednesday will be resolved to the Wednesday that is closest to the document date, be it the current date or any other date. The document date can be set in several ways as will be documented below.','set document date in several ways',0,'',''),(1725,'CoreNLP','If you would like to customize SUTime or make additions, you can alter the rules files accordingly or add new rules files. Setting the property sutime.rules = /path/to/my-rules.txt (or a comma-separated list of rules files) will set the pipeline to use your custom rules.','add new rules files',0,'',''),(1726,'CoreNLP','If you would like to customize SUTime or make additions, you can alter the rules files accordingly or add new rules files. Setting the property sutime.rules = /path/to/my-rules.txt (or a comma-separated list of rules files) will set the pipeline to use your custom rules.','set pipeline',0,'',''),(1727,'CoreNLP','SUTime will be run automatically as a subcomponent of the ner annotator. Several properties can be set to alter the behavior of SUTime.','set several properties',0,'',''),(1728,'CoreNLP','The document date used by SUTime can also be set by specifying a date in an xml file and using the cleanxml annotator.','specify date in xml file',0,'',''),(1729,'CoreNLP','The document date used by SUTime can also be set by specifying a date in an xml file and using the cleanxml annotator.','set document date',0,'',''),(1730,'CoreNLP','The English SUTime system in Stanford CoreNLP is specified in 3 rules files:','specify English SUTime system in rules files',0,'',''),(1731,'CoreNLP','The English SUTime system in Stanford CoreNLP is specified in 3 rules files:','specify English SUTime system in Stanford CoreNLP',0,'',''),(1732,'CoreNLP','In general, temporal concepts are set up in defs.sutime.txt, and the rules for matching phrases to temporal concepts are specified in english.sutime.txt. We will follow this pattern when adding fiscal year rules.','set up temporal concepts in general',0,'',''),(1733,'CoreNLP','In general, temporal concepts are set up in defs.sutime.txt, and the rules for matching phrases to temporal concepts are specified in english.sutime.txt. We will follow this pattern when adding fiscal year rules.','set up temporal concepts in defs.sutime.txt',0,'',''),(1734,'CoreNLP','In general, temporal concepts are set up in defs.sutime.txt, and the rules for matching phrases to temporal concepts are specified in english.sutime.txt. We will follow this pattern when adding fiscal year rules.','specify rules in english.sutime.txt',0,'',''),(1735,'CoreNLP','In general, temporal concepts are set up in defs.sutime.txt, and the rules for matching phrases to temporal concepts are specified in english.sutime.txt. We will follow this pattern when adding fiscal year rules.','specify rules for matching phrases',0,'',''),(1736,'CoreNLP','The fiscal year is typically divided into 4 quarters. Here is an example for FY 2019.','divide fiscal year into quarters',0,'',''),(1737,'CoreNLP','The first step is to specify these periods of time in defs.sutime.txt. Here are the rules in that file that define those blocks of time:','specify periods in defs.sutime.txt',1,'https://stanfordnlp.github.io/CoreNLP/sutime.html','example-1-fiscal-year'),(1738,'CoreNLP','The first step is to specify these periods of time in defs.sutime.txt. Here are the rules in that file that define those blocks of time:','specify periods of time',1,'https://stanfordnlp.github.io/CoreNLP/sutime.html','example-1-fiscal-year'),(1739,'CoreNLP','The first step is to specify these periods of time in defs.sutime.txt. Here are the rules in that file that define those blocks of time:','define blocks of time',1,'https://stanfordnlp.github.io/CoreNLP/sutime.html','example-1-fiscal-year'),(1740,'CoreNLP','The first step is to specify these periods of time in defs.sutime.txt. Here are the rules in that file that define those blocks of time:','define file of time',1,'https://stanfordnlp.github.io/CoreNLP/sutime.html','example-1-fiscal-year'),(1741,'CoreNLP','After this rule has been specified in defs.sutime.txt, further in that rule file and in the subsequent rule files FYQ1 can be accessed to refer to that temporal concept.','specify rule in defs.sutime.txt',1,'https://stanfordnlp.github.io/CoreNLP/sutime.html','example-1-fiscal-year'),(1742,'CoreNLP','After this rule has been specified in defs.sutime.txt, further in that rule file and in the subsequent rule files FYQ1 can be accessed to refer to that temporal concept.','access fyq1',1,'https://stanfordnlp.github.io/CoreNLP/sutime.html','example-1-fiscal-year'),(1743,'CoreNLP','Here two maps are produced, which will map String’s to specific financial quarters, and to integer offsets. When we specify the final rule, we need to potentially subtract 1 from the year if we are recognizing Q1. Also, using the CreateRegex function, we can generate a regex that will match any of the keys in the FISCAL_YEAR_QUARTER_MAP.','produce maps',1,'https://stanfordnlp.github.io/CoreNLP/sutime.html','example-1-fiscal-year'),(1744,'CoreNLP','Here two maps are produced, which will map String’s to specific financial quarters, and to integer offsets. When we specify the final rule, we need to potentially subtract 1 from the year if we are recognizing Q1. Also, using the CreateRegex function, we can generate a regex that will match any of the keys in the FISCAL_YEAR_QUARTER_MAP.','specify final rule',1,'https://stanfordnlp.github.io/CoreNLP/sutime.html','example-1-fiscal-year'),(1745,'CoreNLP','Here two maps are produced, which will map String’s to specific financial quarters, and to integer offsets. When we specify the final rule, we need to potentially subtract 1 from the year if we are recognizing Q1. Also, using the CreateRegex function, we can generate a regex that will match any of the keys in the FISCAL_YEAR_QUARTER_MAP.','recognize q1',1,'https://stanfordnlp.github.io/CoreNLP/sutime.html','example-1-fiscal-year'),(1746,'CoreNLP','The TokensRegex rule specifies a pattern over tokens, and then specifies the temporal value to return.','specify pattern over tokens',0,'',''),(1747,'CoreNLP','The TokensRegex rule specifies a pattern over tokens, and then specifies the temporal value to return.','specify temporal value to return',0,'',''),(1748,'CoreNLP','As a reminder, TokensRegex rules specify regular expression which match tokens. Each space separated regular expression matches a single token or sequence of tokens.','specify regular expression as reminder',0,'',''),(1749,'CoreNLP','The (/$FiscalYearQuarterTerm/) token would represent Q1, Q2, Q3, Q4. The (FY)? represents an optional FY token. This is so both Q1 2019 can be recognized as well as Q1 FY 2019. The (/(FY)?([0-9]{4})/) token captures the year component of phrase, so both Q1 FY2019 can be recognized as well as Q1 2019.','recognize q1',0,'',''),(1750,'CoreNLP','The (/$FiscalYearQuarterTerm/) token would represent Q1, Q2, Q3, Q4. The (FY)? represents an optional FY token. This is so both Q1 2019 can be recognized as well as Q1 FY 2019. The (/(FY)?([0-9]{4})/) token captures the year component of phrase, so both Q1 FY2019 can be recognized as well as Q1 2019.','recognize q1 fy2019 as q1',0,'',''),(1751,'CoreNLP','The result part of the rule specifies what temporal object to create when this pattern over tokens is recognized.','recognize pattern over tokens',1,'https://stanfordnlp.github.io/CoreNLP/sutime.html','example-1-fiscal-year'),(1752,'CoreNLP','The first component of the intersection is the result of the Subtract, which simply subtracts the quarter offset from the numerical value of the year token. So if FY2019 is matched, the numerical component will be 2019. The FISCAL_YEAR_QUARTER_YEAR_OFFSETS_MAP is used to determine the offset. If Q1 FY2019 was matched, Q1 would be mapped to 1, otherwise 0. So either 1 or 0 will be subtracted from 2019, giving the correct year. Note the Subtract is wrapped in an IsoDate. You can build a specific date with IsoDate($Year, $Month, $Day). Passing ANY to IsoDate will create a date with nothing specified for that field. So IsoDate(2019, ANY, ANY) means the year 2019.','determine offset',0,'',''),(1753,'CoreNLP','The first component of the intersection is the result of the Subtract, which simply subtracts the quarter offset from the numerical value of the year token. So if FY2019 is matched, the numerical component will be 2019. The FISCAL_YEAR_QUARTER_YEAR_OFFSETS_MAP is used to determine the offset. If Q1 FY2019 was matched, Q1 would be mapped to 1, otherwise 0. So either 1 or 0 will be subtracted from 2019, giving the correct year. Note the Subtract is wrapped in an IsoDate. You can build a specific date with IsoDate($Year, $Month, $Day). Passing ANY to IsoDate will create a date with nothing specified for that field. So IsoDate(2019, ANY, ANY) means the year 2019.','wrap Subtract in IsoDate',0,'',''),(1754,'CoreNLP','The first component of the intersection is the result of the Subtract, which simply subtracts the quarter offset from the numerical value of the year token. So if FY2019 is matched, the numerical component will be 2019. The FISCAL_YEAR_QUARTER_YEAR_OFFSETS_MAP is used to determine the offset. If Q1 FY2019 was matched, Q1 would be mapped to 1, otherwise 0. So either 1 or 0 will be subtracted from 2019, giving the correct year. Note the Subtract is wrapped in an IsoDate. You can build a specific date with IsoDate($Year, $Month, $Day). Passing ANY to IsoDate will create a date with nothing specified for that field. So IsoDate(2019, ANY, ANY) means the year 2019.','build specific date with IsoDate($Year, $Month, $Day)',0,'',''),(1755,'CoreNLP','The first component of the intersection is the result of the Subtract, which simply subtracts the quarter offset from the numerical value of the year token. So if FY2019 is matched, the numerical component will be 2019. The FISCAL_YEAR_QUARTER_YEAR_OFFSETS_MAP is used to determine the offset. If Q1 FY2019 was matched, Q1 would be mapped to 1, otherwise 0. So either 1 or 0 will be subtracted from 2019, giving the correct year. Note the Subtract is wrapped in an IsoDate. You can build a specific date with IsoDate($Year, $Month, $Day). Passing ANY to IsoDate will create a date with nothing specified for that field. So IsoDate(2019, ANY, ANY) means the year 2019.','create date with nothing',0,'',''),(1756,'CoreNLP','The first component of the intersection is the result of the Subtract, which simply subtracts the quarter offset from the numerical value of the year token. So if FY2019 is matched, the numerical component will be 2019. The FISCAL_YEAR_QUARTER_YEAR_OFFSETS_MAP is used to determine the offset. If Q1 FY2019 was matched, Q1 would be mapped to 1, otherwise 0. So either 1 or 0 will be subtracted from 2019, giving the correct year. Note the Subtract is wrapped in an IsoDate. You can build a specific date with IsoDate($Year, $Month, $Day). Passing ANY to IsoDate will create a date with nothing specified for that field. So IsoDate(2019, ANY, ANY) means the year 2019.','specify  for field',0,'',''),(1757,'CoreNLP','The final temporal object is built and associated with the phrase.','build final temporal object with phrase',0,'',''),(1758,'CoreNLP','If you have created a custom rules file, you can tell SUTime to use it by setting the sutime.rules property when running a pipeline. This property takes in a list of rules files and reads them in order.','create custom rules file',0,'',''),(1759,'CoreNLP','If you have created a custom rules file, you can tell SUTime to use it by setting the sutime.rules property when running a pipeline. This property takes in a list of rules files and reads them in order.','set sutime.rules property',0,'',''),(1760,'CoreNLP','Tokenization is the process of turning text into tokens. For instance, the sentence Marie was born in Paris. would be tokenized as the list \"Marie\", \"was\", \"born\", \"in\", \"Paris\", \".\". CoreNLP splits texts into tokens with an elaborate collection of rules, designed to follow UD 2.0 specifications.','tokenize  as list marie',0,'',''),(1761,'CoreNLP','Tokenization is the process of turning text into tokens. For instance, the sentence Marie was born in Paris. would be tokenized as the list \"Marie\", \"was\", \"born\", \"in\", \"Paris\", \".\". CoreNLP splits texts into tokens with an elaborate collection of rules, designed to follow UD 2.0 specifications.','split texts into tokens',0,'',''),(1762,'CoreNLP','This command will take in the text of the file input.txt and produce a human readable output of the tokens and their character offsets:','produce human readable output of tokens',1,'https://stanfordnlp.github.io/CoreNLP/tokenize.html','tokenizing-from-the-command-line'),(1763,'CoreNLP','This command will take in the text of the file input.txt and produce a human readable output of the tokens and their character offsets:','produce human readable output of character offsets',1,'https://stanfordnlp.github.io/CoreNLP/tokenize.html','tokenizing-from-the-command-line'),(1764,'CoreNLP','The following command is an example of specifying PTBTokenizer options with the tokenize.options option:','specify PTBTokenizer options with tokenize.options option',1,'https://stanfordnlp.github.io/CoreNLP/tokenize.html','tokenizing-from-the-command-line'),(1765,'CoreNLP','This demo code will produce the tokens and the character offsets of the text.','produce tokens of text',1,'https://stanfordnlp.github.io/CoreNLP/tokenize.html','tokenizing-from-java'),(1766,'CoreNLP','This demo code will produce the tokens and the character offsets of the text.','produce character offsets of text',1,'https://stanfordnlp.github.io/CoreNLP/tokenize.html','tokenizing-from-java'),(1767,'CoreNLP','StanfordCoreNLP includes TokensRegex, a framework for defining regular expressions over text and tokens, and mapping matched text to semantic objects.','define regular expressions over text',0,'',''),(1768,'CoreNLP','StanfordCoreNLP includes TokensRegex, a framework for defining regular expressions over text and tokens, and mapping matched text to semantic objects.','define regular expressions over tokens',0,'',''),(1769,'CoreNLP','TokensRegex is a complex and powerful library for identifying and acting on patterns in text. To fully utilize TokensRegex, you should review the high level overview and then work through the specific examples below.','identify  on patterns',0,'',''),(1770,'CoreNLP','With TokensRegex, you can build a rule based system for searching for patterns and performing actions when the patterns are found.','build rule with TokensRegex',0,'',''),(1771,'CoreNLP','With TokensRegex, you can build a rule based system for searching for patterns and performing actions when the patterns are found.','perform actions',0,'',''),(1772,'CoreNLP','In a typical TokensRegex pipeline, you will need some basic Java code to load in your text, split it into sentences, and set up the CoreMapExpressionExtractor. Below is an example class TokensRegexDemo which contains the necessary code for running a TokensRegex pipeline.','split  into sentences',0,'',''),(1773,'CoreNLP','In a typical TokensRegex pipeline, you will need some basic Java code to load in your text, split it into sentences, and set up the CoreMapExpressionExtractor. Below is an example class TokensRegexDemo which contains the necessary code for running a TokensRegex pipeline.','set up CoreMapExpressionExtractor',0,'',''),(1774,'CoreNLP','In a typical TokensRegex pipeline, you will need some basic Java code to load in your text, split it into sentences, and set up the CoreMapExpressionExtractor. Below is an example class TokensRegexDemo which contains the necessary code for running a TokensRegex pipeline.','load  in text',0,'',''),(1775,'CoreNLP','In this code, some util classes and a StanfordCoreNLP pipeline are used to load the text and split it into sentences.','load text',0,'',''),(1776,'CoreNLP','In this code, some util classes and a StanfordCoreNLP pipeline are used to load the text and split it into sentences.','split  into sentences',0,'',''),(1777,'CoreNLP','Then the TokensRegex pipeline is built (not be confused with a general StanfordCoreNLP pipeline). The TokensRegex pipeline is specified by a list of rules files, and an Env object. The next section will contain a thorough example of a rules file which specifies a TokensRegex pipeline. In the example code you can see how the environment is built, and an example of specifying that you want all patterns to be case-insensitive. The list of rules files and the Env are used to construct a CoreMapExpressionExtractor, the main class which runs a TokensRegex pipeline.','build TokensRegex pipeline',0,'',''),(1778,'CoreNLP','Then the TokensRegex pipeline is built (not be confused with a general StanfordCoreNLP pipeline). The TokensRegex pipeline is specified by a list of rules files, and an Env object. The next section will contain a thorough example of a rules file which specifies a TokensRegex pipeline. In the example code you can see how the environment is built, and an example of specifying that you want all patterns to be case-insensitive. The list of rules files and the Env are used to construct a CoreMapExpressionExtractor, the main class which runs a TokensRegex pipeline.','specify TokensRegex pipeline',0,'',''),(1779,'CoreNLP','Then the TokensRegex pipeline is built (not be confused with a general StanfordCoreNLP pipeline). The TokensRegex pipeline is specified by a list of rules files, and an Env object. The next section will contain a thorough example of a rules file which specifies a TokensRegex pipeline. In the example code you can see how the environment is built, and an example of specifying that you want all patterns to be case-insensitive. The list of rules files and the Env are used to construct a CoreMapExpressionExtractor, the main class which runs a TokensRegex pipeline.','specify TokensRegex pipeline of rules file',0,'',''),(1780,'CoreNLP','Then the TokensRegex pipeline is built (not be confused with a general StanfordCoreNLP pipeline). The TokensRegex pipeline is specified by a list of rules files, and an Env object. The next section will contain a thorough example of a rules file which specifies a TokensRegex pipeline. In the example code you can see how the environment is built, and an example of specifying that you want all patterns to be case-insensitive. The list of rules files and the Env are used to construct a CoreMapExpressionExtractor, the main class which runs a TokensRegex pipeline.','specify thorough example of rules file',0,'',''),(1781,'CoreNLP','Then the TokensRegex pipeline is built (not be confused with a general StanfordCoreNLP pipeline). The TokensRegex pipeline is specified by a list of rules files, and an Env object. The next section will contain a thorough example of a rules file which specifies a TokensRegex pipeline. In the example code you can see how the environment is built, and an example of specifying that you want all patterns to be case-insensitive. The list of rules files and the Env are used to construct a CoreMapExpressionExtractor, the main class which runs a TokensRegex pipeline.','build environment',0,'',''),(1782,'CoreNLP','As you work through the examples, it is helpful to understand the high level design of a TokensRegex pipeline. The pipeline is specified in a set of rules files, that are evaluated with respect to an environment. The environment can be initialized in Java code, and altered in the rules files.','specify pipeline in set',0,'',''),(1783,'CoreNLP','As you work through the examples, it is helpful to understand the high level design of a TokensRegex pipeline. The pipeline is specified in a set of rules files, that are evaluated with respect to an environment. The environment can be initialized in Java code, and altered in the rules files.','evaluate rules files with respect',0,'',''),(1784,'CoreNLP','As you work through the examples, it is helpful to understand the high level design of a TokensRegex pipeline. The pipeline is specified in a set of rules files, that are evaluated with respect to an environment. The environment can be initialized in Java code, and altered in the rules files.','evaluate rules files to environment',0,'',''),(1785,'CoreNLP','As you work through the examples, it is helpful to understand the high level design of a TokensRegex pipeline. The pipeline is specified in a set of rules files, that are evaluated with respect to an environment. The environment can be initialized in Java code, and altered in the rules files.','initialize environment in Java code',0,'',''),(1786,'CoreNLP','Generally assignments are made at the top, which set up variables to be used in the TokensRegex pipeline.','set up variables',0,'',''),(1787,'CoreNLP','Generally assignments are made at the top, which set up variables to be used in the TokensRegex pipeline.','set up top',0,'',''),(1788,'CoreNLP','Then the rules are specified. A TokensRegex pipeline can be split into stages (as many as you’d like). Each stage runs until completion, and then the next stage runs. The Multi-Step NER example below illustrates this.','specify rules',0,'',''),(1789,'CoreNLP','Then the rules are specified. A TokensRegex pipeline can be split into stages (as many as you’d like). Each stage runs until completion, and then the next stage runs. The Multi-Step NER example below illustrates this.','split TokensRegex pipeline into stages',0,'',''),(1790,'CoreNLP','The Basic NER example shows token rules, the Extract Quotes example shows a text rule, the Process Math Expressions example shows a composite rule, and the Multi-Step NER example shows a filter rule.','show token rules',0,'',''),(1791,'CoreNLP','The Basic NER example shows token rules, the Extract Quotes example shows a text rule, the Process Math Expressions example shows a composite rule, and the Multi-Step NER example shows a filter rule.','show text rule',0,'',''),(1792,'CoreNLP','The Basic NER example shows token rules, the Extract Quotes example shows a text rule, the Process Math Expressions example shows a composite rule, and the Multi-Step NER example shows a filter rule.','show composite rule',0,'',''),(1793,'CoreNLP','The Basic NER example shows token rules, the Extract Quotes example shows a text rule, the Process Math Expressions example shows a composite rule, and the Multi-Step NER example shows a filter rule.','show filter rule',0,'',''),(1794,'CoreNLP','The “pattern” field specifies the pattern to search for in the list of tokens. Here is a description of the pattern in this example:','specify pattern',0,'',''),(1795,'CoreNLP','Note there are parenthesis around the pizza token. This specifies a group. In this example, the whole match is group $0, and the match on “pizza” is group $1. We can use the group numbers to specify lists of tokens to alter in the action part of the rule.','specify group',0,'',''),(1796,'CoreNLP','Note there are parenthesis around the pizza token. This specifies a group. In this example, the whole match is group $0, and the match on “pizza” is group $1. We can use the group numbers to specify lists of tokens to alter in the action part of the rule.','specify lists of tokens',0,'',''),(1797,'CoreNLP','The “action” field specifies an action to take. The Expressions Javadoc shows more info about the kinds of actions there are. The most common one is Annotate(). In this example we specify to annotate the word “pizza” with the NER tag “FOOD”. (Note: make sure that “ner” is tied to CoreAnnotations.NamedEntityTagAnnotation.class which is shown below). The Annotate() call says to annotate all tokens in group match $1 with named entity tag “FOOD”.','specify action',0,'',''),(1798,'CoreNLP','The “action” field specifies an action to take. The Expressions Javadoc shows more info about the kinds of actions there are. The most common one is Annotate(). In this example we specify to annotate the word “pizza” with the NER tag “FOOD”. (Note: make sure that “ner” is tied to CoreAnnotations.NamedEntityTagAnnotation.class which is shown below). The Annotate() call says to annotate all tokens in group match $1 with named entity tag “FOOD”.','show more info about kinds',0,'',''),(1799,'CoreNLP','Let’s imagine that we want to identify company names. For our simple example, we will assume we are interested in any string of capitalized tokens that ends with a company ending token.','identify company names',0,'',''),(1800,'CoreNLP','We will define the company ending tokens to be “Corp” or “Inc” (and optionally containing a “.”).','define company',0,'',''),(1801,'CoreNLP','To show more functionality, we will also add the constraint that the non-ending tokens in the pattern have to have the part of speech tag “NNP”.','show more functionality',1,'https://stanfordnlp.github.io/CoreNLP/tokensregex.html','example-1-basic-ner'),(1802,'CoreNLP','To show more functionality, we will also add the constraint that the non-ending tokens in the pattern have to have the part of speech tag “NNP”.','add constraint',1,'https://stanfordnlp.github.io/CoreNLP/tokensregex.html','example-1-basic-ner'),(1803,'CoreNLP','The first section influences the environment of the pipeline. Since our Java code sets the rules to be case-insensitive, we will set them to case-sensitive in our rules file for this TokensRegex pipeline. By setting those two flags to 0, the rules will be case-sensitive.','set flags',0,'',''),(1804,'CoreNLP','In the next section we bind certain variables to Java classes used as annotation keys. Here we bind “ner” and “tokens” to the corresponding annotation keys.','bind certain variables in next section',0,'',''),(1805,'CoreNLP','In the next section we bind certain variables to Java classes used as annotation keys. Here we bind “ner” and “tokens” to the corresponding annotation keys.','bind certain variables to Java classes',0,'',''),(1806,'CoreNLP','In the next section we bind certain variables to Java classes used as annotation keys. Here we bind “ner” and “tokens” to the corresponding annotation keys.','bind ner to corresponding annotation keys',0,'',''),(1807,'CoreNLP','In the next section we bind certain variables to Java classes used as annotation keys. Here we bind “ner” and “tokens” to the corresponding annotation keys.','bind tokens to corresponding annotation keys',0,'',''),(1808,'CoreNLP','In the third section we bind some variables to larger regexes. This would be especially useful if the regexes were especially large, though they are small in our simple example. Note that these are regexes that match the full text of a token. So $COMPANY_BEGINING will match all tokens that start with a capital letter and only contain letters (e.g. “Apple”). $COMPANY_ENDING will match the tokens “Corp”, “Inc”, “Corp.”, and “Inc.” By setting these variables to regexes, we don’t have to write out the full regex again every time we want to use it.','bind variables in third section',0,'',''),(1809,'CoreNLP','In the third section we bind some variables to larger regexes. This would be especially useful if the regexes were especially large, though they are small in our simple example. Note that these are regexes that match the full text of a token. So $COMPANY_BEGINING will match all tokens that start with a capital letter and only contain letters (e.g. “Apple”). $COMPANY_ENDING will match the tokens “Corp”, “Inc”, “Corp.”, and “Inc.” By setting these variables to regexes, we don’t have to write out the full regex again every time we want to use it.','bind variables to larger regexes',0,'',''),(1810,'CoreNLP','In the third section we bind some variables to larger regexes. This would be especially useful if the regexes were especially large, though they are small in our simple example. Note that these are regexes that match the full text of a token. So $COMPANY_BEGINING will match all tokens that start with a capital letter and only contain letters (e.g. “Apple”). $COMPANY_ENDING will match the tokens “Corp”, “Inc”, “Corp.”, and “Inc.” By setting these variables to regexes, we don’t have to write out the full regex again every time we want to use it.','set variables to regexes',0,'',''),(1811,'CoreNLP','Finally in the fourth section we define the rule for the token pattern we wish to match. The “ruleType” of the rule is “tokens”, meaning we want to find patterns over sequences of tokens.','define rule for token pattern',0,'',''),(1812,'CoreNLP','Finally in the fourth section we define the rule for the token pattern we wish to match. The “ruleType” of the rule is “tokens”, meaning we want to find patterns over sequences of tokens.','define fourth section for token pattern',0,'',''),(1813,'CoreNLP','The “pattern” of the rule defines the actual pattern we want to see in the tokens. In this case we say we want to see a number of $COMPANY_BEGINNING’s that have the “NNP” part of speech tag. Then we want to end with one token that matches the $COMPANY_ENDING pattern.','define actual pattern',0,'',''),(1814,'CoreNLP','If the pattern is matched,the “action” part of the rule will be executed. In the most typical case, this means we want to annotate all of the tokens in the matched pattern in some manner. This is done with the Annotate() function. In this rule, we state we want to annotate all of the matched tokens in the pattern (indicated by the group $0 in the token pattern), and that we want to set their “CoreAnnotation.NamedEntityTagAnnotation.class” value (indicated by “ner”), to the value “COMPANY”. This is where the actual CoreLabel’s are being altered by having their CoreAnnotations.NamedEntityTagAnnotation.class field changed.','execute action part of rule',0,'',''),(1815,'CoreNLP','If the pattern is matched,the “action” part of the rule will be executed. In the most typical case, this means we want to annotate all of the tokens in the matched pattern in some manner. This is done with the Annotate() function. In this rule, we state we want to annotate all of the matched tokens in the pattern (indicated by the group $0 in the token pattern), and that we want to set their “CoreAnnotation.NamedEntityTagAnnotation.class” value (indicated by “ner”), to the value “COMPANY”. This is where the actual CoreLabel’s are being altered by having their CoreAnnotations.NamedEntityTagAnnotation.class field changed.','set CoreAnnotation.NamedEntityTagAnnotation.class value to value COMPANY',0,'',''),(1816,'CoreNLP','If the pattern is matched,the “action” part of the rule will be executed. In the most typical case, this means we want to annotate all of the tokens in the matched pattern in some manner. This is done with the Annotate() function. In this rule, we state we want to annotate all of the matched tokens in the pattern (indicated by the group $0 in the token pattern), and that we want to set their “CoreAnnotation.NamedEntityTagAnnotation.class” value (indicated by “ner”), to the value “COMPANY”. This is where the actual CoreLabel’s are being altered by having their CoreAnnotations.NamedEntityTagAnnotation.class field changed.','change CoreAnnotations.NamedEntityTagAnnotation.class field',0,'',''),(1817,'CoreNLP','Finally we may want to produce a MatchedExpression for this to operate on in our Java code, and we may want to set the value of that MatchedExpression to something. So we have the rule return a “result” when it fires, and we say the result is “COMPANY_RESULT”. The value of the MatchedExpression will be set to “COMPANY_RESULT” as a result.','produce MatchedExpression',1,'https://stanfordnlp.github.io/CoreNLP/tokensregex.html','example-1-basic-ner'),(1818,'CoreNLP','Finally we may want to produce a MatchedExpression for this to operate on in our Java code, and we may want to set the value of that MatchedExpression to something. So we have the rule return a “result” when it fires, and we say the result is “COMPANY_RESULT”. The value of the MatchedExpression will be set to “COMPANY_RESULT” as a result.','set value of MatchedExpression',1,'https://stanfordnlp.github.io/CoreNLP/tokensregex.html','example-1-basic-ner'),(1819,'CoreNLP','Finally we may want to produce a MatchedExpression for this to operate on in our Java code, and we may want to set the value of that MatchedExpression to something. So we have the rule return a “result” when it fires, and we say the result is “COMPANY_RESULT”. The value of the MatchedExpression will be set to “COMPANY_RESULT” as a result.','set value to something',1,'https://stanfordnlp.github.io/CoreNLP/tokensregex.html','example-1-basic-ner'),(1820,'CoreNLP','Finally we may want to produce a MatchedExpression for this to operate on in our Java code, and we may want to set the value of that MatchedExpression to something. So we have the rule return a “result” when it fires, and we say the result is “COMPANY_RESULT”. The value of the MatchedExpression will be set to “COMPANY_RESULT” as a result.','return result',1,'https://stanfordnlp.github.io/CoreNLP/tokensregex.html','example-1-basic-ner'),(1821,'CoreNLP','Finally we may want to produce a MatchedExpression for this to operate on in our Java code, and we may want to set the value of that MatchedExpression to something. So we have the rule return a “result” when it fires, and we say the result is “COMPANY_RESULT”. The value of the MatchedExpression will be set to “COMPANY_RESULT” as a result.','set value of MatchedExpression',1,'https://stanfordnlp.github.io/CoreNLP/tokensregex.html','example-1-basic-ner'),(1822,'CoreNLP','Note: in this command we are only running tokenize,pos so the CoreLabels will have “null” for the NER token unless our rules find patterns in the input sentences. Also remember that the Java code specifies to create sentences based on newlines, so the input file is interpreted as one-sentence-per-line.','create sentences',1,'https://stanfordnlp.github.io/CoreNLP/tokensregex.html','example-1-basic-ner'),(1823,'CoreNLP','Note that “apple inc” is not being matched, meaning we have successfully set the rules to be case sensitive.','set rules',0,'',''),(1824,'CoreNLP','In this section we will go through building a pipeline that performs multi-step named entity recognition.','build pipeline',0,'',''),(1825,'CoreNLP','In this section we will go through building a pipeline that performs multi-step named entity recognition.','perform multi-step named entity recognition',0,'',''),(1826,'CoreNLP','In this section we will go through building a pipeline that performs multi-step named entity recognition.','perform pipeline',0,'',''),(1827,'CoreNLP','In the first phase, we will identify basic components of a job title. The two we will identify are JOB_TITLE_BASE (e.g. “president”) and JOB_TITLE_MODIFIER (e.g. “vice”).','identify basic components in first phase',0,'',''),(1828,'CoreNLP','In the first phase, we will identify basic components of a job title. The two we will identify are JOB_TITLE_BASE (e.g. “president”) and JOB_TITLE_MODIFIER (e.g. “vice”).','identify basic components of job title',0,'',''),(1829,'CoreNLP','In the second phase, we will build on named entity tags that were applied in the first phase. Every time we see a sequence of JOB_TITLE_MODIFIER’s ending in a JOB_TITLE_BASE we will mark all of those tokens as a COMPLETE_JOB_TITLE.','build  in second phase',1,'https://stanfordnlp.github.io/CoreNLP/tokensregex.html','example-2-multi-step-ner'),(1830,'CoreNLP','In the second phase, we will build on named entity tags that were applied in the first phase. Every time we see a sequence of JOB_TITLE_MODIFIER’s ending in a JOB_TITLE_BASE we will mark all of those tokens as a COMPLETE_JOB_TITLE.','build  on named entity tags',1,'https://stanfordnlp.github.io/CoreNLP/tokensregex.html','example-2-multi-step-ner'),(1831,'CoreNLP','In the second phase, we will build on named entity tags that were applied in the first phase. Every time we see a sequence of JOB_TITLE_MODIFIER’s ending in a JOB_TITLE_BASE we will mark all of those tokens as a COMPLETE_JOB_TITLE.','mark JOB_TITLE_BASE as COMPLETE_JOB_TITLE',1,'https://stanfordnlp.github.io/CoreNLP/tokensregex.html','example-2-multi-step-ner'),(1832,'CoreNLP','You should get this output:','get output',1,'https://stanfordnlp.github.io/CoreNLP/tokensregex.html','example-5-process-math-expressions-composite-rules'),(1833,'CoreNLP','Note that the sentence containing “deputy vice president” does have those tokens tagged as COMPLETE_JOB_TITLE’s, but that no matched expression is found for “deputy vice president” because of the filter. Note that the last two sentences have no named entity tags because we added a cleanup rule at the end. If we didn’t have that cleanup rule “president” and “President” would’ve been tagged with “JOB_TITLE_BASE”.','tag  as COMPLETE_JOB_TITLE',0,'',''),(1834,'CoreNLP','Note that the sentence containing “deputy vice president” does have those tokens tagged as COMPLETE_JOB_TITLE’s, but that no matched expression is found for “deputy vice president” because of the filter. Note that the last two sentences have no named entity tags because we added a cleanup rule at the end. If we didn’t have that cleanup rule “president” and “President” would’ve been tagged with “JOB_TITLE_BASE”.','add cleanup rule at end',0,'',''),(1835,'CoreNLP','Note that the sentence containing “deputy vice president” does have those tokens tagged as COMPLETE_JOB_TITLE’s, but that no matched expression is found for “deputy vice president” because of the filter. Note that the last two sentences have no named entity tags because we added a cleanup rule at the end. If we didn’t have that cleanup rule “president” and “President” would’ve been tagged with “JOB_TITLE_BASE”.','tag  with job_title_base',0,'',''),(1836,'CoreNLP','If the pattern is found, we will get a MatchedExpression which will contain a list of tokens. This could be useful if you wanted to find quoted text and then work on the tokens of the quote.','get MatchedExpression',1,'https://stanfordnlp.github.io/CoreNLP/tokensregex.html','example-3-extract-quotes-find-a-pattern-in-a-string-instead-of-over-tokens'),(1837,'CoreNLP','you should get this output:','get output',0,'',''),(1838,'CoreNLP','The pattern finds a quote, and it returns a MatchedExpression with the values shown in the output.','return MatchedExpression with values',0,'',''),(1839,'CoreNLP','The pattern finds a quote, and it returns a MatchedExpression with the values shown in the output.','show  in output',0,'',''),(1840,'CoreNLP','This example demonstrates the composite rule type, it will run on a math equation and calculate the value of it. The rule should match (among other things) two numbers separated by an operator, and assign that expression the value of executing the operation on the operands. “(“, expression, “)” will be matched to be the same expression and have the same value as the enclosed expression (this is to process parenthesis). Every time a pattern is matched, all of the tokens in the pattern match will be replaced with an “aggregate token” representing the whole matched pattern.','calculate value',0,'',''),(1841,'CoreNLP','This example demonstrates the composite rule type, it will run on a math equation and calculate the value of it. The rule should match (among other things) two numbers separated by an operator, and assign that expression the value of executing the operation on the operands. “(“, expression, “)” will be matched to be the same expression and have the same value as the enclosed expression (this is to process parenthesis). Every time a pattern is matched, all of the tokens in the pattern match will be replaced with an “aggregate token” representing the whole matched pattern.','assign numbers',0,'',''),(1842,'CoreNLP','This example demonstrates the composite rule type, it will run on a math equation and calculate the value of it. The rule should match (among other things) two numbers separated by an operator, and assign that expression the value of executing the operation on the operands. “(“, expression, “)” will be matched to be the same expression and have the same value as the enclosed expression (this is to process parenthesis). Every time a pattern is matched, all of the tokens in the pattern match will be replaced with an “aggregate token” representing the whole matched pattern.','execute operation on operands',0,'',''),(1843,'CoreNLP','This example demonstrates the composite rule type, it will run on a math equation and calculate the value of it. The rule should match (among other things) two numbers separated by an operator, and assign that expression the value of executing the operation on the operands. “(“, expression, “)” will be matched to be the same expression and have the same value as the enclosed expression (this is to process parenthesis). Every time a pattern is matched, all of the tokens in the pattern match will be replaced with an “aggregate token” representing the whole matched pattern.','replace  with aggregate token',0,'',''),(1844,'CoreNLP','The composite rules are run over and over again until nothing changes. Matched expressions are replaced with an aggregate token which represents the whole matched expression.','replace matched expressions with aggregate token',1,'https://stanfordnlp.github.io/CoreNLP/tokensregex.html','example-5-process-math-expressions-composite-rules'),(1845,'CoreNLP','However, here are some tutorials by third parties. Note that some of this tutorial material ages with the release of newer versions of CoreNLP, and it may not be fully up to date with current CoreNLP. Check the date/version of it.','check date/version',0,'',''),(1846,'Requests','Requests was lovingly created by Kenneth Reitz.','create requests',0,'',''),(3854,'memfs','While we\'ve got prettier setup we currently don\'t enforce it - this changes that.','get prettier setup',0,'',''),(3855,'memfs','🎉 This PR is included in version 3.4.7 🎉','include PR in version 3.4.7',0,'',''),(3856,'memfs','Create a file system from a plain JSON:','create file system from plain JSON',1,'https://github.com/streamich/memfs','user-content-usage'),(3857,'memfs','Use it for testing:','use  for testing',1,'https://github.com/streamich/memfs','user-content-usage'),(3858,'memfs','Create as many filesystem volumes as you need:','create  as many filesystem volumes',1,'https://github.com/streamich/memfs','user-content-usage'),(3859,'memfs','Use memfs together with unionfs to create one filesystem\nfrom your in-memory volumes and the real disk filesystem:','create filesystem from real disk filesystem',1,'https://github.com/streamich/memfs','user-content-usage'),(3860,'memfs','Use memfs together with unionfs to create one filesystem\nfrom your in-memory volumes and the real disk filesystem:','create filesystem from in-memory volumes',1,'https://github.com/streamich/memfs','user-content-usage'),(3861,'memfs','Use fs-monkey to monkey-patch Node\'s require function:','use fs-monkey to require function',1,'https://github.com/streamich/memfs','user-content-usage'),(3862,'memfs','@Mesteery Please add fs.realpath.native to the list. It is available since Node.js 9.2.0.\nhttps://nodejs.org/api/fs.html#fsrealpathnativepath-options-callback','add fs.realpath.native to list',0,'',''),(3863,'memfs','Basically you need to add an alias like this:','add alias',1,'https://github.com/streamich/memfs-webpack','user-content-memfs-webpack'),(3864,'memfs','Now open your browser and go to http://localhost:8080/index.html.\nOpen dev console and you should see:','open browser',1,'https://github.com/streamich/memfs-webpack','user-content-getting-started-with-this-example'),(3865,'memfs','It is output from memfs, although in the code we used the actual fs module:','use actual fs module in code',1,'https://github.com/streamich/memfs-webpack','user-content-getting-started-with-this-example'),(3866,'memfs','I\'m not an expert on Node internals but from briefly reading the source code, it seems the problem is that .closed doesn\'t have a setter since Node 18 (https://github.com/nodejs/node/blob/v18.0.0/lib/internal/streams/readable.js#L1243).','read source code',0,'',''),(3867,'memfs','I also upgraded the node image in CI - to use Node 18.','use Node',0,'',''),(3868,'memfs','The test plan is I guess just to see if CI checks pass. I saw #829 and it seems the tests failed there. From my understanding, if my fix is correct, CI checks should pass now. I also ran yarn test locally on Node 18.1 and it succeeded.','pass  from understanding',0,'',''),(3869,'memfs','The test plan is I guess just to see if CI checks pass. I saw #829 and it seems the tests failed there. From my understanding, if my fix is correct, CI checks should pass now. I also ran yarn test locally on Node 18.1 and it succeeded.','run yarn test on Node 18.1',0,'',''),(3870,'memfs','There was a problem hiding this comment.','hide comment',0,'',''),(3871,'memfs','It should be possible to use optional chaining here right?','use optional chaining',0,'',''),(3872,'memfs','@G-Rath I addressed your feedback and also realized that I should fix the FsWriteStream implementation. I decided to copy-paste the close method from FsReadStream because in my opinion sth like the following would look weird:','fix FsWriteStream implementation',1,'https://github.com/streamich/memfs/pull/836',''),(3873,'memfs','🎉 This PR is included in version 3.4.2 🎉','include PR in version 3.4.2',0,'',''),(3874,'memfs','I\'m inclined to believe that the library should be simultaneously tested on all LTS versions of Node.js in addition to at least the major versions of the recent ones.','test library on LTS versions',0,'',''),(3875,'memfs','I\'m inclined to believe that the library should be simultaneously tested on all LTS versions of Node.js in addition to at least the major versions of the recent ones.','test library on major versions',0,'',''),(3876,'memfs','Theoretically they all are in active dev, or maintenance, and as such bear the potential to break. If the e2e test suite could be run on all versions, that can act as the first line of defence. Thoughts?','run e2e test suite on versions',0,'',''),(3877,'memfs','I agree. I simply changed this value because I\'m not a maintainer/code-owner of this lib and this was the easiest I could do to make sure it works on Node 18.','change value',0,'',''),(3878,'memfs','This is now redundant because it\'s not actually testing anything useful - either the methods will be defined, which in case we\'re testing node internals, or they won\'t and we\'re testing the JS engines ability to implement syntax.','test node internals in case',0,'',''),(3879,'memfs','This is now redundant because it\'s not actually testing anything useful - either the methods will be defined, which in case we\'re testing node internals, or they won\'t and we\'re testing the JS engines ability to implement syntax.','test JS engines ability',0,'',''),(3880,'memfs','This is now redundant because it\'s not actually testing anything useful - either the methods will be defined, which in case we\'re testing node internals, or they won\'t and we\'re testing the JS engines ability to implement syntax.','implement syntax',0,'',''),(3881,'memfs','This is now redundant because it\'s not actually testing anything useful - either the methods will be defined, which in case we\'re testing node internals, or they won\'t and we\'re testing the JS engines ability to implement syntax.','define methods',0,'',''),(3882,'memfs','🎉 This PR is included in version 3.4.6 🎉','include PR in version 3.4.6',0,'',''),(3883,'memfs','This version was pushed to npm by nlf, a new releaser for hosted-git-info since your current version.','push version',0,'',''),(3884,'memfs','Dependabot will resolve any conflicts with this PR as long as you don\'t alter it yourself. You can also trigger a rebase manually by commenting @dependabot rebase.','resolve conflicts with PR',0,'',''),(3885,'memfs','Dependabot will resolve any conflicts with this PR as long as you don\'t alter it yourself. You can also trigger a rebase manually by commenting @dependabot rebase.','trigger rebase by commenting',0,'',''),(3886,'memfs','You can trigger Dependabot actions by commenting on this PR:','trigger Dependabot actions by commenting',0,'',''),(3887,'memfs','You can disable automated security fix PRs for this repo from the Security Alerts page.','disable automated security fix prs for repo',0,'',''),(3888,'netty','Please use the following checklist before pushing your commits or issuing a pull request:','use following checklist before pushing',0,'',''),(3889,'netty','Please use the following checklist before pushing your commits or issuing a pull request:','use following checklist before issuing',0,'',''),(3890,'netty','Please use the following checklist before pushing your commits or issuing a pull request:','push commits',0,'',''),(3891,'netty','Nowadays we use general purpose applications or libraries to communicate with each other. For example, we often use an HTTP client library to retrieve information from a web server and to invoke a remote procedure call via web services.','retrieve information from web server',0,'',''),(3892,'netty','However, a general purpose protocol or its implementation sometimes does not scale very well. It is like we don\'t use a general purpose HTTP server to exchange huge files, e-mail messages, and near-realtime messages such as financial information and multiplayer game data. What\'s required is a highly optimized protocol implementation which is dedicated to a special purpose. For example, you might want to implement an HTTP server which is optimized for AJAX-based chat application, media streaming, or large file transfer. You could even want to design and implement a whole new protocol which is precisely tailored to your need.','implement HTTP server',0,'',''),(3893,'netty','However, a general purpose protocol or its implementation sometimes does not scale very well. It is like we don\'t use a general purpose HTTP server to exchange huge files, e-mail messages, and near-realtime messages such as financial information and multiplayer game data. What\'s required is a highly optimized protocol implementation which is dedicated to a special purpose. For example, you might want to implement an HTTP server which is optimized for AJAX-based chat application, media streaming, or large file transfer. You could even want to design and implement a whole new protocol which is precisely tailored to your need.','design whole new protocol',0,'',''),(3894,'netty','However, a general purpose protocol or its implementation sometimes does not scale very well. It is like we don\'t use a general purpose HTTP server to exchange huge files, e-mail messages, and near-realtime messages such as financial information and multiplayer game data. What\'s required is a highly optimized protocol implementation which is dedicated to a special purpose. For example, you might want to implement an HTTP server which is optimized for AJAX-based chat application, media streaming, or large file transfer. You could even want to design and implement a whole new protocol which is precisely tailored to your need.','implement whole new protocol',0,'',''),(3895,'netty','Another inevitable case is when you have to deal with a legacy proprietary protocol to ensure the interoperability with an old system. What matters in this case is how quickly we can implement that protocol while not sacrificing the stability and performance of the resulting application.','implement protocol',0,'',''),(3896,'netty','The Netty project is an effort to provide an asynchronous event-driven network application framework and tooling for the rapid development of maintainable high-performance · high-scalability protocol servers and clients.','provide tooling for rapid development',0,'',''),(3897,'netty','The Netty project is an effort to provide an asynchronous event-driven network application framework and tooling for the rapid development of maintainable high-performance · high-scalability protocol servers and clients.','provide framework for rapid development',0,'',''),(3898,'netty','In other words, Netty is a NIO client server framework which enables quick and easy development of network applications such as protocol servers and clients. It greatly simplifies and streamlines network programming such as TCP and UDP socket server development.','enable quick easy development in other words',0,'',''),(3899,'netty','In other words, Netty is a NIO client server framework which enables quick and easy development of network applications such as protocol servers and clients. It greatly simplifies and streamlines network programming such as TCP and UDP socket server development.','enable quick easy development of network applications',0,'',''),(3900,'netty','In other words, Netty is a NIO client server framework which enables quick and easy development of network applications such as protocol servers and clients. It greatly simplifies and streamlines network programming such as TCP and UDP socket server development.','enable NIO client server framework in other words',0,'',''),(3901,'netty','In other words, Netty is a NIO client server framework which enables quick and easy development of network applications such as protocol servers and clients. It greatly simplifies and streamlines network programming such as TCP and UDP socket server development.','enable NIO client server framework of network applications',0,'',''),(3902,'netty','\'Quick and easy\' does not mean that a resulting application will suffer from a maintainability or a performance issue. Netty has been designed carefully with the experiences earned from the implementation of a lot of protocols such as FTP, SMTP, HTTP, and various binary and text-based legacy protocols. As a result, Netty has succeeded to find a way to achieve ease of development, performance, stability, and flexibility without a compromise.','design netty with experiences',0,'',''),(3903,'netty','\'Quick and easy\' does not mean that a resulting application will suffer from a maintainability or a performance issue. Netty has been designed carefully with the experiences earned from the implementation of a lot of protocols such as FTP, SMTP, HTTP, and various binary and text-based legacy protocols. As a result, Netty has succeeded to find a way to achieve ease of development, performance, stability, and flexibility without a compromise.','find way',0,'',''),(3904,'netty','Some users might already have found other network application framework that claims to have the same advantage, and you might want to ask what makes Netty so different from them. The answer is the philosophy where it is built on. Netty is designed to give you the most comfortable experience both in terms of the API and the implementation from the day one. It is not something tangible but you will realize that this philosophy will make your life much easier as you read this guide and play with Netty.','find other network application framework',0,'',''),(3905,'netty','Some users might already have found other network application framework that claims to have the same advantage, and you might want to ask what makes Netty so different from them. The answer is the philosophy where it is built on. Netty is designed to give you the most comfortable experience both in terms of the API and the implementation from the day one. It is not something tangible but you will realize that this philosophy will make your life much easier as you read this guide and play with Netty.','design netty',0,'',''),(3906,'netty','Some users might already have found other network application framework that claims to have the same advantage, and you might want to ask what makes Netty so different from them. The answer is the philosophy where it is built on. Netty is designed to give you the most comfortable experience both in terms of the API and the implementation from the day one. It is not something tangible but you will realize that this philosophy will make your life much easier as you read this guide and play with Netty.','read guide',0,'',''),(3907,'netty','Some users might already have found other network application framework that claims to have the same advantage, and you might want to ask what makes Netty so different from them. The answer is the philosophy where it is built on. Netty is designed to give you the most comfortable experience both in terms of the API and the implementation from the day one. It is not something tangible but you will realize that this philosophy will make your life much easier as you read this guide and play with Netty.','play  with netty',0,'',''),(3908,'netty','This chapter tours around the core constructs of Netty with simple examples to let you get started quickly. You will be able to write a client and a server on top of Netty right away when you are at the end of this chapter.','write client on_top_of Netty',0,'',''),(3909,'netty','This chapter tours around the core constructs of Netty with simple examples to let you get started quickly. You will be able to write a client and a server on top of Netty right away when you are at the end of this chapter.','write server on_top_of Netty',0,'',''),(3910,'netty','If you prefer top-down approach in learning something, you might want to start from Chapter 2, Architectural Overview and get back here.','learn something',0,'',''),(3911,'netty','The minimum requirements to run the examples which are introduced in this chapter are only two; the latest version of Netty and JDK 1.6 or above. The latest version of Netty is available in the project download page. To download the right version of JDK, please refer to your preferred JDK vendor\'s web site.','run examples',0,'',''),(3912,'netty','The minimum requirements to run the examples which are introduced in this chapter are only two; the latest version of Netty and JDK 1.6 or above. The latest version of Netty is available in the project download page. To download the right version of JDK, please refer to your preferred JDK vendor\'s web site.','introduce examples in chapter',0,'',''),(3913,'netty','The minimum requirements to run the examples which are introduced in this chapter are only two; the latest version of Netty and JDK 1.6 or above. The latest version of Netty is available in the project download page. To download the right version of JDK, please refer to your preferred JDK vendor\'s web site.','download right version of JDK',0,'',''),(3914,'netty','As you read, you might have more questions about the classes introduced in this chapter. Please refer to the API reference whenever you want to know more about them. All class names in this document are linked to the online API reference for your convenience. Also, please don\'t hesitate to contact the Netty project community and let us know if there\'s any incorrect information, errors in grammar and typo, and if you have a good idea to improve the documentation.','introduce  in chapter',0,'',''),(3915,'netty','As you read, you might have more questions about the classes introduced in this chapter. Please refer to the API reference whenever you want to know more about them. All class names in this document are linked to the online API reference for your convenience. Also, please don\'t hesitate to contact the Netty project community and let us know if there\'s any incorrect information, errors in grammar and typo, and if you have a good idea to improve the documentation.','link class names in document',0,'',''),(3916,'netty','As you read, you might have more questions about the classes introduced in this chapter. Please refer to the API reference whenever you want to know more about them. All class names in this document are linked to the online API reference for your convenience. Also, please don\'t hesitate to contact the Netty project community and let us know if there\'s any incorrect information, errors in grammar and typo, and if you have a good idea to improve the documentation.','link class names to online API reference',0,'',''),(3917,'netty','The most simplistic protocol in the world is not \'Hello, World!\' but DISCARD. It\'s a protocol which discards any received data without any response.','receive data without response',0,'',''),(3918,'netty','To implement the DISCARD protocol, the only thing you need to do is to ignore all received data. Let us start straight from the handler implementation, which handles I/O events generated by Netty.','implement DISCARD protocol',1,'https://netty.io/wiki/user-guide-for-4.x.html','wiki-h3-6'),(3919,'netty','To implement the DISCARD protocol, the only thing you need to do is to ignore all received data. Let us start straight from the handler implementation, which handles I/O events generated by Netty.','ignore received data',1,'https://netty.io/wiki/user-guide-for-4.x.html','wiki-h3-6'),(3920,'netty','To implement the DISCARD protocol, the only thing you need to do is to ignore all received data. Let us start straight from the handler implementation, which handles I/O events generated by Netty.','generate  by netty',1,'https://netty.io/wiki/user-guide-for-4.x.html','wiki-h3-6'),(3921,'netty','To implement the DISCARD protocol, the only thing you need to do is to ignore all received data. Let us start straight from the handler implementation, which handles I/O events generated by Netty.','handle handler implementation',1,'https://netty.io/wiki/user-guide-for-4.x.html','wiki-h3-6'),(3922,'netty','So far so good. We have implemented the first half of the DISCARD server. What\'s left now is to write the main() method which starts the server with the DiscardServerHandler.','implement first half of DISCARD server',1,'https://netty.io/wiki/user-guide-for-4.x.html','wiki-h3-6'),(3923,'netty','So far so good. We have implemented the first half of the DISCARD server. What\'s left now is to write the main() method which starts the server with the DiscardServerHandler.','write main() method',1,'https://netty.io/wiki/user-guide-for-4.x.html','wiki-h3-6'),(3924,'netty','Now that we have written our first server, we need to test if it really works. The easiest way to test it is to use the telnet command. For example, you could enter telnet localhost 8080 in the command line and type something.','write first server',0,'',''),(3925,'netty','Now that we have written our first server, we need to test if it really works. The easiest way to test it is to use the telnet command. For example, you could enter telnet localhost 8080 in the command line and type something.','use telnet command',0,'',''),(3926,'netty','Now that we have written our first server, we need to test if it really works. The easiest way to test it is to use the telnet command. For example, you could enter telnet localhost 8080 in the command line and type something.','enter telnet localhost in type something',0,'',''),(3927,'netty','Now that we have written our first server, we need to test if it really works. The easiest way to test it is to use the telnet command. For example, you could enter telnet localhost 8080 in the command line and type something.','enter telnet localhost in command line',0,'',''),(3928,'netty','However, can we say that the server is working fine? We cannot really know that because it is a discard server. You will not get any response at all. To prove it is really working, let us modify the server to print what it has received.','modify server',0,'',''),(3929,'netty','We already know that channelRead() method is invoked whenever data is received. Let us put some code into the channelRead() method of the DiscardServerHandler:','receive data',1,'https://netty.io/wiki/user-guide-for-4.x.html','wiki-h3-7'),(3930,'netty','If you run the telnet command again, you will see the server prints what has received.','run telnet command',0,'',''),(3931,'netty','If you run the telnet command again, you will see the server prints what has received.','receive server prints',0,'',''),(3932,'netty','The full source code of the discard server is located in the io.netty.example.discard package of the distribution.','locate full source code in io.netty.example.discard package',0,'',''),(3933,'netty','The full source code of the discard server is located in the io.netty.example.discard package of the distribution.','locate full source code of discard server',0,'',''),(3934,'netty','So far, we have been consuming data without responding at all. A server, however, is usually supposed to respond to a request. Let us learn how to write a response message to a client by implementing the ECHO protocol, where any received data is sent back.','write response message by implementing',0,'',''),(3935,'netty','So far, we have been consuming data without responding at all. A server, however, is usually supposed to respond to a request. Let us learn how to write a response message to a client by implementing the ECHO protocol, where any received data is sent back.','write response message to client',0,'',''),(3936,'netty','So far, we have been consuming data without responding at all. A server, however, is usually supposed to respond to a request. Let us learn how to write a response message to a client by implementing the ECHO protocol, where any received data is sent back.','implement ECHO protocol',0,'',''),(3937,'netty','So far, we have been consuming data without responding at all. A server, however, is usually supposed to respond to a request. Let us learn how to write a response message to a client by implementing the ECHO protocol, where any received data is sent back.','send data',0,'',''),(3938,'netty','The only difference from the discard server we have implemented in the previous sections is that it sends the received data back instead of printing the received data out to the console. Therefore, it is enough again to modify the channelRead() method:','send received data instead_of printing',1,'https://netty.io/wiki/user-guide-for-4.x.html','wiki-h3-8'),(3939,'netty','The only difference from the discard server we have implemented in the previous sections is that it sends the received data back instead of printing the received data out to the console. Therefore, it is enough again to modify the channelRead() method:','implement discard server in previous sections',1,'https://netty.io/wiki/user-guide-for-4.x.html','wiki-h3-8'),(3940,'netty','The only difference from the discard server we have implemented in the previous sections is that it sends the received data back instead of printing the received data out to the console. Therefore, it is enough again to modify the channelRead() method:','modify channelRead() method',1,'https://netty.io/wiki/user-guide-for-4.x.html','wiki-h3-8'),(3941,'netty','If you run the telnet command again, you will see the server sends back whatever you have sent to it.','run telnet command',0,'',''),(3942,'netty','The full source code of the echo server is located in the io.netty.example.echo package of the distribution.','locate full source code in io.netty.example.echo package',0,'',''),(3943,'netty','The full source code of the echo server is located in the io.netty.example.echo package of the distribution.','locate full source code of echo server',0,'',''),(3944,'netty','The protocol to implement in this section is the TIME protocol. It is different from the previous examples in that it sends a message, which contains a 32-bit integer, without receiving any requests and closes the connection once the message is sent. In this example, you will learn how to construct and send a message, and to close the connection on completion.','implement  in section',0,'',''),(3945,'netty','The protocol to implement in this section is the TIME protocol. It is different from the previous examples in that it sends a message, which contains a 32-bit integer, without receiving any requests and closes the connection once the message is sent. In this example, you will learn how to construct and send a message, and to close the connection on completion.','send message without receiving',0,'',''),(3946,'netty','The protocol to implement in this section is the TIME protocol. It is different from the previous examples in that it sends a message, which contains a 32-bit integer, without receiving any requests and closes the connection once the message is sent. In this example, you will learn how to construct and send a message, and to close the connection on completion.','send previous examples without receiving',0,'',''),(3947,'netty','The protocol to implement in this section is the TIME protocol. It is different from the previous examples in that it sends a message, which contains a 32-bit integer, without receiving any requests and closes the connection once the message is sent. In this example, you will learn how to construct and send a message, and to close the connection on completion.','receive requests',0,'',''),(3948,'netty','The protocol to implement in this section is the TIME protocol. It is different from the previous examples in that it sends a message, which contains a 32-bit integer, without receiving any requests and closes the connection once the message is sent. In this example, you will learn how to construct and send a message, and to close the connection on completion.','send message',0,'',''),(3949,'netty','Because we are going to ignore any received data but to send a message as soon as a connection is established, we cannot use the channelRead() method this time. Instead, we should override the channelActive() method. The following is the implementation:','ignore received data',1,'https://netty.io/wiki/user-guide-for-4.x.html','wiki-h3-9'),(3950,'netty','Because we are going to ignore any received data but to send a message as soon as a connection is established, we cannot use the channelRead() method this time. Instead, we should override the channelActive() method. The following is the implementation:','send message',1,'https://netty.io/wiki/user-guide-for-4.x.html','wiki-h3-9'),(3951,'netty','Because we are going to ignore any received data but to send a message as soon as a connection is established, we cannot use the channelRead() method this time. Instead, we should override the channelActive() method. The following is the implementation:','override channelActive() method',1,'https://netty.io/wiki/user-guide-for-4.x.html','wiki-h3-9'),(3952,'netty','As explained, the channelActive() method will be invoked when a connection is established and ready to generate traffic. Let\'s write a 32-bit integer that represents the current time in this method.','generate traffic',0,'',''),(3953,'netty','As explained, the channelActive() method will be invoked when a connection is established and ready to generate traffic. Let\'s write a 32-bit integer that represents the current time in this method.','write 32-bit integer',0,'',''),(3954,'netty','To send a new message, we need to allocate a new buffer which will contain the message. We are going to write a 32-bit integer, and therefore we need a ByteBuf whose capacity is at least 4 bytes. Get the current ByteBufAllocator via ChannelHandlerContext.alloc() and allocate a new buffer.','send new message',0,'',''),(3955,'netty','To send a new message, we need to allocate a new buffer which will contain the message. We are going to write a 32-bit integer, and therefore we need a ByteBuf whose capacity is at least 4 bytes. Get the current ByteBufAllocator via ChannelHandlerContext.alloc() and allocate a new buffer.','write 32-bit integer',0,'',''),(3956,'netty','To send a new message, we need to allocate a new buffer which will contain the message. We are going to write a 32-bit integer, and therefore we need a ByteBuf whose capacity is at least 4 bytes. Get the current ByteBufAllocator via ChannelHandlerContext.alloc() and allocate a new buffer.','get current ByteBufAllocator via ChannelHandlerContext.alloc()',0,'',''),(3957,'netty','As usual, we write the constructed message.','write constructed message',0,'',''),(3958,'netty','But wait, where\'s the flip? Didn\'t we used to call java.nio.ByteBuffer.flip() before sending a message in NIO? ByteBuf does not have such a method because it has two pointers; one for read operations and the other for write operations. The writer index increases when you write something to a ByteBuf while the reader index does not change. The reader index and the writer index represents where the message starts and ends respectively.','send message in NIO',0,'',''),(3959,'netty','But wait, where\'s the flip? Didn\'t we used to call java.nio.ByteBuffer.flip() before sending a message in NIO? ByteBuf does not have such a method because it has two pointers; one for read operations and the other for write operations. The writer index increases when you write something to a ByteBuf while the reader index does not change. The reader index and the writer index represents where the message starts and ends respectively.','write something to ByteBuf',0,'',''),(3960,'netty','In contrast, NIO buffer does not provide a clean way to figure out where the message content starts and ends without calling the flip method. You will be in trouble when you forget to flip the buffer because nothing or incorrect data will be sent. Such an error does not happen in Netty because we have different pointer for different operation types. You will find it makes your life much easier as you get used to it -- a life without flipping out!','call flip method',0,'',''),(3961,'netty','In contrast, NIO buffer does not provide a clean way to figure out where the message content starts and ends without calling the flip method. You will be in trouble when you forget to flip the buffer because nothing or incorrect data will be sent. Such an error does not happen in Netty because we have different pointer for different operation types. You will find it makes your life much easier as you get used to it -- a life without flipping out!','send nothing incorrect data',0,'',''),(3962,'netty','In contrast, NIO buffer does not provide a clean way to figure out where the message content starts and ends without calling the flip method. You will be in trouble when you forget to flip the buffer because nothing or incorrect data will be sent. Such an error does not happen in Netty because we have different pointer for different operation types. You will find it makes your life much easier as you get used to it -- a life without flipping out!','use life without flipping',0,'',''),(3963,'netty','In contrast, NIO buffer does not provide a clean way to figure out where the message content starts and ends without calling the flip method. You will be in trouble when you forget to flip the buffer because nothing or incorrect data will be sent. Such an error does not happen in Netty because we have different pointer for different operation types. You will find it makes your life much easier as you get used to it -- a life without flipping out!','use life without flipping',0,'',''),(3964,'netty','Another point to note is that the ChannelHandlerContext.write() (and writeAndFlush()) method returns a ChannelFuture. A ChannelFuture represents an I/O operation which has not yet occurred. It means, any requested operation might not have been performed yet because all operations are asynchronous in Netty. For example, the following code might close the connection even before a message is sent:','return ChannelFuture',1,'https://netty.io/wiki/user-guide-for-4.x.html',''),(3965,'netty','Another point to note is that the ChannelHandlerContext.write() (and writeAndFlush()) method returns a ChannelFuture. A ChannelFuture represents an I/O operation which has not yet occurred. It means, any requested operation might not have been performed yet because all operations are asynchronous in Netty. For example, the following code might close the connection even before a message is sent:','send message',1,'https://netty.io/wiki/user-guide-for-4.x.html',''),(3966,'netty','Therefore, you need to call the close() method after the ChannelFuture is complete, which was returned by the write() method, and it notifies its listeners when the write operation has been done. Please note that, close() also might not close the connection immediately, and it returns a ChannelFuture.','call close() method',0,'',''),(3967,'netty','Therefore, you need to call the close() method after the ChannelFuture is complete, which was returned by the write() method, and it notifies its listeners when the write operation has been done. Please note that, close() also might not close the connection immediately, and it returns a ChannelFuture.','return ChannelFuture',0,'',''),(3968,'netty','How do we get notified when a write request is finished then? This is as simple as adding a ChannelFutureListener to the returned ChannelFuture. Here, we created a new anonymous ChannelFutureListener which closes the Channel when the operation is done.','add ChannelFutureListener to returned ChannelFuture',0,'',''),(3969,'netty','How do we get notified when a write request is finished then? This is as simple as adding a ChannelFutureListener to the returned ChannelFuture. Here, we created a new anonymous ChannelFutureListener which closes the Channel when the operation is done.','create new anonymous ChannelFutureListener',0,'',''),(3970,'netty','Alternatively, you could simplify the code using a pre-defined listener:','use pre-defined listener',1,'https://netty.io/wiki/user-guide-for-4.x.html',''),(3971,'netty','To test if our time server works as expected, you can use the UNIX rdate command:','use UNIX rdate command',1,'https://netty.io/wiki/user-guide-for-4.x.html','wiki-h3-9'),(3972,'netty','where  is the port number you specified in the main() method and  is usually localhost.','specify port number in main() method',0,'',''),(3973,'netty','Unlike DISCARD and ECHO servers, we need a client for the TIME protocol because a human cannot translate a 32-bit binary data into a date on a calendar. In this section, we discuss how to make sure the server works correctly and learn how to write a client with Netty.','write client with netty',0,'',''),(3974,'netty','The biggest and only difference between a server and a client in Netty is that different Bootstrap and Channel implementations are used. Please take a look at the following code:','use different bootstrap',1,'https://netty.io/wiki/user-guide-for-4.x.html','wiki-h3-10'),(3975,'netty','The biggest and only difference between a server and a client in Netty is that different Bootstrap and Channel implementations are used. Please take a look at the following code:','use channel implementations',1,'https://netty.io/wiki/user-guide-for-4.x.html','wiki-h3-10'),(3976,'netty','As you can see, it is not really different from the the server-side code. What about the ChannelHandler implementation? It should receive a 32-bit integer from the server, translate it into a human readable format, print the translated time, and close the connection:','receive 32-bit integer from server',1,'https://netty.io/wiki/user-guide-for-5.x.html','wiki-h3-11'),(3977,'netty','As you can see, it is not really different from the the server-side code. What about the ChannelHandler implementation? It should receive a 32-bit integer from the server, translate it into a human readable format, print the translated time, and close the connection:','translate  into human readable format',1,'https://netty.io/wiki/user-guide-for-5.x.html','wiki-h3-11'),(3978,'netty','As you can see, it is not really different from the the server-side code. What about the ChannelHandler implementation? It should receive a 32-bit integer from the server, translate it into a human readable format, print the translated time, and close the connection:','print translated time',1,'https://netty.io/wiki/user-guide-for-5.x.html','wiki-h3-11'),(3979,'netty','It looks very simple and does not look any different from the server side example. However, this handler sometimes will refuse to work raising an IndexOutOfBoundsException. We discuss why this happens in the next section.','raise IndexOutOfBoundsException',0,'',''),(3980,'netty','In a stream-based transport such as TCP/IP, received data is stored into a socket receive buffer. Unfortunately, the buffer of a stream-based transport is not a queue of packets but a queue of bytes. It means, even if you sent two messages as two independent packets, an operating system will not treat them as two messages but as just a bunch of bytes. Therefore, there is no guarantee that what you read is exactly what your remote peer wrote. For example, let us assume that the TCP/IP stack of an operating system has received three packets:','receive packets',0,'',''),(3981,'netty','In a stream-based transport such as TCP/IP, received data is stored into a socket receive buffer. Unfortunately, the buffer of a stream-based transport is not a queue of packets but a queue of bytes. It means, even if you sent two messages as two independent packets, an operating system will not treat them as two messages but as just a bunch of bytes. Therefore, there is no guarantee that what you read is exactly what your remote peer wrote. For example, let us assume that the TCP/IP stack of an operating system has received three packets:','receive operating system',0,'',''),(3982,'netty','Because of this general property of a stream-based protocol, there\'s high chance of reading them in the following fragmented form in your application:','read  in fragmented form',0,'',''),(3983,'netty','The simplistic solution is to create an internal cumulative buffer and wait until all 4 bytes are received into the internal buffer. The following is the modified TimeClientHandler implementation that fixes the problem:','create internal cumulative buffer',1,'https://netty.io/wiki/user-guide-for-4.x.html','wiki-h4-13'),(3984,'netty','The simplistic solution is to create an internal cumulative buffer and wait until all 4 bytes are received into the internal buffer. The following is the modified TimeClientHandler implementation that fixes the problem:','receive bytes into internal buffer',1,'https://netty.io/wiki/user-guide-for-4.x.html','wiki-h4-13'),(3985,'netty','The simplistic solution is to create an internal cumulative buffer and wait until all 4 bytes are received into the internal buffer. The following is the modified TimeClientHandler implementation that fixes the problem:','fix modified TimeClientHandler implementation',1,'https://netty.io/wiki/user-guide-for-4.x.html','wiki-h4-13'),(3986,'netty','Although the first solution has resolved the problem with the TIME client, the modified handler does not look that clean. Imagine a more complicated protocol which is composed of multiple fields such as a variable length field. Your ChannelHandler implementation will become unmaintainable very quickly.','resolve  with TIME client',0,'',''),(3987,'netty','Although the first solution has resolved the problem with the TIME client, the modified handler does not look that clean. Imagine a more complicated protocol which is composed of multiple fields such as a variable length field. Your ChannelHandler implementation will become unmaintainable very quickly.','compose complicated protocol of multiple fields',0,'',''),(3988,'netty','As you may have noticed, you can add more than one ChannelHandler to a ChannelPipeline, and therefore, you can split one monolithic ChannelHandler into multiple modular ones to reduce the complexity of your application. For example, you could split TimeClientHandler into two handlers:','add ChannelHandler to ChannelPipeline',0,'',''),(3989,'netty','As you may have noticed, you can add more than one ChannelHandler to a ChannelPipeline, and therefore, you can split one monolithic ChannelHandler into multiple modular ones to reduce the complexity of your application. For example, you could split TimeClientHandler into two handlers:','split monolithic ChannelHandler',0,'',''),(3990,'netty','As you may have noticed, you can add more than one ChannelHandler to a ChannelPipeline, and therefore, you can split one monolithic ChannelHandler into multiple modular ones to reduce the complexity of your application. For example, you could split TimeClientHandler into two handlers:','split TimeClientHandler into handlers',0,'',''),(3991,'netty','Fortunately, Netty provides an extensible class which helps you write the first one out of the box:','provide extensible class',1,'https://netty.io/wiki/user-guide-for-4.x.html','wiki-h4-14'),(3992,'netty','Fortunately, Netty provides an extensible class which helps you write the first one out of the box:','write first one out_of box',1,'https://netty.io/wiki/user-guide-for-4.x.html','wiki-h4-14'),(3993,'netty','Now that we have another handler to insert into the ChannelPipeline, we should modify the ChannelInitializer implementation in the TimeClient:','modify ChannelInitializer implementation in TimeClient',1,'https://netty.io/wiki/user-guide-for-4.x.html','wiki-h4-14'),(3994,'netty','Now that we have another handler to insert into the ChannelPipeline, we should modify the ChannelInitializer implementation in the TimeClient:','insert  into ChannelPipeline',1,'https://netty.io/wiki/user-guide-for-4.x.html','wiki-h4-14'),(3995,'netty','Additionally, Netty provides out-of-the-box decoders which enables you to implement most protocols very easily and helps you avoid from ending up with a monolithic unmaintainable handler implementation. Please refer to the following packages for more detailed examples:','provide out-of-the-box decoders',0,'',''),(3996,'netty','Additionally, Netty provides out-of-the-box decoders which enables you to implement most protocols very easily and helps you avoid from ending up with a monolithic unmaintainable handler implementation. Please refer to the following packages for more detailed examples:','implement most protocols',0,'',''),(3997,'netty','Additionally, Netty provides out-of-the-box decoders which enables you to implement most protocols very easily and helps you avoid from ending up with a monolithic unmaintainable handler implementation. Please refer to the following packages for more detailed examples:','enable out-of-the-box decoders',0,'',''),(3998,'netty','All the examples we have reviewed so far used a ByteBuf as a primary data structure of a protocol message. In this section, we will improve the TIME protocol client and server example to use a POJO instead of a ByteBuf.','use ByteBuf as primary data structure',0,'',''),(3999,'netty','All the examples we have reviewed so far used a ByteBuf as a primary data structure of a protocol message. In this section, we will improve the TIME protocol client and server example to use a POJO instead of a ByteBuf.','use POJO instead_of ByteBuf',0,'',''),(4000,'netty','The advantage of using a POJO in your ChannelHandlers is obvious; your handler becomes more maintainable and reusable by separating the code which extracts information from ByteBuf out from the handler. In the TIME client and server examples, we read only one 32-bit integer and it is not a major issue to use ByteBuf directly. However, you will find it is necessary to make the separation as you implement a real world protocol.','use POJO in ChannelHandler',0,'',''),(4001,'netty','The advantage of using a POJO in your ChannelHandlers is obvious; your handler becomes more maintainable and reusable by separating the code which extracts information from ByteBuf out from the handler. In the TIME client and server examples, we read only one 32-bit integer and it is not a major issue to use ByteBuf directly. However, you will find it is necessary to make the separation as you implement a real world protocol.','separate code',0,'',''),(4002,'netty','The advantage of using a POJO in your ChannelHandlers is obvious; your handler becomes more maintainable and reusable by separating the code which extracts information from ByteBuf out from the handler. In the TIME client and server examples, we read only one 32-bit integer and it is not a major issue to use ByteBuf directly. However, you will find it is necessary to make the separation as you implement a real world protocol.','read 32-bit integer in TIME client',0,'',''),(4003,'netty','The advantage of using a POJO in your ChannelHandlers is obvious; your handler becomes more maintainable and reusable by separating the code which extracts information from ByteBuf out from the handler. In the TIME client and server examples, we read only one 32-bit integer and it is not a major issue to use ByteBuf directly. However, you will find it is necessary to make the separation as you implement a real world protocol.','read 32-bit integer in server examples',0,'',''),(4004,'netty','The advantage of using a POJO in your ChannelHandlers is obvious; your handler becomes more maintainable and reusable by separating the code which extracts information from ByteBuf out from the handler. In the TIME client and server examples, we read only one 32-bit integer and it is not a major issue to use ByteBuf directly. However, you will find it is necessary to make the separation as you implement a real world protocol.','use ByteBuf',0,'',''),(4005,'netty','The advantage of using a POJO in your ChannelHandlers is obvious; your handler becomes more maintainable and reusable by separating the code which extracts information from ByteBuf out from the handler. In the TIME client and server examples, we read only one 32-bit integer and it is not a major issue to use ByteBuf directly. However, you will find it is necessary to make the separation as you implement a real world protocol.','implement real world protocol',0,'',''),(4006,'netty','First, let us define a new type called UnixTime.','define new type',1,'https://netty.io/wiki/user-guide-for-4.x.html','wiki-h3-15'),(4007,'netty','First, let us define a new type called UnixTime.','call UnixTime',1,'https://netty.io/wiki/user-guide-for-4.x.html','wiki-h3-15'),(4008,'netty','We can now revise the TimeDecoder to produce a UnixTime instead of a ByteBuf.','produce UnixTime instead_of ByteBuf',1,'https://netty.io/wiki/user-guide-for-4.x.html','wiki-h3-15'),(4009,'netty','Much simpler and elegant, right? The same technique can be applied on the server side. Let us update the TimeServerHandler first this time:','apply same technique on server side',1,'https://netty.io/wiki/user-guide-for-4.x.html','wiki-h3-15'),(4010,'netty','Much simpler and elegant, right? The same technique can be applied on the server side. Let us update the TimeServerHandler first this time:','update TimeServerHandler',1,'https://netty.io/wiki/user-guide-for-4.x.html','wiki-h3-15'),(4011,'netty','Now, the only missing piece is an encoder, which is an implementation of ChannelHandler that translates a UnixTime back into a ByteBuf. It\'s much simpler than writing a decoder because there\'s no need to deal with packet fragmentation and assembly when encoding a message.','write decoder',1,'https://netty.io/wiki/user-guide-for-5.x.html','wiki-h3-16'),(4012,'netty','Now, the only missing piece is an encoder, which is an implementation of ChannelHandler that translates a UnixTime back into a ByteBuf. It\'s much simpler than writing a decoder because there\'s no need to deal with packet fragmentation and assembly when encoding a message.','encode message',1,'https://netty.io/wiki/user-guide-for-5.x.html','wiki-h3-16'),(4013,'netty','First, we pass the original ChannelPromise as-is so that Netty marks it as success or failure when the encoded data is actually written out to the wire.','pass original ChannelPromise as-is',0,'',''),(4014,'netty','First, we pass the original ChannelPromise as-is so that Netty marks it as success or failure when the encoded data is actually written out to the wire.','mark  as failure',0,'',''),(4015,'netty','First, we pass the original ChannelPromise as-is so that Netty marks it as success or failure when the encoded data is actually written out to the wire.','mark  as success',0,'',''),(4016,'netty','Second, we did not call ctx.flush(). There is a separate handler method void flush(ChannelHandlerContext ctx) which is purposed to override the flush() operation.','override flush() operation',0,'',''),(4017,'netty','The last task left is to insert a TimeEncoder into the ChannelPipeline on the server side before the TimeServerHandler, and it is left as a trivial exercise.','insert TimeEncoder into ChannelPipeline',0,'',''),(4018,'netty','The last task left is to insert a TimeEncoder into the ChannelPipeline on the server side before the TimeServerHandler, and it is left as a trivial exercise.','insert TimeEncoder before TimeServerHandler',0,'',''),(4019,'netty','Shutting down a Netty application is usually as simple as shutting down all EventLoopGroups you created via shutdownGracefully(). It returns a Future that notifies you when the EventLoopGroup has been terminated completely and all Channels that belong to the group have been closed.','create  via shutdownGracefully()',0,'',''),(4020,'netty','Shutting down a Netty application is usually as simple as shutting down all EventLoopGroups you created via shutdownGracefully(). It returns a Future that notifies you when the EventLoopGroup has been terminated completely and all Channels that belong to the group have been closed.','return future',0,'',''),(4021,'netty','In this chapter, we had a quick tour of Netty with a demonstration on how to write a fully working network application on top of Netty.','write working network application on_top_of netty',0,'',''),(4022,'netty','This page lists the organizations who adopted Netty in their projects or products. Make sure to sort the list alphabetically and keep the list up-to-date.','list organizations',0,'',''),(4023,'netty','This page lists the organizations who adopted Netty in their projects or products. Make sure to sort the list alphabetically and keep the list up-to-date.','sort list',0,'',''),(4024,'netty','Netty 5 introduces a new Buffer API, that is simpler and safer to use than ByteBuf.\nFor details, see the pull request #11347.\nIn summary, the new API has the following headline differences:','use  than ByteBuf',0,'',''),(4025,'netty','ChannelInboundHandlerAdapter, ChannelOutboundHandlerAdapter, and ChannelDuplexHandlerAdapter have been removed and replaced by ChannelHandlerAdapter.','remove ChannelInboundHandlerAdapter',0,'',''),(4026,'netty','ChannelInboundHandlerAdapter, ChannelOutboundHandlerAdapter, and ChannelDuplexHandlerAdapter have been removed and replaced by ChannelHandlerAdapter.','remove ChannelOutboundHandlerAdapter',0,'',''),(4027,'netty','ChannelInboundHandlerAdapter, ChannelOutboundHandlerAdapter, and ChannelDuplexHandlerAdapter have been removed and replaced by ChannelHandlerAdapter.','remove ChannelDuplexHandlerAdapter',0,'',''),(4028,'netty','ChannelInboundHandlerAdapter, ChannelOutboundHandlerAdapter, and ChannelDuplexHandlerAdapter have been removed and replaced by ChannelHandlerAdapter.','replace ChannelInboundHandlerAdapter',0,'',''),(4029,'netty','ChannelInboundHandlerAdapter, ChannelOutboundHandlerAdapter, and ChannelDuplexHandlerAdapter have been removed and replaced by ChannelHandlerAdapter.','replace ChannelOutboundHandlerAdapter',0,'',''),(4030,'netty','ChannelInboundHandlerAdapter, ChannelOutboundHandlerAdapter, and ChannelDuplexHandlerAdapter have been removed and replaced by ChannelHandlerAdapter.','replace ChannelDuplexHandlerAdapter',0,'',''),(4031,'netty','Because it is now impossible to tell if a handler is an inbound handler or an outbound handler, CombinedChannelDuplexHandler has been replaced by ChannelHandlerAppender.','replace CombinedChannelDuplexHandler',0,'',''),(4032,'netty','If you are using SimpleChannelInboundHandler, you have to rename channelRead0() to messageReceived().','use SimpleChannelInboundHandler',0,'',''),(4033,'netty','If you are using SimpleChannelInboundHandler, you have to rename channelRead0() to messageReceived().','rename channelRead0() to messageReceived()',0,'',''),(4034,'netty','All ChannelHandler outbound methods (except flush and read) now return a Future. This ensures proper propagation and chaining.\nBeside this we also renamed exceptionCaught(...) to channelExceptionCaught(...) to make it clear that this handles inbound exceptions.','rename exceptionCaught(...) to channelExceptionCaught(...)',0,'',''),(4035,'netty','All ChannelHandler outbound methods (except flush and read) now return a Future. This ensures proper propagation and chaining.\nBeside this we also renamed exceptionCaught(...) to channelExceptionCaught(...) to make it clear that this handles inbound exceptions.','handle inbound exceptions',0,'',''),(4036,'netty','It\'s now possible to fire user / custom events in both directions through the pipeline. For inbound events you would use fireChannelInboundEvent(...) (replacement of fireUserEventTriggered(...) and for outbound events sendOutboundEvent(...).\nBoth of these can be intercepted by methods defined in ChannelHandler as usual.','use fireChannelInboundEvent(...) ( replacement for inbound events',0,'',''),(4037,'netty','It\'s now possible to fire user / custom events in both directions through the pipeline. For inbound events you would use fireChannelInboundEvent(...) (replacement of fireUserEventTriggered(...) and for outbound events sendOutboundEvent(...).\nBoth of these can be intercepted by methods defined in ChannelHandler as usual.','define  in ChannelHandler usual',0,'',''),(4038,'netty','Netty5 has support for half-closure build in its core now. For this ChannelHandler.shutdown and ChannelHandler.channelShutdown were introduced. Beside this also Channel.isShutdown(...) and ChannelOutboundInvoker.shutdown(...) where added. This replace the old DuplexChannel abstraction, which was completely removed. For more details see the pull request #12468.','introduce ChannelHandler.shutdown',0,'',''),(4039,'netty','Netty5 has support for half-closure build in its core now. For this ChannelHandler.shutdown and ChannelHandler.channelShutdown were introduced. Beside this also Channel.isShutdown(...) and ChannelOutboundInvoker.shutdown(...) where added. This replace the old DuplexChannel abstraction, which was completely removed. For more details see the pull request #12468.','introduce ChannelHandler.channelShutdown',0,'',''),(4040,'netty','Netty5 has support for half-closure build in its core now. For this ChannelHandler.shutdown and ChannelHandler.channelShutdown were introduced. Beside this also Channel.isShutdown(...) and ChannelOutboundInvoker.shutdown(...) where added. This replace the old DuplexChannel abstraction, which was completely removed. For more details see the pull request #12468.','replace old DuplexChannel abstraction',0,'',''),(4041,'netty','Netty5 has support for half-closure build in its core now. For this ChannelHandler.shutdown and ChannelHandler.channelShutdown were introduced. Beside this also Channel.isShutdown(...) and ChannelOutboundInvoker.shutdown(...) where added. This replace the old DuplexChannel abstraction, which was completely removed. For more details see the pull request #12468.','remove old DuplexChannel abstraction',0,'',''),(4042,'netty','We Changed ChannelHandlerContext to not extend AttributeMap anymore. In the case of you using attributes you should directly use Channel which still extends AttributeMap.','use attributes',0,'',''),(4043,'netty','We Changed ChannelHandlerContext to not extend AttributeMap anymore. In the case of you using attributes you should directly use Channel which still extends AttributeMap.','use channel in case',0,'',''),(4044,'netty','We Changed ChannelHandlerContext to not extend AttributeMap anymore. In the case of you using attributes you should directly use Channel which still extends AttributeMap.','extend AttributeMap',0,'',''),(4045,'netty','We Changed ChannelHandlerContext to not extend AttributeMap anymore. In the case of you using attributes you should directly use Channel which still extends AttributeMap.','extend channel',0,'',''),(4046,'netty','In netty 4.x we added the ability to add ChannelHandlers to a ChannelPipeline with an explicit EventExecutorGroup. While this seemed like a good idea it turned out that it has quite some problems when it comes to life-cycles:','add ChannelHandler',0,'',''),(4047,'netty','With this in mind we realised that really what the user mostly want is to have the incoming messages handled by another thread to process the business-logic. This is better be done in a custom implementation provided by the user as the user has a better handle on when things can be destroyed or not.','process business-logic',0,'',''),(4048,'netty','In netty 5.x we added the executor() method to ChannelOutboundInvoker and as this method returns EventExecutor we did decide to remove the eventLoop() method from Channel and just override executor() to return EventLoop for Channel.','add executor() method to ChannelOutboundInvoker',0,'',''),(4049,'netty','In netty 5.x we added the executor() method to ChannelOutboundInvoker and as this method returns EventExecutor we did decide to remove the eventLoop() method from Channel and just override executor() to return EventLoop for Channel.','remove eventLoop() method from channel',0,'',''),(4050,'netty','In netty 5.x we added the executor() method to ChannelOutboundInvoker and as this method returns EventExecutor we did decide to remove the eventLoop() method from Channel and just override executor() to return EventLoop for Channel.','override executor()',0,'',''),(4051,'netty','In netty 5.x we added the executor() method to ChannelOutboundInvoker and as this method returns EventExecutor we did decide to remove the eventLoop() method from Channel and just override executor() to return EventLoop for Channel.','return EventLoop for channel',0,'',''),(4052,'netty','It\'s now possible to check if a Channel sub-type is compatible with the EventLoopGroup / EventLoop before trying to use it. This can help to select the correct Channel sub-type.','select correct channel sub-type',0,'',''),(4053,'netty','New methods were added to the EventLoop interface to allow registration and deregistration of Channels. These should not be used by the user directly but by Channel implementations itself.','add new methods to EventLoop interface',0,'',''),(4054,'netty','The Channel.Unsafe interface was completely removed so its not possible for the end-user to mess-up internals.','remove possible internals',0,'',''),(4055,'netty','The Channel.Unsafe interface was completely removed so its not possible for the end-user to mess-up internals.','remove Channel.Unsafe interface',0,'',''),(4056,'netty','The ChannelOutboundBuffer is an implementation details of our AbstractChannel implementation and so was removed for the Channel itself completely.','remove ChannelOutboundBuffer for channel',0,'',''),(4057,'netty','We removed the Channel.beforeBeforeWritable() method as it was not used at all and renamed Channel.bytesBeforeUnwritable() to Channel.writableBytes.','remove Channel.beforeBeforeWritable() method',0,'',''),(4058,'netty','We removed the Channel.beforeBeforeWritable() method as it was not used at all and renamed Channel.bytesBeforeUnwritable() to Channel.writableBytes.','rename Channel.bytesBeforeUnwritable() to Channel.writableBytes',0,'',''),(4059,'netty','The support for ProgressiveFuture / ProgressivePromise was completely removed in netty 5. The reason for this was that while it may have been useful sometimes it also did require that all handlers in the pipeline take special action here if they did chain up promises. This was not really the case and is quite cumbersome to do in reality.','remove progressive promise',0,'',''),(4060,'netty','Due the stated problems we decided that it would be best to just remove this feature all together as there was not much usage of this feature anyway. It is better to not support something at all than have something only work \"sometimes\". This also means there is less code to maintain.','remove feature',0,'',''),(4061,'netty','In netty 4.1.x it was possible to use the voidPromise() method to obtain a special ChannelPromise implementation that could be used for various IO operations (like write) to reduce the number of objects created. While the motivation of this feature was good it turned out that this special case of a ChannelPromise did actually bring a lot of problems:','use voidPromise() method',0,'',''),(4062,'netty','In netty 4.1.x it was possible to use the voidPromise() method to obtain a special ChannelPromise implementation that could be used for various IO operations (like write) to reduce the number of objects created. While the motivation of this feature was good it turned out that this special case of a ChannelPromise did actually bring a lot of problems:','obtain special ChannelPromise implementation',0,'',''),(4063,'netty','In netty 4.1.x it was possible to use the voidPromise() method to obtain a special ChannelPromise implementation that could be used for various IO operations (like write) to reduce the number of objects created. While the motivation of this feature was good it turned out that this special case of a ChannelPromise did actually bring a lot of problems:','use special ChannelPromise implementation for various IO operations',0,'',''),(4064,'netty','All our compression implementations were changed to make use of the new Compression API to make it easier to re-use in different codecs without the need to create an extra EmbeddedChannel.','create extra EmbeddedChannel',0,'',''),(4065,'netty','All our compression implementations were changed to make use of the new Compression API to make it easier to re-use in different codecs without the need to create an extra EmbeddedChannel.','change compression',0,'',''),(4066,'netty','To slim the code base down and ease the maintenance burden, the following codecs and handlers have been moved to Netty Contrib:','move handlers to netty Contrib',0,'',''),(4067,'netty','To slim the code base down and ease the maintenance burden, the following codecs and handlers have been moved to Netty Contrib:','move following codecs to netty Contrib',0,'',''),(4068,'netty','Make sure the list contains only open source projects documented in English and the list is sorted alphabetically. Remove unmaintained projects (no commit activity for last 12 months.)','document  in English',0,'',''),(4069,'netty','Make sure the list contains only open source projects documented in English and the list is sorted alphabetically. Remove unmaintained projects (no commit activity for last 12 months.)','sort list',0,'',''),(4070,'netty','Make sure the list contains only open source projects documented in English and the list is sorted alphabetically. Remove unmaintained projects (no commit activity for last 12 months.)','remove unmaintained projects',0,'',''),(4071,'netty','Please read this until the user guide is moved to the wiki.','move user guide to wiki',0,'',''),(4072,'netty','There is a bug in section 1.6 Writing a Time Client, the TimeClientHandler.java should transfer received signed int to \"unsigned int\".','write Time client',1,'https://netty.io/wiki/user-guide-for-3.x.html','wiki-h2-1'),(4073,'netty','Although we did our best to keep the backward compatibility from 4.0, 4.1 contains multiple additions which might not be fully backward-compatible with 4.0. Please make sure to recompile your application against the new version.','recompile application against new version',0,'',''),(4074,'netty','When you recompile your application, you might find some deprecation warnings. Please make sure to fix them all by using the suggested alternative, so that you have less trouble when upgrading to the next version.','recompile application',0,'',''),(4075,'netty','When you recompile your application, you might find some deprecation warnings. Please make sure to fix them all by using the suggested alternative, so that you have less trouble when upgrading to the next version.','find deprecation warnings',0,'',''),(4076,'netty','When you recompile your application, you might find some deprecation warnings. Please make sure to fix them all by using the suggested alternative, so that you have less trouble when upgrading to the next version.','use suggested alternative',0,'',''),(4077,'netty','we decided to support Android (4.0 or above) officially.','support Android',0,'',''),(4078,'netty','However, we do not have an automated testsuite for Android yet. If you find any issues with Android, please feel free to file an issue. Please also consider contributing to the project to make Android tests a part of the build process.','find issues with android',0,'',''),(4079,'netty','Both Channel and ChannelHandlerContext implement the interface AttributeMap to enable a user to attach one or more user-defined attributes to them. What sometimes made a user confused was that a Channel and a ChannelHandlerContext had its own storage for the user-defined attributes. For example, even if you put an attribute \'KEY_X\' via Channel.attr(KEY_X).set(valueX), you will never find it via ChannelHandlerContext.attr(KEY_X).get() and vice versa. This behavior is not only confusing but also is waste of memory.','implement interface AttributeMap',0,'',''),(4080,'netty','Both Channel and ChannelHandlerContext implement the interface AttributeMap to enable a user to attach one or more user-defined attributes to them. What sometimes made a user confused was that a Channel and a ChannelHandlerContext had its own storage for the user-defined attributes. For example, even if you put an attribute \'KEY_X\' via Channel.attr(KEY_X).set(valueX), you will never find it via ChannelHandlerContext.attr(KEY_X).get() and vice versa. This behavior is not only confusing but also is waste of memory.','enable user',0,'',''),(4081,'netty','Both Channel and ChannelHandlerContext implement the interface AttributeMap to enable a user to attach one or more user-defined attributes to them. What sometimes made a user confused was that a Channel and a ChannelHandlerContext had its own storage for the user-defined attributes. For example, even if you put an attribute \'KEY_X\' via Channel.attr(KEY_X).set(valueX), you will never find it via ChannelHandlerContext.attr(KEY_X).get() and vice versa. This behavior is not only confusing but also is waste of memory.','attach user-defined attributes',0,'',''),(4082,'netty','To address this issue, we decided to keep only one map per Channel internally. AttributeMap always uses AttributeKey as its key. AttributeKey ensures uniqueness between each key, and thus there\'s no point of having more than one attribute map per Channel. As long as a user defines its own AttributeKey as a private static final field of his or her ChannelHandler, there will be no risk of duplicate keys.','use AttributeKey as key',0,'',''),(4083,'netty','To address this issue, we decided to keep only one map per Channel internally. AttributeMap always uses AttributeKey as its key. AttributeKey ensures uniqueness between each key, and thus there\'s no point of having more than one attribute map per Channel. As long as a user defines its own AttributeKey as a private static final field of his or her ChannelHandler, there will be no risk of duplicate keys.','define own AttributeKey as private static final field',0,'',''),(4084,'netty','Previously, it was not easy to find where the buffer leak occurred, and the leak warning was not very helpful. We now have an advanced leak reporting mechanism which can be enabled at the cost of increased overhead.','enable advanced leak reporting mechanism at cost',0,'',''),(4085,'netty','See Reference counted objects for more information. This feature also has been backported to 4.0.14.Final due to its importance.','count objects for more information',0,'',''),(4086,'netty','In 4.x, UnpooledByteBufAllocator was the default allocator in spite of its limitation. Now that PooledByteBufAllocator has been in the wild for a while and we have advanced buffer leak tracking mechanism, it is time to make it a new default.','track mechanism',0,'',''),(4087,'netty','Every Channel now has a globally unique ID which is generated from:','generate globally unique ID',0,'',''),(4088,'netty','The ID of a Channel can be obtained using the Channel.id() method.','use Channel.id() method',0,'',''),(4089,'netty','The ID of a Channel can be obtained using the Channel.id() method.','obtain ID of channel',0,'',''),(4090,'netty','readInbound() and readOutbound() in EmbeddedChannel return an ad-hoc type parameter so you do not need to downcast their return values. This will reduce the verbosity of your unit test code quite a bit.','return ad-hoc type parameter',1,'https://netty.io/wiki/new-and-noteworthy-in-4.1.html','wiki-h3-9'),(4091,'netty','Some applications require a user to run his or her task in a given Executor. 4.x required a user to specify ThreadFactory when creating an event loop, but not anymore.','run his her task in given executor',0,'',''),(4092,'netty','Some applications require a user to run his or her task in a given Executor. 4.x required a user to specify ThreadFactory when creating an event loop, but not anymore.','specify ThreadFactory',0,'',''),(4093,'netty','Some applications require a user to run his or her task in a given Executor. 4.x required a user to specify ThreadFactory when creating an event loop, but not anymore.','create event loop',0,'',''),(4094,'netty','Some types such as AttributeKey were unfriendly to the applications that run in a container environment, but not anymore.','run applications in container environment',0,'',''),(4095,'netty','The logic that calculates the new capacity of the expanded ByteBuf has been moved from AbstractByteBuf to ByteBufAllocator because ByteBufAllocator knows better about the capacity calculation of the buffers it manages.','calculate new capacity of expanded ByteBuf',0,'',''),(4096,'netty','The logic that calculates the new capacity of the expanded ByteBuf has been moved from AbstractByteBuf to ByteBufAllocator because ByteBufAllocator knows better about the capacity calculation of the buffers it manages.','calculate logic of expanded ByteBuf',0,'',''),(4097,'netty','The logic that calculates the new capacity of the expanded ByteBuf has been moved from AbstractByteBuf to ByteBufAllocator because ByteBufAllocator knows better about the capacity calculation of the buffers it manages.','move logic from AbstractByteBuf',0,'',''),(4098,'netty','The logic that calculates the new capacity of the expanded ByteBuf has been moved from AbstractByteBuf to ByteBufAllocator because ByteBufAllocator knows better about the capacity calculation of the buffers it manages.','move logic to ByteBufAllocator',0,'',''),(4099,'netty','The logic that calculates the new capacity of the expanded ByteBuf has been moved from AbstractByteBuf to ByteBufAllocator because ByteBufAllocator knows better about the capacity calculation of the buffers it manages.','manage buffers',0,'',''),(4100,'netty','For instance, the HTTP codec and STOMP codec in Netty use AsciiString to represent the header names. Because AsciiString does not have any conversion cost when encoding it into a ByteBuf, it guarantees better performance than using String.','use AsciiString for instance',0,'',''),(4101,'netty','For instance, the HTTP codec and STOMP codec in Netty use AsciiString to represent the header names. Because AsciiString does not have any conversion cost when encoding it into a ByteBuf, it guarantees better performance than using String.','encode  into ByteBuf',0,'',''),(4102,'netty','For instance, the HTTP codec and STOMP codec in Netty use AsciiString to represent the header names. Because AsciiString does not have any conversion cost when encoding it into a ByteBuf, it guarantees better performance than using String.','use string',0,'',''),(4103,'netty','TextHeaders provides a generic data structure for HTTP header-like string multimaps. HttpHeaders also has been rewritten using TextHeaders.','provide generic data structure for HTTP header-like string multimaps',0,'',''),(4104,'netty','TextHeaders provides a generic data structure for HTTP header-like string multimaps. HttpHeaders also has been rewritten using TextHeaders.','use TextHeaders',0,'',''),(4105,'netty','MessageAggregator provides generic functionality that aggregates multiple small messages into a larger one, just like HttpObjectAggregator does. HttpObjectAggregator also has been rewritten using MessageAggregator.','provide generic functionality',0,'',''),(4106,'netty','MessageAggregator provides generic functionality that aggregates multiple small messages into a larger one, just like HttpObjectAggregator does. HttpObjectAggregator also has been rewritten using MessageAggregator.','use MessageAggregator',0,'',''),(4107,'netty','In 4.0, there was no way to reject an oversized HTTP message before a client sends the content even if 100-continue header was present.','send content',0,'',''),(4108,'netty','This release adds an overridable method called handleOversizedMessage so that a user can perform his or her preferred task. By default, it responds with \'413 Request Entity Too Large\' response and closed the connection.','call handleOversizedMessage',0,'',''),(4109,'netty','This release adds an overridable method called handleOversizedMessage so that a user can perform his or her preferred task. By default, it responds with \'413 Request Entity Too Large\' response and closed the connection.','perform his her preferred task',0,'',''),(4110,'netty','ChunkedInput has two new methods; progress() and length() which return the progress of its transfer and the total length of the stream respectively. ChunkedWriteHandler uses this information to notify ChannelProgressiveFutureListener.','return total length of stream',0,'',''),(4111,'netty','ChunkedInput has two new methods; progress() and length() which return the progress of its transfer and the total length of the stream respectively. ChunkedWriteHandler uses this information to notify ChannelProgressiveFutureListener.','return total length of transfer',0,'',''),(4112,'netty','ChunkedInput has two new methods; progress() and length() which return the progress of its transfer and the total length of the stream respectively. ChunkedWriteHandler uses this information to notify ChannelProgressiveFutureListener.','return progress of stream',0,'',''),(4113,'netty','ChunkedInput has two new methods; progress() and length() which return the progress of its transfer and the total length of the stream respectively. ChunkedWriteHandler uses this information to notify ChannelProgressiveFutureListener.','return progress of transfer',0,'',''),(4114,'netty','ChunkedInput has two new methods; progress() and length() which return the progress of its transfer and the total length of the stream respectively. ChunkedWriteHandler uses this information to notify ChannelProgressiveFutureListener.','return progress() of stream',0,'',''),(4115,'netty','ChunkedInput has two new methods; progress() and length() which return the progress of its transfer and the total length of the stream respectively. ChunkedWriteHandler uses this information to notify ChannelProgressiveFutureListener.','return progress() of transfer',0,'',''),(4116,'netty','ChunkedInput has two new methods; progress() and length() which return the progress of its transfer and the total length of the stream respectively. ChunkedWriteHandler uses this information to notify ChannelProgressiveFutureListener.','return length() of stream',0,'',''),(4117,'netty','ChunkedInput has two new methods; progress() and length() which return the progress of its transfer and the total length of the stream respectively. ChunkedWriteHandler uses this information to notify ChannelProgressiveFutureListener.','return length() of transfer',0,'',''),(4118,'netty','ChunkedInput has two new methods; progress() and length() which return the progress of its transfer and the total length of the stream respectively. ChunkedWriteHandler uses this information to notify ChannelProgressiveFutureListener.','use information',0,'',''),(4119,'netty','These two classes have been renamed to SnappyFrameEncoder and SnappyFrameDecoder. The old classes were marked as deprecated and they are actually the subclasses of the new ones.','rename classes to SnappyFrameEncoder',0,'',''),(4120,'netty','These two classes have been renamed to SnappyFrameEncoder and SnappyFrameDecoder. The old classes were marked as deprecated and they are actually the subclasses of the new ones.','rename classes to SnappyFrameDecoder',0,'',''),(4121,'netty','These two classes have been renamed to SnappyFrameEncoder and SnappyFrameDecoder. The old classes were marked as deprecated and they are actually the subclasses of the new ones.','mark old classes as deprecated',0,'',''),(4122,'netty','Nowadays we use general purpose applications or libraries to communicate with each other. For example, we often use an HTTP client library to retrieve information from a web server and to invoke a remote procedure call via web services.\nHowever, a general purpose protocol or its implementation sometimes does not scale very well. It is like how we don\'t use a general purpose HTTP server to exchange huge files, e-mail messages, and near-realtime messages such as financial information and multiplayer game data. What\'s required is a highly optimized protocol implementation that is dedicated to a special purpose. For example, you might want to implement an HTTP server that is optimized for AJAX-based chat application, media streaming, or large file transfer. You could even want to design and implement a whole new protocol that is precisely tailored to your need.\nAnother inevitable case is when you have to deal with a legacy proprietary protocol to ensure the interoperability with an old system. What matters in this case is how quickly we can implement that protocol while not sacrificing the stability and performance of the resulting application.','retrieve information from web server',0,'',''),(4123,'netty','Nowadays we use general purpose applications or libraries to communicate with each other. For example, we often use an HTTP client library to retrieve information from a web server and to invoke a remote procedure call via web services.\nHowever, a general purpose protocol or its implementation sometimes does not scale very well. It is like how we don\'t use a general purpose HTTP server to exchange huge files, e-mail messages, and near-realtime messages such as financial information and multiplayer game data. What\'s required is a highly optimized protocol implementation that is dedicated to a special purpose. For example, you might want to implement an HTTP server that is optimized for AJAX-based chat application, media streaming, or large file transfer. You could even want to design and implement a whole new protocol that is precisely tailored to your need.\nAnother inevitable case is when you have to deal with a legacy proprietary protocol to ensure the interoperability with an old system. What matters in this case is how quickly we can implement that protocol while not sacrificing the stability and performance of the resulting application.','implement HTTP server',0,'',''),(4124,'netty','Nowadays we use general purpose applications or libraries to communicate with each other. For example, we often use an HTTP client library to retrieve information from a web server and to invoke a remote procedure call via web services.\nHowever, a general purpose protocol or its implementation sometimes does not scale very well. It is like how we don\'t use a general purpose HTTP server to exchange huge files, e-mail messages, and near-realtime messages such as financial information and multiplayer game data. What\'s required is a highly optimized protocol implementation that is dedicated to a special purpose. For example, you might want to implement an HTTP server that is optimized for AJAX-based chat application, media streaming, or large file transfer. You could even want to design and implement a whole new protocol that is precisely tailored to your need.\nAnother inevitable case is when you have to deal with a legacy proprietary protocol to ensure the interoperability with an old system. What matters in this case is how quickly we can implement that protocol while not sacrificing the stability and performance of the resulting application.','design whole new protocol',0,'',''),(4125,'netty','Nowadays we use general purpose applications or libraries to communicate with each other. For example, we often use an HTTP client library to retrieve information from a web server and to invoke a remote procedure call via web services.\nHowever, a general purpose protocol or its implementation sometimes does not scale very well. It is like how we don\'t use a general purpose HTTP server to exchange huge files, e-mail messages, and near-realtime messages such as financial information and multiplayer game data. What\'s required is a highly optimized protocol implementation that is dedicated to a special purpose. For example, you might want to implement an HTTP server that is optimized for AJAX-based chat application, media streaming, or large file transfer. You could even want to design and implement a whole new protocol that is precisely tailored to your need.\nAnother inevitable case is when you have to deal with a legacy proprietary protocol to ensure the interoperability with an old system. What matters in this case is how quickly we can implement that protocol while not sacrificing the stability and performance of the resulting application.','implement whole new protocol',0,'',''),(4126,'netty','Nowadays we use general purpose applications or libraries to communicate with each other. For example, we often use an HTTP client library to retrieve information from a web server and to invoke a remote procedure call via web services.\nHowever, a general purpose protocol or its implementation sometimes does not scale very well. It is like how we don\'t use a general purpose HTTP server to exchange huge files, e-mail messages, and near-realtime messages such as financial information and multiplayer game data. What\'s required is a highly optimized protocol implementation that is dedicated to a special purpose. For example, you might want to implement an HTTP server that is optimized for AJAX-based chat application, media streaming, or large file transfer. You could even want to design and implement a whole new protocol that is precisely tailored to your need.\nAnother inevitable case is when you have to deal with a legacy proprietary protocol to ensure the interoperability with an old system. What matters in this case is how quickly we can implement that protocol while not sacrificing the stability and performance of the resulting application.','implement protocol',0,'',''),(4127,'netty','The Netty project is an effort to provide an asynchronous event-driven network application framework and tooling for the rapid development of maintainable high-performance and high-scalability protocol servers and clients.','provide tooling for rapid development',0,'',''),(4128,'netty','The Netty project is an effort to provide an asynchronous event-driven network application framework and tooling for the rapid development of maintainable high-performance and high-scalability protocol servers and clients.','provide framework for rapid development',0,'',''),(4129,'netty','In other words, Netty is an NIO client server framework that enables quick and easy development of network applications such as protocol servers and clients. It greatly simplifies and streamlines network programming such as TCP and UDP socket server development.','enable quick easy development in other words',0,'',''),(4130,'netty','In other words, Netty is an NIO client server framework that enables quick and easy development of network applications such as protocol servers and clients. It greatly simplifies and streamlines network programming such as TCP and UDP socket server development.','enable quick easy development of network applications',0,'',''),(4131,'netty','In other words, Netty is an NIO client server framework that enables quick and easy development of network applications such as protocol servers and clients. It greatly simplifies and streamlines network programming such as TCP and UDP socket server development.','enable NIO client server framework in other words',0,'',''),(4132,'netty','In other words, Netty is an NIO client server framework that enables quick and easy development of network applications such as protocol servers and clients. It greatly simplifies and streamlines network programming such as TCP and UDP socket server development.','enable NIO client server framework of network applications',0,'',''),(4133,'netty','\'Quick and easy\' does not mean that a resulting application will suffer from a maintainability or a performance issue. Netty has been designed carefully with the experiences learned from the implementation of a lot of protocols such as FTP, SMTP, HTTP, and various binary and text-based legacy protocols. As a result, Netty has succeeded to find a way to achieve ease of development, performance, stability, and flexibility without a compromise.','design netty with experiences',0,'',''),(4134,'netty','\'Quick and easy\' does not mean that a resulting application will suffer from a maintainability or a performance issue. Netty has been designed carefully with the experiences learned from the implementation of a lot of protocols such as FTP, SMTP, HTTP, and various binary and text-based legacy protocols. As a result, Netty has succeeded to find a way to achieve ease of development, performance, stability, and flexibility without a compromise.','learn  from implementation',0,'',''),(4135,'netty','\'Quick and easy\' does not mean that a resulting application will suffer from a maintainability or a performance issue. Netty has been designed carefully with the experiences learned from the implementation of a lot of protocols such as FTP, SMTP, HTTP, and various binary and text-based legacy protocols. As a result, Netty has succeeded to find a way to achieve ease of development, performance, stability, and flexibility without a compromise.','find way',0,'',''),(4136,'netty','Some users might already have found other network application frameworks that claim to have the same advantage, and you might want to ask what makes Netty so different from them. The answer is the philosophy it is built on. Netty is designed to give you the most comfortable experience both in terms of the API and the implementation from day one. It is not something tangible but you will realize that this philosophy will make your life much easier as you read this guide and play with Netty.','find other network application frameworks',0,'',''),(4137,'netty','Some users might already have found other network application frameworks that claim to have the same advantage, and you might want to ask what makes Netty so different from them. The answer is the philosophy it is built on. Netty is designed to give you the most comfortable experience both in terms of the API and the implementation from day one. It is not something tangible but you will realize that this philosophy will make your life much easier as you read this guide and play with Netty.','design netty',0,'',''),(4138,'netty','Some users might already have found other network application frameworks that claim to have the same advantage, and you might want to ask what makes Netty so different from them. The answer is the philosophy it is built on. Netty is designed to give you the most comfortable experience both in terms of the API and the implementation from day one. It is not something tangible but you will realize that this philosophy will make your life much easier as you read this guide and play with Netty.','read guide',0,'',''),(4139,'netty','Some users might already have found other network application frameworks that claim to have the same advantage, and you might want to ask what makes Netty so different from them. The answer is the philosophy it is built on. Netty is designed to give you the most comfortable experience both in terms of the API and the implementation from day one. It is not something tangible but you will realize that this philosophy will make your life much easier as you read this guide and play with Netty.','play  with netty',0,'',''),(4140,'netty','If you prefer a top-down approach in learning something, you might want to start from Chapter 2, Architectural Overview and get back here.','learn something',0,'',''),(4141,'netty','The minimum requirements to run the examples in this chapter are only two; the latest version of Netty and JDK 1.6 or above. The latest version of Netty is available in the project download page. To download the right version of JDK, please refer to your preferred JDK vendor\'s web site.','run examples in chapter',0,'',''),(4142,'netty','The minimum requirements to run the examples in this chapter are only two; the latest version of Netty and JDK 1.6 or above. The latest version of Netty is available in the project download page. To download the right version of JDK, please refer to your preferred JDK vendor\'s web site.','download right version of JDK',0,'',''),(4143,'netty','As you read, you might have more questions about the classes introduced in this chapter. Please refer to the API reference whenever you want to know more about them. All class names in this document are linked to the online API reference for your convenience. Also, please don\'t hesitate to contact the Netty project community and let us know if there\'s any incorrect information, errors in grammar or typos, and if you have any good ideas to help improve the documentation.','introduce  in chapter',0,'',''),(4144,'netty','As you read, you might have more questions about the classes introduced in this chapter. Please refer to the API reference whenever you want to know more about them. All class names in this document are linked to the online API reference for your convenience. Also, please don\'t hesitate to contact the Netty project community and let us know if there\'s any incorrect information, errors in grammar or typos, and if you have any good ideas to help improve the documentation.','link class names in document',0,'',''),(4145,'netty','As you read, you might have more questions about the classes introduced in this chapter. Please refer to the API reference whenever you want to know more about them. All class names in this document are linked to the online API reference for your convenience. Also, please don\'t hesitate to contact the Netty project community and let us know if there\'s any incorrect information, errors in grammar or typos, and if you have any good ideas to help improve the documentation.','link class names to online API reference',0,'',''),(4146,'netty','The most simplistic protocol in the world is not \'Hello, World!\' but DISCARD. It\'s a protocol that discards any received data without any response.','receive data without response',0,'',''),(4147,'netty','If you run the telnet command again, you will see the server prints what it has received.','run telnet command',0,'',''),(4148,'netty','If you run the telnet command again, you will see the server prints what it has received.','receive server prints',0,'',''),(4149,'netty','As you can see, it is not really different from the server-side code. What about the ChannelHandler implementation? It should receive a 32-bit integer from the server, translate it into a human-readable format, print the translated time, and close the connection:','receive 32-bit integer from server',1,'https://netty.io/wiki/user-guide-for-4.x.html','wiki-h3-10'),(4150,'netty','As you can see, it is not really different from the server-side code. What about the ChannelHandler implementation? It should receive a 32-bit integer from the server, translate it into a human-readable format, print the translated time, and close the connection:','translate  into human-readable format',1,'https://netty.io/wiki/user-guide-for-4.x.html','wiki-h3-10'),(4151,'netty','As you can see, it is not really different from the server-side code. What about the ChannelHandler implementation? It should receive a 32-bit integer from the server, translate it into a human-readable format, print the translated time, and close the connection:','print translated time',1,'https://netty.io/wiki/user-guide-for-4.x.html','wiki-h3-10'),(4152,'netty','Because of this general property of a stream-based protocol, there\'s a high chance of reading them in the following fragmented form in your application:','read  in fragmented form',0,'',''),(4153,'netty','Although the first solution has resolved the problem with the TIME client, the modified handler does not look that clean. Imagine a more complicated protocol which is composed of multiple fields such as a variable length field. Your ChannelInboundHandler implementation will become unmaintainable very quickly.','resolve  with TIME client',0,'',''),(4154,'netty','Although the first solution has resolved the problem with the TIME client, the modified handler does not look that clean. Imagine a more complicated protocol which is composed of multiple fields such as a variable length field. Your ChannelInboundHandler implementation will become unmaintainable very quickly.','compose complicated protocol of multiple fields',0,'',''),(4155,'netty','The advantage of using a POJO in your ChannelHandlers is obvious; your handler becomes more maintainable and reusable by separating the code which extracts information from ByteBuf out from the handler. In the TIME client and server examples, we read only one 32-bit integer and it is not a major issue to use ByteBuf directly. However, you will find it is necessary to make the separation as you implement a real-world protocol.','use POJO in ChannelHandler',0,'',''),(4156,'netty','The advantage of using a POJO in your ChannelHandlers is obvious; your handler becomes more maintainable and reusable by separating the code which extracts information from ByteBuf out from the handler. In the TIME client and server examples, we read only one 32-bit integer and it is not a major issue to use ByteBuf directly. However, you will find it is necessary to make the separation as you implement a real-world protocol.','separate code',0,'',''),(4157,'netty','The advantage of using a POJO in your ChannelHandlers is obvious; your handler becomes more maintainable and reusable by separating the code which extracts information from ByteBuf out from the handler. In the TIME client and server examples, we read only one 32-bit integer and it is not a major issue to use ByteBuf directly. However, you will find it is necessary to make the separation as you implement a real-world protocol.','read 32-bit integer in TIME client',0,'',''),(4158,'netty','The advantage of using a POJO in your ChannelHandlers is obvious; your handler becomes more maintainable and reusable by separating the code which extracts information from ByteBuf out from the handler. In the TIME client and server examples, we read only one 32-bit integer and it is not a major issue to use ByteBuf directly. However, you will find it is necessary to make the separation as you implement a real-world protocol.','read 32-bit integer in server examples',0,'',''),(4159,'netty','The advantage of using a POJO in your ChannelHandlers is obvious; your handler becomes more maintainable and reusable by separating the code which extracts information from ByteBuf out from the handler. In the TIME client and server examples, we read only one 32-bit integer and it is not a major issue to use ByteBuf directly. However, you will find it is necessary to make the separation as you implement a real-world protocol.','use ByteBuf',0,'',''),(4160,'netty','The advantage of using a POJO in your ChannelHandlers is obvious; your handler becomes more maintainable and reusable by separating the code which extracts information from ByteBuf out from the handler. In the TIME client and server examples, we read only one 32-bit integer and it is not a major issue to use ByteBuf directly. However, you will find it is necessary to make the separation as you implement a real-world protocol.','implement real-world protocol',0,'',''),(4161,'netty','Now, the only missing piece is an encoder, which is an implementation of ChannelOutboundHandler that translates a UnixTime back into a ByteBuf. It\'s much simpler than writing a decoder because there\'s no need to deal with packet fragmentation and assembly when encoding a message.','write decoder',1,'https://netty.io/wiki/user-guide-for-4.x.html','wiki-h3-15'),(4162,'netty','Now, the only missing piece is an encoder, which is an implementation of ChannelOutboundHandler that translates a UnixTime back into a ByteBuf. It\'s much simpler than writing a decoder because there\'s no need to deal with packet fragmentation and assembly when encoding a message.','encode message',1,'https://netty.io/wiki/user-guide-for-4.x.html','wiki-h3-15'),(4163,'netty','The package name of Netty has been changed from org.jboss.netty to io.netty since we are not part of JBoss.org anymore.','change package name of Netty',0,'',''),(4164,'netty','The package name of Netty has been changed from org.jboss.netty to io.netty since we are not part of JBoss.org anymore.','change package name from org.jboss.netty',0,'',''),(4165,'netty','The package name of Netty has been changed from org.jboss.netty to io.netty since we are not part of JBoss.org anymore.','change package name to io.netty',0,'',''),(4166,'netty','The binary JAR has been split into multiple submodules so that a user can exclude unnecessary features from the class path. The current structure looks like this following:','exclude unnecessary features from class path',0,'',''),(4167,'netty','The binary JAR has been split into multiple submodules so that a user can exclude unnecessary features from the class path. The current structure looks like this following:','split binary JAR into multiple submodules',0,'',''),(4168,'netty','All artifacts (except for netty-all.jar) are now OSGi bundles and can be used in your favorite OSGi container.','use artifacts in favorite osgi container',0,'',''),(4169,'netty','Thanks to the structural changes mentioned above, the buffer API can be used as a separate package. Even if you are not interested in adopting Netty as a network application framework, you can still use our buffer API. Therefore, the type name ChannelBuffer does not make sense anymore, and has been renamed to ByteBuf.','use buffer API as separate package',0,'',''),(4170,'netty','Thanks to the structural changes mentioned above, the buffer API can be used as a separate package. Even if you are not interested in adopting Netty as a network application framework, you can still use our buffer API. Therefore, the type name ChannelBuffer does not make sense anymore, and has been renamed to ByteBuf.','use buffer API',0,'',''),(4171,'netty','Thanks to the structural changes mentioned above, the buffer API can be used as a separate package. Even if you are not interested in adopting Netty as a network application framework, you can still use our buffer API. Therefore, the type name ChannelBuffer does not make sense anymore, and has been renamed to ByteBuf.','rename type name ChannelBuffer to ByteBuf',0,'',''),(4172,'netty','The utility class ChannelBuffers, which creates a new buffer, has been split into two utility classes, Unpooled and ByteBufUtil. As can be guessed from its name Unpooled, 4.0 introduced pooled ByteBufs which can be allocated via ByteBufAllocator implementations.','create new buffer',0,'',''),(4173,'netty','The utility class ChannelBuffers, which creates a new buffer, has been split into two utility classes, Unpooled and ByteBufUtil. As can be guessed from its name Unpooled, 4.0 introduced pooled ByteBufs which can be allocated via ByteBufAllocator implementations.','create utility class ChannelBuffers',0,'',''),(4174,'netty','The utility class ChannelBuffers, which creates a new buffer, has been split into two utility classes, Unpooled and ByteBufUtil. As can be guessed from its name Unpooled, 4.0 introduced pooled ByteBufs which can be allocated via ByteBufAllocator implementations.','split utility class ChannelBuffers into utility classes',0,'',''),(4175,'netty','The utility class ChannelBuffers, which creates a new buffer, has been split into two utility classes, Unpooled and ByteBufUtil. As can be guessed from its name Unpooled, 4.0 introduced pooled ByteBufs which can be allocated via ByteBufAllocator implementations.','split utility class ChannelBuffers into unpooled',0,'',''),(4176,'netty','The utility class ChannelBuffers, which creates a new buffer, has been split into two utility classes, Unpooled and ByteBufUtil. As can be guessed from its name Unpooled, 4.0 introduced pooled ByteBufs which can be allocated via ByteBufAllocator implementations.','split utility class ChannelBuffers into ByteBufUtil',0,'',''),(4177,'netty','According to our internal performance test, converting ByteBuf from an interface to an abstract class improved the overall throughput around 5%.','convert ByteBuf from interface',0,'',''),(4178,'netty','In 3.x, buffers were fixed or dynamic. The capacity of a fixed buffer does not change once it is created while the capacity of a dynamic buffer changes whenever its write*(...) method requires more space.','fix buffers',0,'',''),(4179,'netty','Since 4.0, all buffers are dynamic. However, they are better than the old dynamic buffers. You can decrease or increase the capacity of a buffer more easily and more safely. It\'s easy because there is a new method ByteBuf.capacity(int newCapacity). It\'s safe because you can set the maximum capacity of a buffer so that it does not grow boundlessly.','set maximum capacity of buffer',1,'https://netty.io/wiki/new-and-noteworthy-in-4.0.html','wiki-h3-6'),(4180,'netty','The only exception is the buffer which wraps a single buffer or a single byte array, created by wrappedBuffer(). You cannot increase its capacity because it invalidates the whole point of wrapping an existing buffer - saving memory copies. If you want to change the capacity after you wrap a buffer, you should just create a new buffer with enough capacity and copy the buffer you wanted to wrap.','wrap single byte array',0,'',''),(4181,'netty','The only exception is the buffer which wraps a single buffer or a single byte array, created by wrappedBuffer(). You cannot increase its capacity because it invalidates the whole point of wrapping an existing buffer - saving memory copies. If you want to change the capacity after you wrap a buffer, you should just create a new buffer with enough capacity and copy the buffer you wanted to wrap.','wrap single buffer',0,'',''),(4182,'netty','The only exception is the buffer which wraps a single buffer or a single byte array, created by wrappedBuffer(). You cannot increase its capacity because it invalidates the whole point of wrapping an existing buffer - saving memory copies. If you want to change the capacity after you wrap a buffer, you should just create a new buffer with enough capacity and copy the buffer you wanted to wrap.','wrap buffer',0,'',''),(4183,'netty','The only exception is the buffer which wraps a single buffer or a single byte array, created by wrappedBuffer(). You cannot increase its capacity because it invalidates the whole point of wrapping an existing buffer - saving memory copies. If you want to change the capacity after you wrap a buffer, you should just create a new buffer with enough capacity and copy the buffer you wanted to wrap.','wrap existing buffer',0,'',''),(4184,'netty','The only exception is the buffer which wraps a single buffer or a single byte array, created by wrappedBuffer(). You cannot increase its capacity because it invalidates the whole point of wrapping an existing buffer - saving memory copies. If you want to change the capacity after you wrap a buffer, you should just create a new buffer with enough capacity and copy the buffer you wanted to wrap.','save memory copies',0,'',''),(4185,'netty','The only exception is the buffer which wraps a single buffer or a single byte array, created by wrappedBuffer(). You cannot increase its capacity because it invalidates the whole point of wrapping an existing buffer - saving memory copies. If you want to change the capacity after you wrap a buffer, you should just create a new buffer with enough capacity and copy the buffer you wanted to wrap.','change capacity',0,'',''),(4186,'netty','The only exception is the buffer which wraps a single buffer or a single byte array, created by wrappedBuffer(). You cannot increase its capacity because it invalidates the whole point of wrapping an existing buffer - saving memory copies. If you want to change the capacity after you wrap a buffer, you should just create a new buffer with enough capacity and copy the buffer you wanted to wrap.','wrap buffer',0,'',''),(4187,'netty','The only exception is the buffer which wraps a single buffer or a single byte array, created by wrappedBuffer(). You cannot increase its capacity because it invalidates the whole point of wrapping an existing buffer - saving memory copies. If you want to change the capacity after you wrap a buffer, you should just create a new buffer with enough capacity and copy the buffer you wanted to wrap.','create new buffer with enough capacity',0,'',''),(4188,'netty','A new buffer implementation named CompositeByteBuf defines various advanced operations for composite buffer implementations. A user can save bulk memory copy operations using a composite buffer at the cost of relatively expensive random access. To create a new composite buffer, use either Unpooled.wrappedBuffer(...) like before, Unpooled.compositeBuffer(...), or ByteBufAllocator.compositeBuffer().','define various advanced operations for composite buffer implementations',0,'',''),(4189,'netty','A new buffer implementation named CompositeByteBuf defines various advanced operations for composite buffer implementations. A user can save bulk memory copy operations using a composite buffer at the cost of relatively expensive random access. To create a new composite buffer, use either Unpooled.wrappedBuffer(...) like before, Unpooled.compositeBuffer(...), or ByteBufAllocator.compositeBuffer().','use composite buffer at cost',0,'',''),(4190,'netty','A new buffer implementation named CompositeByteBuf defines various advanced operations for composite buffer implementations. A user can save bulk memory copy operations using a composite buffer at the cost of relatively expensive random access. To create a new composite buffer, use either Unpooled.wrappedBuffer(...) like before, Unpooled.compositeBuffer(...), or ByteBufAllocator.compositeBuffer().','create new composite buffer',0,'',''),(4191,'netty','The contract of ChannelBuffer.toByteBuffer() and its variants were not deterministic enough in 3.x. It was impossible for a user to know if they would return a view buffer with shared data or a copied buffer with separate data. 4.0 replaces toByteBuffer() with ByteBuf.nioBufferCount(), nioBuffer(), and nioBuffers(). If nioBufferCount() returns 0, a user can always get a copied buffer by calling copy().nioBuffer().','return view buffer with shared data',0,'',''),(4192,'netty','The contract of ChannelBuffer.toByteBuffer() and its variants were not deterministic enough in 3.x. It was impossible for a user to know if they would return a view buffer with shared data or a copied buffer with separate data. 4.0 replaces toByteBuffer() with ByteBuf.nioBufferCount(), nioBuffer(), and nioBuffers(). If nioBufferCount() returns 0, a user can always get a copied buffer by calling copy().nioBuffer().','return view buffer with copied buffer',0,'',''),(4193,'netty','The contract of ChannelBuffer.toByteBuffer() and its variants were not deterministic enough in 3.x. It was impossible for a user to know if they would return a view buffer with shared data or a copied buffer with separate data. 4.0 replaces toByteBuffer() with ByteBuf.nioBufferCount(), nioBuffer(), and nioBuffers(). If nioBufferCount() returns 0, a user can always get a copied buffer by calling copy().nioBuffer().','replace toByteBuffer() with ByteBuf.nioBufferCount()',0,'',''),(4194,'netty','The contract of ChannelBuffer.toByteBuffer() and its variants were not deterministic enough in 3.x. It was impossible for a user to know if they would return a view buffer with shared data or a copied buffer with separate data. 4.0 replaces toByteBuffer() with ByteBuf.nioBufferCount(), nioBuffer(), and nioBuffers(). If nioBufferCount() returns 0, a user can always get a copied buffer by calling copy().nioBuffer().','replace toByteBuffer() with nioBuffer()',0,'',''),(4195,'netty','The contract of ChannelBuffer.toByteBuffer() and its variants were not deterministic enough in 3.x. It was impossible for a user to know if they would return a view buffer with shared data or a copied buffer with separate data. 4.0 replaces toByteBuffer() with ByteBuf.nioBufferCount(), nioBuffer(), and nioBuffers(). If nioBufferCount() returns 0, a user can always get a copied buffer by calling copy().nioBuffer().','replace toByteBuffer() with nioBuffers()',0,'',''),(4196,'netty','The contract of ChannelBuffer.toByteBuffer() and its variants were not deterministic enough in 3.x. It was impossible for a user to know if they would return a view buffer with shared data or a copied buffer with separate data. 4.0 replaces toByteBuffer() with ByteBuf.nioBufferCount(), nioBuffer(), and nioBuffers(). If nioBufferCount() returns 0, a user can always get a copied buffer by calling copy().nioBuffer().','get copied buffer by calling',0,'',''),(4197,'netty','The contract of ChannelBuffer.toByteBuffer() and its variants were not deterministic enough in 3.x. It was impossible for a user to know if they would return a view buffer with shared data or a copied buffer with separate data. 4.0 replaces toByteBuffer() with ByteBuf.nioBufferCount(), nioBuffer(), and nioBuffers(). If nioBufferCount() returns 0, a user can always get a copied buffer by calling copy().nioBuffer().','call copy().nioBuffer()',0,'',''),(4198,'netty','Little endian support has been changed significantly. Previously, a user was supposed to specify a LittleEndianHeapChannelBufferFactory or wrap an existing buffer with the desired byte order to get a little endian buffer. 4.0 adds a new method: ByteBuf.order(ByteOrder). It returns a view of the callee with the desired byte order:','change little endian support',1,'https://netty.io/wiki/new-and-noteworthy-in-4.0.html','wiki-h3-9'),(4199,'netty','Little endian support has been changed significantly. Previously, a user was supposed to specify a LittleEndianHeapChannelBufferFactory or wrap an existing buffer with the desired byte order to get a little endian buffer. 4.0 adds a new method: ByteBuf.order(ByteOrder). It returns a view of the callee with the desired byte order:','specify LittleEndianHeapChannelBufferFactory',1,'https://netty.io/wiki/new-and-noteworthy-in-4.0.html','wiki-h3-9'),(4200,'netty','Little endian support has been changed significantly. Previously, a user was supposed to specify a LittleEndianHeapChannelBufferFactory or wrap an existing buffer with the desired byte order to get a little endian buffer. 4.0 adds a new method: ByteBuf.order(ByteOrder). It returns a view of the callee with the desired byte order:','wrap existing buffer',1,'https://netty.io/wiki/new-and-noteworthy-in-4.0.html','wiki-h3-9'),(4201,'netty','Little endian support has been changed significantly. Previously, a user was supposed to specify a LittleEndianHeapChannelBufferFactory or wrap an existing buffer with the desired byte order to get a little endian buffer. 4.0 adds a new method: ByteBuf.order(ByteOrder). It returns a view of the callee with the desired byte order:','get little endian buffer',1,'https://netty.io/wiki/new-and-noteworthy-in-4.0.html','wiki-h3-9'),(4202,'netty','Little endian support has been changed significantly. Previously, a user was supposed to specify a LittleEndianHeapChannelBufferFactory or wrap an existing buffer with the desired byte order to get a little endian buffer. 4.0 adds a new method: ByteBuf.order(ByteOrder). It returns a view of the callee with the desired byte order:','add new method ByteBuf.order(ByteOrder)',1,'https://netty.io/wiki/new-and-noteworthy-in-4.0.html','wiki-h3-9'),(4203,'netty','Little endian support has been changed significantly. Previously, a user was supposed to specify a LittleEndianHeapChannelBufferFactory or wrap an existing buffer with the desired byte order to get a little endian buffer. 4.0 adds a new method: ByteBuf.order(ByteOrder). It returns a view of the callee with the desired byte order:','return view of callee',1,'https://netty.io/wiki/new-and-noteworthy-in-4.0.html','wiki-h3-9'),(4204,'netty','Netty 4 introduces a high-performance buffer pool which is a variant of jemalloc that combines buddy allocation and slab allocation. It gives the following benefits:','introduce high-performance buffer pool',0,'',''),(4205,'netty','Netty 4 introduces a high-performance buffer pool which is a variant of jemalloc that combines buddy allocation and slab allocation. It gives the following benefits:','combine buddy allocation of jemalloc',0,'',''),(4206,'netty','Netty 4 introduces a high-performance buffer pool which is a variant of jemalloc that combines buddy allocation and slab allocation. It gives the following benefits:','combine slab allocation of jemalloc',0,'',''),(4207,'netty','Netty 4 introduces a high-performance buffer pool which is a variant of jemalloc that combines buddy allocation and slab allocation. It gives the following benefits:','combine variant of jemalloc',0,'',''),(4208,'netty','To take advantage of this feature, unless a user wants to get an unpooled buffer, he or she should get a buffer from a ByteBufAllocator:','get unpooled buffer',1,'https://netty.io/wiki/new-and-noteworthy-in-4.0.html','wiki-h3-10'),(4209,'netty','To take advantage of this feature, unless a user wants to get an unpooled buffer, he or she should get a buffer from a ByteBufAllocator:','get buffer from ByteBufAllocator',1,'https://netty.io/wiki/new-and-noteworthy-in-4.0.html','wiki-h3-10'),(4210,'netty','Once a ByteBuf is written to the remote peer it will be returned automatically to the pool it originated from.','write ByteBuf to remote peer',0,'',''),(4211,'netty','Once a ByteBuf is written to the remote peer it will be returned automatically to the pool it originated from.','return remote peer to pool',0,'',''),(4212,'netty','The default ByteBufAllocator is PooledByteBufAllocator. If you do not wish to use buffer pooling or use your own allocator, use Channel.config().setAllocator(...) with an alternative allocator such as UnpooledByteBufAllocator.','use buffer pooling',0,'',''),(4213,'netty','The default ByteBufAllocator is PooledByteBufAllocator. If you do not wish to use buffer pooling or use your own allocator, use Channel.config().setAllocator(...) with an alternative allocator such as UnpooledByteBufAllocator.','use own allocator',0,'',''),(4214,'netty','The default ByteBufAllocator is PooledByteBufAllocator. If you do not wish to use buffer pooling or use your own allocator, use Channel.config().setAllocator(...) with an alternative allocator such as UnpooledByteBufAllocator.','use Channel.config().setAllocator(...) with alternative allocator',0,'',''),(4215,'netty','When a ByteBuf is used in a ChannelPipeline, there are additional rules you need to keep in mind:','use ByteBuf in ChannelPipeline',0,'',''),(4216,'netty','Although reference counting is very powerful, it is also error-prone. To help a user find where he or she forgot to release the buffers, the leak detector logs the stack trace of the location where the leaked buffer was allocated automatically.','release buffers',0,'',''),(4217,'netty','Although reference counting is very powerful, it is also error-prone. To help a user find where he or she forgot to release the buffers, the leak detector logs the stack trace of the location where the leaked buffer was allocated automatically.','log stack trace of location',0,'',''),(4218,'netty','Because the leak detector relies on PhantomReference and obtaining a stack trace is a very expensive operation, it samples approximately 1% of allocations only. Therefore, it\'s a good idea to run the application for a reasonably long time to find all possible leaks.','obtain stack trace',0,'',''),(4219,'netty','Because the leak detector relies on PhantomReference and obtaining a stack trace is a very expensive operation, it samples approximately 1% of allocations only. Therefore, it\'s a good idea to run the application for a reasonably long time to find all possible leaks.','run application for long time',0,'',''),(4220,'netty','Because the leak detector relies on PhantomReference and obtaining a stack trace is a very expensive operation, it samples approximately 1% of allocations only. Therefore, it\'s a good idea to run the application for a reasonably long time to find all possible leaks.','find possible leaks',0,'',''),(4221,'netty','Once all leaks are found and fixed. You can turn this feature off to remove its runtime overhead completely by specifying the -Dio.netty.noResourceLeakDetection JVM option.','find leaks',0,'',''),(4222,'netty','Once all leaks are found and fixed. You can turn this feature off to remove its runtime overhead completely by specifying the -Dio.netty.noResourceLeakDetection JVM option.','fix leaks',0,'',''),(4223,'netty','Once all leaks are found and fixed. You can turn this feature off to remove its runtime overhead completely by specifying the -Dio.netty.noResourceLeakDetection JVM option.','remove runtime overhead by specifying',0,'',''),(4224,'netty','Once all leaks are found and fixed. You can turn this feature off to remove its runtime overhead completely by specifying the -Dio.netty.noResourceLeakDetection JVM option.','specify -Dio.netty.noResourceLeakDetection JVM option',0,'',''),(4225,'netty','Along with the new standalone buffer API, 4.0 provides various constructs which are useful for writing asynchronous applications in general at the new package called io.netty.util.concurrent. Some of those constructs are:','provide various constructs',0,'',''),(4226,'netty','Along with the new standalone buffer API, 4.0 provides various constructs which are useful for writing asynchronous applications in general at the new package called io.netty.util.concurrent. Some of those constructs are:','write asynchronous applications in general io.netty.util.concurrent',0,'',''),(4227,'netty','They are used as the base of the channel API which will be explained later in this document. For example, ChannelFuture extends io.netty.util.concurrent.Future and EventLoopGroup extends EventExecutorGroup.','use  as base',0,'',''),(4228,'netty','They are used as the base of the channel API which will be explained later in this document. For example, ChannelFuture extends io.netty.util.concurrent.Future and EventLoopGroup extends EventExecutorGroup.','extend EventExecutorGroup',0,'',''),(4229,'netty','In 4.0, many classes under the io.netty.channel package have gone through a major overhaul, and thus simple text search-and-replace will not make your 3.x application work with 4.0. This section will try to show the thought process behind such a big change, rather than being an exhaustive resource for all the changes.','show thought process behind big change',0,'',''),(4230,'netty','In 4.0, many classes under the io.netty.channel package have gone through a major overhaul, and thus simple text search-and-replace will not make your 3.x application work with 4.0. This section will try to show the thought process behind such a big change, rather than being an exhaustive resource for all the changes.','show thought process than exhaustive resource',0,'',''),(4231,'netty','In 3.x, ChannelHandler was just a tag interface, and ChannelUpstreamHandler, ChannelDownstreamHandler, and LifeCycleAwareChannelHandler defined the actual handler methods. In Netty 4, ChannelHandler merges LifeCycleAwareChannelHandler along with a couple more methods which are useful to both an inbound and an outbound handler:','define actual handler methods',1,'https://netty.io/wiki/new-and-noteworthy-in-4.0.html','wiki-h4-17'),(4232,'netty','In 3.x, every I/O operation created a ChannelEvent object. For each read / write, it additionally created a new ChannelBuffer. It simplified the internals of Netty quite a lot because it delegates resource management and buffer pooling to the JVM. However, it often was the root cause of GC pressure and uncertainty which are sometimes observed in a Netty-based application under high load.','create new ChannelBuffer',0,'',''),(4233,'netty','4.0 removes event object creation almost completely by replacing the event objects with strongly typed method invocations. 3.x had catch-all event handler methods such as handleUpstream() and handleDownstream(), but this is not the case anymore. Every event type has its own handler method now:','remove event object creation by replacing',1,'https://netty.io/wiki/new-and-noteworthy-in-4.0.html','wiki-h4-18'),(4234,'netty','4.0 removes event object creation almost completely by replacing the event objects with strongly typed method invocations. 3.x had catch-all event handler methods such as handleUpstream() and handleDownstream(), but this is not the case anymore. Every event type has its own handler method now:','replace event objects with typed method invocations',1,'https://netty.io/wiki/new-and-noteworthy-in-4.0.html','wiki-h4-18'),(4235,'netty','ChannelHandlerContext has also been changed to reflect the changes mentioned above:','change ChannelHandlerContext',1,'https://netty.io/wiki/new-and-noteworthy-in-4.0.html','wiki-h4-18'),(4236,'netty','All these changes mean a user cannot extend the non-existing ChannelEvent interface anymore. How then does a user define his or her own event type such as IdleStateEvent? ChannelHandlerContext in 4.0 has a fireUserEventTriggered method for triggering custom events and ChannelInboundHandler now has a handler method called userEventTriggered() which is dedicated to the specific user case of dealing with custom events.','define his her own event type such_as IdleStateEvent',0,'',''),(4237,'netty','All these changes mean a user cannot extend the non-existing ChannelEvent interface anymore. How then does a user define his or her own event type such as IdleStateEvent? ChannelHandlerContext in 4.0 has a fireUserEventTriggered method for triggering custom events and ChannelInboundHandler now has a handler method called userEventTriggered() which is dedicated to the specific user case of dealing with custom events.','call userEventTriggered()',0,'',''),(4238,'netty','When a new connected Channel is created in 3.x, at least three ChannelStateEvents are triggered: channelOpen, channelBound, and channelConnected. When a Channel is closed, at least 3 more: channelDisconnected, channelUnbound, and channelClosed.','create channel',0,'',''),(4239,'netty','When a new connected Channel is created in 3.x, at least three ChannelStateEvents are triggered: channelOpen, channelBound, and channelConnected. When a Channel is closed, at least 3 more: channelDisconnected, channelUnbound, and channelClosed.','trigger ChannelStateEvent',0,'',''),(4240,'netty','However, it\'s of dubious value to trigger that many events. It is more useful for a user to get notified when a Channel enters the state where it can perform reads and writes.','trigger many events',0,'',''),(4241,'netty','However, it\'s of dubious value to trigger that many events. It is more useful for a user to get notified when a Channel enters the state where it can perform reads and writes.','perform state',0,'',''),(4242,'netty','Note that channelRegistered and channelUnregistered are not equivalent to channelOpen and channelClosed. They are new states introduced to support dynamic registration, deregistration, and re-registration of a Channel, as illustrated below:','support dynamic registration of channel',0,'',''),(4243,'netty','Note that channelRegistered and channelUnregistered are not equivalent to channelOpen and channelClosed. They are new states introduced to support dynamic registration, deregistration, and re-registration of a Channel, as illustrated below:','support deregistration of channel',0,'',''),(4244,'netty','Note that channelRegistered and channelUnregistered are not equivalent to channelOpen and channelClosed. They are new states introduced to support dynamic registration, deregistration, and re-registration of a Channel, as illustrated below:','support re-registration of channel',0,'',''),(4245,'netty','4.0 introduced a new operation called flush() which explicitly flushes the outbound buffer of a Channel, and write() operation does not flush automatically. You can think of this as a java.io.BufferedOutputStream, except that it works at message level.','call flush()',0,'',''),(4246,'netty','4.0 introduced a new operation called flush() which explicitly flushes the outbound buffer of a Channel, and write() operation does not flush automatically. You can think of this as a java.io.BufferedOutputStream, except that it works at message level.','flush outbound buffer of channel',0,'',''),(4247,'netty','4.0 introduced a new operation called flush() which explicitly flushes the outbound buffer of a Channel, and write() operation does not flush automatically. You can think of this as a java.io.BufferedOutputStream, except that it works at message level.','flush flush() of channel',0,'',''),(4248,'netty','Because of this change, you must be very careful not to forget to call ctx.flush() after writing something. Alternatively, you could use a shortcut method writeAndFlush().','call ctx.flush() after writing',0,'',''),(4249,'netty','Because of this change, you must be very careful not to forget to call ctx.flush() after writing something. Alternatively, you could use a shortcut method writeAndFlush().','write something',0,'',''),(4250,'netty','Because of this change, you must be very careful not to forget to call ctx.flush() after writing something. Alternatively, you could use a shortcut method writeAndFlush().','use shortcut method writeAndFlush()',0,'',''),(4251,'netty','3.x had an unintuitive inbound traffic suspension mechanism provided by Channel.setReadable(boolean). It introduced complicated interactions between ChannelHandlers and the handlers were easy to interfere with each other if implemented incorrectly.','introduce complicated interactions between ChannelHandlers',0,'',''),(4252,'netty','In 4.0, a new outbound operation called read() has been added. If you turn off the default auto-read flag with Channel.config().setAutoRead(false), Netty will not read anything until you explicitly invoke the read() operation. Once the read() operation you issue is complete and the channel again stops reading, an inbound event called channelReadSuspended() will be triggered so that you can re-issue another read() operation. You can also intercept a read() operation to perform more advanced traffic control.','call  in 4.0',0,'',''),(4253,'netty','In 4.0, a new outbound operation called read() has been added. If you turn off the default auto-read flag with Channel.config().setAutoRead(false), Netty will not read anything until you explicitly invoke the read() operation. Once the read() operation you issue is complete and the channel again stops reading, an inbound event called channelReadSuspended() will be triggered so that you can re-issue another read() operation. You can also intercept a read() operation to perform more advanced traffic control.','add read()',0,'',''),(4254,'netty','In 4.0, a new outbound operation called read() has been added. If you turn off the default auto-read flag with Channel.config().setAutoRead(false), Netty will not read anything until you explicitly invoke the read() operation. Once the read() operation you issue is complete and the channel again stops reading, an inbound event called channelReadSuspended() will be triggered so that you can re-issue another read() operation. You can also intercept a read() operation to perform more advanced traffic control.','trigger channelReadSuspended()',0,'',''),(4255,'netty','In 4.0, a new outbound operation called read() has been added. If you turn off the default auto-read flag with Channel.config().setAutoRead(false), Netty will not read anything until you explicitly invoke the read() operation. Once the read() operation you issue is complete and the channel again stops reading, an inbound event called channelReadSuspended() will be triggered so that you can re-issue another read() operation. You can also intercept a read() operation to perform more advanced traffic control.','perform advanced traffic control',0,'',''),(4256,'netty','TCP and SCTP allow a user to shut down the outbound traffic of a socket without closing it completely. Such a socket is called \'a half-closed socket\', and a user can make a half-closed socket by calling SocketChannel.shutdownOutput() method. If a remote peer shuts down the outbound traffic, SocketChannel.read(..) will return -1, which was seemingly indistinguishable from a closed connection.','call half-closed socket',0,'',''),(4257,'netty','TCP and SCTP allow a user to shut down the outbound traffic of a socket without closing it completely. Such a socket is called \'a half-closed socket\', and a user can make a half-closed socket by calling SocketChannel.shutdownOutput() method. If a remote peer shuts down the outbound traffic, SocketChannel.read(..) will return -1, which was seemingly indistinguishable from a closed connection.','call socket',0,'',''),(4258,'netty','TCP and SCTP allow a user to shut down the outbound traffic of a socket without closing it completely. Such a socket is called \'a half-closed socket\', and a user can make a half-closed socket by calling SocketChannel.shutdownOutput() method. If a remote peer shuts down the outbound traffic, SocketChannel.read(..) will return -1, which was seemingly indistinguishable from a closed connection.','call SocketChannel.shutdownOutput() method',0,'',''),(4259,'netty','To support a half-closed socket, 4.0 adds SocketChannel.shutdownOutput() method, and a user can set the \'ALLOW_HALF_CLOSURE\' ChannelOption to prevent Netty from closing the connection automatically even if SocketChannel.read(..) returns -1.','support half-closed socket',0,'',''),(4260,'netty','To support a half-closed socket, 4.0 adds SocketChannel.shutdownOutput() method, and a user can set the \'ALLOW_HALF_CLOSURE\' ChannelOption to prevent Netty from closing the connection automatically even if SocketChannel.read(..) returns -1.','add SocketChannel.shutdownOutput() method',0,'',''),(4261,'netty','To support a half-closed socket, 4.0 adds SocketChannel.shutdownOutput() method, and a user can set the \'ALLOW_HALF_CLOSURE\' ChannelOption to prevent Netty from closing the connection automatically even if SocketChannel.read(..) returns -1.','set ChannelOption',0,'',''),(4262,'netty','To support a half-closed socket, 4.0 adds SocketChannel.shutdownOutput() method, and a user can set the \'ALLOW_HALF_CLOSURE\' ChannelOption to prevent Netty from closing the connection automatically even if SocketChannel.read(..) returns -1.','prevent Netty from closing',0,'',''),(4263,'netty','In 3.x, a Channel is created by a ChannelFactory and the newly created Channel is automatically registered to a hidden I/O thread. 4.0 replaces ChannelFactory with a new interface called EventLoopGroup which consists of one or more EventLoops. Also, a new Channel is not registered to the EventLoopGroup automatically but a user has to call EventLoopGroup.register() explicitly.','create channel',0,'',''),(4264,'netty','In 3.x, a Channel is created by a ChannelFactory and the newly created Channel is automatically registered to a hidden I/O thread. 4.0 replaces ChannelFactory with a new interface called EventLoopGroup which consists of one or more EventLoops. Also, a new Channel is not registered to the EventLoopGroup automatically but a user has to call EventLoopGroup.register() explicitly.','create created channel',0,'',''),(4265,'netty','In 3.x, a Channel is created by a ChannelFactory and the newly created Channel is automatically registered to a hidden I/O thread. 4.0 replaces ChannelFactory with a new interface called EventLoopGroup which consists of one or more EventLoops. Also, a new Channel is not registered to the EventLoopGroup automatically but a user has to call EventLoopGroup.register() explicitly.','call EventLoopGroup',0,'',''),(4266,'netty','In 3.x, a Channel is created by a ChannelFactory and the newly created Channel is automatically registered to a hidden I/O thread. 4.0 replaces ChannelFactory with a new interface called EventLoopGroup which consists of one or more EventLoops. Also, a new Channel is not registered to the EventLoopGroup automatically but a user has to call EventLoopGroup.register() explicitly.','call EventLoopGroup.register()',0,'',''),(4267,'netty','Thanks to this change (i.e. separation of ChannelFactory and I/O threads), a user can register different Channel implementations to the same EventLoopGroup, or same Channel implementations to different EventLoopGroups. For example, you can run a NIO server socket, NIO client sockets, NIO UDP sockets, and in-VM local channels in the same I/O thread. It should be very useful when writing a proxy server which requires minimal latency.','write proxy server',0,'',''),(4268,'netty','3.x provided no way to create a new Channel from an existing JDK socket such as java.nio.channels.SocketChannel. You can with 4.0.','provide way',0,'',''),(4269,'netty','3.x provided no way to create a new Channel from an existing JDK socket such as java.nio.channels.SocketChannel. You can with 4.0.','create new Channel from existing JDK socket',0,'',''),(4270,'netty','Once a new Channel is created in 3.x, it is completely tied to a single I/O thread until its underlying socket is closed. In 4.0, a user can deregister a Channel from its I/O thread to gain the full control of its underlying JDK socket. For example, you can take advantage of high-level non-blocking I/O Netty provides to deal with complex protocols, and then later deregister the Channel and switch to blocking mode to transfer a file at possible maximum throughput. Of course, it is possible to register the deregistered Channel back again.','create new channel',1,'https://netty.io/wiki/new-and-noteworthy-in-4.0.html','wiki-h3-26'),(4271,'netty','Once a new Channel is created in 3.x, it is completely tied to a single I/O thread until its underlying socket is closed. In 4.0, a user can deregister a Channel from its I/O thread to gain the full control of its underlying JDK socket. For example, you can take advantage of high-level non-blocking I/O Netty provides to deal with complex protocols, and then later deregister the Channel and switch to blocking mode to transfer a file at possible maximum throughput. Of course, it is possible to register the deregistered Channel back again.','switch  to blocking',1,'https://netty.io/wiki/new-and-noteworthy-in-4.0.html','wiki-h3-26'),(4272,'netty','Once a new Channel is created in 3.x, it is completely tied to a single I/O thread until its underlying socket is closed. In 4.0, a user can deregister a Channel from its I/O thread to gain the full control of its underlying JDK socket. For example, you can take advantage of high-level non-blocking I/O Netty provides to deal with complex protocols, and then later deregister the Channel and switch to blocking mode to transfer a file at possible maximum throughput. Of course, it is possible to register the deregistered Channel back again.','provide advantage of high-level non-blocking',1,'https://netty.io/wiki/new-and-noteworthy-in-4.0.html','wiki-h3-26'),(4273,'netty','When a Channel is registered to an EventLoopGroup, the Channel is actually registered to one of the EventLoops which is managed by the EventLoopGroup. EventLoop implements java.util.concurrent.ScheduledExecutorService. It means a user can execute or schedule an arbitrary Runnable or Callable in an I/O thread where the user\'s channel belongs to. Along with the new well-defined thread model, which will be explained later, it became extremely easier to write a thread-safe handler.','manage EventLoop s',1,'https://netty.io/wiki/new-and-noteworthy-in-4.0.html','wiki-h3-27'),(4274,'netty','When a Channel is registered to an EventLoopGroup, the Channel is actually registered to one of the EventLoops which is managed by the EventLoopGroup. EventLoop implements java.util.concurrent.ScheduledExecutorService. It means a user can execute or schedule an arbitrary Runnable or Callable in an I/O thread where the user\'s channel belongs to. Along with the new well-defined thread model, which will be explained later, it became extremely easier to write a thread-safe handler.','implement java.util.concurrent.ScheduledExecutorService',1,'https://netty.io/wiki/new-and-noteworthy-in-4.0.html','wiki-h3-27'),(4275,'netty','When a Channel is registered to an EventLoopGroup, the Channel is actually registered to one of the EventLoops which is managed by the EventLoopGroup. EventLoop implements java.util.concurrent.ScheduledExecutorService. It means a user can execute or schedule an arbitrary Runnable or Callable in an I/O thread where the user\'s channel belongs to. Along with the new well-defined thread model, which will be explained later, it became extremely easier to write a thread-safe handler.','execute runnable callable thread',1,'https://netty.io/wiki/new-and-noteworthy-in-4.0.html','wiki-h3-27'),(4276,'netty','When a Channel is registered to an EventLoopGroup, the Channel is actually registered to one of the EventLoops which is managed by the EventLoopGroup. EventLoop implements java.util.concurrent.ScheduledExecutorService. It means a user can execute or schedule an arbitrary Runnable or Callable in an I/O thread where the user\'s channel belongs to. Along with the new well-defined thread model, which will be explained later, it became extremely easier to write a thread-safe handler.','write thread-safe handler',1,'https://netty.io/wiki/new-and-noteworthy-in-4.0.html','wiki-h3-27'),(4277,'netty','There\'s no more releaseExternalResources(). You can close all open channels immediately and make all I/O threads stop themselves by calling EventLoopGroup.shutdownGracefully().','call EventLoopGroup.shutdownGracefully()',0,'',''),(4278,'netty','There are two ways to configure the socket parameters of a Channel in Netty. One is to call the setters of a ChannelConfig explicitly, such as SocketChannelConfig.setTcpNoDelay(true). It is the most type-safe way. The other is to call ChannelConfig.setOption() method. Sometimes you have to determine what socket options to configure in runtime, and this method is ideal for such cases. However, it is error-prone in 3.x because a user has to specify the option as a pair of a string and an object. If a user calls with the wrong option name or value, he or she will encounter a ClassCastException or the specified option might even be ignored silently.','configure socket parameters in netty',0,'',''),(4279,'netty','There are two ways to configure the socket parameters of a Channel in Netty. One is to call the setters of a ChannelConfig explicitly, such as SocketChannelConfig.setTcpNoDelay(true). It is the most type-safe way. The other is to call ChannelConfig.setOption() method. Sometimes you have to determine what socket options to configure in runtime, and this method is ideal for such cases. However, it is error-prone in 3.x because a user has to specify the option as a pair of a string and an object. If a user calls with the wrong option name or value, he or she will encounter a ClassCastException or the specified option might even be ignored silently.','configure socket parameters of channel',0,'',''),(4280,'netty','There are two ways to configure the socket parameters of a Channel in Netty. One is to call the setters of a ChannelConfig explicitly, such as SocketChannelConfig.setTcpNoDelay(true). It is the most type-safe way. The other is to call ChannelConfig.setOption() method. Sometimes you have to determine what socket options to configure in runtime, and this method is ideal for such cases. However, it is error-prone in 3.x because a user has to specify the option as a pair of a string and an object. If a user calls with the wrong option name or value, he or she will encounter a ClassCastException or the specified option might even be ignored silently.','call setters of ChannelConfig',0,'',''),(4281,'netty','There are two ways to configure the socket parameters of a Channel in Netty. One is to call the setters of a ChannelConfig explicitly, such as SocketChannelConfig.setTcpNoDelay(true). It is the most type-safe way. The other is to call ChannelConfig.setOption() method. Sometimes you have to determine what socket options to configure in runtime, and this method is ideal for such cases. However, it is error-prone in 3.x because a user has to specify the option as a pair of a string and an object. If a user calls with the wrong option name or value, he or she will encounter a ClassCastException or the specified option might even be ignored silently.','call setters such_as SocketChannelConfig.setTcpNoDelay(true)',0,'',''),(4282,'netty','There are two ways to configure the socket parameters of a Channel in Netty. One is to call the setters of a ChannelConfig explicitly, such as SocketChannelConfig.setTcpNoDelay(true). It is the most type-safe way. The other is to call ChannelConfig.setOption() method. Sometimes you have to determine what socket options to configure in runtime, and this method is ideal for such cases. However, it is error-prone in 3.x because a user has to specify the option as a pair of a string and an object. If a user calls with the wrong option name or value, he or she will encounter a ClassCastException or the specified option might even be ignored silently.','call ChannelConfig.setOption() method',0,'',''),(4283,'netty','There are two ways to configure the socket parameters of a Channel in Netty. One is to call the setters of a ChannelConfig explicitly, such as SocketChannelConfig.setTcpNoDelay(true). It is the most type-safe way. The other is to call ChannelConfig.setOption() method. Sometimes you have to determine what socket options to configure in runtime, and this method is ideal for such cases. However, it is error-prone in 3.x because a user has to specify the option as a pair of a string and an object. If a user calls with the wrong option name or value, he or she will encounter a ClassCastException or the specified option might even be ignored silently.','configure  in runtime',0,'',''),(4284,'netty','There are two ways to configure the socket parameters of a Channel in Netty. One is to call the setters of a ChannelConfig explicitly, such as SocketChannelConfig.setTcpNoDelay(true). It is the most type-safe way. The other is to call ChannelConfig.setOption() method. Sometimes you have to determine what socket options to configure in runtime, and this method is ideal for such cases. However, it is error-prone in 3.x because a user has to specify the option as a pair of a string and an object. If a user calls with the wrong option name or value, he or she will encounter a ClassCastException or the specified option might even be ignored silently.','specify option as pair',0,'',''),(4285,'netty','There are two ways to configure the socket parameters of a Channel in Netty. One is to call the setters of a ChannelConfig explicitly, such as SocketChannelConfig.setTcpNoDelay(true). It is the most type-safe way. The other is to call ChannelConfig.setOption() method. Sometimes you have to determine what socket options to configure in runtime, and this method is ideal for such cases. However, it is error-prone in 3.x because a user has to specify the option as a pair of a string and an object. If a user calls with the wrong option name or value, he or she will encounter a ClassCastException or the specified option might even be ignored silently.','call  with wrong option name',0,'',''),(4286,'netty','There are two ways to configure the socket parameters of a Channel in Netty. One is to call the setters of a ChannelConfig explicitly, such as SocketChannelConfig.setTcpNoDelay(true). It is the most type-safe way. The other is to call ChannelConfig.setOption() method. Sometimes you have to determine what socket options to configure in runtime, and this method is ideal for such cases. However, it is error-prone in 3.x because a user has to specify the option as a pair of a string and an object. If a user calls with the wrong option name or value, he or she will encounter a ClassCastException or the specified option might even be ignored silently.','call  with value',0,'',''),(4287,'netty','There are two ways to configure the socket parameters of a Channel in Netty. One is to call the setters of a ChannelConfig explicitly, such as SocketChannelConfig.setTcpNoDelay(true). It is the most type-safe way. The other is to call ChannelConfig.setOption() method. Sometimes you have to determine what socket options to configure in runtime, and this method is ideal for such cases. However, it is error-prone in 3.x because a user has to specify the option as a pair of a string and an object. If a user calls with the wrong option name or value, he or she will encounter a ClassCastException or the specified option might even be ignored silently.','ignore ClassCastException',0,'',''),(4288,'netty','There are two ways to configure the socket parameters of a Channel in Netty. One is to call the setters of a ChannelConfig explicitly, such as SocketChannelConfig.setTcpNoDelay(true). It is the most type-safe way. The other is to call ChannelConfig.setOption() method. Sometimes you have to determine what socket options to configure in runtime, and this method is ideal for such cases. However, it is error-prone in 3.x because a user has to specify the option as a pair of a string and an object. If a user calls with the wrong option name or value, he or she will encounter a ClassCastException or the specified option might even be ignored silently.','ignore specified option',0,'',''),(4289,'netty','4.0 introduces a new type called ChannelOption, which provides type-safe access to socket options.','call ChannelOption',1,'https://netty.io/wiki/new-and-noteworthy-in-4.0.html','wiki-h3-29'),(4290,'netty','4.0 introduces a new type called ChannelOption, which provides type-safe access to socket options.','provide type-safe access to socket options',1,'https://netty.io/wiki/new-and-noteworthy-in-4.0.html','wiki-h3-29'),(4291,'netty','4.0 introduces a new type called ChannelOption, which provides type-safe access to socket options.','provide ChannelOption to socket options',1,'https://netty.io/wiki/new-and-noteworthy-in-4.0.html','wiki-h3-29'),(4292,'netty','In response to user demand, you can attach any object to Channel and ChannelHandlerContext. A new interface called AttributeMap, which Channel and ChannelHandlerContext extend, has been added. Instead, ChannelLocal and Channel.attachment are removed. The attributes are garbage-collected when their associated Channel is garbage-collected.','attach object in response',1,'https://netty.io/wiki/new-and-noteworthy-in-4.0.html','wiki-h3-30'),(4293,'netty','In response to user demand, you can attach any object to Channel and ChannelHandlerContext. A new interface called AttributeMap, which Channel and ChannelHandlerContext extend, has been added. Instead, ChannelLocal and Channel.attachment are removed. The attributes are garbage-collected when their associated Channel is garbage-collected.','attach object to channel',1,'https://netty.io/wiki/new-and-noteworthy-in-4.0.html','wiki-h3-30'),(4294,'netty','In response to user demand, you can attach any object to Channel and ChannelHandlerContext. A new interface called AttributeMap, which Channel and ChannelHandlerContext extend, has been added. Instead, ChannelLocal and Channel.attachment are removed. The attributes are garbage-collected when their associated Channel is garbage-collected.','attach object to ChannelHandlerContext',1,'https://netty.io/wiki/new-and-noteworthy-in-4.0.html','wiki-h3-30'),(4295,'netty','In response to user demand, you can attach any object to Channel and ChannelHandlerContext. A new interface called AttributeMap, which Channel and ChannelHandlerContext extend, has been added. Instead, ChannelLocal and Channel.attachment are removed. The attributes are garbage-collected when their associated Channel is garbage-collected.','extend AttributeMap',1,'https://netty.io/wiki/new-and-noteworthy-in-4.0.html','wiki-h3-30'),(4296,'netty','In response to user demand, you can attach any object to Channel and ChannelHandlerContext. A new interface called AttributeMap, which Channel and ChannelHandlerContext extend, has been added. Instead, ChannelLocal and Channel.attachment are removed. The attributes are garbage-collected when their associated Channel is garbage-collected.','add AttributeMap',1,'https://netty.io/wiki/new-and-noteworthy-in-4.0.html','wiki-h3-30'),(4297,'netty','In response to user demand, you can attach any object to Channel and ChannelHandlerContext. A new interface called AttributeMap, which Channel and ChannelHandlerContext extend, has been added. Instead, ChannelLocal and Channel.attachment are removed. The attributes are garbage-collected when their associated Channel is garbage-collected.','remove ChannelLocal',1,'https://netty.io/wiki/new-and-noteworthy-in-4.0.html','wiki-h3-30'),(4298,'netty','In response to user demand, you can attach any object to Channel and ChannelHandlerContext. A new interface called AttributeMap, which Channel and ChannelHandlerContext extend, has been added. Instead, ChannelLocal and Channel.attachment are removed. The attributes are garbage-collected when their associated Channel is garbage-collected.','remove Channel.attachment',1,'https://netty.io/wiki/new-and-noteworthy-in-4.0.html','wiki-h3-30'),(4299,'netty','The bootstrap API has been rewritten from scratch although its purpose stays same; it performs the typical steps required to make a server or a client up and running, often found in boilerplate code.','perform typical steps',1,'https://netty.io/wiki/new-and-noteworthy-in-4.0.html','wiki-h3-31'),(4300,'netty','The bootstrap API has been rewritten from scratch although its purpose stays same; it performs the typical steps required to make a server or a client up and running, often found in boilerplate code.','find  in boilerplate code',1,'https://netty.io/wiki/new-and-noteworthy-in-4.0.html','wiki-h3-31'),(4301,'netty','As you noticed in the example above, there is no ChannelPipelineFactory anymore. It has been replaced with ChannelInitializer, which gives more control over Channel and ChannelPipeline configuration.','replace  with ChannelInitializer',0,'',''),(4302,'netty','Please note that you don\'t create a new ChannelPipeline by yourself. After observing many use cases reported so far, the Netty project team concluded that it has no benefit for a user to create his or her own pipeline implementation or to extend the default implementation. Therefore, ChannelPipeline is not created by a user anymore. ChannelPipeline is automatically created by a Channel.','create his her own pipeline implementation',0,'',''),(4303,'netty','Please note that you don\'t create a new ChannelPipeline by yourself. After observing many use cases reported so far, the Netty project team concluded that it has no benefit for a user to create his or her own pipeline implementation or to extend the default implementation. Therefore, ChannelPipeline is not created by a user anymore. ChannelPipeline is automatically created by a Channel.','extend default implementation',0,'',''),(4304,'netty','Please note that you don\'t create a new ChannelPipeline by yourself. After observing many use cases reported so far, the Netty project team concluded that it has no benefit for a user to create his or her own pipeline implementation or to extend the default implementation. Therefore, ChannelPipeline is not created by a user anymore. ChannelPipeline is automatically created by a Channel.','create ChannelPipeline',0,'',''),(4305,'netty','ChannelFuture has been split into ChannelFuture and ChannelPromise. This not only makes the contract of consumer and producer of an asynchronous operation explicit, but also makes it more safe to use the returned ChannelFuture in a chain (like filtering), because the state of the ChannelFuture cannot be changed.','split ChannelFuture into ChannelFuture',0,'',''),(4306,'netty','ChannelFuture has been split into ChannelFuture and ChannelPromise. This not only makes the contract of consumer and producer of an asynchronous operation explicit, but also makes it more safe to use the returned ChannelFuture in a chain (like filtering), because the state of the ChannelFuture cannot be changed.','split ChannelFuture into ChannelPromise',0,'',''),(4307,'netty','ChannelFuture has been split into ChannelFuture and ChannelPromise. This not only makes the contract of consumer and producer of an asynchronous operation explicit, but also makes it more safe to use the returned ChannelFuture in a chain (like filtering), because the state of the ChannelFuture cannot be changed.','use returned ChannelFuture in chain',0,'',''),(4308,'netty','Due to this change, some methods now accept ChannelPromise rather than ChannelFuture to modify its state.','modify state',0,'',''),(4309,'netty','There is no well-defined thread model in 3.x although there was an attempt to fix its inconsistency in 3.5. 4.0 defines a strict thread model that helps a user write a ChannelHandler without worrying too much about thread safety.','fix inconsistency',0,'',''),(4310,'netty','There is no well-defined thread model in 3.x although there was an attempt to fix its inconsistency in 3.5. 4.0 defines a strict thread model that helps a user write a ChannelHandler without worrying too much about thread safety.','define strict thread model',0,'',''),(4311,'netty','There is no well-defined thread model in 3.x although there was an attempt to fix its inconsistency in 3.5. 4.0 defines a strict thread model that helps a user write a ChannelHandler without worrying too much about thread safety.','write ChannelHandler without worrying',0,'',''),(4312,'netty','You can specify an EventExecutor when you add a ChannelHandler to a ChannelPipeline to tell the pipeline to always invoke the handler methods of the added ChannelHandler via the specified EventExecutor.','specify EventExecutor',1,'https://netty.io/wiki/new-and-noteworthy-in-4.0.html','wiki-h3-35'),(4313,'netty','You can specify an EventExecutor when you add a ChannelHandler to a ChannelPipeline to tell the pipeline to always invoke the handler methods of the added ChannelHandler via the specified EventExecutor.','add ChannelHandler to ChannelPipeline',1,'https://netty.io/wiki/new-and-noteworthy-in-4.0.html','wiki-h3-35'),(4314,'netty','There were substantial internal changes in the codec framework because 4.0 requires a handler to create and manage its buffer (see Per-handler buffer section in this document.) However, the changes from a user\'s perspective are not very big.','create buffer',0,'',''),(4315,'netty','There were substantial internal changes in the codec framework because 4.0 requires a handler to create and manage its buffer (see Per-handler buffer section in this document.) However, the changes from a user\'s perspective are not very big.','manage buffer',0,'',''),(4316,'netty','Codec embedder has been replaced by io.netty.channel.embedded.EmbeddedChannel to allow a user to test any kind of pipeline including a codec.','test kind of pipeline',0,'',''),(4317,'netty','Codec embedder has been replaced by io.netty.channel.embedded.EmbeddedChannel to allow a user to test any kind of pipeline including a codec.','replace codec embedder',0,'',''),(4318,'netty','HTTP decoders now always generates multiple message objects per a single HTTP message:','generate multiple message objects per single HTTP message',1,'https://netty.io/wiki/new-and-noteworthy-in-4.0.html','wiki-h3-38'),(4319,'netty','The following transports were newly added:','add following transports',0,'',''),(4320,'netty','This section shows rough steps to port the Factorial example from 3.x to 4.0. The Factorial example has been ported to 4.0 already in the io.netty.example.factorial package. Please browse the source code of the example to find every bits changed.','find bits',0,'',''),(4321,'netty','Mostly same with porting the server, but you need to pay attention when you write a potentially large stream.','write large stream',0,'',''),(4322,'netty','Please note that Netty has no mandatory external dependencies. JDK 1.6 for Netty 4+ or above and JDK 11 for Netty 5 is all that you need to run Netty.','run netty',0,'',''),(4323,'netty','You can either subscribe to our official blog or follow @netty_project at Twitter.','subscribe  to official blog',0,'',''),(4324,'netty','Add the following dependency section to your pom.xml:','add following dependency section to    pom.xml',1,'https://netty.io/wiki/../downloads.html',''),(4325,'netty','All previous releases can be downloaded from here.','download previous releases',0,'',''),(4326,'netty','Nightly builds can be found at our CI server. You can also pull the latest snapshots from our Maven snapshot repository.','find nightly builds at CI server',0,'',''),(4327,'netty','Getting involved with the Netty community is easier than you think.\n\nTell us what you think, and open the future of network programming.','open future of network programming',0,'',''),(4328,'netty','We use StackOverflow as the place to ask the questions. Just tag your question with \'netty\', and then we will respond.','use StackOverflow as place',0,'',''),(4329,'netty','We use StackOverflow as the place to ask the questions. Just tag your question with \'netty\', and then we will respond.','ask questions',0,'',''),(4330,'netty','Follow @netty_project at Twitter, mention us, and use the \'#Netty\' hash­tag. Subscribe to our RSS feed to get useful information. If you are interested in how we work with code, watch our Github repository.','use hashtag',0,'',''),(4331,'netty','Follow @netty_project at Twitter, mention us, and use the \'#Netty\' hash­tag. Subscribe to our RSS feed to get useful information. If you are interested in how we work with code, watch our Github repository.','get useful information',0,'',''),(4332,'netty','Even better, if you are in the mood of writing something longer, think about writing an article about Netty and let us know.','write something',0,'',''),(4333,'netty','Even better, if you are in the mood of writing something longer, think about writing an article about Netty and let us know.','write article about Netty',0,'',''),(4334,'netty','Found a bug? Browse our issue tracker and file an issue if it was not reported before. Get back and let us know if it\'s fixed.','find bug',0,'',''),(4335,'netty','If you think the bug you found is likely to make Netty-based applications vulnerable to an attack, please do not use our public issue tracker but report it to the dedicated private Google Group.','find bug',0,'',''),(4336,'netty','It\'s all open source! Netty is hosted at Github. Feel free to fork it, issue a pull request, and join the discussion. We also have a Google Group for the topics that need a broader discussion. If your contribution is not trivial, you will have to sign up the Contributor License Agreement (CLA). Before working with Netty source code, you might want to read the developer guide.','host netty at github',0,'',''),(4337,'netty','It\'s all open source! Netty is hosted at Github. Feel free to fork it, issue a pull request, and join the discussion. We also have a Google Group for the topics that need a broader discussion. If your contribution is not trivial, you will have to sign up the Contributor License Agreement (CLA). Before working with Netty source code, you might want to read the developer guide.','read developer guide',0,'',''),(4338,'netty','You or your company can also donate the resources we need for sustainable development of the project, such as fund to cover the cost for developer meet-ups, heart-warming gift, and software license. The donors are listed here.','list donors',0,'',''),(4339,'netty','Get started with the user guide and the API reference. Also, join the community to get more information.','get more information',0,'',''),(4340,'netty','We often find there are people in the world who are much more talented in technical writing than we, and they kindly wrote great articles for the community.','write great articles for community',0,'',''),(4341,'netty','Clinker provides high-quality one-stop solution for software development ecosystem. Our build server and static analysis server were are donated and powered by Clinker, and we were very happy with their superb support and flexibility.','provide high-quality one-stop solution for software development ecosystem',0,'',''),(4342,'netty','SpigotMC community, the home of the high-performance Minecraft server, kindly shared the donation they received with us.','share donation',0,'',''),(4343,'netty','SpigotMC community, the home of the high-performance Minecraft server, kindly shared the donation they received with us.','receive donation',0,'',''),(4344,'netty','The Netty 4.1.83.Final version suffered a mis-compilation in the macOS KQueue native binaries during the release process.\nApart from the macOS specific native code integrations, there are no differences between the 4.1.83.Final and 4.1.84.Final versions we\'ve released to Maven Central.','release differences to Maven central',0,'',''),(4345,'netty','The Netty 4.1.83.Final version suffered a mis-compilation in the macOS KQueue native binaries during the release process.\nApart from the macOS specific native code integrations, there are no differences between the 4.1.83.Final and 4.1.84.Final versions we\'ve released to Maven Central.','release differences between 4.1.83.Final 4.1.84.Final versions',0,'',''),(4346,'GitPython','Implements an Object which may be Blobs, Trees, Commits and Tags','implement Object',0,'',''),(4347,'GitPython','Initialize an object by identifying it by its binary sha.\nAll keyword arguments will be set on demand if None.','initialize object',0,'',''),(4348,'GitPython','Initialize an object by identifying it by its binary sha.\nAll keyword arguments will be set on demand if None.','identify  by binary sha',0,'',''),(4349,'GitPython','Initialize an object by identifying it by its binary sha.\nAll keyword arguments will be set on demand if None.','set keyword arguments if none',0,'',''),(4350,'GitPython','Initialize an object by identifying it by its binary sha.\nAll keyword arguments will be set on demand if None.','set keyword arguments on demand',0,'',''),(4351,'GitPython','Writes our data directly to the given output stream\n:param ostream: File object compatible stream object.\n:return: self','write data to given output stream',0,'',''),(4352,'GitPython','Initialize a newly instanced IndexObject','initialize instanced IndexObject',0,'',''),(4353,'GitPython','This class will act lazily on some of its attributes and will query the\nvalue on demand only if it involves calling the git binary.','call git binary',0,'',''),(4354,'GitPython','Instantiate a new Commit. All keyword arguments taking None as default will\nbe implicitly set on first query.','instantiate new commit',0,'',''),(4355,'GitPython','Instantiate a new Commit. All keyword arguments taking None as default will\nbe implicitly set on first query.','set keyword arguments on first query',0,'',''),(4356,'GitPython','Search the commit message for any co-authors of this commit.\nDetails on co-authors: https://github.blog/2018-01-29-commit-together-with-co-authors/','search commit message for co-authors',0,'',''),(4357,'GitPython','Commit the given tree, creating a commit object.','create commit object',0,'',''),(4358,'GitPython','Find all commits matching the given criteria.','match given criteria',0,'',''),(4359,'GitPython','Any values provided as keyword arguments will replace the\ncorresponding attribute in the new object.','replace corresponding attribute in new object',0,'',''),(4360,'GitPython','Create a git stat from changes between this commit and its first parent\nor from all changes done if this is the very first commit.','create git stat from changes',0,'',''),(4361,'GitPython','Create a git stat from changes between this commit and its first parent\nor from all changes done if this is the very first commit.','create git stat from changes',0,'',''),(4362,'GitPython','Get the trailers of the message as dictionary','get trailers of message',0,'',''),(4363,'GitPython','This functions calls git interpret-trailers --parse onto the message\nto extract the trailer information. The key value pairs are stripped of\nleading and trailing whitespaces before they get saved into a dictionary.','call git interpret-trailers parse',0,'',''),(4364,'GitPython','This functions calls git interpret-trailers --parse onto the message\nto extract the trailer information. The key value pairs are stripped of\nleading and trailing whitespaces before they get saved into a dictionary.','save  into dictionary',0,'',''),(4365,'GitPython','A utility class providing methods to alter the underlying cache in a list-like fashion.','provide methods',0,'',''),(4366,'GitPython','Once all adjustments are complete, the _cache, which really is a reference to\nthe cache of a tree, will be sorted. Assuring it will be in a serializable state','sort _ cache',0,'',''),(4367,'GitPython','Deletes an item with the given name if it exists','delete item with given name',0,'',''),(4368,'GitPython','Initialize self.  See help(type(self)) for accurate signature.','initialize self',0,'',''),(4369,'GitPython','Add the given item to the tree. If an item with the given name already\nexists, nothing will be done, but a ValueError will be raised if the\nsha and mode of the existing item do not match the one you add, unless\nforce is True','add given item to tree',0,'',''),(4370,'GitPython','Add the given item to the tree. If an item with the given name already\nexists, nothing will be done, but a ValueError will be raised if the\nsha and mode of the existing item do not match the one you add, unless\nforce is True','raise ValueError',0,'',''),(4371,'GitPython','Add the given item to the tree, its correctness is assumed, which\nputs the caller into responsibility to assure the input is correct.\nFor more information on the parameters, see add\n:param binsha: 20 byte binary sha','add given item to tree',0,'',''),(4372,'GitPython','Add the given item to the tree, its correctness is assumed, which\nputs the caller into responsibility to assure the input is correct.\nFor more information on the parameters, see add\n:param binsha: 20 byte binary sha','add param binsha for more information',0,'',''),(4373,'GitPython','Call this method once you are done modifying the tree information.\nIt may be called several times, but be aware that each call will cause\na sort operation\n:return self:','call method',0,'',''),(4374,'GitPython','Call this method once you are done modifying the tree information.\nIt may be called several times, but be aware that each call will cause\na sort operation\n:return self:','modify tree information',0,'',''),(4375,'GitPython','Call this method once you are done modifying the tree information.\nIt may be called several times, but be aware that each call will cause\na sort operation\n:return self:','return self',0,'',''),(4376,'GitPython','Find the named object in this tree’s contents\n:return: git.Blob or git.Tree or git.Submodule','find named object in contents',0,'',''),(4377,'GitPython','For documentation, see util.Traversable._traverse()\nTrees are set to visit_once = False to gain more performance in the traversal','set trees to visit_once = false',0,'',''),(4378,'GitPython','Write the give list of entries into a stream using its write method\n:param entries: sorted list of tuples with (binsha, mode, name)\n:param write: write method which takes a data string','use write method',0,'',''),(4379,'GitPython','Write the give list of entries into a stream using its write method\n:param entries: sorted list of tuples with (binsha, mode, name)\n:param write: write method which takes a data string','sort list of tuples',0,'',''),(4380,'GitPython','Write the give list of entries into a stream using its write method\n:param entries: sorted list of tuples with (binsha, mode, name)\n:param write: write method which takes a data string','write method',0,'',''),(4381,'GitPython','Compare with another submodule','compare  with submodule',0,'',''),(4382,'GitPython','Hash this instance using its logical id, not the sha','use logical id',0,'',''),(4383,'GitPython','Initialize this instance with its attributes. We only document the ones\nthat differ from IndexObject','initialize instance with attributes',0,'',''),(4384,'GitPython','Compare with another submodule for inequality','compare  with submodule',0,'',''),(4385,'GitPython','Add a new submodule to the given repository. This will alter the index\nas well as the .gitmodules file, but will not create a new commit.\nIf the submodule already exists, no matter if the configuration differs\nfrom the one provided, the existing submodule will be returned.','add new submodule to given repository',0,'',''),(4386,'GitPython','Add a new submodule to the given repository. This will alter the index\nas well as the .gitmodules file, but will not create a new commit.\nIf the submodule already exists, no matter if the configuration differs\nfrom the one provided, the existing submodule will be returned.','return existing submodule',0,'',''),(4387,'GitPython','Move the submodule to a another module path. This involves physically moving\nthe repository at our current path, changing the configuration, as well as\nadjusting our index entry accordingly.','move submodule to module path',0,'',''),(4388,'GitPython','Move the submodule to a another module path. This involves physically moving\nthe repository at our current path, changing the configuration, as well as\nadjusting our index entry accordingly.','change configuration',0,'',''),(4389,'GitPython','Move the submodule to a another module path. This involves physically moving\nthe repository at our current path, changing the configuration, as well as\nadjusting our index entry accordingly.','adjust index entry',0,'',''),(4390,'GitPython','Remove this submodule from the repository. This will remove our entry\nfrom the .gitmodules file and the entry in the .git / config file.','remove submodule from repository',0,'',''),(4391,'GitPython','Remove this submodule from the repository. This will remove our entry\nfrom the .gitmodules file and the entry in the .git / config file.','remove entry',0,'',''),(4392,'GitPython','Rename this submodule\n:note: This method takes care of renaming the submodule in various places, such as','rename submodule',0,'',''),(4393,'GitPython','Rename this submodule\n:note: This method takes care of renaming the submodule in various places, such as','rename submodule in various places',0,'',''),(4394,'GitPython','As .gitmodules will be changed, you would need to make a commit afterwards. The changed .gitmodules file\nwill already be added to the index','change gitmodules',0,'',''),(4395,'GitPython','As .gitmodules will be changed, you would need to make a commit afterwards. The changed .gitmodules file\nwill already be added to the index','add gitmodules file to index',0,'',''),(4396,'GitPython','Set this instance to use the given commit whose tree is supposed to\ncontain the .gitmodules blob.','set instance',0,'',''),(4397,'GitPython','Set this instance to use the given commit whose tree is supposed to\ncontain the .gitmodules blob.','use given commit',0,'',''),(4398,'GitPython','Update the repository of this submodule to point to the checkout\nwe point at with the binsha of this instance.','update repository of submodule',0,'',''),(4399,'GitPython','Class providing detailed progress information to the caller who should\nderive from it and implement the update(...) message','provide detailed progress information to caller',0,'',''),(4400,'GitPython','Class providing detailed progress information to the caller who should\nderive from it and implement the update(...) message','implement update(...) message',0,'',''),(4401,'GitPython','Class providing detailed progress information to the caller who should\nderive from it and implement the update(...) message','implement caller',0,'',''),(4402,'GitPython','Update the submodules of this repository to the current HEAD commit.\nThis method behaves smartly by determining changes of the path of a submodules\nrepository, next to changes to the to-be-checked-out commit or the branch to be\nchecked out. This works if the submodules ID does not change.\nAdditionally it will detect addition and removal of submodules, which will be handled\ngracefully.','update submodules of repository',0,'',''),(4403,'GitPython','Update the submodules of this repository to the current HEAD commit.\nThis method behaves smartly by determining changes of the path of a submodules\nrepository, next to changes to the to-be-checked-out commit or the branch to be\nchecked out. This works if the submodules ID does not change.\nAdditionally it will detect addition and removal of submodules, which will be handled\ngracefully.','update submodules to current HEAD',0,'',''),(4404,'GitPython','Update the submodules of this repository to the current HEAD commit.\nThis method behaves smartly by determining changes of the path of a submodules\nrepository, next to changes to the to-be-checked-out commit or the branch to be\nchecked out. This works if the submodules ID does not change.\nAdditionally it will detect addition and removal of submodules, which will be handled\ngracefully.','determine changes of path',0,'',''),(4405,'GitPython','Update the submodules of this repository to the current HEAD commit.\nThis method behaves smartly by determining changes of the path of a submodules\nrepository, next to changes to the to-be-checked-out commit or the branch to be\nchecked out. This works if the submodules ID does not change.\nAdditionally it will detect addition and removal of submodules, which will be handled\ngracefully.','handle submodules',0,'',''),(4406,'GitPython','Utility class which adds more opcodes to the UpdateProgress','add utility class',0,'',''),(4407,'GitPython','Find the remote branch matching the name of the given branch or raise InvalidGitRepositoryError','find remote branch',0,'',''),(4408,'GitPython','Find the remote branch matching the name of the given branch or raise InvalidGitRepositoryError','match name of given branch',0,'',''),(4409,'GitPython','Find the remote branch matching the name of the given branch or raise InvalidGitRepositoryError','raise InvalidGitRepositoryError',0,'',''),(4410,'GitPython','Catches calls to _write, and updates the .gitmodules blob in the index\nwith the new data, if we have written into a stream. Otherwise it will\nadd the local file to the index to make it correspond with the working tree.\nAdditionally, the cache must be cleared','write  into stream',0,'',''),(4411,'GitPython','Catches calls to _write, and updates the .gitmodules blob in the index\nwith the new data, if we have written into a stream. Otherwise it will\nadd the local file to the index to make it correspond with the working tree.\nAdditionally, the cache must be cleared','add local file to index',0,'',''),(4412,'GitPython','Initialize a configuration reader to read the given file_or_files and to\npossibly allow changes to it by setting read_only False','read given file_or_files',0,'',''),(4413,'GitPython','Initialize a configuration reader to read the given file_or_files and to\npossibly allow changes to it by setting read_only False','set read_only false',0,'',''),(4414,'GitPython','Flush changes in our configuration file to the index','change  in configuration file',0,'',''),(4415,'GitPython','Flush changes in our configuration file to the index','change  to index',0,'',''),(4416,'GitPython','Set this instance’s submodule. It must be called before\nthe first write operation begins','set submodule',0,'',''),(4417,'GitPython','Write changes to our file, if there are changes at all','change  to file',0,'',''),(4418,'GitPython','Class wireing all calls to the contained Process instance.','call  to contained Process instance',0,'',''),(4419,'GitPython','Use this type to hide the underlying process to provide access only to a specified\nstream. The process is usually wrapped into an AutoInterrupt class to kill\nit if the instance goes out of scope.','use type',0,'',''),(4420,'GitPython','Use this type to hide the underlying process to provide access only to a specified\nstream. The process is usually wrapped into an AutoInterrupt class to kill\nit if the instance goes out of scope.','hide underlying process',0,'',''),(4421,'GitPython','Use this type to hide the underlying process to provide access only to a specified\nstream. The process is usually wrapped into an AutoInterrupt class to kill\nit if the instance goes out of scope.','provide access to specified stream',0,'',''),(4422,'GitPython','Use this type to hide the underlying process to provide access only to a specified\nstream. The process is usually wrapped into an AutoInterrupt class to kill\nit if the instance goes out of scope.','wrap process into AutoInterrupt class',0,'',''),(4423,'GitPython','Simple interface to perform depth-first or breadth-first traversals\ninto one direction.\nSubclasses only need to implement one function.\nInstances of the Subclass must be hashable','perform depth-first breadth-first traversals into direction',0,'',''),(4424,'GitPython','Simple interface to perform depth-first or breadth-first traversals\ninto one direction.\nSubclasses only need to implement one function.\nInstances of the Subclass must be hashable','implement function',0,'',''),(4425,'GitPython','As above, but inverses the operation, returning a string that can be used\nin commit objects','return string',0,'',''),(4426,'GitPython','As above, but inverses the operation, returning a string that can be used\nin commit objects','use string',0,'',''),(4427,'GitPython','we convert utctz to the timezone in seconds, it is the format time.altzone\nreturns. Git stores it as UTC timezone which has the opposite sign as well,\nwhich explains the -1 * ( that was made explicit here )\n:param utctz: git utc timezone string, i.e. +0200','convert utctz to timezone',0,'',''),(4428,'GitPython','we convert utctz to the timezone in seconds, it is the format time.altzone\nreturns. Git stores it as UTC timezone which has the opposite sign as well,\nwhich explains the -1 * ( that was made explicit here )\n:param utctz: git utc timezone string, i.e. +0200','store  as UTC timezone',0,'',''),(4429,'GitPython','Same as committer(), but defines the main author. It may be specified in the environment,\nbut defaults to the committer','define main author',0,'',''),(4430,'GitPython','Same as committer(), but defines the main author. It may be specified in the environment,\nbut defaults to the committer','specify  in environment',0,'',''),(4431,'GitPython','Implements an Index that can be manipulated using a native implementation in\norder to save git command function calls wherever possible.','use native implementation',0,'',''),(4432,'GitPython','Implements an Index that can be manipulated using a native implementation in\norder to save git command function calls wherever possible.','save git command function calls',0,'',''),(4433,'GitPython','Implements an Index that can be manipulated using a native implementation in\norder to save git command function calls wherever possible.','manipulate implements',0,'',''),(4434,'GitPython','It provides custom merging facilities allowing to merge without actually changing\nyour index or your working tree. This way you can perform own test-merges based\non the index only without having to deal with the working copy. This is useful\nin case of partial working trees.','provide custom',0,'',''),(4435,'GitPython','It provides custom merging facilities allowing to merge without actually changing\nyour index or your working tree. This way you can perform own test-merges based\non the index only without having to deal with the working copy. This is useful\nin case of partial working trees.','change working tree',0,'',''),(4436,'GitPython','It provides custom merging facilities allowing to merge without actually changing\nyour index or your working tree. This way you can perform own test-merges based\non the index only without having to deal with the working copy. This is useful\nin case of partial working trees.','change index',0,'',''),(4437,'GitPython','It provides custom merging facilities allowing to merge without actually changing\nyour index or your working tree. This way you can perform own test-merges based\non the index only without having to deal with the working copy. This is useful\nin case of partial working trees.','perform own test-merges without having',0,'',''),(4438,'GitPython','You may read the entries dict or manipulate it using IndexEntry instance, i.e.:','use IndexEntry instance',1,'https://gitpython.readthedocs.io/en/stable/reference.html',''),(4439,'GitPython','Make sure you use index.write() once you are done manipulating the index directly\nbefore operating on it using the git command','use index.write()',0,'',''),(4440,'GitPython','Make sure you use index.write() once you are done manipulating the index directly\nbefore operating on it using the git command','manipulate index before operating',0,'',''),(4441,'GitPython','Make sure you use index.write() once you are done manipulating the index directly\nbefore operating on it using the git command','use git command',0,'',''),(4442,'GitPython','Initialize this Index instance, optionally from the given file_path.\nIf no file_path is given, we will be created from the current index file.','initialize Index instance from given file_path',0,'',''),(4443,'GitPython','Initialize this Index instance, optionally from the given file_path.\nIf no file_path is given, we will be created from the current index file.','create  from current index file',0,'',''),(4444,'GitPython','If a stream is not given, the stream will be initialized from the current\nrepository’s index on demand.','initialize stream from index',0,'',''),(4445,'GitPython','Add files from the working tree, specific blobs or BaseIndexEntries\nto the index.','add files from working tree',0,'',''),(4446,'GitPython','Add files from the working tree, specific blobs or BaseIndexEntries\nto the index.','add files from specific blobs',0,'',''),(4447,'GitPython','Add files from the working tree, specific blobs or BaseIndexEntries\nto the index.','add files from BaseIndexEntries',0,'',''),(4448,'GitPython','Multiple types of items are supported, types can be mixed within one call.\nDifferent types imply a different handling. File paths may generally be\nrelative or absolute.','support multiple types of items',0,'',''),(4449,'GitPython','Absolute paths must start with working tree directory of this index’s repository\nto be considered valid. For example, if it was initialized with a non-normalized path, like\n/root/repo/../repo, absolute paths to be added must start with /root/repo/../repo.','initialize  with non-normalized path',0,'',''),(4450,'GitPython','Paths provided like this must exist. When added, they will be written\ninto the object database.','write  into object database',0,'',''),(4451,'GitPython','PathStrings may contain globs, such as ‘lib/__init__*’ or can be directories\nlike ‘lib’, the latter ones will add all the files within the directory and\nsubdirectories.','add files within directory',0,'',''),(4452,'GitPython','PathStrings may contain globs, such as ‘lib/__init__*’ or can be directories\nlike ‘lib’, the latter ones will add all the files within the directory and\nsubdirectories.','add files within subdirectories',0,'',''),(4453,'GitPython','If their sha is null ( 40*0 ), their path must exist in the file system\nrelative to the git repository as an object will be created from\nthe data at the path.\nThe handling now very much equals the way string paths are processed, except that\nthe mode you have set will be kept. This allows you to create symlinks\nby settings the mode respectively and writing the target of the symlink\ndirectly into the file. This equals a default Linux-Symlink which\nis not dereferenced automatically, except that it can be created on\nfilesystems not supporting it as well.','create object from data',0,'',''),(4454,'GitPython','If their sha is null ( 40*0 ), their path must exist in the file system\nrelative to the git repository as an object will be created from\nthe data at the path.\nThe handling now very much equals the way string paths are processed, except that\nthe mode you have set will be kept. This allows you to create symlinks\nby settings the mode respectively and writing the target of the symlink\ndirectly into the file. This equals a default Linux-Symlink which\nis not dereferenced automatically, except that it can be created on\nfilesystems not supporting it as well.','set mode',0,'',''),(4455,'GitPython','If their sha is null ( 40*0 ), their path must exist in the file system\nrelative to the git repository as an object will be created from\nthe data at the path.\nThe handling now very much equals the way string paths are processed, except that\nthe mode you have set will be kept. This allows you to create symlinks\nby settings the mode respectively and writing the target of the symlink\ndirectly into the file. This equals a default Linux-Symlink which\nis not dereferenced automatically, except that it can be created on\nfilesystems not supporting it as well.','create symlinks by settings',0,'',''),(4456,'GitPython','If their sha is null ( 40*0 ), their path must exist in the file system\nrelative to the git repository as an object will be created from\nthe data at the path.\nThe handling now very much equals the way string paths are processed, except that\nthe mode you have set will be kept. This allows you to create symlinks\nby settings the mode respectively and writing the target of the symlink\ndirectly into the file. This equals a default Linux-Symlink which\nis not dereferenced automatically, except that it can be created on\nfilesystems not supporting it as well.','create symlinks by writing',0,'',''),(4457,'GitPython','If their sha is null ( 40*0 ), their path must exist in the file system\nrelative to the git repository as an object will be created from\nthe data at the path.\nThe handling now very much equals the way string paths are processed, except that\nthe mode you have set will be kept. This allows you to create symlinks\nby settings the mode respectively and writing the target of the symlink\ndirectly into the file. This equals a default Linux-Symlink which\nis not dereferenced automatically, except that it can be created on\nfilesystems not supporting it as well.','write target into file',0,'',''),(4458,'GitPython','If their sha is null ( 40*0 ), their path must exist in the file system\nrelative to the git repository as an object will be created from\nthe data at the path.\nThe handling now very much equals the way string paths are processed, except that\nthe mode you have set will be kept. This allows you to create symlinks\nby settings the mode respectively and writing the target of the symlink\ndirectly into the file. This equals a default Linux-Symlink which\nis not dereferenced automatically, except that it can be created on\nfilesystems not supporting it as well.','write target of symlink',0,'',''),(4459,'GitPython','If their sha is null ( 40*0 ), their path must exist in the file system\nrelative to the git repository as an object will be created from\nthe data at the path.\nThe handling now very much equals the way string paths are processed, except that\nthe mode you have set will be kept. This allows you to create symlinks\nby settings the mode respectively and writing the target of the symlink\ndirectly into the file. This equals a default Linux-Symlink which\nis not dereferenced automatically, except that it can be created on\nfilesystems not supporting it as well.','create  on filesystems',0,'',''),(4460,'GitPython','Checkout the given paths or all files from the version known to the index into\nthe working tree.','checkout given paths from version',0,'',''),(4461,'GitPython','Checkout the given paths or all files from the version known to the index into\nthe working tree.','checkout files from version',0,'',''),(4462,'GitPython','Commit the current default index file, creating a commit object.\nFor more information on the arguments, see Commit.create_from_tree().','create commit object',0,'',''),(4463,'GitPython','Merge the given treeish revisions into a new index which is returned.\nThe original index will remain unaltered','return new index',0,'',''),(4464,'GitPython','As opposed to the IndexFile.from_tree() method, this allows you to use an already\nexisting tree as the left side of the merge','use existing tree as left side',0,'',''),(4465,'GitPython','Merge the given treeish revisions into a new index which is returned.\nThis method behaves like git-read-tree –aggressive when doing the merge.','return new index',0,'',''),(4466,'GitPython','Remove the given items from the index and optionally from\nthe working tree as well.','remove given items from index',0,'',''),(4467,'GitPython','Remove the given items from the index and optionally from\nthe working tree as well.','remove given items from working tree',0,'',''),(4468,'GitPython','Multiple types of items are supported which may be be freely mixed.','support multiple types of items',0,'',''),(4469,'GitPython','Resolve the blobs given in blob iterator. This will effectively remove the\nindex entries of the respective path at all non-null stages and add the given\nblob as new stage null blob.','resolve blobs',0,'',''),(4470,'GitPython','Resolve the blobs given in blob iterator. This will effectively remove the\nindex entries of the respective path at all non-null stages and add the given\nblob as new stage null blob.','remove index entries at non-null stages',0,'',''),(4471,'GitPython','Resolve the blobs given in blob iterator. This will effectively remove the\nindex entries of the respective path at all non-null stages and add the given\nblob as new stage null blob.','remove index entries of respective path',0,'',''),(4472,'GitPython','Resolve the blobs given in blob iterator. This will effectively remove the\nindex entries of the respective path at all non-null stages and add the given\nblob as new stage null blob.','add given blob as new stage null blob',0,'',''),(4473,'GitPython','For each path there may only be one blob, otherwise a ValueError will be raised\nclaiming the path is already at stage 0.','raise ValueError',0,'',''),(4474,'GitPython','Write the current state to our file path or to the given one','write current state to file path',0,'',''),(4475,'GitPython','Writes this index to a corresponding Tree object into the repository’s\nobject database and return it.','write index into object database',0,'',''),(4476,'GitPython','Writes this index to a corresponding Tree object into the repository’s\nobject database and return it.','write index to corresponding Tree object',0,'',''),(4477,'GitPython','The .valid_files attribute contains a list of relative paths to files that\nwere checked out successfully and hence match the version stored in the\nindex','match version',0,'',''),(4478,'GitPython','The .valid_files attribute contains a list of relative paths to files that\nwere checked out successfully and hence match the version stored in the\nindex','match files',0,'',''),(4479,'GitPython','The .valid_files attribute contains a list of relative paths to files that\nwere checked out successfully and hence match the version stored in the\nindex','store  in index',0,'',''),(4480,'GitPython','Read a cache file from the given stream\n:return: tuple(version, entries_dict, extension_data, content_sha)\n* version is the integer version number\n* entries dict is a dictionary which maps IndexEntry instances to a path at a stage\n* extension_data is ‘’ or 4 bytes of type + 4 bytes of size + size bytes\n* content_sha is a 20 byte sha on all cache file contents','read cache file from given stream',0,'',''),(4481,'GitPython','Create a tree from the given sorted list of entries and put the respective\ntrees into the given object database','create tree from given sorted list',0,'',''),(4482,'GitPython','Convert the given mode from a stat call to the corresponding index mode\nand return it','convert given mode from stat call',0,'',''),(4483,'GitPython','Convert the given mode from a stat call to the corresponding index mode\nand return it','convert given mode to corresponding index mode',0,'',''),(4484,'GitPython','Run the commit hook of the given name. Silently ignores hooks that do not exist.\n:param name: name of hook, like ‘pre-commit’\n:param index: IndexFile instance\n:param args: arguments passed to hook file\n:raises HookExecutionError:','raise hookexecutionerror',0,'',''),(4485,'GitPython','Run the commit hook of the given name. Silently ignores hooks that do not exist.\n:param name: name of hook, like ‘pre-commit’\n:param index: IndexFile instance\n:param args: arguments passed to hook file\n:raises HookExecutionError:','pass  to hook file',0,'',''),(4486,'GitPython','Module with additional types used by the index','use  by index',0,'',''),(4487,'GitPython','Predicate to be used by iter_blobs allowing to filter only return blobs which\nmatch the given list of directories or files.','match given list of directories',0,'',''),(4488,'GitPython','Predicate to be used by iter_blobs allowing to filter only return blobs which\nmatch the given list of directories or files.','match given list of files',0,'',''),(4489,'GitPython','Predicate to be used by iter_blobs allowing to filter only return blobs which\nmatch the given list of directories or files.','match only return blobs of directories',0,'',''),(4490,'GitPython','Predicate to be used by iter_blobs allowing to filter only return blobs which\nmatch the given list of directories or files.','match only return blobs of files',0,'',''),(4491,'GitPython','Small Brother of an index entry which can be created to describe changes\ndone to the index in which case plenty of additional information is not required.','describe changes',0,'',''),(4492,'GitPython','Small Brother of an index entry which can be created to describe changes\ndone to the index in which case plenty of additional information is not required.','create index entry',0,'',''),(4493,'GitPython','As the first 4 data members match exactly to the IndexEntry type, methods\nexpecting a BaseIndexEntry can also handle full IndexEntries even if they\nuse numeric indices for performance reasons.','handle full IndexEntries',0,'',''),(4494,'GitPython','As the first 4 data members match exactly to the IndexEntry type, methods\nexpecting a BaseIndexEntry can also handle full IndexEntries even if they\nuse numeric indices for performance reasons.','use numeric indices for performance reasons',0,'',''),(4495,'GitPython','As the first 4 data members match exactly to the IndexEntry type, methods\nexpecting a BaseIndexEntry can also handle full IndexEntries even if they\nuse numeric indices for performance reasons.','match  to IndexEntry type',0,'',''),(4496,'GitPython','Override __new__ to allow construction from a tuple for backwards compatibility','override __new__',0,'',''),(4497,'GitPython','Attributes usully accessed often are cached in the tuple whereas others are\nunpacked on demand.','cache attributes accessed in tuple',0,'',''),(4498,'GitPython','See ctime property, but returns modification time','return modification time',0,'',''),(4499,'GitPython','Utility class moving a file to a temporary location within the same directory\nand moving it back on to where on object deletion.','move file to temporary location',0,'',''),(4500,'GitPython','Decorator for functions that alter the index using the git command. This would\ninvalidate our possibly existing entries dictionary which is why it must be\ndeleted to allow it to be lazily reread later.','use git command',0,'',''),(4501,'GitPython','Decorator which changes the current working dir to the one of the git\nrepository in order to assure relative paths are handled correctly','change current working dir',0,'',''),(4502,'GitPython','Decorator which changes the current working dir to the one of the git\nrepository in order to assure relative paths are handled correctly','change Decorator',0,'',''),(4503,'GitPython','Decorator which changes the current working dir to the one of the git\nrepository in order to assure relative paths are handled correctly','handle Decorator',0,'',''),(4504,'GitPython','The Git class manages communication with the Git binary.','manage communication with git binary',0,'',''),(4505,'GitPython','It provides a convenient interface to calling the Git binary, such as in:','provide convenient interface to calling',1,'https://gitpython.readthedocs.io/en/stable/reference.html',''),(4506,'GitPython','It provides a convenient interface to calling the Git binary, such as in:','call git binary',1,'https://gitpython.readthedocs.io/en/stable/reference.html',''),(4507,'GitPython','Kill/Interrupt the stored process instance once this instance goes out of scope. It is\nused to prevent processes piling up in case iterators stop reading.\nBesides all attributes are wired through to the contained process object.','prevent processes',0,'',''),(4508,'GitPython','The wait method was overridden to perform automatic status code checking\nand possibly raise.','perform automatic status code checking',0,'',''),(4509,'GitPython','The wait method was overridden to perform automatic status code checking\nand possibly raise.','raise automatic status code checking',0,'',''),(4510,'GitPython','The wait method was overridden to perform automatic status code checking\nand possibly raise.','override wait method',0,'',''),(4511,'GitPython','Wait for the process and return its status code.','return status code',0,'',''),(4512,'GitPython','Object representing a sized read-only stream returning the contents of\nan object.\nIt behaves like a stream, but counts the data read and simulates an empty\nstream once our sized content region is empty.\nIf not all data is read to the end of the objects’s lifetime, we read the\nrest to assure the underlying stream continues to work','return contents of object',0,'',''),(4513,'GitPython','Object representing a sized read-only stream returning the contents of\nan object.\nIt behaves like a stream, but counts the data read and simulates an empty\nstream once our sized content region is empty.\nIf not all data is read to the end of the objects’s lifetime, we read the\nrest to assure the underlying stream continues to work','simulate empty stream',0,'',''),(4514,'GitPython','Object representing a sized read-only stream returning the contents of\nan object.\nIt behaves like a stream, but counts the data read and simulates an empty\nstream once our sized content region is empty.\nIf not all data is read to the end of the objects’s lifetime, we read the\nrest to assure the underlying stream continues to work','read data to end',0,'',''),(4515,'GitPython','A convenience method as it allows to call the command as if it was\nan object.\n:return: Callable object that will execute call _call_process with your arguments.','call command',0,'',''),(4516,'GitPython','A convenience method as it allows to call the command as if it was\nan object.\n:return: Callable object that will execute call _call_process with your arguments.','execute call _ call_process with arguments',0,'',''),(4517,'GitPython','Initialize this instance with:','initialize instance',0,'',''),(4518,'GitPython','Clear all kinds of internal caches to release resources.','release resources',0,'',''),(4519,'GitPython','Note git is executed with LC_MESSAGES=”C” to ensure consistent\noutput regardless of system language.','execute git with LC_MESSAGES = c',0,'',''),(4520,'GitPython','As get_object_header, but returns object data as well\n:return: (hexsha, type_string, size_as_int,data_string)\n:note: not threadsafe','return note',0,'',''),(4521,'GitPython','Use this method to quickly examine the type and size of the object behind\nthe given ref.','use method',0,'',''),(4522,'GitPython','As get_object_header, but returns the data as a stream','return data as get_object_header',0,'',''),(4523,'GitPython','As get_object_header, but returns the data as a stream','return data as stream',0,'',''),(4524,'GitPython','Module containing module parser implementation able to properly read and write\nconfiguration files','read configuration files',0,'',''),(4525,'GitPython','Module containing module parser implementation able to properly read and write\nconfiguration files','write configuration files',0,'',''),(4526,'GitPython','Constrains a ConfigParser to only option commands which are constrained to\nalways use the section we have been initialized with.','use section',0,'',''),(4527,'GitPython','Constrains a ConfigParser to only option commands which are constrained to\nalways use the section we have been initialized with.','initialize section',0,'',''),(4528,'GitPython','It supports all ConfigParser methods that operate on an option.','support ConfigParser methods',0,'',''),(4529,'GitPython','Equivalent to GitConfigParser.release(), which is called on our underlying parser instance','call GitConfigParser.release() on underlying parser instance',0,'',''),(4530,'GitPython','Creates diffs between two items being trees, trees and index or an\nindex and the working tree. It will detect renames automatically.','create diffs between items',0,'',''),(4531,'GitPython','Implements an Index for diffs, allowing a list of Diffs to be queried by\nthe diff properties.','implement Index for diffs',0,'',''),(4532,'GitPython','It contains two sides a and b of the diff, members are prefixed with\n“a” and “b” respectively to inidcate that.','prefix members',1,'https://gitpython.readthedocs.io/en/stable/reference.html',''),(4533,'GitPython','Module containing all exceptions thrown throughout the git package,','throw  throughout git package',0,'',''),(4534,'GitPython','Base for all errors related to the git index, which is called cache internally','call cache',0,'',''),(4535,'GitPython','Base for all errors related to the git index, which is called cache internally','call git index',0,'',''),(4536,'GitPython','Base class for exceptions thrown at every stage of Popen() execution.','throw  at stage',0,'',''),(4537,'GitPython','Thrown if a hook exits with a non-zero exit code. It provides access to the exit code and the string returned\nvia standard output','provide access to exit code',0,'',''),(4538,'GitPython','Thrown if a hook exits with a non-zero exit code. It provides access to the exit code and the string returned\nvia standard output','provide access to string',0,'',''),(4539,'GitPython','Thrown if a hook exits with a non-zero exit code. It provides access to the exit code and the string returned\nvia standard output','return  via standard output',0,'',''),(4540,'GitPython','Thrown to indicate we can’t handle work tree repositories','handle work tree repositories',0,'',''),(4541,'GitPython','Represents a special case of a reference such that this reference is symbolic.\nIt does not point to a specific commit, but to another Head, which itself\nspecifies a commit.','specify commit',0,'',''),(4542,'GitPython','Create a new symbolic reference, hence a reference pointing , to another reference.','create new symbolic reference',0,'',''),(4543,'GitPython','Delete the reference at the given path','delete reference at given path',0,'',''),(4544,'GitPython','Find all refs in the repository','find refs in repository',0,'',''),(4545,'GitPython','List is lexicographically sorted\nThe returned objects represent actual subclasses, such as Head or TagReference','sort list',0,'',''),(4546,'GitPython','Append a logentry to the logfile of this ref','append logentry to logfile',0,'',''),(4547,'GitPython','Returns the Reference we point to','return Reference',0,'',''),(4548,'GitPython','Rename self to a new path','rename self to new path',0,'',''),(4549,'GitPython','Set the object we point to, possibly dereference our symbolic reference first.\nIf the reference does not exist, it will be created','set object',0,'',''),(4550,'GitPython','Set ourselves to the given ref. It will stay a symbol if the ref is a Reference.\nOtherwise an Object, given as Object instance or refspec, is assumed and if valid,\nwill be set which effectively detaches the reference if it was a purely\nsymbolic one.','set  to given ref',0,'',''),(4551,'GitPython','If set to a string, the message will be used in the reflog.\nOtherwise, a reflog entry is not written for the changed reference.\nThe previous commit of the entry will be the commit we point to now.','set  to string',0,'',''),(4552,'GitPython','If set to a string, the message will be used in the reflog.\nOtherwise, a reflog entry is not written for the changed reference.\nThe previous commit of the entry will be the commit we point to now.','use message in reflog',0,'',''),(4553,'GitPython','Represents a named reference to any object. Subclasses may apply restrictions though,\ni.e. Heads can only point to commits.','apply restrictions',0,'',''),(4554,'GitPython','Equivalent to SymbolicReference.iter_items, but will return non-detached\nreferences as well.','return non-detached references',0,'',''),(4555,'GitPython','Special version which checks if the head-log needs an update as well\n:return: self','check special version',0,'',''),(4556,'GitPython','Reset our HEAD to the given commit optionally synchronizing\nthe index and working tree. The reference we refer to will be set to\ncommit as well.','set reference',0,'',''),(4557,'GitPython','Checkout this head by setting the HEAD to this reference, by updating the index\nto reflect the tree we point to and by updating the working tree to reflect\nthe latest index.','checkout head by setting',0,'',''),(4558,'GitPython','Checkout this head by setting the HEAD to this reference, by updating the index\nto reflect the tree we point to and by updating the working tree to reflect\nthe latest index.','set HEAD by updating',0,'',''),(4559,'GitPython','Checkout this head by setting the HEAD to this reference, by updating the index\nto reflect the tree we point to and by updating the working tree to reflect\nthe latest index.','set HEAD by updating',0,'',''),(4560,'GitPython','Checkout this head by setting the HEAD to this reference, by updating the index\nto reflect the tree we point to and by updating the working tree to reflect\nthe latest index.','set HEAD to reference',0,'',''),(4561,'GitPython','Checkout this head by setting the HEAD to this reference, by updating the index\nto reflect the tree we point to and by updating the working tree to reflect\nthe latest index.','update index',0,'',''),(4562,'GitPython','Checkout this head by setting the HEAD to this reference, by updating the index\nto reflect the tree we point to and by updating the working tree to reflect\nthe latest index.','update working tree',0,'',''),(4563,'GitPython','Delete the given heads','delete given heads',0,'',''),(4564,'GitPython','Create a new tag reference.','create new tag reference',0,'',''),(4565,'GitPython','If not None, the message will be used in your tag object. This will also\ncreate an additional tag object that allows to obtain that information, i.e.:','use message in tag object',1,'https://gitpython.readthedocs.io/en/stable/reference.html',''),(4566,'GitPython','If not None, the message will be used in your tag object. This will also\ncreate an additional tag object that allows to obtain that information, i.e.:','create additional tag object',1,'https://gitpython.readthedocs.io/en/stable/reference.html',''),(4567,'GitPython','If not None, the message will be used in your tag object. This will also\ncreate an additional tag object that allows to obtain that information, i.e.:','obtain information',1,'https://gitpython.readthedocs.io/en/stable/reference.html',''),(4568,'GitPython','Delete the given existing tag or tags','delete given existing tag',0,'',''),(4569,'GitPython','Delete the given existing tag or tags','delete tags',0,'',''),(4570,'GitPython','Used to disable this method','disable method',0,'',''),(4571,'GitPython','Delete the given remote references','delete given remote references',0,'',''),(4572,'GitPython','A reflog contains RefLogEntrys, each of which defines a certain state\nof the head in question. Custom query methods allow to retrieve log entries\nby date or by other criteria.','define certain state of head',0,'',''),(4573,'GitPython','A reflog contains RefLogEntrys, each of which defines a certain state\nof the head in question. Custom query methods allow to retrieve log entries\nby date or by other criteria.','define RefLogEntrys of head',0,'',''),(4574,'GitPython','A reflog contains RefLogEntrys, each of which defines a certain state\nof the head in question. Custom query methods allow to retrieve log entries\nby date or by other criteria.','retrieve log entries by date',0,'',''),(4575,'GitPython','A reflog contains RefLogEntrys, each of which defines a certain state\nof the head in question. Custom query methods allow to retrieve log entries\nby date or by other criteria.','retrieve log entries by other criteria',0,'',''),(4576,'GitPython','Reflog entries are ordered, the first added entry is first in the list, the last\nentry, i.e. the last change of the head or reference, is last in the list.','order entries',0,'',''),(4577,'GitPython','Initialize this instance with an optional filepath, from which we will\ninitialize our data. The path is also used to write changes back using\nthe write() method','initialize instance with optional filepath',0,'',''),(4578,'GitPython','Initialize this instance with an optional filepath, from which we will\ninitialize our data. The path is also used to write changes back using\nthe write() method','initialize data',0,'',''),(4579,'GitPython','Initialize this instance with an optional filepath, from which we will\ninitialize our data. The path is also used to write changes back using\nthe write() method','initialize optional filepath',0,'',''),(4580,'GitPython','Initialize this instance with an optional filepath, from which we will\ninitialize our data. The path is also used to write changes back using\nthe write() method','write changes',0,'',''),(4581,'GitPython','Initialize this instance with an optional filepath, from which we will\ninitialize our data. The path is also used to write changes back using\nthe write() method','use write() method',0,'',''),(4582,'GitPython','Initialize this instance with an optional filepath, from which we will\ninitialize our data. The path is also used to write changes back using\nthe write() method','use path',0,'',''),(4583,'GitPython','Create and return a new object.  See help(type) for accurate signature.','create new object',0,'',''),(4584,'GitPython','Create and return a new object.  See help(type) for accurate signature.','return new object',0,'',''),(4585,'GitPython','Append a new log entry to the revlog at filepath.','append new log entry at filepath',0,'',''),(4586,'GitPython','Append a new log entry to the revlog at filepath.','append new log entry to revlog',0,'',''),(4587,'GitPython','Write the contents of the reflog instance to a file at the given filepath.\n:param filepath: path to file, parent directories are assumed to exist','write contents of reflog instance',0,'',''),(4588,'GitPython','Actor instance, providing access','provide access',0,'',''),(4589,'GitPython','Message describing the operation that acted on the reference','describe operation',0,'',''),(4590,'GitPython','Handler providing an interface to parse progress information emitted by git-push\nand git-fetch and to dispatch callbacks allowing subclasses to react to the progress.','provide interface',0,'',''),(4591,'GitPython','Integer allowing to be compared against Operation IDs and stage IDs.','compare  against Operation ids',0,'',''),(4592,'GitPython','Integer allowing to be compared against Operation IDs and stage IDs.','compare  against stage ids',0,'',''),(4593,'GitPython','Stage IDs are BEGIN and END. BEGIN will only be set once for each Operation\nID as well as END. It may be that BEGIN and END are set at once in case only\none progress message was emitted due to the speed of the operation.\nBetween BEGIN and END, none of these flags will be set','set BEGIN for Operation ID',0,'',''),(4594,'GitPython','Stage IDs are BEGIN and END. BEGIN will only be set once for each Operation\nID as well as END. It may be that BEGIN and END are set at once in case only\none progress message was emitted due to the speed of the operation.\nBetween BEGIN and END, none of these flags will be set','set BEGIN for END',0,'',''),(4595,'GitPython','Stage IDs are BEGIN and END. BEGIN will only be set once for each Operation\nID as well as END. It may be that BEGIN and END are set at once in case only\none progress message was emitted due to the speed of the operation.\nBetween BEGIN and END, none of these flags will be set','set BEGIN in case',0,'',''),(4596,'GitPython','Stage IDs are BEGIN and END. BEGIN will only be set once for each Operation\nID as well as END. It may be that BEGIN and END are set at once in case only\none progress message was emitted due to the speed of the operation.\nBetween BEGIN and END, none of these flags will be set','set END in case',0,'',''),(4597,'GitPython','Stage IDs are BEGIN and END. BEGIN will only be set once for each Operation\nID as well as END. It may be that BEGIN and END are set at once in case only\none progress message was emitted due to the speed of the operation.\nBetween BEGIN and END, none of these flags will be set','set none of flags',0,'',''),(4598,'GitPython','Stage IDs are BEGIN and END. BEGIN will only be set once for each Operation\nID as well as END. It may be that BEGIN and END are set at once in case only\none progress message was emitted due to the speed of the operation.\nBetween BEGIN and END, none of these flags will be set','set none between BEGIN',0,'',''),(4599,'GitPython','Stage IDs are BEGIN and END. BEGIN will only be set once for each Operation\nID as well as END. It may be that BEGIN and END are set at once in case only\none progress message was emitted due to the speed of the operation.\nBetween BEGIN and END, none of these flags will be set','set none between END',0,'',''),(4600,'GitPython','You may read the contents of the current line in self._cur_line','read contents of current line',0,'',''),(4601,'GitPython','Initialize a new instance','initialize new instance',0,'',''),(4602,'GitPython','Provides easy read and write access to a git remote.','read access to git remote',0,'',''),(4603,'GitPython','Provides easy read and write access to a git remote.','write access to git remote',0,'',''),(4604,'GitPython','NOTE: When querying configuration, the configuration accessor will be cached\nto speed up subsequent accesses.','cache configuration accessor',0,'',''),(4605,'GitPython','Allows to call this instance like\nremote.special( *args, **kwargs) to call git-remote special self.name','call instance like remote.special( *args, **kwargs)',0,'',''),(4606,'GitPython','Allows to call this instance like\nremote.special( *args, **kwargs) to call git-remote special self.name','call git-remote special self.name',0,'',''),(4607,'GitPython','Initialize a remote instance','initialize remote instance',0,'',''),(4608,'GitPython','Adds a new url on current remote (special case of git remote set_url)','add new url on current remote',0,'',''),(4609,'GitPython','This command adds new URLs to a given remote, making it possible to have\nmultiple URLs for a single remote.','add new urls to given remote',0,'',''),(4610,'GitPython','Create a new remote to the given repository\n:param repo: Repository instance that is to receive the new remote\n:param name: Desired name of the remote\n:param url: URL which corresponds to the remote’s name\n:param kwargs: Additional arguments to be passed to the git-remote add command\n:return: New Remote instance\n:raise GitCommandError: in case an origin with that name already exists','create  to given repository',0,'',''),(4611,'GitPython','Create a new remote to the given repository\n:param repo: Repository instance that is to receive the new remote\n:param name: Desired name of the remote\n:param url: URL which corresponds to the remote’s name\n:param kwargs: Additional arguments to be passed to the git-remote add command\n:return: New Remote instance\n:raise GitCommandError: in case an origin with that name already exists','pass additional arguments to git-remote add command',0,'',''),(4612,'GitPython','Deletes a new url on current remote (special case of git remote set_url)','delete new url on current remote',0,'',''),(4613,'GitPython','This command deletes new URLs to a given remote, making it possible to have\nmultiple URLs for a single remote.','delete new urls to given remote',0,'',''),(4614,'GitPython','Fetch the latest changes for this remote','fetch latest changes',0,'',''),(4615,'GitPython','A “refspec” is used by fetch and push to describe the mapping\nbetween remote ref and local ref. They are combined with a colon in\nthe format :, preceded by an optional plus sign, +.\nFor example: git fetch $URL refs/heads/master:refs/heads/origin means\n“grab the master branch head from the $URL and store it as my origin\nbranch head”. And git push $URL refs/heads/master:refs/heads/to-upstream\nmeans “publish my master branch head as to-upstream branch at $URL”.\nSee also git-push(1).','describe mapping between local ref',0,'',''),(4616,'GitPython','A “refspec” is used by fetch and push to describe the mapping\nbetween remote ref and local ref. They are combined with a colon in\nthe format :, preceded by an optional plus sign, +.\nFor example: git fetch $URL refs/heads/master:refs/heads/origin means\n“grab the master branch head from the $URL and store it as my origin\nbranch head”. And git push $URL refs/heads/master:refs/heads/to-upstream\nmeans “publish my master branch head as to-upstream branch at $URL”.\nSee also git-push(1).','describe mapping between remote ref',0,'',''),(4617,'GitPython','A “refspec” is used by fetch and push to describe the mapping\nbetween remote ref and local ref. They are combined with a colon in\nthe format :, preceded by an optional plus sign, +.\nFor example: git fetch $URL refs/heads/master:refs/heads/origin means\n“grab the master branch head from the $URL and store it as my origin\nbranch head”. And git push $URL refs/heads/master:refs/heads/to-upstream\nmeans “publish my master branch head as to-upstream branch at $URL”.\nSee also git-push(1).','use refspec',0,'',''),(4618,'GitPython','A “refspec” is used by fetch and push to describe the mapping\nbetween remote ref and local ref. They are combined with a colon in\nthe format :, preceded by an optional plus sign, +.\nFor example: git fetch $URL refs/heads/master:refs/heads/origin means\n“grab the master branch head from the $URL and store it as my origin\nbranch head”. And git push $URL refs/heads/master:refs/heads/to-upstream\nmeans “publish my master branch head as to-upstream branch at $URL”.\nSee also git-push(1).','combine  with colon',0,'',''),(4619,'GitPython','A “refspec” is used by fetch and push to describe the mapping\nbetween remote ref and local ref. They are combined with a colon in\nthe format :, preceded by an optional plus sign, +.\nFor example: git fetch $URL refs/heads/master:refs/heads/origin means\n“grab the master branch head from the $URL and store it as my origin\nbranch head”. And git push $URL refs/heads/master:refs/heads/to-upstream\nmeans “publish my master branch head as to-upstream branch at $URL”.\nSee also git-push(1).','store  as origin branch head',0,'',''),(4620,'GitPython','Fetch supports multiple refspecs (as the\nunderlying git-fetch does) - supplying a list rather than a string\nfor ‘refspec’ will make use of this facility.','support multiple refspecs',0,'',''),(4621,'GitPython','Push changes from source branch in refspec to target branch in refspec.','change  from source branch',0,'',''),(4622,'GitPython','Remove the remote with the given name\n:return: the passed remote name to remove','remove  with given name',0,'',''),(4623,'GitPython','This command manages URLs on the remote.','manage urls',0,'',''),(4624,'GitPython','The IterableList is prefixed, hence the ‘origin’ must be omitted. See\n‘refs’ property for an example.','prefix IterableList',0,'',''),(4625,'GitPython','The IterableList is prefixed, hence the ‘origin’ must be omitted. See\n‘refs’ property for an example.','omit âoriginâ',0,'',''),(4626,'GitPython','To make things more complicated, it can be possible for the list to include\nother kinds of references, for example, tag references, if these are stale\nas well. This is a fix for the issue described here:\nhttps://github.com/gitpython-developers/GitPython/issues/260','include other kinds of references',0,'',''),(4627,'GitPython','To make things more complicated, it can be possible for the list to include\nother kinds of references, for example, tag references, if these are stale\nas well. This is a fix for the issue described here:\nhttps://github.com/gitpython-developers/GitPython/issues/260','describe https://github.com/gitpython-developers/GitPython/issues/260',0,'',''),(4628,'GitPython','Fetch all changes for this remote, including new branches which will\nbe forced in ( in case your local remote branch is not part the new remote branches\nancestry anymore ).','fetch changes including new branches',0,'',''),(4629,'GitPython','Fetch all changes for this remote, including new branches which will\nbe forced in ( in case your local remote branch is not part the new remote branches\nancestry anymore ).','force new branches',0,'',''),(4630,'GitPython','Represents a git repository and allows you to query references,\ngather commit information, generate diffs, create and clone repositories query\nthe log.','generate diffs',0,'',''),(4631,'GitPython','‘working_tree_dir’ is the working tree directory, but will raise AssertionError\nif we are a bare repository.','raise AssertionError',0,'',''),(4632,'GitPython','‘git_dir’ is the .git repository directory, which is always set.','set repository directory',0,'',''),(4633,'GitPython','Create a new Repo instance','create new Repo instance',0,'',''),(4634,'GitPython','if True, all parent directories will be searched for a valid repo as well.','search parent directories for valid repo',0,'',''),(4635,'GitPython','Retrieve a list of alternates paths or set a list paths to be used as alternates','retrieve list of alternates paths',0,'',''),(4636,'GitPython','Retrieve a list of alternates paths or set a list paths to be used as alternates','set list of alternates paths',0,'',''),(4637,'GitPython','Retrieve a list of alternates paths or set a list paths to be used as alternates','use list paths as alternates',0,'',''),(4638,'GitPython','Archive the tree at the given revision.','archive tree at given revision',0,'',''),(4639,'GitPython','If you combine all line number ranges outputted by this command, you\nshould get a continuous range spanning all line numbers in the file.','get continuous range',0,'',''),(4640,'GitPython','Create a clone from this repository.','create clone from repository',0,'',''),(4641,'GitPython','Create a clone from the given URL','create clone from given URL',0,'',''),(4642,'GitPython','The configuration will include values from the system, user and repository\nconfiguration files.','include values from system user repository configuration files',0,'',''),(4643,'GitPython','Create a new head within the repository.\nFor more documentation, please see the Head.create method.','create new head within repository',0,'',''),(4644,'GitPython','Create a new submodule','create new submodule',0,'',''),(4645,'GitPython','Create a new tag reference.\nFor more documentation, please see the TagReference.create method.','create new tag reference',0,'',''),(4646,'GitPython','Delete the given remote.','delete given remote',0,'',''),(4647,'GitPython','Delete the given tag references','delete given tag references',0,'',''),(4648,'GitPython','Checks if paths are ignored via .gitignore\nDoing so using the “git check-ignore” method.','ignore paths',0,'',''),(4649,'GitPython','Checks if paths are ignored via .gitignore\nDoing so using the “git check-ignore” method.','use git check-ignore method',0,'',''),(4650,'GitPython','Initialize a git repository at the given path if specified','initialize git repository at given path',0,'',''),(4651,'GitPython','Find the closest common ancestor for the given revision (e.g. Commits, Tags, References, etc)','find closest common ancestor for given revision',0,'',''),(4652,'GitPython','A list of Remote objects allowing to access and manipulate remotes\n:return: git.IterableList(Remote, ...)','access remotes',0,'',''),(4653,'GitPython','A list of Remote objects allowing to access and manipulate remotes\n:return: git.IterableList(Remote, ...)','manipulate remotes',0,'',''),(4654,'GitPython','Search for a submodule repo.','search  for submodule repo',0,'',''),(4655,'GitPython','Recursively dereference a tag and return the resulting object','return resulting object',0,'',''),(4656,'GitPython','Convert the given object to a commit if possible and return it','convert given object to commit possible',0,'',''),(4657,'GitPython','Search for a gitdir for this worktree.','search  for gitdir',0,'',''),(4658,'GitPython','Join path tokens together similar to osp.join, but always use\n‘/’ instead of possibly ‘’ on windows.','use â/â instead_of ââ',0,'',''),(4659,'GitPython','Represents stat information as presented by git at the end of a merge. It is\ncreated from the output of a diff operation.','present  at end',1,'https://gitpython.readthedocs.io/en/stable/reference.html',''),(4660,'GitPython','Represents stat information as presented by git at the end of a merge. It is\ncreated from the output of a diff operation.','present  by git',1,'https://gitpython.readthedocs.io/en/stable/reference.html',''),(4661,'GitPython','Represents stat information as presented by git at the end of a merge. It is\ncreated from the output of a diff operation.','create  from output',1,'https://gitpython.readthedocs.io/en/stable/reference.html',''),(4662,'GitPython','Wrapper around a file-like object that remembers the SHA1 of\nthe data written to it. It will write a sha when the stream is closed\nor if the asked for explicitly using write_sha.','write sha',0,'',''),(4663,'GitPython','Wrapper around a file-like object that remembers the SHA1 of\nthe data written to it. It will write a sha when the stream is closed\nor if the asked for explicitly using write_sha.','use write_sha',0,'',''),(4664,'GitPython','Defines an interface for iterable items which is to assure a uniform\nway to retrieve and iterate items within the git repository','define interface for iterable items',0,'',''),(4665,'GitPython','Defines an interface for iterable items which is to assure a uniform\nway to retrieve and iterate items within the git repository','retrieve items within git repository',0,'',''),(4666,'GitPython','Find all items of this type - subclasses can specify args and kwargs differently.\nIf no args are given, subclasses are obliged to return all items if no additional\narguments arg given.','find items of type',0,'',''),(4667,'GitPython','Find all items of this type - subclasses can specify args and kwargs differently.\nIf no args are given, subclasses are obliged to return all items if no additional\narguments arg given.','specify args',0,'',''),(4668,'GitPython','Find all items of this type - subclasses can specify args and kwargs differently.\nIf no args are given, subclasses are obliged to return all items if no additional\narguments arg given.','specify kwargs',0,'',''),(4669,'GitPython','Find all items of this type - subclasses can specify args and kwargs differently.\nIf no args are given, subclasses are obliged to return all items if no additional\narguments arg given.','return items',0,'',''),(4670,'GitPython','Iterable parent objects = [Commit, SubModule, Reference, FetchInfo, PushInfo]\nIterable via inheritance = [Head, TagReference, RemoteReference]\n]\nIt requires an id_attribute name to be set which will be queried from its\ncontained items to have a means for comparison.','set id_attribute name',0,'',''),(4671,'GitPython','A prefix can be specified which is to be used in case the id returned by the\nitems always contains a prefix that does not matter to the user, so it\ncan be left out.','use  in case',0,'',''),(4672,'GitPython','A prefix can be specified which is to be used in case the id returned by the\nitems always contains a prefix that does not matter to the user, so it\ncan be left out.','specify prefix',0,'',''),(4673,'GitPython','The lock file will block until a lock could be obtained, or fail after\na specified timeout.','obtain lock',0,'',''),(4674,'GitPython','Configure the instance','configure instance',0,'',''),(4675,'GitPython','Provides methods to obtain, check for, and release a file based lock which\nshould be used to handle concurrent access to the same file.','release file',0,'',''),(4676,'GitPython','Provides methods to obtain, check for, and release a file based lock which\nshould be used to handle concurrent access to the same file.','handle concurrent access to same file',0,'',''),(4677,'GitPython','Provides methods to obtain, check for, and release a file based lock which\nshould be used to handle concurrent access to the same file.','use lock',0,'',''),(4678,'GitPython','As we are a utility class to be derived from, we only use protected methods.','use protected methods',0,'',''),(4679,'GitPython','Locks will automatically be released on destruction','release locks on destruction',0,'',''),(4680,'GitPython','Remove the given recursively.','remove given recursively',0,'',''),(4681,'GitPython','Methods with this decorator raise InvalidGitRepositoryError if they\nencounter a bare repository','raise InvalidGitRepositoryError',0,'',''),(4682,'GitPython','We need an easy way to see if Appveyor TCs start failing,\nso the errors marked with this var are considered “acknowledged” ones, awaiting remedy,\ntill then, we wish to hide them.','mark  with var',0,'',''),(4683,'GitPython','Properly signed re-release of v3.0.6 with new signature\n(See #980)','sign re-release with new signature',0,'',''),(4684,'GitPython','Properly signed re-release of v3.0.6 with new signature\n(See #980)','sign re-release of v3.0.6',0,'',''),(4685,'GitPython','Motivation for this is a patch which improves unicode handling when dealing with filesystem paths.\nPython 2 compatibility was introduced to deal with differences, and I thought it would be a good idea\nto ‘just’ drop support right now, mere 5 months away from the official maintenance stop of python 2.7.','introduce Python',0,'',''),(4686,'GitPython','The underlying motivation clearly is my anger when thinking python and unicode, which was a hassle from the\nstart, at least in a codebase as old as GitPython, which totally doesn’t handle encodings correctly in many cases.','handle encodings as GitPython',0,'',''),(4687,'GitPython','The underlying motivation clearly is my anger when thinking python and unicode, which was a hassle from the\nstart, at least in a codebase as old as GitPython, which totally doesn’t handle encodings correctly in many cases.','handle encodings in many cases',0,'',''),(4688,'GitPython','The underlying motivation clearly is my anger when thinking python and unicode, which was a hassle from the\nstart, at least in a codebase as old as GitPython, which totally doesn’t handle encodings correctly in many cases.','handle codebase old as GitPython',0,'',''),(4689,'GitPython','The underlying motivation clearly is my anger when thinking python and unicode, which was a hassle from the\nstart, at least in a codebase as old as GitPython, which totally doesn’t handle encodings correctly in many cases.','handle codebase old in many cases',0,'',''),(4690,'GitPython','Having migrated to using Rust exclusively for tooling, I still see that correct handling of encodings isn’t entirely\ntrivial, but at least Rust makes clear what has to be done at compile time, allowing to write software that is pretty\nmuch guaranteed to work once it compiles.','use rust for tooling',0,'',''),(4691,'GitPython','Having migrated to using Rust exclusively for tooling, I still see that correct handling of encodings isn’t entirely\ntrivial, but at least Rust makes clear what has to be done at compile time, allowing to write software that is pretty\nmuch guaranteed to work once it compiles.','write software',0,'',''),(4692,'GitPython','Again, my apologies if removing Python 2 support caused inconveniences, please see release 2.1.13 which returns it.','remove Python support',0,'',''),(4693,'GitPython','Again, my apologies if removing Python 2 support caused inconveniences, please see release 2.1.13 which returns it.','return release 2.1.13',0,'',''),(4694,'GitPython','My apologies for any inconvenience this may have caused. Following semver, backward incompatible changes\nwill be introduced in a minor version.','introduce incompatible changes in minor version',0,'',''),(4695,'GitPython','My apologies for any inconvenience this may have caused. Following semver, backward incompatible changes\nwill be introduced in a minor version.','introduce incompatible changes following semver',0,'',''),(4696,'GitPython','Special thanks to @ankostis, who made this release possible (nearly) single-handedly.\nGitPython is run by its users, and their PRs make all the difference, they keep\nGitPython relevant. Thank you all so much for contributing !','run GitPython',0,'',''),(4697,'GitPython','Please note that due to breaking changes, we have to increase the major version.','break changes',0,'',''),(4698,'GitPython','GitPython provides object model access to your git repository. This tutorial is composed of multiple sections, most of which explain a real-life use case.','provide object model access to git repository',0,'',''),(4699,'GitPython','GitPython provides object model access to your git repository. This tutorial is composed of multiple sections, most of which explain a real-life use case.','compose tutorial of multiple sections',0,'',''),(4700,'GitPython','All code presented here originated from test_docs.py to assure correctness. Knowing this should also allow you to more easily run the code for your own testing purposes. All you need is a developer installation of git-python.','run code for own testing purposes',0,'',''),(4701,'GitPython','The first step is to create a git.Repo object to represent your repository.','create git.Repo object',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4702,'GitPython','In the above example, the directory self.rorepo.working_tree_dir equals /Users/mtrier/Development/git-python and is my working repository which contains the .git directory. You can also initialize GitPython with a bare repository.','initialize GitPython with bare repository',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4703,'GitPython','A repo object provides high-level access to your data, it allows you to create and delete heads, tags and remotes and access the configuration of the repository.','provide high-level access to data',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4704,'GitPython','A repo object provides high-level access to your data, it allows you to create and delete heads, tags and remotes and access the configuration of the repository.','create heads',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4705,'GitPython','A repo object provides high-level access to your data, it allows you to create and delete heads, tags and remotes and access the configuration of the repository.','create tags',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4706,'GitPython','A repo object provides high-level access to your data, it allows you to create and delete heads, tags and remotes and access the configuration of the repository.','create remotes',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4707,'GitPython','A repo object provides high-level access to your data, it allows you to create and delete heads, tags and remotes and access the configuration of the repository.','delete heads',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4708,'GitPython','A repo object provides high-level access to your data, it allows you to create and delete heads, tags and remotes and access the configuration of the repository.','delete tags',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4709,'GitPython','A repo object provides high-level access to your data, it allows you to create and delete heads, tags and remotes and access the configuration of the repository.','delete remotes',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4710,'GitPython','A repo object provides high-level access to your data, it allows you to create and delete heads, tags and remotes and access the configuration of the repository.','access configuration of repository',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4711,'GitPython','Query the active branch, query untracked files or whether the repository data has been modified.','modify active branch',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4712,'GitPython','Query the active branch, query untracked files or whether the repository data has been modified.','modify query untracked files',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4713,'GitPython','Query the active branch, query untracked files or whether the repository data has been modified.','modify whether repository data',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4714,'GitPython','Clone from existing repositories or initialize new empty ones.','initialize new empty ones',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4715,'GitPython','Clone from existing repositories or initialize new empty ones.','clone  from existing repositories',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4716,'GitPython','You can also create new heads …','create new heads',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4717,'GitPython','Remotes allow to handle fetch, pull and push operations, while providing optional real-time progress information to progress delegates.','fetch operations',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4718,'GitPython','Remotes allow to handle fetch, pull and push operations, while providing optional real-time progress information to progress delegates.','push operations',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4719,'GitPython','Remotes allow to handle fetch, pull and push operations, while providing optional real-time progress information to progress delegates.','provide optional real-time progress information to progress delegates',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4720,'GitPython','The index is also called stage in git-speak. It is used to prepare new commits, and can be used to keep results of merge operations. Our index implementation allows to stream date into the index, which is useful for bare repositories that do not have a working tree.','call stage in git-speak',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4721,'GitPython','The index is also called stage in git-speak. It is used to prepare new commits, and can be used to keep results of merge operations. Our index implementation allows to stream date into the index, which is useful for bare repositories that do not have a working tree.','call index in git-speak',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4722,'GitPython','The index is also called stage in git-speak. It is used to prepare new commits, and can be used to keep results of merge operations. Our index implementation allows to stream date into the index, which is useful for bare repositories that do not have a working tree.','prepare new commits',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4723,'GitPython','Submodules represent all aspects of git submodules, which allows you query all of their related information, and manipulate in various ways.','manipulate  in various ways',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4724,'GitPython','Access the reflog easily.','access reflog',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4725,'GitPython','You can easily create and delete reference types or modify where they point to.','create reference types',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4726,'GitPython','You can easily create and delete reference types or modify where they point to.','delete reference types',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4727,'GitPython','You can easily create and delete reference types or modify where they point to.','modify reference types',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4728,'GitPython','Change the symbolic reference to switch branches cheaply (without adjusting the index or the working tree).','change symbolic reference',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4729,'GitPython','Change the symbolic reference to switch branches cheaply (without adjusting the index or the working tree).','switch branches',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4730,'GitPython','An Object is anything storable in git’s object database. Objects contain information about their type, their uncompressed size as well as the actual data. Each object is uniquely identified by a binary SHA1 hash, being 20 bytes in size, or 40 bytes in hexadecimal notation.','identify object',0,'',''),(4731,'GitPython','In GitPython, all objects can be accessed through their common base, can be compared and hashed. They are usually not instantiated directly, but through references or specialized repository functions.','access objects through common base',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4732,'GitPython','In GitPython, all objects can be accessed through their common base, can be compared and hashed. They are usually not instantiated directly, but through references or specialized repository functions.','access objects in GitPython',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4733,'GitPython','In GitPython, all objects can be accessed through their common base, can be compared and hashed. They are usually not instantiated directly, but through references or specialized repository functions.','compare objects',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4734,'GitPython','Commit objects contain information about a specific commit. Obtain commits using  references as done in Examining References or as follows.','use references',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4735,'GitPython','Iterate 50 commits, and if you need paging, you can specify a number of commits to skip.','specify number of commits',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4736,'GitPython','Once you have a tree, you can get its contents','get contents',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4737,'GitPython','There is a convenience method that allows you to get a named sub-object from a tree with a syntax similar to how paths are written in a posix system','get named sub-object from tree',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4738,'GitPython','There is a convenience method that allows you to get a named sub-object from a tree with a syntax similar to how paths are written in a posix system','write paths in posix system',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4739,'GitPython','You can also get a commit’s root tree directly from the repository','get root tree from repository',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4740,'GitPython','As trees allow direct access to their intermediate child entries only, use the traverse method to obtain an iterator to retrieve entries recursively','use traverse method',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4741,'GitPython','As trees allow direct access to their intermediate child entries only, use the traverse method to obtain an iterator to retrieve entries recursively','obtain iterator',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4742,'GitPython','As trees allow direct access to their intermediate child entries only, use the traverse method to obtain an iterator to retrieve entries recursively','retrieve entries',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4743,'GitPython','The git index is the stage containing changes to be written with the next commit or where merges finally have to take place. You may freely access and manipulate this information using the IndexFile object.\nModify the index with ease','write  with next commit',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4744,'GitPython','The git index is the stage containing changes to be written with the next commit or where merges finally have to take place. You may freely access and manipulate this information using the IndexFile object.\nModify the index with ease','access information',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4745,'GitPython','The git index is the stage containing changes to be written with the next commit or where merges finally have to take place. You may freely access and manipulate this information using the IndexFile object.\nModify the index with ease','manipulate information',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4746,'GitPython','The git index is the stage containing changes to be written with the next commit or where merges finally have to take place. You may freely access and manipulate this information using the IndexFile object.\nModify the index with ease','use IndexFile object',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4747,'GitPython','Create new indices from other trees or as result of a merge. Write that result to a new index file for later inspection.','create new indices as result',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4748,'GitPython','Create new indices from other trees or as result of a merge. Write that result to a new index file for later inspection.','create new indices from other trees',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4749,'GitPython','Create new indices from other trees or as result of a merge. Write that result to a new index file for later inspection.','write result to new index file',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4750,'GitPython','Remotes are used as alias for a foreign repository to ease pushing to and fetching from them','use remotes as alias',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4751,'GitPython','You can easily access configuration information for a remote by accessing options as if they were attributes. The modification of remote configuration is more explicit though.','access configuration information by accessing',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4752,'GitPython','You can easily access configuration information for a remote by accessing options as if they were attributes. The modification of remote configuration is more explicit though.','access options',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4753,'GitPython','You can also specify per-call custom environments using a new context manager on the Git command, e.g. for using a specific SSH key. The following example works with git starting at v2.3:','specify per-call custom environments',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4754,'GitPython','You can also specify per-call custom environments using a new context manager on the Git command, e.g. for using a specific SSH key. The following example works with git starting at v2.3:','use e.g. on git command',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4755,'GitPython','You can also specify per-call custom environments using a new context manager on the Git command, e.g. for using a specific SSH key. The following example works with git starting at v2.3:','use new context manager on git command',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4756,'GitPython','You can also specify per-call custom environments using a new context manager on the Git command, e.g. for using a specific SSH key. The following example works with git starting at v2.3:','use specific SSH key',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4757,'GitPython','This one sets a custom script to be executed in place of ssh, and can be used in git prior to v2.3:','execute custom script in_place_of ssh',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4758,'GitPython','This one sets a custom script to be executed in place of ssh, and can be used in git prior to v2.3:','use  in git',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4759,'GitPython','Here’s an example executable that can be used in place of the ssh_executable above:','use example executable in_place_of ssh_executable',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4760,'GitPython','Please note that the script must be executable (i.e. chmod +x script.sh). StrictHostKeyChecking=no is used to avoid prompts asking to save the hosts key to ~/.ssh/known_hosts, which happens in case you run this as daemon.','save hosts key to ~ /.ssh/known_hosts',0,'',''),(4761,'GitPython','Submodules can be conveniently handled using the methods provided by GitPython, and as an added benefit, GitPython provides functionality which behave smarter and less error prone than its original c-git implementation, that is GitPython tries hard to keep your repository consistent when updating submodules recursively or adjusting the existing configuration.','use methods',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4762,'GitPython','Submodules can be conveniently handled using the methods provided by GitPython, and as an added benefit, GitPython provides functionality which behave smarter and less error prone than its original c-git implementation, that is GitPython tries hard to keep your repository consistent when updating submodules recursively or adjusting the existing configuration.','provide  as added benefit',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4763,'GitPython','Submodules can be conveniently handled using the methods provided by GitPython, and as an added benefit, GitPython provides functionality which behave smarter and less error prone than its original c-git implementation, that is GitPython tries hard to keep your repository consistent when updating submodules recursively or adjusting the existing configuration.','update submodules',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4764,'GitPython','Submodules can be conveniently handled using the methods provided by GitPython, and as an added benefit, GitPython provides functionality which behave smarter and less error prone than its original c-git implementation, that is GitPython tries hard to keep your repository consistent when updating submodules recursively or adjusting the existing configuration.','adjust existing configuration',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4765,'GitPython','Submodules can be conveniently handled using the methods provided by GitPython, and as an added benefit, GitPython provides functionality which behave smarter and less error prone than its original c-git implementation, that is GitPython tries hard to keep your repository consistent when updating submodules recursively or adjusting the existing configuration.','handle submodules',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4766,'GitPython','In addition to the query functionality, you can move the submodule’s repository to a different path <move(...)>,\nwrite its configuration <config_writer().set_value(...).release()>, update its working tree <update(...)>,\nand remove or add them <remove(...), add(...)>.','move repository move(...) &gt;',0,'',''),(4767,'GitPython','In addition to the query functionality, you can move the submodule’s repository to a different path <move(...)>,\nwrite its configuration <config_writer().set_value(...).release()>, update its working tree <update(...)>,\nand remove or add them <remove(...), add(...)>.','add repository move(...) &gt;',0,'',''),(4768,'GitPython','In addition to the query functionality, you can move the submodule’s repository to a different path <move(...)>,\nwrite its configuration <config_writer().set_value(...).release()>, update its working tree <update(...)>,\nand remove or add them <remove(...), add(...)>.','write configuration &lt; config_writer().set_value(...).release() &gt;',0,'',''),(4769,'GitPython','In addition to the query functionality, you can move the submodule’s repository to a different path <move(...)>,\nwrite its configuration <config_writer().set_value(...).release()>, update its working tree <update(...)>,\nand remove or add them <remove(...), add(...)>.','update working tree &lt; update(...) &gt;',0,'',''),(4770,'GitPython','If you obtained your submodule object by traversing a tree object which is not rooted at the head’s commit,\nyou have to inform the submodule about its actual commit to retrieve the data from\nby using the set_parent_commit(...) method.','obtain submodule object by traversing',0,'',''),(4771,'GitPython','If you obtained your submodule object by traversing a tree object which is not rooted at the head’s commit,\nyou have to inform the submodule about its actual commit to retrieve the data from\nby using the set_parent_commit(...) method.','retrieve data',0,'',''),(4772,'GitPython','If you obtained your submodule object by traversing a tree object which is not rooted at the head’s commit,\nyou have to inform the submodule about its actual commit to retrieve the data from\nby using the set_parent_commit(...) method.','use set_parent_commit(...) method',0,'',''),(4773,'GitPython','The special RootModule type allows you to treat your master repository as root of a hierarchy of submodules, which allows very convenient submodule handling. Its update(...) method is reimplemented to provide an advanced way of updating submodules as they change their values over time. The update method will track changes and make sure your working tree and submodule checkouts stay consistent, which is very useful in case submodules get deleted or added to name just two of the handled cases.','provide advanced way of updating',0,'',''),(4774,'GitPython','The special RootModule type allows you to treat your master repository as root of a hierarchy of submodules, which allows very convenient submodule handling. Its update(...) method is reimplemented to provide an advanced way of updating submodules as they change their values over time. The update method will track changes and make sure your working tree and submodule checkouts stay consistent, which is very useful in case submodules get deleted or added to name just two of the handled cases.','update submodules',0,'',''),(4775,'GitPython','The special RootModule type allows you to treat your master repository as root of a hierarchy of submodules, which allows very convenient submodule handling. Its update(...) method is reimplemented to provide an advanced way of updating submodules as they change their values over time. The update method will track changes and make sure your working tree and submodule checkouts stay consistent, which is very useful in case submodules get deleted or added to name just two of the handled cases.','change values over time',0,'',''),(4776,'GitPython','The special RootModule type allows you to treat your master repository as root of a hierarchy of submodules, which allows very convenient submodule handling. Its update(...) method is reimplemented to provide an advanced way of updating submodules as they change their values over time. The update method will track changes and make sure your working tree and submodule checkouts stay consistent, which is very useful in case submodules get deleted or added to name just two of the handled cases.','track changes',0,'',''),(4777,'GitPython','Additionally, GitPython adds functionality to track a specific branch, instead of just a commit. Supported by customized update methods, you are able to automatically update submodules to the latest revision available in the remote repository, as well as to keep track of changes and movements of these submodules. To use it, set the name of the branch you want to track to the submodule.$name.branch option of the .gitmodules  file, and use GitPython update methods on the resulting repository with the to_latest_revision parameter turned on. In the latter case, the sha of your submodule will be ignored, instead a local tracking branch will be updated to the respective remote branch automatically, provided there are no local changes. The resulting behaviour is much like the one of svn::externals, which can be useful in times.','track commit',0,'',''),(4778,'GitPython','Additionally, GitPython adds functionality to track a specific branch, instead of just a commit. Supported by customized update methods, you are able to automatically update submodules to the latest revision available in the remote repository, as well as to keep track of changes and movements of these submodules. To use it, set the name of the branch you want to track to the submodule.$name.branch option of the .gitmodules  file, and use GitPython update methods on the resulting repository with the to_latest_revision parameter turned on. In the latter case, the sha of your submodule will be ignored, instead a local tracking branch will be updated to the respective remote branch automatically, provided there are no local changes. The resulting behaviour is much like the one of svn::externals, which can be useful in times.','track specific branch',0,'',''),(4779,'GitPython','Additionally, GitPython adds functionality to track a specific branch, instead of just a commit. Supported by customized update methods, you are able to automatically update submodules to the latest revision available in the remote repository, as well as to keep track of changes and movements of these submodules. To use it, set the name of the branch you want to track to the submodule.$name.branch option of the .gitmodules  file, and use GitPython update methods on the resulting repository with the to_latest_revision parameter turned on. In the latter case, the sha of your submodule will be ignored, instead a local tracking branch will be updated to the respective remote branch automatically, provided there are no local changes. The resulting behaviour is much like the one of svn::externals, which can be useful in times.','update submodules to latest revision available',0,'',''),(4780,'GitPython','Additionally, GitPython adds functionality to track a specific branch, instead of just a commit. Supported by customized update methods, you are able to automatically update submodules to the latest revision available in the remote repository, as well as to keep track of changes and movements of these submodules. To use it, set the name of the branch you want to track to the submodule.$name.branch option of the .gitmodules  file, and use GitPython update methods on the resulting repository with the to_latest_revision parameter turned on. In the latter case, the sha of your submodule will be ignored, instead a local tracking branch will be updated to the respective remote branch automatically, provided there are no local changes. The resulting behaviour is much like the one of svn::externals, which can be useful in times.','set name of branch',0,'',''),(4781,'GitPython','Additionally, GitPython adds functionality to track a specific branch, instead of just a commit. Supported by customized update methods, you are able to automatically update submodules to the latest revision available in the remote repository, as well as to keep track of changes and movements of these submodules. To use it, set the name of the branch you want to track to the submodule.$name.branch option of the .gitmodules  file, and use GitPython update methods on the resulting repository with the to_latest_revision parameter turned on. In the latter case, the sha of your submodule will be ignored, instead a local tracking branch will be updated to the respective remote branch automatically, provided there are no local changes. The resulting behaviour is much like the one of svn::externals, which can be useful in times.','track  to submodule',0,'',''),(4782,'GitPython','Additionally, GitPython adds functionality to track a specific branch, instead of just a commit. Supported by customized update methods, you are able to automatically update submodules to the latest revision available in the remote repository, as well as to keep track of changes and movements of these submodules. To use it, set the name of the branch you want to track to the submodule.$name.branch option of the .gitmodules  file, and use GitPython update methods on the resulting repository with the to_latest_revision parameter turned on. In the latter case, the sha of your submodule will be ignored, instead a local tracking branch will be updated to the respective remote branch automatically, provided there are no local changes. The resulting behaviour is much like the one of svn::externals, which can be useful in times.','ignore sha in latter case',0,'',''),(4783,'GitPython','Additionally, GitPython adds functionality to track a specific branch, instead of just a commit. Supported by customized update methods, you are able to automatically update submodules to the latest revision available in the remote repository, as well as to keep track of changes and movements of these submodules. To use it, set the name of the branch you want to track to the submodule.$name.branch option of the .gitmodules  file, and use GitPython update methods on the resulting repository with the to_latest_revision parameter turned on. In the latter case, the sha of your submodule will be ignored, instead a local tracking branch will be updated to the respective remote branch automatically, provided there are no local changes. The resulting behaviour is much like the one of svn::externals, which can be useful in times.','ignore sha of submodule',0,'',''),(4784,'GitPython','Diffs can generally be obtained by subclasses of Diffable as they provide the diff method. This operation yields a DiffIndex allowing you to easily access diff information about paths.','provide diff method',0,'',''),(4785,'GitPython','Diffs can generally be obtained by subclasses of Diffable as they provide the diff method. This operation yields a DiffIndex allowing you to easily access diff information about paths.','obtain diffs',0,'',''),(4786,'GitPython','Diffs can generally be obtained by subclasses of Diffable as they provide the diff method. This operation yields a DiffIndex allowing you to easily access diff information about paths.','access diff information about paths',0,'',''),(4787,'GitPython','Diffs can be made between the Index and Trees, Index and the working tree, trees and trees as well as trees and the working copy. If commits are involved, their tree will be used implicitly.','use tree',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4788,'GitPython','Use the diff framework if you want to implement git-status like functionality.','use diff framework',0,'',''),(4789,'GitPython','Use the diff framework if you want to implement git-status like functionality.','implement git-status',0,'',''),(4790,'GitPython','To switch between branches similar to git checkout, you effectively need to point your HEAD symbolic reference to the new branch and reset your index and working copy to match. A simple manual way to do it is the following one','switch  between branches similar',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4791,'GitPython','The previous approach would brutally overwrite the user’s changes in the working copy and index though and is less sophisticated than a git-checkout. The latter will generally prevent you from destroying your work. Use the safer approach as follows.','overwrite changes in index',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4792,'GitPython','The previous approach would brutally overwrite the user’s changes in the working copy and index though and is less sophisticated than a git-checkout. The latter will generally prevent you from destroying your work. Use the safer approach as follows.','overwrite changes in working copy',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4793,'GitPython','The previous approach would brutally overwrite the user’s changes in the working copy and index though and is less sophisticated than a git-checkout. The latter will generally prevent you from destroying your work. Use the safer approach as follows.','prevent  from destroying',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4794,'GitPython','The previous approach would brutally overwrite the user’s changes in the working copy and index though and is less sophisticated than a git-checkout. The latter will generally prevent you from destroying your work. Use the safer approach as follows.','use safer approach',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4795,'GitPython','In this example, we will initialize an empty repository, add an empty file to the index, and commit the change.','initialize empty repository',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4796,'GitPython','In this example, we will initialize an empty repository, add an empty file to the index, and commit the change.','add empty file to index',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4797,'GitPython','Please have a look at the individual methods as they usually support a vast amount of arguments to customize their behavior.','support vast amount of arguments',0,'',''),(4798,'GitPython','Please have a look at the individual methods as they usually support a vast amount of arguments to customize their behavior.','customize behavior',0,'',''),(4799,'GitPython','In case you are missing functionality as it has not been wrapped, you may conveniently use the git command directly. It is owned by each repository instance.','use git command',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4800,'GitPython','Keyword arguments translate to short and long keyword arguments on the command-line.\nThe special notion git.command(flag=True) will create a flag without value like command --flag.','translate  to short long keyword arguments',0,'',''),(4801,'GitPython','Keyword arguments translate to short and long keyword arguments on the command-line.\nThe special notion git.command(flag=True) will create a flag without value like command --flag.','translate  on command-line',0,'',''),(4802,'GitPython','Keyword arguments translate to short and long keyword arguments on the command-line.\nThe special notion git.command(flag=True) will create a flag without value like command --flag.','create flag without value',0,'',''),(4803,'GitPython','If None is found in the arguments, it will be dropped silently. Lists and tuples passed as arguments will be unpacked recursively to individual arguments. Objects are converted to strings using the str(...) function.','find none in arguments',0,'',''),(4804,'GitPython','If None is found in the arguments, it will be dropped silently. Lists and tuples passed as arguments will be unpacked recursively to individual arguments. Objects are converted to strings using the str(...) function.','use str(...) function',0,'',''),(4805,'GitPython','If None is found in the arguments, it will be dropped silently. Lists and tuples passed as arguments will be unpacked recursively to individual arguments. Objects are converted to strings using the str(...) function.','convert objects to strings',0,'',''),(4806,'GitPython','git.Repo instances are powered by its object database instance which will be used when extracting any data, or when writing new objects.','write new objects',0,'',''),(4807,'GitPython','git.Repo instances are powered by its object database instance which will be used when extracting any data, or when writing new objects.','use object database instance',0,'',''),(4808,'GitPython','The type of the database determines certain performance characteristics, such as the quantity of objects that can be read per second, the resource usage when reading large data files, as well as the average memory footprint of your application.','determine average memory footprint of application',0,'',''),(4809,'GitPython','The type of the database determines certain performance characteristics, such as the quantity of objects that can be read per second, the resource usage when reading large data files, as well as the average memory footprint of your application.','determine average memory footprint such_as quantity',0,'',''),(4810,'GitPython','The type of the database determines certain performance characteristics, such as the quantity of objects that can be read per second, the resource usage when reading large data files, as well as the average memory footprint of your application.','determine certain performance characteristics of application',0,'',''),(4811,'GitPython','The type of the database determines certain performance characteristics, such as the quantity of objects that can be read per second, the resource usage when reading large data files, as well as the average memory footprint of your application.','determine certain performance characteristics such_as quantity',0,'',''),(4812,'GitPython','The type of the database determines certain performance characteristics, such as the quantity of objects that can be read per second, the resource usage when reading large data files, as well as the average memory footprint of your application.','read objects',0,'',''),(4813,'GitPython','The GitDB is a pure-python implementation of the git object database. It is the default database to use in GitPython 0.3. It uses less memory when handling huge files, but will be 2 to 5 times slower when extracting large quantities of small objects from densely packed repositories:','use  in GitPython',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4814,'GitPython','The GitDB is a pure-python implementation of the git object database. It is the default database to use in GitPython 0.3. It uses less memory when handling huge files, but will be 2 to 5 times slower when extracting large quantities of small objects from densely packed repositories:','use less memory',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4815,'GitPython','The GitDB is a pure-python implementation of the git object database. It is the default database to use in GitPython 0.3. It uses less memory when handling huge files, but will be 2 to 5 times slower when extracting large quantities of small objects from densely packed repositories:','handle huge files',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4816,'GitPython','The git command database uses persistent git-cat-file instances to read repository information. These operate very fast under all conditions, but will consume additional memory for the process itself. When extracting large files, memory usage will be much higher than GitDB:','use persistent git-cat-file instances',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4817,'GitPython','The git command database uses persistent git-cat-file instances to read repository information. These operate very fast under all conditions, but will consume additional memory for the process itself. When extracting large files, memory usage will be much higher than GitDB:','read repository information',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4818,'GitPython','Using environment variables, you can further adjust the behaviour of the git command.','use environment variables',0,'',''),(4819,'GitPython','Using environment variables, you can further adjust the behaviour of the git command.','adjust behaviour of git command',0,'',''),(4820,'GitPython','NOTE: All logging is outputted using a Python logger, so make sure your program is configured to show INFO-level messages.  If this is not the case, try adding the following to your program:','use Python logger',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4821,'GitPython','NOTE: All logging is outputted using a Python logger, so make sure your program is configured to show INFO-level messages.  If this is not the case, try adding the following to your program:','show INFO-level messages',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4822,'GitPython','NOTE: All logging is outputted using a Python logger, so make sure your program is configured to show INFO-level messages.  If this is not the case, try adding the following to your program:','configure program',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4823,'GitPython','NOTE: All logging is outputted using a Python logger, so make sure your program is configured to show INFO-level messages.  If this is not the case, try adding the following to your program:','add following to program',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(4824,'GitPython','There is more functionality in there, like the ability to archive repositories, get stats and logs, blame, and probably a few other things that were not mentioned here.','get stats like ability',0,'',''),(4825,'GitPython','There is more functionality in there, like the ability to archive repositories, get stats and logs, blame, and probably a few other things that were not mentioned here.','get logs like ability',0,'',''),(4826,'GitPython','There is more functionality in there, like the ability to archive repositories, get stats and logs, blame, and probably a few other things that were not mentioned here.','get blame like ability',0,'',''),(4827,'GitPython','There is more functionality in there, like the ability to archive repositories, get stats and logs, blame, and probably a few other things that were not mentioned here.','get few other things like ability',0,'',''),(4828,'GitPython','Check the unit tests for an in-depth introduction on how each function is supposed to be used.','check unit tests for in-depth introduction',0,'',''),(4829,'GitPython','The full list of milestones including associated tasks can be found on GitHub:\nhttps://github.com/gitpython-developers/GitPython/issues','find full list of milestones',0,'',''),(4830,'GitPython','The full list of milestones including associated tasks can be found on GitHub:\nhttps://github.com/gitpython-developers/GitPython/issues','find full list on github',0,'',''),(4831,'GitPython','Select the respective milestone to filter the list of issues accordingly.','select respective milestone',0,'',''),(4832,'GitPython','It provides abstractions of git objects for easy access of repository data, and additionally allows you to access the git repository more directly using either a pure python implementation, or the faster, but more resource intensive git command implementation.','provide abstractions of git objects',0,'',''),(4833,'GitPython','It provides abstractions of git objects for easy access of repository data, and additionally allows you to access the git repository more directly using either a pure python implementation, or the faster, but more resource intensive git command implementation.','provide abstractions for easy access',0,'',''),(4834,'GitPython','It provides abstractions of git objects for easy access of repository data, and additionally allows you to access the git repository more directly using either a pure python implementation, or the faster, but more resource intensive git command implementation.','use faster resource intensive git command implementation',0,'',''),(4835,'GitPython','It provides abstractions of git objects for easy access of repository data, and additionally allows you to access the git repository more directly using either a pure python implementation, or the faster, but more resource intensive git command implementation.','use pure python implementation',0,'',''),(4836,'GitPython','The object database implementation is optimized for handling large quantities of objects and large datasets, which is achieved by using low-level structures and data streaming.','handle large quantities of objects',0,'',''),(4837,'GitPython','The object database implementation is optimized for handling large quantities of objects and large datasets, which is achieved by using low-level structures and data streaming.','handle large quantities of large datasets',0,'',''),(4838,'GitPython','The object database implementation is optimized for handling large quantities of objects and large datasets, which is achieved by using low-level structures and data streaming.','use low-level structures',0,'',''),(4839,'GitPython','The object database implementation is optimized for handling large quantities of objects and large datasets, which is achieved by using low-level structures and data streaming.','use data',0,'',''),(4840,'GitPython','Installing GitPython is easily done using\npip. Assuming it is\ninstalled, just run the following from the command-line:','use pip',1,'https://gitpython.readthedocs.io/en/stable/intro.html',''),(4841,'GitPython','Installing GitPython is easily done using\npip. Assuming it is\ninstalled, just run the following from the command-line:','run following from command-line',1,'https://gitpython.readthedocs.io/en/stable/intro.html',''),(4842,'GitPython','This command will download the latest version of GitPython from the\nPython Package Index and install it\nto your system. More information about pip and pypi can be found\nhere:','download latest version of GitPython',0,'',''),(4843,'GitPython','This command will download the latest version of GitPython from the\nPython Package Index and install it\nto your system. More information about pip and pypi can be found\nhere:','download latest version from Python Package index',0,'',''),(4844,'GitPython','This command will download the latest version of GitPython from the\nPython Package Index and install it\nto your system. More information about pip and pypi can be found\nhere:','install  to system',0,'',''),(4845,'GitPython','This command will download the latest version of GitPython from the\nPython Package Index and install it\nto your system. More information about pip and pypi can be found\nhere:','find more information about pip',0,'',''),(4846,'GitPython','This command will download the latest version of GitPython from the\nPython Package Index and install it\nto your system. More information about pip and pypi can be found\nhere:','find more information about pypi',0,'',''),(4847,'GitPython','Alternatively, you can install from the distribution using the setup.py\nscript:','use setup.py script',1,'https://gitpython.readthedocs.io/en/stable/intro.html',''),(4848,'GitPython','Alternatively, you can install from the distribution using the setup.py\nscript:','install  from distribution',1,'https://gitpython.readthedocs.io/en/stable/intro.html',''),(4849,'GitPython','GitPython is not suited for long-running processes (like daemons) as it tends to\nleak system resources. It was written in a time where destructors (as implemented\nin the __del__ method) still ran deterministically.','write  in time',0,'',''),(4850,'GitPython','GitPython is not suited for long-running processes (like daemons) as it tends to\nleak system resources. It was written in a time where destructors (as implemented\nin the __del__ method) still ran deterministically.','run time',0,'',''),(4851,'GitPython','In case you still want to use it in such a context, you will want to search the\ncodebase for __del__ implementations and call these yourself when you see fit.','use  in context',0,'',''),(4852,'GitPython','In case you still want to use it in such a context, you will want to search the\ncodebase for __del__ implementations and call these yourself when you see fit.','search codebase for __del__ implementations',0,'',''),(4853,'GitPython','Initialize all submodules to obtain the required dependencies with:','obtain required dependencies',1,'https://gitpython.readthedocs.io/en/stable/intro.html','source-code-label'),(4854,'GitPython','Finally verify the installation by running unit tests:','run unit tests',1,'https://gitpython.readthedocs.io/en/stable/intro.html','source-code-label'),(4855,'GitPython','Please use stackoverflow for questions, and don’t forget to tag it with gitpython to assure the right people see the question in a timely manner.','use stackoverflow for questions',0,'',''),(4856,'GitPython','The issue tracker is hosted by GitHub:','host issue tracker',0,'',''),(4857,'Bpmn-visualization','Please check the ⏩ live environment.','check â© live environment',0,'',''),(4858,'Bpmn-visualization','You will find there basic usage as well as detailed examples showing possible rendering customizations.','find basic usage',0,'',''),(4859,'Bpmn-visualization','You will find there basic usage as well as detailed examples showing possible rendering customizations.','find detailed examples',0,'',''),(4860,'Bpmn-visualization','You will find there basic usage as well as detailed examples showing possible rendering customizations.','show possible rendering customizations',0,'',''),(4861,'Bpmn-visualization','bpmn-visualization is actively developed and maintained.','develop bpmn-visualization',0,'',''),(4862,'Bpmn-visualization','Before the release of version 1.0.0, there may be some breaking changes. We avoid these as much as possible, and carefully document them in the release notes.\nAs far as possible, we maintain compatibility for some minor versions.','document  in release notes',0,'',''),(4863,'Bpmn-visualization','The library is available from NPM. \nWe support various module formats such as:','support various module formats',0,'',''),(4864,'Bpmn-visualization','Then use this snippet to load your BPMN diagram in a page:','use snippet',1,'https://github.com/process-analytics/bpmn-visualization-js.git','user-content--project-usage'),(4865,'Bpmn-visualization','Then use this snippet to load your BPMN diagram in a page:','load BPMN',1,'https://github.com/process-analytics/bpmn-visualization-js.git','user-content--project-usage'),(4866,'Bpmn-visualization','The bpmn-visualization npm package includes type definitions, so the integration works out of the box in TypeScript projects.\nbpmn-visualization requires TypeScript 4.5 or greater.','include type definitions',0,'',''),(4867,'Bpmn-visualization','ℹ️ If you are looking for examples of projects integrating bpmn-visualization with TypeScript, see the bpmn-visualization-examples repository.','integrate bpmn-visualization with TypeScript',0,'',''),(4868,'Bpmn-visualization','To contribute to bpmn-visualization, fork and clone this repository locally and commit your code on a separate branch.\nPlease write tests for your code before opening a pull-request:','write tests before opening',1,'https://github.com/process-analytics/bpmn-visualization-js.git','user-content--contributing'),(4869,'Bpmn-visualization','To contribute to bpmn-visualization, fork and clone this repository locally and commit your code on a separate branch.\nPlease write tests for your code before opening a pull-request:','write tests for code',1,'https://github.com/process-analytics/bpmn-visualization-js.git','user-content--contributing'),(4870,'Bpmn-visualization','To contribute to bpmn-visualization, fork and clone this repository locally and commit your code on a separate branch.\nPlease write tests for your code before opening a pull-request:','open pull-request',1,'https://github.com/process-analytics/bpmn-visualization-js.git','user-content--contributing'),(4871,'Bpmn-visualization','You can find more detail in our Contributing guide. Participation in this open source project is subject to a Code of Conduct.','find more detail in contributing guide',0,'',''),(4872,'Bpmn-visualization','bpmn-visualization is released under the Apache 2.0 license.\nCopyright © 2020-present, Bonitasoft S.A.','release bpmn-visualization under apache 2.0 license',0,'',''),(4873,'Bpmn-visualization','Due to the fact that default image lacks certain libraries needed for the puppeteer to lanch, the new enhanced Dockerfile was created.','create new enhanced Dockerfile due_to fact',0,'',''),(4874,'Bpmn-visualization','Running a fresh workspace, the npm install script was not run.\nThis is probably because there was no .gitpod.yml in the master branch.','run fresh workspace',0,'',''),(4875,'Bpmn-visualization','After having switched to the branch of this pr that has the init tasks, run npm install, the e2e tests fail.','switch  to branch',0,'',''),(4876,'Bpmn-visualization','I have removed the node_modules, then restarted the workspace. The node_modules folder is not created.\ne2e tests still fail.','remove node_modules',0,'',''),(4877,'Bpmn-visualization','I have removed the node_modules, then restarted the workspace. The node_modules folder is not created.\ne2e tests still fail.','restart workspace',0,'',''),(4878,'Bpmn-visualization','Maybe there is some issues with running Gitpod from PR?','run Gitpod from PR',0,'',''),(4879,'Bpmn-visualization','I have just tested by running it from my GitHub branch and tests are passing.\nhttps://github.com/aibcmars/bpmn-visualization-js/tree/infra-gitpod_e2e_tests_fix','run  from GitHub branch',0,'',''),(4880,'Bpmn-visualization','I have just tested by running it from my GitHub branch and tests are passing.\nhttps://github.com/aibcmars/bpmn-visualization-js/tree/infra-gitpod_e2e_tests_fix','test  by running',0,'',''),(4881,'Bpmn-visualization','I have just tested by running it from my GitHub branch and tests are passing.\nhttps://github.com/aibcmars/bpmn-visualization-js/tree/infra-gitpod_e2e_tests_fix','pass  by running',0,'',''),(4882,'Bpmn-visualization','Ok, I will retest with a fresh workspace created from the branch of this PR as described in https://www.gitpod.io/docs/context-urls/#branch-context\nhttps://gitpod.io/#https://github.com/aibcmars/bpmn-visualization-js/tree/infra-gitpod_e2e_tests_fix','create  from branch',0,'',''),(4883,'Bpmn-visualization','✔️ Creating the workspace with the branch of this PR works fine\nThe workspace creation is a bit more slower than before because of the need for rebuilding the Docker image. We may document this.','create workspace with branch',0,'',''),(4884,'Bpmn-visualization','✔️ Creating the workspace with the branch of this PR works fine\nThe workspace creation is a bit more slower than before because of the need for rebuilding the Docker image. We may document this.','rebuild Docker image',0,'',''),(4885,'Bpmn-visualization','npm install is run at workspace startup','run npm install at workspace startup',0,'',''),(4886,'Bpmn-visualization','I got some errors in the log when running e2e tests, but tests pass, so we can check this later','get errors in log',0,'',''),(4887,'Bpmn-visualization','I got some errors in the log when running e2e tests, but tests pass, so we can check this later','run e2e tests',0,'',''),(4888,'Bpmn-visualization','You can trigger a rebase of this PR by commenting @dependabot rebase.','trigger rebase by commenting',0,'',''),(4889,'Bpmn-visualization','You can trigger a rebase of this PR by commenting @dependabot rebase.','trigger rebase of PR',0,'',''),(4890,'Bpmn-visualization','You can trigger Dependabot actions by commenting on this PR:','trigger Dependabot actions by commenting',0,'',''),(4891,'Bpmn-visualization','This repository contains examples showing how to use bpmn-visualization.','use bpmn-visualization',0,'',''),(4892,'Bpmn-visualization','Some examples require loading local files. If you are looking for BPMN diagram files, you can use resources from:','load local files',0,'',''),(4893,'Bpmn-visualization','Some examples require loading local files. If you are looking for BPMN diagram files, you can use resources from:','use resources',0,'',''),(4894,'Bpmn-visualization','Some examples and demos may load ES Modules; in that case, you cannot open html pages directly from your local disk.','load ES modules',0,'',''),(4895,'Bpmn-visualization','For instance, on Chrome, the Console would display the following errors','display following errors for instance',0,'',''),(4896,'Bpmn-visualization','For instance, on Chrome, the Console would display the following errors','display following errors on chrome',0,'',''),(4897,'Bpmn-visualization','Access to script at \'file:///...../bpmn-visualization-examples/examples/my-file.js\' from origin \'null\' has been\nblocked by CORS policy: Cross origin requests are only supported for protocol schemes: http, data, chrome,\nchrome-extension, https. index.html:1\nFailed to load resource: net::ERR_FAILED utils.js:1','support cross origin requests for protocol schemes',0,'',''),(4898,'Bpmn-visualization','Access to script at \'file:///...../bpmn-visualization-examples/examples/my-file.js\' from origin \'null\' has been\nblocked by CORS policy: Cross origin requests are only supported for protocol schemes: http, data, chrome,\nchrome-extension, https. index.html:1\nFailed to load resource: net::ERR_FAILED utils.js:1','load resource',0,'',''),(4899,'Bpmn-visualization','To access such examples, you need to run a local web server and then access the examples via the http protocol.\nWe advise to make the local web server serve the whole repository, to also be able to access to the demo (resources available\nin the ./demo folder).','access such examples',0,'',''),(4900,'Bpmn-visualization','To access such examples, you need to run a local web server and then access the examples via the http protocol.\nWe advise to make the local web server serve the whole repository, to also be able to access to the demo (resources available\nin the ./demo folder).','run local web server',0,'',''),(4901,'Bpmn-visualization','To access such examples, you need to run a local web server and then access the examples via the http protocol.\nWe advise to make the local web server serve the whole repository, to also be able to access to the demo (resources available\nin the ./demo folder).','access examples via http protocol',0,'',''),(4902,'Bpmn-visualization','To access such examples, you need to run a local web server and then access the examples via the http protocol.\nWe advise to make the local web server serve the whole repository, to also be able to access to the demo (resources available\nin the ./demo folder).','access  to demo',0,'',''),(4903,'Bpmn-visualization','Some examples are provided for direct use in the web browser. If you want to integrate their related code in a project, adaptations may be required.','provide examples for direct use',0,'',''),(4904,'Bpmn-visualization','Some examples are provided for direct use in the web browser. If you want to integrate their related code in a project, adaptations may be required.','integrate related code in project',0,'',''),(4905,'Bpmn-visualization','You can check the examples projects in this repository or the Live IDE examples to know how to bootstrap bpmn-visualization in a project.','check examples projects in repository',0,'',''),(4906,'Bpmn-visualization','You can check the examples projects in this repository or the Live IDE examples to know how to bootstrap bpmn-visualization in a project.','check examples projects in live IDE examples',0,'',''),(4907,'Bpmn-visualization','TypeScript\'s users should also read the paragraph about the TypeScript support in the bpmn-visualization README\nespecially when using bpmn-visualization prior version 0.27.0.','read paragraph about TypeScript support',0,'',''),(4908,'Bpmn-visualization','TypeScript\'s users should also read the paragraph about the TypeScript support in the bpmn-visualization README\nespecially when using bpmn-visualization prior version 0.27.0.','use bpmn-visualization prior version 0.27.0',0,'',''),(4909,'Bpmn-visualization','DISCLAIMER: extension points are currently very experimental and are subject to change.\nThey are mainly hacks to let you see what will be later available in a more integrated way. \nCustom BPMN Theme features will be progressively added to bpmn-visualization. See the Extensions Milestone.','add custom BPMN theme features to bpmn-visualization',0,'',''),(4910,'Bpmn-visualization','Show how to integrate bpmn-visualization in project, using various kind of build tools and bundlers:','integrate bpmn-visualization in project',0,'',''),(4911,'Bpmn-visualization','Show how to integrate bpmn-visualization in project, using various kind of build tools and bundlers:','use various kind',0,'',''),(4912,'Bpmn-visualization','To contribute to bpmn-visualization-examples, fork and clone this repository locally and commit your code on a separate branch. \nPlease add a screenshot of the new rendering when you open a pull-request.','add screenshot of new rendering',0,'',''),(4913,'Bpmn-visualization','To contribute to bpmn-visualization-examples, fork and clone this repository locally and commit your code on a separate branch. \nPlease add a screenshot of the new rendering when you open a pull-request.','open pull-request',0,'',''),(4914,'Bpmn-visualization','You can find more detail in our Contributing guide. Participation in this open source project is subject to a Code of Conduct.','find more detail in contributing guide',0,'',''),(4915,'Bpmn-visualization','bpmn-visualization-examples is released under the Apache 2.0 license. \nCopyright © 2020-present, Bonitasoft S.A.','release bpmn-visualization-examples under apache 2.0 license',0,'',''),(4916,'Bpmn-visualization','The extensions panel on Gitpod when opening this PR. The extensions are not sync with the Gitpod user settings letting us to improve the settings iteratively and without impacting the existing settings of the user.','open PR',0,'',''),(4917,'Bpmn-visualization','Please check the ⏩ live environment.','check â© live environment',0,'',''),(4918,'Bpmn-visualization','You will find there basic usage as well as detailed examples showing possible rendering customizations.','find basic usage',0,'',''),(4919,'Bpmn-visualization','You will find there basic usage as well as detailed examples showing possible rendering customizations.','find detailed examples',0,'',''),(4920,'Bpmn-visualization','You will find there basic usage as well as detailed examples showing possible rendering customizations.','show possible rendering customizations',0,'',''),(4921,'Bpmn-visualization','bpmn-visualization is actively developed and maintained.','develop bpmn-visualization',0,'',''),(4922,'Bpmn-visualization','Before the release of version 1.0.0, there may be some breaking changes. We avoid these as much as possible, and carefully document them in the release notes.\nAs far as possible, we maintain compatibility for some minor versions.','document  in release notes',0,'',''),(4923,'Bpmn-visualization','The library is available from NPM. \nWe support various module formats such as:','support various module formats',0,'',''),(4924,'Bpmn-visualization','Then use this snippet to load your BPMN diagram in a page:','use snippet',1,'https://github.com/process-analytics/bpmn-visualization-js.git','user-content--project-usage'),(4925,'Bpmn-visualization','Then use this snippet to load your BPMN diagram in a page:','load BPMN',1,'https://github.com/process-analytics/bpmn-visualization-js.git','user-content--project-usage'),(4926,'Bpmn-visualization','The bpmn-visualization npm package includes type definitions, so the integration works out of the box in TypeScript projects.\nbpmn-visualization requires TypeScript 4.5 or greater.','include type definitions',0,'',''),(4927,'Bpmn-visualization','ℹ️ If you are looking for examples of projects integrating bpmn-visualization with TypeScript, see the bpmn-visualization-examples repository.','integrate bpmn-visualization with TypeScript',0,'',''),(4928,'Bpmn-visualization','To contribute to bpmn-visualization, fork and clone this repository locally and commit your code on a separate branch.\nPlease write tests for your code before opening a pull-request:','write tests before opening',1,'https://github.com/process-analytics/bpmn-visualization-js.git','user-content--contributing'),(4929,'Bpmn-visualization','To contribute to bpmn-visualization, fork and clone this repository locally and commit your code on a separate branch.\nPlease write tests for your code before opening a pull-request:','write tests for code',1,'https://github.com/process-analytics/bpmn-visualization-js.git','user-content--contributing'),(4930,'Bpmn-visualization','To contribute to bpmn-visualization, fork and clone this repository locally and commit your code on a separate branch.\nPlease write tests for your code before opening a pull-request:','open pull-request',1,'https://github.com/process-analytics/bpmn-visualization-js.git','user-content--contributing'),(4931,'Bpmn-visualization','bpmn-visualization is released under the Apache 2.0 license.\nCopyright © 2020-present, Bonitasoft S.A.','release bpmn-visualization under apache 2.0 license',0,'',''),(4932,'Bpmn-visualization','Previously, calling BpmnElementsRegistry.getElementsByIds generated error when the HTML BPMN container has no id.\nWhen using framework like Svelte or Angular, the container doesn\'t have such id, so it prevented to use the API out of the box.','generate error',0,'',''),(4933,'Bpmn-visualization','Previously, calling BpmnElementsRegistry.getElementsByIds generated error when the HTML BPMN container has no id.\nWhen using framework like Svelte or Angular, the container doesn\'t have such id, so it prevented to use the API out of the box.','use framework like Svelte',0,'',''),(4934,'Bpmn-visualization','Previously, calling BpmnElementsRegistry.getElementsByIds generated error when the HTML BPMN container has no id.\nWhen using framework like Svelte or Angular, the container doesn\'t have such id, so it prevented to use the API out of the box.','use framework like angular',0,'',''),(4935,'Bpmn-visualization','Previously, calling BpmnElementsRegistry.getElementsByIds generated error when the HTML BPMN container has no id.\nWhen using framework like Svelte or Angular, the container doesn\'t have such id, so it prevented to use the API out of the box.','use API out_of box',0,'',''),(4936,'Bpmn-visualization','The CSS selector that retrieves the HTML elements has been simplified to not use the id.','retrieve HTML elements',0,'',''),(4937,'Bpmn-visualization','The CSS selector that retrieves the HTML elements has been simplified to not use the id.','retrieve CSS selector',0,'',''),(4938,'Bpmn-visualization','The \"elements-identification\" demo has been updated to use a BPMN container without id.\nPrior, the fix, it reproduced the issue when calling the registry API','use BPMN container without id',1,'https://github.com/process-analytics/bpmn-visualization-js/pull/2282',''),(4939,'Bpmn-visualization','The \"elements-identification\" demo has been updated to use a BPMN container without id.\nPrior, the fix, it reproduced the issue when calling the registry API','call registry API',1,'https://github.com/process-analytics/bpmn-visualization-js/pull/2282',''),(4940,'Bpmn-visualization','The drag\'n drop code was only able to manage container with id. It has been updated to support container without id as well.','manage container with id',0,'',''),(4941,'Bpmn-visualization','The drag\'n drop code was only able to manage container with id. It has been updated to support container without id as well.','support container without id',0,'',''),(4942,'Bpmn-visualization','The bug is reproduced with the first commit (new integration test): df2c5d6\nAdditional tests were added to reproduce the issue with the BpmnElementsRegistry API: 53a42bd\nThe elements-identification.html demo was updated to also reproduce the problem: 8946525','add     df2c5d6    additional tests',0,'',''),(4943,'Bpmn-visualization','At first glance, this looks good. I have provided minor remarks about naming.','provide minor remarks about naming',0,'',''),(4944,'Bpmn-visualization','The current integration tests reproduce the problem but not in the context of the issue.\nThey involve HtmlElementLookup which is a test utility and which uses the code that contains the problem (BpmnQuerySelectors). But this utility uses BpmnQuerySelectors  only to avoid duplication with the production code\nIts implementation may change (We could use a completely different implementation to do the lookup that doesn\'t rely on the production code) and in that case, the tests won\'t cover anything.  The div tests have been created to ensure that the BPMN elements are created in the DOM not to test the BpmnElementsRegistry API.','use code',0,'',''),(4945,'Bpmn-visualization','The current integration tests reproduce the problem but not in the context of the issue.\nThey involve HtmlElementLookup which is a test utility and which uses the code that contains the problem (BpmnQuerySelectors). But this utility uses BpmnQuerySelectors  only to avoid duplication with the production code\nIts implementation may change (We could use a completely different implementation to do the lookup that doesn\'t rely on the production code) and in that case, the tests won\'t cover anything.  The div tests have been created to ensure that the BPMN elements are created in the DOM not to test the BpmnElementsRegistry API.','use BpmnQuerySelectors',0,'',''),(4946,'Bpmn-visualization','The current integration tests reproduce the problem but not in the context of the issue.\nThey involve HtmlElementLookup which is a test utility and which uses the code that contains the problem (BpmnQuerySelectors). But this utility uses BpmnQuerySelectors  only to avoid duplication with the production code\nIts implementation may change (We could use a completely different implementation to do the lookup that doesn\'t rely on the production code) and in that case, the tests won\'t cover anything.  The div tests have been created to ensure that the BPMN elements are created in the DOM not to test the BpmnElementsRegistry API.','change production code',0,'',''),(4947,'Bpmn-visualization','The current integration tests reproduce the problem but not in the context of the issue.\nThey involve HtmlElementLookup which is a test utility and which uses the code that contains the problem (BpmnQuerySelectors). But this utility uses BpmnQuerySelectors  only to avoid duplication with the production code\nIts implementation may change (We could use a completely different implementation to do the lookup that doesn\'t rely on the production code) and in that case, the tests won\'t cover anything.  The div tests have been created to ensure that the BPMN elements are created in the DOM not to test the BpmnElementsRegistry API.','create BPMN elements in DOM',0,'',''),(4948,'Bpmn-visualization','The current integration tests reproduce the problem but not in the context of the issue.\nThey involve HtmlElementLookup which is a test utility and which uses the code that contains the problem (BpmnQuerySelectors). But this utility uses BpmnQuerySelectors  only to avoid duplication with the production code\nIts implementation may change (We could use a completely different implementation to do the lookup that doesn\'t rely on the production code) and in that case, the tests won\'t cover anything.  The div tests have been created to ensure that the BPMN elements are created in the DOM not to test the BpmnElementsRegistry API.','create div tests',0,'',''),(4949,'Bpmn-visualization','In addition, the current integration tests are white/gray box tests as it knows that the implementation uses BpmnQuerySelectors. So, it is not easy to understand what is the problem under the hood. Black box tests, direcly involving BpmnElementsRegistry, would have been more understandable.','use BpmnQuerySelectors',0,'',''),(4950,'Bpmn-visualization','I am not saying that we should remove the existing integration tests.\nBut, IHMO we should add new tests on the BpmnElementsRegistry, so in dom.bpmn.elements.test.ts.','remove existing integration tests',0,'',''),(4951,'Bpmn-visualization','I am not saying that we should remove the existing integration tests.\nBut, IHMO we should add new tests on the BpmnElementsRegistry, so in dom.bpmn.elements.test.ts.','add new tests on BpmnElementsRegistry',0,'',''),(4952,'Bpmn-visualization','I have just added the update of the \"elements-identification\" demo that now uses a BPMN container without id (I updated the PR description with more details).\nThe Drag\'n Drop overlay works whether the BPMN container has an id or not.','add update of elements-identification demo',0,'',''),(4953,'Bpmn-visualization','I have just added the update of the \"elements-identification\" demo that now uses a BPMN container without id (I updated the PR description with more details).\nThe Drag\'n Drop overlay works whether the BPMN container has an id or not.','use BPMN container without id',0,'',''),(4954,'Bpmn-visualization','I have just added the update of the \"elements-identification\" demo that now uses a BPMN container without id (I updated the PR description with more details).\nThe Drag\'n Drop overlay works whether the BPMN container has an id or not.','use elements-identification demo without id',0,'',''),(4955,'Bpmn-visualization','TypeScript projects integrating the lib no longer need to declare \'typed-mxgraph\' types. The TypeScript compilation now works out of the box.\nProjects that customize the mxGraph code don\'t need additional configuration to access mxGraph types.','integrate lib',0,'',''),(4956,'Bpmn-visualization','TypeScript projects integrating the lib no longer need to declare \'typed-mxgraph\' types. The TypeScript compilation now works out of the box.\nProjects that customize the mxGraph code don\'t need additional configuration to access mxGraph types.','customize mxGraph code',0,'',''),(4957,'Bpmn-visualization','TypeScript projects integrating the lib no longer need to declare \'typed-mxgraph\' types. The TypeScript compilation now works out of the box.\nProjects that customize the mxGraph code don\'t need additional configuration to access mxGraph types.','customize projects',0,'',''),(4958,'Bpmn-visualization','Previously, the declaration files included in the npm package referenced \'typed-mxgraph\' with:','include  in typed-mxgraph',1,'https://github.com/process-analytics/bpmn-visualization-js/pull/2258',''),(4959,'Bpmn-visualization','\"typed-mxgraph\" had to be accessible directly and so, node_modules/@typed-mxgraph had to be added to TypeScript configuration typeRoots. This was because the lib itself declared it in typeRoots.','add  to TypeScript configuration typeRoots',0,'',''),(4960,'Bpmn-visualization','The changes are tested with a dedicated TypeScript project that runs the TypeScript compiler. It also tests the lowest TypeScript version that can work with the lib (currently 4.5).','run TypeScript compiler',0,'',''),(4961,'Bpmn-visualization','The changes are tested with a dedicated TypeScript project that runs the TypeScript compiler. It also tests the lowest TypeScript version that can work with the lib (currently 4.5).','run dedicated TypeScript project',0,'',''),(4962,'Bpmn-visualization','The changes are tested with a dedicated TypeScript project that runs the TypeScript compiler. It also tests the lowest TypeScript version that can work with the lib (currently 4.5).','test changes with dedicated TypeScript project',0,'',''),(4963,'Bpmn-visualization','The changes are tested with a dedicated TypeScript project that runs the TypeScript compiler. It also tests the lowest TypeScript version that can work with the lib (currently 4.5).','test lowest TypeScript version',0,'',''),(4964,'Bpmn-visualization','The README has been updating accordingly. It contains a note about the configuration that was previously required. It should help projects still using an old version.','use old version',0,'',''),(4965,'Bpmn-visualization','The projects in the examples repository work with the implementation provided in this PR. See process-analytics/bpmn-visualization-examples#405','provide  in PR',0,'',''),(4966,'Bpmn-visualization','Why global.d.ts instead of compilerOptions.types inside jsconfig.json or tsconfig.json?\nSetting compilerOptions.types shuts out all other types not explicitly listed in the configuration. Using triple-slash references keeps the default TypeScript setting of accepting type information from the entire workspace, while also adding svelte and vite/client type information.','use triple-slash references',0,'',''),(4967,'Bpmn-visualization','Why global.d.ts instead of compilerOptions.types inside jsconfig.json or tsconfig.json?\nSetting compilerOptions.types shuts out all other types not explicitly listed in the configuration. Using triple-slash references keeps the default TypeScript setting of accepting type information from the entire workspace, while also adding svelte and vite/client type information.','add svelte vite/client type information',0,'',''),(4968,'Bpmn-visualization','@assynour could you review the README a provide suggestion/question if it is not clear enough? Thanks','provide suggestion/question',0,'',''),(4969,'Bpmn-visualization','I started working on the repository of examples. The integration works fine for projects that don\'t call mxGraph code.\n⚠️ I see some errors in the vite project that directly calls mxGraph code. The build command fails.\nSo please don\'t merge this PR until we figure out what is going on!','call mxGraph code',0,'',''),(4970,'Bpmn-visualization','I started working on the repository of examples. The integration works fine for projects that don\'t call mxGraph code.\n⚠️ I see some errors in the vite project that directly calls mxGraph code. The build command fails.\nSo please don\'t merge this PR until we figure out what is going on!','call vite project',0,'',''),(4971,'Bpmn-visualization','I started working on the repository of examples. The integration works fine for projects that don\'t call mxGraph code. warning I see some errors in the vite project that directly calls mxGraph code. The build command fails. So please don\'t merge this PR until we figure out what is going on!','call mxGraph code',1,'https://github.com/process-analytics/bpmn-visualization-js/pull/2258',''),(4972,'Bpmn-visualization','I started working on the repository of examples. The integration works fine for projects that don\'t call mxGraph code. warning I see some errors in the vite project that directly calls mxGraph code. The build command fails. So please don\'t merge this PR until we figure out what is going on!','call vite project',1,'https://github.com/process-analytics/bpmn-visualization-js/pull/2258',''),(4973,'Bpmn-visualization','There was a problem hiding this comment.','hide comment',0,'',''),(4974,'Bpmn-visualization','Do you check if there is no error with ESLint in your IDE when a file of the tests is updated ?\nIn my memories, we added this for the edition of the tests on IDE.','add  in memories',0,'',''),(4975,'Bpmn-visualization','Do you check if there is no error with ESLint in your IDE when a file of the tests is updated ?\nIn my memories, we added this for the edition of the tests on IDE.','add  for edition',0,'',''),(4976,'Bpmn-visualization','Do you check if there is no error with ESLint in your IDE when a file of the tests is updated ?\nIn my memories, we added this for the edition of the tests on IDE.','add  on IDE',0,'',''),(4977,'Bpmn-visualization','✔️ Yes it works. If I add an unsued import','add unsued import',1,'https://github.com/process-analytics/bpmn-visualization-js/pull/2258',''),(4978,'Bpmn-visualization','I get a typescript-eslint error:','get typescript-eslint error',1,'https://github.com/process-analytics/bpmn-visualization-js/pull/2258',''),(4979,'Bpmn-visualization','Set eslint rules to ensure we explicitly used the type modifier for imports and exports.\nIt will also help introduce build tools like esbuild.','use type modifier for imports',0,'',''),(4980,'Bpmn-visualization','Set eslint rules to ensure we explicitly used the type modifier for imports and exports.\nIt will also help introduce build tools like esbuild.','use type modifier for exports',0,'',''),(4981,'Bpmn-visualization','Generalize work started in #1666\nSet eslint rules','set eslint rules',0,'',''),(4982,'Bpmn-visualization','I tried to move the parserOptions configuration in the dedicated eslintrc but I got errors.','move parserOptions configuration in dedicated eslintrc',0,'',''),(4983,'Bpmn-visualization','I tried to move the parserOptions configuration in the dedicated eslintrc but I got errors.','get errors',0,'',''),(4984,'Bpmn-visualization','⚠️ performance impact of adding the consistent-type-exports rule: eslint now triggers TS compilation, and this will be done at each commit\nSee https://typescript-eslint.io/docs/linting/type-linting/#how-is-performance','add consistent-type-exports rule eslint',0,'',''),(4985,'Bpmn-visualization','⚠️ performance impact of adding the consistent-type-exports rule: eslint now triggers TS compilation, and this will be done at each commit\nSee https://typescript-eslint.io/docs/linting/type-linting/#how-is-performance','trigger TS compilation',0,'',''),(4986,'Bpmn-visualization','Decision: we are aware of the risk. First usages as part of commit in this PR show no visible commit time change.\nIf this becomes to slow us down, we will revert the rules that requires TSC','show commit time change',0,'',''),(4987,'Bpmn-visualization','Due to the fact that default image lacks certain libraries needed for the puppeteer to lanch, the new enhanced Dockerfile was created.','create new enhanced Dockerfile due_to fact',0,'',''),(4988,'Bpmn-visualization','Running a fresh workspace, the npm install script was not run.\nThis is probably because there was no .gitpod.yml in the master branch.','run fresh workspace',0,'',''),(4989,'Bpmn-visualization','After having switched to the branch of this pr that has the init tasks, run npm install, the e2e tests fail.','switch  to branch',0,'',''),(4990,'Bpmn-visualization','I have removed the node_modules, then restarted the workspace. The node_modules folder is not created.\ne2e tests still fail.','remove node_modules',0,'',''),(4991,'Bpmn-visualization','I have removed the node_modules, then restarted the workspace. The node_modules folder is not created.\ne2e tests still fail.','restart workspace',0,'',''),(4992,'Bpmn-visualization','Maybe there is some issues with running Gitpod from PR?','run Gitpod from PR',0,'',''),(4993,'Bpmn-visualization','I have just tested by running it from my GitHub branch and tests are passing.\nhttps://github.com/aibcmars/bpmn-visualization-js/tree/infra-gitpod_e2e_tests_fix','run  from GitHub branch',0,'',''),(4994,'Bpmn-visualization','I have just tested by running it from my GitHub branch and tests are passing.\nhttps://github.com/aibcmars/bpmn-visualization-js/tree/infra-gitpod_e2e_tests_fix','test  by running',0,'',''),(4995,'Bpmn-visualization','I have just tested by running it from my GitHub branch and tests are passing.\nhttps://github.com/aibcmars/bpmn-visualization-js/tree/infra-gitpod_e2e_tests_fix','pass  by running',0,'',''),(4996,'Bpmn-visualization','Ok, I will retest with a fresh workspace created from the branch of this PR as described in https://www.gitpod.io/docs/context-urls/#branch-context\nhttps://gitpod.io/#https://github.com/aibcmars/bpmn-visualization-js/tree/infra-gitpod_e2e_tests_fix','create  from branch',0,'',''),(4997,'Bpmn-visualization','✔️ Creating the workspace with the branch of this PR works fine\nThe workspace creation is a bit more slower than before because of the need for rebuilding the Docker image. We may document this.','create workspace with branch',0,'',''),(4998,'Bpmn-visualization','✔️ Creating the workspace with the branch of this PR works fine\nThe workspace creation is a bit more slower than before because of the need for rebuilding the Docker image. We may document this.','rebuild Docker image',0,'',''),(4999,'Bpmn-visualization','npm install is run at workspace startup','run npm install at workspace startup',0,'',''),(5000,'Bpmn-visualization','I got some errors in the log when running e2e tests, but tests pass, so we can check this later','get errors in log',1,'https://github.com/process-analytics/bpmn-visualization-js/pull/686',''),(5001,'Bpmn-visualization','I got some errors in the log when running e2e tests, but tests pass, so we can check this later','run e2e tests',1,'https://github.com/process-analytics/bpmn-visualization-js/pull/686',''),(5002,'Bpmn-visualization','Add a step in the release process.','add step in release process',0,'',''),(5003,'Bpmn-visualization','StyleDefault SHAPE_ACTIVITY_MARKER_ICON_SIZE\nImplicitly managed with the issue to have a true marker fixed size.','manage  with issue',0,'',''),(5004,'Bpmn-visualization','StyleConfigurator: lane and pool label style. Documented in the issue.','document  in issue',0,'',''),(5005,'Bpmn-visualization','editorconfig: we use os eol and let git manage eol on push\nThis setting may only be needed for windows, but default git checkout config\nhandle it correctly.\nSo remove the todo about setting a specific configuration.','use os eol',0,'',''),(5006,'Bpmn-visualization','editorconfig: we use os eol and let git manage eol on push\nThis setting may only be needed for windows, but default git checkout config\nhandle it correctly.\nSo remove the todo about setting a specific configuration.','manage eol on push',0,'',''),(5007,'Bpmn-visualization','editorconfig: we use os eol and let git manage eol on push\nThis setting may only be needed for windows, but default git checkout config\nhandle it correctly.\nSo remove the todo about setting a specific configuration.','remove todo about setting',0,'',''),(5008,'Bpmn-visualization','editorconfig: we use os eol and let git manage eol on push\nThis setting may only be needed for windows, but default git checkout config\nhandle it correctly.\nSo remove the todo about setting a specific configuration.','set specific configuration',0,'',''),(5009,'Bpmn-visualization','See milestone 0.27.1 to get the list of issues covered by this release.','get list of issues',0,'',''),(5010,'Bpmn-visualization','Previously, it was mandatory to define an id in the HTML div element used to display the BPMN diagram. ⚠️ It is not a common practice to set the id of a component with Angular and Svelte.\nAs a result, some bpmn-visualization APIs were generating an error when the id was not defined.','define id in HTML div element',0,'',''),(5011,'Bpmn-visualization','Previously, it was mandatory to define an id in the HTML div element used to display the BPMN diagram. ⚠️ It is not a common practice to set the id of a component with Angular and Svelte.\nAs a result, some bpmn-visualization APIs were generating an error when the id was not defined.','display BPMN diagram',0,'',''),(5012,'Bpmn-visualization','Previously, it was mandatory to define an id in the HTML div element used to display the BPMN diagram. ⚠️ It is not a common practice to set the id of a component with Angular and Svelte.\nAs a result, some bpmn-visualization APIs were generating an error when the id was not defined.','set id with Angular',0,'',''),(5013,'Bpmn-visualization','Previously, it was mandatory to define an id in the HTML div element used to display the BPMN diagram. ⚠️ It is not a common practice to set the id of a component with Angular and Svelte.\nAs a result, some bpmn-visualization APIs were generating an error when the id was not defined.','set id with svelte',0,'',''),(5014,'Bpmn-visualization','Previously, it was mandatory to define an id in the HTML div element used to display the BPMN diagram. ⚠️ It is not a common practice to set the id of a component with Angular and Svelte.\nAs a result, some bpmn-visualization APIs were generating an error when the id was not defined.','set id of component',0,'',''),(5015,'Bpmn-visualization','Previously, it was mandatory to define an id in the HTML div element used to display the BPMN diagram. ⚠️ It is not a common practice to set the id of a component with Angular and Svelte.\nAs a result, some bpmn-visualization APIs were generating an error when the id was not defined.','generate error as result',0,'',''),(5016,'Bpmn-visualization','See milestone 0.27.0 to get the list of issues covered by this release.','get list of issues',0,'',''),(5017,'Bpmn-visualization','In 0.24.0, it was announced that bpmnVisualization.fit(fitOptions) was deprecated.\nFrom now, this method is completely removed. Use bpmnVisualization.navigation.fit(fitOptions) instead.','remove method',0,'',''),(5018,'Bpmn-visualization','In 0.24.0, it was announced that bpmnVisualization.fit(fitOptions) was deprecated.\nFrom now, this method is completely removed. Use bpmnVisualization.navigation.fit(fitOptions) instead.','use bpmnVisualization.navigation.fit(fitOptions)',0,'',''),(5019,'Bpmn-visualization','Previously, the TypeScript projects need a specific configuration, in the tsconfig.json file, to integrate bpmn-visualization.','integrate bpmn-visualization',0,'',''),(5020,'Bpmn-visualization','From now, the integration of bpmn-visualization in TypeScript projects is simplified. They no longer need this configuration.\nThe README contains a note about the configuration that was previously required. It should help projects still using an old version.','use old version',0,'',''),(5021,'Bpmn-visualization','In addition, a more explicit error message is displayed when integrating bpmn-visualization in a project that uses a too old TypeScript version. Remember that bpmn-visualization requires TypeScript 4.5 or superior.','integrate bpmn-visualization in project',0,'',''),(5022,'Bpmn-visualization','In addition, a more explicit error message is displayed when integrating bpmn-visualization in a project that uses a too old TypeScript version. Remember that bpmn-visualization requires TypeScript 4.5 or superior.','use old TypeScript version',0,'',''),(5023,'Bpmn-visualization','In addition, a more explicit error message is displayed when integrating bpmn-visualization in a project that uses a too old TypeScript version. Remember that bpmn-visualization requires TypeScript 4.5 or superior.','use project',0,'',''),(5024,'Bpmn-visualization','In addition, a more explicit error message is displayed when integrating bpmn-visualization in a project that uses a too old TypeScript version. Remember that bpmn-visualization requires TypeScript 4.5 or superior.','display explicit error message',0,'',''),(5025,'Bpmn-visualization','bpmn-visualization supports now the detection of the Complex Gateway.','support detection of complex Gateway',0,'',''),(5026,'Bpmn-visualization','For now, the Complex Gateway is displayed as a red diamond, as follows:','display complex Gateway as red diamond',0,'',''),(5027,'Bpmn-visualization','See milestone 0.26.2 to get the list of issues covered by this release.','get list of issues',0,'',''),(5028,'Bpmn-visualization','This is now easier to use bpmn-visualization in Parcel, Webpack and Angular projects. Previously, it was necessary to add a special configuration to integrate bpmn-visualization. With version 0.26.2, this is not needed anymore.','use bpmn-visualization in parcel',0,'',''),(5029,'Bpmn-visualization','This is now easier to use bpmn-visualization in Parcel, Webpack and Angular projects. Previously, it was necessary to add a special configuration to integrate bpmn-visualization. With version 0.26.2, this is not needed anymore.','use bpmn-visualization in webpack',0,'',''),(5030,'Bpmn-visualization','This is now easier to use bpmn-visualization in Parcel, Webpack and Angular projects. Previously, it was necessary to add a special configuration to integrate bpmn-visualization. With version 0.26.2, this is not needed anymore.','use bpmn-visualization in Angular projects',0,'',''),(5031,'Bpmn-visualization','This is now easier to use bpmn-visualization in Parcel, Webpack and Angular projects. Previously, it was necessary to add a special configuration to integrate bpmn-visualization. With version 0.26.2, this is not needed anymore.','add special configuration',0,'',''),(5032,'Bpmn-visualization','This is now easier to use bpmn-visualization in Parcel, Webpack and Angular projects. Previously, it was necessary to add a special configuration to integrate bpmn-visualization. With version 0.26.2, this is not needed anymore.','integrate bpmn-visualization',0,'',''),(5033,'Bpmn-visualization','See milestone 0.26.1 to get the list of issues covered by this release.','get list of issues',0,'',''),(5034,'Bpmn-visualization','This new version brings improvements to customize the style of the Text Annotation elements and a new BPMN theme in the demo.','customize new BPMN theme in demo',0,'',''),(5035,'Bpmn-visualization','This new version brings improvements to customize the style of the Text Annotation elements and a new BPMN theme in the demo.','customize new BPMN theme of text Annotation elements',0,'',''),(5036,'Bpmn-visualization','This new version brings improvements to customize the style of the Text Annotation elements and a new BPMN theme in the demo.','customize style in demo',0,'',''),(5037,'Bpmn-visualization','This new version brings improvements to customize the style of the Text Annotation elements and a new BPMN theme in the demo.','customize style of text Annotation elements',0,'',''),(5038,'Bpmn-visualization','See milestone 0.26.0 to get the list of issues covered by this release.','get list of issues',0,'',''),(5039,'Bpmn-visualization','In previous versions, it was already possible to customize the style of the Text Annotation elements and to configure a fill color (gradient could also be used).\nBut only a small area of the Text Annotation was filled (the area delimited by the open rectangle).','customize style of text Annotation elements',0,'',''),(5040,'Bpmn-visualization','In previous versions, it was already possible to customize the style of the Text Annotation elements and to configure a fill color (gradient could also be used).\nBut only a small area of the Text Annotation was filled (the area delimited by the open rectangle).','configure fill color',0,'',''),(5041,'Bpmn-visualization','In previous versions, it was already possible to customize the style of the Text Annotation elements and to configure a fill color (gradient could also be used).\nBut only a small area of the Text Annotation was filled (the area delimited by the open rectangle).','fill small area of text Annotation',0,'',''),(5042,'Bpmn-visualization','In version 0.26.0, the whole Text Annotation area is now filled.','fill whole text Annotation area in version 0.26.0',0,'',''),(5043,'Bpmn-visualization','This new feature allows you to highlight the entire text of Text Annotation elements.\nCheck the Bonita procurement example using #B4AFAF26 for Text Annotation fill color 👇.','check bonita procurement example',0,'',''),(5044,'Bpmn-visualization','The \'Diagram\' title section has been removed. So there is now more space for the BPMN diagram rendering, especially on mobile.\nIn addition, the \'fit on load\', \'fit margin\' and \'theme\' blocks (from the control panel) align better on small screens.','remove title section',0,'',''),(5045,'Bpmn-visualization','The \'Diagram\' title section has been removed. So there is now more space for the BPMN diagram rendering, especially on mobile.\nIn addition, the \'fit on load\', \'fit margin\' and \'theme\' blocks (from the control panel) align better on small screens.','fit margin',0,'',''),(5046,'Bpmn-visualization','Check the evolution between version 0.25.2 and version 0.26.0 (shown as 0.25.3-post version here) 👇.\nThe videos have been done with Chrome 104.','check evolution between version 0.25.2',0,'',''),(5047,'Bpmn-visualization','Check the evolution between version 0.25.2 and version 0.26.0 (shown as 0.25.3-post version here) 👇.\nThe videos have been done with Chrome 104.','check evolution between version 0.26.0',0,'',''),(5048,'Bpmn-visualization','A new Light Blue BPMN theme is available. It uses the new improvement about the fill color of the Text Annotation elements 👇.','use new improvement about fill color',0,'',''),(5049,'Bpmn-visualization','See milestone 0.25.2 to get the list of issues covered by this release.','get list of issues',0,'',''),(5050,'Bpmn-visualization','See milestone 0.25.1 to get the list of issues covered by this release.','get list of issues',0,'',''),(5051,'Bpmn-visualization','This new release provides a new API to filter pools when loading the BPMN diagram.','provide new API to filter pools',0,'',''),(5052,'Bpmn-visualization','This new release provides a new API to filter pools when loading the BPMN diagram.','load BPMN diagram',0,'',''),(5053,'Bpmn-visualization','See milestone 0.25.0 to get the list of issues covered by this release.','get list of issues',0,'',''),(5054,'Bpmn-visualization','When calling the load method, it is now possible to filter the pools in the diagram you want to display.\nYou can filter one or several pools and specify the filtering options by pool id and/or name.','call load method',0,'',''),(5055,'Bpmn-visualization','When calling the load method, it is now possible to filter the pools in the diagram you want to display.\nYou can filter one or several pools and specify the filtering options by pool id and/or name.','specify filtering options by pool id and/or name',0,'',''),(5056,'Bpmn-visualization','In the following example 👇, we load the same diagram with different filter configuration. First without filter, so we see the whole diagram. Then we filter different pools, one pool at a time. And finally, we filter 3 pools at the same time.','load same diagram with different filter configuration',0,'',''),(5057,'Bpmn-visualization','See milestone 0.24.1 to get the list of issues covered by this release.','get list of issues',0,'',''),(5058,'Bpmn-visualization','Use SVG favicon for a better resolution. It is also used in the HTML documentation as documentation is using the same\nfile as in the demo/example/test pages.\nRename non-regression.js for consistency (same as the page where it is used)','use SVG favicon for better resolution',0,'',''),(5059,'Bpmn-visualization','Use SVG favicon for a better resolution. It is also used in the HTML documentation as documentation is using the same\nfile as in the demo/example/test pages.\nRename non-regression.js for consistency (same as the page where it is used)','use same file',0,'',''),(5060,'Bpmn-visualization','Use SVG favicon for a better resolution. It is also used in the HTML documentation as documentation is using the same\nfile as in the demo/example/test pages.\nRename non-regression.js for consistency (same as the page where it is used)','use  in HTML documentation',0,'',''),(5061,'Bpmn-visualization','Use SVG favicon for a better resolution. It is also used in the HTML documentation as documentation is using the same\nfile as in the demo/example/test pages.\nRename non-regression.js for consistency (same as the page where it is used)','rename non-regression.js for consistency',0,'',''),(5062,'Bpmn-visualization','TypeScript projects integrating bpmn-visualization but using an unsupported TypeScript version now get an explicit error message instead of a list of type errors.','integrate bpmn-visualization',0,'',''),(5063,'Bpmn-visualization','TypeScript projects integrating bpmn-visualization but using an unsupported TypeScript version now get an explicit error message instead of a list of type errors.','use unsupported TypeScript version',0,'',''),(5064,'Bpmn-visualization','TypeScript projects integrating bpmn-visualization but using an unsupported TypeScript version now get an explicit error message instead of a list of type errors.','get explicit error message instead_of list',0,'',''),(5065,'Bpmn-visualization','For instance, when using TypeScript Version 4.4.4','use TypeScript',1,'https://github.com/process-analytics/bpmn-visualization-js/pull/2272',''),(5066,'Bpmn-visualization','To get the error message','get error message',0,'',''),(5067,'Bpmn-visualization','You can trigger a rebase of this PR by commenting @dependabot rebase.','trigger rebase by commenting',0,'',''),(5068,'Bpmn-visualization','You can trigger a rebase of this PR by commenting @dependabot rebase.','trigger rebase of PR',0,'',''),(5069,'Bpmn-visualization','You can trigger Dependabot actions by commenting on this PR:','trigger Dependabot actions by commenting',0,'',''),(5070,'Bpmn-visualization','Update the configuration to only ignore folders at project root. To prevent new\nerrors in the future, also do this for the build and dist folders.\nFix lint errors in files in the config folders.','update configuration',0,'',''),(5071,'Bpmn-visualization','Update the configuration to only ignore folders at project root. To prevent new\nerrors in the future, also do this for the build and dist folders.\nFix lint errors in files in the config folders.','ignore folders at project root',0,'',''),(5072,'Bpmn-visualization','Update the configuration to only ignore folders at project root. To prevent new\nerrors in the future, also do this for the build and dist folders.\nFix lint errors in files in the config folders.','prevent new errors in future',0,'',''),(5073,'Bpmn-visualization','Update the configuration to only ignore folders at project root. To prevent new\nerrors in the future, also do this for the build and dist folders.\nFix lint errors in files in the config folders.','fix lint errors in files',0,'',''),(5074,'Bpmn-visualization','This repository contains examples showing how to use bpmn-visualization.','use bpmn-visualization',0,'',''),(5075,'Bpmn-visualization','Some examples require loading local files. If you are looking for BPMN diagram files, you can use resources from:','load local files',0,'',''),(5076,'Bpmn-visualization','Some examples require loading local files. If you are looking for BPMN diagram files, you can use resources from:','use resources',0,'',''),(5077,'Bpmn-visualization','Some examples and demos may load ES Modules; in that case, you cannot open html pages directly from your local disk.','load ES modules',0,'',''),(5078,'Bpmn-visualization','For instance, on Chrome, the Console would display the following errors','display following errors for instance',0,'',''),(5079,'Bpmn-visualization','For instance, on Chrome, the Console would display the following errors','display following errors on chrome',0,'',''),(5080,'Bpmn-visualization','Access to script at \'file:///...../bpmn-visualization-examples/examples/my-file.js\' from origin \'null\' has been\nblocked by CORS policy: Cross origin requests are only supported for protocol schemes: http, data, chrome,\nchrome-extension, https. index.html:1\nFailed to load resource: net::ERR_FAILED utils.js:1','support cross origin requests for protocol schemes',0,'',''),(5081,'Bpmn-visualization','Access to script at \'file:///...../bpmn-visualization-examples/examples/my-file.js\' from origin \'null\' has been\nblocked by CORS policy: Cross origin requests are only supported for protocol schemes: http, data, chrome,\nchrome-extension, https. index.html:1\nFailed to load resource: net::ERR_FAILED utils.js:1','load resource',0,'',''),(5082,'Bpmn-visualization','To access such examples, you need to run a local web server and then access the examples via the http protocol.\nWe advise to make the local web server serve the whole repository, to also be able to access to the demo (resources available\nin the ./demo folder).','access such examples',0,'',''),(5083,'Bpmn-visualization','To access such examples, you need to run a local web server and then access the examples via the http protocol.\nWe advise to make the local web server serve the whole repository, to also be able to access to the demo (resources available\nin the ./demo folder).','run local web server',0,'',''),(5084,'Bpmn-visualization','To access such examples, you need to run a local web server and then access the examples via the http protocol.\nWe advise to make the local web server serve the whole repository, to also be able to access to the demo (resources available\nin the ./demo folder).','access examples via http protocol',0,'',''),(5085,'Bpmn-visualization','To access such examples, you need to run a local web server and then access the examples via the http protocol.\nWe advise to make the local web server serve the whole repository, to also be able to access to the demo (resources available\nin the ./demo folder).','access  to demo',0,'',''),(5086,'Bpmn-visualization','Some examples are provided for direct use in the web browser. If you want to integrate their related code in a project, adaptations may be required.','provide examples for direct use',0,'',''),(5087,'Bpmn-visualization','Some examples are provided for direct use in the web browser. If you want to integrate their related code in a project, adaptations may be required.','integrate related code in project',0,'',''),(5088,'Bpmn-visualization','You can check the examples projects in this repository or the Live IDE examples to know how to bootstrap bpmn-visualization in a project.','check examples projects in repository',0,'',''),(5089,'Bpmn-visualization','You can check the examples projects in this repository or the Live IDE examples to know how to bootstrap bpmn-visualization in a project.','check examples projects in live IDE examples',0,'',''),(5090,'Bpmn-visualization','TypeScript\'s users should also read the paragraph about the TypeScript support in the bpmn-visualization README\nespecially when using bpmn-visualization prior version 0.27.0.','read paragraph about TypeScript support',0,'',''),(5091,'Bpmn-visualization','TypeScript\'s users should also read the paragraph about the TypeScript support in the bpmn-visualization README\nespecially when using bpmn-visualization prior version 0.27.0.','use bpmn-visualization prior version 0.27.0',0,'',''),(5092,'Bpmn-visualization','DISCLAIMER: extension points are currently very experimental and are subject to change.\nThey are mainly hacks to let you see what will be later available in a more integrated way. \nCustom BPMN Theme features will be progressively added to bpmn-visualization. See the Extensions Milestone.','add custom BPMN theme features to bpmn-visualization',0,'',''),(5093,'Bpmn-visualization','Show how to integrate bpmn-visualization in project, using various kind of build tools and bundlers:','integrate bpmn-visualization in project',0,'',''),(5094,'Bpmn-visualization','Show how to integrate bpmn-visualization in project, using various kind of build tools and bundlers:','use various kind',0,'',''),(5095,'Bpmn-visualization','To contribute to bpmn-visualization-examples, fork and clone this repository locally and commit your code on a separate branch. \nPlease add a screenshot of the new rendering when you open a pull-request.','add screenshot of new rendering',0,'',''),(5096,'Bpmn-visualization','To contribute to bpmn-visualization-examples, fork and clone this repository locally and commit your code on a separate branch. \nPlease add a screenshot of the new rendering when you open a pull-request.','open pull-request',0,'',''),(5097,'Bpmn-visualization','You can find more detail in our Contributing guide. Participation in this open source project is subject to a Code of Conduct.','find more detail in contributing guide',0,'',''),(5098,'Bpmn-visualization','bpmn-visualization-examples is released under the Apache 2.0 license. \nCopyright © 2020-present, Bonitasoft S.A.','release bpmn-visualization-examples under apache 2.0 license',0,'',''),(5099,'Bpmn-visualization','The extensions panel on Gitpod when opening this PR. The extensions are not sync with the Gitpod user settings letting us to improve the settings iteratively and without impacting the existing settings of the user.','open PR',0,'',''),(5100,'Bpmn-visualization','Please check the ⏩ live environment.','check â© live environment',0,'',''),(5101,'Bpmn-visualization','You will find there basic usage as well as detailed examples showing possible rendering customizations.','find basic usage',0,'',''),(5102,'Bpmn-visualization','You will find there basic usage as well as detailed examples showing possible rendering customizations.','find detailed examples',0,'',''),(5103,'Bpmn-visualization','You will find there basic usage as well as detailed examples showing possible rendering customizations.','show possible rendering customizations',0,'',''),(5104,'Bpmn-visualization','bpmn-visualization is actively developed and maintained.','develop bpmn-visualization',0,'',''),(5105,'Bpmn-visualization','Before the release of version 1.0.0, there may be some breaking changes. We avoid these as much as possible, and carefully document them in the release notes.\nAs far as possible, we maintain compatibility for some minor versions.','document  in release notes',0,'',''),(5106,'Bpmn-visualization','The library is available from NPM. \nWe support various module formats such as:','support various module formats',0,'',''),(5107,'Bpmn-visualization','Then use this snippet to load your BPMN diagram in a page:','use snippet',1,'https://github.com/process-analytics/bpmn-visualization-js.git','user-content--project-usage'),(5108,'Bpmn-visualization','Then use this snippet to load your BPMN diagram in a page:','load BPMN',1,'https://github.com/process-analytics/bpmn-visualization-js.git','user-content--project-usage'),(5109,'Bpmn-visualization','The bpmn-visualization npm package includes type definitions, so the integration works out of the box in TypeScript projects.\nbpmn-visualization requires TypeScript 4.5 or greater.','include type definitions',0,'',''),(5110,'Bpmn-visualization','ℹ️ If you are looking for examples of projects integrating bpmn-visualization with TypeScript, see the bpmn-visualization-examples repository.','integrate bpmn-visualization with TypeScript',0,'',''),(5111,'Bpmn-visualization','To contribute to bpmn-visualization, fork and clone this repository locally and commit your code on a separate branch.\nPlease write tests for your code before opening a pull-request:','write tests before opening',1,'https://github.com/process-analytics/bpmn-visualization-js.git','user-content--contributing'),(5112,'Bpmn-visualization','To contribute to bpmn-visualization, fork and clone this repository locally and commit your code on a separate branch.\nPlease write tests for your code before opening a pull-request:','write tests for code',1,'https://github.com/process-analytics/bpmn-visualization-js.git','user-content--contributing'),(5113,'Bpmn-visualization','To contribute to bpmn-visualization, fork and clone this repository locally and commit your code on a separate branch.\nPlease write tests for your code before opening a pull-request:','open pull-request',1,'https://github.com/process-analytics/bpmn-visualization-js.git','user-content--contributing'),(5114,'Bpmn-visualization','bpmn-visualization is released under the Apache 2.0 license.\nCopyright © 2020-present, Bonitasoft S.A.','release bpmn-visualization under apache 2.0 license',0,'',''),(5115,'Bpmn-visualization','🔗 Release Notes','release Notes',0,'',''),(5116,'Bpmn-visualization','Prettier now switches to using the resolve module for resolving configuration files and plugins if it detects that require.resolve isn\'t Node\'s builtin function (doesn\'t support the second argument), which happens in environments like editor extensions. To force the fallback, set the PRETTIER_FALLBACK_RESOLVE environment variable to true.','use resolve module for resolving',0,'',''),(5117,'Bpmn-visualization','Prettier now switches to using the resolve module for resolving configuration files and plugins if it detects that require.resolve isn\'t Node\'s builtin function (doesn\'t support the second argument), which happens in environments like editor extensions. To force the fallback, set the PRETTIER_FALLBACK_RESOLVE environment variable to true.','resolve configuration files',0,'',''),(5118,'Bpmn-visualization','Prettier now switches to using the resolve module for resolving configuration files and plugins if it detects that require.resolve isn\'t Node\'s builtin function (doesn\'t support the second argument), which happens in environments like editor extensions. To force the fallback, set the PRETTIER_FALLBACK_RESOLVE environment variable to true.','resolve plugins',0,'',''),(5119,'Bpmn-visualization','Prettier now switches to using the resolve module for resolving configuration files and plugins if it detects that require.resolve isn\'t Node\'s builtin function (doesn\'t support the second argument), which happens in environments like editor extensions. To force the fallback, set the PRETTIER_FALLBACK_RESOLVE environment variable to true.','force fallback',0,'',''),(5120,'Bpmn-visualization','Prettier now switches to using the resolve module for resolving configuration files and plugins if it detects that require.resolve isn\'t Node\'s builtin function (doesn\'t support the second argument), which happens in environments like editor extensions. To force the fallback, set the PRETTIER_FALLBACK_RESOLVE environment variable to true.','set PRETTIER_FALLBACK_RESOLVE environment variable to true',0,'',''),(5121,'Bpmn-visualization','This version was pushed to npm by thorn0, a new releaser for prettier since your current version.','push version',0,'',''),(5122,'Bpmn-visualization','Dependabot will resolve any conflicts with this PR as long as you don\'t alter it yourself. You can also trigger a rebase manually by commenting @dependabot rebase.','resolve conflicts with PR',0,'',''),(5123,'Bpmn-visualization','Dependabot will resolve any conflicts with this PR as long as you don\'t alter it yourself. You can also trigger a rebase manually by commenting @dependabot rebase.','trigger rebase by commenting',0,'',''),(5124,'Bpmn-visualization','You can trigger Dependabot actions by commenting on this PR:','trigger Dependabot actions by commenting',0,'',''),(5125,'Bpmn-visualization','This allows people who are used to reading changelog files to know where to find the bpmn-visualization release notes.','read changelog files',0,'',''),(5126,'Bpmn-visualization','This allows people who are used to reading changelog files to know where to find the bpmn-visualization release notes.','find bpmn-visualization release notes',0,'',''),(5127,'Bpmn-visualization','This allows people who are used to reading changelog files to know where to find the bpmn-visualization release notes.','use people to reading',0,'',''),(5128,'Bpmn-visualization','Reuse the image from the examples repository.','reuse image from examples repository',0,'',''),(5129,'Bpmn-visualization','Previously, calling BpmnElementsRegistry.getElementsByIds generated error when the HTML BPMN container has no id.\nWhen using framework like Svelte or Angular, the container doesn\'t have such id, so it prevented to use the API out of the box.','generate error',0,'',''),(5130,'Bpmn-visualization','Previously, calling BpmnElementsRegistry.getElementsByIds generated error when the HTML BPMN container has no id.\nWhen using framework like Svelte or Angular, the container doesn\'t have such id, so it prevented to use the API out of the box.','use framework like Svelte',0,'',''),(5131,'Bpmn-visualization','Previously, calling BpmnElementsRegistry.getElementsByIds generated error when the HTML BPMN container has no id.\nWhen using framework like Svelte or Angular, the container doesn\'t have such id, so it prevented to use the API out of the box.','use framework like angular',0,'',''),(5132,'Bpmn-visualization','Previously, calling BpmnElementsRegistry.getElementsByIds generated error when the HTML BPMN container has no id.\nWhen using framework like Svelte or Angular, the container doesn\'t have such id, so it prevented to use the API out of the box.','use API out_of box',0,'',''),(5133,'Bpmn-visualization','The CSS selector that retrieves the HTML elements has been simplified to not use the id.','retrieve HTML elements',0,'',''),(5134,'Bpmn-visualization','The CSS selector that retrieves the HTML elements has been simplified to not use the id.','retrieve CSS selector',0,'',''),(5135,'Bpmn-visualization','The \"elements-identification\" demo has been updated to use a BPMN container without id.\nPrior, the fix, it reproduced the issue when calling the registry API','use BPMN container without id',1,'https://github.com/process-analytics/bpmn-visualization-js/pull/2282',''),(5136,'Bpmn-visualization','The \"elements-identification\" demo has been updated to use a BPMN container without id.\nPrior, the fix, it reproduced the issue when calling the registry API','call registry API',1,'https://github.com/process-analytics/bpmn-visualization-js/pull/2282',''),(5137,'Bpmn-visualization','The drag\'n drop code was only able to manage container with id. It has been updated to support container without id as well.','manage container with id',0,'',''),(5138,'Bpmn-visualization','The drag\'n drop code was only able to manage container with id. It has been updated to support container without id as well.','support container without id',0,'',''),(5139,'Bpmn-visualization','The bug is reproduced with the first commit (new integration test): df2c5d6\nAdditional tests were added to reproduce the issue with the BpmnElementsRegistry API: 53a42bd\nThe elements-identification.html demo was updated to also reproduce the problem: 8946525','add     df2c5d6    additional tests',0,'',''),(5140,'Bpmn-visualization','At first glance, this looks good. I have provided minor remarks about naming.','provide minor remarks about naming',0,'',''),(5141,'Bpmn-visualization','The current integration tests reproduce the problem but not in the context of the issue.\nThey involve HtmlElementLookup which is a test utility and which uses the code that contains the problem (BpmnQuerySelectors). But this utility uses BpmnQuerySelectors  only to avoid duplication with the production code\nIts implementation may change (We could use a completely different implementation to do the lookup that doesn\'t rely on the production code) and in that case, the tests won\'t cover anything.  The div tests have been created to ensure that the BPMN elements are created in the DOM not to test the BpmnElementsRegistry API.','use code',0,'',''),(5142,'Bpmn-visualization','The current integration tests reproduce the problem but not in the context of the issue.\nThey involve HtmlElementLookup which is a test utility and which uses the code that contains the problem (BpmnQuerySelectors). But this utility uses BpmnQuerySelectors  only to avoid duplication with the production code\nIts implementation may change (We could use a completely different implementation to do the lookup that doesn\'t rely on the production code) and in that case, the tests won\'t cover anything.  The div tests have been created to ensure that the BPMN elements are created in the DOM not to test the BpmnElementsRegistry API.','use BpmnQuerySelectors',0,'',''),(5143,'Bpmn-visualization','The current integration tests reproduce the problem but not in the context of the issue.\nThey involve HtmlElementLookup which is a test utility and which uses the code that contains the problem (BpmnQuerySelectors). But this utility uses BpmnQuerySelectors  only to avoid duplication with the production code\nIts implementation may change (We could use a completely different implementation to do the lookup that doesn\'t rely on the production code) and in that case, the tests won\'t cover anything.  The div tests have been created to ensure that the BPMN elements are created in the DOM not to test the BpmnElementsRegistry API.','change production code',0,'',''),(5144,'Bpmn-visualization','The current integration tests reproduce the problem but not in the context of the issue.\nThey involve HtmlElementLookup which is a test utility and which uses the code that contains the problem (BpmnQuerySelectors). But this utility uses BpmnQuerySelectors  only to avoid duplication with the production code\nIts implementation may change (We could use a completely different implementation to do the lookup that doesn\'t rely on the production code) and in that case, the tests won\'t cover anything.  The div tests have been created to ensure that the BPMN elements are created in the DOM not to test the BpmnElementsRegistry API.','create BPMN elements in DOM',0,'',''),(5145,'Bpmn-visualization','The current integration tests reproduce the problem but not in the context of the issue.\nThey involve HtmlElementLookup which is a test utility and which uses the code that contains the problem (BpmnQuerySelectors). But this utility uses BpmnQuerySelectors  only to avoid duplication with the production code\nIts implementation may change (We could use a completely different implementation to do the lookup that doesn\'t rely on the production code) and in that case, the tests won\'t cover anything.  The div tests have been created to ensure that the BPMN elements are created in the DOM not to test the BpmnElementsRegistry API.','create div tests',0,'',''),(5146,'Bpmn-visualization','In addition, the current integration tests are white/gray box tests as it knows that the implementation uses BpmnQuerySelectors. So, it is not easy to understand what is the problem under the hood. Black box tests, direcly involving BpmnElementsRegistry, would have been more understandable.','use BpmnQuerySelectors',0,'',''),(5147,'Bpmn-visualization','I am not saying that we should remove the existing integration tests.\nBut, IHMO we should add new tests on the BpmnElementsRegistry, so in dom.bpmn.elements.test.ts.','remove existing integration tests',0,'',''),(5148,'Bpmn-visualization','I am not saying that we should remove the existing integration tests.\nBut, IHMO we should add new tests on the BpmnElementsRegistry, so in dom.bpmn.elements.test.ts.','add new tests on BpmnElementsRegistry',0,'',''),(5149,'Bpmn-visualization','I have just added the update of the \"elements-identification\" demo that now uses a BPMN container without id (I updated the PR description with more details).\nThe Drag\'n Drop overlay works whether the BPMN container has an id or not.','add update of elements-identification demo',0,'',''),(5150,'Bpmn-visualization','I have just added the update of the \"elements-identification\" demo that now uses a BPMN container without id (I updated the PR description with more details).\nThe Drag\'n Drop overlay works whether the BPMN container has an id or not.','use BPMN container without id',0,'',''),(5151,'Bpmn-visualization','I have just added the update of the \"elements-identification\" demo that now uses a BPMN container without id (I updated the PR description with more details).\nThe Drag\'n Drop overlay works whether the BPMN container has an id or not.','use elements-identification demo without id',0,'',''),(5152,'Bpmn-visualization','Remove extra TSDoc syntax, only keep plain text.\nThe NOTICE file has been excluded from the eslint processing: this file doesn\'t change, is related to the documentation, and does not follow the JS/TS header file format. So there is no reason to lint it.','remove extra TSDoc syntax',0,'',''),(5153,'Bpmn-visualization','Remove extra TSDoc syntax, only keep plain text.\nThe NOTICE file has been excluded from the eslint processing: this file doesn\'t change, is related to the documentation, and does not follow the JS/TS header file format. So there is no reason to lint it.','exclude NOTICE file from eslint processing',0,'',''),(5154,'Bpmn-visualization','TypeScript projects integrating the lib no longer need to declare \'typed-mxgraph\' types. The TypeScript compilation now works out of the box.\nProjects that customize the mxGraph code don\'t need additional configuration to access mxGraph types.','integrate lib',0,'',''),(5155,'Bpmn-visualization','TypeScript projects integrating the lib no longer need to declare \'typed-mxgraph\' types. The TypeScript compilation now works out of the box.\nProjects that customize the mxGraph code don\'t need additional configuration to access mxGraph types.','customize mxGraph code',0,'',''),(5156,'Bpmn-visualization','TypeScript projects integrating the lib no longer need to declare \'typed-mxgraph\' types. The TypeScript compilation now works out of the box.\nProjects that customize the mxGraph code don\'t need additional configuration to access mxGraph types.','customize projects',0,'',''),(5157,'Bpmn-visualization','Previously, the declaration files included in the npm package referenced \'typed-mxgraph\' with:','include  in typed-mxgraph',1,'https://github.com/process-analytics/bpmn-visualization-js/pull/2258',''),(5158,'Bpmn-visualization','\"typed-mxgraph\" had to be accessible directly and so, node_modules/@typed-mxgraph had to be added to TypeScript configuration typeRoots. This was because the lib itself declared it in typeRoots.','add  to TypeScript configuration typeRoots',0,'',''),(5159,'Bpmn-visualization','The changes are tested with a dedicated TypeScript project that runs the TypeScript compiler. It also tests the lowest TypeScript version that can work with the lib (currently 4.5).','run TypeScript compiler',0,'',''),(5160,'Bpmn-visualization','The changes are tested with a dedicated TypeScript project that runs the TypeScript compiler. It also tests the lowest TypeScript version that can work with the lib (currently 4.5).','run dedicated TypeScript project',0,'',''),(5161,'Bpmn-visualization','The changes are tested with a dedicated TypeScript project that runs the TypeScript compiler. It also tests the lowest TypeScript version that can work with the lib (currently 4.5).','test changes with dedicated TypeScript project',0,'',''),(5162,'Bpmn-visualization','The changes are tested with a dedicated TypeScript project that runs the TypeScript compiler. It also tests the lowest TypeScript version that can work with the lib (currently 4.5).','test lowest TypeScript version',0,'',''),(5163,'Bpmn-visualization','The README has been updating accordingly. It contains a note about the configuration that was previously required. It should help projects still using an old version.','use old version',0,'',''),(5164,'Bpmn-visualization','The projects in the examples repository work with the implementation provided in this PR. See process-analytics/bpmn-visualization-examples#405','provide  in PR',0,'',''),(5165,'Bpmn-visualization','Why global.d.ts instead of compilerOptions.types inside jsconfig.json or tsconfig.json?\nSetting compilerOptions.types shuts out all other types not explicitly listed in the configuration. Using triple-slash references keeps the default TypeScript setting of accepting type information from the entire workspace, while also adding svelte and vite/client type information.','use triple-slash references',0,'',''),(5166,'Bpmn-visualization','Why global.d.ts instead of compilerOptions.types inside jsconfig.json or tsconfig.json?\nSetting compilerOptions.types shuts out all other types not explicitly listed in the configuration. Using triple-slash references keeps the default TypeScript setting of accepting type information from the entire workspace, while also adding svelte and vite/client type information.','add svelte vite/client type information',0,'',''),(5167,'Bpmn-visualization','@assynour could you review the README a provide suggestion/question if it is not clear enough? Thanks','provide suggestion/question',0,'',''),(5168,'Bpmn-visualization','I started working on the repository of examples. The integration works fine for projects that don\'t call mxGraph code.\n⚠️ I see some errors in the vite project that directly calls mxGraph code. The build command fails.\nSo please don\'t merge this PR until we figure out what is going on!','call mxGraph code',0,'',''),(5169,'Bpmn-visualization','I started working on the repository of examples. The integration works fine for projects that don\'t call mxGraph code.\n⚠️ I see some errors in the vite project that directly calls mxGraph code. The build command fails.\nSo please don\'t merge this PR until we figure out what is going on!','call vite project',0,'',''),(5170,'Bpmn-visualization','I started working on the repository of examples. The integration works fine for projects that don\'t call mxGraph code. warning I see some errors in the vite project that directly calls mxGraph code. The build command fails. So please don\'t merge this PR until we figure out what is going on!','call mxGraph code',1,'https://github.com/process-analytics/bpmn-visualization-js/pull/2258',''),(5171,'Bpmn-visualization','I started working on the repository of examples. The integration works fine for projects that don\'t call mxGraph code. warning I see some errors in the vite project that directly calls mxGraph code. The build command fails. So please don\'t merge this PR until we figure out what is going on!','call vite project',1,'https://github.com/process-analytics/bpmn-visualization-js/pull/2258',''),(5172,'Bpmn-visualization','There was a problem hiding this comment.','hide comment',0,'',''),(5173,'Bpmn-visualization','Do you check if there is no error with ESLint in your IDE when a file of the tests is updated ?\nIn my memories, we added this for the edition of the tests on IDE.','add  in memories',0,'',''),(5174,'Bpmn-visualization','Do you check if there is no error with ESLint in your IDE when a file of the tests is updated ?\nIn my memories, we added this for the edition of the tests on IDE.','add  for edition',0,'',''),(5175,'Bpmn-visualization','Do you check if there is no error with ESLint in your IDE when a file of the tests is updated ?\nIn my memories, we added this for the edition of the tests on IDE.','add  on IDE',0,'',''),(5176,'Bpmn-visualization','✔️ Yes it works. If I add an unsued import','add unsued import',1,'https://github.com/process-analytics/bpmn-visualization-js/pull/2258',''),(5177,'Bpmn-visualization','I get a typescript-eslint error:','get typescript-eslint error',1,'https://github.com/process-analytics/bpmn-visualization-js/pull/2258',''),(5178,'Bpmn-visualization','Read the announcement post for all the details.','read announcement post for details',0,'',''),(5179,'Bpmn-visualization','Set eslint rules to ensure we explicitly used the type modifier for imports and exports.\nIt will also help introduce build tools like esbuild.','use type modifier for imports',0,'',''),(5180,'Bpmn-visualization','Set eslint rules to ensure we explicitly used the type modifier for imports and exports.\nIt will also help introduce build tools like esbuild.','use type modifier for exports',0,'',''),(5181,'Bpmn-visualization','Generalize work started in #1666\nSet eslint rules','set eslint rules',0,'',''),(5182,'Bpmn-visualization','I tried to move the parserOptions configuration in the dedicated eslintrc but I got errors.','move parserOptions configuration in dedicated eslintrc',0,'',''),(5183,'Bpmn-visualization','I tried to move the parserOptions configuration in the dedicated eslintrc but I got errors.','get errors',0,'',''),(5184,'Bpmn-visualization','⚠️ performance impact of adding the consistent-type-exports rule: eslint now triggers TS compilation, and this will be done at each commit\nSee https://typescript-eslint.io/docs/linting/type-linting/#how-is-performance','add consistent-type-exports rule eslint',0,'',''),(5185,'Bpmn-visualization','⚠️ performance impact of adding the consistent-type-exports rule: eslint now triggers TS compilation, and this will be done at each commit\nSee https://typescript-eslint.io/docs/linting/type-linting/#how-is-performance','trigger TS compilation',0,'',''),(5186,'Bpmn-visualization','Decision: we are aware of the risk. First usages as part of commit in this PR show no visible commit time change.\nIf this becomes to slow us down, we will revert the rules that requires TSC','show commit time change',0,'',''),(5187,'Bpmn-visualization','Due to the fact that default image lacks certain libraries needed for the puppeteer to lanch, the new enhanced Dockerfile was created.','create new enhanced Dockerfile due_to fact',0,'',''),(5188,'Bpmn-visualization','Running a fresh workspace, the npm install script was not run.\nThis is probably because there was no .gitpod.yml in the master branch.','run fresh workspace',0,'',''),(5189,'Bpmn-visualization','After having switched to the branch of this pr that has the init tasks, run npm install, the e2e tests fail.','switch  to branch',0,'',''),(5190,'Bpmn-visualization','I have removed the node_modules, then restarted the workspace. The node_modules folder is not created.\ne2e tests still fail.','remove node_modules',0,'',''),(5191,'Bpmn-visualization','I have removed the node_modules, then restarted the workspace. The node_modules folder is not created.\ne2e tests still fail.','restart workspace',0,'',''),(5192,'Bpmn-visualization','Maybe there is some issues with running Gitpod from PR?','run Gitpod from PR',0,'',''),(5193,'Bpmn-visualization','I have just tested by running it from my GitHub branch and tests are passing.\nhttps://github.com/aibcmars/bpmn-visualization-js/tree/infra-gitpod_e2e_tests_fix','run  from GitHub branch',0,'',''),(5194,'Bpmn-visualization','I have just tested by running it from my GitHub branch and tests are passing.\nhttps://github.com/aibcmars/bpmn-visualization-js/tree/infra-gitpod_e2e_tests_fix','test  by running',0,'',''),(5195,'Bpmn-visualization','I have just tested by running it from my GitHub branch and tests are passing.\nhttps://github.com/aibcmars/bpmn-visualization-js/tree/infra-gitpod_e2e_tests_fix','pass  by running',0,'',''),(5196,'Bpmn-visualization','Ok, I will retest with a fresh workspace created from the branch of this PR as described in https://www.gitpod.io/docs/context-urls/#branch-context\nhttps://gitpod.io/#https://github.com/aibcmars/bpmn-visualization-js/tree/infra-gitpod_e2e_tests_fix','create  from branch',0,'',''),(5197,'Bpmn-visualization','✔️ Creating the workspace with the branch of this PR works fine\nThe workspace creation is a bit more slower than before because of the need for rebuilding the Docker image. We may document this.','create workspace with branch',0,'',''),(5198,'Bpmn-visualization','✔️ Creating the workspace with the branch of this PR works fine\nThe workspace creation is a bit more slower than before because of the need for rebuilding the Docker image. We may document this.','rebuild Docker image',0,'',''),(5199,'Bpmn-visualization','npm install is run at workspace startup','run npm install at workspace startup',0,'',''),(5200,'Bpmn-visualization','I got some errors in the log when running e2e tests, but tests pass, so we can check this later','get errors in log',1,'https://github.com/process-analytics/bpmn-visualization-js/pull/686',''),(5201,'Bpmn-visualization','I got some errors in the log when running e2e tests, but tests pass, so we can check this later','run e2e tests',1,'https://github.com/process-analytics/bpmn-visualization-js/pull/686',''),(5202,'Bpmn-visualization','Add a step in the release process.','add step in release process',0,'',''),(5203,'Bpmn-visualization','StyleDefault SHAPE_ACTIVITY_MARKER_ICON_SIZE\nImplicitly managed with the issue to have a true marker fixed size.','manage  with issue',0,'',''),(5204,'Bpmn-visualization','StyleConfigurator: lane and pool label style. Documented in the issue.','document  in issue',0,'',''),(5205,'Bpmn-visualization','editorconfig: we use os eol and let git manage eol on push\nThis setting may only be needed for windows, but default git checkout config\nhandle it correctly.\nSo remove the todo about setting a specific configuration.','use os eol',0,'',''),(5206,'Bpmn-visualization','editorconfig: we use os eol and let git manage eol on push\nThis setting may only be needed for windows, but default git checkout config\nhandle it correctly.\nSo remove the todo about setting a specific configuration.','manage eol on push',0,'',''),(5207,'Bpmn-visualization','editorconfig: we use os eol and let git manage eol on push\nThis setting may only be needed for windows, but default git checkout config\nhandle it correctly.\nSo remove the todo about setting a specific configuration.','remove todo about setting',0,'',''),(5208,'Bpmn-visualization','editorconfig: we use os eol and let git manage eol on push\nThis setting may only be needed for windows, but default git checkout config\nhandle it correctly.\nSo remove the todo about setting a specific configuration.','set specific configuration',0,'',''),(5209,'Bpmn-visualization','Ok I will test on a local Windows 10 machine, probably on Monday.','test  on local Windows machine',0,'',''),(5210,'Bpmn-visualization','I will manage it while testing on Ubuntu locally.','manage  while testing',0,'',''),(5211,'Bpmn-visualization','I will manage it while testing on Ubuntu locally.','test  on Ubuntu',0,'',''),(5212,'Bpmn-visualization','See milestone 0.27.1 to get the list of issues covered by this release.','get list of issues',0,'',''),(5213,'Bpmn-visualization','Previously, it was mandatory to define an id in the HTML div element used to display the BPMN diagram. ⚠️ It is not a common practice to set the id of a component with Angular and Svelte.\nAs a result, some bpmn-visualization APIs were generating an error when the id was not defined.','define id in HTML div element',0,'',''),(5214,'Bpmn-visualization','Previously, it was mandatory to define an id in the HTML div element used to display the BPMN diagram. ⚠️ It is not a common practice to set the id of a component with Angular and Svelte.\nAs a result, some bpmn-visualization APIs were generating an error when the id was not defined.','display BPMN diagram',0,'',''),(5215,'Bpmn-visualization','Previously, it was mandatory to define an id in the HTML div element used to display the BPMN diagram. ⚠️ It is not a common practice to set the id of a component with Angular and Svelte.\nAs a result, some bpmn-visualization APIs were generating an error when the id was not defined.','set id with Angular',0,'',''),(5216,'Bpmn-visualization','Previously, it was mandatory to define an id in the HTML div element used to display the BPMN diagram. ⚠️ It is not a common practice to set the id of a component with Angular and Svelte.\nAs a result, some bpmn-visualization APIs were generating an error when the id was not defined.','set id with svelte',0,'',''),(5217,'Bpmn-visualization','Previously, it was mandatory to define an id in the HTML div element used to display the BPMN diagram. ⚠️ It is not a common practice to set the id of a component with Angular and Svelte.\nAs a result, some bpmn-visualization APIs were generating an error when the id was not defined.','set id of component',0,'',''),(5218,'Bpmn-visualization','Previously, it was mandatory to define an id in the HTML div element used to display the BPMN diagram. ⚠️ It is not a common practice to set the id of a component with Angular and Svelte.\nAs a result, some bpmn-visualization APIs were generating an error when the id was not defined.','generate error as result',0,'',''),(5219,'Bpmn-visualization','See milestone 0.27.0 to get the list of issues covered by this release.','get list of issues',0,'',''),(5220,'Bpmn-visualization','In 0.24.0, it was announced that bpmnVisualization.fit(fitOptions) was deprecated.\nFrom now, this method is completely removed. Use bpmnVisualization.navigation.fit(fitOptions) instead.','remove method',0,'',''),(5221,'Bpmn-visualization','In 0.24.0, it was announced that bpmnVisualization.fit(fitOptions) was deprecated.\nFrom now, this method is completely removed. Use bpmnVisualization.navigation.fit(fitOptions) instead.','use bpmnVisualization.navigation.fit(fitOptions)',0,'',''),(5222,'Bpmn-visualization','Previously, the TypeScript projects need a specific configuration, in the tsconfig.json file, to integrate bpmn-visualization.','integrate bpmn-visualization',0,'',''),(5223,'Bpmn-visualization','From now, the integration of bpmn-visualization in TypeScript projects is simplified. They no longer need this configuration.\nThe README contains a note about the configuration that was previously required. It should help projects still using an old version.','use old version',0,'',''),(5224,'Bpmn-visualization','In addition, a more explicit error message is displayed when integrating bpmn-visualization in a project that uses a too old TypeScript version. Remember that bpmn-visualization requires TypeScript 4.5 or superior.','integrate bpmn-visualization in project',0,'',''),(5225,'Bpmn-visualization','In addition, a more explicit error message is displayed when integrating bpmn-visualization in a project that uses a too old TypeScript version. Remember that bpmn-visualization requires TypeScript 4.5 or superior.','use old TypeScript version',0,'',''),(5226,'Bpmn-visualization','In addition, a more explicit error message is displayed when integrating bpmn-visualization in a project that uses a too old TypeScript version. Remember that bpmn-visualization requires TypeScript 4.5 or superior.','use project',0,'',''),(5227,'Bpmn-visualization','In addition, a more explicit error message is displayed when integrating bpmn-visualization in a project that uses a too old TypeScript version. Remember that bpmn-visualization requires TypeScript 4.5 or superior.','display explicit error message',0,'',''),(5228,'Bpmn-visualization','bpmn-visualization supports now the detection of the Complex Gateway.','support detection of complex Gateway',0,'',''),(5229,'Bpmn-visualization','For now, the Complex Gateway is displayed as a red diamond, as follows:','display complex Gateway as red diamond',0,'',''),(5230,'Bpmn-visualization','See milestone 0.26.2 to get the list of issues covered by this release.','get list of issues',0,'',''),(5231,'Bpmn-visualization','This is now easier to use bpmn-visualization in Parcel, Webpack and Angular projects. Previously, it was necessary to add a special configuration to integrate bpmn-visualization. With version 0.26.2, this is not needed anymore.','use bpmn-visualization in parcel',0,'',''),(5232,'Bpmn-visualization','This is now easier to use bpmn-visualization in Parcel, Webpack and Angular projects. Previously, it was necessary to add a special configuration to integrate bpmn-visualization. With version 0.26.2, this is not needed anymore.','use bpmn-visualization in webpack',0,'',''),(5233,'Bpmn-visualization','This is now easier to use bpmn-visualization in Parcel, Webpack and Angular projects. Previously, it was necessary to add a special configuration to integrate bpmn-visualization. With version 0.26.2, this is not needed anymore.','use bpmn-visualization in Angular projects',0,'',''),(5234,'Bpmn-visualization','This is now easier to use bpmn-visualization in Parcel, Webpack and Angular projects. Previously, it was necessary to add a special configuration to integrate bpmn-visualization. With version 0.26.2, this is not needed anymore.','add special configuration',0,'',''),(5235,'Bpmn-visualization','This is now easier to use bpmn-visualization in Parcel, Webpack and Angular projects. Previously, it was necessary to add a special configuration to integrate bpmn-visualization. With version 0.26.2, this is not needed anymore.','integrate bpmn-visualization',0,'',''),(5236,'Bpmn-visualization','See milestone 0.26.1 to get the list of issues covered by this release.','get list of issues',0,'',''),(5237,'Bpmn-visualization','This new version brings improvements to customize the style of the Text Annotation elements and a new BPMN theme in the demo.','customize new BPMN theme in demo',0,'',''),(5238,'Bpmn-visualization','This new version brings improvements to customize the style of the Text Annotation elements and a new BPMN theme in the demo.','customize new BPMN theme of text Annotation elements',0,'',''),(5239,'Bpmn-visualization','This new version brings improvements to customize the style of the Text Annotation elements and a new BPMN theme in the demo.','customize style in demo',0,'',''),(5240,'Bpmn-visualization','This new version brings improvements to customize the style of the Text Annotation elements and a new BPMN theme in the demo.','customize style of text Annotation elements',0,'',''),(5241,'Bpmn-visualization','See milestone 0.26.0 to get the list of issues covered by this release.','get list of issues',0,'',''),(5242,'Bpmn-visualization','In previous versions, it was already possible to customize the style of the Text Annotation elements and to configure a fill color (gradient could also be used).\nBut only a small area of the Text Annotation was filled (the area delimited by the open rectangle).','customize style of text Annotation elements',0,'',''),(5243,'Bpmn-visualization','In previous versions, it was already possible to customize the style of the Text Annotation elements and to configure a fill color (gradient could also be used).\nBut only a small area of the Text Annotation was filled (the area delimited by the open rectangle).','configure fill color',0,'',''),(5244,'Bpmn-visualization','In previous versions, it was already possible to customize the style of the Text Annotation elements and to configure a fill color (gradient could also be used).\nBut only a small area of the Text Annotation was filled (the area delimited by the open rectangle).','fill small area of text Annotation',0,'',''),(5245,'Bpmn-visualization','In version 0.26.0, the whole Text Annotation area is now filled.','fill whole text Annotation area in version 0.26.0',0,'',''),(5246,'Bpmn-visualization','This new feature allows you to highlight the entire text of Text Annotation elements.\nCheck the Bonita procurement example using #B4AFAF26 for Text Annotation fill color 👇.','check bonita procurement example',0,'',''),(5247,'Bpmn-visualization','The \'Diagram\' title section has been removed. So there is now more space for the BPMN diagram rendering, especially on mobile.\nIn addition, the \'fit on load\', \'fit margin\' and \'theme\' blocks (from the control panel) align better on small screens.','remove title section',0,'',''),(5248,'Bpmn-visualization','The \'Diagram\' title section has been removed. So there is now more space for the BPMN diagram rendering, especially on mobile.\nIn addition, the \'fit on load\', \'fit margin\' and \'theme\' blocks (from the control panel) align better on small screens.','fit margin',0,'',''),(5249,'Bpmn-visualization','Check the evolution between version 0.25.2 and version 0.26.0 (shown as 0.25.3-post version here) 👇.\nThe videos have been done with Chrome 104.','check evolution between version 0.25.2',0,'',''),(5250,'Bpmn-visualization','Check the evolution between version 0.25.2 and version 0.26.0 (shown as 0.25.3-post version here) 👇.\nThe videos have been done with Chrome 104.','check evolution between version 0.26.0',0,'',''),(5251,'Bpmn-visualization','A new Light Blue BPMN theme is available. It uses the new improvement about the fill color of the Text Annotation elements 👇.','use new improvement about fill color',0,'',''),(5252,'Bpmn-visualization','See milestone 0.25.2 to get the list of issues covered by this release.','get list of issues',0,'',''),(5253,'Bpmn-visualization','See milestone 0.25.1 to get the list of issues covered by this release.','get list of issues',0,'',''),(5254,'Bpmn-visualization','This new release provides a new API to filter pools when loading the BPMN diagram.','provide new API to filter pools',0,'',''),(5255,'Bpmn-visualization','This new release provides a new API to filter pools when loading the BPMN diagram.','load BPMN diagram',0,'',''),(5256,'Bpmn-visualization','See milestone 0.25.0 to get the list of issues covered by this release.','get list of issues',0,'',''),(5257,'Bpmn-visualization','When calling the load method, it is now possible to filter the pools in the diagram you want to display.\nYou can filter one or several pools and specify the filtering options by pool id and/or name.','call load method',0,'',''),(5258,'Bpmn-visualization','When calling the load method, it is now possible to filter the pools in the diagram you want to display.\nYou can filter one or several pools and specify the filtering options by pool id and/or name.','specify filtering options by pool id and/or name',0,'',''),(5259,'Bpmn-visualization','In the following example 👇, we load the same diagram with different filter configuration. First without filter, so we see the whole diagram. Then we filter different pools, one pool at a time. And finally, we filter 3 pools at the same time.','load same diagram with different filter configuration',0,'',''),(5260,'Bpmn-visualization','See milestone 0.24.1 to get the list of issues covered by this release.','get list of issues',0,'',''),(5261,'Bpmn-visualization','Use SVG favicon for a better resolution. It is also used in the HTML documentation as documentation is using the same\nfile as in the demo/example/test pages.\nRename non-regression.js for consistency (same as the page where it is used)','use SVG favicon for better resolution',0,'',''),(5262,'Bpmn-visualization','Use SVG favicon for a better resolution. It is also used in the HTML documentation as documentation is using the same\nfile as in the demo/example/test pages.\nRename non-regression.js for consistency (same as the page where it is used)','use same file',0,'',''),(5263,'Bpmn-visualization','Use SVG favicon for a better resolution. It is also used in the HTML documentation as documentation is using the same\nfile as in the demo/example/test pages.\nRename non-regression.js for consistency (same as the page where it is used)','use  in HTML documentation',0,'',''),(5264,'Bpmn-visualization','Use SVG favicon for a better resolution. It is also used in the HTML documentation as documentation is using the same\nfile as in the demo/example/test pages.\nRename non-regression.js for consistency (same as the page where it is used)','rename non-regression.js for consistency',0,'',''),(5265,'Bpmn-visualization','TypeScript projects integrating bpmn-visualization but using an unsupported TypeScript version now get an explicit error message instead of a list of type errors.','integrate bpmn-visualization',0,'',''),(5266,'Bpmn-visualization','TypeScript projects integrating bpmn-visualization but using an unsupported TypeScript version now get an explicit error message instead of a list of type errors.','use unsupported TypeScript version',0,'',''),(5267,'Bpmn-visualization','TypeScript projects integrating bpmn-visualization but using an unsupported TypeScript version now get an explicit error message instead of a list of type errors.','get explicit error message instead_of list',0,'',''),(5268,'Bpmn-visualization','For instance, when using TypeScript Version 4.4.4','use TypeScript',1,'https://github.com/process-analytics/bpmn-visualization-js/pull/2272',''),(5269,'Bpmn-visualization','To get the error message','get error message',0,'',''),(5270,'Bpmn-visualization','We benefit from the ViteJS \'unbundled\' way of working: the dev server starts and updates in 200-300 ms instead of 13-18\nseconds.\nWe also have a much better integration for tailwindcss than with the custom hack we previously used.','use custom hack',0,'',''),(5271,'Bpmn-visualization','You can trigger a rebase of this PR by commenting @dependabot rebase.','trigger rebase by commenting',0,'',''),(5272,'Bpmn-visualization','You can trigger a rebase of this PR by commenting @dependabot rebase.','trigger rebase of PR',0,'',''),(5273,'Bpmn-visualization','Update the configuration to only ignore folders at project root. To prevent new\nerrors in the future, also do this for the build and dist folders.\nFix lint errors in files in the config folders.','update configuration',0,'',''),(5274,'Bpmn-visualization','Update the configuration to only ignore folders at project root. To prevent new\nerrors in the future, also do this for the build and dist folders.\nFix lint errors in files in the config folders.','ignore folders at project root',0,'',''),(5275,'Bpmn-visualization','Update the configuration to only ignore folders at project root. To prevent new\nerrors in the future, also do this for the build and dist folders.\nFix lint errors in files in the config folders.','prevent new errors in future',0,'',''),(5276,'Bpmn-visualization','Update the configuration to only ignore folders at project root. To prevent new\nerrors in the future, also do this for the build and dist folders.\nFix lint errors in files in the config folders.','fix lint errors in files',0,'',''),(5277,'Ivy','By default, Ivy searches for a site configuration file called either site.py or config.py.\nYou can specify a custom filename for the site configuration file using the IVY_CONFIG_FILE environment variable, e.g.','call site.py by default',1,'http://www.dmulholl.com/docs/ivy/main/options.html','site-configuration-file'),(5278,'Ivy','By default, Ivy searches for a site configuration file called either site.py or config.py.\nYou can specify a custom filename for the site configuration file using the IVY_CONFIG_FILE environment variable, e.g.','call config.py by default',1,'http://www.dmulholl.com/docs/ivy/main/options.html','site-configuration-file'),(5279,'Ivy','By default, Ivy searches for a site configuration file called either site.py or config.py.\nYou can specify a custom filename for the site configuration file using the IVY_CONFIG_FILE environment variable, e.g.','specify custom filename for site configuration file',1,'http://www.dmulholl.com/docs/ivy/main/options.html','site-configuration-file'),(5280,'Ivy','By default, Ivy searches for a site configuration file called either site.py or config.py.\nYou can specify a custom filename for the site configuration file using the IVY_CONFIG_FILE environment variable, e.g.','use IVY_CONFIG_FILE environment variable',1,'http://www.dmulholl.com/docs/ivy/main/options.html','site-configuration-file'),(5281,'Ivy','By default, Ivy uses directories named ext, inc, lib, out, res, and src.','use directories by default',0,'',''),(5282,'Ivy','You can customize these default directory names using environment variables, e.g.','use environment variables',1,'http://www.dmulholl.com/docs/ivy/main/options.html','directory-names'),(5283,'Ivy','Alternatively, you can customize directory names on a per-site basis by specifying alternate names in your site configuration file, e.g.','customize directory names by specifying',1,'http://www.dmulholl.com/docs/ivy/main/options.html','directory-names'),(5284,'Ivy','Alternatively, you can customize directory names on a per-site basis by specifying alternate names in your site configuration file, e.g.','customize directory names on per-site basis',1,'http://www.dmulholl.com/docs/ivy/main/options.html','directory-names'),(5285,'Ivy','Alternatively, you can customize directory names on a per-site basis by specifying alternate names in your site configuration file, e.g.','specify alternate names in site configuration file',1,'http://www.dmulholl.com/docs/ivy/main/options.html','directory-names'),(5286,'Ivy','Ivy generates output pages with a .html file extension by default.','generate output pages',0,'',''),(5287,'Ivy','You can specify a custom file extension for output files in your site configuration file, e.g.','specify custom file extension in site configuration file',1,'http://www.dmulholl.com/docs/ivy/main/options.html','custom-file-extensions'),(5288,'Ivy','You can specify a custom file extension for output files in your site configuration file, e.g.','specify custom file extension for output files',1,'http://www.dmulholl.com/docs/ivy/main/options.html','custom-file-extensions'),(5289,'Ivy','You can generate directory-style URLs — i.e. URLs ending in a forward slash — by setting a custom file extension of \"/\" in your site configuration file:','generate directory-style urls â i.e. urls',1,'http://www.dmulholl.com/docs/ivy/main/options.html','directory-style-urls'),(5290,'Ivy','You can generate directory-style URLs — i.e. URLs ending in a forward slash — by setting a custom file extension of \"/\" in your site configuration file:','set custom file extension of /',1,'http://www.dmulholl.com/docs/ivy/main/options.html','directory-style-urls'),(5291,'Ivy','Ivy generates page-relative URLs by default.','generate page-relative urls by default',0,'',''),(5292,'Ivy','You can generate absolute URLs by specifying an explicit root URL in your site configuration file, e.g.','generate absolute urls by specifying',1,'http://www.dmulholl.com/docs/ivy/main/options.html','absolute-urls'),(5293,'Ivy','You can generate absolute URLs by specifying an explicit root URL in your site configuration file, e.g.','specify explicit root URL in site configuration file',1,'http://www.dmulholl.com/docs/ivy/main/options.html','absolute-urls'),(5294,'Ivy','You can generate site-relative URLs — i.e. URLs that begin with a / — by specifying a root URL of \"/\" in your site configuration file:','generate site-relative urls â i.e. urls',1,'http://www.dmulholl.com/docs/ivy/main/options.html','site-relative-urls'),(5295,'Ivy','To initialize a new site, create a site directory, cd into it, and run the init command:','initialize new site',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','command-line-interface'),(5296,'Ivy','To initialize a new site, create a site directory, cd into it, and run the init command:','create site directory',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','command-line-interface'),(5297,'Ivy','To initialize a new site, create a site directory, cd into it, and run the init command:','run init command',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','command-line-interface'),(5298,'Ivy','Use the ivy --help flag to view the full command-line help text.','use ivy',0,'',''),(5299,'Ivy','Ivy assumes that a site uses the following default directory structure:','use following default directory structure',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','site-structure'),(5300,'Ivy','Ivy uses the presence of a site.py file (alternatively, a config.py file) to identify a site\'s home directory.','identify home directory',0,'',''),(5301,'Ivy','Static assets such as image files should be placed in the site\'s resources directory, res. The content of this directory is copied to the output directory when the site is built.','place static assets in resources directory',0,'',''),(5302,'Ivy','Static assets such as image files should be placed in the site\'s resources directory, res. The content of this directory is copied to the output directory when the site is built.','place static assets such_as image files',0,'',''),(5303,'Ivy','A node is a text file or directory stored in a site\'s src directory. Ivy parses the src directory into a tree of nodes which it then renders into a website, generating a single HTML page in the out directory for each node in the tree.','store  in src directory',0,'',''),(5304,'Ivy','A node is a text file or directory stored in a site\'s src directory. Ivy parses the src directory into a tree of nodes which it then renders into a website, generating a single HTML page in the out directory for each node in the tree.','render nodes into website',0,'',''),(5305,'Ivy','A node is a text file or directory stored in a site\'s src directory. Ivy parses the src directory into a tree of nodes which it then renders into a website, generating a single HTML page in the out directory for each node in the tree.','generate single HTML page in out directory',0,'',''),(5306,'Ivy','A node file can begin with a YAML header specifying metadata for the node:','specify metadata for node',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','nodes'),(5307,'Ivy','Node content can be written in Markdown, Syntext, or plain HTML.\nFiles with a .md extension have their content passed through a Markdown renderer; files with a .stx extension have their content passed through a Syntext renderer; files with an unregistered extension (like .txt or .html) have their content preserved as-is.','write node content in markdown',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','nodes'),(5308,'Ivy','Node content can be written in Markdown, Syntext, or plain HTML.\nFiles with a .md extension have their content passed through a Markdown renderer; files with a .stx extension have their content passed through a Syntext renderer; files with an unregistered extension (like .txt or .html) have their content preserved as-is.','write node content in syntext',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','nodes'),(5309,'Ivy','Node content can be written in Markdown, Syntext, or plain HTML.\nFiles with a .md extension have their content passed through a Markdown renderer; files with a .stx extension have their content passed through a Syntext renderer; files with an unregistered extension (like .txt or .html) have their content preserved as-is.','write node content in plain HTML',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','nodes'),(5310,'Ivy','Node content can be written in Markdown, Syntext, or plain HTML.\nFiles with a .md extension have their content passed through a Markdown renderer; files with a .stx extension have their content passed through a Syntext renderer; files with an unregistered extension (like .txt or .html) have their content preserved as-is.','pass  through Markdown renderer',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','nodes'),(5311,'Ivy','Node content can be written in Markdown, Syntext, or plain HTML.\nFiles with a .md extension have their content passed through a Markdown renderer; files with a .stx extension have their content passed through a Syntext renderer; files with an unregistered extension (like .txt or .html) have their content preserved as-is.','pass  through Syntext renderer',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','nodes'),(5312,'Ivy','correspond to a single node in the parse tree. Node files provide content and metadata for a node; node directories store child nodes.','provide content for node',0,'',''),(5313,'Ivy','correspond to a single node in the parse tree. Node files provide content and metadata for a node; node directories store child nodes.','provide metadata for node',0,'',''),(5314,'Ivy','correspond to a single node in the parse tree. Node files provide content and metadata for a node; node directories store child nodes.','store child nodes',0,'',''),(5315,'Ivy','Ivy has builtin support for node metadata in YAML format. Note that metadata keys are converted to lowercase and spaces and hyphens are replaced by underscores so the YAML attribute:','replace spaces',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','metadata'),(5316,'Ivy','Ivy has builtin support for node metadata in YAML format. Note that metadata keys are converted to lowercase and spaces and hyphens are replaced by underscores so the YAML attribute:','replace hyphens',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','metadata'),(5317,'Ivy','Ivy has builtin support for node metadata in YAML format. Note that metadata keys are converted to lowercase and spaces and hyphens are replaced by underscores so the YAML attribute:','convert metadata keys',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','metadata'),(5318,'Ivy','The node\'s text content as read from the source file.','read  from source file',0,'',''),(5319,'Ivy','The node\'s text content after it has been rendered into HTML. (This will only differ from node.text if a renderer has been registered for the node file\'s extension. By default a Markdown renderer is registered for .md files and a Syntext renderer for .stx files.)','render text content into HTML',0,'',''),(5320,'Ivy','Ivy generates page-relative URLs and files with a .html extension by default.','generate page-relative urls',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','links'),(5321,'Ivy','Ivy generates page-relative URLs and files with a .html extension by default.','generate files',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','links'),(5322,'Ivy','Use two trailing slashes when linking to pages generated by Ivy itself — this tells Ivy to rewrite the ending to suit your extension settings.','use trailing slashes',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','links'),(5323,'Ivy','Use two trailing slashes when linking to pages generated by Ivy itself — this tells Ivy to rewrite the ending to suit your extension settings.','link  to pages',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','links'),(5324,'Ivy','Use two trailing slashes when linking to pages generated by Ivy itself — this tells Ivy to rewrite the ending to suit your extension settings.','generate  by ivy',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','links'),(5325,'Ivy','Linking to the homepage is a special case — a simple @root/ will always suffice.','link  to homepage',0,'',''),(5326,'Ivy','A node\'s URL is determined by its slug and by the slugs of its ancestor nodes. By default a node\'s slug is generated by slugifying its filename — the extension is stripped, text is converted to lowercase ASCII, spaces are converted to hyphens etc., so a node file named Foo Bar.md would have the slug foo-bar.','determine URL',0,'',''),(5327,'Ivy','A node\'s URL is determined by its slug and by the slugs of its ancestor nodes. By default a node\'s slug is generated by slugifying its filename — the extension is stripped, text is converted to lowercase ASCII, spaces are converted to hyphens etc., so a node file named Foo Bar.md would have the slug foo-bar.','generate slug',0,'',''),(5328,'Ivy','A node\'s URL is determined by its slug and by the slugs of its ancestor nodes. By default a node\'s slug is generated by slugifying its filename — the extension is stripped, text is converted to lowercase ASCII, spaces are converted to hyphens etc., so a node file named Foo Bar.md would have the slug foo-bar.','convert spaces',0,'',''),(5329,'Ivy','A node\'s URL is determined by its slug and by the slugs of its ancestor nodes. By default a node\'s slug is generated by slugifying its filename — the extension is stripped, text is converted to lowercase ASCII, spaces are converted to hyphens etc., so a node file named Foo Bar.md would have the slug foo-bar.','convert text',0,'',''),(5330,'Ivy','This default slug can be overridden by setting a custom slug in the header:','set custom slug in header',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','slugs'),(5331,'Ivy','This default slug can be overridden by setting a custom slug in the header:','override default slug',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','slugs'),(5332,'Ivy','Slugs can be customized sitewide by registering a filter callback on the Filter.SLUGIFY filter hook. (You can find this hook in the ivy/utils.py file.)','customize sitewide',0,'',''),(5333,'Ivy','Slugs can be customized sitewide by registering a filter callback on the Filter.SLUGIFY filter hook. (You can find this hook in the ivy/utils.py file.)','customize slugs',0,'',''),(5334,'Ivy','Ivy automatically generates a list of useful CSS classes for each page\'s  element based on the page\'s URL slugs. For example the page with the URL:','generate list of useful CSS classes',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','classes'),(5335,'Ivy','You can add your own custom classes for a particular node by adding a comma-separated classes list to the node\'s header, e.g.','add own custom classes by adding',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','classes'),(5336,'Ivy','You can add your own custom classes for a particular node by adding a comma-separated classes list to the node\'s header, e.g.','add own custom classes for particular node',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','classes'),(5337,'Ivy','You can add your own custom classes for a particular node by adding a comma-separated classes list to the node\'s header, e.g.','add comma-separated classes list to header',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','classes'),(5338,'Ivy','Note that the homepage node automatically gets the class homepage.','get class homepage',0,'',''),(5339,'Ivy','The includes directory, inc, is for includeable files, typically snippets of content that can be reused on multiple pages throughout the site like menus or footer links. Source files placed in this folder will be parsed as Markdown or Syntext depending on their extension and the resulting HTML made available for inclusion in templates via an inc. variable.','reuse snippets of content',0,'',''),(5340,'Ivy','The includes directory, inc, is for includeable files, typically snippets of content that can be reused on multiple pages throughout the site like menus or footer links. Source files placed in this folder will be parsed as Markdown or Syntext depending on their extension and the resulting HTML made available for inclusion in templates via an inc. variable.','reuse snippets for includeable files',0,'',''),(5341,'Ivy','The includes directory, inc, is for includeable files, typically snippets of content that can be reused on multiple pages throughout the site like menus or footer links. Source files placed in this folder will be parsed as Markdown or Syntext depending on their extension and the resulting HTML made available for inclusion in templates via an inc. variable.','reuse snippets throughout site',0,'',''),(5342,'Ivy','The includes directory, inc, is for includeable files, typically snippets of content that can be reused on multiple pages throughout the site like menus or footer links. Source files placed in this folder will be parsed as Markdown or Syntext depending on their extension and the resulting HTML made available for inclusion in templates via an inc. variable.','reuse snippets on multiple pages',0,'',''),(5343,'Ivy','The includes directory, inc, is for includeable files, typically snippets of content that can be reused on multiple pages throughout the site like menus or footer links. Source files placed in this folder will be parsed as Markdown or Syntext depending on their extension and the resulting HTML made available for inclusion in templates via an inc. variable.','place  in folder',0,'',''),(5344,'Ivy','For example, a simple menu can be constructed in Markdown using nested lists:','use nested lists',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','includes'),(5345,'Ivy','If this menu was placed in a file named menu.md then the rendered HTML would be available in templates via an inc.menu variable. (Note that filenames are converted to lower case and spaces and hyphens are converted to underscores.)','place menu in file',0,'',''),(5346,'Ivy','You can add files with any extension to the inc directory including .html, .js, and .css.\nIf no renderer has been registered for the extension the file\'s content will be preserved as-is.','add files with extension',0,'',''),(5347,'Ivy','You can add files with any extension to the inc directory including .html, .js, and .css.\nIf no renderer has been registered for the extension the file\'s content will be preserved as-is.','add files to inc directory',0,'',''),(5348,'Ivy','Just add meta_title and/or meta_description attributes to the page\'s header:','add meta_title and/or',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','meta-titles-and-descriptions'),(5349,'Ivy','This isn\'t really a feature of Ivy itself — the default theme simply checks for these attributes in its template files and you can add similar support to your own custom themes.','add similar support to own custom themes',0,'',''),(5350,'Ivy','This isn\'t really a feature of Ivy itself — the default theme simply checks for these attributes in its template files and you can add similar support to your own custom themes.','check  for attributes',0,'',''),(5351,'Ivy','An extension (also known as a plugin) is a Python module or package that extends Ivy\'s functionality. You can install extensions for a site in one of two ways.','extend Python module',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','installing-extensions'),(5352,'Ivy','An extension (also known as a plugin) is a Python module or package that extends Ivy\'s functionality. You can install extensions for a site in one of two ways.','extend package',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','installing-extensions'),(5353,'Ivy','An extension (also known as a plugin) is a Python module or package that extends Ivy\'s functionality. You can install extensions for a site in one of two ways.','install extensions for site',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','installing-extensions'),(5354,'Ivy','You can add an extensions directory named ext to your site\'s root directory. Extension modules placed in this ext directory will be loaded automatically by Ivy.','add extensions directory',0,'',''),(5355,'Ivy','You can add an extensions directory named ext to your site\'s root directory. Extension modules placed in this ext directory will be loaded automatically by Ivy.','place  in ext directory',0,'',''),(5356,'Ivy','You can add an extensions directory named ext to your site\'s root directory. Extension modules placed in this ext directory will be loaded automatically by Ivy.','load extension modules',0,'',''),(5357,'Ivy','If an extension module has been installed on Python\'s standard import path you can activate it for a particular site by adding its name to an extensions list in the site\'s configuration file:','activate  by adding',0,'',''),(5358,'Ivy','If an extension module has been installed on Python\'s standard import path you can activate it for a particular site by adding its name to an extensions list in the site\'s configuration file:','activate  for particular site',0,'',''),(5359,'Ivy','If an extension module has been installed on Python\'s standard import path you can activate it for a particular site by adding its name to an extensions list in the site\'s configuration file:','add name to extensions list',0,'',''),(5360,'Ivy','If an extension module has been installed on Python\'s standard import path you can activate it for a particular site by adding its name to an extensions list in the site\'s configuration file:','install  on standard import path',0,'',''),(5361,'Ivy','This second method can be used to enable extensions installed from the Python package index using pip.','enable extensions',0,'',''),(5362,'Ivy','This second method can be used to enable extensions installed from the Python package index using pip.','use pip',0,'',''),(5363,'Ivy','This second method can be used to enable extensions installed from the Python package index using pip.','install  from Python package index',0,'',''),(5364,'Ivy','This second method can be used to enable extensions installed from the Python package index using pip.','use second method',0,'',''),(5365,'Ivy','Ivy exports a flexible framework of event and filter hooks. Plugins can extend Ivy by registering callback functions on these hooks.','extend ivy by registering',0,'',''),(5366,'Ivy','You can find these bundled plugins in the ivy/ext/ directory which you can view on Github.','find bundled plugins in ivy/ext/ directory',0,'',''),(5367,'Ivy','Event callbacks accept zero or more arguments depending on the specific hook. They may modify their arguments in place but have no return value.','modify arguments in place',0,'',''),(5368,'Ivy','Here\'s a simple event callback that prints a count of the number of pages that have been written to disk:','print count of number',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','events'),(5369,'Ivy','Here\'s a simple event callback that prints a count of the number of pages that have been written to disk:','print simple event callback of number',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','events'),(5370,'Ivy','Here\'s a simple event callback that prints a count of the number of pages that have been written to disk:','write pages to disk',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','events'),(5371,'Ivy','Filter callbacks accept at least one argument — the value to be filtered. They may accept additional arguments depending on the specific hook. Filter callbacks modify and return the value of their first argument.','modify value of first argument',0,'',''),(5372,'Ivy','Filter callbacks accept at least one argument — the value to be filtered. They may accept additional arguments depending on the specific hook. Filter callbacks modify and return the value of their first argument.','return value of first argument',0,'',''),(5373,'Ivy','Here\'s a simple filter callback that changes every instance of the word foo in node content to bar:','change instance of word foo',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','filters'),(5374,'Ivy','Here\'s a simple filter callback that changes every instance of the word foo in node content to bar:','change instance to bar',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','filters'),(5375,'Ivy','Here\'s a simple filter callback that changes every instance of the word foo in node content to bar:','change simple filter callback of word foo',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','filters'),(5376,'Ivy','Here\'s a simple filter callback that changes every instance of the word foo in node content to bar:','change simple filter callback to bar',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','filters'),(5377,'Ivy','This callback is registered on the NODE_TEXT filter hook which fires just before a node\'s text is rendered into HTML. (The NODE_TEXT filter hook can be found in the ivy/nodes.py file).','render text into HTML',0,'',''),(5378,'Ivy','Note that this hook supplies us with the Node instance itself as an additional argument which in this case we ignore.','ignore additional argument in case',0,'',''),(5379,'Ivy','Ivy relies for most of its functionality on a suite of pluggable rendering and parsing engines, e.g. the Jinja template-engine for handling .jinja template files. Extensions can register support for additional rendering and parsing engines using a system of @register decorators.','use system of @register decorators',0,'',''),(5380,'Ivy','Template-engines produce the output HTML for finished .html pages in the site.','produce output HTML',0,'',''),(5381,'Ivy','Ivy has builtin support for Jinja and Ibis templates. Extensions can register support for additional template-engines using the @ivy.templates.register() decorator. Template-engine callbacks are registered per template-file-extension, e.g.','use  decorator',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','template-engines'),(5382,'Ivy','A template-engine callback should accept a dictionary of page data and a template filename and return a string of HTML.','return string of HTML',0,'',''),(5383,'Ivy','Rendering-engines convert node content into HTML which can then be poured into a template to produce the finished .html output page.','convert node content into HTML',0,'',''),(5384,'Ivy','Ivy has builtin support for node files written in Markdown and Syntext. Extensions can register support for additional input formats using the @ivy.renderers.register() decorator. Rendering-engine callbacks are registered per file-extension, e.g.','write  in markdown',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','rendering-engines'),(5385,'Ivy','Ivy has builtin support for node files written in Markdown and Syntext. Extensions can register support for additional input formats using the @ivy.renderers.register() decorator. Rendering-engine callbacks are registered per file-extension, e.g.','write  in syntext',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','rendering-engines'),(5386,'Ivy','Ivy has builtin support for node files written in Markdown and Syntext. Extensions can register support for additional input formats using the @ivy.renderers.register() decorator. Rendering-engine callbacks are registered per file-extension, e.g.','use  decorator',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','rendering-engines'),(5387,'Ivy','A rendering-engine callback should accept a single string argument containing plain text and return a string of HTML.','return string of HTML',0,'',''),(5388,'Ivy','Note that if you register a custom callback for .md files, this will override the default Markdown renderer.','override default Markdown renderer',0,'',''),(5389,'Ivy','Ivy has builtin support for YAML file headers. Extensions can add support for additional metadata formats by preprocessing file content on the file_text filter hook.','add support by preprocessing',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','node-metadata'),(5390,'Ivy','Ivy has builtin support for YAML file headers. Extensions can add support for additional metadata formats by preprocessing file content on the file_text filter hook.','add support for additional metadata formats',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','node-metadata'),(5391,'Ivy','This filter fires each time a node file is loaded from disk; it passes the raw file text along with a metadata dictionary. Callbacks can check the text for an appropriate header marker, process the header if found, and update the dictionary. They should return the text with the header stripped.','pass raw file text along_with metadata dictionary',0,'',''),(5392,'Ivy','This filter fires each time a node file is loaded from disk; it passes the raw file text along with a metadata dictionary. Callbacks can check the text for an appropriate header marker, process the header if found, and update the dictionary. They should return the text with the header stripped.','load node file from disk',0,'',''),(5393,'Ivy','This filter fires each time a node file is loaded from disk; it passes the raw file text along with a metadata dictionary. Callbacks can check the text for an appropriate header marker, process the header if found, and update the dictionary. They should return the text with the header stripped.','load time from disk',0,'',''),(5394,'Ivy','This filter fires each time a node file is loaded from disk; it passes the raw file text along with a metadata dictionary. Callbacks can check the text for an appropriate header marker, process the header if found, and update the dictionary. They should return the text with the header stripped.','check text for appropriate header marker',0,'',''),(5395,'Ivy','This filter fires each time a node file is loaded from disk; it passes the raw file text along with a metadata dictionary. Callbacks can check the text for an appropriate header marker, process the header if found, and update the dictionary. They should return the text with the header stripped.','process header',0,'',''),(5396,'Ivy','This filter fires each time a node file is loaded from disk; it passes the raw file text along with a metadata dictionary. Callbacks can check the text for an appropriate header marker, process the header if found, and update the dictionary. They should return the text with the header stripped.','update dictionary',0,'',''),(5397,'Ivy','This filter fires each time a node file is loaded from disk; it passes the raw file text along with a metadata dictionary. Callbacks can check the text for an appropriate header marker, process the header if found, and update the dictionary. They should return the text with the header stripped.','return text with header',0,'',''),(5398,'Ivy','The FILE_TEXT filter hook can be found in the ivy/utils.py file.','find FILE_TEXT filter hook in ivy/utils.py file',0,'',''),(5399,'Ivy','Ivy uses the Markdown package to render node files with a .md extension. You can add a\ndictionary of keyword arguments for the Markdown renderer to your site configuration file via a\nmarkdown_settings attribute, e.g.','render node files',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','markdown'),(5400,'Ivy','Ivy uses the Markdown package to render node files with a .md extension. You can add a\ndictionary of keyword arguments for the Markdown renderer to your site configuration file via a\nmarkdown_settings attribute, e.g.','add dictionary of keyword arguments',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','markdown'),(5401,'Ivy','Ivy uses the Markdown package to render node files with a .md extension. You can add a\ndictionary of keyword arguments for the Markdown renderer to your site configuration file via a\nmarkdown_settings attribute, e.g.','add dictionary to site configuration file',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','markdown'),(5402,'Ivy','Note that you can register a custom handler for .md files to use an alternative Markdown library of your choice.','use alternative Markdown library of choice',0,'',''),(5403,'Ivy','Ivy uses the Syntext package to render node files with a .stx extension. You can add a dictionary of keyword arguments for the Syntext renderer to your site configuration file via a syntext_settings attribute, e.g.','render node files',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','syntext'),(5404,'Ivy','Ivy uses the Syntext package to render node files with a .stx extension. You can add a dictionary of keyword arguments for the Syntext renderer to your site configuration file via a syntext_settings attribute, e.g.','add dictionary of keyword arguments',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','syntext'),(5405,'Ivy','Ivy uses the Syntext package to render node files with a .stx extension. You can add a dictionary of keyword arguments for the Syntext renderer to your site configuration file via a syntext_settings attribute, e.g.','add dictionary to site configuration file',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','syntext'),(5406,'Ivy','Ivy uses the Jinja package to render template files with a .jinja extension. You can add a\ndictionary of keyword arguments for the Jinja environment to your site configuration file via a\njinja_settings attribute.','render template files',0,'',''),(5407,'Ivy','Ivy uses the Jinja package to render template files with a .jinja extension. You can add a\ndictionary of keyword arguments for the Jinja environment to your site configuration file via a\njinja_settings attribute.','add dictionary of keyword arguments',0,'',''),(5408,'Ivy','Ivy uses the Jinja package to render template files with a .jinja extension. You can add a\ndictionary of keyword arguments for the Jinja environment to your site configuration file via a\njinja_settings attribute.','add dictionary to site configuration file',0,'',''),(5409,'Ivy','Ivy uses the Shortcodes package to process shortcodes in node files. You can add a dictionary of\nkeyword arguments for the shortcode parser to your site configuration file via a shortcode_settings attribute.','process shortcodes in node files',0,'',''),(5410,'Ivy','Ivy uses the Shortcodes package to process shortcodes in node files. You can add a dictionary of\nkeyword arguments for the shortcode parser to your site configuration file via a shortcode_settings attribute.','add dictionary of keyword arguments',0,'',''),(5411,'Ivy','Ivy uses the Shortcodes package to process shortcodes in node files. You can add a dictionary of\nkeyword arguments for the shortcode parser to your site configuration file via a shortcode_settings attribute.','add dictionary to site configuration file',0,'',''),(5412,'Ivy','The bundled Automenu extension automatically generates a menu containing links to every node in the site. The menu can be accessed in templates via the automenu attribute. This menu can be customized in three ways:','generate menu',0,'',''),(5413,'Ivy','The bundled Automenu extension automatically generates a menu containing links to every node in the site. The menu can be accessed in templates via the automenu attribute. This menu can be customized in three ways:','access menu in templates',0,'',''),(5414,'Ivy','The bundled Automenu extension automatically generates a menu containing links to every node in the site. The menu can be accessed in templates via the automenu attribute. This menu can be customized in three ways:','customize menu in ways',0,'',''),(5415,'Ivy','If a node has a menu_title attribute, its value will be used in the menu in place of the node\'s title.','use value in menu',0,'',''),(5416,'Ivy','By default entries are ordered alphabetically by filename. Entry order can be customized by giving nodes an integer menu_order attribute (positive or negative) with lower numbers coming first. The default order value is 0. (Note that the homepage is an exception and will always be the first entry in the menu.)','order entries',0,'',''),(5417,'Ivy','By default entries are ordered alphabetically by filename. Entry order can be customized by giving nodes an integer menu_order attribute (positive or negative) with lower numbers coming first. The default order value is 0. (Note that the homepage is an exception and will always be the first entry in the menu.)','customize entry order',0,'',''),(5418,'Ivy','If a node has a menu_exclude attribute set to true it (and its children) will be omitted from the menu.','set  to true',0,'',''),(5419,'Ivy','If a node has a menu_exclude attribute set to true it (and its children) will be omitted from the menu.','omit  from menu',0,'',''),(5420,'Ivy','Only nodes which have a menu_title or title attribute are included in the menu.','include nodes in menu',0,'',''),(5421,'Ivy','This plugin adds support for TOML metadata headers as an alternative to YAML.','add support as alternative',0,'',''),(5422,'Ivy','This plugin adds support for TOML metadata headers as an alternative to YAML.','add support for TOML metadata headers',0,'',''),(5423,'Ivy','A clean, responsive, text-focused theme for Ivy.\nThis is the theme I use for my own personal website.','use theme for own personal website',0,'',''),(5424,'Ivy','No. Ivy is designed to be easy to use, with lots of flexibility under the hood if you\'re prepared to write a little extension code. Execution speed isn\'t a significant design goal as it\'s simply irrelevant for the kind of small personal or project websites Ivy is intended to be used for.','write little extension code',0,'',''),(5425,'Ivy','No. Ivy is designed to be easy to use, with lots of flexibility under the hood if you\'re prepared to write a little extension code. Execution speed isn\'t a significant design goal as it\'s simply irrelevant for the kind of small personal or project websites Ivy is intended to be used for.','use  with lots',0,'',''),(5426,'Ivy','No. Ivy is designed to be easy to use, with lots of flexibility under the hood if you\'re prepared to write a little extension code. Execution speed isn\'t a significant design goal as it\'s simply irrelevant for the kind of small personal or project websites Ivy is intended to be used for.','use  under hood',0,'',''),(5427,'Ivy','No. Ivy is designed to be easy to use, with lots of flexibility under the hood if you\'re prepared to write a little extension code. Execution speed isn\'t a significant design goal as it\'s simply irrelevant for the kind of small personal or project websites Ivy is intended to be used for.','design ivy',0,'',''),(5428,'Ivy','Holly is a blog-engine plugin for Ivy. It adds support for WordPress-style post and tag indexes.','add support for wordpress-style post',0,'',''),(5429,'Ivy','Holly is a blog-engine plugin for Ivy. It adds support for WordPress-style post and tag indexes.','add support for tag indexes',0,'',''),(5430,'Ivy','Image files, along with any other static assets, should be stored in the site\'s resources directory, res. The content of this directory is copied to the output directory when the site is built.','store image files along_with other static assets',0,'',''),(5431,'Ivy','Image files, along with any other static assets, should be stored in the site\'s resources directory, res. The content of this directory is copied to the output directory when the site is built.','store image files in resources directory',0,'',''),(5432,'Ivy','As an example, assume we have a file named photo.jpg stored in a directory named images within the res directory, i.e.','store  in directory',1,'http://www.dmulholl.com/docs/ivy/main/faq.html','where-do-i-put-my-image-files'),(5433,'Ivy','This file will be copied to the output directory and can be accessed in templates and node files via the URL:','access file in templates node files',1,'http://www.dmulholl.com/docs/ivy/main/faq.html','where-do-i-put-my-image-files'),(5434,'Ivy','Ivy has no special support for WordPress-style featured images but we can implement similar functionality simply by adding the image name as an attribute to the page header, e.g.','implement similar functionality by adding',1,'http://www.dmulholl.com/docs/ivy/main/faq.html','does-ivy-support-featured-images-or-image-galleries'),(5435,'Ivy','Ivy has no special support for WordPress-style featured images but we can implement similar functionality simply by adding the image name as an attribute to the page header, e.g.','add image name as attribute',1,'http://www.dmulholl.com/docs/ivy/main/faq.html','does-ivy-support-featured-images-or-image-galleries'),(5436,'Ivy','Ivy has no special support for WordPress-style featured images but we can implement similar functionality simply by adding the image name as an attribute to the page header, e.g.','add image name to page header',1,'http://www.dmulholl.com/docs/ivy/main/faq.html','does-ivy-support-featured-images-or-image-galleries'),(5437,'Ivy','We can then check for the presence of a featured image in the appropriate template file:','check  for presence',1,'http://www.dmulholl.com/docs/ivy/main/faq.html','does-ivy-support-featured-images-or-image-galleries'),(5438,'Ivy','YAML supports lists so we can implement galleries in a similar manner by adding a list of image names to the header and then iterating over the list in the template file:','implement galleries by iterating',1,'http://www.dmulholl.com/docs/ivy/main/faq.html','does-ivy-support-featured-images-or-image-galleries'),(5439,'Ivy','YAML supports lists so we can implement galleries in a similar manner by adding a list of image names to the header and then iterating over the list in the template file:','implement galleries by adding',1,'http://www.dmulholl.com/docs/ivy/main/faq.html','does-ivy-support-featured-images-or-image-galleries'),(5440,'Ivy','YAML supports lists so we can implement galleries in a similar manner by adding a list of image names to the header and then iterating over the list in the template file:','add list of image names',1,'http://www.dmulholl.com/docs/ivy/main/faq.html','does-ivy-support-featured-images-or-image-galleries'),(5441,'Ivy','YAML supports lists so we can implement galleries in a similar manner by adding a list of image names to the header and then iterating over the list in the template file:','add list to header',1,'http://www.dmulholl.com/docs/ivy/main/faq.html','does-ivy-support-featured-images-or-image-galleries'),(5442,'Ivy','YAML doesn\'t support unquoted values that begin with an @ symbol so you\'ll get an error message if you add a bare @root/ URL to a YAML header, e.g.','get error message',1,'http://www.dmulholl.com/docs/ivy/main/faq.html','why-do-i-get-an-error-when-i-add-a-url-to-a-yaml-header'),(5443,'Ivy','YAML doesn\'t support unquoted values that begin with an @ symbol so you\'ll get an error message if you add a bare @root/ URL to a YAML header, e.g.','add bare @root / URL to YAML header',1,'http://www.dmulholl.com/docs/ivy/main/faq.html','why-do-i-get-an-error-when-i-add-a-url-to-a-yaml-header'),(5444,'Ivy','One of the nicest things about a static website is that it\'s completely independent of the tool used to build it. You can host your website anywhere you like — in the simplest case you can \'deploy\' it simply by double-clicking on the .html files to view them locally in your browser.','host website',0,'',''),(5445,'Ivy','One of the nicest things about a static website is that it\'s completely independent of the tool used to build it. You can host your website anywhere you like — in the simplest case you can \'deploy\' it simply by double-clicking on the .html files to view them locally in your browser.','deploy simplest case by double-clicking',0,'',''),(5446,'Ivy','The simplest option to get started is to use a service like Github Pages which will host static websites for free.','use service like github Pages',0,'',''),(5447,'Ivy','The simplest option to get started is to use a service like Github Pages which will host static websites for free.','host static websites like github Pages',0,'',''),(5448,'Ivy','The simplest option to get started is to use a service like Github Pages which will host static websites for free.','host service like github Pages',0,'',''),(5449,'Ivy','The next step up is \'shared web hosting\' — it\'s cheap, flexible, and lots of online companies offer it. I\'ve used NearlyFreeSpeech myself and been happy with their service.','share â',0,'',''),(5450,'Ivy','The next step up is \'shared web hosting\' — it\'s cheap, flexible, and lots of online companies offer it. I\'ve used NearlyFreeSpeech myself and been happy with their service.','share next step',0,'',''),(5451,'Ivy','If you need more control over your hosting environment you can run your own webserver (typically Apache or Nginx) on a virtual server machine (a VPS or Virtual Private Server) you rent from a company like Digital Ocean.','run own webserver on virtual server machine',0,'',''),(5452,'Ivy','You can add a disable flag to a node\'s metadata header:','add disable flag to metadata header',1,'http://www.dmulholl.com/docs/ivy/main/faq.html','can-i-disable-a-node'),(5453,'Ivy','This will stop Ivy from producing an output HTML page for the node.','produce output HTML page for node',0,'',''),(5454,'Ivy','Sure. Ivy defaults to using the Markdown library to render .md files but you can register a custom handler to use any library you like.','use markdown library to render',0,'',''),(5455,'Ivy','Sure. Ivy defaults to using the Markdown library to render .md files but you can register a custom handler to use any library you like.','use library',0,'',''),(5456,'Ivy','Here\'s a simple demo of an Ivy site using the KaTeX JavaScript library to render LaTeX markup.','use KaTeX JavaScript library',0,'',''),(5457,'Ivy','Here\'s a simple demo of an Ivy site using the KaTeX JavaScript library to render LaTeX markup.','render LaTeX markup',0,'',''),(5458,'Ivy','Shortcodes are powerful — you can use them to inject content into a node\'s text or to customize the formatting of a block of content.','customize formatting of block',0,'',''),(5459,'Ivy','Shortcodes are implemented by the shortcodes package, an external library.\nAn Ivy extension can register a new shortcode tag using the shortcode package\'s @register() decorator:','implement shortcodes',1,'http://www.dmulholl.com/docs/ivy/main/shortcodes.html','registering-shortcodes'),(5460,'Ivy','Shortcodes are implemented by the shortcodes package, an external library.\nAn Ivy extension can register a new shortcode tag using the shortcode package\'s @register() decorator:','use  decorator',1,'http://www.dmulholl.com/docs/ivy/main/shortcodes.html','registering-shortcodes'),(5461,'Ivy','Positional and keyword arguments are passed as strings. The handler function itself should return a string which will replace the shortcode in the text.','pass positional keyword arguments as strings',0,'',''),(5462,'Ivy','Positional and keyword arguments are passed as strings. The handler function itself should return a string which will replace the shortcode in the text.','return string',0,'',''),(5463,'Ivy','Positional and keyword arguments are passed as strings. The handler function itself should return a string which will replace the shortcode in the text.','replace shortcode in text',0,'',''),(5464,'Ivy','Positional and keyword arguments are passed as strings. The handler function itself should return a string which will replace the shortcode in the text.','replace string in text',0,'',''),(5465,'Ivy','Note that shortcodes are processed before node text is rendered into HTML so any content injected by a shortcode should be compatible with the existing text\'s format (Markdown, Syntext, etc.).','render node text into HTML',0,'',''),(5466,'Ivy','Note that shortcodes are processed before node text is rendered into HTML so any content injected by a shortcode should be compatible with the existing text\'s format (Markdown, Syntext, etc.).','process shortcodes',0,'',''),(5467,'Ivy','Here\'s a sample shortcode you could use to inject the raw content of a file from the site\'s includes directory, inc, directly into a node file:','use sample shortcode',1,'http://www.dmulholl.com/docs/ivy/main/shortcodes.html','example-include-raw'),(5468,'Ivy','Here\'s a sample shortcode you could use to inject the raw content of a file from the site\'s includes directory, inc, directly into a node file:','include site',1,'http://www.dmulholl.com/docs/ivy/main/shortcodes.html','example-include-raw'),(5469,'Ivy','To use this shortcode, just supply the name of the file you want to include, e.g.','use shortcode e.g.',1,'http://www.dmulholl.com/docs/ivy/main/shortcodes.html','example-include-raw'),(5470,'Ivy','The shortcode will be replaced by the content of the file.','replace shortcode',0,'',''),(5471,'Ivy','Ivy already loads and renders the content of files from the includes directory to make it available in template files. What if you want to include this pre-rendered content in a node file?','include directory',1,'http://www.dmulholl.com/docs/ivy/main/shortcodes.html','example-include-rendered'),(5472,'Ivy','Ivy already loads and renders the content of files from the includes directory to make it available in template files. What if you want to include this pre-rendered content in a node file?','include pre-rendered content in node file',1,'http://www.dmulholl.com/docs/ivy/main/shortcodes.html','example-include-rendered'),(5473,'Ivy','To use this shortcode, just supply the name of the file you want to include, leaving off the file extension, e.g.','use shortcode',1,'http://www.dmulholl.com/docs/ivy/main/shortcodes.html','example-include-rendered'),(5474,'Ivy','The shortcode will be replaced by the rendered content of the file.','replace shortcode',0,'',''),(5475,'Ivy','To use this shortcode, just supply the @root/ url of the target node, e.g.','use shortcode',1,'http://www.dmulholl.com/docs/ivy/main/shortcodes.html','example-list-children'),(5476,'Ivy','The shortcode will be replaced by the list of links.','replace shortcode',0,'',''),(5477,'Ivy','Here\'s an example of a block-level shortcode wrapping a block of content. Imagine we want to add special styling to quotes with the name of the quote\'s author attached:','wrap block of content',1,'http://www.dmulholl.com/docs/ivy/main/shortcodes.html','example-quote'),(5478,'Ivy','Here\'s an example of a block-level shortcode wrapping a block of content. Imagine we want to add special styling to quotes with the name of the quote\'s author attached:','add special styling with name',1,'http://www.dmulholl.com/docs/ivy/main/shortcodes.html','example-quote'),(5479,'Ivy','Here\'s an example of a block-level shortcode wrapping a block of content. Imagine we want to add special styling to quotes with the name of the quote\'s author attached:','add special styling to quotes',1,'http://www.dmulholl.com/docs/ivy/main/shortcodes.html','example-quote'),(5480,'Ivy','We can use this shortcode in a source file by supplying the author\'s name as an argument:','use shortcode in source file',1,'http://www.dmulholl.com/docs/ivy/main/shortcodes.html','example-quote'),(5481,'Ivy','We can use this shortcode in a source file by supplying the author\'s name as an argument:','use shortcode by supplying',1,'http://www.dmulholl.com/docs/ivy/main/shortcodes.html','example-quote'),(5482,'Ivy','Install Ivy from the Python Package Index using pip:','use pip',1,'http://www.dmulholl.com/docs/ivy/main/index.html','installation'),(5483,'Ivy','Once Ivy is installed, create a new directory for your site and cd into it:','create new directory for site',1,'http://www.dmulholl.com/docs/ivy/main/quickstart.html',''),(5484,'Ivy','Once Ivy is installed, create a new directory for your site and cd into it:','create new directory for cd',1,'http://www.dmulholl.com/docs/ivy/main/quickstart.html',''),(5485,'Ivy','Once Ivy is installed, create a new directory for your site and cd into it:','install ivy',1,'http://www.dmulholl.com/docs/ivy/main/quickstart.html',''),(5486,'Ivy','Initialize the site directory using the init command:','initialize site directory',1,'http://www.dmulholl.com/docs/ivy/main/quickstart.html',''),(5487,'Ivy','Initialize the site directory using the init command:','use init command',1,'http://www.dmulholl.com/docs/ivy/main/quickstart.html',''),(5488,'Ivy','Ivy will create the following directory structure for your site:','create following directory structure for site',1,'http://www.dmulholl.com/docs/ivy/main/quickstart.html',''),(5489,'Ivy','Ivy initializes your src directory with a simple skeleton site which you can build immediately using the build command:','initialize src directory with simple skeleton site',1,'http://www.dmulholl.com/docs/ivy/main/quickstart.html',''),(5490,'Ivy','You can run the build command from the site directory itself or from any of its subdirectories. It tells Ivy to render the text files in the src directory into HTML and place the output in an out directory.','render text files into HTML',0,'',''),(5491,'Ivy','You can run the build command from the site directory itself or from any of its subdirectories. It tells Ivy to render the text files in the src directory into HTML and place the output in an out directory.','render text files in src directory',0,'',''),(5492,'Ivy','You can run the build command from the site directory itself or from any of its subdirectories. It tells Ivy to render the text files in the src directory into HTML and place the output in an out directory.','place output in out directory',0,'',''),(5493,'Ivy','Run the build command and take a look at the output. You can open the HTML files directly in your browser or use Ivy\'s builtin test server to serve the contents of the out directory:','open HTML files in browser',1,'http://www.dmulholl.com/docs/ivy/main/quickstart.html',''),(5494,'Ivy','Run the build command and take a look at the output. You can open the HTML files directly in your browser or use Ivy\'s builtin test server to serve the contents of the out directory:','use builtin test server',1,'http://www.dmulholl.com/docs/ivy/main/quickstart.html',''),(5495,'Ivy','Ivy will build the site using its default graphite theme, which you can find in the lib folder. Try rebuilding the site using the debug theme which is less pretty but provides a lot of useful information that can help you when building or customizing your own themes:','use default graphite theme',1,'http://www.dmulholl.com/docs/ivy/main/quickstart.html',''),(5496,'Ivy','Ivy will build the site using its default graphite theme, which you can find in the lib folder. Try rebuilding the site using the debug theme which is less pretty but provides a lot of useful information that can help you when building or customizing your own themes:','find  in lib folder',1,'http://www.dmulholl.com/docs/ivy/main/quickstart.html',''),(5497,'Ivy','Ivy will build the site using its default graphite theme, which you can find in the lib folder. Try rebuilding the site using the debug theme which is less pretty but provides a lot of useful information that can help you when building or customizing your own themes:','rebuild site',1,'http://www.dmulholl.com/docs/ivy/main/quickstart.html',''),(5498,'Ivy','Ivy will build the site using its default graphite theme, which you can find in the lib folder. Try rebuilding the site using the debug theme which is less pretty but provides a lot of useful information that can help you when building or customizing your own themes:','use debug theme',1,'http://www.dmulholl.com/docs/ivy/main/quickstart.html',''),(5499,'Ivy','Ivy will build the site using its default graphite theme, which you can find in the lib folder. Try rebuilding the site using the debug theme which is less pretty but provides a lot of useful information that can help you when building or customizing your own themes:','provide lot of useful information',1,'http://www.dmulholl.com/docs/ivy/main/quickstart.html',''),(5500,'Ivy','Ivy will build the site using its default graphite theme, which you can find in the lib folder. Try rebuilding the site using the debug theme which is less pretty but provides a lot of useful information that can help you when building or customizing your own themes:','provide debug theme of useful information',1,'http://www.dmulholl.com/docs/ivy/main/quickstart.html',''),(5501,'Ivy','You can run ivy --help to see a list of all the available commands. Note that you can get help for a specific command by running','run ivy',1,'http://www.dmulholl.com/docs/ivy/main/quickstart.html','');
INSERT INTO `overview_task` VALUES (5502,'Ivy','You can run ivy --help to see a list of all the available commands. Note that you can get help for a specific command by running','get help by running',1,'http://www.dmulholl.com/docs/ivy/main/quickstart.html',''),(5503,'Ivy','You can run ivy --help to see a list of all the available commands. Note that you can get help for a specific command by running','get help for specific command',1,'http://www.dmulholl.com/docs/ivy/main/quickstart.html',''),(5504,'Ivy','replacing  with the command name.','replace  with command name',0,'',''),(5505,'Ivy','You can build many different kinds of website using Ivy but it\'s particularly suited to building project documentation like the documentation you\'re looking at right now.','use ivy',0,'',''),(5506,'Ivy','Ivy has builtin support for content written in Markdown, Syntext, or plain HTML, but Ivy itself is format-agnostic — you can write your content in any format with a suitable Python library.','write content in format',0,'',''),(5507,'Ivy','Ivy has builtin support for content written in Markdown, Syntext, or plain HTML, but Ivy itself is format-agnostic — you can write your content in any format with a suitable Python library.','write  in markdown',0,'',''),(5508,'Ivy','Ivy has builtin support for content written in Markdown, Syntext, or plain HTML, but Ivy itself is format-agnostic — you can write your content in any format with a suitable Python library.','write  in syntext',0,'',''),(5509,'Ivy','Ivy has builtin support for content written in Markdown, Syntext, or plain HTML, but Ivy itself is format-agnostic — you can write your content in any format with a suitable Python library.','write  in plain HTML',0,'',''),(5510,'Ivy','Similarly, Ivy has builtin support for Jinja and Ibis templates but can use any template language with a suitable Python library.','use template language with suitable Python library',0,'',''),(5511,'Ivy','This work has been placed in the public domain.','place work in public domain',0,'',''),(5512,'Ivy','Ivy borrows its idea of themes from WordPress where a theme is a directory of templates, styles, and scripts that together provide the look and feel for a site.','provide look',0,'',''),(5513,'Ivy','Ivy borrows its idea of themes from WordPress where a theme is a directory of templates, styles, and scripts that together provide the look and feel for a site.','provide scripts',0,'',''),(5514,'Ivy','This idea is central. You can swap between themes and completely change the appearance of your site without touching its content.','change appearance of site',0,'',''),(5515,'Ivy','This idea is central. You can swap between themes and completely change the appearance of your site without touching its content.','change appearance without touching',0,'',''),(5516,'Ivy','Themes should be placed in the site\'s lib directory, and the name of the active theme directory specified in the site\'s configuration file.','place themes in lib directory',1,'http://www.dmulholl.com/docs/ivy/main/themes.html','location'),(5517,'Ivy','Themes should be placed in the site\'s lib directory, and the name of the active theme directory specified in the site\'s configuration file.','specify  in configuration file',1,'http://www.dmulholl.com/docs/ivy/main/themes.html','location'),(5518,'Ivy','Ivy ships with a small collection of bundled themes including graphite, the default theme you\'re looking at right now, and debug, a diagnostic theme useful when designing themes or debugging sites.','design themes',0,'',''),(5519,'Ivy','Note that you can override the currently active theme with the build command\'s --theme flag:','override active theme with theme flag',1,'http://www.dmulholl.com/docs/ivy/main/themes.html','location'),(5520,'Ivy','Ivy searches for a named theme first in the site\'s theme library, then (if it exists) in the global theme library specified by the $IVY_THEMES environment variable. Finally it searches among the default themes bundled with Ivy itself.','specify  by $IVY_THEMES environment variable',0,'',''),(5521,'Ivy','Ivy searches for a named theme first in the site\'s theme library, then (if it exists) in the global theme library specified by the $IVY_THEMES environment variable. Finally it searches among the default themes bundled with Ivy itself.','specify  for ivy searches',0,'',''),(5522,'Ivy','Ivy searches for a named theme first in the site\'s theme library, then (if it exists) in the global theme library specified by the $IVY_THEMES environment variable. Finally it searches among the default themes bundled with Ivy itself.','search  among default themes',0,'',''),(5523,'Ivy','The content of the resources directory is copied to the output directory when the site is built.\nA theme should store its static assets in this directory, e.g. CSS, JavaScript, font, and image files.','store static assets in font',0,'',''),(5524,'Ivy','The content of the resources directory is copied to the output directory when the site is built.\nA theme should store its static assets in this directory, e.g. CSS, JavaScript, font, and image files.','store static assets in image files',0,'',''),(5525,'Ivy','The content of the resources directory is copied to the output directory when the site is built.\nA theme should store its static assets in this directory, e.g. CSS, JavaScript, font, and image files.','store static assets in directory',0,'',''),(5526,'Ivy','The content of the resources directory is copied to the output directory when the site is built.\nA theme should store its static assets in this directory, e.g. CSS, JavaScript, font, and image files.','store static assets in e.g. CSS',0,'',''),(5527,'Ivy','The content of the resources directory is copied to the output directory when the site is built.\nA theme should store its static assets in this directory, e.g. CSS, JavaScript, font, and image files.','store static assets in JavaScript',0,'',''),(5528,'Ivy','The templates directory is where Ivy looks for the theme\'s template files.\nThis directory is also where Jinja and Ibis will look for files included in templates using {% include %} tags.','use {% include %} tags',0,'',''),(5529,'Ivy','The templates directory is where Ivy looks for the theme\'s template files.\nThis directory is also where Jinja and Ibis will look for files included in templates using {% include %} tags.','include  in templates',0,'',''),(5530,'Ivy','Themes can bundle extensions for Ivy by placing Python modules or packages in the extensions directory.\nThese will be loaded automatically by Ivy.','place Python modules in extensions directory',0,'',''),(5531,'Ivy','Themes can bundle extensions for Ivy by placing Python modules or packages in the extensions directory.\nThese will be loaded automatically by Ivy.','place packages in extensions directory',0,'',''),(5532,'Ivy','There are countless templating languages and Ivy can use any of them, but it has builtin support for Jinja and Ibis. Ivy determines the language of a template file by looking at its extension — .jinja for Jinja and .ibis for Ibis.','determine language by looking',0,'',''),(5533,'Ivy','There are countless templating languages and Ivy can use any of them, but it has builtin support for Jinja and Ibis. Ivy determines the language of a template file by looking at its extension — .jinja for Jinja and .ibis for Ibis.','determine language of template file',0,'',''),(5534,'Ivy','You can add support for alternative templating languages via plugins.','add support for alternative templating languages',0,'',''),(5535,'Ivy','When Ivy generates a HTML page for a node it searches for the appropriate template file to use in reverse order of specificity (most specific first, least specific last).','generate HTML page for node',1,'http://www.dmulholl.com/docs/ivy/main/themes.html','template-hierarchy'),(5536,'Ivy','When Ivy generates a HTML page for a node it searches for the appropriate template file to use in reverse order of specificity (most specific first, least specific last).','search  for appropriate template file',1,'http://www.dmulholl.com/docs/ivy/main/themes.html','template-hierarchy'),(5537,'Ivy','Ivy will search for a template file for this node in the following order:','search  for template file',1,'http://www.dmulholl.com/docs/ivy/main/themes.html','template-hierarchy'),(5538,'Ivy','Ultimately, Ivy will always check for a template file called node.* — this is the default template name and the only template file actually required by a theme.','check  for template file',0,'',''),(5539,'Ivy','A node can override this process by specifying a custom template name in its header:','override process by specifying',1,'http://www.dmulholl.com/docs/ivy/main/themes.html','template-hierarchy'),(5540,'Ivy','A node can override this process by specifying a custom template name in its header:','specify custom template name in header',1,'http://www.dmulholl.com/docs/ivy/main/themes.html','template-hierarchy'),(5541,'Ivy','Note that the file extension should be omitted from the template name.','omit file extension from template name',0,'',''),(5542,'Ivy','All of Ivy\'s code has been placed in the public domain and is free for personal and commercial use. No attribution is required.','place  in public domain',1,'http://www.dmulholl.com/docs/ivy/main/license.html','ivy'),(5543,'Ivy','All other theme code has been placed in the public domain.','place other theme code in public domain',0,'',''),(5544,'scanpy','Fabian Theis & lab: enabling guidance, support and environment','enable guidance',0,'',''),(5545,'scanpy','Fabian Theis & lab: enabling guidance, support and environment','enable support',0,'',''),(5546,'scanpy','Fabian Theis & lab: enabling guidance, support and environment','enable environment',0,'',''),(5547,'scanpy','If you do not have a working installation of Python 3.6 (or later), consider\ninstalling Miniconda (see [Installing Miniconda]). Then run:','install miniconda',1,'https://scanpy.readthedocs.io/en/stable/installation.html',''),(5548,'scanpy','If you prefer to exclusively use PyPI run:','use PyPI run',1,'https://scanpy.readthedocs.io/en/stable/installation.html',''),(5549,'scanpy','The extra [leiden] installs two packages that are needed for popular\nparts of scanpy but aren’t requirements: python-igraph [^cite_csardi06] and leiden [^cite_traag18].','install packages',0,'',''),(5550,'scanpy','To work with the latest version on GitHub: clone the repository and cd into its root directory.','clone repository into root directory',1,'https://scanpy.readthedocs.io/en/stable/installation.html','dev-install-instructions'),(5551,'scanpy','To work with the latest version on GitHub: clone the repository and cd into its root directory.','clone cd into root directory',1,'https://scanpy.readthedocs.io/en/stable/installation.html','dev-install-instructions'),(5552,'scanpy','For older versions of pip, flit can be used directly.\nTo install using symbolic links (stay up to date with your cloned version after you update with git pull) call:','use flit for older versions',1,'https://scanpy.readthedocs.io/en/stable/installation.html','dev-install-instructions'),(5553,'scanpy','If you want to let [conda] handle the installations of dependencies, do:','handle installations of dependencies',1,'https://scanpy.readthedocs.io/en/stable/installation.html','dev-install-instructions'),(5554,'scanpy','On Windows, you might have to use flit install --pth-file\nif you are not able to give yourself the create symbolic links privilege.','use flit install',0,'',''),(5555,'scanpy','If you’re using Docker, you can use e.g. the image gcfntnu/scanpy from Docker Hub.','use docker',0,'',''),(5556,'scanpy','If you get a Permission denied error, never use sudo pip. Instead, use virtual environments or:','use virtual environments',1,'https://scanpy.readthedocs.io/en/stable/installation.html',''),(5557,'scanpy','On MacOS, if not using conda, you might need to install the C core of igraph via homebrew first','install c core of igraph',0,'',''),(5558,'scanpy','brew install igraph','install igraph',0,'',''),(5559,'scanpy','If python-igraph still fails to install, see the question on compiling igraph.\nAlternatively consider installing gcc via brew install gcc --without-multilib\nand exporting the required variables:','compile igraph',1,'https://scanpy.readthedocs.io/en/stable/installation.html',''),(5560,'scanpy','If python-igraph still fails to install, see the question on compiling igraph.\nAlternatively consider installing gcc via brew install gcc --without-multilib\nand exporting the required variables:','install gcc without-multilib exporting',1,'https://scanpy.readthedocs.io/en/stable/installation.html',''),(5561,'scanpy','On Windows, there also often problems installing compiled packages such as igraph,\nbut you can find precompiled packages on Christoph Gohlke’s unofficial binaries.\nDownload those and install them using pip install ./path/to/file.whl','compile packages such_as igraph',0,'',''),(5562,'scanpy','On Windows, there also often problems installing compiled packages such as igraph,\nbut you can find precompiled packages on Christoph Gohlke’s unofficial binaries.\nDownload those and install them using pip install ./path/to/file.whl','find precompiled packages on unofficial binaries',0,'',''),(5563,'scanpy','On Windows, there also often problems installing compiled packages such as igraph,\nbut you can find precompiled packages on Christoph Gohlke’s unofficial binaries.\nDownload those and install them using pip install ./path/to/file.whl','install  on Windows',0,'',''),(5564,'scanpy','After downloading Miniconda, in a unix shell (Linux, Mac), run','run  in unix shell',1,'https://scanpy.readthedocs.io/en/stable/installation.html','conda'),(5565,'scanpy','After downloading Miniconda, in a unix shell (Linux, Mac), run','run  after downloading miniconda',1,'https://scanpy.readthedocs.io/en/stable/installation.html','conda'),(5566,'scanpy','More examples for trajectory inference on complex datasets can be found in the\nPAGA repository [^cite_wolf19], for instance, multi-resolution analyses of whole\nanimals, such as for planaria for data of [^cite_plass18].','find more examples in PAGA repository  ^ cite_wolf19',0,'',''),(5567,'scanpy','More examples for trajectory inference on complex datasets can be found in the\nPAGA repository [^cite_wolf19], for instance, multi-resolution analyses of whole\nanimals, such as for planaria for data of [^cite_plass18].','find more examples for instance',0,'',''),(5568,'scanpy','More examples for trajectory inference on complex datasets can be found in the\nPAGA repository [^cite_wolf19], for instance, multi-resolution analyses of whole\nanimals, such as for planaria for data of [^cite_plass18].','find more examples for trajectory inference',0,'',''),(5569,'scanpy','As a reference for simple pseudotime analyses, we provide the diffusion pseudotime (DPT) analyses of [^cite_haghverdi16]\nfor two hematopoiesis datasets: DPT example 1 [^cite_paul15] and DPT example 2 [^cite_moignard15].','provide diffusion pseudotime analyses as reference',0,'',''),(5570,'scanpy','As a reference for simple pseudotime analyses, we provide the diffusion pseudotime (DPT) analyses of [^cite_haghverdi16]\nfor two hematopoiesis datasets: DPT example 1 [^cite_paul15] and DPT example 2 [^cite_moignard15].','provide diffusion pseudotime analyses of  ^ cite_haghverdi16',0,'',''),(5571,'scanpy','Integrating spatial data with scRNA-seq using scanorama: → tutorial: spatial/integration-scanorama','integrate spatial data',0,'',''),(5572,'scanpy','Integrating spatial data with scRNA-seq using scanorama: → tutorial: spatial/integration-scanorama','use scanorama',0,'',''),(5573,'scanpy','Simulating single cells using literature-curated gene regulatory networks [^cite_wittmann09].','simulate single cells',0,'',''),(5574,'scanpy','Simulating single cells using literature-curated gene regulatory networks [^cite_wittmann09].','use literature-curated gene',0,'',''),(5575,'scanpy','Scanpy is a scalable toolkit for analyzing single-cell gene expression data\nbuilt jointly with anndata.  It includes\npreprocessing, visualization, clustering, trajectory inference and differential\nexpression testing.  The Python-based implementation efficiently deals with\ndatasets of more than one million cells.','include preprocessing trajectory inference',0,'',''),(5576,'scanpy','Scanpy is a scalable toolkit for analyzing single-cell gene expression data\nbuilt jointly with anndata.  It includes\npreprocessing, visualization, clustering, trajectory inference and differential\nexpression testing.  The Python-based implementation efficiently deals with\ndatasets of more than one million cells.','include differential expression testing',0,'',''),(5577,'scanpy','Find tools that harmonize well with anndata & Scanpy via the external API and the ecosystem page.','find tools',0,'',''),(5578,'scanpy','We’ve moved our forums and have a new publicly available chat!','move forums',0,'',''),(5579,'scanpy','Our private developer Slack has been replaced by a public Zulip chat (scverse.zulipchat.com).','replace private developer Slack',0,'',''),(5580,'scanpy','Two large toolkits extending our ecosystem to new modalities have had their manuscripts published!','extend ecosystem to new modalities',0,'',''),(5581,'scanpy','Fix embedding plots by bumping matplotlib dependency to version 3.4 PR 2212 I Virshup','fix embedding plots by bumping',0,'',''),(5582,'scanpy','scanpy.external.pp.scrublet() (and related functions) can now be used on AnnData objects containing multiple batches PR 1965 J Manning','use scanpy.external.pp.scrublet() on AnnData objects',0,'',''),(5583,'scanpy','Number of variables plotted with pca_loadings() can now be controlled with n_points argument. Additionally, variables are no longer repeated if the anndata has less than 30 variables PR 2075 Yves33','repeat variables',0,'',''),(5584,'scanpy','Embedding plots can now pass colorbar_loc to specify the location of colorbar legend, or pass None to not show a colorbar PR 1821 A Schaar I Virshup','pass colorbar_loc for embedding plots',0,'',''),(5585,'scanpy','Embedding plots can now pass colorbar_loc to specify the location of colorbar legend, or pass None to not show a colorbar PR 1821 A Schaar I Virshup','specify location of colorbar legend',0,'',''),(5586,'scanpy','Embedding plots can now pass colorbar_loc to specify the location of colorbar legend, or pass None to not show a colorbar PR 1821 A Schaar I Virshup','pass none',0,'',''),(5587,'scanpy','Embedding plots now have a dimensions argument, which lets users select which dimensions of their embedding to plot and uses the same broadcasting rules as other arguments PR 1538 I Virshup','embed plots',0,'',''),(5588,'scanpy','Embedding plots now have a dimensions argument, which lets users select which dimensions of their embedding to plot and uses the same broadcasting rules as other arguments PR 1538 I Virshup','use same broadcasting rules as other arguments PR 1538 i virshup',0,'',''),(5589,'scanpy','Embedding plots now have a dimensions argument, which lets users select which dimensions of their embedding to plot and uses the same broadcasting rules as other arguments PR 1538 I Virshup','use argument as other arguments PR 1538 i virshup',0,'',''),(5590,'scanpy','Multiple packages have been added to our ecosystem page, including:','add multiple packages to ecosystem page',0,'',''),(5591,'scanpy','Fixed scanpy.external.pp.scrublet() to address issue 1957 FlMai and ensure raw counts are used for simulation','use fixed scanpy.external.pp.scrublet() for simulation',0,'',''),(5592,'scanpy','Functions in scanpy.datasets no longer throw OldFormatWarnings when using anndata 0.8 PR 2096 I Virshup','throw OldFormatWarnings',0,'',''),(5593,'scanpy','Functions in scanpy.datasets no longer throw OldFormatWarnings when using anndata 0.8 PR 2096 I Virshup','use anndata',0,'',''),(5594,'scanpy','Fixed use of scanpy.pp.neighbors() with method=\'rapids\': RAPIDS cuML no longer returns a squared Euclidean distance matrix, so we should not square-root the kNN distance matrix. PR 1828 M Zaslavsky','return squared Euclidean distance matrix',0,'',''),(5595,'scanpy','Removed pytables dependency by implementing read_10x_h5 with h5py due to installation errors on Windows PR 2064','implement read_10x_h5 with h5py errors',0,'',''),(5596,'scanpy','Fixed bug in scanpy.external.pp.hashsolo() where default value was set improperly PR 2190 B Reiz','set default value',0,'',''),(5597,'scanpy','Fixed bug in scanpy.pl.embedding() functions where an error could be raised when there were missing values and large numbers of categories PR 2187 I Virshup','raise error',0,'',''),(5598,'scanpy','Fixed bug in scanpy.pl.embedding() functions where an error could be raised when there were missing values and large numbers of categories PR 2187 I Virshup','raise scanpy.pl.embedding() functions',0,'',''),(5599,'scanpy','Amid & Warmuth (2019),\nTriMap: Large-scale Dimensionality Reduction Using Triplets,\narXiv.','use Triplets',0,'',''),(5600,'scanpy','Amir et al. (2013),\nviSNE enables visualization of high dimensional single-cell data and reveals phenotypic heterogeneity of leukemia,\nNature Biotechnology.','enable visualization of high dimensional single-cell data',0,'',''),(5601,'scanpy','Eraslan and Simon et al. (2018),\nSingle cell RNA-seq denoising using a deep count autoencoder,\nbioRxiv.','use deep count autoencoder',0,'',''),(5602,'scanpy','Eulenberg et al. (2017),\nReconstructing cell cycle and disease progression using deep learning\nNature Communications.','learn nature communications',0,'',''),(5603,'scanpy','Gardner et al., (2000)\nConstruction of a genetic toggle switch in Escherichia coli,\nNature.','switch  in Escherichia coli',0,'',''),(5604,'scanpy','Hagberg et al. (2008),\nExploring Network Structure, Dynamics, and Function using NetworkX,\nScipy Conference.','use networkx',0,'',''),(5605,'scanpy','Haghverdi et al. (2018),\nBatch effects in single-cell RNA-sequencing data are corrected by matching mutual nearest neighbors,\nNature Biotechnology.','match mutual nearest neighbors',0,'',''),(5606,'scanpy','Hie et al. (2019),\nEfficient integration of heterogeneous single-cell transcriptomes using Scanorama,\nNature Biotechnology.','use Scanorama',0,'',''),(5607,'scanpy','Johnson, Li & Rabinovic (2007),\nAdjusting batch effects in microarray expression data using empirical Bayes methods,\nBiostatistics.','adjust batch effects in microarray expression data',0,'',''),(5608,'scanpy','Johnson, Li & Rabinovic (2007),\nAdjusting batch effects in microarray expression data using empirical Bayes methods,\nBiostatistics.','use empirical Bayes methods',0,'',''),(5609,'scanpy','Van Dijk D et al. (2018),\nRecovering Gene Interactions from Single-Cell Data Using Data Diffusion,\nCell.','use Data diffusion',0,'',''),(5610,'scanpy','where adata is an AnnData object.\nEach of these calls adds annotation to an expression matrix X,\nwhich stores n_obs observations (cells) of n_vars variables (genes).\nFor each tool, there typically is an associated plotting function in sc.pl:','add annotation to expression matrix x',1,'https://scanpy.readthedocs.io/en/stable/usage-principles.html',''),(5611,'scanpy','where adata is an AnnData object.\nEach of these calls adds annotation to an expression matrix X,\nwhich stores n_obs observations (cells) of n_vars variables (genes).\nFor each tool, there typically is an associated plotting function in sc.pl:','store n_obs observations of n_vars variables',1,'https://scanpy.readthedocs.io/en/stable/usage-principles.html',''),(5612,'scanpy','where adata is an AnnData object.\nEach of these calls adds annotation to an expression matrix X,\nwhich stores n_obs observations (cells) of n_vars variables (genes).\nFor each tool, there typically is an associated plotting function in sc.pl:','store expression matrix x of n_vars variables',1,'https://scanpy.readthedocs.io/en/stable/usage-principles.html',''),(5613,'scanpy','If you pass show=False, a Axes instance is returned\nand you have all of matplotlib’s detailed configuration possibilities.','return axes instance',0,'',''),(5614,'scanpy','To facilitate writing memory-efficient pipelines, by default,\nScanpy tools operate inplace on adata and return None –\nthis also allows to easily transition to out-of-memory pipelines.\nIf you want to return a copy of the AnnData object\nand leave the passed adata unchanged, pass copy=True or inplace=False.','write memory-efficient pipelines',0,'',''),(5615,'scanpy','To facilitate writing memory-efficient pipelines, by default,\nScanpy tools operate inplace on adata and return None –\nthis also allows to easily transition to out-of-memory pipelines.\nIf you want to return a copy of the AnnData object\nand leave the passed adata unchanged, pass copy=True or inplace=False.','return copy of AnnData object',0,'',''),(5616,'scanpy','Scanpy is based on anndata, which provides the AnnData class.','provide AnnData class',0,'',''),(5617,'scanpy','Scanpy is based on anndata, which provides the AnnData class.','provide anndata',0,'',''),(5618,'scanpy','At the most basic level, an AnnData object adata stores\na data matrix adata.X, annotation of observations\nadata.obs and variables adata.var as pd.DataFrame and unstructured\nannotation adata.uns as dict. Names of observations and\nvariables can be accessed via adata.obs_names and adata.var_names,\nrespectively. AnnData objects can be sliced like\ndataframes, for example, adata_subset = adata[:, list_of_gene_names].\nFor more, see this blog post.','access names of observations',0,'',''),(5619,'scanpy','At the most basic level, an AnnData object adata stores\na data matrix adata.X, annotation of observations\nadata.obs and variables adata.var as pd.DataFrame and unstructured\nannotation adata.uns as dict. Names of observations and\nvariables can be accessed via adata.obs_names and adata.var_names,\nrespectively. AnnData objects can be sliced like\ndataframes, for example, adata_subset = adata[:, list_of_gene_names].\nFor more, see this blog post.','access names of variables',0,'',''),(5620,'scanpy','At the most basic level, an AnnData object adata stores\na data matrix adata.X, annotation of observations\nadata.obs and variables adata.var as pd.DataFrame and unstructured\nannotation adata.uns as dict. Names of observations and\nvariables can be accessed via adata.obs_names and adata.var_names,\nrespectively. AnnData objects can be sliced like\ndataframes, for example, adata_subset = adata[:, list_of_gene_names].\nFor more, see this blog post.','access names via adata.obs_names',0,'',''),(5621,'scanpy','At the most basic level, an AnnData object adata stores\na data matrix adata.X, annotation of observations\nadata.obs and variables adata.var as pd.DataFrame and unstructured\nannotation adata.uns as dict. Names of observations and\nvariables can be accessed via adata.obs_names and adata.var_names,\nrespectively. AnnData objects can be sliced like\ndataframes, for example, adata_subset = adata[:, list_of_gene_names].\nFor more, see this blog post.','access names via adata.var_names',0,'',''),(5622,'scanpy','To read a data file to an AnnData object, call:','read data file to AnnData object',1,'https://scanpy.readthedocs.io/en/stable/usage-principles.html',''),(5623,'scanpy','to initialize an AnnData object. Possibly add further annotation using, e.g., pd.read_csv:','initialize AnnData',1,'https://scanpy.readthedocs.io/en/stable/usage-principles.html',''),(5624,'scanpy','to initialize an AnnData object. Possibly add further annotation using, e.g., pd.read_csv:','add further annotation',1,'https://scanpy.readthedocs.io/en/stable/usage-principles.html',''),(5625,'scanpy','Genome Biology: Celebrating 20 Years of Genome Biology selected the initial Scanpy paper for the year 2018 among 20 papers for 20 years [tweet].','select initial Scanpy paper among papers',0,'',''),(5626,'scanpy','Genome Biology: Celebrating 20 Years of Genome Biology selected the initial Scanpy paper for the year 2018 among 20 papers for 20 years [tweet].','select initial Scanpy paper for year',0,'',''),(5627,'scanpy','In a joint initiative, the Wellcome Sanger Institute, the Human Cell Atlas, and the CZI distribute datasets related to COVID-19 via anndata’s h5ad files: covid19cellatlas.org. It wasn’t anticipated that the initial idea of sharing and backing an on-disk representation of AnnData would become so widely adopted. Curious? Read up more on the format.','share on-disk representation of AnnData',0,'',''),(5628,'scanpy','In a joint initiative, the Wellcome Sanger Institute, the Human Cell Atlas, and the CZI distribute datasets related to COVID-19 via anndata’s h5ad files: covid19cellatlas.org. It wasn’t anticipated that the initial idea of sharing and backing an on-disk representation of AnnData would become so widely adopted. Curious? Read up more on the format.','read  on format',0,'',''),(5629,'scanpy','Single-cell RNA-seq analysis software providers scramble to offer solutions mentions Scanpy along with Seurat as the two major open source software packages for single-cell analysis [pdf].','offer solutions',0,'',''),(5630,'scanpy','Scanpy has been selected an essential open source software for science by\nCZI among 32 projects, along with giants such as Scipy, Numpy, Pandas,\nMatplotlib, scikit-learn, scikit-image/plotly, pip, jupyterhub/binder,\nBioconda, Seurat, Bioconductor, and others.','select essential open source software among projects',0,'',''),(5631,'scanpy','Scanpy has been selected an essential open source software for science by\nCZI among 32 projects, along with giants such as Scipy, Numpy, Pandas,\nMatplotlib, scikit-learn, scikit-image/plotly, pip, jupyterhub/binder,\nBioconda, Seurat, Bioconductor, and others.','select essential open source software among others',0,'',''),(5632,'scanpy','Scanpy has been selected an essential open source software for science by\nCZI among 32 projects, along with giants such as Scipy, Numpy, Pandas,\nMatplotlib, scikit-learn, scikit-image/plotly, pip, jupyterhub/binder,\nBioconda, Seurat, Bioconductor, and others.','select essential open source software for science',0,'',''),(5633,'scanpy','Scanpy has been selected an essential open source software for science by\nCZI among 32 projects, along with giants such as Scipy, Numpy, Pandas,\nMatplotlib, scikit-learn, scikit-image/plotly, pip, jupyterhub/binder,\nBioconda, Seurat, Bioconductor, and others.','select scanpy among projects',0,'',''),(5634,'scanpy','Scanpy has been selected an essential open source software for science by\nCZI among 32 projects, along with giants such as Scipy, Numpy, Pandas,\nMatplotlib, scikit-learn, scikit-image/plotly, pip, jupyterhub/binder,\nBioconda, Seurat, Bioconductor, and others.','select scanpy among others',0,'',''),(5635,'scanpy','Scanpy has been selected an essential open source software for science by\nCZI among 32 projects, along with giants such as Scipy, Numpy, Pandas,\nMatplotlib, scikit-learn, scikit-image/plotly, pip, jupyterhub/binder,\nBioconda, Seurat, Bioconductor, and others.','select scanpy for science',0,'',''),(5636,'scanpy','More tools that integrate well with scanpy and anndata can be found on the ecosystem page.','integrate more tools with scanpy',0,'',''),(5637,'scanpy','More tools that integrate well with scanpy and anndata can be found on the ecosystem page.','integrate more tools with anndata',0,'',''),(5638,'scanpy','More tools that integrate well with scanpy and anndata can be found on the ecosystem page.','find more tools on ecosystem page',0,'',''),(5639,'scanpy','If you’d like to include a tool here, consider making a pull request (instructions).\nIf the tool already uses scanpy or anndata, it may fit better in the ecosystem page.','include tool',0,'',''),(5640,'scanpy','If you’d like to include a tool here, consider making a pull request (instructions).\nIf the tool already uses scanpy or anndata, it may fit better in the ecosystem page.','use scanpy',0,'',''),(5641,'scanpy','If you’d like to include a tool here, consider making a pull request (instructions).\nIf the tool already uses scanpy or anndata, it may fit better in the ecosystem page.','use anndata',0,'',''),(5642,'scanpy','If you’d like to include a tool here, consider making a pull request (instructions).\nIf the tool already uses scanpy or anndata, it may fit better in the ecosystem page.','fit  in ecosystem page',0,'',''),(5643,'scanpy','Use harmonypy [Korunsky19] to integrate different experiments.','integrate different experiments',0,'',''),(5644,'scanpy','Correct batch effects by matching mutual nearest neighbors [Haghverdi18] [Kang18].','match mutual nearest neighbors',0,'',''),(5645,'scanpy','Use Scanorama [Hie19] to integrate different experiments.','integrate different experiments',0,'',''),(5646,'scanpy','Simulate doublets by adding the counts of random observed transcriptome pairs.','add counts of observed transcriptome pairs',0,'',''),(5647,'scanpy','Probabilistic demultiplexing of cell hashing data using HashSolo [Bernstein20].','use HashSolo  bernstein20',0,'',''),(5648,'scanpy','Run Diffusion maps using the adaptive anisotropic kernel [Setty18].','use adaptive anisotropic kernel',0,'',''),(5649,'scanpy','TriMap: Large-scale Dimensionality Reduction Using Triplets [Amid19].','use Triplets  amid19',0,'',''),(5650,'scanpy','Running Palantir','run Palantir',0,'',''),(5651,'scanpy','Scatter plot using the SAM projection or another input projection.','use SAM projection',0,'',''),(5652,'scanpy','Scatter plot using the SAM projection or another input projection.','use input projection',0,'',''),(5653,'scanpy','Plot marker trends along trajectory, and return trajectory branches for further analysis and visualization (heatmap, etc..)','return trajectory branches for further analysis',0,'',''),(5654,'scanpy','Plot marker trends along trajectory, and return trajectory branches for further analysis and visualization (heatmap, etc..)','return trajectory branches for visualization',0,'',''),(5655,'scanpy','The scverse Discourse forum is place to go to ask usage questions and for longer form discussions around the project.','ask usage questions',0,'',''),(5656,'scanpy','Additional functionality is available in the broader ecosystem, with some tools being wrapped in the scanpy.external module.','wrap  in scanpy.external module',0,'',''),(5657,'scanpy','Any transformation of the data matrix that is not a tool. Other than tools, preprocessing steps usually don’t return an easily interpretable annotation, but perform a basic transformation on the data matrix.','return interpretable annotation',0,'',''),(5658,'scanpy','Any transformation of the data matrix that is not a tool. Other than tools, preprocessing steps usually don’t return an easily interpretable annotation, but perform a basic transformation on the data matrix.','perform basic transformation on data matrix',0,'',''),(5659,'scanpy','Calculate quality control metrics.','calculate quality control metrics',0,'',''),(5660,'scanpy','Normalize counts per cell.','count  per cell',0,'',''),(5661,'scanpy','Downsample counts from count matrix.','count  from count matrix',0,'',''),(5662,'scanpy','Compute a neighborhood graph of observations [McInnes18].','compute neighborhood graph of observations  mcinnes18',0,'',''),(5663,'scanpy','Any transformation of the data matrix that is not preprocessing. In contrast to a preprocessing function, a tool usually adds an easily interpretable annotation to the data matrix, which can then be visualized with a corresponding plotting function.','add interpretable annotation in contrast',0,'',''),(5664,'scanpy','Any transformation of the data matrix that is not preprocessing. In contrast to a preprocessing function, a tool usually adds an easily interpretable annotation to the data matrix, which can then be visualized with a corresponding plotting function.','add interpretable annotation to data matrix',0,'',''),(5665,'scanpy','Embed the neighborhood graph using UMAP [McInnes18].','embed neighborhood graph',0,'',''),(5666,'scanpy','Embed the neighborhood graph using UMAP [McInnes18].','use UMAP  mcinnes18',0,'',''),(5667,'scanpy','Calculate the density of cells in an embedding (per condition).','calculate density of cells',0,'',''),(5668,'scanpy','Computes a hierarchical clustering for the given groupby categories.','compute hierarchical clustering for given groupby categories',0,'',''),(5669,'scanpy','Calculate an overlap score between data-deriven marker genes and provided markers','calculate overlap score between data-deriven marker genes',0,'',''),(5670,'scanpy','Calculate an overlap score between data-deriven marker genes and provided markers','provide markers',0,'',''),(5671,'scanpy','The plotting module scanpy.pl largely parallels the tl.* and a few of the pp.* functions.\nFor most tools and for some preprocessing functions, you’ll find a plotting function with the same name.','find plotting function with same name',0,'',''),(5672,'scanpy','See → tutorial: plotting/core for an overview of how to use these functions.','use functions',0,'',''),(5673,'scanpy','Creates a heatmap of the mean expression values per group of each var_names.','create heatmap of mean expression values',0,'',''),(5674,'scanpy','Plots a dendrogram of the categories defined in groupby.','define  in groupby',0,'',''),(5675,'scanpy','Allows the visualization of two values that are encoded as dot size and color.','encode values as dot size',0,'',''),(5676,'scanpy','Allows the visualization of two values that are encoded as dot size and color.','encode values as color',0,'',''),(5677,'scanpy','Allows the visualization of values using a color map.','use color map',0,'',''),(5678,'scanpy','Fraction of counts assigned to each gene over all cells.','assign  to gene',0,'',''),(5679,'scanpy','Visualize clusters using one of the embedding methods passing color=\'louvain\'.','pass louvain',0,'',''),(5680,'scanpy','Plot ranking of genes for all tested comparisons.','test comparisons',0,'',''),(5681,'scanpy','Plot ranking of genes using stacked_violin plot (see stacked_violin())','use stacked_violin plot',0,'',''),(5682,'scanpy','Plot ranking of genes using heatmap plot (see heatmap())','use heatmap plot',0,'',''),(5683,'scanpy','Plot ranking of genes using dotplot plot (see dotplot())','use dotplot plot',0,'',''),(5684,'scanpy','Plot ranking of genes using matrixplot plot (see matrixplot())','use matrixplot plot',0,'',''),(5685,'scanpy','For reading annotation use pandas.read_…\nand add it to your anndata.AnnData object. The following read functions are\nintended for the numeric data in the data matrix X.','use pandas.read_â¦ for reading',0,'',''),(5686,'scanpy','For reading annotation use pandas.read_…\nand add it to your anndata.AnnData object. The following read functions are\nintended for the numeric data in the data matrix X.','add  to anndata.AnnData object',0,'',''),(5687,'scanpy','Read common file formats using','read common file formats',0,'',''),(5688,'scanpy','Read 10x formatted hdf5 files and directories containing .mtx files using','format hdf5 files',0,'',''),(5689,'scanpy','Read 10x formatted hdf5 files and directories containing .mtx files using','format directories',0,'',''),(5690,'scanpy','Read 10x-Genomics-formatted hdf5 file.','read 10x-genomics-formatted hdf5 file',0,'',''),(5691,'scanpy','Read 10x-Genomics-formatted mtx directory.','read 10x-genomics-formatted mtx directory',0,'',''),(5692,'scanpy','Read 10x-Genomics-formatted visum dataset.','read 10x-genomics-formatted visum dataset',0,'',''),(5693,'scanpy','Read other formats using functions borrowed from anndata','read other formats',0,'',''),(5694,'scanpy','Read other formats using functions borrowed from anndata','use functions',0,'',''),(5695,'scanpy','Read .h5ad-formatted hdf5 file.','format hdf5 file',0,'',''),(5696,'scanpy','Read .loom-formatted hdf5 file.','format hdf5 file',0,'',''),(5697,'scanpy','Read a gzipped condensed count matrix from umi_tools.','read gzipped condensed count matrix from umi_tools',0,'',''),(5698,'scanpy','The module sc.get provides convenience functions for getting values back in\nuseful formats.','provide convenience functions for getting',0,'',''),(5699,'scanpy','This module provides useful queries for annotation and enrichment.','provide useful queries for annotation',0,'',''),(5700,'scanpy','This module provides useful queries for annotation and enrichment.','provide useful queries for enrichment',0,'',''),(5701,'scanpy','Get enrichment for DE results.','get enrichment for DE results',0,'',''),(5702,'scanpy','Given an original and new set of labels, create a labelled confusion matrix.','create labelled confusion matrix',0,'',''),(5703,'scanpy','Calculate Geary\'s C, as used by VISION.','use  by VISION',0,'',''),(5704,'scanpy','Select highly variable genes using analytic Pearson residuals [Lause21].','use analytic Pearson residuals',0,'',''),(5705,'scanpy','Set resolution/size, styling and format of figures.','set resolution/size of figures',0,'',''),(5706,'scanpy','Set resolution/size, styling and format of figures.','set styling of figures',0,'',''),(5707,'scanpy','Set resolution/size, styling and format of figures.','set format of figures',0,'',''),(5708,'scanpy','An instance of the ScanpyConfig is available as scanpy.settings and allows configuring Scanpy.','configure scanpy',0,'',''),(5709,'scanpy','Influence the global behavior of plotting functions. In non-interactive scripts,\nyou’d usually want to set settings.autoshow to False.','set settings.autoshow to false',0,'',''),(5710,'scanpy','Automatically save figures in figdir (default False).','save figures in figdir',0,'',''),(5711,'scanpy','The default directories for saving figures, caching files and storing datasets.','save figures',0,'',''),(5712,'scanpy','The default directories for saving figures, caching files and storing datasets.','store figures',0,'',''),(5713,'scanpy','The default directories for saving figures, caching files and storing datasets.','cache files',0,'',''),(5714,'scanpy','Load a dataset from the EBI Single Cell Expression Atlas','load dataset expression Atlas',0,'',''),(5715,'scanpy','PASTE is a computational method to align and integrate spatial transcriptomics data across adjacent tissue slices by leveraging both gene expression similarity and spatial distances between spots.','align spatial transcriptomics data across adjacent tissue slices',0,'',''),(5716,'scanpy','PASTE is a computational method to align and integrate spatial transcriptomics data across adjacent tissue slices by leveraging both gene expression similarity and spatial distances between spots.','align spatial transcriptomics data by leveraging',0,'',''),(5717,'scanpy','PASTE is a computational method to align and integrate spatial transcriptomics data across adjacent tissue slices by leveraging both gene expression similarity and spatial distances between spots.','integrate spatial transcriptomics data across adjacent tissue slices',0,'',''),(5718,'scanpy','PASTE is a computational method to align and integrate spatial transcriptomics data across adjacent tissue slices by leveraging both gene expression similarity and spatial distances between spots.','integrate spatial transcriptomics data by leveraging',0,'',''),(5719,'scanpy','MUON, and it’s associated data structure MuData are designed to organise, analyse, visualise, and exchange multimodal data.\nMUON enables a range of analyses for ATAC and CITE-seq, from data preprocessing to flexible multi-omics alignment.','design MUON',0,'',''),(5720,'scanpy','MUON, and it’s associated data structure MuData are designed to organise, analyse, visualise, and exchange multimodal data.\nMUON enables a range of analyses for ATAC and CITE-seq, from data preprocessing to flexible multi-omics alignment.','design associated data structure MuData',0,'',''),(5721,'scanpy','MUON, and it’s associated data structure MuData are designed to organise, analyse, visualise, and exchange multimodal data.\nMUON enables a range of analyses for ATAC and CITE-seq, from data preprocessing to flexible multi-omics alignment.','enable range of analyses',0,'',''),(5722,'scanpy','MUON, and it’s associated data structure MuData are designed to organise, analyse, visualise, and exchange multimodal data.\nMUON enables a range of analyses for ATAC and CITE-seq, from data preprocessing to flexible multi-omics alignment.','enable range from data',0,'',''),(5723,'scanpy','dandelion is a single-cell BCR-seq network analysis package that integrates with transcriptomic data analyzed via scanpy.','integrate single-cell BCR-seq network analysis package with transcriptomic data',0,'',''),(5724,'scanpy','Swan is a Python library designed for the analysis and visualization of transcriptomes, especially with long-read transcriptomes in mind.\nUsers can add transcriptomes from different datasets and explore distinct splicing and expression patterns across datasets.','design  with long-read transcriptomes',0,'',''),(5725,'scanpy','Swan is a Python library designed for the analysis and visualization of transcriptomes, especially with long-read transcriptomes in mind.\nUsers can add transcriptomes from different datasets and explore distinct splicing and expression patterns across datasets.','design  for analysis',0,'',''),(5726,'scanpy','Swan is a Python library designed for the analysis and visualization of transcriptomes, especially with long-read transcriptomes in mind.\nUsers can add transcriptomes from different datasets and explore distinct splicing and expression patterns across datasets.','design  for visualization',0,'',''),(5727,'scanpy','Swan is a Python library designed for the analysis and visualization of transcriptomes, especially with long-read transcriptomes in mind.\nUsers can add transcriptomes from different datasets and explore distinct splicing and expression patterns across datasets.','add transcriptomes from different datasets',0,'',''),(5728,'scanpy','scvi-tools hosts deep generative models (DGM) for end-to-end analysis of single-cell\nomics data (e.g., scVI, scANVI, totalVI). It also contains several primitives to build novel DGMs.','host deep generative models for end-to-end analysis',0,'',''),(5729,'scanpy','Analyses using curated prior knowledge','use curated prior knowledge',0,'',''),(5730,'scanpy','Intuitive Nonparametric Gene Network Search Algorithm that learns from existing biological pathways & multiplicative gene interference patterns.','learn intuitive nonparametric Gene network Search algorithm from existing biological pathways',0,'',''),(5731,'PyOpenGL','OpenGL under Python is largely the same as OpenGL under most\nother languages, so you can use much of             the documentation\nyou\'ll find around the Internet, or in your local bookstore.  This\npage primarily provides links to PyOpenGL-specific documentation.\n Users of OpenGLContext should also see the OpenGLContext\ndocumentation page.','find documentation in local bookstore',0,'',''),(5732,'PyOpenGL','OpenGL under Python is largely the same as OpenGL under most\nother languages, so you can use much of             the documentation\nyou\'ll find around the Internet, or in your local bookstore.  This\npage primarily provides links to PyOpenGL-specific documentation.\n Users of OpenGLContext should also see the OpenGLContext\ndocumentation page.','find documentation around internet',0,'',''),(5733,'PyOpenGL','OpenGL under Python is largely the same as OpenGL under most\nother languages, so you can use much of             the documentation\nyou\'ll find around the Internet, or in your local bookstore.  This\npage primarily provides links to PyOpenGL-specific documentation.\n Users of OpenGLContext should also see the OpenGLContext\ndocumentation page.','provide links to pyopengl-specific documentation',0,'',''),(5734,'PyOpenGL','There\nare a large number of very good books on OpenGL available. Many\nof these books cover \"legacy\" OpenGL, rather than the\nshader/buffer/texture model of OpenGL 3.0. Still, they provide a\ngood grounding that allows you to learn the basics of OpenGL.','provide good grounding',0,'',''),(5735,'PyOpenGL','There\nare a large number of very good books on OpenGL available. Many\nof these books cover \"legacy\" OpenGL, rather than the\nshader/buffer/texture model of OpenGL 3.0. Still, they provide a\ngood grounding that allows you to learn the basics of OpenGL.','learn basics of OpenGL',0,'',''),(5736,'PyOpenGL','Older versions of the official OpenGL Programming Guide, a.k.a\n\"The Red Book\" are available online in various\nplaces (version 2.0 covers OpenGL 1.1). If you are serious about\nlearning OpenGL, the newer versions of the Red Book, (v3.0) is likely on\nthe shelves of your local bookstore, and is quite readable.','learn OpenGL',0,'',''),(5737,'PyOpenGL','You\'ll find versions of some of the Red Book tutorial code for\nPython included in the PyOpenGL-Demo/redbook directory of the PyOpenGL-Demo\ndistribution. These versions are very close to the original source\ncode. The OpenGLContext tests directory also has four of the\ntutorials converted, \"alpha\", \"alpha3D\", \"surface\" and \"trim\".','find versions for Python',0,'',''),(5738,'PyOpenGL','You\'ll find versions of some of the Red Book tutorial code for\nPython included in the PyOpenGL-Demo/redbook directory of the PyOpenGL-Demo\ndistribution. These versions are very close to the original source\ncode. The OpenGLContext tests directory also has four of the\ntutorials converted, \"alpha\", \"alpha3D\", \"surface\" and \"trim\".','include  in pyopengl-demo/redbook directory',0,'',''),(5739,'PyOpenGL','This\nbook serves as a good introduction to shaders. The shaders\ndescribed cover the gamut from the simplest 1-line shaders through code\nto emulate legacy operation to non-realistic shading to caustics and\nthe like. You will generally have to adapt any code you take from\nhere to work with your real-world scenes, but the book offers a strong\ngrounding.','offer strong grounding',0,'',''),(5740,'PyOpenGL','When people think of an \"OpenGL tutorial\", many will\nimmediately think of the NeHe tutorials by Jeff Molofee, available at http://nehe.gamedev.net/\nthese\ntutorials range from the very simple (create an OpenGL window) through\nthe advanced (particle systems, loading scenes from various formats,\ndisplaying video textures, text, morphing, multi-texturing). The\nolder tutorials tend to be legacy-mode operations, so you should keep\nin mind that they are describing old ways of working as you learn with\nthem.','describe old ways of working',0,'',''),(5741,'PyOpenGL','If you have a PyOpenGL-specific tutorial you\'d like added to this area, please post to the PyOpenGL-user\'s mailing list.','add  to area',0,'',''),(5742,'PyOpenGL','Bug reports and feature requests should use the SourceForge project\npage. General questions, including most programming questions\nare best answered on the PyOpenGL mailing list.\nQuestions regarding project administration, or development can use the PyOpenGL-devel\nmailing list.','use SourceForge project page',0,'',''),(5743,'PyOpenGL','Bug reports and feature requests should use the SourceForge project\npage. General questions, including most programming questions\nare best answered on the PyOpenGL mailing list.\nQuestions regarding project administration, or development can use the PyOpenGL-devel\nmailing list.','use pyopengl-devel mailing list',0,'',''),(5744,'numpy','NumPy (Numerical Python) is an open source Python library that’s used in\nalmost every field of science and engineering. It’s the universal standard for\nworking with numerical data in Python, and it’s at the core of the scientific\nPython and PyData ecosystems. NumPy users include everyone from beginning coders\nto experienced researchers doing state-of-the-art scientific and industrial\nresearch and development. The NumPy API is used extensively in Pandas, SciPy,\nMatplotlib, scikit-learn, scikit-image and most other data science and\nscientific Python packages.','use open source Python library in field',0,'',''),(5745,'numpy','NumPy (Numerical Python) is an open source Python library that’s used in\nalmost every field of science and engineering. It’s the universal standard for\nworking with numerical data in Python, and it’s at the core of the scientific\nPython and PyData ecosystems. NumPy users include everyone from beginning coders\nto experienced researchers doing state-of-the-art scientific and industrial\nresearch and development. The NumPy API is used extensively in Pandas, SciPy,\nMatplotlib, scikit-learn, scikit-image and most other data science and\nscientific Python packages.','include everyone from beginning',0,'',''),(5746,'numpy','NumPy (Numerical Python) is an open source Python library that’s used in\nalmost every field of science and engineering. It’s the universal standard for\nworking with numerical data in Python, and it’s at the core of the scientific\nPython and PyData ecosystems. NumPy users include everyone from beginning coders\nto experienced researchers doing state-of-the-art scientific and industrial\nresearch and development. The NumPy API is used extensively in Pandas, SciPy,\nMatplotlib, scikit-learn, scikit-image and most other data science and\nscientific Python packages.','use NumPy API in scikit-image',0,'',''),(5747,'numpy','NumPy (Numerical Python) is an open source Python library that’s used in\nalmost every field of science and engineering. It’s the universal standard for\nworking with numerical data in Python, and it’s at the core of the scientific\nPython and PyData ecosystems. NumPy users include everyone from beginning coders\nto experienced researchers doing state-of-the-art scientific and industrial\nresearch and development. The NumPy API is used extensively in Pandas, SciPy,\nMatplotlib, scikit-learn, scikit-image and most other data science and\nscientific Python packages.','use NumPy API in other data science',0,'',''),(5748,'numpy','NumPy (Numerical Python) is an open source Python library that’s used in\nalmost every field of science and engineering. It’s the universal standard for\nworking with numerical data in Python, and it’s at the core of the scientific\nPython and PyData ecosystems. NumPy users include everyone from beginning coders\nto experienced researchers doing state-of-the-art scientific and industrial\nresearch and development. The NumPy API is used extensively in Pandas, SciPy,\nMatplotlib, scikit-learn, scikit-image and most other data science and\nscientific Python packages.','use NumPy API in pandas',0,'',''),(5749,'numpy','NumPy (Numerical Python) is an open source Python library that’s used in\nalmost every field of science and engineering. It’s the universal standard for\nworking with numerical data in Python, and it’s at the core of the scientific\nPython and PyData ecosystems. NumPy users include everyone from beginning coders\nto experienced researchers doing state-of-the-art scientific and industrial\nresearch and development. The NumPy API is used extensively in Pandas, SciPy,\nMatplotlib, scikit-learn, scikit-image and most other data science and\nscientific Python packages.','use NumPy API in SciPy',0,'',''),(5750,'numpy','NumPy (Numerical Python) is an open source Python library that’s used in\nalmost every field of science and engineering. It’s the universal standard for\nworking with numerical data in Python, and it’s at the core of the scientific\nPython and PyData ecosystems. NumPy users include everyone from beginning coders\nto experienced researchers doing state-of-the-art scientific and industrial\nresearch and development. The NumPy API is used extensively in Pandas, SciPy,\nMatplotlib, scikit-learn, scikit-image and most other data science and\nscientific Python packages.','use NumPy API in matplotlib',0,'',''),(5751,'numpy','NumPy (Numerical Python) is an open source Python library that’s used in\nalmost every field of science and engineering. It’s the universal standard for\nworking with numerical data in Python, and it’s at the core of the scientific\nPython and PyData ecosystems. NumPy users include everyone from beginning coders\nto experienced researchers doing state-of-the-art scientific and industrial\nresearch and development. The NumPy API is used extensively in Pandas, SciPy,\nMatplotlib, scikit-learn, scikit-image and most other data science and\nscientific Python packages.','use NumPy API in scikit-learn',0,'',''),(5752,'numpy','The NumPy library contains multidimensional array and matrix data structures\n(you’ll find more information about this in later sections). It provides\nndarray, a homogeneous n-dimensional array object, with methods to\nefficiently operate on it. NumPy can be used to perform a wide variety of\nmathematical operations on arrays.  It adds powerful data structures to Python\nthat guarantee efficient calculations with arrays and matrices and it supplies\nan enormous library of high-level mathematical functions that operate on these\narrays and matrices.','provide ndarray with methods',0,'',''),(5753,'numpy','The NumPy library contains multidimensional array and matrix data structures\n(you’ll find more information about this in later sections). It provides\nndarray, a homogeneous n-dimensional array object, with methods to\nefficiently operate on it. NumPy can be used to perform a wide variety of\nmathematical operations on arrays.  It adds powerful data structures to Python\nthat guarantee efficient calculations with arrays and matrices and it supplies\nan enormous library of high-level mathematical functions that operate on these\narrays and matrices.','perform wide variety of mathematical operations',0,'',''),(5754,'numpy','The NumPy library contains multidimensional array and matrix data structures\n(you’ll find more information about this in later sections). It provides\nndarray, a homogeneous n-dimensional array object, with methods to\nefficiently operate on it. NumPy can be used to perform a wide variety of\nmathematical operations on arrays.  It adds powerful data structures to Python\nthat guarantee efficient calculations with arrays and matrices and it supplies\nan enormous library of high-level mathematical functions that operate on these\narrays and matrices.','perform wide variety on arrays',0,'',''),(5755,'numpy','The NumPy library contains multidimensional array and matrix data structures\n(you’ll find more information about this in later sections). It provides\nndarray, a homogeneous n-dimensional array object, with methods to\nefficiently operate on it. NumPy can be used to perform a wide variety of\nmathematical operations on arrays.  It adds powerful data structures to Python\nthat guarantee efficient calculations with arrays and matrices and it supplies\nan enormous library of high-level mathematical functions that operate on these\narrays and matrices.','use NumPy',0,'',''),(5756,'numpy','The NumPy library contains multidimensional array and matrix data structures\n(you’ll find more information about this in later sections). It provides\nndarray, a homogeneous n-dimensional array object, with methods to\nefficiently operate on it. NumPy can be used to perform a wide variety of\nmathematical operations on arrays.  It adds powerful data structures to Python\nthat guarantee efficient calculations with arrays and matrices and it supplies\nan enormous library of high-level mathematical functions that operate on these\narrays and matrices.','add powerful data structures to Python',0,'',''),(5757,'numpy','To install NumPy, we strongly recommend using a scientific Python distribution.\nIf you’re looking for the full instructions for installing NumPy on your\noperating system, see Installing NumPy.','install NumPy',0,'',''),(5758,'numpy','To install NumPy, we strongly recommend using a scientific Python distribution.\nIf you’re looking for the full instructions for installing NumPy on your\noperating system, see Installing NumPy.','use scientific Python distribution',0,'',''),(5759,'numpy','To install NumPy, we strongly recommend using a scientific Python distribution.\nIf you’re looking for the full instructions for installing NumPy on your\noperating system, see Installing NumPy.','install NumPy on operating system',0,'',''),(5760,'numpy','If you already have Python, you can install NumPy with:','install NumPy',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5761,'numpy','If you don’t have Python yet, you might want to consider using Anaconda. It’s the easiest way to get started. The good\nthing about getting this distribution is the fact that you don’t need to worry\ntoo much about separately installing NumPy or any of the major packages that\nyou’ll be using for your data analyses, like pandas, Scikit-Learn, etc.','use anaconda',0,'',''),(5762,'numpy','If you don’t have Python yet, you might want to consider using Anaconda. It’s the easiest way to get started. The good\nthing about getting this distribution is the fact that you don’t need to worry\ntoo much about separately installing NumPy or any of the major packages that\nyou’ll be using for your data analyses, like pandas, Scikit-Learn, etc.','get distribution',0,'',''),(5763,'numpy','If you don’t have Python yet, you might want to consider using Anaconda. It’s the easiest way to get started. The good\nthing about getting this distribution is the fact that you don’t need to worry\ntoo much about separately installing NumPy or any of the major packages that\nyou’ll be using for your data analyses, like pandas, Scikit-Learn, etc.','install NumPy of major packages',0,'',''),(5764,'numpy','If you don’t have Python yet, you might want to consider using Anaconda. It’s the easiest way to get started. The good\nthing about getting this distribution is the fact that you don’t need to worry\ntoo much about separately installing NumPy or any of the major packages that\nyou’ll be using for your data analyses, like pandas, Scikit-Learn, etc.','use  for data analyses',0,'',''),(5765,'numpy','To access NumPy and its functions import it in your Python code like this:','import  in Python code',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5766,'numpy','To access NumPy and its functions import it in your Python code like this:','import  to access NumPy',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5767,'numpy','To access NumPy and its functions import it in your Python code like this:','import  to functions',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5768,'numpy','We shorten the imported name to np for better readability of code using\nNumPy. This is a widely adopted convention that you should follow so that\nanyone working with your code can easily understand it.','shorten imported name to np',0,'',''),(5769,'numpy','We shorten the imported name to np for better readability of code using\nNumPy. This is a widely adopted convention that you should follow so that\nanyone working with your code can easily understand it.','use NumPy',0,'',''),(5770,'numpy','If you aren’t already comfortable with reading tutorials that contain a lot of code,\nyou might not know how to interpret a code block that looks\nlike this:','read tutorials',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5771,'numpy','If you aren’t familiar with this style, it’s very easy to understand.\nIf you see >>>, you’re looking at input, or the code that\nyou would enter. Everything that doesn’t have >>> in front of it\nis output, or the results of running your code. This is the style\nyou see when you run python on the command line, but if you’re using\nIPython, you might see a different style. Note that it is not part of the\ncode and will cause an error if typed or pasted into the Python\nshell. It can be safely typed or pasted into the IPython shell; the >>>\nis ignored.','run code',0,'',''),(5772,'numpy','If you aren’t familiar with this style, it’s very easy to understand.\nIf you see >>>, you’re looking at input, or the code that\nyou would enter. Everything that doesn’t have >>> in front of it\nis output, or the results of running your code. This is the style\nyou see when you run python on the command line, but if you’re using\nIPython, you might see a different style. Note that it is not part of the\ncode and will cause an error if typed or pasted into the Python\nshell. It can be safely typed or pasted into the IPython shell; the >>>\nis ignored.','run python on command line',0,'',''),(5773,'numpy','If you aren’t familiar with this style, it’s very easy to understand.\nIf you see >>>, you’re looking at input, or the code that\nyou would enter. Everything that doesn’t have >>> in front of it\nis output, or the results of running your code. This is the style\nyou see when you run python on the command line, but if you’re using\nIPython, you might see a different style. Note that it is not part of the\ncode and will cause an error if typed or pasted into the Python\nshell. It can be safely typed or pasted into the IPython shell; the >>>\nis ignored.','use ipython',0,'',''),(5774,'numpy','If you aren’t familiar with this style, it’s very easy to understand.\nIf you see >>>, you’re looking at input, or the code that\nyou would enter. Everything that doesn’t have >>> in front of it\nis output, or the results of running your code. This is the style\nyou see when you run python on the command line, but if you’re using\nIPython, you might see a different style. Note that it is not part of the\ncode and will cause an error if typed or pasted into the Python\nshell. It can be safely typed or pasted into the IPython shell; the >>>\nis ignored.','ignore &gt; &gt; &gt;',0,'',''),(5775,'numpy','NumPy gives you an enormous range of fast and efficient ways of creating arrays\nand manipulating numerical data inside them. While a Python list can contain\ndifferent data types within a single list, all of the elements in a NumPy array\nshould be homogeneous. The mathematical operations that are meant to be performed\non arrays would be extremely inefficient if the arrays weren’t homogeneous.','create arrays',0,'',''),(5776,'numpy','NumPy gives you an enormous range of fast and efficient ways of creating arrays\nand manipulating numerical data inside them. While a Python list can contain\ndifferent data types within a single list, all of the elements in a NumPy array\nshould be homogeneous. The mathematical operations that are meant to be performed\non arrays would be extremely inefficient if the arrays weren’t homogeneous.','manipulate numerical data',0,'',''),(5777,'numpy','NumPy gives you an enormous range of fast and efficient ways of creating arrays\nand manipulating numerical data inside them. While a Python list can contain\ndifferent data types within a single list, all of the elements in a NumPy array\nshould be homogeneous. The mathematical operations that are meant to be performed\non arrays would be extremely inefficient if the arrays weren’t homogeneous.','perform  on arrays',0,'',''),(5778,'numpy','Why use NumPy?','use numpy',0,'',''),(5779,'numpy','NumPy arrays are faster and more compact than Python lists. An array consumes\nless memory and is convenient to use. NumPy uses much less memory to store data\nand it provides a mechanism of specifying the data types. This allows the code\nto be optimized even further.','use less memory to store data',0,'',''),(5780,'numpy','NumPy arrays are faster and more compact than Python lists. An array consumes\nless memory and is convenient to use. NumPy uses much less memory to store data\nand it provides a mechanism of specifying the data types. This allows the code\nto be optimized even further.','provide mechanism of specifying',0,'',''),(5781,'numpy','NumPy arrays are faster and more compact than Python lists. An array consumes\nless memory and is convenient to use. NumPy uses much less memory to store data\nand it provides a mechanism of specifying the data types. This allows the code\nto be optimized even further.','specify data types',0,'',''),(5782,'numpy','An array is a central data structure of the NumPy library. An array is a grid of\nvalues and it contains information about the raw data, how to locate an element,\nand how to interpret an element. It has a grid of elements that can be indexed\nin various ways.\nThe elements are all of the same type, referred to as the array dtype.','locate element',0,'',''),(5783,'numpy','One way we can initialize NumPy arrays is from Python lists, using nested lists\nfor two- or higher-dimensional data.','initialize NumPy arrays',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5784,'numpy','One way we can initialize NumPy arrays is from Python lists, using nested lists\nfor two- or higher-dimensional data.','initialize way',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5785,'numpy','One way we can initialize NumPy arrays is from Python lists, using nested lists\nfor two- or higher-dimensional data.','use higher-dimensional data',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5786,'numpy','One way we can initialize NumPy arrays is from Python lists, using nested lists\nfor two- or higher-dimensional data.','use nested lists',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5787,'numpy','We can access the elements in the array using square brackets. When you’re\naccessing elements, remember that indexing in NumPy starts at 0. That means that\nif you want to access the first element in your array, you’ll be accessing\nelement “0”.','access elements in array',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5788,'numpy','We can access the elements in the array using square brackets. When you’re\naccessing elements, remember that indexing in NumPy starts at 0. That means that\nif you want to access the first element in your array, you’ll be accessing\nelement “0”.','use square brackets',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5789,'numpy','We can access the elements in the array using square brackets. When you’re\naccessing elements, remember that indexing in NumPy starts at 0. That means that\nif you want to access the first element in your array, you’ll be accessing\nelement “0”.','access elements',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5790,'numpy','We can access the elements in the array using square brackets. When you’re\naccessing elements, remember that indexing in NumPy starts at 0. That means that\nif you want to access the first element in your array, you’ll be accessing\nelement “0”.','access first element in array',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5791,'numpy','We can access the elements in the array using square brackets. When you’re\naccessing elements, remember that indexing in NumPy starts at 0. That means that\nif you want to access the first element in your array, you’ll be accessing\nelement “0”.','access element',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5792,'numpy','You might occasionally hear an array referred to as a “ndarray,” which is\nshorthand for “N-dimensional array.” An N-dimensional array is simply an array\nwith any number of dimensions. You might also hear 1-D, or one-dimensional\narray, 2-D, or two-dimensional array, and so on. The NumPy ndarray class\nis used to represent both matrices and vectors. A vector is an array with a\nsingle dimension (there’s no difference\nbetween row and column vectors), while a matrix refers to an\narray with two dimensions. For 3-D or higher dimensional arrays, the term\ntensor is also commonly used.','use NumPy ndarray class',0,'',''),(5793,'numpy','You might occasionally hear an array referred to as a “ndarray,” which is\nshorthand for “N-dimensional array.” An N-dimensional array is simply an array\nwith any number of dimensions. You might also hear 1-D, or one-dimensional\narray, 2-D, or two-dimensional array, and so on. The NumPy ndarray class\nis used to represent both matrices and vectors. A vector is an array with a\nsingle dimension (there’s no difference\nbetween row and column vectors), while a matrix refers to an\narray with two dimensions. For 3-D or higher dimensional arrays, the term\ntensor is also commonly used.','use term tensor for higher dimensional arrays',0,'',''),(5794,'numpy','An array is usually a fixed-size container of items of the same type and size.\nThe number of dimensions and items in an array is defined by its shape. The\nshape of an array is a tuple of non-negative integers that specify the sizes of\neach dimension.','define number of dimensions',0,'',''),(5795,'numpy','An array is usually a fixed-size container of items of the same type and size.\nThe number of dimensions and items in an array is defined by its shape. The\nshape of an array is a tuple of non-negative integers that specify the sizes of\neach dimension.','define number of items',0,'',''),(5796,'numpy','An array is usually a fixed-size container of items of the same type and size.\nThe number of dimensions and items in an array is defined by its shape. The\nshape of an array is a tuple of non-negative integers that specify the sizes of\neach dimension.','specify sizes of dimension',0,'',''),(5797,'numpy','An array is usually a fixed-size container of items of the same type and size.\nThe number of dimensions and items in an array is defined by its shape. The\nshape of an array is a tuple of non-negative integers that specify the sizes of\neach dimension.','specify sizes of non-negative integers',0,'',''),(5798,'numpy','An array is usually a fixed-size container of items of the same type and size.\nThe number of dimensions and items in an array is defined by its shape. The\nshape of an array is a tuple of non-negative integers that specify the sizes of\neach dimension.','specify tuple of dimension',0,'',''),(5799,'numpy','An array is usually a fixed-size container of items of the same type and size.\nThe number of dimensions and items in an array is defined by its shape. The\nshape of an array is a tuple of non-negative integers that specify the sizes of\neach dimension.','specify tuple of non-negative integers',0,'',''),(5800,'numpy','In NumPy, dimensions are called axes. This means that if you have a 2D array\nthat looks like this:','call axes in NumPy',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5801,'numpy','In NumPy, dimensions are called axes. This means that if you have a 2D array\nthat looks like this:','call dimensions in NumPy',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5802,'numpy','Just like in other Python container objects, the contents of an array can be\naccessed and modified by indexing or slicing the array. Unlike the typical container\nobjects, different arrays can share the same data, so changes made on one array might\nbe visible in another.','access contents of array',0,'',''),(5803,'numpy','Just like in other Python container objects, the contents of an array can be\naccessed and modified by indexing or slicing the array. Unlike the typical container\nobjects, different arrays can share the same data, so changes made on one array might\nbe visible in another.','modify contents of array',0,'',''),(5804,'numpy','Just like in other Python container objects, the contents of an array can be\naccessed and modified by indexing or slicing the array. Unlike the typical container\nobjects, different arrays can share the same data, so changes made on one array might\nbe visible in another.','share same data unlike typical container objects',0,'',''),(5805,'numpy','Array attributes reflect information intrinsic to the array itself. If you\nneed to get, or even set, properties of an array without creating a new array,\nyou can often access an array through its attributes.','create new array',0,'',''),(5806,'numpy','Array attributes reflect information intrinsic to the array itself. If you\nneed to get, or even set, properties of an array without creating a new array,\nyou can often access an array through its attributes.','access array through attributes',0,'',''),(5807,'numpy','Read more about array attributes here and learn about\narray objects here.','learn  about array objects',0,'',''),(5808,'numpy','To create a NumPy array, you can use the function np.array().','create NumPy array',0,'',''),(5809,'numpy','To create a NumPy array, you can use the function np.array().','use function np.array()',0,'',''),(5810,'numpy','All you need to do to create a simple array is pass a list to it. If you choose\nto, you can also specify the type of data in your list.\nYou can find more information about data types here.','create simple array',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5811,'numpy','All you need to do to create a simple array is pass a list to it. If you choose\nto, you can also specify the type of data in your list.\nYou can find more information about data types here.','pass list',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5812,'numpy','All you need to do to create a simple array is pass a list to it. If you choose\nto, you can also specify the type of data in your list.\nYou can find more information about data types here.','specify type of data',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5813,'numpy','All you need to do to create a simple array is pass a list to it. If you choose\nto, you can also specify the type of data in your list.\nYou can find more information about data types here.','find more information about data types',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5814,'numpy','Besides creating an array from a sequence of elements, you can easily create an\narray filled with 0’s:','create array from sequence',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5815,'numpy','Besides creating an array from a sequence of elements, you can easily create an\narray filled with 0’s:','create array besides creating',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5816,'numpy','Or even an empty array! The function empty creates an array whose initial\ncontent is random and depends on the state of the memory. The reason to use\nempty over zeros (or something similar) is speed - just make sure to\nfill every element afterwards!','create array',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5817,'numpy','Or even an empty array! The function empty creates an array whose initial\ncontent is random and depends on the state of the memory. The reason to use\nempty over zeros (or something similar) is speed - just make sure to\nfill every element afterwards!','fill element',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5818,'numpy','Or even an empty array! The function empty creates an array whose initial\ncontent is random and depends on the state of the memory. The reason to use\nempty over zeros (or something similar) is speed - just make sure to\nfill every element afterwards!','use  over zeros',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5819,'numpy','You can create an array with a range of elements:','create array with range',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5820,'numpy','And even an array that contains a range of evenly spaced intervals. To do this,\nyou will specify the first number, last number, and the step size.','specify step size',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5821,'numpy','And even an array that contains a range of evenly spaced intervals. To do this,\nyou will specify the first number, last number, and the step size.','specify first number',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5822,'numpy','And even an array that contains a range of evenly spaced intervals. To do this,\nyou will specify the first number, last number, and the step size.','specify last number',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5823,'numpy','You can also use np.linspace() to create an array with values that are\nspaced linearly in a specified interval:','use np.linspace()',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5824,'numpy','You can also use np.linspace() to create an array with values that are\nspaced linearly in a specified interval:','create array with values',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5825,'numpy','Specifying your data type','specify data type',0,'',''),(5826,'numpy','While the default data type is floating point (np.float64), you can explicitly\nspecify which data type you want using the dtype keyword.','use dtype keyword',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5827,'numpy','Learn more about creating arrays here','create arrays',0,'',''),(5828,'numpy','Sorting an element is simple with np.sort(). You can specify the axis, kind,\nand order when you call the function.','sort element',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5829,'numpy','Sorting an element is simple with np.sort(). You can specify the axis, kind,\nand order when you call the function.','specify axis',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5830,'numpy','Sorting an element is simple with np.sort(). You can specify the axis, kind,\nand order when you call the function.','specify kind',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5831,'numpy','Sorting an element is simple with np.sort(). You can specify the axis, kind,\nand order when you call the function.','call function',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5832,'numpy','You can quickly sort the numbers in ascending order with:','sort numbers in ascending',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5833,'numpy','In addition to sort, which returns a sorted copy of an array, you can use:','return sorted copy of array',0,'',''),(5834,'numpy','In addition to sort, which returns a sorted copy of an array, you can use:','return sort of array',0,'',''),(5835,'numpy','In addition to sort, which returns a sorted copy of an array, you can use:','use  in_addition_to sort',0,'',''),(5836,'numpy','searchsorted, which will find elements in a sorted array, and','find elements in sorted array',0,'',''),(5837,'numpy','searchsorted, which will find elements in a sorted array, and','find searchsorted in sorted array',0,'',''),(5838,'numpy','To read more about sorting an array, see: sort.','read  about sorting',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5839,'numpy','To read more about sorting an array, see: sort.','sort array',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5840,'numpy','In order to remove elements from an array, it’s simple to use indexing to select\nthe elements that you want to keep.','remove elements from array',0,'',''),(5841,'numpy','In order to remove elements from an array, it’s simple to use indexing to select\nthe elements that you want to keep.','use indexing',0,'',''),(5842,'numpy','In order to remove elements from an array, it’s simple to use indexing to select\nthe elements that you want to keep.','select elements',0,'',''),(5843,'numpy','To read more about concatenate, see: concatenate.','read  about concatenate',0,'',''),(5844,'numpy','ndarray.shape will display a tuple of integers that indicate the number of\nelements stored along each dimension of the array. If, for example, you have a\n2-D array with 2 rows and 3 columns, the shape of your array is (2, 3).','display tuple of integers',0,'',''),(5845,'numpy','ndarray.shape will display a tuple of integers that indicate the number of\nelements stored along each dimension of the array. If, for example, you have a\n2-D array with 2 rows and 3 columns, the shape of your array is (2, 3).','store  along dimension',0,'',''),(5846,'numpy','For example, if you create this array:','create array',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5847,'numpy','To find the number of dimensions of the array, run:','find number of dimensions',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5848,'numpy','To find the number of dimensions of the array, run:','find number of array',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5849,'numpy','To find the total number of elements in the array, run:','find total number in array',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5850,'numpy','To find the total number of elements in the array, run:','find total number of elements',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5851,'numpy','And to find the shape of your array, run:','find shape of array',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5852,'numpy','Using arr.reshape() will give a new shape to an array without changing the\ndata. Just remember that when you use the reshape method, the array you want to\nproduce needs to have the same number of elements as the original array. If you\nstart with an array with 12 elements, you’ll need to make sure that your new\narray also has a total of 12 elements.','change data',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5853,'numpy','Using arr.reshape() will give a new shape to an array without changing the\ndata. Just remember that when you use the reshape method, the array you want to\nproduce needs to have the same number of elements as the original array. If you\nstart with an array with 12 elements, you’ll need to make sure that your new\narray also has a total of 12 elements.','use reshape method',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5854,'numpy','You can use reshape() to reshape your array. For example, you can reshape\nthis array to an array with three rows and two columns:','use reshape()',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5855,'numpy','With np.reshape, you can specify a few optional parameters:','specify few optional parameters with np.reshape',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5856,'numpy','newshape is the new shape you want. You can specify an integer or a tuple of\nintegers. If you specify an integer, the result will be an array of that length.\nThe shape should be compatible with the original shape.','specify integer of integers',0,'',''),(5857,'numpy','newshape is the new shape you want. You can specify an integer or a tuple of\nintegers. If you specify an integer, the result will be an array of that length.\nThe shape should be compatible with the original shape.','specify tuple of integers',0,'',''),(5858,'numpy','newshape is the new shape you want. You can specify an integer or a tuple of\nintegers. If you specify an integer, the result will be an array of that length.\nThe shape should be compatible with the original shape.','specify integer',0,'',''),(5859,'numpy','order: C means to read/write the elements using C-like index order,\nF means to read/write the elements using Fortran-like index order, A\nmeans to read/write the elements in Fortran-like index order if a is Fortran\ncontiguous in memory, C-like order otherwise. (This is an optional parameter and\ndoesn’t need to be specified.)','use fortran-like index order',0,'',''),(5860,'numpy','If you want to learn more about C and Fortran order, you can\nread more about the internal organization of NumPy arrays here.\nEssentially, C and Fortran orders have to do with how indices correspond\nto the order the array is stored in memory. In Fortran, when moving through\nthe elements of a two-dimensional array as it is stored in memory, the first\nindex is the most rapidly varying index. As the first index moves to the next\nrow as it changes, the matrix is stored one column at a time.\nThis is why Fortran is thought of as a Column-major language.\nIn C on the other hand, the last index changes\nthe most rapidly. The matrix is stored by rows, making it a Row-major\nlanguage. What you do for C or Fortran depends on whether it’s more important\nto preserve the indexing convention or not reorder the data.','learn  about c',0,'',''),(5861,'numpy','If you want to learn more about C and Fortran order, you can\nread more about the internal organization of NumPy arrays here.\nEssentially, C and Fortran orders have to do with how indices correspond\nto the order the array is stored in memory. In Fortran, when moving through\nthe elements of a two-dimensional array as it is stored in memory, the first\nindex is the most rapidly varying index. As the first index moves to the next\nrow as it changes, the matrix is stored one column at a time.\nThis is why Fortran is thought of as a Column-major language.\nIn C on the other hand, the last index changes\nthe most rapidly. The matrix is stored by rows, making it a Row-major\nlanguage. What you do for C or Fortran depends on whether it’s more important\nto preserve the indexing convention or not reorder the data.','read  about internal organization',0,'',''),(5862,'numpy','If you want to learn more about C and Fortran order, you can\nread more about the internal organization of NumPy arrays here.\nEssentially, C and Fortran orders have to do with how indices correspond\nto the order the array is stored in memory. In Fortran, when moving through\nthe elements of a two-dimensional array as it is stored in memory, the first\nindex is the most rapidly varying index. As the first index moves to the next\nrow as it changes, the matrix is stored one column at a time.\nThis is why Fortran is thought of as a Column-major language.\nIn C on the other hand, the last index changes\nthe most rapidly. The matrix is stored by rows, making it a Row-major\nlanguage. What you do for C or Fortran depends on whether it’s more important\nto preserve the indexing convention or not reorder the data.','store array in memory',0,'',''),(5863,'numpy','If you want to learn more about C and Fortran order, you can\nread more about the internal organization of NumPy arrays here.\nEssentially, C and Fortran orders have to do with how indices correspond\nto the order the array is stored in memory. In Fortran, when moving through\nthe elements of a two-dimensional array as it is stored in memory, the first\nindex is the most rapidly varying index. As the first index moves to the next\nrow as it changes, the matrix is stored one column at a time.\nThis is why Fortran is thought of as a Column-major language.\nIn C on the other hand, the last index changes\nthe most rapidly. The matrix is stored by rows, making it a Row-major\nlanguage. What you do for C or Fortran depends on whether it’s more important\nto preserve the indexing convention or not reorder the data.','move  through elements',0,'',''),(5864,'numpy','If you want to learn more about C and Fortran order, you can\nread more about the internal organization of NumPy arrays here.\nEssentially, C and Fortran orders have to do with how indices correspond\nto the order the array is stored in memory. In Fortran, when moving through\nthe elements of a two-dimensional array as it is stored in memory, the first\nindex is the most rapidly varying index. As the first index moves to the next\nrow as it changes, the matrix is stored one column at a time.\nThis is why Fortran is thought of as a Column-major language.\nIn C on the other hand, the last index changes\nthe most rapidly. The matrix is stored by rows, making it a Row-major\nlanguage. What you do for C or Fortran depends on whether it’s more important\nto preserve the indexing convention or not reorder the data.','store  in memory',0,'',''),(5865,'numpy','If you want to learn more about C and Fortran order, you can\nread more about the internal organization of NumPy arrays here.\nEssentially, C and Fortran orders have to do with how indices correspond\nto the order the array is stored in memory. In Fortran, when moving through\nthe elements of a two-dimensional array as it is stored in memory, the first\nindex is the most rapidly varying index. As the first index moves to the next\nrow as it changes, the matrix is stored one column at a time.\nThis is why Fortran is thought of as a Column-major language.\nIn C on the other hand, the last index changes\nthe most rapidly. The matrix is stored by rows, making it a Row-major\nlanguage. What you do for C or Fortran depends on whether it’s more important\nto preserve the indexing convention or not reorder the data.','store column at time',0,'',''),(5866,'numpy','If you want to learn more about C and Fortran order, you can\nread more about the internal organization of NumPy arrays here.\nEssentially, C and Fortran orders have to do with how indices correspond\nto the order the array is stored in memory. In Fortran, when moving through\nthe elements of a two-dimensional array as it is stored in memory, the first\nindex is the most rapidly varying index. As the first index moves to the next\nrow as it changes, the matrix is stored one column at a time.\nThis is why Fortran is thought of as a Column-major language.\nIn C on the other hand, the last index changes\nthe most rapidly. The matrix is stored by rows, making it a Row-major\nlanguage. What you do for C or Fortran depends on whether it’s more important\nto preserve the indexing convention or not reorder the data.','store matrix at time',0,'',''),(5867,'numpy','If you want to learn more about C and Fortran order, you can\nread more about the internal organization of NumPy arrays here.\nEssentially, C and Fortran orders have to do with how indices correspond\nto the order the array is stored in memory. In Fortran, when moving through\nthe elements of a two-dimensional array as it is stored in memory, the first\nindex is the most rapidly varying index. As the first index moves to the next\nrow as it changes, the matrix is stored one column at a time.\nThis is why Fortran is thought of as a Column-major language.\nIn C on the other hand, the last index changes\nthe most rapidly. The matrix is stored by rows, making it a Row-major\nlanguage. What you do for C or Fortran depends on whether it’s more important\nto preserve the indexing convention or not reorder the data.','move  to next row',0,'',''),(5868,'numpy','If you want to learn more about C and Fortran order, you can\nread more about the internal organization of NumPy arrays here.\nEssentially, C and Fortran orders have to do with how indices correspond\nto the order the array is stored in memory. In Fortran, when moving through\nthe elements of a two-dimensional array as it is stored in memory, the first\nindex is the most rapidly varying index. As the first index moves to the next\nrow as it changes, the matrix is stored one column at a time.\nThis is why Fortran is thought of as a Column-major language.\nIn C on the other hand, the last index changes\nthe most rapidly. The matrix is stored by rows, making it a Row-major\nlanguage. What you do for C or Fortran depends on whether it’s more important\nto preserve the indexing convention or not reorder the data.','change  in c',0,'',''),(5869,'numpy','If you want to learn more about C and Fortran order, you can\nread more about the internal organization of NumPy arrays here.\nEssentially, C and Fortran orders have to do with how indices correspond\nto the order the array is stored in memory. In Fortran, when moving through\nthe elements of a two-dimensional array as it is stored in memory, the first\nindex is the most rapidly varying index. As the first index moves to the next\nrow as it changes, the matrix is stored one column at a time.\nThis is why Fortran is thought of as a Column-major language.\nIn C on the other hand, the last index changes\nthe most rapidly. The matrix is stored by rows, making it a Row-major\nlanguage. What you do for C or Fortran depends on whether it’s more important\nto preserve the indexing convention or not reorder the data.','store matrix',0,'',''),(5870,'numpy','You can use np.newaxis and np.expand_dims to increase the dimensions of\nyour existing array.','use np.newaxis',0,'',''),(5871,'numpy','You can use np.newaxis and np.expand_dims to increase the dimensions of\nyour existing array.','use np.expand_dims',0,'',''),(5872,'numpy','Using np.newaxis will increase the dimensions of your array by one dimension\nwhen used once. This means that a 1D array will become a 2D array, a\n2D array will become a 3D array, and so on.','use np.newaxis',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5873,'numpy','You can use np.newaxis to add a new axis:','use np.newaxis',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5874,'numpy','You can use np.newaxis to add a new axis:','add new axis',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5875,'numpy','You can explicitly convert a 1D array with either a row vector or a column\nvector using np.newaxis. For example, you can convert a 1D array to a row\nvector by inserting an axis along the first dimension:','convert 1D array',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5876,'numpy','You can explicitly convert a 1D array with either a row vector or a column\nvector using np.newaxis. For example, you can convert a 1D array to a row\nvector by inserting an axis along the first dimension:','use np.newaxis',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5877,'numpy','You can explicitly convert a 1D array with either a row vector or a column\nvector using np.newaxis. For example, you can convert a 1D array to a row\nvector by inserting an axis along the first dimension:','convert 1D array by inserting',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5878,'numpy','You can explicitly convert a 1D array with either a row vector or a column\nvector using np.newaxis. For example, you can convert a 1D array to a row\nvector by inserting an axis along the first dimension:','convert 1D array to row vector',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5879,'numpy','You can explicitly convert a 1D array with either a row vector or a column\nvector using np.newaxis. For example, you can convert a 1D array to a row\nvector by inserting an axis along the first dimension:','insert axis along first dimension',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5880,'numpy','Or, for a column vector, you can insert an axis along the second dimension:','insert axis along second dimension',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5881,'numpy','Or, for a column vector, you can insert an axis along the second dimension:','insert axis for column vector',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5882,'numpy','You can also expand an array by inserting a new axis at a specified position\nwith np.expand_dims.','expand array by inserting',0,'',''),(5883,'numpy','You can also expand an array by inserting a new axis at a specified position\nwith np.expand_dims.','insert new axis at specified position',0,'',''),(5884,'numpy','You can use np.expand_dims to add an axis at index position 1 with:','use np.expand_dims',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5885,'numpy','You can use np.expand_dims to add an axis at index position 1 with:','add axis at index position',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5886,'numpy','You can add an axis at index position 0 with:','add axis at index position',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5887,'numpy','Find more information about newaxis here and\nexpand_dims at expand_dims.','find more information at expand_dims',0,'',''),(5888,'numpy','Find more information about newaxis here and\nexpand_dims at expand_dims.','find more information about newaxis',0,'',''),(5889,'numpy','Find more information about newaxis here and\nexpand_dims at expand_dims.','find expand_dims at expand_dims',0,'',''),(5890,'numpy','Find more information about newaxis here and\nexpand_dims at expand_dims.','find expand_dims about newaxis',0,'',''),(5891,'numpy','You may want to take a section of your array or specific array elements to use\nin further analysis or additional operations. To do that, you’ll need to subset,\nslice, and/or index your arrays.','use  in further analysis',0,'',''),(5892,'numpy','You may want to take a section of your array or specific array elements to use\nin further analysis or additional operations. To do that, you’ll need to subset,\nslice, and/or index your arrays.','use  in additional operations',0,'',''),(5893,'numpy','If you want to select values from your array that fulfill certain conditions,\nit’s straightforward with NumPy.','select values from array',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5894,'numpy','You can easily print all of the values in the array that are less than 5.','print  in array',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5895,'numpy','You can also select, for example, numbers that are equal to or greater than 5,\nand use that condition to index an array.','select array',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5896,'numpy','You can also select, for example, numbers that are equal to or greater than 5,\nand use that condition to index an array.','use condition to index',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5897,'numpy','You can select elements that are divisible by 2:','select elements',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5898,'numpy','Or you can select elements that satisfy two conditions using the & and |\noperators:','select elements',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5899,'numpy','Or you can select elements that satisfy two conditions using the & and |\noperators:','use &amp; | operators',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5900,'numpy','You can also make use of the logical operators & and | in order to\nreturn boolean values that specify whether or not the values in an array fulfill\na certain condition. This can be useful with arrays that contain names or other\ncategorical values.','return boolean values',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5901,'numpy','You can also make use of the logical operators & and | in order to\nreturn boolean values that specify whether or not the values in an array fulfill\na certain condition. This can be useful with arrays that contain names or other\ncategorical values.','specify boolean values',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5902,'numpy','You can also use np.nonzero() to select elements or indices from an array.','use np.nonzero()',0,'',''),(5903,'numpy','You can also use np.nonzero() to select elements or indices from an array.','select elements from array',0,'',''),(5904,'numpy','You can also use np.nonzero() to select elements or indices from an array.','select indices from array',0,'',''),(5905,'numpy','You can use np.nonzero() to print the indices of elements that are, for\nexample, less than 5:','use np.nonzero()',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5906,'numpy','You can use np.nonzero() to print the indices of elements that are, for\nexample, less than 5:','print indices of elements',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5907,'numpy','In this example, a tuple of arrays was returned: one for each dimension. The\nfirst array represents the row indices where these values are found, and the\nsecond array represents the column indices where the values are found.','return tuple of arrays',0,'',''),(5908,'numpy','In this example, a tuple of arrays was returned: one for each dimension. The\nfirst array represents the row indices where these values are found, and the\nsecond array represents the column indices where the values are found.','find values',0,'',''),(5909,'numpy','In this example, a tuple of arrays was returned: one for each dimension. The\nfirst array represents the row indices where these values are found, and the\nsecond array represents the column indices where the values are found.','find values',0,'',''),(5910,'numpy','If you want to generate a list of coordinates where the elements exist, you can\nzip the arrays, iterate over the list of coordinates, and print them. For\nexample:','generate list of coordinates',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5911,'numpy','You can also use np.nonzero() to print the elements in an array that are less\nthan 5 with:','use np.nonzero()',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5912,'numpy','You can also use np.nonzero() to print the elements in an array that are less\nthan 5 with:','print elements in array',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5913,'numpy','Learn more about indexing and slicing here\nand here.','learn  about indexing',0,'',''),(5914,'numpy','Read more about using the nonzero function at: nonzero.','use nonzero',0,'',''),(5915,'numpy','You can easily create a new array from a section of an existing array.','create new array from section',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5916,'numpy','You can create a new array from a section of your array any time by specifying\nwhere you want to slice your array.','create new array by specifying',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5917,'numpy','You can create a new array from a section of your array any time by specifying\nwhere you want to slice your array.','create new array from section',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5918,'numpy','You can split an array into several smaller arrays using hsplit. You can\nspecify either the number of equally shaped arrays to return or the columns\nafter which the division should occur.','split array',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5919,'numpy','You can split an array into several smaller arrays using hsplit. You can\nspecify either the number of equally shaped arrays to return or the columns\nafter which the division should occur.','use hsplit',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5920,'numpy','You can split an array into several smaller arrays using hsplit. You can\nspecify either the number of equally shaped arrays to return or the columns\nafter which the division should occur.','specify number of shaped arrays',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5921,'numpy','You can split an array into several smaller arrays using hsplit. You can\nspecify either the number of equally shaped arrays to return or the columns\nafter which the division should occur.','specify number to return',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5922,'numpy','You can split an array into several smaller arrays using hsplit. You can\nspecify either the number of equally shaped arrays to return or the columns\nafter which the division should occur.','specify number to columns',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5923,'numpy','If you wanted to split this array into three equally shaped arrays, you would\nrun:','split array into shaped arrays',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5924,'numpy','If you wanted to split your array after the third and fourth column, you’d run:','split array after third fourth column',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5925,'numpy','You can use the view method to create a new array object that looks at the\nsame data as the original array (a shallow copy).','use view method',0,'',''),(5926,'numpy','You can use the view method to create a new array object that looks at the\nsame data as the original array (a shallow copy).','create new array object',0,'',''),(5927,'numpy','Views are an important NumPy concept! NumPy functions, as well as operations\nlike indexing and slicing, will return views whenever possible. This saves\nmemory and is faster (no copy of the data has to be made). However it’s\nimportant to be aware of this - modifying data in a view also modifies the\noriginal array!','return views',0,'',''),(5928,'numpy','Views are an important NumPy concept! NumPy functions, as well as operations\nlike indexing and slicing, will return views whenever possible. This saves\nmemory and is faster (no copy of the data has to be made). However it’s\nimportant to be aware of this - modifying data in a view also modifies the\noriginal array!','save memory',0,'',''),(5929,'numpy','Views are an important NumPy concept! NumPy functions, as well as operations\nlike indexing and slicing, will return views whenever possible. This saves\nmemory and is faster (no copy of the data has to be made). However it’s\nimportant to be aware of this - modifying data in a view also modifies the\noriginal array!','modify original array',0,'',''),(5930,'numpy','Let’s say you create this array:','create array',0,'',''),(5931,'numpy','Now we create an array b1 by slicing a and modify the first element of\nb1. This will modify the corresponding element in a as well!','create array b1',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5932,'numpy','Now we create an array b1 by slicing a and modify the first element of\nb1. This will modify the corresponding element in a as well!','modify first element',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5933,'numpy','Now we create an array b1 by slicing a and modify the first element of\nb1. This will modify the corresponding element in a as well!','modify corresponding element',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5934,'numpy','Using the copy method will make a complete copy of the array and its data (a\ndeep copy). To use this on your array, you could run:','use copy method',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5935,'numpy','Once you’ve created your arrays, you can start to work with them.  Let’s say,\nfor example, that you’ve created two arrays, one called “data” and one called\n“ones”','create arrays',0,'',''),(5936,'numpy','Once you’ve created your arrays, you can start to work with them.  Let’s say,\nfor example, that you’ve created two arrays, one called “data” and one called\n“ones”','create called data',0,'',''),(5937,'numpy','Once you’ve created your arrays, you can start to work with them.  Let’s say,\nfor example, that you’ve created two arrays, one called “data” and one called\n“ones”','create called ones',0,'',''),(5938,'numpy','Once you’ve created your arrays, you can start to work with them.  Let’s say,\nfor example, that you’ve created two arrays, one called “data” and one called\n“ones”','create arrays',0,'',''),(5939,'numpy','You can add the arrays together with the plus sign.','add arrays together_with plus sign',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5940,'numpy','Basic operations are simple with NumPy. If you want to find the sum of the\nelements in an array, you’d use sum(). This works for 1D arrays, 2D arrays,\nand arrays in higher dimensions.','find sum of elements',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5941,'numpy','Basic operations are simple with NumPy. If you want to find the sum of the\nelements in an array, you’d use sum(). This works for 1D arrays, 2D arrays,\nand arrays in higher dimensions.','use sum()',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5942,'numpy','To add the rows or the columns in a 2D array, you would specify the axis.','add rows in 2D array',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5943,'numpy','To add the rows or the columns in a 2D array, you would specify the axis.','add columns in 2D array',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5944,'numpy','To add the rows or the columns in a 2D array, you would specify the axis.','specify axis',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5945,'numpy','There are times when you might want to carry out an operation between an array\nand a single number (also called an operation between a vector and a scalar)\nor between arrays of two different sizes. For example, your array (we’ll call it\n“data”) might contain information about distance in miles but you want to\nconvert the information to kilometers. You can perform this operation with:','convert information to kilometers',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5946,'numpy','There are times when you might want to carry out an operation between an array\nand a single number (also called an operation between a vector and a scalar)\nor between arrays of two different sizes. For example, your array (we’ll call it\n“data”) might contain information about distance in miles but you want to\nconvert the information to kilometers. You can perform this operation with:','perform operation',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5947,'numpy','NumPy understands that the multiplication should happen with each cell. That\nconcept is called broadcasting. Broadcasting is a mechanism that allows\nNumPy to perform operations on arrays of different shapes. The dimensions of\nyour array must be compatible, for example, when the dimensions of both arrays\nare equal or when one of them is 1. If the dimensions are not compatible, you\nwill get a ValueError.','call broadcasting',0,'',''),(5948,'numpy','NumPy understands that the multiplication should happen with each cell. That\nconcept is called broadcasting. Broadcasting is a mechanism that allows\nNumPy to perform operations on arrays of different shapes. The dimensions of\nyour array must be compatible, for example, when the dimensions of both arrays\nare equal or when one of them is 1. If the dimensions are not compatible, you\nwill get a ValueError.','call concept',0,'',''),(5949,'numpy','NumPy understands that the multiplication should happen with each cell. That\nconcept is called broadcasting. Broadcasting is a mechanism that allows\nNumPy to perform operations on arrays of different shapes. The dimensions of\nyour array must be compatible, for example, when the dimensions of both arrays\nare equal or when one of them is 1. If the dimensions are not compatible, you\nwill get a ValueError.','perform operations on arrays',0,'',''),(5950,'numpy','NumPy understands that the multiplication should happen with each cell. That\nconcept is called broadcasting. Broadcasting is a mechanism that allows\nNumPy to perform operations on arrays of different shapes. The dimensions of\nyour array must be compatible, for example, when the dimensions of both arrays\nare equal or when one of them is 1. If the dimensions are not compatible, you\nwill get a ValueError.','get ValueError',0,'',''),(5951,'numpy','NumPy also performs aggregation functions. In addition to min, max, and\nsum, you can easily run mean to get the average, prod to get the\nresult of multiplying the elements together, std to get the standard\ndeviation, and more.','perform aggregation functions',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5952,'numpy','NumPy also performs aggregation functions. In addition to min, max, and\nsum, you can easily run mean to get the average, prod to get the\nresult of multiplying the elements together, std to get the standard\ndeviation, and more.','get average',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5953,'numpy','NumPy also performs aggregation functions. In addition to min, max, and\nsum, you can easily run mean to get the average, prod to get the\nresult of multiplying the elements together, std to get the standard\ndeviation, and more.','get result of multiplying',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5954,'numpy','NumPy also performs aggregation functions. In addition to min, max, and\nsum, you can easily run mean to get the average, prod to get the\nresult of multiplying the elements together, std to get the standard\ndeviation, and more.','multiply elements',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5955,'numpy','NumPy also performs aggregation functions. In addition to min, max, and\nsum, you can easily run mean to get the average, prod to get the\nresult of multiplying the elements together, std to get the standard\ndeviation, and more.','get standard deviation',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5956,'numpy','Let’s start with this array, called “a”','call a.',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5957,'numpy','It’s very common to want to aggregate along a row or column. By default, every\nNumPy aggregation function will return the aggregate of the entire array. To\nfind the sum or the minimum of the elements in your array, run:','return aggregate by default',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5958,'numpy','It’s very common to want to aggregate along a row or column. By default, every\nNumPy aggregation function will return the aggregate of the entire array. To\nfind the sum or the minimum of the elements in your array, run:','return aggregate of entire array',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5959,'numpy','It’s very common to want to aggregate along a row or column. By default, every\nNumPy aggregation function will return the aggregate of the entire array. To\nfind the sum or the minimum of the elements in your array, run:','find sum in array',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5960,'numpy','It’s very common to want to aggregate along a row or column. By default, every\nNumPy aggregation function will return the aggregate of the entire array. To\nfind the sum or the minimum of the elements in your array, run:','find sum of elements',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5961,'numpy','It’s very common to want to aggregate along a row or column. By default, every\nNumPy aggregation function will return the aggregate of the entire array. To\nfind the sum or the minimum of the elements in your array, run:','find minimum in array',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5962,'numpy','It’s very common to want to aggregate along a row or column. By default, every\nNumPy aggregation function will return the aggregate of the entire array. To\nfind the sum or the minimum of the elements in your array, run:','find minimum of elements',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5963,'numpy','You can specify on which axis you want the aggregation function to be computed.\nFor example, you can find the minimum value within each column by specifying\naxis=0.','find minimum value within column',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5964,'numpy','You can specify on which axis you want the aggregation function to be computed.\nFor example, you can find the minimum value within each column by specifying\naxis=0.','find minimum value by specifying',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5965,'numpy','The four values listed above correspond to the number of columns in your array.\nWith a four-column array, you will get four values as your result.','list  above correspond',0,'',''),(5966,'numpy','The four values listed above correspond to the number of columns in your array.\nWith a four-column array, you will get four values as your result.','list  to number',0,'',''),(5967,'numpy','The four values listed above correspond to the number of columns in your array.\nWith a four-column array, you will get four values as your result.','get values with four-column array',0,'',''),(5968,'numpy','The four values listed above correspond to the number of columns in your array.\nWith a four-column array, you will get four values as your result.','get values as result',0,'',''),(5969,'numpy','You can pass Python lists of lists to create a 2-D array (or “matrix”) to\nrepresent them in NumPy.','pass Python lists of lists',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5970,'numpy','You can pass Python lists of lists to create a 2-D array (or “matrix”) to\nrepresent them in NumPy.','create 2-d array',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5971,'numpy','Indexing and slicing operations are useful when you’re manipulating matrices:','manipulate matrices',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5972,'numpy','You can aggregate all the values in a matrix and you can aggregate them across\ncolumns or rows using the axis parameter. To illustrate this point, let’s\nlook at a slightly modified dataset:','use axis parameter',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5973,'numpy','Once you’ve created your matrices, you can add and multiply them using\narithmetic operators if you have two matrices that are the same size.','create matrices',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5974,'numpy','Once you’ve created your matrices, you can add and multiply them using\narithmetic operators if you have two matrices that are the same size.','use arithmetic operators',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5975,'numpy','You can do these arithmetic operations on matrices of different sizes, but only\nif one matrix has only one column or one row. In this case, NumPy will use its\nbroadcast rules for the operation.','use broadcast rules in case',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5976,'numpy','You can do these arithmetic operations on matrices of different sizes, but only\nif one matrix has only one column or one row. In this case, NumPy will use its\nbroadcast rules for the operation.','use broadcast rules for operation',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5977,'numpy','Be aware that when NumPy prints N-dimensional arrays, the last axis is looped\nover the fastest while the first axis is the slowest. For instance:','print n-dimensional arrays',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5978,'numpy','There are often instances where we want NumPy to initialize the values of an\narray. NumPy offers functions like ones() and zeros(), and the\nrandom.Generator class for random number generation for that.\nAll you need to do is pass in the number of elements you want it to generate:','initialize values of array',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5979,'numpy','There are often instances where we want NumPy to initialize the values of an\narray. NumPy offers functions like ones() and zeros(), and the\nrandom.Generator class for random number generation for that.\nAll you need to do is pass in the number of elements you want it to generate:','offer functions like ones()',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5980,'numpy','There are often instances where we want NumPy to initialize the values of an\narray. NumPy offers functions like ones() and zeros(), and the\nrandom.Generator class for random number generation for that.\nAll you need to do is pass in the number of elements you want it to generate:','offer functions like zeros()',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5981,'numpy','There are often instances where we want NumPy to initialize the values of an\narray. NumPy offers functions like ones() and zeros(), and the\nrandom.Generator class for random number generation for that.\nAll you need to do is pass in the number of elements you want it to generate:','offer functions for random number generation',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5982,'numpy','There are often instances where we want NumPy to initialize the values of an\narray. NumPy offers functions like ones() and zeros(), and the\nrandom.Generator class for random number generation for that.\nAll you need to do is pass in the number of elements you want it to generate:','offer random.Generator class like ones()',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5983,'numpy','There are often instances where we want NumPy to initialize the values of an\narray. NumPy offers functions like ones() and zeros(), and the\nrandom.Generator class for random number generation for that.\nAll you need to do is pass in the number of elements you want it to generate:','offer random.Generator class like zeros()',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5984,'numpy','There are often instances where we want NumPy to initialize the values of an\narray. NumPy offers functions like ones() and zeros(), and the\nrandom.Generator class for random number generation for that.\nAll you need to do is pass in the number of elements you want it to generate:','offer random.Generator class for random number generation',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5985,'numpy','There are often instances where we want NumPy to initialize the values of an\narray. NumPy offers functions like ones() and zeros(), and the\nrandom.Generator class for random number generation for that.\nAll you need to do is pass in the number of elements you want it to generate:','pass  in number',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5986,'numpy','You can also use ones(), zeros(), and random() to create\na 2D array if you give them a tuple describing the dimensions of the matrix:','use ones()',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5987,'numpy','You can also use ones(), zeros(), and random() to create\na 2D array if you give them a tuple describing the dimensions of the matrix:','use zeros()',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5988,'numpy','You can also use ones(), zeros(), and random() to create\na 2D array if you give them a tuple describing the dimensions of the matrix:','use random()',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5989,'numpy','You can also use ones(), zeros(), and random() to create\na 2D array if you give them a tuple describing the dimensions of the matrix:','create 2D array',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5990,'numpy','You can also use ones(), zeros(), and random() to create\na 2D array if you give them a tuple describing the dimensions of the matrix:','describe dimensions of matrix',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(5991,'numpy','Read more about creating arrays, filled with 0’s, 1’s, other values or\nuninitialized, at array creation routines.','create arrays at array creation routines',0,'',''),(5992,'numpy','Read more about creating arrays, filled with 0’s, 1’s, other values or\nuninitialized, at array creation routines.','read  about creating',0,'',''),(5993,'numpy','Read more about creating arrays, filled with 0’s, 1’s, other values or\nuninitialized, at array creation routines.','fill  with other values',0,'',''),(5994,'numpy','Read more about creating arrays, filled with 0’s, 1’s, other values or\nuninitialized, at array creation routines.','fill  with uninitialized',0,'',''),(5995,'numpy','Read more about creating arrays, filled with 0’s, 1’s, other values or\nuninitialized, at array creation routines.','fill  with âs',0,'',''),(5996,'numpy','Read more about creating arrays, filled with 0’s, 1’s, other values or\nuninitialized, at array creation routines.','fill  with âs',0,'',''),(5997,'numpy','The use of random number generation is an important part of the configuration\nand evaluation of many numerical and machine learning algorithms. Whether you\nneed to randomly initialize weights in an artificial neural network, split data\ninto random sets, or randomly shuffle your dataset, being able to generate\nrandom numbers (actually, repeatable pseudo-random numbers) is essential.','initialize weights in artificial neural network',0,'',''),(5998,'numpy','The use of random number generation is an important part of the configuration\nand evaluation of many numerical and machine learning algorithms. Whether you\nneed to randomly initialize weights in an artificial neural network, split data\ninto random sets, or randomly shuffle your dataset, being able to generate\nrandom numbers (actually, repeatable pseudo-random numbers) is essential.','split data into random sets',0,'',''),(5999,'numpy','The use of random number generation is an important part of the configuration\nand evaluation of many numerical and machine learning algorithms. Whether you\nneed to randomly initialize weights in an artificial neural network, split data\ninto random sets, or randomly shuffle your dataset, being able to generate\nrandom numbers (actually, repeatable pseudo-random numbers) is essential.','generate random numbers',0,'',''),(6000,'numpy','With Generator.integers, you can generate random integers from low (remember\nthat this is inclusive with NumPy) to high (exclusive). You can set\nendpoint=True to make the high number inclusive.','generate random integers with Generator.integers',0,'',''),(6001,'numpy','You can generate a 2 x 4 array of random integers between 0 and 4 with:','generate x array of random integers',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6002,'numpy','Read more about random number generation here.','read random number generation',0,'',''),(6003,'numpy','You can find the unique elements in an array easily with np.unique.','find unique elements with np.unique',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6004,'numpy','You can find the unique elements in an array easily with np.unique.','find unique elements in array',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6005,'numpy','you can use np.unique to print the unique values in your array:','use np.unique',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6006,'numpy','you can use np.unique to print the unique values in your array:','print unique values in array',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6007,'numpy','To get the indices of unique values in a NumPy array (an array of first index\npositions of unique values in the array), just pass the return_index\nargument in np.unique() as well as your array.','get indices in NumPy array',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6008,'numpy','To get the indices of unique values in a NumPy array (an array of first index\npositions of unique values in the array), just pass the return_index\nargument in np.unique() as well as your array.','get indices of unique values',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6009,'numpy','To get the indices of unique values in a NumPy array (an array of first index\npositions of unique values in the array), just pass the return_index\nargument in np.unique() as well as your array.','pass return_index argument in np.unique()',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6010,'numpy','To get the indices of unique values in a NumPy array (an array of first index\npositions of unique values in the array), just pass the return_index\nargument in np.unique() as well as your array.','pass array in np.unique()',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6011,'numpy','You can pass the return_counts argument in np.unique() along with your\narray to get the frequency count of unique values in a NumPy array.','pass return_counts argument along_with array',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6012,'numpy','You can pass the return_counts argument in np.unique() along with your\narray to get the frequency count of unique values in a NumPy array.','pass return_counts argument in np.unique()',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6013,'numpy','You can pass the return_counts argument in np.unique() along with your\narray to get the frequency count of unique values in a NumPy array.','get frequency count in NumPy array',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6014,'numpy','You can pass the return_counts argument in np.unique() along with your\narray to get the frequency count of unique values in a NumPy array.','get frequency count of unique values',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6015,'numpy','You can find unique values with:','find unique values',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6016,'numpy','If the axis argument isn’t passed, your 2D array will be flattened.','pass axis argument',0,'',''),(6017,'numpy','If you want to get the unique rows or columns, make sure to pass the axis\nargument. To find the unique rows, specify axis=0 and for columns, specify\naxis=1.','get unique rows',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6018,'numpy','If you want to get the unique rows or columns, make sure to pass the axis\nargument. To find the unique rows, specify axis=0 and for columns, specify\naxis=1.','get columns',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6019,'numpy','If you want to get the unique rows or columns, make sure to pass the axis\nargument. To find the unique rows, specify axis=0 and for columns, specify\naxis=1.','pass axis argument',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6020,'numpy','If you want to get the unique rows or columns, make sure to pass the axis\nargument. To find the unique rows, specify axis=0 and for columns, specify\naxis=1.','find unique rows',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6021,'numpy','To get the unique rows, index position, and occurrence count, you can use:','get unique rows',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6022,'numpy','To get the unique rows, index position, and occurrence count, you can use:','get index position',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6023,'numpy','To get the unique rows, index position, and occurrence count, you can use:','get occurrence count',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6024,'numpy','To learn more about finding the unique elements in an array, see unique.','learn  about finding',0,'',''),(6025,'numpy','To learn more about finding the unique elements in an array, see unique.','find unique elements in array',0,'',''),(6026,'numpy','You may also need to switch the dimensions of a matrix. This can happen when,\nfor example, you have a model that expects a certain input shape that is\ndifferent from your dataset. This is where the reshape method can be useful.\nYou simply need to pass in the new dimensions that you want for the matrix.','switch dimensions of matrix',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6027,'numpy','You may also need to switch the dimensions of a matrix. This can happen when,\nfor example, you have a model that expects a certain input shape that is\ndifferent from your dataset. This is where the reshape method can be useful.\nYou simply need to pass in the new dimensions that you want for the matrix.','pass  in new dimensions',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6028,'numpy','You can also use .transpose() to reverse or change the axes of an array\naccording to the values you specify.','use .transpose()',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6029,'numpy','You can also use .transpose() to reverse or change the axes of an array\naccording to the values you specify.','change axes of array',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6030,'numpy','You can also use .transpose() to reverse or change the axes of an array\naccording to the values you specify.','specify values',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6031,'numpy','You can also use arr.T:','use arr.T',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6032,'numpy','To learn more about transposing and reshaping arrays, see transpose and\nreshape.','learn  about transposing',0,'',''),(6033,'numpy','To learn more about transposing and reshaping arrays, see transpose and\nreshape.','learn  about reshaping',0,'',''),(6034,'numpy','NumPy’s np.flip() function allows you to flip, or reverse, the contents of\nan array along an axis. When using np.flip(), specify the array you would like\nto reverse and the axis. If you don’t specify the axis, NumPy will reverse the\ncontents along all of the axes of your input array.','use np.flip()',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6035,'numpy','NumPy’s np.flip() function allows you to flip, or reverse, the contents of\nan array along an axis. When using np.flip(), specify the array you would like\nto reverse and the axis. If you don’t specify the axis, NumPy will reverse the\ncontents along all of the axes of your input array.','specify array',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6036,'numpy','NumPy’s np.flip() function allows you to flip, or reverse, the contents of\nan array along an axis. When using np.flip(), specify the array you would like\nto reverse and the axis. If you don’t specify the axis, NumPy will reverse the\ncontents along all of the axes of your input array.','specify axis',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6037,'numpy','If you want to print your reversed array, you can run:','print reversed array',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6038,'numpy','Read more about reversing arrays at flip.','read  about reversing',0,'',''),(6039,'numpy','There are two popular ways to flatten an array: .flatten() and .ravel().\nThe primary difference between the two is that the new array created using\nravel() is actually a reference to the parent array (i.e., a “view”). This\nmeans that any changes to the new array will affect the parent array as well.\nSince ravel does not create a copy, it’s memory efficient.','use ravel()',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6040,'numpy','When you use flatten, changes to your new array won’t change the parent\narray.','change parent array',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6041,'numpy','When it comes to the data science ecosystem, Python and NumPy are built with the\nuser in mind. One of the best examples of this is the built-in access to\ndocumentation. Every object contains the reference to a string, which is known\nas the docstring. In most cases, this docstring contains a quick and concise\nsummary of the object and how to use it. Python has a built-in help()\nfunction that can help you access this information. This means that nearly any\ntime you need more information, you can use help() to quickly find the\ninformation that you need.','access information',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6042,'numpy','When it comes to the data science ecosystem, Python and NumPy are built with the\nuser in mind. One of the best examples of this is the built-in access to\ndocumentation. Every object contains the reference to a string, which is known\nas the docstring. In most cases, this docstring contains a quick and concise\nsummary of the object and how to use it. Python has a built-in help()\nfunction that can help you access this information. This means that nearly any\ntime you need more information, you can use help() to quickly find the\ninformation that you need.','use help()',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6043,'numpy','When it comes to the data science ecosystem, Python and NumPy are built with the\nuser in mind. One of the best examples of this is the built-in access to\ndocumentation. Every object contains the reference to a string, which is known\nas the docstring. In most cases, this docstring contains a quick and concise\nsummary of the object and how to use it. Python has a built-in help()\nfunction that can help you access this information. This means that nearly any\ntime you need more information, you can use help() to quickly find the\ninformation that you need.','find information',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6044,'numpy','Because access to additional information is so useful, IPython uses the ?\ncharacter as a shorthand for accessing this documentation along with other\nrelevant information. IPython is a command shell for interactive computing in\nmultiple languages.\nYou can find more information about IPython here.','access documentation along_with other relevant information',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6045,'numpy','Because access to additional information is so useful, IPython uses the ?\ncharacter as a shorthand for accessing this documentation along with other\nrelevant information. IPython is a command shell for interactive computing in\nmultiple languages.\nYou can find more information about IPython here.','find more information about ipython',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6046,'numpy','You can even use this notation for object methods and objects themselves.','use notation for object methods',0,'',''),(6047,'numpy','You can even use this notation for object methods and objects themselves.','use notation for objects',0,'',''),(6048,'numpy','Then you can obtain a lot of useful information (first details about a itself,\nfollowed by the docstring of ndarray of which a is an instance):','obtain lot of useful information',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6049,'numpy','This also works for functions and other objects that you create. Just\nremember to include a docstring with your function using a string literal\n(\"\"\" \"\"\" or \'\'\' \'\'\' around your documentation).','include docstring with function',0,'',''),(6050,'numpy','This also works for functions and other objects that you create. Just\nremember to include a docstring with your function using a string literal\n(\"\"\" \"\"\" or \'\'\' \'\'\' around your documentation).','use string literal',0,'',''),(6051,'numpy','For example, if you create this function:','create function',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6052,'numpy','You can obtain information about the function:','obtain information about function',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6053,'numpy','You can reach another level of information by reading the source code of the\nobject you’re interested in. Using a double question mark (??) allows you to\naccess the source code.','reach level by reading',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6054,'numpy','You can reach another level of information by reading the source code of the\nobject you’re interested in. Using a double question mark (??) allows you to\naccess the source code.','reach level of information',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6055,'numpy','You can reach another level of information by reading the source code of the\nobject you’re interested in. Using a double question mark (??) allows you to\naccess the source code.','read source code of object',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6056,'numpy','You can reach another level of information by reading the source code of the\nobject you’re interested in. Using a double question mark (??) allows you to\naccess the source code.','use double question mark',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6057,'numpy','You can reach another level of information by reading the source code of the\nobject you’re interested in. Using a double question mark (??) allows you to\naccess the source code.','access source code',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6058,'numpy','If the object in question is compiled in a language other than Python, using\n?? will return the same information as ?. You’ll find this with a lot of\nbuilt-in objects and types, for example:','use ??',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6059,'numpy','If the object in question is compiled in a language other than Python, using\n?? will return the same information as ?. You’ll find this with a lot of\nbuilt-in objects and types, for example:','compile object in language other',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6060,'numpy','If the object in question is compiled in a language other than Python, using\n?? will return the same information as ?. You’ll find this with a lot of\nbuilt-in objects and types, for example:','compile object in question',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6061,'numpy','If the object in question is compiled in a language other than Python, using\n?? will return the same information as ?. You’ll find this with a lot of\nbuilt-in objects and types, for example:','compile object than Python',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6062,'numpy','If the object in question is compiled in a language other than Python, using\n?? will return the same information as ?. You’ll find this with a lot of\nbuilt-in objects and types, for example:','return same information',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6063,'numpy','If the object in question is compiled in a language other than Python, using\n?? will return the same information as ?. You’ll find this with a lot of\nbuilt-in objects and types, for example:','find  with lot',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6064,'numpy','have the same output because they were compiled in a programming language other\nthan Python.','compile  in programming language',0,'',''),(6065,'numpy','The ease of implementing mathematical formulas that work on arrays is one of\nthe things that make NumPy so widely used in the scientific Python community.','implement mathematical formulas',0,'',''),(6066,'numpy','The ease of implementing mathematical formulas that work on arrays is one of\nthe things that make NumPy so widely used in the scientific Python community.','use  in scientific Python community',0,'',''),(6067,'numpy','You will, at some point, want to save your arrays to disk and load them back\nwithout having to re-run the code. Fortunately, there are several ways to save\nand load objects with NumPy. The ndarray objects can be saved to and loaded from\nthe disk files with loadtxt and savetxt functions that handle normal\ntext files, load and save functions that handle NumPy binary files with\na .npy file extension, and a savez function that handles NumPy files\nwith a .npz file extension.','save arrays to disk',0,'',''),(6068,'numpy','You will, at some point, want to save your arrays to disk and load them back\nwithout having to re-run the code. Fortunately, there are several ways to save\nand load objects with NumPy. The ndarray objects can be saved to and loaded from\nthe disk files with loadtxt and savetxt functions that handle normal\ntext files, load and save functions that handle NumPy binary files with\na .npy file extension, and a savez function that handles NumPy files\nwith a .npz file extension.','load  without having',0,'',''),(6069,'numpy','You will, at some point, want to save your arrays to disk and load them back\nwithout having to re-run the code. Fortunately, there are several ways to save\nand load objects with NumPy. The ndarray objects can be saved to and loaded from\nthe disk files with loadtxt and savetxt functions that handle normal\ntext files, load and save functions that handle NumPy binary files with\na .npy file extension, and a savez function that handles NumPy files\nwith a .npz file extension.','save objects with NumPy',0,'',''),(6070,'numpy','You will, at some point, want to save your arrays to disk and load them back\nwithout having to re-run the code. Fortunately, there are several ways to save\nand load objects with NumPy. The ndarray objects can be saved to and loaded from\nthe disk files with loadtxt and savetxt functions that handle normal\ntext files, load and save functions that handle NumPy binary files with\na .npy file extension, and a savez function that handles NumPy files\nwith a .npz file extension.','load objects with NumPy',0,'',''),(6071,'numpy','You will, at some point, want to save your arrays to disk and load them back\nwithout having to re-run the code. Fortunately, there are several ways to save\nand load objects with NumPy. The ndarray objects can be saved to and loaded from\nthe disk files with loadtxt and savetxt functions that handle normal\ntext files, load and save functions that handle NumPy binary files with\na .npy file extension, and a savez function that handles NumPy files\nwith a .npz file extension.','handle normal text files',0,'',''),(6072,'numpy','You will, at some point, want to save your arrays to disk and load them back\nwithout having to re-run the code. Fortunately, there are several ways to save\nand load objects with NumPy. The ndarray objects can be saved to and loaded from\nthe disk files with loadtxt and savetxt functions that handle normal\ntext files, load and save functions that handle NumPy binary files with\na .npy file extension, and a savez function that handles NumPy files\nwith a .npz file extension.','save functions',0,'',''),(6073,'numpy','You will, at some point, want to save your arrays to disk and load them back\nwithout having to re-run the code. Fortunately, there are several ways to save\nand load objects with NumPy. The ndarray objects can be saved to and loaded from\nthe disk files with loadtxt and savetxt functions that handle normal\ntext files, load and save functions that handle NumPy binary files with\na .npy file extension, and a savez function that handles NumPy files\nwith a .npz file extension.','handle NumPy binary files',0,'',''),(6074,'numpy','You will, at some point, want to save your arrays to disk and load them back\nwithout having to re-run the code. Fortunately, there are several ways to save\nand load objects with NumPy. The ndarray objects can be saved to and loaded from\nthe disk files with loadtxt and savetxt functions that handle normal\ntext files, load and save functions that handle NumPy binary files with\na .npy file extension, and a savez function that handles NumPy files\nwith a .npz file extension.','handle functions',0,'',''),(6075,'numpy','You will, at some point, want to save your arrays to disk and load them back\nwithout having to re-run the code. Fortunately, there are several ways to save\nand load objects with NumPy. The ndarray objects can be saved to and loaded from\nthe disk files with loadtxt and savetxt functions that handle normal\ntext files, load and save functions that handle NumPy binary files with\na .npy file extension, and a savez function that handles NumPy files\nwith a .npz file extension.','load ndarray objects with loadtxt savetxt functions',0,'',''),(6076,'numpy','You will, at some point, want to save your arrays to disk and load them back\nwithout having to re-run the code. Fortunately, there are several ways to save\nand load objects with NumPy. The ndarray objects can be saved to and loaded from\nthe disk files with loadtxt and savetxt functions that handle normal\ntext files, load and save functions that handle NumPy binary files with\na .npy file extension, and a savez function that handles NumPy files\nwith a .npz file extension.','load ndarray objects from disk files',0,'',''),(6077,'numpy','You will, at some point, want to save your arrays to disk and load them back\nwithout having to re-run the code. Fortunately, there are several ways to save\nand load objects with NumPy. The ndarray objects can be saved to and loaded from\nthe disk files with loadtxt and savetxt functions that handle normal\ntext files, load and save functions that handle NumPy binary files with\na .npy file extension, and a savez function that handles NumPy files\nwith a .npz file extension.','save ndarray objects',0,'',''),(6078,'numpy','You will, at some point, want to save your arrays to disk and load them back\nwithout having to re-run the code. Fortunately, there are several ways to save\nand load objects with NumPy. The ndarray objects can be saved to and loaded from\nthe disk files with loadtxt and savetxt functions that handle normal\ntext files, load and save functions that handle NumPy binary files with\na .npy file extension, and a savez function that handles NumPy files\nwith a .npz file extension.','load ndarray objects',0,'',''),(6079,'numpy','You will, at some point, want to save your arrays to disk and load them back\nwithout having to re-run the code. Fortunately, there are several ways to save\nand load objects with NumPy. The ndarray objects can be saved to and loaded from\nthe disk files with loadtxt and savetxt functions that handle normal\ntext files, load and save functions that handle NumPy binary files with\na .npy file extension, and a savez function that handles NumPy files\nwith a .npz file extension.','handle NumPy files',0,'',''),(6080,'numpy','If you want to store a single ndarray object, store it as a .npy file using\nnp.save. If you want to store more than one ndarray object in a single file,\nsave it as a .npz file using np.savez. You can also save several arrays\ninto a single file in compressed npz format with savez_compressed.','store single ndarray object',0,'',''),(6081,'numpy','If you want to store a single ndarray object, store it as a .npy file using\nnp.save. If you want to store more than one ndarray object in a single file,\nsave it as a .npz file using np.savez. You can also save several arrays\ninto a single file in compressed npz format with savez_compressed.','use np.save',0,'',''),(6082,'numpy','If you want to store a single ndarray object, store it as a .npy file using\nnp.save. If you want to store more than one ndarray object in a single file,\nsave it as a .npz file using np.savez. You can also save several arrays\ninto a single file in compressed npz format with savez_compressed.','store ndarray object in single file',0,'',''),(6083,'numpy','If you want to store a single ndarray object, store it as a .npy file using\nnp.save. If you want to store more than one ndarray object in a single file,\nsave it as a .npz file using np.savez. You can also save several arrays\ninto a single file in compressed npz format with savez_compressed.','use np.savez',0,'',''),(6084,'numpy','If you want to store a single ndarray object, store it as a .npy file using\nnp.save. If you want to store more than one ndarray object in a single file,\nsave it as a .npz file using np.savez. You can also save several arrays\ninto a single file in compressed npz format with savez_compressed.','save several arrays into single file',0,'',''),(6085,'numpy','It’s easy to save and load and array with np.save(). Just make sure to\nspecify the array you want to save and a file name. For example, if you create\nthis array:','specify array',0,'',''),(6086,'numpy','It’s easy to save and load and array with np.save(). Just make sure to\nspecify the array you want to save and a file name. For example, if you create\nthis array:','specify file name',0,'',''),(6087,'numpy','It’s easy to save and load and array with np.save(). Just make sure to\nspecify the array you want to save and a file name. For example, if you create\nthis array:','create array',0,'',''),(6088,'numpy','You can save it as “filename.npy” with:','save  as filename.npy',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6089,'numpy','You can use np.load() to reconstruct your array.','use np.load()',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6090,'numpy','If you want to check your array, you can run::','check array',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6091,'numpy','You can save a NumPy array as a plain text file like a .csv or .txt file\nwith np.savetxt.','save NumPy array as plain text file',0,'',''),(6092,'numpy','You can quickly and easily load your saved text file using loadtxt():','load saved text file',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6093,'numpy','You can quickly and easily load your saved text file using loadtxt():','use loadtxt()',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6094,'numpy','The savetxt() and loadtxt() functions accept additional optional\nparameters such as header, footer, and delimiter. While text files can be easier\nfor sharing, .npy and .npz files are smaller and faster to read. If you need more\nsophisticated handling of your text file (for example, if you need to work with\nlines that contain missing values), you will want to use the genfromtxt\nfunction.','use genfromtxt function',0,'',''),(6095,'numpy','With savetxt, you can specify headers, footers, comments, and more.','specify headers with savetxt',0,'',''),(6096,'numpy','With savetxt, you can specify headers, footers, comments, and more.','specify footers with savetxt',0,'',''),(6097,'numpy','With savetxt, you can specify headers, footers, comments, and more.','specify comments with savetxt',0,'',''),(6098,'numpy','It’s simple to read in a CSV that contains existing information. The best and\neasiest way to do this is to use\nPandas.','read  in CSV',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6099,'numpy','It’s simple to read in a CSV that contains existing information. The best and\neasiest way to do this is to use\nPandas.','use pandas',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6100,'numpy','It’s simple to use Pandas in order to export your array as well. If you are new\nto NumPy, you may want to  create a Pandas dataframe from the values in your\narray and then write the data frame to a CSV file with Pandas.','use Pandas',0,'',''),(6101,'numpy','It’s simple to use Pandas in order to export your array as well. If you are new\nto NumPy, you may want to  create a Pandas dataframe from the values in your\narray and then write the data frame to a CSV file with Pandas.','create Pandas dataframe from values',0,'',''),(6102,'numpy','It’s simple to use Pandas in order to export your array as well. If you are new\nto NumPy, you may want to  create a Pandas dataframe from the values in your\narray and then write the data frame to a CSV file with Pandas.','write data frame with pandas',0,'',''),(6103,'numpy','It’s simple to use Pandas in order to export your array as well. If you are new\nto NumPy, you may want to  create a Pandas dataframe from the values in your\narray and then write the data frame to a CSV file with Pandas.','write data frame to CSV file',0,'',''),(6104,'numpy','If you created this array “a”','create array a.',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6105,'numpy','You could create a Pandas dataframe','create Pandas dataframe',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6106,'numpy','You can easily save your dataframe with:','save dataframe',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6107,'numpy','And read your CSV with:','read CSV',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6108,'numpy','You can also save your array with the NumPy savetxt method.','save array with NumPy savetxt method',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6109,'numpy','If you’re using the command line, you can read your saved CSV any time with a\ncommand such as:','use command line',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6110,'numpy','If you’re using the command line, you can read your saved CSV any time with a\ncommand such as:','read saved CSV with command',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6111,'numpy','Or you can open the file any time with a text editor!','open file with text editor',0,'',''),(6112,'numpy','If you’re interested in learning more about Pandas, take a look at the\nofficial Pandas documentation.\nLearn how to install Pandas with the\nofficial Pandas installation information.','learn  about pandas',0,'',''),(6113,'numpy','If you’re interested in learning more about Pandas, take a look at the\nofficial Pandas documentation.\nLearn how to install Pandas with the\nofficial Pandas installation information.','install Pandas with official Pandas installation information',0,'',''),(6114,'numpy','If you need to generate a plot for your values, it’s very simple with\nMatplotlib.','generate plot for values',1,'https://numpy.org/doc/stable/user/absolute_beginners.html',''),(6115,'numpy','To read more about Matplotlib and what it can do, take a look at\nthe official documentation.\nFor directions regarding installing Matplotlib, see the official\ninstallation section.','read  about Matplotlib',0,'',''),(6116,'numpy','To read more about Matplotlib and what it can do, take a look at\nthe official documentation.\nFor directions regarding installing Matplotlib, see the official\ninstallation section.','install matplotlib',0,'',''),(6117,'numpy','User questions: The best way to get help is to post your question to a site\nlike StackOverflow, with\nthousands of users available to answer. Smaller alternatives include\nIRC,\nGitter, and\nReddit. We wish we could keep an eye on\nthese sites, or answer questions directly, but the volume is just a little\noverwhelming!','get help',0,'',''),(6118,'numpy','User questions: The best way to get help is to post your question to a site\nlike StackOverflow, with\nthousands of users available to answer. Smaller alternatives include\nIRC,\nGitter, and\nReddit. We wish we could keep an eye on\nthese sites, or answer questions directly, but the volume is just a little\noverwhelming!','include IRC',0,'',''),(6119,'numpy','User questions: The best way to get help is to post your question to a site\nlike StackOverflow, with\nthousands of users available to answer. Smaller alternatives include\nIRC,\nGitter, and\nReddit. We wish we could keep an eye on\nthese sites, or answer questions directly, but the volume is just a little\noverwhelming!','include gitter',0,'',''),(6120,'numpy','User questions: The best way to get help is to post your question to a site\nlike StackOverflow, with\nthousands of users available to answer. Smaller alternatives include\nIRC,\nGitter, and\nReddit. We wish we could keep an eye on\nthese sites, or answer questions directly, but the volume is just a little\noverwhelming!','include reddit',0,'',''),(6121,'numpy','A forum for asking usage questions, e.g. “How do I do X in NumPy?”. Please use the #numpy tag','ask usage questions',0,'',''),(6122,'numpy','A forum for asking usage questions, e.g. “How do I do X in NumPy?”. Please use the #numpy tag','use #numpy tag',0,'',''),(6123,'numpy','Not a coder? Not a problem! NumPy is multi-faceted, and we can use a lot of help.\nThese are all activities we’d like to get help with (they’re all important, so\nwe list them in alphabetical order):','use lot of help',0,'',''),(6124,'numpy','Translating content','translate content',0,'',''),(6125,'numpy','Writing technical documentation','write technical documentation',0,'',''),(6126,'numpy','The rest of this document discusses working on the NumPy code base and documentation.\nWe’re in the process of updating our descriptions of other activities and roles.\nIf you are interested in these other activities, please contact us!\nYou can do this via\nthe numpy-discussion mailing list,\nor on GitHub (open an issue or comment on a\nrelevant issue). These are our preferred communication channels (open source is open\nby nature!), however if you prefer to discuss in private first, please reach out to\nour community coordinators at numpy-team@googlegroups.com or numpy-team.slack.com (send an email to numpy-team@googlegroups.com for an\ninvite the first time).','update descriptions of other activities',0,'',''),(6127,'numpy','The rest of this document discusses working on the NumPy code base and documentation.\nWe’re in the process of updating our descriptions of other activities and roles.\nIf you are interested in these other activities, please contact us!\nYou can do this via\nthe numpy-discussion mailing list,\nor on GitHub (open an issue or comment on a\nrelevant issue). These are our preferred communication channels (open source is open\nby nature!), however if you prefer to discuss in private first, please reach out to\nour community coordinators at numpy-team@googlegroups.com or numpy-team.slack.com (send an email to numpy-team@googlegroups.com for an\ninvite the first time).','update descriptions of roles',0,'',''),(6128,'numpy','Go to https://github.com/numpy/numpy and click the\n“fork” button to create your own copy of the project.','create own copy of project',0,'',''),(6129,'numpy','Clone the project to your local computer:','clone project to local computer',1,'https://numpy.org/doc/stable/dev/index.html',''),(6130,'numpy','Change the directory:','change directory',0,'',''),(6131,'numpy','Add the upstream repository:','add upstream repository',1,'https://numpy.org/doc/stable/dev/index.html',''),(6132,'numpy','Now, git remote -v will show two remote repositories named:','show remote repositories',0,'',''),(6133,'numpy','Develop your contribution:','develop contribution',0,'',''),(6134,'numpy','Create a branch for the feature you want to work on. Since the\nbranch name will appear in the merge message, use a sensible name\nsuch as ‘linspace-speedups’:','create branch for feature',1,'https://numpy.org/doc/stable/dev/index.html',''),(6135,'numpy','Create a branch for the feature you want to work on. Since the\nbranch name will appear in the merge message, use a sensible name\nsuch as ‘linspace-speedups’:','use sensible name such_as âlinspace-speedupsâ',1,'https://numpy.org/doc/stable/dev/index.html',''),(6136,'numpy','Commit locally as you progress (git add and git commit)\nUse a properly formatted commit message,\nwrite tests that fail before your change and pass afterward, run all the\ntests locally. Be sure to document any\nchanged behavior in docstrings, keeping to the NumPy docstring\nstandard.','use formatted commit message',0,'',''),(6137,'numpy','Commit locally as you progress (git add and git commit)\nUse a properly formatted commit message,\nwrite tests that fail before your change and pass afterward, run all the\ntests locally. Be sure to document any\nchanged behavior in docstrings, keeping to the NumPy docstring\nstandard.','write tests',0,'',''),(6138,'numpy','Commit locally as you progress (git add and git commit)\nUse a properly formatted commit message,\nwrite tests that fail before your change and pass afterward, run all the\ntests locally. Be sure to document any\nchanged behavior in docstrings, keeping to the NumPy docstring\nstandard.','pass tests',0,'',''),(6139,'numpy','Commit locally as you progress (git add and git commit)\nUse a properly formatted commit message,\nwrite tests that fail before your change and pass afterward, run all the\ntests locally. Be sure to document any\nchanged behavior in docstrings, keeping to the NumPy docstring\nstandard.','run tests',0,'',''),(6140,'numpy','Commit locally as you progress (git add and git commit)\nUse a properly formatted commit message,\nwrite tests that fail before your change and pass afterward, run all the\ntests locally. Be sure to document any\nchanged behavior in docstrings, keeping to the NumPy docstring\nstandard.','document changed behavior in docstrings',0,'',''),(6141,'numpy','To submit your contribution:','submit contribution',0,'',''),(6142,'numpy','Enter your GitHub username and password (repeat contributors or advanced\nusers can remove this step by connecting to GitHub with\nSSH).','enter GitHub username',0,'',''),(6143,'numpy','Enter your GitHub username and password (repeat contributors or advanced\nusers can remove this step by connecting to GitHub with\nSSH).','enter password',0,'',''),(6144,'numpy','If your commit introduces a new feature or changes functionality, post on\nthe mailing list to explain your changes. For bug fixes, documentation\nupdates, etc., this is generally not necessary, though if you do not get\nany reaction, do feel free to ask for review.','introduce new feature',0,'',''),(6145,'numpy','If your commit introduces a new feature or changes functionality, post on\nthe mailing list to explain your changes. For bug fixes, documentation\nupdates, etc., this is generally not necessary, though if you do not get\nany reaction, do feel free to ask for review.','introduce changes',0,'',''),(6146,'numpy','If your commit introduces a new feature or changes functionality, post on\nthe mailing list to explain your changes. For bug fixes, documentation\nupdates, etc., this is generally not necessary, though if you do not get\nany reaction, do feel free to ask for review.','ask  for review',0,'',''),(6147,'numpy','Reviewers (the other developers and interested community members) will\nwrite inline and/or general comments on your Pull Request (PR) to help\nyou improve its implementation, documentation and style.  Every single\ndeveloper working on the project has their code reviewed, and we’ve come\nto see it as friendly conversation from which we all learn and the\noverall code quality benefits.  Therefore, please don’t let the review\ndiscourage you from contributing: its only aim is to improve the quality\nof project, not to criticize (we are, after all, very grateful for the\ntime you’re donating!). See our Reviewer Guidelines for more information.','write inline and/or general comments on Pull request',0,'',''),(6148,'numpy','Reviewers (the other developers and interested community members) will\nwrite inline and/or general comments on your Pull Request (PR) to help\nyou improve its implementation, documentation and style.  Every single\ndeveloper working on the project has their code reviewed, and we’ve come\nto see it as friendly conversation from which we all learn and the\noverall code quality benefits.  Therefore, please don’t let the review\ndiscourage you from contributing: its only aim is to improve the quality\nof project, not to criticize (we are, after all, very grateful for the\ntime you’re donating!). See our Reviewer Guidelines for more information.','learn friendly conversation',0,'',''),(6149,'numpy','Reviewers (the other developers and interested community members) will\nwrite inline and/or general comments on your Pull Request (PR) to help\nyou improve its implementation, documentation and style.  Every single\ndeveloper working on the project has their code reviewed, and we’ve come\nto see it as friendly conversation from which we all learn and the\noverall code quality benefits.  Therefore, please don’t let the review\ndiscourage you from contributing: its only aim is to improve the quality\nof project, not to criticize (we are, after all, very grateful for the\ntime you’re donating!). See our Reviewer Guidelines for more information.','learn overall code',0,'',''),(6150,'numpy','To update your PR, make your changes on your local repository, commit,\nrun tests, and only if they succeed push to your fork. As soon as\nthose changes are pushed up (to the same branch as before) the PR will\nupdate automatically. If you have no idea how to fix the test failures,\nyou may push your changes anyway and ask for help in a PR comment.','update PR',0,'',''),(6151,'numpy','To update your PR, make your changes on your local repository, commit,\nrun tests, and only if they succeed push to your fork. As soon as\nthose changes are pushed up (to the same branch as before) the PR will\nupdate automatically. If you have no idea how to fix the test failures,\nyou may push your changes anyway and ask for help in a PR comment.','run tests',0,'',''),(6152,'numpy','To update your PR, make your changes on your local repository, commit,\nrun tests, and only if they succeed push to your fork. As soon as\nthose changes are pushed up (to the same branch as before) the PR will\nupdate automatically. If you have no idea how to fix the test failures,\nyou may push your changes anyway and ask for help in a PR comment.','push  to fork',0,'',''),(6153,'numpy','To update your PR, make your changes on your local repository, commit,\nrun tests, and only if they succeed push to your fork. As soon as\nthose changes are pushed up (to the same branch as before) the PR will\nupdate automatically. If you have no idea how to fix the test failures,\nyou may push your changes anyway and ask for help in a PR comment.','fix test failures',0,'',''),(6154,'numpy','To update your PR, make your changes on your local repository, commit,\nrun tests, and only if they succeed push to your fork. As soon as\nthose changes are pushed up (to the same branch as before) the PR will\nupdate automatically. If you have no idea how to fix the test failures,\nyou may push your changes anyway and ask for help in a PR comment.','push changes',0,'',''),(6155,'numpy','To update your PR, make your changes on your local repository, commit,\nrun tests, and only if they succeed push to your fork. As soon as\nthose changes are pushed up (to the same branch as before) the PR will\nupdate automatically. If you have no idea how to fix the test failures,\nyou may push your changes anyway and ask for help in a PR comment.','ask  for help',0,'',''),(6156,'numpy','Various continuous integration (CI) services are triggered after each PR\nupdate to build the code, run unit tests, measure code coverage and check\ncoding style of your branch. The CI tests must pass before your PR can be\nmerged. If CI fails, you can find out why by clicking on the “failed”\nicon (red cross) and inspecting the build and test log. To avoid overuse\nand waste of this resource,\ntest your work locally before\ncommitting.','run unit tests',0,'',''),(6157,'numpy','Various continuous integration (CI) services are triggered after each PR\nupdate to build the code, run unit tests, measure code coverage and check\ncoding style of your branch. The CI tests must pass before your PR can be\nmerged. If CI fails, you can find out why by clicking on the “failed”\nicon (red cross) and inspecting the build and test log. To avoid overuse\nand waste of this resource,\ntest your work locally before\ncommitting.','check coding style of branch',0,'',''),(6158,'numpy','Various continuous integration (CI) services are triggered after each PR\nupdate to build the code, run unit tests, measure code coverage and check\ncoding style of your branch. The CI tests must pass before your PR can be\nmerged. If CI fails, you can find out why by clicking on the “failed”\nicon (red cross) and inspecting the build and test log. To avoid overuse\nand waste of this resource,\ntest your work locally before\ncommitting.','trigger various continuous integration services after PR update',0,'',''),(6159,'numpy','Various continuous integration (CI) services are triggered after each PR\nupdate to build the code, run unit tests, measure code coverage and check\ncoding style of your branch. The CI tests must pass before your PR can be\nmerged. If CI fails, you can find out why by clicking on the “failed”\nicon (red cross) and inspecting the build and test log. To avoid overuse\nand waste of this resource,\ntest your work locally before\ncommitting.','test work before committing',0,'',''),(6160,'numpy','Beyond changes to a functions docstring and possible description in the\ngeneral documentation, if your change introduces any user-facing\nmodifications they may need to be mentioned in the release notes.\nTo add your change to the release notes, you need to create a short file\nwith a summary and place it in doc/release/upcoming_changes.\nThe file doc/release/upcoming_changes/README.rst details the format and\nfilename conventions.','introduce user-facing modifications',0,'',''),(6161,'numpy','Beyond changes to a functions docstring and possible description in the\ngeneral documentation, if your change introduces any user-facing\nmodifications they may need to be mentioned in the release notes.\nTo add your change to the release notes, you need to create a short file\nwith a summary and place it in doc/release/upcoming_changes.\nThe file doc/release/upcoming_changes/README.rst details the format and\nfilename conventions.','add change to release notes',0,'',''),(6162,'numpy','Beyond changes to a functions docstring and possible description in the\ngeneral documentation, if your change introduces any user-facing\nmodifications they may need to be mentioned in the release notes.\nTo add your change to the release notes, you need to create a short file\nwith a summary and place it in doc/release/upcoming_changes.\nThe file doc/release/upcoming_changes/README.rst details the format and\nfilename conventions.','create short file with summary',0,'',''),(6163,'numpy','If your change introduces a deprecation, make sure to discuss this first on\nGitHub or the mailing list first. If agreement on the deprecation is\nreached, follow NEP 23 deprecation policy  to add the deprecation.','introduce deprecation',0,'',''),(6164,'numpy','If your change introduces a deprecation, make sure to discuss this first on\nGitHub or the mailing list first. If agreement on the deprecation is\nreached, follow NEP 23 deprecation policy  to add the deprecation.','add deprecation',0,'',''),(6165,'numpy','If your change introduces a deprecation, make sure to discuss this first on\nGitHub or the mailing list first. If agreement on the deprecation is\nreached, follow NEP 23 deprecation policy  to add the deprecation.','reach agreement on deprecation',0,'',''),(6166,'numpy','Cross referencing issues','reference issues',0,'',''),(6167,'numpy','If the PR relates to any issues, you can add the text xref gh-xxxx where\nxxxx is the number of the issue to github comments. Likewise, if the PR\nsolves an issue, replace the xref with closes, fixes or any of\nthe other flavors github accepts.','add text xref gh-xxxx',0,'',''),(6168,'numpy','If the PR relates to any issues, you can add the text xref gh-xxxx where\nxxxx is the number of the issue to github comments. Likewise, if the PR\nsolves an issue, replace the xref with closes, fixes or any of\nthe other flavors github accepts.','replace xref with closes',0,'',''),(6169,'numpy','All code should be documented.','document code',0,'',''),(6170,'numpy','No changes are ever committed without review and approval by a core\nteam member. Please ask politely on the PR or on the mailing list if you\nget no response to your pull request within a week.','get response to pull request',0,'',''),(6171,'numpy','No changes are ever committed without review and approval by a core\nteam member. Please ask politely on the PR or on the mailing list if you\nget no response to your pull request within a week.','ask  on PR',0,'',''),(6172,'numpy','No changes are ever committed without review and approval by a core\nteam member. Please ask politely on the PR or on the mailing list if you\nget no response to your pull request within a week.','ask  on mailing list',0,'',''),(6173,'numpy','Set up your editor to follow PEP 8 (remove trailing white space, no tabs, etc.).  Check code with\npyflakes / flake8.','set up editor',0,'',''),(6174,'numpy','Use NumPy data types instead of strings (np.uint8 instead of\n\"uint8\").','use NumPy data types instead_of strings',0,'',''),(6175,'numpy','Use the following import conventions:','use following import conventions',1,'https://numpy.org/doc/stable/dev/index.html',''),(6176,'numpy','Pull requests (PRs) that modify code should either have new tests, or modify existing\ntests to fail before the PR and pass afterwards. You should run the tests before pushing a PR.','modify code',0,'',''),(6177,'numpy','Pull requests (PRs) that modify code should either have new tests, or modify existing\ntests to fail before the PR and pass afterwards. You should run the tests before pushing a PR.','modify pull requests',0,'',''),(6178,'numpy','Pull requests (PRs) that modify code should either have new tests, or modify existing\ntests to fail before the PR and pass afterwards. You should run the tests before pushing a PR.','modify existing tests',0,'',''),(6179,'numpy','Pull requests (PRs) that modify code should either have new tests, or modify existing\ntests to fail before the PR and pass afterwards. You should run the tests before pushing a PR.','run tests before pushing',0,'',''),(6180,'numpy','Pull requests (PRs) that modify code should either have new tests, or modify existing\ntests to fail before the PR and pass afterwards. You should run the tests before pushing a PR.','push PR',0,'',''),(6181,'numpy','Running NumPy’s test suite locally requires some additional packages, such as\npytest and hypothesis. The additional testing dependencies are listed\nin test_requirements.txt in the top-level directory, and can conveniently\nbe installed with:','run test suite',1,'https://numpy.org/doc/stable/dev/index.html',''),(6182,'numpy','Running NumPy’s test suite locally requires some additional packages, such as\npytest and hypothesis. The additional testing dependencies are listed\nin test_requirements.txt in the top-level directory, and can conveniently\nbe installed with:','list additional testing dependencies in test_requirements.txt',1,'https://numpy.org/doc/stable/dev/index.html',''),(6183,'numpy','Running NumPy’s test suite locally requires some additional packages, such as\npytest and hypothesis. The additional testing dependencies are listed\nin test_requirements.txt in the top-level directory, and can conveniently\nbe installed with:','install additional testing dependencies',1,'https://numpy.org/doc/stable/dev/index.html',''),(6184,'numpy','This will create a report in build/coverage, which can be viewed with:','create report in build/coverage',1,'https://numpy.org/doc/stable/dev/index.html',''),(6185,'numpy','To get the appropriate dependencies and other requirements,\nsee Building the NumPy API and reference docs.','get appropriate dependencies',0,'',''),(6186,'numpy','To get the appropriate dependencies and other requirements,\nsee Building the NumPy API and reference docs.','get other requirements',0,'',''),(6187,'numpy','“citation not found: R###” There is probably an underscore after a\nreference in the first line of a docstring (e.g. [1]_). Use this\nmethod to find the source file: $ cd doc/build; grep -rin R####','use method',0,'',''),(6188,'numpy','“citation not found: R###” There is probably an underscore after a\nreference in the first line of a docstring (e.g. [1]_). Use this\nmethod to find the source file: $ cd doc/build; grep -rin R####','find source file',0,'',''),(6189,'pyAFQ','Tractography based on diffusion weighted MRI (dMRI) is used to find the major\nwhite matter fascicles (tracts) in the living human brain. The health of these\ntracts is an important factor underlying many cognitive and neurological\ndisorders.','find major white matter',0,'',''),(6190,'pyAFQ','Tissue properties may vary systematically along each tract: different\npopulations of axons enter and exit the tract, and disease can strike at local\npositions within the tract. Because of this, quantifying and understanding\ndiffusion measures along each fiber tract (the tract profile) may reveal new\ninsights into white matter development, function, and disease that are not\nobvious from mean measures of that tract ([Yeatman2012]).','enter tract',0,'',''),(6191,'pyAFQ','pyAFQ is a software package focused on automated delineation of the major\nfiber tracts in individual human brains, and quantification of the tissue\nproperties within the tracts. To learn more about the software please refer to the Table of Contents.','learn  about software',0,'',''),(6192,'pyAFQ','If you use this software in your work, please consider citing the papers that\ndescribe the method [Yeatman2012], the specific implementation [Kruper2021],\nas well as the underlying modeling and tractography implementations in DIPY [Garyfallidis2014]. If you use the RecoBundles method,\nplease also cite the original paper describing that method [Garyfallidis2018].','use software in work',0,'',''),(6193,'pyAFQ','If you use this software in your work, please consider citing the papers that\ndescribe the method [Yeatman2012], the specific implementation [Kruper2021],\nas well as the underlying modeling and tractography implementations in DIPY [Garyfallidis2014]. If you use the RecoBundles method,\nplease also cite the original paper describing that method [Garyfallidis2018].','describe method',0,'',''),(6194,'pyAFQ','If you use this software in your work, please consider citing the papers that\ndescribe the method [Yeatman2012], the specific implementation [Kruper2021],\nas well as the underlying modeling and tractography implementations in DIPY [Garyfallidis2014]. If you use the RecoBundles method,\nplease also cite the original paper describing that method [Garyfallidis2018].','describe papers',0,'',''),(6195,'pyAFQ','If you use this software in your work, please consider citing the papers that\ndescribe the method [Yeatman2012], the specific implementation [Kruper2021],\nas well as the underlying modeling and tractography implementations in DIPY [Garyfallidis2014]. If you use the RecoBundles method,\nplease also cite the original paper describing that method [Garyfallidis2018].','use RecoBundles method',0,'',''),(6196,'pyAFQ','If you use this software in your work, please consider citing the papers that\ndescribe the method [Yeatman2012], the specific implementation [Kruper2021],\nas well as the underlying modeling and tractography implementations in DIPY [Garyfallidis2014]. If you use the RecoBundles method,\nplease also cite the original paper describing that method [Garyfallidis2018].','describe method',0,'',''),(6197,'pyAFQ','Garyfallidis E, Côté MA, Rheault F, Sidhu J, Hau J, Petit L, Fortin D, Cunanne S, Descoteaux M. Recognition of white matter bundles using local and global streamline-based registration and clustering. Neuroimage. 2018 170:283-295. https://doi.org/10.1016/j.neuroimage.2017.07.015.','use local global streamline-based registration',0,'',''),(6198,'pyAFQ','Work on this software is supported through grant 1RF1MH121868-01 from the National Institutes for Mental Health / The BRAIN Initiative\nand by a grant from the\nGordon & Betty Moore Foundation,  and from the\nAlfred P. Sloan Foundation to the\nUniversity of Washington eScience Institute, by a CRCNS grant (NIH\nR01EB027585) to Eleftherios Garyfallidis and to Ariel Rokem , and by NSF grant 1551330 to Jason Yeatman.','support work through grant health initiative',0,'',''),(6199,'pyAFQ','Work on this software is supported through grant 1RF1MH121868-01 from the National Institutes for Mental Health / The BRAIN Initiative\nand by a grant from the\nGordon & Betty Moore Foundation,  and from the\nAlfred P. Sloan Foundation to the\nUniversity of Washington eScience Institute, by a CRCNS grant (NIH\nR01EB027585) to Eleftherios Garyfallidis and to Ariel Rokem , and by NSF grant 1551330 to Jason Yeatman.','support work to institute',0,'',''),(6200,'pyAFQ','Work on this software is supported through grant 1RF1MH121868-01 from the National Institutes for Mental Health / The BRAIN Initiative\nand by a grant from the\nGordon & Betty Moore Foundation,  and from the\nAlfred P. Sloan Foundation to the\nUniversity of Washington eScience Institute, by a CRCNS grant (NIH\nR01EB027585) to Eleftherios Garyfallidis and to Ariel Rokem , and by NSF grant 1551330 to Jason Yeatman.','support work on software',0,'',''),(6201,'pyAFQ','A mapping between DWI space and a template. If None, mapping will\nbe registered from data used in prepare_img. Default: None.','use  in prepare_img',0,'',''),(6202,'pyAFQ','The linear transformation to be applied to align input images to\nthe reference space before warping under the deformation field.\nDefault: None.','align input images before warping',0,'',''),(6203,'pyAFQ','The linear transformation to be applied to align input images to\nthe reference space before warping under the deformation field.\nDefault: None.','align input images to reference space',0,'',''),(6204,'pyAFQ','The linear transformation to be applied to align input images to\nthe reference space before warping under the deformation field.\nDefault: None.','apply linear transformation',0,'',''),(6205,'pyAFQ','Template to use for registration. Default: MNI T2.','use  for registration',0,'',''),(6206,'pyAFQ','Myall, Brian A. Wandell, and Heidi M. Feldman. 2012. “Tract Profiles of\nWhite Matter Properties: Automating Fiber-Tract Quantification”\nPloS One 7 (11): e49790.\n.. [R03e71c6d7dc6-Garyfallidis17] Garyfallidis et al. Recognition of white matter\nbundles using local and global streamline-based registration and\nclustering, Neuroimage, 2017.','use local global streamline-based registration',0,'',''),(6207,'pyAFQ','Prepare image data from DWI data.\nParameters\n———-\nfdata, fbval, fbvec : str','prepare image data from DWI data',0,'',''),(6208,'pyAFQ','Set mapping between DWI space and a template.\nParameters\n———-\nmapping : DiffeomorphicMap object, str or nib.Nifti1Image, optional.','set mapping between DWI space',0,'',''),(6209,'pyAFQ','Set mapping between DWI space and a template.\nParameters\n———-\nmapping : DiffeomorphicMap object, str or nib.Nifti1Image, optional.','set mapping between template',0,'',''),(6210,'pyAFQ','A mapping between DWI space and a template.\nIf None, mapping will be registered from data used in prepare_img.\nDefault: None.','use  in prepare_img',0,'',''),(6211,'pyAFQ','Classify the streamlines by whether they cross the midline.\nCreates a crosses attribute which is an array of booleans. Each boolean\ncorresponds to a streamline, and is whether or not that streamline\ncrosses the midline.\nParameters\n———-\ntg : StatefulTractogram class instance.\ntemplate : nibabel.Nifti1Image class instance','create crosses attribute',0,'',''),(6212,'pyAFQ','Get fiber probabilites and ROIs for a given bundle.','get fiber probabilites for given bundle',0,'',''),(6213,'pyAFQ','Get fiber probabilites and ROIs for a given bundle.','get rois for given bundle',0,'',''),(6214,'pyAFQ','Helper function for segment_afq, to return an empty dict under\nsome conditions.','return empty dict under conditions',0,'',''),(6215,'pyAFQ','Assign streamlines to bundles using the waypoint ROI approach\nParameters\n———-\ntg : StatefulTractogram class instance','assign streamlines to bundles',0,'',''),(6216,'pyAFQ','Assign streamlines to bundles using the waypoint ROI approach\nParameters\n———-\ntg : StatefulTractogram class instance','use waypoint ROI approach Parameters',0,'',''),(6217,'pyAFQ','Segment streamlines using the RecoBundles algorithm [Garyfallidis2017]\nParameters\n———-\ntg : StatefulTractogram class instance','use RecoBundles algorithm',0,'',''),(6218,'pyAFQ','Number of streamlines in a bundle under which we will\nnot bother with cleaning outliers. Default: 20.','clean outliers',0,'',''),(6219,'pyAFQ','The statistic of each node relative to which the Mahalanobis is\ncalculated. Default: np.mean (but can also use median, etc.)','calculate Mahalanobis',0,'',''),(6220,'pyAFQ','Clean a collection of streamlines based on their two endpoints\nFilters down to only include items that have their starting points close to\nthe targets0 and ending points close to targets1\nParameters\n———-\nstreamlines : sequence of 3XN_i arrays The collection of streamlines to','include items close_to targets0',0,'',''),(6221,'pyAFQ','Clean a collection of streamlines based on their two endpoints\nFilters down to only include items that have their starting points close to\nthe targets0 and ending points close to targets1\nParameters\n———-\nstreamlines : sequence of 3XN_i arrays The collection of streamlines to','include starting points close_to targets0',0,'',''),(6222,'pyAFQ','The targets. Numerical values in the atlas array for targets for the\nfirst and last node in each streamline respectively, or NX3 arrays with\neach row containing the indices for these locations in the atlas.\nIf provided a None, this means no restriction on that end.','provide none',0,'',''),(6223,'rcdesign','Create a separate directory and install a virtual environment. Activate the virtual environment and install required packages. On *nix systems, do the following:','create separate directory',1,'https://github.com/satish-annigeri/rcdesign','user-content-install-from-pypi'),(6224,'rcdesign','Create a separate directory and install a virtual environment. Activate the virtual environment and install required packages. On *nix systems, do the following:','install virtual environment',1,'https://github.com/satish-annigeri/rcdesign','user-content-install-from-pypi'),(6225,'rcdesign','Create a separate directory and install a virtual environment. Activate the virtual environment and install required packages. On *nix systems, do the following:','activate virtual environment',1,'https://github.com/satish-annigeri/rcdesign','user-content-install-from-pypi'),(6226,'rcdesign','Create a separate directory and install a virtual environment. Activate the virtual environment and install required packages. On *nix systems, do the following:','install required packages',1,'https://github.com/satish-annigeri/rcdesign','user-content-install-from-pypi'),(6227,'rcdesign','To install from github, clone the github repository and give it a try. If you are not familiar with the workflow for working with a source repository, follow these steps.','clone github repository',0,'',''),(6228,'rcdesign','To install from github, clone the github repository and give it a try. If you are not familiar with the workflow for working with a source repository, follow these steps.','install  from github',0,'',''),(6229,'rcdesign','Check the version of Python you are using. You will require version 3.7 or later. To print the version of Python, use the command','check version of Python',1,'https://github.com/satish-annigeri/rcdesign','user-content-preliminary-checks'),(6230,'rcdesign','Check the version of Python you are using. You will require version 3.7 or later. To print the version of Python, use the command','print version of Python',1,'https://github.com/satish-annigeri/rcdesign','user-content-preliminary-checks'),(6231,'rcdesign','Check the version of Python you are using. You will require version 3.7 or later. To print the version of Python, use the command','use command',1,'https://github.com/satish-annigeri/rcdesign','user-content-preliminary-checks'),(6232,'rcdesign','When you clone the rcdesign repository from github, a new directory named rcdesign will be created in the current working directory. Therefore change over to a suitable directory within which to clone the repository. Clone the repository using git','clone rcdesign repository from github',1,'https://github.com/satish-annigeri/rcdesign','user-content-clone-the-repository'),(6233,'rcdesign','When you clone the rcdesign repository from github, a new directory named rcdesign will be created in the current working directory. Therefore change over to a suitable directory within which to clone the repository. Clone the repository using git','create rcdesign in current working directory',1,'https://github.com/satish-annigeri/rcdesign','user-content-clone-the-repository'),(6234,'rcdesign','When you clone the rcdesign repository from github, a new directory named rcdesign will be created in the current working directory. Therefore change over to a suitable directory within which to clone the repository. Clone the repository using git','clone repository',1,'https://github.com/satish-annigeri/rcdesign','user-content-clone-the-repository'),(6235,'rcdesign','When you clone the rcdesign repository from github, a new directory named rcdesign will be created in the current working directory. Therefore change over to a suitable directory within which to clone the repository. Clone the repository using git','clone repository',1,'https://github.com/satish-annigeri/rcdesign','user-content-clone-the-repository'),(6236,'rcdesign','When you clone the rcdesign repository from github, a new directory named rcdesign will be created in the current working directory. Therefore change over to a suitable directory within which to clone the repository. Clone the repository using git','use git',1,'https://github.com/satish-annigeri/rcdesign','user-content-clone-the-repository'),(6237,'rcdesign','Change over to the directory rcdesign that is created with the command','create directory rcdesign with command',1,'https://github.com/satish-annigeri/rcdesign','user-content-clone-the-repository'),(6238,'rcdesign','List the directory contents and verify the directory structure.','list directory contents',0,'',''),(6239,'rcdesign','Create a virtual environment inside the rcdesign directory with the following command','create virtual environment inside rcdesign directory',1,'https://github.com/satish-annigeri/rcdesign','user-content-create-a-virtual-environment'),(6240,'rcdesign','Activate the virtual environment with the command','activate virtual environment with command',1,'https://github.com/satish-annigeri/rcdesign','user-content-create-a-virtual-environment'),(6241,'rcdesign','Install additional packages required to run tests.','run tests',1,'https://github.com/satish-annigeri/rcdesign','user-content-run-tests'),(6242,'rcdesign','Check code coverage.','check code coverage',0,'',''),(6243,'rcdesign','You can also use nox to run the tests. Install nox using pip, if necessary.','use nox',1,'https://github.com/satish-annigeri/rcdesign','user-content-run-tests'),(6244,'rcdesign','You can also use nox to run the tests. Install nox using pip, if necessary.','run tests',1,'https://github.com/satish-annigeri/rcdesign','user-content-run-tests'),(6245,'rcdesign','You can also use nox to run the tests. Install nox using pip, if necessary.','use pip',1,'https://github.com/satish-annigeri/rcdesign','user-content-run-tests'),(6246,'rcdesign','When you are done using the virtual environment, you can deactivate it with the command deactivate at the command prompt in all operating systems.','use virtual environment',0,'',''),(6247,'rcdesign','When you are done using the virtual environment, you can deactivate it with the command deactivate at the command prompt in all operating systems.','deactivate  with command deactivate',0,'',''),(6248,'rcdesign','When you are done using the virtual environment, you can deactivate it with the command deactivate at the command prompt in all operating systems.','deactivate  at command prompt',0,'',''),(6249,'rcdesign','Alternately, you can create the following Python script example.py, which is in fact the first example in the __main__.py file of the rcdesign package (the built-in example), and run the script.','create following Python script example.py',1,'https://github.com/satish-annigeri/rcdesign','user-content-your-own-example'),(6250,'rcdesign','Alternately, you can create the following Python script example.py, which is in fact the first example in the __main__.py file of the rcdesign package (the built-in example), and run the script.','run script',1,'https://github.com/satish-annigeri/rcdesign','user-content-your-own-example'),(6251,'rcdesign','Check the output.','check output',0,'',''),(6252,'rcdesign','Rectangular and flanged sections must be of a given grade of concrete. Main (longitudinal) reinforcement to resist bending must be provided as a single group of reinforcement layers, possibly with one or more layers in the compression zone in addition to one or more layers in the tension zone. However, since the position of the neutral axis is dependent on the section size and the amount and location of main reinforcement, whether a layer of reinforcement lies in the tension zone or the compression zone will be known after an analysis of the section.','provide main reinforcement with layers',0,'',''),(6253,'rcdesign','Rectangular and flanged sections must be of a given grade of concrete. Main (longitudinal) reinforcement to resist bending must be provided as a single group of reinforcement layers, possibly with one or more layers in the compression zone in addition to one or more layers in the tension zone. However, since the position of the neutral axis is dependent on the section size and the amount and location of main reinforcement, whether a layer of reinforcement lies in the tension zone or the compression zone will be known after an analysis of the section.','provide main reinforcement as single group',0,'',''),(6254,'rcdesign','Rectangular and flanged sections must be of a given grade of concrete. Main (longitudinal) reinforcement to resist bending must be provided as a single group of reinforcement layers, possibly with one or more layers in the compression zone in addition to one or more layers in the tension zone. However, since the position of the neutral axis is dependent on the section size and the amount and location of main reinforcement, whether a layer of reinforcement lies in the tension zone or the compression zone will be known after an analysis of the section.','provide main reinforcement to layers',0,'',''),(6255,'rcdesign','The following classes have been implemented:','implement following classes',0,'',''),(6256,'rcdesign','Following funcationality has been implemented for the different classes:','implement  for different classes',0,'',''),(6257,'rcdesign','These are implemented for both the following cases:','implement  for following cases',0,'',''),(6258,'rcdesign','RebarGroup: Calculation of the sum of the following values aggregated after calculating the values individually for each layer:','calculate values for layer',0,'',''),(6259,'rcdesign','Testing  has been implemented using pytest and unit tests have been implemented for the following classes:','implement pytest unit tests for following classes',0,'',''),(6260,'rcdesign','Testing  has been implemented using pytest and unit tests have been implemented for the following classes:','implement testing',0,'',''),(6261,'rcdesign','Code coverage through tests using pytest-cov at the current time is 100%, excepting the example script and the methods that implement __repe__() and report().','implement __repe__()',0,'',''),(6262,'rcdesign','Code coverage through tests using pytest-cov at the current time is 100%, excepting the example script and the methods that implement __repe__() and report().','implement report()',0,'',''),(6263,'rcdesign','Code coverage through tests using pytest-cov at the current time is 100%, excepting the example script and the methods that implement __repe__() and report().','implement methods',0,'',''),(6264,'rcdesign','Analysis of rectangular and flanged beam sections with and without compression reinforcement, for flexure and shear, has been completed. Several examples have been solved and verified by hand to consider different cases.','complete analysis of rectangular flanged beam sections',0,'',''),(6265,'rcdesign','Analysis of rectangular and flanged beam sections with and without compression reinforcement, for flexure and shear, has been completed. Several examples have been solved and verified by hand to consider different cases.','complete analysis for shear',0,'',''),(6266,'rcdesign','Analysis of rectangular and flanged beam sections with and without compression reinforcement, for flexure and shear, has been completed. Several examples have been solved and verified by hand to consider different cases.','complete analysis for flexure',0,'',''),(6267,'rcdesign','Analysis of rectangular column sections for combined axial compression and bending about one axis has been completed. An example has been solved and verified by hand.','complete analysis of rectangular',0,'',''),(6268,'rcdesign','Analysis of rectangular column sections for combined axial compression and bending about one axis has been completed. An example has been solved and verified by hand.','complete analysis of bending',0,'',''),(6269,'rcdesign','Automated testing can be done using. Check to ensure that nox is installed using the command','use command',1,'https://github.com/satish-annigeri/rcdesign','user-content-testing'),(6270,'rcdesign','Automated testing can be done using. Check to ensure that nox is installed using the command','install nox',1,'https://github.com/satish-annigeri/rcdesign','user-content-testing'),(6271,'rcdesign','If required, install nox with the command:','install nox with command',1,'https://github.com/satish-annigeri/rcdesign','user-content-testing'),(6272,'rcdesign','Immediate plans include the design of sections:','include design of sections',0,'',''),(6273,'rcdesign','Create a separate directory and install a virtual environment. Activate the virtual environment and install required packages. On *nix systems, do the following:','create separate directory',1,'https://github.com/satish-annigeri/rcdesign','user-content-install-from-pypi'),(6274,'rcdesign','Create a separate directory and install a virtual environment. Activate the virtual environment and install required packages. On *nix systems, do the following:','install virtual environment',1,'https://github.com/satish-annigeri/rcdesign','user-content-install-from-pypi'),(6275,'rcdesign','Create a separate directory and install a virtual environment. Activate the virtual environment and install required packages. On *nix systems, do the following:','activate virtual environment',1,'https://github.com/satish-annigeri/rcdesign','user-content-install-from-pypi'),(6276,'rcdesign','Create a separate directory and install a virtual environment. Activate the virtual environment and install required packages. On *nix systems, do the following:','install required packages',1,'https://github.com/satish-annigeri/rcdesign','user-content-install-from-pypi'),(6277,'rcdesign','To install from github, clone the github repository and give it a try. If you are not familiar with the workflow for working with a source repository, follow these steps.','clone github repository',0,'',''),(6278,'rcdesign','To install from github, clone the github repository and give it a try. If you are not familiar with the workflow for working with a source repository, follow these steps.','install  from github',0,'',''),(6279,'rcdesign','Check the version of Python you are using. You will require version 3.7 or later. To print the version of Python, use the command','check version of Python',1,'https://github.com/satish-annigeri/rcdesign','user-content-preliminary-checks'),(6280,'rcdesign','Check the version of Python you are using. You will require version 3.7 or later. To print the version of Python, use the command','print version of Python',1,'https://github.com/satish-annigeri/rcdesign','user-content-preliminary-checks'),(6281,'rcdesign','Check the version of Python you are using. You will require version 3.7 or later. To print the version of Python, use the command','use command',1,'https://github.com/satish-annigeri/rcdesign','user-content-preliminary-checks'),(6282,'rcdesign','When you clone the rcdesign repository from github, a new directory named rcdesign will be created in the current working directory. Therefore change over to a suitable directory within which to clone the repository. Clone the repository using git','clone rcdesign repository from github',1,'https://github.com/satish-annigeri/rcdesign','user-content-clone-the-repository'),(6283,'rcdesign','When you clone the rcdesign repository from github, a new directory named rcdesign will be created in the current working directory. Therefore change over to a suitable directory within which to clone the repository. Clone the repository using git','create rcdesign in current working directory',1,'https://github.com/satish-annigeri/rcdesign','user-content-clone-the-repository'),(6284,'rcdesign','When you clone the rcdesign repository from github, a new directory named rcdesign will be created in the current working directory. Therefore change over to a suitable directory within which to clone the repository. Clone the repository using git','clone repository',1,'https://github.com/satish-annigeri/rcdesign','user-content-clone-the-repository'),(6285,'rcdesign','When you clone the rcdesign repository from github, a new directory named rcdesign will be created in the current working directory. Therefore change over to a suitable directory within which to clone the repository. Clone the repository using git','clone repository',1,'https://github.com/satish-annigeri/rcdesign','user-content-clone-the-repository'),(6286,'rcdesign','When you clone the rcdesign repository from github, a new directory named rcdesign will be created in the current working directory. Therefore change over to a suitable directory within which to clone the repository. Clone the repository using git','use git',1,'https://github.com/satish-annigeri/rcdesign','user-content-clone-the-repository'),(6287,'rcdesign','Change over to the directory rcdesign that is created with the command','create directory rcdesign with command',1,'https://github.com/satish-annigeri/rcdesign','user-content-clone-the-repository'),(6288,'rcdesign','List the directory contents and verify the directory structure.','list directory contents',0,'',''),(6289,'rcdesign','Create a virtual environment inside the rcdesign directory with the following command','create virtual environment inside rcdesign directory',1,'https://github.com/satish-annigeri/rcdesign','user-content-create-a-virtual-environment'),(6290,'rcdesign','Activate the virtual environment with the command','activate virtual environment with command',1,'https://github.com/satish-annigeri/rcdesign','user-content-create-a-virtual-environment'),(6291,'rcdesign','Install additional packages required to run tests.','run tests',1,'https://github.com/satish-annigeri/rcdesign','user-content-run-tests'),(6292,'rcdesign','Check code coverage.','check code coverage',0,'',''),(6293,'rcdesign','You can also use nox to run the tests. Install nox using pip, if necessary.','use nox',1,'https://github.com/satish-annigeri/rcdesign','user-content-run-tests'),(6294,'rcdesign','You can also use nox to run the tests. Install nox using pip, if necessary.','run tests',1,'https://github.com/satish-annigeri/rcdesign','user-content-run-tests'),(6295,'rcdesign','You can also use nox to run the tests. Install nox using pip, if necessary.','use pip',1,'https://github.com/satish-annigeri/rcdesign','user-content-run-tests'),(6296,'rcdesign','When you are done using the virtual environment, you can deactivate it with the command deactivate at the command prompt in all operating systems.','use virtual environment',0,'',''),(6297,'rcdesign','When you are done using the virtual environment, you can deactivate it with the command deactivate at the command prompt in all operating systems.','deactivate  with command deactivate',0,'',''),(6298,'rcdesign','When you are done using the virtual environment, you can deactivate it with the command deactivate at the command prompt in all operating systems.','deactivate  at command prompt',0,'',''),(6299,'rcdesign','Alternately, you can create the following Python script example.py, which is in fact the first example in the __main__.py file of the rcdesign package (the built-in example), and run the script.','create following Python script example.py',1,'https://github.com/satish-annigeri/rcdesign','user-content-your-own-example'),(6300,'rcdesign','Alternately, you can create the following Python script example.py, which is in fact the first example in the __main__.py file of the rcdesign package (the built-in example), and run the script.','run script',1,'https://github.com/satish-annigeri/rcdesign','user-content-your-own-example'),(6301,'rcdesign','Check the output.','check output',0,'',''),(6302,'rcdesign','Rectangular and flanged sections must be of a given grade of concrete. Main (longitudinal) reinforcement to resist bending must be provided as a single group of reinforcement layers, possibly with one or more layers in the compression zone in addition to one or more layers in the tension zone. However, since the position of the neutral axis is dependent on the section size and the amount and location of main reinforcement, whether a layer of reinforcement lies in the tension zone or the compression zone will be known after an analysis of the section.','provide main reinforcement with layers',0,'',''),(6303,'rcdesign','Rectangular and flanged sections must be of a given grade of concrete. Main (longitudinal) reinforcement to resist bending must be provided as a single group of reinforcement layers, possibly with one or more layers in the compression zone in addition to one or more layers in the tension zone. However, since the position of the neutral axis is dependent on the section size and the amount and location of main reinforcement, whether a layer of reinforcement lies in the tension zone or the compression zone will be known after an analysis of the section.','provide main reinforcement as single group',0,'',''),(6304,'rcdesign','Rectangular and flanged sections must be of a given grade of concrete. Main (longitudinal) reinforcement to resist bending must be provided as a single group of reinforcement layers, possibly with one or more layers in the compression zone in addition to one or more layers in the tension zone. However, since the position of the neutral axis is dependent on the section size and the amount and location of main reinforcement, whether a layer of reinforcement lies in the tension zone or the compression zone will be known after an analysis of the section.','provide main reinforcement to layers',0,'',''),(6305,'rcdesign','The following classes have been implemented:','implement following classes',0,'',''),(6306,'rcdesign','Following funcationality has been implemented for the different classes:','implement  for different classes',0,'',''),(6307,'rcdesign','These are implemented for both the following cases:','implement  for following cases',0,'',''),(6308,'rcdesign','RebarGroup: Calculation of the sum of the following values aggregated after calculating the values individually for each layer:','calculate values for layer',0,'',''),(6309,'rcdesign','Testing  has been implemented using pytest and unit tests have been implemented for the following classes:','implement pytest unit tests for following classes',0,'',''),(6310,'rcdesign','Testing  has been implemented using pytest and unit tests have been implemented for the following classes:','implement testing',0,'',''),(6311,'rcdesign','Code coverage through tests using pytest-cov at the current time is 100%, excepting the example script and the methods that implement __repe__() and report().','implement __repe__()',0,'',''),(6312,'rcdesign','Code coverage through tests using pytest-cov at the current time is 100%, excepting the example script and the methods that implement __repe__() and report().','implement report()',0,'',''),(6313,'rcdesign','Code coverage through tests using pytest-cov at the current time is 100%, excepting the example script and the methods that implement __repe__() and report().','implement methods',0,'',''),(6314,'rcdesign','Analysis of rectangular and flanged beam sections with and without compression reinforcement, for flexure and shear, has been completed. Several examples have been solved and verified by hand to consider different cases.','complete analysis of rectangular flanged beam sections',0,'',''),(6315,'rcdesign','Analysis of rectangular and flanged beam sections with and without compression reinforcement, for flexure and shear, has been completed. Several examples have been solved and verified by hand to consider different cases.','complete analysis for shear',0,'',''),(6316,'rcdesign','Analysis of rectangular and flanged beam sections with and without compression reinforcement, for flexure and shear, has been completed. Several examples have been solved and verified by hand to consider different cases.','complete analysis for flexure',0,'',''),(6317,'rcdesign','Analysis of rectangular column sections for combined axial compression and bending about one axis has been completed. An example has been solved and verified by hand.','complete analysis of rectangular',0,'',''),(6318,'rcdesign','Analysis of rectangular column sections for combined axial compression and bending about one axis has been completed. An example has been solved and verified by hand.','complete analysis of bending',0,'',''),(6319,'rcdesign','Automated testing can be done using. Check to ensure that nox is installed using the command','use command',1,'https://github.com/satish-annigeri/rcdesign','user-content-testing'),(6320,'rcdesign','Automated testing can be done using. Check to ensure that nox is installed using the command','install nox',1,'https://github.com/satish-annigeri/rcdesign','user-content-testing'),(6321,'rcdesign','If required, install nox with the command:','install nox with command',1,'https://github.com/satish-annigeri/rcdesign','user-content-testing'),(6322,'rcdesign','Immediate plans include the design of sections:','include design of sections',0,'',''),(6323,'Bpmn-visualization','This repository contains examples showing how to use bpmn-visualization.','use bpmn-visualization',0,'',''),(6324,'Bpmn-visualization','Some examples require loading local files. If you are looking for BPMN diagram files, you can use resources from:','load local files',0,'',''),(6325,'Bpmn-visualization','Some examples require loading local files. If you are looking for BPMN diagram files, you can use resources from:','use resources',0,'',''),(6326,'Bpmn-visualization','Some examples and demos may load ES Modules; in that case, you cannot open html pages directly from your local disk.','load ES modules',0,'',''),(6327,'Bpmn-visualization','For instance, on Chrome, the Console would display the following errors','display following errors for instance',0,'',''),(6328,'Bpmn-visualization','For instance, on Chrome, the Console would display the following errors','display following errors on chrome',0,'',''),(6329,'Bpmn-visualization','Access to script at \'file:///...../bpmn-visualization-examples/examples/my-file.js\' from origin \'null\' has been\nblocked by CORS policy: Cross origin requests are only supported for protocol schemes: http, data, chrome,\nchrome-extension, https. index.html:1\nFailed to load resource: net::ERR_FAILED utils.js:1','support cross origin requests for protocol schemes',0,'',''),(6330,'Bpmn-visualization','Access to script at \'file:///...../bpmn-visualization-examples/examples/my-file.js\' from origin \'null\' has been\nblocked by CORS policy: Cross origin requests are only supported for protocol schemes: http, data, chrome,\nchrome-extension, https. index.html:1\nFailed to load resource: net::ERR_FAILED utils.js:1','load resource',0,'',''),(6331,'Bpmn-visualization','To access such examples, you need to run a local web server and then access the examples via the http protocol.\nWe advise to make the local web server serve the whole repository, to also be able to access to the demo (resources available\nin the ./demo folder).','access such examples',0,'',''),(6332,'Bpmn-visualization','To access such examples, you need to run a local web server and then access the examples via the http protocol.\nWe advise to make the local web server serve the whole repository, to also be able to access to the demo (resources available\nin the ./demo folder).','run local web server',0,'',''),(6333,'Bpmn-visualization','To access such examples, you need to run a local web server and then access the examples via the http protocol.\nWe advise to make the local web server serve the whole repository, to also be able to access to the demo (resources available\nin the ./demo folder).','access examples via http protocol',0,'',''),(6334,'Bpmn-visualization','To access such examples, you need to run a local web server and then access the examples via the http protocol.\nWe advise to make the local web server serve the whole repository, to also be able to access to the demo (resources available\nin the ./demo folder).','access  to demo',0,'',''),(6335,'Bpmn-visualization','Some examples are provided for direct use in the web browser. If you want to integrate their related code in a project, adaptations may be required.','provide examples for direct use',0,'',''),(6336,'Bpmn-visualization','Some examples are provided for direct use in the web browser. If you want to integrate their related code in a project, adaptations may be required.','integrate related code in project',0,'',''),(6337,'Bpmn-visualization','You can check the examples projects in this repository or the Live IDE examples to know how to bootstrap bpmn-visualization in a project.','check examples projects in repository',0,'',''),(6338,'Bpmn-visualization','You can check the examples projects in this repository or the Live IDE examples to know how to bootstrap bpmn-visualization in a project.','check examples projects in live IDE examples',0,'',''),(6339,'Bpmn-visualization','TypeScript\'s users should also read the paragraph about the TypeScript support in the bpmn-visualization README\nespecially when using bpmn-visualization prior version 0.27.0.','read paragraph about TypeScript support',0,'',''),(6340,'Bpmn-visualization','TypeScript\'s users should also read the paragraph about the TypeScript support in the bpmn-visualization README\nespecially when using bpmn-visualization prior version 0.27.0.','use bpmn-visualization prior version 0.27.0',0,'',''),(6341,'Bpmn-visualization','DISCLAIMER: extension points are currently very experimental and are subject to change.\nThey are mainly hacks to let you see what will be later available in a more integrated way. \nCustom BPMN Theme features will be progressively added to bpmn-visualization. See the Extensions Milestone.','add custom BPMN theme features to bpmn-visualization',0,'',''),(6342,'Bpmn-visualization','Show how to integrate bpmn-visualization in project, using various kind of build tools and bundlers:','integrate bpmn-visualization in project',0,'',''),(6343,'Bpmn-visualization','Show how to integrate bpmn-visualization in project, using various kind of build tools and bundlers:','use various kind',0,'',''),(6344,'Bpmn-visualization','To contribute to bpmn-visualization-examples, fork and clone this repository locally and commit your code on a separate branch. \nPlease add a screenshot of the new rendering when you open a pull-request.','add screenshot of new rendering',0,'',''),(6345,'Bpmn-visualization','To contribute to bpmn-visualization-examples, fork and clone this repository locally and commit your code on a separate branch. \nPlease add a screenshot of the new rendering when you open a pull-request.','open pull-request',0,'',''),(6346,'Bpmn-visualization','You can find more detail in our Contributing guide. Participation in this open source project is subject to a Code of Conduct.','find more detail in contributing guide',0,'',''),(6347,'Bpmn-visualization','bpmn-visualization-examples is released under the Apache 2.0 license. \nCopyright © 2020-present, Bonitasoft S.A.','release bpmn-visualization-examples under apache 2.0 license',0,'',''),(6348,'Bpmn-visualization','The extensions panel on Gitpod when opening this PR. The extensions are not sync with the Gitpod user settings letting us to improve the settings iteratively and without impacting the existing settings of the user.','open PR',0,'',''),(6349,'Bpmn-visualization','Please check the ⏩ live environment.','check â© live environment',0,'',''),(6350,'Bpmn-visualization','You will find there basic usage as well as detailed examples showing possible rendering customizations.','find basic usage',0,'',''),(6351,'Bpmn-visualization','You will find there basic usage as well as detailed examples showing possible rendering customizations.','find detailed examples',0,'',''),(6352,'Bpmn-visualization','You will find there basic usage as well as detailed examples showing possible rendering customizations.','show possible rendering customizations',0,'',''),(6353,'Bpmn-visualization','bpmn-visualization is actively developed and maintained.','develop bpmn-visualization',0,'',''),(6354,'Bpmn-visualization','Before the release of version 1.0.0, there may be some breaking changes. We avoid these as much as possible, and carefully document them in the release notes.\nAs far as possible, we maintain compatibility for some minor versions.','document  in release notes',0,'',''),(6355,'Bpmn-visualization','The library is available from NPM. \nWe support various module formats such as:','support various module formats',0,'',''),(6356,'Bpmn-visualization','Then use this snippet to load your BPMN diagram in a page:','use snippet',1,'https://github.com/process-analytics/bpmn-visualization-js.git','user-content--project-usage'),(6357,'Bpmn-visualization','Then use this snippet to load your BPMN diagram in a page:','load BPMN',1,'https://github.com/process-analytics/bpmn-visualization-js.git','user-content--project-usage'),(6358,'Bpmn-visualization','The bpmn-visualization npm package includes type definitions, so the integration works out of the box in TypeScript projects.\nbpmn-visualization requires TypeScript 4.5 or greater.','include type definitions',0,'',''),(6359,'Bpmn-visualization','ℹ️ If you are looking for examples of projects integrating bpmn-visualization with TypeScript, see the bpmn-visualization-examples repository.','integrate bpmn-visualization with TypeScript',0,'',''),(6360,'Bpmn-visualization','To contribute to bpmn-visualization, fork and clone this repository locally and commit your code on a separate branch.\nPlease write tests for your code before opening a pull-request:','write tests before opening',1,'https://github.com/process-analytics/bpmn-visualization-js.git','user-content--contributing'),(6361,'Bpmn-visualization','To contribute to bpmn-visualization, fork and clone this repository locally and commit your code on a separate branch.\nPlease write tests for your code before opening a pull-request:','write tests for code',1,'https://github.com/process-analytics/bpmn-visualization-js.git','user-content--contributing'),(6362,'Bpmn-visualization','To contribute to bpmn-visualization, fork and clone this repository locally and commit your code on a separate branch.\nPlease write tests for your code before opening a pull-request:','open pull-request',1,'https://github.com/process-analytics/bpmn-visualization-js.git','user-content--contributing'),(6363,'Bpmn-visualization','bpmn-visualization is released under the Apache 2.0 license.\nCopyright © 2020-present, Bonitasoft S.A.','release bpmn-visualization under apache 2.0 license',0,'',''),(6364,'Bpmn-visualization','🔗 Release Notes','release Notes',0,'',''),(6365,'Bpmn-visualization','Prettier now switches to using the resolve module for resolving configuration files and plugins if it detects that require.resolve isn\'t Node\'s builtin function (doesn\'t support the second argument), which happens in environments like editor extensions. To force the fallback, set the PRETTIER_FALLBACK_RESOLVE environment variable to true.','use resolve module for resolving',0,'',''),(6366,'Bpmn-visualization','Prettier now switches to using the resolve module for resolving configuration files and plugins if it detects that require.resolve isn\'t Node\'s builtin function (doesn\'t support the second argument), which happens in environments like editor extensions. To force the fallback, set the PRETTIER_FALLBACK_RESOLVE environment variable to true.','resolve configuration files',0,'',''),(6367,'Bpmn-visualization','Prettier now switches to using the resolve module for resolving configuration files and plugins if it detects that require.resolve isn\'t Node\'s builtin function (doesn\'t support the second argument), which happens in environments like editor extensions. To force the fallback, set the PRETTIER_FALLBACK_RESOLVE environment variable to true.','resolve plugins',0,'',''),(6368,'Bpmn-visualization','Prettier now switches to using the resolve module for resolving configuration files and plugins if it detects that require.resolve isn\'t Node\'s builtin function (doesn\'t support the second argument), which happens in environments like editor extensions. To force the fallback, set the PRETTIER_FALLBACK_RESOLVE environment variable to true.','force fallback',0,'',''),(6369,'Bpmn-visualization','Prettier now switches to using the resolve module for resolving configuration files and plugins if it detects that require.resolve isn\'t Node\'s builtin function (doesn\'t support the second argument), which happens in environments like editor extensions. To force the fallback, set the PRETTIER_FALLBACK_RESOLVE environment variable to true.','set PRETTIER_FALLBACK_RESOLVE environment variable to true',0,'',''),(6370,'Bpmn-visualization','This version was pushed to npm by thorn0, a new releaser for prettier since your current version.','push version',0,'',''),(6371,'Bpmn-visualization','Dependabot will resolve any conflicts with this PR as long as you don\'t alter it yourself. You can also trigger a rebase manually by commenting @dependabot rebase.','resolve conflicts with PR',0,'',''),(6372,'Bpmn-visualization','Dependabot will resolve any conflicts with this PR as long as you don\'t alter it yourself. You can also trigger a rebase manually by commenting @dependabot rebase.','trigger rebase by commenting',0,'',''),(6373,'Bpmn-visualization','You can trigger Dependabot actions by commenting on this PR:','trigger Dependabot actions by commenting',0,'',''),(6374,'Bpmn-visualization','This allows people who are used to reading changelog files to know where to find the bpmn-visualization release notes.','read changelog files',0,'',''),(6375,'Bpmn-visualization','This allows people who are used to reading changelog files to know where to find the bpmn-visualization release notes.','find bpmn-visualization release notes',0,'',''),(6376,'Bpmn-visualization','This allows people who are used to reading changelog files to know where to find the bpmn-visualization release notes.','use people to reading',0,'',''),(6377,'Bpmn-visualization','Reuse the image from the examples repository.','reuse image from examples repository',0,'',''),(6378,'Bpmn-visualization','Previously, calling BpmnElementsRegistry.getElementsByIds generated error when the HTML BPMN container has no id.\nWhen using framework like Svelte or Angular, the container doesn\'t have such id, so it prevented to use the API out of the box.','generate error',0,'',''),(6379,'Bpmn-visualization','Previously, calling BpmnElementsRegistry.getElementsByIds generated error when the HTML BPMN container has no id.\nWhen using framework like Svelte or Angular, the container doesn\'t have such id, so it prevented to use the API out of the box.','use framework like Svelte',0,'',''),(6380,'Bpmn-visualization','Previously, calling BpmnElementsRegistry.getElementsByIds generated error when the HTML BPMN container has no id.\nWhen using framework like Svelte or Angular, the container doesn\'t have such id, so it prevented to use the API out of the box.','use framework like angular',0,'',''),(6381,'Bpmn-visualization','Previously, calling BpmnElementsRegistry.getElementsByIds generated error when the HTML BPMN container has no id.\nWhen using framework like Svelte or Angular, the container doesn\'t have such id, so it prevented to use the API out of the box.','use API out_of box',0,'',''),(6382,'Bpmn-visualization','The CSS selector that retrieves the HTML elements has been simplified to not use the id.','retrieve HTML elements',0,'',''),(6383,'Bpmn-visualization','The CSS selector that retrieves the HTML elements has been simplified to not use the id.','retrieve CSS selector',0,'',''),(6384,'Bpmn-visualization','The \"elements-identification\" demo has been updated to use a BPMN container without id.\nPrior, the fix, it reproduced the issue when calling the registry API','use BPMN container without id',1,'https://github.com/process-analytics/bpmn-visualization-js/pull/2282',''),(6385,'Bpmn-visualization','The \"elements-identification\" demo has been updated to use a BPMN container without id.\nPrior, the fix, it reproduced the issue when calling the registry API','call registry API',1,'https://github.com/process-analytics/bpmn-visualization-js/pull/2282',''),(6386,'Bpmn-visualization','The drag\'n drop code was only able to manage container with id. It has been updated to support container without id as well.','manage container with id',0,'',''),(6387,'Bpmn-visualization','The drag\'n drop code was only able to manage container with id. It has been updated to support container without id as well.','support container without id',0,'',''),(6388,'Bpmn-visualization','The bug is reproduced with the first commit (new integration test): df2c5d6\nAdditional tests were added to reproduce the issue with the BpmnElementsRegistry API: 53a42bd\nThe elements-identification.html demo was updated to also reproduce the problem: 8946525','add     df2c5d6    additional tests',0,'',''),(6389,'Bpmn-visualization','At first glance, this looks good. I have provided minor remarks about naming.','provide minor remarks about naming',0,'',''),(6390,'Bpmn-visualization','The current integration tests reproduce the problem but not in the context of the issue.\nThey involve HtmlElementLookup which is a test utility and which uses the code that contains the problem (BpmnQuerySelectors). But this utility uses BpmnQuerySelectors  only to avoid duplication with the production code\nIts implementation may change (We could use a completely different implementation to do the lookup that doesn\'t rely on the production code) and in that case, the tests won\'t cover anything.  The div tests have been created to ensure that the BPMN elements are created in the DOM not to test the BpmnElementsRegistry API.','use code',0,'',''),(6391,'Bpmn-visualization','The current integration tests reproduce the problem but not in the context of the issue.\nThey involve HtmlElementLookup which is a test utility and which uses the code that contains the problem (BpmnQuerySelectors). But this utility uses BpmnQuerySelectors  only to avoid duplication with the production code\nIts implementation may change (We could use a completely different implementation to do the lookup that doesn\'t rely on the production code) and in that case, the tests won\'t cover anything.  The div tests have been created to ensure that the BPMN elements are created in the DOM not to test the BpmnElementsRegistry API.','use BpmnQuerySelectors',0,'',''),(6392,'Bpmn-visualization','The current integration tests reproduce the problem but not in the context of the issue.\nThey involve HtmlElementLookup which is a test utility and which uses the code that contains the problem (BpmnQuerySelectors). But this utility uses BpmnQuerySelectors  only to avoid duplication with the production code\nIts implementation may change (We could use a completely different implementation to do the lookup that doesn\'t rely on the production code) and in that case, the tests won\'t cover anything.  The div tests have been created to ensure that the BPMN elements are created in the DOM not to test the BpmnElementsRegistry API.','change production code',0,'',''),(6393,'Bpmn-visualization','The current integration tests reproduce the problem but not in the context of the issue.\nThey involve HtmlElementLookup which is a test utility and which uses the code that contains the problem (BpmnQuerySelectors). But this utility uses BpmnQuerySelectors  only to avoid duplication with the production code\nIts implementation may change (We could use a completely different implementation to do the lookup that doesn\'t rely on the production code) and in that case, the tests won\'t cover anything.  The div tests have been created to ensure that the BPMN elements are created in the DOM not to test the BpmnElementsRegistry API.','create BPMN elements in DOM',0,'',''),(6394,'Bpmn-visualization','The current integration tests reproduce the problem but not in the context of the issue.\nThey involve HtmlElementLookup which is a test utility and which uses the code that contains the problem (BpmnQuerySelectors). But this utility uses BpmnQuerySelectors  only to avoid duplication with the production code\nIts implementation may change (We could use a completely different implementation to do the lookup that doesn\'t rely on the production code) and in that case, the tests won\'t cover anything.  The div tests have been created to ensure that the BPMN elements are created in the DOM not to test the BpmnElementsRegistry API.','create div tests',0,'',''),(6395,'Bpmn-visualization','In addition, the current integration tests are white/gray box tests as it knows that the implementation uses BpmnQuerySelectors. So, it is not easy to understand what is the problem under the hood. Black box tests, direcly involving BpmnElementsRegistry, would have been more understandable.','use BpmnQuerySelectors',0,'',''),(6396,'Bpmn-visualization','I am not saying that we should remove the existing integration tests.\nBut, IHMO we should add new tests on the BpmnElementsRegistry, so in dom.bpmn.elements.test.ts.','remove existing integration tests',0,'',''),(6397,'Bpmn-visualization','I am not saying that we should remove the existing integration tests.\nBut, IHMO we should add new tests on the BpmnElementsRegistry, so in dom.bpmn.elements.test.ts.','add new tests on BpmnElementsRegistry',0,'',''),(6398,'Bpmn-visualization','I have just added the update of the \"elements-identification\" demo that now uses a BPMN container without id (I updated the PR description with more details).\nThe Drag\'n Drop overlay works whether the BPMN container has an id or not.','add update of elements-identification demo',0,'',''),(6399,'Bpmn-visualization','I have just added the update of the \"elements-identification\" demo that now uses a BPMN container without id (I updated the PR description with more details).\nThe Drag\'n Drop overlay works whether the BPMN container has an id or not.','use BPMN container without id',0,'',''),(6400,'Bpmn-visualization','I have just added the update of the \"elements-identification\" demo that now uses a BPMN container without id (I updated the PR description with more details).\nThe Drag\'n Drop overlay works whether the BPMN container has an id or not.','use elements-identification demo without id',0,'',''),(6401,'Bpmn-visualization','Remove extra TSDoc syntax, only keep plain text.\nThe NOTICE file has been excluded from the eslint processing: this file doesn\'t change, is related to the documentation, and does not follow the JS/TS header file format. So there is no reason to lint it.','remove extra TSDoc syntax',0,'',''),(6402,'Bpmn-visualization','Remove extra TSDoc syntax, only keep plain text.\nThe NOTICE file has been excluded from the eslint processing: this file doesn\'t change, is related to the documentation, and does not follow the JS/TS header file format. So there is no reason to lint it.','exclude NOTICE file from eslint processing',0,'',''),(6403,'Bpmn-visualization','TypeScript projects integrating the lib no longer need to declare \'typed-mxgraph\' types. The TypeScript compilation now works out of the box.\nProjects that customize the mxGraph code don\'t need additional configuration to access mxGraph types.','integrate lib',0,'',''),(6404,'Bpmn-visualization','TypeScript projects integrating the lib no longer need to declare \'typed-mxgraph\' types. The TypeScript compilation now works out of the box.\nProjects that customize the mxGraph code don\'t need additional configuration to access mxGraph types.','customize mxGraph code',0,'',''),(6405,'Bpmn-visualization','TypeScript projects integrating the lib no longer need to declare \'typed-mxgraph\' types. The TypeScript compilation now works out of the box.\nProjects that customize the mxGraph code don\'t need additional configuration to access mxGraph types.','customize projects',0,'',''),(6406,'Bpmn-visualization','Previously, the declaration files included in the npm package referenced \'typed-mxgraph\' with:','include  in typed-mxgraph',1,'https://github.com/process-analytics/bpmn-visualization-js/pull/2258',''),(6407,'Bpmn-visualization','\"typed-mxgraph\" had to be accessible directly and so, node_modules/@typed-mxgraph had to be added to TypeScript configuration typeRoots. This was because the lib itself declared it in typeRoots.','add  to TypeScript configuration typeRoots',0,'',''),(6408,'Bpmn-visualization','The changes are tested with a dedicated TypeScript project that runs the TypeScript compiler. It also tests the lowest TypeScript version that can work with the lib (currently 4.5).','run TypeScript compiler',0,'',''),(6409,'Bpmn-visualization','The changes are tested with a dedicated TypeScript project that runs the TypeScript compiler. It also tests the lowest TypeScript version that can work with the lib (currently 4.5).','run dedicated TypeScript project',0,'',''),(6410,'Bpmn-visualization','The changes are tested with a dedicated TypeScript project that runs the TypeScript compiler. It also tests the lowest TypeScript version that can work with the lib (currently 4.5).','test changes with dedicated TypeScript project',0,'',''),(6411,'Bpmn-visualization','The changes are tested with a dedicated TypeScript project that runs the TypeScript compiler. It also tests the lowest TypeScript version that can work with the lib (currently 4.5).','test lowest TypeScript version',0,'',''),(6412,'Bpmn-visualization','The README has been updating accordingly. It contains a note about the configuration that was previously required. It should help projects still using an old version.','use old version',0,'',''),(6413,'Bpmn-visualization','The projects in the examples repository work with the implementation provided in this PR. See process-analytics/bpmn-visualization-examples#405','provide  in PR',0,'',''),(6414,'Bpmn-visualization','Why global.d.ts instead of compilerOptions.types inside jsconfig.json or tsconfig.json?\nSetting compilerOptions.types shuts out all other types not explicitly listed in the configuration. Using triple-slash references keeps the default TypeScript setting of accepting type information from the entire workspace, while also adding svelte and vite/client type information.','use triple-slash references',0,'',''),(6415,'Bpmn-visualization','Why global.d.ts instead of compilerOptions.types inside jsconfig.json or tsconfig.json?\nSetting compilerOptions.types shuts out all other types not explicitly listed in the configuration. Using triple-slash references keeps the default TypeScript setting of accepting type information from the entire workspace, while also adding svelte and vite/client type information.','add svelte vite/client type information',0,'',''),(6416,'Bpmn-visualization','@assynour could you review the README a provide suggestion/question if it is not clear enough? Thanks','provide suggestion/question',0,'',''),(6417,'Bpmn-visualization','I started working on the repository of examples. The integration works fine for projects that don\'t call mxGraph code.\n⚠️ I see some errors in the vite project that directly calls mxGraph code. The build command fails.\nSo please don\'t merge this PR until we figure out what is going on!','call mxGraph code',0,'',''),(6418,'Bpmn-visualization','I started working on the repository of examples. The integration works fine for projects that don\'t call mxGraph code.\n⚠️ I see some errors in the vite project that directly calls mxGraph code. The build command fails.\nSo please don\'t merge this PR until we figure out what is going on!','call vite project',0,'',''),(6419,'Bpmn-visualization','I started working on the repository of examples. The integration works fine for projects that don\'t call mxGraph code. warning I see some errors in the vite project that directly calls mxGraph code. The build command fails. So please don\'t merge this PR until we figure out what is going on!','call mxGraph code',1,'https://github.com/process-analytics/bpmn-visualization-js/pull/2258',''),(6420,'Bpmn-visualization','I started working on the repository of examples. The integration works fine for projects that don\'t call mxGraph code. warning I see some errors in the vite project that directly calls mxGraph code. The build command fails. So please don\'t merge this PR until we figure out what is going on!','call vite project',1,'https://github.com/process-analytics/bpmn-visualization-js/pull/2258',''),(6421,'Bpmn-visualization','There was a problem hiding this comment.','hide comment',0,'',''),(6422,'Bpmn-visualization','Do you check if there is no error with ESLint in your IDE when a file of the tests is updated ?\nIn my memories, we added this for the edition of the tests on IDE.','add  in memories',0,'',''),(6423,'Bpmn-visualization','Do you check if there is no error with ESLint in your IDE when a file of the tests is updated ?\nIn my memories, we added this for the edition of the tests on IDE.','add  for edition',0,'',''),(6424,'Bpmn-visualization','Do you check if there is no error with ESLint in your IDE when a file of the tests is updated ?\nIn my memories, we added this for the edition of the tests on IDE.','add  on IDE',0,'',''),(6425,'Bpmn-visualization','✔️ Yes it works. If I add an unsued import','add unsued import',1,'https://github.com/process-analytics/bpmn-visualization-js/pull/2258',''),(6426,'Bpmn-visualization','I get a typescript-eslint error:','get typescript-eslint error',1,'https://github.com/process-analytics/bpmn-visualization-js/pull/2258',''),(6427,'Bpmn-visualization','Read the announcement post for all the details.','read announcement post for details',0,'',''),(6428,'Bpmn-visualization','Set eslint rules to ensure we explicitly used the type modifier for imports and exports.\nIt will also help introduce build tools like esbuild.','use type modifier for imports',0,'',''),(6429,'Bpmn-visualization','Set eslint rules to ensure we explicitly used the type modifier for imports and exports.\nIt will also help introduce build tools like esbuild.','use type modifier for exports',0,'',''),(6430,'Bpmn-visualization','Generalize work started in #1666\nSet eslint rules','set eslint rules',0,'',''),(6431,'Bpmn-visualization','I tried to move the parserOptions configuration in the dedicated eslintrc but I got errors.','move parserOptions configuration in dedicated eslintrc',0,'',''),(6432,'Bpmn-visualization','I tried to move the parserOptions configuration in the dedicated eslintrc but I got errors.','get errors',0,'',''),(6433,'Bpmn-visualization','⚠️ performance impact of adding the consistent-type-exports rule: eslint now triggers TS compilation, and this will be done at each commit\nSee https://typescript-eslint.io/docs/linting/type-linting/#how-is-performance','add consistent-type-exports rule eslint',0,'',''),(6434,'Bpmn-visualization','⚠️ performance impact of adding the consistent-type-exports rule: eslint now triggers TS compilation, and this will be done at each commit\nSee https://typescript-eslint.io/docs/linting/type-linting/#how-is-performance','trigger TS compilation',0,'',''),(6435,'Bpmn-visualization','Decision: we are aware of the risk. First usages as part of commit in this PR show no visible commit time change.\nIf this becomes to slow us down, we will revert the rules that requires TSC','show commit time change',0,'',''),(6436,'Bpmn-visualization','Due to the fact that default image lacks certain libraries needed for the puppeteer to lanch, the new enhanced Dockerfile was created.','create new enhanced Dockerfile due_to fact',0,'',''),(6437,'Bpmn-visualization','Running a fresh workspace, the npm install script was not run.\nThis is probably because there was no .gitpod.yml in the master branch.','run fresh workspace',0,'',''),(6438,'Bpmn-visualization','After having switched to the branch of this pr that has the init tasks, run npm install, the e2e tests fail.','switch  to branch',0,'',''),(6439,'Bpmn-visualization','I have removed the node_modules, then restarted the workspace. The node_modules folder is not created.\ne2e tests still fail.','remove node_modules',0,'',''),(6440,'Bpmn-visualization','I have removed the node_modules, then restarted the workspace. The node_modules folder is not created.\ne2e tests still fail.','restart workspace',0,'',''),(6441,'Bpmn-visualization','Maybe there is some issues with running Gitpod from PR?','run Gitpod from PR',0,'',''),(6442,'Bpmn-visualization','I have just tested by running it from my GitHub branch and tests are passing.\nhttps://github.com/aibcmars/bpmn-visualization-js/tree/infra-gitpod_e2e_tests_fix','run  from GitHub branch',0,'',''),(6443,'Bpmn-visualization','I have just tested by running it from my GitHub branch and tests are passing.\nhttps://github.com/aibcmars/bpmn-visualization-js/tree/infra-gitpod_e2e_tests_fix','test  by running',0,'',''),(6444,'Bpmn-visualization','I have just tested by running it from my GitHub branch and tests are passing.\nhttps://github.com/aibcmars/bpmn-visualization-js/tree/infra-gitpod_e2e_tests_fix','pass  by running',0,'',''),(6445,'Bpmn-visualization','Ok, I will retest with a fresh workspace created from the branch of this PR as described in https://www.gitpod.io/docs/context-urls/#branch-context\nhttps://gitpod.io/#https://github.com/aibcmars/bpmn-visualization-js/tree/infra-gitpod_e2e_tests_fix','create  from branch',0,'',''),(6446,'Bpmn-visualization','✔️ Creating the workspace with the branch of this PR works fine\nThe workspace creation is a bit more slower than before because of the need for rebuilding the Docker image. We may document this.','create workspace with branch',0,'',''),(6447,'Bpmn-visualization','✔️ Creating the workspace with the branch of this PR works fine\nThe workspace creation is a bit more slower than before because of the need for rebuilding the Docker image. We may document this.','rebuild Docker image',0,'',''),(6448,'Bpmn-visualization','npm install is run at workspace startup','run npm install at workspace startup',0,'',''),(6449,'Bpmn-visualization','I got some errors in the log when running e2e tests, but tests pass, so we can check this later','get errors in log',1,'https://github.com/process-analytics/bpmn-visualization-js/pull/686',''),(6450,'Bpmn-visualization','I got some errors in the log when running e2e tests, but tests pass, so we can check this later','run e2e tests',1,'https://github.com/process-analytics/bpmn-visualization-js/pull/686',''),(6451,'Bpmn-visualization','Add a step in the release process.','add step in release process',0,'',''),(6452,'Bpmn-visualization','StyleDefault SHAPE_ACTIVITY_MARKER_ICON_SIZE\nImplicitly managed with the issue to have a true marker fixed size.','manage  with issue',0,'',''),(6453,'Bpmn-visualization','StyleConfigurator: lane and pool label style. Documented in the issue.','document  in issue',0,'',''),(6454,'Bpmn-visualization','editorconfig: we use os eol and let git manage eol on push\nThis setting may only be needed for windows, but default git checkout config\nhandle it correctly.\nSo remove the todo about setting a specific configuration.','use os eol',0,'',''),(6455,'Bpmn-visualization','editorconfig: we use os eol and let git manage eol on push\nThis setting may only be needed for windows, but default git checkout config\nhandle it correctly.\nSo remove the todo about setting a specific configuration.','manage eol on push',0,'',''),(6456,'Bpmn-visualization','editorconfig: we use os eol and let git manage eol on push\nThis setting may only be needed for windows, but default git checkout config\nhandle it correctly.\nSo remove the todo about setting a specific configuration.','remove todo about setting',0,'',''),(6457,'Bpmn-visualization','editorconfig: we use os eol and let git manage eol on push\nThis setting may only be needed for windows, but default git checkout config\nhandle it correctly.\nSo remove the todo about setting a specific configuration.','set specific configuration',0,'',''),(6458,'Bpmn-visualization','Ok I will test on a local Windows 10 machine, probably on Monday.','test  on local Windows machine',0,'',''),(6459,'Bpmn-visualization','I will manage it while testing on Ubuntu locally.','manage  while testing',0,'',''),(6460,'Bpmn-visualization','I will manage it while testing on Ubuntu locally.','test  on Ubuntu',0,'',''),(6461,'Bpmn-visualization','See milestone 0.27.1 to get the list of issues covered by this release.','get list of issues',0,'',''),(6462,'Bpmn-visualization','Previously, it was mandatory to define an id in the HTML div element used to display the BPMN diagram. ⚠️ It is not a common practice to set the id of a component with Angular and Svelte.\nAs a result, some bpmn-visualization APIs were generating an error when the id was not defined.','define id in HTML div element',0,'',''),(6463,'Bpmn-visualization','Previously, it was mandatory to define an id in the HTML div element used to display the BPMN diagram. ⚠️ It is not a common practice to set the id of a component with Angular and Svelte.\nAs a result, some bpmn-visualization APIs were generating an error when the id was not defined.','display BPMN diagram',0,'',''),(6464,'Bpmn-visualization','Previously, it was mandatory to define an id in the HTML div element used to display the BPMN diagram. ⚠️ It is not a common practice to set the id of a component with Angular and Svelte.\nAs a result, some bpmn-visualization APIs were generating an error when the id was not defined.','set id with Angular',0,'',''),(6465,'Bpmn-visualization','Previously, it was mandatory to define an id in the HTML div element used to display the BPMN diagram. ⚠️ It is not a common practice to set the id of a component with Angular and Svelte.\nAs a result, some bpmn-visualization APIs were generating an error when the id was not defined.','set id with svelte',0,'',''),(6466,'Bpmn-visualization','Previously, it was mandatory to define an id in the HTML div element used to display the BPMN diagram. ⚠️ It is not a common practice to set the id of a component with Angular and Svelte.\nAs a result, some bpmn-visualization APIs were generating an error when the id was not defined.','set id of component',0,'',''),(6467,'Bpmn-visualization','Previously, it was mandatory to define an id in the HTML div element used to display the BPMN diagram. ⚠️ It is not a common practice to set the id of a component with Angular and Svelte.\nAs a result, some bpmn-visualization APIs were generating an error when the id was not defined.','generate error as result',0,'',''),(6468,'Bpmn-visualization','See milestone 0.27.0 to get the list of issues covered by this release.','get list of issues',0,'',''),(6469,'Bpmn-visualization','In 0.24.0, it was announced that bpmnVisualization.fit(fitOptions) was deprecated.\nFrom now, this method is completely removed. Use bpmnVisualization.navigation.fit(fitOptions) instead.','remove method',0,'',''),(6470,'Bpmn-visualization','In 0.24.0, it was announced that bpmnVisualization.fit(fitOptions) was deprecated.\nFrom now, this method is completely removed. Use bpmnVisualization.navigation.fit(fitOptions) instead.','use bpmnVisualization.navigation.fit(fitOptions)',0,'',''),(6471,'Bpmn-visualization','Previously, the TypeScript projects need a specific configuration, in the tsconfig.json file, to integrate bpmn-visualization.','integrate bpmn-visualization',0,'',''),(6472,'Bpmn-visualization','From now, the integration of bpmn-visualization in TypeScript projects is simplified. They no longer need this configuration.\nThe README contains a note about the configuration that was previously required. It should help projects still using an old version.','use old version',0,'',''),(6473,'Bpmn-visualization','In addition, a more explicit error message is displayed when integrating bpmn-visualization in a project that uses a too old TypeScript version. Remember that bpmn-visualization requires TypeScript 4.5 or superior.','integrate bpmn-visualization in project',0,'',''),(6474,'Bpmn-visualization','In addition, a more explicit error message is displayed when integrating bpmn-visualization in a project that uses a too old TypeScript version. Remember that bpmn-visualization requires TypeScript 4.5 or superior.','use old TypeScript version',0,'',''),(6475,'Bpmn-visualization','In addition, a more explicit error message is displayed when integrating bpmn-visualization in a project that uses a too old TypeScript version. Remember that bpmn-visualization requires TypeScript 4.5 or superior.','use project',0,'',''),(6476,'Bpmn-visualization','In addition, a more explicit error message is displayed when integrating bpmn-visualization in a project that uses a too old TypeScript version. Remember that bpmn-visualization requires TypeScript 4.5 or superior.','display explicit error message',0,'',''),(6477,'Bpmn-visualization','bpmn-visualization supports now the detection of the Complex Gateway.','support detection of complex Gateway',0,'',''),(6478,'Bpmn-visualization','For now, the Complex Gateway is displayed as a red diamond, as follows:','display complex Gateway as red diamond',0,'',''),(6479,'Bpmn-visualization','See milestone 0.26.2 to get the list of issues covered by this release.','get list of issues',0,'',''),(6480,'Bpmn-visualization','This is now easier to use bpmn-visualization in Parcel, Webpack and Angular projects. Previously, it was necessary to add a special configuration to integrate bpmn-visualization. With version 0.26.2, this is not needed anymore.','use bpmn-visualization in parcel',0,'',''),(6481,'Bpmn-visualization','This is now easier to use bpmn-visualization in Parcel, Webpack and Angular projects. Previously, it was necessary to add a special configuration to integrate bpmn-visualization. With version 0.26.2, this is not needed anymore.','use bpmn-visualization in webpack',0,'',''),(6482,'Bpmn-visualization','This is now easier to use bpmn-visualization in Parcel, Webpack and Angular projects. Previously, it was necessary to add a special configuration to integrate bpmn-visualization. With version 0.26.2, this is not needed anymore.','use bpmn-visualization in Angular projects',0,'',''),(6483,'Bpmn-visualization','This is now easier to use bpmn-visualization in Parcel, Webpack and Angular projects. Previously, it was necessary to add a special configuration to integrate bpmn-visualization. With version 0.26.2, this is not needed anymore.','add special configuration',0,'',''),(6484,'Bpmn-visualization','This is now easier to use bpmn-visualization in Parcel, Webpack and Angular projects. Previously, it was necessary to add a special configuration to integrate bpmn-visualization. With version 0.26.2, this is not needed anymore.','integrate bpmn-visualization',0,'',''),(6485,'Bpmn-visualization','See milestone 0.26.1 to get the list of issues covered by this release.','get list of issues',0,'',''),(6486,'Bpmn-visualization','This new version brings improvements to customize the style of the Text Annotation elements and a new BPMN theme in the demo.','customize new BPMN theme in demo',0,'',''),(6487,'Bpmn-visualization','This new version brings improvements to customize the style of the Text Annotation elements and a new BPMN theme in the demo.','customize new BPMN theme of text Annotation elements',0,'',''),(6488,'Bpmn-visualization','This new version brings improvements to customize the style of the Text Annotation elements and a new BPMN theme in the demo.','customize style in demo',0,'',''),(6489,'Bpmn-visualization','This new version brings improvements to customize the style of the Text Annotation elements and a new BPMN theme in the demo.','customize style of text Annotation elements',0,'',''),(6490,'Bpmn-visualization','See milestone 0.26.0 to get the list of issues covered by this release.','get list of issues',0,'',''),(6491,'Bpmn-visualization','In previous versions, it was already possible to customize the style of the Text Annotation elements and to configure a fill color (gradient could also be used).\nBut only a small area of the Text Annotation was filled (the area delimited by the open rectangle).','customize style of text Annotation elements',0,'',''),(6492,'Bpmn-visualization','In previous versions, it was already possible to customize the style of the Text Annotation elements and to configure a fill color (gradient could also be used).\nBut only a small area of the Text Annotation was filled (the area delimited by the open rectangle).','configure fill color',0,'',''),(6493,'Bpmn-visualization','In previous versions, it was already possible to customize the style of the Text Annotation elements and to configure a fill color (gradient could also be used).\nBut only a small area of the Text Annotation was filled (the area delimited by the open rectangle).','fill small area of text Annotation',0,'',''),(6494,'Bpmn-visualization','In version 0.26.0, the whole Text Annotation area is now filled.','fill whole text Annotation area in version 0.26.0',0,'',''),(6495,'Bpmn-visualization','This new feature allows you to highlight the entire text of Text Annotation elements.\nCheck the Bonita procurement example using #B4AFAF26 for Text Annotation fill color 👇.','check bonita procurement example',0,'',''),(6496,'Bpmn-visualization','The \'Diagram\' title section has been removed. So there is now more space for the BPMN diagram rendering, especially on mobile.\nIn addition, the \'fit on load\', \'fit margin\' and \'theme\' blocks (from the control panel) align better on small screens.','remove title section',0,'',''),(6497,'Bpmn-visualization','The \'Diagram\' title section has been removed. So there is now more space for the BPMN diagram rendering, especially on mobile.\nIn addition, the \'fit on load\', \'fit margin\' and \'theme\' blocks (from the control panel) align better on small screens.','fit margin',0,'',''),(6498,'Bpmn-visualization','Check the evolution between version 0.25.2 and version 0.26.0 (shown as 0.25.3-post version here) 👇.\nThe videos have been done with Chrome 104.','check evolution between version 0.25.2',0,'',''),(6499,'Bpmn-visualization','Check the evolution between version 0.25.2 and version 0.26.0 (shown as 0.25.3-post version here) 👇.\nThe videos have been done with Chrome 104.','check evolution between version 0.26.0',0,'',''),(6500,'Bpmn-visualization','A new Light Blue BPMN theme is available. It uses the new improvement about the fill color of the Text Annotation elements 👇.','use new improvement about fill color',0,'',''),(6501,'Bpmn-visualization','See milestone 0.25.2 to get the list of issues covered by this release.','get list of issues',0,'',''),(6502,'Bpmn-visualization','See milestone 0.25.1 to get the list of issues covered by this release.','get list of issues',0,'',''),(6503,'Bpmn-visualization','This new release provides a new API to filter pools when loading the BPMN diagram.','provide new API to filter pools',0,'',''),(6504,'Bpmn-visualization','This new release provides a new API to filter pools when loading the BPMN diagram.','load BPMN diagram',0,'',''),(6505,'Bpmn-visualization','See milestone 0.25.0 to get the list of issues covered by this release.','get list of issues',0,'',''),(6506,'Bpmn-visualization','When calling the load method, it is now possible to filter the pools in the diagram you want to display.\nYou can filter one or several pools and specify the filtering options by pool id and/or name.','call load method',0,'',''),(6507,'Bpmn-visualization','When calling the load method, it is now possible to filter the pools in the diagram you want to display.\nYou can filter one or several pools and specify the filtering options by pool id and/or name.','specify filtering options by pool id and/or name',0,'',''),(6508,'Bpmn-visualization','In the following example 👇, we load the same diagram with different filter configuration. First without filter, so we see the whole diagram. Then we filter different pools, one pool at a time. And finally, we filter 3 pools at the same time.','load same diagram with different filter configuration',0,'',''),(6509,'Bpmn-visualization','See milestone 0.24.1 to get the list of issues covered by this release.','get list of issues',0,'',''),(6510,'Bpmn-visualization','Use SVG favicon for a better resolution. It is also used in the HTML documentation as documentation is using the same\nfile as in the demo/example/test pages.\nRename non-regression.js for consistency (same as the page where it is used)','use SVG favicon for better resolution',0,'',''),(6511,'Bpmn-visualization','Use SVG favicon for a better resolution. It is also used in the HTML documentation as documentation is using the same\nfile as in the demo/example/test pages.\nRename non-regression.js for consistency (same as the page where it is used)','use same file',0,'',''),(6512,'Bpmn-visualization','Use SVG favicon for a better resolution. It is also used in the HTML documentation as documentation is using the same\nfile as in the demo/example/test pages.\nRename non-regression.js for consistency (same as the page where it is used)','use  in HTML documentation',0,'',''),(6513,'Bpmn-visualization','Use SVG favicon for a better resolution. It is also used in the HTML documentation as documentation is using the same\nfile as in the demo/example/test pages.\nRename non-regression.js for consistency (same as the page where it is used)','rename non-regression.js for consistency',0,'',''),(6514,'Bpmn-visualization','TypeScript projects integrating bpmn-visualization but using an unsupported TypeScript version now get an explicit error message instead of a list of type errors.','integrate bpmn-visualization',0,'',''),(6515,'Bpmn-visualization','TypeScript projects integrating bpmn-visualization but using an unsupported TypeScript version now get an explicit error message instead of a list of type errors.','use unsupported TypeScript version',0,'',''),(6516,'Bpmn-visualization','TypeScript projects integrating bpmn-visualization but using an unsupported TypeScript version now get an explicit error message instead of a list of type errors.','get explicit error message instead_of list',0,'',''),(6517,'Bpmn-visualization','For instance, when using TypeScript Version 4.4.4','use TypeScript',1,'https://github.com/process-analytics/bpmn-visualization-js/pull/2272',''),(6518,'Bpmn-visualization','To get the error message','get error message',0,'',''),(6519,'Bpmn-visualization','We benefit from the ViteJS \'unbundled\' way of working: the dev server starts and updates in 200-300 ms instead of 13-18\nseconds.\nWe also have a much better integration for tailwindcss than with the custom hack we previously used.','use custom hack',0,'',''),(6520,'Bpmn-visualization','You can trigger a rebase of this PR by commenting @dependabot rebase.','trigger rebase by commenting',0,'',''),(6521,'Bpmn-visualization','You can trigger a rebase of this PR by commenting @dependabot rebase.','trigger rebase of PR',0,'',''),(6522,'Bpmn-visualization','Update the configuration to only ignore folders at project root. To prevent new\nerrors in the future, also do this for the build and dist folders.\nFix lint errors in files in the config folders.','update configuration',0,'',''),(6523,'Bpmn-visualization','Update the configuration to only ignore folders at project root. To prevent new\nerrors in the future, also do this for the build and dist folders.\nFix lint errors in files in the config folders.','ignore folders at project root',0,'',''),(6524,'Bpmn-visualization','Update the configuration to only ignore folders at project root. To prevent new\nerrors in the future, also do this for the build and dist folders.\nFix lint errors in files in the config folders.','prevent new errors in future',0,'',''),(6525,'Bpmn-visualization','Update the configuration to only ignore folders at project root. To prevent new\nerrors in the future, also do this for the build and dist folders.\nFix lint errors in files in the config folders.','fix lint errors in files',0,'',''),(6526,'Ivy','By default, Ivy searches for a site configuration file called either site.py or config.py.\nYou can specify a custom filename for the site configuration file using the IVY_CONFIG_FILE environment variable, e.g.','call site.py by default',1,'http://www.dmulholl.com/docs/ivy/main/options.html','site-configuration-file'),(6527,'Ivy','By default, Ivy searches for a site configuration file called either site.py or config.py.\nYou can specify a custom filename for the site configuration file using the IVY_CONFIG_FILE environment variable, e.g.','call config.py by default',1,'http://www.dmulholl.com/docs/ivy/main/options.html','site-configuration-file'),(6528,'Ivy','By default, Ivy searches for a site configuration file called either site.py or config.py.\nYou can specify a custom filename for the site configuration file using the IVY_CONFIG_FILE environment variable, e.g.','specify custom filename for site configuration file',1,'http://www.dmulholl.com/docs/ivy/main/options.html','site-configuration-file'),(6529,'Ivy','By default, Ivy searches for a site configuration file called either site.py or config.py.\nYou can specify a custom filename for the site configuration file using the IVY_CONFIG_FILE environment variable, e.g.','use IVY_CONFIG_FILE environment variable',1,'http://www.dmulholl.com/docs/ivy/main/options.html','site-configuration-file'),(6530,'Ivy','By default, Ivy uses directories named ext, inc, lib, out, res, and src.','use directories by default',0,'',''),(6531,'Ivy','You can customize these default directory names using environment variables, e.g.','use environment variables',1,'http://www.dmulholl.com/docs/ivy/main/options.html','directory-names'),(6532,'Ivy','Alternatively, you can customize directory names on a per-site basis by specifying alternate names in your site configuration file, e.g.','customize directory names by specifying',1,'http://www.dmulholl.com/docs/ivy/main/options.html','directory-names'),(6533,'Ivy','Alternatively, you can customize directory names on a per-site basis by specifying alternate names in your site configuration file, e.g.','customize directory names on per-site basis',1,'http://www.dmulholl.com/docs/ivy/main/options.html','directory-names'),(6534,'Ivy','Alternatively, you can customize directory names on a per-site basis by specifying alternate names in your site configuration file, e.g.','specify alternate names in site configuration file',1,'http://www.dmulholl.com/docs/ivy/main/options.html','directory-names'),(6535,'Ivy','Ivy generates output pages with a .html file extension by default.','generate output pages',0,'',''),(6536,'Ivy','You can specify a custom file extension for output files in your site configuration file, e.g.','specify custom file extension in site configuration file',1,'http://www.dmulholl.com/docs/ivy/main/options.html','custom-file-extensions'),(6537,'Ivy','You can specify a custom file extension for output files in your site configuration file, e.g.','specify custom file extension for output files',1,'http://www.dmulholl.com/docs/ivy/main/options.html','custom-file-extensions'),(6538,'Ivy','You can generate directory-style URLs — i.e. URLs ending in a forward slash — by setting a custom file extension of \"/\" in your site configuration file:','generate directory-style urls â i.e. urls',1,'http://www.dmulholl.com/docs/ivy/main/options.html','directory-style-urls'),(6539,'Ivy','You can generate directory-style URLs — i.e. URLs ending in a forward slash — by setting a custom file extension of \"/\" in your site configuration file:','set custom file extension of /',1,'http://www.dmulholl.com/docs/ivy/main/options.html','directory-style-urls'),(6540,'Ivy','Ivy generates page-relative URLs by default.','generate page-relative urls by default',0,'',''),(6541,'Ivy','You can generate absolute URLs by specifying an explicit root URL in your site configuration file, e.g.','generate absolute urls by specifying',1,'http://www.dmulholl.com/docs/ivy/main/options.html','absolute-urls'),(6542,'Ivy','You can generate absolute URLs by specifying an explicit root URL in your site configuration file, e.g.','specify explicit root URL in site configuration file',1,'http://www.dmulholl.com/docs/ivy/main/options.html','absolute-urls'),(6543,'Ivy','You can generate site-relative URLs — i.e. URLs that begin with a / — by specifying a root URL of \"/\" in your site configuration file:','generate site-relative urls â i.e. urls',1,'http://www.dmulholl.com/docs/ivy/main/options.html','site-relative-urls'),(6544,'Ivy','To initialize a new site, create a site directory, cd into it, and run the init command:','initialize new site',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','command-line-interface'),(6545,'Ivy','To initialize a new site, create a site directory, cd into it, and run the init command:','create site directory',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','command-line-interface'),(6546,'Ivy','To initialize a new site, create a site directory, cd into it, and run the init command:','run init command',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','command-line-interface'),(6547,'Ivy','Use the ivy --help flag to view the full command-line help text.','use ivy',0,'',''),(6548,'Ivy','Ivy assumes that a site uses the following default directory structure:','use following default directory structure',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','site-structure'),(6549,'Ivy','Ivy uses the presence of a site.py file (alternatively, a config.py file) to identify a site\'s home directory.','identify home directory',0,'',''),(6550,'Ivy','Static assets such as image files should be placed in the site\'s resources directory, res. The content of this directory is copied to the output directory when the site is built.','place static assets in resources directory',0,'',''),(6551,'Ivy','Static assets such as image files should be placed in the site\'s resources directory, res. The content of this directory is copied to the output directory when the site is built.','place static assets such_as image files',0,'',''),(6552,'Ivy','A node is a text file or directory stored in a site\'s src directory. Ivy parses the src directory into a tree of nodes which it then renders into a website, generating a single HTML page in the out directory for each node in the tree.','store  in src directory',0,'',''),(6553,'Ivy','A node is a text file or directory stored in a site\'s src directory. Ivy parses the src directory into a tree of nodes which it then renders into a website, generating a single HTML page in the out directory for each node in the tree.','render nodes into website',0,'',''),(6554,'Ivy','A node is a text file or directory stored in a site\'s src directory. Ivy parses the src directory into a tree of nodes which it then renders into a website, generating a single HTML page in the out directory for each node in the tree.','generate single HTML page in out directory',0,'',''),(6555,'Ivy','A node file can begin with a YAML header specifying metadata for the node:','specify metadata for node',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','nodes'),(6556,'Ivy','Node content can be written in Markdown, Syntext, or plain HTML.\nFiles with a .md extension have their content passed through a Markdown renderer; files with a .stx extension have their content passed through a Syntext renderer; files with an unregistered extension (like .txt or .html) have their content preserved as-is.','write node content in markdown',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','nodes'),(6557,'Ivy','Node content can be written in Markdown, Syntext, or plain HTML.\nFiles with a .md extension have their content passed through a Markdown renderer; files with a .stx extension have their content passed through a Syntext renderer; files with an unregistered extension (like .txt or .html) have their content preserved as-is.','write node content in syntext',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','nodes'),(6558,'Ivy','Node content can be written in Markdown, Syntext, or plain HTML.\nFiles with a .md extension have their content passed through a Markdown renderer; files with a .stx extension have their content passed through a Syntext renderer; files with an unregistered extension (like .txt or .html) have their content preserved as-is.','write node content in plain HTML',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','nodes'),(6559,'Ivy','Node content can be written in Markdown, Syntext, or plain HTML.\nFiles with a .md extension have their content passed through a Markdown renderer; files with a .stx extension have their content passed through a Syntext renderer; files with an unregistered extension (like .txt or .html) have their content preserved as-is.','pass  through Markdown renderer',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','nodes'),(6560,'Ivy','Node content can be written in Markdown, Syntext, or plain HTML.\nFiles with a .md extension have their content passed through a Markdown renderer; files with a .stx extension have their content passed through a Syntext renderer; files with an unregistered extension (like .txt or .html) have their content preserved as-is.','pass  through Syntext renderer',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','nodes'),(6561,'Ivy','correspond to a single node in the parse tree. Node files provide content and metadata for a node; node directories store child nodes.','provide content for node',0,'',''),(6562,'Ivy','correspond to a single node in the parse tree. Node files provide content and metadata for a node; node directories store child nodes.','provide metadata for node',0,'',''),(6563,'Ivy','correspond to a single node in the parse tree. Node files provide content and metadata for a node; node directories store child nodes.','store child nodes',0,'',''),(6564,'Ivy','Ivy has builtin support for node metadata in YAML format. Note that metadata keys are converted to lowercase and spaces and hyphens are replaced by underscores so the YAML attribute:','replace spaces',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','metadata'),(6565,'Ivy','Ivy has builtin support for node metadata in YAML format. Note that metadata keys are converted to lowercase and spaces and hyphens are replaced by underscores so the YAML attribute:','replace hyphens',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','metadata'),(6566,'Ivy','Ivy has builtin support for node metadata in YAML format. Note that metadata keys are converted to lowercase and spaces and hyphens are replaced by underscores so the YAML attribute:','convert metadata keys',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','metadata'),(6567,'Ivy','The node\'s text content as read from the source file.','read  from source file',0,'',''),(6568,'Ivy','The node\'s text content after it has been rendered into HTML. (This will only differ from node.text if a renderer has been registered for the node file\'s extension. By default a Markdown renderer is registered for .md files and a Syntext renderer for .stx files.)','render text content into HTML',0,'',''),(6569,'Ivy','Ivy generates page-relative URLs and files with a .html extension by default.','generate page-relative urls',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','links'),(6570,'Ivy','Ivy generates page-relative URLs and files with a .html extension by default.','generate files',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','links'),(6571,'Ivy','Use two trailing slashes when linking to pages generated by Ivy itself — this tells Ivy to rewrite the ending to suit your extension settings.','use trailing slashes',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','links'),(6572,'Ivy','Use two trailing slashes when linking to pages generated by Ivy itself — this tells Ivy to rewrite the ending to suit your extension settings.','link  to pages',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','links'),(6573,'Ivy','Use two trailing slashes when linking to pages generated by Ivy itself — this tells Ivy to rewrite the ending to suit your extension settings.','generate  by ivy',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','links'),(6574,'Ivy','Linking to the homepage is a special case — a simple @root/ will always suffice.','link  to homepage',0,'',''),(6575,'Ivy','A node\'s URL is determined by its slug and by the slugs of its ancestor nodes. By default a node\'s slug is generated by slugifying its filename — the extension is stripped, text is converted to lowercase ASCII, spaces are converted to hyphens etc., so a node file named Foo Bar.md would have the slug foo-bar.','determine URL',0,'',''),(6576,'Ivy','A node\'s URL is determined by its slug and by the slugs of its ancestor nodes. By default a node\'s slug is generated by slugifying its filename — the extension is stripped, text is converted to lowercase ASCII, spaces are converted to hyphens etc., so a node file named Foo Bar.md would have the slug foo-bar.','generate slug',0,'',''),(6577,'Ivy','A node\'s URL is determined by its slug and by the slugs of its ancestor nodes. By default a node\'s slug is generated by slugifying its filename — the extension is stripped, text is converted to lowercase ASCII, spaces are converted to hyphens etc., so a node file named Foo Bar.md would have the slug foo-bar.','convert spaces',0,'',''),(6578,'Ivy','A node\'s URL is determined by its slug and by the slugs of its ancestor nodes. By default a node\'s slug is generated by slugifying its filename — the extension is stripped, text is converted to lowercase ASCII, spaces are converted to hyphens etc., so a node file named Foo Bar.md would have the slug foo-bar.','convert text',0,'',''),(6579,'Ivy','This default slug can be overridden by setting a custom slug in the header:','set custom slug in header',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','slugs'),(6580,'Ivy','This default slug can be overridden by setting a custom slug in the header:','override default slug',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','slugs'),(6581,'Ivy','Slugs can be customized sitewide by registering a filter callback on the Filter.SLUGIFY filter hook. (You can find this hook in the ivy/utils.py file.)','customize sitewide',0,'',''),(6582,'Ivy','Slugs can be customized sitewide by registering a filter callback on the Filter.SLUGIFY filter hook. (You can find this hook in the ivy/utils.py file.)','customize slugs',0,'',''),(6583,'Ivy','Ivy automatically generates a list of useful CSS classes for each page\'s  element based on the page\'s URL slugs. For example the page with the URL:','generate list of useful CSS classes',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','classes'),(6584,'Ivy','You can add your own custom classes for a particular node by adding a comma-separated classes list to the node\'s header, e.g.','add own custom classes by adding',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','classes'),(6585,'Ivy','You can add your own custom classes for a particular node by adding a comma-separated classes list to the node\'s header, e.g.','add own custom classes for particular node',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','classes'),(6586,'Ivy','You can add your own custom classes for a particular node by adding a comma-separated classes list to the node\'s header, e.g.','add comma-separated classes list to header',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','classes'),(6587,'Ivy','Note that the homepage node automatically gets the class homepage.','get class homepage',0,'',''),(6588,'Ivy','The includes directory, inc, is for includeable files, typically snippets of content that can be reused on multiple pages throughout the site like menus or footer links. Source files placed in this folder will be parsed as Markdown or Syntext depending on their extension and the resulting HTML made available for inclusion in templates via an inc. variable.','reuse snippets of content',0,'',''),(6589,'Ivy','The includes directory, inc, is for includeable files, typically snippets of content that can be reused on multiple pages throughout the site like menus or footer links. Source files placed in this folder will be parsed as Markdown or Syntext depending on their extension and the resulting HTML made available for inclusion in templates via an inc. variable.','reuse snippets for includeable files',0,'',''),(6590,'Ivy','The includes directory, inc, is for includeable files, typically snippets of content that can be reused on multiple pages throughout the site like menus or footer links. Source files placed in this folder will be parsed as Markdown or Syntext depending on their extension and the resulting HTML made available for inclusion in templates via an inc. variable.','reuse snippets throughout site',0,'',''),(6591,'Ivy','The includes directory, inc, is for includeable files, typically snippets of content that can be reused on multiple pages throughout the site like menus or footer links. Source files placed in this folder will be parsed as Markdown or Syntext depending on their extension and the resulting HTML made available for inclusion in templates via an inc. variable.','reuse snippets on multiple pages',0,'',''),(6592,'Ivy','The includes directory, inc, is for includeable files, typically snippets of content that can be reused on multiple pages throughout the site like menus or footer links. Source files placed in this folder will be parsed as Markdown or Syntext depending on their extension and the resulting HTML made available for inclusion in templates via an inc. variable.','place  in folder',0,'',''),(6593,'Ivy','For example, a simple menu can be constructed in Markdown using nested lists:','use nested lists',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','includes'),(6594,'Ivy','If this menu was placed in a file named menu.md then the rendered HTML would be available in templates via an inc.menu variable. (Note that filenames are converted to lower case and spaces and hyphens are converted to underscores.)','place menu in file',0,'',''),(6595,'Ivy','You can add files with any extension to the inc directory including .html, .js, and .css.\nIf no renderer has been registered for the extension the file\'s content will be preserved as-is.','add files with extension',0,'',''),(6596,'Ivy','You can add files with any extension to the inc directory including .html, .js, and .css.\nIf no renderer has been registered for the extension the file\'s content will be preserved as-is.','add files to inc directory',0,'',''),(6597,'Ivy','Just add meta_title and/or meta_description attributes to the page\'s header:','add meta_title and/or',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','meta-titles-and-descriptions'),(6598,'Ivy','This isn\'t really a feature of Ivy itself — the default theme simply checks for these attributes in its template files and you can add similar support to your own custom themes.','add similar support to own custom themes',0,'',''),(6599,'Ivy','This isn\'t really a feature of Ivy itself — the default theme simply checks for these attributes in its template files and you can add similar support to your own custom themes.','check  for attributes',0,'',''),(6600,'Ivy','An extension (also known as a plugin) is a Python module or package that extends Ivy\'s functionality. You can install extensions for a site in one of two ways.','extend Python module',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','installing-extensions'),(6601,'Ivy','An extension (also known as a plugin) is a Python module or package that extends Ivy\'s functionality. You can install extensions for a site in one of two ways.','extend package',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','installing-extensions'),(6602,'Ivy','An extension (also known as a plugin) is a Python module or package that extends Ivy\'s functionality. You can install extensions for a site in one of two ways.','install extensions for site',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','installing-extensions'),(6603,'Ivy','You can add an extensions directory named ext to your site\'s root directory. Extension modules placed in this ext directory will be loaded automatically by Ivy.','add extensions directory',0,'',''),(6604,'Ivy','You can add an extensions directory named ext to your site\'s root directory. Extension modules placed in this ext directory will be loaded automatically by Ivy.','place  in ext directory',0,'',''),(6605,'Ivy','You can add an extensions directory named ext to your site\'s root directory. Extension modules placed in this ext directory will be loaded automatically by Ivy.','load extension modules',0,'',''),(6606,'Ivy','If an extension module has been installed on Python\'s standard import path you can activate it for a particular site by adding its name to an extensions list in the site\'s configuration file:','activate  by adding',0,'',''),(6607,'Ivy','If an extension module has been installed on Python\'s standard import path you can activate it for a particular site by adding its name to an extensions list in the site\'s configuration file:','activate  for particular site',0,'',''),(6608,'Ivy','If an extension module has been installed on Python\'s standard import path you can activate it for a particular site by adding its name to an extensions list in the site\'s configuration file:','add name to extensions list',0,'',''),(6609,'Ivy','If an extension module has been installed on Python\'s standard import path you can activate it for a particular site by adding its name to an extensions list in the site\'s configuration file:','install  on standard import path',0,'',''),(6610,'Ivy','This second method can be used to enable extensions installed from the Python package index using pip.','enable extensions',0,'',''),(6611,'Ivy','This second method can be used to enable extensions installed from the Python package index using pip.','use pip',0,'',''),(6612,'Ivy','This second method can be used to enable extensions installed from the Python package index using pip.','install  from Python package index',0,'',''),(6613,'Ivy','This second method can be used to enable extensions installed from the Python package index using pip.','use second method',0,'',''),(6614,'Ivy','Ivy exports a flexible framework of event and filter hooks. Plugins can extend Ivy by registering callback functions on these hooks.','extend ivy by registering',0,'',''),(6615,'Ivy','You can find these bundled plugins in the ivy/ext/ directory which you can view on Github.','find bundled plugins in ivy/ext/ directory',0,'',''),(6616,'Ivy','Event callbacks accept zero or more arguments depending on the specific hook. They may modify their arguments in place but have no return value.','modify arguments in place',0,'',''),(6617,'Ivy','Here\'s a simple event callback that prints a count of the number of pages that have been written to disk:','print count of number',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','events'),(6618,'Ivy','Here\'s a simple event callback that prints a count of the number of pages that have been written to disk:','print simple event callback of number',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','events'),(6619,'Ivy','Here\'s a simple event callback that prints a count of the number of pages that have been written to disk:','write pages to disk',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','events'),(6620,'Ivy','Filter callbacks accept at least one argument — the value to be filtered. They may accept additional arguments depending on the specific hook. Filter callbacks modify and return the value of their first argument.','modify value of first argument',0,'',''),(6621,'Ivy','Filter callbacks accept at least one argument — the value to be filtered. They may accept additional arguments depending on the specific hook. Filter callbacks modify and return the value of their first argument.','return value of first argument',0,'',''),(6622,'Ivy','Here\'s a simple filter callback that changes every instance of the word foo in node content to bar:','change instance of word foo',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','filters'),(6623,'Ivy','Here\'s a simple filter callback that changes every instance of the word foo in node content to bar:','change instance to bar',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','filters'),(6624,'Ivy','Here\'s a simple filter callback that changes every instance of the word foo in node content to bar:','change simple filter callback of word foo',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','filters'),(6625,'Ivy','Here\'s a simple filter callback that changes every instance of the word foo in node content to bar:','change simple filter callback to bar',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','filters'),(6626,'Ivy','This callback is registered on the NODE_TEXT filter hook which fires just before a node\'s text is rendered into HTML. (The NODE_TEXT filter hook can be found in the ivy/nodes.py file).','render text into HTML',0,'',''),(6627,'Ivy','Note that this hook supplies us with the Node instance itself as an additional argument which in this case we ignore.','ignore additional argument in case',0,'',''),(6628,'Ivy','Ivy relies for most of its functionality on a suite of pluggable rendering and parsing engines, e.g. the Jinja template-engine for handling .jinja template files. Extensions can register support for additional rendering and parsing engines using a system of @register decorators.','use system of @register decorators',0,'',''),(6629,'Ivy','Template-engines produce the output HTML for finished .html pages in the site.','produce output HTML',0,'',''),(6630,'Ivy','Ivy has builtin support for Jinja and Ibis templates. Extensions can register support for additional template-engines using the @ivy.templates.register() decorator. Template-engine callbacks are registered per template-file-extension, e.g.','use  decorator',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','template-engines'),(6631,'Ivy','A template-engine callback should accept a dictionary of page data and a template filename and return a string of HTML.','return string of HTML',0,'',''),(6632,'Ivy','Rendering-engines convert node content into HTML which can then be poured into a template to produce the finished .html output page.','convert node content into HTML',0,'',''),(6633,'Ivy','Ivy has builtin support for node files written in Markdown and Syntext. Extensions can register support for additional input formats using the @ivy.renderers.register() decorator. Rendering-engine callbacks are registered per file-extension, e.g.','write  in markdown',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','rendering-engines'),(6634,'Ivy','Ivy has builtin support for node files written in Markdown and Syntext. Extensions can register support for additional input formats using the @ivy.renderers.register() decorator. Rendering-engine callbacks are registered per file-extension, e.g.','write  in syntext',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','rendering-engines'),(6635,'Ivy','Ivy has builtin support for node files written in Markdown and Syntext. Extensions can register support for additional input formats using the @ivy.renderers.register() decorator. Rendering-engine callbacks are registered per file-extension, e.g.','use  decorator',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','rendering-engines'),(6636,'Ivy','A rendering-engine callback should accept a single string argument containing plain text and return a string of HTML.','return string of HTML',0,'',''),(6637,'Ivy','Note that if you register a custom callback for .md files, this will override the default Markdown renderer.','override default Markdown renderer',0,'',''),(6638,'Ivy','Ivy has builtin support for YAML file headers. Extensions can add support for additional metadata formats by preprocessing file content on the file_text filter hook.','add support by preprocessing',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','node-metadata'),(6639,'Ivy','Ivy has builtin support for YAML file headers. Extensions can add support for additional metadata formats by preprocessing file content on the file_text filter hook.','add support for additional metadata formats',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','node-metadata'),(6640,'Ivy','This filter fires each time a node file is loaded from disk; it passes the raw file text along with a metadata dictionary. Callbacks can check the text for an appropriate header marker, process the header if found, and update the dictionary. They should return the text with the header stripped.','pass raw file text along_with metadata dictionary',0,'',''),(6641,'Ivy','This filter fires each time a node file is loaded from disk; it passes the raw file text along with a metadata dictionary. Callbacks can check the text for an appropriate header marker, process the header if found, and update the dictionary. They should return the text with the header stripped.','load node file from disk',0,'',''),(6642,'Ivy','This filter fires each time a node file is loaded from disk; it passes the raw file text along with a metadata dictionary. Callbacks can check the text for an appropriate header marker, process the header if found, and update the dictionary. They should return the text with the header stripped.','load time from disk',0,'',''),(6643,'Ivy','This filter fires each time a node file is loaded from disk; it passes the raw file text along with a metadata dictionary. Callbacks can check the text for an appropriate header marker, process the header if found, and update the dictionary. They should return the text with the header stripped.','check text for appropriate header marker',0,'',''),(6644,'Ivy','This filter fires each time a node file is loaded from disk; it passes the raw file text along with a metadata dictionary. Callbacks can check the text for an appropriate header marker, process the header if found, and update the dictionary. They should return the text with the header stripped.','process header',0,'',''),(6645,'Ivy','This filter fires each time a node file is loaded from disk; it passes the raw file text along with a metadata dictionary. Callbacks can check the text for an appropriate header marker, process the header if found, and update the dictionary. They should return the text with the header stripped.','update dictionary',0,'',''),(6646,'Ivy','This filter fires each time a node file is loaded from disk; it passes the raw file text along with a metadata dictionary. Callbacks can check the text for an appropriate header marker, process the header if found, and update the dictionary. They should return the text with the header stripped.','return text with header',0,'',''),(6647,'Ivy','The FILE_TEXT filter hook can be found in the ivy/utils.py file.','find FILE_TEXT filter hook in ivy/utils.py file',0,'',''),(6648,'Ivy','Ivy uses the Markdown package to render node files with a .md extension. You can add a\ndictionary of keyword arguments for the Markdown renderer to your site configuration file via a\nmarkdown_settings attribute, e.g.','render node files',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','markdown'),(6649,'Ivy','Ivy uses the Markdown package to render node files with a .md extension. You can add a\ndictionary of keyword arguments for the Markdown renderer to your site configuration file via a\nmarkdown_settings attribute, e.g.','add dictionary of keyword arguments',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','markdown'),(6650,'Ivy','Ivy uses the Markdown package to render node files with a .md extension. You can add a\ndictionary of keyword arguments for the Markdown renderer to your site configuration file via a\nmarkdown_settings attribute, e.g.','add dictionary to site configuration file',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','markdown'),(6651,'Ivy','Note that you can register a custom handler for .md files to use an alternative Markdown library of your choice.','use alternative Markdown library of choice',0,'',''),(6652,'Ivy','Ivy uses the Syntext package to render node files with a .stx extension. You can add a dictionary of keyword arguments for the Syntext renderer to your site configuration file via a syntext_settings attribute, e.g.','render node files',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','syntext'),(6653,'Ivy','Ivy uses the Syntext package to render node files with a .stx extension. You can add a dictionary of keyword arguments for the Syntext renderer to your site configuration file via a syntext_settings attribute, e.g.','add dictionary of keyword arguments',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','syntext'),(6654,'Ivy','Ivy uses the Syntext package to render node files with a .stx extension. You can add a dictionary of keyword arguments for the Syntext renderer to your site configuration file via a syntext_settings attribute, e.g.','add dictionary to site configuration file',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','syntext'),(6655,'Ivy','Ivy uses the Jinja package to render template files with a .jinja extension. You can add a\ndictionary of keyword arguments for the Jinja environment to your site configuration file via a\njinja_settings attribute.','render template files',0,'',''),(6656,'Ivy','Ivy uses the Jinja package to render template files with a .jinja extension. You can add a\ndictionary of keyword arguments for the Jinja environment to your site configuration file via a\njinja_settings attribute.','add dictionary of keyword arguments',0,'',''),(6657,'Ivy','Ivy uses the Jinja package to render template files with a .jinja extension. You can add a\ndictionary of keyword arguments for the Jinja environment to your site configuration file via a\njinja_settings attribute.','add dictionary to site configuration file',0,'',''),(6658,'Ivy','Ivy uses the Shortcodes package to process shortcodes in node files. You can add a dictionary of\nkeyword arguments for the shortcode parser to your site configuration file via a shortcode_settings attribute.','process shortcodes in node files',0,'',''),(6659,'Ivy','Ivy uses the Shortcodes package to process shortcodes in node files. You can add a dictionary of\nkeyword arguments for the shortcode parser to your site configuration file via a shortcode_settings attribute.','add dictionary of keyword arguments',0,'',''),(6660,'Ivy','Ivy uses the Shortcodes package to process shortcodes in node files. You can add a dictionary of\nkeyword arguments for the shortcode parser to your site configuration file via a shortcode_settings attribute.','add dictionary to site configuration file',0,'',''),(6661,'Ivy','The bundled Automenu extension automatically generates a menu containing links to every node in the site. The menu can be accessed in templates via the automenu attribute. This menu can be customized in three ways:','generate menu',0,'',''),(6662,'Ivy','The bundled Automenu extension automatically generates a menu containing links to every node in the site. The menu can be accessed in templates via the automenu attribute. This menu can be customized in three ways:','access menu in templates',0,'',''),(6663,'Ivy','The bundled Automenu extension automatically generates a menu containing links to every node in the site. The menu can be accessed in templates via the automenu attribute. This menu can be customized in three ways:','customize menu in ways',0,'',''),(6664,'Ivy','If a node has a menu_title attribute, its value will be used in the menu in place of the node\'s title.','use value in menu',0,'',''),(6665,'Ivy','By default entries are ordered alphabetically by filename. Entry order can be customized by giving nodes an integer menu_order attribute (positive or negative) with lower numbers coming first. The default order value is 0. (Note that the homepage is an exception and will always be the first entry in the menu.)','order entries',0,'',''),(6666,'Ivy','By default entries are ordered alphabetically by filename. Entry order can be customized by giving nodes an integer menu_order attribute (positive or negative) with lower numbers coming first. The default order value is 0. (Note that the homepage is an exception and will always be the first entry in the menu.)','customize entry order',0,'',''),(6667,'Ivy','If a node has a menu_exclude attribute set to true it (and its children) will be omitted from the menu.','set  to true',0,'',''),(6668,'Ivy','If a node has a menu_exclude attribute set to true it (and its children) will be omitted from the menu.','omit  from menu',0,'',''),(6669,'Ivy','Only nodes which have a menu_title or title attribute are included in the menu.','include nodes in menu',0,'',''),(6670,'Ivy','This plugin adds support for TOML metadata headers as an alternative to YAML.','add support as alternative',0,'',''),(6671,'Ivy','This plugin adds support for TOML metadata headers as an alternative to YAML.','add support for TOML metadata headers',0,'',''),(6672,'Ivy','A clean, responsive, text-focused theme for Ivy.\nThis is the theme I use for my own personal website.','use theme for own personal website',0,'',''),(6673,'Ivy','No. Ivy is designed to be easy to use, with lots of flexibility under the hood if you\'re prepared to write a little extension code. Execution speed isn\'t a significant design goal as it\'s simply irrelevant for the kind of small personal or project websites Ivy is intended to be used for.','write little extension code',0,'',''),(6674,'Ivy','No. Ivy is designed to be easy to use, with lots of flexibility under the hood if you\'re prepared to write a little extension code. Execution speed isn\'t a significant design goal as it\'s simply irrelevant for the kind of small personal or project websites Ivy is intended to be used for.','use  with lots',0,'',''),(6675,'Ivy','No. Ivy is designed to be easy to use, with lots of flexibility under the hood if you\'re prepared to write a little extension code. Execution speed isn\'t a significant design goal as it\'s simply irrelevant for the kind of small personal or project websites Ivy is intended to be used for.','use  under hood',0,'',''),(6676,'Ivy','No. Ivy is designed to be easy to use, with lots of flexibility under the hood if you\'re prepared to write a little extension code. Execution speed isn\'t a significant design goal as it\'s simply irrelevant for the kind of small personal or project websites Ivy is intended to be used for.','design ivy',0,'',''),(6677,'Ivy','Holly is a blog-engine plugin for Ivy. It adds support for WordPress-style post and tag indexes.','add support for wordpress-style post',0,'',''),(6678,'Ivy','Holly is a blog-engine plugin for Ivy. It adds support for WordPress-style post and tag indexes.','add support for tag indexes',0,'',''),(6679,'Ivy','Image files, along with any other static assets, should be stored in the site\'s resources directory, res. The content of this directory is copied to the output directory when the site is built.','store image files along_with other static assets',0,'',''),(6680,'Ivy','Image files, along with any other static assets, should be stored in the site\'s resources directory, res. The content of this directory is copied to the output directory when the site is built.','store image files in resources directory',0,'',''),(6681,'Ivy','As an example, assume we have a file named photo.jpg stored in a directory named images within the res directory, i.e.','store  in directory',1,'http://www.dmulholl.com/docs/ivy/main/faq.html','where-do-i-put-my-image-files'),(6682,'Ivy','This file will be copied to the output directory and can be accessed in templates and node files via the URL:','access file in templates node files',1,'http://www.dmulholl.com/docs/ivy/main/faq.html','where-do-i-put-my-image-files'),(6683,'Ivy','Ivy has no special support for WordPress-style featured images but we can implement similar functionality simply by adding the image name as an attribute to the page header, e.g.','implement similar functionality by adding',1,'http://www.dmulholl.com/docs/ivy/main/faq.html','does-ivy-support-featured-images-or-image-galleries'),(6684,'Ivy','Ivy has no special support for WordPress-style featured images but we can implement similar functionality simply by adding the image name as an attribute to the page header, e.g.','add image name as attribute',1,'http://www.dmulholl.com/docs/ivy/main/faq.html','does-ivy-support-featured-images-or-image-galleries'),(6685,'Ivy','Ivy has no special support for WordPress-style featured images but we can implement similar functionality simply by adding the image name as an attribute to the page header, e.g.','add image name to page header',1,'http://www.dmulholl.com/docs/ivy/main/faq.html','does-ivy-support-featured-images-or-image-galleries'),(6686,'Ivy','We can then check for the presence of a featured image in the appropriate template file:','check  for presence',1,'http://www.dmulholl.com/docs/ivy/main/faq.html','does-ivy-support-featured-images-or-image-galleries'),(6687,'Ivy','YAML supports lists so we can implement galleries in a similar manner by adding a list of image names to the header and then iterating over the list in the template file:','implement galleries by iterating',1,'http://www.dmulholl.com/docs/ivy/main/faq.html','does-ivy-support-featured-images-or-image-galleries'),(6688,'Ivy','YAML supports lists so we can implement galleries in a similar manner by adding a list of image names to the header and then iterating over the list in the template file:','implement galleries by adding',1,'http://www.dmulholl.com/docs/ivy/main/faq.html','does-ivy-support-featured-images-or-image-galleries'),(6689,'Ivy','YAML supports lists so we can implement galleries in a similar manner by adding a list of image names to the header and then iterating over the list in the template file:','add list of image names',1,'http://www.dmulholl.com/docs/ivy/main/faq.html','does-ivy-support-featured-images-or-image-galleries'),(6690,'Ivy','YAML supports lists so we can implement galleries in a similar manner by adding a list of image names to the header and then iterating over the list in the template file:','add list to header',1,'http://www.dmulholl.com/docs/ivy/main/faq.html','does-ivy-support-featured-images-or-image-galleries'),(6691,'Ivy','YAML doesn\'t support unquoted values that begin with an @ symbol so you\'ll get an error message if you add a bare @root/ URL to a YAML header, e.g.','get error message',1,'http://www.dmulholl.com/docs/ivy/main/faq.html','why-do-i-get-an-error-when-i-add-a-url-to-a-yaml-header'),(6692,'Ivy','YAML doesn\'t support unquoted values that begin with an @ symbol so you\'ll get an error message if you add a bare @root/ URL to a YAML header, e.g.','add bare @root / URL to YAML header',1,'http://www.dmulholl.com/docs/ivy/main/faq.html','why-do-i-get-an-error-when-i-add-a-url-to-a-yaml-header'),(6693,'Ivy','One of the nicest things about a static website is that it\'s completely independent of the tool used to build it. You can host your website anywhere you like — in the simplest case you can \'deploy\' it simply by double-clicking on the .html files to view them locally in your browser.','host website',0,'',''),(6694,'Ivy','One of the nicest things about a static website is that it\'s completely independent of the tool used to build it. You can host your website anywhere you like — in the simplest case you can \'deploy\' it simply by double-clicking on the .html files to view them locally in your browser.','deploy simplest case by double-clicking',0,'',''),(6695,'Ivy','The simplest option to get started is to use a service like Github Pages which will host static websites for free.','use service like github Pages',0,'',''),(6696,'Ivy','The simplest option to get started is to use a service like Github Pages which will host static websites for free.','host static websites like github Pages',0,'',''),(6697,'Ivy','The simplest option to get started is to use a service like Github Pages which will host static websites for free.','host service like github Pages',0,'',''),(6698,'Ivy','The next step up is \'shared web hosting\' — it\'s cheap, flexible, and lots of online companies offer it. I\'ve used NearlyFreeSpeech myself and been happy with their service.','share â',0,'',''),(6699,'Ivy','The next step up is \'shared web hosting\' — it\'s cheap, flexible, and lots of online companies offer it. I\'ve used NearlyFreeSpeech myself and been happy with their service.','share next step',0,'',''),(6700,'Ivy','If you need more control over your hosting environment you can run your own webserver (typically Apache or Nginx) on a virtual server machine (a VPS or Virtual Private Server) you rent from a company like Digital Ocean.','run own webserver on virtual server machine',0,'',''),(6701,'Ivy','You can add a disable flag to a node\'s metadata header:','add disable flag to metadata header',1,'http://www.dmulholl.com/docs/ivy/main/faq.html','can-i-disable-a-node'),(6702,'Ivy','This will stop Ivy from producing an output HTML page for the node.','produce output HTML page for node',0,'',''),(6703,'Ivy','Sure. Ivy defaults to using the Markdown library to render .md files but you can register a custom handler to use any library you like.','use markdown library to render',0,'',''),(6704,'Ivy','Sure. Ivy defaults to using the Markdown library to render .md files but you can register a custom handler to use any library you like.','use library',0,'',''),(6705,'Ivy','Here\'s a simple demo of an Ivy site using the KaTeX JavaScript library to render LaTeX markup.','use KaTeX JavaScript library',0,'',''),(6706,'Ivy','Here\'s a simple demo of an Ivy site using the KaTeX JavaScript library to render LaTeX markup.','render LaTeX markup',0,'',''),(6707,'Ivy','Shortcodes are powerful — you can use them to inject content into a node\'s text or to customize the formatting of a block of content.','customize formatting of block',0,'',''),(6708,'Ivy','Shortcodes are implemented by the shortcodes package, an external library.\nAn Ivy extension can register a new shortcode tag using the shortcode package\'s @register() decorator:','implement shortcodes',1,'http://www.dmulholl.com/docs/ivy/main/shortcodes.html','registering-shortcodes'),(6709,'Ivy','Shortcodes are implemented by the shortcodes package, an external library.\nAn Ivy extension can register a new shortcode tag using the shortcode package\'s @register() decorator:','use  decorator',1,'http://www.dmulholl.com/docs/ivy/main/shortcodes.html','registering-shortcodes'),(6710,'Ivy','Positional and keyword arguments are passed as strings. The handler function itself should return a string which will replace the shortcode in the text.','pass positional keyword arguments as strings',0,'',''),(6711,'Ivy','Positional and keyword arguments are passed as strings. The handler function itself should return a string which will replace the shortcode in the text.','return string',0,'',''),(6712,'Ivy','Positional and keyword arguments are passed as strings. The handler function itself should return a string which will replace the shortcode in the text.','replace shortcode in text',0,'',''),(6713,'Ivy','Positional and keyword arguments are passed as strings. The handler function itself should return a string which will replace the shortcode in the text.','replace string in text',0,'',''),(6714,'Ivy','Note that shortcodes are processed before node text is rendered into HTML so any content injected by a shortcode should be compatible with the existing text\'s format (Markdown, Syntext, etc.).','render node text into HTML',0,'',''),(6715,'Ivy','Note that shortcodes are processed before node text is rendered into HTML so any content injected by a shortcode should be compatible with the existing text\'s format (Markdown, Syntext, etc.).','process shortcodes',0,'',''),(6716,'Ivy','Here\'s a sample shortcode you could use to inject the raw content of a file from the site\'s includes directory, inc, directly into a node file:','use sample shortcode',1,'http://www.dmulholl.com/docs/ivy/main/shortcodes.html','example-include-raw'),(6717,'Ivy','Here\'s a sample shortcode you could use to inject the raw content of a file from the site\'s includes directory, inc, directly into a node file:','include site',1,'http://www.dmulholl.com/docs/ivy/main/shortcodes.html','example-include-raw'),(6718,'Ivy','To use this shortcode, just supply the name of the file you want to include, e.g.','use shortcode e.g.',1,'http://www.dmulholl.com/docs/ivy/main/shortcodes.html','example-include-raw'),(6719,'Ivy','The shortcode will be replaced by the content of the file.','replace shortcode',0,'',''),(6720,'Ivy','Ivy already loads and renders the content of files from the includes directory to make it available in template files. What if you want to include this pre-rendered content in a node file?','include directory',1,'http://www.dmulholl.com/docs/ivy/main/shortcodes.html','example-include-rendered'),(6721,'Ivy','Ivy already loads and renders the content of files from the includes directory to make it available in template files. What if you want to include this pre-rendered content in a node file?','include pre-rendered content in node file',1,'http://www.dmulholl.com/docs/ivy/main/shortcodes.html','example-include-rendered'),(6722,'Ivy','To use this shortcode, just supply the name of the file you want to include, leaving off the file extension, e.g.','use shortcode',1,'http://www.dmulholl.com/docs/ivy/main/shortcodes.html','example-include-rendered'),(6723,'Ivy','The shortcode will be replaced by the rendered content of the file.','replace shortcode',0,'',''),(6724,'Ivy','To use this shortcode, just supply the @root/ url of the target node, e.g.','use shortcode',1,'http://www.dmulholl.com/docs/ivy/main/shortcodes.html','example-list-children'),(6725,'Ivy','The shortcode will be replaced by the list of links.','replace shortcode',0,'',''),(6726,'Ivy','Here\'s an example of a block-level shortcode wrapping a block of content. Imagine we want to add special styling to quotes with the name of the quote\'s author attached:','wrap block of content',1,'http://www.dmulholl.com/docs/ivy/main/shortcodes.html','example-quote'),(6727,'Ivy','Here\'s an example of a block-level shortcode wrapping a block of content. Imagine we want to add special styling to quotes with the name of the quote\'s author attached:','add special styling with name',1,'http://www.dmulholl.com/docs/ivy/main/shortcodes.html','example-quote'),(6728,'Ivy','Here\'s an example of a block-level shortcode wrapping a block of content. Imagine we want to add special styling to quotes with the name of the quote\'s author attached:','add special styling to quotes',1,'http://www.dmulholl.com/docs/ivy/main/shortcodes.html','example-quote'),(6729,'Ivy','We can use this shortcode in a source file by supplying the author\'s name as an argument:','use shortcode in source file',1,'http://www.dmulholl.com/docs/ivy/main/shortcodes.html','example-quote'),(6730,'Ivy','We can use this shortcode in a source file by supplying the author\'s name as an argument:','use shortcode by supplying',1,'http://www.dmulholl.com/docs/ivy/main/shortcodes.html','example-quote'),(6731,'Ivy','Install Ivy from the Python Package Index using pip:','use pip',1,'http://www.dmulholl.com/docs/ivy/main/index.html','installation'),(6732,'Ivy','Once Ivy is installed, create a new directory for your site and cd into it:','create new directory for site',1,'http://www.dmulholl.com/docs/ivy/main/quickstart.html',''),(6733,'Ivy','Once Ivy is installed, create a new directory for your site and cd into it:','create new directory for cd',1,'http://www.dmulholl.com/docs/ivy/main/quickstart.html',''),(6734,'Ivy','Once Ivy is installed, create a new directory for your site and cd into it:','install ivy',1,'http://www.dmulholl.com/docs/ivy/main/quickstart.html',''),(6735,'Ivy','Initialize the site directory using the init command:','initialize site directory',1,'http://www.dmulholl.com/docs/ivy/main/quickstart.html',''),(6736,'Ivy','Initialize the site directory using the init command:','use init command',1,'http://www.dmulholl.com/docs/ivy/main/quickstart.html',''),(6737,'Ivy','Ivy will create the following directory structure for your site:','create following directory structure for site',1,'http://www.dmulholl.com/docs/ivy/main/quickstart.html',''),(6738,'Ivy','Ivy initializes your src directory with a simple skeleton site which you can build immediately using the build command:','initialize src directory with simple skeleton site',1,'http://www.dmulholl.com/docs/ivy/main/quickstart.html',''),(6739,'Ivy','You can run the build command from the site directory itself or from any of its subdirectories. It tells Ivy to render the text files in the src directory into HTML and place the output in an out directory.','render text files into HTML',0,'',''),(6740,'Ivy','You can run the build command from the site directory itself or from any of its subdirectories. It tells Ivy to render the text files in the src directory into HTML and place the output in an out directory.','render text files in src directory',0,'',''),(6741,'Ivy','You can run the build command from the site directory itself or from any of its subdirectories. It tells Ivy to render the text files in the src directory into HTML and place the output in an out directory.','place output in out directory',0,'',''),(6742,'Ivy','Run the build command and take a look at the output. You can open the HTML files directly in your browser or use Ivy\'s builtin test server to serve the contents of the out directory:','open HTML files in browser',1,'http://www.dmulholl.com/docs/ivy/main/quickstart.html',''),(6743,'Ivy','Run the build command and take a look at the output. You can open the HTML files directly in your browser or use Ivy\'s builtin test server to serve the contents of the out directory:','use builtin test server',1,'http://www.dmulholl.com/docs/ivy/main/quickstart.html',''),(6744,'Ivy','Ivy will build the site using its default graphite theme, which you can find in the lib folder. Try rebuilding the site using the debug theme which is less pretty but provides a lot of useful information that can help you when building or customizing your own themes:','use default graphite theme',1,'http://www.dmulholl.com/docs/ivy/main/quickstart.html',''),(6745,'Ivy','Ivy will build the site using its default graphite theme, which you can find in the lib folder. Try rebuilding the site using the debug theme which is less pretty but provides a lot of useful information that can help you when building or customizing your own themes:','find  in lib folder',1,'http://www.dmulholl.com/docs/ivy/main/quickstart.html',''),(6746,'Ivy','Ivy will build the site using its default graphite theme, which you can find in the lib folder. Try rebuilding the site using the debug theme which is less pretty but provides a lot of useful information that can help you when building or customizing your own themes:','rebuild site',1,'http://www.dmulholl.com/docs/ivy/main/quickstart.html',''),(6747,'Ivy','Ivy will build the site using its default graphite theme, which you can find in the lib folder. Try rebuilding the site using the debug theme which is less pretty but provides a lot of useful information that can help you when building or customizing your own themes:','use debug theme',1,'http://www.dmulholl.com/docs/ivy/main/quickstart.html',''),(6748,'Ivy','Ivy will build the site using its default graphite theme, which you can find in the lib folder. Try rebuilding the site using the debug theme which is less pretty but provides a lot of useful information that can help you when building or customizing your own themes:','provide lot of useful information',1,'http://www.dmulholl.com/docs/ivy/main/quickstart.html',''),(6749,'Ivy','Ivy will build the site using its default graphite theme, which you can find in the lib folder. Try rebuilding the site using the debug theme which is less pretty but provides a lot of useful information that can help you when building or customizing your own themes:','provide debug theme of useful information',1,'http://www.dmulholl.com/docs/ivy/main/quickstart.html',''),(6750,'Ivy','You can run ivy --help to see a list of all the available commands. Note that you can get help for a specific command by running','run ivy',1,'http://www.dmulholl.com/docs/ivy/main/quickstart.html',''),(6751,'Ivy','You can run ivy --help to see a list of all the available commands. Note that you can get help for a specific command by running','get help by running',1,'http://www.dmulholl.com/docs/ivy/main/quickstart.html',''),(6752,'Ivy','You can run ivy --help to see a list of all the available commands. Note that you can get help for a specific command by running','get help for specific command',1,'http://www.dmulholl.com/docs/ivy/main/quickstart.html',''),(6753,'Ivy','replacing  with the command name.','replace  with command name',0,'',''),(6754,'Ivy','You can build many different kinds of website using Ivy but it\'s particularly suited to building project documentation like the documentation you\'re looking at right now.','use ivy',0,'',''),(6755,'Ivy','Ivy has builtin support for content written in Markdown, Syntext, or plain HTML, but Ivy itself is format-agnostic — you can write your content in any format with a suitable Python library.','write content in format',0,'',''),(6756,'Ivy','Ivy has builtin support for content written in Markdown, Syntext, or plain HTML, but Ivy itself is format-agnostic — you can write your content in any format with a suitable Python library.','write  in markdown',0,'',''),(6757,'Ivy','Ivy has builtin support for content written in Markdown, Syntext, or plain HTML, but Ivy itself is format-agnostic — you can write your content in any format with a suitable Python library.','write  in syntext',0,'',''),(6758,'Ivy','Ivy has builtin support for content written in Markdown, Syntext, or plain HTML, but Ivy itself is format-agnostic — you can write your content in any format with a suitable Python library.','write  in plain HTML',0,'',''),(6759,'Ivy','Similarly, Ivy has builtin support for Jinja and Ibis templates but can use any template language with a suitable Python library.','use template language with suitable Python library',0,'',''),(6760,'Ivy','This work has been placed in the public domain.','place work in public domain',0,'',''),(6761,'Ivy','Ivy borrows its idea of themes from WordPress where a theme is a directory of templates, styles, and scripts that together provide the look and feel for a site.','provide look',0,'',''),(6762,'Ivy','Ivy borrows its idea of themes from WordPress where a theme is a directory of templates, styles, and scripts that together provide the look and feel for a site.','provide scripts',0,'',''),(6763,'Ivy','This idea is central. You can swap between themes and completely change the appearance of your site without touching its content.','change appearance of site',0,'',''),(6764,'Ivy','This idea is central. You can swap between themes and completely change the appearance of your site without touching its content.','change appearance without touching',0,'',''),(6765,'Ivy','Themes should be placed in the site\'s lib directory, and the name of the active theme directory specified in the site\'s configuration file.','place themes in lib directory',1,'http://www.dmulholl.com/docs/ivy/main/themes.html','location'),(6766,'Ivy','Themes should be placed in the site\'s lib directory, and the name of the active theme directory specified in the site\'s configuration file.','specify  in configuration file',1,'http://www.dmulholl.com/docs/ivy/main/themes.html','location'),(6767,'Ivy','Ivy ships with a small collection of bundled themes including graphite, the default theme you\'re looking at right now, and debug, a diagnostic theme useful when designing themes or debugging sites.','design themes',0,'',''),(6768,'Ivy','Note that you can override the currently active theme with the build command\'s --theme flag:','override active theme with theme flag',1,'http://www.dmulholl.com/docs/ivy/main/themes.html','location'),(6769,'Ivy','Ivy searches for a named theme first in the site\'s theme library, then (if it exists) in the global theme library specified by the $IVY_THEMES environment variable. Finally it searches among the default themes bundled with Ivy itself.','specify  by $IVY_THEMES environment variable',0,'',''),(6770,'Ivy','Ivy searches for a named theme first in the site\'s theme library, then (if it exists) in the global theme library specified by the $IVY_THEMES environment variable. Finally it searches among the default themes bundled with Ivy itself.','specify  for ivy searches',0,'',''),(6771,'Ivy','Ivy searches for a named theme first in the site\'s theme library, then (if it exists) in the global theme library specified by the $IVY_THEMES environment variable. Finally it searches among the default themes bundled with Ivy itself.','search  among default themes',0,'',''),(6772,'Ivy','The content of the resources directory is copied to the output directory when the site is built.\nA theme should store its static assets in this directory, e.g. CSS, JavaScript, font, and image files.','store static assets in font',0,'',''),(6773,'Ivy','The content of the resources directory is copied to the output directory when the site is built.\nA theme should store its static assets in this directory, e.g. CSS, JavaScript, font, and image files.','store static assets in image files',0,'',''),(6774,'Ivy','The content of the resources directory is copied to the output directory when the site is built.\nA theme should store its static assets in this directory, e.g. CSS, JavaScript, font, and image files.','store static assets in directory',0,'',''),(6775,'Ivy','The content of the resources directory is copied to the output directory when the site is built.\nA theme should store its static assets in this directory, e.g. CSS, JavaScript, font, and image files.','store static assets in e.g. CSS',0,'',''),(6776,'Ivy','The content of the resources directory is copied to the output directory when the site is built.\nA theme should store its static assets in this directory, e.g. CSS, JavaScript, font, and image files.','store static assets in JavaScript',0,'',''),(6777,'Ivy','The templates directory is where Ivy looks for the theme\'s template files.\nThis directory is also where Jinja and Ibis will look for files included in templates using {% include %} tags.','use {% include %} tags',0,'',''),(6778,'Ivy','The templates directory is where Ivy looks for the theme\'s template files.\nThis directory is also where Jinja and Ibis will look for files included in templates using {% include %} tags.','include  in templates',0,'',''),(6779,'Ivy','Themes can bundle extensions for Ivy by placing Python modules or packages in the extensions directory.\nThese will be loaded automatically by Ivy.','place Python modules in extensions directory',0,'',''),(6780,'Ivy','Themes can bundle extensions for Ivy by placing Python modules or packages in the extensions directory.\nThese will be loaded automatically by Ivy.','place packages in extensions directory',0,'',''),(6781,'Ivy','There are countless templating languages and Ivy can use any of them, but it has builtin support for Jinja and Ibis. Ivy determines the language of a template file by looking at its extension — .jinja for Jinja and .ibis for Ibis.','determine language by looking',0,'',''),(6782,'Ivy','There are countless templating languages and Ivy can use any of them, but it has builtin support for Jinja and Ibis. Ivy determines the language of a template file by looking at its extension — .jinja for Jinja and .ibis for Ibis.','determine language of template file',0,'',''),(6783,'Ivy','You can add support for alternative templating languages via plugins.','add support for alternative templating languages',0,'',''),(6784,'Ivy','When Ivy generates a HTML page for a node it searches for the appropriate template file to use in reverse order of specificity (most specific first, least specific last).','generate HTML page for node',1,'http://www.dmulholl.com/docs/ivy/main/themes.html','template-hierarchy'),(6785,'Ivy','When Ivy generates a HTML page for a node it searches for the appropriate template file to use in reverse order of specificity (most specific first, least specific last).','search  for appropriate template file',1,'http://www.dmulholl.com/docs/ivy/main/themes.html','template-hierarchy'),(6786,'Ivy','Ivy will search for a template file for this node in the following order:','search  for template file',1,'http://www.dmulholl.com/docs/ivy/main/themes.html','template-hierarchy'),(6787,'Ivy','Ultimately, Ivy will always check for a template file called node.* — this is the default template name and the only template file actually required by a theme.','check  for template file',0,'',''),(6788,'Ivy','A node can override this process by specifying a custom template name in its header:','override process by specifying',1,'http://www.dmulholl.com/docs/ivy/main/themes.html','template-hierarchy'),(6789,'Ivy','A node can override this process by specifying a custom template name in its header:','specify custom template name in header',1,'http://www.dmulholl.com/docs/ivy/main/themes.html','template-hierarchy'),(6790,'Ivy','Note that the file extension should be omitted from the template name.','omit file extension from template name',0,'',''),(6791,'Ivy','All of Ivy\'s code has been placed in the public domain and is free for personal and commercial use. No attribution is required.','place  in public domain',1,'http://www.dmulholl.com/docs/ivy/main/license.html','ivy'),(6792,'Ivy','All other theme code has been placed in the public domain.','place other theme code in public domain',0,'',''),(6793,'GitPython','Implements an Object which may be Blobs, Trees, Commits and Tags','implement Object',0,'',''),(6794,'GitPython','Initialize an object by identifying it by its binary sha.\nAll keyword arguments will be set on demand if None.','initialize object',0,'',''),(6795,'GitPython','Initialize an object by identifying it by its binary sha.\nAll keyword arguments will be set on demand if None.','identify  by binary sha',0,'',''),(6796,'GitPython','Initialize an object by identifying it by its binary sha.\nAll keyword arguments will be set on demand if None.','set keyword arguments if none',0,'',''),(6797,'GitPython','Initialize an object by identifying it by its binary sha.\nAll keyword arguments will be set on demand if None.','set keyword arguments on demand',0,'',''),(6798,'GitPython','Writes our data directly to the given output stream\n:param ostream: File object compatible stream object.\n:return: self','write data to given output stream',0,'',''),(6799,'GitPython','Initialize a newly instanced IndexObject','initialize instanced IndexObject',0,'',''),(6800,'GitPython','This class will act lazily on some of its attributes and will query the\nvalue on demand only if it involves calling the git binary.','call git binary',0,'',''),(6801,'GitPython','Instantiate a new Commit. All keyword arguments taking None as default will\nbe implicitly set on first query.','instantiate new commit',0,'',''),(6802,'GitPython','Instantiate a new Commit. All keyword arguments taking None as default will\nbe implicitly set on first query.','set keyword arguments on first query',0,'',''),(6803,'GitPython','Search the commit message for any co-authors of this commit.\nDetails on co-authors: https://github.blog/2018-01-29-commit-together-with-co-authors/','search commit message for co-authors',0,'',''),(6804,'GitPython','Commit the given tree, creating a commit object.','create commit object',0,'',''),(6805,'GitPython','Find all commits matching the given criteria.','match given criteria',0,'',''),(6806,'GitPython','Any values provided as keyword arguments will replace the\ncorresponding attribute in the new object.','replace corresponding attribute in new object',0,'',''),(6807,'GitPython','Create a git stat from changes between this commit and its first parent\nor from all changes done if this is the very first commit.','create git stat from changes',0,'',''),(6808,'GitPython','Create a git stat from changes between this commit and its first parent\nor from all changes done if this is the very first commit.','create git stat from changes',0,'',''),(6809,'GitPython','Get the trailers of the message as dictionary','get trailers of message',0,'',''),(6810,'GitPython','This functions calls git interpret-trailers --parse onto the message\nto extract the trailer information. The key value pairs are stripped of\nleading and trailing whitespaces before they get saved into a dictionary.','call git interpret-trailers parse',0,'',''),(6811,'GitPython','This functions calls git interpret-trailers --parse onto the message\nto extract the trailer information. The key value pairs are stripped of\nleading and trailing whitespaces before they get saved into a dictionary.','save  into dictionary',0,'',''),(6812,'GitPython','A utility class providing methods to alter the underlying cache in a list-like fashion.','provide methods',0,'',''),(6813,'GitPython','Once all adjustments are complete, the _cache, which really is a reference to\nthe cache of a tree, will be sorted. Assuring it will be in a serializable state','sort _ cache',0,'',''),(6814,'GitPython','Deletes an item with the given name if it exists','delete item with given name',0,'',''),(6815,'GitPython','Initialize self.  See help(type(self)) for accurate signature.','initialize self',0,'',''),(6816,'GitPython','Add the given item to the tree. If an item with the given name already\nexists, nothing will be done, but a ValueError will be raised if the\nsha and mode of the existing item do not match the one you add, unless\nforce is True','add given item to tree',0,'',''),(6817,'GitPython','Add the given item to the tree. If an item with the given name already\nexists, nothing will be done, but a ValueError will be raised if the\nsha and mode of the existing item do not match the one you add, unless\nforce is True','raise ValueError',0,'',''),(6818,'GitPython','Add the given item to the tree, its correctness is assumed, which\nputs the caller into responsibility to assure the input is correct.\nFor more information on the parameters, see add\n:param binsha: 20 byte binary sha','add given item to tree',0,'',''),(6819,'GitPython','Add the given item to the tree, its correctness is assumed, which\nputs the caller into responsibility to assure the input is correct.\nFor more information on the parameters, see add\n:param binsha: 20 byte binary sha','add param binsha for more information',0,'',''),(6820,'GitPython','Call this method once you are done modifying the tree information.\nIt may be called several times, but be aware that each call will cause\na sort operation\n:return self:','call method',0,'',''),(6821,'GitPython','Call this method once you are done modifying the tree information.\nIt may be called several times, but be aware that each call will cause\na sort operation\n:return self:','modify tree information',0,'',''),(6822,'GitPython','Call this method once you are done modifying the tree information.\nIt may be called several times, but be aware that each call will cause\na sort operation\n:return self:','return self',0,'',''),(6823,'GitPython','Find the named object in this tree’s contents\n:return: git.Blob or git.Tree or git.Submodule','find named object in contents',0,'',''),(6824,'GitPython','For documentation, see util.Traversable._traverse()\nTrees are set to visit_once = False to gain more performance in the traversal','set trees to visit_once = false',0,'',''),(6825,'GitPython','Write the give list of entries into a stream using its write method\n:param entries: sorted list of tuples with (binsha, mode, name)\n:param write: write method which takes a data string','use write method',0,'',''),(6826,'GitPython','Write the give list of entries into a stream using its write method\n:param entries: sorted list of tuples with (binsha, mode, name)\n:param write: write method which takes a data string','sort list of tuples',0,'',''),(6827,'GitPython','Write the give list of entries into a stream using its write method\n:param entries: sorted list of tuples with (binsha, mode, name)\n:param write: write method which takes a data string','write method',0,'',''),(6828,'GitPython','Compare with another submodule','compare  with submodule',0,'',''),(6829,'GitPython','Hash this instance using its logical id, not the sha','use logical id',0,'',''),(6830,'GitPython','Initialize this instance with its attributes. We only document the ones\nthat differ from IndexObject','initialize instance with attributes',0,'',''),(6831,'GitPython','Compare with another submodule for inequality','compare  with submodule',0,'',''),(6832,'GitPython','Add a new submodule to the given repository. This will alter the index\nas well as the .gitmodules file, but will not create a new commit.\nIf the submodule already exists, no matter if the configuration differs\nfrom the one provided, the existing submodule will be returned.','add new submodule to given repository',0,'',''),(6833,'GitPython','Add a new submodule to the given repository. This will alter the index\nas well as the .gitmodules file, but will not create a new commit.\nIf the submodule already exists, no matter if the configuration differs\nfrom the one provided, the existing submodule will be returned.','return existing submodule',0,'',''),(6834,'GitPython','Move the submodule to a another module path. This involves physically moving\nthe repository at our current path, changing the configuration, as well as\nadjusting our index entry accordingly.','move submodule to module path',0,'',''),(6835,'GitPython','Move the submodule to a another module path. This involves physically moving\nthe repository at our current path, changing the configuration, as well as\nadjusting our index entry accordingly.','change configuration',0,'',''),(6836,'GitPython','Move the submodule to a another module path. This involves physically moving\nthe repository at our current path, changing the configuration, as well as\nadjusting our index entry accordingly.','adjust index entry',0,'',''),(6837,'GitPython','Remove this submodule from the repository. This will remove our entry\nfrom the .gitmodules file and the entry in the .git / config file.','remove submodule from repository',0,'',''),(6838,'GitPython','Remove this submodule from the repository. This will remove our entry\nfrom the .gitmodules file and the entry in the .git / config file.','remove entry',0,'',''),(6839,'GitPython','Rename this submodule\n:note: This method takes care of renaming the submodule in various places, such as','rename submodule',0,'',''),(6840,'GitPython','Rename this submodule\n:note: This method takes care of renaming the submodule in various places, such as','rename submodule in various places',0,'',''),(6841,'GitPython','As .gitmodules will be changed, you would need to make a commit afterwards. The changed .gitmodules file\nwill already be added to the index','change gitmodules',0,'',''),(6842,'GitPython','As .gitmodules will be changed, you would need to make a commit afterwards. The changed .gitmodules file\nwill already be added to the index','add gitmodules file to index',0,'',''),(6843,'GitPython','Set this instance to use the given commit whose tree is supposed to\ncontain the .gitmodules blob.','set instance',0,'',''),(6844,'GitPython','Set this instance to use the given commit whose tree is supposed to\ncontain the .gitmodules blob.','use given commit',0,'',''),(6845,'GitPython','Update the repository of this submodule to point to the checkout\nwe point at with the binsha of this instance.','update repository of submodule',0,'',''),(6846,'GitPython','Class providing detailed progress information to the caller who should\nderive from it and implement the update(...) message','provide detailed progress information to caller',0,'',''),(6847,'GitPython','Class providing detailed progress information to the caller who should\nderive from it and implement the update(...) message','implement update(...) message',0,'',''),(6848,'GitPython','Class providing detailed progress information to the caller who should\nderive from it and implement the update(...) message','implement caller',0,'',''),(6849,'GitPython','Update the submodules of this repository to the current HEAD commit.\nThis method behaves smartly by determining changes of the path of a submodules\nrepository, next to changes to the to-be-checked-out commit or the branch to be\nchecked out. This works if the submodules ID does not change.\nAdditionally it will detect addition and removal of submodules, which will be handled\ngracefully.','update submodules of repository',0,'',''),(6850,'GitPython','Update the submodules of this repository to the current HEAD commit.\nThis method behaves smartly by determining changes of the path of a submodules\nrepository, next to changes to the to-be-checked-out commit or the branch to be\nchecked out. This works if the submodules ID does not change.\nAdditionally it will detect addition and removal of submodules, which will be handled\ngracefully.','update submodules to current HEAD',0,'',''),(6851,'GitPython','Update the submodules of this repository to the current HEAD commit.\nThis method behaves smartly by determining changes of the path of a submodules\nrepository, next to changes to the to-be-checked-out commit or the branch to be\nchecked out. This works if the submodules ID does not change.\nAdditionally it will detect addition and removal of submodules, which will be handled\ngracefully.','determine changes of path',0,'',''),(6852,'GitPython','Update the submodules of this repository to the current HEAD commit.\nThis method behaves smartly by determining changes of the path of a submodules\nrepository, next to changes to the to-be-checked-out commit or the branch to be\nchecked out. This works if the submodules ID does not change.\nAdditionally it will detect addition and removal of submodules, which will be handled\ngracefully.','handle submodules',0,'',''),(6853,'GitPython','Utility class which adds more opcodes to the UpdateProgress','add utility class',0,'',''),(6854,'GitPython','Find the remote branch matching the name of the given branch or raise InvalidGitRepositoryError','find remote branch',0,'',''),(6855,'GitPython','Find the remote branch matching the name of the given branch or raise InvalidGitRepositoryError','match name of given branch',0,'',''),(6856,'GitPython','Find the remote branch matching the name of the given branch or raise InvalidGitRepositoryError','raise InvalidGitRepositoryError',0,'',''),(6857,'GitPython','Catches calls to _write, and updates the .gitmodules blob in the index\nwith the new data, if we have written into a stream. Otherwise it will\nadd the local file to the index to make it correspond with the working tree.\nAdditionally, the cache must be cleared','write  into stream',0,'',''),(6858,'GitPython','Catches calls to _write, and updates the .gitmodules blob in the index\nwith the new data, if we have written into a stream. Otherwise it will\nadd the local file to the index to make it correspond with the working tree.\nAdditionally, the cache must be cleared','add local file to index',0,'',''),(6859,'GitPython','Initialize a configuration reader to read the given file_or_files and to\npossibly allow changes to it by setting read_only False','read given file_or_files',0,'',''),(6860,'GitPython','Initialize a configuration reader to read the given file_or_files and to\npossibly allow changes to it by setting read_only False','set read_only false',0,'',''),(6861,'GitPython','Flush changes in our configuration file to the index','change  in configuration file',0,'',''),(6862,'GitPython','Flush changes in our configuration file to the index','change  to index',0,'',''),(6863,'GitPython','Set this instance’s submodule. It must be called before\nthe first write operation begins','set submodule',0,'',''),(6864,'GitPython','Write changes to our file, if there are changes at all','change  to file',0,'',''),(6865,'GitPython','Class wireing all calls to the contained Process instance.','call  to contained Process instance',0,'',''),(6866,'GitPython','Use this type to hide the underlying process to provide access only to a specified\nstream. The process is usually wrapped into an AutoInterrupt class to kill\nit if the instance goes out of scope.','use type',0,'',''),(6867,'GitPython','Use this type to hide the underlying process to provide access only to a specified\nstream. The process is usually wrapped into an AutoInterrupt class to kill\nit if the instance goes out of scope.','hide underlying process',0,'',''),(6868,'GitPython','Use this type to hide the underlying process to provide access only to a specified\nstream. The process is usually wrapped into an AutoInterrupt class to kill\nit if the instance goes out of scope.','provide access to specified stream',0,'',''),(6869,'GitPython','Use this type to hide the underlying process to provide access only to a specified\nstream. The process is usually wrapped into an AutoInterrupt class to kill\nit if the instance goes out of scope.','wrap process into AutoInterrupt class',0,'',''),(6870,'GitPython','Simple interface to perform depth-first or breadth-first traversals\ninto one direction.\nSubclasses only need to implement one function.\nInstances of the Subclass must be hashable','perform depth-first breadth-first traversals into direction',0,'',''),(6871,'GitPython','Simple interface to perform depth-first or breadth-first traversals\ninto one direction.\nSubclasses only need to implement one function.\nInstances of the Subclass must be hashable','implement function',0,'',''),(6872,'GitPython','As above, but inverses the operation, returning a string that can be used\nin commit objects','return string',0,'',''),(6873,'GitPython','As above, but inverses the operation, returning a string that can be used\nin commit objects','use string',0,'',''),(6874,'GitPython','we convert utctz to the timezone in seconds, it is the format time.altzone\nreturns. Git stores it as UTC timezone which has the opposite sign as well,\nwhich explains the -1 * ( that was made explicit here )\n:param utctz: git utc timezone string, i.e. +0200','convert utctz to timezone',0,'',''),(6875,'GitPython','we convert utctz to the timezone in seconds, it is the format time.altzone\nreturns. Git stores it as UTC timezone which has the opposite sign as well,\nwhich explains the -1 * ( that was made explicit here )\n:param utctz: git utc timezone string, i.e. +0200','store  as UTC timezone',0,'',''),(6876,'GitPython','Same as committer(), but defines the main author. It may be specified in the environment,\nbut defaults to the committer','define main author',0,'',''),(6877,'GitPython','Same as committer(), but defines the main author. It may be specified in the environment,\nbut defaults to the committer','specify  in environment',0,'',''),(6878,'GitPython','Implements an Index that can be manipulated using a native implementation in\norder to save git command function calls wherever possible.','use native implementation',0,'',''),(6879,'GitPython','Implements an Index that can be manipulated using a native implementation in\norder to save git command function calls wherever possible.','save git command function calls',0,'',''),(6880,'GitPython','Implements an Index that can be manipulated using a native implementation in\norder to save git command function calls wherever possible.','manipulate implements',0,'',''),(6881,'GitPython','It provides custom merging facilities allowing to merge without actually changing\nyour index or your working tree. This way you can perform own test-merges based\non the index only without having to deal with the working copy. This is useful\nin case of partial working trees.','provide custom',0,'',''),(6882,'GitPython','It provides custom merging facilities allowing to merge without actually changing\nyour index or your working tree. This way you can perform own test-merges based\non the index only without having to deal with the working copy. This is useful\nin case of partial working trees.','change working tree',0,'',''),(6883,'GitPython','It provides custom merging facilities allowing to merge without actually changing\nyour index or your working tree. This way you can perform own test-merges based\non the index only without having to deal with the working copy. This is useful\nin case of partial working trees.','change index',0,'',''),(6884,'GitPython','It provides custom merging facilities allowing to merge without actually changing\nyour index or your working tree. This way you can perform own test-merges based\non the index only without having to deal with the working copy. This is useful\nin case of partial working trees.','perform own test-merges without having',0,'',''),(6885,'GitPython','You may read the entries dict or manipulate it using IndexEntry instance, i.e.:','use IndexEntry instance',1,'https://gitpython.readthedocs.io/en/stable/reference.html',''),(6886,'GitPython','Make sure you use index.write() once you are done manipulating the index directly\nbefore operating on it using the git command','use index.write()',0,'',''),(6887,'GitPython','Make sure you use index.write() once you are done manipulating the index directly\nbefore operating on it using the git command','manipulate index before operating',0,'',''),(6888,'GitPython','Make sure you use index.write() once you are done manipulating the index directly\nbefore operating on it using the git command','use git command',0,'',''),(6889,'GitPython','Initialize this Index instance, optionally from the given file_path.\nIf no file_path is given, we will be created from the current index file.','initialize Index instance from given file_path',0,'',''),(6890,'GitPython','Initialize this Index instance, optionally from the given file_path.\nIf no file_path is given, we will be created from the current index file.','create  from current index file',0,'',''),(6891,'GitPython','If a stream is not given, the stream will be initialized from the current\nrepository’s index on demand.','initialize stream from index',0,'',''),(6892,'GitPython','Add files from the working tree, specific blobs or BaseIndexEntries\nto the index.','add files from working tree',0,'',''),(6893,'GitPython','Add files from the working tree, specific blobs or BaseIndexEntries\nto the index.','add files from specific blobs',0,'',''),(6894,'GitPython','Add files from the working tree, specific blobs or BaseIndexEntries\nto the index.','add files from BaseIndexEntries',0,'',''),(6895,'GitPython','Multiple types of items are supported, types can be mixed within one call.\nDifferent types imply a different handling. File paths may generally be\nrelative or absolute.','support multiple types of items',0,'',''),(6896,'GitPython','Absolute paths must start with working tree directory of this index’s repository\nto be considered valid. For example, if it was initialized with a non-normalized path, like\n/root/repo/../repo, absolute paths to be added must start with /root/repo/../repo.','initialize  with non-normalized path',0,'',''),(6897,'GitPython','Paths provided like this must exist. When added, they will be written\ninto the object database.','write  into object database',0,'',''),(6898,'GitPython','PathStrings may contain globs, such as ‘lib/__init__*’ or can be directories\nlike ‘lib’, the latter ones will add all the files within the directory and\nsubdirectories.','add files within directory',0,'',''),(6899,'GitPython','PathStrings may contain globs, such as ‘lib/__init__*’ or can be directories\nlike ‘lib’, the latter ones will add all the files within the directory and\nsubdirectories.','add files within subdirectories',0,'',''),(6900,'GitPython','If their sha is null ( 40*0 ), their path must exist in the file system\nrelative to the git repository as an object will be created from\nthe data at the path.\nThe handling now very much equals the way string paths are processed, except that\nthe mode you have set will be kept. This allows you to create symlinks\nby settings the mode respectively and writing the target of the symlink\ndirectly into the file. This equals a default Linux-Symlink which\nis not dereferenced automatically, except that it can be created on\nfilesystems not supporting it as well.','create object from data',0,'',''),(6901,'GitPython','If their sha is null ( 40*0 ), their path must exist in the file system\nrelative to the git repository as an object will be created from\nthe data at the path.\nThe handling now very much equals the way string paths are processed, except that\nthe mode you have set will be kept. This allows you to create symlinks\nby settings the mode respectively and writing the target of the symlink\ndirectly into the file. This equals a default Linux-Symlink which\nis not dereferenced automatically, except that it can be created on\nfilesystems not supporting it as well.','set mode',0,'',''),(6902,'GitPython','If their sha is null ( 40*0 ), their path must exist in the file system\nrelative to the git repository as an object will be created from\nthe data at the path.\nThe handling now very much equals the way string paths are processed, except that\nthe mode you have set will be kept. This allows you to create symlinks\nby settings the mode respectively and writing the target of the symlink\ndirectly into the file. This equals a default Linux-Symlink which\nis not dereferenced automatically, except that it can be created on\nfilesystems not supporting it as well.','create symlinks by settings',0,'',''),(6903,'GitPython','If their sha is null ( 40*0 ), their path must exist in the file system\nrelative to the git repository as an object will be created from\nthe data at the path.\nThe handling now very much equals the way string paths are processed, except that\nthe mode you have set will be kept. This allows you to create symlinks\nby settings the mode respectively and writing the target of the symlink\ndirectly into the file. This equals a default Linux-Symlink which\nis not dereferenced automatically, except that it can be created on\nfilesystems not supporting it as well.','create symlinks by writing',0,'',''),(6904,'GitPython','If their sha is null ( 40*0 ), their path must exist in the file system\nrelative to the git repository as an object will be created from\nthe data at the path.\nThe handling now very much equals the way string paths are processed, except that\nthe mode you have set will be kept. This allows you to create symlinks\nby settings the mode respectively and writing the target of the symlink\ndirectly into the file. This equals a default Linux-Symlink which\nis not dereferenced automatically, except that it can be created on\nfilesystems not supporting it as well.','write target into file',0,'',''),(6905,'GitPython','If their sha is null ( 40*0 ), their path must exist in the file system\nrelative to the git repository as an object will be created from\nthe data at the path.\nThe handling now very much equals the way string paths are processed, except that\nthe mode you have set will be kept. This allows you to create symlinks\nby settings the mode respectively and writing the target of the symlink\ndirectly into the file. This equals a default Linux-Symlink which\nis not dereferenced automatically, except that it can be created on\nfilesystems not supporting it as well.','write target of symlink',0,'',''),(6906,'GitPython','If their sha is null ( 40*0 ), their path must exist in the file system\nrelative to the git repository as an object will be created from\nthe data at the path.\nThe handling now very much equals the way string paths are processed, except that\nthe mode you have set will be kept. This allows you to create symlinks\nby settings the mode respectively and writing the target of the symlink\ndirectly into the file. This equals a default Linux-Symlink which\nis not dereferenced automatically, except that it can be created on\nfilesystems not supporting it as well.','create  on filesystems',0,'',''),(6907,'GitPython','Checkout the given paths or all files from the version known to the index into\nthe working tree.','checkout given paths from version',0,'',''),(6908,'GitPython','Checkout the given paths or all files from the version known to the index into\nthe working tree.','checkout files from version',0,'',''),(6909,'GitPython','Commit the current default index file, creating a commit object.\nFor more information on the arguments, see Commit.create_from_tree().','create commit object',0,'',''),(6910,'GitPython','Merge the given treeish revisions into a new index which is returned.\nThe original index will remain unaltered','return new index',0,'',''),(6911,'GitPython','As opposed to the IndexFile.from_tree() method, this allows you to use an already\nexisting tree as the left side of the merge','use existing tree as left side',0,'',''),(6912,'GitPython','Merge the given treeish revisions into a new index which is returned.\nThis method behaves like git-read-tree –aggressive when doing the merge.','return new index',0,'',''),(6913,'GitPython','Remove the given items from the index and optionally from\nthe working tree as well.','remove given items from index',0,'',''),(6914,'GitPython','Remove the given items from the index and optionally from\nthe working tree as well.','remove given items from working tree',0,'',''),(6915,'GitPython','Multiple types of items are supported which may be be freely mixed.','support multiple types of items',0,'',''),(6916,'GitPython','Resolve the blobs given in blob iterator. This will effectively remove the\nindex entries of the respective path at all non-null stages and add the given\nblob as new stage null blob.','resolve blobs',0,'',''),(6917,'GitPython','Resolve the blobs given in blob iterator. This will effectively remove the\nindex entries of the respective path at all non-null stages and add the given\nblob as new stage null blob.','remove index entries at non-null stages',0,'',''),(6918,'GitPython','Resolve the blobs given in blob iterator. This will effectively remove the\nindex entries of the respective path at all non-null stages and add the given\nblob as new stage null blob.','remove index entries of respective path',0,'',''),(6919,'GitPython','Resolve the blobs given in blob iterator. This will effectively remove the\nindex entries of the respective path at all non-null stages and add the given\nblob as new stage null blob.','add given blob as new stage null blob',0,'',''),(6920,'GitPython','For each path there may only be one blob, otherwise a ValueError will be raised\nclaiming the path is already at stage 0.','raise ValueError',0,'',''),(6921,'GitPython','Write the current state to our file path or to the given one','write current state to file path',0,'',''),(6922,'GitPython','Writes this index to a corresponding Tree object into the repository’s\nobject database and return it.','write index into object database',0,'',''),(6923,'GitPython','Writes this index to a corresponding Tree object into the repository’s\nobject database and return it.','write index to corresponding Tree object',0,'',''),(6924,'GitPython','The .valid_files attribute contains a list of relative paths to files that\nwere checked out successfully and hence match the version stored in the\nindex','match version',0,'',''),(6925,'GitPython','The .valid_files attribute contains a list of relative paths to files that\nwere checked out successfully and hence match the version stored in the\nindex','match files',0,'',''),(6926,'GitPython','The .valid_files attribute contains a list of relative paths to files that\nwere checked out successfully and hence match the version stored in the\nindex','store  in index',0,'',''),(6927,'GitPython','Read a cache file from the given stream\n:return: tuple(version, entries_dict, extension_data, content_sha)\n* version is the integer version number\n* entries dict is a dictionary which maps IndexEntry instances to a path at a stage\n* extension_data is ‘’ or 4 bytes of type + 4 bytes of size + size bytes\n* content_sha is a 20 byte sha on all cache file contents','read cache file from given stream',0,'',''),(6928,'GitPython','Create a tree from the given sorted list of entries and put the respective\ntrees into the given object database','create tree from given sorted list',0,'',''),(6929,'GitPython','Convert the given mode from a stat call to the corresponding index mode\nand return it','convert given mode from stat call',0,'',''),(6930,'GitPython','Convert the given mode from a stat call to the corresponding index mode\nand return it','convert given mode to corresponding index mode',0,'',''),(6931,'GitPython','Run the commit hook of the given name. Silently ignores hooks that do not exist.\n:param name: name of hook, like ‘pre-commit’\n:param index: IndexFile instance\n:param args: arguments passed to hook file\n:raises HookExecutionError:','raise hookexecutionerror',0,'',''),(6932,'GitPython','Run the commit hook of the given name. Silently ignores hooks that do not exist.\n:param name: name of hook, like ‘pre-commit’\n:param index: IndexFile instance\n:param args: arguments passed to hook file\n:raises HookExecutionError:','pass  to hook file',0,'',''),(6933,'GitPython','Module with additional types used by the index','use  by index',0,'',''),(6934,'GitPython','Predicate to be used by iter_blobs allowing to filter only return blobs which\nmatch the given list of directories or files.','match given list of directories',0,'',''),(6935,'GitPython','Predicate to be used by iter_blobs allowing to filter only return blobs which\nmatch the given list of directories or files.','match given list of files',0,'',''),(6936,'GitPython','Predicate to be used by iter_blobs allowing to filter only return blobs which\nmatch the given list of directories or files.','match only return blobs of directories',0,'',''),(6937,'GitPython','Predicate to be used by iter_blobs allowing to filter only return blobs which\nmatch the given list of directories or files.','match only return blobs of files',0,'',''),(6938,'GitPython','Small Brother of an index entry which can be created to describe changes\ndone to the index in which case plenty of additional information is not required.','describe changes',0,'',''),(6939,'GitPython','Small Brother of an index entry which can be created to describe changes\ndone to the index in which case plenty of additional information is not required.','create index entry',0,'',''),(6940,'GitPython','As the first 4 data members match exactly to the IndexEntry type, methods\nexpecting a BaseIndexEntry can also handle full IndexEntries even if they\nuse numeric indices for performance reasons.','handle full IndexEntries',0,'',''),(6941,'GitPython','As the first 4 data members match exactly to the IndexEntry type, methods\nexpecting a BaseIndexEntry can also handle full IndexEntries even if they\nuse numeric indices for performance reasons.','use numeric indices for performance reasons',0,'',''),(6942,'GitPython','As the first 4 data members match exactly to the IndexEntry type, methods\nexpecting a BaseIndexEntry can also handle full IndexEntries even if they\nuse numeric indices for performance reasons.','match  to IndexEntry type',0,'',''),(6943,'GitPython','Override __new__ to allow construction from a tuple for backwards compatibility','override __new__',0,'',''),(6944,'GitPython','Attributes usully accessed often are cached in the tuple whereas others are\nunpacked on demand.','cache attributes accessed in tuple',0,'',''),(6945,'GitPython','See ctime property, but returns modification time','return modification time',0,'',''),(6946,'GitPython','Utility class moving a file to a temporary location within the same directory\nand moving it back on to where on object deletion.','move file to temporary location',0,'',''),(6947,'GitPython','Decorator for functions that alter the index using the git command. This would\ninvalidate our possibly existing entries dictionary which is why it must be\ndeleted to allow it to be lazily reread later.','use git command',0,'',''),(6948,'GitPython','Decorator which changes the current working dir to the one of the git\nrepository in order to assure relative paths are handled correctly','change current working dir',0,'',''),(6949,'GitPython','Decorator which changes the current working dir to the one of the git\nrepository in order to assure relative paths are handled correctly','change Decorator',0,'',''),(6950,'GitPython','Decorator which changes the current working dir to the one of the git\nrepository in order to assure relative paths are handled correctly','handle Decorator',0,'',''),(6951,'GitPython','The Git class manages communication with the Git binary.','manage communication with git binary',0,'',''),(6952,'GitPython','It provides a convenient interface to calling the Git binary, such as in:','provide convenient interface to calling',1,'https://gitpython.readthedocs.io/en/stable/reference.html',''),(6953,'GitPython','It provides a convenient interface to calling the Git binary, such as in:','call git binary',1,'https://gitpython.readthedocs.io/en/stable/reference.html',''),(6954,'GitPython','Kill/Interrupt the stored process instance once this instance goes out of scope. It is\nused to prevent processes piling up in case iterators stop reading.\nBesides all attributes are wired through to the contained process object.','prevent processes',0,'',''),(6955,'GitPython','The wait method was overridden to perform automatic status code checking\nand possibly raise.','perform automatic status code checking',0,'',''),(6956,'GitPython','The wait method was overridden to perform automatic status code checking\nand possibly raise.','raise automatic status code checking',0,'',''),(6957,'GitPython','The wait method was overridden to perform automatic status code checking\nand possibly raise.','override wait method',0,'',''),(6958,'GitPython','Wait for the process and return its status code.','return status code',0,'',''),(6959,'GitPython','Object representing a sized read-only stream returning the contents of\nan object.\nIt behaves like a stream, but counts the data read and simulates an empty\nstream once our sized content region is empty.\nIf not all data is read to the end of the objects’s lifetime, we read the\nrest to assure the underlying stream continues to work','return contents of object',0,'',''),(6960,'GitPython','Object representing a sized read-only stream returning the contents of\nan object.\nIt behaves like a stream, but counts the data read and simulates an empty\nstream once our sized content region is empty.\nIf not all data is read to the end of the objects’s lifetime, we read the\nrest to assure the underlying stream continues to work','simulate empty stream',0,'',''),(6961,'GitPython','Object representing a sized read-only stream returning the contents of\nan object.\nIt behaves like a stream, but counts the data read and simulates an empty\nstream once our sized content region is empty.\nIf not all data is read to the end of the objects’s lifetime, we read the\nrest to assure the underlying stream continues to work','read data to end',0,'',''),(6962,'GitPython','A convenience method as it allows to call the command as if it was\nan object.\n:return: Callable object that will execute call _call_process with your arguments.','call command',0,'',''),(6963,'GitPython','A convenience method as it allows to call the command as if it was\nan object.\n:return: Callable object that will execute call _call_process with your arguments.','execute call _ call_process with arguments',0,'',''),(6964,'GitPython','Initialize this instance with:','initialize instance',0,'',''),(6965,'GitPython','Clear all kinds of internal caches to release resources.','release resources',0,'',''),(6966,'GitPython','Note git is executed with LC_MESSAGES=”C” to ensure consistent\noutput regardless of system language.','execute git with LC_MESSAGES = c',0,'',''),(6967,'GitPython','As get_object_header, but returns object data as well\n:return: (hexsha, type_string, size_as_int,data_string)\n:note: not threadsafe','return note',0,'',''),(6968,'GitPython','Use this method to quickly examine the type and size of the object behind\nthe given ref.','use method',0,'',''),(6969,'GitPython','As get_object_header, but returns the data as a stream','return data as get_object_header',0,'',''),(6970,'GitPython','As get_object_header, but returns the data as a stream','return data as stream',0,'',''),(6971,'GitPython','Module containing module parser implementation able to properly read and write\nconfiguration files','read configuration files',0,'',''),(6972,'GitPython','Module containing module parser implementation able to properly read and write\nconfiguration files','write configuration files',0,'',''),(6973,'GitPython','Constrains a ConfigParser to only option commands which are constrained to\nalways use the section we have been initialized with.','use section',0,'',''),(6974,'GitPython','Constrains a ConfigParser to only option commands which are constrained to\nalways use the section we have been initialized with.','initialize section',0,'',''),(6975,'GitPython','It supports all ConfigParser methods that operate on an option.','support ConfigParser methods',0,'',''),(6976,'GitPython','Equivalent to GitConfigParser.release(), which is called on our underlying parser instance','call GitConfigParser.release() on underlying parser instance',0,'',''),(6977,'GitPython','Creates diffs between two items being trees, trees and index or an\nindex and the working tree. It will detect renames automatically.','create diffs between items',0,'',''),(6978,'GitPython','Implements an Index for diffs, allowing a list of Diffs to be queried by\nthe diff properties.','implement Index for diffs',0,'',''),(6979,'GitPython','It contains two sides a and b of the diff, members are prefixed with\n“a” and “b” respectively to inidcate that.','prefix members',1,'https://gitpython.readthedocs.io/en/stable/reference.html',''),(6980,'GitPython','Module containing all exceptions thrown throughout the git package,','throw  throughout git package',0,'',''),(6981,'GitPython','Base for all errors related to the git index, which is called cache internally','call cache',0,'',''),(6982,'GitPython','Base for all errors related to the git index, which is called cache internally','call git index',0,'',''),(6983,'GitPython','Base class for exceptions thrown at every stage of Popen() execution.','throw  at stage',0,'',''),(6984,'GitPython','Thrown if a hook exits with a non-zero exit code. It provides access to the exit code and the string returned\nvia standard output','provide access to exit code',0,'',''),(6985,'GitPython','Thrown if a hook exits with a non-zero exit code. It provides access to the exit code and the string returned\nvia standard output','provide access to string',0,'',''),(6986,'GitPython','Thrown if a hook exits with a non-zero exit code. It provides access to the exit code and the string returned\nvia standard output','return  via standard output',0,'',''),(6987,'GitPython','Thrown to indicate we can’t handle work tree repositories','handle work tree repositories',0,'',''),(6988,'GitPython','Represents a special case of a reference such that this reference is symbolic.\nIt does not point to a specific commit, but to another Head, which itself\nspecifies a commit.','specify commit',0,'',''),(6989,'GitPython','Create a new symbolic reference, hence a reference pointing , to another reference.','create new symbolic reference',0,'',''),(6990,'GitPython','Delete the reference at the given path','delete reference at given path',0,'',''),(6991,'GitPython','Find all refs in the repository','find refs in repository',0,'',''),(6992,'GitPython','List is lexicographically sorted\nThe returned objects represent actual subclasses, such as Head or TagReference','sort list',0,'',''),(6993,'GitPython','Append a logentry to the logfile of this ref','append logentry to logfile',0,'',''),(6994,'GitPython','Returns the Reference we point to','return Reference',0,'',''),(6995,'GitPython','Rename self to a new path','rename self to new path',0,'',''),(6996,'GitPython','Set the object we point to, possibly dereference our symbolic reference first.\nIf the reference does not exist, it will be created','set object',0,'',''),(6997,'GitPython','Set ourselves to the given ref. It will stay a symbol if the ref is a Reference.\nOtherwise an Object, given as Object instance or refspec, is assumed and if valid,\nwill be set which effectively detaches the reference if it was a purely\nsymbolic one.','set  to given ref',0,'',''),(6998,'GitPython','If set to a string, the message will be used in the reflog.\nOtherwise, a reflog entry is not written for the changed reference.\nThe previous commit of the entry will be the commit we point to now.','set  to string',0,'',''),(6999,'GitPython','If set to a string, the message will be used in the reflog.\nOtherwise, a reflog entry is not written for the changed reference.\nThe previous commit of the entry will be the commit we point to now.','use message in reflog',0,'',''),(7000,'GitPython','Represents a named reference to any object. Subclasses may apply restrictions though,\ni.e. Heads can only point to commits.','apply restrictions',0,'',''),(7001,'GitPython','Equivalent to SymbolicReference.iter_items, but will return non-detached\nreferences as well.','return non-detached references',0,'',''),(7002,'GitPython','Special version which checks if the head-log needs an update as well\n:return: self','check special version',0,'',''),(7003,'GitPython','Reset our HEAD to the given commit optionally synchronizing\nthe index and working tree. The reference we refer to will be set to\ncommit as well.','set reference',0,'',''),(7004,'GitPython','Checkout this head by setting the HEAD to this reference, by updating the index\nto reflect the tree we point to and by updating the working tree to reflect\nthe latest index.','checkout head by setting',0,'',''),(7005,'GitPython','Checkout this head by setting the HEAD to this reference, by updating the index\nto reflect the tree we point to and by updating the working tree to reflect\nthe latest index.','set HEAD by updating',0,'',''),(7006,'GitPython','Checkout this head by setting the HEAD to this reference, by updating the index\nto reflect the tree we point to and by updating the working tree to reflect\nthe latest index.','set HEAD by updating',0,'',''),(7007,'GitPython','Checkout this head by setting the HEAD to this reference, by updating the index\nto reflect the tree we point to and by updating the working tree to reflect\nthe latest index.','set HEAD to reference',0,'',''),(7008,'GitPython','Checkout this head by setting the HEAD to this reference, by updating the index\nto reflect the tree we point to and by updating the working tree to reflect\nthe latest index.','update index',0,'',''),(7009,'GitPython','Checkout this head by setting the HEAD to this reference, by updating the index\nto reflect the tree we point to and by updating the working tree to reflect\nthe latest index.','update working tree',0,'',''),(7010,'GitPython','Delete the given heads','delete given heads',0,'',''),(7011,'GitPython','Create a new tag reference.','create new tag reference',0,'',''),(7012,'GitPython','If not None, the message will be used in your tag object. This will also\ncreate an additional tag object that allows to obtain that information, i.e.:','use message in tag object',1,'https://gitpython.readthedocs.io/en/stable/reference.html',''),(7013,'GitPython','If not None, the message will be used in your tag object. This will also\ncreate an additional tag object that allows to obtain that information, i.e.:','create additional tag object',1,'https://gitpython.readthedocs.io/en/stable/reference.html',''),(7014,'GitPython','If not None, the message will be used in your tag object. This will also\ncreate an additional tag object that allows to obtain that information, i.e.:','obtain information',1,'https://gitpython.readthedocs.io/en/stable/reference.html',''),(7015,'GitPython','Delete the given existing tag or tags','delete given existing tag',0,'',''),(7016,'GitPython','Delete the given existing tag or tags','delete tags',0,'',''),(7017,'GitPython','Used to disable this method','disable method',0,'',''),(7018,'GitPython','Delete the given remote references','delete given remote references',0,'',''),(7019,'GitPython','A reflog contains RefLogEntrys, each of which defines a certain state\nof the head in question. Custom query methods allow to retrieve log entries\nby date or by other criteria.','define certain state of head',0,'',''),(7020,'GitPython','A reflog contains RefLogEntrys, each of which defines a certain state\nof the head in question. Custom query methods allow to retrieve log entries\nby date or by other criteria.','define RefLogEntrys of head',0,'',''),(7021,'GitPython','A reflog contains RefLogEntrys, each of which defines a certain state\nof the head in question. Custom query methods allow to retrieve log entries\nby date or by other criteria.','retrieve log entries by date',0,'',''),(7022,'GitPython','A reflog contains RefLogEntrys, each of which defines a certain state\nof the head in question. Custom query methods allow to retrieve log entries\nby date or by other criteria.','retrieve log entries by other criteria',0,'',''),(7023,'GitPython','Reflog entries are ordered, the first added entry is first in the list, the last\nentry, i.e. the last change of the head or reference, is last in the list.','order entries',0,'',''),(7024,'GitPython','Initialize this instance with an optional filepath, from which we will\ninitialize our data. The path is also used to write changes back using\nthe write() method','initialize instance with optional filepath',0,'',''),(7025,'GitPython','Initialize this instance with an optional filepath, from which we will\ninitialize our data. The path is also used to write changes back using\nthe write() method','initialize data',0,'',''),(7026,'GitPython','Initialize this instance with an optional filepath, from which we will\ninitialize our data. The path is also used to write changes back using\nthe write() method','initialize optional filepath',0,'',''),(7027,'GitPython','Initialize this instance with an optional filepath, from which we will\ninitialize our data. The path is also used to write changes back using\nthe write() method','write changes',0,'',''),(7028,'GitPython','Initialize this instance with an optional filepath, from which we will\ninitialize our data. The path is also used to write changes back using\nthe write() method','use write() method',0,'',''),(7029,'GitPython','Initialize this instance with an optional filepath, from which we will\ninitialize our data. The path is also used to write changes back using\nthe write() method','use path',0,'',''),(7030,'GitPython','Create and return a new object.  See help(type) for accurate signature.','create new object',0,'',''),(7031,'GitPython','Create and return a new object.  See help(type) for accurate signature.','return new object',0,'',''),(7032,'GitPython','Append a new log entry to the revlog at filepath.','append new log entry at filepath',0,'',''),(7033,'GitPython','Append a new log entry to the revlog at filepath.','append new log entry to revlog',0,'',''),(7034,'GitPython','Write the contents of the reflog instance to a file at the given filepath.\n:param filepath: path to file, parent directories are assumed to exist','write contents of reflog instance',0,'',''),(7035,'GitPython','Actor instance, providing access','provide access',0,'',''),(7036,'GitPython','Message describing the operation that acted on the reference','describe operation',0,'',''),(7037,'GitPython','Handler providing an interface to parse progress information emitted by git-push\nand git-fetch and to dispatch callbacks allowing subclasses to react to the progress.','provide interface',0,'',''),(7038,'GitPython','Integer allowing to be compared against Operation IDs and stage IDs.','compare  against Operation ids',0,'',''),(7039,'GitPython','Integer allowing to be compared against Operation IDs and stage IDs.','compare  against stage ids',0,'',''),(7040,'GitPython','Stage IDs are BEGIN and END. BEGIN will only be set once for each Operation\nID as well as END. It may be that BEGIN and END are set at once in case only\none progress message was emitted due to the speed of the operation.\nBetween BEGIN and END, none of these flags will be set','set BEGIN for Operation ID',0,'',''),(7041,'GitPython','Stage IDs are BEGIN and END. BEGIN will only be set once for each Operation\nID as well as END. It may be that BEGIN and END are set at once in case only\none progress message was emitted due to the speed of the operation.\nBetween BEGIN and END, none of these flags will be set','set BEGIN for END',0,'',''),(7042,'GitPython','Stage IDs are BEGIN and END. BEGIN will only be set once for each Operation\nID as well as END. It may be that BEGIN and END are set at once in case only\none progress message was emitted due to the speed of the operation.\nBetween BEGIN and END, none of these flags will be set','set BEGIN in case',0,'',''),(7043,'GitPython','Stage IDs are BEGIN and END. BEGIN will only be set once for each Operation\nID as well as END. It may be that BEGIN and END are set at once in case only\none progress message was emitted due to the speed of the operation.\nBetween BEGIN and END, none of these flags will be set','set END in case',0,'',''),(7044,'GitPython','Stage IDs are BEGIN and END. BEGIN will only be set once for each Operation\nID as well as END. It may be that BEGIN and END are set at once in case only\none progress message was emitted due to the speed of the operation.\nBetween BEGIN and END, none of these flags will be set','set none of flags',0,'',''),(7045,'GitPython','Stage IDs are BEGIN and END. BEGIN will only be set once for each Operation\nID as well as END. It may be that BEGIN and END are set at once in case only\none progress message was emitted due to the speed of the operation.\nBetween BEGIN and END, none of these flags will be set','set none between BEGIN',0,'',''),(7046,'GitPython','Stage IDs are BEGIN and END. BEGIN will only be set once for each Operation\nID as well as END. It may be that BEGIN and END are set at once in case only\none progress message was emitted due to the speed of the operation.\nBetween BEGIN and END, none of these flags will be set','set none between END',0,'',''),(7047,'GitPython','You may read the contents of the current line in self._cur_line','read contents of current line',0,'',''),(7048,'GitPython','Initialize a new instance','initialize new instance',0,'',''),(7049,'GitPython','Provides easy read and write access to a git remote.','read access to git remote',0,'',''),(7050,'GitPython','Provides easy read and write access to a git remote.','write access to git remote',0,'',''),(7051,'GitPython','NOTE: When querying configuration, the configuration accessor will be cached\nto speed up subsequent accesses.','cache configuration accessor',0,'',''),(7052,'GitPython','Allows to call this instance like\nremote.special( *args, **kwargs) to call git-remote special self.name','call instance like remote.special( *args, **kwargs)',0,'',''),(7053,'GitPython','Allows to call this instance like\nremote.special( *args, **kwargs) to call git-remote special self.name','call git-remote special self.name',0,'',''),(7054,'GitPython','Initialize a remote instance','initialize remote instance',0,'',''),(7055,'GitPython','Adds a new url on current remote (special case of git remote set_url)','add new url on current remote',0,'',''),(7056,'GitPython','This command adds new URLs to a given remote, making it possible to have\nmultiple URLs for a single remote.','add new urls to given remote',0,'',''),(7057,'GitPython','Create a new remote to the given repository\n:param repo: Repository instance that is to receive the new remote\n:param name: Desired name of the remote\n:param url: URL which corresponds to the remote’s name\n:param kwargs: Additional arguments to be passed to the git-remote add command\n:return: New Remote instance\n:raise GitCommandError: in case an origin with that name already exists','create  to given repository',0,'',''),(7058,'GitPython','Create a new remote to the given repository\n:param repo: Repository instance that is to receive the new remote\n:param name: Desired name of the remote\n:param url: URL which corresponds to the remote’s name\n:param kwargs: Additional arguments to be passed to the git-remote add command\n:return: New Remote instance\n:raise GitCommandError: in case an origin with that name already exists','pass additional arguments to git-remote add command',0,'',''),(7059,'GitPython','Deletes a new url on current remote (special case of git remote set_url)','delete new url on current remote',0,'',''),(7060,'GitPython','This command deletes new URLs to a given remote, making it possible to have\nmultiple URLs for a single remote.','delete new urls to given remote',0,'',''),(7061,'GitPython','Fetch the latest changes for this remote','fetch latest changes',0,'',''),(7062,'GitPython','A “refspec” is used by fetch and push to describe the mapping\nbetween remote ref and local ref. They are combined with a colon in\nthe format :, preceded by an optional plus sign, +.\nFor example: git fetch $URL refs/heads/master:refs/heads/origin means\n“grab the master branch head from the $URL and store it as my origin\nbranch head”. And git push $URL refs/heads/master:refs/heads/to-upstream\nmeans “publish my master branch head as to-upstream branch at $URL”.\nSee also git-push(1).','describe mapping between local ref',0,'',''),(7063,'GitPython','A “refspec” is used by fetch and push to describe the mapping\nbetween remote ref and local ref. They are combined with a colon in\nthe format :, preceded by an optional plus sign, +.\nFor example: git fetch $URL refs/heads/master:refs/heads/origin means\n“grab the master branch head from the $URL and store it as my origin\nbranch head”. And git push $URL refs/heads/master:refs/heads/to-upstream\nmeans “publish my master branch head as to-upstream branch at $URL”.\nSee also git-push(1).','describe mapping between remote ref',0,'',''),(7064,'GitPython','A “refspec” is used by fetch and push to describe the mapping\nbetween remote ref and local ref. They are combined with a colon in\nthe format :, preceded by an optional plus sign, +.\nFor example: git fetch $URL refs/heads/master:refs/heads/origin means\n“grab the master branch head from the $URL and store it as my origin\nbranch head”. And git push $URL refs/heads/master:refs/heads/to-upstream\nmeans “publish my master branch head as to-upstream branch at $URL”.\nSee also git-push(1).','use refspec',0,'',''),(7065,'GitPython','A “refspec” is used by fetch and push to describe the mapping\nbetween remote ref and local ref. They are combined with a colon in\nthe format :, preceded by an optional plus sign, +.\nFor example: git fetch $URL refs/heads/master:refs/heads/origin means\n“grab the master branch head from the $URL and store it as my origin\nbranch head”. And git push $URL refs/heads/master:refs/heads/to-upstream\nmeans “publish my master branch head as to-upstream branch at $URL”.\nSee also git-push(1).','combine  with colon',0,'',''),(7066,'GitPython','A “refspec” is used by fetch and push to describe the mapping\nbetween remote ref and local ref. They are combined with a colon in\nthe format :, preceded by an optional plus sign, +.\nFor example: git fetch $URL refs/heads/master:refs/heads/origin means\n“grab the master branch head from the $URL and store it as my origin\nbranch head”. And git push $URL refs/heads/master:refs/heads/to-upstream\nmeans “publish my master branch head as to-upstream branch at $URL”.\nSee also git-push(1).','store  as origin branch head',0,'',''),(7067,'GitPython','Fetch supports multiple refspecs (as the\nunderlying git-fetch does) - supplying a list rather than a string\nfor ‘refspec’ will make use of this facility.','support multiple refspecs',0,'',''),(7068,'GitPython','Push changes from source branch in refspec to target branch in refspec.','change  from source branch',0,'',''),(7069,'GitPython','Remove the remote with the given name\n:return: the passed remote name to remove','remove  with given name',0,'',''),(7070,'GitPython','This command manages URLs on the remote.','manage urls',0,'',''),(7071,'GitPython','The IterableList is prefixed, hence the ‘origin’ must be omitted. See\n‘refs’ property for an example.','prefix IterableList',0,'',''),(7072,'GitPython','The IterableList is prefixed, hence the ‘origin’ must be omitted. See\n‘refs’ property for an example.','omit âoriginâ',0,'',''),(7073,'GitPython','To make things more complicated, it can be possible for the list to include\nother kinds of references, for example, tag references, if these are stale\nas well. This is a fix for the issue described here:\nhttps://github.com/gitpython-developers/GitPython/issues/260','include other kinds of references',0,'',''),(7074,'GitPython','To make things more complicated, it can be possible for the list to include\nother kinds of references, for example, tag references, if these are stale\nas well. This is a fix for the issue described here:\nhttps://github.com/gitpython-developers/GitPython/issues/260','describe https://github.com/gitpython-developers/GitPython/issues/260',0,'',''),(7075,'GitPython','Fetch all changes for this remote, including new branches which will\nbe forced in ( in case your local remote branch is not part the new remote branches\nancestry anymore ).','fetch changes including new branches',0,'',''),(7076,'GitPython','Fetch all changes for this remote, including new branches which will\nbe forced in ( in case your local remote branch is not part the new remote branches\nancestry anymore ).','force new branches',0,'',''),(7077,'GitPython','Represents a git repository and allows you to query references,\ngather commit information, generate diffs, create and clone repositories query\nthe log.','generate diffs',0,'',''),(7078,'GitPython','‘working_tree_dir’ is the working tree directory, but will raise AssertionError\nif we are a bare repository.','raise AssertionError',0,'',''),(7079,'GitPython','‘git_dir’ is the .git repository directory, which is always set.','set repository directory',0,'',''),(7080,'GitPython','Create a new Repo instance','create new Repo instance',0,'',''),(7081,'GitPython','if True, all parent directories will be searched for a valid repo as well.','search parent directories for valid repo',0,'',''),(7082,'GitPython','Retrieve a list of alternates paths or set a list paths to be used as alternates','retrieve list of alternates paths',0,'',''),(7083,'GitPython','Retrieve a list of alternates paths or set a list paths to be used as alternates','set list of alternates paths',0,'',''),(7084,'GitPython','Retrieve a list of alternates paths or set a list paths to be used as alternates','use list paths as alternates',0,'',''),(7085,'GitPython','Archive the tree at the given revision.','archive tree at given revision',0,'',''),(7086,'GitPython','If you combine all line number ranges outputted by this command, you\nshould get a continuous range spanning all line numbers in the file.','get continuous range',0,'',''),(7087,'GitPython','Create a clone from this repository.','create clone from repository',0,'',''),(7088,'GitPython','Create a clone from the given URL','create clone from given URL',0,'',''),(7089,'GitPython','The configuration will include values from the system, user and repository\nconfiguration files.','include values from system user repository configuration files',0,'',''),(7090,'GitPython','Create a new head within the repository.\nFor more documentation, please see the Head.create method.','create new head within repository',0,'',''),(7091,'GitPython','Create a new submodule','create new submodule',0,'',''),(7092,'GitPython','Create a new tag reference.\nFor more documentation, please see the TagReference.create method.','create new tag reference',0,'',''),(7093,'GitPython','Delete the given remote.','delete given remote',0,'',''),(7094,'GitPython','Delete the given tag references','delete given tag references',0,'',''),(7095,'GitPython','Checks if paths are ignored via .gitignore\nDoing so using the “git check-ignore” method.','ignore paths',0,'',''),(7096,'GitPython','Checks if paths are ignored via .gitignore\nDoing so using the “git check-ignore” method.','use git check-ignore method',0,'',''),(7097,'GitPython','Initialize a git repository at the given path if specified','initialize git repository at given path',0,'',''),(7098,'GitPython','Find the closest common ancestor for the given revision (e.g. Commits, Tags, References, etc)','find closest common ancestor for given revision',0,'',''),(7099,'GitPython','A list of Remote objects allowing to access and manipulate remotes\n:return: git.IterableList(Remote, ...)','access remotes',0,'',''),(7100,'GitPython','A list of Remote objects allowing to access and manipulate remotes\n:return: git.IterableList(Remote, ...)','manipulate remotes',0,'',''),(7101,'GitPython','Search for a submodule repo.','search  for submodule repo',0,'',''),(7102,'GitPython','Recursively dereference a tag and return the resulting object','return resulting object',0,'',''),(7103,'GitPython','Convert the given object to a commit if possible and return it','convert given object to commit possible',0,'',''),(7104,'GitPython','Search for a gitdir for this worktree.','search  for gitdir',0,'',''),(7105,'GitPython','Join path tokens together similar to osp.join, but always use\n‘/’ instead of possibly ‘’ on windows.','use â/â instead_of ââ',0,'',''),(7106,'GitPython','Represents stat information as presented by git at the end of a merge. It is\ncreated from the output of a diff operation.','present  at end',1,'https://gitpython.readthedocs.io/en/stable/reference.html',''),(7107,'GitPython','Represents stat information as presented by git at the end of a merge. It is\ncreated from the output of a diff operation.','present  by git',1,'https://gitpython.readthedocs.io/en/stable/reference.html',''),(7108,'GitPython','Represents stat information as presented by git at the end of a merge. It is\ncreated from the output of a diff operation.','create  from output',1,'https://gitpython.readthedocs.io/en/stable/reference.html',''),(7109,'GitPython','Wrapper around a file-like object that remembers the SHA1 of\nthe data written to it. It will write a sha when the stream is closed\nor if the asked for explicitly using write_sha.','write sha',0,'',''),(7110,'GitPython','Wrapper around a file-like object that remembers the SHA1 of\nthe data written to it. It will write a sha when the stream is closed\nor if the asked for explicitly using write_sha.','use write_sha',0,'',''),(7111,'GitPython','Defines an interface for iterable items which is to assure a uniform\nway to retrieve and iterate items within the git repository','define interface for iterable items',0,'',''),(7112,'GitPython','Defines an interface for iterable items which is to assure a uniform\nway to retrieve and iterate items within the git repository','retrieve items within git repository',0,'',''),(7113,'GitPython','Find all items of this type - subclasses can specify args and kwargs differently.\nIf no args are given, subclasses are obliged to return all items if no additional\narguments arg given.','find items of type',0,'',''),(7114,'GitPython','Find all items of this type - subclasses can specify args and kwargs differently.\nIf no args are given, subclasses are obliged to return all items if no additional\narguments arg given.','specify args',0,'',''),(7115,'GitPython','Find all items of this type - subclasses can specify args and kwargs differently.\nIf no args are given, subclasses are obliged to return all items if no additional\narguments arg given.','specify kwargs',0,'',''),(7116,'GitPython','Find all items of this type - subclasses can specify args and kwargs differently.\nIf no args are given, subclasses are obliged to return all items if no additional\narguments arg given.','return items',0,'',''),(7117,'GitPython','Iterable parent objects = [Commit, SubModule, Reference, FetchInfo, PushInfo]\nIterable via inheritance = [Head, TagReference, RemoteReference]\n]\nIt requires an id_attribute name to be set which will be queried from its\ncontained items to have a means for comparison.','set id_attribute name',0,'',''),(7118,'GitPython','A prefix can be specified which is to be used in case the id returned by the\nitems always contains a prefix that does not matter to the user, so it\ncan be left out.','use  in case',0,'',''),(7119,'GitPython','A prefix can be specified which is to be used in case the id returned by the\nitems always contains a prefix that does not matter to the user, so it\ncan be left out.','specify prefix',0,'',''),(7120,'GitPython','The lock file will block until a lock could be obtained, or fail after\na specified timeout.','obtain lock',0,'',''),(7121,'GitPython','Configure the instance','configure instance',0,'',''),(7122,'GitPython','Provides methods to obtain, check for, and release a file based lock which\nshould be used to handle concurrent access to the same file.','release file',0,'',''),(7123,'GitPython','Provides methods to obtain, check for, and release a file based lock which\nshould be used to handle concurrent access to the same file.','handle concurrent access to same file',0,'',''),(7124,'GitPython','Provides methods to obtain, check for, and release a file based lock which\nshould be used to handle concurrent access to the same file.','use lock',0,'',''),(7125,'GitPython','As we are a utility class to be derived from, we only use protected methods.','use protected methods',0,'',''),(7126,'GitPython','Locks will automatically be released on destruction','release locks on destruction',0,'',''),(7127,'GitPython','Remove the given recursively.','remove given recursively',0,'',''),(7128,'GitPython','Methods with this decorator raise InvalidGitRepositoryError if they\nencounter a bare repository','raise InvalidGitRepositoryError',0,'',''),(7129,'GitPython','We need an easy way to see if Appveyor TCs start failing,\nso the errors marked with this var are considered “acknowledged” ones, awaiting remedy,\ntill then, we wish to hide them.','mark  with var',0,'',''),(7130,'GitPython','Properly signed re-release of v3.0.6 with new signature\n(See #980)','sign re-release with new signature',0,'',''),(7131,'GitPython','Properly signed re-release of v3.0.6 with new signature\n(See #980)','sign re-release of v3.0.6',0,'',''),(7132,'GitPython','Motivation for this is a patch which improves unicode handling when dealing with filesystem paths.\nPython 2 compatibility was introduced to deal with differences, and I thought it would be a good idea\nto ‘just’ drop support right now, mere 5 months away from the official maintenance stop of python 2.7.','introduce Python',0,'',''),(7133,'GitPython','The underlying motivation clearly is my anger when thinking python and unicode, which was a hassle from the\nstart, at least in a codebase as old as GitPython, which totally doesn’t handle encodings correctly in many cases.','handle encodings as GitPython',0,'',''),(7134,'GitPython','The underlying motivation clearly is my anger when thinking python and unicode, which was a hassle from the\nstart, at least in a codebase as old as GitPython, which totally doesn’t handle encodings correctly in many cases.','handle encodings in many cases',0,'',''),(7135,'GitPython','The underlying motivation clearly is my anger when thinking python and unicode, which was a hassle from the\nstart, at least in a codebase as old as GitPython, which totally doesn’t handle encodings correctly in many cases.','handle codebase old as GitPython',0,'',''),(7136,'GitPython','The underlying motivation clearly is my anger when thinking python and unicode, which was a hassle from the\nstart, at least in a codebase as old as GitPython, which totally doesn’t handle encodings correctly in many cases.','handle codebase old in many cases',0,'',''),(7137,'GitPython','Having migrated to using Rust exclusively for tooling, I still see that correct handling of encodings isn’t entirely\ntrivial, but at least Rust makes clear what has to be done at compile time, allowing to write software that is pretty\nmuch guaranteed to work once it compiles.','use rust for tooling',0,'',''),(7138,'GitPython','Having migrated to using Rust exclusively for tooling, I still see that correct handling of encodings isn’t entirely\ntrivial, but at least Rust makes clear what has to be done at compile time, allowing to write software that is pretty\nmuch guaranteed to work once it compiles.','write software',0,'',''),(7139,'GitPython','Again, my apologies if removing Python 2 support caused inconveniences, please see release 2.1.13 which returns it.','remove Python support',0,'',''),(7140,'GitPython','Again, my apologies if removing Python 2 support caused inconveniences, please see release 2.1.13 which returns it.','return release 2.1.13',0,'',''),(7141,'GitPython','My apologies for any inconvenience this may have caused. Following semver, backward incompatible changes\nwill be introduced in a minor version.','introduce incompatible changes in minor version',0,'',''),(7142,'GitPython','My apologies for any inconvenience this may have caused. Following semver, backward incompatible changes\nwill be introduced in a minor version.','introduce incompatible changes following semver',0,'',''),(7143,'GitPython','Special thanks to @ankostis, who made this release possible (nearly) single-handedly.\nGitPython is run by its users, and their PRs make all the difference, they keep\nGitPython relevant. Thank you all so much for contributing !','run GitPython',0,'',''),(7144,'GitPython','Please note that due to breaking changes, we have to increase the major version.','break changes',0,'',''),(7145,'GitPython','GitPython provides object model access to your git repository. This tutorial is composed of multiple sections, most of which explain a real-life use case.','provide object model access to git repository',0,'',''),(7146,'GitPython','GitPython provides object model access to your git repository. This tutorial is composed of multiple sections, most of which explain a real-life use case.','compose tutorial of multiple sections',0,'',''),(7147,'GitPython','All code presented here originated from test_docs.py to assure correctness. Knowing this should also allow you to more easily run the code for your own testing purposes. All you need is a developer installation of git-python.','run code for own testing purposes',0,'',''),(7148,'GitPython','The first step is to create a git.Repo object to represent your repository.','create git.Repo object',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7149,'GitPython','In the above example, the directory self.rorepo.working_tree_dir equals /Users/mtrier/Development/git-python and is my working repository which contains the .git directory. You can also initialize GitPython with a bare repository.','initialize GitPython with bare repository',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7150,'GitPython','A repo object provides high-level access to your data, it allows you to create and delete heads, tags and remotes and access the configuration of the repository.','provide high-level access to data',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7151,'GitPython','A repo object provides high-level access to your data, it allows you to create and delete heads, tags and remotes and access the configuration of the repository.','create heads',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7152,'GitPython','A repo object provides high-level access to your data, it allows you to create and delete heads, tags and remotes and access the configuration of the repository.','create tags',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7153,'GitPython','A repo object provides high-level access to your data, it allows you to create and delete heads, tags and remotes and access the configuration of the repository.','create remotes',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7154,'GitPython','A repo object provides high-level access to your data, it allows you to create and delete heads, tags and remotes and access the configuration of the repository.','delete heads',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7155,'GitPython','A repo object provides high-level access to your data, it allows you to create and delete heads, tags and remotes and access the configuration of the repository.','delete tags',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7156,'GitPython','A repo object provides high-level access to your data, it allows you to create and delete heads, tags and remotes and access the configuration of the repository.','delete remotes',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7157,'GitPython','A repo object provides high-level access to your data, it allows you to create and delete heads, tags and remotes and access the configuration of the repository.','access configuration of repository',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7158,'GitPython','Query the active branch, query untracked files or whether the repository data has been modified.','modify active branch',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7159,'GitPython','Query the active branch, query untracked files or whether the repository data has been modified.','modify query untracked files',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7160,'GitPython','Query the active branch, query untracked files or whether the repository data has been modified.','modify whether repository data',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7161,'GitPython','Clone from existing repositories or initialize new empty ones.','initialize new empty ones',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7162,'GitPython','Clone from existing repositories or initialize new empty ones.','clone  from existing repositories',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7163,'GitPython','You can also create new heads …','create new heads',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7164,'GitPython','Remotes allow to handle fetch, pull and push operations, while providing optional real-time progress information to progress delegates.','fetch operations',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7165,'GitPython','Remotes allow to handle fetch, pull and push operations, while providing optional real-time progress information to progress delegates.','push operations',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7166,'GitPython','Remotes allow to handle fetch, pull and push operations, while providing optional real-time progress information to progress delegates.','provide optional real-time progress information to progress delegates',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7167,'GitPython','The index is also called stage in git-speak. It is used to prepare new commits, and can be used to keep results of merge operations. Our index implementation allows to stream date into the index, which is useful for bare repositories that do not have a working tree.','call stage in git-speak',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7168,'GitPython','The index is also called stage in git-speak. It is used to prepare new commits, and can be used to keep results of merge operations. Our index implementation allows to stream date into the index, which is useful for bare repositories that do not have a working tree.','call index in git-speak',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7169,'GitPython','The index is also called stage in git-speak. It is used to prepare new commits, and can be used to keep results of merge operations. Our index implementation allows to stream date into the index, which is useful for bare repositories that do not have a working tree.','prepare new commits',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7170,'GitPython','Submodules represent all aspects of git submodules, which allows you query all of their related information, and manipulate in various ways.','manipulate  in various ways',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7171,'GitPython','Access the reflog easily.','access reflog',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7172,'GitPython','You can easily create and delete reference types or modify where they point to.','create reference types',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7173,'GitPython','You can easily create and delete reference types or modify where they point to.','delete reference types',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7174,'GitPython','You can easily create and delete reference types or modify where they point to.','modify reference types',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7175,'GitPython','Change the symbolic reference to switch branches cheaply (without adjusting the index or the working tree).','change symbolic reference',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7176,'GitPython','Change the symbolic reference to switch branches cheaply (without adjusting the index or the working tree).','switch branches',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7177,'GitPython','An Object is anything storable in git’s object database. Objects contain information about their type, their uncompressed size as well as the actual data. Each object is uniquely identified by a binary SHA1 hash, being 20 bytes in size, or 40 bytes in hexadecimal notation.','identify object',0,'',''),(7178,'GitPython','In GitPython, all objects can be accessed through their common base, can be compared and hashed. They are usually not instantiated directly, but through references or specialized repository functions.','access objects through common base',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7179,'GitPython','In GitPython, all objects can be accessed through their common base, can be compared and hashed. They are usually not instantiated directly, but through references or specialized repository functions.','access objects in GitPython',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7180,'GitPython','In GitPython, all objects can be accessed through their common base, can be compared and hashed. They are usually not instantiated directly, but through references or specialized repository functions.','compare objects',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7181,'GitPython','Commit objects contain information about a specific commit. Obtain commits using  references as done in Examining References or as follows.','use references',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7182,'GitPython','Iterate 50 commits, and if you need paging, you can specify a number of commits to skip.','specify number of commits',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7183,'GitPython','Once you have a tree, you can get its contents','get contents',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7184,'GitPython','There is a convenience method that allows you to get a named sub-object from a tree with a syntax similar to how paths are written in a posix system','get named sub-object from tree',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7185,'GitPython','There is a convenience method that allows you to get a named sub-object from a tree with a syntax similar to how paths are written in a posix system','write paths in posix system',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7186,'GitPython','You can also get a commit’s root tree directly from the repository','get root tree from repository',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7187,'GitPython','As trees allow direct access to their intermediate child entries only, use the traverse method to obtain an iterator to retrieve entries recursively','use traverse method',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7188,'GitPython','As trees allow direct access to their intermediate child entries only, use the traverse method to obtain an iterator to retrieve entries recursively','obtain iterator',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7189,'GitPython','As trees allow direct access to their intermediate child entries only, use the traverse method to obtain an iterator to retrieve entries recursively','retrieve entries',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7190,'GitPython','The git index is the stage containing changes to be written with the next commit or where merges finally have to take place. You may freely access and manipulate this information using the IndexFile object.\nModify the index with ease','write  with next commit',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7191,'GitPython','The git index is the stage containing changes to be written with the next commit or where merges finally have to take place. You may freely access and manipulate this information using the IndexFile object.\nModify the index with ease','access information',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7192,'GitPython','The git index is the stage containing changes to be written with the next commit or where merges finally have to take place. You may freely access and manipulate this information using the IndexFile object.\nModify the index with ease','manipulate information',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7193,'GitPython','The git index is the stage containing changes to be written with the next commit or where merges finally have to take place. You may freely access and manipulate this information using the IndexFile object.\nModify the index with ease','use IndexFile object',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7194,'GitPython','Create new indices from other trees or as result of a merge. Write that result to a new index file for later inspection.','create new indices as result',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7195,'GitPython','Create new indices from other trees or as result of a merge. Write that result to a new index file for later inspection.','create new indices from other trees',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7196,'GitPython','Create new indices from other trees or as result of a merge. Write that result to a new index file for later inspection.','write result to new index file',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7197,'GitPython','Remotes are used as alias for a foreign repository to ease pushing to and fetching from them','use remotes as alias',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7198,'GitPython','You can easily access configuration information for a remote by accessing options as if they were attributes. The modification of remote configuration is more explicit though.','access configuration information by accessing',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7199,'GitPython','You can easily access configuration information for a remote by accessing options as if they were attributes. The modification of remote configuration is more explicit though.','access options',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7200,'GitPython','You can also specify per-call custom environments using a new context manager on the Git command, e.g. for using a specific SSH key. The following example works with git starting at v2.3:','specify per-call custom environments',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7201,'GitPython','You can also specify per-call custom environments using a new context manager on the Git command, e.g. for using a specific SSH key. The following example works with git starting at v2.3:','use e.g. on git command',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7202,'GitPython','You can also specify per-call custom environments using a new context manager on the Git command, e.g. for using a specific SSH key. The following example works with git starting at v2.3:','use new context manager on git command',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7203,'GitPython','You can also specify per-call custom environments using a new context manager on the Git command, e.g. for using a specific SSH key. The following example works with git starting at v2.3:','use specific SSH key',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7204,'GitPython','This one sets a custom script to be executed in place of ssh, and can be used in git prior to v2.3:','execute custom script in_place_of ssh',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7205,'GitPython','This one sets a custom script to be executed in place of ssh, and can be used in git prior to v2.3:','use  in git',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7206,'GitPython','Here’s an example executable that can be used in place of the ssh_executable above:','use example executable in_place_of ssh_executable',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7207,'GitPython','Please note that the script must be executable (i.e. chmod +x script.sh). StrictHostKeyChecking=no is used to avoid prompts asking to save the hosts key to ~/.ssh/known_hosts, which happens in case you run this as daemon.','save hosts key to ~ /.ssh/known_hosts',0,'',''),(7208,'GitPython','Submodules can be conveniently handled using the methods provided by GitPython, and as an added benefit, GitPython provides functionality which behave smarter and less error prone than its original c-git implementation, that is GitPython tries hard to keep your repository consistent when updating submodules recursively or adjusting the existing configuration.','use methods',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7209,'GitPython','Submodules can be conveniently handled using the methods provided by GitPython, and as an added benefit, GitPython provides functionality which behave smarter and less error prone than its original c-git implementation, that is GitPython tries hard to keep your repository consistent when updating submodules recursively or adjusting the existing configuration.','provide  as added benefit',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7210,'GitPython','Submodules can be conveniently handled using the methods provided by GitPython, and as an added benefit, GitPython provides functionality which behave smarter and less error prone than its original c-git implementation, that is GitPython tries hard to keep your repository consistent when updating submodules recursively or adjusting the existing configuration.','update submodules',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7211,'GitPython','Submodules can be conveniently handled using the methods provided by GitPython, and as an added benefit, GitPython provides functionality which behave smarter and less error prone than its original c-git implementation, that is GitPython tries hard to keep your repository consistent when updating submodules recursively or adjusting the existing configuration.','adjust existing configuration',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7212,'GitPython','Submodules can be conveniently handled using the methods provided by GitPython, and as an added benefit, GitPython provides functionality which behave smarter and less error prone than its original c-git implementation, that is GitPython tries hard to keep your repository consistent when updating submodules recursively or adjusting the existing configuration.','handle submodules',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7213,'GitPython','In addition to the query functionality, you can move the submodule’s repository to a different path <move(...)>,\nwrite its configuration <config_writer().set_value(...).release()>, update its working tree <update(...)>,\nand remove or add them <remove(...), add(...)>.','move repository move(...) &gt;',0,'',''),(7214,'GitPython','In addition to the query functionality, you can move the submodule’s repository to a different path <move(...)>,\nwrite its configuration <config_writer().set_value(...).release()>, update its working tree <update(...)>,\nand remove or add them <remove(...), add(...)>.','add repository move(...) &gt;',0,'',''),(7215,'GitPython','In addition to the query functionality, you can move the submodule’s repository to a different path <move(...)>,\nwrite its configuration <config_writer().set_value(...).release()>, update its working tree <update(...)>,\nand remove or add them <remove(...), add(...)>.','write configuration &lt; config_writer().set_value(...).release() &gt;',0,'',''),(7216,'GitPython','In addition to the query functionality, you can move the submodule’s repository to a different path <move(...)>,\nwrite its configuration <config_writer().set_value(...).release()>, update its working tree <update(...)>,\nand remove or add them <remove(...), add(...)>.','update working tree &lt; update(...) &gt;',0,'',''),(7217,'GitPython','If you obtained your submodule object by traversing a tree object which is not rooted at the head’s commit,\nyou have to inform the submodule about its actual commit to retrieve the data from\nby using the set_parent_commit(...) method.','obtain submodule object by traversing',0,'',''),(7218,'GitPython','If you obtained your submodule object by traversing a tree object which is not rooted at the head’s commit,\nyou have to inform the submodule about its actual commit to retrieve the data from\nby using the set_parent_commit(...) method.','retrieve data',0,'',''),(7219,'GitPython','If you obtained your submodule object by traversing a tree object which is not rooted at the head’s commit,\nyou have to inform the submodule about its actual commit to retrieve the data from\nby using the set_parent_commit(...) method.','use set_parent_commit(...) method',0,'',''),(7220,'GitPython','The special RootModule type allows you to treat your master repository as root of a hierarchy of submodules, which allows very convenient submodule handling. Its update(...) method is reimplemented to provide an advanced way of updating submodules as they change their values over time. The update method will track changes and make sure your working tree and submodule checkouts stay consistent, which is very useful in case submodules get deleted or added to name just two of the handled cases.','provide advanced way of updating',0,'',''),(7221,'GitPython','The special RootModule type allows you to treat your master repository as root of a hierarchy of submodules, which allows very convenient submodule handling. Its update(...) method is reimplemented to provide an advanced way of updating submodules as they change their values over time. The update method will track changes and make sure your working tree and submodule checkouts stay consistent, which is very useful in case submodules get deleted or added to name just two of the handled cases.','update submodules',0,'',''),(7222,'GitPython','The special RootModule type allows you to treat your master repository as root of a hierarchy of submodules, which allows very convenient submodule handling. Its update(...) method is reimplemented to provide an advanced way of updating submodules as they change their values over time. The update method will track changes and make sure your working tree and submodule checkouts stay consistent, which is very useful in case submodules get deleted or added to name just two of the handled cases.','change values over time',0,'',''),(7223,'GitPython','The special RootModule type allows you to treat your master repository as root of a hierarchy of submodules, which allows very convenient submodule handling. Its update(...) method is reimplemented to provide an advanced way of updating submodules as they change their values over time. The update method will track changes and make sure your working tree and submodule checkouts stay consistent, which is very useful in case submodules get deleted or added to name just two of the handled cases.','track changes',0,'',''),(7224,'GitPython','Additionally, GitPython adds functionality to track a specific branch, instead of just a commit. Supported by customized update methods, you are able to automatically update submodules to the latest revision available in the remote repository, as well as to keep track of changes and movements of these submodules. To use it, set the name of the branch you want to track to the submodule.$name.branch option of the .gitmodules  file, and use GitPython update methods on the resulting repository with the to_latest_revision parameter turned on. In the latter case, the sha of your submodule will be ignored, instead a local tracking branch will be updated to the respective remote branch automatically, provided there are no local changes. The resulting behaviour is much like the one of svn::externals, which can be useful in times.','track commit',0,'',''),(7225,'GitPython','Additionally, GitPython adds functionality to track a specific branch, instead of just a commit. Supported by customized update methods, you are able to automatically update submodules to the latest revision available in the remote repository, as well as to keep track of changes and movements of these submodules. To use it, set the name of the branch you want to track to the submodule.$name.branch option of the .gitmodules  file, and use GitPython update methods on the resulting repository with the to_latest_revision parameter turned on. In the latter case, the sha of your submodule will be ignored, instead a local tracking branch will be updated to the respective remote branch automatically, provided there are no local changes. The resulting behaviour is much like the one of svn::externals, which can be useful in times.','track specific branch',0,'',''),(7226,'GitPython','Additionally, GitPython adds functionality to track a specific branch, instead of just a commit. Supported by customized update methods, you are able to automatically update submodules to the latest revision available in the remote repository, as well as to keep track of changes and movements of these submodules. To use it, set the name of the branch you want to track to the submodule.$name.branch option of the .gitmodules  file, and use GitPython update methods on the resulting repository with the to_latest_revision parameter turned on. In the latter case, the sha of your submodule will be ignored, instead a local tracking branch will be updated to the respective remote branch automatically, provided there are no local changes. The resulting behaviour is much like the one of svn::externals, which can be useful in times.','update submodules to latest revision available',0,'',''),(7227,'GitPython','Additionally, GitPython adds functionality to track a specific branch, instead of just a commit. Supported by customized update methods, you are able to automatically update submodules to the latest revision available in the remote repository, as well as to keep track of changes and movements of these submodules. To use it, set the name of the branch you want to track to the submodule.$name.branch option of the .gitmodules  file, and use GitPython update methods on the resulting repository with the to_latest_revision parameter turned on. In the latter case, the sha of your submodule will be ignored, instead a local tracking branch will be updated to the respective remote branch automatically, provided there are no local changes. The resulting behaviour is much like the one of svn::externals, which can be useful in times.','set name of branch',0,'',''),(7228,'GitPython','Additionally, GitPython adds functionality to track a specific branch, instead of just a commit. Supported by customized update methods, you are able to automatically update submodules to the latest revision available in the remote repository, as well as to keep track of changes and movements of these submodules. To use it, set the name of the branch you want to track to the submodule.$name.branch option of the .gitmodules  file, and use GitPython update methods on the resulting repository with the to_latest_revision parameter turned on. In the latter case, the sha of your submodule will be ignored, instead a local tracking branch will be updated to the respective remote branch automatically, provided there are no local changes. The resulting behaviour is much like the one of svn::externals, which can be useful in times.','track  to submodule',0,'',''),(7229,'GitPython','Additionally, GitPython adds functionality to track a specific branch, instead of just a commit. Supported by customized update methods, you are able to automatically update submodules to the latest revision available in the remote repository, as well as to keep track of changes and movements of these submodules. To use it, set the name of the branch you want to track to the submodule.$name.branch option of the .gitmodules  file, and use GitPython update methods on the resulting repository with the to_latest_revision parameter turned on. In the latter case, the sha of your submodule will be ignored, instead a local tracking branch will be updated to the respective remote branch automatically, provided there are no local changes. The resulting behaviour is much like the one of svn::externals, which can be useful in times.','ignore sha in latter case',0,'',''),(7230,'GitPython','Additionally, GitPython adds functionality to track a specific branch, instead of just a commit. Supported by customized update methods, you are able to automatically update submodules to the latest revision available in the remote repository, as well as to keep track of changes and movements of these submodules. To use it, set the name of the branch you want to track to the submodule.$name.branch option of the .gitmodules  file, and use GitPython update methods on the resulting repository with the to_latest_revision parameter turned on. In the latter case, the sha of your submodule will be ignored, instead a local tracking branch will be updated to the respective remote branch automatically, provided there are no local changes. The resulting behaviour is much like the one of svn::externals, which can be useful in times.','ignore sha of submodule',0,'',''),(7231,'GitPython','Diffs can generally be obtained by subclasses of Diffable as they provide the diff method. This operation yields a DiffIndex allowing you to easily access diff information about paths.','provide diff method',0,'',''),(7232,'GitPython','Diffs can generally be obtained by subclasses of Diffable as they provide the diff method. This operation yields a DiffIndex allowing you to easily access diff information about paths.','obtain diffs',0,'',''),(7233,'GitPython','Diffs can generally be obtained by subclasses of Diffable as they provide the diff method. This operation yields a DiffIndex allowing you to easily access diff information about paths.','access diff information about paths',0,'',''),(7234,'GitPython','Diffs can be made between the Index and Trees, Index and the working tree, trees and trees as well as trees and the working copy. If commits are involved, their tree will be used implicitly.','use tree',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7235,'GitPython','Use the diff framework if you want to implement git-status like functionality.','use diff framework',0,'',''),(7236,'GitPython','Use the diff framework if you want to implement git-status like functionality.','implement git-status',0,'',''),(7237,'GitPython','To switch between branches similar to git checkout, you effectively need to point your HEAD symbolic reference to the new branch and reset your index and working copy to match. A simple manual way to do it is the following one','switch  between branches similar',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7238,'GitPython','The previous approach would brutally overwrite the user’s changes in the working copy and index though and is less sophisticated than a git-checkout. The latter will generally prevent you from destroying your work. Use the safer approach as follows.','overwrite changes in index',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7239,'GitPython','The previous approach would brutally overwrite the user’s changes in the working copy and index though and is less sophisticated than a git-checkout. The latter will generally prevent you from destroying your work. Use the safer approach as follows.','overwrite changes in working copy',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7240,'GitPython','The previous approach would brutally overwrite the user’s changes in the working copy and index though and is less sophisticated than a git-checkout. The latter will generally prevent you from destroying your work. Use the safer approach as follows.','prevent  from destroying',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7241,'GitPython','The previous approach would brutally overwrite the user’s changes in the working copy and index though and is less sophisticated than a git-checkout. The latter will generally prevent you from destroying your work. Use the safer approach as follows.','use safer approach',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7242,'GitPython','In this example, we will initialize an empty repository, add an empty file to the index, and commit the change.','initialize empty repository',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7243,'GitPython','In this example, we will initialize an empty repository, add an empty file to the index, and commit the change.','add empty file to index',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7244,'GitPython','Please have a look at the individual methods as they usually support a vast amount of arguments to customize their behavior.','support vast amount of arguments',0,'',''),(7245,'GitPython','Please have a look at the individual methods as they usually support a vast amount of arguments to customize their behavior.','customize behavior',0,'',''),(7246,'GitPython','In case you are missing functionality as it has not been wrapped, you may conveniently use the git command directly. It is owned by each repository instance.','use git command',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7247,'GitPython','Keyword arguments translate to short and long keyword arguments on the command-line.\nThe special notion git.command(flag=True) will create a flag without value like command --flag.','translate  to short long keyword arguments',0,'',''),(7248,'GitPython','Keyword arguments translate to short and long keyword arguments on the command-line.\nThe special notion git.command(flag=True) will create a flag without value like command --flag.','translate  on command-line',0,'',''),(7249,'GitPython','Keyword arguments translate to short and long keyword arguments on the command-line.\nThe special notion git.command(flag=True) will create a flag without value like command --flag.','create flag without value',0,'',''),(7250,'GitPython','If None is found in the arguments, it will be dropped silently. Lists and tuples passed as arguments will be unpacked recursively to individual arguments. Objects are converted to strings using the str(...) function.','find none in arguments',0,'',''),(7251,'GitPython','If None is found in the arguments, it will be dropped silently. Lists and tuples passed as arguments will be unpacked recursively to individual arguments. Objects are converted to strings using the str(...) function.','use str(...) function',0,'',''),(7252,'GitPython','If None is found in the arguments, it will be dropped silently. Lists and tuples passed as arguments will be unpacked recursively to individual arguments. Objects are converted to strings using the str(...) function.','convert objects to strings',0,'',''),(7253,'GitPython','git.Repo instances are powered by its object database instance which will be used when extracting any data, or when writing new objects.','write new objects',0,'',''),(7254,'GitPython','git.Repo instances are powered by its object database instance which will be used when extracting any data, or when writing new objects.','use object database instance',0,'',''),(7255,'GitPython','The type of the database determines certain performance characteristics, such as the quantity of objects that can be read per second, the resource usage when reading large data files, as well as the average memory footprint of your application.','determine average memory footprint of application',0,'',''),(7256,'GitPython','The type of the database determines certain performance characteristics, such as the quantity of objects that can be read per second, the resource usage when reading large data files, as well as the average memory footprint of your application.','determine average memory footprint such_as quantity',0,'',''),(7257,'GitPython','The type of the database determines certain performance characteristics, such as the quantity of objects that can be read per second, the resource usage when reading large data files, as well as the average memory footprint of your application.','determine certain performance characteristics of application',0,'',''),(7258,'GitPython','The type of the database determines certain performance characteristics, such as the quantity of objects that can be read per second, the resource usage when reading large data files, as well as the average memory footprint of your application.','determine certain performance characteristics such_as quantity',0,'',''),(7259,'GitPython','The type of the database determines certain performance characteristics, such as the quantity of objects that can be read per second, the resource usage when reading large data files, as well as the average memory footprint of your application.','read objects',0,'',''),(7260,'GitPython','The GitDB is a pure-python implementation of the git object database. It is the default database to use in GitPython 0.3. It uses less memory when handling huge files, but will be 2 to 5 times slower when extracting large quantities of small objects from densely packed repositories:','use  in GitPython',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7261,'GitPython','The GitDB is a pure-python implementation of the git object database. It is the default database to use in GitPython 0.3. It uses less memory when handling huge files, but will be 2 to 5 times slower when extracting large quantities of small objects from densely packed repositories:','use less memory',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7262,'GitPython','The GitDB is a pure-python implementation of the git object database. It is the default database to use in GitPython 0.3. It uses less memory when handling huge files, but will be 2 to 5 times slower when extracting large quantities of small objects from densely packed repositories:','handle huge files',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7263,'GitPython','The git command database uses persistent git-cat-file instances to read repository information. These operate very fast under all conditions, but will consume additional memory for the process itself. When extracting large files, memory usage will be much higher than GitDB:','use persistent git-cat-file instances',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7264,'GitPython','The git command database uses persistent git-cat-file instances to read repository information. These operate very fast under all conditions, but will consume additional memory for the process itself. When extracting large files, memory usage will be much higher than GitDB:','read repository information',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7265,'GitPython','Using environment variables, you can further adjust the behaviour of the git command.','use environment variables',0,'',''),(7266,'GitPython','Using environment variables, you can further adjust the behaviour of the git command.','adjust behaviour of git command',0,'',''),(7267,'GitPython','NOTE: All logging is outputted using a Python logger, so make sure your program is configured to show INFO-level messages.  If this is not the case, try adding the following to your program:','use Python logger',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7268,'GitPython','NOTE: All logging is outputted using a Python logger, so make sure your program is configured to show INFO-level messages.  If this is not the case, try adding the following to your program:','show INFO-level messages',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7269,'GitPython','NOTE: All logging is outputted using a Python logger, so make sure your program is configured to show INFO-level messages.  If this is not the case, try adding the following to your program:','configure program',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7270,'GitPython','NOTE: All logging is outputted using a Python logger, so make sure your program is configured to show INFO-level messages.  If this is not the case, try adding the following to your program:','add following to program',1,'https://gitpython.readthedocs.io/en/stable/tutorial.html',''),(7271,'GitPython','There is more functionality in there, like the ability to archive repositories, get stats and logs, blame, and probably a few other things that were not mentioned here.','get stats like ability',0,'',''),(7272,'GitPython','There is more functionality in there, like the ability to archive repositories, get stats and logs, blame, and probably a few other things that were not mentioned here.','get logs like ability',0,'',''),(7273,'GitPython','There is more functionality in there, like the ability to archive repositories, get stats and logs, blame, and probably a few other things that were not mentioned here.','get blame like ability',0,'',''),(7274,'GitPython','There is more functionality in there, like the ability to archive repositories, get stats and logs, blame, and probably a few other things that were not mentioned here.','get few other things like ability',0,'',''),(7275,'GitPython','Check the unit tests for an in-depth introduction on how each function is supposed to be used.','check unit tests for in-depth introduction',0,'',''),(7276,'GitPython','The full list of milestones including associated tasks can be found on GitHub:\nhttps://github.com/gitpython-developers/GitPython/issues','find full list of milestones',0,'',''),(7277,'GitPython','The full list of milestones including associated tasks can be found on GitHub:\nhttps://github.com/gitpython-developers/GitPython/issues','find full list on github',0,'',''),(7278,'GitPython','Select the respective milestone to filter the list of issues accordingly.','select respective milestone',0,'',''),(7279,'GitPython','It provides abstractions of git objects for easy access of repository data, and additionally allows you to access the git repository more directly using either a pure python implementation, or the faster, but more resource intensive git command implementation.','provide abstractions of git objects',0,'',''),(7280,'GitPython','It provides abstractions of git objects for easy access of repository data, and additionally allows you to access the git repository more directly using either a pure python implementation, or the faster, but more resource intensive git command implementation.','provide abstractions for easy access',0,'',''),(7281,'GitPython','It provides abstractions of git objects for easy access of repository data, and additionally allows you to access the git repository more directly using either a pure python implementation, or the faster, but more resource intensive git command implementation.','use faster resource intensive git command implementation',0,'',''),(7282,'GitPython','It provides abstractions of git objects for easy access of repository data, and additionally allows you to access the git repository more directly using either a pure python implementation, or the faster, but more resource intensive git command implementation.','use pure python implementation',0,'',''),(7283,'GitPython','The object database implementation is optimized for handling large quantities of objects and large datasets, which is achieved by using low-level structures and data streaming.','handle large quantities of objects',0,'',''),(7284,'GitPython','The object database implementation is optimized for handling large quantities of objects and large datasets, which is achieved by using low-level structures and data streaming.','handle large quantities of large datasets',0,'',''),(7285,'GitPython','The object database implementation is optimized for handling large quantities of objects and large datasets, which is achieved by using low-level structures and data streaming.','use low-level structures',0,'',''),(7286,'GitPython','The object database implementation is optimized for handling large quantities of objects and large datasets, which is achieved by using low-level structures and data streaming.','use data',0,'',''),(7287,'GitPython','Installing GitPython is easily done using\npip. Assuming it is\ninstalled, just run the following from the command-line:','use pip',1,'https://gitpython.readthedocs.io/en/stable/intro.html',''),(7288,'GitPython','Installing GitPython is easily done using\npip. Assuming it is\ninstalled, just run the following from the command-line:','run following from command-line',1,'https://gitpython.readthedocs.io/en/stable/intro.html',''),(7289,'GitPython','This command will download the latest version of GitPython from the\nPython Package Index and install it\nto your system. More information about pip and pypi can be found\nhere:','download latest version of GitPython',0,'',''),(7290,'GitPython','This command will download the latest version of GitPython from the\nPython Package Index and install it\nto your system. More information about pip and pypi can be found\nhere:','download latest version from Python Package index',0,'',''),(7291,'GitPython','This command will download the latest version of GitPython from the\nPython Package Index and install it\nto your system. More information about pip and pypi can be found\nhere:','install  to system',0,'',''),(7292,'GitPython','This command will download the latest version of GitPython from the\nPython Package Index and install it\nto your system. More information about pip and pypi can be found\nhere:','find more information about pip',0,'',''),(7293,'GitPython','This command will download the latest version of GitPython from the\nPython Package Index and install it\nto your system. More information about pip and pypi can be found\nhere:','find more information about pypi',0,'',''),(7294,'GitPython','Alternatively, you can install from the distribution using the setup.py\nscript:','use setup.py script',1,'https://gitpython.readthedocs.io/en/stable/intro.html',''),(7295,'GitPython','Alternatively, you can install from the distribution using the setup.py\nscript:','install  from distribution',1,'https://gitpython.readthedocs.io/en/stable/intro.html',''),(7296,'GitPython','GitPython is not suited for long-running processes (like daemons) as it tends to\nleak system resources. It was written in a time where destructors (as implemented\nin the __del__ method) still ran deterministically.','write  in time',0,'',''),(7297,'GitPython','GitPython is not suited for long-running processes (like daemons) as it tends to\nleak system resources. It was written in a time where destructors (as implemented\nin the __del__ method) still ran deterministically.','run time',0,'',''),(7298,'GitPython','In case you still want to use it in such a context, you will want to search the\ncodebase for __del__ implementations and call these yourself when you see fit.','use  in context',0,'',''),(7299,'GitPython','In case you still want to use it in such a context, you will want to search the\ncodebase for __del__ implementations and call these yourself when you see fit.','search codebase for __del__ implementations',0,'',''),(7300,'GitPython','Initialize all submodules to obtain the required dependencies with:','obtain required dependencies',1,'https://gitpython.readthedocs.io/en/stable/intro.html','source-code-label'),(7301,'GitPython','Finally verify the installation by running unit tests:','run unit tests',1,'https://gitpython.readthedocs.io/en/stable/intro.html','source-code-label'),(7302,'GitPython','Please use stackoverflow for questions, and don’t forget to tag it with gitpython to assure the right people see the question in a timely manner.','use stackoverflow for questions',0,'',''),(7303,'GitPython','The issue tracker is hosted by GitHub:','host issue tracker',0,'',''),(7304,'Ivy','By default, Ivy searches for a site configuration file called either site.py or config.py.\nYou can specify a custom filename for the site configuration file using the IVY_CONFIG_FILE environment variable, e.g.','call site.py by default',1,'http://www.dmulholl.com/docs/ivy/main/options.html','site-configuration-file'),(7305,'Ivy','By default, Ivy searches for a site configuration file called either site.py or config.py.\nYou can specify a custom filename for the site configuration file using the IVY_CONFIG_FILE environment variable, e.g.','call config.py by default',1,'http://www.dmulholl.com/docs/ivy/main/options.html','site-configuration-file'),(7306,'Ivy','By default, Ivy searches for a site configuration file called either site.py or config.py.\nYou can specify a custom filename for the site configuration file using the IVY_CONFIG_FILE environment variable, e.g.','specify custom filename for site configuration file',1,'http://www.dmulholl.com/docs/ivy/main/options.html','site-configuration-file'),(7307,'Ivy','By default, Ivy searches for a site configuration file called either site.py or config.py.\nYou can specify a custom filename for the site configuration file using the IVY_CONFIG_FILE environment variable, e.g.','use IVY_CONFIG_FILE environment variable',1,'http://www.dmulholl.com/docs/ivy/main/options.html','site-configuration-file'),(7308,'Ivy','By default, Ivy uses directories named ext, inc, lib, out, res, and src.','use directories by default',0,'',''),(7309,'Ivy','You can customize these default directory names using environment variables, e.g.','use environment variables',1,'http://www.dmulholl.com/docs/ivy/main/options.html','directory-names'),(7310,'Ivy','Alternatively, you can customize directory names on a per-site basis by specifying alternate names in your site configuration file, e.g.','customize directory names by specifying',1,'http://www.dmulholl.com/docs/ivy/main/options.html','directory-names'),(7311,'Ivy','Alternatively, you can customize directory names on a per-site basis by specifying alternate names in your site configuration file, e.g.','customize directory names on per-site basis',1,'http://www.dmulholl.com/docs/ivy/main/options.html','directory-names'),(7312,'Ivy','Alternatively, you can customize directory names on a per-site basis by specifying alternate names in your site configuration file, e.g.','specify alternate names in site configuration file',1,'http://www.dmulholl.com/docs/ivy/main/options.html','directory-names'),(7313,'Ivy','Ivy generates output pages with a .html file extension by default.','generate output pages',0,'',''),(7314,'Ivy','You can specify a custom file extension for output files in your site configuration file, e.g.','specify custom file extension in site configuration file',1,'http://www.dmulholl.com/docs/ivy/main/options.html','custom-file-extensions'),(7315,'Ivy','You can specify a custom file extension for output files in your site configuration file, e.g.','specify custom file extension for output files',1,'http://www.dmulholl.com/docs/ivy/main/options.html','custom-file-extensions'),(7316,'Ivy','You can generate directory-style URLs — i.e. URLs ending in a forward slash — by setting a custom file extension of \"/\" in your site configuration file:','generate directory-style urls â i.e. urls',1,'http://www.dmulholl.com/docs/ivy/main/options.html','directory-style-urls'),(7317,'Ivy','You can generate directory-style URLs — i.e. URLs ending in a forward slash — by setting a custom file extension of \"/\" in your site configuration file:','set custom file extension of /',1,'http://www.dmulholl.com/docs/ivy/main/options.html','directory-style-urls'),(7318,'Ivy','Ivy generates page-relative URLs by default.','generate page-relative urls by default',0,'',''),(7319,'Ivy','You can generate absolute URLs by specifying an explicit root URL in your site configuration file, e.g.','generate absolute urls by specifying',1,'http://www.dmulholl.com/docs/ivy/main/options.html','absolute-urls'),(7320,'Ivy','You can generate absolute URLs by specifying an explicit root URL in your site configuration file, e.g.','specify explicit root URL in site configuration file',1,'http://www.dmulholl.com/docs/ivy/main/options.html','absolute-urls'),(7321,'Ivy','You can generate site-relative URLs — i.e. URLs that begin with a / — by specifying a root URL of \"/\" in your site configuration file:','generate site-relative urls â i.e. urls',1,'http://www.dmulholl.com/docs/ivy/main/options.html','site-relative-urls'),(7322,'Ivy','To initialize a new site, create a site directory, cd into it, and run the init command:','initialize new site',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','command-line-interface'),(7323,'Ivy','To initialize a new site, create a site directory, cd into it, and run the init command:','create site directory',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','command-line-interface'),(7324,'Ivy','To initialize a new site, create a site directory, cd into it, and run the init command:','run init command',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','command-line-interface'),(7325,'Ivy','Use the ivy --help flag to view the full command-line help text.','use ivy',0,'',''),(7326,'Ivy','Ivy assumes that a site uses the following default directory structure:','use following default directory structure',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','site-structure'),(7327,'Ivy','Ivy uses the presence of a site.py file (alternatively, a config.py file) to identify a site\'s home directory.','identify home directory',0,'',''),(7328,'Ivy','Static assets such as image files should be placed in the site\'s resources directory, res. The content of this directory is copied to the output directory when the site is built.','place static assets in resources directory',0,'',''),(7329,'Ivy','Static assets such as image files should be placed in the site\'s resources directory, res. The content of this directory is copied to the output directory when the site is built.','place static assets such_as image files',0,'',''),(7330,'Ivy','A node is a text file or directory stored in a site\'s src directory. Ivy parses the src directory into a tree of nodes which it then renders into a website, generating a single HTML page in the out directory for each node in the tree.','store  in src directory',0,'',''),(7331,'Ivy','A node is a text file or directory stored in a site\'s src directory. Ivy parses the src directory into a tree of nodes which it then renders into a website, generating a single HTML page in the out directory for each node in the tree.','render nodes into website',0,'',''),(7332,'Ivy','A node is a text file or directory stored in a site\'s src directory. Ivy parses the src directory into a tree of nodes which it then renders into a website, generating a single HTML page in the out directory for each node in the tree.','generate single HTML page in out directory',0,'',''),(7333,'Ivy','A node file can begin with a YAML header specifying metadata for the node:','specify metadata for node',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','nodes'),(7334,'Ivy','Node content can be written in Markdown, Syntext, or plain HTML.\nFiles with a .md extension have their content passed through a Markdown renderer; files with a .stx extension have their content passed through a Syntext renderer; files with an unregistered extension (like .txt or .html) have their content preserved as-is.','write node content in markdown',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','nodes'),(7335,'Ivy','Node content can be written in Markdown, Syntext, or plain HTML.\nFiles with a .md extension have their content passed through a Markdown renderer; files with a .stx extension have their content passed through a Syntext renderer; files with an unregistered extension (like .txt or .html) have their content preserved as-is.','write node content in syntext',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','nodes'),(7336,'Ivy','Node content can be written in Markdown, Syntext, or plain HTML.\nFiles with a .md extension have their content passed through a Markdown renderer; files with a .stx extension have their content passed through a Syntext renderer; files with an unregistered extension (like .txt or .html) have their content preserved as-is.','write node content in plain HTML',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','nodes'),(7337,'Ivy','Node content can be written in Markdown, Syntext, or plain HTML.\nFiles with a .md extension have their content passed through a Markdown renderer; files with a .stx extension have their content passed through a Syntext renderer; files with an unregistered extension (like .txt or .html) have their content preserved as-is.','pass  through Markdown renderer',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','nodes'),(7338,'Ivy','Node content can be written in Markdown, Syntext, or plain HTML.\nFiles with a .md extension have their content passed through a Markdown renderer; files with a .stx extension have their content passed through a Syntext renderer; files with an unregistered extension (like .txt or .html) have their content preserved as-is.','pass  through Syntext renderer',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','nodes'),(7339,'Ivy','correspond to a single node in the parse tree. Node files provide content and metadata for a node; node directories store child nodes.','provide content for node',0,'',''),(7340,'Ivy','correspond to a single node in the parse tree. Node files provide content and metadata for a node; node directories store child nodes.','provide metadata for node',0,'',''),(7341,'Ivy','correspond to a single node in the parse tree. Node files provide content and metadata for a node; node directories store child nodes.','store child nodes',0,'',''),(7342,'Ivy','Ivy has builtin support for node metadata in YAML format. Note that metadata keys are converted to lowercase and spaces and hyphens are replaced by underscores so the YAML attribute:','replace spaces',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','metadata'),(7343,'Ivy','Ivy has builtin support for node metadata in YAML format. Note that metadata keys are converted to lowercase and spaces and hyphens are replaced by underscores so the YAML attribute:','replace hyphens',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','metadata'),(7344,'Ivy','Ivy has builtin support for node metadata in YAML format. Note that metadata keys are converted to lowercase and spaces and hyphens are replaced by underscores so the YAML attribute:','convert metadata keys',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','metadata'),(7345,'Ivy','The node\'s text content as read from the source file.','read  from source file',0,'',''),(7346,'Ivy','The node\'s text content after it has been rendered into HTML. (This will only differ from node.text if a renderer has been registered for the node file\'s extension. By default a Markdown renderer is registered for .md files and a Syntext renderer for .stx files.)','render text content into HTML',0,'',''),(7347,'Ivy','Ivy generates page-relative URLs and files with a .html extension by default.','generate page-relative urls',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','links'),(7348,'Ivy','Ivy generates page-relative URLs and files with a .html extension by default.','generate files',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','links'),(7349,'Ivy','Use two trailing slashes when linking to pages generated by Ivy itself — this tells Ivy to rewrite the ending to suit your extension settings.','use trailing slashes',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','links'),(7350,'Ivy','Use two trailing slashes when linking to pages generated by Ivy itself — this tells Ivy to rewrite the ending to suit your extension settings.','link  to pages',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','links'),(7351,'Ivy','Use two trailing slashes when linking to pages generated by Ivy itself — this tells Ivy to rewrite the ending to suit your extension settings.','generate  by ivy',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','links'),(7352,'Ivy','Linking to the homepage is a special case — a simple @root/ will always suffice.','link  to homepage',0,'',''),(7353,'Ivy','A node\'s URL is determined by its slug and by the slugs of its ancestor nodes. By default a node\'s slug is generated by slugifying its filename — the extension is stripped, text is converted to lowercase ASCII, spaces are converted to hyphens etc., so a node file named Foo Bar.md would have the slug foo-bar.','determine URL',0,'',''),(7354,'Ivy','A node\'s URL is determined by its slug and by the slugs of its ancestor nodes. By default a node\'s slug is generated by slugifying its filename — the extension is stripped, text is converted to lowercase ASCII, spaces are converted to hyphens etc., so a node file named Foo Bar.md would have the slug foo-bar.','generate slug',0,'',''),(7355,'Ivy','A node\'s URL is determined by its slug and by the slugs of its ancestor nodes. By default a node\'s slug is generated by slugifying its filename — the extension is stripped, text is converted to lowercase ASCII, spaces are converted to hyphens etc., so a node file named Foo Bar.md would have the slug foo-bar.','convert spaces',0,'',''),(7356,'Ivy','A node\'s URL is determined by its slug and by the slugs of its ancestor nodes. By default a node\'s slug is generated by slugifying its filename — the extension is stripped, text is converted to lowercase ASCII, spaces are converted to hyphens etc., so a node file named Foo Bar.md would have the slug foo-bar.','convert text',0,'',''),(7357,'Ivy','This default slug can be overridden by setting a custom slug in the header:','set custom slug in header',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','slugs'),(7358,'Ivy','This default slug can be overridden by setting a custom slug in the header:','override default slug',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','slugs'),(7359,'Ivy','Slugs can be customized sitewide by registering a filter callback on the Filter.SLUGIFY filter hook. (You can find this hook in the ivy/utils.py file.)','customize sitewide',0,'',''),(7360,'Ivy','Slugs can be customized sitewide by registering a filter callback on the Filter.SLUGIFY filter hook. (You can find this hook in the ivy/utils.py file.)','customize slugs',0,'',''),(7361,'Ivy','Ivy automatically generates a list of useful CSS classes for each page\'s  element based on the page\'s URL slugs. For example the page with the URL:','generate list of useful CSS classes',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','classes'),(7362,'Ivy','You can add your own custom classes for a particular node by adding a comma-separated classes list to the node\'s header, e.g.','add own custom classes by adding',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','classes'),(7363,'Ivy','You can add your own custom classes for a particular node by adding a comma-separated classes list to the node\'s header, e.g.','add own custom classes for particular node',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','classes'),(7364,'Ivy','You can add your own custom classes for a particular node by adding a comma-separated classes list to the node\'s header, e.g.','add comma-separated classes list to header',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','classes'),(7365,'Ivy','Note that the homepage node automatically gets the class homepage.','get class homepage',0,'',''),(7366,'Ivy','The includes directory, inc, is for includeable files, typically snippets of content that can be reused on multiple pages throughout the site like menus or footer links. Source files placed in this folder will be parsed as Markdown or Syntext depending on their extension and the resulting HTML made available for inclusion in templates via an inc. variable.','reuse snippets of content',0,'',''),(7367,'Ivy','The includes directory, inc, is for includeable files, typically snippets of content that can be reused on multiple pages throughout the site like menus or footer links. Source files placed in this folder will be parsed as Markdown or Syntext depending on their extension and the resulting HTML made available for inclusion in templates via an inc. variable.','reuse snippets for includeable files',0,'',''),(7368,'Ivy','The includes directory, inc, is for includeable files, typically snippets of content that can be reused on multiple pages throughout the site like menus or footer links. Source files placed in this folder will be parsed as Markdown or Syntext depending on their extension and the resulting HTML made available for inclusion in templates via an inc. variable.','reuse snippets throughout site',0,'',''),(7369,'Ivy','The includes directory, inc, is for includeable files, typically snippets of content that can be reused on multiple pages throughout the site like menus or footer links. Source files placed in this folder will be parsed as Markdown or Syntext depending on their extension and the resulting HTML made available for inclusion in templates via an inc. variable.','reuse snippets on multiple pages',0,'',''),(7370,'Ivy','The includes directory, inc, is for includeable files, typically snippets of content that can be reused on multiple pages throughout the site like menus or footer links. Source files placed in this folder will be parsed as Markdown or Syntext depending on their extension and the resulting HTML made available for inclusion in templates via an inc. variable.','place  in folder',0,'',''),(7371,'Ivy','For example, a simple menu can be constructed in Markdown using nested lists:','use nested lists',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','includes'),(7372,'Ivy','If this menu was placed in a file named menu.md then the rendered HTML would be available in templates via an inc.menu variable. (Note that filenames are converted to lower case and spaces and hyphens are converted to underscores.)','place menu in file',0,'',''),(7373,'Ivy','You can add files with any extension to the inc directory including .html, .js, and .css.\nIf no renderer has been registered for the extension the file\'s content will be preserved as-is.','add files with extension',0,'',''),(7374,'Ivy','You can add files with any extension to the inc directory including .html, .js, and .css.\nIf no renderer has been registered for the extension the file\'s content will be preserved as-is.','add files to inc directory',0,'',''),(7375,'Ivy','Just add meta_title and/or meta_description attributes to the page\'s header:','add meta_title and/or',1,'http://www.dmulholl.com/docs/ivy/main/sites.html','meta-titles-and-descriptions'),(7376,'Ivy','This isn\'t really a feature of Ivy itself — the default theme simply checks for these attributes in its template files and you can add similar support to your own custom themes.','add similar support to own custom themes',0,'',''),(7377,'Ivy','This isn\'t really a feature of Ivy itself — the default theme simply checks for these attributes in its template files and you can add similar support to your own custom themes.','check  for attributes',0,'',''),(7378,'Ivy','An extension (also known as a plugin) is a Python module or package that extends Ivy\'s functionality. You can install extensions for a site in one of two ways.','extend Python module',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','installing-extensions'),(7379,'Ivy','An extension (also known as a plugin) is a Python module or package that extends Ivy\'s functionality. You can install extensions for a site in one of two ways.','extend package',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','installing-extensions'),(7380,'Ivy','An extension (also known as a plugin) is a Python module or package that extends Ivy\'s functionality. You can install extensions for a site in one of two ways.','install extensions for site',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','installing-extensions'),(7381,'Ivy','You can add an extensions directory named ext to your site\'s root directory. Extension modules placed in this ext directory will be loaded automatically by Ivy.','add extensions directory',0,'',''),(7382,'Ivy','You can add an extensions directory named ext to your site\'s root directory. Extension modules placed in this ext directory will be loaded automatically by Ivy.','place  in ext directory',0,'',''),(7383,'Ivy','You can add an extensions directory named ext to your site\'s root directory. Extension modules placed in this ext directory will be loaded automatically by Ivy.','load extension modules',0,'',''),(7384,'Ivy','If an extension module has been installed on Python\'s standard import path you can activate it for a particular site by adding its name to an extensions list in the site\'s configuration file:','activate  by adding',0,'',''),(7385,'Ivy','If an extension module has been installed on Python\'s standard import path you can activate it for a particular site by adding its name to an extensions list in the site\'s configuration file:','activate  for particular site',0,'',''),(7386,'Ivy','If an extension module has been installed on Python\'s standard import path you can activate it for a particular site by adding its name to an extensions list in the site\'s configuration file:','add name to extensions list',0,'',''),(7387,'Ivy','If an extension module has been installed on Python\'s standard import path you can activate it for a particular site by adding its name to an extensions list in the site\'s configuration file:','install  on standard import path',0,'',''),(7388,'Ivy','This second method can be used to enable extensions installed from the Python package index using pip.','enable extensions',0,'',''),(7389,'Ivy','This second method can be used to enable extensions installed from the Python package index using pip.','use pip',0,'',''),(7390,'Ivy','This second method can be used to enable extensions installed from the Python package index using pip.','install  from Python package index',0,'',''),(7391,'Ivy','This second method can be used to enable extensions installed from the Python package index using pip.','use second method',0,'',''),(7392,'Ivy','Ivy exports a flexible framework of event and filter hooks. Plugins can extend Ivy by registering callback functions on these hooks.','extend ivy by registering',0,'',''),(7393,'Ivy','You can find these bundled plugins in the ivy/ext/ directory which you can view on Github.','find bundled plugins in ivy/ext/ directory',0,'',''),(7394,'Ivy','Event callbacks accept zero or more arguments depending on the specific hook. They may modify their arguments in place but have no return value.','modify arguments in place',0,'',''),(7395,'Ivy','Here\'s a simple event callback that prints a count of the number of pages that have been written to disk:','print count of number',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','events'),(7396,'Ivy','Here\'s a simple event callback that prints a count of the number of pages that have been written to disk:','print simple event callback of number',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','events'),(7397,'Ivy','Here\'s a simple event callback that prints a count of the number of pages that have been written to disk:','write pages to disk',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','events'),(7398,'Ivy','Filter callbacks accept at least one argument — the value to be filtered. They may accept additional arguments depending on the specific hook. Filter callbacks modify and return the value of their first argument.','modify value of first argument',0,'',''),(7399,'Ivy','Filter callbacks accept at least one argument — the value to be filtered. They may accept additional arguments depending on the specific hook. Filter callbacks modify and return the value of their first argument.','return value of first argument',0,'',''),(7400,'Ivy','Here\'s a simple filter callback that changes every instance of the word foo in node content to bar:','change instance of word foo',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','filters'),(7401,'Ivy','Here\'s a simple filter callback that changes every instance of the word foo in node content to bar:','change instance to bar',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','filters'),(7402,'Ivy','Here\'s a simple filter callback that changes every instance of the word foo in node content to bar:','change simple filter callback of word foo',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','filters'),(7403,'Ivy','Here\'s a simple filter callback that changes every instance of the word foo in node content to bar:','change simple filter callback to bar',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','filters'),(7404,'Ivy','This callback is registered on the NODE_TEXT filter hook which fires just before a node\'s text is rendered into HTML. (The NODE_TEXT filter hook can be found in the ivy/nodes.py file).','render text into HTML',0,'',''),(7405,'Ivy','Note that this hook supplies us with the Node instance itself as an additional argument which in this case we ignore.','ignore additional argument in case',0,'',''),(7406,'Ivy','Ivy relies for most of its functionality on a suite of pluggable rendering and parsing engines, e.g. the Jinja template-engine for handling .jinja template files. Extensions can register support for additional rendering and parsing engines using a system of @register decorators.','use system of @register decorators',0,'',''),(7407,'Ivy','Template-engines produce the output HTML for finished .html pages in the site.','produce output HTML',0,'',''),(7408,'Ivy','Ivy has builtin support for Jinja and Ibis templates. Extensions can register support for additional template-engines using the @ivy.templates.register() decorator. Template-engine callbacks are registered per template-file-extension, e.g.','use  decorator',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','template-engines'),(7409,'Ivy','A template-engine callback should accept a dictionary of page data and a template filename and return a string of HTML.','return string of HTML',0,'',''),(7410,'Ivy','Rendering-engines convert node content into HTML which can then be poured into a template to produce the finished .html output page.','convert node content into HTML',0,'',''),(7411,'Ivy','Ivy has builtin support for node files written in Markdown and Syntext. Extensions can register support for additional input formats using the @ivy.renderers.register() decorator. Rendering-engine callbacks are registered per file-extension, e.g.','write  in markdown',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','rendering-engines'),(7412,'Ivy','Ivy has builtin support for node files written in Markdown and Syntext. Extensions can register support for additional input formats using the @ivy.renderers.register() decorator. Rendering-engine callbacks are registered per file-extension, e.g.','write  in syntext',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','rendering-engines'),(7413,'Ivy','Ivy has builtin support for node files written in Markdown and Syntext. Extensions can register support for additional input formats using the @ivy.renderers.register() decorator. Rendering-engine callbacks are registered per file-extension, e.g.','use  decorator',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','rendering-engines'),(7414,'Ivy','A rendering-engine callback should accept a single string argument containing plain text and return a string of HTML.','return string of HTML',0,'',''),(7415,'Ivy','Note that if you register a custom callback for .md files, this will override the default Markdown renderer.','override default Markdown renderer',0,'',''),(7416,'Ivy','Ivy has builtin support for YAML file headers. Extensions can add support for additional metadata formats by preprocessing file content on the file_text filter hook.','add support by preprocessing',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','node-metadata'),(7417,'Ivy','Ivy has builtin support for YAML file headers. Extensions can add support for additional metadata formats by preprocessing file content on the file_text filter hook.','add support for additional metadata formats',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','node-metadata'),(7418,'Ivy','This filter fires each time a node file is loaded from disk; it passes the raw file text along with a metadata dictionary. Callbacks can check the text for an appropriate header marker, process the header if found, and update the dictionary. They should return the text with the header stripped.','pass raw file text along_with metadata dictionary',0,'',''),(7419,'Ivy','This filter fires each time a node file is loaded from disk; it passes the raw file text along with a metadata dictionary. Callbacks can check the text for an appropriate header marker, process the header if found, and update the dictionary. They should return the text with the header stripped.','load node file from disk',0,'',''),(7420,'Ivy','This filter fires each time a node file is loaded from disk; it passes the raw file text along with a metadata dictionary. Callbacks can check the text for an appropriate header marker, process the header if found, and update the dictionary. They should return the text with the header stripped.','load time from disk',0,'',''),(7421,'Ivy','This filter fires each time a node file is loaded from disk; it passes the raw file text along with a metadata dictionary. Callbacks can check the text for an appropriate header marker, process the header if found, and update the dictionary. They should return the text with the header stripped.','check text for appropriate header marker',0,'',''),(7422,'Ivy','This filter fires each time a node file is loaded from disk; it passes the raw file text along with a metadata dictionary. Callbacks can check the text for an appropriate header marker, process the header if found, and update the dictionary. They should return the text with the header stripped.','process header',0,'',''),(7423,'Ivy','This filter fires each time a node file is loaded from disk; it passes the raw file text along with a metadata dictionary. Callbacks can check the text for an appropriate header marker, process the header if found, and update the dictionary. They should return the text with the header stripped.','update dictionary',0,'',''),(7424,'Ivy','This filter fires each time a node file is loaded from disk; it passes the raw file text along with a metadata dictionary. Callbacks can check the text for an appropriate header marker, process the header if found, and update the dictionary. They should return the text with the header stripped.','return text with header',0,'',''),(7425,'Ivy','The FILE_TEXT filter hook can be found in the ivy/utils.py file.','find FILE_TEXT filter hook in ivy/utils.py file',0,'',''),(7426,'Ivy','Ivy uses the Markdown package to render node files with a .md extension. You can add a\ndictionary of keyword arguments for the Markdown renderer to your site configuration file via a\nmarkdown_settings attribute, e.g.','render node files',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','markdown'),(7427,'Ivy','Ivy uses the Markdown package to render node files with a .md extension. You can add a\ndictionary of keyword arguments for the Markdown renderer to your site configuration file via a\nmarkdown_settings attribute, e.g.','add dictionary of keyword arguments',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','markdown'),(7428,'Ivy','Ivy uses the Markdown package to render node files with a .md extension. You can add a\ndictionary of keyword arguments for the Markdown renderer to your site configuration file via a\nmarkdown_settings attribute, e.g.','add dictionary to site configuration file',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','markdown'),(7429,'Ivy','Note that you can register a custom handler for .md files to use an alternative Markdown library of your choice.','use alternative Markdown library of choice',0,'',''),(7430,'Ivy','Ivy uses the Syntext package to render node files with a .stx extension. You can add a dictionary of keyword arguments for the Syntext renderer to your site configuration file via a syntext_settings attribute, e.g.','render node files',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','syntext'),(7431,'Ivy','Ivy uses the Syntext package to render node files with a .stx extension. You can add a dictionary of keyword arguments for the Syntext renderer to your site configuration file via a syntext_settings attribute, e.g.','add dictionary of keyword arguments',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','syntext'),(7432,'Ivy','Ivy uses the Syntext package to render node files with a .stx extension. You can add a dictionary of keyword arguments for the Syntext renderer to your site configuration file via a syntext_settings attribute, e.g.','add dictionary to site configuration file',1,'http://www.dmulholl.com/docs/ivy/main/extensions.html','syntext'),(7433,'Ivy','Ivy uses the Jinja package to render template files with a .jinja extension. You can add a\ndictionary of keyword arguments for the Jinja environment to your site configuration file via a\njinja_settings attribute.','render template files',0,'',''),(7434,'Ivy','Ivy uses the Jinja package to render template files with a .jinja extension. You can add a\ndictionary of keyword arguments for the Jinja environment to your site configuration file via a\njinja_settings attribute.','add dictionary of keyword arguments',0,'',''),(7435,'Ivy','Ivy uses the Jinja package to render template files with a .jinja extension. You can add a\ndictionary of keyword arguments for the Jinja environment to your site configuration file via a\njinja_settings attribute.','add dictionary to site configuration file',0,'',''),(7436,'Ivy','Ivy uses the Shortcodes package to process shortcodes in node files. You can add a dictionary of\nkeyword arguments for the shortcode parser to your site configuration file via a shortcode_settings attribute.','process shortcodes in node files',0,'',''),(7437,'Ivy','Ivy uses the Shortcodes package to process shortcodes in node files. You can add a dictionary of\nkeyword arguments for the shortcode parser to your site configuration file via a shortcode_settings attribute.','add dictionary of keyword arguments',0,'',''),(7438,'Ivy','Ivy uses the Shortcodes package to process shortcodes in node files. You can add a dictionary of\nkeyword arguments for the shortcode parser to your site configuration file via a shortcode_settings attribute.','add dictionary to site configuration file',0,'',''),(7439,'Ivy','The bundled Automenu extension automatically generates a menu containing links to every node in the site. The menu can be accessed in templates via the automenu attribute. This menu can be customized in three ways:','generate menu',0,'',''),(7440,'Ivy','The bundled Automenu extension automatically generates a menu containing links to every node in the site. The menu can be accessed in templates via the automenu attribute. This menu can be customized in three ways:','access menu in templates',0,'',''),(7441,'Ivy','The bundled Automenu extension automatically generates a menu containing links to every node in the site. The menu can be accessed in templates via the automenu attribute. This menu can be customized in three ways:','customize menu in ways',0,'',''),(7442,'Ivy','If a node has a menu_title attribute, its value will be used in the menu in place of the node\'s title.','use value in menu',0,'',''),(7443,'Ivy','By default entries are ordered alphabetically by filename. Entry order can be customized by giving nodes an integer menu_order attribute (positive or negative) with lower numbers coming first. The default order value is 0. (Note that the homepage is an exception and will always be the first entry in the menu.)','order entries',0,'',''),(7444,'Ivy','By default entries are ordered alphabetically by filename. Entry order can be customized by giving nodes an integer menu_order attribute (positive or negative) with lower numbers coming first. The default order value is 0. (Note that the homepage is an exception and will always be the first entry in the menu.)','customize entry order',0,'',''),(7445,'Ivy','If a node has a menu_exclude attribute set to true it (and its children) will be omitted from the menu.','set  to true',0,'',''),(7446,'Ivy','If a node has a menu_exclude attribute set to true it (and its children) will be omitted from the menu.','omit  from menu',0,'',''),(7447,'Ivy','Only nodes which have a menu_title or title attribute are included in the menu.','include nodes in menu',0,'',''),(7448,'Ivy','This plugin adds support for TOML metadata headers as an alternative to YAML.','add support as alternative',0,'',''),(7449,'Ivy','This plugin adds support for TOML metadata headers as an alternative to YAML.','add support for TOML metadata headers',0,'',''),(7450,'Ivy','A clean, responsive, text-focused theme for Ivy.\nThis is the theme I use for my own personal website.','use theme for own personal website',0,'',''),(7451,'Ivy','No. Ivy is designed to be easy to use, with lots of flexibility under the hood if you\'re prepared to write a little extension code. Execution speed isn\'t a significant design goal as it\'s simply irrelevant for the kind of small personal or project websites Ivy is intended to be used for.','write little extension code',0,'',''),(7452,'Ivy','No. Ivy is designed to be easy to use, with lots of flexibility under the hood if you\'re prepared to write a little extension code. Execution speed isn\'t a significant design goal as it\'s simply irrelevant for the kind of small personal or project websites Ivy is intended to be used for.','use  with lots',0,'',''),(7453,'Ivy','No. Ivy is designed to be easy to use, with lots of flexibility under the hood if you\'re prepared to write a little extension code. Execution speed isn\'t a significant design goal as it\'s simply irrelevant for the kind of small personal or project websites Ivy is intended to be used for.','use  under hood',0,'',''),(7454,'Ivy','No. Ivy is designed to be easy to use, with lots of flexibility under the hood if you\'re prepared to write a little extension code. Execution speed isn\'t a significant design goal as it\'s simply irrelevant for the kind of small personal or project websites Ivy is intended to be used for.','design ivy',0,'',''),(7455,'Ivy','Holly is a blog-engine plugin for Ivy. It adds support for WordPress-style post and tag indexes.','add support for wordpress-style post',0,'',''),(7456,'Ivy','Holly is a blog-engine plugin for Ivy. It adds support for WordPress-style post and tag indexes.','add support for tag indexes',0,'',''),(7457,'Ivy','Image files, along with any other static assets, should be stored in the site\'s resources directory, res. The content of this directory is copied to the output directory when the site is built.','store image files along_with other static assets',0,'',''),(7458,'Ivy','Image files, along with any other static assets, should be stored in the site\'s resources directory, res. The content of this directory is copied to the output directory when the site is built.','store image files in resources directory',0,'',''),(7459,'Ivy','As an example, assume we have a file named photo.jpg stored in a directory named images within the res directory, i.e.','store  in directory',1,'http://www.dmulholl.com/docs/ivy/main/faq.html','where-do-i-put-my-image-files'),(7460,'Ivy','This file will be copied to the output directory and can be accessed in templates and node files via the URL:','access file in templates node files',1,'http://www.dmulholl.com/docs/ivy/main/faq.html','where-do-i-put-my-image-files'),(7461,'Ivy','Ivy has no special support for WordPress-style featured images but we can implement similar functionality simply by adding the image name as an attribute to the page header, e.g.','implement similar functionality by adding',1,'http://www.dmulholl.com/docs/ivy/main/faq.html','does-ivy-support-featured-images-or-image-galleries'),(7462,'Ivy','Ivy has no special support for WordPress-style featured images but we can implement similar functionality simply by adding the image name as an attribute to the page header, e.g.','add image name as attribute',1,'http://www.dmulholl.com/docs/ivy/main/faq.html','does-ivy-support-featured-images-or-image-galleries'),(7463,'Ivy','Ivy has no special support for WordPress-style featured images but we can implement similar functionality simply by adding the image name as an attribute to the page header, e.g.','add image name to page header',1,'http://www.dmulholl.com/docs/ivy/main/faq.html','does-ivy-support-featured-images-or-image-galleries'),(7464,'Ivy','We can then check for the presence of a featured image in the appropriate template file:','check  for presence',1,'http://www.dmulholl.com/docs/ivy/main/faq.html','does-ivy-support-featured-images-or-image-galleries'),(7465,'Ivy','YAML supports lists so we can implement galleries in a similar manner by adding a list of image names to the header and then iterating over the list in the template file:','implement galleries by iterating',1,'http://www.dmulholl.com/docs/ivy/main/faq.html','does-ivy-support-featured-images-or-image-galleries'),(7466,'Ivy','YAML supports lists so we can implement galleries in a similar manner by adding a list of image names to the header and then iterating over the list in the template file:','implement galleries by adding',1,'http://www.dmulholl.com/docs/ivy/main/faq.html','does-ivy-support-featured-images-or-image-galleries'),(7467,'Ivy','YAML supports lists so we can implement galleries in a similar manner by adding a list of image names to the header and then iterating over the list in the template file:','add list of image names',1,'http://www.dmulholl.com/docs/ivy/main/faq.html','does-ivy-support-featured-images-or-image-galleries'),(7468,'Ivy','YAML supports lists so we can implement galleries in a similar manner by adding a list of image names to the header and then iterating over the list in the template file:','add list to header',1,'http://www.dmulholl.com/docs/ivy/main/faq.html','does-ivy-support-featured-images-or-image-galleries'),(7469,'Ivy','YAML doesn\'t support unquoted values that begin with an @ symbol so you\'ll get an error message if you add a bare @root/ URL to a YAML header, e.g.','get error message',1,'http://www.dmulholl.com/docs/ivy/main/faq.html','why-do-i-get-an-error-when-i-add-a-url-to-a-yaml-header'),(7470,'Ivy','YAML doesn\'t support unquoted values that begin with an @ symbol so you\'ll get an error message if you add a bare @root/ URL to a YAML header, e.g.','add bare @root / URL to YAML header',1,'http://www.dmulholl.com/docs/ivy/main/faq.html','why-do-i-get-an-error-when-i-add-a-url-to-a-yaml-header'),(7471,'Ivy','One of the nicest things about a static website is that it\'s completely independent of the tool used to build it. You can host your website anywhere you like — in the simplest case you can \'deploy\' it simply by double-clicking on the .html files to view them locally in your browser.','host website',0,'',''),(7472,'Ivy','One of the nicest things about a static website is that it\'s completely independent of the tool used to build it. You can host your website anywhere you like — in the simplest case you can \'deploy\' it simply by double-clicking on the .html files to view them locally in your browser.','deploy simplest case by double-clicking',0,'',''),(7473,'Ivy','The simplest option to get started is to use a service like Github Pages which will host static websites for free.','use service like github Pages',0,'',''),(7474,'Ivy','The simplest option to get started is to use a service like Github Pages which will host static websites for free.','host static websites like github Pages',0,'',''),(7475,'Ivy','The simplest option to get started is to use a service like Github Pages which will host static websites for free.','host service like github Pages',0,'',''),(7476,'Ivy','The next step up is \'shared web hosting\' — it\'s cheap, flexible, and lots of online companies offer it. I\'ve used NearlyFreeSpeech myself and been happy with their service.','share â',0,'',''),(7477,'Ivy','The next step up is \'shared web hosting\' — it\'s cheap, flexible, and lots of online companies offer it. I\'ve used NearlyFreeSpeech myself and been happy with their service.','share next step',0,'',''),(7478,'Ivy','If you need more control over your hosting environment you can run your own webserver (typically Apache or Nginx) on a virtual server machine (a VPS or Virtual Private Server) you rent from a company like Digital Ocean.','run own webserver on virtual server machine',0,'',''),(7479,'Ivy','You can add a disable flag to a node\'s metadata header:','add disable flag to metadata header',1,'http://www.dmulholl.com/docs/ivy/main/faq.html','can-i-disable-a-node'),(7480,'Ivy','This will stop Ivy from producing an output HTML page for the node.','produce output HTML page for node',0,'',''),(7481,'Ivy','Sure. Ivy defaults to using the Markdown library to render .md files but you can register a custom handler to use any library you like.','use markdown library to render',0,'',''),(7482,'Ivy','Sure. Ivy defaults to using the Markdown library to render .md files but you can register a custom handler to use any library you like.','use library',0,'',''),(7483,'Ivy','Here\'s a simple demo of an Ivy site using the KaTeX JavaScript library to render LaTeX markup.','use KaTeX JavaScript library',0,'',''),(7484,'Ivy','Here\'s a simple demo of an Ivy site using the KaTeX JavaScript library to render LaTeX markup.','render LaTeX markup',0,'',''),(7485,'Ivy','Shortcodes are powerful — you can use them to inject content into a node\'s text or to customize the formatting of a block of content.','customize formatting of block',0,'',''),(7486,'Ivy','Shortcodes are implemented by the shortcodes package, an external library.\nAn Ivy extension can register a new shortcode tag using the shortcode package\'s @register() decorator:','implement shortcodes',1,'http://www.dmulholl.com/docs/ivy/main/shortcodes.html','registering-shortcodes'),(7487,'Ivy','Shortcodes are implemented by the shortcodes package, an external library.\nAn Ivy extension can register a new shortcode tag using the shortcode package\'s @register() decorator:','use  decorator',1,'http://www.dmulholl.com/docs/ivy/main/shortcodes.html','registering-shortcodes'),(7488,'Ivy','Positional and keyword arguments are passed as strings. The handler function itself should return a string which will replace the shortcode in the text.','pass positional keyword arguments as strings',0,'',''),(7489,'Ivy','Positional and keyword arguments are passed as strings. The handler function itself should return a string which will replace the shortcode in the text.','return string',0,'',''),(7490,'Ivy','Positional and keyword arguments are passed as strings. The handler function itself should return a string which will replace the shortcode in the text.','replace shortcode in text',0,'',''),(7491,'Ivy','Positional and keyword arguments are passed as strings. The handler function itself should return a string which will replace the shortcode in the text.','replace string in text',0,'',''),(7492,'Ivy','Note that shortcodes are processed before node text is rendered into HTML so any content injected by a shortcode should be compatible with the existing text\'s format (Markdown, Syntext, etc.).','render node text into HTML',0,'',''),(7493,'Ivy','Note that shortcodes are processed before node text is rendered into HTML so any content injected by a shortcode should be compatible with the existing text\'s format (Markdown, Syntext, etc.).','process shortcodes',0,'',''),(7494,'Ivy','Here\'s a sample shortcode you could use to inject the raw content of a file from the site\'s includes directory, inc, directly into a node file:','use sample shortcode',1,'http://www.dmulholl.com/docs/ivy/main/shortcodes.html','example-include-raw'),(7495,'Ivy','Here\'s a sample shortcode you could use to inject the raw content of a file from the site\'s includes directory, inc, directly into a node file:','include site',1,'http://www.dmulholl.com/docs/ivy/main/shortcodes.html','example-include-raw'),(7496,'Ivy','To use this shortcode, just supply the name of the file you want to include, e.g.','use shortcode e.g.',1,'http://www.dmulholl.com/docs/ivy/main/shortcodes.html','example-include-raw'),(7497,'Ivy','The shortcode will be replaced by the content of the file.','replace shortcode',0,'',''),(7498,'Ivy','Ivy already loads and renders the content of files from the includes directory to make it available in template files. What if you want to include this pre-rendered content in a node file?','include directory',1,'http://www.dmulholl.com/docs/ivy/main/shortcodes.html','example-include-rendered'),(7499,'Ivy','Ivy already loads and renders the content of files from the includes directory to make it available in template files. What if you want to include this pre-rendered content in a node file?','include pre-rendered content in node file',1,'http://www.dmulholl.com/docs/ivy/main/shortcodes.html','example-include-rendered'),(7500,'Ivy','To use this shortcode, just supply the name of the file you want to include, leaving off the file extension, e.g.','use shortcode',1,'http://www.dmulholl.com/docs/ivy/main/shortcodes.html','example-include-rendered'),(7501,'Ivy','The shortcode will be replaced by the rendered content of the file.','replace shortcode',0,'',''),(7502,'Ivy','To use this shortcode, just supply the @root/ url of the target node, e.g.','use shortcode',1,'http://www.dmulholl.com/docs/ivy/main/shortcodes.html','example-list-children'),(7503,'Ivy','The shortcode will be replaced by the list of links.','replace shortcode',0,'',''),(7504,'Ivy','Here\'s an example of a block-level shortcode wrapping a block of content. Imagine we want to add special styling to quotes with the name of the quote\'s author attached:','wrap block of content',1,'http://www.dmulholl.com/docs/ivy/main/shortcodes.html','example-quote'),(7505,'Ivy','Here\'s an example of a block-level shortcode wrapping a block of content. Imagine we want to add special styling to quotes with the name of the quote\'s author attached:','add special styling with name',1,'http://www.dmulholl.com/docs/ivy/main/shortcodes.html','example-quote'),(7506,'Ivy','Here\'s an example of a block-level shortcode wrapping a block of content. Imagine we want to add special styling to quotes with the name of the quote\'s author attached:','add special styling to quotes',1,'http://www.dmulholl.com/docs/ivy/main/shortcodes.html','example-quote'),(7507,'Ivy','We can use this shortcode in a source file by supplying the author\'s name as an argument:','use shortcode in source file',1,'http://www.dmulholl.com/docs/ivy/main/shortcodes.html','example-quote'),(7508,'Ivy','We can use this shortcode in a source file by supplying the author\'s name as an argument:','use shortcode by supplying',1,'http://www.dmulholl.com/docs/ivy/main/shortcodes.html','example-quote'),(7509,'Ivy','Install Ivy from the Python Package Index using pip:','use pip',1,'http://www.dmulholl.com/docs/ivy/main/index.html','installation'),(7510,'Ivy','Once Ivy is installed, create a new directory for your site and cd into it:','create new directory for site',1,'http://www.dmulholl.com/docs/ivy/main/quickstart.html',''),(7511,'Ivy','Once Ivy is installed, create a new directory for your site and cd into it:','create new directory for cd',1,'http://www.dmulholl.com/docs/ivy/main/quickstart.html',''),(7512,'Ivy','Once Ivy is installed, create a new directory for your site and cd into it:','install ivy',1,'http://www.dmulholl.com/docs/ivy/main/quickstart.html',''),(7513,'Ivy','Initialize the site directory using the init command:','initialize site directory',1,'http://www.dmulholl.com/docs/ivy/main/quickstart.html',''),(7514,'Ivy','Initialize the site directory using the init command:','use init command',1,'http://www.dmulholl.com/docs/ivy/main/quickstart.html',''),(7515,'Ivy','Ivy will create the following directory structure for your site:','create following directory structure for site',1,'http://www.dmulholl.com/docs/ivy/main/quickstart.html',''),(7516,'Ivy','Ivy initializes your src directory with a simple skeleton site which you can build immediately using the build command:','initialize src directory with simple skeleton site',1,'http://www.dmulholl.com/docs/ivy/main/quickstart.html',''),(7517,'Ivy','You can run the build command from the site directory itself or from any of its subdirectories. It tells Ivy to render the text files in the src directory into HTML and place the output in an out directory.','render text files into HTML',0,'',''),(7518,'Ivy','You can run the build command from the site directory itself or from any of its subdirectories. It tells Ivy to render the text files in the src directory into HTML and place the output in an out directory.','render text files in src directory',0,'',''),(7519,'Ivy','You can run the build command from the site directory itself or from any of its subdirectories. It tells Ivy to render the text files in the src directory into HTML and place the output in an out directory.','place output in out directory',0,'',''),(7520,'Ivy','Run the build command and take a look at the output. You can open the HTML files directly in your browser or use Ivy\'s builtin test server to serve the contents of the out directory:','open HTML files in browser',1,'http://www.dmulholl.com/docs/ivy/main/quickstart.html',''),(7521,'Ivy','Run the build command and take a look at the output. You can open the HTML files directly in your browser or use Ivy\'s builtin test server to serve the contents of the out directory:','use builtin test server',1,'http://www.dmulholl.com/docs/ivy/main/quickstart.html',''),(7522,'Ivy','Ivy will build the site using its default graphite theme, which you can find in the lib folder. Try rebuilding the site using the debug theme which is less pretty but provides a lot of useful information that can help you when building or customizing your own themes:','use default graphite theme',1,'http://www.dmulholl.com/docs/ivy/main/quickstart.html',''),(7523,'Ivy','Ivy will build the site using its default graphite theme, which you can find in the lib folder. Try rebuilding the site using the debug theme which is less pretty but provides a lot of useful information that can help you when building or customizing your own themes:','find  in lib folder',1,'http://www.dmulholl.com/docs/ivy/main/quickstart.html',''),(7524,'Ivy','Ivy will build the site using its default graphite theme, which you can find in the lib folder. Try rebuilding the site using the debug theme which is less pretty but provides a lot of useful information that can help you when building or customizing your own themes:','rebuild site',1,'http://www.dmulholl.com/docs/ivy/main/quickstart.html',''),(7525,'Ivy','Ivy will build the site using its default graphite theme, which you can find in the lib folder. Try rebuilding the site using the debug theme which is less pretty but provides a lot of useful information that can help you when building or customizing your own themes:','use debug theme',1,'http://www.dmulholl.com/docs/ivy/main/quickstart.html',''),(7526,'Ivy','Ivy will build the site using its default graphite theme, which you can find in the lib folder. Try rebuilding the site using the debug theme which is less pretty but provides a lot of useful information that can help you when building or customizing your own themes:','provide lot of useful information',1,'http://www.dmulholl.com/docs/ivy/main/quickstart.html',''),(7527,'Ivy','Ivy will build the site using its default graphite theme, which you can find in the lib folder. Try rebuilding the site using the debug theme which is less pretty but provides a lot of useful information that can help you when building or customizing your own themes:','provide debug theme of useful information',1,'http://www.dmulholl.com/docs/ivy/main/quickstart.html',''),(7528,'Ivy','You can run ivy --help to see a list of all the available commands. Note that you can get help for a specific command by running','run ivy',1,'http://www.dmulholl.com/docs/ivy/main/quickstart.html',''),(7529,'Ivy','You can run ivy --help to see a list of all the available commands. Note that you can get help for a specific command by running','get help by running',1,'http://www.dmulholl.com/docs/ivy/main/quickstart.html',''),(7530,'Ivy','You can run ivy --help to see a list of all the available commands. Note that you can get help for a specific command by running','get help for specific command',1,'http://www.dmulholl.com/docs/ivy/main/quickstart.html',''),(7531,'Ivy','replacing  with the command name.','replace  with command name',0,'',''),(7532,'Ivy','You can build many different kinds of website using Ivy but it\'s particularly suited to building project documentation like the documentation you\'re looking at right now.','use ivy',0,'',''),(7533,'Ivy','Ivy has builtin support for content written in Markdown, Syntext, or plain HTML, but Ivy itself is format-agnostic — you can write your content in any format with a suitable Python library.','write content in format',0,'',''),(7534,'Ivy','Ivy has builtin support for content written in Markdown, Syntext, or plain HTML, but Ivy itself is format-agnostic — you can write your content in any format with a suitable Python library.','write  in markdown',0,'',''),(7535,'Ivy','Ivy has builtin support for content written in Markdown, Syntext, or plain HTML, but Ivy itself is format-agnostic — you can write your content in any format with a suitable Python library.','write  in syntext',0,'',''),(7536,'Ivy','Ivy has builtin support for content written in Markdown, Syntext, or plain HTML, but Ivy itself is format-agnostic — you can write your content in any format with a suitable Python library.','write  in plain HTML',0,'',''),(7537,'Ivy','Similarly, Ivy has builtin support for Jinja and Ibis templates but can use any template language with a suitable Python library.','use template language with suitable Python library',0,'',''),(7538,'Ivy','This work has been placed in the public domain.','place work in public domain',0,'',''),(7539,'Ivy','Ivy borrows its idea of themes from WordPress where a theme is a directory of templates, styles, and scripts that together provide the look and feel for a site.','provide look',0,'',''),(7540,'Ivy','Ivy borrows its idea of themes from WordPress where a theme is a directory of templates, styles, and scripts that together provide the look and feel for a site.','provide scripts',0,'',''),(7541,'Ivy','This idea is central. You can swap between themes and completely change the appearance of your site without touching its content.','change appearance of site',0,'',''),(7542,'Ivy','This idea is central. You can swap between themes and completely change the appearance of your site without touching its content.','change appearance without touching',0,'',''),(7543,'Ivy','Themes should be placed in the site\'s lib directory, and the name of the active theme directory specified in the site\'s configuration file.','place themes in lib directory',1,'http://www.dmulholl.com/docs/ivy/main/themes.html','location'),(7544,'Ivy','Themes should be placed in the site\'s lib directory, and the name of the active theme directory specified in the site\'s configuration file.','specify  in configuration file',1,'http://www.dmulholl.com/docs/ivy/main/themes.html','location'),(7545,'Ivy','Ivy ships with a small collection of bundled themes including graphite, the default theme you\'re looking at right now, and debug, a diagnostic theme useful when designing themes or debugging sites.','design themes',0,'',''),(7546,'Ivy','Note that you can override the currently active theme with the build command\'s --theme flag:','override active theme with theme flag',1,'http://www.dmulholl.com/docs/ivy/main/themes.html','location'),(7547,'Ivy','Ivy searches for a named theme first in the site\'s theme library, then (if it exists) in the global theme library specified by the $IVY_THEMES environment variable. Finally it searches among the default themes bundled with Ivy itself.','specify  by $IVY_THEMES environment variable',0,'',''),(7548,'Ivy','Ivy searches for a named theme first in the site\'s theme library, then (if it exists) in the global theme library specified by the $IVY_THEMES environment variable. Finally it searches among the default themes bundled with Ivy itself.','specify  for ivy searches',0,'',''),(7549,'Ivy','Ivy searches for a named theme first in the site\'s theme library, then (if it exists) in the global theme library specified by the $IVY_THEMES environment variable. Finally it searches among the default themes bundled with Ivy itself.','search  among default themes',0,'',''),(7550,'Ivy','The content of the resources directory is copied to the output directory when the site is built.\nA theme should store its static assets in this directory, e.g. CSS, JavaScript, font, and image files.','store static assets in font',0,'',''),(7551,'Ivy','The content of the resources directory is copied to the output directory when the site is built.\nA theme should store its static assets in this directory, e.g. CSS, JavaScript, font, and image files.','store static assets in image files',0,'',''),(7552,'Ivy','The content of the resources directory is copied to the output directory when the site is built.\nA theme should store its static assets in this directory, e.g. CSS, JavaScript, font, and image files.','store static assets in directory',0,'',''),(7553,'Ivy','The content of the resources directory is copied to the output directory when the site is built.\nA theme should store its static assets in this directory, e.g. CSS, JavaScript, font, and image files.','store static assets in e.g. CSS',0,'',''),(7554,'Ivy','The content of the resources directory is copied to the output directory when the site is built.\nA theme should store its static assets in this directory, e.g. CSS, JavaScript, font, and image files.','store static assets in JavaScript',0,'',''),(7555,'Ivy','The templates directory is where Ivy looks for the theme\'s template files.\nThis directory is also where Jinja and Ibis will look for files included in templates using {% include %} tags.','use {% include %} tags',0,'',''),(7556,'Ivy','The templates directory is where Ivy looks for the theme\'s template files.\nThis directory is also where Jinja and Ibis will look for files included in templates using {% include %} tags.','include  in templates',0,'',''),(7557,'Ivy','Themes can bundle extensions for Ivy by placing Python modules or packages in the extensions directory.\nThese will be loaded automatically by Ivy.','place Python modules in extensions directory',0,'',''),(7558,'Ivy','Themes can bundle extensions for Ivy by placing Python modules or packages in the extensions directory.\nThese will be loaded automatically by Ivy.','place packages in extensions directory',0,'',''),(7559,'Ivy','There are countless templating languages and Ivy can use any of them, but it has builtin support for Jinja and Ibis. Ivy determines the language of a template file by looking at its extension — .jinja for Jinja and .ibis for Ibis.','determine language by looking',0,'',''),(7560,'Ivy','There are countless templating languages and Ivy can use any of them, but it has builtin support for Jinja and Ibis. Ivy determines the language of a template file by looking at its extension — .jinja for Jinja and .ibis for Ibis.','determine language of template file',0,'',''),(7561,'Ivy','You can add support for alternative templating languages via plugins.','add support for alternative templating languages',0,'',''),(7562,'Ivy','When Ivy generates a HTML page for a node it searches for the appropriate template file to use in reverse order of specificity (most specific first, least specific last).','generate HTML page for node',1,'http://www.dmulholl.com/docs/ivy/main/themes.html','template-hierarchy'),(7563,'Ivy','When Ivy generates a HTML page for a node it searches for the appropriate template file to use in reverse order of specificity (most specific first, least specific last).','search  for appropriate template file',1,'http://www.dmulholl.com/docs/ivy/main/themes.html','template-hierarchy'),(7564,'Ivy','Ivy will search for a template file for this node in the following order:','search  for template file',1,'http://www.dmulholl.com/docs/ivy/main/themes.html','template-hierarchy'),(7565,'Ivy','Ultimately, Ivy will always check for a template file called node.* — this is the default template name and the only template file actually required by a theme.','check  for template file',0,'',''),(7566,'Ivy','A node can override this process by specifying a custom template name in its header:','override process by specifying',1,'http://www.dmulholl.com/docs/ivy/main/themes.html','template-hierarchy'),(7567,'Ivy','A node can override this process by specifying a custom template name in its header:','specify custom template name in header',1,'http://www.dmulholl.com/docs/ivy/main/themes.html','template-hierarchy'),(7568,'Ivy','Note that the file extension should be omitted from the template name.','omit file extension from template name',0,'',''),(7569,'Ivy','All of Ivy\'s code has been placed in the public domain and is free for personal and commercial use. No attribution is required.','place  in public domain',1,'http://www.dmulholl.com/docs/ivy/main/license.html','ivy'),(7570,'Ivy','All other theme code has been placed in the public domain.','place other theme code in public domain',0,'',''),(7571,'PyOpenGL','The râison d\'ętre (apologies for my rusty French) for OpenGLContext\n        is to\n        provide a platform for testing and sample code, so you\'ll find a lot of\n        it lurking about in the project. In particular, in the source-code\n        release, you can find\n        sample code for:','provide platform for testing sample code',0,'',''),(7572,'PyOpenGL','The râison d\'ętre (apologies for my rusty French) for OpenGLContext\n        is to\n        provide a platform for testing and sample code, so you\'ll find a lot of\n        it lurking about in the project. In particular, in the source-code\n        release, you can find\n        sample code for:','find lot',0,'',''),(7573,'PyOpenGL','The râison d\'ętre (apologies for my rusty French) for OpenGLContext\n        is to\n        provide a platform for testing and sample code, so you\'ll find a lot of\n        it lurking about in the project. In particular, in the source-code\n        release, you can find\n        sample code for:','find sample code in source-code release',0,'',''),(7574,'PyOpenGL','OpenGL under Python is largely the same as OpenGL under most\nother languages, so you can use much of             the documentation\nyou\'ll find around the Internet, or in your local bookstore.  This\npage primarily provides links to PyOpenGL-specific documentation.\n Users of OpenGLContext should also see the OpenGLContext\ndocumentation page.','find documentation in local bookstore',0,'',''),(7575,'PyOpenGL','OpenGL under Python is largely the same as OpenGL under most\nother languages, so you can use much of             the documentation\nyou\'ll find around the Internet, or in your local bookstore.  This\npage primarily provides links to PyOpenGL-specific documentation.\n Users of OpenGLContext should also see the OpenGLContext\ndocumentation page.','find documentation around internet',0,'',''),(7576,'PyOpenGL','OpenGL under Python is largely the same as OpenGL under most\nother languages, so you can use much of             the documentation\nyou\'ll find around the Internet, or in your local bookstore.  This\npage primarily provides links to PyOpenGL-specific documentation.\n Users of OpenGLContext should also see the OpenGLContext\ndocumentation page.','provide links to pyopengl-specific documentation',0,'',''),(7577,'PyOpenGL','There\nare a large number of very good books on OpenGL available. Many\nof these books cover \"legacy\" OpenGL, rather than the\nshader/buffer/texture model of OpenGL 3.0. Still, they provide a\ngood grounding that allows you to learn the basics of OpenGL.','provide good grounding',0,'',''),(7578,'PyOpenGL','There\nare a large number of very good books on OpenGL available. Many\nof these books cover \"legacy\" OpenGL, rather than the\nshader/buffer/texture model of OpenGL 3.0. Still, they provide a\ngood grounding that allows you to learn the basics of OpenGL.','learn basics of OpenGL',0,'',''),(7579,'PyOpenGL','Older versions of the official OpenGL Programming Guide, a.k.a\n\"The Red Book\" are available online in various\nplaces (version 2.0 covers OpenGL 1.1). If you are serious about\nlearning OpenGL, the newer versions of the Red Book, (v3.0) is likely on\nthe shelves of your local bookstore, and is quite readable.','learn OpenGL',0,'',''),(7580,'PyOpenGL','You\'ll find versions of some of the Red Book tutorial code for\nPython included in the PyOpenGL-Demo/redbook directory of the PyOpenGL-Demo\ndistribution. These versions are very close to the original source\ncode. The OpenGLContext tests directory also has four of the\ntutorials converted, \"alpha\", \"alpha3D\", \"surface\" and \"trim\".','find versions for Python',0,'',''),(7581,'PyOpenGL','You\'ll find versions of some of the Red Book tutorial code for\nPython included in the PyOpenGL-Demo/redbook directory of the PyOpenGL-Demo\ndistribution. These versions are very close to the original source\ncode. The OpenGLContext tests directory also has four of the\ntutorials converted, \"alpha\", \"alpha3D\", \"surface\" and \"trim\".','include  in pyopengl-demo/redbook directory',0,'',''),(7582,'PyOpenGL','This\nbook serves as a good introduction to shaders. The shaders\ndescribed cover the gamut from the simplest 1-line shaders through code\nto emulate legacy operation to non-realistic shading to caustics and\nthe like. You will generally have to adapt any code you take from\nhere to work with your real-world scenes, but the book offers a strong\ngrounding.','offer strong grounding',0,'',''),(7583,'PyOpenGL','When people think of an \"OpenGL tutorial\", many will\nimmediately think of the NeHe tutorials by Jeff Molofee, available at http://nehe.gamedev.net/\nthese\ntutorials range from the very simple (create an OpenGL window) through\nthe advanced (particle systems, loading scenes from various formats,\ndisplaying video textures, text, morphing, multi-texturing). The\nolder tutorials tend to be legacy-mode operations, so you should keep\nin mind that they are describing old ways of working as you learn with\nthem.','describe old ways of working',0,'',''),(7584,'PyOpenGL','If you have a PyOpenGL-specific tutorial you\'d like added to this area, please post to the PyOpenGL-user\'s mailing list.','add  to area',0,'',''),(7585,'PyOpenGL','Bug reports and feature requests should use the SourceForge project\npage. General questions, including most programming questions\nare best answered on the PyOpenGL mailing list.\nQuestions regarding project administration, or development can use the PyOpenGL-devel\nmailing list.','use SourceForge project page',0,'',''),(7586,'PyOpenGL','Bug reports and feature requests should use the SourceForge project\npage. General questions, including most programming questions\nare best answered on the PyOpenGL mailing list.\nQuestions regarding project administration, or development can use the PyOpenGL-devel\nmailing list.','use pyopengl-devel mailing list',0,'',''),(7587,'rcdesign','Search Page','search Page',0,'',''),(7588,'rcdesign','Create a separate directory and install a virtual environment. Activate the virtual environment and install required packages. On *nix systems, do the following:','create separate directory',1,'https://rcdesign.readthedocs.io/en/latest/installation.html',''),(7589,'rcdesign','Create a separate directory and install a virtual environment. Activate the virtual environment and install required packages. On *nix systems, do the following:','install virtual environment',1,'https://rcdesign.readthedocs.io/en/latest/installation.html',''),(7590,'rcdesign','Create a separate directory and install a virtual environment. Activate the virtual environment and install required packages. On *nix systems, do the following:','activate virtual environment',1,'https://rcdesign.readthedocs.io/en/latest/installation.html',''),(7591,'rcdesign','Create a separate directory and install a virtual environment. Activate the virtual environment and install required packages. On *nix systems, do the following:','install required packages',1,'https://rcdesign.readthedocs.io/en/latest/installation.html',''),(7592,'rcdesign','To install from github, you can clone the github repository and give it a try. If you are not familiar with the workflow for working with a source repository, you can follow the steps below.','clone github repository',0,'',''),(7593,'rcdesign','To install from github, you can clone the github repository and give it a try. If you are not familiar with the workflow for working with a source repository, you can follow the steps below.','install  from github',0,'',''),(7594,'rcdesign','Check the version of Python you are using. You will require version 3.7 or later. To print the version of Python, use the command','check version of Python',1,'https://rcdesign.readthedocs.io/en/latest/installation.html',''),(7595,'rcdesign','Check the version of Python you are using. You will require version 3.7 or later. To print the version of Python, use the command','print version of Python',1,'https://rcdesign.readthedocs.io/en/latest/installation.html',''),(7596,'rcdesign','Check the version of Python you are using. You will require version 3.7 or later. To print the version of Python, use the command','use command',1,'https://rcdesign.readthedocs.io/en/latest/installation.html',''),(7597,'rcdesign','When you clone the rcdesign repository from github, a new directory named rcdesign will be created in the current working directory. Therefore change over to the a suitable directory which will become the parent directory of the clone. Clone the repository using git','clone rcdesign repository from github',1,'https://rcdesign.readthedocs.io/en/latest/installation.html',''),(7598,'rcdesign','When you clone the rcdesign repository from github, a new directory named rcdesign will be created in the current working directory. Therefore change over to the a suitable directory which will become the parent directory of the clone. Clone the repository using git','create rcdesign in current working directory',1,'https://rcdesign.readthedocs.io/en/latest/installation.html',''),(7599,'rcdesign','When you clone the rcdesign repository from github, a new directory named rcdesign will be created in the current working directory. Therefore change over to the a suitable directory which will become the parent directory of the clone. Clone the repository using git','clone repository',1,'https://rcdesign.readthedocs.io/en/latest/installation.html',''),(7600,'rcdesign','When you clone the rcdesign repository from github, a new directory named rcdesign will be created in the current working directory. Therefore change over to the a suitable directory which will become the parent directory of the clone. Clone the repository using git','use git',1,'https://rcdesign.readthedocs.io/en/latest/installation.html',''),(7601,'rcdesign','Change over to the directory rcdesign that is created with the command','create directory rcdesign with command',1,'https://rcdesign.readthedocs.io/en/latest/installation.html',''),(7602,'rcdesign','List the directory contents and verify the directory structure.','list directory contents',0,'',''),(7603,'rcdesign','Create a virtual environment inside the rcdesign directory with the following command','create virtual environment inside rcdesign directory',1,'https://rcdesign.readthedocs.io/en/latest/installation.html',''),(7604,'rcdesign','Activate the virtual environment with the command','activate virtual environment with command',1,'https://rcdesign.readthedocs.io/en/latest/installation.html',''),(7605,'rcdesign','If you are using Windows operating system, the command is','use Windows operating system',1,'https://rcdesign.readthedocs.io/en/latest/installation.html',''),(7606,'rcdesign','Install additional packages required to run tests.','run tests',1,'https://rcdesign.readthedocs.io/en/latest/installation.html',''),(7607,'rcdesign','Check code coverage.','check code coverage',0,'',''),(7608,'rcdesign','You can also use nox to run the tests.','use nox',1,'https://rcdesign.readthedocs.io/en/latest/installation.html',''),(7609,'rcdesign','You can also use nox to run the tests.','run tests',1,'https://rcdesign.readthedocs.io/en/latest/installation.html',''),(7610,'rcdesign','When you are done using the virtual environment, you can deactivate with the command deactivate at the command prompt in all operating systems.','use virtual environment',0,'',''),(7611,'rcdesign','When you are done using the virtual environment, you can deactivate with the command deactivate at the command prompt in all operating systems.','deactivate  with command deactivate',0,'',''),(7612,'rcdesign','When you are done using the virtual environment, you can deactivate with the command deactivate at the command prompt in all operating systems.','deactivate  at command prompt',0,'',''),(7613,'rcdesign','Install rcdesign from PyPI using pip as explained in Installation. Verify that installation is successful, by running the example problem:','use pip',1,'https://rcdesign.readthedocs.io/en/latest/tutorial.html',''),(7614,'rcdesign','Install rcdesign from PyPI using pip as explained in Installation. Verify that installation is successful, by running the example problem:','run example problem',1,'https://rcdesign.readthedocs.io/en/latest/tutorial.html',''),(7615,'rcdesign','Let us determine the Limit State capacity of the section in bending and shear.','determine Limit state capacity of section',1,'https://rcdesign.readthedocs.io/en/latest/tutorial.html',''),(7616,'rcdesign','Run the script from the command line:','run script from command line',1,'https://rcdesign.readthedocs.io/en/latest/tutorial.html',''),(7617,'PyOpenGL','The râison d\'ętre (apologies for my rusty French) for OpenGLContext\n        is to\n        provide a platform for testing and sample code, so you\'ll find a lot of\n        it lurking about in the project. In particular, in the source-code\n        release, you can find\n        sample code for:','provide platform for testing sample code',0,'',''),(7618,'PyOpenGL','The râison d\'ętre (apologies for my rusty French) for OpenGLContext\n        is to\n        provide a platform for testing and sample code, so you\'ll find a lot of\n        it lurking about in the project. In particular, in the source-code\n        release, you can find\n        sample code for:','find lot',0,'',''),(7619,'PyOpenGL','The râison d\'ętre (apologies for my rusty French) for OpenGLContext\n        is to\n        provide a platform for testing and sample code, so you\'ll find a lot of\n        it lurking about in the project. In particular, in the source-code\n        release, you can find\n        sample code for:','find sample code in source-code release',0,'',''),(7620,'PyOpenGL','OpenGL under Python is largely the same as OpenGL under most\nother languages, so you can use much of             the documentation\nyou\'ll find around the Internet, or in your local bookstore.  This\npage primarily provides links to PyOpenGL-specific documentation.\n Users of OpenGLContext should also see the OpenGLContext\ndocumentation page.','find documentation in local bookstore',0,'',''),(7621,'PyOpenGL','OpenGL under Python is largely the same as OpenGL under most\nother languages, so you can use much of             the documentation\nyou\'ll find around the Internet, or in your local bookstore.  This\npage primarily provides links to PyOpenGL-specific documentation.\n Users of OpenGLContext should also see the OpenGLContext\ndocumentation page.','find documentation around internet',0,'',''),(7622,'PyOpenGL','OpenGL under Python is largely the same as OpenGL under most\nother languages, so you can use much of             the documentation\nyou\'ll find around the Internet, or in your local bookstore.  This\npage primarily provides links to PyOpenGL-specific documentation.\n Users of OpenGLContext should also see the OpenGLContext\ndocumentation page.','provide links to pyopengl-specific documentation',0,'',''),(7623,'PyOpenGL','There\nare a large number of very good books on OpenGL available. Many\nof these books cover \"legacy\" OpenGL, rather than the\nshader/buffer/texture model of OpenGL 3.0. Still, they provide a\ngood grounding that allows you to learn the basics of OpenGL.','provide good grounding',0,'',''),(7624,'PyOpenGL','There\nare a large number of very good books on OpenGL available. Many\nof these books cover \"legacy\" OpenGL, rather than the\nshader/buffer/texture model of OpenGL 3.0. Still, they provide a\ngood grounding that allows you to learn the basics of OpenGL.','learn basics of OpenGL',0,'',''),(7625,'PyOpenGL','Older versions of the official OpenGL Programming Guide, a.k.a\n\"The Red Book\" are available online in various\nplaces (version 2.0 covers OpenGL 1.1). If you are serious about\nlearning OpenGL, the newer versions of the Red Book, (v3.0) is likely on\nthe shelves of your local bookstore, and is quite readable.','learn OpenGL',0,'',''),(7626,'PyOpenGL','You\'ll find versions of some of the Red Book tutorial code for\nPython included in the PyOpenGL-Demo/redbook directory of the PyOpenGL-Demo\ndistribution. These versions are very close to the original source\ncode. The OpenGLContext tests directory also has four of the\ntutorials converted, \"alpha\", \"alpha3D\", \"surface\" and \"trim\".','find versions for Python',0,'',''),(7627,'PyOpenGL','You\'ll find versions of some of the Red Book tutorial code for\nPython included in the PyOpenGL-Demo/redbook directory of the PyOpenGL-Demo\ndistribution. These versions are very close to the original source\ncode. The OpenGLContext tests directory also has four of the\ntutorials converted, \"alpha\", \"alpha3D\", \"surface\" and \"trim\".','include  in pyopengl-demo/redbook directory',0,'',''),(7628,'PyOpenGL','This\nbook serves as a good introduction to shaders. The shaders\ndescribed cover the gamut from the simplest 1-line shaders through code\nto emulate legacy operation to non-realistic shading to caustics and\nthe like. You will generally have to adapt any code you take from\nhere to work with your real-world scenes, but the book offers a strong\ngrounding.','offer strong grounding',0,'',''),(7629,'PyOpenGL','When people think of an \"OpenGL tutorial\", many will\nimmediately think of the NeHe tutorials by Jeff Molofee, available at http://nehe.gamedev.net/\nthese\ntutorials range from the very simple (create an OpenGL window) through\nthe advanced (particle systems, loading scenes from various formats,\ndisplaying video textures, text, morphing, multi-texturing). The\nolder tutorials tend to be legacy-mode operations, so you should keep\nin mind that they are describing old ways of working as you learn with\nthem.','describe old ways of working',0,'',''),(7630,'PyOpenGL','If you have a PyOpenGL-specific tutorial you\'d like added to this area, please post to the PyOpenGL-user\'s mailing list.','add  to area',0,'',''),(7631,'PyOpenGL','Bug reports and feature requests should use the SourceForge project\npage. General questions, including most programming questions\nare best answered on the PyOpenGL mailing list.\nQuestions regarding project administration, or development can use the PyOpenGL-devel\nmailing list.','use SourceForge project page',0,'',''),(7632,'PyOpenGL','Bug reports and feature requests should use the SourceForge project\npage. General questions, including most programming questions\nare best answered on the PyOpenGL mailing list.\nQuestions regarding project administration, or development can use the PyOpenGL-devel\nmailing list.','use pyopengl-devel mailing list',0,'',''),(7633,'PyOpenGL','The râison d\'ętre (apologies for my rusty French) for OpenGLContext\n        is to\n        provide a platform for testing and sample code, so you\'ll find a lot of\n        it lurking about in the project. In particular, in the source-code\n        release, you can find\n        sample code for:','provide platform for testing sample code',0,'',''),(7634,'PyOpenGL','The râison d\'ętre (apologies for my rusty French) for OpenGLContext\n        is to\n        provide a platform for testing and sample code, so you\'ll find a lot of\n        it lurking about in the project. In particular, in the source-code\n        release, you can find\n        sample code for:','find lot',0,'',''),(7635,'PyOpenGL','The râison d\'ętre (apologies for my rusty French) for OpenGLContext\n        is to\n        provide a platform for testing and sample code, so you\'ll find a lot of\n        it lurking about in the project. In particular, in the source-code\n        release, you can find\n        sample code for:','find sample code in source-code release',0,'',''),(7636,'PyOpenGL','OpenGL under Python is largely the same as OpenGL under most\nother languages, so you can use much of             the documentation\nyou\'ll find around the Internet, or in your local bookstore.  This\npage primarily provides links to PyOpenGL-specific documentation.\n Users of OpenGLContext should also see the OpenGLContext\ndocumentation page.','find documentation in local bookstore',0,'',''),(7637,'PyOpenGL','OpenGL under Python is largely the same as OpenGL under most\nother languages, so you can use much of             the documentation\nyou\'ll find around the Internet, or in your local bookstore.  This\npage primarily provides links to PyOpenGL-specific documentation.\n Users of OpenGLContext should also see the OpenGLContext\ndocumentation page.','find documentation around internet',0,'',''),(7638,'PyOpenGL','OpenGL under Python is largely the same as OpenGL under most\nother languages, so you can use much of             the documentation\nyou\'ll find around the Internet, or in your local bookstore.  This\npage primarily provides links to PyOpenGL-specific documentation.\n Users of OpenGLContext should also see the OpenGLContext\ndocumentation page.','provide links to pyopengl-specific documentation',0,'',''),(7639,'PyOpenGL','There\nare a large number of very good books on OpenGL available. Many\nof these books cover \"legacy\" OpenGL, rather than the\nshader/buffer/texture model of OpenGL 3.0. Still, they provide a\ngood grounding that allows you to learn the basics of OpenGL.','provide good grounding',0,'',''),(7640,'PyOpenGL','There\nare a large number of very good books on OpenGL available. Many\nof these books cover \"legacy\" OpenGL, rather than the\nshader/buffer/texture model of OpenGL 3.0. Still, they provide a\ngood grounding that allows you to learn the basics of OpenGL.','learn basics of OpenGL',0,'',''),(7641,'PyOpenGL','Older versions of the official OpenGL Programming Guide, a.k.a\n\"The Red Book\" are available online in various\nplaces (version 2.0 covers OpenGL 1.1). If you are serious about\nlearning OpenGL, the newer versions of the Red Book, (v3.0) is likely on\nthe shelves of your local bookstore, and is quite readable.','learn OpenGL',0,'',''),(7642,'PyOpenGL','You\'ll find versions of some of the Red Book tutorial code for\nPython included in the PyOpenGL-Demo/redbook directory of the PyOpenGL-Demo\ndistribution. These versions are very close to the original source\ncode. The OpenGLContext tests directory also has four of the\ntutorials converted, \"alpha\", \"alpha3D\", \"surface\" and \"trim\".','find versions for Python',0,'',''),(7643,'PyOpenGL','You\'ll find versions of some of the Red Book tutorial code for\nPython included in the PyOpenGL-Demo/redbook directory of the PyOpenGL-Demo\ndistribution. These versions are very close to the original source\ncode. The OpenGLContext tests directory also has four of the\ntutorials converted, \"alpha\", \"alpha3D\", \"surface\" and \"trim\".','include  in pyopengl-demo/redbook directory',0,'',''),(7644,'PyOpenGL','This\nbook serves as a good introduction to shaders. The shaders\ndescribed cover the gamut from the simplest 1-line shaders through code\nto emulate legacy operation to non-realistic shading to caustics and\nthe like. You will generally have to adapt any code you take from\nhere to work with your real-world scenes, but the book offers a strong\ngrounding.','offer strong grounding',0,'',''),(7645,'PyOpenGL','When people think of an \"OpenGL tutorial\", many will\nimmediately think of the NeHe tutorials by Jeff Molofee, available at http://nehe.gamedev.net/\nthese\ntutorials range from the very simple (create an OpenGL window) through\nthe advanced (particle systems, loading scenes from various formats,\ndisplaying video textures, text, morphing, multi-texturing). The\nolder tutorials tend to be legacy-mode operations, so you should keep\nin mind that they are describing old ways of working as you learn with\nthem.','describe old ways of working',0,'',''),(7646,'PyOpenGL','If you have a PyOpenGL-specific tutorial you\'d like added to this area, please post to the PyOpenGL-user\'s mailing list.','add  to area',0,'',''),(7647,'PyOpenGL','Bug reports and feature requests should use the SourceForge project\npage. General questions, including most programming questions\nare best answered on the PyOpenGL mailing list.\nQuestions regarding project administration, or development can use the PyOpenGL-devel\nmailing list.','use SourceForge project page',0,'',''),(7648,'PyOpenGL','Bug reports and feature requests should use the SourceForge project\npage. General questions, including most programming questions\nare best answered on the PyOpenGL mailing list.\nQuestions regarding project administration, or development can use the PyOpenGL-devel\nmailing list.','use pyopengl-devel mailing list',0,'',''),(7649,'twilio','Send and receive text messages','send text messages',0,'',''),(7650,'twilio','Send and receive text messages','receive text messages',0,'',''),(7651,'twilio','Create omnichannel campaigns with a unified, data-first platform','create omnichannel campaigns with unified data-first platform',0,'',''),(7652,'twilio','Create and manage email marketing campaigns','create email marketing campaigns',0,'',''),(7653,'twilio','Create and manage email marketing campaigns','manage email marketing campaigns',0,'',''),(7654,'twilio','Access local, national, and toll-free phone numbers','access toll-free phone numbers',0,'',''),(7655,'twilio','Browse our content library for more resources on how you can create lasting customer relationships','create lasting customer relationships',0,'',''),(7656,'twilio','Prepare for the new A2P 10DLC requirements','prepare  for new a2p 10DLC requirements',0,'',''),(7657,'twilio','Read tutorials, community projects, and product updates','read tutorials',0,'',''),(7658,'twilio','Read tutorials, community projects, and product updates','read community projects',0,'',''),(7659,'twilio','Read tutorials, community projects, and product updates','read product updates',0,'',''),(7660,'twilio','Ask the Twilio community for help','ask Twilio community for help',0,'',''),(7661,'twilio','Check real-time monitoring of APIs and all services','check real-time monitoring of apis',0,'',''),(7662,'twilio','Check real-time monitoring of APIs and all services','check real-time monitoring of services',0,'',''),(7663,'twilio','Get technical and strategic advice from Twilio experts','get technical strategic advice from Twilio experts',0,'',''),(7664,'twilio','Create the exact solution you need to engage customers at every step of their journey. Twilio Customer Engagement Platform combines flexible APIs for any digital channel, first-party customer data, and global infrastructure to support you at scale.','create exact solution',0,'',''),(7665,'twilio','Create the exact solution you need to engage customers at every step of their journey. Twilio Customer Engagement Platform combines flexible APIs for any digital channel, first-party customer data, and global infrastructure to support you at scale.','combine flexible apis for global infrastructure',0,'',''),(7666,'twilio','Create the exact solution you need to engage customers at every step of their journey. Twilio Customer Engagement Platform combines flexible APIs for any digital channel, first-party customer data, and global infrastructure to support you at scale.','combine flexible apis for digital channel',0,'',''),(7667,'twilio','Create the exact solution you need to engage customers at every step of their journey. Twilio Customer Engagement Platform combines flexible APIs for any digital channel, first-party customer data, and global infrastructure to support you at scale.','combine flexible apis for first-party customer data',0,'',''),(7668,'twilio','Create the exact solution you need to engage customers at every step of their journey. Twilio Customer Engagement Platform combines flexible APIs for any digital channel, first-party customer data, and global infrastructure to support you at scale.','support  at scale',0,'',''),(7669,'twilio','Connect with customers on their preferred channels—anywhere in the world. Quickly integrate powerful APIs to start building solutions for SMS and WhatsApp messaging, voice, video, and email.','integrate video',0,'',''),(7670,'twilio','Connect with customers on their preferred channels—anywhere in the world. Quickly integrate powerful APIs to start building solutions for SMS and WhatsApp messaging, voice, video, and email.','integrate powerful apis',0,'',''),(7671,'twilio','Connect with customers on their preferred channels—anywhere in the world. Quickly integrate powerful APIs to start building solutions for SMS and WhatsApp messaging, voice, video, and email.','integrate email',0,'',''),(7672,'twilio','Connect with customers on their preferred channels—anywhere in the world. Quickly integrate powerful APIs to start building solutions for SMS and WhatsApp messaging, voice, video, and email.','integrate voice',0,'',''),(7673,'twilio','Provide service so convenient and proactive, your customers will think you can read minds. Contextual data, flexible workflows, and seamless cross-channel communications empower your teams to engage people in powerful new ways.','read minds',0,'',''),(7674,'twilio','Retail giant Marks & Spencer uses Twilio to deliver the same quality of customer service you’d find in a store, over the phone. Using Twilio, they deliver personalized support, powering over $10M in new sales.','use Twilio',0,'',''),(7675,'twilio','Retail giant Marks & Spencer uses Twilio to deliver the same quality of customer service you’d find in a store, over the phone. Using Twilio, they deliver personalized support, powering over $10M in new sales.','find  over phone',0,'',''),(7676,'twilio','Retail giant Marks & Spencer uses Twilio to deliver the same quality of customer service you’d find in a store, over the phone. Using Twilio, they deliver personalized support, powering over $10M in new sales.','find  in store',0,'',''),(7677,'twilio','Retail giant Marks & Spencer uses Twilio to deliver the same quality of customer service you’d find in a store, over the phone. Using Twilio, they deliver personalized support, powering over $10M in new sales.','use twilio',0,'',''),(7678,'twilio','With SMS marketing, you can reach thousands or millions of your recipients with the right message, on the right channel, at the right time.','reach thousands with right message',0,'',''),(7679,'twilio','With SMS marketing, you can reach thousands or millions of your recipients with the right message, on the right channel, at the right time.','reach thousands with SMS marketing',0,'',''),(7680,'twilio','With SMS marketing, you can reach thousands or millions of your recipients with the right message, on the right channel, at the right time.','reach thousands at right time',0,'',''),(7681,'twilio','With SMS marketing, you can reach thousands or millions of your recipients with the right message, on the right channel, at the right time.','reach thousands of recipients',0,'',''),(7682,'twilio','With SMS marketing, you can reach thousands or millions of your recipients with the right message, on the right channel, at the right time.','reach thousands on right channel',0,'',''),(7683,'twilio','With SMS marketing, you can reach thousands or millions of your recipients with the right message, on the right channel, at the right time.','reach millions with right message',0,'',''),(7684,'twilio','With SMS marketing, you can reach thousands or millions of your recipients with the right message, on the right channel, at the right time.','reach millions with SMS marketing',0,'',''),(7685,'twilio','With SMS marketing, you can reach thousands or millions of your recipients with the right message, on the right channel, at the right time.','reach millions at right time',0,'',''),(7686,'twilio','With SMS marketing, you can reach thousands or millions of your recipients with the right message, on the right channel, at the right time.','reach millions of recipients',0,'',''),(7687,'twilio','With SMS marketing, you can reach thousands or millions of your recipients with the right message, on the right channel, at the right time.','reach millions on right channel',0,'',''),(7688,'Meyda','Meyda is a Javascript Library that can listen to audio and output a selection of\nstatistics that describe it. Meyda has a variety of different applications, and\nenvironments it can be used in. Lets take a look at some.','describe statistics',0,'',''),(7689,'Meyda','You can get audio analysis of','get audio analysis',0,'',''),(7690,'Meyda','You can use these analyses in','use analyses',0,'',''),(7691,'Meyda','Meyda can calculate a wide variety of standard audio features, including\nloudness, spectral characteristics like brightness (spectral centroid) and\nnoisiness (flatness) and much more. For a full list and explanation of the audio\nfeatures Meyda supports, please see our audio feature reference document.','calculate wide variety including spectral characteristics',0,'',''),(7692,'Meyda','Meyda can calculate a wide variety of standard audio features, including\nloudness, spectral characteristics like brightness (spectral centroid) and\nnoisiness (flatness) and much more. For a full list and explanation of the audio\nfeatures Meyda supports, please see our audio feature reference document.','calculate wide variety including loudness',0,'',''),(7693,'Meyda','Meyda can calculate a wide variety of standard audio features, including\nloudness, spectral characteristics like brightness (spectral centroid) and\nnoisiness (flatness) and much more. For a full list and explanation of the audio\nfeatures Meyda supports, please see our audio feature reference document.','calculate wide variety of standard audio features',0,'',''),(7694,'Meyda','To install Meyda in a modern frontend project, use npm:','install Meyda in modern frontend project',0,'',''),(7695,'Meyda','npm install --save meyda','save meyda',0,'',''),(7696,'Meyda','For web use cases, Meyda bundles a browserified copy of itself that exposes a\nMeyda object on the window object. This can be used in situations where npm\nis not in use, and you need to include a html link to your dependency, like the\njQuery days. To add Meyda to your web page, you can load it via unpkg as\nfollows:','expose meyda object on window object',1,'https://meyda.js.org//getting-started','installation'),(7697,'Meyda','For web use cases, Meyda bundles a browserified copy of itself that exposes a\nMeyda object on the window object. This can be used in situations where npm\nis not in use, and you need to include a html link to your dependency, like the\njQuery days. To add Meyda to your web page, you can load it via unpkg as\nfollows:','expose browserified copy on window object',1,'https://meyda.js.org//getting-started','installation'),(7698,'Meyda','For web use cases, Meyda bundles a browserified copy of itself that exposes a\nMeyda object on the window object. This can be used in situations where npm\nis not in use, and you need to include a html link to your dependency, like the\njQuery days. To add Meyda to your web page, you can load it via unpkg as\nfollows:','include html link like jQuery days',1,'https://meyda.js.org//getting-started','installation'),(7699,'Meyda','For web use cases, Meyda bundles a browserified copy of itself that exposes a\nMeyda object on the window object. This can be used in situations where npm\nis not in use, and you need to include a html link to your dependency, like the\njQuery days. To add Meyda to your web page, you can load it via unpkg as\nfollows:','include html link to dependency',1,'https://meyda.js.org//getting-started','installation'),(7700,'Meyda','For web use cases, Meyda bundles a browserified copy of itself that exposes a\nMeyda object on the window object. This can be used in situations where npm\nis not in use, and you need to include a html link to your dependency, like the\njQuery days. To add Meyda to your web page, you can load it via unpkg as\nfollows:','use  in situations',1,'https://meyda.js.org//getting-started','installation'),(7701,'Meyda','For web use cases, Meyda bundles a browserified copy of itself that exposes a\nMeyda object on the window object. This can be used in situations where npm\nis not in use, and you need to include a html link to your dependency, like the\njQuery days. To add Meyda to your web page, you can load it via unpkg as\nfollows:','add Meyda to web page',1,'https://meyda.js.org//getting-started','installation'),(7702,'Meyda','For web use cases, Meyda bundles a browserified copy of itself that exposes a\nMeyda object on the window object. This can be used in situations where npm\nis not in use, and you need to include a html link to your dependency, like the\njQuery days. To add Meyda to your web page, you can load it via unpkg as\nfollows:','load  via unpkg',1,'https://meyda.js.org//getting-started','installation'),(7703,'Meyda','Here’s a list of examples of projects that use Meyda. Would you like your Meyda project to be featured in our user showcase? Please let us know!','use meyda',0,'',''),(7704,'Meyda','Here’s a list of examples of projects that use Meyda. Would you like your Meyda project to be featured in our user showcase? Please let us know!','use projects',0,'',''),(7705,'Meyda','A computer generated melody project, optionally users can plug-in their guitar and/or MIDI key controller to dictate input harmonic. Meyda.js is being used to extract audio signal features, such as beat dynamic and music segmentation in order to help OSEM to produce high-quality music melody. It is meant to answer the question: “Given an arbitrary backing track (format: wav, mp3) can computer compose?”','generate melody project',0,'',''),(7706,'Meyda','A computer generated melody project, optionally users can plug-in their guitar and/or MIDI key controller to dictate input harmonic. Meyda.js is being used to extract audio signal features, such as beat dynamic and music segmentation in order to help OSEM to produce high-quality music melody. It is meant to answer the question: “Given an arbitrary backing track (format: wav, mp3) can computer compose?”','produce high-quality music',0,'',''),(7707,'Meyda','A computer generated melody project, optionally users can plug-in their guitar and/or MIDI key controller to dictate input harmonic. Meyda.js is being used to extract audio signal features, such as beat dynamic and music segmentation in order to help OSEM to produce high-quality music melody. It is meant to answer the question: “Given an arbitrary backing track (format: wav, mp3) can computer compose?”','use Meyda.js',0,'',''),(7708,'Meyda','Picognizer is the 100% JavaScript library for detecting synthesized sounds (e.g. sound effects of video games, replayed speech or music, and sound alerts of home appliances). You can run it on your web browser without any server-side systems.','run  without server-side systems',0,'',''),(7709,'Meyda','Picognizer is the 100% JavaScript library for detecting synthesized sounds (e.g. sound effects of video games, replayed speech or music, and sound alerts of home appliances). You can run it on your web browser without any server-side systems.','run  on web browser',0,'',''),(7710,'Meyda','A system that allows web users to generate their unique logos using their voices','generate unique logos',0,'',''),(7711,'Meyda','A system that allows web users to generate their unique logos using their voices','use voices',0,'',''),(7712,'Meyda','The Fluid Corpus Manipulation project(FluCoMa)instigates new musical ways of exploiting ever-growing banks of sound and gestures within the digital composition process, by bringing breakthroughs of signal decomposition DSP and machine learning to the toolset of techno-fluent computer composers, creative coders and digital artists.','learn  to toolset',0,'',''),(7713,'Meyda','Generated using TypeDoc','use TypeDoc',0,'',''),(7714,'Meyda','Using conventional commits has proven to add quite a lot of overhead for external contributors, and we’re sorry about that.\nThe reason that we use conventional commits is so that we can automate meyda releases using semantic release, and so that it’s\nreally clear from the git log which commits contain changes that are considered fixes, new features, or breaking changes, which\nis crucial to know in a semantically versioned project.','use conventional commits',0,'',''),(7715,'Meyda','Using conventional commits has proven to add quite a lot of overhead for external contributors, and we’re sorry about that.\nThe reason that we use conventional commits is so that we can automate meyda releases using semantic release, and so that it’s\nreally clear from the git log which commits contain changes that are considered fixes, new features, or breaking changes, which\nis crucial to know in a semantically versioned project.','add lot for external contributors',0,'',''),(7716,'Meyda','Using conventional commits has proven to add quite a lot of overhead for external contributors, and we’re sorry about that.\nThe reason that we use conventional commits is so that we can automate meyda releases using semantic release, and so that it’s\nreally clear from the git log which commits contain changes that are considered fixes, new features, or breaking changes, which\nis crucial to know in a semantically versioned project.','use semantic release',0,'',''),(7717,'Meyda','Some pitfalls some run into are documented here. And remember: the top line description of a commit message should be in all lower case.','run pitfalls',0,'',''),(7718,'Meyda','Some pitfalls some run into are documented here. And remember: the top line description of a commit message should be in all lower case.','document pitfalls',0,'',''),(7719,'Meyda','We hope to have better PR feedback on commit messages in the future - and if possible a bot that will just lint and fix any\nminor errors. Follow along on this issue.','fix possible bot',0,'',''),(7720,'Meyda','Often, observing and analysing an audio signal as a waveform doesn’t provide us a lot of information about its contents. An audio feature is a measurement of a particular characteristic of an audio signal, and it gives us insight into what the signal contains. Audio features can be measured by running an algorithm on an audio signal that will return a number, or a set of numbers that quantify the characteristic that the specific algorithm is intended to measure. Meyda implements a selection of standardized audio features that are used widely across a variety of music computing scenarios.','provide lot of information',0,'',''),(7721,'Meyda','Often, observing and analysing an audio signal as a waveform doesn’t provide us a lot of information about its contents. An audio feature is a measurement of a particular characteristic of an audio signal, and it gives us insight into what the signal contains. Audio features can be measured by running an algorithm on an audio signal that will return a number, or a set of numbers that quantify the characteristic that the specific algorithm is intended to measure. Meyda implements a selection of standardized audio features that are used widely across a variety of music computing scenarios.','run algorithm on set',0,'',''),(7722,'Meyda','Often, observing and analysing an audio signal as a waveform doesn’t provide us a lot of information about its contents. An audio feature is a measurement of a particular characteristic of an audio signal, and it gives us insight into what the signal contains. Audio features can be measured by running an algorithm on an audio signal that will return a number, or a set of numbers that quantify the characteristic that the specific algorithm is intended to measure. Meyda implements a selection of standardized audio features that are used widely across a variety of music computing scenarios.','run algorithm on audio signal',0,'',''),(7723,'Meyda','Often, observing and analysing an audio signal as a waveform doesn’t provide us a lot of information about its contents. An audio feature is a measurement of a particular characteristic of an audio signal, and it gives us insight into what the signal contains. Audio features can be measured by running an algorithm on an audio signal that will return a number, or a set of numbers that quantify the characteristic that the specific algorithm is intended to measure. Meyda implements a selection of standardized audio features that are used widely across a variety of music computing scenarios.','return number of numbers',0,'',''),(7724,'Meyda','Often, observing and analysing an audio signal as a waveform doesn’t provide us a lot of information about its contents. An audio feature is a measurement of a particular characteristic of an audio signal, and it gives us insight into what the signal contains. Audio features can be measured by running an algorithm on an audio signal that will return a number, or a set of numbers that quantify the characteristic that the specific algorithm is intended to measure. Meyda implements a selection of standardized audio features that are used widely across a variety of music computing scenarios.','return audio signal of numbers',0,'',''),(7725,'Meyda','Often, observing and analysing an audio signal as a waveform doesn’t provide us a lot of information about its contents. An audio feature is a measurement of a particular characteristic of an audio signal, and it gives us insight into what the signal contains. Audio features can be measured by running an algorithm on an audio signal that will return a number, or a set of numbers that quantify the characteristic that the specific algorithm is intended to measure. Meyda implements a selection of standardized audio features that are used widely across a variety of music computing scenarios.','return set of numbers',0,'',''),(7726,'Meyda','Often, observing and analysing an audio signal as a waveform doesn’t provide us a lot of information about its contents. An audio feature is a measurement of a particular characteristic of an audio signal, and it gives us insight into what the signal contains. Audio features can be measured by running an algorithm on an audio signal that will return a number, or a set of numbers that quantify the characteristic that the specific algorithm is intended to measure. Meyda implements a selection of standardized audio features that are used widely across a variety of music computing scenarios.','implement selection of standardized audio features',0,'',''),(7727,'Meyda','Often, observing and analysing an audio signal as a waveform doesn’t provide us a lot of information about its contents. An audio feature is a measurement of a particular characteristic of an audio signal, and it gives us insight into what the signal contains. Audio features can be measured by running an algorithm on an audio signal that will return a number, or a set of numbers that quantify the characteristic that the specific algorithm is intended to measure. Meyda implements a selection of standardized audio features that are used widely across a variety of music computing scenarios.','use selection across variety',0,'',''),(7728,'Meyda','Often, observing and analysing an audio signal as a waveform doesn’t provide us a lot of information about its contents. An audio feature is a measurement of a particular characteristic of an audio signal, and it gives us insight into what the signal contains. Audio features can be measured by running an algorithm on an audio signal that will return a number, or a set of numbers that quantify the characteristic that the specific algorithm is intended to measure. Meyda implements a selection of standardized audio features that are used widely across a variety of music computing scenarios.','use selection of standardized audio features',0,'',''),(7729,'Meyda','Bear in mind that by default, Meyda.extract applies a windowing function to the incoming signal using the hanning windowing function by default. If you compare the results of Meyda’s feature extraction to that of another library for the same signal, make sure that the same windowing is being applied, or the features will likely differ. To disable windowing in Meyda.extract, set Meyda.windowingFunction to ‘rect’.','apply windowing by default',0,'',''),(7730,'Meyda','Bear in mind that by default, Meyda.extract applies a windowing function to the incoming signal using the hanning windowing function by default. If you compare the results of Meyda’s feature extraction to that of another library for the same signal, make sure that the same windowing is being applied, or the features will likely differ. To disable windowing in Meyda.extract, set Meyda.windowingFunction to ‘rect’.','use hanning windowing function',0,'',''),(7731,'Meyda','Bear in mind that by default, Meyda.extract applies a windowing function to the incoming signal using the hanning windowing function by default. If you compare the results of Meyda’s feature extraction to that of another library for the same signal, make sure that the same windowing is being applied, or the features will likely differ. To disable windowing in Meyda.extract, set Meyda.windowingFunction to ‘rect’.','compare results of feature extraction',0,'',''),(7732,'Meyda','Bear in mind that by default, Meyda.extract applies a windowing function to the incoming signal using the hanning windowing function by default. If you compare the results of Meyda’s feature extraction to that of another library for the same signal, make sure that the same windowing is being applied, or the features will likely differ. To disable windowing in Meyda.extract, set Meyda.windowingFunction to ‘rect’.','apply same windowing',0,'',''),(7733,'Meyda','Bear in mind that by default, Meyda.extract applies a windowing function to the incoming signal using the hanning windowing function by default. If you compare the results of Meyda’s feature extraction to that of another library for the same signal, make sure that the same windowing is being applied, or the features will likely differ. To disable windowing in Meyda.extract, set Meyda.windowingFunction to ‘rect’.','set Meyda.windowingFunction to ârectâ',0,'',''),(7734,'Meyda','To use RMS in applications where you expect a ceiling on each audio feature, we suggest that you measure examples of audio that you will run feature extraction on, identify a reasonable “maximum” to clamp your max to, and apply the Math.min function to take either the current value of rms, or your maximum threshold, whichever is lower.','use RMS in applications',0,'',''),(7735,'Meyda','To use RMS in applications where you expect a ceiling on each audio feature, we suggest that you measure examples of audio that you will run feature extraction on, identify a reasonable “maximum” to clamp your max to, and apply the Math.min function to take either the current value of rms, or your maximum threshold, whichever is lower.','identify reasonable maximum',0,'',''),(7736,'Meyda','To use RMS in applications where you expect a ceiling on each audio feature, we suggest that you measure examples of audio that you will run feature extraction on, identify a reasonable “maximum” to clamp your max to, and apply the Math.min function to take either the current value of rms, or your maximum threshold, whichever is lower.','apply Math.min function',0,'',''),(7737,'Meyda','Windowing functions are used during the conversion of a signal from the time domain (i.e. air pressure over time) to the frequency domain (the phase and intensity of each sine wave that comprises the signal); a prerequisite for many of the audio features described above. Windowing functions generate an envelope of numbers between 0 and 1, and multiply these numbers pointwise with each sample in the signal buffer, making the samples at the middle of the buffer relatively louder, and making the samples at either end of the buffer relatively quieter. This smooths out the result of the conversion to the frequency domain, which makes the final audio features more consistent and less jittery.','use functions for windowing',0,'',''),(7738,'Meyda','Windowing functions are used during the conversion of a signal from the time domain (i.e. air pressure over time) to the frequency domain (the phase and intensity of each sine wave that comprises the signal); a prerequisite for many of the audio features described above. Windowing functions generate an envelope of numbers between 0 and 1, and multiply these numbers pointwise with each sample in the signal buffer, making the samples at the middle of the buffer relatively louder, and making the samples at either end of the buffer relatively quieter. This smooths out the result of the conversion to the frequency domain, which makes the final audio features more consistent and less jittery.','use functions from time domain',0,'',''),(7739,'Meyda','Windowing functions are used during the conversion of a signal from the time domain (i.e. air pressure over time) to the frequency domain (the phase and intensity of each sine wave that comprises the signal); a prerequisite for many of the audio features described above. Windowing functions generate an envelope of numbers between 0 and 1, and multiply these numbers pointwise with each sample in the signal buffer, making the samples at the middle of the buffer relatively louder, and making the samples at either end of the buffer relatively quieter. This smooths out the result of the conversion to the frequency domain, which makes the final audio features more consistent and less jittery.','use functions to frequency domain',0,'',''),(7740,'Meyda','Windowing functions are used during the conversion of a signal from the time domain (i.e. air pressure over time) to the frequency domain (the phase and intensity of each sine wave that comprises the signal); a prerequisite for many of the audio features described above. Windowing functions generate an envelope of numbers between 0 and 1, and multiply these numbers pointwise with each sample in the signal buffer, making the samples at the middle of the buffer relatively louder, and making the samples at either end of the buffer relatively quieter. This smooths out the result of the conversion to the frequency domain, which makes the final audio features more consistent and less jittery.','use functions during conversion',0,'',''),(7741,'Meyda','Windowing functions are used during the conversion of a signal from the time domain (i.e. air pressure over time) to the frequency domain (the phase and intensity of each sine wave that comprises the signal); a prerequisite for many of the audio features described above. Windowing functions generate an envelope of numbers between 0 and 1, and multiply these numbers pointwise with each sample in the signal buffer, making the samples at the middle of the buffer relatively louder, and making the samples at either end of the buffer relatively quieter. This smooths out the result of the conversion to the frequency domain, which makes the final audio features more consistent and less jittery.','generate envelope of numbers',0,'',''),(7742,'Meyda','Windowing functions are used during the conversion of a signal from the time domain (i.e. air pressure over time) to the frequency domain (the phase and intensity of each sine wave that comprises the signal); a prerequisite for many of the audio features described above. Windowing functions generate an envelope of numbers between 0 and 1, and multiply these numbers pointwise with each sample in the signal buffer, making the samples at the middle of the buffer relatively louder, and making the samples at either end of the buffer relatively quieter. This smooths out the result of the conversion to the frequency domain, which makes the final audio features more consistent and less jittery.','multiply numbers pointwise with sample',0,'',''),(7743,'Meyda','Meyda supports 4 windowing functions, each with different characteristics. For more information on windowing, please consult this article. By default, Meyda applies the hanning window, not the rectangular window, to signals before converting them into the frequency domain.','support windowing functions',0,'',''),(7744,'Meyda','Meyda supports 4 windowing functions, each with different characteristics. For more information on windowing, please consult this article. By default, Meyda applies the hanning window, not the rectangular window, to signals before converting them into the frequency domain.','apply hanning window by default',0,'',''),(7745,'Meyda','Meyda supports 4 windowing functions, each with different characteristics. For more information on windowing, please consult this article. By default, Meyda applies the hanning window, not the rectangular window, to signals before converting them into the frequency domain.','apply hanning window to signals',0,'',''),(7746,'Meyda','Meyda supports 4 windowing functions, each with different characteristics. For more information on windowing, please consult this article. By default, Meyda applies the hanning window, not the rectangular window, to signals before converting them into the frequency domain.','convert  into frequency domain',0,'',''),(7747,'Meyda','[5] M. Grierson, “Maximilian: A cross platform c++ audio synthesis library for artists learning to program.,” in Proceedings of International Computer Music Conference, 2010.','learn  to program.',0,'',''),(7748,'Meyda','Allow microphone access or play this audio file to see a demo.','play audio file',0,'',''),(7749,'Meyda','Meyda is a JavaScript audio feature extraction library. It works with the Web\nAudio API (or plain old JavaScript arrays) to expose information about the\ntimbre and perceived qualities of sound. Meyda supports both offline feature\nextraction as well as real-time feature extraction using the\nWeb Audio API. We wrote a paper about it, which is available\nhere.','expose information about perceived qualities',0,'',''),(7750,'Meyda','Meyda is a JavaScript audio feature extraction library. It works with the Web\nAudio API (or plain old JavaScript arrays) to expose information about the\ntimbre and perceived qualities of sound. Meyda supports both offline feature\nextraction as well as real-time feature extraction using the\nWeb Audio API. We wrote a paper about it, which is available\nhere.','expose information about timbre',0,'',''),(7751,'Meyda','Meyda is a JavaScript audio feature extraction library. It works with the Web\nAudio API (or plain old JavaScript arrays) to expose information about the\ntimbre and perceived qualities of sound. Meyda supports both offline feature\nextraction as well as real-time feature extraction using the\nWeb Audio API. We wrote a paper about it, which is available\nhere.','support offline feature extraction',0,'',''),(7752,'Meyda','Meyda is a JavaScript audio feature extraction library. It works with the Web\nAudio API (or plain old JavaScript arrays) to expose information about the\ntimbre and perceived qualities of sound. Meyda supports both offline feature\nextraction as well as real-time feature extraction using the\nWeb Audio API. We wrote a paper about it, which is available\nhere.','support real-time feature extraction',0,'',''),(7753,'Meyda','Meyda is a JavaScript audio feature extraction library. It works with the Web\nAudio API (or plain old JavaScript arrays) to expose information about the\ntimbre and perceived qualities of sound. Meyda supports both offline feature\nextraction as well as real-time feature extraction using the\nWeb Audio API. We wrote a paper about it, which is available\nhere.','use web Audio API',0,'',''),(7754,'Meyda','Meyda is a JavaScript audio feature extraction library. It works with the Web\nAudio API (or plain old JavaScript arrays) to expose information about the\ntimbre and perceived qualities of sound. Meyda supports both offline feature\nextraction as well as real-time feature extraction using the\nWeb Audio API. We wrote a paper about it, which is available\nhere.','write paper',0,'',''),(7755,'Meyda','Want to ask questions, or chat about Meyda? Check out our slack channel on the Web Audio Slack Team. You’ll need to sign up here before you can join.','ask questions',0,'',''),(9215,'Wikidata','Released on July 31, 2020.','release  on July',0,'',''),(9216,'Wikidata','To replace the babel.core.Locale type,\nthe wikidata.multilingual.Locale type has been\naliased to str. This is a breaking change for all Wikidata public API\nfunctions that formerly returned or ingested babel.core.Locale .','replace babel.core.Locale type',0,'',''),(9217,'Wikidata','To replace the babel.core.Locale type,\nthe wikidata.multilingual.Locale type has been\naliased to str. This is a breaking change for all Wikidata public API\nfunctions that formerly returned or ingested babel.core.Locale .','return breaking change for Wikidata public API functions',0,'',''),(9218,'Wikidata','Released on September 18, 2017.','release  on September',0,'',''),(9219,'Wikidata','Released on September 12, 2017.','release  on September',0,'',''),(9220,'Wikidata','Released on June 30, 2017.','release  on June',0,'',''),(9221,'Wikidata','Although this fix prevents these properties from raising ValueError,\nit doesn’t completely fix the problem.  babel.core.Locale type,\nwhich Wikidata depends on, currently doesn’t supprot languages other\nthan ISO 639-1.  In order to completely fix the problem, we need to\npatch Babel to support them, or make Wikidata independent from Babel.','prevent properties from raising',0,'',''),(9222,'Wikidata','Although this fix prevents these properties from raising ValueError,\nit doesn’t completely fix the problem.  babel.core.Locale type,\nwhich Wikidata depends on, currently doesn’t supprot languages other\nthan ISO 639-1.  In order to completely fix the problem, we need to\npatch Babel to support them, or make Wikidata independent from Babel.','raise ValueError',0,'',''),(9223,'Wikidata','Released on June 28, 2017.','release  on June',0,'',''),(9224,'Wikidata','Released on June 13, 2017.','release  on June',0,'',''),(9225,'Wikidata','Released on April 30, 2017.','release  on April',0,'',''),(9226,'Wikidata','Released on April 24, 2017.','release  on April',0,'',''),(9227,'Wikidata','Released on February 23, 2017.','release  on February',0,'',''),(9228,'Wikidata','Released on February 19, 2017.','release  on February',0,'',''),(9229,'Wikidata','Initial version.  Released on February 15, 2017.','release  on February',0,'',''),(9230,'Wikidata','This module provides the decoder interface for customizing how datavalues are\ndecoded, and the default Decoder implementation.','provide default decoder implementation for customizing',1,'https://wikidata.readthedocs.io/en/stable/wikidata/datavalue.html',''),(9231,'Wikidata','This module provides the decoder interface for customizing how datavalues are\ndecoded, and the default Decoder implementation.','provide decoder interface for customizing',1,'https://wikidata.readthedocs.io/en/stable/wikidata/datavalue.html',''),(9232,'Wikidata','Exception raised during decoding datavalues.  It subclasses\nValueError as well.','raise  during decoding datavalues',0,'',''),(9233,'Wikidata','Decode the given datavalue to a value of the appropriate Python type.\nFor extensibility it uses visitor pattern and is intended to be subclassed.\nTo customize decoding of datavalues subclass it and configure\ndatavalue_decoder option of Client to\nthe customized decoder.','use visitor pattern for extensibility',0,'',''),(9234,'Wikidata','Decode the given datavalue to a value of the appropriate Python type.\nFor extensibility it uses visitor pattern and is intended to be subclassed.\nTo customize decoding of datavalues subclass it and configure\ndatavalue_decoder option of Client to\nthe customized decoder.','customize decoding of datavalues',0,'',''),(9235,'Wikidata','Decode the given datavalue to a value of the appropriate Python type.\nFor extensibility it uses visitor pattern and is intended to be subclassed.\nTo customize decoding of datavalues subclass it and configure\ndatavalue_decoder option of Client to\nthe customized decoder.','configure datavalue_decoder option of client',0,'',''),(9236,'Wikidata','Decode the given datavalue to a value of the appropriate Python type.\nFor extensibility it uses visitor pattern and is intended to be subclassed.\nTo customize decoding of datavalues subclass it and configure\ndatavalue_decoder option of Client to\nthe customized decoder.','configure datavalue_decoder option to customized decoder',0,'',''),(9237,'Wikidata','It automatically invokes an appropriate visitor method using a simple\nrule of name: {datatype}__{datavalue[type]}.  For example,\nif the following call to a decoder was made:','use simple rule of name',1,'https://wikidata.readthedocs.io/en/stable/wikidata/datavalue.html',''),(9238,'Wikidata','If a decoder failed to find a visitor method matched to\n{datatype}__{datavalue[type]} pattern it secondly try to find\na general version of visitor method: {datavalue[type]} which lacks\ndouble underscores.  For example, for the following call:','find visitor method',0,'',''),(9239,'Wikidata','If a decoder failed to find a visitor method matched to\n{datatype}__{datavalue[type]} pattern it secondly try to find\na general version of visitor method: {datavalue[type]} which lacks\ndouble underscores.  For example, for the following call:','find general version of visitor method',0,'',''),(9240,'Wikidata','If a decoder failed to find a visitor method matched to\n{datatype}__{datavalue[type]} pattern it secondly try to find\na general version of visitor method: {datavalue[type]} which lacks\ndouble underscores.  For example, for the following call:','match  to { datatype } __ { datavalue  type  } pattern',0,'',''),(9241,'Wikidata','It firstly try to find the following visitor method:','find following visitor method',0,'',''),(9242,'Wikidata','but if there’s no such method it secondly try to find the following\ngeneral visitor method:','find following general visitor method',0,'',''),(9243,'Wikidata','This twice-try dispatch is useful when to make a visitor method to\nbe matched regardless of datatype.','match  regardless_of datatype',0,'',''),(9244,'Wikidata','If its datavalue[type] contains hyphens they’re replaced by\nunderscores.  For example:','replace  by underscores',1,'https://wikidata.readthedocs.io/en/stable/wikidata/datavalue.html',''),(9245,'Wikidata','This package provides easy APIs to use Wikidata for Python.','use wikidata for Python',1,'https://wikidata.readthedocs.io/',''),(9246,'Wikidata','Changed in version 0.3.0: As the meaning of Client constructor’s base_url parameter,\nit now became to https://www.wikidata.org/ from\nhttps://www.wikidata.org/wiki/ (which contained the trailing path\nwiki/).','change  in version 0.3.0',0,'',''),(9247,'Wikidata','Changed in version 0.3.0: The meaning of base_url parameter changed.  It originally meant\nhttps://www.wikidata.org/wiki/ which contained the trailing path\nwiki/, but now it means only https://www.wikidata.org/.','change  in version 0.3.0',0,'',''),(9248,'Wikidata','Decode the given datavalue using the configured\ndatavalue_decoder.','use configured datavalue_decoder',0,'',''),(9249,'Wikidata','Get a Wikidata entity by its EntityId.','get Wikidata entity by EntityId',0,'',''),(9250,'Wikidata','Guess EntityType from the given\nEntityId.  It could return None when it\nfails to guess.','return none',0,'',''),(9251,'Wikidata','As this project supports various Python interpreters (CPython and PyPy) and\nversions, to ensure it works well with them, we use tox.  You don’t need to\ncreate a virtual environment by yourself.  tox automatically creates\nvirtual environments for various Python versions and run the same test suite\non all of them.','support various Python interpreters',0,'',''),(9252,'Wikidata','As this project supports various Python interpreters (CPython and PyPy) and\nversions, to ensure it works well with them, we use tox.  You don’t need to\ncreate a virtual environment by yourself.  tox automatically creates\nvirtual environments for various Python versions and run the same test suite\non all of them.','support versions',0,'',''),(9253,'Wikidata','As this project supports various Python interpreters (CPython and PyPy) and\nversions, to ensure it works well with them, we use tox.  You don’t need to\ncreate a virtual environment by yourself.  tox automatically creates\nvirtual environments for various Python versions and run the same test suite\non all of them.','use tox',0,'',''),(9254,'Wikidata','As this project supports various Python interpreters (CPython and PyPy) and\nversions, to ensure it works well with them, we use tox.  You don’t need to\ncreate a virtual environment by yourself.  tox automatically creates\nvirtual environments for various Python versions and run the same test suite\non all of them.','create virtual environment',0,'',''),(9255,'Wikidata','As this project supports various Python interpreters (CPython and PyPy) and\nversions, to ensure it works well with them, we use tox.  You don’t need to\ncreate a virtual environment by yourself.  tox automatically creates\nvirtual environments for various Python versions and run the same test suite\non all of them.','create virtual environments for various Python versions',0,'',''),(9256,'Wikidata','As this project supports various Python interpreters (CPython and PyPy) and\nversions, to ensure it works well with them, we use tox.  You don’t need to\ncreate a virtual environment by yourself.  tox automatically creates\nvirtual environments for various Python versions and run the same test suite\non all of them.','run same test suite',0,'',''),(9257,'Wikidata','The easiest to install tox is to use pip [1]:','install tox',1,'https://wikidata.readthedocs.io/en/stable/contributing.html','id1'),(9258,'Wikidata','The easiest to install tox is to use pip [1]:','use',1,'https://wikidata.readthedocs.io/en/stable/contributing.html','id1'),(9259,'Wikidata','Once you’ve installed tox, it’s very simple to run the test suite on\nall Python versions this project aims to support:','run test suite on Python versions',1,'https://wikidata.readthedocs.io/en/stable/contributing.html','id1'),(9260,'Wikidata','Note that you need to install Python interpreters besides tox.\nIf you don’t want to install all of them use --skip-missing-interpreters\noption:','install Python interpreters besides tox',1,'https://wikidata.readthedocs.io/en/stable/contributing.html','id1'),(9261,'Wikidata','To run tests on multiple interpreters at a time, use --parallel option:','run tests at time',1,'https://wikidata.readthedocs.io/en/stable/contributing.html','id1'),(9262,'Wikidata','To run tests on multiple interpreters at a time, use --parallel option:','run tests on multiple interpreters',1,'https://wikidata.readthedocs.io/en/stable/contributing.html','id1'),(9263,'Wikidata','Wikidata entity.  Can be an item or a property.  Its attrributes\ncan be lazily loaded.','load attrributes',0,'',''),(9264,'Wikidata','To get an entity use Client.get()\nmethod instead of the constructor of Entity.','get entity',0,'',''),(9265,'Wikidata','To get an entity use Client.get()\nmethod instead of the constructor of Entity.','use Client.get() method instead_of constructor',0,'',''),(9266,'Wikidata','Define state of Entity.','define state of entity',0,'',''),(9267,'Wikidata','(EntityState) The entity exists and is already loaded.','load entity',0,'',''),(9268,'Wikidata','(EntityType) Properties are Entity objects that\ndescribe a relationship between items (or other Entity objects)\nand values of the property.  Typical properties are population\n(using numbers as values), binomial name (using strings as values),\nbut also has father and author of (both using items as values).','describe relationship between items',0,'',''),(9269,'Wikidata','(EntityType) Properties are Entity objects that\ndescribe a relationship between items (or other Entity objects)\nand values of the property.  Typical properties are population\n(using numbers as values), binomial name (using strings as values),\nbut also has father and author of (both using items as values).','describe relationship between values',0,'',''),(9270,'Wikidata','(EntityType) Properties are Entity objects that\ndescribe a relationship between items (or other Entity objects)\nand values of the property.  Typical properties are population\n(using numbers as values), binomial name (using strings as values),\nbut also has father and author of (both using items as values).','describe entity objects between items',0,'',''),(9271,'Wikidata','(EntityType) Properties are Entity objects that\ndescribe a relationship between items (or other Entity objects)\nand values of the property.  Typical properties are population\n(using numbers as values), binomial name (using strings as values),\nbut also has father and author of (both using items as values).','describe entity objects between values',0,'',''),(9272,'Wikidata','Locale-denoted text. It’s almost equivalent to str (and indeed\nsubclasses str) except that it has an extra attribute,\nlocale, that denotes what language the text is written in.','write text',0,'',''),(9273,'Wikidata','Changed in version 0.5.0.','change  in version 0.5.0',0,'',''),(9274,'Wikidata','Create or update a cache.','create cache',0,'',''),(9275,'Wikidata','Create or update a cache.','update cache',0,'',''),(9276,'Typescript','Using TypeScript in several environments.','use TypeScript in several environments',0,'',''),(9277,'Typescript','Learn how to write declaration files to describe existing JavaScript. Important for DefinitelyTyped contributions.','write declaration',0,'',''),(9278,'Typescript','Learn how to write declaration files to describe existing JavaScript. Important for DefinitelyTyped contributions.','describe existing JavaScript',0,'',''),(9279,'Typescript','How to use TypeScript-powered JavaScript tooling.','use typescript-powered JavaScript tooling',0,'',''),(9280,'Typescript','How to provide types to functions in JavaScript','provide types to functions',0,'',''),(9281,'Typescript','How to provide a type shape to JavaScript objects','provide type',0,'',''),(9282,'Typescript','How to create and type JavaScript variables','create JavaScript variables',0,'',''),(9283,'Typescript','How to provide types to JavaScript ES6 classes','provide types to JavaScript es6 classes',0,'',''),(9284,'Typescript','Explore how TypeScript extends JavaScript to add more safety and tooling.','extend JavaScript',0,'',''),(9285,'Typescript','Explore how TypeScript extends JavaScript to add more safety and tooling.','add more safety',0,'',''),(9286,'Typescript','Explore how TypeScript extends JavaScript to add more safety and tooling.','add tooling',0,'',''),(9287,'twilio','Send and receive text messages','send text messages',0,'',''),(9288,'twilio','Send and receive text messages','receive text messages',0,'',''),(9289,'twilio','Create omnichannel campaigns with a unified, data-first platform','create omnichannel campaigns with unified data-first platform',0,'',''),(9290,'twilio','Create and manage email marketing campaigns','create email marketing campaigns',0,'',''),(9291,'twilio','Create and manage email marketing campaigns','manage email marketing campaigns',0,'',''),(9292,'twilio','Access local, national, and toll-free phone numbers','access toll-free phone numbers',0,'',''),(9293,'twilio','Browse our content library for more resources on how you can create lasting customer relationships','create lasting customer relationships',0,'',''),(9294,'twilio','Prepare for the new A2P 10DLC requirements','prepare  for new a2p 10DLC requirements',0,'',''),(9295,'twilio','Read tutorials, community projects, and product updates','read tutorials',0,'',''),(9296,'twilio','Read tutorials, community projects, and product updates','read community projects',0,'',''),(9297,'twilio','Read tutorials, community projects, and product updates','read product updates',0,'',''),(9298,'twilio','Ask the Twilio community for help','ask Twilio community for help',0,'',''),(9299,'twilio','Check real-time monitoring of APIs and all services','check real-time monitoring of apis',0,'',''),(9300,'twilio','Check real-time monitoring of APIs and all services','check real-time monitoring of services',0,'',''),(9301,'twilio','Get technical and strategic advice from Twilio experts','get technical strategic advice from Twilio experts',0,'',''),(9302,'twilio','Create the exact solution you need to engage customers at every step of their journey. Twilio Customer Engagement Platform combines flexible APIs for any digital channel, first-party customer data, and global infrastructure to support you at scale.','create exact solution',0,'',''),(9303,'twilio','Create the exact solution you need to engage customers at every step of their journey. Twilio Customer Engagement Platform combines flexible APIs for any digital channel, first-party customer data, and global infrastructure to support you at scale.','combine flexible apis for global infrastructure',0,'',''),(9304,'twilio','Create the exact solution you need to engage customers at every step of their journey. Twilio Customer Engagement Platform combines flexible APIs for any digital channel, first-party customer data, and global infrastructure to support you at scale.','combine flexible apis for digital channel',0,'',''),(9305,'twilio','Create the exact solution you need to engage customers at every step of their journey. Twilio Customer Engagement Platform combines flexible APIs for any digital channel, first-party customer data, and global infrastructure to support you at scale.','combine flexible apis for first-party customer data',0,'',''),(9306,'twilio','Create the exact solution you need to engage customers at every step of their journey. Twilio Customer Engagement Platform combines flexible APIs for any digital channel, first-party customer data, and global infrastructure to support you at scale.','support  at scale',0,'',''),(9307,'twilio','Connect with customers on their preferred channels—anywhere in the world. Quickly integrate powerful APIs to start building solutions for SMS and WhatsApp messaging, voice, video, and email.','integrate video',0,'',''),(9308,'twilio','Connect with customers on their preferred channels—anywhere in the world. Quickly integrate powerful APIs to start building solutions for SMS and WhatsApp messaging, voice, video, and email.','integrate powerful apis',0,'',''),(9309,'twilio','Connect with customers on their preferred channels—anywhere in the world. Quickly integrate powerful APIs to start building solutions for SMS and WhatsApp messaging, voice, video, and email.','integrate email',0,'',''),(9310,'twilio','Connect with customers on their preferred channels—anywhere in the world. Quickly integrate powerful APIs to start building solutions for SMS and WhatsApp messaging, voice, video, and email.','integrate voice',0,'',''),(9311,'twilio','Provide service so convenient and proactive, your customers will think you can read minds. Contextual data, flexible workflows, and seamless cross-channel communications empower your teams to engage people in powerful new ways.','read minds',0,'',''),(9312,'twilio','Retail giant Marks & Spencer uses Twilio to deliver the same quality of customer service you’d find in a store, over the phone. Using Twilio, they deliver personalized support, powering over $10M in new sales.','use Twilio',0,'',''),(9313,'twilio','Retail giant Marks & Spencer uses Twilio to deliver the same quality of customer service you’d find in a store, over the phone. Using Twilio, they deliver personalized support, powering over $10M in new sales.','find  over phone',0,'',''),(9314,'twilio','Retail giant Marks & Spencer uses Twilio to deliver the same quality of customer service you’d find in a store, over the phone. Using Twilio, they deliver personalized support, powering over $10M in new sales.','find  in store',0,'',''),(9315,'twilio','Retail giant Marks & Spencer uses Twilio to deliver the same quality of customer service you’d find in a store, over the phone. Using Twilio, they deliver personalized support, powering over $10M in new sales.','use twilio',0,'',''),(9316,'twilio','With SMS marketing, you can reach thousands or millions of your recipients with the right message, on the right channel, at the right time.','reach thousands with right message',0,'',''),(9317,'twilio','With SMS marketing, you can reach thousands or millions of your recipients with the right message, on the right channel, at the right time.','reach thousands with SMS marketing',0,'',''),(9318,'twilio','With SMS marketing, you can reach thousands or millions of your recipients with the right message, on the right channel, at the right time.','reach thousands at right time',0,'',''),(9319,'twilio','With SMS marketing, you can reach thousands or millions of your recipients with the right message, on the right channel, at the right time.','reach thousands of recipients',0,'',''),(9320,'twilio','With SMS marketing, you can reach thousands or millions of your recipients with the right message, on the right channel, at the right time.','reach thousands on right channel',0,'',''),(9321,'twilio','With SMS marketing, you can reach thousands or millions of your recipients with the right message, on the right channel, at the right time.','reach millions with right message',0,'',''),(9322,'twilio','With SMS marketing, you can reach thousands or millions of your recipients with the right message, on the right channel, at the right time.','reach millions with SMS marketing',0,'',''),(9323,'twilio','With SMS marketing, you can reach thousands or millions of your recipients with the right message, on the right channel, at the right time.','reach millions at right time',0,'',''),(9324,'twilio','With SMS marketing, you can reach thousands or millions of your recipients with the right message, on the right channel, at the right time.','reach millions of recipients',0,'',''),(9325,'twilio','With SMS marketing, you can reach thousands or millions of your recipients with the right message, on the right channel, at the right time.','reach millions on right channel',0,'',''),(9438,'python-socketio','This class implements a fully compliant Socket.IO web client with support\nfor websocket and long-polling transports.','implement compliant Socket.IO web client with support',0,'',''),(9439,'python-socketio','The Engine.IO configuration supports the following settings:','support following settings',0,'',''),(9440,'python-socketio','This method issues an emit with a callback and waits for the callback\nto be invoked before returning. If the callback isn’t invoked before\nthe timeout, then a TimeoutError exception is raised. If the\nSocket.IO connection drops during the wait, this method still waits\nuntil the specified timeout.','raise TimeoutError exception',0,'',''),(9441,'python-socketio','Note: this method is not thread safe. If multiple threads are emitting\nat the same time on the same client connection, messages composed of\nmultiple packets may end up being sent in an incorrect sequence. Use\nstandard concurrency solutions (such as a Lock object) to prevent this\nsituation.','compose  of multiple packets',0,'',''),(9442,'python-socketio','Note: this method is not thread safe. If multiple threads are emitting\nat the same time on the same client connection, messages composed of\nmultiple packets may end up being sent in an incorrect sequence. Use\nstandard concurrency solutions (such as a Lock object) to prevent this\nsituation.','send  in incorrect sequence',0,'',''),(9443,'python-socketio','Note: this method is not thread safe. If multiple threads are emitting\nat the same time on the same client connection, messages composed of\nmultiple packets may end up being sent in an incorrect sequence. Use\nstandard concurrency solutions (such as a Lock object) to prevent this\nsituation.','prevent situation',0,'',''),(9444,'python-socketio','This method returns the sid for the requested namespace as a\nstring.','return sid for requested namespace',0,'',''),(9445,'python-socketio','set of connected namespaces.','set  of connected namespaces',0,'',''),(9446,'python-socketio','The \'connect\' event handler receives no arguments. The\n\'message\' handler and handlers for custom event names receive the\nmessage payload as only argument. Any values returned from a message\nhandler will be passed to the client’s acknowledgement callback\nfunction if it exists. The \'disconnect\' handler does not take\narguments.','receive arguments',0,'',''),(9447,'python-socketio','The \'connect\' event handler receives no arguments. The\n\'message\' handler and handlers for custom event names receive the\nmessage payload as only argument. Any values returned from a message\nhandler will be passed to the client’s acknowledgement callback\nfunction if it exists. The \'disconnect\' handler does not take\narguments.','receive message',0,'',''),(9448,'python-socketio','The \'connect\' event handler receives no arguments. The\n\'message\' handler and handlers for custom event names receive the\nmessage payload as only argument. Any values returned from a message\nhandler will be passed to the client’s acknowledgement callback\nfunction if it exists. The \'disconnect\' handler does not take\narguments.','return  from message handler',0,'',''),(9449,'python-socketio','The \'connect\' event handler receives no arguments. The\n\'message\' handler and handlers for custom event names receive the\nmessage payload as only argument. Any values returned from a message\nhandler will be passed to the client’s acknowledgement callback\nfunction if it exists. The \'disconnect\' handler does not take\narguments.','pass values to acknowledgement callback function',0,'',''),(9450,'python-socketio','Send a message to one or more connected clients.','send message to connected clients',0,'',''),(9451,'python-socketio','This function emits an event with the name \'message\'. Use\nemit() to issue custom event names.','use emit() to issue custom event names',0,'',''),(9452,'python-socketio','Sleep for the requested amount of time using the appropriate async\nmodel.','use appropriate async model',0,'',''),(9453,'python-socketio','This is a utility function that applications can use to put a task to\nsleep without having to worry about using the correct call for the\nselected async mode.','use correct call for selected async mode',0,'',''),(9454,'python-socketio','Start a background task using the appropriate async model.','use appropriate async model',0,'',''),(9455,'python-socketio','This is a utility function that applications can use to start a\nbackground task using the method that is compatible with the\nselected async mode.','use method',0,'',''),(9456,'python-socketio','This function returns an object that represents the background task,\non which the join() methond can be invoked to wait for the task to\ncomplete.','return object',0,'',''),(9457,'python-socketio','Return the name of the transport used by the client.','return name of transport',0,'',''),(9458,'python-socketio','Client applications can use this function to block the main thread\nduring the life of the connection.','use function',0,'',''),(9459,'python-socketio','Note: this method is not designed to be used concurrently. If multiple\ntasks are emitting at the same time on the same client connection, then\nmessages composed of multiple packets may end up being sent in an\nincorrect sequence. Use standard concurrency solutions (such as a Lock\nobject) to prevent this situation.','compose  of multiple packets',0,'',''),(9460,'python-socketio','Note: this method is not designed to be used concurrently. If multiple\ntasks are emitting at the same time on the same client connection, then\nmessages composed of multiple packets may end up being sent in an\nincorrect sequence. Use standard concurrency solutions (such as a Lock\nobject) to prevent this situation.','send  in incorrect sequence',0,'',''),(9461,'python-socketio','Note: this method is not designed to be used concurrently. If multiple\ntasks are emitting at the same time on the same client connection, then\nmessages composed of multiple packets may end up being sent in an\nincorrect sequence. Use standard concurrency solutions (such as a Lock\nobject) to prevent this situation.','prevent situation',0,'',''),(9462,'python-socketio','This class implements a fully compliant Socket.IO web server with support\nfor websocket and long-polling transports.','implement compliant Socket.IO web server with support',0,'',''),(9463,'python-socketio','Note: this method is not thread safe. If multiple threads are emitting\nat the same time to the same client, then messages composed of\nmultiple packets may end up being sent in an incorrect sequence. Use\nstandard concurrency solutions (such as a Lock object) to prevent this\nsituation.','compose  of multiple packets',0,'',''),(9464,'python-socketio','Note: this method is not thread safe. If multiple threads are emitting\nat the same time to the same client, then messages composed of\nmultiple packets may end up being sent in an incorrect sequence. Use\nstandard concurrency solutions (such as a Lock object) to prevent this\nsituation.','send  in incorrect sequence',0,'',''),(9465,'python-socketio','Note: this method is not thread safe. If multiple threads are emitting\nat the same time to the same client, then messages composed of\nmultiple packets may end up being sent in an incorrect sequence. Use\nstandard concurrency solutions (such as a Lock object) to prevent this\nsituation.','prevent situation',0,'',''),(9466,'python-socketio','This function removes all the clients from the given room.','remove clients from given room',0,'',''),(9467,'python-socketio','Enter a room.','enter room',0,'',''),(9468,'python-socketio','This function adds the client to a room. The emit() and\nsend() functions can optionally broadcast events to all the\nclients in a room.','add client to room',0,'',''),(9469,'python-socketio','The return value is a dictionary. Modifications made to this\ndictionary are not guaranteed to be preserved unless\nsave_session() is called, or when the session context manager\nis used.','call save_session()',0,'',''),(9470,'python-socketio','The return value is a dictionary. Modifications made to this\ndictionary are not guaranteed to be preserved unless\nsave_session() is called, or when the session context manager\nis used.','use session context manager',0,'',''),(9471,'python-socketio','Handle an HTTP request from the client.','handle HTTP request from client',0,'',''),(9472,'python-socketio','This is the entry point of the Socket.IO application, using the same\ninterface as a WSGI application. For the typical usage, this function\nis invoked by the Middleware instance, but it can be invoked\ndirectly when the middleware is not used.','use same interface as WSGI application',0,'',''),(9473,'python-socketio','This function removes the client from a room.','remove client from room',0,'',''),(9474,'python-socketio','The handler function receives the sid (session ID) for the\nclient as first argument. The \'connect\' event handler receives the\nWSGI environment as a second argument, and can return False to\nreject the connection. The \'message\' handler and handlers for\ncustom event names receive the message payload as a second argument.\nAny values returned from a message handler will be passed to the\nclient’s acknowledgement callback function if it exists. The\n\'disconnect\' handler does not take a second argument.','receive sid for client',0,'',''),(9475,'python-socketio','The handler function receives the sid (session ID) for the\nclient as first argument. The \'connect\' event handler receives the\nWSGI environment as a second argument, and can return False to\nreject the connection. The \'message\' handler and handlers for\ncustom event names receive the message payload as a second argument.\nAny values returned from a message handler will be passed to the\nclient’s acknowledgement callback function if it exists. The\n\'disconnect\' handler does not take a second argument.','receive WSGI environment as second argument',0,'',''),(9476,'python-socketio','The handler function receives the sid (session ID) for the\nclient as first argument. The \'connect\' event handler receives the\nWSGI environment as a second argument, and can return False to\nreject the connection. The \'message\' handler and handlers for\ncustom event names receive the message payload as a second argument.\nAny values returned from a message handler will be passed to the\nclient’s acknowledgement callback function if it exists. The\n\'disconnect\' handler does not take a second argument.','return WSGI environment as second argument',0,'',''),(9477,'python-socketio','The handler function receives the sid (session ID) for the\nclient as first argument. The \'connect\' event handler receives the\nWSGI environment as a second argument, and can return False to\nreject the connection. The \'message\' handler and handlers for\ncustom event names receive the message payload as a second argument.\nAny values returned from a message handler will be passed to the\nclient’s acknowledgement callback function if it exists. The\n\'disconnect\' handler does not take a second argument.','receive message',0,'',''),(9478,'python-socketio','The handler function receives the sid (session ID) for the\nclient as first argument. The \'connect\' event handler receives the\nWSGI environment as a second argument, and can return False to\nreject the connection. The \'message\' handler and handlers for\ncustom event names receive the message payload as a second argument.\nAny values returned from a message handler will be passed to the\nclient’s acknowledgement callback function if it exists. The\n\'disconnect\' handler does not take a second argument.','return  from message handler',0,'',''),(9479,'python-socketio','The handler function receives the sid (session ID) for the\nclient as first argument. The \'connect\' event handler receives the\nWSGI environment as a second argument, and can return False to\nreject the connection. The \'message\' handler and handlers for\ncustom event names receive the message payload as a second argument.\nAny values returned from a message handler will be passed to the\nclient’s acknowledgement callback function if it exists. The\n\'disconnect\' handler does not take a second argument.','pass values to acknowledgement callback function',0,'',''),(9480,'python-socketio','This is a context manager that returns the user session dictionary for\nthe client. Any changes that are made to this dictionary inside the\ncontext manager block are saved back to the session. Example usage:','return user session dictionary for client',1,'https://python-socketio.readthedocs.io/en/latest/api.html',''),(9481,'python-socketio','This is a context manager that returns the user session dictionary for\nthe client. Any changes that are made to this dictionary inside the\ncontext manager block are saved back to the session. Example usage:','return context manager for client',1,'https://python-socketio.readthedocs.io/en/latest/api.html',''),(9482,'python-socketio','This class implements a fully compliant Socket.IO web server with support\nfor websocket and long-polling transports, compatible with the asyncio\nframework.','implement compliant Socket.IO web server with support',0,'',''),(9483,'python-socketio','Attach the Socket.IO server to an application.','attach Socket.IO server to application',0,'',''),(9484,'python-socketio','Note: this method is not designed to be used concurrently. If multiple\ntasks are emitting at the same time to the same client connection, then\nmessages composed of multiple packets may end up being sent in an\nincorrect sequence. Use standard concurrency solutions (such as a Lock\nobject) to prevent this situation.','compose  of multiple packets',0,'',''),(9485,'python-socketio','Note: this method is not designed to be used concurrently. If multiple\ntasks are emitting at the same time to the same client connection, then\nmessages composed of multiple packets may end up being sent in an\nincorrect sequence. Use standard concurrency solutions (such as a Lock\nobject) to prevent this situation.','send  in incorrect sequence',0,'',''),(9486,'python-socketio','Note: this method is not designed to be used concurrently. If multiple\ntasks are emitting at the same time to the same client connection, then\nmessages composed of multiple packets may end up being sent in an\nincorrect sequence. Use standard concurrency solutions (such as a Lock\nobject) to prevent this situation.','prevent situation',0,'',''),(9487,'python-socketio','The return value is a dictionary. Modifications made to this\ndictionary are not guaranteed to be preserved. If you want to modify\nthe user session, use the session context manager instead.','modify user session',0,'',''),(9488,'python-socketio','The return value is a dictionary. Modifications made to this\ndictionary are not guaranteed to be preserved. If you want to modify\nthe user session, use the session context manager instead.','use session context manager',0,'',''),(9489,'python-socketio','This exception can be raised from a connect handler when the connection\nis not accepted. The positional arguments provided with the exception are\nreturned with the error packet to the client.','raise exception from connect handler',0,'',''),(9490,'python-socketio','This exception can be raised from a connect handler when the connection\nis not accepted. The positional arguments provided with the exception are\nreturned with the error packet to the client.','provide  with exception',0,'',''),(9491,'python-socketio','This exception can be raised from a connect handler when the connection\nis not accepted. The positional arguments provided with the exception are\nreturned with the error packet to the client.','return positional arguments with error packet',0,'',''),(9492,'python-socketio','This exception can be raised from a connect handler when the connection\nis not accepted. The positional arguments provided with the exception are\nreturned with the error packet to the client.','return positional arguments to client',0,'',''),(9493,'python-socketio','This class has been renamed to WSGIApp and is now deprecated.','rename class to WSGIApp',0,'',''),(9494,'python-socketio','Send a message to the server.','send message to server',0,'',''),(9495,'python-socketio','In the most common usage, this method is not overloaded by subclasses,\nas it performs the routing of events to methods. However, this\nmethod can be overridden if special dispatching rules are needed, or if\nhaving a single method that catches all events is desired.','perform routing of events',0,'',''),(9496,'python-socketio','In the most common usage, this method is not overloaded by subclasses,\nas it performs the routing of events to methods. However, this\nmethod can be overridden if special dispatching rules are needed, or if\nhaving a single method that catches all events is desired.','perform routing to methods',0,'',''),(9497,'python-socketio','In the most common usage, this method is not overloaded by subclasses,\nas it performs the routing of events to methods. However, this\nmethod can be overridden if special dispatching rules are needed, or if\nhaving a single method that catches all events is desired.','catch events',0,'',''),(9498,'python-socketio','In the most common usage, this method is not overloaded by subclasses,\nas it performs the routing of events to methods. However, this\nmethod can be overridden if special dispatching rules are needed, or if\nhaving a single method that catches all events is desired.','catch single method',0,'',''),(9499,'python-socketio','In the most common usage, this method is not overloaded by subclasses,\nas it performs the routing of events to methods. However, this\nmethod can be overridden if special dispatching rules are needed, or if\nhaving a single method that catches all events is desired.','override method',0,'',''),(9500,'python-socketio','Manage client connections.','manage client connections',0,'',''),(9501,'python-socketio','This class keeps track of all the clients and the rooms they are in, to\nsupport the broadcasting of messages. The data used by this class is\nstored in a memory structure, making it appropriate only for single process\nservices. More sophisticated storage backends can be implemented by\nsubclasses.','support broadcasting of messages',0,'',''),(9502,'python-socketio','This class keeps track of all the clients and the rooms they are in, to\nsupport the broadcasting of messages. The data used by this class is\nstored in a memory structure, making it appropriate only for single process\nservices. More sophisticated storage backends can be implemented by\nsubclasses.','store data in memory structure',0,'',''),(9503,'python-socketio','This class keeps track of all the clients and the rooms they are in, to\nsupport the broadcasting of messages. The data used by this class is\nstored in a memory structure, making it appropriate only for single process\nservices. More sophisticated storage backends can be implemented by\nsubclasses.','implement sophisticated storage backends',0,'',''),(9504,'python-socketio','Remove all participants from a room.','remove participants from room',0,'',''),(9505,'python-socketio','Add a client to a room.','add client to room',0,'',''),(9506,'python-socketio','Invoked before the first request is received. Subclasses can add\ntheir initialization code here.','add initialization code',0,'',''),(9507,'python-socketio','Remove a client from a room.','remove client from room',0,'',''),(9508,'python-socketio','Manage a client list attached to a pub/sub backend.','manage client list',0,'',''),(9509,'python-socketio','Manage a client list attached to a pub/sub backend.','attach  to pub/sub backend',0,'',''),(9510,'python-socketio','This is a base class that enables multiple servers to share the list of\nclients, with the servers communicating events through a pub/sub backend.\nThe use of a pub/sub backend also allows any client connected to the\nbackend to emit events addressed to Socket.IO clients.','share list with communicating',0,'',''),(9511,'python-socketio','This is a base class that enables multiple servers to share the list of\nclients, with the servers communicating events through a pub/sub backend.\nThe use of a pub/sub backend also allows any client connected to the\nbackend to emit events addressed to Socket.IO clients.','share list of clients',0,'',''),(9512,'python-socketio','This is a base class that enables multiple servers to share the list of\nclients, with the servers communicating events through a pub/sub backend.\nThe use of a pub/sub backend also allows any client connected to the\nbackend to emit events addressed to Socket.IO clients.','enable base class',0,'',''),(9513,'python-socketio','The actual backends must be implemented by subclasses, this class only\nprovides a pub/sub generic framework.','provide pub/sub generic framework',0,'',''),(9514,'python-socketio','The actual backends must be implemented by subclasses, this class only\nprovides a pub/sub generic framework.','implement actual backends',0,'',''),(9515,'python-socketio','Client manager that uses kombu for inter-process messaging.','use manager',0,'',''),(9516,'python-socketio','This class implements a client manager backend for event sharing across\nmultiple processes, using RabbitMQ, Redis or any other messaging mechanism\nsupported by kombu.','implement client manager backend for event sharing',0,'',''),(9517,'python-socketio','This class implements a client manager backend for event sharing across\nmultiple processes, using RabbitMQ, Redis or any other messaging mechanism\nsupported by kombu.','use RabbitMQ',0,'',''),(9518,'python-socketio','This class implements a client manager backend for event sharing across\nmultiple processes, using RabbitMQ, Redis or any other messaging mechanism\nsupported by kombu.','use redis',0,'',''),(9519,'python-socketio','This class implements a client manager backend for event sharing across\nmultiple processes, using RabbitMQ, Redis or any other messaging mechanism\nsupported by kombu.','use other messaging mechanism',0,'',''),(9520,'python-socketio','To use a kombu backend, initialize the Server instance as\nfollows:','use kombu backend',1,'https://python-socketio.readthedocs.io/en/latest/api.html',''),(9521,'python-socketio','This class implements a Redis backend for event sharing across multiple\nprocesses. Only kept here as one more example of how to build a custom\nbackend, since the kombu backend is perfectly adequate to support a Redis\nmessage queue.','implement Redis backend across multiple processes',0,'',''),(9522,'python-socketio','This class implements a Redis backend for event sharing across multiple\nprocesses. Only kept here as one more example of how to build a custom\nbackend, since the kombu backend is perfectly adequate to support a Redis\nmessage queue.','implement Redis backend for event sharing',0,'',''),(9523,'python-socketio','This class implements a Redis backend for event sharing across multiple\nprocesses. Only kept here as one more example of how to build a custom\nbackend, since the kombu backend is perfectly adequate to support a Redis\nmessage queue.','support Redis message queue',0,'',''),(9524,'python-socketio','To use a Redis backend, initialize the Server instance as\nfollows:','use Redis backend',0,'',''),(9525,'python-socketio','This class implements a Kafka backend for event sharing across multiple\nprocesses.','implement Kafka backend across multiple processes',0,'',''),(9526,'python-socketio','This class implements a Kafka backend for event sharing across multiple\nprocesses.','implement Kafka backend for event sharing',0,'',''),(9527,'python-socketio','To use a Kafka backend, initialize the Server instance as\nfollows:','use Kafka backend',0,'',''),(9528,'python-socketio','Manage a client list for an asyncio server.','manage client list for asyncio server',0,'',''),(9529,'python-socketio','This class implements a Redis backend for event sharing across multiple\nprocesses.','implement Redis backend across multiple processes',0,'',''),(9530,'python-socketio','This class implements a Redis backend for event sharing across multiple\nprocesses.','implement Redis backend for event sharing',0,'',''),(9531,'python-socketio','To use a Redis backend, initialize the AsyncServer instance as\nfollows:','use Redis backend',1,'https://python-socketio.readthedocs.io/en/latest/api.html',''),(9532,'python-socketio','Client manager that uses aio_pika for inter-process messaging under\nasyncio.','use aio_pika for inter-process',0,'',''),(9533,'python-socketio','Client manager that uses aio_pika for inter-process messaging under\nasyncio.','use manager for inter-process',0,'',''),(9534,'python-socketio','This class implements a client manager backend for event sharing across\nmultiple processes, using RabbitMQ','implement client manager backend for event sharing',0,'',''),(9535,'python-socketio','This class implements a client manager backend for event sharing across\nmultiple processes, using RabbitMQ','use RabbitMQ',0,'',''),(9536,'python-socketio','To use a aio_pika backend, initialize the Server instance as\nfollows:','use aio_pika backend',1,'https://python-socketio.readthedocs.io/en/latest/api.html',''),(9537,'python-socketio','This projects implements Socket.IO clients and servers that can run standalone\nor integrated with a variety of Python web frameworks.','implement Socket.IO clients',0,'',''),(9538,'python-socketio','This projects implements Socket.IO clients and servers that can run standalone\nor integrated with a variety of Python web frameworks.','implement servers',0,'',''),(9539,'python-socketio','This projects implements Socket.IO clients and servers that can run standalone\nor integrated with a variety of Python web frameworks.','run standalone',0,'',''),(9540,'python-socketio','This projects implements Socket.IO clients and servers that can run standalone\nor integrated with a variety of Python web frameworks.','run Socket.IO clients',0,'',''),(9541,'python-socketio','This projects implements Socket.IO clients and servers that can run standalone\nor integrated with a variety of Python web frameworks.','run servers',0,'',''),(9542,'python-socketio','The methods in the two clients are the same, with the only difference that in\nthe asyncio client most methods are implemented as coroutines.','implement most methods as coroutines',0,'',''),(9543,'python-socketio','The methods in the two clients are the same, with the only difference that in\nthe asyncio client most methods are implemented as coroutines.','implement most methods in asyncio client',0,'',''),(9544,'python-socketio','To install the standard Python client along with its dependencies, use the\nfollowing command:','install standard Python client along_with dependencies',1,'https://python-socketio.readthedocs.io/en/latest/client.html',''),(9545,'python-socketio','To install the standard Python client along with its dependencies, use the\nfollowing command:','use following command',1,'https://python-socketio.readthedocs.io/en/latest/client.html',''),(9546,'python-socketio','To install the standard Python client along with its dependencies, use the\nfollowing command:','use dependencies',1,'https://python-socketio.readthedocs.io/en/latest/client.html',''),(9547,'python-socketio','If instead you plan on using the asyncio client, then use this:','use asyncio client',1,'https://python-socketio.readthedocs.io/en/latest/client.html',''),(9548,'python-socketio','To instantiate an Socket.IO client, simply create an instance of the\nappropriate client class:','instantiate Socket.IO client',1,'https://python-socketio.readthedocs.io/en/latest/client.html',''),(9549,'python-socketio','To instantiate an Socket.IO client, simply create an instance of the\nappropriate client class:','create instance of appropriate client class',1,'https://python-socketio.readthedocs.io/en/latest/client.html',''),(9550,'python-socketio','In the first example the event name is obtained from the name of the\nhandler function. The second example is slightly more verbose, but it\nallows the event name to be different than the function name or to include\ncharacters that are illegal in function names, such as spaces.','obtain event name from name',1,'https://python-socketio.readthedocs.io/en/latest/client.html',''),(9551,'python-socketio','In the first example the event name is obtained from the name of the\nhandler function. The second example is slightly more verbose, but it\nallows the event name to be different than the function name or to include\ncharacters that are illegal in function names, such as spaces.','include characters such_as spaces',1,'https://python-socketio.readthedocs.io/en/latest/client.html',''),(9552,'python-socketio','If the server includes arguments with an event, those are passed to the\nhandler function as arguments.','include arguments with event',0,'',''),(9553,'python-socketio','If the server includes arguments with an event, those are passed to the\nhandler function as arguments.','pass  as arguments',0,'',''),(9554,'python-socketio','If the server includes arguments with an event, those are passed to the\nhandler function as arguments.','pass  to handler function',0,'',''),(9555,'python-socketio','A “catch-all” event handler is invoked for any events that do not have an\nevent handler. You can define a catch-all handler using \'*\' as event name:','define catch-all handler',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9556,'python-socketio','A “catch-all” event handler is invoked for any events that do not have an\nevent handler. You can define a catch-all handler using \'*\' as event name:','use * as event name',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9557,'python-socketio','Asyncio clients can also use a coroutine:','use coroutine',1,'https://python-socketio.readthedocs.io/en/latest/client.html',''),(9558,'python-socketio','A catch-all event handler receives the event name as a first argument. The\nremaining arguments are the same as for a regular event handler.','receive event name as first argument',0,'',''),(9559,'python-socketio','The connect_error handler is invoked when a connection attempt fails. If\nthe server provides arguments, these are passed on to the handler. The server\ncan use an argument to provide information to the client regarding the\nconnection failure.','provide arguments',0,'',''),(9560,'python-socketio','The connect_error handler is invoked when a connection attempt fails. If\nthe server provides arguments, these are passed on to the handler. The server\ncan use an argument to provide information to the client regarding the\nconnection failure.','use argument',0,'',''),(9561,'python-socketio','The connect_error handler is invoked when a connection attempt fails. If\nthe server provides arguments, these are passed on to the handler. The server\ncan use an argument to provide information to the client regarding the\nconnection failure.','provide information to client',0,'',''),(9562,'python-socketio','The connection to a server is established by calling the connect()\nmethod:','call connect() method',1,'https://python-socketio.readthedocs.io/en/latest/client.html',''),(9563,'python-socketio','Upon connection, the server assigns the client a unique session identifier.\nThe applicaction can find this identifier in the sid attribute:','assign  upon connection',1,'https://python-socketio.readthedocs.io/en/latest/client.html',''),(9564,'python-socketio','Upon connection, the server assigns the client a unique session identifier.\nThe applicaction can find this identifier in the sid attribute:','find identifier in sid attribute',1,'https://python-socketio.readthedocs.io/en/latest/client.html',''),(9565,'python-socketio','The client can emit an event to the server using the emit() method:','use emit() method',1,'https://python-socketio.readthedocs.io/en/latest/client.html',''),(9566,'python-socketio','The single argument provided to the method is the data that is passed on\nto the server. The data can be of type str, bytes, dict,\nlist or tuple. When sending a tuple, the elements in it need to\nbe of any of the other four allowed types. The elements of the tuple will be\npassed as multiple arguments to the server-side event handler function.','pass data',0,'',''),(9567,'python-socketio','The single argument provided to the method is the data that is passed on\nto the server. The data can be of type str, bytes, dict,\nlist or tuple. When sending a tuple, the elements in it need to\nbe of any of the other four allowed types. The elements of the tuple will be\npassed as multiple arguments to the server-side event handler function.','send tuple',0,'',''),(9568,'python-socketio','The single argument provided to the method is the data that is passed on\nto the server. The data can be of type str, bytes, dict,\nlist or tuple. When sending a tuple, the elements in it need to\nbe of any of the other four allowed types. The elements of the tuple will be\npassed as multiple arguments to the server-side event handler function.','pass elements as multiple arguments',0,'',''),(9569,'python-socketio','The single argument provided to the method is the data that is passed on\nto the server. The data can be of type str, bytes, dict,\nlist or tuple. When sending a tuple, the elements in it need to\nbe of any of the other four allowed types. The elements of the tuple will be\npassed as multiple arguments to the server-side event handler function.','pass elements of tuple',0,'',''),(9570,'python-socketio','The single argument provided to the method is the data that is passed on\nto the server. The data can be of type str, bytes, dict,\nlist or tuple. When sending a tuple, the elements in it need to\nbe of any of the other four allowed types. The elements of the tuple will be\npassed as multiple arguments to the server-side event handler function.','pass elements to server-side event handler function',0,'',''),(9571,'python-socketio','When a server emits an event to a client, it can optionally provide a\ncallback function, to be invoked as a way of acknowledgment that the server\nhas processed the event. While this is entirely managed by the server, the\nclient can provide a list of return values that are to be passed on to the\ncallback function set up by the server. This is achieved simply by returning\nthe desired values from the handler function:','provide callback function',1,'https://python-socketio.readthedocs.io/en/latest/client.html',''),(9572,'python-socketio','When a server emits an event to a client, it can optionally provide a\ncallback function, to be invoked as a way of acknowledgment that the server\nhas processed the event. While this is entirely managed by the server, the\nclient can provide a list of return values that are to be passed on to the\ncallback function set up by the server. This is achieved simply by returning\nthe desired values from the handler function:','process event',1,'https://python-socketio.readthedocs.io/en/latest/client.html',''),(9573,'python-socketio','When a server emits an event to a client, it can optionally provide a\ncallback function, to be invoked as a way of acknowledgment that the server\nhas processed the event. While this is entirely managed by the server, the\nclient can provide a list of return values that are to be passed on to the\ncallback function set up by the server. This is achieved simply by returning\nthe desired values from the handler function:','provide list of return values',1,'https://python-socketio.readthedocs.io/en/latest/client.html',''),(9574,'python-socketio','When a server emits an event to a client, it can optionally provide a\ncallback function, to be invoked as a way of acknowledgment that the server\nhas processed the event. While this is entirely managed by the server, the\nclient can provide a list of return values that are to be passed on to the\ncallback function set up by the server. This is achieved simply by returning\nthe desired values from the handler function:','return desired values from handler function',1,'https://python-socketio.readthedocs.io/en/latest/client.html',''),(9575,'python-socketio','Likewise, the client can request a callback function to be invoked after the\nserver has processed an event. The socketio.Server.emit() method has an\noptional callback argument that can be set to a callable. If this\nargument is given, the callable will be invoked after the server has processed\nthe event, and any values returned by the server handler will be passed as\narguments to this function.','request callback function',0,'',''),(9576,'python-socketio','Likewise, the client can request a callback function to be invoked after the\nserver has processed an event. The socketio.Server.emit() method has an\noptional callback argument that can be set to a callable. If this\nargument is given, the callable will be invoked after the server has processed\nthe event, and any values returned by the server handler will be passed as\narguments to this function.','process event',0,'',''),(9577,'python-socketio','Likewise, the client can request a callback function to be invoked after the\nserver has processed an event. The socketio.Server.emit() method has an\noptional callback argument that can be set to a callable. If this\nargument is given, the callable will be invoked after the server has processed\nthe event, and any values returned by the server handler will be passed as\narguments to this function.','set optional callback argument to callable',0,'',''),(9578,'python-socketio','Likewise, the client can request a callback function to be invoked after the\nserver has processed an event. The socketio.Server.emit() method has an\noptional callback argument that can be set to a callable. If this\nargument is given, the callable will be invoked after the server has processed\nthe event, and any values returned by the server handler will be passed as\narguments to this function.','process event',0,'',''),(9579,'python-socketio','Likewise, the client can request a callback function to be invoked after the\nserver has processed an event. The socketio.Server.emit() method has an\noptional callback argument that can be set to a callable. If this\nargument is given, the callable will be invoked after the server has processed\nthe event, and any values returned by the server handler will be passed as\narguments to this function.','pass values as arguments',0,'',''),(9580,'python-socketio','Likewise, the client can request a callback function to be invoked after the\nserver has processed an event. The socketio.Server.emit() method has an\noptional callback argument that can be set to a callable. If this\nargument is given, the callable will be invoked after the server has processed\nthe event, and any values returned by the server handler will be passed as\narguments to this function.','pass values to function',0,'',''),(9581,'python-socketio','The Socket.IO protocol supports multiple logical connections, all multiplexed\non the same physical connection. Clients can open multiple connections by\nspecifying a different namespace on each. Namespaces use a path syntax\nstarting with a forward slash. A list of namespaces can be given by the client\nin the connect() call. For example, this example creates two logical\nconnections, the default one plus a second connection under the /chat\nnamespace:','support multiple logical connections',1,'https://python-socketio.readthedocs.io/en/latest/client.html',''),(9582,'python-socketio','The Socket.IO protocol supports multiple logical connections, all multiplexed\non the same physical connection. Clients can open multiple connections by\nspecifying a different namespace on each. Namespaces use a path syntax\nstarting with a forward slash. A list of namespaces can be given by the client\nin the connect() call. For example, this example creates two logical\nconnections, the default one plus a second connection under the /chat\nnamespace:','open multiple connections by specifying',1,'https://python-socketio.readthedocs.io/en/latest/client.html',''),(9583,'python-socketio','The Socket.IO protocol supports multiple logical connections, all multiplexed\non the same physical connection. Clients can open multiple connections by\nspecifying a different namespace on each. Namespaces use a path syntax\nstarting with a forward slash. A list of namespaces can be given by the client\nin the connect() call. For example, this example creates two logical\nconnections, the default one plus a second connection under the /chat\nnamespace:','specify different namespace',1,'https://python-socketio.readthedocs.io/en/latest/client.html',''),(9584,'python-socketio','The Socket.IO protocol supports multiple logical connections, all multiplexed\non the same physical connection. Clients can open multiple connections by\nspecifying a different namespace on each. Namespaces use a path syntax\nstarting with a forward slash. A list of namespaces can be given by the client\nin the connect() call. For example, this example creates two logical\nconnections, the default one plus a second connection under the /chat\nnamespace:','use path syntax',1,'https://python-socketio.readthedocs.io/en/latest/client.html',''),(9585,'python-socketio','The Socket.IO protocol supports multiple logical connections, all multiplexed\non the same physical connection. Clients can open multiple connections by\nspecifying a different namespace on each. Namespaces use a path syntax\nstarting with a forward slash. A list of namespaces can be given by the client\nin the connect() call. For example, this example creates two logical\nconnections, the default one plus a second connection under the /chat\nnamespace:','create second connection under / chat namespace',1,'https://python-socketio.readthedocs.io/en/latest/client.html',''),(9586,'python-socketio','The Socket.IO protocol supports multiple logical connections, all multiplexed\non the same physical connection. Clients can open multiple connections by\nspecifying a different namespace on each. Namespaces use a path syntax\nstarting with a forward slash. A list of namespaces can be given by the client\nin the connect() call. For example, this example creates two logical\nconnections, the default one plus a second connection under the /chat\nnamespace:','create logical connections under / chat namespace',1,'https://python-socketio.readthedocs.io/en/latest/client.html',''),(9587,'python-socketio','To define event handlers on a namespace, the namespace argument must be\nadded to the corresponding decorator:','define event handlers on namespace',1,'https://python-socketio.readthedocs.io/en/latest/client.html',''),(9588,'python-socketio','To define event handlers on a namespace, the namespace argument must be\nadded to the corresponding decorator:','add namespace argument to corresponding decorator',1,'https://python-socketio.readthedocs.io/en/latest/client.html',''),(9589,'python-socketio','Likewise, the client can emit an event to the server on a namespace by\nproviding its in the emit() call:','provide  in emit() call',1,'https://python-socketio.readthedocs.io/en/latest/client.html',''),(9590,'python-socketio','If the namespaces argument of the connect() call isn’t given, any\nnamespaces used in event handlers are automatically connected.','use  in event handlers',0,'',''),(9591,'python-socketio','As an alternative to the decorator-based event handlers, the event handlers\nthat belong to a namespace can be created as methods of a subclass of\nsocketio.ClientNamespace:','create event handlers as alternative',1,'https://python-socketio.readthedocs.io/en/latest/client.html',''),(9592,'python-socketio','As an alternative to the decorator-based event handlers, the event handlers\nthat belong to a namespace can be created as methods of a subclass of\nsocketio.ClientNamespace:','create event handlers as methods',1,'https://python-socketio.readthedocs.io/en/latest/client.html',''),(9593,'python-socketio','For asyncio based servers, namespaces must inherit from\nsocketio.AsyncClientNamespace, and can define event handlers as\ncoroutines if desired:','define event handlers as coroutines',1,'https://python-socketio.readthedocs.io/en/latest/client.html',''),(9594,'python-socketio','For asyncio based servers, namespaces must inherit from\nsocketio.AsyncClientNamespace, and can define event handlers as\ncoroutines if desired:','inherit  for asyncio',1,'https://python-socketio.readthedocs.io/en/latest/client.html',''),(9595,'python-socketio','For asyncio based servers, namespaces must inherit from\nsocketio.AsyncClientNamespace, and can define event handlers as\ncoroutines if desired:','inherit  from socketio.AsyncClientNamespace',1,'https://python-socketio.readthedocs.io/en/latest/client.html',''),(9596,'python-socketio','When class-based namespaces are used, any events received by the client are\ndispatched to a method named as the event name with the on_ prefix. For\nexample, event my_event will be handled by a method named on_my_event.\nIf an event is received for which there is no corresponding method defined in\nthe namespace class, then the event is ignored. All event names used in\nclass-based namespaces must use characters that are legal in method names.','use class-based namespaces',0,'',''),(9597,'python-socketio','When class-based namespaces are used, any events received by the client are\ndispatched to a method named as the event name with the on_ prefix. For\nexample, event my_event will be handled by a method named on_my_event.\nIf an event is received for which there is no corresponding method defined in\nthe namespace class, then the event is ignored. All event names used in\nclass-based namespaces must use characters that are legal in method names.','handle event my_event',0,'',''),(9598,'python-socketio','When class-based namespaces are used, any events received by the client are\ndispatched to a method named as the event name with the on_ prefix. For\nexample, event my_event will be handled by a method named on_my_event.\nIf an event is received for which there is no corresponding method defined in\nthe namespace class, then the event is ignored. All event names used in\nclass-based namespaces must use characters that are legal in method names.','receive event',0,'',''),(9599,'python-socketio','When class-based namespaces are used, any events received by the client are\ndispatched to a method named as the event name with the on_ prefix. For\nexample, event my_event will be handled by a method named on_my_event.\nIf an event is received for which there is no corresponding method defined in\nthe namespace class, then the event is ignored. All event names used in\nclass-based namespaces must use characters that are legal in method names.','define  in namespace class',0,'',''),(9600,'python-socketio','When class-based namespaces are used, any events received by the client are\ndispatched to a method named as the event name with the on_ prefix. For\nexample, event my_event will be handled by a method named on_my_event.\nIf an event is received for which there is no corresponding method defined in\nthe namespace class, then the event is ignored. All event names used in\nclass-based namespaces must use characters that are legal in method names.','ignore event',0,'',''),(9601,'python-socketio','When class-based namespaces are used, any events received by the client are\ndispatched to a method named as the event name with the on_ prefix. For\nexample, event my_event will be handled by a method named on_my_event.\nIf an event is received for which there is no corresponding method defined in\nthe namespace class, then the event is ignored. All event names used in\nclass-based namespaces must use characters that are legal in method names.','use characters',0,'',''),(9602,'python-socketio','When class-based namespaces are used, any events received by the client are\ndispatched to a method named as the event name with the on_ prefix. For\nexample, event my_event will be handled by a method named on_my_event.\nIf an event is received for which there is no corresponding method defined in\nthe namespace class, then the event is ignored. All event names used in\nclass-based namespaces must use characters that are legal in method names.','use  in class-based namespaces',0,'',''),(9603,'python-socketio','As a convenience to methods defined in a class-based namespace, the namespace\ninstance includes versions of several of the methods in the\nsocketio.Client and socketio.AsyncClient classes that\ndefault to the proper namespace when the namespace argument is not given.','include versions as convenience',0,'',''),(9604,'python-socketio','As a convenience to methods defined in a class-based namespace, the namespace\ninstance includes versions of several of the methods in the\nsocketio.Client and socketio.AsyncClient classes that\ndefault to the proper namespace when the namespace argument is not given.','define  in class-based namespace',0,'',''),(9605,'python-socketio','At any time the client can request to be disconnected from the server by\ninvoking the disconnect() method:','request client',1,'https://python-socketio.readthedocs.io/en/latest/client.html',''),(9606,'python-socketio','When a client connection to the server is established, a few background\ntasks will be spawned to keep the connection alive and handle incoming\nevents. The application running on the main thread is free to do any\nwork, as this is not going to prevent the functioning of the Socket.IO\nclient.','handle incoming events',0,'',''),(9607,'python-socketio','When a client connection to the server is established, a few background\ntasks will be spawned to keep the connection alive and handle incoming\nevents. The application running on the main thread is free to do any\nwork, as this is not going to prevent the functioning of the Socket.IO\nclient.','prevent functioning of Socket.IO client',0,'',''),(9608,'python-socketio','When a client connection to the server is established, a few background\ntasks will be spawned to keep the connection alive and handle incoming\nevents. The application running on the main thread is free to do any\nwork, as this is not going to prevent the functioning of the Socket.IO\nclient.','run  on main thread',0,'',''),(9609,'python-socketio','If the application does not have anything to do in the main thread and\njust wants to wait until the connection with the server ends, it can call\nthe wait() method:','call wait() method',1,'https://python-socketio.readthedocs.io/en/latest/client.html',''),(9610,'python-socketio','For the convenience of the application, a helper function is provided to\nstart a custom background task:','provide helper function for convenience',1,'https://python-socketio.readthedocs.io/en/latest/client.html',''),(9611,'python-socketio','The arguments passed to this method are the background function and any\npositional or keyword arguments to invoke the function with.','pass  to method',1,'https://python-socketio.readthedocs.io/en/latest/client.html',''),(9612,'python-socketio','The sleep() method is a second convenience function that is provided for\nthe benefit of applications working with background tasks of their own:','provide second convenience function for benefit',1,'https://python-socketio.readthedocs.io/en/latest/client.html',''),(9613,'python-socketio','The single argument passed to the method is the number of seconds to sleep\nfor.','pass  to method',0,'',''),(9614,'python-socketio','To help you debug issues, the client can be configured to output logs to the\nterminal:','configure client to terminal',1,'https://python-socketio.readthedocs.io/en/latest/client.html',''),(9615,'python-socketio','To help you debug issues, the client can be configured to output logs to the\nterminal:','configure client to output logs',1,'https://python-socketio.readthedocs.io/en/latest/client.html',''),(9616,'python-socketio','The logger argument controls logging related to the Socket.IO protocol,\nwhile engineio_logger controls logs that originate in the low-level\nEngine.IO transport. These arguments can be set to True to output logs to\nstderr, or to an object compatible with Python’s logging package\nwhere the logs should be emitted to. A value of False disables logging.','log  to object compatible',0,'',''),(9617,'python-socketio','The logger argument controls logging related to the Socket.IO protocol,\nwhile engineio_logger controls logs that originate in the low-level\nEngine.IO transport. These arguments can be set to True to output logs to\nstderr, or to an object compatible with Python’s logging package\nwhere the logs should be emitted to. A value of False disables logging.','log  to stderr',0,'',''),(9618,'python-socketio','The logger argument controls logging related to the Socket.IO protocol,\nwhile engineio_logger controls logs that originate in the low-level\nEngine.IO transport. These arguments can be set to True to output logs to\nstderr, or to an object compatible with Python’s logging package\nwhere the logs should be emitted to. A value of False disables logging.','set arguments',0,'',''),(9619,'python-socketio','Logging can help identify the cause of connection problems, unexpected\ndisconnections and other issues.','identify cause of connection problems',0,'',''),(9620,'python-socketio','Logging can help identify the cause of connection problems, unexpected\ndisconnections and other issues.','identify cause of unexpected disconnections',0,'',''),(9621,'python-socketio','Logging can help identify the cause of connection problems, unexpected\ndisconnections and other issues.','identify cause of other issues',0,'',''),(9622,'python-socketio','Please activate JavaScript to enable the search\n    functionality.','activate JavaScript',0,'',''),(9623,'python-socketio','Please activate JavaScript to enable the search\n    functionality.','enable search',0,'',''),(9624,'python-socketio','From here you can search these documents. Enter your search\n    words into the box below and click \"search\". Note that the search\n    function will automatically search for all of the words. Pages\n    containing fewer words won\'t appear in the result list.','search documents',0,'',''),(9625,'python-socketio','From here you can search these documents. Enter your search\n    words into the box below and click \"search\". Note that the search\n    function will automatically search for all of the words. Pages\n    containing fewer words won\'t appear in the result list.','enter search words into box',0,'',''),(9626,'python-socketio','Socket.IO is a transport protocol that enables real-time bidirectional\nevent-based communication between clients (typically, though not always,\nweb browsers) and a server. The official implementations of the client\nand server components are written in JavaScript. This package provides\nPython implementations of both, each with standard and asyncio variants.','enable real-time bidirectional event-based communication between server',0,'',''),(9627,'python-socketio','Socket.IO is a transport protocol that enables real-time bidirectional\nevent-based communication between clients (typically, though not always,\nweb browsers) and a server. The official implementations of the client\nand server components are written in JavaScript. This package provides\nPython implementations of both, each with standard and asyncio variants.','enable real-time bidirectional event-based communication between clients',0,'',''),(9628,'python-socketio','Socket.IO is a transport protocol that enables real-time bidirectional\nevent-based communication between clients (typically, though not always,\nweb browsers) and a server. The official implementations of the client\nand server components are written in JavaScript. This package provides\nPython implementations of both, each with standard and asyncio variants.','enable transport protocol between server',0,'',''),(9629,'python-socketio','Socket.IO is a transport protocol that enables real-time bidirectional\nevent-based communication between clients (typically, though not always,\nweb browsers) and a server. The official implementations of the client\nand server components are written in JavaScript. This package provides\nPython implementations of both, each with standard and asyncio variants.','enable transport protocol between clients',0,'',''),(9630,'python-socketio','Socket.IO is a transport protocol that enables real-time bidirectional\nevent-based communication between clients (typically, though not always,\nweb browsers) and a server. The official implementations of the client\nand server components are written in JavaScript. This package provides\nPython implementations of both, each with standard and asyncio variants.','write official implementations in JavaScript',0,'',''),(9631,'python-socketio','Socket.IO is a transport protocol that enables real-time bidirectional\nevent-based communication between clients (typically, though not always,\nweb browsers) and a server. The official implementations of the client\nand server components are written in JavaScript. This package provides\nPython implementations of both, each with standard and asyncio variants.','write official implementations of client server components',0,'',''),(9632,'python-socketio','Socket.IO is a transport protocol that enables real-time bidirectional\nevent-based communication between clients (typically, though not always,\nweb browsers) and a server. The official implementations of the client\nand server components are written in JavaScript. This package provides\nPython implementations of both, each with standard and asyncio variants.','provide Python implementations',0,'',''),(9633,'python-socketio','The Socket.IO protocol has been through a number of revisions, and some of these\nintroduced backward incompatible changes, which means that the client and the\nserver must use compatible versions for everything to work.','introduce incompatible changes',0,'',''),(9634,'python-socketio','The Socket.IO protocol has been through a number of revisions, and some of these\nintroduced backward incompatible changes, which means that the client and the\nserver must use compatible versions for everything to work.','use compatible versions',0,'',''),(9635,'python-socketio','If you are using the Python client and server, the easiest way to ensure compatibility\nis to use the same version of this package for the client and the server. If you are\nusing this package with a different client or server, then you must ensure the\nversions are compatible.','use Python client',0,'',''),(9636,'python-socketio','If you are using the Python client and server, the easiest way to ensure compatibility\nis to use the same version of this package for the client and the server. If you are\nusing this package with a different client or server, then you must ensure the\nversions are compatible.','use server',0,'',''),(9637,'python-socketio','If you are using the Python client and server, the easiest way to ensure compatibility\nis to use the same version of this package for the client and the server. If you are\nusing this package with a different client or server, then you must ensure the\nversions are compatible.','use same version of package',0,'',''),(9638,'python-socketio','If you are using the Python client and server, the easiest way to ensure compatibility\nis to use the same version of this package for the client and the server. If you are\nusing this package with a different client or server, then you must ensure the\nversions are compatible.','use package with different client',0,'',''),(9639,'python-socketio','If you are using the Python client and server, the easiest way to ensure compatibility\nis to use the same version of this package for the client and the server. If you are\nusing this package with a different client or server, then you must ensure the\nversions are compatible.','use package with server',0,'',''),(9640,'python-socketio','The example that follows shows a simple Python client:','show simple Python client',1,'https://python-socketio.readthedocs.io/en/latest/intro.html',''),(9641,'python-socketio','The following application is a basic server example that uses the Eventlet\nasynchronous server:','use Eventlet asynchronous server',1,'https://python-socketio.readthedocs.io/en/latest/intro.html',''),(9642,'python-socketio','The following application is a basic server example that uses the Eventlet\nasynchronous server:','use basic server example',1,'https://python-socketio.readthedocs.io/en/latest/intro.html',''),(9643,'python-socketio','The methods in the two servers are the same, with the only difference that in\nthe asyncio server most methods are implemented as coroutines.','implement most methods as coroutines',0,'',''),(9644,'python-socketio','The methods in the two servers are the same, with the only difference that in\nthe asyncio server most methods are implemented as coroutines.','implement most methods in asyncio server',0,'',''),(9645,'python-socketio','To install the Socket.IO server along with its dependencies, use the following\ncommand:','use following command',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9646,'python-socketio','A Socket.IO server is an instance of class socketio.Server. This\ninstance can be transformed into a standard WSGI application by wrapping it\nwith the socketio.WSGIApp class:','wrap  with socketio.WSGIApp class',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9647,'python-socketio','For asyncio based servers, the socketio.AsyncServer class provides\nthe same functionality, but in a coroutine friendly format. If desired, The\nsocketio.ASGIApp class can transform the server into a standard\nASGI application:','provide same functionality for asyncio',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9648,'python-socketio','These two wrappers can also act as middlewares, forwarding any traffic that is\nnot intended to the Socket.IO server to another application. This allows\nSocket.IO servers to integrate easily into existing WSGI or ASGI applications:','integrate  into existing WSGI',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9649,'python-socketio','These two wrappers can also act as middlewares, forwarding any traffic that is\nnot intended to the Socket.IO server to another application. This allows\nSocket.IO servers to integrate easily into existing WSGI or ASGI applications:','integrate  into ASGI applications',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9650,'python-socketio','The Socket.IO server can be configured to serve static files to clients. This\nis particularly useful to deliver HTML, CSS and JavaScript files to clients\nwhen this package is used without a companion web framework.','configure Socket.IO server',0,'',''),(9651,'python-socketio','The Socket.IO server can be configured to serve static files to clients. This\nis particularly useful to deliver HTML, CSS and JavaScript files to clients\nwhen this package is used without a companion web framework.','use package without companion web framework',0,'',''),(9652,'python-socketio','Static files are configured with a Python dictionary in which each key/value\npair is a static file mapping rule. In its simplest form, this dictionary has\none or more static file URLs as keys, and the corresponding files in the server\nas values:','configure static files with Python dictionary',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9653,'python-socketio','With this example configuration, when the server receives a request for /\n(the root URL) it will return the contents of the file latency.html in the\ncurrent directory, and will assign a content type based on the file extension,\nin this case text/html.','receive request',0,'',''),(9654,'python-socketio','Files with the .html, .css, .js, .json, .jpg, .png,\n.gif and .txt file extensions are automatically recognized and\nassigned the correct content type. For files with other file extensions or\nwith no file extension, the application/octet-stream content type is used\nas a default.','assign txt file extensions',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9655,'python-socketio','Files with the .html, .css, .js, .json, .jpg, .png,\n.gif and .txt file extensions are automatically recognized and\nassigned the correct content type. For files with other file extensions or\nwith no file extension, the application/octet-stream content type is used\nas a default.','use application/octet-stream content type as default',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9656,'python-socketio','Files with the .html, .css, .js, .json, .jpg, .png,\n.gif and .txt file extensions are automatically recognized and\nassigned the correct content type. For files with other file extensions or\nwith no file extension, the application/octet-stream content type is used\nas a default.','use application/octet-stream content type for files',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9657,'python-socketio','It is also possible to configure an entire directory in a single rule, so that all\nthe files in it are served as static files:','configure entire directory in single rule',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9658,'python-socketio','In this example any files with URLs starting with /static will be served\ndirectly from the public folder in the current directory, so for example,\nthe URL /static/index.html will return local file ./public/index.html\nand the URL /static/css/styles.css will return local file\n./public/css/styles.css.','return local file',0,'',''),(9659,'python-socketio','In this example any files with URLs starting with /static will be served\ndirectly from the public folder in the current directory, so for example,\nthe URL /static/index.html will return local file ./public/index.html\nand the URL /static/css/styles.css will return local file\n./public/css/styles.css.','return local file',0,'',''),(9660,'python-socketio','If a URL that ends in a / is requested, then a default filename of\nindex.html is appended to it. In the previous example, a request for the\n/static/ URL would return local file ./public/index.html. The default\nfilename to serve for slash-ending URLs can be set in the static files\ndictionary with an empty key:','return local file',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9661,'python-socketio','If a URL that ends in a / is requested, then a default filename of\nindex.html is appended to it. In the previous example, a request for the\n/static/ URL would return local file ./public/index.html. The default\nfilename to serve for slash-ending URLs can be set in the static files\ndictionary with an empty key:','set slash-ending urls with empty key',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9662,'python-socketio','If a URL that ends in a / is requested, then a default filename of\nindex.html is appended to it. In the previous example, a request for the\n/static/ URL would return local file ./public/index.html. The default\nfilename to serve for slash-ending URLs can be set in the static files\ndictionary with an empty key:','set slash-ending urls in static files dictionary',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9663,'python-socketio','With this configuration, a request for /static/ would return\nlocal file ./public/image.gif. A non-standard content type can also be\nspecified if needed:','return local file with configuration',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9664,'python-socketio','With this configuration, a request for /static/ would return\nlocal file ./public/image.gif. A non-standard content type can also be\nspecified if needed:','specify non-standard content type',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9665,'python-socketio','In the first example the event name is obtained from the name of the handler\nfunction. The second example is slightly more verbose, but it allows the event\nname to be different than the function name or to include characters that are\nillegal in function names, such as spaces.','obtain event name from name',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9666,'python-socketio','In the first example the event name is obtained from the name of the handler\nfunction. The second example is slightly more verbose, but it allows the event\nname to be different than the function name or to include characters that are\nillegal in function names, such as spaces.','include characters such_as spaces',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9667,'python-socketio','Asyncio servers can also use a coroutine:','use coroutine',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9668,'python-socketio','The connect event is an ideal place to perform user authentication, and\nany necessary mapping between user entities in the application and the sid\nthat was assigned to the client. The environ argument is a dictionary in\nstandard WSGI format containing the request information, including HTTP\nheaders. The auth argument contains any authentication details passed by\nthe client, or None if the client did not pass anything. After inspecting\nthe request, the connect event handler can return False to reject the\nconnection with the client.','perform user authentication',0,'',''),(9669,'python-socketio','The connect event is an ideal place to perform user authentication, and\nany necessary mapping between user entities in the application and the sid\nthat was assigned to the client. The environ argument is a dictionary in\nstandard WSGI format containing the request information, including HTTP\nheaders. The auth argument contains any authentication details passed by\nthe client, or None if the client did not pass anything. After inspecting\nthe request, the connect event handler can return False to reject the\nconnection with the client.','assign necessary mapping to client',0,'',''),(9670,'python-socketio','The connect event is an ideal place to perform user authentication, and\nany necessary mapping between user entities in the application and the sid\nthat was assigned to the client. The environ argument is a dictionary in\nstandard WSGI format containing the request information, including HTTP\nheaders. The auth argument contains any authentication details passed by\nthe client, or None if the client did not pass anything. After inspecting\nthe request, the connect event handler can return False to reject the\nconnection with the client.','assign necessary mapping between user entities',0,'',''),(9671,'python-socketio','The connect event is an ideal place to perform user authentication, and\nany necessary mapping between user entities in the application and the sid\nthat was assigned to the client. The environ argument is a dictionary in\nstandard WSGI format containing the request information, including HTTP\nheaders. The auth argument contains any authentication details passed by\nthe client, or None if the client did not pass anything. After inspecting\nthe request, the connect event handler can return False to reject the\nconnection with the client.','return  after inspecting',0,'',''),(9672,'python-socketio','Sometimes it is useful to pass data back to the client being rejected. In that\ncase instead of returning False\nsocketio.exceptions.ConnectionRefusedError can be raised, and all of\nits arguments will be sent to the client with the rejection message:','pass data',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9673,'python-socketio','Sometimes it is useful to pass data back to the client being rejected. In that\ncase instead of returning False\nsocketio.exceptions.ConnectionRefusedError can be raised, and all of\nits arguments will be sent to the client with the rejection message:','return false',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9674,'python-socketio','Sometimes it is useful to pass data back to the client being rejected. In that\ncase instead of returning False\nsocketio.exceptions.ConnectionRefusedError can be raised, and all of\nits arguments will be sent to the client with the rejection message:','raise socketio.exceptions.ConnectionRefusedError in case',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9675,'python-socketio','Sometimes it is useful to pass data back to the client being rejected. In that\ncase instead of returning False\nsocketio.exceptions.ConnectionRefusedError can be raised, and all of\nits arguments will be sent to the client with the rejection message:','send  to client',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9676,'python-socketio','Socket.IO is a bidirectional protocol, so at any time the server can send an\nevent to its connected clients. The socketio.Server.emit() method is\nused for this task:','send event at time',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9677,'python-socketio','Socket.IO is a bidirectional protocol, so at any time the server can send an\nevent to its connected clients. The socketio.Server.emit() method is\nused for this task:','send event to connected clients',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9678,'python-socketio','Socket.IO is a bidirectional protocol, so at any time the server can send an\nevent to its connected clients. The socketio.Server.emit() method is\nused for this task:','use socketio.Server.emit() method for task',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9679,'python-socketio','Sometimes the server may want to send an event just to a particular client.\nThis can be achieved by adding a room argument to the emit call:','send event to particular client',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9680,'python-socketio','Sometimes the server may want to send an event just to a particular client.\nThis can be achieved by adding a room argument to the emit call:','add room argument to emit call',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9681,'python-socketio','The socketio.Server.emit() method takes an event name, a message payload\nof type str, bytes, list, dict or tuple, and the recipient\nroom. When sending a tuple, the elements in it need to be of any of the\nother four allowed types. The elements of the tuple will be passed as multiple\narguments to the client-side event handler function. The room argument is\nused to identify the client that should receive the event, and is set to the\nsid value assigned to that client’s connection with the server. When\nomitted, the event is broadcasted to all connected clients.','send tuple',0,'',''),(9682,'python-socketio','The socketio.Server.emit() method takes an event name, a message payload\nof type str, bytes, list, dict or tuple, and the recipient\nroom. When sending a tuple, the elements in it need to be of any of the\nother four allowed types. The elements of the tuple will be passed as multiple\narguments to the client-side event handler function. The room argument is\nused to identify the client that should receive the event, and is set to the\nsid value assigned to that client’s connection with the server. When\nomitted, the event is broadcasted to all connected clients.','pass elements as multiple arguments',0,'',''),(9683,'python-socketio','The socketio.Server.emit() method takes an event name, a message payload\nof type str, bytes, list, dict or tuple, and the recipient\nroom. When sending a tuple, the elements in it need to be of any of the\nother four allowed types. The elements of the tuple will be passed as multiple\narguments to the client-side event handler function. The room argument is\nused to identify the client that should receive the event, and is set to the\nsid value assigned to that client’s connection with the server. When\nomitted, the event is broadcasted to all connected clients.','pass elements of tuple',0,'',''),(9684,'python-socketio','The socketio.Server.emit() method takes an event name, a message payload\nof type str, bytes, list, dict or tuple, and the recipient\nroom. When sending a tuple, the elements in it need to be of any of the\nother four allowed types. The elements of the tuple will be passed as multiple\narguments to the client-side event handler function. The room argument is\nused to identify the client that should receive the event, and is set to the\nsid value assigned to that client’s connection with the server. When\nomitted, the event is broadcasted to all connected clients.','pass elements to client-side event handler function',0,'',''),(9685,'python-socketio','The socketio.Server.emit() method takes an event name, a message payload\nof type str, bytes, list, dict or tuple, and the recipient\nroom. When sending a tuple, the elements in it need to be of any of the\nother four allowed types. The elements of the tuple will be passed as multiple\narguments to the client-side event handler function. The room argument is\nused to identify the client that should receive the event, and is set to the\nsid value assigned to that client’s connection with the server. When\nomitted, the event is broadcasted to all connected clients.','identify client',0,'',''),(9686,'python-socketio','The socketio.Server.emit() method takes an event name, a message payload\nof type str, bytes, list, dict or tuple, and the recipient\nroom. When sending a tuple, the elements in it need to be of any of the\nother four allowed types. The elements of the tuple will be passed as multiple\narguments to the client-side event handler function. The room argument is\nused to identify the client that should receive the event, and is set to the\nsid value assigned to that client’s connection with the server. When\nomitted, the event is broadcasted to all connected clients.','receive event',0,'',''),(9687,'python-socketio','The socketio.Server.emit() method takes an event name, a message payload\nof type str, bytes, list, dict or tuple, and the recipient\nroom. When sending a tuple, the elements in it need to be of any of the\nother four allowed types. The elements of the tuple will be passed as multiple\narguments to the client-side event handler function. The room argument is\nused to identify the client that should receive the event, and is set to the\nsid value assigned to that client’s connection with the server. When\nomitted, the event is broadcasted to all connected clients.','receive client',0,'',''),(9688,'python-socketio','The socketio.Server.emit() method takes an event name, a message payload\nof type str, bytes, list, dict or tuple, and the recipient\nroom. When sending a tuple, the elements in it need to be of any of the\nother four allowed types. The elements of the tuple will be passed as multiple\narguments to the client-side event handler function. The room argument is\nused to identify the client that should receive the event, and is set to the\nsid value assigned to that client’s connection with the server. When\nomitted, the event is broadcasted to all connected clients.','set room argument to sid value',0,'',''),(9689,'python-socketio','The socketio.Server.emit() method takes an event name, a message payload\nof type str, bytes, list, dict or tuple, and the recipient\nroom. When sending a tuple, the elements in it need to be of any of the\nother four allowed types. The elements of the tuple will be passed as multiple\narguments to the client-side event handler function. The room argument is\nused to identify the client that should receive the event, and is set to the\nsid value assigned to that client’s connection with the server. When\nomitted, the event is broadcasted to all connected clients.','assign  with server',0,'',''),(9690,'python-socketio','The socketio.Server.emit() method takes an event name, a message payload\nof type str, bytes, list, dict or tuple, and the recipient\nroom. When sending a tuple, the elements in it need to be of any of the\nother four allowed types. The elements of the tuple will be passed as multiple\narguments to the client-side event handler function. The room argument is\nused to identify the client that should receive the event, and is set to the\nsid value assigned to that client’s connection with the server. When\nomitted, the event is broadcasted to all connected clients.','assign  to connection',0,'',''),(9691,'python-socketio','The socketio.Server.emit() method takes an event name, a message payload\nof type str, bytes, list, dict or tuple, and the recipient\nroom. When sending a tuple, the elements in it need to be of any of the\nother four allowed types. The elements of the tuple will be passed as multiple\narguments to the client-side event handler function. The room argument is\nused to identify the client that should receive the event, and is set to the\nsid value assigned to that client’s connection with the server. When\nomitted, the event is broadcasted to all connected clients.','use room argument',0,'',''),(9692,'python-socketio','When a client sends an event to the server, it can optionally provide a\ncallback function, to be invoked as a way of acknowledgment that the server\nhas processed the event. While this is entirely managed by the client, the\nserver can provide a list of values that are to be passed on to the callback\nfunction, simply by returning them from the handler function:','send event to server',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9693,'python-socketio','When a client sends an event to the server, it can optionally provide a\ncallback function, to be invoked as a way of acknowledgment that the server\nhas processed the event. While this is entirely managed by the client, the\nserver can provide a list of values that are to be passed on to the callback\nfunction, simply by returning them from the handler function:','provide callback function',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9694,'python-socketio','When a client sends an event to the server, it can optionally provide a\ncallback function, to be invoked as a way of acknowledgment that the server\nhas processed the event. While this is entirely managed by the client, the\nserver can provide a list of values that are to be passed on to the callback\nfunction, simply by returning them from the handler function:','process event',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9695,'python-socketio','When a client sends an event to the server, it can optionally provide a\ncallback function, to be invoked as a way of acknowledgment that the server\nhas processed the event. While this is entirely managed by the client, the\nserver can provide a list of values that are to be passed on to the callback\nfunction, simply by returning them from the handler function:','provide list of values',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9696,'python-socketio','When a client sends an event to the server, it can optionally provide a\ncallback function, to be invoked as a way of acknowledgment that the server\nhas processed the event. While this is entirely managed by the client, the\nserver can provide a list of values that are to be passed on to the callback\nfunction, simply by returning them from the handler function:','return  from handler function',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9697,'python-socketio','Likewise, the server can request a callback function to be invoked after a\nclient has processed an event. The socketio.Server.emit() method has an\noptional callback argument that can be set to a callable. If this\nargument is given, the callable will be invoked after the client has processed\nthe event, and any values returned by the client will be passed as arguments\nto this function. Using callback functions when broadcasting to multiple\nclients is not recommended, as the callback function will be invoked once for\neach client that received the message.','request callback function',0,'',''),(9698,'python-socketio','Likewise, the server can request a callback function to be invoked after a\nclient has processed an event. The socketio.Server.emit() method has an\noptional callback argument that can be set to a callable. If this\nargument is given, the callable will be invoked after the client has processed\nthe event, and any values returned by the client will be passed as arguments\nto this function. Using callback functions when broadcasting to multiple\nclients is not recommended, as the callback function will be invoked once for\neach client that received the message.','process event',0,'',''),(9699,'python-socketio','Likewise, the server can request a callback function to be invoked after a\nclient has processed an event. The socketio.Server.emit() method has an\noptional callback argument that can be set to a callable. If this\nargument is given, the callable will be invoked after the client has processed\nthe event, and any values returned by the client will be passed as arguments\nto this function. Using callback functions when broadcasting to multiple\nclients is not recommended, as the callback function will be invoked once for\neach client that received the message.','set optional callback argument to callable',0,'',''),(9700,'python-socketio','Likewise, the server can request a callback function to be invoked after a\nclient has processed an event. The socketio.Server.emit() method has an\noptional callback argument that can be set to a callable. If this\nargument is given, the callable will be invoked after the client has processed\nthe event, and any values returned by the client will be passed as arguments\nto this function. Using callback functions when broadcasting to multiple\nclients is not recommended, as the callback function will be invoked once for\neach client that received the message.','process event',0,'',''),(9701,'python-socketio','Likewise, the server can request a callback function to be invoked after a\nclient has processed an event. The socketio.Server.emit() method has an\noptional callback argument that can be set to a callable. If this\nargument is given, the callable will be invoked after the client has processed\nthe event, and any values returned by the client will be passed as arguments\nto this function. Using callback functions when broadcasting to multiple\nclients is not recommended, as the callback function will be invoked once for\neach client that received the message.','pass values as arguments',0,'',''),(9702,'python-socketio','Likewise, the server can request a callback function to be invoked after a\nclient has processed an event. The socketio.Server.emit() method has an\noptional callback argument that can be set to a callable. If this\nargument is given, the callable will be invoked after the client has processed\nthe event, and any values returned by the client will be passed as arguments\nto this function. Using callback functions when broadcasting to multiple\nclients is not recommended, as the callback function will be invoked once for\neach client that received the message.','pass values to function',0,'',''),(9703,'python-socketio','Likewise, the server can request a callback function to be invoked after a\nclient has processed an event. The socketio.Server.emit() method has an\noptional callback argument that can be set to a callable. If this\nargument is given, the callable will be invoked after the client has processed\nthe event, and any values returned by the client will be passed as arguments\nto this function. Using callback functions when broadcasting to multiple\nclients is not recommended, as the callback function will be invoked once for\neach client that received the message.','use callback functions',0,'',''),(9704,'python-socketio','Likewise, the server can request a callback function to be invoked after a\nclient has processed an event. The socketio.Server.emit() method has an\noptional callback argument that can be set to a callable. If this\nargument is given, the callable will be invoked after the client has processed\nthe event, and any values returned by the client will be passed as arguments\nto this function. Using callback functions when broadcasting to multiple\nclients is not recommended, as the callback function will be invoked once for\neach client that received the message.','receive message',0,'',''),(9705,'python-socketio','Likewise, the server can request a callback function to be invoked after a\nclient has processed an event. The socketio.Server.emit() method has an\noptional callback argument that can be set to a callable. If this\nargument is given, the callable will be invoked after the client has processed\nthe event, and any values returned by the client will be passed as arguments\nto this function. Using callback functions when broadcasting to multiple\nclients is not recommended, as the callback function will be invoked once for\neach client that received the message.','receive client',0,'',''),(9706,'python-socketio','The Socket.IO protocol supports multiple logical connections, all multiplexed\non the same physical connection. Clients can open multiple connections by\nspecifying a different namespace on each. A namespace is given by the client\nas a pathname following the hostname and port. For example, connecting to\nhttp://example.com:8000/chat would open a connection to the namespace\n/chat.','support multiple logical connections',0,'',''),(9707,'python-socketio','The Socket.IO protocol supports multiple logical connections, all multiplexed\non the same physical connection. Clients can open multiple connections by\nspecifying a different namespace on each. A namespace is given by the client\nas a pathname following the hostname and port. For example, connecting to\nhttp://example.com:8000/chat would open a connection to the namespace\n/chat.','open multiple connections by specifying',0,'',''),(9708,'python-socketio','The Socket.IO protocol supports multiple logical connections, all multiplexed\non the same physical connection. Clients can open multiple connections by\nspecifying a different namespace on each. A namespace is given by the client\nas a pathname following the hostname and port. For example, connecting to\nhttp://example.com:8000/chat would open a connection to the namespace\n/chat.','specify different namespace',0,'',''),(9709,'python-socketio','Each namespace is handled independently from the others, with separate session\nIDs (sids), event handlers and rooms. It is important that applications\nthat use multiple namespaces specify the correct namespace when setting up\ntheir event handlers and rooms, using the optional namespace argument\navailable in all the methods in the socketio.Server class:','handle namespace with separate session ids handlers',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9710,'python-socketio','Each namespace is handled independently from the others, with separate session\nIDs (sids), event handlers and rooms. It is important that applications\nthat use multiple namespaces specify the correct namespace when setting up\ntheir event handlers and rooms, using the optional namespace argument\navailable in all the methods in the socketio.Server class:','handle namespace with rooms',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9711,'python-socketio','Each namespace is handled independently from the others, with separate session\nIDs (sids), event handlers and rooms. It is important that applications\nthat use multiple namespaces specify the correct namespace when setting up\ntheir event handlers and rooms, using the optional namespace argument\navailable in all the methods in the socketio.Server class:','handle namespace with event',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9712,'python-socketio','Each namespace is handled independently from the others, with separate session\nIDs (sids), event handlers and rooms. It is important that applications\nthat use multiple namespaces specify the correct namespace when setting up\ntheir event handlers and rooms, using the optional namespace argument\navailable in all the methods in the socketio.Server class:','handle namespace from others',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9713,'python-socketio','Each namespace is handled independently from the others, with separate session\nIDs (sids), event handlers and rooms. It is important that applications\nthat use multiple namespaces specify the correct namespace when setting up\ntheir event handlers and rooms, using the optional namespace argument\navailable in all the methods in the socketio.Server class:','use multiple namespaces',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9714,'python-socketio','Each namespace is handled independently from the others, with separate session\nIDs (sids), event handlers and rooms. It is important that applications\nthat use multiple namespaces specify the correct namespace when setting up\ntheir event handlers and rooms, using the optional namespace argument\navailable in all the methods in the socketio.Server class:','use applications',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9715,'python-socketio','Each namespace is handled independently from the others, with separate session\nIDs (sids), event handlers and rooms. It is important that applications\nthat use multiple namespaces specify the correct namespace when setting up\ntheir event handlers and rooms, using the optional namespace argument\navailable in all the methods in the socketio.Server class:','specify correct namespace',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9716,'python-socketio','Each namespace is handled independently from the others, with separate session\nIDs (sids), event handlers and rooms. It is important that applications\nthat use multiple namespaces specify the correct namespace when setting up\ntheir event handlers and rooms, using the optional namespace argument\navailable in all the methods in the socketio.Server class:','set up event handlers',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9717,'python-socketio','Each namespace is handled independently from the others, with separate session\nIDs (sids), event handlers and rooms. It is important that applications\nthat use multiple namespaces specify the correct namespace when setting up\ntheir event handlers and rooms, using the optional namespace argument\navailable in all the methods in the socketio.Server class:','set up rooms',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9718,'python-socketio','When emitting an event, the namespace optional argument is used to specify\nwhich namespace to send it on. When the namespace argument is omitted, the\ndefault Socket.IO namespace, which is named /, is used.','use namespace optional argument',0,'',''),(9719,'python-socketio','When emitting an event, the namespace optional argument is used to specify\nwhich namespace to send it on. When the namespace argument is omitted, the\ndefault Socket.IO namespace, which is named /, is used.','omit namespace argument',0,'',''),(9720,'python-socketio','When emitting an event, the namespace optional argument is used to specify\nwhich namespace to send it on. When the namespace argument is omitted, the\ndefault Socket.IO namespace, which is named /, is used.','use default Socket.IO namespace',0,'',''),(9721,'python-socketio','As an alternative to the decorator-based event handlers, the event handlers\nthat belong to a namespace can be created as methods of a subclass of\nsocketio.Namespace:','create event handlers as alternative',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9722,'python-socketio','As an alternative to the decorator-based event handlers, the event handlers\nthat belong to a namespace can be created as methods of a subclass of\nsocketio.Namespace:','create event handlers as methods',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9723,'python-socketio','For asyncio based servers, namespaces must inherit from\nsocketio.AsyncNamespace, and can define event handlers as coroutines\nif desired:','define event handlers as coroutines',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9724,'python-socketio','For asyncio based servers, namespaces must inherit from\nsocketio.AsyncNamespace, and can define event handlers as coroutines\nif desired:','inherit  for asyncio',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9725,'python-socketio','For asyncio based servers, namespaces must inherit from\nsocketio.AsyncNamespace, and can define event handlers as coroutines\nif desired:','inherit  from socketio.AsyncNamespace',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9726,'python-socketio','When class-based namespaces are used, any events received by the server are\ndispatched to a method named as the event name with the on_ prefix. For\nexample, event my_event will be handled by a method named on_my_event.\nIf an event is received for which there is no corresponding method defined in\nthe namespace class, then the event is ignored. All event names used in\nclass-based namespaces must use characters that are legal in method names.','use class-based namespaces',0,'',''),(9727,'python-socketio','When class-based namespaces are used, any events received by the server are\ndispatched to a method named as the event name with the on_ prefix. For\nexample, event my_event will be handled by a method named on_my_event.\nIf an event is received for which there is no corresponding method defined in\nthe namespace class, then the event is ignored. All event names used in\nclass-based namespaces must use characters that are legal in method names.','handle event my_event',0,'',''),(9728,'python-socketio','When class-based namespaces are used, any events received by the server are\ndispatched to a method named as the event name with the on_ prefix. For\nexample, event my_event will be handled by a method named on_my_event.\nIf an event is received for which there is no corresponding method defined in\nthe namespace class, then the event is ignored. All event names used in\nclass-based namespaces must use characters that are legal in method names.','receive event',0,'',''),(9729,'python-socketio','When class-based namespaces are used, any events received by the server are\ndispatched to a method named as the event name with the on_ prefix. For\nexample, event my_event will be handled by a method named on_my_event.\nIf an event is received for which there is no corresponding method defined in\nthe namespace class, then the event is ignored. All event names used in\nclass-based namespaces must use characters that are legal in method names.','define  in namespace class',0,'',''),(9730,'python-socketio','When class-based namespaces are used, any events received by the server are\ndispatched to a method named as the event name with the on_ prefix. For\nexample, event my_event will be handled by a method named on_my_event.\nIf an event is received for which there is no corresponding method defined in\nthe namespace class, then the event is ignored. All event names used in\nclass-based namespaces must use characters that are legal in method names.','ignore event',0,'',''),(9731,'python-socketio','When class-based namespaces are used, any events received by the server are\ndispatched to a method named as the event name with the on_ prefix. For\nexample, event my_event will be handled by a method named on_my_event.\nIf an event is received for which there is no corresponding method defined in\nthe namespace class, then the event is ignored. All event names used in\nclass-based namespaces must use characters that are legal in method names.','use characters',0,'',''),(9732,'python-socketio','When class-based namespaces are used, any events received by the server are\ndispatched to a method named as the event name with the on_ prefix. For\nexample, event my_event will be handled by a method named on_my_event.\nIf an event is received for which there is no corresponding method defined in\nthe namespace class, then the event is ignored. All event names used in\nclass-based namespaces must use characters that are legal in method names.','use  in class-based namespaces',0,'',''),(9733,'python-socketio','As a convenience to methods defined in a class-based namespace, the namespace\ninstance includes versions of several of the methods in the\nsocketio.Server and socketio.AsyncServer classes that default\nto the proper namespace when the namespace argument is not given.','include versions as convenience',0,'',''),(9734,'python-socketio','As a convenience to methods defined in a class-based namespace, the namespace\ninstance includes versions of several of the methods in the\nsocketio.Server and socketio.AsyncServer classes that default\nto the proper namespace when the namespace argument is not given.','define  in class-based namespace',0,'',''),(9735,'python-socketio','It is important to note that class-based namespaces are singletons. This means\nthat a single instance of a namespace class is used for all clients, and\nconsequently, a namespace instance cannot be used to store client specific\ninformation.','use single instance of namespace class',0,'',''),(9736,'python-socketio','It is important to note that class-based namespaces are singletons. This means\nthat a single instance of a namespace class is used for all clients, and\nconsequently, a namespace instance cannot be used to store client specific\ninformation.','use single instance for clients',0,'',''),(9737,'python-socketio','In the previous section the room argument of the\nsocketio.SocketIO.emit() method was used to designate a specific\nclient as the recipient of the event. This is because upon connection, a\npersonal room for each client is created and named with the sid assigned\nto the connection. The application is then free to create additional rooms and\nmanage which clients are in them using the socketio.Server.enter_room()\nand socketio.Server.leave_room() methods. Clients can be in as many\nrooms as needed and can be moved between rooms as often as necessary.','use room argument in previous section',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9738,'python-socketio','In the previous section the room argument of the\nsocketio.SocketIO.emit() method was used to designate a specific\nclient as the recipient of the event. This is because upon connection, a\npersonal room for each client is created and named with the sid assigned\nto the connection. The application is then free to create additional rooms and\nmanage which clients are in them using the socketio.Server.enter_room()\nand socketio.Server.leave_room() methods. Clients can be in as many\nrooms as needed and can be moved between rooms as often as necessary.','use room argument of socketio.SocketIO.emit() method',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9739,'python-socketio','In the previous section the room argument of the\nsocketio.SocketIO.emit() method was used to designate a specific\nclient as the recipient of the event. This is because upon connection, a\npersonal room for each client is created and named with the sid assigned\nto the connection. The application is then free to create additional rooms and\nmanage which clients are in them using the socketio.Server.enter_room()\nand socketio.Server.leave_room() methods. Clients can be in as many\nrooms as needed and can be moved between rooms as often as necessary.','create personal room with sid',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9740,'python-socketio','In the previous section the room argument of the\nsocketio.SocketIO.emit() method was used to designate a specific\nclient as the recipient of the event. This is because upon connection, a\npersonal room for each client is created and named with the sid assigned\nto the connection. The application is then free to create additional rooms and\nmanage which clients are in them using the socketio.Server.enter_room()\nand socketio.Server.leave_room() methods. Clients can be in as many\nrooms as needed and can be moved between rooms as often as necessary.','create personal room for client',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9741,'python-socketio','In the previous section the room argument of the\nsocketio.SocketIO.emit() method was used to designate a specific\nclient as the recipient of the event. This is because upon connection, a\npersonal room for each client is created and named with the sid assigned\nto the connection. The application is then free to create additional rooms and\nmanage which clients are in them using the socketio.Server.enter_room()\nand socketio.Server.leave_room() methods. Clients can be in as many\nrooms as needed and can be moved between rooms as often as necessary.','assign  to connection',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9742,'python-socketio','In the previous section the room argument of the\nsocketio.SocketIO.emit() method was used to designate a specific\nclient as the recipient of the event. This is because upon connection, a\npersonal room for each client is created and named with the sid assigned\nto the connection. The application is then free to create additional rooms and\nmanage which clients are in them using the socketio.Server.enter_room()\nand socketio.Server.leave_room() methods. Clients can be in as many\nrooms as needed and can be moved between rooms as often as necessary.','create additional rooms',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9743,'python-socketio','In the previous section the room argument of the\nsocketio.SocketIO.emit() method was used to designate a specific\nclient as the recipient of the event. This is because upon connection, a\npersonal room for each client is created and named with the sid assigned\nto the connection. The application is then free to create additional rooms and\nmanage which clients are in them using the socketio.Server.enter_room()\nand socketio.Server.leave_room() methods. Clients can be in as many\nrooms as needed and can be moved between rooms as often as necessary.','manage additional rooms',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9744,'python-socketio','In the previous section the room argument of the\nsocketio.SocketIO.emit() method was used to designate a specific\nclient as the recipient of the event. This is because upon connection, a\npersonal room for each client is created and named with the sid assigned\nto the connection. The application is then free to create additional rooms and\nmanage which clients are in them using the socketio.Server.enter_room()\nand socketio.Server.leave_room() methods. Clients can be in as many\nrooms as needed and can be moved between rooms as often as necessary.','use socketio.Server.enter_room() socketio.Server.leave_room() methods',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9745,'python-socketio','In the previous section the room argument of the\nsocketio.SocketIO.emit() method was used to designate a specific\nclient as the recipient of the event. This is because upon connection, a\npersonal room for each client is created and named with the sid assigned\nto the connection. The application is then free to create additional rooms and\nmanage which clients are in them using the socketio.Server.enter_room()\nand socketio.Server.leave_room() methods. Clients can be in as many\nrooms as needed and can be moved between rooms as often as necessary.','move clients between rooms',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9746,'python-socketio','In chat applications it is often desired that an event is broadcasted to all\nthe members of the room except one, which is the originator of the event such\nas a chat message. The socketio.Server.emit() method provides an\noptional skip_sid argument to indicate a client that should be skipped\nduring the broadcast.','provide optional skip_sid argument',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9747,'python-socketio','In chat applications it is often desired that an event is broadcasted to all\nthe members of the room except one, which is the originator of the event such\nas a chat message. The socketio.Server.emit() method provides an\noptional skip_sid argument to indicate a client that should be skipped\nduring the broadcast.','skip client during broadcast',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9748,'python-socketio','The server can maintain application-specific information in a user session\ndedicated to each connected client. Applications can use the user session to\nwrite any details about the user that need to be preserved throughout the life\nof the connection, such as usernames or user ids.','use user session',0,'',''),(9749,'python-socketio','The server can maintain application-specific information in a user session\ndedicated to each connected client. Applications can use the user session to\nwrite any details about the user that need to be preserved throughout the life\nof the connection, such as usernames or user ids.','write details about user',0,'',''),(9750,'python-socketio','The save_session() and get_session() methods are used to store and\nretrieve information in the user session:','store information in user session',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9751,'python-socketio','The save_session() and get_session() methods are used to store and\nretrieve information in the user session:','retrieve information in user session',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9752,'python-socketio','The save_session() and get_session() methods are used to store and\nretrieve information in the user session:','use save_session() get_session() methods',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9753,'python-socketio','The session can also be manipulated with the session() context manager:','manipulate session with session() context manager',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9754,'python-socketio','For the asyncio server, an asynchronous context manager is used:','use asynchronous context manager for asyncio server',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9755,'python-socketio','The get_session(), save_session() and session() methods take an\noptional namespace argument. If this argument isn’t provided, the session\nis attached to the default namespace.','attach session to default namespace',0,'',''),(9756,'python-socketio','The get_session(), save_session() and session() methods take an\noptional namespace argument. If this argument isn’t provided, the session\nis attached to the default namespace.','provide argument',0,'',''),(9757,'python-socketio','When working with distributed applications, it is often necessary to access\nthe functionality of the Socket.IO from multiple processes. There are two\nspecific use cases:','access  from multiple processes',0,'',''),(9758,'python-socketio','As a solution to the above problems, the Socket.IO server can be configured\nto connect to a message queue such as Redis or\nRabbitMQ, to communicate with other related\nSocket.IO servers or auxiliary workers.','configure Socket.IO server as solution',0,'',''),(9759,'python-socketio','To use a Redis message queue, a Python Redis client must be installed:','use Redis message queue',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9760,'python-socketio','To use a Redis message queue, a Python Redis client must be installed:','install Python redis client',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9761,'python-socketio','The Redis queue is configured through the socketio.RedisManager and\nsocketio.AsyncRedisManager classes. These classes connect directly to\nthe Redis store and use the queue’s pub/sub functionality:','configure Redis queue through socketio.RedisManager socketio.AsyncRedisManager classes',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9762,'python-socketio','The Redis queue is configured through the socketio.RedisManager and\nsocketio.AsyncRedisManager classes. These classes connect directly to\nthe Redis store and use the queue’s pub/sub functionality:','use pub/sub functionality',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9763,'python-socketio','Kombu is a Python package that\nprovides access to RabbitMQ and many other message queues. It can be installed\nwith pip:','provide access to RabbitMQ',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9764,'python-socketio','Kombu is a Python package that\nprovides access to RabbitMQ and many other message queues. It can be installed\nwith pip:','provide access to many other message queues',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9765,'python-socketio','Kombu is a Python package that\nprovides access to RabbitMQ and many other message queues. It can be installed\nwith pip:','provide Python package to RabbitMQ',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9766,'python-socketio','Kombu is a Python package that\nprovides access to RabbitMQ and many other message queues. It can be installed\nwith pip:','provide Python package to many other message queues',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9767,'python-socketio','Kombu is a Python package that\nprovides access to RabbitMQ and many other message queues. It can be installed\nwith pip:','install  with pip',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9768,'python-socketio','To use RabbitMQ or other AMQP protocol compatible queues, that is the only\nrequired dependency. But for other message queues, Kombu may require\nadditional packages. For example, to use a Redis queue via Kombu, the Python\npackage for Redis needs to be installed as well:','use RabbitMQ other AMQP protocol queues',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9769,'python-socketio','To use RabbitMQ or other AMQP protocol compatible queues, that is the only\nrequired dependency. But for other message queues, Kombu may require\nadditional packages. For example, to use a Redis queue via Kombu, the Python\npackage for Redis needs to be installed as well:','use Redis queue via kombu',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9770,'python-socketio','The queue is configured through the socketio.KombuManager:','configure queue through socketio.KombuManager',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9771,'python-socketio','The connection URL passed to the KombuManager constructor is passed\ndirectly to Kombu’s Connection object, so\nthe Kombu documentation should be consulted for information on how to build\nthe correct URL for a given message queue.','pass  to KombuManager constructor',0,'',''),(9772,'python-socketio','The connection URL passed to the KombuManager constructor is passed\ndirectly to Kombu’s Connection object, so\nthe Kombu documentation should be consulted for information on how to build\nthe correct URL for a given message queue.','pass connection URL to connection object',0,'',''),(9773,'python-socketio','Apache Kafka is supported through the\nkafka-python\npackage:','support apache Kafka through kafka-python package',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9774,'python-socketio','Access to Kafka is configured through the socketio.KafkaManager\nclass:','configure access through socketio.KafkaManager class',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9775,'python-socketio','Access to Kafka is configured through the socketio.KafkaManager\nclass:','configure access to Kafka',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9776,'python-socketio','A RabbitMQ message queue is supported in asyncio applications through the\nAioPika package::\nYou need to install aio_pika with pip:','install aio_pika with pip',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9777,'python-socketio','A RabbitMQ message queue is supported in asyncio applications through the\nAioPika package::\nYou need to install aio_pika with pip:','support RabbitMQ message queue through AioPika package',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9778,'python-socketio','A RabbitMQ message queue is supported in asyncio applications through the\nAioPika package::\nYou need to install aio_pika with pip:','support RabbitMQ message queue in asyncio applications',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9779,'python-socketio','The RabbitMQ queue is configured through the\nsocketio.AsyncAioPikaManager class:','configure RabbitMQ queue through socketio.AsyncAioPikaManager class',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9780,'python-socketio','To have a process other than a server connect to the queue to emit a message,\nthe same client manager classes can be used as standalone objects. In this\ncase, the write_only argument should be set to True to disable the\ncreation of a listening thread, which only makes sense in a server. For\nexample:','use same client manager classes as standalone objects',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9781,'python-socketio','To have a process other than a server connect to the queue to emit a message,\nthe same client manager classes can be used as standalone objects. In this\ncase, the write_only argument should be set to True to disable the\ncreation of a listening thread, which only makes sense in a server. For\nexample:','disable creation of listening thread',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9782,'python-socketio','To have a process other than a server connect to the queue to emit a message,\nthe same client manager classes can be used as standalone objects. In this\ncase, the write_only argument should be set to True to disable the\ncreation of a listening thread, which only makes sense in a server. For\nexample:','set write_only argument in case',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9783,'python-socketio','To have a process other than a server connect to the queue to emit a message,\nthe same client manager classes can be used as standalone objects. In this\ncase, the write_only argument should be set to True to disable the\ncreation of a listening thread, which only makes sense in a server. For\nexample:','set write_only argument to true',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9784,'python-socketio','A limitation of the write-only client manager object is that it cannot receive\ncallbacks when emitting. When the external process needs to receive callbacks,\nusing a client to connect to the server with read and write support is a better\noption than a write-only client manager.','receive callbacks',0,'',''),(9785,'python-socketio','A limitation of the write-only client manager object is that it cannot receive\ncallbacks when emitting. When the external process needs to receive callbacks,\nusing a client to connect to the server with read and write support is a better\noption than a write-only client manager.','use client',0,'',''),(9786,'python-socketio','A limitation of the write-only client manager object is that it cannot receive\ncallbacks when emitting. When the external process needs to receive callbacks,\nusing a client to connect to the server with read and write support is a better\noption than a write-only client manager.','write support',0,'',''),(9787,'python-socketio','To help you debug issues, the server can be configured to output logs to the\nterminal:','configure server to terminal',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9788,'python-socketio','To help you debug issues, the server can be configured to output logs to the\nterminal:','configure server to output logs',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9789,'python-socketio','Logging can help identify the cause of connection problems, 400 responses,\nbad performance and other issues.','identify cause of other issues',0,'',''),(9790,'python-socketio','Logging can help identify the cause of connection problems, 400 responses,\nbad performance and other issues.','identify cause of connection problems',0,'',''),(9791,'python-socketio','Logging can help identify the cause of connection problems, 400 responses,\nbad performance and other issues.','identify cause of responses',0,'',''),(9792,'python-socketio','Logging can help identify the cause of connection problems, 400 responses,\nbad performance and other issues.','identify cause of bad performance',0,'',''),(9793,'python-socketio','The following sections describe a variety of deployment strategies for\nSocket.IO servers.','describe variety of deployment strategies',0,'',''),(9794,'python-socketio','If desired, the socketio.ASGIApp class can forward any traffic that is not\nSocket.IO to another ASGI application, making it possible to deploy a standard\nASGI web application and the Socket.IO server as a bundle:','deploy Socket.IO server as bundle',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9795,'python-socketio','If desired, the socketio.ASGIApp class can forward any traffic that is not\nSocket.IO to another ASGI application, making it possible to deploy a standard\nASGI web application and the Socket.IO server as a bundle:','deploy standard ASGI web application as bundle',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9796,'python-socketio','The ASGIApp instance is a fully complaint ASGI instance that can be\ndeployed with an ASGI compatible web server.','deploy complaint ASGI instance with ASGI compatible web server',0,'',''),(9797,'python-socketio','Aiohttp is a framework with support for HTTP\nand WebSocket, based on asyncio. Support for this framework is limited to Python\n3.5 and newer.','limit support for framework',0,'',''),(9798,'python-socketio','Aiohttp is a framework with support for HTTP\nand WebSocket, based on asyncio. Support for this framework is limited to Python\n3.5 and newer.','limit support to Python 3.5 newer',0,'',''),(9799,'python-socketio','Instances of class socketio.AsyncServer will automatically use aiohttp\nfor asynchronous operations if the library is installed. To request its use\nexplicitly, the async_mode option can be given in the constructor:','use aiohttp for asynchronous operations',0,'',''),(9800,'python-socketio','Instances of class socketio.AsyncServer will automatically use aiohttp\nfor asynchronous operations if the library is installed. To request its use\nexplicitly, the async_mode option can be given in the constructor:','install library',0,'',''),(9801,'python-socketio','Instances of class socketio.AsyncServer will automatically use aiohttp\nfor asynchronous operations if the library is installed. To request its use\nexplicitly, the async_mode option can be given in the constructor:','request use',0,'',''),(9802,'python-socketio','A server configured for aiohttp must be attached to an existing application:','configure  for aiohttp',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9803,'python-socketio','A server configured for aiohttp must be attached to an existing application:','attach server to existing application',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9804,'python-socketio','The aiohttp application can define regular routes that will coexist with the\nSocket.IO server. A typical pattern is to add routes that serve a client\napplication and any associated static files.','define regular routes',0,'',''),(9805,'python-socketio','The aiohttp application can define regular routes that will coexist with the\nSocket.IO server. A typical pattern is to add routes that serve a client\napplication and any associated static files.','add routes',0,'',''),(9806,'python-socketio','The aiohttp application is then executed in the usual manner:','execute aiohttp application',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9807,'python-socketio','Tornado is a web framework with support\nfor HTTP and WebSocket. Support for this framework requires Python 3.5 and\nnewer. Only Tornado version 5 and newer are supported, thanks to its tight\nintegration with asyncio.','support Tornado version 5 newer thanks_to tight integration',0,'',''),(9808,'python-socketio','Instances of class socketio.AsyncServer will automatically use tornado\nfor asynchronous operations if the library is installed. To request its use\nexplicitly, the async_mode option can be given in the constructor:','use tornado for asynchronous operations',0,'',''),(9809,'python-socketio','Instances of class socketio.AsyncServer will automatically use tornado\nfor asynchronous operations if the library is installed. To request its use\nexplicitly, the async_mode option can be given in the constructor:','install library',0,'',''),(9810,'python-socketio','Instances of class socketio.AsyncServer will automatically use tornado\nfor asynchronous operations if the library is installed. To request its use\nexplicitly, the async_mode option can be given in the constructor:','request use',0,'',''),(9811,'python-socketio','A server configured for tornado must include a request handler for\nSocket.IO:','include request handler for Socket.IO',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9812,'python-socketio','A server configured for tornado must include a request handler for\nSocket.IO:','configure  for tornado',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9813,'python-socketio','The tornado application can define other routes that will coexist with the\nSocket.IO server. A typical pattern is to add routes that serve a client\napplication and any associated static files.','define other routes',0,'',''),(9814,'python-socketio','The tornado application can define other routes that will coexist with the\nSocket.IO server. A typical pattern is to add routes that serve a client\napplication and any associated static files.','add routes',0,'',''),(9815,'python-socketio','The tornado application is then executed in the usual manner:','execute tornado application',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9816,'python-socketio','Note: Due to some backward incompatible changes introduced in recent versions\nof Sanic, it is currently recommended that a Sanic application is deployed with\nthe ASGI integration instead.','introduce  in recent versions',0,'',''),(9817,'python-socketio','Note: Due to some backward incompatible changes introduced in recent versions\nof Sanic, it is currently recommended that a Sanic application is deployed with\nthe ASGI integration instead.','deploy Sanic application with ASGI integration',0,'',''),(9818,'python-socketio','Instances of class socketio.AsyncServer will automatically use Sanic for\nasynchronous operations if the framework is installed. To request its use\nexplicitly, the async_mode option can be given in the constructor:','use Sanic for asynchronous operations',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9819,'python-socketio','Instances of class socketio.AsyncServer will automatically use Sanic for\nasynchronous operations if the framework is installed. To request its use\nexplicitly, the async_mode option can be given in the constructor:','install framework',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9820,'python-socketio','Instances of class socketio.AsyncServer will automatically use Sanic for\nasynchronous operations if the framework is installed. To request its use\nexplicitly, the async_mode option can be given in the constructor:','request use',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9821,'python-socketio','The Sanic application can define regular routes that will coexist with the\nSocket.IO server. A typical pattern is to add routes that serve a client\napplication and any associated static files.','define regular routes',0,'',''),(9822,'python-socketio','The Sanic application can define regular routes that will coexist with the\nSocket.IO server. A typical pattern is to add routes that serve a client\napplication and any associated static files.','add routes',0,'',''),(9823,'python-socketio','The Sanic application is then executed in the usual manner:','execute Sanic application',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9824,'python-socketio','It has been reported that the CORS support provided by the Sanic extension\nsanic-cors is incompatible with\nthis package’s own support for this protocol. To disable CORS support in this\npackage and let Sanic take full control, initialize the server as follows:','disable CORS support in package',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9825,'python-socketio','On the Sanic side you will need to enable the CORS_SUPPORTS_CREDENTIALS\nsetting in addition to any other configuration that you use:','enable CORS_SUPPORTS_CREDENTIALS setting in_addition_to other configuration',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9826,'python-socketio','Eventlet is a high performance concurrent networking\nlibrary for Python 2 and 3 that uses coroutines, enabling code to be written in\nthe same style used with the blocking standard library functions. An Socket.IO\nserver deployed with eventlet has access to the long-polling and WebSocket\ntransports.','use coroutines',0,'',''),(9827,'python-socketio','Eventlet is a high performance concurrent networking\nlibrary for Python 2 and 3 that uses coroutines, enabling code to be written in\nthe same style used with the blocking standard library functions. An Socket.IO\nserver deployed with eventlet has access to the long-polling and WebSocket\ntransports.','enable code',0,'',''),(9828,'python-socketio','Eventlet is a high performance concurrent networking\nlibrary for Python 2 and 3 that uses coroutines, enabling code to be written in\nthe same style used with the blocking standard library functions. An Socket.IO\nserver deployed with eventlet has access to the long-polling and WebSocket\ntransports.','write  in same style',0,'',''),(9829,'python-socketio','Eventlet is a high performance concurrent networking\nlibrary for Python 2 and 3 that uses coroutines, enabling code to be written in\nthe same style used with the blocking standard library functions. An Socket.IO\nserver deployed with eventlet has access to the long-polling and WebSocket\ntransports.','use  with blocking standard library functions',0,'',''),(9830,'python-socketio','Eventlet is a high performance concurrent networking\nlibrary for Python 2 and 3 that uses coroutines, enabling code to be written in\nthe same style used with the blocking standard library functions. An Socket.IO\nserver deployed with eventlet has access to the long-polling and WebSocket\ntransports.','deploy  with eventlet',0,'',''),(9831,'python-socketio','Instances of class socketio.Server will automatically use eventlet for\nasynchronous operations if the library is installed. To request its use\nexplicitly, the async_mode option can be given in the constructor:','use eventlet for asynchronous operations',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9832,'python-socketio','Instances of class socketio.Server will automatically use eventlet for\nasynchronous operations if the library is installed. To request its use\nexplicitly, the async_mode option can be given in the constructor:','install library',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9833,'python-socketio','Instances of class socketio.Server will automatically use eventlet for\nasynchronous operations if the library is installed. To request its use\nexplicitly, the async_mode option can be given in the constructor:','request use',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9834,'python-socketio','A server configured for eventlet is deployed as a regular WSGI application\nusing the provided socketio.WSGIApp:','use provided socketio.WSGIApp',0,'',''),(9835,'python-socketio','A server configured for eventlet is deployed as a regular WSGI application\nusing the provided socketio.WSGIApp:','configure  for eventlet',0,'',''),(9836,'python-socketio','A server configured for eventlet is deployed as a regular WSGI application\nusing the provided socketio.WSGIApp:','deploy server as regular WSGI application',0,'',''),(9837,'python-socketio','An alternative to running the eventlet WSGI server as above is to use\ngunicorn, a fully featured pure Python web server. The\ncommand to launch the application under gunicorn is shown below:','run eventlet WSGI server',0,'',''),(9838,'python-socketio','An alternative to running the eventlet WSGI server as above is to use\ngunicorn, a fully featured pure Python web server. The\ncommand to launch the application under gunicorn is shown below:','use gunicorn',0,'',''),(9839,'python-socketio','An alternative to running the eventlet WSGI server as above is to use\ngunicorn, a fully featured pure Python web server. The\ncommand to launch the application under gunicorn is shown below:','show command',0,'',''),(9840,'python-socketio','Due to limitations in its load balancing algorithm, gunicorn can only be used\nwith one worker process, so the -w option cannot be set to a value higher\nthan 1. A single eventlet worker can handle a large number of concurrent\nclients, each handled by a greenlet.','use gunicorn with worker process',0,'',''),(9841,'python-socketio','Due to limitations in its load balancing algorithm, gunicorn can only be used\nwith one worker process, so the -w option cannot be set to a value higher\nthan 1. A single eventlet worker can handle a large number of concurrent\nclients, each handled by a greenlet.','use gunicorn due_to limitations',0,'',''),(9842,'python-socketio','Due to limitations in its load balancing algorithm, gunicorn can only be used\nwith one worker process, so the -w option cannot be set to a value higher\nthan 1. A single eventlet worker can handle a large number of concurrent\nclients, each handled by a greenlet.','handle large number of concurrent clients',0,'',''),(9843,'python-socketio','Due to limitations in its load balancing algorithm, gunicorn can only be used\nwith one worker process, so the -w option cannot be set to a value higher\nthan 1. A single eventlet worker can handle a large number of concurrent\nclients, each handled by a greenlet.','handle  by greenlet',0,'',''),(9844,'python-socketio','Eventlet provides a monkey_patch() function that replaces all the blocking\nfunctions in the standard library with equivalent asynchronous versions. While\npython-socketio does not require monkey patching, other libraries such as\ndatabase drivers are likely to require it.','provide monkey_patch() function',0,'',''),(9845,'python-socketio','Eventlet provides a monkey_patch() function that replaces all the blocking\nfunctions in the standard library with equivalent asynchronous versions. While\npython-socketio does not require monkey patching, other libraries such as\ndatabase drivers are likely to require it.','replace blocking functions in standard library',0,'',''),(9846,'python-socketio','Eventlet provides a monkey_patch() function that replaces all the blocking\nfunctions in the standard library with equivalent asynchronous versions. While\npython-socketio does not require monkey patching, other libraries such as\ndatabase drivers are likely to require it.','replace monkey_patch() function in standard library',0,'',''),(9847,'python-socketio','Gevent is another asynchronous framework based on\ncoroutines, very similar to eventlet. An Socket.IO server deployed with\ngevent has access to the long-polling transport. If project\ngevent-websocket is\ninstalled, the WebSocket transport is also available.','deploy  with gevent',0,'',''),(9848,'python-socketio','Gevent is another asynchronous framework based on\ncoroutines, very similar to eventlet. An Socket.IO server deployed with\ngevent has access to the long-polling transport. If project\ngevent-websocket is\ninstalled, the WebSocket transport is also available.','install project gevent-websocket',0,'',''),(9849,'python-socketio','Instances of class socketio.Server will automatically use gevent for\nasynchronous operations if the library is installed and eventlet is not\ninstalled. To request gevent to be selected explicitly, the async_mode\noption can be given in the constructor:','use gevent for asynchronous operations',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9850,'python-socketio','Instances of class socketio.Server will automatically use gevent for\nasynchronous operations if the library is installed and eventlet is not\ninstalled. To request gevent to be selected explicitly, the async_mode\noption can be given in the constructor:','install library',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9851,'python-socketio','A server configured for gevent is deployed as a regular WSGI application\nusing the provided socketio.WSGIApp:','use provided socketio.WSGIApp',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9852,'python-socketio','A server configured for gevent is deployed as a regular WSGI application\nusing the provided socketio.WSGIApp:','configure  for gevent',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9853,'python-socketio','A server configured for gevent is deployed as a regular WSGI application\nusing the provided socketio.WSGIApp:','deploy server as regular WSGI application',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9854,'python-socketio','If the WebSocket transport is installed, then the server must be started as\nfollows:','install WebSocket transport',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9855,'python-socketio','An alternative to running the gevent WSGI server as above is to use\ngunicorn, a fully featured pure Python web server. The\ncommand to launch the application under gunicorn is shown below:','run gevent WSGI server',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9856,'python-socketio','An alternative to running the gevent WSGI server as above is to use\ngunicorn, a fully featured pure Python web server. The\ncommand to launch the application under gunicorn is shown below:','use gunicorn',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9857,'python-socketio','An alternative to running the gevent WSGI server as above is to use\ngunicorn, a fully featured pure Python web server. The\ncommand to launch the application under gunicorn is shown below:','show command',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9858,'python-socketio','Or to include WebSocket:','include websocket',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9859,'python-socketio','Same as with eventlet, due to limitations in its load balancing algorithm,\ngunicorn can only be used with one worker process, so the -w option cannot\nbe higher than 1. A single gevent worker can handle a large number of\nconcurrent clients through the use of greenlets.','use gunicorn with worker process',0,'',''),(9860,'python-socketio','Same as with eventlet, due to limitations in its load balancing algorithm,\ngunicorn can only be used with one worker process, so the -w option cannot\nbe higher than 1. A single gevent worker can handle a large number of\nconcurrent clients through the use of greenlets.','use gunicorn due_to limitations',0,'',''),(9861,'python-socketio','Same as with eventlet, due to limitations in its load balancing algorithm,\ngunicorn can only be used with one worker process, so the -w option cannot\nbe higher than 1. A single gevent worker can handle a large number of\nconcurrent clients through the use of greenlets.','handle large number through use',0,'',''),(9862,'python-socketio','Same as with eventlet, due to limitations in its load balancing algorithm,\ngunicorn can only be used with one worker process, so the -w option cannot\nbe higher than 1. A single gevent worker can handle a large number of\nconcurrent clients through the use of greenlets.','handle large number of concurrent clients',0,'',''),(9863,'python-socketio','Gevent provides a monkey_patch() function that replaces all the blocking\nfunctions in the standard library with equivalent asynchronous versions. While\npython-socketio does not require monkey patching, other libraries such as\ndatabase drivers are likely to require it.','provide monkey_patch() function',0,'',''),(9864,'python-socketio','Gevent provides a monkey_patch() function that replaces all the blocking\nfunctions in the standard library with equivalent asynchronous versions. While\npython-socketio does not require monkey patching, other libraries such as\ndatabase drivers are likely to require it.','replace blocking functions in standard library',0,'',''),(9865,'python-socketio','Gevent provides a monkey_patch() function that replaces all the blocking\nfunctions in the standard library with equivalent asynchronous versions. While\npython-socketio does not require monkey patching, other libraries such as\ndatabase drivers are likely to require it.','replace monkey_patch() function in standard library',0,'',''),(9866,'python-socketio','When using the uWSGI server in combination with gevent, the Socket.IO server\ncan take advantage of uWSGI’s native WebSocket support.','use uWSGI server in combination',0,'',''),(9867,'python-socketio','Instances of class socketio.Server will automatically use this option for\nasynchronous operations if both gevent and uWSGI are installed and eventlet is\nnot installed. To request this asynchronous mode explicitly, the\nasync_mode option can be given in the constructor:','use option for asynchronous operations',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9868,'python-socketio','Instances of class socketio.Server will automatically use this option for\nasynchronous operations if both gevent and uWSGI are installed and eventlet is\nnot installed. To request this asynchronous mode explicitly, the\nasync_mode option can be given in the constructor:','install uWSGI',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9869,'python-socketio','Instances of class socketio.Server will automatically use this option for\nasynchronous operations if both gevent and uWSGI are installed and eventlet is\nnot installed. To request this asynchronous mode explicitly, the\nasync_mode option can be given in the constructor:','install gevent',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9870,'python-socketio','Instances of class socketio.Server will automatically use this option for\nasynchronous operations if both gevent and uWSGI are installed and eventlet is\nnot installed. To request this asynchronous mode explicitly, the\nasync_mode option can be given in the constructor:','request asynchronous mode',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9871,'python-socketio','A complete explanation of the configuration and usage of the uWSGI server is\nbeyond the scope of this documentation. The uWSGI server is a fairly complex\npackage that provides a large and comprehensive set of options. It must be\ncompiled with WebSocket and SSL support for the WebSocket transport to be\navailable. As way of an introduction, the following command starts a uWSGI\nserver for the latency.py example on port 5000:','provide large comprehensive set of options',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9872,'python-socketio','A complete explanation of the configuration and usage of the uWSGI server is\nbeyond the scope of this documentation. The uWSGI server is a fairly complex\npackage that provides a large and comprehensive set of options. It must be\ncompiled with WebSocket and SSL support for the WebSocket transport to be\navailable. As way of an introduction, the following command starts a uWSGI\nserver for the latency.py example on port 5000:','provide complex package of options',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9873,'python-socketio','A complete explanation of the configuration and usage of the uWSGI server is\nbeyond the scope of this documentation. The uWSGI server is a fairly complex\npackage that provides a large and comprehensive set of options. It must be\ncompiled with WebSocket and SSL support for the WebSocket transport to be\navailable. As way of an introduction, the following command starts a uWSGI\nserver for the latency.py example on port 5000:','compile  with WebSocket SSL support',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9874,'python-socketio','While not comparable to eventlet and gevent in terms of performance,\nthe Socket.IO server can also be configured to work with multi-threaded web\nservers that use standard Python threads. This is an ideal setup to use with\ndevelopment servers such as Werkzeug.','use standard Python threads',0,'',''),(9875,'python-socketio','While not comparable to eventlet and gevent in terms of performance,\nthe Socket.IO server can also be configured to work with multi-threaded web\nservers that use standard Python threads. This is an ideal setup to use with\ndevelopment servers such as Werkzeug.','use multi-threaded web servers',0,'',''),(9876,'python-socketio','While not comparable to eventlet and gevent in terms of performance,\nthe Socket.IO server can also be configured to work with multi-threaded web\nservers that use standard Python threads. This is an ideal setup to use with\ndevelopment servers such as Werkzeug.','configure Socket.IO server',0,'',''),(9877,'python-socketio','While not comparable to eventlet and gevent in terms of performance,\nthe Socket.IO server can also be configured to work with multi-threaded web\nservers that use standard Python threads. This is an ideal setup to use with\ndevelopment servers such as Werkzeug.','use  with development servers',0,'',''),(9878,'python-socketio','Instances of class socketio.Server will automatically use the threading\nmode if neither eventlet nor gevent are installed. To request the\nthreading mode explicitly, the async_mode option can be given in the\nconstructor:','use threading mode',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9879,'python-socketio','Instances of class socketio.Server will automatically use the threading\nmode if neither eventlet nor gevent are installed. To request the\nthreading mode explicitly, the async_mode option can be given in the\nconstructor:','install eventlet',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9880,'python-socketio','Instances of class socketio.Server will automatically use the threading\nmode if neither eventlet nor gevent are installed. To request the\nthreading mode explicitly, the async_mode option can be given in the\nconstructor:','install gevent',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9881,'python-socketio','Instances of class socketio.Server will automatically use the threading\nmode if neither eventlet nor gevent are installed. To request the\nthreading mode explicitly, the async_mode option can be given in the\nconstructor:','request threading mode',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9882,'python-socketio','A server configured for threading is deployed as a regular web application,\nusing any WSGI complaint multi-threaded server. The example below deploys an\nSocket.IO application combined with a Flask web application, using Flask’s\ndevelopment web server based on Werkzeug:','use WSGI complaint multi-threaded server',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9883,'python-socketio','A server configured for threading is deployed as a regular web application,\nusing any WSGI complaint multi-threaded server. The example below deploys an\nSocket.IO application combined with a Flask web application, using Flask’s\ndevelopment web server based on Werkzeug:','configure  for threading',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9884,'python-socketio','A server configured for threading is deployed as a regular web application,\nusing any WSGI complaint multi-threaded server. The example below deploys an\nSocket.IO application combined with a Flask web application, using Flask’s\ndevelopment web server based on Werkzeug:','deploy server as regular web application',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9885,'python-socketio','A server configured for threading is deployed as a regular web application,\nusing any WSGI complaint multi-threaded server. The example below deploys an\nSocket.IO application combined with a Flask web application, using Flask’s\ndevelopment web server based on Werkzeug:','deploy Socket.IO application',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9886,'python-socketio','A server configured for threading is deployed as a regular web application,\nusing any WSGI complaint multi-threaded server. The example below deploys an\nSocket.IO application combined with a Flask web application, using Flask’s\ndevelopment web server based on Werkzeug:','use development web server',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9887,'python-socketio','The example that follows shows how to start an Socket.IO application using\nGunicorn’s threaded worker class:','use threaded worker class',1,'https://python-socketio.readthedocs.io/en/latest/server.html',''),(9888,'python-socketio','When using standard threads, WebSocket is supported through the\nsimple-websocket\npackage, which must be installed separately. This package provides a\nmulti-threaded WebSocket server that is compatible with Werkzeug and Gunicorn’s\nthreaded worker. Other multi-threaded web servers are not supported and will\nnot enable the WebSocket transport.','use standard threads',0,'',''),(9889,'python-socketio','When using standard threads, WebSocket is supported through the\nsimple-websocket\npackage, which must be installed separately. This package provides a\nmulti-threaded WebSocket server that is compatible with Werkzeug and Gunicorn’s\nthreaded worker. Other multi-threaded web servers are not supported and will\nnot enable the WebSocket transport.','support WebSocket through simple-websocket package',0,'',''),(9890,'python-socketio','When using standard threads, WebSocket is supported through the\nsimple-websocket\npackage, which must be installed separately. This package provides a\nmulti-threaded WebSocket server that is compatible with Werkzeug and Gunicorn’s\nthreaded worker. Other multi-threaded web servers are not supported and will\nnot enable the WebSocket transport.','install simple-websocket package',0,'',''),(9891,'python-socketio','When using standard threads, WebSocket is supported through the\nsimple-websocket\npackage, which must be installed separately. This package provides a\nmulti-threaded WebSocket server that is compatible with Werkzeug and Gunicorn’s\nthreaded worker. Other multi-threaded web servers are not supported and will\nnot enable the WebSocket transport.','provide multi-threaded WebSocket server',0,'',''),(9892,'python-socketio','Socket.IO is a stateful protocol, which makes horizontal scaling more\ndifficult. To deploy a cluster of Socket.IO processes hosted on one or\nmultiple servers, the following conditions must be met:','deploy cluster of Socket.IO processes',0,'',''),(9893,'python-socketio','Socket.IO is a stateful protocol, which makes horizontal scaling more\ndifficult. To deploy a cluster of Socket.IO processes hosted on one or\nmultiple servers, the following conditions must be met:','host  on one multiple servers',0,'',''),(9894,'python-socketio','If necessary, the cors_allowed_origins option can be used to allow other\norigins. This argument can be set to a string to set a single allowed origin, or\nto a list to allow multiple origins. A special value of \'*\' can be used to\ninstruct the server to allow all origins, but this should be done with care, as\nthis could make the server vulnerable to Cross-Site Request Forgery (CSRF)\nattacks.','use cors_allowed_origins option',0,'',''),(9895,'python-socketio','If necessary, the cors_allowed_origins option can be used to allow other\norigins. This argument can be set to a string to set a single allowed origin, or\nto a list to allow multiple origins. A special value of \'*\' can be used to\ninstruct the server to allow all origins, but this should be done with care, as\nthis could make the server vulnerable to Cross-Site Request Forgery (CSRF)\nattacks.','set single allowed origin',0,'',''),(9896,'python-socketio','If necessary, the cors_allowed_origins option can be used to allow other\norigins. This argument can be set to a string to set a single allowed origin, or\nto a list to allow multiple origins. A special value of \'*\' can be used to\ninstruct the server to allow all origins, but this should be done with care, as\nthis could make the server vulnerable to Cross-Site Request Forgery (CSRF)\nattacks.','set argument to list',0,'',''),(9897,'python-socketio','If necessary, the cors_allowed_origins option can be used to allow other\norigins. This argument can be set to a string to set a single allowed origin, or\nto a list to allow multiple origins. A special value of \'*\' can be used to\ninstruct the server to allow all origins, but this should be done with care, as\nthis could make the server vulnerable to Cross-Site Request Forgery (CSRF)\nattacks.','set argument to string',0,'',''),(9898,'python-socketio','If necessary, the cors_allowed_origins option can be used to allow other\norigins. This argument can be set to a string to set a single allowed origin, or\nto a list to allow multiple origins. A special value of \'*\' can be used to\ninstruct the server to allow all origins, but this should be done with care, as\nthis could make the server vulnerable to Cross-Site Request Forgery (CSRF)\nattacks.','use special value of *',0,'',''),(9899,'Astro','Visit astro.new and choose from a variety of templates to get started. Play around with a full, working version of Astro right in your browser!','choose  from variety',0,'',''),(9900,'Astro','Get a new Astro project up and running locally with our helpful create-astro CLI wizard!','run  with helpful create-astro CLI',1,'https://docs.astro.build/en/getting-started/','38-tab.yarn'),(9901,'Astro','Our Installation Guide has full, step-by-step instructions for installing Astro using your favorite package manager.','install Astro',0,'',''),(9902,'Astro','Our Installation Guide has full, step-by-step instructions for installing Astro using your favorite package manager.','use favorite package manager',0,'',''),(9903,'Astro','📚 Add your first page to your site.','add first page to site',0,'',''),(9904,'Astro','📚 Read more about Astro’s project structure.','read  about project structure',0,'',''),(9905,'Astro','… find our full API documentation under the Reference tab.','find full API documentation under reference tab',0,'',''),(9906,'Astro','🧰 Customize your site with official and community plugins and components.','customize site with official community plugins',0,'',''),(9907,'Astro','🧰 Customize your site with official and community plugins and components.','customize site with components',0,'',''),(9908,'Astro','… see our guide to using integrations.','use integrations',0,'',''),(9909,'Astro','Join us in the Astro Discord to share with and get help from an active, friendly community!','get help from active friendly community',0,'',''),(9910,'zoo-web-components','Button group renders group of  components and it works like a tabs, where only one button can be in active state.','render group of components',0,'',''),(9911,'zoo-web-components','Button component which provides styles for','provide styles',0,'',''),(9912,'zoo-web-components','Checkbox component which provides styles for','provide styles',0,'',''),(9913,'zoo-web-components','Checkbox component which provides styles for','provide component',0,'',''),(9914,'zoo-web-components','invalid and highlighted attributes should be used as a boolean attribute.','use invalid highlighted attributes as boolean attribute',0,'',''),(9915,'zoo-web-components','Container component which provides styles for slotted content.','provide styles for slotted content',0,'',''),(9916,'zoo-web-components','Date range component which provides styles for slotted','provide styles for slotted',0,'',''),(9917,'zoo-web-components','Date range component which provides styles for slotted','provide component for slotted',0,'',''),(9918,'zoo-web-components','invalid attribute should be used as a boolean attribute.','use invalid attribute as boolean attribute',0,'',''),(9919,'zoo-web-components','Container component which provides a styled container with preset icon.','provide styled container with preset icon',0,'',''),(9920,'zoo-web-components','sortable attribute should be used as a boolean attribute.','use sortable attribute as boolean attribute',0,'',''),(9921,'zoo-web-components','zoo-grid-row is special component that allows to define row with additional expandable content. \nslot=\"row-content\" can be omitted and then zoo-grid-row works just like a standard ...','define row with additional expandable content',0,'',''),(9922,'zoo-web-components','zoo-grid-row is special component that allows to define row with additional expandable content. \nslot=\"row-content\" can be omitted and then zoo-grid-row works just like a standard ...','omit row-content',0,'',''),(9923,'zoo-web-components','If slot=\"row-content\" is defined, then expand action should be defined to be able to expand additional content.\nTo expand row-content add expanded attribute to , like in example above.\nexpanded attribute should be controlled by client code (button click, row click etc.)','expand additional content',0,'',''),(9924,'zoo-web-components','If slot=\"row-content\" is defined, then expand action should be defined to be able to expand additional content.\nTo expand row-content add expanded attribute to , like in example above.\nexpanded attribute should be controlled by client code (button click, row click etc.)','define slot = row-content',0,'',''),(9925,'zoo-web-components','If slot=\"row-content\" is defined, then expand action should be defined to be able to expand additional content.\nTo expand row-content add expanded attribute to , like in example above.\nexpanded attribute should be controlled by client code (button click, row click etc.)','define action',0,'',''),(9926,'zoo-web-components','If slot=\"row-content\" is defined, then expand action should be defined to be able to expand additional content.\nTo expand row-content add expanded attribute to , like in example above.\nexpanded attribute should be controlled by client code (button click, row click etc.)','expand row-content',0,'',''),(9927,'zoo-web-components','If slot=\"row-content\" is defined, then expand action should be defined to be able to expand additional content.\nTo expand row-content add expanded attribute to , like in example above.\nexpanded attribute should be controlled by client code (button click, row click etc.)','add expanded attribute',0,'',''),(9928,'zoo-web-components','loading, stickyheader, resizable and reorderable attributes should be used as a boolean attribute.','use loading resizable reorderable attributes as boolean attribute',0,'',''),(9929,'zoo-web-components','By default, grid will calculate number of headers supplied via slot,\nand apply repeat(var(--grid-column-num), minmax(50px, 1fr)) css rule\nto header and each row; If you want to change some of widths of some columns\nyou can set --grid-column-sizes css custom property on zoo-grid\nto change width of columns, for example: --grid-column-sizes: 150px repeat(9, minmax(50px, 1fr)) !important;\nto force first column to be 150px wide.\nHowever, when resizable attribute is supplied, grid will set column widths automatically on element level,\nso --grid-column-sizes will not work, to force width of any column use the following css:','calculate number by default',0,'',''),(9930,'zoo-web-components','By default, grid will calculate number of headers supplied via slot,\nand apply repeat(var(--grid-column-num), minmax(50px, 1fr)) css rule\nto header and each row; If you want to change some of widths of some columns\nyou can set --grid-column-sizes css custom property on zoo-grid\nto change width of columns, for example: --grid-column-sizes: 150px repeat(9, minmax(50px, 1fr)) !important;\nto force first column to be 150px wide.\nHowever, when resizable attribute is supplied, grid will set column widths automatically on element level,\nso --grid-column-sizes will not work, to force width of any column use the following css:','calculate number of headers',0,'',''),(9931,'zoo-web-components','By default, grid will calculate number of headers supplied via slot,\nand apply repeat(var(--grid-column-num), minmax(50px, 1fr)) css rule\nto header and each row; If you want to change some of widths of some columns\nyou can set --grid-column-sizes css custom property on zoo-grid\nto change width of columns, for example: --grid-column-sizes: 150px repeat(9, minmax(50px, 1fr)) !important;\nto force first column to be 150px wide.\nHowever, when resizable attribute is supplied, grid will set column widths automatically on element level,\nso --grid-column-sizes will not work, to force width of any column use the following css:','apply repeat(var(--grid-column-num) minmax ) css rule to header',0,'',''),(9932,'zoo-web-components','By default, grid will calculate number of headers supplied via slot,\nand apply repeat(var(--grid-column-num), minmax(50px, 1fr)) css rule\nto header and each row; If you want to change some of widths of some columns\nyou can set --grid-column-sizes css custom property on zoo-grid\nto change width of columns, for example: --grid-column-sizes: 150px repeat(9, minmax(50px, 1fr)) !important;\nto force first column to be 150px wide.\nHowever, when resizable attribute is supplied, grid will set column widths automatically on element level,\nso --grid-column-sizes will not work, to force width of any column use the following css:','apply repeat(var(--grid-column-num) minmax ) css rule to row',0,'',''),(9933,'zoo-web-components','By default, grid will calculate number of headers supplied via slot,\nand apply repeat(var(--grid-column-num), minmax(50px, 1fr)) css rule\nto header and each row; If you want to change some of widths of some columns\nyou can set --grid-column-sizes css custom property on zoo-grid\nto change width of columns, for example: --grid-column-sizes: 150px repeat(9, minmax(50px, 1fr)) !important;\nto force first column to be 150px wide.\nHowever, when resizable attribute is supplied, grid will set column widths automatically on element level,\nso --grid-column-sizes will not work, to force width of any column use the following css:','set grid-column-sizes',0,'',''),(9934,'zoo-web-components','By default, grid will calculate number of headers supplied via slot,\nand apply repeat(var(--grid-column-num), minmax(50px, 1fr)) css rule\nto header and each row; If you want to change some of widths of some columns\nyou can set --grid-column-sizes css custom property on zoo-grid\nto change width of columns, for example: --grid-column-sizes: 150px repeat(9, minmax(50px, 1fr)) !important;\nto force first column to be 150px wide.\nHowever, when resizable attribute is supplied, grid will set column widths automatically on element level,\nso --grid-column-sizes will not work, to force width of any column use the following css:','change width of columns',0,'',''),(9935,'zoo-web-components','By default, grid will calculate number of headers supplied via slot,\nand apply repeat(var(--grid-column-num), minmax(50px, 1fr)) css rule\nto header and each row; If you want to change some of widths of some columns\nyou can set --grid-column-sizes css custom property on zoo-grid\nto change width of columns, for example: --grid-column-sizes: 150px repeat(9, minmax(50px, 1fr)) !important;\nto force first column to be 150px wide.\nHowever, when resizable attribute is supplied, grid will set column widths automatically on element level,\nso --grid-column-sizes will not work, to force width of any column use the following css:','force first column',0,'',''),(9936,'zoo-web-components','By default, grid will calculate number of headers supplied via slot,\nand apply repeat(var(--grid-column-num), minmax(50px, 1fr)) css rule\nto header and each row; If you want to change some of widths of some columns\nyou can set --grid-column-sizes css custom property on zoo-grid\nto change width of columns, for example: --grid-column-sizes: 150px repeat(9, minmax(50px, 1fr)) !important;\nto force first column to be 150px wide.\nHowever, when resizable attribute is supplied, grid will set column widths automatically on element level,\nso --grid-column-sizes will not work, to force width of any column use the following css:','set following css on element level',0,'',''),(9937,'zoo-web-components','By default, grid will calculate number of headers supplied via slot,\nand apply repeat(var(--grid-column-num), minmax(50px, 1fr)) css rule\nto header and each row; If you want to change some of widths of some columns\nyou can set --grid-column-sizes css custom property on zoo-grid\nto change width of columns, for example: --grid-column-sizes: 150px repeat(9, minmax(50px, 1fr)) !important;\nto force first column to be 150px wide.\nHowever, when resizable attribute is supplied, grid will set column widths automatically on element level,\nso --grid-column-sizes will not work, to force width of any column use the following css:','set column widths on element level',0,'',''),(9938,'zoo-web-components','By default, grid will calculate number of headers supplied via slot,\nand apply repeat(var(--grid-column-num), minmax(50px, 1fr)) css rule\nto header and each row; If you want to change some of widths of some columns\nyou can set --grid-column-sizes css custom property on zoo-grid\nto change width of columns, for example: --grid-column-sizes: 150px repeat(9, minmax(50px, 1fr)) !important;\nto force first column to be 150px wide.\nHowever, when resizable attribute is supplied, grid will set column widths automatically on element level,\nso --grid-column-sizes will not work, to force width of any column use the following css:','force width of column use',0,'',''),(9939,'zoo-web-components','Component which provides styles for slotted  inside zoo-input-tag element.','provide styles',0,'',''),(9940,'zoo-web-components','Component which provides styles for slotted  inside zoo-input-tag element.','provide component',0,'',''),(9941,'zoo-web-components','Component which provides styles for slotted . Selected values are stored in slotted .','provide styles',0,'',''),(9942,'zoo-web-components','Component which provides styles for slotted . Selected values are stored in slotted .','provide component',0,'',''),(9943,'zoo-web-components','Component which provides styles for slotted . Selected values are stored in slotted .','store selected values in slotted',0,'',''),(9944,'zoo-web-components','Note: nested zoo-tag should have a data-value attribute matching one of the options value from slotted select.\nThat\'s how the component holds the state of the form control.','match  from slotted select',0,'',''),(9945,'zoo-web-components','Input component which provides styles for slotted','provide styles',1,'https://zooplus.github.io/zoo-web-components-docs/index.html','zoo-quantity-control-template'),(9946,'zoo-web-components','Input component which provides styles for slotted','provide input component',1,'https://zooplus.github.io/zoo-web-components-docs/index.html','zoo-quantity-control-template'),(9947,'zoo-web-components','Link wrapper component which provides styles for','provide styles',0,'',''),(9948,'zoo-web-components','Link wrapper component which provides styles for','provide component',0,'',''),(9949,'zoo-web-components','Container component which provides styles for modal and slotted content.\nModal visibility must be controlled by the client.','provide styles for modal slotted content',0,'',''),(9950,'zoo-web-components','Webkit based browsers (Chrome/Safari) do not support hiding native number scroll on input type=\"number\",\nwhen supplying such input for this component remember to add:','hide native number scroll on input type',0,'',''),(9951,'zoo-web-components','Radio component which provides styles for  and associated','provide styles',0,'',''),(9952,'zoo-web-components','Note: id and for attributes on native elements are optional when you do not care about accessibility, selecting an option by clicking on a label will not be possible without these attributes.','select option by clicking',0,'',''),(9953,'zoo-web-components','Select component which provides styles for slotted ...','provide styles for slotted',0,'',''),(9954,'zoo-web-components','Select component which provides styles for slotted ...','provide select component for slotted',0,'',''),(9955,'zoo-web-components','invalid and loading attributes should be used as a boolean attribute.','use invalid loading attributes as boolean attribute',0,'',''),(9956,'zoo-web-components','Spinner has position: absolute, you have to place it inside an element with position: relative.','place  inside element',0,'',''),(9957,'zoo-web-components','The following CSS Custom Properties should be provided and can be overriden by the user. You can provide them in your global css file.','provide following CSS custom Properties',0,'',''),(9958,'zoo-web-components','The following CSS Custom Properties should be provided and can be overriden by the user. You can provide them in your global css file.','provide  in global css file',0,'',''),(9959,'zoo-web-components','For validation you can use arbitrary tool. If you already use a framework you can use, for example,\nangular forms since the basic elements like , ... are already exposed.','use arbitrary tool for validation',0,'',''),(9960,'zoo-web-components','For validation you can use arbitrary tool. If you already use a framework you can use, for example,\nangular forms since the basic elements like , ... are already exposed.','use framework',0,'',''),(9961,'zoo-web-components','For validation you can use arbitrary tool. If you already use a framework you can use, for example,\nangular forms since the basic elements like , ... are already exposed.','use framework',0,'',''),(9962,'zoo-web-components','However, the preffered way would be to use HTML5 form validation, good articles are:','use html5 form validation',1,'https://zooplus.github.io/zoo-web-components-docs/index.html','input-validation'),(9963,'zoo-web-components','novalidate attribute is defined to prevent browser from showing native error bubbles, since we already have\na way of providing error messages.','prevent browser from showing',0,'',''),(9964,'zoo-web-components','novalidate attribute is defined to prevent browser from showing native error bubbles, since we already have\na way of providing error messages.','show native error bubbles',0,'',''),(9965,'zoo-web-components','novalidate attribute is defined to prevent browser from showing native error bubbles, since we already have\na way of providing error messages.','provide error messages',0,'',''),(9966,'zoo-web-components','novalidate attribute is defined to prevent browser from showing native error bubbles, since we already have\na way of providing error messages.','define novalidate attribute',0,'',''),(9967,'zoo-web-components','The above JS is already loaded into this page, the rendered HTML for you to try it is here:','load above JS into page',0,'',''),(9968,'axios','Axios is a promise-based HTTP Client for node.js and the browser. It is isomorphic (= it can run in the browser and nodejs with the same codebase). On the server-side it uses the native node.js http module, while on the client (browser) it uses XMLHttpRequests.','use XMLHttpRequests on client',0,'',''),(9969,'axios','Axios is a promise-based HTTP Client for node.js and the browser. It is isomorphic (= it can run in the browser and nodejs with the same codebase). On the server-side it uses the native node.js http module, while on the client (browser) it uses XMLHttpRequests.','use  on server-side',0,'',''),(9970,'axios','Using npm:','use npm',0,'',''),(9971,'axios','Using bower:','use bower',0,'',''),(9972,'axios','Using yarn:','use yarn',0,'',''),(9973,'axios','Using jsDelivr CDN:','use jsDelivr CDN',0,'',''),(9974,'axios','Using unpkg CDN:','use unpkg CDN',0,'',''),(9975,'soot','This document is designed to be viewed using the frames feature. If you see this message, you are using a non-frame-capable web client.\n\nLink toNon-frame version.','use frames feature',0,'',''),(9976,'soot','This document is designed to be viewed using the frames feature. If you see this message, you are using a non-frame-capable web client.\n\nLink toNon-frame version.','design document',0,'',''),(9977,'soot','This document is designed to be viewed using the frames feature. If you see this message, you are using a non-frame-capable web client.\n\nLink toNon-frame version.','use non-frame-capable web client',0,'',''),(9978,'react-query','React Query is often described as the missing data-fetching library for React, but in more technical terms, it makes fetching, caching, synchronizing and updating server state in your React applications a breeze.','fetch breeze',0,'',''),(9979,'react-query','React Query is often described as the missing data-fetching library for React, but in more technical terms, it makes fetching, caching, synchronizing and updating server state in your React applications a breeze.','describe react Query as missing data-fetching library',0,'',''),(9980,'react-query','Out of the box, React applications do not come with an opinionated way of fetching or updating data from your components so developers end up building their own ways of fetching data. This usually means cobbling together component-based state and effect using React hooks, or using more general purpose state management libraries to store and provide asynchronous data throughout their apps.','fetch data from components',0,'',''),(9981,'react-query','Out of the box, React applications do not come with an opinionated way of fetching or updating data from your components so developers end up building their own ways of fetching data. This usually means cobbling together component-based state and effect using React hooks, or using more general purpose state management libraries to store and provide asynchronous data throughout their apps.','update data from components',0,'',''),(9982,'react-query','Out of the box, React applications do not come with an opinionated way of fetching or updating data from your components so developers end up building their own ways of fetching data. This usually means cobbling together component-based state and effect using React hooks, or using more general purpose state management libraries to store and provide asynchronous data throughout their apps.','fetch data',0,'',''),(9983,'react-query','Out of the box, React applications do not come with an opinionated way of fetching or updating data from your components so developers end up building their own ways of fetching data. This usually means cobbling together component-based state and effect using React hooks, or using more general purpose state management libraries to store and provide asynchronous data throughout their apps.','use React hooks',0,'',''),(9984,'react-query','Out of the box, React applications do not come with an opinionated way of fetching or updating data from your components so developers end up building their own ways of fetching data. This usually means cobbling together component-based state and effect using React hooks, or using more general purpose state management libraries to store and provide asynchronous data throughout their apps.','use general purpose state management libraries',0,'',''),(9985,'react-query','Out of the box, React applications do not come with an opinionated way of fetching or updating data from your components so developers end up building their own ways of fetching data. This usually means cobbling together component-based state and effect using React hooks, or using more general purpose state management libraries to store and provide asynchronous data throughout their apps.','store asynchronous data throughout apps',0,'',''),(9986,'react-query','Out of the box, React applications do not come with an opinionated way of fetching or updating data from your components so developers end up building their own ways of fetching data. This usually means cobbling together component-based state and effect using React hooks, or using more general purpose state management libraries to store and provide asynchronous data throughout their apps.','provide asynchronous data throughout apps',0,'',''),(9987,'react-query','React Query is hands down one of the best libraries for managing server state. It works amazingly well out-of-the-box, with zero-config, and can be customized to your liking as your application grows.','customize  to liking',1,'https://tanstack.com/query/v4/docs/overview','enough-talk-show-me-some-code-already'),(9988,'react-query','Open in CodeSandbox','open  in CodeSandbox',0,'',''),(9989,'Pytorch','Find resources and get questions answered','find resources',0,'',''),(9990,'Pytorch','Find resources and get questions answered','get questions',0,'',''),(9991,'Pytorch','Find events, webinars, and podcasts','find events',0,'',''),(9992,'Pytorch','Find events, webinars, and podcasts','find webinars',0,'',''),(9993,'Pytorch','Find events, webinars, and podcasts','find podcasts',0,'',''),(9994,'Pytorch','Discover, publish, and reuse pre-trained models','reuse pre-trained models',0,'',''),(9995,'Pytorch','TorchServe is a performant, flexible and easy to use tool for serving PyTorch eager mode and torschripted models.','use tool for serving',0,'',''),(9996,'Pytorch','Model Archive Quick Start - Tutorial that shows you how to package a model archive file.','show tutorial',0,'',''),(9997,'Pytorch','Serving Models - Explains how to use TorchServe','use TorchServe',0,'',''),(9998,'Pytorch','gRPC API - TorchServe supports gRPC APIs for both inference and management calls','support gRPC apis for inference management calls',0,'',''),(9999,'Pytorch','Packaging Model Archive - Explains how to package model archive file, use model-archiver.','use model-archiver',0,'',''),(10000,'Pytorch','Inference API - How to check for the health of a deployed model and get inferences','get inferences',0,'',''),(10001,'Pytorch','Inference API - How to check for the health of a deployed model and get inferences','check  for health',0,'',''),(10002,'Pytorch','Management API - How to manage and scale models','manage models',0,'',''),(10003,'Pytorch','Management API - How to manage and scale models','scale models',0,'',''),(10004,'Pytorch','Metrics - How to configure metrics','configure metrics',0,'',''),(10005,'Pytorch','Prometheus and Grafana metrics - How to configure metrics API with Prometheus formatted metrics in a Grafana dashboard','configure metrics API with Prometheus',0,'',''),(10006,'Pytorch','Prometheus and Grafana metrics - How to configure metrics API with Prometheus formatted metrics in a Grafana dashboard','format metrics in Grafana dashboard',0,'',''),(10007,'Pytorch','Batch inference with TorchServe - How to create and serve a model with batch inference in TorchServe','create model with batch inference',0,'',''),(10008,'Pytorch','Batch inference with TorchServe - How to create and serve a model with batch inference in TorchServe','create model in TorchServe',0,'',''),(10009,'Pytorch','Workflows - How to create workflows to compose Pytorch models and Python functions in sequential and parallel pipelines','compose Pytorch models in sequential parallel pipelines',0,'',''),(10010,'Pytorch','Workflows - How to create workflows to compose Pytorch models and Python functions in sequential and parallel pipelines','compose Python functions in sequential parallel pipelines',0,'',''),(10011,'Pytorch','Image Classifier - This handler takes an image and returns the name of object in that image','return name in image',0,'',''),(10012,'Pytorch','Image Classifier - This handler takes an image and returns the name of object in that image','return name of object',0,'',''),(10013,'Pytorch','Text Classifier - This handler takes a text (string) as input and returns the classification text based on the model vocabulary','return classification text',0,'',''),(10014,'Pytorch','HuggingFace Language Model - This handler takes an input sentence and can return sequence classifications, token classifications or Q&A answers','return token classifications',0,'',''),(10015,'Pytorch','HuggingFace Language Model - This handler takes an input sentence and can return sequence classifications, token classifications or Q&A answers','return q&amp;a answers',0,'',''),(10016,'Pytorch','HuggingFace Language Model - This handler takes an input sentence and can return sequence classifications, token classifications or Q&A answers','return sequence classifications',0,'',''),(10017,'Pytorch','Multi Modal Framework - Build and deploy a classifier that combines text, audio and video input data','combine audio video input data',0,'',''),(10018,'Pytorch','Multi Modal Framework - Build and deploy a classifier that combines text, audio and video input data','combine build deploy classifier',0,'',''),(10019,'Pytorch','Workflow Examples - Examples of how to compose models in a workflow with TorchServe','compose models in workflow',0,'',''),(10020,'Pytorch','A/B test models - A/B test your models for regressions before shipping them to production','test models before shipping',0,'',''),(10021,'Pytorch','A/B test models - A/B test your models for regressions before shipping them to production','test models for regressions',0,'',''),(10022,'Pytorch','Custom Service - Describes how to develop custom inference services.','develop custom inference services',0,'',''),(10023,'Pytorch','TorchServe on Kubernetes -  Demonstrates a Torchserve deployment in Kubernetes using Helm Chart supported in both Azure Kubernetes Service and Google Kubernetes service','use Helm chart',0,'',''),(10024,'Pytorch','TorchServe on Kubernetes -  Demonstrates a Torchserve deployment in Kubernetes using Helm Chart supported in both Azure Kubernetes Service and Google Kubernetes service','support  in Azure kubernetes Service',0,'',''),(10025,'Pytorch','TorchServe on Kubernetes -  Demonstrates a Torchserve deployment in Kubernetes using Helm Chart supported in both Azure Kubernetes Service and Google Kubernetes service','support  in Google kubernetes service',0,'',''),(10026,'Pytorch','Get in-depth tutorials for beginners and advanced developers','get in-depth tutorials for beginners',0,'',''),(10027,'Pytorch','Get in-depth tutorials for beginners and advanced developers','get in-depth tutorials for advanced developers',0,'',''),(10028,'Pytorch','Find development resources and get your questions answered','find development resources',0,'',''),(10029,'Pytorch','Find development resources and get your questions answered','get questions',0,'',''),(10030,'Pytorch','© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.\n          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see\n          www.linuxfoundation.org/policies/. The PyTorch Foundation supports the PyTorch open source\n          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,\n          please see www.lfprojects.org/policies/.','support PyTorch open source project',0,'',''),(10031,'Pytorch','Learn the Basics\nFamiliarize yourself with PyTorch concepts and modules. Learn how to load data, build deep neural networks, train and save your models in this quickstart guide.\nGet started with PyTorch','load data',0,'',''),(10032,'Pytorch','Learn the Basics\nFamiliarize yourself with PyTorch concepts and modules. Learn how to load data, build deep neural networks, train and save your models in this quickstart guide.\nGet started with PyTorch','save models in quickstart guide',0,'',''),(10033,'Pytorch','Learn the Basics\n\nA step-by-step guide to building a complete ML workflow with PyTorch.\nGetting-Started','learn Basics',0,'',''),(10034,'Pytorch','Learning PyTorch with Examples\n\nThis tutorial introduces the fundamental concepts of PyTorch through self-contained examples.\nGetting-Started','introduce fundamental concepts through self-contained examples',0,'',''),(10035,'Pytorch','Learning PyTorch with Examples\n\nThis tutorial introduces the fundamental concepts of PyTorch through self-contained examples.\nGetting-Started','introduce fundamental concepts of PyTorch',0,'',''),(10036,'Pytorch','What is torch.nn really?\n\nUse torch.nn to create and train a neural network.\nGetting-Started','use torch.nn',0,'',''),(10037,'Pytorch','What is torch.nn really?\n\nUse torch.nn to create and train a neural network.\nGetting-Started','create neural network',0,'',''),(10038,'Pytorch','Visualizing Models, Data, and Training with TensorBoard\n\nLearn to use TensorBoard to visualize data and model training.\nInterpretability,Getting-Started,TensorBoard','use TensorBoard',0,'',''),(10039,'Pytorch','Transfer Learning for Computer Vision Tutorial\n\nTrain a convolutional neural network for image classification using transfer learning.\nImage/Video','use transfer learning',0,'',''),(10040,'Pytorch','Optimizing Vision Transformer Model\n\nApply cutting-edge, attention-based transformer models to computer vision tasks.\nImage/Video','apply cutting-edge attention-based transformer models to computer vision tasks',0,'',''),(10041,'Pytorch','Adversarial Example Generation\n\nTrain a convolutional neural network for image classification using transfer learning.\nImage/Video','use transfer learning',0,'',''),(10042,'Pytorch','DCGAN Tutorial\n\nTrain a generative adversarial network (GAN) to generate new celebrities.\nImage/Video','generate new celebrities',0,'',''),(10043,'Pytorch','Spatial Transformer Networks Tutorial\n\nLearn how to augment your network using a visual attention mechanism.\nImage/Video','use visual attention mechanism',0,'',''),(10044,'Pytorch','Audio Resampling\n\nLearn to resample audio waveforms using torchaudio.\nAudio','use torchaudio',0,'',''),(10045,'Pytorch','Audio Data Augmentation\n\nLearn to apply data augmentations using torchaudio.\nAudio','apply data',0,'',''),(10046,'Pytorch','Audio Data Augmentation\n\nLearn to apply data augmentations using torchaudio.\nAudio','use torchaudio',0,'',''),(10047,'Pytorch','Audio Feature Extractions\n\nLearn to extract features using torchaudio.\nAudio','use torchaudio',0,'',''),(10048,'Pytorch','Audio Feature Augmentation\n\nLearn to augment features using torchaudio.\nAudio','use torchaudio',0,'',''),(10049,'Pytorch','Audio Datasets\n\nLearn to use torchaudio datasets.\nAudio','use torchaudio datasets',0,'',''),(10050,'Pytorch','Automatic Speech Recognition with Wav2Vec2 in torchaudio\n\nLearn how to use torchaudio\'s pretrained models for building a speech recognition application.\nAudio','use torchaudio',0,'',''),(10051,'Pytorch','Speech Command Classification\n\nLearn how to correctly format an audio dataset and then train/test an audio classifier network on the dataset.\nAudio','format audio dataset',0,'',''),(10052,'Pytorch','Text-to-Speech with torchaudio\n\nLearn how to use torchaudio\'s pretrained models for building a text-to-speech application.\nAudio','use pretrained models for building',0,'',''),(10053,'Pytorch','Forced Alignment with Wav2Vec2 in torchaudio\n\nLearn how to use torchaudio\'s Wav2Vec2 pretrained models for aligning text to speech\nAudio','force Alignment with Wav2Vec2',0,'',''),(10054,'Pytorch','Forced Alignment with Wav2Vec2 in torchaudio\n\nLearn how to use torchaudio\'s Wav2Vec2 pretrained models for aligning text to speech\nAudio','use Wav2Vec2 pretrained models for aligning',0,'',''),(10055,'Pytorch','Forced Alignment with Wav2Vec2 in torchaudio\n\nLearn how to use torchaudio\'s Wav2Vec2 pretrained models for aligning text to speech\nAudio','align text to speech audio',0,'',''),(10056,'Pytorch','Fast Transformer Inference with Better Transformer\n\nDeploy a PyTorch Transformer model using Better Transformer with high performance for inference\nProduction,Text','use Better transformer with high performance',0,'',''),(10057,'Pytorch','Sequence-to-Sequence Modeling with nn.Transformer and torchtext\n\nLearn how to train a sequence-to-sequence model that uses the nn.Transformer module.\nText','use nn.Transformer module',0,'',''),(10058,'Pytorch','Sequence-to-Sequence Modeling with nn.Transformer and torchtext\n\nLearn how to train a sequence-to-sequence model that uses the nn.Transformer module.\nText','use sequence-to-sequence model',0,'',''),(10059,'Pytorch','NLP from Scratch: Generating Names with a Character-level RNN\n\nAfter using character-level RNN to classify names, learn how to generate names from languages. Second in a series of three tutorials.\nText','use character-level RNN',0,'',''),(10060,'Pytorch','NLP from Scratch: Generating Names with a Character-level RNN\n\nAfter using character-level RNN to classify names, learn how to generate names from languages. Second in a series of three tutorials.\nText','generate names from languages',0,'',''),(10061,'Pytorch','NLP from Scratch: Generating Names with a Character-level RNN\n\nAfter using character-level RNN to classify names, learn how to generate names from languages. Second in a series of three tutorials.\nText','learn <h4> NLP from scratch',0,'',''),(10062,'Pytorch','NLP from Scratch: Translation with a Sequence-to-sequence Network and Attention\n\nThis is the third and final tutorial on doing “NLP From Scratch”, where we write our own classes and functions to preprocess the data to do our NLP modeling tasks.\nText','write functions',0,'',''),(10063,'Pytorch','NLP from Scratch: Translation with a Sequence-to-sequence Network and Attention\n\nThis is the third and final tutorial on doing “NLP From Scratch”, where we write our own classes and functions to preprocess the data to do our NLP modeling tasks.\nText','write own classes',0,'',''),(10064,'Pytorch','NLP from Scratch: Translation with a Sequence-to-sequence Network and Attention\n\nThis is the third and final tutorial on doing “NLP From Scratch”, where we write our own classes and functions to preprocess the data to do our NLP modeling tasks.\nText','write scratch',0,'',''),(10065,'Pytorch','Text Classification with Torchtext\n\nLearn how to build the dataset and classify text using torchtext library.\nText','use torchtext library',0,'',''),(10066,'Pytorch','Language Translation with Transformer\n\nTrain a language translation model from scratch using Transformer.\nText','use transformer',0,'',''),(10067,'Pytorch','Reinforcement Learning (DQN)\n\nLearn how to use PyTorch to train a Deep Q Learning (DQN) agent on the CartPole-v0 task from the OpenAI Gym.\nReinforcement-Learning','use PyTorch',0,'',''),(10068,'Pytorch','Train a Mario-playing RL Agent\n\nUse PyTorch to train a Double Q-learning agent to play Mario.\nReinforcement-Learning','play mario',0,'',''),(10069,'Pytorch','Deploying PyTorch in Python via a REST API with Flask\n\nDeploy a PyTorch model using Flask and expose a REST API for model inference using the example of a pretrained DenseNet 121 model which detects the image.\nProduction','deploy PyTorch model',0,'',''),(10070,'Pytorch','Deploying PyTorch in Python via a REST API with Flask\n\nDeploy a PyTorch model using Flask and expose a REST API for model inference using the example of a pretrained DenseNet 121 model which detects the image.\nProduction','use Flask',0,'',''),(10071,'Pytorch','Deploying PyTorch in Python via a REST API with Flask\n\nDeploy a PyTorch model using Flask and expose a REST API for model inference using the example of a pretrained DenseNet 121 model which detects the image.\nProduction','expose REST API for model inference',0,'',''),(10072,'Pytorch','Introduction to TorchScript\n\nIntroduction to TorchScript, an intermediate representation of a PyTorch model (subclass of nn.Module) that can then be run in a high-performance environment such as C++.\nProduction,TorchScript','run intermediate representation in high-performance environment',0,'',''),(10073,'Pytorch','Introduction to TorchScript\n\nIntroduction to TorchScript, an intermediate representation of a PyTorch model (subclass of nn.Module) that can then be run in a high-performance environment such as C++.\nProduction,TorchScript','run intermediate representation of PyTorch model',0,'',''),(10074,'Pytorch','Loading a TorchScript Model in C++\n\nLearn how PyTorch provides to go from an existing Python model to a serialized representation that can be loaded and executed purely from C++, with no dependency on Python.\nProduction,TorchScript','load TorchScript model in c + + learn',0,'',''),(10075,'Pytorch','Loading a TorchScript Model in C++\n\nLearn how PyTorch provides to go from an existing Python model to a serialized representation that can be loaded and executed purely from C++, with no dependency on Python.\nProduction,TorchScript','provide  to serialized representation',0,'',''),(10076,'Pytorch','Loading a TorchScript Model in C++\n\nLearn how PyTorch provides to go from an existing Python model to a serialized representation that can be loaded and executed purely from C++, with no dependency on Python.\nProduction,TorchScript','load serialized representation',0,'',''),(10077,'Pytorch','Loading a TorchScript Model in C++\n\nLearn how PyTorch provides to go from an existing Python model to a serialized representation that can be loaded and executed purely from C++, with no dependency on Python.\nProduction,TorchScript','execute serialized representation',0,'',''),(10078,'Pytorch','(optional) Exporting a Model from PyTorch to ONNX and Running it using ONNX Runtime\n\nConvert a model defined in PyTorch into the ONNX format and then run it with ONNX Runtime.\nProduction','use ONNX runtime convert',0,'',''),(10079,'Pytorch','(optional) Exporting a Model from PyTorch to ONNX and Running it using ONNX Runtime\n\nConvert a model defined in PyTorch into the ONNX format and then run it with ONNX Runtime.\nProduction','use ONNX',0,'',''),(10080,'Pytorch','(optional) Exporting a Model from PyTorch to ONNX and Running it using ONNX Runtime\n\nConvert a model defined in PyTorch into the ONNX format and then run it with ONNX Runtime.\nProduction','use Running',0,'',''),(10081,'Pytorch','(optional) Exporting a Model from PyTorch to ONNX and Running it using ONNX Runtime\n\nConvert a model defined in PyTorch into the ONNX format and then run it with ONNX Runtime.\nProduction','run ONNX with ONNX runtime',0,'',''),(10082,'Pytorch','(optional) Exporting a Model from PyTorch to ONNX and Running it using ONNX Runtime\n\nConvert a model defined in PyTorch into the ONNX format and then run it with ONNX Runtime.\nProduction','run Running with ONNX runtime',0,'',''),(10083,'Pytorch','(optional) Exporting a Model from PyTorch to ONNX and Running it using ONNX Runtime\n\nConvert a model defined in PyTorch into the ONNX format and then run it with ONNX Runtime.\nProduction','define ONNX runtime convert into ONNX format',0,'',''),(10084,'Pytorch','(optional) Exporting a Model from PyTorch to ONNX and Running it using ONNX Runtime\n\nConvert a model defined in PyTorch into the ONNX format and then run it with ONNX Runtime.\nProduction','define ONNX runtime convert in PyTorch',0,'',''),(10085,'Pytorch','Building a Convolution/Batch Norm fuser in FX\n\nBuild a simple FX pass that fuses batch norm into convolution to improve performance during inference.\nFX','pass fuses batch norm into convolution',0,'',''),(10086,'Pytorch','(beta) Channels Last Memory Format in PyTorch\n\nGet an overview of Channels Last memory format and understand how it is used to order NCHW tensors in memory preserving dimensions.\nMemory-Format,Best-Practice,Frontend-APIs','get overview of Channels last memory format',0,'',''),(10087,'Pytorch','(beta) Channels Last Memory Format in PyTorch\n\nGet an overview of Channels Last memory format and understand how it is used to order NCHW tensors in memory preserving dimensions.\nMemory-Format,Best-Practice,Frontend-APIs','order NCHW tensors in memory',0,'',''),(10088,'Pytorch','Using the PyTorch C++ Frontend\n\nWalk through an end-to-end example of training a model with the C++ frontend by training a DCGAN – a kind of generative model – to generate images of MNIST digits.\nFrontend-APIs,C++','use PyTorch',0,'',''),(10089,'Pytorch','Using the PyTorch C++ Frontend\n\nWalk through an end-to-end example of training a model with the C++ frontend by training a DCGAN – a kind of generative model – to generate images of MNIST digits.\nFrontend-APIs,C++','generate images of MNIST digits',0,'',''),(10090,'Pytorch','Custom C++ and CUDA Extensions\n\nCreate a neural network layer with no parameters using numpy. Then use scipy to create a neural network layer that has learnable weights.\nExtending-PyTorch,Frontend-APIs,C++,CUDA','create neural network layer with parameters',0,'',''),(10091,'Pytorch','Custom C++ and CUDA Extensions\n\nCreate a neural network layer with no parameters using numpy. Then use scipy to create a neural network layer that has learnable weights.\nExtending-PyTorch,Frontend-APIs,C++,CUDA','create neural network layer',0,'',''),(10092,'Pytorch','Extending TorchScript with Custom C++ Operators\n\nImplement a custom TorchScript operator in C++, how to build it into a shared library, how to use it in Python to define TorchScript models and lastly how to load it into a C++ application for inference workloads.\nExtending-PyTorch,Frontend-APIs,TorchScript,C++','use  in Python',0,'',''),(10093,'Pytorch','Extending TorchScript with Custom C++ Operators\n\nImplement a custom TorchScript operator in C++, how to build it into a shared library, how to use it in Python to define TorchScript models and lastly how to load it into a C++ application for inference workloads.\nExtending-PyTorch,Frontend-APIs,TorchScript,C++','define TorchScript models',0,'',''),(10094,'Pytorch','Extending TorchScript with Custom C++ Operators\n\nImplement a custom TorchScript operator in C++, how to build it into a shared library, how to use it in Python to define TorchScript models and lastly how to load it into a C++ application for inference workloads.\nExtending-PyTorch,Frontend-APIs,TorchScript,C++','load  into application',0,'',''),(10095,'Pytorch','Extending TorchScript with Custom C++ Classes\n\nThis is a continuation of the custom operator tutorial, and introduces the API we’ve built for binding C++ classes into TorchScript and Python simultaneously.\nExtending-PyTorch,Frontend-APIs,TorchScript,C++','introduce API',0,'',''),(10096,'Pytorch','Dynamic Parallelism in TorchScript\n\nThis tutorial introduces the syntax for doing *dynamic inter-op parallelism* in TorchScript.\nFrontend-APIs,TorchScript,C++','introduce syntax for doing',0,'',''),(10097,'Pytorch','Real Time Inference on Raspberry Pi 4\n\nThis tutorial covers how to run quantized and fused models on a Raspberry Pi 4 at 30 fps.\nTorchScript,Model-Optimization,Image/Video,Quantization','run quantized fused models at fps',0,'',''),(10098,'Pytorch','Real Time Inference on Raspberry Pi 4\n\nThis tutorial covers how to run quantized and fused models on a Raspberry Pi 4 at 30 fps.\nTorchScript,Model-Optimization,Image/Video,Quantization','run quantized fused models on Raspberry pi',0,'',''),(10099,'Pytorch','Registering a Dispatched Operator in C++\n\nThe dispatcher is an internal component of PyTorch which is responsible for figuring out what code should actually get run when you call a function like torch::add.\nExtending-PyTorch,Frontend-APIs,C++','get run',0,'',''),(10100,'Pytorch','Registering a Dispatched Operator in C++\n\nThe dispatcher is an internal component of PyTorch which is responsible for figuring out what code should actually get run when you call a function like torch::add.\nExtending-PyTorch,Frontend-APIs,C++','call function like torch',0,'',''),(10101,'Pytorch','Extending Dispatcher For a New Backend in C++\n\nLearn how to extend the dispatcher to add a new device living outside of the pytorch/pytorch repo and maintain it to keep in sync with native PyTorch devices.\nExtending-PyTorch,Frontend-APIs,C++','extend dispatcher',0,'',''),(10102,'Pytorch','Extending Dispatcher For a New Backend in C++\n\nLearn how to extend the dispatcher to add a new device living outside of the pytorch/pytorch repo and maintain it to keep in sync with native PyTorch devices.\nExtending-PyTorch,Frontend-APIs,C++','add new device living outside of pytorch/pytorch repo',0,'',''),(10103,'Pytorch','Custom Function Tutorial: Double Backward\n\nLearn how to write a custom autograd Function that supports double backward.\nExtending-PyTorch,Frontend-APIs','write custom',0,'',''),(10104,'Pytorch','Custom Function Tutorial: Double Backward\n\nLearn how to write a custom autograd Function that supports double backward.\nExtending-PyTorch,Frontend-APIs','support Function',0,'',''),(10105,'Pytorch','Custom Function Tutorial: Fusing Convolution and Batch Norm\n\nLearn how to create a custom autograd Function that fuses batch norm into a convolution to improve memory usage.\nExtending-PyTorch,Frontend-APIs','create custom',0,'',''),(10106,'Pytorch','Forward-mode Automatic Differentiation\n\nLearn how to use forward-mode automatic differentiation.\nFrontend-APIs','use forward-mode automatic differentiation',0,'',''),(10107,'Pytorch','Performance Profiling in PyTorch\n\nLearn how to use the PyTorch Profiler to benchmark your module\'s performance.\nModel-Optimization,Best-Practice,Profiling','use PyTorch profiler',0,'',''),(10108,'Pytorch','Performance Profiling in TensorBoard\n\nLearn how to use the TensorBoard plugin to profile and analyze your model\'s performance.\nModel-Optimization,Best-Practice,Profiling,TensorBoard','use TensorBoard plugin',0,'',''),(10109,'Pytorch','Parametrizations Tutorial\n\nLearn how to use torch.nn.utils.parametrize to put constriants on your parameters (e.g. make them orthogonal, symmetric positive definite, low-rank...)\nModel-Optimization,Best-Practice','use torch.nn.utils.parametrize',0,'',''),(10110,'Pytorch','Pruning Tutorial\n\nLearn how to use torch.nn.utils.prune to sparsify your neural networks, and how to extend it to implement your own custom pruning technique.\nModel-Optimization,Best-Practice','use torch.nn.utils.prune',0,'',''),(10111,'Pytorch','Pruning Tutorial\n\nLearn how to use torch.nn.utils.prune to sparsify your neural networks, and how to extend it to implement your own custom pruning technique.\nModel-Optimization,Best-Practice','extend torch.nn.utils.prune',0,'',''),(10112,'Pytorch','Pruning Tutorial\n\nLearn how to use torch.nn.utils.prune to sparsify your neural networks, and how to extend it to implement your own custom pruning technique.\nModel-Optimization,Best-Practice','implement own custom pruning technique',0,'',''),(10113,'Pytorch','(beta) Dynamic Quantization on BERT\n\nApply the dynamic quantization on a BERT (Bidirectional Embedding Representations from Transformers) model.\nText,Quantization,Model-Optimization','apply dynamic quantization on BERT model',0,'',''),(10114,'Pytorch','(beta) Quantized Transfer Learning for Computer Vision Tutorial\n\nExtends the Transfer Learning for Computer Vision Tutorial using a quantized model.\nImage/Video,Quantization,Model-Optimization','use quantized model',0,'',''),(10115,'Pytorch','(beta) Quantized Transfer Learning for Computer Vision Tutorial\n\nExtends the Transfer Learning for Computer Vision Tutorial using a quantized model.\nImage/Video,Quantization,Model-Optimization','learn  for Computer',0,'',''),(10116,'Pytorch','(beta) Static Quantization with Eager Mode in PyTorch\n\nThis tutorial shows how to do post-training static quantization.\nQuantization','show  in PyTorch',0,'',''),(10117,'Pytorch','Multi-Objective Neural Architecture Search with Ax\n\nLearn how to use Ax to search over architectures find optimal tradeoffs between accuracy and latency.\nModel-Optimization,Best-Practice,Ax,TorchX','find optimal tradeoffs between accuracy',0,'',''),(10118,'Pytorch','Multi-Objective Neural Architecture Search with Ax\n\nLearn how to use Ax to search over architectures find optimal tradeoffs between accuracy and latency.\nModel-Optimization,Best-Practice,Ax,TorchX','find optimal tradeoffs between latency',0,'',''),(10119,'Pytorch','PyTorch Distributed Overview\n\nBriefly go over all concepts and features in the distributed package. Use this document to find the distributed training technology that can best serve your application.\nParallel-and-Distributed-Training','use document',0,'',''),(10120,'Pytorch','PyTorch Distributed Overview\n\nBriefly go over all concepts and features in the distributed package. Use this document to find the distributed training technology that can best serve your application.\nParallel-and-Distributed-Training','find distributed training technology',0,'',''),(10121,'Pytorch','Single-Machine Model Parallel Best Practices\n\nLearn how to implement model parallel, a distributed training technique which splits a single model onto different GPUs, rather than replicating the entire model on each GPU\nParallel-and-Distributed-Training','implement model parallel',0,'',''),(10122,'Pytorch','Single-Machine Model Parallel Best Practices\n\nLearn how to implement model parallel, a distributed training technique which splits a single model onto different GPUs, rather than replicating the entire model on each GPU\nParallel-and-Distributed-Training','split single model onto different gpus',0,'',''),(10123,'Pytorch','Single-Machine Model Parallel Best Practices\n\nLearn how to implement model parallel, a distributed training technique which splits a single model onto different GPUs, rather than replicating the entire model on each GPU\nParallel-and-Distributed-Training','split distributed training technique onto different gpus',0,'',''),(10124,'Pytorch','Single-Machine Model Parallel Best Practices\n\nLearn how to implement model parallel, a distributed training technique which splits a single model onto different GPUs, rather than replicating the entire model on each GPU\nParallel-and-Distributed-Training','replicate entire model on GPU parallel-and-distributed-training',0,'',''),(10125,'Pytorch','Getting Started with Distributed Data Parallel\n\nLearn the basics of when to use distributed data paralle versus data parallel and work through an example to set it up.\nParallel-and-Distributed-Training','get Started with Distributed data Parallel learn',0,'',''),(10126,'Pytorch','Getting Started with Distributed Data Parallel\n\nLearn the basics of when to use distributed data paralle versus data parallel and work through an example to set it up.\nParallel-and-Distributed-Training','use distributed data paralle versus data parallel',0,'',''),(10127,'Pytorch','Writing Distributed Applications with PyTorch\n\nSet up the distributed package of PyTorch, use the different communication strategies, and go over some the internals of the package.\nParallel-and-Distributed-Training','write Distributed applications with PyTorch',0,'',''),(10128,'Pytorch','Writing Distributed Applications with PyTorch\n\nSet up the distributed package of PyTorch, use the different communication strategies, and go over some the internals of the package.\nParallel-and-Distributed-Training','set up distributed package of PyTorch',0,'',''),(10129,'Pytorch','Writing Distributed Applications with PyTorch\n\nSet up the distributed package of PyTorch, use the different communication strategies, and go over some the internals of the package.\nParallel-and-Distributed-Training','use different communication strategies',0,'',''),(10130,'Pytorch','Customize Process Group Backends Using Cpp Extensions\n\nExtend ProcessGroup with custom collective communication implementations.\nParallel-and-Distributed-Training','use cpp Extensions extend ProcessGroup with custom collective communication implementations',0,'',''),(10131,'Pytorch','Getting Started with Distributed RPC Framework\n\nLearn how to build distributed training using the torch.distributed.rpc package.\nParallel-and-Distributed-Training','get Started with Distributed RPC framework learn',0,'',''),(10132,'Pytorch','Getting Started with Distributed RPC Framework\n\nLearn how to build distributed training using the torch.distributed.rpc package.\nParallel-and-Distributed-Training','use torch.distributed.rpc package',0,'',''),(10133,'Pytorch','Implementing a Parameter Server Using Distributed RPC Framework\n\nWalk through a through a simple example of implementing a parameter server using PyTorch’s Distributed RPC framework.\nParallel-and-Distributed-Training','implement Parameter server Using',0,'',''),(10134,'Pytorch','Implementing a Parameter Server Using Distributed RPC Framework\n\nWalk through a through a simple example of implementing a parameter server using PyTorch’s Distributed RPC framework.\nParallel-and-Distributed-Training','implement parameter server',0,'',''),(10135,'Pytorch','Implementing a Parameter Server Using Distributed RPC Framework\n\nWalk through a through a simple example of implementing a parameter server using PyTorch’s Distributed RPC framework.\nParallel-and-Distributed-Training','use Distributed RPC framework',0,'',''),(10136,'Pytorch','Distributed Pipeline Parallelism Using RPC\n\nDemonstrate how to implement distributed pipeline parallelism using RPC\nParallel-and-Distributed-Training','implement distributed pipeline parallelism',0,'',''),(10137,'Pytorch','Distributed Pipeline Parallelism Using RPC\n\nDemonstrate how to implement distributed pipeline parallelism using RPC\nParallel-and-Distributed-Training','use RPC parallel-and-distributed-training',0,'',''),(10138,'Pytorch','Implementing Batch RPC Processing Using Asynchronous Executions\n\nLearn how to use rpc.functions.async_execution to implement batch RPC\nParallel-and-Distributed-Training','implement Batch RPC processing Using asynchronous Executions learn',0,'',''),(10139,'Pytorch','Implementing Batch RPC Processing Using Asynchronous Executions\n\nLearn how to use rpc.functions.async_execution to implement batch RPC\nParallel-and-Distributed-Training','use rpc.functions.async_execution',0,'',''),(10140,'Pytorch','Implementing Batch RPC Processing Using Asynchronous Executions\n\nLearn how to use rpc.functions.async_execution to implement batch RPC\nParallel-and-Distributed-Training','implement batch RPC parallel-and-distributed-training',0,'',''),(10141,'Pytorch','Combining Distributed DataParallel with Distributed RPC Framework\n\nWalk through a through a simple example of how to combine distributed data parallelism with distributed model parallelism.\nParallel-and-Distributed-Training','combine Distributed DataParallel with Distributed RPC framework',0,'',''),(10142,'Pytorch','Combining Distributed DataParallel with Distributed RPC Framework\n\nWalk through a through a simple example of how to combine distributed data parallelism with distributed model parallelism.\nParallel-and-Distributed-Training','combine distributed data parallelism with distributed model parallelism',0,'',''),(10143,'Pytorch','Training Transformer models using Pipeline Parallelism\n\nWalk through a through a simple example of how to train a transformer model using pipeline parallelism.\nParallel-and-Distributed-Training','use Pipeline parallelism',0,'',''),(10144,'Pytorch','Training Transformer models using Pipeline Parallelism\n\nWalk through a through a simple example of how to train a transformer model using pipeline parallelism.\nParallel-and-Distributed-Training','use pipeline parallelism',0,'',''),(10145,'Pytorch','Training Transformer models using Distributed Data Parallel and Pipeline Parallelism\n\nWalk through a through a simple example of how to train a transformer model using Distributed Data Parallel and Pipeline Parallelism\nParallel-and-Distributed-Training','use Pipeline parallelism parallel-and-distributed-training',0,'',''),(10146,'Pytorch','Training Transformer models using Distributed Data Parallel and Pipeline Parallelism\n\nWalk through a through a simple example of how to train a transformer model using Distributed Data Parallel and Pipeline Parallelism\nParallel-and-Distributed-Training','use Distributed data Parallel',0,'',''),(10147,'Pytorch','Getting Started with Fully Sharded Data Parallel(FSDP)\n\nLearn how to train models with Fully Sharded Data Parallel package.\nParallel-and-Distributed-Training','get Started with Fully sharded Data Parallel(FSDP) learn',0,'',''),(10148,'Pytorch','Image Segmentation DeepLabV3 on iOS\n\nA comprehensive step-by-step tutorial on how to prepare and run the PyTorch DeepLabV3 image segmentation model on iOS.\nMobile','prepare PyTorch DeepLabV3 image segmentation model on iOS',0,'',''),(10149,'Pytorch','Image Segmentation DeepLabV3 on iOS\n\nA comprehensive step-by-step tutorial on how to prepare and run the PyTorch DeepLabV3 image segmentation model on iOS.\nMobile','run PyTorch DeepLabV3 image segmentation model on iOS',0,'',''),(10150,'Pytorch','Image Segmentation DeepLabV3 on Android\n\nA comprehensive step-by-step tutorial on how to prepare and run the PyTorch DeepLabV3 image segmentation model on Android.\nMobile','prepare PyTorch DeepLabV3 image segmentation model on android',0,'',''),(10151,'Pytorch','Image Segmentation DeepLabV3 on Android\n\nA comprehensive step-by-step tutorial on how to prepare and run the PyTorch DeepLabV3 image segmentation model on Android.\nMobile','run PyTorch DeepLabV3 image segmentation model on android',0,'',''),(10152,'Pytorch','Introduction to TorchRec\n\nTorchRec is a PyTorch domain library built to provide common sparsity & parallelism primitives needed for large-scale recommender systems.\nTorchRec,Recommender','provide common sparsity &amp; parallelism primitives',0,'',''),(10153,'Pytorch','Exploring TorchRec sharding\n\nThis tutorial covers the sharding schemes of embedding tables by using EmbeddingPlanner and DistributedModelParallel API.\nTorchRec,Recommender','embed tables',0,'',''),(10154,'Pytorch','Exploring TorchRec sharding\n\nThis tutorial covers the sharding schemes of embedding tables by using EmbeddingPlanner and DistributedModelParallel API.\nTorchRec,Recommender','use EmbeddingPlanner DistributedModelParallel API',0,'',''),(10155,'Pytorch','Introduction to TorchMultimodal\n\nTorchMultimodal is a library that provides models, primitives and examples for training multimodal tasks\nTorchMultimodal','provide models for training',0,'',''),(10156,'Pytorch','Introduction to TorchMultimodal\n\nTorchMultimodal is a library that provides models, primitives and examples for training multimodal tasks\nTorchMultimodal','provide primitives for training',0,'',''),(10157,'Pytorch','Introduction to TorchMultimodal\n\nTorchMultimodal is a library that provides models, primitives and examples for training multimodal tasks\nTorchMultimodal','provide examples for training',0,'',''),(10158,'Pytorch','Introduction to TorchMultimodal\n\nTorchMultimodal is a library that provides models, primitives and examples for training multimodal tasks\nTorchMultimodal','provide library for training',0,'',''),(10159,'Pytorch','Examples of PyTorch\nA set of examples around PyTorch in Vision, Text, Reinforcement Learning that you can incorporate in your existing work.\nCheck Out Examples','set  of examples',0,'',''),(10160,'Pytorch','Tutorials on GitHub\nAccess PyTorch Tutorials from GitHub.\nGo To GitHub','access PyTorch tutorials from GitHub',0,'',''),(10161,'Pytorch','Run Tutorials on Google Colab\nLearn how to copy tutorial data into Google Drive so that you can run tutorials on Google Colab.\nOpen','run Tutorials on Google colab learn',0,'',''),(10162,'Pytorch','Run Tutorials on Google Colab\nLearn how to copy tutorial data into Google Drive so that you can run tutorials on Google Colab.\nOpen','run tutorials on Google colab',0,'',''),(10163,'Pytorch','See the posters presented at ecosystem day 2021','present  at ecosystem day',0,'',''),(10164,'Pytorch','See the posters presented at developer day 2021','present  at developer day',0,'',''),(10165,'Pytorch','Learn more about the PyTorch Foundation.','learn  about PyTorch foundation',0,'',''),(10166,'Pytorch','© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation. \n          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see \n          www.linuxfoundation.org/policies/. The PyTorch Foundation supports the PyTorch open source \n          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC, \n          please see www.lfprojects.org/policies/.','support PyTorch open source project',0,'',''),(10167,'Pytorch','This library is part of the PyTorch project. PyTorch is an open source\nmachine learning framework.','learn framework',0,'',''),(10168,'Pytorch','Features described in this documentation are classified by release status:','describe  in documentation',0,'',''),(10169,'Pytorch','Gets the name of the package used to load images','get name of package',0,'',''),(10170,'Pytorch','Gets the name of the package used to load images','use  to load images',0,'',''),(10171,'Pytorch','Returns the currently active video backend used to decode videos.','return active video backend',0,'',''),(10172,'Pytorch','Specifies the package used to load images.','load images',0,'',''),(10173,'Pytorch','backend (string) – Name of the image backend. one of {‘PIL’, ‘accimage’}.\nThe accimage package uses the Intel IPP library. It is\ngenerally faster than PIL, but does not support as many operations.','use Intel IPP library',0,'',''),(10174,'Pytorch','backend (string) – Name of the video backend. one of {‘pyav’, ‘video_reader’}.\nThe pyav package uses the 3rd party PyAv library. It is a Pythonic\nbinding for the FFmpeg libraries.\nThe video_reader package includes a native C++ implementation on\ntop of FFMPEG libraries, and a python API of TorchScript custom operator.\nIt generally decodes faster than pyav, but is perhaps less robust.','use 3rd party PyAv library',0,'',''),(10175,'Pytorch','backend (string) – Name of the video backend. one of {‘pyav’, ‘video_reader’}.\nThe pyav package uses the 3rd party PyAv library. It is a Pythonic\nbinding for the FFmpeg libraries.\nThe video_reader package includes a native C++ implementation on\ntop of FFMPEG libraries, and a python API of TorchScript custom operator.\nIt generally decodes faster than pyav, but is perhaps less robust.','include python API on_top_of FFMPEG libraries',0,'',''),(10176,'Pytorch','backend (string) – Name of the video backend. one of {‘pyav’, ‘video_reader’}.\nThe pyav package uses the 3rd party PyAv library. It is a Pythonic\nbinding for the FFmpeg libraries.\nThe video_reader package includes a native C++ implementation on\ntop of FFMPEG libraries, and a python API of TorchScript custom operator.\nIt generally decodes faster than pyav, but is perhaps less robust.','include python API of TorchScript custom operator',0,'',''),(10177,'Pytorch','backend (string) – Name of the video backend. one of {‘pyav’, ‘video_reader’}.\nThe pyav package uses the 3rd party PyAv library. It is a Pythonic\nbinding for the FFmpeg libraries.\nThe video_reader package includes a native C++ implementation on\ntop of FFMPEG libraries, and a python API of TorchScript custom operator.\nIt generally decodes faster than pyav, but is perhaps less robust.','include native implementation on_top_of FFMPEG libraries',0,'',''),(10178,'Pytorch','backend (string) – Name of the video backend. one of {‘pyav’, ‘video_reader’}.\nThe pyav package uses the 3rd party PyAv library. It is a Pythonic\nbinding for the FFmpeg libraries.\nThe video_reader package includes a native C++ implementation on\ntop of FFMPEG libraries, and a python API of TorchScript custom operator.\nIt generally decodes faster than pyav, but is perhaps less robust.','include native implementation of TorchScript custom operator',0,'',''),(10179,'Pytorch','Building with FFMPEG is disabled by default in the latest main. If you want to use the ‘video_reader’\nbackend, please compile torchvision from source.','disable building with FFMPEG',0,'',''),(10180,'Pytorch','Building with FFMPEG is disabled by default in the latest main. If you want to use the ‘video_reader’\nbackend, please compile torchvision from source.','use âvideo_readerâ backend',0,'',''),(10181,'Pytorch','Building with FFMPEG is disabled by default in the latest main. If you want to use the ‘video_reader’\nbackend, please compile torchvision from source.','compile torchvision from source',0,'',''),(10182,'Pytorch','Join us for our flagship conference experience. Apply Now to attend in person.\nWe are excited to announce that the PyTorch Conference returns in-person as a satellite event to NeurlPS (Neural Information Processing Systems) in New Orleans on Dec. 2nd. This is an opportunity to be part of the biggest PyTorch event of the year!\nWhen: Dec 2nd, 2022\nWhere: New Orleans, Louisiana (USA) at Generations Hall | Virtual option as well\nWhat: The PyTorch Conference brings together leading academics, researchers and developers from the Machine Learning community to learn more about software releases on PyTorch, ways PyTorch is being used in academia and industry, development in trends, and more.\nJoin us for technical talks, project deep dives, and a poster exhibition with the opportunity to meet the authors to learn more about their PyTorch projects and network with the machine learning community. There will also be a virtual option for those who can’t join in-person. More information will be shared soon.\nFor more information please visit our Facebook Event page for virtual livestream information or https://pytorchconference22.splashthat.com for full details.\nFAQs\nQ: Is there a fee to attend the PyTorch Conference?\nA: There is no registration fee to attend the conference, however attendees are responsible for their own travel, and accommodations.\nQ: Is The PyTorch Conference affiliated with NeurIPS?\nA: As a satellite event, we have to use NeurlPS’s hotel portal for reservations, however aside from that our events are independent of one another, meaning registration to our event does not grant you access to NeurlPS and vice versa.\nQ: When will I find out if I have been confirmed for the in-person conference?\nA: The PyTorch Team will be following up with applicants in the next few weeks.\nQuestions: Contact pytorch-marketing@fb.com','return in-person Orleans on dec.',0,'',''),(10183,'Pytorch','Join us for our flagship conference experience. Apply Now to attend in person.\nWe are excited to announce that the PyTorch Conference returns in-person as a satellite event to NeurlPS (Neural Information Processing Systems) in New Orleans on Dec. 2nd. This is an opportunity to be part of the biggest PyTorch event of the year!\nWhen: Dec 2nd, 2022\nWhere: New Orleans, Louisiana (USA) at Generations Hall | Virtual option as well\nWhat: The PyTorch Conference brings together leading academics, researchers and developers from the Machine Learning community to learn more about software releases on PyTorch, ways PyTorch is being used in academia and industry, development in trends, and more.\nJoin us for technical talks, project deep dives, and a poster exhibition with the opportunity to meet the authors to learn more about their PyTorch projects and network with the machine learning community. There will also be a virtual option for those who can’t join in-person. More information will be shared soon.\nFor more information please visit our Facebook Event page for virtual livestream information or https://pytorchconference22.splashthat.com for full details.\nFAQs\nQ: Is there a fee to attend the PyTorch Conference?\nA: There is no registration fee to attend the conference, however attendees are responsible for their own travel, and accommodations.\nQ: Is The PyTorch Conference affiliated with NeurIPS?\nA: As a satellite event, we have to use NeurlPS’s hotel portal for reservations, however aside from that our events are independent of one another, meaning registration to our event does not grant you access to NeurlPS and vice versa.\nQ: When will I find out if I have been confirmed for the in-person conference?\nA: The PyTorch Team will be following up with applicants in the next few weeks.\nQuestions: Contact pytorch-marketing@fb.com','learn  on PyTorch',0,'',''),(10184,'Pytorch','Join us for our flagship conference experience. Apply Now to attend in person.\nWe are excited to announce that the PyTorch Conference returns in-person as a satellite event to NeurlPS (Neural Information Processing Systems) in New Orleans on Dec. 2nd. This is an opportunity to be part of the biggest PyTorch event of the year!\nWhen: Dec 2nd, 2022\nWhere: New Orleans, Louisiana (USA) at Generations Hall | Virtual option as well\nWhat: The PyTorch Conference brings together leading academics, researchers and developers from the Machine Learning community to learn more about software releases on PyTorch, ways PyTorch is being used in academia and industry, development in trends, and more.\nJoin us for technical talks, project deep dives, and a poster exhibition with the opportunity to meet the authors to learn more about their PyTorch projects and network with the machine learning community. There will also be a virtual option for those who can’t join in-person. More information will be shared soon.\nFor more information please visit our Facebook Event page for virtual livestream information or https://pytorchconference22.splashthat.com for full details.\nFAQs\nQ: Is there a fee to attend the PyTorch Conference?\nA: There is no registration fee to attend the conference, however attendees are responsible for their own travel, and accommodations.\nQ: Is The PyTorch Conference affiliated with NeurIPS?\nA: As a satellite event, we have to use NeurlPS’s hotel portal for reservations, however aside from that our events are independent of one another, meaning registration to our event does not grant you access to NeurlPS and vice versa.\nQ: When will I find out if I have been confirmed for the in-person conference?\nA: The PyTorch Team will be following up with applicants in the next few weeks.\nQuestions: Contact pytorch-marketing@fb.com','use dec in academia',0,'',''),(10185,'Pytorch','Join us for our flagship conference experience. Apply Now to attend in person.\nWe are excited to announce that the PyTorch Conference returns in-person as a satellite event to NeurlPS (Neural Information Processing Systems) in New Orleans on Dec. 2nd. This is an opportunity to be part of the biggest PyTorch event of the year!\nWhen: Dec 2nd, 2022\nWhere: New Orleans, Louisiana (USA) at Generations Hall | Virtual option as well\nWhat: The PyTorch Conference brings together leading academics, researchers and developers from the Machine Learning community to learn more about software releases on PyTorch, ways PyTorch is being used in academia and industry, development in trends, and more.\nJoin us for technical talks, project deep dives, and a poster exhibition with the opportunity to meet the authors to learn more about their PyTorch projects and network with the machine learning community. There will also be a virtual option for those who can’t join in-person. More information will be shared soon.\nFor more information please visit our Facebook Event page for virtual livestream information or https://pytorchconference22.splashthat.com for full details.\nFAQs\nQ: Is there a fee to attend the PyTorch Conference?\nA: There is no registration fee to attend the conference, however attendees are responsible for their own travel, and accommodations.\nQ: Is The PyTorch Conference affiliated with NeurIPS?\nA: As a satellite event, we have to use NeurlPS’s hotel portal for reservations, however aside from that our events are independent of one another, meaning registration to our event does not grant you access to NeurlPS and vice versa.\nQ: When will I find out if I have been confirmed for the in-person conference?\nA: The PyTorch Team will be following up with applicants in the next few weeks.\nQuestions: Contact pytorch-marketing@fb.com','use dec in industry',0,'',''),(10186,'Pytorch','Join us for our flagship conference experience. Apply Now to attend in person.\nWe are excited to announce that the PyTorch Conference returns in-person as a satellite event to NeurlPS (Neural Information Processing Systems) in New Orleans on Dec. 2nd. This is an opportunity to be part of the biggest PyTorch event of the year!\nWhen: Dec 2nd, 2022\nWhere: New Orleans, Louisiana (USA) at Generations Hall | Virtual option as well\nWhat: The PyTorch Conference brings together leading academics, researchers and developers from the Machine Learning community to learn more about software releases on PyTorch, ways PyTorch is being used in academia and industry, development in trends, and more.\nJoin us for technical talks, project deep dives, and a poster exhibition with the opportunity to meet the authors to learn more about their PyTorch projects and network with the machine learning community. There will also be a virtual option for those who can’t join in-person. More information will be shared soon.\nFor more information please visit our Facebook Event page for virtual livestream information or https://pytorchconference22.splashthat.com for full details.\nFAQs\nQ: Is there a fee to attend the PyTorch Conference?\nA: There is no registration fee to attend the conference, however attendees are responsible for their own travel, and accommodations.\nQ: Is The PyTorch Conference affiliated with NeurIPS?\nA: As a satellite event, we have to use NeurlPS’s hotel portal for reservations, however aside from that our events are independent of one another, meaning registration to our event does not grant you access to NeurlPS and vice versa.\nQ: When will I find out if I have been confirmed for the in-person conference?\nA: The PyTorch Team will be following up with applicants in the next few weeks.\nQuestions: Contact pytorch-marketing@fb.com','use dec in development',0,'',''),(10187,'Pytorch','Join us for our flagship conference experience. Apply Now to attend in person.\nWe are excited to announce that the PyTorch Conference returns in-person as a satellite event to NeurlPS (Neural Information Processing Systems) in New Orleans on Dec. 2nd. This is an opportunity to be part of the biggest PyTorch event of the year!\nWhen: Dec 2nd, 2022\nWhere: New Orleans, Louisiana (USA) at Generations Hall | Virtual option as well\nWhat: The PyTorch Conference brings together leading academics, researchers and developers from the Machine Learning community to learn more about software releases on PyTorch, ways PyTorch is being used in academia and industry, development in trends, and more.\nJoin us for technical talks, project deep dives, and a poster exhibition with the opportunity to meet the authors to learn more about their PyTorch projects and network with the machine learning community. There will also be a virtual option for those who can’t join in-person. More information will be shared soon.\nFor more information please visit our Facebook Event page for virtual livestream information or https://pytorchconference22.splashthat.com for full details.\nFAQs\nQ: Is there a fee to attend the PyTorch Conference?\nA: There is no registration fee to attend the conference, however attendees are responsible for their own travel, and accommodations.\nQ: Is The PyTorch Conference affiliated with NeurIPS?\nA: As a satellite event, we have to use NeurlPS’s hotel portal for reservations, however aside from that our events are independent of one another, meaning registration to our event does not grant you access to NeurlPS and vice versa.\nQ: When will I find out if I have been confirmed for the in-person conference?\nA: The PyTorch Team will be following up with applicants in the next few weeks.\nQuestions: Contact pytorch-marketing@fb.com','learn  about PyTorch projects',0,'',''),(10188,'Pytorch','Join us for our flagship conference experience. Apply Now to attend in person.\nWe are excited to announce that the PyTorch Conference returns in-person as a satellite event to NeurlPS (Neural Information Processing Systems) in New Orleans on Dec. 2nd. This is an opportunity to be part of the biggest PyTorch event of the year!\nWhen: Dec 2nd, 2022\nWhere: New Orleans, Louisiana (USA) at Generations Hall | Virtual option as well\nWhat: The PyTorch Conference brings together leading academics, researchers and developers from the Machine Learning community to learn more about software releases on PyTorch, ways PyTorch is being used in academia and industry, development in trends, and more.\nJoin us for technical talks, project deep dives, and a poster exhibition with the opportunity to meet the authors to learn more about their PyTorch projects and network with the machine learning community. There will also be a virtual option for those who can’t join in-person. More information will be shared soon.\nFor more information please visit our Facebook Event page for virtual livestream information or https://pytorchconference22.splashthat.com for full details.\nFAQs\nQ: Is there a fee to attend the PyTorch Conference?\nA: There is no registration fee to attend the conference, however attendees are responsible for their own travel, and accommodations.\nQ: Is The PyTorch Conference affiliated with NeurIPS?\nA: As a satellite event, we have to use NeurlPS’s hotel portal for reservations, however aside from that our events are independent of one another, meaning registration to our event does not grant you access to NeurlPS and vice versa.\nQ: When will I find out if I have been confirmed for the in-person conference?\nA: The PyTorch Team will be following up with applicants in the next few weeks.\nQuestions: Contact pytorch-marketing@fb.com','share more information',0,'',''),(10189,'Pytorch','Join us for our flagship conference experience. Apply Now to attend in person.\nWe are excited to announce that the PyTorch Conference returns in-person as a satellite event to NeurlPS (Neural Information Processing Systems) in New Orleans on Dec. 2nd. This is an opportunity to be part of the biggest PyTorch event of the year!\nWhen: Dec 2nd, 2022\nWhere: New Orleans, Louisiana (USA) at Generations Hall | Virtual option as well\nWhat: The PyTorch Conference brings together leading academics, researchers and developers from the Machine Learning community to learn more about software releases on PyTorch, ways PyTorch is being used in academia and industry, development in trends, and more.\nJoin us for technical talks, project deep dives, and a poster exhibition with the opportunity to meet the authors to learn more about their PyTorch projects and network with the machine learning community. There will also be a virtual option for those who can’t join in-person. More information will be shared soon.\nFor more information please visit our Facebook Event page for virtual livestream information or https://pytorchconference22.splashthat.com for full details.\nFAQs\nQ: Is there a fee to attend the PyTorch Conference?\nA: There is no registration fee to attend the conference, however attendees are responsible for their own travel, and accommodations.\nQ: Is The PyTorch Conference affiliated with NeurIPS?\nA: As a satellite event, we have to use NeurlPS’s hotel portal for reservations, however aside from that our events are independent of one another, meaning registration to our event does not grant you access to NeurlPS and vice versa.\nQ: When will I find out if I have been confirmed for the in-person conference?\nA: The PyTorch Team will be following up with applicants in the next few weeks.\nQuestions: Contact pytorch-marketing@fb.com','use hotel portal for reservations',0,'',''),(10190,'Pytorch','We are excited to announce that the PyTorch Conference returns in-person as a satellite event to NeurlPS (Neural Information Processing Systems) in New Orleans on Dec. 2nd. This is an opportunity to be part of the biggest PyTorch event of the year!','return in-person Orleans on dec.',0,'',''),(10191,'Pytorch','What: The PyTorch Conference brings together leading academics, researchers and developers from the Machine Learning community to learn more about software releases on PyTorch, ways PyTorch is being used in academia and industry, development in trends, and more.','learn  about software releases',0,'',''),(10192,'Pytorch','What: The PyTorch Conference brings together leading academics, researchers and developers from the Machine Learning community to learn more about software releases on PyTorch, ways PyTorch is being used in academia and industry, development in trends, and more.','use PyTorch in academia',0,'',''),(10193,'Pytorch','What: The PyTorch Conference brings together leading academics, researchers and developers from the Machine Learning community to learn more about software releases on PyTorch, ways PyTorch is being used in academia and industry, development in trends, and more.','use PyTorch in industry',0,'',''),(10194,'Pytorch','What: The PyTorch Conference brings together leading academics, researchers and developers from the Machine Learning community to learn more about software releases on PyTorch, ways PyTorch is being used in academia and industry, development in trends, and more.','use ways in academia',0,'',''),(10195,'Pytorch','What: The PyTorch Conference brings together leading academics, researchers and developers from the Machine Learning community to learn more about software releases on PyTorch, ways PyTorch is being used in academia and industry, development in trends, and more.','use ways in industry',0,'',''),(10196,'Pytorch','Join us for technical talks, project deep dives, and a poster exhibition with the opportunity to meet the authors to learn more about their PyTorch projects and network with the machine learning community. There will also be a virtual option for those who can’t join in-person. More information will be shared soon.','learn  about PyTorch projects',0,'',''),(10197,'Pytorch','Join us for technical talks, project deep dives, and a poster exhibition with the opportunity to meet the authors to learn more about their PyTorch projects and network with the machine learning community. There will also be a virtual option for those who can’t join in-person. More information will be shared soon.','share more information',0,'',''),(10198,'Pytorch','A: As a satellite event, we have to use NeurlPS’s hotel portal for reservations, however aside from that our events are independent of one another, meaning registration to our event does not grant you access to NeurlPS and vice versa.','use hotel portal for reservations',0,'',''),(10199,'Pytorch','Date: Thursday, September 28, 2022 at 7:30am PT\nJoin us for a conversation between Soumith Chintala and Ibrahim Haddad about the creation of PyTorch Foundation. Over 150,000 developers and 18,000 organizations work with PyTorch today. In this conversation you will learn about:\n\n\nPyTorch’s evolution as an open source project\n\n\nWhere PyTorch is used in production environments and in academic settings\n\n\nNext steps for the project under the PyTorch Foundation\n\n\nRegister here','use PyTorch in production environments',0,'',''),(10200,'Pytorch','Date: Thursday, September 28, 2022 at 7:30am PT\nJoin us for a conversation between Soumith Chintala and Ibrahim Haddad about the creation of PyTorch Foundation. Over 150,000 developers and 18,000 organizations work with PyTorch today. In this conversation you will learn about:\n\n\nPyTorch’s evolution as an open source project\n\n\nWhere PyTorch is used in production environments and in academic settings\n\n\nNext steps for the project under the PyTorch Foundation\n\n\nRegister here','use PyTorch in academic settings',0,'',''),(10201,'Pytorch','Date: Thursday, September 28, 2022 at 7:30am PT\nJoin us for a conversation between Soumith Chintala and Ibrahim Haddad about the creation of PyTorch Foundation. Over 150,000 developers and 18,000 organizations work with PyTorch today. In this conversation you will learn about:\n\n\nPyTorch’s evolution as an open source project\n\n\nWhere PyTorch is used in production environments and in academic settings\n\n\nNext steps for the project under the PyTorch Foundation\n\n\nRegister here','use PyTorch for project',0,'',''),(10202,'Pytorch','Date: Thursday, September 28, 2022 at 7:30am PT\nJoin us for a conversation between Soumith Chintala and Ibrahim Haddad about the creation of PyTorch Foundation. Over 150,000 developers and 18,000 organizations work with PyTorch today. In this conversation you will learn about:\n\n\nPyTorch’s evolution as an open source project\n\n\nWhere PyTorch is used in production environments and in academic settings\n\n\nNext steps for the project under the PyTorch Foundation\n\n\nRegister here','use PyTorch under PyTorch foundation register',0,'',''),(10203,'Pytorch','Join us for a conversation between Soumith Chintala and Ibrahim Haddad about the creation of PyTorch Foundation. Over 150,000 developers and 18,000 organizations work with PyTorch today. In this conversation you will learn about:','learn  in conversation',0,'',''),(10204,'Pytorch','Where PyTorch is used in production environments and in academic settings','use PyTorch in production environments',0,'',''),(10205,'Pytorch','Where PyTorch is used in production environments and in academic settings','use PyTorch in academic settings',0,'',''),(10206,'Pytorch','The PyTorch Developer Day is a virtual event that brings together leading researchers and developers from the Machine Learning (ML) community to join a multiple set of talks covering new software releases, ways PyTorch is being used in academia and industry, and current trends in ML development. Find all the talks below:\n\n\nKeynotes: Learn about the innovations, the new features, updates, and release of PyTorch, and how industries are using it for production and deployment.\n\n\nFireside Chat: An informal and intimate conversation with two pioneers in the field of AI (and PyTorch) sharing their thoughts and vision for the future, commentary on top-of-mind trends they are seeing.\n\n\nCommunity Talks: PyTorch has grown thanks to our community. Hear from our members on the work being done with PyTorch.','use PyTorch in academia',0,'',''),(10207,'Pytorch','The PyTorch Developer Day is a virtual event that brings together leading researchers and developers from the Machine Learning (ML) community to join a multiple set of talks covering new software releases, ways PyTorch is being used in academia and industry, and current trends in ML development. Find all the talks below:\n\n\nKeynotes: Learn about the innovations, the new features, updates, and release of PyTorch, and how industries are using it for production and deployment.\n\n\nFireside Chat: An informal and intimate conversation with two pioneers in the field of AI (and PyTorch) sharing their thoughts and vision for the future, commentary on top-of-mind trends they are seeing.\n\n\nCommunity Talks: PyTorch has grown thanks to our community. Hear from our members on the work being done with PyTorch.','use PyTorch in industry',0,'',''),(10208,'Pytorch','The PyTorch Developer Day is a virtual event that brings together leading researchers and developers from the Machine Learning (ML) community to join a multiple set of talks covering new software releases, ways PyTorch is being used in academia and industry, and current trends in ML development. Find all the talks below:\n\n\nKeynotes: Learn about the innovations, the new features, updates, and release of PyTorch, and how industries are using it for production and deployment.\n\n\nFireside Chat: An informal and intimate conversation with two pioneers in the field of AI (and PyTorch) sharing their thoughts and vision for the future, commentary on top-of-mind trends they are seeing.\n\n\nCommunity Talks: PyTorch has grown thanks to our community. Hear from our members on the work being done with PyTorch.','use ways in academia',0,'',''),(10209,'Pytorch','The PyTorch Developer Day is a virtual event that brings together leading researchers and developers from the Machine Learning (ML) community to join a multiple set of talks covering new software releases, ways PyTorch is being used in academia and industry, and current trends in ML development. Find all the talks below:\n\n\nKeynotes: Learn about the innovations, the new features, updates, and release of PyTorch, and how industries are using it for production and deployment.\n\n\nFireside Chat: An informal and intimate conversation with two pioneers in the field of AI (and PyTorch) sharing their thoughts and vision for the future, commentary on top-of-mind trends they are seeing.\n\n\nCommunity Talks: PyTorch has grown thanks to our community. Hear from our members on the work being done with PyTorch.','use ways in industry',0,'',''),(10210,'Pytorch','The PyTorch Developer Day is a virtual event that brings together leading researchers and developers from the Machine Learning (ML) community to join a multiple set of talks covering new software releases, ways PyTorch is being used in academia and industry, and current trends in ML development. Find all the talks below:\n\n\nKeynotes: Learn about the innovations, the new features, updates, and release of PyTorch, and how industries are using it for production and deployment.\n\n\nFireside Chat: An informal and intimate conversation with two pioneers in the field of AI (and PyTorch) sharing their thoughts and vision for the future, commentary on top-of-mind trends they are seeing.\n\n\nCommunity Talks: PyTorch has grown thanks to our community. Hear from our members on the work being done with PyTorch.','find talks',0,'',''),(10211,'Pytorch','The PyTorch Developer Day is a virtual event that brings together leading researchers and developers from the Machine Learning (ML) community to join a multiple set of talks covering new software releases, ways PyTorch is being used in academia and industry, and current trends in ML development. Find all the talks below:\n\n\nKeynotes: Learn about the innovations, the new features, updates, and release of PyTorch, and how industries are using it for production and deployment.\n\n\nFireside Chat: An informal and intimate conversation with two pioneers in the field of AI (and PyTorch) sharing their thoughts and vision for the future, commentary on top-of-mind trends they are seeing.\n\n\nCommunity Talks: PyTorch has grown thanks to our community. Hear from our members on the work being done with PyTorch.','find keynotes',0,'',''),(10212,'Pytorch','The PyTorch Developer Day is a virtual event that brings together leading researchers and developers from the Machine Learning (ML) community to join a multiple set of talks covering new software releases, ways PyTorch is being used in academia and industry, and current trends in ML development. Find all the talks below:\n\n\nKeynotes: Learn about the innovations, the new features, updates, and release of PyTorch, and how industries are using it for production and deployment.\n\n\nFireside Chat: An informal and intimate conversation with two pioneers in the field of AI (and PyTorch) sharing their thoughts and vision for the future, commentary on top-of-mind trends they are seeing.\n\n\nCommunity Talks: PyTorch has grown thanks to our community. Hear from our members on the work being done with PyTorch.','use  for production',0,'',''),(10213,'Pytorch','The PyTorch Developer Day is a virtual event that brings together leading researchers and developers from the Machine Learning (ML) community to join a multiple set of talks covering new software releases, ways PyTorch is being used in academia and industry, and current trends in ML development. Find all the talks below:\n\n\nKeynotes: Learn about the innovations, the new features, updates, and release of PyTorch, and how industries are using it for production and deployment.\n\n\nFireside Chat: An informal and intimate conversation with two pioneers in the field of AI (and PyTorch) sharing their thoughts and vision for the future, commentary on top-of-mind trends they are seeing.\n\n\nCommunity Talks: PyTorch has grown thanks to our community. Hear from our members on the work being done with PyTorch.','use  for deployment',0,'',''),(10214,'Pytorch','The PyTorch Developer Day is a virtual event that brings together leading researchers and developers from the Machine Learning (ML) community to join a multiple set of talks covering new software releases, ways PyTorch is being used in academia and industry, and current trends in ML development. Find all the talks below:\n\n\nKeynotes: Learn about the innovations, the new features, updates, and release of PyTorch, and how industries are using it for production and deployment.\n\n\nFireside Chat: An informal and intimate conversation with two pioneers in the field of AI (and PyTorch) sharing their thoughts and vision for the future, commentary on top-of-mind trends they are seeing.\n\n\nCommunity Talks: PyTorch has grown thanks to our community. Hear from our members on the work being done with PyTorch.','share thoughts for future',0,'',''),(10215,'Pytorch','The PyTorch Developer Day is a virtual event that brings together leading researchers and developers from the Machine Learning (ML) community to join a multiple set of talks covering new software releases, ways PyTorch is being used in academia and industry, and current trends in ML development. Find all the talks below:\n\n\nKeynotes: Learn about the innovations, the new features, updates, and release of PyTorch, and how industries are using it for production and deployment.\n\n\nFireside Chat: An informal and intimate conversation with two pioneers in the field of AI (and PyTorch) sharing their thoughts and vision for the future, commentary on top-of-mind trends they are seeing.\n\n\nCommunity Talks: PyTorch has grown thanks to our community. Hear from our members on the work being done with PyTorch.','share vision for future',0,'',''),(10216,'Pytorch','The PyTorch Developer Day is a virtual event that brings together leading researchers and developers from the Machine Learning (ML) community to join a multiple set of talks covering new software releases, ways PyTorch is being used in academia and industry, and current trends in ML development. Find all the talks below:','use PyTorch in academia',0,'',''),(10217,'Pytorch','The PyTorch Developer Day is a virtual event that brings together leading researchers and developers from the Machine Learning (ML) community to join a multiple set of talks covering new software releases, ways PyTorch is being used in academia and industry, and current trends in ML development. Find all the talks below:','use PyTorch in industry',0,'',''),(10218,'Pytorch','The PyTorch Developer Day is a virtual event that brings together leading researchers and developers from the Machine Learning (ML) community to join a multiple set of talks covering new software releases, ways PyTorch is being used in academia and industry, and current trends in ML development. Find all the talks below:','use ways in academia',0,'',''),(10219,'Pytorch','The PyTorch Developer Day is a virtual event that brings together leading researchers and developers from the Machine Learning (ML) community to join a multiple set of talks covering new software releases, ways PyTorch is being used in academia and industry, and current trends in ML development. Find all the talks below:','use ways in industry',0,'',''),(10220,'Pytorch','The PyTorch Developer Day is a virtual event that brings together leading researchers and developers from the Machine Learning (ML) community to join a multiple set of talks covering new software releases, ways PyTorch is being used in academia and industry, and current trends in ML development. Find all the talks below:','find talks',0,'',''),(10221,'Pytorch','Keynotes: Learn about the innovations, the new features, updates, and release of PyTorch, and how industries are using it for production and deployment.','use  for production',0,'',''),(10222,'Pytorch','Keynotes: Learn about the innovations, the new features, updates, and release of PyTorch, and how industries are using it for production and deployment.','use  for deployment',0,'',''),(10223,'Pytorch','Fireside Chat: An informal and intimate conversation with two pioneers in the field of AI (and PyTorch) sharing their thoughts and vision for the future, commentary on top-of-mind trends they are seeing.','share thoughts for future',0,'',''),(10224,'Pytorch','Fireside Chat: An informal and intimate conversation with two pioneers in the field of AI (and PyTorch) sharing their thoughts and vision for the future, commentary on top-of-mind trends they are seeing.','share vision for future',0,'',''),(10225,'Pytorch','PyTorch Ecosystem Day, a virtual event designed for our ecosystem and industry communities to showcase their work and discover new opportunities to collaborate. Join us for discussions on new developments, trends, challenges, and best practices through keynotes, breakout sessions, and a unique networking opportunity hosted through Gather.Town.','design  for ecosystem',0,'',''),(10226,'Pytorch','PyTorch Ecosystem Day, a virtual event designed for our ecosystem and industry communities to showcase their work and discover new opportunities to collaborate. Join us for discussions on new developments, trends, challenges, and best practices through keynotes, breakout sessions, and a unique networking opportunity hosted through Gather.Town.','design  for industry communities',0,'',''),(10227,'Pytorch','PyTorch Ecosystem Day, a virtual event designed for our ecosystem and industry communities to showcase their work and discover new opportunities to collaborate. Join us for discussions on new developments, trends, challenges, and best practices through keynotes, breakout sessions, and a unique networking opportunity hosted through Gather.Town.','host  through Gather.Town.',0,'',''),(10228,'Pytorch','The PyTorch Developer Day, a virtual event that brings together leading researchers and developers from the Machine Learning (ML) community to join a multiple set of talks covering new software releases, ways PyTorch is being used in academia and industry, ML development trends, a poster session, and many opportunities for networking.','use ways PyTorch in poster session',0,'',''),(10229,'Pytorch','The PyTorch Developer Day, a virtual event that brings together leading researchers and developers from the Machine Learning (ML) community to join a multiple set of talks covering new software releases, ways PyTorch is being used in academia and industry, ML development trends, a poster session, and many opportunities for networking.','use ways PyTorch in many opportunities',0,'',''),(10230,'Pytorch','The PyTorch Developer Day, a virtual event that brings together leading researchers and developers from the Machine Learning (ML) community to join a multiple set of talks covering new software releases, ways PyTorch is being used in academia and industry, ML development trends, a poster session, and many opportunities for networking.','use ways PyTorch in academia',0,'',''),(10231,'Pytorch','The PyTorch Developer Day, a virtual event that brings together leading researchers and developers from the Machine Learning (ML) community to join a multiple set of talks covering new software releases, ways PyTorch is being used in academia and industry, ML development trends, a poster session, and many opportunities for networking.','use ways PyTorch in industry',0,'',''),(10232,'Pytorch','The PyTorch Developer Day, a virtual event that brings together leading researchers and developers from the Machine Learning (ML) community to join a multiple set of talks covering new software releases, ways PyTorch is being used in academia and industry, ML development trends, a poster session, and many opportunities for networking.','use ways PyTorch in ML development trends',0,'',''),(10233,'Pytorch','The PyTorch Summer Hackathon, a virtual event that invites developers to hack with the PyTorch community to build innovative, impactful models, applications and other projects that create positive impact for businesses or people. In it, developers are able to put their machine learning skills to the test in one of the following categories:\n\n\nPyTorch Developer Tools : Tools or libraries designed to improve productivity and efficiency of PyTorch for researchers and developers.\n\n\nWeb/Mobile Applications powered by PyTorch : Applications with web/mobile interfaces and/or embedded devices powered by PyTorch.\n\n\nPyTorch Responsible AI Development Tools : Tools, libraries, or web/mobile apps for responsible AI development.','create positive impact for businesses',0,'',''),(10234,'Pytorch','The PyTorch Summer Hackathon, a virtual event that invites developers to hack with the PyTorch community to build innovative, impactful models, applications and other projects that create positive impact for businesses or people. In it, developers are able to put their machine learning skills to the test in one of the following categories:\n\n\nPyTorch Developer Tools : Tools or libraries designed to improve productivity and efficiency of PyTorch for researchers and developers.\n\n\nWeb/Mobile Applications powered by PyTorch : Applications with web/mobile interfaces and/or embedded devices powered by PyTorch.\n\n\nPyTorch Responsible AI Development Tools : Tools, libraries, or web/mobile apps for responsible AI development.','create positive impact for people',0,'',''),(10235,'Pytorch','The PyTorch Summer Hackathon, a virtual event that invites developers to hack with the PyTorch community to build innovative, impactful models, applications and other projects that create positive impact for businesses or people. In it, developers are able to put their machine learning skills to the test in one of the following categories:\n\n\nPyTorch Developer Tools : Tools or libraries designed to improve productivity and efficiency of PyTorch for researchers and developers.\n\n\nWeb/Mobile Applications powered by PyTorch : Applications with web/mobile interfaces and/or embedded devices powered by PyTorch.\n\n\nPyTorch Responsible AI Development Tools : Tools, libraries, or web/mobile apps for responsible AI development.','create other projects for businesses',0,'',''),(10236,'Pytorch','The PyTorch Summer Hackathon, a virtual event that invites developers to hack with the PyTorch community to build innovative, impactful models, applications and other projects that create positive impact for businesses or people. In it, developers are able to put their machine learning skills to the test in one of the following categories:\n\n\nPyTorch Developer Tools : Tools or libraries designed to improve productivity and efficiency of PyTorch for researchers and developers.\n\n\nWeb/Mobile Applications powered by PyTorch : Applications with web/mobile interfaces and/or embedded devices powered by PyTorch.\n\n\nPyTorch Responsible AI Development Tools : Tools, libraries, or web/mobile apps for responsible AI development.','create other projects for people',0,'',''),(10237,'Pytorch','The PyTorch Summer Hackathon, a virtual event that invites developers to hack with the PyTorch community to build innovative, impactful models, applications and other projects that create positive impact for businesses or people. In it, developers are able to put their machine learning skills to the test in one of the following categories:','create positive impact for businesses',0,'',''),(10238,'Pytorch','The PyTorch Summer Hackathon, a virtual event that invites developers to hack with the PyTorch community to build innovative, impactful models, applications and other projects that create positive impact for businesses or people. In it, developers are able to put their machine learning skills to the test in one of the following categories:','create positive impact for people',0,'',''),(10239,'Pytorch','The PyTorch Summer Hackathon, a virtual event that invites developers to hack with the PyTorch community to build innovative, impactful models, applications and other projects that create positive impact for businesses or people. In it, developers are able to put their machine learning skills to the test in one of the following categories:','create other projects for businesses',0,'',''),(10240,'Pytorch','The PyTorch Summer Hackathon, a virtual event that invites developers to hack with the PyTorch community to build innovative, impactful models, applications and other projects that create positive impact for businesses or people. In it, developers are able to put their machine learning skills to the test in one of the following categories:','create other projects for people',0,'',''),(10241,'Pytorch','The PyTorch Summer Hackathon, a virtual event that invites developers to hack with the PyTorch community to build innovative, impactful models, applications and other projects that create positive impact for businesses or people. In it, developers are able to put their machine learning skills to the test in one of the following categories:','learn skills to test',0,'',''),(10242,'Pytorch','With TorchScript, PyTorch provides ease-of-use and flexibility in eager mode, while seamlessly transitioning to graph mode for speed, optimization, and functionality in C++ runtime environments.','provide ease-of-use with TorchScript',0,'',''),(10243,'Pytorch','With TorchScript, PyTorch provides ease-of-use and flexibility in eager mode, while seamlessly transitioning to graph mode for speed, optimization, and functionality in C++ runtime environments.','provide ease-of-use in eager mode',0,'',''),(10244,'Pytorch','With TorchScript, PyTorch provides ease-of-use and flexibility in eager mode, while seamlessly transitioning to graph mode for speed, optimization, and functionality in C++ runtime environments.','provide flexibility with TorchScript',0,'',''),(10245,'Pytorch','With TorchScript, PyTorch provides ease-of-use and flexibility in eager mode, while seamlessly transitioning to graph mode for speed, optimization, and functionality in C++ runtime environments.','provide flexibility in eager mode',0,'',''),(10246,'Pytorch','TorchServe is an easy to use tool for deploying PyTorch models at scale. It is cloud and environment agnostic and supports features such as multi-model serving, logging, metrics and the creation of RESTful endpoints for application integration.','deploy PyTorch models at scale',0,'',''),(10247,'Pytorch','TorchServe is an easy to use tool for deploying PyTorch models at scale. It is cloud and environment agnostic and supports features such as multi-model serving, logging, metrics and the creation of RESTful endpoints for application integration.','support features of RESTful endpoints',0,'',''),(10248,'Pytorch','TorchServe is an easy to use tool for deploying PyTorch models at scale. It is cloud and environment agnostic and supports features such as multi-model serving, logging, metrics and the creation of RESTful endpoints for application integration.','support features for application integration',0,'',''),(10249,'Pytorch','TorchServe is an easy to use tool for deploying PyTorch models at scale. It is cloud and environment agnostic and supports features such as multi-model serving, logging, metrics and the creation of RESTful endpoints for application integration.','support features such_as metrics',0,'',''),(10250,'Pytorch','TorchServe is an easy to use tool for deploying PyTorch models at scale. It is cloud and environment agnostic and supports features such as multi-model serving, logging, metrics and the creation of RESTful endpoints for application integration.','support features such_as creation',0,'',''),(10251,'Pytorch','TorchServe is an easy to use tool for deploying PyTorch models at scale. It is cloud and environment agnostic and supports features such as multi-model serving, logging, metrics and the creation of RESTful endpoints for application integration.','support features such_as multi-model serving',0,'',''),(10252,'Pytorch','TorchServe is an easy to use tool for deploying PyTorch models at scale. It is cloud and environment agnostic and supports features such as multi-model serving, logging, metrics and the creation of RESTful endpoints for application integration.','support features such_as logging',0,'',''),(10253,'Pytorch','PyTorch supports an end-to-end workflow from Python to deployment on iOS and Android. It extends the PyTorch API to cover common preprocessing and integration tasks needed for incorporating ML in mobile applications.','support end-to-end workflow from Python',0,'',''),(10254,'Pytorch','PyTorch supports an end-to-end workflow from Python to deployment on iOS and Android. It extends the PyTorch API to cover common preprocessing and integration tasks needed for incorporating ML in mobile applications.','support end-to-end workflow to deployment',0,'',''),(10255,'Pytorch','An active community of researchers and developers have built a rich ecosystem of tools and libraries for extending PyTorch and supporting development in areas from computer vision to reinforcement learning.','extend PyTorch',0,'',''),(10256,'Pytorch','An active community of researchers and developers have built a rich ecosystem of tools and libraries for extending PyTorch and supporting development in areas from computer vision to reinforcement learning.','support development in areas',0,'',''),(10257,'Pytorch','An active community of researchers and developers have built a rich ecosystem of tools and libraries for extending PyTorch and supporting development in areas from computer vision to reinforcement learning.','support development to reinforcement learning',0,'',''),(10258,'Pytorch','The C++ frontend is a pure C++ interface to PyTorch that follows the design and architecture of the established Python frontend. It is intended to enable research in high performance, low latency and bare metal C++ applications.','enable research in high performance',0,'',''),(10259,'Pytorch','The C++ frontend is a pure C++ interface to PyTorch that follows the design and architecture of the established Python frontend. It is intended to enable research in high performance, low latency and bare metal C++ applications.','enable research in low latency',0,'',''),(10260,'Pytorch','The C++ frontend is a pure C++ interface to PyTorch that follows the design and architecture of the established Python frontend. It is intended to enable research in high performance, low latency and bare metal C++ applications.','enable research in bare metal',0,'',''),(10261,'Pytorch','PyTorch is well supported on major cloud platforms, providing frictionless development and easy scaling through prebuilt images, large scale training on GPUs, ability to run models in a production scale environment, and more.','provide large scale training through prebuilt images',0,'',''),(10262,'Pytorch','PyTorch is well supported on major cloud platforms, providing frictionless development and easy scaling through prebuilt images, large scale training on GPUs, ability to run models in a production scale environment, and more.','provide large scale training on gpus',0,'',''),(10263,'Pytorch','PyTorch is well supported on major cloud platforms, providing frictionless development and easy scaling through prebuilt images, large scale training on GPUs, ability to run models in a production scale environment, and more.','provide ability through prebuilt images',0,'',''),(10264,'Pytorch','PyTorch is well supported on major cloud platforms, providing frictionless development and easy scaling through prebuilt images, large scale training on GPUs, ability to run models in a production scale environment, and more.','provide ability on gpus',0,'',''),(10265,'Pytorch','PyTorch is well supported on major cloud platforms, providing frictionless development and easy scaling through prebuilt images, large scale training on GPUs, ability to run models in a production scale environment, and more.','provide development easy scaling through prebuilt images',0,'',''),(10266,'Pytorch','PyTorch is well supported on major cloud platforms, providing frictionless development and easy scaling through prebuilt images, large scale training on GPUs, ability to run models in a production scale environment, and more.','provide development easy scaling on gpus',0,'',''),(10267,'Pytorch','PyTorch is well supported on major cloud platforms, providing frictionless development and easy scaling through prebuilt images, large scale training on GPUs, ability to run models in a production scale environment, and more.','run models in production scale environment',0,'',''),(10268,'Pytorch','PyTorch is well supported on major cloud platforms, providing frictionless development and easy scaling through prebuilt images, large scale training on GPUs, ability to run models in a production scale environment, and more.','support PyTorch on major cloud platforms',0,'',''),(10269,'Pytorch','Select your preferences and run the install command. Stable represents the most currently tested and supported version of PyTorch. This should\n   be suitable for many users. Preview is available if you want the latest, not fully tested and supported, builds that are generated nightly.\n   Please ensure that you have met the prerequisites below (e.g., numpy),  depending on your package manager. Anaconda is our recommended\n   package manager since it installs all dependencies. You can also\n  install previous versions of PyTorch. Note that LibTorch is only available for C++.','select preferences',0,'',''),(10270,'Pytorch','Select your preferences and run the install command. Stable represents the most currently tested and supported version of PyTorch. This should\n   be suitable for many users. Preview is available if you want the latest, not fully tested and supported, builds that are generated nightly.\n   Please ensure that you have met the prerequisites below (e.g., numpy),  depending on your package manager. Anaconda is our recommended\n   package manager since it installs all dependencies. You can also\n  install previous versions of PyTorch. Note that LibTorch is only available for C++.','run install command',0,'',''),(10271,'Pytorch','Select your preferences and run the install command. Stable represents the most currently tested and supported version of PyTorch. This should\n   be suitable for many users. Preview is available if you want the latest, not fully tested and supported, builds that are generated nightly.\n   Please ensure that you have met the prerequisites below (e.g., numpy),  depending on your package manager. Anaconda is our recommended\n   package manager since it installs all dependencies. You can also\n  install previous versions of PyTorch. Note that LibTorch is only available for C++.','test version of PyTorch',0,'',''),(10272,'Pytorch','Select your preferences and run the install command. Stable represents the most currently tested and supported version of PyTorch. This should\n   be suitable for many users. Preview is available if you want the latest, not fully tested and supported, builds that are generated nightly.\n   Please ensure that you have met the prerequisites below (e.g., numpy),  depending on your package manager. Anaconda is our recommended\n   package manager since it installs all dependencies. You can also\n  install previous versions of PyTorch. Note that LibTorch is only available for C++.','support version of PyTorch',0,'',''),(10273,'Pytorch','Select your preferences and run the install command. Stable represents the most currently tested and supported version of PyTorch. This should\n   be suitable for many users. Preview is available if you want the latest, not fully tested and supported, builds that are generated nightly.\n   Please ensure that you have met the prerequisites below (e.g., numpy),  depending on your package manager. Anaconda is our recommended\n   package manager since it installs all dependencies. You can also\n  install previous versions of PyTorch. Note that LibTorch is only available for C++.','install dependencies',0,'',''),(10274,'Pytorch','Select your preferences and run the install command. Stable represents the most currently tested and supported version of PyTorch. This should\n   be suitable for many users. Preview is available if you want the latest, not fully tested and supported, builds that are generated nightly.\n   Please ensure that you have met the prerequisites below (e.g., numpy),  depending on your package manager. Anaconda is our recommended\n   package manager since it installs all dependencies. You can also\n  install previous versions of PyTorch. Note that LibTorch is only available for C++.','install previous versions of PyTorch',0,'',''),(10275,'Pytorch','Get up and running with PyTorch quickly through popular cloud platforms and machine learning services.','run  through popular cloud platforms',0,'',''),(10276,'Pytorch','Get up and running with PyTorch quickly through popular cloud platforms and machine learning services.','run  through machine learning services',0,'',''),(10277,'Pytorch','Get up and running with PyTorch quickly through popular cloud platforms and machine learning services.','run  with PyTorch',0,'',''),(10278,'Pytorch','TorchRec is a PyTorch domain library built to provide common\nsparsity & parallelism primitives needed for large-scale recommender\nsystems (RecSys). It allows authors to train models with large\nembedding tables sharded across many GPUs.','provide common sparsity &amp; parallelism primitives',0,'',''),(10279,'Pytorch','In this tutorial, we introduce the primary torchRec\nAPI called DistributedModelParallel, or DMP.\nLike pytorch’s DistributedDataParallel,\nDMP wraps a model to enable distributed training.','introduce primary torchRec API in tutorial',0,'',''),(10280,'Pytorch','In this tutorial, we introduce the primary torchRec\nAPI called DistributedModelParallel, or DMP.\nLike pytorch’s DistributedDataParallel,\nDMP wraps a model to enable distributed training.','introduce DMP in tutorial',0,'',''),(10281,'Pytorch','In this tutorial, we introduce the primary torchRec\nAPI called DistributedModelParallel, or DMP.\nLike pytorch’s DistributedDataParallel,\nDMP wraps a model to enable distributed training.','call DistributedModelParallel',0,'',''),(10282,'Pytorch','In this tutorial, we introduce the primary torchRec\nAPI called DistributedModelParallel, or DMP.\nLike pytorch’s DistributedDataParallel,\nDMP wraps a model to enable distributed training.','wrap model like DistributedDataParallel',0,'',''),(10283,'Pytorch','In this tutorial, we introduce the primary torchRec\nAPI called DistributedModelParallel, or DMP.\nLike pytorch’s DistributedDataParallel,\nDMP wraps a model to enable distributed training.','enable distributed training',0,'',''),(10284,'Pytorch','Open in Google Colab','open  in google Colab',0,'',''),(10285,'Pytorch','Search Page','search Page',0,'',''),(10286,'React','React has been designed from the start for gradual adoption, and you can use as little or as much React as you need. Whether you want to get a taste of React, add some interactivity to a simple HTML page, or start a complex React-powered app, the links in this section will help you get started.','design react from start',0,'',''),(10287,'React','React has been designed from the start for gradual adoption, and you can use as little or as much React as you need. Whether you want to get a taste of React, add some interactivity to a simple HTML page, or start a complex React-powered app, the links in this section will help you get started.','use  as React',0,'',''),(10288,'React','React has been designed from the start for gradual adoption, and you can use as little or as much React as you need. Whether you want to get a taste of React, add some interactivity to a simple HTML page, or start a complex React-powered app, the links in this section will help you get started.','get taste of react',0,'',''),(10289,'React','React has been designed from the start for gradual adoption, and you can use as little or as much React as you need. Whether you want to get a taste of React, add some interactivity to a simple HTML page, or start a complex React-powered app, the links in this section will help you get started.','add interactivity to simple HTML page',0,'',''),(10290,'React','If you’re interested in playing around with React, you can use an online code playground. Try a Hello World template on CodePen, CodeSandbox, or Stackblitz.','use online code playground',0,'',''),(10291,'React','If you prefer to use your own text editor, you can also download this HTML file, edit it, and open it from the local filesystem in your browser. It does a slow runtime code transformation, so we’d only recommend using this for simple demos.','use own text editor',0,'',''),(10292,'React','If you prefer to use your own text editor, you can also download this HTML file, edit it, and open it from the local filesystem in your browser. It does a slow runtime code transformation, so we’d only recommend using this for simple demos.','download HTML file',0,'',''),(10293,'React','If you prefer to use your own text editor, you can also download this HTML file, edit it, and open it from the local filesystem in your browser. It does a slow runtime code transformation, so we’d only recommend using this for simple demos.','open  from local filesystem',0,'',''),(10294,'React','You can add React to an HTML page in one minute. You can then either gradually expand its presence, or keep it contained to a few dynamic widgets.','add React to HTML page',0,'',''),(10295,'React','You can add React to an HTML page in one minute. You can then either gradually expand its presence, or keep it contained to a few dynamic widgets.','expand presence',0,'',''),(10296,'React','Like any unfamiliar technology, React does have a learning curve. With practice and some patience, you will get the hang of it.','get hang with practice',0,'',''),(10297,'React','Like any unfamiliar technology, React does have a learning curve. With practice and some patience, you will get the hang of it.','get hang with patience',0,'',''),(10298,'React','The React homepage contains a few small React examples with a live editor. Even if you don’t know anything about React yet, try changing their code and see how it affects the result.','change code',0,'',''),(10299,'React','If you feel that the React documentation goes at a faster pace than you’re comfortable with, check out this overview of React by Tania Rascia. It introduces the most important React concepts in a detailed, beginner-friendly way. Once you’re done, give the documentation another try!','introduce important React concepts in detailed beginner-friendly way',0,'',''),(10300,'React','The React documentation assumes some familiarity with programming in the JavaScript language. You don’t have to be an expert, but it’s harder to learn both React and JavaScript at the same time.','learn React at same time',0,'',''),(10301,'React','The React documentation assumes some familiarity with programming in the JavaScript language. You don’t have to be an expert, but it’s harder to learn both React and JavaScript at the same time.','learn JavaScript at same time',0,'',''),(10302,'React','We recommend going through this JavaScript overview to check your knowledge level. It will take you between 30 minutes and an hour but you will feel more confident learning React.','check knowledge level',0,'',''),(10303,'React','We recommend going through this JavaScript overview to check your knowledge level. It will take you between 30 minutes and an hour but you will feel more confident learning React.','learn react',0,'',''),(10304,'React','Whenever you get confused by something in JavaScript, MDN and javascript.info are great websites to check. There are also community support forums where you can ask for help.','ask community support forums for help',0,'',''),(10305,'React','If you prefer to learn by doing, check out our practical tutorial. In this tutorial, we build a tic-tac-toe game in React. You might be tempted to skip it because you’re not into building games — but give it a chance. The techniques you’ll learn in the tutorial are fundamental to building any React apps, and mastering it will give you a much deeper understanding.','learn  by doing',0,'',''),(10306,'React','If you prefer to learn by doing, check out our practical tutorial. In this tutorial, we build a tic-tac-toe game in React. You might be tempted to skip it because you’re not into building games — but give it a chance. The techniques you’ll learn in the tutorial are fundamental to building any React apps, and mastering it will give you a much deeper understanding.','learn  in tutorial',0,'',''),(10307,'React','If you prefer to learn concepts step by step, our guide to main concepts is the best place to start. Every next chapter in it builds on the knowledge introduced in the previous chapters so you won’t miss anything as you go along.','learn concepts step by step',0,'',''),(10308,'React','If you prefer to learn concepts step by step, our guide to main concepts is the best place to start. Every next chapter in it builds on the knowledge introduced in the previous chapters so you won’t miss anything as you go along.','introduce  in previous chapters',0,'',''),(10309,'React','Many React users credit reading Thinking in React as the moment React finally “clicked” for them. It’s probably the oldest React walkthrough but it’s still just as relevant.','read thinking as moment React',0,'',''),(10310,'React','Many React users credit reading Thinking in React as the moment React finally “clicked” for them. It’s probably the oldest React walkthrough but it’s still just as relevant.','read thinking in React',0,'',''),(10311,'React','Once you’re comfortable with the main concepts and played with React a little bit, you might be interested in more advanced topics. This section will introduce you to the powerful, but less commonly used React features like context and refs.','play  with React',0,'',''),(10312,'React','Once you’re comfortable with the main concepts and played with React a little bit, you might be interested in more advanced topics. This section will introduce you to the powerful, but less commonly used React features like context and refs.','introduce  to powerful used React features',0,'',''),(10313,'React','This documentation section is useful when you want to learn more details about a particular React API. For example, React.Component API reference can provide you with details on how setState() works, and what different lifecycle methods are useful for.','learn more details about particular React API',0,'',''),(10314,'React','This documentation section is useful when you want to learn more details about a particular React API. For example, React.Component API reference can provide you with details on how setState() works, and what different lifecycle methods are useful for.','provide  with details',0,'',''),(10315,'React','You can also follow the @reactjs account on Twitter, but you won’t miss anything essential if you only read the blog.','read blog',0,'',''),(10316,'React','Not every React release deserves its own blog post, but you can find a detailed changelog for every release in the CHANGELOG.md file in the React repository, as well as on the Releases page.','find detailed changelog for release',0,'',''),(10317,'React','This documentation always reflects the latest stable version of React. Since React 16, you can find older versions of the documentation on a separate page. Note that documentation for past versions is snapshotted at the time of the release, and isn’t being continuously updated.','find older versions of documentation',0,'',''),(10318,'React','This documentation always reflects the latest stable version of React. Since React 16, you can find older versions of the documentation on a separate page. Note that documentation for past versions is snapshotted at the time of the release, and isn’t being continuously updated.','find older versions since React',0,'',''),(10319,'pyppeteer','When importing pyppeteer at all on my Ubuntu 21.10 system I recieve a circular import error as seen below. This is in a fresh virtualenv using Python 3.9.7.','import pyppeteer on Ubuntu system',1,'https://github.com/pyppeteer/pyppeteer/issues/344',''),(10320,'pyppeteer','When importing pyppeteer at all on my Ubuntu 21.10 system I recieve a circular import error as seen below. This is in a fresh virtualenv using Python 3.9.7.','use Python 3.9.7',1,'https://github.com/pyppeteer/pyppeteer/issues/344',''),(10321,'pyppeteer','I\'ve also run into this issue while trying to use requests_html (I am not actually importing pyppeteer directly). For reference, I\'m on Windows 11 with Python 3.10.1. Seems like there is no way around this bug atm.','use requests_html',0,'',''),(10322,'pyppeteer','I\'ve also run into this issue while trying to use requests_html (I am not actually importing pyppeteer directly). For reference, I\'m on Windows 11 with Python 3.10.1. Seems like there is no way around this bug atm.','run  into issue while',0,'',''),(10323,'pyppeteer','I\'ll take a look into this tonight. Does this occur in 1.0.0? I don\'t recall changing anything major and I thought I did test 1.0.1','change anything major',0,'',''),(10324,'pyppeteer','Note: this is a continuation of the pyppeteer project. Before undertaking any sort of developement, it is highly recommended that you take a look at #16 for the ongoing effort to update this library to avoid duplicating efforts.','update library',0,'',''),(10325,'pyppeteer','Install with pip from PyPI:','install  with pip',1,'https://github.com/pyppeteer/pyppeteer.git','user-content-installation'),(10326,'pyppeteer','Install with pip from PyPI:','install  from pypi',1,'https://github.com/pyppeteer/pyppeteer.git','user-content-installation'),(10327,'pyppeteer','Or install the latest version from this github repo:','install latest version from github repo',1,'https://github.com/pyppeteer/pyppeteer.git','user-content-installation'),(10328,'pyppeteer','Note: When you run pyppeteer for the first time, it downloads the latest version of Chromium (~150MB) if it is not found on your system. If you don\'t prefer this behavior, ensure that a suitable Chrome binary is installed. One way to do this is to run pyppeteer-install command before prior to using this library.','run pyppeteer for first time',0,'',''),(10329,'pyppeteer','Note: When you run pyppeteer for the first time, it downloads the latest version of Chromium (~150MB) if it is not found on your system. If you don\'t prefer this behavior, ensure that a suitable Chrome binary is installed. One way to do this is to run pyppeteer-install command before prior to using this library.','download latest version of Chromium',0,'',''),(10330,'pyppeteer','Note: When you run pyppeteer for the first time, it downloads the latest version of Chromium (~150MB) if it is not found on your system. If you don\'t prefer this behavior, ensure that a suitable Chrome binary is installed. One way to do this is to run pyppeteer-install command before prior to using this library.','install suitable Chrome binary',0,'',''),(10331,'pyppeteer','Note: When you run pyppeteer for the first time, it downloads the latest version of Chromium (~150MB) if it is not found on your system. If you don\'t prefer this behavior, ensure that a suitable Chrome binary is installed. One way to do this is to run pyppeteer-install command before prior to using this library.','run pyppeteer-install command',0,'',''),(10332,'pyppeteer','Note: When you run pyppeteer for the first time, it downloads the latest version of Chromium (~150MB) if it is not found on your system. If you don\'t prefer this behavior, ensure that a suitable Chrome binary is installed. One way to do this is to run pyppeteer-install command before prior to using this library.','use library',0,'',''),(10333,'pyppeteer','Full documentation can be found here. Puppeteer\'s documentation and its troubleshooting guide are also great resources for pyppeteer users.','find full documentation',0,'',''),(10334,'pyppeteer','Open web page and take a screenshot:','open web page',1,'https://github.com/pyppeteer/pyppeteer.git','user-content-examples'),(10335,'pyppeteer','pyppeteer strives to replicate the puppeteer API as close as possible, however, fundamental differences between Javascript and Python make this difficult to do precisely. More information on specifics can be found in the documentation.','replicate close',0,'',''),(10336,'pyppeteer','pyppeteer strives to replicate the puppeteer API as close as possible, however, fundamental differences between Javascript and Python make this difficult to do precisely. More information on specifics can be found in the documentation.','find more information in documentation',0,'',''),(10337,'pyppeteer','pyppeteer strives to replicate the puppeteer API as close as possible, however, fundamental differences between Javascript and Python make this difficult to do precisely. More information on specifics can be found in the documentation.','find more information on specifics',0,'',''),(10338,'pyppeteer','puppeteer uses an object for passing options to functions/methods. pyppeteer methods/functions accept both dictionary (python equivalent to JavaScript\'s objects) and keyword arguments for options.','pass options',1,'https://github.com/pyppeteer/pyppeteer.git','user-content-keyword-arguments-for-options'),(10339,'pyppeteer','In python, $ is not a valid identifier. The equivalent methods to Puppeteer\'s $, $$, and $x methods are listed below, along with some shorthand methods for your convenience:','list equivalent methods along_with shorthand methods',0,'',''),(10340,'pyppeteer','In python, $ is not a valid identifier. The equivalent methods to Puppeteer\'s $, $$, and $x methods are listed below, along with some shorthand methods for your convenience:','list equivalent methods to $',0,'',''),(10341,'pyppeteer','In python, $ is not a valid identifier. The equivalent methods to Puppeteer\'s $, $$, and $x methods are listed below, along with some shorthand methods for your convenience:','list $x methods along_with shorthand methods',0,'',''),(10342,'pyppeteer','In python, $ is not a valid identifier. The equivalent methods to Puppeteer\'s $, $$, and $x methods are listed below, along with some shorthand methods for your convenience:','list $x methods to $',0,'',''),(10343,'pyppeteer','puppeteer\'s version of evaluate() takes a JavaScript function or a string representation of a JavaScript expression. pyppeteer takes string representation of JavaScript expression or function. pyppeteer will try to automatically detect if the string is function or expression, but it will fail sometimes. If an expression is erroneously treated as function and an error is raised, try setting force_expr to True, to force pyppeteer to treat the string as expression.','set force_expr to true',0,'',''),(10344,'pyppeteer','puppeteer\'s version of evaluate() takes a JavaScript function or a string representation of a JavaScript expression. pyppeteer takes string representation of JavaScript expression or function. pyppeteer will try to automatically detect if the string is function or expression, but it will fail sometimes. If an expression is erroneously treated as function and an error is raised, try setting force_expr to True, to force pyppeteer to treat the string as expression.','force pyppeteer',0,'',''),(10345,'pyppeteer','puppeteer\'s version of evaluate() takes a JavaScript function or a string representation of a JavaScript expression. pyppeteer takes string representation of JavaScript expression or function. pyppeteer will try to automatically detect if the string is function or expression, but it will fail sometimes. If an expression is erroneously treated as function and an error is raised, try setting force_expr to True, to force pyppeteer to treat the string as expression.','raise error',0,'',''),(10346,'pyppeteer','Get a page\'s textContent:','get textContent',1,'https://github.com/pyppeteer/pyppeteer.git','user-content-examples-1'),(10347,'pyppeteer','Get an element\'s textContent:','get textContent',1,'https://github.com/pyppeteer/pyppeteer.git','user-content-examples-1'),(10348,'pyppeteer','There was a problem hiding this comment.','hide comment',0,'',''),(10349,'pyppeteer','Issue #119\nWe probably want to check if error.args has any elements, otherwise this throws an exception','throw exception',0,'',''),(10350,'pyppeteer','Could the page make it a little bit more clear what the status of this branch is vs \"dev\", and which one is recommended that people a) user as end users and b) send patches to? It seems dev is very active, while this port is not.','send patches',0,'',''),(10351,'scikit-learn','Release notes for all scikit-learn releases are linked in this page.','link release notes in page',0,'',''),(10352,'scikit-learn','Release notes for all scikit-learn releases are linked in this page.','link release notes for scikit-learn releases',0,'',''),(10353,'scikit-learn','Tip: Subscribe to scikit-learn releases\non libraries.io to be notified when new versions are released.','release new versions',0,'',''),(10354,'scikit-learn','The project is hosted on https://github.com/scikit-learn/scikit-learn','host project on https://github.com/scikit-learn/scikit-learn',0,'',''),(10355,'scikit-learn','Scikit-learn is somewhat selective when it comes to\nadding new algorithms, and the best way to contribute and to help the project\nis to start working on known issues.\nSee Issues for New Contributors to get started.','add new algorithms',0,'',''),(10356,'scikit-learn','In case you experience issues using this package, do not hesitate to submit a\nticket to the\nGitHub issue tracker. You are also\nwelcome to post feature requests or pull requests.','use package',0,'',''),(10357,'scikit-learn','In case you experience issues using this package, do not hesitate to submit a\nticket to the\nGitHub issue tracker. You are also\nwelcome to post feature requests or pull requests.','submit ticket to GitHub issue tracker',0,'',''),(10358,'scikit-learn','There are many ways to contribute to scikit-learn, with the most common ones\nbeing contribution of code or documentation to the project. Improving the\ndocumentation is no less important than improving the library itself.  If you\nfind a typo in the documentation, or have made improvements, do not hesitate to\nsend an email to the mailing list or preferably submit a GitHub pull request.\nFull documentation can be found under the doc/ directory.','find typo in documentation',0,'',''),(10359,'scikit-learn','There are many ways to contribute to scikit-learn, with the most common ones\nbeing contribution of code or documentation to the project. Improving the\ndocumentation is no less important than improving the library itself.  If you\nfind a typo in the documentation, or have made improvements, do not hesitate to\nsend an email to the mailing list or preferably submit a GitHub pull request.\nFull documentation can be found under the doc/ directory.','send email to mailing list',0,'',''),(10360,'scikit-learn','There are many ways to contribute to scikit-learn, with the most common ones\nbeing contribution of code or documentation to the project. Improving the\ndocumentation is no less important than improving the library itself.  If you\nfind a typo in the documentation, or have made improvements, do not hesitate to\nsend an email to the mailing list or preferably submit a GitHub pull request.\nFull documentation can be found under the doc/ directory.','submit GitHub pull request',0,'',''),(10361,'scikit-learn','There are many ways to contribute to scikit-learn, with the most common ones\nbeing contribution of code or documentation to the project. Improving the\ndocumentation is no less important than improving the library itself.  If you\nfind a typo in the documentation, or have made improvements, do not hesitate to\nsend an email to the mailing list or preferably submit a GitHub pull request.\nFull documentation can be found under the doc/ directory.','find full documentation under doc / directory',0,'',''),(10362,'scikit-learn','Another way to contribute is to report issues you’re facing, and give a “thumbs\nup” on issues that others reported and that are relevant to you.  It also helps\nus if you spread the word: reference the project from your blog and articles,\nlink to it from your website, or simply star to say “I use it”:','reference project from blog',0,'',''),(10363,'scikit-learn','Another way to contribute is to report issues you’re facing, and give a “thumbs\nup” on issues that others reported and that are relevant to you.  It also helps\nus if you spread the word: reference the project from your blog and articles,\nlink to it from your website, or simply star to say “I use it”:','reference project from articles',0,'',''),(10364,'scikit-learn','Another way to contribute is to report issues you’re facing, and give a “thumbs\nup” on issues that others reported and that are relevant to you.  It also helps\nus if you spread the word: reference the project from your blog and articles,\nlink to it from your website, or simply star to say “I use it”:','link  from website',0,'',''),(10365,'scikit-learn','In case a contribution/issue involves changes to the API principles\nor changes to dependencies or supported versions, it must be backed by a\nEnhancement proposals (SLEPs), where a SLEP must be submitted as a pull-request to\nenhancement proposals\nusing the SLEP template\nand follows the decision-making process outlined in Scikit-learn governance and decision-making.','support versions',0,'',''),(10366,'scikit-learn','In case a contribution/issue involves changes to the API principles\nor changes to dependencies or supported versions, it must be backed by a\nEnhancement proposals (SLEPs), where a SLEP must be submitted as a pull-request to\nenhancement proposals\nusing the SLEP template\nand follows the decision-making process outlined in Scikit-learn governance and decision-making.','use SLEP template',0,'',''),(10367,'scikit-learn','In case a contribution/issue involves changes to the API principles\nor changes to dependencies or supported versions, it must be backed by a\nEnhancement proposals (SLEPs), where a SLEP must be submitted as a pull-request to\nenhancement proposals\nusing the SLEP template\nand follows the decision-making process outlined in Scikit-learn governance and decision-making.','submit SLEP as pull-request',0,'',''),(10368,'scikit-learn','We use GitHub issues to track all bugs and feature requests; feel free to open\nan issue if you have found a bug or wish to see a feature implemented.','use GitHub issues',0,'',''),(10369,'scikit-learn','We use GitHub issues to track all bugs and feature requests; feel free to open\nan issue if you have found a bug or wish to see a feature implemented.','open issue',0,'',''),(10370,'scikit-learn','We use GitHub issues to track all bugs and feature requests; feel free to open\nan issue if you have found a bug or wish to see a feature implemented.','find bug',0,'',''),(10371,'scikit-learn','In case you experience issues using this package, do not hesitate to submit a\nticket to the\nBug Tracker. You are\nalso welcome to post feature requests or pull requests.','use package',0,'',''),(10372,'scikit-learn','In case you experience issues using this package, do not hesitate to submit a\nticket to the\nBug Tracker. You are\nalso welcome to post feature requests or pull requests.','submit ticket to bug Tracker',0,'',''),(10373,'scikit-learn','If you are submitting an algorithm or feature request, please verify that\nthe algorithm fulfills our\nnew algorithm requirements.','submit algorithm feature request',0,'',''),(10374,'scikit-learn','If you are submitting a bug report, we strongly encourage you to follow the guidelines in\nHow to make a good bug report.','submit bug report',0,'',''),(10375,'scikit-learn','When you submit an issue to Github, please do your best to\nfollow these guidelines! This will make it a lot easier to provide you with good\nfeedback:','submit issue to github',0,'',''),(10376,'scikit-learn','When you submit an issue to Github, please do your best to\nfollow these guidelines! This will make it a lot easier to provide you with good\nfeedback:','provide  with good feedback',0,'',''),(10377,'scikit-learn','If not feasible to include a reproducible snippet, please be specific about\nwhat estimators and/or functions are involved and the shape of the data.','include reproducible snippet',0,'',''),(10378,'scikit-learn','If an exception is raised, please provide the full traceback.','provide full traceback',0,'',''),(10379,'scikit-learn','If an exception is raised, please provide the full traceback.','raise exception',0,'',''),(10380,'scikit-learn','Please include your operating system type and version number, as well as\nyour Python, scikit-learn, numpy, and scipy versions. This information\ncan be found by running the following code snippet:','include operating system type',1,'https://scikit-learn.org/dev/developers/contributing.html',''),(10381,'scikit-learn','Please include your operating system type and version number, as well as\nyour Python, scikit-learn, numpy, and scipy versions. This information\ncan be found by running the following code snippet:','include scikit-learn',1,'https://scikit-learn.org/dev/developers/contributing.html',''),(10382,'scikit-learn','Please include your operating system type and version number, as well as\nyour Python, scikit-learn, numpy, and scipy versions. This information\ncan be found by running the following code snippet:','include numpy',1,'https://scikit-learn.org/dev/developers/contributing.html',''),(10383,'scikit-learn','Please include your operating system type and version number, as well as\nyour Python, scikit-learn, numpy, and scipy versions. This information\ncan be found by running the following code snippet:','include scipy versions',1,'https://scikit-learn.org/dev/developers/contributing.html',''),(10384,'scikit-learn','Please include your operating system type and version number, as well as\nyour Python, scikit-learn, numpy, and scipy versions. This information\ncan be found by running the following code snippet:','include version number',1,'https://scikit-learn.org/dev/developers/contributing.html',''),(10385,'scikit-learn','Please include your operating system type and version number, as well as\nyour Python, scikit-learn, numpy, and scipy versions. This information\ncan be found by running the following code snippet:','include Python',1,'https://scikit-learn.org/dev/developers/contributing.html',''),(10386,'scikit-learn','Please include your operating system type and version number, as well as\nyour Python, scikit-learn, numpy, and scipy versions. This information\ncan be found by running the following code snippet:','run following code snippet',1,'https://scikit-learn.org/dev/developers/contributing.html',''),(10387,'scikit-learn','Please include your operating system type and version number, as well as\nyour Python, scikit-learn, numpy, and scipy versions. This information\ncan be found by running the following code snippet:','find information',1,'https://scikit-learn.org/dev/developers/contributing.html',''),(10388,'scikit-learn','Please ensure all code snippets and error messages are formatted in\nappropriate code blocks.  See Creating and highlighting code blocks\nfor more details.','format code snippets in appropriate code blocks',0,'',''),(10389,'scikit-learn','Please ensure all code snippets and error messages are formatted in\nappropriate code blocks.  See Creating and highlighting code blocks\nfor more details.','format error messages in appropriate code blocks',0,'',''),(10390,'scikit-learn','Please ensure all code snippets and error messages are formatted in\nappropriate code blocks.  See Creating and highlighting code blocks\nfor more details.','create code blocks for more details',0,'',''),(10391,'scikit-learn','If you want to help curate issues, read the following.','read following',0,'',''),(10392,'scikit-learn','To avoid duplicating work, it is highly advised that you search through the\nissue tracker and\nthe PR list.\nIf in doubt about duplicated work, or if you want to work on a non-trivial\nfeature, it’s recommended to first open an issue in\nthe issue tracker\nto get some feedbacks from core developers.','search  through issue tracker',0,'',''),(10393,'scikit-learn','To avoid duplicating work, it is highly advised that you search through the\nissue tracker and\nthe PR list.\nIf in doubt about duplicated work, or if you want to work on a non-trivial\nfeature, it’s recommended to first open an issue in\nthe issue tracker\nto get some feedbacks from core developers.','search  through PR list',0,'',''),(10394,'scikit-learn','To avoid duplicating work, it is highly advised that you search through the\nissue tracker and\nthe PR list.\nIf in doubt about duplicated work, or if you want to work on a non-trivial\nfeature, it’s recommended to first open an issue in\nthe issue tracker\nto get some feedbacks from core developers.','open issue in issue tracker',0,'',''),(10395,'scikit-learn','To avoid duplicating work, it is highly advised that you search through the\nissue tracker and\nthe PR list.\nIf in doubt about duplicated work, or if you want to work on a non-trivial\nfeature, it’s recommended to first open an issue in\nthe issue tracker\nto get some feedbacks from core developers.','get feedbacks from core developers',0,'',''),(10396,'scikit-learn','One easy way to find an issue to work on is by applying the “help wanted”\nlabel in your search. This lists all the issues that have been unclaimed\nso far. In order to claim an issue for yourself, please comment exactly\n/take on it for the CI to automatically assign the issue to you.','find issue',0,'',''),(10397,'scikit-learn','One easy way to find an issue to work on is by applying the “help wanted”\nlabel in your search. This lists all the issues that have been unclaimed\nso far. In order to claim an issue for yourself, please comment exactly\n/take on it for the CI to automatically assign the issue to you.','list issues',0,'',''),(10398,'scikit-learn','One easy way to find an issue to work on is by applying the “help wanted”\nlabel in your search. This lists all the issues that have been unclaimed\nso far. In order to claim an issue for yourself, please comment exactly\n/take on it for the CI to automatically assign the issue to you.','assign issue',0,'',''),(10399,'scikit-learn','These videos are step-by-step introductions on how to contribute to\nscikit-learn, and are a great companion to the following text guidelines.\nPlease make sure to still check our guidelines below, since they describe our\nlatest up-to-date workflow.','check guidelines',0,'',''),(10400,'scikit-learn','These videos are step-by-step introductions on how to contribute to\nscikit-learn, and are a great companion to the following text guidelines.\nPlease make sure to still check our guidelines below, since they describe our\nlatest up-to-date workflow.','describe latest up-to-date workflow',0,'',''),(10401,'scikit-learn','In January 2021, the default branch name changed from master to main\nfor the scikit-learn GitHub repository to use more inclusive terms.\nThese videos were created prior to the renaming of the branch.\nFor contributors who are viewing these videos to set up their\nworking environment and submitting a PR, master should be replaced to main.','use more inclusive terms',0,'',''),(10402,'scikit-learn','In January 2021, the default branch name changed from master to main\nfor the scikit-learn GitHub repository to use more inclusive terms.\nThese videos were created prior to the renaming of the branch.\nFor contributors who are viewing these videos to set up their\nworking environment and submitting a PR, master should be replaced to main.','change  in January',0,'',''),(10403,'scikit-learn','In January 2021, the default branch name changed from master to main\nfor the scikit-learn GitHub repository to use more inclusive terms.\nThese videos were created prior to the renaming of the branch.\nFor contributors who are viewing these videos to set up their\nworking environment and submitting a PR, master should be replaced to main.','change  from master',0,'',''),(10404,'scikit-learn','In January 2021, the default branch name changed from master to main\nfor the scikit-learn GitHub repository to use more inclusive terms.\nThese videos were created prior to the renaming of the branch.\nFor contributors who are viewing these videos to set up their\nworking environment and submitting a PR, master should be replaced to main.','create videos prior_to renaming',0,'',''),(10405,'scikit-learn','In January 2021, the default branch name changed from master to main\nfor the scikit-learn GitHub repository to use more inclusive terms.\nThese videos were created prior to the renaming of the branch.\nFor contributors who are viewing these videos to set up their\nworking environment and submitting a PR, master should be replaced to main.','set up working environment',0,'',''),(10406,'scikit-learn','In January 2021, the default branch name changed from master to main\nfor the scikit-learn GitHub repository to use more inclusive terms.\nThese videos were created prior to the renaming of the branch.\nFor contributors who are viewing these videos to set up their\nworking environment and submitting a PR, master should be replaced to main.','submit PR',0,'',''),(10407,'scikit-learn','In January 2021, the default branch name changed from master to main\nfor the scikit-learn GitHub repository to use more inclusive terms.\nThese videos were created prior to the renaming of the branch.\nFor contributors who are viewing these videos to set up their\nworking environment and submitting a PR, master should be replaced to main.','submit contributors',0,'',''),(10408,'scikit-learn','In January 2021, the default branch name changed from master to main\nfor the scikit-learn GitHub repository to use more inclusive terms.\nThese videos were created prior to the renaming of the branch.\nFor contributors who are viewing these videos to set up their\nworking environment and submitting a PR, master should be replaced to main.','replace master for contributors',0,'',''),(10409,'scikit-learn','The preferred way to contribute to scikit-learn is to fork the main\nrepository on GitHub,\nthen submit a “pull request” (PR).','submit pull request',0,'',''),(10410,'scikit-learn','In the first few steps, we explain how to locally install scikit-learn, and\nhow to set up your git repository:','install scikit-learn',0,'',''),(10411,'scikit-learn','In the first few steps, we explain how to locally install scikit-learn, and\nhow to set up your git repository:','set up git repository',0,'',''),(10412,'scikit-learn','Create an account on\nGitHub if you do not already have one.','create account on GitHub',0,'',''),(10413,'scikit-learn','Fork the project repository: click on the ‘Fork’\nbutton near the top of the page. This creates a copy of the code under your\naccount on the GitHub user account. For more details on how to fork a\nrepository see this guide.','create copy of code',0,'',''),(10414,'scikit-learn','Fork the project repository: click on the ‘Fork’\nbutton near the top of the page. This creates a copy of the code under your\naccount on the GitHub user account. For more details on how to fork a\nrepository see this guide.','create copy under account',0,'',''),(10415,'scikit-learn','Clone your fork of the scikit-learn repo from your GitHub account to your\nlocal disk:','clone fork of scikit-learn repo',1,'https://scikit-learn.org/dev/developers/contributing.html',''),(10416,'scikit-learn','Clone your fork of the scikit-learn repo from your GitHub account to your\nlocal disk:','clone fork to local disk',1,'https://scikit-learn.org/dev/developers/contributing.html',''),(10417,'scikit-learn','Follow steps 2-7 in Building from source to build scikit-learn in\ndevelopment mode and return to this document.','return  to document',0,'',''),(10418,'scikit-learn','Install the development dependencies:','install development dependencies',1,'https://scikit-learn.org/dev/developers/contributing.html',''),(10419,'scikit-learn','Add the upstream remote. This saves a reference to the main\nscikit-learn repository, which you can use to keep your repository\nsynchronized with the latest changes:','save reference to main scikit-learn repository',1,'https://scikit-learn.org/dev/developers/contributing.html',''),(10420,'scikit-learn','Add the upstream remote. This saves a reference to the main\nscikit-learn repository, which you can use to keep your repository\nsynchronized with the latest changes:','use main scikit-learn repository',1,'https://scikit-learn.org/dev/developers/contributing.html',''),(10421,'scikit-learn','Check that the upstream and origin remote aliases are configured correctly\nby running git remote -v which should display:','configure origin remote aliases',1,'https://scikit-learn.org/dev/developers/contributing.html',''),(10422,'scikit-learn','Check that the upstream and origin remote aliases are configured correctly\nby running git remote -v which should display:','display v',1,'https://scikit-learn.org/dev/developers/contributing.html',''),(10423,'scikit-learn','You should now have a working installation of scikit-learn, and your git\nrepository properly configured. The next steps now describe the process of\nmodifying code and submitting a PR:','describe process of modifying',1,'https://scikit-learn.org/dev/developers/contributing.html','upstream'),(10424,'scikit-learn','You should now have a working installation of scikit-learn, and your git\nrepository properly configured. The next steps now describe the process of\nmodifying code and submitting a PR:','describe process of submitting',1,'https://scikit-learn.org/dev/developers/contributing.html','upstream'),(10425,'scikit-learn','You should now have a working installation of scikit-learn, and your git\nrepository properly configured. The next steps now describe the process of\nmodifying code and submitting a PR:','modify code',1,'https://scikit-learn.org/dev/developers/contributing.html','upstream'),(10426,'scikit-learn','You should now have a working installation of scikit-learn, and your git\nrepository properly configured. The next steps now describe the process of\nmodifying code and submitting a PR:','submit PR',1,'https://scikit-learn.org/dev/developers/contributing.html','upstream'),(10427,'scikit-learn','and start making changes. Always use a feature branch. It’s good\npractice to never work on the main branch!','use feature branch',0,'',''),(10428,'scikit-learn','(Optional) Install pre-commit to\nrun code style checks before each commit:','run code style checks',1,'https://scikit-learn.org/dev/developers/contributing.html',''),(10429,'scikit-learn','pre-commit checks can be disabled for a particular commit with\ngit commit -n.','disable pre-commit checks for particular commit',0,'',''),(10430,'scikit-learn','Develop the feature on your feature branch on your computer, using Git to\ndo the version control. When you’re done editing, add changed files using\ngit add and then git commit:','develop feature on computer',1,'https://scikit-learn.org/dev/developers/contributing.html',''),(10431,'scikit-learn','Develop the feature on your feature branch on your computer, using Git to\ndo the version control. When you’re done editing, add changed files using\ngit add and then git commit:','develop feature on feature branch',1,'https://scikit-learn.org/dev/developers/contributing.html',''),(10432,'scikit-learn','Develop the feature on your feature branch on your computer, using Git to\ndo the version control. When you’re done editing, add changed files using\ngit add and then git commit:','add changed files',1,'https://scikit-learn.org/dev/developers/contributing.html',''),(10433,'scikit-learn','to record your changes in Git, then push the changes to your GitHub\naccount with:','push changes to GitHub account',1,'https://scikit-learn.org/dev/developers/contributing.html',''),(10434,'scikit-learn','Follow these\ninstructions to create a pull request from your fork. This will send an\nemail to the committers. You may want to consider sending an email to the\nmailing list for more visibility.','create pull request from fork',0,'',''),(10435,'scikit-learn','Follow these\ninstructions to create a pull request from your fork. This will send an\nemail to the committers. You may want to consider sending an email to the\nmailing list for more visibility.','send email to committers',0,'',''),(10436,'scikit-learn','Follow these\ninstructions to create a pull request from your fork. This will send an\nemail to the committers. You may want to consider sending an email to the\nmailing list for more visibility.','send email to mailing list',0,'',''),(10437,'scikit-learn','If you are modifying a Cython module, you have to re-compile after\nmodifications and before testing them:','modify Cython module',1,'https://scikit-learn.org/dev/developers/contributing.html',''),(10438,'scikit-learn','Use the --no-build-isolation flag to avoid compiling the whole project\neach time, only the files you have modified.','use no-build-isolation flag',0,'',''),(10439,'scikit-learn','Use the --no-build-isolation flag to avoid compiling the whole project\neach time, only the files you have modified.','compile whole project',0,'',''),(10440,'scikit-learn','Subsequently, you might need to solve the conflicts. You can refer to the\nGit documentation related to resolving merge conflict using the command\nline.','use command line',0,'',''),(10441,'scikit-learn','Before a PR can be merged, it needs to be approved by two core developers.\nPlease prefix the title of your pull request with [MRG] if the\ncontribution is complete and should be subjected to a detailed review. An\nincomplete contribution – where you expect to do more work before receiving\na full review – should be prefixed [WIP] (to indicate a work in\nprogress) and changed to [MRG] when it matures. WIPs may be useful to:\nindicate you are working on something to avoid duplicated work, request\nbroad review of functionality or API, or seek collaborators. WIPs often\nbenefit from the inclusion of a task list in\nthe PR description.','prefix title with  MRG',0,'',''),(10442,'scikit-learn','Before a PR can be merged, it needs to be approved by two core developers.\nPlease prefix the title of your pull request with [MRG] if the\ncontribution is complete and should be subjected to a detailed review. An\nincomplete contribution – where you expect to do more work before receiving\na full review – should be prefixed [WIP] (to indicate a work in\nprogress) and changed to [MRG] when it matures. WIPs may be useful to:\nindicate you are working on something to avoid duplicated work, request\nbroad review of functionality or API, or seek collaborators. WIPs often\nbenefit from the inclusion of a task list in\nthe PR description.','prefix title of pull request',0,'',''),(10443,'scikit-learn','Before a PR can be merged, it needs to be approved by two core developers.\nPlease prefix the title of your pull request with [MRG] if the\ncontribution is complete and should be subjected to a detailed review. An\nincomplete contribution – where you expect to do more work before receiving\na full review – should be prefixed [WIP] (to indicate a work in\nprogress) and changed to [MRG] when it matures. WIPs may be useful to:\nindicate you are working on something to avoid duplicated work, request\nbroad review of functionality or API, or seek collaborators. WIPs often\nbenefit from the inclusion of a task list in\nthe PR description.','receive full review',0,'',''),(10444,'scikit-learn','Before a PR can be merged, it needs to be approved by two core developers.\nPlease prefix the title of your pull request with [MRG] if the\ncontribution is complete and should be subjected to a detailed review. An\nincomplete contribution – where you expect to do more work before receiving\na full review – should be prefixed [WIP] (to indicate a work in\nprogress) and changed to [MRG] when it matures. WIPs may be useful to:\nindicate you are working on something to avoid duplicated work, request\nbroad review of functionality or API, or seek collaborators. WIPs often\nbenefit from the inclusion of a task list in\nthe PR description.','prefix  WIP',0,'',''),(10445,'scikit-learn','Before a PR can be merged, it needs to be approved by two core developers.\nPlease prefix the title of your pull request with [MRG] if the\ncontribution is complete and should be subjected to a detailed review. An\nincomplete contribution – where you expect to do more work before receiving\na full review – should be prefixed [WIP] (to indicate a work in\nprogress) and changed to [MRG] when it matures. WIPs may be useful to:\nindicate you are working on something to avoid duplicated work, request\nbroad review of functionality or API, or seek collaborators. WIPs often\nbenefit from the inclusion of a task list in\nthe PR description.','prefix incomplete contribution',0,'',''),(10446,'scikit-learn','Before a PR can be merged, it needs to be approved by two core developers.\nPlease prefix the title of your pull request with [MRG] if the\ncontribution is complete and should be subjected to a detailed review. An\nincomplete contribution – where you expect to do more work before receiving\na full review – should be prefixed [WIP] (to indicate a work in\nprogress) and changed to [MRG] when it matures. WIPs may be useful to:\nindicate you are working on something to avoid duplicated work, request\nbroad review of functionality or API, or seek collaborators. WIPs often\nbenefit from the inclusion of a task list in\nthe PR description.','change incomplete contribution',0,'',''),(10447,'scikit-learn','In order to ease the reviewing process, we recommend that your contribution\ncomplies with the following rules before marking a PR as [MRG]. The\nbolded ones are especially important:','mark PR as  MRG',0,'',''),(10448,'scikit-learn','Give your pull request a helpful title that summarizes what your\ncontribution does. This title will often become the commit message once\nmerged so it should summarize your contribution for posterity. In some\ncases “Fix ” is enough. “Fix #” is never a\ngood title.','summarize helpful title',0,'',''),(10449,'scikit-learn','Give your pull request a helpful title that summarizes what your\ncontribution does. This title will often become the commit message once\nmerged so it should summarize your contribution for posterity. In some\ncases “Fix ” is enough. “Fix #” is never a\ngood title.','summarize contribution for posterity',0,'',''),(10450,'scikit-learn','Make sure your code passes the tests. The whole test suite can be run\nwith pytest, but it is usually not recommended since it takes a long\ntime. It is often enough to only run the test related to your changes:\nfor example, if you changed something in\nsklearn/linear_model/_logistic.py, running the following commands will\nusually be enough:','pass tests',0,'',''),(10451,'scikit-learn','Make sure your code passes the tests. The whole test suite can be run\nwith pytest, but it is usually not recommended since it takes a long\ntime. It is often enough to only run the test related to your changes:\nfor example, if you changed something in\nsklearn/linear_model/_logistic.py, running the following commands will\nusually be enough:','run whole test suite with pytest',0,'',''),(10452,'scikit-learn','Make sure your code passes the tests. The whole test suite can be run\nwith pytest, but it is usually not recommended since it takes a long\ntime. It is often enough to only run the test related to your changes:\nfor example, if you changed something in\nsklearn/linear_model/_logistic.py, running the following commands will\nusually be enough:','run test',0,'',''),(10453,'scikit-learn','Make sure your code passes the tests. The whole test suite can be run\nwith pytest, but it is usually not recommended since it takes a long\ntime. It is often enough to only run the test related to your changes:\nfor example, if you changed something in\nsklearn/linear_model/_logistic.py, running the following commands will\nusually be enough:','change something in sklearn/linear_model/_logistic.py',0,'',''),(10454,'scikit-learn','pytest sklearn/linear_model to test the whole\nlinear_model module','test whole linear_model module',0,'',''),(10455,'scikit-learn','pytest sklearn/tests/test_common.py -k LogisticRegression to run all our\nestimator checks (specifically for LogisticRegression, if that’s the\nestimator you changed).','run estimator checks',0,'',''),(10456,'scikit-learn','There may be other failing tests, but they will be caught by the CI so\nyou don’t need to run the whole test suite locally. For guidelines on how\nto use pytest efficiently, see the Useful pytest aliases and flags.','run whole test suite',0,'',''),(10457,'scikit-learn','There may be other failing tests, but they will be caught by the CI so\nyou don’t need to run the whole test suite locally. For guidelines on how\nto use pytest efficiently, see the Useful pytest aliases and flags.','use pytest efficiently',0,'',''),(10458,'scikit-learn','Make sure your code is properly commented and documented, and make\nsure the documentation renders properly. To build the documentation, please\nrefer to our Documentation guidelines. The CI will also\nbuild the docs: please refer to Generated documentation on GitHub Actions.','document code',0,'',''),(10459,'scikit-learn','Tests are necessary for enhancements to be\naccepted. Bug-fixes or new features should be provided with\nnon-regression tests. These tests\nverify the correct behavior of the fix or feature. In this manner, further\nmodifications on the code base are granted to be consistent with the\ndesired behavior. In the case of bug fixes, at the time of the PR, the\nnon-regression tests should fail for the code base in the main branch\nand pass for the PR code.','provide bug-fixes new features with non-regression tests',0,'',''),(10460,'scikit-learn','Tests are necessary for enhancements to be\naccepted. Bug-fixes or new features should be provided with\nnon-regression tests. These tests\nverify the correct behavior of the fix or feature. In this manner, further\nmodifications on the code base are granted to be consistent with the\ndesired behavior. In the case of bug fixes, at the time of the PR, the\nnon-regression tests should fail for the code base in the main branch\nand pass for the PR code.','pass  for PR code',0,'',''),(10461,'scikit-learn','See black’s\neditor integration documentation\nto configure your editor to run black.','configure editor',0,'',''),(10462,'scikit-learn','When applicable, use the validation tools and scripts in the\nsklearn.utils submodule.  A list of utility routines available\nfor developers can be found in the Utilities for Developers page.','use validation',0,'',''),(10463,'scikit-learn','When applicable, use the validation tools and scripts in the\nsklearn.utils submodule.  A list of utility routines available\nfor developers can be found in the Utilities for Developers page.','find list in utilities',0,'',''),(10464,'scikit-learn','When applicable, use the validation tools and scripts in the\nsklearn.utils submodule.  A list of utility routines available\nfor developers can be found in the Utilities for Developers page.','find list of utility routines available',0,'',''),(10465,'scikit-learn','When applicable, use the validation tools and scripts in the\nsklearn.utils submodule.  A list of utility routines available\nfor developers can be found in the Utilities for Developers page.','find list for Developers page',0,'',''),(10466,'scikit-learn','Often pull requests resolve one or more other issues (or pull requests).\nIf merging your pull request means that some other issues/PRs should\nbe closed, you should use keywords to create link to them\n(e.g., Fixes #1234; multiple issues/PRs are allowed as long as each\none is preceded by a keyword). Upon merging, those issues/PRs will\nautomatically be closed by GitHub. If your pull request is simply\nrelated to some other issues/PRs, create a link to them without using\nthe keywords (e.g., See also #1234).','resolve other issues',0,'',''),(10467,'scikit-learn','Often pull requests resolve one or more other issues (or pull requests).\nIf merging your pull request means that some other issues/PRs should\nbe closed, you should use keywords to create link to them\n(e.g., Fixes #1234; multiple issues/PRs are allowed as long as each\none is preceded by a keyword). Upon merging, those issues/PRs will\nautomatically be closed by GitHub. If your pull request is simply\nrelated to some other issues/PRs, create a link to them without using\nthe keywords (e.g., See also #1234).','create link upon merging',0,'',''),(10468,'scikit-learn','Often pull requests resolve one or more other issues (or pull requests).\nIf merging your pull request means that some other issues/PRs should\nbe closed, you should use keywords to create link to them\n(e.g., Fixes #1234; multiple issues/PRs are allowed as long as each\none is preceded by a keyword). Upon merging, those issues/PRs will\nautomatically be closed by GitHub. If your pull request is simply\nrelated to some other issues/PRs, create a link to them without using\nthe keywords (e.g., See also #1234).','use keywords',0,'',''),(10469,'scikit-learn','PRs should often substantiate the change, through benchmarks of\nperformance and efficiency (see Monitoring performance) or through\nexamples of usage. Examples also illustrate the features and intricacies of\nthe library to users. Have a look at other examples in the examples/\ndirectory for reference. Examples should demonstrate why the new\nfunctionality is useful in practice and, if possible, compare it to other\nmethods available in scikit-learn.','compare  to other methods available',0,'',''),(10470,'scikit-learn','New features have some maintenance overhead. We expect PR authors\nto take part in the maintenance for the code they submit, at least\ninitially. New features need to be illustrated with narrative\ndocumentation in the user guide, with small code snippets.\nIf relevant, please also add references in the literature, with PDF links\nwhen possible.','submit code',0,'',''),(10471,'scikit-learn','New features have some maintenance overhead. We expect PR authors\nto take part in the maintenance for the code they submit, at least\ninitially. New features need to be illustrated with narrative\ndocumentation in the user guide, with small code snippets.\nIf relevant, please also add references in the literature, with PDF links\nwhen possible.','add references with PDF links',0,'',''),(10472,'scikit-learn','New features have some maintenance overhead. We expect PR authors\nto take part in the maintenance for the code they submit, at least\ninitially. New features need to be illustrated with narrative\ndocumentation in the user guide, with small code snippets.\nIf relevant, please also add references in the literature, with PDF links\nwhen possible.','add references in literature',0,'',''),(10473,'scikit-learn','The user guide should also include expected time and space complexity\nof the algorithm and scalability, e.g. “this algorithm can scale to a\nlarge number of samples > 100000, but does not scale in dimensionality:\nn_features is expected to be lower than 100”.','include expected time of scalability',0,'',''),(10474,'scikit-learn','The user guide should also include expected time and space complexity\nof the algorithm and scalability, e.g. “this algorithm can scale to a\nlarge number of samples > 100000, but does not scale in dimensionality:\nn_features is expected to be lower than 100”.','include expected time of algorithm',0,'',''),(10475,'scikit-learn','The user guide should also include expected time and space complexity\nof the algorithm and scalability, e.g. “this algorithm can scale to a\nlarge number of samples > 100000, but does not scale in dimensionality:\nn_features is expected to be lower than 100”.','include space complexity of scalability',0,'',''),(10476,'scikit-learn','The user guide should also include expected time and space complexity\nof the algorithm and scalability, e.g. “this algorithm can scale to a\nlarge number of samples > 100000, but does not scale in dimensionality:\nn_features is expected to be lower than 100”.','include space complexity of algorithm',0,'',''),(10477,'scikit-learn','The user guide should also include expected time and space complexity\nof the algorithm and scalability, e.g. “this algorithm can scale to a\nlarge number of samples > 100000, but does not scale in dimensionality:\nn_features is expected to be lower than 100”.','scale e.g. to large number',0,'',''),(10478,'scikit-learn','You can also check our Code Review Guidelines to get an idea of what reviewers\nwill expect.','check code Review guidelines',0,'',''),(10479,'scikit-learn','You can also check our Code Review Guidelines to get an idea of what reviewers\nwill expect.','get idea',0,'',''),(10480,'scikit-learn','You can check for common programming errors with the following tools:','check  with following tools',0,'',''),(10481,'scikit-learn','You can check for common programming errors with the following tools:','check  for common programming errors',0,'',''),(10482,'scikit-learn','see also Testing and improving test coverage','test test coverage',0,'',''),(10483,'scikit-learn','Run static analysis with mypy:','run static analysis with mypy',1,'https://scikit-learn.org/dev/developers/contributing.html',''),(10484,'scikit-learn','must not produce new errors in your pull request. Using # type: ignore\nannotation can be a workaround for a few cases that are not supported by\nmypy, in particular,','ignore annotation',0,'',''),(10485,'scikit-learn','when importing C or Cython modules','import c',0,'',''),(10486,'scikit-learn','when importing C or Cython modules','import Cython',0,'',''),(10487,'scikit-learn','Bonus points for contributions that include a performance analysis with\na benchmark script and profiling output (see Monitoring performance).','include performance analysis with profiling output',0,'',''),(10488,'scikit-learn','Bonus points for contributions that include a performance analysis with\na benchmark script and profiling output (see Monitoring performance).','include performance analysis with benchmark script',0,'',''),(10489,'scikit-learn','Bonus points for contributions that include a performance analysis with\na benchmark script and profiling output (see Monitoring performance).','include contributions with profiling output',0,'',''),(10490,'scikit-learn','Bonus points for contributions that include a performance analysis with\na benchmark script and profiling output (see Monitoring performance).','include contributions with benchmark script',0,'',''),(10491,'scikit-learn','The current state of the scikit-learn code base is not compliant with\nall of those guidelines, but we expect that enforcing those constraints\non all new contributions will get the overall code base quality in the\nright direction.','get overall code base quality in right direction',0,'',''),(10492,'scikit-learn','Azure pipelines are used for testing scikit-learn on Linux, Mac and Windows,\nwith different dependencies and settings.','use azure pipelines with different dependencies',0,'',''),(10493,'scikit-learn','Azure pipelines are used for testing scikit-learn on Linux, Mac and Windows,\nwith different dependencies and settings.','use azure pipelines with settings',0,'',''),(10494,'scikit-learn','Azure pipelines are used for testing scikit-learn on Linux, Mac and Windows,\nwith different dependencies and settings.','use azure pipelines for testing scikit-learn',0,'',''),(10495,'scikit-learn','Azure pipelines are used for testing scikit-learn on Linux, Mac and Windows,\nwith different dependencies and settings.','use azure pipelines on linux',0,'',''),(10496,'scikit-learn','Azure pipelines are used for testing scikit-learn on Linux, Mac and Windows,\nwith different dependencies and settings.','use azure pipelines on mac',0,'',''),(10497,'scikit-learn','Azure pipelines are used for testing scikit-learn on Linux, Mac and Windows,\nwith different dependencies and settings.','use azure pipelines on windows',0,'',''),(10498,'scikit-learn','CircleCI is used to build the docs for viewing, for linting with flake8, and\nfor testing with ARM64 / aarch64 on Linux','use CircleCI',0,'',''),(10499,'scikit-learn','CircleCI is used to build the docs for viewing, for linting with flake8, and\nfor testing with ARM64 / aarch64 on Linux','test  with ARM64 / aarch64',0,'',''),(10500,'scikit-learn','CD is run (wheels and source distribution are built)','run CD',0,'',''),(10501,'scikit-learn','CD is run only for GitHub Actions','run CD for GitHub actions',0,'',''),(10502,'scikit-learn','Build & test with PyPy','test  with PyPy',0,'',''),(10503,'scikit-learn','Run float32 tests by setting SKLEARN_RUN_FLOAT32_TESTS=1. See Environment variables for more details','test  by setting',0,'',''),(10504,'scikit-learn','Docs built, but excludes example gallery plots','exclude example gallery plots',0,'',''),(10505,'scikit-learn','Note that, by default, the documentation is built but only the examples\nthat are directly modified by the pull request are executed.','modify examples',0,'',''),(10506,'scikit-learn','Note that, by default, the documentation is built but only the examples\nthat are directly modified by the pull request are executed.','execute examples',0,'',''),(10507,'scikit-learn','A pull request may have the label “stalled” or “help wanted” if we\nhave already identified it as a candidate for other contributors.','identify  as candidate',0,'',''),(10508,'scikit-learn','To decide whether an inactive PR is stalled, ask the contributor if\nshe/he plans to continue working on the PR in the near future.\nFailure to respond within 2 weeks with an activity that moves the PR\nforward suggests that the PR is stalled and will result in tagging\nthat PR with “help wanted”.','ask contributor',0,'',''),(10509,'scikit-learn','To decide whether an inactive PR is stalled, ask the contributor if\nshe/he plans to continue working on the PR in the near future.\nFailure to respond within 2 weeks with an activity that moves the PR\nforward suggests that the PR is stalled and will result in tagging\nthat PR with “help wanted”.','move activity',0,'',''),(10510,'scikit-learn','Note that if a PR has received earlier comments on the contribution\nthat have had no reply in a month, it is safe to assume that the PR\nis stalled and to shorten the wait time to one day.','receive earlier comments on contribution',0,'',''),(10511,'scikit-learn','Note that if a PR has received earlier comments on the contribution\nthat have had no reply in a month, it is safe to assume that the PR\nis stalled and to shorten the wait time to one day.','shorten wait time to day',0,'',''),(10512,'scikit-learn','After a sprint, follow-up for un-merged PRs opened during sprint will\nbe communicated to participants at the sprint, and those PRs will be\ntagged “sprint”. PRs tagged with “sprint” can be reassigned or\ndeclared stalled by sprint leaders.','open  during sprint',0,'',''),(10513,'scikit-learn','Taking over a stalled PR: To take over a PR, it is important to\ncomment on the stalled PR that you are taking over and to link from the\nnew PR to the old one. The new PR should be created by pulling from the\nold one.','link  from new PR',0,'',''),(10514,'scikit-learn','Taking over a stalled PR: To take over a PR, it is important to\ncomment on the stalled PR that you are taking over and to link from the\nnew PR to the old one. The new PR should be created by pulling from the\nold one.','create new PR',0,'',''),(10515,'scikit-learn','Generally speaking, issues which are up for grabs will have a\n“help wanted”.\ntag. However, not all issues which need contributors will have this tag,\nas the “help wanted” tag is not always up-to-date with the state\nof the issue. Contributors can find issues which are still up for grabs\nusing the following guidelines:','find issues',0,'',''),(10516,'scikit-learn','Generally speaking, issues which are up for grabs will have a\n“help wanted”.\ntag. However, not all issues which need contributors will have this tag,\nas the “help wanted” tag is not always up-to-date with the state\nof the issue. Contributors can find issues which are still up for grabs\nusing the following guidelines:','use following guidelines',0,'',''),(10517,'scikit-learn','Generally speaking, issues which are up for grabs will have a\n“help wanted”.\ntag. However, not all issues which need contributors will have this tag,\nas the “help wanted” tag is not always up-to-date with the state\nof the issue. Contributors can find issues which are still up for grabs\nusing the following guidelines:','use issues',0,'',''),(10518,'scikit-learn','Check for linked pull requests','check  for linked pull requests',0,'',''),(10519,'scikit-learn','Check the conversation to see if anyone has said that they’re working on\ncreating a pull request','check conversation',0,'',''),(10520,'scikit-learn','Check the conversation to see if anyone has said that they’re working on\ncreating a pull request','create pull request',0,'',''),(10521,'scikit-learn','If the issue is linked to a stalled pull request,\nwe recommend that contributors follow the procedure\ndescribed in the Stalled pull requests\nsection rather than working directly on the issue.','link issue to stalled pull request',0,'',''),(10522,'scikit-learn','If the issue is linked to a stalled pull request,\nwe recommend that contributors follow the procedure\ndescribed in the Stalled pull requests\nsection rather than working directly on the issue.','describe  in stalled pull requests section',0,'',''),(10523,'scikit-learn','We often use the help wanted tag to mark issues regardless of difficulty. Additionally,\nwe use the help wanted tag to mark Pull Requests which have been abandoned\nby their original contributor and are available for someone to pick up where the original\ncontributor left off. The list of issues with the help wanted tag can be found\nhere.','mark issues regardless_of difficulty',0,'',''),(10524,'scikit-learn','We often use the help wanted tag to mark issues regardless of difficulty. Additionally,\nwe use the help wanted tag to mark Pull Requests which have been abandoned\nby their original contributor and are available for someone to pick up where the original\ncontributor left off. The list of issues with the help wanted tag can be found\nhere.','mark Pull requests',0,'',''),(10525,'scikit-learn','We often use the help wanted tag to mark issues regardless of difficulty. Additionally,\nwe use the help wanted tag to mark Pull Requests which have been abandoned\nby their original contributor and are available for someone to pick up where the original\ncontributor left off. The list of issues with the help wanted tag can be found\nhere.','find tag',0,'',''),(10526,'scikit-learn','user guide - these provide more detailed information about the algorithms\nimplemented in scikit-learn and generally live in the root\ndoc/ directory\nand\ndoc/modules/.','provide more detailed information about algorithms',0,'',''),(10527,'scikit-learn','user guide - these provide more detailed information about the algorithms\nimplemented in scikit-learn and generally live in the root\ndoc/ directory\nand\ndoc/modules/.','implement  in scikit-learn',0,'',''),(10528,'scikit-learn','tutorials - these introduce various statistical learning and machine learning\nconcepts and are located in\ndoc/tutorial.','introduce various statistical learning',0,'',''),(10529,'scikit-learn','tutorials - these introduce various statistical learning and machine learning\nconcepts and are located in\ndoc/tutorial.','introduce machine learning concepts',0,'',''),(10530,'scikit-learn','tutorials - these introduce various statistical learning and machine learning\nconcepts and are located in\ndoc/tutorial.','locate  in doc/tutorial',0,'',''),(10531,'scikit-learn','examples - these provide full code examples that may demonstrate the use\nof scikit-learn modules, compare different algorithms or discuss their\ninterpretation etc. Examples live in\nexamples/','provide full code examples',0,'',''),(10532,'scikit-learn','examples - these provide full code examples that may demonstrate the use\nof scikit-learn modules, compare different algorithms or discuss their\ninterpretation etc. Examples live in\nexamples/','compare different algorithms',0,'',''),(10533,'scikit-learn','other reStructuredText documents (like this one) - provide various other\nuseful information (e.g., our guide to contributing) and live in\ndoc/.','provide various other useful information',0,'',''),(10534,'scikit-learn','You can edit the documentation using any text editor, and then generate the\nHTML output by following Building the documentation. The resulting HTML files\nwill be placed in _build/html/stable and are viewable in a web browser, for\ninstance by opening the local _build/html/stable/index.html file.','edit documentation',0,'',''),(10535,'scikit-learn','You can edit the documentation using any text editor, and then generate the\nHTML output by following Building the documentation. The resulting HTML files\nwill be placed in _build/html/stable and are viewable in a web browser, for\ninstance by opening the local _build/html/stable/index.html file.','use text editor',0,'',''),(10536,'scikit-learn','You can edit the documentation using any text editor, and then generate the\nHTML output by following Building the documentation. The resulting HTML files\nwill be placed in _build/html/stable and are viewable in a web browser, for\ninstance by opening the local _build/html/stable/index.html file.','generate HTML output by following',0,'',''),(10537,'scikit-learn','You can edit the documentation using any text editor, and then generate the\nHTML output by following Building the documentation. The resulting HTML files\nwill be placed in _build/html/stable and are viewable in a web browser, for\ninstance by opening the local _build/html/stable/index.html file.','open local _build/html/stable/index.html file',0,'',''),(10538,'scikit-learn','You can edit the documentation using any text editor, and then generate the\nHTML output by following Building the documentation. The resulting HTML files\nwill be placed in _build/html/stable and are viewable in a web browser, for\ninstance by opening the local _build/html/stable/index.html file.','place resulting HTML files in _',0,'',''),(10539,'scikit-learn','First, make sure you have properly installed\nthe development version.','install development version',0,'',''),(10540,'scikit-learn','Building the documentation requires installing some additional packages:','install additional packages',1,'https://scikit-learn.org/dev/developers/contributing.html','building-documentation'),(10541,'scikit-learn','In the vast majority of cases, you only need to generate the full web site,\nwithout the example gallery:','generate full web site without example gallery',1,'https://scikit-learn.org/dev/developers/contributing.html','building-documentation'),(10542,'scikit-learn','The documentation will be generated in the _build/html/stable directory\nand are viewable in a web browser, for instance by opening the local\n_build/html/stable/index.html file.\nTo also generate the example gallery you can use:','open local _build/html/stable/index.html file',1,'https://scikit-learn.org/dev/developers/contributing.html','building-documentation'),(10543,'scikit-learn','The documentation will be generated in the _build/html/stable directory\nand are viewable in a web browser, for instance by opening the local\n_build/html/stable/index.html file.\nTo also generate the example gallery you can use:','generate documentation in _ build/html/stable directory',1,'https://scikit-learn.org/dev/developers/contributing.html','building-documentation'),(10544,'scikit-learn','The documentation will be generated in the _build/html/stable directory\nand are viewable in a web browser, for instance by opening the local\n_build/html/stable/index.html file.\nTo also generate the example gallery you can use:','generate example gallery',1,'https://scikit-learn.org/dev/developers/contributing.html','building-documentation'),(10545,'scikit-learn','This will run all the examples, which takes a while. If you only want to\ngenerate a few examples, you can use:','run examples',1,'https://scikit-learn.org/dev/developers/contributing.html','building-documentation'),(10546,'scikit-learn','This will run all the examples, which takes a while. If you only want to\ngenerate a few examples, you can use:','generate few examples',1,'https://scikit-learn.org/dev/developers/contributing.html','building-documentation'),(10547,'scikit-learn','This is particularly useful if you are modifying a few examples.','modify few examples',1,'https://scikit-learn.org/dev/developers/contributing.html','building-documentation'),(10548,'scikit-learn','While we do our best to have the documentation build under as many\nversions of Sphinx as possible, the different versions tend to\nbehave slightly differently. To get the best results, you should\nuse the same version as the one we used on CircleCI. Look at this\ngithub search\nto know the exact version.','get best results',0,'',''),(10549,'scikit-learn','While we do our best to have the documentation build under as many\nversions of Sphinx as possible, the different versions tend to\nbehave slightly differently. To get the best results, you should\nuse the same version as the one we used on CircleCI. Look at this\ngithub search\nto know the exact version.','use same version',0,'',''),(10550,'scikit-learn','While we do our best to have the documentation build under as many\nversions of Sphinx as possible, the different versions tend to\nbehave slightly differently. To get the best results, you should\nuse the same version as the one we used on CircleCI. Look at this\ngithub search\nto know the exact version.','use  on CircleCI',0,'',''),(10551,'scikit-learn','Basically, to elaborate on the above, it is best to always\nstart with a small paragraph with a hand-waving explanation of what the\nmethod does to the data. Then, it is very helpful to point out why the feature is\nuseful and when it should be used - the latter also including “big O”\n(\\(O\\left(g\\left(n\\right)\\right)\\)) complexities of the algorithm, as opposed\nto just rules of thumb, as the latter can be very machine-dependent. If those\ncomplexities are not available, then rules of thumb may be provided instead.','use latter including big o \\ right',0,'',''),(10552,'scikit-learn','Basically, to elaborate on the above, it is best to always\nstart with a small paragraph with a hand-waving explanation of what the\nmethod does to the data. Then, it is very helpful to point out why the feature is\nuseful and when it should be used - the latter also including “big O”\n(\\(O\\left(g\\left(n\\right)\\right)\\)) complexities of the algorithm, as opposed\nto just rules of thumb, as the latter can be very machine-dependent. If those\ncomplexities are not available, then rules of thumb may be provided instead.','provide rules of thumb',0,'',''),(10553,'scikit-learn','Secondly, a generated figure from an example (as mentioned in the previous\nparagraph) should then be included to further provide some intuition.','provide intuition',0,'',''),(10554,'scikit-learn','Secondly, a generated figure from an example (as mentioned in the previous\nparagraph) should then be included to further provide some intuition.','include generated figure',0,'',''),(10555,'scikit-learn','Next, one or two small code examples to show its use can be added.','show use',0,'',''),(10556,'scikit-learn','Next, one or two small code examples to show its use can be added.','add small code examples',0,'',''),(10557,'scikit-learn','Next, any math and equations, followed by references,\ncan be added to further the documentation. Not starting the\ndocumentation with the maths makes it more friendly towards\nusers that are just interested in what the feature will do, as\nopposed to how it works “under the hood”.','add math',0,'',''),(10558,'scikit-learn','Next, any math and equations, followed by references,\ncan be added to further the documentation. Not starting the\ndocumentation with the maths makes it more friendly towards\nusers that are just interested in what the feature will do, as\nopposed to how it works “under the hood”.','add equations',0,'',''),(10559,'scikit-learn','When documenting the parameters and attributes, here is a list of some\nwell-formatted examples:','document parameters',1,'https://scikit-learn.org/dev/developers/contributing.html',''),(10560,'scikit-learn','Use Python basic types. (bool instead of boolean)','use Python basic types',0,'',''),(10561,'scikit-learn','Specify dataframe when “frame-like” features are being used, such\nas the column names.','use frame-like features such_as column names',0,'',''),(10562,'scikit-learn','When specifying the data type of a list, use of as a delimiter:\nlist of int. When the parameter supports arrays giving details\nabout the shape and/or data type and a list of such arrays, you can\nuse one of array-like of shape (n_samples,) or list of such arrays.','specify data type of list',0,'',''),(10563,'scikit-learn','When specifying the data type of a list, use of as a delimiter:\nlist of int. When the parameter supports arrays giving details\nabout the shape and/or data type and a list of such arrays, you can\nuse one of array-like of shape (n_samples,) or list of such arrays.','use delimiter',0,'',''),(10564,'scikit-learn','When specifying the data type of a list, use of as a delimiter:\nlist of int. When the parameter supports arrays giving details\nabout the shape and/or data type and a list of such arrays, you can\nuse one of array-like of shape (n_samples,) or list of such arrays.','support arrays',0,'',''),(10565,'scikit-learn','When specifying the dtype of an ndarray, use e.g. dtype=np.int32\nafter defining the shape:\nndarray of shape (n_samples,), dtype=np.int32. You can specify\nmultiple dtype as a set:\narray-like of shape (n_samples,), dtype={np.float64, np.float32}.\nIf one wants to mention arbitrary precision, use integral and\nfloating rather than the Python dtype int and float. When both\nint and floating are supported, there is no need to specify the\ndtype.','specify dtype of ndarray',0,'',''),(10566,'scikit-learn','When specifying the dtype of an ndarray, use e.g. dtype=np.int32\nafter defining the shape:\nndarray of shape (n_samples,), dtype=np.int32. You can specify\nmultiple dtype as a set:\narray-like of shape (n_samples,), dtype={np.float64, np.float32}.\nIf one wants to mention arbitrary precision, use integral and\nfloating rather than the Python dtype int and float. When both\nint and floating are supported, there is no need to specify the\ndtype.','define shape',0,'',''),(10567,'scikit-learn','When specifying the dtype of an ndarray, use e.g. dtype=np.int32\nafter defining the shape:\nndarray of shape (n_samples,), dtype=np.int32. You can specify\nmultiple dtype as a set:\narray-like of shape (n_samples,), dtype={np.float64, np.float32}.\nIf one wants to mention arbitrary precision, use integral and\nfloating rather than the Python dtype int and float. When both\nint and floating are supported, there is no need to specify the\ndtype.','specify multiple dtype np.float32 }',0,'',''),(10568,'scikit-learn','When specifying the dtype of an ndarray, use e.g. dtype=np.int32\nafter defining the shape:\nndarray of shape (n_samples,), dtype=np.int32. You can specify\nmultiple dtype as a set:\narray-like of shape (n_samples,), dtype={np.float64, np.float32}.\nIf one wants to mention arbitrary precision, use integral and\nfloating rather than the Python dtype int and float. When both\nint and floating are supported, there is no need to specify the\ndtype.','use Python dtype int',0,'',''),(10569,'scikit-learn','When specifying the dtype of an ndarray, use e.g. dtype=np.int32\nafter defining the shape:\nndarray of shape (n_samples,), dtype=np.int32. You can specify\nmultiple dtype as a set:\narray-like of shape (n_samples,), dtype={np.float64, np.float32}.\nIf one wants to mention arbitrary precision, use integral and\nfloating rather than the Python dtype int and float. When both\nint and floating are supported, there is no need to specify the\ndtype.','use float',0,'',''),(10570,'scikit-learn','When specifying the dtype of an ndarray, use e.g. dtype=np.int32\nafter defining the shape:\nndarray of shape (n_samples,), dtype=np.int32. You can specify\nmultiple dtype as a set:\narray-like of shape (n_samples,), dtype={np.float64, np.float32}.\nIf one wants to mention arbitrary precision, use integral and\nfloating rather than the Python dtype int and float. When both\nint and floating are supported, there is no need to specify the\ndtype.','specify dtype',0,'',''),(10571,'scikit-learn','When specifying the dtype of an ndarray, use e.g. dtype=np.int32\nafter defining the shape:\nndarray of shape (n_samples,), dtype=np.int32. You can specify\nmultiple dtype as a set:\narray-like of shape (n_samples,), dtype={np.float64, np.float32}.\nIf one wants to mention arbitrary precision, use integral and\nfloating rather than the Python dtype int and float. When both\nint and floating are supported, there is no need to specify the\ndtype.','support int',0,'',''),(10572,'scikit-learn','When the default is None, None only needs to be specified at the\nend with default=None. Be sure to include in the docstring, what it\nmeans for the parameter or attribute to be None.','specify  at end',0,'',''),(10573,'scikit-learn','When the default is None, None only needs to be specified at the\nend with default=None. Be sure to include in the docstring, what it\nmeans for the parameter or attribute to be None.','include  in docstring',0,'',''),(10574,'scikit-learn','When bibliographic references are available with arxiv\nor Digital Object Identifier identification numbers,\nuse the sphinx directives :arxiv: or :doi:. For example, see references in\nSpectral Clustering Graphs.','use sphinx directives',0,'',''),(10575,'scikit-learn','In scikit-learn reStructuredText files both single and double backticks\nsurrounding text will render as inline literal (often used for code, e.g.,\nlist). This is due to specific configurations we have set. Single\nbackticks should be used nowadays.','render  as inline literal',0,'',''),(10576,'scikit-learn','In scikit-learn reStructuredText files both single and double backticks\nsurrounding text will render as inline literal (often used for code, e.g.,\nlist). This is due to specific configurations we have set. Single\nbackticks should be used nowadays.','render  in scikit-learn reStructuredText files',0,'',''),(10577,'scikit-learn','In scikit-learn reStructuredText files both single and double backticks\nsurrounding text will render as inline literal (often used for code, e.g.,\nlist). This is due to specific configurations we have set. Single\nbackticks should be used nowadays.','use single backticks',0,'',''),(10578,'scikit-learn','Before submitting your pull request check if your modifications have\nintroduced new sphinx warnings and try to fix them.','submit pull',0,'',''),(10579,'scikit-learn','Before submitting your pull request check if your modifications have\nintroduced new sphinx warnings and try to fix them.','introduce new sphinx warnings',0,'',''),(10580,'scikit-learn','Before submitting your pull request check if your modifications have\nintroduced new sphinx warnings and try to fix them.','check  before submitting',0,'',''),(10581,'scikit-learn','Section - to link to an arbitrary section in the documentation, use reference\nlabels (see\nSphinx docs).\nFor example:','link  to arbitrary section',1,'https://scikit-learn.org/dev/developers/contributing.html',''),(10582,'scikit-learn','You should not modify existing sphinx reference labels as this would break\nexisting cross references and external links pointing to specific sections in\nthe scikit-learn documentation.','break external links',0,'',''),(10583,'scikit-learn','You should not modify existing sphinx reference labels as this would break\nexisting cross references and external links pointing to specific sections in\nthe scikit-learn documentation.','break existing cross references',0,'',''),(10584,'scikit-learn','Glossary - linking to a term in the Glossary of Common Terms and API Elements:','link  to term',1,'https://scikit-learn.org/dev/developers/contributing.html',''),(10585,'scikit-learn','Function - to link to the documentation of a function, use the full\nimport path to the function:','use full import path to function',1,'https://scikit-learn.org/dev/developers/contributing.html',''),(10586,'scikit-learn','Function - to link to the documentation of a function, use the full\nimport path to the function:','use function to function',1,'https://scikit-learn.org/dev/developers/contributing.html',''),(10587,'scikit-learn','Function - to link to the documentation of a function, use the full\nimport path to the function:','link  to documentation',1,'https://scikit-learn.org/dev/developers/contributing.html',''),(10588,'scikit-learn','However, if there is a ‘currentmodule’ directive above you in the document,\nyou will only need to use the path to the function succeeding the current\nmodule specified. For example:','use path to function',1,'https://scikit-learn.org/dev/developers/contributing.html',''),(10589,'scikit-learn','Class - to link to documentation of a class, use the full import path to the\nclass, unless there is a ‘currentmodule’ directive in the document above\n(see above):','use full import path to class',1,'https://scikit-learn.org/dev/developers/contributing.html',''),(10590,'scikit-learn','Class - to link to documentation of a class, use the full import path to the\nclass, unless there is a ‘currentmodule’ directive in the document above\n(see above):','use class to class',1,'https://scikit-learn.org/dev/developers/contributing.html',''),(10591,'scikit-learn','Class - to link to documentation of a class, use the full import path to the\nclass, unless there is a ‘currentmodule’ directive in the document above\n(see above):','link  to documentation',1,'https://scikit-learn.org/dev/developers/contributing.html',''),(10592,'scikit-learn','When you change the documentation in a pull request, GitHub Actions automatically\nbuilds it. To view the documentation generated by GitHub Actions, simply go to the\nbottom of your PR page, look for the item “Check the rendered docs here!” and\nclick on ‘details’ next to it:','change documentation in pull request',0,'',''),(10593,'scikit-learn','When you change the documentation in a pull request, GitHub Actions automatically\nbuilds it. To view the documentation generated by GitHub Actions, simply go to the\nbottom of your PR page, look for the item “Check the rendered docs here!” and\nclick on ‘details’ next to it:','check rendered docs',0,'',''),(10594,'scikit-learn','High-quality unit testing\nis a corner-stone of the scikit-learn development process. For this\npurpose, we use the pytest\npackage. The tests are functions appropriately named, located in tests\nsubdirectories, that check the validity of the algorithms and the\ndifferent options of the code.','use pytest package for purpose',0,'',''),(10595,'scikit-learn','High-quality unit testing\nis a corner-stone of the scikit-learn development process. For this\npurpose, we use the pytest\npackage. The tests are functions appropriately named, located in tests\nsubdirectories, that check the validity of the algorithms and the\ndifferent options of the code.','check validity of algorithms',0,'',''),(10596,'scikit-learn','High-quality unit testing\nis a corner-stone of the scikit-learn development process. For this\npurpose, we use the pytest\npackage. The tests are functions appropriately named, located in tests\nsubdirectories, that check the validity of the algorithms and the\ndifferent options of the code.','check validity of code',0,'',''),(10597,'scikit-learn','High-quality unit testing\nis a corner-stone of the scikit-learn development process. For this\npurpose, we use the pytest\npackage. The tests are functions appropriately named, located in tests\nsubdirectories, that check the validity of the algorithms and the\ndifferent options of the code.','check different options of algorithms',0,'',''),(10598,'scikit-learn','High-quality unit testing\nis a corner-stone of the scikit-learn development process. For this\npurpose, we use the pytest\npackage. The tests are functions appropriately named, located in tests\nsubdirectories, that check the validity of the algorithms and the\ndifferent options of the code.','check different options of code',0,'',''),(10599,'scikit-learn','High-quality unit testing\nis a corner-stone of the scikit-learn development process. For this\npurpose, we use the pytest\npackage. The tests are functions appropriately named, located in tests\nsubdirectories, that check the validity of the algorithms and the\ndifferent options of the code.','check tests subdirectories of algorithms',0,'',''),(10600,'scikit-learn','High-quality unit testing\nis a corner-stone of the scikit-learn development process. For this\npurpose, we use the pytest\npackage. The tests are functions appropriately named, located in tests\nsubdirectories, that check the validity of the algorithms and the\ndifferent options of the code.','check tests subdirectories of code',0,'',''),(10601,'scikit-learn','High-quality unit testing\nis a corner-stone of the scikit-learn development process. For this\npurpose, we use the pytest\npackage. The tests are functions appropriately named, located in tests\nsubdirectories, that check the validity of the algorithms and the\ndifferent options of the code.','locate  in tests subdirectories',0,'',''),(10602,'scikit-learn','Running pytest in a folder will run all the tests of the corresponding\nsubpackages. For a more detailed pytest workflow, please refer to the\nPull request checklist.','run pytest in folder',0,'',''),(10603,'scikit-learn','Running pytest in a folder will run all the tests of the corresponding\nsubpackages. For a more detailed pytest workflow, please refer to the\nPull request checklist.','run tests of corresponding subpackages',0,'',''),(10604,'scikit-learn','Test fixtures ensure that a set of tests will be executing with the appropriate\ninitialization and cleanup. The scikit-learn test suite implements a fixture\nwhich can be used with matplotlib.','execute  with cleanup',0,'',''),(10605,'scikit-learn','Test fixtures ensure that a set of tests will be executing with the appropriate\ninitialization and cleanup. The scikit-learn test suite implements a fixture\nwhich can be used with matplotlib.','execute  with appropriate initialization',0,'',''),(10606,'scikit-learn','Test fixtures ensure that a set of tests will be executing with the appropriate\ninitialization and cleanup. The scikit-learn test suite implements a fixture\nwhich can be used with matplotlib.','implement fixture',0,'',''),(10607,'scikit-learn','Test fixtures ensure that a set of tests will be executing with the appropriate\ninitialization and cleanup. The scikit-learn test suite implements a fixture\nwhich can be used with matplotlib.','use fixture with matplotlib',0,'',''),(10608,'scikit-learn','The pyplot fixture should be used when a test function is dealing with\nmatplotlib. matplotlib is a soft dependency and is not required.\nThis fixture is in charge of skipping the tests if matplotlib is not\ninstalled. In addition, figures created during the tests will be\nautomatically closed once the test function has been executed.','use pyplot fixture',0,'',''),(10609,'scikit-learn','The pyplot fixture should be used when a test function is dealing with\nmatplotlib. matplotlib is a soft dependency and is not required.\nThis fixture is in charge of skipping the tests if matplotlib is not\ninstalled. In addition, figures created during the tests will be\nautomatically closed once the test function has been executed.','skip tests',0,'',''),(10610,'scikit-learn','The pyplot fixture should be used when a test function is dealing with\nmatplotlib. matplotlib is a soft dependency and is not required.\nThis fixture is in charge of skipping the tests if matplotlib is not\ninstalled. In addition, figures created during the tests will be\nautomatically closed once the test function has been executed.','create  during tests',0,'',''),(10611,'scikit-learn','The pyplot fixture should be used when a test function is dealing with\nmatplotlib. matplotlib is a soft dependency and is not required.\nThis fixture is in charge of skipping the tests if matplotlib is not\ninstalled. In addition, figures created during the tests will be\nautomatically closed once the test function has been executed.','execute test function',0,'',''),(10612,'scikit-learn','To use this fixture in a test function, one needs to pass it as an\nargument:','use fixture in test function',1,'https://scikit-learn.org/dev/developers/contributing.html',''),(10613,'scikit-learn','To use this fixture in a test function, one needs to pass it as an\nargument:','pass  as argument',1,'https://scikit-learn.org/dev/developers/contributing.html',''),(10614,'scikit-learn','To test code coverage, you need to install the coverage package in addition to pytest.','test code coverage',0,'',''),(10615,'scikit-learn','To test code coverage, you need to install the coverage package in addition to pytest.','install coverage package to pytest',0,'',''),(10616,'scikit-learn','write or adapt a test specifically for these lines.','write test for lines',0,'',''),(10617,'scikit-learn','When proposing changes to the existing code base, it’s important to make sure\nthat they don’t introduce performance regressions. Scikit-learn uses\nasv benchmarks to monitor the\nperformance of a selection of common estimators and functions. You can view\nthese benchmarks on the scikit-learn benchmark page.\nThe corresponding benchmark suite can be found in the scikit-learn/asv_benchmarks directory.','introduce performance regressions',0,'',''),(10618,'scikit-learn','When proposing changes to the existing code base, it’s important to make sure\nthat they don’t introduce performance regressions. Scikit-learn uses\nasv benchmarks to monitor the\nperformance of a selection of common estimators and functions. You can view\nthese benchmarks on the scikit-learn benchmark page.\nThe corresponding benchmark suite can be found in the scikit-learn/asv_benchmarks directory.','find corresponding benchmark suite in scikit-learn/asv _ benchmarks directory',0,'',''),(10619,'scikit-learn','To use all features of asv, you will need either conda or virtualenv. For\nmore details please check the asv installation webpage.','use features of asv',0,'',''),(10620,'scikit-learn','To use all features of asv, you will need either conda or virtualenv. For\nmore details please check the asv installation webpage.','check asv installation webpage',0,'',''),(10621,'scikit-learn','First of all you need to install the development version of asv:','install development version of asv',1,'https://scikit-learn.org/dev/developers/contributing.html','monitoring-performances'),(10622,'scikit-learn','and change your directory to asv_benchmarks/:','change directory to asv_benchmarks /',1,'https://scikit-learn.org/dev/developers/contributing.html','monitoring-performances'),(10623,'scikit-learn','The benchmark suite is configured to run against your local clone of\nscikit-learn. Make sure it is up to date:','run  against local clone',1,'https://scikit-learn.org/dev/developers/contributing.html','monitoring-performances'),(10624,'scikit-learn','The benchmark suite is configured to run against your local clone of\nscikit-learn. Make sure it is up to date:','configure benchmark suite',1,'https://scikit-learn.org/dev/developers/contributing.html','monitoring-performances'),(10625,'scikit-learn','In the benchmark suite, the benchmarks are organized following the same\nstructure as scikit-learn. For example, you can compare the performance of a\nspecific estimator between upstream/main and the branch you are working on:','compare performance of branch',1,'https://scikit-learn.org/dev/developers/contributing.html','monitoring-performances'),(10626,'scikit-learn','In the benchmark suite, the benchmarks are organized following the same\nstructure as scikit-learn. For example, you can compare the performance of a\nspecific estimator between upstream/main and the branch you are working on:','compare performance of specific estimator',1,'https://scikit-learn.org/dev/developers/contributing.html','monitoring-performances'),(10627,'scikit-learn','The command uses conda by default for creating the benchmark environments. If\nyou want to use virtualenv instead, use the -E flag:','use conda by default',1,'https://scikit-learn.org/dev/developers/contributing.html','monitoring-performances'),(10628,'scikit-learn','The command uses conda by default for creating the benchmark environments. If\nyou want to use virtualenv instead, use the -E flag:','create benchmark environments',1,'https://scikit-learn.org/dev/developers/contributing.html','monitoring-performances'),(10629,'scikit-learn','The command uses conda by default for creating the benchmark environments. If\nyou want to use virtualenv instead, use the -E flag:','use virtualenv',1,'https://scikit-learn.org/dev/developers/contributing.html','monitoring-performances'),(10630,'scikit-learn','The command uses conda by default for creating the benchmark environments. If\nyou want to use virtualenv instead, use the -E flag:','use e flag',1,'https://scikit-learn.org/dev/developers/contributing.html','monitoring-performances'),(10631,'scikit-learn','You can also specify a whole module to benchmark:','specify whole module to benchmark',1,'https://scikit-learn.org/dev/developers/contributing.html','monitoring-performances'),(10632,'scikit-learn','You can replace HEAD by any local branch. By default it will only report the\nbenchmarks that have change by at least 10%. You can control this ratio with\nthe -f flag.','replace HEAD by local branch',0,'',''),(10633,'scikit-learn','To run the full benchmark suite, simply remove the -b flag :','run full benchmark suite',1,'https://scikit-learn.org/dev/developers/contributing.html','monitoring-performances'),(10634,'scikit-learn','To run the full benchmark suite, simply remove the -b flag :','remove b flag',1,'https://scikit-learn.org/dev/developers/contributing.html','monitoring-performances'),(10635,'scikit-learn','To run the benchmarks without comparing to another branch, use the run\ncommand:','run benchmarks without comparing',1,'https://scikit-learn.org/dev/developers/contributing.html','monitoring-performances'),(10636,'scikit-learn','To run the benchmarks without comparing to another branch, use the run\ncommand:','use run command',1,'https://scikit-learn.org/dev/developers/contributing.html','monitoring-performances'),(10637,'scikit-learn','To run the benchmarks without comparing to another branch, use the run\ncommand:','use branch',1,'https://scikit-learn.org/dev/developers/contributing.html','monitoring-performances'),(10638,'scikit-learn','To run the benchmarks without comparing to another branch, use the run\ncommand:','compare  to branch',1,'https://scikit-learn.org/dev/developers/contributing.html','monitoring-performances'),(10639,'scikit-learn','You can also run the benchmark suite using the version of scikit-learn already\ninstalled in your current Python environment:','run benchmark suite',1,'https://scikit-learn.org/dev/developers/contributing.html','monitoring-performances'),(10640,'scikit-learn','You can also run the benchmark suite using the version of scikit-learn already\ninstalled in your current Python environment:','use version of scikit-learn',1,'https://scikit-learn.org/dev/developers/contributing.html','monitoring-performances'),(10641,'scikit-learn','You can also run the benchmark suite using the version of scikit-learn already\ninstalled in your current Python environment:','install  in current Python environment',1,'https://scikit-learn.org/dev/developers/contributing.html','monitoring-performances'),(10642,'scikit-learn','It’s particularly useful when you installed scikit-learn in editable mode to\navoid creating a new environment each time you run the benchmarks. By default\nthe results are not saved when using an existing installation. To save the\nresults you must specify a commit hash:','install scikit-learn in editable mode',1,'https://scikit-learn.org/dev/developers/contributing.html','monitoring-performances'),(10643,'scikit-learn','It’s particularly useful when you installed scikit-learn in editable mode to\navoid creating a new environment each time you run the benchmarks. By default\nthe results are not saved when using an existing installation. To save the\nresults you must specify a commit hash:','create new environment',1,'https://scikit-learn.org/dev/developers/contributing.html','monitoring-performances'),(10644,'scikit-learn','It’s particularly useful when you installed scikit-learn in editable mode to\navoid creating a new environment each time you run the benchmarks. By default\nthe results are not saved when using an existing installation. To save the\nresults you must specify a commit hash:','run benchmarks',1,'https://scikit-learn.org/dev/developers/contributing.html','monitoring-performances'),(10645,'scikit-learn','It’s particularly useful when you installed scikit-learn in editable mode to\navoid creating a new environment each time you run the benchmarks. By default\nthe results are not saved when using an existing installation. To save the\nresults you must specify a commit hash:','use existing installation',1,'https://scikit-learn.org/dev/developers/contributing.html','monitoring-performances'),(10646,'scikit-learn','It’s particularly useful when you installed scikit-learn in editable mode to\navoid creating a new environment each time you run the benchmarks. By default\nthe results are not saved when using an existing installation. To save the\nresults you must specify a commit hash:','save results',1,'https://scikit-learn.org/dev/developers/contributing.html','monitoring-performances'),(10647,'scikit-learn','It’s particularly useful when you installed scikit-learn in editable mode to\navoid creating a new environment each time you run the benchmarks. By default\nthe results are not saved when using an existing installation. To save the\nresults you must specify a commit hash:','specify commit hash',1,'https://scikit-learn.org/dev/developers/contributing.html','monitoring-performances'),(10648,'scikit-learn','Benchmarks are saved and organized by machine, environment and commit. To see\nthe list of all saved benchmarks:','save benchmarks',1,'https://scikit-learn.org/dev/developers/contributing.html','monitoring-performances'),(10649,'scikit-learn','Benchmarks are saved and organized by machine, environment and commit. To see\nthe list of all saved benchmarks:','save benchmarks',1,'https://scikit-learn.org/dev/developers/contributing.html','monitoring-performances'),(10650,'scikit-learn','When running benchmarks for a pull request you’re working on please report the\nresults on github.','run benchmarks for pull request',0,'',''),(10651,'scikit-learn','The benchmark suite supports additional configurable options which can be set\nin the benchmarks/config.json configuration file. For example, the benchmarks\ncan run for a provided list of values for the n_jobs parameter.','support additional configurable options',0,'',''),(10652,'scikit-learn','The benchmark suite supports additional configurable options which can be set\nin the benchmarks/config.json configuration file. For example, the benchmarks\ncan run for a provided list of values for the n_jobs parameter.','set additional configurable options in benchmarks/config.json configuration file',0,'',''),(10653,'scikit-learn','The benchmark suite supports additional configurable options which can be set\nin the benchmarks/config.json configuration file. For example, the benchmarks\ncan run for a provided list of values for the n_jobs parameter.','run  for provided list',0,'',''),(10654,'scikit-learn','More information on how to write a benchmark and how to use asv can be found in\nthe asv documentation.','write benchmark',0,'',''),(10655,'scikit-learn','More information on how to write a benchmark and how to use asv can be found in\nthe asv documentation.','use asv',0,'',''),(10656,'scikit-learn','More information on how to write a benchmark and how to use asv can be found in\nthe asv documentation.','find more information in asv documentation',0,'',''),(10657,'scikit-learn','Feature requests and pull requests implementing a new feature.','implement new feature',0,'',''),(10658,'scikit-learn','This issue is ideal for a first contribution to scikit-learn. Ask for help\nif the formulation is unclear. If you have already contributed to\nscikit-learn, look at Easy issues instead.','ask  for help',0,'',''),(10659,'scikit-learn','This tag marks an issue which currently lacks a contributor or a\nPR that needs another contributor to take over the work. These\nissues can range in difficulty, and may not be approachable\nfor new contributors. Note that not all issues which need\ncontributors will have this tag.','mark issue',0,'',''),(10660,'scikit-learn','If any publicly accessible method, function, attribute or parameter\nis renamed, we still support the old one for two releases and issue\na deprecation warning when it is called/passed/accessed.\nE.g., if the function zero_one is renamed to zero_one_loss,\nwe add the decorator deprecated (from sklearn.utils)\nto zero_one and call zero_one_loss from that function:','support old one for releases',1,'https://scikit-learn.org/dev/developers/contributing.html','contributing-deprecation'),(10661,'scikit-learn','If any publicly accessible method, function, attribute or parameter\nis renamed, we still support the old one for two releases and issue\na deprecation warning when it is called/passed/accessed.\nE.g., if the function zero_one is renamed to zero_one_loss,\nwe add the decorator deprecated (from sklearn.utils)\nto zero_one and call zero_one_loss from that function:','rename accessible method',1,'https://scikit-learn.org/dev/developers/contributing.html','contributing-deprecation'),(10662,'scikit-learn','If any publicly accessible method, function, attribute or parameter\nis renamed, we still support the old one for two releases and issue\na deprecation warning when it is called/passed/accessed.\nE.g., if the function zero_one is renamed to zero_one_loss,\nwe add the decorator deprecated (from sklearn.utils)\nto zero_one and call zero_one_loss from that function:','rename function zero_one to zero_one_loss',1,'https://scikit-learn.org/dev/developers/contributing.html','contributing-deprecation'),(10663,'scikit-learn','If an attribute is to be deprecated,\nuse the decorator deprecated on a property. Please note that the\nproperty decorator should be placed before the deprecated\ndecorator for the docstrings to be rendered properly.\nE.g., renaming an attribute labels_ to classes_ can be done as:','use decorator',1,'https://scikit-learn.org/dev/developers/contributing.html','contributing-deprecation'),(10664,'scikit-learn','If an attribute is to be deprecated,\nuse the decorator deprecated on a property. Please note that the\nproperty decorator should be placed before the deprecated\ndecorator for the docstrings to be rendered properly.\nE.g., renaming an attribute labels_ to classes_ can be done as:','place property decorator before deprecated decorator',1,'https://scikit-learn.org/dev/developers/contributing.html','contributing-deprecation'),(10665,'scikit-learn','If a parameter has to be deprecated, a FutureWarning warning\nmust be raised too.\nIn the following example, k is deprecated and renamed to n_clusters:','raise FutureWarning warning',1,'https://scikit-learn.org/dev/developers/contributing.html','contributing-deprecation'),(10666,'scikit-learn','If a parameter has to be deprecated, a FutureWarning warning\nmust be raised too.\nIn the following example, k is deprecated and renamed to n_clusters:','rename k',1,'https://scikit-learn.org/dev/developers/contributing.html','contributing-deprecation'),(10667,'scikit-learn','As in these examples, the warning message should always give both the\nversion in which the deprecation happened and the version in which the\nold behavior will be removed. If the deprecation happened in version\n0.x-dev, the message should say deprecation occurred in version 0.x and\nthe removal will be in 0.(x+2), so that users will have enough time to\nadapt their code to the new behaviour. For example, if the deprecation happened\nin version 0.18-dev, the message should say it happened in version 0.18\nand the old behavior will be removed in version 0.20.','remove old behavior',0,'',''),(10668,'scikit-learn','As in these examples, the warning message should always give both the\nversion in which the deprecation happened and the version in which the\nold behavior will be removed. If the deprecation happened in version\n0.x-dev, the message should say deprecation occurred in version 0.x and\nthe removal will be in 0.(x+2), so that users will have enough time to\nadapt their code to the new behaviour. For example, if the deprecation happened\nin version 0.18-dev, the message should say it happened in version 0.18\nand the old behavior will be removed in version 0.20.','remove version',0,'',''),(10669,'scikit-learn','As in these examples, the warning message should always give both the\nversion in which the deprecation happened and the version in which the\nold behavior will be removed. If the deprecation happened in version\n0.x-dev, the message should say deprecation occurred in version 0.x and\nthe removal will be in 0.(x+2), so that users will have enough time to\nadapt their code to the new behaviour. For example, if the deprecation happened\nin version 0.18-dev, the message should say it happened in version 0.18\nand the old behavior will be removed in version 0.20.','remove old behavior in version',0,'',''),(10670,'scikit-learn','In addition, a deprecation note should be added in the docstring, recalling the\nsame information as the deprecation warning as explained above. Use the\n.. deprecated:: directive:','add deprecation note in docstring',1,'https://scikit-learn.org/dev/developers/contributing.html','contributing-deprecation'),(10671,'scikit-learn','What’s more, a deprecation requires a test which ensures that the warning is\nraised in relevant cases but not in other cases. The warning should be caught\nin all other tests (using e.g., @pytest.mark.filterwarnings),\nand there should be no warning in the examples.','raise warning in relevant cases',0,'',''),(10672,'scikit-learn','What’s more, a deprecation requires a test which ensures that the warning is\nraised in relevant cases but not in other cases. The warning should be caught\nin all other tests (using e.g., @pytest.mark.filterwarnings),\nand there should be no warning in the examples.','raise warning in other cases',0,'',''),(10673,'scikit-learn','What’s more, a deprecation requires a test which ensures that the warning is\nraised in relevant cases but not in other cases. The warning should be caught\nin all other tests (using e.g., @pytest.mark.filterwarnings),\nand there should be no warning in the examples.','catch warning in other tests',0,'',''),(10674,'scikit-learn','If the default value of a parameter needs to be changed, please replace the\ndefault value with a specific value (e.g., warn) and raise\nFutureWarning when users are using the default value. The following\nexample assumes that the current version is 0.20 and that we change the\ndefault value of n_clusters from 5 (old default for 0.20) to 10\n(new default for 0.22):','replace default value with specific value',1,'https://scikit-learn.org/dev/developers/contributing.html',''),(10675,'scikit-learn','If the default value of a parameter needs to be changed, please replace the\ndefault value with a specific value (e.g., warn) and raise\nFutureWarning when users are using the default value. The following\nexample assumes that the current version is 0.20 and that we change the\ndefault value of n_clusters from 5 (old default for 0.20) to 10\n(new default for 0.22):','raise FutureWarning',1,'https://scikit-learn.org/dev/developers/contributing.html',''),(10676,'scikit-learn','If the default value of a parameter needs to be changed, please replace the\ndefault value with a specific value (e.g., warn) and raise\nFutureWarning when users are using the default value. The following\nexample assumes that the current version is 0.20 and that we change the\ndefault value of n_clusters from 5 (old default for 0.20) to 10\n(new default for 0.22):','use default value',1,'https://scikit-learn.org/dev/developers/contributing.html',''),(10677,'scikit-learn','If the default value of a parameter needs to be changed, please replace the\ndefault value with a specific value (e.g., warn) and raise\nFutureWarning when users are using the default value. The following\nexample assumes that the current version is 0.20 and that we change the\ndefault value of n_clusters from 5 (old default for 0.20) to 10\n(new default for 0.22):','change default value of n_clusters',1,'https://scikit-learn.org/dev/developers/contributing.html',''),(10678,'scikit-learn','Similar to deprecations, the warning message should always give both the\nversion in which the change happened and the version in which the old behavior\nwill be removed.','remove old behavior',0,'',''),(10679,'scikit-learn','Similar to deprecations, the warning message should always give both the\nversion in which the change happened and the version in which the old behavior\nwill be removed.','remove version',0,'',''),(10680,'scikit-learn','The parameter description in the docstring needs to be updated accordingly by adding\na versionchanged directive with the old and new default value, pointing to the\nversion when the change will be effective:','add versionchanged directive with old new default value',1,'https://scikit-learn.org/dev/developers/contributing.html',''),(10681,'scikit-learn','Finally, we need a test which ensures that the warning is raised in relevant cases but\nnot in other cases. The warning should be caught in all other tests\n(using e.g., @pytest.mark.filterwarnings), and there should be no warning\nin the examples.','raise warning in relevant cases',0,'',''),(10682,'scikit-learn','Finally, we need a test which ensures that the warning is raised in relevant cases but\nnot in other cases. The warning should be caught in all other tests\n(using e.g., @pytest.mark.filterwarnings), and there should be no warning\nin the examples.','raise warning in other cases',0,'',''),(10683,'scikit-learn','Finally, we need a test which ensures that the warning is raised in relevant cases but\nnot in other cases. The warning should be caught in all other tests\n(using e.g., @pytest.mark.filterwarnings), and there should be no warning\nin the examples.','catch warning in other tests',0,'',''),(10684,'scikit-learn','Reviewing code contributed to the project as PRs is a crucial component of\nscikit-learn development. We encourage anyone to start reviewing code of other\ndevelopers. The code review process is often highly educational for everybody\ninvolved. This is particularly appropriate if it is a feature you would like to\nuse, and so can respond critically about whether the PR meets your needs. While\neach pull request needs to be signed off by two core developers, you can speed\nup this process by providing your feedback.','provide feedback',0,'',''),(10685,'scikit-learn','The difference between an objective improvement and a subjective nit isn’t\nalways clear. Reviewers should recall that code review is primarily about\nreducing risk in the project. When reviewing code, one should aim at\npreventing situations which may require a bug fix, a deprecation, or a\nretraction. Regarding docs: typos, grammar issues and disambiguations are\nbetter addressed immediately.','prevent situations',0,'',''),(10686,'scikit-learn','Is any new functionality described in the user-guide and illustrated with examples?','describe  in user-guide',0,'',''),(10687,'scikit-learn','Is every public function/class tested? Are a reasonable set of\nparameters, their values, value types, and combinations tested? Do\nthe tests validate that the code is correct, i.e. doing what the\ndocumentation says it does? If the change is a bug-fix, is a\nnon-regression test included? Look at this\nto get started with testing in Python.','test public function/class',0,'',''),(10688,'scikit-learn','Is every public function/class tested? Are a reasonable set of\nparameters, their values, value types, and combinations tested? Do\nthe tests validate that the code is correct, i.e. doing what the\ndocumentation says it does? If the change is a bug-fix, is a\nnon-regression test included? Look at this\nto get started with testing in Python.','include non-regression test',0,'',''),(10689,'scikit-learn','Is every public function/class tested? Are a reasonable set of\nparameters, their values, value types, and combinations tested? Do\nthe tests validate that the code is correct, i.e. doing what the\ndocumentation says it does? If the change is a bug-fix, is a\nnon-regression test included? Look at this\nto get started with testing in Python.','test  in Python',0,'',''),(10690,'scikit-learn','Is the code easy to read and low on redundancy? Should variable names be\nimproved for clarity or consistency? Should comments be added? Should comments\nbe removed as unhelpful or extraneous?','add comments',0,'',''),(10691,'scikit-learn','Is the code easy to read and low on redundancy? Should variable names be\nimproved for clarity or consistency? Should comments be added? Should comments\nbe removed as unhelpful or extraneous?','remove comments',0,'',''),(10692,'scikit-learn','Could the code easily be rewritten to run much more efficiently for\nrelevant settings?','run  for relevant settings',0,'',''),(10693,'scikit-learn','Will the new code add any dependencies on other libraries? (this is\nunlikely to be accepted)','add dependencies on other libraries',0,'',''),(10694,'scikit-learn','Standard replies for reviewing includes some frequent comments that reviewers may make.','include frequent comments',0,'',''),(10695,'scikit-learn','Reviewing open pull requests (PRs) helps move the project forward. It is a\ngreat way to get familiar with the codebase and should motivate the\ncontributor to keep involved in the project. [1]','move project',0,'',''),(10696,'scikit-learn','Begin if possible with the large issues, so the author knows they’ve been\nunderstood. Resist the temptation to immediately go line by line, or to open\nwith small pervasive issues.','open  with small pervasive issues',0,'',''),(10697,'scikit-learn','prefix them as “Nit” so that the contributor knows it’s OK not to address;','prefix  as nit',0,'',''),(10698,'scikit-learn','Reading and digesting an existing code base is always a difficult exercise\nthat takes time and experience to main. Even though we try to write simple\ncode in general, understanding the code can seem overwhelming at first,\ngiven the sheer size of the project. Here is a list of tips that may help\nmake this task easier and faster (in no particular order).','read existing code base',0,'',''),(10699,'scikit-learn','Reading and digesting an existing code base is always a difficult exercise\nthat takes time and experience to main. Even though we try to write simple\ncode in general, understanding the code can seem overwhelming at first,\ngiven the sheer size of the project. Here is a list of tips that may help\nmake this task easier and faster (in no particular order).','write simple code in general',0,'',''),(10700,'scikit-learn','The trickiest thing is often to identify which portions of the code are\nrelevant, and which are not. In scikit-learn a lot of input checking\nis performed, especially at the beginning of the fit methods.\nSometimes, only a very small portion of the code is doing the actual job.\nFor example looking at the fit() method of\nLinearRegression, what you’re looking for\nmight just be the call the scipy.linalg.lstsq, but it is buried into\nmultiple lines of input checking and the handling of different kinds of\nparameters.','perform lot at beginning',0,'',''),(10701,'scikit-learn','The trickiest thing is often to identify which portions of the code are\nrelevant, and which are not. In scikit-learn a lot of input checking\nis performed, especially at the beginning of the fit methods.\nSometimes, only a very small portion of the code is doing the actual job.\nFor example looking at the fit() method of\nLinearRegression, what you’re looking for\nmight just be the call the scipy.linalg.lstsq, but it is buried into\nmultiple lines of input checking and the handling of different kinds of\nparameters.','perform lot in scikit-learn',0,'',''),(10702,'scikit-learn','The trickiest thing is often to identify which portions of the code are\nrelevant, and which are not. In scikit-learn a lot of input checking\nis performed, especially at the beginning of the fit methods.\nSometimes, only a very small portion of the code is doing the actual job.\nFor example looking at the fit() method of\nLinearRegression, what you’re looking for\nmight just be the call the scipy.linalg.lstsq, but it is buried into\nmultiple lines of input checking and the handling of different kinds of\nparameters.','perform lot of input checking',0,'',''),(10703,'scikit-learn','Due to the use of Inheritance,\nsome methods may be implemented in parent classes. All estimators inherit\nat least from BaseEstimator, and\nfrom a Mixin class (e.g. ClassifierMixin) that enables default\nbehaviour depending on the nature of the estimator (classifier, regressor,\ntransformer, etc.).','implement methods due_to use',0,'',''),(10704,'scikit-learn','Due to the use of Inheritance,\nsome methods may be implemented in parent classes. All estimators inherit\nat least from BaseEstimator, and\nfrom a Mixin class (e.g. ClassifierMixin) that enables default\nbehaviour depending on the nature of the estimator (classifier, regressor,\ntransformer, etc.).','implement methods in parent classes',0,'',''),(10705,'scikit-learn','Due to the use of Inheritance,\nsome methods may be implemented in parent classes. All estimators inherit\nat least from BaseEstimator, and\nfrom a Mixin class (e.g. ClassifierMixin) that enables default\nbehaviour depending on the nature of the estimator (classifier, regressor,\ntransformer, etc.).','enable default behaviour',0,'',''),(10706,'scikit-learn','Due to the use of Inheritance,\nsome methods may be implemented in parent classes. All estimators inherit\nat least from BaseEstimator, and\nfrom a Mixin class (e.g. ClassifierMixin) that enables default\nbehaviour depending on the nature of the estimator (classifier, regressor,\ntransformer, etc.).','enable mixin class',0,'',''),(10707,'scikit-learn','Due to the use of Inheritance,\nsome methods may be implemented in parent classes. All estimators inherit\nat least from BaseEstimator, and\nfrom a Mixin class (e.g. ClassifierMixin) that enables default\nbehaviour depending on the nature of the estimator (classifier, regressor,\ntransformer, etc.).','inherit  from BaseEstimator',0,'',''),(10708,'scikit-learn','Due to the use of Inheritance,\nsome methods may be implemented in parent classes. All estimators inherit\nat least from BaseEstimator, and\nfrom a Mixin class (e.g. ClassifierMixin) that enables default\nbehaviour depending on the nature of the estimator (classifier, regressor,\ntransformer, etc.).','inherit  from mixin class',0,'',''),(10709,'scikit-learn','Sometimes, reading the tests for a given function will give you an idea of\nwhat its intended purpose is. You can use git grep (see below) to find\nall the tests written for a function. Most tests for a specific\nfunction/class are placed under the tests/ folder of the module','read tests for given function',0,'',''),(10710,'scikit-learn','Sometimes, reading the tests for a given function will give you an idea of\nwhat its intended purpose is. You can use git grep (see below) to find\nall the tests written for a function. Most tests for a specific\nfunction/class are placed under the tests/ folder of the module','use git grep',0,'',''),(10711,'scikit-learn','Sometimes, reading the tests for a given function will give you an idea of\nwhat its intended purpose is. You can use git grep (see below) to find\nall the tests written for a function. Most tests for a specific\nfunction/class are placed under the tests/ folder of the module','find tests',0,'',''),(10712,'scikit-learn','Sometimes, reading the tests for a given function will give you an idea of\nwhat its intended purpose is. You can use git grep (see below) to find\nall the tests written for a function. Most tests for a specific\nfunction/class are placed under the tests/ folder of the module','write  for function',0,'',''),(10713,'scikit-learn','Sometimes, reading the tests for a given function will give you an idea of\nwhat its intended purpose is. You can use git grep (see below) to find\nall the tests written for a function. Most tests for a specific\nfunction/class are placed under the tests/ folder of the module','test  for specific function/class are placed under the         tests/ folder',0,'',''),(10714,'scikit-learn','You’ll often see code looking like this:\nout = Parallel(...)(delayed(some_function)(param) for param in\nsome_iterable). This runs some_function in parallel using Joblib. out is then an iterable containing\nthe values returned by some_function for each call.','run some_function',0,'',''),(10715,'scikit-learn','You’ll often see code looking like this:\nout = Parallel(...)(delayed(some_function)(param) for param in\nsome_iterable). This runs some_function in parallel using Joblib. out is then an iterable containing\nthe values returned by some_function for each call.','use joblib',0,'',''),(10716,'scikit-learn','We use Cython to write fast code. Cython code is\nlocated in .pyx and .pxd files. Cython code has a more C-like\nflavor: we use pointers, perform manual memory allocation, etc. Having\nsome minimal experience in C / C++ is pretty much mandatory here.','write fast code',0,'',''),(10717,'scikit-learn','We use Cython to write fast code. Cython code is\nlocated in .pyx and .pxd files. Cython code has a more C-like\nflavor: we use pointers, perform manual memory allocation, etc. Having\nsome minimal experience in C / C++ is pretty much mandatory here.','locate cython code',0,'',''),(10718,'scikit-learn','We use Cython to write fast code. Cython code is\nlocated in .pyx and .pxd files. Cython code has a more C-like\nflavor: we use pointers, perform manual memory allocation, etc. Having\nsome minimal experience in C / C++ is pretty much mandatory here.','use pointers',0,'',''),(10719,'scikit-learn','We use Cython to write fast code. Cython code is\nlocated in .pyx and .pxd files. Cython code has a more C-like\nflavor: we use pointers, perform manual memory allocation, etc. Having\nsome minimal experience in C / C++ is pretty much mandatory here.','perform manual memory',0,'',''),(10720,'scikit-learn','With such a big project, being efficient with your favorite editor or\nIDE goes a long way towards digesting the code base. Being able to quickly\njump (or peek) to a function/class/attribute definition helps a lot.\nSo does being able to quickly see where a given name is used in a file.','use given name in file',0,'',''),(10721,'scikit-learn','git also has some built-in killer\nfeatures. It is often useful to understand how a file changed over time,\nusing e.g. git blame (manual). This can also be done directly\non GitHub. git grep (examples) is also extremely\nuseful to see every occurrence of a pattern (e.g. a function call or a\nvariable) in the code base.','change  over time',0,'',''),(10722,'scikit-learn','Configure git blame to ignore the commit that migrated the code style to\nblack.','ignore commit',1,'https://scikit-learn.org/dev/developers/contributing.html',''),(10723,'GraphQL compiler','GraphQL compiler is a library that simplifies data querying and exploration by exposing one\nsimple query language to target multiple database backends. The query language is:','expose simple query language',0,'',''),(10724,'GraphQL compiler','To use GraphQL compiler the first thing one needs to do is to generate the schema info from the\nunderlying database as in the example below. Even though the example targets an OrientDB\ndatabase, it is meant as a generic schema info generation example. See the homepage of your target\ndatabase for more instructions on how to generate the necessary schema info.','use GraphQL compiler',1,'https://graphql-compiler.readthedocs.io/',''),(10725,'GraphQL compiler','To use GraphQL compiler the first thing one needs to do is to generate the schema info from the\nunderlying database as in the example below. Even though the example targets an OrientDB\ndatabase, it is meant as a generic schema info generation example. See the homepage of your target\ndatabase for more instructions on how to generate the necessary schema info.','generate schema info from underlying database',1,'https://graphql-compiler.readthedocs.io/',''),(10726,'GraphQL compiler','To use GraphQL compiler the first thing one needs to do is to generate the schema info from the\nunderlying database as in the example below. Even though the example targets an OrientDB\ndatabase, it is meant as a generic schema info generation example. See the homepage of your target\ndatabase for more instructions on how to generate the necessary schema info.','generate necessary schema info',1,'https://graphql-compiler.readthedocs.io/',''),(10727,'GraphQL compiler','Besides representing the database schema, a GraphQL schema includes other metadata such as a list\nof custom scalar types used by the compiler. We’ll talk more about this metadata in\nschema types. For now let’s focus on how a database\nschema might be represented in a GraphQL schema:','include other metadata besides representing',1,'https://graphql-compiler.readthedocs.io/',''),(10728,'GraphQL compiler','Besides representing the database schema, a GraphQL schema includes other metadata such as a list\nof custom scalar types used by the compiler. We’ll talk more about this metadata in\nschema types. For now let’s focus on how a database\nschema might be represented in a GraphQL schema:','include other metadata such_as list',1,'https://graphql-compiler.readthedocs.io/',''),(10729,'GraphQL compiler','Once we have the schema info we can write the following query to get the names of all the animals\nthat live in Africa:','write following query',1,'https://graphql-compiler.readthedocs.io/',''),(10730,'GraphQL compiler','Once we have the schema info we can write the following query to get the names of all the animals\nthat live in Africa:','get names of animals',1,'https://graphql-compiler.readthedocs.io/',''),(10731,'GraphQL compiler','Finally, with the GraphQL query and its parameters at hand, we can use the compiler to obtain a\nquery that we can directly execute against OrientDB.','use compiler with GraphQL query',1,'https://graphql-compiler.readthedocs.io/',''),(10732,'GraphQL compiler','Finally, with the GraphQL query and its parameters at hand, we can use the compiler to obtain a\nquery that we can directly execute against OrientDB.','use compiler with parameters',1,'https://graphql-compiler.readthedocs.io/',''),(10733,'GraphQL compiler','Finally, with the GraphQL query and its parameters at hand, we can use the compiler to obtain a\nquery that we can directly execute against OrientDB.','obtain query',1,'https://graphql-compiler.readthedocs.io/',''),(10734,'GraphQL compiler','Finally, with the GraphQL query and its parameters at hand, we can use the compiler to obtain a\nquery that we can directly execute against OrientDB.','execute  against OrientDB',1,'https://graphql-compiler.readthedocs.io/',''),(10735,'GraphQL compiler','Refer to this section to learn how the compiler integrates with the target database. The database\nhome pages include an end-to-end example, instruction for schema info generation, and any\nlimitations or intricacies related to working with said database. We currently support two\ntypes of database backends:','integrate  with target database',0,'',''),(10736,'GraphQL compiler','Refer to this section to learn how the compiler integrates with the target database. The database\nhome pages include an end-to-end example, instruction for schema info generation, and any\nlimitations or intricacies related to working with said database. We currently support two\ntypes of database backends:','include limitations for schema info generation',0,'',''),(10737,'GraphQL compiler','Refer to this section to learn how the compiler integrates with the target database. The database\nhome pages include an end-to-end example, instruction for schema info generation, and any\nlimitations or intricacies related to working with said database. We currently support two\ntypes of database backends:','include intricacies for schema info generation',0,'',''),(10738,'GraphQL compiler','Refer to this section to learn how the compiler integrates with the target database. The database\nhome pages include an end-to-end example, instruction for schema info generation, and any\nlimitations or intricacies related to working with said database. We currently support two\ntypes of database backends:','include end-to-end example for schema info generation',0,'',''),(10739,'GraphQL compiler','Refer to this section to learn how the compiler integrates with the target database. The database\nhome pages include an end-to-end example, instruction for schema info generation, and any\nlimitations or intricacies related to working with said database. We currently support two\ntypes of database backends:','include instruction for schema info generation',0,'',''),(10740,'GraphQL compiler','Refer to this section to learn how the compiler integrates with the target database. The database\nhome pages include an end-to-end example, instruction for schema info generation, and any\nlimitations or intricacies related to working with said database. We currently support two\ntypes of database backends:','support types of database backends',0,'',''),(10741,'GraphQL compiler','To learn more about the advanced features in the GraphQL compiler see:','learn  in GraphQL',0,'',''),(10742,'GraphQL compiler','To learn more about the GraphQL compiler project see:','learn  about GraphQL',0,'',''),(10743,'Flask','Fix the default value for app.env to be \"production\". This\nattribute remains deprecated. #4740','fix default value for app.env',0,'',''),(10744,'Flask','Setting or accessing json_encoder or json_decoder raises a\ndeprecation warning. #4732','set json_encoder',0,'',''),(10745,'Flask','Setting or accessing json_encoder or json_decoder raises a\ndeprecation warning. #4732','set json_decoder',0,'',''),(10746,'Flask','Setting or accessing json_encoder or json_decoder raises a\ndeprecation warning. #4732','access json_encoder',0,'',''),(10747,'Flask','Setting or accessing json_encoder or json_decoder raises a\ndeprecation warning. #4732','access json_decoder',0,'',''),(10748,'Flask','Setting or accessing json_encoder or json_decoder raises a\ndeprecation warning. #4732','raise deprecation warning',0,'',''),(10749,'Flask','Remove previously deprecated code. #4667','remove deprecated code',0,'',''),(10750,'Flask','Old names for some send_file parameters have been removed.\ndownload_name replaces attachment_filename, max_age\nreplaces cache_timeout, and etag replaces add_etags.\nAdditionally, path replaces filename in\nsend_from_directory.','remove old names for send_file parameters',0,'',''),(10751,'Flask','Old names for some send_file parameters have been removed.\ndownload_name replaces attachment_filename, max_age\nreplaces cache_timeout, and etag replaces add_etags.\nAdditionally, path replaces filename in\nsend_from_directory.','replace attachment_filename',0,'',''),(10752,'Flask','Old names for some send_file parameters have been removed.\ndownload_name replaces attachment_filename, max_age\nreplaces cache_timeout, and etag replaces add_etags.\nAdditionally, path replaces filename in\nsend_from_directory.','replace cache_timeout',0,'',''),(10753,'Flask','Old names for some send_file parameters have been removed.\ndownload_name replaces attachment_filename, max_age\nreplaces cache_timeout, and etag replaces add_etags.\nAdditionally, path replaces filename in\nsend_from_directory.','replace add_etags',0,'',''),(10754,'Flask','Old names for some send_file parameters have been removed.\ndownload_name replaces attachment_filename, max_age\nreplaces cache_timeout, and etag replaces add_etags.\nAdditionally, path replaces filename in\nsend_from_directory.','replace filename in send_from_directory',0,'',''),(10755,'Flask','The RequestContext.g property returning AppContext.g is\nremoved.','return AppContext',0,'',''),(10756,'Flask','The RequestContext.g property returning AppContext.g is\nremoved.','remove g',0,'',''),(10757,'Flask','The app and request contexts are managed using Python context vars\ndirectly rather than Werkzeug’s LocalStack. This should result\nin better performance and memory use. #4682','use LocalStack',0,'',''),(10758,'Flask','The app and request contexts are managed using Python context vars\ndirectly rather than Werkzeug’s LocalStack. This should result\nin better performance and memory use. #4682','use Python context vars',0,'',''),(10759,'Flask','The app and request contexts are managed using Python context vars\ndirectly rather than Werkzeug’s LocalStack. This should result\nin better performance and memory use. #4682','manage app request contexts',0,'',''),(10760,'Flask','Extension maintainers, be aware that _app_ctx_stack.top\nand _request_ctx_stack.top are deprecated. Store data on\ng instead using a unique prefix, like\ng._extension_name_attr.','use unique prefix',0,'',''),(10761,'Flask','The FLASK_ENV environment variable and app.env attribute are\ndeprecated, removing the distinction between development and debug\nmode. Debug mode should be controlled directly using the --debug\noption or app.run(debug=True). #4714','remove distinction between development',0,'',''),(10762,'Flask','Some attributes that proxied config keys on app are deprecated:\nsession_cookie_name, send_file_max_age_default,\nuse_x_sendfile, propagate_exceptions, and\ntemplates_auto_reload. Use the relevant config keys instead.\n#4716','use relevant config keys',0,'',''),(10763,'Flask','Add new customization points to the Flask app object for many\npreviously global behaviors.','add new customization points to flask app object',0,'',''),(10764,'Flask','flask.url_for will call app.url_for. #4568','call app.url_for',0,'',''),(10765,'Flask','flask.abort will call app.aborter.\nFlask.aborter_class and Flask.make_aborter can be used\nto customize this aborter. #4567','call app.aborter',0,'',''),(10766,'Flask','flask.abort will call app.aborter.\nFlask.aborter_class and Flask.make_aborter can be used\nto customize this aborter. #4567','customize aborter',0,'',''),(10767,'Flask','flask.abort will call app.aborter.\nFlask.aborter_class and Flask.make_aborter can be used\nto customize this aborter. #4567','use Flask.aborter_class',0,'',''),(10768,'Flask','flask.abort will call app.aborter.\nFlask.aborter_class and Flask.make_aborter can be used\nto customize this aborter. #4567','use Flask.make_aborter',0,'',''),(10769,'Flask','flask.redirect will call app.redirect. #4569','call app.redirect',0,'',''),(10770,'Flask','flask.json is an instance of JSONProvider. A different\nprovider can be set to use a different JSON library.\nflask.jsonify will call app.json.response, other\nfunctions in flask.json will call corresponding functions in\napp.json. #4692','use different JSON library',0,'',''),(10771,'Flask','flask.json is an instance of JSONProvider. A different\nprovider can be set to use a different JSON library.\nflask.jsonify will call app.json.response, other\nfunctions in flask.json will call corresponding functions in\napp.json. #4692','set different provider',0,'',''),(10772,'Flask','flask.json is an instance of JSONProvider. A different\nprovider can be set to use a different JSON library.\nflask.jsonify will call app.json.response, other\nfunctions in flask.json will call corresponding functions in\napp.json. #4692','call app.json.response',0,'',''),(10773,'Flask','flask.json is an instance of JSONProvider. A different\nprovider can be set to use a different JSON library.\nflask.jsonify will call app.json.response, other\nfunctions in flask.json will call corresponding functions in\napp.json. #4692','call corresponding functions in app.json',0,'',''),(10774,'Flask','JSON configuration is moved to attributes on the default\napp.json provider. JSON_AS_ASCII, JSON_SORT_KEYS,\nJSONIFY_MIMETYPE, and JSONIFY_PRETTYPRINT_REGULAR are\ndeprecated. #4692','move JSON configuration to attributes',0,'',''),(10775,'Flask','Setting custom json_encoder and json_decoder classes on the\napp or a blueprint, and the corresponding json.JSONEncoder and\nJSONDecoder classes, are deprecated. JSON behavior can now be\noverridden using the app.json provider interface. #4692','set custom',0,'',''),(10776,'Flask','Setting custom json_encoder and json_decoder classes on the\napp or a blueprint, and the corresponding json.JSONEncoder and\nJSONDecoder classes, are deprecated. JSON behavior can now be\noverridden using the app.json provider interface. #4692','use app.json provider interface',0,'',''),(10777,'Flask','Setting custom json_encoder and json_decoder classes on the\napp or a blueprint, and the corresponding json.JSONEncoder and\nJSONDecoder classes, are deprecated. JSON behavior can now be\noverridden using the app.json provider interface. #4692','override JSON behavior',0,'',''),(10778,'Flask','Refactor register_error_handler to consolidate error checking.\nRewrite some error messages to be more consistent. #4559','refactor register_error_handler',0,'',''),(10779,'Flask','Use Blueprint decorators and functions intended for setup after\nregistering the blueprint will show a warning. In the next version,\nthis will become an error just like the application setup methods.\n#4571','show warning',0,'',''),(10780,'Flask','before_first_request is deprecated. Run setup code when creating\nthe application instead. #4605','create application',0,'',''),(10781,'Flask','Added the View.init_every_request class attribute. If a view\nsubclass sets this to False, the view will not create a new\ninstance on every request. #2520.','set  to false',0,'',''),(10782,'Flask','Add --app and --debug options to the flask CLI, instead\nof requiring that they are set through environment variables.\n#2836','add app',0,'',''),(10783,'Flask','Add --app and --debug options to the flask CLI, instead\nof requiring that they are set through environment variables.\n#2836','set  through environment variables',0,'',''),(10784,'Flask','Add --env-file option to the flask CLI. This allows\nspecifying a dotenv file to load in addition to .env and\n.flaskenv. #3108','specify dotenv file',0,'',''),(10785,'Flask','SessionInterface.get_expiration_time uses a timezone-aware\nvalue. #4645','use timezone-aware value',0,'',''),(10786,'Flask','View functions can return generators directly instead of wrapping\nthem in a Response. #4629','return generators instead_of wrapping',0,'',''),(10787,'Flask','View functions can return generators directly instead of wrapping\nthem in a Response. #4629','wrap  in response',0,'',''),(10788,'Flask','Add stream_template and stream_template_string functions to\nrender a template as a stream of pieces. #4629','render template as stream',0,'',''),(10789,'Flask','Teardown functions are always run at the end of the request,\neven if the context is preserved. They are also run after the\npreserved context is popped.','run teardown functions at end',0,'',''),(10790,'Flask','stream_with_context preserves context separately from a\nwith client block. It will be cleaned up when\nresponse.get_data() or response.close() is called.','call response.get_data()',0,'',''),(10791,'Flask','stream_with_context preserves context separately from a\nwith client block. It will be cleaned up when\nresponse.get_data() or response.close() is called.','call response.close()',0,'',''),(10792,'Flask','Allow returning a list from a view function, to convert it to a\nJSON response like a dict is. #4672','return list from view function',0,'',''),(10793,'Flask','Allow returning a list from a view function, to convert it to a\nJSON response like a dict is. #4672','convert  to JSON response',0,'',''),(10794,'Flask','When type checking, allow TypedDict to be returned from view\nfunctions. #4695','return  from view functions',0,'',''),(10795,'Flask','Remove the --eager-loading/--lazy-loading options from the\nflask run command. The app is always eager loaded the first\ntime, then lazily loaded in the reloader. The reloader always prints\nerrors immediately but continues serving. Remove the internal\nDispatchingApp middleware used by the previous implementation.\n#4715','remove the lazy-loading options from flask run command',0,'',''),(10796,'Flask','Remove the --eager-loading/--lazy-loading options from the\nflask run command. The app is always eager loaded the first\ntime, then lazily loaded in the reloader. The reloader always prints\nerrors immediately but continues serving. Remove the internal\nDispatchingApp middleware used by the previous implementation.\n#4715','load first time in reloader',0,'',''),(10797,'Flask','Remove the --eager-loading/--lazy-loading options from the\nflask run command. The app is always eager loaded the first\ntime, then lazily loaded in the reloader. The reloader always prints\nerrors immediately but continues serving. Remove the internal\nDispatchingApp middleware used by the previous implementation.\n#4715','print errors',0,'',''),(10798,'Flask','Remove the --eager-loading/--lazy-loading options from the\nflask run command. The app is always eager loaded the first\ntime, then lazily loaded in the reloader. The reloader always prints\nerrors immediately but continues serving. Remove the internal\nDispatchingApp middleware used by the previous implementation.\n#4715','remove internal DispatchingApp middleware',0,'',''),(10799,'Flask','Inline some optional imports that are only used for certain CLI\ncommands. #4606','use optional imports for certain CLI commands',0,'',''),(10800,'Flask','instance_path for namespace packages uses the path closest to\nthe imported submodule. #4610','use path',0,'',''),(10801,'Flask','Clearer error message when render_template and\nrender_template_string are used outside an application context.\n#4693','use render_template outside application context',0,'',''),(10802,'Flask','Clearer error message when render_template and\nrender_template_string are used outside an application context.\n#4693','use render_template_string outside application context',0,'',''),(10803,'Flask','Fix type annotation for json.loads, it accepts str or bytes.\n#4519','fix type annotation for json.loads',0,'',''),(10804,'Flask','Set the minimum required version of importlib_metadata to 3.6.0,\nwhich is required on Python < 3.10. #4502','set minimum required version of importlib_metadata',0,'',''),(10805,'Flask','Set the minimum required version of importlib_metadata to 3.6.0,\nwhich is required on Python < 3.10. #4502','set minimum required version to 3.6.0',0,'',''),(10806,'Flask','Drop support for Python 3.6. #4335','support  for Python',0,'',''),(10807,'Flask','Remove previously deprecated code. #4337','remove deprecated code',0,'',''),(10808,'Flask','config.from_json is replaced by\nconfig.from_file(name, load=json.load).','replace config.from_json',0,'',''),(10809,'Flask','safe_join is removed, use werkzeug.utils.safe_join\ninstead.','use werkzeug.utils.safe_join',0,'',''),(10810,'Flask','safe_join is removed, use werkzeug.utils.safe_join\ninstead.','remove safe_join',0,'',''),(10811,'Flask','total_seconds is removed, use timedelta.total_seconds\ninstead.','use timedelta.total_seconds',0,'',''),(10812,'Flask','total_seconds is removed, use timedelta.total_seconds\ninstead.','remove total_seconds',0,'',''),(10813,'Flask','The same blueprint cannot be registered with the same name. Use\nname= when registering to specify a unique name.','specify unique name',0,'',''),(10814,'Flask','The test client’s as_tuple parameter is removed. Use\nresponse.request.environ instead. #4417','remove as_tuple parameter',0,'',''),(10815,'Flask','The test client’s as_tuple parameter is removed. Use\nresponse.request.environ instead. #4417','use response.request.environ',0,'',''),(10816,'Flask','Some parameters in send_file and send_from_directory were\nrenamed in 2.0. The deprecation period for the old names is extended\nto 2.2. Be sure to test with deprecation warnings visible.','rename parameters in 2.0',0,'',''),(10817,'Flask','Some parameters in send_file and send_from_directory were\nrenamed in 2.0. The deprecation period for the old names is extended\nto 2.2. Be sure to test with deprecation warnings visible.','rename parameters in send_file',0,'',''),(10818,'Flask','Some parameters in send_file and send_from_directory were\nrenamed in 2.0. The deprecation period for the old names is extended\nto 2.2. Be sure to test with deprecation warnings visible.','rename parameters in send_from_directory',0,'',''),(10819,'Flask','Some parameters in send_file and send_from_directory were\nrenamed in 2.0. The deprecation period for the old names is extended\nto 2.2. Be sure to test with deprecation warnings visible.','extend deprecation period for old names',0,'',''),(10820,'Flask','Some parameters in send_file and send_from_directory were\nrenamed in 2.0. The deprecation period for the old names is extended\nto 2.2. Be sure to test with deprecation warnings visible.','test  with deprecation warnings',0,'',''),(10821,'Flask','attachment_filename is renamed to download_name.','rename attachment_filename to download_name',0,'',''),(10822,'Flask','cache_timeout is renamed to max_age.','rename cache_timeout to max_age',0,'',''),(10823,'Flask','add_etags is renamed to etag.','rename add_etags to etag',0,'',''),(10824,'Flask','filename is renamed to path.','rename filename to path',0,'',''),(10825,'Flask','The RequestContext.g property is deprecated. Use g directly\nor AppContext.g instead. #3898','use g',0,'',''),(10826,'Flask','The RequestContext.g property is deprecated. Use g directly\nor AppContext.g instead. #3898','use AppContext',0,'',''),(10827,'Flask','The CLI uses importlib.metadata instead of setuptools to\nload command entry points. #4419','load command entry points',0,'',''),(10828,'Flask','Add an --exclude-patterns option to the flask run CLI\ncommand to specify patterns that will be ignored by the reloader.\n#4188','add exclude-patterns option to flask',0,'',''),(10829,'Flask','Add an --exclude-patterns option to the flask run CLI\ncommand to specify patterns that will be ignored by the reloader.\n#4188','run CLI command',0,'',''),(10830,'Flask','Add an --exclude-patterns option to the flask run CLI\ncommand to specify patterns that will be ignored by the reloader.\n#4188','specify patterns',0,'',''),(10831,'Flask','Add an --exclude-patterns option to the flask run CLI\ncommand to specify patterns that will be ignored by the reloader.\n#4188','ignore patterns',0,'',''),(10832,'Flask','When using lazy loading (the default with the debugger), the Click\ncontext from the flask run command remains available in the\nloader thread. #4460','use lazy loading',0,'',''),(10833,'Flask','Deleting the session cookie uses the httponly flag.\n#4485','delete session cookie',0,'',''),(10834,'Flask','Deleting the session cookie uses the httponly flag.\n#4485','use httponly flag',0,'',''),(10835,'Flask','Relax typing for errorhandler to allow the user to use more\nprecise types and decorate the same function multiple times.\n#4095, #4295, #4297','use more precise types',0,'',''),(10836,'Flask','From Werkzeug, for redirect responses the Location header URL\nwill remain relative, and exclude the scheme and domain, by default.\n#4496','exclude scheme',0,'',''),(10837,'Flask','From Werkzeug, for redirect responses the Location header URL\nwill remain relative, and exclude the scheme and domain, by default.\n#4496','exclude domain',0,'',''),(10838,'Flask','Add Config.from_prefixed_env() to load config values from\nenvironment variables that start with FLASK_ or another prefix.\nThis parses values as JSON by default, and allows setting keys in\nnested dicts. #4479','add Config.from_prefixed_env()',0,'',''),(10839,'Flask','Add Config.from_prefixed_env() to load config values from\nenvironment variables that start with FLASK_ or another prefix.\nThis parses values as JSON by default, and allows setting keys in\nnested dicts. #4479','load config values from environment variables',0,'',''),(10840,'Flask','Add Config.from_prefixed_env() to load config values from\nenvironment variables that start with FLASK_ or another prefix.\nThis parses values as JSON by default, and allows setting keys in\nnested dicts. #4479','set keys in nested dicts',0,'',''),(10841,'Flask','The test client’s as_tuple parameter is deprecated and will be\nremoved in Werkzeug 2.1. It is now also deprecated in Flask, to be\nremoved in Flask 2.1, while remaining compatible with both in\n2.0.x. Use response.request.environ instead. #4341','remove as_tuple parameter in Werkzeug',0,'',''),(10842,'Flask','The test client’s as_tuple parameter is deprecated and will be\nremoved in Werkzeug 2.1. It is now also deprecated in Flask, to be\nremoved in Flask 2.1, while remaining compatible with both in\n2.0.x. Use response.request.environ instead. #4341','remove  in Flask',0,'',''),(10843,'Flask','The test client’s as_tuple parameter is deprecated and will be\nremoved in Werkzeug 2.1. It is now also deprecated in Flask, to be\nremoved in Flask 2.1, while remaining compatible with both in\n2.0.x. Use response.request.environ instead. #4341','remove  while remaining',0,'','');
INSERT INTO `overview_task` VALUES (10844,'Flask','The test client’s as_tuple parameter is deprecated and will be\nremoved in Werkzeug 2.1. It is now also deprecated in Flask, to be\nremoved in Flask 2.1, while remaining compatible with both in\n2.0.x. Use response.request.environ instead. #4341','use response.request.environ',0,'',''),(10845,'Flask','Fix type annotation for errorhandler decorator. #4295','fix type annotation for errorhandler decorator',0,'',''),(10846,'Flask','Revert a change to the CLI that caused it to hide ImportError\ntracebacks when importing the application. #4307','hide ImportError tracebacks',0,'',''),(10847,'Flask','Revert a change to the CLI that caused it to hide ImportError\ntracebacks when importing the application. #4307','import application',0,'',''),(10848,'Flask','app.json_encoder and json_decoder are only passed to\ndumps and loads if they have custom behavior. This improves\nperformance, mainly on PyPy. #4349','pass app.json_encoder to dumps',0,'',''),(10849,'Flask','app.json_encoder and json_decoder are only passed to\ndumps and loads if they have custom behavior. This improves\nperformance, mainly on PyPy. #4349','pass app.json_encoder to loads',0,'',''),(10850,'Flask','app.json_encoder and json_decoder are only passed to\ndumps and loads if they have custom behavior. This improves\nperformance, mainly on PyPy. #4349','pass json_decoder to dumps',0,'',''),(10851,'Flask','app.json_encoder and json_decoder are only passed to\ndumps and loads if they have custom behavior. This improves\nperformance, mainly on PyPy. #4349','pass json_decoder to loads',0,'',''),(10852,'Flask','Clearer error message when after_this_request is used outside a\nrequest context. #4333','use after_this_request outside request context',0,'',''),(10853,'Flask','Fix type annotation for teardown_* methods. #4093','fix type annotation for teardown _ * methods',0,'',''),(10854,'Flask','Fix type annotation for before_request and before_app_request\ndecorators. #4104','fix type annotation for before_request before_app_request decorators',0,'',''),(10855,'Flask','Fixed the issue where typing requires template global\ndecorators to accept functions with no arguments. #4098','fix issue',0,'',''),(10856,'Flask','Fix the type of static_folder to accept pathlib.Path.\n#4150','fix type of static_folder',0,'',''),(10857,'Flask','jsonify handles decimal.Decimal by encoding to str.\n#4157','handle decimal.Decimal by encoding',0,'',''),(10858,'Flask','jsonify handles decimal.Decimal by encoding to str.\n#4157','encode  to str',0,'',''),(10859,'Flask','Correctly handle raising deferred errors in CLI lazy loading.\n#4096','raise deferred errors in CLI lazy loading',0,'',''),(10860,'Flask','The CLI loader handles **kwargs in a create_app function.\n#4170','handle ** kwargs in create_app function',0,'',''),(10861,'Flask','Fix the order of before_request and other callbacks that trigger\nbefore the view returns. They are called from the app down to the\nclosest nested blueprint. #4229','trigger  before view returns',0,'',''),(10862,'Flask','Fix the order of before_request and other callbacks that trigger\nbefore the view returns. They are called from the app down to the\nclosest nested blueprint. #4229','call  from app',0,'',''),(10863,'Flask','Re-add the filename parameter in send_from_directory. The\nfilename parameter has been renamed to path, the old name\nis deprecated. #4019','rename filename parameter to path',0,'',''),(10864,'Flask','Fix type annotation for g and inform mypy that it is a namespace\nobject that has arbitrary attributes. #4020','fix type annotation for g',0,'',''),(10865,'Flask','Fix some types that weren’t available in Python 3.6.0. #4040','fix types',0,'',''),(10866,'Flask','Show an error when a blueprint name contains a dot. The . has\nspecial meaning, it is used to separate (nested) blueprint names and\nthe endpoint name. #4041','show error',0,'',''),(10867,'Flask','Show an error when a blueprint name contains a dot. The . has\nspecial meaning, it is used to separate (nested) blueprint names and\nthe endpoint name. #4041','use  to separate blueprint names',0,'',''),(10868,'Flask','Show an error when a blueprint name contains a dot. The . has\nspecial meaning, it is used to separate (nested) blueprint names and\nthe endpoint name. #4041','use  to endpoint name',0,'',''),(10869,'Flask','Combine URL prefixes when nesting blueprints that were created with\na url_prefix value. #4037','combine URL prefixes',0,'',''),(10870,'Flask','Combine URL prefixes when nesting blueprints that were created with\na url_prefix value. #4037','create  with url_prefix value',0,'',''),(10871,'Flask','Revert a change to the order that URL matching was done. The\nURL is again matched after the session is loaded, so the session is\navailable in custom URL converters. #4053','match URL',0,'',''),(10872,'Flask','Revert a change to the order that URL matching was done. The\nURL is again matched after the session is loaded, so the session is\navailable in custom URL converters. #4053','load session',0,'',''),(10873,'Flask','Re-add deprecated Config.from_json, which was accidentally\nremoved early. #4078','remove Config.from_json',0,'',''),(10874,'Flask','register_blueprint takes a name option to change the\n(pre-dotted) name the blueprint is registered with. This allows the\nsame blueprint to be registered multiple times with unique names for\nurl_for. Registering the same blueprint with the same name\nmultiple times is deprecated. #1091','change name',0,'',''),(10875,'Flask','Drop support for Python 2 and 3.5.','support  for Python',0,'',''),(10876,'Flask','Bump minimum versions of other Pallets projects: Werkzeug >= 2,\nJinja2 >= 3, MarkupSafe >= 2, ItsDangerous >= 2, Click >= 8. Be sure\nto check the change logs for each project. For better compatibility\nwith other applications (e.g. Celery) that still require Click 7,\nthere is no hard dependency on Click 8 yet, but using Click 7 will\ntrigger a DeprecationWarning and Flask 2.1 will depend on Click 8.','check change',0,'',''),(10877,'Flask','Bump minimum versions of other Pallets projects: Werkzeug >= 2,\nJinja2 >= 3, MarkupSafe >= 2, ItsDangerous >= 2, Click >= 8. Be sure\nto check the change logs for each project. For better compatibility\nwith other applications (e.g. Celery) that still require Click 7,\nthere is no hard dependency on Click 8 yet, but using Click 7 will\ntrigger a DeprecationWarning and Flask 2.1 will depend on Click 8.','log  for project',0,'',''),(10878,'Flask','Bump minimum versions of other Pallets projects: Werkzeug >= 2,\nJinja2 >= 3, MarkupSafe >= 2, ItsDangerous >= 2, Click >= 8. Be sure\nto check the change logs for each project. For better compatibility\nwith other applications (e.g. Celery) that still require Click 7,\nthere is no hard dependency on Click 8 yet, but using Click 7 will\ntrigger a DeprecationWarning and Flask 2.1 will depend on Click 8.','trigger Flask',0,'',''),(10879,'Flask','Bump minimum versions of other Pallets projects: Werkzeug >= 2,\nJinja2 >= 3, MarkupSafe >= 2, ItsDangerous >= 2, Click >= 8. Be sure\nto check the change logs for each project. For better compatibility\nwith other applications (e.g. Celery) that still require Click 7,\nthere is no hard dependency on Click 8 yet, but using Click 7 will\ntrigger a DeprecationWarning and Flask 2.1 will depend on Click 8.','trigger DeprecationWarning',0,'',''),(10880,'Flask','JSON support no longer uses simplejson. To use another JSON module,\noverride app.json_encoder and json_decoder. #3555','use simplejson',0,'',''),(10881,'Flask','JSON support no longer uses simplejson. To use another JSON module,\noverride app.json_encoder and json_decoder. #3555','use JSON module',0,'',''),(10882,'Flask','JSON support no longer uses simplejson. To use another JSON module,\noverride app.json_encoder and json_decoder. #3555','use override app.json_encoder',0,'',''),(10883,'Flask','JSON support no longer uses simplejson. To use another JSON module,\noverride app.json_encoder and json_decoder. #3555','use json_decoder',0,'',''),(10884,'Flask','Passing script_info to app factory functions is deprecated. This\nwas not portable outside the flask command. Use\nclick.get_current_context().obj if it’s needed. #3552','use click.get_current_context().obj',0,'',''),(10885,'Flask','The CLI shows better error messages when the app failed to load\nwhen looking up commands. #2741','show better error messages',0,'',''),(10886,'Flask','Add SessionInterface.get_cookie_name to allow setting the\nsession cookie name dynamically. #3369','add SessionInterface.get_cookie_name',0,'',''),(10887,'Flask','Add SessionInterface.get_cookie_name to allow setting the\nsession cookie name dynamically. #3369','set session cookie name',0,'',''),(10888,'Flask','Add Config.from_file to load config using arbitrary file\nloaders, such as toml.load or json.load.\nConfig.from_json is deprecated in favor of this. #3398','add Config.from_file',0,'',''),(10889,'Flask','Add Config.from_file to load config using arbitrary file\nloaders, such as toml.load or json.load.\nConfig.from_json is deprecated in favor of this. #3398','use arbitrary file loaders such_as toml.load',0,'',''),(10890,'Flask','Add Config.from_file to load config using arbitrary file\nloaders, such as toml.load or json.load.\nConfig.from_json is deprecated in favor of this. #3398','use arbitrary file loaders such_as json.load',0,'',''),(10891,'Flask','The flask run command will only defer errors on reload. Errors\npresent during the initial call will cause the server to exit with\nthe traceback immediately. #3431','defer errors on reload',0,'',''),(10892,'Flask','send_file raises a ValueError when passed an io object\nin text mode. Previously, it would respond with 200 OK and an empty\nfile. #3358','raise ValueError',0,'',''),(10893,'Flask','When using ad-hoc certificates, check for the cryptography library\ninstead of PyOpenSSL. #3492','use ad-hoc certificates',0,'',''),(10894,'Flask','When using ad-hoc certificates, check for the cryptography library\ninstead of PyOpenSSL. #3492','check  for cryptography library',0,'',''),(10895,'Flask','When specifying a factory function with FLASK_APP, keyword\nargument can be passed. #3553','specify factory function with FLASK_APP',0,'',''),(10896,'Flask','When specifying a factory function with FLASK_APP, keyword\nargument can be passed. #3553','pass keyword argument',0,'',''),(10897,'Flask','When loading a .env or .flaskenv file, the current working\ndirectory is no longer changed to the location of the file.\n#3560','change current working directory to location',0,'',''),(10898,'Flask','When returning a (response, headers) tuple from a view, the\nheaders replace rather than extend existing headers on the response.\nFor example, this allows setting the Content-Type for\njsonify(). Use response.headers.extend() if extending is\ndesired. #3628','return tuple from view',0,'',''),(10899,'Flask','When returning a (response, headers) tuple from a view, the\nheaders replace rather than extend existing headers on the response.\nFor example, this allows setting the Content-Type for\njsonify(). Use response.headers.extend() if extending is\ndesired. #3628','set content-type for jsonify()',0,'',''),(10900,'Flask','When returning a (response, headers) tuple from a view, the\nheaders replace rather than extend existing headers on the response.\nFor example, this allows setting the Content-Type for\njsonify(). Use response.headers.extend() if extending is\ndesired. #3628','use response.headers.extend()',0,'',''),(10901,'Flask','The Scaffold class provides a common API for the Flask and\nBlueprint classes. Blueprint information is stored in\nattributes just like Flask, rather than opaque lambda functions.\nThis is intended to improve consistency and maintainability.\n#3215','provide common API for flask blueprint classes',0,'',''),(10902,'Flask','The Scaffold class provides a common API for the Flask and\nBlueprint classes. Blueprint information is stored in\nattributes just like Flask, rather than opaque lambda functions.\nThis is intended to improve consistency and maintainability.\n#3215','store blueprint information in attributes',0,'',''),(10903,'Flask','The Scaffold class provides a common API for the Flask and\nBlueprint classes. Blueprint information is stored in\nattributes just like Flask, rather than opaque lambda functions.\nThis is intended to improve consistency and maintainability.\n#3215','store blueprint information in opaque lambda functions',0,'',''),(10904,'Flask','Include samesite and secure options when removing the\nsession cookie. #3726','include samesite secure options',0,'',''),(10905,'Flask','Include samesite and secure options when removing the\nsession cookie. #3726','remove session cookie',0,'',''),(10906,'Flask','Support passing a pathlib.Path to static_folder. #3579','pass pathlib.Path to static_folder',0,'',''),(10907,'Flask','Some send_file parameters have been renamed, the old names are\ndeprecated. attachment_filename is renamed to download_name.\ncache_timeout is renamed to max_age. add_etags is\nrenamed to etag. #3828, #3883','rename send_file parameters',0,'',''),(10908,'Flask','Some send_file parameters have been renamed, the old names are\ndeprecated. attachment_filename is renamed to download_name.\ncache_timeout is renamed to max_age. add_etags is\nrenamed to etag. #3828, #3883','rename attachment_filename to download_name',0,'',''),(10909,'Flask','Some send_file parameters have been renamed, the old names are\ndeprecated. attachment_filename is renamed to download_name.\ncache_timeout is renamed to max_age. add_etags is\nrenamed to etag. #3828, #3883','rename cache_timeout to max_age',0,'',''),(10910,'Flask','Some send_file parameters have been renamed, the old names are\ndeprecated. attachment_filename is renamed to download_name.\ncache_timeout is renamed to max_age. add_etags is\nrenamed to etag. #3828, #3883','rename add_etags to etag',0,'',''),(10911,'Flask','send_file passes download_name even if\nas_attachment=False by using Content-Disposition: inline.\n#3828','pass download_name',0,'',''),(10912,'Flask','send_file passes download_name even if\nas_attachment=False by using Content-Disposition: inline.\n#3828','use content-disposition',0,'',''),(10913,'Flask','send_file sets conditional=True and max_age=None by\ndefault. Cache-Control is set to no-cache if max_age is\nnot set, otherwise public. This tells browsers to validate\nconditional requests instead of using a timed cache. #3828','set cache-control',0,'',''),(10914,'Flask','send_file sets conditional=True and max_age=None by\ndefault. Cache-Control is set to no-cache if max_age is\nnot set, otherwise public. This tells browsers to validate\nconditional requests instead of using a timed cache. #3828','use timed cache',0,'',''),(10915,'Flask','helpers.safe_join is deprecated. Use\nwerkzeug.utils.safe_join instead. #3828','use werkzeug.utils.safe_join',0,'',''),(10916,'Flask','The request context does route matching before opening the session.\nThis could allow a session interface to change behavior based on\nrequest.endpoint. #3776','open session',0,'',''),(10917,'Flask','The request context does route matching before opening the session.\nThis could allow a session interface to change behavior based on\nrequest.endpoint. #3776','change behavior',0,'',''),(10918,'Flask','Use Jinja’s implementation of the |tojson filter. #3881','use implementation of | tojson filter',0,'',''),(10919,'Flask','Add route decorators for common HTTP methods. For example,\n@app.post(\"/login\") is a shortcut for\n@app.route(\"/login\", methods=[\"POST\"]). #3907','add route decorators for common HTTP methods',0,'',''),(10920,'Flask','Set the default encoding to “UTF-8” when loading .env and\n.flaskenv files to allow to use non-ASCII characters. #3931','use non-ASCII characters',0,'',''),(10921,'Flask','flask shell sets up tab and history completion like the default\npython shell if readline is installed. #3941','set up tab history completion like default python shell',0,'',''),(10922,'Flask','flask shell sets up tab and history completion like the default\npython shell if readline is installed. #3941','install readline',0,'',''),(10923,'Flask','helpers.total_seconds() is deprecated. Use\ntimedelta.total_seconds() instead. #3962','use timedelta.total_seconds()',0,'',''),(10924,'Flask','Add type hinting. #3973.','add type hinting',0,'',''),(10925,'Flask','Update static_folder to use _compat.fspath instead of\nos.fspath to continue supporting Python < 3.6 #4050','use _compat.fspath instead_of os.fspath',0,'',''),(10926,'Flask','Set maximum versions of Werkzeug, Jinja, Click, and ItsDangerous.\n#4043','set maximum versions of werkzeug click',0,'',''),(10927,'Flask','Set maximum versions of Werkzeug, Jinja, Click, and ItsDangerous.\n#4043','set maximum versions of ItsDangerous',0,'',''),(10928,'Flask','Re-add support for passing a pathlib.Path for static_folder.\n#3579','pass pathlib.Path for static_folder',0,'',''),(10929,'Flask','Work around an issue when running the flask command with an\nexternal debugger on Windows. #3297','run flask command with external debugger',0,'',''),(10930,'Flask','The flask.json_available flag was added back for compatibility\nwith some extensions. It will raise a deprecation warning when used,\nand will be removed in version 2.0.0. #3288','raise deprecation warning',0,'',''),(10931,'Flask','The flask.json_available flag was added back for compatibility\nwith some extensions. It will raise a deprecation warning when used,\nand will be removed in version 2.0.0. #3288','remove  in version 2.0.0',0,'',''),(10932,'Flask','Drop support for Python 3.4.','support  for Python',0,'',''),(10933,'Flask','Error handlers for InternalServerError or 500 will always be\npassed an instance of InternalServerError. If they are invoked\ndue to an unhandled exception, that original exception is now\navailable as e.original_exception rather than being passed\ndirectly to the handler. The same is true if the handler is for the\nbase HTTPException. This makes error handler behavior more\nconsistent. #3266','pass instance of InternalServerError',0,'',''),(10934,'Flask','Error handlers for InternalServerError or 500 will always be\npassed an instance of InternalServerError. If they are invoked\ndue to an unhandled exception, that original exception is now\navailable as e.original_exception rather than being passed\ndirectly to the handler. The same is true if the handler is for the\nbase HTTPException. This makes error handler behavior more\nconsistent. #3266','pass instance for InternalServerError',0,'',''),(10935,'Flask','Error handlers for InternalServerError or 500 will always be\npassed an instance of InternalServerError. If they are invoked\ndue to an unhandled exception, that original exception is now\navailable as e.original_exception rather than being passed\ndirectly to the handler. The same is true if the handler is for the\nbase HTTPException. This makes error handler behavior more\nconsistent. #3266','pass error handlers of InternalServerError',0,'',''),(10936,'Flask','Error handlers for InternalServerError or 500 will always be\npassed an instance of InternalServerError. If they are invoked\ndue to an unhandled exception, that original exception is now\navailable as e.original_exception rather than being passed\ndirectly to the handler. The same is true if the handler is for the\nbase HTTPException. This makes error handler behavior more\nconsistent. #3266','pass error handlers for InternalServerError',0,'',''),(10937,'Flask','Error handlers for InternalServerError or 500 will always be\npassed an instance of InternalServerError. If they are invoked\ndue to an unhandled exception, that original exception is now\navailable as e.original_exception rather than being passed\ndirectly to the handler. The same is true if the handler is for the\nbase HTTPException. This makes error handler behavior more\nconsistent. #3266','pass original exception to handler',0,'',''),(10938,'Flask','Flask.finalize_request is called for all unhandled\nexceptions even if there is no 500 error handler.','call Flask.finalize_request for unhandled exceptions',0,'',''),(10939,'Flask','Flask.logger takes the same name as Flask.name (the value\npassed as Flask(import_name). This reverts 1.0’s behavior of\nalways logging to \"flask.app\", in order to support multiple apps\nin the same process. A warning will be shown if old configuration is\ndetected that needs to be moved. #2866','pass  as Flask(import_name)',0,'',''),(10940,'Flask','Flask.logger takes the same name as Flask.name (the value\npassed as Flask(import_name). This reverts 1.0’s behavior of\nalways logging to \"flask.app\", in order to support multiple apps\nin the same process. A warning will be shown if old configuration is\ndetected that needs to be moved. #2866','support multiple apps in same process',0,'',''),(10941,'Flask','Flask.logger takes the same name as Flask.name (the value\npassed as Flask(import_name). This reverts 1.0’s behavior of\nalways logging to \"flask.app\", in order to support multiple apps\nin the same process. A warning will be shown if old configuration is\ndetected that needs to be moved. #2866','show warning',0,'',''),(10942,'Flask','RequestContext.copy includes the current session object in the\nrequest context copy. This prevents session pointing to an\nout-of-date object. #2935','include current session object in request context copy',0,'',''),(10943,'Flask','RequestContext.copy includes the current session object in the\nrequest context copy. This prevents session pointing to an\nout-of-date object. #2935','prevent session',0,'',''),(10944,'Flask','Using built-in RequestContext, unprintable Unicode characters in\nHost header will result in a HTTP 400 response and not HTTP 500 as\npreviously. #2994','use built-in RequestContext',0,'',''),(10945,'Flask','send_file supports PathLike objects as described in\nPEP 519, to support pathlib in Python 3. #3059','support PathLike objects',0,'',''),(10946,'Flask','send_file supports PathLike objects as described in\nPEP 519, to support pathlib in Python 3. #3059','support pathlib in Python',0,'',''),(10947,'Flask','send_file supports PathLike objects as described in\nPEP 519, to support pathlib in Python 3. #3059','describe  in PEP 519',0,'',''),(10948,'Flask','send_file supports BytesIO partial content.\n#2957','support BytesIO partial content',0,'',''),(10949,'Flask','The MethodView.methods attribute set in a base class is used by\nsubclasses. #3138','set  in base class',0,'',''),(10950,'Flask','The MethodView.methods attribute set in a base class is used by\nsubclasses. #3138','use MethodView.methods attribute',0,'',''),(10951,'Flask','Flask.jinja_options is a dict instead of an\nImmutableDict to allow easier configuration. Changes must still\nbe made before creating the environment. #3190','create environment',0,'',''),(10952,'Flask','Flask’s JSONMixin for the request and response wrappers was\nmoved into Werkzeug. Use Werkzeug’s version with Flask-specific\nsupport. This bumps the Werkzeug dependency to >= 0.15.\n#3125','move JSONMixin into werkzeug',0,'',''),(10953,'Flask','Flask’s JSONMixin for the request and response wrappers was\nmoved into Werkzeug. Use Werkzeug’s version with Flask-specific\nsupport. This bumps the Werkzeug dependency to >= 0.15.\n#3125','move JSONMixin for request response wrappers',0,'',''),(10954,'Flask','Support empty static_folder without requiring setting an empty\nstatic_url_path as well. #3124','set empty static_url_path',0,'',''),(10955,'Flask','Allow customizing the Flask.url_map_class used for routing.\n#3069','customize Flask.url_map_class',0,'',''),(10956,'Flask','Allow customizing the Flask.url_map_class used for routing.\n#3069','use  for routing',0,'',''),(10957,'Flask','The development server port can be set to 0, which tells the OS to\npick an available port. #2926','set development server port',0,'',''),(10958,'Flask','The return value from cli.load_dotenv is more consistent with\nthe documentation. It will return False if python-dotenv is not\ninstalled, or if the given path isn’t a file. #2937','return false',0,'',''),(10959,'Flask','Add an --extra-files option to the flask run CLI command to\nspecify extra files that will trigger the reloader on change.\n#2897','add extra-files option to flask',0,'',''),(10960,'Flask','Add an --extra-files option to the flask run CLI command to\nspecify extra files that will trigger the reloader on change.\n#2897','run CLI command',0,'',''),(10961,'Flask','Add an --extra-files option to the flask run CLI command to\nspecify extra files that will trigger the reloader on change.\n#2897','specify extra files',0,'',''),(10962,'Flask','Add an --extra-files option to the flask run CLI command to\nspecify extra files that will trigger the reloader on change.\n#2897','trigger reloader on change',0,'',''),(10963,'Flask','Add an --extra-files option to the flask run CLI command to\nspecify extra files that will trigger the reloader on change.\n#2897','trigger extra files on change',0,'',''),(10964,'Flask','Allow returning a dictionary from a view function. Similar to how\nreturning a string will produce a text/html response, returning\na dict will call jsonify to produce a application/json\nresponse. #3111','return dictionary from view function',0,'',''),(10965,'Flask','Allow returning a dictionary from a view function. Similar to how\nreturning a string will produce a text/html response, returning\na dict will call jsonify to produce a application/json\nresponse. #3111','return string',0,'',''),(10966,'Flask','When using the test client as a context manager (with client:),\nall preserved request contexts are popped when the block exits,\nensuring nested contexts are cleaned up correctly. #3157','use test client as context manager',0,'',''),(10967,'Flask','Show a better error message when the view return type is not\nsupported. #3214','show better error message',0,'',''),(10968,'Flask','The flask run command no longer fails if Python is not built\nwith SSL support. Using the --cert option will show an\nappropriate error message. #3211','use cert option',0,'',''),(10969,'Flask','The flask run command no longer fails if Python is not built\nwith SSL support. Using the --cert option will show an\nappropriate error message. #3211','show appropriate error message',0,'',''),(10970,'Flask','URL matching now occurs after the request context is pushed, rather\nthan when it’s created. This allows custom URL converters to access\nthe app and request contexts, such as to query a database for an id.\n#3088','push request context',0,'',''),(10971,'Flask','URL matching now occurs after the request context is pushed, rather\nthan when it’s created. This allows custom URL converters to access\nthe app and request contexts, such as to query a database for an id.\n#3088','access app request contexts',0,'',''),(10972,'Flask','Allow custom CLIs using FlaskGroup to set the debug flag without\nit always being overwritten based on environment variables.\n#2765','use FlaskGroup',0,'',''),(10973,'Flask','Allow custom CLIs using FlaskGroup to set the debug flag without\nit always being overwritten based on environment variables.\n#2765','set debug flag',0,'',''),(10974,'Flask','flask --version outputs Werkzeug’s version and simplifies the\nPython version. #2825','output version',0,'',''),(10975,'Flask','send_file handles an attachment_filename that is a native\nPython 2 string (bytes) with UTF-8 coded bytes. #2933','handle attachment_filename',0,'',''),(10976,'Flask','A catch-all error handler registered for HTTPException will not\nhandle RoutingException, which is used internally during\nrouting. This fixes the unexpected behavior that had been introduced\nin 1.0. #2986','use RoutingException during routing',0,'',''),(10977,'Flask','A catch-all error handler registered for HTTPException will not\nhandle RoutingException, which is used internally during\nrouting. This fixes the unexpected behavior that had been introduced\nin 1.0. #2986','fix unexpected behavior',0,'',''),(10978,'Flask','A catch-all error handler registered for HTTPException will not\nhandle RoutingException, which is used internally during\nrouting. This fixes the unexpected behavior that had been introduced\nin 1.0. #2986','introduce unexpected behavior',0,'',''),(10979,'Flask','Passing the json argument to app.test_client does not\npush/pop an extra app context. #2900','pass json argument to app.test_client',0,'',''),(10980,'Flask','Fix more backwards compatibility issues with merging slashes between\na blueprint prefix and route. #2748','fix compatibility issues with merging',0,'',''),(10981,'Flask','Don’t treat lists returned from view functions the same as tuples.\nOnly tuples are interpreted as response data. #2736','return  as tuples',0,'',''),(10982,'Flask','Don’t treat lists returned from view functions the same as tuples.\nOnly tuples are interpreted as response data. #2736','return  from view functions',0,'',''),(10983,'Flask','Extra slashes between a blueprint’s url_prefix and a route URL\nare merged. This fixes some backwards compatibility issues with the\nchange in 1.0. #2731, #2742','fix backwards compatibility issues with change',0,'',''),(10984,'Flask','The FLASK_SKIP_DOTENV environment variable can be set to 1\nto skip automatically loading dotenv files. #2722','load dotenv files',0,'',''),(10985,'Flask','The FLASK_SKIP_DOTENV environment variable can be set to 1\nto skip automatically loading dotenv files. #2722','set FLASK_SKIP_DOTENV environment variable',0,'',''),(10986,'Flask','Python 2.6 and 3.3 are no longer supported.','support Python',0,'',''),(10987,'Flask','Skip app.run when a Flask application is run from the command\nline. This avoids some behavior that was confusing to debug.','run Flask application from command line',0,'',''),(10988,'Flask','Change the default for JSONIFY_PRETTYPRINT_REGULAR to\nFalse. ~json.jsonify returns a compact format by default,\nand an indented format in debug mode. #2193','return compact format in debug mode',0,'',''),(10989,'Flask','Change the default for JSONIFY_PRETTYPRINT_REGULAR to\nFalse. ~json.jsonify returns a compact format by default,\nand an indented format in debug mode. #2193','return compact format by default',0,'',''),(10990,'Flask','Change the default for JSONIFY_PRETTYPRINT_REGULAR to\nFalse. ~json.jsonify returns a compact format by default,\nand an indented format in debug mode. #2193','return indented format in debug mode',0,'',''),(10991,'Flask','Change the default for JSONIFY_PRETTYPRINT_REGULAR to\nFalse. ~json.jsonify returns a compact format by default,\nand an indented format in debug mode. #2193','return indented format by default',0,'',''),(10992,'Flask','Flask.__init__ accepts the host_matching argument and sets\nit on Flask.url_map. #1559','set  on Flask.url_map',0,'',''),(10993,'Flask','Flask.__init__ accepts the static_host argument and passes\nit as the host argument when defining the static route.\n#1559','pass  as host argument',0,'',''),(10994,'Flask','Flask.__init__ accepts the static_host argument and passes\nit as the host argument when defining the static route.\n#1559','define static route',0,'',''),(10995,'Flask','send_file supports Unicode in attachment_filename.\n#2223','support Unicode in attachment_filename',0,'',''),(10996,'Flask','Flask.add_url_rule accepts the provide_automatic_options\nargument to disable adding the OPTIONS method. #1489','add OPTIONS method',0,'',''),(10997,'Flask','MethodView subclasses inherit method handlers from base classes.\n#1936','inherit method handlers from base classes',0,'',''),(10998,'Flask','Errors caused while opening the session at the beginning of the\nrequest are handled by the app’s error handlers. #2254','open session at beginning',0,'',''),(10999,'Flask','Blueprints gained Blueprint.json_encoder and\nBlueprint.json_decoder attributes to override the app’s\nencoder and decoder. #1898','override encoder',0,'',''),(11000,'Flask','Blueprints gained Blueprint.json_encoder and\nBlueprint.json_decoder attributes to override the app’s\nencoder and decoder. #1898','override decoder',0,'',''),(11001,'Flask','Flask.make_response raises TypeError instead of\nValueError for bad response types. The error messages have been\nimproved to describe why the type is invalid. #2256','raise TypeError instead_of ValueError',0,'',''),(11002,'Flask','SESSION_COOKIE_DOMAIN is set if it is detected through\nSERVER_NAME. #2282','set SESSION_COOKIE_DOMAIN',0,'',''),(11003,'Flask','Auto-detect zero-argument app factory called create_app or\nmake_app from FLASK_APP. #2297','call create_app from FLASK_APP',0,'',''),(11004,'Flask','Auto-detect zero-argument app factory called create_app or\nmake_app from FLASK_APP. #2297','call make_app from FLASK_APP',0,'',''),(11005,'Flask','Factory functions are not required to take a script_info\nparameter to work with the flask command. If they take a single\nparameter or a parameter named script_info, the ScriptInfo\nobject will be passed. #2319','pass ScriptInfo object',0,'',''),(11006,'Flask','FLASK_APP can be set to an app factory, with arguments if\nneeded, for example FLASK_APP=myproject.app:create_app(\'dev\').\n#2326','set FLASK_APP with arguments',0,'',''),(11007,'Flask','FLASK_APP can be set to an app factory, with arguments if\nneeded, for example FLASK_APP=myproject.app:create_app(\'dev\').\n#2326','set FLASK_APP to app factory',0,'',''),(11008,'Flask','The View class attribute\nView.provide_automatic_options is set in View.as_view, to be\ndetected by Flask.add_url_rule. #2316','set view class attribute View.provide_automatic_options in View.as_view',0,'',''),(11009,'Flask','Cookie is added to the response’s Vary header if the session\nis accessed at all during the request (and not deleted). #2288','add cookie to vary header',0,'',''),(11010,'Flask','Cookie is added to the response’s Vary header if the session\nis accessed at all during the request (and not deleted). #2288','access session during request',0,'',''),(11011,'Flask','Set APPLICATION_ROOT to \'/\' by default. This was already the\nimplicit default when it was set to None.','set APPLICATION_ROOT',0,'',''),(11012,'Flask','Set APPLICATION_ROOT to \'/\' by default. This was already the\nimplicit default when it was set to None.','set  to none',0,'',''),(11013,'Flask','TRAP_BAD_REQUEST_ERRORS is enabled by default in debug mode.\nBadRequestKeyError has a message with the bad key in debug mode\ninstead of the generic bad request message. #2348','enable TRAP_BAD_REQUEST_ERRORS in debug',0,'',''),(11014,'Flask','Allow registering new tags with TaggedJSONSerializer to support\nstoring other types in the session cookie. #2352','store other types in session cookie',0,'',''),(11015,'Flask','Only open the session if the request has not been pushed onto the\ncontext stack yet. This allows stream_with_context generators to\naccess the same session that the containing view uses. #2354','open session',0,'',''),(11016,'Flask','Only open the session if the request has not been pushed onto the\ncontext stack yet. This allows stream_with_context generators to\naccess the same session that the containing view uses. #2354','access same session',0,'',''),(11017,'Flask','Add json keyword argument for the test client request methods.\nThis will dump the given object as JSON and set the appropriate\ncontent type. #2358','add json keyword argument for test client request methods',0,'',''),(11018,'Flask','Add json keyword argument for the test client request methods.\nThis will dump the given object as JSON and set the appropriate\ncontent type. #2358','set appropriate content type',0,'',''),(11019,'Flask','Extract JSON handling to a mixin applied to both the Request and\nResponse classes. This adds the Response.is_json and\nResponse.get_json methods to the response to make testing JSON\nresponse much easier. #2358','handle  to mixin',0,'',''),(11020,'Flask','Extract JSON handling to a mixin applied to both the Request and\nResponse classes. This adds the Response.is_json and\nResponse.get_json methods to the response to make testing JSON\nresponse much easier. #2358','apply  to request',0,'',''),(11021,'Flask','Extract JSON handling to a mixin applied to both the Request and\nResponse classes. This adds the Response.is_json and\nResponse.get_json methods to the response to make testing JSON\nresponse much easier. #2358','apply  to response classes',0,'',''),(11022,'Flask','Extract JSON handling to a mixin applied to both the Request and\nResponse classes. This adds the Response.is_json and\nResponse.get_json methods to the response to make testing JSON\nresponse much easier. #2358','add Response.is_json Response.get_json methods to response',0,'',''),(11023,'Flask','Fix incorrect JSON encoding of aware, non-UTC datetimes. #2374','fix incorrect JSON encoding of non-UTC datetimes',0,'',''),(11024,'Flask','Template auto reloading will honor debug mode even even if\nFlask.jinja_env was already accessed. #2373','access Flask.jinja_env',0,'',''),(11025,'Flask','The following old deprecated code was removed. #2385','remove following old deprecated code',0,'',''),(11026,'Flask','Flask.init_jinja_globals - extend\nFlask.create_jinja_environment instead.','extend Flask.create_jinja_environment',0,'',''),(11027,'Flask','Flask.error_handlers - tracked by\nFlask.error_handler_spec, use Flask.errorhandler\nto register handlers.','track  by Flask.error_handler_spec',0,'',''),(11028,'Flask','Flask.request_globals_class - use\nFlask.app_ctx_globals_class instead.','use Flask.app_ctx_globals_class',0,'',''),(11029,'Flask','Flask.static_path - use Flask.static_url_path instead.','use Flask.static_url_path',0,'',''),(11030,'Flask','Request.module - use Request.blueprint instead.','use Request.blueprint',0,'',''),(11031,'Flask','Support passing a EnvironBuilder or dict to\ntest_client.open. #2412','pass EnvironBuilder to test_client.open',0,'',''),(11032,'Flask','Support passing a EnvironBuilder or dict to\ntest_client.open. #2412','pass dict to test_client.open',0,'',''),(11033,'Flask','The flask command and Flask.run will load environment\nvariables from .env and .flaskenv files if python-dotenv is\ninstalled. #2416','load environment variables',0,'',''),(11034,'Flask','When passing a full URL to the test client, the scheme in the URL is\nused instead of PREFERRED_URL_SCHEME. #2430','pass full URL to test client',0,'',''),(11035,'Flask','When passing a full URL to the test client, the scheme in the URL is\nused instead of PREFERRED_URL_SCHEME. #2430','use scheme instead_of PREFERRED_URL_SCHEME',0,'',''),(11036,'Flask','When passing a full URL to the test client, the scheme in the URL is\nused instead of PREFERRED_URL_SCHEME. #2430','use scheme in URL',0,'',''),(11037,'Flask','Flask.logger has been simplified. LOGGER_NAME and\nLOGGER_HANDLER_POLICY config was removed. The logger is always\nnamed flask.app. The level is only set on first access, it\ndoesn’t check Flask.debug each time. Only one format is used,\nnot different ones depending on Flask.debug. No handlers are\nremoved, and a handler is only added if no handlers are already\nconfigured. #2436','remove LOGGER_NAME LOGGER_HANDLER_POLICY config',0,'',''),(11038,'Flask','Flask.logger has been simplified. LOGGER_NAME and\nLOGGER_HANDLER_POLICY config was removed. The logger is always\nnamed flask.app. The level is only set on first access, it\ndoesn’t check Flask.debug each time. Only one format is used,\nnot different ones depending on Flask.debug. No handlers are\nremoved, and a handler is only added if no handlers are already\nconfigured. #2436','check Flask.debug',0,'',''),(11039,'Flask','Flask.logger has been simplified. LOGGER_NAME and\nLOGGER_HANDLER_POLICY config was removed. The logger is always\nnamed flask.app. The level is only set on first access, it\ndoesn’t check Flask.debug each time. Only one format is used,\nnot different ones depending on Flask.debug. No handlers are\nremoved, and a handler is only added if no handlers are already\nconfigured. #2436','set level on first access',0,'',''),(11040,'Flask','Flask.logger has been simplified. LOGGER_NAME and\nLOGGER_HANDLER_POLICY config was removed. The logger is always\nnamed flask.app. The level is only set on first access, it\ndoesn’t check Flask.debug each time. Only one format is used,\nnot different ones depending on Flask.debug. No handlers are\nremoved, and a handler is only added if no handlers are already\nconfigured. #2436','remove handlers',0,'',''),(11041,'Flask','Flask.logger has been simplified. LOGGER_NAME and\nLOGGER_HANDLER_POLICY config was removed. The logger is always\nnamed flask.app. The level is only set on first access, it\ndoesn’t check Flask.debug each time. Only one format is used,\nnot different ones depending on Flask.debug. No handlers are\nremoved, and a handler is only added if no handlers are already\nconfigured. #2436','add handler',0,'',''),(11042,'Flask','Flask.logger has been simplified. LOGGER_NAME and\nLOGGER_HANDLER_POLICY config was removed. The logger is always\nnamed flask.app. The level is only set on first access, it\ndoesn’t check Flask.debug each time. Only one format is used,\nnot different ones depending on Flask.debug. No handlers are\nremoved, and a handler is only added if no handlers are already\nconfigured. #2436','configure handlers',0,'',''),(11043,'Flask','Fix a ValueError caused by invalid Range requests in some\ncases. #2526','fix ValueError',0,'',''),(11044,'Flask','The development server uses threads by default. #2529','use threads by default',0,'',''),(11045,'Flask','Loading config files with silent=True will ignore ENOTDIR\nerrors. #2581','ignore ENOTDIR errors',0,'',''),(11046,'Flask','Pass --cert and --key options to flask run to run the\ndevelopment server over HTTPS. #2606','run development server over HTTPS',0,'',''),(11047,'Flask','Added Flask.test_cli_runner to create a Click runner that can\ninvoke Flask CLI commands for testing. #2636','add Flask.test_cli_runner',0,'',''),(11048,'Flask','Added Flask.test_cli_runner to create a Click runner that can\ninvoke Flask CLI commands for testing. #2636','create Click runner',0,'',''),(11049,'Flask','Subdomain matching is disabled by default and setting\nSERVER_NAME does not implicitly enable it. It can be enabled by\npassing subdomain_matching=True to the Flask constructor.\n#2635','disable subdomain matching',0,'',''),(11050,'Flask','Subdomain matching is disabled by default and setting\nSERVER_NAME does not implicitly enable it. It can be enabled by\npassing subdomain_matching=True to the Flask constructor.\n#2635','pass subdomain_matching =',0,'',''),(11051,'Flask','Request.get_json doesn’t cache the result if parsing fails when\nsilent is true. #2651','cache result',0,'',''),(11052,'Flask','Request.get_json no longer accepts arbitrary encodings. Incoming\nJSON should be encoded using UTF-8 per RFC 8259, but Flask will\nautodetect UTF-8, -16, or -32. #2691','encode incoming JSON',0,'',''),(11053,'Flask','Added MAX_COOKIE_SIZE and Response.max_cookie_size to\ncontrol when Werkzeug warns about large cookies that browsers may\nignore. #2693','add MAX_COOKIE_SIZE',0,'',''),(11054,'Flask','Added MAX_COOKIE_SIZE and Response.max_cookie_size to\ncontrol when Werkzeug warns about large cookies that browsers may\nignore. #2693','add Response.max_cookie_size',0,'',''),(11055,'Flask','Repackage 0.12.3 to fix package layout issue. #2728','fix package layout issue',0,'',''),(11056,'Flask','Request.get_json no longer accepts arbitrary encodings.\nIncoming JSON should be encoded using UTF-8 per RFC 8259, but\nFlask will autodetect UTF-8, -16, or -32. #2692','encode incoming JSON',0,'',''),(11057,'Flask','Fix a Python warning about imports when using python -m flask.\n#2666','fix Python warning about imports',0,'',''),(11058,'Flask','Fix a Python warning about imports when using python -m flask.\n#2666','use python',0,'',''),(11059,'Flask','Fix a ValueError caused by invalid Range requests in some\ncases.','fix ValueError',0,'',''),(11060,'Flask','Fix a bug in safe_join on Windows.','fix bug in safe_join',0,'',''),(11061,'Flask','Prevent flask run from showing a NoAppException when an\nImportError occurs within the imported application module.','show NoAppException',0,'',''),(11062,'Flask','Prevent flask run from showing a NoAppException when an\nImportError occurs within the imported application module.','run  from showing',0,'',''),(11063,'Flask','Fix encoding behavior of app.config.from_pyfile for Python 3.\n#2118','fix encoding behavior of app.config.from_pyfile',0,'',''),(11064,'Flask','Use the SERVER_NAME config if it is present as default values\nfor app.run. #2109, #2152','use SERVER_NAME',0,'',''),(11065,'Flask','Call ctx.auto_pop with the exception object instead of None,\nin the event that a BaseException such as KeyboardInterrupt\nis raised in a request handler.','raise BaseException in request handler',0,'',''),(11066,'Flask','Call ctx.auto_pop with the exception object instead of None,\nin the event that a BaseException such as KeyboardInterrupt\nis raised in a request handler.','raise BaseException such_as KeyboardInterrupt',0,'',''),(11067,'Flask','Mimetype guessing and ETag generation for file-like objects in\nsend_file has been removed. #104, :pr`1849`','remove mimetype',0,'',''),(11068,'Flask','Revert a behavior change that made the dev server crash instead of\nreturning an Internal Server Error. #2006','return Internal server error',0,'',''),(11069,'Flask','Disable logger propagation by default for the app logger.','disable logger propagation by default',0,'',''),(11070,'Flask','Add support for range requests in send_file.','add support for range requests',0,'',''),(11071,'Flask','app.test_client includes preset default environment, which can\nnow be directly set, instead of per client.get.','include preset default environment',0,'',''),(11072,'Flask','app.test_client includes preset default environment, which can\nnow be directly set, instead of per client.get.','set preset default environment',0,'',''),(11073,'Flask','Fix crash when running under PyPy3. #1814','fix crash',0,'',''),(11074,'Flask','Fix crash when running under PyPy3. #1814','run  under PyPy3',0,'',''),(11075,'Flask','Fixed a bug that prevented FLASK_APP=foobar/__init__.py from\nworking. #1872','fix bug',0,'',''),(11076,'Flask','Fixed a bug that prevented FLASK_APP=foobar/__init__.py from\nworking. #1872','prevent bug from working',0,'',''),(11077,'Flask','Added support to serializing top-level arrays to jsonify. This\nintroduces a security risk in ancient browsers.','introduce security risk in ancient browsers',0,'',''),(11078,'Flask','Added **kwargs to Flask.test_client to support passing\nadditional keyword arguments to the constructor of\nFlask.test_client_class.','add ** kwargs to Flask.test_client',0,'',''),(11079,'Flask','Added **kwargs to Flask.test_client to support passing\nadditional keyword arguments to the constructor of\nFlask.test_client_class.','pass additional keyword arguments to constructor',0,'',''),(11080,'Flask','Added SESSION_REFRESH_EACH_REQUEST config key that controls the\nset-cookie behavior. If set to True a permanent session will be\nrefreshed each request and get their lifetime extended, if set to\nFalse it will only be modified if the session actually modifies.\nNon permanent sessions are not affected by this and will always\nexpire if the browser window closes.','add SESSION_REFRESH_EACH_REQUEST config key',0,'',''),(11081,'Flask','Added SESSION_REFRESH_EACH_REQUEST config key that controls the\nset-cookie behavior. If set to True a permanent session will be\nrefreshed each request and get their lifetime extended, if set to\nFalse it will only be modified if the session actually modifies.\nNon permanent sessions are not affected by this and will always\nexpire if the browser window closes.','get lifetime',0,'',''),(11082,'Flask','Added SESSION_REFRESH_EACH_REQUEST config key that controls the\nset-cookie behavior. If set to True a permanent session will be\nrefreshed each request and get their lifetime extended, if set to\nFalse it will only be modified if the session actually modifies.\nNon permanent sessions are not affected by this and will always\nexpire if the browser window closes.','set  to permanent session',0,'',''),(11083,'Flask','Added SESSION_REFRESH_EACH_REQUEST config key that controls the\nset-cookie behavior. If set to True a permanent session will be\nrefreshed each request and get their lifetime extended, if set to\nFalse it will only be modified if the session actually modifies.\nNon permanent sessions are not affected by this and will always\nexpire if the browser window closes.','set  to false',0,'',''),(11084,'Flask','Added support for returning tuples in the form (response,\nheaders) from a view function.','return tuples in form',0,'',''),(11085,'Flask','Added support for returning tuples in the form (response,\nheaders) from a view function.','support  for returning',0,'',''),(11086,'Flask','Added Config.from_json.','add Config.from_json',0,'',''),(11087,'Flask','Added Flask.config_class.','add Flask.config_class',0,'',''),(11088,'Flask','Added Config.get_namespace.','add Config.get_namespace',0,'',''),(11089,'Flask','Templates are no longer automatically reloaded outside of debug\nmode. This can be configured with the new TEMPLATES_AUTO_RELOAD\nconfig key.','configure  with new TEMPLATES_AUTO_RELOAD config key',0,'',''),(11090,'Flask','Added a workaround for a limitation in Python 3.3’s namespace\nloader.','add workaround for namespace loader',0,'',''),(11091,'Flask','Added support for explicit root paths when using Python 3.3’s\nnamespace packages.','use namespace packages',0,'',''),(11092,'Flask','Added support for explicit root paths when using Python 3.3’s\nnamespace packages.','support  for explicit root paths',0,'',''),(11093,'Flask','Added flask and the flask.cli module to start the\nlocal debug server through the click CLI system. This is recommended\nover the old flask.run() method as it works faster and more\nreliable due to a different design and also replaces\nFlask-Script.','replace flask-script',0,'',''),(11094,'Flask','Error handlers that match specific classes are now checked first,\nthereby allowing catching exceptions that are subclasses of HTTP\nexceptions (in werkzeug.exceptions). This makes it possible for\nan extension author to create exceptions that will by default result\nin the HTTP error of their choosing, but may be caught with a custom\nerror handler if desired.','catch exceptions',0,'',''),(11095,'Flask','Error handlers that match specific classes are now checked first,\nthereby allowing catching exceptions that are subclasses of HTTP\nexceptions (in werkzeug.exceptions). This makes it possible for\nan extension author to create exceptions that will by default result\nin the HTTP error of their choosing, but may be caught with a custom\nerror handler if desired.','match  for error handlers',0,'',''),(11096,'Flask','Error handlers that match specific classes are now checked first,\nthereby allowing catching exceptions that are subclasses of HTTP\nexceptions (in werkzeug.exceptions). This makes it possible for\nan extension author to create exceptions that will by default result\nin the HTTP error of their choosing, but may be caught with a custom\nerror handler if desired.','check specific classes',0,'',''),(11097,'Flask','Error handlers that match specific classes are now checked first,\nthereby allowing catching exceptions that are subclasses of HTTP\nexceptions (in werkzeug.exceptions). This makes it possible for\nan extension author to create exceptions that will by default result\nin the HTTP error of their choosing, but may be caught with a custom\nerror handler if desired.','create exceptions',0,'',''),(11098,'Flask','Error handlers that match specific classes are now checked first,\nthereby allowing catching exceptions that are subclasses of HTTP\nexceptions (in werkzeug.exceptions). This makes it possible for\nan extension author to create exceptions that will by default result\nin the HTTP error of their choosing, but may be caught with a custom\nerror handler if desired.','catch  with custom error handler',0,'',''),(11099,'Flask','Added Config.from_mapping.','add Config.from_mapping',0,'',''),(11100,'Flask','Flask will now log by default even if debug is disabled. The log\nformat is now hardcoded but the default log handling can be disabled\nthrough the LOGGER_HANDLER_POLICY configuration key.','log  by default',0,'',''),(11101,'Flask','Flask will now log by default even if debug is disabled. The log\nformat is now hardcoded but the default log handling can be disabled\nthrough the LOGGER_HANDLER_POLICY configuration key.','disable debug',0,'',''),(11102,'Flask','Flask will now log by default even if debug is disabled. The log\nformat is now hardcoded but the default log handling can be disabled\nthrough the LOGGER_HANDLER_POLICY configuration key.','disable default log handling through LOGGER_HANDLER_POLICY configuration key',0,'',''),(11103,'Flask','Added the EXPLAIN_TEMPLATE_LOADING config flag which when\nenabled will instruct Flask to explain how it locates templates.\nThis should help users debug when the wrong templates are loaded.','add EXPLAIN_TEMPLATE_LOADING config flag',0,'',''),(11104,'Flask','Added the EXPLAIN_TEMPLATE_LOADING config flag which when\nenabled will instruct Flask to explain how it locates templates.\nThis should help users debug when the wrong templates are loaded.','locate templates',0,'',''),(11105,'Flask','Added the EXPLAIN_TEMPLATE_LOADING config flag which when\nenabled will instruct Flask to explain how it locates templates.\nThis should help users debug when the wrong templates are loaded.','load wrong templates',0,'',''),(11106,'Flask','Ported test suite to py.test.','test suite to py.test.',0,'',''),(11107,'Flask','Add “pretty” and “compressed” separators definitions in jsonify()\nmethod. Reduces JSON response size when\nJSONIFY_PRETTYPRINT_REGULAR=False by removing unnecessary white\nspace included by default after separators.','compress separators definitions in jsonify() method',0,'',''),(11108,'Flask','Add “pretty” and “compressed” separators definitions in jsonify()\nmethod. Reduces JSON response size when\nJSONIFY_PRETTYPRINT_REGULAR=False by removing unnecessary white\nspace included by default after separators.','remove unnecessary white space',0,'',''),(11109,'Flask','Add “pretty” and “compressed” separators definitions in jsonify()\nmethod. Reduces JSON response size when\nJSONIFY_PRETTYPRINT_REGULAR=False by removing unnecessary white\nspace included by default after separators.','include  by default',0,'',''),(11110,'Flask','Add “pretty” and “compressed” separators definitions in jsonify()\nmethod. Reduces JSON response size when\nJSONIFY_PRETTYPRINT_REGULAR=False by removing unnecessary white\nspace included by default after separators.','include  after separators',0,'',''),(11111,'Flask','flask.json.jsonify now supports the datetime.date type.\n#1326','support datetime.date type',0,'',''),(11112,'Flask','Don’t leak exception info of already caught exceptions to context\nteardown handlers. #1393','catch exceptions to context teardown handlers',0,'',''),(11113,'Flask','send_from_directory now raises BadRequest if the filename is\ninvalid on the server OS. #1763','raise BadRequest',0,'',''),(11114,'Flask','Added the JSONIFY_MIMETYPE configuration variable. #1728','add JSONIFY_MIMETYPE configuration variable',0,'',''),(11115,'Flask','Fixed broken test_appcontext_signals() test case.','test case',0,'',''),(11116,'Flask','Raise an AttributeError in helpers.find_package with a\nuseful message explaining why it is raised when a PEP 302 import\nhook is used without an is_package() method.','raise AttributeError with useful message',0,'',''),(11117,'Flask','Raise an AttributeError in helpers.find_package with a\nuseful message explaining why it is raised when a PEP 302 import\nhook is used without an is_package() method.','raise AttributeError in helpers.find_package',0,'',''),(11118,'Flask','Raise an AttributeError in helpers.find_package with a\nuseful message explaining why it is raised when a PEP 302 import\nhook is used without an is_package() method.','use PEP import hook without is_package() method',0,'',''),(11119,'Flask','Fixed an issue causing exceptions raised before entering a request\nor app context to be passed to teardown handlers.','fix issue',0,'',''),(11120,'Flask','Fixed an issue causing exceptions raised before entering a request\nor app context to be passed to teardown handlers.','enter request app context',0,'',''),(11121,'Flask','Fixed an issue causing exceptions raised before entering a request\nor app context to be passed to teardown handlers.','raise  before entering',0,'',''),(11122,'Flask','Fixed an issue causing exceptions raised before entering a request\nor app context to be passed to teardown handlers.','pass  to teardown handlers',0,'',''),(11123,'Flask','Fixed an issue with query parameters getting removed from requests\nin the test client when absolute URLs were requested.','fix issue with query parameters',0,'',''),(11124,'Flask','Fixed an issue with query parameters getting removed from requests\nin the test client when absolute URLs were requested.','remove  from requests',0,'',''),(11125,'Flask','Fixed an issue with query parameters getting removed from requests\nin the test client when absolute URLs were requested.','request absolute urls',0,'',''),(11126,'Flask','Fixed an etags bug when sending a file streams with a name.','fix etags bug',0,'',''),(11127,'Flask','Fixed an etags bug when sending a file streams with a name.','send file',0,'',''),(11128,'Flask','Fixed an issue where |tojson was not quoting single quotes which\nmade the filter not work properly in HTML attributes. Now it’s\npossible to use that filter in single quoted attributes. This should\nmake using that filter with angular.js easier.','fix issue',0,'',''),(11129,'Flask','Fixed an issue where |tojson was not quoting single quotes which\nmade the filter not work properly in HTML attributes. Now it’s\npossible to use that filter in single quoted attributes. This should\nmake using that filter with angular.js easier.','use filter in single quoted attributes',0,'',''),(11130,'Flask','Added support for byte strings back to the session system. This\nbroke compatibility with the common case of people putting binary\ndata for token verification into the session.','support  for byte strings',0,'',''),(11131,'Flask','Added support for byte strings back to the session system. This\nbroke compatibility with the common case of people putting binary\ndata for token verification into the session.','break compatibility with common case',0,'',''),(11132,'Flask','Fixed an issue where registering the same method twice for the same\nendpoint would trigger an exception incorrectly.','fix issue',0,'',''),(11133,'Flask','Fixed an issue where registering the same method twice for the same\nendpoint would trigger an exception incorrectly.','trigger exception',0,'',''),(11134,'Flask','Changed default cookie serialization format from pickle to JSON to\nlimit the impact an attacker can do if the secret key leaks.','change default cookie serialization format from pickle',0,'',''),(11135,'Flask','Changed default cookie serialization format from pickle to JSON to\nlimit the impact an attacker can do if the secret key leaks.','change default cookie serialization format to JSON',0,'',''),(11136,'Flask','Changed default cookie serialization format from pickle to JSON to\nlimit the impact an attacker can do if the secret key leaks.','limit impact',0,'',''),(11137,'Flask','Added template_test methods in addition to the already existing\ntemplate_filter method family.','add template_test methods to existing template_filter method family',0,'',''),(11138,'Flask','Added template_global methods in addition to the already\nexisting template_filter method family.','add template_global methods to existing template_filter method family',0,'',''),(11139,'Flask','Set the content-length header for x-sendfile.','set content-length header for x-sendfile',0,'',''),(11140,'Flask','tojson used in templates is now safe by default. This was\nallowed due to the different escaping behavior.','use  in templates',0,'',''),(11141,'Flask','Flask will now raise an error if you attempt to register a new\nfunction on an already used endpoint.','raise error',0,'',''),(11142,'Flask','Added wrapper module around simplejson and added default\nserialization of datetime objects. This allows much easier\ncustomization of how JSON is handled by Flask or any Flask\nextension.','add default serialization of datetime objects',0,'',''),(11143,'Flask','Added wrapper module around simplejson and added default\nserialization of datetime objects. This allows much easier\ncustomization of how JSON is handled by Flask or any Flask\nextension.','handle JSON',0,'',''),(11144,'Flask','Removed deprecated internal flask.session module alias. Use\nflask.sessions instead to get the session module. This is not to\nbe confused with flask.session the session proxy.','get session module',0,'',''),(11145,'Flask','Templates can now be rendered without request context. The behavior\nis slightly different as the request, session and g\nobjects will not be available and blueprint’s context processors are\nnot called.','render Templates without request context',0,'',''),(11146,'Flask','Added an option to generate non-ascii encoded JSON which should\nresult in less bytes being transmitted over the network. It’s\ndisabled by default to not cause confusion with existing libraries\nthat might expect flask.json.dumps to return bytes by default.','add option',0,'',''),(11147,'Flask','Added an option to generate non-ascii encoded JSON which should\nresult in less bytes being transmitted over the network. It’s\ndisabled by default to not cause confusion with existing libraries\nthat might expect flask.json.dumps to return bytes by default.','generate non-ascii encoded JSON',0,'',''),(11148,'Flask','Added an option to generate non-ascii encoded JSON which should\nresult in less bytes being transmitted over the network. It’s\ndisabled by default to not cause confusion with existing libraries\nthat might expect flask.json.dumps to return bytes by default.','return bytes by default',0,'',''),(11149,'Flask','flask.g is now stored on the app context instead of the request\ncontext.','store g on app context',0,'',''),(11150,'Flask','flask.g now can be used with the in operator to see what’s\ndefined and it now is iterable and will yield all attributes stored.','use g',0,'',''),(11151,'Flask','flask.Flask.request_globals_class got renamed to\nflask.Flask.app_ctx_globals_class which is a better name to what\nit does since 0.10.','rename flask.Flask.request_globals_class to flask.Flask.app_ctx_globals_class',0,'',''),(11152,'Flask','request, session and g are now also added as proxies to\nthe template context which makes them available in imported\ntemplates. One has to be very careful with those though because\nusage outside of macros might cause caching.','add request as proxies',0,'',''),(11153,'Flask','request, session and g are now also added as proxies to\nthe template context which makes them available in imported\ntemplates. One has to be very careful with those though because\nusage outside of macros might cause caching.','add request to template context',0,'',''),(11154,'Flask','request, session and g are now also added as proxies to\nthe template context which makes them available in imported\ntemplates. One has to be very careful with those though because\nusage outside of macros might cause caching.','add session as proxies',0,'',''),(11155,'Flask','request, session and g are now also added as proxies to\nthe template context which makes them available in imported\ntemplates. One has to be very careful with those though because\nusage outside of macros might cause caching.','add session to template context',0,'',''),(11156,'Flask','request, session and g are now also added as proxies to\nthe template context which makes them available in imported\ntemplates. One has to be very careful with those though because\nusage outside of macros might cause caching.','add g as proxies',0,'',''),(11157,'Flask','request, session and g are now also added as proxies to\nthe template context which makes them available in imported\ntemplates. One has to be very careful with those though because\nusage outside of macros might cause caching.','add g to template context',0,'',''),(11158,'Flask','Flask will no longer invoke the wrong error handlers if a proxy\nexception is passed through.','pass proxy exception',0,'',''),(11159,'Flask','Added a workaround for chrome’s cookies in localhost not working as\nintended with domain names.','add workaround for working',0,'',''),(11160,'Flask','Removed custom JSON HTTP exception subclasses. If you were relying\non them you can reintroduce them again yourself trivially. Using\nthem however is strongly discouraged as the interface was flawed.','remove custom JSON HTTP exception subclasses',0,'',''),(11161,'Flask','Python requirements changed: requiring Python 2.6 or 2.7 now to\nprepare for Python 3.3 port.','prepare  for Python port',0,'',''),(11162,'Flask','Changed how the teardown system is informed about exceptions. This\nis now more reliable in case something handles an exception halfway\nthrough the error handling process.','handle exception through error handling process',0,'',''),(11163,'Flask','Added the JSONIFY_PRETTYPRINT_REGULAR configuration variable.','add JSONIFY_PRETTYPRINT_REGULAR configuration variable',0,'',''),(11164,'Flask','Added appcontext_pushed and appcontext_popped signals.','add appcontext_pushed appcontext_popped signals',0,'',''),(11165,'Flask','Added flask.request.get_json() as a replacement for the old\nflask.request.json property.','add flask.request.get_json() as replacement',0,'',''),(11166,'Flask','Added flask.request.get_json() as a replacement for the old\nflask.request.json property.','add flask.request.get_json() for old flask.request.json property',0,'',''),(11167,'Flask','The Request.on_json_loading_failed now returns a JSON formatted\nresponse by default.','format response by default',0,'',''),(11168,'Flask','The url_for function now can generate anchors to the generated\nlinks.','generate anchors to generated links',0,'',''),(11169,'Flask','Logger now only returns the debug log setting if it was not set\nexplicitly.','return debug log',0,'',''),(11170,'Flask','Unregister a circular dependency between the WSGI environment and\nthe request object when shutting down the request. This means that\nenviron werkzeug.request will be None after the response was\nreturned to the WSGI server but has the advantage that the garbage\ncollector is not needed on CPython to tear down the request unless\nthe user created circular dependencies themselves.','return response to WSGI server',0,'',''),(11171,'Flask','Session is now stored after callbacks so that if the session payload\nis stored in the session you can still modify it in an after request\ncallback.','modify  in after request callback',0,'',''),(11172,'Flask','Session is now stored after callbacks so that if the session payload\nis stored in the session you can still modify it in an after request\ncallback.','store session after callbacks',0,'',''),(11173,'Flask','Session is now stored after callbacks so that if the session payload\nis stored in the session you can still modify it in an after request\ncallback.','store session payload in session',0,'',''),(11174,'Flask','The Flask class will avoid importing the provided import name if\nit can (the required first parameter), to benefit tools which build\nFlask instances programmatically. The Flask class will fall back to\nusing import on systems with custom module hooks, e.g. Google App\nEngine, or when the import name is inside a zip archive (usually an\negg) prior to Python 2.7.','import provided import name',0,'',''),(11175,'Flask','The Flask class will avoid importing the provided import name if\nit can (the required first parameter), to benefit tools which build\nFlask instances programmatically. The Flask class will fall back to\nusing import on systems with custom module hooks, e.g. Google App\nEngine, or when the import name is inside a zip archive (usually an\negg) prior to Python 2.7.','use import on e.g. google app engine',0,'',''),(11176,'Flask','The Flask class will avoid importing the provided import name if\nit can (the required first parameter), to benefit tools which build\nFlask instances programmatically. The Flask class will fall back to\nusing import on systems with custom module hooks, e.g. Google App\nEngine, or when the import name is inside a zip archive (usually an\negg) prior to Python 2.7.','use import on systems',0,'',''),(11177,'Flask','Blueprints now have a decorator to add custom template filters\napplication wide, Blueprint.app_template_filter.','add Blueprint.app_template_filter',0,'',''),(11178,'Flask','The get_flashed_messages function now allows rendering flashed\nmessage categories in separate blocks, through a category_filter\nargument.','render flashed message categories through category_filter argument',0,'',''),(11179,'Flask','The get_flashed_messages function now allows rendering flashed\nmessage categories in separate blocks, through a category_filter\nargument.','render flashed message categories in separate blocks',0,'',''),(11180,'Flask','The Flask.run method now accepts None for host and\nport arguments, using default values when None. This allows\nfor calling run using configuration values, e.g.\napp.run(app.config.get(\'MYHOST\'), app.config.get(\'MYPORT\')),\nwith proper behavior whether or not a config file is provided.','use default values',0,'',''),(11181,'Flask','The Flask.run method now accepts None for host and\nport arguments, using default values when None. This allows\nfor calling run using configuration values, e.g.\napp.run(app.config.get(\'MYHOST\'), app.config.get(\'MYPORT\')),\nwith proper behavior whether or not a config file is provided.','call run',0,'',''),(11182,'Flask','The Flask.run method now accepts None for host and\nport arguments, using default values when None. This allows\nfor calling run using configuration values, e.g.\napp.run(app.config.get(\'MYHOST\'), app.config.get(\'MYPORT\')),\nwith proper behavior whether or not a config file is provided.','use configuration values with proper behavior',0,'',''),(11183,'Flask','The Flask.run method now accepts None for host and\nport arguments, using default values when None. This allows\nfor calling run using configuration values, e.g.\napp.run(app.config.get(\'MYHOST\'), app.config.get(\'MYPORT\')),\nwith proper behavior whether or not a config file is provided.','provide config file',0,'',''),(11184,'Flask','The render_template method now accepts a either an iterable of\ntemplate names or a single template name. Previously, it only\naccepted a single template name. On an iterable, the first template\nfound is rendered.','render first template on iterable',0,'',''),(11185,'Flask','Added Flask.app_context which works very similar to the request\ncontext but only provides access to the current application. This\nalso adds support for URL generation without an active request\ncontext.','provide access to current application',0,'',''),(11186,'Flask','Added Flask.app_context which works very similar to the request\ncontext but only provides access to the current application. This\nalso adds support for URL generation without an active request\ncontext.','add support for URL generation',0,'',''),(11187,'Flask','Added Flask.app_context which works very similar to the request\ncontext but only provides access to the current application. This\nalso adds support for URL generation without an active request\ncontext.','add support without active request context',0,'',''),(11188,'Flask','View functions can now return a tuple with the first instance being\nan instance of Response. This allows for returning\njsonify(error=\"error msg\"), 400 from a view function.','return tuple with first instance',0,'',''),(11189,'Flask','View functions can now return a tuple with the first instance being\nan instance of Response. This allows for returning\njsonify(error=\"error msg\"), 400 from a view function.','return jsonify(error=\\\"error          msg\\\")',0,'',''),(11190,'Flask','Flask and Blueprint now provide a get_send_file_max_age\nhook for subclasses to override behavior of serving static files\nfrom Flask when using Flask.send_static_file (used for the\ndefault static file handler) and helpers.send_file. This hook is\nprovided a filename, which for example allows changing cache\ncontrols by file extension. The default max-age for send_file\nand static files can be configured through a new\nSEND_FILE_MAX_AGE_DEFAULT configuration variable, which is used\nin the default get_send_file_max_age implementation.','provide get_send_file_max_age hook for subclasses',0,'',''),(11191,'Flask','Flask and Blueprint now provide a get_send_file_max_age\nhook for subclasses to override behavior of serving static files\nfrom Flask when using Flask.send_static_file (used for the\ndefault static file handler) and helpers.send_file. This hook is\nprovided a filename, which for example allows changing cache\ncontrols by file extension. The default max-age for send_file\nand static files can be configured through a new\nSEND_FILE_MAX_AGE_DEFAULT configuration variable, which is used\nin the default get_send_file_max_age implementation.','override behavior of serving',0,'',''),(11192,'Flask','Flask and Blueprint now provide a get_send_file_max_age\nhook for subclasses to override behavior of serving static files\nfrom Flask when using Flask.send_static_file (used for the\ndefault static file handler) and helpers.send_file. This hook is\nprovided a filename, which for example allows changing cache\ncontrols by file extension. The default max-age for send_file\nand static files can be configured through a new\nSEND_FILE_MAX_AGE_DEFAULT configuration variable, which is used\nin the default get_send_file_max_age implementation.','use Flask.send_static_file',0,'',''),(11193,'Flask','Flask and Blueprint now provide a get_send_file_max_age\nhook for subclasses to override behavior of serving static files\nfrom Flask when using Flask.send_static_file (used for the\ndefault static file handler) and helpers.send_file. This hook is\nprovided a filename, which for example allows changing cache\ncontrols by file extension. The default max-age for send_file\nand static files can be configured through a new\nSEND_FILE_MAX_AGE_DEFAULT configuration variable, which is used\nin the default get_send_file_max_age implementation.','use helpers.send_file',0,'',''),(11194,'Flask','Flask and Blueprint now provide a get_send_file_max_age\nhook for subclasses to override behavior of serving static files\nfrom Flask when using Flask.send_static_file (used for the\ndefault static file handler) and helpers.send_file. This hook is\nprovided a filename, which for example allows changing cache\ncontrols by file extension. The default max-age for send_file\nand static files can be configured through a new\nSEND_FILE_MAX_AGE_DEFAULT configuration variable, which is used\nin the default get_send_file_max_age implementation.','provide filename',0,'',''),(11195,'Flask','Flask and Blueprint now provide a get_send_file_max_age\nhook for subclasses to override behavior of serving static files\nfrom Flask when using Flask.send_static_file (used for the\ndefault static file handler) and helpers.send_file. This hook is\nprovided a filename, which for example allows changing cache\ncontrols by file extension. The default max-age for send_file\nand static files can be configured through a new\nSEND_FILE_MAX_AGE_DEFAULT configuration variable, which is used\nin the default get_send_file_max_age implementation.','provide hook',0,'',''),(11196,'Flask','Flask and Blueprint now provide a get_send_file_max_age\nhook for subclasses to override behavior of serving static files\nfrom Flask when using Flask.send_static_file (used for the\ndefault static file handler) and helpers.send_file. This hook is\nprovided a filename, which for example allows changing cache\ncontrols by file extension. The default max-age for send_file\nand static files can be configured through a new\nSEND_FILE_MAX_AGE_DEFAULT configuration variable, which is used\nin the default get_send_file_max_age implementation.','change cache controls by file extension',0,'',''),(11197,'Flask','Flask and Blueprint now provide a get_send_file_max_age\nhook for subclasses to override behavior of serving static files\nfrom Flask when using Flask.send_static_file (used for the\ndefault static file handler) and helpers.send_file. This hook is\nprovided a filename, which for example allows changing cache\ncontrols by file extension. The default max-age for send_file\nand static files can be configured through a new\nSEND_FILE_MAX_AGE_DEFAULT configuration variable, which is used\nin the default get_send_file_max_age implementation.','configure default max-age through new SEND_FILE_MAX_AGE_DEFAULT configuration variable',0,'',''),(11198,'Flask','Flask and Blueprint now provide a get_send_file_max_age\nhook for subclasses to override behavior of serving static files\nfrom Flask when using Flask.send_static_file (used for the\ndefault static file handler) and helpers.send_file. This hook is\nprovided a filename, which for example allows changing cache\ncontrols by file extension. The default max-age for send_file\nand static files can be configured through a new\nSEND_FILE_MAX_AGE_DEFAULT configuration variable, which is used\nin the default get_send_file_max_age implementation.','configure default max-age for send_file static files',0,'',''),(11199,'Flask','Fixed an assumption in sessions implementation which could break\nmessage flashing on sessions implementations which use external\nstorage.','fix assumption in sessions implementation',0,'',''),(11200,'Flask','Fixed an assumption in sessions implementation which could break\nmessage flashing on sessions implementations which use external\nstorage.','break message in sessions implementation',0,'',''),(11201,'Flask','Fixed an assumption in sessions implementation which could break\nmessage flashing on sessions implementations which use external\nstorage.','break assumption in sessions implementation',0,'',''),(11202,'Flask','Fixed an assumption in sessions implementation which could break\nmessage flashing on sessions implementations which use external\nstorage.','use external storage',0,'',''),(11203,'Flask','Fixed an assumption in sessions implementation which could break\nmessage flashing on sessions implementations which use external\nstorage.','use sessions implementations',0,'',''),(11204,'Flask','Changed the behavior of tuple return values from functions. They are\nno longer arguments to the response object, they now have a defined\nmeaning.','change behavior of tuple return values',0,'',''),(11205,'Flask','Changed the behavior of tuple return values from functions. They are\nno longer arguments to the response object, they now have a defined\nmeaning.','change behavior from functions',0,'',''),(11206,'Flask','Added Flask.request_globals_class to allow a specific class to\nbe used on creation of the g instance of each request.','add Flask.request_globals_class',0,'',''),(11207,'Flask','Added Flask.request_globals_class to allow a specific class to\nbe used on creation of the g instance of each request.','use  on creation',0,'',''),(11208,'Flask','Added flask.after_this_request.','add flask.after_this_request',0,'',''),(11209,'Flask','Added flask.stream_with_context and the ability to push contexts\nmultiple times without producing unexpected behavior.','produce unexpected behavior',0,'',''),(11210,'Flask','Fixed an issue with the undocumented flask.session module to not\nwork properly on Python 2.5. It should not be used but did cause\nsome problems for package managers.','fix issue with undocumented flask.session',0,'',''),(11211,'Flask','Refactored session support into a session interface so that the\nimplementation of the sessions can be changed without having to\noverride the Flask class.','override Flask class',0,'',''),(11212,'Flask','Refactored session support into a session interface so that the\nimplementation of the sessions can be changed without having to\noverride the Flask class.','change implementation of sessions',0,'',''),(11213,'Flask','Refactored session support into a session interface so that the\nimplementation of the sessions can be changed without having to\noverride the Flask class.','change implementation without having',0,'',''),(11214,'Flask','Empty session cookies are now deleted properly automatically.','delete empty session cookies',0,'',''),(11215,'Flask','View functions can now opt out of getting the automatic OPTIONS\nimplementation.','get automatic OPTIONS implementation',0,'',''),(11216,'Flask','Flask in debug mode will now complain with an assertion error if a\nview was attached after the first request was handled. This gives\nearlier feedback when users forget to import view code ahead of\ntime.','attach view',0,'',''),(11217,'Flask','Flask in debug mode will now complain with an assertion error if a\nview was attached after the first request was handled. This gives\nearlier feedback when users forget to import view code ahead of\ntime.','handle first request',0,'',''),(11218,'Flask','Flask in debug mode will now complain with an assertion error if a\nview was attached after the first request was handled. This gives\nearlier feedback when users forget to import view code ahead of\ntime.','import view code ahead_of time',0,'',''),(11219,'Flask','Added the ability to register callbacks that are only triggered once\nat the beginning of the first request with\nFlask.before_first_request.','add ability',0,'',''),(11220,'Flask','Added the ability to register callbacks that are only triggered once\nat the beginning of the first request with\nFlask.before_first_request.','trigger callbacks at beginning',0,'',''),(11221,'Flask','Malformed JSON data will now trigger a bad request HTTP exception\ninstead of a value error which usually would result in a 500\ninternal server error if not handled. This is a backwards\nincompatible change.','trigger bad request HTTP exception instead_of value error',0,'',''),(11222,'Flask','Applications now not only have a root path where the resources and\nmodules are located but also an instance path which is the\ndesignated place to drop files that are modified at runtime (uploads\netc.). Also this is conceptually only instance depending and outside\nversion control so it’s the perfect place to put configuration files\netc.','modify designated place at runtime',0,'',''),(11223,'Flask','Applications now not only have a root path where the resources and\nmodules are located but also an instance path which is the\ndesignated place to drop files that are modified at runtime (uploads\netc.). Also this is conceptually only instance depending and outside\nversion control so it’s the perfect place to put configuration files\netc.','modify designated place to drop files',0,'',''),(11224,'Flask','Applications now not only have a root path where the resources and\nmodules are located but also an instance path which is the\ndesignated place to drop files that are modified at runtime (uploads\netc.). Also this is conceptually only instance depending and outside\nversion control so it’s the perfect place to put configuration files\netc.','locate resources',0,'',''),(11225,'Flask','Applications now not only have a root path where the resources and\nmodules are located but also an instance path which is the\ndesignated place to drop files that are modified at runtime (uploads\netc.). Also this is conceptually only instance depending and outside\nversion control so it’s the perfect place to put configuration files\netc.','locate modules',0,'',''),(11226,'Flask','Applications now not only have a root path where the resources and\nmodules are located but also an instance path which is the\ndesignated place to drop files that are modified at runtime (uploads\netc.). Also this is conceptually only instance depending and outside\nversion control so it’s the perfect place to put configuration files\netc.','locate root path',0,'',''),(11227,'Flask','Applications now not only have a root path where the resources and\nmodules are located but also an instance path which is the\ndesignated place to drop files that are modified at runtime (uploads\netc.). Also this is conceptually only instance depending and outside\nversion control so it’s the perfect place to put configuration files\netc.','locate instance path',0,'',''),(11228,'Flask','Added the APPLICATION_ROOT configuration variable.','add APPLICATION_ROOT configuration variable',0,'',''),(11229,'Flask','Implemented TestClient.session_transaction to easily modify\nsessions from the test environment.','modify sessions from test environment',0,'',''),(11230,'Flask','Refactored test client internally. The APPLICATION_ROOT\nconfiguration variable as well as SERVER_NAME are now properly\nused by the test client as defaults.','test client',0,'',''),(11231,'Flask','Refactored test client internally. The APPLICATION_ROOT\nconfiguration variable as well as SERVER_NAME are now properly\nused by the test client as defaults.','use APPLICATION_ROOT',0,'',''),(11232,'Flask','Refactored test client internally. The APPLICATION_ROOT\nconfiguration variable as well as SERVER_NAME are now properly\nused by the test client as defaults.','use SERVER_NAME',0,'',''),(11233,'Flask','Added View.decorators to support simpler decorating of pluggable\n(class-based) views.','add View.decorators',0,'',''),(11234,'Flask','Added View.decorators to support simpler decorating of pluggable\n(class-based) views.','support simpler decorating of pluggable views',0,'',''),(11235,'Flask','Fixed an issue where the test client if used with the “with”\nstatement did not trigger the execution of the teardown handlers.','fix issue',0,'',''),(11236,'Flask','HEAD requests to a method view now automatically dispatch to the\nget method if no handler was implemented.','get method',0,'',''),(11237,'Flask','HEAD requests to a method view now automatically dispatch to the\nget method if no handler was implemented.','implement handler',0,'',''),(11238,'Flask','Implemented the virtual flask.ext package to import extensions\nfrom.','implement virtual flask.ext package to import extensions',0,'',''),(11239,'Flask','Fixed the Jinja2 environment’s list_templates method not\nreturning the correct names when blueprints or modules were\ninvolved.','fix list_templates method',0,'',''),(11240,'Flask','Fixed an issue with URL processors not properly working on\nblueprints.','fix issue with URL processors',0,'',''),(11241,'Flask','Added missing future import that broke 2.5 compatibility.','break compatibility',0,'',''),(11242,'Flask','Added missing future import that broke 2.5 compatibility.','break future import',0,'',''),(11243,'Flask','Fixed an infinite redirect issue with blueprints.','fix infinite redirect issue with blueprints',0,'',''),(11244,'Flask','Added Flask.make_default_options_response which can be used by\nsubclasses to alter the default behavior for OPTIONS responses.','use added Flask.make_default_options_response',0,'',''),(11245,'Flask','Unbound locals now raise a proper RuntimeError instead of an\nAttributeError.','raise proper RuntimeError instead_of AttributeError',0,'',''),(11246,'Flask','Mimetype guessing and etag support based on file objects is now\ndeprecated for send_file because it was unreliable. Pass\nfilenames instead or attach your own etags and provide a proper\nmimetype by hand.','pass filenames',0,'',''),(11247,'Flask','Mimetype guessing and etag support based on file objects is now\ndeprecated for send_file because it was unreliable. Pass\nfilenames instead or attach your own etags and provide a proper\nmimetype by hand.','attach own etags',0,'',''),(11248,'Flask','Mimetype guessing and etag support based on file objects is now\ndeprecated for send_file because it was unreliable. Pass\nfilenames instead or attach your own etags and provide a proper\nmimetype by hand.','provide proper mimetype by hand',0,'',''),(11249,'Flask','Fixed a problem for Flask to run on jython.','run  on jython',0,'',''),(11250,'Flask','Added a PROPAGATE_EXCEPTIONS configuration variable that can be\nused to flip the setting of exception propagation which previously\nwas linked to DEBUG alone and is now linked to either DEBUG\nor TESTING.','add PROPAGATE_EXCEPTIONS configuration variable',0,'',''),(11251,'Flask','Added a PROPAGATE_EXCEPTIONS configuration variable that can be\nused to flip the setting of exception propagation which previously\nwas linked to DEBUG alone and is now linked to either DEBUG\nor TESTING.','link setting of exception propagation',0,'',''),(11252,'Flask','Added a PROPAGATE_EXCEPTIONS configuration variable that can be\nused to flip the setting of exception propagation which previously\nwas linked to DEBUG alone and is now linked to either DEBUG\nor TESTING.','link setting to DEBUG',0,'',''),(11253,'Flask','Added a PROPAGATE_EXCEPTIONS configuration variable that can be\nused to flip the setting of exception propagation which previously\nwas linked to DEBUG alone and is now linked to either DEBUG\nor TESTING.','link  to TESTING',0,'',''),(11254,'Flask','Added a PROPAGATE_EXCEPTIONS configuration variable that can be\nused to flip the setting of exception propagation which previously\nwas linked to DEBUG alone and is now linked to either DEBUG\nor TESTING.','link  to DEBUG',0,'',''),(11255,'Flask','Added a PROPAGATE_EXCEPTIONS configuration variable that can be\nused to flip the setting of exception propagation which previously\nwas linked to DEBUG alone and is now linked to either DEBUG\nor TESTING.','use PROPAGATE_EXCEPTIONS configuration variable',0,'',''),(11256,'Flask','Flask no longer internally depends on rules being added through the\nadd_url_rule function and can now also accept regular werkzeug\nrules added to the url map.','add  through add_url_rule function',0,'',''),(11257,'Flask','Flask no longer internally depends on rules being added through the\nadd_url_rule function and can now also accept regular werkzeug\nrules added to the url map.','add  to url map',0,'',''),(11258,'Flask','Added an endpoint method to the flask application object which\nallows one to register a callback to an arbitrary endpoint with a\ndecorator.','add endpoint method to flask application',0,'',''),(11259,'Flask','Use Last-Modified for static file sending instead of Date which was\nincorrectly introduced in 0.6.','send  instead_of Date',0,'',''),(11260,'Flask','Use Last-Modified for static file sending instead of Date which was\nincorrectly introduced in 0.6.','introduce Date',0,'',''),(11261,'Flask','Added create_jinja_loader to override the loader creation\nprocess.','add create_jinja_loader',0,'',''),(11262,'Flask','Added create_jinja_loader to override the loader creation\nprocess.','override loader creation process',0,'',''),(11263,'Flask','Implemented a silent flag for config.from_pyfile.','implement silent flag for config.from_pyfile',0,'',''),(11264,'Flask','Added teardown_request decorator, for functions that should run\nat the end of a request regardless of whether an exception occurred.\nAlso the behavior for after_request was changed. It’s now no\nlonger executed when an exception is raised.','add teardown_request decorator for functions',0,'',''),(11265,'Flask','Added teardown_request decorator, for functions that should run\nat the end of a request regardless of whether an exception occurred.\nAlso the behavior for after_request was changed. It’s now no\nlonger executed when an exception is raised.','run functions at end',0,'',''),(11266,'Flask','Added teardown_request decorator, for functions that should run\nat the end of a request regardless of whether an exception occurred.\nAlso the behavior for after_request was changed. It’s now no\nlonger executed when an exception is raised.','change behavior for after_request',0,'',''),(11267,'Flask','Added teardown_request decorator, for functions that should run\nat the end of a request regardless of whether an exception occurred.\nAlso the behavior for after_request was changed. It’s now no\nlonger executed when an exception is raised.','raise exception',0,'',''),(11268,'Flask','Added safe_join.','add safe_join',0,'',''),(11269,'Flask','Don’t modify the session on get_flashed_messages if there are no\nmessages in the session.','modify session on get_flashed_messages',0,'',''),(11270,'Flask','It is not possible to define user exception handlers. That way you\ncan provide custom error messages from a central hub for certain\nerrors that might occur during request processing (for instance\ndatabase connection errors, timeouts from remote resources etc.).','define user exception handlers',0,'',''),(11271,'Flask','It is not possible to define user exception handlers. That way you\ncan provide custom error messages from a central hub for certain\nerrors that might occur during request processing (for instance\ndatabase connection errors, timeouts from remote resources etc.).','provide custom error messages from central hub',0,'',''),(11272,'Flask','Blueprints can provide blueprint specific error handlers.','provide blueprint specific error handlers',0,'',''),(11273,'Flask','Implemented generic class-based views.','implement generic class-based views',0,'',''),(11274,'Flask','Fixed an issue where the default OPTIONS response was not\nexposing all valid methods in the Allow header.','fix issue',0,'',''),(11275,'Flask','Fixed an issue where the subdomain setting for modules was ignored\nfor the static folder.','fix issue',0,'',''),(11276,'Flask','Fixed an issue where the subdomain setting for modules was ignored\nfor the static folder.','ignore subdomain setting for static folder',0,'',''),(11277,'Flask','Fixed an issue where the subdomain setting for modules was ignored\nfor the static folder.','ignore subdomain setting for modules',0,'',''),(11278,'Flask','Fixed a security problem that allowed clients to download arbitrary\nfiles if the host server was a windows based operating system and\nthe client uses backslashes to escape the directory the files where\nexposed from.','fix security problem',0,'',''),(11279,'Flask','Fixed a security problem that allowed clients to download arbitrary\nfiles if the host server was a windows based operating system and\nthe client uses backslashes to escape the directory the files where\nexposed from.','expose files',0,'',''),(11280,'Flask','After request functions are now called in reverse order of\nregistration.','call functions after request',0,'',''),(11281,'Flask','OPTIONS is now automatically implemented by Flask unless the\napplication explicitly adds ‘OPTIONS’ as method to the URL rule. In\nthis case no automatic OPTIONS handling kicks in.','add âOPTIONSâ as method',0,'',''),(11282,'Flask','OPTIONS is now automatically implemented by Flask unless the\napplication explicitly adds ‘OPTIONS’ as method to the URL rule. In\nthis case no automatic OPTIONS handling kicks in.','add âOPTIONSâ to URL rule',0,'',''),(11283,'Flask','OPTIONS is now automatically implemented by Flask unless the\napplication explicitly adds ‘OPTIONS’ as method to the URL rule. In\nthis case no automatic OPTIONS handling kicks in.','implement OPTIONS',0,'',''),(11284,'Flask','Static rules are now even in place if there is no static folder for\nthe module. This was implemented to aid GAE which will remove the\nstatic folder if it’s part of a mapping in the .yml file.','remove static folder',0,'',''),(11285,'Flask','Static rules are now even in place if there is no static folder for\nthe module. This was implemented to aid GAE which will remove the\nstatic folder if it’s part of a mapping in the .yml file.','remove GAE',0,'',''),(11286,'Flask','Context processors will no longer override values passed directly to\nthe render function.','override values',0,'',''),(11287,'Flask','Context processors will no longer override values passed directly to\nthe render function.','pass  to render function',0,'',''),(11288,'Flask','Added the ability to limit the incoming request data with the new\nMAX_CONTENT_LENGTH configuration value.','add ability',0,'',''),(11289,'Flask','Added the ability to limit the incoming request data with the new\nMAX_CONTENT_LENGTH configuration value.','limit incoming request data with new MAX_CONTENT_LENGTH configuration value',0,'',''),(11290,'Flask','Added a make_response function that simplifies creating response\nobject instances in views.','add make_response function',0,'',''),(11291,'Flask','Added a make_response function that simplifies creating response\nobject instances in views.','create response object instances in views',0,'',''),(11292,'Flask','Refactored the way URL adapters are created. This process is now\nfully customizable with the Flask.create_url_adapter method.','create refactored URL adapters',0,'',''),(11293,'Flask','Modules can now register for a subdomain instead of just an URL\nprefix. This makes it possible to bind a whole module to a\nconfigurable subdomain.','bind whole module to configurable subdomain',0,'',''),(11294,'Flask','Fixed another issue with loading templates from directories when\nmodules were used.','fix issue with loading',0,'',''),(11295,'Flask','Fixed another issue with loading templates from directories when\nmodules were used.','load templates from directories',0,'',''),(11296,'Flask','Fixed another issue with loading templates from directories when\nmodules were used.','use modules',0,'',''),(11297,'Flask','Fixes an issue with template loading from directories when modules\nwhere used.','fix issue with template',0,'',''),(11298,'Flask','Fixes an issue with template loading from directories when modules\nwhere used.','load  from directories',0,'',''),(11299,'Flask','Fixed a bug with subdomains that was caused by the inability to\nspecify the server name. The server name can now be set with the\nSERVER_NAME config key. This key is now also used to set the\nsession cookie cross-subdomain wide.','fix bug with subdomains',0,'',''),(11300,'Flask','Fixed a bug with subdomains that was caused by the inability to\nspecify the server name. The server name can now be set with the\nSERVER_NAME config key. This key is now also used to set the\nsession cookie cross-subdomain wide.','specify server name',0,'',''),(11301,'Flask','Fixed a bug with subdomains that was caused by the inability to\nspecify the server name. The server name can now be set with the\nSERVER_NAME config key. This key is now also used to set the\nsession cookie cross-subdomain wide.','set server name with SERVER_NAME config key',0,'',''),(11302,'Flask','Fixed a bug with subdomains that was caused by the inability to\nspecify the server name. The server name can now be set with the\nSERVER_NAME config key. This key is now also used to set the\nsession cookie cross-subdomain wide.','use key',0,'',''),(11303,'Flask','Autoescaping is no longer active for all templates. Instead it is\nonly active for .html, .htm, .xml and .xhtml. Inside\ntemplates this behavior can be changed with the autoescape tag.','change behavior with autoescape tag',0,'',''),(11304,'Flask','Autoescaping is no longer active for all templates. Instead it is\nonly active for .html, .htm, .xml and .xhtml. Inside\ntemplates this behavior can be changed with the autoescape tag.','change behavior inside templates',0,'',''),(11305,'Flask','Added support for per-package template and static-file directories.','support  for per-package template',0,'',''),(11306,'Flask','Added support for per-package template and static-file directories.','support  for static-file directories',0,'',''),(11307,'Flask','Removed support for create_jinja_loader which is no longer used\nin 0.5 due to the improved module support.','support  for create_jinja_loader',0,'',''),(11308,'Flask','Removed support for create_jinja_loader which is no longer used\nin 0.5 due to the improved module support.','use create_jinja_loader due_to improved module support',0,'',''),(11309,'Flask','Added a helper function to expose files from any directory.','expose files from directory',0,'',''),(11310,'Flask','Added the ability to register application wide error handlers from\nmodules.','add ability',0,'',''),(11311,'Flask','Test client has not the ability to preserve the request context for\na little longer. This can also be used to trigger custom requests\nthat do not pop the request stack for testing.','trigger custom requests',0,'',''),(11312,'Flask','Added TESTING switch that can activate unittesting helpers.','activate unittesting helpers',0,'',''),(11313,'Flask','The logger switches to DEBUG mode now if debug is enabled.','switch  to DEBUG mode',0,'',''),(11314,'Flask','The logger switches to DEBUG mode now if debug is enabled.','enable debug',0,'',''),(11315,'Flask','Fixed a error reporting bug with Config.from_envvar.','fix error reporting bug with Config.from_envvar',0,'',''),(11316,'Flask','Removed some unused code.','remove unused code',0,'',''),(11317,'Flask','Release does no longer include development leftover files (.git\nfolder for themes, built documentation in zip and pdf file and some\n.pyc files)','include development leftover files',0,'',''),(11318,'Flask','Added support for categories for flashed messages.','support  for categories',0,'',''),(11319,'Flask','The application now configures a logging.Handler and will log\nrequest handling exceptions to that logger when not in debug mode.\nThis makes it possible to receive mails on server errors for\nexample.','configure logging.Handler',0,'',''),(11320,'Flask','The application now configures a logging.Handler and will log\nrequest handling exceptions to that logger when not in debug mode.\nThis makes it possible to receive mails on server errors for\nexample.','log request handling exceptions to logger',0,'',''),(11321,'Flask','The application now configures a logging.Handler and will log\nrequest handling exceptions to that logger when not in debug mode.\nThis makes it possible to receive mails on server errors for\nexample.','receive mails on server errors',0,'',''),(11322,'Flask','Added support for context binding that does not require the use of\nthe with statement for playing in the console.','play  in console',0,'',''),(11323,'Flask','The request context is now available within the with statement\nmaking it possible to further push the request context or pop it.','push request context',0,'',''),(11324,'Flask','Added support for configurations.','support  for configurations',0,'',''),(11325,'Flask','Server listens on 127.0.0.1 by default now to fix issues with\nchrome.','fix issues with chrome',0,'',''),(11326,'Flask','Added support for send_file.','support  for send_file',0,'',''),(11327,'Flask','Module support and internal request handling refactoring to better\nsupport pluggable applications.','support pluggable applications',0,'',''),(11328,'Flask','Sessions can be set to be permanent now on a per-session basis.','set sessions',0,'',''),(11329,'Flask','Added support for Google Appengine.','support  for Google appengine',0,'',''),(11330,'pytest','merlinux.eu offers pytest and tox-related professional teaching and\nconsulting.','offer pytest tox-related professional teaching',0,'',''),(11331,'pytest','merlinux.eu offers pytest and tox-related professional teaching and\nconsulting.','offer consulting',0,'',''),(11332,'pytest','Tidelift is working with the maintainers of pytest and thousands of other\nopen source projects to deliver commercial support and maintenance for the open source dependencies you use\nto build your applications. Save time, reduce risk, and improve code health, while paying the maintainers of the\nexact dependencies you use.','save time',0,'',''),(11333,'pytest','Get more details','get more details',0,'',''),(11334,'pytest','Tidelift verifies license information to enable easy policy enforcement and adds intellectual property indemnification to cover creators and users in case something goes wrong. You always have a 100% up-to-date bill of materials for your dependencies to share with your legal team, customers, or partners.','enable easy policy enforcement',0,'',''),(11335,'pytest','Tidelift verifies license information to enable easy policy enforcement and adds intellectual property indemnification to cover creators and users in case something goes wrong. You always have a 100% up-to-date bill of materials for your dependencies to share with your legal team, customers, or partners.','add intellectual property indemnification',0,'',''),(11336,'pytest','Tidelift verifies license information to enable easy policy enforcement and adds intellectual property indemnification to cover creators and users in case something goes wrong. You always have a 100% up-to-date bill of materials for your dependencies to share with your legal team, customers, or partners.','share  with legal team',0,'',''),(11337,'pytest','Tidelift verifies license information to enable easy policy enforcement and adds intellectual property indemnification to cover creators and users in case something goes wrong. You always have a 100% up-to-date bill of materials for your dependencies to share with your legal team, customers, or partners.','share  with customers',0,'',''),(11338,'pytest','Tidelift verifies license information to enable easy policy enforcement and adds intellectual property indemnification to cover creators and users in case something goes wrong. You always have a 100% up-to-date bill of materials for your dependencies to share with your legal team, customers, or partners.','share  with partners',0,'',''),(11339,'pytest','Tidelift helps you choose the best open source packages from the start—and then guide you through updates to stay on the best releases as new issues arise.','choose open source packages from start â',0,'',''),(11340,'pytest','Take a seat at the table with the creators behind the software you use. Tidelift’s participating maintainers earn more income as their software is used by more subscribers, so they’re interested in knowing what you need.','use software',0,'',''),(11341,'pytest','The end result? All of the capabilities you expect from commercial-grade software, for the full breadth of open\nsource you use. That means less time grappling with esoteric open source trivia, and more time building your own\napplications—and your business.','use  for full breadth',0,'',''),(11342,'pytest','Request a demo','request demo',0,'',''),(11343,'pytest','Backward incompatible (breaking) changes will only be introduced in major versions\nwith advance notice in the Deprecations section of releases.','introduce backward incompatible changes with advance notice',0,'',''),(11344,'pytest','Backward incompatible (breaking) changes will only be introduced in major versions\nwith advance notice in the Deprecations section of releases.','introduce backward incompatible changes in major versions',0,'',''),(11345,'pytest','#10012: Update pytest.PytestUnhandledCoroutineWarning to a deprecation; it will raise an error in pytest 8.','raise error',0,'',''),(11346,'pytest','#10396: pytest no longer depends on the py library.  pytest provides a vendored copy of py.error and py.path modules but will use the py library if it is installed.  If you need other py.* modules, continue to install the deprecated py library separately, otherwise it can usually be removed as a dependency.','provide vendored copy of py.error py.path modules',0,'',''),(11347,'pytest','#10396: pytest no longer depends on the py library.  pytest provides a vendored copy of py.error and py.path modules but will use the py library if it is installed.  If you need other py.* modules, continue to install the deprecated py library separately, otherwise it can usually be removed as a dependency.','use py library',0,'',''),(11348,'pytest','#10396: pytest no longer depends on the py library.  pytest provides a vendored copy of py.error and py.path modules but will use the py library if it is installed.  If you need other py.* modules, continue to install the deprecated py library separately, otherwise it can usually be removed as a dependency.','install deprecated py library',0,'',''),(11349,'pytest','#10396: pytest no longer depends on the py library.  pytest provides a vendored copy of py.error and py.path modules but will use the py library if it is installed.  If you need other py.* modules, continue to install the deprecated py library separately, otherwise it can usually be removed as a dependency.','remove * modules as dependency',0,'',''),(11350,'pytest','#4562: Deprecate configuring hook specs/impls using attributes/marks.','configure hook specs/impls using attributes/marks',0,'',''),(11351,'pytest','Instead use pytest.hookimpl() and pytest.hookspec().\nFor more details, see the docs.','use pytest.hookimpl()',0,'',''),(11352,'pytest','Instead use pytest.hookimpl() and pytest.hookspec().\nFor more details, see the docs.','use pytest.hookspec()',0,'',''),(11353,'pytest','#9886: The functionality for running tests written for nose has been officially deprecated.','run tests',0,'',''),(11354,'pytest','#9886: The functionality for running tests written for nose has been officially deprecated.','write  for nose',0,'',''),(11355,'pytest','Plain setup and teardown functions and methods: this might catch users by surprise, as setup() and teardown() are not pytest idioms, but part of the nose support.','catch users by surprise',0,'',''),(11356,'pytest','Setup/teardown using the @with_setup decorator.','use @with_setup decorator',0,'',''),(11357,'pytest','#7337: A deprecation warning is now emitted if a test function returns something other than None. This prevents a common mistake among beginners that expect that returning a bool (for example return foo(a, b) == result) would cause a test to pass or fail, instead of using assert. The plan is to make returning non-None from tests an error in the future.','return something other than none',0,'',''),(11358,'pytest','#7337: A deprecation warning is now emitted if a test function returns something other than None. This prevents a common mistake among beginners that expect that returning a bool (for example return foo(a, b) == result) would cause a test to pass or fail, instead of using assert. The plan is to make returning non-None from tests an error in the future.','prevent common mistake among beginners',0,'',''),(11359,'pytest','#9897: Added shell-style wildcard support to testpaths.','add shell-style wildcard support to testpaths',0,'',''),(11360,'pytest','#10381: The --no-showlocals flag has been added. This can be passed directly to tests to override --showlocals declared through addopts.','add flag',0,'',''),(11361,'pytest','#10381: The --no-showlocals flag has been added. This can be passed directly to tests to override --showlocals declared through addopts.','add no-showlocals',0,'',''),(11362,'pytest','#10381: The --no-showlocals flag has been added. This can be passed directly to tests to override --showlocals declared through addopts.','pass  to tests',0,'',''),(11363,'pytest','#8508: Introduce multiline display for warning matching  via pytest.warns() and\nenhance match comparison for _pytest._code.ExceptionInfo.match() as returned by pytest.raises().','return  by pytest.raises()',0,'',''),(11364,'pytest','#8646: Improve pytest.raises(). Previously passing an empty tuple would give a confusing\nerror. We now raise immediately with a more helpful message.','pass empty tuple',0,'',''),(11365,'pytest','#8646: Improve pytest.raises(). Previously passing an empty tuple would give a confusing\nerror. We now raise immediately with a more helpful message.','raise  with helpful message',0,'',''),(11366,'pytest','#9741: On Python 3.11, use the standard library’s tomllib to parse TOML.','use tomllib',0,'',''),(11367,'pytest','#9823: Improved error message that is shown when no collector is found for a given file.','find collector for given file',0,'',''),(11368,'pytest','#9823: Improved error message that is shown when no collector is found for a given file.','show improved error message',0,'',''),(11369,'pytest','#9873: Some coloring has been added to the short test summary.','add coloring to short test summary',0,'',''),(11370,'pytest','#9920: Display full crash messages in short test summary info, when running in a CI environment.','run  in CI environment',0,'',''),(11371,'pytest','#10150: sys.stdin now contains all expected methods of a file-like object when capture is enabled.','enable capture',0,'',''),(11372,'pytest','#7792: Marks are now inherited according to the full MRO in test classes. Previously, if a test class inherited from two or more classes, only marks from the first super-class would apply.','inherit marks',0,'',''),(11373,'pytest','#7792: Marks are now inherited according to the full MRO in test classes. Previously, if a test class inherited from two or more classes, only marks from the first super-class would apply.','inherit  from classes',0,'',''),(11374,'pytest','When inheriting marks from super-classes, marks from the sub-classes are now ordered before marks from the super-classes, in MRO order. Previously it was the reverse.','inherit marks from super-classes',0,'',''),(11375,'pytest','When inheriting marks from super-classes, marks from the sub-classes are now ordered before marks from the super-classes, in MRO order. Previously it was the reverse.','order marks before marks',0,'',''),(11376,'pytest','When inheriting marks from super-classes, marks from the sub-classes are now ordered before marks from the super-classes, in MRO order. Previously it was the reverse.','order marks from super-classes',0,'',''),(11377,'pytest','When inheriting marks from super-classes, marks from the sub-classes are now ordered before marks from the super-classes, in MRO order. Previously it was the reverse.','order marks from sub-classes',0,'',''),(11378,'pytest','When inheriting marks from super-classes, the pytestmark attribute of the sub-class now only contains the marks directly applied to it. Previously, it also contained marks from its super-classes. Please note that this attribute should not normally be accessed directly; use pytest.Node.iter_markers() instead.','inherit marks from super-classes',0,'',''),(11379,'pytest','When inheriting marks from super-classes, the pytestmark attribute of the sub-class now only contains the marks directly applied to it. Previously, it also contained marks from its super-classes. Please note that this attribute should not normally be accessed directly; use pytest.Node.iter_markers() instead.','use pytest.Node.iter_markers()',0,'',''),(11380,'pytest','#9159: Showing inner exceptions by forcing native display in ExceptionGroups even when using display options other than --tb=native. A temporary step before full implementation of pytest-native display for inner exceptions in ExceptionGroups.','show inner exceptions by forcing',0,'',''),(11381,'pytest','#9159: Showing inner exceptions by forcing native display in ExceptionGroups even when using display options other than --tb=native. A temporary step before full implementation of pytest-native display for inner exceptions in ExceptionGroups.','force native display in ExceptionGroups',0,'',''),(11382,'pytest','#9159: Showing inner exceptions by forcing native display in ExceptionGroups even when using display options other than --tb=native. A temporary step before full implementation of pytest-native display for inner exceptions in ExceptionGroups.','use display options',0,'',''),(11383,'pytest','#10344: Update information on writing plugins to use pyproject.toml instead of setup.py.','write plugins',0,'',''),(11384,'pytest','#10344: Update information on writing plugins to use pyproject.toml instead of setup.py.','use pyproject.toml instead_of setup.py',0,'',''),(11385,'pytest','#9248: The documentation is now built using Sphinx 5.x (up from 3.x previously).','use Sphinx',0,'',''),(11386,'pytest','#9984: Improve the error message when we attempt to access a fixture that has been\ntorn down.\nAdd an additional sentence to the docstring explaining when it’s not a good\nidea to call getfixturevalue.','access fixture',0,'',''),(11387,'pytest','#9984: Improve the error message when we attempt to access a fixture that has been\ntorn down.\nAdd an additional sentence to the docstring explaining when it’s not a good\nidea to call getfixturevalue.','add additional sentence to docstring',0,'',''),(11388,'pytest','#9984: Improve the error message when we attempt to access a fixture that has been\ntorn down.\nAdd an additional sentence to the docstring explaining when it’s not a good\nidea to call getfixturevalue.','call getfixturevalue',0,'',''),(11389,'pytest','#10060: When running with --pdb, TestCase.tearDown is no longer called for tests when the class has been skipped via unittest.skip or pytest.mark.skip.','call TestCase.tearDown for tests',0,'',''),(11390,'pytest','#10060: When running with --pdb, TestCase.tearDown is no longer called for tests when the class has been skipped via unittest.skip or pytest.mark.skip.','skip class via unittest.skip',0,'',''),(11391,'pytest','#10060: When running with --pdb, TestCase.tearDown is no longer called for tests when the class has been skipped via unittest.skip or pytest.mark.skip.','skip class via pytest.mark.skip',0,'',''),(11392,'pytest','#10230: Ignore .py files created by pyproject.toml-based editable builds introduced in pip 21.3.','create  by pyproject.toml',0,'',''),(11393,'pytest','#9514: Type-annotate FixtureRequest.param as Any as a stop gap measure until issue #8073 is fixed.','fix issue',0,'',''),(11394,'pytest','#9791: Fixed a path handling code in rewrite.py that seems to work fine, but was incorrect and fails in some systems.','fix path handling code in rewrite.py',0,'',''),(11395,'pytest','#9917: Fixed string representation for pytest.approx() when used to compare tuples.','compare tuples',0,'',''),(11396,'pytest','#9726: An unnecessary numpy import inside pytest.approx() was removed.','remove unnecessary numpy import inside pytest.approx()',0,'',''),(11397,'pytest','#9871: Fix a bizarre (and fortunately rare) bug where the temp_path fixture could raise\nan internal error while attempting to get the current user’s username.','fix bizarre bug',0,'',''),(11398,'pytest','#9871: Fix a bizarre (and fortunately rare) bug where the temp_path fixture could raise\nan internal error while attempting to get the current user’s username.','raise internal error while attempting',0,'',''),(11399,'pytest','#9871: Fix a bizarre (and fortunately rare) bug where the temp_path fixture could raise\nan internal error while attempting to get the current user’s username.','get username',0,'',''),(11400,'pytest','pytest_warning_captured hook - use pytest_warning_recorded instead.','use pytest_warning_recorded',0,'',''),(11401,'pytest','pytest.collect module - import from pytest directly.','import  from pytest',0,'',''),(11402,'pytest','#9437: Dropped support for Python 3.6, which reached end-of-life at 2021-12-23.','reach end-of-life',0,'',''),(11403,'pytest','#9437: Dropped support for Python 3.6, which reached end-of-life at 2021-12-23.','reach Python',0,'',''),(11404,'pytest','#5192: Fixed test output for some data types where -v would show less information.','show less information for data types',0,'',''),(11405,'pytest','#5192: Fixed test output for some data types where -v would show less information.','show fixed test output for data types',0,'',''),(11406,'pytest','Also, when showing diffs for sequences, -q would produce full diffs instead of the expected diff.','show diffs for sequences',0,'',''),(11407,'pytest','Also, when showing diffs for sequences, -q would produce full diffs instead of the expected diff.','produce full diffs instead_of expected diff',0,'',''),(11408,'pytest','#9362: pytest now avoids specialized assert formatting when it is detected that the default __eq__ is overridden in attrs or dataclasses.','override default __eq__ in attrs',0,'',''),(11409,'pytest','#9362: pytest now avoids specialized assert formatting when it is detected that the default __eq__ is overridden in attrs or dataclasses.','override default __eq__ in dataclasses',0,'',''),(11410,'pytest','#9536: When -vv is given on command line, show skipping and xfail reasons in full instead of truncating them to fit the terminal width.','show skipping xfail reasons',0,'',''),(11411,'pytest','#9536: When -vv is given on command line, show skipping and xfail reasons in full instead of truncating them to fit the terminal width.','fit terminal width',0,'',''),(11412,'pytest','#9644: More information about the location of resources that led Python to raise ResourceWarning can now\nbe obtained by enabling tracemalloc.','raise ResourceWarning',0,'',''),(11413,'pytest','#9644: More information about the location of resources that led Python to raise ResourceWarning can now\nbe obtained by enabling tracemalloc.','obtain Python',0,'',''),(11414,'pytest','#9692: pytest.approx() now raises a TypeError when given an unordered sequence (such as set).','raise TypeError',0,'',''),(11415,'pytest','Note that this implies that custom classes which only implement __iter__ and __len__ are no longer supported as they don’t guarantee order.','implement __iter__',0,'',''),(11416,'pytest','Note that this implies that custom classes which only implement __iter__ and __len__ are no longer supported as they don’t guarantee order.','implement __len__',0,'',''),(11417,'pytest','Note that this implies that custom classes which only implement __iter__ and __len__ are no longer supported as they don’t guarantee order.','implement custom classes',0,'',''),(11418,'pytest','Note that this implies that custom classes which only implement __iter__ and __len__ are no longer supported as they don’t guarantee order.','support custom classes',0,'',''),(11419,'pytest','#8242: The deprecation of raising unittest.SkipTest to skip collection of\ntests during the pytest collection phase is reverted - this is now a supported\nfeature again.','raise unittest.SkipTest',0,'',''),(11420,'pytest','#8242: The deprecation of raising unittest.SkipTest to skip collection of\ntests during the pytest collection phase is reverted - this is now a supported\nfeature again.','skip collection of tests',0,'',''),(11421,'pytest','#8242: The deprecation of raising unittest.SkipTest to skip collection of\ntests during the pytest collection phase is reverted - this is now a supported\nfeature again.','skip collection during pytest collection phase',0,'',''),(11422,'pytest','#9493: Symbolic link components are no longer resolved in conftest paths.\nThis means that if a conftest appears twice in collection tree, using symlinks, it will be executed twice.\nFor example, given','resolve symbolic link components in conftest paths',0,'',''),(11423,'pytest','#9493: Symbolic link components are no longer resolved in conftest paths.\nThis means that if a conftest appears twice in collection tree, using symlinks, it will be executed twice.\nFor example, given','use symlinks',0,'',''),(11424,'pytest','running pytest tests now imports the conftest twice, once as tests/real/conftest.py and once as tests/link/conftest.py.\nThis is a fix to match a similar change made to test collection itself in pytest 6.0 (see pull request #6523 for details).','run pytest',0,'',''),(11425,'pytest','running pytest tests now imports the conftest twice, once as tests/real/conftest.py and once as tests/link/conftest.py.\nThis is a fix to match a similar change made to test collection itself in pytest 6.0 (see pull request #6523 for details).','import conftest tests/link/conftest.py for running',0,'',''),(11426,'pytest','running pytest tests now imports the conftest twice, once as tests/real/conftest.py and once as tests/link/conftest.py.\nThis is a fix to match a similar change made to test collection itself in pytest 6.0 (see pull request #6523 for details).','test collection',0,'',''),(11427,'pytest','If there were errors or skipped modules on collection, pytest would mistakenly subtract those from the selected count.','skip modules on collection',0,'',''),(11428,'pytest','#9645: Fixed regression where --import-mode=importlib used together with PYTHONPATH or pythonpath would cause import errors in test suites.','use  together_with pythonpath',0,'',''),(11429,'pytest','#9645: Fixed regression where --import-mode=importlib used together with PYTHONPATH or pythonpath would cause import errors in test suites.','use  together_with PYTHONPATH',0,'',''),(11430,'pytest','#9708: pytester now requests a monkeypatch fixture instead of creating one internally. This solves some issues with tests that involve pytest environment variables.','request monkeypatch fixture instead_of creating',0,'',''),(11431,'pytest','#9730: Malformed pyproject.toml files now produce a clearer error message.','produce clearer error message',0,'',''),(11432,'pytest','#9608: Fix invalid importing of importlib.readers in Python 3.9.','import  of importlib.readers',0,'',''),(11433,'pytest','#9610: Restore UnitTestFunction.obj to return unbound rather than bound method.\nFixes a crash during a failed teardown in unittest TestCases with non-default __init__.\nRegressed in pytest 7.0.0.','return unbound method',0,'',''),(11434,'pytest','#9610: Restore UnitTestFunction.obj to return unbound rather than bound method.\nFixes a crash during a failed teardown in unittest TestCases with non-default __init__.\nRegressed in pytest 7.0.0.','fix crash during failed teardown',0,'',''),(11435,'pytest','#9636: The pythonpath plugin was renamed to python_path. This avoids a conflict with the pytest-pythonpath plugin.','rename pythonpath plugin to python_path',0,'',''),(11436,'pytest','#9643: Delay issuing a PytestWarning about diamond inheritance involving Item and\nCollector so it can be filtered using standard warning filters.','use standard warning filters',0,'',''),(11437,'pytest','#9488: If custom subclasses of nodes like pytest.Item override the\n__init__ method, they should take **kwargs. See\nConstructors of custom pytest.Node subclasses should take **kwargs for details.','override __init__ method',0,'',''),(11438,'pytest','Note that a deprection warning is only emitted when there is a conflict in the\narguments pytest expected to pass. This deprecation was already part of pytest\n7.0.0rc1 but wasn’t documented.','document deprecation',0,'',''),(11439,'pytest','#9404: Added extra documentation on alternatives to common misuses of pytest.warns(None) ahead of its deprecation.','add extra documentation to common misuses',0,'',''),(11440,'pytest','#9404: Added extra documentation on alternatives to common misuses of pytest.warns(None) ahead of its deprecation.','add extra documentation on alternatives',0,'',''),(11441,'pytest','#9505: Clarify where the configuration files are located. To avoid confusions documentation mentions\nthat configuration file is located in the root of the repository.','locate configuration files',0,'',''),(11442,'pytest','#9505: Clarify where the configuration files are located. To avoid confusions documentation mentions\nthat configuration file is located in the root of the repository.','locate clarify',0,'',''),(11443,'pytest','#9505: Clarify where the configuration files are located. To avoid confusions documentation mentions\nthat configuration file is located in the root of the repository.','locate configuration file in root',0,'',''),(11444,'pytest','#7259: The Node.reportinfo() function first return value type has been expanded from py.path.local | str to os.PathLike[str] | str.','expand first return value type from py.path.local | str',0,'',''),(11445,'pytest','#7259: The Node.reportinfo() function first return value type has been expanded from py.path.local | str to os.PathLike[str] | str.','expand first return value type to os.PathLikestr | str',0,'',''),(11446,'pytest','Most plugins which refer to reportinfo() only define it as part of a custom pytest.Item implementation.\nSince py.path.local is a os.PathLike[str], these plugins are unaffacted.','define  as part',0,'',''),(11447,'pytest','Plugins and users which call reportinfo(), use the first return value and interact with it as a py.path.local, would need to adjust by calling py.path.local(fspath).\nAlthough preferably, avoid the legacy py.path.local and use pathlib.Path, or use item.location or item.path, instead.','call reportinfo()',0,'',''),(11448,'pytest','Plugins and users which call reportinfo(), use the first return value and interact with it as a py.path.local, would need to adjust by calling py.path.local(fspath).\nAlthough preferably, avoid the legacy py.path.local and use pathlib.Path, or use item.location or item.path, instead.','call plugins',0,'',''),(11449,'pytest','Plugins and users which call reportinfo(), use the first return value and interact with it as a py.path.local, would need to adjust by calling py.path.local(fspath).\nAlthough preferably, avoid the legacy py.path.local and use pathlib.Path, or use item.location or item.path, instead.','call users',0,'',''),(11450,'pytest','Plugins and users which call reportinfo(), use the first return value and interact with it as a py.path.local, would need to adjust by calling py.path.local(fspath).\nAlthough preferably, avoid the legacy py.path.local and use pathlib.Path, or use item.location or item.path, instead.','use first return value',0,'',''),(11451,'pytest','Plugins and users which call reportinfo(), use the first return value and interact with it as a py.path.local, would need to adjust by calling py.path.local(fspath).\nAlthough preferably, avoid the legacy py.path.local and use pathlib.Path, or use item.location or item.path, instead.','use plugins',0,'',''),(11452,'pytest','Plugins and users which call reportinfo(), use the first return value and interact with it as a py.path.local, would need to adjust by calling py.path.local(fspath).\nAlthough preferably, avoid the legacy py.path.local and use pathlib.Path, or use item.location or item.path, instead.','use users',0,'',''),(11453,'pytest','Plugins and users which call reportinfo(), use the first return value and interact with it as a py.path.local, would need to adjust by calling py.path.local(fspath).\nAlthough preferably, avoid the legacy py.path.local and use pathlib.Path, or use item.location or item.path, instead.','call py.path.local(fspath)',0,'',''),(11454,'pytest','Plugins and users which call reportinfo(), use the first return value and interact with it as a py.path.local, would need to adjust by calling py.path.local(fspath).\nAlthough preferably, avoid the legacy py.path.local and use pathlib.Path, or use item.location or item.path, instead.','adjust  by calling',0,'',''),(11455,'pytest','Plugins and users which call reportinfo(), use the first return value and interact with it as a py.path.local, would need to adjust by calling py.path.local(fspath).\nAlthough preferably, avoid the legacy py.path.local and use pathlib.Path, or use item.location or item.path, instead.','use pathlib.Path',0,'',''),(11456,'pytest','Plugins and users which call reportinfo(), use the first return value and interact with it as a py.path.local, would need to adjust by calling py.path.local(fspath).\nAlthough preferably, avoid the legacy py.path.local and use pathlib.Path, or use item.location or item.path, instead.','use item.path',0,'',''),(11457,'pytest','Plugins and users which call reportinfo(), use the first return value and interact with it as a py.path.local, would need to adjust by calling py.path.local(fspath).\nAlthough preferably, avoid the legacy py.path.local and use pathlib.Path, or use item.location or item.path, instead.','use item.location',0,'',''),(11458,'pytest','Note: pytest was not able to provide a deprecation period for this change.','provide deprecation period for change',0,'',''),(11459,'pytest','#8246: --version now writes version information to stdout rather than stderr.','write version information',0,'',''),(11460,'pytest','The workaround was introduced in #1281 in 2015, however since then\npyreadline seems to have gone unmaintained, is generating\nwarnings, and will stop working on Python 3.10.','generate warnings',0,'',''),(11461,'pytest','The workaround was introduced in #1281 in 2015, however since then\npyreadline seems to have gone unmaintained, is generating\nwarnings, and will stop working on Python 3.10.','introduce workaround',0,'',''),(11462,'pytest','#9061: Using pytest.approx() in a boolean context now raises an error hinting at the proper usage.','use pytest.approx() in boolean context',0,'',''),(11463,'pytest','#9061: Using pytest.approx() in a boolean context now raises an error hinting at the proper usage.','raise error',0,'',''),(11464,'pytest','It is apparently common for users to mistakenly use pytest.approx like this:','use pytest.approx',1,'https://docs.pytest.org/en/7.2.x/changelog.html',''),(11465,'pytest','The new error message helps catch those mistakes.','catch mistakes',0,'',''),(11466,'pytest','#9277: The pytest.Instance collector type has been removed.\nImporting pytest.Instance or _pytest.python.Instance returns a dummy type and emits a deprecation warning.\nSee The pytest.Instance collector for details.','remove pytest.Instance collector type',0,'',''),(11467,'pytest','#9277: The pytest.Instance collector type has been removed.\nImporting pytest.Instance or _pytest.python.Instance returns a dummy type and emits a deprecation warning.\nSee The pytest.Instance collector for details.','import pytest.Instance',0,'',''),(11468,'pytest','#9277: The pytest.Instance collector type has been removed.\nImporting pytest.Instance or _pytest.python.Instance returns a dummy type and emits a deprecation warning.\nSee The pytest.Instance collector for details.','import _pytest.python.Instance',0,'',''),(11469,'pytest','#9277: The pytest.Instance collector type has been removed.\nImporting pytest.Instance or _pytest.python.Instance returns a dummy type and emits a deprecation warning.\nSee The pytest.Instance collector for details.','return dummy type',0,'',''),(11470,'pytest','Following our plan to remove deprecated features with as little disruption as\npossible, all warnings of type PytestRemovedIn7Warning now generate errors\ninstead of warning messages by default.','remove deprecated features as little disruption possible',0,'',''),(11471,'pytest','Following our plan to remove deprecated features with as little disruption as\npossible, all warnings of type PytestRemovedIn7Warning now generate errors\ninstead of warning messages by default.','generate errors instead_of warning messages',0,'',''),(11472,'pytest','Following our plan to remove deprecated features with as little disruption as\npossible, all warnings of type PytestRemovedIn7Warning now generate errors\ninstead of warning messages by default.','generate errors following plan',0,'',''),(11473,'pytest','Following our plan to remove deprecated features with as little disruption as\npossible, all warnings of type PytestRemovedIn7Warning now generate errors\ninstead of warning messages by default.','generate errors by default',0,'',''),(11474,'pytest','The affected features will be effectively removed in pytest 7.1, so please consult the\nDeprecations and Removals section in the docs for directions on how to update existing code.','update existing code',0,'',''),(11475,'pytest','The affected features will be effectively removed in pytest 7.1, so please consult the\nDeprecations and Removals section in the docs for directions on how to update existing code.','remove affected features',0,'',''),(11476,'pytest','In the pytest 7.0.X series, it is possible to change the errors back into warnings as a\nstopgap measure by adding this to your pytest.ini file:','add  to pytest.ini file',0,'',''),(11477,'pytest','But this will stop working when pytest 7.1 is released.','release pytest',0,'',''),(11478,'pytest','If you have concerns about the removal of a specific feature, please add a\ncomment to issue #9308.','add comment',0,'',''),(11479,'pytest','This is an unfortunate artifact due to historical reasons, which should be\nresolved in future versions as we slowly get rid of the py\ndependency (see issue #9283 for a longer discussion).','resolve historical reasons in future versions',0,'',''),(11480,'pytest','#8242: Raising unittest.SkipTest to skip collection of tests during the\npytest collection phase is deprecated. Use pytest.skip() instead.','skip collection of tests',0,'',''),(11481,'pytest','#8242: Raising unittest.SkipTest to skip collection of tests during the\npytest collection phase is deprecated. Use pytest.skip() instead.','skip collection during pytest collection phase',0,'',''),(11482,'pytest','#8242: Raising unittest.SkipTest to skip collection of tests during the\npytest collection phase is deprecated. Use pytest.skip() instead.','use pytest.skip()',0,'',''),(11483,'pytest','Note: This deprecation only relates to using unittest.SkipTest during test\ncollection. You are probably not doing that. Ordinary usage of\nunittest.SkipTest / unittest.TestCase.skipTest() /\nunittest.skip() in unittest test cases is fully supported.','use unittest.SkipTest during test collection',0,'',''),(11484,'pytest','#8447: Defining a custom pytest node type which is both an pytest.Item and a pytest.Collector (e.g. pytest.File) now issues a warning.\nIt was never sanely supported and triggers hard to debug errors.','define custom pytest node type',0,'',''),(11485,'pytest','#8592: pytest_cmdline_preparse has been officially deprecated.  It will be removed in a future release.  Use pytest_load_initial_conftests instead.','remove  in future release',0,'',''),(11486,'pytest','#8592: pytest_cmdline_preparse has been officially deprecated.  It will be removed in a future release.  Use pytest_load_initial_conftests instead.','use pytest_load_initial_conftests',0,'',''),(11487,'pytest','#8948: pytest.skip(msg=...), pytest.fail(msg=...) and pytest.exit(msg=...)\nsignatures now accept a reason argument instead of msg.  Using msg still works, but is deprecated and will be removed in a future release.','use msg',0,'',''),(11488,'pytest','#8948: pytest.skip(msg=...), pytest.fail(msg=...) and pytest.exit(msg=...)\nsignatures now accept a reason argument instead of msg.  Using msg still works, but is deprecated and will be removed in a future release.','remove  in future release',0,'',''),(11489,'pytest','This was changed for consistency with pytest.mark.skip and  pytest.mark.xfail which both accept\nreason as an argument.','change  for consistency',0,'',''),(11490,'pytest','The path property of _pytest.code.Code returns Path instead of py.path.local.','return path instead_of py.path.local',0,'',''),(11491,'pytest','The path property of _pytest.code.TracebackEntry returns Path instead of py.path.local.','return path instead_of py.path.local',0,'',''),(11492,'pytest','#5196: Tests are now ordered by definition order in more cases.','order tests',0,'',''),(11493,'pytest','In a class hierarchy, tests from base classes are now consistently ordered before tests defined on their subclasses (reverse MRO order).','order tests in class hierarchy',0,'',''),(11494,'pytest','In a class hierarchy, tests from base classes are now consistently ordered before tests defined on their subclasses (reverse MRO order).','order tests before tests',0,'',''),(11495,'pytest','In a class hierarchy, tests from base classes are now consistently ordered before tests defined on their subclasses (reverse MRO order).','order tests from base classes',0,'',''),(11496,'pytest','In a class hierarchy, tests from base classes are now consistently ordered before tests defined on their subclasses (reverse MRO order).','define  on subclasses',0,'',''),(11497,'pytest','#7132: Added two environment variables PYTEST_THEME and PYTEST_THEME_MODE to let the users customize the pygments theme used.','customize pygments theme',0,'',''),(11498,'pytest','#7259: Added cache.mkdir(), which is similar to the existing cache.makedir(),\nbut returns a pathlib.Path instead of a legacy py.path.local.','return pathlib.Path instead_of legacy py.path.local',0,'',''),(11499,'pytest','#7259: Added cache.mkdir(), which is similar to the existing cache.makedir(),\nbut returns a pathlib.Path instead of a legacy py.path.local.','return added cache.mkdir() instead_of legacy py.path.local',0,'',''),(11500,'pytest','Added a paths type to parser.addini(),\nas in parser.addini(\"mypaths\", \"my paths\", type=\"paths\"),\nwhich is similar to the existing pathlist,\nbut returns a list of pathlib.Path instead of legacy py.path.local.','add paths type to parser.addini()',0,'',''),(11501,'pytest','Added a paths type to parser.addini(),\nas in parser.addini(\"mypaths\", \"my paths\", type=\"paths\"),\nwhich is similar to the existing pathlist,\nbut returns a list of pathlib.Path instead of legacy py.path.local.','return list of pathlib.Path',0,'',''),(11502,'pytest','#7469: The types of objects used in pytest’s API are now exported so they may be used in type annotations.','use  in API',0,'',''),(11503,'pytest','#7469: The types of objects used in pytest’s API are now exported so they may be used in type annotations.','use  in type annotations',0,'',''),(11504,'pytest','pytest.CallInfo for the CallInfo type passed to various hooks.','pass  to various hooks',0,'',''),(11505,'pytest','pytest.ExceptionInfo for the ExceptionInfo type returned from pytest.raises() and passed to various hooks.','return  from pytest.raises()',0,'',''),(11506,'pytest','pytest.ExceptionInfo for the ExceptionInfo type returned from pytest.raises() and passed to various hooks.','pass  to various hooks',0,'',''),(11507,'pytest','pytest.Parser for the Parser type passed to the pytest_addoption hook.','pass  to pytest_addoption hook',0,'',''),(11508,'pytest','pytest.OptionGroup for the OptionGroup type returned from the parser.addgroup method.','return  from parser.addgroup method',0,'',''),(11509,'pytest','pytest.HookRecorder for the HookRecorder type returned from Pytester.','return  from pytester',0,'',''),(11510,'pytest','pytest.RecordedHookCall for the RecordedHookCall type returned from HookRecorder.','return  from HookRecorder',0,'',''),(11511,'pytest','pytest.RunResult for the RunResult type returned from Pytester.','return  from pytester',0,'',''),(11512,'pytest','pytest.LineMatcher for the LineMatcher type used in RunResult and others.','use  in RunResult',0,'',''),(11513,'pytest','pytest.LineMatcher for the LineMatcher type used in RunResult and others.','use  in others',0,'',''),(11514,'pytest','pytest.TestReport for the TestReport type used in various hooks.','use  in various hooks',0,'',''),(11515,'pytest','pytest.CollectReport for the CollectReport type used in various hooks.','use  in various hooks',0,'',''),(11516,'pytest','#8144: The following hooks now receive an additional pathlib.Path argument, equivalent to an existing py.path.local argument:','receive additional pathlib.Path argument equivalent',0,'',''),(11517,'pytest','#8251: Implement Node.path as a pathlib.Path. Both the old fspath and this new attribute gets set no matter whether path or fspath (deprecated) is passed to the constructor. It is a replacement for the fspath attribute (which represents the same path as py.path.local). While fspath is not deprecated yet\ndue to the ongoing migration of methods like reportinfo(), we expect to deprecate it in a future release.','pass fspath to constructor',0,'',''),(11518,'pytest','#8251: Implement Node.path as a pathlib.Path. Both the old fspath and this new attribute gets set no matter whether path or fspath (deprecated) is passed to the constructor. It is a replacement for the fspath attribute (which represents the same path as py.path.local). While fspath is not deprecated yet\ndue to the ongoing migration of methods like reportinfo(), we expect to deprecate it in a future release.','pass path to constructor',0,'',''),(11519,'pytest','#8251: Implement Node.path as a pathlib.Path. Both the old fspath and this new attribute gets set no matter whether path or fspath (deprecated) is passed to the constructor. It is a replacement for the fspath attribute (which represents the same path as py.path.local). While fspath is not deprecated yet\ndue to the ongoing migration of methods like reportinfo(), we expect to deprecate it in a future release.','set old fspath',0,'',''),(11520,'pytest','#8251: Implement Node.path as a pathlib.Path. Both the old fspath and this new attribute gets set no matter whether path or fspath (deprecated) is passed to the constructor. It is a replacement for the fspath attribute (which represents the same path as py.path.local). While fspath is not deprecated yet\ndue to the ongoing migration of methods like reportinfo(), we expect to deprecate it in a future release.','set new attribute',0,'',''),(11521,'pytest','Fixture location path printed with the fixture name.','print  with fixture name',0,'',''),(11522,'pytest','First section of the fixture’s docstring printed under the fixture name.','print  under fixture name',0,'',''),(11523,'pytest','Whole of fixture’s docstring printed under the fixture name using --verbose option.','print  under fixture name',0,'',''),(11524,'pytest','#8920: Added pytest.Stash, a facility for plugins to store their data on Config and Nodes in a type-safe and conflict-free manner.\nSee Storing data on items across hook functions for details.','store data on config',0,'',''),(11525,'pytest','#8920: Added pytest.Stash, a facility for plugins to store their data on Config and Nodes in a type-safe and conflict-free manner.\nSee Storing data on items across hook functions for details.','store data on node',0,'',''),(11526,'pytest','#9023: Full diffs are now always shown for equality assertions of iterables when\nCI or BUILD_NUMBER is found in the environment, even when -v isn’t\nused.','show full diffs for equality assertions',0,'',''),(11527,'pytest','#9023: Full diffs are now always shown for equality assertions of iterables when\nCI or BUILD_NUMBER is found in the environment, even when -v isn’t\nused.','find CI in environment',0,'',''),(11528,'pytest','#9023: Full diffs are now always shown for equality assertions of iterables when\nCI or BUILD_NUMBER is found in the environment, even when -v isn’t\nused.','find BUILD_NUMBER in environment',0,'',''),(11529,'pytest','#9023: Full diffs are now always shown for equality assertions of iterables when\nCI or BUILD_NUMBER is found in the environment, even when -v isn’t\nused.','use v',0,'',''),(11530,'pytest','#9114: Added pythonpath setting that adds listed paths to sys.path for the duration of the test session. If you currently use the pytest-pythonpath or pytest-srcpaths plugins, you should be able to replace them with built-in pythonpath setting.','add listed paths to sys.path',0,'',''),(11531,'pytest','#9114: Added pythonpath setting that adds listed paths to sys.path for the duration of the test session. If you currently use the pytest-pythonpath or pytest-srcpaths plugins, you should be able to replace them with built-in pythonpath setting.','add added pythonpath setting to sys.path',0,'',''),(11532,'pytest','#9114: Added pythonpath setting that adds listed paths to sys.path for the duration of the test session. If you currently use the pytest-pythonpath or pytest-srcpaths plugins, you should be able to replace them with built-in pythonpath setting.','use pytest-pythonpath pytest-srcpaths plugins',0,'',''),(11533,'pytest','#9114: Added pythonpath setting that adds listed paths to sys.path for the duration of the test session. If you currently use the pytest-pythonpath or pytest-srcpaths plugins, you should be able to replace them with built-in pythonpath setting.','replace  with built-in pythonpath setting',0,'',''),(11534,'pytest','#7480: A deprecation scheduled to be removed in a major version X (e.g. pytest 7, 8, 9, …) now uses warning category PytestRemovedInXWarning,\na subclass of PytestDeprecationWarning,\ninstead of PytestDeprecationWarning directly.','remove  in major version',0,'',''),(11535,'pytest','#7480: A deprecation scheduled to be removed in a major version X (e.g. pytest 7, 8, 9, …) now uses warning category PytestRemovedInXWarning,\na subclass of PytestDeprecationWarning,\ninstead of PytestDeprecationWarning directly.','use major version',0,'',''),(11536,'pytest','Previously pytest would show an internal traceback, which besides being ugly sometimes would hide the cause\nof the problem (for example an ImportError while importing a specific warning type).','show internal traceback',0,'',''),(11537,'pytest','Previously pytest would show an internal traceback, which besides being ugly sometimes would hide the cause\nof the problem (for example an ImportError while importing a specific warning type).','hide cause',0,'',''),(11538,'pytest','Previously pytest would show an internal traceback, which besides being ugly sometimes would hide the cause\nof the problem (for example an ImportError while importing a specific warning type).','hide internal traceback',0,'',''),(11539,'pytest','However, in some cases the longer output helps, or is even crucial, to diagnose a failure. Using -v will\nnow increase the truncation threshold to 2400 characters, and -vv or higher will disable truncation entirely.','disable truncation',0,'',''),(11540,'pytest','#8803: It is now possible to add colors to custom log levels on cli log.','add colors to custom log levels',0,'',''),(11541,'pytest','By using add_color_level from a pytest_configure hook, colors can be added:','use add_color_level from pytest_configure hook',1,'https://docs.pytest.org/en/7.2.x/changelog.html',''),(11542,'pytest','By using add_color_level from a pytest_configure hook, colors can be added:','add colors',1,'https://docs.pytest.org/en/7.2.x/changelog.html',''),(11543,'pytest','#8822: When showing fixture paths in --fixtures or --fixtures-by-test, fixtures coming from pytest itself now display an elided path, rather than the full path to the file in the site-packages directory.','show fixture paths',0,'',''),(11544,'pytest','#8822: When showing fixture paths in --fixtures or --fixtures-by-test, fixtures coming from pytest itself now display an elided path, rather than the full path to the file in the site-packages directory.','display elided path to file',0,'',''),(11545,'pytest','#8822: When showing fixture paths in --fixtures or --fixtures-by-test, fixtures coming from pytest itself now display an elided path, rather than the full path to the file in the site-packages directory.','display full path to file',0,'',''),(11546,'pytest','#8898: Complex numbers are now treated like floats and integers when generating parameterization IDs.','generate parameterization ids',0,'',''),(11547,'pytest','#9062: --stepwise-skip now implicitly enables --stepwise and can be used on its own.','use stepwise-skip',0,'',''),(11548,'pytest','#9205: pytest.Cache.set() now preserves key order when saving dicts.','save dicts',0,'',''),(11549,'pytest','#7124: Fixed an issue where __main__.py would raise an ImportError when --doctest-modules was provided.','fix issue',0,'',''),(11550,'pytest','#7124: Fixed an issue where __main__.py would raise an ImportError when --doctest-modules was provided.','raise ImportError',0,'',''),(11551,'pytest','#7124: Fixed an issue where __main__.py would raise an ImportError when --doctest-modules was provided.','provide doctest-modules',0,'',''),(11552,'pytest','#8061: Fixed failing staticmethod test cases if they are inherited from a parent test class.','inherit  from parent test class',0,'',''),(11553,'pytest','#8258: Fixed issue where pytest’s faulthandler support would not dump traceback on crashes\nif the faulthandler module was already enabled during pytest startup (using\npython -X dev -m pytest for example).','enable faulthandler module during pytest startup',0,'',''),(11554,'pytest','#8317: Fixed an issue where illegal directory characters derived from getpass.getuser() raised an OSError.','raise OSError',0,'',''),(11555,'pytest','#8317: Fixed an issue where illegal directory characters derived from getpass.getuser() raised an OSError.','raise fixed',0,'',''),(11556,'pytest','#8377: The test selection options pytest -k and pytest -m now support matching\nnames containing forward slash (/) characters.','support matching names',0,'',''),(11557,'pytest','#8384: The @pytest.mark.skip decorator now correctly handles its arguments. When the reason argument is accidentally given both positional and as a keyword (e.g. because it was confused with skipif), a TypeError now occurs. Before, such tests were silently skipped, and the positional argument ignored. Additionally, reason is now documented correctly as positional or keyword (rather than keyword-only).','handle arguments',0,'',''),(11558,'pytest','#8384: The @pytest.mark.skip decorator now correctly handles its arguments. When the reason argument is accidentally given both positional and as a keyword (e.g. because it was confused with skipif), a TypeError now occurs. Before, such tests were silently skipped, and the positional argument ignored. Additionally, reason is now documented correctly as positional or keyword (rather than keyword-only).','document reason',0,'',''),(11559,'pytest','#8394: Use private names for internal fixtures that handle classic setup/teardown so that they don’t show up with the default --fixtures invocation (but they still show up with --fixtures -v).','handle classic setup/teardown for internal fixtures',0,'',''),(11560,'pytest','#8394: Use private names for internal fixtures that handle classic setup/teardown so that they don’t show up with the default --fixtures invocation (but they still show up with --fixtures -v).','handle use private names for internal fixtures',0,'',''),(11561,'pytest','#8456: The required_plugins config option now works correctly when pre-releases of plugins are installed, rather than falsely claiming that those plugins aren’t installed at all.','install pre-releases of plugins',0,'',''),(11562,'pytest','#8456: The required_plugins config option now works correctly when pre-releases of plugins are installed, rather than falsely claiming that those plugins aren’t installed at all.','install pre-releases than claiming',0,'',''),(11563,'pytest','#8456: The required_plugins config option now works correctly when pre-releases of plugins are installed, rather than falsely claiming that those plugins aren’t installed at all.','install plugins',0,'',''),(11564,'pytest','#8464: -c  file> now also properly defines rootdir as the directory that contains  file>.','define rootdir as directory',0,'',''),(11565,'pytest','#8503: pytest.MonkeyPatch.syspath_prepend() no longer fails when\nsetuptools is not installed.\nIt now only calls pkg_resources.fixup_namespace_packages() if\npkg_resources was previously imported, because it is not needed otherwise.','call pkg_resources.fixup_namespace_packages()',0,'',''),(11566,'pytest','#8548: Introduce fix to handle precision width in log-cli-format in turn to fix output coloring for certain formats.','handle precision width in turn',0,'',''),(11567,'pytest','#8548: Introduce fix to handle precision width in log-cli-format in turn to fix output coloring for certain formats.','handle precision width in log-cli-format',0,'',''),(11568,'pytest','#8548: Introduce fix to handle precision width in log-cli-format in turn to fix output coloring for certain formats.','fix output coloring for certain formats',0,'',''),(11569,'pytest','#8983: The test selection options pytest -k and pytest -m now support matching names containing backslash (\\) characters.\nBackslashes are treated literally, not as escape characters (the values being matched against are already escaped).','support matching names',0,'',''),(11570,'pytest','#9077: Fixed confusing error message when request.fspath / request.path was accessed from a session-scoped fixture.','access request.fspath / request.path from session-scoped fixture',0,'',''),(11571,'pytest','#9131: Fixed the URL used by --pastebin to use bpa.st.','fix URL',0,'',''),(11572,'pytest','#9131: Fixed the URL used by --pastebin to use bpa.st.','use bpa.st',0,'',''),(11573,'pytest','#9163: The end line number and end column offset are now properly set for rewritten assert statements.','set  for rewritten assert statements',0,'',''),(11574,'pytest','#9272: The nose compatibility module-level fixtures setup() and teardown() are now only called once per module, instead of for each test function.\nThey are now called even if object-level setup/teardown is defined.','call module-level fixtures setup() for test function',0,'',''),(11575,'pytest','#9272: The nose compatibility module-level fixtures setup() and teardown() are now only called once per module, instead of for each test function.\nThey are now called even if object-level setup/teardown is defined.','call module-level fixtures setup() per module',0,'',''),(11576,'pytest','#9272: The nose compatibility module-level fixtures setup() and teardown() are now only called once per module, instead of for each test function.\nThey are now called even if object-level setup/teardown is defined.','call teardown() for test function',0,'',''),(11577,'pytest','#9272: The nose compatibility module-level fixtures setup() and teardown() are now only called once per module, instead of for each test function.\nThey are now called even if object-level setup/teardown is defined.','call teardown() per module',0,'',''),(11578,'pytest','#9272: The nose compatibility module-level fixtures setup() and teardown() are now only called once per module, instead of for each test function.\nThey are now called even if object-level setup/teardown is defined.','call nose compatibility for test function',0,'',''),(11579,'pytest','#9272: The nose compatibility module-level fixtures setup() and teardown() are now only called once per module, instead of for each test function.\nThey are now called even if object-level setup/teardown is defined.','call nose compatibility per module',0,'',''),(11580,'pytest','#9272: The nose compatibility module-level fixtures setup() and teardown() are now only called once per module, instead of for each test function.\nThey are now called even if object-level setup/teardown is defined.','define object-level setup / teardown',0,'',''),(11581,'pytest','#5105: Add automatically generated Plugin List. The list is updated on a periodic schedule.','generate plugin List',0,'',''),(11582,'pytest','#5105: Add automatically generated Plugin List. The list is updated on a periodic schedule.','update  on periodic schedule',0,'',''),(11583,'pytest','#9210: Remove incorrect docs about confcutdir being a configuration option: it can only be set through the --confcutdir command-line option.','remove incorrect docs about confcutdir',0,'',''),(11584,'pytest','#9341: Various methods commonly used for Working with non-python tests are now correctly documented in the reference docs. They were undocumented previously.','use  with non-python tests',0,'',''),(11585,'pytest','#9341: Various methods commonly used for Working with non-python tests are now correctly documented in the reference docs. They were undocumented previously.','use  for working',0,'',''),(11586,'pytest','#9341: Various methods commonly used for Working with non-python tests are now correctly documented in the reference docs. They were undocumented previously.','document  in reference docs',0,'',''),(11587,'pytest','#8133: Migrate to setuptools_scm 6.x to use SETUPTOOLS_SCM_PRETEND_VERSION_FOR_PYTEST for more robust release tooling.','use SETUPTOOLS_SCM_PRETEND_VERSION_FOR_PYTEST for robust release tooling',0,'',''),(11588,'pytest','The _pytest.code.getfslineno() function returns Path instead of py.path.local.','return path instead_of py.path.local',0,'',''),(11589,'pytest','#8248: Internal Restructure: let python.PyObjMixin inherit from nodes.Node to carry over typing information.','inherit  from nodes.Node',0,'',''),(11590,'pytest','#8432: Improve error message when pytest.skip() is used at module level without passing allow_module_level=True.','use pytest.skip() at module level',0,'',''),(11591,'pytest','#8432: Improve error message when pytest.skip() is used at module level without passing allow_module_level=True.','use pytest.skip() without passing',0,'',''),(11592,'pytest','#8913: The private CallSpec2._arg2scopenum attribute has been removed after an internal refactoring.','remove private CallSpec2._arg2scopenum attribute after internal refactoring',0,'',''),(11593,'pytest','#9225: Changed the command used to create sdist and wheel artifacts: using the build package instead of setup.py.','change command',0,'',''),(11594,'pytest','#9225: Changed the command used to create sdist and wheel artifacts: using the build package instead of setup.py.','create sdist wheel artifacts',0,'',''),(11595,'pytest','issue #8494: Python 3.10 is now supported.','support Python',0,'',''),(11596,'pytest','issue #8414: pytest used to create directories under /tmp with world-readable\npermissions. This means that any user in the system was able to read\ninformation written by tests in temporary directories (such as those created by\nthe tmp_path/tmpdir fixture). Now the directories are created with\nprivate permissions.','create directories with private permissions',0,'',''),(11597,'pytest','pytest used to silently use a pre-existing /tmp/pytest-of- directory,\neven if owned by another user. This means another user could pre-create such a\ndirectory and gain control of another user’s temporary directory. Now such a\ncondition results in an error.','use pre-existing /tmp/pytest-of directory',0,'',''),(11598,'pytest','issue #8152: Fixed “()” being shown as a skip reason in the verbose test summary line when the reason is empty.','show  as skip reason',0,'',''),(11599,'pytest','issue #8249: Fix the faulthandler plugin for occasions when running with twisted.logger and using pytest --capture=no.','fix faulthandler plugin for occasions',0,'',''),(11600,'pytest','issue #8249: Fix the faulthandler plugin for occasions when running with twisted.logger and using pytest --capture=no.','use pytest',0,'',''),(11601,'pytest','issue #8249: Fix the faulthandler plugin for occasions when running with twisted.logger and using pytest --capture=no.','run  with twisted.logger',0,'',''),(11602,'pytest','issue #7678: Fixed bug where ImportPathMismatchError would be raised for files compiled in\nthe host and loaded later from an UNC mounted path (Windows).','raise ImportPathMismatchError for files',0,'',''),(11603,'pytest','issue #7678: Fixed bug where ImportPathMismatchError would be raised for files compiled in\nthe host and loaded later from an UNC mounted path (Windows).','raise fixed bug for files',0,'',''),(11604,'pytest','issue #7678: Fixed bug where ImportPathMismatchError would be raised for files compiled in\nthe host and loaded later from an UNC mounted path (Windows).','compile  in host',0,'',''),(11605,'pytest','issue #7678: Fixed bug where ImportPathMismatchError would be raised for files compiled in\nthe host and loaded later from an UNC mounted path (Windows).','load  from UNC',0,'',''),(11606,'pytest','issue #8132: Fixed regression in approx: in 6.2.0 approx no longer raises\nTypeError when dealing with non-numeric types, falling back to normal comparison.\nBefore 6.2.0, array types like tf.DeviceArray fell through to the scalar case,\nand happened to compare correctly to a scalar if they had only one element.\nAfter 6.2.0, these types began failing, because they inherited neither from\nstandard Python number hierarchy nor from numpy.ndarray.','raise TypeError',0,'',''),(11607,'pytest','issue #8132: Fixed regression in approx: in 6.2.0 approx no longer raises\nTypeError when dealing with non-numeric types, falling back to normal comparison.\nBefore 6.2.0, array types like tf.DeviceArray fell through to the scalar case,\nand happened to compare correctly to a scalar if they had only one element.\nAfter 6.2.0, these types began failing, because they inherited neither from\nstandard Python number hierarchy nor from numpy.ndarray.','compare  to scalar',0,'',''),(11608,'pytest','approx now converts arguments to numpy.ndarray if they expose the array\nprotocol and are not scalars. This treats array-like objects like numpy arrays,\nregardless of size.','convert arguments to numpy.ndarray',0,'',''),(11609,'pytest','approx now converts arguments to numpy.ndarray if they expose the array\nprotocol and are not scalars. This treats array-like objects like numpy arrays,\nregardless of size.','expose array protocol',0,'',''),(11610,'pytest','issue #7808: pytest now supports python3.6+ only.','support +',0,'',''),(11611,'pytest','issue #7988: The @pytest.yield_fixture decorator/function is now deprecated. Use pytest.fixture() instead.','use pytest.fixture()',0,'',''),(11612,'pytest','This is part of the movement to use pathlib.Path objects internally, in order to remove the dependency to py in the future.','use pathlib.Path objects',0,'',''),(11613,'pytest','This is part of the movement to use pathlib.Path objects internally, in order to remove the dependency to py in the future.','remove dependency',0,'',''),(11614,'pytest','issue #7695: A new hook was added, pytest_markeval_namespace which should return a dictionary.\nThis dictionary will be used to augment the “global” variables available to evaluate skipif/xfail/xpass markers.','add pytest_markeval_namespace',1,'https://docs.pytest.org/en/7.2.x/changelog.html',''),(11615,'pytest','issue #7695: A new hook was added, pytest_markeval_namespace which should return a dictionary.\nThis dictionary will be used to augment the “global” variables available to evaluate skipif/xfail/xpass markers.','add new hook',1,'https://docs.pytest.org/en/7.2.x/changelog.html',''),(11616,'pytest','issue #7695: A new hook was added, pytest_markeval_namespace which should return a dictionary.\nThis dictionary will be used to augment the “global” variables available to evaluate skipif/xfail/xpass markers.','return dictionary',1,'https://docs.pytest.org/en/7.2.x/changelog.html',''),(11617,'pytest','issue #7695: A new hook was added, pytest_markeval_namespace which should return a dictionary.\nThis dictionary will be used to augment the “global” variables available to evaluate skipif/xfail/xpass markers.','return pytest_markeval_namespace',1,'https://docs.pytest.org/en/7.2.x/changelog.html',''),(11618,'pytest','issue #7695: A new hook was added, pytest_markeval_namespace which should return a dictionary.\nThis dictionary will be used to augment the “global” variables available to evaluate skipif/xfail/xpass markers.','use dictionary',1,'https://docs.pytest.org/en/7.2.x/changelog.html',''),(11619,'pytest','issue #8006: It is now possible to construct a MonkeyPatch object directly as pytest.MonkeyPatch(),\nin cases when the monkeypatch fixture cannot be used. Previously some users imported it\nfrom the private _pytest.monkeypatch.MonkeyPatch namespace.','import  from private _pytest.monkeypatch.MonkeyPatch namespace',0,'',''),(11620,'pytest','Additionally, MonkeyPatch.context is now a classmethod,\nand can be used as with MonkeyPatch.context() as mp: .... This is the recommended way to use\nMonkeyPatch directly, since unlike the monkeypatch fixture, an instance created directly\nis not undo()-ed automatically.','use MonkeyPatch.context with MonkeyPatch.context()',0,'',''),(11621,'pytest','Additionally, MonkeyPatch.context is now a classmethod,\nand can be used as with MonkeyPatch.context() as mp: .... This is the recommended way to use\nMonkeyPatch directly, since unlike the monkeypatch fixture, an instance created directly\nis not undo()-ed automatically.','use MonkeyPatch',0,'',''),(11622,'pytest','issue #1265: Added an __str__ implementation to the LineMatcher class which is returned from pytester.run_pytest().stdout and similar. It returns the entire output, like the existing str() method.','add __str__ implementation to LineMatcher class',0,'',''),(11623,'pytest','issue #1265: Added an __str__ implementation to the LineMatcher class which is returned from pytester.run_pytest().stdout and similar. It returns the entire output, like the existing str() method.','return  from pytester.run_pytest().stdout',0,'',''),(11624,'pytest','issue #1265: Added an __str__ implementation to the LineMatcher class which is returned from pytester.run_pytest().stdout and similar. It returns the entire output, like the existing str() method.','return entire output like existing str() method',0,'',''),(11625,'pytest','issue #2044: Verbose mode now shows the reason that a test was skipped in the test’s terminal line after the “SKIPPED”, “XFAIL” or “XPASS”.','show reason',0,'',''),(11626,'pytest','issue #2044: Verbose mode now shows the reason that a test was skipped in the test’s terminal line after the “SKIPPED”, “XFAIL” or “XPASS”.','skip test in terminal line',0,'',''),(11627,'pytest','issue #2044: Verbose mode now shows the reason that a test was skipped in the test’s terminal line after the “SKIPPED”, “XFAIL” or “XPASS”.','skip test after SKIPPED',0,'',''),(11628,'pytest','issue #2044: Verbose mode now shows the reason that a test was skipped in the test’s terminal line after the “SKIPPED”, “XFAIL” or “XPASS”.','skip test after XFAIL',0,'',''),(11629,'pytest','issue #2044: Verbose mode now shows the reason that a test was skipped in the test’s terminal line after the “SKIPPED”, “XFAIL” or “XPASS”.','skip test after XPASS',0,'',''),(11630,'pytest','issue #7469 The types of builtin pytest fixtures are now exported so they may be used in type annotations of test functions.\nThe newly-exported types are:','use  in type annotations',0,'',''),(11631,'pytest','issue #7527: When a comparison between namedtuple instances of the same type fails, pytest now shows the differing field names (possibly nested) instead of their indexes.','show differing field names instead_of indexes',0,'',''),(11632,'pytest','issue #7701: Improved reporting when using --collected-only. It will now show the number of collected tests in the summary stats.','show number in summary stats',0,'',''),(11633,'pytest','issue #7701: Improved reporting when using --collected-only. It will now show the number of collected tests in the summary stats.','show number of collected tests',0,'',''),(11634,'pytest','issue #7710: Use strict equality comparison for non-numeric types in pytest.approx() instead of\nraising TypeError.','raise TypeError',0,'',''),(11635,'pytest','issue #8023: Added \'node_modules\' to default value for norecursedirs.','add node_modules for norecursedirs',0,'',''),(11636,'pytest','issue #8023: Added \'node_modules\' to default value for norecursedirs.','add node_modules to default value',0,'',''),(11637,'pytest','issue #8032: doClassCleanups (introduced in unittest in Python and 3.8) is now called appropriately.','call doClassCleanups',0,'',''),(11638,'pytest','issue #4824: Fixed quadratic behavior and improved performance of collection of items using autouse fixtures and xunit fixtures.','use autouse fixtures',0,'',''),(11639,'pytest','issue #4824: Fixed quadratic behavior and improved performance of collection of items using autouse fixtures and xunit fixtures.','use xunit fixtures',0,'',''),(11640,'pytest','issue #7758: Fixed an issue where some files in packages are getting lost from --lf even though they contain tests that failed. Regressed in pytest 5.4.0.','fix issue',0,'',''),(11641,'pytest','issue #7911: Directories created by by tmp_path and tmpdir are now considered stale after 3 days without modification (previous value was 3 hours) to avoid deleting directories still in use in long running test suites.','delete directories in use',0,'',''),(11642,'pytest','issue #7911: Directories created by by tmp_path and tmpdir are now considered stale after 3 days without modification (previous value was 3 hours) to avoid deleting directories still in use in long running test suites.','run test suites',0,'',''),(11643,'pytest','issue #7951: Fixed handling of recursive symlinks when collecting tests.','handle  of recursive symlinks',0,'',''),(11644,'pytest','issue #8016: Fixed only one doctest being collected when using pytest --doctest-modules path/to/an/__init__.py.','fix doctest',0,'',''),(11645,'pytest','issue #8016: Fixed only one doctest being collected when using pytest --doctest-modules path/to/an/__init__.py.','use pytest',0,'',''),(11646,'pytest','issue #7429: Add more information and use cases about skipping doctests.','add more information about skipping',0,'',''),(11647,'pytest','issue #7429: Add more information and use cases about skipping doctests.','add use cases about skipping',0,'',''),(11648,'pytest','issue #7429: Add more information and use cases about skipping doctests.','skip doctests',0,'',''),(11649,'pytest','issue #7780: Classes which should not be inherited from are now marked final class in the API reference.','mark final class in API reference',0,'',''),(11650,'pytest','issue #7878: In pull request section, ask to commit after editing changelog and authors file.','ask  in pull request section',0,'',''),(11651,'pytest','issue #7911: Directories created by tmpdir are now considered stale after 3 days without modification (previous value was 3 hours) to avoid deleting directories still in use in long running test suites.','delete directories in use',0,'',''),(11652,'pytest','issue #7911: Directories created by tmpdir are now considered stale after 3 days without modification (previous value was 3 hours) to avoid deleting directories still in use in long running test suites.','run test suites',0,'',''),(11653,'pytest','issue #7807: Fixed regression in pytest 6.1.0 causing incorrect rootdir to be determined in some non-trivial cases where parent directories have config files as well.','determine  in non-trivial cases',0,'',''),(11654,'pytest','issue #7814: Fixed crash in header reporting when testpaths is used and contains absolute paths (regression in 6.1.0).','use testpaths',0,'',''),(11655,'pytest','issue #5585: As per our policy, the following features which have been deprecated in the 5.X series are now\nremoved:','remove x series',0,'',''),(11656,'pytest','@pytest.fixture no longer supports positional arguments, pass all arguments by keyword instead.','support positional arguments',0,'',''),(11657,'pytest','@pytest.fixture no longer supports positional arguments, pass all arguments by keyword instead.','pass arguments by keyword',0,'',''),(11658,'pytest','Direct construction of Node subclasses now raise an error, use from_parent instead.','raise error from_parent',0,'',''),(11659,'pytest','The default value for junit_family has changed to xunit2. If you require the old format, add junit_family=xunit1 to your configuration file.','add junit_family to configuration file',0,'',''),(11660,'pytest','The TerminalReporter no longer has a writer attribute. Plugin authors may use the public functions of the TerminalReporter instead of accessing the TerminalWriter object directly.','use public functions instead_of accessing',0,'',''),(11661,'pytest','The TerminalReporter no longer has a writer attribute. Plugin authors may use the public functions of the TerminalReporter instead of accessing the TerminalWriter object directly.','use public functions of TerminalReporter',0,'',''),(11662,'pytest','The TerminalReporter no longer has a writer attribute. Plugin authors may use the public functions of the TerminalReporter instead of accessing the TerminalWriter object directly.','access TerminalWriter object',0,'',''),(11663,'pytest','The --result-log option has been removed. Users are recommended to use the pytest-reportlog plugin instead.','remove option',0,'',''),(11664,'pytest','The --result-log option has been removed. Users are recommended to use the pytest-reportlog plugin instead.','use pytest-reportlog plugin',0,'',''),(11665,'pytest','issue #6981: The pytest.collect module is deprecated: all its names can be imported from pytest directly.','import names from pytest',0,'',''),(11666,'pytest','It’s functionality is not meant to be used directly, but if you must replace\nit, use function._request._fillfixtures() instead, though note this is not\na public API and may break in the future.','use function._request._fillfixtures()',0,'',''),(11667,'pytest','It’s functionality is not meant to be used directly, but if you must replace\nit, use function._request._fillfixtures() instead, though note this is not\na public API and may break in the future.','break  in future',0,'',''),(11668,'pytest','The special -k \'expr:\' syntax to -k is deprecated. Please open an issue\nif you use this and want a replacement.','open issue',0,'',''),(11669,'pytest','issue #7255: The pytest_warning_captured hook is deprecated in favor\nof pytest_warning_recorded, and will be removed in a future version.','remove pytest_warning_captured hook in future version',0,'',''),(11670,'pytest','issue #7648: The gethookproxy() and isinitpath() methods of FSCollector and Package are deprecated;\nuse self.session.gethookproxy() and self.session.isinitpath() instead.\nThis should work on all pytest versions.','use self.session.gethookproxy()',0,'',''),(11671,'pytest','issue #7648: The gethookproxy() and isinitpath() methods of FSCollector and Package are deprecated;\nuse self.session.gethookproxy() and self.session.isinitpath() instead.\nThis should work on all pytest versions.','use self.session.isinitpath()',0,'',''),(11672,'pytest','issue #6681: Internal pytest warnings issued during the early stages of initialization are now properly handled and can filtered through filterwarnings or --pythonwarnings/-W.','handle internal pytest warnings',0,'',''),(11673,'pytest','This also fixes a number of long standing issues: issue #2891, issue #7620, issue #7426.','fix number of long standing issues',0,'',''),(11674,'pytest','issue #7572: When a plugin listed in required_plugins is missing or an unknown config key is used with --strict-config, a simple error message is now shown instead of a stacktrace.','list  in required_plugins',0,'',''),(11675,'pytest','issue #7572: When a plugin listed in required_plugins is missing or an unknown config key is used with --strict-config, a simple error message is now shown instead of a stacktrace.','use unknown config key',0,'',''),(11676,'pytest','issue #7572: When a plugin listed in required_plugins is missing or an unknown config key is used with --strict-config, a simple error message is now shown instead of a stacktrace.','show simple error message instead_of stacktrace',0,'',''),(11677,'pytest','issue #7780: Public classes which are not designed to be inherited from are now marked @final.\nCode which inherits from these classes will trigger a type-checking (e.g. mypy) error, but will still work in runtime.\nCurrently the final designation does not appear in the API Reference but hopefully will in the future.','mark @final',0,'',''),(11678,'pytest','issue #7780: Public classes which are not designed to be inherited from are now marked @final.\nCode which inherits from these classes will trigger a type-checking (e.g. mypy) error, but will still work in runtime.\nCurrently the final designation does not appear in the API Reference but hopefully will in the future.','trigger type-checking error',0,'',''),(11679,'pytest','issue #7780: Public classes which are not designed to be inherited from are now marked @final.\nCode which inherits from these classes will trigger a type-checking (e.g. mypy) error, but will still work in runtime.\nCurrently the final designation does not appear in the API Reference but hopefully will in the future.','inherit code from classes',0,'',''),(11680,'pytest','issue #1953: Fixed error when overwriting a parametrized fixture, while also reusing the super fixture value.','overwrite parametrized fixture',1,'https://docs.pytest.org/en/7.2.x/changelog.html',''),(11681,'pytest','issue #1953: Fixed error when overwriting a parametrized fixture, while also reusing the super fixture value.','reuse super fixture value',1,'https://docs.pytest.org/en/7.2.x/changelog.html',''),(11682,'pytest','issue #4984: Fixed an internal error crash with IndexError: list index out of range when\ncollecting a module which starts with a decorated function, the decorator\nraises, and assertion rewriting is enabled.','fix internal error crash with indexerror',0,'',''),(11683,'pytest','issue #4984: Fixed an internal error crash with IndexError: list index out of range when\ncollecting a module which starts with a decorated function, the decorator\nraises, and assertion rewriting is enabled.','enable assertion rewriting',0,'',''),(11684,'pytest','issue #7591: pylint shouldn’t complain anymore about unimplemented abstract methods when inheriting from File.','inherit  from File',0,'',''),(11685,'pytest','issue #7628: Fixed test collection when a full path without a drive letter was passed to pytest on Windows (for example \\projects\\tests\\test.py instead of c:\\projects\\tests\\pytest.py).','pass full path without drive letter',0,'',''),(11686,'pytest','issue #7536: The internal junitxml plugin has rewritten to use xml.etree.ElementTree.\nThe order of attributes in XML elements might differ. Some unneeded escaping is\nno longer performed.','use xml.etree.ElementTree',0,'',''),(11687,'pytest','issue #7536: The internal junitxml plugin has rewritten to use xml.etree.ElementTree.\nThe order of attributes in XML elements might differ. Some unneeded escaping is\nno longer performed.','perform unneeded escaping',0,'',''),(11688,'pytest','issue #7587: The dependency on the more-itertools package has been removed.','remove issue',0,'',''),(11689,'pytest','issue #7671: When collecting tests, pytest finds test classes and functions by examining the\nattributes of python objects (modules, classes and instances). To speed up this\nprocess, pytest now ignores builtin attributes (like __class__,\n__delattr__ and __new__) without consulting the python_classes and\npython_functions configuration options and without passing them to plugins\nusing the pytest_pycollect_makeitem hook.','find test classes by examining',0,'',''),(11690,'pytest','issue #7671: When collecting tests, pytest finds test classes and functions by examining the\nattributes of python objects (modules, classes and instances). To speed up this\nprocess, pytest now ignores builtin attributes (like __class__,\n__delattr__ and __new__) without consulting the python_classes and\npython_functions configuration options and without passing them to plugins\nusing the pytest_pycollect_makeitem hook.','find functions by examining',0,'',''),(11691,'pytest','issue #7671: When collecting tests, pytest finds test classes and functions by examining the\nattributes of python objects (modules, classes and instances). To speed up this\nprocess, pytest now ignores builtin attributes (like __class__,\n__delattr__ and __new__) without consulting the python_classes and\npython_functions configuration options and without passing them to plugins\nusing the pytest_pycollect_makeitem hook.','ignore builtin attributes without passing',0,'',''),(11692,'pytest','issue #7671: When collecting tests, pytest finds test classes and functions by examining the\nattributes of python objects (modules, classes and instances). To speed up this\nprocess, pytest now ignores builtin attributes (like __class__,\n__delattr__ and __new__) without consulting the python_classes and\npython_functions configuration options and without passing them to plugins\nusing the pytest_pycollect_makeitem hook.','ignore builtin attributes without consulting',0,'',''),(11693,'pytest','issue #7671: When collecting tests, pytest finds test classes and functions by examining the\nattributes of python objects (modules, classes and instances). To speed up this\nprocess, pytest now ignores builtin attributes (like __class__,\n__delattr__ and __new__) without consulting the python_classes and\npython_functions configuration options and without passing them to plugins\nusing the pytest_pycollect_makeitem hook.','pass  to plugins',0,'',''),(11694,'pytest','issue #7671: When collecting tests, pytest finds test classes and functions by examining the\nattributes of python objects (modules, classes and instances). To speed up this\nprocess, pytest now ignores builtin attributes (like __class__,\n__delattr__ and __new__) without consulting the python_classes and\npython_functions configuration options and without passing them to plugins\nusing the pytest_pycollect_makeitem hook.','use pytest_pycollect_makeitem hook',0,'',''),(11695,'pytest','issue #7672: Fixed log-capturing level restored incorrectly if caplog.set_level is called more than once.','call caplog.set_level',0,'',''),(11696,'pytest','issue #7686: Fixed NotSetType.token being used as the parameter ID when the parametrization list is empty.\nRegressed in pytest 6.0.0.','use  as parameter ID',0,'',''),(11697,'pytest','issue #7707: Fix internal error when handling some exceptions that contain multiple lines or the style uses multiple lines (--tb=line for example).','handle exceptions',0,'',''),(11698,'pytest','issue #7707: Fix internal error when handling some exceptions that contain multiple lines or the style uses multiple lines (--tb=line for example).','use multiple lines',0,'',''),(11699,'pytest','issue #7394: Passing an empty help value to Parser.add_option is now accepted instead of crashing when running pytest --help.\nPassing None raises a more informative TypeError.','pass empty help value to Parser.add_option',0,'',''),(11700,'pytest','issue #7394: Passing an empty help value to Parser.add_option is now accepted instead of crashing when running pytest --help.\nPassing None raises a more informative TypeError.','run pytest',0,'',''),(11701,'pytest','issue #7394: Passing an empty help value to Parser.add_option is now accepted instead of crashing when running pytest --help.\nPassing None raises a more informative TypeError.','raise informative TypeError',0,'',''),(11702,'pytest','issue #7559: Fix regression in plugins using TestReport.longreprtext (such as pytest-html) when TestReport.longrepr is not a string.','use TestReport.longreprtext',0,'',''),(11703,'pytest','Following our plan to remove deprecated features with as little disruption as\npossible, all warnings of type PytestDeprecationWarning now generate errors\ninstead of warning messages.','remove deprecated features as little disruption possible',0,'',''),(11704,'pytest','Following our plan to remove deprecated features with as little disruption as\npossible, all warnings of type PytestDeprecationWarning now generate errors\ninstead of warning messages.','generate errors instead_of warning messages',0,'',''),(11705,'pytest','Following our plan to remove deprecated features with as little disruption as\npossible, all warnings of type PytestDeprecationWarning now generate errors\ninstead of warning messages.','generate errors following plan',0,'',''),(11706,'pytest','The affected features will be effectively removed in pytest 6.1, so please consult the\nDeprecations and Removals section in the docs for directions on how to update existing code.','update existing code',0,'',''),(11707,'pytest','The affected features will be effectively removed in pytest 6.1, so please consult the\nDeprecations and Removals section in the docs for directions on how to update existing code.','remove affected features',0,'',''),(11708,'pytest','In the pytest 6.0.X series, it is possible to change the errors back into warnings as a\nstopgap measure by adding this to your pytest.ini file:','add  to pytest.ini file',0,'',''),(11709,'pytest','But this will stop working when pytest 6.1 is released.','release pytest',0,'',''),(11710,'pytest','If you have concerns about the removal of a specific feature, please add a\ncomment to issue #5584.','add comment',0,'',''),(11711,'pytest','issue #7472: The exec_() and is_true() methods of _pytest._code.Frame have been removed.','remove issue',0,'',''),(11712,'pytest','issue #7464: Added support for NO_COLOR and FORCE_COLOR environment variables to control colored output.','add support for NO_COLOR FORCE_COLOR environment variables',0,'',''),(11713,'pytest','issue #7467: --log-file CLI option and log_file ini marker now create subdirectories if needed.','create subdirectories',0,'',''),(11714,'pytest','issue #7392: Fix the reported location of tests skipped with @pytest.mark.skip when --runxfail is used.','fix reported location of tests',0,'',''),(11715,'pytest','issue #7392: Fix the reported location of tests skipped with @pytest.mark.skip when --runxfail is used.','skip  with',0,'',''),(11716,'pytest','issue #7392: Fix the reported location of tests skipped with @pytest.mark.skip when --runxfail is used.','use runxfail',0,'',''),(11717,'pytest','issue #7491: tmpdir and tmp_path no longer raise an error if the lock to check for\nstale temporary directories is not accessible.','raise error',0,'',''),(11718,'pytest','issue #7491: tmpdir and tmp_path no longer raise an error if the lock to check for\nstale temporary directories is not accessible.','check  for stale temporary directories',0,'',''),(11719,'pytest','issue #7534: Restored the previous formatting of TracebackEntry.__str__ which was changed by accident.','change previous formatting of TracebackEntry.__str__',0,'',''),(11720,'pytest','issue #7422: Clarified when the usefixtures mark can apply fixtures to test.','apply fixtures to test',0,'',''),(11721,'pytest','issue #7441: Add a note about -q option used in getting started guide.','add note about q option',0,'',''),(11722,'pytest','issue #7441: Add a note about -q option used in getting started guide.','use  in getting',0,'',''),(11723,'pytest','issue #5965: symlinks are no longer resolved during collection and matching conftest.py files with test file paths.','resolve symlinks with test file paths',0,'',''),(11724,'pytest','issue #5965: symlinks are no longer resolved during collection and matching conftest.py files with test file paths.','resolve symlinks during collection matching conftest.py files',0,'',''),(11725,'pytest','Resolving symlinks for the current directory and during collection was introduced as a bugfix in 3.9.0, but it actually is a new feature which had unfortunate consequences in Windows and surprising results in other platforms.','introduce resolving symlinks as bugfix',0,'',''),(11726,'pytest','Resolving symlinks for the current directory and during collection was introduced as a bugfix in 3.9.0, but it actually is a new feature which had unfortunate consequences in Windows and surprising results in other platforms.','introduce resolving symlinks for current directory',0,'',''),(11727,'pytest','Resolving symlinks for the current directory and during collection was introduced as a bugfix in 3.9.0, but it actually is a new feature which had unfortunate consequences in Windows and surprising results in other platforms.','introduce resolving symlinks during collection',0,'',''),(11728,'pytest','The team decided to step back on resolving symlinks at all, planning to review this in the future with a more solid solution (see discussion in\npull request #6523 for details).','resolve symlinks',0,'',''),(11729,'pytest','This might break test suites which made use of this feature; the fix is to create a symlink\nfor the entire test tree, and not only to partial files/tress as it was possible previously.','break test suites',0,'',''),(11730,'pytest','This might break test suites which made use of this feature; the fix is to create a symlink\nfor the entire test tree, and not only to partial files/tress as it was possible previously.','create symlink',0,'',''),(11731,'pytest','issue #6505: Testdir.run().parseoutcomes() now always returns the parsed nouns in plural form.','return parsed nouns in plural form',0,'',''),(11732,'pytest','Originally parseoutcomes() would always returns the nouns in plural form, but a change\nmeant to improve the terminal summary by using singular form single items (1 warning or 1 error)\ncaused an unintended regression by changing the keys returned by parseoutcomes().','return nouns in plural form',0,'',''),(11733,'pytest','Originally parseoutcomes() would always returns the nouns in plural form, but a change\nmeant to improve the terminal summary by using singular form single items (1 warning or 1 error)\ncaused an unintended regression by changing the keys returned by parseoutcomes().','use singular form',0,'',''),(11734,'pytest','Originally parseoutcomes() would always returns the nouns in plural form, but a change\nmeant to improve the terminal summary by using singular form single items (1 warning or 1 error)\ncaused an unintended regression by changing the keys returned by parseoutcomes().','change keys',0,'',''),(11735,'pytest','Now the API guarantees to always return the plural form, so calls like this:','return plural form',1,'https://docs.pytest.org/en/7.2.x/changelog.html',''),(11736,'pytest','Need to be changed to:','change need',0,'',''),(11737,'pytest','issue #7040: -k no longer matches against the names of the directories outside the test session root.','match  against names',0,'',''),(11738,'pytest','Also, pytest.Package.name is now just the name of the directory containing the package’s\n__init__.py file, instead of the full path. This is consistent with how the other nodes\nare named, and also one of the reasons why -k would match against any directory containing\nthe test suite.','match  against directory',0,'',''),(11739,'pytest','issue #7135: Pytest now uses its own TerminalWriter class instead of using the one from the py library.\nPlugins generally access this class through TerminalReporter.writer, TerminalReporter.write()\n(and similar methods), or _pytest.config.create_terminal_writer().','use own TerminalWriter class',0,'',''),(11740,'pytest','issue #7135: Pytest now uses its own TerminalWriter class instead of using the one from the py library.\nPlugins generally access this class through TerminalReporter.writer, TerminalReporter.write()\n(and similar methods), or _pytest.config.create_terminal_writer().','use  from py library',0,'',''),(11741,'pytest','issue #7135: Pytest now uses its own TerminalWriter class instead of using the one from the py library.\nPlugins generally access this class through TerminalReporter.writer, TerminalReporter.write()\n(and similar methods), or _pytest.config.create_terminal_writer().','access class through TerminalReporter.writer',0,'',''),(11742,'pytest','issue #7135: Pytest now uses its own TerminalWriter class instead of using the one from the py library.\nPlugins generally access this class through TerminalReporter.writer, TerminalReporter.write()\n(and similar methods), or _pytest.config.create_terminal_writer().','access class through TerminalReporter.write()',0,'',''),(11743,'pytest','issue #7135: Pytest now uses its own TerminalWriter class instead of using the one from the py library.\nPlugins generally access this class through TerminalReporter.writer, TerminalReporter.write()\n(and similar methods), or _pytest.config.create_terminal_writer().','access class through _pytest.config.create_terminal_writer()',0,'',''),(11744,'pytest','Output (write() method and others) no longer flush implicitly; the flushing behavior\nof the underlying file is respected. To flush explicitly (for example, if you\nwant output to be shown before an end-of-line is printed), use write(flush=True) or\nterminal_writer.flush().','use write(flush=True)',0,'',''),(11745,'pytest','Output (write() method and others) no longer flush implicitly; the flushing behavior\nof the underlying file is respected. To flush explicitly (for example, if you\nwant output to be shown before an end-of-line is printed), use write(flush=True) or\nterminal_writer.flush().','use terminal_writer.flush()',0,'',''),(11746,'pytest','Support for writing bytes was removed.','remove support for writing bytes',0,'',''),(11747,'pytest','The reline method and chars_on_current_line property were removed.','remove reline method',0,'',''),(11748,'pytest','The reline method and chars_on_current_line property were removed.','remove chars_on_current_line property',0,'',''),(11749,'pytest','The stringio and encoding arguments was removed.','remove stringio encoding arguments',0,'',''),(11750,'pytest','Support for passing a callable instead of a file was removed.','pass callable instead_of file',0,'',''),(11751,'pytest','Support for passing a callable instead of a file was removed.','remove support for passing',0,'',''),(11752,'pytest','The deprecated --no-print-logs option and log_print ini option are removed. Use --show-capture instead.','remove no-print-logs option',0,'',''),(11753,'pytest','The deprecated --no-print-logs option and log_print ini option are removed. Use --show-capture instead.','remove log_print ini option',0,'',''),(11754,'pytest','issue #7226: Removed the unused args parameter from pytest.Function.__init__.','remove unused args parameter from pytest.Function.__init__',0,'',''),(11755,'pytest','issue #7418: Removed the pytest_doctest_prepare_content hook specification. This hook\nhasn’t been triggered by pytest for at least 10 years.','remove pytest_doctest_prepare_content hook specification',0,'',''),(11756,'pytest','issue #7418: Removed the pytest_doctest_prepare_content hook specification. This hook\nhasn’t been triggered by pytest for at least 10 years.','trigger hook',0,'',''),(11757,'pytest','issue #7438: Some changes were made to the internal _pytest._code.source, listed here\nfor the benefit of plugin authors who may be using it:','use benefit of plugin authors',0,'',''),(11758,'pytest','issue #7438: Some changes were made to the internal _pytest._code.source, listed here\nfor the benefit of plugin authors who may be using it:','list  for benefit',0,'',''),(11759,'pytest','The deindent argument to Source() has been removed, now it is always true.','remove deindent argument to Source()',0,'',''),(11760,'pytest','Support for zero or multiple arguments to Source() has been removed.','remove support to Source()',0,'',''),(11761,'pytest','Support for zero or multiple arguments to Source() has been removed.','remove multiple arguments to Source()',0,'',''),(11762,'pytest','Support for comparing Source with an str has been removed.','compare source with str',0,'',''),(11763,'pytest','Support for comparing Source with an str has been removed.','remove support for comparing',0,'',''),(11764,'pytest','The methods Source.isparseable() and Source.putaround() have been removed.','remove methods Source.isparseable()',0,'',''),(11765,'pytest','The methods Source.isparseable() and Source.putaround() have been removed.','remove Source.putaround()',0,'',''),(11766,'pytest','The method Source.compile() and function _pytest._code.compile() have\nbeen removed; use plain compile() instead.','use plain compile()',0,'',''),(11767,'pytest','The method Source.compile() and function _pytest._code.compile() have\nbeen removed; use plain compile() instead.','remove method Source.compile()',0,'',''),(11768,'pytest','The method Source.compile() and function _pytest._code.compile() have\nbeen removed; use plain compile() instead.','remove function _pytest._code.compile()',0,'',''),(11769,'pytest','The function _pytest._code.source.getsource() has been removed; use\nSource() directly instead.','use Source()',0,'',''),(11770,'pytest','The function _pytest._code.source.getsource() has been removed; use\nSource() directly instead.','remove function _pytest._code.source.getsource()',0,'',''),(11771,'pytest','issue #1556: pytest now supports pyproject.toml files for configuration.','support pyproject.toml files for configuration',0,'',''),(11772,'pytest','The configuration options is similar to the one available in other formats, but must be defined\nin a [tool.pytest.ini_options] table to be picked up by pytest:','define configuration options in  tool.pytest.ini_options table',1,'https://docs.pytest.org/en/7.2.x/changelog.html',''),(11773,'pytest','More information can be found in the docs.','find more information in docs',0,'',''),(11774,'pytest','issue #3342: pytest now includes inline type annotations and exposes them to user programs.\nMost of the user-facing API is covered, as well as internal code.','include inline type annotations',0,'',''),(11775,'pytest','issue #3342: pytest now includes inline type annotations and exposes them to user programs.\nMost of the user-facing API is covered, as well as internal code.','expose  to user programs',0,'',''),(11776,'pytest','If you are running a type checker such as mypy on your tests, you may start\nnoticing type errors indicating incorrect usage. If you run into an error that\nyou believe to be incorrect, please let us know in an issue.','run type checker such_as mypy',0,'',''),(11777,'pytest','If you are running a type checker such as mypy on your tests, you may start\nnoticing type errors indicating incorrect usage. If you run into an error that\nyou believe to be incorrect, please let us know in an issue.','run  into error',0,'',''),(11778,'pytest','The types were developed against mypy version 0.780. Versions before 0.750\nare known not to work. We recommend using the latest version. Other type\ncheckers may work as well, but they are not officially verified to work by\npytest yet.','develop types against mypy version',0,'',''),(11779,'pytest','The types were developed against mypy version 0.780. Versions before 0.750\nare known not to work. We recommend using the latest version. Other type\ncheckers may work as well, but they are not officially verified to work by\npytest yet.','use latest version',0,'',''),(11780,'pytest','issue #4049: Introduced a new hook named pytest_warning_recorded to convey information about warnings captured by the internal pytest warnings plugin.','introduce new hook',0,'',''),(11781,'pytest','This hook is meant to replace pytest_warning_captured, which is deprecated and will be removed in a future release.','replace pytest_warning_captured',0,'',''),(11782,'pytest','This hook is meant to replace pytest_warning_captured, which is deprecated and will be removed in a future release.','remove pytest_warning_captured in future release',0,'',''),(11783,'pytest','issue #6856: A warning is now shown when an unknown key is read from a config INI file.','read unknown key from config INI file',0,'',''),(11784,'pytest','issue #6856: A warning is now shown when an unknown key is read from a config INI file.','show warning',0,'',''),(11785,'pytest','The --strict-config flag has been added to treat these warnings as errors.','add flag',0,'',''),(11786,'pytest','issue #7245: New --import-mode=importlib option that uses importlib to import test modules.','import test modules',0,'',''),(11787,'pytest','issue #7245: New --import-mode=importlib option that uses importlib to import test modules.','use import-mode = importlib option',0,'',''),(11788,'pytest','Traditionally pytest used __import__ while changing sys.path to import test modules (which\nalso changes sys.modules as a side-effect), which works but has a number of drawbacks, like requiring test modules\nthat don’t live in packages to have unique names (as they need to reside under a unique name in sys.modules).','use __import__',0,'',''),(11789,'pytest','Traditionally pytest used __import__ while changing sys.path to import test modules (which\nalso changes sys.modules as a side-effect), which works but has a number of drawbacks, like requiring test modules\nthat don’t live in packages to have unique names (as they need to reside under a unique name in sys.modules).','import test modules like requiring',0,'',''),(11790,'pytest','--import-mode=importlib uses more fine grained import mechanisms from importlib which don’t\nrequire pytest to change sys.path or sys.modules at all, eliminating much of the drawbacks\nof the previous mode.','change sys.path',0,'',''),(11791,'pytest','--import-mode=importlib uses more fine grained import mechanisms from importlib which don’t\nrequire pytest to change sys.path or sys.modules at all, eliminating much of the drawbacks\nof the previous mode.','change sys.modules',0,'',''),(11792,'pytest','We intend to make --import-mode=importlib the default in future versions, so users are encouraged\nto try the new mode and provide feedback (both positive or negative) in issue issue #7245.','provide feedback in issue issue',0,'',''),(11793,'pytest','You can read more about this option in the documentation.','read  about option',0,'',''),(11794,'pytest','issue #7305: New required_plugins configuration option allows the user to specify a list of plugins, including version information, that are required for pytest to run. An error is raised if any required plugins are not found when running pytest.','specify list including version information',0,'',''),(11795,'pytest','issue #7305: New required_plugins configuration option allows the user to specify a list of plugins, including version information, that are required for pytest to run. An error is raised if any required plugins are not found when running pytest.','specify list of plugins',0,'',''),(11796,'pytest','issue #7305: New required_plugins configuration option allows the user to specify a list of plugins, including version information, that are required for pytest to run. An error is raised if any required plugins are not found when running pytest.','run pytest',0,'',''),(11797,'pytest','issue #7305: New required_plugins configuration option allows the user to specify a list of plugins, including version information, that are required for pytest to run. An error is raised if any required plugins are not found when running pytest.','raise error',0,'',''),(11798,'pytest','issue #4375: The pytest command now suppresses the BrokenPipeError error message that\nis printed to stderr when the output of pytest is piped and and the pipe is\nclosed by the piped-to program (common examples are less and head).','print BrokenPipeError error message',0,'',''),(11799,'pytest','issue #4391: Improved precision of test durations measurement. CallInfo items now have a new .duration attribute, created using time.perf_counter(). This attribute is used to fill the .duration attribute, which is more accurate than the previous .stop - .start (as these are based on time.time()).','use time.perf_counter()',0,'',''),(11800,'pytest','issue #4391: Improved precision of test durations measurement. CallInfo items now have a new .duration attribute, created using time.perf_counter(). This attribute is used to fill the .duration attribute, which is more accurate than the previous .stop - .start (as these are based on time.time()).','use attribute',0,'',''),(11801,'pytest','issue #6285: Exposed the pytest.FixtureLookupError exception which is raised by request.getfixturevalue()\n(where request is a FixtureRequest fixture) when a fixture with the given name cannot be returned.','expose pytest.FixtureLookupError exception',0,'',''),(11802,'pytest','issue #6285: Exposed the pytest.FixtureLookupError exception which is raised by request.getfixturevalue()\n(where request is a FixtureRequest fixture) when a fixture with the given name cannot be returned.','raise pytest.FixtureLookupError exception',0,'',''),(11803,'pytest','issue #6433: If an error is encountered while formatting the message in a logging call, for\nexample logging.warning(\"oh no!: %s: %s\", \"first\") (a second argument is\nmissing), pytest now propagates the error, likely causing the test to fail.','format message in logging call',0,'',''),(11804,'pytest','Previously, such a mistake would cause an error to be printed to stderr, which\nis not displayed by default for passing tests. This change makes the mistake\nvisible during testing.','print  to stderr',0,'',''),(11805,'pytest','issue #6817: Explicit new-lines in help texts of command-line options are preserved, allowing plugins better control\nof the help displayed to users.','display  to users',0,'',''),(11806,'pytest','issue #6940: When using the --duration option, the terminal message output is now more precise about the number and duration of hidden items.','use output',0,'',''),(11807,'pytest','issue #6991: Collected files are displayed after any reports from hooks, e.g. the status from --lf.','display collected files from hooks',0,'',''),(11808,'pytest','issue #6991: Collected files are displayed after any reports from hooks, e.g. the status from --lf.','display collected files after reports',0,'',''),(11809,'pytest','issue #7091: When fd capturing is used, through --capture=fd or the capfd and\ncapfdbinary fixtures, and the file descriptor (0, 1, 2) cannot be\nduplicated, FD capturing is still performed. Previously, direct writes to the\nfile descriptors would fail or be lost in this case.','use fd capturing',0,'',''),(11810,'pytest','issue #7091: When fd capturing is used, through --capture=fd or the capfd and\ncapfdbinary fixtures, and the file descriptor (0, 1, 2) cannot be\nduplicated, FD capturing is still performed. Previously, direct writes to the\nfile descriptors would fail or be lost in this case.','perform FD capturing',0,'',''),(11811,'pytest','issue #7119: Exit with an error if the --basetemp argument is empty, is the current working directory or is one of the parent directories.\nThis is done to protect against accidental data loss, as any directory passed to this argument is cleared.','pass  to argument',0,'',''),(11812,'pytest','issue #7128: pytest --version now displays just the pytest version, while pytest --version --version displays more verbose information including plugins. This is more consistent with how other tools show --version.','display pytest version',0,'',''),(11813,'pytest','issue #7128: pytest --version now displays just the pytest version, while pytest --version --version displays more verbose information including plugins. This is more consistent with how other tools show --version.','display more verbose information including plugins',0,'',''),(11814,'pytest','issue #7128: pytest --version now displays just the pytest version, while pytest --version --version displays more verbose information including plugins. This is more consistent with how other tools show --version.','show version',0,'',''),(11815,'pytest','issue #7133: caplog.set_level() will now override any log_level set via the CLI or configuration file.','override log_level set via CLI configuration file',0,'',''),(11816,'pytest','issue #7159: caplog.set_level() and caplog.at_level() no longer affect\nthe level of logs that are shown in the Captured log report report section.','show level in captured log report report section',0,'',''),(11817,'pytest','issue #7159: caplog.set_level() and caplog.at_level() no longer affect\nthe level of logs that are shown in the Captured log report report section.','show level of logs',0,'',''),(11818,'pytest','issue #1120: Fix issue where directories from tmpdir are not removed properly when multiple instances of pytest are running in parallel.','run  in parallel',0,'',''),(11819,'pytest','issue #4583: Prevent crashing and provide a user-friendly error when a marker expression (-m) invoking of eval() raises any exception.','provide user-friendly error',0,'',''),(11820,'pytest','issue #4583: Prevent crashing and provide a user-friendly error when a marker expression (-m) invoking of eval() raises any exception.','raise exception',0,'',''),(11821,'pytest','issue #4677: The path shown in the summary report for SKIPPED tests is now always relative. Previously it was sometimes absolute.','show  in summary report',0,'',''),(11822,'pytest','issue #5456: Fix a possible race condition when trying to remove lock files used to control access to folders\ncreated by tmp_path and tmpdir.','fix possible race condition',0,'',''),(11823,'pytest','issue #5456: Fix a possible race condition when trying to remove lock files used to control access to folders\ncreated by tmp_path and tmpdir.','remove lock files',0,'',''),(11824,'pytest','issue #6240: Fixes an issue where logging during collection step caused duplication of log\nmessages to stderr.','fix issue',0,'',''),(11825,'pytest','issue #6240: Fixes an issue where logging during collection step caused duplication of log\nmessages to stderr.','log  during collection step',0,'',''),(11826,'pytest','issue #6428: Paths appearing in error messages are now correct in case the current working directory has\nchanged since the start of the session.','change  since start',0,'',''),(11827,'pytest','issue #6755: Support deleting paths longer than 260 characters on windows created inside tmpdir.','delete paths on windows',0,'',''),(11828,'pytest','issue #6755: Support deleting paths longer than 260 characters on windows created inside tmpdir.','create  inside tmpdir',0,'',''),(11829,'pytest','issue #6871: Fix crash with captured output when using capsysbinary.','fix crash with captured output',0,'',''),(11830,'pytest','issue #6909: Revert the change introduced by pull request #6330, which required all arguments to @pytest.mark.parametrize to be explicitly defined in the function signature.','introduce  by pull request',0,'',''),(11831,'pytest','issue #6909: Revert the change introduced by pull request #6330, which required all arguments to @pytest.mark.parametrize to be explicitly defined in the function signature.','define  in function signature',0,'',''),(11832,'pytest','issue #6910: Fix crash when plugins return an unknown stats while using the --reportlog option.','return unknown stats',0,'',''),(11833,'pytest','issue #6910: Fix crash when plugins return an unknown stats while using the --reportlog option.','use reportlog option',0,'',''),(11834,'pytest','issue #6925: Fix TerminalRepr instances to be hashable again.','fix TerminalRepr instances',0,'',''),(11835,'pytest','issue #6951: Allow users to still set the deprecated TerminalReporter.writer attribute.','set deprecated TerminalReporter.writer attribute',0,'',''),(11836,'pytest','issue #7076: The path of file skipped by @pytest.mark.skip in the SKIPPED report is now relative to invocation directory. Previously it was relative to root directory.','skip  in SKIPPED report',0,'',''),(11837,'pytest','issue #7076: The path of file skipped by @pytest.mark.skip in the SKIPPED report is now relative to invocation directory. Previously it was relative to root directory.','skip  by',0,'',''),(11838,'pytest','issue #7110: Fixed regression: asyncbase.TestCase tests are executed correctly again.','execute asyncbase.TestCase tests',0,'',''),(11839,'pytest','issue #7126: --setup-show now doesn’t raise an error when a bytes value is used as a parametrize\nparameter when Python is called with the -bb flag.','raise error',0,'',''),(11840,'pytest','issue #7126: --setup-show now doesn’t raise an error when a bytes value is used as a parametrize\nparameter when Python is called with the -bb flag.','use bytes value as parametrize parameter',0,'',''),(11841,'pytest','issue #7126: --setup-show now doesn’t raise an error when a bytes value is used as a parametrize\nparameter when Python is called with the -bb flag.','call Python with bb flag',0,'',''),(11842,'pytest','issue #7145: Classes with broken __getattribute__ methods are displayed correctly during failures.','display issue during failures',0,'',''),(11843,'pytest','issue #7150: Prevent hiding the underlying exception when ConfTestImportFailure is raised.','hide underlying exception',0,'',''),(11844,'pytest','issue #7150: Prevent hiding the underlying exception when ConfTestImportFailure is raised.','raise ConfTestImportFailure',0,'',''),(11845,'pytest','issue #7180: Fix _is_setup_py for files encoded differently than locale.','encode  than locale',0,'',''),(11846,'pytest','issue #7215: Fix regression where running with --pdb would call unittest.TestCase.tearDown() for skipped tests.','call unittest.TestCase.tearDown() for skipped tests',0,'',''),(11847,'pytest','issue #7215: Fix regression where running with --pdb would call unittest.TestCase.tearDown() for skipped tests.','call pdb for skipped tests',0,'',''),(11848,'pytest','issue #7215: Fix regression where running with --pdb would call unittest.TestCase.tearDown() for skipped tests.','run fix regression',0,'',''),(11849,'pytest','issue #7253: When using pytest.fixture on a function directly, as in pytest.fixture(func),\nif the autouse or params arguments are also passed, the function is no longer\nignored, but is marked as a fixture.','use pytest.fixture on function',0,'',''),(11850,'pytest','issue #7253: When using pytest.fixture on a function directly, as in pytest.fixture(func),\nif the autouse or params arguments are also passed, the function is no longer\nignored, but is marked as a fixture.','mark function as fixture',0,'',''),(11851,'pytest','issue #7253: When using pytest.fixture on a function directly, as in pytest.fixture(func),\nif the autouse or params arguments are also passed, the function is no longer\nignored, but is marked as a fixture.','pass autouse params arguments',0,'',''),(11852,'pytest','issue #7253: When using pytest.fixture on a function directly, as in pytest.fixture(func),\nif the autouse or params arguments are also passed, the function is no longer\nignored, but is marked as a fixture.','ignore function',0,'',''),(11853,'pytest','issue #7360: Fix possibly incorrect evaluation of string expressions passed to pytest.mark.skipif and pytest.mark.xfail,\nin rare circumstances where the exact same string is used but refers to different global values.','pass  in rare circumstances',0,'',''),(11854,'pytest','issue #7360: Fix possibly incorrect evaluation of string expressions passed to pytest.mark.skipif and pytest.mark.xfail,\nin rare circumstances where the exact same string is used but refers to different global values.','pass  to pytest.mark.xfail',0,'',''),(11855,'pytest','issue #7360: Fix possibly incorrect evaluation of string expressions passed to pytest.mark.skipif and pytest.mark.xfail,\nin rare circumstances where the exact same string is used but refers to different global values.','pass  to pytest.mark.skipif',0,'',''),(11856,'pytest','issue #7360: Fix possibly incorrect evaluation of string expressions passed to pytest.mark.skipif and pytest.mark.xfail,\nin rare circumstances where the exact same string is used but refers to different global values.','use exact same string',0,'',''),(11857,'pytest','issue #7360: Fix possibly incorrect evaluation of string expressions passed to pytest.mark.skipif and pytest.mark.xfail,\nin rare circumstances where the exact same string is used but refers to different global values.','use rare circumstances',0,'',''),(11858,'pytest','issue #7383: Fixed exception causes all over the codebase, i.e. use raise new_exception from old_exception when wrapping an exception.','fix exception causes over codebase i.e. use raise new_exception',0,'',''),(11859,'pytest','issue #7383: Fixed exception causes all over the codebase, i.e. use raise new_exception from old_exception when wrapping an exception.','wrap exception',0,'',''),(11860,'pytest','issue #7202: The development guide now links to the contributing section of the docs and RELEASING.rst on GitHub.','link  to contributing section',0,'',''),(11861,'pytest','issue #7233: Add a note about --strict and --strict-markers and the preference for the latter one.','add note',0,'',''),(11862,'pytest','issue #7035: The originalname attribute of _pytest.python.Function now defaults to name if not\nprovided explicitly, and is always set.','set issue',0,'',''),(11863,'pytest','issue #7264: The dependency on the wcwidth package has been removed.','remove issue',0,'',''),(11864,'pytest','issue #7215: Fix regression where running with --pdb would call the tearDown methods of unittest.TestCase\nsubclasses for skipped tests.','call tearDown methods of unittest.TestCase subclasses',0,'',''),(11865,'pytest','issue #7215: Fix regression where running with --pdb would call the tearDown methods of unittest.TestCase\nsubclasses for skipped tests.','call tearDown methods for skipped tests',0,'',''),(11866,'pytest','issue #7215: Fix regression where running with --pdb would call the tearDown methods of unittest.TestCase\nsubclasses for skipped tests.','call pdb of unittest.TestCase subclasses',0,'',''),(11867,'pytest','issue #7215: Fix regression where running with --pdb would call the tearDown methods of unittest.TestCase\nsubclasses for skipped tests.','call pdb for skipped tests',0,'',''),(11868,'pytest','issue #7215: Fix regression where running with --pdb would call the tearDown methods of unittest.TestCase\nsubclasses for skipped tests.','run fix regression',0,'',''),(11869,'pytest','issue #6871: Fix crash with captured output when using the capsysbinary fixture.','fix crash with captured output',0,'',''),(11870,'pytest','issue #6871: Fix crash with captured output when using the capsysbinary fixture.','use capsysbinary fixture',0,'',''),(11871,'pytest','issue #6443: Plugins specified with -p are now loaded after internal plugins, which results in their hooks being called before the internal ones.','load p after internal plugins',0,'',''),(11872,'pytest','issue #6637: Removed the long-deprecated pytest_itemstart hook.','remove long-deprecated pytest_itemstart hook',0,'',''),(11873,'pytest','This hook has been marked as deprecated and not been even called by pytest for over 10 years now.','mark hook as deprecated',0,'',''),(11874,'pytest','This hook has been marked as deprecated and not been even called by pytest for over 10 years now.','call  for years',0,'',''),(11875,'pytest','issue #6737: The cached_result attribute of FixtureDef is now set to None when\nthe result is unavailable, instead of being deleted.','set issue to none',0,'',''),(11876,'pytest','If your plugin performs checks like hasattr(fixturedef, \'cached_result\'),\nfor example in a pytest_fixture_post_finalizer hook implementation, replace\nit with fixturedef.cached_result is not None. If you del the attribute,\nset it to None instead.','perform checks like hasattr(fixturedef,          \'cached_result\')',0,'',''),(11877,'pytest','If your plugin performs checks like hasattr(fixturedef, \'cached_result\'),\nfor example in a pytest_fixture_post_finalizer hook implementation, replace\nit with fixturedef.cached_result is not None. If you del the attribute,\nset it to None instead.','replace  with fixturedef.cached_result',0,'',''),(11878,'pytest','issue #3238: Option --no-print-logs is deprecated and meant to be removed in a future release. If you use --no-print-logs, please try out --show-capture and\nprovide feedback.','remove  in future release',0,'',''),(11879,'pytest','issue #3238: Option --no-print-logs is deprecated and meant to be removed in a future release. If you use --no-print-logs, please try out --show-capture and\nprovide feedback.','use no-print-logs',0,'',''),(11880,'pytest','--show-capture command-line option was added in pytest 3.5.0 and allows to specify how to\ndisplay captured output when tests fail: no, stdout, stderr, log or all (the default).','add show-capture command-line option in pytest 3.5.0',0,'',''),(11881,'pytest','issue #571: Deprecate the unused/broken pytest_collect_directory hook.\nIt was misaligned since the removal of the Directory collector in 2010\nand incorrect/unusable as soon as collection was split from test execution.','split collection from test execution',0,'',''),(11882,'pytest','issue #5975: Deprecate using direct constructors for Nodes.','use direct constructors for nodes',0,'',''),(11883,'pytest','Subclasses are expected to use super().from_parent if they intend to expand the creation of Nodes.','use super().from_parent',0,'',''),(11884,'pytest','Subclasses are expected to use super().from_parent if they intend to expand the creation of Nodes.','expand creation of nodes',0,'',''),(11885,'pytest','issue #6779: The TerminalReporter.writer attribute has been deprecated and should no longer be used. This\nwas inadvertently exposed as part of the public API of that plugin and ties it too much\nwith py.io.TerminalWriter.','use TerminalReporter.writer attribute',0,'',''),(11886,'pytest','issue #6779: The TerminalReporter.writer attribute has been deprecated and should no longer be used. This\nwas inadvertently exposed as part of the public API of that plugin and ties it too much\nwith py.io.TerminalWriter.','expose  as part',0,'',''),(11887,'pytest','issue #5712: Now all arguments to @pytest.mark.parametrize need to be explicitly declared in the function signature or via indirect.\nPreviously it was possible to omit an argument if a fixture with the same name existed, which was just an accident of implementation and was not meant to be a part of the API.','omit argument',0,'',''),(11888,'pytest','issue #6454: Changed default for -r to fE, which displays failures and errors in the short test summary.  -rN can be used to disable it (the old behavior).','display errors in short test summary',0,'',''),(11889,'pytest','issue #6454: Changed default for -r to fE, which displays failures and errors in the short test summary.  -rN can be used to disable it (the old behavior).','display failures in short test summary',0,'',''),(11890,'pytest','issue #6454: Changed default for -r to fE, which displays failures and errors in the short test summary.  -rN can be used to disable it (the old behavior).','display fE in short test summary',0,'',''),(11891,'pytest','issue #6454: Changed default for -r to fE, which displays failures and errors in the short test summary.  -rN can be used to disable it (the old behavior).','use rn',0,'',''),(11892,'pytest','issue #6469: New options have been added to the junit_logging option: log, out-err, and all.','add new options to junit_logging option',0,'',''),(11893,'pytest','issue #449: Use “yellow” main color with any XPASSED tests.','use yellow main color with XPASSED tests',0,'',''),(11894,'pytest','issue #5984: The pytest_warning_captured hook now receives a location parameter with the code location that generated the warning.','receive location parameter with code location',0,'',''),(11895,'pytest','issue #5984: The pytest_warning_captured hook now receives a location parameter with the code location that generated the warning.','generate warning',0,'',''),(11896,'pytest','issue #5984: The pytest_warning_captured hook now receives a location parameter with the code location that generated the warning.','generate code location',0,'',''),(11897,'pytest','issue #6653: Add support for matching lines consecutively with LineMatcher’s fnmatch_lines() and re_match_lines().','match lines with re_match_lines()',0,'',''),(11898,'pytest','issue #6653: Add support for matching lines consecutively with LineMatcher’s fnmatch_lines() and re_match_lines().','match lines with fnmatch_lines()',0,'',''),(11899,'pytest','issue #6658: Code is now highlighted in tracebacks when pygments is installed.','install pygments',0,'',''),(11900,'pytest','Users are encouraged to install pygments into their environment and provide feedback, because\nthe plan is to make pygments a regular dependency in the future.','install pygments into environment',0,'',''),(11901,'pytest','Users are encouraged to install pygments into their environment and provide feedback, because\nthe plan is to make pygments a regular dependency in the future.','provide feedback',0,'',''),(11902,'pytest','issue #759: pytest.mark.parametrize supports iterators and generators for ids.','support iterators for ids',0,'',''),(11903,'pytest','issue #759: pytest.mark.parametrize supports iterators and generators for ids.','support generators for ids',0,'',''),(11904,'pytest','issue #310: Add support for calling pytest.xfail() and pytest.importorskip() with doctests.','add support for calling',0,'',''),(11905,'pytest','issue #310: Add support for calling pytest.xfail() and pytest.importorskip() with doctests.','call pytest.xfail() with doctests',0,'',''),(11906,'pytest','issue #310: Add support for calling pytest.xfail() and pytest.importorskip() with doctests.','call pytest.importorskip() with doctests',0,'',''),(11907,'pytest','issue #4445: Fixed some warning reports produced by pytest to point to the correct location of the warning in the user’s code.','produce  by pytest',0,'',''),(11908,'pytest','issue #6334: Fix summary entries appearing twice when f/F and s/S report chars were used at the same time in the -r command-line option (for example -rFf).','use f/F       and         s/s report chars at same time',0,'',''),(11909,'pytest','A construct if key == cached_key: can fail either because == is explicitly disallowed, or for, e.g., NumPy arrays, where the result of a == b cannot generally be converted to bool.\nThe implemented fix replaces == with is.','replace implemented fix',0,'',''),(11910,'pytest','issue #6557: Make capture output streams .write() method return the same return value from original streams.','return same return value from original streams',0,'',''),(11911,'pytest','issue #6566: Fix EncodedFile.writelines to call the underlying buffer’s writelines method.','call writelines method',0,'',''),(11912,'pytest','issue #6575: Fix internal crash when faulthandler starts initialized\n(for example with PYTHONFAULTHANDLER=1 environment variable set) and faulthandler_timeout defined\nin the configuration file.','define  in configuration file',0,'',''),(11913,'pytest','issue #6646: Assertion rewriting hooks are (re)stored for the current item, which fixes them being still used after e.g. pytester’s testdir.runpytest etc.','store rewriting hooks for current item',0,'',''),(11914,'pytest','issue #6646: Assertion rewriting hooks are (re)stored for the current item, which fixes them being still used after e.g. pytester’s testdir.runpytest etc.','store assertion for current item',0,'',''),(11915,'pytest','issue #6646: Assertion rewriting hooks are (re)stored for the current item, which fixes them being still used after e.g. pytester’s testdir.runpytest etc.','use  after testdir.runpytest etc.',0,'',''),(11916,'pytest','issue #6646: Assertion rewriting hooks are (re)stored for the current item, which fixes them being still used after e.g. pytester’s testdir.runpytest etc.','fix current item',0,'',''),(11917,'pytest','issue #6660: pytest.exit() is handled when emitted from the pytest_sessionfinish hook.  This includes quitting from a debugger.','handle pytest.exit()',0,'',''),(11918,'pytest','issue #6752: When pytest.raises() is used as a function (as opposed to a context manager),\na match keyword argument is now passed through to the tested function. Previously\nit was swallowed and ignored (regression in pytest 5.1.0).','use pytest.raises() as function',0,'',''),(11919,'pytest','issue #6752: When pytest.raises() is used as a function (as opposed to a context manager),\na match keyword argument is now passed through to the tested function. Previously\nit was swallowed and ignored (regression in pytest 5.1.0).','pass argument',0,'',''),(11920,'pytest','issue #6742: Expand first sentence on fixtures into a paragraph.','expand first sentence into paragraph',0,'',''),(11921,'pytest','issue #6742: Expand first sentence on fixtures into a paragraph.','expand first sentence on fixtures',0,'',''),(11922,'pytest','issue #2780: Captured output during teardown is shown with -rP.','show captured output during teardown',0,'',''),(11923,'pytest','issue #5971: Fix a pytest-xdist crash when dealing with exceptions raised in subprocesses created by the\nmultiprocessing module.','fix pytest-xdist crash',0,'',''),(11924,'pytest','issue #5971: Fix a pytest-xdist crash when dealing with exceptions raised in subprocesses created by the\nmultiprocessing module.','raise  in subprocesses',0,'',''),(11925,'pytest','issue #6436: FixtureDef objects now properly register their finalizers with autouse and\nparameterized fixtures that execute before them in the fixture stack so they are torn\ndown at the right times, and in the right order.','execute autouse parameterized fixtures',0,'',''),(11926,'pytest','issue #5430: junitxml: Logs for failed test are now passed to junit report in case the test fails during call phase.','pass issue for failed test',0,'',''),(11927,'pytest','issue #6257: Handle pytest.exit() being used via pytest_internalerror, e.g. when quitting pdb from post mortem.','use  via pytest_internalerror',0,'',''),(11928,'pytest','issue #5914: pytester: fix no_fnmatch_line() when used after positive matching.','use  after positive matching',0,'',''),(11929,'pytest','issue #6255: Clear the sys.last_traceback, sys.last_type\nand sys.last_value attributes by deleting them instead\nof setting them to None. This better matches the behaviour of\nthe Python standard library.','set  to none',0,'',''),(11930,'pytest','issue #6255: Clear the sys.last_traceback, sys.last_type\nand sys.last_value attributes by deleting them instead\nof setting them to None. This better matches the behaviour of\nthe Python standard library.','match behaviour of Python standard library',0,'',''),(11931,'pytest','issue #6179: The default value of junit_family option will change to \"xunit2\" in pytest 6.0, given\nthat this is the version supported by default in modern tools that manipulate this type of file.','manipulate type of file',0,'',''),(11932,'pytest','issue #6179: The default value of junit_family option will change to \"xunit2\" in pytest 6.0, given\nthat this is the version supported by default in modern tools that manipulate this type of file.','manipulate version of file',0,'',''),(11933,'pytest','issue #6179: The default value of junit_family option will change to \"xunit2\" in pytest 6.0, given\nthat this is the version supported by default in modern tools that manipulate this type of file.','change  to xunit2',0,'',''),(11934,'pytest','issue #4488: The pytest team has created the pytest-reportlog\nplugin, which provides a new --report-log=FILE option that writes report logs into a file as the test session executes.','create pytest-reportlog plugin',0,'',''),(11935,'pytest','issue #4488: The pytest team has created the pytest-reportlog\nplugin, which provides a new --report-log=FILE option that writes report logs into a file as the test session executes.','create pytest team',0,'',''),(11936,'pytest','issue #4488: The pytest team has created the pytest-reportlog\nplugin, which provides a new --report-log=FILE option that writes report logs into a file as the test session executes.','provide pytest-reportlog plugin',0,'',''),(11937,'pytest','issue #4488: The pytest team has created the pytest-reportlog\nplugin, which provides a new --report-log=FILE option that writes report logs into a file as the test session executes.','log  into file',0,'',''),(11938,'pytest','issue #4488: The pytest team has created the pytest-reportlog\nplugin, which provides a new --report-log=FILE option that writes report logs into a file as the test session executes.','write report-log = FILE option',0,'',''),(11939,'pytest','Each line of the report log contains a self contained JSON object corresponding to a testing event,\nsuch as a collection or a test result report. The file is guaranteed to be flushed after writing\neach line, so systems can read and process events in real-time.','write line',0,'',''),(11940,'pytest','Each line of the report log contains a self contained JSON object corresponding to a testing event,\nsuch as a collection or a test result report. The file is guaranteed to be flushed after writing\neach line, so systems can read and process events in real-time.','read events in real-time',0,'',''),(11941,'pytest','Each line of the report log contains a self contained JSON object corresponding to a testing event,\nsuch as a collection or a test result report. The file is guaranteed to be flushed after writing\neach line, so systems can read and process events in real-time.','process events in real-time',0,'',''),(11942,'pytest','Each line of the report log contains a self contained JSON object corresponding to a testing event,\nsuch as a collection or a test result report. The file is guaranteed to be flushed after writing\neach line, so systems can read and process events in real-time.','flush  after writing',0,'',''),(11943,'pytest','The plugin is meant to replace the --resultlog option, which is deprecated and meant to be removed\nin a future release. If you use --resultlog, please try out pytest-reportlog and\nprovide feedback.','replace resultlog option',0,'',''),(11944,'pytest','The plugin is meant to replace the --resultlog option, which is deprecated and meant to be removed\nin a future release. If you use --resultlog, please try out pytest-reportlog and\nprovide feedback.','remove  in future release',0,'',''),(11945,'pytest','The plugin is meant to replace the --resultlog option, which is deprecated and meant to be removed\nin a future release. If you use --resultlog, please try out pytest-reportlog and\nprovide feedback.','use resultlog',0,'',''),(11946,'pytest','issue #4730: When sys.pycache_prefix (Python 3.8+) is set, it will be used by pytest to cache test files changed by the assertion rewriting mechanism.','use  to cache test files',0,'',''),(11947,'pytest','issue #4730: When sys.pycache_prefix (Python 3.8+) is set, it will be used by pytest to cache test files changed by the assertion rewriting mechanism.','set sys.pycache_prefix',0,'',''),(11948,'pytest','Adds command line option --log-auto-indent, config option\nlog_auto_indent and support for per-entry configuration of\nindentation behavior on calls to logging.log().','add command line option',0,'',''),(11949,'pytest','Alters the default for auto-indention from \"on\" to \"off\". This\nrestores the older behavior that existed prior to v4.6.0. This\nreversion to earlier behavior was done because it is better to\nactivate new features that may lead to broken tests explicitly\nrather than implicitly.','activate new features',0,'',''),(11950,'pytest','issue #5914: testdir learned two new functions, no_fnmatch_line() and\nno_re_match_line().','learn new functions',0,'',''),(11951,'pytest','issue #5914: testdir learned two new functions, no_fnmatch_line() and\nno_re_match_line().','learn no_fnmatch_line()',0,'',''),(11952,'pytest','issue #5914: testdir learned two new functions, no_fnmatch_line() and\nno_re_match_line().','learn no_re_match_line()',0,'',''),(11953,'pytest','The functions are used to ensure the captured text does not match the given\npattern.','use functions',0,'',''),(11954,'pytest','The previous idiom was to use re.match():','use re.match()',1,'https://docs.pytest.org/en/7.2.x/changelog.html',''),(11955,'pytest','But the new functions produce best output on failure.','produce best output on failure',0,'',''),(11956,'pytest','issue #6057: Added tolerances to complex values when printing pytest.approx.','add tolerances to complex values',0,'',''),(11957,'pytest','issue #6057: Added tolerances to complex values when printing pytest.approx.','print pytest.approx',0,'',''),(11958,'pytest','For example, repr(pytest.approx(3+4j)) returns (3+4j) ± 5e-06 ∠ ±180°. This is polar notation indicating a circle around the expected value, with a radius of 5e-06. For approx comparisons to return True, the actual value should fall within this circle.','return 5e-06 â  Â± Â°',0,'',''),(11959,'pytest','issue #6061: Added the pluginmanager as an argument to pytest_addoption\nso that hooks can be invoked when setting up command line options. This is\nuseful for having one plugin communicate things to another plugin,\nsuch as default values or which set of command line options to add.','add pluginmanager as argument',0,'',''),(11960,'pytest','issue #6061: Added the pluginmanager as an argument to pytest_addoption\nso that hooks can be invoked when setting up command line options. This is\nuseful for having one plugin communicate things to another plugin,\nsuch as default values or which set of command line options to add.','add pluginmanager to pytest_addoption',0,'',''),(11961,'pytest','issue #6061: Added the pluginmanager as an argument to pytest_addoption\nso that hooks can be invoked when setting up command line options. This is\nuseful for having one plugin communicate things to another plugin,\nsuch as default values or which set of command line options to add.','set up command line options',0,'',''),(11962,'pytest','issue #6061: Added the pluginmanager as an argument to pytest_addoption\nso that hooks can be invoked when setting up command line options. This is\nuseful for having one plugin communicate things to another plugin,\nsuch as default values or which set of command line options to add.','set  of command line options',0,'',''),(11963,'pytest','issue #5630: Quitting from debuggers is now properly handled in doctest items.','handle issue in doctest items',0,'',''),(11964,'pytest','issue #6023: pytest.main returns a pytest.ExitCode instance now, except for when custom exit codes are used (where it returns int then still).','use custom exit codes',0,'',''),(11965,'pytest','issue #6148: atomicwrites is now only used on Windows, fixing a performance regression with assertion rewriting on Unix.','fix performance regression with assertion rewriting',0,'',''),(11966,'pytest','issue #6148: atomicwrites is now only used on Windows, fixing a performance regression with assertion rewriting on Unix.','use atomicwrites on windows',0,'',''),(11967,'pytest','issue #6152: Now parametrization will use the __name__ attribute of any object for the id, if present. Previously it would only use __name__ for functions and classes.','use __name__ attribute of object',0,'',''),(11968,'pytest','issue #6152: Now parametrization will use the __name__ attribute of any object for the id, if present. Previously it would only use __name__ for functions and classes.','use __name__ attribute for id',0,'',''),(11969,'pytest','issue #6152: Now parametrization will use the __name__ attribute of any object for the id, if present. Previously it would only use __name__ for functions and classes.','use __name__ for functions',0,'',''),(11970,'pytest','issue #6152: Now parametrization will use the __name__ attribute of any object for the id, if present. Previously it would only use __name__ for functions and classes.','use __name__ for classes',0,'',''),(11971,'pytest','issue #2049: Fixed --setup-plan showing inaccurate information about fixture lifetimes.','show inaccurate information about fixture lifetimes',0,'',''),(11972,'pytest','This is important when used with pytester’s runpytest_inprocess.','use  with runpytest_inprocess',0,'',''),(11973,'pytest','issue #6047: BaseExceptions are now handled in saferepr, which includes pytest.fail.Exception etc.','include pytest.fail.Exception etc.',0,'',''),(11974,'pytest','issue #6047: BaseExceptions are now handled in saferepr, which includes pytest.fail.Exception etc.','include saferepr',0,'',''),(11975,'pytest','issue #6047: BaseExceptions are now handled in saferepr, which includes pytest.fail.Exception etc.','handle BaseExceptions in saferepr',0,'',''),(11976,'pytest','issue #6197: Revert “The first test in a package (__init__.py) marked with @pytest.mark.skip is now correctly skipped.”.','mark  with',0,'',''),(11977,'pytest','issue #5830: The first test in a package (__init__.py) marked with @pytest.mark.skip is now correctly skipped.','mark  with',0,'',''),(11978,'pytest','issue #6099: Fix --trace when used with parametrized functions.','use  with parametrized functions',0,'',''),(11979,'pytest','issue #6183: Using request as a parameter name in @pytest.mark.parametrize now produces a more\nuser-friendly error.','use request as parameter name',0,'',''),(11980,'pytest','issue #6183: Using request as a parameter name in @pytest.mark.parametrize now produces a more\nuser-friendly error.','produce more user-friendly error',0,'',''),(11981,'pytest','issue #5906: Fix crash with KeyboardInterrupt during --setup-show.','fix crash with KeyboardInterrupt',0,'',''),(11982,'pytest','issue #6044: Properly ignore FileNotFoundError exceptions when trying to remove old temporary directories,\nfor instance when multiple processes try to remove the same directory (common with pytest-xdist\nfor example).','ignore FileNotFoundError exceptions for instance',0,'',''),(11983,'pytest','issue #6044: Properly ignore FileNotFoundError exceptions when trying to remove old temporary directories,\nfor instance when multiple processes try to remove the same directory (common with pytest-xdist\nfor example).','remove old temporary directories',0,'',''),(11984,'pytest','issue #6044: Properly ignore FileNotFoundError exceptions when trying to remove old temporary directories,\nfor instance when multiple processes try to remove the same directory (common with pytest-xdist\nfor example).','remove same directory',0,'',''),(11985,'pytest','issue #1682: Passing arguments to pytest.fixture() as positional arguments is deprecated - pass them\nas a keyword argument instead.','pass arguments to pytest.fixture()',0,'',''),(11986,'pytest','issue #1682: Passing arguments to pytest.fixture() as positional arguments is deprecated - pass them\nas a keyword argument instead.','pass  as keyword argument',0,'',''),(11987,'pytest','issue #1682: The scope parameter of @pytest.fixture can now be a callable that receives\nthe fixture name and the config object as keyword-only parameters.\nSee the docs for more information.','receive fixture',0,'',''),(11988,'pytest','issue #5807: Fix pypy3.6 (nightly) on windows.','fix  on windows',0,'',''),(11989,'pytest','issue #2270: Fixed self reference in function-scoped fixtures defined plugin classes: previously self\nwould be a reference to a test class, not the plugin class.','fix self reference in function-scoped fixtures',0,'',''),(11990,'pytest','issue #2270: Fixed self reference in function-scoped fixtures defined plugin classes: previously self\nwould be a reference to a test class, not the plugin class.','define plugin classes',0,'',''),(11991,'pytest','issue #570: Fixed long standing issue where fixture scope was not respected when indirect fixtures were used during\nparametrization.','fix long standing issue',0,'',''),(11992,'pytest','issue #570: Fixed long standing issue where fixture scope was not respected when indirect fixtures were used during\nparametrization.','use indirect fixtures during parametrization',0,'',''),(11993,'pytest','issue #5782: Fix decoding error when printing an error response from --pastebin.','fix decoding error',0,'',''),(11994,'pytest','issue #5782: Fix decoding error when printing an error response from --pastebin.','print error response',0,'',''),(11995,'pytest','issue #5792: Windows: Fix error that occurs in certain circumstances when loading\nconftest.py from a working directory that has casing other than the one stored\nin the filesystem (e.g., c:\\test instead of C:\\test).','store  in filesystem',0,'',''),(11996,'pytest','issue #5751: Fixed TypeError when importing pytest on Python 3.5.0 and 3.5.1.','import pytest on Python 3.5.0',0,'',''),(11997,'pytest','issue #5751: Fixed TypeError when importing pytest on Python 3.5.0 and 3.5.1.','import pytest on 3.5.1',0,'',''),(11998,'pytest','pytest.raises and pytest.warns no longer support strings as the second argument.','support strings as second argument',0,'',''),(11999,'pytest','pytest.raises, pytest.warns and ParameterSet.param now use native keyword-only\nsyntax. This might change the exception message from previous versions, but they still raise\nTypeError on unknown keyword arguments as before.','use native keyword-only syntax',0,'',''),(12000,'pytest','pytest.raises, pytest.warns and ParameterSet.param now use native keyword-only\nsyntax. This might change the exception message from previous versions, but they still raise\nTypeError on unknown keyword arguments as before.','change exception message from previous versions',0,'',''),(12001,'pytest','pytest.raises, pytest.warns and ParameterSet.param now use native keyword-only\nsyntax. This might change the exception message from previous versions, but they still raise\nTypeError on unknown keyword arguments as before.','raise TypeError on unknown keyword arguments',0,'',''),(12002,'pytest','Although our policy is to introduce a deprecation period before removing any features or support\nfor third party libraries, because this code is apparently not used\nat all (even if unittest2 is used by a test suite executed by pytest), it was decided to\nremove it in this release.','introduce deprecation period before removing',0,'',''),(12003,'pytest','Although our policy is to introduce a deprecation period before removing any features or support\nfor third party libraries, because this code is apparently not used\nat all (even if unittest2 is used by a test suite executed by pytest), it was decided to\nremove it in this release.','remove features',0,'',''),(12004,'pytest','Although our policy is to introduce a deprecation period before removing any features or support\nfor third party libraries, because this code is apparently not used\nat all (even if unittest2 is used by a test suite executed by pytest), it was decided to\nremove it in this release.','remove  in release',0,'',''),(12005,'pytest','Although our policy is to introduce a deprecation period before removing any features or support\nfor third party libraries, because this code is apparently not used\nat all (even if unittest2 is used by a test suite executed by pytest), it was decided to\nremove it in this release.','support  for third party libraries',0,'',''),(12006,'pytest','This was supported for Python 2 where it was tempting to use \"message\"\ninstead of u\"message\".','use message instead_of u message',0,'',''),(12007,'pytest','This was supported for Python 2 where it was tempting to use \"message\"\ninstead of u\"message\".','support  for Python',0,'',''),(12008,'pytest','Python 3 code is unlikely to pass bytes to these functions. If you do,\nplease decode it to an str beforehand.','pass bytes to functions',0,'',''),(12009,'pytest','issue #5564: New Config.invocation_args attribute containing the unchanged arguments passed to pytest.main().','pass  to pytest.main()',0,'',''),(12010,'pytest','issue #5576: New NUMBER\noption for doctests to ignore irrelevant differences in floating-point numbers.\nInspired by Sébastien Boisgérault’s numtest\nextension for doctest.','ignore irrelevant differences in floating-point numbers',0,'',''),(12011,'pytest','issue #5471: JUnit XML now includes a timestamp and hostname in the testsuite tag.','include timestamp in testsuite tag',0,'',''),(12012,'pytest','issue #5471: JUnit XML now includes a timestamp and hostname in the testsuite tag.','include hostname in testsuite tag',0,'',''),(12013,'pytest','issue #5707: Time taken to run the test suite now includes a human-readable representation when it takes over\n60 seconds, for example:','run test suite',1,'https://docs.pytest.org/en/7.2.x/changelog.html',''),(12014,'pytest','issue #5707: Time taken to run the test suite now includes a human-readable representation when it takes over\n60 seconds, for example:','include human-readable representation',1,'https://docs.pytest.org/en/7.2.x/changelog.html',''),(12015,'pytest','issue #5115: Warnings issued during pytest_configure are explicitly not treated as errors, even if configured as such, because it otherwise completely breaks pytest.','break pytest',0,'',''),(12016,'pytest','issue #5524: Fix issue where tmp_path and tmpdir would not remove directories containing files marked as read-only,\nwhich could lead to pytest crashing when executed a second time with the --basetemp option.','execute second time with basetemp option',0,'',''),(12017,'pytest','issue #5578: Improve type checking for some exception-raising functions (pytest.xfail, pytest.skip, etc)\nso they provide better error messages when users meant to use marks (for example @pytest.xfail\ninstead of @pytest.mark.xfail).','provide better error messages',0,'',''),(12018,'pytest','issue #5578: Improve type checking for some exception-raising functions (pytest.xfail, pytest.skip, etc)\nso they provide better error messages when users meant to use marks (for example @pytest.xfail\ninstead of @pytest.mark.xfail).','use marks',0,'',''),(12019,'pytest','issue #5578: Improve type checking for some exception-raising functions (pytest.xfail, pytest.skip, etc)\nso they provide better error messages when users meant to use marks (for example @pytest.xfail\ninstead of @pytest.mark.xfail).','check  for exception-raising functions',0,'',''),(12020,'pytest','issue #5606: Fixed internal error when test functions were patched with objects that cannot be compared\nfor truth values against others, like numpy arrays.','patch test functions with objects',0,'',''),(12021,'pytest','issue #5634: pytest.exit is now correctly handled in unittest cases.\nThis makes unittest cases handle quit from pytest’s pdb correctly.','handle pytest.exit in unittest cases',0,'',''),(12022,'pytest','issue #5701: Fix collection of staticmethod objects defined with functools.partial.','define  with functools.partial',0,'',''),(12023,'pytest','issue #5734: Skip async generator test functions, and update the warning message to refer to async def functions.','update warning message',0,'',''),(12024,'pytest','issue #5603: Simplified internal SafeRepr class and removed some dead code.','remove dead code',0,'',''),(12025,'pytest','issue #5523: Fixed using multiple short options together in the command-line (for example -vs) in Python 3.8+.','use multiple short options in command-line',0,'',''),(12026,'pytest','issue #5547: --step-wise now handles xfail(strict=True) markers properly.','handle xfail(strict=True) markers',0,'',''),(12027,'pytest','issue #5517: Improve “Declaring new hooks” section in chapter “Writing Plugins”','write plugins',0,'',''),(12028,'pytest','The affected features will be effectively removed in pytest 5.1, so please consult the\nDeprecations and Removals section in the docs for directions on how to update existing code.','update existing code',0,'',''),(12029,'pytest','The affected features will be effectively removed in pytest 5.1, so please consult the\nDeprecations and Removals section in the docs for directions on how to update existing code.','remove affected features',0,'',''),(12030,'pytest','In the pytest 5.0.X series, it is possible to change the errors back into warnings as a stop\ngap measure by adding this to your pytest.ini file:','add  to pytest.ini file',0,'',''),(12031,'pytest','But this will stop working when pytest 5.1 is released.','release pytest',0,'',''),(12032,'pytest','If you have concerns about the removal of a specific feature, please add a\ncomment to issue #5402.','add comment',0,'',''),(12033,'pytest','issue #5412: ExceptionInfo objects (returned by pytest.raises) now have the same str representation as repr, which\navoids some confusion when users use print(e) to inspect the object.','use print(e)',1,'https://docs.pytest.org/en/7.2.x/changelog.html',''),(12034,'pytest','Needs to be changed to:','change needs',1,'https://docs.pytest.org/en/7.2.x/changelog.html',''),(12035,'pytest','issue #4488: The removal of the --result-log option and module has been postponed to (tentatively) pytest 6.0 as\nthe team has not yet got around to implement a good alternative for it.','implement good alternative',0,'',''),(12036,'pytest','issue #3457: New pytest_assertion_pass\nhook, called with context information when an assertion passes.','call  with context information',0,'',''),(12037,'pytest','This hook is still experimental so use it with caution.','use  with caution',0,'',''),(12038,'pytest','issue #5440: The faulthandler standard library\nmodule is now enabled by default to help users diagnose crashes in C modules.','enable standard library module',0,'',''),(12039,'pytest','issue #5440: The faulthandler standard library\nmodule is now enabled by default to help users diagnose crashes in C modules.','enable faulthandler',0,'',''),(12040,'pytest','This functionality was provided by integrating the external\npytest-faulthandler plugin into the core,\nso users should remove that plugin from their requirements if used.','integrate external pytest-faulthandler plugin into core',0,'',''),(12041,'pytest','This functionality was provided by integrating the external\npytest-faulthandler plugin into the core,\nso users should remove that plugin from their requirements if used.','remove plugin from requirements',0,'',''),(12042,'pytest','issue #5452: When warnings are configured as errors, pytest warnings now appear as originating from pytest. instead of the internal _pytest.warning_types. module.','configure warnings',0,'',''),(12043,'pytest','issue #5125: Session.exitcode values are now coded in pytest.ExitCode, an IntEnum. This makes the exit code available for consumer code and are more explicit other than just documentation. User defined exit codes are still valid, but should be used with caution.','use exit codes with caution',0,'',''),(12044,'pytest','The team doesn’t expect this change to break test suites or plugins in general, except in esoteric/specific scenarios.','break test suites in general',0,'',''),(12045,'pytest','The team doesn’t expect this change to break test suites or plugins in general, except in esoteric/specific scenarios.','break plugins in general',0,'',''),(12046,'pytest','issue #1403: Switch from imp to importlib.','switch  from imp',0,'',''),(12047,'pytest','issue #1403: Switch from imp to importlib.','switch  to importlib',0,'',''),(12048,'pytest','issue #1671: The name of the .pyc files cached by the assertion writer now includes the pytest version\nto avoid stale caches.','include pytest version',0,'',''),(12049,'pytest','When comparing bytes, the assertion message used to show the byte numeric value when showing the differences:','compare bytes',1,'https://docs.pytest.org/en/7.2.x/changelog.html',''),(12050,'pytest','When comparing bytes, the assertion message used to show the byte numeric value when showing the differences:','show byte numeric value',1,'https://docs.pytest.org/en/7.2.x/changelog.html',''),(12051,'pytest','When comparing bytes, the assertion message used to show the byte numeric value when showing the differences:','show differences',1,'https://docs.pytest.org/en/7.2.x/changelog.html',''),(12052,'pytest','It now shows the actual ascii representation instead, which is often more useful:','show actual ascii representation',1,'https://docs.pytest.org/en/7.2.x/changelog.html',''),(12053,'pytest','issue #5335: Colorize level names when the level in the logging format is formatted using\n‘%(levelname).Xs’ (truncated fixed width alignment), where X is an integer.','use â%(levelname).Xsâ',0,'',''),(12054,'pytest','issue #5335: Colorize level names when the level in the logging format is formatted using\n‘%(levelname).Xs’ (truncated fixed width alignment), where X is an integer.','format level in logging format',0,'',''),(12055,'pytest','issue #5370: Revert unrolling of all() to fix NameError on nested comprehensions.','fix NameError on nested comprehensions',0,'',''),(12056,'pytest','issue #5371: Revert unrolling of all() to fix incorrect handling of generators with if.','fix incorrect handling of generators',0,'',''),(12057,'pytest','issue #5372: Revert unrolling of all() to fix incorrect assertion when using all() in an expression.','fix incorrect assertion',0,'',''),(12058,'pytest','issue #5372: Revert unrolling of all() to fix incorrect assertion when using all() in an expression.','use all() in expression',0,'',''),(12059,'pytest','issue #5383: -q has again an impact on the style of the collected items\n(--collect-only) when --log-cli-level is used.','use log-cli-level',0,'',''),(12060,'pytest','issue #5390: Fix regression where the obj attribute of TestCase items was no longer bound to methods.','bind obj attribute of TestCase items',0,'',''),(12061,'pytest','issue #5390: Fix regression where the obj attribute of TestCase items was no longer bound to methods.','bind obj attribute to methods',0,'',''),(12062,'pytest','issue #5390: Fix regression where the obj attribute of TestCase items was no longer bound to methods.','bind fix regression of TestCase items',0,'',''),(12063,'pytest','issue #5390: Fix regression where the obj attribute of TestCase items was no longer bound to methods.','bind fix regression to methods',0,'',''),(12064,'pytest','issue #5404: Emit a warning when attempting to unwrap a broken object raises an exception,\nfor easier debugging (issue #5080).','raise exception',0,'',''),(12065,'pytest','issue #5432: Prevent “already imported” warnings from assertion rewriter when invoking pytest in-process multiple times.','import warnings from assertion rewriter',0,'',''),(12066,'pytest','issue #5444: Fix --stepwise mode when the first file passed on the command-line fails to collect.','pass  on command-line',0,'',''),(12067,'pytest','issue #5482: Fix bug introduced in 4.6.0 causing collection errors when passing\nmore than 2 positional arguments to pytest.mark.parametrize.','pass positional arguments to pytest.mark.parametrize',0,'',''),(12068,'pytest','issue #5482: Fix bug introduced in 4.6.0 causing collection errors when passing\nmore than 2 positional arguments to pytest.mark.parametrize.','introduce  in 4.6.0',0,'',''),(12069,'pytest','issue #5315: Expand docs on mocking classes and dictionaries with monkeypatch.','mock classes with monkeypatch',0,'',''),(12070,'pytest','issue #5315: Expand docs on mocking classes and dictionaries with monkeypatch.','mock dictionaries with monkeypatch',0,'',''),(12071,'pytest','issue #7310: Fix UnboundLocalError: local variable \'letter\' referenced before\nassignment in _pytest.terminal.pytest_report_teststatus()\nwhen plugins return report objects in an unconventional state.','return report objects in unconventional state',0,'',''),(12072,'pytest','This was making pytest_report_teststatus() skip\nentering if-block branches that declare the letter variable.','enter if-block branches',0,'',''),(12073,'pytest','The fix was to set the initial value of the letter before\nthe if-block cascade so that it always has a value.','set initial value before if-block cascade',0,'',''),(12074,'pytest','The fix was to set the initial value of the letter before\nthe if-block cascade so that it always has a value.','set initial value of letter',0,'',''),(12075,'pytest','issue #6870: New Config.invocation_args attribute containing the unchanged arguments passed to pytest.main().','pass  to pytest.main()',0,'',''),(12076,'pytest','Remark: while this is technically a new feature and according to our\npolicy\nit should not have been backported, we have opened an exception in this\nparticular case because it fixes a serious interaction with pytest-xdist,\nso it can also be considered a bugfix.','open exception in particular case',0,'',''),(12077,'pytest','Remark: while this is technically a new feature and according to our\npolicy\nit should not have been backported, we have opened an exception in this\nparticular case because it fixes a serious interaction with pytest-xdist,\nso it can also be considered a bugfix.','fix serious interaction with pytest-xdist',0,'',''),(12078,'pytest','issue #6345: Pin colorama to 0.4.1 only for Python 3.4 so newer Python versions can still receive colorama updates.','receive colorama updates',0,'',''),(12079,'pytest','issue #6044: Properly ignore FileNotFoundError (OSError.errno == NOENT in Python 2) exceptions when trying to remove old temporary directories,\nfor instance when multiple processes try to remove the same directory (common with pytest-xdist\nfor example).','ignore FileNotFoundError exceptions for instance',0,'',''),(12080,'pytest','issue #6044: Properly ignore FileNotFoundError (OSError.errno == NOENT in Python 2) exceptions when trying to remove old temporary directories,\nfor instance when multiple processes try to remove the same directory (common with pytest-xdist\nfor example).','remove old temporary directories',0,'',''),(12081,'pytest','issue #6044: Properly ignore FileNotFoundError (OSError.errno == NOENT in Python 2) exceptions when trying to remove old temporary directories,\nfor instance when multiple processes try to remove the same directory (common with pytest-xdist\nfor example).','remove same directory',0,'',''),(12082,'pytest','issue #5478: Fix encode error when using unicode strings in exceptions with pytest.raises.','fix encode error',0,'',''),(12083,'pytest','issue #5478: Fix encode error when using unicode strings in exceptions with pytest.raises.','use unicode strings in exceptions',0,'',''),(12084,'pytest','The 4.6.X series will be the last series to support Python 2 and Python 3.4.','support Python',0,'',''),(12085,'pytest','The 4.6.X series will be the last series to support Python 2 and Python 3.4.','support Python',0,'',''),(12086,'pytest','issue #4559: Added the junit_log_passing_tests ini value which can be used to enable or disable logging of passing test output in the Junit XML file.','add junit_log_passing_tests ini value',0,'',''),(12087,'pytest','issue #4559: Added the junit_log_passing_tests ini value which can be used to enable or disable logging of passing test output in the Junit XML file.','pass test output in Junit XML file',0,'',''),(12088,'pytest','issue #4559: Added the junit_log_passing_tests ini value which can be used to enable or disable logging of passing test output in the Junit XML file.','log  of passing',0,'',''),(12089,'pytest','issue #4559: Added the junit_log_passing_tests ini value which can be used to enable or disable logging of passing test output in the Junit XML file.','use junit_log_passing_tests ini value',0,'',''),(12090,'pytest','issue #5062: Unroll calls to all to full for-loops with assertion rewriting for better failure messages, especially when using Generator Expressions.','use Generator expressions',0,'',''),(12091,'pytest','issue #5062: Unroll calls to all to full for-loops with assertion rewriting for better failure messages, especially when using Generator Expressions.','call  with assertion rewriting',0,'',''),(12092,'pytest','issue #5063: Switch from pkg_resources to importlib-metadata for entrypoint detection for improved performance and import time.','switch  from pkg_resources',0,'',''),(12093,'pytest','issue #5063: Switch from pkg_resources to importlib-metadata for entrypoint detection for improved performance and import time.','switch  to importlib-metadata',0,'',''),(12094,'pytest','issue #5269: pytest.importorskip includes the ImportError now in the default reason.','include ImportError in default reason',0,'',''),(12095,'pytest','issue #5311: Captured logs that are output for each failing test are formatted using the\nColoredLevelFormatter.','use ColoredLevelFormatter',0,'',''),(12096,'pytest','issue #4908: The pytest_enter_pdb hook gets called with post-mortem (--pdb).','call pytest_enter_pdb hook with post-mortem',0,'',''),(12097,'pytest','issue #5278: Pytest’s internal python plugin can be disabled using -p no:python again.','disable internal python plugin',0,'',''),(12098,'pytest','issue #5286: Fix issue with disable_test_id_escaping_and_forfeit_all_rights_to_community_support option not working when using a list of test IDs in parametrized tests.','use list of test ids',0,'',''),(12099,'pytest','issue #5330: Show the test module being collected when emitting PytestCollectionWarning messages for\ntest classes with __init__ and __new__ methods to make it easier to pin down the problem.','show test module',0,'',''),(12100,'pytest','issue #5333: Fix regression in 4.5.0 with --lf not re-running all tests with known failures from non-selected tests.','fix regression in 4.5.0',0,'',''),(12101,'pytest','issue #5250: Expand docs on use of setenv and delenv with monkeypatch.','expand docs with monkeypatch',0,'',''),(12102,'pytest','issue #5250: Expand docs on use of setenv and delenv with monkeypatch.','expand docs on use',0,'',''),(12103,'pytest','issue #4826: A warning is now emitted when unknown marks are used as a decorator.\nThis is often due to a typo, which can lead to silently broken tests.','use unknown marks as decorator',0,'',''),(12104,'pytest','issue #5013: Messages from crash reports are displayed within test summaries now, truncated to the terminal width.','display crash reports within test summaries',0,'',''),(12105,'pytest','issue #5023: New flag --strict-markers that triggers an error when unknown markers (e.g. those not registered using the markers option in the configuration file) are used in the test suite.','trigger error',0,'',''),(12106,'pytest','issue #5023: New flag --strict-markers that triggers an error when unknown markers (e.g. those not registered using the markers option in the configuration file) are used in the test suite.','trigger strict-markers',0,'',''),(12107,'pytest','issue #5023: New flag --strict-markers that triggers an error when unknown markers (e.g. those not registered using the markers option in the configuration file) are used in the test suite.','use unknown markers in test suite',0,'',''),(12108,'pytest','issue #5035: The --cache-show option/action accepts an optional glob to show only matching cache entries.','show matching cache entries',0,'',''),(12109,'pytest','issue #5068: The -r option learnt about A to display all reports (including passed ones) in the short test summary.','display reports in short test summary',0,'',''),(12110,'pytest','issue #5068: The -r option learnt about A to display all reports (including passed ones) in the short test summary.','learn  about a',0,'',''),(12111,'pytest','issue #5108: The short test summary is displayed after passes with output (-rP).','display short test summary after passes',0,'',''),(12112,'pytest','issue #5172: The --last-failed (--lf) option got smarter and will now skip entire files if all tests\nof that test file have passed in previous runs, greatly speeding up collection.','skip entire files',0,'',''),(12113,'pytest','issue #5172: The --last-failed (--lf) option got smarter and will now skip entire files if all tests\nof that test file have passed in previous runs, greatly speeding up collection.','pass  in previous runs',0,'',''),(12114,'pytest','issue #5202: New record_testsuite_property session-scoped fixture allows users to log  tags at the testsuite\nlevel with the junitxml plugin.','log tags at testsuite level',0,'',''),(12115,'pytest','issue #5214: The default logging format has been changed to improve readability. Here is an\nexample of a previous logging message:','change format',1,'https://docs.pytest.org/en/7.2.x/changelog.html',''),(12116,'pytest','issue #5214: The default logging format has been changed to improve readability. Here is an\nexample of a previous logging message:','change default',1,'https://docs.pytest.org/en/7.2.x/changelog.html',''),(12117,'pytest','The formatting can be changed through the log_format configuration option.','change formatting through log_format configuration option',0,'',''),(12118,'pytest','issue #5220: --fixtures now also shows fixture scope for scopes other than \"function\".','show fixture scope for scopes',0,'',''),(12119,'pytest','issue #5113: Deselected items from plugins using pytest_collect_modifyitems as a hookwrapper are correctly reported now.','use pytest_collect_modifyitems',0,'',''),(12120,'pytest','issue #5144: With usage errors exitstatus is set to EXIT_USAGEERROR in the pytest_sessionfinish hook now as expected.','set issue with usage errors exitstatus',0,'',''),(12121,'pytest','issue #5144: With usage errors exitstatus is set to EXIT_USAGEERROR in the pytest_sessionfinish hook now as expected.','set issue in pytest_sessionfinish hook',0,'',''),(12122,'pytest','issue #5144: With usage errors exitstatus is set to EXIT_USAGEERROR in the pytest_sessionfinish hook now as expected.','set issue to EXIT_USAGEERROR',0,'',''),(12123,'pytest','issue #5013: pytest now depends on wcwidth to properly track unicode character sizes for more precise terminal output.','track unicode character sizes for precise terminal output',0,'',''),(12124,'pytest','issue #5059: pytester’s Testdir.popen() uses stdout and stderr via keyword arguments with defaults now (subprocess.PIPE).','use stdout via keyword arguments',0,'',''),(12125,'pytest','issue #5059: pytester’s Testdir.popen() uses stdout and stderr via keyword arguments with defaults now (subprocess.PIPE).','use stderr via keyword arguments',0,'',''),(12126,'pytest','issue #5069: The code for the short test summary in the terminal was moved to the terminal plugin.','move issue to terminal plugin',0,'',''),(12127,'pytest','issue #5202: record_property now emits a PytestWarning when used with junit_family=xunit2: the fixture generates\nproperty tags as children of testcase, which is not permitted according to the most\nrecent schema.','generate property tags as children',0,'',''),(12128,'pytest','issue #5202: record_property now emits a PytestWarning when used with junit_family=xunit2: the fixture generates\nproperty tags as children of testcase, which is not permitted according to the most\nrecent schema.','use  with junit_family',0,'',''),(12129,'pytest','issue #5239: Pin pluggy to < 1.0 so we don’t update to 1.0 automatically when\nit gets released: there are planned breaking changes, and we want to ensure\npytest properly supports pluggy 1.0.','break changes',0,'',''),(12130,'pytest','issue #5229: Require pluggy>=0.11.0 which reverts a dependency to importlib-metadata added in 0.10.0.\nThe importlib-metadata package cannot be imported when installed as an egg and causes issues when relying on setup.py to install test dependencies.','add  in 0.10.0',0,'',''),(12131,'pytest','issue #5229: Require pluggy>=0.11.0 which reverts a dependency to importlib-metadata added in 0.10.0.\nThe importlib-metadata package cannot be imported when installed as an egg and causes issues when relying on setup.py to install test dependencies.','install test dependencies',0,'',''),(12132,'pytest','issue #5229: Require pluggy>=0.11.0 which reverts a dependency to importlib-metadata added in 0.10.0.\nThe importlib-metadata package cannot be imported when installed as an egg and causes issues when relying on setup.py to install test dependencies.','install  as egg',0,'',''),(12133,'pytest','issue #5229: Require pluggy>=0.11.0 which reverts a dependency to importlib-metadata added in 0.10.0.\nThe importlib-metadata package cannot be imported when installed as an egg and causes issues when relying on setup.py to install test dependencies.','install  as causes',0,'',''),(12134,'pytest','issue #5031: Environment variables are properly restored when using pytester’s testdir fixture.','use testdir fixture',0,'',''),(12135,'pytest','issue #5092: Produce a warning when unknown keywords are passed to pytest.param(...).','produce warning',0,'',''),(12136,'pytest','issue #5092: Produce a warning when unknown keywords are passed to pytest.param(...).','pass unknown keywords to pytest.param(...)',0,'',''),(12137,'pytest','issue #2482: Include new disable_test_id_escaping_and_forfeit_all_rights_to_community_support option to disable ascii-escaping in parametrized values. This may cause a series of problems and as the name makes clear, use at your own risk.','use  at own risk',0,'',''),(12138,'pytest','issue #4718: The -p option can now be used to early-load plugins also by entry-point name, instead of just\nby module name.','use p option to early-load plugins',0,'',''),(12139,'pytest','This makes it possible to early load external plugins like pytest-cov in the command-line:','load external plugins in command-line',1,'https://docs.pytest.org/en/7.2.x/changelog.html',''),(12140,'pytest','issue #4855: The --pdbcls option handles classes via module attributes now (e.g.\npdb:pdb.Pdb with pdbpp), and its validation was improved.','handle classes via module attributes',0,'',''),(12141,'pytest','issue #4875: The testpaths configuration option is now displayed next\nto the rootdir and inifile lines in the pytest header if the option is in effect, i.e., directories or file names were\nnot explicitly passed in the command line.','display testpaths configuration option in pytest header',0,'',''),(12142,'pytest','issue #4875: The testpaths configuration option is now displayed next\nto the rootdir and inifile lines in the pytest header if the option is in effect, i.e., directories or file names were\nnot explicitly passed in the command line.','display testpaths configuration option next_to rootdir inifile lines',0,'',''),(12143,'pytest','Also, inifile is only displayed if there’s a configuration file, instead of an empty inifile: string.','display inifile',0,'',''),(12144,'pytest','issue #4911: Doctests can be skipped now dynamically using pytest.skip().','use pytest.skip()',0,'',''),(12145,'pytest','issue #4911: Doctests can be skipped now dynamically using pytest.skip().','skip doctests',0,'',''),(12146,'pytest','issue #4920: Internal refactorings have been made in order to make the implementation of the\npytest-subtests plugin\npossible, which adds unittest sub-test support and a new subtests fixture as discussed in\nissue #1367.','add unittest sub-test support',0,'',''),(12147,'pytest','issue #4920: Internal refactorings have been made in order to make the implementation of the\npytest-subtests plugin\npossible, which adds unittest sub-test support and a new subtests fixture as discussed in\nissue #1367.','add new subtests fixture',0,'',''),(12148,'pytest','issue #4920: Internal refactorings have been made in order to make the implementation of the\npytest-subtests plugin\npossible, which adds unittest sub-test support and a new subtests fixture as discussed in\nissue #1367.','add pytest-subtests plugin possible',0,'',''),(12149,'pytest','This can be used to override a blocked plugin (e.g. in “addopts”) from the\ncommand line etc.','override blocked plugin from command line etc.',0,'',''),(12150,'pytest','issue #4951: Output capturing is handled correctly when only capturing via fixtures (capsys, capfs) with pdb.set_trace().','handle output capturing',0,'',''),(12151,'pytest','issue #4956: pytester sets $HOME and $USERPROFILE to the temporary directory during test runs.','set  to temporary directory',0,'',''),(12152,'pytest','issue #4956: pytester sets $HOME and $USERPROFILE to the temporary directory during test runs.','set  to temporary directory',0,'',''),(12153,'pytest','issue #4980: Namespace packages are handled better with monkeypatch.syspath_prepend and testdir.syspathinsert (via pkg_resources.fixup_namespace_packages).','handle namespace packages with monkeypatch.syspath_prepend',0,'',''),(12154,'pytest','issue #4980: Namespace packages are handled better with monkeypatch.syspath_prepend and testdir.syspathinsert (via pkg_resources.fixup_namespace_packages).','handle namespace packages with testdir.syspathinsert',0,'',''),(12155,'pytest','issue #5008: If a setup.cfg file contains [tool:pytest] and also the no longer supported [pytest] section, pytest will use [tool:pytest] ignoring [pytest]. Previously it would unconditionally error out.','support pytest  section',0,'',''),(12156,'pytest','issue #5008: If a setup.cfg file contains [tool:pytest] and also the no longer supported [pytest] section, pytest will use [tool:pytest] ignoring [pytest]. Previously it would unconditionally error out.','use  tool:pytest',0,'',''),(12157,'pytest','issue #5008: If a setup.cfg file contains [tool:pytest] and also the no longer supported [pytest] section, pytest will use [tool:pytest] ignoring [pytest]. Previously it would unconditionally error out.','ignore  pytest',0,'',''),(12158,'pytest','This makes it simpler for plugins to support old pytest versions.','support old pytest versions',0,'',''),(12159,'pytest','issue #1895: Fix bug where fixtures requested dynamically via request.getfixturevalue() might be teardown\nbefore the requesting fixture.','request fix bug',0,'',''),(12160,'pytest','issue #4903: Use the correct modified time for years after 2038 in rewritten .pyc files.','use correct modified time in rewritten',0,'',''),(12161,'pytest','issue #4903: Use the correct modified time for years after 2038 in rewritten .pyc files.','use correct modified time for years',0,'',''),(12162,'pytest','issue #4957: -p no:plugin is handled correctly for default (internal) plugins now, e.g. with -p no:capture.','handle plugin for default plugins',0,'',''),(12163,'pytest','issue #4968: The pdb quit command is handled properly when used after the debug command with pdbpp.','use  after debug command',0,'',''),(12164,'pytest','issue #4968: The pdb quit command is handled properly when used after the debug command with pdbpp.','handle command',0,'',''),(12165,'pytest','issue #4975: Fix the interpretation of -qq option where it was being considered as -v instead.','fix interpretation of qq option',0,'',''),(12166,'pytest','issue #4829: Some left-over internal code related to yield tests has been removed.','remove tests',0,'',''),(12167,'pytest','issue #4890: Remove internally unused anypython fixture from the pytester plugin.','remove unused anypython fixture from pytester plugin',0,'',''),(12168,'pytest','issue #4912: Remove deprecated Sphinx directive, add_description_unit(),\npin sphinx-removed-in to >= 0.2.0 to support Sphinx 2.0.','remove deprecated Sphinx directive sphinx-removed-in',0,'',''),(12169,'pytest','issue #4912: Remove deprecated Sphinx directive, add_description_unit(),\npin sphinx-removed-in to >= 0.2.0 to support Sphinx 2.0.','support Sphinx 2.0',0,'',''),(12170,'pytest','These hooks will be used by pytest-xdist, pytest-subtests, and the replacement for\nresultlog to serialize and customize reports.','use hooks for resultlog',0,'',''),(12171,'pytest','They are experimental, meaning that their details might change or even be removed\ncompletely in future patch releases without warning.','remove details in future patch releases',0,'',''),(12172,'pytest','They are experimental, meaning that their details might change or even be removed\ncompletely in future patch releases without warning.','remove details without warning',0,'',''),(12173,'pytest','issue #4810: Logging messages inside pytest_runtest_logreport() are now properly captured and displayed.','display issue',0,'',''),(12174,'pytest','issue #4861: Improve validation of contents written to captured output so it behaves the same as when capture is disabled.','write  to captured output',0,'',''),(12175,'pytest','issue #4861: Improve validation of contents written to captured output so it behaves the same as when capture is disabled.','disable capture',0,'',''),(12176,'pytest','issue #4724: pytest.warns() now emits a warning when it receives unknown keyword arguments.','receive unknown keyword arguments',0,'',''),(12177,'pytest','This will be changed into an error in the future.','change  into error',0,'',''),(12178,'pytest','issue #3711: Add the --ignore-glob parameter to exclude test-modules with Unix shell-style wildcards.\nAdd the collect_ignore_glob for conftest.py to exclude test-modules with Unix shell-style wildcards.','add ignore-glob parameter',0,'',''),(12179,'pytest','issue #3711: Add the --ignore-glob parameter to exclude test-modules with Unix shell-style wildcards.\nAdd the collect_ignore_glob for conftest.py to exclude test-modules with Unix shell-style wildcards.','exclude test-modules with Unix shell-style wildcards',0,'',''),(12180,'pytest','issue #3711: Add the --ignore-glob parameter to exclude test-modules with Unix shell-style wildcards.\nAdd the collect_ignore_glob for conftest.py to exclude test-modules with Unix shell-style wildcards.','add collect_ignore_glob for conftest.py',0,'',''),(12181,'pytest','issue #3711: Add the --ignore-glob parameter to exclude test-modules with Unix shell-style wildcards.\nAdd the collect_ignore_glob for conftest.py to exclude test-modules with Unix shell-style wildcards.','exclude test-modules with Unix shell-style wildcards',0,'',''),(12182,'pytest','issue #4698: The warning about Python 2.7 and 3.4 not being supported in pytest 5.0 has been removed.','remove issue',0,'',''),(12183,'pytest','issue #4707: With the help of new set_log_path() method there is a way to set log_file paths from hooks.','set log_file paths from hooks',0,'',''),(12184,'pytest','issue #4651: --help and --version are handled with UsageError.','handle version with UsageError',0,'',''),(12185,'pytest','issue #2895: The pytest_report_collectionfinish hook now is also called with --collect-only.','call collect-only',0,'',''),(12186,'pytest','issue #2895: The pytest_report_collectionfinish hook now is also called with --collect-only.','call pytest_report_collectionfinish hook',0,'',''),(12187,'pytest','issue #4347: Fix output capturing when using pdb++ with recursive debugging.','use pdb + + with recursive debugging',0,'',''),(12188,'pytest','issue #4700: Fix regression where setUpClass would always be called in subclasses even if all tests\nwere skipped by a unittest.skip() decorator applied in the subclass.','call setUpClass in subclasses',0,'',''),(12189,'pytest','issue #4700: Fix regression where setUpClass would always be called in subclasses even if all tests\nwere skipped by a unittest.skip() decorator applied in the subclass.','call fix regression in subclasses',0,'',''),(12190,'pytest','issue #4700: Fix regression where setUpClass would always be called in subclasses even if all tests\nwere skipped by a unittest.skip() decorator applied in the subclass.','apply  in subclass',0,'',''),(12191,'pytest','issue #4700: Fix regression where setUpClass would always be called in subclasses even if all tests\nwere skipped by a unittest.skip() decorator applied in the subclass.','skip tests',0,'',''),(12192,'pytest','issue #4739: Fix parametrize(... ids=) when the function returns non-strings.','return non-strings',0,'',''),(12193,'pytest','issue #4745: Fix/improve collection of args when passing in __init__.py and a test file.','pass  in test file',0,'',''),(12194,'pytest','issue #4745: Fix/improve collection of args when passing in __init__.py and a test file.','pass  in __init__.py',0,'',''),(12195,'pytest','issue #3899: Add note to plugins.rst that pytest_plugins should not be used as a name for a user module containing plugins.','add note to plugins.rst',0,'',''),(12196,'pytest','issue #4324: Document how to use raises and does_not_raise to write parametrized tests with conditional raises.','use raises',0,'',''),(12197,'pytest','issue #4324: Document how to use raises and does_not_raise to write parametrized tests with conditional raises.','use does_not_raise',0,'',''),(12198,'pytest','issue #4324: Document how to use raises and does_not_raise to write parametrized tests with conditional raises.','write parametrized tests with conditional raises',0,'',''),(12199,'pytest','issue #4709: Document how to customize test failure messages when using\npytest.warns.','customize test failure messages',0,'',''),(12200,'pytest','issue #4709: Document how to customize test failure messages when using\npytest.warns.','use pytest.warns',0,'',''),(12201,'pytest','issue #4741: Some verbosity related attributes of the TerminalReporter plugin are now\nread only properties.','read only properties',0,'',''),(12202,'pytest','This fixes a number of surprising issues like setup_method being called before session-scoped\nautouse fixtures (see issue #517 for an example).','fix number like setup_method',0,'',''),(12203,'pytest','This fixes a number of surprising issues like setup_method being called before session-scoped\nautouse fixtures (see issue #517 for an example).','fix number of surprising issues',0,'',''),(12204,'pytest','This fixes a number of surprising issues like setup_method being called before session-scoped\nautouse fixtures (see issue #517 for an example).','call  before session-scoped autouse fixtures',0,'',''),(12205,'pytest','issue #4627: Display a message at the end of the test session when running under Python 2.7 and 3.4 that pytest 5.0 will no longer\nsupport those Python versions.','display message at end',0,'',''),(12206,'pytest','issue #4627: Display a message at the end of the test session when running under Python 2.7 and 3.4 that pytest 5.0 will no longer\nsupport those Python versions.','support Python versions',0,'',''),(12207,'pytest','issue #4627: Display a message at the end of the test session when running under Python 2.7 and 3.4 that pytest 5.0 will no longer\nsupport those Python versions.','run  under Python',0,'',''),(12208,'pytest','issue #4660: The number of selected tests now are also displayed when the -k or -m flags are used.','display issue',0,'',''),(12209,'pytest','issue #4660: The number of selected tests now are also displayed when the -k or -m flags are used.','use k',0,'',''),(12210,'pytest','issue #4660: The number of selected tests now are also displayed when the -k or -m flags are used.','use m flags',0,'',''),(12211,'pytest','issue #4688: pytest_report_teststatus hook now can also receive a config parameter.','receive config parameter',0,'',''),(12212,'pytest','issue #4691: pytest_terminal_summary hook now can also receive a config parameter.','receive config parameter',0,'',''),(12213,'pytest','issue #3547: --junitxml can emit XML compatible with Jenkins xUnit.\njunit_family INI option accepts legacy|xunit1, which produces old style output, and xunit2 that conforms more strictly to https://github.com/jenkinsci/xunit-plugin/blob/xunit-2.3.2/src/main/resources/org/jenkinsci/plugins/xunit/types/model/xsd/junit-10.xsd','produce old style output',0,'',''),(12214,'pytest','issue #3547: --junitxml can emit XML compatible with Jenkins xUnit.\njunit_family INI option accepts legacy|xunit1, which produces old style output, and xunit2 that conforms more strictly to https://github.com/jenkinsci/xunit-plugin/blob/xunit-2.3.2/src/main/resources/org/jenkinsci/plugins/xunit/types/model/xsd/junit-10.xsd','produce legacy | xunit1',0,'',''),(12215,'pytest','issue #3547: --junitxml can emit XML compatible with Jenkins xUnit.\njunit_family INI option accepts legacy|xunit1, which produces old style output, and xunit2 that conforms more strictly to https://github.com/jenkinsci/xunit-plugin/blob/xunit-2.3.2/src/main/resources/org/jenkinsci/plugins/xunit/types/model/xsd/junit-10.xsd','produce xunit2',0,'',''),(12216,'pytest','Using q[quit] after pdb.set_trace() will quit pytest also.','use q',0,'',''),(12217,'pytest','This makes the output more compact and better conveys the general idea of how much code is\nactually generating warnings, instead of how many tests call that code.','call code',0,'',''),(12218,'pytest','issue #4536: monkeypatch.delattr handles class descriptors like staticmethod/classmethod.','handle class descriptors like staticmethod',0,'',''),(12219,'pytest','issue #4536: monkeypatch.delattr handles class descriptors like staticmethod/classmethod.','handle issue like staticmethod',0,'',''),(12220,'pytest','issue #4653: tmp_path fixture and other related ones provides resolved path (a.k.a real path)','resolve path',0,'',''),(12221,'pytest','issue #4669: Correctly handle unittest.SkipTest exception containing non-ascii characters on Python 2.','handle unittest.SkipTest exception',0,'',''),(12222,'pytest','issue #3456: Extend Doctest-modules to ignore mock objects.','ignore mock objects',0,'',''),(12223,'pytest','issue #4617: Fixed pytest.warns bug when context manager is reused (e.g. multiple parametrization).','reuse context manager',0,'',''),(12224,'pytest','issue #4631: Don’t rewrite assertion when __getattr__ is broken','break __getattr__',0,'',''),(12225,'pytest','issue #3375: Document that using setup.cfg may crash other tools or cause hard to track down problems because it uses a different parser than pytest.ini or tox.ini files.','use setup.cfg',0,'',''),(12226,'pytest','issue #3375: Document that using setup.cfg may crash other tools or cause hard to track down problems because it uses a different parser than pytest.ini or tox.ini files.','use different parser than pytest.ini tox.ini files',0,'',''),(12227,'pytest','See our docs on information on how to update your code.','update code',0,'',''),(12228,'pytest','issue #3079: Removed support for yield tests - they are fundamentally broken because they don’t support fixtures properly since collection and test execution were separated.','support fixtures',0,'',''),(12229,'pytest','issue #3082: Removed support for applying marks directly to values in @pytest.mark.parametrize. Use pytest.param instead.','apply marks to values',0,'',''),(12230,'pytest','issue #3082: Removed support for applying marks directly to values in @pytest.mark.parametrize. Use pytest.param instead.','use pytest.param',0,'',''),(12231,'pytest','issue #3083: Removed Metafunc.addcall. This was the predecessor mechanism to @pytest.mark.parametrize.','remove Metafunc.addcall',0,'',''),(12232,'pytest','issue #3085: Removed support for passing strings to pytest.main. Now, always pass a list of strings instead.','pass strings to pytest.main',0,'',''),(12233,'pytest','issue #3085: Removed support for passing strings to pytest.main. Now, always pass a list of strings instead.','pass list of strings',0,'',''),(12234,'pytest','issue #3086: [pytest] section in setup.cfg files is no longer supported, use [tool:pytest] instead. setup.cfg files\nare meant for use with distutils, and a section named pytest has notoriously been a source of conflicts and bugs.','use  tool:pytest',0,'',''),(12235,'pytest','issue #3086: [pytest] section in setup.cfg files is no longer supported, use [tool:pytest] instead. setup.cfg files\nare meant for use with distutils, and a section named pytest has notoriously been a source of conflicts and bugs.','support issue',0,'',''),(12236,'pytest','issue #3616: Removed the deprecated compat properties for node.Class/Function/Module - use pytest.Class/Function/Module now.','remove deprecated compat properties for node.Class/Function/Module',0,'',''),(12237,'pytest','issue #3616: Removed the deprecated compat properties for node.Class/Function/Module - use pytest.Class/Function/Module now.','use pytest.Class/Function/Module',0,'',''),(12238,'pytest','issue #4421: Removed the implementation of the pytest_namespace hook.','remove implementation of pytest_namespace hook',0,'',''),(12239,'pytest','issue #4489: Removed request.cached_setup. This was the predecessor mechanism to modern fixtures.','remove request.cached_setup',0,'',''),(12240,'pytest','issue #4535: Removed the deprecated PyCollector.makeitem method. This method was made public by mistake a long time ago.','remove deprecated PyCollector.makeitem method',0,'',''),(12241,'pytest','issue #4543: Removed support to define fixtures using the pytest_funcarg__ prefix. Use the @pytest.fixture decorator instead.','define fixtures',0,'',''),(12242,'pytest','issue #4543: Removed support to define fixtures using the pytest_funcarg__ prefix. Use the @pytest.fixture decorator instead.','use pytest_funcarg__ prefix',0,'',''),(12243,'pytest','issue #4543: Removed support to define fixtures using the pytest_funcarg__ prefix. Use the @pytest.fixture decorator instead.','use  decorator',0,'',''),(12244,'pytest','Use Node.get_closest_marker(name) as a replacement.','use Node.get_closest_marker(name) as replacement',0,'',''),(12245,'pytest','issue #4547: The deprecated record_xml_property fixture has been removed, use the more generic record_property instead.','use generic record_property',0,'',''),(12246,'pytest','issue #4547: The deprecated record_xml_property fixture has been removed, use the more generic record_property instead.','remove issue',0,'',''),(12247,'pytest','issue #4548: An error is now raised if the pytest_plugins variable is defined in a non-top-level conftest.py file (i.e., not residing in the rootdir).','define pytest_plugins variable in non-top-level conftest.py file',0,'',''),(12248,'pytest','issue #4548: An error is now raised if the pytest_plugins variable is defined in a non-top-level conftest.py file (i.e., not residing in the rootdir).','raise error',0,'',''),(12249,'pytest','issue #891: Remove testfunction.markername attributes - use Node.iter_markers(name=None) to iterate them.','use Node.iter_markers(name=None)',0,'',''),(12250,'pytest','It is a common mistake to think this parameter will match the exception message, while in fact\nit only serves to provide a custom message in case the pytest.raises check fails. To avoid this\nmistake and because it is believed to be little used, pytest is deprecating it without providing\nan alternative for the moment.','match exception message',0,'',''),(12251,'pytest','It is a common mistake to think this parameter will match the exception message, while in fact\nit only serves to provide a custom message in case the pytest.raises check fails. To avoid this\nmistake and because it is believed to be little used, pytest is deprecating it without providing\nan alternative for the moment.','provide custom message in case',0,'',''),(12252,'pytest','It is a common mistake to think this parameter will match the exception message, while in fact\nit only serves to provide a custom message in case the pytest.raises check fails. To avoid this\nmistake and because it is believed to be little used, pytest is deprecating it without providing\nan alternative for the moment.','provide alternative for moment',0,'',''),(12253,'pytest','See raises / warns with a string as the second argument for rationale and examples.','raise see',0,'',''),(12254,'pytest','This is a common source of confusion among new users, which write:','write new users',1,'https://docs.pytest.org/en/7.2.x/changelog.html',''),(12255,'pytest','Because the assert_called_with method of mock objects already executes an assertion.','execute assertion because assert_called_with',0,'',''),(12256,'pytest','This warning will not be issued when None is explicitly checked. An assertion like:','check none',1,'https://docs.pytest.org/en/7.2.x/changelog.html',''),(12257,'pytest','issue #3632: Richer equality comparison introspection on AssertionError for objects created using attrs or dataclasses (Python 3.7+, backported to 3.6).','use dataclasses',0,'',''),(12258,'pytest','issue #3632: Richer equality comparison introspection on AssertionError for objects created using attrs or dataclasses (Python 3.7+, backported to 3.6).','use attrs',0,'',''),(12259,'pytest','issue #4278: CACHEDIR.TAG files are now created inside cache directories.','create CACHEDIR.TAG files inside cache directories',0,'',''),(12260,'pytest','Those files are part of the Cache Directory Tagging Standard, and can\nbe used by backup or synchronization programs to identify pytest’s cache directory as such.','identify cache directory',0,'',''),(12261,'pytest','Those files are part of the Cache Directory Tagging Standard, and can\nbe used by backup or synchronization programs to identify pytest’s cache directory as such.','use files',0,'',''),(12262,'pytest','issue #4292: pytest.outcomes.Exit is derived from SystemExit instead of KeyboardInterrupt. This allows us to better handle pdb exiting.','handle pdb exiting',0,'',''),(12263,'pytest','issue #4371: Updated the --collect-only option to display test descriptions when ran using --verbose.','update collect-only option',0,'',''),(12264,'pytest','issue #4371: Updated the --collect-only option to display test descriptions when ran using --verbose.','display test descriptions',0,'',''),(12265,'pytest','issue #4416: pdb: added support for keyword arguments with pdb.set_trace.','add support with pdb.set_trace',0,'',''),(12266,'pytest','issue #4416: pdb: added support for keyword arguments with pdb.set_trace.','add support for keyword arguments',0,'',''),(12267,'pytest','issue #4483: Added ini parameter junit_duration_report to optionally report test call durations, excluding setup and teardown times.','add ini parameter junit_duration_report excluding setup teardown times',0,'',''),(12268,'pytest','issue #4483: Added ini parameter junit_duration_report to optionally report test call durations, excluding setup and teardown times.','add ini parameter junit_duration_report to optionally report test call durations',0,'',''),(12269,'pytest','The JUnit XML specification and the default pytest behavior is to include setup and teardown times in the test duration\nreport. You can include just the call durations instead (excluding setup and teardown) by adding this to your pytest.ini file:','include setup teardown times in test duration report',1,'https://docs.pytest.org/en/7.2.x/changelog.html',''),(12270,'pytest','The JUnit XML specification and the default pytest behavior is to include setup and teardown times in the test duration\nreport. You can include just the call durations instead (excluding setup and teardown) by adding this to your pytest.ini file:','include call durations by adding',1,'https://docs.pytest.org/en/7.2.x/changelog.html',''),(12271,'pytest','The JUnit XML specification and the default pytest behavior is to include setup and teardown times in the test duration\nreport. You can include just the call durations instead (excluding setup and teardown) by adding this to your pytest.ini file:','add  to pytest.ini file',1,'https://docs.pytest.org/en/7.2.x/changelog.html',''),(12272,'pytest','issue #4532: -ra now will show errors and failures last, instead of as the first items in the summary.','show errors as_of first items',0,'',''),(12273,'pytest','issue #4532: -ra now will show errors and failures last, instead of as the first items in the summary.','show failures as_of first items',0,'',''),(12274,'pytest','This makes it easier to obtain a list of errors and failures to run tests selectively.','obtain list of errors',0,'',''),(12275,'pytest','This makes it easier to obtain a list of errors and failures to run tests selectively.','obtain list of failures',0,'',''),(12276,'pytest','This makes it easier to obtain a list of errors and failures to run tests selectively.','run tests',0,'',''),(12277,'pytest','issue #4599: pytest.importorskip now supports a reason parameter, which will be shown when the\nrequested module cannot be imported.','support reason parameter',0,'',''),(12278,'pytest','issue #4599: pytest.importorskip now supports a reason parameter, which will be shown when the\nrequested module cannot be imported.','show reason parameter',0,'',''),(12279,'pytest','issue #4557: Markers example documentation page updated to support latest pytest version.','support pytest version',0,'',''),(12280,'pytest','issue #4558: Update cache documentation example to correctly show cache hit and miss.','show cache hit',0,'',''),(12281,'pytest','issue #4447: Changed the deprecation type of --result-log to PytestDeprecationWarning.','change deprecation type of result-log',0,'',''),(12282,'pytest','It was decided to remove this feature at the next major revision.','remove feature at next major revision',0,'',''),(12283,'pytest','issue #4435: Fix raises(..., \'code(string)\') frame filename.','fix raises(...,          \'code(string)\') frame filename',0,'',''),(12284,'pytest','issue #4400: Rearrange warning handling for the yield test errors so the opt-out in 4.0.x correctly works.','handle  for yield test errors',0,'',''),(12285,'pytest','issue #4425: Ensure we resolve the absolute path when the given --basetemp is a relative path.','resolve absolute path',0,'',''),(12286,'pytest','issue #4440: Adjust the stack level of some internal pytest warnings.','adjust stack level of internal pytest warnings',0,'',''),(12287,'pytest','Following our plan to remove deprecated features with as little disruption as\npossible, all warnings of type RemovedInPytest4Warnings now generate errors\ninstead of warning messages.','remove deprecated features as little disruption possible',0,'',''),(12288,'pytest','Following our plan to remove deprecated features with as little disruption as\npossible, all warnings of type RemovedInPytest4Warnings now generate errors\ninstead of warning messages.','generate errors instead_of warning messages',0,'',''),(12289,'pytest','Following our plan to remove deprecated features with as little disruption as\npossible, all warnings of type RemovedInPytest4Warnings now generate errors\ninstead of warning messages.','generate errors following plan',0,'',''),(12290,'pytest','The affected features will be effectively removed in pytest 4.1, so please consult the\nDeprecations and Removals section in the docs for directions on how to update existing code.','update existing code',0,'',''),(12291,'pytest','The affected features will be effectively removed in pytest 4.1, so please consult the\nDeprecations and Removals section in the docs for directions on how to update existing code.','remove affected features',0,'',''),(12292,'pytest','In the pytest 4.0.X series, it is possible to change the errors back into warnings as a stop\ngap measure by adding this to your pytest.ini file:','add  to pytest.ini file',1,'https://docs.pytest.org/en/7.2.x/changelog.html',''),(12293,'pytest','But this will stop working when pytest 4.1 is released.','release pytest',0,'',''),(12294,'pytest','If you have concerns about the removal of a specific feature, please add a\ncomment to issue #4348.','add comment',0,'',''),(12295,'pytest','issue #4270: The cache_dir option uses $TOX_ENV_DIR as prefix (if set in the environment).','use $TOX_ENV_DIR as prefix',0,'',''),(12296,'pytest','This uses a different cache per tox environment by default.','use different cache by default',0,'',''),(12297,'pytest','This uses a different cache per tox environment by default.','use different cache per tox environment',0,'',''),(12298,'pytest','issue #4310: Fix duplicate collection due to multiple args matching the same packages.','match same packages due_to multiple args',0,'',''),(12299,'pytest','This also adds a new pytest_leave_pdb hook, and passes in pdb to the\nexisting pytest_enter_pdb hook.','add new pytest_leave_pdb hook',0,'',''),(12300,'pytest','This also adds a new pytest_leave_pdb hook, and passes in pdb to the\nexisting pytest_enter_pdb hook.','pass  in pdb',0,'',''),(12301,'pytest','This also adds a new pytest_leave_pdb hook, and passes in pdb to the\nexisting pytest_enter_pdb hook.','pass  to existing pytest_enter_pdb hook',0,'',''),(12302,'pytest','issue #4188: Make --color emit colorful dots when not running in verbose mode. Earlier, it would only colorize the test-by-test output if --verbose was also passed.','pass verbose',0,'',''),(12303,'pytest','issue #4046: Fix problems with running tests in package __init__.py files.','run tests in package __init__.py files',0,'',''),(12304,'pytest','issue #4262: Fix access denied error when deleting stale directories created by tmpdir / tmp_path.','delete stale directories',0,'',''),(12305,'pytest','issue #4262: Fix access denied error when deleting stale directories created by tmpdir / tmp_path.','create  by tmpdir / tmp_path',0,'',''),(12306,'pytest','issue #611: Naming a fixture request will now raise a warning: the request fixture is internal and\nshould not be overwritten as it will lead to internal errors.','raise warning',0,'',''),(12307,'pytest','issue #4266: Handle (ignore) exceptions raised during collection, e.g. with Django’s LazySettings proxy class.','raise  during collection',0,'',''),(12308,'pytest','issue #4255: Added missing documentation about the fact that module names passed to filter warnings are not regex-escaped.','add missing documentation about fact',0,'',''),(12309,'pytest','issue #4255: Added missing documentation about the fact that module names passed to filter warnings are not regex-escaped.','pass  to filter warnings',0,'',''),(12310,'pytest','issue #4243: Fix regression when stacklevel for warnings was passed as positional argument on python2.','pass stacklevel as positional argument',0,'',''),(12311,'pytest','issue #4243: Fix regression when stacklevel for warnings was passed as positional argument on python2.','pass stacklevel for warnings',0,'',''),(12312,'pytest','issue #4028: Revert patching of sys.breakpointhook since it appears to do nothing.','patch  of sys.breakpointhook',0,'',''),(12313,'pytest','issue #3691: Python 2: safely format warning message about passing unicode strings to warnings.warn, which may cause\nsurprising MemoryError exception when monkey patching warnings.warn itself.','pass unicode strings to warnings.warn',0,'',''),(12314,'pytest','issue #4026: Improve error message when it is not possible to determine a function’s signature.','determine signature',0,'',''),(12315,'pytest','issue #4177: Pin setuptools>=40.0 to support py_modules in setup.cfg','support py_modules in setup.cfg',0,'',''),(12316,'pytest','issue #4192: Fix filename reported by warnings.warn when using recwarn under python2.','use recwarn',0,'',''),(12317,'pytest','issue #4159: For test-suites containing test classes, the information about the subclassed\nmodule is now output only if a higher verbosity level is specified (at least\n“-vv”).','specify higher verbosity level',0,'',''),(12318,'pytest','issue #3616: The following accesses have been documented as deprecated for years, but are now actually emitting deprecation warnings.','document following accesses for years',0,'',''),(12319,'pytest','Users should just import pytest and access those objects using the pytest module.','import pytest',0,'',''),(12320,'pytest','Users should just import pytest and access those objects using the pytest module.','access pytest',0,'',''),(12321,'pytest','Users should just import pytest and access those objects using the pytest module.','use pytest module',0,'',''),(12322,'pytest','Using objects named \"Class\" as a way to customize the type of nodes that are collected in Collector\nsubclasses has been deprecated. Users instead should use pytest_collect_make_item to customize node types during\ncollection.','use objects',0,'',''),(12323,'pytest','Using objects named \"Class\" as a way to customize the type of nodes that are collected in Collector\nsubclasses has been deprecated. Users instead should use pytest_collect_make_item to customize node types during\ncollection.','customize type of nodes',0,'',''),(12324,'pytest','Using objects named \"Class\" as a way to customize the type of nodes that are collected in Collector\nsubclasses has been deprecated. Users instead should use pytest_collect_make_item to customize node types during\ncollection.','use pytest_collect_make_item',0,'',''),(12325,'pytest','Using objects named \"Class\" as a way to customize the type of nodes that are collected in Collector\nsubclasses has been deprecated. Users instead should use pytest_collect_make_item to customize node types during\ncollection.','customize node types during collection',0,'',''),(12326,'pytest','This issue should affect only advanced plugins who create new collection types, so if you see this warning\nmessage please contact the authors so they can change the code.','create new collection types',0,'',''),(12327,'pytest','This issue should affect only advanced plugins who create new collection types, so if you see this warning\nmessage please contact the authors so they can change the code.','create advanced plugins',0,'',''),(12328,'pytest','This issue should affect only advanced plugins who create new collection types, so if you see this warning\nmessage please contact the authors so they can change the code.','change code',0,'',''),(12329,'pytest','The warning that produces the message below has changed to RemovedInPytest4Warning:','change  to RemovedInPytest4Warning',1,'https://docs.pytest.org/en/7.2.x/changelog.html',''),(12330,'pytest','The warning that produces the message below has changed to RemovedInPytest4Warning:','produce warning',1,'https://docs.pytest.org/en/7.2.x/changelog.html',''),(12331,'pytest','issue #3988: Add a Deprecation warning for pytest.ensuretemp as it was deprecated since a while.','add Deprecation warning for pytest.ensuretemp',0,'',''),(12332,'pytest','issue #2293: Improve usage errors messages by hiding internal details which can be distracting and noisy.','hide internal details',0,'',''),(12333,'pytest','This has the side effect that some error conditions that previously raised generic errors (such as\nValueError for unregistered marks) are now raising Failed exceptions.','raise generic errors',0,'',''),(12334,'pytest','This has the side effect that some error conditions that previously raised generic errors (such as\nValueError for unregistered marks) are now raising Failed exceptions.','raise error conditions',0,'',''),(12335,'pytest','This has the side effect that some error conditions that previously raised generic errors (such as\nValueError for unregistered marks) are now raising Failed exceptions.','raise failed exceptions',0,'',''),(12336,'pytest','issue #3332: Improve the error displayed when a conftest.py file could not be imported.','display improve',0,'',''),(12337,'pytest','In order to implement this, a new chain parameter was added to ExceptionInfo.getrepr\nto show or hide chained tracebacks in Python 3 (defaults to True).','show chained tracebacks in Python',0,'',''),(12338,'pytest','In order to implement this, a new chain parameter was added to ExceptionInfo.getrepr\nto show or hide chained tracebacks in Python 3 (defaults to True).','hide chained tracebacks in Python',0,'',''),(12339,'pytest','In order to implement this, a new chain parameter was added to ExceptionInfo.getrepr\nto show or hide chained tracebacks in Python 3 (defaults to True).','add new chain parameter to ExceptionInfo.getrepr',0,'',''),(12340,'pytest','issue #3849: Add empty_parameter_set_mark=fail_at_collect ini option for raising an exception when parametrize collects an empty set.','raise exception',0,'',''),(12341,'pytest','issue #3849: Add empty_parameter_set_mark=fail_at_collect ini option for raising an exception when parametrize collects an empty set.','add  for raising',0,'',''),(12342,'pytest','issue #3964: Log messages generated in the collection phase are shown when\nlive-logging is enabled and/or when they are logged to a file.','enable and/or',0,'',''),(12343,'pytest','issue #3964: Log messages generated in the collection phase are shown when\nlive-logging is enabled and/or when they are logged to a file.','enable live-logging',0,'',''),(12344,'pytest','issue #3964: Log messages generated in the collection phase are shown when\nlive-logging is enabled and/or when they are logged to a file.','generate  in collection phase',0,'',''),(12345,'pytest','issue #3964: Log messages generated in the collection phase are shown when\nlive-logging is enabled and/or when they are logged to a file.','log  to file',0,'',''),(12346,'pytest','issue #3985: Introduce tmp_path as a fixture providing a Path object. Also introduce tmp_path_factory as\na session-scoped fixture for creating arbitrary temporary directories from any other fixture or test.','provide Path object',0,'',''),(12347,'pytest','issue #3985: Introduce tmp_path as a fixture providing a Path object. Also introduce tmp_path_factory as\na session-scoped fixture for creating arbitrary temporary directories from any other fixture or test.','introduce tmp_path_factory as session-scoped fixture',0,'',''),(12348,'pytest','issue #3985: Introduce tmp_path as a fixture providing a Path object. Also introduce tmp_path_factory as\na session-scoped fixture for creating arbitrary temporary directories from any other fixture or test.','create temporary directories from other fixture',0,'',''),(12349,'pytest','issue #3985: Introduce tmp_path as a fixture providing a Path object. Also introduce tmp_path_factory as\na session-scoped fixture for creating arbitrary temporary directories from any other fixture or test.','create temporary directories from test',0,'',''),(12350,'pytest','issue #4013: Deprecation warnings are now shown even if you customize the warnings filters yourself. In the previous version\nany customization would override pytest’s filters and deprecation warnings would fall back to being hidden by default.','show deprecation warnings',0,'',''),(12351,'pytest','issue #4013: Deprecation warnings are now shown even if you customize the warnings filters yourself. In the previous version\nany customization would override pytest’s filters and deprecation warnings would fall back to being hidden by default.','override filters in previous version',0,'',''),(12352,'pytest','issue #4098: Add returncode argument to pytest.exit() to exit pytest with a specific return code.','add returncode argument to pytest.exit()',0,'',''),(12353,'pytest','issue #4102: Reimplement pytest.deprecated_call using pytest.warns so it supports the match=\'...\' keyword argument.','use pytest.warns',0,'',''),(12354,'pytest','issue #4102: Reimplement pytest.deprecated_call using pytest.warns so it supports the match=\'...\' keyword argument.','support match =',0,'',''),(12355,'pytest','This has the side effect that pytest.deprecated_call now raises pytest.fail.Exception instead\nof AssertionError.','raise pytest.fail.Exception instead_of AssertionError',0,'',''),(12356,'pytest','issue #4149: Require setuptools>=30.3 and move most of the metadata to setup.cfg.','move  to setup.cfg',0,'',''),(12357,'pytest','issue #2535: Improve error message when test functions of unittest.TestCase subclasses use a parametrized fixture.','use parametrized fixture',0,'',''),(12358,'pytest','issue #3057: request.fixturenames now correctly returns the name of fixtures created by request.getfixturevalue().','return name of fixtures',0,'',''),(12359,'pytest','issue #3946: Warning filters passed as command line options using -W now take precedence over filters defined in ini\nconfiguration files.','pass  as command line options',0,'',''),(12360,'pytest','issue #3946: Warning filters passed as command line options using -W now take precedence over filters defined in ini\nconfiguration files.','define  in ini configuration files',0,'',''),(12361,'pytest','issue #4066: Fix source reindenting by using textwrap.dedent directly.','use textwrap.dedent',0,'',''),(12362,'pytest','This fixes running pytest tests/test_foo.py::test_bar, where tests\nis a symlink to project/app/tests:\npreviously project/app/conftest.py would be ignored for fixtures then.','run pytest tests/test_foo.py',0,'',''),(12363,'pytest','This fixes running pytest tests/test_foo.py::test_bar, where tests\nis a symlink to project/app/tests:\npreviously project/app/conftest.py would be ignored for fixtures then.','ignore test_bar for fixtures',0,'',''),(12364,'pytest','issue #4132: Fix duplicate printing of internal errors when using --pdb.','fix duplicate printing of internal errors',0,'',''),(12365,'pytest','issue #4135: pathlib based tmpdir cleanup now correctly handles symlinks in the folder.','handle symlinks in folder',0,'',''),(12366,'pytest','issue #3713: Update usefixtures documentation to clarify that it can’t be used with fixture functions.','use  with fixture functions',0,'',''),(12367,'pytest','issue #4058: Update fixture documentation to specify that a fixture can be invoked twice in the scope it’s defined for.','define scope',0,'',''),(12368,'pytest','issue #4064: According to unittest.rst, setUpModule and tearDownModule were not implemented, but it turns out they are. So updated the documentation for unittest.','update documentation for unittest',0,'',''),(12369,'pytest','issue #2293: The internal MarkerError exception has been removed.','remove internal MarkerError exception',0,'',''),(12370,'pytest','issue #4063: Exclude 0.00 second entries from --duration output unless -vv is passed on the command-line.','pass second entries from vv',0,'',''),(12371,'pytest','issue #4063: Exclude 0.00 second entries from --duration output unless -vv is passed on the command-line.','pass second entries on command-line',0,'',''),(12372,'pytest','issue #4063: Exclude 0.00 second entries from --duration output unless -vv is passed on the command-line.','pass exclude from vv',0,'',''),(12373,'pytest','issue #4063: Exclude 0.00 second entries from --duration output unless -vv is passed on the command-line.','pass exclude on command-line',0,'',''),(12374,'pytest','issue #4036: The item parameter of pytest_warning_captured hook is now documented as deprecated. We realized only after\nthe 3.8 release that this parameter is incompatible with pytest-xdist.','document issue as deprecated',0,'',''),(12375,'pytest','Our policy is to not deprecate features during bug-fix releases, but in this case we believe it makes sense as we are\nonly documenting it as deprecated, without issuing warnings which might potentially break test suites. This will get\nthe word out that hook implementers should not use this parameter at all.','break test suites',0,'',''),(12376,'pytest','Our policy is to not deprecate features during bug-fix releases, but in this case we believe it makes sense as we are\nonly documenting it as deprecated, without issuing warnings which might potentially break test suites. This will get\nthe word out that hook implementers should not use this parameter at all.','break warnings',0,'',''),(12377,'pytest','Our policy is to not deprecate features during bug-fix releases, but in this case we believe it makes sense as we are\nonly documenting it as deprecated, without issuing warnings which might potentially break test suites. This will get\nthe word out that hook implementers should not use this parameter at all.','get word',0,'',''),(12378,'pytest','issue #4034: The .user_properties attribute of TestReport objects is a list\nof (name, value) tuples, but could sometimes be instantiated as a tuple\nof tuples.  It is now always a list.','instantiate user_properties attribute as tuple',0,'',''),(12379,'pytest','issue #4034: The .user_properties attribute of TestReport objects is a list\nof (name, value) tuples, but could sometimes be instantiated as a tuple\nof tuples.  It is now always a list.','instantiate user_properties attribute of TestReport objects',0,'',''),(12380,'pytest','issue #4039: No longer issue warnings about using pytest_plugins in non-top-level directories when using --pyargs: the\ncurrent --pyargs mechanism is not reliable and might give false negatives.','use pytest_plugins in non-top-level directories',0,'',''),(12381,'pytest','issue #4040: Exclude empty reports for passed tests when -rP option is used.','use rp option',0,'',''),(12382,'pytest','issue #4051: Improve error message when an invalid Python expression is passed to the -m option.','pass invalid Python expression to m option',0,'',''),(12383,'pytest','In Python 2, adding unicode keys to os.environ causes problems with subprocess (and possible other modules),\nmaking this a subtle bug specially susceptible when used with from __future__ import unicode_literals.','add unicode keys to os.environ',0,'',''),(12384,'pytest','issue #3928: Add possible values for fixture scope to docs.','add possible values for fixture scope',0,'',''),(12385,'pytest','issue #3928: Add possible values for fixture scope to docs.','add possible values to docs',0,'',''),(12386,'pytest','issue #3286: .pytest_cache directory is now automatically ignored by Git. Users who would like to contribute a solution for other SCMs please consult/comment on this issue.','ignore pytest_cache directory',0,'',''),(12387,'pytest','issue #3749: Fix the following error during collection of tests inside packages:','fix following error during collection',1,'https://docs.pytest.org/en/7.2.x/changelog.html',''),(12388,'pytest','issue #3941: Fix bug where indirect parametrization would consider the scope of all fixtures used by the test function to determine the parametrization scope, and not only the scope of the fixtures being parametrized.','determine parametrization scope',0,'',''),(12389,'pytest','issue #3973: Fix crash of the assertion rewriter if a test changed the current working directory without restoring it afterwards.','change current working directory without restoring',0,'',''),(12390,'pytest','issue #3998: Fix issue that prevented some caplog properties (for example record_tuples) from being available when entering the debugger with --pdb.','prevent caplog properties',0,'',''),(12391,'pytest','issue #3998: Fix issue that prevented some caplog properties (for example record_tuples) from being available when entering the debugger with --pdb.','prevent fix issue',0,'',''),(12392,'pytest','issue #3998: Fix issue that prevented some caplog properties (for example record_tuples) from being available when entering the debugger with --pdb.','enter debugger',0,'',''),(12393,'pytest','issue #3999: Fix UnicodeDecodeError in python2.x when a class returns a non-ascii binary __repr__ in an assertion which also contains non-ascii text.','return non-ascii binary __repr__ in assertion',0,'',''),(12394,'pytest','issue #3996: New Deprecations and Removals page shows all currently\ndeprecated features, the rationale to do so, and alternatives to update your code. It also list features removed\nfrom pytest in past major releases to help those with ancient pytest versions to upgrade.','update code',0,'',''),(12395,'pytest','issue #3996: New Deprecations and Removals page shows all currently\ndeprecated features, the rationale to do so, and alternatives to update your code. It also list features removed\nfrom pytest in past major releases to help those with ancient pytest versions to upgrade.','list features',0,'',''),(12396,'pytest','issue #3996: New Deprecations and Removals page shows all currently\ndeprecated features, the rationale to do so, and alternatives to update your code. It also list features removed\nfrom pytest in past major releases to help those with ancient pytest versions to upgrade.','remove  from pytest',0,'',''),(12397,'pytest','issue #3975: Remove legacy code around im_func as that was python2 only','remove legacy code around im_func',0,'',''),(12398,'pytest','issue #3936: @pytest.mark.filterwarnings second parameter is no longer regex-escaped,\nmaking it possible to actually use regular expressions to check the warning message.','check warning message',0,'',''),(12399,'pytest','Note: regex-escaping the match string was an implementation oversight that might break test suites which depend\non the old behavior.','break test suites',0,'',''),(12400,'pytest','Note: regex-escaping the match string was an implementation oversight that might break test suites which depend\non the old behavior.','break implementation oversight',0,'',''),(12401,'pytest','issue #2452: Internal pytest warnings are now issued using the standard warnings module, making it possible to use\nthe standard warnings filters to manage those warnings. This introduces PytestWarning,\nPytestDeprecationWarning and RemovedInPytest4Warning warning types as part of the public API.','use standard warnings module',0,'',''),(12402,'pytest','issue #2452: Internal pytest warnings are now issued using the standard warnings module, making it possible to use\nthe standard warnings filters to manage those warnings. This introduces PytestWarning,\nPytestDeprecationWarning and RemovedInPytest4Warning warning types as part of the public API.','manage warnings',0,'',''),(12403,'pytest','issue #2452: Internal pytest warnings are now issued using the standard warnings module, making it possible to use\nthe standard warnings filters to manage those warnings. This introduces PytestWarning,\nPytestDeprecationWarning and RemovedInPytest4Warning warning types as part of the public API.','introduce PytestWarning PytestDeprecationWarning RemovedInPytest4Warning warning types as part',0,'',''),(12404,'pytest','issue #2908: DeprecationWarning and PendingDeprecationWarning are now shown by default if no other warning filter is\nconfigured. This makes pytest more compliant with\nPEP 506#recommended-filter-settings-for-test-runners. See\nthe docs for\nmore info.','show DeprecationWarning',0,'',''),(12405,'pytest','issue #2908: DeprecationWarning and PendingDeprecationWarning are now shown by default if no other warning filter is\nconfigured. This makes pytest more compliant with\nPEP 506#recommended-filter-settings-for-test-runners. See\nthe docs for\nmore info.','show PendingDeprecationWarning',0,'',''),(12406,'pytest','issue #2908: DeprecationWarning and PendingDeprecationWarning are now shown by default if no other warning filter is\nconfigured. This makes pytest more compliant with\nPEP 506#recommended-filter-settings-for-test-runners. See\nthe docs for\nmore info.','configure other warning filter',0,'',''),(12407,'pytest','issue #3251: Warnings are now captured and displayed during test collection.','display warnings',0,'',''),(12408,'pytest','issue #3829: Added the count option to console_output_style to enable displaying the progress as a count instead of a percentage.','add count option to console_output_style',0,'',''),(12409,'pytest','issue #3829: Added the count option to console_output_style to enable displaying the progress as a count instead of a percentage.','display progress as count',0,'',''),(12410,'pytest','issue #3837: Added support for ‘xfailed’ and ‘xpassed’ outcomes to the pytester.RunResult.assert_outcomes signature.','add support for âxfailedâ âxpassedâ outcomes',0,'',''),(12411,'pytest','issue #3837: Added support for ‘xfailed’ and ‘xpassed’ outcomes to the pytester.RunResult.assert_outcomes signature.','add support to pytester.RunResult.assert_outcomes signature',0,'',''),(12412,'pytest','issue #3913: Pytest now returns with correct exit code (EXIT_USAGEERROR, 4) when called with unknown arguments.','return  with correct exit code',0,'',''),(12413,'pytest','issue #3913: Pytest now returns with correct exit code (EXIT_USAGEERROR, 4) when called with unknown arguments.','call  with unknown arguments',0,'',''),(12414,'pytest','issue #3566: Added a blurb in usage.rst for the usage of -r flag which is used to show an extra test summary info.','add blurb in usage.rst',0,'',''),(12415,'pytest','issue #3566: Added a blurb in usage.rst for the usage of -r flag which is used to show an extra test summary info.','add blurb for usage',0,'',''),(12416,'pytest','issue #3566: Added a blurb in usage.rst for the usage of -r flag which is used to show an extra test summary info.','show extra test summary info',0,'',''),(12417,'pytest','issue #3566: Added a blurb in usage.rst for the usage of -r flag which is used to show an extra test summary info.','use r flag',0,'',''),(12418,'pytest','issue #3853: Removed \"run all (no recorded failures)\" message printed with --failed-first and --last-failed when there are no failed tests.','run message',0,'',''),(12419,'pytest','issue #3506: Fix possible infinite recursion when writing .pyc files.','fix possible infinite recursion',0,'',''),(12420,'pytest','issue #3853: Cache plugin now obeys the -q flag when --last-failed and --failed-first flags are used.','use failed-first flags',0,'',''),(12421,'pytest','issue #3883: Fix bad console output when using console_output_style=classic.','fix bad console output',0,'',''),(12422,'pytest','issue #3888: Fix macOS specific code using capturemanager plugin in doctests.','use capturemanager plugin in doctests',0,'',''),(12423,'pytest','issue #3902: Fix pytest.org links','fix pytest.org links',0,'',''),(12424,'pytest','issue #3033: Fixtures during teardown can again use capsys and capfd to inspect output captured during tests.','use capsys',0,'',''),(12425,'pytest','issue #3773: Fix collection of tests from __init__.py files if they match the python_files configuration option.','match python_files configuration option',0,'',''),(12426,'pytest','issue #3796: Fix issue where teardown of fixtures of consecutive sub-packages were executed once, at the end of the outer\npackage.','execute teardown at end',0,'',''),(12427,'pytest','issue #3796: Fix issue where teardown of fixtures of consecutive sub-packages were executed once, at the end of the outer\npackage.','execute teardown of fixtures',0,'',''),(12428,'pytest','issue #3796: Fix issue where teardown of fixtures of consecutive sub-packages were executed once, at the end of the outer\npackage.','execute fix issue at end',0,'',''),(12429,'pytest','issue #3796: Fix issue where teardown of fixtures of consecutive sub-packages were executed once, at the end of the outer\npackage.','execute fix issue of fixtures',0,'',''),(12430,'pytest','issue #3816: Fix bug where --show-capture=no option would still show logs printed during fixture teardown.','print fix bug during fixture teardown',0,'',''),(12431,'pytest','issue #3816: Fix bug where --show-capture=no option would still show logs printed during fixture teardown.','show show-capture =',0,'',''),(12432,'pytest','issue #3843: Fix collection error when specifying test functions directly in the command line using test.py::test syntax together with --doctest-modules.','specify test functions',0,'',''),(12433,'pytest','issue #3843: Fix collection error when specifying test functions directly in the command line using test.py::test syntax together with --doctest-modules.','use test.py',0,'',''),(12434,'pytest','issue #3824: Added example for multiple glob pattern matches in python_files.','match  in python_files',0,'',''),(12435,'pytest','issue #3833: Added missing docs for pytester.Testdir.','add missing docs for pytester.Testdir',0,'',''),(12436,'pytest','issue #3845: Remove a reference to issue issue #568 from the documentation, which has since been\nfixed.','remove reference',0,'',''),(12437,'pytest','issue #3845: Remove a reference to issue issue #568 from the documentation, which has since been\nfixed.','fix documentation',0,'',''),(12438,'pytest','issue #3771: Fix infinite recursion during collection if a pytest_ignore_collect hook returns False instead of None.','fix infinite recursion during collection',0,'',''),(12439,'pytest','issue #3771: Fix infinite recursion during collection if a pytest_ignore_collect hook returns False instead of None.','return false instead_of none',0,'',''),(12440,'pytest','issue #3775: Fix bug where importing modules or other objects with prefix pytest_ prefix would raise a PluginValidationError.','import modules with prefix pytest _ prefix',0,'',''),(12441,'pytest','issue #3775: Fix bug where importing modules or other objects with prefix pytest_ prefix would raise a PluginValidationError.','import other objects with prefix pytest _ prefix',0,'',''),(12442,'pytest','issue #3775: Fix bug where importing modules or other objects with prefix pytest_ prefix would raise a PluginValidationError.','raise PluginValidationError',0,'',''),(12443,'pytest','issue #3775: Fix bug where importing modules or other objects with prefix pytest_ prefix would raise a PluginValidationError.','raise fix bug',0,'',''),(12444,'pytest','issue #3788: Fix AttributeError during teardown of TestCase subclasses which raise an exception during __init__.','raise exception during __init__',0,'',''),(12445,'pytest','issue #3788: Fix AttributeError during teardown of TestCase subclasses which raise an exception during __init__.','raise exception during teardown',0,'',''),(12446,'pytest','issue #3788: Fix AttributeError during teardown of TestCase subclasses which raise an exception during __init__.','raise fix AttributeError during __init__',0,'',''),(12447,'pytest','issue #3788: Fix AttributeError during teardown of TestCase subclasses which raise an exception during __init__.','raise fix AttributeError during teardown',0,'',''),(12448,'pytest','issue #3746: Add documentation for metafunc.config that had been mistakenly hidden.','hide add documentation for metafunc.config',0,'',''),(12449,'pytest','issue #3712: Correctly represent the dimensions of a numpy array when calling repr() on approx().','call repr() on approx()',0,'',''),(12450,'pytest','issue #3742: Fix incompatibility with third party plugins during collection, which produced the error object has no attribute \'_collectfile\'.','fix  with third party plugins',0,'',''),(12451,'pytest','issue #3742: Fix incompatibility with third party plugins during collection, which produced the error object has no attribute \'_collectfile\'.','fix  during collection',0,'',''),(12452,'pytest','issue #3742: Fix incompatibility with third party plugins during collection, which produced the error object has no attribute \'_collectfile\'.','produce collection',0,'',''),(12453,'pytest','issue #3661: Calling a fixture function directly, as opposed to request them in a test function, now issues a RemovedInPytest4Warning. See the documentation for rationale and examples.','call fixture function',0,'',''),(12454,'pytest','issue #3661: Calling a fixture function directly, as opposed to request them in a test function, now issues a RemovedInPytest4Warning. See the documentation for rationale and examples.','request  in test function',0,'',''),(12455,'pytest','issue #3576: Node.add_marker now supports an append=True/False parameter to determine whether the mark comes last (default) or first.','support append',0,'',''),(12456,'pytest','issue #3579: Fixture caplog now has a messages property, providing convenient access to the format-interpolated log messages without the extra data provided by the formatter/handler.','provide convenient access to format-interpolated log messages',0,'',''),(12457,'pytest','issue #3579: Fixture caplog now has a messages property, providing convenient access to the format-interpolated log messages without the extra data provided by the formatter/handler.','provide convenient access without extra data',0,'',''),(12458,'pytest','issue #3610: New --trace option to enter the debugger at the start of a test.','enter debugger at start',0,'',''),(12459,'pytest','issue #2220: Fix a bug where fixtures overridden by direct parameters (for example parametrization) were being instantiated even if they were not being used by a test.','fix bug',0,'',''),(12460,'pytest','issue #2220: Fix a bug where fixtures overridden by direct parameters (for example parametrization) were being instantiated even if they were not being used by a test.','instantiate fixtures',0,'',''),(12461,'pytest','issue #3695: Fix ApproxNumpy initialisation argument mixup, abs and rel tolerances were flipped causing strange comparison results.\nAdd tests to check abs and rel tolerances for np.array and test for expecting nan with np.array()','fix ApproxNumpy initialisation argument mixup',0,'',''),(12462,'pytest','issue #3695: Fix ApproxNumpy initialisation argument mixup, abs and rel tolerances were flipped causing strange comparison results.\nAdd tests to check abs and rel tolerances for np.array and test for expecting nan with np.array()','check abs rel tolerances for np.array',0,'',''),(12463,'pytest','issue #3695: Fix ApproxNumpy initialisation argument mixup, abs and rel tolerances were flipped causing strange comparison results.\nAdd tests to check abs and rel tolerances for np.array and test for expecting nan with np.array()','check abs rel tolerances for test',0,'',''),(12464,'pytest','issue #980: Fix truncated locals output in verbose mode.','fix truncated locals output in verbose mode',0,'',''),(12465,'pytest','issue #3519: Now a README.md file is created in .pytest_cache to make it clear why the directory exists.','create README.md file',0,'',''),(12466,'pytest','Invoke pytest using -mpytest so sys.path does not get polluted by packages installed in site-packages. (issue #742)','install  in site-packages',0,'',''),(12467,'pytest','Remove obsolete __future__ imports. (issue #2319)','remove obsolete __future__ imports',0,'',''),(12468,'pytest','Add CITATION to provide information on how to formally cite pytest. (issue #3402)','add CITATION',0,'',''),(12469,'pytest','Add CITATION to provide information on how to formally cite pytest. (issue #3402)','provide information',0,'',''),(12470,'pytest','Replace broken type annotations with type comments. (issue #3635)','replace broken type annotations with type comments',0,'',''),(12471,'pytest','Fix ImportWarning triggered by explicit relative imports in\nassertion-rewritten package modules. (issue #3061)','trigger  in assertion-rewritten package modules',0,'',''),(12472,'pytest','Fix ImportWarning triggered by explicit relative imports in\nassertion-rewritten package modules. (issue #3061)','trigger  by explicit relative imports',0,'',''),(12473,'pytest','Fix error in pytest.approx when dealing with 0-dimension numpy\narrays. (issue #3593)','fix error in pytest.approx',0,'',''),(12474,'pytest','No longer raise ValueError when using the get_marker API. (issue #3605)','raise ValueError',0,'',''),(12475,'pytest','No longer raise ValueError when using the get_marker API. (issue #3605)','use get_marker API',0,'',''),(12476,'pytest','No longer raise AttributeError when legacy marks can’t be stored in\nfunctions. (issue #3631)','raise AttributeError',0,'',''),(12477,'pytest','No longer raise AttributeError when legacy marks can’t be stored in\nfunctions. (issue #3631)','store legacy marks in functions',0,'',''),(12478,'pytest','The description above the example for @pytest.mark.skipif now better\nmatches the code. (issue #3611)','match code',0,'',''),(12479,'pytest','Internal refactoring: removed unused CallSpec2tox ._globalid_args\nattribute and metafunc parameter from CallSpec2.copy(). (issue #3598)','remove unused CallSpec2tox',0,'',''),(12480,'pytest','Fix usage of attr.ib deprecated convert parameter. (issue #3653)','convert parameter',0,'',''),(12481,'pytest','Fix regression in Node.add_marker by extracting the mark object of a\nMarkDecorator. (issue #3555)','fix regression in Node.add_marker',0,'',''),(12482,'pytest','Fix regression in Node.add_marker by extracting the mark object of a\nMarkDecorator. (issue #3555)','fix regression by extracting',0,'',''),(12483,'pytest','Continue to call finalizers in the stack when a finalizer in a former scope\nraises an exception. (issue #3569)','call finalizers in stack',0,'',''),(12484,'pytest','Continue to call finalizers in the stack when a finalizer in a former scope\nraises an exception. (issue #3569)','raise exception',0,'',''),(12485,'pytest','Fix encoding error with print statements in doctests (issue #3583)','fix encoding error with print statements',0,'',''),(12486,'pytest','Add documentation for the --strict flag. (issue #3549)','add documentation for strict flag',0,'',''),(12487,'pytest','Fix typo in documentation (issue #3567)','fix typo in documentation',0,'',''),(12488,'pytest','Fixed a bug where stdout and stderr were logged twice by junitxml when a test\nwas marked xfail. (issue #3491)','fix bug',0,'',''),(12489,'pytest','Fixed a bug where stdout and stderr were logged twice by junitxml when a test\nwas marked xfail. (issue #3491)','log stdout',0,'',''),(12490,'pytest','Fixed a bug where stdout and stderr were logged twice by junitxml when a test\nwas marked xfail. (issue #3491)','log stderr',0,'',''),(12491,'pytest','Fixed a bug where stdout and stderr were logged twice by junitxml when a test\nwas marked xfail. (issue #3491)','mark test',0,'',''),(12492,'pytest','Fix usefixtures mark applied to unittest tests by correctly instantiating\nFixtureInfo. (issue #3498)','instantiate FixtureInfo',0,'',''),(12493,'pytest','Fix assertion rewriter compatibility with libraries that monkey patch\nfile objects. (issue #3503)','fix assertion rewriter compatibility with libraries',0,'',''),(12494,'pytest','Added a section on how to use fixtures as factories to the fixture\ndocumentation. (issue #3461)','add section',0,'',''),(12495,'pytest','Added a section on how to use fixtures as factories to the fixture\ndocumentation. (issue #3461)','use fixtures as factories',0,'',''),(12496,'pytest','Switch pytest to the src/ layout as we already suggested it for good practice\n- now we implement it as well. (issue #3513)','switch pytest to src',0,'',''),(12497,'pytest','Switch pytest to the src/ layout as we already suggested it for good practice\n- now we implement it as well. (issue #3513)','implement pytest to src',0,'',''),(12498,'pytest','Fix if in tests to support 3.7.0b5, where a docstring handling in AST got\nreverted. (issue #3530)','support 3.7.0b5',0,'',''),(12499,'pytest','Remove some python2.5 compatibility code. (issue #3529)','remove python2 compatibility code',0,'',''),(12500,'pytest','Revamp the internals of the pytest.mark implementation with correct per\nnode handling which fixes a number of long standing bugs caused by the old\ndesign. This introduces new Node.iter_markers(name) and\nNode.get_closest_marker(name) APIs. Users are strongly encouraged to\nread the reasons for the revamp in the docs,\nor jump over to details about updating existing code to use the new APIs.\n(issue #3317)','fix number of long standing',0,'',''),(12501,'pytest','Revamp the internals of the pytest.mark implementation with correct per\nnode handling which fixes a number of long standing bugs caused by the old\ndesign. This introduces new Node.iter_markers(name) and\nNode.get_closest_marker(name) APIs. Users are strongly encouraged to\nread the reasons for the revamp in the docs,\nor jump over to details about updating existing code to use the new APIs.\n(issue #3317)','fix node handling of long standing',0,'',''),(12502,'pytest','Revamp the internals of the pytest.mark implementation with correct per\nnode handling which fixes a number of long standing bugs caused by the old\ndesign. This introduces new Node.iter_markers(name) and\nNode.get_closest_marker(name) APIs. Users are strongly encouraged to\nread the reasons for the revamp in the docs,\nor jump over to details about updating existing code to use the new APIs.\n(issue #3317)','introduce new Node.iter_markers(name)',0,'',''),(12503,'pytest','Revamp the internals of the pytest.mark implementation with correct per\nnode handling which fixes a number of long standing bugs caused by the old\ndesign. This introduces new Node.iter_markers(name) and\nNode.get_closest_marker(name) APIs. Users are strongly encouraged to\nread the reasons for the revamp in the docs,\nor jump over to details about updating existing code to use the new APIs.\n(issue #3317)','introduce Node.get_closest_marker(name) apis',0,'',''),(12504,'pytest','Revamp the internals of the pytest.mark implementation with correct per\nnode handling which fixes a number of long standing bugs caused by the old\ndesign. This introduces new Node.iter_markers(name) and\nNode.get_closest_marker(name) APIs. Users are strongly encouraged to\nread the reasons for the revamp in the docs,\nor jump over to details about updating existing code to use the new APIs.\n(issue #3317)','read reasons for revamp',0,'',''),(12505,'pytest','Revamp the internals of the pytest.mark implementation with correct per\nnode handling which fixes a number of long standing bugs caused by the old\ndesign. This introduces new Node.iter_markers(name) and\nNode.get_closest_marker(name) APIs. Users are strongly encouraged to\nread the reasons for the revamp in the docs,\nor jump over to details about updating existing code to use the new APIs.\n(issue #3317)','update existing code',0,'',''),(12506,'pytest','Revamp the internals of the pytest.mark implementation with correct per\nnode handling which fixes a number of long standing bugs caused by the old\ndesign. This introduces new Node.iter_markers(name) and\nNode.get_closest_marker(name) APIs. Users are strongly encouraged to\nread the reasons for the revamp in the docs,\nor jump over to details about updating existing code to use the new APIs.\n(issue #3317)','use new apis',0,'',''),(12507,'pytest','Now when @pytest.fixture is applied more than once to the same function a\nValueError is raised. This buggy behavior would cause surprising problems\nand if was working for a test suite it was mostly by accident. (issue #2334)','apply  to same function',0,'',''),(12508,'pytest','Now when @pytest.fixture is applied more than once to the same function a\nValueError is raised. This buggy behavior would cause surprising problems\nand if was working for a test suite it was mostly by accident. (issue #2334)','raise ValueError',0,'',''),(12509,'pytest','Support for Python 3.7’s builtin breakpoint() method, see\nUsing the builtin breakpoint function for\ndetails. (issue #3180)','use builtin breakpoint function for details',0,'',''),(12510,'pytest','monkeypatch now supports a context() function which acts as a context\nmanager which undoes all patching done within the with block. (issue #3290)','support context() function',0,'',''),(12511,'pytest','The --pdb option now causes KeyboardInterrupt to enter the debugger,\ninstead of stopping the test session. On python 2.7, hitting CTRL+C again\nexits the debugger. On python 3.2 and higher, use CTRL+D. (issue #3299)','enter debugger',0,'',''),(12512,'pytest','The --pdb option now causes KeyboardInterrupt to enter the debugger,\ninstead of stopping the test session. On python 2.7, hitting CTRL+C again\nexits the debugger. On python 3.2 and higher, use CTRL+D. (issue #3299)','use CTRL + d. on python',0,'',''),(12513,'pytest','pytest no longer changes the log level of the root logger when the\nlog-level parameter has greater numeric value than that of the level of\nthe root logger, which makes it play better with custom logging configuration\nin user code. (issue #3307)','change log level of root logger',0,'',''),(12514,'pytest','pytest no longer changes the log level of the root logger when the\nlog-level parameter has greater numeric value than that of the level of\nthe root logger, which makes it play better with custom logging configuration\nin user code. (issue #3307)','play  with custom logging configuration',0,'',''),(12515,'pytest','Also use iter_marker for discovering the marks applying for marker\nexpressions from the cli to avoid the bad data from the legacy mark storage.\n(issue #3441)','use iter_marker',0,'',''),(12516,'pytest','Also use iter_marker for discovering the marks applying for marker\nexpressions from the cli to avoid the bad data from the legacy mark storage.\n(issue #3441)','apply  for marker expressions',0,'',''),(12517,'pytest','Also use iter_marker for discovering the marks applying for marker\nexpressions from the cli to avoid the bad data from the legacy mark storage.\n(issue #3441)','apply  from cli',0,'',''),(12518,'pytest','When showing diffs of failed assertions where the contents contain only\nwhitespace, escape them using repr() first to make it easy to spot the\ndifferences. (issue #3443)','show diffs of failed assertions',0,'',''),(12519,'pytest','When showing diffs of failed assertions where the contents contain only\nwhitespace, escape them using repr() first to make it easy to spot the\ndifferences. (issue #3443)','use repr() first',0,'',''),(12520,'pytest','Detect pytest_ prefixed hooks using the internal plugin manager since\npluggy is deprecating the implprefix argument to PluginManager.\n(issue #3487)','use internal plugin manager since pluggy',0,'',''),(12521,'pytest','Import Mapping and Sequence from _pytest.compat instead of\ndirectly from collections in python_api.py::approx. Add Mapping\nto _pytest.compat, import it from collections on python 2, but from\ncollections.abc on Python 3 to avoid a DeprecationWarning on Python\n3.7 or newer. (issue #3497)','import  from collections.abc',0,'',''),(12522,'pytest','Import Mapping and Sequence from _pytest.compat instead of\ndirectly from collections in python_api.py::approx. Add Mapping\nto _pytest.compat, import it from collections on python 2, but from\ncollections.abc on Python 3 to avoid a DeprecationWarning on Python\n3.7 or newer. (issue #3497)','import  from collections',0,'',''),(12523,'pytest','Reset sys.last_type, sys.last_value and sys.last_traceback before\neach test executes. Those attributes are added by pytest during the test run\nto aid debugging, but were never reset so they would create a leaking\nreference to the last failing test’s frame which in turn could never be\nreclaimed by the garbage collector. (issue #2798)','create leaking reference to frame',0,'',''),(12524,'pytest','Reset sys.last_type, sys.last_value and sys.last_traceback before\neach test executes. Those attributes are added by pytest during the test run\nto aid debugging, but were never reset so they would create a leaking\nreference to the last failing test’s frame which in turn could never be\nreclaimed by the garbage collector. (issue #2798)','add attributes during test',0,'',''),(12525,'pytest','pytest.raises now raises TypeError when receiving an unknown keyword\nargument. (issue #3348)','raise TypeError',0,'',''),(12526,'pytest','pytest.raises now raises TypeError when receiving an unknown keyword\nargument. (issue #3348)','receive unknown keyword argument',0,'',''),(12527,'pytest','Fix typo in caplog fixture documentation, which incorrectly identified\ncertain attributes as methods. (issue #3406)','fix typo in caplog fixture documentation',0,'',''),(12528,'pytest','Fix typo in caplog fixture documentation, which incorrectly identified\ncertain attributes as methods. (issue #3406)','identify certain attributes as methods',0,'',''),(12529,'pytest','Fix typo in caplog fixture documentation, which incorrectly identified\ncertain attributes as methods. (issue #3406)','identify caplog fixture documentation as methods',0,'',''),(12530,'pytest','Added a more indicative error message when parametrizing a function whose\nargument takes a default value. (issue #3221)','add indicative error message',0,'',''),(12531,'pytest','Remove internal _pytest.terminal.flatten function in favor of\nmore_itertools.collapse. (issue #3330)','remove internal _pytest.terminal.flatten function in favor',0,'',''),(12532,'pytest','Mention in documentation and CLI help that fixtures with leading _ are\nprinted by pytest --fixtures only if the -v option is added. (issue #3398)','print fixtures with leading _',0,'',''),(12533,'pytest','Mention in documentation and CLI help that fixtures with leading _ are\nprinted by pytest --fixtures only if the -v option is added. (issue #3398)','add v option',0,'',''),(12534,'pytest','New --rootdir command-line option to override the rules for discovering\nthe root directory. See customize in the documentation for\ndetails. (issue #1642)','override rules for discovering',0,'',''),(12535,'pytest','Fixtures are now instantiated based on their scopes, with higher-scoped\nfixtures (such as session) being instantiated first than lower-scoped\nfixtures (such as function). The relative order of fixtures of the same\nscope is kept unchanged, based in their declaration order and their\ndependencies. (issue #2405)','instantiate fixtures with higher-scoped fixtures',0,'',''),(12536,'pytest','Fixtures are now instantiated based on their scopes, with higher-scoped\nfixtures (such as session) being instantiated first than lower-scoped\nfixtures (such as function). The relative order of fixtures of the same\nscope is kept unchanged, based in their declaration order and their\ndependencies. (issue #2405)','instantiate  than lower-scoped fixtures',0,'',''),(12537,'pytest','record_xml_property renamed to record_property and is now compatible\nwith xdist, markers and any reporter. record_xml_property name is now\ndeprecated. (issue #2770)','rename  to record_property',0,'',''),(12538,'pytest','New --nf, --new-first options: run new tests first followed by the\nrest of the tests, in both cases tests are also sorted by the file modified\ntime, with more recent files coming first. (issue #3034)','sort tests in cases',0,'',''),(12539,'pytest','New --nf, --new-first options: run new tests first followed by the\nrest of the tests, in both cases tests are also sorted by the file modified\ntime, with more recent files coming first. (issue #3034)','sort new in cases',0,'',''),(12540,'pytest','New --nf, --new-first options: run new tests first followed by the\nrest of the tests, in both cases tests are also sorted by the file modified\ntime, with more recent files coming first. (issue #3034)','modify  with more recent files',0,'',''),(12541,'pytest','New --last-failed-no-failures command-line option that allows to specify\nthe behavior of the cache plugin’s `--last-failed feature when no tests\nfailed in the last run (or no cache was found): none or all (the\ndefault). (issue #3139)','specify behavior of cache plugin',0,'',''),(12542,'pytest','New --doctest-continue-on-failure command-line option to enable doctests\nto show multiple failures for each snippet, instead of stopping at the first\nfailure. (issue #3149)','enable doctests instead_of stopping',0,'',''),(12543,'pytest','New --doctest-continue-on-failure command-line option to enable doctests\nto show multiple failures for each snippet, instead of stopping at the first\nfailure. (issue #3149)','show multiple failures for snippet',0,'',''),(12544,'pytest','Captured log messages are added to the  tag in the generated\njunit xml file if the junit_logging ini option is set to system-out.\nIf the value of this ini option is system-err, the logs are written to\n. The default value for junit_logging is no, meaning\ncaptured logs are not written to the output file. (issue #3156)','add captured log messages to tag',0,'',''),(12545,'pytest','Captured log messages are added to the  tag in the generated\njunit xml file if the junit_logging ini option is set to system-out.\nIf the value of this ini option is system-err, the logs are written to\n. The default value for junit_logging is no, meaning\ncaptured logs are not written to the output file. (issue #3156)','set junit_logging ini option to system-out',0,'',''),(12546,'pytest','Captured log messages are added to the  tag in the generated\njunit xml file if the junit_logging ini option is set to system-out.\nIf the value of this ini option is system-err, the logs are written to\n. The default value for junit_logging is no, meaning\ncaptured logs are not written to the output file. (issue #3156)','write logs',0,'',''),(12547,'pytest','Allow the logging plugin to handle pytest_runtest_logstart and\npytest_runtest_logfinish hooks when live logs are enabled. (issue #3189)','handle pytest_runtest_logstart pytest_runtest_logfinish hooks',0,'',''),(12548,'pytest','Allow the logging plugin to handle pytest_runtest_logstart and\npytest_runtest_logfinish hooks when live logs are enabled. (issue #3189)','enable live logs',0,'',''),(12549,'pytest','Passing --log-cli-level in the command-line now automatically activates\nlive logging. (issue #3190)','activate live logging',0,'',''),(12550,'pytest','Captured logs are printed before entering pdb. (issue #3204)','enter pdb',0,'',''),(12551,'pytest','Captured logs are printed before entering pdb. (issue #3204)','print captured logs before entering',0,'',''),(12552,'pytest','Deselected item count is now shown before tests are run, e.g. collected X\nitems / Y deselected. (issue #3213)','show deselected item count',0,'',''),(12553,'pytest','Deselected item count is now shown before tests are run, e.g. collected X\nitems / Y deselected. (issue #3213)','run tests',0,'',''),(12554,'pytest','The short test summary info section now is displayed after tracebacks and\nwarnings in the terminal. (issue #3255)','display short test summary info section in terminal',0,'',''),(12555,'pytest','The short test summary info section now is displayed after tracebacks and\nwarnings in the terminal. (issue #3255)','display short test summary info section after tracebacks',0,'',''),(12556,'pytest','The short test summary info section now is displayed after tracebacks and\nwarnings in the terminal. (issue #3255)','display short test summary info section after warnings',0,'',''),(12557,'pytest','New --verbosity flag to set verbosity level explicitly. (issue #3296)','set verbosity level',0,'',''),(12558,'pytest','pytest.approx now accepts comparing a numpy array with a scalar. (issue #3312)','compare numpy array with scalar',0,'',''),(12559,'pytest','Suppress IOError when closing the temporary file used for capturing\nstreams in Python 2.7. (issue #2370)','use  for capturing',0,'',''),(12560,'pytest','Added a reference page\nto the docs. (issue #1713)','add reference page to docs',0,'',''),(12561,'pytest','Renamed example directories so all tests pass when ran from the base\ndirectory. (issue #3245)','run  from base directory',0,'',''),(12562,'pytest','Added warning when [pytest] section is used in a .cfg file passed\nwith -c (issue #3268)','use pytest  section',0,'',''),(12563,'pytest','Added warning when [pytest] section is used in a .cfg file passed\nwith -c (issue #3268)','pass  with c.',0,'',''),(12564,'pytest','nodeids can now be passed explicitly to FSCollector and Node\nconstructors. (issue #3291)','pass nodeids to FSCollector node constructors',0,'',''),(12565,'pytest','Internal refactoring of FormattedExcinfo to use attrs facilities and\nremove old support code for legacy Python versions. (issue #3292)','use attrs facilities',0,'',''),(12566,'pytest','Internal refactoring of FormattedExcinfo to use attrs facilities and\nremove old support code for legacy Python versions. (issue #3292)','remove old support code for legacy Python versions',0,'',''),(12567,'pytest','Internal refactoring of FormattedExcinfo to use attrs facilities and\nremove old support code for legacy Python versions. (issue #3292)','refactor  of FormattedExcinfo',0,'',''),(12568,'pytest','Internal refactoring to better integrate with argparse. (issue #3304)','integrate  with argparse',0,'',''),(12569,'pytest','Fix a python example when calling a fixture in doc/en/usage.rst (issue #3308)','fix python example',0,'',''),(12570,'pytest','Fix a python example when calling a fixture in doc/en/usage.rst (issue #3308)','call fixture in doc/en/usage.rst',0,'',''),(12571,'pytest','Removed progress information when capture option is no. (issue #3203)','remove progress information',0,'',''),(12572,'pytest','Fix TypeError issue when using approx with a Decimal value.\n(issue #3247)','fix TypeError issue',0,'',''),(12573,'pytest','Fix TypeError issue when using approx with a Decimal value.\n(issue #3247)','use approx with decimal value',0,'',''),(12574,'pytest','Fix reference cycle generated when using the request fixture. (issue #3249)','use request fixture',0,'',''),(12575,'pytest','Add logging plugin to plugins list. (issue #3209)','add logging plugin to plugins list',0,'',''),(12576,'pytest','Fix minor typo in fixture.rst (issue #3259)','fix minor typo in fixture.rst',0,'',''),(12577,'pytest','Move import of doctest.UnexpectedException to top-level to avoid possible\nerrors when using --pdb. (issue #1810)','move import of doctest.UnexpectedException',0,'',''),(12578,'pytest','Added printing of captured stdout/stderr before entering pdb, and improved a\ntest which was giving false negatives about output capturing. (issue #3052)','add printing before entering',0,'',''),(12579,'pytest','Added printing of captured stdout/stderr before entering pdb, and improved a\ntest which was giving false negatives about output capturing. (issue #3052)','add printing of captured stdout/stderr',0,'',''),(12580,'pytest','Added printing of captured stdout/stderr before entering pdb, and improved a\ntest which was giving false negatives about output capturing. (issue #3052)','enter pdb',0,'',''),(12581,'pytest','Fix ordering of tests using parametrized fixtures which can lead to fixtures\nbeing created more than necessary. (issue #3161)','use parametrized fixtures',0,'',''),(12582,'pytest','Fix ordering of tests using parametrized fixtures which can lead to fixtures\nbeing created more than necessary. (issue #3161)','order  of tests',0,'',''),(12583,'pytest','Fix bug where logging happening at hooks outside of “test run” hooks would\ncause an internal error. (issue #3184)','fix bug',0,'',''),(12584,'pytest','Detect arguments injected by unittest.mock.patch decorator correctly when\npypi mock.patch is installed and imported. (issue #3206)','install pypi mock.patch',0,'',''),(12585,'pytest','Detect arguments injected by unittest.mock.patch decorator correctly when\npypi mock.patch is installed and imported. (issue #3206)','import pypi mock.patch',0,'',''),(12586,'pytest','Errors shown when a pytest.raises() with match= fails are now cleaner\non what happened: When no exception was raised, the “matching ‘…’” part got\nremoved as it falsely implies that an exception was raised but it didn’t\nmatch. When a wrong exception was raised, it’s now thrown (like\npytest.raised() without match= would) instead of complaining about\nthe unmatched text. (issue #3222)','raise exception',0,'',''),(12587,'pytest','Errors shown when a pytest.raises() with match= fails are now cleaner\non what happened: When no exception was raised, the “matching ‘…’” part got\nremoved as it falsely implies that an exception was raised but it didn’t\nmatch. When a wrong exception was raised, it’s now thrown (like\npytest.raised() without match= would) instead of complaining about\nthe unmatched text. (issue #3222)','remove matching ââ¦â part',0,'',''),(12588,'pytest','Errors shown when a pytest.raises() with match= fails are now cleaner\non what happened: When no exception was raised, the “matching ‘…’” part got\nremoved as it falsely implies that an exception was raised but it didn’t\nmatch. When a wrong exception was raised, it’s now thrown (like\npytest.raised() without match= would) instead of complaining about\nthe unmatched text. (issue #3222)','raise exception',0,'',''),(12589,'pytest','Errors shown when a pytest.raises() with match= fails are now cleaner\non what happened: When no exception was raised, the “matching ‘…’” part got\nremoved as it falsely implies that an exception was raised but it didn’t\nmatch. When a wrong exception was raised, it’s now thrown (like\npytest.raised() without match= would) instead of complaining about\nthe unmatched text. (issue #3222)','throw  instead_of complaining',0,'',''),(12590,'pytest','Errors shown when a pytest.raises() with match= fails are now cleaner\non what happened: When no exception was raised, the “matching ‘…’” part got\nremoved as it falsely implies that an exception was raised but it didn’t\nmatch. When a wrong exception was raised, it’s now thrown (like\npytest.raised() without match= would) instead of complaining about\nthe unmatched text. (issue #3222)','raise wrong exception',0,'',''),(12591,'pytest','Fixed output capture handling in doctests on macOS. (issue #985)','handle  in doctests',0,'',''),(12592,'pytest','Add Sphinx parameter docs for match and message args to\npytest.raises. (issue #3202)','add Sphinx parameter docs for match message args',0,'',''),(12593,'pytest','Add Sphinx parameter docs for match and message args to\npytest.raises. (issue #3202)','add Sphinx parameter docs to pytest.raises',0,'',''),(12594,'pytest','pytest has changed the publication procedure and is now being published to\nPyPI directly from Travis. (issue #3060)','change publication procedure',0,'',''),(12595,'pytest','Rename ParameterSet._for_parameterize() to _for_parametrize() in\norder to comply with the naming convention. (issue #3166)','rename ParameterSet._for_parameterize() to _',0,'',''),(12596,'pytest','Introduce empty_parameter_set_mark ini option to select which mark to\napply when @pytest.mark.parametrize is given an empty set of parameters.\nValid options are skip (default) and xfail. Note that it is planned\nto change the default to xfail in future releases as this is considered\nless error prone. (issue #2527)','change default',0,'',''),(12597,'pytest','New pytest_runtest_logfinish\nhook which is called when a test item has finished executing, analogous to\npytest_runtest_logstart.\n(issue #3101)','call pytest_runtest_logfinish hook',0,'',''),(12598,'pytest','Improve performance when collecting tests using many fixtures. (issue #3107)','use many fixtures',0,'',''),(12599,'pytest','New caplog.get_records(when) method which provides access to the captured\nrecords for the \"setup\", \"call\" and \"teardown\"\ntesting stages. (issue #3117)','provide access to captured',0,'',''),(12600,'pytest','New caplog.get_records(when) method which provides access to the captured\nrecords for the \"setup\", \"call\" and \"teardown\"\ntesting stages. (issue #3117)','provide new caplog.get_records(when) method to captured',0,'',''),(12601,'pytest','The default cache directory has been renamed from .cache to\n.pytest_cache after community feedback that the name .cache did not\nmake it clear that it was used by pytest. (issue #3138)','rename default cache directory',0,'',''),(12602,'pytest','Fix hanging pexpect test on MacOS by using flush() instead of wait().\n(issue #2022)','use flush() instead_of wait()',0,'',''),(12603,'pytest','Fix restoring Python state after in-process pytest runs with the\npytester plugin; this may break tests using multiple inprocess\npytest runs if later ones depend on earlier ones leaking global interpreter\nchanges. (issue #3016)','break tests',0,'',''),(12604,'pytest','Fix restoring Python state after in-process pytest runs with the\npytester plugin; this may break tests using multiple inprocess\npytest runs if later ones depend on earlier ones leaking global interpreter\nchanges. (issue #3016)','use multiple inprocess',0,'',''),(12605,'pytest','Fix restoring Python state after in-process pytest runs with the\npytester plugin; this may break tests using multiple inprocess\npytest runs if later ones depend on earlier ones leaking global interpreter\nchanges. (issue #3016)','run  with pytester plugin',0,'',''),(12606,'pytest','Fix restoring Python state after in-process pytest runs with the\npytester plugin; this may break tests using multiple inprocess\npytest runs if later ones depend on earlier ones leaking global interpreter\nchanges. (issue #3016)','run multiple inprocess',0,'',''),(12607,'pytest','Fix skipping plugin reporting hook when test aborted before plugin setup\nhook. (issue #3074)','skip plugin reporting hook',0,'',''),(12608,'pytest','Clarify that warning capturing doesn’t change the warning filter by default.\n(issue #2457)','change warning filter by default',0,'',''),(12609,'pytest','Clarify a possible confusion when using pytest_fixture_setup with fixture\nfunctions that return None. (issue #2698)','use pytest_fixture_setup with fixture functions',0,'',''),(12610,'pytest','Fix the wording of a sentence on doctest flags used in pytest. (issue #3076)','fix wording of sentence',0,'',''),(12611,'pytest','Fix the wording of a sentence on doctest flags used in pytest. (issue #3076)','use  in pytest',0,'',''),(12612,'pytest','Added note that calling pytest.main multiple times from the same process is\nnot recommended because of import caching. (issue #3143)','call pytest.main multiple times from same process',0,'',''),(12613,'pytest','Show a simple and easy error when keyword expressions trigger a syntax error\n(for example, \"-k foo and import\" will show an error that you can not use\nthe import keyword in expressions). (issue #2953)','show simple easy error',0,'',''),(12614,'pytest','Change parametrized automatic test id generation to use the __name__\nattribute of functions instead of the fallback argument name plus counter.\n(issue #2976)','use __name__ attribute of functions',0,'',''),(12615,'pytest','Replace py.std with stdlib imports. (issue #3067)','replace py.std with stdlib imports',0,'',''),(12616,'pytest','pytester: ignore files used to obtain current user metadata in the fd leak\ndetector. (issue #2784)','obtain current user metadata in fd leak detector',0,'',''),(12617,'pytest','Fix memory leak where objects returned by fixtures were never destructed\nby the garbage collector. (issue #2981)','return fix memory leak by fixtures',0,'',''),(12618,'pytest','Fix conversion of pyargs to filename to not convert symlinks on Python 2. (issue #2985)','fix conversion of pyargs',0,'',''),(12619,'pytest','PYTEST_DONT_REWRITE is now checked for plugins too rather than only for\ntest modules. (issue #2995)','check PYTEST_DONT_REWRITE for plugins',0,'',''),(12620,'pytest','PYTEST_DONT_REWRITE is now checked for plugins too rather than only for\ntest modules. (issue #2995)','check PYTEST_DONT_REWRITE for test modules',0,'',''),(12621,'pytest','Clean up code by replacing imports and references of _ast to ast.\n(issue #3018)','replace imports of _ ast',0,'',''),(12622,'pytest','Clean up code by replacing imports and references of _ast to ast.\n(issue #3018)','replace imports to ast',0,'',''),(12623,'pytest','Clean up code by replacing imports and references of _ast to ast.\n(issue #3018)','replace references of _ ast',0,'',''),(12624,'pytest','Clean up code by replacing imports and references of _ast to ast.\n(issue #3018)','replace references to ast',0,'',''),(12625,'pytest','Fix regression with warnings that contained non-strings in their arguments in\nPython 2. (issue #2956)','fix regression with warnings',0,'',''),(12626,'pytest','Always escape null bytes when setting PYTEST_CURRENT_TEST. (issue #2957)','set PYTEST_CURRENT_TEST',0,'',''),(12627,'pytest','Fix ZeroDivisionError when using the testmon plugin when no tests\nwere actually collected. (issue #2971)','fix ZeroDivisionError',0,'',''),(12628,'pytest','Fix ZeroDivisionError when using the testmon plugin when no tests\nwere actually collected. (issue #2971)','use testmon plugin',0,'',''),(12629,'pytest','Bring back TerminalReporter.writer as an alias to\nTerminalReporter._tw. This alias was removed by accident in the 3.3.0\nrelease. (issue #2984)','remove alias',0,'',''),(12630,'pytest','Fix broken link to plugin pytest-localserver. (issue #2963)','fix broken link to plugin pytest-localserver',0,'',''),(12631,'pytest','Update github “bugs” link in CONTRIBUTING.rst (issue #2949)','link  in CONTRIBUTING.rst',0,'',''),(12632,'pytest','pytest no longer supports Python 2.6 and 3.3. Those Python versions\nare EOL for some time now and incur maintenance and compatibility costs on\nthe pytest core team, and following up with the rest of the community we\ndecided that they will no longer be supported starting on this version. Users\nwhich still require those versions should pin pytest to <3.3. (issue #2812)','support Python',0,'',''),(12633,'pytest','Remove internal _preloadplugins() function. This removal is part of the\npytest_namespace() hook deprecation. (issue #2636)','remove internal _ preloadplugins() function',0,'',''),(12634,'pytest','Internally change CallSpec2 to have a list of marks instead of a broken\nmapping of keywords. This removes the keywords attribute of the internal\nCallSpec2 class. (issue #2672)','change CallSpec2',0,'',''),(12635,'pytest','Internally change CallSpec2 to have a list of marks instead of a broken\nmapping of keywords. This removes the keywords attribute of the internal\nCallSpec2 class. (issue #2672)','remove keywords attribute of internal CallSpec2 class',0,'',''),(12636,'pytest','Remove the internal multi-typed attribute Node._evalskip and replace it\nwith the boolean Node._skipped_by_mark. (issue #2767)','remove internal multi-typed attribute Node._evalskip',0,'',''),(12637,'pytest','Remove the internal multi-typed attribute Node._evalskip and replace it\nwith the boolean Node._skipped_by_mark. (issue #2767)','replace  with boolean Node._skipped_by_mark',0,'',''),(12638,'pytest','The params list passed to pytest.fixture is now for\nall effects considered immutable and frozen at the moment of the pytest.fixture\ncall. Previously the list could be changed before the first invocation of the fixture\nallowing for a form of dynamic parametrization (for example, updated from command-line options),\nbut this was an unwanted implementation detail which complicated the internals and prevented\nsome internal cleanup. See issue issue #2959\nfor details and a recommended workaround.','pass  to pytest.fixture',0,'',''),(12639,'pytest','The params list passed to pytest.fixture is now for\nall effects considered immutable and frozen at the moment of the pytest.fixture\ncall. Previously the list could be changed before the first invocation of the fixture\nallowing for a form of dynamic parametrization (for example, updated from command-line options),\nbut this was an unwanted implementation detail which complicated the internals and prevented\nsome internal cleanup. See issue issue #2959\nfor details and a recommended workaround.','prevent internal cleanup',0,'',''),(12640,'pytest','The params list passed to pytest.fixture is now for\nall effects considered immutable and frozen at the moment of the pytest.fixture\ncall. Previously the list could be changed before the first invocation of the fixture\nallowing for a form of dynamic parametrization (for example, updated from command-line options),\nbut this was an unwanted implementation detail which complicated the internals and prevented\nsome internal cleanup. See issue issue #2959\nfor details and a recommended workaround.','prevent unwanted implementation detail',0,'',''),(12641,'pytest','The params list passed to pytest.fixture is now for\nall effects considered immutable and frozen at the moment of the pytest.fixture\ncall. Previously the list could be changed before the first invocation of the fixture\nallowing for a form of dynamic parametrization (for example, updated from command-line options),\nbut this was an unwanted implementation detail which complicated the internals and prevented\nsome internal cleanup. See issue issue #2959\nfor details and a recommended workaround.','change list before first invocation',0,'',''),(12642,'pytest','pytest_fixture_post_finalizer hook can now receive a request\nargument. (issue #2124)','receive request argument',0,'',''),(12643,'pytest','Replace the old introspection code in compat.py that determines the available\narguments of fixtures with inspect.signature on Python 3 and\nfuncsigs.signature on Python 2. This should respect __signature__\ndeclarations on functions. (issue #2267)','replace old introspection code in compat.py',0,'',''),(12644,'pytest','Replace the old introspection code in compat.py that determines the available\narguments of fixtures with inspect.signature on Python 3 and\nfuncsigs.signature on Python 2. This should respect __signature__\ndeclarations on functions. (issue #2267)','determine available arguments in compat.py',0,'',''),(12645,'pytest','Replace the old introspection code in compat.py that determines the available\narguments of fixtures with inspect.signature on Python 3 and\nfuncsigs.signature on Python 2. This should respect __signature__\ndeclarations on functions. (issue #2267)','determine available arguments of fixtures',0,'',''),(12646,'pytest','Replace the old introspection code in compat.py that determines the available\narguments of fixtures with inspect.signature on Python 3 and\nfuncsigs.signature on Python 2. This should respect __signature__\ndeclarations on functions. (issue #2267)','determine old introspection code in compat.py',0,'',''),(12647,'pytest','Replace the old introspection code in compat.py that determines the available\narguments of fixtures with inspect.signature on Python 3 and\nfuncsigs.signature on Python 2. This should respect __signature__\ndeclarations on functions. (issue #2267)','determine old introspection code of fixtures',0,'',''),(12648,'pytest','Report tests with global pytestmark variable only once. (issue #2549)','test  with global pytestmark variable',0,'',''),(12649,'pytest','Now pytest displays the total progress percentage while running tests. The\nprevious output style can be set by configuring the console_output_style\nsetting to classic. (issue #2657)','display total progress percentage while running',0,'',''),(12650,'pytest','Now pytest displays the total progress percentage while running tests. The\nprevious output style can be set by configuring the console_output_style\nsetting to classic. (issue #2657)','run tests',0,'',''),(12651,'pytest','Now pytest displays the total progress percentage while running tests. The\nprevious output style can be set by configuring the console_output_style\nsetting to classic. (issue #2657)','configure console_output_style setting to classic',0,'',''),(12652,'pytest','Now pytest displays the total progress percentage while running tests. The\nprevious output style can be set by configuring the console_output_style\nsetting to classic. (issue #2657)','set previous output style',0,'',''),(12653,'pytest','Match warns signature to raises by adding match keyword. (issue #2708)','add match keyword',0,'',''),(12654,'pytest','pytest now captures and displays output from the standard logging module.\nThe user can control the logging level to be captured by specifying options\nin pytest.ini, the command line and also during individual tests using\nmarkers. Also, a caplog fixture is available that enables users to test\nthe captured log during specific tests (similar to capsys for example).\nFor more information, please see the logging docs. This feature was\nintroduced by merging the popular pytest-catchlog plugin, thanks to @thisch.\nBe advised that during the merging the\nbackward compatibility interface with the defunct pytest-capturelog has\nbeen dropped. (issue #2794)','specify options in pytest.ini',0,'',''),(12655,'pytest','pytest now captures and displays output from the standard logging module.\nThe user can control the logging level to be captured by specifying options\nin pytest.ini, the command line and also during individual tests using\nmarkers. Also, a caplog fixture is available that enables users to test\nthe captured log during specific tests (similar to capsys for example).\nFor more information, please see the logging docs. This feature was\nintroduced by merging the popular pytest-catchlog plugin, thanks to @thisch.\nBe advised that during the merging the\nbackward compatibility interface with the defunct pytest-capturelog has\nbeen dropped. (issue #2794)','use markers',0,'',''),(12656,'pytest','pytest now captures and displays output from the standard logging module.\nThe user can control the logging level to be captured by specifying options\nin pytest.ini, the command line and also during individual tests using\nmarkers. Also, a caplog fixture is available that enables users to test\nthe captured log during specific tests (similar to capsys for example).\nFor more information, please see the logging docs. This feature was\nintroduced by merging the popular pytest-catchlog plugin, thanks to @thisch.\nBe advised that during the merging the\nbackward compatibility interface with the defunct pytest-capturelog has\nbeen dropped. (issue #2794)','test captured log during specific tests',0,'',''),(12657,'pytest','pytest now captures and displays output from the standard logging module.\nThe user can control the logging level to be captured by specifying options\nin pytest.ini, the command line and also during individual tests using\nmarkers. Also, a caplog fixture is available that enables users to test\nthe captured log during specific tests (similar to capsys for example).\nFor more information, please see the logging docs. This feature was\nintroduced by merging the popular pytest-catchlog plugin, thanks to @thisch.\nBe advised that during the merging the\nbackward compatibility interface with the defunct pytest-capturelog has\nbeen dropped. (issue #2794)','introduce feature',0,'',''),(12658,'pytest','Add allow_module_level kwarg to pytest.skip(), enabling to skip the\nwhole module. (issue #2808)','add allow_module_level',0,'',''),(12659,'pytest','Add allow_module_level kwarg to pytest.skip(), enabling to skip the\nwhole module. (issue #2808)','skip whole module',0,'',''),(12660,'pytest','Return stdout/stderr capture results as a namedtuple, so out and\nerr can be accessed by attribute. (issue #2879)','access return stdout/stderr capture results as namedtuple out err',0,'',''),(12661,'pytest','Add capfdbinary, a version of capfd which returns bytes from\nreadouterr(). (issue #2923)','return capfd',0,'',''),(12662,'pytest','Add capsysbinary a version of capsys which returns bytes from\nreadouterr(). (issue #2934)','add version of capsys',0,'',''),(12663,'pytest','Add capsysbinary a version of capsys which returns bytes from\nreadouterr(). (issue #2934)','return bytes from readouterr()',0,'',''),(12664,'pytest','Add capsysbinary a version of capsys which returns bytes from\nreadouterr(). (issue #2934)','return capsys from readouterr()',0,'',''),(12665,'pytest','Implement feature to skip setup.py files when run with\n--doctest-modules. (issue #502)','skip setup.py files',0,'',''),(12666,'pytest','pytest_fixture_setup and pytest_fixture_post_finalizer hooks are now\ncalled for all conftest.py files. (issue #2124)','call pytest_fixture_setup pytest_fixture_post_finalizer hooks for conftest.py files',0,'',''),(12667,'pytest','If an exception happens while loading a plugin, pytest no longer hides the\noriginal traceback. In Python 2 it will show the original traceback with a new\nmessage that explains in which plugin. In Python 3 it will show 2 canonized\nexceptions, the original exception while loading the plugin in addition to an\nexception that pytest throws about loading a plugin. (issue #2491)','load plugin',0,'',''),(12668,'pytest','If an exception happens while loading a plugin, pytest no longer hides the\noriginal traceback. In Python 2 it will show the original traceback with a new\nmessage that explains in which plugin. In Python 3 it will show 2 canonized\nexceptions, the original exception while loading the plugin in addition to an\nexception that pytest throws about loading a plugin. (issue #2491)','hide original traceback',0,'',''),(12669,'pytest','If an exception happens while loading a plugin, pytest no longer hides the\noriginal traceback. In Python 2 it will show the original traceback with a new\nmessage that explains in which plugin. In Python 3 it will show 2 canonized\nexceptions, the original exception while loading the plugin in addition to an\nexception that pytest throws about loading a plugin. (issue #2491)','show original traceback with new message',0,'',''),(12670,'pytest','If an exception happens while loading a plugin, pytest no longer hides the\noriginal traceback. In Python 2 it will show the original traceback with a new\nmessage that explains in which plugin. In Python 3 it will show 2 canonized\nexceptions, the original exception while loading the plugin in addition to an\nexception that pytest throws about loading a plugin. (issue #2491)','show original traceback in Python',0,'',''),(12671,'pytest','If an exception happens while loading a plugin, pytest no longer hides the\noriginal traceback. In Python 2 it will show the original traceback with a new\nmessage that explains in which plugin. In Python 3 it will show 2 canonized\nexceptions, the original exception while loading the plugin in addition to an\nexception that pytest throws about loading a plugin. (issue #2491)','show canonized exceptions in Python',0,'',''),(12672,'pytest','If an exception happens while loading a plugin, pytest no longer hides the\noriginal traceback. In Python 2 it will show the original traceback with a new\nmessage that explains in which plugin. In Python 3 it will show 2 canonized\nexceptions, the original exception while loading the plugin in addition to an\nexception that pytest throws about loading a plugin. (issue #2491)','load plugin to exception',0,'',''),(12673,'pytest','If an exception happens while loading a plugin, pytest no longer hides the\noriginal traceback. In Python 2 it will show the original traceback with a new\nmessage that explains in which plugin. In Python 3 it will show 2 canonized\nexceptions, the original exception while loading the plugin in addition to an\nexception that pytest throws about loading a plugin. (issue #2491)','load plugin',0,'',''),(12674,'pytest','If an exception happens while loading a plugin, pytest no longer hides the\noriginal traceback. In Python 2 it will show the original traceback with a new\nmessage that explains in which plugin. In Python 3 it will show 2 canonized\nexceptions, the original exception while loading the plugin in addition to an\nexception that pytest throws about loading a plugin. (issue #2491)','throw  about loading',0,'',''),(12675,'pytest','capsys and capfd can now be used by other fixtures. (issue #2709)','use capsys',0,'',''),(12676,'pytest','capsys and capfd can now be used by other fixtures. (issue #2709)','use capfd',0,'',''),(12677,'pytest','Internal pytester plugin properly encodes bytes arguments to\nutf-8. (issue #2738)','encode bytes arguments',0,'',''),(12678,'pytest','testdir now uses use the same method used by tmpdir to create its\ntemporary directory. This changes the final structure of the testdir\ndirectory slightly, but should not affect usage in normal scenarios and\navoids a number of potential problems. (issue #2751)','use same method',0,'',''),(12679,'pytest','testdir now uses use the same method used by tmpdir to create its\ntemporary directory. This changes the final structure of the testdir\ndirectory slightly, but should not affect usage in normal scenarios and\navoids a number of potential problems. (issue #2751)','create temporary directory',0,'',''),(12680,'pytest','testdir now uses use the same method used by tmpdir to create its\ntemporary directory. This changes the final structure of the testdir\ndirectory slightly, but should not affect usage in normal scenarios and\navoids a number of potential problems. (issue #2751)','change final structure of testdir directory',0,'',''),(12681,'pytest','pytest no longer complains about warnings with unicode messages being\nnon-ascii compatible even for ascii-compatible messages. As a result of this,\nwarnings with unicode messages are converted first to an ascii representation\nfor safety. (issue #2809)','convert warnings with unicode messages',0,'',''),(12682,'pytest','pytest no longer complains about warnings with unicode messages being\nnon-ascii compatible even for ascii-compatible messages. As a result of this,\nwarnings with unicode messages are converted first to an ascii representation\nfor safety. (issue #2809)','convert warnings as result',0,'',''),(12683,'pytest','pytest no longer complains about warnings with unicode messages being\nnon-ascii compatible even for ascii-compatible messages. As a result of this,\nwarnings with unicode messages are converted first to an ascii representation\nfor safety. (issue #2809)','convert warnings to ascii representation',0,'',''),(12684,'pytest','Change return value of pytest command when --maxfail is reached from\n2 (interrupted) to 1 (failed). (issue #2845)','reach maxfail for change return value',0,'',''),(12685,'pytest','Fix issue in assertion rewriting which could lead it to rewrite modules which\nshould not be rewritten. (issue #2939)','fix issue in assertion rewriting',0,'',''),(12686,'pytest','Handle marks without description in pytest.ini. (issue #2942)','mark  without description',0,'',''),(12687,'pytest','Internal refactor: simplify ascii string escaping by using the\nbackslashreplace error handler in newer Python 3 versions. (issue #2734)','use backslashreplace error handler in newer Python',0,'',''),(12688,'pytest','Remove unnecessary mark evaluator in unittest plugin (issue #2767)','remove unnecessary mark evaluator in unittest plugin',0,'',''),(12689,'pytest','Internal move of the parameterset extraction to a more maintainable place.\n(issue #2877)','move  of parameterset extraction',0,'',''),(12690,'pytest','Internal move of the parameterset extraction to a more maintainable place.\n(issue #2877)','move  to maintainable place',0,'',''),(12691,'pytest','Configure pytest to prevent pip from installing pytest in unsupported\nPython versions. (issue #2922)','prevent pip from installing',0,'',''),(12692,'pytest','Configure pytest to prevent pip from installing pytest in unsupported\nPython versions. (issue #2922)','install pytest in unsupported Python versions',0,'',''),(12693,'pytest','Remove py<1.5 restriction from pytest as this can cause version\nconflicts in some installations. (issue #2926)','remove restriction from pytest',0,'',''),(12694,'pytest','Fix the bug where running with --pyargs will result in items with\nempty parent.nodeid if run from a different root directory. (issue #2775)','fix bug',0,'',''),(12695,'pytest','Fix the bug where running with --pyargs will result in items with\nempty parent.nodeid if run from a different root directory. (issue #2775)','run  from different root directory',0,'',''),(12696,'pytest','Fix issue with @pytest.parametrize if argnames was specified as keyword arguments.\n(issue #2819)','fix issue with',0,'',''),(12697,'pytest','Fix issue with @pytest.parametrize if argnames was specified as keyword arguments.\n(issue #2819)','specify argnames as keyword arguments',0,'',''),(12698,'pytest','Strip whitespace from marker names when reading them from INI config. (issue #2856)','read  from INI config',0,'',''),(12699,'pytest','Show full context of doctest source in the pytest output, if the line number of\nfailed example in the docstring is < 9. (issue #2882)','show full context of doctest source',0,'',''),(12700,'pytest','Match fixture paths against actual path segments in order to avoid matching folders which share a prefix.\n(issue #2836)','share prefix',0,'',''),(12701,'pytest','Match fixture paths against actual path segments in order to avoid matching folders which share a prefix.\n(issue #2836)','share matching folders',0,'',''),(12702,'pytest','Introduce a dedicated section about conftest.py. (issue #1505)','introduce dedicated section about conftest.py.',0,'',''),(12703,'pytest','List python 3.6 in the documented supported versions in the getting started\ndocument. (issue #2903)','support versions',0,'',''),(12704,'pytest','List python 3.6 in the documented supported versions in the getting started\ndocument. (issue #2903)','support list python',0,'',''),(12705,'pytest','Add documentation about the python -m pytest invocation adding the\ncurrent directory to sys.path. (issue #911)','add documentation about python',0,'',''),(12706,'pytest','Add documentation about the python -m pytest invocation adding the\ncurrent directory to sys.path. (issue #911)','add current directory to sys.path.',0,'',''),(12707,'pytest','Fix crash in tab completion when no prefix is given. (issue #2748)','fix crash in tab completion',0,'',''),(12708,'pytest','In help text of -k option, add example of using not to not select\ncertain tests whose names match the provided expression. (issue #1442)','add  in text',0,'',''),(12709,'pytest','In help text of -k option, add example of using not to not select\ncertain tests whose names match the provided expression. (issue #1442)','match provided expression',0,'',''),(12710,'pytest','In help text of -k option, add example of using not to not select\ncertain tests whose names match the provided expression. (issue #1442)','match certain tests',0,'',''),(12711,'pytest','Add note in parametrize.rst about calling metafunc.parametrize\nmultiple times. (issue #1548)','add note in parametrize.rst',0,'',''),(12712,'pytest','Add note in parametrize.rst about calling metafunc.parametrize\nmultiple times. (issue #1548)','add note about calling',0,'',''),(12713,'pytest','Add note in parametrize.rst about calling metafunc.parametrize\nmultiple times. (issue #1548)','call metafunc.parametrize',0,'',''),(12714,'pytest','Set xfail_strict=True in pytest’s own test suite to catch expected\nfailures as soon as they start to pass. (issue #2722)','catch expected failures',0,'',''),(12715,'pytest','Fix typo in example of passing a callable to markers (in example/markers.rst)\n(issue #2765)','fix typo',0,'',''),(12716,'pytest','Fix typo in example of passing a callable to markers (in example/markers.rst)\n(issue #2765)','pass callable markers',0,'',''),(12717,'pytest','Calling the deprecated request.getfuncargvalue() now shows the source of\nthe call. (issue #2681)','call deprecated request.getfuncargvalue()',0,'',''),(12718,'pytest','Calling the deprecated request.getfuncargvalue() now shows the source of\nthe call. (issue #2681)','show source of call',0,'',''),(12719,'pytest','Allow tests declared as @staticmethod to use fixtures. (issue #2699)','use fixtures',0,'',''),(12720,'pytest','Fixed edge-case during collection: attributes which raised pytest.fail\nwhen accessed would abort the entire collection. (issue #2707)','raise pytest.fail',0,'',''),(12721,'pytest','Fixed edge-case during collection: attributes which raised pytest.fail\nwhen accessed would abort the entire collection. (issue #2707)','raise attributes',0,'',''),(12722,'pytest','Fix ReprFuncArgs with mixed unicode and UTF-8 args. (issue #2731)','fix ReprFuncArgs with mixed unicode',0,'',''),(12723,'pytest','Fix ReprFuncArgs with mixed unicode and UTF-8 args. (issue #2731)','fix ReprFuncArgs with UTF-8 args',0,'',''),(12724,'pytest','In examples on working with custom markers, add examples demonstrating the\nusage of pytest.mark.MARKER_NAME.with_args in comparison with\npytest.mark.MARKER_NAME.__call__ (issue #2604)','add examples in examples',0,'',''),(12725,'pytest','In one of the simple examples, use pytest_collection_modifyitems() to skip\ntests based on a command-line option, allowing its sharing while preventing a\nuser error when accessing pytest.config before the argument parsing.\n(issue #2653)','use pytest_collection_modifyitems()',0,'',''),(12726,'pytest','In one of the simple examples, use pytest_collection_modifyitems() to skip\ntests based on a command-line option, allowing its sharing while preventing a\nuser error when accessing pytest.config before the argument parsing.\n(issue #2653)','skip tests',0,'',''),(12727,'pytest','In one of the simple examples, use pytest_collection_modifyitems() to skip\ntests based on a command-line option, allowing its sharing while preventing a\nuser error when accessing pytest.config before the argument parsing.\n(issue #2653)','prevent user error',0,'',''),(12728,'pytest','In one of the simple examples, use pytest_collection_modifyitems() to skip\ntests based on a command-line option, allowing its sharing while preventing a\nuser error when accessing pytest.config before the argument parsing.\n(issue #2653)','access pytest.config before argument parsing',0,'',''),(12729,'pytest','Correctly consider / as the file separator to automatically mark plugin\nfiles for rewrite on Windows. (issue #2591)','mark plugin files for rewrite',0,'',''),(12730,'pytest','Correctly consider / as the file separator to automatically mark plugin\nfiles for rewrite on Windows. (issue #2591)','mark plugin files on windows',0,'',''),(12731,'pytest','Properly escape test names when setting PYTEST_CURRENT_TEST environment\nvariable. (issue #2644)','set PYTEST_CURRENT_TEST environment variable',0,'',''),(12732,'pytest','Fix error on Windows and Python 3.6+ when sys.stdout has been replaced\nwith a stream-like object which does not implement the full io module\nbuffer protocol. In particular this affects pytest-xdist users on the\naforementioned platform. (issue #2666)','replace sys.stdout with stream-like object',0,'',''),(12733,'pytest','pytest.approx no longer supports >, >=, < and <=\noperators to avoid surprising/inconsistent behavior. See the approx() docs for more\ninformation. (issue #2003)','support &gt; &gt; = operators',0,'',''),(12734,'pytest','All old-style specific behavior in current classes in the pytest’s API is\nconsidered deprecated at this point and will be removed in a future release.\nThis affects Python 2 users only and in rare situations. (issue #2147)','remove old-style specific behavior in future release',0,'',''),(12735,'pytest','All old-style specific behavior in current classes in the pytest’s API is\nconsidered deprecated at this point and will be removed in a future release.\nThis affects Python 2 users only and in rare situations. (issue #2147)','remove old-style specific behavior in current classes',0,'',''),(12736,'pytest','A deprecation warning is now raised when using marks for parameters\nin pytest.mark.parametrize. Use pytest.param to apply marks to\nparameters instead. (issue #2427)','use marks for parameters',0,'',''),(12737,'pytest','A deprecation warning is now raised when using marks for parameters\nin pytest.mark.parametrize. Use pytest.param to apply marks to\nparameters instead. (issue #2427)','raise deprecation warning',0,'',''),(12738,'pytest','A deprecation warning is now raised when using marks for parameters\nin pytest.mark.parametrize. Use pytest.param to apply marks to\nparameters instead. (issue #2427)','use pytest.param',0,'',''),(12739,'pytest','A deprecation warning is now raised when using marks for parameters\nin pytest.mark.parametrize. Use pytest.param to apply marks to\nparameters instead. (issue #2427)','apply marks to parameters',0,'',''),(12740,'pytest','Add support for numpy arrays (and dicts) to approx. (issue #1994)','add support for numpy arrays',0,'',''),(12741,'pytest','Now test function objects have a pytestmark attribute containing a list\nof marks applied directly to the test function, as opposed to marks inherited\nfrom parent classes or modules. (issue #2516)','apply  to test function',0,'',''),(12742,'pytest','Now test function objects have a pytestmark attribute containing a list\nof marks applied directly to the test function, as opposed to marks inherited\nfrom parent classes or modules. (issue #2516)','inherit  from parent classes',0,'',''),(12743,'pytest','Now test function objects have a pytestmark attribute containing a list\nof marks applied directly to the test function, as opposed to marks inherited\nfrom parent classes or modules. (issue #2516)','inherit  from modules',0,'',''),(12744,'pytest','Collection ignores local virtualenvs by default; --collect-in-virtualenv\noverrides this behavior. (issue #2518)','ignore local virtualenvs by default',0,'',''),(12745,'pytest','Collection ignores local virtualenvs by default; --collect-in-virtualenv\noverrides this behavior. (issue #2518)','override behavior',0,'',''),(12746,'pytest','Introduce mark.with_args in order to allow passing functions/classes as\nsole argument to marks. (issue #2540)','introduce mark.with_args',0,'',''),(12747,'pytest','Introduce mark.with_args in order to allow passing functions/classes as\nsole argument to marks. (issue #2540)','pass functions/classes as sole argument',0,'',''),(12748,'pytest','Introduce mark.with_args in order to allow passing functions/classes as\nsole argument to marks. (issue #2540)','pass functions/classes to marks',0,'',''),(12749,'pytest','New cache_dir ini option: sets the directory where the contents of the\ncache plugin are stored. Directory may be relative or absolute path: if relative path, then\ndirectory is created relative to rootdir, otherwise it is used as is.\nAdditionally path may contain environment variables which are expanded during\nruntime. (issue #2543)','set directory',0,'',''),(12750,'pytest','New cache_dir ini option: sets the directory where the contents of the\ncache plugin are stored. Directory may be relative or absolute path: if relative path, then\ndirectory is created relative to rootdir, otherwise it is used as is.\nAdditionally path may contain environment variables which are expanded during\nruntime. (issue #2543)','store contents of cache plugin',0,'',''),(12751,'pytest','New cache_dir ini option: sets the directory where the contents of the\ncache plugin are stored. Directory may be relative or absolute path: if relative path, then\ndirectory is created relative to rootdir, otherwise it is used as is.\nAdditionally path may contain environment variables which are expanded during\nruntime. (issue #2543)','store directory of cache plugin',0,'',''),(12752,'pytest','New cache_dir ini option: sets the directory where the contents of the\ncache plugin are stored. Directory may be relative or absolute path: if relative path, then\ndirectory is created relative to rootdir, otherwise it is used as is.\nAdditionally path may contain environment variables which are expanded during\nruntime. (issue #2543)','create relative path to rootdir',0,'',''),(12753,'pytest','New cache_dir ini option: sets the directory where the contents of the\ncache plugin are stored. Directory may be relative or absolute path: if relative path, then\ndirectory is created relative to rootdir, otherwise it is used as is.\nAdditionally path may contain environment variables which are expanded during\nruntime. (issue #2543)','expand environment variables during runtime',0,'',''),(12754,'pytest','Introduce the PYTEST_CURRENT_TEST environment variable that is set with\nthe nodeid and stage (setup, call and teardown) of the test\nbeing currently executed. See the documentation\nfor more info. (issue #2583)','introduce PYTEST_CURRENT_TEST environment variable',0,'',''),(12755,'pytest','Introduce the PYTEST_CURRENT_TEST environment variable that is set with\nthe nodeid and stage (setup, call and teardown) of the test\nbeing currently executed. See the documentation\nfor more info. (issue #2583)','set PYTEST_CURRENT_TEST environment variable with nodeid',0,'',''),(12756,'pytest','Introduce the PYTEST_CURRENT_TEST environment variable that is set with\nthe nodeid and stage (setup, call and teardown) of the test\nbeing currently executed. See the documentation\nfor more info. (issue #2583)','set PYTEST_CURRENT_TEST environment variable with stage',0,'',''),(12757,'pytest','Introduced @pytest.mark.filterwarnings mark which allows overwriting the\nwarnings filter on a per test, class or module level. See the docs\nfor more information. (issue #2598)','overwrite warnings filter on module level',0,'',''),(12758,'pytest','Introduced @pytest.mark.filterwarnings mark which allows overwriting the\nwarnings filter on a per test, class or module level. See the docs\nfor more information. (issue #2598)','overwrite warnings filter on per test',0,'',''),(12759,'pytest','Introduced @pytest.mark.filterwarnings mark which allows overwriting the\nwarnings filter on a per test, class or module level. See the docs\nfor more information. (issue #2598)','overwrite warnings filter on class',0,'',''),(12760,'pytest','--last-failed now remembers forever when a test has failed and only\nforgets it if it passes again. This makes it easy to fix a test suite by\nselectively running files and fixing tests incrementally. (issue #2621)','fix test suite by running',0,'',''),(12761,'pytest','--last-failed now remembers forever when a test has failed and only\nforgets it if it passes again. This makes it easy to fix a test suite by\nselectively running files and fixing tests incrementally. (issue #2621)','fix test suite by fixing',0,'',''),(12762,'pytest','--last-failed now remembers forever when a test has failed and only\nforgets it if it passes again. This makes it easy to fix a test suite by\nselectively running files and fixing tests incrementally. (issue #2621)','run files',0,'',''),(12763,'pytest','--last-failed now remembers forever when a test has failed and only\nforgets it if it passes again. This makes it easy to fix a test suite by\nselectively running files and fixing tests incrementally. (issue #2621)','fix tests',0,'',''),(12764,'pytest','New pytest_report_collectionfinish hook which allows plugins to add\nmessages to the terminal reporting after collection has been finished\nsuccessfully. (issue #2622)','add messages to terminal',0,'',''),(12765,'pytest','Added support for PEP 415\'s\nException.__suppress_context__. Now if a raise exception from None is\ncaught by pytest, pytest will no longer chain the context in the test report.\nThe behavior now matches Python’s traceback behavior. (issue #2631)','support  for Exception.__suppress_context__',0,'',''),(12766,'pytest','Added support for PEP 415\'s\nException.__suppress_context__. Now if a raise exception from None is\ncaught by pytest, pytest will no longer chain the context in the test report.\nThe behavior now matches Python’s traceback behavior. (issue #2631)','catch raise exception from none',0,'',''),(12767,'pytest','Added support for PEP 415\'s\nException.__suppress_context__. Now if a raise exception from None is\ncaught by pytest, pytest will no longer chain the context in the test report.\nThe behavior now matches Python’s traceback behavior. (issue #2631)','match traceback behavior',0,'',''),(12768,'pytest','Fix terminal color changing to black on Windows if colorama is imported\nin a conftest.py file. (issue #2510)','fix terminal color',0,'',''),(12769,'pytest','Fix terminal color changing to black on Windows if colorama is imported\nin a conftest.py file. (issue #2510)','import colorama in conftest.py file',0,'',''),(12770,'pytest','Fix line number when reporting summary of skipped tests. (issue #2548)','fix line number',0,'',''),(12771,'pytest','doctests line numbers are now reported correctly, fixing pytest-sugar#122. (issue #2610)','fix pytest-sugar',0,'',''),(12772,'pytest','Fix non-determinism in order of fixture collection. Adds new dependency\n(ordereddict) for Python 2.6. (issue #920)','fix non-determinism',0,'',''),(12773,'pytest','Fix non-determinism in order of fixture collection. Adds new dependency\n(ordereddict) for Python 2.6. (issue #920)','add new dependency for Python',0,'',''),(12774,'pytest','Extend documentation for testing plugin code with the pytester plugin.\n(issue #971)','test plugin code with pytester plugin',0,'',''),(12775,'pytest','Renamed the utility function _pytest.compat._escape_strings to\n_ascii_escaped to better communicate the function’s purpose. (issue #2533)','rename utility function _pytest.compat._escape_strings to _',0,'',''),(12776,'pytest','Ensure final collected line doesn’t include artifacts of previous write.\n(issue #2571)','include artifacts of previous write',0,'',''),(12777,'pytest','Fixed all flake8 errors and warnings. (issue #2581)','fix flake8 errors',0,'',''),(12778,'pytest','Fixed all flake8 errors and warnings. (issue #2581)','fix warnings',0,'',''),(12779,'pytest','Added fix-lint tox environment to run automatic pep8 fixes on the code.\n(issue #2582)','add fix-lint tox environment',0,'',''),(12780,'pytest','Added fix-lint tox environment to run automatic pep8 fixes on the code.\n(issue #2582)','run automatic pep8 fixes on code',0,'',''),(12781,'pytest','Show multiple issue links in CHANGELOG entries. (issue #2620)','show multiple issue links in CHANGELOG entries',0,'',''),(12782,'pytest','Fix decode error in Python 2 for doctests in docstrings. (issue #2434)','fix decode error in Python',0,'',''),(12783,'pytest','Exceptions raised during teardown by finalizers are now suppressed until all\nfinalizers are called, with the initial exception reraised. (issue #2440)','raise  during teardown',0,'',''),(12784,'pytest','Exceptions raised during teardown by finalizers are now suppressed until all\nfinalizers are called, with the initial exception reraised. (issue #2440)','call finalizers with initial exception',0,'',''),(12785,'pytest','Fix incorrect “collected items” report when specifying tests on the command-\nline. (issue #2464)','specify tests on command line',0,'',''),(12786,'pytest','deprecated_call in context-manager form now captures deprecation warnings\neven if the same warning has already been raised. Also, deprecated_call\nwill always produce the same error message (previously it would produce\ndifferent messages in context-manager vs. function-call mode). (issue #2469)','raise same warning',0,'',''),(12787,'pytest','deprecated_call in context-manager form now captures deprecation warnings\neven if the same warning has already been raised. Also, deprecated_call\nwill always produce the same error message (previously it would produce\ndifferent messages in context-manager vs. function-call mode). (issue #2469)','produce same error message',0,'',''),(12788,'pytest','Fix issue where paths collected by pytest could have triple leading /\ncharacters. (issue #2475)','fix issue',0,'',''),(12789,'pytest','Fix internal error when trying to detect the start of a recursive traceback.\n(issue #2486)','fix internal error',0,'',''),(12790,'pytest','Create invoke tasks for updating the vendored packages. (issue #2474)','update vendored packages',0,'',''),(12791,'pytest','Required options added via pytest_addoption will no longer prevent using\n–help without passing them. (#1999)','use â help without passing',0,'',''),(12792,'pytest','Required options added via pytest_addoption will no longer prevent using\n–help without passing them. (#1999)','add  via pytest_addoption',0,'',''),(12793,'pytest','Fix recursion error detection when frames in the traceback contain objects\nthat can’t be compared (like numpy arrays). (#2459)','fix recursion error detection',0,'',''),(12794,'pytest','Fix recursion error detection when frames in the traceback contain objects\nthat can’t be compared (like numpy arrays). (#2459)','compare objects',0,'',''),(12795,'pytest','Fix internal API links to pluggy objects. (#2331)','fix internal API links to pluggy objects',0,'',''),(12796,'pytest','pytest warning capture no longer overrides existing warning filters. The\nprevious behaviour would override all filters and caused regressions in test\nsuites which configure warning filters to match their needs. Note that as a\nside-effect of this is that DeprecationWarning and\nPendingDeprecationWarning are no longer shown by default. (#2430)','override existing warning filters',0,'',''),(12797,'pytest','pytest warning capture no longer overrides existing warning filters. The\nprevious behaviour would override all filters and caused regressions in test\nsuites which configure warning filters to match their needs. Note that as a\nside-effect of this is that DeprecationWarning and\nPendingDeprecationWarning are no longer shown by default. (#2430)','override filters',0,'',''),(12798,'pytest','pytest warning capture no longer overrides existing warning filters. The\nprevious behaviour would override all filters and caused regressions in test\nsuites which configure warning filters to match their needs. Note that as a\nside-effect of this is that DeprecationWarning and\nPendingDeprecationWarning are no longer shown by default. (#2430)','match needs',0,'',''),(12799,'pytest','pytest warning capture no longer overrides existing warning filters. The\nprevious behaviour would override all filters and caused regressions in test\nsuites which configure warning filters to match their needs. Note that as a\nside-effect of this is that DeprecationWarning and\nPendingDeprecationWarning are no longer shown by default. (#2430)','configure test suites',0,'',''),(12800,'pytest','pytest warning capture no longer overrides existing warning filters. The\nprevious behaviour would override all filters and caused regressions in test\nsuites which configure warning filters to match their needs. Note that as a\nside-effect of this is that DeprecationWarning and\nPendingDeprecationWarning are no longer shown by default. (#2430)','show DeprecationWarning',0,'',''),(12801,'pytest','pytest warning capture no longer overrides existing warning filters. The\nprevious behaviour would override all filters and caused regressions in test\nsuites which configure warning filters to match their needs. Note that as a\nside-effect of this is that DeprecationWarning and\nPendingDeprecationWarning are no longer shown by default. (#2430)','show PendingDeprecationWarning',0,'',''),(12802,'pytest','Fix issue with non-ascii contents in doctest text files. (#2434)','fix issue with non-ascii contents',0,'',''),(12803,'pytest','Fix encoding errors for unicode warnings in Python 2. (#2436)','fix encoding errors for unicode warnings',0,'',''),(12804,'pytest','The pytest-warnings plugin has been integrated into the core and now pytest automatically\ncaptures and displays warnings at the end of the test session.','integrate pytest-warnings plugin into core',0,'',''),(12805,'pytest','This feature may disrupt test suites which apply and treat warnings themselves, and can be\ndisabled in your pytest.ini:','apply warnings',1,'https://docs.pytest.org/en/7.2.x/changelog.html',''),(12806,'pytest','This feature may disrupt test suites which apply and treat warnings themselves, and can be\ndisabled in your pytest.ini:','apply test suites',1,'https://docs.pytest.org/en/7.2.x/changelog.html',''),(12807,'pytest','This feature may disrupt test suites which apply and treat warnings themselves, and can be\ndisabled in your pytest.ini:','disable test suites in pytest.ini',1,'https://docs.pytest.org/en/7.2.x/changelog.html',''),(12808,'pytest','Added junit_suite_name ini option to specify root  name for JUnit XML reports (issue #533).','specify root name for junit XML reports',0,'',''),(12809,'pytest','Added an ini option doctest_encoding to specify which encoding to use for doctest files.\nThanks @wheerd for the PR (pull request #2101).','add ini option doctest_encoding',0,'',''),(12810,'pytest','Added an ini option doctest_encoding to specify which encoding to use for doctest files.\nThanks @wheerd for the PR (pull request #2101).','use  for doctest files',0,'',''),(12811,'pytest','pytest.warns now checks for subclass relationship rather than\nclass equality. Thanks @lesteve for the PR (pull request #2166)','check  for subclass relationship',0,'',''),(12812,'pytest','pytest.warns now checks for subclass relationship rather than\nclass equality. Thanks @lesteve for the PR (pull request #2166)','check  for class equality',0,'',''),(12813,'pytest','pytest.raises now asserts that the error message matches a text or regex\nwith the match keyword argument. Thanks @Kriechi for the PR.','match text with match keyword argument',0,'',''),(12814,'pytest','pytest.raises now asserts that the error message matches a text or regex\nwith the match keyword argument. Thanks @Kriechi for the PR.','match regex with match keyword argument',0,'',''),(12815,'pytest','pytest.param can be used to declare test parameter sets with marks and test ids.\nThanks @RonnyPfannschmidt for the PR.','use pytest.param',0,'',''),(12816,'pytest','remove all internal uses of pytest_namespace hooks,\nthis is to prepare the removal of preloadconfig in pytest 4.0\nThanks to @RonnyPfannschmidt for the PR.','remove internal uses',0,'',''),(12817,'pytest','remove all internal uses of pytest_namespace hooks,\nthis is to prepare the removal of preloadconfig in pytest 4.0\nThanks to @RonnyPfannschmidt for the PR.','prepare removal of preloadconfig',0,'',''),(12818,'pytest','pytest now warns when a callable ids raises in a parametrized test. Thanks @fogo for the PR.','raise  in parametrized test',0,'',''),(12819,'pytest','It is now possible to skip test classes from being collected by setting a\n__test__ attribute to False in the class body (issue #2007). Thanks\nto @syre for the report and @lwm for the PR.','skip test classes',0,'',''),(12820,'pytest','Change junitxml.py to produce reports that comply with Junitxml schema.\nIf the same test fails with failure in call and then errors in teardown\nwe split testcase element into two, one containing the error and the other\nthe failure. (issue #2228) Thanks to @kkoukiou for the PR.','produce reports',0,'',''),(12821,'pytest','Change junitxml.py to produce reports that comply with Junitxml schema.\nIf the same test fails with failure in call and then errors in teardown\nwe split testcase element into two, one containing the error and the other\nthe failure. (issue #2228) Thanks to @kkoukiou for the PR.','split testcase element',0,'',''),(12822,'pytest','Remove common items from dict comparison output when verbosity=1. Also update\nthe truncation message to make it clearer that pytest truncates all\nassertion messages if verbosity < 2 (issue #1512).\nThanks @mattduck for the PR','remove common items from dict comparison output',0,'',''),(12823,'pytest','--pdbcls no longer implies --pdb. This makes it possible to use\naddopts=--pdbcls=module.SomeClass on pytest.ini. Thanks @davidszotten for\nthe PR (pull request #1952).','use addopts = on pytest.ini',0,'',''),(12824,'pytest','fix issue #2013: turn RecordedWarning into namedtuple,\nto give it a comprehensible repr while preventing unwarranted modification.','prevent unwarranted modification',0,'',''),(12825,'pytest','Hooks are now verified after collection is complete, rather than right after loading installed plugins. This\nmakes it easy to write hooks for plugins which will be loaded during collection, for example using the\npytest_plugins special variable (issue #1821).\nThanks @nicoddemus for the PR.','load installed plugins',0,'',''),(12826,'pytest','Hooks are now verified after collection is complete, rather than right after loading installed plugins. This\nmakes it easy to write hooks for plugins which will be loaded during collection, for example using the\npytest_plugins special variable (issue #1821).\nThanks @nicoddemus for the PR.','write hooks for plugins',0,'',''),(12827,'pytest','Hooks are now verified after collection is complete, rather than right after loading installed plugins. This\nmakes it easy to write hooks for plugins which will be loaded during collection, for example using the\npytest_plugins special variable (issue #1821).\nThanks @nicoddemus for the PR.','use pytest_plugins special variable',0,'',''),(12828,'pytest','Hooks are now verified after collection is complete, rather than right after loading installed plugins. This\nmakes it easy to write hooks for plugins which will be loaded during collection, for example using the\npytest_plugins special variable (issue #1821).\nThanks @nicoddemus for the PR.','load plugins during collection',0,'',''),(12829,'pytest','fix issue #2308: When using both --lf and --ff, only the last failed tests are run.\nThanks @ojii for the PR.','run fix issue',0,'',''),(12830,'pytest','Replace minor/patch level version numbers in the documentation with placeholders.\nThis significantly reduces change-noise as different contributors regenerate\nthe documentation on different platforms.\nThanks @RonnyPfannschmidt for the PR.','regenerate documentation on different platforms',0,'',''),(12831,'pytest','Fix AttributeError on sys.stdout.buffer / sys.stderr.buffer\nwhile using capsys fixture in python 3. (issue #1407).\nThanks to @asottile.','fix AttributeError on sys.stdout.buffer',0,'',''),(12832,'pytest','Fix AttributeError on sys.stdout.buffer / sys.stderr.buffer\nwhile using capsys fixture in python 3. (issue #1407).\nThanks to @asottile.','use capsys fixture in python',0,'',''),(12833,'pytest','Change capture.py’s DontReadFromInput class to throw io.UnsupportedOperation errors rather\nthan ValueErrors in the fileno method (issue #2276).\nThanks @metasyn and @vlad-dragos for the PR.','throw io.UnsupportedOperation errors',0,'',''),(12834,'pytest','Fix exception formatting while importing modules when the exception message\ncontains non-ascii characters (issue #2336).\nThanks @fabioz for the report and @nicoddemus for the PR.','fix exception formatting while importing',0,'',''),(12835,'pytest','Fix exception formatting while importing modules when the exception message\ncontains non-ascii characters (issue #2336).\nThanks @fabioz for the report and @nicoddemus for the PR.','import modules',0,'',''),(12836,'pytest','Show the correct error message when collect “parametrize” func with wrong args (issue #2383).\nThanks @The-Compiler for the report and @robin0371 for the PR.','show correct error message',0,'',''),(12837,'pytest','Fix issue in assertion rewriting breaking due to modules silently discarding\nother modules when importing fails\nNotably, importing the anydbm module is fixed. (issue #2248).\nThanks @pfhayes for the PR.','import anydbm module',0,'',''),(12838,'pytest','Fix issue in assertion rewriting breaking due to modules silently discarding\nother modules when importing fails\nNotably, importing the anydbm module is fixed. (issue #2248).\nThanks @pfhayes for the PR.','fix fix issue in assertion rewriting breaking',0,'',''),(12839,'pytest','Fix regression, pytest now skips unittest correctly if run with --pdb\n(issue #2137). Thanks to @gst for the report and @mbyt for the PR.','fix regression',0,'',''),(12840,'pytest','Ignore exceptions raised from descriptors (e.g. properties) during Python test collection (issue #2234).\nThanks to @bluetech.','raise  from descriptors',0,'',''),(12841,'pytest','Ignore exceptions raised from descriptors (e.g. properties) during Python test collection (issue #2234).\nThanks to @bluetech.','raise  during Python test collection',0,'',''),(12842,'pytest','--override-ini now correctly overrides some fundamental options like python_files (issue #2238).\nThanks @sirex for the report and @nicoddemus for the PR.','override fundamental options like python_files',0,'',''),(12843,'pytest','Replace raise StopIteration usages in the code by simple returns to finish generators, in accordance to PEP 479 (issue #2160).\nThanks to @nicoddemus for the PR.','raise StopIteration usages in code',0,'',''),(12844,'pytest','Fix internal errors when an unprintable AssertionError is raised inside a test.\nThanks @omerhadari for the PR.','fix internal errors',0,'',''),(12845,'pytest','Fix internal errors when an unprintable AssertionError is raised inside a test.\nThanks @omerhadari for the PR.','raise unprintable AssertionError inside test',0,'',''),(12846,'pytest','Skipping plugin now also works with test items generated by custom collectors (issue #2231).\nThanks to @vidartf.','skip plugin',0,'',''),(12847,'pytest','Skipping plugin now also works with test items generated by custom collectors (issue #2231).\nThanks to @vidartf.','generate  by custom collectors',0,'',''),(12848,'pytest','Skipping plugin now also works with test items generated by custom collectors (issue #2231).\nThanks to @vidartf.','generate  for skipping',0,'',''),(12849,'pytest','Conditionless xfail markers no longer rely on the underlying test item\nbeing an instance of PyobjMixin, and can therefore apply to tests not\ncollected by the built-in python test collector. Thanks @barneygale for the\nPR.','apply  to tests',0,'',''),(12850,'pytest','pytest no longer generates PendingDeprecationWarning from its own operations, which was introduced by mistake in version 3.0.5 (issue #2118).\nThanks to @nicoddemus for the report and @RonnyPfannschmidt for the PR.','generate PendingDeprecationWarning from own operations',0,'',''),(12851,'pytest','pytest no longer generates PendingDeprecationWarning from its own operations, which was introduced by mistake in version 3.0.5 (issue #2118).\nThanks to @nicoddemus for the report and @RonnyPfannschmidt for the PR.','introduce own operations',0,'',''),(12852,'pytest','Improve error message when pytest.warns fails (issue #2150). The type(s) of the\nexpected warnings and the list of caught warnings is added to the\nerror message. Thanks @lesteve for the PR.','add type of expected warnings',0,'',''),(12853,'pytest','Improve error message when pytest.warns fails (issue #2150). The type(s) of the\nexpected warnings and the list of caught warnings is added to the\nerror message. Thanks @lesteve for the PR.','add type of list',0,'',''),(12854,'pytest','Improve error message when pytest.warns fails (issue #2150). The type(s) of the\nexpected warnings and the list of caught warnings is added to the\nerror message. Thanks @lesteve for the PR.','add type to error message',0,'',''),(12855,'pytest','Fix pytester internal plugin to work correctly with latest versions of\nzope.interface (issue #1989). Thanks @nicoddemus for the PR.','fix pytester internal plugin',0,'',''),(12856,'pytest','Specifying tests with colons like test_foo.py::test_bar for tests in\nsubdirectories with ini configuration files now uses the correct ini file\n(issue #2148).  Thanks @pelme.','specify tests with colons',0,'',''),(12857,'pytest','Specifying tests with colons like test_foo.py::test_bar for tests in\nsubdirectories with ini configuration files now uses the correct ini file\n(issue #2148).  Thanks @pelme.','use correct ini file',0,'',''),(12858,'pytest','Add hint to error message hinting possible missing __init__.py (issue #478). Thanks @DuncanBetts.','add hint to error message',0,'',''),(12859,'pytest','Provide :ref: targets for recwarn.rst so we can use intersphinx referencing.\nThanks to @dupuy for the report and @lwm for the PR.','use intersphinx referencing',0,'',''),(12860,'pytest','In Python 2, use a simple +- ASCII string in the string representation of pytest.approx (for example \"4 +- 4.0e-06\")\nbecause it is brittle to handle that in different contexts and representations internally in pytest\nwhich can result in bugs such as issue #2111. In Python 3, the representation still uses ± (for example 4 ± 4.0e-06).\nThanks @kerrick-lyft for the report and @nicoddemus for the PR.','use simple + in Python',0,'',''),(12861,'pytest','In Python 2, use a simple +- ASCII string in the string representation of pytest.approx (for example \"4 +- 4.0e-06\")\nbecause it is brittle to handle that in different contexts and representations internally in pytest\nwhich can result in bugs such as issue #2111. In Python 3, the representation still uses ± (for example 4 ± 4.0e-06).\nThanks @kerrick-lyft for the report and @nicoddemus for the PR.','handle  in pytest',0,'',''),(12862,'pytest','In Python 2, use a simple +- ASCII string in the string representation of pytest.approx (for example \"4 +- 4.0e-06\")\nbecause it is brittle to handle that in different contexts and representations internally in pytest\nwhich can result in bugs such as issue #2111. In Python 3, the representation still uses ± (for example 4 ± 4.0e-06).\nThanks @kerrick-lyft for the report and @nicoddemus for the PR.','use  in Python',0,'',''),(12863,'pytest','Using item.Function, item.Module, etc., is now issuing deprecation warnings, prefer\npytest.Function, pytest.Module, etc., instead (issue #2034).\nThanks @nmundar for the PR.','use item.Function',0,'',''),(12864,'pytest','Fix error message using approx with complex numbers (issue #2082).\nThanks @adler-j for the report and @nicoddemus for the PR.','fix error message',0,'',''),(12865,'pytest','Fix error message using approx with complex numbers (issue #2082).\nThanks @adler-j for the report and @nicoddemus for the PR.','use approx with complex numbers',0,'',''),(12866,'pytest','Remove an internal cache which could cause hooks from conftest.py files in\nsub-directories to be called in other directories incorrectly (issue #2016).\nThanks @d-b-w for the report and @nicoddemus for the PR.','remove internal cache',0,'',''),(12867,'pytest','Remove an internal cache which could cause hooks from conftest.py files in\nsub-directories to be called in other directories incorrectly (issue #2016).\nThanks @d-b-w for the report and @nicoddemus for the PR.','call  in other directories',0,'',''),(12868,'pytest','Remove internal code meant to support earlier Python 3 versions that produced the side effect\nof leaving None in sys.modules when expressions were evaluated by pytest (for example passing a condition\nas a string to pytest.mark.skipif)(issue #2103).\nThanks @jaraco for the report and @nicoddemus for the PR.','support earlier Python',0,'',''),(12869,'pytest','Remove internal code meant to support earlier Python 3 versions that produced the side effect\nof leaving None in sys.modules when expressions were evaluated by pytest (for example passing a condition\nas a string to pytest.mark.skipif)(issue #2103).\nThanks @jaraco for the report and @nicoddemus for the PR.','produce side effect of leaving',0,'',''),(12870,'pytest','Remove internal code meant to support earlier Python 3 versions that produced the side effect\nof leaving None in sys.modules when expressions were evaluated by pytest (for example passing a condition\nas a string to pytest.mark.skipif)(issue #2103).\nThanks @jaraco for the report and @nicoddemus for the PR.','produce versions of leaving',0,'',''),(12871,'pytest','Import errors when collecting test modules now display the full traceback (issue #1976).\nThanks @cwitty for the report and @nicoddemus for the PR.','display full traceback',0,'',''),(12872,'pytest','Fix confusing command-line help message for custom options with two or more metavar properties (issue #2004).\nThanks @okulynyak and @davehunt for the report and @nicoddemus for the PR.','fix confusing command-line help message for custom options',0,'',''),(12873,'pytest','When loading plugins, import errors which contain non-ascii messages are now properly handled in Python 2 (issue #1998).\nThanks @nicoddemus for the PR.','handle import errors in Python',0,'',''),(12874,'pytest','Fixed cyclic reference when pytest.raises is used in context-manager form (issue #1965). Also as a\nresult of this fix, sys.exc_info() is left empty in both context-manager and function call usages.\nPreviously, sys.exc_info would contain the exception caught by the context manager,\neven when the expected exception occurred.\nThanks @MSeifert04 for the report and the PR.','fix cyclic reference',0,'',''),(12875,'pytest','Fixed cyclic reference when pytest.raises is used in context-manager form (issue #1965). Also as a\nresult of this fix, sys.exc_info() is left empty in both context-manager and function call usages.\nPreviously, sys.exc_info would contain the exception caught by the context manager,\neven when the expected exception occurred.\nThanks @MSeifert04 for the report and the PR.','use pytest.raises in context-manager form',0,'',''),(12876,'pytest','Fixed false-positives warnings from assertion rewrite hook for modules that were rewritten but\nwere later marked explicitly by pytest.register_assert_rewrite\nor implicitly as a plugin (issue #2005).\nThanks @RonnyPfannschmidt for the report and @nicoddemus for the PR.','mark modules as plugin',0,'',''),(12877,'pytest','Fix teardown error message in generated xUnit XML.\nThanks @gdyuldin for the PR.','fix teardown error message in generated xUnit XML',0,'',''),(12878,'pytest','Properly handle exceptions in multiprocessing tasks (issue #1984).\nThanks @adborden for the report and @nicoddemus for the PR.','handle exceptions in multiprocessing tasks',0,'',''),(12879,'pytest','Fix pkg_resources import error in Jython projects (issue #1853).\nThanks @raquelalegre for the PR.','fix pkg_resources import error in Jython projects',0,'',''),(12880,'pytest','Explain a bad scope value passed to @fixture declarations or\na MetaFunc.parametrize() call.','pass  to @fixture declarations',0,'',''),(12881,'pytest','Explain a bad scope value passed to @fixture declarations or\na MetaFunc.parametrize() call.','pass  to MetaFunc.parametrize() call',0,'',''),(12882,'pytest','This version includes pluggy-0.4.0, which correctly handles\nVersionConflict errors in plugins (issue #704).\nThanks @nicoddemus for the PR.','handle VersionConflict errors in plugins',0,'',''),(12883,'pytest','Improve error message when passing non-string ids to pytest.mark.parametrize (issue #1857).\nThanks @okken for the report and @nicoddemus for the PR.','pass non-string ids to pytest.mark.parametrize',0,'',''),(12884,'pytest','Fix UnicodeEncodeError when string comparison with unicode has failed. (issue #1864)\nThanks @AiOO for the PR.','fix UnicodeEncodeError',0,'',''),(12885,'pytest','pytest_plugins is now handled correctly if defined as a string (as opposed as\na sequence of strings) when modules are considered for assertion rewriting.\nDue to this bug, much more modules were being rewritten than necessary\nif a test suite uses pytest_plugins to load internal plugins (issue #1888).\nThanks @jaraco for the report and @nicoddemus for the PR (pull request #1891).','define  as string',0,'',''),(12886,'pytest','pytest_plugins is now handled correctly if defined as a string (as opposed as\na sequence of strings) when modules are considered for assertion rewriting.\nDue to this bug, much more modules were being rewritten than necessary\nif a test suite uses pytest_plugins to load internal plugins (issue #1888).\nThanks @jaraco for the report and @nicoddemus for the PR (pull request #1891).','handle pytest_plugins',0,'',''),(12887,'pytest','pytest_plugins is now handled correctly if defined as a string (as opposed as\na sequence of strings) when modules are considered for assertion rewriting.\nDue to this bug, much more modules were being rewritten than necessary\nif a test suite uses pytest_plugins to load internal plugins (issue #1888).\nThanks @jaraco for the report and @nicoddemus for the PR (pull request #1891).','use pytest_plugins',0,'',''),(12888,'pytest','pytest_plugins is now handled correctly if defined as a string (as opposed as\na sequence of strings) when modules are considered for assertion rewriting.\nDue to this bug, much more modules were being rewritten than necessary\nif a test suite uses pytest_plugins to load internal plugins (issue #1888).\nThanks @jaraco for the report and @nicoddemus for the PR (pull request #1891).','load internal plugins',0,'',''),(12889,'pytest','Do not call tearDown and cleanups when running tests from\nunittest.TestCase subclasses with --pdb\nenabled. This allows proper post mortem debugging for all applications\nwhich have significant logic in their tearDown machinery (issue #1890). Thanks\n@mbyt for the PR.','run tests from unittest.TestCase',0,'',''),(12890,'pytest','Fix use of deprecated getfuncargvalue method in the internal doctest plugin.\nThanks @ViviCoder for the report (issue #1898).','fix use of deprecated getfuncargvalue method',0,'',''),(12891,'pytest','Fix regression when importorskip is used at module level (issue #1822).\nThanks @jaraco and @The-Compiler for the report and @nicoddemus for the PR.','fix regression',0,'',''),(12892,'pytest','Fix regression when importorskip is used at module level (issue #1822).\nThanks @jaraco and @The-Compiler for the report and @nicoddemus for the PR.','use importorskip at module level',0,'',''),(12893,'pytest','Fix parametrization scope when session fixtures are used in conjunction\nwith normal parameters in the same call (issue #1832).\nThanks @The-Compiler for the report, @Kingdread and @nicoddemus for the PR.','fix parametrization scope',0,'',''),(12894,'pytest','Fix parametrization scope when session fixtures are used in conjunction\nwith normal parameters in the same call (issue #1832).\nThanks @The-Compiler for the report, @Kingdread and @nicoddemus for the PR.','use session fixtures with normal parameters',0,'',''),(12895,'pytest','Fix parametrization scope when session fixtures are used in conjunction\nwith normal parameters in the same call (issue #1832).\nThanks @The-Compiler for the report, @Kingdread and @nicoddemus for the PR.','use session fixtures in conjunction',0,'',''),(12896,'pytest','Fix internal error when parametrizing tests or fixtures using an empty ids argument (issue #1849).\nThanks @OPpuolitaival for the report and @nicoddemus for the PR.','fix internal error',0,'',''),(12897,'pytest','Fix internal error when parametrizing tests or fixtures using an empty ids argument (issue #1849).\nThanks @OPpuolitaival for the report and @nicoddemus for the PR.','use empty ids argument',0,'',''),(12898,'pytest','Fix loader error when running pytest embedded in a zipfile.\nThanks @mbachry for the PR.','fix loader error',0,'',''),(12899,'pytest','Fix loader error when running pytest embedded in a zipfile.\nThanks @mbachry for the PR.','embed  in zipfile',0,'',''),(12900,'pytest','A number of incompatible changes were made in this release, with the intent of removing features deprecated for a long\ntime or change existing behaviors in order to make them less surprising/more useful.','remove features',0,'',''),(12901,'pytest','Reinterpretation mode has now been removed.  Only plain and rewrite\nmode are available, consequently the --assert=reinterp option is\nno longer available.  This also means files imported from plugins or\nconftest.py will not benefit from improved assertions by\ndefault, you should use pytest.register_assert_rewrite() to\nexplicitly turn on assertion rewriting for those files.  Thanks\n@flub for the PR.','remove reinterpretation mode',0,'',''),(12902,'pytest','Reinterpretation mode has now been removed.  Only plain and rewrite\nmode are available, consequently the --assert=reinterp option is\nno longer available.  This also means files imported from plugins or\nconftest.py will not benefit from improved assertions by\ndefault, you should use pytest.register_assert_rewrite() to\nexplicitly turn on assertion rewriting for those files.  Thanks\n@flub for the PR.','use pytest.register_assert_rewrite()',0,'',''),(12903,'pytest','Reinterpretation mode has now been removed.  Only plain and rewrite\nmode are available, consequently the --assert=reinterp option is\nno longer available.  This also means files imported from plugins or\nconftest.py will not benefit from improved assertions by\ndefault, you should use pytest.register_assert_rewrite() to\nexplicitly turn on assertion rewriting for those files.  Thanks\n@flub for the PR.','import  from plugins',0,'',''),(12904,'pytest','Reinterpretation mode has now been removed.  Only plain and rewrite\nmode are available, consequently the --assert=reinterp option is\nno longer available.  This also means files imported from plugins or\nconftest.py will not benefit from improved assertions by\ndefault, you should use pytest.register_assert_rewrite() to\nexplicitly turn on assertion rewriting for those files.  Thanks\n@flub for the PR.','import  from conftest.py',0,'',''),(12905,'pytest','The following deprecated commandline options were removed:','remove commandline options',0,'',''),(12906,'pytest','Removed all py.test-X* entry points. The versioned, suffixed entry points\nwere never documented and a leftover from a pre-virtualenv era. These entry\npoints also created broken entry points in wheels, so removing them also\nremoves a source of confusion for users (issue #1632).\nThanks @obestwalter for the PR.','create broken entry points in wheels',0,'',''),(12907,'pytest','Removed all py.test-X* entry points. The versioned, suffixed entry points\nwere never documented and a leftover from a pre-virtualenv era. These entry\npoints also created broken entry points in wheels, so removing them also\nremoves a source of confusion for users (issue #1632).\nThanks @obestwalter for the PR.','remove source of confusion',0,'',''),(12908,'pytest','pytest.skip() now raises an error when used to decorate a test function,\nas opposed to its original intent (to imperatively skip a test inside a test function). Previously\nthis usage would cause the entire module to be skipped (issue #607).\nThanks @omarkohl for the complete PR (pull request #1519).','raise error',0,'',''),(12909,'pytest','Exit tests if a collection error occurs. A poll indicated most users will hit CTRL-C\nanyway as soon as they see collection errors, so pytest might as well make that the default behavior (issue #1421).\nA --continue-on-collection-errors option has been added to restore the previous behaviour.\nThanks @olegpidsadnyi and @omarkohl for the complete PR (pull request #1628).','add continue-on-collection-errors option',0,'',''),(12910,'pytest','Renamed the pytest pdb module (plugin) into debugging to avoid clashes with the builtin pdb module.','rename pytest pdb module into debugging',0,'',''),(12911,'pytest','Raise a helpful failure message when requesting a parametrized fixture at runtime,\ne.g. with request.getfixturevalue. Previously these parameters were simply\nnever defined, so a fixture decorated like @pytest.fixture(params=[0, 1, 2])\nonly ran once (pull request #460).\nThanks to @nikratio for the bug report, @RedBeardCode and @tomviner for the PR.','raise helpful failure message',0,'',''),(12912,'pytest','Raise a helpful failure message when requesting a parametrized fixture at runtime,\ne.g. with request.getfixturevalue. Previously these parameters were simply\nnever defined, so a fixture decorated like @pytest.fixture(params=[0, 1, 2])\nonly ran once (pull request #460).\nThanks to @nikratio for the bug report, @RedBeardCode and @tomviner for the PR.','request parametrized fixture at runtime',0,'',''),(12913,'pytest','_pytest.monkeypatch.monkeypatch class has been renamed to _pytest.monkeypatch.MonkeyPatch\nso it doesn’t conflict with the monkeypatch fixture.','rename _pytest.monkeypatch.monkeypatch class to _pytest.monkeypatch.MonkeyPatch',0,'',''),(12914,'pytest','Support nose-style __test__ attribute on methods of classes,\nincluding unittest-style Classes. If set to False, the test will not be\ncollected.','set  to false',0,'',''),(12915,'pytest','New doctest_namespace fixture for injecting names into the\nnamespace in which doctests run.\nThanks @milliams for the complete PR (pull request #1428).','run namespace',0,'',''),(12916,'pytest','New --doctest-report option available to change the output format of diffs\nwhen running (failing) doctests (implements issue #1749).\nThanks @hartym for the PR.','change output format of diffs',0,'',''),(12917,'pytest','New --doctest-report option available to change the output format of diffs\nwhen running (failing) doctests (implements issue #1749).\nThanks @hartym for the PR.','run doctests',0,'',''),(12918,'pytest','New approx() function for easily comparing floating-point numbers in\ntests.\nThanks @kalekundert for the complete PR (pull request #1441).','compare floating-point numbers in tests',0,'',''),(12919,'pytest','Ability to add global properties in the final xunit output file by accessing\nthe internal junitxml plugin (experimental).\nThanks @tareqalayan for the complete PR pull request #1454).','add global properties in final xunit output file',0,'',''),(12920,'pytest','Ability to add global properties in the final xunit output file by accessing\nthe internal junitxml plugin (experimental).\nThanks @tareqalayan for the complete PR pull request #1454).','add global properties by accessing',0,'',''),(12921,'pytest','Ability to add global properties in the final xunit output file by accessing\nthe internal junitxml plugin (experimental).\nThanks @tareqalayan for the complete PR pull request #1454).','access internal junitxml plugin',0,'',''),(12922,'pytest','New ExceptionInfo.match() method to match a regular expression on the\nstring representation of an exception (issue #372).\nThanks @omarkohl for the complete PR (pull request #1502).','match regular expression on string representation',0,'',''),(12923,'pytest','__tracebackhide__ can now also be set to a callable which then can decide\nwhether to filter the traceback based on the ExceptionInfo object passed\nto it. Thanks @The-Compiler for the complete PR (pull request #1526).','set __tracebackhide__ to callable',0,'',''),(12924,'pytest','New pytest_make_parametrize_id(config, val) hook which can be used by plugins to provide\nfriendly strings for custom types.\nThanks @palaviv for the PR.','provide friendly strings for custom types',0,'',''),(12925,'pytest','New pytest_make_parametrize_id(config, val) hook which can be used by plugins to provide\nfriendly strings for custom types.\nThanks @palaviv for the PR.','use new pytest_make_parametrize_id(config,          val) hook',0,'',''),(12926,'pytest','capsys and capfd now have a disabled() context-manager method, which\ncan be used to temporarily disable capture within a test.\nThanks @nicoddemus for the PR.','disable capture within test',0,'',''),(12927,'pytest','capsys and capfd now have a disabled() context-manager method, which\ncan be used to temporarily disable capture within a test.\nThanks @nicoddemus for the PR.','use disabled() context-manager method',0,'',''),(12928,'pytest','New cli flag --fixtures-per-test: shows which fixtures are being used\nfor each selected test item. Features doc strings of fixtures by default.\nCan also show where fixtures are defined if combined with -v.\nThanks @hackebrot for the PR.','use fixtures for selected test item',0,'',''),(12929,'pytest','New cli flag --fixtures-per-test: shows which fixtures are being used\nfor each selected test item. Features doc strings of fixtures by default.\nCan also show where fixtures are defined if combined with -v.\nThanks @hackebrot for the PR.','combine  with v',0,'',''),(12930,'pytest','New cli flag --fixtures-per-test: shows which fixtures are being used\nfor each selected test item. Features doc strings of fixtures by default.\nCan also show where fixtures are defined if combined with -v.\nThanks @hackebrot for the PR.','define fixtures',0,'',''),(12931,'pytest','Introduce pytest command as recommended entry point. Note that py.test\nstill works and is not scheduled for removal. Closes proposal\nissue #1629. Thanks @obestwalter and @davehunt for the complete PR\n(pull request #1633).','introduce pytest command as recommended entry point',0,'',''),(12932,'pytest','--setup-plan: performs normal collection and reports\nthe potential setup and teardown and does not execute any fixtures and tests;','perform normal collection',0,'',''),(12933,'pytest','--setup-only: performs normal collection, executes setup and teardown of\nfixtures and reports them;','execute setup of fixtures',0,'',''),(12934,'pytest','--setup-only: performs normal collection, executes setup and teardown of\nfixtures and reports them;','execute teardown of fixtures',0,'',''),(12935,'pytest','--setup-show: performs normal test execution and additionally shows\nsetup and teardown of fixtures;','perform normal test execution',0,'',''),(12936,'pytest','--setup-show: performs normal test execution and additionally shows\nsetup and teardown of fixtures;','show setup of fixtures',0,'',''),(12937,'pytest','--setup-show: performs normal test execution and additionally shows\nsetup and teardown of fixtures;','show teardown of fixtures',0,'',''),(12938,'pytest','--keep-duplicates: py.test now ignores duplicated paths given in the command\nline. To retain the previous behavior where the same test could be run multiple\ntimes by specifying it in the command-line multiple times, pass the --keep-duplicates\nargument (issue #1609);','ignore duplicated paths',0,'',''),(12939,'pytest','--keep-duplicates: py.test now ignores duplicated paths given in the command\nline. To retain the previous behavior where the same test could be run multiple\ntimes by specifying it in the command-line multiple times, pass the --keep-duplicates\nargument (issue #1609);','run multiple times',0,'',''),(12940,'pytest','--keep-duplicates: py.test now ignores duplicated paths given in the command\nline. To retain the previous behavior where the same test could be run multiple\ntimes by specifying it in the command-line multiple times, pass the --keep-duplicates\nargument (issue #1609);','run same test',0,'',''),(12941,'pytest','--keep-duplicates: py.test now ignores duplicated paths given in the command\nline. To retain the previous behavior where the same test could be run multiple\ntimes by specifying it in the command-line multiple times, pass the --keep-duplicates\nargument (issue #1609);','specify  in command-line multiple times',0,'',''),(12942,'pytest','--keep-duplicates: py.test now ignores duplicated paths given in the command\nline. To retain the previous behavior where the same test could be run multiple\ntimes by specifying it in the command-line multiple times, pass the --keep-duplicates\nargument (issue #1609);','pass keep-duplicates argument',0,'',''),(12943,'pytest','pytest_fixture_post_finalizer(fixturedef): called after the fixture’s\nfinalizer and has access to the fixture’s result cache.','call  after finalizer',0,'',''),(12944,'pytest','Allow passing a custom debugger class (e.g. --pdbcls=IPython.core.debugger:Pdb).\nThanks to @anntzer for the PR.','pass custom debugger class',0,'',''),(12945,'pytest','Tests marked with xfail(strict=False) (the default) now appear in\nJUnitXML reports as passing tests instead of skipped.\nThanks to @hackebrot for the PR (pull request #1795).','pass tests instead_of skipped',0,'',''),(12946,'pytest','Tests marked with xfail(strict=False) (the default) now appear in\nJUnitXML reports as passing tests instead of skipped.\nThanks to @hackebrot for the PR (pull request #1795).','mark  with xfail(strict=False)',0,'',''),(12947,'pytest','Fixtures marked with @pytest.fixture can now use yield statements exactly like\nthose marked with the @pytest.yield_fixture decorator. This change renders\n@pytest.yield_fixture deprecated and makes @pytest.fixture with yield statements\nthe preferred way to write teardown code (pull request #1461).\nThanks @csaftoiu for bringing this to attention and @nicoddemus for the PR.','use yield statements',0,'',''),(12948,'pytest','Fixtures marked with @pytest.fixture can now use yield statements exactly like\nthose marked with the @pytest.yield_fixture decorator. This change renders\n@pytest.yield_fixture deprecated and makes @pytest.fixture with yield statements\nthe preferred way to write teardown code (pull request #1461).\nThanks @csaftoiu for bringing this to attention and @nicoddemus for the PR.','mark  with',0,'',''),(12949,'pytest','Fixtures marked with @pytest.fixture can now use yield statements exactly like\nthose marked with the @pytest.yield_fixture decorator. This change renders\n@pytest.yield_fixture deprecated and makes @pytest.fixture with yield statements\nthe preferred way to write teardown code (pull request #1461).\nThanks @csaftoiu for bringing this to attention and @nicoddemus for the PR.','mark  with  decorator',0,'',''),(12950,'pytest','Fixtures marked with @pytest.fixture can now use yield statements exactly like\nthose marked with the @pytest.yield_fixture decorator. This change renders\n@pytest.yield_fixture deprecated and makes @pytest.fixture with yield statements\nthe preferred way to write teardown code (pull request #1461).\nThanks @csaftoiu for bringing this to attention and @nicoddemus for the PR.','write teardown code',0,'',''),(12951,'pytest','Fixtures are now sorted in the error message displayed when an unknown\nfixture is declared in a test function.\nThanks @nicoddemus for the PR.','sort fixtures in error message',0,'',''),(12952,'pytest','pytest_terminal_summary hook now receives the exitstatus\nof the test session as argument. Thanks @blueyed for the PR (pull request #1809).','receive exitstatus as argument',0,'',''),(12953,'pytest','pytest_terminal_summary hook now receives the exitstatus\nof the test session as argument. Thanks @blueyed for the PR (pull request #1809).','receive exitstatus of test session',0,'',''),(12954,'pytest','Parametrize ids can accept None as specific test id, in which case the\nautomatically generated id for that argument will be used.\nThanks @palaviv for the complete PR (pull request #1468).','use id for argument',0,'',''),(12955,'pytest','Parametrize ids can accept None as specific test id, in which case the\nautomatically generated id for that argument will be used.\nThanks @palaviv for the complete PR (pull request #1468).','generate specific test id',0,'',''),(12956,'pytest','The parameter to xunit-style setup/teardown methods (setup_method,\nsetup_module, etc.) is now optional and may be omitted.\nThanks @okken for bringing this to attention and @nicoddemus for the PR.','omit parameter to xunit-style setup/teardown methods',0,'',''),(12957,'pytest','Now pytest warnings summary is shown up by default. Added a new flag\n--disable-pytest-warnings to explicitly disable the warnings summary (issue #1668).','add new flag',0,'',''),(12958,'pytest','Now pytest warnings summary is shown up by default. Added a new flag\n--disable-pytest-warnings to explicitly disable the warnings summary (issue #1668).','disable warnings summary',0,'',''),(12959,'pytest','Make ImportError during collection more explicit by reminding\nthe user to check the name of the test module/package(s) (issue #1426).\nThanks @omarkohl for the complete PR (pull request #1520).','check name of test module/package',0,'',''),(12960,'pytest','Ensure that a module within a namespace package can be found when it\nis specified on the command line together with the --pyargs\noption.  Thanks to @taschini for the PR (pull request #1597).','specify  together_with pyargs',0,'',''),(12961,'pytest','Ensure that a module within a namespace package can be found when it\nis specified on the command line together with the --pyargs\noption.  Thanks to @taschini for the PR (pull request #1597).','specify  on command line',0,'',''),(12962,'pytest','Ensure that a module within a namespace package can be found when it\nis specified on the command line together with the --pyargs\noption.  Thanks to @taschini for the PR (pull request #1597).','find module within namespace package',0,'',''),(12963,'pytest','Always include full assertion explanation during assertion rewriting. The previous behaviour was hiding\nsub-expressions that happened to be False, assuming this was redundant information.\nThanks @bagerard for reporting (issue #1503). Thanks to @davehunt and\n@tomviner for the PR.','include full assertion explanation during assertion rewriting',0,'',''),(12964,'pytest','Always include full assertion explanation during assertion rewriting. The previous behaviour was hiding\nsub-expressions that happened to be False, assuming this was redundant information.\nThanks @bagerard for reporting (issue #1503). Thanks to @davehunt and\n@tomviner for the PR.','hide sub-expressions',0,'',''),(12965,'pytest','OptionGroup.addoption() now checks if option names were already\nadded before, to make it easier to track down issues like issue #1618.\nBefore, you only got exceptions later from argparse library,\ngiving no clue about the actual reason for double-added options.','add option names',0,'',''),(12966,'pytest','OptionGroup.addoption() now checks if option names were already\nadded before, to make it easier to track down issues like issue #1618.\nBefore, you only got exceptions later from argparse library,\ngiving no clue about the actual reason for double-added options.','get exceptions from argparse library',0,'',''),(12967,'pytest','yield-based tests are considered deprecated and will be removed in pytest-4.0.\nThanks @nicoddemus for the PR.','remove tests',0,'',''),(12968,'pytest','Using pytest_funcarg__ prefix to declare fixtures is considered deprecated and will be\nremoved in pytest-4.0 (pull request #1684).\nThanks @nicoddemus for the PR.','use pytest_funcarg__ prefix',0,'',''),(12969,'pytest','Passing a command-line string to pytest.main() is considered deprecated and scheduled\nfor removal in pytest-4.0. It is recommended to pass a list of arguments instead (pull request #1723).','pass command-line string to pytest.main()',0,'',''),(12970,'pytest','Passing a command-line string to pytest.main() is considered deprecated and scheduled\nfor removal in pytest-4.0. It is recommended to pass a list of arguments instead (pull request #1723).','pass list of arguments',0,'',''),(12971,'pytest','optparse type usage now triggers DeprecationWarnings (issue #1740).','trigger DeprecationWarnings',0,'',''),(12972,'pytest','optparse backward compatibility supports float/complex types (issue #457).','support float/complex types',0,'',''),(12973,'pytest','Refined logic for determining the rootdir, considering only valid\npaths which fixes a number of issues: issue #1594, issue #1435 and issue #1471.\nUpdated the documentation according to current behavior. Thanks to\n@blueyed, @davehunt and @matthiasha for the PR.','determine rootdir',0,'',''),(12974,'pytest','Refined logic for determining the rootdir, considering only valid\npaths which fixes a number of issues: issue #1594, issue #1435 and issue #1471.\nUpdated the documentation according to current behavior. Thanks to\n@blueyed, @davehunt and @matthiasha for the PR.','fix number of issues',0,'',''),(12975,'pytest','Refined logic for determining the rootdir, considering only valid\npaths which fixes a number of issues: issue #1594, issue #1435 and issue #1471.\nUpdated the documentation according to current behavior. Thanks to\n@blueyed, @davehunt and @matthiasha for the PR.','fix valid paths of issues',0,'',''),(12976,'pytest','Refined logic for determining the rootdir, considering only valid\npaths which fixes a number of issues: issue #1594, issue #1435 and issue #1471.\nUpdated the documentation according to current behavior. Thanks to\n@blueyed, @davehunt and @matthiasha for the PR.','update documentation',0,'',''),(12977,'pytest','Always include full assertion explanation. The previous behaviour was hiding\nsub-expressions that happened to be False, assuming this was redundant information.\nThanks @bagerard for reporting (issue #1503). Thanks to @davehunt and\n@tomviner for PR.','include full assertion explanation',0,'',''),(12978,'pytest','Always include full assertion explanation. The previous behaviour was hiding\nsub-expressions that happened to be False, assuming this was redundant information.\nThanks @bagerard for reporting (issue #1503). Thanks to @davehunt and\n@tomviner for PR.','hide sub-expressions',0,'',''),(12979,'pytest','Add stderr write for pytest.exit(msg) during startup. Previously the message was never shown.\nThanks @BeyondEvil for reporting issue #1210. Thanks to @jgsonesen and\n@tomviner for the PR.','add stderr',0,'',''),(12980,'pytest','Add stderr write for pytest.exit(msg) during startup. Previously the message was never shown.\nThanks @BeyondEvil for reporting issue #1210. Thanks to @jgsonesen and\n@tomviner for the PR.','write  for pytest.exit(msg)',0,'',''),(12981,'pytest','Add stderr write for pytest.exit(msg) during startup. Previously the message was never shown.\nThanks @BeyondEvil for reporting issue #1210. Thanks to @jgsonesen and\n@tomviner for the PR.','write  during startup',0,'',''),(12982,'pytest','No longer display the incorrect test deselection reason (issue #1372).\nThanks @ronnypfannschmidt for the PR.','display incorrect test deselection reason',0,'',''),(12983,'pytest','Improve error message with fixture lookup errors: add an ‘E’ to the first\nline and ‘>’ to the rest. Fixes issue #717. Thanks @blueyed for reporting and\na PR, @eolo999 for the initial PR and @tomviner for his guidance during\nEuroPython2016 sprint.','add âEâ to â&gt;â',0,'',''),(12984,'pytest','Improve error message with fixture lookup errors: add an ‘E’ to the first\nline and ‘>’ to the rest. Fixes issue #717. Thanks @blueyed for reporting and\na PR, @eolo999 for the initial PR and @tomviner for his guidance during\nEuroPython2016 sprint.','add âEâ to first line',0,'',''),(12985,'pytest','Parametrize now correctly handles duplicated test ids.','handle duplicated test ids',0,'',''),(12986,'pytest','Fix internal error issue when the method argument is missing for\nteardown_method() (issue #1605).','fix internal error issue',0,'',''),(12987,'pytest','Fix exception visualization in case the current working directory (CWD) gets\ndeleted during testing (issue #1235). Thanks @bukzor for reporting. PR by\n@marscher.','fix exception visualization in case',0,'',''),(12988,'pytest','Fix exception visualization in case the current working directory (CWD) gets\ndeleted during testing (issue #1235). Thanks @bukzor for reporting. PR by\n@marscher.','delete current working directory during testing',0,'',''),(12989,'pytest','Create correct diff for strings ending with newlines (issue #1553).\nThanks @Vogtinator for reporting and @RedBeardCode and\n@tomviner for the PR.','create correct diff for strings',0,'',''),(12990,'pytest','ConftestImportFailure now shows the traceback making it easier to\nidentify bugs in conftest.py files (pull request #1516). Thanks @txomon for\nthe PR.','show traceback',0,'',''),(12991,'pytest','ConftestImportFailure now shows the traceback making it easier to\nidentify bugs in conftest.py files (pull request #1516). Thanks @txomon for\nthe PR.','identify bugs in conftest.py files',0,'',''),(12992,'pytest','Fixed the total tests tally in junit xml output (pull request #1798).\nThanks to @cboelsen for the PR.','fix total tests tally in junit xml output',0,'',''),(12993,'pytest','Fixed off-by-one error with lines from request.node.warn.\nThanks to @blueyed for the PR.','fix off-by-one error with lines',0,'',''),(12994,'pytest','Fixed off-by-one error with lines from request.node.warn.\nThanks to @blueyed for the PR.','fix off-by-one error from request.node.warn',0,'',''),(12995,'pytest','Fix win32 path issue when putting custom config file with absolute path\nin pytest.main(\"-c your_absolute_path\").','fix win32 path issue',0,'',''),(12996,'pytest','Fix maximum recursion depth detection when raised error class is not aware\nof unicode/encoded bytes.\nThanks @prusse-martin for the PR (pull request #1506).','fix maximum recursion depth detection',0,'',''),(12997,'pytest','Fix pytest.mark.skip mark when used in strict mode.\nThanks @pquentin for the PR and @RonnyPfannschmidt for\nshowing how to fix the bug.','fix pytest.mark.skip mark',0,'',''),(12998,'pytest','Fix pytest.mark.skip mark when used in strict mode.\nThanks @pquentin for the PR and @RonnyPfannschmidt for\nshowing how to fix the bug.','use  in strict mode',0,'',''),(12999,'pytest','Fix pytest.mark.skip mark when used in strict mode.\nThanks @pquentin for the PR and @RonnyPfannschmidt for\nshowing how to fix the bug.','fix bug',0,'',''),(13000,'pytest','Fix (issue #1178):\npytest.fail with non-ascii characters raises an internal pytest error.\nThanks @nicoddemus for the PR.','raise internal pytest error',0,'',''),(13001,'pytest','Fix (issue #578): SyntaxErrors\ncontaining non-ascii lines at the point of failure generated an internal\npy.test error.\nThanks @asottile for the report and @nicoddemus for the PR.','generate internal py.test error',0,'',''),(13002,'pytest','Fix (issue #1437): When passing in a bytestring regex pattern to parameterize\nattempt to decode it as utf-8 ignoring errors.','ignore errors',0,'',''),(13003,'pytest','Fix (issue #1437): When passing in a bytestring regex pattern to parameterize\nattempt to decode it as utf-8 ignoring errors.','pass  in bytestring regex pattern',0,'',''),(13004,'pytest','Fix (issue #649): parametrized test nodes cannot be specified to run on the command line.','run  on command line',0,'',''),(13005,'pytest','New pytest.mark.skip mark, which unconditionally skips marked tests.\nThanks @MichaelAquilina for the complete PR (pull request #1040).','mark tests',0,'',''),(13006,'pytest','New pytest.mark.skip mark, which unconditionally skips marked tests.\nThanks @MichaelAquilina for the complete PR (pull request #1040).','skip new pytest.mark.skip mark',0,'',''),(13007,'pytest','--doctest-glob may now be passed multiple times in the command-line.\nThanks @jab and @nicoddemus for the PR.','pass doctest-glob in command-line',0,'',''),(13008,'pytest','pytest.mark.xfail now has a strict option, which makes XPASS\ntests to fail the test suite (defaulting to False). There’s also a\nxfail_strict ini option that can be used to configure it project-wise.\nThanks @rabbbit for the request and @nicoddemus for the PR (pull request #1355).','use xfail_strict ini option',0,'',''),(13009,'pytest','Parser.addini now supports options of type bool.\nThanks @nicoddemus for the PR.','support options of type bool',0,'',''),(13010,'pytest','New ALLOW_BYTES doctest option. This strips b prefixes from byte strings\nin doctest output (similar to ALLOW_UNICODE).\nThanks @jaraco for the request and @nicoddemus for the PR (pull request #1287).','prefix  from byte strings',0,'',''),(13011,'pytest','Give a hint on KeyboardInterrupt to use the --fulltrace option to show the errors.\nFixes issue #1366.\nThanks to @hpk42 for the report and @RonnyPfannschmidt for the PR.','use fulltrace option',0,'',''),(13012,'pytest','Give a hint on KeyboardInterrupt to use the --fulltrace option to show the errors.\nFixes issue #1366.\nThanks to @hpk42 for the report and @RonnyPfannschmidt for the PR.','show errors',0,'',''),(13013,'pytest','Catch IndexError exceptions when getting exception source location.\nFixes a pytest internal error for dynamically generated code (fixtures and tests)\nwhere source lines are fake by intention.','catch IndexError exceptions',0,'',''),(13014,'pytest','Catch IndexError exceptions when getting exception source location.\nFixes a pytest internal error for dynamically generated code (fixtures and tests)\nwhere source lines are fake by intention.','get exception source location',0,'',''),(13015,'pytest','Catch IndexError exceptions when getting exception source location.\nFixes a pytest internal error for dynamically generated code (fixtures and tests)\nwhere source lines are fake by intention.','generate code',0,'',''),(13016,'pytest','Important: py.code has been\nmerged into the pytest repository as pytest._code. This decision\nwas made because py.code had very few uses outside pytest and the\nfact that it was in a different repository made it difficult to fix bugs on\nits code in a timely manner. The team hopes with this to be able to better\nrefactor out and improve that code.\nThis change shouldn’t affect users, but it is useful to let users aware\nif they encounter any strange behavior.','fix bugs on code',0,'',''),(13017,'pytest','pytest_enter_pdb now optionally receives the pytest config object.\nThanks @nicoddemus for the PR.','receive pytest config object',0,'',''),(13018,'pytest','Comparisons now always show up in full when CI or BUILD_NUMBER is\nfound in the environment, even when -vv isn’t used.\nThanks @The-Compiler for the PR.','find CI in environment',0,'',''),(13019,'pytest','Comparisons now always show up in full when CI or BUILD_NUMBER is\nfound in the environment, even when -vv isn’t used.\nThanks @The-Compiler for the PR.','find BUILD_NUMBER in environment',0,'',''),(13020,'pytest','Comparisons now always show up in full when CI or BUILD_NUMBER is\nfound in the environment, even when -vv isn’t used.\nThanks @The-Compiler for the PR.','use vv',0,'',''),(13021,'pytest','Collection only displays progress (“collecting X items”) when in a terminal.\nThis avoids cluttering the output when using --color=yes to obtain\ncolors in CI integrations systems (issue #1397).','display progress',0,'',''),(13022,'pytest','Collection only displays progress (“collecting X items”) when in a terminal.\nThis avoids cluttering the output when using --color=yes to obtain\ncolors in CI integrations systems (issue #1397).','obtain colors in CI integrations systems',0,'',''),(13023,'pytest','Fix formatting utf-8 explanation messages (issue #1379).\nThanks @biern for the PR.','format utf-8 explanation messages',0,'',''),(13024,'pytest','Fix traceback style docs to describe all of the available options\n(auto/long/short/line/native/no), with auto being the default since v2.6.\nThanks @hackebrot for the PR.','describe  with default',0,'',''),(13025,'pytest','fix #1338: use predictable object resolution for monkeypatch','use predictable object resolution for monkeypatch',0,'',''),(13026,'pytest','fix #900: Better error message in case the target of a monkeypatch call\nraises an ImportError.','raise ImportError',0,'',''),(13027,'pytest','fix #900: Better error message in case the target of a monkeypatch call\nraises an ImportError.','raise case',0,'',''),(13028,'pytest','fix #1223: captured stdout and stderr are now properly displayed before\nentering pdb when --pdb is used instead of being thrown away.\nThanks Cal Leeming for the PR.','enter pdb',0,'',''),(13029,'pytest','fix #1223: captured stdout and stderr are now properly displayed before\nentering pdb when --pdb is used instead of being thrown away.\nThanks Cal Leeming for the PR.','display  before entering',0,'',''),(13030,'pytest','fix #1223: captured stdout and stderr are now properly displayed before\nentering pdb when --pdb is used instead of being thrown away.\nThanks Cal Leeming for the PR.','use pdb',0,'',''),(13031,'pytest','fix #1243: fixed issue where class attributes injected during collection could break pytest.\nPR by Alexei Kozlenok, thanks Ronny Pfannschmidt and Bruno Oliveira for the review and help.','break pytest',0,'',''),(13032,'pytest','fix #1243: fixed issue where class attributes injected during collection could break pytest.\nPR by Alexei Kozlenok, thanks Ronny Pfannschmidt and Bruno Oliveira for the review and help.','break fixed issue',0,'',''),(13033,'pytest','fix #1074: precompute junitxml chunks instead of storing the whole tree in objects\nThanks Bruno Oliveira for the report and Ronny Pfannschmidt for the PR','store whole tree in objects Thanks bruno Oliveira',0,'',''),(13034,'pytest','fix #1238: fix pytest.deprecated_call() receiving multiple arguments\n(Regression introduced in 2.8.4). Thanks Alex Gaynor for the report and\nBruno Oliveira for the PR.','receive multiple arguments',0,'',''),(13035,'pytest','fix #1190: deprecated_call() now works when the deprecated\nfunction has been already called by another test in the same\nmodule. Thanks Mikhail Chernykh for the report and Bruno Oliveira for the\nPR.','call deprecated function',0,'',''),(13036,'pytest','fix the summary printed when no tests did run.\nThanks Florian Bruhin for the PR.','fix summary',0,'',''),(13037,'pytest','fix #1169: add __name__ attribute to testcases in TestCaseFunction to\nsupport the @unittest.skip decorator on functions and methods.\nThanks Lee Kamentsky for the PR.','add __name__ attribute to testcases',0,'',''),(13038,'pytest','fix #1169: add __name__ attribute to testcases in TestCaseFunction to\nsupport the @unittest.skip decorator on functions and methods.\nThanks Lee Kamentsky for the PR.','support  decorator on functions',0,'',''),(13039,'pytest','fix #1169: add __name__ attribute to testcases in TestCaseFunction to\nsupport the @unittest.skip decorator on functions and methods.\nThanks Lee Kamentsky for the PR.','support  decorator on methods',0,'',''),(13040,'pytest','add more talks to the documentation','add more talks to documentation',0,'',''),(13041,'pytest','extend documentation on the –ignore cli option','extend documentation on â ignore cli option',0,'',''),(13042,'pytest','use pytest-runner for setuptools integration','use pytest-runner for setuptools integration',0,'',''),(13043,'pytest','fix #1085: proper handling of encoding errors when passing encoded byte\nstrings to pytest.parametrize in Python 2.\nThanks Themanwithoutaplan for the report and Bruno Oliveira for the PR.','pass encoded byte strings to pytest.parametrize',0,'',''),(13044,'pytest','fix #1087: handling SystemError when passing empty byte strings to\npytest.parametrize in Python 3.\nThanks Paul Kehrer for the report and Bruno Oliveira for the PR.','pass empty byte strings to pytest.parametrize',0,'',''),(13045,'pytest','fix #995: fixed internal error when filtering tracebacks where one entry\nwas generated by an exec() statement.\nThanks Daniel Hahler, Ashley C Straw, Philippe Gauthier and Pavel Savchenko\nfor contributing and Bruno Oliveira for the PR.','generate entry',0,'',''),(13046,'pytest','fix #1100 and #1057: errors when using autouse fixtures and doctest modules.\nThanks Sergey B Kirpichev and Vital Kudzelka for contributing and Bruno\nOliveira for the PR.','use autouse fixtures',0,'',''),(13047,'pytest','fix #1100 and #1057: errors when using autouse fixtures and doctest modules.\nThanks Sergey B Kirpichev and Vital Kudzelka for contributing and Bruno\nOliveira for the PR.','use doctest modules',0,'',''),(13048,'pytest','fix issue #1073: avoid calling __getattr__ on potential plugin objects.\nThis fixes an incompatibility with pytest-django.  Thanks Andreas Pelme,\nBruno Oliveira and Ronny Pfannschmidt for contributing and Holger Krekel\nfor the fix.','call __getattr__ on potential plugin objects',0,'',''),(13049,'pytest','fix issue #1073: avoid calling __getattr__ on potential plugin objects.\nThis fixes an incompatibility with pytest-django.  Thanks Andreas Pelme,\nBruno Oliveira and Ronny Pfannschmidt for contributing and Holger Krekel\nfor the fix.','fix incompatibility with pytest-django',0,'',''),(13050,'pytest','Fix issue #704: handle versionconflict during plugin loading more\ngracefully.  Thanks Bruno Oliveira for the PR.','handle versionconflict during plugin',0,'',''),(13051,'pytest','Fix issue #1064: “”–junitxml” regression when used with the\n“pytest-xdist” plugin, with test reports being assigned to the wrong tests.\nThanks Daniel Grunwald for the report and Bruno Oliveira for the PR.','use  with test reports',0,'',''),(13052,'pytest','Fix issue #1064: “”–junitxml” regression when used with the\n“pytest-xdist” plugin, with test reports being assigned to the wrong tests.\nThanks Daniel Grunwald for the report and Bruno Oliveira for the PR.','use  with pytest-xdist plugin',0,'',''),(13053,'pytest','Fix issue #1064: “”–junitxml” regression when used with the\n“pytest-xdist” plugin, with test reports being assigned to the wrong tests.\nThanks Daniel Grunwald for the report and Bruno Oliveira for the PR.','assign  to wrong tests',0,'',''),(13054,'pytest','(experimental) adapt more SEMVER style versioning and change meaning of\nmaster branch in git repo: “master” branch now keeps the bug fixes, changes\naimed for micro releases.  “features” branch will only be released\nwith minor or major pytest releases.','release features branch with minor major pytest releases',0,'',''),(13055,'pytest','Fix issue #766 by removing documentation references to distutils.\nThanks Russel Winder.','remove documentation references to distutils',0,'',''),(13056,'pytest','Fix issue #1030: now byte-strings are escaped to produce item node ids\nto make them always serializable.\nThanks Andy Freeland for the report and Bruno Oliveira for the PR.','produce item node ids',0,'',''),(13057,'pytest','Python 2: if unicode parametrized values are convertible to ascii, their\nascii representation is used for the node id.','use ascii representation for node id',0,'',''),(13058,'pytest','Fix issue #653: deprecated_call can be used as context manager.','use deprecated_call as context manager',0,'',''),(13059,'pytest','fix issue 877: properly handle assertion explanations with non-ascii repr\nThanks Mathieu Agopian for the report and Ronny Pfannschmidt for the PR.','handle assertion explanations with non-ascii repr Thanks mathieu Agopian',0,'',''),(13060,'pytest','fix issue 1029: transform errors when writing cache values into pytest-warnings','fix issue',0,'',''),(13061,'pytest','fix issue 1029: transform errors when writing cache values into pytest-warnings','write cache values into pytest-warnings',0,'',''),(13062,'pytest','new --lf and -ff options to run only the last failing tests or\n“failing tests first” from the last run.  This functionality is provided\nthrough porting the formerly external pytest-cache plugin into pytest core.\nBACKWARD INCOMPAT: if you used pytest-cache’s functionality to persist\ndata between test runs be aware that we don’t serialize sets anymore.\nThanks Ronny Pfannschmidt for most of the merging work.','provide  through porting',0,'',''),(13063,'pytest','“-r” option now accepts “a” to include all possible reports, similar\nto passing “fEsxXw” explicitly (issue960).\nThanks Abhijeet Kasurde for the PR.','include possible reports similar',0,'',''),(13064,'pytest','“-r” option now accepts “a” to include all possible reports, similar\nto passing “fEsxXw” explicitly (issue960).\nThanks Abhijeet Kasurde for the PR.','pass fesxxw',0,'',''),(13065,'pytest','avoid python3.5 deprecation warnings by introducing version\nspecific inspection helpers, thanks Michael Droettboom.','introduce version specific inspection helpers',0,'',''),(13066,'pytest','fix issue934: when string comparison fails and a diff is too large to display\nwithout passing -vv, still show a few lines of the diff.\nThanks Florian Bruhin for the report and Bruno Oliveira for the PR.','show few lines of diff',0,'',''),(13067,'pytest','fix issue934: when string comparison fails and a diff is too large to display\nwithout passing -vv, still show a few lines of the diff.\nThanks Florian Bruhin for the report and Bruno Oliveira for the PR.','display  without passing',0,'',''),(13068,'pytest','fix issue736: Fix a bug where fixture params would be discarded when combined\nwith parametrization markers.\nThanks to Markus Unterwaditzer for the PR.','fix bug',0,'',''),(13069,'pytest','fix issue736: Fix a bug where fixture params would be discarded when combined\nwith parametrization markers.\nThanks to Markus Unterwaditzer for the PR.','combine  with parametrization markers',0,'',''),(13070,'pytest','fix issue710: introduce ALLOW_UNICODE doctest option: when enabled, the\nu prefix is stripped from unicode strings in expected doctest output. This\nallows doctests which use unicode to run in Python 2 and 3 unchanged.\nThanks Jason R. Coombs for the report and Bruno Oliveira for the PR.','introduce ALLOW_UNICODE doctest option',0,'',''),(13071,'pytest','fix issue710: introduce ALLOW_UNICODE doctest option: when enabled, the\nu prefix is stripped from unicode strings in expected doctest output. This\nallows doctests which use unicode to run in Python 2 and 3 unchanged.\nThanks Jason R. Coombs for the report and Bruno Oliveira for the PR.','run  in Python',0,'',''),(13072,'pytest','fix issue710: introduce ALLOW_UNICODE doctest option: when enabled, the\nu prefix is stripped from unicode strings in expected doctest output. This\nallows doctests which use unicode to run in Python 2 and 3 unchanged.\nThanks Jason R. Coombs for the report and Bruno Oliveira for the PR.','use doctests',0,'',''),(13073,'pytest','parametrize now also generates meaningful test IDs for enum, regex and class\nobjects (as opposed to class instances).\nThanks to Florian Bruhin for the PR.','generate meaningful test ids for enum regex class objects',0,'',''),(13074,'pytest','Add ‘warns’ to assert that warnings are thrown (like ‘raises’).\nThanks to Eric Hunsberger for the PR.','add âwarnsâ',0,'',''),(13075,'pytest','Add ‘warns’ to assert that warnings are thrown (like ‘raises’).\nThanks to Eric Hunsberger for the PR.','throw warnings',0,'',''),(13076,'pytest','fix issue82: avoid loading conftest files from setup.cfg/pytest.ini/tox.ini\nfiles and upwards by default (–confcutdir can still be set to override this).\nThanks Bruno Oliveira for the PR.','load conftest files by default',0,'',''),(13077,'pytest','fix issue82: avoid loading conftest files from setup.cfg/pytest.ini/tox.ini\nfiles and upwards by default (–confcutdir can still be set to override this).\nThanks Bruno Oliveira for the PR.','load conftest files from setup.cfg/pytest.ini/tox.ini files',0,'',''),(13078,'pytest','fix issue82: avoid loading conftest files from setup.cfg/pytest.ini/tox.ini\nfiles and upwards by default (–confcutdir can still be set to override this).\nThanks Bruno Oliveira for the PR.','load conftest files from upwards',0,'',''),(13079,'pytest','fix issue768: docstrings found in python modules were not setting up session\nfixtures. Thanks Jason R. Coombs for reporting and Bruno Oliveira for the PR.','find  in python modules',0,'',''),(13080,'pytest','added tmpdir_factory, a session-scoped fixture that can be used to create\ndirectories under the base temporary directory. Previously this object was\ninstalled as a _tmpdirhandler attribute of the config object, but now it\nis part of the official API and using config._tmpdirhandler is\ndeprecated.\nThanks Bruno Oliveira for the PR.','create directories under base temporary directory',0,'',''),(13081,'pytest','added tmpdir_factory, a session-scoped fixture that can be used to create\ndirectories under the base temporary directory. Previously this object was\ninstalled as a _tmpdirhandler attribute of the config object, but now it\nis part of the official API and using config._tmpdirhandler is\ndeprecated.\nThanks Bruno Oliveira for the PR.','use session-scoped fixture',0,'',''),(13082,'pytest','added tmpdir_factory, a session-scoped fixture that can be used to create\ndirectories under the base temporary directory. Previously this object was\ninstalled as a _tmpdirhandler attribute of the config object, but now it\nis part of the official API and using config._tmpdirhandler is\ndeprecated.\nThanks Bruno Oliveira for the PR.','use config._tmpdirhandler',0,'',''),(13083,'pytest','added tmpdir_factory, a session-scoped fixture that can be used to create\ndirectories under the base temporary directory. Previously this object was\ninstalled as a _tmpdirhandler attribute of the config object, but now it\nis part of the official API and using config._tmpdirhandler is\ndeprecated.\nThanks Bruno Oliveira for the PR.','install object as _ tmpdirhandler attribute',0,'',''),(13084,'pytest','fix issue808: pytest’s internal assertion rewrite hook now implements the\noptional PEP 302 get_data API so tests can access data files next to them.\nThanks xmo-odoo for request and example and Bruno Oliveira for\nthe PR.','implement optional PEP get_data API',0,'',''),(13085,'pytest','fix issue808: pytest’s internal assertion rewrite hook now implements the\noptional PEP 302 get_data API so tests can access data files next to them.\nThanks xmo-odoo for request and example and Bruno Oliveira for\nthe PR.','access data files',0,'',''),(13086,'pytest','rootdir and inifile are now displayed during usage errors to help\nusers diagnose problems such as unexpected ini files which add\nunknown options being picked up by pytest. Thanks to Pavel Savchenko for\nbringing the problem to attention in #821 and Bruno Oliveira for the PR.','add unknown options',0,'',''),(13087,'pytest','rootdir and inifile are now displayed during usage errors to help\nusers diagnose problems such as unexpected ini files which add\nunknown options being picked up by pytest. Thanks to Pavel Savchenko for\nbringing the problem to attention in #821 and Bruno Oliveira for the PR.','add unexpected ini files',0,'',''),(13088,'pytest','rootdir and inifile are now displayed during usage errors to help\nusers diagnose problems such as unexpected ini files which add\nunknown options being picked up by pytest. Thanks to Pavel Savchenko for\nbringing the problem to attention in #821 and Bruno Oliveira for the PR.','display rootdir during usage errors',0,'',''),(13089,'pytest','rootdir and inifile are now displayed during usage errors to help\nusers diagnose problems such as unexpected ini files which add\nunknown options being picked up by pytest. Thanks to Pavel Savchenko for\nbringing the problem to attention in #821 and Bruno Oliveira for the PR.','display inifile during usage errors',0,'',''),(13090,'pytest','Summary bar now is colored yellow for warning\nsituations such as: all tests either were skipped or xpass/xfailed,\nor no tests were run at all (this is a partial fix for issue500).','run tests',0,'',''),(13091,'pytest','fix issue812: pytest now exits with status code 5 in situations where no\ntests were run at all, such as the directory given in the command line does\nnot contain any tests or as result of a command line option filters\nall out all tests (-k for example).\nThanks Eric Siegerman (issue812) and Bruno Oliveira for the PR.','run tests',0,'',''),(13092,'pytest','fix issue812: pytest now exits with status code 5 in situations where no\ntests were run at all, such as the directory given in the command line does\nnot contain any tests or as result of a command line option filters\nall out all tests (-k for example).\nThanks Eric Siegerman (issue812) and Bruno Oliveira for the PR.','run situations',0,'',''),(13093,'pytest','Summary bar now is colored yellow for warning\nsituations such as: all tests either were skipped or xpass/xfailed,\nor no tests were run at all (related to issue500).\nThanks Eric Siegerman.','run tests',0,'',''),(13094,'pytest','New testpaths ini option: list of directories to search for tests\nwhen executing pytest from the root directory. This can be used\nto speed up test collection when a project has well specified directories\nfor tests, being usually more practical than configuring norecursedirs for\nall directories that do not contain tests.\nThanks to Adrian for idea (#694) and Bruno Oliveira for the PR.','execute pytest from root directory',0,'',''),(13095,'pytest','New testpaths ini option: list of directories to search for tests\nwhen executing pytest from the root directory. This can be used\nto speed up test collection when a project has well specified directories\nfor tests, being usually more practical than configuring norecursedirs for\nall directories that do not contain tests.\nThanks to Adrian for idea (#694) and Bruno Oliveira for the PR.','search  for tests',0,'',''),(13096,'pytest','New testpaths ini option: list of directories to search for tests\nwhen executing pytest from the root directory. This can be used\nto speed up test collection when a project has well specified directories\nfor tests, being usually more practical than configuring norecursedirs for\nall directories that do not contain tests.\nThanks to Adrian for idea (#694) and Bruno Oliveira for the PR.','specify directories for tests',0,'',''),(13097,'pytest','New testpaths ini option: list of directories to search for tests\nwhen executing pytest from the root directory. This can be used\nto speed up test collection when a project has well specified directories\nfor tests, being usually more practical than configuring norecursedirs for\nall directories that do not contain tests.\nThanks to Adrian for idea (#694) and Bruno Oliveira for the PR.','configure norecursedirs for directories',0,'',''),(13098,'pytest','Include setup and teardown in junitxml test durations.\nThanks Janne Vanhala.','include setup in junitxml test durations',0,'',''),(13099,'pytest','Include setup and teardown in junitxml test durations.\nThanks Janne Vanhala.','include teardown in junitxml test durations',0,'',''),(13100,'pytest','new option --import-mode to allow to change test module importing\nbehaviour to append to sys.path instead of prepending.  This better allows\nto run test modules against installed versions of a package even if the\npackage under test has the same import root.  In this example:','change test',1,'https://docs.pytest.org/en/7.2.x/changelog.html',''),(13101,'pytest','new option --import-mode to allow to change test module importing\nbehaviour to append to sys.path instead of prepending.  This better allows\nto run test modules against installed versions of a package even if the\npackage under test has the same import root.  In this example:','import behaviour',1,'https://docs.pytest.org/en/7.2.x/changelog.html',''),(13102,'pytest','new option --import-mode to allow to change test module importing\nbehaviour to append to sys.path instead of prepending.  This better allows\nto run test modules against installed versions of a package even if the\npackage under test has the same import root.  In this example:','append  to sys.path',1,'https://docs.pytest.org/en/7.2.x/changelog.html',''),(13103,'pytest','new option --import-mode to allow to change test module importing\nbehaviour to append to sys.path instead of prepending.  This better allows\nto run test modules against installed versions of a package even if the\npackage under test has the same import root.  In this example:','run test modules against installed versions',1,'https://docs.pytest.org/en/7.2.x/changelog.html',''),(13104,'pytest','the tests will run against the installed version\nof pkg_under_test when --import-mode=append is used whereas\nby default they would always pick up the local version.  Thanks Holger Krekel.','run  against installed version',0,'',''),(13105,'pytest','the tests will run against the installed version\nof pkg_under_test when --import-mode=append is used whereas\nby default they would always pick up the local version.  Thanks Holger Krekel.','use import-mode = append',0,'',''),(13106,'pytest','pytester: add method TmpTestdir.delete_loaded_modules(), and call it\nfrom inline_run() to allow temporary modules to be reloaded.\nThanks Eduardo Schettino.','add method TmpTestdir.delete_loaded_modules()',0,'',''),(13107,'pytest','pytester: add method TmpTestdir.delete_loaded_modules(), and call it\nfrom inline_run() to allow temporary modules to be reloaded.\nThanks Eduardo Schettino.','call  from inline_run()',0,'',''),(13108,'pytest','internally refactor pluginmanager API and code so that there\nis a clear distinction between a pytest-agnostic rather simple\npluginmanager and the PytestPluginManager which adds a lot of\nbehaviour, among it handling of the local conftest files.\nIn terms of documented methods this is a backward compatible\nchange but it might still break 3rd party plugins which relied on\ndetails like especially the pluginmanager.add_shutdown() API.\nThanks Holger Krekel.','add lot of behaviour',0,'',''),(13109,'pytest','internally refactor pluginmanager API and code so that there\nis a clear distinction between a pytest-agnostic rather simple\npluginmanager and the PytestPluginManager which adds a lot of\nbehaviour, among it handling of the local conftest files.\nIn terms of documented methods this is a backward compatible\nchange but it might still break 3rd party plugins which relied on\ndetails like especially the pluginmanager.add_shutdown() API.\nThanks Holger Krekel.','add PytestPluginManager of behaviour',0,'',''),(13110,'pytest','internally refactor pluginmanager API and code so that there\nis a clear distinction between a pytest-agnostic rather simple\npluginmanager and the PytestPluginManager which adds a lot of\nbehaviour, among it handling of the local conftest files.\nIn terms of documented methods this is a backward compatible\nchange but it might still break 3rd party plugins which relied on\ndetails like especially the pluginmanager.add_shutdown() API.\nThanks Holger Krekel.','handle  of local conftest files',0,'',''),(13111,'pytest','internally refactor pluginmanager API and code so that there\nis a clear distinction between a pytest-agnostic rather simple\npluginmanager and the PytestPluginManager which adds a lot of\nbehaviour, among it handling of the local conftest files.\nIn terms of documented methods this is a backward compatible\nchange but it might still break 3rd party plugins which relied on\ndetails like especially the pluginmanager.add_shutdown() API.\nThanks Holger Krekel.','break 3rd party plugins',0,'',''),(13112,'pytest','pluginmanagement: introduce pytest.hookimpl and\npytest.hookspec decorators for setting impl/spec\nspecific parameters.  This substitutes the previous\nnow deprecated use of pytest.mark which is meant to\ncontain markers for test functions only.','introduce pytest.hookimpl pytest.hookspec decorators for setting',0,'',''),(13113,'pytest','pluginmanagement: introduce pytest.hookimpl and\npytest.hookspec decorators for setting impl/spec\nspecific parameters.  This substitutes the previous\nnow deprecated use of pytest.mark which is meant to\ncontain markers for test functions only.','set impl/spec specific parameters',0,'',''),(13114,'pytest','fix issue732: properly unregister plugins from any hook calling\nsites allowing to have temporary plugins during test execution.','call sites',0,'',''),(13115,'pytest','speed up pytest’s own test suite considerably by using inprocess\ntests by default (testrun can be modified with –runpytest=subprocess\nto create subprocesses in many places instead).  The main\nAPIs to run pytest in a test is “runpytest()” or “runpytest_subprocess”\nand “runpytest_inprocess” if you need a particular way of running\nthe test.  In all cases you get back a RunResult but the inprocess\none will also have a “reprec” attribute with the recorded events/reports.','use inprocess tests by default',0,'',''),(13116,'pytest','speed up pytest’s own test suite considerably by using inprocess\ntests by default (testrun can be modified with –runpytest=subprocess\nto create subprocesses in many places instead).  The main\nAPIs to run pytest in a test is “runpytest()” or “runpytest_subprocess”\nand “runpytest_inprocess” if you need a particular way of running\nthe test.  In all cases you get back a RunResult but the inprocess\none will also have a “reprec” attribute with the recorded events/reports.','run pytest in test',0,'',''),(13117,'pytest','speed up pytest’s own test suite considerably by using inprocess\ntests by default (testrun can be modified with –runpytest=subprocess\nto create subprocesses in many places instead).  The main\nAPIs to run pytest in a test is “runpytest()” or “runpytest_subprocess”\nand “runpytest_inprocess” if you need a particular way of running\nthe test.  In all cases you get back a RunResult but the inprocess\none will also have a “reprec” attribute with the recorded events/reports.','run test',0,'',''),(13118,'pytest','fix monkeypatch.setattr(“x.y”, raising=False) to actually not raise\nif “y” is not a pre-existing attribute. Thanks Florian Bruhin.','fix monkeypatch.setattr(âx.yâ, raising=False)',0,'',''),(13119,'pytest','fix issue741: make running output from testdir.run copy/pasteable\nThanks Bruno Oliveira.','run output from testdir.run copy/pasteable Thanks bruno oliveira',0,'',''),(13120,'pytest','add a new --noconftest argument which ignores all conftest.py files.','add noconftest argument',0,'',''),(13121,'pytest','add a new --noconftest argument which ignores all conftest.py files.','ignore noconftest argument',0,'',''),(13122,'pytest','add file and line attributes to JUnit-XML output.','add file line attributes to junit-XML output',0,'',''),(13123,'pytest','fix issue714: add ability to apply indirect=True parameter on particular argnames.\nThanks Elizaveta239.','add ability',0,'',''),(13124,'pytest','fix issue714: add ability to apply indirect=True parameter on particular argnames.\nThanks Elizaveta239.','apply indirect true parameter on particular argnames',0,'',''),(13125,'pytest','issue951: add new record_xml_property fixture, that supports logging\nadditional information on xml output. Thanks David Diaz for the PR.','add new record_xml_property fixture',0,'',''),(13126,'pytest','issue951: add new record_xml_property fixture, that supports logging\nadditional information on xml output. Thanks David Diaz for the PR.','support logging additional information on xml output',0,'',''),(13127,'pytest','issue951: add new record_xml_property fixture, that supports logging\nadditional information on xml output. Thanks David Diaz for the PR.','support new record_xml_property fixture on xml output',0,'',''),(13128,'pytest','issue949: paths after normal options (for example -s, -v, etc) are now\nproperly used to discover rootdir and ini files.\nThanks Peter Lauri for the report and Bruno Oliveira for the PR.','use normal options',0,'',''),(13129,'pytest','fix issue855: passing str objects as plugins argument to pytest.main\nis now interpreted as a module name to be imported and registered as a\nplugin, instead of silently having no effect.\nThanks xmo-odoo for the report and Bruno Oliveira for the PR.','pass str objects as plugins argument',0,'',''),(13130,'pytest','fix issue855: passing str objects as plugins argument to pytest.main\nis now interpreted as a module name to be imported and registered as a\nplugin, instead of silently having no effect.\nThanks xmo-odoo for the report and Bruno Oliveira for the PR.','pass str objects to pytest.main',0,'',''),(13131,'pytest','fix issue855: passing str objects as plugins argument to pytest.main\nis now interpreted as a module name to be imported and registered as a\nplugin, instead of silently having no effect.\nThanks xmo-odoo for the report and Bruno Oliveira for the PR.','import  as plugin',0,'',''),(13132,'pytest','fix issue842: applying markers in classes no longer propagate this markers\nto superclasses which also have markers.\nThanks xmo-odoo for the report and Bruno Oliveira for the PR.','apply markers in classes',0,'',''),(13133,'pytest','fix issue833: –fixtures now shows all fixtures of collected test files, instead of just the\nfixtures declared on the first one.\nThanks Florian Bruhin for reporting and Bruno Oliveira for the PR.','show fixtures of collected test files',0,'',''),(13134,'pytest','fix issue833: –fixtures now shows all fixtures of collected test files, instead of just the\nfixtures declared on the first one.\nThanks Florian Bruhin for reporting and Bruno Oliveira for the PR.','show fixtures of collected test files',0,'',''),(13135,'pytest','fix issue863: skipped tests now report the correct reason when a skip/xfail\ncondition is met when using multiple markers.\nThanks Raphael Pierzina for reporting and Bruno Oliveira for the PR.','use multiple markers',0,'',''),(13136,'pytest','optimized tmpdir fixture initialization, which should make test sessions\nfaster (specially when using pytest-xdist). The only visible effect\nis that now pytest uses a subdirectory in the $TEMP directory for all\ndirectories created by this fixture (defaults to $TEMP/pytest-$USER).\nThanks Bruno Oliveira for the PR.','use subdirectory in  directory',0,'',''),(13137,'pytest','fix issue767: pytest.raises value attribute does not contain the exception\ninstance on Python 2.6. Thanks Eric Siegerman for providing the test\ncase and Bruno Oliveira for PR.','provide test case for PR',0,'',''),(13138,'pytest','fix issue767: pytest.raises value attribute does not contain the exception\ninstance on Python 2.6. Thanks Eric Siegerman for providing the test\ncase and Bruno Oliveira for PR.','provide Bruno oliveira for PR',0,'',''),(13139,'pytest','fix issue718: failed to create representation of sets containing unsortable\nelements in python 2. Thanks Edison Gustavo Muenz.','create representation of sets',0,'',''),(13140,'pytest','fix issue553: properly handling inspect.getsourcelines failures in\nFixtureLookupError which would lead to an internal error,\nobfuscating the original problem. Thanks talljosh for initial\ndiagnose/patch and Bruno Oliveira for final patch.','handle inspect.getsourcelines failures in FixtureLookupError',0,'',''),(13141,'pytest','fix issue660: properly report scope-mismatch-access errors\nindependently from ordering of fixture arguments.  Also\navoid the pytest internal traceback which does not provide\ninformation to the user. Thanks Holger Krekel.','order  of fixture arguments',0,'',''),(13142,'pytest','streamlined and documented release process.  Also all versions\n(in setup.py and documentation generation) are now read\nfrom _pytest/__init__.py. Thanks Holger Krekel.','read versions from _pytest/__init__.py. Holger krekel',0,'',''),(13143,'pytest','fixed docs to remove the notion that yield-fixtures are experimental.\nThey are here to stay :)  Thanks Bruno Oliveira.','remove notion',0,'',''),(13144,'pytest','Support building wheels by using environment markers for the\nrequirements.  Thanks Ionel Maries Cristian.','use environment',0,'',''),(13145,'pytest','fixed regression to 2.6.4 which surfaced e.g. in lost stdout capture printing\nwhen tests raised SystemExit. Thanks Holger Krekel.','raise SystemExit',0,'',''),(13146,'pytest','reintroduced _pytest fixture of the pytester plugin which is used\nat least by pytest-xdist.','use fixture of pytester plugin',0,'',''),(13147,'pytest','fix issue616: conftest.py files and their contained fixtures are now\nproperly considered for visibility, independently from the exact\ncurrent working directory and test arguments that are used.\nMany thanks to Eric Siegerman and his PR235 which contains\nsystematic tests for conftest visibility and now passes.\nThis change also introduces the concept of a rootdir which\nis printed as a new pytest header and documented in the pytest\ncustomize web page.','use test arguments',0,'',''),(13148,'pytest','fix issue616: conftest.py files and their contained fixtures are now\nproperly considered for visibility, independently from the exact\ncurrent working directory and test arguments that are used.\nMany thanks to Eric Siegerman and his PR235 which contains\nsystematic tests for conftest visibility and now passes.\nThis change also introduces the concept of a rootdir which\nis printed as a new pytest header and documented in the pytest\ncustomize web page.','pass pr235',0,'',''),(13149,'pytest','fix issue616: conftest.py files and their contained fixtures are now\nproperly considered for visibility, independently from the exact\ncurrent working directory and test arguments that are used.\nMany thanks to Eric Siegerman and his PR235 which contains\nsystematic tests for conftest visibility and now passes.\nThis change also introduces the concept of a rootdir which\nis printed as a new pytest header and documented in the pytest\ncustomize web page.','introduce concept of rootdir',0,'',''),(13150,'pytest','fix issue616: conftest.py files and their contained fixtures are now\nproperly considered for visibility, independently from the exact\ncurrent working directory and test arguments that are used.\nMany thanks to Eric Siegerman and his PR235 which contains\nsystematic tests for conftest visibility and now passes.\nThis change also introduces the concept of a rootdir which\nis printed as a new pytest header and documented in the pytest\ncustomize web page.','print rootdir as new pytest header',0,'',''),(13151,'pytest','fix issue616: conftest.py files and their contained fixtures are now\nproperly considered for visibility, independently from the exact\ncurrent working directory and test arguments that are used.\nMany thanks to Eric Siegerman and his PR235 which contains\nsystematic tests for conftest visibility and now passes.\nThis change also introduces the concept of a rootdir which\nis printed as a new pytest header and documented in the pytest\ncustomize web page.','document rootdir in pytest customize web page',0,'',''),(13152,'pytest','change reporting of “diverted” tests, i.e. tests that are collected\nin one file but actually come from another (e.g. when tests in a test class\ncome from a base class in a different file).  We now show the nodeid\nand indicate via a postfix the other file.','change reporting of diverted tests',0,'',''),(13153,'pytest','change reporting of “diverted” tests, i.e. tests that are collected\nin one file but actually come from another (e.g. when tests in a test class\ncome from a base class in a different file).  We now show the nodeid\nand indicate via a postfix the other file.','show nodeid',0,'',''),(13154,'pytest','change reporting of “diverted” tests, i.e. tests that are collected\nin one file but actually come from another (e.g. when tests in a test class\ncome from a base class in a different file).  We now show the nodeid\nand indicate via a postfix the other file.','show other file',0,'',''),(13155,'pytest','add ability to set command line options by environment variable PYTEST_ADDOPTS.','add ability',0,'',''),(13156,'pytest','add ability to set command line options by environment variable PYTEST_ADDOPTS.','set command line options by environment variable PYTEST_ADDOPTS',0,'',''),(13157,'pytest','fix issue615: assertion rewriting did not correctly escape % signs\nwhen formatting boolean operations, which tripped over mixing\nbooleans with modulo operators.  Thanks to Tom Viner for the report,\ntriaging and fix.','format boolean operations',0,'',''),(13158,'pytest','implement issue351: add ability to specify parametrize ids as a callable\nto generate custom test ids.  Thanks Brianna Laugher for the idea and\nimplementation.','implement issue351',0,'',''),(13159,'pytest','implement issue351: add ability to specify parametrize ids as a callable\nto generate custom test ids.  Thanks Brianna Laugher for the idea and\nimplementation.','add ability',0,'',''),(13160,'pytest','implement issue351: add ability to specify parametrize ids as a callable\nto generate custom test ids.  Thanks Brianna Laugher for the idea and\nimplementation.','specify parametrize ids as callable test ids',0,'',''),(13161,'pytest','implement issue351: add ability to specify parametrize ids as a callable\nto generate custom test ids.  Thanks Brianna Laugher for the idea and\nimplementation.','generate custom',0,'',''),(13162,'pytest','introduce and document new hookwrapper mechanism useful for plugins\nwhich want to wrap the execution of certain hooks for their purposes.\nThis supersedes the undocumented __multicall__ protocol which\npytest itself and some external plugins use.  Note that pytest-2.8\nis scheduled to drop supporting the old __multicall__\nand only support the hookwrapper protocol.','introduce new hookwrapper mechanism',0,'',''),(13163,'pytest','introduce and document new hookwrapper mechanism useful for plugins\nwhich want to wrap the execution of certain hooks for their purposes.\nThis supersedes the undocumented __multicall__ protocol which\npytest itself and some external plugins use.  Note that pytest-2.8\nis scheduled to drop supporting the old __multicall__\nand only support the hookwrapper protocol.','document new hookwrapper mechanism',0,'',''),(13164,'pytest','introduce and document new hookwrapper mechanism useful for plugins\nwhich want to wrap the execution of certain hooks for their purposes.\nThis supersedes the undocumented __multicall__ protocol which\npytest itself and some external plugins use.  Note that pytest-2.8\nis scheduled to drop supporting the old __multicall__\nand only support the hookwrapper protocol.','wrap execution of certain hooks',0,'',''),(13165,'pytest','introduce and document new hookwrapper mechanism useful for plugins\nwhich want to wrap the execution of certain hooks for their purposes.\nThis supersedes the undocumented __multicall__ protocol which\npytest itself and some external plugins use.  Note that pytest-2.8\nis scheduled to drop supporting the old __multicall__\nand only support the hookwrapper protocol.','wrap execution for purposes',0,'',''),(13166,'pytest','introduce and document new hookwrapper mechanism useful for plugins\nwhich want to wrap the execution of certain hooks for their purposes.\nThis supersedes the undocumented __multicall__ protocol which\npytest itself and some external plugins use.  Note that pytest-2.8\nis scheduled to drop supporting the old __multicall__\nand only support the hookwrapper protocol.','support old __multicall__',0,'',''),(13167,'pytest','introduce and document new hookwrapper mechanism useful for plugins\nwhich want to wrap the execution of certain hooks for their purposes.\nThis supersedes the undocumented __multicall__ protocol which\npytest itself and some external plugins use.  Note that pytest-2.8\nis scheduled to drop supporting the old __multicall__\nand only support the hookwrapper protocol.','support hookwrapper protocol',0,'',''),(13168,'pytest','use hookwrapper mechanism in builtin pytest plugins.','use hookwrapper mechanism in builtin pytest plugins',0,'',''),(13169,'pytest','add a doctest ini option for doctest flags, thanks Holger Peters.','add doctest ini option for doctest flags',0,'',''),(13170,'pytest','add note to docs that if you want to mark a parameter and the\nparameter is a callable, you also need to pass in a reason to disambiguate\nit from the “decorator” case.  Thanks Tom Viner.','add note to docs',0,'',''),(13171,'pytest','add note to docs that if you want to mark a parameter and the\nparameter is a callable, you also need to pass in a reason to disambiguate\nit from the “decorator” case.  Thanks Tom Viner.','mark parameter',0,'',''),(13172,'pytest','add note to docs that if you want to mark a parameter and the\nparameter is a callable, you also need to pass in a reason to disambiguate\nit from the “decorator” case.  Thanks Tom Viner.','pass  in reason',0,'',''),(13173,'pytest','“python_classes” and “python_functions” options now support glob-patterns\nfor test discovery, as discussed in issue600. Thanks Ldiary Translations.','support glob-patterns for test discovery',0,'',''),(13174,'pytest','allow to override parametrized fixtures with non-parametrized ones and vice versa (bubenkoff).','override parametrized fixtures',0,'',''),(13175,'pytest','fix issue463: raise specific error for ‘parameterize’ misspelling (pfctdayelise).','raise specific error for âparameterizeâ misspelling',0,'',''),(13176,'pytest','On failure, the sys.last_value, sys.last_type and\nsys.last_traceback are set, so that a user can inspect the error\nvia postmortem debugging (almarklein).','set sys.last_value on failure',0,'',''),(13177,'pytest','On failure, the sys.last_value, sys.last_type and\nsys.last_traceback are set, so that a user can inspect the error\nvia postmortem debugging (almarklein).','set sys.last_type on failure',0,'',''),(13178,'pytest','On failure, the sys.last_value, sys.last_type and\nsys.last_traceback are set, so that a user can inspect the error\nvia postmortem debugging (almarklein).','set sys.last_traceback on failure',0,'',''),(13179,'pytest','Improve assertion failure reporting on iterables, by using ndiff and\npprint.','use ndiff',0,'',''),(13180,'pytest','Improve assertion failure reporting on iterables, by using ndiff and\npprint.','use pprint',0,'',''),(13181,'pytest','removed outdated japanese docs from source tree.','remove outdated japanese docs from source tree',0,'',''),(13182,'pytest','fix issue620: add explanation in the –genscript target about what\nthe binary blob means. Thanks Dinu Gherman.','add explanation in â genscript target',0,'',''),(13183,'pytest','Fix infinite recursion bug when pickling capture.EncodedFile, thanks\nUwe Schmitt.','fix infinite recursion bug',0,'',''),(13184,'pytest','fix issue589: fix bad interaction with numpy and others when showing\nexceptions.  Check for precise “maximum recursion depth exceed” exception\ninstead of presuming any RuntimeError is that one (implemented in py\ndep).  Thanks Charles Cloud for analysing the issue.','fix bad interaction with numpy',0,'',''),(13185,'pytest','fix issue589: fix bad interaction with numpy and others when showing\nexceptions.  Check for precise “maximum recursion depth exceed” exception\ninstead of presuming any RuntimeError is that one (implemented in py\ndep).  Thanks Charles Cloud for analysing the issue.','fix bad interaction with others',0,'',''),(13186,'pytest','fix issue589: fix bad interaction with numpy and others when showing\nexceptions.  Check for precise “maximum recursion depth exceed” exception\ninstead of presuming any RuntimeError is that one (implemented in py\ndep).  Thanks Charles Cloud for analysing the issue.','show exceptions',0,'',''),(13187,'pytest','fix issue589: fix bad interaction with numpy and others when showing\nexceptions.  Check for precise “maximum recursion depth exceed” exception\ninstead of presuming any RuntimeError is that one (implemented in py\ndep).  Thanks Charles Cloud for analysing the issue.','check  for precise maximum recursion depth',0,'',''),(13188,'pytest','fix conftest related fixture visibility issue: when running with a\nCWD outside of a test package pytest would get fixture discovery wrong.\nThanks to Wolfgang Schnerring for figuring out a reproducible example.','fix conftest related fixture visibility issue',0,'',''),(13189,'pytest','fix conftest related fixture visibility issue: when running with a\nCWD outside of a test package pytest would get fixture discovery wrong.\nThanks to Wolfgang Schnerring for figuring out a reproducible example.','run  with CWD outside',0,'',''),(13190,'pytest','Introduce pytest_enter_pdb hook (needed e.g. by pytest_timeout to cancel the\ntimeout when interactively entering pdb).  Thanks Wolfgang Schnerring.','introduce pytest_enter_pdb hook',0,'',''),(13191,'pytest','check xfail/skip also with non-python function test items. Thanks\nFloris Bruynooghe.','check xfail/skip with non-python function test items',0,'',''),(13192,'pytest','Added function pytest.freeze_includes(), which makes it easy to embed\npytest into executables using tools like cx_freeze.\nSee docs for examples and rationale. Thanks Bruno Oliveira.','use tools like cx_freeze',0,'',''),(13193,'pytest','fix issue560: correctly display code if an “else:” or “finally:” is\nfollowed by statements on the same line.','display code',0,'',''),(13194,'pytest','Implement issue549: user-provided assertion messages now no longer\nreplace the py.test introspection message but are shown in addition\nto them.','replace py.test introspection message',0,'',''),(13195,'pytest','Implement issue549: user-provided assertion messages now no longer\nreplace the py.test introspection message but are shown in addition\nto them.','show user-provided assertion messages',0,'',''),(13196,'pytest','No longer show line numbers in the –verbose output, the output is now\npurely the nodeid.  The line number is still shown in failure reports.\nThanks Floris Bruynooghe.','show line number in failure reports',0,'',''),(13197,'pytest','fix issue555: add “errors” attribute to capture-streams to satisfy\nsome distutils and possibly other code accessing sys.stdout.errors.','access sys.stdout.errors.',0,'',''),(13198,'pytest','fix issue547 capsys/capfd also work when output capturing (“-s”) is disabled.','disable output capturing',0,'',''),(13199,'pytest','fix integration of pytest with unittest.mock.patch decorator when\nit uses the “new” argument.  Thanks Nicolas Delaby for test and PR.','fix integration with unittest.mock.patch decorator',0,'',''),(13200,'pytest','fix integration of pytest with unittest.mock.patch decorator when\nit uses the “new” argument.  Thanks Nicolas Delaby for test and PR.','fix integration of pytest',0,'',''),(13201,'pytest','fix integration of pytest with unittest.mock.patch decorator when\nit uses the “new” argument.  Thanks Nicolas Delaby for test and PR.','use new argument',0,'',''),(13202,'pytest','fix issue with detecting conftest files if the arguments contain\n“::” node id specifications (copy pasted from “-v” output)','fix issue with detecting',0,'',''),(13203,'pytest','fix issue544 by only removing “@NUM” at the end of “::” separated parts\nand if the part has a “.py” extension','fix  by removing',0,'',''),(13204,'pytest','fix issue544 by only removing “@NUM” at the end of “::” separated parts\nand if the part has a “.py” extension','remove @NUM at end',0,'',''),(13205,'pytest','don’t use py.std import helper, rather import things directly.\nThanks Bruno Oliveira.','use py.std import helper',0,'',''),(13206,'pytest','Cache exceptions from fixtures according to their scope (issue 467).','cache exceptions from fixtures',0,'',''),(13207,'pytest','fix issue537: Avoid importing old assertion reinterpretation code by default.','import old assertion reinterpretation code',0,'',''),(13208,'pytest','fix issue364: shorten and enhance tracebacks representation by default.\nThe new “–tb=auto” option (default) will only display long tracebacks\nfor the first and last entry.  You can get the old behaviour of printing\nall entries as long entries with “–tb=long”.  Also short entries by\ndefault are now printed very similarly to “–tb=native” ones.','shorten tracebacks representation by default',0,'',''),(13209,'pytest','fix issue364: shorten and enhance tracebacks representation by default.\nThe new “–tb=auto” option (default) will only display long tracebacks\nfor the first and last entry.  You can get the old behaviour of printing\nall entries as long entries with “–tb=long”.  Also short entries by\ndefault are now printed very similarly to “–tb=native” ones.','display long tracebacks for first last entry',0,'',''),(13210,'pytest','fix issue364: shorten and enhance tracebacks representation by default.\nThe new “–tb=auto” option (default) will only display long tracebacks\nfor the first and last entry.  You can get the old behaviour of printing\nall entries as long entries with “–tb=long”.  Also short entries by\ndefault are now printed very similarly to “–tb=native” ones.','get old behaviour of printing',0,'',''),(13211,'pytest','fix issue364: shorten and enhance tracebacks representation by default.\nThe new “–tb=auto” option (default) will only display long tracebacks\nfor the first and last entry.  You can get the old behaviour of printing\nall entries as long entries with “–tb=long”.  Also short entries by\ndefault are now printed very similarly to “–tb=native” ones.','print entries',0,'',''),(13212,'pytest','fix issue364: shorten and enhance tracebacks representation by default.\nThe new “–tb=auto” option (default) will only display long tracebacks\nfor the first and last entry.  You can get the old behaviour of printing\nall entries as long entries with “–tb=long”.  Also short entries by\ndefault are now printed very similarly to “–tb=native” ones.','print short entries by default',0,'',''),(13213,'pytest','change -v output to include full node IDs of tests.  Users can copy\na node ID from a test run, including line number, and use it as a\npositional argument in order to run only a single test.','include full node ids of tests',0,'',''),(13214,'pytest','change -v output to include full node IDs of tests.  Users can copy\na node ID from a test run, including line number, and use it as a\npositional argument in order to run only a single test.','use  as positional argument',0,'',''),(13215,'pytest','change -v output to include full node IDs of tests.  Users can copy\na node ID from a test run, including line number, and use it as a\npositional argument in order to run only a single test.','run single test',0,'',''),(13216,'pytest','fix issue 475: fail early and comprehensible if calling\npytest.raises with wrong exception type.','fix issue early comprehensible',0,'',''),(13217,'pytest','fix issue 475: fail early and comprehensible if calling\npytest.raises with wrong exception type.','call pytest.raises with wrong exception type',0,'',''),(13218,'pytest','cleanup setup.py a bit and specify supported versions. Thanks Jurko\nGospodnetic for the PR.','support versions',0,'',''),(13219,'pytest','change XPASS colour to yellow rather then red when tests are run\nwith -v.','change XPASS colour',0,'',''),(13220,'pytest','change XPASS colour to yellow rather then red when tests are run\nwith -v.','run tests',0,'',''),(13221,'pytest','internal new warning system: pytest will now produce warnings when\nit detects oddities in your test collection or execution.\nWarnings are ultimately sent to a new pytest_logwarning hook which is\ncurrently only implemented by the terminal plugin which displays\nwarnings in the summary line and shows more details when -rw (report on\nwarnings) is specified.','produce warnings',0,'',''),(13222,'pytest','internal new warning system: pytest will now produce warnings when\nit detects oddities in your test collection or execution.\nWarnings are ultimately sent to a new pytest_logwarning hook which is\ncurrently only implemented by the terminal plugin which displays\nwarnings in the summary line and shows more details when -rw (report on\nwarnings) is specified.','display warnings in summary line',0,'',''),(13223,'pytest','internal new warning system: pytest will now produce warnings when\nit detects oddities in your test collection or execution.\nWarnings are ultimately sent to a new pytest_logwarning hook which is\ncurrently only implemented by the terminal plugin which displays\nwarnings in the summary line and shows more details when -rw (report on\nwarnings) is specified.','display terminal plugin in summary line',0,'',''),(13224,'pytest','internal new warning system: pytest will now produce warnings when\nit detects oddities in your test collection or execution.\nWarnings are ultimately sent to a new pytest_logwarning hook which is\ncurrently only implemented by the terminal plugin which displays\nwarnings in the summary line and shows more details when -rw (report on\nwarnings) is specified.','show more details',0,'',''),(13225,'pytest','internal new warning system: pytest will now produce warnings when\nit detects oddities in your test collection or execution.\nWarnings are ultimately sent to a new pytest_logwarning hook which is\ncurrently only implemented by the terminal plugin which displays\nwarnings in the summary line and shows more details when -rw (report on\nwarnings) is specified.','show terminal plugin',0,'',''),(13226,'pytest','internal new warning system: pytest will now produce warnings when\nit detects oddities in your test collection or execution.\nWarnings are ultimately sent to a new pytest_logwarning hook which is\ncurrently only implemented by the terminal plugin which displays\nwarnings in the summary line and shows more details when -rw (report on\nwarnings) is specified.','send warnings to new pytest_logwarning hook',0,'',''),(13227,'pytest','internal new warning system: pytest will now produce warnings when\nit detects oddities in your test collection or execution.\nWarnings are ultimately sent to a new pytest_logwarning hook which is\ncurrently only implemented by the terminal plugin which displays\nwarnings in the summary line and shows more details when -rw (report on\nwarnings) is specified.','implement new pytest_logwarning hook',0,'',''),(13228,'pytest','internal new warning system: pytest will now produce warnings when\nit detects oddities in your test collection or execution.\nWarnings are ultimately sent to a new pytest_logwarning hook which is\ncurrently only implemented by the terminal plugin which displays\nwarnings in the summary line and shows more details when -rw (report on\nwarnings) is specified.','specify rw',0,'',''),(13229,'pytest','change skips into warnings for test classes with an __init__ and\ncallables in test modules which look like a test but are not functions.','skip  into warnings',0,'',''),(13230,'pytest','change skips into warnings for test classes with an __init__ and\ncallables in test modules which look like a test but are not functions.','skip  with __init__',0,'',''),(13231,'pytest','change skips into warnings for test classes with an __init__ and\ncallables in test modules which look like a test but are not functions.','skip  with callables',0,'',''),(13232,'pytest','fix issue436: improved finding of initial conftest files from command\nline arguments by using the result of parse_known_args rather than\nthe previous flaky heuristics.  Thanks Marc Abramowitz for tests\nand initial fixing approaches in this area.','use result of parse_known_args',0,'',''),(13233,'pytest','fix issue436: improved finding of initial conftest files from command\nline arguments by using the result of parse_known_args rather than\nthe previous flaky heuristics.  Thanks Marc Abramowitz for tests\nand initial fixing approaches in this area.','use previous flaky heuristics of parse_known_args',0,'',''),(13234,'pytest','fix issue #479: properly handle nose/unittest(2) SkipTest exceptions\nduring collection/loading of test modules.  Thanks to Marc Schlaich\nfor the complete PR.','handle nose/unittest(2) SkipTest exceptions during collection/loading of test modules',0,'',''),(13235,'pytest','fix issue490: include pytest_load_initial_conftests in documentation\nand improve docstring.','include pytest_load_initial_conftests in documentation',0,'',''),(13236,'pytest','fix issue472: clarify that pytest.config.getvalue() cannot work\nif it’s triggered ahead of command line parsing.','trigger  ahead_of command line parsing',0,'',''),(13237,'pytest','improve example for pytest integration with “python setup.py test”\nwhich now has a generic “-a” or “–pytest-args” option where you\ncan pass additional options as a quoted string.  Thanks Trevor Bekolay.','pass additional options as quoted string',0,'',''),(13238,'pytest','improve example for pytest integration with “python setup.py test”\nwhich now has a generic “-a” or “–pytest-args” option where you\ncan pass additional options as a quoted string.  Thanks Trevor Bekolay.','pass a â pytest-args option as quoted string',0,'',''),(13239,'pytest','simplified internal capturing mechanism and made it more robust\nagainst tests or setups changing FD1/FD2, also better integrated\nnow with pytest.pdb() in single tests.','change fd1/fd2 integrated with pytest.pdb()',0,'',''),(13240,'pytest','simplified internal capturing mechanism and made it more robust\nagainst tests or setups changing FD1/FD2, also better integrated\nnow with pytest.pdb() in single tests.','change fd1/fd2 integrated in single tests',0,'',''),(13241,'pytest','fix issue493: don’t run tests in doc directory with python setup.py test\n(use tox -e doctesting for that)','run tests with python setup.py test',0,'',''),(13242,'pytest','fix issue493: don’t run tests in doc directory with python setup.py test\n(use tox -e doctesting for that)','run tests in doc directory',0,'',''),(13243,'pytest','work a bit harder to break reference cycles when catching exceptions.\nThanks Jurko Gospodnetic.','break reference cycles',0,'',''),(13244,'pytest','work a bit harder to break reference cycles when catching exceptions.\nThanks Jurko Gospodnetic.','catch exceptions',0,'',''),(13245,'pytest','fix issue443: fix skip examples to use proper comparison.  Thanks Alex\nGroenholm.','fix skip examples',0,'',''),(13246,'pytest','fix issue443: fix skip examples to use proper comparison.  Thanks Alex\nGroenholm.','use proper comparison',0,'',''),(13247,'pytest','support nose-style __test__ attribute on modules, classes and\nfunctions, including unittest-style Classes.  If set to False, the\ntest will not be collected.','set  to false',0,'',''),(13248,'pytest','fix issue409 – better interoperate with cx_freeze by not\ntrying to import from collections.abc which causes problems\nfor py27/cx_freeze.  Thanks Wolfgang L. for reporting and tracking it down.','import  from collections.abc',0,'',''),(13249,'pytest','fix issue413: exceptions with unicode attributes are now printed\ncorrectly also on python2 and with pytest-xdist runs. (the fix\nrequires py-1.4.20)','print exceptions with pytest-xdist runs',0,'',''),(13250,'pytest','fix issue413: exceptions with unicode attributes are now printed\ncorrectly also on python2 and with pytest-xdist runs. (the fix\nrequires py-1.4.20)','print exceptions with unicode attributes',0,'',''),(13251,'pytest','fix issue429: comparing byte strings with non-ascii chars in assert\nexpressions now work better.  Thanks Floris Bruynooghe.','compare byte strings with non-ascii chars',0,'',''),(13252,'pytest','Allow parameterized fixtures to specify the ID of the parameters by\nadding an ids argument to pytest.fixture() and pytest.yield_fixture().\nThanks Floris Bruynooghe.','specify ID by adding',0,'',''),(13253,'pytest','Allow parameterized fixtures to specify the ID of the parameters by\nadding an ids argument to pytest.fixture() and pytest.yield_fixture().\nThanks Floris Bruynooghe.','specify ID of parameters',0,'',''),(13254,'pytest','Allow parameterized fixtures to specify the ID of the parameters by\nadding an ids argument to pytest.fixture() and pytest.yield_fixture().\nThanks Floris Bruynooghe.','add ids argument to pytest.fixture() pytest.yield_fixture(). thanks Floris bruynooghe',0,'',''),(13255,'pytest','fix issue404 by always using the binary xml escape in the junitxml\nplugin.  Thanks Ronny Pfannschmidt.','use binary xml escape in junitxml plugin',0,'',''),(13256,'pytest','simplified and fixed implementation for calling finalizers when\nparametrized fixtures or function arguments are involved.  finalization\nis now performed lazily at setup time instead of in the “teardown phase”.\nWhile this might sound odd at first, it helps to ensure that we are\ncorrectly handling setup/teardown even in complex code.  User-level code\nshould not be affected unless it’s implementing the pytest_runtest_teardown\nhook and expecting certain fixture instances are torn down within (very\nunlikely and would have been unreliable anyway).','perform finalization at setup time',0,'',''),(13257,'pytest','simplified and fixed implementation for calling finalizers when\nparametrized fixtures or function arguments are involved.  finalization\nis now performed lazily at setup time instead of in the “teardown phase”.\nWhile this might sound odd at first, it helps to ensure that we are\ncorrectly handling setup/teardown even in complex code.  User-level code\nshould not be affected unless it’s implementing the pytest_runtest_teardown\nhook and expecting certain fixture instances are torn down within (very\nunlikely and would have been unreliable anyway).','perform finalization in teardown phase',0,'',''),(13258,'pytest','simplified and fixed implementation for calling finalizers when\nparametrized fixtures or function arguments are involved.  finalization\nis now performed lazily at setup time instead of in the “teardown phase”.\nWhile this might sound odd at first, it helps to ensure that we are\ncorrectly handling setup/teardown even in complex code.  User-level code\nshould not be affected unless it’s implementing the pytest_runtest_teardown\nhook and expecting certain fixture instances are torn down within (very\nunlikely and would have been unreliable anyway).','handle setup/teardown in complex code',0,'',''),(13259,'pytest','simplified and fixed implementation for calling finalizers when\nparametrized fixtures or function arguments are involved.  finalization\nis now performed lazily at setup time instead of in the “teardown phase”.\nWhile this might sound odd at first, it helps to ensure that we are\ncorrectly handling setup/teardown even in complex code.  User-level code\nshould not be affected unless it’s implementing the pytest_runtest_teardown\nhook and expecting certain fixture instances are torn down within (very\nunlikely and would have been unreliable anyway).','implement pytest_runtest_teardown hook',0,'',''),(13260,'pytest','PR90: add –color=yes|no|auto option to force terminal coloring\nmode (“auto” is default).  Thanks Marc Abramowitz.','force coloring mode',0,'',''),(13261,'pytest','fix issue319 - correctly show unicode in assertion errors.  Many\nthanks to Floris Bruynooghe for the complete PR.  Also means\nwe depend on py>=1.4.19 now.','show unicode in assertion errors',0,'',''),(13262,'pytest','fix issue396 - correctly sort and finalize class-scoped parametrized\ntests independently from number of methods on the class.','sort class-scoped parametrized tests from number',0,'',''),(13263,'pytest','close issue240 - document precisely how pytest module importing\nworks, discuss the two common test directory layouts, and how it\ninteracts with PEP 420-namespace packages.','import works',0,'',''),(13264,'pytest','fix issue244 by implementing special index for parameters to only use\nindices for paramentrized test ids','fix  by implementing',0,'',''),(13265,'pytest','fix issue244 by implementing special index for parameters to only use\nindices for paramentrized test ids','implement special index for parameters',0,'',''),(13266,'pytest','fix issue244 by implementing special index for parameters to only use\nindices for paramentrized test ids','use indices for paramentrized test ids',0,'',''),(13267,'pytest','fix issue287 by running all finalizers but saving the exception\nfrom the first failing finalizer and re-raising it so teardown will\nstill have failed.  We reraise the first failing exception because\nit might be the cause for other finalizers to fail.','fix  by running',0,'',''),(13268,'pytest','fix issue287 by running all finalizers but saving the exception\nfrom the first failing finalizer and re-raising it so teardown will\nstill have failed.  We reraise the first failing exception because\nit might be the cause for other finalizers to fail.','fix  by saving',0,'',''),(13269,'pytest','fix issue287 by running all finalizers but saving the exception\nfrom the first failing finalizer and re-raising it so teardown will\nstill have failed.  We reraise the first failing exception because\nit might be the cause for other finalizers to fail.','run finalizers',0,'',''),(13270,'pytest','fix issue287 by running all finalizers but saving the exception\nfrom the first failing finalizer and re-raising it so teardown will\nstill have failed.  We reraise the first failing exception because\nit might be the cause for other finalizers to fail.','save exception from first failing finalizer',0,'',''),(13271,'pytest','fix ordering when mock.patch or other standard decorator-wrappings\nare used with test methods.  This fixues issue346 and should\nhelp with random “xdist” collection failures.  Thanks to\nRonny Pfannschmidt and Donald Stufft for helping to isolate it.','use mock.patch with test methods',0,'',''),(13272,'pytest','fix ordering when mock.patch or other standard decorator-wrappings\nare used with test methods.  This fixues issue346 and should\nhelp with random “xdist” collection failures.  Thanks to\nRonny Pfannschmidt and Donald Stufft for helping to isolate it.','use other standard decorator-wrappings with test methods',0,'',''),(13273,'pytest','fix issue357 - special case “-k” expressions to allow for\nfiltering with simple strings that are not valid python expressions.\nExamples: “-k 1.3” matches all tests parametrized with 1.3.\n“-k None” filters all tests that have “None” in their name\nand conversely “-k ‘not None’”.\nPreviously these examples would raise syntax errors.','match tests',0,'',''),(13274,'pytest','fix issue357 - special case “-k” expressions to allow for\nfiltering with simple strings that are not valid python expressions.\nExamples: “-k 1.3” matches all tests parametrized with 1.3.\n“-k None” filters all tests that have “None” in their name\nand conversely “-k ‘not None’”.\nPreviously these examples would raise syntax errors.','raise syntax errors',0,'',''),(13275,'pytest','fix issue384 by removing the trial support code\nsince the unittest compat enhancements allow\ntrial to handle it on its own','fix  by removing',0,'',''),(13276,'pytest','fix issue384 by removing the trial support code\nsince the unittest compat enhancements allow\ntrial to handle it on its own','remove trial support code',0,'',''),(13277,'pytest','don’t hide an ImportError when importing a plugin produces one.\nfixes issue375.','hide ImportError',0,'',''),(13278,'pytest','don’t hide an ImportError when importing a plugin produces one.\nfixes issue375.','import plugin',0,'',''),(13279,'pytest','fix issue275 - allow usefixtures and autouse fixtures\nfor running doctest text files.','run doctest text files',0,'',''),(13280,'pytest','fix pexpect-3.0 compatibility for pytest’s own tests.\n(fixes issue386)','fix pexpect-3 compatibility for own tests',0,'',''),(13281,'pytest','fix unicode handling with new monkeypatch.setattr(import_path, value)\nAPI.  Thanks Rob Dennis.  Fixes issue371.','fix unicode handling with new monkeypatch.setattr(import_path, value) API',0,'',''),(13282,'pytest','fix unicode handling with junitxml, fixes issue368.','fix unicode handling with junitxml fixes issue368',0,'',''),(13283,'pytest','In assertion rewriting mode on Python 2, fix the detection of coding\ncookies. See issue #330.','fix detection in assertion rewriting mode',0,'',''),(13284,'pytest','In assertion rewriting mode on Python 2, fix the detection of coding\ncookies. See issue #330.','fix detection of coding cookies',0,'',''),(13285,'pytest','would not work correctly because pytest assumes @pytest.mark.some\ngets a function to be decorated already.  We now at least detect if this\narg is a lambda and thus the example will work.  Thanks Alex Gaynor\nfor bringing it up.','get function',0,'',''),(13286,'pytest','xfail a test on pypy that checks wrong encoding/ascii (pypy does\nnot error out). fixes issue385.','check wrong encoding/ascii on pypy',0,'',''),(13287,'pytest','xfail a test on pypy that checks wrong encoding/ascii (pypy does\nnot error out). fixes issue385.','check test on pypy',0,'',''),(13288,'pytest','fix issue221 - handle importing of namespace-package with no\n__init__.py properly.','import  with __init__.py',0,'',''),(13289,'pytest','fix issue221 - handle importing of namespace-package with no\n__init__.py properly.','import  of namespace-package',0,'',''),(13290,'pytest','refactor internal FixtureRequest handling to avoid monkeypatching.\nOne of the positive user-facing effects is that the “request” object\ncan now be used in closures.','use request object in closures',0,'',''),(13291,'pytest','fix issue377 by clarifying in the nose-compat docs that pytest\ndoes not duplicate the unittest-API into the “plain” namespace.','fix  by clarifying',0,'',''),(13292,'pytest','fix verbose reporting for @mock’d test functions','test functions',0,'',''),(13293,'pytest','on Windows require colorama and a newer py lib so that py.io.TerminalWriter()\nnow uses colorama instead of its own ctypes hacks. (fixes issue365)\nthanks Paul Moore for bringing it up.','use colorama instead_of own ctypes hacks',0,'',''),(13294,'pytest','fix “-k” matching of tests where “repr” and “attr” and other names would\ncause wrong matches because of an internal implementation quirk\n(don’t ask) which is now properly implemented. fixes issue345.','match  because_of internal implementation quirk',0,'',''),(13295,'pytest','fix “-k” matching of tests where “repr” and “attr” and other names would\ncause wrong matches because of an internal implementation quirk\n(don’t ask) which is now properly implemented. fixes issue345.','implement internal implementation quirk',0,'',''),(13296,'pytest','avoid tmpdir fixture to create too long filenames especially\nwhen parametrization is used (issue354)','create long filenames',0,'',''),(13297,'pytest','avoid tmpdir fixture to create too long filenames especially\nwhen parametrization is used (issue354)','use parametrization',0,'',''),(13298,'pytest','fix pytest-pep8 and pytest-flakes / pytest interactions\n(collection names in mark plugin was assuming an item always\nhas a function which is not true for those plugins etc.)\nThanks Andi Zeidler.','fix pytest-pep8 pytest-flakes / Andi zeidler',0,'',''),(13299,'pytest','introduce node.get_marker/node.add_marker API for plugins\nlike pytest-pep8 and pytest-flakes to avoid the messy\ndetails of the node.keywords  pseudo-dicts.  Adapted\ndocs.','introduce node.get_marker/node.add_marker API for plugins',0,'',''),(13300,'pytest','remove attempt to “dup” stdout at startup as it’s icky.\nthe normal capturing should catch enough possibilities\nof tests messing up standard FDs.','remove attempt',0,'',''),(13301,'pytest','remove attempt to “dup” stdout at startup as it’s icky.\nthe normal capturing should catch enough possibilities\nof tests messing up standard FDs.','catch enough possibilities of tests',0,'',''),(13302,'pytest','add pluginmanager.do_configure(config) as a link to\nconfig.do_configure() for plugin-compatibility','add pluginmanager.do_configure(config) as link',0,'',''),(13303,'pytest','When using parser.addoption() unicode arguments to the\n“type” keyword should also be converted to the respective types.\nthanks Floris Bruynooghe, @dnozay. (fixes issue360 and issue362)','use parser.addoption() unicode arguments to type',0,'',''),(13304,'pytest','When using parser.addoption() unicode arguments to the\n“type” keyword should also be converted to the respective types.\nthanks Floris Bruynooghe, @dnozay. (fixes issue360 and issue362)','convert  to respective types',0,'',''),(13305,'pytest','fix dotted filename completion when using argcomplete\nthanks Anthon van der Neuth. (fixes issue361)','use argcomplete thanks',0,'',''),(13306,'pytest','fix regression when a 1-tuple (“arg”,) is used for specifying\nparametrization (the values of the parametrization were passed\nnested in a tuple).  Thanks Donald Stufft.','fix regression',0,'',''),(13307,'pytest','fix regression when a 1-tuple (“arg”,) is used for specifying\nparametrization (the values of the parametrization were passed\nnested in a tuple).  Thanks Donald Stufft.','specify parametrization',0,'',''),(13308,'pytest','fix regression when a 1-tuple (“arg”,) is used for specifying\nparametrization (the values of the parametrization were passed\nnested in a tuple).  Thanks Donald Stufft.','use 1-tuple for specifying',0,'',''),(13309,'pytest','if calling –genscript from python2.7 or above, you only get a\nstandalone script which works on python2.7 or above.  Use Python2.6\nto also get a python2.5 compatible version.','call â genscript',0,'',''),(13310,'pytest','if calling –genscript from python2.7 or above, you only get a\nstandalone script which works on python2.7 or above.  Use Python2.6\nto also get a python2.5 compatible version.','get standalone script',0,'',''),(13311,'pytest','if calling –genscript from python2.7 or above, you only get a\nstandalone script which works on python2.7 or above.  Use Python2.6\nto also get a python2.5 compatible version.','get python2 compatible version',0,'',''),(13312,'pytest','the pytest_plugin_unregister hook wasn’t ever properly called\nand there is no known implementation of the hook - so it got removed.','call pytest_plugin_unregister hook',0,'',''),(13313,'pytest','pytest.fixture-decorated functions cannot be generators (i.e. use\nyield) anymore.  This change might be reversed in 2.4.1 if it causes\nunforeseen real-life issues.  However, you can always write and return\nan inner function/generator and change the fixture consumer to iterate\nover the returned generator.  This change was done in lieu of the new\npytest.yield_fixture decorator, see below.','write inner function/generator',0,'',''),(13314,'pytest','pytest.fixture-decorated functions cannot be generators (i.e. use\nyield) anymore.  This change might be reversed in 2.4.1 if it causes\nunforeseen real-life issues.  However, you can always write and return\nan inner function/generator and change the fixture consumer to iterate\nover the returned generator.  This change was done in lieu of the new\npytest.yield_fixture decorator, see below.','return inner function/generator',0,'',''),(13315,'pytest','pytest.fixture-decorated functions cannot be generators (i.e. use\nyield) anymore.  This change might be reversed in 2.4.1 if it causes\nunforeseen real-life issues.  However, you can always write and return\nan inner function/generator and change the fixture consumer to iterate\nover the returned generator.  This change was done in lieu of the new\npytest.yield_fixture decorator, see below.','change fixture consumer',0,'',''),(13316,'pytest','experimentally introduce a new pytest.yield_fixture decorator\nwhich accepts exactly the same parameters as pytest.fixture but\nmandates a yield statement instead of a return statement from\nfixture functions.  This allows direct integration with “with-style”\ncontext managers in fixture functions and generally avoids registering\nof finalization callbacks in favour of treating the “after-yield” as\nteardown code.  Thanks Andreas Pelme, Vladimir Keleshev, Floris\nBruynooghe, Ronny Pfannschmidt and many others for discussions.','introduce new pytest.yield_fixture decorator',0,'',''),(13317,'pytest','allow boolean expression directly with skipif/xfail\nif a “reason” is also specified.  Rework skipping documentation\nto recommend “condition as booleans” because it prevents surprises\nwhen importing markers between modules.  Specifying conditions\nas strings will remain fully supported.','specify boolean expression',0,'',''),(13318,'pytest','allow boolean expression directly with skipif/xfail\nif a “reason” is also specified.  Rework skipping documentation\nto recommend “condition as booleans” because it prevents surprises\nwhen importing markers between modules.  Specifying conditions\nas strings will remain fully supported.','specify reason',0,'',''),(13319,'pytest','allow boolean expression directly with skipif/xfail\nif a “reason” is also specified.  Rework skipping documentation\nto recommend “condition as booleans” because it prevents surprises\nwhen importing markers between modules.  Specifying conditions\nas strings will remain fully supported.','skip documentation',0,'',''),(13320,'pytest','allow boolean expression directly with skipif/xfail\nif a “reason” is also specified.  Rework skipping documentation\nto recommend “condition as booleans” because it prevents surprises\nwhen importing markers between modules.  Specifying conditions\nas strings will remain fully supported.','prevent surprises',0,'',''),(13321,'pytest','allow boolean expression directly with skipif/xfail\nif a “reason” is also specified.  Rework skipping documentation\nto recommend “condition as booleans” because it prevents surprises\nwhen importing markers between modules.  Specifying conditions\nas strings will remain fully supported.','import markers between modules',0,'',''),(13322,'pytest','allow boolean expression directly with skipif/xfail\nif a “reason” is also specified.  Rework skipping documentation\nto recommend “condition as booleans” because it prevents surprises\nwhen importing markers between modules.  Specifying conditions\nas strings will remain fully supported.','support specifying conditions as strings',0,'',''),(13323,'pytest','fix issue341: introduce new experimental hook for IDEs/terminals to\nintercept debugging: pytest_exception_interact(node, call, report).','introduce new experimental hook for ides/terminals',0,'',''),(13324,'pytest','new monkeypatch.setattr() variant to provide a shorter\ninvocation for patching out classes/functions from modules:','provide shorter invocation for patching',0,'',''),(13325,'pytest','will replace the “get” function of the “requests” module with myfunc.','get function of requests module',0,'',''),(13326,'pytest','fix issue322: tearDownClass is not run if setUpClass failed. Thanks\nMathieu Agopian for the initial fix.  Also make all of pytest/nose\nfinalizer mimic the same generic behaviour: if a setupX exists and\nfails, don’t run teardownX.  This internally introduces a new method\n“node.addfinalizer()” helper which can only be called during the setup\nphase of a node.','run teardownX',0,'',''),(13327,'pytest','fix issue322: tearDownClass is not run if setUpClass failed. Thanks\nMathieu Agopian for the initial fix.  Also make all of pytest/nose\nfinalizer mimic the same generic behaviour: if a setupX exists and\nfails, don’t run teardownX.  This internally introduces a new method\n“node.addfinalizer()” helper which can only be called during the setup\nphase of a node.','introduce new method node.addfinalizer() helper',0,'',''),(13328,'pytest','fix issue322: tearDownClass is not run if setUpClass failed. Thanks\nMathieu Agopian for the initial fix.  Also make all of pytest/nose\nfinalizer mimic the same generic behaviour: if a setupX exists and\nfails, don’t run teardownX.  This internally introduces a new method\n“node.addfinalizer()” helper which can only be called during the setup\nphase of a node.','call new method node.addfinalizer() helper during setup phase',0,'',''),(13329,'pytest','simplify pytest.mark.parametrize() signature: allow to pass a\nCSV-separated string to specify argnames.  For example:\npytest.mark.parametrize(\"input,expected\",  [(1,2), (2,3)])\nworks as well as the previous:\npytest.mark.parametrize((\"input\", \"expected\"), ...).','pass CSV-separated string',0,'',''),(13330,'pytest','simplify pytest.mark.parametrize() signature: allow to pass a\nCSV-separated string to specify argnames.  For example:\npytest.mark.parametrize(\"input,expected\",  [(1,2), (2,3)])\nworks as well as the previous:\npytest.mark.parametrize((\"input\", \"expected\"), ...).','specify argnames',0,'',''),(13331,'pytest','add support for setUpModule/tearDownModule detection, thanks Brian Okken.','add support for setupmodule/tearDownModule detection',0,'',''),(13332,'pytest','integrate tab-completion on options through use of “argcomplete”.\nThanks Anthon van der Neut for the PR.','integrate tab-completion through use',0,'',''),(13333,'pytest','integrate tab-completion on options through use of “argcomplete”.\nThanks Anthon van der Neut for the PR.','integrate tab-completion on options',0,'',''),(13334,'pytest','change option names to be hyphen-separated long options but keep the\nold spelling backward compatible.  py.test -h will only show the\nhyphenated version, for example “–collect-only” but “–collectonly”\nwill remain valid as well (for backward-compat reasons).  Many thanks to\nAnthon van der Neut for the implementation and to Hynek Schlawack for\npushing us.','change option names',0,'',''),(13335,'pytest','change option names to be hyphen-separated long options but keep the\nold spelling backward compatible.  py.test -h will only show the\nhyphenated version, for example “–collect-only” but “–collectonly”\nwill remain valid as well (for backward-compat reasons).  Many thanks to\nAnthon van der Neut for the implementation and to Hynek Schlawack for\npushing us.','show hyphenated version',0,'',''),(13336,'pytest','fix issue 308 - allow to mark/xfail/skip individual parameter sets\nwhen parametrizing.  Thanks Brianna Laugher.','fix issue',0,'',''),(13337,'pytest','call new experimental pytest_load_initial_conftests hook to allow\n3rd party plugins to do something before a conftest is loaded.','call new experimental pytest_load_initial_conftests hook',0,'',''),(13338,'pytest','call new experimental pytest_load_initial_conftests hook to allow\n3rd party plugins to do something before a conftest is loaded.','load conftest',0,'',''),(13339,'pytest','fix issue358 - capturing options are now parsed more properly\nby using a new parser.parse_known_args method.','use new parser.parse_known_args method',0,'',''),(13340,'pytest','pytest now uses argparse instead of optparse (thanks Anthon) which\nmeans that “argparse” is added as a dependency if installing into python2.6\nenvironments or below.','use argparse instead_of optparse',0,'',''),(13341,'pytest','pytest now uses argparse instead of optparse (thanks Anthon) which\nmeans that “argparse” is added as a dependency if installing into python2.6\nenvironments or below.','add argparse as dependency',0,'',''),(13342,'pytest','pytest now uses argparse instead of optparse (thanks Anthon) which\nmeans that “argparse” is added as a dependency if installing into python2.6\nenvironments or below.','add argparse if installing',0,'',''),(13343,'pytest','fix issue333: fix a case of bad unittest/pytest hook interaction.','fix case of bad unittest/pytest hook interaction',0,'',''),(13344,'pytest','PR27: correctly handle nose.SkipTest during collection.  Thanks\nAntonio Cuni, Ronny Pfannschmidt.','handle nose.SkipTest during collection',0,'',''),(13345,'pytest','fix issue335: document py.code.ExceptionInfo() object returned\nfrom pytest.raises(), thanks Mathieu Agopian.','return  from pytest.raises()',0,'',''),(13346,'pytest','remove implicit distribute_setup support from setup.py.','remove implicit distribute_setup support from setup.py.',0,'',''),(13347,'pytest','fix issue305: ignore any problems when writing pyc files.','ignore problems',0,'',''),(13348,'pytest','fix issue305: ignore any problems when writing pyc files.','write pyc files',0,'',''),(13349,'pytest','fix issue320 - fix class scope for fixtures when mixed with\nmodule-level functions.  Thanks Anatloy Bubenkoff.','fix class scope for fixtures',0,'',''),(13350,'pytest','you can specify “-q” or “-qq” to get different levels of “quieter”\nreporting (thanks Katarzyna Jachim)','get different levels of quieter reporting',0,'',''),(13351,'pytest','fix issue323 - sorting of many module-scoped arg parametrizations','sort  of many module-scoped arg parametrizations',0,'',''),(13352,'pytest','make sessionfinish hooks execute with the same cwd-context as at\nsession start (helps fix plugin behaviour which write output files\nwith relative path such as pytest-cov)','execute  with same cwd-context',0,'',''),(13353,'pytest','fix issue316 - properly reference collection hooks in docs','reference collection hooks in docs',0,'',''),(13354,'pytest','improved doctest counting for doctests in python modules –\nfiles without any doctest items will not show up anymore\nand doctest examples are counted as separate test items.\nthanks Danilo Bellini.','count doctest examples as separate test items',0,'',''),(13355,'pytest','fix issue245 by depending on the released py-1.4.14\nwhich fixes py.io.dupfile to work with files with no\nmode. Thanks Jason R. Coombs.','fix  by depending',0,'',''),(13356,'pytest','fix issue245 by depending on the released py-1.4.14\nwhich fixes py.io.dupfile to work with files with no\nmode. Thanks Jason R. Coombs.','fix py.io.dupfile',0,'',''),(13357,'pytest','fix issue245 by depending on the released py-1.4.14\nwhich fixes py.io.dupfile to work with files with no\nmode. Thanks Jason R. Coombs.','fix released py-1.4.14',0,'',''),(13358,'pytest','fix junitxml generation when test output contains control characters,\naddressing issue267, thanks Jaap Broekhuizen','fix junitxml generation',0,'',''),(13359,'pytest','fix issue307 - use yaml.safe_load in example, thanks Mark Eichin.','use yaml.safe_load',0,'',''),(13360,'pytest','pytest_terminal_summary(terminalreporter) hooks can now use\n“.section(title)” and “.line(msg)” methods to print extra\ninformation at the end of a test run.','use .section(title) .line(msg) methods',0,'',''),(13361,'pytest','pytest_terminal_summary(terminalreporter) hooks can now use\n“.section(title)” and “.line(msg)” methods to print extra\ninformation at the end of a test run.','print extra information at end',0,'',''),(13362,'pytest','put captured stdout/stderr into junitxml output even for passing tests\n(thanks Adam Goucher)','pass tests',0,'',''),(13363,'pytest','Issue 265 - integrate nose setup/teardown with setupstate\nso it doesn’t try to teardown if it did not setup','integrate nose setup/teardown with setupstate',0,'',''),(13364,'pytest','issue 271 - don’t write junitxml on worker nodes','write junitxml on worker nodes',0,'',''),(13365,'pytest','Issue 274 - don’t try to show full doctest example\nwhen doctest does not know the example location','show full doctest example',0,'',''),(13366,'pytest','inject “getfixture()” helper to retrieve fixtures from doctests,\nthanks Andreas Zeidler','retrieve fixtures from doctests',0,'',''),(13367,'pytest','issue 251 - report a skip instead of ignoring classes with init','ignore classes with init',0,'',''),(13368,'pytest','fix –genscript option to generate standalone scripts that also\nwork with python3.3 (importer ordering)','fix â genscript option',0,'',''),(13369,'pytest','fix –genscript option to generate standalone scripts that also\nwork with python3.3 (importer ordering)','generate standalone scripts',0,'',''),(13370,'pytest','issue171 - in assertion rewriting, show the repr of some\nglobal variables','show repr of global variables',0,'',''),(13371,'pytest','fix option help for “-k”','fix option help for k.',0,'',''),(13372,'pytest','move long description of distribution into README.rst','move long description into README.rst',0,'',''),(13373,'pytest','move long description of distribution into README.rst','move long description of distribution',0,'',''),(13374,'pytest','fix bug where using capsys with pytest.set_trace() in a test\nfunction would break when looking at capsys.readouterr()','fix bug',0,'',''),(13375,'pytest','fix bug where using capsys with pytest.set_trace() in a test\nfunction would break when looking at capsys.readouterr()','use capsys with pytest.set_trace()',0,'',''),(13376,'pytest','allow to specify prefixes starting with “_” when\ncustomizing python_functions test discovery. (thanks Graham Horler)','specify prefixes',0,'',''),(13377,'pytest','allow to specify prefixes starting with “_” when\ncustomizing python_functions test discovery. (thanks Graham Horler)','customize python_functions test discovery',0,'',''),(13378,'pytest','ensure OutcomeExceptions like skip/fail have initialized exception attributes','initialize exception attributes',0,'',''),(13379,'pytest','issue 260 - don’t use nose special setup on plain unittest cases','use nose special setup on plain unittest cases',0,'',''),(13380,'pytest','fix issue134 - print the collect errors that prevent running specified test items','print collect errors',0,'',''),(13381,'pytest','fix issue134 - print the collect errors that prevent running specified test items','run specified test items',0,'',''),(13382,'pytest','fix issue134 - print the collect errors that prevent running specified test items','prevent collect errors',0,'',''),(13383,'pytest','yielded test functions will now have autouse-fixtures active but\ncannot accept fixtures as funcargs - it’s anyway recommended to\nrather use the post-2.0 parametrize features instead of yield, see:\nhttp://pytest.org/en/stable/example/how-to/parametrize.html','use post-2 parametrize features instead_of yield',0,'',''),(13384,'pytest','fix autouse-issue where autouse-fixtures would not be discovered\nif defined in an a/conftest.py file and tests in a/tests/test_some.py','define  in tests',0,'',''),(13385,'pytest','fix autouse-issue where autouse-fixtures would not be discovered\nif defined in an a/conftest.py file and tests in a/tests/test_some.py','define  in a/tests/test_some.py',0,'',''),(13386,'pytest','fix autouse-issue where autouse-fixtures would not be discovered\nif defined in an a/conftest.py file and tests in a/tests/test_some.py','define  in a/conftest.py file',0,'',''),(13387,'pytest','fix issue226 - LIFO ordering for fixture teardowns','order  for fixture teardowns',0,'',''),(13388,'pytest','allow to dynamically define markers via\nitem.keywords[…]=assignment integrating with “-m” option','define markers via item.keywordsâ¦=assignment',0,'',''),(13389,'pytest','allow to dynamically define markers via\nitem.keywords[…]=assignment integrating with “-m” option','integrate  with m option',0,'',''),(13390,'pytest','make “-k” accept an expressions the same as with “-m” so that one\ncan write: -k “name1 or name2” etc.  This is a slight incompatibility\nif you used special syntax like “TestClass.test_method” which you now\nneed to write as -k “TestClass and test_method” to match a certain\nmethod in a certain test class.','use special syntax like TestClass.test_method',0,'',''),(13391,'pytest','make “-k” accept an expressions the same as with “-m” so that one\ncan write: -k “name1 or name2” etc.  This is a slight incompatibility\nif you used special syntax like “TestClass.test_method” which you now\nneed to write as -k “TestClass and test_method” to match a certain\nmethod in a certain test class.','match certain method in certain test class',0,'',''),(13392,'pytest','make “-k” accept an expressions the same as with “-m” so that one\ncan write: -k “name1 or name2” etc.  This is a slight incompatibility\nif you used special syntax like “TestClass.test_method” which you now\nneed to write as -k “TestClass and test_method” to match a certain\nmethod in a certain test class.','write  as k TestClass',0,'',''),(13393,'pytest','make “-k” accept an expressions the same as with “-m” so that one\ncan write: -k “name1 or name2” etc.  This is a slight incompatibility\nif you used special syntax like “TestClass.test_method” which you now\nneed to write as -k “TestClass and test_method” to match a certain\nmethod in a certain test class.','write  as test_method',0,'',''),(13394,'pytest','fix issue215 - split test_python.org into multiple files','split test_python.org into multiple files',0,'',''),(13395,'pytest','fix issue148 - @unittest.skip on classes is now recognized and avoids\ncalling setUpClass/tearDownClass, thanks Pavel Repin','call setupclass/tearDownClass thanks Pavel repin',0,'',''),(13396,'pytest','fix issue219 - add py2.4-3.3 classifiers to TROVE list','add py2.4-3 classifiers to TROVE list',0,'',''),(13397,'pytest','in tracebacks ,* arg values are now shown next to normal arguments\n(thanks Manuel Jacob)','show * arg values in tracebacks',0,'',''),(13398,'pytest','in tracebacks ,* arg values are now shown next to normal arguments\n(thanks Manuel Jacob)','show * arg values next_to normal arguments',0,'',''),(13399,'pytest','fix issue127 - improve documentation for pytest_addoption() and\nadd a config.getoption(name) helper function for consistency.','add config.getoption(name) helper function for consistency',0,'',''),(13400,'pytest','fix teardown-ordering for parametrized setups','fix teardown-ordering for parametrized setups',0,'',''),(13401,'pytest','add tox.ini to pytest distribution so that ignore-dirs and others config\nbits are properly distributed for maintainers who run pytest-own tests','add tox.ini',0,'',''),(13402,'pytest','add tox.ini to pytest distribution so that ignore-dirs and others config\nbits are properly distributed for maintainers who run pytest-own tests','run pytest-own tests',0,'',''),(13403,'pytest','add tox.ini to pytest distribution so that ignore-dirs and others config\nbits are properly distributed for maintainers who run pytest-own tests','run maintainers',0,'',''),(13404,'pytest','fix issue202 - fix regression: using “self” from fixture functions now\nworks as expected (it’s the same “self” instance that a test method\nwhich uses the fixture sees)','fix regression',0,'',''),(13405,'pytest','skip pexpect using tests (test_pdb.py mostly) on freebsd* systems\ndue to pexpect not supporting it properly (hanging)','skip pexpect',0,'',''),(13406,'pytest','skip pexpect using tests (test_pdb.py mostly) on freebsd* systems\ndue to pexpect not supporting it properly (hanging)','use tests on supporting',0,'',''),(13407,'pytest','link to web pages from –markers output which provides help for\npytest.mark.* usage.','provide output',0,'',''),(13408,'pytest','fix issue139 - introduce @pytest.fixture which allows direct scoping\nand parametrization of funcarg factories.','introduce',0,'',''),(13409,'pytest','fix issue193 skip test functions with were parametrized with empty\nparameter sets','fix issue193 skip test functions',0,'',''),(13410,'pytest','fix python3.3 compat, mostly reporting bits that previously depended\non dict ordering','fix compat reporting bits',0,'',''),(13411,'pytest','introduce re-ordering of tests by resource and parametrization setup\nwhich takes precedence to the usual file-ordering','introduce re-ordering of tests',0,'',''),(13412,'pytest','fix issue172 duplicate call of pytest.fixture decoratored setup_module\nfunctions','fix issue172 duplicate call of pytest.fixture decoratored setup_module functions',0,'',''),(13413,'pytest','fix “python setup.py test” example to cause a proper “errno” return','fix python setup.py test example',0,'',''),(13414,'pytest','fix issue165 - fix broken doc links and mention stackoverflow for FAQ','fix broken doc links',0,'',''),(13415,'pytest','catch unicode-issues when writing failure representations\nto terminal to prevent the whole session from crashing','catch unicode-issues',0,'',''),(13416,'pytest','catch unicode-issues when writing failure representations\nto terminal to prevent the whole session from crashing','write failure representations to terminal',0,'',''),(13417,'pytest','catch unicode-issues when writing failure representations\nto terminal to prevent the whole session from crashing','prevent whole session from crashing',0,'',''),(13418,'pytest','always report installed 3rd party plugins in the header of a test run','install 3rd party plugins in header',0,'',''),(13419,'pytest','fix issue128: show captured output when capsys/capfd are used','use capsys/capfd',0,'',''),(13420,'pytest','pluginmanager.register(…) now raises ValueError if the\nplugin has been already registered or the name is taken','raise ValueError',0,'',''),(13421,'pytest','fix issue 178: xml binary escapes are now wrapped in py.xml.raw','wrap xml binary escapes in py.xml.raw',0,'',''),(13422,'pytest','fix issue 176: correctly catch the builtin AssertionError\neven when we replaced AssertionError with a subclass on the\npython level','fix issue',0,'',''),(13423,'pytest','fix issue 176: correctly catch the builtin AssertionError\neven when we replaced AssertionError with a subclass on the\npython level','catch builtin AssertionError',0,'',''),(13424,'pytest','fix issue 176: correctly catch the builtin AssertionError\neven when we replaced AssertionError with a subclass on the\npython level','replace AssertionError with subclass',0,'',''),(13425,'pytest','fix issue 176: correctly catch the builtin AssertionError\neven when we replaced AssertionError with a subclass on the\npython level','replace AssertionError on python level',0,'',''),(13426,'pytest','factory discovery no longer fails with magic global callables\nthat provide no sane __code__ object (mock.call for example)','provide sane __code__ object',0,'',''),(13427,'pytest','factory discovery no longer fails with magic global callables\nthat provide no sane __code__ object (mock.call for example)','provide magic global callables',0,'',''),(13428,'pytest','fix issue 182: testdir.inprocess_run now considers passed plugins','pass plugins',0,'',''),(13429,'pytest','before calling into a test','call  into test',0,'',''),(13430,'pytest','fix issue 191: add unittest TestCase runTest method support','fix issue 191',0,'',''),(13431,'pytest','fix issue 191: add unittest TestCase runTest method support','add unittest TestCase runTest method support',0,'',''),(13432,'pytest','fix issue 156: monkeypatch correctly handles class level descriptors','fix issue',0,'',''),(13433,'pytest','fix issue 156: monkeypatch correctly handles class level descriptors','handle class level descriptors',0,'',''),(13434,'pytest','pytest_report_header now receives a “startdir” so that\nyou can use startdir.bestrelpath(yourpath) to show\nnice relative path','receive startdir',0,'',''),(13435,'pytest','pytest_report_header now receives a “startdir” so that\nyou can use startdir.bestrelpath(yourpath) to show\nnice relative path','use startdir.bestrelpath(yourpath)',0,'',''),(13436,'pytest','pytest_report_header now receives a “startdir” so that\nyou can use startdir.bestrelpath(yourpath) to show\nnice relative path','show nice relative path',0,'',''),(13437,'pytest','allow plugins to implement both pytest_report_header and\npytest_sessionstart (sessionstart is invoked first).','implement pytest_report_header',0,'',''),(13438,'pytest','allow plugins to implement both pytest_report_header and\npytest_sessionstart (sessionstart is invoked first).','implement pytest_sessionstart',0,'',''),(13439,'pytest','don’t show deselected reason line if there is none','show deselected reason line',0,'',''),(13440,'pytest','fix error message for rewritten assertions involving the % operator','fix error message for rewritten assertions',0,'',''),(13441,'pytest','fix issue 126: correctly match all invalid xml characters for junitxml\nbinary escape','match invalid xml characters for junitxml binary escape',0,'',''),(13442,'pytest','fix issue with unittest: now @unittest.expectedFailure markers should\nbe processed correctly (you can also use @pytest.mark markers)','fix issue with unittest',0,'',''),(13443,'pytest','fix issue with unittest: now @unittest.expectedFailure markers should\nbe processed correctly (you can also use @pytest.mark markers)','process  markers',0,'',''),(13444,'pytest','fix issue 140: properly get the real functions\nof bound classmethods for setup/teardown_class','fix issue',0,'',''),(13445,'pytest','fix issue 140: properly get the real functions\nof bound classmethods for setup/teardown_class','get real functions of bound classmethods',0,'',''),(13446,'pytest','fix issue 140: properly get the real functions\nof bound classmethods for setup/teardown_class','get real functions for setup/teardown _ class',0,'',''),(13447,'pytest','fix issue #141: switch from the deceased paste.pocoo.org to bpaste.net','switch  from deceased paste.pocoo.org',0,'',''),(13448,'pytest','fix issue #141: switch from the deceased paste.pocoo.org to bpaste.net','switch  to bpaste.net',0,'',''),(13449,'pytest','fix uploaded package to only include necessary files','fix uploaded package',0,'',''),(13450,'pytest','fix uploaded package to only include necessary files','include necessary files',0,'',''),(13451,'pytest','fix issue101: wrong args to unittest.TestCase test function now\nproduce better output','produce better output',0,'',''),(13452,'pytest','fix issue102: report more useful errors and hints for when a\ntest directory was renamed and some pyc/__pycache__ remain','rename test directory',0,'',''),(13453,'pytest','fix issue106: allow parametrize to be applied multiple times\ne.g. from module, class and at function level.','apply  at function level',0,'',''),(13454,'pytest','fix issue106: allow parametrize to be applied multiple times\ne.g. from module, class and at function level.','apply  from e.g.',0,'',''),(13455,'pytest','fix issue107: actually perform session scope finalization','perform session scope finalization',0,'',''),(13456,'pytest','don’t check in parametrize if indirect parameters are funcarg names','check  in parametrize',0,'',''),(13457,'pytest','fix crash resulting from calling monkeypatch undo a second time','call monkeypatch',0,'',''),(13458,'pytest','“-qq –collectonly” now shows only files and the number of tests in them','show only files of tests',0,'',''),(13459,'pytest','“-qq –collectonly” now shows only files and the number of tests in them','show number of tests',0,'',''),(13460,'pytest','“-q –collectonly” now shows test ids','show test ids',0,'',''),(13461,'pytest','allow adding of attributes to test reports such that it also works\nwith distributed testing (no upgrade of pytest-xdist needed)','test reports',0,'',''),(13462,'pytest','allow adding of attributes to test reports such that it also works\nwith distributed testing (no upgrade of pytest-xdist needed)','add  of attributes',0,'',''),(13463,'pytest','fix issue99 (in pytest and py) internallerrors with resultlog now\nproduce better output - fixed by normalizing pytest_internalerror\ninput arguments.','fix issue99 internallerrors with resultlog',0,'',''),(13464,'pytest','fix issue99 (in pytest and py) internallerrors with resultlog now\nproduce better output - fixed by normalizing pytest_internalerror\ninput arguments.','produce better output',0,'',''),(13465,'pytest','fix issue93 (in pytest and pytest-xdist) avoid “delayed teardowns”:\nthe final test in a test node will now run its teardown directly\ninstead of waiting for the end of the session. Thanks Dave Hunt for\nthe good reporting and feedback.  The pytest_runtest_protocol as well\nas the pytest_runtest_teardown hooks now have “nextitem” available\nwhich will be None indicating the end of the test run.','run teardown instead_of waiting',0,'',''),(13466,'pytest','fix issue90: introduce eager tearing down of test items so that\nteardown function are called earlier.','call teardown function',0,'',''),(13467,'pytest','add an all-powerful metafunc.parametrize function which allows to\nparametrize test function arguments in multiple steps and therefore\nfrom independent plugins and places.','add all-powerful metafunc.parametrize function',0,'',''),(13468,'pytest','add a @pytest.mark.parametrize helper which allows to easily\ncall a test function with different argument values','add  helper',0,'',''),(13469,'pytest','add a @pytest.mark.parametrize helper which allows to easily\ncall a test function with different argument values','call test function with different argument values',0,'',''),(13470,'pytest','Add examples to the “parametrize” example page, including a quick port\nof Test scenarios and the new parametrize function and decorator.','add examples to parametrize example page',0,'',''),(13471,'pytest','introduce registration for “pytest.mark.*” helpers via ini-files\nor through plugin hooks.  Also introduce a “–strict” option which\nwill treat unregistered markers as errors\nallowing to avoid typos and maintain a well described set of markers\nfor your test suite.  See examples at http://pytest.org/en/stable/how-to/mark.html\nand its links.','introduce registration through plugin hooks',0,'',''),(13472,'pytest','introduce registration for “pytest.mark.*” helpers via ini-files\nor through plugin hooks.  Also introduce a “–strict” option which\nwill treat unregistered markers as errors\nallowing to avoid typos and maintain a well described set of markers\nfor your test suite.  See examples at http://pytest.org/en/stable/how-to/mark.html\nand its links.','introduce registration for pytest.mark.* helpers',0,'',''),(13473,'pytest','introduce registration for “pytest.mark.*” helpers via ini-files\nor through plugin hooks.  Also introduce a “–strict” option which\nwill treat unregistered markers as errors\nallowing to avoid typos and maintain a well described set of markers\nfor your test suite.  See examples at http://pytest.org/en/stable/how-to/mark.html\nand its links.','introduce â strict option',0,'',''),(13474,'pytest','issue50: introduce “-m marker” option to select tests based on markers\n(this is a stricter and more predictable version of ‘-k’ in that “-m”\nonly matches complete markers and has more obvious rules for and/or\nsemantics.','introduce m marker option',0,'',''),(13475,'pytest','issue50: introduce “-m marker” option to select tests based on markers\n(this is a stricter and more predictable version of ‘-k’ in that “-m”\nonly matches complete markers and has more obvious rules for and/or\nsemantics.','select tests',0,'',''),(13476,'pytest','issue50: introduce “-m marker” option to select tests based on markers\n(this is a stricter and more predictable version of ‘-k’ in that “-m”\nonly matches complete markers and has more obvious rules for and/or\nsemantics.','match complete markers',0,'',''),(13477,'pytest','new feature to help optimizing the speed of your tests:\n–durations=N option for displaying N slowest test calls\nand setup/teardown methods.','display n slowest test calls',0,'',''),(13478,'pytest','new feature to help optimizing the speed of your tests:\n–durations=N option for displaying N slowest test calls\nand setup/teardown methods.','display setup/teardown methods',0,'',''),(13479,'pytest','fix issue74: pyarg module names are now checked against imp.find_module false positives','check pyarg module names against imp.find_module false positives',0,'',''),(13480,'pytest','fix compatibility with twisted/trial-11.1.0 use cases','use cases',0,'',''),(13481,'pytest','add support for skip properties on unittest classes and functions','add support for skip properties',0,'',''),(13482,'pytest','correctly handle zero length arguments (a la pytest ‘’)','handle length arguments',0,'',''),(13483,'pytest','fix issue75 / skipping test failure on jython','skip test failure on jython',0,'',''),(13484,'pytest','fix issue77 / Allow assertrepr_compare hook to apply to a subset of tests','apply  to subset',0,'',''),(13485,'pytest','fix assertion rewriting on files with windows newlines on some Python versions','fix assertion rewriting on files',0,'',''),(13486,'pytest','fix issue69 / assertion rewriting fixed on some boolean operations','fix  on boolean operations',0,'',''),(13487,'pytest','fix issue66: use different assertion rewriting caches when the -O option is passed','pass o option',0,'',''),(13488,'pytest','fix assertion rewriting on calls with a ** arg','fix assertion rewriting on calls',0,'',''),(13489,'pytest','don’t cache rewritten modules if bytecode generation is disabled','disable bytecode generation',0,'',''),(13490,'pytest','fix assertion rewriting in read-only directories','fix assertion rewriting in read-only directories',0,'',''),(13491,'pytest','fix issue59: provide system-out/err tags for junitxml output','provide system-out/err tags for junitxml output',0,'',''),(13492,'pytest','fix issue53 call nosestyle setup functions with correct ordering','call nosestyle setup functions with correct ordering',0,'',''),(13493,'pytest','merge Benjamin’s assertionrewrite branch: now assertions\nfor test modules on python 2.6 and above are done by rewriting\nthe AST and saving the pyc file before the test module is imported.\nsee doc/assert.txt for more info.','save pyc file',0,'',''),(13494,'pytest','show releaselevel information in test runs for pypy','run  for pypy',0,'',''),(13495,'pytest','fix issue 35 - provide PDF doc version and download link from index page','fix issue',0,'',''),(13496,'pytest','fix issue 35 - provide PDF doc version and download link from index page','provide PDF doc version from index page',0,'',''),(13497,'pytest','fix issue 35 - provide PDF doc version and download link from index page','provide download link from index page',0,'',''),(13498,'pytest','fix missing skip reason/meta information in junitxml files, reported\nvia http://lists.idyll.org/pipermail/testing-in-python/2011-March/003928.html','fix missing skip reason/meta information in junitxml files',0,'',''),(13499,'pytest','fix issue30 - extended xfail/skipif handling and improved reporting.\nIf you have a syntax error in your skip/xfail\nexpressions you now get nice error reports.','get nice error reports',0,'',''),(13500,'pytest','Also you can now access module globals from xfail/skipif\nexpressions so that this for example works now:','access module globals from xfail/skipif expressions',1,'https://docs.pytest.org/en/7.2.x/changelog.html',''),(13501,'pytest','This will not run the test function if the module’s version string\ndoes not start with a “1”.  Note that specifying a string instead\nof a boolean expressions allows py.test to report meaningful information\nwhen summarizing a test run as to what conditions lead to skipping\n(or xfail-ing) tests.','specify string instead_of boolean expressions',0,'',''),(13502,'pytest','This will not run the test function if the module’s version string\ndoes not start with a “1”.  Note that specifying a string instead\nof a boolean expressions allows py.test to report meaningful information\nwhen summarizing a test run as to what conditions lead to skipping\n(or xfail-ing) tests.','summarize test',0,'',''),(13503,'pytest','This will not run the test function if the module’s version string\ndoes not start with a “1”.  Note that specifying a string instead\nof a boolean expressions allows py.test to report meaningful information\nwhen summarizing a test run as to what conditions lead to skipping\n(or xfail-ing) tests.','skip tests',0,'',''),(13504,'pytest','fix issue28 - setup_method and pytest_generate_tests work together\nThe setup_method fixture method now gets called also for\ntest function invocations generated from the pytest_generate_tests\nhook.','call fixture method for test function invocations',0,'',''),(13505,'pytest','fix issue28 - setup_method and pytest_generate_tests work together\nThe setup_method fixture method now gets called also for\ntest function invocations generated from the pytest_generate_tests\nhook.','call setup_method for test function invocations',0,'',''),(13506,'pytest','fix issue28 - setup_method and pytest_generate_tests work together\nThe setup_method fixture method now gets called also for\ntest function invocations generated from the pytest_generate_tests\nhook.','generate  from pytest_generate_tests hook',0,'',''),(13507,'pytest','fix issue27 - collectonly and keyword-selection (-k) now work together\nAlso, if you do “py.test –collectonly -q” you now get a flat list\nof test ids that you can use to paste to the py.test commandline\nin order to execute a particular test.','get flat list of test ids',0,'',''),(13508,'pytest','fix issue27 - collectonly and keyword-selection (-k) now work together\nAlso, if you do “py.test –collectonly -q” you now get a flat list\nof test ids that you can use to paste to the py.test commandline\nin order to execute a particular test.','execute particular test',0,'',''),(13509,'pytest','fix issue27 - collectonly and keyword-selection (-k) now work together\nAlso, if you do “py.test –collectonly -q” you now get a flat list\nof test ids that you can use to paste to the py.test commandline\nin order to execute a particular test.','paste  to py.test commandline',0,'',''),(13510,'pytest','fix issue23 - tmpdir argument now works on Python3.2 and WindowsXP\nStarting with Python3.2 os.symlink may be supported. By requiring\na newer py lib version the py.path.local() implementation acknowledges\nthis.','support os.symlink',0,'',''),(13511,'pytest','fix issue23 - tmpdir argument now works on Python3.2 and WindowsXP\nStarting with Python3.2 os.symlink may be supported. By requiring\na newer py lib version the py.path.local() implementation acknowledges\nthis.','support python3',0,'',''),(13512,'pytest','fix slightly wrong output of verbose progress reporting for classes\n(thanks Amaury)','fix wrong output of verbose progress',0,'',''),(13513,'pytest','refine and unify initial capturing so that it works nicely\neven if the logging module is used on an early-loaded conftest.py\nfile or plugin.','use logging module on early-loaded conftest.py file',0,'',''),(13514,'pytest','refine and unify initial capturing so that it works nicely\neven if the logging module is used on an early-loaded conftest.py\nfile or plugin.','use logging module on plugin',0,'',''),(13515,'pytest','allow to omit “()” in test ids to allow for uniform test ids\nas produced by Alfredo’s nice pytest.vim plugin.','omit  in test ids',0,'',''),(13516,'pytest','allow to omit “()” in test ids to allow for uniform test ids\nas produced by Alfredo’s nice pytest.vim plugin.','produce  by nice pytest.vim plugin',0,'',''),(13517,'pytest','fix issue12 - show plugin versions with “–version” and\n“–traceconfig” and also document how to add extra information\nto reporting test header','show plugin versions with â version',0,'',''),(13518,'pytest','fix issue12 - show plugin versions with “–version” and\n“–traceconfig” and also document how to add extra information\nto reporting test header','show plugin versions with â traceconfig',0,'',''),(13519,'pytest','fix issue12 - show plugin versions with “–version” and\n“–traceconfig” and also document how to add extra information\nto reporting test header','document plugin versions with â version',0,'',''),(13520,'pytest','fix issue12 - show plugin versions with “–version” and\n“–traceconfig” and also document how to add extra information\nto reporting test header','document plugin versions with â traceconfig',0,'',''),(13521,'pytest','fix issue12 - show plugin versions with “–version” and\n“–traceconfig” and also document how to add extra information\nto reporting test header','add extra information to reporting',0,'',''),(13522,'pytest','fix issue17 (import-* reporting issue on python3) by\nrequiring py>1.4.0 (1.4.1 is going to include it)','fix  by requiring',0,'',''),(13523,'pytest','fix issue10 (numpy arrays truth checking) by refining\nassertion interpretation in py lib','fix  by refining assertion interpretation',0,'',''),(13524,'pytest','remove somewhat surprising “same-conftest” detection because\nit ignores conftest.py when they appear in several subdirs.','remove surprising same-conftest detection',0,'',''),(13525,'pytest','remove somewhat surprising “same-conftest” detection because\nit ignores conftest.py when they appear in several subdirs.','ignore conftest.py',0,'',''),(13526,'pytest','improve behaviour/warnings when running on top of “python -OO”\n(assertions and docstrings are turned off, leading to potential\nfalse positives)','run  on_top_of python',0,'',''),(13527,'pytest','introduce a pytest_cmdline_processargs(args) hook\nto allow dynamic computation of command line arguments.\nThis fixes a regression because py.test prior to 2.0\nallowed to set command line options from conftest.py\nfiles which so far pytest-2.0 only allowed from ini-files now.','fix regression prior_to 2.0',0,'',''),(13528,'pytest','introduce a pytest_cmdline_processargs(args) hook\nto allow dynamic computation of command line arguments.\nThis fixes a regression because py.test prior to 2.0\nallowed to set command line options from conftest.py\nfiles which so far pytest-2.0 only allowed from ini-files now.','fix regression because py.test',0,'',''),(13529,'pytest','introduce a pytest_cmdline_processargs(args) hook\nto allow dynamic computation of command line arguments.\nThis fixes a regression because py.test prior to 2.0\nallowed to set command line options from conftest.py\nfiles which so far pytest-2.0 only allowed from ini-files now.','set command line options from conftest.py files',0,'',''),(13530,'pytest','introduce a mechanism to prevent/unregister plugins from the\ncommand line, see http://pytest.org/en/stable/how-to/plugins.html#cmdunregister','introduce mechanism',0,'',''),(13531,'pytest','new python invocation: pytest.main(args, plugins) to load\nsome custom plugins early.','load custom plugins',0,'',''),(13532,'pytest','try harder to run unittest test suites in a more compatible manner\nby deferring setup/teardown semantics to the unittest package.\nalso work harder to run twisted/trial and Django tests which\nshould now basically work by default.','run unittest test suites',0,'',''),(13533,'pytest','introduce a new way to set config options via ini-style files,\nby default setup.cfg and tox.ini files are searched.  The old\nways (certain environment variables, dynamic conftest.py reading\nis removed).','introduce new way by tox.ini files',0,'',''),(13534,'pytest','introduce a new way to set config options via ini-style files,\nby default setup.cfg and tox.ini files are searched.  The old\nways (certain environment variables, dynamic conftest.py reading\nis removed).','introduce new way by default setup.cfg',0,'',''),(13535,'pytest','introduce a new way to set config options via ini-style files,\nby default setup.cfg and tox.ini files are searched.  The old\nways (certain environment variables, dynamic conftest.py reading\nis removed).','set config options via ini-style files',0,'',''),(13536,'pytest','add a new “-q” option which decreases verbosity and prints a more\nnose/unittest-style “dot” output.','print nose/unittest-style dot output',0,'',''),(13537,'pytest','add a new “-q” option which decreases verbosity and prints a more\nnose/unittest-style “dot” output.','print q option',0,'',''),(13538,'pytest','fix issue126 - introduce py.test.set_trace() to trace execution via\nPDB during the running of tests even if capturing is ongoing.','introduce py.test.set_trace()',0,'',''),(13539,'pytest','introduce (customizable) assertion failure representations and enhance\noutput on assertion failures for comparisons and other cases (Floris Bruynooghe)','introduce assertion failure representations',0,'',''),(13540,'pytest','nose-plugin: pass through type-signature failures in setup/teardown\nfunctions instead of not calling them (Ed Singleton)','pass  through type-signature failures',0,'',''),(13541,'pytest','nose-plugin: pass through type-signature failures in setup/teardown\nfunctions instead of not calling them (Ed Singleton)','pass  instead_of calling',0,'',''),(13542,'pytest','remove py.test.collect.Directory (follows from a major refactoring\nand simplification of the collection process)','remove py.test.collect.Directory',0,'',''),(13543,'pytest','refine ‘tmpdir’ creation, will now create basenames better associated\nwith test names (thanks Ronny)','create basenames',0,'',''),(13544,'pytest','fix issue131 / issue60 - importing doctests in __init__ files used as namespace packages','import doctests in __init__ files',0,'',''),(13545,'pytest','fix issue131 / issue60 - importing doctests in __init__ files used as namespace packages','use  as namespace packages',0,'',''),(13546,'pytest','fix issue93 stdout/stderr is captured while importing conftest.py','import conftest.py',0,'',''),(13547,'pytest','fix bug: unittest collected functions now also can have “pytestmark”\napplied at class/module level','apply  at class/module level',0,'',''),(13548,'pytest','add ability to use “class” level for cached_setup helper','add ability',0,'',''),(13549,'pytest','add ability to use “class” level for cached_setup helper','use class level for cached_setup helper',0,'',''),(13550,'pytest','fix strangeness: mark.* objects are now immutable, create new instances','create new instances',0,'',''),(13551,'pytest','fix issue111: improve install documentation for windows','install documentation for windows',0,'',''),(13552,'pytest','fix issue118: new –tb=native for presenting cpython-standard exceptions','present cpython-standard exceptions',0,'',''),(13553,'pytest','make conftest loading detect that a conftest file with the same\ncontent was already loaded, avoids surprises in nested directory structures\nwhich can be produced e.g. by Hudson. It probably removes the need to use\n–confcutdir in most cases.','produce e.g. in nested directory structures',0,'',''),(13554,'pytest','make conftest loading detect that a conftest file with the same\ncontent was already loaded, avoids surprises in nested directory structures\nwhich can be produced e.g. by Hudson. It probably removes the need to use\n–confcutdir in most cases.','produce surprises in nested directory structures',0,'',''),(13555,'pytest','make conftest loading detect that a conftest file with the same\ncontent was already loaded, avoids surprises in nested directory structures\nwhich can be produced e.g. by Hudson. It probably removes the need to use\n–confcutdir in most cases.','load conftest file with same content',0,'',''),(13556,'pytest','make conftest loading detect that a conftest file with the same\ncontent was already loaded, avoids surprises in nested directory structures\nwhich can be produced e.g. by Hudson. It probably removes the need to use\n–confcutdir in most cases.','remove need',0,'',''),(13557,'pytest','make conftest loading detect that a conftest file with the same\ncontent was already loaded, avoids surprises in nested directory structures\nwhich can be produced e.g. by Hudson. It probably removes the need to use\n–confcutdir in most cases.','use â confcutdir in most cases',0,'',''),(13558,'pytest','fix terminal coloring for win32\n(thanks Michael Foord for reporting)','fix terminal coloring',0,'',''),(13559,'pytest','Funcarg factories can now dynamically apply a marker to a\ntest invocation.  This is for example useful if a factory\nprovides parameters to a test which are expected-to-fail:','apply marker to test invocation',1,'https://docs.pytest.org/en/7.2.x/changelog.html',''),(13560,'pytest','Funcarg factories can now dynamically apply a marker to a\ntest invocation.  This is for example useful if a factory\nprovides parameters to a test which are expected-to-fail:','provide parameters to test',1,'https://docs.pytest.org/en/7.2.x/changelog.html',''),(13561,'pytest','improved error reporting on collection and import errors. This makes\nuse of a more general mechanism, namely that for custom test item/collect\nnodes node.repr_failure(excinfo) is now uniformly called so that you can\noverride it to return a string error representation of your choice\nwhich is going to be reported as a (red) string.','return string error representation of choice',0,'',''),(13562,'pytest','improved error reporting on collection and import errors. This makes\nuse of a more general mechanism, namely that for custom test item/collect\nnodes node.repr_failure(excinfo) is now uniformly called so that you can\noverride it to return a string error representation of your choice\nwhich is going to be reported as a (red) string.','call node.repr_failure(excinfo) for custom test item/collect nodes',0,'',''),(13563,'pytest','refine –pdb: ignore xfailed tests, unify its TB-reporting and\ndon’t display failures again at the end.','ignore xfailed tests',0,'',''),(13564,'pytest','refine –pdb: ignore xfailed tests, unify its TB-reporting and\ndon’t display failures again at the end.','display failures at end',0,'',''),(13565,'pytest','fix assertion interpretation with the ** operator (thanks Benjamin Peterson)','fix assertion interpretation with ** operator',0,'',''),(13566,'pytest','fix issue105 assignment on the same line as a failing assertion (thanks Benjamin Peterson)','fix issue105 assignment on same line',0,'',''),(13567,'pytest','fix issue104 proper escaping for test names in junitxml plugin (thanks anonymous)','fix issue104 proper escaping for test names',0,'',''),(13568,'pytest','fix issue92 collectonly reporter and –pastebin (thanks Benjamin Peterson)','fix issue92 collectonly reporter',0,'',''),(13569,'pytest','fix issue92 collectonly reporter and –pastebin (thanks Benjamin Peterson)','fix â pastebin',0,'',''),(13570,'pytest','fix py.code.compile(source) to generate unique filenames','fix py.code.compile(source)',0,'',''),(13571,'pytest','fix py.code.compile(source) to generate unique filenames','generate unique filenames',0,'',''),(13572,'pytest','fix assertion re-interp problems on PyPy, by deferring code\ncompilation to the (overridable) Frame.eval class. (thanks Amaury Forgeot)','fix assertion re-interp problems by deferring',0,'',''),(13573,'pytest','fix assertion re-interp problems on PyPy, by deferring code\ncompilation to the (overridable) Frame.eval class. (thanks Amaury Forgeot)','fix assertion re-interp problems on PyPy',0,'',''),(13574,'pytest','fix assertion re-interp problems on PyPy, by deferring code\ncompilation to the (overridable) Frame.eval class. (thanks Amaury Forgeot)','defer code compilation to Frame.eval class',0,'',''),(13575,'pytest','fix py.path.local.pyimport() to work with directories','fix py.path.local.pyimport()',0,'',''),(13576,'pytest','don’t print empty lines when showing junitxml-filename','print empty lines',0,'',''),(13577,'pytest','don’t print empty lines when showing junitxml-filename','show junitxml-filename',0,'',''),(13578,'pytest','add optional boolean ignore_errors parameter to py.path.local.remove','add optional boolean ignore_errors parameter to py.path.local.remove',0,'',''),(13579,'pytest','fix terminal writing on win32/python2.4','fix terminal',0,'',''),(13580,'pytest','py.process.cmdexec() now tries harder to return properly encoded unicode objects\non all python versions','return encoded unicode objects on python versions',0,'',''),(13581,'pytest','install plain py.test/py.which scripts also for Jython, this helps to\nget canonical script paths in virtualenv situations','install plain py.test/py.which scripts for jython',0,'',''),(13582,'pytest','install plain py.test/py.which scripts also for Jython, this helps to\nget canonical script paths in virtualenv situations','get canonical script paths in virtualenv situations',0,'',''),(13583,'pytest','make path.bestrelpath(path) return “.”, note that when calling\nX.bestrelpath the assumption is that X is a directory.','call assumption',0,'',''),(13584,'pytest','make initial conftest discovery ignore “–” prefixed arguments','ignore prefixed arguments',0,'',''),(13585,'pytest','fix resultlog plugin when used in a multicpu/multihost xdist situation\n(thanks Jakub Gustak)','fix resultlog plugin',0,'',''),(13586,'pytest','fix resultlog plugin when used in a multicpu/multihost xdist situation\n(thanks Jakub Gustak)','use  in multicpu/multihost xdist situation',0,'',''),(13587,'pytest','perform distributed testing related reporting in the xdist-plugin\nrather than having dist-related code in the generic py.test\ndistribution','perform distributed testing',0,'',''),(13588,'pytest','fix homedir detection on Windows','fix homedir detection on Windows',0,'',''),(13589,'pytest','issue91: introduce new py.test.xfail(reason) helper\nto imperatively mark a test as expected to fail. Can\nbe used from within setup and test functions. This is\nuseful especially for parametrized tests when certain\nconfigurations are expected-to-fail.  In this case the\ndeclarative approach with the @py.test.mark.xfail cannot\nbe used as it would mark all configurations as xfail.','introduce new py.test.xfail(reason) helper to imperatively mark',0,'',''),(13590,'pytest','issue91: introduce new py.test.xfail(reason) helper\nto imperatively mark a test as expected to fail. Can\nbe used from within setup and test functions. This is\nuseful especially for parametrized tests when certain\nconfigurations are expected-to-fail.  In this case the\ndeclarative approach with the @py.test.mark.xfail cannot\nbe used as it would mark all configurations as xfail.','mark configurations as xfail',0,'',''),(13591,'pytest','issue102: introduce new –maxfail=NUM option to stop\ntest runs after NUM failures.  This is a generalization\nof the ‘-x’ or ‘–exitfirst’ option which is now equivalent\nto ‘–maxfail=1’.  Both ‘-x’ and ‘–maxfail’ will\nnow also print a line near the end indicating the Interruption.','print line near end',0,'',''),(13592,'pytest','issue89: allow py.test.mark decorators to be used on classes\n(class decorators were introduced with python2.6) and\nalso allow to have multiple markers applied at class/module level\nby specifying a list.','specify list',0,'',''),(13593,'pytest','issue89: allow py.test.mark decorators to be used on classes\n(class decorators were introduced with python2.6) and\nalso allow to have multiple markers applied at class/module level\nby specifying a list.','use py.test.mark decorators on classes',0,'',''),(13594,'pytest','issue89: allow py.test.mark decorators to be used on classes\n(class decorators were introduced with python2.6) and\nalso allow to have multiple markers applied at class/module level\nby specifying a list.','apply  at class/module level',0,'',''),(13595,'pytest','improve and refine letter reporting in the progress bar:\n.  pass\nf  failed test\ns  skipped tests (reminder: use for dependency/platform mismatch only)\nx  xfailed test (test that was expected to fail)\nX  xpassed test (test that was expected to fail but passed)','pass failed test',0,'',''),(13596,'pytest','improve and refine letter reporting in the progress bar:\n.  pass\nf  failed test\ns  skipped tests (reminder: use for dependency/platform mismatch only)\nx  xfailed test (test that was expected to fail)\nX  xpassed test (test that was expected to fail but passed)','skip tests',0,'',''),(13597,'pytest','improve and refine letter reporting in the progress bar:\n.  pass\nf  failed test\ns  skipped tests (reminder: use for dependency/platform mismatch only)\nx  xfailed test (test that was expected to fail)\nX  xpassed test (test that was expected to fail but passed)','skip failed test',0,'',''),(13598,'pytest','You can use any combination of ‘fsxX’ with the ‘-r’ extended\nreporting option. The xfail/xpass results will show up as\nskipped tests in the junitxml output - which also fixes\nissue99.','use combination with â-râ',0,'',''),(13599,'pytest','You can use any combination of ‘fsxX’ with the ‘-r’ extended\nreporting option. The xfail/xpass results will show up as\nskipped tests in the junitxml output - which also fixes\nissue99.','use combination of âfsxXâ',0,'',''),(13600,'pytest','You can use any combination of ‘fsxX’ with the ‘-r’ extended\nreporting option. The xfail/xpass results will show up as\nskipped tests in the junitxml output - which also fixes\nissue99.','fix skipped tests in junitxml output',0,'',''),(13601,'pytest','make py.test.cmdline.main() return the exitstatus instead of raising\nSystemExit and also allow it to be called multiple times.  This of\ncourse requires that your application and tests are properly teared\ndown and don’t have global state.','return exitstatus instead_of raising',0,'',''),(13602,'pytest','make py.test.cmdline.main() return the exitstatus instead of raising\nSystemExit and also allow it to be called multiple times.  This of\ncourse requires that your application and tests are properly teared\ndown and don’t have global state.','raise SystemExit',0,'',''),(13603,'pytest','improve support for raises and other dynamically compiled code by\nmanipulating python’s linecache.cache instead of the previous\nrather hacky way of creating custom code objects.  This makes\nit seamlessly work on Jython and PyPy where it previously didn’t.','compile code',0,'',''),(13604,'pytest','improve support for raises and other dynamically compiled code by\nmanipulating python’s linecache.cache instead of the previous\nrather hacky way of creating custom code objects.  This makes\nit seamlessly work on Jython and PyPy where it previously didn’t.','manipulate linecache.cache instead_of previous hacky way',0,'',''),(13605,'pytest','improve support for raises and other dynamically compiled code by\nmanipulating python’s linecache.cache instead of the previous\nrather hacky way of creating custom code objects.  This makes\nit seamlessly work on Jython and PyPy where it previously didn’t.','create custom code objects',0,'',''),(13606,'pytest','fix chaining of conditional skipif/xfail decorators - so it works now\nas expected to use multiple @py.test.mark.skipif(condition) decorators,\nincluding specific reporting which of the conditions lead to skipping.','use multiple  decorators',0,'',''),(13607,'pytest','deprecate –report option in favour of a new shorter and easier to\nremember -r option: it takes a string argument consisting of any\ncombination of ‘xfsX’ characters.  They relate to the single chars\nyou see during the dotted progress printing and will print an extra line\nper test at the end of the test run.  This extra line indicates the exact\nposition or test ID that you directly paste to the py.test cmdline in order\nto re-run a particular test.','print extra line at end',0,'',''),(13608,'pytest','deprecate –report option in favour of a new shorter and easier to\nremember -r option: it takes a string argument consisting of any\ncombination of ‘xfsX’ characters.  They relate to the single chars\nyou see during the dotted progress printing and will print an extra line\nper test at the end of the test run.  This extra line indicates the exact\nposition or test ID that you directly paste to the py.test cmdline in order\nto re-run a particular test.','print extra line per test',0,'',''),(13609,'pytest','deprecate –report option in favour of a new shorter and easier to\nremember -r option: it takes a string argument consisting of any\ncombination of ‘xfsX’ characters.  They relate to the single chars\nyou see during the dotted progress printing and will print an extra line\nper test at the end of the test run.  This extra line indicates the exact\nposition or test ID that you directly paste to the py.test cmdline in order\nto re-run a particular test.','print single chars at end',0,'',''),(13610,'pytest','deprecate –report option in favour of a new shorter and easier to\nremember -r option: it takes a string argument consisting of any\ncombination of ‘xfsX’ characters.  They relate to the single chars\nyou see during the dotted progress printing and will print an extra line\nper test at the end of the test run.  This extra line indicates the exact\nposition or test ID that you directly paste to the py.test cmdline in order\nto re-run a particular test.','print single chars per test',0,'',''),(13611,'pytest','deprecate –report option in favour of a new shorter and easier to\nremember -r option: it takes a string argument consisting of any\ncombination of ‘xfsX’ characters.  They relate to the single chars\nyou see during the dotted progress printing and will print an extra line\nper test at the end of the test run.  This extra line indicates the exact\nposition or test ID that you directly paste to the py.test cmdline in order\nto re-run a particular test.','paste  to py.test cmdline',0,'',''),(13612,'pytest','deprecate –report option in favour of a new shorter and easier to\nremember -r option: it takes a string argument consisting of any\ncombination of ‘xfsX’ characters.  They relate to the single chars\nyou see during the dotted progress printing and will print an extra line\nper test at the end of the test run.  This extra line indicates the exact\nposition or test ID that you directly paste to the py.test cmdline in order\nto re-run a particular test.','paste  to re-run particular test',0,'',''),(13613,'pytest','add a new pytest_ignore_collect(path, config) hook to allow projects and\nplugins to define exclusion behaviour for their directory structure -\nfor example you may define in a conftest.py this method:','add new pytest_ignore_collect(path, config) hook',1,'https://docs.pytest.org/en/7.2.x/changelog.html',''),(13614,'pytest','add a new pytest_ignore_collect(path, config) hook to allow projects and\nplugins to define exclusion behaviour for their directory structure -\nfor example you may define in a conftest.py this method:','define exclusion behaviour for directory structure',1,'https://docs.pytest.org/en/7.2.x/changelog.html',''),(13615,'pytest','add a new pytest_ignore_collect(path, config) hook to allow projects and\nplugins to define exclusion behaviour for their directory structure -\nfor example you may define in a conftest.py this method:','define  in conftest.py',1,'https://docs.pytest.org/en/7.2.x/changelog.html',''),(13616,'pytest','to prevent even a collection try of any tests in symlinked dirs.','prevent collection',0,'',''),(13617,'pytest','extend and refine xfail mechanism:\n@py.test.mark.xfail(run=False) do not run the decorated test\n@py.test.mark.xfail(reason=\"...\") prints the reason string in xfail summaries\nspecifying --runxfail on command line virtually ignores xfail markers','extend xfail mechanism',0,'',''),(13618,'pytest','extend and refine xfail mechanism:\n@py.test.mark.xfail(run=False) do not run the decorated test\n@py.test.mark.xfail(reason=\"...\") prints the reason string in xfail summaries\nspecifying --runxfail on command line virtually ignores xfail markers','print reason string in xfail summaries',0,'',''),(13619,'pytest','extend and refine xfail mechanism:\n@py.test.mark.xfail(run=False) do not run the decorated test\n@py.test.mark.xfail(reason=\"...\") prints the reason string in xfail summaries\nspecifying --runxfail on command line virtually ignores xfail markers','ignore xfail markers',0,'',''),(13620,'pytest','expose (previously internal) commonly useful methods:\npy.io.get_terminal_with() -> return terminal width\npy.io.ansi_print(…) -> print colored/bold text on linux/win32\npy.io.saferepr(obj) -> return limited representation string','expose useful methods',0,'',''),(13621,'pytest','expose (previously internal) commonly useful methods:\npy.io.get_terminal_with() -> return terminal width\npy.io.ansi_print(…) -> print colored/bold text on linux/win32\npy.io.saferepr(obj) -> return limited representation string','return limited representation string',0,'',''),(13622,'pytest','(issue85) fix junitxml plugin to handle tests with non-ascii output','fix junitxml plugin',0,'',''),(13623,'pytest','(issue85) fix junitxml plugin to handle tests with non-ascii output','handle tests with non-ascii output',0,'',''),(13624,'pytest','fixes for making the jython/win32 combination work, note however:\njython2.5.1/win32 does not provide a command line launcher, see\nhttps://bugs.jython.org/issue1491 . See pylib install documentation\nfor how to work around.','install documentation',0,'',''),(13625,'pytest','(issue87) fix unboundlocal error in assertionold code','fix unboundlocal error in assertionold code',0,'',''),(13626,'pytest','add a new option “py.test –funcargs” which shows available funcargs\nand their help strings (docstrings on their respective factory function)\nfor a given test path','add new option py.test â funcargs',0,'',''),(13627,'pytest','add a new option “py.test –funcargs” which shows available funcargs\nand their help strings (docstrings on their respective factory function)\nfor a given test path','show available funcargs for given test path',0,'',''),(13628,'pytest','add a new option “py.test –funcargs” which shows available funcargs\nand their help strings (docstrings on their respective factory function)\nfor a given test path','show help strings for given test path',0,'',''),(13629,'pytest','add a new option “py.test –funcargs” which shows available funcargs\nand their help strings (docstrings on their respective factory function)\nfor a given test path','show new option py.test â funcargs for given test path',0,'',''),(13630,'pytest','display a short and concise traceback if a funcarg lookup fails','display short concise traceback',0,'',''),(13631,'pytest','early-load “conftest.py” files in non-dot first-level sub directories.\nallows to conveniently keep and access test-related options in a test\nsubdir and still add command line options.','add command line options',0,'',''),(13632,'pytest','fix issue67: new super-short traceback-printing option: “–tb=line” will print a single line for each failing (python) test indicating its filename, lineno and the failure value','print single line for failing test',0,'',''),(13633,'pytest','fix issue78: always call python-level teardown functions even if the\naccording setup failed.  This includes refinements for calling setup_module/class functions\nwhich will now only be called once instead of the previous behaviour where they’d be called\nmultiple times if they raise an exception (including a Skipped exception).  Any exception\nwill be re-corded and associated with all tests in the according module/class scope.','call python-level teardown functions',0,'',''),(13634,'pytest','fix issue78: always call python-level teardown functions even if the\naccording setup failed.  This includes refinements for calling setup_module/class functions\nwhich will now only be called once instead of the previous behaviour where they’d be called\nmultiple times if they raise an exception (including a Skipped exception).  Any exception\nwill be re-corded and associated with all tests in the according module/class scope.','include refinements for calling',0,'',''),(13635,'pytest','fix pdb debugging to be in the correct frame on raises-related errors','fix pdb',0,'',''),(13636,'pytest','update apipkg.py to fix an issue where recursive imports might\nunnecessarily break importing','update apipkg.py',0,'',''),(13637,'pytest','update apipkg.py to fix an issue where recursive imports might\nunnecessarily break importing','fix issue',0,'',''),(13638,'pytest','fix plugin links','fix plugin links',0,'',''),(13639,'pytest','moved dist/looponfailing from py.test core into a new\nseparately released pytest-xdist plugin.','release pytest-xdist plugin',0,'',''),(13640,'pytest','new junitxml plugin: –junitxml=path will generate a junit style xml file\nwhich is processable e.g. by the Hudson CI system.','generate junit style xml file',0,'',''),(13641,'pytest','new option: –genscript=path will generate a standalone py.test script\nwhich will not need any libraries installed.  thanks to Ralf Schmitt.','generate standalone py.test script',0,'',''),(13642,'pytest','new option: –ignore will prevent specified path from collection.\nCan be specified multiple times.','prevent specified path from collection',0,'',''),(13643,'pytest','new funcarg: “pytestconfig” is the pytest config object for access\nto command line args and can now be easily used in a test.','use  in test',0,'',''),(13644,'pytest','install py.test and py.which with a -$VERSION suffix to\ndisambiguate between Python3, python2.X, Jython and PyPy installed versions.','install py.test with  suffix',0,'',''),(13645,'pytest','install py.test and py.which with a -$VERSION suffix to\ndisambiguate between Python3, python2.X, Jython and PyPy installed versions.','install py.which with  suffix',0,'',''),(13646,'pytest','new “pytestconfig” funcarg allows access to test config object','test config object',0,'',''),(13647,'pytest','new “pytest_report_header” hook can return additional lines\nto be displayed at the header of a test run.','return additional lines',0,'',''),(13648,'pytest','new “pytest_report_header” hook can return additional lines\nto be displayed at the header of a test run.','display  at header',0,'',''),(13649,'pytest','streamlined plugin loading: order is now as documented in\ncustomize.html: setuptools, ENV, commandline, conftest.\nalso setuptools entry point names are turned to canonical names (“pytest_*”)','document  in customize.html',0,'',''),(13650,'pytest','automatically skip tests that need ‘capfd’ but have no os.dup','skip tests',0,'',''),(13651,'pytest','allow pytest_generate_tests to be defined in classes as well','define  in classes',0,'',''),(13652,'pytest','collection/item node specific runtest/collect hooks are only called exactly\non matching conftest.py files, i.e. ones which are exactly below\nthe filesystem path of an item','call collection/item node specific runtest/collect hooks on matching conftest.py files',0,'',''),(13653,'pytest','change: the first pytest_collect_directory hook to return something\nwill now prevent further hooks to be called.','prevent further hooks',0,'',''),(13654,'pytest','change: figleaf plugin now requires –figleaf to run.  Also\nchange its long command line options to be a bit shorter (see py.test -h).','change long command line options',0,'',''),(13655,'pytest','change: pytest doctest plugin is now enabled by default and has a\nnew option –doctest-glob to set a pattern for file matches.','set pattern for file',0,'',''),(13656,'pytest','change: pytest doctest plugin is now enabled by default and has a\nnew option –doctest-glob to set a pattern for file matches.','enable pytest doctest plugin',0,'',''),(13657,'pytest','change: remove internal py._* helper vars, only keep py._pydir','remove internal py',0,'',''),(13658,'pytest','simplify internal collection tree by introducing a RootCollector node','introduce RootCollector node',0,'',''),(13659,'pytest','fix issue65: properly handle dist-testing if no\nexecnet/py lib installed remotely.','install remotely',0,'',''),(13660,'pytest','skip some install-tests if no execnet is available','skip install-tests',0,'',''),(13661,'pytest','fix docs, fix internal bin/ script generation','fix docs',0,'',''),(13662,'pytest','fix docs, fix internal bin/ script generation','fix script generation',0,'',''),(13663,'pytest','fix docs, fix internal bin/ script generation','fix internal bin /',0,'',''),(13664,'pytest','introduce automatic plugin registration via ‘pytest11’\nentrypoints via setuptools’ pkg_resources.iter_entry_points','introduce automatic plugin registration via âpytest11â entrypoints',0,'',''),(13665,'pytest','svn paths: fix a bug with path.check(versioned=True) for svn paths,\nallow ‘%’ in svn paths, make svnwc.update() default to interactive mode\nlike in 1.0.x and add svnwc.update(interactive=False) to inhibit interaction.','fix bug with path.check(versioned=True)',0,'',''),(13666,'pytest','svn paths: fix a bug with path.check(versioned=True) for svn paths,\nallow ‘%’ in svn paths, make svnwc.update() default to interactive mode\nlike in 1.0.x and add svnwc.update(interactive=False) to inhibit interaction.','add svnwc.update(interactive=False)',0,'',''),(13667,'pytest','adjust and improve docs','adjust docs',0,'',''),(13668,'pytest','remove py.rest tool and internal namespace - it was\nnever really advertised and can still be used with\nthe old release if needed.  If there is interest\nit could be revived into its own tool i guess.','remove py.rest tool',0,'',''),(13669,'pytest','remove py.rest tool and internal namespace - it was\nnever really advertised and can still be used with\nthe old release if needed.  If there is interest\nit could be revived into its own tool i guess.','remove internal namespace',0,'',''),(13670,'pytest','remove py.rest tool and internal namespace - it was\nnever really advertised and can still be used with\nthe old release if needed.  If there is interest\nit could be revived into its own tool i guess.','use  with old release',0,'',''),(13671,'pytest','fix issue48 and issue59: raise an Error if the module\nfrom an imported test file does not seem to come from\nthe filepath - avoids “same-name” confusion that has\nbeen reported repeatedly','raise Error',0,'',''),(13672,'pytest','merged Ronny’s nose-compatibility hacks: now\nnose-style setup_module() and setup() functions are\nsupported','support nose-style setup_module()',0,'',''),(13673,'pytest','merged Ronny’s nose-compatibility hacks: now\nnose-style setup_module() and setup() functions are\nsupported','support setup() functions',0,'',''),(13674,'pytest','introduce generalized py.test.mark function marking','introduce generalized py.test.mark function',0,'',''),(13675,'pytest','deprecate parser.addgroup in favour of getgroup which creates option group','create option group in favour',0,'',''),(13676,'pytest','deprecate parser.addgroup in favour of getgroup which creates option group','create parser.addgroup in favour',0,'',''),(13677,'pytest','add –report command line option that allows to control showing of skipped/xfailed sections','add â report command line option',0,'',''),(13678,'pytest','generalized skipping: a new way to mark python functions with skipif or xfail\nat function, class and modules level based on platform or sys-module attributes.','mark python functions with skipif',0,'',''),(13679,'pytest','generalized skipping: a new way to mark python functions with skipif or xfail\nat function, class and modules level based on platform or sys-module attributes.','mark python functions with xfail',0,'',''),(13680,'pytest','generalized skipping: a new way to mark python functions with skipif or xfail\nat function, class and modules level based on platform or sys-module attributes.','mark python functions at function class modules level',0,'',''),(13681,'pytest','introduce and test “py.cleanup -d” to remove empty directories','introduce py.cleanup',0,'',''),(13682,'pytest','introduce and test “py.cleanup -d” to remove empty directories','test py.cleanup',0,'',''),(13683,'pytest','introduce and test “py.cleanup -d” to remove empty directories','remove empty directories',0,'',''),(13684,'pytest','make bpython/help interaction work by adding an __all__ attribute\nto ApiModule, cleanup initpkg','add __all__ attribute to ApiModule',0,'',''),(13685,'pytest','use MIT license for pylib, add some contributors','add contributors',0,'',''),(13686,'pytest','remove py.execnet code and substitute all usages with ‘execnet’ proper','remove py.execnet code',0,'',''),(13687,'pytest','fix issue50 - cached_setup now caches more to expectations\nfor test functions with multiple arguments.','cache  with multiple arguments',0,'',''),(13688,'pytest','fix issue50 - cached_setup now caches more to expectations\nfor test functions with multiple arguments.','cache  to expectations',0,'',''),(13689,'pytest','add the ability to specify a path for py.lookup to search in','add ability',0,'',''),(13690,'pytest','add the ability to specify a path for py.lookup to search in','specify path for py.lookup',0,'',''),(13691,'pytest','fix a funcarg cached_setup bug probably only occurring\nin distributed testing and “module” scope with teardown.','fix funcarg cached_setup bug',0,'',''),(13692,'pytest','deprecate py.magic.autopath, remove py/magic directory','remove py/magic directory',0,'',''),(13693,'pytest','move pytest assertion handling to py/code and a pytest_assertion\nplugin, add “–no-assert” option, deprecate py.magic namespaces\nin favour of (less) py.code ones.','move pytest assertion handling to py/code',0,'',''),(13694,'pytest','move pytest assertion handling to py/code and a pytest_assertion\nplugin, add “–no-assert” option, deprecate py.magic namespaces\nin favour of (less) py.code ones.','move pytest assertion handling to pytest_assertion plugin',0,'',''),(13695,'pytest','move pytest assertion handling to py/code and a pytest_assertion\nplugin, add “–no-assert” option, deprecate py.magic namespaces\nin favour of (less) py.code ones.','add â no-assert option',0,'',''),(13696,'pytest','introduce delattr/delitem/delenv methods to py.test’s monkeypatch funcarg','introduce delattr/delitem/delenv methods to monkeypatch funcarg',0,'',''),(13697,'pytest','consolidate py.log implementation, remove old approach.','remove old approach',0,'',''),(13698,'pytest','introduce py.io.TextIO and py.io.BytesIO for distinguishing between\ntext/unicode and byte-streams (uses underlying standard lib io.*\nif available)','introduce py.io.TextIO',0,'',''),(13699,'pytest','introduce py.io.TextIO and py.io.BytesIO for distinguishing between\ntext/unicode and byte-streams (uses underlying standard lib io.*\nif available)','introduce py.io.BytesIO',0,'',''),(13700,'pytest','make py.unittest_convert helper script available which converts “unittest.py”\nstyle files into the simpler assert/direct-test-classes py.test/nosetests\nstyle.  The script was written by Laura Creighton.','convert unittest.py style files into simpler assert/direct-test-classes py.test/nosetests style',0,'',''),(13701,'pytest','make py.unittest_convert helper script available which converts “unittest.py”\nstyle files into the simpler assert/direct-test-classes py.test/nosetests\nstyle.  The script was written by Laura Creighton.','write script',0,'',''),(13702,'pytest','fixing packaging issues, triggered by fedora redhat packaging,\nalso added doc, examples and contrib dirs to the tarball.','add doc examples for fixing packaging issues',0,'',''),(13703,'pytest','fixing packaging issues, triggered by fedora redhat packaging,\nalso added doc, examples and contrib dirs to the tarball.','add doc examples to tarball',0,'',''),(13704,'pytest','fixing packaging issues, triggered by fedora redhat packaging,\nalso added doc, examples and contrib dirs to the tarball.','add contrib dirs for fixing packaging issues',0,'',''),(13705,'pytest','fixing packaging issues, triggered by fedora redhat packaging,\nalso added doc, examples and contrib dirs to the tarball.','add contrib dirs to tarball',0,'',''),(13706,'pytest','fixing packaging issues, triggered by fedora redhat packaging,\nalso added doc, examples and contrib dirs to the tarball.','trigger  by fedora redhat packaging',0,'',''),(13707,'pytest','added a documentation link to the new django plugin.','add documentation link to new django plugin',0,'',''),(13708,'pytest','added a ‘pytest_nose’ plugin which handles nose.SkipTest,\nnose-style function/method/generator setup/teardown and\ntries to report functions correctly.','add âpytest_noseâ plugin',0,'',''),(13709,'pytest','added a ‘pytest_nose’ plugin which handles nose.SkipTest,\nnose-style function/method/generator setup/teardown and\ntries to report functions correctly.','handle nose.SkipTest nose-style function/method/generator setup/teardown',0,'',''),(13710,'pytest','added a ‘pytest_nose’ plugin which handles nose.SkipTest,\nnose-style function/method/generator setup/teardown and\ntries to report functions correctly.','handle âpytest_noseâ plugin',0,'',''),(13711,'pytest','capturing of unicode writes or encoded strings to sys.stdout/err\nwork better, also terminalwriting was adapted and somewhat\nunified between windows and linux.','encode strings to sys.stdout/err work better terminalwriting linux',0,'',''),(13712,'pytest','added a “–help-config” option to show conftest.py / ENV-var names for\nall longopt cmdline options, and some special conftest.py variables.\nrenamed ‘conf_capture’ conftest setting to ‘option_capture’ accordingly.','add â help-config option',0,'',''),(13713,'pytest','added a “–help-config” option to show conftest.py / ENV-var names for\nall longopt cmdline options, and some special conftest.py variables.\nrenamed ‘conf_capture’ conftest setting to ‘option_capture’ accordingly.','show conftest.py',0,'',''),(13714,'pytest','added a “–help-config” option to show conftest.py / ENV-var names for\nall longopt cmdline options, and some special conftest.py variables.\nrenamed ‘conf_capture’ conftest setting to ‘option_capture’ accordingly.','set  to âoption_captureâ',0,'',''),(13715,'pytest','fix issue #33: added –version flag (thanks Benjamin Peterson)','add â version flag',0,'',''),(13716,'pytest','fix issue #32: adding support for “incomplete” paths to wcpath.status()','add support for incomplete paths',0,'',''),(13717,'pytest','fix issue #32: adding support for “incomplete” paths to wcpath.status()','add support to wcpath.status()',0,'',''),(13718,'pytest','simplified multicall mechanism and plugin architecture,\nrenamed some internal methods and argnames','rename internal methods',0,'',''),(13719,'pytest','simplified multicall mechanism and plugin architecture,\nrenamed some internal methods and argnames','rename argnames',0,'',''),(13720,'pytest','fix svn-1.6 compat issue with py.path.svnwc().versioned()\n(thanks Wouter Vanden Hove)','fix svn-1 compat issue with py.path.svnwc().versioned()',0,'',''),(13721,'pytest','setup/teardown or collection problems now show as ERRORs\nor with big “E“‘s in the progress lines.  they are reported\nand counted separately.','show  with big es',0,'',''),(13722,'pytest','setup/teardown or collection problems now show as ERRORs\nor with big “E“‘s in the progress lines.  they are reported\nand counted separately.','show  as errors',0,'',''),(13723,'pytest','dist-testing: properly handle test items that get locally\ncollected but cannot be collected on the remote side - often\ndue to platform/dependency reasons','handle test items due_to platform/dependency reasons',0,'',''),(13724,'pytest','integrate better with logging: capturing now by default captures\ntest functions and their immediate setup/teardown in a single stream','integrate  with immediate setup/teardown',0,'',''),(13725,'pytest','integrate better with logging: capturing now by default captures\ntest functions and their immediate setup/teardown in a single stream','integrate  with logging',0,'',''),(13726,'pytest','integrate better with logging: capturing now by default captures\ntest functions and their immediate setup/teardown in a single stream','integrate  with capturing',0,'',''),(13727,'pytest','introduced pytest_keyboardinterrupt hook and\nrefined pytest_sessionfinish hooked, added tests.','introduce pytest_keyboardinterrupt hook',0,'',''),(13728,'pytest','introduced pytest_keyboardinterrupt hook and\nrefined pytest_sessionfinish hooked, added tests.','introduce refined pytest_sessionfinish',0,'',''),(13729,'pytest','if plugins use “py.test.importorskip” for importing\na dependency only a warning will be issued instead\nof exiting the testing process.','use py.test.importorskip for importing',0,'',''),(13730,'pytest','if plugins use “py.test.importorskip” for importing\na dependency only a warning will be issued instead\nof exiting the testing process.','import dependency',0,'',''),(13731,'pytest','many improvements to docs:\n- refined funcargs doc , use the term “factory” instead of “provider”\n- added a new talk/tutorial doc page\n- better download page\n- better plugin docstrings\n- added new plugins page and automatic doc generation script','add new plugins page',0,'',''),(13732,'pytest','many improvements to docs:\n- refined funcargs doc , use the term “factory” instead of “provider”\n- added a new talk/tutorial doc page\n- better download page\n- better plugin docstrings\n- added new plugins page and automatic doc generation script','add automatic doc generation script',0,'',''),(13733,'pytest','many improvements to docs:\n- refined funcargs doc , use the term “factory” instead of “provider”\n- added a new talk/tutorial doc page\n- better download page\n- better plugin docstrings\n- added new plugins page and automatic doc generation script','add term factory instead_of provider',0,'',''),(13734,'pytest','renamed py.test.xfail back to py.test.mark.xfail to avoid\ntwo ways to decorate for xfail','rename py.test.xfail',0,'',''),(13735,'pytest','perform setup finalization before reporting failures','perform setup finalization before reporting',0,'',''),(13736,'pytest','apply modified patches from Andreas Kloeckner to allow\ntest functions to have no func_code (#22) and to make\n“-k” and function keywords work  (#20)','apply modified patches from Andreas kloeckner',0,'',''),(13737,'pytest','apply patch from Daniel Peolzleithner (issue #23)','apply patch from Daniel peolzleithner',0,'',''),(13738,'pytest','plugin classes are removed: one now defines\nhooks directly in conftest.py or global pytest_*.py\nfiles.','define hooks in conftest.py global pytest _ *',0,'',''),(13739,'pytest','plugin classes are removed: one now defines\nhooks directly in conftest.py or global pytest_*.py\nfiles.','remove plugin classes',0,'',''),(13740,'pytest','added new style of generative tests via\npytest_generate_tests hook that integrates\nwell with function arguments.','integrate pytest_generate_tests hook with function arguments',0,'',''),(13741,'pytest','introduced new “funcarg” setup method,\nsee doc/test/funcarg.txt','introduce new funcarg setup method',0,'',''),(13742,'pytest','new method: py.test.importorskip(mod,minversion)\nwill either import or call py.test.skip()','import py.test.skip()',0,'',''),(13743,'pytest','new method: py.test.importorskip(mod,minversion)\nwill either import or call py.test.skip()','call py.test.skip()',0,'',''),(13744,'pytest','new py.process.ForkedFunc object allowing to\nfork execution of a function to a sub process\nand getting a result back.','get result',0,'',''),(13745,'pytest','refined installation and metadata, created new setup.py,\nnow based on setuptools/ez_setup (thanks to Ralf Schmitt\nfor his support).','create new setup.py',0,'',''),(13746,'pytest','improved the way of making py.* scripts available in\nwindows environments, they are now added to the\nScripts directory as “.cmd” files.','add  to Scripts directory',0,'',''),(13747,'pytest','py.path.svnwc.status() now is more complete and\nuses xml output from the ‘svn’ command if available\n(Guido Wesdorp)','use xml output from âsvnâ command available',0,'',''),(13748,'pytest','fix for py.path.svn* to work with svn 1.5\n(Chris Lamb)','fix  for py.path.svn*',0,'',''),(13749,'pytest','fix path.relto(otherpath) method on windows to\nuse normcase for checking if a path is relative.','fix path.relto(otherpath) method on windows',0,'',''),(13750,'pytest','fix path.relto(otherpath) method on windows to\nuse normcase for checking if a path is relative.','use normcase for checking',0,'',''),(13751,'pytest','removed previously accidentally added\npy.test.broken and py.test.notimplemented helpers.','add py.test.broken py.test.notimplemented helpers',0,'',''),(13752,'pytest','fixed support for Failed exceptions without excinfo in py.test [39340]','fix support for Failed exceptions',0,'',''),(13753,'pytest','fixed support for Failed exceptions without excinfo in py.test [39340]','fix support without excinfo',0,'',''),(13754,'pytest','added support for killing processes for Windows (as well as platforms that\nsupport os.kill) in py.misc.killproc [39655]','add support',0,'',''),(13755,'pytest','added setup/teardown for generative tests to py.test [40702]','add setup/teardown for generative tests',0,'',''),(13756,'pytest','added setup/teardown for generative tests to py.test [40702]','add setup/teardown to py.test',0,'',''),(13757,'pytest','added detection of FAILED TO LOAD MODULE to py.test [40703, 40738, 40739]','add detection of FAILED TO LOAD MODULE',0,'',''),(13758,'pytest','added detection of FAILED TO LOAD MODULE to py.test [40703, 40738, 40739]','add detection to py.test',0,'',''),(13759,'pytest','fixed problem with calling .remove() on wcpaths of non-versioned files in\npy.path [44248]','fix  with calling',0,'',''),(13760,'pytest','fixed problem with calling .remove() on wcpaths of non-versioned files in\npy.path [44248]','call .remove() on wcpaths',0,'',''),(13761,'pytest','fixed some import and inheritance issues in py.test [41480, 44648, 44655]','fix import inheritance issues in py.test',0,'',''),(13762,'pytest','fail to run greenlet tests when pypy is available, but without stackless\n[45294]','run greenlet tests',0,'',''),(13763,'pytest','made that non-existing files are ignored by the py.lookup script [45519]','ignore non-existing files',0,'',''),(13764,'pytest','made that less threads are used in execnet [merge in 45539]','use less threads in execnet',0,'',''),(13765,'pytest','removed lock required for atomic reporting issue displaying in py.test\n[45545]','remove lock',0,'',''),(13766,'pytest','removed lock required for atomic reporting issue displaying in py.test\n[45545]','display  in py.test',0,'',''),(13767,'pytest','removed globals from execnet [45541, 45547]','remove globals from execnet',0,'',''),(13768,'pytest','refactored cleanup mechanics, made that setDaemon is set to 1 to make atexit\nget called in 2.5 (py.execnet) [45548]','refactor cleanup mechanics',0,'',''),(13769,'pytest','refactored cleanup mechanics, made that setDaemon is set to 1 to make atexit\nget called in 2.5 (py.execnet) [45548]','set setDaemon',0,'',''),(13770,'pytest','refactored cleanup mechanics, made that setDaemon is set to 1 to make atexit\nget called in 2.5 (py.execnet) [45548]','call atexit',0,'',''),(13771,'pytest','using repr() on test outcome [45647]','use repr() on test outcome  45647',0,'',''),(13772,'pytest','added ‘Reason’ classes for py.test.skip() [45648, 45649]','add âReasonâ classes for py.test.skip()',0,'',''),(13773,'pytest','avoid using os.tmpfile() in py.io.fdcapture because on Windows it’s only\nusable by Administrators [45901]','use os.tmpfile() in py.io.fdcapture',0,'',''),(13774,'pytest','added support for locking and non-recursive commits to py.path.svnwc [45994]','add support for locking non-recursive commits',0,'',''),(13775,'pytest','added support for locking and non-recursive commits to py.path.svnwc [45994]','add support to py.path.svnwc',0,'',''),(13776,'pytest','locking files in py.execnet to prevent CPython from segfaulting [46010]','prevent cpython from segfaulting',0,'',''),(13777,'pytest','fixed argument concatenation problem in py.path.svnwc [49423]','fix argument concatenation problem in py.path.svnwc',0,'',''),(13778,'pytest','fix _docgen.py documentation building [51285]','fix _docgen.py',0,'',''),(13779,'pytest','added support for passing authentication to py.path.svn* objects [52000,\n52001]','add support for passing',0,'',''),(13780,'pytest','added support for passing authentication to py.path.svn* objects [52000,\n52001]','pass authentication to py.path.svn* objects',0,'',''),(13781,'pytest','removed sorted() call for py.apigen tests in favour of [].sort() to support\nPython 2.3 [52481]','remove sorted() call for py.apigen tests',0,'',''),(13782,'pytest','removed sorted() call for py.apigen tests in favour of [].sort() to support\nPython 2.3 [52481]','support Python',0,'',''),(13783,'pytest','Download latest version as PDF','download latest version as PDF',0,'',''),(13784,'pytest','Run the following command in your command line:','run following command in command line',0,'',''),(13785,'pytest','Check that you installed the correct version:','install correct version',0,'',''),(13786,'pytest','Create a new file called test_sample.py, containing a function, and a test:','call test_sample.py',1,'https://docs.pytest.org/en/7.2.x/getting-started.html','simpletest'),(13787,'pytest','The [100%] refers to the overall progress of running all test cases. After it finishes, pytest then shows a failure report because func(3) does not return 5.','run test cases',0,'',''),(13788,'pytest','The [100%] refers to the overall progress of running all test cases. After it finishes, pytest then shows a failure report because func(3) does not return 5.','show failure report',0,'',''),(13789,'pytest','You can use the assert statement to verify test expectations. pytest’s Advanced assertion introspection will intelligently report intermediate values of the assert expression so you can avoid the many names of JUnit legacy methods.','use assert statement',0,'',''),(13790,'pytest','pytest will run all files of the form test_*.py or *_test.py in the current directory and its subdirectories. More generally, it follows standard test discovery rules.','run files of form test _ *',0,'',''),(13791,'pytest','Use the raises helper to assert that some code raises an exception:','raise exception',1,'https://docs.pytest.org/en/7.2.x/getting-started.html',''),(13792,'pytest','Execute the test function with “quiet” reporting mode:','execute test function with quiet reporting mode',1,'https://docs.pytest.org/en/7.2.x/getting-started.html',''),(13793,'pytest','Once you develop multiple tests, you may want to group them into a class. pytest makes it easy to create a class containing more than one test:','develop multiple tests',1,'https://docs.pytest.org/en/7.2.x/getting-started.html',''),(13794,'pytest','Once you develop multiple tests, you may want to group them into a class. pytest makes it easy to create a class containing more than one test:','create class',1,'https://docs.pytest.org/en/7.2.x/getting-started.html',''),(13795,'pytest','pytest discovers all tests following its Conventions for Python test discovery, so it finds both test_ prefixed functions. There is no need to subclass anything, but make sure to prefix your class with Test otherwise the class will be skipped. We can simply run the module by passing its filename:','find test',1,'https://docs.pytest.org/en/7.2.x/getting-started.html',''),(13796,'pytest','pytest discovers all tests following its Conventions for Python test discovery, so it finds both test_ prefixed functions. There is no need to subclass anything, but make sure to prefix your class with Test otherwise the class will be skipped. We can simply run the module by passing its filename:','prefix class with test',1,'https://docs.pytest.org/en/7.2.x/getting-started.html',''),(13797,'pytest','pytest discovers all tests following its Conventions for Python test discovery, so it finds both test_ prefixed functions. There is no need to subclass anything, but make sure to prefix your class with Test otherwise the class will be skipped. We can simply run the module by passing its filename:','run module by passing',1,'https://docs.pytest.org/en/7.2.x/getting-started.html',''),(13798,'pytest','pytest discovers all tests following its Conventions for Python test discovery, so it finds both test_ prefixed functions. There is no need to subclass anything, but make sure to prefix your class with Test otherwise the class will be skipped. We can simply run the module by passing its filename:','pass filename',1,'https://docs.pytest.org/en/7.2.x/getting-started.html',''),(13799,'pytest','Sharing fixtures for tests only in that particular class','share fixtures for tests',0,'',''),(13800,'pytest','Applying marks at the class level and having them implicitly apply to all tests','apply marks at class level',0,'',''),(13801,'pytest','Applying marks at the class level and having them implicitly apply to all tests','apply  to tests',0,'',''),(13802,'pytest','Something to be aware of when grouping tests inside classes is that each test has a unique instance of the class.\nHaving each test share the same class instance would be very detrimental to test isolation and would promote poor test practices.\nThis is outlined below:','group tests inside classes',1,'https://docs.pytest.org/en/7.2.x/getting-started.html',''),(13803,'pytest','Something to be aware of when grouping tests inside classes is that each test has a unique instance of the class.\nHaving each test share the same class instance would be very detrimental to test isolation and would promote poor test practices.\nThis is outlined below:','share same class instance',1,'https://docs.pytest.org/en/7.2.x/getting-started.html',''),(13804,'pytest','Something to be aware of when grouping tests inside classes is that each test has a unique instance of the class.\nHaving each test share the same class instance would be very detrimental to test isolation and would promote poor test practices.\nThis is outlined below:','test isolation',1,'https://docs.pytest.org/en/7.2.x/getting-started.html',''),(13805,'pytest','Note that attributes added at class level are class attributes, so they will be shared between tests.','add  at class level',0,'',''),(13806,'pytest','Note that attributes added at class level are class attributes, so they will be shared between tests.','share  between tests',0,'',''),(13807,'pytest','pytest provides Builtin fixtures/function arguments to request arbitrary resources, like a unique temporary directory:','request arbitrary resources like unique temporary directory',1,'https://docs.pytest.org/en/7.2.x/getting-started.html',''),(13808,'pytest','List the name tmp_path in the test function signature and pytest will lookup and call a fixture factory to create the resource before performing the test function call. Before the test runs, pytest creates a unique-per-test-invocation temporary directory:','list name tmp_path in test function signature',1,'https://docs.pytest.org/en/7.2.x/getting-started.html',''),(13809,'pytest','List the name tmp_path in the test function signature and pytest will lookup and call a fixture factory to create the resource before performing the test function call. Before the test runs, pytest creates a unique-per-test-invocation temporary directory:','list name tmp_path in pytest',1,'https://docs.pytest.org/en/7.2.x/getting-started.html',''),(13810,'pytest','List the name tmp_path in the test function signature and pytest will lookup and call a fixture factory to create the resource before performing the test function call. Before the test runs, pytest creates a unique-per-test-invocation temporary directory:','create resource before performing',1,'https://docs.pytest.org/en/7.2.x/getting-started.html',''),(13811,'pytest','List the name tmp_path in the test function signature and pytest will lookup and call a fixture factory to create the resource before performing the test function call. Before the test runs, pytest creates a unique-per-test-invocation temporary directory:','perform test function call',1,'https://docs.pytest.org/en/7.2.x/getting-started.html',''),(13812,'pytest','List the name tmp_path in the test function signature and pytest will lookup and call a fixture factory to create the resource before performing the test function call. Before the test runs, pytest creates a unique-per-test-invocation temporary directory:','create unique-per-test-invocation temporary directory',1,'https://docs.pytest.org/en/7.2.x/getting-started.html',''),(13813,'pytest','Note that this command omits fixtures with leading _ unless the -v option is added.','omit fixtures with leading _',0,'',''),(13814,'pytest','Note that this command omits fixtures with leading _ unless the -v option is added.','add v option',0,'',''),(13815,'pytest','Check out additional pytest resources to help you customize tests for your unique workflow:','customize tests for unique workflow',0,'',''),(13816,'pytest','“How to use pytest with an existing test suite” for working with pre-existing tests','use pytest with existing test suite',0,'',''),(13817,'pytest','“How to mark test functions with attributes” for information on the pytest.mark mechanism','mark test functions',0,'',''),(13818,'pytest','“Fixtures reference” for providing a functional baseline to your tests','provide functional baseline to tests',0,'',''),(13819,'pytest','“Fixtures reference” for providing a functional baseline to your tests','reference  for providing',0,'',''),(13820,'pytest','“Writing plugins” for managing and writing plugins','manage plugins',0,'',''),(13821,'pytest','“Writing plugins” for managing and writing plugins','write plugins',0,'',''),(13822,'pytest','Testing PySide/PyQt code easily using the pytest framework, Florian Bruhin, Qt World Summit 2019 (slides, recording)','use pytest framework',0,'',''),(13823,'pytest','Why i use py.test and maybe you should too, Andy Todd, Pycon AU 2013','use py.test',0,'',''),(13824,'pytest','pytest: helps you write better Django apps, Andreas Pelme, DjangoCon\nEurope 2014.','write better Django apps',0,'',''),(13825,'pytest','test generators and cached setup','test generators',0,'',''),(13826,'pytest','test generators and cached setup','test cached setup',0,'',''),(13827,'pytest','simultaneously test your code on all platforms (blog entry)','test code on platforms',0,'',''),(13828,'pytest','skipping slow tests by default in pytest (blog entry)','skip slow tests by default',0,'',''),(13829,'pytest','The pytest framework makes it easy to write small, readable tests, and can\nscale to support complex functional testing for applications and libraries.','write small readable tests',0,'',''),(13830,'pytest','The pytest framework makes it easy to write small, readable tests, and can\nscale to support complex functional testing for applications and libraries.','support functional testing for applications',0,'',''),(13831,'pytest','The pytest framework makes it easy to write small, readable tests, and can\nscale to support complex functional testing for applications and libraries.','support functional testing for libraries',0,'',''),(13832,'pytest','Due to pytest’s detailed assertion introspection, only plain assert statements are used.\nSee Get started for a basic introduction to using pytest.','use plain assert statements due_to detailed assertion introspection',0,'',''),(13833,'pytest','Due to pytest’s detailed assertion introspection, only plain assert statements are used.\nSee Get started for a basic introduction to using pytest.','use pytest',0,'',''),(13834,'pytest','Modular fixtures for managing small or parametrized long-lived test resources','manage small parametrized long-lived test resources',0,'',''),(13835,'pytest','Can run unittest (including trial) and nose test suites out of the box','run unittest nose test suites out_of box',0,'',''),(13836,'pytest','Get started - install pytest and grasp its basics just twenty minutes','install pytest',0,'',''),(13837,'pytest','Reference guides - includes the complete pytest API reference, lists of plugins and more','include complete pytest API reference of plugins',0,'',''),(13838,'pytest','Reference guides - includes the complete pytest API reference, lists of plugins and more','include lists of plugins',0,'',''),(13839,'pytest','Please use the GitHub issue tracker to submit bugs or request features.','submit bugs',0,'',''),(13840,'pytest','Please use the GitHub issue tracker to submit bugs or request features.','submit request features',0,'',''),(13841,'pytest','Open Collective is an online funding platform for open and transparent communities.\nIt provides tools to raise money and share your finances in full transparency.','raise money',0,'',''),(13842,'pytest','Open Collective is an online funding platform for open and transparent communities.\nIt provides tools to raise money and share your finances in full transparency.','share finances in full transparency',0,'',''),(13843,'pytest','The maintainers of pytest and thousands of other packages are working with Tidelift to deliver commercial support and\nmaintenance for the open source dependencies you use to build your applications.\nSave time, reduce risk, and improve code health, while paying the maintainers of the exact dependencies you use.','save time',0,'',''),(13844,'pytest','pytest has never been associated with a security vulnerability, but in any case, to report a\nsecurity vulnerability please use the Tidelift security contact.\nTidelift will coordinate the fix and disclosure.','use tidelift security contact',0,'',''),(13845,'pytest','pytest is a mature full-featured Python testing tool that helps\n  you write better programs.','write better programs',0,'',''),(13846,'pytest','While we implement those modifications we try to ensure an easy transition and don’t want to impose unnecessary churn on our users and community/plugin authors.','implement modifications',0,'',''),(13847,'pytest','trivial: APIs which trivially translate to the new mechanism,\nand do not cause problematic changes.','translate apis to new mechanism',0,'',''),(13848,'pytest','transitional: the old and new API don’t conflict\nand we can help users transition by using warnings, while supporting both for a prolonged time.','use warnings',0,'',''),(13849,'pytest','A deprecated feature scheduled to be removed in major version X will use the warning class PytestRemovedInXWarning (a subclass of PytestDeprecationwarning).','use warning class PytestRemovedInXWarning',0,'',''),(13850,'pytest','A deprecated feature scheduled to be removed in major version X will use the warning class PytestRemovedInXWarning (a subclass of PytestDeprecationwarning).','remove  in major version x',0,'',''),(13851,'pytest','When the deprecation expires (e.g. 4.0 is released), we won’t remove the deprecated functionality immediately, but will use the standard warning filters to turn PytestRemovedInXWarning (e.g. PytestRemovedIn4Warning) into errors by default. This approach makes it explicit that removal is imminent, and still gives you time to turn the deprecated feature into a warning instead of an error so it can be dealt with in your own time. In the next minor release (e.g. 4.1), the feature will be effectively removed.','remove deprecated functionality',0,'',''),(13852,'pytest','When the deprecation expires (e.g. 4.0 is released), we won’t remove the deprecated functionality immediately, but will use the standard warning filters to turn PytestRemovedInXWarning (e.g. PytestRemovedIn4Warning) into errors by default. This approach makes it explicit that removal is imminent, and still gives you time to turn the deprecated feature into a warning instead of an error so it can be dealt with in your own time. In the next minor release (e.g. 4.1), the feature will be effectively removed.','use standard warning filters',0,'',''),(13853,'pytest','When the deprecation expires (e.g. 4.0 is released), we won’t remove the deprecated functionality immediately, but will use the standard warning filters to turn PytestRemovedInXWarning (e.g. PytestRemovedIn4Warning) into errors by default. This approach makes it explicit that removal is imminent, and still gives you time to turn the deprecated feature into a warning instead of an error so it can be dealt with in your own time. In the next minor release (e.g. 4.1), the feature will be effectively removed.','remove feature in next minor release',0,'',''),(13854,'pytest','true breakage: should only be considered when normal transition is unreasonably unsustainable and would offset important development/features by years.\nIn addition, they should be limited to APIs where the number of actual users is very small (for example only impacting some plugins), and can be coordinated with the community in advance.','limit  to apis',0,'',''),(13855,'pytest','rearranging of the node tree to include FunctionDefinition','include FunctionDefinition',0,'',''),(13856,'pytest','For the PR to mature from POC to acceptance, it must contain:\n* Setup of deprecation errors/warnings that help users fix and port their code. If it is possible to introduce a deprecation period under the current series, before the true breakage, it should be introduced in a separate PR and be part of the current release stream.\n* Detailed description of the rationale and examples on how to port code in doc/en/deprecations.rst.','fix code',0,'',''),(13857,'pytest','For the PR to mature from POC to acceptance, it must contain:\n* Setup of deprecation errors/warnings that help users fix and port their code. If it is possible to introduce a deprecation period under the current series, before the true breakage, it should be introduced in a separate PR and be part of the current release stream.\n* Detailed description of the rationale and examples on how to port code in doc/en/deprecations.rst.','introduce deprecation period under current series',0,'',''),(13858,'pytest','For the PR to mature from POC to acceptance, it must contain:\n* Setup of deprecation errors/warnings that help users fix and port their code. If it is possible to introduce a deprecation period under the current series, before the true breakage, it should be introduced in a separate PR and be part of the current release stream.\n* Detailed description of the rationale and examples on how to port code in doc/en/deprecations.rst.','introduce  in separate PR',0,'',''),(13859,'pytest','With the pytest 3.0 release we introduced a clear communication scheme for when we will actually remove the old busted joint and politely ask you to use the new hotness instead, while giving you enough time to adjust your tests or raise concerns if there are valid reasons to keep deprecated functionality around.','introduce clear communication scheme with pytest release',0,'',''),(13860,'pytest','With the pytest 3.0 release we introduced a clear communication scheme for when we will actually remove the old busted joint and politely ask you to use the new hotness instead, while giving you enough time to adjust your tests or raise concerns if there are valid reasons to keep deprecated functionality around.','remove old busted joint',0,'',''),(13861,'pytest','With the pytest 3.0 release we introduced a clear communication scheme for when we will actually remove the old busted joint and politely ask you to use the new hotness instead, while giving you enough time to adjust your tests or raise concerns if there are valid reasons to keep deprecated functionality around.','ask old busted joint',0,'',''),(13862,'pytest','With the pytest 3.0 release we introduced a clear communication scheme for when we will actually remove the old busted joint and politely ask you to use the new hotness instead, while giving you enough time to adjust your tests or raise concerns if there are valid reasons to keep deprecated functionality around.','use new hotness',0,'',''),(13863,'pytest','With the pytest 3.0 release we introduced a clear communication scheme for when we will actually remove the old busted joint and politely ask you to use the new hotness instead, while giving you enough time to adjust your tests or raise concerns if there are valid reasons to keep deprecated functionality around.','adjust tests',0,'',''),(13864,'pytest','With the pytest 3.0 release we introduced a clear communication scheme for when we will actually remove the old busted joint and politely ask you to use the new hotness instead, while giving you enough time to adjust your tests or raise concerns if there are valid reasons to keep deprecated functionality around.','raise concerns',0,'',''),(13865,'pytest','To communicate changes we issue deprecation warnings using a custom warning hierarchy (see Internal pytest warnings). These warnings may be suppressed using the standard means: -W command-line flag or filterwarnings ini options (see How to capture warnings), but we suggest to use these sparingly and temporarily, and heed the warnings when possible.','use custom warning hierarchy',0,'',''),(13866,'pytest','To communicate changes we issue deprecation warnings using a custom warning hierarchy (see Internal pytest warnings). These warnings may be suppressed using the standard means: -W command-line flag or filterwarnings ini options (see How to capture warnings), but we suggest to use these sparingly and temporarily, and heed the warnings when possible.','use standard means',0,'',''),(13867,'pytest','When the deprecation expires (e.g. 4.0 is released), we won’t remove the deprecated functionality immediately, but will use the standard warning filters to turn them into errors by default. This approach makes it explicit that removal is imminent, and still gives you time to turn the deprecated feature into a warning instead of an error so it can be dealt with in your own time. In the next minor release (e.g. 4.1), the feature will be effectively removed.','remove deprecated functionality',0,'',''),(13868,'pytest','When the deprecation expires (e.g. 4.0 is released), we won’t remove the deprecated functionality immediately, but will use the standard warning filters to turn them into errors by default. This approach makes it explicit that removal is imminent, and still gives you time to turn the deprecated feature into a warning instead of an error so it can be dealt with in your own time. In the next minor release (e.g. 4.1), the feature will be effectively removed.','use standard warning filters',0,'',''),(13869,'pytest','When the deprecation expires (e.g. 4.0 is released), we won’t remove the deprecated functionality immediately, but will use the standard warning filters to turn them into errors by default. This approach makes it explicit that removal is imminent, and still gives you time to turn the deprecated feature into a warning instead of an error so it can be dealt with in your own time. In the next minor release (e.g. 4.1), the feature will be effectively removed.','remove feature in next minor release',0,'',''),(13870,'pytest','Features currently deprecated and removed in previous releases can be found in Deprecations and Removals.','find features in deprecations',0,'',''),(13871,'pytest','Features currently deprecated and removed in previous releases can be found in Deprecations and Removals.','find features in Removals',0,'',''),(13872,'pytest','We track future deprecation and removal of features using milestones and the deprecation and removal labels on GitHub.','track future deprecation of features',0,'',''),(13873,'pytest','We track future deprecation and removal of features using milestones and the deprecation and removal labels on GitHub.','track removal of features',0,'',''),(13874,'pytest','We track future deprecation and removal of features using milestones and the deprecation and removal labels on GitHub.','use removal labels on GitHub',0,'',''),(13875,'pytest','We track future deprecation and removal of features using milestones and the deprecation and removal labels on GitHub.','use milestones on GitHub',0,'',''),(13876,'pytest','We track future deprecation and removal of features using milestones and the deprecation and removal labels on GitHub.','use deprecation on GitHub',0,'',''),(13877,'pytest','Released pytest versions support all Python versions that are actively maintained at the time of the release:','support Python versions',0,'',''),(13878,'pytest','Fix bugs','fix bugs',0,'',''),(13879,'pytest','Write documentation','write documentation',0,'',''),(13880,'pytest','Submitting Plugins to pytest-dev','submit Plugins to pytest-dev',0,'',''),(13881,'pytest','Handling stale issues/PRs','handle stale issues/prs',0,'',''),(13882,'pytest','If you can write a demonstration test that currently fails but should pass\n(xfail), that is a very useful commit to make as well, even if you cannot\nfix the bug itself.','write demonstration test',0,'',''),(13883,'pytest','If you can write a demonstration test that currently fails but should pass\n(xfail), that is a very useful commit to make as well, even if you cannot\nfix the bug itself.','pass demonstration test',0,'',''),(13884,'pytest','Talk to developers to find out how you can fix specific bugs. To indicate that you are going\nto work on a particular issue, add a comment to that effect on the specific issue.','fix specific bugs',0,'',''),(13885,'pytest','Talk to developers to find out how you can fix specific bugs. To indicate that you are going\nto work on a particular issue, add a comment to that effect on the specific issue.','add comment to effect',0,'',''),(13886,'pytest','Don’t forget to check the issue trackers of your favourite plugins, too!','check issue trackers of favourite plugins',0,'',''),(13887,'pytest','Talk to developers to find out how you can implement specific\nfeatures.','implement specific features',0,'',''),(13888,'pytest','Pytest could always use more documentation.  What exactly is needed?','use more documentation',0,'',''),(13889,'pytest','More complementary documentation.  Have you perhaps found something unclear?','find something unclear',0,'',''),(13890,'pytest','You can also edit documentation files directly in the GitHub web interface,\nwithout using a local copy.  This can be convenient for small fixes.','edit documentation files in GitHub web interface',0,'',''),(13891,'pytest','You can also edit documentation files directly in the GitHub web interface,\nwithout using a local copy.  This can be convenient for small fixes.','use local copy',0,'',''),(13892,'pytest','Pytest has an API reference which in large part is\ngenerated automatically\nfrom the docstrings of the documented items. Pytest uses the\nSphinx docstring format.\nFor example:','generate API reference in large part',1,'https://docs.pytest.org/en/7.2.x/contributing.html',''),(13893,'pytest','Pytest has an API reference which in large part is\ngenerated automatically\nfrom the docstrings of the documented items. Pytest uses the\nSphinx docstring format.\nFor example:','generate API reference from docstrings',1,'https://docs.pytest.org/en/7.2.x/contributing.html',''),(13894,'pytest','Pytest has an API reference which in large part is\ngenerated automatically\nfrom the docstrings of the documented items. Pytest uses the\nSphinx docstring format.\nFor example:','use sphinx',1,'https://docs.pytest.org/en/7.2.x/contributing.html',''),(13895,'pytest','All pytest-dev Contributors team members have write access to all contained\nrepositories.  Pytest core and plugins are generally developed\nusing pull requests to respective repositories.','write access to contained repositories',0,'',''),(13896,'pytest','All pytest-dev Contributors team members have write access to all contained\nrepositories.  Pytest core and plugins are generally developed\nusing pull requests to respective repositories.','use pull requests to respective repositories',0,'',''),(13897,'pytest','All pytest-dev Contributors team members have write access to all contained\nrepositories.  Pytest core and plugins are generally developed\nusing pull requests to respective repositories.','develop pytest core',0,'',''),(13898,'pytest','All pytest-dev Contributors team members have write access to all contained\nrepositories.  Pytest core and plugins are generally developed\nusing pull requests to respective repositories.','develop plugins',0,'',''),(13899,'pytest','You can submit your plugin by subscribing to the pytest-dev mail list and writing a\nmail pointing to your existing pytest plugin repository which must have\nthe following:','submit plugin by subscribing',0,'',''),(13900,'pytest','You can submit your plugin by subscribing to the pytest-dev mail list and writing a\nmail pointing to your existing pytest plugin repository which must have\nthe following:','submit plugin by writing',0,'',''),(13901,'pytest','You can submit your plugin by subscribing to the pytest-dev mail list and writing a\nmail pointing to your existing pytest plugin repository which must have\nthe following:','write mail',0,'',''),(13902,'pytest','You can submit your plugin by subscribing to the pytest-dev mail list and writing a\nmail pointing to your existing pytest plugin repository which must have\nthe following:','subscribe  to pytest-dev mail list',0,'',''),(13903,'pytest','a  tox configuration\nfor running tests using tox.','use tox',0,'',''),(13904,'pytest','a README describing how to use the plugin and on which\nplatforms it runs.','use plugin',0,'',''),(13905,'pytest','a README describing how to use the plugin and on which\nplatforms it runs.','run plugin',0,'',''),(13906,'pytest','a LICENSE file containing the licensing information, with\nmatching info in its packaging metadata.','match info in packaging metadata',0,'',''),(13907,'pytest','calvin creates pytest-xyz-admin and pytest-xyz-developers teams, inviting joedoe to both as maintainer.','create pytest-xyz-admin pytest-xyz-developers teams',0,'',''),(13908,'pytest','pytest-xyz-developers write access;','write access',0,'',''),(13909,'pytest','The pytest-dev/Contributors team has write access to all projects, and\nevery project administrator is in it. We recommend that each plugin has at least three\npeople who have the right to release to PyPI.','write access to projects',0,'',''),(13910,'pytest','The pytest-dev/Contributors team has write access to all projects, and\nevery project administrator is in it. We recommend that each plugin has at least three\npeople who have the right to release to PyPI.','release  to PyPI',0,'',''),(13911,'pytest','Repository owners can rest assured that no pytest-dev administrator will ever make\nreleases of your repository or take ownership in any way, except in rare cases\nwhere someone becomes unresponsive after months of contact attempts.\nAs stated, the objective is to share maintenance and avoid “plugin-abandon”.','share maintenance',0,'',''),(13912,'pytest','Enable and install pre-commit to ensure style-guides and code checks are followed.','enable pre-commit',0,'',''),(13913,'pytest','Enable and install pre-commit to ensure style-guides and code checks are followed.','install pre-commit',0,'',''),(13914,'pytest','Tests are run using tox:','use tox',1,'https://docs.pytest.org/en/7.2.x/contributing.html',''),(13915,'pytest','Tests are run using tox:','run tests',1,'https://docs.pytest.org/en/7.2.x/contributing.html',''),(13916,'pytest','Write a changelog entry: changelog/2574.bugfix.rst, use issue id number\nand one of feature, improvement, bugfix, doc, deprecation,\nbreaking, vendor or trivial for the issue type.','write changelog entry',0,'',''),(13917,'pytest','Unless your change is a trivial or a documentation fix (e.g., a typo or reword of a small section) please\nadd yourself to the AUTHORS file, in alphabetical order.','add  to AUTHORS file',0,'',''),(13918,'pytest','What is a “pull request”?  It informs the project’s core developers about the\nchanges you want to review and merge.  Pull requests are stored on\nGitHub servers.\nOnce you send a pull request, we can discuss its potential modifications and\neven add more commits to it later on. There’s an excellent tutorial on how Pull\nRequests work in the\nGitHub Help Center.','store pull requests on GitHub servers',0,'',''),(13919,'pytest','What is a “pull request”?  It informs the project’s core developers about the\nchanges you want to review and merge.  Pull requests are stored on\nGitHub servers.\nOnce you send a pull request, we can discuss its potential modifications and\neven add more commits to it later on. There’s an excellent tutorial on how Pull\nRequests work in the\nGitHub Help Center.','send pull request',0,'',''),(13920,'pytest','Fork the\npytest GitHub repository.  It’s\nfine to use pytest as your fork repository name because it will live\nunder your user.','use pytest as fork repository name',0,'',''),(13921,'pytest','Clone your fork locally using git and create a branch:','clone fork',1,'https://docs.pytest.org/en/7.2.x/contributing.html',''),(13922,'pytest','Clone your fork locally using git and create a branch:','use git',1,'https://docs.pytest.org/en/7.2.x/contributing.html',''),(13923,'pytest','Clone your fork locally using git and create a branch:','create branch',1,'https://docs.pytest.org/en/7.2.x/contributing.html',''),(13924,'pytest','Given we have “major.minor.micro” version numbers, bug fixes will usually\nbe released in micro releases whereas features will be released in\nminor releases and incompatible changes in major releases.','release bug fixes in micro releases',0,'',''),(13925,'pytest','Given we have “major.minor.micro” version numbers, bug fixes will usually\nbe released in micro releases whereas features will be released in\nminor releases and incompatible changes in major releases.','release features in minor releases',0,'',''),(13926,'pytest','Given we have “major.minor.micro” version numbers, bug fixes will usually\nbe released in micro releases whereas features will be released in\nminor releases and incompatible changes in major releases.','release features in incompatible changes',0,'',''),(13927,'pytest','Given we have “major.minor.micro” version numbers, bug fixes will usually\nbe released in micro releases whereas features will be released in\nminor releases and incompatible changes in major releases.','release features in major releases',0,'',''),(13928,'pytest','You will need the tags to test locally, so be sure you have the tags from the main repository. If you suspect you don’t, set the main repository as upstream and fetch the tags:','set main repository',1,'https://docs.pytest.org/en/7.2.x/contributing.html',''),(13929,'pytest','You will need the tags to test locally, so be sure you have the tags from the main repository. If you suspect you don’t, set the main repository as upstream and fetch the tags:','fetch tags',1,'https://docs.pytest.org/en/7.2.x/contributing.html',''),(13930,'pytest','Tox is used to run all the tests and will automatically setup virtualenvs\nto run the tests in.\n(will implicitly use https://virtualenv.pypa.io/en/latest/):','run tests',1,'https://docs.pytest.org/en/7.2.x/contributing.html',''),(13931,'pytest','Tox is used to run all the tests and will automatically setup virtualenvs\nto run the tests in.\n(will implicitly use https://virtualenv.pypa.io/en/latest/):','run tests',1,'https://docs.pytest.org/en/7.2.x/contributing.html',''),(13932,'pytest','Tox is used to run all the tests and will automatically setup virtualenvs\nto run the tests in.\n(will implicitly use https://virtualenv.pypa.io/en/latest/):','use tox',1,'https://docs.pytest.org/en/7.2.x/contributing.html',''),(13933,'pytest','This command will run tests via the “tox” tool against Python 3.7\nand also perform “lint” coding-style checks.','run tests against Python',0,'',''),(13934,'pytest','This command will run tests via the “tox” tool against Python 3.7\nand also perform “lint” coding-style checks.','run tests via tox tool',0,'',''),(13935,'pytest','This command will run tests via the “tox” tool against Python 3.7\nand also perform “lint” coding-style checks.','perform lint coding-style checks',0,'',''),(13936,'pytest','You can now edit your local working copy and run the tests again as necessary. Please follow PEP-8 for naming.','edit local working copy',0,'',''),(13937,'pytest','You can now edit your local working copy and run the tests again as necessary. Please follow PEP-8 for naming.','run tests',0,'',''),(13938,'pytest','You can pass different options to tox. For example, to run tests on Python 3.7 and pass options to pytest\n(e.g. enter pdb on failure) to pytest you can do:','pass different options to tox',1,'https://docs.pytest.org/en/7.2.x/contributing.html',''),(13939,'pytest','You can pass different options to tox. For example, to run tests on Python 3.7 and pass options to pytest\n(e.g. enter pdb on failure) to pytest you can do:','run tests on Python',1,'https://docs.pytest.org/en/7.2.x/contributing.html',''),(13940,'pytest','You can pass different options to tox. For example, to run tests on Python 3.7 and pass options to pytest\n(e.g. enter pdb on failure) to pytest you can do:','pass tests on Python',1,'https://docs.pytest.org/en/7.2.x/contributing.html',''),(13941,'pytest','Or to only run tests in a particular test module on Python 3.7:','run tests in particular test module',1,'https://docs.pytest.org/en/7.2.x/contributing.html',''),(13942,'pytest','If instead of using tox you prefer to run the tests directly, then we suggest to create a virtual environment and use\nan editable install with the testing extra:','use tox',1,'https://docs.pytest.org/en/7.2.x/contributing.html',''),(13943,'pytest','If instead of using tox you prefer to run the tests directly, then we suggest to create a virtual environment and use\nan editable install with the testing extra:','run tests',1,'https://docs.pytest.org/en/7.2.x/contributing.html',''),(13944,'pytest','If instead of using tox you prefer to run the tests directly, then we suggest to create a virtual environment and use\nan editable install with the testing extra:','create virtual environment',1,'https://docs.pytest.org/en/7.2.x/contributing.html',''),(13945,'pytest','If instead of using tox you prefer to run the tests directly, then we suggest to create a virtual environment and use\nan editable install with the testing extra:','use virtual environment',1,'https://docs.pytest.org/en/7.2.x/contributing.html',''),(13946,'pytest','If instead of using tox you prefer to run the tests directly, then we suggest to create a virtual environment and use\nan editable install with the testing extra:','install  with testing extra',1,'https://docs.pytest.org/en/7.2.x/contributing.html',''),(13947,'pytest','Afterwards, you can edit the files and run pytest normally:','edit files',1,'https://docs.pytest.org/en/7.2.x/contributing.html',''),(13948,'pytest','Afterwards, you can edit the files and run pytest normally:','run pytest',1,'https://docs.pytest.org/en/7.2.x/contributing.html',''),(13949,'pytest','Create a new changelog entry in changelog. The file should be named ..rst,\nwhere issueid is the number of the issue related to the change and type is one of\nfeature, improvement, bugfix, doc, deprecation, breaking, vendor\nor trivial. You may skip creating the changelog entry if the change doesn’t affect the\ndocumented behaviour of pytest.','create new changelog entry in changelog',0,'',''),(13950,'pytest','Create a new changelog entry in changelog. The file should be named ..rst,\nwhere issueid is the number of the issue related to the change and type is one of\nfeature, improvement, bugfix, doc, deprecation, breaking, vendor\nor trivial. You may skip creating the changelog entry if the change doesn’t affect the\ndocumented behaviour of pytest.','create changelog entry',0,'',''),(13951,'pytest','Add yourself to AUTHORS file if not there yet, in alphabetical order.','add  to AUTHORS file',0,'',''),(13952,'pytest','Finally, submit a pull request through the GitHub website using this data:','submit pull request through GitHub website',1,'https://docs.pytest.org/en/7.2.x/contributing.html',''),(13953,'pytest','Finally, submit a pull request through the GitHub website using this data:','use data',1,'https://docs.pytest.org/en/7.2.x/contributing.html',''),(13954,'pytest','Writing tests for plugins or for pytest itself is often done using the pytester fixture, as a “black-box” test.','write tests',1,'https://docs.pytest.org/en/7.2.x/contributing.html',''),(13955,'pytest','Writing tests for plugins or for pytest itself is often done using the pytester fixture, as a “black-box” test.','use pytester fixture',1,'https://docs.pytest.org/en/7.2.x/contributing.html',''),(13956,'pytest','Alternatively, it is possible to make checks based on the actual output of the termal using\nglob-like expressions:','use glob-like expressions',1,'https://docs.pytest.org/en/7.2.x/contributing.html',''),(13957,'pytest','When choosing a file where to write a new test, take a look at the existing files and see if there’s\none file which looks like a good fit. For example, a regression test about a bug in the --lf option\nshould go into test_cacheprovider.py, given that this option is implemented in cacheprovider.py.\nIf in doubt, go ahead and open a PR with your best guess and we can discuss this over the code.','choose file',0,'',''),(13958,'pytest','When choosing a file where to write a new test, take a look at the existing files and see if there’s\none file which looks like a good fit. For example, a regression test about a bug in the --lf option\nshould go into test_cacheprovider.py, given that this option is implemented in cacheprovider.py.\nIf in doubt, go ahead and open a PR with your best guess and we can discuss this over the code.','write new test',0,'',''),(13959,'pytest','When choosing a file where to write a new test, take a look at the existing files and see if there’s\none file which looks like a good fit. For example, a regression test about a bug in the --lf option\nshould go into test_cacheprovider.py, given that this option is implemented in cacheprovider.py.\nIf in doubt, go ahead and open a PR with your best guess and we can discuss this over the code.','implement option in cacheprovider.py',0,'',''),(13960,'pytest','When choosing a file where to write a new test, take a look at the existing files and see if there’s\none file which looks like a good fit. For example, a regression test about a bug in the --lf option\nshould go into test_cacheprovider.py, given that this option is implemented in cacheprovider.py.\nIf in doubt, go ahead and open a PR with your best guess and we can discuss this over the code.','open PR with best guess',0,'',''),(13961,'pytest','Pytest makes a feature release every few weeks or months. In between, patch releases\nare made to the previous feature release, containing bug fixes only. The bug fixes\nusually fix regressions, but may be any change that should reach users before the\nnext feature release.','fix fix regressions',0,'',''),(13962,'pytest','Pytest makes a feature release every few weeks or months. In between, patch releases\nare made to the previous feature release, containing bug fixes only. The bug fixes\nusually fix regressions, but may be any change that should reach users before the\nnext feature release.','reach users before next feature release',0,'',''),(13963,'pytest','Pytest makes a feature release every few weeks or months. In between, patch releases\nare made to the previous feature release, containing bug fixes only. The bug fixes\nusually fix regressions, but may be any change that should reach users before the\nnext feature release.','reach change before next feature release',0,'',''),(13964,'pytest','Suppose for example that the latest release was 1.2.3, and you want to include\na bug fix in 1.2.4 (check https://github.com/pytest-dev/pytest/releases for the\nactual latest release). The procedure for this is:','include bug fix in 1.2.4',0,'',''),(13965,'pytest','First, make sure the bug is fixed in the main branch, with a regular pull\nrequest, as described above. An exception to this is if the bug fix is not\napplicable to main anymore.','fix bug with regular pull request',0,'',''),(13966,'pytest','First, make sure the bug is fixed in the main branch, with a regular pull\nrequest, as described above. An exception to this is if the bug fix is not\napplicable to main anymore.','fix bug in main branch',0,'',''),(13967,'pytest','Add a backport 1.2.x label to the PR you want to backport. This will create\na backport PR against the 1.2.x branch.','add backport 1.2.x label to PR',0,'',''),(13968,'pytest','Add a backport 1.2.x label to the PR you want to backport. This will create\na backport PR against the 1.2.x branch.','create backport PR against 1.2.x branch',0,'',''),(13969,'pytest','git checkout origin/1.2.x -b backport-XXXX # use the main PR number here','use main PR number',0,'',''),(13970,'pytest','git cherry-pick -x -m1 REVISION # use the revision you found above (0f8b462).','use revision',0,'',''),(13971,'pytest','git cherry-pick -x -m1 REVISION # use the revision you found above (0f8b462).','find revision',0,'',''),(13972,'pytest','Open a PR targeting 1.2.x:','open PR',0,'',''),(13973,'pytest','Delete the PR body, it usually contains a duplicate commit message.','delete PR body',0,'',''),(13974,'pytest','As mentioned above, bugs should first be fixed on main (except in rare occasions\nthat a bug only happens in a previous release). So, who should do the backport procedure described\nabove?','fix bugs',0,'',''),(13975,'pytest','If the bug was fixed by a core developer, it is the main responsibility of that core developer\nto do the backport.','fix bug',0,'',''),(13976,'pytest','If a non-maintainers notices a bug which is fixed on main but has not been backported\n(due to maintainers forgetting to apply the needs backport label, or just plain missing it),\nthey are also welcome to open a PR with the backport. The procedure is simple and really\nhelps with the maintenance of the project.','open PR with backport',0,'',''),(13977,'pytest','If a non-maintainers notices a bug which is fixed on main but has not been backported\n(due to maintainers forgetting to apply the needs backport label, or just plain missing it),\nthey are also welcome to open a PR with the backport. The procedure is simple and really\nhelps with the maintenance of the project.','fix bug',0,'',''),(13978,'pytest','There are many reasons why people don’t answer questions or implement requested changes:\nthey might get busy, lose interest, or just forget about it,\nbut the fact is that this is very common in open source software.','implement requested changes',0,'',''),(13979,'pytest','There are many reasons why people don’t answer questions or implement requested changes:\nthey might get busy, lose interest, or just forget about it,\nbut the fact is that this is very common in open source software.','implement many reasons',0,'',''),(13980,'pytest','Here are a few general rules the maintainers use deciding when to close issues/PRs because\nof lack of inactivity:','use few general rules',0,'',''),(13981,'pytest','Pull requests: after one month, consider pinging the author, update linked issue, or consider closing. For pull requests which are nearly finished, the team should consider finishing it up and merging it.','update linked issue',0,'',''),(13982,'pytest','When closing a Pull Request, it needs to be acknowledging the time, effort, and interest demonstrated by the person which submitted it. As mentioned previously, it is not the intent of the team to dismiss a stalled pull request entirely but to merely to clear up our queue, so a message like the one below is warranted when closing a pull request that went stale:','submit person',0,'',''),(13983,'pytest','We noticed it has been awhile since you have updated this PR, however. pytest is a high activity project, with many issues/PRs being opened daily, so it is hard for us maintainers to track which PRs are ready for merging, for review, or need more attention.','update PR',0,'',''),(13984,'pytest','When a pull request is submitted to fix an issue, add text like closes #XYZW to the PR description and/or commits (where XYZW is the issue number). See the GitHub docs for more information.','fix issue',0,'',''),(13985,'pytest','When a pull request is submitted to fix an issue, add text like closes #XYZW to the PR description and/or commits (where XYZW is the issue number). See the GitHub docs for more information.','add text',0,'',''),(13986,'pytest','When a pull request is submitted to fix an issue, add text like closes #XYZW to the PR description and/or commits (where XYZW is the issue number). See the GitHub docs for more information.','submit pull request',0,'',''),(13987,'pytest','When an issue is due to user error (e.g. misunderstanding of a functionality), please politely explain to the user why the issue raised is really a non-issue and ask them to close the issue if they have no further questions. If the original requestor is unresponsive, the issue will be handled as described in the section Handling stale issues/PRs above.','handle stale issues/prs',0,'',''),(13988,'pytest','When an issue is due to user error (e.g. misunderstanding of a functionality), please politely explain to the user why the issue raised is really a non-issue and ask them to close the issue if they have no further questions. If the original requestor is unresponsive, the issue will be handled as described in the section Handling stale issues/PRs above.','describe  in section',0,'',''),(13989,'pytest','When an issue is due to user error (e.g. misunderstanding of a functionality), please politely explain to the user why the issue raised is really a non-issue and ask them to close the issue if they have no further questions. If the original requestor is unresponsive, the issue will be handled as described in the section Handling stale issues/PRs above.','handle issue',0,'',''),(13990,'pytest','Get Started for basic introductory examples','get Started for basic introductory examples',0,'',''),(13991,'pytest','How to write and report assertions in tests for basic assertion examples','write assertions in tests',0,'',''),(13992,'pytest','How to write and report assertions in tests for basic assertion examples','write assertions for basic assertion examples',0,'',''),(13993,'pytest','How to use unittest-based tests with pytest for basic unittest integration','use unittest-based tests with pytest',0,'',''),(13994,'pytest','How to run tests written for nose for basic nosetests integration','run tests',0,'',''),(13995,'pytest','How to run tests written for nose for basic nosetests integration','write  for nose',0,'',''),(13996,'pytest','pytest is maintained by a team of volunteers from all around the world in their free time. While\nwe work on pytest because we love the project and use it daily at our daily jobs, monetary\ncompensation when possible is welcome to justify time away from friends, family and personal time.','use  at daily jobs',0,'',''),(13997,'pytest','Money is also used to fund local sprints, merchandising (stickers to distribute in conferences for example)\nand every few years a large sprint involving all members.','use money',0,'',''),(13998,'pytest','Open Collective is an online funding platform for open and transparent communities.\nIt provide tools to raise money and share your finances in full transparency.','raise money',0,'',''),(13999,'pytest','Open Collective is an online funding platform for open and transparent communities.\nIt provide tools to raise money and share your finances in full transparency.','share finances in full transparency',0,'',''),(14000,'React-query','React Query is often described as the missing data-fetching library for React, but in more technical terms, it makes fetching, caching, synchronizing and updating server state in your React applications a breeze.','fetch breeze',0,'',''),(14001,'React-query','React Query is often described as the missing data-fetching library for React, but in more technical terms, it makes fetching, caching, synchronizing and updating server state in your React applications a breeze.','describe react Query as missing data-fetching library',0,'',''),(14002,'React-query','Out of the box, React applications do not come with an opinionated way of fetching or updating data from your components so developers end up building their own ways of fetching data. This usually means cobbling together component-based state and effect using React hooks, or using more general purpose state management libraries to store and provide asynchronous data throughout their apps.','fetch data from components',0,'',''),(14003,'React-query','Out of the box, React applications do not come with an opinionated way of fetching or updating data from your components so developers end up building their own ways of fetching data. This usually means cobbling together component-based state and effect using React hooks, or using more general purpose state management libraries to store and provide asynchronous data throughout their apps.','update data from components',0,'',''),(14004,'React-query','Out of the box, React applications do not come with an opinionated way of fetching or updating data from your components so developers end up building their own ways of fetching data. This usually means cobbling together component-based state and effect using React hooks, or using more general purpose state management libraries to store and provide asynchronous data throughout their apps.','fetch data',0,'',''),(14005,'React-query','Out of the box, React applications do not come with an opinionated way of fetching or updating data from your components so developers end up building their own ways of fetching data. This usually means cobbling together component-based state and effect using React hooks, or using more general purpose state management libraries to store and provide asynchronous data throughout their apps.','use React hooks',0,'',''),(14006,'React-query','Out of the box, React applications do not come with an opinionated way of fetching or updating data from your components so developers end up building their own ways of fetching data. This usually means cobbling together component-based state and effect using React hooks, or using more general purpose state management libraries to store and provide asynchronous data throughout their apps.','use general purpose state management libraries',0,'',''),(14007,'React-query','Out of the box, React applications do not come with an opinionated way of fetching or updating data from your components so developers end up building their own ways of fetching data. This usually means cobbling together component-based state and effect using React hooks, or using more general purpose state management libraries to store and provide asynchronous data throughout their apps.','store asynchronous data throughout apps',0,'',''),(14008,'React-query','Out of the box, React applications do not come with an opinionated way of fetching or updating data from your components so developers end up building their own ways of fetching data. This usually means cobbling together component-based state and effect using React hooks, or using more general purpose state management libraries to store and provide asynchronous data throughout their apps.','provide asynchronous data throughout apps',0,'',''),(14009,'React-query','React Query is hands down one of the best libraries for managing server state. It works amazingly well out-of-the-box, with zero-config, and can be customized to your liking as your application grows.','customize  to liking',1,'https://tanstack.com/query/v4/docs/overview','enough-talk-show-me-some-code-already'),(14010,'React-query','Open in CodeSandbox','open  in CodeSandbox',0,'',''),(14011,'pandas','pandas is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool,\nbuilt on top of the Python programming language.','use open source data',0,'',''),(14012,'pandas','© 2023 pandas via NumFOCUS, Inc. Hosted by OVHcloud.','host  by OVHcloud',0,'',''),(14013,'pandas','This is the list of changes to pandas between each release. For full details,\nsee the commit logs. For install and\nupgrade instructions, see Installation.','install instructions',0,'','');
/*!40000 ALTER TABLE `overview_task` ENABLE KEYS */;
UNLOCK TABLES;
/*!40103 SET TIME_ZONE=@OLD_TIME_ZONE */;

/*!40101 SET SQL_MODE=@OLD_SQL_MODE */;
/*!40014 SET FOREIGN_KEY_CHECKS=@OLD_FOREIGN_KEY_CHECKS */;
/*!40014 SET UNIQUE_CHECKS=@OLD_UNIQUE_CHECKS */;
/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;
/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;
/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;
/*!40111 SET SQL_NOTES=@OLD_SQL_NOTES */;

-- Dump completed on 2023-02-25  0:06:08
