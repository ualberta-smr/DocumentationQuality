Paragraph,Tasks
"""Recognizes named entities (person and company names, etc.) in text. Principally, this annotator uses one or more machine learning sequence models to label entities, but it may also call specialist rule-based components, such as for labeling and interpreting times and dates. Numerical entities that require normalization, e.g., dates, have their normalized value stored in NormalizedNamedEntityTagAnnotation. For more extensive support for rule-based NER, you may also want to look at the RegexNER annotator. The set of entities recognized is language-dependent, and the recognized set of entities is frequently more limited for other languages than what is described below for English. As the name “NERClassifierCombiner” implies, commonly this annotator will run several named entity recognizers and then combine their results but it can run just a single annotator or only rule-based quantity NER.""","Label entities with machine learning, Label entities with specialist rule-based components"
"""For English, by default, this annotator recognizes named (PERSON, LOCATION, ORGANIZATION, MISC), numerical (MONEY, NUMBER, ORDINAL, PERCENT), and temporal (DATE, TIME, DURATION, SET) entities (12 classes). Adding the regexner annotator and using the supplied RegexNER pattern files adds support for the fine-grained and additional entity classes EMAIL, URL, CITY, STATE_OR_PROVINCE, COUNTRY, NATIONALITY, RELIGION, (job) TITLE, IDEOLOGY, CRIMINAL_CHARGE, CAUSE_OF_DEATH, (Twitter, etc.) HANDLE (12 classes) for a total of 24 classes. Named entities are recognized using a combination of three CRF sequence taggers trained on various corpora, including CoNLL, ACE, MUC, and ERE corpora. Numerical entities are recognized using a rule-based system.""","Recognize named/numerical/temporal entities, Add support for fine-grained and additional entity classes"
The full named entity recognition pipeline has become fairly complex and involves a set of distinct phases integrating statistical and rule based approaches. Here is a breakdown of those distinct phases.,
The main class that runs this process is edu.stanford.nlp.pipeline.NERCombinerAnnotator,
During this phase a series of trained CRF’s will be run on each sentence. These CRF’s are trained on large tagged data sets. They evaluate the entire sequence and pick the optimal tag sequence.,
These are the default models that are run:,
Tags written by one model cannot be overwritten by subsequent models in the series.,
There are two options for how the models are combined. These are selected with the ner.combinationMode property.,
"""So for example, if the ner.combinationMode is set to NORMAL, only the 3-class model’s ORGANIZATION tags will be applied. If it is set to HIGH_RECALL, the 7-class and 4-class models’ ORGANIZATION tags will also be applied.""",
"""If you do not want to run any statistical models, set ner.model to the empty string.""",
Next a series of rule based systems are run to recognize and tag numeric sequences and time related sequences.,
"""This phase runs by default, but can be deactivated by setting ner.applyNumericClassifiers to false.""",Deactivate numerical classifiers
"""This produces tags such as NUMBER, ORDINAL, MONEY, DATE, and TIME""",
The class that runs this phase is edu.stanford.nlp.ie.regexp.NumberSequenceClassifier,
SUTime (described in more detail below) is also used by default. You can deactivate this by setting ner.useSUTime to false.,Deactivate SUTime
"""At this point, a series of rules used for the KBP 2017 competition will be run to create more fine-grained NER tags. These rules are applied using a TokensRegexNERAnnotator sub-annotator. That is the main NERCombinerAnnotator builds a TokensRegexNERAnnotator as a sub-annotator and runs it on all sentences as part of it’s entire tagging process. The purpose of these rules is give tokens more specific tags. So for instance California would be tagged as a STATE_OR_PROVINCE rather than just a LOCATION.""",
The TokensRegexNERAnnotator runs TokensRegex rules. You can review all of the settings for a TokensRegexNERAnnotator here.,
NOTE: applying these rules will significantly slow down the tagging process.,
The tags set by this phase include:,
"""If you do not want to run the fine-grained rules, set ner.applyFineGrained to false.""",Disable fine-grained rules
There is a more detailed write up about RegexNER here,
The format is a series of tab-delimited columns.,
"""The first column is the tokens pattern, the second column is the NER tag to apply, the third is the types of NER tags that can be overwritten, and the fourth is a priority used for tie-breaking if two rules match a sequence.""",
Each space delimited entry represents a regex to match a token.,
The rule (remember these are tab-delimited columns):,
"""means to match the token “Los” followed by the token “Angeles”, and label them both as CITY, provided they have a current NER tag of O, LOCATION, or MISC.""",
The rule:,
"""means to match the token “Bachelor”, then the token “of”, and finally either the token “Arts” or “Science”.""",
Here is a breakdown of how to customize the fine-grained NER. The overall ner annotator creates a sub-annotator called ner.fine.regexner which is an instance of a TokensRegexNERAnnotator.,Customize fine-grained NER
The ner.fine.regexner.mapping property allows one to specify a set of rules files and additional properties for each rules file.,Specify rules files and properties
The format is as follows:,
"""As an example, this is the default ner.fine.regexner.mapping setting:""",
The two rules files are:,
The options for edu/stanford/nlp/models/kbp/english/gazetteers/regexner_caseless.tab are:,
"""ignorecase=true,validpospattern=^(NN|JJ).*""",
while there are no options set for edu/stanford/nlp/models/kbp/english/gazetteers/regexner_cased.tab in this example.,
Here is a description of some common options for the TokensRegexNERAnnotator sub-annotator used by ner,
You can find more details on the page for the TokensRegexNERAnnotator located here,
"""If you want to set global settings that will apply for all rules files, remember to use ner.fine.regexner.ignorecase and ner.fine.regexner.validpospattern. If you are setting options for a specific rules file with the ner.fine.regexner.mapping option, follow the pattern from above.""",Set global settings for all rules files
"""After the fine-grained rules are run, there is also an option for a user to specify additional rules they would like to have run after the fine-grained NER phase.""",Specify additional rules after fine-grained NER phase
This second TokensRegexNERAnnotator sub-annotator has the name ner.additional.regexner and is customized in the same manner. This is for the case when users want to run their own rules after the standard rules we provide.,
"""For instance, suppose you want to match sports teams after the previous NER steps have been run.""",
Your rules file might look like this /path/to/sports_teams.rules,
You could integrate this into the entire NER process by setting ner.additional.regexner.mapping to /path/to/sports_teams.rules,
"""By default no additional rules are run, so leaving ner.additional.regexner.mapping blank will cause this phase to not be run at all.""",
"""If you want to run a series of TokensRegex rules before entity building, you can also specify a set of TokensRegex rules. A TokensRegexAnnotator sub-annotator will be called. It has the name ner.additional.tokensregex.""",Run series of TokensRegex rules before entity building
Example command:,
You can learn more about TokensRegex rules here,
"""After all of the previous steps have been run, entity detection will be run to combine the tagged tokens into entities. The entity mention detection will be based off of the tagging scheme. This is accomplished with an EntityMentionsAnnotator sub-annotator.""",
You can find a more detailed description of this annotator here,
"""If a basic IO tagging scheme (example: PERSON, ORGANIZATION, LOCATION) is used, all contiguous sequences of tokens with the same tag will be marked as an entity.""",
"""If a more advanced tagging scheme (such as BIO with tags like B-PERSON and I-PERSON) is used, sequences with the same tag split by a B-tag will be turned into multiple entities.""",
"""All of our models and rule files use a basic tagging scheme, but you could create your own models and rules that use BIO.""",
For instance (Joe PERSON) (Smith PERSON) (Jane PERSON) (Smith PERSON) will create the entity Joe Smith Jane Smith.,
On the other hand (Joe B-PERSON) (Smith I-PERSON) (Jane B-PERSON) (Smith I-PERSON) will create two entities: Joe Smith and Jane Smith.,
You can deactivate this with ner.buildEntityMentions being set to false.,Deactivate entity mentions
"""At this point the NER process will be finished, having tagged tokens with NER tags and created entities.""",
There a variety of ways to customize an NER pipeline. Below are some example commands.,Customize NER pipeline
"""Stanford CoreNLP includes SUTime, Stanford’s temporal expression recognizer. SUTime is transparently called from the “ner” annotator, so no configuration is necessary. Furthermore, the “cleanxml” annotator can extract the reference date for a given XML document, so relative dates, e.g., “yesterday”, are transparently normalized with no configuration necessary.""",
"""SUTime supports the same annotations as before, i.e., NamedEntityTagAnnotation is set with the label of the numeric entity (DATE, TIME, DURATION, MONEY, PERCENT, or NUMBER) and NormalizedNamedEntityTagAnnotation is set to the value of the normalized temporal expression.""",
"""Also, SUTime sets the TimexAnnotation key to an edu.stanford.nlp.time.Timex object, which contains the complete list of TIMEX3 fields for the corresponding expressions, such as “val”, “alt_val”, “type”, “tid”. This might be useful to developers interested in recovering complete TIMEX3 expressions.""",
"""Reference dates are by default extracted from the “datetime” and “date” tags in an xml document. To set a different set of tags to use, use the clean.datetags property. When using the API, reference dates can be added to an Annotation via edu.stanford.nlp.ling.CoreAnnotations.DocDateAnnotation, although note that when processing an xml document, the cleanxml annotator will overwrite the DocDateAnnotation if “datetime” or “date” are specified in the document.""",Set different tags for dates.
The DocDateAnnotator provides a variety of options for setting the document date. The ner annotator will run this annotator as a sub-annotator. These can be specified by setting properties for the ner.docdate sub-annotator.,
The following example shows how to access label confidences for tokens and entities. Each token stores the probability of its NER label given by the CRF that was used to assign the label in the CoreAnnotations.NamedEntityTagProbsAnnotation.class. Each entity mention contains the probability of the token with the lowest label probability in its span. For example if Los Angeles had the following probabilities:,Access label confidences for tokens and entities
the entity Los Angeles would be assigned the LOCATION tag with a confidence of .992.,
Below is code for accessing these confidences.,Code for accessing confidences
It is possible to run Stanford CoreNLP with NER models that ignore capitalization. We have trained models like this for English. You can find details on the Caseless models page.,Ignore capitalization
The train/dev/test data files should be in the following format:,
"""In this example, each line is a token, followed by a tab, followed by the NER tag. A blank line represents a sentence break. The model that we release is trained on over a million tokens. The more training data you have, the more accurate your model should be.""",
"""The standard training data sets used for PERSON/LOCATION/ORGANIZATION/MISC must be purchased from the LDC, we do not distribute them.""",
Here is the command for starting the training process (make sure your CLASSPATH is set up to include all of the Stanford CoreNLP jars):,Start the training process
The training process can be customized using a properties file. Here is an example properties file for training an English model(ner.model.props):,Customize training process
There is more info about training a CRF model here.,Training a CRF model
You can learn more about what the various properties above mean here.,Modify properties file
"""SUTime rules can be changed by modifying its included TokensRegex rule files. Changing other rule-based components (money, etc.) requires changes to the Java source code.""",Modify SUTime rules
For more details on the CRF tagger see this page.,Using CRF Tagger