These are the default models that are run:,"# tags: LOCATION, ORGANIZATION, PERSON edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz # tags: DATE, LOCATION, MONEY, ORGANIZATION, PERCENT, PERSON, TIME edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz # LOCATION, MISC, ORGANIZATION, PERSON edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz"
"At this point, a series of rules used for the KBP 2017 competition will be run to create more fine-grained NER tags. These rules are applied using a TokensRegexNERAnnotator sub-annotator. That is the main NERCombinerAnnotator builds a TokensRegexNERAnnotator as a sub-annotator and runs it on all sentences as part of it’s entire tagging process. The purpose of these rules is give tokens more specific tags. So for instance California would be tagged as a STATE_OR_PROVINCE rather than just a LOCATION.","CAUSE_OF_DEATH, CITY, COUNTRY, CRIMINAL_CHARGE, EMAIL, HANDLE, IDEOLOGY, NATIONALITY, RELIGION, STATE_OR_PROVINCE, TITLE, URL"
"The first column is the tokens pattern, the second column is the NER tag to apply, the third is the types of NER tags that can be overwritten, and the fourth is a priority used for tie-breaking if two rules match a sequence.","Los Angeles CITY LOCATION,MISC 1.0"
"means to match the token “Los” followed by the token “Angeles”, and label them both as CITY, provided they have a current NER tag of O, LOCATION, or MISC.",Bachelor of (Arts|Science) DEGREE MISC 1.0
Here is a breakdown of how to customize the fine-grained NER. The overall ner annotator creates a sub-annotator called ner.fine.regexner which is an instance of a TokensRegexNERAnnotator.,"ignorecase=true,validpospattern=^(NN|JJ).*,edu/stanford/nlp/models/kbp/english/gazetteers/regexner_caseless.tab;edu/stanford/nlp/models/kbp/english/gazetteers/regexner_cased.tab"
Here is a breakdown of how to customize the fine-grained NER. The overall ner annotator creates a sub-annotator called ner.fine.regexner which is an instance of a TokensRegexNERAnnotator.,edu/stanford/nlp/models/kbp/english/gazetteers/regexner_caseless.tab edu/stanford/nlp/models/kbp/english/gazetteers/regexner_cased.tab
"For instance, suppose you want to match sports teams after the previous NER steps have been run.","Boston Red Sox SPORTS_TEAM ORGANIZATION,MISC 1 Denver Broncos SPORTS_TEAM ORGANIZATION,MISC 1 Detroit Red Wings SPORTS_TEAM ORGANIZATION,MISC 1 Los Angeles Lakers SPORTS_TEAM ORGANIZATION,MISC 1"
"If you want to run a series of TokensRegex rules before entity building, you can also specify a set of TokensRegex rules. A TokensRegexAnnotator sub-annotator will be called. It has the name ner.additional.tokensregex.","java -Xmx5g edu.stanford.nlp.pipeline.StanfordCoreNLP -annotators tokenize,ssplit,pos,lemma,ner -ner.additional.tokensregex.rules example.rules -file example.txt -outputFormat text"
There a variety of ways to customize an NER pipeline. Below are some example commands.,"# run default NER java -Xmx4g -cp ""*"" edu.stanford.nlp.pipeline.StanfordCoreNLP -annotators tokenize,ssplit,pos,lemma,ner -file example.txt -outputFormat text"
There a variety of ways to customize an NER pipeline. Below are some example commands.,"# only run rules based NER (numeric classifiers, SUTime, TokensRegexNER, TokensRegex) java -Xmx4g -cp ""*"" edu.stanford.nlp.pipeline.StanfordCoreNLP -annotators tokenize,ssplit,pos,lemma,ner -ner.rulesOnly -file example.txt"
There a variety of ways to customize an NER pipeline. Below are some example commands.,"# only run statistical NER java -Xmx4g -cp ""*"" edu.stanford.nlp.pipeline.StanfordCoreNLP -annotators tokenize,ssplit,pos,lemma,ner -ner.statisticalOnly -file example.txt"
There a variety of ways to customize an NER pipeline. Below are some example commands.,"# shut off numeric classifiers # note that in this case ner no longer requires pos or lemma java -Xmx4g -cp ""*"" edu.stanford.nlp.pipeline.StanfordCoreNLP -annotators tokenize,ssplit,ner -ner.applyNumericClassifiers false -file example.txt -outputFormat text"
There a variety of ways to customize an NER pipeline. Below are some example commands.,"# shut off SUTime java -Xmx4g -cp ""*"" edu.stanford.nlp.pipeline.StanfordCoreNLP -annotators tokenize,ssplit,pos,lemma,ner -ner.useSUTime false -file example.txt -outputFormat text"
There a variety of ways to customize an NER pipeline. Below are some example commands.,"# specify doc date for each document to be 2019-01-01 # other options for setting doc date specified below java -Xmx4g -cp ""*"" edu.stanford.nlp.pipeline.StanfordCoreNLP -annotators tokenize,ssplit,pos,lemma,ner -ner.docdate.useFixedDate 2019-01-01 -file example.txt"
There a variety of ways to customize an NER pipeline. Below are some example commands.,"# shut off fine grained NER java -Xmx4g -cp ""*"" edu.stanford.nlp.pipeline.StanfordCoreNLP -annotators tokenize,ssplit,pos,lemma,ner -ner.applyFineGrained false -file example.txt -outputFormat text"
There a variety of ways to customize an NER pipeline. Below are some example commands.,"# run fine-grained NER with a custom rules file java -Xmx4g -cp ""*"" edu.stanford.nlp.pipeline.StanfordCoreNLP -annotators tokenize,ssplit,pos,lemma,ner -ner.fine.regexner.mapping custom.rules -file example.txt -outputFormat text"
There a variety of ways to customize an NER pipeline. Below are some example commands.,"# run fine-grained NER with two custom rules files # the first rules file caseless.rules should be case-insensitive, the second rules file uses default options java -Xmx4g -cp ""*"" edu.stanford.nlp.pipeline.StanfordCoreNLP -annotators tokenize,ssplit,pos,lemma,ner -ner.fine.regexner.mapping ""ignorecase=true,caseless.rules;cased.rules"" -file example.txt -outputFormat text"
There a variety of ways to customize an NER pipeline. Below are some example commands.,"# add additional rules to run after fine-grained NER java -Xmx4g -cp ""*"" edu.stanford.nlp.pipeline.StanfordCoreNLP -annotators tokenize,ssplit,pos,lemma,ner -ner.additional.regexner.mapping additional.rules -file example.txt -outputFormat text"
There a variety of ways to customize an NER pipeline. Below are some example commands.,"# run tokens regex rules java -Xmx5g edu.stanford.nlp.pipeline.StanfordCoreNLP -annotators tokenize,ssplit,pos,lemma,ner -ner.additional.tokensregex.rules example.rules -file example.txt -outputFormat text"
There a variety of ways to customize an NER pipeline. Below are some example commands.,"# don't build entity mentions java -Xmx4g -cp ""*"" edu.stanford.nlp.pipeline.StanfordCoreNLP -annotators tokenize,ssplit,pos,lemma,ner -ner.buildEntityMentions false -file example.txt -outputFormat text"
The following example shows how to access label confidences for tokens and entities. Each token stores the probability of its NER label given by the CRF that was used to assign the label in the CoreAnnotations.NamedEntityTagProbsAnnotation.class. Each entity mention contains the probability of the token with the lowest label probability in its span. For example if Los Angeles had the following probabilities:,"{word: 'Los', 'tag': 'LOCATION', 'prob': .992} {word: 'Angeles', 'tag': 'LOCATION', 'prob': .999}"
Below is code for accessing these confidences.,"package edu.stanford.nlp.examples; import edu.stanford.nlp.ling.*; import edu.stanford.nlp.pipeline.*; import java.util.*; public class NERConfidenceExample { public static void main(String[] args) { String exampleText = ""Joe Smith lives in California.""; Properties props = new Properties(); props.setProperty(""annotators"", ""tokenize,ssplit,pos,lemma,ner""); StanfordCoreNLP pipeline = new StanfordCoreNLP(props); CoreDocument document = new CoreDocument(exampleText); pipeline.annotate(document); // get confidences for entities for (CoreEntityMention em : document.entityMentions()) { System.out.println(em.text() + ""\t"" + em.entityTypeConfidences()); } // get confidences for tokens for (CoreLabel token : document.tokens()) { System.out.println(token.word() + ""\t"" + token.get(CoreAnnotations.NamedEntityTagProbsAnnotation.class)); } } }"
"The standard training data sets used for PERSON/LOCATION/ORGANIZATION/MISC must be purchased from the LDC, we do not distribute them.","java -Xmx2g -cp ""*"" edu.stanford.nlp.ie.crf.CRFClassifier -prop ner.model.props"
The training process can be customized using a properties file. Here is an example properties file for training an English model(ner.model.props):,"# location of training data trainFileList = /path/to/conll.3class.train # location of test data testFile = /path/to/all.3class.test # where to store the saved model serializeTo = ner.model.ser.gz type = crf wordFunction = edu.stanford.nlp.process.AmericanizeFunction useDistSim = false # establish the data file format map = word=0,answer=1 saveFeatureIndexToDisk = true useClassFeature=true useWord=true useNGrams=true noMidNGrams=true maxNGramLeng=6 usePrev=true useNext=true useLongSequences=true useSequences=true usePrevSequences=true maxLeft=1 useTypeSeqs=true useTypeSeqs2=true useTypeySequences=true useOccurrencePatterns=true useLastRealWord=true useNextRealWord=true normalize=true wordShape=chris2useLC useDisjunctive=true disjunctionWidth=5 readerAndWriter=edu.stanford.nlp.sequences.ColumnDocumentReaderAndWriter useObservedSequencesOnly=true useQN = true QNsize = 25 # makes it go faster featureDiffThresh=0.05"
