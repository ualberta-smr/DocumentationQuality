Paragraph,Tasks
Bases: object,
"""A processing class for deriving trees that represent possible structures for a sequence of tokens. These tree structures are known as “parses”. Typically, parsers are used to derive syntax trees for sentences. But parsers can also be used to derive other kinds of tree structure, such as morphological trees and discourse structures.""",
"""at least one of: parse(), parse_sents().""",
grammar(),
The grammar used by this parser.,
An iterator that generates parse trees for the sentence.,Generate parse trees
When possible this list is sorted from most likely to least likely.,
sent (list(str)) – The sentence to be parsed,
iter(Tree),
list(Tree),
Tree or None,
Apply self.parse() to each element of sents. :rtype: iter(iter(Tree)),
Bases: nltk.parse.api.ParserI,
Interface for parsing with BLLIP Parser. BllipParser objects can be constructed with the BllipParser.from_unified_model_dir class method or manually using the BllipParser constructor.,
Create a BllipParser object from a unified parsing model directory. Unified parsing model directories are a standardized way of storing BLLIP parser and reranker models together on disk. See bllipparser.RerankingParser.get_unified_model_parameters() for more information about unified model directories.,Create BllipParser
A BllipParser object using the parser and reranker,
models in the model directory.,
model_dir (str) – Path to the unified model directory.,
"""parser_options – optional dictionary of parser options, see""",
"""bllipparser.RerankingParser.RerankingParser.load_parser_options() for more information. :type parser_options: dict(str) :param reranker_options: optional dictionary of reranker options, see bllipparser.RerankingParser.RerankingParser.load_reranker_model() for more information. :type reranker_options: dict(str) :rtype: BllipParser""",
Use BLLIP Parser to parse a sentence. Takes a sentence as a list of words; it will be automatically tagged with this BLLIP Parser instance’s tagger.,Use BLLIP
An iterator that generates parse trees for the sentence,Generate parse trees
from most likely to least likely.,
sentence (list(str)) – The sentence to be parsed,
iter(Tree),
"""Use BLLIP to parse a sentence. Takes a sentence as a list of (word, tag) tuples; the sentence must have already been tokenized and tagged. BLLIP will attempt to use the tags provided but may use others if it can’t come up with a complete parse subject to those constraints. You may also specify a tag as None to leave a token’s tag unconstrained.""","Use BLLIP, Specify tag as None"
An iterator that generates parse trees for the sentence,
from most likely to least likely.,
"""sentence (list(tuple(str, str))) – Input sentence to parse as (word, tag) pairs""",
iter(Tree),
"""Data classes and parser implementations for “chart parsers”, which use dynamic programming to efficiently parse a text. A chart parser derives parse trees for a text by iteratively adding “edges” to a “chart.” Each edge represents a hypothesis about the tree structure for a subsequence of the text. The chart is a “blackboard” for composing and combining these hypotheses.""",
"""When a chart parser begins parsing a text, it creates a new (empty) chart, spanning the text. It then incrementally adds new edges to the chart. A set of “chart rules” specifies the conditions under which new edges should be added to the chart. Once the chart reaches a stage where none of the chart rules adds any new edges, parsing is complete.""",
"""Charts are encoded with the Chart class, and edges are encoded with the TreeEdge and LeafEdge classes. The chart parser module defines three chart parsers:""",
"""ChartParser is a simple and flexible chart parser. Given a set of chart rules, it will apply those rules to the chart until no more edges are added.""",
SteppingChartParser is a subclass of ChartParser that can be used to step through the parsing process.,
Bases: nltk.parse.chart.ChartRuleI,
An abstract base class for chart rules. AbstractChartRule provides:,
A default implementation for apply.,
"""A default implementation for apply_everywhere, (Currently, this implementation assumes that ``NUM_EDGES``<=3.)""",
"""A default implementation for __str__, which returns a name based on the rule’s class name.""",
"""Return a generator that will add edges licensed by this rule and the given edges to the chart, one at a time. Each time the generator is resumed, it will either add a new edge and yield that edge; or return.""","Add edges at time, Add edges to chart, Add new edge"
edges (list(EdgeI)) – A set of existing edges. The number of edges that should be passed to apply() is specified by the NUM_EDGES class variable.,"Pass edges to apply(), specify number of edges"
iter(EdgeI),
"""Return a generator that will add all edges licensed by this rule, given the edges that are currently in the chart, one at a time. Each time the generator is resumed, it will either add a new edge and yield that edge; or return.""","Add edges, Add new edge"
iter(EdgeI),
Bases: nltk.parse.chart.ChartParser,
A ChartParser using a bottom-up parsing strategy. See ChartParser for more information.,
Bases: nltk.parse.chart.ChartParser,
A ChartParser using a bottom-up left-corner parsing strategy. This strategy is often more efficient than standard bottom-up. See ChartParser for more information.,
Bases: nltk.parse.chart.BottomUpPredictRule,
"""A rule licensing any edge corresponding to a production whose right-hand side begins with a complete edge’s left-hand side. In particular, this rule specifies that [A -> alpha \*] licenses the edge [B -> A \* beta] for each grammar production B -> A beta.""",
"""This is like BottomUpPredictRule, but it also applies the FundamentalRule to the resulting edge.""",
"""Return a generator that will add edges licensed by this rule and the given edges to the chart, one at a time. Each time the generator is resumed, it will either add a new edge and yield that edge; or return.""","Add edges, Add new edge"
edges (list(EdgeI)) – A set of existing edges. The number of edges that should be passed to apply() is specified by the NUM_EDGES class variable.,"pass edges to apply(), Specify number of edges"
iter(EdgeI),
Bases: nltk.parse.chart.AbstractChartRule,
"""A rule licensing any edge corresponding to a production whose right-hand side begins with a complete edge’s left-hand side. In particular, this rule specifies that [A -> alpha \*] licenses the edge [B -> \* A beta] for each grammar production B -> A beta.""",
"""Return a generator that will add edges licensed by this rule and the given edges to the chart, one at a time. Each time the generator is resumed, it will either add a new edge and yield that edge; or return.""","Add edges, Add new edge"
edges (list(EdgeI)) – A set of existing edges. The number of edges that should be passed to apply() is specified by the NUM_EDGES class variable.,"pass edges to apply(), Specify number of edges"
iter(EdgeI),
Bases: nltk.parse.chart.TopDownPredictRule,
"""A cached version of TopDownPredictRule. After the first time this rule is applied to an edge with a given end and next, it will not generate any more edges for edges with that end and next.""",
"""If chart or grammar are changed, then the cache is flushed.""",
"""Return a generator that will add edges licensed by this rule and the given edges to the chart, one at a time. Each time the generator is resumed, it will either add a new edge and yield that edge; or return.""","Add edges, Add new edge"
edges (list(EdgeI)) – A set of existing edges. The number of edges that should be passed to apply() is specified by the NUM_EDGES class variable.,"pass edges to apply(), Specify number of edges"
iter(EdgeI),
Bases: object,
"""A blackboard for hypotheses about the syntactic constituents of a sentence. A chart contains a set of edges, and each edge encodes a single hypothesis about the structure of some portion of the sentence.""",
"""The select method can be used to select a specific collection of edges. For example chart.select(is_complete=True, start=0) yields all complete edges whose start indices are 0. To ensure the efficiency of these selection operations, Chart dynamically creates and maintains an index for each set of attributes that have been selected on.""","Select specific collection of edges, Use select method, Create index for set"
"""In order to reconstruct the trees that are represented by an edge, the chart associates each edge with a set of child pointer lists. A child pointer list is a list of the edges that license an edge’s right-hand side.""",
_tokens – The sentence that the chart covers.,
_num_leaves – The number of tokens.,
_edges – A list of the edges in the chart,
_edge_to_cpls – A dictionary mapping each edge to a set of child pointer lists that are associated with that edge.,
"""_indexes – A dictionary mapping tuples of edge attributes to indices, where each index maps the corresponding edge attribute values to lists of edges.""",
Return the set of child pointer lists for the given edge. Each child pointer list is a list of edges that have been used to form this edge.,"List for given edge, Use edges"
list(list(EdgeI)),
Return a list of all edges in this chart. New edges that are added to the chart after the call to edges() will not be contained in this list.,Return list of edges in chart
list(EdgeI),
"""iteredges, select""",
Clear the chart.,Clear chart 
"""Add a new edge to the chart, and return True if this operation modified the chart. In particular, return true iff the chart did not already contain edge, or if it did not already associate child_pointer_lists with edge.""","Add new edge to chart, Modify, Chart"
edge (EdgeI) – The new edge,
child_pointer_lists (sequence of tuple(EdgeI)) – A sequence of lists of the edges that were used to form this edge. This list is used to reconstruct the trees (or partial trees) that are associated with edge.,Use sequence of lists
bool,
"""Add a new edge to the chart, using a pointer to the previous edge.""","Add new edge to chart, Use pointer to previous edge "
Return an iterator over the edges in this chart. It is not guaranteed that new edges which are added to the chart before the iterator is exhausted will also be generated.,Return iterator over chart
iter(EdgeI),
"""edges, select""",
Return the leaf value of the word at the given index.,Return leaf value of word
str,
Return a list of the leaf values of each word in the chart’s sentence.,Return list of leaf values
list(str),
Return the number of edges contained in this chart.,Return number of edges
int,
Return the number of words in this chart’s sentence.,
int,
"""Return an iterator of the complete tree structures that span the entire chart, and whose root node is root.""",Return iterator that span chart
Return a pretty-printed string representation of this chart.,Return pretty-printed string representatin of this chart
width – The number of characters allotted to each index in the sentence.,
str,
Return a pretty-printed string representation of a given edge in this chart.,Return pretty-printed string representation of given edge
str,
width – The number of characters allotted to each index in the sentence.,
Return a pretty-printed string representation of this chart’s leaves. This string can be used as a header for calls to pretty_format_edge.,Return pretty-printed string representation of chart leaves
Return an iterator over the edges in this chart. Any new edges that are added to the chart before the iterator is exahusted will also be generated. restrictions can be used to restrict the set of edges that will be generated.,Return iterator over edges in chart
span – Only generate edges e where e.span()==span,Generate edges e
start – Only generate edges e where e.start()==start,Generate edges e
end – Only generate edges e where e.end()==end,Generate edges e
length – Only generate edges e where e.length()==length,Generate edges e
lhs – Only generate edges e where e.lhs()==lhs,Generate edges e
rhs – Only generate edges e where e.rhs()==rhs,Generate edges e
nextsym – Only generate edges e where e.nextsym()==nextsym,Generate edges e
dot – Only generate edges e where e.dot()==dot,Generate edges e
is_complete – Only generate edges e where e.is_complete()==is_complete,Generate edges e
is_incomplete – Only generate edges e where e.is_incomplete()==is_incomplete,Generate edges e
iter(EdgeI),
Return an iterator of the tree structures that are associated with edge.,Return iterator of tree structures
"""If edge is incomplete, then the unexpanded children will be encoded as childless subtrees, whose node value is the corresponding terminal or nonterminal.""",
list(Tree),
"""If two trees share a common subtree, then the same Tree may be used to encode that subtree in both trees. If you need to eliminate this subtree sharing, then create a deep copy of each tree.""","Encode subtree in trees, Create deep copy of tree"
Bases: nltk.parse.api.ParserI,
"""A generic chart parser. A “strategy”, or list of ChartRuleI instances, is used to decide what edges to add to the chart. In particular, ChartParser uses the following algorithm to parse texts:""",
Return the final parse Chart from which all possible parse trees can be extracted.,Return final parse chart
tokens (list(str)) – The sentence to be parsed,
Chart,
The grammar used by this parser.,Use by parser
An iterator that generates parse trees for the sentence.,Generate parse trees
When possible this list is sorted from most likely to least likely.,
sent (list(str)) – The sentence to be parsed,
iter(Tree),
Bases: object,
"""A rule that specifies what new edges are licensed by any given set of existing edges. Each chart rule expects a fixed number of edges, as indicated by the class variable NUM_EDGES. In particular:""",Specify rule of existing edges
"""A chart rule with NUM_EDGES=0 specifies what new edges are licensed, regardless of existing edges.""",Specify regardless of existing edges
A chart rule with NUM_EDGES=1 specifies what new edges are licensed by a single existing edge.,Specify by single edge
A chart rule with NUM_EDGES=2 specifies what new edges are licensed by a pair of existing edges.,Specify by pair of edges
"""NUM_EDGES – The number of existing edges that this rule uses to license new edges. Typically, this number ranges from zero to two.""",
"""Return a generator that will add edges licensed by this rule and the given edges to the chart, one at a time. Each time the generator is resumed, it will either add a new edge and yield that edge; or return.""","Add edges to chart, Add new edge"
edges (list(EdgeI)) – A set of existing edges. The number of edges that should be passed to apply() is specified by the NUM_EDGES class variable.,"Pass edges to apply(), Specify number of edges"
iter(EdgeI),
"""Return a generator that will add all edges licensed by this rule, given the edges that are currently in the chart, one at a time. Each time the generator is resumed, it will either add a new edge and yield that edge; or return.""","Add edges to chart, Add new edge"
iter(EdgeI),
Bases: object,
A hypothesis about the structure of part of a sentence. Each edge records the fact that a structure is (partially) consistent with the sentence. An edge contains:,
"""A span, indicating what part of the sentence is consistent with the hypothesized structure.""",
"""A left-hand side, specifying what kind of structure is hypothesized.""",
"""A right-hand side, specifying the contents of the hypothesized structure.""",
"""A dot position, indicating how much of the hypothesized structure is consistent with the sentence.""",
Every edge is either complete or incomplete:,
An edge is complete if its structure is fully consistent with the sentence.,
"""An edge is incomplete if its structure is partially consistent with the sentence. For every incomplete edge, the span specifies a possible prefix for the edge’s structure.""",
There are two kinds of edge:,
A TreeEdge records which trees have been found to be (partially) consistent with the text.,
A LeafEdge records the tokens occurring in the text.,
"""The EdgeI interface provides a common interface to both types of edge, allowing chart parsers to treat them in a uniform manner.""",
"""Return this edge’s dot position, which indicates how much of the hypothesized structure is consistent with the sentence. In particular, self.rhs[:dot] is consistent with tokens[self.start():self.end()].""",Return dot position
int,
Return the end index of this edge’s span.,Return end index
int,
Return True if this edge’s structure is fully consistent with the text.,
bool,
Return True if this edge’s structure is partially consistent with the text.,
bool,
Return the length of this edge’s span.,Return edge span length
int,
"""Return this edge’s left-hand side, which specifies what kind of structure is hypothesized by this edge.""","Return left-hand side, Specify kind of structure"
TreeEdge and LeafEdge for a description of the left-hand side values for each edge type.,
Return the element of this edge’s right-hand side that immediately follows its dot.,Return element of right-hand side
Nonterminal or terminal or None,
"""Return this edge’s right-hand side, which specifies the content of the structure hypothesized by this edge.""","Return right-hand side, Specify content of structure"
TreeEdge and LeafEdge for a description of the right-hand side values for each edge type.,
"""Return a tuple (s, e), where tokens[s:e] is the portion of the sentence that is consistent with this edge’s structure.""","Return tuple (s, e)"
"""tuple(int, int)""",
Return the start index of this edge’s span.,Return start index
int,
Bases: nltk.parse.chart.AbstractChartRule,
"""A rule that inserts all empty productions as passive edges, in every position in the chart.""",
"""Return a generator that will add edges licensed by this rule and the given edges to the chart, one at a time. Each time the generator is resumed, it will either add a new edge and yield that edge; or return.""","Add edges to chart, Add new edge"
edges (list(EdgeI)) – A set of existing edges. The number of edges that should be passed to apply() is specified by the NUM_EDGES class variable.,"Pass edges to apply(), Specify number of edges"
iter(EdgeI),
Bases: nltk.parse.chart.BottomUpPredictCombineRule,
"""Return a generator that will add edges licensed by this rule and the given edges to the chart, one at a time. Each time the generator is resumed, it will either add a new edge and yield that edge; or return.""","Add edges to chart, Add new edge"
edges (list(EdgeI)) – A set of existing edges. The number of edges that should be passed to apply() is specified by the NUM_EDGES class variable.,"Pass edges to apply(), Specify number of edges"
iter(EdgeI),
Bases: nltk.parse.chart.SingleEdgeFundamentalRule,
Bases: nltk.parse.chart.AbstractChartRule,
"""A rule that joins two adjacent edges to form a single combined edge. In particular, this rule specifies that any pair of edges""",
[A -> alpha \* B beta][i:j],
[B -> gamma \*][j:k],
licenses the edge:,
[A -> alpha B * beta][i:j],
"""Return a generator that will add edges licensed by this rule and the given edges to the chart, one at a time. Each time the generator is resumed, it will either add a new edge and yield that edge; or return.""","Add edges to chart, Add new edge"
edges (list(EdgeI)) – A set of existing edges. The number of edges that should be passed to apply() is specified by the NUM_EDGES class variable.,"Pass edges to apply(), Specify number of edges"
iter(EdgeI),
Bases: nltk.parse.chart.EdgeI,
An edge that records the fact that a leaf value is consistent with a word in the sentence. A leaf edge consists of:,
"""An index, indicating the position of the word.""",
"""A leaf, specifying the word’s content.""",
"""A leaf edge’s left-hand side is its leaf value, and its right hand side is (). Its span is [index, index+1], and its dot position is 0.""",
"""Return this edge’s dot position, which indicates how much of the hypothesized structure is consistent with the sentence. In particular, self.rhs[:dot] is consistent with tokens[self.start():self.end()].""",
int,
Return the end index of this edge’s span.,Return end index
int,
Return True if this edge’s structure is fully consistent with the text.,
bool,
Return True if this edge’s structure is partially consistent with the text.,
bool,
Return the length of this edge’s span.,Return edge span length
int,
"""Return this edge’s left-hand side, which specifies what kind of structure is hypothesized by this edge.""","Return left-hand side, Specify kind of structure"
TreeEdge and LeafEdge for a description of the left-hand side values for each edge type.,
Return the element of this edge’s right-hand side that immediately follows its dot.,Return element of right-hand side
Nonterminal or terminal or None,
"""Return this edge’s right-hand side, which specifies the content of the structure hypothesized by this edge.""","Return right-hand side, Specify content of structure"
TreeEdge and LeafEdge for a description of the right-hand side values for each edge type.,
"""Return a tuple (s, e), where tokens[s:e] is the portion of the sentence that is consistent with this edge’s structure.""","Return tuple (s, e)"
"""tuple(int, int)""",
Return the start index of this edge’s span.,Return start index
int,
Bases: nltk.parse.chart.AbstractChartRule,
"""Return a generator that will add edges licensed by this rule and the given edges to the chart, one at a time. Each time the generator is resumed, it will either add a new edge and yield that edge; or return.""","Add edges to chart, Add new edge"
edges (list(EdgeI)) – A set of existing edges. The number of edges that should be passed to apply() is specified by the NUM_EDGES class variable.,"Pass edges to apply(), Specify number of edges"
iter(EdgeI),
Bases: nltk.parse.chart.ChartParser,
Bases: nltk.parse.chart.FundamentalRule,
"""A rule that joins a given edge with adjacent edges in the chart, to form combined edges. In particular, this rule specifies that either of the edges:""",
[A -> alpha \* B beta][i:j],
[B -> gamma \*][j:k],
licenses the edge:,
[A -> alpha B * beta][i:j],
if the other edge is already in the chart.,
"""This is basically FundamentalRule, with one edge left unspecified.""",
"""Return a generator that will add edges licensed by this rule and the given edges to the chart, one at a time. Each time the generator is resumed, it will either add a new edge and yield that edge; or return.""","Add edges to chart, Add new edge"
edges (list(EdgeI)) – A set of existing edges. The number of edges that should be passed to apply() is specified by the NUM_EDGES class variable.,"Pass edges to apply(), Specify number of edges"
iter(EdgeI),
Bases: nltk.parse.chart.ChartParser,
"""A ChartParser that allows you to step through the parsing process, adding a single edge at a time. It also allows you to change the parser’s strategy or grammar midway through parsing a text.""",
The initialize method is used to start parsing a text. step adds a single edge to the chart. set_strategy changes the strategy used by the chart parser. parses returns the set of parses that has been found by the chart parser.,
"""_restart – Records whether the parser’s strategy, grammar, or chart has been changed. If so, then step must restart the parsing algorithm.""",
Return the chart that is used by this parser.,
Return the chart rule used to generate the most recent edge.,
Return the grammar used by this parser.,
Begin parsing the given tokens.,
An iterator that generates parse trees for the sentence.,
When possible this list is sorted from most likely to least likely.,
sent (list(str)) – The sentence to be parsed,
iter(Tree),
Return the parse trees currently contained in the chart.,
Load a given chart into the chart parser.,
Change the grammar used by the parser.,
Change the strategy that the parser uses to decide which edges to add to the chart.,
strategy (list(ChartRuleI)) – A list of rules that should be used to decide what edges to add to the chart.,
"""Return a generator that adds edges to the chart, one at a time. Each time the generator is resumed, it adds a single edge and yields that edge. If no more edges can be added, then it yields None.""",
"""If the parser’s strategy, grammar, or chart is changed, then the generator will continue adding edges using the new strategy, grammar, or chart.""",
"""Note that this generator never terminates, since the grammar or strategy might be changed to values that would add new edges. Instead, it yields None when no more edges can be added with the current strategy and grammar.""",
Return the strategy used by this parser.,
Bases: nltk.parse.chart.ChartParser,
A ChartParser using a top-down parsing strategy. See ChartParser for more information.,
Bases: nltk.parse.chart.AbstractChartRule,
"""A rule licensing edges corresponding to the grammar productions for the grammar’s start symbol. In particular, this rule specifies that [S -> \* alpha][0:i] is licensed for each grammar production S -> alpha, where S is the grammar’s start symbol.""",
"""Return a generator that will add edges licensed by this rule and the given edges to the chart, one at a time. Each time the generator is resumed, it will either add a new edge and yield that edge; or return.""","Add edges to chart, Add new edge"
edges (list(EdgeI)) – A set of existing edges. The number of edges that should be passed to apply() is specified by the NUM_EDGES class variable.,"Pass edges to apply(), Specify number of edges"
iter(EdgeI),
Bases: nltk.parse.chart.AbstractChartRule,
"""A rule licensing edges corresponding to the grammar productions for the nonterminal following an incomplete edge’s dot. In particular, this rule specifies that [A -> alpha \* B beta][i:j] licenses the edge [B -> \* gamma][j:j] for each grammar production B -> gamma.""",
This rule corresponds to the Predictor Rule in Earley parsing.,
"""Return a generator that will add edges licensed by this rule and the given edges to the chart, one at a time. Each time the generator is resumed, it will either add a new edge and yield that edge; or return.""","Add edges to chart, Add new edge"
edges (list(EdgeI)) – A set of existing edges. The number of edges that should be passed to apply() is specified by the NUM_EDGES class variable.,"Pass edges to apply(), Specify number of edges"
iter(EdgeI),
Bases: nltk.parse.chart.EdgeI,
An edge that records the fact that a tree is (partially) consistent with the sentence. A tree edge consists of:,
"""A span, indicating what part of the sentence is consistent with the hypothesized tree.""",
"""A left-hand side, specifying the hypothesized tree’s node value.""",
"""A right-hand side, specifying the hypothesized tree’s children. Each element of the right-hand side is either a terminal, specifying a token with that terminal as its leaf value; or a nonterminal, specifying a subtree with that nonterminal’s symbol as its node value.""",
"""A dot position, indicating which children are consistent with part of the sentence. In particular, if dot is the dot position, rhs is the right-hand size, (start,end) is the span, and sentence is the list of tokens in the sentence, then tokens[start:end] can be spanned by the children specified by rhs[:dot].""",
"""For more information about edges, see the EdgeI interface.""",
"""Return this edge’s dot position, which indicates how much of the hypothesized structure is consistent with the sentence. In particular, self.rhs[:dot] is consistent with tokens[self.start():self.end()].""",Return dot position
int,
Return the end index of this edge’s span.,Return end index
int,
"""Return a new TreeEdge formed from the given production. The new edge’s left-hand side and right-hand side will be taken from production; its span will be (index,index); and its dot position will be 0.""",
TreeEdge,
Return True if this edge’s structure is fully consistent with the text.,
bool,
Return True if this edge’s structure is partially consistent with the text.,
bool,
Return the length of this edge’s span.,Return edge span length
int,
"""Return this edge’s left-hand side, which specifies what kind of structure is hypothesized by this edge.""","Return left-hand side, Specify kind of structure"
TreeEdge and LeafEdge for a description of the left-hand side values for each edge type.,
"""Return a new TreeEdge formed from this edge. The new edge’s dot position is increased by 1, and its end index will be replaced by new_end.""",
new_end (int) – The new end index.,
TreeEdge,
Return the element of this edge’s right-hand side that immediately follows its dot.,Return element of right-hand side
Nonterminal or terminal or None,
"""Return this edge’s right-hand side, which specifies the content of the structure hypothesized by this edge.""","Return right-hand side, Specify content of structure"
TreeEdge and LeafEdge for a description of the right-hand side values for each edge type.,
"""Return a tuple (s, e), where tokens[s:e] is the portion of the sentence that is consistent with this edge’s structure.""","Return tuple (s, e)"
"""tuple(int, int)""",
Return the start index of this edge’s span.,Return start index
int,
A demonstration of the chart parsers.,
Bases: nltk.parse.corenlp.GenericCoreNLPParser,
Dependency parser.,
Non-breaking space inside of a token.,
Phone numbers.,
Bases: nltk.parse.corenlp.GenericCoreNLPParser,
Bases: object,
Starts the CoreNLP server,
"""stderr (stdout,) – Specifies where CoreNLP output is redirected. Valid values are ‘devnull’, ‘stdout’, ‘pipe’""",
Bases: OSError,
Exceptions associated with the Core NLP server.,
"""Bases: nltk.parse.api.ParserI, nltk.tokenize.api.TokenizerI, nltk.tag.api.TaggerI""",
Interface to the CoreNLP Parser.,
Parse multiple sentences.,
Takes multiple sentences as a list where each sentence is a list of words. Each sentence will be automatically tagged with this CoreNLPParser instance’s tagger.,
"""If a whitespace exists inside a token, then the token will be treated as several tokens.""",
sentences (list(list(str))) – Input sentences to parse,
iter(iter(Tree)),
Parse a piece of text.,
The text might contain several sentences which will be split by CoreNLP.,
text (str) – text to be split.,
an iterable of syntactic structures. # TODO: should it be an iterable of iterables?,
Parse a sentence.,
"""Takes a sentence as a string; before parsing, it will be automatically tokenized and tagged by the CoreNLP Parser.""","Tokenize sentences, Tag sentence"
sentence (str) – Input sentence to parse,
iter(Tree),
Parse multiple sentences.,
Takes multiple sentences as a list of strings. Each sentence will be automatically tokenized and tagged.,"Tokenize sentence, Tag sentence"
sentences (list(str)) – Input sentences to parse.,
iter(iter(Tree)),
Tag multiple sentences.,
Takes multiple sentences as a list where each sentence is a string.,
sentences (list(str)) – Input sentences to tag,
"""list(list(list(tuple(str, str)))""",
Tag a list of tokens.,
"""list(tuple(str, str))""",
Tag multiple sentences.,
Takes multiple sentences as a list where each sentence is a list of tokens.,
sentences (list(list(str))) – Input sentences to tag,
"""list(list(tuple(str, str))""",
Tokenize a string of text.,
Tools for reading and writing dependency trees. The input is assumed to be in Malt-TAB format (http://stp.lingfil.uu.se/~nivre/research/MaltXML.html).,
Bases: object,
A container for the nodes and labelled edges of a dependency structure.,
Adds an arc from the node specified by head_address to the node specified by the mod address.,"Add arc from node, Specify to node"
Fully connects all non-root nodes. All nodes are set to be dependents of the root node.,Set nodes
"""Returns true if the graph contains a node with the given node address, false otherwise.""",Return true
Check whether there are cycles.,Check cycles
Return the node with the given address.,Return node with given address
Returns the number of left children under the node specified by the given address.,"Return number of left children, Return number under node"
filename – a name of a file in Malt-TAB format,
zero_based – nodes in the input file are numbered starting from 0,
"""rather than 1 (as produced by, e.g., zpar) :param str cell_separator: the cell separator. If not provided, cells are split by whitespace. :param str top_relation_label: the label by which the top relation is identified, for examlple, ROOT, null or TOP.""",
a list of DependencyGraphs,
Convert the data in a nodelist into a networkx labeled directed graph.,"Convert data into networkx, Convert data in nodelist"
Redirects arcs to any of the nodes in the originals list to the redirect node address.,Redirect nocde arcs
Removes the node with the given address. References to this node in others will still exist.,Remove node with given address
Returns the number of right children under the node specified by the given address.,"Return number of right children, Return number under node"
The dependency graph in CoNLL format.,
"""style (int) – the style to use for the format (3, 4, 10 columns)""",
str,
Return a dot representation suitable for using with Graphviz.,Use with Graphviz
"""Starting with the root node, build a dependency tree using the NLTK Tree constructor. Dependency labels are omitted.""",
"""Extract dependency triples of the form: ((head word, head tag), rel, (dep word, dep tag))""",Extract dependency triples
Bases: Exception,
Dependency graph exception.,
A demonstration of how to read a string representation of a CoNLL format dependency tree.,
A demonstration of the result of reading a dependency version of the first sentence of the Penn Treebank.,
"""Data classes and parser implementations for incremental chart parsers, which use dynamic programming to efficiently parse a text. A “chart parser” derives parse trees for a text by iteratively adding “edges” to a “chart”. Each “edge” represents a hypothesis about the tree structure for a subsequence of the text. The “chart” is a “blackboard” for composing and combining these hypotheses.""",
"""A parser is “incremental”, if it guarantees that for all i, j where i < j, all edges ending at i are built before any edges ending at j. This is appealing for, say, speech recognizer hypothesis filtering.""",
"""The main parser class is EarleyChartParser, which is a top-down algorithm, originally formulated by Jay Earley (1970).""",
Bases: nltk.parse.chart.SingleEdgeFundamentalRule,
Bases: nltk.parse.earleychart.CompleteFundamentalRule,
"""Return a generator that will add edges licensed by this rule and the given edges to the chart, one at a time. Each time the generator is resumed, it will either add a new edge and yield that edge; or return.""","Add edges to chart, Add new edge"
edges (list(EdgeI)) – A set of existing edges. The number of edges that should be passed to apply() is specified by the NUM_EDGES class variable.,"Pass edges to apply(), Specify number of edges"
iter(EdgeI),
Bases: nltk.parse.earleychart.IncrementalChartParser,
Bases: nltk.parse.featurechart.FeatureSingleEdgeFundamentalRule,
Bases: nltk.parse.earleychart.CompleterRule,
Bases: nltk.parse.earleychart.FeatureIncrementalChartParser,
Bases: nltk.parse.earleychart.FeatureIncrementalChartParser,
Bases: nltk.parse.earleychart.FeatureIncrementalChartParser,
"""Bases: nltk.parse.earleychart.IncrementalChart, nltk.parse.featurechart.FeatureChart""",
Returns an iterator over the edges in this chart. See Chart.select for more information about the restrictions on the edges.,Return iterator over edges
"""Bases: nltk.parse.earleychart.IncrementalChartParser, nltk.parse.featurechart.FeatureChartParser""",
Bases: nltk.parse.earleychart.FeatureIncrementalChartParser,
Bases: nltk.parse.featurechart.FeatureTopDownPredictRule,
Bases: nltk.parse.earleychart.ScannerRule,
Bases: nltk.parse.chart.FilteredSingleEdgeFundamentalRule,
"""Return a generator that will add edges licensed by this rule and the given edges to the chart, one at a time. Each time the generator is resumed, it will either add a new edge and yield that edge; or return.""","Add edges to chart, Add new edge"
edges (list(EdgeI)) – A set of existing edges. The number of edges that should be passed to apply() is specified by the NUM_EDGES class variable.,"Pass edges to apply(), Specify number of edges"
iter(EdgeI),
Bases: nltk.parse.earleychart.IncrementalChartParser,
Bases: nltk.parse.earleychart.IncrementalChartParser,
Bases: nltk.parse.chart.Chart,
Return a list of all edges in this chart. New edges that are added to the chart after the call to edges() will not be contained in this list.,Return list of edges in chart
list(EdgeI),
"""iteredges, select""",
Clear the chart.,Clear chart 
Return an iterator over the edges in this chart. It is not guaranteed that new edges which are added to the chart before the iterator is exhausted will also be generated.,Return iterator over chart
iter(EdgeI),
"""edges, select""",
Return an iterator over the edges in this chart. Any new edges that are added to the chart before the iterator is exahusted will also be generated. restrictions can be used to restrict the set of edges that will be generated.,"Return iterator over edges, Use restrictions"
span – Only generate edges e where e.span()==span,Generate edges e
start – Only generate edges e where e.start()==start,Generate edges e
end – Only generate edges e where e.end()==end,Generate edges e
length – Only generate edges e where e.length()==length,Generate edges e
lhs – Only generate edges e where e.lhs()==lhs,Generate edges e
rhs – Only generate edges e where e.rhs()==rhs,Generate edges e
nextsym – Only generate edges e where e.nextsym()==nextsym,Generate edges e
dot – Only generate edges e where e.dot()==dot,Generate edges e
is_complete – Only generate edges e where e.is_complete()==is_complete,Generate edges e
is_incomplete – Only generate edges e where e.is_incomplete()==is_incomplete,Generate edges e
iter(EdgeI),
Bases: nltk.parse.chart.ChartParser,
An incremental chart parser implementing Jay Earley’s parsing algorithm:,
Return the final parse Chart from which all possible parse trees can be extracted.,Return final parse Chart
tokens (list(str)) – The sentence to be parsed,
Chart,
Bases: nltk.parse.earleychart.IncrementalChartParser,
Bases: nltk.parse.earleychart.IncrementalChartParser,
Bases: nltk.parse.chart.CachedTopDownPredictRule,
Bases: nltk.parse.earleychart.CompleteFundamentalRule,
"""Return a generator that will add edges licensed by this rule and the given edges to the chart, one at a time. Each time the generator is resumed, it will either add a new edge and yield that edge; or return.""","Add edges to chart, Add new edge"
edges (list(EdgeI)) – A set of existing edges. The number of edges that should be passed to apply() is specified by the NUM_EDGES class variable.,"Pass edges to apply(), Specify number of edges"
iter(EdgeI),
A demonstration of the Earley parsers.,
Bases: object,
Class for measuring labelled and unlabelled attachment score for dependency parsing. Note that the evaluation ignores punctuation.,
Return the Labeled Attachment Score (LAS) and Unlabeled Attachment Score (UAS),"Return Labeled attachment score, Return Unlabeled attachment score"
""":return : tuple(float,float)""",
Extension of chart parsing implementation to handle grammars with feature structures as nodes.,
Bases: nltk.parse.featurechart.FeatureChartParser,
Bases: nltk.parse.featurechart.FeatureChartParser,
Bases: nltk.parse.chart.BottomUpPredictCombineRule,
"""Return a generator that will add edges licensed by this rule and the given edges to the chart, one at a time. Each time the generator is resumed, it will either add a new edge and yield that edge; or return.""","Add edges to chart, Add new edge"
edges (list(EdgeI)) – A set of existing edges. The number of edges that should be passed to apply() is specified by the NUM_EDGES class variable.,"Pass edges to apply(), Specify number of edges"
iter(EdgeI),
Bases: nltk.parse.chart.BottomUpPredictRule,
"""Return a generator that will add edges licensed by this rule and the given edges to the chart, one at a time. Each time the generator is resumed, it will either add a new edge and yield that edge; or return.""","Add edges to chart, Add new edge"
edges (list(EdgeI)) – A set of existing edges. The number of edges that should be passed to apply() is specified by the NUM_EDGES class variable.,"Pass edges to apply(), Specify number of edges"
iter(EdgeI),
Bases: nltk.parse.chart.Chart,
A Chart for feature grammars. :see: Chart for more information.,
"""Return an iterator of the complete tree structures that span the entire chart, and whose root node is root.""",Return iterator that span chart
Returns an iterator over the edges in this chart. See Chart.select for more information about the restrictions on the edges.,Return iterator over edges
Bases: nltk.parse.chart.ChartParser,
Bases: nltk.parse.chart.EmptyPredictRule,
"""Return a generator that will add edges licensed by this rule and the given edges to the chart, one at a time. Each time the generator is resumed, it will either add a new edge and yield that edge; or return.""","Add edges to chart, Add new edge"
edges (list(EdgeI)) – A set of existing edges. The number of edges that should be passed to apply() is specified by the NUM_EDGES class variable.,"Pass edges to apply(), Specify number of edges"
iter(EdgeI),
Bases: nltk.parse.chart.FundamentalRule,
"""A specialized version of the fundamental rule that operates on nonterminals whose symbols are FeatStructNonterminal``s.  Rather tha simply comparing the nonterminals for equality, they are unified.  Variable bindings from these unifications are collected and stored in the chart using a ``FeatureTreeEdge. When a complete edge is generated, these bindings are applied to all nonterminals in the edge.""",
The fundamental rule states that:,
[A -> alpha \* B1 beta][i:j],
[B2 -> gamma \*][j:k],
licenses the edge:,
[A -> alpha B3 \* beta][i:j],
assuming that B1 and B2 can be unified to generate B3.,
"""Return a generator that will add edges licensed by this rule and the given edges to the chart, one at a time. Each time the generator is resumed, it will either add a new edge and yield that edge; or return.""","Add edges to chart, Add new edge"
edges (list(EdgeI)) – A set of existing edges. The number of edges that should be passed to apply() is specified by the NUM_EDGES class variable.,"Pass edges to apply(), Specify number of edges"
iter(EdgeI),
Bases: nltk.parse.chart.SingleEdgeFundamentalRule,
"""A specialized version of the completer / single edge fundamental rule that operates on nonterminals whose symbols are ``FeatStructNonterminal``s. Rather than simply comparing the nonterminals for equality, they are unified.""",
Bases: nltk.parse.featurechart.FeatureChartParser,
Bases: nltk.parse.chart.TopDownInitRule,
"""Return a generator that will add edges licensed by this rule and the given edges to the chart, one at a time. Each time the generator is resumed, it will either add a new edge and yield that edge; or return.""","Add edges to chart, Add new edge"
edges (list(EdgeI)) – A set of existing edges. The number of edges that should be passed to apply() is specified by the NUM_EDGES class variable.,"Pass edges to apply(), Specify number of edges"
iter(EdgeI),
Bases: nltk.parse.chart.CachedTopDownPredictRule,
"""A specialized version of the (cached) top down predict rule that operates on nonterminals whose symbols are ``FeatStructNonterminal``s. Rather than simply comparing the nonterminals for equality, they are unified.""",
The top down expand rule states that:,
[A -> alpha \* B1 beta][i:j],
licenses the edge:,
[B2 -> \* gamma][j:j],
"""for each grammar production B2 -> gamma, assuming that B1 and B2 can be unified.""",
"""Return a generator that will add edges licensed by this rule and the given edges to the chart, one at a time. Each time the generator is resumed, it will either add a new edge and yield that edge; or return.""","Add edges to chart, Add new edge"
edges (list(EdgeI)) – A set of existing edges. The number of edges that should be passed to apply() is specified by the NUM_EDGES class variable.,"Pass edges to apply(), Specify number of edges"
iter(EdgeI),
Bases: nltk.parse.chart.TreeEdge,
A specialized tree edge that allows shared variable bindings between nonterminals on the left-hand side and right-hand side.,
"""Each FeatureTreeEdge contains a set of bindings, i.e., a dictionary mapping from variables to values. If the edge is not complete, then these bindings are simply stored. However, if the edge is complete, then the constructor applies these bindings to every nonterminal in the edge whose symbol implements the interface SubstituteBindingsI.""",
Return a copy of this edge’s bindings dictionary.,Return edge bindings
"""A new TreeEdge formed from the given production. The new edge’s left-hand side and right-hand side will be taken from production; its span will be (index,index); and its dot position will be 0.""",
TreeEdge,
"""A new FeatureTreeEdge formed from this edge. The new edge’s dot position is increased by 1, and its end index will be replaced by new_end.""",
FeatureTreeEdge,
new_end (int) – The new end index.,
bindings (dict) – Bindings for the new edge.,
The set of variables used by this edge.,
set(Variable),
Bases: nltk.parse.featurechart.FeatureChart,
"""A specialized chart that ‘instantiates’ variables whose names start with ‘@’, by replacing them with unique new variables. In particular, whenever a complete edge is added to the chart, any variables in the edge’s lhs whose names start with ‘@’ will be replaced by unique new ``Variable``s.""",
Clear the chart.,
"""Add a new edge to the chart, and return True if this operation modified the chart. In particular, return true iff the chart did not already contain edge, or if it did not already associate child_pointer_lists with edge.""","Add new edge to chart, Return True, Modify Chart"
edge (EdgeI) – The new edge,
child_pointer_lists (sequence of tuple(EdgeI)) – A sequence of lists of the edges that were used to form this edge. This list is used to reconstruct the trees (or partial trees) that are associated with edge.,
bool,
"""If the edge is a FeatureTreeEdge, and it is complete, then instantiate all variables whose names start with ‘@’, by replacing them with unique new variables.""",
"""Note that instantiation is done in-place, since the parsing algorithms might already hold a reference to the edge for future use.""",
Generates an iterator of all sentences from a CFG.,
grammar – The Grammar used to generate sentences.,
start – The Nonterminal from which to start generate sentences.,
depth – The maximal depth of the generated tree.,
n – The maximum number of sentences to return.,
An iterator of lists of terminal tokens.,
Bases: nltk.parse.api.ParserI,
A class for dependency parsing with MaltParser. The input is the paths to: - a maltparser directory - (optionally) the path to a pre-trained MaltParser .mco model file - (optionally) the tagger to use for POS tagging before parsing - (optionally) additional Java arguments,
This function generates the maltparser command use at the terminal.,
inputfilename (str) – path to the input file,
outputfilename (str) – path to the output file,
"""Use MaltParser to parse multiple sentences. Takes a list of sentences, where each sentence is a list of words. Each sentence will be automatically tagged with this MaltParser instance’s tagger.""",
sentences – Input sentences to parse,
iter(DependencyGraph),
"""Use MaltParser to parse multiple POS tagged sentences. Takes multiple sentences where each sentence is a list of (word, tag) tuples. The sentences must have already been tokenized and tagged.""",
sentences – Input sentences to parse,
iter(iter(DependencyGraph)) the dependency graph,
representation of each sentence,
Train MaltParser from a list of DependencyGraph objects,Train MaltParser
depgraphs (DependencyGraph) – list of DependencyGraph objects for training input data,
Train MaltParser from a file :param conll_file: str for the filename of the training input data :type conll_file: str,Train MaltParser
A module to find pre-trained MaltParser model.,
A module to find MaltParser .jar file and its dependencies.,
Bases: nltk.parse.nonprojectivedependencyparser.DependencyScorerI,
graph (DependencyGraph) – A dependency graph whose set of edges need to be,
"""scored. :rtype: A three-dimensional list of numbers. :return: The score is returned in a multidimensional(3) list, such that the outer-dimension refers to the head, and the inner-dimension refers to the dependencies. For instance, scores[0][1] would reference the list of scores corresponding to arcs from node 0 to node 1. The node’s ‘address’ field can be used to determine its number identification.""",
"""For further illustration, a score list corresponding to Fig.2 of Keith Hall’s ‘K-best Spanning Tree Parsing’ paper:""",
"""[[], [], [11], [4]], [[], [10], [], [5]], [[], [8], [8], []]]""",
"""When used in conjunction with a MaxEntClassifier, each score would correspond to the confidence of a particular edge being classified with the positive training examples.""",
graphs (list(DependencyGraph)) – A list of dependency graphs to train the scorer.,
"""Typically the edges present in the graphs can be used as positive training examples, and the edges not present as negative examples.""",
Bases: object,
"""A scorer for calculated the weights on the edges of a weighted dependency graph. This is used by a ProbabilisticNonprojectiveParser to initialize the edge weights of a DependencyGraph. While typically this would be done by training a binary classifier, any class that can return a multidimensional list representation of the edge weights can implement this interface. As such, it has no necessary fields.""",
graph (DependencyGraph) – A dependency graph whose set of edges need to be,
"""scored. :rtype: A three-dimensional list of numbers. :return: The score is returned in a multidimensional(3) list, such that the outer-dimension refers to the head, and the inner-dimension refers to the dependencies. For instance, scores[0][1] would reference the list of scores corresponding to arcs from node 0 to node 1. The node’s ‘address’ field can be used to determine its number identification.""",
"""For further illustration, a score list corresponding to Fig.2 of Keith Hall’s ‘K-best Spanning Tree Parsing’ paper:""",
"""[[], [], [11], [4]], [[], [10], [], [5]], [[], [8], [8], []]]""",
"""When used in conjunction with a MaxEntClassifier, each score would correspond to the confidence of a particular edge being classified with the positive training examples.""",
graphs (list(DependencyGraph)) – A list of dependency graphs to train the scorer.,
"""Typically the edges present in the graphs can be used as positive training examples, and the edges not present as negative examples.""",
Bases: nltk.parse.nonprojectivedependencyparser.DependencyScorerI,
"""A dependency scorer built around a MaxEnt classifier. In this particular class that classifier is a NaiveBayesClassifier. It uses head-word, head-tag, child-word, and child-tag features for classification.""",
"""Converts the graph into a feature-based representation of each edge, and then assigns a score to each based on the confidence of the classifier in assigning it to the positive label. Scores are returned in a multidimensional list.""","Convert graph into feature-based representation, Assign score, Assign to positive label, Return scores in multidimensional list"
graph (DependencyGraph) – A dependency graph to score.,
3 dimensional list,
Edge scores for the graph parameter.,
"""Trains a NaiveBayesClassifier using the edges present in graphs list as positive examples, the edges not present as negative examples. Uses a feature vector of head-word, head-tag, child-word, and child-tag.""","Use edges present list as positive examples, Train NaiveBayesClassifier"
graphs (list(DependencyGraph)) – A list of dependency graphs to train the scorer.,
Bases: object,
"""A non-projective, rule-based, dependency parser. This parser will return the set of all possible non-projective parses based on the word-to-word relations defined in the parser’s dependency grammar, and will allow the branches of the parse tree to cross in order to capture a variety of linguistic phenomena that a projective parser will not.""",
"""Parses the input tokens with respect to the parser’s grammar. Parsing is accomplished by representing the search-space of possible parses as a fully-connected directed graph. Arcs that would lead to ungrammatical parses are removed and a lattice is constructed of length n, where n is the number of input tokens, to represent all possible grammatical traversals. All possible paths through the lattice are then enumerated to produce the set of non-projective parses.""",
param tokens: A list of tokens to parse. type tokens: list(str) return: An iterator of non-projective parses. rtype: iter(DependencyGraph),
Bases: object,
A probabilistic non-projective dependency parser.,
"""Nonprojective dependencies allows for “crossing branches” in the parse tree which is necessary for representing particular linguistic phenomena, or even typical parses in some languages. This parser follows the MST parsing algorithm, outlined in McDonald(2005), which likens the search for the best non-projective parse to finding the maximum spanning tree in a weighted directed graph.""",
Returns the source of the best incoming arc to the node with address: node_index,
"""node_index (integer.) – The address of the ‘destination’ node,""",
the node that is arced to.,
"""Takes a list of nodes that have been identified to belong to a cycle, and collapses them into on larger node. The arcs of all nodes in the graph must be updated to account for this.""",Collapse list of nodes
new_node (Node.) – A Node (Dictionary) to collapse the cycle nodes into.,
"""cycle_path (A list of integers.) – A list of node addresses, each of which is in the cycle.""",
"""b_graph, c_graph (g_graph,) – Graphs which need to be updated.""",
When updating scores the score of the highest-weighted incoming arc is subtracted upon collapse. This returns the correct amount to subtract from that edge.,
column_index (integer.) – A index representing the column of incoming arcs,
to a particular node being updated :type cycle_indexes: A list of integers. :param cycle_indexes: Only arcs from cycle nodes are considered. This is a list of such nodes addresses.,
"""As nodes are collapsed into others, they are replaced by the new node in the graph, but it’s still necessary to keep track of what these original nodes were. This takes a list of node addresses and replaces any collapsed node addresses with their original addresses.""",
new_indexes (A list of integers.) – A list of node addresses to check for,
subsumed nodes.,
Assigns a score to every edge in the DependencyGraph graph. These scores are generated via the parser’s scorer which was assigned during the training process.,Assign score
graph (DependencyGraph) – A dependency graph to assign scores to.,
Parses a list of tokens in accordance to the MST parsing algorithm for non-projective dependency parses. Assumes that the tokens to be parsed have already been tagged and those tags are provided. Various scoring methods can be used by implementing the DependencyScorerI interface and passing it to the training algorithm.,Parse list of tokens
tokens (list(str)) – A list of words or punctuation to be parsed.,
tags (list(str)) – A list of tags corresponding by index to the words in the tokens list.,
An iterator of non-projective parses.,
iter(DependencyGraph),
"""Trains a DependencyScorerI from a set of DependencyGraph objects, and establishes this as the parser’s scorer. This is used to initialize the scores on a DependencyGraph during the parsing procedure.""",
graphs (list(DependencyGraph)) – A list of dependency graphs to train the scorer.,
dependency_scorer (DependencyScorerI) – A scorer which implements the DependencyScorerI interface.,
Updates the edge scores to reflect a collapse operation into new_node.,
new_node (A Node.) – The node which cycle nodes are collapsed into.,
cycle_path (A list of integers.) – A list of node addresses that belong to the cycle.,
Classes and interfaces for associating probabilities with tree structures that represent the internal organization of a text. The probabilistic parser module defines BottomUpProbabilisticChartParser.,
"""BottomUpProbabilisticChartParser is an abstract class that implements a bottom-up chart parser for PCFG grammars. It maintains a queue of edges, and adds them to the chart one at a time. The ordering of this queue is based on the probabilities associated with the edges, allowing the parser to expand more likely edges before less likely ones. Each subclass implements a different queue ordering, producing different search strategies. Currently the following subclasses are defined:""",
InsideChartParser searches edges in decreasing order of their trees’ inside probabilities.,
RandomChartParser searches edges in random order.,
LongestChartParser searches edges in decreasing order of their location’s length.,
"""The BottomUpProbabilisticChartParser constructor has an optional argument beam_size. If non-zero, this controls the size of the beam (aka the edge queue). This option is most useful with InsideChartParser.""",
Bases: nltk.parse.api.ParserI,
"""An abstract bottom-up parser for PCFG grammars that uses a Chart to record partial results. BottomUpProbabilisticChartParser maintains a queue of edges that can be added to the chart. This queue is initialized with edges for each token in the text that is being parsed. BottomUpProbabilisticChartParser inserts these edges into the chart one at a time, starting with the most likely edges, and proceeding to less likely edges. For each edge that is added to the chart, it may become possible to insert additional edges into the chart; these are added to the queue. This process continues until enough complete parses have been generated, or until the queue is empty.""",
The sorting order for the queue is not specified by BottomUpProbabilisticChartParser. Different sorting orders will result in different search strategies. The sorting order for the queue is defined by the method sort_queue; subclasses are required to provide a definition for this method.,
_grammar – The grammar used to parse sentences.,
_trace – The level of tracing output that should be generated when parsing a text.,
The grammar used by this parser.,
An iterator that generates parse trees for the sentence.,
When possible this list is sorted from most likely to least likely.,
sent (list(str)) – The sentence to be parsed,
iter(Tree),
"""Sort the given queue of Edge objects, placing the edge that should be tried first at the beginning of the queue. This method will be called after each Edge is added to the queue.""",Sort edge objects
queue (list(Edge)) – The queue of Edge objects to sort. Each edge in this queue is an edge that could be added to the chart by the fundamental rule; but that has not yet been added.,
chart (Chart) – The chart being used to parse the text. This chart can be used to provide extra information for sorting the queue.,
None,
Set the level of tracing output that should be generated when parsing a text.,Set tracing level
trace (int) – The trace level. A trace level of 0 will generate no tracing output; and higher trace levels will produce more verbose tracing output.,
None,
Bases: nltk.parse.pchart.BottomUpProbabilisticChartParser,
"""A bottom-up parser for PCFG grammars that tries edges in descending order of the inside probabilities of their trees. The “inside probability” of a tree is simply the probability of the entire tree, ignoring its context. In particular, the inside probability of a tree generated by production p with children c[1], c[2], …, c[n] is P(p)P(c[1])P(c[2])…P(c[n]); and the inside probability of a token is 1 if it is present in the text, and 0 if it is absent.""",
This sorting order results in a type of lowest-cost-first search strategy.,
"""Sort the given queue of edges, in descending order of the inside probabilities of the edges’ trees.""",Sort edges
queue (list(Edge)) – The queue of Edge objects to sort. Each edge in this queue is an edge that could be added to the chart by the fundamental rule; but that has not yet been added.,
chart (Chart) – The chart being used to parse the text. This chart can be used to provide extra information for sorting the queue.,
None,
Bases: nltk.parse.pchart.BottomUpProbabilisticChartParser,
A bottom-up parser for PCFG grammars that tries longer edges before shorter ones. This sorting order results in a type of best-first search strategy.,
"""Sort the given queue of Edge objects, placing the edge that should be tried first at the beginning of the queue. This method will be called after each Edge is added to the queue.""",
queue (list(Edge)) – The queue of Edge objects to sort. Each edge in this queue is an edge that could be added to the chart by the fundamental rule; but that has not yet been added.,
chart (Chart) – The chart being used to parse the text. This chart can be used to provide extra information for sorting the queue.,
None,
Bases: nltk.parse.chart.AbstractChartRule,
"""Return a generator that will add edges licensed by this rule and the given edges to the chart, one at a time. Each time the generator is resumed, it will either add a new edge and yield that edge; or return.""","Add edges to chart, Add new edge"
edges (list(EdgeI)) – A set of existing edges. The number of edges that should be passed to apply() is specified by the NUM_EDGES class variable.,"Pass edges to apply(), Specify number of edges"
iter(EdgeI),
Bases: nltk.parse.chart.AbstractChartRule,
"""Return a generator that will add edges licensed by this rule and the given edges to the chart, one at a time. Each time the generator is resumed, it will either add a new edge and yield that edge; or return.""","Add edges to chart, Add new edge"
edges (list(EdgeI)) – A set of existing edges. The number of edges that should be passed to apply() is specified by the NUM_EDGES class variable.,"Pass edges to apply(), Specify number of edges"
iter(EdgeI),
Bases: nltk.parse.chart.AbstractChartRule,
"""Return a generator that will add edges licensed by this rule and the given edges to the chart, one at a time. Each time the generator is resumed, it will either add a new edge and yield that edge; or return.""","Add edges to chart, Add new edge"
edges (list(EdgeI)) – A set of existing edges. The number of edges that should be passed to apply() is specified by the NUM_EDGES class variable.,"Pass edges to apply(), Specify number of edges"
iter(EdgeI),
Bases: nltk.parse.chart.LeafEdge,
Bases: nltk.parse.chart.TreeEdge,
"""Return a new TreeEdge formed from the given production. The new edge’s left-hand side and right-hand side will be taken from production; its span will be (index,index); and its dot position will be 0.""",Return TreeEdge
TreeEdge,
Bases: nltk.parse.pchart.BottomUpProbabilisticChartParser,
A bottom-up parser for PCFG grammars that tries edges in random order. This sorting order results in a random search strategy.,
"""Sort the given queue of Edge objects, placing the edge that should be tried first at the beginning of the queue. This method will be called after each Edge is added to the queue.""",Sort edge objects
queue (list(Edge)) – The queue of Edge objects to sort. Each edge in this queue is an edge that could be added to the chart by the fundamental rule; but that has not yet been added.,
chart (Chart) – The chart being used to parse the text. This chart can be used to provide extra information for sorting the queue.,
None,
Bases: nltk.parse.chart.AbstractChartRule,
"""Return a generator that will add edges licensed by this rule and the given edges to the chart, one at a time. Each time the generator is resumed, it will either add a new edge and yield that edge; or return.""","Add edges to chart, Add new edge"
edges (list(EdgeI)) – A set of existing edges. The number of edges that should be passed to apply() is specified by the NUM_EDGES class variable.,"Pass edges to apply(), Specify number of edges"
iter(EdgeI),
Bases: nltk.parse.pchart.BottomUpProbabilisticChartParser,
A bottom-up parser for PCFG grammars that tries edges in whatever order.,
"""Sort the given queue of Edge objects, placing the edge that should be tried first at the beginning of the queue. This method will be called after each Edge is added to the queue.""",
queue (list(Edge)) – The queue of Edge objects to sort. Each edge in this queue is an edge that could be added to the chart by the fundamental rule; but that has not yet been added.,
chart (Chart) – The chart being used to parse the text. This chart can be used to provide extra information for sorting the queue.,
None,
"""A demonstration of the probabilistic parsers. The user is prompted to select which demo to run, and how many parses should be found; and then each parser is run on the same demo, and a summary of the results are displayed.""",
Bases: object,
"""A cell from the parse chart formed when performing the CYK algorithm. Each cell keeps track of its x and y coordinates (though this will probably be discarded), and a list of spans serving as the cell’s entries.""",
Appends the given span to the list of spans representing the chart cell’s entries.,
span (DependencySpan) – The span to add.,
Bases: object,
"""A contiguous span over some part of the input string representing dependency (head -> modifier) relationships amongst words. An atomic span corresponds to only one word so it isn’t a ‘span’ in the conventional sense, as its _start_index = _end_index = _head_index for concatenation purposes. All other spans are assumed to have arcs between all nodes within the start and end indexes of the span, and one head index corresponding to the head word for the entire span. This is the same as the root node if the dependency structure were depicted as a graph.""",
An value indexing the head of the entire DependencySpan.,
int,
Bases: object,
"""A probabilistic, projective dependency parser.""",
"""This parser returns the most probable projective parse derived from the probabilistic dependency grammar derived from the train() method. The probabilistic model is an implementation of Eisner’s (1996) Model C, which conditions on head-word, head-tag, child-word, and child-tag. The decoding uses a bottom-up chart-based span concatenation algorithm that’s identical to the one utilized by the rule-based projective parser.""",
Computes the probability of a dependency graph based on the parser’s probability model (defined by the parser’s statistical dependency grammar).,Compute dependency graph probability
dg (DependencyGraph) – A dependency graph to score.,
The probability of the dependency graph.,
int,
"""Concatenates the two spans in whichever way possible. This includes rightward concatenation (from the leftmost word of the leftmost span to the rightmost word of the rightmost span) and leftward concatenation (vice-versa) between adjacent spans. Unlike Eisner’s presentation of span concatenation, these spans do not share or pivot on a particular word/word-index.""",Concatenate spans
A list of new spans formed through concatenation.,
list(DependencySpan),
Parses the list of tokens subject to the projectivity constraint and the productions in the parser’s grammar. This uses a method similar to the span-concatenation algorithm defined in Eisner (1996). It returns the most probable parse derived from the parser’s probabilistic dependency grammar.,
"""Trains a ProbabilisticDependencyGrammar based on the list of input DependencyGraphs. This model is an implementation of Eisner’s (1996) Model C, which derives its statistics from head-word, head-tag, child-word, and child-tag relationships.""",
graphs – A list of dependency graphs to train from.,
list(DependencyGraph),
Bases: object,
"""A projective, rule-based, dependency parser. A ProjectiveDependencyParser is created with a DependencyGrammar, a set of productions specifying word-to-word dependency relations. The parse() method will then return the set of all parses, in tree representation, for a given input sequence of tokens. Each parse must meet the requirements of the both the grammar and the projectivity constraint which specifies that the branches of the dependency tree are not allowed to cross. Alternatively, this can be understood as stating that each parent node and its children in the parse tree form a continuous substring of the input sequence.""",
"""Concatenates the two spans in whichever way possible. This includes rightward concatenation (from the leftmost word of the leftmost span to the rightmost word of the rightmost span) and leftward concatenation (vice-versa) between adjacent spans. Unlike Eisner’s presentation of span concatenation, these spans do not share or pivot on a particular word/word-index.""",Concatenate spans
A list of new spans formed through concatenation.,
list(DependencySpan),
"""Performs a projective dependency parse on the list of tokens using a chart-based, span-concatenation algorithm similar to Eisner (1996).""",
tokens (list(str)) – The list of input tokens.,
An iterator over parse trees.,
iter(Tree),
A demonstration showing the creation of a DependencyGrammar in which a specific number of modifiers is listed for a given head. This can further constrain the number of possible parses created by a ProjectiveDependencyParser.,
A demo showing the training and use of a projective dependency parser.,
A demonstration showing the creation and use of a DependencyGrammar to perform a projective dependency parse.,
Bases: nltk.parse.api.ParserI,
"""A simple top-down CFG parser that parses texts by recursively expanding the fringe of a Tree, and matching it against a text.""",
RecursiveDescentParser uses a list of tree locations called a “frontier” to remember which subtrees have not yet been expanded and which leaves have not yet been matched against the text. Each tree location consists of a list of child indices specifying the path from the root of the tree to a subtree or a leaf; see the reference documentation for Tree for more information about tree locations.,
"""When the parser begins parsing a text, it constructs a tree containing only the start symbol, and a frontier containing the location of the tree’s root node. It then extends the tree to cover the text, using the following recursive procedure:""",
"""If the frontier is empty, and the text is covered by the tree, then return the tree as a possible parse.""",
"""If the frontier is empty, and the text is not covered by the tree, then return no parses.""",
"""If the first element of the frontier is a subtree, then use CFG productions to “expand” it. For each applicable production, add the expanded subtree’s children to the frontier, and recursively find all parses that can be generated by the new tree and frontier.""",
"""If the first element of the frontier is a token, then “match” it against the next token from the text. Remove the token from the frontier, and recursively find all parses that can be generated by the new tree and frontier.""",
nltk.grammar,
The grammar used by this parser.,
An iterator that generates parse trees for the sentence.,
When possible this list is sorted from most likely to least likely.,
sent (list(str)) – The sentence to be parsed,
iter(Tree),
Set the level of tracing output that should be generated when parsing a text.,
trace (int) – The trace level. A trace level of 0 will generate no tracing output; and higher trace levels will produce more verbose tracing output.,
None,
Bases: nltk.parse.recursivedescent.RecursiveDescentParser,
"""A RecursiveDescentParser that allows you to step through the parsing process, performing a single operation at a time.""",
"""The initialize method is used to start parsing a text. expand expands the first element on the frontier using a single CFG production, and match matches the first element on the frontier against the next text token. backtrack undoes the most recent expand or match operation. step performs a single expand, match, or backtrack operation. parses returns the set of parses that have been found by the parser.""",
"""_history – A list of (rtext, tree, frontier) tripples, containing the previous states of the parser. This history is used to implement the backtrack operation.""",
_tried_e – A record of all productions that have been tried for a given tree. This record is used by expand to perform the next untried production.,
_tried_m – A record of what tokens have been matched for a given tree. This record is used by step to decide whether or not to match a token.,
nltk.grammar,
"""Return the parser to its state before the most recent match or expand operation. Calling undo repeatedly return the parser to successively earlier states. If no match or expand operations have been performed, undo will make no changes.""",
true if an operation was successfully undone.,
bool,
Whether the parser’s current state represents a complete parse.,
bool,
"""Expand the first element of the frontier. In particular, if the first element of the frontier is a subtree whose node type is equal to production’s left hand side, then add a child to that subtree for each element of production’s right hand side. If production is not specified, then use the first untried expandable production. If all expandable productions have been tried, do nothing.""",
"""The production used to expand the frontier, if an expansion was performed. If no expansion was performed, return None.""",
Production or None,
A list of all the productions for which expansions are available for the current parser state.,
list(Production),
"""A list of the tree locations of all subtrees that have not yet been expanded, and all leaves that have not yet been matched.""",
list(tuple(int)),
"""Start parsing a given text. This sets the parser’s tree to the start symbol, its frontier to the root node, and its remaining text to token['SUBTOKENS'].""",
"""Match the first element of the frontier. In particular, if the first element of the frontier has the same type as the next text token, then substitute the text token into the tree.""",
"""The token matched, if a match operation was performed. If no match was performed, return None""",
str or None,
An iterator that generates parse trees for the sentence.,
When possible this list is sorted from most likely to least likely.,
sent (list(str)) – The sentence to be parsed,
iter(Tree),
An iterator of the parses that have been found by this parser so far.,
list of Tree,
The portion of the text that is not yet covered by the tree.,
list(str),
Change the grammar used to parse texts.,
grammar (CFG) – The new grammar.,
"""Perform a single parsing operation. If an untried match is possible, then perform the match, and return the matched token. If an untried expansion is possible, then perform the expansion, and return the production that it is based on. If backtracking is possible, then backtrack, and return True. Otherwise, return None.""","Perform match, Return matched token, Perform expansion, Return production"
None if no operation was performed; a token if a match was performed; a production if an expansion was performed; and True if a backtrack operation was performed.,
Production or String or bool,
A partial structure for the text that is currently being parsed. The elements specified by the frontier have not yet been expanded or matched.,
Tree,
A list of all the untried productions for which expansions are available for the current parser state.,
list(Production),
Whether the first element of the frontier is a token that has not yet been matched.,
bool,
A demonstration of the recursive descent parser.,
Bases: nltk.parse.api.ParserI,
"""A simple bottom-up CFG parser that uses two operations, “shift” and “reduce”, to find a single parse for a text.""",
"""ShiftReduceParser maintains a stack, which records the structure of a portion of the text. This stack is a list of strings and Trees that collectively cover a portion of the text. For example, while parsing the sentence “the dog saw the man” with a typical grammar, ShiftReduceParser will produce the following stack, which covers “the dog saw”:""",
"""ShiftReduceParser attempts to extend the stack to cover the entire text, and to combine the stack elements into a single tree, producing a complete parse for the sentence.""",
"""Initially, the stack is empty. It is extended to cover the text, from left to right, by repeatedly applying two operations:""",
“shift” moves a token from the beginning of the text to the end of the stack.,
“reduce” uses a CFG production to combine the rightmost stack elements into a single Tree.,
"""Often, more than one operation can be performed on a given stack. In this case, ShiftReduceParser uses the following heuristics to decide which operation to perform:""",
Only shift if no reductions are available.,
"""If multiple reductions are available, then apply the reduction whose CFG production is listed earliest in the grammar.""",
"""Note that these heuristics are not guaranteed to choose an operation that leads to a parse of the text. Also, if multiple parses exists, ShiftReduceParser will return at most one of them.""",
nltk.grammar,
The grammar used by this parser.,
An iterator that generates parse trees for the sentence.,
When possible this list is sorted from most likely to least likely.,
sent (list(str)) – The sentence to be parsed,
iter(Tree),
Set the level of tracing output that should be generated when parsing a text.,Set tracing level
trace (int) – The trace level. A trace level of 0 will generate no tracing output; and higher trace levels will produce more verbose tracing output.,
None,
Bases: nltk.parse.shiftreduce.ShiftReduceParser,
"""A ShiftReduceParser that allows you to setp through the parsing process, performing a single operation at a time. It also allows you to change the parser’s grammar midway through parsing a text.""",
"""The initialize method is used to start parsing a text. shift performs a single shift operation, and reduce performs a single reduce operation. step will perform a single reduce operation if possible; otherwise, it will perform a single shift operation. parses returns the set of parses that have been found by the parser.""",
"""_history – A list of (stack, remaining_text) pairs, containing all of the previous states of the parser. This history is used to implement the undo operation.""",
nltk.grammar,
Start parsing a given text. This sets the parser’s stack to [] and sets its remaining text to tokens.,
An iterator that generates parse trees for the sentence.,
When possible this list is sorted from most likely to least likely.,
sent (list(str)) – The sentence to be parsed,
iter(Tree),
An iterator of the parses that have been found by this parser so far.,
iter(Tree),
"""Use production to combine the rightmost stack elements into a single Tree. If production does not match the rightmost stack elements, then do nothing.""",
"""The production used to reduce the stack, if a reduction was performed. If no reduction was performed, return None.""",
Production or None,
A list of the productions for which reductions are available for the current parser state.,
list(Production),
The portion of the text that is not yet covered by the stack.,
list(str),
Change the grammar used to parse texts.,
grammar (CFG) – The new grammar.,
"""Move a token from the beginning of the remaining text to the end of the stack. If there are no more tokens in the remaining text, then do nothing.""",Move token
True if the shift operation was successful.,
bool,
The parser’s stack.,
list(str and Tree),
"""Perform a single parsing operation. If a reduction is possible, then perform that reduction, and return the production that it is based on. Otherwise, if a shift is possible, then perform it, and return True. Otherwise, return False.""","Perform reduction, Return production"
False if no operation was performed; True if a shift was performed; and the CFG production used to reduce if a reduction was performed.,
Production or bool,
"""Return the parser to its state before the most recent shift or reduce operation. Calling undo repeatedly return the parser to successively earlier states. If no shift or reduce operations have been performed, undo will make no changes.""",Return parser
true if an operation was successfully undone.,
bool,
A demonstration of the shift-reduce parser.,
Bases: nltk.parse.api.ParserI,
Interface to the Stanford Parser,
"""Use StanfordParser to parse multiple sentences. Takes multiple sentences as a list where each sentence is a list of words. Each sentence will be automatically tagged with this StanfordParser instance’s tagger. If whitespaces exists inside a token, then the token will be treated as separate tokens.""",Use StanfordParser
sentences (list(list(str))) – Input sentences to parse,
iter(iter(Tree)),
"""Use StanfordParser to parse a sentence. Takes a sentence as a string; before parsing, it will be automatically tokenized and tagged by the Stanford Parser.""",Use StanfordParser
sentence (str) – Input sentence to parse,
iter(Tree),
Use StanfordParser to parse multiple sentences. Takes multiple sentences as a list of strings. Each sentence will be automatically tokenized and tagged by the Stanford Parser.,Use StanfordParser
sentences (list(str)) – Input sentences to parse,
iter(iter(Tree)),
"""Use StanfordParser to parse a sentence. Takes a sentence as a list of (word, tag) tuples; the sentence must have already been tokenized and tagged.""",Use StanfordParser
"""sentence (list(tuple(str, str))) – Input sentence to parse""",
iter(Tree),
"""Use StanfordParser to parse multiple sentences. Takes multiple sentences where each sentence is a list of (word, tag) tuples. The sentences must have already been tokenized and tagged.""",Use StanfordParser
"""sentences (list(list(tuple(str, str)))) – Input sentences to parse""",
iter(iter(Tree)),
Bases: nltk.parse.stanford.GenericStanfordParser,
Bases: nltk.parse.stanford.GenericStanfordParser,
Currently unimplemented because the neural dependency parser (and the StanfordCoreNLP pipeline class) doesn’t support passing in pre- tagged tokens.,
Bases: nltk.parse.stanford.GenericStanfordParser,
Bases: object,
Class for holding configuration which is the partial analysis of the input sentence. The transition based parser aims at finding set of operators that transfer the initial configuration to the terminal configuration.,
Stack: for storing partially proceeded words,
Buffer: for storing remaining input words,
Set of arcs: for storing partially built dependency tree,
This class also provides a method to represent a configuration as list of features.,
"""Extract the set of features for the current configuration. Implement standard features as describe in Table 3.2 (page 31) in Dependency Parsing book by Sandra Kubler, Ryan McDonal, Joakim Nivre. Please note that these features are very basic. :return: list(str)""","Extract features, Implement features"
Bases: object,
"""This class defines a set of transition which is applied to a configuration to get another configuration Note that for different parsing algorithm, the transition is different.""",
is the current configuration,
:return : A new configuration or -1 if the pre-condition is not satisfied,
is the current configuration,
:return : A new configuration or -1 if the pre-condition is not satisfied,
is the current configuration,
:return : A new configuration or -1 if the pre-condition is not satisfied,
is the current configuration,
:return : A new configuration or -1 if the pre-condition is not satisfied,
Bases: nltk.parse.api.ParserI,
Class for transition based parser. Implement 2 algorithms which are “arc-standard” and “arc-eager”,
"""depgraphs (list(DependencyGraph)) – the list of test sentence, each sentence is represented as a dependency graph where the ‘head’ information is dummy""",
modelfile (str) – the model file,
list (DependencyGraph) with the ‘head’ and ‘rel’ information,
:param depgraphs : list of DependencyGraph as the training data :type depgraphs : DependencyGraph :param modelfile : file name to save the trained model :type modelfile : str,
###################### Check the Initial Feature ########################,
"""###################### Check The Transition ####################### Check the Initialized Configuration >>> print(conf) Stack : [0] Buffer : [1, 2, 3, 4, 5, 6, 7, 8, 9] Arcs : []""",
Do some transition checks for ARC-STANDARD,
"""Middle Configuration and Features Check >>> print(conf) Stack : [0, 3, 5, 6] Buffer : [8, 9] Arcs : [(2, ‘ATT’, 1), (3, ‘SBJ’, 2), (5, ‘ATT’, 4), (8, ‘ATT’, 7)]""",
"""Terminated Configuration Check >>> print(conf) Stack : [0] Buffer : [] Arcs : [(2, ‘ATT’, 1), (3, ‘SBJ’, 2), (5, ‘ATT’, 4), (8, ‘ATT’, 7), (6, ‘PC’, 8), (5, ‘ATT’, 6), (3, ‘OBJ’, 5), (3, ‘PU’, 9), (0, ‘ROOT’, 3)]""",
Do some transition checks for ARC-EAGER,
###################### Check The Training Function #######################,
"""A. Check the ARC-STANDARD training >>> import tempfile >>> import os >>> input_file = tempfile.NamedTemporaryFile(prefix=’transition_parse.train’, dir=tempfile.gettempdir(), delete=False)""",
Check the ARC-EAGER training,
###################### Check The Parsing Function ########################,
Check the ARC-STANDARD parser,
"""B. Check the ARC-EAGER parser >>> result = parser_eager.parse([gold_sent], ‘temp.arceager.model’) >>> de = DependencyEvaluator(result, [gold_sent]) >>> de.eval() >= (0, 0) True""",
Remove test temporary files >>> remove(‘temp.arceager.model’) >>> remove(‘temp.arcstd.model’),Remove test files
Note that result is very poor because of only one training example.,
Utility functions for parsers.,
Bases: object,
Unit tests for CFG.,
grammatical (accept) and,
ungrammatical (reject).,
"""If a sentence should parse accordng to the grammar, the value of trees will be a non-empty list. If a sentence should be rejected according to the grammar, then the value of trees will be None.""",
Parses a string with one test sentence per line. Lines can optionally begin with:,
"""a bool, saying if the sentence is grammatical or not, or""",
"""an int, giving the number of parse trees is should have,""",
"""The result information is followed by a colon, and then the sentence. Empty lines and lines beginning with a comment char are ignored.""",
"""a list of tuple of sentences and expected results, where a sentence is a list of str, and a result is None, or bool, or int""",
comment_chars – str of possible comment characters.,
"""encoding – the encoding of the string, if it is binary""",
"""Load a grammar from a file, and build a parser based on that grammar. The parser depends on the grammar format, and might also depend on properties of the grammar itself.""",Build parser
cfg' (CFGs: CFG),
pcfg' (probabilistic CFGs: PCFG),
fcfg' (feature-based CFGs: FeatureGrammar),
"""grammar_url (str) – A URL specifying where the grammar is located. The default protocol is """"nltk:"""", which searches for the file in the the NLTK data package.""",
trace (int) – The level of tracing that should be used when parsing a text. 0 will generate no tracing output; and higher numbers will produce more verbose tracing output.,
"""parser – The class used for parsing; should be ChartParser or a subclass. If None, the class depends on the grammar format.""",
"""chart_class – The class used for storing the chart; should be Chart or a subclass. Only used for CFGs and feature CFGs. If None, the chart class depends on the grammar format.""",
beam_size (int) – The maximum length for the parser’s edge queue. Only used for probabilistic CFGs.,
load_args – Keyword parameters used when loading the grammar. See data.load for more information.,
A module to convert a single POS tagged sentence into CONLL format.,
"""sentence (list(tuple(str, str))) – A single input sentence to parse""",
iter(str),
a generator yielding a single sentence in CONLL format.,
"""A module to convert the a POS tagged document stream (i.e. list of list of tuples, a list of sentences) and yield lines in CONLL format. This module yields one line per word and two newlines for end of sentence.""",
sentences – Input sentences to parse,
iter(str),
a generator yielding sentences in CONLL format.,
Bases: nltk.parse.api.ParserI,
"""A bottom-up PCFG parser that uses dynamic programming to find the single most likely parse for a text. The ViterbiParser parser parses texts by filling in a “most likely constituent table”. This table records the most probable tree representation for any given span and node value. In particular, it has an entry for every start index, end index, and node value, recording the most likely subtree that spans from the start index to the end index, and has the given node value.""",
"""The ViterbiParser parser fills in this table incrementally. It starts by filling in all entries for constituents that span one element of text (i.e., entries where the end index is one greater than the start index). After it has filled in all table entries for constituents that span one element of text, it fills in the entries for constitutants that span two elements of text. It continues filling in the entries for constituents spanning larger and larger portions of the text, until the entire table has been filled. Finally, it returns the table entry for a constituent spanning the entire text, whose node value is the grammar’s start symbol.""",
"""In order to find the most likely constituent with a given span and node value, the ViterbiParser parser considers all productions that could produce that node value. For each production, it finds all children that collectively cover the span and have the node values specified by the production’s right hand side. If the probability of the tree formed by applying the production to the children is greater than the probability of the current entry in the table, then the table is updated with this new tree.""",
A pseudo-code description of the algorithm used by ViterbiParser is:,
_grammar – The grammar used to parse sentences.,
_trace – The level of tracing output that should be generated when parsing a text.,
The grammar used by this parser.,
An iterator that generates parse trees for the sentence.,
When possible this list is sorted from most likely to least likely.,
sent (list(str)) – The sentence to be parsed,
iter(Tree),
Set the level of tracing output that should be generated when parsing a text.,Set tracing level
trace (int) – The trace level. A trace level of 0 will generate no tracing output; and higher trace levels will produce more verbose tracing output.,
None,
"""A demonstration of the probabilistic parsers. The user is prompted to select which demo to run, and how many parses should be found; and then each parser is run on the same demo, and a summary of the results are displayed.""",
NLTK Parsers,
"""Classes and interfaces for producing tree structures that represent the internal organization of a text. This task is known as “parsing” the text, and the resulting tree structures are called the text’s “parses”. Typically, the text is a single sentence, and the tree structure represents the syntactic structure of the sentence. However, parsers can also be used in other domains. For example, parsers can be used to derive the morphological structure of the morphemes that make up a word, or to derive the discourse structure for a set of utterances.""",
"""Sometimes, a single piece of text can be represented by more than one tree structure. Texts represented by more than one tree structure are called “ambiguous” texts. Note that there are actually two ways in which a text can be ambiguous:""",
The text has multiple correct parses.,
There is not enough information to decide which of several candidate parses is correct.,
"""However, the parser module does not distinguish these two types of ambiguity.""",
"""The parser module defines ParserI, a standard interface for parsing texts; and two simple implementations of that interface, ShiftReduceParser and RecursiveDescentParser. It also contains three sub-modules for specialized kinds of parsing:""",
"""nltk.parser.chart defines chart parsing, which uses dynamic programming to efficiently parse texts.""",
"""nltk.parser.probabilistic defines probabilistic parsing, which associates a probability with each parse.""",
