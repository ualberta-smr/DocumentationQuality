<!DOCTYPE html>
<html lang="en-US"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=Edge"><title>Command Line Usage - CoreNLP</title><meta name="keywords" content=" cmdline, command line"><link rel="shortcut icon" href="https://stanfordnlp.github.io/CoreNLP/favicon.ico" type="image/x-icon"><link rel="stylesheet" href="corenlp-clu_files/font-awesome.css"><link rel="stylesheet" href="corenlp-clu_files/all.css" integrity="sha384-UHRtZLI+pbxtHCWp1t77Bi1L4ZtiqrqD80Kn4Z8NTSRyMA2Fd33n5dQ8lWUE00s/" crossorigin="anonymous"><link rel="stylesheet" href="corenlp-clu_files/just-the-docs.css"> <script type="text/javascript" async="" src="corenlp-clu_files/analytics.js"></script><script async="" src="corenlp-clu_files/js.js"></script> <script> window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', "UA-133356038-1"); </script> <script type="text/javascript" src="corenlp-clu_files/lunr.js"></script> <script type="text/javascript" src="corenlp-clu_files/just-the-docs.js"></script><meta name="viewport" content="width=device-width, initial-scale=1"><title>Command Line Usage | CoreNLP</title><meta name="generator" content="Jekyll v3.9.0"><meta property="og:title" content="Command Line Usage"><meta property="og:locale" content="en_US"><meta name="description" content="NLP Processing In Java"><meta property="og:description" content="NLP Processing In Java"><link rel="canonical" href="https://stanfordnlp.github.io/CoreNLP/cmdline.html"><meta property="og:url" content="https://stanfordnlp.github.io/CoreNLP/cmdline.html"><meta property="og:site_name" content="CoreNLP"><meta name="twitter:card" content="summary"><meta property="twitter:title" content="Command Line Usage"> <script type="application/ld+json"> {"description":"NLP Processing In Java","url":"https://stanfordnlp.github.io/CoreNLP/cmdline.html","@type":"WebPage","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"https://stanfordnlp.github.io/CoreNLP/assets/images/corenlp-logo.png"}},"headline":"Command Line Usage","@context":"https://schema.org"}</script><meta name="twitter:card" content="summary_large_image"><meta name="twitter:site" content="@stanfordnlp"><meta name="twitter:creator" content="@stanfordnlp"><meta name="twitter:title" content="CoreNLP"><meta name="twitter:description" content="High-performance human language analysis tools, now with native deep learning modules in Python, available in many human languages."><meta name="twitter:image" content="https://stanfordnlp.github.io/CoreNLP/assets/images/corenlp-logo.png"><meta name="google-site-verification" content="h3zCtOJy9KzG1XWf5-3ppU1liaJ8NkpGvK_BbOOq3-4"></head><body> <svg xmlns="http://www.w3.org/2000/svg" style="display: none;"> <symbol id="link" viewBox="0 0 16 16"><title>Link</title><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path> </symbol> </svg><div class="page-wrap"><div class="side-bar"><div class="site-header"> <a href="https://stanfordnlp.github.io/CoreNLP" class="site-title lh-tight"><div class="site-logo"></div></a> <button class="menu-button fs-3 js-main-nav-trigger" data-text-toggle="Hide" type="button">Menu</button></div><div class="navigation main-nav js-main-nav"><nav role="navigation" aria-label="Main navigation"><ul class="navigation-list"><li class="navigation-list-item"><a href="https://stanfordnlp.github.io/CoreNLP/index.html" class="navigation-list-link">Overview</a></li><li class="navigation-list-item active"><a href="https://stanfordnlp.github.io/CoreNLP/usage.html" class="navigation-list-link">Usage</a><ul class="navigation-list-child-list "><li class="navigation-list-item "><a href="https://stanfordnlp.github.io/CoreNLP/download.html" class="navigation-list-link">Download</a></li><li class="navigation-list-item "><a href="https://stanfordnlp.github.io/CoreNLP/migration.html" class="navigation-list-link">Migration</a></li><li class="navigation-list-item active"><a href="https://stanfordnlp.github.io/CoreNLP/cmdline.html" class="navigation-list-link active">Command Line Usage</a></li><li class="navigation-list-item "><a href="https://stanfordnlp.github.io/CoreNLP/api.html" class="navigation-list-link">CoreNLP API</a></li><li class="navigation-list-item "><a href="https://stanfordnlp.github.io/CoreNLP/simple.html" class="navigation-list-link">Simple API</a></li><li class="navigation-list-item "><a href="https://stanfordnlp.github.io/CoreNLP/repl.html" class="navigation-list-link">Interactive mode (REPL)</a></li><li class="navigation-list-item "><a href="https://stanfordnlp.github.io/CoreNLP/corenlp-server.html" class="navigation-list-link">CoreNLP Server</a></li><li class="navigation-list-item "><a href="https://stanfordnlp.github.io/CoreNLP/caseless.html" class="navigation-list-link">Caseless models</a></li><li class="navigation-list-item "><a href="https://stanfordnlp.github.io/CoreNLP/human-languages.html" class="navigation-list-link">Using CoreNLP on other human languages</a></li><li class="navigation-list-item "><a href="https://stanfordnlp.github.io/CoreNLP/other-languages.html" class="navigation-list-link">Using CoreNLP within other programming languages and packages</a></li></ul></li><li class="navigation-list-item"><a href="https://stanfordnlp.github.io/CoreNLP/demo.html" class="navigation-list-link">Demo</a></li><li class="navigation-list-item"><a href="https://stanfordnlp.github.io/CoreNLP/pipeline.html" class="navigation-list-link">Pipeline</a><ul class="navigation-list-child-list "><li class="navigation-list-item "><a href="https://stanfordnlp.github.io/CoreNLP/annotators.html" class="navigation-list-link">Full List Of Annotators</a></li><li class="navigation-list-item "><a href="https://stanfordnlp.github.io/CoreNLP/new_annotator.html" class="navigation-list-link">Custom Annotators</a></li><li class="navigation-list-item "><a href="https://stanfordnlp.github.io/CoreNLP/tokenize.html" class="navigation-list-link">Tokenization</a></li><li class="navigation-list-item "><a href="https://stanfordnlp.github.io/CoreNLP/cleanxml.html" class="navigation-list-link">CleanXML</a></li><li class="navigation-list-item "><a href="https://stanfordnlp.github.io/CoreNLP/ssplit.html" class="navigation-list-link">Sentence Splitting</a></li><li class="navigation-list-item "><a href="https://stanfordnlp.github.io/CoreNLP/mwt.html" class="navigation-list-link">Multi Word Token Expansion</a></li><li class="navigation-list-item "><a href="https://stanfordnlp.github.io/CoreNLP/pos.html" class="navigation-list-link">Parts Of Speech</a></li><li class="navigation-list-item "><a href="https://stanfordnlp.github.io/CoreNLP/lemma.html" class="navigation-list-link">Lemmatization</a></li><li class="navigation-list-item "><a href="https://stanfordnlp.github.io/CoreNLP/ner.html" class="navigation-list-link">Named Entity Recognition</a></li><li class="navigation-list-item "><a href="https://stanfordnlp.github.io/CoreNLP/depparse.html" class="navigation-list-link">Dependency Parsing</a></li><li class="navigation-list-item "><a href="https://stanfordnlp.github.io/CoreNLP/parse.html" class="navigation-list-link">Constituency Parsing</a></li><li class="navigation-list-item "><a href="https://stanfordnlp.github.io/CoreNLP/coref.html" class="navigation-list-link">Coreference Resolution</a></li><li class="navigation-list-item "><a href="https://stanfordnlp.github.io/CoreNLP/openie.html" class="navigation-list-link">OpenIE</a></li><li class="navigation-list-item "><a href="https://stanfordnlp.github.io/CoreNLP/kbp.html" class="navigation-list-link">KBP</a></li><li class="navigation-list-item "><a href="https://stanfordnlp.github.io/CoreNLP/entitylink.html" class="navigation-list-link">Entity Linking</a></li><li class="navigation-list-item "><a href="https://stanfordnlp.github.io/CoreNLP/quote.html" class="navigation-list-link">Quote Extraction And Attribution</a></li><li class="navigation-list-item "><a href="https://stanfordnlp.github.io/CoreNLP/sentiment.html" class="navigation-list-link">Sentiment</a></li></ul></li><li class="navigation-list-item"><a href="https://stanfordnlp.github.io/CoreNLP/additional.html" class="navigation-list-link">Additional Tools</a><ul class="navigation-list-child-list "><li class="navigation-list-item "><a href="https://stanfordnlp.github.io/CoreNLP/patterns.html" class="navigation-list-link">Bootstrapped surface patterns</a></li><li class="navigation-list-item "><a href="https://stanfordnlp.github.io/CoreNLP/extensions.html" class="navigation-list-link">Extensions and Packages and Models by others extending CoreNLP</a></li><li class="navigation-list-item "><a href="https://stanfordnlp.github.io/CoreNLP/sutime.html" class="navigation-list-link">SUTime</a></li><li class="navigation-list-item "><a href="https://stanfordnlp.github.io/CoreNLP/tokensregex.html" class="navigation-list-link">TokensRegex</a></li></ul></li><li class="navigation-list-item"><a href="https://stanfordnlp.github.io/CoreNLP/resources.html" class="navigation-list-link">Resources</a><ul class="navigation-list-child-list "><li class="navigation-list-item "><a href="https://stanfordnlp.github.io/CoreNLP/model-zoo.html" class="navigation-list-link">Model Zoo</a></li><li class="navigation-list-item "><a href="https://stanfordnlp.github.io/CoreNLP/faq.html" class="navigation-list-link">FAQ</a></li><li class="navigation-list-item "><a href="https://stanfordnlp.github.io/CoreNLP/tutorials.html" class="navigation-list-link">Tutorials</a></li><li class="navigation-list-item "><a href="https://stanfordnlp.github.io/CoreNLP/memory-time.html" class="navigation-list-link">Understanding memory and time usage</a></li><li class="navigation-list-item "><a href="https://stanfordnlp.github.io/CoreNLP/pipelines.html" class="navigation-list-link">CoreNLP Pipelines</a></li><li class="navigation-list-item "><a href="https://stanfordnlp.github.io/CoreNLP/history.html" class="navigation-list-link">Release History</a></li><li class="navigation-list-item "><a href="https://stanfordnlp.github.io/CoreNLP/contact.html" class="navigation-list-link">Contact</a></li></ul></li><li class="navigation-list-item"><a href="https://stanfordnlp.github.io/CoreNLP/standalone.html" class="navigation-list-link">Standalone Distributions</a><ul class="navigation-list-child-list "><li class="navigation-list-item "><a href="https://stanfordnlp.github.io/CoreNLP/parser-standalone.html" class="navigation-list-link">Parser</a></li></ul></li></ul></nav></div><footer class="site-footer"><ul><li><a href="https://github.com/stanfordnlp/CoreNLP"><i class="fab fa-github"></i></a></li><li><a href="https://twitter.com/stanfordnlp"><i class="fab fa-twitter"></i></a></li></ul><p class="text-small text-grey-dk-000 mb-4">CoreNLP is created by the <a href="https://nlp.stanford.edu/">Stanford NLP Group</a>. This site uses the Jekyll theme <a href="https://github.com/pmarsceill/just-the-docs">Just the Docs</a>.</p></footer></div><div class="main-content-wrap js-main-content" tabindex="0"><div class="main-content"><div class="page-header js-page-header"><div class="search"><div class="search-input-wrap"> <input type="text" class="js-search-input search-input" tabindex="0" placeholder="Search CoreNLP" aria-label="Search CoreNLP" autocomplete="off"> <svg width="14" height="14" viewBox="0 0 28 28" xmlns="http://www.w3.org/2000/svg" class="search-icon"><title>Search</title><g fill-rule="nonzero"><path d="M17.332 20.735c-5.537 0-10-4.6-10-10.247 0-5.646 4.463-10.247 10-10.247 5.536 0 10 4.601 10 10.247s-4.464 10.247-10 10.247zm0-4c3.3 0 6-2.783 6-6.247 0-3.463-2.7-6.247-6-6.247s-6 2.784-6 6.247c0 3.464 2.7 6.247 6 6.247z"></path><path d="M11.672 13.791L.192 25.271 3.02 28.1 14.5 16.62z"></path></g></svg></div><div class="js-search-results search-results-wrap"></div></div></div><div class="page"><nav class="breadcrumb-nav"><ol class="breadcrumb-nav-list"><li class="breadcrumb-nav-list-item"><a href="https://stanfordnlp.github.io/CoreNLP/usage.html">Usage</a></li><li class="breadcrumb-nav-list-item"><span>Command Line Usage</span></li></ol></nav><div id="main-content" class="page-content" role="main"><h1> Command Line Usage</h1><h2 class="text-delta"> Table of contents</h2><div class="toc"><ul><li><a href="#quick-start">Quick start</a><ul><li><a href="#notes">Notes</a></li></ul></li><li><a href="#classpath">Classpath</a></li><li><a href="#configuring-corenlp-properties">Configuring CoreNLP: Properties</a></li><li><a href="#languages-other-than-english">Languages other than English</a></li><li><a href="#input">Input</a><ul><li><a href="#using-corenlp-as-a-filter-in-a-pipe">Using CoreNLP as a filter in a pipe</a></li><li><a href="#common-input-options">Common input options</a></li><li><a href="#inputting-serialized-files">Inputting serialized files</a></li></ul></li><li><a href="#output">Output</a><ul><li><a href="#output-options">Output options</a></li><li><a href="#output-serializer">Output serializer</a></li><li><a href="#a-note-on-numbering">A note on numbering</a></li></ul></li><li><a href="#character-encoding">Character encoding</a></li></ul></div><hr><h2 id="quick-start"> <a href="#quick-start" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#link"></use></svg></a> Quick start</h2><p>Note:
 Stanford CoreNLP v.3.5+ requires Java 8, but works with Java 9/10/11 as
 well. If using Java 9/10/11, you need to add this Java flag to avoid 
errors (a CoreNLP library dependency uses the JAXB module that was 
deleted from the default libraries for Java 9+):</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>--add-modules java.se.ee
</code></pre></div></div><p>The minimal command to run Stanford CoreNLP from the command line is:</p><div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>java <span class="nt">-cp</span> <span class="s2">"*"</span> edu.stanford.nlp.pipeline.StanfordCoreNLP <span class="nt">-file</span> input.txt
</code></pre></div></div><p>If this command is run from the distribution directory, it processes the included <a href="https://stanfordnlp.github.io/CoreNLP/files/input.txt">sample file</a> <code class="language-plaintext highlighter-rouge">input.txt</code>. We use a wildcard <code class="language-plaintext highlighter-rouge">"*"</code> after <code class="language-plaintext highlighter-rouge">-cp</code> to load all jar files in the current directory – it needs to be in quotes. This command writes the output to an XML <a href="https://stanfordnlp.github.io/CoreNLP/files/input.txt.xml.txt">file</a> named <code class="language-plaintext highlighter-rouge">input.txt.xml</code> in the same directory.</p><h3 id="notes"> <a href="#notes" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#link"></use></svg></a> Notes</h3><ul><li>Processing
 a short text like this is very inefficient. It takes a minute to load 
everything before processing begins. You should batch your processing.</li><li>Current releases of Stanford CoreNLP require Java version 8 or higher.</li><li>Specifying memory: adding, e.g., <code class="language-plaintext highlighter-rouge">-Xmx2g</code> before the <code class="language-plaintext highlighter-rouge">-cp</code>
 flag specifies the amount of RAM that Java will make available for 
CoreNLP. On a 64-bit machine, Stanford CoreNLP typically requires 2GB to
 run (and it may need up to 6GB, depending on the annotators used and 
the size of the document to parse). On a 32 bit machine (in 2016, this 
is most commonly a 32-bit Windows machine), you cannot allocate 2GB of 
RAM; probably you should try with <code class="language-plaintext highlighter-rouge">-Xmx1800m</code> or maybe with just <code class="language-plaintext highlighter-rouge">-Xmx1500m</code>, but this amount of memory is a bit marginal. You probably can’t run some annotators, such as the statistical <code class="language-plaintext highlighter-rouge">coref</code>.
 Providing your machine has lots of memory, in most cases Java will now 
start with a large memory allocation and you shouldn’t need to specify 
this flag manually.</li><li>Stanford CoreNLP includes an interactive 
shell for analyzing sentences. If you do not specify any properties that
 load input files, you will be placed in the interactive shell. Type <code class="language-plaintext highlighter-rouge">q</code> to exit.</li></ul><h2 id="classpath"> <a href="#classpath" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#link"></use></svg></a> Classpath</h2><p>Your
 command line has to load the code, libraries, and model jars that 
CoreNLP uses. These are all contained in JAR files (compressed archives 
with extension “.jar”) which come in the CoreNLP download or which can 
be downloaded on demand from Maven Central. The easiest way to make them
 available is with a command line like this, where <code class="language-plaintext highlighter-rouge">/Users/me/corenlp/</code> should be changed to the path where you put CoreNLP:</p><div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>java <span class="nt">-cp</span> <span class="s2">"/Users/me/corenlp/*"</span> edu.stanford.nlp.pipeline.StanfordCoreNLP <span class="nt">-file</span> inputFile
</code></pre></div></div><p>Alternatively, you can [add this path to 
your CLASSPATH environment 
variable](https://en.wikipedia.org/wiki/Classpath_(Java%29), so these 
libraries are always available.</p><p>The “*” (which must be enclosed in
 quotes) says to add all JAR files in the given directory to the 
classpath. You can also individually specify the needed jar files. Use 
the following sort of command line, adjusting the JAR file date 
extensions <code class="language-plaintext highlighter-rouge">VV</code> to your downloaded release.</p><div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>java <span class="nt">-cp</span> stanford-corenlp-VV.jar:stanford-corenlp-VV-models.jar:xom.jar:joda-time.jar:jollyday.jar:ejml-VV.jar <span class="nt">-Xmx2g</span> edu.stanford.nlp.pipeline.StanfordCoreNLP <span class="nt">-file</span> inputFile
</code></pre></div></div><p>The command above works for Mac OS X or 
Linux. For Windows, the colons (:) separating the jar files need to be 
semi-colons (;). If you are not sitting in the distribution directory, 
you’ll also need to include a path to the files before each.</p><h2 id="configuring-corenlp-properties"> <a href="#configuring-corenlp-properties" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#link"></use></svg></a> Configuring CoreNLP: Properties</h2><p>Before
 using Stanford CoreNLP, it is usual to create a configuration file (a 
Java Properties file). Minimally, this file should contain the 
“annotators” property, which contains a comma-separated list of 
Annotators to use. For example, the setting below enables: tokenization,
 sentence splitting (required by most Annotators), POS tagging, 
lemmatization, NER, (constituency) parsing, and (rule-based) coreference
 resolution.</p><blockquote><p>annotators = tokenize, ssplit, pos, lemma, ner, parse, dcoref</p></blockquote><p>To use the properties in the properties file <a href="https://stanfordnlp.github.io/CoreNLP/files/sampleProps.properties">sampleProps.properties</a>, you give a command as follows:</p><div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>java <span class="nt">-cp</span> <span class="s2">"*"</span> <span class="nt">-Xmx2g</span> edu.stanford.nlp.pipeline.StanfordCoreNLP <span class="nt">-props</span> sampleProps.properties
</code></pre></div></div><p>This results in the output file <a href="https://stanfordnlp.github.io/CoreNLP/files/input.txt.output">input.txt.output</a> given the same input file <code class="language-plaintext highlighter-rouge">input.txt</code>.</p><p>However,
 if you just want to specify a few properties, you can instead place 
them on the command line. For example, we can specify annotators and the
 output format with:</p><div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>java <span class="nt">-cp</span> <span class="s2">"*"</span> edu.stanford.nlp.pipeline.StanfordCoreNLP <span class="nt">-annotators</span> tokenize,ssplit <span class="nt">-file</span> input.txt <span class="nt">-outputFormat</span> conll <span class="nt">-output</span>.columns word
</code></pre></div></div><p>The <code class="language-plaintext highlighter-rouge">-props</code>
 parameter is optional. By default, Stanford CoreNLP will search for 
StanfordCoreNLP.properties in your classpath and use the defaults 
included in the distribution.</p><p>The <code class="language-plaintext highlighter-rouge">-annotators</code>
 argument is also optional. If you leave it out, the code uses a built 
in properties file, which enables the following annotators: tokenization
 and sentence splitting, POS tagging, lemmatization, NER, dependency 
parsing, and statistical coreference resolution: <code class="language-plaintext highlighter-rouge">annotators = tokenize, ssplit, pos, lemma, ner, depparse, coref</code>.</p><p>If you have a lot of text but all you want to do is to, say, get part-of-speech (POS) tags, then you should <strong>definitely</strong>
 specify an annotators list, as above, since you can then omit later 
annotators which invoke much more expensive processing that you don’t 
need. For example, you might give the command:</p><div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>java <span class="nt">-cp</span> <span class="s2">"*"</span> <span class="nt">-Xmx500m</span> edu.stanford.nlp.pipeline.StanfordCoreNLP <span class="nt">-annotators</span> tokenize,ssplit,pos <span class="nt">-file</span> wikipedia.txt <span class="nt">-outputFormat</span> conll
</code></pre></div></div><p>We provide a small shell script <code class="language-plaintext highlighter-rouge">corenlp.sh</code>.
 On Linux or OS X, this may be useful in allowing you to type shorter 
command lines to invoke CoreNLP. For example, you can instead say:</p><div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>./corenlp.sh <span class="nt">-annotators</span> tokenize,ssplit,pos <span class="nt">-file</span> wikipedia.txt <span class="nt">-outputFormat</span> conll
</code></pre></div></div><h2 id="languages-other-than-english"> <a href="#languages-other-than-english" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#link"></use></svg></a> Languages other than English</h2><p>You
 first have to have available a models jar file for the language you 
wish to use. You can download it from this site or you can use the 
models file on <a href="http://search.maven.org/#search%7Cga%7C1%7Ca%3A%22stanford-corenlp%22">Maven Central</a>. If using Maven, you add it to your pom file like this:</p><div class="language-xml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;dependency&gt;</span>
    <span class="nt">&lt;groupId&gt;</span>edu.stanford.nlp<span class="nt">&lt;/groupId&gt;</span>
    <span class="nt">&lt;artifactId&gt;</span>stanford-corenlp<span class="nt">&lt;/artifactId&gt;</span>
    <span class="nt">&lt;version&gt;</span>3.9.1<span class="nt">&lt;/version&gt;</span>
    <span class="nt">&lt;classifier&gt;</span>models-chinese<span class="nt">&lt;/classifier&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
</code></pre></div></div><p>Our examples assume that you are in the root
 directory of CoreNLP and that these extra jar files are also available 
there. Each language jar contains a default properties file for the 
appropriate language. Working with text in another language is then as 
easy as specifying this properties file. For example, for Chinese:</p><div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>java <span class="nt">-mx3g</span> <span class="nt">-cp</span> <span class="s2">"*"</span> edu.stanford.nlp.pipeline.StanfordCoreNLP <span class="nt">-props</span> StanfordCoreNLP-chinese.properties <span class="nt">-file</span> chinese.txt <span class="nt">-outputFormat</span> text
</code></pre></div></div><p>You can as usual specify details on the annotators and properties:</p><div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>java <span class="nt">-mx1g</span> <span class="nt">-cp</span> <span class="s2">"*"</span> edu.stanford.nlp.pipeline.StanfordCoreNLP <span class="nt">-props</span> StanfordCoreNLP-french.properties <span class="nt">-annotators</span> tokenize,ssplit,pos,depparse <span class="nt">-file</span> french.txt <span class="nt">-outputFormat</span> conllu
</code></pre></div></div><h2 id="input"> <a href="#input" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#link"></use></svg></a> Input</h2><p>To process one file, use the <code class="language-plaintext highlighter-rouge">-file</code> option followed by a filename. To process a list of files, use the <code class="language-plaintext highlighter-rouge">-fileList</code> parameter:</p><div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>java <span class="nt">-cp</span> <span class="s2">"*"</span> <span class="nt">-Xmx2g</span> edu.stanford.nlp.pipeline.StanfordCoreNLP <span class="o">[</span> <span class="nt">-props</span> myprops.props <span class="o">]</span> <span class="nt">-fileList</span> filelist.txt
</code></pre></div></div><p>where the <code class="language-plaintext highlighter-rouge">-fileList</code> parameter points to a file which lists all files to be processed (one per line).</p><p>If
 you do not specify any properties that load input files (and do not 
specify any input or output redirections), then you will be placed in 
the <a href="https://stanfordnlp.github.io/CoreNLP/repl.html">interactive shell</a>. Type <code class="language-plaintext highlighter-rouge">q</code> to exit.</p><h3 id="using-corenlp-as-a-filter-in-a-pipe"> <a href="#using-corenlp-as-a-filter-in-a-pipe" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#link"></use></svg></a> Using CoreNLP as a filter in a pipe</h3><p>If
 you do not specify an option that loads input files and you redirect 
either input or output, then Stanford CoreNLP runs as a filter that 
reads from stdin and writes to stdout. The default mode is 
line-oriented: Each line of input counts as a document. If you give the 
flag/property <code class="language-plaintext highlighter-rouge">-isOneDocument</code> (<code class="language-plaintext highlighter-rouge">isOneDocument = true</code>) then the input till end-of-file will be treated as one document.</p><h3 id="common-input-options"> <a href="#common-input-options" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#link"></use></svg></a> Common input options</h3><p>If your input files have XML tags in them, you may wish to add the <code class="language-plaintext highlighter-rouge">cleanxml</code> annotator to preprocess it. Place it immediately after <code class="language-plaintext highlighter-rouge">tokenize</code>.</p><p>If your input is already tokenzed and one sentence per line, then you should use the flags: <code class="language-plaintext highlighter-rouge">-tokenize.whitespace -ssplit.eolonly</code>.</p><p>Fine point: Stanford CoreNLP treats <a href="https://www.unicode.org/standard/reports/tr13/tr13-5.html">Unicode end of line markers</a>
 (LS U+2028 and PS U+2029) as line ends, whereas conventional Unix 
utilities do not. If these characters are present and you are using 
CoreNLP in a Unix line-oriented processing pipeline, you may need to 
remap these characters to ‘\n’ or ‘ ‘ at the start of your processing 
pipeline.</p><p>You can find other input processing options in the documentation of the <a href="https://stanfordnlp.github.io/CoreNLP/tokenize.html">tokenize</a>, <a href="https://stanfordnlp.github.io/CoreNLP/cleanxml.html">cleanxml</a>, and <a href="https://stanfordnlp.github.io/CoreNLP/ssplit.html">ssplit</a> annotators.</p><h3 id="inputting-serialized-files"> <a href="#inputting-serialized-files" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#link"></use></svg></a> Inputting serialized files</h3><p>If
 (and only if) the input filename ends with “.ser.gz” then CoreNLP will 
interpret the file as the output of a previous annotation run, to which 
you presumably want to add on further annotations. CoreNLP will read 
these Annotations using the class specified in the <code class="language-plaintext highlighter-rouge">inputSerializer</code> property. The options for this are the same as for <code class="language-plaintext highlighter-rouge">outputSerializer</code> <a href="https://stanfordnlp.github.io/CoreNLP/cmdline.html#output-serializer">below</a>. Note: To successfully load a pipeline for layering on additional annotations, you need to include the property <code class="language-plaintext highlighter-rouge">enforceRequirements = false</code> to avoid complaints about required earlier annotators not being present in the pipeline.</p><h2 id="output"> <a href="#output" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#link"></use></svg></a> Output</h2><p>For
 each input file, Stanford CoreNLP generates one output file, with a 
name that adds an extra extension to the input filename. (If reading 
input from stdin, then it will send output to stdout.) The output may 
contain the output of all annotations that were done, or just a subset 
of them. For the first example under Quick Start above, with <code class="language-plaintext highlighter-rouge">input.txt</code> containing the text below:</p><blockquote><p>Stanford University is located in California. It is a great university.</p></blockquote><p>Stanford CoreNLP generates <a href="https://stanfordnlp.github.io/CoreNLP/files/input.txt.output">this output</a>.</p><p>Note that this XML output can use the <code class="language-plaintext highlighter-rouge">CoreNLP-to-HTML.xsl</code> stylesheet file, which comes with the CoreNLP download or can be downloaded from <a href="https://stanfordnlp.github.io/CoreNLP/files/CoreNLP-to-HTML.xsl">here</a>. This stylesheet enables human-readable display of the above XML content. For example, this example should display like <a href="https://stanfordnlp.github.io/CoreNLP/files/input.txt.xml">this</a>.</p><h3 id="output-options"> <a href="#output-options" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#link"></use></svg></a> Output options</h3><p>The following properties are associated with output :</p><ul><li><code class="language-plaintext highlighter-rouge">-outputDirectory</code> : By default, output files are written to the current directory. You may specify an alternate output directory with the flag <code class="language-plaintext highlighter-rouge">-outputDirectory</code>.</li><li><code class="language-plaintext highlighter-rouge">-outputExtension</code> : Output filenames are the same as input filenames but with <code class="language-plaintext highlighter-rouge">-outputExtension</code> added to them (the default depends on the <code class="language-plaintext highlighter-rouge">outputFormat</code>).</li><li><code class="language-plaintext highlighter-rouge">-noClobber</code> : By default, files are overwritten (clobbered). Pass <code class="language-plaintext highlighter-rouge">-noClobber</code> to avoid this behavior.</li><li><code class="language-plaintext highlighter-rouge">-replaceExtension</code> : If you’d rather replace the extension with the <code class="language-plaintext highlighter-rouge">-outputExtension</code>, pass the <code class="language-plaintext highlighter-rouge">-replaceExtension</code> flag. This will result in filenames like <code class="language-plaintext highlighter-rouge">input.xml</code> instead of <code class="language-plaintext highlighter-rouge">input.txt.xml</code> (when given <code class="language-plaintext highlighter-rouge">input.txt</code> as an input file).</li><li><code class="language-plaintext highlighter-rouge">-outputFormat</code> : Different methods for outputting results. Can be:<ul><li>“text”:
 An ad hoc human-readable text format. Tokens, s-expression parse trees,
 relation(head, dep) dependencies. Output file extension is <code class="language-plaintext highlighter-rouge">.out</code>. This is the default output format only if the XMLOutputter is unavailable.</li><li>“xml”: An XML format with accompanying XSLT stylesheet, which allows web browser rendering. Output file extension is <code class="language-plaintext highlighter-rouge">.xml</code>. This is the default output format, unless the XMLOutputter is unavailable.</li><li>“json”: JSON. Output file extension is <code class="language-plaintext highlighter-rouge">.json</code>. ’Nuf said.</li><li>“conll”: A tab-separated values (TSV) format. Output extension is <code class="language-plaintext highlighter-rouge">.conll</code>. This output format usually only gives a partial view of an <code class="language-plaintext highlighter-rouge">Annotation</code> and doesn’t correspond to any particular CoNLL format. By default, the columns written are: <code class="language-plaintext highlighter-rouge">idx</code>, <code class="language-plaintext highlighter-rouge">word</code>, <code class="language-plaintext highlighter-rouge">lemma</code>, <code class="language-plaintext highlighter-rouge">pos</code>, <code class="language-plaintext highlighter-rouge">ner</code>, <code class="language-plaintext highlighter-rouge">headidx</code>, <code class="language-plaintext highlighter-rouge">deprel</code>. You can customize which fields are written with the <code class="language-plaintext highlighter-rouge">output.columns</code> property. Its value is a comma-separated list of output key names, where the names are ones understood by <code class="language-plaintext highlighter-rouge">AnnotationLookup.KeyLookup</code>. Available names include the seven used in the default output and others such as <code class="language-plaintext highlighter-rouge">shape</code>, <code class="language-plaintext highlighter-rouge">speaker</code>. For instance, you can write out just tokenized text, with one token per line and a blank line between sentences by using <code class="language-plaintext highlighter-rouge">-output.columns word</code>. Alternatively, if you give the property <code class="language-plaintext highlighter-rouge">output.prettyPrint = false</code>
 to this outputter, it will print one sentence per line output with the 
selected fields separated by slash (/) characters. You can hence use 
this option to write tokenized text, one sentence per line with the 
options <code class="language-plaintext highlighter-rouge">-outputFormat conll -output.columns word -output.prettyPrint false</code>.</li><li>“conllu”: <a href="https://universaldependencies.github.io/docs/format.html">CoNLL-U</a> output format, another tab-separated values (TSV) format, with particular extended features. Output extension is <code class="language-plaintext highlighter-rouge">.conllu</code>. This representation may give only a partial view of an <code class="language-plaintext highlighter-rouge">Annotation</code>.</li><li>“serialized”: Produces some serialized version of each <code class="language-plaintext highlighter-rouge">Annotation</code>. May or may not be lossy. What you actually get depends on the <code class="language-plaintext highlighter-rouge">outputSerializer</code> property, which you should also set. The default is the <code class="language-plaintext highlighter-rouge">GenericAnnotationSerializer</code>, which uses the built-in Java object serialization and writes a file with extension <code class="language-plaintext highlighter-rouge">.ser.gz</code>.</li></ul></li></ul><p>Other more obscure output options are:</p><ul><li><code class="language-plaintext highlighter-rouge">output.includeText</code> : Boolean. Whether to include text of document in document annotations.</li><li><code class="language-plaintext highlighter-rouge">output.prettyPrint</code> : Boolean. Whether to pretty print certain annotations (more friendly to humans; less space efficient.</li><li><code class="language-plaintext highlighter-rouge">output.constituencyTree</code> : String. Style of constituency tree printing to be used. One known to <code class="language-plaintext highlighter-rouge">TreePrint</code>.</li><li><code class="language-plaintext highlighter-rouge">output.dependencyTree</code> : String. Style of dependency tree printing to be used. One known to <code class="language-plaintext highlighter-rouge">TreePrint</code>.</li><li><code class="language-plaintext highlighter-rouge">output.coreferenceContextSize</code> : int. Whether to print some conext around a coreference mention.</li><li><code class="language-plaintext highlighter-rouge">output.printSingletonEntities</code> : Boolean. Whether to print singleton entity mentions in coreference output.</li><li><code class="language-plaintext highlighter-rouge">output.relationsBeam</code> : double. Whether to filter relations extracted by goodness score.</li><li><code class="language-plaintext highlighter-rouge">output.columns</code> : String. Which columns to print in <code class="language-plaintext highlighter-rouge">conll</code> output. A list of names like: <code class="language-plaintext highlighter-rouge">idx,word,pos,ner</code>.</li></ul><h3 id="output-serializer"> <a href="#output-serializer" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#link"></use></svg></a> Output serializer</h3><p>The value of the <code class="language-plaintext highlighter-rouge">outputSerializer</code> property is the name of a class which extends <code class="language-plaintext highlighter-rouge">edu.stanford.nlp.pipeline.AnnotationSerializer</code>. Valid choices include: <code class="language-plaintext highlighter-rouge">edu.stanford.nlp.pipeline.GenericAnnotationSerializer</code>, <code class="language-plaintext highlighter-rouge">edu.stanford.nlp.pipeline.CustomAnnotationSerializer</code>, <code class="language-plaintext highlighter-rouge">edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer</code>; <code class="language-plaintext highlighter-rouge">edu.stanford.nlp.kbp.common.KBPProtobufAnnotationSerializer</code>, <code class="language-plaintext highlighter-rouge">edu.stanford.nlp.kbp.slotfilling.ir.index.KryoAnnotationSerializer</code>. If unspecified the value of the <code class="language-plaintext highlighter-rouge">serializer</code> property will be tried instead. If it is also not defined, the default is to use <code class="language-plaintext highlighter-rouge">edu.stanford.nlp.pipeline.GenericAnnotationSerializer</code>.</p><p>The <code class="language-plaintext highlighter-rouge">ProtobufAnnotationSerializer</code>
 is a non-lossy annotation serialization. It uses the Java methods 
writeDelimitedTo() and parseDelimitedFrom(), which allow sending several
 length-prefixed messages in one stream. Unfortunately, Google has 
declined to implement these methods for Python or C++. You can get 
information from Stack Overflow and other places on how to roll your own
 version for C++ or Python. Probably the best place is <a href="http://stackoverflow.com/questions/2340730/are-there-c-equivalents-for-the-protocol-buffers-delimited-i-o-functions-in-ja/">here</a> but there are many other sources of information including: <a href="http://stackoverflow.com/questions/8269452/google-protocol-buffers-parsedelimitedfrom-and-writedelimitedto-for-c">here</a>, <a href="https://github.com/google/protobuf/pull/710">here</a>, <a href="http://stackoverflow.com/questions/11484700/python-example-for-reading-multiple-protobuf-messages-from-a-stream">here</a>, and <a href="http://eli.thegreenplace.net/2011/08/02/length-prefix-framing-for-protocol-buffers">here</a>. <a href="http://stackoverflow.com/questions/39433279/read-protobuf-serialization-of-stanfordnlp-output-in-python/40964310">This Stack Overflow question</a> explicitly addresses the issue for CoreNLP.</p><h3 id="a-note-on-numbering"> <a href="#a-note-on-numbering" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#link"></use></svg></a> A note on numbering</h3><p>In
 all output formats (and in our code), we number sentences and character
 offsets from 0 and we number tokens from 1. We realize that this is 
inconsistent! However, it seemed to be the best thing to do. Numbering 
character offsets from 0 is the only good choice, given how the Java 
String class and most modern programming languages work, following <a href="https://www.cs.utexas.edu/users/EWD/ewd08xx/EWD831.PDF">Dijkstra’s arguments</a>
 for indexing from 0 (which were influential at the time if not 
necessarily so water-tight). Numbering tokens from 1 not only 
corresponds to the human-natural convention (“the first word of the 
sentence”) but most importantly is consistent with common NLP standards,
 such as the CoNLL formats used from <a href="http://www.aclweb.org/anthology/W06-2920">CoNLL-X</a> through <a href="">CoNLL 2009</a>, etc., and in <a href="http://universaldependencies.org/format.html">CoNLL-U</a>,
 which number tokens starting from 1. For sentences, we could then 
choose to be consistent with either but not both of the above. We went 
with 0-indexing.</p><h2 id="character-encoding"> <a href="#character-encoding" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#link"></use></svg></a> Character encoding</h2><p>CoreNLP’s
 default character encoding is Unicode’s UTF-8. You can change the 
encoding used by supplying the program with the command line flag <code class="language-plaintext highlighter-rouge">-encoding FOO</code>
 (or including the corresponding property in a properties file that you 
are using). We’ve done a lot of careful work to make sure CoreNLP works 
with any character encoding supported by Java. Want to use ISO-8859-15 
or GB18030? Be our guest!</p><hr><footer role="contentinfo"><p class="text-small text-grey-dk-000 mb-0">Copyright © 2020 Stanford NLP Group.</p></footer></div></div></div></div>
</div></body></html>