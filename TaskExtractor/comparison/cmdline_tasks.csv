Paragraph,Ground truth tasks,Program tasks,Partial Ratio
The minimal command to run Stanford CoreNLP from the command line is:,run stanford corenlp from command line,run stanford corenlp from command line,100
"To use the properties in the properties file sampleProps.properties, you give a command as follows:",use properties in properties file sampleprops.properties,use properties in properties file sampleprops.properties,100
"However, if you just want to specify a few properties, you can instead place them on the command line. For example, we can specify annotators and the output format with:","specify few properties, specify annotators, specify output format",specify few properties,100
"However, if you just want to specify a few properties, you can instead place them on the command line. For example, we can specify annotators and the output format with:","specify few properties, specify annotators, specify output format",place  on command line,36
"However, if you just want to specify a few properties, you can instead place them on the command line. For example, we can specify annotators and the output format with:","specify few properties, specify annotators, specify output format",specify annotators,100
"However, if you just want to specify a few properties, you can instead place them on the command line. For example, we can specify annotators and the output format with:","specify few properties, specify annotators, specify output format",specify output format,100
"If you have a lot of text but all you want to do is to, say, get part-of-speech (POS) tags, then you should definitely specify an annotators list, as above, since you can then omit later annotators which invoke much more expensive processing that you don’t need. For example, you might give the command:","get part-of-speech tags, specify annotators list, omit later annotators",get part-of-speech tags,100
"If you have a lot of text but all you want to do is to, say, get part-of-speech (POS) tags, then you should definitely specify an annotators list, as above, since you can then omit later annotators which invoke much more expensive processing that you don’t need. For example, you might give the command:","get part-of-speech tags, specify annotators list, omit later annotators",specify annotators list,100
"If you have a lot of text but all you want to do is to, say, get part-of-speech (POS) tags, then you should definitely specify an annotators list, as above, since you can then omit later annotators which invoke much more expensive processing that you don’t need. For example, you might give the command:","get part-of-speech tags, specify annotators list, omit later annotators",omit later annotators,100
You can as usual specify details on the annotators and properties:,"specify details on annotators, specify details on properties",specify details on annotators,100
You can as usual specify details on the annotators and properties:,"specify details on annotators, specify details on properties",specify details on properties,100
"To process one file, use the -file option followed by a filename. To process a list of files, use the -fileList parameter:","process file, process list of files",process file,100
"To process one file, use the -file option followed by a filename. To process a list of files, use the -fileList parameter:","process file, process list of files",use -file option,56
"To process one file, use the -file option followed by a filename. To process a list of files, use the -fileList parameter:","process file, process list of files",process list of files,100
"To process one file, use the -file option followed by a filename. To process a list of files, use the -fileList parameter:","process file, process list of files",use -filelist parameter,48
"To process one file, use the -file option followed by a filename. To process a list of files, use the -fileList parameter:","process file, process list of files",use files,67
"If your input files have XML tags in them, you may wish to add the cleanxml annotator to preprocess it. Place it immediately after tokenize.","add cleanxml annotator, place after tokenize",add cleanxml annotator,100
"If your input files have XML tags in them, you may wish to add the cleanxml annotator to preprocess it. Place it immediately after tokenize.","add cleanxml annotator, place after tokenize",place  after tokenize,98
"The ProtobufAnnotationSerializer is a non-lossy annotation serialization. It uses the Java methods writeDelimitedTo() and parseDelimitedFrom(), which allow sending several length-prefixed messages in one stream. Unfortunately, Google has declined to implement these methods for Python or C++. You can get information from Stack Overflow and other places on how to roll your own version for C++ or Python. Probably the best place is here but there are many other sources of information including: here, here, here, and here. This Stack Overflow question explicitly addresses the issue for CoreNLP.",send several length-prefixed messages in stream,use java methods,50
"The ProtobufAnnotationSerializer is a non-lossy annotation serialization. It uses the Java methods writeDelimitedTo() and parseDelimitedFrom(), which allow sending several length-prefixed messages in one stream. Unfortunately, Google has declined to implement these methods for Python or C++. You can get information from Stack Overflow and other places on how to roll your own version for C++ or Python. Probably the best place is here but there are many other sources of information including: here, here, here, and here. This Stack Overflow question explicitly addresses the issue for CoreNLP.",send several length-prefixed messages in stream,send several length-prefixed messages in stream,100
"The ProtobufAnnotationSerializer is a non-lossy annotation serialization. It uses the Java methods writeDelimitedTo() and parseDelimitedFrom(), which allow sending several length-prefixed messages in one stream. Unfortunately, Google has declined to implement these methods for Python or C++. You can get information from Stack Overflow and other places on how to roll your own version for C++ or Python. Probably the best place is here but there are many other sources of information including: here, here, here, and here. This Stack Overflow question explicitly addresses the issue for CoreNLP.",send several length-prefixed messages in stream,implement methods for python,36
"The ProtobufAnnotationSerializer is a non-lossy annotation serialization. It uses the Java methods writeDelimitedTo() and parseDelimitedFrom(), which allow sending several length-prefixed messages in one stream. Unfortunately, Google has declined to implement these methods for Python or C++. You can get information from Stack Overflow and other places on how to roll your own version for C++ or Python. Probably the best place is here but there are many other sources of information including: here, here, here, and here. This Stack Overflow question explicitly addresses the issue for CoreNLP.",send several length-prefixed messages in stream,implement methods for c + +,33
"The ProtobufAnnotationSerializer is a non-lossy annotation serialization. It uses the Java methods writeDelimitedTo() and parseDelimitedFrom(), which allow sending several length-prefixed messages in one stream. Unfortunately, Google has declined to implement these methods for Python or C++. You can get information from Stack Overflow and other places on how to roll your own version for C++ or Python. Probably the best place is here but there are many other sources of information including: here, here, here, and here. This Stack Overflow question explicitly addresses the issue for CoreNLP.",send several length-prefixed messages in stream,get information from stack overflow,31
"The ProtobufAnnotationSerializer is a non-lossy annotation serialization. It uses the Java methods writeDelimitedTo() and parseDelimitedFrom(), which allow sending several length-prefixed messages in one stream. Unfortunately, Google has declined to implement these methods for Python or C++. You can get information from Stack Overflow and other places on how to roll your own version for C++ or Python. Probably the best place is here but there are many other sources of information including: here, here, here, and here. This Stack Overflow question explicitly addresses the issue for CoreNLP.",send several length-prefixed messages in stream,get information from other places,33
