Paragraph,Ground truth tasks,Program tasks,Partial Ratio
The minimal command to run Stanford CoreNLP from the command line is:,run corenlp from command line,run stanford corenlp from command line,93
"To use the properties in the properties file sampleProps.properties, you give a command as follows:",use properties file,use properties in properties file sampleprops.properties,84
"However, if you just want to specify a few properties, you can instead place them on the command line. For example, we can specify annotators and the output format with:",specify few properties,specify few properties,100
"However, if you just want to specify a few properties, you can instead place them on the command line. For example, we can specify annotators and the output format with:",specify few properties,place  on command line,32
"However, if you just want to specify a few properties, you can instead place them on the command line. For example, we can specify annotators and the output format with:",specify few properties,specify annotators,56
"However, if you just want to specify a few properties, you can instead place them on the command line. For example, we can specify annotators and the output format with:",specify few properties,specify output format,57
"If you have a lot of text but all you want to do is to, say, get part-of-speech (POS) tags, then you should definitely specify an annotators list, as above, since you can then omit later annotators which invoke much more expensive processing that you don’t need. For example, you might give the command:",get pos tags,get part-of-speech tags,50
"If you have a lot of text but all you want to do is to, say, get part-of-speech (POS) tags, then you should definitely specify an annotators list, as above, since you can then omit later annotators which invoke much more expensive processing that you don’t need. For example, you might give the command:",get pos tags,specify annotators list,42
"If you have a lot of text but all you want to do is to, say, get part-of-speech (POS) tags, then you should definitely specify an annotators list, as above, since you can then omit later annotators which invoke much more expensive processing that you don’t need. For example, you might give the command:",get pos tags,omit later annotators,42
You can as usual specify details on the annotators and properties:,specify details on annotators and properties,specify details on annotators,100
You can as usual specify details on the annotators and properties:,specify details on annotators and properties,specify details on properties,76
"To process one file, use the -file option followed by a filename. To process a list of files, use the -fileList parameter:",process (multiple) files,process file,75
"To process one file, use the -file option followed by a filename. To process a list of files, use the -fileList parameter:",process (multiple) files,process list of files,62
"If your input files have XML tags in them, you may wish to add the cleanxml annotator to preprocess it. Place it immediately after tokenize.",process xml,add cleanxml annotator,45
"If your input files have XML tags in them, you may wish to add the cleanxml annotator to preprocess it. Place it immediately after tokenize.",process xml,place  after tokenize,36
"The ProtobufAnnotationSerializer is a non-lossy annotation serialization. It uses the Java methods writeDelimitedTo() and parseDelimitedFrom(), which allow sending several length-prefixed messages in one stream. Unfortunately, Google has declined to implement these methods for Python or C++. You can get information from Stack Overflow and other places on how to roll your own version for C++ or Python. Probably the best place is here but there are many other sources of information including: here, here, here, and here. This Stack Overflow question explicitly addresses the issue for CoreNLP.",protobufannotationserializer for python or c++ for non-lossy annotation serialization,use java methods,39
"The ProtobufAnnotationSerializer is a non-lossy annotation serialization. It uses the Java methods writeDelimitedTo() and parseDelimitedFrom(), which allow sending several length-prefixed messages in one stream. Unfortunately, Google has declined to implement these methods for Python or C++. You can get information from Stack Overflow and other places on how to roll your own version for C++ or Python. Probably the best place is here but there are many other sources of information including: here, here, here, and here. This Stack Overflow question explicitly addresses the issue for CoreNLP.",protobufannotationserializer for python or c++ for non-lossy annotation serialization,send several length-prefixed messages in stream,34
"The ProtobufAnnotationSerializer is a non-lossy annotation serialization. It uses the Java methods writeDelimitedTo() and parseDelimitedFrom(), which allow sending several length-prefixed messages in one stream. Unfortunately, Google has declined to implement these methods for Python or C++. You can get information from Stack Overflow and other places on how to roll your own version for C++ or Python. Probably the best place is here but there are many other sources of information including: here, here, here, and here. This Stack Overflow question explicitly addresses the issue for CoreNLP.",protobufannotationserializer for python or c++ for non-lossy annotation serialization,implement methods for python,50
"The ProtobufAnnotationSerializer is a non-lossy annotation serialization. It uses the Java methods writeDelimitedTo() and parseDelimitedFrom(), which allow sending several length-prefixed messages in one stream. Unfortunately, Google has declined to implement these methods for Python or C++. You can get information from Stack Overflow and other places on how to roll your own version for C++ or Python. Probably the best place is here but there are many other sources of information including: here, here, here, and here. This Stack Overflow question explicitly addresses the issue for CoreNLP.",protobufannotationserializer for python or c++ for non-lossy annotation serialization,implement methods for c + +,52
"The ProtobufAnnotationSerializer is a non-lossy annotation serialization. It uses the Java methods writeDelimitedTo() and parseDelimitedFrom(), which allow sending several length-prefixed messages in one stream. Unfortunately, Google has declined to implement these methods for Python or C++. You can get information from Stack Overflow and other places on how to roll your own version for C++ or Python. Probably the best place is here but there are many other sources of information including: here, here, here, and here. This Stack Overflow question explicitly addresses the issue for CoreNLP.",protobufannotationserializer for python or c++ for non-lossy annotation serialization,get information from stack overflow,49
"The ProtobufAnnotationSerializer is a non-lossy annotation serialization. It uses the Java methods writeDelimitedTo() and parseDelimitedFrom(), which allow sending several length-prefixed messages in one stream. Unfortunately, Google has declined to implement these methods for Python or C++. You can get information from Stack Overflow and other places on how to roll your own version for C++ or Python. Probably the best place is here but there are many other sources of information including: here, here, here, and here. This Stack Overflow question explicitly addresses the issue for CoreNLP.",protobufannotationserializer for python or c++ for non-lossy annotation serialization,get information from other places,45
