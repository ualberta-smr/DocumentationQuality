"import pandas as pd
pd.DataFrame({'A': [1, 2, 3]})
",https://pandas.pydata.org/docs/user_guide/index.html, pandas.DataFrame
"In [1]: import pandas as pd

In [2]: pd.DataFrame({'A': [1, 2, 3]})
Out[2]: 
   A
0  1
1  2
2  3
",https://pandas.pydata.org/docs/user_guide/index.html, pandas.DataFrame
"In [2]: titanic = pd.read_csv(""data/titanic.csv"")

In [3]: titanic.head()
Out[3]: 
   PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked
0            1         0       3  ...   7.2500   NaN         S
1            2         1       1  ...  71.2833   C85         C
2            3         1       3  ...   7.9250   NaN         S
3            4         1       1  ...  53.1000  C123         S
4            5         0       3  ...   8.0500   NaN         S

[5 rows x 12 columns]
",https://pandas.pydata.org/docs/getting_started/intro_tutorials/06_calculate_statistics.html, pandas.read_csv
"In [2]: air_quality = pd.read_csv(""data/air_quality_no2.csv"", index_col=0, parse_dates=True)

In [3]: air_quality.head()
Out[3]: 
                     station_antwerp  station_paris  station_london
datetime                                                           
2019-05-07 02:00:00              NaN            NaN            23.0
2019-05-07 03:00:00             50.5           25.0            19.0
2019-05-07 04:00:00             45.0           27.7            19.0
2019-05-07 05:00:00              NaN           50.4            16.0
2019-05-07 06:00:00              NaN           61.9             NaN
",https://pandas.pydata.org/docs/getting_started/intro_tutorials/05_add_columns.html, pandas.read_csv
"In [3]: df = pd.DataFrame({""x"": [1, 3, 5], ""y"": [2, 4, 6]})

In [4]: df
Out[4]: 
   x  y
0  1  2
1  3  4
2  5  6
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_stata.html, pandas.DataFrame
"In [5]: url = (
   ...:     ""https://raw.githubusercontent.com/pandas-dev""
   ...:     ""/pandas/main/pandas/tests/io/data/csv/tips.csv""
   ...: )
   ...: 

In [6]: tips = pd.read_csv(url)

In [7]: tips
Out[7]: 
     total_bill   tip     sex smoker   day    time  size
0         16.99  1.01  Female     No   Sun  Dinner     2
1         10.34  1.66    Male     No   Sun  Dinner     3
2         21.01  3.50    Male     No   Sun  Dinner     3
3         23.68  3.31    Male     No   Sun  Dinner     2
4         24.59  3.61  Female     No   Sun  Dinner     4
..          ...   ...     ...    ...   ...     ...   ...
239       29.03  5.92    Male     No   Sat  Dinner     3
240       27.18  2.00  Female    Yes   Sat  Dinner     2
241       22.67  2.00    Male    Yes   Sat  Dinner     2
242       17.82  1.75    Male     No   Sat  Dinner     2
243       18.78  3.00  Female     No  Thur  Dinner     2

[244 rows x 7 columns]
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_stata.html, pandas.read_csv
"tips = pd.read_csv(""tips.csv"", sep=""\t"", header=None)

# alternatively, read_table is an alias to read_csv with tab delimiter
tips = pd.read_table(""tips.csv"", header=None)
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_stata.html, pandas.read_csv pandas.read_table
"df = pd.read_stata(""data.dta"")
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_stata.html, pandas.read_stata
"tips.to_stata(""tips2.dta"")
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_stata.html, pandas.DataFrame.to_stata
"generate date1 = mdy(1, 15, 2013)
generate date2 = date(""Feb152015"", ""MDY"")

generate date1_year = year(date1)
generate date2_month = month(date2)

* shift date to beginning of next month
generate date1_next = mdy(month(date1) + 1, 1, year(date1)) if month(date1) != 12
replace date1_next = mdy(1, 1, year(date1) + 1) if month(date1) == 12
generate months_between = mofd(date2) - mofd(date1)

list date1 date2 date1_year date2_month date1_next months_between
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_stata.html, pandas.Timestamp.date
"In [32]: tips[""time""].str.len()
Out[32]: 
67     6
92     6
111    6
145    5
135    5
      ..
182    6
156    6
59     6
212    6
170    6
Name: time, Length: 244, dtype: int64

In [33]: tips[""time""].str.rstrip().str.len()
Out[33]: 
67     6
92     6
111    6
145    5
135    5
      ..
182    6
156    6
59     6
212    6
170    6
Name: time, Length: 244, dtype: int64
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_stata.html, pandas.Series.str.rstrip
"In [34]: tips[""sex""].str.find(""ale"")
Out[34]: 
67     3
92     3
111    3
145    3
135    3
      ..
182    1
156    1
59     1
212    1
170    1
Name: sex, Length: 244, dtype: int64
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_stata.html, pandas.Series.str.find
"In [36]: firstlast = pd.DataFrame({""String"": [""John Smith"", ""Jane Cook""]})

In [37]: firstlast[""First_Name""] = firstlast[""String""].str.split("" "", expand=True)[0]

In [38]: firstlast[""Last_Name""] = firstlast[""String""].str.rsplit("" "", expand=True)[1]

In [39]: firstlast
Out[39]: 
       String First_Name Last_Name
0  John Smith       John     Smith
1   Jane Cook       Jane      Cook
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_stata.html, pandas.DataFrame pandas.Series.str.split pandas.Series.str.rsplit
"In [40]: firstlast = pd.DataFrame({""string"": [""John Smith"", ""Jane Cook""]})

In [41]: firstlast[""upper""] = firstlast[""string""].str.upper()

In [42]: firstlast[""lower""] = firstlast[""string""].str.lower()

In [43]: firstlast[""title""] = firstlast[""string""].str.title()

In [44]: firstlast
Out[44]: 
       string       upper       lower       title
0  John Smith  JOHN SMITH  john smith  John Smith
1   Jane Cook   JANE COOK   jane cook   Jane Cook
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_stata.html, pandas.DataFrame pandas.Series.str.upper pandas.Series.str.lower pandas.Series.str.title
"In [45]: df1 = pd.DataFrame({""key"": [""A"", ""B"", ""C"", ""D""], ""value"": np.random.randn(4)})

In [46]: df1
Out[46]: 
  key     value
0   A  0.469112
1   B -0.282863
2   C -1.509059
3   D -1.135632

In [47]: df2 = pd.DataFrame({""key"": [""B"", ""D"", ""D"", ""E""], ""value"": np.random.randn(4)})

In [48]: df2
Out[48]: 
  key     value
0   B  1.212112
1   D -0.173215
2   D  0.119209
3   E -1.044236
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_stata.html, pandas.DataFrame
"In [49]: inner_join = df1.merge(df2, on=[""key""], how=""inner"")

In [50]: inner_join
Out[50]: 
  key   value_x   value_y
0   B -0.282863  1.212112
1   D -1.135632 -0.173215
2   D -1.135632  0.119209

In [51]: left_join = df1.merge(df2, on=[""key""], how=""left"")

In [52]: left_join
Out[52]: 
  key   value_x   value_y
0   A  0.469112       NaN
1   B -0.282863  1.212112
2   C -1.509059       NaN
3   D -1.135632 -0.173215
4   D -1.135632  0.119209

In [53]: right_join = df1.merge(df2, on=[""key""], how=""right"")

In [54]: right_join
Out[54]: 
  key   value_x   value_y
0   B -0.282863  1.212112
1   D -1.135632 -0.173215
2   D -1.135632  0.119209
3   E       NaN -1.044236

In [55]: outer_join = df1.merge(df2, on=[""key""], how=""outer"")

In [56]: outer_join
Out[56]: 
  key   value_x   value_y
0   A  0.469112       NaN
1   B -0.282863  1.212112
2   C -1.509059       NaN
3   D -1.135632 -0.173215
4   D -1.135632  0.119209
5   E       NaN -1.044236
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_stata.html, pandas.DataFrame.merge
">>> import pandas as pd
>>> pd.test()
running: pytest -m ""not slow and not network and not db"" /home/user/anaconda3/lib/python3.9/site-packages/pandas

============================= test session starts ==============================
platform linux -- Python 3.9.7, pytest-6.2.5, py-1.11.0, pluggy-1.0.0
rootdir: /home/user
plugins: dash-1.19.0, anyio-3.5.0, hypothesis-6.29.3
collected 154975 items / 4 skipped / 154971 selected
........................................................................ [  0%]
........................................................................ [ 99%]
.......................................                                  [100%]

==================================== ERRORS ====================================

=================================== FAILURES ===================================

=============================== warnings summary ===============================

=========================== short test summary info ============================

= 1 failed, 146194 passed, 7402 skipped, 1367 xfailed, 5 xpassed, 197 warnings, 10 errors in 1090.16s (0:18:10) =
",https://pandas.pydata.org/docs/getting_started/install.html, pandas.test
"sorted_df = df.sort_values(""col1"")
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_spreadsheets.html, pandas.DataFrame.sort_values
"df = df.sort_values(""col1"")
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_spreadsheets.html, pandas.DataFrame.sort_values
"df.replace(5, inplace=True)
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_spreadsheets.html, pandas.DataFrame.replace
"In [3]: df = pd.DataFrame({""x"": [1, 3, 5], ""y"": [2, 4, 6]})

In [4]: df
Out[4]: 
   x  y
0  1  2
1  3  4
2  5  6
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_spreadsheets.html, pandas.DataFrame
"In [5]: url = (
   ...:     ""https://raw.githubusercontent.com/pandas-dev""
   ...:     ""/pandas/main/pandas/tests/io/data/csv/tips.csv""
   ...: )
   ...: 

In [6]: tips = pd.read_csv(url)

In [7]: tips
Out[7]: 
     total_bill   tip     sex smoker   day    time  size
0         16.99  1.01  Female     No   Sun  Dinner     2
1         10.34  1.66    Male     No   Sun  Dinner     3
2         21.01  3.50    Male     No   Sun  Dinner     3
3         23.68  3.31    Male     No   Sun  Dinner     2
4         24.59  3.61  Female     No   Sun  Dinner     4
..          ...   ...     ...    ...   ...     ...   ...
239       29.03  5.92    Male     No   Sat  Dinner     3
240       27.18  2.00  Female    Yes   Sat  Dinner     2
241       22.67  2.00    Male    Yes   Sat  Dinner     2
242       17.82  1.75    Male     No   Sat  Dinner     2
243       18.78  3.00  Female     No  Thur  Dinner     2

[244 rows x 7 columns]
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_spreadsheets.html, pandas.read_csv
"tips = pd.read_csv(""tips.csv"", sep=""\t"", header=None)

# alternatively, read_table is an alias to read_csv with tab delimiter
tips = pd.read_table(""tips.csv"", header=None)
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_spreadsheets.html, pandas.read_csv pandas.read_table
"tips_df = pd.read_excel(""./tips.xlsx"", index_col=0)
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_spreadsheets.html, pandas.read_excel
"In [32]: tips[""time""].str.len()
Out[32]: 
67     6
92     6
111    6
145    5
135    5
      ..
182    6
156    6
59     6
212    6
170    6
Name: time, Length: 244, dtype: int64

In [33]: tips[""time""].str.rstrip().str.len()
Out[33]: 
67     6
92     6
111    6
145    5
135    5
      ..
182    6
156    6
59     6
212    6
170    6
Name: time, Length: 244, dtype: int64
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_spreadsheets.html, pandas.Series.str.rstrip
"In [34]: tips[""sex""].str.find(""ale"")
Out[34]: 
67     3
92     3
111    3
145    3
135    3
      ..
182    1
156    1
59     1
212    1
170    1
Name: sex, Length: 244, dtype: int64
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_spreadsheets.html, pandas.Series.str.find
"In [36]: firstlast = pd.DataFrame({""String"": [""John Smith"", ""Jane Cook""]})

In [37]: firstlast[""First_Name""] = firstlast[""String""].str.split("" "", expand=True)[0]

In [38]: firstlast[""Last_Name""] = firstlast[""String""].str.rsplit("" "", expand=True)[1]

In [39]: firstlast
Out[39]: 
       String First_Name Last_Name
0  John Smith       John     Smith
1   Jane Cook       Jane      Cook
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_spreadsheets.html, pandas.DataFrame pandas.Series.str.split pandas.Series.str.rsplit
"In [40]: firstlast = pd.DataFrame({""string"": [""John Smith"", ""Jane Cook""]})

In [41]: firstlast[""upper""] = firstlast[""string""].str.upper()

In [42]: firstlast[""lower""] = firstlast[""string""].str.lower()

In [43]: firstlast[""title""] = firstlast[""string""].str.title()

In [44]: firstlast
Out[44]: 
       string       upper       lower       title
0  John Smith  JOHN SMITH  john smith  John Smith
1   Jane Cook   JANE COOK   jane cook   Jane Cook
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_spreadsheets.html, pandas.DataFrame pandas.Series.str.upper pandas.Series.str.lower pandas.Series.str.title
"In [45]: df1 = pd.DataFrame({""key"": [""A"", ""B"", ""C"", ""D""], ""value"": np.random.randn(4)})

In [46]: df1
Out[46]: 
  key     value
0   A  0.469112
1   B -0.282863
2   C -1.509059
3   D -1.135632

In [47]: df2 = pd.DataFrame({""key"": [""B"", ""D"", ""D"", ""E""], ""value"": np.random.randn(4)})

In [48]: df2
Out[48]: 
  key     value
0   B  1.212112
1   D -0.173215
2   D  0.119209
3   E -1.044236
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_spreadsheets.html, pandas.DataFrame
"In [49]: inner_join = df1.merge(df2, on=[""key""], how=""inner"")

In [50]: inner_join
Out[50]: 
  key   value_x   value_y
0   B -0.282863  1.212112
1   D -1.135632 -0.173215
2   D -1.135632  0.119209

In [51]: left_join = df1.merge(df2, on=[""key""], how=""left"")

In [52]: left_join
Out[52]: 
  key   value_x   value_y
0   A  0.469112       NaN
1   B -0.282863  1.212112
2   C -1.509059       NaN
3   D -1.135632 -0.173215
4   D -1.135632  0.119209

In [53]: right_join = df1.merge(df2, on=[""key""], how=""right"")

In [54]: right_join
Out[54]: 
  key   value_x   value_y
0   B -0.282863  1.212112
1   D -1.135632 -0.173215
2   D -1.135632  0.119209
3   E       NaN -1.044236

In [55]: outer_join = df1.merge(df2, on=[""key""], how=""outer"")

In [56]: outer_join
Out[56]: 
  key   value_x   value_y
0   A  0.469112       NaN
1   B -0.282863  1.212112
2   C -1.509059       NaN
3   D -1.135632 -0.173215
4   D -1.135632  0.119209
5   E       NaN -1.044236
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_spreadsheets.html, pandas.DataFrame.merge
"In [57]: df = pd.DataFrame({""AAA"": [1] * 8, ""BBB"": list(range(0, 8))})

In [58]: df
Out[58]: 
   AAA  BBB
0    1    0
1    1    1
2    1    2
3    1    3
4    1    4
5    1    5
6    1    6
7    1    7

In [59]: series = list(range(1, 5))

In [60]: series
Out[60]: [1, 2, 3, 4]

In [61]: df.loc[2:5, ""AAA""] = series

In [62]: df
Out[62]: 
   AAA  BBB
0    1    0
1    1    1
2    1    2
3    2    3
4    3    4
5    4    5
6    1    6
7    1    7
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_spreadsheets.html, pandas.DataFrame
"In [63]: df = pd.DataFrame(
   ....:     {
   ....:         ""class"": [""A"", ""A"", ""A"", ""B"", ""C"", ""D""],
   ....:         ""student_count"": [42, 35, 42, 50, 47, 45],
   ....:         ""all_pass"": [""Yes"", ""Yes"", ""Yes"", ""No"", ""No"", ""Yes""],
   ....:     }
   ....: )
   ....: 

In [64]: df.drop_duplicates()
Out[64]: 
  class  student_count all_pass
0     A             42      Yes
1     A             35      Yes
3     B             50       No
4     C             47       No
5     D             45      Yes

In [65]: df.drop_duplicates([""class"", ""student_count""])
Out[65]: 
  class  student_count all_pass
0     A             42      Yes
1     A             35      Yes
3     B             50       No
4     C             47       No
5     D             45      Yes
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_spreadsheets.html, pandas.DataFrame pandas.DataFrame.drop_duplicates
"In [66]: pd.pivot_table(
   ....:     tips, values=""tip"", index=[""size""], columns=[""sex""], aggfunc=np.average
   ....: )
   ....: 
Out[66]: 
sex     Female      Male
size                    
1     1.276667  1.920000
2     2.528448  2.614184
3     3.250000  3.476667
4     4.021111  4.172143
5     5.140000  3.750000
6     4.600000  5.850000
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_spreadsheets.html, pandas.pivot_table
"In [67]: df
Out[67]: 
  class  student_count all_pass
0     A             42      Yes
1     A             35      Yes
2     A             42      Yes
3     B             50       No
4     C             47       No
5     D             45      Yes

In [68]: new_row = pd.DataFrame([[""E"", 51, True]],
   ....:                        columns=[""class"", ""student_count"", ""all_pass""])
   ....: 

In [69]: pd.concat([df, new_row])
Out[69]: 
  class  student_count all_pass
0     A             42      Yes
1     A             35      Yes
2     A             42      Yes
3     B             50       No
4     C             47       No
5     D             45      Yes
0     E             51     True
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_spreadsheets.html, pandas.DataFrame pandas.concat
"In [2]: titanic = pd.read_csv(""data/titanic.csv"")
",https://pandas.pydata.org/docs/getting_started/intro_tutorials/02_read_write.html, pandas.read_csv
"In [7]: titanic = pd.read_excel(""titanic.xlsx"", sheet_name=""passengers"")
",https://pandas.pydata.org/docs/getting_started/intro_tutorials/02_read_write.html, pandas.read_excel
">>> pd.Series(['a', 'b']).dt
Traceback (most recent call last):
...
AttributeError: Can only use .dt accessor with datetimelike values
",https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.register_index_accessor.html, pandas.Series
"import pandas as pd

@pd.api.extensions.register_dataframe_accessor(""geo"")
class GeoAccessor:
    def __init__(self, pandas_obj):
        self._obj = pandas_obj

    @property
    def center(self):
        # return the geographic center point of this DataFrame
        lat = self._obj.latitude
        lon = self._obj.longitude
        return (float(lon.mean()), float(lat.mean()))

    def plot(self):
        # plot this array's data on a map, e.g., using Cartopy
        pass
",https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.register_index_accessor.html, pandas.api.extensions.register_dataframe_accessor pandas.Series.str.center
"In [1]: ds = pd.DataFrame({""longitude"": np.linspace(0, 10),
   ...:                    ""latitude"": np.linspace(0, 20)})
In [2]: ds.geo.center
Out[2]: (5.0, 10.0)
In [3]: ds.geo.plot()  # plots data on a map
",https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.register_index_accessor.html, pandas.DataFrame
">>> pd.plotting.register_matplotlib_converters()
",https://pandas.pydata.org/docs/reference/api/pandas.plotting.deregister_matplotlib_converters.html, pandas.plotting.register_matplotlib_converters
">>> df = pd.DataFrame({'ts': pd.period_range('2020', periods=2, freq='M'),
...                    'y': [1, 2]
...                    })
>>> plot = df.plot.line(x='ts', y='y')
",https://pandas.pydata.org/docs/reference/api/pandas.plotting.deregister_matplotlib_converters.html, pandas.DataFrame pandas.period_range pandas.DataFrame.plot.line
">>> pd.set_option(""plotting.matplotlib.register_converters"",
...               False)  
>>> df.plot.line(x='ts', y='y')  
Traceback (most recent call last):
TypeError: float() argument must be a string or a real number, not 'Period'
",https://pandas.pydata.org/docs/reference/api/pandas.plotting.deregister_matplotlib_converters.html, pandas.DataFrame.plot.line
"In [3]: url = (
   ...:     ""https://raw.githubusercontent.com/pandas-dev""
   ...:     ""/pandas/main/pandas/tests/io/data/csv/tips.csv""
   ...: )
   ...: 

In [4]: tips = pd.read_csv(url)

In [5]: tips
Out[5]: 
     total_bill   tip     sex smoker   day    time  size
0         16.99  1.01  Female     No   Sun  Dinner     2
1         10.34  1.66    Male     No   Sun  Dinner     3
2         21.01  3.50    Male     No   Sun  Dinner     3
3         23.68  3.31    Male     No   Sun  Dinner     2
4         24.59  3.61  Female     No   Sun  Dinner     4
..          ...   ...     ...    ...   ...     ...   ...
239       29.03  5.92    Male     No   Sat  Dinner     3
240       27.18  2.00  Female    Yes   Sat  Dinner     2
241       22.67  2.00    Male    Yes   Sat  Dinner     2
242       17.82  1.75    Male     No   Sat  Dinner     2
243       18.78  3.00  Female     No  Thur  Dinner     2

[244 rows x 7 columns]
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_sql.html, pandas.read_csv
"sorted_df = df.sort_values(""col1"")
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_sql.html, pandas.DataFrame.sort_values
"df = df.sort_values(""col1"")
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_sql.html, pandas.DataFrame.sort_values
"df.replace(5, inplace=True)
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_sql.html, pandas.DataFrame.replace
"In [7]: tips.assign(tip_rate=tips[""tip""] / tips[""total_bill""])
Out[7]: 
     total_bill   tip     sex smoker   day    time  size  tip_rate
0         16.99  1.01  Female     No   Sun  Dinner     2  0.059447
1         10.34  1.66    Male     No   Sun  Dinner     3  0.160542
2         21.01  3.50    Male     No   Sun  Dinner     3  0.166587
3         23.68  3.31    Male     No   Sun  Dinner     2  0.139780
4         24.59  3.61  Female     No   Sun  Dinner     4  0.146808
..          ...   ...     ...    ...   ...     ...   ...       ...
239       29.03  5.92    Male     No   Sat  Dinner     3  0.203927
240       27.18  2.00  Female    Yes   Sat  Dinner     2  0.073584
241       22.67  2.00    Male    Yes   Sat  Dinner     2  0.088222
242       17.82  1.75    Male     No   Sat  Dinner     2  0.098204
243       18.78  3.00  Female     No  Thur  Dinner     2  0.159744

[244 rows x 8 columns]
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_sql.html, pandas.DataFrame.assign
"In [15]: frame = pd.DataFrame(
   ....:     {""col1"": [""A"", ""B"", np.nan, ""C"", ""D""], ""col2"": [""F"", np.nan, ""G"", ""H"", ""I""]}
   ....: )
   ....: 

In [16]: frame
Out[16]: 
  col1 col2
0    A    F
1    B  NaN
2  NaN    G
3    C    H
4    D    I
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_sql.html, pandas.DataFrame
"In [24]: df1 = pd.DataFrame({""key"": [""A"", ""B"", ""C"", ""D""], ""value"": np.random.randn(4)})

In [25]: df2 = pd.DataFrame({""key"": [""B"", ""D"", ""D"", ""E""], ""value"": np.random.randn(4)})
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_sql.html, pandas.DataFrame
"# merge performs an INNER JOIN by default
In [26]: pd.merge(df1, df2, on=""key"")
Out[26]: 
  key   value_x   value_y
0   B -0.282863  1.212112
1   D -1.135632 -0.173215
2   D -1.135632  0.119209
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_sql.html, pandas.merge
"In [27]: indexed_df2 = df2.set_index(""key"")

In [28]: pd.merge(df1, indexed_df2, left_on=""key"", right_index=True)
Out[28]: 
  key   value_x   value_y
1   B -0.282863  1.212112
3   D -1.135632 -0.173215
3   D -1.135632  0.119209
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_sql.html, pandas.DataFrame.set_index pandas.merge
"In [29]: pd.merge(df1, df2, on=""key"", how=""left"")
Out[29]: 
  key   value_x   value_y
0   A  0.469112       NaN
1   B -0.282863  1.212112
2   C -1.509059       NaN
3   D -1.135632 -0.173215
4   D -1.135632  0.119209
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_sql.html, pandas.merge
"In [30]: pd.merge(df1, df2, on=""key"", how=""right"")
Out[30]: 
  key   value_x   value_y
0   B -0.282863  1.212112
1   D -1.135632 -0.173215
2   D -1.135632  0.119209
3   E       NaN -1.044236
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_sql.html, pandas.merge
"In [31]: pd.merge(df1, df2, on=""key"", how=""outer"")
Out[31]: 
  key   value_x   value_y
0   A  0.469112       NaN
1   B -0.282863  1.212112
2   C -1.509059       NaN
3   D -1.135632 -0.173215
4   D -1.135632  0.119209
5   E       NaN -1.044236
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_sql.html, pandas.merge
"In [32]: df1 = pd.DataFrame(
   ....:     {""city"": [""Chicago"", ""San Francisco"", ""New York City""], ""rank"": range(1, 4)}
   ....: )
   ....: 

In [33]: df2 = pd.DataFrame(
   ....:     {""city"": [""Chicago"", ""Boston"", ""Los Angeles""], ""rank"": [1, 4, 5]}
   ....: )
   ....: 
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_sql.html, pandas.DataFrame
"In [34]: pd.concat([df1, df2])
Out[34]: 
            city  rank
0        Chicago     1
1  San Francisco     2
2  New York City     3
0        Chicago     1
1         Boston     4
2    Los Angeles     5
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_sql.html, pandas.concat
"In [35]: pd.concat([df1, df2]).drop_duplicates()
Out[35]: 
            city  rank
0        Chicago     1
1  San Francisco     2
2  New York City     3
1         Boston     4
2    Los Angeles     5
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_sql.html, pandas.concat
"In [38]: (
   ....:     tips.assign(
   ....:         rn=tips.sort_values([""total_bill""], ascending=False)
   ....:         .groupby([""day""])
   ....:         .cumcount()
   ....:         + 1
   ....:     )
   ....:     .query(""rn < 3"")
   ....:     .sort_values([""day"", ""rn""])
   ....: )
   ....: 
Out[38]: 
     total_bill    tip     sex smoker   day    time  size  rn
95        40.17   4.73    Male    Yes   Fri  Dinner     4   1
90        28.97   3.00    Male    Yes   Fri  Dinner     2   2
170       50.81  10.00    Male    Yes   Sat  Dinner     3   1
212       48.33   9.00    Male     No   Sat  Dinner     4   2
156       48.17   5.00    Male     No   Sun  Dinner     6   1
182       45.35   3.50    Male    Yes   Sun  Dinner     3   2
197       43.11   5.00  Female    Yes  Thur   Lunch     4   1
142       41.19   5.00    Male     No  Thur   Lunch     5   2
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_sql.html, pandas.DataFrame.assign pandas.DataFrame.query
"In [39]: (
   ....:     tips.assign(
   ....:         rnk=tips.groupby([""day""])[""total_bill""].rank(
   ....:             method=""first"", ascending=False
   ....:         )
   ....:     )
   ....:     .query(""rnk < 3"")
   ....:     .sort_values([""day"", ""rnk""])
   ....: )
   ....: 
Out[39]: 
     total_bill    tip     sex smoker   day    time  size  rnk
95        40.17   4.73    Male    Yes   Fri  Dinner     4  1.0
90        28.97   3.00    Male    Yes   Fri  Dinner     2  2.0
170       50.81  10.00    Male    Yes   Sat  Dinner     3  1.0
212       48.33   9.00    Male     No   Sat  Dinner     4  2.0
156       48.17   5.00    Male     No   Sun  Dinner     6  1.0
182       45.35   3.50    Male    Yes   Sun  Dinner     3  2.0
197       43.11   5.00  Female    Yes  Thur   Lunch     4  1.0
142       41.19   5.00    Male     No  Thur   Lunch     5  2.0
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_sql.html, pandas.DataFrame.assign pandas.DataFrame.query
"In [40]: (
   ....:     tips[tips[""tip""] < 2]
   ....:     .assign(rnk_min=tips.groupby([""sex""])[""tip""].rank(method=""min""))
   ....:     .query(""rnk_min < 3"")
   ....:     .sort_values([""sex"", ""rnk_min""])
   ....: )
   ....: 
Out[40]: 
     total_bill   tip     sex smoker  day    time  size  rnk_min
67         3.07  1.00  Female    Yes  Sat  Dinner     1      1.0
92         5.75  1.00  Female    Yes  Fri  Dinner     2      1.0
111        7.25  1.00  Female     No  Sat  Dinner     1      1.0
236       12.60  1.00    Male    Yes  Sat  Dinner     2      1.0
237       32.83  1.17    Male    Yes  Sat  Dinner     2      2.0
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_sql.html, pandas.DataFrame.assign pandas.DataFrame.query
">>> df = pd.DataFrame(np.random.randn(1000, 4), columns=['A','B','C','D'])
>>> pd.plotting.scatter_matrix(df, alpha=0.2)
array([[, ,
        , ],
       [, ,
        , ],
       [, ,
        , ],
       [, ,
        , ]],
      dtype=object)
",https://pandas.pydata.org/docs/reference/api/pandas.plotting.scatter_matrix.html, pandas.DataFrame pandas.plotting.scatter_matrix pandas.array
"In [2]: titanic = pd.read_csv(""data/titanic.csv"")

In [3]: titanic.head()
Out[3]: 
   PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked
0            1         0       3  ...   7.2500   NaN         S
1            2         1       1  ...  71.2833   C85         C
2            3         1       3  ...   7.9250   NaN         S
3            4         1       1  ...  53.1000  C123         S
4            5         0       3  ...   8.0500   NaN         S

[5 rows x 12 columns]
",https://pandas.pydata.org/docs/getting_started/intro_tutorials/07_reshape_table_layout.html, pandas.read_csv
"In [4]: air_quality = pd.read_csv(
   ...:     ""data/air_quality_long.csv"", index_col=""date.utc"", parse_dates=True
   ...: )
   ...: 

In [5]: air_quality.head()
Out[5]: 
                                city country location parameter  value   unit
date.utc                                                                     
2019-06-18 06:00:00+00:00  Antwerpen      BE  BETR801      pm25   18.0  µg/m³
2019-06-17 08:00:00+00:00  Antwerpen      BE  BETR801      pm25    6.5  µg/m³
2019-06-17 07:00:00+00:00  Antwerpen      BE  BETR801      pm25   18.5  µg/m³
2019-06-17 06:00:00+00:00  Antwerpen      BE  BETR801      pm25   16.0  µg/m³
2019-06-17 05:00:00+00:00  Antwerpen      BE  BETR801      pm25    7.5  µg/m³
",https://pandas.pydata.org/docs/getting_started/intro_tutorials/07_reshape_table_layout.html, pandas.read_csv
"In [2]: air_quality_no2 = pd.read_csv(""data/air_quality_no2_long.csv"",
   ...:                               parse_dates=True)
   ...: 

In [3]: air_quality_no2 = air_quality_no2[[""date.utc"", ""location"",
   ...:                                    ""parameter"", ""value""]]
   ...: 

In [4]: air_quality_no2.head()
Out[4]: 
                    date.utc location parameter  value
0  2019-06-21 00:00:00+00:00  FR04014       no2   20.0
1  2019-06-20 23:00:00+00:00  FR04014       no2   21.8
2  2019-06-20 22:00:00+00:00  FR04014       no2   26.5
3  2019-06-20 21:00:00+00:00  FR04014       no2   24.9
4  2019-06-20 20:00:00+00:00  FR04014       no2   21.4
",https://pandas.pydata.org/docs/getting_started/intro_tutorials/08_combine_dataframes.html, pandas.read_csv
"In [5]: air_quality_pm25 = pd.read_csv(""data/air_quality_pm25_long.csv"",
   ...:                                parse_dates=True)
   ...: 

In [6]: air_quality_pm25 = air_quality_pm25[[""date.utc"", ""location"",
   ...:                                      ""parameter"", ""value""]]
   ...: 

In [7]: air_quality_pm25.head()
Out[7]: 
                    date.utc location parameter  value
0  2019-06-18 06:00:00+00:00  BETR801      pm25   18.0
1  2019-06-17 08:00:00+00:00  BETR801      pm25    6.5
2  2019-06-17 07:00:00+00:00  BETR801      pm25   18.5
3  2019-06-17 06:00:00+00:00  BETR801      pm25   16.0
4  2019-06-17 05:00:00+00:00  BETR801      pm25    7.5
",https://pandas.pydata.org/docs/getting_started/intro_tutorials/08_combine_dataframes.html, pandas.read_csv
"In [8]: air_quality = pd.concat([air_quality_pm25, air_quality_no2], axis=0)

In [9]: air_quality.head()
Out[9]: 
                    date.utc location parameter  value
0  2019-06-18 06:00:00+00:00  BETR801      pm25   18.0
1  2019-06-17 08:00:00+00:00  BETR801      pm25    6.5
2  2019-06-17 07:00:00+00:00  BETR801      pm25   18.5
3  2019-06-17 06:00:00+00:00  BETR801      pm25   16.0
4  2019-06-17 05:00:00+00:00  BETR801      pm25    7.5
",https://pandas.pydata.org/docs/getting_started/intro_tutorials/08_combine_dataframes.html, pandas.concat
"In [15]: air_quality_ = pd.concat([air_quality_pm25, air_quality_no2], keys=[""PM25"", ""NO2""])

In [16]: air_quality_.head()
Out[16]: 
                         date.utc location parameter  value
PM25 0  2019-06-18 06:00:00+00:00  BETR801      pm25   18.0
     1  2019-06-17 08:00:00+00:00  BETR801      pm25    6.5
     2  2019-06-17 07:00:00+00:00  BETR801      pm25   18.5
     3  2019-06-17 06:00:00+00:00  BETR801      pm25   16.0
     4  2019-06-17 05:00:00+00:00  BETR801      pm25    7.5
",https://pandas.pydata.org/docs/getting_started/intro_tutorials/08_combine_dataframes.html, pandas.concat
"In [17]: stations_coord = pd.read_csv(""data/air_quality_stations.csv"")

In [18]: stations_coord.head()
Out[18]: 
  location  coordinates.latitude  coordinates.longitude
0  BELAL01              51.23619                4.38522
1  BELHB23              51.17030                4.34100
2  BELLD01              51.10998                5.00486
3  BELLD02              51.12038                5.02155
4  BELR833              51.32766                4.36226
",https://pandas.pydata.org/docs/getting_started/intro_tutorials/08_combine_dataframes.html, pandas.read_csv
"In [20]: air_quality = pd.merge(air_quality, stations_coord, how=""left"", on=""location"")

In [21]: air_quality.head()
Out[21]: 
                    date.utc  ... coordinates.longitude
0  2019-05-07 01:00:00+00:00  ...              -0.13193
1  2019-05-07 01:00:00+00:00  ...               2.39390
2  2019-05-07 01:00:00+00:00  ...               2.39390
3  2019-05-07 01:00:00+00:00  ...               4.43182
4  2019-05-07 01:00:00+00:00  ...               4.43182

[5 rows x 6 columns]
",https://pandas.pydata.org/docs/getting_started/intro_tutorials/08_combine_dataframes.html, pandas.merge
"In [22]: air_quality_parameters = pd.read_csv(""data/air_quality_parameters.csv"")

In [23]: air_quality_parameters.head()
Out[23]: 
     id                                        description  name
0    bc                                       Black Carbon    BC
1    co                                    Carbon Monoxide    CO
2   no2                                   Nitrogen Dioxide   NO2
3    o3                                              Ozone    O3
4  pm10  Particulate matter less than 10 micrometers in...  PM10
",https://pandas.pydata.org/docs/getting_started/intro_tutorials/08_combine_dataframes.html, pandas.read_csv
"In [24]: air_quality = pd.merge(air_quality, air_quality_parameters,
   ....:                        how='left', left_on='parameter', right_on='id')
   ....: 

In [25]: air_quality.head()
Out[25]: 
                    date.utc  ...   name
0  2019-05-07 01:00:00+00:00  ...    NO2
1  2019-05-07 01:00:00+00:00  ...    NO2
2  2019-05-07 01:00:00+00:00  ...    NO2
3  2019-05-07 01:00:00+00:00  ...  PM2.5
4  2019-05-07 01:00:00+00:00  ...    NO2

[5 rows x 9 columns]
",https://pandas.pydata.org/docs/getting_started/intro_tutorials/08_combine_dataframes.html, pandas.merge
"class Series:

    def head(self, n=5):
        """"""
        Return the first elements of the Series.

        This function is mainly useful to preview the values of the
        Series without displaying all of it.

        Parameters
        ----------
        n : int
            Number of values to return.

        Return
        ------
        pandas.Series
            Subset of the original series with the n first values.

        See Also
        --------
        tail : Return the last n elements of the Series.

        Examples
        --------
        >>> ser = pd.Series(['Ant', 'Bear', 'Cow', 'Dog', 'Falcon',
        ...                'Lion', 'Monkey', 'Rabbit', 'Zebra'])
        >>> ser.head()
        0   Ant
        1   Bear
        2   Cow
        3   Dog
        4   Falcon
        dtype: object

        With the ``n`` parameter, we can change the number of returned rows:

        >>> ser.head(n=3)
        0   Ant
        1   Bear
        2   Cow
        dtype: object
        """"""
        return self.iloc[:n]
",https://pandas.pydata.org/docs/development/contributing_docstring.html, pandas.Series
"class Series:

    def mean(self):
        """"""
        Compute the mean of the input.

        Examples
        --------
        >>> ser = pd.Series([1, 2, 3])
        >>> ser.mean()
        2
        """"""
        pass


    def fillna(self, value):
        """"""
        Replace missing values by ``value``.

        Examples
        --------
        >>> ser = pd.Series([1, np.nan, 3])
        >>> ser.fillna(0)
        [1, 0, 3]
        """"""
        pass

    def groupby_mean(self):
        """"""
        Group by index and return mean.

        Examples
        --------
        >>> ser = pd.Series([380., 370., 24., 26],
        ...               name='max_speed',
        ...               index=['falcon', 'falcon', 'parrot', 'parrot'])
        >>> ser.groupby_mean()
        index
        falcon    375.0
        parrot     25.0
        Name: max_speed, dtype: float64
        """"""
        pass

    def contains(self, pattern, case_sensitive=True, na=numpy.nan):
        """"""
        Return whether each value contains ``pattern``.

        In this case, we are illustrating how to use sections, even
        if the example is simple enough and does not require them.

        Examples
        --------
        >>> ser = pd.Series('Antelope', 'Lion', 'Zebra', np.nan)
        >>> ser.contains(pattern='a')
        0    False
        1    False
        2     True
        3      NaN
        dtype: bool

        **Case sensitivity**

        With ``case_sensitive`` set to ``False`` we can match ``a`` with both
        ``a`` and ``A``:

        >>> s.contains(pattern='a', case_sensitive=False)
        0     True
        1    False
        2     True
        3      NaN
        dtype: bool

        **Missing values**

        We can fill missing values in the output using the ``na`` parameter:

        >>> ser.contains(pattern='a', na=False)
        0    False
        1    False
        2     True
        3    False
        dtype: bool
        """"""
        pass
",https://pandas.pydata.org/docs/development/contributing_docstring.html, pandas.Series
"def method(foo=None, bar=None):
    """"""
    A sample DataFrame method.

    Do not import NumPy and pandas.

    Try to use meaningful data, when it makes the example easier
    to understand.

    Try to avoid positional arguments like in ``df.method(1)``. They
    can be all right if previously defined with a meaningful name,
    like in ``present_value(interest_rate)``, but avoid them otherwise.

    When presenting the behavior with different parameters, do not place
    all the calls one next to the other. Instead, add a short sentence
    explaining what the example shows.

    Examples
    --------
    >>> import numpy as np
    >>> import pandas as pd
    >>> df = pd.DataFrame(np.random.randn(3, 3),
    ...                   columns=('a', 'b', 'c'))
    >>> df.method(1)
    21
    >>> df.method(bar=14)
    123
    """"""
    pass
",https://pandas.pydata.org/docs/development/contributing_docstring.html, pandas.DataFrame
">>> np.random.seed(42)
>>> df = pd.DataFrame({'normal': np.random.normal(100, 5, 20)})
",https://pandas.pydata.org/docs/development/contributing_docstring.html, pandas.DataFrame
">>> df = pd.DataFrame([[1, 2, 3], [4, 5, 6]], index=['a', 'b', 'c'],
...                   columns=['A', 'B'])
",https://pandas.pydata.org/docs/development/contributing_docstring.html, pandas.DataFrame
">>> pd.to_datetime([""712-01-01""])
Traceback (most recent call last):
OutOfBoundsDatetime: Out of bounds nanosecond timestamp: 712-01-01 00:00:00
",https://pandas.pydata.org/docs/development/contributing_docstring.html, pandas.to_datetime
"class Series:
    def plot(self):
        """"""
        Generate a plot with the ``Series`` data.

        Examples
        --------

        .. plot::
            :context: close-figs

            >>> ser = pd.Series([1, 2, 3])
            >>> ser.plot()
        """"""
        pass
",https://pandas.pydata.org/docs/development/contributing_docstring.html, pandas.Series
"In [1]: import pandas as pd

In [2]: import numpy as np

In [3]: def make_timeseries(start=""2000-01-01"", end=""2000-12-31"", freq=""1D"", seed=None):
   ...:     index = pd.date_range(start=start, end=end, freq=freq, name=""timestamp"")
   ...:     n = len(index)
   ...:     state = np.random.RandomState(seed)
   ...:     columns = {
   ...:         ""name"": state.choice([""Alice"", ""Bob"", ""Charlie""], size=n),
   ...:         ""id"": state.poisson(1000, size=n),
   ...:         ""x"": state.rand(n) * 2 - 1,
   ...:         ""y"": state.rand(n) * 2 - 1,
   ...:     }
   ...:     df = pd.DataFrame(columns, index=index, columns=sorted(columns))
   ...:     if df.index[-1] == end:
   ...:         df = df.iloc[:-1]
   ...:     return df
   ...: 

In [4]: timeseries = [
   ...:     make_timeseries(freq=""1min"", seed=i).rename(columns=lambda x: f""{x}_{i}"")
   ...:     for i in range(10)
   ...: ]
   ...: 

In [5]: ts_wide = pd.concat(timeseries, axis=1)

In [6]: ts_wide.head()
Out[6]: 
                     id_0 name_0       x_0  ...   name_9       x_9       y_9
timestamp                                   ...                             
2000-01-01 00:00:00   977  Alice -0.821225  ...  Charlie -0.957208 -0.757508
2000-01-01 00:01:00  1018    Bob -0.219182  ...    Alice -0.414445 -0.100298
2000-01-01 00:02:00   927  Alice  0.660908  ...  Charlie -0.325838  0.581859
2000-01-01 00:03:00   997    Bob -0.852458  ...      Bob  0.992033 -0.686692
2000-01-01 00:04:00   965    Bob  0.717283  ...  Charlie -0.924556 -0.184161

[5 rows x 40 columns]

In [7]: ts_wide.to_parquet(""timeseries_wide.parquet"")
",https://pandas.pydata.org/docs/user_guide/scale.html, pandas.date_range pandas.DataFrame pandas.concat pandas.DataFrame.to_parquet
"In [8]: columns = [""id_0"", ""name_0"", ""x_0"", ""y_0""]

In [9]: pd.read_parquet(""timeseries_wide.parquet"")[columns]
Out[9]: 
                     id_0 name_0       x_0       y_0
timestamp                                           
2000-01-01 00:00:00   977  Alice -0.821225  0.906222
2000-01-01 00:01:00  1018    Bob -0.219182  0.350855
2000-01-01 00:02:00   927  Alice  0.660908 -0.798511
2000-01-01 00:03:00   997    Bob -0.852458  0.735260
2000-01-01 00:04:00   965    Bob  0.717283  0.393391
...                   ...    ...       ...       ...
2000-12-30 23:56:00  1037    Bob -0.814321  0.612836
2000-12-30 23:57:00   980    Bob  0.232195 -0.618828
2000-12-30 23:58:00   965  Alice -0.231131  0.026310
2000-12-30 23:59:00   984  Alice  0.942819  0.853128
2000-12-31 00:00:00  1003  Alice  0.201125 -0.136655

[525601 rows x 4 columns]
",https://pandas.pydata.org/docs/user_guide/scale.html, pandas.read_parquet
"In [10]: pd.read_parquet(""timeseries_wide.parquet"", columns=columns)
Out[10]: 
                     id_0 name_0       x_0       y_0
timestamp                                           
2000-01-01 00:00:00   977  Alice -0.821225  0.906222
2000-01-01 00:01:00  1018    Bob -0.219182  0.350855
2000-01-01 00:02:00   927  Alice  0.660908 -0.798511
2000-01-01 00:03:00   997    Bob -0.852458  0.735260
2000-01-01 00:04:00   965    Bob  0.717283  0.393391
...                   ...    ...       ...       ...
2000-12-30 23:56:00  1037    Bob -0.814321  0.612836
2000-12-30 23:57:00   980    Bob  0.232195 -0.618828
2000-12-30 23:58:00   965  Alice -0.231131  0.026310
2000-12-30 23:59:00   984  Alice  0.942819  0.853128
2000-12-31 00:00:00  1003  Alice  0.201125 -0.136655

[525601 rows x 4 columns]
",https://pandas.pydata.org/docs/user_guide/scale.html, pandas.read_parquet
"In [11]: ts = make_timeseries(freq=""30s"", seed=0)

In [12]: ts.to_parquet(""timeseries.parquet"")

In [13]: ts = pd.read_parquet(""timeseries.parquet"")

In [14]: ts
Out[14]: 
                       id     name         x         y
timestamp                                             
2000-01-01 00:00:00  1041    Alice  0.889987  0.281011
2000-01-01 00:00:30   988      Bob -0.455299  0.488153
2000-01-01 00:01:00  1018    Alice  0.096061  0.580473
2000-01-01 00:01:30   992      Bob  0.142482  0.041665
2000-01-01 00:02:00   960      Bob -0.036235  0.802159
...                   ...      ...       ...       ...
2000-12-30 23:58:00  1022    Alice  0.266191  0.875579
2000-12-30 23:58:30   974    Alice -0.009826  0.413686
2000-12-30 23:59:00  1028  Charlie  0.307108 -0.656789
2000-12-30 23:59:30  1002    Alice  0.202602  0.541335
2000-12-31 00:00:00   987    Alice  0.200832  0.615972

[1051201 rows x 4 columns]
",https://pandas.pydata.org/docs/user_guide/scale.html, pandas.DataFrame.to_parquet pandas.read_parquet
"In [20]: ts2[""id""] = pd.to_numeric(ts2[""id""], downcast=""unsigned"")

In [21]: ts2[[""x"", ""y""]] = ts2[[""x"", ""y""]].apply(pd.to_numeric, downcast=""float"")

In [22]: ts2.dtypes
Out[22]: 
id        uint16
name    category
x        float32
y        float32
dtype: object
",https://pandas.pydata.org/docs/user_guide/scale.html, pandas.to_numeric
"In [26]: import pathlib

In [27]: N = 12

In [28]: starts = [f""20{i:>02d}-01-01"" for i in range(N)]

In [29]: ends = [f""20{i:>02d}-12-13"" for i in range(N)]

In [30]: pathlib.Path(""data/timeseries"").mkdir(exist_ok=True)

In [31]: for i, (start, end) in enumerate(zip(starts, ends)):
   ....:     ts = make_timeseries(start=start, end=end, freq=""1min"", seed=i)
   ....:     ts.to_parquet(f""data/timeseries/ts-{i:0>2d}.parquet"")
   ....: 
",https://pandas.pydata.org/docs/user_guide/scale.html, pandas.DataFrame.to_parquet
"In [32]: %%time
   ....: files = pathlib.Path(""data/timeseries/"").glob(""ts*.parquet"")
   ....: counts = pd.Series(dtype=int)
   ....: for path in files:
   ....:     df = pd.read_parquet(path)
   ....:     counts = counts.add(df[""name""].value_counts(), fill_value=0)
   ....: counts.astype(int)
   ....: 
CPU times: user 760 ms, sys: 26.1 ms, total: 786 ms
Wall time: 559 ms
Out[32]: 
name
Alice      1994645
Bob        1993692
Charlie    1994875
dtype: int64
",https://pandas.pydata.org/docs/user_guide/scale.html, pandas.Series pandas.read_parquet
">>> df = pd.DataFrame(
...     {
...         'SepalLength': [6.5, 7.7, 5.1, 5.8, 7.6, 5.0, 5.4, 4.6, 6.7, 4.6],
...         'SepalWidth': [3.0, 3.8, 3.8, 2.7, 3.0, 2.3, 3.0, 3.2, 3.3, 3.6],
...         'PetalLength': [5.5, 6.7, 1.9, 5.1, 6.6, 3.3, 4.5, 1.4, 5.7, 1.0],
...         'PetalWidth': [1.8, 2.2, 0.4, 1.9, 2.1, 1.0, 1.5, 0.2, 2.1, 0.2],
...         'Category': [
...             'virginica',
...             'virginica',
...             'setosa',
...             'virginica',
...             'virginica',
...             'versicolor',
...             'versicolor',
...             'setosa',
...             'virginica',
...             'setosa'
...         ]
...     }
... )
>>> pd.plotting.radviz(df, 'Category')  
",https://pandas.pydata.org/docs/reference/api/pandas.plotting.radviz.html, pandas.DataFrame pandas.plotting.radviz
"In [2]: df = pd.DataFrame(
   ...:     {
   ...:         ""Name"": [
   ...:             ""Braund, Mr. Owen Harris"",
   ...:             ""Allen, Mr. William Henry"",
   ...:             ""Bonnell, Miss. Elizabeth"",
   ...:         ],
   ...:         ""Age"": [22, 35, 58],
   ...:         ""Sex"": [""male"", ""male"", ""female""],
   ...:     }
   ...: )
   ...: 

In [3]: df
Out[3]: 
                       Name  Age     Sex
0   Braund, Mr. Owen Harris   22    male
1  Allen, Mr. William Henry   35    male
2  Bonnell, Miss. Elizabeth   58  female
",https://pandas.pydata.org/docs/getting_started/intro_tutorials/01_table_oriented.html, pandas.DataFrame
"In [5]: ages = pd.Series([22, 35, 58], name=""Age"")

In [6]: ages
Out[6]: 
0    22
1    35
2    58
Name: Age, dtype: int64
",https://pandas.pydata.org/docs/getting_started/intro_tutorials/01_table_oriented.html, pandas.Series
"In [8]: ages.max()
Out[8]: 58
",https://pandas.pydata.org/docs/getting_started/intro_tutorials/01_table_oriented.html, pandas.Series.max
"In [9]: df.describe()
Out[9]: 
             Age
count   3.000000
mean   38.333333
std    18.230012
min    22.000000
25%    28.500000
50%    35.000000
75%    46.500000
max    58.000000
",https://pandas.pydata.org/docs/getting_started/intro_tutorials/01_table_oriented.html, pandas.DataFrame.describe
">>> df = pd.read_csv(
...     'https://raw.githubusercontent.com/pandas-dev/'
...     'pandas/main/pandas/tests/io/data/csv/iris.csv'
... )
>>> pd.plotting.andrews_curves(df, 'Name')  
",https://pandas.pydata.org/docs/reference/api/pandas.plotting.andrews_curves.html, pandas.read_csv pandas.plotting.andrews_curves
"In [3]: air_quality = pd.read_csv(""data/air_quality_no2.csv"", index_col=0, parse_dates=True)

In [4]: air_quality.head()
Out[4]: 
                     station_antwerp  station_paris  station_london
datetime                                                           
2019-05-07 02:00:00              NaN            NaN            23.0
2019-05-07 03:00:00             50.5           25.0            19.0
2019-05-07 04:00:00             45.0           27.7            19.0
2019-05-07 05:00:00              NaN           50.4            16.0
2019-05-07 06:00:00              NaN           61.9             NaN
",https://pandas.pydata.org/docs/getting_started/intro_tutorials/04_plotting.html, pandas.read_csv
"In [11]: [
   ....:     method_name
   ....:     for method_name in dir(air_quality.plot)
   ....:     if not method_name.startswith(""_"")
   ....: ]
   ....: 
Out[11]: 
['area',
 'bar',
 'barh',
 'box',
 'density',
 'hexbin',
 'hist',
 'kde',
 'line',
 'pie',
 'scatter']
",https://pandas.pydata.org/docs/getting_started/intro_tutorials/04_plotting.html, pandas.Series.str.startswith
"In [2]: titanic = pd.read_csv(""data/titanic.csv"")

In [3]: titanic.head()
Out[3]: 
   PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked
0            1         0       3  ...   7.2500   NaN         S
1            2         1       1  ...  71.2833   C85         C
2            3         1       3  ...   7.9250   NaN         S
3            4         1       1  ...  53.1000  C123         S
4            5         0       3  ...   8.0500   NaN         S

[5 rows x 12 columns]
",https://pandas.pydata.org/docs/getting_started/intro_tutorials/10_text_data.html, pandas.read_csv
"In [4]: titanic[""Name""].str.lower()
Out[4]: 
0                                braund, mr. owen harris
1      cumings, mrs. john bradley (florence briggs th...
2                                 heikkinen, miss. laina
3           futrelle, mrs. jacques heath (lily may peel)
4                               allen, mr. william henry
                             ...                        
886                                montvila, rev. juozas
887                         graham, miss. margaret edith
888             johnston, miss. catherine helen ""carrie""
889                                behr, mr. karl howell
890                                  dooley, mr. patrick
Name: Name, Length: 891, dtype: object
",https://pandas.pydata.org/docs/getting_started/intro_tutorials/10_text_data.html, pandas.Series.str.lower
"In [5]: titanic[""Name""].str.split("","")
Out[5]: 
0                             [Braund,  Mr. Owen Harris]
1      [Cumings,  Mrs. John Bradley (Florence Briggs ...
2                              [Heikkinen,  Miss. Laina]
3        [Futrelle,  Mrs. Jacques Heath (Lily May Peel)]
4                            [Allen,  Mr. William Henry]
                             ...                        
886                             [Montvila,  Rev. Juozas]
887                      [Graham,  Miss. Margaret Edith]
888          [Johnston,  Miss. Catherine Helen ""Carrie""]
889                             [Behr,  Mr. Karl Howell]
890                               [Dooley,  Mr. Patrick]
Name: Name, Length: 891, dtype: object
",https://pandas.pydata.org/docs/getting_started/intro_tutorials/10_text_data.html, pandas.Series.str.split
"In [6]: titanic[""Surname""] = titanic[""Name""].str.split("","").str.get(0)

In [7]: titanic[""Surname""]
Out[7]: 
0         Braund
1        Cumings
2      Heikkinen
3       Futrelle
4          Allen
         ...    
886     Montvila
887       Graham
888     Johnston
889         Behr
890       Dooley
Name: Surname, Length: 891, dtype: object
",https://pandas.pydata.org/docs/getting_started/intro_tutorials/10_text_data.html, pandas.Series.str.split
"In [3]: air_quality = pd.read_csv(""data/air_quality_no2_long.csv"")

In [4]: air_quality = air_quality.rename(columns={""date.utc"": ""datetime""})

In [5]: air_quality.head()
Out[5]: 
    city country                   datetime location parameter  value   unit
0  Paris      FR  2019-06-21 00:00:00+00:00  FR04014       no2   20.0  µg/m³
1  Paris      FR  2019-06-20 23:00:00+00:00  FR04014       no2   21.8  µg/m³
2  Paris      FR  2019-06-20 22:00:00+00:00  FR04014       no2   26.5  µg/m³
3  Paris      FR  2019-06-20 21:00:00+00:00  FR04014       no2   24.9  µg/m³
4  Paris      FR  2019-06-20 20:00:00+00:00  FR04014       no2   21.4  µg/m³
",https://pandas.pydata.org/docs/getting_started/intro_tutorials/09_timeseries.html, pandas.read_csv
"In [6]: air_quality.city.unique()
Out[6]: array(['Paris', 'Antwerpen', 'London'], dtype=object)
",https://pandas.pydata.org/docs/getting_started/intro_tutorials/09_timeseries.html, pandas.array
"In [7]: air_quality[""datetime""] = pd.to_datetime(air_quality[""datetime""])

In [8]: air_quality[""datetime""]
Out[8]: 
0      2019-06-21 00:00:00+00:00
1      2019-06-20 23:00:00+00:00
2      2019-06-20 22:00:00+00:00
3      2019-06-20 21:00:00+00:00
4      2019-06-20 20:00:00+00:00
                  ...           
2063   2019-05-07 06:00:00+00:00
2064   2019-05-07 04:00:00+00:00
2065   2019-05-07 03:00:00+00:00
2066   2019-05-07 02:00:00+00:00
2067   2019-05-07 01:00:00+00:00
Name: datetime, Length: 2068, dtype: datetime64[ns, UTC]
",https://pandas.pydata.org/docs/getting_started/intro_tutorials/09_timeseries.html, pandas.to_datetime
"pd.read_csv(""../data/air_quality_no2_long.csv"", parse_dates=[""datetime""])
",https://pandas.pydata.org/docs/getting_started/intro_tutorials/09_timeseries.html, pandas.read_csv
"In [20]: no_2.index.year, no_2.index.weekday
Out[20]: 
(Index([2019, 2019, 2019, 2019, 2019, 2019, 2019, 2019, 2019, 2019,
        ...
        2019, 2019, 2019, 2019, 2019, 2019, 2019, 2019, 2019, 2019],
       dtype='int32', name='datetime', length=1033),
 Index([1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        ...
        3, 3, 3, 3, 3, 3, 3, 3, 3, 4],
       dtype='int32', name='datetime', length=1033))
",https://pandas.pydata.org/docs/getting_started/intro_tutorials/09_timeseries.html, pandas.Index
"In [1]: index = pd.MultiIndex.from_product(
   ...:     [range(3), [""one"", ""two""]], names=[""first"", ""second""]
   ...: )
   ...: 

In [2]: index
Out[2]: 
MultiIndex([(0, 'one'),
            (0, 'two'),
            (1, 'one'),
            (1, 'two'),
            (2, 'one'),
            (2, 'two')],
           names=['first', 'second'])

In [3]: index.levels
Out[3]: FrozenList([[0, 1, 2], ['one', 'two']])

In [4]: index.codes
Out[4]: FrozenList([[0, 0, 1, 1, 2, 2], [0, 1, 0, 1, 0, 1]])

In [5]: index.names
Out[5]: FrozenList(['first', 'second'])
",https://pandas.pydata.org/docs/development/internals.html, pandas.MultiIndex.from_product pandas.MultiIndex
">>> np.random.seed(1234)
>>> df = pd.DataFrame(np.random.randn(10, 4),
...                   columns=['Col1', 'Col2', 'Col3', 'Col4'])
>>> boxplot = df.boxplot(column=['Col1', 'Col2', 'Col3'])  
",https://pandas.pydata.org/docs/reference/api/pandas.plotting.boxplot.html, pandas.DataFrame pandas.DataFrame.boxplot
">>> df = pd.DataFrame(np.random.randn(10, 2),
...                   columns=['Col1', 'Col2'])
>>> df['X'] = pd.Series(['A', 'A', 'A', 'A', 'A',
...                      'B', 'B', 'B', 'B', 'B'])
>>> boxplot = df.boxplot(by='X')
",https://pandas.pydata.org/docs/reference/api/pandas.plotting.boxplot.html, pandas.DataFrame pandas.Series pandas.DataFrame.boxplot
">>> df = pd.DataFrame(np.random.randn(10, 3),
...                   columns=['Col1', 'Col2', 'Col3'])
>>> df['X'] = pd.Series(['A', 'A', 'A', 'A', 'A',
...                      'B', 'B', 'B', 'B', 'B'])
>>> df['Y'] = pd.Series(['A', 'B', 'A', 'B', 'A',
...                      'B', 'A', 'B', 'A', 'B'])
>>> boxplot = df.boxplot(column=['Col1', 'Col2'], by=['X', 'Y'])
",https://pandas.pydata.org/docs/reference/api/pandas.plotting.boxplot.html, pandas.DataFrame pandas.Series pandas.DataFrame.boxplot
">>> boxplot = df.boxplot(column=['Col1', 'Col2'], by='X',
...                      layout=(2, 1))
",https://pandas.pydata.org/docs/reference/api/pandas.plotting.boxplot.html, pandas.DataFrame.boxplot
">>> boxplot = df.boxplot(grid=False, rot=45, fontsize=15)  
",https://pandas.pydata.org/docs/reference/api/pandas.plotting.boxplot.html, pandas.DataFrame.boxplot
">>> boxplot = df.boxplot(column=['Col1', 'Col2'], return_type='axes')
>>> type(boxplot)

",https://pandas.pydata.org/docs/reference/api/pandas.plotting.boxplot.html, pandas.DataFrame.boxplot
">>> boxplot = df.boxplot(column=['Col1', 'Col2'], by='X',
...                      return_type='axes')
>>> type(boxplot)

",https://pandas.pydata.org/docs/reference/api/pandas.plotting.boxplot.html, pandas.DataFrame.boxplot
">>> boxplot = df.boxplot(column=['Col1', 'Col2'], by='X',
...                      return_type=None)
>>> type(boxplot)

",https://pandas.pydata.org/docs/reference/api/pandas.plotting.boxplot.html, pandas.DataFrame.boxplot
">>> mask = pd.array([True, False])
>>> arr = pd.array([1, 2])
>>> pd.api.indexers.check_array_indexer(arr, mask)
array([ True, False])
",https://pandas.pydata.org/docs/reference/api/pandas.api.indexers.check_array_indexer.html, pandas.array pandas.api.indexers.check_array_indexer pandas.array
">>> mask = pd.array([True, False, True])
>>> pd.api.indexers.check_array_indexer(arr, mask)
Traceback (most recent call last):
...
IndexError: Boolean index has wrong length: 3 instead of 2.
",https://pandas.pydata.org/docs/reference/api/pandas.api.indexers.check_array_indexer.html, pandas.array pandas.api.indexers.check_array_indexer
">>> mask = pd.array([True, pd.NA])
>>> pd.api.indexers.check_array_indexer(arr, mask)
array([ True, False])
",https://pandas.pydata.org/docs/reference/api/pandas.api.indexers.check_array_indexer.html, pandas.array pandas.api.indexers.check_array_indexer pandas.array
">>> mask = np.array([True, False])
>>> pd.api.indexers.check_array_indexer(arr, mask)
array([ True, False])
",https://pandas.pydata.org/docs/reference/api/pandas.api.indexers.check_array_indexer.html, pandas.api.indexers.check_array_indexer pandas.array
">>> indexer = pd.array([0, 2], dtype=""Int64"")
>>> arr = pd.array([1, 2, 3])
>>> pd.api.indexers.check_array_indexer(arr, indexer)
array([0, 2])
",https://pandas.pydata.org/docs/reference/api/pandas.api.indexers.check_array_indexer.html, pandas.array pandas.api.indexers.check_array_indexer pandas.array
">>> indexer = pd.array([0, pd.NA], dtype=""Int64"")
>>> pd.api.indexers.check_array_indexer(arr, indexer)
Traceback (most recent call last):
...
ValueError: Cannot index with an integer indexer containing NA values
",https://pandas.pydata.org/docs/reference/api/pandas.api.indexers.check_array_indexer.html, pandas.array pandas.api.indexers.check_array_indexer
">>> indexer = np.array([0., 2.], dtype=""float64"")
>>> pd.api.indexers.check_array_indexer(arr, indexer)
Traceback (most recent call last):
...
IndexError: arrays used as indices must be of integer or boolean type
",https://pandas.pydata.org/docs/reference/api/pandas.api.indexers.check_array_indexer.html, pandas.api.indexers.check_array_indexer
"In [1]: df = pd.DataFrame(np.random.randn(10, 3), columns=list(""abc""))

In [2]: df[[""a"", ""c""]]
Out[2]: 
          a         c
0  0.469112 -1.509059
1 -1.135632 -0.173215
2  0.119209 -0.861849
3 -2.104569  1.071804
4  0.721555 -1.039575
5  0.271860  0.567020
6  0.276232 -0.673690
7  0.113648  0.524988
8  0.404705 -1.715002
9 -1.039268 -1.157892

In [3]: df.loc[:, [""a"", ""c""]]
Out[3]: 
          a         c
0  0.469112 -1.509059
1 -1.135632 -0.173215
2  0.119209 -0.861849
3 -2.104569  1.071804
4  0.721555 -1.039575
5  0.271860  0.567020
6  0.276232 -0.673690
7  0.113648  0.524988
8  0.404705 -1.715002
9 -1.039268 -1.157892
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_r.html, pandas.DataFrame
"In [4]: named = list(""abcdefg"")

In [5]: n = 30

In [6]: columns = named + np.arange(len(named), n).tolist()

In [7]: df = pd.DataFrame(np.random.randn(n, n), columns=columns)

In [8]: df.iloc[:, np.r_[:10, 24:30]]
Out[8]: 
           a         b         c  ...        27        28        29
0  -1.344312  0.844885  1.075770  ...  0.813850  0.132003 -0.827317
1  -0.076467 -1.187678  1.130127  ...  0.149748 -0.732339  0.687738
2   0.176444  0.403310 -0.154951  ... -0.493662  0.600178  0.274230
3   0.132885 -0.023688  2.410179  ...  0.109121  1.126203 -0.977349
4   1.474071 -0.064034 -1.282782  ... -0.858447  0.306996 -0.028665
..       ...       ...       ...  ...       ...       ...       ...
25  1.492125 -0.068190  0.681456  ...  0.428572  0.880609  0.487645
26  0.725238  0.624607 -0.141185  ...  1.008500  1.424017  0.717110
27  1.262419  1.950057  0.301038  ...  1.007824  2.826008  1.458383
28 -1.585746 -0.899734  0.921494  ...  0.577223 -1.088417  0.326687
29 -0.986248  0.169729 -1.158091  ... -2.013086 -1.602549  0.333109

[30 rows x 16 columns]
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_r.html, pandas.api.extensions.ExtensionArray.tolist pandas.DataFrame
"In [9]: df = pd.DataFrame(
   ...:     {
   ...:         ""v1"": [1, 3, 5, 7, 8, 3, 5, np.nan, 4, 5, 7, 9],
   ...:         ""v2"": [11, 33, 55, 77, 88, 33, 55, np.nan, 44, 55, 77, 99],
   ...:         ""by1"": [""red"", ""blue"", 1, 2, np.nan, ""big"", 1, 2, ""red"", 1, np.nan, 12],
   ...:         ""by2"": [
   ...:             ""wet"",
   ...:             ""dry"",
   ...:             99,
   ...:             95,
   ...:             np.nan,
   ...:             ""damp"",
   ...:             95,
   ...:             99,
   ...:             ""red"",
   ...:             99,
   ...:             np.nan,
   ...:             np.nan,
   ...:         ],
   ...:     }
   ...: )
   ...: 

In [10]: g = df.groupby([""by1"", ""by2""])

In [11]: g[[""v1"", ""v2""]].mean()
Out[11]: 
            v1    v2
by1  by2            
1    95    5.0  55.0
     99    5.0  55.0
2    95    7.0  77.0
     99    NaN   NaN
big  damp  3.0  33.0
blue dry   3.0  33.0
red  red   4.0  44.0
     wet   1.0  11.0
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_r.html, pandas.DataFrame pandas.DataFrame.groupby
"In [12]: s = pd.Series(np.arange(5), dtype=np.float32)

In [13]: s.isin([2, 4])
Out[13]: 
0    False
1    False
2     True
3    False
4     True
dtype: bool
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_r.html, pandas.Series pandas.Series.isin
"s <- 0:4
match(s, c(2,4))
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_r.html, pandas.Series.str.match
"In [14]: import random

In [15]: import string

In [16]: baseball = pd.DataFrame(
   ....:     {
   ....:         ""team"": [""team %d"" % (x + 1) for x in range(5)] * 5,
   ....:         ""player"": random.sample(list(string.ascii_lowercase), 25),
   ....:         ""batting avg"": np.random.uniform(0.200, 0.400, 25),
   ....:     }
   ....: )
   ....: 

In [17]: baseball.pivot_table(values=""batting avg"", columns=""team"", aggfunc=""max"")
Out[17]: 
team           team 1    team 2    team 3    team 4    team 5
batting avg  0.352134  0.295327  0.397191  0.394457  0.396194
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_r.html, pandas.DataFrame pandas.DataFrame.pivot_table
"In [18]: df = pd.DataFrame({""a"": np.random.randn(10), ""b"": np.random.randn(10)})

In [19]: df.query(""a <= b"")
Out[19]: 
          a         b
1  0.174950  0.552887
2 -0.023167  0.148084
3 -0.495291 -0.300218
4 -0.860736  0.197378
5 -1.134146  1.720780
7 -0.290098  0.083515
8  0.238636  0.946550

In [20]: df[df[""a""] <= df[""b""]]
Out[20]: 
          a         b
1  0.174950  0.552887
2 -0.023167  0.148084
3 -0.495291 -0.300218
4 -0.860736  0.197378
5 -1.134146  1.720780
7 -0.290098  0.083515
8  0.238636  0.946550

In [21]: df.loc[df[""a""] <= df[""b""]]
Out[21]: 
          a         b
1  0.174950  0.552887
2 -0.023167  0.148084
3 -0.495291 -0.300218
4 -0.860736  0.197378
5 -1.134146  1.720780
7 -0.290098  0.083515
8  0.238636  0.946550
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_r.html, pandas.DataFrame pandas.DataFrame.query
"In [22]: df = pd.DataFrame({""a"": np.random.randn(10), ""b"": np.random.randn(10)})

In [23]: df.eval(""a + b"")
Out[23]: 
0   -0.091430
1   -2.483890
2   -0.252728
3   -0.626444
4   -0.261740
5    2.149503
6   -0.332214
7    0.799331
8   -2.377245
9    2.104677
dtype: float64

In [24]: df[""a""] + df[""b""]  # same as the previous expression
Out[24]: 
0   -0.091430
1   -2.483890
2   -0.252728
3   -0.626444
4   -0.261740
5    2.149503
6   -0.332214
7    0.799331
8   -2.377245
9    2.104677
dtype: float64
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_r.html, pandas.DataFrame pandas.DataFrame.eval
"In [25]: df = pd.DataFrame(
   ....:     {
   ....:         ""x"": np.random.uniform(1.0, 168.0, 120),
   ....:         ""y"": np.random.uniform(7.0, 334.0, 120),
   ....:         ""z"": np.random.uniform(1.7, 20.7, 120),
   ....:         ""month"": [5, 6, 7, 8] * 30,
   ....:         ""week"": np.random.randint(1, 4, 120),
   ....:     }
   ....: )
   ....: 

In [26]: grouped = df.groupby([""month"", ""week""])

In [27]: grouped[""x""].agg([""mean"", ""std""])
Out[27]: 
                  mean        std
month week                       
5     1      63.653367  40.601965
      2      78.126605  53.342400
      3      92.091886  57.630110
6     1      81.747070  54.339218
      2      70.971205  54.687287
      3     100.968344  54.010081
7     1      61.576332  38.844274
      2      61.733510  48.209013
      3      71.688795  37.595638
8     1      62.741922  34.618153
      2      91.774627  49.790202
      3      73.936856  60.773900
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_r.html, pandas.DataFrame pandas.DataFrame.groupby
"a <- array(c(1:23, NA), c(2,3,4))
data.frame(melt(a))
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_r.html, pandas.array
"In [28]: a = np.array(list(range(1, 24)) + [np.NAN]).reshape(2, 3, 4)

In [29]: pd.DataFrame([tuple(list(x) + [val]) for x, val in np.ndenumerate(a)])
Out[29]: 
    0  1  2     3
0   0  0  0   1.0
1   0  0  1   2.0
2   0  0  2   3.0
3   0  0  3   4.0
4   0  1  0   5.0
.. .. .. ..   ...
19  1  1  3  20.0
20  1  2  0  21.0
21  1  2  1  22.0
22  1  2  2  23.0
23  1  2  3   NaN

[24 rows x 4 columns]
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_r.html, pandas.DataFrame
"In [30]: a = list(enumerate(list(range(1, 5)) + [np.NAN]))

In [31]: pd.DataFrame(a)
Out[31]: 
   0    1
0  0  1.0
1  1  2.0
2  2  3.0
3  3  4.0
4  4  NaN
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_r.html, pandas.DataFrame
"In [32]: cheese = pd.DataFrame(
   ....:     {
   ....:         ""first"": [""John"", ""Mary""],
   ....:         ""last"": [""Doe"", ""Bo""],
   ....:         ""height"": [5.5, 6.0],
   ....:         ""weight"": [130, 150],
   ....:     }
   ....: )
   ....: 

In [33]: pd.melt(cheese, id_vars=[""first"", ""last""])
Out[33]: 
  first last variable  value
0  John  Doe   height    5.5
1  Mary   Bo   height    6.0
2  John  Doe   weight  130.0
3  Mary   Bo   weight  150.0

In [34]: cheese.set_index([""first"", ""last""]).stack(future_stack=True)  # alternative way
Out[34]: 
first  last        
John   Doe   height      5.5
             weight    130.0
Mary   Bo    height      6.0
             weight    150.0
dtype: float64
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_r.html, pandas.DataFrame pandas.melt pandas.DataFrame.set_index pandas.DataFrame.stack
"In [35]: df = pd.DataFrame(
   ....:     {
   ....:         ""x"": np.random.uniform(1.0, 168.0, 12),
   ....:         ""y"": np.random.uniform(7.0, 334.0, 12),
   ....:         ""z"": np.random.uniform(1.7, 20.7, 12),
   ....:         ""month"": [5, 6, 7] * 4,
   ....:         ""week"": [1, 2] * 6,
   ....:     }
   ....: )
   ....: 

In [36]: mdf = pd.melt(df, id_vars=[""month"", ""week""])

In [37]: pd.pivot_table(
   ....:     mdf,
   ....:     values=""value"",
   ....:     index=[""variable"", ""week""],
   ....:     columns=[""month""],
   ....:     aggfunc=""mean"",
   ....: )
   ....: 
Out[37]: 
month                  5           6           7
variable week                                   
x        1     93.888747   98.762034   55.219673
         2     94.391427   38.112932   83.942781
y        1     94.306912  279.454811  227.840449
         2     87.392662  193.028166  173.899260
z        1     11.016009   10.079307   16.170549
         2      8.476111   17.638509   19.003494
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_r.html, pandas.DataFrame pandas.melt pandas.pivot_table
"In [38]: df = pd.DataFrame(
   ....:     {
   ....:         ""Animal"": [
   ....:             ""Animal1"",
   ....:             ""Animal2"",
   ....:             ""Animal3"",
   ....:             ""Animal2"",
   ....:             ""Animal1"",
   ....:             ""Animal2"",
   ....:             ""Animal3"",
   ....:         ],
   ....:         ""FeedType"": [""A"", ""B"", ""A"", ""A"", ""B"", ""B"", ""A""],
   ....:         ""Amount"": [10, 7, 4, 2, 5, 6, 2],
   ....:     }
   ....: )
   ....: 

In [39]: df.pivot_table(values=""Amount"", index=""Animal"", columns=""FeedType"", aggfunc=""sum"")
Out[39]: 
FeedType     A     B
Animal              
Animal1   10.0   5.0
Animal2    2.0  13.0
Animal3    6.0   NaN
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_r.html, pandas.DataFrame pandas.DataFrame.pivot_table
"In [40]: df.groupby([""Animal"", ""FeedType""])[""Amount""].sum()
Out[40]: 
Animal   FeedType
Animal1  A           10
         B            5
Animal2  A            2
         B           13
Animal3  A            6
Name: Amount, dtype: int64
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_r.html, pandas.DataFrame.groupby
"cut(c(1,2,3,4,5,6), 3)
factor(c(1,2,3,2,2,3))
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_r.html, pandas.cut
"In [41]: pd.cut(pd.Series([1, 2, 3, 4, 5, 6]), 3)
Out[41]: 
0    (0.995, 2.667]
1    (0.995, 2.667]
2    (2.667, 4.333]
3    (2.667, 4.333]
4      (4.333, 6.0]
5      (4.333, 6.0]
dtype: category
Categories (3, interval[float64, right]): [(0.995, 2.667] < (2.667, 4.333] < (4.333, 6.0]]

In [42]: pd.Series([1, 2, 3, 2, 2, 3]).astype(""category"")
Out[42]: 
0    1
1    2
2    3
3    2
4    2
5    3
dtype: category
Categories (3, int64): [1, 2, 3]
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_r.html, pandas.cut pandas.Series
">>> from pandas.tseries.frequencies import to_offset
>>> to_offset(""5min"")
<5 * Minutes>
",https://pandas.pydata.org/docs/reference/api/pandas.tseries.frequencies.to_offset.html, pandas.tseries.frequencies.to_offset
">>> to_offset(""1D1h"")
<25 * Hours>
",https://pandas.pydata.org/docs/reference/api/pandas.tseries.frequencies.to_offset.html, pandas.tseries.frequencies.to_offset
">>> to_offset(""2W"")
<2 * Weeks: weekday=6>
",https://pandas.pydata.org/docs/reference/api/pandas.tseries.frequencies.to_offset.html, pandas.tseries.frequencies.to_offset
">>> to_offset(""2B"")
<2 * BusinessDays>
",https://pandas.pydata.org/docs/reference/api/pandas.tseries.frequencies.to_offset.html, pandas.tseries.frequencies.to_offset
">>> to_offset(pd.Timedelta(days=1))

",https://pandas.pydata.org/docs/reference/api/pandas.tseries.frequencies.to_offset.html, pandas.tseries.frequencies.to_offset
">>> to_offset(pd.offsets.Hour())

",https://pandas.pydata.org/docs/reference/api/pandas.tseries.frequencies.to_offset.html, pandas.tseries.frequencies.to_offset
"In [2]: titanic = pd.read_csv(""data/titanic.csv"")

In [3]: titanic.head()
Out[3]: 
   PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked
0            1         0       3  ...   7.2500   NaN         S
1            2         1       1  ...  71.2833   C85         C
2            3         1       3  ...   7.9250   NaN         S
3            4         1       1  ...  53.1000  C123         S
4            5         0       3  ...   8.0500   NaN         S

[5 rows x 12 columns]
",https://pandas.pydata.org/docs/getting_started/intro_tutorials/03_subset_data.html, pandas.read_csv
"In [4]: ages = titanic[""Age""]

In [5]: ages.head()
Out[5]: 
0    22.0
1    38.0
2    26.0
3    35.0
4    35.0
Name: Age, dtype: float64
",https://pandas.pydata.org/docs/getting_started/intro_tutorials/03_subset_data.html, pandas.Series.head
">>> pd.Series(['a', 'b']).dt
Traceback (most recent call last):
...
AttributeError: Can only use .dt accessor with datetimelike values
",https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.register_dataframe_accessor.html, pandas.Series
"import pandas as pd

@pd.api.extensions.register_dataframe_accessor(""geo"")
class GeoAccessor:
    def __init__(self, pandas_obj):
        self._obj = pandas_obj

    @property
    def center(self):
        # return the geographic center point of this DataFrame
        lat = self._obj.latitude
        lon = self._obj.longitude
        return (float(lon.mean()), float(lat.mean()))

    def plot(self):
        # plot this array's data on a map, e.g., using Cartopy
        pass
",https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.register_dataframe_accessor.html, pandas.api.extensions.register_dataframe_accessor pandas.Series.str.center
"In [1]: ds = pd.DataFrame({""longitude"": np.linspace(0, 10),
   ...:                    ""latitude"": np.linspace(0, 20)})
In [2]: ds.geo.center
Out[2]: (5.0, 10.0)
In [3]: ds.geo.plot()  # plots data on a map
",https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.register_dataframe_accessor.html, pandas.DataFrame
">>> pd.Series(['a', 'b']).dt
Traceback (most recent call last):
...
AttributeError: Can only use .dt accessor with datetimelike values
",https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.register_series_accessor.html, pandas.Series
"import pandas as pd

@pd.api.extensions.register_dataframe_accessor(""geo"")
class GeoAccessor:
    def __init__(self, pandas_obj):
        self._obj = pandas_obj

    @property
    def center(self):
        # return the geographic center point of this DataFrame
        lat = self._obj.latitude
        lon = self._obj.longitude
        return (float(lon.mean()), float(lat.mean()))

    def plot(self):
        # plot this array's data on a map, e.g., using Cartopy
        pass
",https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.register_series_accessor.html, pandas.api.extensions.register_dataframe_accessor pandas.Series.str.center
"In [1]: ds = pd.DataFrame({""longitude"": np.linspace(0, 10),
   ...:                    ""latitude"": np.linspace(0, 20)})
In [2]: ds.geo.center
Out[2]: (5.0, 10.0)
In [3]: ds.geo.plot()  # plots data on a map
",https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.register_series_accessor.html, pandas.DataFrame
"sorted_df = df.sort_values(""col1"")
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_sas.html, pandas.DataFrame.sort_values
"df = df.sort_values(""col1"")
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_sas.html, pandas.DataFrame.sort_values
"df.replace(5, inplace=True)
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_sas.html, pandas.DataFrame.replace
"In [1]: df = pd.DataFrame({""x"": [1, 3, 5], ""y"": [2, 4, 6]})

In [2]: df
Out[2]: 
   x  y
0  1  2
1  3  4
2  5  6
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_sas.html, pandas.DataFrame
"In [3]: url = (
   ...:     ""https://raw.githubusercontent.com/pandas-dev/""
   ...:     ""pandas/main/pandas/tests/io/data/csv/tips.csv""
   ...: )
   ...: 

In [4]: tips = pd.read_csv(url)

In [5]: tips
Out[5]: 
     total_bill   tip     sex smoker   day    time  size
0         16.99  1.01  Female     No   Sun  Dinner     2
1         10.34  1.66    Male     No   Sun  Dinner     3
2         21.01  3.50    Male     No   Sun  Dinner     3
3         23.68  3.31    Male     No   Sun  Dinner     2
4         24.59  3.61  Female     No   Sun  Dinner     4
..          ...   ...     ...    ...   ...     ...   ...
239       29.03  5.92    Male     No   Sat  Dinner     3
240       27.18  2.00  Female    Yes   Sat  Dinner     2
241       22.67  2.00    Male    Yes   Sat  Dinner     2
242       17.82  1.75    Male     No   Sat  Dinner     2
243       18.78  3.00  Female     No  Thur  Dinner     2

[244 rows x 7 columns]
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_sas.html, pandas.read_csv
"tips = pd.read_csv(""tips.csv"", sep=""\t"", header=None)

# alternatively, read_table is an alias to read_csv with tab delimiter
tips = pd.read_table(""tips.csv"", header=None)
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_sas.html, pandas.read_csv pandas.read_table
"data _null_;
set tips;
put(LENGTHN(time));
put(LENGTHC(time));
run;
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_sas.html, pandas.HDFStore.put
"In [1]: tips[""time""].str.len()
Out[1]: 
67     6
92     6
111    6
145    5
135    5
      ..
182    6
156    6
59     6
212    6
170    6
Name: time, Length: 244, dtype: int64

In [2]: tips[""time""].str.rstrip().str.len()
Out[2]: 
67     6
92     6
111    6
145    5
135    5
      ..
182    6
156    6
59     6
212    6
170    6
Name: time, Length: 244, dtype: int64
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_sas.html, pandas.Series.str.rstrip
"data _null_;
set tips;
put(FINDW(sex,'ale'));
run;
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_sas.html, pandas.HDFStore.put
"In [1]: tips[""sex""].str.find(""ale"")
Out[1]: 
67     3
92     3
111    3
145    3
135    3
      ..
182    1
156    1
59     1
212    1
170    1
Name: sex, Length: 244, dtype: int64
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_sas.html, pandas.Series.str.find
"data _null_;
set tips;
put(substr(sex,1,1));
run;
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_sas.html, pandas.HDFStore.put
"In [1]: firstlast = pd.DataFrame({""String"": [""John Smith"", ""Jane Cook""]})

In [2]: firstlast[""First_Name""] = firstlast[""String""].str.split("" "", expand=True)[0]

In [3]: firstlast[""Last_Name""] = firstlast[""String""].str.rsplit("" "", expand=True)[1]

In [4]: firstlast
Out[4]: 
       String First_Name Last_Name
0  John Smith       John     Smith
1   Jane Cook       Jane      Cook
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_sas.html, pandas.DataFrame pandas.Series.str.split pandas.Series.str.rsplit
"In [1]: firstlast = pd.DataFrame({""string"": [""John Smith"", ""Jane Cook""]})

In [2]: firstlast[""upper""] = firstlast[""string""].str.upper()

In [3]: firstlast[""lower""] = firstlast[""string""].str.lower()

In [4]: firstlast[""title""] = firstlast[""string""].str.title()

In [5]: firstlast
Out[5]: 
       string       upper       lower       title
0  John Smith  JOHN SMITH  john smith  John Smith
1   Jane Cook   JANE COOK   jane cook   Jane Cook
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_sas.html, pandas.DataFrame pandas.Series.str.upper pandas.Series.str.lower pandas.Series.str.title
"In [1]: df1 = pd.DataFrame({""key"": [""A"", ""B"", ""C"", ""D""], ""value"": np.random.randn(4)})

In [2]: df1
Out[2]: 
  key     value
0   A  0.469112
1   B -0.282863
2   C -1.509059
3   D -1.135632

In [3]: df2 = pd.DataFrame({""key"": [""B"", ""D"", ""D"", ""E""], ""value"": np.random.randn(4)})

In [4]: df2
Out[4]: 
  key     value
0   B  1.212112
1   D -0.173215
2   D  0.119209
3   E -1.044236
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_sas.html, pandas.DataFrame
"In [1]: inner_join = df1.merge(df2, on=[""key""], how=""inner"")

In [2]: inner_join
Out[2]: 
  key   value_x   value_y
0   B -0.282863  1.212112
1   D -1.135632 -0.173215
2   D -1.135632  0.119209

In [3]: left_join = df1.merge(df2, on=[""key""], how=""left"")

In [4]: left_join
Out[4]: 
  key   value_x   value_y
0   A  0.469112       NaN
1   B -0.282863  1.212112
2   C -1.509059       NaN
3   D -1.135632 -0.173215
4   D -1.135632  0.119209

In [5]: right_join = df1.merge(df2, on=[""key""], how=""right"")

In [6]: right_join
Out[6]: 
  key   value_x   value_y
0   B -0.282863  1.212112
1   D -1.135632 -0.173215
2   D -1.135632  0.119209
3   E       NaN -1.044236

In [7]: outer_join = df1.merge(df2, on=[""key""], how=""outer"")

In [8]: outer_join
Out[8]: 
  key   value_x   value_y
0   A  0.469112       NaN
1   B -0.282863  1.212112
2   C -1.509059       NaN
3   D -1.135632 -0.173215
4   D -1.135632  0.119209
5   E       NaN -1.044236
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_sas.html, pandas.DataFrame.merge
"df = pd.read_sas(""transport-file.xpt"")
df = pd.read_sas(""binary-file.sas7bdat"")
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_sas.html, pandas.read_sas
"df = pd.read_sas(""transport-file.xpt"", format=""xport"")
df = pd.read_sas(""binary-file.sas7bdat"", format=""sas7bdat"")
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_sas.html, pandas.read_sas
"# version 0.17, 10M rows

In [8]: %time df = pd.read_sas('big.xpt')
Wall time: 14.6 s

In [9]: %time df = pd.read_csv('big.csv')
Wall time: 4.86 s
",https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_sas.html, pandas.read_sas pandas.read_csv
"@pd.api.extensions.register_dataframe_accessor(""geo"")
class GeoAccessor:
    def __init__(self, pandas_obj):
        self._validate(pandas_obj)
        self._obj = pandas_obj

    @staticmethod
    def _validate(obj):
        # verify there is a column latitude and a column longitude
        if ""latitude"" not in obj.columns or ""longitude"" not in obj.columns:
            raise AttributeError(""Must have 'latitude' and 'longitude'."")

    @property
    def center(self):
        # return the geographic center point of this DataFrame
        lat = self._obj.latitude
        lon = self._obj.longitude
        return (float(lon.mean()), float(lat.mean()))

    def plot(self):
        # plot this array's data on a map, e.g., using Cartopy
        pass
",https://pandas.pydata.org/docs/development/extending.html, pandas.api.extensions.register_dataframe_accessor pandas.Series.str.center
">>> ds = pd.DataFrame(
...     {""longitude"": np.linspace(0, 10), ""latitude"": np.linspace(0, 20)}
... )
>>> ds.geo.center
(5.0, 10.0)
>>> ds.geo.plot()
# plots data on a map
",https://pandas.pydata.org/docs/development/extending.html, pandas.DataFrame
"class MyExtensionArray(ExtensionArray):
    ...

    def __arrow_array__(self, type=None):
        # convert the underlying array values to a pyarrow Array
        import pyarrow

        return pyarrow.array(..., type=type)
",https://pandas.pydata.org/docs/development/extending.html, pandas.array
">>> s = SubclassedSeries([1, 2, 3])
>>> type(s)


>>> to_framed = s.to_frame()
>>> type(to_framed)


>>> df = SubclassedDataFrame({""A"": [1, 2, 3], ""B"": [4, 5, 6], ""C"": [7, 8, 9]})
>>> df
   A  B  C
0  1  4  7
1  2  5  8
2  3  6  9

>>> type(df)


>>> sliced1 = df[[""A"", ""B""]]
>>> sliced1
   A  B
0  1  4
1  2  5
2  3  6

>>> type(sliced1)


>>> sliced2 = df[""A""]
>>> sliced2
0    1
1    2
2    3
Name: A, dtype: int64

>>> type(sliced2)

",https://pandas.pydata.org/docs/development/extending.html, pandas.Series.to_frame
">>> pd.set_option(""plotting.backend"", ""backend.module"")
>>> pd.Series([1, 2, 3]).plot()
",https://pandas.pydata.org/docs/development/extending.html, pandas.Series
">>> import backend.module
>>> backend.module.plot(pd.Series([1, 2, 3]))
",https://pandas.pydata.org/docs/development/extending.html, pandas.Series
">>> pd.Series([1, 2]) + [10, 20]
0    11
1    22
dtype: int64
",https://pandas.pydata.org/docs/development/extending.html, pandas.Series
"class CustomList(list):
    __pandas_priority__ = 5000

    def __radd__(self, other):
        # return `self` and not the addition for simplicity
        return self

custom = CustomList()
series = pd.Series([1, 2, 3])

# Series refuses to add custom, since it's an unknown type with higher priority
assert series.__add__(custom) is NotImplemented

# This will cause the custom class `__radd__` being used instead
assert series + custom is custom
",https://pandas.pydata.org/docs/development/extending.html, pandas.Series
"from typing import cast

from pandas.core.dtypes.common import is_number

def cannot_infer_bad(obj: Union[str, int, float]):

    if is_number(obj):
        ...
    else:  # Reasonably only str objects would reach this but...
        obj = cast(str, obj)  # Mypy complains without this!
        return obj.upper()
",https://pandas.pydata.org/docs/development/contributing_codebase.html, pandas.api.types.is_number pandas.Series.str.upper
"def cannot_infer_good(obj: Union[str, int, float]):

    if isinstance(obj, str):
        return obj.upper()
    else:
        ...
",https://pandas.pydata.org/docs/development/contributing_codebase.html, pandas.Series.str.upper
"import pandas as pd
import pandas._testing as tm

def test_getitem_listlike_of_ints():
    ser = pd.Series(range(5))

    result = ser[[3, 4]]
    expected = pd.Series([2, 3])
    tm.assert_series_equal(result, expected)

    result = ser.loc[[3, 4]]
    tm.assert_series_equal(result, expected)
",https://pandas.pydata.org/docs/development/contributing_codebase.html, pandas.Series
"@pytest.mark.network
@pytest.mark.single_cpu
def test_network(httpserver):
    httpserver.serve_content(content=""content"")
    result = pd.read_html(httpserver.url)
",https://pandas.pydata.org/docs/development/contributing_codebase.html, pandas.read_html
"import pytest
import numpy as np
import pandas as pd


@pytest.mark.parametrize('dtype', ['int8', 'int16', 'int32', 'int64'])
def test_dtypes(dtype):
    assert str(np.dtype(dtype)) == dtype


@pytest.mark.parametrize(
    'dtype', ['float32', pytest.param('int16', marks=pytest.mark.skip),
              pytest.param('int32', marks=pytest.mark.xfail(
                  reason='to show how it works'))])
def test_mark(dtype):
    assert str(np.dtype(dtype)) == 'float32'


@pytest.fixture
def series():
    return pd.Series([1, 2, 3])


@pytest.fixture(params=['int8', 'int16', 'int32', 'int64'])
def dtype(request):
    return request.param


def test_series(series, dtype):
    # GH 
    result = series.astype(dtype)
    assert result.dtype == dtype

    expected = pd.Series([1, 2, 3], dtype=dtype)
    tm.assert_series_equal(result, expected)
",https://pandas.pydata.org/docs/development/contributing_codebase.html, pandas.Series pandas.Series.astype
"pd.test()
",https://pandas.pydata.org/docs/development/contributing_codebase.html, pandas.test
">>> df = pd.read_csv(
...     'https://raw.githubusercontent.com/pandas-dev/'
...     'pandas/main/pandas/tests/io/data/csv/iris.csv'
... )
>>> pd.plotting.parallel_coordinates(
...     df, 'Name', color=('#556270', '#4ECDC4', '#C7F464')
... )  
",https://pandas.pydata.org/docs/reference/api/pandas.plotting.parallel_coordinates.html, pandas.read_csv pandas.plotting.parallel_coordinates
"In [1]: dtypes = [
   ...:     ""int64"",
   ...:     ""float64"",
   ...:     ""datetime64[ns]"",
   ...:     ""timedelta64[ns]"",
   ...:     ""complex128"",
   ...:     ""object"",
   ...:     ""bool"",
   ...: ]
   ...: 

In [2]: n = 5000

In [3]: data = {t: np.random.randint(100, size=n).astype(t) for t in dtypes}

In [4]: df = pd.DataFrame(data)

In [5]: df[""categorical""] = df[""object""].astype(""category"")

In [6]: df.info()

RangeIndex: 5000 entries, 0 to 4999
Data columns (total 8 columns):
 #   Column           Non-Null Count  Dtype          
---  ------           --------------  -----          
 0   int64            5000 non-null   int64          
 1   float64          5000 non-null   float64        
 2   datetime64[ns]   5000 non-null   datetime64[ns] 
 3   timedelta64[ns]  5000 non-null   timedelta64[ns]
 4   complex128       5000 non-null   complex128     
 5   object           5000 non-null   object         
 6   bool             5000 non-null   bool           
 7   categorical      5000 non-null   category       
dtypes: bool(1), category(1), complex128(1), datetime64[ns](1), float64(1), int64(1), object(1), timedelta64[ns](1)
memory usage: 288.2+ KB
",https://pandas.pydata.org/docs/user_guide/gotchas.html, pandas.DataFrame pandas.DataFrame.info
"In [7]: df.info(memory_usage=""deep"")

RangeIndex: 5000 entries, 0 to 4999
Data columns (total 8 columns):
 #   Column           Non-Null Count  Dtype          
---  ------           --------------  -----          
 0   int64            5000 non-null   int64          
 1   float64          5000 non-null   float64        
 2   datetime64[ns]   5000 non-null   datetime64[ns] 
 3   timedelta64[ns]  5000 non-null   timedelta64[ns]
 4   complex128       5000 non-null   complex128     
 5   object           5000 non-null   object         
 6   bool             5000 non-null   bool           
 7   categorical      5000 non-null   category       
dtypes: bool(1), category(1), complex128(1), datetime64[ns](1), float64(1), int64(1), object(1), timedelta64[ns](1)
memory usage: 424.7 KB
",https://pandas.pydata.org/docs/user_guide/gotchas.html, pandas.DataFrame.info
"In [8]: df.memory_usage()
Out[8]: 
Index                128
int64              40000
float64            40000
datetime64[ns]     40000
timedelta64[ns]    40000
complex128         80000
object             40000
bool                5000
categorical         9968
dtype: int64

# total memory usage of dataframe
In [9]: df.memory_usage().sum()
Out[9]: 295096
",https://pandas.pydata.org/docs/user_guide/gotchas.html, pandas.DataFrame.memory_usage
"In [10]: df.memory_usage(index=False)
Out[10]: 
int64              40000
float64            40000
datetime64[ns]     40000
timedelta64[ns]    40000
complex128         80000
object             40000
bool                5000
categorical         9968
dtype: int64
",https://pandas.pydata.org/docs/user_guide/gotchas.html, pandas.DataFrame.memory_usage
">>> if pd.Series([False, True, False]):
...     pass
",https://pandas.pydata.org/docs/user_guide/gotchas.html, pandas.Series
"In [11]: if pd.Series([False, True, False]):
   ....:     print(""I was true"")
   ....: 
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
 in ?()
----> 1 if pd.Series([False, True, False]):
      2     print(""I was true"")

~/work/pandas/pandas/pandas/core/generic.py in ?(self)
   1575     @final
   1576     def __nonzero__(self) -> NoReturn:
-> 1577         raise ValueError(
   1578             f""The truth value of a {type(self).__name__} is ambiguous. ""
   1579             ""Use a.empty, a.bool(), a.item(), a.any() or a.all().""
   1580         )

ValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().
",https://pandas.pydata.org/docs/user_guide/gotchas.html, pandas.Series
"In [12]: if pd.Series([False, True, False]) is not None:
   ....:     print(""I was not None"")
   ....: 
I was not None
",https://pandas.pydata.org/docs/user_guide/gotchas.html, pandas.Series
"In [13]: if pd.Series([False, True, False]).any():
   ....:     print(""I am any"")
   ....: 
I am any
",https://pandas.pydata.org/docs/user_guide/gotchas.html, pandas.Series
"In [14]: s = pd.Series(range(5))

In [15]: s == 4
Out[15]: 
0    False
1    False
2    False
3    False
4     True
dtype: bool
",https://pandas.pydata.org/docs/user_guide/gotchas.html, pandas.Series
"In [16]: s = pd.Series(range(5), index=list(""abcde""))

In [17]: 2 in s
Out[17]: False

In [18]: 'b' in s
Out[18]: True
",https://pandas.pydata.org/docs/user_guide/gotchas.html, pandas.Series
"In [19]: s.isin([2])
Out[19]: 
a    False
b    False
c     True
d    False
e    False
dtype: bool

In [20]: s.isin([2]).any()
Out[20]: True
",https://pandas.pydata.org/docs/user_guide/gotchas.html, pandas.Series.isin
"In [25]: def f(s):
   ....:     s.pop(""a"")
   ....:     return s
   ....: 

In [26]: df = pd.DataFrame({""a"": [1, 2, 3], ""b"": [4, 5, 6]})

In [27]: df.apply(f, axis=""columns"")
---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
File ~/work/pandas/pandas/pandas/core/indexes/base.py:3805, in Index.get_loc(self, key)
   3804 try:
-> 3805     return self._engine.get_loc(casted_key)
   3806 except KeyError as err:

File index.pyx:167, in pandas._libs.index.IndexEngine.get_loc()

File index.pyx:196, in pandas._libs.index.IndexEngine.get_loc()

File pandas/_libs/hashtable_class_helper.pxi:7081, in pandas._libs.hashtable.PyObjectHashTable.get_item()

File pandas/_libs/hashtable_class_helper.pxi:7089, in pandas._libs.hashtable.PyObjectHashTable.get_item()

KeyError: 'a'

The above exception was the direct cause of the following exception:

KeyError                                  Traceback (most recent call last)
Cell In[27], line 1
----> 1 df.apply(f, axis=""columns"")

File ~/work/pandas/pandas/pandas/core/frame.py:10374, in DataFrame.apply(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)
  10360 from pandas.core.apply import frame_apply
  10362 op = frame_apply(
  10363     self,
  10364     func=func,
   (...)
  10372     kwargs=kwargs,
  10373 )
> 10374 return op.apply().__finalize__(self, method=""apply"")

File ~/work/pandas/pandas/pandas/core/apply.py:916, in FrameApply.apply(self)
    913 elif self.raw:
    914     return self.apply_raw(engine=self.engine, engine_kwargs=self.engine_kwargs)
--> 916 return self.apply_standard()

File ~/work/pandas/pandas/pandas/core/apply.py:1063, in FrameApply.apply_standard(self)
   1061 def apply_standard(self):
   1062     if self.engine == ""python"":
-> 1063         results, res_index = self.apply_series_generator()
   1064     else:
   1065         results, res_index = self.apply_series_numba()

File ~/work/pandas/pandas/pandas/core/apply.py:1081, in FrameApply.apply_series_generator(self)
   1078 with option_context(""mode.chained_assignment"", None):
   1079     for i, v in enumerate(series_gen):
   1080         # ignore SettingWithCopy here in case the user mutates
-> 1081         results[i] = self.func(v, *self.args, **self.kwargs)
   1082         if isinstance(results[i], ABCSeries):
   1083             # If we have a view on v, we need to make a copy because
   1084             #  series_generator will swap out the underlying data
   1085             results[i] = results[i].copy(deep=False)

Cell In[25], line 2, in f(s)
      1 def f(s):
----> 2     s.pop(""a"")
      3     return s

File ~/work/pandas/pandas/pandas/core/series.py:5391, in Series.pop(self, item)
   5366 def pop(self, item: Hashable) -> Any:
   5367     """"""
   5368     Return item and drops from series. Raise KeyError if not found.
   5369 
   (...)
   5389     dtype: int64
   5390     """"""
-> 5391     return super().pop(item=item)

File ~/work/pandas/pandas/pandas/core/generic.py:947, in NDFrame.pop(self, item)
    946 def pop(self, item: Hashable) -> Series | Any:
--> 947     result = self[item]
    948     del self[item]
    950     return result

File ~/work/pandas/pandas/pandas/core/series.py:1121, in Series.__getitem__(self, key)
   1118     return self._values[key]
   1120 elif key_is_scalar:
-> 1121     return self._get_value(key)
   1123 # Convert generator to list before going through hashable part
   1124 # (We will iterate through the generator there to check for slices)
   1125 if is_iterator(key):

File ~/work/pandas/pandas/pandas/core/series.py:1237, in Series._get_value(self, label, takeable)
   1234     return self._values[label]
   1236 # Similar to Index.get_value, but we do not fall back to positional
-> 1237 loc = self.index.get_loc(label)
   1239 if is_integer(loc):
   1240     return self._values[loc]

File ~/work/pandas/pandas/pandas/core/indexes/base.py:3812, in Index.get_loc(self, key)
   3807     if isinstance(casted_key, slice) or (
   3808         isinstance(casted_key, abc.Iterable)
   3809         and any(isinstance(x, slice) for x in casted_key)
   3810     ):
   3811         raise InvalidIndexError(key)
-> 3812     raise KeyError(key) from err
   3813 except TypeError:
   3814     # If we have a listlike key, _check_indexing_error will raise
   3815     #  InvalidIndexError. Otherwise we fall through and re-raise
   3816     #  the TypeError.
   3817     self._check_indexing_error(key)

KeyError: 'a'
",https://pandas.pydata.org/docs/user_guide/gotchas.html, pandas.Series.pop pandas.DataFrame pandas.DataFrame.apply pandas.Index.get_loc pandas.DataFrame.apply pandas.Series.pop pandas.api.types.is_iterator pandas.api.types.is_integer pandas.errors.InvalidIndexError
"In [32]: def f(s):
   ....:     s = s.copy()
   ....:     s.pop(""a"")
   ....:     return s
   ....: 

In [33]: df = pd.DataFrame({""a"": [1, 2, 3], 'b': [4, 5, 6]})

In [34]: df.apply(f, axis=""columns"")
Out[34]: 
   b
0  4
1  5
2  6
",https://pandas.pydata.org/docs/user_guide/gotchas.html, pandas.Series.copy pandas.Series.pop pandas.DataFrame pandas.DataFrame.apply
"In [35]: s = pd.Series([1, 2, 3, 4, 5], index=list(""abcde""))

In [36]: s
Out[36]: 
a    1
b    2
c    3
d    4
e    5
dtype: int64

In [37]: s.dtype
Out[37]: dtype('int64')

In [38]: s2 = s.reindex([""a"", ""b"", ""c"", ""f"", ""u""])

In [39]: s2
Out[39]: 
a    1.0
b    2.0
c    3.0
f    NaN
u    NaN
dtype: float64

In [40]: s2.dtype
Out[40]: dtype('float64')
",https://pandas.pydata.org/docs/user_guide/gotchas.html, pandas.Series pandas.Series.reindex
"In [41]: s_int = pd.Series([1, 2, 3, 4, 5], index=list(""abcde""), dtype=pd.Int64Dtype())

In [42]: s_int
Out[42]: 
a    1
b    2
c    3
d    4
e    5
dtype: Int64

In [43]: s_int.dtype
Out[43]: Int64Dtype()

In [44]: s2_int = s_int.reindex([""a"", ""b"", ""c"", ""f"", ""u""])

In [45]: s2_int
Out[45]: 
a       1
b       2
c       3
f    
u    
dtype: Int64

In [46]: s2_int.dtype
Out[46]: Int64Dtype()

In [47]: s_int_pa = pd.Series([1, 2, None], dtype=""int64[pyarrow]"")

In [48]: s_int_pa
Out[48]: 
0       1
1       2
2    
dtype: int64[pyarrow]
",https://pandas.pydata.org/docs/user_guide/gotchas.html, pandas.Series pandas.Int64Dtype pandas.Int64Dtype pandas.Series.reindex
"In [49]: x = np.array(list(range(10)), "">i4"")  # big endian

In [50]: newx = x.byteswap().view(x.dtype.newbyteorder())  # force native byteorder

In [51]: s = pd.Series(newx)
",https://pandas.pydata.org/docs/user_guide/gotchas.html, pandas.Series
"In [1]: df1 = pd.DataFrame(
   ...:     {
   ...:         ""A"": [""A0"", ""A1"", ""A2"", ""A3""],
   ...:         ""B"": [""B0"", ""B1"", ""B2"", ""B3""],
   ...:         ""C"": [""C0"", ""C1"", ""C2"", ""C3""],
   ...:         ""D"": [""D0"", ""D1"", ""D2"", ""D3""],
   ...:     },
   ...:     index=[0, 1, 2, 3],
   ...: )
   ...: 

In [2]: df2 = pd.DataFrame(
   ...:     {
   ...:         ""A"": [""A4"", ""A5"", ""A6"", ""A7""],
   ...:         ""B"": [""B4"", ""B5"", ""B6"", ""B7""],
   ...:         ""C"": [""C4"", ""C5"", ""C6"", ""C7""],
   ...:         ""D"": [""D4"", ""D5"", ""D6"", ""D7""],
   ...:     },
   ...:     index=[4, 5, 6, 7],
   ...: )
   ...: 

In [3]: df3 = pd.DataFrame(
   ...:     {
   ...:         ""A"": [""A8"", ""A9"", ""A10"", ""A11""],
   ...:         ""B"": [""B8"", ""B9"", ""B10"", ""B11""],
   ...:         ""C"": [""C8"", ""C9"", ""C10"", ""C11""],
   ...:         ""D"": [""D8"", ""D9"", ""D10"", ""D11""],
   ...:     },
   ...:     index=[8, 9, 10, 11],
   ...: )
   ...: 

In [4]: frames = [df1, df2, df3]

In [5]: result = pd.concat(frames)

In [6]: result
Out[6]: 
      A    B    C    D
0    A0   B0   C0   D0
1    A1   B1   C1   D1
2    A2   B2   C2   D2
3    A3   B3   C3   D3
4    A4   B4   C4   D4
5    A5   B5   C5   D5
6    A6   B6   C6   D6
7    A7   B7   C7   D7
8    A8   B8   C8   D8
9    A9   B9   C9   D9
10  A10  B10  C10  D10
11  A11  B11  C11  D11
",https://pandas.pydata.org/docs/user_guide/merging.html, pandas.DataFrame pandas.concat
"frames = [process_your_file(f) for f in files]
result = pd.concat(frames)
",https://pandas.pydata.org/docs/user_guide/merging.html, pandas.concat
"In [7]: df4 = pd.DataFrame(
   ...:     {
   ...:         ""B"": [""B2"", ""B3"", ""B6"", ""B7""],
   ...:         ""D"": [""D2"", ""D3"", ""D6"", ""D7""],
   ...:         ""F"": [""F2"", ""F3"", ""F6"", ""F7""],
   ...:     },
   ...:     index=[2, 3, 6, 7],
   ...: )
   ...: 

In [8]: result = pd.concat([df1, df4], axis=1)

In [9]: result
Out[9]: 
     A    B    C    D    B    D    F
0   A0   B0   C0   D0  NaN  NaN  NaN
1   A1   B1   C1   D1  NaN  NaN  NaN
2   A2   B2   C2   D2   B2   D2   F2
3   A3   B3   C3   D3   B3   D3   F3
6  NaN  NaN  NaN  NaN   B6   D6   F6
7  NaN  NaN  NaN  NaN   B7   D7   F7
",https://pandas.pydata.org/docs/user_guide/merging.html, pandas.DataFrame pandas.concat
"In [10]: result = pd.concat([df1, df4], axis=1, join=""inner"")

In [11]: result
Out[11]: 
    A   B   C   D   B   D   F
2  A2  B2  C2  D2  B2  D2  F2
3  A3  B3  C3  D3  B3  D3  F3
",https://pandas.pydata.org/docs/user_guide/merging.html, pandas.concat
"In [12]: result = pd.concat([df1, df4], axis=1).reindex(df1.index)

In [13]: result
Out[13]: 
    A   B   C   D    B    D    F
0  A0  B0  C0  D0  NaN  NaN  NaN
1  A1  B1  C1  D1  NaN  NaN  NaN
2  A2  B2  C2  D2   B2   D2   F2
3  A3  B3  C3  D3   B3   D3   F3
",https://pandas.pydata.org/docs/user_guide/merging.html, pandas.concat
"In [14]: result = pd.concat([df1, df4], ignore_index=True, sort=False)

In [15]: result
Out[15]: 
     A   B    C   D    F
0   A0  B0   C0  D0  NaN
1   A1  B1   C1  D1  NaN
2   A2  B2   C2  D2  NaN
3   A3  B3   C3  D3  NaN
4  NaN  B2  NaN  D2   F2
5  NaN  B3  NaN  D3   F3
6  NaN  B6  NaN  D6   F6
7  NaN  B7  NaN  D7   F7
",https://pandas.pydata.org/docs/user_guide/merging.html, pandas.concat
"In [16]: s1 = pd.Series([""X0"", ""X1"", ""X2"", ""X3""], name=""X"")

In [17]: result = pd.concat([df1, s1], axis=1)

In [18]: result
Out[18]: 
    A   B   C   D   X
0  A0  B0  C0  D0  X0
1  A1  B1  C1  D1  X1
2  A2  B2  C2  D2  X2
3  A3  B3  C3  D3  X3
",https://pandas.pydata.org/docs/user_guide/merging.html, pandas.Series pandas.concat
"In [19]: s2 = pd.Series([""_0"", ""_1"", ""_2"", ""_3""])

In [20]: result = pd.concat([df1, s2, s2, s2], axis=1)

In [21]: result
Out[21]: 
    A   B   C   D   0   1   2
0  A0  B0  C0  D0  _0  _0  _0
1  A1  B1  C1  D1  _1  _1  _1
2  A2  B2  C2  D2  _2  _2  _2
3  A3  B3  C3  D3  _3  _3  _3
",https://pandas.pydata.org/docs/user_guide/merging.html, pandas.Series pandas.concat
"In [22]: result = pd.concat([df1, s1], axis=1, ignore_index=True)

In [23]: result
Out[23]: 
    0   1   2   3   4
0  A0  B0  C0  D0  X0
1  A1  B1  C1  D1  X1
2  A2  B2  C2  D2  X2
3  A3  B3  C3  D3  X3
",https://pandas.pydata.org/docs/user_guide/merging.html, pandas.concat
"In [24]: result = pd.concat(frames, keys=[""x"", ""y"", ""z""])

In [25]: result
Out[25]: 
        A    B    C    D
x 0    A0   B0   C0   D0
  1    A1   B1   C1   D1
  2    A2   B2   C2   D2
  3    A3   B3   C3   D3
y 4    A4   B4   C4   D4
  5    A5   B5   C5   D5
  6    A6   B6   C6   D6
  7    A7   B7   C7   D7
z 8    A8   B8   C8   D8
  9    A9   B9   C9   D9
  10  A10  B10  C10  D10
  11  A11  B11  C11  D11

In [26]: result.loc[""y""]
Out[26]: 
    A   B   C   D
4  A4  B4  C4  D4
5  A5  B5  C5  D5
6  A6  B6  C6  D6
7  A7  B7  C7  D7
",https://pandas.pydata.org/docs/user_guide/merging.html, pandas.concat
"In [27]: s3 = pd.Series([0, 1, 2, 3], name=""foo"")

In [28]: s4 = pd.Series([0, 1, 2, 3])

In [29]: s5 = pd.Series([0, 1, 4, 5])

In [30]: pd.concat([s3, s4, s5], axis=1)
Out[30]: 
   foo  0  1
0    0  0  0
1    1  1  1
2    2  2  4
3    3  3  5

In [31]: pd.concat([s3, s4, s5], axis=1, keys=[""red"", ""blue"", ""yellow""])
Out[31]: 
   red  blue  yellow
0    0     0       0
1    1     1       1
2    2     2       4
3    3     3       5
",https://pandas.pydata.org/docs/user_guide/merging.html, pandas.Series pandas.concat
"In [32]: pieces = {""x"": df1, ""y"": df2, ""z"": df3}

In [33]: result = pd.concat(pieces)

In [34]: result
Out[34]: 
        A    B    C    D
x 0    A0   B0   C0   D0
  1    A1   B1   C1   D1
  2    A2   B2   C2   D2
  3    A3   B3   C3   D3
y 4    A4   B4   C4   D4
  5    A5   B5   C5   D5
  6    A6   B6   C6   D6
  7    A7   B7   C7   D7
z 8    A8   B8   C8   D8
  9    A9   B9   C9   D9
  10  A10  B10  C10  D10
  11  A11  B11  C11  D11
",https://pandas.pydata.org/docs/user_guide/merging.html, pandas.concat
"In [35]: result = pd.concat(pieces, keys=[""z"", ""y""])

In [36]: result
Out[36]: 
        A    B    C    D
z 8    A8   B8   C8   D8
  9    A9   B9   C9   D9
  10  A10  B10  C10  D10
  11  A11  B11  C11  D11
y 4    A4   B4   C4   D4
  5    A5   B5   C5   D5
  6    A6   B6   C6   D6
  7    A7   B7   C7   D7
",https://pandas.pydata.org/docs/user_guide/merging.html, pandas.concat
"In [38]: result = pd.concat(
   ....:     pieces, keys=[""x"", ""y"", ""z""], levels=[[""z"", ""y"", ""x"", ""w""]], names=[""group_key""]
   ....: )
   ....: 

In [39]: result
Out[39]: 
                A    B    C    D
group_key                       
x         0    A0   B0   C0   D0
          1    A1   B1   C1   D1
          2    A2   B2   C2   D2
          3    A3   B3   C3   D3
y         4    A4   B4   C4   D4
          5    A5   B5   C5   D5
          6    A6   B6   C6   D6
          7    A7   B7   C7   D7
z         8    A8   B8   C8   D8
          9    A9   B9   C9   D9
          10  A10  B10  C10  D10
          11  A11  B11  C11  D11
",https://pandas.pydata.org/docs/user_guide/merging.html, pandas.concat
"In [41]: s2 = pd.Series([""X0"", ""X1"", ""X2"", ""X3""], index=[""A"", ""B"", ""C"", ""D""])

In [42]: result = pd.concat([df1, s2.to_frame().T], ignore_index=True)

In [43]: result
Out[43]: 
    A   B   C   D
0  A0  B0  C0  D0
1  A1  B1  C1  D1
2  A2  B2  C2  D2
3  A3  B3  C3  D3
4  X0  X1  X2  X3
",https://pandas.pydata.org/docs/user_guide/merging.html, pandas.Series pandas.concat pandas.Series.to_frame
"In [44]: left = pd.DataFrame(
   ....:     {
   ....:         ""key"": [""K0"", ""K1"", ""K2"", ""K3""],
   ....:         ""A"": [""A0"", ""A1"", ""A2"", ""A3""],
   ....:         ""B"": [""B0"", ""B1"", ""B2"", ""B3""],
   ....:     }
   ....: )
   ....: 

In [45]: right = pd.DataFrame(
   ....:     {
   ....:         ""key"": [""K0"", ""K1"", ""K2"", ""K3""],
   ....:         ""C"": [""C0"", ""C1"", ""C2"", ""C3""],
   ....:         ""D"": [""D0"", ""D1"", ""D2"", ""D3""],
   ....:     }
   ....: )
   ....: 

In [46]: result = pd.merge(left, right, on=""key"")

In [47]: result
Out[47]: 
  key   A   B   C   D
0  K0  A0  B0  C0  D0
1  K1  A1  B1  C1  D1
2  K2  A2  B2  C2  D2
3  K3  A3  B3  C3  D3
",https://pandas.pydata.org/docs/user_guide/merging.html, pandas.DataFrame pandas.merge
"In [48]: left = pd.DataFrame(
   ....:    {
   ....:       ""key1"": [""K0"", ""K0"", ""K1"", ""K2""],
   ....:       ""key2"": [""K0"", ""K1"", ""K0"", ""K1""],
   ....:       ""A"": [""A0"", ""A1"", ""A2"", ""A3""],
   ....:       ""B"": [""B0"", ""B1"", ""B2"", ""B3""],
   ....:    }
   ....: )
   ....: 

In [49]: right = pd.DataFrame(
   ....:    {
   ....:       ""key1"": [""K0"", ""K1"", ""K1"", ""K2""],
   ....:       ""key2"": [""K0"", ""K0"", ""K0"", ""K0""],
   ....:       ""C"": [""C0"", ""C1"", ""C2"", ""C3""],
   ....:       ""D"": [""D0"", ""D1"", ""D2"", ""D3""],
   ....:    }
   ....: )
   ....: 

In [50]: result = pd.merge(left, right, how=""left"", on=[""key1"", ""key2""])

In [51]: result
Out[51]: 
  key1 key2   A   B    C    D
0   K0   K0  A0  B0   C0   D0
1   K0   K1  A1  B1  NaN  NaN
2   K1   K0  A2  B2   C1   D1
3   K1   K0  A2  B2   C2   D2
4   K2   K1  A3  B3  NaN  NaN
",https://pandas.pydata.org/docs/user_guide/merging.html, pandas.DataFrame pandas.merge
"In [52]: result = pd.merge(left, right, how=""right"", on=[""key1"", ""key2""])

In [53]: result
Out[53]: 
  key1 key2    A    B   C   D
0   K0   K0   A0   B0  C0  D0
1   K1   K0   A2   B2  C1  D1
2   K1   K0   A2   B2  C2  D2
3   K2   K0  NaN  NaN  C3  D3
",https://pandas.pydata.org/docs/user_guide/merging.html, pandas.merge
"In [54]: result = pd.merge(left, right, how=""outer"", on=[""key1"", ""key2""])

In [55]: result
Out[55]: 
  key1 key2    A    B    C    D
0   K0   K0   A0   B0   C0   D0
1   K0   K1   A1   B1  NaN  NaN
2   K1   K0   A2   B2   C1   D1
3   K1   K0   A2   B2   C2   D2
4   K2   K0  NaN  NaN   C3   D3
5   K2   K1   A3   B3  NaN  NaN
",https://pandas.pydata.org/docs/user_guide/merging.html, pandas.merge
"In [56]: result = pd.merge(left, right, how=""inner"", on=[""key1"", ""key2""])

In [57]: result
Out[57]: 
  key1 key2   A   B   C   D
0   K0   K0  A0  B0  C0  D0
1   K1   K0  A2  B2  C1  D1
2   K1   K0  A2  B2  C2  D2
",https://pandas.pydata.org/docs/user_guide/merging.html, pandas.merge
"In [58]: result = pd.merge(left, right, how=""cross"")

In [59]: result
Out[59]: 
   key1_x key2_x   A   B key1_y key2_y   C   D
0      K0     K0  A0  B0     K0     K0  C0  D0
1      K0     K0  A0  B0     K1     K0  C1  D1
2      K0     K0  A0  B0     K1     K0  C2  D2
3      K0     K0  A0  B0     K2     K0  C3  D3
4      K0     K1  A1  B1     K0     K0  C0  D0
..    ...    ...  ..  ..    ...    ...  ..  ..
11     K1     K0  A2  B2     K2     K0  C3  D3
12     K2     K1  A3  B3     K0     K0  C0  D0
13     K2     K1  A3  B3     K1     K0  C1  D1
14     K2     K1  A3  B3     K1     K0  C2  D2
15     K2     K1  A3  B3     K2     K0  C3  D3

[16 rows x 8 columns]
",https://pandas.pydata.org/docs/user_guide/merging.html, pandas.merge
"In [60]: df = pd.DataFrame({""Let"": [""A"", ""B"", ""C""], ""Num"": [1, 2, 3]})

In [61]: df
Out[61]: 
  Let  Num
0   A    1
1   B    2
2   C    3

In [62]: ser = pd.Series(
   ....:     [""a"", ""b"", ""c"", ""d"", ""e"", ""f""],
   ....:     index=pd.MultiIndex.from_arrays(
   ....:         [[""A"", ""B"", ""C""] * 2, [1, 2, 3, 4, 5, 6]], names=[""Let"", ""Num""]
   ....:     ),
   ....: )
   ....: 

In [63]: ser
Out[63]: 
Let  Num
A    1      a
B    2      b
C    3      c
A    4      d
B    5      e
C    6      f
dtype: object

In [64]: pd.merge(df, ser.reset_index(), on=[""Let"", ""Num""])
Out[64]: 
  Let  Num  0
0   A    1  a
1   B    2  b
2   C    3  c
",https://pandas.pydata.org/docs/user_guide/merging.html, pandas.DataFrame pandas.Series pandas.MultiIndex.from_arrays pandas.merge pandas.Series.reset_index
"In [65]: left = pd.DataFrame({""A"": [1, 2], ""B"": [2, 2]})

In [66]: right = pd.DataFrame({""A"": [4, 5, 6], ""B"": [2, 2, 2]})

In [67]: result = pd.merge(left, right, on=""B"", how=""outer"")

In [68]: result
Out[68]: 
   A_x  B  A_y
0    1  2    4
1    1  2    5
2    1  2    6
3    2  2    4
4    2  2    5
5    2  2    6
",https://pandas.pydata.org/docs/user_guide/merging.html, pandas.DataFrame pandas.merge
"In [69]: left = pd.DataFrame({""A"": [1, 2], ""B"": [1, 2]})

In [70]: right = pd.DataFrame({""A"": [4, 5, 6], ""B"": [2, 2, 2]})

In [71]: result = pd.merge(left, right, on=""B"", how=""outer"", validate=""one_to_one"")
---------------------------------------------------------------------------
MergeError                                Traceback (most recent call last)
Cell In[71], line 1
----> 1 result = pd.merge(left, right, on=""B"", how=""outer"", validate=""one_to_one"")

File ~/work/pandas/pandas/pandas/core/reshape/merge.py:170, in merge(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)
    155     return _cross_merge(
    156         left_df,
    157         right_df,
   (...)
    167         copy=copy,
    168     )
    169 else:
--> 170     op = _MergeOperation(
    171         left_df,
    172         right_df,
    173         how=how,
    174         on=on,
    175         left_on=left_on,
    176         right_on=right_on,
    177         left_index=left_index,
    178         right_index=right_index,
    179         sort=sort,
    180         suffixes=suffixes,
    181         indicator=indicator,
    182         validate=validate,
    183     )
    184     return op.get_result(copy=copy)

File ~/work/pandas/pandas/pandas/core/reshape/merge.py:813, in _MergeOperation.__init__(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)
    809 # If argument passed to validate,
    810 # check if columns specified as unique
    811 # are in fact unique.
    812 if validate is not None:
--> 813     self._validate_validate_kwd(validate)

File ~/work/pandas/pandas/pandas/core/reshape/merge.py:1657, in _MergeOperation._validate_validate_kwd(self, validate)
   1653         raise MergeError(
   1654             ""Merge keys are not unique in left dataset; not a one-to-one merge""
   1655         )
   1656     if not right_unique:
-> 1657         raise MergeError(
   1658             ""Merge keys are not unique in right dataset; not a one-to-one merge""
   1659         )
   1661 elif validate in [""one_to_many"", ""1:m""]:
   1662     if not left_unique:

MergeError: Merge keys are not unique in right dataset; not a one-to-one merge
",https://pandas.pydata.org/docs/user_guide/merging.html, pandas.DataFrame pandas.merge pandas.errors.MergeError
"In [72]: pd.merge(left, right, on=""B"", how=""outer"", validate=""one_to_many"")
Out[72]: 
   A_x  B  A_y
0    1  1  NaN
1    2  2  4.0
2    2  2  5.0
3    2  2  6.0
",https://pandas.pydata.org/docs/user_guide/merging.html, pandas.merge
"In [73]: df1 = pd.DataFrame({""col1"": [0, 1], ""col_left"": [""a"", ""b""]})

In [74]: df2 = pd.DataFrame({""col1"": [1, 2, 2], ""col_right"": [2, 2, 2]})

In [75]: pd.merge(df1, df2, on=""col1"", how=""outer"", indicator=True)
Out[75]: 
   col1 col_left  col_right      _merge
0     0        a        NaN   left_only
1     1        b        2.0        both
2     2      NaN        2.0  right_only
3     2      NaN        2.0  right_only
",https://pandas.pydata.org/docs/user_guide/merging.html, pandas.DataFrame pandas.merge
"In [76]: pd.merge(df1, df2, on=""col1"", how=""outer"", indicator=""indicator_column"")
Out[76]: 
   col1 col_left  col_right indicator_column
0     0        a        NaN        left_only
1     1        b        2.0             both
2     2      NaN        2.0       right_only
3     2      NaN        2.0       right_only
",https://pandas.pydata.org/docs/user_guide/merging.html, pandas.merge
"In [77]: left = pd.DataFrame({""k"": [""K0"", ""K1"", ""K2""], ""v"": [1, 2, 3]})

In [78]: right = pd.DataFrame({""k"": [""K0"", ""K0"", ""K3""], ""v"": [4, 5, 6]})

In [79]: result = pd.merge(left, right, on=""k"")

In [80]: result
Out[80]: 
    k  v_x  v_y
0  K0    1    4
1  K0    1    5
",https://pandas.pydata.org/docs/user_guide/merging.html, pandas.DataFrame pandas.merge
"In [81]: result = pd.merge(left, right, on=""k"", suffixes=(""_l"", ""_r""))

In [82]: result
Out[82]: 
    k  v_l  v_r
0  K0    1    4
1  K0    1    5
",https://pandas.pydata.org/docs/user_guide/merging.html, pandas.merge
"In [83]: left = pd.DataFrame(
   ....:     {""A"": [""A0"", ""A1"", ""A2""], ""B"": [""B0"", ""B1"", ""B2""]}, index=[""K0"", ""K1"", ""K2""]
   ....: )
   ....: 

In [84]: right = pd.DataFrame(
   ....:     {""C"": [""C0"", ""C2"", ""C3""], ""D"": [""D0"", ""D2"", ""D3""]}, index=[""K0"", ""K2"", ""K3""]
   ....: )
   ....: 

In [85]: result = left.join(right)

In [86]: result
Out[86]: 
     A   B    C    D
K0  A0  B0   C0   D0
K1  A1  B1  NaN  NaN
K2  A2  B2   C2   D2
",https://pandas.pydata.org/docs/user_guide/merging.html, pandas.DataFrame pandas.DataFrame.join
"In [87]: result = left.join(right, how=""outer"")

In [88]: result
Out[88]: 
      A    B    C    D
K0   A0   B0   C0   D0
K1   A1   B1  NaN  NaN
K2   A2   B2   C2   D2
K3  NaN  NaN   C3   D3
",https://pandas.pydata.org/docs/user_guide/merging.html, pandas.DataFrame.join
"In [89]: result = left.join(right, how=""inner"")

In [90]: result
Out[90]: 
     A   B   C   D
K0  A0  B0  C0  D0
K2  A2  B2  C2  D2
",https://pandas.pydata.org/docs/user_guide/merging.html, pandas.DataFrame.join
"In [91]: left = pd.DataFrame(
   ....:     {
   ....:         ""A"": [""A0"", ""A1"", ""A2"", ""A3""],
   ....:         ""B"": [""B0"", ""B1"", ""B2"", ""B3""],
   ....:         ""key"": [""K0"", ""K1"", ""K0"", ""K1""],
   ....:     }
   ....: )
   ....: 

In [92]: right = pd.DataFrame({""C"": [""C0"", ""C1""], ""D"": [""D0"", ""D1""]}, index=[""K0"", ""K1""])

In [93]: result = left.join(right, on=""key"")

In [94]: result
Out[94]: 
    A   B key   C   D
0  A0  B0  K0  C0  D0
1  A1  B1  K1  C1  D1
2  A2  B2  K0  C0  D0
3  A3  B3  K1  C1  D1
",https://pandas.pydata.org/docs/user_guide/merging.html, pandas.DataFrame pandas.DataFrame.join
"In [95]: result = pd.merge(
   ....:     left, right, left_on=""key"", right_index=True, how=""left"", sort=False
   ....: )
   ....: 

In [96]: result
Out[96]: 
    A   B key   C   D
0  A0  B0  K0  C0  D0
1  A1  B1  K1  C1  D1
2  A2  B2  K0  C0  D0
3  A3  B3  K1  C1  D1
",https://pandas.pydata.org/docs/user_guide/merging.html, pandas.merge
"In [97]: left = pd.DataFrame(
   ....:     {
   ....:         ""A"": [""A0"", ""A1"", ""A2"", ""A3""],
   ....:         ""B"": [""B0"", ""B1"", ""B2"", ""B3""],
   ....:         ""key1"": [""K0"", ""K0"", ""K1"", ""K2""],
   ....:         ""key2"": [""K0"", ""K1"", ""K0"", ""K1""],
   ....:     }
   ....: )
   ....: 

In [98]: index = pd.MultiIndex.from_tuples(
   ....:     [(""K0"", ""K0""), (""K1"", ""K0""), (""K2"", ""K0""), (""K2"", ""K1"")]
   ....: )
   ....: 

In [99]: right = pd.DataFrame(
   ....:     {""C"": [""C0"", ""C1"", ""C2"", ""C3""], ""D"": [""D0"", ""D1"", ""D2"", ""D3""]}, index=index
   ....: )
   ....: 

In [100]: result = left.join(right, on=[""key1"", ""key2""])

In [101]: result
Out[101]: 
    A   B key1 key2    C    D
0  A0  B0   K0   K0   C0   D0
1  A1  B1   K0   K1  NaN  NaN
2  A2  B2   K1   K0   C1   D1
3  A3  B3   K2   K1   C3   D3
",https://pandas.pydata.org/docs/user_guide/merging.html, pandas.DataFrame pandas.MultiIndex.from_tuples pandas.DataFrame.join
"In [102]: result = left.join(right, on=[""key1"", ""key2""], how=""inner"")

In [103]: result
Out[103]: 
    A   B key1 key2   C   D
0  A0  B0   K0   K0  C0  D0
2  A2  B2   K1   K0  C1  D1
3  A3  B3   K2   K1  C3  D3
",https://pandas.pydata.org/docs/user_guide/merging.html, pandas.DataFrame.join
"In [104]: left = pd.DataFrame(
   .....:     {""A"": [""A0"", ""A1"", ""A2""], ""B"": [""B0"", ""B1"", ""B2""]},
   .....:     index=pd.Index([""K0"", ""K1"", ""K2""], name=""key""),
   .....: )
   .....: 

In [105]: index = pd.MultiIndex.from_tuples(
   .....:     [(""K0"", ""Y0""), (""K1"", ""Y1""), (""K2"", ""Y2""), (""K2"", ""Y3"")],
   .....:     names=[""key"", ""Y""],
   .....: )
   .....: 

In [106]: right = pd.DataFrame(
   .....:     {""C"": [""C0"", ""C1"", ""C2"", ""C3""], ""D"": [""D0"", ""D1"", ""D2"", ""D3""]},
   .....:     index=index,
   .....: )
   .....: 

In [107]: result = left.join(right, how=""inner"")

In [108]: result
Out[108]: 
         A   B   C   D
key Y                 
K0  Y0  A0  B0  C0  D0
K1  Y1  A1  B1  C1  D1
K2  Y2  A2  B2  C2  D2
    Y3  A2  B2  C3  D3
",https://pandas.pydata.org/docs/user_guide/merging.html, pandas.DataFrame pandas.Index pandas.MultiIndex.from_tuples pandas.DataFrame.join
"In [109]: leftindex = pd.MultiIndex.from_product(
   .....:     [list(""abc""), list(""xy""), [1, 2]], names=[""abc"", ""xy"", ""num""]
   .....: )
   .....: 

In [110]: left = pd.DataFrame({""v1"": range(12)}, index=leftindex)

In [111]: left
Out[111]: 
            v1
abc xy num    
a   x  1     0
       2     1
    y  1     2
       2     3
b   x  1     4
       2     5
    y  1     6
       2     7
c   x  1     8
       2     9
    y  1    10
       2    11

In [112]: rightindex = pd.MultiIndex.from_product(
   .....:     [list(""abc""), list(""xy"")], names=[""abc"", ""xy""]
   .....: )
   .....: 

In [113]: right = pd.DataFrame({""v2"": [100 * i for i in range(1, 7)]}, index=rightindex)

In [114]: right
Out[114]: 
         v2
abc xy     
a   x   100
    y   200
b   x   300
    y   400
c   x   500
    y   600

In [115]: left.join(right, on=[""abc"", ""xy""], how=""inner"")
Out[115]: 
            v1   v2
abc xy num         
a   x  1     0  100
       2     1  100
    y  1     2  200
       2     3  200
b   x  1     4  300
       2     5  300
    y  1     6  400
       2     7  400
c   x  1     8  500
       2     9  500
    y  1    10  600
       2    11  600
",https://pandas.pydata.org/docs/user_guide/merging.html, pandas.MultiIndex.from_product pandas.DataFrame pandas.DataFrame.join
"In [116]: leftindex = pd.MultiIndex.from_tuples(
   .....:     [(""K0"", ""X0""), (""K0"", ""X1""), (""K1"", ""X2"")], names=[""key"", ""X""]
   .....: )
   .....: 

In [117]: left = pd.DataFrame(
   .....:     {""A"": [""A0"", ""A1"", ""A2""], ""B"": [""B0"", ""B1"", ""B2""]}, index=leftindex
   .....: )
   .....: 

In [118]: rightindex = pd.MultiIndex.from_tuples(
   .....:     [(""K0"", ""Y0""), (""K1"", ""Y1""), (""K2"", ""Y2""), (""K2"", ""Y3"")], names=[""key"", ""Y""]
   .....: )
   .....: 

In [119]: right = pd.DataFrame(
   .....:     {""C"": [""C0"", ""C1"", ""C2"", ""C3""], ""D"": [""D0"", ""D1"", ""D2"", ""D3""]}, index=rightindex
   .....: )
   .....: 

In [120]: result = pd.merge(
   .....:     left.reset_index(), right.reset_index(), on=[""key""], how=""inner""
   .....: ).set_index([""key"", ""X"", ""Y""])
   .....: 

In [121]: result
Out[121]: 
            A   B   C   D
key X  Y                 
K0  X0 Y0  A0  B0  C0  D0
    X1 Y0  A1  B1  C0  D0
K1  X2 Y1  A2  B2  C1  D1
",https://pandas.pydata.org/docs/user_guide/merging.html, pandas.MultiIndex.from_tuples pandas.DataFrame pandas.merge pandas.DataFrame.reset_index pandas.DataFrame.reset_index pandas.DataFrame.set_index
"In [122]: left_index = pd.Index([""K0"", ""K0"", ""K1"", ""K2""], name=""key1"")

In [123]: left = pd.DataFrame(
   .....:     {
   .....:         ""A"": [""A0"", ""A1"", ""A2"", ""A3""],
   .....:         ""B"": [""B0"", ""B1"", ""B2"", ""B3""],
   .....:         ""key2"": [""K0"", ""K1"", ""K0"", ""K1""],
   .....:     },
   .....:     index=left_index,
   .....: )
   .....: 

In [124]: right_index = pd.Index([""K0"", ""K1"", ""K2"", ""K2""], name=""key1"")

In [125]: right = pd.DataFrame(
   .....:     {
   .....:         ""C"": [""C0"", ""C1"", ""C2"", ""C3""],
   .....:         ""D"": [""D0"", ""D1"", ""D2"", ""D3""],
   .....:         ""key2"": [""K0"", ""K0"", ""K0"", ""K1""],
   .....:     },
   .....:     index=right_index,
   .....: )
   .....: 

In [126]: result = left.merge(right, on=[""key1"", ""key2""])

In [127]: result
Out[127]: 
       A   B key2   C   D
key1                     
K0    A0  B0   K0  C0  D0
K1    A2  B2   K0  C1  D1
K2    A3  B3   K1  C3  D3
",https://pandas.pydata.org/docs/user_guide/merging.html, pandas.Index pandas.DataFrame pandas.DataFrame.merge
"In [128]: right2 = pd.DataFrame({""v"": [7, 8, 9]}, index=[""K1"", ""K1"", ""K2""])

In [129]: result = left.join([right, right2])
",https://pandas.pydata.org/docs/user_guide/merging.html, pandas.DataFrame pandas.DataFrame.join
"In [130]: df1 = pd.DataFrame(
   .....:     [[np.nan, 3.0, 5.0], [-4.6, np.nan, np.nan], [np.nan, 7.0, np.nan]]
   .....: )
   .....: 

In [131]: df2 = pd.DataFrame([[-42.6, np.nan, -8.2], [-5.0, 1.6, 4]], index=[1, 2])

In [132]: result = df1.combine_first(df2)

In [133]: result
Out[133]: 
     0    1    2
0  NaN  3.0  5.0
1 -4.6  NaN -8.2
2 -5.0  7.0  4.0
",https://pandas.pydata.org/docs/user_guide/merging.html, pandas.DataFrame pandas.DataFrame.combine_first
"In [134]: left = pd.DataFrame(
   .....:     {""k"": [""K0"", ""K1"", ""K1"", ""K2""], ""lv"": [1, 2, 3, 4], ""s"": [""a"", ""b"", ""c"", ""d""]}
   .....: )
   .....: 

In [135]: right = pd.DataFrame({""k"": [""K1"", ""K2"", ""K4""], ""rv"": [1, 2, 3]})

In [136]: pd.merge_ordered(left, right, fill_method=""ffill"", left_by=""s"")
Out[136]: 
     k   lv  s   rv
0   K0  1.0  a  NaN
1   K1  1.0  a  1.0
2   K2  1.0  a  2.0
3   K4  1.0  a  3.0
4   K1  2.0  b  1.0
5   K2  2.0  b  2.0
6   K4  2.0  b  3.0
7   K1  3.0  c  1.0
8   K2  3.0  c  2.0
9   K4  3.0  c  3.0
10  K1  NaN  d  1.0
11  K2  4.0  d  2.0
12  K4  4.0  d  3.0
",https://pandas.pydata.org/docs/user_guide/merging.html, pandas.DataFrame pandas.merge_ordered
"In [137]: trades = pd.DataFrame(
   .....:     {
   .....:         ""time"": pd.to_datetime(
   .....:             [
   .....:                 ""20160525 13:30:00.023"",
   .....:                 ""20160525 13:30:00.038"",
   .....:                 ""20160525 13:30:00.048"",
   .....:                 ""20160525 13:30:00.048"",
   .....:                 ""20160525 13:30:00.048"",
   .....:             ]
   .....:         ),
   .....:         ""ticker"": [""MSFT"", ""MSFT"", ""GOOG"", ""GOOG"", ""AAPL""],
   .....:         ""price"": [51.95, 51.95, 720.77, 720.92, 98.00],
   .....:         ""quantity"": [75, 155, 100, 100, 100],
   .....:     },
   .....:     columns=[""time"", ""ticker"", ""price"", ""quantity""],
   .....: )
   .....: 

In [138]: quotes = pd.DataFrame(
   .....:     {
   .....:         ""time"": pd.to_datetime(
   .....:             [
   .....:                 ""20160525 13:30:00.023"",
   .....:                 ""20160525 13:30:00.023"",
   .....:                 ""20160525 13:30:00.030"",
   .....:                 ""20160525 13:30:00.041"",
   .....:                 ""20160525 13:30:00.048"",
   .....:                 ""20160525 13:30:00.049"",
   .....:                 ""20160525 13:30:00.072"",
   .....:                 ""20160525 13:30:00.075"",
   .....:             ]
   .....:         ),
   .....:         ""ticker"": [""GOOG"", ""MSFT"", ""MSFT"", ""MSFT"", ""GOOG"", ""AAPL"", ""GOOG"", ""MSFT""],
   .....:         ""bid"": [720.50, 51.95, 51.97, 51.99, 720.50, 97.99, 720.50, 52.01],
   .....:         ""ask"": [720.93, 51.96, 51.98, 52.00, 720.93, 98.01, 720.88, 52.03],
   .....:     },
   .....:     columns=[""time"", ""ticker"", ""bid"", ""ask""],
   .....: )
   .....: 

In [139]: trades
Out[139]: 
                     time ticker   price  quantity
0 2016-05-25 13:30:00.023   MSFT   51.95        75
1 2016-05-25 13:30:00.038   MSFT   51.95       155
2 2016-05-25 13:30:00.048   GOOG  720.77       100
3 2016-05-25 13:30:00.048   GOOG  720.92       100
4 2016-05-25 13:30:00.048   AAPL   98.00       100

In [140]: quotes
Out[140]: 
                     time ticker     bid     ask
0 2016-05-25 13:30:00.023   GOOG  720.50  720.93
1 2016-05-25 13:30:00.023   MSFT   51.95   51.96
2 2016-05-25 13:30:00.030   MSFT   51.97   51.98
3 2016-05-25 13:30:00.041   MSFT   51.99   52.00
4 2016-05-25 13:30:00.048   GOOG  720.50  720.93
5 2016-05-25 13:30:00.049   AAPL   97.99   98.01
6 2016-05-25 13:30:00.072   GOOG  720.50  720.88
7 2016-05-25 13:30:00.075   MSFT   52.01   52.03

In [141]: pd.merge_asof(trades, quotes, on=""time"", by=""ticker"")
Out[141]: 
                     time ticker   price  quantity     bid     ask
0 2016-05-25 13:30:00.023   MSFT   51.95        75   51.95   51.96
1 2016-05-25 13:30:00.038   MSFT   51.95       155   51.97   51.98
2 2016-05-25 13:30:00.048   GOOG  720.77       100  720.50  720.93
3 2016-05-25 13:30:00.048   GOOG  720.92       100  720.50  720.93
4 2016-05-25 13:30:00.048   AAPL   98.00       100     NaN     NaN
",https://pandas.pydata.org/docs/user_guide/merging.html, pandas.DataFrame pandas.to_datetime pandas.merge_asof
"In [142]: pd.merge_asof(trades, quotes, on=""time"", by=""ticker"", tolerance=pd.Timedelta(""2ms""))
Out[142]: 
                     time ticker   price  quantity     bid     ask
0 2016-05-25 13:30:00.023   MSFT   51.95        75   51.95   51.96
1 2016-05-25 13:30:00.038   MSFT   51.95       155     NaN     NaN
2 2016-05-25 13:30:00.048   GOOG  720.77       100  720.50  720.93
3 2016-05-25 13:30:00.048   GOOG  720.92       100  720.50  720.93
4 2016-05-25 13:30:00.048   AAPL   98.00       100     NaN     NaN
",https://pandas.pydata.org/docs/user_guide/merging.html, pandas.merge_asof
"In [143]: pd.merge_asof(
   .....:     trades,
   .....:     quotes,
   .....:     on=""time"",
   .....:     by=""ticker"",
   .....:     tolerance=pd.Timedelta(""10ms""),
   .....:     allow_exact_matches=False,
   .....: )
   .....: 
Out[143]: 
                     time ticker   price  quantity    bid    ask
0 2016-05-25 13:30:00.023   MSFT   51.95        75    NaN    NaN
1 2016-05-25 13:30:00.038   MSFT   51.95       155  51.97  51.98
2 2016-05-25 13:30:00.048   GOOG  720.77       100    NaN    NaN
3 2016-05-25 13:30:00.048   GOOG  720.92       100    NaN    NaN
4 2016-05-25 13:30:00.048   AAPL   98.00       100    NaN    NaN
",https://pandas.pydata.org/docs/user_guide/merging.html, pandas.merge_asof
"In [144]: df = pd.DataFrame(
   .....:     {
   .....:         ""col1"": [""a"", ""a"", ""b"", ""b"", ""a""],
   .....:         ""col2"": [1.0, 2.0, 3.0, np.nan, 5.0],
   .....:         ""col3"": [1.0, 2.0, 3.0, 4.0, 5.0],
   .....:     },
   .....:     columns=[""col1"", ""col2"", ""col3""],
   .....: )
   .....: 

In [145]: df
Out[145]: 
  col1  col2  col3
0    a   1.0   1.0
1    a   2.0   2.0
2    b   3.0   3.0
3    b   NaN   4.0
4    a   5.0   5.0

In [146]: df2 = df.copy()

In [147]: df2.loc[0, ""col1""] = ""c""

In [148]: df2.loc[2, ""col3""] = 4.0

In [149]: df2
Out[149]: 
  col1  col2  col3
0    c   1.0   1.0
1    a   2.0   2.0
2    b   3.0   4.0
3    b   NaN   4.0
4    a   5.0   5.0

In [150]: df.compare(df2)
Out[150]: 
  col1       col3      
  self other self other
0    a     c  NaN   NaN
2  NaN   NaN  3.0   4.0
",https://pandas.pydata.org/docs/user_guide/merging.html, pandas.DataFrame pandas.DataFrame.copy pandas.DataFrame.compare
"In [151]: df.compare(df2, align_axis=0)
Out[151]: 
        col1  col3
0 self     a   NaN
  other    c   NaN
2 self   NaN   3.0
  other  NaN   4.0
",https://pandas.pydata.org/docs/user_guide/merging.html, pandas.DataFrame.compare
"In [152]: df.compare(df2, keep_shape=True)
Out[152]: 
  col1       col2       col3      
  self other self other self other
0    a     c  NaN   NaN  NaN   NaN
1  NaN   NaN  NaN   NaN  NaN   NaN
2  NaN   NaN  NaN   NaN  3.0   4.0
3  NaN   NaN  NaN   NaN  NaN   NaN
4  NaN   NaN  NaN   NaN  NaN   NaN
",https://pandas.pydata.org/docs/user_guide/merging.html, pandas.DataFrame.compare
"In [153]: df.compare(df2, keep_shape=True, keep_equal=True)
Out[153]: 
  col1       col2       col3      
  self other self other self other
0    a     c  1.0   1.0  1.0   1.0
1    a     a  2.0   2.0  2.0   2.0
2    b     b  3.0   3.0  3.0   4.0
3    b     b  NaN   NaN  4.0   4.0
4    a     a  5.0   5.0  5.0   5.0
",https://pandas.pydata.org/docs/user_guide/merging.html, pandas.DataFrame.compare
"index = pd.RangeIndex(0, 10, 2)
{
    ""kind"": ""range"",
    ""name"": index.name,
    ""start"": index.start,
    ""stop"": index.stop,
    ""step"": index.step,
}
",https://pandas.pydata.org/docs/development/developer.html, pandas.RangeIndex
">>> np.random.seed(42)
>>> df = pd.DataFrame({'A': np.random.randn(10),
...                   'B': np.random.randn(10)},
...                   index=pd.date_range(""1/1/2000"",
...                   freq='4MS', periods=10))
>>> with pd.plotting.plot_params.use(""x_compat"", True):
...     _ = df[""A""].plot(color=""r"")
...     _ = df[""B""].plot(color=""g"")
",https://pandas.pydata.org/docs/reference/api/pandas.plotting.plot_params.html, pandas.DataFrame pandas.date_range
"In [1]: s = pd.Series([1, 2, 3])

In [2]: mask = pd.array([True, False, pd.NA], dtype=""boolean"")

In [3]: s[mask]
Out[3]: 
0    1
dtype: int64
",https://pandas.pydata.org/docs/user_guide/boolean.html, pandas.Series pandas.array
"In [5]: pd.Series([True, False, np.nan], dtype=""object"") | True
Out[5]: 
0     True
1     True
2    False
dtype: bool

In [6]: pd.Series([True, False, np.nan], dtype=""boolean"") | True
Out[6]: 
0    True
1    True
2    True
dtype: boolean
",https://pandas.pydata.org/docs/user_guide/boolean.html, pandas.Series
"In [7]: pd.Series([True, False, np.nan], dtype=""object"") & True
Out[7]: 
0     True
1    False
2    False
dtype: bool

In [8]: pd.Series([True, False, np.nan], dtype=""boolean"") & True
Out[8]: 
0     True
1    False
2     
dtype: boolean
",https://pandas.pydata.org/docs/user_guide/boolean.html, pandas.Series
"s = pd.Series(data, index=index)
",https://pandas.pydata.org/docs/user_guide/dsintro.html, pandas.Series
"In [3]: s = pd.Series(np.random.randn(5), index=[""a"", ""b"", ""c"", ""d"", ""e""])

In [4]: s
Out[4]: 
a    0.469112
b   -0.282863
c   -1.509059
d   -1.135632
e    1.212112
dtype: float64

In [5]: s.index
Out[5]: Index(['a', 'b', 'c', 'd', 'e'], dtype='object')

In [6]: pd.Series(np.random.randn(5))
Out[6]: 
0   -0.173215
1    0.119209
2   -1.044236
3   -0.861849
4   -2.104569
dtype: float64
",https://pandas.pydata.org/docs/user_guide/dsintro.html, pandas.Series pandas.Index
"In [7]: d = {""b"": 1, ""a"": 0, ""c"": 2}

In [8]: pd.Series(d)
Out[8]: 
b    1
a    0
c    2
dtype: int64
",https://pandas.pydata.org/docs/user_guide/dsintro.html, pandas.Series
"In [9]: d = {""a"": 0.0, ""b"": 1.0, ""c"": 2.0}

In [10]: pd.Series(d)
Out[10]: 
a    0.0
b    1.0
c    2.0
dtype: float64

In [11]: pd.Series(d, index=[""b"", ""c"", ""d"", ""a""])
Out[11]: 
b    1.0
c    2.0
d    NaN
a    0.0
dtype: float64
",https://pandas.pydata.org/docs/user_guide/dsintro.html, pandas.Series
"In [12]: pd.Series(5.0, index=[""a"", ""b"", ""c"", ""d"", ""e""])
Out[12]: 
a    5.0
b    5.0
c    5.0
d    5.0
e    5.0
dtype: float64
",https://pandas.pydata.org/docs/user_guide/dsintro.html, pandas.Series
"In [13]: s.iloc[0]
Out[13]: 0.4691122999071863

In [14]: s.iloc[:3]
Out[14]: 
a    0.469112
b   -0.282863
c   -1.509059
dtype: float64

In [15]: s[s > s.median()]
Out[15]: 
a    0.469112
e    1.212112
dtype: float64

In [16]: s.iloc[[4, 3, 1]]
Out[16]: 
e    1.212112
d   -1.135632
b   -0.282863
dtype: float64

In [17]: np.exp(s)
Out[17]: 
a    1.598575
b    0.753623
c    0.221118
d    0.321219
e    3.360575
dtype: float64
",https://pandas.pydata.org/docs/user_guide/dsintro.html, pandas.Series.median
"In [20]: s.to_numpy()
Out[20]: array([ 0.4691, -0.2829, -1.5091, -1.1356,  1.2121])
",https://pandas.pydata.org/docs/user_guide/dsintro.html, pandas.Series.to_numpy pandas.array
"In [26]: s[""f""]
---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
File ~/work/pandas/pandas/pandas/core/indexes/base.py:3805, in Index.get_loc(self, key)
   3804 try:
-> 3805     return self._engine.get_loc(casted_key)
   3806 except KeyError as err:

File index.pyx:167, in pandas._libs.index.IndexEngine.get_loc()

File index.pyx:196, in pandas._libs.index.IndexEngine.get_loc()

File pandas/_libs/hashtable_class_helper.pxi:7081, in pandas._libs.hashtable.PyObjectHashTable.get_item()

File pandas/_libs/hashtable_class_helper.pxi:7089, in pandas._libs.hashtable.PyObjectHashTable.get_item()

KeyError: 'f'

The above exception was the direct cause of the following exception:

KeyError                                  Traceback (most recent call last)
Cell In[26], line 1
----> 1 s[""f""]

File ~/work/pandas/pandas/pandas/core/series.py:1121, in Series.__getitem__(self, key)
   1118     return self._values[key]
   1120 elif key_is_scalar:
-> 1121     return self._get_value(key)
   1123 # Convert generator to list before going through hashable part
   1124 # (We will iterate through the generator there to check for slices)
   1125 if is_iterator(key):

File ~/work/pandas/pandas/pandas/core/series.py:1237, in Series._get_value(self, label, takeable)
   1234     return self._values[label]
   1236 # Similar to Index.get_value, but we do not fall back to positional
-> 1237 loc = self.index.get_loc(label)
   1239 if is_integer(loc):
   1240     return self._values[loc]

File ~/work/pandas/pandas/pandas/core/indexes/base.py:3812, in Index.get_loc(self, key)
   3807     if isinstance(casted_key, slice) or (
   3808         isinstance(casted_key, abc.Iterable)
   3809         and any(isinstance(x, slice) for x in casted_key)
   3810     ):
   3811         raise InvalidIndexError(key)
-> 3812     raise KeyError(key) from err
   3813 except TypeError:
   3814     # If we have a listlike key, _check_indexing_error will raise
   3815     #  InvalidIndexError. Otherwise we fall through and re-raise
   3816     #  the TypeError.
   3817     self._check_indexing_error(key)

KeyError: 'f'
",https://pandas.pydata.org/docs/user_guide/dsintro.html, pandas.Index.get_loc pandas.api.types.is_iterator pandas.api.types.is_integer pandas.errors.InvalidIndexError
"In [27]: s.get(""f"")

In [28]: s.get(""f"", np.nan)
Out[28]: nan
",https://pandas.pydata.org/docs/user_guide/dsintro.html, pandas.Series.get
"In [33]: s = pd.Series(np.random.randn(5), name=""something"")

In [34]: s
Out[34]: 
0   -0.494929
1    1.071804
2    0.721555
3   -0.706771
4   -1.039575
Name: something, dtype: float64

In [35]: s.name
Out[35]: 'something'
",https://pandas.pydata.org/docs/user_guide/dsintro.html, pandas.Series
"In [36]: s2 = s.rename(""different"")

In [37]: s2.name
Out[37]: 'different'
",https://pandas.pydata.org/docs/user_guide/dsintro.html, pandas.Series.rename
"In [38]: d = {
   ....:     ""one"": pd.Series([1.0, 2.0, 3.0], index=[""a"", ""b"", ""c""]),
   ....:     ""two"": pd.Series([1.0, 2.0, 3.0, 4.0], index=[""a"", ""b"", ""c"", ""d""]),
   ....: }
   ....: 

In [39]: df = pd.DataFrame(d)

In [40]: df
Out[40]: 
   one  two
a  1.0  1.0
b  2.0  2.0
c  3.0  3.0
d  NaN  4.0

In [41]: pd.DataFrame(d, index=[""d"", ""b"", ""a""])
Out[41]: 
   one  two
d  NaN  4.0
b  2.0  2.0
a  1.0  1.0

In [42]: pd.DataFrame(d, index=[""d"", ""b"", ""a""], columns=[""two"", ""three""])
Out[42]: 
   two three
d  4.0   NaN
b  2.0   NaN
a  1.0   NaN
",https://pandas.pydata.org/docs/user_guide/dsintro.html, pandas.Series pandas.DataFrame
"In [43]: df.index
Out[43]: Index(['a', 'b', 'c', 'd'], dtype='object')

In [44]: df.columns
Out[44]: Index(['one', 'two'], dtype='object')
",https://pandas.pydata.org/docs/user_guide/dsintro.html, pandas.Index
"In [45]: d = {""one"": [1.0, 2.0, 3.0, 4.0], ""two"": [4.0, 3.0, 2.0, 1.0]}

In [46]: pd.DataFrame(d)
Out[46]: 
   one  two
0  1.0  4.0
1  2.0  3.0
2  3.0  2.0
3  4.0  1.0

In [47]: pd.DataFrame(d, index=[""a"", ""b"", ""c"", ""d""])
Out[47]: 
   one  two
a  1.0  4.0
b  2.0  3.0
c  3.0  2.0
d  4.0  1.0
",https://pandas.pydata.org/docs/user_guide/dsintro.html, pandas.DataFrame
"In [48]: data = np.zeros((2,), dtype=[(""A"", ""i4""), (""B"", ""f4""), (""C"", ""a10"")])

In [49]: data[:] = [(1, 2.0, ""Hello""), (2, 3.0, ""World"")]

In [50]: pd.DataFrame(data)
Out[50]: 
   A    B         C
0  1  2.0  b'Hello'
1  2  3.0  b'World'

In [51]: pd.DataFrame(data, index=[""first"", ""second""])
Out[51]: 
        A    B         C
first   1  2.0  b'Hello'
second  2  3.0  b'World'

In [52]: pd.DataFrame(data, columns=[""C"", ""A"", ""B""])
Out[52]: 
          C  A    B
0  b'Hello'  1  2.0
1  b'World'  2  3.0
",https://pandas.pydata.org/docs/user_guide/dsintro.html, pandas.DataFrame
"In [53]: data2 = [{""a"": 1, ""b"": 2}, {""a"": 5, ""b"": 10, ""c"": 20}]

In [54]: pd.DataFrame(data2)
Out[54]: 
   a   b     c
0  1   2   NaN
1  5  10  20.0

In [55]: pd.DataFrame(data2, index=[""first"", ""second""])
Out[55]: 
        a   b     c
first   1   2   NaN
second  5  10  20.0

In [56]: pd.DataFrame(data2, columns=[""a"", ""b""])
Out[56]: 
   a   b
0  1   2
1  5  10
",https://pandas.pydata.org/docs/user_guide/dsintro.html, pandas.DataFrame
"In [57]: pd.DataFrame(
   ....:     {
   ....:         (""a"", ""b""): {(""A"", ""B""): 1, (""A"", ""C""): 2},
   ....:         (""a"", ""a""): {(""A"", ""C""): 3, (""A"", ""B""): 4},
   ....:         (""a"", ""c""): {(""A"", ""B""): 5, (""A"", ""C""): 6},
   ....:         (""b"", ""a""): {(""A"", ""C""): 7, (""A"", ""B""): 8},
   ....:         (""b"", ""b""): {(""A"", ""D""): 9, (""A"", ""B""): 10},
   ....:     }
   ....: )
   ....: 
Out[57]: 
       a              b      
       b    a    c    a     b
A B  1.0  4.0  5.0  8.0  10.0
  C  2.0  3.0  6.0  7.0   NaN
  D  NaN  NaN  NaN  NaN   9.0
",https://pandas.pydata.org/docs/user_guide/dsintro.html, pandas.DataFrame
"In [58]: ser = pd.Series(range(3), index=list(""abc""), name=""ser"")

In [59]: pd.DataFrame(ser)
Out[59]: 
   ser
a    0
b    1
c    2
",https://pandas.pydata.org/docs/user_guide/dsintro.html, pandas.Series pandas.DataFrame
"In [60]: from collections import namedtuple

In [61]: Point = namedtuple(""Point"", ""x y"")

In [62]: pd.DataFrame([Point(0, 0), Point(0, 3), (2, 3)])
Out[62]: 
   x  y
0  0  0
1  0  3
2  2  3

In [63]: Point3D = namedtuple(""Point3D"", ""x y z"")

In [64]: pd.DataFrame([Point3D(0, 0, 0), Point3D(0, 3, 5), Point(2, 3)])
Out[64]: 
   x  y    z
0  0  0  0.0
1  0  3  5.0
2  2  3  NaN
",https://pandas.pydata.org/docs/user_guide/dsintro.html, pandas.DataFrame
"In [65]: from dataclasses import make_dataclass

In [66]: Point = make_dataclass(""Point"", [(""x"", int), (""y"", int)])

In [67]: pd.DataFrame([Point(0, 0), Point(0, 3), Point(2, 3)])
Out[67]: 
   x  y
0  0  0
1  0  3
2  2  3
",https://pandas.pydata.org/docs/user_guide/dsintro.html, pandas.DataFrame
"In [68]: pd.DataFrame.from_dict(dict([(""A"", [1, 2, 3]), (""B"", [4, 5, 6])]))
Out[68]: 
   A  B
0  1  4
1  2  5
2  3  6
",https://pandas.pydata.org/docs/user_guide/dsintro.html, pandas.DataFrame.from_dict
"In [69]: pd.DataFrame.from_dict(
   ....:     dict([(""A"", [1, 2, 3]), (""B"", [4, 5, 6])]),
   ....:     orient=""index"",
   ....:     columns=[""one"", ""two"", ""three""],
   ....: )
   ....: 
Out[69]: 
   one  two  three
A    1    2      3
B    4    5      6
",https://pandas.pydata.org/docs/user_guide/dsintro.html, pandas.DataFrame.from_dict
"In [70]: data
Out[70]: 
array([(1, 2., b'Hello'), (2, 3., b'World')],
      dtype=[('A', '

In [71]: pd.DataFrame.from_records(data, index=""C"")
Out[71]: 
          A    B
C               
b'Hello'  1  2.0
b'World'  2  3.0
",https://pandas.pydata.org/docs/user_guide/dsintro.html, pandas.array pandas.DataFrame.from_records
"In [76]: del df[""two""]

In [77]: three = df.pop(""three"")

In [78]: df
Out[78]: 
   one   flag
a  1.0  False
b  2.0  False
c  3.0   True
d  NaN  False
",https://pandas.pydata.org/docs/user_guide/dsintro.html, pandas.DataFrame.pop
"In [83]: df.insert(1, ""bar"", df[""one""])

In [84]: df
Out[84]: 
   one  bar   flag  foo  one_trunc
a  1.0  1.0  False  bar        1.0
b  2.0  2.0  False  bar        2.0
c  3.0  3.0   True  bar        NaN
d  NaN  NaN  False  bar        NaN
",https://pandas.pydata.org/docs/user_guide/dsintro.html, pandas.DataFrame.insert
"In [85]: iris = pd.read_csv(""data/iris.data"")

In [86]: iris.head()
Out[86]: 
   SepalLength  SepalWidth  PetalLength  PetalWidth         Name
0          5.1         3.5          1.4         0.2  Iris-setosa
1          4.9         3.0          1.4         0.2  Iris-setosa
2          4.7         3.2          1.3         0.2  Iris-setosa
3          4.6         3.1          1.5         0.2  Iris-setosa
4          5.0         3.6          1.4         0.2  Iris-setosa

In [87]: iris.assign(sepal_ratio=iris[""SepalWidth""] / iris[""SepalLength""]).head()
Out[87]: 
   SepalLength  SepalWidth  PetalLength  PetalWidth         Name  sepal_ratio
0          5.1         3.5          1.4         0.2  Iris-setosa     0.686275
1          4.9         3.0          1.4         0.2  Iris-setosa     0.612245
2          4.7         3.2          1.3         0.2  Iris-setosa     0.680851
3          4.6         3.1          1.5         0.2  Iris-setosa     0.673913
4          5.0         3.6          1.4         0.2  Iris-setosa     0.720000
",https://pandas.pydata.org/docs/user_guide/dsintro.html, pandas.read_csv pandas.DataFrame.assign
"In [88]: iris.assign(sepal_ratio=lambda x: (x[""SepalWidth""] / x[""SepalLength""])).head()
Out[88]: 
   SepalLength  SepalWidth  PetalLength  PetalWidth         Name  sepal_ratio
0          5.1         3.5          1.4         0.2  Iris-setosa     0.686275
1          4.9         3.0          1.4         0.2  Iris-setosa     0.612245
2          4.7         3.2          1.3         0.2  Iris-setosa     0.680851
3          4.6         3.1          1.5         0.2  Iris-setosa     0.673913
4          5.0         3.6          1.4         0.2  Iris-setosa     0.720000
",https://pandas.pydata.org/docs/user_guide/dsintro.html, pandas.DataFrame.assign
"In [89]: (
   ....:     iris.query(""SepalLength > 5"")
   ....:     .assign(
   ....:         SepalRatio=lambda x: x.SepalWidth / x.SepalLength,
   ....:         PetalRatio=lambda x: x.PetalWidth / x.PetalLength,
   ....:     )
   ....:     .plot(kind=""scatter"", x=""SepalRatio"", y=""PetalRatio"")
   ....: )
   ....: 
Out[89]: 
",https://pandas.pydata.org/docs/user_guide/dsintro.html, pandas.DataFrame.query pandas.DataFrame.assign
"In [90]: dfa = pd.DataFrame({""A"": [1, 2, 3], ""B"": [4, 5, 6]})

In [91]: dfa.assign(C=lambda x: x[""A""] + x[""B""], D=lambda x: x[""A""] + x[""C""])
Out[91]: 
   A  B  C   D
0  1  4  5   6
1  2  5  7   9
2  3  6  9  12
",https://pandas.pydata.org/docs/user_guide/dsintro.html, pandas.DataFrame pandas.DataFrame.assign
"In [94]: df = pd.DataFrame(np.random.randn(10, 4), columns=[""A"", ""B"", ""C"", ""D""])

In [95]: df2 = pd.DataFrame(np.random.randn(7, 3), columns=[""A"", ""B"", ""C""])

In [96]: df + df2
Out[96]: 
          A         B         C   D
0  0.045691 -0.014138  1.380871 NaN
1 -0.955398 -1.501007  0.037181 NaN
2 -0.662690  1.534833 -0.859691 NaN
3 -2.452949  1.237274 -0.133712 NaN
4  1.414490  1.951676 -2.320422 NaN
5 -0.494922 -1.649727 -1.084601 NaN
6 -1.047551 -0.748572 -0.805479 NaN
7       NaN       NaN       NaN NaN
8       NaN       NaN       NaN NaN
9       NaN       NaN       NaN NaN
",https://pandas.pydata.org/docs/user_guide/dsintro.html, pandas.DataFrame
"In [101]: df1 = pd.DataFrame({""a"": [1, 0, 1], ""b"": [0, 1, 1]}, dtype=bool)

In [102]: df2 = pd.DataFrame({""a"": [0, 1, 1], ""b"": [1, 1, 0]}, dtype=bool)

In [103]: df1 & df2
Out[103]: 
       a      b
0  False  False
1  False   True
2   True  False

In [104]: df1 | df2
Out[104]: 
      a     b
0  True  True
1  True  True
2  True  True

In [105]: df1 ^ df2
Out[105]: 
       a      b
0   True   True
1   True  False
2  False   True

In [106]: -df1
Out[106]: 
       a      b
0  False   True
1   True  False
2  False  False
",https://pandas.pydata.org/docs/user_guide/dsintro.html, pandas.DataFrame
"In [108]: np.exp(df)
Out[108]: 
           A         B         C         D
0   1.312403  0.653788  1.763006  1.318154
1   0.337092  0.509824  1.120358  0.227996
2   1.690438  1.498861  1.780770  0.179963
3   0.353713  0.690288  0.314148  0.260719
4   2.327710  2.932249  0.896686  5.173571
5   0.230066  1.429065  0.509360  0.169161
6   0.379495  0.274028  1.512461  1.318720
7   0.623732  0.986137  0.695904  0.993865
8   0.397301  2.449092  2.237242  0.299269
9  13.009059  4.183951  3.820223  0.310274

In [109]: np.asarray(df)
Out[109]: 
array([[ 0.2719, -0.425 ,  0.567 ,  0.2762],
       [-1.0874, -0.6737,  0.1136, -1.4784],
       [ 0.525 ,  0.4047,  0.577 , -1.715 ],
       [-1.0393, -0.3706, -1.1579, -1.3443],
       [ 0.8449,  1.0758, -0.109 ,  1.6436],
       [-1.4694,  0.357 , -0.6746, -1.7769],
       [-0.9689, -1.2945,  0.4137,  0.2767],
       [-0.472 , -0.014 , -0.3625, -0.0062],
       [-0.9231,  0.8957,  0.8052, -1.2064],
       [ 2.5656,  1.4313,  1.3403, -1.1703]])
",https://pandas.pydata.org/docs/user_guide/dsintro.html, pandas.array
"In [110]: ser = pd.Series([1, 2, 3, 4])

In [111]: np.exp(ser)
Out[111]: 
0     2.718282
1     7.389056
2    20.085537
3    54.598150
dtype: float64
",https://pandas.pydata.org/docs/user_guide/dsintro.html, pandas.Series
"In [112]: ser1 = pd.Series([1, 2, 3], index=[""a"", ""b"", ""c""])

In [113]: ser2 = pd.Series([1, 3, 5], index=[""b"", ""a"", ""c""])

In [114]: ser1
Out[114]: 
a    1
b    2
c    3
dtype: int64

In [115]: ser2
Out[115]: 
b    1
a    3
c    5
dtype: int64

In [116]: np.remainder(ser1, ser2)
Out[116]: 
a    1
b    0
c    3
dtype: int64
",https://pandas.pydata.org/docs/user_guide/dsintro.html, pandas.Series
"In [117]: ser3 = pd.Series([2, 4, 6], index=[""b"", ""c"", ""d""])

In [118]: ser3
Out[118]: 
b    2
c    4
d    6
dtype: int64

In [119]: np.remainder(ser1, ser3)
Out[119]: 
a    NaN
b    0.0
c    3.0
d    NaN
dtype: float64
",https://pandas.pydata.org/docs/user_guide/dsintro.html, pandas.Series
"In [120]: ser = pd.Series([1, 2, 3])

In [121]: idx = pd.Index([4, 5, 6])

In [122]: np.maximum(ser, idx)
Out[122]: 
0    4
1    5
2    6
dtype: int64
",https://pandas.pydata.org/docs/user_guide/dsintro.html, pandas.Series pandas.Index
"In [123]: baseball = pd.read_csv(""data/baseball.csv"")

In [124]: print(baseball)
       id     player  year  stint team  lg  ...    so  ibb  hbp   sh   sf  gidp
0   88641  womacto01  2006      2  CHN  NL  ...   4.0  0.0  0.0  3.0  0.0   0.0
1   88643  schilcu01  2006      1  BOS  AL  ...   1.0  0.0  0.0  0.0  0.0   0.0
..    ...        ...   ...    ...  ...  ..  ...   ...  ...  ...  ...  ...   ...
98  89533   aloumo01  2007      1  NYN  NL  ...  30.0  5.0  2.0  0.0  3.0  13.0
99  89534  alomasa02  2007      1  NYN  NL  ...   3.0  0.0  0.0  0.0  0.0   0.0

[100 rows x 23 columns]

In [125]: baseball.info()

RangeIndex: 100 entries, 0 to 99
Data columns (total 23 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   id      100 non-null    int64  
 1   player  100 non-null    object 
 2   year    100 non-null    int64  
 3   stint   100 non-null    int64  
 4   team    100 non-null    object 
 5   lg      100 non-null    object 
 6   g       100 non-null    int64  
 7   ab      100 non-null    int64  
 8   r       100 non-null    int64  
 9   h       100 non-null    int64  
 10  X2b     100 non-null    int64  
 11  X3b     100 non-null    int64  
 12  hr      100 non-null    int64  
 13  rbi     100 non-null    float64
 14  sb      100 non-null    float64
 15  cs      100 non-null    float64
 16  bb      100 non-null    int64  
 17  so      100 non-null    float64
 18  ibb     100 non-null    float64
 19  hbp     100 non-null    float64
 20  sh      100 non-null    float64
 21  sf      100 non-null    float64
 22  gidp    100 non-null    float64
dtypes: float64(9), int64(11), object(3)
memory usage: 18.1+ KB
",https://pandas.pydata.org/docs/user_guide/dsintro.html, pandas.read_csv pandas.DataFrame.info
"In [127]: pd.DataFrame(np.random.randn(3, 12))
Out[127]: 
         0         1         2   ...        9         10        11
0 -1.226825  0.769804 -1.281247  ... -1.110336 -0.619976  0.149748
1 -0.732339  0.687738  0.176444  ...  1.462696 -1.743161 -0.826591
2 -0.345352  1.314232  0.690579  ...  0.896171 -0.487602 -0.082240

[3 rows x 12 columns]
",https://pandas.pydata.org/docs/user_guide/dsintro.html, pandas.DataFrame
"In [128]: pd.set_option(""display.width"", 40)  # default is 80

In [129]: pd.DataFrame(np.random.randn(3, 12))
Out[129]: 
         0         1         2   ...        9         10        11
0 -2.182937  0.380396  0.084844  ... -0.023688  2.410179  1.450520
1  0.206053 -0.251905 -2.213588  ... -0.025747 -0.988387  0.094055
2  1.262731  1.289997  0.082423  ... -0.281461  0.030711  0.109121

[3 rows x 12 columns]
",https://pandas.pydata.org/docs/user_guide/dsintro.html, pandas.DataFrame
"In [130]: datafile = {
   .....:     ""filename"": [""filename_01"", ""filename_02""],
   .....:     ""path"": [
   .....:         ""media/user_name/storage/folder_01/filename_01"",
   .....:         ""media/user_name/storage/folder_02/filename_02"",
   .....:     ],
   .....: }
   .....: 

In [131]: pd.set_option(""display.max_colwidth"", 30)

In [132]: pd.DataFrame(datafile)
Out[132]: 
      filename                           path
0  filename_01  media/user_name/storage/fo...
1  filename_02  media/user_name/storage/fo...

In [133]: pd.set_option(""display.max_colwidth"", 100)

In [134]: pd.DataFrame(datafile)
Out[134]: 
      filename                                           path
0  filename_01  media/user_name/storage/folder_01/filename_01
1  filename_02  media/user_name/storage/folder_02/filename_02
",https://pandas.pydata.org/docs/user_guide/dsintro.html, pandas.DataFrame
"In [135]: df = pd.DataFrame({""foo1"": np.random.randn(5), ""foo2"": np.random.randn(5)})

In [136]: df
Out[136]: 
       foo1      foo2
0  1.126203  0.781836
1 -0.977349 -1.071357
2  1.474071  0.441153
3 -0.064034  2.353925
4 -1.282782  0.583787

In [137]: df.foo1
Out[137]: 
0    1.126203
1   -0.977349
2    1.474071
3   -0.064034
4   -1.282782
Name: foo1, dtype: float64
",https://pandas.pydata.org/docs/user_guide/dsintro.html, pandas.DataFrame
"In [17]: pd.to_timedelta(""1 days 06:05:01.00003"")
Out[17]: Timedelta('1 days 06:05:01.000030')

In [18]: pd.to_timedelta(""15.5us"")
Out[18]: Timedelta('0 days 00:00:00.000015500')
",https://pandas.pydata.org/docs/user_guide/timedeltas.html, pandas.to_timedelta
"In [19]: pd.to_timedelta([""1 days 06:05:01.00003"", ""15.5us"", ""nan""])
Out[19]: TimedeltaIndex(['1 days 06:05:01.000030', '0 days 00:00:00.000015500', NaT], dtype='timedelta64[ns]', freq=None)
",https://pandas.pydata.org/docs/user_guide/timedeltas.html, pandas.to_timedelta pandas.TimedeltaIndex
"In [20]: pd.to_timedelta(np.arange(5), unit=""s"")
Out[20]: 
TimedeltaIndex(['0 days 00:00:00', '0 days 00:00:01', '0 days 00:00:02',
                '0 days 00:00:03', '0 days 00:00:04'],
               dtype='timedelta64[ns]', freq=None)

In [21]: pd.to_timedelta(np.arange(5), unit=""d"")
Out[21]: TimedeltaIndex(['0 days', '1 days', '2 days', '3 days', '4 days'], dtype='timedelta64[ns]', freq=None)
",https://pandas.pydata.org/docs/user_guide/timedeltas.html, pandas.to_timedelta pandas.TimedeltaIndex
"In [24]: s = pd.Series(pd.date_range(""2012-1-1"", periods=3, freq=""D""))

In [25]: td = pd.Series([pd.Timedelta(days=i) for i in range(3)])

In [26]: df = pd.DataFrame({""A"": s, ""B"": td})

In [27]: df
Out[27]: 
           A      B
0 2012-01-01 0 days
1 2012-01-02 1 days
2 2012-01-03 2 days

In [28]: df[""C""] = df[""A""] + df[""B""]

In [29]: df
Out[29]: 
           A      B          C
0 2012-01-01 0 days 2012-01-01
1 2012-01-02 1 days 2012-01-03
2 2012-01-03 2 days 2012-01-05

In [30]: df.dtypes
Out[30]: 
A     datetime64[ns]
B    timedelta64[ns]
C     datetime64[ns]
dtype: object

In [31]: s - s.max()
Out[31]: 
0   -2 days
1   -1 days
2    0 days
dtype: timedelta64[ns]

In [32]: s - datetime.datetime(2011, 1, 1, 3, 5)
Out[32]: 
0   364 days 20:55:00
1   365 days 20:55:00
2   366 days 20:55:00
dtype: timedelta64[ns]

In [33]: s + datetime.timedelta(minutes=5)
Out[33]: 
0   2012-01-01 00:05:00
1   2012-01-02 00:05:00
2   2012-01-03 00:05:00
dtype: datetime64[ns]

In [34]: s + pd.offsets.Minute(5)
Out[34]: 
0   2012-01-01 00:05:00
1   2012-01-02 00:05:00
2   2012-01-03 00:05:00
dtype: datetime64[ns]

In [35]: s + pd.offsets.Minute(5) + pd.offsets.Milli(5)
Out[35]: 
0   2012-01-01 00:05:00.005
1   2012-01-02 00:05:00.005
2   2012-01-03 00:05:00.005
dtype: datetime64[ns]
",https://pandas.pydata.org/docs/user_guide/timedeltas.html, pandas.Series pandas.date_range pandas.DataFrame pandas.Series.max
"In [38]: y = s - s.shift()

In [39]: y
Out[39]: 
0      NaT
1   1 days
2   1 days
dtype: timedelta64[ns]
",https://pandas.pydata.org/docs/user_guide/timedeltas.html, pandas.Series.shift
"In [42]: s.max() - s
Out[42]: 
0   2 days
1   1 days
2   0 days
dtype: timedelta64[ns]

In [43]: datetime.datetime(2011, 1, 1, 3, 5) - s
Out[43]: 
0   -365 days +03:05:00
1   -366 days +03:05:00
2   -367 days +03:05:00
dtype: timedelta64[ns]

In [44]: datetime.timedelta(minutes=5) + s
Out[44]: 
0   2012-01-01 00:05:00
1   2012-01-02 00:05:00
2   2012-01-03 00:05:00
dtype: datetime64[ns]
",https://pandas.pydata.org/docs/user_guide/timedeltas.html, pandas.Series.max
"In [45]: A = s - pd.Timestamp(""20120101"") - pd.Timedelta(""00:05:05"")

In [46]: B = s - pd.Series(pd.date_range(""2012-1-2"", periods=3, freq=""D""))

In [47]: df = pd.DataFrame({""A"": A, ""B"": B})

In [48]: df
Out[48]: 
                  A       B
0 -1 days +23:54:55 -1 days
1   0 days 23:54:55 -1 days
2   1 days 23:54:55 -1 days

In [49]: df.min()
Out[49]: 
A   -1 days +23:54:55
B   -1 days +00:00:00
dtype: timedelta64[ns]

In [50]: df.min(axis=1)
Out[50]: 
0   -1 days
1   -1 days
2   -1 days
dtype: timedelta64[ns]

In [51]: df.idxmin()
Out[51]: 
A    0
B    0
dtype: int64

In [52]: df.idxmax()
Out[52]: 
A    2
B    0
dtype: int64
",https://pandas.pydata.org/docs/user_guide/timedeltas.html, pandas.Series pandas.date_range pandas.DataFrame pandas.DataFrame.min pandas.DataFrame.idxmin pandas.DataFrame.idxmax
"In [53]: df.min().max()
Out[53]: Timedelta('-1 days +23:54:55')

In [54]: df.min(axis=1).min()
Out[54]: Timedelta('-1 days +00:00:00')

In [55]: df.min().idxmax()
Out[55]: 'A'

In [56]: df.min(axis=1).idxmin()
Out[56]: 0
",https://pandas.pydata.org/docs/user_guide/timedeltas.html, pandas.DataFrame.min
"In [65]: y2 = pd.Series(
   ....:     pd.to_timedelta([""-1 days +00:00:05"", ""nat"", ""-1 days +00:00:05"", ""1 days""])
   ....: )
   ....: 

In [66]: y2
Out[66]: 
0   -1 days +00:00:05
1                 NaT
2   -1 days +00:00:05
3     1 days 00:00:00
dtype: timedelta64[ns]

In [67]: y2.mean()
Out[67]: Timedelta('-1 days +16:00:03.333333334')

In [68]: y2.median()
Out[68]: Timedelta('-1 days +00:00:05')

In [69]: y2.quantile(0.1)
Out[69]: Timedelta('-1 days +00:00:05')

In [70]: y2.sum()
Out[70]: Timedelta('-1 days +00:00:10')
",https://pandas.pydata.org/docs/user_guide/timedeltas.html, pandas.Series pandas.to_timedelta pandas.Series.mean pandas.Series.median pandas.Series.quantile pandas.Series.sum
"In [71]: december = pd.Series(pd.date_range(""20121201"", periods=4))

In [72]: january = pd.Series(pd.date_range(""20130101"", periods=4))

In [73]: td = january - december

In [74]: td[2] += datetime.timedelta(minutes=5, seconds=3)

In [75]: td[3] = np.nan

In [76]: td
Out[76]: 
0   31 days 00:00:00
1   31 days 00:00:00
2   31 days 00:05:03
3                NaT
dtype: timedelta64[ns]

# to seconds
In [77]: td.astype(""timedelta64[s]"")
Out[77]: 
0   31 days 00:00:00
1   31 days 00:00:00
2   31 days 00:05:03
3                NaT
dtype: timedelta64[s]
",https://pandas.pydata.org/docs/user_guide/timedeltas.html, pandas.Series pandas.date_range pandas.Series.astype
"In [79]: td * -1
Out[79]: 
0   -31 days +00:00:00
1   -31 days +00:00:00
2   -32 days +23:54:57
3                  NaT
dtype: timedelta64[ns]

In [80]: td * pd.Series([1, 2, 3, 4])
Out[80]: 
0   31 days 00:00:00
1   62 days 00:00:00
2   93 days 00:15:09
3                NaT
dtype: timedelta64[ns]
",https://pandas.pydata.org/docs/user_guide/timedeltas.html, pandas.Series
"In [95]: pd.TimedeltaIndex(
   ....:     [
   ....:         ""1 days"",
   ....:         ""1 days, 00:00:05"",
   ....:         np.timedelta64(2, ""D""),
   ....:         datetime.timedelta(days=2, seconds=2),
   ....:     ]
   ....: )
   ....: 
Out[95]: 
TimedeltaIndex(['1 days 00:00:00', '1 days 00:00:05', '2 days 00:00:00',
                '2 days 00:00:02'],
               dtype='timedelta64[ns]', freq=None)
",https://pandas.pydata.org/docs/user_guide/timedeltas.html, pandas.TimedeltaIndex pandas.TimedeltaIndex
"In [96]: pd.TimedeltaIndex([""0 days"", ""10 days"", ""20 days""], freq=""infer"")
Out[96]: TimedeltaIndex(['0 days', '10 days', '20 days'], dtype='timedelta64[ns]', freq='10D')
",https://pandas.pydata.org/docs/user_guide/timedeltas.html, pandas.TimedeltaIndex pandas.TimedeltaIndex
"In [97]: pd.timedelta_range(start=""1 days"", periods=5)
Out[97]: TimedeltaIndex(['1 days', '2 days', '3 days', '4 days', '5 days'], dtype='timedelta64[ns]', freq='D')
",https://pandas.pydata.org/docs/user_guide/timedeltas.html, pandas.timedelta_range pandas.TimedeltaIndex
"In [98]: pd.timedelta_range(start=""1 days"", end=""5 days"")
Out[98]: TimedeltaIndex(['1 days', '2 days', '3 days', '4 days', '5 days'], dtype='timedelta64[ns]', freq='D')

In [99]: pd.timedelta_range(end=""10 days"", periods=4)
Out[99]: TimedeltaIndex(['7 days', '8 days', '9 days', '10 days'], dtype='timedelta64[ns]', freq='D')
",https://pandas.pydata.org/docs/user_guide/timedeltas.html, pandas.timedelta_range pandas.TimedeltaIndex
"In [100]: pd.timedelta_range(start=""1 days"", end=""2 days"", freq=""30min"")
Out[100]: 
TimedeltaIndex(['1 days 00:00:00', '1 days 00:30:00', '1 days 01:00:00',
                '1 days 01:30:00', '1 days 02:00:00', '1 days 02:30:00',
                '1 days 03:00:00', '1 days 03:30:00', '1 days 04:00:00',
                '1 days 04:30:00', '1 days 05:00:00', '1 days 05:30:00',
                '1 days 06:00:00', '1 days 06:30:00', '1 days 07:00:00',
                '1 days 07:30:00', '1 days 08:00:00', '1 days 08:30:00',
                '1 days 09:00:00', '1 days 09:30:00', '1 days 10:00:00',
                '1 days 10:30:00', '1 days 11:00:00', '1 days 11:30:00',
                '1 days 12:00:00', '1 days 12:30:00', '1 days 13:00:00',
                '1 days 13:30:00', '1 days 14:00:00', '1 days 14:30:00',
                '1 days 15:00:00', '1 days 15:30:00', '1 days 16:00:00',
                '1 days 16:30:00', '1 days 17:00:00', '1 days 17:30:00',
                '1 days 18:00:00', '1 days 18:30:00', '1 days 19:00:00',
                '1 days 19:30:00', '1 days 20:00:00', '1 days 20:30:00',
                '1 days 21:00:00', '1 days 21:30:00', '1 days 22:00:00',
                '1 days 22:30:00', '1 days 23:00:00', '1 days 23:30:00',
                '2 days 00:00:00'],
               dtype='timedelta64[ns]', freq='30min')

In [101]: pd.timedelta_range(start=""1 days"", periods=5, freq=""2D5h"")
Out[101]: 
TimedeltaIndex(['1 days 00:00:00', '3 days 05:00:00', '5 days 10:00:00',
                '7 days 15:00:00', '9 days 20:00:00'],
               dtype='timedelta64[ns]', freq='53h')
",https://pandas.pydata.org/docs/user_guide/timedeltas.html, pandas.timedelta_range pandas.TimedeltaIndex
"In [102]: pd.timedelta_range(""0 days"", ""4 days"", periods=5)
Out[102]: TimedeltaIndex(['0 days', '1 days', '2 days', '3 days', '4 days'], dtype='timedelta64[ns]', freq=None)

In [103]: pd.timedelta_range(""0 days"", ""4 days"", periods=10)
Out[103]: 
TimedeltaIndex(['0 days 00:00:00', '0 days 10:40:00', '0 days 21:20:00',
                '1 days 08:00:00', '1 days 18:40:00', '2 days 05:20:00',
                '2 days 16:00:00', '3 days 02:40:00', '3 days 13:20:00',
                '4 days 00:00:00'],
               dtype='timedelta64[ns]', freq=None)
",https://pandas.pydata.org/docs/user_guide/timedeltas.html, pandas.timedelta_range pandas.TimedeltaIndex
"In [104]: s = pd.Series(
   .....:     np.arange(100),
   .....:     index=pd.timedelta_range(""1 days"", periods=100, freq=""h""),
   .....: )
   .....: 

In [105]: s
Out[105]: 
1 days 00:00:00     0
1 days 01:00:00     1
1 days 02:00:00     2
1 days 03:00:00     3
1 days 04:00:00     4
                   ..
4 days 23:00:00    95
5 days 00:00:00    96
5 days 01:00:00    97
5 days 02:00:00    98
5 days 03:00:00    99
Freq: h, Length: 100, dtype: int64
",https://pandas.pydata.org/docs/user_guide/timedeltas.html, pandas.Series pandas.timedelta_range
"In [110]: tdi = pd.TimedeltaIndex([""1 days"", pd.NaT, ""2 days""])

In [111]: tdi.to_list()
Out[111]: [Timedelta('1 days 00:00:00'), NaT, Timedelta('2 days 00:00:00')]

In [112]: dti = pd.date_range(""20130101"", periods=3)

In [113]: dti.to_list()
Out[113]: 
[Timestamp('2013-01-01 00:00:00'),
 Timestamp('2013-01-02 00:00:00'),
 Timestamp('2013-01-03 00:00:00')]

In [114]: (dti + tdi).to_list()
Out[114]: [Timestamp('2013-01-02 00:00:00'), NaT, Timestamp('2013-01-05 00:00:00')]

In [115]: (dti - tdi).to_list()
Out[115]: [Timestamp('2012-12-31 00:00:00'), NaT, Timestamp('2013-01-01 00:00:00')]
",https://pandas.pydata.org/docs/user_guide/timedeltas.html, pandas.TimedeltaIndex pandas.date_range
"In [116]: tdi / np.timedelta64(1, ""s"")
Out[116]: Index([86400.0, nan, 172800.0], dtype='float64')

In [117]: tdi.astype(""timedelta64[s]"")
Out[117]: TimedeltaIndex(['1 days', NaT, '2 days'], dtype='timedelta64[s]', freq=None)
",https://pandas.pydata.org/docs/user_guide/timedeltas.html, pandas.Index pandas.TimedeltaIndex
"# adding or timedelta and date -> datelike
In [118]: tdi + pd.Timestamp(""20130101"")
Out[118]: DatetimeIndex(['2013-01-02', 'NaT', '2013-01-03'], dtype='datetime64[ns]', freq=None)

# subtraction of a date and a timedelta -> datelike
# note that trying to subtract a date from a Timedelta will raise an exception
In [119]: (pd.Timestamp(""20130101"") - tdi).to_list()
Out[119]: [Timestamp('2012-12-31 00:00:00'), NaT, Timestamp('2012-12-30 00:00:00')]

# timedelta + timedelta -> timedelta
In [120]: tdi + pd.Timedelta(""10 days"")
Out[120]: TimedeltaIndex(['11 days', NaT, '12 days'], dtype='timedelta64[ns]', freq=None)

# division can result in a Timedelta if the divisor is an integer
In [121]: tdi / 2
Out[121]: TimedeltaIndex(['0 days 12:00:00', NaT, '1 days 00:00:00'], dtype='timedelta64[ns]', freq=None)

# or a float64 Index if the divisor is a Timedelta
In [122]: tdi / tdi[0]
Out[122]: Index([1.0, nan, 2.0], dtype='float64')
",https://pandas.pydata.org/docs/user_guide/timedeltas.html, pandas.DatetimeIndex pandas.TimedeltaIndex pandas.Index
"In [123]: s.resample(""D"").mean()
Out[123]: 
1 days    11.5
2 days    35.5
3 days    59.5
4 days    83.5
5 days    97.5
Freq: D, dtype: float64
",https://pandas.pydata.org/docs/user_guide/timedeltas.html, pandas.Series.resample
"In [1]: arrays = [
   ...:     [""bar"", ""bar"", ""baz"", ""baz"", ""foo"", ""foo"", ""qux"", ""qux""],
   ...:     [""one"", ""two"", ""one"", ""two"", ""one"", ""two"", ""one"", ""two""],
   ...: ]
   ...: 

In [2]: tuples = list(zip(*arrays))

In [3]: tuples
Out[3]: 
[('bar', 'one'),
 ('bar', 'two'),
 ('baz', 'one'),
 ('baz', 'two'),
 ('foo', 'one'),
 ('foo', 'two'),
 ('qux', 'one'),
 ('qux', 'two')]

In [4]: index = pd.MultiIndex.from_tuples(tuples, names=[""first"", ""second""])

In [5]: index
Out[5]: 
MultiIndex([('bar', 'one'),
            ('bar', 'two'),
            ('baz', 'one'),
            ('baz', 'two'),
            ('foo', 'one'),
            ('foo', 'two'),
            ('qux', 'one'),
            ('qux', 'two')],
           names=['first', 'second'])

In [6]: s = pd.Series(np.random.randn(8), index=index)

In [7]: s
Out[7]: 
first  second
bar    one       0.469112
       two      -0.282863
baz    one      -1.509059
       two      -1.135632
foo    one       1.212112
       two      -0.173215
qux    one       0.119209
       two      -1.044236
dtype: float64
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.MultiIndex.from_tuples pandas.MultiIndex pandas.Series
"In [8]: iterables = [[""bar"", ""baz"", ""foo"", ""qux""], [""one"", ""two""]]

In [9]: pd.MultiIndex.from_product(iterables, names=[""first"", ""second""])
Out[9]: 
MultiIndex([('bar', 'one'),
            ('bar', 'two'),
            ('baz', 'one'),
            ('baz', 'two'),
            ('foo', 'one'),
            ('foo', 'two'),
            ('qux', 'one'),
            ('qux', 'two')],
           names=['first', 'second'])
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.MultiIndex.from_product pandas.MultiIndex
"In [10]: df = pd.DataFrame(
   ....:     [[""bar"", ""one""], [""bar"", ""two""], [""foo"", ""one""], [""foo"", ""two""]],
   ....:     columns=[""first"", ""second""],
   ....: )
   ....: 

In [11]: pd.MultiIndex.from_frame(df)
Out[11]: 
MultiIndex([('bar', 'one'),
            ('bar', 'two'),
            ('foo', 'one'),
            ('foo', 'two')],
           names=['first', 'second'])
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.DataFrame pandas.MultiIndex.from_frame pandas.MultiIndex
"In [12]: arrays = [
   ....:     np.array([""bar"", ""bar"", ""baz"", ""baz"", ""foo"", ""foo"", ""qux"", ""qux""]),
   ....:     np.array([""one"", ""two"", ""one"", ""two"", ""one"", ""two"", ""one"", ""two""]),
   ....: ]
   ....: 

In [13]: s = pd.Series(np.random.randn(8), index=arrays)

In [14]: s
Out[14]: 
bar  one   -0.861849
     two   -2.104569
baz  one   -0.494929
     two    1.071804
foo  one    0.721555
     two   -0.706771
qux  one   -1.039575
     two    0.271860
dtype: float64

In [15]: df = pd.DataFrame(np.random.randn(8, 4), index=arrays)

In [16]: df
Out[16]: 
                0         1         2         3
bar one -0.424972  0.567020  0.276232 -1.087401
    two -0.673690  0.113648 -1.478427  0.524988
baz one  0.404705  0.577046 -1.715002 -1.039268
    two -0.370647 -1.157892 -1.344312  0.844885
foo one  1.075770 -0.109050  1.643563 -1.469388
    two  0.357021 -0.674600 -1.776904 -0.968914
qux one -1.294524  0.413738  0.276662 -0.472035
    two -0.013960 -0.362543 -0.006154 -0.923061
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.Series pandas.DataFrame
"In [18]: df = pd.DataFrame(np.random.randn(3, 8), index=[""A"", ""B"", ""C""], columns=index)

In [19]: df
Out[19]: 
first        bar                 baz  ...       foo       qux          
second       one       two       one  ...       two       one       two
A       0.895717  0.805244 -1.206412  ...  1.340309 -1.170299 -0.226169
B       0.410835  0.813850  0.132003  ... -1.187678  1.130127 -1.436737
C      -1.413681  1.607920  1.024180  ... -2.211372  0.974466 -2.006747

[3 rows x 8 columns]

In [20]: pd.DataFrame(np.random.randn(6, 6), index=index[:6], columns=index[:6])
Out[20]: 
first              bar                 baz                 foo          
second             one       two       one       two       one       two
first second                                                            
bar   one    -0.410001 -0.078638  0.545952 -1.219217 -1.226825  0.769804
      two    -1.281247 -0.727707 -0.121306 -0.097883  0.695775  0.341734
baz   one     0.959726 -1.110336 -0.619976  0.149748 -0.732339  0.687738
      two     0.176444  0.403310 -0.154951  0.301624 -2.179861 -1.369849
foo   one    -0.954208  1.462696 -1.743161 -0.826591 -0.345352  1.314232
      two     0.690579  0.995761  2.396780  0.014871  3.357427 -0.317441
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.DataFrame
"In [22]: pd.Series(np.random.randn(8), index=tuples)
Out[22]: 
(bar, one)   -1.236269
(bar, two)    0.896171
(baz, one)   -0.487602
(baz, two)   -0.082240
(foo, one)   -2.182937
(foo, two)    0.380396
(qux, one)    0.084844
(qux, two)    0.432390
dtype: float64
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.Series
"In [23]: index.get_level_values(0)
Out[23]: Index(['bar', 'bar', 'baz', 'baz', 'foo', 'foo', 'qux', 'qux'], dtype='object', name='first')

In [24]: index.get_level_values(""second"")
Out[24]: Index(['one', 'two', 'one', 'two', 'one', 'two', 'one', 'two'], dtype='object', name='second')
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.Index
"In [31]: df[[""foo"", ""qux""]].columns.to_numpy()
Out[31]: 
array([('foo', 'one'), ('foo', 'two'), ('qux', 'one'), ('qux', 'two')],
      dtype=object)

# for a specific level
In [32]: df[[""foo"", ""qux""]].columns.get_level_values(0)
Out[32]: Index(['foo', 'foo', 'qux', 'qux'], dtype='object', name='first')
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.array pandas.Index
"In [33]: new_mi = df[[""foo"", ""qux""]].columns.remove_unused_levels()

In [34]: new_mi.levels
Out[34]: FrozenList([['foo', 'qux'], ['one', 'two']])
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.MultiIndex.remove_unused_levels
"In [37]: s.reindex(index[:3])
Out[37]: 
first  second
bar    one      -0.861849
       two      -2.104569
baz    one      -0.494929
dtype: float64

In [38]: s.reindex([(""foo"", ""two""), (""bar"", ""one""), (""qux"", ""one""), (""baz"", ""one"")])
Out[38]: 
foo  two   -0.706771
bar  one   -0.861849
qux  one   -1.039575
baz  one   -0.494929
dtype: float64
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.Series.reindex
"In [48]: s = pd.Series(
   ....:     [1, 2, 3, 4, 5, 6],
   ....:     index=pd.MultiIndex.from_product([[""A"", ""B""], [""c"", ""d"", ""e""]]),
   ....: )
   ....: 

In [49]: s.loc[[(""A"", ""c""), (""B"", ""d"")]]  # list of tuples
Out[49]: 
A  c    1
B  d    5
dtype: int64

In [50]: s.loc[([""A"", ""B""], [""c"", ""d""])]  # tuple of lists
Out[50]: 
A  c    1
   d    2
B  c    4
   d    5
dtype: int64
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.Series pandas.MultiIndex.from_product
"df.loc[(slice(""A1"", ""A3""), ...), :]  # noqa: E999
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.Series.str.slice
"df.loc[(slice(""A1"", ""A3""), ...)]  # noqa: E999
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.Series.str.slice
"In [51]: def mklbl(prefix, n):
   ....:     return [""%s%s"" % (prefix, i) for i in range(n)]
   ....: 

In [52]: miindex = pd.MultiIndex.from_product(
   ....:     [mklbl(""A"", 4), mklbl(""B"", 2), mklbl(""C"", 4), mklbl(""D"", 2)]
   ....: )
   ....: 

In [53]: micolumns = pd.MultiIndex.from_tuples(
   ....:     [(""a"", ""foo""), (""a"", ""bar""), (""b"", ""foo""), (""b"", ""bah"")], names=[""lvl0"", ""lvl1""]
   ....: )
   ....: 

In [54]: dfmi = (
   ....:     pd.DataFrame(
   ....:         np.arange(len(miindex) * len(micolumns)).reshape(
   ....:             (len(miindex), len(micolumns))
   ....:         ),
   ....:         index=miindex,
   ....:         columns=micolumns,
   ....:     )
   ....:     .sort_index()
   ....:     .sort_index(axis=1)
   ....: )
   ....: 

In [55]: dfmi
Out[55]: 
lvl0           a         b     
lvl1         bar  foo  bah  foo
A0 B0 C0 D0    1    0    3    2
         D1    5    4    7    6
      C1 D0    9    8   11   10
         D1   13   12   15   14
      C2 D0   17   16   19   18
...          ...  ...  ...  ...
A3 B1 C1 D1  237  236  239  238
      C2 D0  241  240  243  242
         D1  245  244  247  246
      C3 D0  249  248  251  250
         D1  253  252  255  254

[64 rows x 4 columns]
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.MultiIndex.from_product pandas.MultiIndex.from_tuples pandas.DataFrame
"In [56]: dfmi.loc[(slice(""A1"", ""A3""), slice(None), [""C1"", ""C3""]), :]
Out[56]: 
lvl0           a         b     
lvl1         bar  foo  bah  foo
A1 B0 C1 D0   73   72   75   74
         D1   77   76   79   78
      C3 D0   89   88   91   90
         D1   93   92   95   94
   B1 C1 D0  105  104  107  106
...          ...  ...  ...  ...
A3 B0 C3 D1  221  220  223  222
   B1 C1 D0  233  232  235  234
         D1  237  236  239  238
      C3 D0  249  248  251  250
         D1  253  252  255  254

[24 rows x 4 columns]
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.Series.str.slice
"In [59]: dfmi.loc[""A1"", (slice(None), ""foo"")]
Out[59]: 
lvl0        a    b
lvl1      foo  foo
B0 C0 D0   64   66
      D1   68   70
   C1 D0   72   74
      D1   76   78
   C2 D0   80   82
...       ...  ...
B1 C1 D1  108  110
   C2 D0  112  114
      D1  116  118
   C3 D0  120  122
      D1  124  126

[16 rows x 2 columns]

In [60]: dfmi.loc[idx[:, :, [""C1"", ""C3""]], idx[:, ""foo""]]
Out[60]: 
lvl0           a    b
lvl1         foo  foo
A0 B0 C1 D0    8   10
         D1   12   14
      C3 D0   24   26
         D1   28   30
   B1 C1 D0   40   42
...          ...  ...
A3 B0 C3 D1  220  222
   B1 C1 D0  232  234
         D1  236  238
      C3 D0  248  250
         D1  252  254

[32 rows x 2 columns]
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.Series.str.slice
"In [70]: df
Out[70]: 
                     A         B         C
first second                              
bar   one     0.895717  0.410835 -1.413681
      two     0.805244  0.813850  1.607920
baz   one    -1.206412  0.132003  1.024180
      two     2.565646 -0.827317  0.569605
foo   one     1.431256 -0.076467  0.875906
      two     1.340309 -1.187678 -2.211372
qux   one    -1.170299  1.130127  0.974466
      two    -0.226169 -1.436737 -2.006747

In [71]: df.xs(""one"", level=""second"")
Out[71]: 
              A         B         C
first                              
bar    0.895717  0.410835 -1.413681
baz   -1.206412  0.132003  1.024180
foo    1.431256 -0.076467  0.875906
qux   -1.170299  1.130127  0.974466
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.DataFrame.xs
"# using the slicers
In [72]: df.loc[(slice(None), ""one""), :]
Out[72]: 
                     A         B         C
first second                              
bar   one     0.895717  0.410835 -1.413681
baz   one    -1.206412  0.132003  1.024180
foo   one     1.431256 -0.076467  0.875906
qux   one    -1.170299  1.130127  0.974466
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.Series.str.slice
"In [73]: df = df.T

In [74]: df.xs(""one"", level=""second"", axis=1)
Out[74]: 
first       bar       baz       foo       qux
A      0.895717 -1.206412  1.431256 -1.170299
B      0.410835  0.132003 -0.076467  1.130127
C     -1.413681  1.024180  0.875906  0.974466
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.DataFrame.xs
"# using the slicers
In [75]: df.loc[:, (slice(None), ""one"")]
Out[75]: 
first        bar       baz       foo       qux
second       one       one       one       one
A       0.895717 -1.206412  1.431256 -1.170299
B       0.410835  0.132003 -0.076467  1.130127
C      -1.413681  1.024180  0.875906  0.974466
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.Series.str.slice
"In [76]: df.xs((""one"", ""bar""), level=(""second"", ""first""), axis=1)
Out[76]: 
first        bar
second       one
A       0.895717
B       0.410835
C      -1.413681
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.DataFrame.xs
"In [78]: df.xs(""one"", level=""second"", axis=1, drop_level=False)
Out[78]: 
first        bar       baz       foo       qux
second       one       one       one       one
A       0.895717 -1.206412  1.431256 -1.170299
B       0.410835  0.132003 -0.076467  1.130127
C      -1.413681  1.024180  0.875906  0.974466
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.DataFrame.xs
"In [79]: df.xs(""one"", level=""second"", axis=1, drop_level=True)
Out[79]: 
first       bar       baz       foo       qux
A      0.895717 -1.206412  1.431256 -1.170299
B      0.410835  0.132003 -0.076467  1.130127
C     -1.413681  1.024180  0.875906  0.974466
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.DataFrame.xs
"In [80]: midx = pd.MultiIndex(
   ....:     levels=[[""zero"", ""one""], [""x"", ""y""]], codes=[[1, 1, 0, 0], [1, 0, 1, 0]]
   ....: )
   ....: 

In [81]: df = pd.DataFrame(np.random.randn(4, 2), index=midx)

In [82]: df
Out[82]: 
               0         1
one  y  1.519970 -0.493662
     x  0.600178  0.274230
zero y  0.132885 -0.023688
     x  2.410179  1.450520

In [83]: df2 = df.groupby(level=0).mean()

In [84]: df2
Out[84]: 
             0         1
one   1.060074 -0.109716
zero  1.271532  0.713416

In [85]: df2.reindex(df.index, level=0)
Out[85]: 
               0         1
one  y  1.060074 -0.109716
     x  1.060074 -0.109716
zero y  1.271532  0.713416
     x  1.271532  0.713416

# aligning
In [86]: df_aligned, df2_aligned = df.align(df2, level=0)

In [87]: df_aligned
Out[87]: 
               0         1
one  y  1.519970 -0.493662
     x  0.600178  0.274230
zero y  0.132885 -0.023688
     x  2.410179  1.450520

In [88]: df2_aligned
Out[88]: 
               0         1
one  y  1.060074 -0.109716
     x  1.060074 -0.109716
zero y  1.271532  0.713416
     x  1.271532  0.713416
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.MultiIndex pandas.DataFrame pandas.DataFrame.groupby pandas.DataFrame.reindex pandas.DataFrame.align
"In [92]: df.rename(columns={0: ""col0"", 1: ""col1""})
Out[92]: 
            col0      col1
one  y  1.519970 -0.493662
     x  0.600178  0.274230
zero y  0.132885 -0.023688
     x  2.410179  1.450520
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.DataFrame.rename
"In [93]: df.rename(index={""one"": ""two"", ""y"": ""z""})
Out[93]: 
               0         1
two  z  1.519970 -0.493662
     x  0.600178  0.274230
zero z  0.132885 -0.023688
     x  2.410179  1.450520
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.DataFrame.rename
"In [94]: df.rename_axis(index=[""abc"", ""def""])
Out[94]: 
                 0         1
abc  def                    
one  y    1.519970 -0.493662
     x    0.600178  0.274230
zero y    0.132885 -0.023688
     x    2.410179  1.450520
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.DataFrame.rename_axis
"In [95]: df.rename_axis(columns=""Cols"").columns
Out[95]: RangeIndex(start=0, stop=2, step=1, name='Cols')
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.DataFrame.rename_axis pandas.RangeIndex
"In [96]: mi = pd.MultiIndex.from_product([[1, 2], [""a"", ""b""]], names=[""x"", ""y""])

In [97]: mi.names
Out[97]: FrozenList(['x', 'y'])

In [98]: mi2 = mi.rename(""new name"", level=0)

In [99]: mi2
Out[99]: 
MultiIndex([(1, 'a'),
            (1, 'b'),
            (2, 'a'),
            (2, 'b')],
           names=['new name', 'y'])
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.MultiIndex.from_product pandas.MultiIndex
"In [101]: import random

In [102]: random.shuffle(tuples)

In [103]: s = pd.Series(np.random.randn(8), index=pd.MultiIndex.from_tuples(tuples))

In [104]: s
Out[104]: 
qux  two    0.206053
bar  one   -0.251905
foo  one   -2.213588
qux  one    1.063327
foo  two    1.266143
baz  two    0.299368
bar  two   -0.863838
baz  one    0.408204
dtype: float64

In [105]: s.sort_index()
Out[105]: 
bar  one   -0.251905
     two   -0.863838
baz  one    0.408204
     two    0.299368
foo  one   -2.213588
     two    1.266143
qux  one    1.063327
     two    0.206053
dtype: float64

In [106]: s.sort_index(level=0)
Out[106]: 
bar  one   -0.251905
     two   -0.863838
baz  one    0.408204
     two    0.299368
foo  one   -2.213588
     two    1.266143
qux  one    1.063327
     two    0.206053
dtype: float64

In [107]: s.sort_index(level=1)
Out[107]: 
bar  one   -0.251905
baz  one    0.408204
foo  one   -2.213588
qux  one    1.063327
bar  two   -0.863838
baz  two    0.299368
foo  two    1.266143
qux  two    0.206053
dtype: float64
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.Series pandas.MultiIndex.from_tuples pandas.Series.sort_index
"In [108]: s.index = s.index.set_names([""L1"", ""L2""])

In [109]: s.sort_index(level=""L1"")
Out[109]: 
L1   L2 
bar  one   -0.251905
     two   -0.863838
baz  one    0.408204
     two    0.299368
foo  one   -2.213588
     two    1.266143
qux  one    1.063327
     two    0.206053
dtype: float64

In [110]: s.sort_index(level=""L2"")
Out[110]: 
L1   L2 
bar  one   -0.251905
baz  one    0.408204
foo  one   -2.213588
qux  one    1.063327
bar  two   -0.863838
baz  two    0.299368
foo  two    1.266143
qux  two    0.206053
dtype: float64
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.Series.sort_index
"In [112]: dfm = pd.DataFrame(
   .....:     {""jim"": [0, 0, 1, 1], ""joe"": [""x"", ""x"", ""z"", ""y""], ""jolie"": np.random.rand(4)}
   .....: )
   .....: 

In [113]: dfm = dfm.set_index([""jim"", ""joe""])

In [114]: dfm
Out[114]: 
            jolie
jim joe          
0   x    0.490671
    x    0.120248
1   z    0.537020
    y    0.110968

In [115]: dfm.loc[(1, 'z')]
Out[115]: 
           jolie
jim joe         
1   z    0.53702
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.DataFrame pandas.DataFrame.set_index
"In [116]: dfm.loc[(0, 'y'):(1, 'z')]
---------------------------------------------------------------------------
UnsortedIndexError                        Traceback (most recent call last)
Cell In[116], line 1
----> 1 dfm.loc[(0, 'y'):(1, 'z')]

File ~/work/pandas/pandas/pandas/core/indexing.py:1191, in _LocationIndexer.__getitem__(self, key)
   1189 maybe_callable = com.apply_if_callable(key, self.obj)
   1190 maybe_callable = self._check_deprecated_callable_usage(key, maybe_callable)
-> 1191 return self._getitem_axis(maybe_callable, axis=axis)

File ~/work/pandas/pandas/pandas/core/indexing.py:1411, in _LocIndexer._getitem_axis(self, key, axis)
   1409 if isinstance(key, slice):
   1410     self._validate_key(key, axis)
-> 1411     return self._get_slice_axis(key, axis=axis)
   1412 elif com.is_bool_indexer(key):
   1413     return self._getbool_axis(key, axis=axis)

File ~/work/pandas/pandas/pandas/core/indexing.py:1443, in _LocIndexer._get_slice_axis(self, slice_obj, axis)
   1440     return obj.copy(deep=False)
   1442 labels = obj._get_axis(axis)
-> 1443 indexer = labels.slice_indexer(slice_obj.start, slice_obj.stop, slice_obj.step)
   1445 if isinstance(indexer, slice):
   1446     return self.obj._slice(indexer, axis=axis)

File ~/work/pandas/pandas/pandas/core/indexes/base.py:6662, in Index.slice_indexer(self, start, end, step)
   6618 def slice_indexer(
   6619     self,
   6620     start: Hashable | None = None,
   6621     end: Hashable | None = None,
   6622     step: int | None = None,
   6623 ) -> slice:
   6624     """"""
   6625     Compute the slice indexer for input labels and step.
   6626 
   (...)
   6660     slice(1, 3, None)
   6661     """"""
-> 6662     start_slice, end_slice = self.slice_locs(start, end, step=step)
   6664     # return a slice
   6665     if not is_scalar(start_slice):

File ~/work/pandas/pandas/pandas/core/indexes/multi.py:2904, in MultiIndex.slice_locs(self, start, end, step)
   2852 """"""
   2853 For an ordered MultiIndex, compute the slice locations for input
   2854 labels.
   (...)
   2900                       sequence of such.
   2901 """"""
   2902 # This function adds nothing to its parent implementation (the magic
   2903 # happens in get_slice_bound method), but it adds meaningful doc.
-> 2904 return super().slice_locs(start, end, step)

File ~/work/pandas/pandas/pandas/core/indexes/base.py:6879, in Index.slice_locs(self, start, end, step)
   6877 start_slice = None
   6878 if start is not None:
-> 6879     start_slice = self.get_slice_bound(start, ""left"")
   6880 if start_slice is None:
   6881     start_slice = 0

File ~/work/pandas/pandas/pandas/core/indexes/multi.py:2848, in MultiIndex.get_slice_bound(self, label, side)
   2846 if not isinstance(label, tuple):
   2847     label = (label,)
-> 2848 return self._partial_tup_index(label, side=side)

File ~/work/pandas/pandas/pandas/core/indexes/multi.py:2908, in MultiIndex._partial_tup_index(self, tup, side)
   2906 def _partial_tup_index(self, tup: tuple, side: Literal[""left"", ""right""] = ""left""):
   2907     if len(tup) > self._lexsort_depth:
-> 2908         raise UnsortedIndexError(
   2909             f""Key length ({len(tup)}) was greater than MultiIndex lexsort depth ""
   2910             f""({self._lexsort_depth})""
   2911         )
   2913     n = len(tup)
   2914     start, end = 0, len(self)

UnsortedIndexError: 'Key length (2) was greater than MultiIndex lexsort depth (1)'
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.Index.slice_indexer pandas.Index.slice_indexer pandas.Index.slice_indexer pandas.Series.str.slice pandas.Index.slice_locs pandas.api.types.is_scalar pandas.Index.slice_locs pandas.Index.slice_locs pandas.Index.slice_locs pandas.Index.get_slice_bound pandas.Index.get_slice_bound pandas.errors.UnsortedIndexError
"In [118]: dfm = dfm.sort_index()

In [119]: dfm
Out[119]: 
            jolie
jim joe          
0   x    0.490671
    x    0.120248
1   y    0.110968
    z    0.537020

In [120]: dfm.index.is_monotonic_increasing
Out[120]: True
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.DataFrame.sort_index
"In [122]: index = pd.Index(np.random.randint(0, 1000, 10))

In [123]: index
Out[123]: Index([214, 502, 712, 567, 786, 175, 993, 133, 758, 329], dtype='int64')

In [124]: positions = [0, 9, 3]

In [125]: index[positions]
Out[125]: Index([214, 329, 567], dtype='int64')

In [126]: index.take(positions)
Out[126]: Index([214, 329, 567], dtype='int64')

In [127]: ser = pd.Series(np.random.randn(10))

In [128]: ser.iloc[positions]
Out[128]: 
0   -0.179666
9    1.824375
3    0.392149
dtype: float64

In [129]: ser.take(positions)
Out[129]: 
0   -0.179666
9    1.824375
3    0.392149
dtype: float64
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.Index pandas.Index pandas.Index.take pandas.Series pandas.Series.take
"In [130]: frm = pd.DataFrame(np.random.randn(5, 3))

In [131]: frm.take([1, 4, 3])
Out[131]: 
          0         1         2
1 -1.237881  0.106854 -1.276829
4  0.629675 -1.425966  1.857704
3  0.979542 -1.633678  0.615855

In [132]: frm.take([0, 2], axis=1)
Out[132]: 
          0         2
0  0.595974  0.601544
1 -1.237881 -1.276829
2 -0.767101  1.499591
3  0.979542  0.615855
4  0.629675  1.857704
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.DataFrame pandas.DataFrame.take
"In [133]: arr = np.random.randn(10)

In [134]: arr.take([False, False, True, True])
Out[134]: array([-1.1935, -1.1935,  0.6775,  0.6775])

In [135]: arr[[0, 1]]
Out[135]: array([-1.1935,  0.6775])

In [136]: ser = pd.Series(np.random.randn(10))

In [137]: ser.take([False, False, True, True])
Out[137]: 
0    0.233141
0    0.233141
1   -0.223540
1   -0.223540
dtype: float64

In [138]: ser.iloc[[0, 1]]
Out[138]: 
0    0.233141
1   -0.223540
dtype: float64
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.array pandas.Series pandas.Series.take
"In [143]: ser = pd.Series(arr[:, 0])

In [144]: %timeit ser.iloc[indexer]
   .....: %timeit ser.take(indexer)
   .....: 
144 us +- 3.69 us per loop (mean +- std. dev. of 7 runs, 10,000 loops each)
129 us +- 2 us per loop (mean +- std. dev. of 7 runs, 10,000 loops each)
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.Series pandas.Series.take
"In [145]: from pandas.api.types import CategoricalDtype

In [146]: df = pd.DataFrame({""A"": np.arange(6), ""B"": list(""aabbca"")})

In [147]: df[""B""] = df[""B""].astype(CategoricalDtype(list(""cab"")))

In [148]: df
Out[148]: 
   A  B
0  0  a
1  1  a
2  2  b
3  3  b
4  4  c
5  5  a

In [149]: df.dtypes
Out[149]: 
A       int64
B    category
dtype: object

In [150]: df[""B""].cat.categories
Out[150]: Index(['c', 'a', 'b'], dtype='object')
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.DataFrame pandas.CategoricalDtype pandas.Index
"In [151]: df2 = df.set_index(""B"")

In [152]: df2.index
Out[152]: CategoricalIndex(['a', 'a', 'b', 'b', 'c', 'a'], categories=['c', 'a', 'b'], ordered=False, dtype='category', name='B')
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.DataFrame.set_index pandas.CategoricalIndex
"In [154]: df2.loc[""a""].index
Out[154]: CategoricalIndex(['a', 'a', 'a'], categories=['c', 'a', 'b'], ordered=False, dtype='category', name='B')
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.CategoricalIndex
"In [155]: df2.sort_index()
Out[155]: 
   A
B   
c  4
a  0
a  1
a  5
b  2
b  3
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.DataFrame.sort_index
"In [156]: df2.groupby(level=0, observed=True).sum()
Out[156]: 
   A
B   
c  4
a  6
b  5

In [157]: df2.groupby(level=0, observed=True).sum().index
Out[157]: CategoricalIndex(['c', 'a', 'b'], categories=['c', 'a', 'b'], ordered=False, dtype='category', name='B')
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.DataFrame.groupby pandas.CategoricalIndex
"In [158]: df3 = pd.DataFrame(
   .....:     {""A"": np.arange(3), ""B"": pd.Series(list(""abc"")).astype(""category"")}
   .....: )
   .....: 

In [159]: df3 = df3.set_index(""B"")

In [160]: df3
Out[160]: 
   A
B   
a  0
b  1
c  2
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.DataFrame pandas.Series pandas.DataFrame.set_index
"In [161]: df3.reindex([""a"", ""e""])
Out[161]: 
     A
B     
a  0.0
e  NaN

In [162]: df3.reindex([""a"", ""e""]).index
Out[162]: Index(['a', 'e'], dtype='object', name='B')

In [163]: df3.reindex(pd.Categorical([""a"", ""e""], categories=list(""abe"")))
Out[163]: 
     A
B     
a  0.0
e  NaN

In [164]: df3.reindex(pd.Categorical([""a"", ""e""], categories=list(""abe""))).index
Out[164]: CategoricalIndex(['a', 'e'], categories=['a', 'b', 'e'], ordered=False, dtype='category', name='B')
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.DataFrame.reindex pandas.Index pandas.Categorical pandas.CategoricalIndex
"In [165]: df4 = pd.DataFrame({""A"": np.arange(2), ""B"": list(""ba"")})

In [166]: df4[""B""] = df4[""B""].astype(CategoricalDtype(list(""ab"")))

In [167]: df4 = df4.set_index(""B"")

In [168]: df4.index
Out[168]: CategoricalIndex(['b', 'a'], categories=['a', 'b'], ordered=False, dtype='category', name='B')

In [169]: df5 = pd.DataFrame({""A"": np.arange(2), ""B"": list(""bc"")})

In [170]: df5[""B""] = df5[""B""].astype(CategoricalDtype(list(""bc"")))

In [171]: df5 = df5.set_index(""B"")

In [172]: df5.index
Out[172]: CategoricalIndex(['b', 'c'], categories=['b', 'c'], ordered=False, dtype='category', name='B')
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.DataFrame pandas.CategoricalDtype pandas.DataFrame.set_index pandas.CategoricalIndex pandas.DataFrame.set_index
"In [173]: pd.concat([df4, df5])
Out[173]: 
   A
B   
b  0
a  1
b  0
c  1
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.concat
"In [174]: idx = pd.RangeIndex(5)

In [175]: idx
Out[175]: RangeIndex(start=0, stop=5, step=1)
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.RangeIndex pandas.RangeIndex
"In [176]: ser = pd.Series([1, 2, 3])

In [177]: ser.index
Out[177]: RangeIndex(start=0, stop=3, step=1)

In [178]: df = pd.DataFrame([[1, 2], [3, 4]])

In [179]: df.index
Out[179]: RangeIndex(start=0, stop=2, step=1)

In [180]: df.columns
Out[180]: RangeIndex(start=0, stop=2, step=1)
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.Series pandas.RangeIndex pandas.DataFrame
"In [181]: idx[[0, 2]]
Out[181]: Index([0, 2], dtype='int64')
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.Index
"In [182]: df = pd.DataFrame(
   .....:     {""A"": [1, 2, 3, 4]}, index=pd.IntervalIndex.from_breaks([0, 1, 2, 3, 4])
   .....: )
   .....: 

In [183]: df
Out[183]: 
        A
(0, 1]  1
(1, 2]  2
(2, 3]  3
(3, 4]  4
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.DataFrame pandas.IntervalIndex.from_breaks
"In [188]: df.loc[pd.Interval(1, 2)]
Out[188]: 
A    2
Name: (1, 2], dtype: int64
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.Interval
"In [189]: df.loc[pd.Interval(0.5, 2.5)]
---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
Cell In[189], line 1
----> 1 df.loc[pd.Interval(0.5, 2.5)]

File ~/work/pandas/pandas/pandas/core/indexing.py:1191, in _LocationIndexer.__getitem__(self, key)
   1189 maybe_callable = com.apply_if_callable(key, self.obj)
   1190 maybe_callable = self._check_deprecated_callable_usage(key, maybe_callable)
-> 1191 return self._getitem_axis(maybe_callable, axis=axis)

File ~/work/pandas/pandas/pandas/core/indexing.py:1431, in _LocIndexer._getitem_axis(self, key, axis)
   1429 # fall thru to straight lookup
   1430 self._validate_key(key, axis)
-> 1431 return self._get_label(key, axis=axis)

File ~/work/pandas/pandas/pandas/core/indexing.py:1381, in _LocIndexer._get_label(self, label, axis)
   1379 def _get_label(self, label, axis: AxisInt):
   1380     # GH#5567 this will fail if the label is not present in the axis.
-> 1381     return self.obj.xs(label, axis=axis)

File ~/work/pandas/pandas/pandas/core/generic.py:4301, in NDFrame.xs(self, key, axis, level, drop_level)
   4299             new_index = index[loc]
   4300 else:
-> 4301     loc = index.get_loc(key)
   4303     if isinstance(loc, np.ndarray):
   4304         if loc.dtype == np.bool_:

File ~/work/pandas/pandas/pandas/core/indexes/interval.py:678, in IntervalIndex.get_loc(self, key)
    676 matches = mask.sum()
    677 if matches == 0:
--> 678     raise KeyError(key)
    679 if matches == 1:
    680     return mask.argmax()

KeyError: Interval(0.5, 2.5, closed='right')
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.Interval pandas.Index.get_loc pandas.IntervalIndex.get_loc pandas.Interval
"In [190]: idxr = df.index.overlaps(pd.Interval(0.5, 2.5))

In [191]: idxr
Out[191]: array([ True,  True,  True, False])

In [192]: df[idxr]
Out[192]: 
        A
(0, 1]  1
(1, 2]  2
(2, 3]  3
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.Interval pandas.array
"In [193]: c = pd.cut(range(4), bins=2)

In [194]: c
Out[194]: 
[(-0.003, 1.5], (-0.003, 1.5], (1.5, 3.0], (1.5, 3.0]]
Categories (2, interval[float64, right]): [(-0.003, 1.5] < (1.5, 3.0]]

In [195]: c.categories
Out[195]: IntervalIndex([(-0.003, 1.5], (1.5, 3.0]], dtype='interval[float64, right]')
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.cut pandas.IntervalIndex
"In [196]: pd.cut([0, 3, 5, 1], bins=c.categories)
Out[196]: 
[(-0.003, 1.5], (1.5, 3.0], NaN, (-0.003, 1.5]]
Categories (2, interval[float64, right]): [(-0.003, 1.5] < (1.5, 3.0]]
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.cut
"In [197]: pd.interval_range(start=0, end=5)
Out[197]: IntervalIndex([(0, 1], (1, 2], (2, 3], (3, 4], (4, 5]], dtype='interval[int64, right]')

In [198]: pd.interval_range(start=pd.Timestamp(""2017-01-01""), periods=4)
Out[198]: 
IntervalIndex([(2017-01-01 00:00:00, 2017-01-02 00:00:00],
               (2017-01-02 00:00:00, 2017-01-03 00:00:00],
               (2017-01-03 00:00:00, 2017-01-04 00:00:00],
               (2017-01-04 00:00:00, 2017-01-05 00:00:00]],
              dtype='interval[datetime64[ns], right]')

In [199]: pd.interval_range(end=pd.Timedelta(""3 days""), periods=3)
Out[199]: 
IntervalIndex([(0 days 00:00:00, 1 days 00:00:00],
               (1 days 00:00:00, 2 days 00:00:00],
               (2 days 00:00:00, 3 days 00:00:00]],
              dtype='interval[timedelta64[ns], right]')
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.interval_range pandas.IntervalIndex
"In [200]: pd.interval_range(start=0, periods=5, freq=1.5)
Out[200]: IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0], (6.0, 7.5]], dtype='interval[float64, right]')

In [201]: pd.interval_range(start=pd.Timestamp(""2017-01-01""), periods=4, freq=""W"")
Out[201]: 
IntervalIndex([(2017-01-01 00:00:00, 2017-01-08 00:00:00],
               (2017-01-08 00:00:00, 2017-01-15 00:00:00],
               (2017-01-15 00:00:00, 2017-01-22 00:00:00],
               (2017-01-22 00:00:00, 2017-01-29 00:00:00]],
              dtype='interval[datetime64[ns], right]')

In [202]: pd.interval_range(start=pd.Timedelta(""0 days""), periods=3, freq=""9h"")
Out[202]: 
IntervalIndex([(0 days 00:00:00, 0 days 09:00:00],
               (0 days 09:00:00, 0 days 18:00:00],
               (0 days 18:00:00, 1 days 03:00:00]],
              dtype='interval[timedelta64[ns], right]')
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.interval_range pandas.IntervalIndex
"In [203]: pd.interval_range(start=0, end=4, closed=""both"")
Out[203]: IntervalIndex([[0, 1], [1, 2], [2, 3], [3, 4]], dtype='interval[int64, both]')

In [204]: pd.interval_range(start=0, end=4, closed=""neither"")
Out[204]: IntervalIndex([(0, 1), (1, 2), (2, 3), (3, 4)], dtype='interval[int64, neither]')
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.interval_range pandas.IntervalIndex
"In [205]: pd.interval_range(start=0, end=6, periods=4)
Out[205]: IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]], dtype='interval[float64, right]')

In [206]: pd.interval_range(pd.Timestamp(""2018-01-01""), pd.Timestamp(""2018-02-28""), periods=3)
Out[206]: 
IntervalIndex([(2018-01-01 00:00:00, 2018-01-20 08:00:00],
               (2018-01-20 08:00:00, 2018-02-08 16:00:00],
               (2018-02-08 16:00:00, 2018-02-28 00:00:00]],
              dtype='interval[datetime64[ns], right]')
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.interval_range pandas.IntervalIndex
"In [207]: s = pd.Series(range(5))

In [208]: s[-1]
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
File ~/work/pandas/pandas/pandas/core/indexes/range.py:413, in RangeIndex.get_loc(self, key)
    412 try:
--> 413     return self._range.index(new_key)
    414 except ValueError as err:

ValueError: -1 is not in range

The above exception was the direct cause of the following exception:

KeyError                                  Traceback (most recent call last)
Cell In[208], line 1
----> 1 s[-1]

File ~/work/pandas/pandas/pandas/core/series.py:1121, in Series.__getitem__(self, key)
   1118     return self._values[key]
   1120 elif key_is_scalar:
-> 1121     return self._get_value(key)
   1123 # Convert generator to list before going through hashable part
   1124 # (We will iterate through the generator there to check for slices)
   1125 if is_iterator(key):

File ~/work/pandas/pandas/pandas/core/series.py:1237, in Series._get_value(self, label, takeable)
   1234     return self._values[label]
   1236 # Similar to Index.get_value, but we do not fall back to positional
-> 1237 loc = self.index.get_loc(label)
   1239 if is_integer(loc):
   1240     return self._values[loc]

File ~/work/pandas/pandas/pandas/core/indexes/range.py:415, in RangeIndex.get_loc(self, key)
    413         return self._range.index(new_key)
    414     except ValueError as err:
--> 415         raise KeyError(key) from err
    416 if isinstance(key, Hashable):
    417     raise KeyError(key)

KeyError: -1

In [209]: df = pd.DataFrame(np.random.randn(5, 4))

In [210]: df
Out[210]: 
          0         1         2         3
0 -0.435772 -1.188928 -0.808286 -0.284634
1 -1.815703  1.347213 -0.243487  0.514704
2  1.162969 -0.287725 -0.179734  0.993962
3 -0.212673  0.909872 -0.733333 -0.349893
4  0.456434 -0.306735  0.553396  0.166221

In [211]: df.loc[-2:]
Out[211]: 
          0         1         2         3
0 -0.435772 -1.188928 -0.808286 -0.284634
1 -1.815703  1.347213 -0.243487  0.514704
2  1.162969 -0.287725 -0.179734  0.993962
3 -0.212673  0.909872 -0.733333 -0.349893
4  0.456434 -0.306735  0.553396  0.166221
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.Series pandas.api.types.is_iterator pandas.api.types.is_integer pandas.DataFrame
"In [212]: df = pd.DataFrame(index=[2, 3, 3, 4, 5], columns=[""data""], data=list(range(5)))

In [213]: df.index.is_monotonic_increasing
Out[213]: True

# no rows 0 or 1, but still returns rows 2, 3 (both of them), and 4:
In [214]: df.loc[0:4, :]
Out[214]: 
   data
2     0
3     1
3     2
4     3

# slice is are outside the index, so empty DataFrame is returned
In [215]: df.loc[13:15, :]
Out[215]: 
Empty DataFrame
Columns: [data]
Index: []
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.DataFrame
"In [216]: df = pd.DataFrame(index=[2, 3, 1, 4, 3, 5], columns=[""data""], data=list(range(6)))

In [217]: df.index.is_monotonic_increasing
Out[217]: False

# OK because 2 and 4 are in the index
In [218]: df.loc[2:4, :]
Out[218]: 
   data
2     0
3     1
1     2
4     3
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.DataFrame
" # 0 is not in the index
In [219]: df.loc[0:4, :]
---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
File ~/work/pandas/pandas/pandas/core/indexes/base.py:3805, in Index.get_loc(self, key)
   3804 try:
-> 3805     return self._engine.get_loc(casted_key)
   3806 except KeyError as err:

File index.pyx:167, in pandas._libs.index.IndexEngine.get_loc()

File index.pyx:191, in pandas._libs.index.IndexEngine.get_loc()

File index.pyx:234, in pandas._libs.index.IndexEngine._get_loc_duplicates()

File index.pyx:242, in pandas._libs.index.IndexEngine._maybe_get_bool_indexer()

File index.pyx:134, in pandas._libs.index._unpack_bool_indexer()

KeyError: 0

The above exception was the direct cause of the following exception:

KeyError                                  Traceback (most recent call last)
Cell In[219], line 1
----> 1 df.loc[0:4, :]

File ~/work/pandas/pandas/pandas/core/indexing.py:1184, in _LocationIndexer.__getitem__(self, key)
   1182     if self._is_scalar_access(key):
   1183         return self.obj._get_value(*key, takeable=self._takeable)
-> 1184     return self._getitem_tuple(key)
   1185 else:
   1186     # we by definition only have the 0th axis
   1187     axis = self.axis or 0

File ~/work/pandas/pandas/pandas/core/indexing.py:1377, in _LocIndexer._getitem_tuple(self, tup)
   1374 if self._multi_take_opportunity(tup):
   1375     return self._multi_take(tup)
-> 1377 return self._getitem_tuple_same_dim(tup)

File ~/work/pandas/pandas/pandas/core/indexing.py:1020, in _LocationIndexer._getitem_tuple_same_dim(self, tup)
   1017 if com.is_null_slice(key):
   1018     continue
-> 1020 retval = getattr(retval, self.name)._getitem_axis(key, axis=i)
   1021 # We should never have retval.ndim < self.ndim, as that should
   1022 #  be handled by the _getitem_lowerdim call above.
   1023 assert retval.ndim == self.ndim

File ~/work/pandas/pandas/pandas/core/indexing.py:1411, in _LocIndexer._getitem_axis(self, key, axis)
   1409 if isinstance(key, slice):
   1410     self._validate_key(key, axis)
-> 1411     return self._get_slice_axis(key, axis=axis)
   1412 elif com.is_bool_indexer(key):
   1413     return self._getbool_axis(key, axis=axis)

File ~/work/pandas/pandas/pandas/core/indexing.py:1443, in _LocIndexer._get_slice_axis(self, slice_obj, axis)
   1440     return obj.copy(deep=False)
   1442 labels = obj._get_axis(axis)
-> 1443 indexer = labels.slice_indexer(slice_obj.start, slice_obj.stop, slice_obj.step)
   1445 if isinstance(indexer, slice):
   1446     return self.obj._slice(indexer, axis=axis)

File ~/work/pandas/pandas/pandas/core/indexes/base.py:6662, in Index.slice_indexer(self, start, end, step)
   6618 def slice_indexer(
   6619     self,
   6620     start: Hashable | None = None,
   6621     end: Hashable | None = None,
   6622     step: int | None = None,
   6623 ) -> slice:
   6624     """"""
   6625     Compute the slice indexer for input labels and step.
   6626 
   (...)
   6660     slice(1, 3, None)
   6661     """"""
-> 6662     start_slice, end_slice = self.slice_locs(start, end, step=step)
   6664     # return a slice
   6665     if not is_scalar(start_slice):

File ~/work/pandas/pandas/pandas/core/indexes/base.py:6879, in Index.slice_locs(self, start, end, step)
   6877 start_slice = None
   6878 if start is not None:
-> 6879     start_slice = self.get_slice_bound(start, ""left"")
   6880 if start_slice is None:
   6881     start_slice = 0

File ~/work/pandas/pandas/pandas/core/indexes/base.py:6804, in Index.get_slice_bound(self, label, side)
   6801         return self._searchsorted_monotonic(label, side)
   6802     except ValueError:
   6803         # raise the original KeyError
-> 6804         raise err
   6806 if isinstance(slc, np.ndarray):
   6807     # get_loc may return a boolean array, which
   6808     # is OK as long as they are representable by a slice.
   6809     assert is_bool_dtype(slc.dtype)

File ~/work/pandas/pandas/pandas/core/indexes/base.py:6798, in Index.get_slice_bound(self, label, side)
   6796 # we need to look up the label
   6797 try:
-> 6798     slc = self.get_loc(label)
   6799 except KeyError as err:
   6800     try:

File ~/work/pandas/pandas/pandas/core/indexes/base.py:3812, in Index.get_loc(self, key)
   3807     if isinstance(casted_key, slice) or (
   3808         isinstance(casted_key, abc.Iterable)
   3809         and any(isinstance(x, slice) for x in casted_key)
   3810     ):
   3811         raise InvalidIndexError(key)
-> 3812     raise KeyError(key) from err
   3813 except TypeError:
   3814     # If we have a listlike key, _check_indexing_error will raise
   3815     #  InvalidIndexError. Otherwise we fall through and re-raise
   3816     #  the TypeError.
   3817     self._check_indexing_error(key)

KeyError: 0

 # 3 is not a unique label
In [220]: df.loc[2:3, :]
---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
Cell In[220], line 1
----> 1 df.loc[2:3, :]

File ~/work/pandas/pandas/pandas/core/indexing.py:1184, in _LocationIndexer.__getitem__(self, key)
   1182     if self._is_scalar_access(key):
   1183         return self.obj._get_value(*key, takeable=self._takeable)
-> 1184     return self._getitem_tuple(key)
   1185 else:
   1186     # we by definition only have the 0th axis
   1187     axis = self.axis or 0

File ~/work/pandas/pandas/pandas/core/indexing.py:1377, in _LocIndexer._getitem_tuple(self, tup)
   1374 if self._multi_take_opportunity(tup):
   1375     return self._multi_take(tup)
-> 1377 return self._getitem_tuple_same_dim(tup)

File ~/work/pandas/pandas/pandas/core/indexing.py:1020, in _LocationIndexer._getitem_tuple_same_dim(self, tup)
   1017 if com.is_null_slice(key):
   1018     continue
-> 1020 retval = getattr(retval, self.name)._getitem_axis(key, axis=i)
   1021 # We should never have retval.ndim < self.ndim, as that should
   1022 #  be handled by the _getitem_lowerdim call above.
   1023 assert retval.ndim == self.ndim

File ~/work/pandas/pandas/pandas/core/indexing.py:1411, in _LocIndexer._getitem_axis(self, key, axis)
   1409 if isinstance(key, slice):
   1410     self._validate_key(key, axis)
-> 1411     return self._get_slice_axis(key, axis=axis)
   1412 elif com.is_bool_indexer(key):
   1413     return self._getbool_axis(key, axis=axis)

File ~/work/pandas/pandas/pandas/core/indexing.py:1443, in _LocIndexer._get_slice_axis(self, slice_obj, axis)
   1440     return obj.copy(deep=False)
   1442 labels = obj._get_axis(axis)
-> 1443 indexer = labels.slice_indexer(slice_obj.start, slice_obj.stop, slice_obj.step)
   1445 if isinstance(indexer, slice):
   1446     return self.obj._slice(indexer, axis=axis)

File ~/work/pandas/pandas/pandas/core/indexes/base.py:6662, in Index.slice_indexer(self, start, end, step)
   6618 def slice_indexer(
   6619     self,
   6620     start: Hashable | None = None,
   6621     end: Hashable | None = None,
   6622     step: int | None = None,
   6623 ) -> slice:
   6624     """"""
   6625     Compute the slice indexer for input labels and step.
   6626 
   (...)
   6660     slice(1, 3, None)
   6661     """"""
-> 6662     start_slice, end_slice = self.slice_locs(start, end, step=step)
   6664     # return a slice
   6665     if not is_scalar(start_slice):

File ~/work/pandas/pandas/pandas/core/indexes/base.py:6885, in Index.slice_locs(self, start, end, step)
   6883 end_slice = None
   6884 if end is not None:
-> 6885     end_slice = self.get_slice_bound(end, ""right"")
   6886 if end_slice is None:
   6887     end_slice = len(self)

File ~/work/pandas/pandas/pandas/core/indexes/base.py:6812, in Index.get_slice_bound(self, label, side)
   6810     slc = lib.maybe_booleans_to_slice(slc.view(""u1""))
   6811     if isinstance(slc, np.ndarray):
-> 6812         raise KeyError(
   6813             f""Cannot get {side} slice bound for non-unique ""
   6814             f""label: {repr(original_label)}""
   6815         )
   6817 if isinstance(slc, slice):
   6818     if side == ""left"":

KeyError: 'Cannot get right slice bound for non-unique label: 3'
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.Index.get_loc pandas.Index.slice_indexer pandas.Index.slice_indexer pandas.Index.slice_indexer pandas.Series.str.slice pandas.Index.slice_locs pandas.api.types.is_scalar pandas.Index.slice_locs pandas.Index.get_slice_bound pandas.Index.get_slice_bound pandas.api.types.is_bool_dtype pandas.errors.InvalidIndexError
"In [221]: weakly_monotonic = pd.Index([""a"", ""b"", ""c"", ""c""])

In [222]: weakly_monotonic
Out[222]: Index(['a', 'b', 'c', 'c'], dtype='object')

In [223]: weakly_monotonic.is_monotonic_increasing
Out[223]: True

In [224]: weakly_monotonic.is_monotonic_increasing & weakly_monotonic.is_unique
Out[224]: False
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.Index pandas.Index
"In [225]: s = pd.Series(np.random.randn(6), index=list(""abcdef""))

In [226]: s
Out[226]: 
a   -0.101684
b   -0.734907
c   -0.130121
d   -0.476046
e    0.759104
f    0.213379
dtype: float64
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.Series
"In [230]: series1 = pd.Series([1, 2, 3])

In [231]: series1.dtype
Out[231]: dtype('int64')

In [232]: res = series1.reindex([0, 4])

In [233]: res.dtype
Out[233]: dtype('float64')

In [234]: res
Out[234]: 
0    1.0
4    NaN
dtype: float64
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.Series pandas.Series.reindex
"In [235]: series2 = pd.Series([True])

In [236]: series2.dtype
Out[236]: dtype('bool')

In [237]: res = series2.reindex_like(series1)

In [238]: res.dtype
Out[238]: dtype('O')

In [239]: res
Out[239]: 
0    True
1     NaN
2     NaN
dtype: object
",https://pandas.pydata.org/docs/user_guide/advanced.html, pandas.Series pandas.Series.reindex_like
">>> import matplotlib.pyplot as plt
>>> df = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})
>>> fix, ax = plt.subplots()
>>> ax.axis('off')
(0.0, 1.0, 0.0, 1.0)
>>> table = pd.plotting.table(ax, df, loc='center',
...                           cellLoc='center', colWidths=list([.2, .2]))
",https://pandas.pydata.org/docs/reference/api/pandas.plotting.table.html, pandas.DataFrame pandas.plotting.table
"In [1]: df = pd.DataFrame(
   ...:     {""AAA"": [4, 5, 6, 7], ""BBB"": [10, 20, 30, 40], ""CCC"": [100, 50, -30, -50]}
   ...: )
   ...: 

In [2]: df
Out[2]: 
   AAA  BBB  CCC
0    4   10  100
1    5   20   50
2    6   30  -30
3    7   40  -50
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.DataFrame
"In [9]: df_mask = pd.DataFrame(
   ...:     {""AAA"": [True] * 4, ""BBB"": [False] * 4, ""CCC"": [True, False] * 2}
   ...: )
   ...: 

In [10]: df.where(df_mask, -1000)
Out[10]: 
   AAA   BBB   CCC
0    4 -1000  2000
1    5 -1000 -1000
2    6 -1000   555
3    7 -1000 -1000
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.DataFrame pandas.DataFrame.where
"In [11]: df = pd.DataFrame(
   ....:     {""AAA"": [4, 5, 6, 7], ""BBB"": [10, 20, 30, 40], ""CCC"": [100, 50, -30, -50]}
   ....: )
   ....: 

In [12]: df
Out[12]: 
   AAA  BBB  CCC
0    4   10  100
1    5   20   50
2    6   30  -30
3    7   40  -50

In [13]: df[""logic""] = np.where(df[""AAA""] > 5, ""high"", ""low"")

In [14]: df
Out[14]: 
   AAA  BBB  CCC logic
0    4   10  100   low
1    5   20   50   low
2    6   30  -30  high
3    7   40  -50  high
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.DataFrame
"In [15]: df = pd.DataFrame(
   ....:     {""AAA"": [4, 5, 6, 7], ""BBB"": [10, 20, 30, 40], ""CCC"": [100, 50, -30, -50]}
   ....: )
   ....: 

In [16]: df
Out[16]: 
   AAA  BBB  CCC
0    4   10  100
1    5   20   50
2    6   30  -30
3    7   40  -50

In [17]: df[df.AAA <= 5]
Out[17]: 
   AAA  BBB  CCC
0    4   10  100
1    5   20   50

In [18]: df[df.AAA > 5]
Out[18]: 
   AAA  BBB  CCC
2    6   30  -30
3    7   40  -50
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.DataFrame
"In [19]: df = pd.DataFrame(
   ....:     {""AAA"": [4, 5, 6, 7], ""BBB"": [10, 20, 30, 40], ""CCC"": [100, 50, -30, -50]}
   ....: )
   ....: 

In [20]: df
Out[20]: 
   AAA  BBB  CCC
0    4   10  100
1    5   20   50
2    6   30  -30
3    7   40  -50
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.DataFrame
"In [25]: df = pd.DataFrame(
   ....:     {""AAA"": [4, 5, 6, 7], ""BBB"": [10, 20, 30, 40], ""CCC"": [100, 50, -30, -50]}
   ....: )
   ....: 

In [26]: df
Out[26]: 
   AAA  BBB  CCC
0    4   10  100
1    5   20   50
2    6   30  -30
3    7   40  -50

In [27]: aValue = 43.0

In [28]: df.loc[(df.CCC - aValue).abs().argsort()]
Out[28]: 
   AAA  BBB  CCC
1    5   20   50
0    4   10  100
2    6   30  -30
3    7   40  -50
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.DataFrame
"In [29]: df = pd.DataFrame(
   ....:     {""AAA"": [4, 5, 6, 7], ""BBB"": [10, 20, 30, 40], ""CCC"": [100, 50, -30, -50]}
   ....: )
   ....: 

In [30]: df
Out[30]: 
   AAA  BBB  CCC
0    4   10  100
1    5   20   50
2    6   30  -30
3    7   40  -50

In [31]: Crit1 = df.AAA <= 5.5

In [32]: Crit2 = df.BBB == 10.0

In [33]: Crit3 = df.CCC > -40.0
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.DataFrame
"In [39]: df = pd.DataFrame(
   ....:     {""AAA"": [4, 5, 6, 7], ""BBB"": [10, 20, 30, 40], ""CCC"": [100, 50, -30, -50]}
   ....: )
   ....: 

In [40]: df
Out[40]: 
   AAA  BBB  CCC
0    4   10  100
1    5   20   50
2    6   30  -30
3    7   40  -50

In [41]: df[(df.AAA <= 6) & (df.index.isin([0, 2, 4]))]
Out[41]: 
   AAA  BBB  CCC
0    4   10  100
2    6   30  -30
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.DataFrame
"In [42]: df = pd.DataFrame(
   ....:     {""AAA"": [4, 5, 6, 7], ""BBB"": [10, 20, 30, 40], ""CCC"": [100, 50, -30, -50]},
   ....:     index=[""foo"", ""bar"", ""boo"", ""kar""],
   ....: )
   ....: 
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.DataFrame
"In [46]: data = {""AAA"": [4, 5, 6, 7], ""BBB"": [10, 20, 30, 40], ""CCC"": [100, 50, -30, -50]}

In [47]: df2 = pd.DataFrame(data=data, index=[1, 2, 3, 4])  # Note index starts at 1.

In [48]: df2.iloc[1:3]  # Position-oriented
Out[48]: 
   AAA  BBB  CCC
2    5   20   50
3    6   30  -30

In [49]: df2.loc[1:3]  # Label-oriented
Out[49]: 
   AAA  BBB  CCC
1    4   10  100
2    5   20   50
3    6   30  -30
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.DataFrame
"In [50]: df = pd.DataFrame(
   ....:     {""AAA"": [4, 5, 6, 7], ""BBB"": [10, 20, 30, 40], ""CCC"": [100, 50, -30, -50]}
   ....: )
   ....: 

In [51]: df
Out[51]: 
   AAA  BBB  CCC
0    4   10  100
1    5   20   50
2    6   30  -30
3    7   40  -50

In [52]: df[~((df.AAA <= 6) & (df.index.isin([0, 2, 4])))]
Out[52]: 
   AAA  BBB  CCC
1    5   20   50
3    7   40  -50
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.DataFrame
"In [53]: df = pd.DataFrame({""AAA"": [1, 2, 1, 3], ""BBB"": [1, 1, 2, 2], ""CCC"": [2, 1, 3, 1]})

In [54]: df
Out[54]: 
   AAA  BBB  CCC
0    1    1    2
1    2    1    1
2    1    2    3
3    3    2    1

In [55]: source_cols = df.columns  # Or some subset would work too

In [56]: new_cols = [str(x) + ""_cat"" for x in source_cols]

In [57]: categories = {1: ""Alpha"", 2: ""Beta"", 3: ""Charlie""}

In [58]: df[new_cols] = df[source_cols].map(categories.get)

In [59]: df
Out[59]: 
   AAA  BBB  CCC  AAA_cat BBB_cat  CCC_cat
0    1    1    2    Alpha   Alpha     Beta
1    2    1    1     Beta   Alpha    Alpha
2    1    2    3    Alpha    Beta  Charlie
3    3    2    1  Charlie    Beta    Alpha
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.DataFrame
"In [60]: df = pd.DataFrame(
   ....:     {""AAA"": [1, 1, 1, 2, 2, 2, 3, 3], ""BBB"": [2, 1, 3, 4, 5, 1, 2, 3]}
   ....: )
   ....: 

In [61]: df
Out[61]: 
   AAA  BBB
0    1    2
1    1    1
2    1    3
3    2    4
4    2    5
5    2    1
6    3    2
7    3    3
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.DataFrame
"In [62]: df.loc[df.groupby(""AAA"")[""BBB""].idxmin()]
Out[62]: 
   AAA  BBB
1    1    1
5    2    1
6    3    2
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.DataFrame.groupby
"In [63]: df.sort_values(by=""BBB"").groupby(""AAA"", as_index=False).first()
Out[63]: 
   AAA  BBB
0    1    1
1    2    1
2    3    2
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.DataFrame.sort_values
"In [64]: df = pd.DataFrame(
   ....:     {
   ....:         ""row"": [0, 1, 2],
   ....:         ""One_X"": [1.1, 1.1, 1.1],
   ....:         ""One_Y"": [1.2, 1.2, 1.2],
   ....:         ""Two_X"": [1.11, 1.11, 1.11],
   ....:         ""Two_Y"": [1.22, 1.22, 1.22],
   ....:     }
   ....: )
   ....: 

In [65]: df
Out[65]: 
   row  One_X  One_Y  Two_X  Two_Y
0    0    1.1    1.2   1.11   1.22
1    1    1.1    1.2   1.11   1.22
2    2    1.1    1.2   1.11   1.22

# As Labelled Index
In [66]: df = df.set_index(""row"")

In [67]: df
Out[67]: 
     One_X  One_Y  Two_X  Two_Y
row                            
0      1.1    1.2   1.11   1.22
1      1.1    1.2   1.11   1.22
2      1.1    1.2   1.11   1.22

# With Hierarchical Columns
In [68]: df.columns = pd.MultiIndex.from_tuples([tuple(c.split(""_"")) for c in df.columns])

In [69]: df
Out[69]: 
     One        Two      
       X    Y     X     Y
row                      
0    1.1  1.2  1.11  1.22
1    1.1  1.2  1.11  1.22
2    1.1  1.2  1.11  1.22

# Now stack & Reset
In [70]: df = df.stack(0, future_stack=True).reset_index(1)

In [71]: df
Out[71]: 
    level_1     X     Y
row                    
0       One  1.10  1.20
0       Two  1.11  1.22
1       One  1.10  1.20
1       Two  1.11  1.22
2       One  1.10  1.20
2       Two  1.11  1.22

# And fix the labels (Notice the label 'level_1' got added automatically)
In [72]: df.columns = [""Sample"", ""All_X"", ""All_Y""]

In [73]: df
Out[73]: 
    Sample  All_X  All_Y
row                     
0      One   1.10   1.20
0      Two   1.11   1.22
1      One   1.10   1.20
1      Two   1.11   1.22
2      One   1.10   1.20
2      Two   1.11   1.22
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.DataFrame pandas.DataFrame.set_index pandas.MultiIndex.from_tuples pandas.Series.str.split pandas.DataFrame.stack
"In [74]: cols = pd.MultiIndex.from_tuples(
   ....:     [(x, y) for x in [""A"", ""B"", ""C""] for y in [""O"", ""I""]]
   ....: )
   ....: 

In [75]: df = pd.DataFrame(np.random.randn(2, 6), index=[""n"", ""m""], columns=cols)

In [76]: df
Out[76]: 
          A                   B                   C          
          O         I         O         I         O         I
n  0.469112 -0.282863 -1.509059 -1.135632  1.212112 -0.173215
m  0.119209 -1.044236 -0.861849 -2.104569 -0.494929  1.071804

In [77]: df = df.div(df[""C""], level=1)

In [78]: df
Out[78]: 
          A                   B              C     
          O         I         O         I    O    I
n  0.387021  1.633022 -1.244983  6.556214  1.0  1.0
m -0.240860 -0.974279  1.741358 -1.963577  1.0  1.0
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.MultiIndex.from_tuples pandas.DataFrame pandas.DataFrame.div
"In [79]: coords = [(""AA"", ""one""), (""AA"", ""six""), (""BB"", ""one""), (""BB"", ""two""), (""BB"", ""six"")]

In [80]: index = pd.MultiIndex.from_tuples(coords)

In [81]: df = pd.DataFrame([11, 22, 33, 44, 55], index, [""MyData""])

In [82]: df
Out[82]: 
        MyData
AA one      11
   six      22
BB one      33
   two      44
   six      55
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.MultiIndex.from_tuples pandas.DataFrame
"# Note : level and axis are optional, and default to zero
In [83]: df.xs(""BB"", level=0, axis=0)
Out[83]: 
     MyData
one      33
two      44
six      55
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.DataFrame.xs
"In [84]: df.xs(""six"", level=1, axis=0)
Out[84]: 
    MyData
AA      22
BB      55
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.DataFrame.xs
"In [85]: import itertools

In [86]: index = list(itertools.product([""Ada"", ""Quinn"", ""Violet""], [""Comp"", ""Math"", ""Sci""]))

In [87]: headr = list(itertools.product([""Exams"", ""Labs""], [""I"", ""II""]))

In [88]: indx = pd.MultiIndex.from_tuples(index, names=[""Student"", ""Course""])

In [89]: cols = pd.MultiIndex.from_tuples(headr)  # Notice these are un-named

In [90]: data = [[70 + x + y + (x * y) % 3 for x in range(4)] for y in range(9)]

In [91]: df = pd.DataFrame(data, indx, cols)

In [92]: df
Out[92]: 
               Exams     Labs    
                   I  II    I  II
Student Course                   
Ada     Comp      70  71   72  73
        Math      71  73   75  74
        Sci       72  75   75  75
Quinn   Comp      73  74   75  76
        Math      74  76   78  77
        Sci       75  78   78  78
Violet  Comp      76  77   78  79
        Math      77  79   81  80
        Sci       78  81   81  81

In [93]: All = slice(None)

In [94]: df.loc[""Violet""]
Out[94]: 
       Exams     Labs    
           I  II    I  II
Course                   
Comp      76  77   78  79
Math      77  79   81  80
Sci       78  81   81  81

In [95]: df.loc[(All, ""Math""), All]
Out[95]: 
               Exams     Labs    
                   I  II    I  II
Student Course                   
Ada     Math      71  73   75  74
Quinn   Math      74  76   78  77
Violet  Math      77  79   81  80

In [96]: df.loc[(slice(""Ada"", ""Quinn""), ""Math""), All]
Out[96]: 
               Exams     Labs    
                   I  II    I  II
Student Course                   
Ada     Math      71  73   75  74
Quinn   Math      74  76   78  77

In [97]: df.loc[(All, ""Math""), (""Exams"")]
Out[97]: 
                 I  II
Student Course        
Ada     Math    71  73
Quinn   Math    74  76
Violet  Math    77  79

In [98]: df.loc[(All, ""Math""), (All, ""II"")]
Out[98]: 
               Exams Labs
                  II   II
Student Course           
Ada     Math      73   74
Quinn   Math      76   77
Violet  Math      79   80
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.MultiIndex.from_tuples pandas.DataFrame pandas.Series.str.slice
"In [99]: df.sort_values(by=(""Labs"", ""II""), ascending=False)
Out[99]: 
               Exams     Labs    
                   I  II    I  II
Student Course                   
Violet  Sci       78  81   81  81
        Math      77  79   81  80
        Comp      76  77   78  79
Quinn   Sci       75  78   78  78
        Math      74  76   78  77
        Comp      73  74   75  76
Ada     Sci       72  75   75  75
        Math      71  73   75  74
        Comp      70  71   72  73
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.DataFrame.sort_values
"In [100]: df = pd.DataFrame(
   .....:     np.random.randn(6, 1),
   .....:     index=pd.date_range(""2013-08-01"", periods=6, freq=""B""),
   .....:     columns=list(""A""),
   .....: )
   .....: 

In [101]: df.loc[df.index[3], ""A""] = np.nan

In [102]: df
Out[102]: 
                   A
2013-08-01  0.721555
2013-08-02 -0.706771
2013-08-05 -1.039575
2013-08-06       NaN
2013-08-07 -0.424972
2013-08-08  0.567020

In [103]: df.bfill()
Out[103]: 
                   A
2013-08-01  0.721555
2013-08-02 -0.706771
2013-08-05 -1.039575
2013-08-06 -0.424972
2013-08-07 -0.424972
2013-08-08  0.567020
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.DataFrame pandas.date_range pandas.DataFrame.bfill
"In [104]: df = pd.DataFrame(
   .....:     {
   .....:         ""animal"": ""cat dog cat fish dog cat cat"".split(),
   .....:         ""size"": list(""SSMMMLL""),
   .....:         ""weight"": [8, 10, 11, 1, 20, 12, 12],
   .....:         ""adult"": [False] * 5 + [True] * 2,
   .....:     }
   .....: )
   .....: 

In [105]: df
Out[105]: 
  animal size  weight  adult
0    cat    S       8  False
1    dog    S      10  False
2    cat    M      11  False
3   fish    M       1  False
4    dog    M      20  False
5    cat    L      12   True
6    cat    L      12   True

# List the size of the animals with the highest weight.
In [106]: df.groupby(""animal"").apply(lambda subf: subf[""size""][subf[""weight""].idxmax()], include_groups=False)
Out[106]: 
animal
cat     L
dog     M
fish    M
dtype: object
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.DataFrame pandas.Series.str.split pandas.DataFrame.groupby
"In [107]: gb = df.groupby(""animal"")

In [108]: gb.get_group(""cat"")
Out[108]: 
  animal size  weight  adult
0    cat    S       8  False
2    cat    M      11  False
5    cat    L      12   True
6    cat    L      12   True
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.DataFrame.groupby
"In [109]: def GrowUp(x):
   .....:     avg_weight = sum(x[x[""size""] == ""S""].weight * 1.5)
   .....:     avg_weight += sum(x[x[""size""] == ""M""].weight * 1.25)
   .....:     avg_weight += sum(x[x[""size""] == ""L""].weight)
   .....:     avg_weight /= len(x)
   .....:     return pd.Series([""L"", avg_weight, True], index=[""size"", ""weight"", ""adult""])
   .....: 

In [110]: expected_df = gb.apply(GrowUp, include_groups=False)

In [111]: expected_df
Out[111]: 
       size   weight  adult
animal                     
cat       L  12.4375   True
dog       L  20.0000   True
fish      L   1.2500   True
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.Series
"In [112]: S = pd.Series([i / 100.0 for i in range(1, 11)])

In [113]: def cum_ret(x, y):
   .....:     return x * (1 + y)
   .....: 

In [114]: def red(x):
   .....:     return functools.reduce(cum_ret, x, 1.0)
   .....: 

In [115]: S.expanding().apply(red, raw=True)
Out[115]: 
0    1.010000
1    1.030200
2    1.061106
3    1.103550
4    1.158728
5    1.228251
6    1.314229
7    1.419367
8    1.547110
9    1.701821
dtype: float64
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.Series pandas.Series.expanding
"In [116]: df = pd.DataFrame({""A"": [1, 1, 2, 2], ""B"": [1, -1, 1, 2]})

In [117]: gb = df.groupby(""A"")

In [118]: def replace(g):
   .....:     mask = g < 0
   .....:     return g.where(~mask, g[~mask].mean())
   .....: 

In [119]: gb.transform(replace)
Out[119]: 
   B
0  1
1  1
2  1
3  2
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.DataFrame pandas.DataFrame.groupby
"In [120]: df = pd.DataFrame(
   .....:     {
   .....:         ""code"": [""foo"", ""bar"", ""baz""] * 2,
   .....:         ""data"": [0.16, -0.21, 0.33, 0.45, -0.59, 0.62],
   .....:         ""flag"": [False, True] * 3,
   .....:     }
   .....: )
   .....: 

In [121]: code_groups = df.groupby(""code"")

In [122]: agg_n_sort_order = code_groups[[""data""]].transform(""sum"").sort_values(by=""data"")

In [123]: sorted_df = df.loc[agg_n_sort_order.index]

In [124]: sorted_df
Out[124]: 
  code  data   flag
1  bar -0.21   True
4  bar -0.59  False
0  foo  0.16  False
3  foo  0.45   True
2  baz  0.33  False
5  baz  0.62   True
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.DataFrame pandas.DataFrame.groupby
"In [125]: rng = pd.date_range(start=""2014-10-07"", periods=10, freq=""2min"")

In [126]: ts = pd.Series(data=list(range(10)), index=rng)

In [127]: def MyCust(x):
   .....:     if len(x) > 2:
   .....:         return x.iloc[1] * 1.234
   .....:     return pd.NaT
   .....: 

In [128]: mhc = {""Mean"": ""mean"", ""Max"": ""max"", ""Custom"": MyCust}

In [129]: ts.resample(""5min"").apply(mhc)
Out[129]: 
                     Mean  Max Custom
2014-10-07 00:00:00   1.0    2  1.234
2014-10-07 00:05:00   3.5    4    NaT
2014-10-07 00:10:00   6.0    7  7.404
2014-10-07 00:15:00   8.5    9    NaT

In [130]: ts
Out[130]: 
2014-10-07 00:00:00    0
2014-10-07 00:02:00    1
2014-10-07 00:04:00    2
2014-10-07 00:06:00    3
2014-10-07 00:08:00    4
2014-10-07 00:10:00    5
2014-10-07 00:12:00    6
2014-10-07 00:14:00    7
2014-10-07 00:16:00    8
2014-10-07 00:18:00    9
Freq: 2min, dtype: int64
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.date_range pandas.Series pandas.Series.resample
"In [131]: df = pd.DataFrame(
   .....:     {""Color"": ""Red Red Red Blue"".split(), ""Value"": [100, 150, 50, 50]}
   .....: )
   .....: 

In [132]: df
Out[132]: 
  Color  Value
0   Red    100
1   Red    150
2   Red     50
3  Blue     50

In [133]: df[""Counts""] = df.groupby([""Color""]).transform(len)

In [134]: df
Out[134]: 
  Color  Value  Counts
0   Red    100       3
1   Red    150       3
2   Red     50       3
3  Blue     50       1
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.DataFrame pandas.Series.str.split pandas.DataFrame.groupby
"In [135]: df = pd.DataFrame(
   .....:     {""line_race"": [10, 10, 8, 10, 10, 8], ""beyer"": [99, 102, 103, 103, 88, 100]},
   .....:     index=[
   .....:         ""Last Gunfighter"",
   .....:         ""Last Gunfighter"",
   .....:         ""Last Gunfighter"",
   .....:         ""Paynter"",
   .....:         ""Paynter"",
   .....:         ""Paynter"",
   .....:     ],
   .....: )
   .....: 

In [136]: df
Out[136]: 
                 line_race  beyer
Last Gunfighter         10     99
Last Gunfighter         10    102
Last Gunfighter          8    103
Paynter                 10    103
Paynter                 10     88
Paynter                  8    100

In [137]: df[""beyer_shifted""] = df.groupby(level=0)[""beyer""].shift(1)

In [138]: df
Out[138]: 
                 line_race  beyer  beyer_shifted
Last Gunfighter         10     99            NaN
Last Gunfighter         10    102           99.0
Last Gunfighter          8    103          102.0
Paynter                 10    103            NaN
Paynter                 10     88          103.0
Paynter                  8    100           88.0
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.DataFrame pandas.DataFrame.groupby
"In [139]: df = pd.DataFrame(
   .....:     {
   .....:         ""host"": [""other"", ""other"", ""that"", ""this"", ""this""],
   .....:         ""service"": [""mail"", ""web"", ""mail"", ""mail"", ""web""],
   .....:         ""no"": [1, 2, 1, 2, 1],
   .....:     }
   .....: ).set_index([""host"", ""service""])
   .....: 

In [140]: mask = df.groupby(level=0).agg(""idxmax"")

In [141]: df_count = df.loc[mask[""no""]].reset_index()

In [142]: df_count
Out[142]: 
    host service  no
0  other     web   2
1   that    mail   1
2   this    mail   2
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.DataFrame pandas.DataFrame.set_index pandas.DataFrame.groupby
"In [143]: df = pd.DataFrame([0, 1, 0, 1, 1, 1, 0, 1, 1], columns=[""A""])

In [144]: df[""A""].groupby((df[""A""] != df[""A""].shift()).cumsum()).groups
Out[144]: {1: [0], 2: [1], 3: [2], 4: [3, 4, 5], 5: [6], 6: [7, 8]}

In [145]: df[""A""].groupby((df[""A""] != df[""A""].shift()).cumsum()).cumsum()
Out[145]: 
0    0
1    1
2    0
3    1
4    2
5    3
6    0
7    1
8    2
Name: A, dtype: int64
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.DataFrame
"In [146]: df = pd.DataFrame(
   .....:     data={
   .....:         ""Case"": [""A"", ""A"", ""A"", ""B"", ""A"", ""A"", ""B"", ""A"", ""A""],
   .....:         ""Data"": np.random.randn(9),
   .....:     }
   .....: )
   .....: 

In [147]: dfs = list(
   .....:     zip(
   .....:         *df.groupby(
   .....:             (1 * (df[""Case""] == ""B""))
   .....:             .cumsum()
   .....:             .rolling(window=3, min_periods=1)
   .....:             .median()
   .....:         )
   .....:     )
   .....: )[-1]
   .....: 

In [148]: dfs[0]
Out[148]: 
  Case      Data
0    A  0.276232
1    A -1.087401
2    A -0.673690
3    B  0.113648

In [149]: dfs[1]
Out[149]: 
  Case      Data
4    A -1.478427
5    A  0.524988
6    B  0.404705

In [150]: dfs[2]
Out[150]: 
  Case      Data
7    A  0.577046
8    A -1.715002
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.DataFrame pandas.DataFrame.groupby
"In [151]: df = pd.DataFrame(
   .....:     data={
   .....:         ""Province"": [""ON"", ""QC"", ""BC"", ""AL"", ""AL"", ""MN"", ""ON""],
   .....:         ""City"": [
   .....:             ""Toronto"",
   .....:             ""Montreal"",
   .....:             ""Vancouver"",
   .....:             ""Calgary"",
   .....:             ""Edmonton"",
   .....:             ""Winnipeg"",
   .....:             ""Windsor"",
   .....:         ],
   .....:         ""Sales"": [13, 6, 16, 8, 4, 3, 1],
   .....:     }
   .....: )
   .....: 

In [152]: table = pd.pivot_table(
   .....:     df,
   .....:     values=[""Sales""],
   .....:     index=[""Province""],
   .....:     columns=[""City""],
   .....:     aggfunc=""sum"",
   .....:     margins=True,
   .....: )
   .....: 

In [153]: table.stack(""City"", future_stack=True)
Out[153]: 
                    Sales
Province City            
AL       Calgary      8.0
         Edmonton     4.0
         Montreal     NaN
         Toronto      NaN
         Vancouver    NaN
...                   ...
All      Toronto     13.0
         Vancouver   16.0
         Windsor      1.0
         Winnipeg     3.0
         All         51.0

[48 rows x 1 columns]
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.DataFrame pandas.pivot_table pandas.DataFrame.stack
"In [154]: grades = [48, 99, 75, 80, 42, 80, 72, 68, 36, 78]

In [155]: df = pd.DataFrame(
   .....:     {
   .....:         ""ID"": [""x%d"" % r for r in range(10)],
   .....:         ""Gender"": [""F"", ""M"", ""F"", ""M"", ""F"", ""M"", ""F"", ""M"", ""M"", ""M""],
   .....:         ""ExamYear"": [
   .....:             ""2007"",
   .....:             ""2007"",
   .....:             ""2007"",
   .....:             ""2008"",
   .....:             ""2008"",
   .....:             ""2008"",
   .....:             ""2008"",
   .....:             ""2009"",
   .....:             ""2009"",
   .....:             ""2009"",
   .....:         ],
   .....:         ""Class"": [
   .....:             ""algebra"",
   .....:             ""stats"",
   .....:             ""bio"",
   .....:             ""algebra"",
   .....:             ""algebra"",
   .....:             ""stats"",
   .....:             ""stats"",
   .....:             ""algebra"",
   .....:             ""bio"",
   .....:             ""bio"",
   .....:         ],
   .....:         ""Participated"": [
   .....:             ""yes"",
   .....:             ""yes"",
   .....:             ""yes"",
   .....:             ""yes"",
   .....:             ""no"",
   .....:             ""yes"",
   .....:             ""yes"",
   .....:             ""yes"",
   .....:             ""yes"",
   .....:             ""yes"",
   .....:         ],
   .....:         ""Passed"": [""yes"" if x > 50 else ""no"" for x in grades],
   .....:         ""Employed"": [
   .....:             True,
   .....:             True,
   .....:             True,
   .....:             False,
   .....:             False,
   .....:             False,
   .....:             False,
   .....:             True,
   .....:             True,
   .....:             False,
   .....:         ],
   .....:         ""Grade"": grades,
   .....:     }
   .....: )
   .....: 

In [156]: df.groupby(""ExamYear"").agg(
   .....:     {
   .....:         ""Participated"": lambda x: x.value_counts()[""yes""],
   .....:         ""Passed"": lambda x: sum(x == ""yes""),
   .....:         ""Employed"": lambda x: sum(x),
   .....:         ""Grade"": lambda x: sum(x) / len(x),
   .....:     }
   .....: )
   .....: 
Out[156]: 
          Participated  Passed  Employed      Grade
ExamYear                                           
2007                 3       2         3  74.000000
2008                 3       3         0  68.500000
2009                 3       2         2  60.666667
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.DataFrame pandas.DataFrame.groupby
"In [157]: df = pd.DataFrame(
   .....:     {""value"": np.random.randn(36)},
   .....:     index=pd.date_range(""2011-01-01"", freq=""ME"", periods=36),
   .....: )
   .....: 

In [158]: pd.pivot_table(
   .....:     df, index=df.index.month, columns=df.index.year, values=""value"", aggfunc=""sum""
   .....: )
   .....: 
Out[158]: 
        2011      2012      2013
1  -1.039268 -0.968914  2.565646
2  -0.370647 -1.294524  1.431256
3  -1.157892  0.413738  1.340309
4  -1.344312  0.276662 -1.170299
5   0.844885 -0.472035 -0.226169
6   1.075770 -0.013960  0.410835
7  -0.109050 -0.362543  0.813850
8   1.643563 -0.006154  0.132003
9  -1.469388 -0.923061 -0.827317
10  0.357021  0.895717 -0.076467
11 -0.674600  0.805244 -1.187678
12 -1.776904 -1.206412  1.130127
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.DataFrame pandas.date_range pandas.pivot_table
"In [159]: df = pd.DataFrame(
   .....:     data={
   .....:         ""A"": [[2, 4, 8, 16], [100, 200], [10, 20, 30]],
   .....:         ""B"": [[""a"", ""b"", ""c""], [""jj"", ""kk""], [""ccc""]],
   .....:     },
   .....:     index=[""I"", ""II"", ""III""],
   .....: )
   .....: 

In [160]: def SeriesFromSubList(aList):
   .....:     return pd.Series(aList)
   .....: 

In [161]: df_orgz = pd.concat(
   .....:     {ind: row.apply(SeriesFromSubList) for ind, row in df.iterrows()}
   .....: )
   .....: 

In [162]: df_orgz
Out[162]: 
         0     1     2     3
I   A    2     4     8  16.0
    B    a     b     c   NaN
II  A  100   200   NaN   NaN
    B   jj    kk   NaN   NaN
III A   10  20.0  30.0   NaN
    B  ccc   NaN   NaN   NaN
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.DataFrame pandas.Series pandas.concat pandas.DataFrame.iterrows
"In [163]: df = pd.DataFrame(
   .....:     data=np.random.randn(2000, 2) / 10000,
   .....:     index=pd.date_range(""2001-01-01"", periods=2000),
   .....:     columns=[""A"", ""B""],
   .....: )
   .....: 

In [164]: df
Out[164]: 
                   A         B
2001-01-01 -0.000144 -0.000141
2001-01-02  0.000161  0.000102
2001-01-03  0.000057  0.000088
2001-01-04 -0.000221  0.000097
2001-01-05 -0.000201 -0.000041
...              ...       ...
2006-06-19  0.000040 -0.000235
2006-06-20 -0.000123 -0.000021
2006-06-21 -0.000113  0.000114
2006-06-22  0.000136  0.000109
2006-06-23  0.000027  0.000030

[2000 rows x 2 columns]

In [165]: def gm(df, const):
   .....:     v = ((((df[""A""] + df[""B""]) + 1).cumprod()) - 1) * const
   .....:     return v.iloc[-1]
   .....: 

In [166]: s = pd.Series(
   .....:     {
   .....:         df.index[i]: gm(df.iloc[i: min(i + 51, len(df) - 1)], 5)
   .....:         for i in range(len(df) - 50)
   .....:     }
   .....: )
   .....: 

In [167]: s
Out[167]: 
2001-01-01    0.000930
2001-01-02    0.002615
2001-01-03    0.001281
2001-01-04    0.001117
2001-01-05    0.002772
                ...   
2006-04-30    0.003296
2006-05-01    0.002629
2006-05-02    0.002081
2006-05-03    0.004247
2006-05-04    0.003928
Length: 1950, dtype: float64
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.DataFrame pandas.date_range pandas.Series
"In [168]: rng = pd.date_range(start=""2014-01-01"", periods=100)

In [169]: df = pd.DataFrame(
   .....:     {
   .....:         ""Open"": np.random.randn(len(rng)),
   .....:         ""Close"": np.random.randn(len(rng)),
   .....:         ""Volume"": np.random.randint(100, 2000, len(rng)),
   .....:     },
   .....:     index=rng,
   .....: )
   .....: 

In [170]: df
Out[170]: 
                Open     Close  Volume
2014-01-01 -1.611353 -0.492885    1219
2014-01-02 -3.000951  0.445794    1054
2014-01-03 -0.138359 -0.076081    1381
2014-01-04  0.301568  1.198259    1253
2014-01-05  0.276381 -0.669831    1728
...              ...       ...     ...
2014-04-06 -0.040338  0.937843    1188
2014-04-07  0.359661 -0.285908    1864
2014-04-08  0.060978  1.714814     941
2014-04-09  1.759055 -0.455942    1065
2014-04-10  0.138185 -1.147008    1453

[100 rows x 3 columns]

In [171]: def vwap(bars):
   .....:     return (bars.Close * bars.Volume).sum() / bars.Volume.sum()
   .....: 

In [172]: window = 5

In [173]: s = pd.concat(
   .....:     [
   .....:         (pd.Series(vwap(df.iloc[i: i + window]), index=[df.index[i + window]]))
   .....:         for i in range(len(df) - window)
   .....:     ]
   .....: )
   .....: 

In [174]: s.round(2)
Out[174]: 
2014-01-06    0.02
2014-01-07    0.11
2014-01-08    0.10
2014-01-09    0.07
2014-01-10   -0.29
              ... 
2014-04-06   -0.63
2014-04-07   -0.02
2014-04-08   -0.03
2014-04-09    0.34
2014-04-10    0.29
Length: 95, dtype: float64
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.date_range pandas.DataFrame pandas.concat pandas.Series pandas.Series.round
"In [175]: dates = pd.date_range(""2000-01-01"", periods=5)

In [176]: dates.to_period(freq=""M"").to_timestamp()
Out[176]: 
DatetimeIndex(['2000-01-01', '2000-01-01', '2000-01-01', '2000-01-01',
               '2000-01-01'],
              dtype='datetime64[ns]', freq=None)
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.date_range pandas.DatetimeIndex
"In [177]: rng = pd.date_range(""2000-01-01"", periods=6)

In [178]: df1 = pd.DataFrame(np.random.randn(6, 3), index=rng, columns=[""A"", ""B"", ""C""])

In [179]: df2 = df1.copy()
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.date_range pandas.DataFrame pandas.DataFrame.copy
"In [180]: df = pd.concat([df1, df2], ignore_index=True)

In [181]: df
Out[181]: 
           A         B         C
0  -0.870117 -0.479265 -0.790855
1   0.144817  1.726395 -0.464535
2  -0.821906  1.597605  0.187307
3  -0.128342 -1.511638 -0.289858
4   0.399194 -1.430030 -0.639760
5   1.115116 -2.012600  1.810662
6  -0.870117 -0.479265 -0.790855
7   0.144817  1.726395 -0.464535
8  -0.821906  1.597605  0.187307
9  -0.128342 -1.511638 -0.289858
10  0.399194 -1.430030 -0.639760
11  1.115116 -2.012600  1.810662
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.concat
"In [182]: df = pd.DataFrame(
   .....:     data={
   .....:         ""Area"": [""A""] * 5 + [""C""] * 2,
   .....:         ""Bins"": [110] * 2 + [160] * 3 + [40] * 2,
   .....:         ""Test_0"": [0, 1, 0, 1, 2, 0, 1],
   .....:         ""Data"": np.random.randn(7),
   .....:     }
   .....: )
   .....: 

In [183]: df
Out[183]: 
  Area  Bins  Test_0      Data
0    A   110       0 -0.433937
1    A   110       1 -0.160552
2    A   160       0  0.744434
3    A   160       1  1.754213
4    A   160       2  0.000850
5    C    40       0  0.342243
6    C    40       1  1.070599

In [184]: df[""Test_1""] = df[""Test_0""] - 1

In [185]: pd.merge(
   .....:     df,
   .....:     df,
   .....:     left_on=[""Bins"", ""Area"", ""Test_0""],
   .....:     right_on=[""Bins"", ""Area"", ""Test_1""],
   .....:     suffixes=(""_L"", ""_R""),
   .....: )
   .....: 
Out[185]: 
  Area  Bins  Test_0_L    Data_L  Test_1_L  Test_0_R    Data_R  Test_1_R
0    A   110         0 -0.433937        -1         1 -0.160552         0
1    A   160         0  0.744434        -1         1  1.754213         0
2    A   160         1  1.754213         0         2  0.000850         1
3    C    40         0  0.342243        -1         1  1.070599         0
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.DataFrame pandas.merge
"In [186]: df = pd.DataFrame(
   .....:     {
   .....:         ""stratifying_var"": np.random.uniform(0, 100, 20),
   .....:         ""price"": np.random.normal(100, 5, 20),
   .....:     }
   .....: )
   .....: 

In [187]: df[""quartiles""] = pd.qcut(
   .....:     df[""stratifying_var""], 4, labels=[""0-25%"", ""25-50%"", ""50-75%"", ""75-100%""]
   .....: )
   .....: 

In [188]: df.boxplot(column=""price"", by=""quartiles"")
Out[188]: 
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.DataFrame pandas.qcut pandas.DataFrame.boxplot
"In [189]: for i in range(3):
   .....:     data = pd.DataFrame(np.random.randn(10, 4))
   .....:     data.to_csv(""file_{}.csv"".format(i))
   .....: 

In [190]: files = [""file_0.csv"", ""file_1.csv"", ""file_2.csv""]

In [191]: result = pd.concat([pd.read_csv(f) for f in files], ignore_index=True)
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.DataFrame pandas.io.formats.style.Styler.format pandas.concat pandas.read_csv
"In [192]: import glob

In [193]: import os

In [194]: files = glob.glob(""file_*.csv"")

In [195]: result = pd.concat([pd.read_csv(f) for f in files], ignore_index=True)
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.concat pandas.read_csv
"In [196]: i = pd.date_range(""20000101"", periods=10000)

In [197]: df = pd.DataFrame({""year"": i.year, ""month"": i.month, ""day"": i.day})

In [198]: df.head()
Out[198]: 
   year  month  day
0  2000      1    1
1  2000      1    2
2  2000      1    3
3  2000      1    4
4  2000      1    5

In [199]: %timeit pd.to_datetime(df.year * 10000 + df.month * 100 + df.day, format='%Y%m%d')
   .....: ds = df.apply(lambda x: ""%04d%02d%02d"" % (x[""year""], x[""month""], x[""day""]), axis=1)
   .....: ds.head()
   .....: %timeit pd.to_datetime(ds)
   .....: 
4.01 ms +- 635 us per loop (mean +- std. dev. of 7 runs, 100 loops each)
1.05 ms +- 7.39 us per loop (mean +- std. dev. of 7 runs, 1,000 loops each)
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.date_range pandas.DataFrame pandas.DataFrame.head pandas.to_datetime pandas.DataFrame.apply pandas.DataFrame.head
"In [201]: from io import StringIO

In [202]: pd.read_csv(
   .....:     StringIO(data),
   .....:     sep="";"",
   .....:     skiprows=[11, 12],
   .....:     index_col=0,
   .....:     parse_dates=True,
   .....:     header=10,
   .....: )
   .....: 
Out[202]: 
                     Param1  Param2  Param4  Param5
date                                               
1990-01-01 00:00:00       1       1       2       3
1990-01-01 01:00:00       5       3       4       5
1990-01-01 02:00:00       9       5       6       7
1990-01-01 03:00:00      13       7       8       9
1990-01-01 04:00:00      17       9      10      11
1990-01-01 05:00:00      21      11      12      13
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.read_csv
"In [203]: pd.read_csv(StringIO(data), sep="";"", header=10, nrows=10).columns
Out[203]: Index(['date', 'Param1', 'Param2', 'Param4', 'Param5'], dtype='object')

In [204]: columns = pd.read_csv(StringIO(data), sep="";"", header=10, nrows=10).columns

In [205]: pd.read_csv(
   .....:     StringIO(data), sep="";"", index_col=0, header=12, parse_dates=True, names=columns
   .....: )
   .....: 
Out[205]: 
                     Param1  Param2  Param4  Param5
date                                               
1990-01-01 00:00:00       1       1       2       3
1990-01-01 01:00:00       5       3       4       5
1990-01-01 02:00:00       9       5       6       7
1990-01-01 03:00:00      13       7       8       9
1990-01-01 04:00:00      17       9      10      11
1990-01-01 05:00:00      21      11      12      13
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.read_csv pandas.Index
"In [206]: df = pd.DataFrame(np.random.randn(8, 3))

In [207]: store = pd.HDFStore(""test.h5"")

In [208]: store.put(""df"", df)

# you can store an arbitrary Python object via pickle
In [209]: store.get_storer(""df"").attrs.my_attribute = {""A"": 10}

In [210]: store.get_storer(""df"").attrs.my_attribute
Out[210]: {'A': 10}
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.DataFrame pandas.HDFStore.put
"In [211]: store = pd.HDFStore(""test.h5"", ""w"", driver=""H5FD_CORE"")

In [212]: df = pd.DataFrame(np.random.randn(8, 3))

In [213]: store[""test""] = df

# only after closing the store, data is written to disk:
In [214]: store.close()
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.DataFrame
"names = ""count"", ""avg"", ""scale""

# note that the offsets are larger than the size of the type because of
# struct padding
offsets = 0, 8, 16
formats = ""i4"", ""f8"", ""f4""
dt = np.dtype({""names"": names, ""offsets"": offsets, ""formats"": formats}, align=True)
df = pd.DataFrame(np.fromfile(""binary.dat"", dt))
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.DataFrame
"In [215]: df = pd.DataFrame(np.random.random(size=(100, 5)))

In [216]: corr_mat = df.corr()

In [217]: mask = np.tril(np.ones_like(corr_mat, dtype=np.bool_), k=-1)

In [218]: corr_mat.where(mask)
Out[218]: 
          0         1         2        3   4
0       NaN       NaN       NaN      NaN NaN
1 -0.079861       NaN       NaN      NaN NaN
2 -0.236573  0.183801       NaN      NaN NaN
3 -0.013795 -0.051975  0.037235      NaN NaN
4 -0.031974  0.118342 -0.073499 -0.02063 NaN
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.DataFrame pandas.DataFrame.corr
"In [219]: def distcorr(x, y):
   .....:     n = len(x)
   .....:     a = np.zeros(shape=(n, n))
   .....:     b = np.zeros(shape=(n, n))
   .....:     for i in range(n):
   .....:         for j in range(i + 1, n):
   .....:             a[i, j] = abs(x[i] - x[j])
   .....:             b[i, j] = abs(y[i] - y[j])
   .....:     a += a.T
   .....:     b += b.T
   .....:     a_bar = np.vstack([np.nanmean(a, axis=0)] * n)
   .....:     b_bar = np.vstack([np.nanmean(b, axis=0)] * n)
   .....:     A = a - a_bar - a_bar.T + np.full(shape=(n, n), fill_value=a_bar.mean())
   .....:     B = b - b_bar - b_bar.T + np.full(shape=(n, n), fill_value=b_bar.mean())
   .....:     cov_ab = np.sqrt(np.nansum(A * B)) / n
   .....:     std_a = np.sqrt(np.sqrt(np.nansum(A ** 2)) / n)
   .....:     std_b = np.sqrt(np.sqrt(np.nansum(B ** 2)) / n)
   .....:     return cov_ab / std_a / std_b
   .....: 

In [220]: df = pd.DataFrame(np.random.normal(size=(100, 3)))

In [221]: df.corr(method=distcorr)
Out[221]: 
          0         1         2
0  1.000000  0.197613  0.216328
1  0.197613  1.000000  0.208749
2  0.216328  0.208749  1.000000
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.DataFrame pandas.DataFrame.corr
"In [222]: import datetime

In [223]: s = pd.Series(pd.date_range(""2012-1-1"", periods=3, freq=""D""))

In [224]: s - s.max()
Out[224]: 
0   -2 days
1   -1 days
2    0 days
dtype: timedelta64[ns]

In [225]: s.max() - s
Out[225]: 
0   2 days
1   1 days
2   0 days
dtype: timedelta64[ns]

In [226]: s - datetime.datetime(2011, 1, 1, 3, 5)
Out[226]: 
0   364 days 20:55:00
1   365 days 20:55:00
2   366 days 20:55:00
dtype: timedelta64[ns]

In [227]: s + datetime.timedelta(minutes=5)
Out[227]: 
0   2012-01-01 00:05:00
1   2012-01-02 00:05:00
2   2012-01-03 00:05:00
dtype: datetime64[ns]

In [228]: datetime.datetime(2011, 1, 1, 3, 5) - s
Out[228]: 
0   -365 days +03:05:00
1   -366 days +03:05:00
2   -367 days +03:05:00
dtype: timedelta64[ns]

In [229]: datetime.timedelta(minutes=5) + s
Out[229]: 
0   2012-01-01 00:05:00
1   2012-01-02 00:05:00
2   2012-01-03 00:05:00
dtype: datetime64[ns]
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.Series pandas.date_range pandas.Series.max
"In [230]: deltas = pd.Series([datetime.timedelta(days=i) for i in range(3)])

In [231]: df = pd.DataFrame({""A"": s, ""B"": deltas})

In [232]: df
Out[232]: 
           A      B
0 2012-01-01 0 days
1 2012-01-02 1 days
2 2012-01-03 2 days

In [233]: df[""New Dates""] = df[""A""] + df[""B""]

In [234]: df[""Delta""] = df[""A""] - df[""New Dates""]

In [235]: df
Out[235]: 
           A      B  New Dates   Delta
0 2012-01-01 0 days 2012-01-01  0 days
1 2012-01-02 1 days 2012-01-03 -1 days
2 2012-01-03 2 days 2012-01-05 -2 days

In [236]: df.dtypes
Out[236]: 
A             datetime64[ns]
B            timedelta64[ns]
New Dates     datetime64[ns]
Delta        timedelta64[ns]
dtype: object
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.Series pandas.DataFrame
"In [237]: y = s - s.shift()

In [238]: y
Out[238]: 
0      NaT
1   1 days
2   1 days
dtype: timedelta64[ns]

In [239]: y[1] = np.nan

In [240]: y
Out[240]: 
0      NaT
1      NaT
2   1 days
dtype: timedelta64[ns]
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.Series.shift
"In [241]: def expand_grid(data_dict):
   .....:     rows = itertools.product(*data_dict.values())
   .....:     return pd.DataFrame.from_records(rows, columns=data_dict.keys())
   .....: 

In [242]: df = expand_grid(
   .....:     {""height"": [60, 70], ""weight"": [100, 140, 180], ""sex"": [""Male"", ""Female""]}
   .....: )
   .....: 

In [243]: df
Out[243]: 
    height  weight     sex
0       60     100    Male
1       60     100  Female
2       60     140    Male
3       60     140  Female
4       60     180    Male
5       60     180  Female
6       70     100    Male
7       70     100  Female
8       70     140    Male
9       70     140  Female
10      70     180    Male
11      70     180  Female
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.DataFrame.from_records
"In [244]: v = s.to_numpy()

In [245]: is_constant = v.shape[0] == 0 or (s[0] == s).all()
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.Series.to_numpy
"In [246]: v = s.dropna().to_numpy()

In [247]: is_constant = v.shape[0] == 0 or (s[0] == s).all()
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.Series.dropna
"In [248]: v = s.to_numpy()

In [249]: is_constant = v.shape[0] == 0 or (s[0] == s).all() or not pd.notna(v).any()
",https://pandas.pydata.org/docs/user_guide/cookbook.html, pandas.Series.to_numpy pandas.notna
"In [1]: speeds = pd.DataFrame(
   ...:     [
   ...:         (""bird"", ""Falconiformes"", 389.0),
   ...:         (""bird"", ""Psittaciformes"", 24.0),
   ...:         (""mammal"", ""Carnivora"", 80.2),
   ...:         (""mammal"", ""Primates"", np.nan),
   ...:         (""mammal"", ""Carnivora"", 58),
   ...:     ],
   ...:     index=[""falcon"", ""parrot"", ""lion"", ""monkey"", ""leopard""],
   ...:     columns=(""class"", ""order"", ""max_speed""),
   ...: )
   ...: 

In [2]: speeds
Out[2]: 
          class           order  max_speed
falcon     bird   Falconiformes      389.0
parrot     bird  Psittaciformes       24.0
lion     mammal       Carnivora       80.2
monkey   mammal        Primates        NaN
leopard  mammal       Carnivora       58.0

In [3]: grouped = speeds.groupby(""class"")

In [4]: grouped = speeds.groupby([""class"", ""order""])
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame pandas.DataFrame.groupby
"In [5]: df = pd.DataFrame(
   ...:     {
   ...:         ""A"": [""foo"", ""bar"", ""foo"", ""bar"", ""foo"", ""bar"", ""foo"", ""foo""],
   ...:         ""B"": [""one"", ""one"", ""two"", ""three"", ""two"", ""two"", ""one"", ""three""],
   ...:         ""C"": np.random.randn(8),
   ...:         ""D"": np.random.randn(8),
   ...:     }
   ...: )
   ...: 

In [6]: df
Out[6]: 
     A      B         C         D
0  foo    one  0.469112 -0.861849
1  bar    one -0.282863 -2.104569
2  foo    two -1.509059 -0.494929
3  bar  three -1.135632  1.071804
4  foo    two  1.212112  0.721555
5  bar    two -0.173215 -0.706771
6  foo    one  0.119209 -1.039575
7  foo  three -1.044236  0.271860
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame
"In [7]: grouped = df.groupby(""A"")

In [8]: grouped = df.groupby(""B"")

In [9]: grouped = df.groupby([""A"", ""B""])
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame.groupby
"In [10]: df2 = df.set_index([""A"", ""B""])

In [11]: grouped = df2.groupby(level=df2.index.names.difference([""B""]))

In [12]: grouped.sum()
Out[12]: 
            C         D
A                      
bar -1.591710 -1.739537
foo -0.752861 -1.402938
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame.set_index pandas.DataFrame.groupby
"In [13]: def get_letter_type(letter):
   ....:     if letter.lower() in 'aeiou':
   ....:         return 'vowel'
   ....:     else:
   ....:         return 'consonant'
   ....: 

In [14]: grouped = df.T.groupby(get_letter_type)
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.Series.str.lower
"In [15]: index = [1, 2, 3, 1, 2, 3]

In [16]: s = pd.Series([1, 2, 3, 10, 20, 30], index=index)

In [17]: s
Out[17]: 
1     1
2     2
3     3
1    10
2    20
3    30
dtype: int64

In [18]: grouped = s.groupby(level=0)

In [19]: grouped.first()
Out[19]: 
1    1
2    2
3    3
dtype: int64

In [20]: grouped.last()
Out[20]: 
1    10
2    20
3    30
dtype: int64

In [21]: grouped.sum()
Out[21]: 
1    11
2    22
3    33
dtype: int64
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.Series pandas.Series.groupby
"In [22]: df2 = pd.DataFrame({""X"": [""B"", ""B"", ""A"", ""A""], ""Y"": [1, 2, 3, 4]})

In [23]: df2.groupby([""X""]).sum()
Out[23]: 
   Y
X   
A  7
B  3

In [24]: df2.groupby([""X""], sort=False).sum()
Out[24]: 
   Y
X   
B  3
A  7
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame pandas.DataFrame.groupby
"In [25]: df3 = pd.DataFrame({""X"": [""A"", ""B"", ""A"", ""B""], ""Y"": [1, 4, 3, 2]})

In [26]: df3.groupby(""X"").get_group(""A"")
Out[26]: 
   X  Y
0  A  1
2  A  3

In [27]: df3.groupby([""X""]).get_group((""B"",))
Out[27]: 
   X  Y
1  B  4
3  B  2
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame pandas.DataFrame.groupby
"In [28]: df_list = [[1, 2, 3], [1, None, 4], [2, 1, 3], [1, 2, 2]]

In [29]: df_dropna = pd.DataFrame(df_list, columns=[""a"", ""b"", ""c""])

In [30]: df_dropna
Out[30]: 
   a    b  c
0  1  2.0  3
1  1  NaN  4
2  2  1.0  3
3  1  2.0  2
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame
"# Default ``dropna`` is set to True, which will exclude NaNs in keys
In [31]: df_dropna.groupby(by=[""b""], dropna=True).sum()
Out[31]: 
     a  c
b        
1.0  2  3
2.0  2  5

# In order to allow NaN in keys, set ``dropna`` to False
In [32]: df_dropna.groupby(by=[""b""], dropna=False).sum()
Out[32]: 
     a  c
b        
1.0  2  3
2.0  2  5
NaN  1  4
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame.groupby
"In [33]: df.groupby(""A"").groups
Out[33]: {'bar': [1, 3, 5], 'foo': [0, 2, 4, 6, 7]}

In [34]: df.T.groupby(get_letter_type).groups
Out[34]: {'consonant': ['B', 'C', 'D'], 'vowel': ['A']}
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame.groupby
"In [35]: grouped = df.groupby([""A"", ""B""])

In [36]: grouped.groups
Out[36]: {('bar', 'one'): [1], ('bar', 'three'): [3], ('bar', 'two'): [5], ('foo', 'one'): [0, 6], ('foo', 'three'): [7], ('foo', 'two'): [2, 4]}

In [37]: len(grouped)
Out[37]: 6
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame.groupby
"In [38]: n = 10

In [39]: weight = np.random.normal(166, 20, size=n)

In [40]: height = np.random.normal(60, 10, size=n)

In [41]: time = pd.date_range(""1/1/2000"", periods=n)

In [42]: gender = np.random.choice([""male"", ""female""], size=n)

In [43]: df = pd.DataFrame(
   ....:     {""height"": height, ""weight"": weight, ""gender"": gender}, index=time
   ....: )
   ....: 

In [44]: df
Out[44]: 
               height      weight  gender
2000-01-01  42.849980  157.500553    male
2000-01-02  49.607315  177.340407    male
2000-01-03  56.293531  171.524640    male
2000-01-04  48.421077  144.251986  female
2000-01-05  46.556882  152.526206    male
2000-01-06  68.448851  168.272968  female
2000-01-07  70.757698  136.431469    male
2000-01-08  58.909500  176.499753  female
2000-01-09  76.435631  174.094104  female
2000-01-10  45.306120  177.540920    male

In [45]: gb = df.groupby(""gender"")
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.date_range pandas.DataFrame pandas.DataFrame.groupby
"In [47]: arrays = [
   ....:     [""bar"", ""bar"", ""baz"", ""baz"", ""foo"", ""foo"", ""qux"", ""qux""],
   ....:     [""one"", ""two"", ""one"", ""two"", ""one"", ""two"", ""one"", ""two""],
   ....: ]
   ....: 

In [48]: index = pd.MultiIndex.from_arrays(arrays, names=[""first"", ""second""])

In [49]: s = pd.Series(np.random.randn(8), index=index)

In [50]: s
Out[50]: 
first  second
bar    one      -0.919854
       two      -0.042379
baz    one       1.247642
       two      -0.009920
foo    one       0.290213
       two       0.495767
qux    one       0.362949
       two       1.548106
dtype: float64
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.MultiIndex.from_arrays pandas.Series
"In [51]: grouped = s.groupby(level=0)

In [52]: grouped.sum()
Out[52]: 
first
bar   -0.962232
baz    1.237723
foo    0.785980
qux    1.911055
dtype: float64
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.Series.groupby
"In [53]: s.groupby(level=""second"").sum()
Out[53]: 
second
one    0.980950
two    1.991575
dtype: float64
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.Series.groupby
"In [54]: arrays = [
   ....:     [""bar"", ""bar"", ""baz"", ""baz"", ""foo"", ""foo"", ""qux"", ""qux""],
   ....:     [""doo"", ""doo"", ""bee"", ""bee"", ""bop"", ""bop"", ""bop"", ""bop""],
   ....:     [""one"", ""two"", ""one"", ""two"", ""one"", ""two"", ""one"", ""two""],
   ....: ]
   ....: 

In [55]: index = pd.MultiIndex.from_arrays(arrays, names=[""first"", ""second"", ""third""])

In [56]: s = pd.Series(np.random.randn(8), index=index)

In [57]: s
Out[57]: 
first  second  third
bar    doo     one     -1.131345
               two     -0.089329
baz    bee     one      0.337863
               two     -0.945867
foo    bop     one     -0.932132
               two      1.956030
qux    bop     one      0.017587
               two     -0.016692
dtype: float64

In [58]: s.groupby(level=[""first"", ""second""]).sum()
Out[58]: 
first  second
bar    doo      -1.220674
baz    bee      -0.608004
foo    bop       1.023898
qux    bop       0.000895
dtype: float64
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.MultiIndex.from_arrays pandas.Series pandas.Series.groupby
"In [59]: s.groupby([""first"", ""second""]).sum()
Out[59]: 
first  second
bar    doo      -1.220674
baz    bee      -0.608004
foo    bop       1.023898
qux    bop       0.000895
dtype: float64
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.Series.groupby
"In [60]: arrays = [
   ....:     [""bar"", ""bar"", ""baz"", ""baz"", ""foo"", ""foo"", ""qux"", ""qux""],
   ....:     [""one"", ""two"", ""one"", ""two"", ""one"", ""two"", ""one"", ""two""],
   ....: ]
   ....: 

In [61]: index = pd.MultiIndex.from_arrays(arrays, names=[""first"", ""second""])

In [62]: df = pd.DataFrame({""A"": [1, 1, 1, 1, 2, 2, 3, 3], ""B"": np.arange(8)}, index=index)

In [63]: df
Out[63]: 
              A  B
first second      
bar   one     1  0
      two     1  1
baz   one     1  2
      two     1  3
foo   one     2  4
      two     2  5
qux   one     3  6
      two     3  7
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.MultiIndex.from_arrays pandas.DataFrame
"In [64]: df.groupby([pd.Grouper(level=1), ""A""]).sum()
Out[64]: 
          B
second A   
one    1  2
       2  4
       3  6
two    1  4
       2  5
       3  7
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame.groupby pandas.Grouper
"In [65]: df.groupby([pd.Grouper(level=""second""), ""A""]).sum()
Out[65]: 
          B
second A   
one    1  2
       2  4
       3  6
two    1  4
       2  5
       3  7
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame.groupby pandas.Grouper
"In [66]: df.groupby([""second"", ""A""]).sum()
Out[66]: 
          B
second A   
one    1  2
       2  4
       3  6
two    1  4
       2  5
       3  7
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame.groupby
"In [67]: df = pd.DataFrame(
   ....:     {
   ....:         ""A"": [""foo"", ""bar"", ""foo"", ""bar"", ""foo"", ""bar"", ""foo"", ""foo""],
   ....:         ""B"": [""one"", ""one"", ""two"", ""three"", ""two"", ""two"", ""one"", ""three""],
   ....:         ""C"": np.random.randn(8),
   ....:         ""D"": np.random.randn(8),
   ....:     }
   ....: )
   ....: 

In [68]: df
Out[68]: 
     A      B         C         D
0  foo    one -0.575247  1.346061
1  bar    one  0.254161  1.511763
2  foo    two -1.143704  1.627081
3  bar  three  0.215897 -0.990582
4  foo    two  1.193555 -0.441652
5  bar    two -0.077118  1.211526
6  foo    one -0.408530  0.268520
7  foo  three -0.862495  0.024580

In [69]: grouped = df.groupby([""A""])

In [70]: grouped_C = grouped[""C""]

In [71]: grouped_D = grouped[""D""]
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame pandas.DataFrame.groupby
"In [74]: grouped = df.groupby('A')

In [75]: for name, group in grouped:
   ....:     print(name)
   ....:     print(group)
   ....: 
bar
     A      B         C         D
1  bar    one  0.254161  1.511763
3  bar  three  0.215897 -0.990582
5  bar    two -0.077118  1.211526
foo
     A      B         C         D
0  foo    one -0.575247  1.346061
2  foo    two -1.143704  1.627081
4  foo    two  1.193555 -0.441652
6  foo    one -0.408530  0.268520
7  foo  three -0.862495  0.024580
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame.groupby
"In [76]: for name, group in df.groupby(['A', 'B']):
   ....:     print(name)
   ....:     print(group)
   ....: 
('bar', 'one')
     A    B         C         D
1  bar  one  0.254161  1.511763
('bar', 'three')
     A      B         C         D
3  bar  three  0.215897 -0.990582
('bar', 'two')
     A    B         C         D
5  bar  two -0.077118  1.211526
('foo', 'one')
     A    B         C         D
0  foo  one -0.575247  1.346061
6  foo  one -0.408530  0.268520
('foo', 'three')
     A      B         C        D
7  foo  three -0.862495  0.02458
('foo', 'two')
     A    B         C         D
2  foo  two -1.143704  1.627081
4  foo  two  1.193555 -0.441652
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame.groupby
"In [78]: df.groupby([""A"", ""B""]).get_group((""bar"", ""one""))
Out[78]: 
     A    B         C         D
1  bar  one  0.254161  1.511763
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame.groupby
"In [79]: animals = pd.DataFrame(
   ....:     {
   ....:         ""kind"": [""cat"", ""dog"", ""cat"", ""dog""],
   ....:         ""height"": [9.1, 6.0, 9.5, 34.0],
   ....:         ""weight"": [7.9, 7.5, 9.9, 198.0],
   ....:     }
   ....: )
   ....: 

In [80]: animals
Out[80]: 
  kind  height  weight
0  cat     9.1     7.9
1  dog     6.0     7.5
2  cat     9.5     9.9
3  dog    34.0   198.0

In [81]: animals.groupby(""kind"").sum()
Out[81]: 
      height  weight
kind                
cat     18.6    17.8
dog     40.0   205.5
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame pandas.DataFrame.groupby
"In [82]: animals.groupby(""kind"", as_index=False).sum()
Out[82]: 
  kind  height  weight
0  cat    18.6    17.8
1  dog    40.0   205.5
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame.groupby
"In [83]: df.groupby(""A"")[[""C"", ""D""]].max()
Out[83]: 
            C         D
A                      
bar  0.254161  1.511763
foo  1.193555  1.627081

In [84]: df.groupby([""A"", ""B""]).mean()
Out[84]: 
                  C         D
A   B                        
bar one    0.254161  1.511763
    three  0.215897 -0.990582
    two   -0.077118  1.211526
foo one   -0.491888  0.807291
    three -0.862495  0.024580
    two    0.024925  0.592714
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame.groupby
"In [85]: grouped = df.groupby([""A"", ""B""])

In [86]: grouped.size()
Out[86]: 
A    B    
bar  one      1
     three    1
     two      1
foo  one      2
     three    1
     two      2
dtype: int64
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame.groupby
"In [88]: ll = [['foo', 1], ['foo', 2], ['foo', 2], ['bar', 1], ['bar', 1]]

In [89]: df4 = pd.DataFrame(ll, columns=[""A"", ""B""])

In [90]: df4
Out[90]: 
     A  B
0  foo  1
1  foo  2
2  foo  2
3  bar  1
4  bar  1

In [91]: df4.groupby(""A"")[""B""].nunique()
Out[91]: 
A
bar    1
foo    2
Name: B, dtype: int64
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame pandas.DataFrame.groupby
"In [92]: grouped = df.groupby(""A"")

In [93]: grouped[[""C"", ""D""]].aggregate(""sum"")
Out[93]: 
            C         D
A                      
bar  0.392940  1.732707
foo -1.796421  2.824590

In [94]: grouped = df.groupby([""A"", ""B""])

In [95]: grouped.agg(""sum"")
Out[95]: 
                  C         D
A   B                        
bar one    0.254161  1.511763
    three  0.215897 -0.990582
    two   -0.077118  1.211526
foo one   -0.983776  1.614581
    three -0.862495  0.024580
    two    0.049851  1.185429
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame.groupby
"In [96]: grouped = df.groupby([""A"", ""B""], as_index=False)

In [97]: grouped.agg(""sum"")
Out[97]: 
     A      B         C         D
0  bar    one  0.254161  1.511763
1  bar  three  0.215897 -0.990582
2  bar    two -0.077118  1.211526
3  foo    one -0.983776  1.614581
4  foo  three -0.862495  0.024580
5  foo    two  0.049851  1.185429

In [98]: df.groupby(""A"", as_index=False)[[""C"", ""D""]].agg(""sum"")
Out[98]: 
     A         C         D
0  bar  0.392940  1.732707
1  foo -1.796421  2.824590
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame.groupby
"In [99]: df.groupby([""A"", ""B""]).agg(""sum"").reset_index()
Out[99]: 
     A      B         C         D
0  bar    one  0.254161  1.511763
1  bar  three  0.215897 -0.990582
2  bar    two -0.077118  1.211526
3  foo    one -0.983776  1.614581
4  foo  three -0.862495  0.024580
5  foo    two  0.049851  1.185429
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame.groupby
"In [100]: animals
Out[100]: 
  kind  height  weight
0  cat     9.1     7.9
1  dog     6.0     7.5
2  cat     9.5     9.9
3  dog    34.0   198.0

In [101]: animals.groupby(""kind"")[[""height""]].agg(lambda x: set(x))
Out[101]: 
           height
kind             
cat    {9.1, 9.5}
dog   {34.0, 6.0}
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame.groupby
"In [102]: animals.groupby(""kind"")[[""height""]].agg(lambda x: x.astype(int).sum())
Out[102]: 
      height
kind        
cat       18
dog       40
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame.groupby
"In [103]: grouped = df.groupby(""A"")

In [104]: grouped[""C""].agg([""sum"", ""mean"", ""std""])
Out[104]: 
          sum      mean       std
A                                
bar  0.392940  0.130980  0.181231
foo -1.796421 -0.359284  0.912265
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame.groupby
"In [110]: animals
Out[110]: 
  kind  height  weight
0  cat     9.1     7.9
1  dog     6.0     7.5
2  cat     9.5     9.9
3  dog    34.0   198.0

In [111]: animals.groupby(""kind"").agg(
   .....:     min_height=pd.NamedAgg(column=""height"", aggfunc=""min""),
   .....:     max_height=pd.NamedAgg(column=""height"", aggfunc=""max""),
   .....:     average_weight=pd.NamedAgg(column=""weight"", aggfunc=""mean""),
   .....: )
   .....: 
Out[111]: 
      min_height  max_height  average_weight
kind                                        
cat          9.1         9.5            8.90
dog          6.0        34.0          102.75
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame.groupby pandas.NamedAgg
"In [112]: animals.groupby(""kind"").agg(
   .....:     min_height=(""height"", ""min""),
   .....:     max_height=(""height"", ""max""),
   .....:     average_weight=(""weight"", ""mean""),
   .....: )
   .....: 
Out[112]: 
      min_height  max_height  average_weight
kind                                        
cat          9.1         9.5            8.90
dog          6.0        34.0          102.75
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame.groupby
"In [113]: animals.groupby(""kind"").agg(
   .....:     **{
   .....:         ""total weight"": pd.NamedAgg(column=""weight"", aggfunc=""sum"")
   .....:     }
   .....: )
   .....: 
Out[113]: 
      total weight
kind              
cat           17.8
dog          205.5
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame.groupby pandas.NamedAgg
"In [114]: animals.groupby(""kind"").height.agg(
   .....:     min_height=""min"",
   .....:     max_height=""max"",
   .....: )
   .....: 
Out[114]: 
      min_height  max_height
kind                        
cat          9.1         9.5
dog          6.0        34.0
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame.groupby
"In [117]: speeds
Out[117]: 
          class           order  max_speed
falcon     bird   Falconiformes      389.0
parrot     bird  Psittaciformes       24.0
lion     mammal       Carnivora       80.2
monkey   mammal        Primates        NaN
leopard  mammal       Carnivora       58.0

In [118]: grouped = speeds.groupby(""class"")[""max_speed""]

In [119]: grouped.cumsum()
Out[119]: 
falcon     389.0
parrot     413.0
lion        80.2
monkey       NaN
leopard    138.2
Name: max_speed, dtype: float64

In [120]: grouped.diff()
Out[120]: 
falcon       NaN
parrot    -365.0
lion         NaN
monkey       NaN
leopard      NaN
Name: max_speed, dtype: float64
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame.groupby
"In [121]: result = speeds.copy()

In [122]: result[""cumsum""] = grouped.cumsum()

In [123]: result[""diff""] = grouped.diff()

In [124]: result
Out[124]: 
          class           order  max_speed  cumsum   diff
falcon     bird   Falconiformes      389.0   389.0    NaN
parrot     bird  Psittaciformes       24.0   413.0 -365.0
lion     mammal       Carnivora       80.2    80.2    NaN
monkey   mammal        Primates        NaN     NaN    NaN
leopard  mammal       Carnivora       58.0   138.2    NaN
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame.copy
"In [125]: speeds
Out[125]: 
          class           order  max_speed
falcon     bird   Falconiformes      389.0
parrot     bird  Psittaciformes       24.0
lion     mammal       Carnivora       80.2
monkey   mammal        Primates        NaN
leopard  mammal       Carnivora       58.0

In [126]: grouped = speeds.groupby(""class"")[[""max_speed""]]

In [127]: grouped.transform(""cumsum"")
Out[127]: 
         max_speed
falcon       389.0
parrot       413.0
lion          80.2
monkey         NaN
leopard      138.2

In [128]: grouped.transform(""sum"")
Out[128]: 
         max_speed
falcon       413.0
parrot       413.0
lion         138.2
monkey       138.2
leopard      138.2
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame.groupby
"In [129]: index = pd.date_range(""10/1/1999"", periods=1100)

In [130]: ts = pd.Series(np.random.normal(0.5, 2, 1100), index)

In [131]: ts = ts.rolling(window=100, min_periods=100).mean().dropna()

In [132]: ts.head()
Out[132]: 
2000-01-08    0.779333
2000-01-09    0.778852
2000-01-10    0.786476
2000-01-11    0.782797
2000-01-12    0.798110
Freq: D, dtype: float64

In [133]: ts.tail()
Out[133]: 
2002-09-30    0.660294
2002-10-01    0.631095
2002-10-02    0.673601
2002-10-03    0.709213
2002-10-04    0.719369
Freq: D, dtype: float64

In [134]: transformed = ts.groupby(lambda x: x.year).transform(
   .....:     lambda x: (x - x.mean()) / x.std()
   .....: )
   .....: 
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.date_range pandas.Series pandas.Series.rolling pandas.Series.head pandas.Series.tail pandas.Series.groupby
"# Original Data
In [135]: grouped = ts.groupby(lambda x: x.year)

In [136]: grouped.mean()
Out[136]: 
2000    0.442441
2001    0.526246
2002    0.459365
dtype: float64

In [137]: grouped.std()
Out[137]: 
2000    0.131752
2001    0.210945
2002    0.128753
dtype: float64

# Transformed Data
In [138]: grouped_trans = transformed.groupby(lambda x: x.year)

In [139]: grouped_trans.mean()
Out[139]: 
2000   -4.870756e-16
2001   -1.545187e-16
2002    4.136282e-16
dtype: float64

In [140]: grouped_trans.std()
Out[140]: 
2000    1.0
2001    1.0
2002    1.0
dtype: float64
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.Series.groupby
"In [141]: compare = pd.DataFrame({""Original"": ts, ""Transformed"": transformed})

In [142]: compare.plot()
Out[142]: 
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame pandas.DataFrame.plot
"In [143]: ts.groupby(lambda x: x.year).transform(lambda x: x.max() - x.min())
Out[143]: 
2000-01-08    0.623893
2000-01-09    0.623893
2000-01-10    0.623893
2000-01-11    0.623893
2000-01-12    0.623893
                ...   
2002-09-30    0.558275
2002-10-01    0.558275
2002-10-02    0.558275
2002-10-03    0.558275
2002-10-04    0.558275
Freq: D, Length: 1001, dtype: float64
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.Series.groupby
"In [144]: cols = [""A"", ""B"", ""C""]

In [145]: values = np.random.randn(1000, 3)

In [146]: values[np.random.randint(0, 1000, 100), 0] = np.nan

In [147]: values[np.random.randint(0, 1000, 50), 1] = np.nan

In [148]: values[np.random.randint(0, 1000, 200), 2] = np.nan

In [149]: data_df = pd.DataFrame(values, columns=cols)

In [150]: data_df
Out[150]: 
            A         B         C
0    1.539708 -1.166480  0.533026
1    1.302092 -0.505754       NaN
2   -0.371983  1.104803 -0.651520
3   -1.309622  1.118697 -1.161657
4   -1.924296  0.396437  0.812436
..        ...       ...       ...
995 -0.093110  0.683847 -0.774753
996 -0.185043  1.438572       NaN
997 -0.394469 -0.642343  0.011374
998 -1.174126  1.857148       NaN
999  0.234564  0.517098  0.393534

[1000 rows x 3 columns]

In [151]: countries = np.array([""US"", ""UK"", ""GR"", ""JP""])

In [152]: key = countries[np.random.randint(0, 4, 1000)]

In [153]: grouped = data_df.groupby(key)

# Non-NA count in each group
In [154]: grouped.count()
Out[154]: 
      A    B    C
GR  209  217  189
JP  240  255  217
UK  216  231  193
US  239  250  217

In [155]: transformed = grouped.transform(lambda x: x.fillna(x.mean()))
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame pandas.DataFrame.groupby
"# result = ts.groupby(lambda x: x.year).transform(
#     lambda x: (x - x.mean()) / x.std()
# )
In [162]: grouped = ts.groupby(lambda x: x.year)

In [163]: result = (ts - grouped.transform(""mean"")) / grouped.transform(""std"")

# result = ts.groupby(lambda x: x.year).transform(lambda x: x.max() - x.min())
In [164]: grouped = ts.groupby(lambda x: x.year)

In [165]: result = grouped.transform(""max"") - grouped.transform(""min"")

# grouped = data_df.groupby(key)
# result = grouped.transform(lambda x: x.fillna(x.mean()))
In [166]: grouped = data_df.groupby(key)

In [167]: result = data_df.fillna(grouped.transform(""mean""))
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.Series.groupby pandas.DataFrame.groupby pandas.DataFrame.fillna
"In [168]: df_re = pd.DataFrame({""A"": [1] * 10 + [5] * 10, ""B"": np.arange(20)})

In [169]: df_re
Out[169]: 
    A   B
0   1   0
1   1   1
2   1   2
3   1   3
4   1   4
.. ..  ..
15  5  15
16  5  16
17  5  17
18  5  18
19  5  19

[20 rows x 2 columns]

In [170]: df_re.groupby(""A"").rolling(4).B.mean()
Out[170]: 
A    
1  0      NaN
   1      NaN
   2      NaN
   3      1.5
   4      2.5
         ... 
5  15    13.5
   16    14.5
   17    15.5
   18    16.5
   19    17.5
Name: B, Length: 20, dtype: float64
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame pandas.DataFrame.groupby
"In [171]: df_re.groupby(""A"").expanding().sum()
Out[171]: 
          B
A          
1 0     0.0
  1     1.0
  2     3.0
  3     6.0
  4    10.0
...     ...
5 15   75.0
  16   91.0
  17  108.0
  18  126.0
  19  145.0

[20 rows x 1 columns]
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame.groupby
"In [172]: df_re = pd.DataFrame(
   .....:     {
   .....:         ""date"": pd.date_range(start=""2016-01-01"", periods=4, freq=""W""),
   .....:         ""group"": [1, 1, 2, 2],
   .....:         ""val"": [5, 6, 7, 8],
   .....:     }
   .....: ).set_index(""date"")
   .....: 

In [173]: df_re
Out[173]: 
            group  val
date                  
2016-01-03      1    5
2016-01-10      1    6
2016-01-17      2    7
2016-01-24      2    8

In [174]: df_re.groupby(""group"").resample(""1D"", include_groups=False).ffill()
Out[174]: 
                  val
group date           
1     2016-01-03    5
      2016-01-04    5
      2016-01-05    5
      2016-01-06    5
      2016-01-07    5
...               ...
2     2016-01-20    7
      2016-01-21    7
      2016-01-22    7
      2016-01-23    7
      2016-01-24    8

[16 rows x 1 columns]
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame pandas.date_range pandas.DataFrame.set_index pandas.DataFrame.groupby
"In [175]: speeds
Out[175]: 
          class           order  max_speed
falcon     bird   Falconiformes      389.0
parrot     bird  Psittaciformes       24.0
lion     mammal       Carnivora       80.2
monkey   mammal        Primates        NaN
leopard  mammal       Carnivora       58.0

In [176]: speeds.groupby(""class"").nth(1)
Out[176]: 
         class           order  max_speed
parrot    bird  Psittaciformes       24.0
monkey  mammal        Primates        NaN
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame.groupby
"In [177]: speeds.groupby(""class"")[[""order"", ""max_speed""]].nth(1)
Out[177]: 
                 order  max_speed
parrot  Psittaciformes       24.0
monkey        Primates        NaN
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame.groupby
"In [178]: product_volumes = pd.DataFrame(
   .....:     {
   .....:         ""group"": list(""xxxxyyy""),
   .....:         ""product"": list(""abcdefg""),
   .....:         ""volume"": [10, 30, 20, 15, 40, 10, 20],
   .....:     }
   .....: )
   .....: 

In [179]: product_volumes
Out[179]: 
  group product  volume
0     x       a      10
1     x       b      30
2     x       c      20
3     x       d      15
4     y       e      40
5     y       f      10
6     y       g      20

# Sort by volume to select the largest products first
In [180]: product_volumes = product_volumes.sort_values(""volume"", ascending=False)

In [181]: grouped = product_volumes.groupby(""group"")[""volume""]

In [182]: cumpct = grouped.cumsum() / grouped.transform(""sum"")

In [183]: cumpct
Out[183]: 
4    0.571429
1    0.400000
2    0.666667
6    0.857143
3    0.866667
0    1.000000
5    1.000000
Name: volume, dtype: float64

In [184]: significant_products = product_volumes[cumpct <= 0.9]

In [185]: significant_products.sort_values([""group"", ""product""])
Out[185]: 
  group product  volume
1     x       b      30
2     x       c      20
3     x       d      15
4     y       e      40
6     y       g      20
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame pandas.DataFrame.sort_values pandas.DataFrame.groupby
"In [186]: sf = pd.Series([1, 1, 2, 3, 3, 3])

In [187]: sf.groupby(sf).filter(lambda x: x.sum() > 2)
Out[187]: 
3    3
4    3
5    3
dtype: int64
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.Series pandas.Series.groupby
"In [188]: dff = pd.DataFrame({""A"": np.arange(8), ""B"": list(""aabbbbcc"")})

In [189]: dff.groupby(""B"").filter(lambda x: len(x) > 2)
Out[189]: 
   A  B
2  2  b
3  3  b
4  4  b
5  5  b
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame pandas.DataFrame.groupby
"In [190]: dff.groupby(""B"").filter(lambda x: len(x) > 2, dropna=False)
Out[190]: 
     A    B
0  NaN  NaN
1  NaN  NaN
2  2.0    b
3  3.0    b
4  4.0    b
5  5.0    b
6  NaN  NaN
7  NaN  NaN
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame.groupby
"In [191]: dff[""C""] = np.arange(8)

In [192]: dff.groupby(""B"").filter(lambda x: len(x[""C""]) > 2)
Out[192]: 
   A  B  C
2  2  b  2
3  3  b  3
4  4  b  4
5  5  b  5
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame.groupby
"In [193]: df
Out[193]: 
     A      B         C         D
0  foo    one -0.575247  1.346061
1  bar    one  0.254161  1.511763
2  foo    two -1.143704  1.627081
3  bar  three  0.215897 -0.990582
4  foo    two  1.193555 -0.441652
5  bar    two -0.077118  1.211526
6  foo    one -0.408530  0.268520
7  foo  three -0.862495  0.024580

In [194]: grouped = df.groupby(""A"")

# could also just call .describe()
In [195]: grouped[""C""].apply(lambda x: x.describe())
Out[195]: 
A         
bar  count    3.000000
     mean     0.130980
     std      0.181231
     min     -0.077118
     25%      0.069390
                ...   
foo  min     -1.143704
     25%     -0.862495
     50%     -0.575247
     75%     -0.408530
     max      1.193555
Name: C, Length: 16, dtype: float64
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame.groupby
"In [196]: grouped = df.groupby('A')['C']

In [197]: def f(group):
   .....:     return pd.DataFrame({'original': group,
   .....:                          'demeaned': group - group.mean()})
   .....: 

In [198]: grouped.apply(f)
Out[198]: 
       original  demeaned
A                        
bar 1  0.254161  0.123181
    3  0.215897  0.084917
    5 -0.077118 -0.208098
foo 0 -0.575247 -0.215962
    2 -1.143704 -0.784420
    4  1.193555  1.552839
    6 -0.408530 -0.049245
    7 -0.862495 -0.503211
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame.groupby pandas.DataFrame
"In [199]: def f(x):
   .....:     return pd.Series([x, x ** 2], index=[""x"", ""x^2""])
   .....: 

In [200]: s = pd.Series(np.random.rand(5))

In [201]: s
Out[201]: 
0    0.582898
1    0.098352
2    0.001438
3    0.009420
4    0.815826
dtype: float64

In [202]: s.apply(f)
Out[202]: 
          x       x^2
0  0.582898  0.339770
1  0.098352  0.009673
2  0.001438  0.000002
3  0.009420  0.000089
4  0.815826  0.665572
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.Series pandas.Series.apply
"In [203]: df.groupby(""A"", group_keys=True).apply(lambda x: x, include_groups=False)
Out[203]: 
           B         C         D
A                               
bar 1    one  0.254161  1.511763
    3  three  0.215897 -0.990582
    5    two -0.077118  1.211526
foo 0    one -0.575247  1.346061
    2    two -1.143704  1.627081
    4    two  1.193555 -0.441652
    6    one -0.408530  0.268520
    7  three -0.862495  0.024580
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame.groupby
"In [204]: df.groupby(""A"", group_keys=False).apply(lambda x: x, include_groups=False)
Out[204]: 
       B         C         D
0    one -0.575247  1.346061
1    one  0.254161  1.511763
2    two -1.143704  1.627081
3  three  0.215897 -0.990582
4    two  1.193555 -0.441652
5    two -0.077118  1.211526
6    one -0.408530  0.268520
7  three -0.862495  0.024580
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame.groupby
"In [206]: df.groupby(""A"").std(numeric_only=True)
Out[206]: 
            C         D
A                      
bar  0.181231  1.366330
foo  0.912265  0.884785
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame.groupby
"In [207]: from decimal import Decimal

In [208]: df_dec = pd.DataFrame(
   .....:     {
   .....:         ""id"": [1, 2, 1, 2],
   .....:         ""int_column"": [1, 2, 3, 4],
   .....:         ""dec_column"": [
   .....:             Decimal(""0.50""),
   .....:             Decimal(""0.15""),
   .....:             Decimal(""0.25""),
   .....:             Decimal(""0.40""),
   .....:         ],
   .....:     }
   .....: )
   .....: 

In [209]: df_dec.groupby([""id""])[[""dec_column""]].sum()
Out[209]: 
   dec_column
id           
1        0.75
2        0.55
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame pandas.DataFrame.groupby
"In [210]: pd.Series([1, 1, 1]).groupby(
   .....:     pd.Categorical([""a"", ""a"", ""a""], categories=[""a"", ""b""]), observed=False
   .....: ).count()
   .....: 
Out[210]: 
a    3
b    0
dtype: int64
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.Series pandas.Categorical
"In [211]: pd.Series([1, 1, 1]).groupby(
   .....:     pd.Categorical([""a"", ""a"", ""a""], categories=[""a"", ""b""]), observed=True
   .....: ).count()
   .....: 
Out[211]: 
a    3
dtype: int64
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.Series pandas.Categorical
"In [212]: s = (
   .....:     pd.Series([1, 1, 1])
   .....:     .groupby(pd.Categorical([""a"", ""a"", ""a""], categories=[""a"", ""b""]), observed=True)
   .....:     .count()
   .....: )
   .....: 

In [213]: s.index.dtype
Out[213]: CategoricalDtype(categories=['a', 'b'], ordered=False, categories_dtype=object)
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.Series pandas.Categorical pandas.CategoricalDtype
"In [214]: df = pd.DataFrame({""key"": [1.0, 1.0, np.nan, 2.0, np.nan], ""A"": [1, 2, 3, 4, 5]})

In [215]: df
Out[215]: 
   key  A
0  1.0  1
1  1.0  2
2  NaN  3
3  2.0  4
4  NaN  5

In [216]: df.groupby(""key"", dropna=True).sum()
Out[216]: 
     A
key   
1.0  3
2.0  4

In [217]: df.groupby(""key"", dropna=False).sum()
Out[217]: 
     A
key   
1.0  3
2.0  4
NaN  8
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame pandas.DataFrame.groupby
"In [218]: days = pd.Categorical(
   .....:     values=[""Wed"", ""Mon"", ""Thu"", ""Mon"", ""Wed"", ""Sat""],
   .....:     categories=[""Mon"", ""Tue"", ""Wed"", ""Thu"", ""Fri"", ""Sat"", ""Sun""],
   .....: )
   .....: 

In [219]: data = pd.DataFrame(
   .....:    {
   .....:        ""day"": days,
   .....:        ""workers"": [3, 4, 1, 4, 2, 2],
   .....:    }
   .....: )
   .....: 

In [220]: data
Out[220]: 
   day  workers
0  Wed        3
1  Mon        4
2  Thu        1
3  Mon        4
4  Wed        2
5  Sat        2

In [221]: data.groupby(""day"", observed=False, sort=True).sum()
Out[221]: 
     workers
day         
Mon        8
Tue        0
Wed        5
Thu        1
Fri        0
Sat        2
Sun        0

In [222]: data.groupby(""day"", observed=False, sort=False).sum()
Out[222]: 
     workers
day         
Wed        5
Mon        8
Thu        1
Sat        2
Tue        0
Fri        0
Sun        0
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.Categorical pandas.DataFrame pandas.DataFrame.groupby
"In [223]: import datetime

In [224]: df = pd.DataFrame(
   .....:     {
   .....:         ""Branch"": ""A A A A A A A B"".split(),
   .....:         ""Buyer"": ""Carl Mark Carl Carl Joe Joe Joe Carl"".split(),
   .....:         ""Quantity"": [1, 3, 5, 1, 8, 1, 9, 3],
   .....:         ""Date"": [
   .....:             datetime.datetime(2013, 1, 1, 13, 0),
   .....:             datetime.datetime(2013, 1, 1, 13, 5),
   .....:             datetime.datetime(2013, 10, 1, 20, 0),
   .....:             datetime.datetime(2013, 10, 2, 10, 0),
   .....:             datetime.datetime(2013, 10, 1, 20, 0),
   .....:             datetime.datetime(2013, 10, 2, 10, 0),
   .....:             datetime.datetime(2013, 12, 2, 12, 0),
   .....:             datetime.datetime(2013, 12, 2, 14, 0),
   .....:         ],
   .....:     }
   .....: )
   .....: 

In [225]: df
Out[225]: 
  Branch Buyer  Quantity                Date
0      A  Carl         1 2013-01-01 13:00:00
1      A  Mark         3 2013-01-01 13:05:00
2      A  Carl         5 2013-10-01 20:00:00
3      A  Carl         1 2013-10-02 10:00:00
4      A   Joe         8 2013-10-01 20:00:00
5      A   Joe         1 2013-10-02 10:00:00
6      A   Joe         9 2013-12-02 12:00:00
7      B  Carl         3 2013-12-02 14:00:00
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame pandas.Series.str.split
"In [226]: df.groupby([pd.Grouper(freq=""1ME"", key=""Date""), ""Buyer""])[[""Quantity""]].sum()
Out[226]: 
                  Quantity
Date       Buyer          
2013-01-31 Carl          1
           Mark          3
2013-10-31 Carl          6
           Joe           9
2013-12-31 Carl          3
           Joe           9
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame.groupby pandas.Grouper
"In [227]: df = df.set_index(""Date"")

In [228]: df[""Date""] = df.index + pd.offsets.MonthEnd(2)

In [229]: df.groupby([pd.Grouper(freq=""6ME"", key=""Date""), ""Buyer""])[[""Quantity""]].sum()
Out[229]: 
                  Quantity
Date       Buyer          
2013-02-28 Carl          1
           Mark          3
2014-02-28 Carl          9
           Joe          18

In [230]: df.groupby([pd.Grouper(freq=""6ME"", level=""Date""), ""Buyer""])[[""Quantity""]].sum()
Out[230]: 
                  Quantity
Date       Buyer          
2013-01-31 Carl          1
           Mark          3
2014-01-31 Carl          9
           Joe          18
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame.set_index pandas.DataFrame.groupby pandas.Grouper
"In [231]: df = pd.DataFrame([[1, 2], [1, 4], [5, 6]], columns=[""A"", ""B""])

In [232]: df
Out[232]: 
   A  B
0  1  2
1  1  4
2  5  6

In [233]: g = df.groupby(""A"")

In [234]: g.head(1)
Out[234]: 
   A  B
0  1  2
2  5  6

In [235]: g.tail(1)
Out[235]: 
   A  B
1  1  4
2  5  6
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame pandas.DataFrame.groupby
"In [236]: df = pd.DataFrame([[1, np.nan], [1, 4], [5, 6]], columns=[""A"", ""B""])

In [237]: g = df.groupby(""A"")

In [238]: g.nth(0)
Out[238]: 
   A    B
0  1  NaN
2  5  6.0

In [239]: g.nth(-1)
Out[239]: 
   A    B
1  1  4.0
2  5  6.0

In [240]: g.nth(1)
Out[240]: 
   A    B
1  1  4.0
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame pandas.DataFrame.groupby
"In [247]: business_dates = pd.date_range(start=""4/1/2014"", end=""6/30/2014"", freq=""B"")

In [248]: df = pd.DataFrame(1, index=business_dates, columns=[""a"", ""b""])

# get the first, 4th, and last date index for each month
In [249]: df.groupby([df.index.year, df.index.month]).nth([0, 3, -1])
Out[249]: 
            a  b
2014-04-01  1  1
2014-04-04  1  1
2014-04-30  1  1
2014-05-01  1  1
2014-05-06  1  1
2014-05-30  1  1
2014-06-02  1  1
2014-06-05  1  1
2014-06-30  1  1
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.date_range pandas.DataFrame pandas.DataFrame.groupby
"In [250]: df.groupby([df.index.year, df.index.month]).nth[1:]
Out[250]: 
            a  b
2014-04-02  1  1
2014-04-03  1  1
2014-04-04  1  1
2014-04-07  1  1
2014-04-08  1  1
...        .. ..
2014-06-24  1  1
2014-06-25  1  1
2014-06-26  1  1
2014-06-27  1  1
2014-06-30  1  1

[62 rows x 2 columns]

In [251]: df.groupby([df.index.year, df.index.month]).nth[1:, :-1]
Out[251]: 
            a  b
2014-04-01  1  1
2014-04-02  1  1
2014-04-03  1  1
2014-04-04  1  1
2014-04-07  1  1
...        .. ..
2014-06-24  1  1
2014-06-25  1  1
2014-06-26  1  1
2014-06-27  1  1
2014-06-30  1  1

[65 rows x 2 columns]
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame.groupby
"In [252]: dfg = pd.DataFrame(list(""aaabba""), columns=[""A""])

In [253]: dfg
Out[253]: 
   A
0  a
1  a
2  a
3  b
4  b
5  a

In [254]: dfg.groupby(""A"").cumcount()
Out[254]: 
0    0
1    1
2    2
3    0
4    1
5    3
dtype: int64

In [255]: dfg.groupby(""A"").cumcount(ascending=False)
Out[255]: 
0    3
1    2
2    1
3    1
4    0
5    0
dtype: int64
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame pandas.DataFrame.groupby
"In [256]: dfg = pd.DataFrame(list(""aaabba""), columns=[""A""])

In [257]: dfg
Out[257]: 
   A
0  a
1  a
2  a
3  b
4  b
5  a

In [258]: dfg.groupby(""A"").ngroup()
Out[258]: 
0    0
1    0
2    0
3    1
4    1
5    0
dtype: int64

In [259]: dfg.groupby(""A"").ngroup(ascending=False)
Out[259]: 
0    1
1    1
2    1
3    0
4    0
5    1
dtype: int64
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame pandas.DataFrame.groupby
"In [260]: np.random.seed(1234)

In [261]: df = pd.DataFrame(np.random.randn(50, 2))

In [262]: df[""g""] = np.random.choice([""A"", ""B""], size=50)

In [263]: df.loc[df[""g""] == ""B"", 1] += 3
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame
"In [264]: df.groupby(""g"").boxplot()
Out[264]: 
A         Axes(0.1,0.15;0.363636x0.75)
B    Axes(0.536364,0.15;0.363636x0.75)
dtype: object
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame.groupby
"In [265]: n = 1000

In [266]: df = pd.DataFrame(
   .....:     {
   .....:         ""Store"": np.random.choice([""Store_1"", ""Store_2""], n),
   .....:         ""Product"": np.random.choice([""Product_1"", ""Product_2""], n),
   .....:         ""Revenue"": (np.random.random(n) * 50 + 10).round(2),
   .....:         ""Quantity"": np.random.randint(1, 10, size=n),
   .....:     }
   .....: )
   .....: 

In [267]: df.head(2)
Out[267]: 
     Store    Product  Revenue  Quantity
0  Store_2  Product_1    26.12         1
1  Store_2  Product_1    28.86         1
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame pandas.DataFrame.head
"In [268]: (
   .....:     df.groupby([""Store"", ""Product""])
   .....:     .pipe(lambda grp: grp.Revenue.sum() / grp.Quantity.sum())
   .....:     .unstack()
   .....:     .round(2)
   .....: )
   .....: 
Out[268]: 
Product  Product_1  Product_2
Store                        
Store_1       6.82       7.05
Store_2       6.30       6.64
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame.groupby
"In [269]: def mean(groupby):
   .....:     return groupby.mean()
   .....: 

In [270]: df.groupby([""Store"", ""Product""]).pipe(mean)
Out[270]: 
                     Revenue  Quantity
Store   Product                       
Store_1 Product_1  34.622727  5.075758
        Product_2  35.482815  5.029630
Store_2 Product_1  32.972837  5.237589
        Product_2  34.684360  5.224000
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame.groupby
"In [271]: dfg = pd.DataFrame({""A"": [1, 1, 2, 3, 2], ""B"": list(""aaaba"")})

In [272]: dfg
Out[272]: 
   A  B
0  1  a
1  1  a
2  2  a
3  3  b
4  2  a

In [273]: dfg.groupby([""A"", ""B""]).ngroup()
Out[273]: 
0    0
1    0
2    1
3    2
4    1
dtype: int64

In [274]: dfg.groupby([""A"", [0, 0, 0, 1, 1]]).ngroup()
Out[274]: 
0    0
1    0
2    1
3    3
4    2
dtype: int64
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame pandas.DataFrame.groupby
"In [275]: df = pd.DataFrame(np.random.randn(10, 2))

In [276]: df
Out[276]: 
          0         1
0 -0.793893  0.321153
1  0.342250  1.618906
2 -0.975807  1.918201
3 -0.810847 -1.405919
4 -1.977759  0.461659
5  0.730057 -1.316938
6 -0.751328  0.528290
7 -0.257759 -1.081009
8  0.505895 -1.701948
9 -1.006349  0.020208

In [277]: df.index // 5
Out[277]: Index([0, 0, 0, 0, 0, 1, 1, 1, 1, 1], dtype='int64')

In [278]: df.groupby(df.index // 5).std()
Out[278]: 
          0         1
0  0.823647  1.312912
1  0.760109  0.942941
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame pandas.Index pandas.DataFrame.groupby
"In [279]: df = pd.DataFrame(
   .....:     {
   .....:         ""a"": [0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2],
   .....:         ""b"": [0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1],
   .....:         ""c"": [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0],
   .....:         ""d"": [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1],
   .....:     }
   .....: )
   .....: 

In [280]: def compute_metrics(x):
   .....:     result = {""b_sum"": x[""b""].sum(), ""c_mean"": x[""c""].mean()}
   .....:     return pd.Series(result, name=""metrics"")
   .....: 

In [281]: result = df.groupby(""a"").apply(compute_metrics, include_groups=False)

In [282]: result
Out[282]: 
metrics  b_sum  c_mean
a                     
0          2.0     0.5
1          2.0     0.5
2          2.0     0.5

In [283]: result.stack(future_stack=True)
Out[283]: 
a  metrics
0  b_sum      2.0
   c_mean     0.5
1  b_sum      2.0
   c_mean     0.5
2  b_sum      2.0
   c_mean     0.5
dtype: float64
",https://pandas.pydata.org/docs/user_guide/groupby.html, pandas.DataFrame pandas.Series pandas.DataFrame.groupby pandas.DataFrame.stack
"In [1]: s = pd.Series([""a"", ""b"", ""c"", ""a""], dtype=""category"")

In [2]: s
Out[2]: 
0    a
1    b
2    c
3    a
dtype: category
Categories (3, object): ['a', 'b', 'c']
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.Series
"In [3]: df = pd.DataFrame({""A"": [""a"", ""b"", ""c"", ""a""]})

In [4]: df[""B""] = df[""A""].astype(""category"")

In [5]: df
Out[5]: 
   A  B
0  a  a
1  b  b
2  c  c
3  a  a
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.DataFrame
"In [6]: df = pd.DataFrame({""value"": np.random.randint(0, 100, 20)})

In [7]: labels = [""{0} - {1}"".format(i, i + 9) for i in range(0, 100, 10)]

In [8]: df[""group""] = pd.cut(df.value, range(0, 105, 10), right=False, labels=labels)

In [9]: df.head(10)
Out[9]: 
   value    group
0     65  60 - 69
1     49  40 - 49
2     56  50 - 59
3     43  40 - 49
4     43  40 - 49
5     91  90 - 99
6     32  30 - 39
7     87  80 - 89
8     36  30 - 39
9      8    0 - 9
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.DataFrame pandas.io.formats.style.Styler.format pandas.cut pandas.DataFrame.head
"In [10]: raw_cat = pd.Categorical(
   ....:     [""a"", ""b"", ""c"", ""a""], categories=[""b"", ""c"", ""d""], ordered=False
   ....: )
   ....: 

In [11]: s = pd.Series(raw_cat)

In [12]: s
Out[12]: 
0    NaN
1      b
2      c
3    NaN
dtype: category
Categories (3, object): ['b', 'c', 'd']

In [13]: df = pd.DataFrame({""A"": [""a"", ""b"", ""c"", ""a""]})

In [14]: df[""B""] = raw_cat

In [15]: df
Out[15]: 
   A    B
0  a  NaN
1  b    b
2  c    c
3  a  NaN
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.Categorical pandas.Series pandas.DataFrame
"In [17]: df = pd.DataFrame({""A"": list(""abca""), ""B"": list(""bccd"")}, dtype=""category"")

In [18]: df.dtypes
Out[18]: 
A    category
B    category
dtype: object
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.DataFrame
"In [21]: df = pd.DataFrame({""A"": list(""abca""), ""B"": list(""bccd"")})

In [22]: df_cat = df.astype(""category"")

In [23]: df_cat.dtypes
Out[23]: 
A    category
B    category
dtype: object
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.DataFrame pandas.DataFrame.astype
"In [26]: from pandas.api.types import CategoricalDtype

In [27]: s = pd.Series([""a"", ""b"", ""c"", ""a""])

In [28]: cat_type = CategoricalDtype(categories=[""b"", ""c"", ""d""], ordered=True)

In [29]: s_cat = s.astype(cat_type)

In [30]: s_cat
Out[30]: 
0    NaN
1      b
2      c
3    NaN
dtype: category
Categories (3, object): ['b' < 'c' < 'd']
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.Series pandas.CategoricalDtype pandas.Series.astype
"In [31]: from pandas.api.types import CategoricalDtype

In [32]: df = pd.DataFrame({""A"": list(""abca""), ""B"": list(""bccd"")})

In [33]: cat_type = CategoricalDtype(categories=list(""abcd""), ordered=True)

In [34]: df_cat = df.astype(cat_type)

In [35]: df_cat[""A""]
Out[35]: 
0    a
1    b
2    c
3    a
Name: A, dtype: category
Categories (4, object): ['a' < 'b' < 'c' < 'd']

In [36]: df_cat[""B""]
Out[36]: 
0    b
1    c
2    c
3    d
Name: B, dtype: category
Categories (4, object): ['a' < 'b' < 'c' < 'd']
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.DataFrame pandas.CategoricalDtype pandas.DataFrame.astype
"In [37]: splitter = np.random.choice([0, 1], 5, p=[0.5, 0.5])

In [38]: s = pd.Series(pd.Categorical.from_codes(splitter, categories=[""train"", ""test""]))
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.Series pandas.Categorical.from_codes
"In [39]: s = pd.Series([""a"", ""b"", ""c"", ""a""])

In [40]: s
Out[40]: 
0    a
1    b
2    c
3    a
dtype: object

In [41]: s2 = s.astype(""category"")

In [42]: s2
Out[42]: 
0    a
1    b
2    c
3    a
dtype: category
Categories (3, object): ['a', 'b', 'c']

In [43]: s2.astype(str)
Out[43]: 
0    a
1    b
2    c
3    a
dtype: object

In [44]: np.asarray(s2)
Out[44]: array(['a', 'b', 'c', 'a'], dtype=object)
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.Series pandas.Series.astype pandas.Series.astype pandas.array
"In [45]: from pandas.api.types import CategoricalDtype

In [46]: CategoricalDtype([""a"", ""b"", ""c""])
Out[46]: CategoricalDtype(categories=['a', 'b', 'c'], ordered=False, categories_dtype=object)

In [47]: CategoricalDtype([""a"", ""b"", ""c""], ordered=True)
Out[47]: CategoricalDtype(categories=['a', 'b', 'c'], ordered=True, categories_dtype=object)

In [48]: CategoricalDtype()
Out[48]: CategoricalDtype(categories=None, ordered=False, categories_dtype=None)
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.CategoricalDtype
"In [49]: c1 = CategoricalDtype([""a"", ""b"", ""c""], ordered=False)

# Equal, since order is not considered when ordered=False
In [50]: c1 == CategoricalDtype([""b"", ""c"", ""a""], ordered=False)
Out[50]: True

# Unequal, since the second CategoricalDtype is ordered
In [51]: c1 == CategoricalDtype([""a"", ""b"", ""c""], ordered=True)
Out[51]: False
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.CategoricalDtype
"In [53]: cat = pd.Categorical([""a"", ""c"", ""c"", np.nan], categories=[""b"", ""a"", ""c""])

In [54]: df = pd.DataFrame({""cat"": cat, ""s"": [""a"", ""c"", ""c"", np.nan]})

In [55]: df.describe()
Out[55]: 
       cat  s
count    3  3
unique   2  2
top      c  c
freq     2  2

In [56]: df[""cat""].describe()
Out[56]: 
count     3
unique    2
top       c
freq      2
Name: cat, dtype: object
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.Categorical pandas.DataFrame pandas.DataFrame.describe
"In [57]: s = pd.Series([""a"", ""b"", ""c"", ""a""], dtype=""category"")

In [58]: s.cat.categories
Out[58]: Index(['a', 'b', 'c'], dtype='object')

In [59]: s.cat.ordered
Out[59]: False
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.Series pandas.Index
"In [60]: s = pd.Series(pd.Categorical([""a"", ""b"", ""c"", ""a""], categories=[""c"", ""b"", ""a""]))

In [61]: s.cat.categories
Out[61]: Index(['c', 'b', 'a'], dtype='object')

In [62]: s.cat.ordered
Out[62]: False
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.Series pandas.Categorical pandas.Index
"In [63]: s = pd.Series(list(""babc"")).astype(CategoricalDtype(list(""abcd"")))

In [64]: s
Out[64]: 
0    b
1    a
2    b
3    c
dtype: category
Categories (4, object): ['a', 'b', 'c', 'd']

# categories
In [65]: s.cat.categories
Out[65]: Index(['a', 'b', 'c', 'd'], dtype='object')

# uniques
In [66]: s.unique()
Out[66]: 
['b', 'a', 'c']
Categories (4, object): ['a', 'b', 'c', 'd']
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.Series pandas.CategoricalDtype pandas.Index pandas.Series.unique
"In [67]: s = pd.Series([""a"", ""b"", ""c"", ""a""], dtype=""category"")

In [68]: s
Out[68]: 
0    a
1    b
2    c
3    a
dtype: category
Categories (3, object): ['a', 'b', 'c']

In [69]: new_categories = [""Group %s"" % g for g in s.cat.categories]

In [70]: s = s.cat.rename_categories(new_categories)

In [71]: s
Out[71]: 
0    Group a
1    Group b
2    Group c
3    Group a
dtype: category
Categories (3, object): ['Group a', 'Group b', 'Group c']

# You can also pass a dict-like object to map the renaming
In [72]: s = s.cat.rename_categories({1: ""x"", 2: ""y"", 3: ""z""})

In [73]: s
Out[73]: 
0    Group a
1    Group b
2    Group c
3    Group a
dtype: category
Categories (3, object): ['Group a', 'Group b', 'Group c']
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.Series pandas.Series.cat.rename_categories
"In [74]: try:
   ....:     s = s.cat.rename_categories([1, 1, 1])
   ....: except ValueError as e:
   ....:     print(""ValueError:"", str(e))
   ....: 
ValueError: Categorical categories must be unique
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.Series.cat.rename_categories
"In [75]: try:
   ....:     s = s.cat.rename_categories([1, 2, np.nan])
   ....: except ValueError as e:
   ....:     print(""ValueError:"", str(e))
   ....: 
ValueError: Categorical categories cannot be null
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.Series.cat.rename_categories
"In [76]: s = s.cat.add_categories([4])

In [77]: s.cat.categories
Out[77]: Index(['Group a', 'Group b', 'Group c', 4], dtype='object')

In [78]: s
Out[78]: 
0    Group a
1    Group b
2    Group c
3    Group a
dtype: category
Categories (4, object): ['Group a', 'Group b', 'Group c', 4]
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.Series.cat.add_categories pandas.Index
"In [79]: s = s.cat.remove_categories([4])

In [80]: s
Out[80]: 
0    Group a
1    Group b
2    Group c
3    Group a
dtype: category
Categories (3, object): ['Group a', 'Group b', 'Group c']
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.Series.cat.remove_categories
"In [81]: s = pd.Series(pd.Categorical([""a"", ""b"", ""a""], categories=[""a"", ""b"", ""c"", ""d""]))

In [82]: s
Out[82]: 
0    a
1    b
2    a
dtype: category
Categories (4, object): ['a', 'b', 'c', 'd']

In [83]: s.cat.remove_unused_categories()
Out[83]: 
0    a
1    b
2    a
dtype: category
Categories (2, object): ['a', 'b']
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.Series pandas.Categorical pandas.Series.cat.remove_unused_categories
"In [84]: s = pd.Series([""one"", ""two"", ""four"", ""-""], dtype=""category"")

In [85]: s
Out[85]: 
0     one
1     two
2    four
3       -
dtype: category
Categories (4, object): ['-', 'four', 'one', 'two']

In [86]: s = s.cat.set_categories([""one"", ""two"", ""three"", ""four""])

In [87]: s
Out[87]: 
0     one
1     two
2    four
3     NaN
dtype: category
Categories (4, object): ['one', 'two', 'three', 'four']
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.Series pandas.Series.cat.set_categories
"In [88]: s = pd.Series(pd.Categorical([""a"", ""b"", ""c"", ""a""], ordered=False))

In [89]: s = s.sort_values()

In [90]: s = pd.Series([""a"", ""b"", ""c"", ""a""]).astype(CategoricalDtype(ordered=True))

In [91]: s = s.sort_values()

In [92]: s
Out[92]: 
0    a
3    a
1    b
2    c
dtype: category
Categories (3, object): ['a' < 'b' < 'c']

In [93]: s.min(), s.max()
Out[93]: ('a', 'c')
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.Series pandas.Categorical pandas.Series.sort_values pandas.CategoricalDtype pandas.Series.min pandas.Series.max
"In [94]: s.cat.as_ordered()
Out[94]: 
0    a
3    a
1    b
2    c
dtype: category
Categories (3, object): ['a' < 'b' < 'c']

In [95]: s.cat.as_unordered()
Out[95]: 
0    a
3    a
1    b
2    c
dtype: category
Categories (3, object): ['a', 'b', 'c']
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.Series.cat.as_ordered pandas.Series.cat.as_unordered
"In [96]: s = pd.Series([1, 2, 3, 1], dtype=""category"")

In [97]: s = s.cat.set_categories([2, 3, 1], ordered=True)

In [98]: s
Out[98]: 
0    1
1    2
2    3
3    1
dtype: category
Categories (3, int64): [2 < 3 < 1]

In [99]: s = s.sort_values()

In [100]: s
Out[100]: 
1    2
2    3
0    1
3    1
dtype: category
Categories (3, int64): [2 < 3 < 1]

In [101]: s.min(), s.max()
Out[101]: (2, 1)
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.Series pandas.Series.cat.set_categories pandas.Series.sort_values pandas.Series.min pandas.Series.max
"In [102]: s = pd.Series([1, 2, 3, 1], dtype=""category"")

In [103]: s = s.cat.reorder_categories([2, 3, 1], ordered=True)

In [104]: s
Out[104]: 
0    1
1    2
2    3
3    1
dtype: category
Categories (3, int64): [2 < 3 < 1]

In [105]: s = s.sort_values()

In [106]: s
Out[106]: 
1    2
2    3
0    1
3    1
dtype: category
Categories (3, int64): [2 < 3 < 1]

In [107]: s.min(), s.max()
Out[107]: (2, 1)
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.Series pandas.Series.cat.reorder_categories pandas.Series.sort_values pandas.Series.min pandas.Series.max
"In [108]: dfs = pd.DataFrame(
   .....:     {
   .....:         ""A"": pd.Categorical(
   .....:             list(""bbeebbaa""),
   .....:             categories=[""e"", ""a"", ""b""],
   .....:             ordered=True,
   .....:         ),
   .....:         ""B"": [1, 2, 1, 2, 2, 1, 2, 1],
   .....:     }
   .....: )
   .....: 

In [109]: dfs.sort_values(by=[""A"", ""B""])
Out[109]: 
   A  B
2  e  1
3  e  2
7  a  1
6  a  2
0  b  1
5  b  1
1  b  2
4  b  2
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.DataFrame pandas.Categorical pandas.DataFrame.sort_values
"In [110]: dfs[""A""] = dfs[""A""].cat.reorder_categories([""a"", ""b"", ""e""])

In [111]: dfs.sort_values(by=[""A"", ""B""])
Out[111]: 
   A  B
7  a  1
6  a  2
0  b  1
5  b  1
1  b  2
4  b  2
2  e  1
3  e  2
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.DataFrame.sort_values
"In [112]: cat = pd.Series([1, 2, 3]).astype(CategoricalDtype([3, 2, 1], ordered=True))

In [113]: cat_base = pd.Series([2, 2, 2]).astype(CategoricalDtype([3, 2, 1], ordered=True))

In [114]: cat_base2 = pd.Series([2, 2, 2]).astype(CategoricalDtype(ordered=True))

In [115]: cat
Out[115]: 
0    1
1    2
2    3
dtype: category
Categories (3, int64): [3 < 2 < 1]

In [116]: cat_base
Out[116]: 
0    2
1    2
2    2
dtype: category
Categories (3, int64): [3 < 2 < 1]

In [117]: cat_base2
Out[117]: 
0    2
1    2
2    2
dtype: category
Categories (1, int64): [2]
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.Series pandas.CategoricalDtype
"In [124]: base = np.array([1, 2, 3])

In [125]: try:
   .....:     cat > base
   .....: except TypeError as e:
   .....:     print(""TypeError:"", str(e))
   .....: 
TypeError: Cannot compare a Categorical for op __gt__ with type .
If you want to compare values, use 'np.asarray(cat)  other'.

In [126]: np.asarray(cat) > base
Out[126]: array([False, False, False])
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.array
"In [127]: c1 = pd.Categorical([""a"", ""b""], categories=[""a"", ""b""], ordered=False)

In [128]: c2 = pd.Categorical([""a"", ""b""], categories=[""b"", ""a""], ordered=False)

In [129]: c1 == c2
Out[129]: array([ True,  True])
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.Categorical pandas.array
"In [130]: s = pd.Series(pd.Categorical([""a"", ""b"", ""c"", ""c""], categories=[""c"", ""a"", ""b"", ""d""]))

In [131]: s.value_counts()
Out[131]: 
c    2
a    1
b    1
d    0
Name: count, dtype: int64
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.Series pandas.Categorical pandas.Series.value_counts
"In [132]: columns = pd.Categorical(
   .....:     [""One"", ""One"", ""Two""], categories=[""One"", ""Two"", ""Three""], ordered=True
   .....: )
   .....: 

In [133]: df = pd.DataFrame(
   .....:     data=[[1, 2, 3], [4, 5, 6]],
   .....:     columns=pd.MultiIndex.from_arrays([[""A"", ""B"", ""B""], columns]),
   .....: ).T
   .....: 

In [134]: df.groupby(level=1, observed=False).sum()
Out[134]: 
       0  1
One    3  9
Two    3  6
Three  0  0
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.Categorical pandas.DataFrame pandas.MultiIndex.from_arrays pandas.DataFrame.groupby
"In [135]: cats = pd.Categorical(
   .....:     [""a"", ""b"", ""b"", ""b"", ""c"", ""c"", ""c""], categories=[""a"", ""b"", ""c"", ""d""]
   .....: )
   .....: 

In [136]: df = pd.DataFrame({""cats"": cats, ""values"": [1, 2, 2, 2, 3, 4, 5]})

In [137]: df.groupby(""cats"", observed=False).mean()
Out[137]: 
      values
cats        
a        1.0
b        2.0
c        4.0
d        NaN

In [138]: cats2 = pd.Categorical([""a"", ""a"", ""b"", ""b""], categories=[""a"", ""b"", ""c""])

In [139]: df2 = pd.DataFrame(
   .....:     {
   .....:         ""cats"": cats2,
   .....:         ""B"": [""c"", ""d"", ""c"", ""d""],
   .....:         ""values"": [1, 2, 3, 4],
   .....:     }
   .....: )
   .....: 

In [140]: df2.groupby([""cats"", ""B""], observed=False).mean()
Out[140]: 
        values
cats B        
a    c     1.0
     d     2.0
b    c     3.0
     d     4.0
c    c     NaN
     d     NaN
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.Categorical pandas.DataFrame pandas.DataFrame.groupby pandas.DataFrame.groupby
"In [141]: raw_cat = pd.Categorical([""a"", ""a"", ""b"", ""b""], categories=[""a"", ""b"", ""c""])

In [142]: df = pd.DataFrame({""A"": raw_cat, ""B"": [""c"", ""d"", ""c"", ""d""], ""values"": [1, 2, 3, 4]})

In [143]: pd.pivot_table(df, values=""values"", index=[""A"", ""B""], observed=False)
Out[143]: 
     values
A B        
a c     1.0
  d     2.0
b c     3.0
  d     4.0
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.Categorical pandas.DataFrame pandas.pivot_table
"In [144]: idx = pd.Index([""h"", ""i"", ""j"", ""k"", ""l"", ""m"", ""n""])

In [145]: cats = pd.Series([""a"", ""b"", ""b"", ""b"", ""c"", ""c"", ""c""], dtype=""category"", index=idx)

In [146]: values = [1, 2, 2, 2, 3, 4, 5]

In [147]: df = pd.DataFrame({""cats"": cats, ""values"": values}, index=idx)

In [148]: df.iloc[2:4, :]
Out[148]: 
  cats  values
j    b       2
k    b       2

In [149]: df.iloc[2:4, :].dtypes
Out[149]: 
cats      category
values       int64
dtype: object

In [150]: df.loc[""h"":""j"", ""cats""]
Out[150]: 
h    a
i    b
j    b
Name: cats, dtype: category
Categories (3, object): ['a', 'b', 'c']

In [151]: df[df[""cats""] == ""b""]
Out[151]: 
  cats  values
i    b       2
j    b       2
k    b       2
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.Index pandas.Series pandas.DataFrame
"In [157]: str_s = pd.Series(list(""aabb""))

In [158]: str_cat = str_s.astype(""category"")

In [159]: str_cat
Out[159]: 
0    a
1    a
2    b
3    b
dtype: category
Categories (2, object): ['a', 'b']

In [160]: str_cat.str.contains(""a"")
Out[160]: 
0     True
1     True
2    False
3    False
dtype: bool

In [161]: date_s = pd.Series(pd.date_range(""1/1/2015"", periods=5))

In [162]: date_cat = date_s.astype(""category"")

In [163]: date_cat
Out[163]: 
0   2015-01-01
1   2015-01-02
2   2015-01-03
3   2015-01-04
4   2015-01-05
dtype: category
Categories (5, datetime64[ns]): [2015-01-01, 2015-01-02, 2015-01-03, 2015-01-04, 2015-01-05]

In [164]: date_cat.dt.day
Out[164]: 
0    1
1    2
2    3
3    4
4    5
dtype: int32
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.Series pandas.Series.astype pandas.date_range pandas.Series.astype
"In [165]: ret_s = str_s.str.contains(""a"")

In [166]: ret_cat = str_cat.str.contains(""a"")

In [167]: ret_s.dtype == ret_cat.dtype
Out[167]: True

In [168]: ret_s == ret_cat
Out[168]: 
0    True
1    True
2    True
3    True
dtype: bool
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.Series.str.contains
"In [169]: idx = pd.Index([""h"", ""i"", ""j"", ""k"", ""l"", ""m"", ""n""])

In [170]: cats = pd.Categorical([""a"", ""a"", ""a"", ""a"", ""a"", ""a"", ""a""], categories=[""a"", ""b""])

In [171]: values = [1, 1, 1, 1, 1, 1, 1]

In [172]: df = pd.DataFrame({""cats"": cats, ""values"": values}, index=idx)

In [173]: df.iloc[2:4, :] = [[""b"", 2], [""b"", 2]]

In [174]: df
Out[174]: 
  cats  values
h    a       1
i    a       1
j    b       2
k    b       2
l    a       1
m    a       1
n    a       1

In [175]: try:
   .....:     df.iloc[2:4, :] = [[""c"", 3], [""c"", 3]]
   .....: except TypeError as e:
   .....:     print(""TypeError:"", str(e))
   .....: 
TypeError: Cannot setitem on a Categorical with a new category, set the categories first
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.Index pandas.Categorical pandas.DataFrame
"In [176]: df.loc[""j"":""k"", ""cats""] = pd.Categorical([""a"", ""a""], categories=[""a"", ""b""])

In [177]: df
Out[177]: 
  cats  values
h    a       1
i    a       1
j    a       2
k    a       2
l    a       1
m    a       1
n    a       1

In [178]: try:
   .....:     df.loc[""j"":""k"", ""cats""] = pd.Categorical([""b"", ""b""], categories=[""a"", ""b"", ""c""])
   .....: except TypeError as e:
   .....:     print(""TypeError:"", str(e))
   .....: 
TypeError: Cannot set a Categorical with another, without identical categories
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.Categorical
"In [179]: df = pd.DataFrame({""a"": [1, 1, 1, 1, 1], ""b"": [""a"", ""a"", ""a"", ""a"", ""a""]})

In [180]: df.loc[1:2, ""a""] = pd.Categorical([""b"", ""b""], categories=[""a"", ""b""])

In [181]: df.loc[2:3, ""b""] = pd.Categorical([""b"", ""b""], categories=[""a"", ""b""])

In [182]: df
Out[182]: 
   a  b
0  1  a
1  b  a
2  b  b
3  1  b
4  1  a

In [183]: df.dtypes
Out[183]: 
a    object
b    object
dtype: object
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.DataFrame pandas.Categorical
"In [184]: from pandas.api.types import union_categoricals

# same categories
In [185]: s1 = pd.Series([""a"", ""b""], dtype=""category"")

In [186]: s2 = pd.Series([""a"", ""b"", ""a""], dtype=""category"")

In [187]: pd.concat([s1, s2])
Out[187]: 
0    a
1    b
0    a
1    b
2    a
dtype: category
Categories (2, object): ['a', 'b']

# different categories
In [188]: s3 = pd.Series([""b"", ""c""], dtype=""category"")

In [189]: pd.concat([s1, s3])
Out[189]: 
0    a
1    b
0    b
1    c
dtype: object

# Output dtype is inferred based on categories values
In [190]: int_cats = pd.Series([1, 2], dtype=""category"")

In [191]: float_cats = pd.Series([3.0, 4.0], dtype=""category"")

In [192]: pd.concat([int_cats, float_cats])
Out[192]: 
0    1.0
1    2.0
0    3.0
1    4.0
dtype: float64

In [193]: pd.concat([s1, s3]).astype(""category"")
Out[193]: 
0    a
1    b
0    b
1    c
dtype: category
Categories (3, object): ['a', 'b', 'c']

In [194]: union_categoricals([s1.array, s3.array])
Out[194]: 
['a', 'b', 'b', 'c']
Categories (3, object): ['a', 'b', 'c']
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.Series pandas.concat pandas.api.types.union_categoricals
"In [195]: from pandas.api.types import union_categoricals

In [196]: a = pd.Categorical([""b"", ""c""])

In [197]: b = pd.Categorical([""a"", ""b""])

In [198]: union_categoricals([a, b])
Out[198]: 
['b', 'c', 'a', 'b']
Categories (3, object): ['b', 'c', 'a']
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.Categorical pandas.api.types.union_categoricals
"In [199]: union_categoricals([a, b], sort_categories=True)
Out[199]: 
['b', 'c', 'a', 'b']
Categories (3, object): ['a', 'b', 'c']
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.api.types.union_categoricals
"In [200]: a = pd.Categorical([""a"", ""b""], ordered=True)

In [201]: b = pd.Categorical([""a"", ""b"", ""a""], ordered=True)

In [202]: union_categoricals([a, b])
Out[202]: 
['a', 'b', 'a', 'b', 'a']
Categories (2, object): ['a' < 'b']
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.Categorical pandas.api.types.union_categoricals
"In [203]: a = pd.Categorical([""a"", ""b""], ordered=True)

In [204]: b = pd.Categorical([""a"", ""b"", ""c""], ordered=True)

In [205]: union_categoricals([a, b])
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
Cell In[205], line 1
----> 1 union_categoricals([a, b])

File ~/work/pandas/pandas/pandas/core/dtypes/concat.py:341, in union_categoricals(to_union, sort_categories, ignore_order)
    339     if all(c.ordered for c in to_union):
    340         msg = ""to union ordered Categoricals, all categories must be the same""
--> 341         raise TypeError(msg)
    342     raise TypeError(""Categorical.ordered must be the same"")
    344 if ignore_order:

TypeError: to union ordered Categoricals, all categories must be the same
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.Categorical pandas.api.types.union_categoricals
"In [206]: a = pd.Categorical([""a"", ""b"", ""c""], ordered=True)

In [207]: b = pd.Categorical([""c"", ""b"", ""a""], ordered=True)

In [208]: union_categoricals([a, b], ignore_order=True)
Out[208]: 
['a', 'b', 'c', 'c', 'b', 'a']
Categories (3, object): ['a', 'b', 'c']
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.Categorical pandas.api.types.union_categoricals
"In [209]: a = pd.Series([""b"", ""c""], dtype=""category"")

In [210]: b = pd.Series([""a"", ""b""], dtype=""category"")

In [211]: union_categoricals([a, b])
Out[211]: 
['b', 'c', 'a', 'b']
Categories (3, object): ['b', 'c', 'a']
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.Series pandas.api.types.union_categoricals
"In [212]: c1 = pd.Categorical([""b"", ""c""])

In [213]: c2 = pd.Categorical([""a"", ""b""])

In [214]: c1
Out[214]: 
['b', 'c']
Categories (2, object): ['b', 'c']

# ""b"" is coded to 0
In [215]: c1.codes
Out[215]: array([0, 1], dtype=int8)

In [216]: c2
Out[216]: 
['a', 'b']
Categories (2, object): ['a', 'b']

# ""b"" is coded to 1
In [217]: c2.codes
Out[217]: array([0, 1], dtype=int8)

In [218]: c = union_categoricals([c1, c2])

In [219]: c
Out[219]: 
['b', 'c', 'a', 'b']
Categories (3, object): ['b', 'c', 'a']

# ""b"" is coded to 0 throughout, same as c1, different from c2
In [220]: c.codes
Out[220]: array([0, 1, 2, 0], dtype=int8)
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.Categorical pandas.array pandas.api.types.union_categoricals
"In [221]: import io

In [222]: s = pd.Series(pd.Categorical([""a"", ""b"", ""b"", ""a"", ""a"", ""d""]))

# rename the categories
In [223]: s = s.cat.rename_categories([""very good"", ""good"", ""bad""])

# reorder the categories and add missing categories
In [224]: s = s.cat.set_categories([""very bad"", ""bad"", ""medium"", ""good"", ""very good""])

In [225]: df = pd.DataFrame({""cats"": s, ""vals"": [1, 2, 3, 4, 5, 6]})

In [226]: csv = io.StringIO()

In [227]: df.to_csv(csv)

In [228]: df2 = pd.read_csv(io.StringIO(csv.getvalue()))

In [229]: df2.dtypes
Out[229]: 
Unnamed: 0     int64
cats          object
vals           int64
dtype: object

In [230]: df2[""cats""]
Out[230]: 
0    very good
1         good
2         good
3    very good
4    very good
5          bad
Name: cats, dtype: object

# Redo the category
In [231]: df2[""cats""] = df2[""cats""].astype(""category"")

In [232]: df2[""cats""] = df2[""cats""].cat.set_categories(
   .....:     [""very bad"", ""bad"", ""medium"", ""good"", ""very good""]
   .....: )
   .....: 

In [233]: df2.dtypes
Out[233]: 
Unnamed: 0       int64
cats          category
vals             int64
dtype: object

In [234]: df2[""cats""]
Out[234]: 
0    very good
1         good
2         good
3    very good
4    very good
5          bad
Name: cats, dtype: category
Categories (5, object): ['very bad', 'bad', 'medium', 'good', 'very good']
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.Series pandas.Categorical pandas.Series.cat.rename_categories pandas.Series.cat.set_categories pandas.DataFrame pandas.DataFrame.to_csv pandas.read_csv
"In [235]: s = pd.Series([""a"", ""b"", np.nan, ""a""], dtype=""category"")

# only two categories
In [236]: s
Out[236]: 
0      a
1      b
2    NaN
3      a
dtype: category
Categories (2, object): ['a', 'b']

In [237]: s.cat.codes
Out[237]: 
0    0
1    1
2   -1
3    0
dtype: int8
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.Series
"In [238]: s = pd.Series([""a"", ""b"", np.nan], dtype=""category"")

In [239]: s
Out[239]: 
0      a
1      b
2    NaN
dtype: category
Categories (2, object): ['a', 'b']

In [240]: pd.isna(s)
Out[240]: 
0    False
1    False
2     True
dtype: bool

In [241]: s.fillna(""a"")
Out[241]: 
0    a
1    b
2    a
dtype: category
Categories (2, object): ['a', 'b']
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.Series pandas.isna pandas.Series.fillna
"In [242]: s = pd.Series([""foo"", ""bar""] * 1000)

# object dtype
In [243]: s.nbytes
Out[243]: 16000

# category dtype
In [244]: s.astype(""category"").nbytes
Out[244]: 2016
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.Series pandas.Series.astype
"In [245]: s = pd.Series([""foo%04d"" % i for i in range(2000)])

# object dtype
In [246]: s.nbytes
Out[246]: 16000

# category dtype
In [247]: s.astype(""category"").nbytes
Out[247]: 20000
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.Series pandas.Series.astype
"In [248]: try:
   .....:     np.dtype(""category"")
   .....: except TypeError as e:
   .....:     print(""TypeError:"", str(e))
   .....: 
TypeError: data type 'category' not understood

In [249]: dtype = pd.Categorical([""a""]).dtype

In [250]: try:
   .....:     np.dtype(dtype)
   .....: except TypeError as e:
   .....:     print(""TypeError:"", str(e))
   .....: 
TypeError: Cannot interpret 'CategoricalDtype(categories=['a'], ordered=False, categories_dtype=object)' as a data type
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.Categorical pandas.CategoricalDtype
"In [253]: hasattr(pd.Series([""a""], dtype=""category""), ""cat"")
Out[253]: True

In [254]: hasattr(pd.Series([""a""]), ""cat"")
Out[254]: False
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.Series
"In [255]: s = pd.Series(pd.Categorical([1, 2, 3, 4]))

In [256]: try:
   .....:     np.sum(s)
   .....: except TypeError as e:
   .....:     print(""TypeError:"", str(e))
   .....: 
TypeError: 'Categorical' with dtype category does not support reduction 'sum'
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.Series pandas.Categorical
"In [257]: df = pd.DataFrame(
   .....:     {
   .....:         ""a"": [1, 2, 3, 4],
   .....:         ""b"": [""a"", ""b"", ""c"", ""d""],
   .....:         ""cats"": pd.Categorical([1, 2, 3, 2]),
   .....:     }
   .....: )
   .....: 

In [258]: df.apply(lambda row: type(row[""cats""]), axis=1)
Out[258]: 
0    
1    
2    
3    
dtype: object

In [259]: df.apply(lambda col: col.dtype, axis=0)
Out[259]: 
a          int64
b         object
cats    category
dtype: object
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.DataFrame pandas.Categorical pandas.DataFrame.apply
"In [260]: cats = pd.Categorical([1, 2, 3, 4], categories=[4, 2, 3, 1])

In [261]: strings = [""a"", ""b"", ""c"", ""d""]

In [262]: values = [4, 2, 3, 1]

In [263]: df = pd.DataFrame({""strings"": strings, ""values"": values}, index=cats)

In [264]: df.index
Out[264]: CategoricalIndex([1, 2, 3, 4], categories=[4, 2, 3, 1], ordered=False, dtype='category')

# This now sorts by the categories order
In [265]: df.sort_index()
Out[265]: 
  strings  values
4       d       1
2       b       2
3       c       3
1       a       4
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.Categorical pandas.DataFrame pandas.CategoricalIndex pandas.DataFrame.sort_index
"In [266]: cat = pd.Categorical([1, 2, 3, 10], categories=[1, 2, 3, 4, 10])

In [267]: s = pd.Series(cat, name=""cat"")

In [268]: cat
Out[268]: 
[1, 2, 3, 10]
Categories (5, int64): [1, 2, 3, 4, 10]

In [269]: s.iloc[0:2] = 10

In [270]: cat
Out[270]: 
[10, 10, 3, 10]
Categories (5, int64): [1, 2, 3, 4, 10]
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.Categorical pandas.Series
"In [271]: cat = pd.Categorical([1, 2, 3, 10], categories=[1, 2, 3, 4, 10])

In [272]: s = pd.Series(cat, name=""cat"", copy=True)

In [273]: cat
Out[273]: 
[1, 2, 3, 10]
Categories (5, int64): [1, 2, 3, 4, 10]

In [274]: s.iloc[0:2] = 10

In [275]: cat
Out[275]: 
[1, 2, 3, 10]
Categories (5, int64): [1, 2, 3, 4, 10]
",https://pandas.pydata.org/docs/user_guide/categorical.html, pandas.Categorical pandas.Series
"In [1]: df = pd.DataFrame(
   ...:     {
   ...:         ""a"": np.random.randn(1000),
   ...:         ""b"": np.random.randn(1000),
   ...:         ""N"": np.random.randint(100, 1000, (1000)),
   ...:         ""x"": ""x"",
   ...:     }
   ...: )
   ...: 

In [2]: df
Out[2]: 
            a         b    N  x
0    0.469112 -0.218470  585  x
1   -0.282863 -0.061645  841  x
2   -1.509059 -0.723780  251  x
3   -1.135632  0.551225  972  x
4    1.212112 -0.497767  181  x
..        ...       ...  ... ..
995 -1.512743  0.874737  374  x
996  0.933753  1.120790  246  x
997 -0.308013  0.198768  157  x
998 -0.079915  1.757555  977  x
999 -1.010589 -1.115680  770  x

[1000 rows x 4 columns]
",https://pandas.pydata.org/docs/user_guide/enhancingperf.html, pandas.DataFrame
"In [5]: %timeit df.apply(lambda x: integrate_f(x[""a""], x[""b""], x[""N""]), axis=1)
74.9 ms +- 728 us per loop (mean +- std. dev. of 7 runs, 10 loops each)
",https://pandas.pydata.org/docs/user_guide/enhancingperf.html, pandas.DataFrame.apply
"# most time consuming 4 calls
In [6]: %prun -l 4 df.apply(lambda x: integrate_f(x[""a""], x[""b""], x[""N""]), axis=1)  # noqa E999
         605956 function calls (605938 primitive calls) in 0.167 seconds

   Ordered by: internal time
   List reduced from 163 to 4 due to restriction <4>

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1000    0.097    0.000    0.148    0.000 :1(integrate_f)
   552423    0.051    0.000    0.051    0.000 :1(f)
     3000    0.003    0.000    0.012    0.000 series.py:1095(__getitem__)
     3000    0.002    0.000    0.005    0.000 series.py:1220(_get_value)
",https://pandas.pydata.org/docs/user_guide/enhancingperf.html, pandas.DataFrame.apply
"In [9]: %timeit df.apply(lambda x: integrate_f_plain(x[""a""], x[""b""], x[""N""]), axis=1)
46.6 ms +- 466 us per loop (mean +- std. dev. of 7 runs, 10 loops each)
",https://pandas.pydata.org/docs/user_guide/enhancingperf.html, pandas.DataFrame.apply
"In [11]: %timeit df.apply(lambda x: integrate_f_typed(x[""a""], x[""b""], x[""N""]), axis=1)
7.76 ms +- 83.8 us per loop (mean +- std. dev. of 7 runs, 100 loops each)
",https://pandas.pydata.org/docs/user_guide/enhancingperf.html, pandas.DataFrame.apply
"In [12]: %prun -l 4 df.apply(lambda x: integrate_f_typed(x[""a""], x[""b""], x[""N""]), axis=1)
         52533 function calls (52515 primitive calls) in 0.019 seconds

   Ordered by: internal time
   List reduced from 161 to 4 due to restriction <4>

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     3000    0.003    0.000    0.012    0.000 series.py:1095(__getitem__)
     3000    0.002    0.000    0.005    0.000 series.py:1220(_get_value)
     3000    0.002    0.000    0.002    0.000 base.py:3777(get_loc)
     3000    0.002    0.000    0.002    0.000 indexing.py:2765(check_dict_or_set_indexers)
",https://pandas.pydata.org/docs/user_guide/enhancingperf.html, pandas.DataFrame.apply
"In [1]: data = pd.Series(range(1_000_000))  # noqa: E225

In [2]: roll = data.rolling(10)

In [3]: def f(x):
   ...:     return np.sum(x) + 5
# Run the first time, compilation time will affect performance
In [4]: %timeit -r 1 -n 1 roll.apply(f, engine='numba', raw=True)
1.23 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)
# Function is cached and performance will improve
In [5]: %timeit roll.apply(f, engine='numba', raw=True)
188 ms ± 1.93 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)

In [6]: %timeit roll.apply(f, engine='cython', raw=True)
3.92 s ± 59 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)
",https://pandas.pydata.org/docs/user_guide/enhancingperf.html, pandas.Series pandas.Series.rolling
"In [1]: import numba

In [2]: numba.set_num_threads(1)

In [3]: df = pd.DataFrame(np.random.randn(10_000, 100))

In [4]: roll = df.rolling(100)

In [5]: %timeit roll.mean(engine=""numba"", engine_kwargs={""parallel"": True})
347 ms ± 26 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)

In [6]: numba.set_num_threads(2)

In [7]: %timeit roll.mean(engine=""numba"", engine_kwargs={""parallel"": True})
201 ms ± 2.97 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)
",https://pandas.pydata.org/docs/user_guide/enhancingperf.html, pandas.DataFrame pandas.DataFrame.rolling
"import numba


@numba.jit
def f_plain(x):
    return x * (x - 1)


@numba.jit
def integrate_f_numba(a, b, N):
    s = 0
    dx = (b - a) / N
    for i in range(N):
        s += f_plain(a + i * dx)
    return s * dx


@numba.jit
def apply_integrate_f_numba(col_a, col_b, col_N):
    n = len(col_N)
    result = np.empty(n, dtype=""float64"")
    assert len(col_a) == len(col_b) == n
    for i in range(n):
        result[i] = integrate_f_numba(col_a[i], col_b[i], col_N[i])
    return result


def compute_numba(df):
    result = apply_integrate_f_numba(
        df[""a""].to_numpy(), df[""b""].to_numpy(), df[""N""].to_numpy()
    )
    return pd.Series(result, index=df.index, name=""result"")
",https://pandas.pydata.org/docs/user_guide/enhancingperf.html, pandas.Series
"In [18]: df = pd.DataFrame(np.random.randn(5, 2), columns=list(""ab""))

In [19]: newcol = np.random.randn(len(df))

In [20]: df.eval(""b + @newcol"")
Out[20]: 
0   -0.206122
1   -1.029587
2    0.519726
3   -2.052589
4    1.453210
dtype: float64

In [21]: df.query(""b < @newcol"")
Out[21]: 
          a         b
1  0.160268 -0.848896
3  0.333758 -1.180355
4  0.572182  0.439895
",https://pandas.pydata.org/docs/user_guide/enhancingperf.html, pandas.DataFrame pandas.DataFrame.eval pandas.DataFrame.query
"In [22]: a = np.random.randn()

In [23]: df.query(""@a < a"")
Out[23]: 
          a         b
0  0.473349  0.891236
1  0.160268 -0.848896
2  0.803311  1.662031
3  0.333758 -1.180355
4  0.572182  0.439895

In [24]: df.loc[a < df[""a""]]  # same as the previous expression
Out[24]: 
          a         b
0  0.473349  0.891236
1  0.160268 -0.848896
2  0.803311  1.662031
3  0.333758 -1.180355
4  0.572182  0.439895
",https://pandas.pydata.org/docs/user_guide/enhancingperf.html, pandas.DataFrame.query
"In [25]: a, b = 1, 2

In [26]: pd.eval(""@a + b"")
Traceback (most recent call last):

  File ~/micromamba/envs/test/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3577 in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)

  Cell In[26], line 1
    pd.eval(""@a + b"")

  File ~/work/pandas/pandas/pandas/core/computation/eval.py:325 in eval
    _check_for_locals(expr, level, parser)

  File ~/work/pandas/pandas/pandas/core/computation/eval.py:167 in _check_for_locals
    raise SyntaxError(msg)

  File 
SyntaxError: The '@' prefix is not allowed in top-level eval calls.
please refer to your variables by name without the '@' prefix.
",https://pandas.pydata.org/docs/user_guide/enhancingperf.html, pandas.eval
"In [27]: pd.eval(""a + b"")
Out[27]: 3
",https://pandas.pydata.org/docs/user_guide/enhancingperf.html, pandas.eval
"In [28]: nrows, ncols = 20000, 100

In [29]: df1, df2, df3, df4 = [pd.DataFrame(np.random.randn(nrows, ncols)) for _ in range(4)]

In [30]: expr = ""(df1 > 0) & (df2 > 0) & (df3 > 0) & (df4 > 0)""

In [31]: x = pd.eval(expr, parser=""python"")

In [32]: expr_no_parens = ""df1 > 0 & df2 > 0 & df3 > 0 & df4 > 0""

In [33]: y = pd.eval(expr_no_parens, parser=""pandas"")

In [34]: np.all(x == y)
Out[34]: True
",https://pandas.pydata.org/docs/user_guide/enhancingperf.html, pandas.DataFrame pandas.eval
"In [35]: expr = ""(df1 > 0) & (df2 > 0) & (df3 > 0) & (df4 > 0)""

In [36]: x = pd.eval(expr, parser=""python"")

In [37]: expr_with_ands = ""df1 > 0 and df2 > 0 and df3 > 0 and df4 > 0""

In [38]: y = pd.eval(expr_with_ands, parser=""pandas"")

In [39]: np.all(x == y)
Out[39]: True
",https://pandas.pydata.org/docs/user_guide/enhancingperf.html, pandas.eval
"In [41]: %timeit pd.eval(""df1 + df2 + df3 + df4"", engine=""python"")
8.11 ms +- 161 us per loop (mean +- std. dev. of 7 runs, 100 loops each)
",https://pandas.pydata.org/docs/user_guide/enhancingperf.html, pandas.eval
"In [42]: df = pd.DataFrame(np.random.randn(5, 2), columns=[""a"", ""b""])

In [43]: df.eval(""a + b"")
Out[43]: 
0   -0.161099
1    0.805452
2    0.747447
3    1.189042
4   -2.057490
dtype: float64
",https://pandas.pydata.org/docs/user_guide/enhancingperf.html, pandas.DataFrame pandas.DataFrame.eval
"In [44]: df = pd.DataFrame(dict(a=range(5), b=range(5, 10)))

In [45]: df = df.eval(""c = a + b"")

In [46]: df = df.eval(""d = a + b + c"")

In [47]: df = df.eval(""a = 1"")

In [48]: df
Out[48]: 
   a  b   c   d
0  1  5   5  10
1  1  6   7  14
2  1  7   9  18
3  1  8  11  22
4  1  9  13  26
",https://pandas.pydata.org/docs/user_guide/enhancingperf.html, pandas.DataFrame pandas.DataFrame.eval
"In [49]: df
Out[49]: 
   a  b   c   d
0  1  5   5  10
1  1  6   7  14
2  1  7   9  18
3  1  8  11  22
4  1  9  13  26

In [50]: df.eval(""e = a - c"")
Out[50]: 
   a  b   c   d   e
0  1  5   5  10  -4
1  1  6   7  14  -6
2  1  7   9  18  -8
3  1  8  11  22 -10
4  1  9  13  26 -12

In [51]: df
Out[51]: 
   a  b   c   d
0  1  5   5  10
1  1  6   7  14
2  1  7   9  18
3  1  8  11  22
4  1  9  13  26
",https://pandas.pydata.org/docs/user_guide/enhancingperf.html, pandas.DataFrame.eval
"In [52]: df.eval(
   ....:     """"""
   ....: c = a + b
   ....: d = a + b + c
   ....: a = 1"""""",
   ....: )
   ....: 
Out[52]: 
   a  b   c   d
0  1  5   6  12
1  1  6   7  14
2  1  7   8  16
3  1  8   9  18
4  1  9  10  20
",https://pandas.pydata.org/docs/user_guide/enhancingperf.html, pandas.DataFrame.eval
"In [53]: df = pd.DataFrame(dict(a=range(5), b=range(5, 10)))

In [54]: df[""c""] = df[""a""] + df[""b""]

In [55]: df[""d""] = df[""a""] + df[""b""] + df[""c""]

In [56]: df[""a""] = 1

In [57]: df
Out[57]: 
   a  b   c   d
0  1  5   5  10
1  1  6   7  14
2  1  7   9  18
3  1  8  11  22
4  1  9  13  26
",https://pandas.pydata.org/docs/user_guide/enhancingperf.html, pandas.DataFrame
"In [58]: nrows, ncols = 20000, 100

In [59]: df1, df2, df3, df4 = [pd.DataFrame(np.random.randn(nrows, ncols)) for _ in range(4)]
",https://pandas.pydata.org/docs/user_guide/enhancingperf.html, pandas.DataFrame
"In [61]: %timeit pd.eval(""df1 + df2 + df3 + df4"")
2.85 ms +- 58.8 us per loop (mean +- std. dev. of 7 runs, 100 loops each)
",https://pandas.pydata.org/docs/user_guide/enhancingperf.html, pandas.eval
"In [63]: %timeit pd.eval(""(df1 > 0) & (df2 > 0) & (df3 > 0) & (df4 > 0)"")
9.38 ms +- 36.7 us per loop (mean +- std. dev. of 7 runs, 100 loops each)
",https://pandas.pydata.org/docs/user_guide/enhancingperf.html, pandas.eval
"In [64]: s = pd.Series(np.random.randn(50))

In [65]: %timeit df1 + df2 + df3 + df4 + s
12.6 ms +- 105 us per loop (mean +- std. dev. of 7 runs, 100 loops each)
",https://pandas.pydata.org/docs/user_guide/enhancingperf.html, pandas.Series
"In [66]: %timeit pd.eval(""df1 + df2 + df3 + df4 + s"")
3.69 ms +- 62 us per loop (mean +- std. dev. of 7 runs, 100 loops each)
",https://pandas.pydata.org/docs/user_guide/enhancingperf.html, pandas.eval
"In [67]: df = pd.DataFrame(
   ....:     {""strings"": np.repeat(list(""cba""), 3), ""nums"": np.repeat(range(3), 3)}
   ....: )
   ....: 

In [68]: df
Out[68]: 
  strings  nums
0       c     0
1       c     0
2       c     0
3       b     1
4       b     1
5       b     1
6       a     2
7       a     2
8       a     2

In [69]: df.query(""strings == 'a' and nums == 1"")
Out[69]: 
Empty DataFrame
Columns: [strings, nums]
Index: []
",https://pandas.pydata.org/docs/user_guide/enhancingperf.html, pandas.DataFrame pandas.DataFrame.query
"In [1]: df = pd.DataFrame({""foo"": [1, 2, 3], ""bar"": [4, 5, 6]})

In [2]: subset = df[""foo""]

In [3]: subset.iloc[0] = 100

In [4]: df
Out[4]: 
   foo  bar
0  100    4
1    2    5
2    3    6
",https://pandas.pydata.org/docs/user_guide/copy_on_write.html, pandas.DataFrame
"In [5]: pd.options.mode.copy_on_write = True

In [6]: df = pd.DataFrame({""foo"": [1, 2, 3], ""bar"": [4, 5, 6]})

In [7]: subset = df[""foo""]

In [8]: subset.iloc[0] = 100

In [9]: df
Out[9]: 
   foo  bar
0    1    4
1    2    5
2    3    6
",https://pandas.pydata.org/docs/user_guide/copy_on_write.html, pandas.DataFrame
"In [10]: ser = pd.Series([1, 2, 3])

In [11]: ser.to_numpy()
Out[11]: array([1, 2, 3])
",https://pandas.pydata.org/docs/user_guide/copy_on_write.html, pandas.Series pandas.Series.to_numpy pandas.array
"In [12]: df = pd.DataFrame({""foo"": [1, 2, 3], ""bar"": [4, 5, 6]})

In [13]: subset = df[""foo""]

In [14]: subset.iloc[0] = 100

In [15]: df
Out[15]: 
   foo  bar
0    1    4
1    2    5
2    3    6
",https://pandas.pydata.org/docs/user_guide/copy_on_write.html, pandas.DataFrame
"In [16]: df = pd.DataFrame({""foo"": [1, 2, 3], ""bar"": [4, 5, 6]})

In [17]: df[""foo""].replace(1, 5, inplace=True)

In [18]: df
Out[18]: 
   foo  bar
0    1    4
1    2    5
2    3    6
",https://pandas.pydata.org/docs/user_guide/copy_on_write.html, pandas.DataFrame
"In [19]: df = pd.DataFrame({""foo"": [1, 2, 3], ""bar"": [4, 5, 6]})

In [20]: df.replace({""foo"": {1: 5}}, inplace=True)

In [21]: df
Out[21]: 
   foo  bar
0    5    4
1    2    5
2    3    6
",https://pandas.pydata.org/docs/user_guide/copy_on_write.html, pandas.DataFrame pandas.DataFrame.replace
"In [22]: df = pd.DataFrame({""foo"": [1, 2, 3], ""bar"": [4, 5, 6]})

In [23]: df[""foo""] = df[""foo""].replace(1, 5)

In [24]: df
Out[24]: 
   foo  bar
0    5    4
1    2    5
2    3    6
",https://pandas.pydata.org/docs/user_guide/copy_on_write.html, pandas.DataFrame
"In [25]: df = pd.DataFrame({""foo"": [1, 2, 3], ""bar"": [4, 5, 6]})

In [26]: df.iloc[0, 0] = 100

In [27]: df
Out[27]: 
   foo  bar
0  100    4
1    2    5
2    3    6
",https://pandas.pydata.org/docs/user_guide/copy_on_write.html, pandas.DataFrame
"In [28]: df = pd.DataFrame({""foo"": [1, 2, 3], ""bar"": [4, 5, 6]})

In [29]: df2 = df.reset_index(drop=True)

In [30]: df2.iloc[0, 0] = 100

In [31]: df
Out[31]: 
   foo  bar
0    1    4
1    2    5
2    3    6

In [32]: df2
Out[32]: 
   foo  bar
0  100    4
1    2    5
2    3    6
",https://pandas.pydata.org/docs/user_guide/copy_on_write.html, pandas.DataFrame pandas.DataFrame.reset_index
"In [33]: df = pd.DataFrame({""foo"": [1, 2, 3], ""bar"": [4, 5, 6]})

In [34]: df = df.reset_index(drop=True)

In [35]: df.iloc[0, 0] = 100

In [36]: df
Out[36]: 
   foo  bar
0  100    4
1    2    5
2    3    6
",https://pandas.pydata.org/docs/user_guide/copy_on_write.html, pandas.DataFrame pandas.DataFrame.reset_index
"In [37]: with pd.option_context(""mode.copy_on_write"", False):
   ....:     df = pd.DataFrame({""foo"": [1, 2, 3], ""bar"": [4, 5, 6]})
   ....:     view = df[:]
   ....:     df.iloc[0, 0] = 100
   ....: 

In [38]: df
Out[38]: 
   foo  bar
0  100    4
1    2    5
2    3    6

In [39]: view
Out[39]: 
   foo  bar
0  100    4
1    2    5
2    3    6
",https://pandas.pydata.org/docs/user_guide/copy_on_write.html, pandas.DataFrame
"In [40]: df = pd.DataFrame({""foo"": [1, 2, 3], ""bar"": [4, 5, 6]})

In [41]: view = df[:]

In [42]: df.iloc[0, 0] = 100

In [43]: df
Out[43]: 
   foo  bar
0  100    4
1    2    5
2    3    6

In [44]: view
Out[44]: 
   foo  bar
0    1    4
1    2    5
2    3    6
",https://pandas.pydata.org/docs/user_guide/copy_on_write.html, pandas.DataFrame
"In [45]: with pd.option_context(""mode.copy_on_write"", False):
   ....:     df = pd.DataFrame({""foo"": [1, 2, 3], ""bar"": [4, 5, 6]})
   ....:     df[""foo""][df[""bar""] > 5] = 100
   ....:     df
   ....: 
",https://pandas.pydata.org/docs/user_guide/copy_on_write.html, pandas.DataFrame
"In [46]: df = pd.DataFrame({""foo"": [1, 2, 3], ""bar"": [4, 5, 6]})

In [47]: df[""foo""][df[""bar""] > 5] = 100
",https://pandas.pydata.org/docs/user_guide/copy_on_write.html, pandas.DataFrame
"In [49]: df = pd.DataFrame({""a"": [1, 2], ""b"": [1.5, 2.5]})

In [50]: df.to_numpy()
Out[50]: 
array([[1. , 1.5],
       [2. , 2.5]])
",https://pandas.pydata.org/docs/user_guide/copy_on_write.html, pandas.DataFrame pandas.DataFrame.to_numpy pandas.array
"In [51]: df = pd.DataFrame({""a"": [1, 2], ""b"": [3, 4]})

In [52]: df.to_numpy()
Out[52]: 
array([[1, 3],
       [2, 4]])
",https://pandas.pydata.org/docs/user_guide/copy_on_write.html, pandas.DataFrame pandas.DataFrame.to_numpy pandas.array
"In [53]: arr = df.to_numpy()

In [54]: arr[0, 0] = 100
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
Cell In[54], line 1
----> 1 arr[0, 0] = 100

ValueError: assignment destination is read-only
",https://pandas.pydata.org/docs/user_guide/copy_on_write.html, pandas.DataFrame.to_numpy
"In [55]: arr = df.to_numpy()

In [56]: arr.flags.writeable = True

In [57]: arr[0, 0] = 100

In [58]: arr
Out[58]: 
array([[100,   3],
       [  2,   4]])
",https://pandas.pydata.org/docs/user_guide/copy_on_write.html, pandas.DataFrame.to_numpy pandas.array
"In [59]: df = pd.DataFrame({""a"": [1, 2, 3], ""b"": [4, 5, 6]})

In [60]: df2 = df.reset_index(drop=True)

In [61]: df2.iloc[0, 0] = 100
",https://pandas.pydata.org/docs/user_guide/copy_on_write.html, pandas.DataFrame pandas.DataFrame.reset_index
"In [62]: df = pd.DataFrame({""a"": [1, 2, 3], ""b"": [4, 5, 6]})

In [63]: df = df.reset_index(drop=True)

In [64]: df.iloc[0, 0] = 100
",https://pandas.pydata.org/docs/user_guide/copy_on_write.html, pandas.DataFrame pandas.DataFrame.reset_index
"In [1]: pd.Series([""a"", ""b"", ""c""])
Out[1]: 
0    a
1    b
2    c
dtype: object
",https://pandas.pydata.org/docs/user_guide/text.html, pandas.Series
"In [2]: pd.Series([""a"", ""b"", ""c""], dtype=""string"")
Out[2]: 
0    a
1    b
2    c
dtype: string

In [3]: pd.Series([""a"", ""b"", ""c""], dtype=pd.StringDtype())
Out[3]: 
0    a
1    b
2    c
dtype: string
",https://pandas.pydata.org/docs/user_guide/text.html, pandas.Series pandas.StringDtype
"In [4]: s = pd.Series([""a"", ""b"", ""c""])

In [5]: s
Out[5]: 
0    a
1    b
2    c
dtype: object

In [6]: s.astype(""string"")
Out[6]: 
0    a
1    b
2    c
dtype: string
",https://pandas.pydata.org/docs/user_guide/text.html, pandas.Series pandas.Series.astype
"In [7]: s = pd.Series([""a"", 2, np.nan], dtype=""string"")

In [8]: s
Out[8]: 
0       a
1       2
2    
dtype: string

In [9]: type(s[1])
Out[9]: str
",https://pandas.pydata.org/docs/user_guide/text.html, pandas.Series
"In [10]: s1 = pd.Series([1, 2, np.nan], dtype=""Int64"")

In [11]: s1
Out[11]: 
0       1
1       2
2    
dtype: Int64

In [12]: s2 = s1.astype(""string"")

In [13]: s2
Out[13]: 
0       1
1       2
2    
dtype: string

In [14]: type(s2[0])
Out[14]: str
",https://pandas.pydata.org/docs/user_guide/text.html, pandas.Series pandas.Series.astype
"In [15]: s = pd.Series([""a"", None, ""b""], dtype=""string"")

In [16]: s
Out[16]: 
0       a
1    
2       b
dtype: string

In [17]: s.str.count(""a"")
Out[17]: 
0       1
1    
2       0
dtype: Int64

In [18]: s.dropna().str.count(""a"")
Out[18]: 
0    1
2    0
dtype: Int64
",https://pandas.pydata.org/docs/user_guide/text.html, pandas.Series pandas.Series.str.count pandas.Series.dropna
"In [19]: s2 = pd.Series([""a"", None, ""b""], dtype=""object"")

In [20]: s2.str.count(""a"")
Out[20]: 
0    1.0
1    NaN
2    0.0
dtype: float64

In [21]: s2.dropna().str.count(""a"")
Out[21]: 
0    1
2    0
dtype: int64
",https://pandas.pydata.org/docs/user_guide/text.html, pandas.Series pandas.Series.str.count pandas.Series.dropna
"In [22]: s.str.isdigit()
Out[22]: 
0    False
1     
2    False
dtype: boolean

In [23]: s.str.match(""a"")
Out[23]: 
0     True
1     
2    False
dtype: boolean
",https://pandas.pydata.org/docs/user_guide/text.html, pandas.Series.str.isdigit pandas.Series.str.match
"In [24]: s = pd.Series(
   ....:     [""A"", ""B"", ""C"", ""Aaba"", ""Baca"", np.nan, ""CABA"", ""dog"", ""cat""], dtype=""string""
   ....: )
   ....: 

In [25]: s.str.lower()
Out[25]: 
0       a
1       b
2       c
3    aaba
4    baca
5    
6    caba
7     dog
8     cat
dtype: string

In [26]: s.str.upper()
Out[26]: 
0       A
1       B
2       C
3    AABA
4    BACA
5    
6    CABA
7     DOG
8     CAT
dtype: string

In [27]: s.str.len()
Out[27]: 
0       1
1       1
2       1
3       4
4       4
5    
6       4
7       3
8       3
dtype: Int64
",https://pandas.pydata.org/docs/user_guide/text.html, pandas.Series pandas.Series.str.lower pandas.Series.str.upper pandas.Series.str.len
"In [28]: idx = pd.Index(["" jack"", ""jill "", "" jesse "", ""frank""])

In [29]: idx.str.strip()
Out[29]: Index(['jack', 'jill', 'jesse', 'frank'], dtype='object')

In [30]: idx.str.lstrip()
Out[30]: Index(['jack', 'jill ', 'jesse ', 'frank'], dtype='object')

In [31]: idx.str.rstrip()
Out[31]: Index([' jack', 'jill', ' jesse', 'frank'], dtype='object')
",https://pandas.pydata.org/docs/user_guide/text.html, pandas.Index pandas.Index
"In [32]: df = pd.DataFrame(
   ....:     np.random.randn(3, 2), columns=["" Column A "", "" Column B ""], index=range(3)
   ....: )
   ....: 

In [33]: df
Out[33]: 
   Column A   Column B 
0   0.469112  -0.282863
1  -1.509059  -1.135632
2   1.212112  -0.173215
",https://pandas.pydata.org/docs/user_guide/text.html, pandas.DataFrame
"In [34]: df.columns.str.strip()
Out[34]: Index(['Column A', 'Column B'], dtype='object')

In [35]: df.columns.str.lower()
Out[35]: Index([' column a ', ' column b '], dtype='object')
",https://pandas.pydata.org/docs/user_guide/text.html, pandas.Index
"In [36]: df.columns = df.columns.str.strip().str.lower().str.replace("" "", ""_"")

In [37]: df
Out[37]: 
   column_a  column_b
0  0.469112 -0.282863
1 -1.509059 -1.135632
2  1.212112 -0.173215
",https://pandas.pydata.org/docs/user_guide/text.html, pandas.Series.str.lower
"In [38]: s2 = pd.Series([""a_b_c"", ""c_d_e"", np.nan, ""f_g_h""], dtype=""string"")

In [39]: s2.str.split(""_"")
Out[39]: 
0    [a, b, c]
1    [c, d, e]
2         
3    [f, g, h]
dtype: object
",https://pandas.pydata.org/docs/user_guide/text.html, pandas.Series pandas.Series.str.split
"In [40]: s2.str.split(""_"").str.get(1)
Out[40]: 
0       b
1       d
2    
3       g
dtype: object

In [41]: s2.str.split(""_"").str[1]
Out[41]: 
0       b
1       d
2    
3       g
dtype: object
",https://pandas.pydata.org/docs/user_guide/text.html, pandas.Series.str.split
"In [42]: s2.str.split(""_"", expand=True)
Out[42]: 
      0     1     2
0     a     b     c
1     c     d     e
2      
3     f     g     h
",https://pandas.pydata.org/docs/user_guide/text.html, pandas.Series.str.split
"In [43]: s2.str.split(""_"", expand=True, n=1)
Out[43]: 
      0     1
0     a   b_c
1     c   d_e
2    
3     f   g_h
",https://pandas.pydata.org/docs/user_guide/text.html, pandas.Series.str.split
"In [44]: s2.str.rsplit(""_"", expand=True, n=1)
Out[44]: 
      0     1
0   a_b     c
1   c_d     e
2    
3   f_g     h
",https://pandas.pydata.org/docs/user_guide/text.html, pandas.Series.str.rsplit
"In [45]: s3 = pd.Series(
   ....:     [""A"", ""B"", ""C"", ""Aaba"", ""Baca"", """", np.nan, ""CABA"", ""dog"", ""cat""],
   ....:     dtype=""string"",
   ....: )
   ....: 

In [46]: s3
Out[46]: 
0       A
1       B
2       C
3    Aaba
4    Baca
5        
6    
7    CABA
8     dog
9     cat
dtype: string

In [47]: s3.str.replace(""^.a|dog"", ""XX-XX "", case=False, regex=True)
Out[47]: 
0           A
1           B
2           C
3    XX-XX ba
4    XX-XX ca
5            
6        
7    XX-XX BA
8      XX-XX 
9     XX-XX t
dtype: string
",https://pandas.pydata.org/docs/user_guide/text.html, pandas.Series pandas.Series.str.replace
"In [48]: s4 = pd.Series([""a.b"", ""."", ""b"", np.nan, """"], dtype=""string"")

In [49]: s4
Out[49]: 
0     a.b
1       .
2       b
3    
4        
dtype: string

In [50]: s4.str.replace(""."", ""a"", regex=True)
Out[50]: 
0     aaa
1       a
2       a
3    
4        
dtype: string
",https://pandas.pydata.org/docs/user_guide/text.html, pandas.Series pandas.Series.str.replace
"In [51]: dollars = pd.Series([""12"", ""-$10"", ""$10,000""], dtype=""string"")

# These lines are equivalent
In [52]: dollars.str.replace(r""-\$"", ""-"", regex=True)
Out[52]: 
0         12
1        -10
2    $10,000
dtype: string

In [53]: dollars.str.replace(""-$"", ""-"", regex=False)
Out[53]: 
0         12
1        -10
2    $10,000
dtype: string
",https://pandas.pydata.org/docs/user_guide/text.html, pandas.Series pandas.Series.str.replace
"# Reverse every lowercase alphabetic word
In [54]: pat = r""[a-z]+""

In [55]: def repl(m):
   ....:     return m.group(0)[::-1]
   ....: 

In [56]: pd.Series([""foo 123"", ""bar baz"", np.nan], dtype=""string"").str.replace(
   ....:     pat, repl, regex=True
   ....: )
   ....: 
Out[56]: 
0    oof 123
1    rab zab
2       
dtype: string

# Using regex groups
In [57]: pat = r""(?P\w+) (?P\w+) (?P\w+)""

In [58]: def repl(m):
   ....:     return m.group(""two"").swapcase()
   ....: 

In [59]: pd.Series([""Foo Bar Baz"", np.nan], dtype=""string"").str.replace(
   ....:     pat, repl, regex=True
   ....: )
   ....: 
Out[59]: 
0     bAR
1    
dtype: string
",https://pandas.pydata.org/docs/user_guide/text.html, pandas.Series pandas.Series.str.swapcase
"In [60]: import re

In [61]: regex_pat = re.compile(r""^.a|dog"", flags=re.IGNORECASE)

In [62]: s3.str.replace(regex_pat, ""XX-XX "", regex=True)
Out[62]: 
0           A
1           B
2           C
3    XX-XX ba
4    XX-XX ca
5            
6        
7    XX-XX BA
8      XX-XX 
9     XX-XX t
dtype: string
",https://pandas.pydata.org/docs/user_guide/text.html, pandas.Series.str.replace
"In [63]: s3.str.replace(regex_pat, 'XX-XX ', flags=re.IGNORECASE)
---------------------------------------------------------------------------
ValueError: case and flags cannot be set when pat is a compiled regex
",https://pandas.pydata.org/docs/user_guide/text.html, pandas.Series.str.replace
"In [64]: s = pd.Series([""str_foo"", ""str_bar"", ""no_prefix""])

In [65]: s.str.removeprefix(""str_"")
Out[65]: 
0          foo
1          bar
2    no_prefix
dtype: object

In [66]: s = pd.Series([""foo_str"", ""bar_str"", ""no_suffix""])

In [67]: s.str.removesuffix(""_str"")
Out[67]: 
0          foo
1          bar
2    no_suffix
dtype: object
",https://pandas.pydata.org/docs/user_guide/text.html, pandas.Series pandas.Series.str.removeprefix pandas.Series.str.removesuffix
"In [68]: s = pd.Series([""a"", ""b"", ""c"", ""d""], dtype=""string"")

In [69]: s.str.cat(sep="","")
Out[69]: 'a,b,c,d'
",https://pandas.pydata.org/docs/user_guide/text.html, pandas.Series pandas.Series.str.cat
"In [70]: s.str.cat()
Out[70]: 'abcd'
",https://pandas.pydata.org/docs/user_guide/text.html, pandas.Series.str.cat
"In [71]: t = pd.Series([""a"", ""b"", np.nan, ""d""], dtype=""string"")

In [72]: t.str.cat(sep="","")
Out[72]: 'a,b,d'

In [73]: t.str.cat(sep="","", na_rep=""-"")
Out[73]: 'a,b,-,d'
",https://pandas.pydata.org/docs/user_guide/text.html, pandas.Series pandas.Series.str.cat
"In [74]: s.str.cat([""A"", ""B"", ""C"", ""D""])
Out[74]: 
0    aA
1    bB
2    cC
3    dD
dtype: string
",https://pandas.pydata.org/docs/user_guide/text.html, pandas.Series.str.cat
"In [75]: s.str.cat(t)
Out[75]: 
0      aa
1      bb
2    
3      dd
dtype: string

In [76]: s.str.cat(t, na_rep=""-"")
Out[76]: 
0    aa
1    bb
2    c-
3    dd
dtype: string
",https://pandas.pydata.org/docs/user_guide/text.html, pandas.Series.str.cat
"In [77]: d = pd.concat([t, s], axis=1)

In [78]: s
Out[78]: 
0    a
1    b
2    c
3    d
dtype: string

In [79]: d
Out[79]: 
      0  1
0     a  a
1     b  b
2    c
3     d  d

In [80]: s.str.cat(d, na_rep=""-"")
Out[80]: 
0    aaa
1    bbb
2    c-c
3    ddd
dtype: string
",https://pandas.pydata.org/docs/user_guide/text.html, pandas.concat pandas.Series.str.cat
"In [81]: u = pd.Series([""b"", ""d"", ""a"", ""c""], index=[1, 3, 0, 2], dtype=""string"")

In [82]: s
Out[82]: 
0    a
1    b
2    c
3    d
dtype: string

In [83]: u
Out[83]: 
1    b
3    d
0    a
2    c
dtype: string

In [84]: s.str.cat(u)
Out[84]: 
0    aa
1    bb
2    cc
3    dd
dtype: string

In [85]: s.str.cat(u, join=""left"")
Out[85]: 
0    aa
1    bb
2    cc
3    dd
dtype: string
",https://pandas.pydata.org/docs/user_guide/text.html, pandas.Series pandas.Series.str.cat
"In [86]: v = pd.Series([""z"", ""a"", ""b"", ""d"", ""e""], index=[-1, 0, 1, 3, 4], dtype=""string"")

In [87]: s
Out[87]: 
0    a
1    b
2    c
3    d
dtype: string

In [88]: v
Out[88]: 
-1    z
 0    a
 1    b
 3    d
 4    e
dtype: string

In [89]: s.str.cat(v, join=""left"", na_rep=""-"")
Out[89]: 
0    aa
1    bb
2    c-
3    dd
dtype: string

In [90]: s.str.cat(v, join=""outer"", na_rep=""-"")
Out[90]: 
-1    -z
 0    aa
 1    bb
 2    c-
 3    dd
 4    -e
dtype: string
",https://pandas.pydata.org/docs/user_guide/text.html, pandas.Series pandas.Series.str.cat
"In [91]: f = d.loc[[3, 2, 1, 0], :]

In [92]: s
Out[92]: 
0    a
1    b
2    c
3    d
dtype: string

In [93]: f
Out[93]: 
      0  1
3     d  d
2    c
1     b  b
0     a  a

In [94]: s.str.cat(f, join=""left"", na_rep=""-"")
Out[94]: 
0    aaa
1    bbb
2    c-c
3    ddd
dtype: string
",https://pandas.pydata.org/docs/user_guide/text.html, pandas.Series.str.cat
"In [95]: s
Out[95]: 
0    a
1    b
2    c
3    d
dtype: string

In [96]: u
Out[96]: 
1    b
3    d
0    a
2    c
dtype: string

In [97]: s.str.cat([u, u.to_numpy()], join=""left"")
Out[97]: 
0    aab
1    bbd
2    cca
3    ddc
dtype: string
",https://pandas.pydata.org/docs/user_guide/text.html, pandas.Series.str.cat pandas.Series.to_numpy
"In [98]: v
Out[98]: 
-1    z
 0    a
 1    b
 3    d
 4    e
dtype: string

In [99]: s.str.cat([v, u, u.to_numpy()], join=""outer"", na_rep=""-"")
Out[99]: 
-1    -z--
0     aaab
1     bbbd
2     c-ca
3     dddc
4     -e--
dtype: string
",https://pandas.pydata.org/docs/user_guide/text.html, pandas.Series.str.cat pandas.Series.to_numpy
"In [100]: u.loc[[3]]
Out[100]: 
3    d
dtype: string

In [101]: v.loc[[-1, 0]]
Out[101]: 
-1    z
 0    a
dtype: string

In [102]: s.str.cat([u.loc[[3]], v.loc[[-1, 0]]], join=""right"", na_rep=""-"")
Out[102]: 
 3    dd-
-1    --z
 0    a-a
dtype: string
",https://pandas.pydata.org/docs/user_guide/text.html, pandas.Series.str.cat
"In [103]: s = pd.Series(
   .....:     [""A"", ""B"", ""C"", ""Aaba"", ""Baca"", np.nan, ""CABA"", ""dog"", ""cat""], dtype=""string""
   .....: )
   .....: 

In [104]: s.str[0]
Out[104]: 
0       A
1       B
2       C
3       A
4       B
5    
6       C
7       d
8       c
dtype: string

In [105]: s.str[1]
Out[105]: 
0    
1    
2    
3       a
4       a
5    
6       A
7       o
8       a
dtype: string
",https://pandas.pydata.org/docs/user_guide/text.html, pandas.Series
"In [106]: pd.Series(
   .....:     [""a1"", ""b2"", ""c3""],
   .....:     dtype=""string"",
   .....: ).str.extract(r""([ab])(\d)"", expand=False)
   .....: 
Out[106]: 
      0     1
0     a     1
1     b     2
2    
",https://pandas.pydata.org/docs/user_guide/text.html, pandas.Series pandas.Series.str.extract
"In [107]: pd.Series([""a1"", ""b2"", ""c3""], dtype=""string"").str.extract(
   .....:     r""(?P[ab])(?P\d)"", expand=False
   .....: )
   .....: 
Out[107]: 
  letter digit
0      a     1
1      b     2
2     
",https://pandas.pydata.org/docs/user_guide/text.html, pandas.Series pandas.Series.str.extract
"In [108]: pd.Series(
   .....:     [""a1"", ""b2"", ""3""],
   .....:     dtype=""string"",
   .....: ).str.extract(r""([ab])?(\d)"", expand=False)
   .....: 
Out[108]: 
      0  1
0     a  1
1     b  2
2    3
",https://pandas.pydata.org/docs/user_guide/text.html, pandas.Series pandas.Series.str.extract
"In [109]: pd.Series([""a1"", ""b2"", ""c3""], dtype=""string"").str.extract(r""[ab](\d)"", expand=True)
Out[109]: 
      0
0     1
1     2
2  
",https://pandas.pydata.org/docs/user_guide/text.html, pandas.Series pandas.Series.str.extract
"In [110]: pd.Series([""a1"", ""b2"", ""c3""], dtype=""string"").str.extract(r""[ab](\d)"", expand=False)
Out[110]: 
0       1
1       2
2    
dtype: string
",https://pandas.pydata.org/docs/user_guide/text.html, pandas.Series pandas.Series.str.extract
"In [111]: s = pd.Series([""a1"", ""b2"", ""c3""], [""A11"", ""B22"", ""C33""], dtype=""string"")

In [112]: s
Out[112]: 
A11    a1
B22    b2
C33    c3
dtype: string

In [113]: s.index.str.extract(""(?P[a-zA-Z])"", expand=True)
Out[113]: 
  letter
0      A
1      B
2      C
",https://pandas.pydata.org/docs/user_guide/text.html, pandas.Series
"In [114]: s.index.str.extract(""(?P[a-zA-Z])"", expand=False)
Out[114]: Index(['A', 'B', 'C'], dtype='object', name='letter')
",https://pandas.pydata.org/docs/user_guide/text.html, pandas.Index
"In [116]: s.index.str.extract(""(?P[a-zA-Z])([0-9]+)"", expand=False)
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
Cell In[116], line 1
----> 1 s.index.str.extract(""(?P[a-zA-Z])([0-9]+)"", expand=False)

File ~/work/pandas/pandas/pandas/core/strings/accessor.py:137, in forbid_nonstring_types.._forbid_nonstring_types..wrapper(self, *args, **kwargs)
    132     msg = (
    133         f""Cannot use .str.{func_name} with values of ""
    134         f""inferred dtype '{self._inferred_dtype}'.""
    135     )
    136     raise TypeError(msg)
--> 137 return func(self, *args, **kwargs)

File ~/work/pandas/pandas/pandas/core/strings/accessor.py:2743, in StringMethods.extract(self, pat, flags, expand)
   2740     raise ValueError(""pattern contains no capture groups"")
   2742 if not expand and regex.groups > 1 and isinstance(self._data, ABCIndex):
-> 2743     raise ValueError(""only one regex group is supported with Index"")
   2745 obj = self._data
   2746 result_dtype = _result_dtype(obj)

ValueError: only one regex group is supported with Index
",https://pandas.pydata.org/docs/user_guide/text.html, pandas.Series.str.extract
"In [117]: s = pd.Series([""a1a2"", ""b1"", ""c1""], index=[""A"", ""B"", ""C""], dtype=""string"")

In [118]: s
Out[118]: 
A    a1a2
B      b1
C      c1
dtype: string

In [119]: two_groups = ""(?P[a-z])(?P[0-9])""

In [120]: s.str.extract(two_groups, expand=True)
Out[120]: 
  letter digit
A      a     1
B      b     1
C      c     1
",https://pandas.pydata.org/docs/user_guide/text.html, pandas.Series pandas.Series.str.extract
"In [121]: s.str.extractall(two_groups)
Out[121]: 
        letter digit
  match             
A 0          a     1
  1          a     2
B 0          b     1
C 0          c     1
",https://pandas.pydata.org/docs/user_guide/text.html, pandas.Series.str.extractall
"In [122]: s = pd.Series([""a3"", ""b3"", ""c2""], dtype=""string"")

In [123]: s
Out[123]: 
0    a3
1    b3
2    c2
dtype: string
",https://pandas.pydata.org/docs/user_guide/text.html, pandas.Series
"In [124]: extract_result = s.str.extract(two_groups, expand=True)

In [125]: extract_result
Out[125]: 
  letter digit
0      a     3
1      b     3
2      c     2

In [126]: extractall_result = s.str.extractall(two_groups)

In [127]: extractall_result
Out[127]: 
        letter digit
  match             
0 0          a     3
1 0          b     3
2 0          c     2

In [128]: extractall_result.xs(0, level=""match"")
Out[128]: 
  letter digit
0      a     3
1      b     3
2      c     2
",https://pandas.pydata.org/docs/user_guide/text.html, pandas.Series.str.extract pandas.Series.str.extractall
"In [129]: pd.Index([""a1a2"", ""b1"", ""c1""]).str.extractall(two_groups)
Out[129]: 
        letter digit
  match             
0 0          a     1
  1          a     2
1 0          b     1
2 0          c     1

In [130]: pd.Series([""a1a2"", ""b1"", ""c1""], dtype=""string"").str.extractall(two_groups)
Out[130]: 
        letter digit
  match             
0 0          a     1
  1          a     2
1 0          b     1
2 0          c     1
",https://pandas.pydata.org/docs/user_guide/text.html, pandas.Index pandas.Series.str.extractall pandas.Series
"In [131]: pattern = r""[0-9][a-z]""

In [132]: pd.Series(
   .....:     [""1"", ""2"", ""3a"", ""3b"", ""03c"", ""4dx""],
   .....:     dtype=""string"",
   .....: ).str.contains(pattern)
   .....: 
Out[132]: 
0    False
1    False
2     True
3     True
4     True
5     True
dtype: boolean
",https://pandas.pydata.org/docs/user_guide/text.html, pandas.Series
"In [133]: pd.Series(
   .....:     [""1"", ""2"", ""3a"", ""3b"", ""03c"", ""4dx""],
   .....:     dtype=""string"",
   .....: ).str.match(pattern)
   .....: 
Out[133]: 
0    False
1    False
2     True
3     True
4    False
5     True
dtype: boolean
",https://pandas.pydata.org/docs/user_guide/text.html, pandas.Series pandas.Series.str.match
"In [134]: pd.Series(
   .....:     [""1"", ""2"", ""3a"", ""3b"", ""03c"", ""4dx""],
   .....:     dtype=""string"",
   .....: ).str.fullmatch(pattern)
   .....: 
Out[134]: 
0    False
1    False
2     True
3     True
4    False
5    False
dtype: boolean
",https://pandas.pydata.org/docs/user_guide/text.html, pandas.Series pandas.Series.str.fullmatch
"In [135]: s4 = pd.Series(
   .....:     [""A"", ""B"", ""C"", ""Aaba"", ""Baca"", np.nan, ""CABA"", ""dog"", ""cat""], dtype=""string""
   .....: )
   .....: 

In [136]: s4.str.contains(""A"", na=False)
Out[136]: 
0     True
1    False
2    False
3     True
4    False
5    False
6     True
7    False
8    False
dtype: boolean
",https://pandas.pydata.org/docs/user_guide/text.html, pandas.Series pandas.Series.str.contains
"In [137]: s = pd.Series([""a"", ""a|b"", np.nan, ""a|c""], dtype=""string"")

In [138]: s.str.get_dummies(sep=""|"")
Out[138]: 
   a  b  c
0  1  0  0
1  1  1  0
2  0  0  0
3  1  0  1
",https://pandas.pydata.org/docs/user_guide/text.html, pandas.Series pandas.Series.str.get_dummies
"In [139]: idx = pd.Index([""a"", ""a|b"", np.nan, ""a|c""])

In [140]: idx.str.get_dummies(sep=""|"")
Out[140]: 
MultiIndex([(1, 0, 0),
            (1, 1, 0),
            (0, 0, 0),
            (1, 0, 1)],
           names=['a', 'b', 'c'])
",https://pandas.pydata.org/docs/user_guide/text.html, pandas.Index pandas.MultiIndex
">>> spacing = np.linspace(-9 * np.pi, 9 * np.pi, num=1000)
>>> s = pd.Series(0.7 * np.random.rand(1000) + 0.3 * np.sin(spacing))
>>> pd.plotting.autocorrelation_plot(s)  
",https://pandas.pydata.org/docs/reference/api/pandas.plotting.autocorrelation_plot.html, pandas.Series pandas.plotting.autocorrelation_plot
"In [1]: arr = np.random.randn(10)

In [2]: arr[2:-2] = np.nan

In [3]: ts = pd.Series(pd.arrays.SparseArray(arr))

In [4]: ts
Out[4]: 
0    0.469112
1   -0.282863
2         NaN
3         NaN
4         NaN
5         NaN
6         NaN
7         NaN
8   -0.861849
9   -2.104569
dtype: Sparse[float64, nan]
",https://pandas.pydata.org/docs/user_guide/sparse.html, pandas.Series pandas.arrays.SparseArray
"In [5]: df = pd.DataFrame(np.random.randn(10000, 4))

In [6]: df.iloc[:9998] = np.nan

In [7]: sdf = df.astype(pd.SparseDtype(""float"", np.nan))

In [8]: sdf.head()
Out[8]: 
     0    1    2    3
0  NaN  NaN  NaN  NaN
1  NaN  NaN  NaN  NaN
2  NaN  NaN  NaN  NaN
3  NaN  NaN  NaN  NaN
4  NaN  NaN  NaN  NaN

In [9]: sdf.dtypes
Out[9]: 
0    Sparse[float64, nan]
1    Sparse[float64, nan]
2    Sparse[float64, nan]
3    Sparse[float64, nan]
dtype: object

In [10]: sdf.sparse.density
Out[10]: 0.0002
",https://pandas.pydata.org/docs/user_guide/sparse.html, pandas.DataFrame pandas.DataFrame.astype
"In [11]: 'dense : {:0.2f} bytes'.format(df.memory_usage().sum() / 1e3)
Out[11]: 'dense : 320.13 bytes'

In [12]: 'sparse: {:0.2f} bytes'.format(sdf.memory_usage().sum() / 1e3)
Out[12]: 'sparse: 0.22 bytes'
",https://pandas.pydata.org/docs/user_guide/sparse.html, pandas.io.formats.style.Styler.format pandas.DataFrame.memory_usage
"In [13]: arr = np.random.randn(10)

In [14]: arr[2:5] = np.nan

In [15]: arr[7:8] = np.nan

In [16]: sparr = pd.arrays.SparseArray(arr)

In [17]: sparr
Out[17]: 
[-1.9556635297215477, -1.6588664275960427, nan, nan, nan, 1.1589328886422277, 0.14529711373305043, nan, 0.6060271905134522, 1.3342113401317768]
Fill: nan
IntIndex
Indices: array([0, 1, 5, 6, 8, 9], dtype=int32)
",https://pandas.pydata.org/docs/user_guide/sparse.html, pandas.arrays.SparseArray pandas.array
"In [18]: np.asarray(sparr)
Out[18]: 
array([-1.9557, -1.6589,     nan,     nan,     nan,  1.1589,  0.1453,
           nan,  0.606 ,  1.3342])
",https://pandas.pydata.org/docs/user_guide/sparse.html, pandas.array
"In [22]: pd.array([1, 0, 0, 2], dtype='Sparse[int]')
Out[22]: 
[1, 0, 0, 2]
Fill: 0
IntIndex
Indices: array([0, 3], dtype=int32)
",https://pandas.pydata.org/docs/user_guide/sparse.html, pandas.array pandas.array
"In [23]: s = pd.Series([0, 0, 1, 2], dtype=""Sparse[int]"")

In [24]: s.sparse.density
Out[24]: 0.5

In [25]: s.sparse.fill_value
Out[25]: 0
",https://pandas.pydata.org/docs/user_guide/sparse.html, pandas.Series
"In [26]: arr = pd.arrays.SparseArray([1., np.nan, np.nan, -2., np.nan])

In [27]: np.abs(arr)
Out[27]: 
[1.0, nan, nan, 2.0, nan]
Fill: nan
IntIndex
Indices: array([0, 3], dtype=int32)
",https://pandas.pydata.org/docs/user_guide/sparse.html, pandas.arrays.SparseArray pandas.array
"In [28]: arr = pd.arrays.SparseArray([1., -1, -1, -2., -1], fill_value=-1)

In [29]: np.abs(arr)
Out[29]: 
[1, 1, 1, 2.0, 1]
Fill: 1
IntIndex
Indices: array([3], dtype=int32)

In [30]: np.abs(arr).to_dense()
Out[30]: array([1., 1., 1., 2., 1.])
",https://pandas.pydata.org/docs/user_guide/sparse.html, pandas.arrays.SparseArray pandas.array pandas.DataFrame.sparse.to_dense
"In [32]: dense = pd.DataFrame({""A"": [1, 0, 0, 1]})

In [33]: dtype = pd.SparseDtype(int, fill_value=0)

In [34]: dense.astype(dtype)
Out[34]: 
   A
0  1
1  0
2  0
3  1
",https://pandas.pydata.org/docs/user_guide/sparse.html, pandas.DataFrame pandas.DataFrame.astype
"In [35]: from scipy.sparse import csr_matrix

In [36]: arr = np.random.random(size=(1000, 5))

In [37]: arr[arr < .9] = 0

In [38]: sp_arr = csr_matrix(arr)

In [39]: sp_arr
Out[39]: 
<1000x5 sparse matrix of type ''
	with 517 stored elements in Compressed Sparse Row format>

In [40]: sdf = pd.DataFrame.sparse.from_spmatrix(sp_arr)

In [41]: sdf.head()
Out[41]: 
          0  1  2         3  4
0   0.95638  0  0         0  0
1         0  0  0         0  0
2         0  0  0         0  0
3         0  0  0         0  0
4  0.999552  0  0  0.956153  0

In [42]: sdf.dtypes
Out[42]: 
0    Sparse[float64, 0]
1    Sparse[float64, 0]
2    Sparse[float64, 0]
3    Sparse[float64, 0]
4    Sparse[float64, 0]
dtype: object
",https://pandas.pydata.org/docs/user_guide/sparse.html, pandas.DataFrame.sparse.from_spmatrix
"In [44]: s = pd.Series([3.0, np.nan, 1.0, 3.0, np.nan, np.nan])

In [45]: s.index = pd.MultiIndex.from_tuples(
   ....:     [
   ....:         (1, 2, ""a"", 0),
   ....:         (1, 2, ""a"", 1),
   ....:         (1, 1, ""b"", 0),
   ....:         (1, 1, ""b"", 1),
   ....:         (2, 1, ""b"", 0),
   ....:         (2, 1, ""b"", 1),
   ....:     ],
   ....:     names=[""A"", ""B"", ""C"", ""D""],
   ....: )
   ....: 

In [46]: ss = s.astype('Sparse')

In [47]: ss
Out[47]: 
A  B  C  D
1  2  a  0    3.0
         1    NaN
   1  b  0    1.0
         1    3.0
2  1  b  0    NaN
         1    NaN
dtype: Sparse[float64, nan]
",https://pandas.pydata.org/docs/user_guide/sparse.html, pandas.Series pandas.MultiIndex.from_tuples pandas.Series.astype
"In [62]: ss = pd.Series.sparse.from_coo(A)

In [63]: ss
Out[63]: 
0  2    1.0
   3    2.0
1  0    3.0
dtype: Sparse[float64, nan]
",https://pandas.pydata.org/docs/user_guide/sparse.html, pandas.Series.sparse.from_coo
"In [64]: ss_dense = pd.Series.sparse.from_coo(A, dense_index=True)

In [65]: ss_dense
Out[65]: 
1  0    3.0
   2    NaN
   3    NaN
0  0    NaN
   2    1.0
   3    2.0
   0    NaN
   2    1.0
   3    2.0
dtype: Sparse[float64, nan]
",https://pandas.pydata.org/docs/user_guide/sparse.html, pandas.Series.sparse.from_coo
"In [1]: arr = pd.array([1, 2, None], dtype=pd.Int64Dtype())

In [2]: arr
Out[2]: 

[1, 2, ]
Length: 3, dtype: Int64
",https://pandas.pydata.org/docs/user_guide/integer_na.html, pandas.array pandas.Int64Dtype
"In [3]: pd.array([1, 2, np.nan], dtype=""Int64"")
Out[3]: 

[1, 2, ]
Length: 3, dtype: Int64
",https://pandas.pydata.org/docs/user_guide/integer_na.html, pandas.array
"In [4]: pd.array([1, 2, np.nan, None, pd.NA], dtype=""Int64"")
Out[4]: 

[1, 2, , , ]
Length: 5, dtype: Int64
",https://pandas.pydata.org/docs/user_guide/integer_na.html, pandas.array
"In [5]: pd.Series(arr)
Out[5]: 
0       1
1       2
2    
dtype: Int64
",https://pandas.pydata.org/docs/user_guide/integer_na.html, pandas.Series
"In [6]: pd.array([1, None])
Out[6]: 

[1, ]
Length: 2, dtype: Int64

In [7]: pd.array([1, 2])
Out[7]: 

[1, 2]
Length: 2, dtype: Int64
",https://pandas.pydata.org/docs/user_guide/integer_na.html, pandas.array
"In [8]: pd.Series([1, None])
Out[8]: 
0    1.0
1    NaN
dtype: float64

In [9]: pd.Series([1, 2])
Out[9]: 
0    1
1    2
dtype: int64
",https://pandas.pydata.org/docs/user_guide/integer_na.html, pandas.Series
"In [10]: pd.array([1, None], dtype=""Int64"")
Out[10]: 

[1, ]
Length: 2, dtype: Int64

In [11]: pd.Series([1, None], dtype=""Int64"")
Out[11]: 
0       1
1    
dtype: Int64
",https://pandas.pydata.org/docs/user_guide/integer_na.html, pandas.array pandas.Series
"In [12]: s = pd.Series([1, 2, None], dtype=""Int64"")

# arithmetic
In [13]: s + 1
Out[13]: 
0       2
1       3
2    
dtype: Int64

# comparison
In [14]: s == 1
Out[14]: 
0     True
1    False
2     
dtype: boolean

# slicing operation
In [15]: s.iloc[1:3]
Out[15]: 
1       2
2    
dtype: Int64

# operate with other dtypes
In [16]: s + s.iloc[1:3].astype(""Int8"")
Out[16]: 
0    
1       4
2    
dtype: Int64

# coerce when needed
In [17]: s + 0.01
Out[17]: 
0    1.01
1    2.01
2    
dtype: Float64
",https://pandas.pydata.org/docs/user_guide/integer_na.html, pandas.Series
"In [18]: df = pd.DataFrame({""A"": s, ""B"": [1, 1, 3], ""C"": list(""aab"")})

In [19]: df
Out[19]: 
      A  B  C
0     1  1  a
1     2  1  a
2    3  b

In [20]: df.dtypes
Out[20]: 
A     Int64
B     int64
C    object
dtype: object
",https://pandas.pydata.org/docs/user_guide/integer_na.html, pandas.DataFrame
"In [21]: pd.concat([df[[""A""]], df[[""B"", ""C""]]], axis=1).dtypes
Out[21]: 
A     Int64
B     int64
C    object
dtype: object

In [22]: df[""A""].astype(float)
Out[22]: 
0    1.0
1    2.0
2    NaN
Name: A, dtype: float64
",https://pandas.pydata.org/docs/user_guide/integer_na.html, pandas.concat
"In [23]: df.sum(numeric_only=True)
Out[23]: 
A    3
B    5
dtype: Int64

In [24]: df.sum()
Out[24]: 
A      3
B      5
C    aab
dtype: object

In [25]: df.groupby(""B"").A.sum()
Out[25]: 
B
1    3
3    0
Name: A, dtype: Int64
",https://pandas.pydata.org/docs/user_guide/integer_na.html, pandas.DataFrame.sum pandas.DataFrame.groupby
"In [26]: a = pd.array([1, None], dtype=""Int64"")

In [27]: a[1]
Out[27]: 
",https://pandas.pydata.org/docs/user_guide/integer_na.html, pandas.array
"In [1]: index = pd.date_range(""1/1/2000"", periods=8)

In [2]: s = pd.Series(np.random.randn(5), index=[""a"", ""b"", ""c"", ""d"", ""e""])

In [3]: df = pd.DataFrame(np.random.randn(8, 3), index=index, columns=[""A"", ""B"", ""C""])
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.date_range pandas.Series pandas.DataFrame
"In [4]: long_series = pd.Series(np.random.randn(1000))

In [5]: long_series.head()
Out[5]: 
0   -1.157892
1   -1.344312
2    0.844885
3    1.075770
4   -0.109050
dtype: float64

In [6]: long_series.tail(3)
Out[6]: 
997   -0.289388
998   -1.020544
999    0.589993
dtype: float64
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.Series pandas.Series.head pandas.Series.tail
"In [7]: df[:2]
Out[7]: 
                   A         B         C
2000-01-01 -0.173215  0.119209 -1.044236
2000-01-02 -0.861849 -2.104569 -0.494929

In [8]: df.columns = [x.lower() for x in df.columns]

In [9]: df
Out[9]: 
                   a         b         c
2000-01-01 -0.173215  0.119209 -1.044236
2000-01-02 -0.861849 -2.104569 -0.494929
2000-01-03  1.071804  0.721555 -0.706771
2000-01-04 -1.039575  0.271860 -0.424972
2000-01-05  0.567020  0.276232 -1.087401
2000-01-06 -0.673690  0.113648 -1.478427
2000-01-07  0.524988  0.404705  0.577046
2000-01-08 -1.715002 -1.039268 -0.370647
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.Series.str.lower
"In [12]: s.to_numpy()
Out[12]: array([ 0.4691, -0.2829, -1.5091, -1.1356,  1.2121])

In [13]: np.asarray(s)
Out[13]: array([ 0.4691, -0.2829, -1.5091, -1.1356,  1.2121])
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.Series.to_numpy pandas.array
"In [14]: ser = pd.Series(pd.date_range(""2000"", periods=2, tz=""CET""))

In [15]: ser.to_numpy(dtype=object)
Out[15]: 
array([Timestamp('2000-01-01 00:00:00+0100', tz='CET'),
       Timestamp('2000-01-02 00:00:00+0100', tz='CET')], dtype=object)
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.Series pandas.date_range pandas.Series.to_numpy pandas.array
"In [16]: ser.to_numpy(dtype=""datetime64[ns]"")
Out[16]: 
array(['1999-12-31T23:00:00.000000000', '2000-01-01T23:00:00.000000000'],
      dtype='datetime64[ns]')
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.Series.to_numpy pandas.array
"In [17]: df.to_numpy()
Out[17]: 
array([[-0.1732,  0.1192, -1.0442],
       [-0.8618, -2.1046, -0.4949],
       [ 1.0718,  0.7216, -0.7068],
       [-1.0396,  0.2719, -0.425 ],
       [ 0.567 ,  0.2762, -1.0874],
       [-0.6737,  0.1136, -1.4784],
       [ 0.525 ,  0.4047,  0.577 ],
       [-1.715 , -1.0393, -0.3706]])
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame.to_numpy pandas.array
"In [18]: df = pd.DataFrame(
   ....:     {
   ....:         ""one"": pd.Series(np.random.randn(3), index=[""a"", ""b"", ""c""]),
   ....:         ""two"": pd.Series(np.random.randn(4), index=[""a"", ""b"", ""c"", ""d""]),
   ....:         ""three"": pd.Series(np.random.randn(3), index=[""b"", ""c"", ""d""]),
   ....:     }
   ....: )
   ....: 

In [19]: df
Out[19]: 
        one       two     three
a  1.394981  1.772517       NaN
b  0.343054  1.912123 -0.050390
c  0.695246  1.478369  1.227435
d       NaN  0.279344 -0.613172

In [20]: row = df.iloc[1]

In [21]: column = df[""two""]

In [22]: df.sub(row, axis=""columns"")
Out[22]: 
        one       two     three
a  1.051928 -0.139606       NaN
b  0.000000  0.000000  0.000000
c  0.352192 -0.433754  1.277825
d       NaN -1.632779 -0.562782

In [23]: df.sub(row, axis=1)
Out[23]: 
        one       two     three
a  1.051928 -0.139606       NaN
b  0.000000  0.000000  0.000000
c  0.352192 -0.433754  1.277825
d       NaN -1.632779 -0.562782

In [24]: df.sub(column, axis=""index"")
Out[24]: 
        one  two     three
a -0.377535  0.0       NaN
b -1.569069  0.0 -1.962513
c -0.783123  0.0 -0.250933
d       NaN  0.0 -0.892516

In [25]: df.sub(column, axis=0)
Out[25]: 
        one  two     three
a -0.377535  0.0       NaN
b -1.569069  0.0 -1.962513
c -0.783123  0.0 -0.250933
d       NaN  0.0 -0.892516
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame pandas.Series pandas.DataFrame.sub
"In [26]: dfmi = df.copy()

In [27]: dfmi.index = pd.MultiIndex.from_tuples(
   ....:     [(1, ""a""), (1, ""b""), (1, ""c""), (2, ""a"")], names=[""first"", ""second""]
   ....: )
   ....: 

In [28]: dfmi.sub(column, axis=0, level=""second"")
Out[28]: 
                   one       two     three
first second                              
1     a      -0.377535  0.000000       NaN
      b      -1.569069  0.000000 -1.962513
      c      -0.783123  0.000000 -0.250933
2     a            NaN -1.493173 -2.385688
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame.copy pandas.MultiIndex.from_tuples
"In [29]: s = pd.Series(np.arange(10))

In [30]: s
Out[30]: 
0    0
1    1
2    2
3    3
4    4
5    5
6    6
7    7
8    8
9    9
dtype: int64

In [31]: div, rem = divmod(s, 3)

In [32]: div
Out[32]: 
0    0
1    0
2    0
3    1
4    1
5    1
6    2
7    2
8    2
9    3
dtype: int64

In [33]: rem
Out[33]: 
0    0
1    1
2    2
3    0
4    1
5    2
6    0
7    1
8    2
9    0
dtype: int64

In [34]: idx = pd.Index(np.arange(10))

In [35]: idx
Out[35]: Index([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype='int64')

In [36]: div, rem = divmod(idx, 3)

In [37]: div
Out[37]: Index([0, 0, 0, 1, 1, 1, 2, 2, 2, 3], dtype='int64')

In [38]: rem
Out[38]: Index([0, 1, 2, 0, 1, 2, 0, 1, 2, 0], dtype='int64')
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.Series pandas.Index pandas.Index
"In [42]: df2 = df.copy()

In [43]: df2.loc[""a"", ""three""] = 1.0

In [44]: df
Out[44]: 
        one       two     three
a  1.394981  1.772517       NaN
b  0.343054  1.912123 -0.050390
c  0.695246  1.478369  1.227435
d       NaN  0.279344 -0.613172

In [45]: df2
Out[45]: 
        one       two     three
a  1.394981  1.772517  1.000000
b  0.343054  1.912123 -0.050390
c  0.695246  1.478369  1.227435
d       NaN  0.279344 -0.613172

In [46]: df + df2
Out[46]: 
        one       two     three
a  2.789963  3.545034       NaN
b  0.686107  3.824246 -0.100780
c  1.390491  2.956737  2.454870
d       NaN  0.558688 -1.226343

In [47]: df.add(df2, fill_value=0)
Out[47]: 
        one       two     three
a  2.789963  3.545034  1.000000
b  0.686107  3.824246 -0.100780
c  1.390491  2.956737  2.454870
d       NaN  0.558688 -1.226343
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame.copy pandas.DataFrame.add
"In [48]: df.gt(df2)
Out[48]: 
     one    two  three
a  False  False  False
b  False  False  False
c  False  False  False
d  False  False  False

In [49]: df2.ne(df)
Out[49]: 
     one    two  three
a  False  False   True
b  False  False  False
c  False  False  False
d   True  False  False
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame.gt pandas.DataFrame.ne
"In [53]: df.empty
Out[53]: False

In [54]: pd.DataFrame(columns=list(""ABC"")).empty
Out[54]: True
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame
"In [55]: if df:
   ....:     print(True)
   ....: 
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
 in ?()
----> 1 if df:
      2     print(True)

~/work/pandas/pandas/pandas/core/generic.py in ?(self)
   1575     @final
   1576     def __nonzero__(self) -> NoReturn:
-> 1577         raise ValueError(
   1578             f""The truth value of a {type(self).__name__} is ambiguous. ""
   1579             ""Use a.empty, a.bool(), a.item(), a.any() or a.all().""
   1580         )

ValueError: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.Series.bool pandas.Series.item pandas.Series.any pandas.Series.all
"In [56]: df and df2
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
 in ?()
----> 1 df and df2

~/work/pandas/pandas/pandas/core/generic.py in ?(self)
   1575     @final
   1576     def __nonzero__(self) -> NoReturn:
-> 1577         raise ValueError(
   1578             f""The truth value of a {type(self).__name__} is ambiguous. ""
   1579             ""Use a.empty, a.bool(), a.item(), a.any() or a.all().""
   1580         )

ValueError: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.Series.bool pandas.Series.item pandas.Series.any pandas.Series.all
"In [61]: df1 = pd.DataFrame({""col"": [""foo"", 0, np.nan]})

In [62]: df2 = pd.DataFrame({""col"": [np.nan, 0, ""foo""]}, index=[2, 1, 0])

In [63]: df1.equals(df2)
Out[63]: False

In [64]: df1.equals(df2.sort_index())
Out[64]: True
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame pandas.DataFrame.equals pandas.DataFrame.sort_index
"In [65]: pd.Series([""foo"", ""bar"", ""baz""]) == ""foo""
Out[65]: 
0     True
1    False
2    False
dtype: bool

In [66]: pd.Index([""foo"", ""bar"", ""baz""]) == ""foo""
Out[66]: array([ True, False, False])
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.Series pandas.Index pandas.array
"In [67]: pd.Series([""foo"", ""bar"", ""baz""]) == pd.Index([""foo"", ""bar"", ""qux""])
Out[67]: 
0     True
1     True
2    False
dtype: bool

In [68]: pd.Series([""foo"", ""bar"", ""baz""]) == np.array([""foo"", ""bar"", ""qux""])
Out[68]: 
0     True
1     True
2    False
dtype: bool
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.Series pandas.Index
"In [69]: pd.Series(['foo', 'bar', 'baz']) == pd.Series(['foo', 'bar'])
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
Cell In[69], line 1
----> 1 pd.Series(['foo', 'bar', 'baz']) == pd.Series(['foo', 'bar'])

File ~/work/pandas/pandas/pandas/core/ops/common.py:76, in _unpack_zerodim_and_defer..new_method(self, other)
     72             return NotImplemented
     74 other = item_from_zerodim(other)
---> 76 return method(self, other)

File ~/work/pandas/pandas/pandas/core/arraylike.py:40, in OpsMixin.__eq__(self, other)
     38 @unpack_zerodim_and_defer(""__eq__"")
     39 def __eq__(self, other):
---> 40     return self._cmp_method(other, operator.eq)

File ~/work/pandas/pandas/pandas/core/series.py:6114, in Series._cmp_method(self, other, op)
   6111 res_name = ops.get_op_result_name(self, other)
   6113 if isinstance(other, Series) and not self._indexed_same(other):
-> 6114     raise ValueError(""Can only compare identically-labeled Series objects"")
   6116 lvalues = self._values
   6117 rvalues = extract_array(other, extract_numpy=True, extract_range=True)

ValueError: Can only compare identically-labeled Series objects

In [70]: pd.Series(['foo', 'bar', 'baz']) == pd.Series(['foo'])
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
Cell In[70], line 1
----> 1 pd.Series(['foo', 'bar', 'baz']) == pd.Series(['foo'])

File ~/work/pandas/pandas/pandas/core/ops/common.py:76, in _unpack_zerodim_and_defer..new_method(self, other)
     72             return NotImplemented
     74 other = item_from_zerodim(other)
---> 76 return method(self, other)

File ~/work/pandas/pandas/pandas/core/arraylike.py:40, in OpsMixin.__eq__(self, other)
     38 @unpack_zerodim_and_defer(""__eq__"")
     39 def __eq__(self, other):
---> 40     return self._cmp_method(other, operator.eq)

File ~/work/pandas/pandas/pandas/core/series.py:6114, in Series._cmp_method(self, other, op)
   6111 res_name = ops.get_op_result_name(self, other)
   6113 if isinstance(other, Series) and not self._indexed_same(other):
-> 6114     raise ValueError(""Can only compare identically-labeled Series objects"")
   6116 lvalues = self._values
   6117 rvalues = extract_array(other, extract_numpy=True, extract_range=True)

ValueError: Can only compare identically-labeled Series objects
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.Series
"In [71]: df1 = pd.DataFrame(
   ....:     {""A"": [1.0, np.nan, 3.0, 5.0, np.nan], ""B"": [np.nan, 2.0, 3.0, np.nan, 6.0]}
   ....: )
   ....: 

In [72]: df2 = pd.DataFrame(
   ....:     {
   ....:         ""A"": [5.0, 2.0, 4.0, np.nan, 3.0, 7.0],
   ....:         ""B"": [np.nan, np.nan, 3.0, 4.0, 6.0, 8.0],
   ....:     }
   ....: )
   ....: 

In [73]: df1
Out[73]: 
     A    B
0  1.0  NaN
1  NaN  2.0
2  3.0  3.0
3  5.0  NaN
4  NaN  6.0

In [74]: df2
Out[74]: 
     A    B
0  5.0  NaN
1  2.0  NaN
2  4.0  3.0
3  NaN  4.0
4  3.0  6.0
5  7.0  8.0

In [75]: df1.combine_first(df2)
Out[75]: 
     A    B
0  1.0  NaN
1  2.0  2.0
2  3.0  3.0
3  5.0  4.0
4  3.0  6.0
5  7.0  8.0
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame pandas.DataFrame.combine_first
"In [76]: def combiner(x, y):
   ....:     return np.where(pd.isna(x), y, x)
   ....: 

In [77]: df1.combine(df2, combiner)
Out[77]: 
     A    B
0  1.0  NaN
1  2.0  2.0
2  3.0  3.0
3  5.0  4.0
4  3.0  6.0
5  7.0  8.0
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.isna pandas.DataFrame.combine
"In [78]: df
Out[78]: 
        one       two     three
a  1.394981  1.772517       NaN
b  0.343054  1.912123 -0.050390
c  0.695246  1.478369  1.227435
d       NaN  0.279344 -0.613172

In [79]: df.mean(0)
Out[79]: 
one      0.811094
two      1.360588
three    0.187958
dtype: float64

In [80]: df.mean(1)
Out[80]: 
a    1.583749
b    0.734929
c    1.133683
d   -0.166914
dtype: float64
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame.mean
"In [81]: df.sum(0, skipna=False)
Out[81]: 
one           NaN
two      5.442353
three         NaN
dtype: float64

In [82]: df.sum(axis=1, skipna=True)
Out[82]: 
a    3.167498
b    2.204786
c    3.401050
d   -0.333828
dtype: float64
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame.sum
"In [83]: ts_stand = (df - df.mean()) / df.std()

In [84]: ts_stand.std()
Out[84]: 
one      1.0
two      1.0
three    1.0
dtype: float64

In [85]: xs_stand = df.sub(df.mean(1), axis=0).div(df.std(1), axis=0)

In [86]: xs_stand.std(1)
Out[86]: 
a    1.0
b    1.0
c    1.0
d    1.0
dtype: float64
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame.mean pandas.DataFrame.std pandas.DataFrame.sub
"In [87]: df.cumsum()
Out[87]: 
        one       two     three
a  1.394981  1.772517       NaN
b  1.738035  3.684640 -0.050390
c  2.433281  5.163008  1.177045
d       NaN  5.442353  0.563873
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame.cumsum
"In [90]: series = pd.Series(np.random.randn(500))

In [91]: series[20:500] = np.nan

In [92]: series[10:20] = 5

In [93]: series.nunique()
Out[93]: 11
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.Series pandas.Series.nunique
"In [94]: series = pd.Series(np.random.randn(1000))

In [95]: series[::2] = np.nan

In [96]: series.describe()
Out[96]: 
count    500.000000
mean      -0.021292
std        1.015906
min       -2.683763
25%       -0.699070
50%       -0.069718
75%        0.714483
max        3.160915
dtype: float64

In [97]: frame = pd.DataFrame(np.random.randn(1000, 5), columns=[""a"", ""b"", ""c"", ""d"", ""e""])

In [98]: frame.iloc[::2] = np.nan

In [99]: frame.describe()
Out[99]: 
                a           b           c           d           e
count  500.000000  500.000000  500.000000  500.000000  500.000000
mean     0.033387    0.030045   -0.043719   -0.051686    0.005979
std      1.017152    0.978743    1.025270    1.015988    1.006695
min     -3.000951   -2.637901   -3.303099   -3.159200   -3.188821
25%     -0.647623   -0.576449   -0.712369   -0.691338   -0.691115
50%      0.047578   -0.021499   -0.023888   -0.032652   -0.025363
75%      0.729907    0.775880    0.618896    0.670047    0.649748
max      2.740139    2.752332    3.004229    2.728702    3.240991
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.Series pandas.Series.describe pandas.DataFrame pandas.DataFrame.describe
"In [100]: series.describe(percentiles=[0.05, 0.25, 0.75, 0.95])
Out[100]: 
count    500.000000
mean      -0.021292
std        1.015906
min       -2.683763
5%        -1.645423
25%       -0.699070
50%       -0.069718
75%        0.714483
95%        1.711409
max        3.160915
dtype: float64
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.Series.describe
"In [101]: s = pd.Series([""a"", ""a"", ""b"", ""b"", ""a"", ""a"", np.nan, ""c"", ""d"", ""a""])

In [102]: s.describe()
Out[102]: 
count     9
unique    4
top       a
freq      5
dtype: object
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.Series pandas.Series.describe
"In [103]: frame = pd.DataFrame({""a"": [""Yes"", ""Yes"", ""No"", ""No""], ""b"": range(4)})

In [104]: frame.describe()
Out[104]: 
              b
count  4.000000
mean   1.500000
std    1.290994
min    0.000000
25%    0.750000
50%    1.500000
75%    2.250000
max    3.000000
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame pandas.DataFrame.describe
"In [105]: frame.describe(include=[""object""])
Out[105]: 
          a
count     4
unique    2
top     Yes
freq      2

In [106]: frame.describe(include=[""number""])
Out[106]: 
              b
count  4.000000
mean   1.500000
std    1.290994
min    0.000000
25%    0.750000
50%    1.500000
75%    2.250000
max    3.000000

In [107]: frame.describe(include=""all"")
Out[107]: 
          a         b
count     4  4.000000
unique    2       NaN
top     Yes       NaN
freq      2       NaN
mean    NaN  1.500000
std     NaN  1.290994
min     NaN  0.000000
25%     NaN  0.750000
50%     NaN  1.500000
75%     NaN  2.250000
max     NaN  3.000000
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame.describe
"In [108]: s1 = pd.Series(np.random.randn(5))

In [109]: s1
Out[109]: 
0    1.118076
1   -0.352051
2   -1.242883
3   -1.277155
4   -0.641184
dtype: float64

In [110]: s1.idxmin(), s1.idxmax()
Out[110]: (3, 0)

In [111]: df1 = pd.DataFrame(np.random.randn(5, 3), columns=[""A"", ""B"", ""C""])

In [112]: df1
Out[112]: 
          A         B         C
0 -0.327863 -0.946180 -0.137570
1 -0.186235 -0.257213 -0.486567
2 -0.507027 -0.871259 -0.111110
3  2.000339 -2.430505  0.089759
4 -0.321434 -0.033695  0.096271

In [113]: df1.idxmin(axis=0)
Out[113]: 
A    2
B    3
C    1
dtype: int64

In [114]: df1.idxmax(axis=1)
Out[114]: 
0    C
1    A
2    C
3    A
4    C
dtype: object
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.Series pandas.Series.idxmin pandas.Series.idxmax pandas.DataFrame pandas.DataFrame.idxmin pandas.DataFrame.idxmax
"In [115]: df3 = pd.DataFrame([2, 1, 1, 3, np.nan], columns=[""A""], index=list(""edcba""))

In [116]: df3
Out[116]: 
     A
e  2.0
d  1.0
c  1.0
b  3.0
a  NaN

In [117]: df3[""A""].idxmin()
Out[117]: 'd'
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame
"In [118]: data = np.random.randint(0, 7, size=50)

In [119]: data
Out[119]: 
array([6, 6, 2, 3, 5, 3, 2, 5, 4, 5, 4, 3, 4, 5, 0, 2, 0, 4, 2, 0, 3, 2,
       2, 5, 6, 5, 3, 4, 6, 4, 3, 5, 6, 4, 3, 6, 2, 6, 6, 2, 3, 4, 2, 1,
       6, 2, 6, 1, 5, 4])

In [120]: s = pd.Series(data)

In [121]: s.value_counts()
Out[121]: 
6    10
2    10
4     9
3     8
5     8
0     3
1     2
Name: count, dtype: int64
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.array pandas.Series pandas.Series.value_counts
"In [122]: data = {""a"": [1, 2, 3, 4], ""b"": [""x"", ""x"", ""y"", ""y""]}

In [123]: frame = pd.DataFrame(data)

In [124]: frame.value_counts()
Out[124]: 
a  b
1  x    1
2  x    1
3  y    1
4  y    1
Name: count, dtype: int64
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame pandas.DataFrame.value_counts
"In [125]: s5 = pd.Series([1, 1, 3, 3, 3, 5, 5, 7, 7, 7])

In [126]: s5.mode()
Out[126]: 
0    3
1    7
dtype: int64

In [127]: df5 = pd.DataFrame(
   .....:     {
   .....:         ""A"": np.random.randint(0, 7, size=50),
   .....:         ""B"": np.random.randint(-10, 15, size=50),
   .....:     }
   .....: )
   .....: 

In [128]: df5.mode()
Out[128]: 
     A   B
0  1.0  -9
1  NaN  10
2  NaN  13
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.Series pandas.Series.mode pandas.DataFrame pandas.DataFrame.mode
"In [129]: arr = np.random.randn(20)

In [130]: factor = pd.cut(arr, 4)

In [131]: factor
Out[131]: 
[(-0.251, 0.464], (-0.968, -0.251], (0.464, 1.179], (-0.251, 0.464], (-0.968, -0.251], ..., (-0.251, 0.464], (-0.968, -0.251], (-0.968, -0.251], (-0.968, -0.251], (-0.968, -0.251]]
Length: 20
Categories (4, interval[float64, right]): [(-0.968, -0.251] < (-0.251, 0.464] < (0.464, 1.179] <
                                           (1.179, 1.893]]

In [132]: factor = pd.cut(arr, [-5, -1, 0, 1, 5])

In [133]: factor
Out[133]: 
[(0, 1], (-1, 0], (0, 1], (0, 1], (-1, 0], ..., (-1, 0], (-1, 0], (-1, 0], (-1, 0], (-1, 0]]
Length: 20
Categories (4, interval[int64, right]): [(-5, -1] < (-1, 0] < (0, 1] < (1, 5]]
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.cut
"In [134]: arr = np.random.randn(30)

In [135]: factor = pd.qcut(arr, [0, 0.25, 0.5, 0.75, 1])

In [136]: factor
Out[136]: 
[(0.569, 1.184], (-2.278, -0.301], (-2.278, -0.301], (0.569, 1.184], (0.569, 1.184], ..., (-0.301, 0.569], (1.184, 2.346], (1.184, 2.346], (-0.301, 0.569], (-2.278, -0.301]]
Length: 30
Categories (4, interval[float64, right]): [(-2.278, -0.301] < (-0.301, 0.569] < (0.569, 1.184] <
                                           (1.184, 2.346]]
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.qcut
"In [137]: arr = np.random.randn(20)

In [138]: factor = pd.cut(arr, [-np.inf, 0, np.inf])

In [139]: factor
Out[139]: 
[(-inf, 0.0], (0.0, inf], (0.0, inf], (-inf, 0.0], (-inf, 0.0], ..., (-inf, 0.0], (-inf, 0.0], (-inf, 0.0], (0.0, inf], (0.0, inf]]
Length: 20
Categories (2, interval[float64, right]): [(-inf, 0.0] < (0.0, inf]]
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.cut
"In [140]: def extract_city_name(df):
   .....:     """"""
   .....:     Chicago, IL -> Chicago for city_name column
   .....:     """"""
   .....:     df[""city_name""] = df[""city_and_code""].str.split("","").str.get(0)
   .....:     return df
   .....: 

In [141]: def add_country_name(df, country_name=None):
   .....:     """"""
   .....:     Chicago -> Chicago-US for city_name column
   .....:     """"""
   .....:     col = ""city_name""
   .....:     df[""city_and_country""] = df[col] + country_name
   .....:     return df
   .....: 

In [142]: df_p = pd.DataFrame({""city_and_code"": [""Chicago, IL""]})
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.Series.str.split pandas.DataFrame
"In [144]: df_p.pipe(extract_city_name).pipe(add_country_name, country_name=""US"")
Out[144]: 
  city_and_code city_name city_and_country
0   Chicago, IL   Chicago        ChicagoUS
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame.pipe
"In [147]: import statsmodels.formula.api as sm

In [148]: bb = pd.read_csv(""data/baseball.csv"", index_col=""id"")

In [149]: (
   .....:     bb.query(""h > 0"")
   .....:     .assign(ln_h=lambda df: np.log(df.h))
   .....:     .pipe((sm.ols, ""data""), ""hr ~ ln_h + year + g + C(lg)"")
   .....:     .fit()
   .....:     .summary()
   .....: )
   .....:
Out[149]:

""""""
                           OLS Regression Results
==============================================================================
Dep. Variable:                     hr   R-squared:                       0.685
Model:                            OLS   Adj. R-squared:                  0.665
Method:                 Least Squares   F-statistic:                     34.28
Date:                Tue, 22 Nov 2022   Prob (F-statistic):           3.48e-15
Time:                        05:34:17   Log-Likelihood:                -205.92
No. Observations:                  68   AIC:                             421.8
Df Residuals:                      63   BIC:                             432.9
Df Model:                           4
Covariance Type:            nonrobust
===============================================================================
                  coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------
Intercept   -8484.7720   4664.146     -1.819      0.074   -1.78e+04     835.780
C(lg)[T.NL]    -2.2736      1.325     -1.716      0.091      -4.922       0.375
ln_h           -1.3542      0.875     -1.547      0.127      -3.103       0.395
year            4.2277      2.324      1.819      0.074      -0.417       8.872
g               0.1841      0.029      6.258      0.000       0.125       0.243
==============================================================================
Omnibus:                       10.875   Durbin-Watson:                   1.999
Prob(Omnibus):                  0.004   Jarque-Bera (JB):               17.298
Skew:                           0.537   Prob(JB):                     0.000175
Kurtosis:                       5.225   Cond. No.                     1.49e+07
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 1.49e+07. This might indicate that there are
strong multicollinearity or other numerical problems.
""""""
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.read_csv pandas.DataFrame.query pandas.DataFrame.assign
"In [145]: df.apply(lambda x: np.mean(x))
Out[145]: 
one      0.811094
two      1.360588
three    0.187958
dtype: float64

In [146]: df.apply(lambda x: np.mean(x), axis=1)
Out[146]: 
a    1.583749
b    0.734929
c    1.133683
d   -0.166914
dtype: float64

In [147]: df.apply(lambda x: x.max() - x.min())
Out[147]: 
one      1.051928
two      1.632779
three    1.840607
dtype: float64

In [148]: df.apply(np.cumsum)
Out[148]: 
        one       two     three
a  1.394981  1.772517       NaN
b  1.738035  3.684640 -0.050390
c  2.433281  5.163008  1.177045
d       NaN  5.442353  0.563873

In [149]: df.apply(np.exp)
Out[149]: 
        one       two     three
a  4.034899  5.885648       NaN
b  1.409244  6.767440  0.950858
c  2.004201  4.385785  3.412466
d       NaN  1.322262  0.541630
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame.apply
"In [150]: df.apply(""mean"")
Out[150]: 
one      0.811094
two      1.360588
three    0.187958
dtype: float64

In [151]: df.apply(""mean"", axis=1)
Out[151]: 
a    1.583749
b    0.734929
c    1.133683
d   -0.166914
dtype: float64
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame.apply
"In [152]: tsdf = pd.DataFrame(
   .....:     np.random.randn(1000, 3),
   .....:     columns=[""A"", ""B"", ""C""],
   .....:     index=pd.date_range(""1/1/2000"", periods=1000),
   .....: )
   .....: 

In [153]: tsdf.apply(lambda x: x.idxmax())
Out[153]: 
A   2000-08-06
B   2001-01-18
C   2001-07-18
dtype: datetime64[ns]
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame pandas.date_range pandas.DataFrame.apply
"In [154]: def subtract_and_divide(x, sub, divide=1):
   .....:     return (x - sub) / divide
   .....: 

In [155]: df_udf = pd.DataFrame(np.ones((2, 2)))

In [156]: df_udf.apply(subtract_and_divide, args=(5,), divide=3)
Out[156]: 
          0         1
0 -1.333333 -1.333333
1 -1.333333 -1.333333
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame pandas.DataFrame.apply
"In [157]: tsdf = pd.DataFrame(
   .....:     np.random.randn(10, 3),
   .....:     columns=[""A"", ""B"", ""C""],
   .....:     index=pd.date_range(""1/1/2000"", periods=10),
   .....: )
   .....: 

In [158]: tsdf.iloc[3:7] = np.nan

In [159]: tsdf
Out[159]: 
                   A         B         C
2000-01-01 -0.158131 -0.232466  0.321604
2000-01-02 -1.810340 -3.105758  0.433834
2000-01-03 -1.209847 -1.156793 -0.136794
2000-01-04       NaN       NaN       NaN
2000-01-05       NaN       NaN       NaN
2000-01-06       NaN       NaN       NaN
2000-01-07       NaN       NaN       NaN
2000-01-08 -0.653602  0.178875  1.008298
2000-01-09  1.007996  0.462824  0.254472
2000-01-10  0.307473  0.600337  1.643950

In [160]: tsdf.apply(pd.Series.interpolate)
Out[160]: 
                   A         B         C
2000-01-01 -0.158131 -0.232466  0.321604
2000-01-02 -1.810340 -3.105758  0.433834
2000-01-03 -1.209847 -1.156793 -0.136794
2000-01-04 -1.098598 -0.889659  0.092225
2000-01-05 -0.987349 -0.622526  0.321243
2000-01-06 -0.876100 -0.355392  0.550262
2000-01-07 -0.764851 -0.088259  0.779280
2000-01-08 -0.653602  0.178875  1.008298
2000-01-09  1.007996  0.462824  0.254472
2000-01-10  0.307473  0.600337  1.643950
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame pandas.date_range pandas.DataFrame.apply
"In [161]: tsdf = pd.DataFrame(
   .....:     np.random.randn(10, 3),
   .....:     columns=[""A"", ""B"", ""C""],
   .....:     index=pd.date_range(""1/1/2000"", periods=10),
   .....: )
   .....: 

In [162]: tsdf.iloc[3:7] = np.nan

In [163]: tsdf
Out[163]: 
                   A         B         C
2000-01-01  1.257606  1.004194  0.167574
2000-01-02 -0.749892  0.288112 -0.757304
2000-01-03 -0.207550 -0.298599  0.116018
2000-01-04       NaN       NaN       NaN
2000-01-05       NaN       NaN       NaN
2000-01-06       NaN       NaN       NaN
2000-01-07       NaN       NaN       NaN
2000-01-08  0.814347 -0.257623  0.869226
2000-01-09 -0.250663 -1.206601  0.896839
2000-01-10  2.169758 -1.333363  0.283157
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame pandas.date_range
"In [164]: tsdf.agg(lambda x: np.sum(x))
Out[164]: 
A    3.033606
B   -1.803879
C    1.575510
dtype: float64

In [165]: tsdf.agg(""sum"")
Out[165]: 
A    3.033606
B   -1.803879
C    1.575510
dtype: float64

# these are equivalent to a ``.sum()`` because we are aggregating
# on a single function
In [166]: tsdf.sum()
Out[166]: 
A    3.033606
B   -1.803879
C    1.575510
dtype: float64
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame.agg pandas.DataFrame.sum
"In [168]: tsdf.agg([""sum""])
Out[168]: 
            A         B        C
sum  3.033606 -1.803879  1.57551
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame.agg
"In [169]: tsdf.agg([""sum"", ""mean""])
Out[169]: 
             A         B         C
sum   3.033606 -1.803879  1.575510
mean  0.505601 -0.300647  0.262585
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame.agg
"In [174]: tsdf.agg({""A"": ""mean"", ""B"": ""sum""})
Out[174]: 
A    0.505601
B   -1.803879
dtype: float64
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame.agg
"In [175]: tsdf.agg({""A"": [""mean"", ""min""], ""B"": ""sum""})
Out[175]: 
             A         B
mean  0.505601       NaN
min  -0.749892       NaN
sum        NaN -1.803879
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame.agg
"In [176]: from functools import partial

In [177]: q_25 = partial(pd.Series.quantile, q=0.25)

In [178]: q_25.__name__ = ""25%""

In [179]: q_75 = partial(pd.Series.quantile, q=0.75)

In [180]: q_75.__name__ = ""75%""

In [181]: tsdf.agg([""count"", ""mean"", ""std"", ""min"", q_25, ""median"", q_75, ""max""])
Out[181]: 
               A         B         C
count   6.000000  6.000000  6.000000
mean    0.505601 -0.300647  0.262585
std     1.103362  0.887508  0.606860
min    -0.749892 -1.333363 -0.757304
25%    -0.239885 -0.979600  0.128907
median  0.303398 -0.278111  0.225365
75%     1.146791  0.151678  0.722709
max     2.169758  1.004194  0.896839
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame.agg
"In [182]: tsdf = pd.DataFrame(
   .....:     np.random.randn(10, 3),
   .....:     columns=[""A"", ""B"", ""C""],
   .....:     index=pd.date_range(""1/1/2000"", periods=10),
   .....: )
   .....: 

In [183]: tsdf.iloc[3:7] = np.nan

In [184]: tsdf
Out[184]: 
                   A         B         C
2000-01-01 -0.428759 -0.864890 -0.675341
2000-01-02 -0.168731  1.338144 -1.279321
2000-01-03 -1.621034  0.438107  0.903794
2000-01-04       NaN       NaN       NaN
2000-01-05       NaN       NaN       NaN
2000-01-06       NaN       NaN       NaN
2000-01-07       NaN       NaN       NaN
2000-01-08  0.254374 -1.240447 -0.201052
2000-01-09 -0.157795  0.791197 -1.144209
2000-01-10 -0.030876  0.371900  0.061932
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame pandas.date_range
"In [185]: tsdf.transform(np.abs)
Out[185]: 
                   A         B         C
2000-01-01  0.428759  0.864890  0.675341
2000-01-02  0.168731  1.338144  1.279321
2000-01-03  1.621034  0.438107  0.903794
2000-01-04       NaN       NaN       NaN
2000-01-05       NaN       NaN       NaN
2000-01-06       NaN       NaN       NaN
2000-01-07       NaN       NaN       NaN
2000-01-08  0.254374  1.240447  0.201052
2000-01-09  0.157795  0.791197  1.144209
2000-01-10  0.030876  0.371900  0.061932

In [186]: tsdf.transform(""abs"")
Out[186]: 
                   A         B         C
2000-01-01  0.428759  0.864890  0.675341
2000-01-02  0.168731  1.338144  1.279321
2000-01-03  1.621034  0.438107  0.903794
2000-01-04       NaN       NaN       NaN
2000-01-05       NaN       NaN       NaN
2000-01-06       NaN       NaN       NaN
2000-01-07       NaN       NaN       NaN
2000-01-08  0.254374  1.240447  0.201052
2000-01-09  0.157795  0.791197  1.144209
2000-01-10  0.030876  0.371900  0.061932

In [187]: tsdf.transform(lambda x: x.abs())
Out[187]: 
                   A         B         C
2000-01-01  0.428759  0.864890  0.675341
2000-01-02  0.168731  1.338144  1.279321
2000-01-03  1.621034  0.438107  0.903794
2000-01-04       NaN       NaN       NaN
2000-01-05       NaN       NaN       NaN
2000-01-06       NaN       NaN       NaN
2000-01-07       NaN       NaN       NaN
2000-01-08  0.254374  1.240447  0.201052
2000-01-09  0.157795  0.791197  1.144209
2000-01-10  0.030876  0.371900  0.061932
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame.transform
"In [190]: tsdf.transform([np.abs, lambda x: x + 1])
Out[190]: 
                   A                   B                   C          
            absolute    absolute    absolute  
2000-01-01  0.428759  0.571241  0.864890  0.135110  0.675341  0.324659
2000-01-02  0.168731  0.831269  1.338144  2.338144  1.279321 -0.279321
2000-01-03  1.621034 -0.621034  0.438107  1.438107  0.903794  1.903794
2000-01-04       NaN       NaN       NaN       NaN       NaN       NaN
2000-01-05       NaN       NaN       NaN       NaN       NaN       NaN
2000-01-06       NaN       NaN       NaN       NaN       NaN       NaN
2000-01-07       NaN       NaN       NaN       NaN       NaN       NaN
2000-01-08  0.254374  1.254374  1.240447 -0.240447  0.201052  0.798948
2000-01-09  0.157795  0.842205  0.791197  1.791197  1.144209 -0.144209
2000-01-10  0.030876  0.969124  0.371900  1.371900  0.061932  1.061932
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame.transform
"In [192]: tsdf.transform({""A"": np.abs, ""B"": lambda x: x + 1})
Out[192]: 
                   A         B
2000-01-01  0.428759  0.135110
2000-01-02  0.168731  2.338144
2000-01-03  1.621034  1.438107
2000-01-04       NaN       NaN
2000-01-05       NaN       NaN
2000-01-06       NaN       NaN
2000-01-07       NaN       NaN
2000-01-08  0.254374 -0.240447
2000-01-09  0.157795  1.791197
2000-01-10  0.030876  1.371900
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame.transform
"In [193]: tsdf.transform({""A"": np.abs, ""B"": [lambda x: x + 1, ""sqrt""]})
Out[193]: 
                   A         B          
            absolute        sqrt
2000-01-01  0.428759  0.135110       NaN
2000-01-02  0.168731  2.338144  1.156782
2000-01-03  1.621034  1.438107  0.661897
2000-01-04       NaN       NaN       NaN
2000-01-05       NaN       NaN       NaN
2000-01-06       NaN       NaN       NaN
2000-01-07       NaN       NaN       NaN
2000-01-08  0.254374 -0.240447       NaN
2000-01-09  0.157795  1.791197  0.889493
2000-01-10  0.030876  1.371900  0.609836
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame.transform
"In [194]: df4 = df.copy()

In [195]: df4
Out[195]: 
        one       two     three
a  1.394981  1.772517       NaN
b  0.343054  1.912123 -0.050390
c  0.695246  1.478369  1.227435
d       NaN  0.279344 -0.613172

In [196]: def f(x):
   .....:     return len(str(x))
   .....: 

In [197]: df4[""one""].map(f)
Out[197]: 
a    18
b    19
c    18
d     3
Name: one, dtype: int64

In [198]: df4.map(f)
Out[198]: 
   one  two  three
a   18   17      3
b   19   18     20
c   18   18     16
d    3   19     19
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame.copy pandas.DataFrame.map
"In [199]: s = pd.Series(
   .....:     [""six"", ""seven"", ""six"", ""seven"", ""six""], index=[""a"", ""b"", ""c"", ""d"", ""e""]
   .....: )
   .....: 

In [200]: t = pd.Series({""six"": 6.0, ""seven"": 7.0})

In [201]: s
Out[201]: 
a      six
b    seven
c      six
d    seven
e      six
dtype: object

In [202]: s.map(t)
Out[202]: 
a    6.0
b    7.0
c    6.0
d    7.0
e    6.0
dtype: float64
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.Series pandas.Series.map
"In [203]: s = pd.Series(np.random.randn(5), index=[""a"", ""b"", ""c"", ""d"", ""e""])

In [204]: s
Out[204]: 
a    1.695148
b    1.328614
c    1.234686
d   -0.385845
e   -1.326508
dtype: float64

In [205]: s.reindex([""e"", ""b"", ""f"", ""d""])
Out[205]: 
e   -1.326508
b    1.328614
f         NaN
d   -0.385845
dtype: float64
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.Series pandas.Series.reindex
"In [206]: df
Out[206]: 
        one       two     three
a  1.394981  1.772517       NaN
b  0.343054  1.912123 -0.050390
c  0.695246  1.478369  1.227435
d       NaN  0.279344 -0.613172

In [207]: df.reindex(index=[""c"", ""f"", ""b""], columns=[""three"", ""two"", ""one""])
Out[207]: 
      three       two       one
c  1.227435  1.478369  0.695246
f       NaN       NaN       NaN
b -0.050390  1.912123  0.343054
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame.reindex
"In [208]: rs = s.reindex(df.index)

In [209]: rs
Out[209]: 
a    1.695148
b    1.328614
c    1.234686
d   -0.385845
dtype: float64

In [210]: rs.index is df.index
Out[210]: True
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.Series.reindex
"In [211]: df.reindex([""c"", ""f"", ""b""], axis=""index"")
Out[211]: 
        one       two     three
c  0.695246  1.478369  1.227435
f       NaN       NaN       NaN
b  0.343054  1.912123 -0.050390

In [212]: df.reindex([""three"", ""two"", ""one""], axis=""columns"")
Out[212]: 
      three       two       one
a       NaN  1.772517  1.394981
b -0.050390  1.912123  0.343054
c  1.227435  1.478369  0.695246
d -0.613172  0.279344       NaN
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame.reindex
"In [213]: df2 = df.reindex([""a"", ""b"", ""c""], columns=[""one"", ""two""])

In [214]: df3 = df2 - df2.mean()

In [215]: df2
Out[215]: 
        one       two
a  1.394981  1.772517
b  0.343054  1.912123
c  0.695246  1.478369

In [216]: df3
Out[216]: 
        one       two
a  0.583888  0.051514
b -0.468040  0.191120
c -0.115848 -0.242634

In [217]: df.reindex_like(df2)
Out[217]: 
        one       two
a  1.394981  1.772517
b  0.343054  1.912123
c  0.695246  1.478369
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame.reindex pandas.DataFrame.mean pandas.DataFrame.reindex_like
"In [218]: s = pd.Series(np.random.randn(5), index=[""a"", ""b"", ""c"", ""d"", ""e""])

In [219]: s1 = s[:4]

In [220]: s2 = s[1:]

In [221]: s1.align(s2)
Out[221]: 
(a   -0.186646
 b   -1.692424
 c   -0.303893
 d   -1.425662
 e         NaN
 dtype: float64,
 a         NaN
 b   -1.692424
 c   -0.303893
 d   -1.425662
 e    1.114285
 dtype: float64)

In [222]: s1.align(s2, join=""inner"")
Out[222]: 
(b   -1.692424
 c   -0.303893
 d   -1.425662
 dtype: float64,
 b   -1.692424
 c   -0.303893
 d   -1.425662
 dtype: float64)

In [223]: s1.align(s2, join=""left"")
Out[223]: 
(a   -0.186646
 b   -1.692424
 c   -0.303893
 d   -1.425662
 dtype: float64,
 a         NaN
 b   -1.692424
 c   -0.303893
 d   -1.425662
 dtype: float64)
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.Series pandas.Series.align
"In [224]: df.align(df2, join=""inner"")
Out[224]: 
(        one       two
 a  1.394981  1.772517
 b  0.343054  1.912123
 c  0.695246  1.478369,
         one       two
 a  1.394981  1.772517
 b  0.343054  1.912123
 c  0.695246  1.478369)
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame.align
"In [225]: df.align(df2, join=""inner"", axis=0)
Out[225]: 
(        one       two     three
 a  1.394981  1.772517       NaN
 b  0.343054  1.912123 -0.050390
 c  0.695246  1.478369  1.227435,
         one       two
 a  1.394981  1.772517
 b  0.343054  1.912123
 c  0.695246  1.478369)
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame.align
"In [226]: df.align(df2.iloc[0], axis=1)
Out[226]: 
(        one     three       two
 a  1.394981       NaN  1.772517
 b  0.343054 -0.050390  1.912123
 c  0.695246  1.227435  1.478369
 d       NaN -0.613172  0.279344,
 one      1.394981
 three         NaN
 two      1.772517
 Name: a, dtype: float64)
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame.align
"In [227]: rng = pd.date_range(""1/3/2000"", periods=8)

In [228]: ts = pd.Series(np.random.randn(8), index=rng)

In [229]: ts2 = ts.iloc[[0, 3, 6]]

In [230]: ts
Out[230]: 
2000-01-03    0.183051
2000-01-04    0.400528
2000-01-05   -0.015083
2000-01-06    2.395489
2000-01-07    1.414806
2000-01-08    0.118428
2000-01-09    0.733639
2000-01-10   -0.936077
Freq: D, dtype: float64

In [231]: ts2
Out[231]: 
2000-01-03    0.183051
2000-01-06    2.395489
2000-01-09    0.733639
Freq: 3D, dtype: float64

In [232]: ts2.reindex(ts.index)
Out[232]: 
2000-01-03    0.183051
2000-01-04         NaN
2000-01-05         NaN
2000-01-06    2.395489
2000-01-07         NaN
2000-01-08         NaN
2000-01-09    0.733639
2000-01-10         NaN
Freq: D, dtype: float64

In [233]: ts2.reindex(ts.index, method=""ffill"")
Out[233]: 
2000-01-03    0.183051
2000-01-04    0.183051
2000-01-05    0.183051
2000-01-06    2.395489
2000-01-07    2.395489
2000-01-08    2.395489
2000-01-09    0.733639
2000-01-10    0.733639
Freq: D, dtype: float64

In [234]: ts2.reindex(ts.index, method=""bfill"")
Out[234]: 
2000-01-03    0.183051
2000-01-04    2.395489
2000-01-05    2.395489
2000-01-06    2.395489
2000-01-07    0.733639
2000-01-08    0.733639
2000-01-09    0.733639
2000-01-10         NaN
Freq: D, dtype: float64

In [235]: ts2.reindex(ts.index, method=""nearest"")
Out[235]: 
2000-01-03    0.183051
2000-01-04    0.183051
2000-01-05    2.395489
2000-01-06    2.395489
2000-01-07    2.395489
2000-01-08    0.733639
2000-01-09    0.733639
2000-01-10    0.733639
Freq: D, dtype: float64
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.date_range pandas.Series
"In [239]: df
Out[239]: 
        one       two     three
a  1.394981  1.772517       NaN
b  0.343054  1.912123 -0.050390
c  0.695246  1.478369  1.227435
d       NaN  0.279344 -0.613172

In [240]: df.drop([""a"", ""d""], axis=0)
Out[240]: 
        one       two     three
b  0.343054  1.912123 -0.050390
c  0.695246  1.478369  1.227435

In [241]: df.drop([""one""], axis=1)
Out[241]: 
        two     three
a  1.772517       NaN
b  1.912123 -0.050390
c  1.478369  1.227435
d  0.279344 -0.613172
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame.drop
"In [242]: df.reindex(df.index.difference([""a"", ""d""]))
Out[242]: 
        one       two     three
b  0.343054  1.912123 -0.050390
c  0.695246  1.478369  1.227435
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame.reindex
"In [243]: s
Out[243]: 
a   -0.186646
b   -1.692424
c   -0.303893
d   -1.425662
e    1.114285
dtype: float64

In [244]: s.rename(str.upper)
Out[244]: 
A   -0.186646
B   -1.692424
C   -0.303893
D   -1.425662
E    1.114285
dtype: float64
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.Series.rename
"In [245]: df.rename(
   .....:     columns={""one"": ""foo"", ""two"": ""bar""},
   .....:     index={""a"": ""apple"", ""b"": ""banana"", ""d"": ""durian""},
   .....: )
   .....: 
Out[245]: 
             foo       bar     three
apple   1.394981  1.772517       NaN
banana  0.343054  1.912123 -0.050390
c       0.695246  1.478369  1.227435
durian       NaN  0.279344 -0.613172
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame.rename
"In [246]: df.rename({""one"": ""foo"", ""two"": ""bar""}, axis=""columns"")
Out[246]: 
        foo       bar     three
a  1.394981  1.772517       NaN
b  0.343054  1.912123 -0.050390
c  0.695246  1.478369  1.227435
d       NaN  0.279344 -0.613172

In [247]: df.rename({""a"": ""apple"", ""b"": ""banana"", ""d"": ""durian""}, axis=""index"")
Out[247]: 
             one       two     three
apple   1.394981  1.772517       NaN
banana  0.343054  1.912123 -0.050390
c       0.695246  1.478369  1.227435
durian       NaN  0.279344 -0.613172
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame.rename
"In [248]: s.rename(""scalar-name"")
Out[248]: 
a   -0.186646
b   -1.692424
c   -0.303893
d   -1.425662
e    1.114285
Name: scalar-name, dtype: float64
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.Series.rename
"In [249]: df = pd.DataFrame(
   .....:     {""x"": [1, 2, 3, 4, 5, 6], ""y"": [10, 20, 30, 40, 50, 60]},
   .....:     index=pd.MultiIndex.from_product(
   .....:         [[""a"", ""b"", ""c""], [1, 2]], names=[""let"", ""num""]
   .....:     ),
   .....: )
   .....: 

In [250]: df
Out[250]: 
         x   y
let num       
a   1    1  10
    2    2  20
b   1    3  30
    2    4  40
c   1    5  50
    2    6  60

In [251]: df.rename_axis(index={""let"": ""abc""})
Out[251]: 
         x   y
abc num       
a   1    1  10
    2    2  20
b   1    3  30
    2    4  40
c   1    5  50
    2    6  60

In [252]: df.rename_axis(index=str.upper)
Out[252]: 
         x   y
LET NUM       
a   1    1  10
    2    2  20
b   1    3  30
    2    4  40
c   1    5  50
    2    6  60
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame pandas.MultiIndex.from_product pandas.DataFrame.rename_axis
"In [253]: df = pd.DataFrame(
   .....:     {""col1"": np.random.randn(3), ""col2"": np.random.randn(3)}, index=[""a"", ""b"", ""c""]
   .....: )
   .....: 

In [254]: for col in df:
   .....:     print(col)
   .....: 
col1
col2
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame
"In [255]: df = pd.DataFrame({""a"": [1, 2, 3], ""b"": [""a"", ""b"", ""c""]})

In [256]: for index, row in df.iterrows():
   .....:     row[""a""] = 10
   .....: 

In [257]: df
Out[257]: 
   a  b
0  1  a
1  2  b
2  3  c
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame pandas.DataFrame.iterrows
"In [258]: for label, ser in df.items():
   .....:     print(label)
   .....:     print(ser)
   .....: 
a
0    1
1    2
2    3
Name: a, dtype: int64
b
0    a
1    b
2    c
Name: b, dtype: object
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame.items
"In [259]: for row_index, row in df.iterrows():
   .....:     print(row_index, row, sep=""\n"")
   .....: 
0
a    1
b    a
Name: 0, dtype: object
1
a    2
b    b
Name: 1, dtype: object
2
a    3
b    c
Name: 2, dtype: object
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame.iterrows
"In [260]: df_orig = pd.DataFrame([[1, 1.5]], columns=[""int"", ""float""])

In [261]: df_orig.dtypes
Out[261]: 
int        int64
float    float64
dtype: object

In [262]: row = next(df_orig.iterrows())[1]

In [263]: row
Out[263]: 
int      1.0
float    1.5
Name: 0, dtype: float64
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame pandas.DataFrame.iterrows
"In [266]: df2 = pd.DataFrame({""x"": [1, 2, 3], ""y"": [4, 5, 6]})

In [267]: print(df2)
   x  y
0  1  4
1  2  5
2  3  6

In [268]: print(df2.T)
   0  1  2
x  1  2  3
y  4  5  6

In [269]: df2_t = pd.DataFrame({idx: values for idx, values in df2.iterrows()})

In [270]: print(df2_t)
   0  1  2
x  1  2  3
y  4  5  6
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame pandas.DataFrame.iterrows
"In [271]: for row in df.itertuples():
   .....:     print(row)
   .....: 
Pandas(Index=0, a=1, b='a')
Pandas(Index=1, a=2, b='b')
Pandas(Index=2, a=3, b='c')
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame.itertuples
"# datetime
In [272]: s = pd.Series(pd.date_range(""20130101 09:10:12"", periods=4))

In [273]: s
Out[273]: 
0   2013-01-01 09:10:12
1   2013-01-02 09:10:12
2   2013-01-03 09:10:12
3   2013-01-04 09:10:12
dtype: datetime64[ns]

In [274]: s.dt.hour
Out[274]: 
0    9
1    9
2    9
3    9
dtype: int32

In [275]: s.dt.second
Out[275]: 
0    12
1    12
2    12
3    12
dtype: int32

In [276]: s.dt.day
Out[276]: 
0    1
1    2
2    3
3    4
dtype: int32
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.Series pandas.date_range
"In [278]: stz = s.dt.tz_localize(""US/Eastern"")

In [279]: stz
Out[279]: 
0   2013-01-01 09:10:12-05:00
1   2013-01-02 09:10:12-05:00
2   2013-01-03 09:10:12-05:00
3   2013-01-04 09:10:12-05:00
dtype: datetime64[ns, US/Eastern]

In [280]: stz.dt.tz
Out[280]: 
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.Series.dt.tz_localize
"In [281]: s.dt.tz_localize(""UTC"").dt.tz_convert(""US/Eastern"")
Out[281]: 
0   2013-01-01 04:10:12-05:00
1   2013-01-02 04:10:12-05:00
2   2013-01-03 04:10:12-05:00
3   2013-01-04 04:10:12-05:00
dtype: datetime64[ns, US/Eastern]
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.Series.dt.tz_localize
"# DatetimeIndex
In [282]: s = pd.Series(pd.date_range(""20130101"", periods=4))

In [283]: s
Out[283]: 
0   2013-01-01
1   2013-01-02
2   2013-01-03
3   2013-01-04
dtype: datetime64[ns]

In [284]: s.dt.strftime(""%Y/%m/%d"")
Out[284]: 
0    2013/01/01
1    2013/01/02
2    2013/01/03
3    2013/01/04
dtype: object
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.Series pandas.date_range pandas.Series.dt.strftime
"# PeriodIndex
In [285]: s = pd.Series(pd.period_range(""20130101"", periods=4))

In [286]: s
Out[286]: 
0    2013-01-01
1    2013-01-02
2    2013-01-03
3    2013-01-04
dtype: period[D]

In [287]: s.dt.strftime(""%Y/%m/%d"")
Out[287]: 
0    2013/01/01
1    2013/01/02
2    2013/01/03
3    2013/01/04
dtype: object
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.Series pandas.period_range pandas.Series.dt.strftime
"# period
In [288]: s = pd.Series(pd.period_range(""20130101"", periods=4, freq=""D""))

In [289]: s
Out[289]: 
0    2013-01-01
1    2013-01-02
2    2013-01-03
3    2013-01-04
dtype: period[D]

In [290]: s.dt.year
Out[290]: 
0    2013
1    2013
2    2013
3    2013
dtype: int64

In [291]: s.dt.day
Out[291]: 
0    1
1    2
2    3
3    4
dtype: int64
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.Series pandas.period_range
"# timedelta
In [292]: s = pd.Series(pd.timedelta_range(""1 day 00:00:05"", periods=4, freq=""s""))

In [293]: s
Out[293]: 
0   1 days 00:00:05
1   1 days 00:00:06
2   1 days 00:00:07
3   1 days 00:00:08
dtype: timedelta64[ns]

In [294]: s.dt.days
Out[294]: 
0    1
1    1
2    1
3    1
dtype: int64

In [295]: s.dt.seconds
Out[295]: 
0    5
1    6
2    7
3    8
dtype: int32

In [296]: s.dt.components
Out[296]: 
   days  hours  minutes  seconds  milliseconds  microseconds  nanoseconds
0     1      0        0        5             0             0            0
1     1      0        0        6             0             0            0
2     1      0        0        7             0             0            0
3     1      0        0        8             0             0            0
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.Series pandas.timedelta_range
"In [297]: s = pd.Series(
   .....:     [""A"", ""B"", ""C"", ""Aaba"", ""Baca"", np.nan, ""CABA"", ""dog"", ""cat""], dtype=""string""
   .....: )
   .....: 

In [298]: s.str.lower()
Out[298]: 
0       a
1       b
2       c
3    aaba
4    baca
5    
6    caba
7     dog
8     cat
dtype: string
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.Series pandas.Series.str.lower
"In [299]: df = pd.DataFrame(
   .....:     {
   .....:         ""one"": pd.Series(np.random.randn(3), index=[""a"", ""b"", ""c""]),
   .....:         ""two"": pd.Series(np.random.randn(4), index=[""a"", ""b"", ""c"", ""d""]),
   .....:         ""three"": pd.Series(np.random.randn(3), index=[""b"", ""c"", ""d""]),
   .....:     }
   .....: )
   .....: 

In [300]: unsorted_df = df.reindex(
   .....:     index=[""a"", ""d"", ""c"", ""b""], columns=[""three"", ""two"", ""one""]
   .....: )
   .....: 

In [301]: unsorted_df
Out[301]: 
      three       two       one
a       NaN -1.152244  0.562973
d -0.252916 -0.109597       NaN
c  1.273388 -0.167123  0.640382
b -0.098217  0.009797 -1.299504

# DataFrame
In [302]: unsorted_df.sort_index()
Out[302]: 
      three       two       one
a       NaN -1.152244  0.562973
b -0.098217  0.009797 -1.299504
c  1.273388 -0.167123  0.640382
d -0.252916 -0.109597       NaN

In [303]: unsorted_df.sort_index(ascending=False)
Out[303]: 
      three       two       one
d -0.252916 -0.109597       NaN
c  1.273388 -0.167123  0.640382
b -0.098217  0.009797 -1.299504
a       NaN -1.152244  0.562973

In [304]: unsorted_df.sort_index(axis=1)
Out[304]: 
        one     three       two
a  0.562973       NaN -1.152244
d       NaN -0.252916 -0.109597
c  0.640382  1.273388 -0.167123
b -1.299504 -0.098217  0.009797

# Series
In [305]: unsorted_df[""three""].sort_index()
Out[305]: 
a         NaN
b   -0.098217
c    1.273388
d   -0.252916
Name: three, dtype: float64
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame pandas.Series pandas.DataFrame.reindex
"In [306]: s1 = pd.DataFrame({""a"": [""B"", ""a"", ""C""], ""b"": [1, 2, 3], ""c"": [2, 3, 4]}).set_index(
   .....:     list(""ab"")
   .....: )
   .....: 

In [307]: s1
Out[307]: 
     c
a b   
B 1  2
a 2  3
C 3  4
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame pandas.DataFrame.set_index
"In [308]: s1.sort_index(level=""a"")
Out[308]: 
     c
a b   
B 1  2
C 3  4
a 2  3

In [309]: s1.sort_index(level=""a"", key=lambda idx: idx.str.lower())
Out[309]: 
     c
a b   
a 2  3
B 1  2
C 3  4
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame.sort_index
"In [310]: df1 = pd.DataFrame(
   .....:     {""one"": [2, 1, 1, 1], ""two"": [1, 3, 2, 4], ""three"": [5, 4, 3, 2]}
   .....: )
   .....: 

In [311]: df1.sort_values(by=""two"")
Out[311]: 
   one  two  three
0    2    1      5
2    1    2      3
1    1    3      4
3    1    4      2
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame pandas.DataFrame.sort_values
"In [313]: s[2] = np.nan

In [314]: s.sort_values()
Out[314]: 
0       A
3    Aaba
1       B
4    Baca
6    CABA
8     cat
7     dog
2    
5    
dtype: string

In [315]: s.sort_values(na_position=""first"")
Out[315]: 
2    
5    
0       A
3    Aaba
1       B
4    Baca
6    CABA
8     cat
7     dog
dtype: string
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.Series.sort_values
"In [316]: s1 = pd.Series([""B"", ""a"", ""C""])
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.Series
"In [317]: s1.sort_values()
Out[317]: 
0    B
2    C
1    a
dtype: object

In [318]: s1.sort_values(key=lambda x: x.str.lower())
Out[318]: 
1    a
0    B
2    C
dtype: object
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.Series.sort_values
"In [319]: df = pd.DataFrame({""a"": [""B"", ""a"", ""C""], ""b"": [1, 2, 3]})
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame
"In [320]: df.sort_values(by=""a"")
Out[320]: 
   a  b
0  B  1
2  C  3
1  a  2

In [321]: df.sort_values(by=""a"", key=lambda col: col.str.lower())
Out[321]: 
   a  b
1  a  2
0  B  1
2  C  3
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame.sort_values
"# Build MultiIndex
In [322]: idx = pd.MultiIndex.from_tuples(
   .....:     [(""a"", 1), (""a"", 2), (""a"", 2), (""b"", 2), (""b"", 1), (""b"", 1)]
   .....: )
   .....: 

In [323]: idx.names = [""first"", ""second""]

# Build DataFrame
In [324]: df_multi = pd.DataFrame({""A"": np.arange(6, 0, -1)}, index=idx)

In [325]: df_multi
Out[325]: 
              A
first second   
a     1       6
      2       5
      2       4
b     2       3
      1       2
      1       1
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.MultiIndex.from_tuples pandas.DataFrame
"In [326]: df_multi.sort_values(by=[""second"", ""A""])
Out[326]: 
              A
first second   
b     1       1
      1       2
a     1       6
b     2       3
a     2       4
      2       5
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame.sort_values
"In [327]: ser = pd.Series([1, 2, 3])

In [328]: ser.searchsorted([0, 3])
Out[328]: array([0, 2])

In [329]: ser.searchsorted([0, 4])
Out[329]: array([0, 3])

In [330]: ser.searchsorted([1, 3], side=""right"")
Out[330]: array([1, 3])

In [331]: ser.searchsorted([1, 3], side=""left"")
Out[331]: array([0, 2])

In [332]: ser = pd.Series([3, 1, 2])

In [333]: ser.searchsorted([0, 3], sorter=np.argsort(ser))
Out[333]: array([0, 2])
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.Series pandas.Series.searchsorted pandas.array
"In [334]: s = pd.Series(np.random.permutation(10))

In [335]: s
Out[335]: 
0    2
1    0
2    3
3    7
4    1
5    5
6    9
7    6
8    8
9    4
dtype: int64

In [336]: s.sort_values()
Out[336]: 
1    0
4    1
0    2
2    3
9    4
5    5
7    6
3    7
8    8
6    9
dtype: int64

In [337]: s.nsmallest(3)
Out[337]: 
1    0
4    1
0    2
dtype: int64

In [338]: s.nlargest(3)
Out[338]: 
6    9
8    8
3    7
dtype: int64
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.Series pandas.Series.sort_values pandas.Series.nsmallest pandas.Series.nlargest
"In [339]: df = pd.DataFrame(
   .....:     {
   .....:         ""a"": [-2, -1, 1, 10, 8, 11, -1],
   .....:         ""b"": list(""abdceff""),
   .....:         ""c"": [1.0, 2.0, 4.0, 3.2, np.nan, 3.0, 4.0],
   .....:     }
   .....: )
   .....: 

In [340]: df.nlargest(3, ""a"")
Out[340]: 
    a  b    c
5  11  f  3.0
3  10  c  3.2
4   8  e  NaN

In [341]: df.nlargest(5, [""a"", ""c""])
Out[341]: 
    a  b    c
5  11  f  3.0
3  10  c  3.2
4   8  e  NaN
2   1  d  4.0
6  -1  f  4.0

In [342]: df.nsmallest(3, ""a"")
Out[342]: 
   a  b    c
0 -2  a  1.0
1 -1  b  2.0
6 -1  f  4.0

In [343]: df.nsmallest(5, [""a"", ""c""])
Out[343]: 
   a  b    c
0 -2  a  1.0
1 -1  b  2.0
6 -1  f  4.0
2  1  d  4.0
4  8  e  NaN
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame pandas.DataFrame.nlargest pandas.DataFrame.nsmallest
"In [344]: df1.columns = pd.MultiIndex.from_tuples(
   .....:     [(""a"", ""one""), (""a"", ""two""), (""b"", ""three"")]
   .....: )
   .....: 

In [345]: df1.sort_values(by=(""a"", ""two""))
Out[345]: 
    a         b
  one two three
0   2   1     5
2   1   2     3
1   1   3     4
3   1   4     2
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.MultiIndex.from_tuples pandas.DataFrame.sort_values
"In [346]: dft = pd.DataFrame(
   .....:     {
   .....:         ""A"": np.random.rand(3),
   .....:         ""B"": 1,
   .....:         ""C"": ""foo"",
   .....:         ""D"": pd.Timestamp(""20010102""),
   .....:         ""E"": pd.Series([1.0] * 3).astype(""float32""),
   .....:         ""F"": False,
   .....:         ""G"": pd.Series([1] * 3, dtype=""int8""),
   .....:     }
   .....: )
   .....: 

In [347]: dft
Out[347]: 
          A  B    C          D    E      F  G
0  0.035962  1  foo 2001-01-02  1.0  False  1
1  0.701379  1  foo 2001-01-02  1.0  False  1
2  0.281885  1  foo 2001-01-02  1.0  False  1

In [348]: dft.dtypes
Out[348]: 
A          float64
B            int64
C           object
D    datetime64[s]
E          float32
F             bool
G             int8
dtype: object
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame pandas.Series
"# these ints are coerced to floats
In [350]: pd.Series([1, 2, 3, 4, 5, 6.0])
Out[350]: 
0    1.0
1    2.0
2    3.0
3    4.0
4    5.0
5    6.0
dtype: float64

# string data forces an ``object`` dtype
In [351]: pd.Series([1, 2, 3, 6.0, ""foo""])
Out[351]: 
0      1
1      2
2      3
3    6.0
4    foo
dtype: object
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.Series
"In [353]: df1 = pd.DataFrame(np.random.randn(8, 1), columns=[""A""], dtype=""float32"")

In [354]: df1
Out[354]: 
          A
0  0.224364
1  1.890546
2  0.182879
3  0.787847
4 -0.188449
5  0.667715
6 -0.011736
7 -0.399073

In [355]: df1.dtypes
Out[355]: 
A    float32
dtype: object

In [356]: df2 = pd.DataFrame(
   .....:     {
   .....:         ""A"": pd.Series(np.random.randn(8), dtype=""float16""),
   .....:         ""B"": pd.Series(np.random.randn(8)),
   .....:         ""C"": pd.Series(np.random.randint(0, 255, size=8), dtype=""uint8""),  # [0,255] (range of uint8)
   .....:     }
   .....: )
   .....: 

In [357]: df2
Out[357]: 
          A         B    C
0  0.823242  0.256090   26
1  1.607422  1.426469   86
2 -0.333740 -0.416203   46
3 -0.063477  1.139976  212
4 -1.014648 -1.193477   26
5  0.678711  0.096706    7
6 -0.040863 -1.956850  184
7 -0.357422 -0.714337  206

In [358]: df2.dtypes
Out[358]: 
A    float16
B    float64
C      uint8
dtype: object
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame pandas.Series
"In [359]: pd.DataFrame([1, 2], columns=[""a""]).dtypes
Out[359]: 
a    int64
dtype: object

In [360]: pd.DataFrame({""a"": [1, 2]}).dtypes
Out[360]: 
a    int64
dtype: object

In [361]: pd.DataFrame({""a"": 1}, index=list(range(2))).dtypes
Out[361]: 
a    int64
dtype: object
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame
"In [362]: frame = pd.DataFrame(np.array([1, 2]))
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame
"In [363]: df3 = df1.reindex_like(df2).fillna(value=0.0) + df2

In [364]: df3
Out[364]: 
          A         B      C
0  1.047606  0.256090   26.0
1  3.497968  1.426469   86.0
2 -0.150862 -0.416203   46.0
3  0.724370  1.139976  212.0
4 -1.203098 -1.193477   26.0
5  1.346426  0.096706    7.0
6 -0.052599 -1.956850  184.0
7 -0.756495 -0.714337  206.0

In [365]: df3.dtypes
Out[365]: 
A    float32
B    float64
C    float64
dtype: object
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame.reindex_like
"In [366]: df3.to_numpy().dtype
Out[366]: dtype('float64')
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame.to_numpy
"In [367]: df3
Out[367]: 
          A         B      C
0  1.047606  0.256090   26.0
1  3.497968  1.426469   86.0
2 -0.150862 -0.416203   46.0
3  0.724370  1.139976  212.0
4 -1.203098 -1.193477   26.0
5  1.346426  0.096706    7.0
6 -0.052599 -1.956850  184.0
7 -0.756495 -0.714337  206.0

In [368]: df3.dtypes
Out[368]: 
A    float32
B    float64
C    float64
dtype: object

# conversion of dtypes
In [369]: df3.astype(""float32"").dtypes
Out[369]: 
A    float32
B    float32
C    float32
dtype: object
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame.astype
"In [370]: dft = pd.DataFrame({""a"": [1, 2, 3], ""b"": [4, 5, 6], ""c"": [7, 8, 9]})

In [371]: dft[[""a"", ""b""]] = dft[[""a"", ""b""]].astype(np.uint8)

In [372]: dft
Out[372]: 
   a  b  c
0  1  4  7
1  2  5  8
2  3  6  9

In [373]: dft.dtypes
Out[373]: 
a    uint8
b    uint8
c    int64
dtype: object
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame
"In [374]: dft1 = pd.DataFrame({""a"": [1, 0, 1], ""b"": [4, 5, 6], ""c"": [7, 8, 9]})

In [375]: dft1 = dft1.astype({""a"": np.bool_, ""c"": np.float64})

In [376]: dft1
Out[376]: 
       a  b    c
0   True  4  7.0
1  False  5  8.0
2   True  6  9.0

In [377]: dft1.dtypes
Out[377]: 
a       bool
b      int64
c    float64
dtype: object
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame pandas.DataFrame.astype
"In [378]: dft = pd.DataFrame({""a"": [1, 2, 3], ""b"": [4, 5, 6], ""c"": [7, 8, 9]})

In [379]: dft.loc[:, [""a"", ""b""]].astype(np.uint8).dtypes
Out[379]: 
a    uint8
b    uint8
dtype: object

In [380]: dft.loc[:, [""a"", ""b""]] = dft.loc[:, [""a"", ""b""]].astype(np.uint8)

In [381]: dft.dtypes
Out[381]: 
a    int64
b    int64
c    int64
dtype: object
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame
"In [382]: import datetime

In [383]: df = pd.DataFrame(
   .....:     [
   .....:         [1, 2],
   .....:         [""a"", ""b""],
   .....:         [datetime.datetime(2016, 3, 2), datetime.datetime(2016, 3, 2)],
   .....:     ]
   .....: )
   .....: 

In [384]: df = df.T

In [385]: df
Out[385]: 
   0  1                    2
0  1  a  2016-03-02 00:00:00
1  2  b  2016-03-02 00:00:00

In [386]: df.dtypes
Out[386]: 
0    object
1    object
2    object
dtype: object
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame
"In [387]: df.infer_objects().dtypes
Out[387]: 
0             int64
1            object
2    datetime64[ns]
dtype: object
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame.infer_objects
"In [388]: m = [""1.1"", 2, 3]

In [389]: pd.to_numeric(m)
Out[389]: array([1.1, 2. , 3. ])
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.to_numeric pandas.array
"In [390]: import datetime

In [391]: m = [""2016-07-09"", datetime.datetime(2016, 3, 2)]

In [392]: pd.to_datetime(m)
Out[392]: DatetimeIndex(['2016-07-09', '2016-03-02'], dtype='datetime64[ns]', freq=None)
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.to_datetime pandas.DatetimeIndex
"In [393]: m = [""5us"", pd.Timedelta(""1day"")]

In [394]: pd.to_timedelta(m)
Out[394]: TimedeltaIndex(['0 days 00:00:00.000005', '1 days 00:00:00'], dtype='timedelta64[ns]', freq=None)
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.to_timedelta pandas.TimedeltaIndex
"In [395]: import datetime

In [396]: m = [""apple"", datetime.datetime(2016, 3, 2)]

In [397]: pd.to_datetime(m, errors=""coerce"")
Out[397]: DatetimeIndex(['NaT', '2016-03-02'], dtype='datetime64[ns]', freq=None)

In [398]: m = [""apple"", 2, 3]

In [399]: pd.to_numeric(m, errors=""coerce"")
Out[399]: array([nan,  2.,  3.])

In [400]: m = [""apple"", pd.Timedelta(""1day"")]

In [401]: pd.to_timedelta(m, errors=""coerce"")
Out[401]: TimedeltaIndex([NaT, '1 days'], dtype='timedelta64[ns]', freq=None)
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.to_datetime pandas.DatetimeIndex pandas.to_numeric pandas.array pandas.to_timedelta pandas.TimedeltaIndex
"In [402]: m = [""1"", 2, 3]

In [403]: pd.to_numeric(m, downcast=""integer"")  # smallest signed int dtype
Out[403]: array([1, 2, 3], dtype=int8)

In [404]: pd.to_numeric(m, downcast=""signed"")  # same as 'integer'
Out[404]: array([1, 2, 3], dtype=int8)

In [405]: pd.to_numeric(m, downcast=""unsigned"")  # smallest unsigned int dtype
Out[405]: array([1, 2, 3], dtype=uint8)

In [406]: pd.to_numeric(m, downcast=""float"")  # smallest float dtype
Out[406]: array([1., 2., 3.], dtype=float32)
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.to_numeric pandas.array
"In [407]: import datetime

In [408]: df = pd.DataFrame([[""2016-07-09"", datetime.datetime(2016, 3, 2)]] * 2, dtype=""O"")

In [409]: df
Out[409]: 
            0                    1
0  2016-07-09  2016-03-02 00:00:00
1  2016-07-09  2016-03-02 00:00:00

In [410]: df.apply(pd.to_datetime)
Out[410]: 
           0          1
0 2016-07-09 2016-03-02
1 2016-07-09 2016-03-02

In [411]: df = pd.DataFrame([[""1.1"", 2, 3]] * 2, dtype=""O"")

In [412]: df
Out[412]: 
     0  1  2
0  1.1  2  3
1  1.1  2  3

In [413]: df.apply(pd.to_numeric)
Out[413]: 
     0  1  2
0  1.1  2  3
1  1.1  2  3

In [414]: df = pd.DataFrame([[""5us"", pd.Timedelta(""1day"")]] * 2, dtype=""O"")

In [415]: df
Out[415]: 
     0                1
0  5us  1 days 00:00:00
1  5us  1 days 00:00:00

In [416]: df.apply(pd.to_timedelta)
Out[416]: 
                       0      1
0 0 days 00:00:00.000005 1 days
1 0 days 00:00:00.000005 1 days
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame pandas.DataFrame.apply
"In [417]: dfi = df3.astype(""int32"")

In [418]: dfi[""E""] = 1

In [419]: dfi
Out[419]: 
   A  B    C  E
0  1  0   26  1
1  3  1   86  1
2  0  0   46  1
3  0  1  212  1
4 -1 -1   26  1
5  1  0    7  1
6  0 -1  184  1
7  0  0  206  1

In [420]: dfi.dtypes
Out[420]: 
A    int32
B    int32
C    int32
E    int64
dtype: object

In [421]: casted = dfi[dfi > 0]

In [422]: casted
Out[422]: 
     A    B    C  E
0  1.0  NaN   26  1
1  3.0  1.0   86  1
2  NaN  NaN   46  1
3  NaN  1.0  212  1
4  NaN  NaN   26  1
5  1.0  NaN    7  1
6  NaN  NaN  184  1
7  NaN  NaN  206  1

In [423]: casted.dtypes
Out[423]: 
A    float64
B    float64
C      int32
E      int64
dtype: object
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame.astype
"In [424]: dfa = df3.copy()

In [425]: dfa[""A""] = dfa[""A""].astype(""float32"")

In [426]: dfa.dtypes
Out[426]: 
A    float32
B    float64
C    float64
dtype: object

In [427]: casted = dfa[df2 > 0]

In [428]: casted
Out[428]: 
          A         B      C
0  1.047606  0.256090   26.0
1  3.497968  1.426469   86.0
2       NaN       NaN   46.0
3       NaN  1.139976  212.0
4       NaN       NaN   26.0
5  1.346426  0.096706    7.0
6       NaN       NaN  184.0
7       NaN       NaN  206.0

In [429]: casted.dtypes
Out[429]: 
A    float32
B    float64
C    float64
dtype: object
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame.copy
"In [430]: df = pd.DataFrame(
   .....:     {
   .....:         ""string"": list(""abc""),
   .....:         ""int64"": list(range(1, 4)),
   .....:         ""uint8"": np.arange(3, 6).astype(""u1""),
   .....:         ""float64"": np.arange(4.0, 7.0),
   .....:         ""bool1"": [True, False, True],
   .....:         ""bool2"": [False, True, False],
   .....:         ""dates"": pd.date_range(""now"", periods=3),
   .....:         ""category"": pd.Series(list(""ABC"")).astype(""category""),
   .....:     }
   .....: )
   .....: 

In [431]: df[""tdeltas""] = df.dates.diff()

In [432]: df[""uint64""] = np.arange(3, 6).astype(""u8"")

In [433]: df[""other_dates""] = pd.date_range(""20130101"", periods=3)

In [434]: df[""tz_aware_dates""] = pd.date_range(""20130101"", periods=3, tz=""US/Eastern"")

In [435]: df
Out[435]: 
  string  int64  uint8  ...  uint64  other_dates            tz_aware_dates
0      a      1      3  ...       3   2013-01-01 2013-01-01 00:00:00-05:00
1      b      2      4  ...       4   2013-01-02 2013-01-02 00:00:00-05:00
2      c      3      5  ...       5   2013-01-03 2013-01-03 00:00:00-05:00

[3 rows x 12 columns]
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame pandas.date_range pandas.Series
"In [437]: df.select_dtypes(include=[bool])
Out[437]: 
   bool1  bool2
0   True  False
1  False   True
2   True  False
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame.select_dtypes
"In [438]: df.select_dtypes(include=[""bool""])
Out[438]: 
   bool1  bool2
0   True  False
1  False   True
2   True  False
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame.select_dtypes
"In [439]: df.select_dtypes(include=[""number"", ""bool""], exclude=[""unsignedinteger""])
Out[439]: 
   int64  float64  bool1  bool2 tdeltas
0      1      4.0   True  False     NaT
1      2      5.0  False   True  1 days
2      3      6.0   True  False  1 days
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame.select_dtypes
"In [440]: df.select_dtypes(include=[""object""])
Out[440]: 
  string
0      a
1      b
2      c
",https://pandas.pydata.org/docs/user_guide/basics.html, pandas.DataFrame.select_dtypes
"In [1]: import pandas as pd

In [2]: from io import StringIO

In [3]: data = ""col1,col2,col3\na,b,1\na,b,2\nc,d,3""

In [4]: pd.read_csv(StringIO(data))
Out[4]: 
  col1 col2  col3
0    a    b     1
1    a    b     2
2    c    d     3

In [5]: pd.read_csv(StringIO(data), usecols=lambda x: x.upper() in [""COL1"", ""COL3""])
Out[5]: 
  col1  col3
0    a     1
1    a     2
2    c     3
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv pandas.Series.str.upper
"In [6]: data = ""col1,col2,col3\na,b,1\na,b,2\nc,d,3""

In [7]: pd.read_csv(StringIO(data))
Out[7]: 
  col1 col2  col3
0    a    b     1
1    a    b     2
2    c    d     3

In [8]: pd.read_csv(StringIO(data), skiprows=lambda x: x % 2 != 0)
Out[8]: 
  col1 col2  col3
0    a    b     2
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv
"In [9]: import numpy as np

In [10]: data = ""a,b,c,d\n1,2,3,4\n5,6,7,8\n9,10,11""

In [11]: print(data)
a,b,c,d
1,2,3,4
5,6,7,8
9,10,11

In [12]: df = pd.read_csv(StringIO(data), dtype=object)

In [13]: df
Out[13]: 
   a   b   c    d
0  1   2   3    4
1  5   6   7    8
2  9  10  11  NaN

In [14]: df[""a""][0]
Out[14]: '1'

In [15]: df = pd.read_csv(StringIO(data), dtype={""b"": object, ""c"": np.float64, ""d"": ""Int64""})

In [16]: df.dtypes
Out[16]: 
a      int64
b     object
c    float64
d      Int64
dtype: object
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv
"In [17]: data = ""col_1\n1\n2\n'A'\n4.22""

In [18]: df = pd.read_csv(StringIO(data), converters={""col_1"": str})

In [19]: df
Out[19]: 
  col_1
0     1
1     2
2   'A'
3  4.22

In [20]: df[""col_1""].apply(type).value_counts()
Out[20]: 
col_1
    4
Name: count, dtype: int64
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv
"In [21]: df2 = pd.read_csv(StringIO(data))

In [22]: df2[""col_1""] = pd.to_numeric(df2[""col_1""], errors=""coerce"")

In [23]: df2
Out[23]: 
   col_1
0   1.00
1   2.00
2    NaN
3   4.22

In [24]: df2[""col_1""].apply(type).value_counts()
Out[24]: 
col_1
    4
Name: count, dtype: int64
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv pandas.to_numeric
"In [25]: col_1 = list(range(500000)) + [""a"", ""b""] + list(range(500000))

In [26]: df = pd.DataFrame({""col_1"": col_1})

In [27]: df.to_csv(""foo.csv"")

In [28]: mixed_df = pd.read_csv(""foo.csv"")

In [29]: mixed_df[""col_1""].apply(type).value_counts()
Out[29]: 
col_1
    737858
    262144
Name: count, dtype: int64

In [30]: mixed_df[""col_1""].dtype
Out[30]: dtype('O')
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame pandas.DataFrame.to_csv pandas.read_csv
"In [31]: data = """"""a,b,c,d,e,f,g,h,i,j
   ....: 1,2.5,True,a,,,,,12-31-2019,
   ....: 3,4.5,False,b,6,7.5,True,a,12-31-2019,
   ....: """"""
   ....: 

In [32]: df = pd.read_csv(StringIO(data), dtype_backend=""numpy_nullable"", parse_dates=[""i""])

In [33]: df
Out[33]: 
   a    b      c  d     e     f     g     h          i     j
0  1  2.5   True  a         2019-12-31  
1  3  4.5  False  b     6   7.5  True     a 2019-12-31  

In [34]: df.dtypes
Out[34]: 
a             Int64
b           Float64
c           boolean
d    string[python]
e             Int64
f           Float64
g           boolean
h    string[python]
i    datetime64[ns]
j             Int64
dtype: object
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv
"In [35]: data = ""col1,col2,col3\na,b,1\na,b,2\nc,d,3""

In [36]: pd.read_csv(StringIO(data))
Out[36]: 
  col1 col2  col3
0    a    b     1
1    a    b     2
2    c    d     3

In [37]: pd.read_csv(StringIO(data)).dtypes
Out[37]: 
col1    object
col2    object
col3     int64
dtype: object

In [38]: pd.read_csv(StringIO(data), dtype=""category"").dtypes
Out[38]: 
col1    category
col2    category
col3    category
dtype: object
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv
"In [39]: pd.read_csv(StringIO(data), dtype={""col1"": ""category""}).dtypes
Out[39]: 
col1    category
col2      object
col3       int64
dtype: object
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv
"In [40]: from pandas.api.types import CategoricalDtype

In [41]: dtype = CategoricalDtype([""d"", ""c"", ""b"", ""a""], ordered=True)

In [42]: pd.read_csv(StringIO(data), dtype={""col1"": dtype}).dtypes
Out[42]: 
col1    category
col2      object
col3       int64
dtype: object
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.CategoricalDtype pandas.read_csv
"In [43]: dtype = CategoricalDtype([""a"", ""b"", ""d""])  # No 'c'

In [44]: pd.read_csv(StringIO(data), dtype={""col1"": dtype}).col1
Out[44]: 
0      a
1      a
2    NaN
Name: col1, dtype: category
Categories (3, object): ['a', 'b', 'd']
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.CategoricalDtype pandas.read_csv
"In [45]: df = pd.read_csv(StringIO(data), dtype=""category"")

In [46]: df.dtypes
Out[46]: 
col1    category
col2    category
col3    category
dtype: object

In [47]: df[""col3""]
Out[47]: 
0    1
1    2
2    3
Name: col3, dtype: category
Categories (3, object): ['1', '2', '3']

In [48]: new_categories = pd.to_numeric(df[""col3""].cat.categories)

In [49]: df[""col3""] = df[""col3""].cat.rename_categories(new_categories)

In [50]: df[""col3""]
Out[50]: 
0    1
1    2
2    3
Name: col3, dtype: category
Categories (3, int64): [1, 2, 3]
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv pandas.to_numeric
"In [51]: data = ""a,b,c\n1,2,3\n4,5,6\n7,8,9""

In [52]: print(data)
a,b,c
1,2,3
4,5,6
7,8,9

In [53]: pd.read_csv(StringIO(data))
Out[53]: 
   a  b  c
0  1  2  3
1  4  5  6
2  7  8  9
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv
"In [54]: print(data)
a,b,c
1,2,3
4,5,6
7,8,9

In [55]: pd.read_csv(StringIO(data), names=[""foo"", ""bar"", ""baz""], header=0)
Out[55]: 
   foo  bar  baz
0    1    2    3
1    4    5    6
2    7    8    9

In [56]: pd.read_csv(StringIO(data), names=[""foo"", ""bar"", ""baz""], header=None)
Out[56]: 
  foo bar baz
0   a   b   c
1   1   2   3
2   4   5   6
3   7   8   9
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv
"In [57]: data = ""skip this skip it\na,b,c\n1,2,3\n4,5,6\n7,8,9""

In [58]: pd.read_csv(StringIO(data), header=1)
Out[58]: 
   a  b  c
0  1  2  3
1  4  5  6
2  7  8  9
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv
"In [59]: data = ""a,b,a\n0,1,2\n3,4,5""

In [60]: pd.read_csv(StringIO(data))
Out[60]: 
   a  b  a.1
0  0  1    2
1  3  4    5
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv
"In [61]: data = ""a,b,c,d\n1,2,3,foo\n4,5,6,bar\n7,8,9,baz""

In [62]: pd.read_csv(StringIO(data))
Out[62]: 
   a  b  c    d
0  1  2  3  foo
1  4  5  6  bar
2  7  8  9  baz

In [63]: pd.read_csv(StringIO(data), usecols=[""b"", ""d""])
Out[63]: 
   b    d
0  2  foo
1  5  bar
2  8  baz

In [64]: pd.read_csv(StringIO(data), usecols=[0, 2, 3])
Out[64]: 
   a  c    d
0  1  3  foo
1  4  6  bar
2  7  9  baz

In [65]: pd.read_csv(StringIO(data), usecols=lambda x: x.upper() in [""A"", ""C""])
Out[65]: 
   a  c
0  1  3
1  4  6
2  7  9
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv pandas.Series.str.upper
"In [66]: pd.read_csv(StringIO(data), usecols=lambda x: x not in [""a"", ""c""])
Out[66]: 
   b    d
0  2  foo
1  5  bar
2  8  baz
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv
"In [67]: data = ""\na,b,c\n  \n# commented line\n1,2,3\n\n4,5,6""

In [68]: print(data)

a,b,c
  
# commented line
1,2,3

4,5,6

In [69]: pd.read_csv(StringIO(data), comment=""#"")
Out[69]: 
   a  b  c
0  1  2  3
1  4  5  6
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv
"In [70]: data = ""a,b,c\n\n1,2,3\n\n\n4,5,6""

In [71]: pd.read_csv(StringIO(data), skip_blank_lines=False)
Out[71]: 
     a    b    c
0  NaN  NaN  NaN
1  1.0  2.0  3.0
2  NaN  NaN  NaN
3  NaN  NaN  NaN
4  4.0  5.0  6.0
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv
"In [72]: data = ""#comment\na,b,c\nA,B,C\n1,2,3""

In [73]: pd.read_csv(StringIO(data), comment=""#"", header=1)
Out[73]: 
   A  B  C
0  1  2  3

In [74]: data = ""A,B,C\n#comment\na,b,c\n1,2,3""

In [75]: pd.read_csv(StringIO(data), comment=""#"", skiprows=2)
Out[75]: 
   a  b  c
0  1  2  3
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv
"In [76]: data = (
   ....:     ""# empty\n""
   ....:     ""# second empty line\n""
   ....:     ""# third emptyline\n""
   ....:     ""X,Y,Z\n""
   ....:     ""1,2,3\n""
   ....:     ""A,B,C\n""
   ....:     ""1,2.,4.\n""
   ....:     ""5.,NaN,10.0\n""
   ....: )
   ....: 

In [77]: print(data)
# empty
# second empty line
# third emptyline
X,Y,Z
1,2,3
A,B,C
1,2.,4.
5.,NaN,10.0


In [78]: pd.read_csv(StringIO(data), comment=""#"", skiprows=4, header=1)
Out[78]: 
     A    B     C
0  1.0  2.0   4.0
1  5.0  NaN  10.0
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv
"In [82]: df = pd.read_csv(""tmp.csv"")

In [83]: df
Out[83]: 
         ID    level                        category
0  Patient1   123000           x # really unpleasant
1  Patient2    23000  y # wouldn't take his medicine
2  Patient3  1234018                     z # awesome
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv
"In [84]: df = pd.read_csv(""tmp.csv"", comment=""#"")

In [85]: df
Out[85]: 
         ID    level category
0  Patient1   123000       x 
1  Patient2    23000       y 
2  Patient3  1234018       z 
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv
"In [86]: from io import BytesIO

In [87]: data = b""word,length\n"" b""Tr\xc3\xa4umen,7\n"" b""Gr\xc3\xbc\xc3\x9fe,5""

In [88]: data = data.decode(""utf8"").encode(""latin-1"")

In [89]: df = pd.read_csv(BytesIO(data), encoding=""latin-1"")

In [90]: df
Out[90]: 
      word  length
0  Träumen       7
1    Grüße       5

In [91]: df[""word""][1]
Out[91]: 'Grüße'
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.Series.str.encode pandas.read_csv
"In [92]: data = ""a,b,c\n4,apple,bat,5.7\n8,orange,cow,10""

In [93]: pd.read_csv(StringIO(data))
Out[93]: 
        a    b     c
4   apple  bat   5.7
8  orange  cow  10.0
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv
"In [94]: data = ""index,a,b,c\n4,apple,bat,5.7\n8,orange,cow,10""

In [95]: pd.read_csv(StringIO(data), index_col=0)
Out[95]: 
            a    b     c
index                   
4       apple  bat   5.7
8      orange  cow  10.0
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv
"In [96]: data = ""a,b,c\n4,apple,bat,\n8,orange,cow,""

In [97]: print(data)
a,b,c
4,apple,bat,
8,orange,cow,

In [98]: pd.read_csv(StringIO(data))
Out[98]: 
        a    b   c
4   apple  bat NaN
8  orange  cow NaN

In [99]: pd.read_csv(StringIO(data), index_col=False)
Out[99]: 
   a       b    c
0  4   apple  bat
1  8  orange  cow
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv
"In [100]: data = ""a,b,c\n4,apple,bat,\n8,orange,cow,""

In [101]: print(data)
a,b,c
4,apple,bat,
8,orange,cow,

In [102]: pd.read_csv(StringIO(data), usecols=[""b"", ""c""])
Out[102]: 
     b   c
4  bat NaN
8  cow NaN

In [103]: pd.read_csv(StringIO(data), usecols=[""b"", ""c""], index_col=0)
Out[103]: 
     b   c
4  bat NaN
8  cow NaN
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv
"In [104]: with open(""foo.csv"", mode=""w"") as f:
   .....:     f.write(""date,A,B,C\n20090101,a,1,2\n20090102,b,3,4\n20090103,c,4,5"")
   .....: 

# Use a column as an index, and parse it as dates.
In [105]: df = pd.read_csv(""foo.csv"", index_col=0, parse_dates=True)

In [106]: df
Out[106]: 
            A  B  C
date               
2009-01-01  a  1  2
2009-01-02  b  3  4
2009-01-03  c  4  5

# These are Python datetime objects
In [107]: df.index
Out[107]: DatetimeIndex(['2009-01-01', '2009-01-02', '2009-01-03'], dtype='datetime64[ns]', name='date', freq=None)
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv pandas.DatetimeIndex
"In [108]: data = (
   .....:     ""KORD,19990127, 19:00:00, 18:56:00, 0.8100\n""
   .....:     ""KORD,19990127, 20:00:00, 19:56:00, 0.0100\n""
   .....:     ""KORD,19990127, 21:00:00, 20:56:00, -0.5900\n""
   .....:     ""KORD,19990127, 21:00:00, 21:18:00, -0.9900\n""
   .....:     ""KORD,19990127, 22:00:00, 21:56:00, -0.5900\n""
   .....:     ""KORD,19990127, 23:00:00, 22:56:00, -0.5900""
   .....: )
   .....: 

In [109]: with open(""tmp.csv"", ""w"") as fh:
   .....:     fh.write(data)
   .....: 

In [110]: df = pd.read_csv(""tmp.csv"", header=None, parse_dates=[[1, 2], [1, 3]])

In [111]: df
Out[111]: 
                  1_2                 1_3     0     4
0 1999-01-27 19:00:00 1999-01-27 18:56:00  KORD  0.81
1 1999-01-27 20:00:00 1999-01-27 19:56:00  KORD  0.01
2 1999-01-27 21:00:00 1999-01-27 20:56:00  KORD -0.59
3 1999-01-27 21:00:00 1999-01-27 21:18:00  KORD -0.99
4 1999-01-27 22:00:00 1999-01-27 21:56:00  KORD -0.59
5 1999-01-27 23:00:00 1999-01-27 22:56:00  KORD -0.59
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv
"In [112]: df = pd.read_csv(
   .....:     ""tmp.csv"", header=None, parse_dates=[[1, 2], [1, 3]], keep_date_col=True
   .....: )
   .....: 

In [113]: df
Out[113]: 
                  1_2                 1_3     0  ...          2          3     4
0 1999-01-27 19:00:00 1999-01-27 18:56:00  KORD  ...   19:00:00   18:56:00  0.81
1 1999-01-27 20:00:00 1999-01-27 19:56:00  KORD  ...   20:00:00   19:56:00  0.01
2 1999-01-27 21:00:00 1999-01-27 20:56:00  KORD  ...   21:00:00   20:56:00 -0.59
3 1999-01-27 21:00:00 1999-01-27 21:18:00  KORD  ...   21:00:00   21:18:00 -0.99
4 1999-01-27 22:00:00 1999-01-27 21:56:00  KORD  ...   22:00:00   21:56:00 -0.59
5 1999-01-27 23:00:00 1999-01-27 22:56:00  KORD  ...   23:00:00   22:56:00 -0.59

[6 rows x 7 columns]
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv
"In [114]: date_spec = {""nominal"": [1, 2], ""actual"": [1, 3]}

In [115]: df = pd.read_csv(""tmp.csv"", header=None, parse_dates=date_spec)

In [116]: df
Out[116]: 
              nominal              actual     0     4
0 1999-01-27 19:00:00 1999-01-27 18:56:00  KORD  0.81
1 1999-01-27 20:00:00 1999-01-27 19:56:00  KORD  0.01
2 1999-01-27 21:00:00 1999-01-27 20:56:00  KORD -0.59
3 1999-01-27 21:00:00 1999-01-27 21:18:00  KORD -0.99
4 1999-01-27 22:00:00 1999-01-27 21:56:00  KORD -0.59
5 1999-01-27 23:00:00 1999-01-27 22:56:00  KORD -0.59
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv
"In [117]: date_spec = {""nominal"": [1, 2], ""actual"": [1, 3]}

In [118]: df = pd.read_csv(
   .....:     ""tmp.csv"", header=None, parse_dates=date_spec, index_col=0
   .....: )  # index is the nominal column
   .....: 

In [119]: df
Out[119]: 
                                 actual     0     4
nominal                                            
1999-01-27 19:00:00 1999-01-27 18:56:00  KORD  0.81
1999-01-27 20:00:00 1999-01-27 19:56:00  KORD  0.01
1999-01-27 21:00:00 1999-01-27 20:56:00  KORD -0.59
1999-01-27 21:00:00 1999-01-27 21:18:00  KORD -0.99
1999-01-27 22:00:00 1999-01-27 21:56:00  KORD -0.59
1999-01-27 23:00:00 1999-01-27 22:56:00  KORD -0.59
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv
"In [120]: content = """"""\
   .....: a
   .....: 2000-01-01T00:00:00+05:00
   .....: 2000-01-01T00:00:00+06:00""""""
   .....: 

In [121]: df = pd.read_csv(StringIO(content))

In [122]: df[""a""] = pd.to_datetime(df[""a""], utc=True)

In [123]: df[""a""]
Out[123]: 
0   1999-12-31 19:00:00+00:00
1   1999-12-31 18:00:00+00:00
Name: a, dtype: datetime64[ns, UTC]
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv pandas.to_datetime
"In [124]: df = pd.read_csv(
   .....:     ""foo.csv"",
   .....:     index_col=0,
   .....:     parse_dates=True,
   .....: )
   .....: 

In [125]: df
Out[125]: 
            A  B  C
date               
2009-01-01  a  1  2
2009-01-02  b  3  4
2009-01-03  c  4  5
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv
"In [126]: data = StringIO(""date\n12 Jan 2000\n2000-01-13\n"")

In [127]: df = pd.read_csv(data)

In [128]: df['date'] = pd.to_datetime(df['date'], format='mixed')

In [129]: df
Out[129]: 
        date
0 2000-01-12
1 2000-01-13
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv pandas.to_datetime
"In [130]: data = StringIO(""date\n2020-01-01\n2020-01-01 03:00\n"")

In [131]: df = pd.read_csv(data)

In [132]: df['date'] = pd.to_datetime(df['date'], format='ISO8601')

In [133]: df
Out[133]: 
                 date
0 2020-01-01 00:00:00
1 2020-01-01 03:00:00
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv pandas.to_datetime
"In [134]: data = ""date,value,cat\n1/6/2000,5,a\n2/6/2000,10,b\n3/6/2000,15,c""

In [135]: print(data)
date,value,cat
1/6/2000,5,a
2/6/2000,10,b
3/6/2000,15,c

In [136]: with open(""tmp.csv"", ""w"") as fh:
   .....:     fh.write(data)
   .....: 

In [137]: pd.read_csv(""tmp.csv"", parse_dates=[0])
Out[137]: 
        date  value cat
0 2000-01-06      5   a
1 2000-02-06     10   b
2 2000-03-06     15   c

In [138]: pd.read_csv(""tmp.csv"", dayfirst=True, parse_dates=[0])
Out[138]: 
        date  value cat
0 2000-06-01      5   a
1 2000-06-02     10   b
2 2000-06-03     15   c
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv
"In [139]: import io

In [140]: data = pd.DataFrame([0, 1, 2])

In [141]: buffer = io.BytesIO()

In [142]: data.to_csv(buffer, encoding=""utf-8"", compression=""gzip"")
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame pandas.DataFrame.to_csv
"In [143]: val = ""0.3066101993807095471566981359501369297504425048828125""

In [144]: data = ""a,b,c\n1,2,{0}"".format(val)

In [145]: abs(
   .....:     pd.read_csv(
   .....:         StringIO(data),
   .....:         engine=""c"",
   .....:         float_precision=None,
   .....:     )[""c""][0] - float(val)
   .....: )
   .....: 
Out[145]: 5.551115123125783e-17

In [146]: abs(
   .....:     pd.read_csv(
   .....:         StringIO(data),
   .....:         engine=""c"",
   .....:         float_precision=""high"",
   .....:     )[""c""][0] - float(val)
   .....: )
   .....: 
Out[146]: 5.551115123125783e-17

In [147]: abs(
   .....:     pd.read_csv(StringIO(data), engine=""c"", float_precision=""round_trip"")[""c""][0]
   .....:     - float(val)
   .....: )
   .....: 
Out[147]: 0.0
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.io.formats.style.Styler.format pandas.read_csv
"In [148]: data = (
   .....:     ""ID|level|category\n""
   .....:     ""Patient1|123,000|x\n""
   .....:     ""Patient2|23,000|y\n""
   .....:     ""Patient3|1,234,018|z""
   .....: )
   .....: 

In [149]: with open(""tmp.csv"", ""w"") as fh:
   .....:     fh.write(data)
   .....: 

In [150]: df = pd.read_csv(""tmp.csv"", sep=""|"")

In [151]: df
Out[151]: 
         ID      level category
0  Patient1    123,000        x
1  Patient2     23,000        y
2  Patient3  1,234,018        z

In [152]: df.level.dtype
Out[152]: dtype('O')
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv
"In [153]: df = pd.read_csv(""tmp.csv"", sep=""|"", thousands="","")

In [154]: df
Out[154]: 
         ID    level category
0  Patient1   123000        x
1  Patient2    23000        y
2  Patient3  1234018        z

In [155]: df.level.dtype
Out[155]: dtype('int64')
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv
"pd.read_csv(""path_to_file.csv"", na_values=[5])
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv
"pd.read_csv(""path_to_file.csv"", keep_default_na=False, na_values=[""""])
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv
"pd.read_csv(""path_to_file.csv"", keep_default_na=False, na_values=[""NA"", ""0""])
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv
"pd.read_csv(""path_to_file.csv"", na_values=[""Nope""])
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv
"In [156]: data = ""a,b,c\n1,Yes,2\n3,No,4""

In [157]: print(data)
a,b,c
1,Yes,2
3,No,4

In [158]: pd.read_csv(StringIO(data))
Out[158]: 
   a    b  c
0  1  Yes  2
1  3   No  4

In [159]: pd.read_csv(StringIO(data), true_values=[""Yes""], false_values=[""No""])
Out[159]: 
   a      b  c
0  1   True  2
1  3  False  4
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv
"In [160]: data = ""a,b,c\n1,2,3\n4,5,6,7\n8,9,10""

In [161]: pd.read_csv(StringIO(data))
---------------------------------------------------------------------------
ParserError                               Traceback (most recent call last)
Cell In[161], line 1
----> 1 pd.read_csv(StringIO(data))

File ~/work/pandas/pandas/pandas/io/parsers/readers.py:1026, in read_csv(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)
   1013 kwds_defaults = _refine_defaults_read(
   1014     dialect,
   1015     delimiter,
   (...)
   1022     dtype_backend=dtype_backend,
   1023 )
   1024 kwds.update(kwds_defaults)
-> 1026 return _read(filepath_or_buffer, kwds)

File ~/work/pandas/pandas/pandas/io/parsers/readers.py:626, in _read(filepath_or_buffer, kwds)
    623     return parser
    625 with parser:
--> 626     return parser.read(nrows)

File ~/work/pandas/pandas/pandas/io/parsers/readers.py:1923, in TextFileReader.read(self, nrows)
   1916 nrows = validate_integer(""nrows"", nrows)
   1917 try:
   1918     # error: ""ParserBase"" has no attribute ""read""
   1919     (
   1920         index,
   1921         columns,
   1922         col_dict,
-> 1923     ) = self._engine.read(  # type: ignore[attr-defined]
   1924         nrows
   1925     )
   1926 except Exception:
   1927     self.close()

File ~/work/pandas/pandas/pandas/io/parsers/c_parser_wrapper.py:234, in CParserWrapper.read(self, nrows)
    232 try:
    233     if self.low_memory:
--> 234         chunks = self._reader.read_low_memory(nrows)
    235         # destructive to chunks
    236         data = _concatenate_chunks(chunks)

File parsers.pyx:838, in pandas._libs.parsers.TextReader.read_low_memory()

File parsers.pyx:905, in pandas._libs.parsers.TextReader._read_rows()

File parsers.pyx:874, in pandas._libs.parsers.TextReader._tokenize_rows()

File parsers.pyx:891, in pandas._libs.parsers.TextReader._check_tokenize_status()

File parsers.pyx:2061, in pandas._libs.parsers.raise_parser_error()

ParserError: Error tokenizing data. C error: Expected 3 fields in line 3, saw 4
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv pandas.read_csv
"In [162]: data = ""a,b,c\n1,2,3\n4,5,6,7\n8,9,10""

In [163]: pd.read_csv(StringIO(data), on_bad_lines=""skip"")
Out[163]: 
   a  b   c
0  1  2   3
1  8  9  10
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv
"In [167]: bad_lines_func = lambda line: print(line)

In [168]: data = 'name,type\nname a,a is of type a\nname b,""b\"" is of type b""'

In [169]: data
Out[169]: 'name,type\nname a,a is of type a\nname b,""b"" is of type b""'

In [170]: pd.read_csv(StringIO(data), on_bad_lines=bad_lines_func, engine=""python"")
Out[170]: 
     name            type
0  name a  a is of type a
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv
"In [171]: pd.read_csv(StringIO(data), usecols=[0, 1, 2])
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
Cell In[171], line 1
----> 1 pd.read_csv(StringIO(data), usecols=[0, 1, 2])

File ~/work/pandas/pandas/pandas/io/parsers/readers.py:1026, in read_csv(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)
   1013 kwds_defaults = _refine_defaults_read(
   1014     dialect,
   1015     delimiter,
   (...)
   1022     dtype_backend=dtype_backend,
   1023 )
   1024 kwds.update(kwds_defaults)
-> 1026 return _read(filepath_or_buffer, kwds)

File ~/work/pandas/pandas/pandas/io/parsers/readers.py:620, in _read(filepath_or_buffer, kwds)
    617 _validate_names(kwds.get(""names"", None))
    619 # Create the parser.
--> 620 parser = TextFileReader(filepath_or_buffer, **kwds)
    622 if chunksize or iterator:
    623     return parser

File ~/work/pandas/pandas/pandas/io/parsers/readers.py:1620, in TextFileReader.__init__(self, f, engine, **kwds)
   1617     self.options[""has_index_names""] = kwds[""has_index_names""]
   1619 self.handles: IOHandles | None = None
-> 1620 self._engine = self._make_engine(f, self.engine)

File ~/work/pandas/pandas/pandas/io/parsers/readers.py:1898, in TextFileReader._make_engine(self, f, engine)
   1895     raise ValueError(msg)
   1897 try:
-> 1898     return mapping[engine](f, **self.options)
   1899 except Exception:
   1900     if self.handles is not None:

File ~/work/pandas/pandas/pandas/io/parsers/c_parser_wrapper.py:155, in CParserWrapper.__init__(self, src, **kwds)
    152     # error: Cannot determine type of 'names'
    153     if len(self.names) < len(usecols):  # type: ignore[has-type]
    154         # error: Cannot determine type of 'names'
--> 155         self._validate_usecols_names(
    156             usecols,
    157             self.names,  # type: ignore[has-type]
    158         )
    160 # error: Cannot determine type of 'names'
    161 self._validate_parse_dates_presence(self.names)  # type: ignore[has-type]

File ~/work/pandas/pandas/pandas/io/parsers/base_parser.py:979, in ParserBase._validate_usecols_names(self, usecols, names)
    977 missing = [c for c in usecols if c not in names]
    978 if len(missing) > 0:
--> 979     raise ValueError(
    980         f""Usecols do not match columns, columns expected but not found: ""
    981         f""{missing}""
    982     )
    984 return usecols

ValueError: Usecols do not match columns, columns expected but not found: [0, 1, 2]
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv pandas.read_csv
"In [172]: pd.read_csv(StringIO(data), names=['a', 'b', 'c', 'd'])
Out[172]: 
        a                b   c   d
0    name             type NaN NaN
1  name a   a is of type a NaN NaN
2  name b  b is of type b"" NaN NaN
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv
"In [175]: import csv

In [176]: dia = csv.excel()

In [177]: dia.quoting = csv.QUOTE_NONE

In [178]: pd.read_csv(StringIO(data), dialect=dia)
Out[178]: 
       label1 label2 label3
index1     ""a      c      e
index2      b      d      f
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv
"In [179]: data = ""a,b,c~1,2,3~4,5,6""

In [180]: pd.read_csv(StringIO(data), lineterminator=""~"")
Out[180]: 
   a  b  c
0  1  2  3
1  4  5  6
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv
"In [181]: data = ""a, b, c\n1, 2, 3\n4, 5, 6""

In [182]: print(data)
a, b, c
1, 2, 3
4, 5, 6

In [183]: pd.read_csv(StringIO(data), skipinitialspace=True)
Out[183]: 
   a  b  c
0  1  2  3
1  4  5  6
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv
"In [184]: data = 'a,b\n""hello, \\""Bob\\"", nice to see you"",5'

In [185]: print(data)
a,b
""hello, \""Bob\"", nice to see you"",5

In [186]: pd.read_csv(StringIO(data), escapechar=""\\"")
Out[186]: 
                               a  b
0  hello, ""Bob"", nice to see you  5
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv
"# Column specifications are a list of half-intervals
In [189]: colspecs = [(0, 6), (8, 20), (21, 33), (34, 43)]

In [190]: df = pd.read_fwf(""bar.csv"", colspecs=colspecs, header=None, index_col=0)

In [191]: df
Out[191]: 
                 1           2        3
0                                      
id8141  360.242940  149.910199  11950.7
id1594  444.953632  166.985655  11788.4
id1849  364.136849  183.628767  11806.2
id1230  413.836124  184.375703  11916.8
id1948  502.953953  173.237159  12468.3
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_fwf
"# Widths are a list of integers
In [192]: widths = [6, 14, 13, 10]

In [193]: df = pd.read_fwf(""bar.csv"", widths=widths, header=None)

In [194]: df
Out[194]: 
        0           1           2        3
0  id8141  360.242940  149.910199  11950.7
1  id1594  444.953632  166.985655  11788.4
2  id1849  364.136849  183.628767  11806.2
3  id1230  413.836124  184.375703  11916.8
4  id1948  502.953953  173.237159  12468.3
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_fwf
"In [195]: df = pd.read_fwf(""bar.csv"", header=None, index_col=0)

In [196]: df
Out[196]: 
                 1           2        3
0                                      
id8141  360.242940  149.910199  11950.7
id1594  444.953632  166.985655  11788.4
id1849  364.136849  183.628767  11806.2
id1230  413.836124  184.375703  11916.8
id1948  502.953953  173.237159  12468.3
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_fwf
"In [197]: pd.read_fwf(""bar.csv"", header=None, index_col=0).dtypes
Out[197]: 
1    float64
2    float64
3    float64
dtype: object

In [198]: pd.read_fwf(""bar.csv"", header=None, dtype={2: ""object""}).dtypes
Out[198]: 
0     object
1    float64
2     object
3    float64
dtype: object
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_fwf
"In [202]: pd.read_csv(""foo.csv"")
Out[202]: 
          A  B  C
20090101  a  1  2
20090102  b  3  4
20090103  c  4  5
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv
"In [203]: df = pd.read_csv(""foo.csv"", parse_dates=True)

In [204]: df.index
Out[204]: DatetimeIndex(['2009-01-01', '2009-01-02', '2009-01-03'], dtype='datetime64[ns]', freq=None)
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv pandas.DatetimeIndex
"In [208]: df = pd.read_csv(""mindex_ex.csv"", index_col=[0, 1])

In [209]: df
Out[209]: 
            zit  xit
year indiv          
1977 A      1.2  0.6
     B      1.5  0.5

In [210]: df.loc[1977]
Out[210]: 
       zit  xit
indiv          
A      1.2  0.6
B      1.5  0.5
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv
"In [211]: mi_idx = pd.MultiIndex.from_arrays([[1, 2, 3, 4], list(""abcd"")], names=list(""ab""))

In [212]: mi_col = pd.MultiIndex.from_arrays([[1, 2], list(""ab"")], names=list(""cd""))

In [213]: df = pd.DataFrame(np.ones((4, 2)), index=mi_idx, columns=mi_col)

In [214]: df.to_csv(""mi.csv"")

In [215]: print(open(""mi.csv"").read())
c,,1,2
d,,a,b
a,b,,
1,a,1.0,1.0
2,b,1.0,1.0
3,c,1.0,1.0
4,d,1.0,1.0


In [216]: pd.read_csv(""mi.csv"", header=[0, 1, 2, 3], index_col=[0, 1])
Out[216]: 
c                    1                  2
d                    a                  b
a   Unnamed: 2_level_2 Unnamed: 3_level_2
1                  1.0                1.0
2 b                1.0                1.0
3 c                1.0                1.0
4 d                1.0                1.0
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.MultiIndex.from_arrays pandas.DataFrame pandas.DataFrame.to_csv pandas.read_csv
"In [217]: data = "",a,a,a,b,c,c\n,q,r,s,t,u,v\none,1,2,3,4,5,6\ntwo,7,8,9,10,11,12""

In [218]: print(data)
,a,a,a,b,c,c
,q,r,s,t,u,v
one,1,2,3,4,5,6
two,7,8,9,10,11,12

In [219]: with open(""mi2.csv"", ""w"") as fh:
   .....:     fh.write(data)
   .....: 

In [220]: pd.read_csv(""mi2.csv"", header=[0, 1], index_col=0)
Out[220]: 
     a         b   c    
     q  r  s   t   u   v
one  1  2  3   4   5   6
two  7  8  9  10  11  12
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv
"In [221]: df = pd.DataFrame(np.random.randn(10, 4))

In [222]: df.to_csv(""tmp2.csv"", sep="":"", index=False)

In [223]: pd.read_csv(""tmp2.csv"", sep=None, engine=""python"")
Out[223]: 
          0         1         2         3
0  0.469112 -0.282863 -1.509059 -1.135632
1  1.212112 -0.173215  0.119209 -1.044236
2 -0.861849 -2.104569 -0.494929  1.071804
3  0.721555 -0.706771 -1.039575  0.271860
4 -0.424972  0.567020  0.276232 -1.087401
5 -0.673690  0.113648 -1.478427  0.524988
6  0.404705  0.577046 -1.715002 -1.039268
7 -0.370647 -1.157892 -1.344312  0.844885
8  1.075770 -0.109050  1.643563 -1.469388
9  0.357021 -0.674600 -1.776904 -0.968914
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame pandas.DataFrame.to_csv pandas.read_csv
"In [224]: df = pd.DataFrame(np.random.randn(10, 4))

In [225]: df.to_csv(""tmp.csv"", index=False)

In [226]: table = pd.read_csv(""tmp.csv"")

In [227]: table
Out[227]: 
          0         1         2         3
0 -1.294524  0.413738  0.276662 -0.472035
1 -0.013960 -0.362543 -0.006154 -0.923061
2  0.895717  0.805244 -1.206412  2.565646
3  1.431256  1.340309 -1.170299 -0.226169
4  0.410835  0.813850  0.132003 -0.827317
5 -0.076467 -1.187678  1.130127 -1.436737
6 -1.413681  1.607920  1.024180  0.569605
7  0.875906 -2.211372  0.974466 -2.006747
8 -0.410001 -0.078638  0.545952 -1.219217
9 -1.226825  0.769804 -1.281247 -0.727707
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame pandas.DataFrame.to_csv pandas.read_csv
"In [228]: with pd.read_csv(""tmp.csv"", chunksize=4) as reader:
   .....:     print(reader)
   .....:     for chunk in reader:
   .....:         print(chunk)
   .....: 

          0         1         2         3
0 -1.294524  0.413738  0.276662 -0.472035
1 -0.013960 -0.362543 -0.006154 -0.923061
2  0.895717  0.805244 -1.206412  2.565646
3  1.431256  1.340309 -1.170299 -0.226169
          0         1         2         3
4  0.410835  0.813850  0.132003 -0.827317
5 -0.076467 -1.187678  1.130127 -1.436737
6 -1.413681  1.607920  1.024180  0.569605
7  0.875906 -2.211372  0.974466 -2.006747
          0         1         2         3
8 -0.410001 -0.078638  0.545952 -1.219217
9 -1.226825  0.769804 -1.281247 -0.727707
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv
"In [229]: with pd.read_csv(""tmp.csv"", iterator=True) as reader:
   .....:     print(reader.get_chunk(5))
   .....: 
          0         1         2         3
0 -1.294524  0.413738  0.276662 -0.472035
1 -0.013960 -0.362543 -0.006154 -0.923061
2  0.895717  0.805244 -1.206412  2.565646
3  1.431256  1.340309 -1.170299 -0.226169
4  0.410835  0.813850  0.132003 -0.827317
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv
"df = pd.read_csv(""https://download.bls.gov/pub/time.series/cu/cu.item"", sep=""\t"")
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv
"headers = {""User-Agent"": ""pandas""}
df = pd.read_csv(
    ""https://download.bls.gov/pub/time.series/cu/cu.item"",
    sep=""\t"",
    storage_options=headers
)
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv
"df = pd.read_json(""s3://pandas-test/adatafile.json"")
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_json
"storage_options = {""client_kwargs"": {""endpoint_url"": ""http://127.0.0.1:5555""}}}
df = pd.read_json(""s3://pandas-test/test-1"", storage_options=storage_options)
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_json
"pd.read_csv(
    ""s3://ncei-wcsd-archive/data/processed/SH1305/18kHz/SaKe2013""
    ""-D20130523-T080854_to_SaKe2013-D20130523-T085643.csv"",
    storage_options={""anon"": True},
)
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv
"pd.read_csv(
    ""simplecache::s3://ncei-wcsd-archive/data/processed/SH1305/18kHz/""
    ""SaKe2013-D20130523-T080854_to_SaKe2013-D20130523-T085643.csv"",
    storage_options={""s3"": {""anon"": True}},
)
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_csv
"In [230]: dfj = pd.DataFrame(np.random.randn(5, 2), columns=list(""AB""))

In [231]: json = dfj.to_json()

In [232]: json
Out[232]: '{""A"":{""0"":-0.1213062281,""1"":0.6957746499,""2"":0.9597255933,""3"":-0.6199759194,""4"":-0.7323393705},""B"":{""0"":-0.0978826728,""1"":0.3417343559,""2"":-1.1103361029,""3"":0.1497483186,""4"":0.6877383895}}'
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame pandas.DataFrame.to_json
"In [233]: dfjo = pd.DataFrame(
   .....:     dict(A=range(1, 4), B=range(4, 7), C=range(7, 10)),
   .....:     columns=list(""ABC""),
   .....:     index=list(""xyz""),
   .....: )
   .....: 

In [234]: dfjo
Out[234]: 
   A  B  C
x  1  4  7
y  2  5  8
z  3  6  9

In [235]: sjo = pd.Series(dict(x=15, y=16, z=17), name=""D"")

In [236]: sjo
Out[236]: 
x    15
y    16
z    17
Name: D, dtype: int64
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame pandas.Series
"In [237]: dfjo.to_json(orient=""columns"")
Out[237]: '{""A"":{""x"":1,""y"":2,""z"":3},""B"":{""x"":4,""y"":5,""z"":6},""C"":{""x"":7,""y"":8,""z"":9}}'

# Not available for Series
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame.to_json
"In [238]: dfjo.to_json(orient=""index"")
Out[238]: '{""x"":{""A"":1,""B"":4,""C"":7},""y"":{""A"":2,""B"":5,""C"":8},""z"":{""A"":3,""B"":6,""C"":9}}'

In [239]: sjo.to_json(orient=""index"")
Out[239]: '{""x"":15,""y"":16,""z"":17}'
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame.to_json pandas.Series.to_json
"In [240]: dfjo.to_json(orient=""records"")
Out[240]: '[{""A"":1,""B"":4,""C"":7},{""A"":2,""B"":5,""C"":8},{""A"":3,""B"":6,""C"":9}]'

In [241]: sjo.to_json(orient=""records"")
Out[241]: '[15,16,17]'
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame.to_json pandas.Series.to_json
"In [242]: dfjo.to_json(orient=""values"")
Out[242]: '[[1,4,7],[2,5,8],[3,6,9]]'

# Not available for Series
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame.to_json
"In [243]: dfjo.to_json(orient=""split"")
Out[243]: '{""columns"":[""A"",""B"",""C""],""index"":[""x"",""y"",""z""],""data"":[[1,4,7],[2,5,8],[3,6,9]]}'

In [244]: sjo.to_json(orient=""split"")
Out[244]: '{""name"":""D"",""index"":[""x"",""y"",""z""],""data"":[15,16,17]}'
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame.to_json pandas.Series.to_json
"In [245]: dfd = pd.DataFrame(np.random.randn(5, 2), columns=list(""AB""))

In [246]: dfd[""date""] = pd.Timestamp(""20130101"")

In [247]: dfd = dfd.sort_index(axis=1, ascending=False)

In [248]: json = dfd.to_json(date_format=""iso"")

In [249]: json
Out[249]: '{""date"":{""0"":""2013-01-01T00:00:00.000"",""1"":""2013-01-01T00:00:00.000"",""2"":""2013-01-01T00:00:00.000"",""3"":""2013-01-01T00:00:00.000"",""4"":""2013-01-01T00:00:00.000""},""B"":{""0"":0.403309524,""1"":0.3016244523,""2"":-1.3698493577,""3"":1.4626960492,""4"":-0.8265909164},""A"":{""0"":0.1764443426,""1"":-0.1549507744,""2"":-2.1798606054,""3"":-0.9542078401,""4"":-1.7431609117}}'
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame pandas.DataFrame.sort_index pandas.DataFrame.to_json
"In [250]: json = dfd.to_json(date_format=""iso"", date_unit=""us"")

In [251]: json
Out[251]: '{""date"":{""0"":""2013-01-01T00:00:00.000000"",""1"":""2013-01-01T00:00:00.000000"",""2"":""2013-01-01T00:00:00.000000"",""3"":""2013-01-01T00:00:00.000000"",""4"":""2013-01-01T00:00:00.000000""},""B"":{""0"":0.403309524,""1"":0.3016244523,""2"":-1.3698493577,""3"":1.4626960492,""4"":-0.8265909164},""A"":{""0"":0.1764443426,""1"":-0.1549507744,""2"":-2.1798606054,""3"":-0.9542078401,""4"":-1.7431609117}}'
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame.to_json
"In [252]: json = dfd.to_json(date_format=""epoch"", date_unit=""s"")

In [253]: json
Out[253]: '{""date"":{""0"":1,""1"":1,""2"":1,""3"":1,""4"":1},""B"":{""0"":0.403309524,""1"":0.3016244523,""2"":-1.3698493577,""3"":1.4626960492,""4"":-0.8265909164},""A"":{""0"":0.1764443426,""1"":-0.1549507744,""2"":-2.1798606054,""3"":-0.9542078401,""4"":-1.7431609117}}'
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame.to_json
"In [254]: dfj2 = dfj.copy()

In [255]: dfj2[""date""] = pd.Timestamp(""20130101"")

In [256]: dfj2[""ints""] = list(range(5))

In [257]: dfj2[""bools""] = True

In [258]: dfj2.index = pd.date_range(""20130101"", periods=5)

In [259]: dfj2.to_json(""test.json"")

In [260]: with open(""test.json"") as fh:
   .....:     print(fh.read())
   .....: 
{""A"":{""1356998400000"":-0.1213062281,""1357084800000"":0.6957746499,""1357171200000"":0.9597255933,""1357257600000"":-0.6199759194,""1357344000000"":-0.7323393705},""B"":{""1356998400000"":-0.0978826728,""1357084800000"":0.3417343559,""1357171200000"":-1.1103361029,""1357257600000"":0.1497483186,""1357344000000"":0.6877383895},""date"":{""1356998400000"":1356,""1357084800000"":1356,""1357171200000"":1356,""1357257600000"":1356,""1357344000000"":1356},""ints"":{""1356998400000"":0,""1357084800000"":1,""1357171200000"":2,""1357257600000"":3,""1357344000000"":4},""bools"":{""1356998400000"":true,""1357084800000"":true,""1357171200000"":true,""1357257600000"":true,""1357344000000"":true}}
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame.copy pandas.date_range
">>> DataFrame([1.0, 2.0, complex(1.0, 2.0)]).to_json()  # raises
RuntimeError: Unhandled numpy dtype 15
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame
"In [261]: pd.DataFrame([1.0, 2.0, complex(1.0, 2.0)]).to_json(default_handler=str)
Out[261]: '{""0"":{""0"":""(1+0j)"",""1"":""(2+0j)"",""2"":""(1+2j)""}}'
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame
"In [262]: from io import StringIO

In [263]: pd.read_json(StringIO(json))
Out[263]: 
   date         B         A
0     1  0.403310  0.176444
1     1  0.301624 -0.154951
2     1 -1.369849 -2.179861
3     1  1.462696 -0.954208
4     1 -0.826591 -1.743161
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_json
"In [264]: pd.read_json(""test.json"")
Out[264]: 
                   A         B  date  ints  bools
2013-01-01 -0.121306 -0.097883  1356     0   True
2013-01-02  0.695775  0.341734  1356     1   True
2013-01-03  0.959726 -1.110336  1356     2   True
2013-01-04 -0.619976  0.149748  1356     3   True
2013-01-05 -0.732339  0.687738  1356     4   True
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_json
"In [265]: pd.read_json(""test.json"", dtype=object).dtypes
Out[265]: 
A        object
B        object
date     object
ints     object
bools    object
dtype: object
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_json
"In [266]: pd.read_json(""test.json"", dtype={""A"": ""float32"", ""bools"": ""int8""}).dtypes
Out[266]: 
A        float32
B        float64
date       int64
ints       int64
bools       int8
dtype: object
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_json
"In [267]: from io import StringIO

In [268]: si = pd.DataFrame(
   .....:     np.zeros((4, 4)), columns=list(range(4)), index=[str(i) for i in range(4)]
   .....: )
   .....: 

In [269]: si
Out[269]: 
     0    1    2    3
0  0.0  0.0  0.0  0.0
1  0.0  0.0  0.0  0.0
2  0.0  0.0  0.0  0.0
3  0.0  0.0  0.0  0.0

In [270]: si.index
Out[270]: Index(['0', '1', '2', '3'], dtype='object')

In [271]: si.columns
Out[271]: Index([0, 1, 2, 3], dtype='int64')

In [272]: json = si.to_json()

In [273]: sij = pd.read_json(StringIO(json), convert_axes=False)

In [274]: sij
Out[274]: 
   0  1  2  3
0  0  0  0  0
1  0  0  0  0
2  0  0  0  0
3  0  0  0  0

In [275]: sij.index
Out[275]: Index(['0', '1', '2', '3'], dtype='object')

In [276]: sij.columns
Out[276]: Index(['0', '1', '2', '3'], dtype='object')
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame pandas.Index pandas.DataFrame.to_json pandas.read_json
"In [277]: from io import StringIO

In [278]: json = dfj2.to_json(date_unit=""ns"")

# Try to parse timestamps as milliseconds -> Won't Work
In [279]: dfju = pd.read_json(StringIO(json), date_unit=""ms"")

In [280]: dfju
Out[280]: 
                            A         B        date  ints  bools
1356998400000000000 -0.121306 -0.097883  1356998400     0   True
1357084800000000000  0.695775  0.341734  1356998400     1   True
1357171200000000000  0.959726 -1.110336  1356998400     2   True
1357257600000000000 -0.619976  0.149748  1356998400     3   True
1357344000000000000 -0.732339  0.687738  1356998400     4   True

# Let pandas detect the correct precision
In [281]: dfju = pd.read_json(StringIO(json))

In [282]: dfju
Out[282]: 
                   A         B       date  ints  bools
2013-01-01 -0.121306 -0.097883 2013-01-01     0   True
2013-01-02  0.695775  0.341734 2013-01-01     1   True
2013-01-03  0.959726 -1.110336 2013-01-01     2   True
2013-01-04 -0.619976  0.149748 2013-01-01     3   True
2013-01-05 -0.732339  0.687738 2013-01-01     4   True

# Or specify that all timestamps are in nanoseconds
In [283]: dfju = pd.read_json(StringIO(json), date_unit=""ns"")

In [284]: dfju
Out[284]: 
                   A         B        date  ints  bools
2013-01-01 -0.121306 -0.097883  1356998400     0   True
2013-01-02  0.695775  0.341734  1356998400     1   True
2013-01-03  0.959726 -1.110336  1356998400     2   True
2013-01-04 -0.619976  0.149748  1356998400     3   True
2013-01-05 -0.732339  0.687738  1356998400     4   True
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_json
"In [285]: data = (
   .....:  '{""a"":{""0"":1,""1"":3},""b"":{""0"":2.5,""1"":4.5},""c"":{""0"":true,""1"":false},""d"":{""0"":""a"",""1"":""b""},'
   .....:  '""e"":{""0"":null,""1"":6.0},""f"":{""0"":null,""1"":7.5},""g"":{""0"":null,""1"":true},""h"":{""0"":null,""1"":""a""},'
   .....:  '""i"":{""0"":""12-31-2019"",""1"":""12-31-2019""},""j"":{""0"":null,""1"":null}}'
   .....: )
   .....: 

In [286]: df = pd.read_json(StringIO(data), dtype_backend=""pyarrow"")

In [287]: df
Out[287]: 
   a    b      c  d     e     f     g     h           i     j
0  1  2.5   True  a          12-31-2019  None
1  3  4.5  False  b     6   7.5  True     a  12-31-2019  None

In [288]: df.dtypes
Out[288]: 
a     int64[pyarrow]
b    double[pyarrow]
c      bool[pyarrow]
d    string[pyarrow]
e     int64[pyarrow]
f    double[pyarrow]
g      bool[pyarrow]
h    string[pyarrow]
i    string[pyarrow]
j      null[pyarrow]
dtype: object
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_json
"In [289]: data = [
   .....:     {""id"": 1, ""name"": {""first"": ""Coleen"", ""last"": ""Volk""}},
   .....:     {""name"": {""given"": ""Mark"", ""family"": ""Regner""}},
   .....:     {""id"": 2, ""name"": ""Faye Raker""},
   .....: ]
   .....: 

In [290]: pd.json_normalize(data)
Out[290]: 
    id name.first name.last name.given name.family        name
0  1.0     Coleen      Volk        NaN         NaN         NaN
1  NaN        NaN       NaN       Mark      Regner         NaN
2  2.0        NaN       NaN        NaN         NaN  Faye Raker
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.json_normalize
"In [291]: data = [
   .....:     {
   .....:         ""state"": ""Florida"",
   .....:         ""shortname"": ""FL"",
   .....:         ""info"": {""governor"": ""Rick Scott""},
   .....:         ""county"": [
   .....:             {""name"": ""Dade"", ""population"": 12345},
   .....:             {""name"": ""Broward"", ""population"": 40000},
   .....:             {""name"": ""Palm Beach"", ""population"": 60000},
   .....:         ],
   .....:     },
   .....:     {
   .....:         ""state"": ""Ohio"",
   .....:         ""shortname"": ""OH"",
   .....:         ""info"": {""governor"": ""John Kasich""},
   .....:         ""county"": [
   .....:             {""name"": ""Summit"", ""population"": 1234},
   .....:             {""name"": ""Cuyahoga"", ""population"": 1337},
   .....:         ],
   .....:     },
   .....: ]
   .....: 

In [292]: pd.json_normalize(data, ""county"", [""state"", ""shortname"", [""info"", ""governor""]])
Out[292]: 
         name  population    state shortname info.governor
0        Dade       12345  Florida        FL    Rick Scott
1     Broward       40000  Florida        FL    Rick Scott
2  Palm Beach       60000  Florida        FL    Rick Scott
3      Summit        1234     Ohio        OH   John Kasich
4    Cuyahoga        1337     Ohio        OH   John Kasich
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.json_normalize
"In [293]: data = [
   .....:     {
   .....:         ""CreatedBy"": {""Name"": ""User001""},
   .....:         ""Lookup"": {
   .....:             ""TextField"": ""Some text"",
   .....:             ""UserField"": {""Id"": ""ID001"", ""Name"": ""Name001""},
   .....:         },
   .....:         ""Image"": {""a"": ""b""},
   .....:     }
   .....: ]
   .....: 

In [294]: pd.json_normalize(data, max_level=1)
Out[294]: 
  CreatedBy.Name Lookup.TextField                    Lookup.UserField Image.a
0        User001        Some text  {'Id': 'ID001', 'Name': 'Name001'}       b
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.json_normalize
"In [295]: from io import StringIO

In [296]: jsonl = """"""
   .....:     {""a"": 1, ""b"": 2}
   .....:     {""a"": 3, ""b"": 4}
   .....: """"""
   .....: 

In [297]: df = pd.read_json(StringIO(jsonl), lines=True)

In [298]: df
Out[298]: 
   a  b
0  1  2
1  3  4

In [299]: df.to_json(orient=""records"", lines=True)
Out[299]: '{""a"":1,""b"":2}\n{""a"":3,""b"":4}\n'

# reader is an iterator that returns ``chunksize`` lines each iteration
In [300]: with pd.read_json(StringIO(jsonl), lines=True, chunksize=1) as reader:
   .....:     reader
   .....:     for chunk in reader:
   .....:         print(chunk)
   .....: 
Empty DataFrame
Columns: []
Index: []
   a  b
0  1  2
   a  b
1  3  4
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_json pandas.DataFrame.to_json
"In [301]: from io import BytesIO

In [302]: df = pd.read_json(BytesIO(jsonl.encode()), lines=True, engine=""pyarrow"")

In [303]: df
Out[303]: 
   a  b
0  1  2
1  3  4
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_json pandas.Series.str.encode
"In [304]: df = pd.DataFrame(
   .....:     {
   .....:         ""A"": [1, 2, 3],
   .....:         ""B"": [""a"", ""b"", ""c""],
   .....:         ""C"": pd.date_range(""2016-01-01"", freq=""d"", periods=3),
   .....:     },
   .....:     index=pd.Index(range(3), name=""idx""),
   .....: )
   .....: 

In [305]: df
Out[305]: 
     A  B          C
idx                 
0    1  a 2016-01-01
1    2  b 2016-01-02
2    3  c 2016-01-03

In [306]: df.to_json(orient=""table"", date_format=""iso"")
Out[306]: '{""schema"":{""fields"":[{""name"":""idx"",""type"":""integer""},{""name"":""A"",""type"":""integer""},{""name"":""B"",""type"":""string""},{""name"":""C"",""type"":""datetime""}],""primaryKey"":[""idx""],""pandas_version"":""1.4.0""},""data"":[{""idx"":0,""A"":1,""B"":""a"",""C"":""2016-01-01T00:00:00.000""},{""idx"":1,""A"":2,""B"":""b"",""C"":""2016-01-02T00:00:00.000""},{""idx"":2,""A"":3,""B"":""c"",""C"":""2016-01-03T00:00:00.000""}]}'
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame pandas.date_range pandas.Index pandas.DataFrame.to_json
"In [307]: from pandas.io.json import build_table_schema

In [308]: s = pd.Series(pd.date_range(""2016"", periods=4))

In [309]: build_table_schema(s)
Out[309]: 
{'fields': [{'name': 'index', 'type': 'integer'},
  {'name': 'values', 'type': 'datetime'}],
 'primaryKey': ['index'],
 'pandas_version': '1.4.0'}
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.Series pandas.date_range pandas.io.json.build_table_schema
"In [310]: s_tz = pd.Series(pd.date_range(""2016"", periods=12, tz=""US/Central""))

In [311]: build_table_schema(s_tz)
Out[311]: 
{'fields': [{'name': 'index', 'type': 'integer'},
  {'name': 'values', 'type': 'datetime', 'tz': 'US/Central'}],
 'primaryKey': ['index'],
 'pandas_version': '1.4.0'}
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.Series pandas.date_range pandas.io.json.build_table_schema
"In [312]: s_per = pd.Series(1, index=pd.period_range(""2016"", freq=""Y-DEC"", periods=4))

In [313]: build_table_schema(s_per)
Out[313]: 
{'fields': [{'name': 'index', 'type': 'datetime', 'freq': 'YE-DEC'},
  {'name': 'values', 'type': 'integer'}],
 'primaryKey': ['index'],
 'pandas_version': '1.4.0'}
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.Series pandas.period_range pandas.io.json.build_table_schema
"In [314]: s_cat = pd.Series(pd.Categorical([""a"", ""b"", ""a""]))

In [315]: build_table_schema(s_cat)
Out[315]: 
{'fields': [{'name': 'index', 'type': 'integer'},
  {'name': 'values',
   'type': 'any',
   'constraints': {'enum': ['a', 'b']},
   'ordered': False}],
 'primaryKey': ['index'],
 'pandas_version': '1.4.0'}
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.Series pandas.Categorical pandas.io.json.build_table_schema
"In [316]: s_dupe = pd.Series([1, 2], index=[1, 1])

In [317]: build_table_schema(s_dupe)
Out[317]: 
{'fields': [{'name': 'index', 'type': 'integer'},
  {'name': 'values', 'type': 'integer'}],
 'pandas_version': '1.4.0'}
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.Series pandas.io.json.build_table_schema
"In [318]: s_multi = pd.Series(1, index=pd.MultiIndex.from_product([(""a"", ""b""), (0, 1)]))

In [319]: build_table_schema(s_multi)
Out[319]: 
{'fields': [{'name': 'level_0', 'type': 'string'},
  {'name': 'level_1', 'type': 'integer'},
  {'name': 'values', 'type': 'integer'}],
 'primaryKey': FrozenList(['level_0', 'level_1']),
 'pandas_version': '1.4.0'}
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.Series pandas.MultiIndex.from_product pandas.io.json.build_table_schema
"In [320]: df = pd.DataFrame(
   .....:     {
   .....:         ""foo"": [1, 2, 3, 4],
   .....:         ""bar"": [""a"", ""b"", ""c"", ""d""],
   .....:         ""baz"": pd.date_range(""2018-01-01"", freq=""d"", periods=4),
   .....:         ""qux"": pd.Categorical([""a"", ""b"", ""c"", ""c""]),
   .....:     },
   .....:     index=pd.Index(range(4), name=""idx""),
   .....: )
   .....: 

In [321]: df
Out[321]: 
     foo bar        baz qux
idx                        
0      1   a 2018-01-01   a
1      2   b 2018-01-02   b
2      3   c 2018-01-03   c
3      4   d 2018-01-04   c

In [322]: df.dtypes
Out[322]: 
foo             int64
bar            object
baz    datetime64[ns]
qux          category
dtype: object

In [323]: df.to_json(""test.json"", orient=""table"")

In [324]: new_df = pd.read_json(""test.json"", orient=""table"")

In [325]: new_df
Out[325]: 
     foo bar        baz qux
idx                        
0      1   a 2018-01-01   a
1      2   b 2018-01-02   b
2      3   c 2018-01-03   c
3      4   d 2018-01-04   c

In [326]: new_df.dtypes
Out[326]: 
foo             int64
bar            object
baz    datetime64[ns]
qux          category
dtype: object
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame pandas.date_range pandas.Categorical pandas.Index pandas.DataFrame.to_json pandas.read_json
"In [327]: df.index.name = ""index""

In [328]: df.to_json(""test.json"", orient=""table"")

In [329]: new_df = pd.read_json(""test.json"", orient=""table"")

In [330]: print(new_df.index.name)
None
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame.to_json pandas.read_json
"In [320]: url = ""https://www.fdic.gov/resources/resolutions/bank-failures/failed-bank-list""
In [321]: pd.read_html(url)
Out[321]:
[                         Bank NameBank           CityCity StateSt  ...              Acquiring InstitutionAI Closing DateClosing FundFund
 0                    Almena State Bank             Almena      KS  ...                          Equity Bank    October 23, 2020    10538
 1           First City Bank of Florida  Fort Walton Beach      FL  ...            United Fidelity Bank, fsb    October 16, 2020    10537
 2                 The First State Bank      Barboursville      WV  ...                       MVB Bank, Inc.       April 3, 2020    10536
 3                   Ericson State Bank            Ericson      NE  ...           Farmers and Merchants Bank   February 14, 2020    10535
 4     City National Bank of New Jersey             Newark      NJ  ...                      Industrial Bank    November 1, 2019    10534
 ..                                 ...                ...     ...  ...                                  ...                 ...      ...
 558                 Superior Bank, FSB           Hinsdale      IL  ...                Superior Federal, FSB       July 27, 2001     6004
 559                Malta National Bank              Malta      OH  ...                    North Valley Bank         May 3, 2001     4648
 560    First Alliance Bank & Trust Co.         Manchester      NH  ...  Southern New Hampshire Bank & Trust    February 2, 2001     4647
 561  National State Bank of Metropolis         Metropolis      IL  ...              Banterra Bank of Marion   December 14, 2000     4646
 562                   Bank of Honolulu           Honolulu      HI  ...                   Bank of the Orient    October 13, 2000     4645

 [563 rows x 7 columns]]
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_html
"In [322]: url = 'https://www.sump.org/notes/request/' # HTTP request reflector
In [323]: pd.read_html(url)
Out[323]:
[                   0                    1
 0     Remote Socket:  51.15.105.256:51760
 1  Protocol Version:             HTTP/1.1
 2    Request Method:                  GET
 3       Request URI:      /notes/request/
 4     Request Query:                  NaN,
 0   Accept-Encoding:             identity
 1              Host:         www.sump.org
 2        User-Agent:    Python-urllib/3.8
 3        Connection:                close]
In [324]: headers = {
In [325]:    'User-Agent':'Mozilla Firefox v14.0',
In [326]:    'Accept':'application/json',
In [327]:    'Connection':'keep-alive',
In [328]:    'Auth':'Bearer 2*/f3+fe68df*4'
In [329]: }
In [340]: pd.read_html(url, storage_options=headers)
Out[340]:
[                   0                    1
 0     Remote Socket:  51.15.105.256:51760
 1  Protocol Version:             HTTP/1.1
 2    Request Method:                  GET
 3       Request URI:      /notes/request/
 4     Request Query:                  NaN,
 0        User-Agent: Mozilla Firefox v14.0
 1    AcceptEncoding:   gzip,  deflate,  br
 2            Accept:      application/json
 3        Connection:             keep-alive
 4              Auth:  Bearer 2*/f3+fe68df*4]
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_html
"In [331]: html_str = """"""
   .....:          
   .....:              
   .....:                  A
   .....:                  B
   .....:                  C
   .....:              
   .....:              
   .....:                  a
   .....:                  b
   .....:                  c
   .....:              
   .....:          
   .....:      """"""
   .....: 

In [332]: with open(""tmp.html"", ""w"") as f:
   .....:     f.write(html_str)
   .....: 

In [333]: df = pd.read_html(""tmp.html"")

In [334]: df[0]
Out[334]: 
   A  B  C
0  a  b  c
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_html
"In [335]: dfs = pd.read_html(StringIO(html_str))

In [336]: dfs[0]
Out[336]: 
   A  B  C
0  a  b  c
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_html
"match = ""Metcalf Bank""
df_list = pd.read_html(url, match=match)
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_html
"dfs = pd.read_html(url, header=0)
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_html
"dfs = pd.read_html(url, index_col=0)
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_html
"dfs = pd.read_html(url, skiprows=0)
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_html
"dfs = pd.read_html(url, skiprows=range(2))
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_html
"dfs1 = pd.read_html(url, attrs={""id"": ""table""})
dfs2 = pd.read_html(url, attrs={""class"": ""sortable""})
print(np.array_equal(dfs1[0], dfs2[0]))  # Should be True
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_html
"dfs = pd.read_html(url, na_values=[""No Acquirer""])
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_html
"dfs = pd.read_html(url, keep_default_na=False)
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_html
"url_mcc = ""https://en.wikipedia.org/wiki/Mobile_country_code?oldid=899173761""
dfs = pd.read_html(
    url_mcc,
    match=""Telekom Albania"",
    header=0,
    converters={""MNC"": str},
)
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_html
"dfs = pd.read_html(url, match=""Metcalf Bank"", index_col=0)
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_html
"df = pd.DataFrame(np.random.randn(2, 2))
s = df.to_html(float_format=""{0:.40g}"".format)
dfin = pd.read_html(s, index_col=0)
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame pandas.DataFrame.to_html pandas.read_html
"dfs = pd.read_html(url, ""Metcalf Bank"", index_col=0, flavor=[""lxml""])
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_html
"dfs = pd.read_html(url, ""Metcalf Bank"", index_col=0, flavor=""lxml"")
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_html
"dfs = pd.read_html(url, ""Metcalf Bank"", index_col=0, flavor=[""lxml"", ""bs4""])
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_html
"In [337]: html_table = """"""
   .....: 
   .....:   
   .....:     GitHub
   .....:   
   .....:   
   .....:     pandas
   .....:   
   .....: 
   .....: """"""
   .....: 

In [338]: df = pd.read_html(
   .....:     StringIO(html_table),
   .....:     extract_links=""all""
   .....: )[0]
   .....: 

In [339]: df
Out[339]: 
                                   (GitHub, None)
0  (pandas, https://github.com/pandas-dev/pandas)

In [340]: df[(""GitHub"", None)]
Out[340]: 
0    (pandas, https://github.com/pandas-dev/pandas)
Name: (GitHub, None), dtype: object

In [341]: df[(""GitHub"", None)].str[1]
Out[341]: 
0    https://github.com/pandas-dev/pandas
Name: (GitHub, None), dtype: object
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_html
"In [342]: from IPython.display import display, HTML

In [343]: df = pd.DataFrame(np.random.randn(2, 2))

In [344]: df
Out[344]: 
          0         1
0 -0.345352  1.314232
1  0.690579  0.995761

In [345]: html = df.to_html()

In [346]: print(html)  # raw html

  
    
      
      0
      1
    
  
  
    
      0
      -0.345352
      1.314232
    
    
      1
      0.690579
      0.995761
    
  


In [347]: display(HTML(html))

",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame pandas.DataFrame.to_html
"In [348]: html = df.to_html(columns=[0])

In [349]: print(html)

  
    
      
      0
    
  
  
    
      0
      -0.345352
    
    
      1
      0.690579
    
  


In [350]: display(HTML(html))

",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame.to_html
"In [351]: html = df.to_html(float_format=""{0:.10f}"".format)

In [352]: print(html)

  
    
      
      0
      1
    
  
  
    
      0
      -0.3453521949
      1.3142323796
    
    
      1
      0.6905793352
      0.9957609037
    
  


In [353]: display(HTML(html))

",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame.to_html
"In [354]: html = df.to_html(bold_rows=False)

In [355]: print(html)

  
    
      
      0
      1
    
  
  
    
      0
      -0.345352
      1.314232
    
    
      1
      0.690579
      0.995761
    
  


In [356]: display(HTML(html))

",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame.to_html
"In [357]: print(df.to_html(classes=[""awesome_table_class"", ""even_more_awesome_class""]))

  
    
      
      0
      1
    
  
  
    
      0
      -0.345352
      1.314232
    
    
      1
      0.690579
      0.995761
    
  

",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame.to_html
"In [358]: url_df = pd.DataFrame(
   .....:     {
   .....:         ""name"": [""Python"", ""pandas""],
   .....:         ""url"": [""https://www.python.org/"", ""https://pandas.pydata.org""],
   .....:     }
   .....: )
   .....: 

In [359]: html = url_df.to_html(render_links=True)

In [360]: print(html)

  
    
      
      name
      url
    
  
  
    
      0
      Python
      https://www.python.org/
    
    
      1
      pandas
      https://pandas.pydata.org
    
  


In [361]: display(HTML(html))

",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame pandas.DataFrame.to_html
"In [362]: df = pd.DataFrame({""a"": list(""&<>""), ""b"": np.random.randn(3)})
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame
"In [363]: html = df.to_html()

In [364]: print(html)

  
    
      
      a
      b
    
  
  
    
      0
      &
      2.396780
    
    
      1
      <
      0.014871
    
    
      2
      >
      3.357427
    
  


In [365]: display(HTML(html))

",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame.to_html
"In [366]: html = df.to_html(escape=False)

In [367]: print(html)

  
    
      
      a
      b
    
  
  
    
      0
      &
      2.396780
    
    
      1
      <
      0.014871
    
    
      2
      >
      3.357427
    
  


In [368]: display(HTML(html))

",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame.to_html
"In [369]: df = pd.DataFrame([[1, 2], [3, 4]], index=[""a"", ""b""], columns=[""c"", ""d""])

In [370]: print(df.style.to_latex())
\begin{tabular}{lrr}
 & c & d \\
a & 1 & 2 \\
b & 3 & 4 \\
\end{tabular}
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame
"In [372]: from io import StringIO

In [373]: xml = """"""
   .....: 
   .....:   
   .....:     Everyday Italian
   .....:     Giada De Laurentiis
   .....:     2005
   .....:     30.00
   .....:   
   .....:   
   .....:     Harry Potter
   .....:     J K. Rowling
   .....:     2005
   .....:     29.99
   .....:   
   .....:   
   .....:     Learning XML
   .....:     Erik T. Ray
   .....:     2003
   .....:     39.95
   .....:   
   .....: """"""
   .....: 

In [374]: df = pd.read_xml(StringIO(xml))

In [375]: df
Out[375]: 
   category             title               author  year  price
0   cooking  Everyday Italian  Giada De Laurentiis  2005  30.00
1  children      Harry Potter         J K. Rowling  2005  29.99
2       web      Learning XML          Erik T. Ray  2003  39.95
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_xml
"In [376]: df = pd.read_xml(""https://www.w3schools.com/xml/books.xml"")

In [377]: df
Out[377]: 
   category              title                  author  year  price      cover
0   cooking   Everyday Italian     Giada De Laurentiis  2005  30.00       None
1  children       Harry Potter            J K. Rowling  2005  29.99       None
2       web  XQuery Kick Start  Vaidyanathan Nagarajan  2003  49.99       None
3       web       Learning XML             Erik T. Ray  2003  39.95  paperback
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_xml
"In [378]: file_path = ""books.xml""

In [379]: with open(file_path, ""w"") as f:
   .....:     f.write(xml)
   .....: 

In [380]: with open(file_path, ""r"") as f:
   .....:     df = pd.read_xml(StringIO(f.read()))
   .....: 

In [381]: df
Out[381]: 
   category             title               author  year  price
0   cooking  Everyday Italian  Giada De Laurentiis  2005  30.00
1  children      Harry Potter         J K. Rowling  2005  29.99
2       web      Learning XML          Erik T. Ray  2003  39.95
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_xml
"In [382]: with open(file_path, ""r"") as f:
   .....:     sio = StringIO(f.read())
   .....: 

In [383]: df = pd.read_xml(sio)

In [384]: df
Out[384]: 
   category             title               author  year  price
0   cooking  Everyday Italian  Giada De Laurentiis  2005  30.00
1  children      Harry Potter         J K. Rowling  2005  29.99
2       web      Learning XML          Erik T. Ray  2003  39.95
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_xml
"In [385]: with open(file_path, ""rb"") as f:
   .....:     bio = BytesIO(f.read())
   .....: 

In [386]: df = pd.read_xml(bio)

In [387]: df
Out[387]: 
   category             title               author  year  price
0   cooking  Everyday Italian  Giada De Laurentiis  2005  30.00
1  children      Harry Potter         J K. Rowling  2005  29.99
2       web      Learning XML          Erik T. Ray  2003  39.95
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_xml
"In [388]: df = pd.read_xml(
   .....:     ""s3://pmc-oa-opendata/oa_comm/xml/all/PMC1236943.xml"",
   .....:     xpath="".//journal-meta"",
   .....: )
   .....: 

In [389]: df
Out[389]: 
              journal-id              journal-title       issn  publisher
0  Cardiovasc Ultrasound  Cardiovascular Ultrasound  1476-7120        NaN
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_xml
"In [390]: df = pd.read_xml(file_path, xpath=""//book[year=2005]"")

In [391]: df
Out[391]: 
   category             title               author  year  price
0   cooking  Everyday Italian  Giada De Laurentiis  2005  30.00
1  children      Harry Potter         J K. Rowling  2005  29.99
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_xml
"In [392]: df = pd.read_xml(file_path, elems_only=True)

In [393]: df
Out[393]: 
              title               author  year  price
0  Everyday Italian  Giada De Laurentiis  2005  30.00
1      Harry Potter         J K. Rowling  2005  29.99
2      Learning XML          Erik T. Ray  2003  39.95
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_xml
"In [394]: df = pd.read_xml(file_path, attrs_only=True)

In [395]: df
Out[395]: 
   category
0   cooking
1  children
2       web
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_xml
"In [396]: xml = """"""
   .....: 
   .....:   
   .....:     square
   .....:     360
   .....:     4.0
   .....:   
   .....:   
   .....:     circle
   .....:     360
   .....:     
   .....:   
   .....:   
   .....:     triangle
   .....:     180
   .....:     3.0
   .....:   
   .....: """"""
   .....: 

In [397]: df = pd.read_xml(StringIO(xml),
   .....:                  xpath=""//doc:row"",
   .....:                  namespaces={""doc"": ""https://example.com""})
   .....: 

In [398]: df
Out[398]: 
      shape  degrees  sides
0    square      360    4.0
1    circle      360    NaN
2  triangle      180    3.0
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_xml
"In [399]: xml = """"""
   .....: 
   .....:  
   .....:    square
   .....:    360
   .....:    4.0
   .....:  
   .....:  
   .....:    circle
   .....:    360
   .....:    
   .....:  
   .....:  
   .....:    triangle
   .....:    180
   .....:    3.0
   .....:  
   .....: """"""
   .....: 

In [400]: df = pd.read_xml(StringIO(xml),
   .....:                  xpath=""//pandas:row"",
   .....:                  namespaces={""pandas"": ""https://example.com""})
   .....: 

In [401]: df
Out[401]: 
      shape  degrees  sides
0    square      360    4.0
1    circle      360    NaN
2  triangle      180    3.0
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_xml
"In [402]: xml = """"""
   .....: 
   .....:   
   .....:     square
   .....:     360
   .....:   
   .....:   
   .....:     circle
   .....:     360
   .....:   
   .....:   
   .....:     triangle
   .....:     180
   .....:   
   .....: """"""
   .....: 

In [403]: df = pd.read_xml(StringIO(xml), xpath=""./row"")

In [404]: df
Out[404]: 
      shape  degrees
0    square      360
1    circle      360
2  triangle      180
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_xml
"In [405]: xml = """"""
   .....:  
   .....:   
   .....:     
   .....:     2020-09-01T00:00:00
   .....:     
   .....:       864.2
   .....:       534
   .....:       417.2
   .....:     
   .....:   
   .....:   
   .....:     
   .....:     2020-09-01T00:00:00
   .....:     
   .....:       2707.4
   .....:       1909.8
   .....:       1438.6
   .....:     
   .....:   
   .....:   
   .....:     
   .....:     2020-09-01T00:00:00
   .....:     
   .....:       2949.6
   .....:       1657
   .....:       1453.8
   .....:     
   .....:   
   .....:  """"""
   .....: 

In [406]: xsl = """"""
   .....:    
   .....:    
   .....:    
   .....:       
   .....:         
   .....:       
   .....:    
   .....:    
   .....:       
   .....:         
   .....:         
   .....:         
   .....:       
   .....:    
   .....:  """"""
   .....: 

In [407]: output = """"""
   .....:  
   .....:    
   .....:       40850
   .....:       Library
   .....:       2020-09-01T00:00:00
   .....:       864.2
   .....:       534
   .....:       417.2
   .....:    
   .....:    
   .....:       41700
   .....:       Washington/Wabash
   .....:       2020-09-01T00:00:00
   .....:       2707.4
   .....:       1909.8
   .....:       1438.6
   .....:    
   .....:    
   .....:       40380
   .....:       Clark/Lake
   .....:       2020-09-01T00:00:00
   .....:       2949.6
   .....:       1657
   .....:       1453.8
   .....:    
   .....:  """"""
   .....: 

In [408]: df = pd.read_xml(StringIO(xml), stylesheet=xsl)

In [409]: df
Out[409]: 
   station_id       station_name  ... avg_saturday_rides  avg_sunday_holiday_rides
0       40850            Library  ...              534.0                     417.2
1       41700  Washington/Wabash  ...             1909.8                    1438.6
2       40380         Clark/Lake  ...             1657.0                    1453.8

[3 rows x 6 columns]
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_xml
"In [1]: df = pd.read_xml(
...         ""/path/to/downloaded/enwikisource-latest-pages-articles.xml"",
...         iterparse = {""page"": [""title"", ""ns"", ""id""]}
...     )
...     df
Out[2]:
                                                     title   ns        id
0                                       Gettysburg Address    0     21450
1                                                Main Page    0     42950
2                            Declaration by United Nations    0      8435
3             Constitution of the United States of America    0      8435
4                     Declaration of Independence (Israel)    0     17858
...                                                    ...  ...       ...
3578760               Page:Black cat 1897 07 v2 n10.pdf/17  104    219649
3578761               Page:Black cat 1897 07 v2 n10.pdf/43  104    219649
3578762               Page:Black cat 1897 07 v2 n10.pdf/44  104    219649
3578763      The History of Tom Jones, a Foundling/Book IX    0  12084291
3578764  Page:Shakespeare of Stratford (1926) Yale.djvu/91  104     21450

[3578765 rows x 3 columns]
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_xml
"In [410]: geom_df = pd.DataFrame(
   .....:     {
   .....:         ""shape"": [""square"", ""circle"", ""triangle""],
   .....:         ""degrees"": [360, 360, 180],
   .....:         ""sides"": [4, np.nan, 3],
   .....:     }
   .....: )
   .....: 

In [411]: print(geom_df.to_xml())


  
    0
    square
    360
    4.0
  
  
    1
    circle
    360
    
  
  
    2
    triangle
    180
    3.0
  

",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame pandas.DataFrame.to_xml
"In [412]: print(geom_df.to_xml(root_name=""geometry"", row_name=""objects""))


  
    0
    square
    360
    4.0
  
  
    1
    circle
    360
    
  
  
    2
    triangle
    180
    3.0
  

",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame.to_xml
"In [413]: print(geom_df.to_xml(attr_cols=geom_df.columns.tolist()))


  
  
  

",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame.to_xml
"In [414]: print(
   .....:     geom_df.to_xml(
   .....:         index=False,
   .....:         attr_cols=['shape'],
   .....:         elem_cols=['degrees', 'sides'])
   .....: )
   .....: 


  
    360
    4.0
  
  
    360
    
  
  
    180
    3.0
  

",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame.to_xml
"In [415]: ext_geom_df = pd.DataFrame(
   .....:     {
   .....:         ""type"": [""polygon"", ""other"", ""polygon""],
   .....:         ""shape"": [""square"", ""circle"", ""triangle""],
   .....:         ""degrees"": [360, 360, 180],
   .....:         ""sides"": [4, np.nan, 3],
   .....:     }
   .....: )
   .....: 

In [416]: pvt_df = ext_geom_df.pivot_table(index='shape',
   .....:                                  columns='type',
   .....:                                  values=['degrees', 'sides'],
   .....:                                  aggfunc='sum')
   .....: 

In [417]: pvt_df
Out[417]: 
         degrees         sides        
type       other polygon other polygon
shape                                 
circle     360.0     NaN   0.0     NaN
square       NaN   360.0   NaN     4.0
triangle     NaN   180.0   NaN     3.0

In [418]: print(pvt_df.to_xml())


  
    circle
    360.0
    
    0.0
    
  
  
    square
    
    360.0
    
    4.0
  
  
    triangle
    
    180.0
    
    3.0
  

",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame pandas.DataFrame.pivot_table pandas.DataFrame.to_xml
"In [419]: print(geom_df.to_xml(namespaces={"""": ""https://example.com""}))


  
    0
    square
    360
    4.0
  
  
    1
    circle
    360
    
  
  
    2
    triangle
    180
    3.0
  

",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame.to_xml
"In [420]: print(
   .....:     geom_df.to_xml(namespaces={""doc"": ""https://example.com""},
   .....:                    prefix=""doc"")
   .....: )
   .....: 


  
    0
    square
    360
    4.0
  
  
    1
    circle
    360
    
  
  
    2
    triangle
    180
    3.0
  

",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame.to_xml
"In [421]: print(
   .....:     geom_df.to_xml(xml_declaration=False,
   .....:                    pretty_print=False)
   .....: )
   .....: 
0square3604.01circle3602triangle1803.0
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame.to_xml
"In [422]: xsl = """"""
   .....:    
   .....:    
   .....:    
   .....:      
   .....:        
   .....:      
   .....:    
   .....:    
   .....:      {index}"">
   .....:        
   .....:            polygon
   .....:        
   .....:        
   .....:        
   .....:            
   .....:        
   .....:      
   .....:    
   .....:  """"""
   .....: 

In [423]: print(geom_df.to_xml(stylesheet=xsl))


  
    square
    
      360
      4.0
    
  
  
    circle
    
      360
      
    
  
  
    triangle
    
      180
      3.0
    
  

",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame.to_xml
"# Returns a DataFrame
pd.read_excel(""path_to_file.xls"", sheet_name=""Sheet1"")
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_excel
"xlsx = pd.ExcelFile(""path_to_file.xls"")
df = pd.read_excel(xlsx, ""Sheet1"")
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.ExcelFile pandas.read_excel
"with pd.ExcelFile(""path_to_file.xls"") as xls:
    df1 = pd.read_excel(xls, ""Sheet1"")
    df2 = pd.read_excel(xls, ""Sheet2"")
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.ExcelFile pandas.read_excel
"data = {}
# For when Sheet1's format differs from Sheet2
with pd.ExcelFile(""path_to_file.xls"") as xls:
    data[""Sheet1""] = pd.read_excel(xls, ""Sheet1"", index_col=None, na_values=[""NA""])
    data[""Sheet2""] = pd.read_excel(xls, ""Sheet2"", index_col=1)
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.ExcelFile pandas.read_excel
"# using the ExcelFile class
data = {}
with pd.ExcelFile(""path_to_file.xls"") as xls:
    data[""Sheet1""] = pd.read_excel(xls, ""Sheet1"", index_col=None, na_values=[""NA""])
    data[""Sheet2""] = pd.read_excel(xls, ""Sheet2"", index_col=None, na_values=[""NA""])

# equivalent using the read_excel function
data = pd.read_excel(
    ""path_to_file.xls"", [""Sheet1"", ""Sheet2""], index_col=None, na_values=[""NA""]
)
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.ExcelFile pandas.read_excel
"import xlrd

xlrd_book = xlrd.open_workbook(""path_to_file.xls"", on_demand=True)
with pd.ExcelFile(xlrd_book) as xls:
    df1 = pd.read_excel(xls, ""Sheet1"")
    df2 = pd.read_excel(xls, ""Sheet2"")
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.ExcelFile pandas.read_excel
"# Returns a DataFrame
pd.read_excel(""path_to_file.xls"", ""Sheet1"", index_col=None, na_values=[""NA""])
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_excel
"# Returns a DataFrame
pd.read_excel(""path_to_file.xls"", 0, index_col=None, na_values=[""NA""])
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_excel
"# Returns a DataFrame
pd.read_excel(""path_to_file.xls"")
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_excel
"# Returns a dictionary of DataFrames
pd.read_excel(""path_to_file.xls"", sheet_name=None)
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_excel
"# Returns the 1st and 4th sheet, as a dictionary of DataFrames.
pd.read_excel(""path_to_file.xls"", sheet_name=[""Sheet1"", 3])
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_excel
"In [424]: df = pd.DataFrame(
   .....:     {""a"": [1, 2, 3, 4], ""b"": [5, 6, 7, 8]},
   .....:     index=pd.MultiIndex.from_product([[""a"", ""b""], [""c"", ""d""]]),
   .....: )
   .....: 

In [425]: df.to_excel(""path_to_file.xlsx"")

In [426]: df = pd.read_excel(""path_to_file.xlsx"", index_col=[0, 1])

In [427]: df
Out[427]: 
     a  b
a c  1  5
  d  2  6
b c  3  7
  d  4  8
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame pandas.MultiIndex.from_product pandas.DataFrame.to_excel pandas.read_excel
"In [428]: df.index = df.index.set_names([""lvl1"", ""lvl2""])

In [429]: df.to_excel(""path_to_file.xlsx"")

In [430]: df = pd.read_excel(""path_to_file.xlsx"", index_col=[0, 1])

In [431]: df
Out[431]: 
           a  b
lvl1 lvl2      
a    c     1  5
     d     2  6
b    c     3  7
     d     4  8
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame.to_excel pandas.read_excel
"In [432]: df.columns = pd.MultiIndex.from_product([[""a""], [""b"", ""d""]], names=[""c1"", ""c2""])

In [433]: df.to_excel(""path_to_file.xlsx"")

In [434]: df = pd.read_excel(""path_to_file.xlsx"", index_col=[0, 1], header=[0, 1])

In [435]: df
Out[435]: 
c1         a   
c2         b  d
lvl1 lvl2      
a    c     1  5
     d     2  6
b    c     3  7
     d     4  8
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.MultiIndex.from_product pandas.DataFrame.to_excel pandas.read_excel
"pd.read_excel(""path_to_file.xls"", ""Sheet1"", usecols=""A,C:E"")
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_excel
"pd.read_excel(""path_to_file.xls"", ""Sheet1"", usecols=[0, 2, 3])
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_excel
"pd.read_excel(""path_to_file.xls"", ""Sheet1"", usecols=[""foo"", ""bar""])
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_excel
"pd.read_excel(""path_to_file.xls"", ""Sheet1"", usecols=lambda x: x.isalpha())
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_excel pandas.Series.str.isalpha
"pd.read_excel(""path_to_file.xls"", ""Sheet1"", parse_dates=[""date_strings""])
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_excel
"pd.read_excel(""path_to_file.xls"", ""Sheet1"", converters={""MyBools"": bool})
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_excel
"def cfun(x):
    return int(x) if x else -1


pd.read_excel(""path_to_file.xls"", ""Sheet1"", converters={""MyInts"": cfun})
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_excel
"pd.read_excel(""path_to_file.xls"", dtype={""MyInts"": ""int64"", ""MyText"": str})
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_excel
"df.to_excel(""path_to_file.xlsx"", sheet_name=""Sheet1"")
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame.to_excel
"df.to_excel(""path_to_file.xlsx"", index_label=""label"", merge_cells=False)
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame.to_excel
"with pd.ExcelWriter(""path_to_file.xlsx"") as writer:
    df1.to_excel(writer, sheet_name=""Sheet1"")
    df2.to_excel(writer, sheet_name=""Sheet2"")
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.ExcelWriter pandas.DataFrame.to_excel pandas.DataFrame.to_excel
"from io import BytesIO

bio = BytesIO()

# By setting the 'engine' in the ExcelWriter constructor.
writer = pd.ExcelWriter(bio, engine=""xlsxwriter"")
df.to_excel(writer, sheet_name=""Sheet1"")

# Save the workbook
writer.save()

# Seek to the beginning and read to copy the workbook to a variable in memory
bio.seek(0)
workbook = bio.read()
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.ExcelWriter pandas.DataFrame.to_excel
"# By setting the 'engine' in the DataFrame 'to_excel()' methods.
df.to_excel(""path_to_file.xlsx"", sheet_name=""Sheet1"", engine=""xlsxwriter"")

# By setting the 'engine' in the ExcelWriter constructor.
writer = pd.ExcelWriter(""path_to_file.xlsx"", engine=""xlsxwriter"")

# Or via pandas configuration.
from pandas import options  # noqa: E402

options.io.excel.xlsx.writer = ""xlsxwriter""

df.to_excel(""path_to_file.xlsx"", sheet_name=""Sheet1"")
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame.to_excel pandas.ExcelWriter
"# Returns a DataFrame
pd.read_excel(""path_to_file.ods"", engine=""odf"")
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_excel
"# Writes DataFrame to a .ods file
df.to_excel(""path_to_file.ods"", engine=""odf"")
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame.to_excel
"# Returns a DataFrame
pd.read_excel(""path_to_file.xlsb"", engine=""pyxlsb"")
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_excel
"# Returns a DataFrame
pd.read_excel(""path_to_file.xlsb"", engine=""calamine"")
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_excel
">>> clipdf = pd.read_clipboard()
>>> clipdf
  A B C
x 1 4 p
y 2 5 q
z 3 6 r
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_clipboard
">>> df = pd.DataFrame(
...     {""A"": [1, 2, 3], ""B"": [4, 5, 6], ""C"": [""p"", ""q"", ""r""]}, index=[""x"", ""y"", ""z""]
... )

>>> df
  A B C
x 1 4 p
y 2 5 q
z 3 6 r
>>> df.to_clipboard()
>>> pd.read_clipboard()
  A B C
x 1 4 p
y 2 5 q
z 3 6 r
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame pandas.DataFrame.to_clipboard pandas.read_clipboard
"In [436]: df
Out[436]: 
c1         a   
c2         b  d
lvl1 lvl2      
a    c     1  5
     d     2  6
b    c     3  7
     d     4  8

In [437]: df.to_pickle(""foo.pkl"")
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame.to_pickle
"In [438]: pd.read_pickle(""foo.pkl"")
Out[438]: 
c1         a   
c2         b  d
lvl1 lvl2      
a    c     1  5
     d     2  6
b    c     3  7
     d     4  8
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_pickle
"In [439]: df = pd.DataFrame(
   .....:     {
   .....:         ""A"": np.random.randn(1000),
   .....:         ""B"": ""foo"",
   .....:         ""C"": pd.date_range(""20130101"", periods=1000, freq=""s""),
   .....:     }
   .....: )
   .....: 

In [440]: df
Out[440]: 
            A    B                   C
0   -0.317441  foo 2013-01-01 00:00:00
1   -1.236269  foo 2013-01-01 00:00:01
2    0.896171  foo 2013-01-01 00:00:02
3   -0.487602  foo 2013-01-01 00:00:03
4   -0.082240  foo 2013-01-01 00:00:04
..        ...  ...                 ...
995 -0.171092  foo 2013-01-01 00:16:35
996  1.786173  foo 2013-01-01 00:16:36
997 -0.575189  foo 2013-01-01 00:16:37
998  0.820750  foo 2013-01-01 00:16:38
999 -1.256530  foo 2013-01-01 00:16:39

[1000 rows x 3 columns]
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame pandas.date_range
"In [441]: df.to_pickle(""data.pkl.compress"", compression=""gzip"")

In [442]: rt = pd.read_pickle(""data.pkl.compress"", compression=""gzip"")

In [443]: rt
Out[443]: 
            A    B                   C
0   -0.317441  foo 2013-01-01 00:00:00
1   -1.236269  foo 2013-01-01 00:00:01
2    0.896171  foo 2013-01-01 00:00:02
3   -0.487602  foo 2013-01-01 00:00:03
4   -0.082240  foo 2013-01-01 00:00:04
..        ...  ...                 ...
995 -0.171092  foo 2013-01-01 00:16:35
996  1.786173  foo 2013-01-01 00:16:36
997 -0.575189  foo 2013-01-01 00:16:37
998  0.820750  foo 2013-01-01 00:16:38
999 -1.256530  foo 2013-01-01 00:16:39

[1000 rows x 3 columns]
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame.to_pickle pandas.read_pickle
"In [444]: df.to_pickle(""data.pkl.xz"", compression=""infer"")

In [445]: rt = pd.read_pickle(""data.pkl.xz"", compression=""infer"")

In [446]: rt
Out[446]: 
            A    B                   C
0   -0.317441  foo 2013-01-01 00:00:00
1   -1.236269  foo 2013-01-01 00:00:01
2    0.896171  foo 2013-01-01 00:00:02
3   -0.487602  foo 2013-01-01 00:00:03
4   -0.082240  foo 2013-01-01 00:00:04
..        ...  ...                 ...
995 -0.171092  foo 2013-01-01 00:16:35
996  1.786173  foo 2013-01-01 00:16:36
997 -0.575189  foo 2013-01-01 00:16:37
998  0.820750  foo 2013-01-01 00:16:38
999 -1.256530  foo 2013-01-01 00:16:39

[1000 rows x 3 columns]
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame.to_pickle pandas.read_pickle
"In [447]: df.to_pickle(""data.pkl.gz"")

In [448]: rt = pd.read_pickle(""data.pkl.gz"")

In [449]: rt
Out[449]: 
            A    B                   C
0   -0.317441  foo 2013-01-01 00:00:00
1   -1.236269  foo 2013-01-01 00:00:01
2    0.896171  foo 2013-01-01 00:00:02
3   -0.487602  foo 2013-01-01 00:00:03
4   -0.082240  foo 2013-01-01 00:00:04
..        ...  ...                 ...
995 -0.171092  foo 2013-01-01 00:16:35
996  1.786173  foo 2013-01-01 00:16:36
997 -0.575189  foo 2013-01-01 00:16:37
998  0.820750  foo 2013-01-01 00:16:38
999 -1.256530  foo 2013-01-01 00:16:39

[1000 rows x 3 columns]

In [450]: df[""A""].to_pickle(""s1.pkl.bz2"")

In [451]: rt = pd.read_pickle(""s1.pkl.bz2"")

In [452]: rt
Out[452]: 
0     -0.317441
1     -1.236269
2      0.896171
3     -0.487602
4     -0.082240
         ...   
995   -0.171092
996    1.786173
997   -0.575189
998    0.820750
999   -1.256530
Name: A, Length: 1000, dtype: float64
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame.to_pickle pandas.read_pickle
"In [453]: df.to_pickle(""data.pkl.gz"", compression={""method"": ""gzip"", ""compresslevel"": 1})
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame.to_pickle
"In [456]: index = pd.date_range(""1/1/2000"", periods=8)

In [457]: s = pd.Series(np.random.randn(5), index=[""a"", ""b"", ""c"", ""d"", ""e""])

In [458]: df = pd.DataFrame(np.random.randn(8, 3), index=index, columns=[""A"", ""B"", ""C""])

# store.put('s', s) is an equivalent method
In [459]: store[""s""] = s

In [460]: store[""df""] = df

In [461]: store
Out[461]: 

File path: store.h5
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.date_range pandas.Series pandas.DataFrame pandas.HDFStore.put
"In [470]: df_tl = pd.DataFrame({""A"": list(range(5)), ""B"": list(range(5))})

In [471]: df_tl.to_hdf(""store_tl.h5"", key=""table"", append=True)

In [472]: pd.read_hdf(""store_tl.h5"", ""table"", where=[""index>2""])
Out[472]: 
   A  B
3  3  3
4  4  4
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame pandas.DataFrame.to_hdf pandas.read_hdf
"In [473]: df_with_missing = pd.DataFrame(
   .....:     {
   .....:         ""col1"": [0, np.nan, 2],
   .....:         ""col2"": [1, np.nan, np.nan],
   .....:     }
   .....: )
   .....: 

In [474]: df_with_missing
Out[474]: 
   col1  col2
0   0.0   1.0
1   NaN   NaN
2   2.0   NaN

In [475]: df_with_missing.to_hdf(""file.h5"", key=""df_with_missing"", format=""table"", mode=""w"")

In [476]: pd.read_hdf(""file.h5"", ""df_with_missing"")
Out[476]: 
   col1  col2
0   0.0   1.0
1   NaN   NaN
2   2.0   NaN

In [477]: df_with_missing.to_hdf(
   .....:     ""file.h5"", key=""df_with_missing"", format=""table"", mode=""w"", dropna=True
   .....: )
   .....: 

In [478]: pd.read_hdf(""file.h5"", ""df_with_missing"")
Out[478]: 
   col1  col2
0   0.0   1.0
2   2.0   NaN
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame pandas.DataFrame.to_hdf pandas.read_hdf
"In [479]: pd.DataFrame(np.random.randn(10, 2)).to_hdf(""test_fixed.h5"", key=""df"")

In [480]: pd.read_hdf(""test_fixed.h5"", ""df"", where=""index>5"")
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
Cell In[480], line 1
----> 1 pd.read_hdf(""test_fixed.h5"", ""df"", where=""index>5"")

File ~/work/pandas/pandas/pandas/io/pytables.py:452, in read_hdf(path_or_buf, key, mode, errors, where, start, stop, columns, iterator, chunksize, **kwargs)
    447                 raise ValueError(
    448                     ""key must be provided when HDF5 ""
    449                     ""file contains multiple datasets.""
    450                 )
    451         key = candidate_only_group._v_pathname
--> 452     return store.select(
    453         key,
    454         where=where,
    455         start=start,
    456         stop=stop,
    457         columns=columns,
    458         iterator=iterator,
    459         chunksize=chunksize,
    460         auto_close=auto_close,
    461     )
    462 except (ValueError, TypeError, LookupError):
    463     if not isinstance(path_or_buf, HDFStore):
    464         # if there is an error, close the store if we opened it.

File ~/work/pandas/pandas/pandas/io/pytables.py:906, in HDFStore.select(self, key, where, start, stop, columns, iterator, chunksize, auto_close)
    892 # create the iterator
    893 it = TableIterator(
    894     self,
    895     s,
   (...)
    903     auto_close=auto_close,
    904 )
--> 906 return it.get_result()

File ~/work/pandas/pandas/pandas/io/pytables.py:2029, in TableIterator.get_result(self, coordinates)
   2026     where = self.where
   2028 # directly return the result
-> 2029 results = self.func(self.start, self.stop, where)
   2030 self.close()
   2031 return results

File ~/work/pandas/pandas/pandas/io/pytables.py:890, in HDFStore.select..func(_start, _stop, _where)
    889 def func(_start, _stop, _where):
--> 890     return s.read(start=_start, stop=_stop, where=_where, columns=columns)

File ~/work/pandas/pandas/pandas/io/pytables.py:3278, in BlockManagerFixed.read(self, where, columns, start, stop)
   3270 def read(
   3271     self,
   3272     where=None,
   (...)
   3276 ) -> DataFrame:
   3277     # start, stop applied to rows, so 0th axis only
-> 3278     self.validate_read(columns, where)
   3279     select_axis = self.obj_type()._get_block_manager_axis(0)
   3281     axes = []

File ~/work/pandas/pandas/pandas/io/pytables.py:2922, in GenericFixed.validate_read(self, columns, where)
   2917     raise TypeError(
   2918         ""cannot pass a column specification when reading ""
   2919         ""a Fixed format store. this store must be selected in its entirety""
   2920     )
   2921 if where is not None:
-> 2922     raise TypeError(
   2923         ""cannot pass a where specification when reading ""
   2924         ""from a Fixed format store. this store must be selected in its entirety""
   2925     )

TypeError: cannot pass a where specification when reading from a Fixed format store. this store must be selected in its entirety
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame pandas.read_hdf pandas.read_hdf pandas.HDFStore.select pandas.HDFStore.select
"In [481]: store = pd.HDFStore(""store.h5"")

In [482]: df1 = df[0:4]

In [483]: df2 = df[4:]

# append data (creates a table automatically)
In [484]: store.append(""df"", df1)

In [485]: store.append(""df"", df2)

In [486]: store
Out[486]: 

File path: store.h5

# select the entire object
In [487]: store.select(""df"")
Out[487]: 
                   A         B         C
2000-01-01  0.858644 -0.851236  1.058006
2000-01-02 -0.080372 -1.268121  1.561967
2000-01-03  0.816983  1.965656 -1.169408
2000-01-04  0.712795 -0.062433  0.736755
2000-01-05 -0.298721 -1.988045  1.475308
2000-01-06  1.103675  1.382242 -0.650762
2000-01-07 -0.729161 -0.142928 -1.063038
2000-01-08 -1.005977  0.465222 -0.094517

# the type of stored data
In [488]: store.root.df._v_attrs.pandas_type
Out[488]: 'frame_table'
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.HDFStore.select
"In [489]: store.put(""foo/bar/bah"", df)

In [490]: store.append(""food/orange"", df)

In [491]: store.append(""food/apple"", df)

In [492]: store
Out[492]: 

File path: store.h5

# a list of keys are returned
In [493]: store.keys()
Out[493]: ['/df', '/food/apple', '/food/orange', '/foo/bar/bah']

# remove all nodes under this level
In [494]: store.remove(""food"")

In [495]: store
Out[495]: 

File path: store.h5
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.HDFStore.put
"In [496]: for (path, subgroups, subkeys) in store.walk():
   .....:     for subgroup in subgroups:
   .....:         print(""GROUP: {}/{}"".format(path, subgroup))
   .....:     for subkey in subkeys:
   .....:         key = ""/"".join([path, subkey])
   .....:         print(""KEY: {}"".format(key))
   .....:         print(store.get(key))
   .....: 
GROUP: /foo
KEY: /df
                   A         B         C
2000-01-01  0.858644 -0.851236  1.058006
2000-01-02 -0.080372 -1.268121  1.561967
2000-01-03  0.816983  1.965656 -1.169408
2000-01-04  0.712795 -0.062433  0.736755
2000-01-05 -0.298721 -1.988045  1.475308
2000-01-06  1.103675  1.382242 -0.650762
2000-01-07 -0.729161 -0.142928 -1.063038
2000-01-08 -1.005977  0.465222 -0.094517
GROUP: /foo/bar
KEY: /foo/bar/bah
                   A         B         C
2000-01-01  0.858644 -0.851236  1.058006
2000-01-02 -0.080372 -1.268121  1.561967
2000-01-03  0.816983  1.965656 -1.169408
2000-01-04  0.712795 -0.062433  0.736755
2000-01-05 -0.298721 -1.988045  1.475308
2000-01-06  1.103675  1.382242 -0.650762
2000-01-07 -0.729161 -0.142928 -1.063038
2000-01-08 -1.005977  0.465222 -0.094517
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.HDFStore.walk pandas.io.formats.style.Styler.format
"In [497]: store.foo.bar.bah
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
Cell In[497], line 1
----> 1 store.foo.bar.bah

File ~/work/pandas/pandas/pandas/io/pytables.py:613, in HDFStore.__getattr__(self, name)
    611 """"""allow attribute access to get stores""""""
    612 try:
--> 613     return self.get(name)
    614 except (KeyError, ClosedFileError):
    615     pass

File ~/work/pandas/pandas/pandas/io/pytables.py:813, in HDFStore.get(self, key)
    811 if group is None:
    812     raise KeyError(f""No object named {key} in the file"")
--> 813 return self._read_group(group)

File ~/work/pandas/pandas/pandas/io/pytables.py:1878, in HDFStore._read_group(self, group)
   1877 def _read_group(self, group: Node):
-> 1878     s = self._create_storer(group)
   1879     s.infer_axes()
   1880     return s.read()

File ~/work/pandas/pandas/pandas/io/pytables.py:1752, in HDFStore._create_storer(self, group, format, value, encoding, errors)
   1750         tt = ""generic_table""
   1751     else:
-> 1752         raise TypeError(
   1753             ""cannot create a storer if the object is not existing ""
   1754             ""nor a value are passed""
   1755         )
   1756 else:
   1757     if isinstance(value, Series):

TypeError: cannot create a storer if the object is not existing nor a value are passed
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.HDFStore.get
"In [500]: df_mixed = pd.DataFrame(
   .....:     {
   .....:         ""A"": np.random.randn(8),
   .....:         ""B"": np.random.randn(8),
   .....:         ""C"": np.array(np.random.randn(8), dtype=""float32""),
   .....:         ""string"": ""string"",
   .....:         ""int"": 1,
   .....:         ""bool"": True,
   .....:         ""datetime64"": pd.Timestamp(""20010102""),
   .....:     },
   .....:     index=list(range(8)),
   .....: )
   .....: 

In [501]: df_mixed.loc[df_mixed.index[3:5], [""A"", ""B"", ""string"", ""datetime64""]] = np.nan

In [502]: store.append(""df_mixed"", df_mixed, min_itemsize={""values"": 50})

In [503]: df_mixed1 = store.select(""df_mixed"")

In [504]: df_mixed1
Out[504]: 
          A         B         C  ... int  bool                    datetime64
0  0.013747 -1.166078 -1.292080  ...   1  True 1970-01-01 00:00:00.978393600
1 -0.712009  0.247572  1.526911  ...   1  True 1970-01-01 00:00:00.978393600
2 -0.645096  1.687406  0.288504  ...   1  True 1970-01-01 00:00:00.978393600
3       NaN       NaN  0.097771  ...   1  True                           NaT
4       NaN       NaN  1.536408  ...   1  True                           NaT
5 -0.023202  0.043702  0.926790  ...   1  True 1970-01-01 00:00:00.978393600
6  2.359782  0.088224 -0.676448  ...   1  True 1970-01-01 00:00:00.978393600
7 -0.143428 -0.813360 -0.179724  ...   1  True 1970-01-01 00:00:00.978393600

[8 rows x 7 columns]

In [505]: df_mixed1.dtypes.value_counts()
Out[505]: 
float64           2
float32           1
object            1
int64             1
bool              1
datetime64[ns]    1
Name: count, dtype: int64

# we have provided a minimum string column size
In [506]: store.root.df_mixed.table
Out[506]: 
/df_mixed/table (Table(8,)) ''
  description := {
  ""index"": Int64Col(shape=(), dflt=0, pos=0),
  ""values_block_0"": Float64Col(shape=(2,), dflt=0.0, pos=1),
  ""values_block_1"": Float32Col(shape=(1,), dflt=0.0, pos=2),
  ""values_block_2"": StringCol(itemsize=50, shape=(1,), dflt=b'', pos=3),
  ""values_block_3"": Int64Col(shape=(1,), dflt=0, pos=4),
  ""values_block_4"": BoolCol(shape=(1,), dflt=False, pos=5),
  ""values_block_5"": Int64Col(shape=(1,), dflt=0, pos=6)}
  byteorder := 'little'
  chunkshape := (689,)
  autoindex := True
  colindexes := {
    ""index"": Index(6, mediumshuffle, zlib(1)).is_csi=False}
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame pandas.HDFStore.select pandas.Index
"In [507]: index = pd.MultiIndex(
   .....:    levels=[[""foo"", ""bar"", ""baz"", ""qux""], [""one"", ""two"", ""three""]],
   .....:    codes=[[0, 0, 0, 1, 1, 2, 2, 3, 3, 3], [0, 1, 2, 0, 1, 1, 2, 0, 1, 2]],
   .....:    names=[""foo"", ""bar""],
   .....: )
   .....: 

In [508]: df_mi = pd.DataFrame(np.random.randn(10, 3), index=index, columns=[""A"", ""B"", ""C""])

In [509]: df_mi
Out[509]: 
                  A         B         C
foo bar                                
foo one   -1.303456 -0.642994 -0.649456
    two    1.012694  0.414147  1.950460
    three  1.094544 -0.802899 -0.583343
bar one    0.410395  0.618321  0.560398
    two    1.434027 -0.033270  0.343197
baz two   -1.646063 -0.695847 -0.429156
    three -0.244688 -1.428229 -0.138691
qux one    1.866184 -1.446617  0.036660
    two   -1.660522  0.929553 -1.298649
    three  3.565769  0.682402  1.041927

In [510]: store.append(""df_mi"", df_mi)

In [511]: store.select(""df_mi"")
Out[511]: 
                  A         B         C
foo bar                                
foo one   -1.303456 -0.642994 -0.649456
    two    1.012694  0.414147  1.950460
    three  1.094544 -0.802899 -0.583343
bar one    0.410395  0.618321  0.560398
    two    1.434027 -0.033270  0.343197
baz two   -1.646063 -0.695847 -0.429156
    three -0.244688 -1.428229 -0.138691
qux one    1.866184 -1.446617  0.036660
    two   -1.660522  0.929553 -1.298649
    three  3.565769  0.682402  1.041927

# the levels are automatically included as data columns
In [512]: store.select(""df_mi"", ""foo=bar"")
Out[512]: 
                A         B         C
foo bar                              
bar one  0.410395  0.618321  0.560398
    two  1.434027 -0.033270  0.343197
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.MultiIndex pandas.DataFrame pandas.HDFStore.select
"string = ""HolyMoly'""
store.select(""df"", ""index == string"")
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.HDFStore.select
"string = ""HolyMoly'""
store.select('df', f'index == {string}')
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.HDFStore.select
"store.select(""df"", ""index == %r"" % string)
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.HDFStore.select
"In [513]: dfq = pd.DataFrame(
   .....:     np.random.randn(10, 4),
   .....:     columns=list(""ABCD""),
   .....:     index=pd.date_range(""20130101"", periods=10),
   .....: )
   .....: 

In [514]: store.append(""dfq"", dfq, format=""table"", data_columns=True)
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame pandas.date_range
"In [515]: store.select(""dfq"", ""index>pd.Timestamp('20130104') & columns=['A', 'B']"")
Out[515]: 
                   A         B
2013-01-05 -0.830545 -0.457071
2013-01-06  0.431186  1.049421
2013-01-07  0.617509 -0.811230
2013-01-08  0.947422 -0.671233
2013-01-09 -0.183798 -1.211230
2013-01-10  0.361428  0.887304
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.HDFStore.select
"In [516]: store.select(""dfq"", where=""A>0 or C>0"")
Out[516]: 
                   A         B         C         D
2013-01-02  0.658179  0.362814 -0.917897  0.010165
2013-01-03  0.905122  1.848731 -1.184241  0.932053
2013-01-05 -0.830545 -0.457071  1.565581  1.148032
2013-01-06  0.431186  1.049421  0.383309  0.595013
2013-01-07  0.617509 -0.811230 -2.088563 -1.393500
2013-01-08  0.947422 -0.671233 -0.847097 -1.187785
2013-01-10  0.361428  0.887304  0.266457 -0.399641
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.HDFStore.select
"In [517]: store.select(""df"", ""columns=['A', 'B']"")
Out[517]: 
                   A         B
2000-01-01  0.858644 -0.851236
2000-01-02 -0.080372 -1.268121
2000-01-03  0.816983  1.965656
2000-01-04  0.712795 -0.062433
2000-01-05 -0.298721 -1.988045
2000-01-06  1.103675  1.382242
2000-01-07 -0.729161 -0.142928
2000-01-08 -1.005977  0.465222
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.HDFStore.select
"In [518]: from datetime import timedelta

In [519]: dftd = pd.DataFrame(
   .....:     {
   .....:         ""A"": pd.Timestamp(""20130101""),
   .....:         ""B"": [
   .....:             pd.Timestamp(""20130101"") + timedelta(days=i, seconds=10)
   .....:             for i in range(10)
   .....:         ],
   .....:     }
   .....: )
   .....: 

In [520]: dftd[""C""] = dftd[""A""] - dftd[""B""]

In [521]: dftd
Out[521]: 
           A                   B                  C
0 2013-01-01 2013-01-01 00:00:10  -1 days +23:59:50
1 2013-01-01 2013-01-02 00:00:10  -2 days +23:59:50
2 2013-01-01 2013-01-03 00:00:10  -3 days +23:59:50
3 2013-01-01 2013-01-04 00:00:10  -4 days +23:59:50
4 2013-01-01 2013-01-05 00:00:10  -5 days +23:59:50
5 2013-01-01 2013-01-06 00:00:10  -6 days +23:59:50
6 2013-01-01 2013-01-07 00:00:10  -7 days +23:59:50
7 2013-01-01 2013-01-08 00:00:10  -8 days +23:59:50
8 2013-01-01 2013-01-09 00:00:10  -9 days +23:59:50
9 2013-01-01 2013-01-10 00:00:10 -10 days +23:59:50

In [522]: store.append(""dftd"", dftd, data_columns=True)

In [523]: store.select(""dftd"", ""C<'-3.5D'"")
Out[523]: 
                              A                   B                  C
4 1970-01-01 00:00:01.356998400 2013-01-05 00:00:10  -5 days +23:59:50
5 1970-01-01 00:00:01.356998400 2013-01-06 00:00:10  -6 days +23:59:50
6 1970-01-01 00:00:01.356998400 2013-01-07 00:00:10  -7 days +23:59:50
7 1970-01-01 00:00:01.356998400 2013-01-08 00:00:10  -8 days +23:59:50
8 1970-01-01 00:00:01.356998400 2013-01-09 00:00:10  -9 days +23:59:50
9 1970-01-01 00:00:01.356998400 2013-01-10 00:00:10 -10 days +23:59:50
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame pandas.HDFStore.select
"In [524]: df_mi.index.names
Out[524]: FrozenList(['foo', 'bar'])

In [525]: store.select(""df_mi"", ""foo=baz and bar=two"")
Out[525]: 
                A         B         C
foo bar                              
baz two -1.646063 -0.695847 -0.429156
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.HDFStore.select
"In [526]: index = pd.MultiIndex(
   .....:     levels=[[""foo"", ""bar"", ""baz"", ""qux""], [""one"", ""two"", ""three""]],
   .....:     codes=[[0, 0, 0, 1, 1, 2, 2, 3, 3, 3], [0, 1, 2, 0, 1, 1, 2, 0, 1, 2]],
   .....: )
   .....: 

In [527]: df_mi_2 = pd.DataFrame(np.random.randn(10, 3), index=index, columns=[""A"", ""B"", ""C""])

In [528]: df_mi_2
Out[528]: 
                  A         B         C
foo one   -0.219582  1.186860 -1.437189
    two    0.053768  1.872644 -1.469813
    three -0.564201  0.876341  0.407749
bar one   -0.232583  0.179812  0.922152
    two   -1.820952 -0.641360  2.133239
baz two   -0.941248 -0.136307 -1.271305
    three -0.099774 -0.061438 -0.845172
qux one    0.465793  0.756995 -0.541690
    two   -0.802241  0.877657 -2.553831
    three  0.094899 -2.319519  0.293601

In [529]: store.append(""df_mi_2"", df_mi_2)

# the levels are automatically included as data columns with keyword level_n
In [530]: store.select(""df_mi_2"", ""level_0=foo and level_1=two"")
Out[530]: 
                A         B         C
foo two  0.053768  1.872644 -1.469813
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.MultiIndex pandas.DataFrame pandas.HDFStore.select
"In [536]: df_1 = pd.DataFrame(np.random.randn(10, 2), columns=list(""AB""))

In [537]: df_2 = pd.DataFrame(np.random.randn(10, 2), columns=list(""AB""))

In [538]: st = pd.HDFStore(""appends.h5"", mode=""w"")

In [539]: st.append(""df"", df_1, data_columns=[""B""], index=False)

In [540]: st.append(""df"", df_2, data_columns=[""B""], index=False)

In [541]: st.get_storer(""df"").table
Out[541]: 
/df/table (Table(20,)) ''
  description := {
  ""index"": Int64Col(shape=(), dflt=0, pos=0),
  ""values_block_0"": Float64Col(shape=(1,), dflt=0.0, pos=1),
  ""B"": Float64Col(shape=(), dflt=0.0, pos=2)}
  byteorder := 'little'
  chunkshape := (2730,)
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame
"In [542]: st.create_table_index(""df"", columns=[""B""], optlevel=9, kind=""full"")

In [543]: st.get_storer(""df"").table
Out[543]: 
/df/table (Table(20,)) ''
  description := {
  ""index"": Int64Col(shape=(), dflt=0, pos=0),
  ""values_block_0"": Float64Col(shape=(1,), dflt=0.0, pos=1),
  ""B"": Float64Col(shape=(), dflt=0.0, pos=2)}
  byteorder := 'little'
  chunkshape := (2730,)
  autoindex := True
  colindexes := {
    ""B"": Index(9, fullshuffle, zlib(1)).is_csi=True}

In [544]: st.close()
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.Index
"In [545]: df_dc = df.copy()

In [546]: df_dc[""string""] = ""foo""

In [547]: df_dc.loc[df_dc.index[4:6], ""string""] = np.nan

In [548]: df_dc.loc[df_dc.index[7:9], ""string""] = ""bar""

In [549]: df_dc[""string2""] = ""cool""

In [550]: df_dc.loc[df_dc.index[1:3], [""B"", ""C""]] = 1.0

In [551]: df_dc
Out[551]: 
                   A         B         C string string2
2000-01-01  0.858644 -0.851236  1.058006    foo    cool
2000-01-02 -0.080372  1.000000  1.000000    foo    cool
2000-01-03  0.816983  1.000000  1.000000    foo    cool
2000-01-04  0.712795 -0.062433  0.736755    foo    cool
2000-01-05 -0.298721 -1.988045  1.475308    NaN    cool
2000-01-06  1.103675  1.382242 -0.650762    NaN    cool
2000-01-07 -0.729161 -0.142928 -1.063038    foo    cool
2000-01-08 -1.005977  0.465222 -0.094517    bar    cool

# on-disk operations
In [552]: store.append(""df_dc"", df_dc, data_columns=[""B"", ""C"", ""string"", ""string2""])

In [553]: store.select(""df_dc"", where=""B > 0"")
Out[553]: 
                   A         B         C string string2
2000-01-02 -0.080372  1.000000  1.000000    foo    cool
2000-01-03  0.816983  1.000000  1.000000    foo    cool
2000-01-06  1.103675  1.382242 -0.650762    NaN    cool
2000-01-08 -1.005977  0.465222 -0.094517    bar    cool

# getting creative
In [554]: store.select(""df_dc"", ""B > 0 & C > 0 & string == foo"")
Out[554]: 
                   A    B    C string string2
2000-01-02 -0.080372  1.0  1.0    foo    cool
2000-01-03  0.816983  1.0  1.0    foo    cool

# this is in-memory version of this type of selection
In [555]: df_dc[(df_dc.B > 0) & (df_dc.C > 0) & (df_dc.string == ""foo"")]
Out[555]: 
                   A    B    C string string2
2000-01-02 -0.080372  1.0  1.0    foo    cool
2000-01-03  0.816983  1.0  1.0    foo    cool

# we have automagically created this index and the B/C/string/string2
# columns are stored separately as ``PyTables`` columns
In [556]: store.root.df_dc.table
Out[556]: 
/df_dc/table (Table(8,)) ''
  description := {
  ""index"": Int64Col(shape=(), dflt=0, pos=0),
  ""values_block_0"": Float64Col(shape=(1,), dflt=0.0, pos=1),
  ""B"": Float64Col(shape=(), dflt=0.0, pos=2),
  ""C"": Float64Col(shape=(), dflt=0.0, pos=3),
  ""string"": StringCol(itemsize=3, shape=(), dflt=b'', pos=4),
  ""string2"": StringCol(itemsize=4, shape=(), dflt=b'', pos=5)}
  byteorder := 'little'
  chunkshape := (1680,)
  autoindex := True
  colindexes := {
    ""index"": Index(6, mediumshuffle, zlib(1)).is_csi=False,
    ""B"": Index(6, mediumshuffle, zlib(1)).is_csi=False,
    ""C"": Index(6, mediumshuffle, zlib(1)).is_csi=False,
    ""string"": Index(6, mediumshuffle, zlib(1)).is_csi=False,
    ""string2"": Index(6, mediumshuffle, zlib(1)).is_csi=False}
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame.copy pandas.HDFStore.select pandas.Index
"In [557]: for df in store.select(""df"", chunksize=3):
   .....:     print(df)
   .....: 
                   A         B         C
2000-01-01  0.858644 -0.851236  1.058006
2000-01-02 -0.080372 -1.268121  1.561967
2000-01-03  0.816983  1.965656 -1.169408
                   A         B         C
2000-01-04  0.712795 -0.062433  0.736755
2000-01-05 -0.298721 -1.988045  1.475308
2000-01-06  1.103675  1.382242 -0.650762
                   A         B         C
2000-01-07 -0.729161 -0.142928 -1.063038
2000-01-08 -1.005977  0.465222 -0.094517
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.HDFStore.select
"for df in pd.read_hdf(""store.h5"", ""df"", chunksize=3):
    print(df)
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_hdf
"In [558]: dfeq = pd.DataFrame({""number"": np.arange(1, 11)})

In [559]: dfeq
Out[559]: 
   number
0       1
1       2
2       3
3       4
4       5
5       6
6       7
7       8
8       9
9      10

In [560]: store.append(""dfeq"", dfeq, data_columns=[""number""])

In [561]: def chunks(l, n):
   .....:     return [l[i: i + n] for i in range(0, len(l), n)]
   .....: 

In [562]: evens = [2, 4, 6, 8, 10]

In [563]: coordinates = store.select_as_coordinates(""dfeq"", ""number=evens"")

In [564]: for c in chunks(coordinates, 2):
   .....:     print(store.select(""dfeq"", where=c))
   .....: 
   number
1       2
3       4
   number
5       6
7       8
   number
9      10
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame pandas.HDFStore.select
"In [567]: df_coord = pd.DataFrame(
   .....:     np.random.randn(1000, 2), index=pd.date_range(""20000101"", periods=1000)
   .....: )
   .....: 

In [568]: store.append(""df_coord"", df_coord)

In [569]: c = store.select_as_coordinates(""df_coord"", ""index > 20020101"")

In [570]: c
Out[570]: 
Index([732, 733, 734, 735, 736, 737, 738, 739, 740, 741,
       ...
       990, 991, 992, 993, 994, 995, 996, 997, 998, 999],
      dtype='int64', length=268)

In [571]: store.select(""df_coord"", where=c)
Out[571]: 
                   0         1
2002-01-02  0.007717  1.168386
2002-01-03  0.759328 -0.638934
2002-01-04 -1.154018 -0.324071
2002-01-05 -0.804551 -1.280593
2002-01-06 -0.047208  1.260503
...              ...       ...
2002-09-22 -1.139583  0.344316
2002-09-23 -0.760643 -1.306704
2002-09-24  0.059018  1.775482
2002-09-25  1.242255 -0.055457
2002-09-26  0.410317  2.194489

[268 rows x 2 columns]
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame pandas.date_range pandas.Index pandas.HDFStore.select
"In [572]: df_mask = pd.DataFrame(
   .....:     np.random.randn(1000, 2), index=pd.date_range(""20000101"", periods=1000)
   .....: )
   .....: 

In [573]: store.append(""df_mask"", df_mask)

In [574]: c = store.select_column(""df_mask"", ""index"")

In [575]: where = c[pd.DatetimeIndex(c).month == 5].index

In [576]: store.select(""df_mask"", where=where)
Out[576]: 
                   0         1
2000-05-01  1.479511  0.516433
2000-05-02 -0.334984 -1.493537
2000-05-03  0.900321  0.049695
2000-05-04  0.614266 -1.077151
2000-05-05  0.233881  0.493246
...              ...       ...
2002-05-27  0.294122  0.457407
2002-05-28 -1.102535  1.215650
2002-05-29 -0.432911  0.753606
2002-05-30 -1.105212  2.311877
2002-05-31  2.567296  2.610691

[93 rows x 2 columns]
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame pandas.date_range pandas.DatetimeIndex pandas.HDFStore.select
"In [578]: df_mt = pd.DataFrame(
   .....:     np.random.randn(8, 6),
   .....:     index=pd.date_range(""1/1/2000"", periods=8),
   .....:     columns=[""A"", ""B"", ""C"", ""D"", ""E"", ""F""],
   .....: )
   .....: 

In [579]: df_mt[""foo""] = ""bar""

In [580]: df_mt.loc[df_mt.index[1], (""A"", ""B"")] = np.nan

# you can also create the tables individually
In [581]: store.append_to_multiple(
   .....:     {""df1_mt"": [""A"", ""B""], ""df2_mt"": None}, df_mt, selector=""df1_mt""
   .....: )
   .....: 

In [582]: store
Out[582]: 

File path: store.h5

# individual tables were created
In [583]: store.select(""df1_mt"")
Out[583]: 
                   A         B
2000-01-01  0.162291 -0.430489
2000-01-02       NaN       NaN
2000-01-03  0.429207 -1.099274
2000-01-04  1.869081 -1.466039
2000-01-05  0.092130 -1.726280
2000-01-06  0.266901 -0.036854
2000-01-07 -0.517871 -0.990317
2000-01-08 -0.231342  0.557402

In [584]: store.select(""df2_mt"")
Out[584]: 
                   C         D         E         F  foo
2000-01-01 -2.502042  0.668149  0.460708  1.834518  bar
2000-01-02  0.130441 -0.608465  0.439872  0.506364  bar
2000-01-03 -1.069546  1.236277  0.116634 -1.772519  bar
2000-01-04  0.137462  0.313939  0.748471 -0.943009  bar
2000-01-05  0.836517  2.049798  0.562167  0.189952  bar
2000-01-06  1.112750 -0.151596  1.503311  0.939470  bar
2000-01-07 -0.294348  0.335844 -0.794159  1.495614  bar
2000-01-08  0.860312 -0.538674 -0.541986 -1.759606  bar

# as a multiple
In [585]: store.select_as_multiple(
   .....:     [""df1_mt"", ""df2_mt""],
   .....:     where=[""A>0"", ""B>0""],
   .....:     selector=""df1_mt"",
   .....: )
   .....: 
Out[585]: 
Empty DataFrame
Columns: [A, B, C, D, E, F, foo]
Index: []
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame pandas.date_range pandas.HDFStore.select
"In [586]: dfcat = pd.DataFrame(
   .....:     {""A"": pd.Series(list(""aabbcdba"")).astype(""category""), ""B"": np.random.randn(8)}
   .....: )
   .....: 

In [587]: dfcat
Out[587]: 
   A         B
0  a -1.520478
1  a -1.069391
2  b -0.551981
3  b  0.452407
4  c  0.409257
5  d  0.301911
6  b -0.640843
7  a -2.253022

In [588]: dfcat.dtypes
Out[588]: 
A    category
B     float64
dtype: object

In [589]: cstore = pd.HDFStore(""cats.h5"", mode=""w"")

In [590]: cstore.append(""dfcat"", dfcat, format=""table"", data_columns=[""A""])

In [591]: result = cstore.select(""dfcat"", where=""A in ['b', 'c']"")

In [592]: result
Out[592]: 
   A         B
2  b -0.551981
3  b  0.452407
4  c  0.409257
6  b -0.640843

In [593]: result.dtypes
Out[593]: 
A    category
B     float64
dtype: object
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame pandas.Series pandas.HDFStore.select
"In [594]: dfs = pd.DataFrame({""A"": ""foo"", ""B"": ""bar""}, index=list(range(5)))

In [595]: dfs
Out[595]: 
     A    B
0  foo  bar
1  foo  bar
2  foo  bar
3  foo  bar
4  foo  bar

# A and B have a size of 30
In [596]: store.append(""dfs"", dfs, min_itemsize=30)

In [597]: store.get_storer(""dfs"").table
Out[597]: 
/dfs/table (Table(5,)) ''
  description := {
  ""index"": Int64Col(shape=(), dflt=0, pos=0),
  ""values_block_0"": StringCol(itemsize=30, shape=(2,), dflt=b'', pos=1)}
  byteorder := 'little'
  chunkshape := (963,)
  autoindex := True
  colindexes := {
    ""index"": Index(6, mediumshuffle, zlib(1)).is_csi=False}

# A is created as a data_column with a size of 30
# B is size is calculated
In [598]: store.append(""dfs2"", dfs, min_itemsize={""A"": 30})

In [599]: store.get_storer(""dfs2"").table
Out[599]: 
/dfs2/table (Table(5,)) ''
  description := {
  ""index"": Int64Col(shape=(), dflt=0, pos=0),
  ""values_block_0"": StringCol(itemsize=3, shape=(1,), dflt=b'', pos=1),
  ""A"": StringCol(itemsize=30, shape=(), dflt=b'', pos=2)}
  byteorder := 'little'
  chunkshape := (1598,)
  autoindex := True
  colindexes := {
    ""index"": Index(6, mediumshuffle, zlib(1)).is_csi=False,
    ""A"": Index(6, mediumshuffle, zlib(1)).is_csi=False}
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame pandas.Index
"In [600]: dfss = pd.DataFrame({""A"": [""foo"", ""bar"", ""nan""]})

In [601]: dfss
Out[601]: 
     A
0  foo
1  bar
2  nan

In [602]: store.append(""dfss"", dfss)

In [603]: store.select(""dfss"")
Out[603]: 
     A
0  foo
1  bar
2  NaN

# here you need to specify a different nan rep
In [604]: store.append(""dfss2"", dfss, nan_rep=""_nan_"")

In [605]: store.select(""dfss2"")
Out[605]: 
     A
0  foo
1  bar
2  nan
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame pandas.HDFStore.select
"In [606]: df = pd.DataFrame(
   .....:     {
   .....:         ""a"": list(""abc""),
   .....:         ""b"": list(range(1, 4)),
   .....:         ""c"": np.arange(3, 6).astype(""u1""),
   .....:         ""d"": np.arange(4.0, 7.0, dtype=""float64""),
   .....:         ""e"": [True, False, True],
   .....:         ""f"": pd.Categorical(list(""abc"")),
   .....:         ""g"": pd.date_range(""20130101"", periods=3),
   .....:         ""h"": pd.date_range(""20130101"", periods=3, tz=""US/Eastern""),
   .....:         ""i"": pd.date_range(""20130101"", periods=3, freq=""ns""),
   .....:     }
   .....: )
   .....: 

In [607]: df
Out[607]: 
   a  b  c  ...          g                         h                             i
0  a  1  3  ... 2013-01-01 2013-01-01 00:00:00-05:00 2013-01-01 00:00:00.000000000
1  b  2  4  ... 2013-01-02 2013-01-02 00:00:00-05:00 2013-01-01 00:00:00.000000001
2  c  3  5  ... 2013-01-03 2013-01-03 00:00:00-05:00 2013-01-01 00:00:00.000000002

[3 rows x 9 columns]

In [608]: df.dtypes
Out[608]: 
a                        object
b                         int64
c                         uint8
d                       float64
e                          bool
f                      category
g                datetime64[ns]
h    datetime64[ns, US/Eastern]
i                datetime64[ns]
dtype: object
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame pandas.Categorical pandas.date_range
"In [609]: df.to_feather(""example.feather"")
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame.to_feather
"In [610]: result = pd.read_feather(""example.feather"")

In [611]: result
Out[611]: 
   a  b  c  ...          g                         h                             i
0  a  1  3  ... 2013-01-01 2013-01-01 00:00:00-05:00 2013-01-01 00:00:00.000000000
1  b  2  4  ... 2013-01-02 2013-01-02 00:00:00-05:00 2013-01-01 00:00:00.000000001
2  c  3  5  ... 2013-01-03 2013-01-03 00:00:00-05:00 2013-01-01 00:00:00.000000002

[3 rows x 9 columns]

# we preserve dtypes
In [612]: result.dtypes
Out[612]: 
a                        object
b                         int64
c                         uint8
d                       float64
e                          bool
f                      category
g                datetime64[ns]
h    datetime64[ns, US/Eastern]
i                datetime64[ns]
dtype: object
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_feather
"In [613]: df = pd.DataFrame(
   .....:     {
   .....:         ""a"": list(""abc""),
   .....:         ""b"": list(range(1, 4)),
   .....:         ""c"": np.arange(3, 6).astype(""u1""),
   .....:         ""d"": np.arange(4.0, 7.0, dtype=""float64""),
   .....:         ""e"": [True, False, True],
   .....:         ""f"": pd.date_range(""20130101"", periods=3),
   .....:         ""g"": pd.date_range(""20130101"", periods=3, tz=""US/Eastern""),
   .....:         ""h"": pd.Categorical(list(""abc"")),
   .....:         ""i"": pd.Categorical(list(""abc""), ordered=True),
   .....:     }
   .....: )
   .....: 

In [614]: df
Out[614]: 
   a  b  c    d      e          f                         g  h  i
0  a  1  3  4.0   True 2013-01-01 2013-01-01 00:00:00-05:00  a  a
1  b  2  4  5.0  False 2013-01-02 2013-01-02 00:00:00-05:00  b  b
2  c  3  5  6.0   True 2013-01-03 2013-01-03 00:00:00-05:00  c  c

In [615]: df.dtypes
Out[615]: 
a                        object
b                         int64
c                         uint8
d                       float64
e                          bool
f                datetime64[ns]
g    datetime64[ns, US/Eastern]
h                      category
i                      category
dtype: object
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame pandas.date_range pandas.Categorical
"In [616]: df.to_parquet(""example_pa.parquet"", engine=""pyarrow"")

In [617]: df.to_parquet(""example_fp.parquet"", engine=""fastparquet"")
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame.to_parquet
"In [618]: result = pd.read_parquet(""example_fp.parquet"", engine=""fastparquet"")

In [619]: result = pd.read_parquet(""example_pa.parquet"", engine=""pyarrow"")

In [620]: result.dtypes
Out[620]: 
a                        object
b                         int64
c                         uint8
d                       float64
e                          bool
f                datetime64[ns]
g    datetime64[ns, US/Eastern]
h                      category
i                      category
dtype: object
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_parquet
"In [621]: result = pd.read_parquet(""example_pa.parquet"", engine=""pyarrow"", dtype_backend=""pyarrow"")

In [622]: result.dtypes
Out[622]: 
a                                      string[pyarrow]
b                                       int64[pyarrow]
c                                       uint8[pyarrow]
d                                      double[pyarrow]
e                                        bool[pyarrow]
f                               timestamp[ns][pyarrow]
g                timestamp[ns, tz=US/Eastern][pyarrow]
h    dictionary
i    dictionary
dtype: object
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_parquet
"In [623]: result = pd.read_parquet(
   .....:     ""example_fp.parquet"",
   .....:     engine=""fastparquet"",
   .....:     columns=[""a"", ""b""],
   .....: )
   .....: 

In [624]: result = pd.read_parquet(
   .....:     ""example_pa.parquet"",
   .....:     engine=""pyarrow"",
   .....:     columns=[""a"", ""b""],
   .....: )
   .....: 

In [625]: result.dtypes
Out[625]: 
a    object
b     int64
dtype: object
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_parquet
"In [626]: df = pd.DataFrame({""a"": [1, 2], ""b"": [3, 4]})

In [627]: df.to_parquet(""test.parquet"", engine=""pyarrow"")
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame pandas.DataFrame.to_parquet
"In [628]: df.to_parquet(""test.parquet"", index=False)
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame.to_parquet
"In [629]: df = pd.DataFrame({""a"": [0, 0, 1, 1], ""b"": [0, 1, 0, 1]})

In [630]: df.to_parquet(path=""test"", engine=""pyarrow"", partition_cols=[""a""], compression=None)
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame pandas.DataFrame.to_parquet
"In [631]: df = pd.DataFrame(
   .....:     {
   .....:         ""a"": list(""abc""),
   .....:         ""b"": list(range(1, 4)),
   .....:         ""c"": np.arange(4.0, 7.0, dtype=""float64""),
   .....:         ""d"": [True, False, True],
   .....:         ""e"": pd.date_range(""20130101"", periods=3),
   .....:     }
   .....: )
   .....: 

In [632]: df
Out[632]: 
   a  b    c      d          e
0  a  1  4.0   True 2013-01-01
1  b  2  5.0  False 2013-01-02
2  c  3  6.0   True 2013-01-03

In [633]: df.dtypes
Out[633]: 
a            object
b             int64
c           float64
d              bool
e    datetime64[ns]
dtype: object
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame pandas.date_range
"In [634]: df.to_orc(""example_pa.orc"", engine=""pyarrow"")
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame.to_orc
"In [635]: result = pd.read_orc(""example_pa.orc"")

In [636]: result.dtypes
Out[636]: 
a            object
b             int64
c           float64
d              bool
e    datetime64[ns]
dtype: object
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_orc
"In [637]: result = pd.read_orc(
   .....:     ""example_pa.orc"",
   .....:     columns=[""a"", ""b""],
   .....: )
   .....: 

In [638]: result.dtypes
Out[638]: 
a    object
b     int64
dtype: object
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_orc
"import adbc_driver_sqlite.dbapi as sqlite_dbapi

# Create the connection
with sqlite_dbapi.connect(""sqlite:///:memory:"") as conn:
     df = pd.read_sql_table(""data"", conn)
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_sql_table
"with engine.connect() as conn, conn.begin():
    data = pd.read_sql_table(""data"", conn)
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_sql_table
"In [641]: import datetime

In [642]: c = [""id"", ""Date"", ""Col_1"", ""Col_2"", ""Col_3""]

In [643]: d = [
   .....:     (26, datetime.datetime(2010, 10, 18), ""X"", 27.5, True),
   .....:     (42, datetime.datetime(2010, 10, 19), ""Y"", -12.5, False),
   .....:     (63, datetime.datetime(2010, 10, 20), ""Z"", 5.73, True),
   .....: ]
   .....: 

In [644]: data = pd.DataFrame(d, columns=c)

In [645]: data
Out[645]: 
   id       Date Col_1  Col_2  Col_3
0  26 2010-10-18     X  27.50   True
1  42 2010-10-19     Y -12.50  False
2  63 2010-10-20     Z   5.73   True

In [646]: data.to_sql(""data"", con=engine)
Out[646]: 3
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame pandas.DataFrame.to_sql
"In [647]: data.to_sql(""data_chunked"", con=engine, chunksize=1000)
Out[647]: 3
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame.to_sql
"# for roundtripping
with pg_dbapi.connect(uri) as conn:
    df2 = pd.read_sql(""pandas_table"", conn, dtype_backend=""pyarrow"")
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_sql
"In [648]: from sqlalchemy.types import String

In [649]: data.to_sql(""data_dtype"", con=engine, dtype={""Col_1"": String})
Out[649]: 3
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame.to_sql
"# Alternative to_sql() *method* for DBs that support COPY FROM
import csv
from io import StringIO

def psql_insert_copy(table, conn, keys, data_iter):
    """"""
    Execute SQL statement inserting data

    Parameters
    ----------
    table : pandas.io.sql.SQLTable
    conn : sqlalchemy.engine.Engine or sqlalchemy.engine.Connection
    keys : list of str
        Column names
    data_iter : Iterable that iterates the values to be inserted
    """"""
    # gets a DBAPI connection that can provide a cursor
    dbapi_conn = conn.connection
    with dbapi_conn.cursor() as cur:
        s_buf = StringIO()
        writer = csv.writer(s_buf)
        writer.writerows(data_iter)
        s_buf.seek(0)

        columns = ', '.join(['""{}""'.format(k) for k in keys])
        if table.schema:
            table_name = '{}.{}'.format(table.schema, table.name)
        else:
            table_name = table.name

        sql = 'COPY {} ({}) FROM STDIN WITH CSV'.format(
            table_name, columns)
        cur.copy_expert(sql=sql, file=s_buf)
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.io.formats.style.Styler.format
"In [650]: pd.read_sql_table(""data"", engine)
Out[650]: 
   index  id       Date Col_1  Col_2  Col_3
0      0  26 2010-10-18     X  27.50   True
1      1  42 2010-10-19     Y -12.50  False
2      2  63 2010-10-20     Z   5.73   True
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_sql_table
"In [651]: pd.read_sql_table(""data"", engine, index_col=""id"")
Out[651]: 
    index       Date Col_1  Col_2  Col_3
id                                      
26      0 2010-10-18     X  27.50   True
42      1 2010-10-19     Y -12.50  False
63      2 2010-10-20     Z   5.73   True

In [652]: pd.read_sql_table(""data"", engine, columns=[""Col_1"", ""Col_2""])
Out[652]: 
  Col_1  Col_2
0     X  27.50
1     Y -12.50
2     Z   5.73
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_sql_table
"In [653]: pd.read_sql_table(""data"", engine, parse_dates=[""Date""])
Out[653]: 
   index  id       Date Col_1  Col_2  Col_3
0      0  26 2010-10-18     X  27.50   True
1      1  42 2010-10-19     Y -12.50  False
2      2  63 2010-10-20     Z   5.73   True
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_sql_table
"pd.read_sql_table(""data"", engine, parse_dates={""Date"": ""%Y-%m-%d""})
pd.read_sql_table(
    ""data"",
    engine,
    parse_dates={""Date"": {""format"": ""%Y-%m-%d %H:%M:%S""}},
)
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_sql_table
"df.to_sql(name=""table"", con=engine, schema=""other_schema"")
pd.read_sql_table(""table"", engine, schema=""other_schema"")
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame.to_sql pandas.read_sql_table
"In [654]: pd.read_sql_query(""SELECT * FROM data"", engine)
Out[654]: 
   index  id                        Date Col_1  Col_2  Col_3
0      0  26  2010-10-18 00:00:00.000000     X  27.50      1
1      1  42  2010-10-19 00:00:00.000000     Y -12.50      0
2      2  63  2010-10-20 00:00:00.000000     Z   5.73      1
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_sql_query
"In [655]: pd.read_sql_query(""SELECT id, Col_1, Col_2 FROM data WHERE id = 42;"", engine)
Out[655]: 
   id Col_1  Col_2
0  42     Y  -12.5
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_sql_query
"In [656]: df = pd.DataFrame(np.random.randn(20, 3), columns=list(""abc""))

In [657]: df.to_sql(name=""data_chunks"", con=engine, index=False)
Out[657]: 20
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame pandas.DataFrame.to_sql
"In [658]: for chunk in pd.read_sql_query(""SELECT * FROM data_chunks"", engine, chunksize=5):
   .....:     print(chunk)
   .....: 
          a         b         c
0 -0.395347 -0.822726 -0.363777
1  1.676124 -0.908102 -1.391346
2 -1.094269  0.278380  1.205899
3  1.503443  0.932171 -0.709459
4 -0.645944 -1.351389  0.132023
          a         b         c
0  0.210427  0.192202  0.661949
1  1.690629 -1.046044  0.618697
2 -0.013863  1.314289  1.951611
3 -1.485026  0.304662  1.194757
4 -0.446717  0.528496 -0.657575
          a         b         c
0 -0.876654  0.336252  0.172668
1  0.337684 -0.411202 -0.828394
2 -0.244413  1.094948  0.087183
3  1.125934 -1.480095  1.205944
4 -0.451849  0.452214 -2.208192
          a         b         c
0 -2.061019  0.044184 -0.017118
1  1.248959 -0.675595 -1.908296
2 -0.125934  1.491974  0.648726
3  0.391214  0.438609  1.634248
4  1.208707 -1.535740  1.620399
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_sql_query
"In [659]: import sqlalchemy as sa

In [660]: pd.read_sql(
   .....:     sa.text(""SELECT * FROM data where Col_1=:col1""), engine, params={""col1"": ""X""}
   .....: )
   .....: 
Out[660]: 
   index  id                        Date Col_1  Col_2  Col_3
0      0  26  2010-10-18 00:00:00.000000     X   27.5      1
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_sql
"In [661]: metadata = sa.MetaData()

In [662]: data_table = sa.Table(
   .....:     ""data"",
   .....:     metadata,
   .....:     sa.Column(""index"", sa.Integer),
   .....:     sa.Column(""Date"", sa.DateTime),
   .....:     sa.Column(""Col_1"", sa.String),
   .....:     sa.Column(""Col_2"", sa.Float),
   .....:     sa.Column(""Col_3"", sa.Boolean),
   .....: )
   .....: 

In [663]: pd.read_sql(sa.select(data_table).where(data_table.c.Col_3 is True), engine)
Out[663]: 
Empty DataFrame
Columns: [index, Date, Col_1, Col_2, Col_3]
Index: []
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_sql
"In [664]: import datetime as dt

In [665]: expr = sa.select(data_table).where(data_table.c.Date > sa.bindparam(""date""))

In [666]: pd.read_sql(expr, engine, params={""date"": dt.datetime(2010, 10, 18)})
Out[666]: 
   index       Date Col_1  Col_2  Col_3
0      1 2010-10-19     Y -12.50  False
1      2 2010-10-20     Z   5.73   True
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_sql
"data.to_sql(""data"", con)
pd.read_sql_query(""SELECT * FROM data"", con)
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame.to_sql pandas.read_sql_query
"In [667]: df = pd.DataFrame(np.random.randn(10, 2), columns=list(""AB""))

In [668]: df.to_stata(""stata.dta"")
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame pandas.DataFrame.to_stata
"In [669]: pd.read_stata(""stata.dta"")
Out[669]: 
   index         A         B
0      0 -0.165614  0.490482
1      1 -0.637829  0.067091
2      2 -0.242577  1.348038
3      3  0.647699 -0.644937
4      4  0.625771  0.918376
5      5  0.401781 -1.488919
6      6 -0.981845 -0.046882
7      7 -0.306796  0.877025
8      8 -0.336606  0.624747
9      9 -1.582600  0.806340
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_stata
"In [670]: with pd.read_stata(""stata.dta"", chunksize=3) as reader:
   .....:     for df in reader:
   .....:         print(df.shape)
   .....: 
(3, 3)
(3, 3)
(3, 3)
(1, 3)
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_stata
"In [671]: with pd.read_stata(""stata.dta"", iterator=True) as reader:
   .....:     chunk1 = reader.read(5)
   .....:     chunk2 = reader.read(5)
   .....: 
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_stata
"df = pd.read_sas(""sas_data.sas7bdat"")
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_sas
"def do_something(chunk):
    pass


with pd.read_sas(""sas_xport.xpt"", chunk=100000) as rdr:
    for chunk in rdr:
        do_something(chunk)
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_sas
"df = pd.read_spss(""spss_data.sav"")
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_spss
"df = pd.read_spss(
    ""spss_data.sav"",
    usecols=[""foo"", ""bar""],
    convert_categoricals=False,
)
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.read_spss
"In [1]: sz = 1000000
In [2]: df = pd.DataFrame({'A': np.random.randn(sz), 'B': [1] * sz})

In [3]: df.info()

RangeIndex: 1000000 entries, 0 to 999999
Data columns (total 2 columns):
A    1000000 non-null float64
B    1000000 non-null int64
dtypes: float64(1), int64(1)
memory usage: 15.3 MB
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame pandas.DataFrame.info
"import numpy as np

import os

sz = 1000000
df = pd.DataFrame({""A"": np.random.randn(sz), ""B"": [1] * sz})

sz = 1000000
np.random.seed(42)
df = pd.DataFrame({""A"": np.random.randn(sz), ""B"": [1] * sz})


def test_sql_write(df):
    if os.path.exists(""test.sql""):
        os.remove(""test.sql"")
    sql_db = sqlite3.connect(""test.sql"")
    df.to_sql(name=""test_table"", con=sql_db)
    sql_db.close()


def test_sql_read():
    sql_db = sqlite3.connect(""test.sql"")
    pd.read_sql_query(""select * from test_table"", sql_db)
    sql_db.close()


def test_hdf_fixed_write(df):
    df.to_hdf(""test_fixed.hdf"", key=""test"", mode=""w"")


def test_hdf_fixed_read():
    pd.read_hdf(""test_fixed.hdf"", ""test"")


def test_hdf_fixed_write_compress(df):
    df.to_hdf(""test_fixed_compress.hdf"", key=""test"", mode=""w"", complib=""blosc"")


def test_hdf_fixed_read_compress():
    pd.read_hdf(""test_fixed_compress.hdf"", ""test"")


def test_hdf_table_write(df):
    df.to_hdf(""test_table.hdf"", key=""test"", mode=""w"", format=""table"")


def test_hdf_table_read():
    pd.read_hdf(""test_table.hdf"", ""test"")


def test_hdf_table_write_compress(df):
    df.to_hdf(
        ""test_table_compress.hdf"", key=""test"", mode=""w"", complib=""blosc"", format=""table""
    )


def test_hdf_table_read_compress():
    pd.read_hdf(""test_table_compress.hdf"", ""test"")


def test_csv_write(df):
    df.to_csv(""test.csv"", mode=""w"")


def test_csv_read():
    pd.read_csv(""test.csv"", index_col=0)


def test_feather_write(df):
    df.to_feather(""test.feather"")


def test_feather_read():
    pd.read_feather(""test.feather"")


def test_pickle_write(df):
    df.to_pickle(""test.pkl"")


def test_pickle_read():
    pd.read_pickle(""test.pkl"")


def test_pickle_write_compress(df):
    df.to_pickle(""test.pkl.compress"", compression=""xz"")


def test_pickle_read_compress():
    pd.read_pickle(""test.pkl.compress"", compression=""xz"")


def test_parquet_write(df):
    df.to_parquet(""test.parquet"")


def test_parquet_read():
    pd.read_parquet(""test.parquet"")
",https://pandas.pydata.org/docs/user_guide/io.html, pandas.DataFrame pandas.DataFrame.to_sql pandas.read_sql_query pandas.DataFrame.to_hdf pandas.read_hdf pandas.DataFrame.to_csv pandas.read_csv pandas.DataFrame.to_feather pandas.read_feather pandas.DataFrame.to_pickle pandas.read_pickle pandas.DataFrame.to_parquet pandas.read_parquet
"In [1]: import datetime

In [2]: dti = pd.to_datetime(
   ...:     [""1/1/2018"", np.datetime64(""2018-01-01""), datetime.datetime(2018, 1, 1)]
   ...: )
   ...: 

In [3]: dti
Out[3]: DatetimeIndex(['2018-01-01', '2018-01-01', '2018-01-01'], dtype='datetime64[ns]', freq=None)
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.to_datetime pandas.DatetimeIndex
"In [4]: dti = pd.date_range(""2018-01-01"", periods=3, freq=""h"")

In [5]: dti
Out[5]: 
DatetimeIndex(['2018-01-01 00:00:00', '2018-01-01 01:00:00',
               '2018-01-01 02:00:00'],
              dtype='datetime64[ns]', freq='h')
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.date_range pandas.DatetimeIndex
"In [6]: dti = dti.tz_localize(""UTC"")

In [7]: dti
Out[7]: 
DatetimeIndex(['2018-01-01 00:00:00+00:00', '2018-01-01 01:00:00+00:00',
               '2018-01-01 02:00:00+00:00'],
              dtype='datetime64[ns, UTC]', freq='h')

In [8]: dti.tz_convert(""US/Pacific"")
Out[8]: 
DatetimeIndex(['2017-12-31 16:00:00-08:00', '2017-12-31 17:00:00-08:00',
               '2017-12-31 18:00:00-08:00'],
              dtype='datetime64[ns, US/Pacific]', freq='h')
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.DatetimeIndex
"In [9]: idx = pd.date_range(""2018-01-01"", periods=5, freq=""h"")

In [10]: ts = pd.Series(range(len(idx)), index=idx)

In [11]: ts
Out[11]: 
2018-01-01 00:00:00    0
2018-01-01 01:00:00    1
2018-01-01 02:00:00    2
2018-01-01 03:00:00    3
2018-01-01 04:00:00    4
Freq: h, dtype: int64

In [12]: ts.resample(""2h"").mean()
Out[12]: 
2018-01-01 00:00:00    0.5
2018-01-01 02:00:00    2.5
2018-01-01 04:00:00    4.0
Freq: 2h, dtype: float64
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.date_range pandas.Series pandas.Series.resample
"In [19]: pd.Series(range(3), index=pd.date_range(""2000"", freq=""D"", periods=3))
Out[19]: 
2000-01-01    0
2000-01-02    1
2000-01-03    2
Freq: D, dtype: int64
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.Series pandas.date_range
"In [20]: pd.Series(pd.date_range(""2000"", freq=""D"", periods=3))
Out[20]: 
0   2000-01-01
1   2000-01-02
2   2000-01-03
dtype: datetime64[ns]
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.Series pandas.date_range
"In [21]: pd.Series(pd.period_range(""1/1/2011"", freq=""M"", periods=3))
Out[21]: 
0    2011-01
1    2011-02
2    2011-03
dtype: period[M]

In [22]: pd.Series([pd.DateOffset(1), pd.DateOffset(2)])
Out[22]: 
0         
1    <2 * DateOffsets>
dtype: object

In [23]: pd.Series(pd.date_range(""1/1/2011"", freq=""ME"", periods=3))
Out[23]: 
0   2011-01-31
1   2011-02-28
2   2011-03-31
dtype: datetime64[ns]
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.Series pandas.period_range pandas.date_range
"In [24]: pd.Timestamp(pd.NaT)
Out[24]: NaT

In [25]: pd.Timedelta(pd.NaT)
Out[25]: NaT

In [26]: pd.Period(pd.NaT)
Out[26]: NaT

# Equality acts as np.nan would
In [27]: pd.NaT == pd.NaT
Out[27]: False
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.Period
"In [32]: pd.Period(""2011-01"")
Out[32]: Period('2011-01', 'M')

In [33]: pd.Period(""2012-05"", freq=""D"")
Out[33]: Period('2012-05-01', 'D')
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.Period pandas.Period
"In [34]: dates = [
   ....:     pd.Timestamp(""2012-05-01""),
   ....:     pd.Timestamp(""2012-05-02""),
   ....:     pd.Timestamp(""2012-05-03""),
   ....: ]
   ....: 

In [35]: ts = pd.Series(np.random.randn(3), dates)

In [36]: type(ts.index)
Out[36]: pandas.core.indexes.datetimes.DatetimeIndex

In [37]: ts.index
Out[37]: DatetimeIndex(['2012-05-01', '2012-05-02', '2012-05-03'], dtype='datetime64[ns]', freq=None)

In [38]: ts
Out[38]: 
2012-05-01    0.469112
2012-05-02   -0.282863
2012-05-03   -1.509059
dtype: float64

In [39]: periods = [pd.Period(""2012-01""), pd.Period(""2012-02""), pd.Period(""2012-03"")]

In [40]: ts = pd.Series(np.random.randn(3), periods)

In [41]: type(ts.index)
Out[41]: pandas.core.indexes.period.PeriodIndex

In [42]: ts.index
Out[42]: PeriodIndex(['2012-01', '2012-02', '2012-03'], dtype='period[M]')

In [43]: ts
Out[43]: 
2012-01   -1.135632
2012-02    1.212112
2012-03   -0.173215
Freq: M, dtype: float64
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.Series pandas.DatetimeIndex pandas.Period pandas.PeriodIndex
"In [44]: pd.to_datetime(pd.Series([""Jul 31, 2009"", ""Jan 10, 2010"", None]))
Out[44]: 
0   2009-07-31
1   2010-01-10
2          NaT
dtype: datetime64[ns]

In [45]: pd.to_datetime([""2005/11/23"", ""2010/12/31""])
Out[45]: DatetimeIndex(['2005-11-23', '2010-12-31'], dtype='datetime64[ns]', freq=None)
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.to_datetime pandas.Series pandas.DatetimeIndex
"In [46]: pd.to_datetime([""04-01-2012 10:00""], dayfirst=True)
Out[46]: DatetimeIndex(['2012-01-04 10:00:00'], dtype='datetime64[ns]', freq=None)

In [47]: pd.to_datetime([""04-14-2012 10:00""], dayfirst=True)
Out[47]: DatetimeIndex(['2012-04-14 10:00:00'], dtype='datetime64[ns]', freq=None)
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.to_datetime pandas.DatetimeIndex
"In [48]: pd.to_datetime(""2010/11/12"")
Out[48]: Timestamp('2010-11-12 00:00:00')

In [49]: pd.Timestamp(""2010/11/12"")
Out[49]: Timestamp('2010-11-12 00:00:00')
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.to_datetime
"In [50]: pd.DatetimeIndex([""2018-01-01"", ""2018-01-03"", ""2018-01-05""])
Out[50]: DatetimeIndex(['2018-01-01', '2018-01-03', '2018-01-05'], dtype='datetime64[ns]', freq=None)
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.DatetimeIndex pandas.DatetimeIndex
"In [51]: pd.DatetimeIndex([""2018-01-01"", ""2018-01-03"", ""2018-01-05""], freq=""infer"")
Out[51]: DatetimeIndex(['2018-01-01', '2018-01-03', '2018-01-05'], dtype='datetime64[ns]', freq='2D')
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.DatetimeIndex pandas.DatetimeIndex
"In [52]: pd.to_datetime(""2010/11/12"", format=""%Y/%m/%d"")
Out[52]: Timestamp('2010-11-12 00:00:00')

In [53]: pd.to_datetime(""12-11-2010 00:00"", format=""%d-%m-%Y %H:%M"")
Out[53]: Timestamp('2010-11-12 00:00:00')
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.to_datetime
"In [54]: df = pd.DataFrame(
   ....:     {""year"": [2015, 2016], ""month"": [2, 3], ""day"": [4, 5], ""hour"": [2, 3]}
   ....: )
   ....: 

In [55]: pd.to_datetime(df)
Out[55]: 
0   2015-02-04 02:00:00
1   2016-03-05 03:00:00
dtype: datetime64[ns]
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.DataFrame pandas.to_datetime
"In [56]: pd.to_datetime(df[[""year"", ""month"", ""day""]])
Out[56]: 
0   2015-02-04
1   2016-03-05
dtype: datetime64[ns]
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.to_datetime
"In [57]: pd.to_datetime(['2009/07/31', 'asd'], errors='raise')
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
Cell In[57], line 1
----> 1 pd.to_datetime(['2009/07/31', 'asd'], errors='raise')

File ~/work/pandas/pandas/pandas/core/tools/datetimes.py:1099, in to_datetime(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)
   1097         result = _convert_and_box_cache(argc, cache_array)
   1098     else:
-> 1099         result = convert_listlike(argc, format)
   1100 else:
   1101     result = convert_listlike(np.array([arg]), format)[0]

File ~/work/pandas/pandas/pandas/core/tools/datetimes.py:433, in _convert_listlike_datetimes(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)
    431 # `format` could be inferred, or user didn't ask for mixed-format parsing.
    432 if format is not None and format != ""mixed"":
--> 433     return _array_strptime_with_fallback(arg, name, utc, format, exact, errors)
    435 result, tz_parsed = objects_to_datetime64(
    436     arg,
    437     dayfirst=dayfirst,
   (...)
    441     allow_object=True,
    442 )
    444 if tz_parsed is not None:
    445     # We can take a shortcut since the datetime64 numpy array
    446     # is in UTC

File ~/work/pandas/pandas/pandas/core/tools/datetimes.py:467, in _array_strptime_with_fallback(arg, name, utc, fmt, exact, errors)
    456 def _array_strptime_with_fallback(
    457     arg,
    458     name,
   (...)
    462     errors: str,
    463 ) -> Index:
    464     """"""
    465     Call array_strptime, with fallback behavior depending on 'errors'.
    466     """"""
--> 467     result, tz_out = array_strptime(arg, fmt, exact=exact, errors=errors, utc=utc)
    468     if tz_out is not None:
    469         unit = np.datetime_data(result.dtype)[0]

File strptime.pyx:501, in pandas._libs.tslibs.strptime.array_strptime()

File strptime.pyx:451, in pandas._libs.tslibs.strptime.array_strptime()

File strptime.pyx:583, in pandas._libs.tslibs.strptime._parse_with_format()

ValueError: time data ""asd"" doesn't match format ""%Y/%m/%d"", at position 1. You might want to try:
    - passing `format` if your strings have a consistent format;
    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;
    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.to_datetime pandas.to_datetime
"In [58]: pd.to_datetime([""2009/07/31"", ""asd""], errors=""coerce"")
Out[58]: DatetimeIndex(['2009-07-31', 'NaT'], dtype='datetime64[ns]', freq=None)
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.to_datetime pandas.DatetimeIndex
"In [59]: pd.to_datetime(
   ....:     [1349720105, 1349806505, 1349892905, 1349979305, 1350065705], unit=""s""
   ....: )
   ....: 
Out[59]: 
DatetimeIndex(['2012-10-08 18:15:05', '2012-10-09 18:15:05',
               '2012-10-10 18:15:05', '2012-10-11 18:15:05',
               '2012-10-12 18:15:05'],
              dtype='datetime64[ns]', freq=None)

In [60]: pd.to_datetime(
   ....:     [1349720105100, 1349720105200, 1349720105300, 1349720105400, 1349720105500],
   ....:     unit=""ms"",
   ....: )
   ....: 
Out[60]: 
DatetimeIndex(['2012-10-08 18:15:05.100000', '2012-10-08 18:15:05.200000',
               '2012-10-08 18:15:05.300000', '2012-10-08 18:15:05.400000',
               '2012-10-08 18:15:05.500000'],
              dtype='datetime64[ns]', freq=None)
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.to_datetime pandas.DatetimeIndex
"In [61]: pd.Timestamp(1262347200000000000).tz_localize(""US/Pacific"")
Out[61]: Timestamp('2010-01-01 12:00:00-0800', tz='US/Pacific')

In [62]: pd.DatetimeIndex([1262347200000000000]).tz_localize(""US/Pacific"")
Out[62]: DatetimeIndex(['2010-01-01 12:00:00-08:00'], dtype='datetime64[ns, US/Pacific]', freq=None)
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.DatetimeIndex pandas.DatetimeIndex
"In [63]: pd.to_datetime([1490195805.433, 1490195805.433502912], unit=""s"")
Out[63]: DatetimeIndex(['2017-03-22 15:16:45.433000088', '2017-03-22 15:16:45.433502913'], dtype='datetime64[ns]', freq=None)

In [64]: pd.to_datetime(1490195805433502912, unit=""ns"")
Out[64]: Timestamp('2017-03-22 15:16:45.433502912')
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.to_datetime pandas.DatetimeIndex
"In [65]: stamps = pd.date_range(""2012-10-08 18:15:05"", periods=4, freq=""D"")

In [66]: stamps
Out[66]: 
DatetimeIndex(['2012-10-08 18:15:05', '2012-10-09 18:15:05',
               '2012-10-10 18:15:05', '2012-10-11 18:15:05'],
              dtype='datetime64[ns]', freq='D')
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.date_range pandas.DatetimeIndex
"In [67]: (stamps - pd.Timestamp(""1970-01-01"")) // pd.Timedelta(""1s"")
Out[67]: Index([1349720105, 1349806505, 1349892905, 1349979305], dtype='int64')
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.Index
"In [68]: pd.to_datetime([1, 2, 3], unit=""D"", origin=pd.Timestamp(""1960-01-01""))
Out[68]: DatetimeIndex(['1960-01-02', '1960-01-03', '1960-01-04'], dtype='datetime64[ns]', freq=None)
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.to_datetime pandas.DatetimeIndex
"In [69]: pd.to_datetime([1, 2, 3], unit=""D"")
Out[69]: DatetimeIndex(['1970-01-02', '1970-01-03', '1970-01-04'], dtype='datetime64[ns]', freq=None)
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.to_datetime pandas.DatetimeIndex
"In [70]: dates = [
   ....:     datetime.datetime(2012, 5, 1),
   ....:     datetime.datetime(2012, 5, 2),
   ....:     datetime.datetime(2012, 5, 3),
   ....: ]
   ....: 

# Note the frequency information
In [71]: index = pd.DatetimeIndex(dates)

In [72]: index
Out[72]: DatetimeIndex(['2012-05-01', '2012-05-02', '2012-05-03'], dtype='datetime64[ns]', freq=None)

# Automatically converted to DatetimeIndex
In [73]: index = pd.Index(dates)

In [74]: index
Out[74]: DatetimeIndex(['2012-05-01', '2012-05-02', '2012-05-03'], dtype='datetime64[ns]', freq=None)
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.DatetimeIndex pandas.DatetimeIndex pandas.Index
"In [75]: start = datetime.datetime(2011, 1, 1)

In [76]: end = datetime.datetime(2012, 1, 1)

In [77]: index = pd.date_range(start, end)

In [78]: index
Out[78]: 
DatetimeIndex(['2011-01-01', '2011-01-02', '2011-01-03', '2011-01-04',
               '2011-01-05', '2011-01-06', '2011-01-07', '2011-01-08',
               '2011-01-09', '2011-01-10',
               ...
               '2011-12-23', '2011-12-24', '2011-12-25', '2011-12-26',
               '2011-12-27', '2011-12-28', '2011-12-29', '2011-12-30',
               '2011-12-31', '2012-01-01'],
              dtype='datetime64[ns]', length=366, freq='D')

In [79]: index = pd.bdate_range(start, end)

In [80]: index
Out[80]: 
DatetimeIndex(['2011-01-03', '2011-01-04', '2011-01-05', '2011-01-06',
               '2011-01-07', '2011-01-10', '2011-01-11', '2011-01-12',
               '2011-01-13', '2011-01-14',
               ...
               '2011-12-19', '2011-12-20', '2011-12-21', '2011-12-22',
               '2011-12-23', '2011-12-26', '2011-12-27', '2011-12-28',
               '2011-12-29', '2011-12-30'],
              dtype='datetime64[ns]', length=260, freq='B')
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.date_range pandas.DatetimeIndex pandas.bdate_range
"In [81]: pd.date_range(start, periods=1000, freq=""ME"")
Out[81]: 
DatetimeIndex(['2011-01-31', '2011-02-28', '2011-03-31', '2011-04-30',
               '2011-05-31', '2011-06-30', '2011-07-31', '2011-08-31',
               '2011-09-30', '2011-10-31',
               ...
               '2093-07-31', '2093-08-31', '2093-09-30', '2093-10-31',
               '2093-11-30', '2093-12-31', '2094-01-31', '2094-02-28',
               '2094-03-31', '2094-04-30'],
              dtype='datetime64[ns]', length=1000, freq='ME')

In [82]: pd.bdate_range(start, periods=250, freq=""BQS"")
Out[82]: 
DatetimeIndex(['2011-01-03', '2011-04-01', '2011-07-01', '2011-10-03',
               '2012-01-02', '2012-04-02', '2012-07-02', '2012-10-01',
               '2013-01-01', '2013-04-01',
               ...
               '2071-01-01', '2071-04-01', '2071-07-01', '2071-10-01',
               '2072-01-01', '2072-04-01', '2072-07-01', '2072-10-03',
               '2073-01-02', '2073-04-03'],
              dtype='datetime64[ns]', length=250, freq='BQS-JAN')
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.date_range pandas.DatetimeIndex pandas.bdate_range
"In [83]: pd.date_range(start, end, freq=""BME"")
Out[83]: 
DatetimeIndex(['2011-01-31', '2011-02-28', '2011-03-31', '2011-04-29',
               '2011-05-31', '2011-06-30', '2011-07-29', '2011-08-31',
               '2011-09-30', '2011-10-31', '2011-11-30', '2011-12-30'],
              dtype='datetime64[ns]', freq='BME')

In [84]: pd.date_range(start, end, freq=""W"")
Out[84]: 
DatetimeIndex(['2011-01-02', '2011-01-09', '2011-01-16', '2011-01-23',
               '2011-01-30', '2011-02-06', '2011-02-13', '2011-02-20',
               '2011-02-27', '2011-03-06', '2011-03-13', '2011-03-20',
               '2011-03-27', '2011-04-03', '2011-04-10', '2011-04-17',
               '2011-04-24', '2011-05-01', '2011-05-08', '2011-05-15',
               '2011-05-22', '2011-05-29', '2011-06-05', '2011-06-12',
               '2011-06-19', '2011-06-26', '2011-07-03', '2011-07-10',
               '2011-07-17', '2011-07-24', '2011-07-31', '2011-08-07',
               '2011-08-14', '2011-08-21', '2011-08-28', '2011-09-04',
               '2011-09-11', '2011-09-18', '2011-09-25', '2011-10-02',
               '2011-10-09', '2011-10-16', '2011-10-23', '2011-10-30',
               '2011-11-06', '2011-11-13', '2011-11-20', '2011-11-27',
               '2011-12-04', '2011-12-11', '2011-12-18', '2011-12-25',
               '2012-01-01'],
              dtype='datetime64[ns]', freq='W-SUN')

In [85]: pd.bdate_range(end=end, periods=20)
Out[85]: 
DatetimeIndex(['2011-12-05', '2011-12-06', '2011-12-07', '2011-12-08',
               '2011-12-09', '2011-12-12', '2011-12-13', '2011-12-14',
               '2011-12-15', '2011-12-16', '2011-12-19', '2011-12-20',
               '2011-12-21', '2011-12-22', '2011-12-23', '2011-12-26',
               '2011-12-27', '2011-12-28', '2011-12-29', '2011-12-30'],
              dtype='datetime64[ns]', freq='B')

In [86]: pd.bdate_range(start=start, periods=20)
Out[86]: 
DatetimeIndex(['2011-01-03', '2011-01-04', '2011-01-05', '2011-01-06',
               '2011-01-07', '2011-01-10', '2011-01-11', '2011-01-12',
               '2011-01-13', '2011-01-14', '2011-01-17', '2011-01-18',
               '2011-01-19', '2011-01-20', '2011-01-21', '2011-01-24',
               '2011-01-25', '2011-01-26', '2011-01-27', '2011-01-28'],
              dtype='datetime64[ns]', freq='B')
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.date_range pandas.DatetimeIndex pandas.bdate_range
"In [87]: pd.date_range(""2018-01-01"", ""2018-01-05"", periods=5)
Out[87]: 
DatetimeIndex(['2018-01-01', '2018-01-02', '2018-01-03', '2018-01-04',
               '2018-01-05'],
              dtype='datetime64[ns]', freq=None)

In [88]: pd.date_range(""2018-01-01"", ""2018-01-05"", periods=10)
Out[88]: 
DatetimeIndex(['2018-01-01 00:00:00', '2018-01-01 10:40:00',
               '2018-01-01 21:20:00', '2018-01-02 08:00:00',
               '2018-01-02 18:40:00', '2018-01-03 05:20:00',
               '2018-01-03 16:00:00', '2018-01-04 02:40:00',
               '2018-01-04 13:20:00', '2018-01-05 00:00:00'],
              dtype='datetime64[ns]', freq=None)
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.date_range pandas.DatetimeIndex
"In [89]: weekmask = ""Mon Wed Fri""

In [90]: holidays = [datetime.datetime(2011, 1, 5), datetime.datetime(2011, 3, 14)]

In [91]: pd.bdate_range(start, end, freq=""C"", weekmask=weekmask, holidays=holidays)
Out[91]: 
DatetimeIndex(['2011-01-03', '2011-01-07', '2011-01-10', '2011-01-12',
               '2011-01-14', '2011-01-17', '2011-01-19', '2011-01-21',
               '2011-01-24', '2011-01-26',
               ...
               '2011-12-09', '2011-12-12', '2011-12-14', '2011-12-16',
               '2011-12-19', '2011-12-21', '2011-12-23', '2011-12-26',
               '2011-12-28', '2011-12-30'],
              dtype='datetime64[ns]', length=154, freq='C')

In [92]: pd.bdate_range(start, end, freq=""CBMS"", weekmask=weekmask)
Out[92]: 
DatetimeIndex(['2011-01-03', '2011-02-02', '2011-03-02', '2011-04-01',
               '2011-05-02', '2011-06-01', '2011-07-01', '2011-08-01',
               '2011-09-02', '2011-10-03', '2011-11-02', '2011-12-02'],
              dtype='datetime64[ns]', freq='CBMS')
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.bdate_range pandas.DatetimeIndex
"In [95]: rng = pd.date_range(start, end, freq=""BME"")

In [96]: ts = pd.Series(np.random.randn(len(rng)), index=rng)

In [97]: ts.index
Out[97]: 
DatetimeIndex(['2011-01-31', '2011-02-28', '2011-03-31', '2011-04-29',
               '2011-05-31', '2011-06-30', '2011-07-29', '2011-08-31',
               '2011-09-30', '2011-10-31', '2011-11-30', '2011-12-30'],
              dtype='datetime64[ns]', freq='BME')

In [98]: ts[:5].index
Out[98]: 
DatetimeIndex(['2011-01-31', '2011-02-28', '2011-03-31', '2011-04-29',
               '2011-05-31'],
              dtype='datetime64[ns]', freq='BME')

In [99]: ts[::2].index
Out[99]: 
DatetimeIndex(['2011-01-31', '2011-03-31', '2011-05-31', '2011-07-29',
               '2011-09-30', '2011-11-30'],
              dtype='datetime64[ns]', freq='2BME')
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.date_range pandas.Series pandas.DatetimeIndex
"In [105]: dft = pd.DataFrame(
   .....:     np.random.randn(100000, 1),
   .....:     columns=[""A""],
   .....:     index=pd.date_range(""20130101"", periods=100000, freq=""min""),
   .....: )
   .....: 

In [106]: dft
Out[106]: 
                            A
2013-01-01 00:00:00  0.276232
2013-01-01 00:01:00 -1.087401
2013-01-01 00:02:00 -0.673690
2013-01-01 00:03:00  0.113648
2013-01-01 00:04:00 -1.478427
...                       ...
2013-03-11 10:35:00 -0.747967
2013-03-11 10:36:00 -0.034523
2013-03-11 10:37:00 -0.201754
2013-03-11 10:38:00 -1.509067
2013-03-11 10:39:00 -1.693043

[100000 rows x 1 columns]

In [107]: dft.loc[""2013""]
Out[107]: 
                            A
2013-01-01 00:00:00  0.276232
2013-01-01 00:01:00 -1.087401
2013-01-01 00:02:00 -0.673690
2013-01-01 00:03:00  0.113648
2013-01-01 00:04:00 -1.478427
...                       ...
2013-03-11 10:35:00 -0.747967
2013-03-11 10:36:00 -0.034523
2013-03-11 10:37:00 -0.201754
2013-03-11 10:38:00 -1.509067
2013-03-11 10:39:00 -1.693043

[100000 rows x 1 columns]
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.DataFrame pandas.date_range
"In [112]: dft2 = pd.DataFrame(
   .....:     np.random.randn(20, 1),
   .....:     columns=[""A""],
   .....:     index=pd.MultiIndex.from_product(
   .....:         [pd.date_range(""20130101"", periods=10, freq=""12h""), [""a"", ""b""]]
   .....:     ),
   .....: )
   .....: 

In [113]: dft2
Out[113]: 
                              A
2013-01-01 00:00:00 a -0.298694
                    b  0.823553
2013-01-01 12:00:00 a  0.943285
                    b -1.479399
2013-01-02 00:00:00 a -1.643342
...                         ...
2013-01-04 12:00:00 b  0.069036
2013-01-05 00:00:00 a  0.122297
                    b  1.422060
2013-01-05 12:00:00 a  0.370079
                    b  1.016331

[20 rows x 1 columns]

In [114]: dft2.loc[""2013-01-05""]
Out[114]: 
                              A
2013-01-05 00:00:00 a  0.122297
                    b  1.422060
2013-01-05 12:00:00 a  0.370079
                    b  1.016331

In [115]: idx = pd.IndexSlice

In [116]: dft2 = dft2.swaplevel(0, 1).sort_index()

In [117]: dft2.loc[idx[:, ""2013-01-05""], :]
Out[117]: 
                              A
a 2013-01-05 00:00:00  0.122297
  2013-01-05 12:00:00  0.370079
b 2013-01-05 00:00:00  1.422060
  2013-01-05 12:00:00  1.016331
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.DataFrame pandas.MultiIndex.from_product pandas.date_range pandas.DataFrame.swaplevel
"In [118]: df = pd.DataFrame([0], index=pd.DatetimeIndex([""2019-01-01""], tz=""US/Pacific""))

In [119]: df
Out[119]: 
                           0
2019-01-01 00:00:00-08:00  0

In [120]: df[""2019-01-01 12:00:00+04:00"":""2019-01-01 13:00:00+04:00""]
Out[120]: 
                           0
2019-01-01 00:00:00-08:00  0
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.DataFrame pandas.DatetimeIndex
"In [121]: series_minute = pd.Series(
   .....:     [1, 2, 3],
   .....:     pd.DatetimeIndex(
   .....:         [""2011-12-31 23:59:00"", ""2012-01-01 00:00:00"", ""2012-01-01 00:02:00""]
   .....:     ),
   .....: )
   .....: 

In [122]: series_minute.index.resolution
Out[122]: 'minute'
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.Series pandas.DatetimeIndex
"In [126]: series_second = pd.Series(
   .....:     [1, 2, 3],
   .....:     pd.DatetimeIndex(
   .....:         [""2011-12-31 23:59:59"", ""2012-01-01 00:00:00"", ""2012-01-01 00:00:01""]
   .....:     ),
   .....: )
   .....: 

In [127]: series_second.index.resolution
Out[127]: 'second'

In [128]: series_second[""2011-12-31 23:59""]
Out[128]: 
2011-12-31 23:59:59    1
dtype: int64
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.Series pandas.DatetimeIndex
"In [129]: dft_minute = pd.DataFrame(
   .....:     {""a"": [1, 2, 3], ""b"": [4, 5, 6]}, index=series_minute.index
   .....: )
   .....: 

In [130]: dft_minute.loc[""2011-12-31 23""]
Out[130]: 
                     a  b
2011-12-31 23:59:00  1  4
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.DataFrame
"In [132]: series_monthly = pd.Series(
   .....:     [1, 2, 3], pd.DatetimeIndex([""2011-12"", ""2012-01"", ""2012-02""])
   .....: )
   .....: 

In [133]: series_monthly.index.resolution
Out[133]: 'day'

In [134]: series_monthly[""2011-12""]  # returns Series
Out[134]: 
2011-12-01    1
dtype: int64
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.Series pandas.DatetimeIndex
"In [137]: rng2 = pd.date_range(""2011-01-01"", ""2012-01-01"", freq=""W"")

In [138]: ts2 = pd.Series(np.random.randn(len(rng2)), index=rng2)

In [139]: ts2.truncate(before=""2011-11"", after=""2011-12"")
Out[139]: 
2011-11-06    0.437823
2011-11-13   -0.293083
2011-11-20   -0.059881
2011-11-27    1.252450
Freq: W-SUN, dtype: float64

In [140]: ts2[""2011-11"":""2011-12""]
Out[140]: 
2011-11-06    0.437823
2011-11-13   -0.293083
2011-11-20   -0.059881
2011-11-27    1.252450
2011-12-04    0.046611
2011-12-11    0.059478
2011-12-18   -0.286539
2011-12-25    0.841669
Freq: W-SUN, dtype: float64
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.date_range pandas.Series pandas.Series.truncate
"In [141]: ts2.iloc[[0, 2, 6]].index
Out[141]: DatetimeIndex(['2011-01-02', '2011-01-16', '2011-02-13'], dtype='datetime64[ns]', freq=None)
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.DatetimeIndex
"In [142]: idx = pd.date_range(start=""2019-12-29"", freq=""D"", periods=4)

In [143]: idx.isocalendar()
Out[143]: 
            year  week  day
2019-12-29  2019    52    7
2019-12-30  2020     1    1
2019-12-31  2020     1    2
2020-01-01  2020     1    3

In [144]: idx.to_series().dt.isocalendar()
Out[144]: 
            year  week  day
2019-12-29  2019    52    7
2019-12-30  2020     1    1
2019-12-31  2020     1    2
2020-01-01  2020     1    3
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.date_range
"In [167]: d = datetime.datetime(2008, 8, 18, 9, 0)

In [168]: d
Out[168]: datetime.datetime(2008, 8, 18, 9, 0)

In [169]: d + pd.offsets.Week()
Out[169]: Timestamp('2008-08-25 09:00:00')

In [170]: d + pd.offsets.Week(weekday=4)
Out[170]: Timestamp('2008-08-22 09:00:00')

In [171]: (d + pd.offsets.Week(weekday=4)).weekday()
Out[171]: 4

In [172]: d - pd.offsets.Week()
Out[172]: Timestamp('2008-08-11 09:00:00')
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.Timestamp.weekday
"In [177]: rng = pd.date_range(""2012-01-01"", ""2012-01-03"")

In [178]: s = pd.Series(rng)

In [179]: rng
Out[179]: DatetimeIndex(['2012-01-01', '2012-01-02', '2012-01-03'], dtype='datetime64[ns]', freq='D')

In [180]: rng + pd.DateOffset(months=2)
Out[180]: DatetimeIndex(['2012-03-01', '2012-03-02', '2012-03-03'], dtype='datetime64[ns]', freq=None)

In [181]: s + pd.DateOffset(months=2)
Out[181]: 
0   2012-03-01
1   2012-03-02
2   2012-03-03
dtype: datetime64[ns]

In [182]: s - pd.DateOffset(months=2)
Out[182]: 
0   2011-11-01
1   2011-11-02
2   2011-11-03
dtype: datetime64[ns]
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.date_range pandas.Series pandas.DatetimeIndex
"In [183]: s - pd.offsets.Day(2)
Out[183]: 
0   2011-12-30
1   2011-12-31
2   2012-01-01
dtype: datetime64[ns]

In [184]: td = s - pd.Series(pd.date_range(""2011-12-29"", ""2011-12-31""))

In [185]: td
Out[185]: 
0   3 days
1   3 days
2   3 days
dtype: timedelta64[ns]

In [186]: td + pd.offsets.Minute(15)
Out[186]: 
0   3 days 00:15:00
1   3 days 00:15:00
2   3 days 00:15:00
dtype: timedelta64[ns]
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.Series pandas.date_range
"In [187]: rng + pd.offsets.BQuarterEnd()
Out[187]: DatetimeIndex(['2012-03-30', '2012-03-30', '2012-03-30'], dtype='datetime64[ns]', freq=None)
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.DatetimeIndex
"In [193]: dts = pd.date_range(dt, periods=5, freq=bday_egypt)

In [194]: pd.Series(dts.weekday, dts).map(pd.Series(""Mon Tue Wed Thu Fri Sat Sun"".split()))
Out[194]: 
2013-04-30    Tue
2013-05-02    Thu
2013-05-05    Sun
2013-05-06    Mon
2013-05-07    Tue
Freq: C, dtype: object
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.date_range pandas.Series pandas.Series.str.split
"In [199]: bmth_us = pd.offsets.CustomBusinessMonthBegin(calendar=USFederalHolidayCalendar())

# Skip new years
In [200]: dt = datetime.datetime(2013, 12, 17)

In [201]: dt + bmth_us
Out[201]: Timestamp('2014-01-02 00:00:00')

# Define date index with custom offset
In [202]: pd.date_range(start=""20100101"", end=""20120101"", freq=bmth_us)
Out[202]: 
DatetimeIndex(['2010-01-04', '2010-02-01', '2010-03-01', '2010-04-01',
               '2010-05-03', '2010-06-01', '2010-07-01', '2010-08-02',
               '2010-09-01', '2010-10-01', '2010-11-01', '2010-12-01',
               '2011-01-03', '2011-02-01', '2011-03-01', '2011-04-01',
               '2011-05-02', '2011-06-01', '2011-07-01', '2011-08-01',
               '2011-09-01', '2011-10-03', '2011-11-01', '2011-12-01'],
              dtype='datetime64[ns]', freq='CBMS')
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.date_range pandas.DatetimeIndex
"In [203]: bh = pd.offsets.BusinessHour()

In [204]: bh
Out[204]: 

# 2014-08-01 is Friday
In [205]: pd.Timestamp(""2014-08-01 10:00"").weekday()
Out[205]: 4

In [206]: pd.Timestamp(""2014-08-01 10:00"") + bh
Out[206]: Timestamp('2014-08-01 11:00:00')

# Below example is the same as: pd.Timestamp('2014-08-01 09:00') + bh
In [207]: pd.Timestamp(""2014-08-01 08:00"") + bh
Out[207]: Timestamp('2014-08-01 10:00:00')

# If the results is on the end time, move to the next business day
In [208]: pd.Timestamp(""2014-08-01 16:00"") + bh
Out[208]: Timestamp('2014-08-04 09:00:00')

# Remainings are added to the next day
In [209]: pd.Timestamp(""2014-08-01 16:30"") + bh
Out[209]: Timestamp('2014-08-04 09:30:00')

# Adding 2 business hours
In [210]: pd.Timestamp(""2014-08-01 10:00"") + pd.offsets.BusinessHour(2)
Out[210]: Timestamp('2014-08-01 12:00:00')

# Subtracting 3 business hours
In [211]: pd.Timestamp(""2014-08-01 10:00"") + pd.offsets.BusinessHour(-3)
Out[211]: Timestamp('2014-07-31 15:00:00')
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.Timestamp.weekday
"In [212]: bh = pd.offsets.BusinessHour(start=""11:00"", end=datetime.time(20, 0))

In [213]: bh
Out[213]: 

In [214]: pd.Timestamp(""2014-08-01 13:00"") + bh
Out[214]: Timestamp('2014-08-01 14:00:00')

In [215]: pd.Timestamp(""2014-08-01 09:00"") + bh
Out[215]: Timestamp('2014-08-01 12:00:00')

In [216]: pd.Timestamp(""2014-08-01 18:00"") + bh
Out[216]: Timestamp('2014-08-01 19:00:00')
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.Timestamp.time
"# This adjusts a Timestamp to business hour edge
In [223]: pd.offsets.BusinessHour().rollback(pd.Timestamp(""2014-08-02 15:00""))
Out[223]: Timestamp('2014-08-01 17:00:00')

In [224]: pd.offsets.BusinessHour().rollforward(pd.Timestamp(""2014-08-02 15:00""))
Out[224]: Timestamp('2014-08-04 09:00:00')

# It is the same as BusinessHour() + pd.Timestamp('2014-08-01 17:00').
# And it is the same as BusinessHour() + pd.Timestamp('2014-08-04 09:00')
In [225]: pd.offsets.BusinessHour() + pd.Timestamp(""2014-08-02 15:00"")
Out[225]: Timestamp('2014-08-04 10:00:00')

# BusinessDay results (for reference)
In [226]: pd.offsets.BusinessHour().rollforward(pd.Timestamp(""2014-08-02""))
Out[226]: Timestamp('2014-08-04 09:00:00')

# It is the same as BusinessDay() + pd.Timestamp('2014-08-01')
# The result is the same as rollworward because BusinessDay never overlap.
In [227]: pd.offsets.BusinessHour() + pd.Timestamp(""2014-08-02"")
Out[227]: Timestamp('2014-08-04 10:00:00')
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.tseries.offsets.BusinessHour pandas.tseries.offsets.BusinessDay
"In [235]: dates_lst_1 = pd.date_range(""2020-01-06"", ""2020-04-03"", freq=""MS"")

In [236]: dates_lst_1
Out[236]: DatetimeIndex(['2020-02-01', '2020-03-01', '2020-04-01'], dtype='datetime64[ns]', freq='MS')

In [237]: dates_lst_2 = pd.date_range(""2020-01-01"", ""2020-04-01"", freq=""MS"")

In [238]: dates_lst_2
Out[238]: DatetimeIndex(['2020-01-01', '2020-02-01', '2020-03-01', '2020-04-01'], dtype='datetime64[ns]', freq='MS')
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.date_range pandas.DatetimeIndex
"In [239]: pd.date_range(start, periods=5, freq=""B"")
Out[239]: 
DatetimeIndex(['2011-01-03', '2011-01-04', '2011-01-05', '2011-01-06',
               '2011-01-07'],
              dtype='datetime64[ns]', freq='B')

In [240]: pd.date_range(start, periods=5, freq=pd.offsets.BDay())
Out[240]: 
DatetimeIndex(['2011-01-03', '2011-01-04', '2011-01-05', '2011-01-06',
               '2011-01-07'],
              dtype='datetime64[ns]', freq='B')
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.date_range pandas.DatetimeIndex
"In [241]: pd.date_range(start, periods=10, freq=""2h20min"")
Out[241]: 
DatetimeIndex(['2011-01-01 00:00:00', '2011-01-01 02:20:00',
               '2011-01-01 04:40:00', '2011-01-01 07:00:00',
               '2011-01-01 09:20:00', '2011-01-01 11:40:00',
               '2011-01-01 14:00:00', '2011-01-01 16:20:00',
               '2011-01-01 18:40:00', '2011-01-01 21:00:00'],
              dtype='datetime64[ns]', freq='140min')

In [242]: pd.date_range(start, periods=10, freq=""1D10us"")
Out[242]: 
DatetimeIndex([       '2011-01-01 00:00:00', '2011-01-02 00:00:00.000010',
               '2011-01-03 00:00:00.000020', '2011-01-04 00:00:00.000030',
               '2011-01-05 00:00:00.000040', '2011-01-06 00:00:00.000050',
               '2011-01-07 00:00:00.000060', '2011-01-08 00:00:00.000070',
               '2011-01-09 00:00:00.000080', '2011-01-10 00:00:00.000090'],
              dtype='datetime64[ns]', freq='86400000010us')
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.date_range pandas.DatetimeIndex
"In [259]: from pandas.tseries.holiday import (
   .....:     Holiday,
   .....:     USMemorialDay,
   .....:     AbstractHolidayCalendar,
   .....:     nearest_workday,
   .....:     MO,
   .....: )
   .....: 

In [260]: class ExampleCalendar(AbstractHolidayCalendar):
   .....:     rules = [
   .....:         USMemorialDay,
   .....:         Holiday(""July 4th"", month=7, day=4, observance=nearest_workday),
   .....:         Holiday(
   .....:             ""Columbus Day"",
   .....:             month=10,
   .....:             day=1,
   .....:             offset=pd.DateOffset(weekday=MO(2)),
   .....:         ),
   .....:     ]
   .....: 

In [261]: cal = ExampleCalendar()

In [262]: cal.holidays(datetime.datetime(2012, 1, 1), datetime.datetime(2012, 12, 31))
Out[262]: DatetimeIndex(['2012-05-28', '2012-07-04', '2012-10-08'], dtype='datetime64[ns]', freq=None)
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.DatetimeIndex
"In [263]: pd.date_range(
   .....:     start=""7/1/2012"", end=""7/10/2012"", freq=pd.offsets.CDay(calendar=cal)
   .....: ).to_pydatetime()
   .....: 
Out[263]: 
array([datetime.datetime(2012, 7, 2, 0, 0),
       datetime.datetime(2012, 7, 3, 0, 0),
       datetime.datetime(2012, 7, 5, 0, 0),
       datetime.datetime(2012, 7, 6, 0, 0),
       datetime.datetime(2012, 7, 9, 0, 0),
       datetime.datetime(2012, 7, 10, 0, 0)], dtype=object)

In [264]: offset = pd.offsets.CustomBusinessDay(calendar=cal)

In [265]: datetime.datetime(2012, 5, 25) + offset
Out[265]: Timestamp('2012-05-29 00:00:00')

In [266]: datetime.datetime(2012, 7, 3) + offset
Out[266]: Timestamp('2012-07-05 00:00:00')

In [267]: datetime.datetime(2012, 7, 3) + 2 * offset
Out[267]: Timestamp('2012-07-06 00:00:00')

In [268]: datetime.datetime(2012, 7, 6) + offset
Out[268]: Timestamp('2012-07-09 00:00:00')
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.date_range pandas.array
"In [271]: AbstractHolidayCalendar.start_date = datetime.datetime(2012, 1, 1)

In [272]: AbstractHolidayCalendar.end_date = datetime.datetime(2012, 12, 31)

In [273]: cal.holidays()
Out[273]: DatetimeIndex(['2012-05-28', '2012-07-04', '2012-10-08'], dtype='datetime64[ns]', freq=None)
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.DatetimeIndex
"In [279]: ts = pd.Series(range(len(rng)), index=rng)

In [280]: ts = ts[:5]

In [281]: ts.shift(1)
Out[281]: 
2012-01-01    NaN
2012-01-02    0.0
2012-01-03    1.0
Freq: D, dtype: float64
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.Series pandas.Series.shift
"In [282]: ts.shift(5, freq=""D"")
Out[282]: 
2012-01-06    0
2012-01-07    1
2012-01-08    2
Freq: D, dtype: int64

In [283]: ts.shift(5, freq=pd.offsets.BDay())
Out[283]: 
2012-01-06    0
2012-01-09    1
2012-01-10    2
dtype: int64

In [284]: ts.shift(5, freq=""BME"")
Out[284]: 
2012-05-31    0
2012-05-31    1
2012-05-31    2
dtype: int64
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.Series.shift
"In [285]: dr = pd.date_range(""1/1/2010"", periods=3, freq=3 * pd.offsets.BDay())

In [286]: ts = pd.Series(np.random.randn(3), index=dr)

In [287]: ts
Out[287]: 
2010-01-01    1.494522
2010-01-06   -0.778425
2010-01-11   -0.253355
Freq: 3B, dtype: float64

In [288]: ts.asfreq(pd.offsets.BDay())
Out[288]: 
2010-01-01    1.494522
2010-01-04         NaN
2010-01-05         NaN
2010-01-06   -0.778425
2010-01-07         NaN
2010-01-08         NaN
2010-01-11   -0.253355
Freq: B, dtype: float64
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.date_range pandas.Series pandas.Series.asfreq
"In [289]: ts.asfreq(pd.offsets.BDay(), method=""pad"")
Out[289]: 
2010-01-01    1.494522
2010-01-04    1.494522
2010-01-05    1.494522
2010-01-06   -0.778425
2010-01-07   -0.778425
2010-01-08   -0.778425
2010-01-11   -0.253355
Freq: B, dtype: float64
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.Series.asfreq
"In [290]: rng = pd.date_range(""1/1/2012"", periods=100, freq=""s"")

In [291]: ts = pd.Series(np.random.randint(0, 500, len(rng)), index=rng)

In [292]: ts.resample(""5Min"").sum()
Out[292]: 
2012-01-01    25103
Freq: 5min, dtype: int64
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.date_range pandas.Series pandas.Series.resample
"In [293]: ts.resample(""5Min"").mean()
Out[293]: 
2012-01-01    251.03
Freq: 5min, dtype: float64

In [294]: ts.resample(""5Min"").ohlc()
Out[294]: 
            open  high  low  close
2012-01-01   308   460    9    205

In [295]: ts.resample(""5Min"").max()
Out[295]: 
2012-01-01    460
Freq: 5min, dtype: int64
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.Series.resample
"In [296]: ts.resample(""5Min"", closed=""right"").mean()
Out[296]: 
2011-12-31 23:55:00    308.000000
2012-01-01 00:00:00    250.454545
Freq: 5min, dtype: float64

In [297]: ts.resample(""5Min"", closed=""left"").mean()
Out[297]: 
2012-01-01    251.03
Freq: 5min, dtype: float64
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.Series.resample
"In [298]: ts.resample(""5Min"").mean()  # by default label='left'
Out[298]: 
2012-01-01    251.03
Freq: 5min, dtype: float64

In [299]: ts.resample(""5Min"", label=""left"").mean()
Out[299]: 
2012-01-01    251.03
Freq: 5min, dtype: float64
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.Series.resample
"In [300]: s = pd.date_range(""2000-01-01"", ""2000-01-05"").to_series()

In [301]: s.iloc[2] = pd.NaT

In [302]: s.dt.day_name()
Out[302]: 
2000-01-01     Saturday
2000-01-02       Sunday
2000-01-03          NaN
2000-01-04      Tuesday
2000-01-05    Wednesday
Freq: D, dtype: object

# default: label='left', closed='left'
In [303]: s.resample(""B"").last().dt.day_name()
Out[303]: 
1999-12-31       Sunday
2000-01-03          NaN
2000-01-04      Tuesday
2000-01-05    Wednesday
Freq: B, dtype: object
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.date_range pandas.Series.dt.day_name pandas.Series.resample
"In [304]: s.resample(""B"", label=""right"", closed=""right"").last().dt.day_name()
Out[304]: 
2000-01-03       Sunday
2000-01-04      Tuesday
2000-01-05    Wednesday
2000-01-06          NaN
Freq: B, dtype: object
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.Series.resample
"In [308]: rng = pd.date_range(""2014-1-1"", periods=100, freq=""D"") + pd.Timedelta(""1s"")

In [309]: ts = pd.Series(range(100), index=rng)
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.date_range pandas.Series
"In [310]: ts.resample(""3min"").sum()
Out[310]: 
2014-01-01 00:00:00     0
2014-01-01 00:03:00     0
2014-01-01 00:06:00     0
2014-01-01 00:09:00     0
2014-01-01 00:12:00     0
                       ..
2014-04-09 23:48:00     0
2014-04-09 23:51:00     0
2014-04-09 23:54:00     0
2014-04-09 23:57:00     0
2014-04-10 00:00:00    99
Freq: 3min, Length: 47521, dtype: int64
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.Series.resample
"In [311]: from functools import partial

In [312]: from pandas.tseries.frequencies import to_offset

In [313]: def round(t, freq):
   .....:     freq = to_offset(freq)
   .....:     td = pd.Timedelta(freq)
   .....:     return pd.Timestamp((t.value // td.value) * td.value)
   .....: 

In [314]: ts.groupby(partial(round, freq=""3min"")).sum()
Out[314]: 
2014-01-01     0
2014-01-02     1
2014-01-03     2
2014-01-04     3
2014-01-05     4
              ..
2014-04-06    95
2014-04-07    96
2014-04-08    97
2014-04-09    98
2014-04-10    99
Length: 100, dtype: int64
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.tseries.frequencies.to_offset pandas.Series.groupby
"In [315]: df = pd.DataFrame(
   .....:     np.random.randn(1000, 3),
   .....:     index=pd.date_range(""1/1/2012"", freq=""s"", periods=1000),
   .....:     columns=[""A"", ""B"", ""C""],
   .....: )
   .....: 

In [316]: r = df.resample(""3min"")

In [317]: r.mean()
Out[317]: 
                            A         B         C
2012-01-01 00:00:00 -0.033823 -0.121514 -0.081447
2012-01-01 00:03:00  0.056909  0.146731 -0.024320
2012-01-01 00:06:00 -0.058837  0.047046 -0.052021
2012-01-01 00:09:00  0.063123 -0.026158 -0.066533
2012-01-01 00:12:00  0.186340 -0.003144  0.074752
2012-01-01 00:15:00 -0.085954 -0.016287 -0.050046
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.DataFrame pandas.date_range pandas.DataFrame.resample
"In [325]: df = pd.DataFrame(
   .....:     {""date"": pd.date_range(""2015-01-01"", freq=""W"", periods=5), ""a"": np.arange(5)},
   .....:     index=pd.MultiIndex.from_arrays(
   .....:         [[1, 2, 3, 4, 5], pd.date_range(""2015-01-01"", freq=""W"", periods=5)],
   .....:         names=[""v"", ""d""],
   .....:     ),
   .....: )
   .....: 

In [326]: df
Out[326]: 
                   date  a
v d                       
1 2015-01-04 2015-01-04  0
2 2015-01-11 2015-01-11  1
3 2015-01-18 2015-01-18  2
4 2015-01-25 2015-01-25  3
5 2015-02-01 2015-02-01  4

In [327]: df.resample(""ME"", on=""date"")[[""a""]].sum()
Out[327]: 
            a
date         
2015-01-31  6
2015-02-28  4
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.DataFrame pandas.date_range pandas.MultiIndex.from_arrays pandas.DataFrame.resample
"In [328]: df.resample(""ME"", level=""d"")[[""a""]].sum()
Out[328]: 
            a
d            
2015-01-31  6
2015-02-28  4
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.DataFrame.resample
"In [329]: small = pd.Series(
   .....:     range(6),
   .....:     index=pd.to_datetime(
   .....:         [
   .....:             ""2017-01-01T00:00:00"",
   .....:             ""2017-01-01T00:30:00"",
   .....:             ""2017-01-01T00:31:00"",
   .....:             ""2017-01-01T01:00:00"",
   .....:             ""2017-01-01T03:00:00"",
   .....:             ""2017-01-01T03:05:00"",
   .....:         ]
   .....:     ),
   .....: )
   .....: 

In [330]: resampled = small.resample(""h"")

In [331]: for name, group in resampled:
   .....:     print(""Group: "", name)
   .....:     print(""-"" * 27)
   .....:     print(group, end=""\n\n"")
   .....: 
Group:  2017-01-01 00:00:00
---------------------------
2017-01-01 00:00:00    0
2017-01-01 00:30:00    1
2017-01-01 00:31:00    2
dtype: int64

Group:  2017-01-01 01:00:00
---------------------------
2017-01-01 01:00:00    3
dtype: int64

Group:  2017-01-01 02:00:00
---------------------------
Series([], dtype: int64)

Group:  2017-01-01 03:00:00
---------------------------
2017-01-01 03:00:00    4
2017-01-01 03:05:00    5
dtype: int64
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.Series pandas.to_datetime pandas.Series.resample pandas.Series
"In [332]: start, end = ""2000-10-01 23:30:00"", ""2000-10-02 00:30:00""

In [333]: middle = ""2000-10-02 00:00:00""

In [334]: rng = pd.date_range(start, end, freq=""7min"")

In [335]: ts = pd.Series(np.arange(len(rng)) * 3, index=rng)

In [336]: ts
Out[336]: 
2000-10-01 23:30:00     0
2000-10-01 23:37:00     3
2000-10-01 23:44:00     6
2000-10-01 23:51:00     9
2000-10-01 23:58:00    12
2000-10-02 00:05:00    15
2000-10-02 00:12:00    18
2000-10-02 00:19:00    21
2000-10-02 00:26:00    24
Freq: 7min, dtype: int64
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.date_range pandas.Series
"In [337]: ts.resample(""17min"", origin=""start_day"").sum()
Out[337]: 
2000-10-01 23:14:00     0
2000-10-01 23:31:00     9
2000-10-01 23:48:00    21
2000-10-02 00:05:00    54
2000-10-02 00:22:00    24
Freq: 17min, dtype: int64

In [338]: ts[middle:end].resample(""17min"", origin=""start_day"").sum()
Out[338]: 
2000-10-02 00:00:00    33
2000-10-02 00:17:00    45
Freq: 17min, dtype: int64
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.Series.resample
"In [339]: ts.resample(""17min"", origin=""epoch"").sum()
Out[339]: 
2000-10-01 23:18:00     0
2000-10-01 23:35:00    18
2000-10-01 23:52:00    27
2000-10-02 00:09:00    39
2000-10-02 00:26:00    24
Freq: 17min, dtype: int64

In [340]: ts[middle:end].resample(""17min"", origin=""epoch"").sum()
Out[340]: 
2000-10-01 23:52:00    15
2000-10-02 00:09:00    39
2000-10-02 00:26:00    24
Freq: 17min, dtype: int64
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.Series.resample
"In [341]: ts.resample(""17min"", origin=""2001-01-01"").sum()
Out[341]: 
2000-10-01 23:30:00     9
2000-10-01 23:47:00    21
2000-10-02 00:04:00    54
2000-10-02 00:21:00    24
Freq: 17min, dtype: int64

In [342]: ts[middle:end].resample(""17min"", origin=pd.Timestamp(""2001-01-01"")).sum()
Out[342]: 
2000-10-02 00:04:00    54
2000-10-02 00:21:00    24
Freq: 17min, dtype: int64
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.Series.resample
"In [343]: ts.resample(""17min"", origin=""start"").sum()
Out[343]: 
2000-10-01 23:30:00     9
2000-10-01 23:47:00    21
2000-10-02 00:04:00    54
2000-10-02 00:21:00    24
Freq: 17min, dtype: int64

In [344]: ts.resample(""17min"", offset=""23h30min"").sum()
Out[344]: 
2000-10-01 23:30:00     9
2000-10-01 23:47:00    21
2000-10-02 00:04:00    54
2000-10-02 00:21:00    24
Freq: 17min, dtype: int64
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.Series.resample
"In [345]: ts.resample('17min', origin='end').sum()
Out[345]: 
2000-10-01 23:35:00     0
2000-10-01 23:52:00    18
2000-10-02 00:09:00    27
2000-10-02 00:26:00    63
Freq: 17min, dtype: int64
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.Series.resample
"In [346]: ts.resample('17min', origin='end_day').sum()
Out[346]: 
2000-10-01 23:38:00     3
2000-10-01 23:55:00    15
2000-10-02 00:12:00    45
2000-10-02 00:29:00    45
Freq: 17min, dtype: int64
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.Series.resample
"In [351]: pd.Period(""2012"", freq=""Y-DEC"")
Out[351]: Period('2012', 'Y-DEC')

In [352]: pd.Period(""2012-1-1"", freq=""D"")
Out[352]: Period('2012-01-01', 'D')

In [353]: pd.Period(""2012-1-1 19:00"", freq=""h"")
Out[353]: Period('2012-01-01 19:00', 'h')

In [354]: pd.Period(""2012-1-1 19:00"", freq=""5h"")
Out[354]: Period('2012-01-01 19:00', '5h')
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.Period pandas.Period
"In [355]: p = pd.Period(""2012"", freq=""Y-DEC"")

In [356]: p + 1
Out[356]: Period('2013', 'Y-DEC')

In [357]: p - 3
Out[357]: Period('2009', 'Y-DEC')

In [358]: p = pd.Period(""2012-01"", freq=""2M"")

In [359]: p + 2
Out[359]: Period('2012-05', '2M')

In [360]: p - 1
Out[360]: Period('2011-11', '2M')

In [361]: p == pd.Period(""2012-01"", freq=""3M"")
Out[361]: False
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.Period pandas.Period
"In [362]: p = pd.Period(""2014-07-01 09:00"", freq=""h"")

In [363]: p + pd.offsets.Hour(2)
Out[363]: Period('2014-07-01 11:00', 'h')

In [364]: p + datetime.timedelta(minutes=120)
Out[364]: Period('2014-07-01 11:00', 'h')

In [365]: p + np.timedelta64(7200, ""s"")
Out[365]: Period('2014-07-01 11:00', 'h')
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.Period pandas.Period
"In [366]: p + pd.offsets.Minute(5)
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
File period.pyx:1824, in pandas._libs.tslibs.period._Period._add_timedeltalike_scalar()

File timedeltas.pyx:278, in pandas._libs.tslibs.timedeltas.delta_to_nanoseconds()

File np_datetime.pyx:661, in pandas._libs.tslibs.np_datetime.convert_reso()

ValueError: Cannot losslessly convert units

The above exception was the direct cause of the following exception:

IncompatibleFrequency                     Traceback (most recent call last)
Cell In[366], line 1
----> 1 p + pd.offsets.Minute(5)

File period.pyx:1845, in pandas._libs.tslibs.period._Period.__add__()

File period.pyx:1826, in pandas._libs.tslibs.period._Period._add_timedeltalike_scalar()

IncompatibleFrequency: Input cannot be converted to Period(freq=h)
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.Period
"In [367]: p = pd.Period(""2014-07"", freq=""M"")

In [368]: p + pd.offsets.MonthEnd(3)
Out[368]: Period('2014-10', 'M')
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.Period pandas.Period
"In [369]: p + pd.offsets.MonthBegin(3)
---------------------------------------------------------------------------
IncompatibleFrequency                     Traceback (most recent call last)
Cell In[369], line 1
----> 1 p + pd.offsets.MonthBegin(3)

File period.pyx:1847, in pandas._libs.tslibs.period._Period.__add__()

File period.pyx:1837, in pandas._libs.tslibs.period._Period._add_offset()

File period.pyx:1732, in pandas._libs.tslibs.period.PeriodMixin._require_matching_freq()

IncompatibleFrequency: Input has different freq=3M from Period(freq=M)
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.Period
"In [370]: pd.Period(""2012"", freq=""Y-DEC"") - pd.Period(""2002"", freq=""Y-DEC"")
Out[370]: <10 * YearEnds: month=12>
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.Period
"In [371]: prng = pd.period_range(""1/1/2011"", ""1/1/2012"", freq=""M"")

In [372]: prng
Out[372]: 
PeriodIndex(['2011-01', '2011-02', '2011-03', '2011-04', '2011-05', '2011-06',
             '2011-07', '2011-08', '2011-09', '2011-10', '2011-11', '2011-12',
             '2012-01'],
            dtype='period[M]')
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.period_range pandas.PeriodIndex
"In [373]: pd.PeriodIndex([""2011-1"", ""2011-2"", ""2011-3""], freq=""M"")
Out[373]: PeriodIndex(['2011-01', '2011-02', '2011-03'], dtype='period[M]')
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.PeriodIndex pandas.PeriodIndex
"In [374]: pd.period_range(start=""2014-01"", freq=""3M"", periods=4)
Out[374]: PeriodIndex(['2014-01', '2014-04', '2014-07', '2014-10'], dtype='period[3M]')
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.period_range pandas.PeriodIndex
"In [375]: pd.period_range(
   .....:     start=pd.Period(""2017Q1"", freq=""Q""), end=pd.Period(""2017Q2"", freq=""Q""), freq=""M""
   .....: )
   .....: 
Out[375]: PeriodIndex(['2017-03', '2017-04', '2017-05', '2017-06'], dtype='period[M]')
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.period_range pandas.Period pandas.PeriodIndex
"In [376]: ps = pd.Series(np.random.randn(len(prng)), prng)

In [377]: ps
Out[377]: 
2011-01   -2.916901
2011-02    0.514474
2011-03    1.346470
2011-04    0.816397
2011-05    2.258648
2011-06    0.494789
2011-07    0.301239
2011-08    0.464776
2011-09   -1.393581
2011-10    0.056780
2011-11    0.197035
2011-12    2.261385
2012-01   -0.329583
Freq: M, dtype: float64
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.Series
"In [378]: idx = pd.period_range(""2014-07-01 09:00"", periods=5, freq=""h"")

In [379]: idx
Out[379]: 
PeriodIndex(['2014-07-01 09:00', '2014-07-01 10:00', '2014-07-01 11:00',
             '2014-07-01 12:00', '2014-07-01 13:00'],
            dtype='period[h]')

In [380]: idx + pd.offsets.Hour(2)
Out[380]: 
PeriodIndex(['2014-07-01 11:00', '2014-07-01 12:00', '2014-07-01 13:00',
             '2014-07-01 14:00', '2014-07-01 15:00'],
            dtype='period[h]')

In [381]: idx = pd.period_range(""2014-07"", periods=5, freq=""M"")

In [382]: idx
Out[382]: PeriodIndex(['2014-07', '2014-08', '2014-09', '2014-10', '2014-11'], dtype='period[M]')

In [383]: idx + pd.offsets.MonthEnd(3)
Out[383]: PeriodIndex(['2014-10', '2014-11', '2014-12', '2015-01', '2015-02'], dtype='period[M]')
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.period_range pandas.PeriodIndex
"In [384]: pi = pd.period_range(""2016-01-01"", periods=3, freq=""M"")

In [385]: pi
Out[385]: PeriodIndex(['2016-01', '2016-02', '2016-03'], dtype='period[M]')

In [386]: pi.dtype
Out[386]: period[M]
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.period_range pandas.PeriodIndex
"# change monthly freq to daily freq
In [387]: pi.astype(""period[D]"")
Out[387]: PeriodIndex(['2016-01-31', '2016-02-29', '2016-03-31'], dtype='period[D]')

# convert to DatetimeIndex
In [388]: pi.astype(""datetime64[ns]"")
Out[388]: DatetimeIndex(['2016-01-01', '2016-02-01', '2016-03-01'], dtype='datetime64[ns]', freq='MS')

# convert to PeriodIndex
In [389]: dti = pd.date_range(""2011-01-01"", freq=""ME"", periods=3)

In [390]: dti
Out[390]: DatetimeIndex(['2011-01-31', '2011-02-28', '2011-03-31'], dtype='datetime64[ns]', freq='ME')

In [391]: dti.astype(""period[M]"")
Out[391]: PeriodIndex(['2011-01', '2011-02', '2011-03'], dtype='period[M]')
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.PeriodIndex pandas.DatetimeIndex pandas.date_range
"In [395]: ps[""2011""]
Out[395]: 
2011-01   -2.916901
2011-02    0.514474
2011-03    1.346470
2011-04    0.816397
2011-05    2.258648
2011-06    0.494789
2011-07    0.301239
2011-08    0.464776
2011-09   -1.393581
2011-10    0.056780
2011-11    0.197035
2011-12    2.261385
Freq: M, dtype: float64

In [396]: dfp = pd.DataFrame(
   .....:     np.random.randn(600, 1),
   .....:     columns=[""A""],
   .....:     index=pd.period_range(""2013-01-01 9:00"", periods=600, freq=""min""),
   .....: )
   .....: 

In [397]: dfp
Out[397]: 
                         A
2013-01-01 09:00 -0.538468
2013-01-01 09:01 -1.365819
2013-01-01 09:02 -0.969051
2013-01-01 09:03 -0.331152
2013-01-01 09:04 -0.245334
...                    ...
2013-01-01 18:55  0.522460
2013-01-01 18:56  0.118710
2013-01-01 18:57  0.167517
2013-01-01 18:58  0.922883
2013-01-01 18:59  1.721104

[600 rows x 1 columns]

In [398]: dfp.loc[""2013-01-01 10h""]
Out[398]: 
                         A
2013-01-01 10:00 -0.308975
2013-01-01 10:01  0.542520
2013-01-01 10:02  1.061068
2013-01-01 10:03  0.754005
2013-01-01 10:04  0.352933
...                    ...
2013-01-01 10:55 -0.865621
2013-01-01 10:56 -1.167818
2013-01-01 10:57 -2.081748
2013-01-01 10:58 -0.527146
2013-01-01 10:59  0.802298

[60 rows x 1 columns]
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.DataFrame pandas.period_range
"In [400]: p = pd.Period(""2011"", freq=""Y-DEC"")

In [401]: p
Out[401]: Period('2011', 'Y-DEC')
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.Period pandas.Period
"In [402]: p.asfreq(""M"", how=""start"")
Out[402]: Period('2011-01', 'M')

In [403]: p.asfreq(""M"", how=""end"")
Out[403]: Period('2011-12', 'M')
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.Period.asfreq pandas.Period
"In [404]: p.asfreq(""M"", ""s"")
Out[404]: Period('2011-01', 'M')

In [405]: p.asfreq(""M"", ""e"")
Out[405]: Period('2011-12', 'M')
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.Period.asfreq pandas.Period
"In [406]: p = pd.Period(""2011-12"", freq=""M"")

In [407]: p.asfreq(""Y-NOV"")
Out[407]: Period('2012', 'Y-NOV')
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.Period pandas.Period.asfreq pandas.Period
"In [408]: p = pd.Period(""2012Q1"", freq=""Q-DEC"")

In [409]: p.asfreq(""D"", ""s"")
Out[409]: Period('2012-01-01', 'D')

In [410]: p.asfreq(""D"", ""e"")
Out[410]: Period('2012-03-31', 'D')
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.Period pandas.Period.asfreq pandas.Period
"In [411]: p = pd.Period(""2011Q4"", freq=""Q-MAR"")

In [412]: p.asfreq(""D"", ""s"")
Out[412]: Period('2011-01-01', 'D')

In [413]: p.asfreq(""D"", ""e"")
Out[413]: Period('2011-03-31', 'D')
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.Period pandas.Period.asfreq pandas.Period
"In [414]: rng = pd.date_range(""1/1/2012"", periods=5, freq=""ME"")

In [415]: ts = pd.Series(np.random.randn(len(rng)), index=rng)

In [416]: ts
Out[416]: 
2012-01-31    1.931253
2012-02-29   -0.184594
2012-03-31    0.249656
2012-04-30   -0.978151
2012-05-31   -0.873389
Freq: ME, dtype: float64

In [417]: ps = ts.to_period()

In [418]: ps
Out[418]: 
2012-01    1.931253
2012-02   -0.184594
2012-03    0.249656
2012-04   -0.978151
2012-05   -0.873389
Freq: M, dtype: float64

In [419]: ps.to_timestamp()
Out[419]: 
2012-01-01    1.931253
2012-02-01   -0.184594
2012-03-01    0.249656
2012-04-01   -0.978151
2012-05-01   -0.873389
Freq: MS, dtype: float64
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.date_range pandas.Series pandas.Series.to_period pandas.Series.to_timestamp
"In [420]: ps.to_timestamp(""D"", how=""s"")
Out[420]: 
2012-01-01    1.931253
2012-02-01   -0.184594
2012-03-01    0.249656
2012-04-01   -0.978151
2012-05-01   -0.873389
Freq: MS, dtype: float64
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.Series.to_timestamp
"In [421]: prng = pd.period_range(""1990Q1"", ""2000Q4"", freq=""Q-NOV"")

In [422]: ts = pd.Series(np.random.randn(len(prng)), prng)

In [423]: ts.index = (prng.asfreq(""M"", ""e"") + 1).asfreq(""h"", ""s"") + 9

In [424]: ts.head()
Out[424]: 
1990-03-01 09:00   -0.109291
1990-06-01 09:00   -0.637235
1990-09-01 09:00   -1.735925
1990-12-01 09:00    2.096946
1991-03-01 09:00   -1.039926
Freq: h, dtype: float64
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.period_range pandas.Series pandas.Series.head
"In [425]: span = pd.period_range(""1215-01-01"", ""1381-01-01"", freq=""D"")

In [426]: span
Out[426]: 
PeriodIndex(['1215-01-01', '1215-01-02', '1215-01-03', '1215-01-04',
             '1215-01-05', '1215-01-06', '1215-01-07', '1215-01-08',
             '1215-01-09', '1215-01-10',
             ...
             '1380-12-23', '1380-12-24', '1380-12-25', '1380-12-26',
             '1380-12-27', '1380-12-28', '1380-12-29', '1380-12-30',
             '1380-12-31', '1381-01-01'],
            dtype='period[D]', length=60632)
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.period_range pandas.PeriodIndex
"In [427]: s = pd.Series([20121231, 20141130, 99991231])

In [428]: s
Out[428]: 
0    20121231
1    20141130
2    99991231
dtype: int64

In [429]: def conv(x):
   .....:     return pd.Period(year=x // 10000, month=x // 100 % 100, day=x % 100, freq=""D"")
   .....: 

In [430]: s.apply(conv)
Out[430]: 
0    2012-12-31
1    2014-11-30
2    9999-12-31
dtype: period[D]

In [431]: s.apply(conv)[2]
Out[431]: Period('9999-12-31', 'D')
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.Series pandas.Period pandas.Series.apply pandas.Period
"In [432]: span = pd.PeriodIndex(s.apply(conv))

In [433]: span
Out[433]: PeriodIndex(['2012-12-31', '2014-11-30', '9999-12-31'], dtype='period[D]')
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.PeriodIndex pandas.Series.apply pandas.PeriodIndex
"In [434]: rng = pd.date_range(""3/6/2012 00:00"", periods=15, freq=""D"")

In [435]: rng.tz is None
Out[435]: True
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.date_range
"In [436]: import dateutil

# pytz
In [437]: rng_pytz = pd.date_range(""3/6/2012 00:00"", periods=3, freq=""D"", tz=""Europe/London"")

In [438]: rng_pytz.tz
Out[438]: 

# dateutil
In [439]: rng_dateutil = pd.date_range(""3/6/2012 00:00"", periods=3, freq=""D"")

In [440]: rng_dateutil = rng_dateutil.tz_localize(""dateutil/Europe/London"")

In [441]: rng_dateutil.tz
Out[441]: tzfile('/usr/share/zoneinfo/Europe/London')

# dateutil - utc special case
In [442]: rng_utc = pd.date_range(
   .....:     ""3/6/2012 00:00"",
   .....:     periods=3,
   .....:     freq=""D"",
   .....:     tz=dateutil.tz.tzutc(),
   .....: )
   .....: 

In [443]: rng_utc.tz
Out[443]: tzutc()
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.date_range
"# datetime.timezone
In [444]: rng_utc = pd.date_range(
   .....:     ""3/6/2012 00:00"",
   .....:     periods=3,
   .....:     freq=""D"",
   .....:     tz=datetime.timezone.utc,
   .....: )
   .....: 

In [445]: rng_utc.tz
Out[445]: datetime.timezone.utc
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.date_range
"In [446]: import pytz

# pytz
In [447]: tz_pytz = pytz.timezone(""Europe/London"")

In [448]: rng_pytz = pd.date_range(""3/6/2012 00:00"", periods=3, freq=""D"")

In [449]: rng_pytz = rng_pytz.tz_localize(tz_pytz)

In [450]: rng_pytz.tz == tz_pytz
Out[450]: True

# dateutil
In [451]: tz_dateutil = dateutil.tz.gettz(""Europe/London"")

In [452]: rng_dateutil = pd.date_range(""3/6/2012 00:00"", periods=3, freq=""D"", tz=tz_dateutil)

In [453]: rng_dateutil.tz == tz_dateutil
Out[453]: True
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.date_range
"In [454]: rng_pytz.tz_convert(""US/Eastern"")
Out[454]: 
DatetimeIndex(['2012-03-05 19:00:00-05:00', '2012-03-06 19:00:00-05:00',
               '2012-03-07 19:00:00-05:00'],
              dtype='datetime64[ns, US/Eastern]', freq=None)
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.DatetimeIndex
"In [455]: dti = pd.date_range(""2019-01-01"", periods=3, freq=""D"", tz=""US/Pacific"")

In [456]: dti.tz
Out[456]: 

In [457]: ts = pd.Timestamp(""2019-01-01"", tz=""US/Pacific"")

In [458]: ts.tz
Out[458]: 
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.date_range
"In [469]: ts_utc = pd.Series(range(3), pd.date_range(""20130101"", periods=3, tz=""UTC""))

In [470]: eastern = ts_utc.tz_convert(""US/Eastern"")

In [471]: berlin = ts_utc.tz_convert(""Europe/Berlin"")

In [472]: result = eastern + berlin

In [473]: result
Out[473]: 
2013-01-01 00:00:00+00:00    0
2013-01-02 00:00:00+00:00    2
2013-01-03 00:00:00+00:00    4
Freq: D, dtype: int64

In [474]: result.index
Out[474]: 
DatetimeIndex(['2013-01-01 00:00:00+00:00', '2013-01-02 00:00:00+00:00',
               '2013-01-03 00:00:00+00:00'],
              dtype='datetime64[ns, UTC]', freq='D')
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.Series pandas.date_range pandas.Series.tz_convert pandas.DatetimeIndex
"In [475]: didx = pd.date_range(start=""2014-08-01 09:00"", freq=""h"", periods=3, tz=""US/Eastern"")

In [476]: didx
Out[476]: 
DatetimeIndex(['2014-08-01 09:00:00-04:00', '2014-08-01 10:00:00-04:00',
               '2014-08-01 11:00:00-04:00'],
              dtype='datetime64[ns, US/Eastern]', freq='h')

In [477]: didx.tz_localize(None)
Out[477]: 
DatetimeIndex(['2014-08-01 09:00:00', '2014-08-01 10:00:00',
               '2014-08-01 11:00:00'],
              dtype='datetime64[ns]', freq=None)

In [478]: didx.tz_convert(None)
Out[478]: 
DatetimeIndex(['2014-08-01 13:00:00', '2014-08-01 14:00:00',
               '2014-08-01 15:00:00'],
              dtype='datetime64[ns]', freq='h')

# tz_convert(None) is identical to tz_convert('UTC').tz_localize(None)
In [479]: didx.tz_convert(""UTC"").tz_localize(None)
Out[479]: 
DatetimeIndex(['2014-08-01 13:00:00', '2014-08-01 14:00:00',
               '2014-08-01 15:00:00'],
              dtype='datetime64[ns]', freq=None)
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.date_range pandas.DatetimeIndex
"In [482]: rng_hourly = pd.DatetimeIndex(
   .....:     [""11/06/2011 00:00"", ""11/06/2011 01:00"", ""11/06/2011 01:00"", ""11/06/2011 02:00""]
   .....: )
   .....: 
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.DatetimeIndex
"In [483]: rng_hourly.tz_localize('US/Eastern')
---------------------------------------------------------------------------
AmbiguousTimeError                        Traceback (most recent call last)
Cell In[483], line 1
----> 1 rng_hourly.tz_localize('US/Eastern')

File ~/work/pandas/pandas/pandas/core/indexes/datetimes.py:293, in DatetimeIndex.tz_localize(self, tz, ambiguous, nonexistent)
    286 @doc(DatetimeArray.tz_localize)
    287 def tz_localize(
    288     self,
   (...)
    291     nonexistent: TimeNonexistent = ""raise"",
    292 ) -> Self:
--> 293     arr = self._data.tz_localize(tz, ambiguous, nonexistent)
    294     return type(self)._simple_new(arr, name=self.name)

File ~/work/pandas/pandas/pandas/core/arrays/_mixins.py:81, in ravel_compat..method(self, *args, **kwargs)
     78 @wraps(meth)
     79 def method(self, *args, **kwargs):
     80     if self.ndim == 1:
---> 81         return meth(self, *args, **kwargs)
     83     flags = self._ndarray.flags
     84     flat = self.ravel(""K"")

File ~/work/pandas/pandas/pandas/core/arrays/datetimes.py:1088, in DatetimeArray.tz_localize(self, tz, ambiguous, nonexistent)
   1085     tz = timezones.maybe_get_tz(tz)
   1086     # Convert to UTC
-> 1088     new_dates = tzconversion.tz_localize_to_utc(
   1089         self.asi8,
   1090         tz,
   1091         ambiguous=ambiguous,
   1092         nonexistent=nonexistent,
   1093         creso=self._creso,
   1094     )
   1095 new_dates_dt64 = new_dates.view(f""M8[{self.unit}]"")
   1096 dtype = tz_to_dtype(tz, unit=self.unit)

File tzconversion.pyx:371, in pandas._libs.tslibs.tzconversion.tz_localize_to_utc()

AmbiguousTimeError: Cannot infer dst time from 2011-11-06 01:00:00, try using the 'ambiguous' argument
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.DatetimeIndex.tz_localize pandas.DatetimeIndex.tz_localize
"In [484]: rng_hourly.tz_localize(""US/Eastern"", ambiguous=""infer"")
Out[484]: 
DatetimeIndex(['2011-11-06 00:00:00-04:00', '2011-11-06 01:00:00-04:00',
               '2011-11-06 01:00:00-05:00', '2011-11-06 02:00:00-05:00'],
              dtype='datetime64[ns, US/Eastern]', freq=None)

In [485]: rng_hourly.tz_localize(""US/Eastern"", ambiguous=""NaT"")
Out[485]: 
DatetimeIndex(['2011-11-06 00:00:00-04:00', 'NaT', 'NaT',
               '2011-11-06 02:00:00-05:00'],
              dtype='datetime64[ns, US/Eastern]', freq=None)

In [486]: rng_hourly.tz_localize(""US/Eastern"", ambiguous=[True, True, False, False])
Out[486]: 
DatetimeIndex(['2011-11-06 00:00:00-04:00', '2011-11-06 01:00:00-04:00',
               '2011-11-06 01:00:00-05:00', '2011-11-06 02:00:00-05:00'],
              dtype='datetime64[ns, US/Eastern]', freq=None)
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.DatetimeIndex.tz_localize pandas.DatetimeIndex
"In [487]: dti = pd.date_range(start=""2015-03-29 02:30:00"", periods=3, freq=""h"")

# 2:30 is a nonexistent time
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.date_range
"In [488]: dti.tz_localize('Europe/Warsaw')
---------------------------------------------------------------------------
NonExistentTimeError                      Traceback (most recent call last)
Cell In[488], line 1
----> 1 dti.tz_localize('Europe/Warsaw')

File ~/work/pandas/pandas/pandas/core/indexes/datetimes.py:293, in DatetimeIndex.tz_localize(self, tz, ambiguous, nonexistent)
    286 @doc(DatetimeArray.tz_localize)
    287 def tz_localize(
    288     self,
   (...)
    291     nonexistent: TimeNonexistent = ""raise"",
    292 ) -> Self:
--> 293     arr = self._data.tz_localize(tz, ambiguous, nonexistent)
    294     return type(self)._simple_new(arr, name=self.name)

File ~/work/pandas/pandas/pandas/core/arrays/_mixins.py:81, in ravel_compat..method(self, *args, **kwargs)
     78 @wraps(meth)
     79 def method(self, *args, **kwargs):
     80     if self.ndim == 1:
---> 81         return meth(self, *args, **kwargs)
     83     flags = self._ndarray.flags
     84     flat = self.ravel(""K"")

File ~/work/pandas/pandas/pandas/core/arrays/datetimes.py:1088, in DatetimeArray.tz_localize(self, tz, ambiguous, nonexistent)
   1085     tz = timezones.maybe_get_tz(tz)
   1086     # Convert to UTC
-> 1088     new_dates = tzconversion.tz_localize_to_utc(
   1089         self.asi8,
   1090         tz,
   1091         ambiguous=ambiguous,
   1092         nonexistent=nonexistent,
   1093         creso=self._creso,
   1094     )
   1095 new_dates_dt64 = new_dates.view(f""M8[{self.unit}]"")
   1096 dtype = tz_to_dtype(tz, unit=self.unit)

File tzconversion.pyx:431, in pandas._libs.tslibs.tzconversion.tz_localize_to_utc()

NonExistentTimeError: 2015-03-29 02:30:00
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.DatetimeIndex.tz_localize
"In [489]: dti
Out[489]: 
DatetimeIndex(['2015-03-29 02:30:00', '2015-03-29 03:30:00',
               '2015-03-29 04:30:00'],
              dtype='datetime64[ns]', freq='h')

In [490]: dti.tz_localize(""Europe/Warsaw"", nonexistent=""shift_forward"")
Out[490]: 
DatetimeIndex(['2015-03-29 03:00:00+02:00', '2015-03-29 03:30:00+02:00',
               '2015-03-29 04:30:00+02:00'],
              dtype='datetime64[ns, Europe/Warsaw]', freq=None)

In [491]: dti.tz_localize(""Europe/Warsaw"", nonexistent=""shift_backward"")
Out[491]: 
DatetimeIndex(['2015-03-29 01:59:59.999999999+01:00',
                         '2015-03-29 03:30:00+02:00',
                         '2015-03-29 04:30:00+02:00'],
              dtype='datetime64[ns, Europe/Warsaw]', freq=None)

In [492]: dti.tz_localize(""Europe/Warsaw"", nonexistent=pd.Timedelta(1, unit=""h""))
Out[492]: 
DatetimeIndex(['2015-03-29 03:30:00+02:00', '2015-03-29 03:30:00+02:00',
               '2015-03-29 04:30:00+02:00'],
              dtype='datetime64[ns, Europe/Warsaw]', freq=None)

In [493]: dti.tz_localize(""Europe/Warsaw"", nonexistent=""NaT"")
Out[493]: 
DatetimeIndex(['NaT', '2015-03-29 03:30:00+02:00',
               '2015-03-29 04:30:00+02:00'],
              dtype='datetime64[ns, Europe/Warsaw]', freq=None)
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.DatetimeIndex
"In [494]: s_naive = pd.Series(pd.date_range(""20130101"", periods=3))

In [495]: s_naive
Out[495]: 
0   2013-01-01
1   2013-01-02
2   2013-01-03
dtype: datetime64[ns]
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.Series pandas.date_range
"In [496]: s_aware = pd.Series(pd.date_range(""20130101"", periods=3, tz=""US/Eastern""))

In [497]: s_aware
Out[497]: 
0   2013-01-01 00:00:00-05:00
1   2013-01-02 00:00:00-05:00
2   2013-01-03 00:00:00-05:00
dtype: datetime64[ns, US/Eastern]
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.Series pandas.date_range
"In [498]: s_naive.dt.tz_localize(""UTC"").dt.tz_convert(""US/Eastern"")
Out[498]: 
0   2012-12-31 19:00:00-05:00
1   2013-01-01 19:00:00-05:00
2   2013-01-02 19:00:00-05:00
dtype: datetime64[ns, US/Eastern]
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.Series.dt.tz_localize
"# convert to a new time zone
In [499]: s_aware.astype(""datetime64[ns, CET]"")
Out[499]: 
0   2013-01-01 06:00:00+01:00
1   2013-01-02 06:00:00+01:00
2   2013-01-03 06:00:00+01:00
dtype: datetime64[ns, CET]
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.Series.astype
"In [500]: s_naive.to_numpy()
Out[500]: 
array(['2013-01-01T00:00:00.000000000', '2013-01-02T00:00:00.000000000',
       '2013-01-03T00:00:00.000000000'], dtype='datetime64[ns]')

In [501]: s_aware.to_numpy()
Out[501]: 
array([Timestamp('2013-01-01 00:00:00-0500', tz='US/Eastern'),
       Timestamp('2013-01-02 00:00:00-0500', tz='US/Eastern'),
       Timestamp('2013-01-03 00:00:00-0500', tz='US/Eastern')],
      dtype=object)
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.Series.to_numpy pandas.array pandas.Series.to_numpy
"In [502]: pd.Series(s_aware.to_numpy())
Out[502]: 
0   2013-01-01 00:00:00-05:00
1   2013-01-02 00:00:00-05:00
2   2013-01-03 00:00:00-05:00
dtype: datetime64[ns, US/Eastern]
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.Series pandas.Series.to_numpy
"In [503]: s_aware.to_numpy(dtype=""datetime64[ns]"")
Out[503]: 
array(['2013-01-01T05:00:00.000000000', '2013-01-02T05:00:00.000000000',
       '2013-01-03T05:00:00.000000000'], dtype='datetime64[ns]')
",https://pandas.pydata.org/docs/user_guide/timeseries.html, pandas.Series.to_numpy pandas.array
"In [1]: s = pd.Series(range(5))

In [2]: s.rolling(window=2).sum()
Out[2]: 
0    NaN
1    1.0
2    3.0
3    5.0
4    7.0
dtype: float64
",https://pandas.pydata.org/docs/user_guide/window.html, pandas.Series pandas.Series.rolling
"In [3]: for window in s.rolling(window=2):
   ...:     print(window)
   ...: 
0    0
dtype: int64
0    0
1    1
dtype: int64
1    1
2    2
dtype: int64
2    2
3    3
dtype: int64
3    3
4    4
dtype: int64
",https://pandas.pydata.org/docs/user_guide/window.html, pandas.Series.rolling
"In [4]: s = pd.Series(range(5), index=pd.date_range('2020-01-01', periods=5, freq='1D'))

In [5]: s.rolling(window='2D').sum()
Out[5]: 
2020-01-01    0.0
2020-01-02    1.0
2020-01-03    3.0
2020-01-04    5.0
2020-01-05    7.0
Freq: D, dtype: float64
",https://pandas.pydata.org/docs/user_guide/window.html, pandas.Series pandas.date_range pandas.Series.rolling
"In [6]: df = pd.DataFrame({'A': ['a', 'b', 'a', 'b', 'a'], 'B': range(5)})

In [7]: df.groupby('A').expanding().sum()
Out[7]: 
       B
A       
a 0  0.0
  2  2.0
  4  6.0
b 1  1.0
  3  4.0
",https://pandas.pydata.org/docs/user_guide/window.html, pandas.DataFrame pandas.DataFrame.groupby
"In [8]: def weighted_mean(x):
   ...:     arr = np.ones((1, x.shape[1]))
   ...:     arr[:, :2] = (x[:, :2] * x[:, 2]).sum(axis=0) / x[:, 2].sum()
   ...:     return arr
   ...: 

In [9]: df = pd.DataFrame([[1, 2, 0.6], [2, 3, 0.4], [3, 4, 0.2], [4, 5, 0.7]])

In [10]: df.rolling(2, method=""table"", min_periods=0).apply(weighted_mean, raw=True, engine=""numba"")  # noqa: E501
Out[10]: 
          0         1    2
0  1.000000  2.000000  1.0
1  1.800000  2.000000  1.0
2  3.333333  2.333333  1.0
3  1.555556  7.000000  1.0
",https://pandas.pydata.org/docs/user_guide/window.html, pandas.DataFrame pandas.DataFrame.rolling
"In [11]: df = pd.DataFrame([[1, 2, 0.6], [2, 3, 0.4], [3, 4, 0.2], [4, 5, 0.7]])

In [12]: df.ewm(0.5).mean()
Out[12]: 
          0         1         2
0  1.000000  2.000000  0.600000
1  1.750000  2.750000  0.450000
2  2.615385  3.615385  0.276923
3  3.550000  4.550000  0.562500
",https://pandas.pydata.org/docs/user_guide/window.html, pandas.DataFrame pandas.DataFrame.ewm
"In [13]: online_ewm = df.head(2).ewm(0.5).online()

In [14]: online_ewm.mean()
Out[14]: 
      0     1     2
0  1.00  2.00  0.60
1  1.75  2.75  0.45

In [15]: online_ewm.mean(update=df.tail(1))
Out[15]: 
          0         1         2
3  3.307692  4.307692  0.623077
",https://pandas.pydata.org/docs/user_guide/window.html, pandas.DataFrame.head pandas.DataFrame.tail
"In [16]: s = pd.Series([np.nan, 1, 2, np.nan, np.nan, 3])

In [17]: s.rolling(window=3, min_periods=1).sum()
Out[17]: 
0    NaN
1    1.0
2    3.0
3    3.0
4    2.0
5    3.0
dtype: float64

In [18]: s.rolling(window=3, min_periods=2).sum()
Out[18]: 
0    NaN
1    NaN
2    3.0
3    3.0
4    NaN
5    NaN
dtype: float64

# Equivalent to min_periods=3
In [19]: s.rolling(window=3, min_periods=None).sum()
Out[19]: 
0   NaN
1   NaN
2   NaN
3   NaN
4   NaN
5   NaN
dtype: float64
",https://pandas.pydata.org/docs/user_guide/window.html, pandas.Series pandas.Series.rolling
"In [20]: df = pd.DataFrame({""A"": range(5), ""B"": range(10, 15)})

In [21]: df.expanding().agg([""sum"", ""mean"", ""std""])
Out[21]: 
      A                    B                
    sum mean       std   sum  mean       std
0   0.0  0.0       NaN  10.0  10.0       NaN
1   1.0  0.5  0.707107  21.0  10.5  0.707107
2   3.0  1.0  1.000000  33.0  11.0  1.000000
3   6.0  1.5  1.290994  46.0  11.5  1.290994
4  10.0  2.0  1.581139  60.0  12.0  1.581139
",https://pandas.pydata.org/docs/user_guide/window.html, pandas.DataFrame pandas.DataFrame.expanding
"In [22]: times = ['2020-01-01', '2020-01-03', '2020-01-04', '2020-01-05', '2020-01-29']

In [23]: s = pd.Series(range(5), index=pd.DatetimeIndex(times))

In [24]: s
Out[24]: 
2020-01-01    0
2020-01-03    1
2020-01-04    2
2020-01-05    3
2020-01-29    4
dtype: int64

# Window with 2 observations
In [25]: s.rolling(window=2).sum()
Out[25]: 
2020-01-01    NaN
2020-01-03    1.0
2020-01-04    3.0
2020-01-05    5.0
2020-01-29    7.0
dtype: float64

# Window with 2 days worth of observations
In [26]: s.rolling(window='2D').sum()
Out[26]: 
2020-01-01    0.0
2020-01-03    1.0
2020-01-04    3.0
2020-01-05    5.0
2020-01-29    4.0
dtype: float64
",https://pandas.pydata.org/docs/user_guide/window.html, pandas.Series pandas.DatetimeIndex pandas.Series.rolling
"In [27]: s = pd.Series(range(10))

In [28]: s.rolling(window=5).mean()
Out[28]: 
0    NaN
1    NaN
2    NaN
3    NaN
4    2.0
5    3.0
6    4.0
7    5.0
8    6.0
9    7.0
dtype: float64

In [29]: s.rolling(window=5, center=True).mean()
Out[29]: 
0    NaN
1    NaN
2    2.0
3    3.0
4    4.0
5    5.0
6    6.0
7    7.0
8    NaN
9    NaN
dtype: float64
",https://pandas.pydata.org/docs/user_guide/window.html, pandas.Series pandas.Series.rolling
"In [30]: df = pd.DataFrame(
   ....:     {""A"": [0, 1, 2, 3, 4]}, index=pd.date_range(""2020"", periods=5, freq=""1D"")
   ....: )
   ....: 

In [31]: df
Out[31]: 
            A
2020-01-01  0
2020-01-02  1
2020-01-03  2
2020-01-04  3
2020-01-05  4

In [32]: df.rolling(""2D"", center=False).mean()
Out[32]: 
              A
2020-01-01  0.0
2020-01-02  0.5
2020-01-03  1.5
2020-01-04  2.5
2020-01-05  3.5

In [33]: df.rolling(""2D"", center=True).mean()
Out[33]: 
              A
2020-01-01  0.5
2020-01-02  1.5
2020-01-03  2.5
2020-01-04  3.5
2020-01-05  4.0
",https://pandas.pydata.org/docs/user_guide/window.html, pandas.DataFrame pandas.date_range pandas.DataFrame.rolling
"In [34]: df = pd.DataFrame(
   ....:     {""x"": 1},
   ....:     index=[
   ....:         pd.Timestamp(""20130101 09:00:01""),
   ....:         pd.Timestamp(""20130101 09:00:02""),
   ....:         pd.Timestamp(""20130101 09:00:03""),
   ....:         pd.Timestamp(""20130101 09:00:04""),
   ....:         pd.Timestamp(""20130101 09:00:06""),
   ....:     ],
   ....: )
   ....: 

In [35]: df[""right""] = df.rolling(""2s"", closed=""right"").x.sum()  # default

In [36]: df[""both""] = df.rolling(""2s"", closed=""both"").x.sum()

In [37]: df[""left""] = df.rolling(""2s"", closed=""left"").x.sum()

In [38]: df[""neither""] = df.rolling(""2s"", closed=""neither"").x.sum()

In [39]: df
Out[39]: 
                     x  right  both  left  neither
2013-01-01 09:00:01  1    1.0   1.0   NaN      NaN
2013-01-01 09:00:02  1    2.0   2.0   1.0      1.0
2013-01-01 09:00:03  1    2.0   3.0   2.0      1.0
2013-01-01 09:00:04  1    2.0   3.0   2.0      1.0
2013-01-01 09:00:06  1    1.0   2.0   1.0      NaN
",https://pandas.pydata.org/docs/user_guide/window.html, pandas.DataFrame pandas.DataFrame.rolling
"In [40]: use_expanding = [True, False, True, False, True]

In [41]: use_expanding
Out[41]: [True, False, True, False, True]

In [42]: df = pd.DataFrame({""values"": range(5)})

In [43]: df
Out[43]: 
   values
0       0
1       1
2       2
3       3
4       4
",https://pandas.pydata.org/docs/user_guide/window.html, pandas.DataFrame
"In [44]: from pandas.api.indexers import BaseIndexer

In [45]: class CustomIndexer(BaseIndexer):
   ....:      def get_window_bounds(self, num_values, min_periods, center, closed, step):
   ....:          start = np.empty(num_values, dtype=np.int64)
   ....:          end = np.empty(num_values, dtype=np.int64)
   ....:          for i in range(num_values):
   ....:              if self.use_expanding[i]:
   ....:                  start[i] = 0
   ....:                  end[i] = i + 1
   ....:              else:
   ....:                  start[i] = i
   ....:                  end[i] = i + self.window_size
   ....:          return start, end
   ....: 

In [46]: indexer = CustomIndexer(window_size=1, use_expanding=use_expanding)

In [47]: df.rolling(indexer).sum()
Out[47]: 
   values
0     0.0
1     1.0
2     3.0
3     3.0
4    10.0
",https://pandas.pydata.org/docs/user_guide/window.html, pandas.DataFrame.rolling
"In [48]: from pandas.api.indexers import VariableOffsetWindowIndexer

In [49]: df = pd.DataFrame(range(10), index=pd.date_range(""2020"", periods=10))

In [50]: offset = pd.offsets.BDay(1)

In [51]: indexer = VariableOffsetWindowIndexer(index=df.index, offset=offset)

In [52]: df
Out[52]: 
            0
2020-01-01  0
2020-01-02  1
2020-01-03  2
2020-01-04  3
2020-01-05  4
2020-01-06  5
2020-01-07  6
2020-01-08  7
2020-01-09  8
2020-01-10  9

In [53]: df.rolling(indexer).sum()
Out[53]: 
               0
2020-01-01   0.0
2020-01-02   1.0
2020-01-03   2.0
2020-01-04   3.0
2020-01-05   7.0
2020-01-06  12.0
2020-01-07   6.0
2020-01-08   7.0
2020-01-09   8.0
2020-01-10   9.0
",https://pandas.pydata.org/docs/user_guide/window.html, pandas.DataFrame pandas.date_range pandas.api.indexers.VariableOffsetWindowIndexer pandas.DataFrame.rolling
"In [54]: from pandas.api.indexers import FixedForwardWindowIndexer

In [55]: indexer = FixedForwardWindowIndexer(window_size=2)

In [56]: df.rolling(indexer, min_periods=1).sum()
Out[56]: 
               0
2020-01-01   1.0
2020-01-02   3.0
2020-01-03   5.0
2020-01-04   7.0
2020-01-05   9.0
2020-01-06  11.0
2020-01-07  13.0
2020-01-08  15.0
2020-01-09  17.0
2020-01-10   9.0
",https://pandas.pydata.org/docs/user_guide/window.html, pandas.api.indexers.FixedForwardWindowIndexer pandas.DataFrame.rolling
"In [57]: df = pd.DataFrame(
   ....:     data=[
   ....:         [pd.Timestamp(""2018-01-01 00:00:00""), 100],
   ....:         [pd.Timestamp(""2018-01-01 00:00:01""), 101],
   ....:         [pd.Timestamp(""2018-01-01 00:00:03""), 103],
   ....:         [pd.Timestamp(""2018-01-01 00:00:04""), 111],
   ....:     ],
   ....:     columns=[""time"", ""value""],
   ....: ).set_index(""time"")
   ....: 

In [58]: df
Out[58]: 
                     value
time                      
2018-01-01 00:00:00    100
2018-01-01 00:00:01    101
2018-01-01 00:00:03    103
2018-01-01 00:00:04    111

In [59]: reversed_df = df[::-1].rolling(""2s"").sum()[::-1]

In [60]: reversed_df
Out[60]: 
                     value
time                      
2018-01-01 00:00:00  201.0
2018-01-01 00:00:01  101.0
2018-01-01 00:00:03  214.0
2018-01-01 00:00:04  111.0
",https://pandas.pydata.org/docs/user_guide/window.html, pandas.DataFrame pandas.DataFrame.set_index
"In [61]: def mad(x):
   ....:     return np.fabs(x - x.mean()).mean()
   ....: 

In [62]: s = pd.Series(range(10))

In [63]: s.rolling(window=4).apply(mad, raw=True)
Out[63]: 
0    NaN
1    NaN
2    NaN
3    1.0
4    1.0
5    1.0
6    1.0
7    1.0
8    1.0
9    1.0
dtype: float64
",https://pandas.pydata.org/docs/user_guide/window.html, pandas.Series pandas.Series.rolling
"In [64]: df = pd.DataFrame(
   ....:     np.random.randn(10, 4),
   ....:     index=pd.date_range(""2020-01-01"", periods=10),
   ....:     columns=[""A"", ""B"", ""C"", ""D""],
   ....: )
   ....: 

In [65]: df = df.cumsum()

In [66]: df2 = df[:4]

In [67]: df2.rolling(window=2).corr(df2[""B""])
Out[67]: 
              A    B    C    D
2020-01-01  NaN  NaN  NaN  NaN
2020-01-02 -1.0  1.0 -1.0  1.0
2020-01-03  1.0  1.0  1.0 -1.0
2020-01-04 -1.0  1.0  1.0 -1.0
",https://pandas.pydata.org/docs/user_guide/window.html, pandas.DataFrame pandas.date_range pandas.DataFrame.cumsum pandas.DataFrame.rolling
"In [70]: s = pd.Series(range(10))

In [71]: s.rolling(window=5).mean()
Out[71]: 
0    NaN
1    NaN
2    NaN
3    NaN
4    2.0
5    3.0
6    4.0
7    5.0
8    6.0
9    7.0
dtype: float64

In [72]: s.rolling(window=5, win_type=""triang"").mean()
Out[72]: 
0    NaN
1    NaN
2    NaN
3    NaN
4    2.0
5    3.0
6    4.0
7    5.0
8    6.0
9    7.0
dtype: float64

# Supplementary Scipy arguments passed in the aggregation function
In [73]: s.rolling(window=5, win_type=""gaussian"").mean(std=0.1)
Out[73]: 
0    NaN
1    NaN
2    NaN
3    NaN
4    2.0
5    3.0
6    4.0
7    5.0
8    6.0
9    7.0
dtype: float64
",https://pandas.pydata.org/docs/user_guide/window.html, pandas.Series pandas.Series.rolling
"In [74]: df = pd.DataFrame(range(5))

In [75]: df.rolling(window=len(df), min_periods=1).mean()
Out[75]: 
     0
0  0.0
1  0.5
2  1.0
3  1.5
4  2.0

In [76]: df.expanding(min_periods=1).mean()
Out[76]: 
     0
0  0.0
1  0.5
2  1.0
3  1.5
4  2.0
",https://pandas.pydata.org/docs/user_guide/window.html, pandas.DataFrame pandas.DataFrame.rolling pandas.DataFrame.expanding
"In [77]: df = pd.DataFrame({""B"": [0, 1, 2, np.nan, 4]})

In [78]: df
Out[78]: 
     B
0  0.0
1  1.0
2  2.0
3  NaN
4  4.0

In [79]: times = [""2020-01-01"", ""2020-01-03"", ""2020-01-10"", ""2020-01-15"", ""2020-01-17""]

In [80]: df.ewm(halflife=""4 days"", times=pd.DatetimeIndex(times)).mean()
Out[80]: 
          B
0  0.000000
1  0.585786
2  1.523889
3  1.523889
4  3.233686
",https://pandas.pydata.org/docs/user_guide/window.html, pandas.DataFrame pandas.DataFrame.ewm pandas.DatetimeIndex
">>> s = pd.Series(np.random.uniform(size=100))
>>> pd.plotting.bootstrap_plot(s)  

",https://pandas.pydata.org/docs/reference/api/pandas.plotting.bootstrap_plot.html, pandas.Series pandas.plotting.bootstrap_plot
">>> pd.plotting.register_matplotlib_converters()
",https://pandas.pydata.org/docs/reference/api/pandas.plotting.register_matplotlib_converters.html, pandas.plotting.register_matplotlib_converters
">>> df = pd.DataFrame({'ts': pd.period_range('2020', periods=2, freq='M'),
...                    'y': [1, 2]
...                    })
>>> plot = df.plot.line(x='ts', y='y')
",https://pandas.pydata.org/docs/reference/api/pandas.plotting.register_matplotlib_converters.html, pandas.DataFrame pandas.period_range pandas.DataFrame.plot.line
">>> pd.set_option(""plotting.matplotlib.register_converters"",
...               False)  
>>> df.plot.line(x='ts', y='y')  
Traceback (most recent call last):
TypeError: float() argument must be a string or a real number, not 'Period'
",https://pandas.pydata.org/docs/reference/api/pandas.plotting.register_matplotlib_converters.html, pandas.DataFrame.plot.line
"In [3]: np.random.seed(123456)

In [4]: ts = pd.Series(np.random.randn(1000), index=pd.date_range(""1/1/2000"", periods=1000))

In [5]: ts = ts.cumsum()

In [6]: ts.plot();
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.Series pandas.date_range pandas.Series.cumsum pandas.Series.plot
"In [7]: df = pd.DataFrame(np.random.randn(1000, 4), index=ts.index, columns=list(""ABCD""))

In [8]: df = df.cumsum()

In [9]: plt.figure();

In [10]: df.plot();
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.DataFrame pandas.DataFrame.cumsum pandas.DataFrame.plot
"In [11]: df3 = pd.DataFrame(np.random.randn(1000, 2), columns=[""B"", ""C""]).cumsum()

In [12]: df3[""A""] = pd.Series(list(range(len(df))))

In [13]: df3.plot(x=""A"", y=""B"");
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.DataFrame pandas.Series pandas.DataFrame.plot
"In [16]: df = pd.DataFrame()

In [17]: df.plot.<TAB>  # noqa: E225, E999
df.plot.area     df.plot.barh     df.plot.density  df.plot.hist     df.plot.line     df.plot.scatter
df.plot.bar      df.plot.box      df.plot.hexbin   df.plot.kde      df.plot.pie
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.DataFrame
"In [21]: df2 = pd.DataFrame(np.random.rand(10, 4), columns=[""a"", ""b"", ""c"", ""d""])

In [22]: df2.plot.bar();
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.DataFrame pandas.DataFrame.plot.bar
"In [23]: df2.plot.bar(stacked=True);
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.DataFrame.plot.bar
"In [24]: df2.plot.barh(stacked=True);
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.DataFrame.plot.barh
"In [25]: df4 = pd.DataFrame(
   ....:     {
   ....:         ""a"": np.random.randn(1000) + 1,
   ....:         ""b"": np.random.randn(1000),
   ....:         ""c"": np.random.randn(1000) - 1,
   ....:     },
   ....:     columns=[""a"", ""b"", ""c""],
   ....: )
   ....: 

In [26]: plt.figure();

In [27]: df4.plot.hist(alpha=0.5);
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.DataFrame pandas.DataFrame.plot.hist
"In [28]: plt.figure();

In [29]: df4.plot.hist(stacked=True, bins=20);
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.DataFrame.plot.hist
"In [34]: plt.figure();

In [35]: df.diff().hist(color=""k"", alpha=0.5, bins=50);
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.DataFrame.diff
"In [36]: data = pd.Series(np.random.randn(1000))

In [37]: data.hist(by=np.random.randint(0, 4, 1000), figsize=(6, 4));
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.Series pandas.Series.hist
"In [38]: data = pd.DataFrame(
   ....:     {
   ....:         ""a"": np.random.choice([""x"", ""y"", ""z""], 1000),
   ....:         ""b"": np.random.choice([""e"", ""f"", ""g""], 1000),
   ....:         ""c"": np.random.randn(1000),
   ....:         ""d"": np.random.randn(1000) - 1,
   ....:     },
   ....: )
   ....: 

In [39]: data.plot.hist(by=[""a"", ""b""], figsize=(10, 5));
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.DataFrame pandas.DataFrame.plot.hist
"In [40]: df = pd.DataFrame(np.random.rand(10, 5), columns=[""A"", ""B"", ""C"", ""D"", ""E""])

In [41]: df.plot.box();
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.DataFrame pandas.DataFrame.plot.box
"In [42]: color = {
   ....:     ""boxes"": ""DarkGreen"",
   ....:     ""whiskers"": ""DarkOrange"",
   ....:     ""medians"": ""DarkBlue"",
   ....:     ""caps"": ""Gray"",
   ....: }
   ....: 

In [43]: df.plot.box(color=color, sym=""r+"");
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.DataFrame.plot.box
"In [44]: df.plot.box(vert=False, positions=[1, 4, 5, 6, 8]);
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.DataFrame.plot.box
"In [45]: df = pd.DataFrame(np.random.rand(10, 5))

In [46]: plt.figure();

In [47]: bp = df.boxplot()
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.DataFrame pandas.DataFrame.boxplot
"In [48]: df = pd.DataFrame(np.random.rand(10, 2), columns=[""Col1"", ""Col2""])

In [49]: df[""X""] = pd.Series([""A"", ""A"", ""A"", ""A"", ""A"", ""B"", ""B"", ""B"", ""B"", ""B""])

In [50]: plt.figure();

In [51]: bp = df.boxplot(by=""X"")
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.DataFrame pandas.Series pandas.DataFrame.boxplot
"In [52]: df = pd.DataFrame(np.random.rand(10, 3), columns=[""Col1"", ""Col2"", ""Col3""])

In [53]: df[""X""] = pd.Series([""A"", ""A"", ""A"", ""A"", ""A"", ""B"", ""B"", ""B"", ""B"", ""B""])

In [54]: df[""Y""] = pd.Series([""A"", ""B"", ""A"", ""B"", ""A"", ""B"", ""A"", ""B"", ""A"", ""B""])

In [55]: plt.figure();

In [56]: bp = df.boxplot(column=[""Col1"", ""Col2""], by=[""X"", ""Y""])
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.DataFrame pandas.Series pandas.DataFrame.boxplot
"In [57]: df = pd.DataFrame(np.random.rand(10, 3), columns=[""Col1"", ""Col2"", ""Col3""])

In [58]: df[""X""] = pd.Series([""A"", ""A"", ""A"", ""A"", ""A"", ""B"", ""B"", ""B"", ""B"", ""B""])

In [59]: plt.figure();

In [60]: bp = df.plot.box(column=[""Col1"", ""Col2""], by=""X"")
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.DataFrame pandas.Series pandas.DataFrame.plot.box
"In [61]: np.random.seed(1234)

In [62]: df_box = pd.DataFrame(np.random.randn(50, 2))

In [63]: df_box[""g""] = np.random.choice([""A"", ""B""], size=50)

In [64]: df_box.loc[df_box[""g""] == ""B"", 1] += 3

In [65]: bp = df_box.boxplot(by=""g"")
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.DataFrame pandas.DataFrame.boxplot
"In [66]: bp = df_box.groupby(""g"").boxplot()
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.DataFrame.groupby
"In [67]: df = pd.DataFrame(np.random.rand(10, 4), columns=[""a"", ""b"", ""c"", ""d""])

In [68]: df.plot.area();
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.DataFrame pandas.DataFrame.plot.area
"In [69]: df.plot.area(stacked=False);
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.DataFrame.plot.area
"In [70]: df = pd.DataFrame(np.random.rand(50, 4), columns=[""a"", ""b"", ""c"", ""d""])

In [71]: df[""species""] = pd.Categorical(
   ....:     [""setosa""] * 20 + [""versicolor""] * 20 + [""virginica""] * 10
   ....: )
   ....: 

In [72]: df.plot.scatter(x=""a"", y=""b"");
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.DataFrame pandas.Categorical pandas.DataFrame.plot.scatter
"In [73]: ax = df.plot.scatter(x=""a"", y=""b"", color=""DarkBlue"", label=""Group 1"")

In [74]: df.plot.scatter(x=""c"", y=""d"", color=""DarkGreen"", label=""Group 2"", ax=ax);
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.DataFrame.plot.scatter
"In [75]: df.plot.scatter(x=""a"", y=""b"", c=""c"", s=50);
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.DataFrame.plot.scatter
"In [76]: df.plot.scatter(x=""a"", y=""b"", c=""species"", cmap=""viridis"", s=50);
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.DataFrame.plot.scatter
"In [77]: df.plot.scatter(x=""a"", y=""b"", s=df[""c""] * 200);
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.DataFrame.plot.scatter
"In [78]: df = pd.DataFrame(np.random.randn(1000, 2), columns=[""a"", ""b""])

In [79]: df[""b""] = df[""b""] + np.arange(1000)

In [80]: df.plot.hexbin(x=""a"", y=""b"", gridsize=25);
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.DataFrame pandas.DataFrame.plot.hexbin
"In [81]: df = pd.DataFrame(np.random.randn(1000, 2), columns=[""a"", ""b""])

In [82]: df[""b""] = df[""b""] + np.arange(1000)

In [83]: df[""z""] = np.random.uniform(0, 3, 1000)

In [84]: df.plot.hexbin(x=""a"", y=""b"", C=""z"", reduce_C_function=np.max, gridsize=25);
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.DataFrame pandas.DataFrame.plot.hexbin
"In [85]: series = pd.Series(3 * np.random.rand(4), index=[""a"", ""b"", ""c"", ""d""], name=""series"")

In [86]: series.plot.pie(figsize=(6, 6));
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.Series pandas.Series.plot.pie
"In [87]: df = pd.DataFrame(
   ....:     3 * np.random.rand(4, 2), index=[""a"", ""b"", ""c"", ""d""], columns=[""x"", ""y""]
   ....: )
   ....: 

In [88]: df.plot.pie(subplots=True, figsize=(8, 4));
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.DataFrame pandas.DataFrame.plot.pie
"In [89]: series.plot.pie(
   ....:     labels=[""AA"", ""BB"", ""CC"", ""DD""],
   ....:     colors=[""r"", ""g"", ""b"", ""c""],
   ....:     autopct=""%.2f"",
   ....:     fontsize=20,
   ....:     figsize=(6, 6),
   ....: );
   ....: 
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.Series.plot.pie
"In [90]: series = pd.Series([0.1] * 4, index=[""a"", ""b"", ""c"", ""d""], name=""series2"")

In [91]: series.plot.pie(figsize=(6, 6));
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.Series pandas.Series.plot.pie
"In [92]: from pandas.plotting import scatter_matrix

In [93]: df = pd.DataFrame(np.random.randn(1000, 4), columns=[""a"", ""b"", ""c"", ""d""])

In [94]: scatter_matrix(df, alpha=0.2, figsize=(6, 6), diagonal=""kde"");
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.DataFrame pandas.plotting.scatter_matrix
"In [95]: ser = pd.Series(np.random.randn(1000))

In [96]: ser.plot.kde();
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.Series pandas.Series.plot.kde
"In [97]: from pandas.plotting import andrews_curves

In [98]: data = pd.read_csv(""data/iris.data"")

In [99]: plt.figure();

In [100]: andrews_curves(data, ""Name"");
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.read_csv pandas.plotting.andrews_curves
"In [101]: from pandas.plotting import parallel_coordinates

In [102]: data = pd.read_csv(""data/iris.data"")

In [103]: plt.figure();

In [104]: parallel_coordinates(data, ""Name"");
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.read_csv pandas.plotting.parallel_coordinates
"In [105]: from pandas.plotting import lag_plot

In [106]: plt.figure();

In [107]: spacing = np.linspace(-99 * np.pi, 99 * np.pi, num=1000)

In [108]: data = pd.Series(0.1 * np.random.rand(1000) + 0.9 * np.sin(spacing))

In [109]: lag_plot(data);
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.Series pandas.plotting.lag_plot
"In [110]: from pandas.plotting import autocorrelation_plot

In [111]: plt.figure();

In [112]: spacing = np.linspace(-9 * np.pi, 9 * np.pi, num=1000)

In [113]: data = pd.Series(0.7 * np.random.rand(1000) + 0.3 * np.sin(spacing))

In [114]: autocorrelation_plot(data);
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.Series pandas.plotting.autocorrelation_plot
"In [115]: from pandas.plotting import bootstrap_plot

In [116]: data = pd.Series(np.random.rand(1000))

In [117]: bootstrap_plot(data, size=50, samples=500, color=""grey"");
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.Series pandas.plotting.bootstrap_plot
"In [118]: from pandas.plotting import radviz

In [119]: data = pd.read_csv(""data/iris.data"")

In [120]: plt.figure();

In [121]: radviz(data, ""Name"");
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.read_csv pandas.plotting.radviz
"In [122]: plt.figure();

In [123]: ts.plot(style=""k--"", label=""Series"");
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.Series.plot
"In [124]: df = pd.DataFrame(np.random.randn(1000, 4), index=ts.index, columns=list(""ABCD""))

In [125]: df = df.cumsum()

In [126]: df.plot(legend=False);
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.DataFrame pandas.DataFrame.cumsum pandas.DataFrame.plot
"In [127]: df.plot();

In [128]: df.plot(xlabel=""new x"", ylabel=""new y"");
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.DataFrame.plot
"In [129]: ts = pd.Series(np.random.randn(1000), index=pd.date_range(""1/1/2000"", periods=1000))

In [130]: ts = np.exp(ts.cumsum())

In [131]: ts.plot(logy=True);
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.Series pandas.date_range pandas.Series.cumsum pandas.Series.plot
"In [134]: plt.figure();

In [135]: ax = df.plot(secondary_y=[""A"", ""B""])

In [136]: ax.set_ylabel(""CD scale"");

In [137]: ax.right_ax.set_ylabel(""AB scale"");
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.DataFrame.plot
"In [138]: plt.figure();

In [139]: df.plot(secondary_y=[""A"", ""B""], mark_right=False);
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.DataFrame.plot
"In [146]: df.plot(subplots=True, figsize=(6, 6));
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.DataFrame.plot
"In [147]: df.plot(subplots=True, layout=(2, 3), figsize=(6, 6), sharex=False);
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.DataFrame.plot
"In [148]: df.plot(subplots=True, layout=(2, -1), figsize=(6, 6), sharex=False);
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.DataFrame.plot
"In [149]: fig, axes = plt.subplots(4, 4, figsize=(9, 9))

In [150]: plt.subplots_adjust(wspace=0.5, hspace=0.5)

In [151]: target1 = [axes[0][0], axes[1][1], axes[2][2], axes[3][3]]

In [152]: target2 = [axes[3][0], axes[2][1], axes[1][2], axes[0][3]]

In [153]: df.plot(subplots=True, ax=target1, legend=False, sharex=False, sharey=False);

In [154]: (-df).plot(subplots=True, ax=target2, legend=False, sharex=False, sharey=False);
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.DataFrame.plot
"In [155]: np.random.seed(123456)

In [156]: ts = pd.Series(np.random.randn(1000), index=pd.date_range(""1/1/2000"", periods=1000))

In [157]: ts = ts.cumsum()

In [158]: df = pd.DataFrame(np.random.randn(1000, 4), index=ts.index, columns=list(""ABCD""))

In [159]: df = df.cumsum()
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.Series pandas.date_range pandas.Series.cumsum pandas.DataFrame pandas.DataFrame.cumsum
"# Generate the data
In [170]: ix3 = pd.MultiIndex.from_arrays(
   .....:     [
   .....:         [""a"", ""a"", ""a"", ""a"", ""a"", ""b"", ""b"", ""b"", ""b"", ""b""],
   .....:         [""foo"", ""foo"", ""foo"", ""bar"", ""bar"", ""foo"", ""foo"", ""bar"", ""bar"", ""bar""],
   .....:     ],
   .....:     names=[""letter"", ""word""],
   .....: )
   .....: 

In [171]: df3 = pd.DataFrame(
   .....:     {
   .....:         ""data1"": [9, 3, 2, 4, 3, 2, 4, 6, 3, 2],
   .....:         ""data2"": [9, 6, 5, 7, 5, 4, 5, 6, 5, 1],
   .....:     },
   .....:     index=ix3,
   .....: )
   .....: 

# Group by index labels and take the means and standard deviations
# for each group
In [172]: gp3 = df3.groupby(level=(""letter"", ""word""))

In [173]: means = gp3.mean()

In [174]: errors = gp3.std()

In [175]: means
Out[175]: 
                data1     data2
letter word                    
a      bar   3.500000  6.000000
       foo   4.666667  6.666667
b      bar   3.666667  4.000000
       foo   3.000000  4.500000

In [176]: errors
Out[176]: 
                data1     data2
letter word                    
a      bar   0.707107  1.414214
       foo   3.785939  2.081666
b      bar   2.081666  2.645751
       foo   1.414214  0.707107

# Plot
In [177]: fig, ax = plt.subplots()

In [178]: means.plot.bar(yerr=errors, ax=ax, capsize=4, rot=0);
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.MultiIndex.from_arrays pandas.DataFrame pandas.DataFrame.groupby
"In [184]: np.random.seed(123456)

In [185]: fig, ax = plt.subplots(1, 1, figsize=(7, 6.5))

In [186]: df = pd.DataFrame(np.random.rand(5, 3), columns=[""a"", ""b"", ""c""])

In [187]: ax.xaxis.tick_top()  # Display x-axis ticks on top.

In [188]: df.plot(table=True, ax=ax);
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.DataFrame pandas.DataFrame.plot
"In [189]: fig, ax = plt.subplots(1, 1, figsize=(7, 6.75))

In [190]: ax.xaxis.tick_top()  # Display x-axis ticks on top.

In [191]: df.plot(table=np.round(df.T, 2), ax=ax);
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.DataFrame.plot
"In [192]: from pandas.plotting import table

In [193]: fig, ax = plt.subplots(1, 1)

In [194]: table(ax, np.round(df.describe(), 2), loc=""upper right"", colWidths=[0.2, 0.2, 0.2]);

In [195]: df.plot(ax=ax, ylim=(0, 2), legend=None);
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.plotting.table pandas.DataFrame.describe pandas.DataFrame.plot
"In [196]: np.random.seed(123456)

In [197]: df = pd.DataFrame(np.random.randn(1000, 10), index=ts.index)

In [198]: df = df.cumsum()

In [199]: plt.figure();

In [200]: df.plot(colormap=""cubehelix"");
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.DataFrame pandas.DataFrame.cumsum pandas.DataFrame.plot
"In [201]: from matplotlib import cm

In [202]: plt.figure();

In [203]: df.plot(colormap=cm.cubehelix);
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.DataFrame.plot
"In [204]: np.random.seed(123456)

In [205]: dd = pd.DataFrame(np.random.randn(10, 10)).map(abs)

In [206]: dd = dd.cumsum()

In [207]: plt.figure();

In [208]: dd.plot.bar(colormap=""Greens"");
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.DataFrame pandas.DataFrame.cumsum pandas.DataFrame.plot.bar
"In [209]: plt.figure();

In [210]: parallel_coordinates(data, ""Name"", colormap=""gist_rainbow"");
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.plotting.parallel_coordinates
"In [211]: plt.figure();

In [212]: andrews_curves(data, ""Name"", colormap=""winter"");
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.plotting.andrews_curves
"In [213]: np.random.seed(123456)

In [214]: price = pd.Series(
   .....:     np.random.randn(150).cumsum(),
   .....:     index=pd.date_range(""2000-1-1"", periods=150, freq=""B""),
   .....: )
   .....: 

In [215]: ma = price.rolling(20).mean()

In [216]: mstd = price.rolling(20).std()

In [217]: plt.figure();

In [218]: plt.plot(price.index, price, ""k"");

In [219]: plt.plot(ma.index, ma, ""b"");

In [220]: plt.fill_between(mstd.index, ma - 2 * mstd, ma + 2 * mstd, color=""b"", alpha=0.2);
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.Series pandas.date_range pandas.Series.rolling
">>> Series([1, 2, 3]).plot(backend=""backend.module"")
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.Series
">>> pd.set_option(""plotting.backend"", ""backend.module"")
>>> pd.Series([1, 2, 3]).plot()
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.Series
">>> pd.options.plotting.backend = ""backend.module""
>>> pd.Series([1, 2, 3]).plot()
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.Series
">>> import backend.module
>>> backend.module.plot(pd.Series([1, 2, 3]))
",https://pandas.pydata.org/docs/user_guide/visualization.html, pandas.Series
">>> pd.arrays.NumpyExtensionArray(np.array([0, 1, 2, 3]))

[0, 1, 2, 3]
Length: 4, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.arrays.NumpyExtensionArray.html, pandas.arrays.NumpyExtensionArray
">>> np.random.seed(5)
>>> x = np.cumsum(np.random.normal(loc=1, scale=5, size=50))
>>> s = pd.Series(x)
>>> s.plot()  
",https://pandas.pydata.org/docs/reference/api/pandas.plotting.lag_plot.html, pandas.Series pandas.Series.plot
">>> pd.plotting.lag_plot(s, lag=1)

",https://pandas.pydata.org/docs/reference/api/pandas.plotting.lag_plot.html, pandas.plotting.lag_plot
"import pandas as pd
assert pd.Series([1, 1]).sum() == 2
",https://pandas.pydata.org/docs/development/maintaining.html, pandas.Series
"In [1]: dates = pd.date_range('1/1/2000', periods=8)

In [2]: df = pd.DataFrame(np.random.randn(8, 4),
   ...:                   index=dates, columns=['A', 'B', 'C', 'D'])
   ...: 

In [3]: df
Out[3]: 
                   A         B         C         D
2000-01-01  0.469112 -0.282863 -1.509059 -1.135632
2000-01-02  1.212112 -0.173215  0.119209 -1.044236
2000-01-03 -0.861849 -2.104569 -0.494929  1.071804
2000-01-04  0.721555 -0.706771 -1.039575  0.271860
2000-01-05 -0.424972  0.567020  0.276232 -1.087401
2000-01-06 -0.673690  0.113648 -1.478427  0.524988
2000-01-07  0.404705  0.577046 -1.715002 -1.039268
2000-01-08 -0.370647 -1.157892 -1.344312  0.844885
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.date_range pandas.DataFrame
"In [17]: sa = pd.Series([1, 2, 3], index=list('abc'))

In [18]: dfa = df.copy()
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.Series pandas.DataFrame.copy
"In [27]: x = pd.DataFrame({'x': [1, 2, 3], 'y': [3, 4, 5]})

In [28]: x.iloc[1] = {'x': 9, 'y': 99}

In [29]: x
Out[29]: 
   x   y
0  1   3
1  9  99
2  3   5
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.DataFrame
"In [30]: df_new = pd.DataFrame({'one': [1., 2., 3.]})

In [31]: df_new.two = [4, 5, 6]

In [32]: df_new
Out[32]: 
   one
0  1.0
1  2.0
2  3.0
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.DataFrame
"In [36]: s2 = s.copy()

In [37]: s2[:5] = 0

In [38]: s2
Out[38]: 
2000-01-01    0.000000
2000-01-02    0.000000
2000-01-03    0.000000
2000-01-04    0.000000
2000-01-05    0.000000
2000-01-06   -0.673690
2000-01-07    0.404705
2000-01-08   -0.370647
Freq: D, Name: A, dtype: float64
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.Series.copy
"In [41]: dfl = pd.DataFrame(np.random.randn(5, 4),
   ....:                    columns=list('ABCD'),
   ....:                    index=pd.date_range('20130101', periods=5))
   ....: 

In [42]: dfl
Out[42]: 
                   A         B         C         D
2013-01-01  1.075770 -0.109050  1.643563 -1.469388
2013-01-02  0.357021 -0.674600 -1.776904 -0.968914
2013-01-03 -1.294524  0.413738  0.276662 -0.472035
2013-01-04 -0.013960 -0.362543 -0.006154 -0.923061
2013-01-05  0.895717  0.805244 -1.206412  2.565646

In [43]: dfl.loc[2:3]
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
Cell In[43], line 1
----> 1 dfl.loc[2:3]

File ~/work/pandas/pandas/pandas/core/indexing.py:1191, in _LocationIndexer.__getitem__(self, key)
   1189 maybe_callable = com.apply_if_callable(key, self.obj)
   1190 maybe_callable = self._check_deprecated_callable_usage(key, maybe_callable)
-> 1191 return self._getitem_axis(maybe_callable, axis=axis)

File ~/work/pandas/pandas/pandas/core/indexing.py:1411, in _LocIndexer._getitem_axis(self, key, axis)
   1409 if isinstance(key, slice):
   1410     self._validate_key(key, axis)
-> 1411     return self._get_slice_axis(key, axis=axis)
   1412 elif com.is_bool_indexer(key):
   1413     return self._getbool_axis(key, axis=axis)

File ~/work/pandas/pandas/pandas/core/indexing.py:1443, in _LocIndexer._get_slice_axis(self, slice_obj, axis)
   1440     return obj.copy(deep=False)
   1442 labels = obj._get_axis(axis)
-> 1443 indexer = labels.slice_indexer(slice_obj.start, slice_obj.stop, slice_obj.step)
   1445 if isinstance(indexer, slice):
   1446     return self.obj._slice(indexer, axis=axis)

File ~/work/pandas/pandas/pandas/core/indexes/datetimes.py:682, in DatetimeIndex.slice_indexer(self, start, end, step)
    674 # GH#33146 if start and end are combinations of str and None and Index is not
    675 # monotonic, we can not use Index.slice_indexer because it does not honor the
    676 # actual elements, is only searching for start and end
    677 if (
    678     check_str_or_none(start)
    679     or check_str_or_none(end)
    680     or self.is_monotonic_increasing
    681 ):
--> 682     return Index.slice_indexer(self, start, end, step)
    684 mask = np.array(True)
    685 in_index = True

File ~/work/pandas/pandas/pandas/core/indexes/base.py:6662, in Index.slice_indexer(self, start, end, step)
   6618 def slice_indexer(
   6619     self,
   6620     start: Hashable | None = None,
   6621     end: Hashable | None = None,
   6622     step: int | None = None,
   6623 ) -> slice:
   6624     """"""
   6625     Compute the slice indexer for input labels and step.
   6626 
   (...)
   6660     slice(1, 3, None)
   6661     """"""
-> 6662     start_slice, end_slice = self.slice_locs(start, end, step=step)
   6664     # return a slice
   6665     if not is_scalar(start_slice):

File ~/work/pandas/pandas/pandas/core/indexes/base.py:6879, in Index.slice_locs(self, start, end, step)
   6877 start_slice = None
   6878 if start is not None:
-> 6879     start_slice = self.get_slice_bound(start, ""left"")
   6880 if start_slice is None:
   6881     start_slice = 0

File ~/work/pandas/pandas/pandas/core/indexes/base.py:6794, in Index.get_slice_bound(self, label, side)
   6790 original_label = label
   6792 # For datetime indices label may be a string that has to be converted
   6793 # to datetime boundary according to its resolution.
-> 6794 label = self._maybe_cast_slice_bound(label, side)
   6796 # we need to look up the label
   6797 try:

File ~/work/pandas/pandas/pandas/core/indexes/datetimes.py:642, in DatetimeIndex._maybe_cast_slice_bound(self, label, side)
    637 if isinstance(label, dt.date) and not isinstance(label, dt.datetime):
    638     # Pandas supports slicing with dates, treated as datetimes at midnight.
    639     # https://github.com/pandas-dev/pandas/issues/31501
    640     label = Timestamp(label).to_pydatetime()
--> 642 label = super()._maybe_cast_slice_bound(label, side)
    643 self._data._assert_tzawareness_compat(label)
    644 return Timestamp(label)

File ~/work/pandas/pandas/pandas/core/indexes/datetimelike.py:378, in DatetimeIndexOpsMixin._maybe_cast_slice_bound(self, label, side)
    376     return lower if side == ""left"" else upper
    377 elif not isinstance(label, self._data._recognized_scalars):
--> 378     self._raise_invalid_indexer(""slice"", label)
    380 return label

File ~/work/pandas/pandas/pandas/core/indexes/base.py:4301, in Index._raise_invalid_indexer(self, form, key, reraise)
   4299 if reraise is not lib.no_default:
   4300     raise TypeError(msg) from reraise
-> 4301 raise TypeError(msg)

TypeError: cannot do slice indexing on DatetimeIndex with these indexers [2] of type int
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.DataFrame pandas.date_range pandas.Index.slice_indexer pandas.Index.slice_indexer pandas.Index.slice_indexer pandas.Index.slice_indexer pandas.Series.str.slice pandas.Index.slice_locs pandas.api.types.is_scalar pandas.Index.slice_locs pandas.Index.get_slice_bound pandas.Index.get_slice_bound
"In [45]: s1 = pd.Series(np.random.randn(6), index=list('abcdef'))

In [46]: s1
Out[46]: 
a    1.431256
b    1.340309
c   -1.170299
d   -0.226169
e    0.410835
f    0.813850
dtype: float64

In [47]: s1.loc['c':]
Out[47]: 
c   -1.170299
d   -0.226169
e    0.410835
f    0.813850
dtype: float64

In [48]: s1.loc['b']
Out[48]: 1.3403088497993827
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.Series
"In [51]: df1 = pd.DataFrame(np.random.randn(6, 4),
   ....:                    index=list('abcdef'),
   ....:                    columns=list('ABCD'))
   ....: 

In [52]: df1
Out[52]: 
          A         B         C         D
a  0.132003 -0.827317 -0.076467 -1.187678
b  1.130127 -1.436737 -1.413681  1.607920
c  1.024180  0.569605  0.875906 -2.211372
d  0.974466 -2.006747 -0.410001 -0.078638
e  0.545952 -1.219217 -1.226825  0.769804
f -1.281247 -0.727707 -0.121306 -0.097883

In [53]: df1.loc[['a', 'b', 'd'], :]
Out[53]: 
          A         B         C         D
a  0.132003 -0.827317 -0.076467 -1.187678
b  1.130127 -1.436737 -1.413681  1.607920
d  0.974466 -2.006747 -0.410001 -0.078638
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.DataFrame
"In [58]: mask = pd.array([True, False, True, False, pd.NA, False], dtype=""boolean"")

In [59]: mask
Out[59]: 

[True, False, True, False, , False]
Length: 6, dtype: boolean

In [60]: df1[mask]
Out[60]: 
          A         B         C         D
a  0.132003 -0.827317 -0.076467 -1.187678
c  1.024180  0.569605  0.875906 -2.211372
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.array
"In [62]: s = pd.Series(list('abcde'), index=[0, 3, 2, 5, 4])

In [63]: s.loc[3:5]
Out[63]: 
3    b
2    c
5    d
dtype: object
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.Series
"In [64]: s.sort_index()
Out[64]: 
0    a
2    c
3    b
4    e
5    d
dtype: object

In [65]: s.sort_index().loc[1:6]
Out[65]: 
2    c
3    b
4    e
5    d
dtype: object
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.Series.sort_index
"In [66]: s = pd.Series(list('abcdef'), index=[0, 3, 2, 5, 4, 2])

In [67]: s.loc[3:5]
Out[67]: 
3    b
2    c
5    d
dtype: object
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.Series
"In [68]: s1 = pd.Series(np.random.randn(5), index=list(range(0, 10, 2)))

In [69]: s1
Out[69]: 
0    0.695775
2    0.341734
4    0.959726
6   -1.110336
8   -0.619976
dtype: float64

In [70]: s1.iloc[:3]
Out[70]: 
0    0.695775
2    0.341734
4    0.959726
dtype: float64

In [71]: s1.iloc[3]
Out[71]: -1.110336102891167
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.Series
"In [74]: df1 = pd.DataFrame(np.random.randn(6, 4),
   ....:                    index=list(range(0, 12, 2)),
   ....:                    columns=list(range(0, 8, 2)))
   ....: 

In [75]: df1
Out[75]: 
           0         2         4         6
0   0.149748 -0.732339  0.687738  0.176444
2   0.403310 -0.154951  0.301624 -2.179861
4  -1.369849 -0.954208  1.462696 -1.743161
6  -0.826591 -0.345352  1.314232  0.690579
8   0.995761  2.396780  0.014871  3.357427
10 -0.317441 -1.236269  0.896171 -0.487602
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.DataFrame
"# these are allowed in Python/NumPy.
In [83]: x = list('abcdef')

In [84]: x
Out[84]: ['a', 'b', 'c', 'd', 'e', 'f']

In [85]: x[4:10]
Out[85]: ['e', 'f']

In [86]: x[8:10]
Out[86]: []

In [87]: s = pd.Series(x)

In [88]: s
Out[88]: 
0    a
1    b
2    c
3    d
4    e
5    f
dtype: object

In [89]: s.iloc[4:10]
Out[89]: 
4    e
5    f
dtype: object

In [90]: s.iloc[8:10]
Out[90]: Series([], dtype: object)
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.Series pandas.Series
"In [91]: dfl = pd.DataFrame(np.random.randn(5, 2), columns=list('AB'))

In [92]: dfl
Out[92]: 
          A         B
0 -0.082240 -2.182937
1  0.380396  0.084844
2  0.432390  1.519970
3 -0.493662  0.600178
4  0.274230  0.132885

In [93]: dfl.iloc[:, 2:3]
Out[93]: 
Empty DataFrame
Columns: []
Index: [0, 1, 2, 3, 4]

In [94]: dfl.iloc[:, 1:3]
Out[94]: 
          B
0 -2.182937
1  0.084844
2  1.519970
3  0.600178
4  0.132885

In [95]: dfl.iloc[4:6]
Out[95]: 
         A         B
4  0.27423  0.132885
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.DataFrame
"In [97]: dfl.iloc[:, 4]
---------------------------------------------------------------------------
IndexError                                Traceback (most recent call last)
Cell In[97], line 1
----> 1 dfl.iloc[:, 4]

File ~/work/pandas/pandas/pandas/core/indexing.py:1184, in _LocationIndexer.__getitem__(self, key)
   1182     if self._is_scalar_access(key):
   1183         return self.obj._get_value(*key, takeable=self._takeable)
-> 1184     return self._getitem_tuple(key)
   1185 else:
   1186     # we by definition only have the 0th axis
   1187     axis = self.axis or 0

File ~/work/pandas/pandas/pandas/core/indexing.py:1690, in _iLocIndexer._getitem_tuple(self, tup)
   1689 def _getitem_tuple(self, tup: tuple):
-> 1690     tup = self._validate_tuple_indexer(tup)
   1691     with suppress(IndexingError):
   1692         return self._getitem_lowerdim(tup)

File ~/work/pandas/pandas/pandas/core/indexing.py:966, in _LocationIndexer._validate_tuple_indexer(self, key)
    964 for i, k in enumerate(key):
    965     try:
--> 966         self._validate_key(k, i)
    967     except ValueError as err:
    968         raise ValueError(
    969             ""Location based indexing can only have ""
    970             f""[{self._valid_types}] types""
    971         ) from err

File ~/work/pandas/pandas/pandas/core/indexing.py:1592, in _iLocIndexer._validate_key(self, key, axis)
   1590     return
   1591 elif is_integer(key):
-> 1592     self._validate_integer(key, axis)
   1593 elif isinstance(key, tuple):
   1594     # a tuple should already have been caught by this point
   1595     # so don't treat a tuple as a valid indexer
   1596     raise IndexingError(""Too many indexers"")

File ~/work/pandas/pandas/pandas/core/indexing.py:1685, in _iLocIndexer._validate_integer(self, key, axis)
   1683 len_axis = len(self.obj._get_axis(axis))
   1684 if key >= len_axis or key < -len_axis:
-> 1685     raise IndexError(""single positional indexer is out-of-bounds"")

IndexError: single positional indexer is out-of-bounds
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.api.types.is_integer pandas.errors.IndexingError
"In [98]: df1 = pd.DataFrame(np.random.randn(6, 4),
   ....:                    index=list('abcdef'),
   ....:                    columns=list('ABCD'))
   ....: 

In [99]: df1
Out[99]: 
          A         B         C         D
a -0.023688  2.410179  1.450520  0.206053
b -0.251905 -2.213588  1.063327  1.266143
c  0.299368 -0.863838  0.408204 -1.048089
d -0.025747 -0.988387  0.094055  1.262731
e  1.289997  0.082423 -0.055758  0.536580
f -0.489682  0.369374 -0.034571 -2.484478

In [100]: df1.loc[lambda df: df['A'] > 0, :]
Out[100]: 
          A         B         C         D
c  0.299368 -0.863838  0.408204 -1.048089
e  1.289997  0.082423 -0.055758  0.536580

In [101]: df1.loc[:, lambda df: ['A', 'B']]
Out[101]: 
          A         B
a -0.023688  2.410179
b -0.251905 -2.213588
c  0.299368 -0.863838
d -0.025747 -0.988387
e  1.289997  0.082423
f -0.489682  0.369374

In [102]: df1.iloc[:, lambda df: [0, 1]]
Out[102]: 
          A         B
a -0.023688  2.410179
b -0.251905 -2.213588
c  0.299368 -0.863838
d -0.025747 -0.988387
e  1.289997  0.082423
f -0.489682  0.369374

In [103]: df1[lambda df: df.columns[0]]
Out[103]: 
a   -0.023688
b   -0.251905
c    0.299368
d   -0.025747
e    1.289997
f   -0.489682
Name: A, dtype: float64
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.DataFrame
"In [105]: bb = pd.read_csv('data/baseball.csv', index_col='id')

In [106]: (bb.groupby(['year', 'team']).sum(numeric_only=True)
   .....:    .loc[lambda df: df['r'] > 100])
   .....: 
Out[106]: 
           stint    g    ab    r    h  X2b  ...     so   ibb   hbp    sh    sf  gidp
year team                                   ...                                     
2007 CIN       6  379   745  101  203   35  ...  127.0  14.0   1.0   1.0  15.0  18.0
     DET       5  301  1062  162  283   54  ...  176.0   3.0  10.0   4.0   8.0  28.0
     HOU       4  311   926  109  218   47  ...  212.0   3.0   9.0  16.0   6.0  17.0
     LAN      11  413  1021  153  293   61  ...  141.0   8.0   9.0   3.0   8.0  29.0
     NYN      13  622  1854  240  509  101  ...  310.0  24.0  23.0  18.0  15.0  48.0
     SFN       5  482  1305  198  337   67  ...  188.0  51.0   8.0  16.0   6.0  41.0
     TEX       2  198   729  115  200   40  ...  140.0   4.0   5.0   2.0   8.0  16.0
     TOR       4  459  1408  187  378   96  ...  265.0  16.0  12.0   4.0  16.0  38.0

[8 rows x 18 columns]
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.read_csv
"In [107]: dfd = pd.DataFrame({'A': [1, 2, 3],
   .....:                     'B': [4, 5, 6]},
   .....:                    index=list('abc'))
   .....: 

In [108]: dfd
Out[108]: 
   A  B
a  1  4
b  2  5
c  3  6

In [109]: dfd.loc[dfd.index[[0, 2]], 'A']
Out[109]: 
a    1
c    3
Name: A, dtype: int64
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.DataFrame
"In [112]: s = pd.Series([1, 2, 3])

In [113]: s.reindex([1, 2, 3])
Out[113]: 
1    2.0
2    3.0
3    NaN
dtype: float64
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.Series pandas.Series.reindex
"In [116]: s = pd.Series(np.arange(4), index=['a', 'a', 'b', 'c'])

In [117]: labels = ['c', 'd']

In [118]: s.reindex(labels)
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
Cell In[118], line 1
----> 1 s.reindex(labels)

File ~/work/pandas/pandas/pandas/core/series.py:5153, in Series.reindex(self, index, axis, method, copy, level, fill_value, limit, tolerance)
   5136 @doc(
   5137     NDFrame.reindex,  # type: ignore[has-type]
   5138     klass=_shared_doc_kwargs[""klass""],
   (...)
   5151     tolerance=None,
   5152 ) -> Series:
-> 5153     return super().reindex(
   5154         index=index,
   5155         method=method,
   5156         copy=copy,
   5157         level=level,
   5158         fill_value=fill_value,
   5159         limit=limit,
   5160         tolerance=tolerance,
   5161     )

File ~/work/pandas/pandas/pandas/core/generic.py:5610, in NDFrame.reindex(self, labels, index, columns, axis, method, copy, level, fill_value, limit, tolerance)
   5607     return self._reindex_multi(axes, copy, fill_value)
   5609 # perform the reindex on the axes
-> 5610 return self._reindex_axes(
   5611     axes, level, limit, tolerance, method, fill_value, copy
   5612 ).__finalize__(self, method=""reindex"")

File ~/work/pandas/pandas/pandas/core/generic.py:5633, in NDFrame._reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy)
   5630     continue
   5632 ax = self._get_axis(a)
-> 5633 new_index, indexer = ax.reindex(
   5634     labels, level=level, limit=limit, tolerance=tolerance, method=method
   5635 )
   5637 axis = self._get_axis_number(a)
   5638 obj = obj._reindex_with_indexers(
   5639     {axis: [new_index, indexer]},
   5640     fill_value=fill_value,
   5641     copy=copy,
   5642     allow_dups=False,
   5643 )

File ~/work/pandas/pandas/pandas/core/indexes/base.py:4429, in Index.reindex(self, target, method, level, limit, tolerance)
   4426     raise ValueError(""cannot handle a non-unique multi-index!"")
   4427 elif not self.is_unique:
   4428     # GH#42568
-> 4429     raise ValueError(""cannot reindex on an axis with duplicate labels"")
   4430 else:
   4431     indexer, _ = self.get_indexer_non_unique(target)

ValueError: cannot reindex on an axis with duplicate labels
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.Series pandas.Series.reindex pandas.Series.reindex pandas.Index.reindex pandas.Index.get_indexer_non_unique
"In [120]: labels = ['a', 'd']

In [121]: s.loc[s.index.intersection(labels)].reindex(labels)
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
Cell In[121], line 1
----> 1 s.loc[s.index.intersection(labels)].reindex(labels)

File ~/work/pandas/pandas/pandas/core/series.py:5153, in Series.reindex(self, index, axis, method, copy, level, fill_value, limit, tolerance)
   5136 @doc(
   5137     NDFrame.reindex,  # type: ignore[has-type]
   5138     klass=_shared_doc_kwargs[""klass""],
   (...)
   5151     tolerance=None,
   5152 ) -> Series:
-> 5153     return super().reindex(
   5154         index=index,
   5155         method=method,
   5156         copy=copy,
   5157         level=level,
   5158         fill_value=fill_value,
   5159         limit=limit,
   5160         tolerance=tolerance,
   5161     )

File ~/work/pandas/pandas/pandas/core/generic.py:5610, in NDFrame.reindex(self, labels, index, columns, axis, method, copy, level, fill_value, limit, tolerance)
   5607     return self._reindex_multi(axes, copy, fill_value)
   5609 # perform the reindex on the axes
-> 5610 return self._reindex_axes(
   5611     axes, level, limit, tolerance, method, fill_value, copy
   5612 ).__finalize__(self, method=""reindex"")

File ~/work/pandas/pandas/pandas/core/generic.py:5633, in NDFrame._reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy)
   5630     continue
   5632 ax = self._get_axis(a)
-> 5633 new_index, indexer = ax.reindex(
   5634     labels, level=level, limit=limit, tolerance=tolerance, method=method
   5635 )
   5637 axis = self._get_axis_number(a)
   5638 obj = obj._reindex_with_indexers(
   5639     {axis: [new_index, indexer]},
   5640     fill_value=fill_value,
   5641     copy=copy,
   5642     allow_dups=False,
   5643 )

File ~/work/pandas/pandas/pandas/core/indexes/base.py:4429, in Index.reindex(self, target, method, level, limit, tolerance)
   4426     raise ValueError(""cannot handle a non-unique multi-index!"")
   4427 elif not self.is_unique:
   4428     # GH#42568
-> 4429     raise ValueError(""cannot reindex on an axis with duplicate labels"")
   4430 else:
   4431     indexer, _ = self.get_indexer_non_unique(target)

ValueError: cannot reindex on an axis with duplicate labels
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.Series.reindex pandas.Index.reindex pandas.Index.get_indexer_non_unique
"In [122]: s = pd.Series([0, 1, 2, 3, 4, 5])

# When no arguments are passed, returns 1 row.
In [123]: s.sample()
Out[123]: 
4    4
dtype: int64

# One may specify either a number of rows:
In [124]: s.sample(n=3)
Out[124]: 
0    0
4    4
1    1
dtype: int64

# Or a fraction of the rows:
In [125]: s.sample(frac=0.5)
Out[125]: 
5    5
3    3
1    1
dtype: int64
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.Series pandas.Series.sample
"In [126]: s = pd.Series([0, 1, 2, 3, 4, 5])

# Without replacement (default):
In [127]: s.sample(n=6, replace=False)
Out[127]: 
0    0
1    1
5    5
3    3
2    2
4    4
dtype: int64

# With replacement:
In [128]: s.sample(n=6, replace=True)
Out[128]: 
0    0
4    4
3    3
2    2
4    4
4    4
dtype: int64
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.Series pandas.Series.sample
"In [129]: s = pd.Series([0, 1, 2, 3, 4, 5])

In [130]: example_weights = [0, 0, 0.2, 0.2, 0.2, 0.4]

In [131]: s.sample(n=3, weights=example_weights)
Out[131]: 
5    5
4    4
3    3
dtype: int64

# Weights will be re-normalized automatically
In [132]: example_weights2 = [0.5, 0, 0, 0, 0, 0]

In [133]: s.sample(n=1, weights=example_weights2)
Out[133]: 
0    0
dtype: int64
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.Series pandas.Series.sample
"In [134]: df2 = pd.DataFrame({'col1': [9, 8, 7, 6],
   .....:                     'weight_column': [0.5, 0.4, 0.1, 0]})
   .....: 

In [135]: df2.sample(n=3, weights='weight_column')
Out[135]: 
   col1  weight_column
1     8            0.4
0     9            0.5
2     7            0.1
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.DataFrame pandas.DataFrame.sample
"In [136]: df3 = pd.DataFrame({'col1': [1, 2, 3], 'col2': [2, 3, 4]})

In [137]: df3.sample(n=1, axis=1)
Out[137]: 
   col1
0     1
1     2
2     3
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.DataFrame pandas.DataFrame.sample
"In [138]: df4 = pd.DataFrame({'col1': [1, 2, 3], 'col2': [2, 3, 4]})

# With a given seed, the sample will always draw the same rows.
In [139]: df4.sample(n=2, random_state=2)
Out[139]: 
   col1  col2
2     3     4
1     2     3

In [140]: df4.sample(n=2, random_state=2)
Out[140]: 
   col1  col2
2     3     4
1     2     3
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.DataFrame pandas.DataFrame.sample
"In [141]: se = pd.Series([1, 2, 3])

In [142]: se
Out[142]: 
0    1
1    2
2    3
dtype: int64

In [143]: se[5] = 5.

In [144]: se
Out[144]: 
0    1.0
1    2.0
2    3.0
5    5.0
dtype: float64
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.Series
"In [145]: dfi = pd.DataFrame(np.arange(6).reshape(3, 2),
   .....:                    columns=['A', 'B'])
   .....: 

In [146]: dfi
Out[146]: 
   A  B
0  0  1
1  2  3
2  4  5

In [147]: dfi.loc[:, 'C'] = dfi.loc[:, 'A']

In [148]: dfi
Out[148]: 
   A  B  C
0  0  1  0
1  2  3  2
2  4  5  4
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.DataFrame
"In [158]: s = pd.Series(range(-3, 4))

In [159]: s
Out[159]: 
0   -3
1   -2
2   -1
3    0
4    1
5    2
6    3
dtype: int64

In [160]: s[s > 0]
Out[160]: 
4    1
5    2
6    3
dtype: int64

In [161]: s[(s < -1) | (s > 0.5)]
Out[161]: 
0   -3
1   -2
4    1
5    2
6    3
dtype: int64

In [162]: s[~(s < 0)]
Out[162]: 
3    0
4    1
5    2
6    3
dtype: int64
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.Series
"In [164]: df2 = pd.DataFrame({'a': ['one', 'one', 'two', 'three', 'two', 'one', 'six'],
   .....:                     'b': ['x', 'y', 'y', 'x', 'y', 'x', 'x'],
   .....:                     'c': np.random.randn(7)})
   .....: 

# only want 'two' or 'three'
In [165]: criterion = df2['a'].map(lambda x: x.startswith('t'))

In [166]: df2[criterion]
Out[166]: 
       a  b         c
2    two  y  0.041290
3  three  x  0.361719
4    two  y -0.238075

# equivalent but slower
In [167]: df2[[x.startswith('t') for x in df2['a']]]
Out[167]: 
       a  b         c
2    two  y  0.041290
3  three  x  0.361719
4    two  y -0.238075

# Multiple criteria
In [168]: df2[criterion & (df2['b'] == 'x')]
Out[168]: 
       a  b         c
3  three  x  0.361719
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.DataFrame
"In [170]: df = pd.DataFrame([[1, 2], [3, 4], [5, 6]],
   .....:                   index=list('abc'),
   .....:                   columns=['A', 'B'])
   .....: 

In [171]: s = (df['A'] > 2)

In [172]: s
Out[172]: 
a    False
b     True
c     True
Name: A, dtype: bool

In [173]: df.loc[s, 'B']
Out[173]: 
b    4
c    6
Name: B, dtype: int64

In [174]: df.iloc[s.values, 1]
Out[174]: 
b    4
c    6
Name: B, dtype: int64
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.DataFrame
"In [175]: s = pd.Series(np.arange(5), index=np.arange(5)[::-1], dtype='int64')

In [176]: s
Out[176]: 
4    0
3    1
2    2
1    3
0    4
dtype: int64

In [177]: s.isin([2, 4, 6])
Out[177]: 
4    False
3    False
2     True
1    False
0     True
dtype: bool

In [178]: s[s.isin([2, 4, 6])]
Out[178]: 
2    2
0    4
dtype: int64
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.Series pandas.Series.isin
"In [179]: s[s.index.isin([2, 4, 6])]
Out[179]: 
4    0
2    2
dtype: int64

# compare it to the following
In [180]: s.reindex([2, 4, 6])
Out[180]: 
2    2.0
4    0.0
6    NaN
dtype: float64
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.Series.reindex
"In [181]: s_mi = pd.Series(np.arange(6),
   .....:                  index=pd.MultiIndex.from_product([[0, 1], ['a', 'b', 'c']]))
   .....: 

In [182]: s_mi
Out[182]: 
0  a    0
   b    1
   c    2
1  a    3
   b    4
   c    5
dtype: int64

In [183]: s_mi.iloc[s_mi.index.isin([(1, 'a'), (2, 'b'), (0, 'c')])]
Out[183]: 
0  c    2
1  a    3
dtype: int64

In [184]: s_mi.iloc[s_mi.index.isin(['a', 'c', 'e'], level=1)]
Out[184]: 
0  a    0
   c    2
1  a    3
   c    5
dtype: int64
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.Series pandas.MultiIndex.from_product
"In [185]: df = pd.DataFrame({'vals': [1, 2, 3, 4], 'ids': ['a', 'b', 'f', 'n'],
   .....:                    'ids2': ['a', 'n', 'c', 'n']})
   .....: 

In [186]: values = ['a', 'b', 1, 3]

In [187]: df.isin(values)
Out[187]: 
    vals    ids   ids2
0   True   True   True
1  False   True  False
2   True  False  False
3  False  False  False
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.DataFrame pandas.DataFrame.isin
"In [188]: values = {'ids': ['a', 'b'], 'vals': [1, 3]}

In [189]: df.isin(values)
Out[189]: 
    vals    ids   ids2
0   True   True  False
1  False   True  False
2   True  False  False
3  False  False  False
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.DataFrame.isin
"In [190]: values = {'ids': ['a', 'b'], 'vals': [1, 3]}

In [191]: ~df.isin(values)
Out[191]: 
    vals    ids  ids2
0  False  False  True
1   True  False  True
2  False   True  True
3   True   True  True
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.DataFrame.isin
"In [192]: values = {'ids': ['a', 'b'], 'ids2': ['a', 'c'], 'vals': [1, 3]}

In [193]: row_mask = df.isin(values).all(1)

In [194]: df[row_mask]
Out[194]: 
   vals ids ids2
0     1   a    a
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.DataFrame.isin
"In [196]: s.where(s > 0)
Out[196]: 
4    NaN
3    1.0
2    2.0
1    3.0
0    4.0
dtype: float64
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.Series.where
"In [197]: dates = pd.date_range('1/1/2000', periods=8)

In [198]: df = pd.DataFrame(np.random.randn(8, 4),
   .....:                   index=dates, columns=['A', 'B', 'C', 'D'])
   .....: 

In [199]: df[df < 0]
Out[199]: 
                   A         B         C         D
2000-01-01 -2.104139 -1.309525       NaN       NaN
2000-01-02 -0.352480       NaN -1.192319       NaN
2000-01-03 -0.864883       NaN -0.227870       NaN
2000-01-04       NaN -1.222082       NaN -1.233203
2000-01-05       NaN -0.605656 -1.169184       NaN
2000-01-06       NaN -0.948458       NaN -0.684718
2000-01-07 -2.670153 -0.114722       NaN -0.048048
2000-01-08       NaN       NaN -0.048788 -0.808838
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.date_range pandas.DataFrame
"In [200]: df.where(df < 0, -df)
Out[200]: 
                   A         B         C         D
2000-01-01 -2.104139 -1.309525 -0.485855 -0.245166
2000-01-02 -0.352480 -0.390389 -1.192319 -1.655824
2000-01-03 -0.864883 -0.299674 -0.227870 -0.281059
2000-01-04 -0.846958 -1.222082 -0.600705 -1.233203
2000-01-05 -0.669692 -0.605656 -1.169184 -0.342416
2000-01-06 -0.868584 -0.948458 -2.297780 -0.684718
2000-01-07 -2.670153 -0.114722 -0.168904 -0.048048
2000-01-08 -0.801196 -1.392071 -0.048788 -0.808838
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.DataFrame.where
"In [201]: s2 = s.copy()

In [202]: s2[s2 < 0] = 0

In [203]: s2
Out[203]: 
4    0
3    1
2    2
1    3
0    4
dtype: int64

In [204]: df2 = df.copy()

In [205]: df2[df2 < 0] = 0

In [206]: df2
Out[206]: 
                   A         B         C         D
2000-01-01  0.000000  0.000000  0.485855  0.245166
2000-01-02  0.000000  0.390389  0.000000  1.655824
2000-01-03  0.000000  0.299674  0.000000  0.281059
2000-01-04  0.846958  0.000000  0.600705  0.000000
2000-01-05  0.669692  0.000000  0.000000  0.342416
2000-01-06  0.868584  0.000000  2.297780  0.000000
2000-01-07  0.000000  0.000000  0.168904  0.000000
2000-01-08  0.801196  1.392071  0.000000  0.000000
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.Series.copy pandas.DataFrame.copy
"In [207]: df.where(df < 0, -df) == np.where(df < 0, df, -df)
Out[207]: 
               A     B     C     D
2000-01-01  True  True  True  True
2000-01-02  True  True  True  True
2000-01-03  True  True  True  True
2000-01-04  True  True  True  True
2000-01-05  True  True  True  True
2000-01-06  True  True  True  True
2000-01-07  True  True  True  True
2000-01-08  True  True  True  True
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.DataFrame.where
"In [208]: df2 = df.copy()

In [209]: df2[df2[1:4] > 0] = 3

In [210]: df2
Out[210]: 
                   A         B         C         D
2000-01-01 -2.104139 -1.309525  0.485855  0.245166
2000-01-02 -0.352480  3.000000 -1.192319  3.000000
2000-01-03 -0.864883  3.000000 -0.227870  3.000000
2000-01-04  3.000000 -1.222082  3.000000 -1.233203
2000-01-05  0.669692 -0.605656 -1.169184  0.342416
2000-01-06  0.868584 -0.948458  2.297780 -0.684718
2000-01-07 -2.670153 -0.114722  0.168904 -0.048048
2000-01-08  0.801196  1.392071 -0.048788 -0.808838
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.DataFrame.copy
"In [211]: df2 = df.copy()

In [212]: df2.where(df2 > 0, df2['A'], axis='index')
Out[212]: 
                   A         B         C         D
2000-01-01 -2.104139 -2.104139  0.485855  0.245166
2000-01-02 -0.352480  0.390389 -0.352480  1.655824
2000-01-03 -0.864883  0.299674 -0.864883  0.281059
2000-01-04  0.846958  0.846958  0.600705  0.846958
2000-01-05  0.669692  0.669692  0.669692  0.342416
2000-01-06  0.868584  0.868584  2.297780  0.868584
2000-01-07 -2.670153 -2.670153  0.168904 -2.670153
2000-01-08  0.801196  1.392071  0.801196  0.801196
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.DataFrame.copy pandas.DataFrame.where
"In [213]: df2 = df.copy()

In [214]: df.apply(lambda x, y: x.where(x > 0, y), y=df['A'])
Out[214]: 
                   A         B         C         D
2000-01-01 -2.104139 -2.104139  0.485855  0.245166
2000-01-02 -0.352480  0.390389 -0.352480  1.655824
2000-01-03 -0.864883  0.299674 -0.864883  0.281059
2000-01-04  0.846958  0.846958  0.600705  0.846958
2000-01-05  0.669692  0.669692  0.669692  0.342416
2000-01-06  0.868584  0.868584  2.297780  0.868584
2000-01-07 -2.670153 -2.670153  0.168904 -2.670153
2000-01-08  0.801196  1.392071  0.801196  0.801196
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.DataFrame.copy pandas.DataFrame.apply pandas.DataFrame.where
"In [215]: df3 = pd.DataFrame({'A': [1, 2, 3],
   .....:                     'B': [4, 5, 6],
   .....:                     'C': [7, 8, 9]})
   .....: 

In [216]: df3.where(lambda x: x > 4, lambda x: x + 10)
Out[216]: 
    A   B  C
0  11  14  7
1  12   5  8
2  13   6  9
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.DataFrame pandas.DataFrame.where
"In [217]: s.mask(s >= 0)
Out[217]: 
4   NaN
3   NaN
2   NaN
1   NaN
0   NaN
dtype: float64

In [218]: df.mask(df >= 0)
Out[218]: 
                   A         B         C         D
2000-01-01 -2.104139 -1.309525       NaN       NaN
2000-01-02 -0.352480       NaN -1.192319       NaN
2000-01-03 -0.864883       NaN -0.227870       NaN
2000-01-04       NaN -1.222082       NaN -1.233203
2000-01-05       NaN -0.605656 -1.169184       NaN
2000-01-06       NaN -0.948458       NaN -0.684718
2000-01-07 -2.670153 -0.114722       NaN -0.048048
2000-01-08       NaN       NaN -0.048788 -0.808838
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.Series.mask pandas.DataFrame.mask
"In [219]: df = pd.DataFrame({'col1': list('ABBC'), 'col2': list('ZZXY')})

In [220]: df['color'] = np.where(df['col2'] == 'Z', 'green', 'red')

In [221]: df
Out[221]: 
  col1 col2  color
0    A    Z  green
1    B    Z  green
2    B    X    red
3    C    Y    red
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.DataFrame
"In [226]: n = 10

In [227]: df = pd.DataFrame(np.random.rand(n, 3), columns=list('abc'))

In [228]: df
Out[228]: 
          a         b         c
0  0.438921  0.118680  0.863670
1  0.138138  0.577363  0.686602
2  0.595307  0.564592  0.520630
3  0.913052  0.926075  0.616184
4  0.078718  0.854477  0.898725
5  0.076404  0.523211  0.591538
6  0.792342  0.216974  0.564056
7  0.397890  0.454131  0.915716
8  0.074315  0.437913  0.019794
9  0.559209  0.502065  0.026437

# pure python
In [229]: df[(df['a'] < df['b']) & (df['b'] < df['c'])]
Out[229]: 
          a         b         c
1  0.138138  0.577363  0.686602
4  0.078718  0.854477  0.898725
5  0.076404  0.523211  0.591538
7  0.397890  0.454131  0.915716

# query
In [230]: df.query('(a < b) & (b < c)')
Out[230]: 
          a         b         c
1  0.138138  0.577363  0.686602
4  0.078718  0.854477  0.898725
5  0.076404  0.523211  0.591538
7  0.397890  0.454131  0.915716
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.DataFrame pandas.DataFrame.query
"In [231]: df = pd.DataFrame(np.random.randint(n / 2, size=(n, 2)), columns=list('bc'))

In [232]: df.index.name = 'a'

In [233]: df
Out[233]: 
   b  c
a      
0  0  4
1  0  1
2  3  4
3  4  3
4  1  4
5  0  3
6  0  1
7  3  4
8  2  3
9  1  1

In [234]: df.query('a < b and b < c')
Out[234]: 
   b  c
a      
2  3  4
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.DataFrame pandas.DataFrame.query
"In [235]: df = pd.DataFrame(np.random.randint(n, size=(n, 2)), columns=list('bc'))

In [236]: df
Out[236]: 
   b  c
0  3  1
1  3  0
2  5  6
3  5  2
4  7  4
5  0  1
6  2  5
7  0  1
8  6  0
9  7  9

In [237]: df.query('index < b < c')
Out[237]: 
   b  c
2  5  6
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.DataFrame pandas.DataFrame.query
"In [238]: df = pd.DataFrame({'a': np.random.randint(5, size=5)})

In [239]: df.index.name = 'a'

In [240]: df.query('a > 2')  # uses the column 'a', not the index
Out[240]: 
   a
a   
1  3
3  3
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.DataFrame pandas.DataFrame.query
"In [241]: df.query('index > 2')
Out[241]: 
   a
a   
3  3
4  2
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.DataFrame.query
"In [242]: n = 10

In [243]: colors = np.random.choice(['red', 'green'], size=n)

In [244]: foods = np.random.choice(['eggs', 'ham'], size=n)

In [245]: colors
Out[245]: 
array(['red', 'red', 'red', 'green', 'green', 'green', 'green', 'green',
       'green', 'green'], dtype='

In [246]: foods
Out[246]: 
array(['ham', 'ham', 'eggs', 'eggs', 'eggs', 'ham', 'ham', 'eggs', 'eggs',
       'eggs'], dtype='

In [247]: index = pd.MultiIndex.from_arrays([colors, foods], names=['color', 'food'])

In [248]: df = pd.DataFrame(np.random.randn(n, 2), index=index)

In [249]: df
Out[249]: 
                   0         1
color food                    
red   ham   0.194889 -0.381994
      ham   0.318587  2.089075
      eggs -0.728293 -0.090255
green eggs -0.748199  1.318931
      eggs -2.029766  0.792652
      ham   0.461007 -0.542749
      ham  -0.305384 -0.479195
      eggs  0.095031 -0.270099
      eggs -0.707140 -0.773882
      eggs  0.229453  0.304418

In [250]: df.query('color == ""red""')
Out[250]: 
                   0         1
color food                    
red   ham   0.194889 -0.381994
      ham   0.318587  2.089075
      eggs -0.728293 -0.090255
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.array pandas.MultiIndex.from_arrays pandas.DataFrame pandas.DataFrame.query
"In [251]: df.index.names = [None, None]

In [252]: df
Out[252]: 
                   0         1
red   ham   0.194889 -0.381994
      ham   0.318587  2.089075
      eggs -0.728293 -0.090255
green eggs -0.748199  1.318931
      eggs -2.029766  0.792652
      ham   0.461007 -0.542749
      ham  -0.305384 -0.479195
      eggs  0.095031 -0.270099
      eggs -0.707140 -0.773882
      eggs  0.229453  0.304418

In [253]: df.query('ilevel_0 == ""red""')
Out[253]: 
                 0         1
red ham   0.194889 -0.381994
    ham   0.318587  2.089075
    eggs -0.728293 -0.090255
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.DataFrame.query
"In [254]: df = pd.DataFrame(np.random.rand(n, 3), columns=list('abc'))

In [255]: df
Out[255]: 
          a         b         c
0  0.224283  0.736107  0.139168
1  0.302827  0.657803  0.713897
2  0.611185  0.136624  0.984960
3  0.195246  0.123436  0.627712
4  0.618673  0.371660  0.047902
5  0.480088  0.062993  0.185760
6  0.568018  0.483467  0.445289
7  0.309040  0.274580  0.587101
8  0.258993  0.477769  0.370255
9  0.550459  0.840870  0.304611

In [256]: df2 = pd.DataFrame(np.random.rand(n + 2, 3), columns=df.columns)

In [257]: df2
Out[257]: 
           a         b         c
0   0.357579  0.229800  0.596001
1   0.309059  0.957923  0.965663
2   0.123102  0.336914  0.318616
3   0.526506  0.323321  0.860813
4   0.518736  0.486514  0.384724
5   0.190804  0.505723  0.614533
6   0.891939  0.623977  0.676639
7   0.480559  0.378528  0.460858
8   0.420223  0.136404  0.141295
9   0.732206  0.419540  0.604675
10  0.604466  0.848974  0.896165
11  0.589168  0.920046  0.732716

In [258]: expr = '0.0 <= a <= c <= 0.5'

In [259]: map(lambda frame: frame.query(expr), [df, df2])
Out[259]: 
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.DataFrame pandas.DataFrame.query
"In [260]: df = pd.DataFrame(np.random.randint(n, size=(n, 3)), columns=list('abc'))

In [261]: df
Out[261]: 
   a  b  c
0  7  8  9
1  1  0  7
2  2  7  2
3  6  2  2
4  2  6  3
5  3  8  2
6  1  7  2
7  5  1  5
8  9  8  0
9  1  5  0

In [262]: df.query('(a < b) & (b < c)')
Out[262]: 
   a  b  c
0  7  8  9

In [263]: df[(df['a'] < df['b']) & (df['b'] < df['c'])]
Out[263]: 
   a  b  c
0  7  8  9
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.DataFrame pandas.DataFrame.query
"In [264]: df.query('a < b & b < c')
Out[264]: 
   a  b  c
0  7  8  9
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.DataFrame.query
"In [265]: df.query('a < b and b < c')
Out[265]: 
   a  b  c
0  7  8  9
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.DataFrame.query
"In [266]: df.query('a < b < c')
Out[266]: 
   a  b  c
0  7  8  9
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.DataFrame.query
"# get all rows where columns ""a"" and ""b"" have overlapping values
In [267]: df = pd.DataFrame({'a': list('aabbccddeeff'), 'b': list('aaaabbbbcccc'),
   .....:                    'c': np.random.randint(5, size=12),
   .....:                    'd': np.random.randint(9, size=12)})
   .....: 

In [268]: df
Out[268]: 
    a  b  c  d
0   a  a  2  6
1   a  a  4  7
2   b  a  1  6
3   b  a  2  1
4   c  b  3  6
5   c  b  0  2
6   d  b  3  3
7   d  b  2  1
8   e  c  4  3
9   e  c  2  0
10  f  c  0  6
11  f  c  1  2

In [269]: df.query('a in b')
Out[269]: 
   a  b  c  d
0  a  a  2  6
1  a  a  4  7
2  b  a  1  6
3  b  a  2  1
4  c  b  3  6
5  c  b  0  2

# How you'd do it in pure Python
In [270]: df[df['a'].isin(df['b'])]
Out[270]: 
   a  b  c  d
0  a  a  2  6
1  a  a  4  7
2  b  a  1  6
3  b  a  2  1
4  c  b  3  6
5  c  b  0  2

In [271]: df.query('a not in b')
Out[271]: 
    a  b  c  d
6   d  b  3  3
7   d  b  2  1
8   e  c  4  3
9   e  c  2  0
10  f  c  0  6
11  f  c  1  2

# pure Python
In [272]: df[~df['a'].isin(df['b'])]
Out[272]: 
    a  b  c  d
6   d  b  3  3
7   d  b  2  1
8   e  c  4  3
9   e  c  2  0
10  f  c  0  6
11  f  c  1  2
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.DataFrame pandas.DataFrame.query
"# rows where cols a and b have overlapping values
# and col c's values are less than col d's
In [273]: df.query('a in b and c < d')
Out[273]: 
   a  b  c  d
0  a  a  2  6
1  a  a  4  7
2  b  a  1  6
4  c  b  3  6
5  c  b  0  2

# pure Python
In [274]: df[df['b'].isin(df['a']) & (df['c'] < df['d'])]
Out[274]: 
    a  b  c  d
0   a  a  2  6
1   a  a  4  7
2   b  a  1  6
4   c  b  3  6
5   c  b  0  2
10  f  c  0  6
11  f  c  1  2
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.DataFrame.query
"df.query('a in b + c + d')
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.DataFrame.query
"In [275]: df.query('b == [""a"", ""b"", ""c""]')
Out[275]: 
    a  b  c  d
0   a  a  2  6
1   a  a  4  7
2   b  a  1  6
3   b  a  2  1
4   c  b  3  6
5   c  b  0  2
6   d  b  3  3
7   d  b  2  1
8   e  c  4  3
9   e  c  2  0
10  f  c  0  6
11  f  c  1  2

# pure Python
In [276]: df[df['b'].isin([""a"", ""b"", ""c""])]
Out[276]: 
    a  b  c  d
0   a  a  2  6
1   a  a  4  7
2   b  a  1  6
3   b  a  2  1
4   c  b  3  6
5   c  b  0  2
6   d  b  3  3
7   d  b  2  1
8   e  c  4  3
9   e  c  2  0
10  f  c  0  6
11  f  c  1  2

In [277]: df.query('c == [1, 2]')
Out[277]: 
    a  b  c  d
0   a  a  2  6
2   b  a  1  6
3   b  a  2  1
7   d  b  2  1
9   e  c  2  0
11  f  c  1  2

In [278]: df.query('c != [1, 2]')
Out[278]: 
    a  b  c  d
1   a  a  4  7
4   c  b  3  6
5   c  b  0  2
6   d  b  3  3
8   e  c  4  3
10  f  c  0  6

# using in/not in
In [279]: df.query('[1, 2] in c')
Out[279]: 
    a  b  c  d
0   a  a  2  6
2   b  a  1  6
3   b  a  2  1
7   d  b  2  1
9   e  c  2  0
11  f  c  1  2

In [280]: df.query('[1, 2] not in c')
Out[280]: 
    a  b  c  d
1   a  a  4  7
4   c  b  3  6
5   c  b  0  2
6   d  b  3  3
8   e  c  4  3
10  f  c  0  6

# pure Python
In [281]: df[df['c'].isin([1, 2])]
Out[281]: 
    a  b  c  d
0   a  a  2  6
2   b  a  1  6
3   b  a  2  1
7   d  b  2  1
9   e  c  2  0
11  f  c  1  2
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.DataFrame.query
"In [282]: df = pd.DataFrame(np.random.rand(n, 3), columns=list('abc'))

In [283]: df['bools'] = np.random.rand(len(df)) > 0.5

In [284]: df.query('~bools')
Out[284]: 
          a         b         c  bools
2  0.697753  0.212799  0.329209  False
7  0.275396  0.691034  0.826619  False
8  0.190649  0.558748  0.262467  False

In [285]: df.query('not bools')
Out[285]: 
          a         b         c  bools
2  0.697753  0.212799  0.329209  False
7  0.275396  0.691034  0.826619  False
8  0.190649  0.558748  0.262467  False

In [286]: df.query('not bools') == df[~df['bools']]
Out[286]: 
      a     b     c  bools
2  True  True  True   True
7  True  True  True   True
8  True  True  True   True
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.DataFrame pandas.DataFrame.query
"# short query syntax
In [287]: shorter = df.query('a < b < c and (not bools) or bools > 2')

# equivalent in pure Python
In [288]: longer = df[(df['a'] < df['b'])
   .....:             & (df['b'] < df['c'])
   .....:             & (~df['bools'])
   .....:             | (df['bools'] > 2)]
   .....: 

In [289]: shorter
Out[289]: 
          a         b         c  bools
7  0.275396  0.691034  0.826619  False

In [290]: longer
Out[290]: 
          a         b         c  bools
7  0.275396  0.691034  0.826619  False

In [291]: shorter == longer
Out[291]: 
      a     b     c  bools
7  True  True  True   True
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.DataFrame.query
"In [292]: df = pd.DataFrame(np.random.randn(8, 4),
   .....:                   index=dates, columns=['A', 'B', 'C', 'D'])
   .....: 

In [293]: df2 = df.copy()
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.DataFrame pandas.DataFrame.copy
"In [294]: df2 = pd.DataFrame({'a': ['one', 'one', 'two', 'two', 'two', 'three', 'four'],
   .....:                     'b': ['x', 'y', 'x', 'y', 'x', 'x', 'x'],
   .....:                     'c': np.random.randn(7)})
   .....: 

In [295]: df2
Out[295]: 
       a  b         c
0    one  x -1.067137
1    one  y  0.309500
2    two  x -0.211056
3    two  y -1.842023
4    two  x -0.390820
5  three  x -1.964475
6   four  x  1.298329

In [296]: df2.duplicated('a')
Out[296]: 
0    False
1     True
2    False
3     True
4     True
5    False
6    False
dtype: bool

In [297]: df2.duplicated('a', keep='last')
Out[297]: 
0     True
1    False
2     True
3     True
4    False
5    False
6    False
dtype: bool

In [298]: df2.duplicated('a', keep=False)
Out[298]: 
0     True
1     True
2     True
3     True
4     True
5    False
6    False
dtype: bool

In [299]: df2.drop_duplicates('a')
Out[299]: 
       a  b         c
0    one  x -1.067137
2    two  x -0.211056
5  three  x -1.964475
6   four  x  1.298329

In [300]: df2.drop_duplicates('a', keep='last')
Out[300]: 
       a  b         c
1    one  y  0.309500
4    two  x -0.390820
5  three  x -1.964475
6   four  x  1.298329

In [301]: df2.drop_duplicates('a', keep=False)
Out[301]: 
       a  b         c
5  three  x -1.964475
6   four  x  1.298329
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.DataFrame pandas.DataFrame.duplicated pandas.DataFrame.drop_duplicates
"In [302]: df2.duplicated(['a', 'b'])
Out[302]: 
0    False
1    False
2    False
3    False
4     True
5    False
6    False
dtype: bool

In [303]: df2.drop_duplicates(['a', 'b'])
Out[303]: 
       a  b         c
0    one  x -1.067137
1    one  y  0.309500
2    two  x -0.211056
3    two  y -1.842023
5  three  x -1.964475
6   four  x  1.298329
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.DataFrame.duplicated pandas.DataFrame.drop_duplicates
"In [304]: df3 = pd.DataFrame({'a': np.arange(6),
   .....:                     'b': np.random.randn(6)},
   .....:                    index=['a', 'a', 'b', 'c', 'b', 'a'])
   .....: 

In [305]: df3
Out[305]: 
   a         b
a  0  1.440455
a  1  2.456086
b  2  1.038402
c  3 -0.894409
b  4  0.683536
a  5  3.082764

In [306]: df3.index.duplicated()
Out[306]: array([False,  True, False, False,  True,  True])

In [307]: df3[~df3.index.duplicated()]
Out[307]: 
   a         b
a  0  1.440455
b  2  1.038402
c  3 -0.894409

In [308]: df3[~df3.index.duplicated(keep='last')]
Out[308]: 
   a         b
c  3 -0.894409
b  4  0.683536
a  5  3.082764

In [309]: df3[~df3.index.duplicated(keep=False)]
Out[309]: 
   a         b
c  3 -0.894409
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.DataFrame pandas.array
"In [310]: s = pd.Series([1, 2, 3], index=['a', 'b', 'c'])

In [311]: s.get('a')  # equivalent to s['a']
Out[311]: 1

In [312]: s.get('x', default=-1)
Out[312]: -1
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.Series pandas.Series.get
"In [313]: df = pd.DataFrame({'col': [""A"", ""A"", ""B"", ""B""],
   .....:                    'A': [80, 23, np.nan, 22],
   .....:                    'B': [80, 55, 76, 67]})
   .....: 

In [314]: df
Out[314]: 
  col     A   B
0   A  80.0  80
1   A  23.0  55
2   B   NaN  76
3   B  22.0  67

In [315]: idx, cols = pd.factorize(df['col'])

In [316]: df.reindex(cols, axis=1).to_numpy()[np.arange(len(df)), idx]
Out[316]: array([80., 23., 76., 67.])
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.DataFrame pandas.factorize pandas.DataFrame.reindex pandas.array
"In [317]: index = pd.Index(['e', 'd', 'a', 'b'])

In [318]: index
Out[318]: Index(['e', 'd', 'a', 'b'], dtype='object')

In [319]: 'd' in index
Out[319]: True
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.Index pandas.Index
"In [320]: index = pd.Index([1, 5, 12])

In [321]: index
Out[321]: Index([1, 5, 12], dtype='int64')

In [322]: 5 in index
Out[322]: True
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.Index pandas.Index
"In [323]: index = pd.Index(['e', 'd', 'a', 'b'], dtype=""string"")

In [324]: index
Out[324]: Index(['e', 'd', 'a', 'b'], dtype='string')

In [325]: index = pd.Index([1, 5, 12], dtype=""int8"")

In [326]: index
Out[326]: Index([1, 5, 12], dtype='int8')

In [327]: index = pd.Index([1, 5, 12], dtype=""float32"")

In [328]: index
Out[328]: Index([1.0, 5.0, 12.0], dtype='float32')
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.Index pandas.Index
"In [329]: index = pd.Index(['e', 'd', 'a', 'b'], name='something')

In [330]: index.name
Out[330]: 'something'
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.Index
"In [331]: index = pd.Index(list(range(5)), name='rows')

In [332]: columns = pd.Index(['A', 'B', 'C'], name='cols')

In [333]: df = pd.DataFrame(np.random.randn(5, 3), index=index, columns=columns)

In [334]: df
Out[334]: 
cols         A         B         C
rows                              
0     1.295989 -1.051694  1.340429
1    -2.366110  0.428241  0.387275
2     0.433306  0.929548  0.278094
3     2.154730 -0.315628  0.264223
4     1.126818  1.132290 -0.353310

In [335]: df['A']
Out[335]: 
rows
0    1.295989
1   -2.366110
2    0.433306
3    2.154730
4    1.126818
Name: A, dtype: float64
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.Index pandas.DataFrame
"In [336]: ind = pd.Index([1, 2, 3])

In [337]: ind.rename(""apple"")
Out[337]: Index([1, 2, 3], dtype='int64', name='apple')

In [338]: ind
Out[338]: Index([1, 2, 3], dtype='int64')

In [339]: ind = ind.set_names([""apple""])

In [340]: ind.name = ""bob""

In [341]: ind
Out[341]: Index([1, 2, 3], dtype='int64', name='bob')
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.Index pandas.Index.rename pandas.Index pandas.Index.set_names
"In [342]: index = pd.MultiIndex.from_product([range(3), ['one', 'two']], names=['first', 'second'])

In [343]: index
Out[343]: 
MultiIndex([(0, 'one'),
            (0, 'two'),
            (1, 'one'),
            (1, 'two'),
            (2, 'one'),
            (2, 'two')],
           names=['first', 'second'])

In [344]: index.levels[1]
Out[344]: Index(['one', 'two'], dtype='object', name='second')

In [345]: index.set_levels([""a"", ""b""], level=1)
Out[345]: 
MultiIndex([(0, 'a'),
            (0, 'b'),
            (1, 'a'),
            (1, 'b'),
            (2, 'a'),
            (2, 'b')],
           names=['first', 'second'])
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.MultiIndex.from_product pandas.MultiIndex pandas.Index
"In [346]: a = pd.Index(['c', 'b', 'a'])

In [347]: b = pd.Index(['c', 'e', 'd'])

In [348]: a.difference(b)
Out[348]: Index(['a', 'b'], dtype='object')
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.Index pandas.Index
"In [349]: idx1 = pd.Index([1, 2, 3, 4])

In [350]: idx2 = pd.Index([2, 3, 4, 5])

In [351]: idx1.symmetric_difference(idx2)
Out[351]: Index([1, 5], dtype='int64')
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.Index pandas.Index.symmetric_difference pandas.Index
"In [352]: idx1 = pd.Index([0, 1, 2])

In [353]: idx2 = pd.Index([0.5, 1.5])

In [354]: idx1.union(idx2)
Out[354]: Index([0.0, 0.5, 1.0, 1.5, 2.0], dtype='float64')
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.Index pandas.Index
"In [355]: idx1 = pd.Index([1, np.nan, 3, 4])

In [356]: idx1
Out[356]: Index([1.0, nan, 3.0, 4.0], dtype='float64')

In [357]: idx1.fillna(2)
Out[357]: Index([1.0, 2.0, 3.0, 4.0], dtype='float64')

In [358]: idx2 = pd.DatetimeIndex([pd.Timestamp('2011-01-01'),
   .....:                          pd.NaT,
   .....:                          pd.Timestamp('2011-01-03')])
   .....: 

In [359]: idx2
Out[359]: DatetimeIndex(['2011-01-01', 'NaT', '2011-01-03'], dtype='datetime64[ns]', freq=None)

In [360]: idx2.fillna(pd.Timestamp('2011-01-02'))
Out[360]: DatetimeIndex(['2011-01-01', '2011-01-02', '2011-01-03'], dtype='datetime64[ns]', freq=None)
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.Index pandas.Index pandas.Index.fillna pandas.DatetimeIndex pandas.DatetimeIndex
"In [361]: data = pd.DataFrame({'a': ['bar', 'bar', 'foo', 'foo'],
   .....:                      'b': ['one', 'two', 'one', 'two'],
   .....:                      'c': ['z', 'y', 'x', 'w'],
   .....:                      'd': [1., 2., 3, 4]})
   .....: 

In [362]: data
Out[362]: 
     a    b  c    d
0  bar  one  z  1.0
1  bar  two  y  2.0
2  foo  one  x  3.0
3  foo  two  w  4.0

In [363]: indexed1 = data.set_index('c')

In [364]: indexed1
Out[364]: 
     a    b    d
c               
z  bar  one  1.0
y  bar  two  2.0
x  foo  one  3.0
w  foo  two  4.0

In [365]: indexed2 = data.set_index(['a', 'b'])

In [366]: indexed2
Out[366]: 
         c    d
a   b          
bar one  z  1.0
    two  y  2.0
foo one  x  3.0
    two  w  4.0
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.DataFrame pandas.DataFrame.set_index
"In [367]: frame = data.set_index('c', drop=False)

In [368]: frame = frame.set_index(['a', 'b'], append=True)

In [369]: frame
Out[369]: 
           c    d
c a   b          
z bar one  z  1.0
y bar two  y  2.0
x foo one  x  3.0
w foo two  w  4.0
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.DataFrame.set_index pandas.DataFrame.set_index
"In [370]: data.set_index('c', drop=False)
Out[370]: 
     a    b  c    d
c                  
z  bar  one  z  1.0
y  bar  two  y  2.0
x  foo  one  x  3.0
w  foo  two  w  4.0
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.DataFrame.set_index
"In [371]: data
Out[371]: 
     a    b  c    d
0  bar  one  z  1.0
1  bar  two  y  2.0
2  foo  one  x  3.0
3  foo  two  w  4.0

In [372]: data.reset_index()
Out[372]: 
   index    a    b  c    d
0      0  bar  one  z  1.0
1      1  bar  two  y  2.0
2      2  foo  one  x  3.0
3      3  foo  two  w  4.0
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.DataFrame.reset_index
"In [373]: frame
Out[373]: 
           c    d
c a   b          
z bar one  z  1.0
y bar two  y  2.0
x foo one  x  3.0
w foo two  w  4.0

In [374]: frame.reset_index(level=1)
Out[374]: 
         a  c    d
c b               
z one  bar  z  1.0
y two  bar  y  2.0
x one  foo  x  3.0
w two  foo  w  4.0
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.DataFrame.reset_index
"In [375]: df_idx = pd.DataFrame(range(4))

In [376]: df_idx.index = pd.Index([10, 20, 30, 40], name=""a"")

In [377]: df_idx
Out[377]: 
    0
a    
10  0
20  1
30  2
40  3
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.DataFrame pandas.Index
"In [378]: dfmi = pd.DataFrame([list('abcd'),
   .....:                      list('efgh'),
   .....:                      list('ijkl'),
   .....:                      list('mnop')],
   .....:                     columns=pd.MultiIndex.from_product([['one', 'two'],
   .....:                                                         ['first', 'second']]))
   .....: 

In [379]: dfmi
Out[379]: 
    one          two       
  first second first second
0     a      b     c      d
1     e      f     g      h
2     i      j     k      l
3     m      n     o      p
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.DataFrame pandas.MultiIndex.from_product
"dfmi.loc[:, ('one', 'second')] = value
# becomes
dfmi.loc.__setitem__((slice(None), ('one', 'second')), value)
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.Series.str.slice
"In [382]: dfb = pd.DataFrame({'a': ['one', 'one', 'two',
   .....:                           'three', 'two', 'one', 'six'],
   .....:                     'c': np.arange(7)})
   .....: 

# This will show the SettingWithCopyWarning
# but the frame values will be set
In [383]: dfb['c'][dfb['a'].str.startswith('o')] = 42
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.DataFrame pandas.Series.str.startswith
"In [384]: with pd.option_context('mode.chained_assignment','warn'):
   .....:     dfb[dfb['a'].str.startswith('o')]['c'] = 42
   .....: 
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.Series.str.startswith
"In [385]: dfc = pd.DataFrame({'a': ['one', 'one', 'two',
   .....:                           'three', 'two', 'one', 'six'],
   .....:                     'c': np.arange(7)})
   .....: 

In [386]: dfd = dfc.copy()

# Setting multiple items using a mask
In [387]: mask = dfd['a'].str.startswith('o')

In [388]: dfd.loc[mask, 'c'] = 42

In [389]: dfd
Out[389]: 
       a   c
0    one  42
1    one  42
2    two   2
3  three   3
4    two   4
5    one  42
6    six   6

# Setting a single item
In [390]: dfd = dfc.copy()

In [391]: dfd.loc[2, 'a'] = 11

In [392]: dfd
Out[392]: 
       a  c
0    one  0
1    one  1
2     11  2
3  three  3
4    two  4
5    one  5
6    six  6
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.DataFrame pandas.DataFrame.copy pandas.Series.str.startswith
"In [393]: dfd = dfc.copy()

In [394]: dfd['a'][2] = 111

In [395]: dfd
Out[395]: 
       a  c
0    one  0
1    one  1
2    111  2
3  three  3
4    two  4
5    one  5
6    six  6
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.DataFrame.copy
"In [396]: with pd.option_context('mode.chained_assignment','raise'):
   .....:     dfd.loc[0]['a'] = 1111
   .....: 
---------------------------------------------------------------------------
SettingWithCopyError                      Traceback (most recent call last)
 in ?()
      1 with pd.option_context('mode.chained_assignment','raise'):
----> 2     dfd.loc[0]['a'] = 1111

~/work/pandas/pandas/pandas/core/series.py in ?(self, key, value)
   1284                 )
   1285 
   1286         check_dict_or_set_indexers(key)
   1287         key = com.apply_if_callable(key, self)
-> 1288         cacher_needs_updating = self._check_is_chained_assignment_possible()
   1289 
   1290         if key is Ellipsis:
   1291             key = slice(None)

~/work/pandas/pandas/pandas/core/series.py in ?(self)
   1489             ref = self._get_cacher()
   1490             if ref is not None and ref._is_mixed_type:
   1491                 self._check_setitem_copy(t=""referent"", force=True)
   1492             return True
-> 1493         return super()._check_is_chained_assignment_possible()

~/work/pandas/pandas/pandas/core/generic.py in ?(self)
   4395         single-dtype meaning that the cacher should be updated following
   4396         setting.
   4397         """"""
   4398         if self._is_copy:
-> 4399             self._check_setitem_copy(t=""referent"")
   4400         return False

~/work/pandas/pandas/pandas/core/generic.py in ?(self, t, force)
   4469                 ""indexing.html#returning-a-view-versus-a-copy""
   4470             )
   4471 
   4472         if value == ""raise"":
-> 4473             raise SettingWithCopyError(t)
   4474         if value == ""warn"":
   4475             warnings.warn(t, SettingWithCopyWarning, stacklevel=find_stack_level())

SettingWithCopyError: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
",https://pandas.pydata.org/docs/user_guide/indexing.html, pandas.Series.str.slice pandas.errors.SettingWithCopyError
"In [1]: data = {
   ...:    ""value"": range(12),
   ...:    ""variable"": [""A""] * 3 + [""B""] * 3 + [""C""] * 3 + [""D""] * 3,
   ...:    ""date"": pd.to_datetime([""2020-01-03"", ""2020-01-04"", ""2020-01-05""] * 4)
   ...: }
   ...: 

In [2]: df = pd.DataFrame(data)
",https://pandas.pydata.org/docs/user_guide/reshaping.html, pandas.to_datetime pandas.DataFrame
"In [3]: pivoted = df.pivot(index=""date"", columns=""variable"", values=""value"")

In [4]: pivoted
Out[4]: 
variable    A  B  C   D
date                   
2020-01-03  0  3  6   9
2020-01-04  1  4  7  10
2020-01-05  2  5  8  11
",https://pandas.pydata.org/docs/user_guide/reshaping.html, pandas.DataFrame.pivot
"In [5]: df[""value2""] = df[""value""] * 2

In [6]: pivoted = df.pivot(index=""date"", columns=""variable"")

In [7]: pivoted
Out[7]: 
           value           value2            
variable       A  B  C   D      A   B   C   D
date                                         
2020-01-03     0  3  6   9      0   6  12  18
2020-01-04     1  4  7  10      2   8  14  20
2020-01-05     2  5  8  11      4  10  16  22
",https://pandas.pydata.org/docs/user_guide/reshaping.html, pandas.DataFrame.pivot
"In [9]: import datetime

In [10]: df = pd.DataFrame(
   ....:     {
   ....:         ""A"": [""one"", ""one"", ""two"", ""three""] * 6,
   ....:         ""B"": [""A"", ""B"", ""C""] * 8,
   ....:         ""C"": [""foo"", ""foo"", ""foo"", ""bar"", ""bar"", ""bar""] * 4,
   ....:         ""D"": np.random.randn(24),
   ....:         ""E"": np.random.randn(24),
   ....:         ""F"": [datetime.datetime(2013, i, 1) for i in range(1, 13)]
   ....:         + [datetime.datetime(2013, i, 15) for i in range(1, 13)],
   ....:     }
   ....: )
   ....: 

In [11]: df
Out[11]: 
        A  B    C         D         E          F
0     one  A  foo  0.469112  0.404705 2013-01-01
1     one  B  foo -0.282863  0.577046 2013-02-01
2     two  C  foo -1.509059 -1.715002 2013-03-01
3   three  A  bar -1.135632 -1.039268 2013-04-01
4     one  B  bar  1.212112 -0.370647 2013-05-01
..    ... ..  ...       ...       ...        ...
19  three  B  foo -1.087401 -0.472035 2013-08-15
20    one  C  foo -0.673690 -0.013960 2013-09-15
21    one  A  bar  0.113648 -0.362543 2013-10-15
22    two  B  bar -1.478427 -0.006154 2013-11-15
23  three  C  bar  0.524988 -0.923061 2013-12-15

[24 rows x 6 columns]

In [12]: pd.pivot_table(df, values=""D"", index=[""A"", ""B""], columns=[""C""])
Out[12]: 
C             bar       foo
A     B                    
one   A -0.995460  0.595334
      B  0.393570 -0.494817
      C  0.196903 -0.767769
three A -0.431886       NaN
      B       NaN -1.065818
      C  0.798396       NaN
two   A       NaN  0.197720
      B -0.986678       NaN
      C       NaN -1.274317

In [13]: pd.pivot_table(
   ....:     df, values=[""D"", ""E""],
   ....:     index=[""B""],
   ....:     columns=[""A"", ""C""],
   ....:     aggfunc=""sum"",
   ....: )
   ....: 
Out[13]: 
          D                      ...         E                   
A       one               three  ...     three      two          
C       bar       foo       bar  ...       foo      bar       foo
B                                ...                             
A -1.990921  1.190667 -0.863772  ...       NaN      NaN -1.067650
B  0.787140 -0.989634       NaN  ...  0.372851  1.63741       NaN
C  0.393806 -1.535539  1.596791  ...       NaN      NaN -3.491906

[3 rows x 12 columns]

In [14]: pd.pivot_table(
   ....:     df, values=""E"",
   ....:     index=[""B"", ""C""],
   ....:     columns=[""A""],
   ....:     aggfunc=[""sum"", ""mean""],
   ....: )
   ....: 
Out[14]: 
            sum                          mean                    
A           one     three       two       one     three       two
B C                                                              
A bar -0.471593 -2.008182       NaN -0.235796 -1.004091       NaN
  foo  0.761726       NaN -1.067650  0.380863       NaN -0.533825
B bar -1.665170       NaN  1.637410 -0.832585       NaN  0.818705
  foo -0.097554  0.372851       NaN -0.048777  0.186425       NaN
C bar -0.744154 -2.392449       NaN -0.372077 -1.196224       NaN
  foo  1.061810       NaN -3.491906  0.530905       NaN -1.745953
",https://pandas.pydata.org/docs/user_guide/reshaping.html, pandas.DataFrame pandas.pivot_table
"In [15]: pd.pivot_table(df[[""A"", ""B"", ""C"", ""D"", ""E""]], index=[""A"", ""B""], columns=[""C""])
Out[15]: 
                D                   E          
C             bar       foo       bar       foo
A     B                                        
one   A -0.995460  0.595334 -0.235796  0.380863
      B  0.393570 -0.494817 -0.832585 -0.048777
      C  0.196903 -0.767769 -0.372077  0.530905
three A -0.431886       NaN -1.004091       NaN
      B       NaN -1.065818       NaN  0.186425
      C  0.798396       NaN -1.196224       NaN
two   A       NaN  0.197720       NaN -0.533825
      B -0.986678       NaN  0.818705       NaN
      C       NaN -1.274317       NaN -1.745953
",https://pandas.pydata.org/docs/user_guide/reshaping.html, pandas.pivot_table
"In [16]: pd.pivot_table(df, values=""D"", index=pd.Grouper(freq=""ME"", key=""F""), columns=""C"")
Out[16]: 
C                bar       foo
F                             
2013-01-31       NaN  0.595334
2013-02-28       NaN -0.494817
2013-03-31       NaN -1.274317
2013-04-30 -0.431886       NaN
2013-05-31  0.393570       NaN
2013-06-30  0.196903       NaN
2013-07-31       NaN  0.197720
2013-08-31       NaN -1.065818
2013-09-30       NaN -0.767769
2013-10-31 -0.995460       NaN
2013-11-30 -0.986678       NaN
2013-12-31  0.798396       NaN
",https://pandas.pydata.org/docs/user_guide/reshaping.html, pandas.pivot_table pandas.Grouper
"In [17]: table = df.pivot_table(
   ....:     index=[""A"", ""B""],
   ....:     columns=""C"",
   ....:     values=[""D"", ""E""],
   ....:     margins=True,
   ....:     aggfunc=""std""
   ....: )
   ....: 

In [18]: table
Out[18]: 
                D                             E                    
C             bar       foo       All       bar       foo       All
A     B                                                            
one   A  1.568517  0.178504  1.293926  0.179247  0.033718  0.371275
      B  1.157593  0.299748  0.860059  0.653280  0.885047  0.779837
      C  0.523425  0.133049  0.638297  1.111310  0.770555  0.938819
three A  0.995247       NaN  0.995247  0.049748       NaN  0.049748
      B       NaN  0.030522  0.030522       NaN  0.931203  0.931203
      C  0.386657       NaN  0.386657  0.386312       NaN  0.386312
two   A       NaN  0.111032  0.111032       NaN  1.146201  1.146201
      B  0.695438       NaN  0.695438  1.166526       NaN  1.166526
      C       NaN  0.331975  0.331975       NaN  0.043771  0.043771
All      1.014073  0.713941  0.871016  0.881376  0.984017  0.923568
",https://pandas.pydata.org/docs/user_guide/reshaping.html, pandas.DataFrame.pivot_table
"In [19]: table.stack(future_stack=True)
Out[19]: 
                  D         E
A   B C                      
one A bar  1.568517  0.179247
      foo  0.178504  0.033718
      All  1.293926  0.371275
    B bar  1.157593  0.653280
      foo  0.299748  0.885047
...             ...       ...
two C foo  0.331975  0.043771
      All  0.331975  0.043771
All   bar  1.014073  0.881376
      foo  0.713941  0.984017
      All  0.871016  0.923568

[30 rows x 2 columns]
",https://pandas.pydata.org/docs/user_guide/reshaping.html, pandas.DataFrame.stack
"In [20]: tuples = [
   ....:    [""bar"", ""bar"", ""baz"", ""baz"", ""foo"", ""foo"", ""qux"", ""qux""],
   ....:    [""one"", ""two"", ""one"", ""two"", ""one"", ""two"", ""one"", ""two""],
   ....: ]
   ....: 

In [21]: index = pd.MultiIndex.from_arrays(tuples, names=[""first"", ""second""])

In [22]: df = pd.DataFrame(np.random.randn(8, 2), index=index, columns=[""A"", ""B""])

In [23]: df2 = df[:4]

In [24]: df2
Out[24]: 
                     A         B
first second                    
bar   one     0.895717  0.805244
      two    -1.206412  2.565646
baz   one     1.431256  1.340309
      two    -1.170299 -0.226169
",https://pandas.pydata.org/docs/user_guide/reshaping.html, pandas.MultiIndex.from_arrays pandas.DataFrame
"In [25]: stacked = df2.stack(future_stack=True)

In [26]: stacked
Out[26]: 
first  second   
bar    one     A    0.895717
               B    0.805244
       two     A   -1.206412
               B    2.565646
baz    one     A    1.431256
               B    1.340309
       two     A   -1.170299
               B   -0.226169
dtype: float64
",https://pandas.pydata.org/docs/user_guide/reshaping.html, pandas.DataFrame.stack
"In [31]: index = pd.MultiIndex.from_product([[2, 1], [""a"", ""b""]])

In [32]: df = pd.DataFrame(np.random.randn(4), index=index, columns=[""A""])

In [33]: df
Out[33]: 
            A
2 a -1.413681
  b  1.607920
1 a  1.024180
  b  0.569605

In [34]: all(df.unstack().stack(future_stack=True) == df.sort_index())
Out[34]: True
",https://pandas.pydata.org/docs/user_guide/reshaping.html, pandas.MultiIndex.from_product pandas.DataFrame pandas.DataFrame.unstack pandas.DataFrame.stack pandas.DataFrame.sort_index
"In [35]: columns = pd.MultiIndex.from_tuples(
   ....:     [
   ....:         (""A"", ""cat"", ""long""),
   ....:         (""B"", ""cat"", ""long""),
   ....:         (""A"", ""dog"", ""short""),
   ....:         (""B"", ""dog"", ""short""),
   ....:     ],
   ....:     names=[""exp"", ""animal"", ""hair_length""],
   ....: )
   ....: 

In [36]: df = pd.DataFrame(np.random.randn(4, 4), columns=columns)

In [37]: df
Out[37]: 
exp                 A         B         A         B
animal            cat       cat       dog       dog
hair_length      long      long     short     short
0            0.875906 -2.211372  0.974466 -2.006747
1           -0.410001 -0.078638  0.545952 -1.219217
2           -1.226825  0.769804 -1.281247 -0.727707
3           -0.121306 -0.097883  0.695775  0.341734

In [38]: df.stack(level=[""animal"", ""hair_length""], future_stack=True)
Out[38]: 
exp                          A         B
  animal hair_length                    
0 cat    long         0.875906 -2.211372
  dog    short        0.974466 -2.006747
1 cat    long        -0.410001 -0.078638
  dog    short        0.545952 -1.219217
2 cat    long        -1.226825  0.769804
  dog    short       -1.281247 -0.727707
3 cat    long        -0.121306 -0.097883
  dog    short        0.695775  0.341734
",https://pandas.pydata.org/docs/user_guide/reshaping.html, pandas.MultiIndex.from_tuples pandas.DataFrame pandas.DataFrame.stack
"# df.stack(level=['animal', 'hair_length'], future_stack=True)
# from above is equivalent to:
In [39]: df.stack(level=[1, 2], future_stack=True)
Out[39]: 
exp                          A         B
  animal hair_length                    
0 cat    long         0.875906 -2.211372
  dog    short        0.974466 -2.006747
1 cat    long        -0.410001 -0.078638
  dog    short        0.545952 -1.219217
2 cat    long        -1.226825  0.769804
  dog    short       -1.281247 -0.727707
3 cat    long        -0.121306 -0.097883
  dog    short        0.695775  0.341734
",https://pandas.pydata.org/docs/user_guide/reshaping.html, pandas.DataFrame.stack
"In [40]: columns = pd.MultiIndex.from_tuples(
   ....:     [
   ....:         (""A"", ""cat""),
   ....:         (""B"", ""dog""),
   ....:         (""B"", ""cat""),
   ....:         (""A"", ""dog""),
   ....:     ],
   ....:     names=[""exp"", ""animal""],
   ....: )
   ....: 

In [41]: index = pd.MultiIndex.from_product(
   ....:     [(""bar"", ""baz"", ""foo"", ""qux""), (""one"", ""two"")], names=[""first"", ""second""]
   ....: )
   ....: 

In [42]: df = pd.DataFrame(np.random.randn(8, 4), index=index, columns=columns)

In [43]: df3 = df.iloc[[0, 1, 4, 7], [1, 2]]

In [44]: df3
Out[44]: 
exp                  B          
animal             dog       cat
first second                    
bar   one    -1.110336 -0.619976
      two     0.687738  0.176444
foo   one     1.314232  0.690579
qux   two     0.380396  0.084844

In [45]: df3.unstack()
Out[45]: 
exp            B                              
animal       dog                 cat          
second       one       two       one       two
first                                         
bar    -1.110336  0.687738 -0.619976  0.176444
foo     1.314232       NaN  0.690579       NaN
qux          NaN  0.380396       NaN  0.084844
",https://pandas.pydata.org/docs/user_guide/reshaping.html, pandas.MultiIndex.from_tuples pandas.MultiIndex.from_product pandas.DataFrame pandas.DataFrame.unstack
"In [46]: df3.unstack(fill_value=-1e9)
Out[46]: 
exp                B                                          
animal           dog                         cat              
second           one           two           one           two
first                                                         
bar    -1.110336e+00  6.877384e-01 -6.199759e-01  1.764443e-01
foo     1.314232e+00 -1.000000e+09  6.905793e-01 -1.000000e+09
qux    -1.000000e+09  3.803956e-01 -1.000000e+09  8.484421e-02
",https://pandas.pydata.org/docs/user_guide/reshaping.html, pandas.DataFrame.unstack
"In [47]: cheese = pd.DataFrame(
   ....:     {
   ....:         ""first"": [""John"", ""Mary""],
   ....:         ""last"": [""Doe"", ""Bo""],
   ....:         ""height"": [5.5, 6.0],
   ....:         ""weight"": [130, 150],
   ....:     }
   ....: )
   ....: 

In [48]: cheese
Out[48]: 
  first last  height  weight
0  John  Doe     5.5     130
1  Mary   Bo     6.0     150

In [49]: cheese.melt(id_vars=[""first"", ""last""])
Out[49]: 
  first last variable  value
0  John  Doe   height    5.5
1  Mary   Bo   height    6.0
2  John  Doe   weight  130.0
3  Mary   Bo   weight  150.0

In [50]: cheese.melt(id_vars=[""first"", ""last""], var_name=""quantity"")
Out[50]: 
  first last quantity  value
0  John  Doe   height    5.5
1  Mary   Bo   height    6.0
2  John  Doe   weight  130.0
3  Mary   Bo   weight  150.0
",https://pandas.pydata.org/docs/user_guide/reshaping.html, pandas.DataFrame pandas.DataFrame.melt
"In [51]: index = pd.MultiIndex.from_tuples([(""person"", ""A""), (""person"", ""B"")])

In [52]: cheese = pd.DataFrame(
   ....:     {
   ....:         ""first"": [""John"", ""Mary""],
   ....:         ""last"": [""Doe"", ""Bo""],
   ....:         ""height"": [5.5, 6.0],
   ....:         ""weight"": [130, 150],
   ....:     },
   ....:     index=index,
   ....: )
   ....: 

In [53]: cheese
Out[53]: 
         first last  height  weight
person A  John  Doe     5.5     130
       B  Mary   Bo     6.0     150

In [54]: cheese.melt(id_vars=[""first"", ""last""])
Out[54]: 
  first last variable  value
0  John  Doe   height    5.5
1  Mary   Bo   height    6.0
2  John  Doe   weight  130.0
3  Mary   Bo   weight  150.0

In [55]: cheese.melt(id_vars=[""first"", ""last""], ignore_index=False)
Out[55]: 
         first last variable  value
person A  John  Doe   height    5.5
       B  Mary   Bo   height    6.0
       A  John  Doe   weight  130.0
       B  Mary   Bo   weight  150.0
",https://pandas.pydata.org/docs/user_guide/reshaping.html, pandas.MultiIndex.from_tuples pandas.DataFrame pandas.DataFrame.melt
"In [56]: dft = pd.DataFrame(
   ....:     {
   ....:         ""A1970"": {0: ""a"", 1: ""b"", 2: ""c""},
   ....:         ""A1980"": {0: ""d"", 1: ""e"", 2: ""f""},
   ....:         ""B1970"": {0: 2.5, 1: 1.2, 2: 0.7},
   ....:         ""B1980"": {0: 3.2, 1: 1.3, 2: 0.1},
   ....:         ""X"": dict(zip(range(3), np.random.randn(3))),
   ....:     }
   ....: )
   ....: 

In [57]: dft[""id""] = dft.index

In [58]: dft
Out[58]: 
  A1970 A1980  B1970  B1980         X  id
0     a     d    2.5    3.2  1.519970   0
1     b     e    1.2    1.3 -0.493662   1
2     c     f    0.7    0.1  0.600178   2

In [59]: pd.wide_to_long(dft, [""A"", ""B""], i=""id"", j=""year"")
Out[59]: 
                X  A    B
id year                  
0  1970  1.519970  a  2.5
1  1970 -0.493662  b  1.2
2  1970  0.600178  c  0.7
0  1980  1.519970  d  3.2
1  1980 -0.493662  e  1.3
2  1980  0.600178  f  0.1
",https://pandas.pydata.org/docs/user_guide/reshaping.html, pandas.DataFrame pandas.wide_to_long
"In [60]: df = pd.DataFrame({""key"": list(""bbacab""), ""data1"": range(6)})

In [61]: pd.get_dummies(df[""key""])
Out[61]: 
       a      b      c
0  False   True  False
1  False   True  False
2   True  False  False
3  False  False   True
4   True  False  False
5  False   True  False

In [62]: df[""key""].str.get_dummies()
Out[62]: 
   a  b  c
0  0  1  0
1  0  1  0
2  1  0  0
3  0  0  1
4  1  0  0
5  0  1  0
",https://pandas.pydata.org/docs/user_guide/reshaping.html, pandas.DataFrame pandas.get_dummies
"In [63]: dummies = pd.get_dummies(df[""key""], prefix=""key"")

In [64]: dummies
Out[64]: 
   key_a  key_b  key_c
0  False   True  False
1  False   True  False
2   True  False  False
3  False  False   True
4   True  False  False
5  False   True  False

In [65]: df[[""data1""]].join(dummies)
Out[65]: 
   data1  key_a  key_b  key_c
0      0  False   True  False
1      1  False   True  False
2      2   True  False  False
3      3  False  False   True
4      4   True  False  False
5      5  False   True  False
",https://pandas.pydata.org/docs/user_guide/reshaping.html, pandas.get_dummies
"In [66]: values = np.random.randn(10)

In [67]: values
Out[67]: 
array([ 0.2742,  0.1329, -0.0237,  2.4102,  1.4505,  0.2061, -0.2519,
       -2.2136,  1.0633,  1.2661])

In [68]: bins = [0, 0.2, 0.4, 0.6, 0.8, 1]

In [69]: pd.get_dummies(pd.cut(values, bins))
Out[69]: 
   (0.0, 0.2]  (0.2, 0.4]  (0.4, 0.6]  (0.6, 0.8]  (0.8, 1.0]
0       False        True       False       False       False
1        True       False       False       False       False
2       False       False       False       False       False
3       False       False       False       False       False
4       False       False       False       False       False
5       False        True       False       False       False
6       False       False       False       False       False
7       False       False       False       False       False
8       False       False       False       False       False
9       False       False       False       False       False
",https://pandas.pydata.org/docs/user_guide/reshaping.html, pandas.array pandas.get_dummies pandas.cut
"In [70]: df = pd.DataFrame({""A"": [""a"", ""b"", ""a""], ""B"": [""c"", ""c"", ""b""], ""C"": [1, 2, 3]})

In [71]: pd.get_dummies(df)
Out[71]: 
   C    A_a    A_b    B_b    B_c
0  1   True  False  False   True
1  2  False   True  False   True
2  3   True  False   True  False
",https://pandas.pydata.org/docs/user_guide/reshaping.html, pandas.DataFrame pandas.get_dummies
"In [72]: pd.get_dummies(df, columns=[""A""])
Out[72]: 
   B  C    A_a    A_b
0  c  1   True  False
1  c  2  False   True
2  b  3   True  False
",https://pandas.pydata.org/docs/user_guide/reshaping.html, pandas.get_dummies
"In [73]: simple = pd.get_dummies(df, prefix=""new_prefix"")

In [74]: simple
Out[74]: 
   C  new_prefix_a  new_prefix_b  new_prefix_b  new_prefix_c
0  1          True         False         False          True
1  2         False          True         False          True
2  3          True         False          True         False

In [75]: from_list = pd.get_dummies(df, prefix=[""from_A"", ""from_B""])

In [76]: from_list
Out[76]: 
   C  from_A_a  from_A_b  from_B_b  from_B_c
0  1      True     False     False      True
1  2     False      True     False      True
2  3      True     False      True     False

In [77]: from_dict = pd.get_dummies(df, prefix={""B"": ""from_B"", ""A"": ""from_A""})

In [78]: from_dict
Out[78]: 
   C  from_A_a  from_A_b  from_B_b  from_B_c
0  1      True     False     False      True
1  2     False      True     False      True
2  3      True     False      True     False
",https://pandas.pydata.org/docs/user_guide/reshaping.html, pandas.get_dummies
"In [79]: s = pd.Series(list(""abcaa""))

In [80]: pd.get_dummies(s)
Out[80]: 
       a      b      c
0   True  False  False
1  False   True  False
2  False  False   True
3   True  False  False
4   True  False  False

In [81]: pd.get_dummies(s, drop_first=True)
Out[81]: 
       b      c
0  False  False
1   True  False
2  False   True
3  False  False
4  False  False
",https://pandas.pydata.org/docs/user_guide/reshaping.html, pandas.Series pandas.get_dummies
"In [82]: df = pd.DataFrame({""A"": list(""aaaaa""), ""B"": list(""ababc"")})

In [83]: pd.get_dummies(df)
Out[83]: 
    A_a    B_a    B_b    B_c
0  True   True  False  False
1  True  False   True  False
2  True   True  False  False
3  True  False   True  False
4  True  False  False   True

In [84]: pd.get_dummies(df, drop_first=True)
Out[84]: 
     B_b    B_c
0  False  False
1   True  False
2  False  False
3   True  False
4  False   True
",https://pandas.pydata.org/docs/user_guide/reshaping.html, pandas.DataFrame pandas.get_dummies
"In [85]: df = pd.DataFrame({""A"": list(""abc""), ""B"": [1.1, 2.2, 3.3]})

In [86]: pd.get_dummies(df, dtype=np.float32).dtypes
Out[86]: 
B      float64
A_a    float32
A_b    float32
A_c    float32
dtype: object
",https://pandas.pydata.org/docs/user_guide/reshaping.html, pandas.DataFrame pandas.get_dummies
"In [87]: df = pd.DataFrame({""prefix_a"": [0, 1, 0], ""prefix_b"": [1, 0, 1]})

In [88]: df
Out[88]: 
   prefix_a  prefix_b
0         0         1
1         1         0
2         0         1

In [89]: pd.from_dummies(df, sep=""_"")
Out[89]: 
  prefix
0      b
1      a
2      b
",https://pandas.pydata.org/docs/user_guide/reshaping.html, pandas.DataFrame pandas.from_dummies
"In [90]: df = pd.DataFrame({""prefix_a"": [0, 1, 0]})

In [91]: df
Out[91]: 
   prefix_a
0         0
1         1
2         0

In [92]: pd.from_dummies(df, sep=""_"", default_category=""b"")
Out[92]: 
  prefix
0      b
1      a
2      b
",https://pandas.pydata.org/docs/user_guide/reshaping.html, pandas.DataFrame pandas.from_dummies
"In [93]: keys = [""panda1"", ""panda2"", ""panda3""]

In [94]: values = [[""eats"", ""shoots""], [""shoots"", ""leaves""], [""eats"", ""leaves""]]

In [95]: df = pd.DataFrame({""keys"": keys, ""values"": values})

In [96]: df
Out[96]: 
     keys            values
0  panda1    [eats, shoots]
1  panda2  [shoots, leaves]
2  panda3    [eats, leaves]

In [97]: df[""values""].explode()
Out[97]: 
0      eats
0    shoots
1    shoots
1    leaves
2      eats
2    leaves
Name: values, dtype: object
",https://pandas.pydata.org/docs/user_guide/reshaping.html, pandas.DataFrame
"In [98]: df.explode(""values"")
Out[98]: 
     keys  values
0  panda1    eats
0  panda1  shoots
1  panda2  shoots
1  panda2  leaves
2  panda3    eats
2  panda3  leaves
",https://pandas.pydata.org/docs/user_guide/reshaping.html, pandas.DataFrame.explode
"In [99]: s = pd.Series([[1, 2, 3], ""foo"", [], [""a"", ""b""]])

In [100]: s
Out[100]: 
0    [1, 2, 3]
1          foo
2           []
3       [a, b]
dtype: object

In [101]: s.explode()
Out[101]: 
0      1
0      2
0      3
1    foo
2    NaN
3      a
3      b
dtype: object
",https://pandas.pydata.org/docs/user_guide/reshaping.html, pandas.Series pandas.Series.explode
"In [102]: df = pd.DataFrame([{""var1"": ""a,b,c"", ""var2"": 1}, {""var1"": ""d,e,f"", ""var2"": 2}])

In [103]: df.assign(var1=df.var1.str.split("","")).explode(""var1"")
Out[103]: 
  var1  var2
0    a     1
0    b     1
0    c     1
1    d     2
1    e     2
1    f     2
",https://pandas.pydata.org/docs/user_guide/reshaping.html, pandas.DataFrame pandas.DataFrame.assign
"In [104]: a = np.array([""foo"", ""foo"", ""bar"", ""bar"", ""foo"", ""foo""], dtype=object)

In [105]: b = np.array([""one"", ""one"", ""two"", ""one"", ""two"", ""one""], dtype=object)

In [106]: c = np.array([""dull"", ""dull"", ""shiny"", ""dull"", ""dull"", ""shiny""], dtype=object)

In [107]: pd.crosstab(a, [b, c], rownames=[""a""], colnames=[""b"", ""c""])
Out[107]: 
b    one        two      
c   dull shiny dull shiny
a                        
bar    1     0    0     1
foo    2     1    1     0
",https://pandas.pydata.org/docs/user_guide/reshaping.html, pandas.crosstab
"In [108]: df = pd.DataFrame(
   .....:     {""A"": [1, 2, 2, 2, 2], ""B"": [3, 3, 4, 4, 4], ""C"": [1, 1, np.nan, 1, 1]}
   .....: )
   .....: 

In [109]: df
Out[109]: 
   A  B    C
0  1  3  1.0
1  2  3  1.0
2  2  4  NaN
3  2  4  1.0
4  2  4  1.0

In [110]: pd.crosstab(df[""A""], df[""B""])
Out[110]: 
B  3  4
A      
1  1  0
2  1  3
",https://pandas.pydata.org/docs/user_guide/reshaping.html, pandas.DataFrame pandas.crosstab
"In [111]: foo = pd.Categorical([""a"", ""b""], categories=[""a"", ""b"", ""c""])

In [112]: bar = pd.Categorical([""d"", ""e""], categories=[""d"", ""e"", ""f""])

In [113]: pd.crosstab(foo, bar)
Out[113]: 
col_0  d  e
row_0      
a      1  0
b      0  1
",https://pandas.pydata.org/docs/user_guide/reshaping.html, pandas.Categorical pandas.crosstab
"In [114]: pd.crosstab(foo, bar, dropna=False)
Out[114]: 
col_0  d  e  f
row_0         
a      1  0  0
b      0  1  0
c      0  0  0
",https://pandas.pydata.org/docs/user_guide/reshaping.html, pandas.crosstab
"In [115]: pd.crosstab(df[""A""], df[""B""], normalize=True)
Out[115]: 
B    3    4
A          
1  0.2  0.0
2  0.2  0.6
",https://pandas.pydata.org/docs/user_guide/reshaping.html, pandas.crosstab
"In [116]: pd.crosstab(df[""A""], df[""B""], normalize=""columns"")
Out[116]: 
B    3    4
A          
1  0.5  0.0
2  0.5  1.0
",https://pandas.pydata.org/docs/user_guide/reshaping.html, pandas.crosstab
"In [117]: pd.crosstab(df[""A""], df[""B""], values=df[""C""], aggfunc=""sum"")
Out[117]: 
B    3    4
A          
1  1.0  NaN
2  1.0  2.0
",https://pandas.pydata.org/docs/user_guide/reshaping.html, pandas.crosstab
"In [118]: pd.crosstab(
   .....:     df[""A""], df[""B""], values=df[""C""], aggfunc=""sum"", normalize=True, margins=True
   .....: )
   .....: 
Out[118]: 
B       3    4   All
A                   
1    0.25  0.0  0.25
2    0.25  0.5  0.75
All  0.50  0.5  1.00
",https://pandas.pydata.org/docs/user_guide/reshaping.html, pandas.crosstab
"In [119]: ages = np.array([10, 15, 13, 12, 23, 25, 28, 59, 60])

In [120]: pd.cut(ages, bins=3)
Out[120]: 
[(9.95, 26.667], (9.95, 26.667], (9.95, 26.667], (9.95, 26.667], (9.95, 26.667], (9.95, 26.667], (26.667, 43.333], (43.333, 60.0], (43.333, 60.0]]
Categories (3, interval[float64, right]): [(9.95, 26.667] < (26.667, 43.333] < (43.333, 60.0]]
",https://pandas.pydata.org/docs/user_guide/reshaping.html, pandas.cut
"In [121]: pd.cut(ages, bins=[0, 18, 35, 70])
Out[121]: 
[(0, 18], (0, 18], (0, 18], (0, 18], (18, 35], (18, 35], (18, 35], (35, 70], (35, 70]]
Categories (3, interval[int64, right]): [(0, 18] < (18, 35] < (35, 70]]
",https://pandas.pydata.org/docs/user_guide/reshaping.html, pandas.cut
"In [122]: pd.cut(ages, bins=pd.IntervalIndex.from_breaks([0, 40, 70]))
Out[122]: 
[(0, 40], (0, 40], (0, 40], (0, 40], (0, 40], (0, 40], (0, 40], (40, 70], (40, 70]]
Categories (2, interval[int64, right]): [(0, 40] < (40, 70]]
",https://pandas.pydata.org/docs/user_guide/reshaping.html, pandas.cut pandas.IntervalIndex.from_breaks
"In [123]: x = pd.Series([""A"", ""A"", np.nan, ""B"", 3.14, np.inf])

In [124]: x
Out[124]: 
0       A
1       A
2     NaN
3       B
4    3.14
5     inf
dtype: object

In [125]: labels, uniques = pd.factorize(x)

In [126]: labels
Out[126]: array([ 0,  0, -1,  1,  2,  3])

In [127]: uniques
Out[127]: Index(['A', 'B', 3.14, inf], dtype='object')
",https://pandas.pydata.org/docs/user_guide/reshaping.html, pandas.Series pandas.factorize pandas.array pandas.Index
"In [128]: pd.Categorical(x)
Out[128]: 
['A', 'A', NaN, 'B', 3.14, inf]
Categories (4, object): [3.14, inf, 'A', 'B']
",https://pandas.pydata.org/docs/user_guide/reshaping.html, pandas.Categorical
"In [3]: s = pd.Series([1, 3, 5, np.nan, 6, 8])

In [4]: s
Out[4]: 
0    1.0
1    3.0
2    5.0
3    NaN
4    6.0
5    8.0
dtype: float64
",https://pandas.pydata.org/docs/user_guide/10min.html, pandas.Series
"In [5]: dates = pd.date_range(""20130101"", periods=6)

In [6]: dates
Out[6]: 
DatetimeIndex(['2013-01-01', '2013-01-02', '2013-01-03', '2013-01-04',
               '2013-01-05', '2013-01-06'],
              dtype='datetime64[ns]', freq='D')

In [7]: df = pd.DataFrame(np.random.randn(6, 4), index=dates, columns=list(""ABCD""))

In [8]: df
Out[8]: 
                   A         B         C         D
2013-01-01  0.469112 -0.282863 -1.509059 -1.135632
2013-01-02  1.212112 -0.173215  0.119209 -1.044236
2013-01-03 -0.861849 -2.104569 -0.494929  1.071804
2013-01-04  0.721555 -0.706771 -1.039575  0.271860
2013-01-05 -0.424972  0.567020  0.276232 -1.087401
2013-01-06 -0.673690  0.113648 -1.478427  0.524988
",https://pandas.pydata.org/docs/user_guide/10min.html, pandas.date_range pandas.DatetimeIndex pandas.DataFrame
"In [9]: df2 = pd.DataFrame(
   ...:     {
   ...:         ""A"": 1.0,
   ...:         ""B"": pd.Timestamp(""20130102""),
   ...:         ""C"": pd.Series(1, index=list(range(4)), dtype=""float32""),
   ...:         ""D"": np.array([3] * 4, dtype=""int32""),
   ...:         ""E"": pd.Categorical([""test"", ""train"", ""test"", ""train""]),
   ...:         ""F"": ""foo"",
   ...:     }
   ...: )
   ...: 

In [10]: df2
Out[10]: 
     A          B    C  D      E    F
0  1.0 2013-01-02  1.0  3   test  foo
1  1.0 2013-01-02  1.0  3  train  foo
2  1.0 2013-01-02  1.0  3   test  foo
3  1.0 2013-01-02  1.0  3  train  foo
",https://pandas.pydata.org/docs/user_guide/10min.html, pandas.DataFrame pandas.Series pandas.Categorical
"In [13]: df.head()
Out[13]: 
                   A         B         C         D
2013-01-01  0.469112 -0.282863 -1.509059 -1.135632
2013-01-02  1.212112 -0.173215  0.119209 -1.044236
2013-01-03 -0.861849 -2.104569 -0.494929  1.071804
2013-01-04  0.721555 -0.706771 -1.039575  0.271860
2013-01-05 -0.424972  0.567020  0.276232 -1.087401

In [14]: df.tail(3)
Out[14]: 
                   A         B         C         D
2013-01-04  0.721555 -0.706771 -1.039575  0.271860
2013-01-05 -0.424972  0.567020  0.276232 -1.087401
2013-01-06 -0.673690  0.113648 -1.478427  0.524988
",https://pandas.pydata.org/docs/user_guide/10min.html, pandas.DataFrame.head pandas.DataFrame.tail
"In [15]: df.index
Out[15]: 
DatetimeIndex(['2013-01-01', '2013-01-02', '2013-01-03', '2013-01-04',
               '2013-01-05', '2013-01-06'],
              dtype='datetime64[ns]', freq='D')

In [16]: df.columns
Out[16]: Index(['A', 'B', 'C', 'D'], dtype='object')
",https://pandas.pydata.org/docs/user_guide/10min.html, pandas.DatetimeIndex pandas.Index
"In [17]: df.to_numpy()
Out[17]: 
array([[ 0.4691, -0.2829, -1.5091, -1.1356],
       [ 1.2121, -0.1732,  0.1192, -1.0442],
       [-0.8618, -2.1046, -0.4949,  1.0718],
       [ 0.7216, -0.7068, -1.0396,  0.2719],
       [-0.425 ,  0.567 ,  0.2762, -1.0874],
       [-0.6737,  0.1136, -1.4784,  0.525 ]])
",https://pandas.pydata.org/docs/user_guide/10min.html, pandas.DataFrame.to_numpy pandas.array
"In [18]: df2.dtypes
Out[18]: 
A          float64
B    datetime64[s]
C          float32
D            int32
E         category
F           object
dtype: object

In [19]: df2.to_numpy()
Out[19]: 
array([[1.0, Timestamp('2013-01-02 00:00:00'), 1.0, 3, 'test', 'foo'],
       [1.0, Timestamp('2013-01-02 00:00:00'), 1.0, 3, 'train', 'foo'],
       [1.0, Timestamp('2013-01-02 00:00:00'), 1.0, 3, 'test', 'foo'],
       [1.0, Timestamp('2013-01-02 00:00:00'), 1.0, 3, 'train', 'foo']],
      dtype=object)
",https://pandas.pydata.org/docs/user_guide/10min.html, pandas.DataFrame.to_numpy pandas.array
"In [20]: df.describe()
Out[20]: 
              A         B         C         D
count  6.000000  6.000000  6.000000  6.000000
mean   0.073711 -0.431125 -0.687758 -0.233103
std    0.843157  0.922818  0.779887  0.973118
min   -0.861849 -2.104569 -1.509059 -1.135632
25%   -0.611510 -0.600794 -1.368714 -1.076610
50%    0.022070 -0.228039 -0.767252 -0.386188
75%    0.658444  0.041933 -0.034326  0.461706
max    1.212112  0.567020  0.276232  1.071804
",https://pandas.pydata.org/docs/user_guide/10min.html, pandas.DataFrame.describe
"In [22]: df.sort_index(axis=1, ascending=False)
Out[22]: 
                   D         C         B         A
2013-01-01 -1.135632 -1.509059 -0.282863  0.469112
2013-01-02 -1.044236  0.119209 -0.173215  1.212112
2013-01-03  1.071804 -0.494929 -2.104569 -0.861849
2013-01-04  0.271860 -1.039575 -0.706771  0.721555
2013-01-05 -1.087401  0.276232  0.567020 -0.424972
2013-01-06  0.524988 -1.478427  0.113648 -0.673690
",https://pandas.pydata.org/docs/user_guide/10min.html, pandas.DataFrame.sort_index
"In [23]: df.sort_values(by=""B"")
Out[23]: 
                   A         B         C         D
2013-01-03 -0.861849 -2.104569 -0.494929  1.071804
2013-01-04  0.721555 -0.706771 -1.039575  0.271860
2013-01-01  0.469112 -0.282863 -1.509059 -1.135632
2013-01-02  1.212112 -0.173215  0.119209 -1.044236
2013-01-06 -0.673690  0.113648 -1.478427  0.524988
2013-01-05 -0.424972  0.567020  0.276232 -1.087401
",https://pandas.pydata.org/docs/user_guide/10min.html, pandas.DataFrame.sort_values
"In [41]: df2 = df.copy()

In [42]: df2[""E""] = [""one"", ""one"", ""two"", ""three"", ""four"", ""three""]

In [43]: df2
Out[43]: 
                   A         B         C         D      E
2013-01-01  0.469112 -0.282863 -1.509059 -1.135632    one
2013-01-02  1.212112 -0.173215  0.119209 -1.044236    one
2013-01-03 -0.861849 -2.104569 -0.494929  1.071804    two
2013-01-04  0.721555 -0.706771 -1.039575  0.271860  three
2013-01-05 -0.424972  0.567020  0.276232 -1.087401   four
2013-01-06 -0.673690  0.113648 -1.478427  0.524988  three

In [44]: df2[df2[""E""].isin([""two"", ""four""])]
Out[44]: 
                   A         B         C         D     E
2013-01-03 -0.861849 -2.104569 -0.494929  1.071804   two
2013-01-05 -0.424972  0.567020  0.276232 -1.087401  four
",https://pandas.pydata.org/docs/user_guide/10min.html, pandas.DataFrame.copy
"In [45]: s1 = pd.Series([1, 2, 3, 4, 5, 6], index=pd.date_range(""20130102"", periods=6))

In [46]: s1
Out[46]: 
2013-01-02    1
2013-01-03    2
2013-01-04    3
2013-01-05    4
2013-01-06    5
2013-01-07    6
Freq: D, dtype: int64

In [47]: df[""F""] = s1
",https://pandas.pydata.org/docs/user_guide/10min.html, pandas.Series pandas.date_range
"In [52]: df2 = df.copy()

In [53]: df2[df2 > 0] = -df2

In [54]: df2
Out[54]: 
                   A         B         C    D    F
2013-01-01  0.000000  0.000000 -1.509059 -5.0  NaN
2013-01-02 -1.212112 -0.173215 -0.119209 -5.0 -1.0
2013-01-03 -0.861849 -2.104569 -0.494929 -5.0 -2.0
2013-01-04 -0.721555 -0.706771 -1.039575 -5.0 -3.0
2013-01-05 -0.424972 -0.567020 -0.276232 -5.0 -4.0
2013-01-06 -0.673690 -0.113648 -1.478427 -5.0 -5.0
",https://pandas.pydata.org/docs/user_guide/10min.html, pandas.DataFrame.copy
"In [55]: df1 = df.reindex(index=dates[0:4], columns=list(df.columns) + [""E""])

In [56]: df1.loc[dates[0] : dates[1], ""E""] = 1

In [57]: df1
Out[57]: 
                   A         B         C    D    F    E
2013-01-01  0.000000  0.000000 -1.509059  5.0  NaN  1.0
2013-01-02  1.212112 -0.173215  0.119209  5.0  1.0  1.0
2013-01-03 -0.861849 -2.104569 -0.494929  5.0  2.0  NaN
2013-01-04  0.721555 -0.706771 -1.039575  5.0  3.0  NaN
",https://pandas.pydata.org/docs/user_guide/10min.html, pandas.DataFrame.reindex
"In [58]: df1.dropna(how=""any"")
Out[58]: 
                   A         B         C    D    F    E
2013-01-02  1.212112 -0.173215  0.119209  5.0  1.0  1.0
",https://pandas.pydata.org/docs/user_guide/10min.html, pandas.DataFrame.dropna
"In [59]: df1.fillna(value=5)
Out[59]: 
                   A         B         C    D    F    E
2013-01-01  0.000000  0.000000 -1.509059  5.0  5.0  1.0
2013-01-02  1.212112 -0.173215  0.119209  5.0  1.0  1.0
2013-01-03 -0.861849 -2.104569 -0.494929  5.0  2.0  5.0
2013-01-04  0.721555 -0.706771 -1.039575  5.0  3.0  5.0
",https://pandas.pydata.org/docs/user_guide/10min.html, pandas.DataFrame.fillna
"In [60]: pd.isna(df1)
Out[60]: 
                A      B      C      D      F      E
2013-01-01  False  False  False  False   True  False
2013-01-02  False  False  False  False  False  False
2013-01-03  False  False  False  False  False   True
2013-01-04  False  False  False  False  False   True
",https://pandas.pydata.org/docs/user_guide/10min.html, pandas.isna
"In [61]: df.mean()
Out[61]: 
A   -0.004474
B   -0.383981
C   -0.687758
D    5.000000
F    3.000000
dtype: float64
",https://pandas.pydata.org/docs/user_guide/10min.html, pandas.DataFrame.mean
"In [62]: df.mean(axis=1)
Out[62]: 
2013-01-01    0.872735
2013-01-02    1.431621
2013-01-03    0.707731
2013-01-04    1.395042
2013-01-05    1.883656
2013-01-06    1.592306
Freq: D, dtype: float64
",https://pandas.pydata.org/docs/user_guide/10min.html, pandas.DataFrame.mean
"In [63]: s = pd.Series([1, 3, 5, np.nan, 6, 8], index=dates).shift(2)

In [64]: s
Out[64]: 
2013-01-01    NaN
2013-01-02    NaN
2013-01-03    1.0
2013-01-04    3.0
2013-01-05    5.0
2013-01-06    NaN
Freq: D, dtype: float64

In [65]: df.sub(s, axis=""index"")
Out[65]: 
                   A         B         C    D    F
2013-01-01       NaN       NaN       NaN  NaN  NaN
2013-01-02       NaN       NaN       NaN  NaN  NaN
2013-01-03 -1.861849 -3.104569 -1.494929  4.0  1.0
2013-01-04 -2.278445 -3.706771 -4.039575  2.0  0.0
2013-01-05 -5.424972 -4.432980 -4.723768  0.0 -1.0
2013-01-06       NaN       NaN       NaN  NaN  NaN
",https://pandas.pydata.org/docs/user_guide/10min.html, pandas.Series pandas.DataFrame.sub
"In [66]: df.agg(lambda x: np.mean(x) * 5.6)
Out[66]: 
A    -0.025054
B    -2.150294
C    -3.851445
D    28.000000
F    16.800000
dtype: float64

In [67]: df.transform(lambda x: x * 101.2)
Out[67]: 
                     A           B           C      D      F
2013-01-01    0.000000    0.000000 -152.716721  506.0    NaN
2013-01-02  122.665737  -17.529322   12.063922  506.0  101.2
2013-01-03  -87.219115 -212.982405  -50.086843  506.0  202.4
2013-01-04   73.021382  -71.525239 -105.204988  506.0  303.6
2013-01-05  -43.007200   57.382459   27.954680  506.0  404.8
2013-01-06  -68.177398   11.501219 -149.616767  506.0  506.0
",https://pandas.pydata.org/docs/user_guide/10min.html, pandas.DataFrame.agg pandas.DataFrame.transform
"In [68]: s = pd.Series(np.random.randint(0, 7, size=10))

In [69]: s
Out[69]: 
0    4
1    2
2    1
3    2
4    6
5    4
6    4
7    6
8    4
9    4
dtype: int64

In [70]: s.value_counts()
Out[70]: 
4    5
2    2
6    2
1    1
Name: count, dtype: int64
",https://pandas.pydata.org/docs/user_guide/10min.html, pandas.Series pandas.Series.value_counts
"In [71]: s = pd.Series([""A"", ""B"", ""C"", ""Aaba"", ""Baca"", np.nan, ""CABA"", ""dog"", ""cat""])

In [72]: s.str.lower()
Out[72]: 
0       a
1       b
2       c
3    aaba
4    baca
5     NaN
6    caba
7     dog
8     cat
dtype: object
",https://pandas.pydata.org/docs/user_guide/10min.html, pandas.Series pandas.Series.str.lower
"In [73]: df = pd.DataFrame(np.random.randn(10, 4))

In [74]: df
Out[74]: 
          0         1         2         3
0 -0.548702  1.467327 -1.015962 -0.483075
1  1.637550 -1.217659 -0.291519 -1.745505
2 -0.263952  0.991460 -0.919069  0.266046
3 -0.709661  1.669052  1.037882 -1.705775
4 -0.919854 -0.042379  1.247642 -0.009920
5  0.290213  0.495767  0.362949  1.548106
6 -1.131345 -0.089329  0.337863 -0.945867
7 -0.932132  1.956030  0.017587 -0.016692
8 -0.575247  0.254161 -1.143704  0.215897
9  1.193555 -0.077118 -0.408530 -0.862495

# break it into pieces
In [75]: pieces = [df[:3], df[3:7], df[7:]]

In [76]: pd.concat(pieces)
Out[76]: 
          0         1         2         3
0 -0.548702  1.467327 -1.015962 -0.483075
1  1.637550 -1.217659 -0.291519 -1.745505
2 -0.263952  0.991460 -0.919069  0.266046
3 -0.709661  1.669052  1.037882 -1.705775
4 -0.919854 -0.042379  1.247642 -0.009920
5  0.290213  0.495767  0.362949  1.548106
6 -1.131345 -0.089329  0.337863 -0.945867
7 -0.932132  1.956030  0.017587 -0.016692
8 -0.575247  0.254161 -1.143704  0.215897
9  1.193555 -0.077118 -0.408530 -0.862495
",https://pandas.pydata.org/docs/user_guide/10min.html, pandas.DataFrame pandas.concat
"In [77]: left = pd.DataFrame({""key"": [""foo"", ""foo""], ""lval"": [1, 2]})

In [78]: right = pd.DataFrame({""key"": [""foo"", ""foo""], ""rval"": [4, 5]})

In [79]: left
Out[79]: 
   key  lval
0  foo     1
1  foo     2

In [80]: right
Out[80]: 
   key  rval
0  foo     4
1  foo     5

In [81]: pd.merge(left, right, on=""key"")
Out[81]: 
   key  lval  rval
0  foo     1     4
1  foo     1     5
2  foo     2     4
3  foo     2     5
",https://pandas.pydata.org/docs/user_guide/10min.html, pandas.DataFrame pandas.merge
"In [82]: left = pd.DataFrame({""key"": [""foo"", ""bar""], ""lval"": [1, 2]})

In [83]: right = pd.DataFrame({""key"": [""foo"", ""bar""], ""rval"": [4, 5]})

In [84]: left
Out[84]: 
   key  lval
0  foo     1
1  bar     2

In [85]: right
Out[85]: 
   key  rval
0  foo     4
1  bar     5

In [86]: pd.merge(left, right, on=""key"")
Out[86]: 
   key  lval  rval
0  foo     1     4
1  bar     2     5
",https://pandas.pydata.org/docs/user_guide/10min.html, pandas.DataFrame pandas.merge
"In [87]: df = pd.DataFrame(
   ....:     {
   ....:         ""A"": [""foo"", ""bar"", ""foo"", ""bar"", ""foo"", ""bar"", ""foo"", ""foo""],
   ....:         ""B"": [""one"", ""one"", ""two"", ""three"", ""two"", ""two"", ""one"", ""three""],
   ....:         ""C"": np.random.randn(8),
   ....:         ""D"": np.random.randn(8),
   ....:     }
   ....: )
   ....: 

In [88]: df
Out[88]: 
     A      B         C         D
0  foo    one  1.346061 -1.577585
1  bar    one  1.511763  0.396823
2  foo    two  1.627081 -0.105381
3  bar  three -0.990582 -0.532532
4  foo    two -0.441652  1.453749
5  bar    two  1.211526  1.208843
6  foo    one  0.268520 -0.080952
7  foo  three  0.024580 -0.264610
",https://pandas.pydata.org/docs/user_guide/10min.html, pandas.DataFrame
"In [89]: df.groupby(""A"")[[""C"", ""D""]].sum()
Out[89]: 
            C         D
A                      
bar  1.732707  1.073134
foo  2.824590 -0.574779
",https://pandas.pydata.org/docs/user_guide/10min.html, pandas.DataFrame.groupby
"In [90]: df.groupby([""A"", ""B""]).sum()
Out[90]: 
                  C         D
A   B                        
bar one    1.511763  0.396823
    three -0.990582 -0.532532
    two    1.211526  1.208843
foo one    1.614581 -1.658537
    three  0.024580 -0.264610
    two    1.185429  1.348368
",https://pandas.pydata.org/docs/user_guide/10min.html, pandas.DataFrame.groupby
"In [91]: arrays = [
   ....:    [""bar"", ""bar"", ""baz"", ""baz"", ""foo"", ""foo"", ""qux"", ""qux""],
   ....:    [""one"", ""two"", ""one"", ""two"", ""one"", ""two"", ""one"", ""two""],
   ....: ]
   ....: 

In [92]: index = pd.MultiIndex.from_arrays(arrays, names=[""first"", ""second""])

In [93]: df = pd.DataFrame(np.random.randn(8, 2), index=index, columns=[""A"", ""B""])

In [94]: df2 = df[:4]

In [95]: df2
Out[95]: 
                     A         B
first second                    
bar   one    -0.727965 -0.589346
      two     0.339969 -0.693205
baz   one    -0.339355  0.593616
      two     0.884345  1.591431
",https://pandas.pydata.org/docs/user_guide/10min.html, pandas.MultiIndex.from_arrays pandas.DataFrame
"In [96]: stacked = df2.stack(future_stack=True)

In [97]: stacked
Out[97]: 
first  second   
bar    one     A   -0.727965
               B   -0.589346
       two     A    0.339969
               B   -0.693205
baz    one     A   -0.339355
               B    0.593616
       two     A    0.884345
               B    1.591431
dtype: float64
",https://pandas.pydata.org/docs/user_guide/10min.html, pandas.DataFrame.stack
"In [101]: df = pd.DataFrame(
   .....:     {
   .....:         ""A"": [""one"", ""one"", ""two"", ""three""] * 3,
   .....:         ""B"": [""A"", ""B"", ""C""] * 4,
   .....:         ""C"": [""foo"", ""foo"", ""foo"", ""bar"", ""bar"", ""bar""] * 2,
   .....:         ""D"": np.random.randn(12),
   .....:         ""E"": np.random.randn(12),
   .....:     }
   .....: )
   .....: 

In [102]: df
Out[102]: 
        A  B    C         D         E
0     one  A  foo -1.202872  0.047609
1     one  B  foo -1.814470 -0.136473
2     two  C  foo  1.018601 -0.561757
3   three  A  bar -0.595447 -1.623033
4     one  B  bar  1.395433  0.029399
5     one  C  bar -0.392670 -0.542108
6     two  A  foo  0.007207  0.282696
7   three  B  foo  1.928123 -0.087302
8     one  C  foo -0.055224 -1.575170
9     one  A  bar  2.395985  1.771208
10    two  B  bar  1.552825  0.816482
11  three  C  bar  0.166599  1.100230
",https://pandas.pydata.org/docs/user_guide/10min.html, pandas.DataFrame
"In [103]: pd.pivot_table(df, values=""D"", index=[""A"", ""B""], columns=[""C""])
Out[103]: 
C             bar       foo
A     B                    
one   A  2.395985 -1.202872
      B  1.395433 -1.814470
      C -0.392670 -0.055224
three A -0.595447       NaN
      B       NaN  1.928123
      C  0.166599       NaN
two   A       NaN  0.007207
      B  1.552825       NaN
      C       NaN  1.018601
",https://pandas.pydata.org/docs/user_guide/10min.html, pandas.pivot_table
"In [104]: rng = pd.date_range(""1/1/2012"", periods=100, freq=""s"")

In [105]: ts = pd.Series(np.random.randint(0, 500, len(rng)), index=rng)

In [106]: ts.resample(""5Min"").sum()
Out[106]: 
2012-01-01    24182
Freq: 5min, dtype: int64
",https://pandas.pydata.org/docs/user_guide/10min.html, pandas.date_range pandas.Series pandas.Series.resample
"In [107]: rng = pd.date_range(""3/6/2012 00:00"", periods=5, freq=""D"")

In [108]: ts = pd.Series(np.random.randn(len(rng)), rng)

In [109]: ts
Out[109]: 
2012-03-06    1.857704
2012-03-07   -1.193545
2012-03-08    0.677510
2012-03-09   -0.153931
2012-03-10    0.520091
Freq: D, dtype: float64

In [110]: ts_utc = ts.tz_localize(""UTC"")

In [111]: ts_utc
Out[111]: 
2012-03-06 00:00:00+00:00    1.857704
2012-03-07 00:00:00+00:00   -1.193545
2012-03-08 00:00:00+00:00    0.677510
2012-03-09 00:00:00+00:00   -0.153931
2012-03-10 00:00:00+00:00    0.520091
Freq: D, dtype: float64
",https://pandas.pydata.org/docs/user_guide/10min.html, pandas.date_range pandas.Series pandas.Series.tz_localize
"In [112]: ts_utc.tz_convert(""US/Eastern"")
Out[112]: 
2012-03-05 19:00:00-05:00    1.857704
2012-03-06 19:00:00-05:00   -1.193545
2012-03-07 19:00:00-05:00    0.677510
2012-03-08 19:00:00-05:00   -0.153931
2012-03-09 19:00:00-05:00    0.520091
Freq: D, dtype: float64
",https://pandas.pydata.org/docs/user_guide/10min.html, pandas.Series.tz_convert
"In [113]: rng
Out[113]: 
DatetimeIndex(['2012-03-06', '2012-03-07', '2012-03-08', '2012-03-09',
               '2012-03-10'],
              dtype='datetime64[ns]', freq='D')

In [114]: rng + pd.offsets.BusinessDay(5)
Out[114]: 
DatetimeIndex(['2012-03-13', '2012-03-14', '2012-03-15', '2012-03-16',
               '2012-03-16'],
              dtype='datetime64[ns]', freq=None)
",https://pandas.pydata.org/docs/user_guide/10min.html, pandas.DatetimeIndex
"In [115]: df = pd.DataFrame(
   .....:     {""id"": [1, 2, 3, 4, 5, 6], ""raw_grade"": [""a"", ""b"", ""b"", ""a"", ""a"", ""e""]}
   .....: )
   .....: 
",https://pandas.pydata.org/docs/user_guide/10min.html, pandas.DataFrame
"In [122]: df.sort_values(by=""grade"")
Out[122]: 
   id raw_grade      grade
5   6         e   very bad
1   2         b       good
2   3         b       good
0   1         a  very good
3   4         a  very good
4   5         a  very good
",https://pandas.pydata.org/docs/user_guide/10min.html, pandas.DataFrame.sort_values
"In [123]: df.groupby(""grade"", observed=False).size()
Out[123]: 
grade
very bad     1
bad          0
medium       0
good         2
very good    3
dtype: int64
",https://pandas.pydata.org/docs/user_guide/10min.html, pandas.DataFrame.groupby
"In [126]: ts = pd.Series(np.random.randn(1000), index=pd.date_range(""1/1/2000"", periods=1000))

In [127]: ts = ts.cumsum()

In [128]: ts.plot();
",https://pandas.pydata.org/docs/user_guide/10min.html, pandas.Series pandas.date_range pandas.Series.cumsum pandas.Series.plot
"In [129]: df = pd.DataFrame(
   .....:     np.random.randn(1000, 4), index=ts.index, columns=[""A"", ""B"", ""C"", ""D""]
   .....: )
   .....: 

In [130]: df = df.cumsum()

In [131]: plt.figure();

In [132]: df.plot();

In [133]: plt.legend(loc='best');
",https://pandas.pydata.org/docs/user_guide/10min.html, pandas.DataFrame pandas.DataFrame.cumsum pandas.DataFrame.plot
"In [134]: df = pd.DataFrame(np.random.randint(0, 5, (10, 5)))

In [135]: df.to_csv(""foo.csv"")
",https://pandas.pydata.org/docs/user_guide/10min.html, pandas.DataFrame pandas.DataFrame.to_csv
"In [136]: pd.read_csv(""foo.csv"")
Out[136]: 
   Unnamed: 0  0  1  2  3  4
0           0  4  3  1  1  2
1           1  1  0  2  3  2
2           2  1  4  2  1  2
3           3  0  4  0  2  2
4           4  4  2  2  3  4
5           5  4  0  4  3  1
6           6  2  1  2  0  3
7           7  4  0  4  4  4
8           8  4  4  1  0  1
9           9  0  4  3  0  3
",https://pandas.pydata.org/docs/user_guide/10min.html, pandas.read_csv
"In [137]: df.to_parquet(""foo.parquet"")
",https://pandas.pydata.org/docs/user_guide/10min.html, pandas.DataFrame.to_parquet
"In [138]: pd.read_parquet(""foo.parquet"")
Out[138]: 
   0  1  2  3  4
0  4  3  1  1  2
1  1  0  2  3  2
2  1  4  2  1  2
3  0  4  0  2  2
4  4  2  2  3  4
5  4  0  4  3  1
6  2  1  2  0  3
7  4  0  4  4  4
8  4  4  1  0  1
9  0  4  3  0  3
",https://pandas.pydata.org/docs/user_guide/10min.html, pandas.read_parquet
"In [139]: df.to_excel(""foo.xlsx"", sheet_name=""Sheet1"")
",https://pandas.pydata.org/docs/user_guide/10min.html, pandas.DataFrame.to_excel
"In [140]: pd.read_excel(""foo.xlsx"", ""Sheet1"", index_col=None, na_values=[""NA""])
Out[140]: 
   Unnamed: 0  0  1  2  3  4
0           0  4  3  1  1  2
1           1  1  0  2  3  2
2           2  1  4  2  1  2
3           3  0  4  0  2  2
4           4  4  2  2  3  4
5           5  4  0  4  3  1
6           6  2  1  2  0  3
7           7  4  0  4  4  4
8           8  4  4  1  0  1
9           9  0  4  3  0  3
",https://pandas.pydata.org/docs/user_guide/10min.html, pandas.read_excel
"In [141]: if pd.Series([False, True, False]):
   .....:      print(""I was true"")
   .....: 
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
 in ?()
----> 1 if pd.Series([False, True, False]):
      2      print(""I was true"")

~/work/pandas/pandas/pandas/core/generic.py in ?(self)
   1575     @final
   1576     def __nonzero__(self) -> NoReturn:
-> 1577         raise ValueError(
   1578             f""The truth value of a {type(self).__name__} is ambiguous. ""
   1579             ""Use a.empty, a.bool(), a.item(), a.any() or a.all().""
   1580         )

ValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().
",https://pandas.pydata.org/docs/user_guide/10min.html, pandas.Series pandas.Index.item pandas.Index.any pandas.Index.all
"In [1]: ser = pd.Series([-1.5, 0.2, None], dtype=""float32[pyarrow]"")

In [2]: ser
Out[2]: 
0    -1.5
1     0.2
2    
dtype: float[pyarrow]

In [3]: idx = pd.Index([True, None], dtype=""bool[pyarrow]"")

In [4]: idx
Out[4]: Index([True, ], dtype='bool[pyarrow]')

In [5]: df = pd.DataFrame([[1, 2], [3, 4]], dtype=""uint64[pyarrow]"")

In [6]: df
Out[6]: 
   0  1
0  1  2
1  3  4
",https://pandas.pydata.org/docs/user_guide/pyarrow.html, pandas.Series pandas.Index pandas.Index pandas.DataFrame
"In [7]: import pyarrow as pa

In [8]: data = list(""abc"")

In [9]: ser_sd = pd.Series(data, dtype=""string[pyarrow]"")

In [10]: ser_ad = pd.Series(data, dtype=pd.ArrowDtype(pa.string()))

In [11]: ser_ad.dtype == ser_sd.dtype
Out[11]: False

In [12]: ser_sd.str.contains(""a"")
Out[12]: 
0     True
1    False
2    False
dtype: boolean

In [13]: ser_ad.str.contains(""a"")
Out[13]: 
0     True
1    False
2    False
dtype: bool[pyarrow]
",https://pandas.pydata.org/docs/user_guide/pyarrow.html, pandas.Series pandas.ArrowDtype pandas.Series.str.contains pandas.Series.str.contains
"In [14]: import pyarrow as pa

In [15]: list_str_type = pa.list_(pa.string())

In [16]: ser = pd.Series([[""hello""], [""there""]], dtype=pd.ArrowDtype(list_str_type))

In [17]: ser
Out[17]: 
0    ['hello']
1    ['there']
dtype: list[pyarrow]
",https://pandas.pydata.org/docs/user_guide/pyarrow.html, pandas.Series pandas.ArrowDtype
"In [18]: from datetime import time

In [19]: idx = pd.Index([time(12, 30), None], dtype=pd.ArrowDtype(pa.time64(""us"")))

In [20]: idx
Out[20]: Index([12:30:00, ], dtype='time64[us][pyarrow]')
",https://pandas.pydata.org/docs/user_guide/pyarrow.html, pandas.Index pandas.Timestamp.time pandas.ArrowDtype pandas.Index
"In [21]: from decimal import Decimal

In [22]: decimal_type = pd.ArrowDtype(pa.decimal128(3, scale=2))

In [23]: data = [[Decimal(""3.19""), None], [None, Decimal(""-1.23"")]]

In [24]: df = pd.DataFrame(data, dtype=decimal_type)

In [25]: df
Out[25]: 
      0      1
0  3.19   
1    -1.23
",https://pandas.pydata.org/docs/user_guide/pyarrow.html, pandas.ArrowDtype pandas.DataFrame
"In [26]: pa_array = pa.array(
   ....:     [{""1"": ""2""}, {""10"": ""20""}, None],
   ....:     type=pa.map_(pa.string(), pa.string()),
   ....: )
   ....: 

In [27]: ser = pd.Series(pd.arrays.ArrowExtensionArray(pa_array))

In [28]: ser
Out[28]: 
0      [('1', '2')]
1    [('10', '20')]
2              
dtype: map[pyarrow]
",https://pandas.pydata.org/docs/user_guide/pyarrow.html, pandas.Series pandas.arrays.ArrowExtensionArray
"In [29]: ser = pd.Series([1, 2, None], dtype=""uint8[pyarrow]"")

In [30]: pa.array(ser)
Out[30]: 

[
  1,
  2,
  null
]

In [31]: idx = pd.Index(ser)

In [32]: pa.array(idx)
Out[32]: 

[
  1,
  2,
  null
]
",https://pandas.pydata.org/docs/user_guide/pyarrow.html, pandas.Series pandas.Index
"In [37]: import pyarrow as pa

In [38]: ser = pd.Series([-1.545, 0.211, None], dtype=""float32[pyarrow]"")

In [39]: ser.mean()
Out[39]: -0.6669999808073044

In [40]: ser + ser
Out[40]: 
0    -3.09
1    0.422
2     
dtype: float[pyarrow]

In [41]: ser > (ser + 1)
Out[41]: 
0    False
1    False
2     
dtype: bool[pyarrow]

In [42]: ser.dropna()
Out[42]: 
0   -1.545
1    0.211
dtype: float[pyarrow]

In [43]: ser.isna()
Out[43]: 
0    False
1    False
2     True
dtype: bool

In [44]: ser.fillna(0)
Out[44]: 
0   -1.545
1    0.211
2      0.0
dtype: float[pyarrow]
",https://pandas.pydata.org/docs/user_guide/pyarrow.html, pandas.Series pandas.Series.mean pandas.Series.dropna pandas.Series.isna pandas.Series.fillna
"In [45]: ser_str = pd.Series([""a"", ""b"", None], dtype=pd.ArrowDtype(pa.string()))

In [46]: ser_str.str.startswith(""a"")
Out[46]: 
0     True
1    False
2     
dtype: bool[pyarrow]
",https://pandas.pydata.org/docs/user_guide/pyarrow.html, pandas.Series pandas.ArrowDtype pandas.Series.str.startswith
"In [47]: from datetime import datetime

In [48]: pa_type = pd.ArrowDtype(pa.timestamp(""ns""))

In [49]: ser_dt = pd.Series([datetime(2022, 1, 1), None], dtype=pa_type)

In [50]: ser_dt.dt.strftime(""%Y-%m"")
Out[50]: 
0    2022-01
1       
dtype: string[pyarrow]
",https://pandas.pydata.org/docs/user_guide/pyarrow.html, pandas.ArrowDtype pandas.Series pandas.Series.dt.strftime
"In [51]: import io

In [52]: data = io.StringIO(""""""a,b,c
   ....:    1,2.5,True
   ....:    3,4.5,False
   ....: """""")
   ....: 

In [53]: df = pd.read_csv(data, engine=""pyarrow"")

In [54]: df
Out[54]: 
   a    b      c
0  1  2.5   True
1  3  4.5  False
",https://pandas.pydata.org/docs/user_guide/pyarrow.html, pandas.read_csv
"In [55]: import io

In [56]: data = io.StringIO(""""""a,b,c,d,e,f,g,h,i
   ....:     1,2.5,True,a,,,,,
   ....:     3,4.5,False,b,6,7.5,True,a,
   ....: """""")
   ....: 

In [57]: df_pyarrow = pd.read_csv(data, dtype_backend=""pyarrow"")

In [58]: df_pyarrow.dtypes
Out[58]: 
a     int64[pyarrow]
b    double[pyarrow]
c      bool[pyarrow]
d    string[pyarrow]
e     int64[pyarrow]
f    double[pyarrow]
g      bool[pyarrow]
h    string[pyarrow]
i      null[pyarrow]
dtype: object
",https://pandas.pydata.org/docs/user_guide/pyarrow.html, pandas.read_csv
"In [1]: pd.Series([1, 2], dtype=np.int64).reindex([0, 1, 2])
Out[1]: 
0    1.0
1    2.0
2    NaN
dtype: float64

In [2]: pd.Series([True, False], dtype=np.bool_).reindex([0, 1, 2])
Out[2]: 
0     True
1    False
2      NaN
dtype: object
",https://pandas.pydata.org/docs/user_guide/missing_data.html, pandas.Series
"In [3]: pd.Series([1, 2], dtype=np.dtype(""timedelta64[ns]"")).reindex([0, 1, 2])
Out[3]: 
0   0 days 00:00:00.000000001
1   0 days 00:00:00.000000002
2                         NaT
dtype: timedelta64[ns]

In [4]: pd.Series([1, 2], dtype=np.dtype(""datetime64[ns]"")).reindex([0, 1, 2])
Out[4]: 
0   1970-01-01 00:00:00.000000001
1   1970-01-01 00:00:00.000000002
2                             NaT
dtype: datetime64[ns]

In [5]: pd.Series([""2020"", ""2020""], dtype=pd.PeriodDtype(""D"")).reindex([0, 1, 2])
Out[5]: 
0    2020-01-01
1    2020-01-01
2           NaT
dtype: period[D]
",https://pandas.pydata.org/docs/user_guide/missing_data.html, pandas.Series pandas.PeriodDtype
"In [6]: pd.Series([1, 2], dtype=""Int64"").reindex([0, 1, 2])
Out[6]: 
0       1
1       2
2    
dtype: Int64

In [7]: pd.Series([True, False], dtype=""boolean[pyarrow]"").reindex([0, 1, 2])
Out[7]: 
0     True
1    False
2     
dtype: bool[pyarrow]
",https://pandas.pydata.org/docs/user_guide/missing_data.html, pandas.Series
"In [8]: ser = pd.Series([pd.Timestamp(""2020-01-01""), pd.NaT])

In [9]: ser
Out[9]: 
0   2020-01-01
1          NaT
dtype: datetime64[ns]

In [10]: pd.isna(ser)
Out[10]: 
0    False
1     True
dtype: bool
",https://pandas.pydata.org/docs/user_guide/missing_data.html, pandas.Series pandas.isna
"In [11]: ser = pd.Series([1, None], dtype=object)

In [12]: ser
Out[12]: 
0       1
1    None
dtype: object

In [13]: pd.isna(ser)
Out[13]: 
0    False
1     True
dtype: bool
",https://pandas.pydata.org/docs/user_guide/missing_data.html, pandas.Series pandas.isna
"In [18]: ser = pd.Series([True, None], dtype=""boolean[pyarrow]"")

In [19]: ser == pd.NA
Out[19]: 
0    
1    
dtype: bool[pyarrow]

In [20]: pd.isna(ser)
Out[20]: 
0    False
1     True
dtype: bool
",https://pandas.pydata.org/docs/user_guide/missing_data.html, pandas.Series pandas.isna
"In [21]: s = pd.Series([1, 2, None], dtype=""Int64"")

In [22]: s
Out[22]: 
0       1
1       2
2    
dtype: Int64

In [23]: s[2]
Out[23]: 

In [24]: s[2] is pd.NA
Out[24]: True
",https://pandas.pydata.org/docs/user_guide/missing_data.html, pandas.Series
"In [32]: pd.isna(pd.NA)
Out[32]: True
",https://pandas.pydata.org/docs/user_guide/missing_data.html, pandas.isna
"In [48]: a = np.array([1, 2, 3])

In [49]: np.greater(a, pd.NA)
Out[49]: array([, , ], dtype=object)
",https://pandas.pydata.org/docs/user_guide/missing_data.html, pandas.array
"In [50]: import io

In [51]: data = io.StringIO(""a,b\n,True\n2,"")

In [52]: df = pd.read_csv(data)

In [53]: df.dtypes
Out[53]: 
a    float64
b     object
dtype: object

In [54]: df_conv = df.convert_dtypes()

In [55]: df_conv
Out[55]: 
      a     b
0    True
1     2  

In [56]: df_conv.dtypes
Out[56]: 
a      Int64
b    boolean
dtype: object
",https://pandas.pydata.org/docs/user_guide/missing_data.html, pandas.read_csv pandas.DataFrame.convert_dtypes
"In [57]: ser = pd.Series([1., 2., 3.])

In [58]: ser.loc[0] = None

In [59]: ser
Out[59]: 
0    NaN
1    2.0
2    3.0
dtype: float64

In [60]: ser = pd.Series([pd.Timestamp(""2021""), pd.Timestamp(""2021"")])

In [61]: ser.iloc[0] = np.nan

In [62]: ser
Out[62]: 
0          NaT
1   2021-01-01
dtype: datetime64[ns]

In [63]: ser = pd.Series([True, False], dtype=""boolean[pyarrow]"")

In [64]: ser.iloc[0] = None

In [65]: ser
Out[65]: 
0     
1    False
dtype: bool[pyarrow]
",https://pandas.pydata.org/docs/user_guide/missing_data.html, pandas.Series
"In [66]: s = pd.Series([""a"", ""b"", ""c""], dtype=object)

In [67]: s.loc[0] = None

In [68]: s.loc[1] = np.nan

In [69]: s
Out[69]: 
0    None
1     NaN
2       c
dtype: object
",https://pandas.pydata.org/docs/user_guide/missing_data.html, pandas.Series
"In [70]: ser1 = pd.Series([np.nan, np.nan, 2, 3])

In [71]: ser2 = pd.Series([np.nan, 1, np.nan, 4])

In [72]: ser1
Out[72]: 
0    NaN
1    NaN
2    2.0
3    3.0
dtype: float64

In [73]: ser2
Out[73]: 
0    NaN
1    1.0
2    NaN
3    4.0
dtype: float64

In [74]: ser1 + ser2
Out[74]: 
0    NaN
1    NaN
2    NaN
3    7.0
dtype: float64
",https://pandas.pydata.org/docs/user_guide/missing_data.html, pandas.Series
"In [75]: pd.Series([np.nan]).sum()
Out[75]: 0.0

In [76]: pd.Series([], dtype=""float64"").sum()
Out[76]: 0.0
",https://pandas.pydata.org/docs/user_guide/missing_data.html, pandas.Series
"In [77]: pd.Series([np.nan]).prod()
Out[77]: 1.0

In [78]: pd.Series([], dtype=""float64"").prod()
Out[78]: 1.0
",https://pandas.pydata.org/docs/user_guide/missing_data.html, pandas.Series
"In [79]: ser = pd.Series([1, np.nan, 3, np.nan])

In [80]: ser
Out[80]: 
0    1.0
1    NaN
2    3.0
3    NaN
dtype: float64

In [81]: ser.cumsum()
Out[81]: 
0    1.0
1    NaN
2    4.0
3    NaN
dtype: float64

In [82]: ser.cumsum(skipna=False)
Out[82]: 
0    1.0
1    NaN
2    NaN
3    NaN
dtype: float64
",https://pandas.pydata.org/docs/user_guide/missing_data.html, pandas.Series pandas.Series.cumsum
"In [83]: df = pd.DataFrame([[np.nan, 1, 2], [1, 2, np.nan], [1, 2, 3]])

In [84]: df
Out[84]: 
     0  1    2
0  NaN  1  2.0
1  1.0  2  NaN
2  1.0  2  3.0

In [85]: df.dropna()
Out[85]: 
     0  1    2
2  1.0  2  3.0

In [86]: df.dropna(axis=1)
Out[86]: 
   1
0  1
1  2
2  2

In [87]: ser = pd.Series([1, pd.NA], dtype=""int64[pyarrow]"")

In [88]: ser.dropna()
Out[88]: 
0    1
dtype: int64[pyarrow]
",https://pandas.pydata.org/docs/user_guide/missing_data.html, pandas.DataFrame pandas.DataFrame.dropna pandas.Series pandas.Series.dropna
"In [89]: data = {""np"": [1.0, np.nan, np.nan, 2], ""arrow"": pd.array([1.0, pd.NA, pd.NA, 2], dtype=""float64[pyarrow]"")}

In [90]: df = pd.DataFrame(data)

In [91]: df
Out[91]: 
    np  arrow
0  1.0    1.0
1  NaN   
2  NaN   
3  2.0    2.0

In [92]: df.fillna(0)
Out[92]: 
    np  arrow
0  1.0    1.0
1  0.0    0.0
2  0.0    0.0
3  2.0    2.0
",https://pandas.pydata.org/docs/user_guide/missing_data.html, pandas.array pandas.DataFrame pandas.DataFrame.fillna
"In [93]: df.ffill()
Out[93]: 
    np  arrow
0  1.0    1.0
1  1.0    1.0
2  1.0    1.0
3  2.0    2.0

In [94]: df.bfill()
Out[94]: 
    np  arrow
0  1.0    1.0
1  2.0    2.0
2  2.0    2.0
3  2.0    2.0
",https://pandas.pydata.org/docs/user_guide/missing_data.html, pandas.DataFrame.ffill pandas.DataFrame.bfill
"In [95]: df.ffill(limit=1)
Out[95]: 
    np  arrow
0  1.0    1.0
1  1.0    1.0
2  NaN   
3  2.0    2.0
",https://pandas.pydata.org/docs/user_guide/missing_data.html, pandas.DataFrame.ffill
"In [96]: dff = pd.DataFrame(np.arange(30, dtype=np.float64).reshape(10, 3), columns=list(""ABC""))

In [97]: dff.iloc[3:5, 0] = np.nan

In [98]: dff.iloc[4:6, 1] = np.nan

In [99]: dff.iloc[5:8, 2] = np.nan

In [100]: dff
Out[100]: 
      A     B     C
0   0.0   1.0   2.0
1   3.0   4.0   5.0
2   6.0   7.0   8.0
3   NaN  10.0  11.0
4   NaN   NaN  14.0
5  15.0   NaN   NaN
6  18.0  19.0   NaN
7  21.0  22.0   NaN
8  24.0  25.0  26.0
9  27.0  28.0  29.0

In [101]: dff.fillna(dff.mean())
Out[101]: 
       A     B          C
0   0.00   1.0   2.000000
1   3.00   4.0   5.000000
2   6.00   7.0   8.000000
3  14.25  10.0  11.000000
4  14.25  14.5  14.000000
5  15.00  14.5  13.571429
6  18.00  19.0  13.571429
7  21.00  22.0  13.571429
8  24.00  25.0  26.000000
9  27.00  28.0  29.000000
",https://pandas.pydata.org/docs/user_guide/missing_data.html, pandas.DataFrame pandas.DataFrame.fillna pandas.DataFrame.mean
"In [102]: dff.where(pd.notna(dff), dff.mean(), axis=""columns"")
Out[102]: 
       A     B          C
0   0.00   1.0   2.000000
1   3.00   4.0   5.000000
2   6.00   7.0   8.000000
3  14.25  10.0  11.000000
4  14.25  14.5  14.000000
5  15.00  14.5  13.571429
6  18.00  19.0  13.571429
7  21.00  22.0  13.571429
8  24.00  25.0  26.000000
9  27.00  28.0  29.000000
",https://pandas.pydata.org/docs/user_guide/missing_data.html, pandas.DataFrame.where pandas.notna pandas.DataFrame.mean
"In [103]: df = pd.DataFrame(
   .....:     {
   .....:         ""A"": [1, 2.1, np.nan, 4.7, 5.6, 6.8],
   .....:         ""B"": [0.25, np.nan, np.nan, 4, 12.2, 14.4],
   .....:     }
   .....: )
   .....: 

In [104]: df
Out[104]: 
     A      B
0  1.0   0.25
1  2.1    NaN
2  NaN    NaN
3  4.7   4.00
4  5.6  12.20
5  6.8  14.40

In [105]: df.interpolate()
Out[105]: 
     A      B
0  1.0   0.25
1  2.1   1.50
2  3.4   2.75
3  4.7   4.00
4  5.6  12.20
5  6.8  14.40

In [106]: idx = pd.date_range(""2020-01-01"", periods=10, freq=""D"")

In [107]: data = np.random.default_rng(2).integers(0, 10, 10).astype(np.float64)

In [108]: ts = pd.Series(data, index=idx)

In [109]: ts.iloc[[1, 2, 5, 6, 9]] = np.nan

In [110]: ts
Out[110]: 
2020-01-01    8.0
2020-01-02    NaN
2020-01-03    NaN
2020-01-04    2.0
2020-01-05    4.0
2020-01-06    NaN
2020-01-07    NaN
2020-01-08    0.0
2020-01-09    3.0
2020-01-10    NaN
Freq: D, dtype: float64

In [111]: ts.plot()
Out[111]: 
",https://pandas.pydata.org/docs/user_guide/missing_data.html, pandas.DataFrame pandas.DataFrame.interpolate pandas.date_range pandas.Series pandas.Series.plot
"In [112]: ts.interpolate()
Out[112]: 
2020-01-01    8.000000
2020-01-02    6.000000
2020-01-03    4.000000
2020-01-04    2.000000
2020-01-05    4.000000
2020-01-06    2.666667
2020-01-07    1.333333
2020-01-08    0.000000
2020-01-09    3.000000
2020-01-10    3.000000
Freq: D, dtype: float64

In [113]: ts.interpolate().plot()
Out[113]: 
",https://pandas.pydata.org/docs/user_guide/missing_data.html, pandas.Series.interpolate
"In [114]: ts2 = ts.iloc[[0, 1, 3, 7, 9]]

In [115]: ts2
Out[115]: 
2020-01-01    8.0
2020-01-02    NaN
2020-01-04    2.0
2020-01-08    0.0
2020-01-10    NaN
dtype: float64

In [116]: ts2.interpolate()
Out[116]: 
2020-01-01    8.0
2020-01-02    5.0
2020-01-04    2.0
2020-01-08    0.0
2020-01-10    0.0
dtype: float64

In [117]: ts2.interpolate(method=""time"")
Out[117]: 
2020-01-01    8.0
2020-01-02    6.0
2020-01-04    2.0
2020-01-08    0.0
2020-01-10    0.0
dtype: float64
",https://pandas.pydata.org/docs/user_guide/missing_data.html, pandas.Series.interpolate
"In [118]: idx = [0.0, 1.0, 10.0]

In [119]: ser = pd.Series([0.0, np.nan, 10.0], idx)

In [120]: ser
Out[120]: 
0.0      0.0
1.0      NaN
10.0    10.0
dtype: float64

In [121]: ser.interpolate()
Out[121]: 
0.0      0.0
1.0      5.0
10.0    10.0
dtype: float64

In [122]: ser.interpolate(method=""values"")
Out[122]: 
0.0      0.0
1.0      1.0
10.0    10.0
dtype: float64
",https://pandas.pydata.org/docs/user_guide/missing_data.html, pandas.Series pandas.Series.interpolate
"In [123]: df = pd.DataFrame(
   .....:    {
   .....:       ""A"": [1, 2.1, np.nan, 4.7, 5.6, 6.8],
   .....:       ""B"": [0.25, np.nan, np.nan, 4, 12.2, 14.4],
   .....:    }
   .....: )
   .....: 

In [124]: df
Out[124]: 
     A      B
0  1.0   0.25
1  2.1    NaN
2  NaN    NaN
3  4.7   4.00
4  5.6  12.20
5  6.8  14.40

In [125]: df.interpolate(method=""barycentric"")
Out[125]: 
      A       B
0  1.00   0.250
1  2.10  -7.660
2  3.53  -4.515
3  4.70   4.000
4  5.60  12.200
5  6.80  14.400

In [126]: df.interpolate(method=""pchip"")
Out[126]: 
         A          B
0  1.00000   0.250000
1  2.10000   0.672808
2  3.43454   1.928950
3  4.70000   4.000000
4  5.60000  12.200000
5  6.80000  14.400000

In [127]: df.interpolate(method=""akima"")
Out[127]: 
          A          B
0  1.000000   0.250000
1  2.100000  -0.873316
2  3.406667   0.320034
3  4.700000   4.000000
4  5.600000  12.200000
5  6.800000  14.400000
",https://pandas.pydata.org/docs/user_guide/missing_data.html, pandas.DataFrame pandas.DataFrame.interpolate
"In [128]: df.interpolate(method=""spline"", order=2)
Out[128]: 
          A          B
0  1.000000   0.250000
1  2.100000  -0.428598
2  3.404545   1.206900
3  4.700000   4.000000
4  5.600000  12.200000
5  6.800000  14.400000

In [129]: df.interpolate(method=""polynomial"", order=2)
Out[129]: 
          A          B
0  1.000000   0.250000
1  2.100000  -2.703846
2  3.451351  -1.453846
3  4.700000   4.000000
4  5.600000  12.200000
5  6.800000  14.400000
",https://pandas.pydata.org/docs/user_guide/missing_data.html, pandas.DataFrame.interpolate
"In [130]: np.random.seed(2)

In [131]: ser = pd.Series(np.arange(1, 10.1, 0.25) ** 2 + np.random.randn(37))

In [132]: missing = np.array([4, 13, 14, 15, 16, 17, 18, 20, 29])

In [133]: ser.iloc[missing] = np.nan

In [134]: methods = [""linear"", ""quadratic"", ""cubic""]

In [135]: df = pd.DataFrame({m: ser.interpolate(method=m) for m in methods})

In [136]: df.plot()
Out[136]: 
",https://pandas.pydata.org/docs/user_guide/missing_data.html, pandas.Series pandas.DataFrame pandas.Series.interpolate pandas.DataFrame.plot
"In [137]: ser = pd.Series(np.sort(np.random.uniform(size=100)))

# interpolate at new_index
In [138]: new_index = ser.index.union(pd.Index([49.25, 49.5, 49.75, 50.25, 50.5, 50.75]))

In [139]: interp_s = ser.reindex(new_index).interpolate(method=""pchip"")

In [140]: interp_s.loc[49:51]
Out[140]: 
49.00    0.471410
49.25    0.476841
49.50    0.481780
49.75    0.485998
50.00    0.489266
50.25    0.491814
50.50    0.493995
50.75    0.495763
51.00    0.497074
dtype: float64
",https://pandas.pydata.org/docs/user_guide/missing_data.html, pandas.Series pandas.Index pandas.Series.reindex
"In [141]: ser = pd.Series([np.nan, np.nan, 5, np.nan, np.nan, np.nan, 13, np.nan, np.nan])

In [142]: ser
Out[142]: 
0     NaN
1     NaN
2     5.0
3     NaN
4     NaN
5     NaN
6    13.0
7     NaN
8     NaN
dtype: float64

In [143]: ser.interpolate()
Out[143]: 
0     NaN
1     NaN
2     5.0
3     7.0
4     9.0
5    11.0
6    13.0
7    13.0
8    13.0
dtype: float64

In [144]: ser.interpolate(limit=1)
Out[144]: 
0     NaN
1     NaN
2     5.0
3     7.0
4     NaN
5     NaN
6    13.0
7    13.0
8     NaN
dtype: float64
",https://pandas.pydata.org/docs/user_guide/missing_data.html, pandas.Series pandas.Series.interpolate
"In [145]: ser.interpolate(limit=1, limit_direction=""backward"")
Out[145]: 
0     NaN
1     5.0
2     5.0
3     NaN
4     NaN
5    11.0
6    13.0
7     NaN
8     NaN
dtype: float64

In [146]: ser.interpolate(limit=1, limit_direction=""both"")
Out[146]: 
0     NaN
1     5.0
2     5.0
3     7.0
4     NaN
5    11.0
6    13.0
7    13.0
8     NaN
dtype: float64

In [147]: ser.interpolate(limit_direction=""both"")
Out[147]: 
0     5.0
1     5.0
2     5.0
3     7.0
4     9.0
5    11.0
6    13.0
7    13.0
8    13.0
dtype: float64
",https://pandas.pydata.org/docs/user_guide/missing_data.html, pandas.Series.interpolate
"# fill one consecutive inside value in both directions
In [148]: ser.interpolate(limit_direction=""both"", limit_area=""inside"", limit=1)
Out[148]: 
0     NaN
1     NaN
2     5.0
3     7.0
4     NaN
5    11.0
6    13.0
7     NaN
8     NaN
dtype: float64

# fill all consecutive outside values backward
In [149]: ser.interpolate(limit_direction=""backward"", limit_area=""outside"")
Out[149]: 
0     5.0
1     5.0
2     5.0
3     NaN
4     NaN
5     NaN
6    13.0
7     NaN
8     NaN
dtype: float64

# fill all consecutive outside values in both directions
In [150]: ser.interpolate(limit_direction=""both"", limit_area=""outside"")
Out[150]: 
0     5.0
1     5.0
2     5.0
3     NaN
4     NaN
5     NaN
6    13.0
7    13.0
8    13.0
dtype: float64
",https://pandas.pydata.org/docs/user_guide/missing_data.html, pandas.Series.interpolate
"In [151]: df = pd.DataFrame(np.eye(3))

In [152]: df
Out[152]: 
     0    1    2
0  1.0  0.0  0.0
1  0.0  1.0  0.0
2  0.0  0.0  1.0

In [153]: df_missing = df.replace(0, np.nan)

In [154]: df_missing
Out[154]: 
     0    1    2
0  1.0  NaN  NaN
1  NaN  1.0  NaN
2  NaN  NaN  1.0

In [155]: df_filled = df_missing.replace(np.nan, 2)

In [156]: df_filled
Out[156]: 
     0    1    2
0  1.0  2.0  2.0
1  2.0  1.0  2.0
2  2.0  2.0  1.0
",https://pandas.pydata.org/docs/user_guide/missing_data.html, pandas.DataFrame pandas.DataFrame.replace
"In [159]: d = {""a"": list(range(4)), ""b"": list(""ab..""), ""c"": [""a"", ""b"", np.nan, ""d""]}

In [160]: df = pd.DataFrame(d)

In [161]: df.replace(""."", np.nan)
Out[161]: 
   a    b    c
0  0    a    a
1  1    b    b
2  2  NaN  NaN
3  3  NaN    d
",https://pandas.pydata.org/docs/user_guide/missing_data.html, pandas.DataFrame pandas.DataFrame.replace
"In [162]: df.replace(r""\s*\.\s*"", np.nan, regex=True)
Out[162]: 
   a    b    c
0  0    a    a
1  1    b    b
2  2  NaN  NaN
3  3  NaN    d
",https://pandas.pydata.org/docs/user_guide/missing_data.html, pandas.DataFrame.replace
"In [163]: df.replace([r""\."", r""(a)""], [""dot"", r""\1stuff""], regex=True)
Out[163]: 
   a       b       c
0  0  astuff  astuff
1  1       b       b
2  2     dot     NaN
3  3     dot       d
",https://pandas.pydata.org/docs/user_guide/missing_data.html, pandas.DataFrame.replace
"In [164]: df.replace({""b"": r""\s*\.\s*""}, {""b"": np.nan}, regex=True)
Out[164]: 
   a    b    c
0  0    a    a
1  1    b    b
2  2  NaN  NaN
3  3  NaN    d
",https://pandas.pydata.org/docs/user_guide/missing_data.html, pandas.DataFrame.replace
"In [165]: df.replace({""b"": {""b"": r""""}}, regex=True)
Out[165]: 
   a  b    c
0  0  a    a
1  1       b
2  2  .  NaN
3  3  .    d

In [166]: df.replace(regex={""b"": {r""\s*\.\s*"": np.nan}})
Out[166]: 
   a    b    c
0  0    a    a
1  1    b    b
2  2  NaN  NaN
3  3  NaN    d

In [167]: df.replace({""b"": r""\s*(\.)\s*""}, {""b"": r""\1ty""}, regex=True)
Out[167]: 
   a    b    c
0  0    a    a
1  1    b    b
2  2  .ty  NaN
3  3  .ty    d
",https://pandas.pydata.org/docs/user_guide/missing_data.html, pandas.DataFrame.replace
"In [168]: df.replace([r""\s*\.\s*"", r""a|b""], ""placeholder"", regex=True)
Out[168]: 
   a            b            c
0  0  placeholder  placeholder
1  1  placeholder  placeholder
2  2  placeholder          NaN
3  3  placeholder            d
",https://pandas.pydata.org/docs/user_guide/missing_data.html, pandas.DataFrame.replace
"In [169]: df.replace(regex=[r""\s*\.\s*"", r""a|b""], value=""placeholder"")
Out[169]: 
   a            b            c
0  0  placeholder  placeholder
1  1  placeholder  placeholder
2  2  placeholder          NaN
3  3  placeholder            d
",https://pandas.pydata.org/docs/user_guide/missing_data.html, pandas.DataFrame.replace
"In [3]: s1 = pd.Series([0, 1, 2], index=[""a"", ""b"", ""b""])

In [4]: s1.reindex([""a"", ""b"", ""c""])
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
Cell In[4], line 1
----> 1 s1.reindex([""a"", ""b"", ""c""])

File ~/work/pandas/pandas/pandas/core/series.py:5153, in Series.reindex(self, index, axis, method, copy, level, fill_value, limit, tolerance)
   5136 @doc(
   5137     NDFrame.reindex,  # type: ignore[has-type]
   5138     klass=_shared_doc_kwargs[""klass""],
   (...)
   5151     tolerance=None,
   5152 ) -> Series:
-> 5153     return super().reindex(
   5154         index=index,
   5155         method=method,
   5156         copy=copy,
   5157         level=level,
   5158         fill_value=fill_value,
   5159         limit=limit,
   5160         tolerance=tolerance,
   5161     )

File ~/work/pandas/pandas/pandas/core/generic.py:5610, in NDFrame.reindex(self, labels, index, columns, axis, method, copy, level, fill_value, limit, tolerance)
   5607     return self._reindex_multi(axes, copy, fill_value)
   5609 # perform the reindex on the axes
-> 5610 return self._reindex_axes(
   5611     axes, level, limit, tolerance, method, fill_value, copy
   5612 ).__finalize__(self, method=""reindex"")

File ~/work/pandas/pandas/pandas/core/generic.py:5633, in NDFrame._reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy)
   5630     continue
   5632 ax = self._get_axis(a)
-> 5633 new_index, indexer = ax.reindex(
   5634     labels, level=level, limit=limit, tolerance=tolerance, method=method
   5635 )
   5637 axis = self._get_axis_number(a)
   5638 obj = obj._reindex_with_indexers(
   5639     {axis: [new_index, indexer]},
   5640     fill_value=fill_value,
   5641     copy=copy,
   5642     allow_dups=False,
   5643 )

File ~/work/pandas/pandas/pandas/core/indexes/base.py:4429, in Index.reindex(self, target, method, level, limit, tolerance)
   4426     raise ValueError(""cannot handle a non-unique multi-index!"")
   4427 elif not self.is_unique:
   4428     # GH#42568
-> 4429     raise ValueError(""cannot reindex on an axis with duplicate labels"")
   4430 else:
   4431     indexer, _ = self.get_indexer_non_unique(target)

ValueError: cannot reindex on an axis with duplicate labels
",https://pandas.pydata.org/docs/user_guide/duplicates.html, pandas.Series pandas.Series.reindex pandas.Series.reindex pandas.Index.reindex pandas.Index.get_indexer_non_unique
"In [5]: df1 = pd.DataFrame([[0, 1, 2], [3, 4, 5]], columns=[""A"", ""A"", ""B""])

In [6]: df1
Out[6]: 
   A  A  B
0  0  1  2
1  3  4  5
",https://pandas.pydata.org/docs/user_guide/duplicates.html, pandas.DataFrame
"In [9]: df2 = pd.DataFrame({""A"": [0, 1, 2]}, index=[""a"", ""a"", ""b""])

In [10]: df2
Out[10]: 
   A
a  0
a  1
b  2

In [11]: df2.loc[""b"", ""A""]  # a scalar
Out[11]: 2

In [12]: df2.loc[""a"", ""A""]  # a Series
Out[12]: 
a    0
a    1
Name: A, dtype: int64
",https://pandas.pydata.org/docs/user_guide/duplicates.html, pandas.DataFrame
"In [16]: df2.index.duplicated()
Out[16]: array([False,  True, False])
",https://pandas.pydata.org/docs/user_guide/duplicates.html, pandas.array
"In [18]: df2.groupby(level=0).mean()
Out[18]: 
     A
a  0.5
b  2.0
",https://pandas.pydata.org/docs/user_guide/duplicates.html, pandas.DataFrame.groupby
"In [19]: pd.Series([0, 1, 2], index=[""a"", ""b"", ""b""]).set_flags(allows_duplicate_labels=False)
---------------------------------------------------------------------------
DuplicateLabelError                       Traceback (most recent call last)
Cell In[19], line 1
----> 1 pd.Series([0, 1, 2], index=[""a"", ""b"", ""b""]).set_flags(allows_duplicate_labels=False)

File ~/work/pandas/pandas/pandas/core/generic.py:508, in NDFrame.set_flags(self, copy, allows_duplicate_labels)
    506 df = self.copy(deep=copy and not using_copy_on_write())
    507 if allows_duplicate_labels is not None:
--> 508     df.flags[""allows_duplicate_labels""] = allows_duplicate_labels
    509 return df

File ~/work/pandas/pandas/pandas/core/flags.py:109, in Flags.__setitem__(self, key, value)
    107 if key not in self._keys:
    108     raise ValueError(f""Unknown flag {key}. Must be one of {self._keys}"")
--> 109 setattr(self, key, value)

File ~/work/pandas/pandas/pandas/core/flags.py:96, in Flags.allows_duplicate_labels(self, value)
     94 if not value:
     95     for ax in obj.axes:
---> 96         ax._maybe_check_unique()
     98 self._allows_duplicate_labels = value

File ~/work/pandas/pandas/pandas/core/indexes/base.py:715, in Index._maybe_check_unique(self)
    712 duplicates = self._format_duplicate_message()
    713 msg += f""\n{duplicates}""
--> 715 raise DuplicateLabelError(msg)

DuplicateLabelError: Index has duplicates.
      positions
label          
b        [1, 2]
",https://pandas.pydata.org/docs/user_guide/duplicates.html, pandas.Series pandas.errors.DuplicateLabelError
"In [20]: pd.DataFrame([[0, 1, 2], [3, 4, 5]], columns=[""A"", ""B"", ""C""],).set_flags(
   ....:     allows_duplicate_labels=False
   ....: )
   ....: 
Out[20]: 
   A  B  C
0  0  1  2
1  3  4  5
",https://pandas.pydata.org/docs/user_guide/duplicates.html, pandas.DataFrame
"In [21]: df = pd.DataFrame({""A"": [0, 1, 2, 3]}, index=[""x"", ""y"", ""X"", ""Y""]).set_flags(
   ....:     allows_duplicate_labels=False
   ....: )
   ....: 

In [22]: df
Out[22]: 
   A
x  0
y  1
X  2
Y  3

In [23]: df.flags.allows_duplicate_labels
Out[23]: False
",https://pandas.pydata.org/docs/user_guide/duplicates.html, pandas.DataFrame
"In [24]: df2 = df.set_flags(allows_duplicate_labels=True)

In [25]: df2.flags.allows_duplicate_labels
Out[25]: True
",https://pandas.pydata.org/docs/user_guide/duplicates.html, pandas.DataFrame.set_flags
">>> raw = pd.read_csv(""..."")
>>> deduplicated = raw.groupby(level=0).first()  # remove duplicates
>>> deduplicated.flags.allows_duplicate_labels = False  # disallow going forward
",https://pandas.pydata.org/docs/user_guide/duplicates.html, pandas.read_csv
"In [28]: df.rename(str.upper)
---------------------------------------------------------------------------
DuplicateLabelError                       Traceback (most recent call last)
Cell In[28], line 1
----> 1 df.rename(str.upper)

File ~/work/pandas/pandas/pandas/core/frame.py:5767, in DataFrame.rename(self, mapper, index, columns, axis, copy, inplace, level, errors)
   5636 def rename(
   5637     self,
   5638     mapper: Renamer | None = None,
   (...)
   5646     errors: IgnoreRaise = ""ignore"",
   5647 ) -> DataFrame | None:
   5648     """"""
   5649     Rename columns or index labels.
   5650 
   (...)
   5765     4  3  6
   5766     """"""
-> 5767     return super()._rename(
   5768         mapper=mapper,
   5769         index=index,
   5770         columns=columns,
   5771         axis=axis,
   5772         copy=copy,
   5773         inplace=inplace,
   5774         level=level,
   5775         errors=errors,
   5776     )

File ~/work/pandas/pandas/pandas/core/generic.py:1140, in NDFrame._rename(self, mapper, index, columns, axis, copy, inplace, level, errors)
   1138     return None
   1139 else:
-> 1140     return result.__finalize__(self, method=""rename"")

File ~/work/pandas/pandas/pandas/core/generic.py:6262, in NDFrame.__finalize__(self, other, method, **kwargs)
   6255 if other.attrs:
   6256     # We want attrs propagation to have minimal performance
   6257     # impact if attrs are not used; i.e. attrs is an empty dict.
   6258     # One could make the deepcopy unconditionally, but a deepcopy
   6259     # of an empty dict is 50x more expensive than the empty check.
   6260     self.attrs = deepcopy(other.attrs)
-> 6262 self.flags.allows_duplicate_labels = other.flags.allows_duplicate_labels
   6263 # For subclasses using _metadata.
   6264 for name in set(self._metadata) & set(other._metadata):

File ~/work/pandas/pandas/pandas/core/flags.py:96, in Flags.allows_duplicate_labels(self, value)
     94 if not value:
     95     for ax in obj.axes:
---> 96         ax._maybe_check_unique()
     98 self._allows_duplicate_labels = value

File ~/work/pandas/pandas/pandas/core/indexes/base.py:715, in Index._maybe_check_unique(self)
    712 duplicates = self._format_duplicate_message()
    713 msg += f""\n{duplicates}""
--> 715 raise DuplicateLabelError(msg)

DuplicateLabelError: Index has duplicates.
      positions
label          
X        [0, 2]
Y        [1, 3]
",https://pandas.pydata.org/docs/user_guide/duplicates.html, pandas.DataFrame.rename pandas.DataFrame.rename pandas.errors.DuplicateLabelError
"In [29]: s1 = pd.Series(0, index=[""a"", ""b""]).set_flags(allows_duplicate_labels=False)

In [30]: s1
Out[30]: 
a    0
b    0
dtype: int64

In [31]: s1.head().rename({""a"": ""b""})
---------------------------------------------------------------------------
DuplicateLabelError                       Traceback (most recent call last)
Cell In[31], line 1
----> 1 s1.head().rename({""a"": ""b""})

File ~/work/pandas/pandas/pandas/core/series.py:5090, in Series.rename(self, index, axis, copy, inplace, level, errors)
   5083     axis = self._get_axis_number(axis)
   5085 if callable(index) or is_dict_like(index):
   5086     # error: Argument 1 to ""_rename"" of ""NDFrame"" has incompatible
   5087     # type ""Union[Union[Mapping[Any, Hashable], Callable[[Any],
   5088     # Hashable]], Hashable, None]""; expected ""Union[Mapping[Any,
   5089     # Hashable], Callable[[Any], Hashable], None]""
-> 5090     return super()._rename(
   5091         index,  # type: ignore[arg-type]
   5092         copy=copy,
   5093         inplace=inplace,
   5094         level=level,
   5095         errors=errors,
   5096     )
   5097 else:
   5098     return self._set_name(index, inplace=inplace, deep=copy)

File ~/work/pandas/pandas/pandas/core/generic.py:1140, in NDFrame._rename(self, mapper, index, columns, axis, copy, inplace, level, errors)
   1138     return None
   1139 else:
-> 1140     return result.__finalize__(self, method=""rename"")

File ~/work/pandas/pandas/pandas/core/generic.py:6262, in NDFrame.__finalize__(self, other, method, **kwargs)
   6255 if other.attrs:
   6256     # We want attrs propagation to have minimal performance
   6257     # impact if attrs are not used; i.e. attrs is an empty dict.
   6258     # One could make the deepcopy unconditionally, but a deepcopy
   6259     # of an empty dict is 50x more expensive than the empty check.
   6260     self.attrs = deepcopy(other.attrs)
-> 6262 self.flags.allows_duplicate_labels = other.flags.allows_duplicate_labels
   6263 # For subclasses using _metadata.
   6264 for name in set(self._metadata) & set(other._metadata):

File ~/work/pandas/pandas/pandas/core/flags.py:96, in Flags.allows_duplicate_labels(self, value)
     94 if not value:
     95     for ax in obj.axes:
---> 96         ax._maybe_check_unique()
     98 self._allows_duplicate_labels = value

File ~/work/pandas/pandas/pandas/core/indexes/base.py:715, in Index._maybe_check_unique(self)
    712 duplicates = self._format_duplicate_message()
    713 msg += f""\n{duplicates}""
--> 715 raise DuplicateLabelError(msg)

DuplicateLabelError: Index has duplicates.
      positions
label          
b        [0, 1]
",https://pandas.pydata.org/docs/user_guide/duplicates.html, pandas.Series pandas.Series.head pandas.Series.rename pandas.api.types.is_dict_like pandas.errors.DuplicateLabelError
"import pandas as pd
import numpy as np
import matplotlib as mpl

df = pd.DataFrame({
    ""strings"": [""Adam"", ""Mike""],
    ""ints"": [1, 3],
    ""floats"": [1.123, 1000.23]
})
df.style \
  .format(precision=3, thousands=""."", decimal="","") \
  .format_index(str.upper, axis=1) \
  .relabel_index([""row 1"", ""row 2""], axis=0)
",https://pandas.pydata.org/docs/user_guide/style.html, pandas.DataFrame pandas.io.formats.style.Styler.format pandas.io.formats.style.Styler.format_index pandas.io.formats.style.Styler.relabel_index
"weather_df = pd.DataFrame(np.random.rand(10,2)*5,
                          index=pd.date_range(start=""2021-01-01"", periods=10),
                          columns=[""Tokyo"", ""Beijing""])

def rain_condition(v):
    if v < 1.75:
        return ""Dry""
    elif v < 2.75:
        return ""Rain""
    return ""Heavy Rain""

def make_pretty(styler):
    styler.set_caption(""Weather Conditions"")
    styler.format(rain_condition)
    styler.format_index(lambda v: v.strftime(""%A""))
    styler.background_gradient(axis=None, vmin=1, vmax=5, cmap=""YlGnBu"")
    return styler

weather_df
",https://pandas.pydata.org/docs/user_guide/style.html, pandas.DataFrame pandas.date_range pandas.io.formats.style.Styler.set_caption pandas.io.formats.style.Styler.format pandas.io.formats.style.Styler.format_index pandas.io.formats.style.Styler.background_gradient
"df = pd.DataFrame(np.random.randn(5, 5))
df.style \
  .hide(subset=[0, 2, 4], axis=0) \
  .hide(subset=[0, 2, 4], axis=1)
",https://pandas.pydata.org/docs/user_guide/style.html, pandas.DataFrame pandas.io.formats.style.Styler.hide
"show = [0, 2, 4]
df.style \
  .hide([row for row in df.index if row not in show], axis=0) \
  .hide([col for col in df.columns if col not in show], axis=1)
",https://pandas.pydata.org/docs/user_guide/style.html, pandas.io.formats.style.Styler.hide
"summary_styler = df.agg([""sum"", ""mean""]).style \
                   .format(precision=3) \
                   .relabel_index([""Sum"", ""Average""])
df.style.format(precision=1).concat(summary_styler)
",https://pandas.pydata.org/docs/user_guide/style.html, pandas.DataFrame.agg pandas.io.formats.style.Styler.format pandas.io.formats.style.Styler.relabel_index
"df = pd.DataFrame([[38.0, 2.0, 18.0, 22.0, 21, np.nan],[19, 439, 6, 452, 226,232]],
                  index=pd.Index(['Tumour (Positive)', 'Non-Tumour (Negative)'], name='Actual Label:'),
                  columns=pd.MultiIndex.from_product([['Decision Tree', 'Regression', 'Random'],['Tumour', 'Non-Tumour']], names=['Model:', 'Predicted:']))
df.style
",https://pandas.pydata.org/docs/user_guide/style.html, pandas.DataFrame pandas.Index pandas.MultiIndex.from_product
"s = df.style.format('{:.0f}').hide([('Random', 'Tumour'), ('Random', 'Non-Tumour')], axis=""columns"")
s
",https://pandas.pydata.org/docs/user_guide/style.html, pandas.io.formats.style.Styler.hide
"out = s.set_table_attributes('class=""my-table-cls""').to_html()
print(out[out.find('):][:109])
",https://pandas.pydata.org/docs/user_guide/style.html, pandas.Series.str.find
"s.set_table_styles([  # create internal CSS classes
    {'selector': '.true', 'props': 'background-color: #e6ffe6;'},
    {'selector': '.false', 'props': 'background-color: #ffe6e6;'},
], overwrite=False)
cell_color = pd.DataFrame([['true ', 'false ', 'true ', 'false '],
                           ['false ', 'true ', 'false ', 'true ']],
                          index=df.index,
                          columns=df.columns[:4])
s.set_td_classes(cell_color)
",https://pandas.pydata.org/docs/user_guide/style.html, pandas.DataFrame
"np.random.seed(0)
df2 = pd.DataFrame(np.random.randn(10,4), columns=['A','B','C','D'])
df2.style
",https://pandas.pydata.org/docs/user_guide/style.html, pandas.DataFrame
"def highlight_max(s, props=''):
    return np.where(s == np.nanmax(s.values), props, '')
s2.apply(highlight_max, props='color:white;background-color:darkblue', axis=0)
",https://pandas.pydata.org/docs/user_guide/style.html, pandas.io.formats.style.Styler.highlight_max pandas.Series.apply
"s2.apply(highlight_max, props='color:white;background-color:pink;', axis=1)\
  .apply(highlight_max, props='color:white;background-color:purple', axis=None)
",https://pandas.pydata.org/docs/user_guide/style.html, pandas.Series.apply
"s2.map_index(lambda v: ""color:pink;"" if v>4 else ""color:darkblue;"", axis=0)
s2.apply_index(lambda s: np.where(s.isin([""A"", ""B""]), ""color:pink;"", ""color:darkblue;""), axis=1)
",https://pandas.pydata.org/docs/user_guide/style.html, pandas.Series.isin
"s.set_caption(""Confusion matrix for multiple cancer prediction models."")\
 .set_table_styles([{
     'selector': 'caption',
     'props': 'caption-side: bottom; font-size:1.25em;'
 }], overwrite=False)
",https://pandas.pydata.org/docs/user_guide/style.html, pandas.io.formats.style.Styler.set_table_styles
"tt = pd.DataFrame([['This model has a very strong true positive rate',
                    ""This model's total number of false negatives is too high""]],
                  index=['Tumour (Positive)'], columns=df.columns[[0,3]])
s.set_tooltips(tt, props='visibility: hidden; position: absolute; z-index: 1; border: 1px solid #000066;'
                         'background-color: white; color: #000066; font-size: 0.8em;'
                         'transform: translate(0px, -24px); padding: 0.6em; border-radius: 0.5em;')
",https://pandas.pydata.org/docs/user_guide/style.html, pandas.DataFrame pandas.Series.str.translate
"s.set_table_styles([  # create internal CSS classes
    {'selector': '.border-red', 'props': 'border: 2px dashed red;'},
    {'selector': '.border-green', 'props': 'border: 2px dashed green;'},
], overwrite=False)
cell_border = pd.DataFrame([['border-green ', ' ', ' ', 'border-red '],
                           [' ', ' ', ' ', ' ']],
                          index=df.index,
                          columns=df.columns[:4])
s.set_td_classes(cell_color + cell_border)
",https://pandas.pydata.org/docs/user_guide/style.html, pandas.DataFrame
"df3 = pd.DataFrame(np.random.randn(4,4),
                   pd.MultiIndex.from_product([['A', 'B'], ['r1', 'r2']]),
                   columns=['c1','c2','c3','c4'])
df3
",https://pandas.pydata.org/docs/user_guide/style.html, pandas.DataFrame pandas.MultiIndex.from_product
"slice_ = ['c3', 'c4']
df3.style.apply(highlight_max, props='color:red;', axis=0, subset=slice_)\
         .set_properties(**{'background-color': '#ffffb3'}, subset=slice_)
",https://pandas.pydata.org/docs/user_guide/style.html, pandas.io.formats.style.Styler.set_properties
"idx = pd.IndexSlice
slice_ = idx[idx[:,'r1'], idx['c2':'c4']]
df3.style.apply(highlight_max, props='color:red;', axis=0, subset=slice_)\
         .set_properties(**{'background-color': '#ffffb3'}, subset=slice_)
",https://pandas.pydata.org/docs/user_guide/style.html, pandas.io.formats.style.Styler.set_properties
"slice_ = idx[idx[:,'r2'], :]
df3.style.apply(highlight_max, props='color:red;', axis=1, subset=slice_)\
         .set_properties(**{'background-color': '#ffffb3'}, subset=slice_)
",https://pandas.pydata.org/docs/user_guide/style.html, pandas.io.formats.style.Styler.set_properties
"slice_ = idx[idx[(df3['c1'] + df3['c3']) < -2.0], ['c2', 'c4']]
df3.style.apply(highlight_max, props='color:red;', axis=1, subset=slice_)\
         .set_properties(**{'background-color': '#ffffb3'}, subset=slice_)
",https://pandas.pydata.org/docs/user_guide/style.html, pandas.io.formats.style.Styler.set_properties
"df4 = pd.DataFrame([[1,2],[3,4]])
s4 = df4.style
",https://pandas.pydata.org/docs/user_guide/style.html, pandas.DataFrame
"from pandas.io.formats.style import Styler
s4 = Styler(df4, uuid_len=0, cell_ids=False)
",https://pandas.pydata.org/docs/user_guide/style.html, pandas.io.formats.style.Styler
"build = lambda x: pd.DataFrame(x, index=df2.index, columns=df2.columns)
cls1 = build(df2.apply(highlight_max, props='cls-1 ', axis=0))
cls2 = build(df2.apply(highlight_max, props='cls-2 ', axis=1, result_type='expand').values)
cls3 = build(highlight_max(df2, props='cls-3 '))
df2.style.set_table_styles([
    {'selector': '.cls-1', 'props': 'color:white;background-color:darkblue;'},
    {'selector': '.cls-2', 'props': 'color:white;background-color:pink;'},
    {'selector': '.cls-3', 'props': 'color:white;background-color:purple;'}
]).set_td_classes(cls1 + cls2 + cls3)
",https://pandas.pydata.org/docs/user_guide/style.html, pandas.DataFrame pandas.DataFrame.apply pandas.io.formats.style.Styler.highlight_max pandas.io.formats.style.Styler.set_td_classes
"my_css = {
    ""row_heading"": """",
    ""col_heading"": """",
    ""index_name"": """",
    ""col"": ""c"",
    ""row"": ""r"",
    ""col_trim"": """",
    ""row_trim"": """",
    ""level"": ""l"",
    ""data"": """",
    ""blank"": """",
}
html = Styler(df4, uuid_len=0, cell_ids=False)
html.set_table_styles([{'selector': 'td', 'props': props},
                       {'selector': '.c1', 'props': 'color:green;'},
                       {'selector': '.l0', 'props': 'color:blue;'}],
                      css_class_names=my_css)
print(html.to_html())
",https://pandas.pydata.org/docs/user_guide/style.html, pandas.io.formats.style.Styler
"df2.iloc[0,2] = np.nan
df2.iloc[4,3] = np.nan
df2.loc[:4].style.highlight_null(color='yellow')
",https://pandas.pydata.org/docs/user_guide/style.html, pandas.io.formats.style.Styler.highlight_null
"df2.loc[:4].style.highlight_max(axis=1, props='color:white; font-weight:bold; background-color:darkblue;')
",https://pandas.pydata.org/docs/user_guide/style.html, pandas.io.formats.style.Styler.highlight_max
"left = pd.Series([1.0, 0.0, 1.0], index=[""A"", ""B"", ""D""])
df2.loc[:4].style.highlight_between(left=left, right=1.5, axis=1, props='color:white; background-color:purple;')
",https://pandas.pydata.org/docs/user_guide/style.html, pandas.Series pandas.io.formats.style.Styler.highlight_between
"df2.loc[:4].style.highlight_quantile(q_left=0.85, axis=None, color='yellow')
",https://pandas.pydata.org/docs/user_guide/style.html, pandas.io.formats.style.Styler.highlight_quantile
"df2.loc[:4].style.set_properties(**{'background-color': 'black',
                           'color': 'lawngreen',
                           'border-color': 'white'})
",https://pandas.pydata.org/docs/user_guide/style.html, pandas.io.formats.style.Styler.set_properties
"df2.style.format('{:.3f}', na_rep="""")\
         .bar(align=0, vmin=-2.5, vmax=2.5, cmap=""bwr"", height=50,
              width=60, props=""width: 120px; border-right: 1px solid black;"")\
         .text_gradient(cmap=""bwr"", vmin=-2.5, vmax=2.5)
",https://pandas.pydata.org/docs/user_guide/style.html, pandas.io.formats.style.Styler.text_gradient
"style1 = df2.style\
            .map(style_negative, props='color:red;')\
            .map(lambda v: 'opacity: 20%;' if (v < 0.3) and (v > -0.3) else None)\
            .set_table_styles([{""selector"": ""th"", ""props"": ""color: blue;""}])\
            .hide(axis=""index"")
style1
",https://pandas.pydata.org/docs/user_guide/style.html, pandas.io.formats.style.Styler.set_table_styles pandas.io.formats.style.Styler.hide
"style2 = df3.style
style2.use(style1.export())
style2
",https://pandas.pydata.org/docs/user_guide/style.html, pandas.io.formats.style.Styler.use pandas.io.formats.style.Styler.export
"np.random.seed(25)
cmap = cmap=sns.diverging_palette(5, 250, as_cmap=True)
bigdf = pd.DataFrame(np.random.randn(20, 25)).cumsum()

bigdf.style.background_gradient(cmap, axis=1)\
    .set_properties(**{'max-width': '80px', 'font-size': '1pt'})\
    .set_caption(""Hover to magnify"")\
    .format(precision=2)\
    .set_table_styles(magnify())
",https://pandas.pydata.org/docs/user_guide/style.html, pandas.DataFrame pandas.io.formats.style.Styler.set_properties pandas.io.formats.style.Styler.set_caption pandas.io.formats.style.Styler.format pandas.io.formats.style.Styler.set_table_styles
"bigdf = pd.DataFrame(np.random.randn(16, 100))
bigdf.style.set_sticky(axis=""index"")
",https://pandas.pydata.org/docs/user_guide/style.html, pandas.DataFrame
"bigdf.index = pd.MultiIndex.from_product([[""A"",""B""],[0,1],[0,1,2,3]])
bigdf.style.set_sticky(axis=""index"", pixel_size=18, levels=[1,2])
",https://pandas.pydata.org/docs/user_guide/style.html, pandas.MultiIndex.from_product
"df4 = pd.DataFrame([['', '""&other""', '']])
df4.style
",https://pandas.pydata.org/docs/user_guide/style.html, pandas.DataFrame
"df2.style.\
    map(style_negative, props='color:red;').\
    highlight_max(axis=0).\
    to_excel('styled.xlsx', engine='openpyxl')
",https://pandas.pydata.org/docs/user_guide/style.html, pandas.io.formats.style.Styler.highlight_max
"print(pd.DataFrame([[1,2],[3,4]], index=['i1', 'i2'], columns=['c1', 'c2']).style.to_html())
",https://pandas.pydata.org/docs/user_guide/style.html, pandas.DataFrame
"df4 = pd.DataFrame([['text']])
df4.style.map(lambda x: 'color:green;')\
         .map(lambda x: 'color:red;')
",https://pandas.pydata.org/docs/user_guide/style.html, pandas.DataFrame
"df4.style.set_uuid('a_')\
         .set_table_styles([{'selector': 'td', 'props': 'color:red;'}])\
         .map(lambda x: 'color:green;')
",https://pandas.pydata.org/docs/user_guide/style.html, pandas.io.formats.style.Styler.set_table_styles
"df4.style.set_uuid('b_')\
         .set_table_styles([{'selector': 'td', 'props': 'color:red;'},
                            {'selector': '.cls-1', 'props': 'color:blue;'}])\
         .map(lambda x: 'color:green;')\
         .set_td_classes(pd.DataFrame([['cls-1']]))
",https://pandas.pydata.org/docs/user_guide/style.html, pandas.io.formats.style.Styler.set_table_styles pandas.io.formats.style.Styler.set_td_classes pandas.DataFrame
"df4.style.set_uuid('c_')\
         .set_table_styles([{'selector': 'td', 'props': 'color:red;'},
                            {'selector': '.cls-1', 'props': 'color:blue;'},
                            {'selector': 'td.data', 'props': 'color:yellow;'}])\
         .map(lambda x: 'color:green;')\
         .set_td_classes(pd.DataFrame([['cls-1']]))
",https://pandas.pydata.org/docs/user_guide/style.html, pandas.io.formats.style.Styler.set_table_styles pandas.io.formats.style.Styler.set_td_classes pandas.DataFrame
"df4.style.set_uuid('d_')\
         .set_table_styles([{'selector': 'td', 'props': 'color:red;'},
                            {'selector': '.cls-1', 'props': 'color:blue;'},
                            {'selector': 'td.data', 'props': 'color:yellow;'}])\
         .map(lambda x: 'color:green !important;')\
         .set_td_classes(pd.DataFrame([['cls-1']]))
",https://pandas.pydata.org/docs/user_guide/style.html, pandas.io.formats.style.Styler.set_table_styles pandas.io.formats.style.Styler.set_td_classes pandas.DataFrame
"EasyStyler = Styler.from_custom_template(""templates"", ""myhtml.tpl"")
HTML(EasyStyler(df3).to_html(table_title=""Another Title""))
",https://pandas.pydata.org/docs/user_guide/style.html, pandas.io.formats.style.Styler.from_custom_template
">>> lst = ['a', 'a', 'b']
>>> ser = pd.Series([1, 2, np.nan], index=lst)
>>> ser
a    1.0
a    2.0
b    NaN
dtype: float64
>>> ser.groupby(level=0).count()
a    2
b    0
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.count.html, pandas.Series pandas.Series.groupby
">>> data = [[1, np.nan, 3], [1, np.nan, 6], [7, 8, 9]]
>>> df = pd.DataFrame(data, columns=[""a"", ""b"", ""c""],
...                   index=[""cow"", ""horse"", ""bull""])
>>> df
        a         b     c
cow     1       NaN     3
horse   1       NaN     6
bull    7       8.0     9
>>> df.groupby(""a"").count()
    b   c
a
1   0   2
7   1   1
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.count.html, pandas.DataFrame pandas.DataFrame.groupby
">>> ser = pd.Series([1, 2, 3, 4], index=pd.DatetimeIndex(
...                 ['2023-01-01', '2023-01-15', '2023-02-01', '2023-02-15']))
>>> ser
2023-01-01    1
2023-01-15    2
2023-02-01    3
2023-02-15    4
dtype: int64
>>> ser.resample('MS').count()
2023-01-01    2
2023-02-01    2
Freq: MS, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.count.html, pandas.Series pandas.DatetimeIndex pandas.Series.resample
">>> ser = pd.Series([1, 3, 2, 4, 3, 8],
...                 index=pd.DatetimeIndex(['2023-01-01',
...                                         '2023-01-10',
...                                         '2023-01-15',
...                                         '2023-02-01',
...                                         '2023-02-10',
...                                         '2023-02-15']))
>>> ser.resample('MS').quantile()
2023-01-01    2.0
2023-02-01    4.0
Freq: MS, dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.quantile.html, pandas.Series pandas.DatetimeIndex pandas.Series.resample
">>> ser.resample('MS').quantile(.25)
2023-01-01    1.5
2023-02-01    3.5
Freq: MS, dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.quantile.html, pandas.Series.resample
">>> lst = ['a', 'a', 'b']
>>> ser = pd.Series([1, 2, 3], index=lst)
>>> ser
a     1
a     2
b     3
dtype: int64
>>> ser.groupby(level=0).size()
a    2
b    1
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.size.html, pandas.Series pandas.Series.groupby
">>> data = [[1, 2, 3], [1, 5, 6], [7, 8, 9]]
>>> df = pd.DataFrame(data, columns=[""a"", ""b"", ""c""],
...                   index=[""owl"", ""toucan"", ""eagle""])
>>> df
        a  b  c
owl     1  2  3
toucan  1  5  6
eagle   7  8  9
>>> df.groupby(""a"").size()
a
1    2
7    1
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.size.html, pandas.DataFrame pandas.DataFrame.groupby
">>> ser = pd.Series([1, 2, 3], index=pd.DatetimeIndex(
...                 ['2023-01-01', '2023-01-15', '2023-02-01']))
>>> ser
2023-01-01    1
2023-01-15    2
2023-02-01    3
dtype: int64
>>> ser.resample('MS').size()
2023-01-01    2
2023-02-01    1
Freq: MS, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.size.html, pandas.Series pandas.DatetimeIndex pandas.Series.resample
">>> s = pd.Series([1, 2, 3],
...               index=pd.date_range('20180101', periods=3, freq='h'))
>>> s
2018-01-01 00:00:00    1
2018-01-01 01:00:00    2
2018-01-01 02:00:00    3
Freq: h, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.fillna.html, pandas.Series pandas.date_range
">>> s.resample(""30min"").asfreq()
2018-01-01 00:00:00    1.0
2018-01-01 00:30:00    NaN
2018-01-01 01:00:00    2.0
2018-01-01 01:30:00    NaN
2018-01-01 02:00:00    3.0
Freq: 30min, dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.fillna.html, pandas.Series.resample
">>> s.resample('30min').fillna(""backfill"")
2018-01-01 00:00:00    1
2018-01-01 00:30:00    2
2018-01-01 01:00:00    2
2018-01-01 01:30:00    3
2018-01-01 02:00:00    3
Freq: 30min, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.fillna.html, pandas.Series.resample
">>> s.resample('15min').fillna(""backfill"", limit=2)
2018-01-01 00:00:00    1.0
2018-01-01 00:15:00    NaN
2018-01-01 00:30:00    2.0
2018-01-01 00:45:00    2.0
2018-01-01 01:00:00    2.0
2018-01-01 01:15:00    NaN
2018-01-01 01:30:00    3.0
2018-01-01 01:45:00    3.0
2018-01-01 02:00:00    3.0
Freq: 15min, dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.fillna.html, pandas.Series.resample
">>> s.resample('30min').fillna(""pad"")
2018-01-01 00:00:00    1
2018-01-01 00:30:00    1
2018-01-01 01:00:00    2
2018-01-01 01:30:00    2
2018-01-01 02:00:00    3
Freq: 30min, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.fillna.html, pandas.Series.resample
">>> s.resample('30min').fillna(""nearest"")
2018-01-01 00:00:00    1
2018-01-01 00:30:00    2
2018-01-01 01:00:00    2
2018-01-01 01:30:00    3
2018-01-01 02:00:00    3
Freq: 30min, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.fillna.html, pandas.Series.resample
">>> sm = pd.Series([1, None, 3],
...                index=pd.date_range('20180101', periods=3, freq='h'))
>>> sm
2018-01-01 00:00:00    1.0
2018-01-01 01:00:00    NaN
2018-01-01 02:00:00    3.0
Freq: h, dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.fillna.html, pandas.Series pandas.date_range
">>> sm.resample('30min').fillna('backfill')
2018-01-01 00:00:00    1.0
2018-01-01 00:30:00    NaN
2018-01-01 01:00:00    NaN
2018-01-01 01:30:00    3.0
2018-01-01 02:00:00    3.0
Freq: 30min, dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.fillna.html, pandas.Series.resample
">>> sm.resample('30min').fillna('pad')
2018-01-01 00:00:00    1.0
2018-01-01 00:30:00    1.0
2018-01-01 01:00:00    NaN
2018-01-01 01:30:00    NaN
2018-01-01 02:00:00    3.0
Freq: 30min, dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.fillna.html, pandas.Series.resample
">>> sm.resample('30min').fillna('nearest')
2018-01-01 00:00:00    1.0
2018-01-01 00:30:00    NaN
2018-01-01 01:00:00    NaN
2018-01-01 01:30:00    3.0
2018-01-01 02:00:00    3.0
Freq: 30min, dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.fillna.html, pandas.Series.resample
">>> df = pd.DataFrame({'a': [2, np.nan, 6], 'b': [1, 3, 5]},
...                   index=pd.date_range('20180101', periods=3,
...                                       freq='h'))
>>> df
                       a  b
2018-01-01 00:00:00  2.0  1
2018-01-01 01:00:00  NaN  3
2018-01-01 02:00:00  6.0  5
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.fillna.html, pandas.DataFrame pandas.date_range
">>> df.resample('30min').fillna(""bfill"")
                       a  b
2018-01-01 00:00:00  2.0  1
2018-01-01 00:30:00  NaN  3
2018-01-01 01:00:00  NaN  3
2018-01-01 01:30:00  6.0  5
2018-01-01 02:00:00  6.0  5
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.fillna.html, pandas.DataFrame.resample
">>> ser = pd.Series([1, 2, 3, 4], index=pd.DatetimeIndex(
...                 ['2023-01-01', '2023-01-15', '2023-02-01', '2023-02-15']))
>>> ser
2023-01-01    1
2023-01-15    2
2023-02-01    3
2023-02-15    4
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.ffill.html, pandas.Series pandas.DatetimeIndex
">>> ser.resample('MS').ffill()
2023-01-01    1
2023-02-01    3
Freq: MS, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.ffill.html, pandas.Series.resample
">>> ser.resample('W').ffill()
2023-01-01    1
2023-01-08    1
2023-01-15    2
2023-01-22    2
2023-01-29    2
2023-02-05    3
2023-02-12    3
2023-02-19    4
Freq: W-SUN, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.ffill.html, pandas.Series.resample
">>> ser.resample('W').ffill(limit=1)
2023-01-01    1.0
2023-01-08    1.0
2023-01-15    2.0
2023-01-22    2.0
2023-01-29    NaN
2023-02-05    3.0
2023-02-12    NaN
2023-02-19    4.0
Freq: W-SUN, dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.ffill.html, pandas.Series.resample
">>> lst = ['a', 'a', 'b', 'b']
>>> ser = pd.Series([5, 10, 8, 14], index=lst)
>>> ser
a     5
a    10
b     8
b    14
dtype: int64
>>> ser.groupby(level=0).sem()
a    2.5
b    3.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.sem.html, pandas.Series pandas.Series.groupby
">>> data = [[1, 12, 11], [1, 15, 2], [2, 5, 8], [2, 6, 12]]
>>> df = pd.DataFrame(data, columns=[""a"", ""b"", ""c""],
...                   index=[""tuna"", ""salmon"", ""catfish"", ""goldfish""])
>>> df
           a   b   c
    tuna   1  12  11
  salmon   1  15   2
 catfish   2   5   8
goldfish   2   6  12
>>> df.groupby(""a"").sem()
      b  c
a
1    1.5  4.5
2    0.5  2.0
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.sem.html, pandas.DataFrame pandas.DataFrame.groupby
">>> ser = pd.Series([1, 3, 2, 4, 3, 8],
...                 index=pd.DatetimeIndex(['2023-01-01',
...                                         '2023-01-10',
...                                         '2023-01-15',
...                                         '2023-02-01',
...                                         '2023-02-10',
...                                         '2023-02-15']))
>>> ser.resample('MS').sem()
2023-01-01    0.577350
2023-02-01    1.527525
Freq: MS, dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.sem.html, pandas.Series pandas.DatetimeIndex pandas.Series.resample
">>> ser = pd.Series([1, 2, 3, 4], index=pd.DatetimeIndex(
...                 ['2023-01-01', '2023-01-15', '2023-02-01', '2023-02-15']))
>>> ser
2023-01-01    1
2023-01-15    2
2023-02-01    3
2023-02-15    4
dtype: int64
>>> ser.resample('MS').min()
2023-01-01    1
2023-02-01    3
Freq: MS, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.min.html, pandas.Series pandas.DatetimeIndex pandas.Series.resample
">>> lst = ['a', 'a', 'b']
>>> ser = pd.Series([1, 2, 3], index=lst)
>>> ser
a    1
a    2
b    3
dtype: int64
>>> ser.groupby(level=0).get_group(""a"")
a    1
a    2
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.get_group.html, pandas.Series pandas.Series.groupby
">>> data = [[1, 2, 3], [1, 5, 6], [7, 8, 9]]
>>> df = pd.DataFrame(data, columns=[""a"", ""b"", ""c""],
...                   index=[""owl"", ""toucan"", ""eagle""])
>>> df
        a  b  c
owl     1  2  3
toucan  1  5  6
eagle   7  8  9
>>> df.groupby(by=[""a""]).get_group((1,))
        a  b  c
owl     1  2  3
toucan  1  5  6
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.get_group.html, pandas.DataFrame pandas.DataFrame.groupby
">>> ser = pd.Series([1, 2, 3, 4], index=pd.DatetimeIndex(
...                 ['2023-01-01', '2023-01-15', '2023-02-01', '2023-02-15']))
>>> ser
2023-01-01    1
2023-01-15    2
2023-02-01    3
2023-02-15    4
dtype: int64
>>> ser.resample('MS').get_group('2023-01-01')
2023-01-01    1
2023-01-15    2
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.get_group.html, pandas.Series pandas.DatetimeIndex pandas.Series.resample
">>> ser = pd.Series([1, 2, 3, 4], index=pd.DatetimeIndex(
...                 ['2023-01-01', '2023-01-15', '2023-02-01', '2023-02-15']))
>>> ser
2023-01-01    1
2023-01-15    2
2023-02-01    3
2023-02-15    4
dtype: int64
>>> ser.resample('MS').mean()
2023-01-01    1.5
2023-02-01    3.5
Freq: MS, dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.mean.html, pandas.Series pandas.DatetimeIndex pandas.Series.resample
">>> s = pd.Series([1, 2],
...               index=pd.date_range('20180101',
...                                   periods=2,
...                                   freq='1h'))
>>> s
2018-01-01 00:00:00    1
2018-01-01 01:00:00    2
Freq: h, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.transform.html, pandas.Series pandas.date_range
">>> resampled = s.resample('15min')
>>> resampled.transform(lambda x: (x - x.mean()) / x.std())
2018-01-01 00:00:00   NaN
2018-01-01 01:00:00   NaN
Freq: h, dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.transform.html, pandas.Series.resample pandas.Series.mean pandas.Series.std
">>> ser = pd.Series([1, 2, 3, 4], index=pd.DatetimeIndex(
...                 ['2023-01-01', '2023-01-15', '2023-02-01', '2023-02-15']))
>>> ser
2023-01-01    1
2023-01-15    2
2023-02-01    3
2023-02-15    4
dtype: int64
>>> ser.resample('MS').max()
2023-01-01    2
2023-02-01    4
Freq: MS, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.max.html, pandas.Series pandas.DatetimeIndex pandas.Series.resample
">>> lst = ['a', 'a', 'b']
>>> ser = pd.Series([1, 2, 3], index=lst)
>>> ser
a    1
a    2
b    3
dtype: int64
>>> ser.groupby(level=0).groups
{'a': ['a', 'a'], 'b': ['b']}
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.groups.html, pandas.Series pandas.Series.groupby
">>> data = [[1, 2, 3], [1, 5, 6], [7, 8, 9]]
>>> df = pd.DataFrame(data, columns=[""a"", ""b"", ""c""])
>>> df
   a  b  c
0  1  2  3
1  1  5  6
2  7  8  9
>>> df.groupby(by=[""a""]).groups
{1: [0, 1], 7: [2]}
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.groups.html, pandas.DataFrame pandas.DataFrame.groupby
">>> ser = pd.Series([1, 2, 3, 4], index=pd.DatetimeIndex(
...                 ['2023-01-01', '2023-01-15', '2023-02-01', '2023-02-15']))
>>> ser
2023-01-01    1
2023-01-15    2
2023-02-01    3
2023-02-15    4
dtype: int64
>>> ser.resample('MS').groups
{Timestamp('2023-01-01 00:00:00'): 2, Timestamp('2023-02-01 00:00:00'): 4}
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.groups.html, pandas.Series pandas.DatetimeIndex pandas.Series.resample
">>> s = pd.Series([1, 2],
...               index=pd.date_range('20180101',
...                                   periods=2,
...                                   freq='1h'))
>>> s
2018-01-01 00:00:00    1
2018-01-01 01:00:00    2
Freq: h, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.nearest.html, pandas.Series pandas.date_range
">>> s.resample('15min').nearest()
2018-01-01 00:00:00    1
2018-01-01 00:15:00    1
2018-01-01 00:30:00    2
2018-01-01 00:45:00    2
2018-01-01 01:00:00    2
Freq: 15min, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.nearest.html, pandas.Series.resample
">>> s.resample('15min').nearest(limit=1)
2018-01-01 00:00:00    1.0
2018-01-01 00:15:00    1.0
2018-01-01 00:30:00    NaN
2018-01-01 00:45:00    2.0
2018-01-01 01:00:00    2.0
Freq: 15min, dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.nearest.html, pandas.Series.resample
">>> h = lambda x, arg2, arg3: x + 1 - arg2 * arg3
>>> g = lambda x, arg1: x * 5 / arg1
>>> f = lambda x: x ** 4
>>> df = pd.DataFrame([[""a"", 4], [""b"", 5]], columns=[""group"", ""value""])
>>> h(g(f(df.groupby('group')), arg1=1), arg2=2, arg3=3)  
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.pipe.html, pandas.DataFrame pandas.DataFrame.groupby
">>> (df.groupby('group')
...    .pipe(f)
...    .pipe(g, arg1=1)
...    .pipe(h, arg2=2, arg3=3))  
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.pipe.html, pandas.DataFrame.groupby
">>> df = pd.DataFrame({'A': [1, 2, 3, 4]},
...                   index=pd.date_range('2012-08-02', periods=4))
>>> df
            A
2012-08-02  1
2012-08-03  2
2012-08-04  3
2012-08-05  4
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.pipe.html, pandas.DataFrame pandas.date_range
">>> df.resample('2D').pipe(lambda x: x.max() - x.min())
            A
2012-08-02  1
2012-08-04  1
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.pipe.html, pandas.DataFrame.resample pandas.Series.max pandas.Series.min
">>> start = ""2023-03-01T07:00:00""
>>> timesteps = pd.date_range(start, periods=5, freq=""s"")
>>> series = pd.Series(data=[1, -1, 2, 1, 3], index=timesteps)
>>> series
2023-03-01 07:00:00    1
2023-03-01 07:00:01   -1
2023-03-01 07:00:02    2
2023-03-01 07:00:03    1
2023-03-01 07:00:04    3
Freq: s, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.interpolate.html, pandas.date_range pandas.Series
">>> series.resample(""2s"").interpolate(""linear"")
2023-03-01 07:00:00    1
2023-03-01 07:00:02    2
2023-03-01 07:00:04    3
Freq: 2s, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.interpolate.html, pandas.Series.resample
">>> series.resample(""500ms"").interpolate(""linear"")
2023-03-01 07:00:00.000    1.0
2023-03-01 07:00:00.500    0.0
2023-03-01 07:00:01.000   -1.0
2023-03-01 07:00:01.500    0.5
2023-03-01 07:00:02.000    2.0
2023-03-01 07:00:02.500    1.5
2023-03-01 07:00:03.000    1.0
2023-03-01 07:00:03.500    2.0
2023-03-01 07:00:04.000    3.0
Freq: 500ms, dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.interpolate.html, pandas.Series.resample
">>> series.resample(""400ms"").interpolate(""linear"")
2023-03-01 07:00:00.000    1.0
2023-03-01 07:00:00.400    1.2
2023-03-01 07:00:00.800    1.4
2023-03-01 07:00:01.200    1.6
2023-03-01 07:00:01.600    1.8
2023-03-01 07:00:02.000    2.0
2023-03-01 07:00:02.400    2.2
2023-03-01 07:00:02.800    2.4
2023-03-01 07:00:03.200    2.6
2023-03-01 07:00:03.600    2.8
2023-03-01 07:00:04.000    3.0
Freq: 400ms, dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.interpolate.html, pandas.Series.resample
">>> lst = ['a', 'a', 'a', 'b', 'b', 'b']
>>> ser = pd.Series([7, 2, 8, 4, 3, 3], index=lst)
>>> ser
a     7
a     2
a     8
b     4
b     3
b     3
dtype: int64
>>> ser.groupby(level=0).median()
a    7.0
b    3.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.median.html, pandas.Series pandas.Series.groupby
">>> data = {'a': [1, 3, 5, 7, 7, 8, 3], 'b': [1, 4, 8, 4, 4, 2, 1]}
>>> df = pd.DataFrame(data, index=['dog', 'dog', 'dog',
...                   'mouse', 'mouse', 'mouse', 'mouse'])
>>> df
         a  b
  dog    1  1
  dog    3  4
  dog    5  8
mouse    7  4
mouse    7  4
mouse    8  2
mouse    3  1
>>> df.groupby(level=0).median()
         a    b
dog    3.0  4.0
mouse  7.0  3.0
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.median.html, pandas.DataFrame pandas.DataFrame.groupby
">>> ser = pd.Series([1, 2, 3, 3, 4, 5],
...                 index=pd.DatetimeIndex(['2023-01-01',
...                                         '2023-01-10',
...                                         '2023-01-15',
...                                         '2023-02-01',
...                                         '2023-02-10',
...                                         '2023-02-15']))
>>> ser.resample('MS').median()
2023-01-01    2.0
2023-02-01    4.0
Freq: MS, dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.median.html, pandas.Series pandas.DatetimeIndex pandas.Series.resample
">>> lst = ['a', 'a', 'b']
>>> ser = pd.Series([1, 2, 3], index=lst)
>>> ser
a    1
a    2
b    3
dtype: int64
>>> ser.groupby(level=0).indices
{'a': array([0, 1]), 'b': array([2])}
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.indices.html, pandas.Series pandas.Series.groupby pandas.array
">>> data = [[1, 2, 3], [1, 5, 6], [7, 8, 9]]
>>> df = pd.DataFrame(data, columns=[""a"", ""b"", ""c""],
...                   index=[""owl"", ""toucan"", ""eagle""])
>>> df
        a  b  c
owl     1  2  3
toucan  1  5  6
eagle   7  8  9
>>> df.groupby(by=[""a""]).indices
{1: array([0, 1]), 7: array([2])}
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.indices.html, pandas.DataFrame pandas.DataFrame.groupby pandas.array
">>> ser = pd.Series([1, 2, 3, 4], index=pd.DatetimeIndex(
...                 ['2023-01-01', '2023-01-15', '2023-02-01', '2023-02-15']))
>>> ser
2023-01-01    1
2023-01-15    2
2023-02-01    3
2023-02-15    4
dtype: int64
>>> ser.resample('MS').indices
defaultdict(, {Timestamp('2023-01-01 00:00:00'): [0, 1],
Timestamp('2023-02-01 00:00:00'): [2, 3]})
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.indices.html, pandas.Series pandas.DatetimeIndex pandas.Series.resample
">>> ser = pd.Series([1, 2, 3, 4], index=pd.DatetimeIndex(
...                 ['2023-01-01', '2023-01-15', '2023-02-01', '2023-02-15']))
>>> ser
2023-01-01    1
2023-01-15    2
2023-02-01    3
2023-02-15    4
dtype: int64
>>> ser.resample('MS').sum()
2023-01-01    3
2023-02-01    7
Freq: MS, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.sum.html, pandas.Series pandas.DatetimeIndex pandas.Series.resample
">>> lst = ['a', 'a', 'b']
>>> ser = pd.Series([1, 2, 3], index=lst)
>>> ser
a    1
a    2
b    3
dtype: int64
>>> for x, y in ser.groupby(level=0):
...     print(f'{x}\n{y}\n')
a
a    1
a    2
dtype: int64
b
b    3
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.__iter__.html, pandas.Series pandas.Series.groupby
">>> data = [[1, 2, 3], [1, 5, 6], [7, 8, 9]]
>>> df = pd.DataFrame(data, columns=[""a"", ""b"", ""c""])
>>> df
   a  b  c
0  1  2  3
1  1  5  6
2  7  8  9
>>> for x, y in df.groupby(by=[""a""]):
...     print(f'{x}\n{y}\n')
(1,)
   a  b  c
0  1  2  3
1  1  5  6
(7,)
   a  b  c
2  7  8  9
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.__iter__.html, pandas.DataFrame pandas.DataFrame.groupby
">>> ser = pd.Series([1, 2, 3, 4], index=pd.DatetimeIndex(
...                 ['2023-01-01', '2023-01-15', '2023-02-01', '2023-02-15']))
>>> ser
2023-01-01    1
2023-01-15    2
2023-02-01    3
2023-02-15    4
dtype: int64
>>> for x, y in ser.resample('MS'):
...     print(f'{x}\n{y}\n')
2023-01-01 00:00:00
2023-01-01    1
2023-01-15    2
dtype: int64
2023-02-01 00:00:00
2023-02-01    3
2023-02-15    4
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.__iter__.html, pandas.Series pandas.DatetimeIndex pandas.Series.resample
">>> df = pd.DataFrame([[1, 2, 3], [4, 5, 6]], columns=['A', 'B', 'C'])
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_clipboard.html, pandas.DataFrame
">>> df.to_clipboard(sep=',')  
... # Wrote the following to the system clipboard:
... # ,A,B,C
... # 0,1,2,3
... # 1,4,5,6
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_clipboard.html, pandas.DataFrame.to_clipboard
">>> df.to_clipboard(sep=',', index=False)  
... # Wrote the following to the system clipboard:
... # A,B,C
... # 1,2,3
... # 4,5,6
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_clipboard.html, pandas.DataFrame.to_clipboard
">>> s = pd.Series([1, 2, 3, 4, 5],
...               index=pd.date_range('20130101', periods=5, freq='s'))
>>> s
2013-01-01 00:00:00    1
2013-01-01 00:00:01    2
2013-01-01 00:00:02    3
2013-01-01 00:00:03    4
2013-01-01 00:00:04    5
Freq: s, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.apply.html, pandas.Series pandas.date_range
">>> r = s.resample('2s')
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.apply.html, pandas.Series.resample
">>> r.agg({'result': lambda x: x.mean() / x.std(),
...        'total': ""sum""})
                       result  total
2013-01-01 00:00:00  2.121320      3
2013-01-01 00:00:02  4.949747      7
2013-01-01 00:00:04       NaN      5
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.apply.html, pandas.Series.mean pandas.Series.std
">>> df = pd.DataFrame(dict(A=[1, 1, 3], B=[5, None, 6], C=[1, 2, 3]))
>>> df.groupby(""A"").last()
     B  C
A
1  5.0  2
3  6.0  3
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.last.html, pandas.DataFrame pandas.DataFrame.groupby
">>> df = pd.DataFrame([[1,2], [3,4]])
>>> s = df.style.highlight_max(axis=None,
...                            props='background-color:red; font-weight:bold;')
>>> s.to_html()  
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.to_latex.html, pandas.DataFrame
">>> s = df.style.highlight_max(axis=None,
...                            props='cellcolor:{red}; bfseries: ;')
>>> s.to_latex()  
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.to_latex.html, pandas.Series.to_latex
">>> df = pd.DataFrame([[1, 2.2, ""dogs""], [3, 4.4, ""cats""], [2, 6.6, ""cows""]],
...                   index=[""ix1"", ""ix2"", ""ix3""],
...                   columns=[""Integers"", ""Floats"", ""Strings""])
>>> s = df.style.highlight_max(
...     props='cellcolor:[HTML]{FFFF00}; color:{red};'
...           'textit:--rwrap; textbf:--rwrap;'
... )
>>> s.to_latex()  
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.to_latex.html, pandas.DataFrame pandas.Series.to_latex
"set_table_styles([
    {""selector"": ""column_format"", ""props"": f"":{column_format};""},
    {""selector"": ""position"", ""props"": f"":{position};""},
    {""selector"": ""position_float"", ""props"": f"":{position_float};""},
    {""selector"": ""label"", ""props"": f"":{{{label.replace(':','§')}}};""}
], overwrite=False)
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.to_latex.html, pandas.io.formats.style.Styler.set_table_styles
"set_table_styles([
    {'selector': 'toprule', 'props': ':toprule;'},
    {'selector': 'bottomrule', 'props': ':hline;'},
], overwrite=False)
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.to_latex.html, pandas.io.formats.style.Styler.set_table_styles
"set_table_styles([
    {'selector': 'rowcolors', 'props': ':{1}{pink}{red};'}
], overwrite=False)
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.to_latex.html, pandas.io.formats.style.Styler.set_table_styles
">>> df.columns = pd.MultiIndex.from_tuples([
...     (""Numeric"", ""Integers""),
...     (""Numeric"", ""Floats""),
...     (""Non-Numeric"", ""Strings"")
... ])
>>> df.index = pd.MultiIndex.from_tuples([
...     (""L0"", ""ix1""), (""L0"", ""ix2""), (""L1"", ""ix3"")
... ])
>>> s = df.style.highlight_max(
...     props='cellcolor:[HTML]{FFFF00}; color:{red}; itshape:; bfseries:;'
... )
>>> s.to_latex(
...     column_format=""rrrrr"", position=""h"", position_float=""centering"",
...     hrules=True, label=""table:5"", caption=""Styled LaTeX Table"",
...     multirow_align=""t"", multicol_align=""r""
... )  
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.to_latex.html, pandas.MultiIndex.from_tuples pandas.Series.to_latex
">>> s.to_latex()  
\begin{tabular}{llrrl}
{} & {} & \multicolumn{2}{r}{Numeric} & {Non-Numeric} \\
{} & {} & {Integers} & {Floats} & {Strings} \\
\multirow[c]{2}{*}{L0} & ix1 & \\$1 & 2.200 & DOGS \\
 & ix2 & \$3 & 4.400 & CATS \\
L1 & ix3 & \$2 & 6.600 & COWS \\
\end{tabular}
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.to_latex.html, pandas.Series.to_latex
">>> df = pd.DataFrame([[1]])
>>> df.style.set_properties(
...     **{""font-weight"": ""bold /* --dwrap */"", ""Huge"": ""--latex--rwrap""}
... ).to_latex(convert_css=True)  
\begin{tabular}{lr}
{} & {0} \\
0 & {\bfseries}{\Huge{1}} \\
\end{tabular}
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.to_latex.html, pandas.DataFrame
">>> cidx = pd.MultiIndex.from_arrays([
...     [""Equity"", ""Equity"", ""Equity"", ""Equity"",
...      ""Stats"", ""Stats"", ""Stats"", ""Stats"", ""Rating""],
...     [""Energy"", ""Energy"", ""Consumer"", ""Consumer"", """", """", """", """", """"],
...     [""BP"", ""Shell"", ""H&M"", ""Unilever"",
...      ""Std Dev"", ""Variance"", ""52w High"", ""52w Low"", """"]
... ])
>>> iidx = pd.MultiIndex.from_arrays([
...     [""Equity"", ""Equity"", ""Equity"", ""Equity""],
...     [""Energy"", ""Energy"", ""Consumer"", ""Consumer""],
...     [""BP"", ""Shell"", ""H&M"", ""Unilever""]
... ])
>>> styler = pd.DataFrame([
...     [1, 0.8, 0.66, 0.72, 32.1678, 32.1678**2, 335.12, 240.89, ""Buy""],
...     [0.8, 1.0, 0.69, 0.79, 1.876, 1.876**2, 14.12, 19.78, ""Hold""],
...     [0.66, 0.69, 1.0, 0.86, 7, 7**2, 210.9, 140.6, ""Buy""],
...     [0.72, 0.79, 0.86, 1.0, 213.76, 213.76**2, 2807, 3678, ""Sell""],
... ], columns=cidx, index=iidx).style
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.to_latex.html, pandas.MultiIndex.from_arrays pandas.DataFrame
">>> (styler.format(subset=""Equity"", precision=2)
...       .format(subset=""Stats"", precision=1, thousands="","")
...       .format(subset=""Rating"", formatter=str.upper)
...       .format_index(escape=""latex"", axis=1)
...       .format_index(escape=""latex"", axis=0)
...       .hide(level=0, axis=0))  
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.to_latex.html, pandas.io.formats.style.Styler.format pandas.io.formats.style.Styler.format_index pandas.io.formats.style.Styler.hide
">>> styler.to_latex(
...     caption=""Selected stock correlation and simple statistics."",
...     clines=""skip-last;data"",
...     convert_css=True,
...     position_float=""centering"",
...     multicol_align=""|c|"",
...     hrules=True,
... )  
\begin{table}
\centering
\caption{Selected stock correlation and simple statistics.}
\begin{tabular}{llrrrrrrrrl}
\toprule
 &  & \multicolumn{4}{|c|}{Equity} & \multicolumn{4}{|c|}{Stats} & Rating \\
 &  & \multicolumn{2}{|c|}{Energy} & \multicolumn{2}{|c|}{Consumer} &
\multicolumn{4}{|c|}{} &  \\
 &  & \rotatebox{45}{BP} & \rotatebox{45}{Shell} & \rotatebox{45}{H\&M} &
\rotatebox{45}{Unilever} & \rotatebox{45}{Std Dev} & \rotatebox{45}{Variance} &
\rotatebox{45}{52w High} & \rotatebox{45}{52w Low} & \rotatebox{45}{} \\
\midrule
\multirow[c]{2}{*}{Energy} & BP & {\cellcolor[HTML]{FCFFA4}}
\color[HTML]{000000} 1.00 & {\cellcolor[HTML]{FCA50A}} \color[HTML]{000000}
0.80 & {\cellcolor[HTML]{EB6628}} \color[HTML]{F1F1F1} 0.66 &
{\cellcolor[HTML]{F68013}} \color[HTML]{F1F1F1} 0.72 & 32.2 & 1,034.8 & 335.1
& 240.9 & \color[HTML]{33FF85} \bfseries BUY \\
 & Shell & {\cellcolor[HTML]{FCA50A}} \color[HTML]{000000} 0.80 &
{\cellcolor[HTML]{FCFFA4}} \color[HTML]{000000} 1.00 &
{\cellcolor[HTML]{F1731D}} \color[HTML]{F1F1F1} 0.69 &
{\cellcolor[HTML]{FCA108}} \color[HTML]{000000} 0.79 & 1.9 & 3.5 & 14.1 &
19.8 & \color[HTML]{FFDD33} \bfseries HOLD \\
\cline{1-11}
\multirow[c]{2}{*}{Consumer} & H\&M & {\cellcolor[HTML]{EB6628}}
\color[HTML]{F1F1F1} 0.66 & {\cellcolor[HTML]{F1731D}} \color[HTML]{F1F1F1}
0.69 & {\cellcolor[HTML]{FCFFA4}} \color[HTML]{000000} 1.00 &
{\cellcolor[HTML]{FAC42A}} \color[HTML]{000000} 0.86 & 7.0 & 49.0 & 210.9 &
140.6 & \color[HTML]{33FF85} \bfseries BUY \\
 & Unilever & {\cellcolor[HTML]{F68013}} \color[HTML]{F1F1F1} 0.72 &
{\cellcolor[HTML]{FCA108}} \color[HTML]{000000} 0.79 &
{\cellcolor[HTML]{FAC42A}} \color[HTML]{000000} 0.86 &
{\cellcolor[HTML]{FCFFA4}} \color[HTML]{000000} 1.00 & 213.8 & 45,693.3 &
2,807.0 & 3,678.0 & \color[HTML]{FF5933} \bfseries SELL \\
\cline{1-11}
\bottomrule
\end{tabular}
\end{table}
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.to_latex.html, pandas.DataFrame.to_latex
">>> s = pd.Series([1, 2, 3],
...               index=pd.date_range('20180101', periods=3, freq='h'))
>>> s
2018-01-01 00:00:00    1
2018-01-01 01:00:00    2
2018-01-01 02:00:00    3
Freq: h, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.bfill.html, pandas.Series pandas.date_range
">>> s.resample('30min').bfill()
2018-01-01 00:00:00    1
2018-01-01 00:30:00    2
2018-01-01 01:00:00    2
2018-01-01 01:30:00    3
2018-01-01 02:00:00    3
Freq: 30min, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.bfill.html, pandas.Series.resample
">>> s.resample('15min').bfill(limit=2)
2018-01-01 00:00:00    1.0
2018-01-01 00:15:00    NaN
2018-01-01 00:30:00    2.0
2018-01-01 00:45:00    2.0
2018-01-01 01:00:00    2.0
2018-01-01 01:15:00    NaN
2018-01-01 01:30:00    3.0
2018-01-01 01:45:00    3.0
2018-01-01 02:00:00    3.0
Freq: 15min, dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.bfill.html, pandas.Series.resample
">>> df = pd.DataFrame({'a': [2, np.nan, 6], 'b': [1, 3, 5]},
...                   index=pd.date_range('20180101', periods=3,
...                                       freq='h'))
>>> df
                       a  b
2018-01-01 00:00:00  2.0  1
2018-01-01 01:00:00  NaN  3
2018-01-01 02:00:00  6.0  5
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.bfill.html, pandas.DataFrame pandas.date_range
">>> df.resample('30min').bfill()
                       a  b
2018-01-01 00:00:00  2.0  1
2018-01-01 00:30:00  NaN  3
2018-01-01 01:00:00  NaN  3
2018-01-01 01:30:00  6.0  5
2018-01-01 02:00:00  6.0  5
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.bfill.html, pandas.DataFrame.resample
">>> df.resample('15min').bfill(limit=2)
                       a    b
2018-01-01 00:00:00  2.0  1.0
2018-01-01 00:15:00  NaN  NaN
2018-01-01 00:30:00  NaN  3.0
2018-01-01 00:45:00  NaN  3.0
2018-01-01 01:00:00  NaN  3.0
2018-01-01 01:15:00  NaN  NaN
2018-01-01 01:30:00  6.0  5.0
2018-01-01 01:45:00  6.0  5.0
2018-01-01 02:00:00  6.0  5.0
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.bfill.html, pandas.DataFrame.resample
">>> lst = ['SPX', 'CAC', 'SPX', 'CAC', 'SPX', 'CAC', 'SPX', 'CAC',]
>>> ser = pd.Series([3.4, 9.0, 7.2, 5.2, 8.8, 9.4, 0.1, 0.5], index=lst)
>>> ser
SPX     3.4
CAC     9.0
SPX     7.2
CAC     5.2
SPX     8.8
CAC     9.4
SPX     0.1
CAC     0.5
dtype: float64
>>> ser.groupby(level=0).ohlc()
     open  high  low  close
CAC   9.0   9.4  0.5    0.5
SPX   3.4   8.8  0.1    0.1
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.ohlc.html, pandas.Series pandas.Series.groupby
">>> data = {2022: [1.2, 2.3, 8.9, 4.5, 4.4, 3, 2 , 1],
...         2023: [3.4, 9.0, 7.2, 5.2, 8.8, 9.4, 8.2, 1.0]}
>>> df = pd.DataFrame(data, index=['SPX', 'CAC', 'SPX', 'CAC',
...                   'SPX', 'CAC', 'SPX', 'CAC'])
>>> df
     2022  2023
SPX   1.2   3.4
CAC   2.3   9.0
SPX   8.9   7.2
CAC   4.5   5.2
SPX   4.4   8.8
CAC   3.0   9.4
SPX   2.0   8.2
CAC   1.0   1.0
>>> df.groupby(level=0).ohlc()
    2022                 2023
    open high  low close open high  low close
CAC  2.3  4.5  1.0   1.0  9.0  9.4  1.0   1.0
SPX  1.2  8.9  1.2   2.0  3.4  8.8  3.4   8.2
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.ohlc.html, pandas.DataFrame pandas.DataFrame.groupby
">>> ser = pd.Series([1, 3, 2, 4, 3, 5],
...                 index=pd.DatetimeIndex(['2023-01-01',
...                                         '2023-01-10',
...                                         '2023-01-15',
...                                         '2023-02-01',
...                                         '2023-02-10',
...                                         '2023-02-15']))
>>> ser.resample('MS').ohlc()
            open  high  low  close
2023-01-01     1     3    1      2
2023-02-01     4     5    3      5
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.ohlc.html, pandas.Series pandas.DatetimeIndex pandas.Series.resample
">>> lst = ['a', 'a', 'b', 'b']
>>> ser = pd.Series([1, 2, 3, 3], index=lst)
>>> ser
a    1
a    2
b    3
b    3
dtype: int64
>>> ser.groupby(level=0).nunique()
a    2
b    1
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.nunique.html, pandas.Series pandas.Series.groupby
">>> ser = pd.Series([1, 2, 3, 3], index=pd.DatetimeIndex(
...                 ['2023-01-01', '2023-01-15', '2023-02-01', '2023-02-15']))
>>> ser
2023-01-01    1
2023-01-15    2
2023-02-01    3
2023-02-15    3
dtype: int64
>>> ser.resample('MS').nunique()
2023-01-01    2
2023-02-01    1
Freq: MS, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.nunique.html, pandas.Series pandas.DatetimeIndex pandas.Series.resample
">>> ser = pd.Series([1, 3, 2, 4, 3, 8],
...                 index=pd.DatetimeIndex(['2023-01-01',
...                                         '2023-01-10',
...                                         '2023-01-15',
...                                         '2023-02-01',
...                                         '2023-02-10',
...                                         '2023-02-15']))
>>> ser.resample('MS').var()
2023-01-01    1.0
2023-02-01    7.0
Freq: MS, dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.var.html, pandas.Series pandas.DatetimeIndex pandas.Series.resample
">>> ser.resample('MS').var(ddof=0)
2023-01-01    0.666667
2023-02-01    4.666667
Freq: MS, dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.var.html, pandas.Series.resample
">>> df1 = pd.DataFrame([[1, 2], [3, 4]], columns=['A', 'B'])
>>> store = pd.HDFStore(""store.h5"", 'w')  
>>> store.put('data', df1, format='table')  
>>> df2 = pd.DataFrame([[5, 6], [7, 8]], columns=['A', 'B'])
>>> store.append('data', df2)  
>>> store.close()  
>>> for group in store.walk():  
...     print(group)  
>>> store.close()  
",https://pandas.pydata.org/docs/reference/api/pandas.HDFStore.walk.html, pandas.DataFrame pandas.HDFStore.put pandas.HDFStore.walk
">>> df = pd.read_xml(StringIO(xml))
>>> df
      shape  degrees  sides
0    square      360    4.0
1    circle      360    NaN
2  triangle      180    3.0
",https://pandas.pydata.org/docs/reference/api/pandas.read_xml.html, pandas.read_xml
">>> df = pd.read_xml(StringIO(xml), xpath="".//row"")
>>> df
      shape  degrees  sides
0    square      360    4.0
1    circle      360    NaN
2  triangle      180    3.0
",https://pandas.pydata.org/docs/reference/api/pandas.read_xml.html, pandas.read_xml
">>> df = pd.read_xml(StringIO(xml),
...                  xpath=""//doc:row"",
...                  namespaces={""doc"": ""https://example.com""})
>>> df
      shape  degrees  sides
0    square      360    4.0
1    circle      360    NaN
2  triangle      180    3.0
",https://pandas.pydata.org/docs/reference/api/pandas.read_xml.html, pandas.read_xml
">>> df = pd.read_xml(StringIO(xml_data),
...                  dtype_backend=""numpy_nullable"",
...                  parse_dates=[""e""])
>>> df
   index     a    b      c  d          e
0      0     1  2.5   True  a 2019-12-31
1      1    4.5  False  b 2019-12-31
",https://pandas.pydata.org/docs/reference/api/pandas.read_xml.html, pandas.read_xml
">>> s = pd.Series([1, 2, 3, 4, 5],
...               index=pd.date_range('20130101', periods=5, freq='s'))
>>> s
2013-01-01 00:00:00    1
2013-01-01 00:00:01    2
2013-01-01 00:00:02    3
2013-01-01 00:00:03    4
2013-01-01 00:00:04    5
Freq: s, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.aggregate.html, pandas.Series pandas.date_range
">>> r = s.resample('2s')
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.aggregate.html, pandas.Series.resample
">>> r.agg({'result': lambda x: x.mean() / x.std(),
...        'total': ""sum""})
                       result  total
2013-01-01 00:00:00  2.121320      3
2013-01-01 00:00:02  4.949747      7
2013-01-01 00:00:04       NaN      5
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.aggregate.html, pandas.Series.mean pandas.Series.std
">>> ser = pd.Series([1, 2, 3, 4], index=pd.DatetimeIndex(
...                 ['2023-01-01', '2023-01-31', '2023-02-01', '2023-02-28']))
>>> ser
2023-01-01    1
2023-01-31    2
2023-02-01    3
2023-02-28    4
dtype: int64
>>> ser.resample('MS').asfreq()
2023-01-01    1
2023-02-01    3
Freq: MS, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.asfreq.html, pandas.Series pandas.DatetimeIndex pandas.Series.resample
">>> ser = pd.Series([1, 2, 3, 3])
>>> plot = ser.plot(kind='hist', title=""My plot"")
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.plot.html, pandas.Series pandas.Series.plot
">>> df = pd.DataFrame({'length': [1.5, 0.5, 1.2, 0.9, 3],
...                   'width': [0.7, 0.2, 0.15, 0.2, 1.1]},
...                   index=['pig', 'rabbit', 'duck', 'chicken', 'horse'])
>>> plot = df.plot(title=""DataFrame Plot"")
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.plot.html, pandas.DataFrame pandas.DataFrame.plot
">>> lst = [-1, -2, -3, 1, 2, 3]
>>> ser = pd.Series([1, 2, 2, 4, 6, 6], index=lst)
>>> plot = ser.groupby(lambda x: x > 0).plot(title=""SeriesGroupBy Plot"")
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.plot.html, pandas.Series pandas.Series.groupby
">>> df = pd.DataFrame({""col1"" : [1, 2, 3, 4],
...                   ""col2"" : [""A"", ""B"", ""A"", ""B""]})
>>> plot = df.groupby(""col2"").plot(kind=""bar"", title=""DataFrameGroupBy Plot"")
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.plot.html, pandas.DataFrame pandas.DataFrame.groupby
">>> df = pd.DataFrame({""fully_labelled"": [1, 2, 3, 3, 1],
...                    ""partially_labelled"": [1.0, 2.0, np.nan, 9.0, np.nan],
...                    ""Y"": [7, 7, 9, 8, 10],
...                    ""Z"": pd.Categorical([""j"", ""k"", ""l"", ""k"", ""j""]),
...                    })
>>> path = ""/My_path/filename.dta""
>>> labels = {""fully_labelled"": {1: ""one"", 2: ""two"", 3: ""three""},
...           ""partially_labelled"": {1.0: ""one"", 2.0: ""two""},
...           }
>>> writer = pd.io.stata.StataWriter(path,
...                                  df,
...                                  value_labels=labels)  
>>> writer.write_file()  
>>> df = pd.read_stata(path)  
>>> df  
    index fully_labelled  partially_labeled  Y  Z
0       0            one                one  7  j
1       1            two                two  7  k
2       2          three                NaN  9  l
3       3          three                9.0  8  k
4       4            one                NaN 10  j
",https://pandas.pydata.org/docs/reference/api/pandas.io.stata.StataWriter.write_file.html, pandas.DataFrame pandas.Categorical pandas.read_stata
">>> df = pd.DataFrame({'name' : ['User 1', 'User 2', 'User 3']})
>>> df
     name
0  User 1
1  User 2
2  User 3
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_sql.html, pandas.DataFrame
">>> df.to_sql(name='users', con=engine)
3
>>> from sqlalchemy import text
>>> with engine.connect() as conn:
...    conn.execute(text(""SELECT * FROM users"")).fetchall()
[(0, 'User 1'), (1, 'User 2'), (2, 'User 3')]
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_sql.html, pandas.DataFrame.to_sql
">>> with engine.begin() as connection:
...     df1 = pd.DataFrame({'name' : ['User 4', 'User 5']})
...     df1.to_sql(name='users', con=connection, if_exists='append')
2
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_sql.html, pandas.DataFrame pandas.DataFrame.to_sql
">>> df2 = pd.DataFrame({'name' : ['User 6', 'User 7']})
>>> df2.to_sql(name='users', con=engine, if_exists='append')
2
>>> with engine.connect() as conn:
...    conn.execute(text(""SELECT * FROM users"")).fetchall()
[(0, 'User 1'), (1, 'User 2'), (2, 'User 3'),
 (0, 'User 4'), (1, 'User 5'), (0, 'User 6'),
 (1, 'User 7')]
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_sql.html, pandas.DataFrame pandas.DataFrame.to_sql
">>> df2.to_sql(name='users', con=engine, if_exists='replace',
...            index_label='id')
2
>>> with engine.connect() as conn:
...    conn.execute(text(""SELECT * FROM users"")).fetchall()
[(0, 'User 6'), (1, 'User 7')]
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_sql.html, pandas.DataFrame.to_sql
">>> df = pd.DataFrame({""A"": [1, None, 2]})
>>> df
     A
0  1.0
1  NaN
2  2.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_sql.html, pandas.DataFrame
">>> from sqlalchemy.types import Integer
>>> df.to_sql(name='integers', con=engine, index=False,
...           dtype={""A"": Integer()})
3
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_sql.html, pandas.DataFrame.to_sql
">>> ser = pd.Series([1, 2, 3, 4], index=pd.DatetimeIndex(
...                 ['2023-01-01', '2023-01-15', '2023-02-01', '2023-02-15']))
>>> ser
2023-01-01    1
2023-01-15    2
2023-02-01    3
2023-02-15    4
dtype: int64
>>> ser.resample('MS').prod()
2023-01-01    2
2023-02-01   12
Freq: MS, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.prod.html, pandas.Series pandas.DatetimeIndex pandas.Series.resample
">>> from sqlalchemy import create_engine  
>>> engine = create_engine(""sqlite:///database.db"")  
>>> with engine.connect() as conn, conn.begin():  
...     data = pd.read_sql_table(""data"", conn)  
",https://pandas.pydata.org/docs/reference/api/pandas.read_sql_query.html, pandas.read_sql_table
">>> df = pd.DataFrame(dict(A=[1, 1, 3], B=[None, 5, 6], C=[1, 2, 3],
...                        D=['3/11/2000', '3/12/2000', '3/13/2000']))
>>> df['D'] = pd.to_datetime(df['D'])
>>> df.groupby(""A"").first()
     B  C          D
A
1  5.0  1 2000-03-11
3  6.0  3 2000-03-13
>>> df.groupby(""A"").first(min_count=2)
    B    C          D
A
1 NaN  1.0 2000-03-11
3 NaN  NaN        NaT
>>> df.groupby(""A"").first(numeric_only=True)
     B  C
A
1  5.0  1
3  6.0  3
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.first.html, pandas.DataFrame pandas.to_datetime pandas.DataFrame.groupby
">>> df1 = pd.DataFrame([['a', 'b'], ['c', 'd']],
...                    index=['row 1', 'row 2'],
...                    columns=['col 1', 'col 2'])
>>> df1.to_excel(""output.xlsx"")  
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_excel.html, pandas.DataFrame pandas.DataFrame.to_excel
">>> df1.to_excel(""output.xlsx"",
...              sheet_name='Sheet_name_1')  
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_excel.html, pandas.DataFrame.to_excel
">>> df2 = df1.copy()
>>> with pd.ExcelWriter('output.xlsx') as writer:  
...     df1.to_excel(writer, sheet_name='Sheet_name_1')
...     df2.to_excel(writer, sheet_name='Sheet_name_2')
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_excel.html, pandas.DataFrame.copy pandas.ExcelWriter pandas.DataFrame.to_excel pandas.DataFrame.to_excel
">>> with pd.ExcelWriter('output.xlsx',
...                     mode='a') as writer:  
...     df1.to_excel(writer, sheet_name='Sheet_name_3')
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_excel.html, pandas.ExcelWriter pandas.DataFrame.to_excel
">>> df1.to_excel('output1.xlsx', engine='xlsxwriter')  
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_excel.html, pandas.DataFrame.to_excel
">>> ser = pd.Series([1, 3, 2, 4, 3, 8],
...                 index=pd.DatetimeIndex(['2023-01-01',
...                                         '2023-01-10',
...                                         '2023-01-15',
...                                         '2023-02-01',
...                                         '2023-02-10',
...                                         '2023-02-15']))
>>> ser.resample('MS').std()
2023-01-01    1.000000
2023-02-01    2.645751
Freq: MS, dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.std.html, pandas.Series pandas.DatetimeIndex pandas.Series.resample
">>> df = pd.DataFrame([[""ABC"", ""XYZ""]], columns=[""Foo"", ""Bar""])  
>>> with pd.ExcelWriter(""path_to_file.xlsx"") as writer:
...     df.to_excel(writer)  
",https://pandas.pydata.org/docs/reference/api/pandas.ExcelWriter.html, pandas.DataFrame pandas.ExcelWriter pandas.DataFrame.to_excel
">>> df1 = pd.DataFrame([[""AAA"", ""BBB""]], columns=[""Spam"", ""Egg""])  
>>> df2 = pd.DataFrame([[""ABC"", ""XYZ""]], columns=[""Foo"", ""Bar""])  
>>> with pd.ExcelWriter(""path_to_file.xlsx"") as writer:
...     df1.to_excel(writer, sheet_name=""Sheet1"")  
...     df2.to_excel(writer, sheet_name=""Sheet2"")  
",https://pandas.pydata.org/docs/reference/api/pandas.ExcelWriter.html, pandas.DataFrame pandas.ExcelWriter pandas.DataFrame.to_excel pandas.DataFrame.to_excel
">>> from datetime import date, datetime  
>>> df = pd.DataFrame(
...     [
...         [date(2014, 1, 31), date(1999, 9, 24)],
...         [datetime(1998, 5, 26, 23, 33, 4), datetime(2014, 2, 28, 13, 5, 13)],
...     ],
...     index=[""Date"", ""Datetime""],
...     columns=[""X"", ""Y""],
... )  
>>> with pd.ExcelWriter(
...     ""path_to_file.xlsx"",
...     date_format=""YYYY-MM-DD"",
...     datetime_format=""YYYY-MM-DD HH:MM:SS""
... ) as writer:
...     df.to_excel(writer)  
",https://pandas.pydata.org/docs/reference/api/pandas.ExcelWriter.html, pandas.DataFrame pandas.Timestamp.date pandas.ExcelWriter pandas.DataFrame.to_excel
">>> with pd.ExcelWriter(""path_to_file.xlsx"", mode=""a"", engine=""openpyxl"") as writer:
...     df.to_excel(writer, sheet_name=""Sheet3"")  
",https://pandas.pydata.org/docs/reference/api/pandas.ExcelWriter.html, pandas.ExcelWriter pandas.DataFrame.to_excel
">>> with ExcelWriter(
...     ""path_to_file.xlsx"",
...     mode=""a"",
...     engine=""openpyxl"",
...     if_sheet_exists=""replace"",
... ) as writer:
...     df.to_excel(writer, sheet_name=""Sheet1"")  
",https://pandas.pydata.org/docs/reference/api/pandas.ExcelWriter.html, pandas.ExcelWriter pandas.DataFrame.to_excel
">>> with ExcelWriter(""path_to_file.xlsx"",
...     mode=""a"",
...     engine=""openpyxl"",
...     if_sheet_exists=""overlay"",
... ) as writer:
...     df1.to_excel(writer, sheet_name=""Sheet1"")
...     df2.to_excel(writer, sheet_name=""Sheet1"", startcol=3)  
",https://pandas.pydata.org/docs/reference/api/pandas.ExcelWriter.html, pandas.ExcelWriter pandas.DataFrame.to_excel pandas.DataFrame.to_excel
">>> import io
>>> df = pd.DataFrame([[""ABC"", ""XYZ""]], columns=[""Foo"", ""Bar""])
>>> buffer = io.BytesIO()
>>> with pd.ExcelWriter(buffer) as writer:
...     df.to_excel(writer)
",https://pandas.pydata.org/docs/reference/api/pandas.ExcelWriter.html, pandas.DataFrame pandas.ExcelWriter pandas.DataFrame.to_excel
">>> import zipfile  
>>> df = pd.DataFrame([[""ABC"", ""XYZ""]], columns=[""Foo"", ""Bar""])  
>>> with zipfile.ZipFile(""path_to_file.zip"", ""w"") as zf:
...     with zf.open(""filename.xlsx"", ""w"") as buffer:
...         with pd.ExcelWriter(buffer) as writer:
...             df.to_excel(writer)  
",https://pandas.pydata.org/docs/reference/api/pandas.ExcelWriter.html, pandas.DataFrame pandas.ExcelWriter pandas.DataFrame.to_excel
">>> with pd.ExcelWriter(
...     ""path_to_file.xlsx"",
...     engine=""xlsxwriter"",
...     engine_kwargs={""options"": {""nan_inf_to_errors"": True}}
... ) as writer:
...     df.to_excel(writer)  
",https://pandas.pydata.org/docs/reference/api/pandas.ExcelWriter.html, pandas.ExcelWriter pandas.DataFrame.to_excel
">>> with pd.ExcelWriter(
...     ""path_to_file.xlsx"",
...     engine=""openpyxl"",
...     mode=""a"",
...     engine_kwargs={""keep_vba"": True}
... ) as writer:
...     df.to_excel(writer, sheet_name=""Sheet2"")  
",https://pandas.pydata.org/docs/reference/api/pandas.ExcelWriter.html, pandas.ExcelWriter pandas.DataFrame.to_excel
">>> df = pd.DataFrame([[1, 1.0, 'a']], columns=['x', 'y', 'z'])  
>>> df.to_hdf('./store.h5', 'data')  
>>> reread = pd.read_hdf('./store.h5')  
",https://pandas.pydata.org/docs/reference/api/pandas.read_hdf.html, pandas.DataFrame pandas.DataFrame.to_hdf pandas.read_hdf
">>> df = pd.DataFrame([[1, 2], [3, 4]], columns=[""col_1"", ""col_2""])
>>> time_stamp = pd.Timestamp(2000, 2, 29, 14, 21)
>>> path = ""/My_path/filename.dta""
>>> value_labels = {""col_1"": {3: ""x""}}
>>> df.to_stata(path, time_stamp=time_stamp,  
...             value_labels=value_labels, version=None)  
>>> with pd.io.stata.StataReader(path) as reader:  
...     print(reader.value_labels())  
{'col_1': {3: 'x'}}
>>> pd.read_stata(path)  
    index col_1 col_2
0       0    1    2
1       1    x    4
",https://pandas.pydata.org/docs/reference/api/pandas.io.stata.StataReader.value_labels.html, pandas.DataFrame pandas.DataFrame.to_stata pandas.io.stata.StataReader.value_labels pandas.read_stata
">>> from pandas.io.json._table_schema import build_table_schema
>>> df = pd.DataFrame(
...     {'A': [1, 2, 3],
...      'B': ['a', 'b', 'c'],
...      'C': pd.date_range('2016-01-01', freq='d', periods=3),
...     }, index=pd.Index(range(3), name='idx'))
>>> build_table_schema(df)
{'fields': [{'name': 'idx', 'type': 'integer'}, {'name': 'A', 'type': 'integer'}, {'name': 'B', 'type': 'string'}, {'name': 'C', 'type': 'datetime'}], 'primaryKey': ['idx'], 'pandas_version': '1.4.0'}
",https://pandas.pydata.org/docs/reference/api/pandas.io.json.build_table_schema.html, pandas.DataFrame pandas.date_range pandas.Index pandas.io.json.build_table_schema
">>> df = pd.DataFrame([[1, 2], [3, 4]], columns=['A', 'B'])
>>> store = pd.HDFStore(""store.h5"", 'w')  
>>> store.put('data', df)  
>>> store.get('data')  
>>> print(store.keys())  
['/data1', '/data2']
>>> store.close()  
",https://pandas.pydata.org/docs/reference/api/pandas.HDFStore.keys.html, pandas.DataFrame pandas.HDFStore.put
">>> from sqlite3 import connect
>>> conn = connect(':memory:')
>>> df = pd.DataFrame(data=[[0, '10/11/12'], [1, '12/11/10']],
...                   columns=['int_column', 'date_column'])
>>> df.to_sql(name='test_data', con=conn)
2
",https://pandas.pydata.org/docs/reference/api/pandas.read_sql.html, pandas.DataFrame pandas.DataFrame.to_sql
">>> pd.read_sql('SELECT int_column, date_column FROM test_data', conn)
   int_column date_column
0           0    10/11/12
1           1    12/11/10
",https://pandas.pydata.org/docs/reference/api/pandas.read_sql.html, pandas.read_sql
">>> pd.read_sql('test_data', 'postgres:///db_name')  
",https://pandas.pydata.org/docs/reference/api/pandas.read_sql.html, pandas.read_sql
">>> pd.read_sql('SELECT int_column, date_column FROM test_data',
...             conn,
...             parse_dates={""date_column"": {""format"": ""%d/%m/%y""}})
   int_column date_column
0           0  2012-11-10
1           1  2010-11-12
",https://pandas.pydata.org/docs/reference/api/pandas.read_sql.html, pandas.read_sql
">>> from adbc_driver_postgresql import dbapi  
>>> with dbapi.connect('postgres:///db_name') as conn:  
...     pd.read_sql('SELECT int_column FROM test_data', conn)
   int_column
0           0
1           1
",https://pandas.pydata.org/docs/reference/api/pandas.read_sql.html, pandas.read_sql
">>> pd.read_excel('tmp.xlsx', index_col=0)  
       Name  Value
0   string1      1
1   string2      2
2  #Comment      3
",https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html, pandas.read_excel
">>> pd.read_excel(open('tmp.xlsx', 'rb'),
...               sheet_name='Sheet3')  
   Unnamed: 0      Name  Value
0           0   string1      1
1           1   string2      2
2           2  #Comment      3
",https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html, pandas.read_excel
">>> pd.read_excel('tmp.xlsx', index_col=None, header=None)  
     0         1      2
0  NaN      Name  Value
1  0.0   string1      1
2  1.0   string2      2
3  2.0  #Comment      3
",https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html, pandas.read_excel
">>> pd.read_excel('tmp.xlsx', index_col=0,
...               dtype={'Name': str, 'Value': float})  
       Name  Value
0   string1    1.0
1   string2    2.0
2  #Comment    3.0
",https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html, pandas.read_excel
">>> pd.read_excel('tmp.xlsx', index_col=0,
...               na_values=['string1', 'string2'])  
       Name  Value
0       NaN      1
1       NaN      2
2  #Comment      3
",https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html, pandas.read_excel
">>> pd.read_excel('tmp.xlsx', index_col=0, comment='#')  
      Name  Value
0  string1    1.0
1  string2    2.0
2     None    NaN
",https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html, pandas.read_excel
">>> df = pd.DataFrame(dict(name=['Raphael', 'Donatello'],
...                        age=[26, 45],
...                        height=[181.23, 177.65]))
>>> print(df.to_latex(index=False,
...                   formatters={""name"": str.upper},
...                   float_format=""{:.1f}"".format,
... ))  
\begin{tabular}{lrr}
\toprule
name & age & height \\
\midrule
RAPHAEL & 26 & 181.2 \\
DONATELLO & 45 & 177.7 \\
\bottomrule
\end{tabular}
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_latex.html, pandas.DataFrame pandas.DataFrame.to_latex
">>> df = pd.DataFrame([(1,)], columns=[""variable""])
>>> time_stamp = pd.Timestamp(2000, 2, 29, 14, 21)
>>> data_label = ""This is a data file.""
>>> path = ""/My_path/filename.dta""
>>> df.to_stata(path, time_stamp=time_stamp,    
...             data_label=data_label,  
...             version=None)  
>>> with pd.io.stata.StataReader(path) as reader:  
...     print(reader.data_label)  
This is a data file.
",https://pandas.pydata.org/docs/reference/api/pandas.io.stata.StataReader.data_label.html, pandas.DataFrame pandas.DataFrame.to_stata
">>> original_df = pd.DataFrame(
...     {""foo"": range(5), ""bar"": range(5, 10)}
...    )  
>>> original_df  
   foo  bar
0    0    5
1    1    6
2    2    7
3    3    8
4    4    9
>>> pd.to_pickle(original_df, ""./dummy.pkl"")  
",https://pandas.pydata.org/docs/reference/api/pandas.read_pickle.html, pandas.DataFrame
">>> unpickled_df = pd.read_pickle(""./dummy.pkl"")  
>>> unpickled_df  
   foo  bar
0    0    5
1    1    6
2    2    7
3    3    8
4    4    9
",https://pandas.pydata.org/docs/reference/api/pandas.read_pickle.html, pandas.read_pickle
">>> file = pd.ExcelFile('myfile.xlsx')  
>>> with pd.ExcelFile(""myfile.xls"") as xls:  
...     df1 = pd.read_excel(xls, ""Sheet1"")  
",https://pandas.pydata.org/docs/reference/api/pandas.ExcelFile.html, pandas.ExcelFile pandas.read_excel
">>> df = pd.DataFrame({'animal': ['falcon', 'parrot', 'falcon', 'parrot'],
...                     'speed': [350, 18, 361, 15]})  
>>> df.to_stata('animals.dta')  
",https://pandas.pydata.org/docs/reference/api/pandas.read_stata.html, pandas.DataFrame pandas.DataFrame.to_stata
">>> df = pd.read_stata('animals.dta')  
",https://pandas.pydata.org/docs/reference/api/pandas.read_stata.html, pandas.read_stata
">>> values = np.random.randint(0, 10, size=(20_000, 1), dtype=""uint8"")  
>>> df = pd.DataFrame(values, columns=[""i""])  
>>> df.to_stata('filename.dta')  
",https://pandas.pydata.org/docs/reference/api/pandas.read_stata.html, pandas.DataFrame pandas.DataFrame.to_stata
">>> with pd.read_stata('filename.dta', chunksize=10000) as itr: 
>>>     for chunk in itr:
...         # Operate on a single chunk, e.g., chunk.mean()
...         pass  
",https://pandas.pydata.org/docs/reference/api/pandas.read_stata.html, pandas.read_stata
">>> df = pd.read_spss(""spss_data.sav"")  
",https://pandas.pydata.org/docs/reference/api/pandas.read_spss.html, pandas.read_spss
">>> df = pd.DataFrame([[1, 2], [3, 4]], columns=[""col_1"", ""col_2""])
>>> time_stamp = pd.Timestamp(2000, 2, 29, 14, 21)
>>> path = ""/My_path/filename.dta""
>>> variable_labels = {""col_1"": ""This is an example""}
>>> df.to_stata(path, time_stamp=time_stamp,  
...             variable_labels=variable_labels, version=None)  
>>> with pd.io.stata.StataReader(path) as reader:  
...     print(reader.variable_labels())  
{'index': '', 'col_1': 'This is an example', 'col_2': ''}
>>> pd.read_stata(path)  
    index col_1 col_2
0       0    1    2
1       1    3    4
",https://pandas.pydata.org/docs/reference/api/pandas.io.stata.StataReader.variable_labels.html, pandas.DataFrame pandas.DataFrame.to_stata pandas.io.stata.StataReader.variable_labels pandas.read_stata
">>> pd.read_csv('data.csv')  
",https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html, pandas.read_csv
">>> from json import loads, dumps
>>> df = pd.DataFrame(
...     [[""a"", ""b""], [""c"", ""d""]],
...     index=[""row 1"", ""row 2""],
...     columns=[""col 1"", ""col 2""],
... )
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_json.html, pandas.DataFrame
">>> result = df.to_json(orient=""split"")
>>> parsed = loads(result)
>>> dumps(parsed, indent=4)  
{
    ""columns"": [
        ""col 1"",
        ""col 2""
    ],
    ""index"": [
        ""row 1"",
        ""row 2""
    ],
    ""data"": [
        [
            ""a"",
            ""b""
        ],
        [
            ""c"",
            ""d""
        ]
    ]
}
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_json.html, pandas.DataFrame.to_json
">>> result = df.to_json(orient=""records"")
>>> parsed = loads(result)
>>> dumps(parsed, indent=4)  
[
    {
        ""col 1"": ""a"",
        ""col 2"": ""b""
    },
    {
        ""col 1"": ""c"",
        ""col 2"": ""d""
    }
]
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_json.html, pandas.DataFrame.to_json
">>> result = df.to_json(orient=""index"")
>>> parsed = loads(result)
>>> dumps(parsed, indent=4)  
{
    ""row 1"": {
        ""col 1"": ""a"",
        ""col 2"": ""b""
    },
    ""row 2"": {
        ""col 1"": ""c"",
        ""col 2"": ""d""
    }
}
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_json.html, pandas.DataFrame.to_json
">>> result = df.to_json(orient=""columns"")
>>> parsed = loads(result)
>>> dumps(parsed, indent=4)  
{
    ""col 1"": {
        ""row 1"": ""a"",
        ""row 2"": ""c""
    },
    ""col 2"": {
        ""row 1"": ""b"",
        ""row 2"": ""d""
    }
}
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_json.html, pandas.DataFrame.to_json
">>> result = df.to_json(orient=""values"")
>>> parsed = loads(result)
>>> dumps(parsed, indent=4)  
[
    [
        ""a"",
        ""b""
    ],
    [
        ""c"",
        ""d""
    ]
]
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_json.html, pandas.DataFrame.to_json
">>> result = df.to_json(orient=""table"")
>>> parsed = loads(result)
>>> dumps(parsed, indent=4)  
{
    ""schema"": {
        ""fields"": [
            {
                ""name"": ""index"",
                ""type"": ""string""
            },
            {
                ""name"": ""col 1"",
                ""type"": ""string""
            },
            {
                ""name"": ""col 2"",
                ""type"": ""string""
            }
        ],
        ""primaryKey"": [
            ""index""
        ],
        ""pandas_version"": ""1.4.0""
    },
    ""data"": [
        {
            ""index"": ""row 1"",
            ""col 1"": ""a"",
            ""col 2"": ""b""
        },
        {
            ""index"": ""row 2"",
            ""col 1"": ""c"",
            ""col 2"": ""d""
        }
    ]
}
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_json.html, pandas.DataFrame.to_json
">>> original_df = pd.DataFrame(
...     {""foo"": range(5), ""bar"": range(5, 10)}
...    )
>>> original_df
   foo  bar
0    0    5
1    1    6
2    2    7
3    3    8
4    4    9
>>> df_parquet_bytes = original_df.to_parquet()
>>> from io import BytesIO
>>> restored_df = pd.read_parquet(BytesIO(df_parquet_bytes))
>>> restored_df
   foo  bar
0    0    5
1    1    6
2    2    7
3    3    8
4    4    9
>>> restored_df.equals(original_df)
True
>>> restored_bar = pd.read_parquet(BytesIO(df_parquet_bytes), columns=[""bar""])
>>> restored_bar
    bar
0    5
1    6
2    7
3    8
4    9
>>> restored_bar.equals(original_df[['bar']])
True
",https://pandas.pydata.org/docs/reference/api/pandas.read_parquet.html, pandas.DataFrame pandas.DataFrame.to_parquet pandas.read_parquet
">>> sel = [(""foo"", "">"", 2)]
>>> restored_part = pd.read_parquet(BytesIO(df_parquet_bytes), filters=sel)
>>> restored_part
    foo  bar
0    3    8
1    4    9
",https://pandas.pydata.org/docs/reference/api/pandas.read_parquet.html, pandas.read_parquet
">>> df = pd.DataFrame({'shape': ['square', 'circle', 'triangle'],
...                    'degrees': [360, 360, 180],
...                    'sides': [4, np.nan, 3]})
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_xml.html, pandas.DataFrame
">>> df.to_xml()  


  
    0
    square
    360
    4.0
  
  
    1
    circle
    360
    
  
  
    2
    triangle
    180
    3.0
  

",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_xml.html, pandas.DataFrame.to_xml
">>> df.to_xml(attr_cols=[
...           'index', 'shape', 'degrees', 'sides'
...           ])  


  
  
  

",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_xml.html, pandas.DataFrame.to_xml
">>> df.to_xml(namespaces={""doc"": ""https://example.com""},
...           prefix=""doc"")  


  
    0
    square
    360
    4.0
  
  
    1
    circle
    360
    
  
  
    2
    triangle
    180
    3.0
  

",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_xml.html, pandas.DataFrame.to_xml
">>> df = pd.DataFrame(data={'col1': [1, 2], 'col2': [4, 3]})
>>> df.to_orc('df.orc')  
>>> pd.read_orc('df.orc')  
   col1  col2
0     1     4
1     2     3
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_orc.html, pandas.DataFrame pandas.DataFrame.to_orc pandas.read_orc
">>> import io
>>> b = io.BytesIO(df.to_orc())  
>>> b.seek(0)  
0
>>> content = b.read()  
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_orc.html, pandas.DataFrame.to_orc
">>> df = pd.DataFrame([[1, 2], [3, 4]], columns=['A', 'B'])
>>> store = pd.HDFStore(""store.h5"", 'w')  
>>> store.put('data', df)  
>>> store.get('data')  
>>> print(store.keys())  
['/data1', '/data2']
>>> store.select('/data1')  
   A  B
0  1  2
1  3  4
>>> store.select('/data1', where='columns == A')  
   A
0  1
1  3
>>> store.close()  
",https://pandas.pydata.org/docs/reference/api/pandas.HDFStore.select.html, pandas.DataFrame pandas.HDFStore.put pandas.HDFStore.select
">>> df = pd.DataFrame([[1, 2, 3], [4, 5, 6]], columns=['A', 'B', 'C'])
>>> df.to_excel('myfile.xlsx')  
>>> file = pd.ExcelFile('myfile.xlsx')  
>>> file.parse()  
",https://pandas.pydata.org/docs/reference/api/pandas.ExcelFile.parse.html, pandas.DataFrame pandas.DataFrame.to_excel pandas.ExcelFile pandas.ExcelFile.parse
">>> df = pd.DataFrame([[1, 2, 3], [4, 5, 6]], columns=['A', 'B', 'C'])
>>> df.to_clipboard()  
>>> pd.read_clipboard()  
     A  B  C
0    1  2  3
1    4  5  6
",https://pandas.pydata.org/docs/reference/api/pandas.read_clipboard.html, pandas.DataFrame pandas.DataFrame.to_clipboard pandas.read_clipboard
">>> df = pd.DataFrame([[1, 2], [3, 4]], columns=['A', 'B'])
>>> store = pd.HDFStore(""store.h5"", 'w')  
>>> store.put('data', df)  
",https://pandas.pydata.org/docs/reference/api/pandas.HDFStore.put.html, pandas.DataFrame pandas.HDFStore.put
">>> pd.read_table('data.csv')  
",https://pandas.pydata.org/docs/reference/api/pandas.read_table.html, pandas.read_table
">>> result = pd.read_orc(""example_pa.orc"")  
",https://pandas.pydata.org/docs/reference/api/pandas.read_orc.html, pandas.read_orc
">>> lst = ['a', 'a', 'a', 'b', 'b', 'b']
>>> ser = pd.Series([7, 2, 8, 4, 3, 3], index=lst)
>>> ser
a     7
a     2
a     8
b     4
b     3
b     3
dtype: int64
>>> ser.groupby(level=0).diff()
a    NaN
a   -5.0
a    6.0
b    NaN
b   -1.0
b    0.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.diff.html, pandas.Series pandas.Series.groupby
">>> data = {'a': [1, 3, 5, 7, 7, 8, 3], 'b': [1, 4, 8, 4, 4, 2, 1]}
>>> df = pd.DataFrame(data, index=['dog', 'dog', 'dog',
...                   'mouse', 'mouse', 'mouse', 'mouse'])
>>> df
         a  b
  dog    1  1
  dog    3  4
  dog    5  8
mouse    7  4
mouse    7  4
mouse    8  2
mouse    3  1
>>> df.groupby(level=0).diff()
         a    b
  dog  NaN  NaN
  dog  2.0  3.0
  dog  2.0  4.0
mouse  NaN  NaN
mouse  0.0  0.0
mouse  1.0 -2.0
mouse -5.0 -1.0
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.diff.html, pandas.DataFrame pandas.DataFrame.groupby
">>> lst = ['a', 'a', 'a', 'b', 'b', 'b']
>>> ser = pd.Series([7, 2, 8, 4, 3, 3], index=lst)
>>> ser
a     7
a     2
a     8
b     4
b     3
b     3
dtype: int64
>>> ser.groupby(level=0).median()
a    7.0
b    3.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.median.html, pandas.Series pandas.Series.groupby
">>> data = {'a': [1, 3, 5, 7, 7, 8, 3], 'b': [1, 4, 8, 4, 4, 2, 1]}
>>> df = pd.DataFrame(data, index=['dog', 'dog', 'dog',
...                   'mouse', 'mouse', 'mouse', 'mouse'])
>>> df
         a  b
  dog    1  1
  dog    3  4
  dog    5  8
mouse    7  4
mouse    7  4
mouse    8  2
mouse    3  1
>>> df.groupby(level=0).median()
         a    b
dog    3.0  4.0
mouse  7.0  3.0
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.median.html, pandas.DataFrame pandas.DataFrame.groupby
">>> ser = pd.Series([1, 2, 3, 3, 4, 5],
...                 index=pd.DatetimeIndex(['2023-01-01',
...                                         '2023-01-10',
...                                         '2023-01-15',
...                                         '2023-02-01',
...                                         '2023-02-10',
...                                         '2023-02-15']))
>>> ser.resample('MS').median()
2023-01-01    2.0
2023-02-01    4.0
Freq: MS, dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.median.html, pandas.Series pandas.DatetimeIndex pandas.Series.resample
">>> pd.read_fwf('data.csv')  
",https://pandas.pydata.org/docs/reference/api/pandas.read_fwf.html, pandas.read_fwf
">>> df = pd.read_sas(""sas_data.sas7bdat"")  
",https://pandas.pydata.org/docs/reference/api/pandas.read_sas.html, pandas.read_sas
">>> df = pd.DataFrame(data={'col1': [1, 2], 'col2': [4, 3]})
>>> html_string = '''
...   
...     
...       
...       col1
...       col2
...     
...   
...   
...     
...       0
...       1
...       4
...     
...     
...       1
...       2
...       3
...     
...   
... '''
>>> assert html_string == df.to_html()
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_html.html, pandas.DataFrame pandas.DataFrame.to_html
">>> lst = ['a', 'a', 'b']
>>> ser = pd.Series([1, 2, np.nan], index=lst)
>>> ser
a    1.0
a    2.0
b    NaN
dtype: float64
>>> ser.groupby(level=0).count()
a    2
b    0
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.count.html, pandas.Series pandas.Series.groupby
">>> data = [[1, np.nan, 3], [1, np.nan, 6], [7, 8, 9]]
>>> df = pd.DataFrame(data, columns=[""a"", ""b"", ""c""],
...                   index=[""cow"", ""horse"", ""bull""])
>>> df
        a         b     c
cow     1       NaN     3
horse   1       NaN     6
bull    7       8.0     9
>>> df.groupby(""a"").count()
    b   c
a
1   0   2
7   1   1
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.count.html, pandas.DataFrame pandas.DataFrame.groupby
">>> ser = pd.Series([1, 2, 3, 4], index=pd.DatetimeIndex(
...                 ['2023-01-01', '2023-01-15', '2023-02-01', '2023-02-15']))
>>> ser
2023-01-01    1
2023-01-15    2
2023-02-01    3
2023-02-15    4
dtype: int64
>>> ser.resample('MS').count()
2023-01-01    2
2023-02-01    2
Freq: MS, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.count.html, pandas.Series pandas.DatetimeIndex pandas.Series.resample
">>> lst = ['a', 'a', 'a', 'b', 'b', 'b']
>>> ser = pd.Series([7, 2, 8, 4, 3, 3], index=lst)
>>> ser
a     7
a     2
a     8
b     4
b     3
b     3
dtype: int64
>>> ser.groupby(level=0).var()
a    10.333333
b     0.333333
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.var.html, pandas.Series pandas.Series.groupby
">>> data = {'a': [1, 3, 5, 7, 7, 8, 3], 'b': [1, 4, 8, 4, 4, 2, 1]}
>>> df = pd.DataFrame(data, index=['dog', 'dog', 'dog',
...                   'mouse', 'mouse', 'mouse', 'mouse'])
>>> df
         a  b
  dog    1  1
  dog    3  4
  dog    5  8
mouse    7  4
mouse    7  4
mouse    8  2
mouse    3  1
>>> df.groupby(level=0).var()
              a          b
dog    4.000000  12.333333
mouse  4.916667   2.250000
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.var.html, pandas.DataFrame pandas.DataFrame.groupby
">>> lst = ['cat', 'cat', 'cat', 'mouse', 'mouse']
>>> ser = pd.Series([1, None, None, 2, None], index=lst)
>>> ser
cat    1.0
cat    NaN
cat    NaN
mouse  2.0
mouse  NaN
dtype: float64
>>> ser.groupby(level=0).fillna(0, limit=1)
cat    1.0
cat    0.0
cat    NaN
mouse  2.0
mouse  0.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.fillna.html, pandas.Series pandas.Series.groupby
">>> lst = ['a', 'a', 'b']
>>> ser = pd.Series([1, 2, 0], index=lst)
>>> ser
a    1
a    2
b    0
dtype: int64
>>> ser.groupby(level=0).any()
a     True
b    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.any.html, pandas.Series pandas.Series.groupby
">>> data = [[1, 0, 3], [1, 0, 6], [7, 1, 9]]
>>> df = pd.DataFrame(data, columns=[""a"", ""b"", ""c""],
...                   index=[""ostrich"", ""penguin"", ""parrot""])
>>> df
         a  b  c
ostrich  1  0  3
penguin  1  0  6
parrot   7  1  9
>>> df.groupby(by=[""a""]).any()
       b      c
a
1  False   True
7   True   True
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.any.html, pandas.DataFrame pandas.DataFrame.groupby
">>> countries_population = {""Italy"": 59000000, ""France"": 65000000,
...                         ""Malta"": 434000, ""Maldives"": 434000,
...                         ""Brunei"": 434000, ""Iceland"": 337000,
...                         ""Nauru"": 11300, ""Tuvalu"": 11300,
...                         ""Anguilla"": 11300, ""Montserrat"": 5200}
>>> s = pd.Series(countries_population)
>>> s
Italy       59000000
France      65000000
Malta         434000
Maldives      434000
Brunei        434000
Iceland       337000
Nauru          11300
Tuvalu         11300
Anguilla       11300
Montserrat      5200
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.nlargest.html, pandas.Series
">>> s.nlargest()
France      65000000
Italy       59000000
Malta         434000
Maldives      434000
Brunei        434000
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.nlargest.html, pandas.Series.nlargest
">>> s.nlargest(3)
France    65000000
Italy     59000000
Malta       434000
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.nlargest.html, pandas.Series.nlargest
">>> s.nlargest(3, keep='last')
France      65000000
Italy       59000000
Brunei        434000
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.nlargest.html, pandas.Series.nlargest
">>> s.nlargest(3, keep='all')
France      65000000
Italy       59000000
Malta         434000
Maldives      434000
Brunei        434000
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.nlargest.html, pandas.Series.nlargest
">>> lst = ['a', 'a', 'b', 'b']
>>> ser = pd.Series([1, 2, 3, 4], index=lst)
>>> ser
a    1
a    2
b    3
b    4
dtype: int64
>>> ser.groupby(level=0).prod()
a    2
b   12
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.prod.html, pandas.Series pandas.Series.groupby
">>> data = [[1, 8, 2], [1, 2, 5], [2, 5, 8], [2, 6, 9]]
>>> df = pd.DataFrame(data, columns=[""a"", ""b"", ""c""],
...                   index=[""tiger"", ""leopard"", ""cheetah"", ""lion""])
>>> df
          a  b  c
  tiger   1  8  2
leopard   1  2  5
cheetah   2  5  8
   lion   2  6  9
>>> df.groupby(""a"").prod()
     b    c
a
1   16   10
2   30   72
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.prod.html, pandas.DataFrame pandas.DataFrame.groupby
">>> df = pd.DataFrame([[1, 2], [3, 4]], columns=['A', 'B'])
>>> store = pd.HDFStore(""store.h5"", 'w')  
>>> store.put('data', df)  
>>> store.get('data')  
>>> store.close()  
",https://pandas.pydata.org/docs/reference/api/pandas.HDFStore.get.html, pandas.DataFrame pandas.HDFStore.put
">>> lst = ['a', 'a', 'a', 'b', 'b', 'b']
>>> ser = pd.Series([1, 6, 2, 3, 0, 4], index=lst)
>>> ser
a    1
a    6
a    2
b    3
b    0
b    4
dtype: int64
>>> ser.groupby(level=0).cummin()
a    1
a    1
a    1
b    3
b    0
b    0
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.cummin.html, pandas.Series pandas.Series.groupby
">>> data = [[1, 0, 2], [1, 1, 5], [6, 6, 9]]
>>> df = pd.DataFrame(data, columns=[""a"", ""b"", ""c""],
...                   index=[""snake"", ""rabbit"", ""turtle""])
>>> df
        a   b   c
snake   1   0   2
rabbit  1   1   5
turtle  6   6   9
>>> df.groupby(""a"").groups
{1: ['snake', 'rabbit'], 6: ['turtle']}
>>> df.groupby(""a"").cummin()
        b   c
snake   0   2
rabbit  0   2
turtle  6   9
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.cummin.html, pandas.DataFrame pandas.DataFrame.groupby
">>> idx = pd.date_range('1/1/2000', periods=4, freq='min')
>>> df = pd.DataFrame(data=4 * [range(2)],
...                   index=idx,
...                   columns=['a', 'b'])
>>> df.iloc[2, 0] = 5
>>> df
                    a  b
2000-01-01 00:00:00  0  1
2000-01-01 00:01:00  0  1
2000-01-01 00:02:00  5  1
2000-01-01 00:03:00  0  1
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.resample.html, pandas.date_range pandas.DataFrame
">>> df.groupby('a').resample('3min', include_groups=False).sum()
                         b
a
0   2000-01-01 00:00:00  2
    2000-01-01 00:03:00  1
5   2000-01-01 00:00:00  1
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.resample.html, pandas.DataFrame.groupby
">>> df.groupby('a').resample('30s', include_groups=False).sum()
                    b
a
0   2000-01-01 00:00:00  1
    2000-01-01 00:00:30  0
    2000-01-01 00:01:00  1
    2000-01-01 00:01:30  0
    2000-01-01 00:02:00  0
    2000-01-01 00:02:30  0
    2000-01-01 00:03:00  1
5   2000-01-01 00:02:00  1
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.resample.html, pandas.DataFrame.groupby
">>> df.groupby('a').resample('ME', include_groups=False).sum()
            b
a
0   2000-01-31  3
5   2000-01-31  1
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.resample.html, pandas.DataFrame.groupby
">>> (
...     df.groupby('a')
...     .resample('3min', closed='right', include_groups=False)
...     .sum()
... )
                         b
a
0   1999-12-31 23:57:00  1
    2000-01-01 00:00:00  2
5   2000-01-01 00:00:00  1
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.resample.html, pandas.DataFrame.groupby
">>> (
...     df.groupby('a')
...     .resample('3min', closed='right', label='right', include_groups=False)
...     .sum()
... )
                         b
a
0   2000-01-01 00:00:00  1
    2000-01-01 00:03:00  2
5   2000-01-01 00:03:00  1
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.resample.html, pandas.DataFrame.groupby
">>> df = pd.DataFrame([[1, 2], [3, 4]], columns=['A', 'B'])
>>> store = pd.HDFStore(""store.h5"", 'w')  
>>> store.put('data', df)  
>>> print(store.info())  
>>> store.close()  

File path: store.h5
/data    frame    (shape->[2,2])
",https://pandas.pydata.org/docs/reference/api/pandas.HDFStore.info.html, pandas.DataFrame pandas.HDFStore.put
">>> pd.read_sql_table('table_name', 'postgres:///db_name')  
",https://pandas.pydata.org/docs/reference/api/pandas.read_sql_table.html, pandas.read_sql_table
">>> data = {'length': [1.5, 0.5, 1.2, 0.9, 3],
...         'width': [0.7, 0.2, 0.15, 0.2, 1.1]}
>>> index = ['pig', 'rabbit', 'duck', 'chicken', 'horse']
>>> df = pd.DataFrame(data, index=index)
>>> hist = df.hist(bins=3)
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.hist.html, pandas.DataFrame pandas.DataFrame.hist
">>> df = pd.DataFrame({'name': ['Raphael', 'Donatello'],
...                    'mask': ['red', 'purple'],
...                    'weapon': ['sai', 'bo staff']})
>>> df.to_csv('out.csv', index=False)  
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html, pandas.DataFrame pandas.DataFrame.to_csv
">>> df.to_csv(index=False)
'name,mask,weapon\nRaphael,red,sai\nDonatello,purple,bo staff\n'
>>> compression_opts = dict(method='zip',
...                         archive_name='out.csv')  
>>> df.to_csv('out.zip', index=False,
...           compression=compression_opts)  
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html, pandas.DataFrame.to_csv
">>> from pathlib import Path  
>>> filepath = Path('folder/subfolder/out.csv')  
>>> filepath.parent.mkdir(parents=True, exist_ok=True)  
>>> df.to_csv(filepath)  
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html, pandas.DataFrame.to_csv
">>> import os  
>>> os.makedirs('folder/subfolder', exist_ok=True)  
>>> df.to_csv('folder/subfolder/out.csv')  
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html, pandas.DataFrame.to_csv
">>> df = pd.DataFrame(
...     {""a"": [""red""] * 2 + [""blue""] * 2 + [""black""] * 2, ""b"": range(6)}
... )
>>> df
       a  b
0    red  0
1    red  1
2   blue  2
3   blue  3
4  black  4
5  black  5
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.sample.html, pandas.DataFrame
">>> df.groupby(""a"").sample(n=1, random_state=1)
       a  b
4  black  4
2   blue  2
1    red  1
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.sample.html, pandas.DataFrame.groupby
">>> df.groupby(""a"")[""b""].sample(frac=0.5, random_state=2)
5    5
2    2
0    0
Name: b, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.sample.html, pandas.DataFrame.groupby
">>> df.groupby(""a"").sample(
...     n=1,
...     weights=[1, 1, 1, 0, 0, 1],
...     random_state=1,
... )
       a  b
5  black  5
2   blue  2
0    red  0
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.sample.html, pandas.DataFrame.groupby
">>> lst = ['a', 'a', 'b']
>>> ser = pd.Series([1, 2, 0], index=lst)
>>> ser
a    1
a    2
b    0
dtype: int64
>>> ser.groupby(level=0).any()
a     True
b    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.any.html, pandas.Series pandas.Series.groupby
">>> data = [[1, 0, 3], [1, 0, 6], [7, 1, 9]]
>>> df = pd.DataFrame(data, columns=[""a"", ""b"", ""c""],
...                   index=[""ostrich"", ""penguin"", ""parrot""])
>>> df
         a  b  c
ostrich  1  0  3
penguin  1  0  6
parrot   7  1  9
>>> df.groupby(by=[""a""]).any()
       b      c
a
1  False   True
7   True   True
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.any.html, pandas.DataFrame pandas.DataFrame.groupby
">>> df = pd.DataFrame({'A': 'a a b'.split(),
...                    'B': [1, 2, 3],
...                    'C': [4, 6, 5]})
>>> g1 = df.groupby('A', group_keys=False)
>>> g2 = df.groupby('A', group_keys=True)
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.apply.html, pandas.DataFrame pandas.Series.str.split pandas.DataFrame.groupby
">>> g1[['B', 'C']].apply(lambda x: x / x.sum())
          B    C
0  0.333333  0.4
1  0.666667  0.6
2  1.000000  1.0
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.apply.html, pandas.Series.sum
">>> g2[['B', 'C']].apply(lambda x: x / x.sum())
            B    C
A
a 0  0.333333  0.4
  1  0.666667  0.6
b 2  1.000000  1.0
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.apply.html, pandas.Series.sum
">>> g1[['B', 'C']].apply(lambda x: x.astype(float).max() - x.min())
     B    C
A
a  1.0  2.0
b  0.0  0.0
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.apply.html, pandas.Series.astype pandas.Series.min
">>> g2[['B', 'C']].apply(lambda x: x.astype(float).max() - x.min())
     B    C
A
a  1.0  2.0
b  0.0  0.0
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.apply.html, pandas.Series.astype pandas.Series.min
">>> data = [
...     {""id"": 1, ""name"": {""first"": ""Coleen"", ""last"": ""Volk""}},
...     {""name"": {""given"": ""Mark"", ""family"": ""Regner""}},
...     {""id"": 2, ""name"": ""Faye Raker""},
... ]
>>> pd.json_normalize(data)
    id name.first name.last name.given name.family        name
0  1.0     Coleen      Volk        NaN         NaN         NaN
1  NaN        NaN       NaN       Mark      Regner         NaN
2  2.0        NaN       NaN        NaN         NaN  Faye Raker
",https://pandas.pydata.org/docs/reference/api/pandas.json_normalize.html, pandas.json_normalize
">>> data = [
...     {
...         ""id"": 1,
...         ""name"": ""Cole Volk"",
...         ""fitness"": {""height"": 130, ""weight"": 60},
...     },
...     {""name"": ""Mark Reg"", ""fitness"": {""height"": 130, ""weight"": 60}},
...     {
...         ""id"": 2,
...         ""name"": ""Faye Raker"",
...         ""fitness"": {""height"": 130, ""weight"": 60},
...     },
... ]
>>> pd.json_normalize(data, max_level=0)
    id        name                        fitness
0  1.0   Cole Volk  {'height': 130, 'weight': 60}
1  NaN    Mark Reg  {'height': 130, 'weight': 60}
2  2.0  Faye Raker  {'height': 130, 'weight': 60}
",https://pandas.pydata.org/docs/reference/api/pandas.json_normalize.html, pandas.json_normalize
">>> data = [
...     {
...         ""id"": 1,
...         ""name"": ""Cole Volk"",
...         ""fitness"": {""height"": 130, ""weight"": 60},
...     },
...     {""name"": ""Mark Reg"", ""fitness"": {""height"": 130, ""weight"": 60}},
...     {
...         ""id"": 2,
...         ""name"": ""Faye Raker"",
...         ""fitness"": {""height"": 130, ""weight"": 60},
...     },
... ]
>>> pd.json_normalize(data, max_level=1)
    id        name  fitness.height  fitness.weight
0  1.0   Cole Volk             130              60
1  NaN    Mark Reg             130              60
2  2.0  Faye Raker             130              60
",https://pandas.pydata.org/docs/reference/api/pandas.json_normalize.html, pandas.json_normalize
">>> data = [
...     {
...         ""state"": ""Florida"",
...         ""shortname"": ""FL"",
...         ""info"": {""governor"": ""Rick Scott""},
...         ""counties"": [
...             {""name"": ""Dade"", ""population"": 12345},
...             {""name"": ""Broward"", ""population"": 40000},
...             {""name"": ""Palm Beach"", ""population"": 60000},
...         ],
...     },
...     {
...         ""state"": ""Ohio"",
...         ""shortname"": ""OH"",
...         ""info"": {""governor"": ""John Kasich""},
...         ""counties"": [
...             {""name"": ""Summit"", ""population"": 1234},
...             {""name"": ""Cuyahoga"", ""population"": 1337},
...         ],
...     },
... ]
>>> result = pd.json_normalize(
...     data, ""counties"", [""state"", ""shortname"", [""info"", ""governor""]]
... )
>>> result
         name  population    state shortname info.governor
0        Dade       12345   Florida    FL    Rick Scott
1     Broward       40000   Florida    FL    Rick Scott
2  Palm Beach       60000   Florida    FL    Rick Scott
3      Summit        1234   Ohio       OH    John Kasich
4    Cuyahoga        1337   Ohio       OH    John Kasich
",https://pandas.pydata.org/docs/reference/api/pandas.json_normalize.html, pandas.json_normalize
">>> data = {""A"": [1, 2]}
>>> pd.json_normalize(data, ""A"", record_prefix=""Prefix."")
    Prefix.0
0          1
1          2
",https://pandas.pydata.org/docs/reference/api/pandas.json_normalize.html, pandas.json_normalize
">>> df = pd.DataFrame([['a', 1], ['a', 2], ['b', 1], ['b', 2]],
...                   columns=['A', 'B'])
>>> df.groupby('A').tail(1)
   A  B
1  a  2
3  b  2
>>> df.groupby('A').tail(-1)
   A  B
1  a  2
3  b  2
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.tail.html, pandas.DataFrame pandas.DataFrame.groupby
">>> lst = ['a', 'a', 'b']
>>> ser = pd.Series([1, 2, 3], index=lst)
>>> ser
a    1
a    2
b    3
dtype: int64
>>> for x, y in ser.groupby(level=0):
...     print(f'{x}\n{y}\n')
a
a    1
a    2
dtype: int64
b
b    3
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.__iter__.html, pandas.Series pandas.Series.groupby
">>> data = [[1, 2, 3], [1, 5, 6], [7, 8, 9]]
>>> df = pd.DataFrame(data, columns=[""a"", ""b"", ""c""])
>>> df
   a  b  c
0  1  2  3
1  1  5  6
2  7  8  9
>>> for x, y in df.groupby(by=[""a""]):
...     print(f'{x}\n{y}\n')
(1,)
   a  b  c
0  1  2  3
1  1  5  6
(7,)
   a  b  c
2  7  8  9
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.__iter__.html, pandas.DataFrame pandas.DataFrame.groupby
">>> ser = pd.Series([1, 2, 3, 4], index=pd.DatetimeIndex(
...                 ['2023-01-01', '2023-01-15', '2023-02-01', '2023-02-15']))
>>> ser
2023-01-01    1
2023-01-15    2
2023-02-01    3
2023-02-15    4
dtype: int64
>>> for x, y in ser.resample('MS'):
...     print(f'{x}\n{y}\n')
2023-01-01 00:00:00
2023-01-01    1
2023-01-15    2
dtype: int64
2023-02-01 00:00:00
2023-02-01    3
2023-02-15    4
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.__iter__.html, pandas.Series pandas.DatetimeIndex pandas.Series.resample
">>> df = pd.DataFrame({""key"": [1, 1, 2], ""a"": [-1, 0, 1], 1: [10, 11, 12]})
>>> agg_a = pd.NamedAgg(column=""a"", aggfunc=""min"")
>>> agg_1 = pd.NamedAgg(column=1, aggfunc=lambda x: np.mean(x))
>>> df.groupby(""key"").agg(result_a=agg_a, result_1=agg_1)
     result_a  result_1
key
1          -1      10.5
2           1      12.0
",https://pandas.pydata.org/docs/reference/api/pandas.NamedAgg.html, pandas.DataFrame pandas.NamedAgg pandas.DataFrame.groupby
">>> idx = pd.date_range('1/1/2000', periods=4, freq='min')
>>> df = pd.DataFrame(data=4 * [range(2)],
...                   index=idx,
...                   columns=['a', 'b'])
>>> df.iloc[2, 0] = 5
>>> df
                    a  b
2000-01-01 00:00:00  0  1
2000-01-01 00:01:00  0  1
2000-01-01 00:02:00  5  1
2000-01-01 00:03:00  0  1
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.resample.html, pandas.date_range pandas.DataFrame
">>> df.groupby('a').resample('3min', include_groups=False).sum()
                         b
a
0   2000-01-01 00:00:00  2
    2000-01-01 00:03:00  1
5   2000-01-01 00:00:00  1
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.resample.html, pandas.DataFrame.groupby
">>> df.groupby('a').resample('30s', include_groups=False).sum()
                    b
a
0   2000-01-01 00:00:00  1
    2000-01-01 00:00:30  0
    2000-01-01 00:01:00  1
    2000-01-01 00:01:30  0
    2000-01-01 00:02:00  0
    2000-01-01 00:02:30  0
    2000-01-01 00:03:00  1
5   2000-01-01 00:02:00  1
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.resample.html, pandas.DataFrame.groupby
">>> df.groupby('a').resample('ME', include_groups=False).sum()
            b
a
0   2000-01-31  3
5   2000-01-31  1
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.resample.html, pandas.DataFrame.groupby
">>> (
...     df.groupby('a')
...     .resample('3min', closed='right', include_groups=False)
...     .sum()
... )
                         b
a
0   1999-12-31 23:57:00  1
    2000-01-01 00:00:00  2
5   2000-01-01 00:00:00  1
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.resample.html, pandas.DataFrame.groupby
">>> (
...     df.groupby('a')
...     .resample('3min', closed='right', label='right', include_groups=False)
...     .sum()
... )
                         b
a
0   2000-01-01 00:00:00  1
    2000-01-01 00:03:00  2
5   2000-01-01 00:03:00  1
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.resample.html, pandas.DataFrame.groupby
">>> from io import StringIO
>>> df = pd.DataFrame([['a', 'b'], ['c', 'd']],
...                   index=['row 1', 'row 2'],
...                   columns=['col 1', 'col 2'])
",https://pandas.pydata.org/docs/reference/api/pandas.read_json.html, pandas.DataFrame
">>> df.to_json(orient='split')
    '{""columns"":[""col 1"",""col 2""],""index"":[""row 1"",""row 2""],""data"":[[""a"",""b""],[""c"",""d""]]}'
>>> pd.read_json(StringIO(_), orient='split')
      col 1 col 2
row 1     a     b
row 2     c     d
",https://pandas.pydata.org/docs/reference/api/pandas.read_json.html, pandas.DataFrame.to_json pandas.read_json
">>> df.to_json(orient='index')
'{""row 1"":{""col 1"":""a"",""col 2"":""b""},""row 2"":{""col 1"":""c"",""col 2"":""d""}}'
",https://pandas.pydata.org/docs/reference/api/pandas.read_json.html, pandas.DataFrame.to_json
">>> pd.read_json(StringIO(_), orient='index')
      col 1 col 2
row 1     a     b
row 2     c     d
",https://pandas.pydata.org/docs/reference/api/pandas.read_json.html, pandas.read_json
">>> df.to_json(orient='records')
'[{""col 1"":""a"",""col 2"":""b""},{""col 1"":""c"",""col 2"":""d""}]'
>>> pd.read_json(StringIO(_), orient='records')
  col 1 col 2
0     a     b
1     c     d
",https://pandas.pydata.org/docs/reference/api/pandas.read_json.html, pandas.DataFrame.to_json pandas.read_json
">>> df.to_json(orient='table')
    '{""schema"":{""fields"":[{""name"":""index"",""type"":""string""},{""name"":""col 1"",""type"":""string""},{""name"":""col 2"",""type"":""string""}],""primaryKey"":[""index""],""pandas_version"":""1.4.0""},""data"":[{""index"":""row 1"",""col 1"":""a"",""col 2"":""b""},{""index"":""row 2"",""col 1"":""c"",""col 2"":""d""}]}'
",https://pandas.pydata.org/docs/reference/api/pandas.read_json.html, pandas.DataFrame.to_json
">>> data = '''{""index"": {""0"": 0, ""1"": 1},
...        ""a"": {""0"": 1, ""1"": null},
...        ""b"": {""0"": 2.5, ""1"": 4.5},
...        ""c"": {""0"": true, ""1"": false},
...        ""d"": {""0"": ""a"", ""1"": ""b""},
...        ""e"": {""0"": 1577.2, ""1"": 1577.1}}'''
>>> pd.read_json(StringIO(data), dtype_backend=""numpy_nullable"")
   index     a    b      c  d       e
0      0     1  2.5   True  a  1577.2
1      1    4.5  False  b  1577.1
",https://pandas.pydata.org/docs/reference/api/pandas.read_json.html, pandas.read_json
">>> df = pd.DataFrame({""color"": [""red"", None, ""red"", ""blue"", ""blue"", ""red""]})
>>> df
   color
0    red
1   None
2    red
3   blue
4   blue
5    red
>>> df.groupby(""color"").ngroup()
0    1.0
1    NaN
2    1.0
3    0.0
4    0.0
5    1.0
dtype: float64
>>> df.groupby(""color"", dropna=False).ngroup()
0    1
1    2
2    1
3    0
4    0
5    1
dtype: int64
>>> df.groupby(""color"", dropna=False).ngroup(ascending=False)
0    1
1    0
2    1
3    2
4    2
5    1
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.ngroup.html, pandas.DataFrame pandas.DataFrame.groupby
">>> df = pd.DataFrame([('Chihuahua', 'dog', 6.1),
...                    ('Beagle', 'dog', 15.2),
...                    ('Chihuahua', 'dog', 6.9),
...                    ('Persian', 'cat', 9.2),
...                    ('Chihuahua', 'dog', 7),
...                    ('Persian', 'cat', 8.8)],
...                   columns=['breed', 'animal', 'height_in'])
>>> df
       breed     animal   height_in
0  Chihuahua        dog         6.1
1     Beagle        dog        15.2
2  Chihuahua        dog         6.9
3    Persian        cat         9.2
4  Chihuahua        dog         7.0
5    Persian        cat         8.8
>>> ser = df.groupby('animal')['breed'].unique()
>>> ser
animal
cat              [Persian]
dog    [Chihuahua, Beagle]
Name: breed, dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.unique.html, pandas.DataFrame pandas.DataFrame.groupby
">>> df = pd.DataFrame(dict(A=[1, 1, 3], B=[None, 5, 6], C=[1, 2, 3],
...                        D=['3/11/2000', '3/12/2000', '3/13/2000']))
>>> df['D'] = pd.to_datetime(df['D'])
>>> df.groupby(""A"").first()
     B  C          D
A
1  5.0  1 2000-03-11
3  6.0  3 2000-03-13
>>> df.groupby(""A"").first(min_count=2)
    B    C          D
A
1 NaN  1.0 2000-03-11
3 NaN  NaN        NaT
>>> df.groupby(""A"").first(numeric_only=True)
     B  C
A
1  5.0  1
3  6.0  3
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.first.html, pandas.DataFrame pandas.to_datetime pandas.DataFrame.groupby
">>> df = pd.DataFrame({""color"": [""red"", None, ""red"", ""blue"", ""blue"", ""red""]})
>>> df
   color
0    red
1   None
2    red
3   blue
4   blue
5    red
>>> df.groupby(""color"").ngroup()
0    1.0
1    NaN
2    1.0
3    0.0
4    0.0
5    1.0
dtype: float64
>>> df.groupby(""color"", dropna=False).ngroup()
0    1
1    2
2    1
3    0
4    0
5    1
dtype: int64
>>> df.groupby(""color"", dropna=False).ngroup(ascending=False)
0    1
1    0
2    1
3    2
4    2
5    1
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.ngroup.html, pandas.DataFrame pandas.DataFrame.groupby
">>> sql = ""SELECT name FROM table_name WHERE state = 'TX' LIMIT 100;""
>>> df = pd.read_gbq(sql, dialect=""standard"")  
>>> project_id = ""your-project-id""  
>>> df = pd.read_gbq(sql,
...                  project_id=project_id,
...                  dialect=""standard""
...                  )  
",https://pandas.pydata.org/docs/reference/api/pandas.read_gbq.html, pandas.read_gbq
">>> countries_population = {""Italy"": 59000000, ""France"": 65000000,
...                         ""Brunei"": 434000, ""Malta"": 434000,
...                         ""Maldives"": 434000, ""Iceland"": 337000,
...                         ""Nauru"": 11300, ""Tuvalu"": 11300,
...                         ""Anguilla"": 11300, ""Montserrat"": 5200}
>>> s = pd.Series(countries_population)
>>> s
Italy       59000000
France      65000000
Brunei        434000
Malta         434000
Maldives      434000
Iceland       337000
Nauru          11300
Tuvalu         11300
Anguilla       11300
Montserrat      5200
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.nsmallest.html, pandas.Series
">>> s.nsmallest()
Montserrat    5200
Nauru        11300
Tuvalu       11300
Anguilla     11300
Iceland     337000
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.nsmallest.html, pandas.Series.nsmallest
">>> s.nsmallest(3)
Montserrat   5200
Nauru       11300
Tuvalu      11300
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.nsmallest.html, pandas.Series.nsmallest
">>> s.nsmallest(3, keep='last')
Montserrat   5200
Anguilla    11300
Tuvalu      11300
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.nsmallest.html, pandas.Series.nsmallest
">>> s.nsmallest(3, keep='all')
Montserrat   5200
Nauru       11300
Tuvalu      11300
Anguilla    11300
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.nsmallest.html, pandas.Series.nsmallest
">>> ser = pd.Series([390., 350., 357., np.nan, 22., 20., 30.],
...                 index=['Falcon', 'Falcon', 'Falcon', 'Falcon',
...                        'Parrot', 'Parrot', 'Parrot'],
...                 name=""Max Speed"")
>>> ser
Falcon    390.0
Falcon    350.0
Falcon    357.0
Falcon      NaN
Parrot     22.0
Parrot     20.0
Parrot     30.0
Name: Max Speed, dtype: float64
>>> ser.groupby(level=0).skew()
Falcon    1.525174
Parrot    1.457863
Name: Max Speed, dtype: float64
>>> ser.groupby(level=0).skew(skipna=False)
Falcon         NaN
Parrot    1.457863
Name: Max Speed, dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.skew.html, pandas.Series pandas.Series.groupby
">>> df = pd.DataFrame({'A': [1, 1, 2, 2],
...                    'B': [1, 2, 3, 4],
...                    'C': [0.362, 0.227, 1.267, -0.562]})
>>> df
      A  B      C
0     1  1  0.362
1     1  2  0.227
2     2  3  1.267
3     2  4 -0.562
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.rolling.html, pandas.DataFrame
">>> df.groupby('A').rolling(2).sum()
    B      C
A
1 0  NaN    NaN
  1  3.0  0.589
2 2  NaN    NaN
  3  7.0  0.705
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.rolling.html, pandas.DataFrame.groupby
">>> df.groupby('A').rolling(2, min_periods=1).sum()
    B      C
A
1 0  1.0  0.362
  1  3.0  0.589
2 2  3.0  1.267
  3  7.0  0.705
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.rolling.html, pandas.DataFrame.groupby
">>> df.groupby('A').rolling(2, on='B').sum()
    B      C
A
1 0  1    NaN
  1  2  0.589
2 2  3    NaN
  3  4  0.705
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.rolling.html, pandas.DataFrame.groupby
">>> lst = ['a', 'a', 'a', 'b', 'b', 'b']
>>> ser = pd.Series([1, 6, 2, 3, 1, 4], index=lst)
>>> ser
a    1
a    6
a    2
b    3
b    1
b    4
dtype: int64
>>> ser.groupby(level=0).cummax()
a    1
a    6
a    6
b    3
b    3
b    4
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.cummax.html, pandas.Series pandas.Series.groupby
">>> data = [[1, 8, 2], [1, 1, 0], [2, 6, 9]]
>>> df = pd.DataFrame(data, columns=[""a"", ""b"", ""c""],
...                   index=[""cow"", ""horse"", ""bull""])
>>> df
        a   b   c
cow     1   8   2
horse   1   1   0
bull    2   6   9
>>> df.groupby(""a"").groups
{1: ['cow', 'horse'], 2: ['bull']}
>>> df.groupby(""a"").cummax()
        b   c
cow     8   2
horse   8   2
bull    6   9
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.cummax.html, pandas.DataFrame pandas.DataFrame.groupby
">>> df = pd.DataFrame({'consumption': [10.51, 103.11, 55.48],
...                    'co2_emissions': [37.2, 19.66, 1712]},
...                   index=['Pork', 'Wheat Products', 'Beef'])
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.idxmax.html, pandas.DataFrame
">>> df.idxmax()
consumption     Wheat Products
co2_emissions             Beef
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.idxmax.html, pandas.DataFrame.idxmax
">>> df.idxmax(axis=""columns"")
Pork              co2_emissions
Wheat Products     consumption
Beef              co2_emissions
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.idxmax.html, pandas.DataFrame.idxmax
">>> data = {""A"": [1, 1, 2, 2],
...         ""B"": [1, 2, 3, 4],
...         ""C"": [0.362838, 0.227877, 1.267767, -0.562860]}
>>> df = pd.DataFrame(data)
>>> df
   A  B         C
0  1  1  0.362838
1  1  2  0.227877
2  2  3  1.267767
3  2  4 -0.562860
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.agg.html, pandas.DataFrame
">>> df.groupby('A').agg('min')
   B         C
A
1  1  0.227877
2  3 -0.562860
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.agg.html, pandas.DataFrame.groupby
">>> df.groupby('A').agg(['min', 'max'])
    B             C
  min max       min       max
A
1   1   2  0.227877  0.362838
2   3   4 -0.562860  1.267767
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.agg.html, pandas.DataFrame.groupby
">>> df.groupby('A').B.agg(['min', 'max'])
   min  max
A
1    1    2
2    3    4
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.agg.html, pandas.DataFrame.groupby
">>> df.groupby('A').agg(lambda x: sum(x) + 2)
    B          C
A
1       5       2.590715
2       9       2.704907
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.agg.html, pandas.DataFrame.groupby
">>> df.groupby('A').agg({'B': ['min', 'max'], 'C': 'sum'})
    B             C
  min max       sum
A
1   1   2  0.590715
2   3   4  0.704907
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.agg.html, pandas.DataFrame.groupby
">>> df.groupby(""A"").agg(
...     b_min=pd.NamedAgg(column=""B"", aggfunc=""min""),
...     c_sum=pd.NamedAgg(column=""C"", aggfunc=""sum"")
... )
   b_min     c_sum
A
1      1  0.590715
2      3  0.704907
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.agg.html, pandas.DataFrame.groupby pandas.NamedAgg
">>> df.groupby(""A"")[[""B""]].agg(lambda x: x.astype(float).min())
      B
A
1   1.0
2   3.0
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.agg.html, pandas.DataFrame.groupby pandas.Series.astype
">>> original_df = pd.DataFrame({""foo"": range(5), ""bar"": range(5, 10)})  
>>> original_df  
   foo  bar
0    0    5
1    1    6
2    2    7
3    3    8
4    4    9
>>> original_df.to_pickle(""./dummy.pkl"")  
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_pickle.html, pandas.DataFrame pandas.DataFrame.to_pickle
">>> unpickled_df = pd.read_pickle(""./dummy.pkl"")  
>>> unpickled_df  
   foo  bar
0    0    5
1    1    6
2    2    7
3    3    8
4    4    9
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_pickle.html, pandas.read_pickle
">>> df = pd.DataFrame({'animal': ['falcon', 'parrot', 'falcon',
...                               'parrot'],
...                    'speed': [350, 18, 361, 15]})
>>> df.to_stata('animals.dta')  
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_stata.html, pandas.DataFrame pandas.DataFrame.to_stata
">>> index = ['Falcon', 'Falcon', 'Parrot', 'Parrot', 'Parrot']
>>> s = pd.Series([None, 1, None, None, 3], index=index)
>>> s
Falcon    NaN
Falcon    1.0
Parrot    NaN
Parrot    NaN
Parrot    3.0
dtype: float64
>>> s.groupby(level=0).bfill()
Falcon    1.0
Falcon    1.0
Parrot    3.0
Parrot    3.0
Parrot    3.0
dtype: float64
>>> s.groupby(level=0).bfill(limit=1)
Falcon    1.0
Falcon    1.0
Parrot    NaN
Parrot    3.0
Parrot    3.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.bfill.html, pandas.Series pandas.Series.groupby
">>> df = pd.DataFrame({'A': [1, None, None, None, 4],
...                    'B': [None, None, 5, None, 7]}, index=index)
>>> df
          A         B
Falcon  1.0       NaN
Falcon  NaN       NaN
Parrot  NaN       5.0
Parrot  NaN       NaN
Parrot  4.0       7.0
>>> df.groupby(level=0).bfill()
          A         B
Falcon  1.0       NaN
Falcon  NaN       NaN
Parrot  4.0       5.0
Parrot  4.0       7.0
Parrot  4.0       7.0
>>> df.groupby(level=0).bfill(limit=1)
          A         B
Falcon  1.0       NaN
Falcon  NaN       NaN
Parrot  NaN       5.0
Parrot  4.0       7.0
Parrot  4.0       7.0
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.bfill.html, pandas.DataFrame pandas.DataFrame.groupby
">>> lst = ['a', 'a', 'b', 'b']
>>> ser = pd.Series([1, 2, 3, 4], index=lst)
>>> ser
a    1
a    2
b    3
b    4
dtype: int64
>>> ser.groupby(level=0).sum()
a    3
b    7
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.sum.html, pandas.Series pandas.Series.groupby
">>> data = [[1, 8, 2], [1, 2, 5], [2, 5, 8], [2, 6, 9]]
>>> df = pd.DataFrame(data, columns=[""a"", ""b"", ""c""],
...                   index=[""tiger"", ""leopard"", ""cheetah"", ""lion""])
>>> df
          a  b  c
  tiger   1  8  2
leopard   1  2  5
cheetah   2  5  8
   lion   2  6  9
>>> df.groupby(""a"").sum()
     b   c
a
1   10   7
2   11  17
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.sum.html, pandas.DataFrame pandas.DataFrame.groupby
">>> lst = ['a', 'a', 'a', 'b', 'b', 'b']
>>> ser = pd.Series([7, 2, 8, 4, 3, 3], index=lst)
>>> ser
a     7
a     2
a     8
b     4
b     3
b     3
dtype: int64
>>> ser.groupby(level=0).std()
a    3.21455
b    0.57735
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.std.html, pandas.Series pandas.Series.groupby
">>> data = {'a': [1, 3, 5, 7, 7, 8, 3], 'b': [1, 4, 8, 4, 4, 2, 1]}
>>> df = pd.DataFrame(data, index=['dog', 'dog', 'dog',
...                   'mouse', 'mouse', 'mouse', 'mouse'])
>>> df
         a  b
  dog    1  1
  dog    3  4
  dog    5  8
mouse    7  4
mouse    7  4
mouse    8  2
mouse    3  1
>>> df.groupby(level=0).std()
              a         b
dog    2.000000  3.511885
mouse  2.217356  1.500000
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.std.html, pandas.DataFrame pandas.DataFrame.groupby
">>> df = pd.DataFrame({'consumption': [10.51, 103.11, 55.48],
...                    'co2_emissions': [37.2, 19.66, 1712]},
...                   index=['Pork', 'Wheat Products', 'Beef'])
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.idxmin.html, pandas.DataFrame
">>> df.idxmin()
consumption                Pork
co2_emissions    Wheat Products
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.idxmin.html, pandas.DataFrame.idxmin
">>> df.idxmin(axis=""columns"")
Pork                consumption
Wheat Products    co2_emissions
Beef                consumption
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.idxmin.html, pandas.DataFrame.idxmin
">>> lst = ['a', 'a', 'b', 'b']
>>> ser = pd.Series([1, 2, 3, 3], index=lst)
>>> ser
a    1
a    2
b    3
b    3
dtype: int64
>>> ser.groupby(level=0).nunique()
a    2
b    1
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.nunique.html, pandas.Series pandas.Series.groupby
">>> ser = pd.Series([1, 2, 3, 3], index=pd.DatetimeIndex(
...                 ['2023-01-01', '2023-01-15', '2023-02-01', '2023-02-15']))
>>> ser
2023-01-01    1
2023-01-15    2
2023-02-01    3
2023-02-15    3
dtype: int64
>>> ser.resample('MS').nunique()
2023-01-01    2
2023-02-01    1
Freq: MS, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.nunique.html, pandas.Series pandas.DatetimeIndex pandas.Series.resample
">>> lst = ['a', 'a', 'a', 'b', 'b', 'b']
>>> ser = pd.Series([7, 2, 8, 4, 3, 3], index=lst)
>>> ser
a     7
a     2
a     8
b     4
b     3
b     3
dtype: int64
>>> ser.groupby(level=0).median()
a    7.0
b    3.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.median.html, pandas.Series pandas.Series.groupby
">>> data = {'a': [1, 3, 5, 7, 7, 8, 3], 'b': [1, 4, 8, 4, 4, 2, 1]}
>>> df = pd.DataFrame(data, index=['dog', 'dog', 'dog',
...                   'mouse', 'mouse', 'mouse', 'mouse'])
>>> df
         a  b
  dog    1  1
  dog    3  4
  dog    5  8
mouse    7  4
mouse    7  4
mouse    8  2
mouse    3  1
>>> df.groupby(level=0).median()
         a    b
dog    3.0  4.0
mouse  7.0  3.0
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.median.html, pandas.DataFrame pandas.DataFrame.groupby
">>> ser = pd.Series([1, 2, 3, 3, 4, 5],
...                 index=pd.DatetimeIndex(['2023-01-01',
...                                         '2023-01-10',
...                                         '2023-01-15',
...                                         '2023-02-01',
...                                         '2023-02-10',
...                                         '2023-02-15']))
>>> ser.resample('MS').median()
2023-01-01    2.0
2023-02-01    4.0
Freq: MS, dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.median.html, pandas.Series pandas.DatetimeIndex pandas.Series.resample
">>> df = pd.DataFrame({'A': [1, 1, 2, 1, 2],
...                    'B': [np.nan, 2, 3, 4, 5]}, columns=['A', 'B'])
>>> g = df.groupby('A')
>>> g.nth(0)
   A   B
0  1 NaN
2  2 3.0
>>> g.nth(1)
   A   B
1  1 2.0
4  2 5.0
>>> g.nth(-1)
   A   B
3  1 4.0
4  2 5.0
>>> g.nth([0, 1])
   A   B
0  1 NaN
1  1 2.0
2  2 3.0
4  2 5.0
>>> g.nth(slice(None, -1))
   A   B
0  1 NaN
1  1 2.0
2  2 3.0
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.nth.html, pandas.DataFrame pandas.DataFrame.groupby pandas.Series.str.slice
">>> lst = ['a', 'a', 'b', 'b']
>>> ser = pd.Series([5, 10, 8, 14], index=lst)
>>> ser
a     5
a    10
b     8
b    14
dtype: int64
>>> ser.groupby(level=0).sem()
a    2.5
b    3.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.sem.html, pandas.Series pandas.Series.groupby
">>> data = [[1, 12, 11], [1, 15, 2], [2, 5, 8], [2, 6, 12]]
>>> df = pd.DataFrame(data, columns=[""a"", ""b"", ""c""],
...                   index=[""tuna"", ""salmon"", ""catfish"", ""goldfish""])
>>> df
           a   b   c
    tuna   1  12  11
  salmon   1  15   2
 catfish   2   5   8
goldfish   2   6  12
>>> df.groupby(""a"").sem()
      b  c
a
1    1.5  4.5
2    0.5  2.0
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.sem.html, pandas.DataFrame pandas.DataFrame.groupby
">>> ser = pd.Series([1, 3, 2, 4, 3, 8],
...                 index=pd.DatetimeIndex(['2023-01-01',
...                                         '2023-01-10',
...                                         '2023-01-15',
...                                         '2023-02-01',
...                                         '2023-02-10',
...                                         '2023-02-15']))
>>> ser.resample('MS').sem()
2023-01-01    0.577350
2023-02-01    1.527525
Freq: MS, dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.sem.html, pandas.Series pandas.DatetimeIndex pandas.Series.resample
">>> df1 = pd.DataFrame([[1, 2], [3, 4]], columns=['A', 'B'])
>>> store = pd.HDFStore(""store.h5"", 'w')  
>>> store.put('data', df1, format='table')  
>>> df2 = pd.DataFrame([[5, 6], [7, 8]], columns=['A', 'B'])
>>> store.append('data', df2)  
>>> store.close()  
   A  B
0  1  2
1  3  4
0  5  6
1  7  8
",https://pandas.pydata.org/docs/reference/api/pandas.HDFStore.append.html, pandas.DataFrame pandas.HDFStore.put
">>> df = pd.read_feather(""path/to/file.feather"")  
",https://pandas.pydata.org/docs/reference/api/pandas.read_feather.html, pandas.read_feather
">>> df = pd.DataFrame([[1, 2, 3], [4, 5, 6]])
>>> df.to_feather(""file.feather"")  
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_feather.html, pandas.DataFrame pandas.DataFrame.to_feather
">>> df = pd.DataFrame(data={'col1': [1, 2], 'col2': [3, 4]})
>>> df.to_parquet('df.parquet.gzip',
...               compression='gzip')  
>>> pd.read_parquet('df.parquet.gzip')  
   col1  col2
0     1     3
1     2     4
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_parquet.html, pandas.DataFrame pandas.DataFrame.to_parquet pandas.read_parquet
">>> import io
>>> f = io.BytesIO()
>>> df.to_parquet(f)
>>> f.seek(0)
0
>>> content = f.read()
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_parquet.html, pandas.DataFrame.to_parquet
">>> df1 = pd.DataFrame([['a', 'b'], ['c', 'd']],
...                    index=['row 1', 'row 2'],
...                    columns=['col 1', 'col 2'])
>>> df1.to_excel(""output.xlsx"")  
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.to_excel.html, pandas.DataFrame pandas.DataFrame.to_excel
">>> df1.to_excel(""output.xlsx"",
...              sheet_name='Sheet_name_1')  
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.to_excel.html, pandas.DataFrame.to_excel
">>> df2 = df1.copy()
>>> with pd.ExcelWriter('output.xlsx') as writer:  
...     df1.to_excel(writer, sheet_name='Sheet_name_1')
...     df2.to_excel(writer, sheet_name='Sheet_name_2')
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.to_excel.html, pandas.DataFrame.copy pandas.ExcelWriter pandas.DataFrame.to_excel pandas.DataFrame.to_excel
">>> with pd.ExcelWriter('output.xlsx',
...                     mode='a') as writer:  
...     df1.to_excel(writer, sheet_name='Sheet_name_3')
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.to_excel.html, pandas.ExcelWriter pandas.DataFrame.to_excel
">>> df1.to_excel('output1.xlsx', engine='xlsxwriter')  
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.to_excel.html, pandas.DataFrame.to_excel
">>> df = pd.DataFrame([[1, 2], [3, 4]], columns=['A', 'B'])
>>> store = pd.HDFStore(""store.h5"", 'w')  
>>> store.put('data', df)  
>>> print(store.groups())  
>>> store.close()  
[/data (Group) ''
  children := ['axis0' (Array), 'axis1' (Array), 'block0_values' (Array),
  'block0_items' (Array)]]
",https://pandas.pydata.org/docs/reference/api/pandas.HDFStore.groups.html, pandas.DataFrame pandas.HDFStore.put pandas.HDFStore.groups
">>> lst = ['a', 'a', 'b', 'b']
>>> ser = pd.Series([1, 2, 3, 4], index=lst)
>>> ser
a    1
a    2
b    3
b    4
dtype: int64
>>> ser.groupby(level=0).shift(1)
a    NaN
a    1.0
b    NaN
b    3.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.shift.html, pandas.Series pandas.Series.groupby
">>> data = [[1, 2, 3], [1, 5, 6], [2, 5, 8], [2, 6, 9]]
>>> df = pd.DataFrame(data, columns=[""a"", ""b"", ""c""],
...                   index=[""tuna"", ""salmon"", ""catfish"", ""goldfish""])
>>> df
           a  b  c
    tuna   1  2  3
  salmon   1  5  6
 catfish   2  5  8
goldfish   2  6  9
>>> df.groupby(""a"").shift(1)
              b    c
    tuna    NaN  NaN
  salmon    2.0  3.0
 catfish    NaN  NaN
goldfish    5.0  8.0
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.shift.html, pandas.DataFrame pandas.DataFrame.groupby
">>> df = pd.DataFrame(
...     {
...         ""group"": [""a"", ""a"", ""a"", ""a"", ""a"", ""b"", ""b"", ""b"", ""b"", ""b""],
...         ""value"": [2, 4, 2, 3, 5, 1, 2, 4, 1, 5],
...     }
... )
>>> df
  group  value
0     a      2
1     a      4
2     a      2
3     a      3
4     a      5
5     b      1
6     b      2
7     b      4
8     b      1
9     b      5
>>> for method in ['average', 'min', 'max', 'dense', 'first']:
...     df[f'{method}_rank'] = df.groupby('group')['value'].rank(method)
>>> df
  group  value  average_rank  min_rank  max_rank  dense_rank  first_rank
0     a      2           1.5       1.0       2.0         1.0         1.0
1     a      4           4.0       4.0       4.0         3.0         4.0
2     a      2           1.5       1.0       2.0         1.0         2.0
3     a      3           3.0       3.0       3.0         2.0         3.0
4     a      5           5.0       5.0       5.0         4.0         5.0
5     b      1           1.5       1.0       2.0         1.0         1.0
6     b      2           3.0       3.0       3.0         2.0         3.0
7     b      4           4.0       4.0       4.0         3.0         4.0
8     b      1           1.5       1.0       2.0         1.0         2.0
9     b      5           5.0       5.0       5.0         4.0         5.0
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.rank.html, pandas.DataFrame pandas.DataFrame.groupby
">>> df = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar',
...                           'foo', 'bar'],
...                    'B' : ['one', 'one', 'two', 'three',
...                           'two', 'two'],
...                    'C' : [1, 5, 5, 2, 5, 5],
...                    'D' : [2.0, 5., 8., 1., 2., 9.]})
>>> grouped = df.groupby('A')[['C', 'D']]
>>> grouped.transform(lambda x: (x - x.mean()) / x.std())
        C         D
0 -1.154701 -0.577350
1  0.577350  0.000000
2  0.577350  1.154701
3 -1.154701 -1.000000
4  0.577350 -0.577350
5  0.577350  1.000000
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.transform.html, pandas.DataFrame pandas.DataFrame.groupby pandas.Series.mean pandas.Series.std
">>> grouped.transform(lambda x: x.max() - x.min())
    C    D
0  4.0  6.0
1  3.0  8.0
2  4.0  6.0
3  3.0  8.0
4  4.0  6.0
5  3.0  8.0
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.transform.html, pandas.Series.max pandas.Series.min
">>> grouped.transform(lambda x: x.astype(int).max())
C  D
0  5  8
1  5  9
2  5  8
3  5  9
4  5  8
5  5  9
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.transform.html, pandas.Series.astype
">>> df = pd.DataFrame(dict(A=[1, 1, 3], B=[5, None, 6], C=[1, 2, 3]))
>>> df.groupby(""A"").last()
     B  C
A
1  5.0  2
3  6.0  3
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.last.html, pandas.DataFrame pandas.DataFrame.groupby
">>> lst = ['a', 'a', 'b']
>>> ser = pd.Series([1, 2, 0], index=lst)
>>> ser
a    1
a    2
b    0
dtype: int64
>>> ser.groupby(level=0).all()
a     True
b    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.all.html, pandas.Series pandas.Series.groupby
">>> data = [[1, 0, 3], [1, 5, 6], [7, 8, 9]]
>>> df = pd.DataFrame(data, columns=[""a"", ""b"", ""c""],
...                   index=[""ostrich"", ""penguin"", ""parrot""])
>>> df
         a  b  c
ostrich  1  0  3
penguin  1  5  6
parrot   7  8  9
>>> df.groupby(by=[""a""]).all()
       b      c
a
1  False   True
7   True   True
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.all.html, pandas.DataFrame pandas.DataFrame.groupby
">>> lst = ['SPX', 'CAC', 'SPX', 'CAC', 'SPX', 'CAC', 'SPX', 'CAC',]
>>> ser = pd.Series([3.4, 9.0, 7.2, 5.2, 8.8, 9.4, 0.1, 0.5], index=lst)
>>> ser
SPX     3.4
CAC     9.0
SPX     7.2
CAC     5.2
SPX     8.8
CAC     9.4
SPX     0.1
CAC     0.5
dtype: float64
>>> ser.groupby(level=0).ohlc()
     open  high  low  close
CAC   9.0   9.4  0.5    0.5
SPX   3.4   8.8  0.1    0.1
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.ohlc.html, pandas.Series pandas.Series.groupby
">>> data = {2022: [1.2, 2.3, 8.9, 4.5, 4.4, 3, 2 , 1],
...         2023: [3.4, 9.0, 7.2, 5.2, 8.8, 9.4, 8.2, 1.0]}
>>> df = pd.DataFrame(data, index=['SPX', 'CAC', 'SPX', 'CAC',
...                   'SPX', 'CAC', 'SPX', 'CAC'])
>>> df
     2022  2023
SPX   1.2   3.4
CAC   2.3   9.0
SPX   8.9   7.2
CAC   4.5   5.2
SPX   4.4   8.8
CAC   3.0   9.4
SPX   2.0   8.2
CAC   1.0   1.0
>>> df.groupby(level=0).ohlc()
    2022                 2023
    open high  low close open high  low close
CAC  2.3  4.5  1.0   1.0  9.0  9.4  1.0   1.0
SPX  1.2  8.9  1.2   2.0  3.4  8.8  3.4   8.2
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.ohlc.html, pandas.DataFrame pandas.DataFrame.groupby
">>> ser = pd.Series([1, 3, 2, 4, 3, 5],
...                 index=pd.DatetimeIndex(['2023-01-01',
...                                         '2023-01-10',
...                                         '2023-01-15',
...                                         '2023-02-01',
...                                         '2023-02-10',
...                                         '2023-02-15']))
>>> ser.resample('MS').ohlc()
            open  high  low  close
2023-01-01     1     3    1      2
2023-02-01     4     5    3      5
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.ohlc.html, pandas.Series pandas.DatetimeIndex pandas.Series.resample
">>> df = pd.DataFrame([['a', 1], ['a', 2], ['b', 1], ['b', 2]],
...                   columns=['A', 'B'])
>>> df.groupby('A').tail(1)
   A  B
1  a  2
3  b  2
>>> df.groupby('A').tail(-1)
   A  B
1  a  2
3  b  2
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.tail.html, pandas.DataFrame pandas.DataFrame.groupby
">>> lst = ['a', 'a', 'a', 'b', 'b', 'b']
>>> ser = pd.Series([1, 2, 2, 4, 6, 6], index=lst)
>>> hist = ser.hist()
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.hist.html, pandas.Series pandas.Series.hist
">>> lst = ['a', 'a', 'a', 'b', 'b', 'b']
>>> ser = pd.Series([1, 2, 2, 4, 6, 6], index=lst)
>>> hist = ser.groupby(level=0).hist()
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.hist.html, pandas.Series pandas.Series.groupby
">>> lst = ['a', 'a', 'b']
>>> ser = pd.Series([1, 2, 3], index=lst)
>>> ser
a     1
a     2
b     3
dtype: int64
>>> ser.groupby(level=0).size()
a    2
b    1
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.size.html, pandas.Series pandas.Series.groupby
">>> data = [[1, 2, 3], [1, 5, 6], [7, 8, 9]]
>>> df = pd.DataFrame(data, columns=[""a"", ""b"", ""c""],
...                   index=[""owl"", ""toucan"", ""eagle""])
>>> df
        a  b  c
owl     1  2  3
toucan  1  5  6
eagle   7  8  9
>>> df.groupby(""a"").size()
a
1    2
7    1
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.size.html, pandas.DataFrame pandas.DataFrame.groupby
">>> ser = pd.Series([1, 2, 3], index=pd.DatetimeIndex(
...                 ['2023-01-01', '2023-01-15', '2023-02-01']))
>>> ser
2023-01-01    1
2023-01-15    2
2023-02-01    3
dtype: int64
>>> ser.resample('MS').size()
2023-01-01    2
2023-02-01    1
Freq: MS, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.size.html, pandas.Series pandas.DatetimeIndex pandas.Series.resample
">>> lst = ['a', 'a', 'a', 'b', 'b', 'b']
>>> ser = pd.Series([7, 2, 8, 4, 3, 3], index=lst)
>>> ser
a     7
a     2
a     8
b     4
b     3
b     3
dtype: int64
>>> ser.groupby(level=0).diff()
a    NaN
a   -5.0
a    6.0
b    NaN
b   -1.0
b    0.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.diff.html, pandas.Series pandas.Series.groupby
">>> data = {'a': [1, 3, 5, 7, 7, 8, 3], 'b': [1, 4, 8, 4, 4, 2, 1]}
>>> df = pd.DataFrame(data, index=['dog', 'dog', 'dog',
...                   'mouse', 'mouse', 'mouse', 'mouse'])
>>> df
         a  b
  dog    1  1
  dog    3  4
  dog    5  8
mouse    7  4
mouse    7  4
mouse    8  2
mouse    3  1
>>> df.groupby(level=0).diff()
         a    b
  dog  NaN  NaN
  dog  2.0  3.0
  dog  2.0  4.0
mouse  NaN  NaN
mouse  0.0  0.0
mouse  1.0 -2.0
mouse -5.0 -1.0
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.diff.html, pandas.DataFrame pandas.DataFrame.groupby
">>> lst = ['a', 'a', 'b']
>>> ser = pd.Series([1, 2, 3], index=lst)
>>> ser
a    1
a    2
b    3
dtype: int64
>>> ser.groupby(level=0).get_group(""a"")
a    1
a    2
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.get_group.html, pandas.Series pandas.Series.groupby
">>> data = [[1, 2, 3], [1, 5, 6], [7, 8, 9]]
>>> df = pd.DataFrame(data, columns=[""a"", ""b"", ""c""],
...                   index=[""owl"", ""toucan"", ""eagle""])
>>> df
        a  b  c
owl     1  2  3
toucan  1  5  6
eagle   7  8  9
>>> df.groupby(by=[""a""]).get_group((1,))
        a  b  c
owl     1  2  3
toucan  1  5  6
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.get_group.html, pandas.DataFrame pandas.DataFrame.groupby
">>> ser = pd.Series([1, 2, 3, 4], index=pd.DatetimeIndex(
...                 ['2023-01-01', '2023-01-15', '2023-02-01', '2023-02-15']))
>>> ser
2023-01-01    1
2023-01-15    2
2023-02-01    3
2023-02-15    4
dtype: int64
>>> ser.resample('MS').get_group('2023-01-01')
2023-01-01    1
2023-01-15    2
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.get_group.html, pandas.Series pandas.DatetimeIndex pandas.Series.resample
">>> lst = ['a', 'a', 'b']
>>> ser = pd.Series([1, 2, 3], index=lst)
>>> ser
a    1
a    2
b    3
dtype: int64
>>> ser.groupby(level=0).groups
{'a': ['a', 'a'], 'b': ['b']}
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.groups.html, pandas.Series pandas.Series.groupby
">>> data = [[1, 2, 3], [1, 5, 6], [7, 8, 9]]
>>> df = pd.DataFrame(data, columns=[""a"", ""b"", ""c""])
>>> df
   a  b  c
0  1  2  3
1  1  5  6
2  7  8  9
>>> df.groupby(by=[""a""]).groups
{1: [0, 1], 7: [2]}
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.groups.html, pandas.DataFrame pandas.DataFrame.groupby
">>> ser = pd.Series([1, 2, 3, 4], index=pd.DatetimeIndex(
...                 ['2023-01-01', '2023-01-15', '2023-02-01', '2023-02-15']))
>>> ser
2023-01-01    1
2023-01-15    2
2023-02-01    3
2023-02-15    4
dtype: int64
>>> ser.resample('MS').groups
{Timestamp('2023-01-01 00:00:00'): 2, Timestamp('2023-02-01 00:00:00'): 4}
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.groups.html, pandas.Series pandas.DatetimeIndex pandas.Series.resample
">>> lst = ['a', 'a', 'b']
>>> ser = pd.Series([6, 2, 0], index=lst)
>>> ser
a    6
a    2
b    0
dtype: int64
>>> ser.groupby(level=0).cumprod()
a    6
a   12
b    0
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.cumprod.html, pandas.Series pandas.Series.groupby
">>> data = [[1, 8, 2], [1, 2, 5], [2, 6, 9]]
>>> df = pd.DataFrame(data, columns=[""a"", ""b"", ""c""],
...                   index=[""cow"", ""horse"", ""bull""])
>>> df
        a   b   c
cow     1   8   2
horse   1   2   5
bull    2   6   9
>>> df.groupby(""a"").groups
{1: ['cow', 'horse'], 2: ['bull']}
>>> df.groupby(""a"").cumprod()
        b   c
cow     8   2
horse  16  10
bull    6   9
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.cumprod.html, pandas.DataFrame pandas.DataFrame.groupby
">>> lst = ['a', 'a', 'a', 'b', 'b', 'b']
>>> ser = pd.Series([7, 2, 8, 4, 3, 3], index=lst)
>>> ser
a     7
a     2
a     8
b     4
b     3
b     3
dtype: int64
>>> ser.groupby(level=0).std()
a    3.21455
b    0.57735
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.std.html, pandas.Series pandas.Series.groupby
">>> data = {'a': [1, 3, 5, 7, 7, 8, 3], 'b': [1, 4, 8, 4, 4, 2, 1]}
>>> df = pd.DataFrame(data, index=['dog', 'dog', 'dog',
...                   'mouse', 'mouse', 'mouse', 'mouse'])
>>> df
         a  b
  dog    1  1
  dog    3  4
  dog    5  8
mouse    7  4
mouse    7  4
mouse    8  2
mouse    3  1
>>> df.groupby(level=0).std()
              a         b
dog    2.000000  3.511885
mouse  2.217356  1.500000
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.std.html, pandas.DataFrame pandas.DataFrame.groupby
">>> lst = ['a', 'a', 'b', 'b']
>>> ser = pd.Series([1, 2, 3, 4], index=lst)
>>> ser
a    1
a    2
b    3
b    4
dtype: int64
>>> ser.groupby(level=0).pct_change()
a         NaN
a    1.000000
b         NaN
b    0.333333
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.pct_change.html, pandas.Series pandas.Series.groupby
">>> data = [[1, 2, 3], [1, 5, 6], [2, 5, 8], [2, 6, 9]]
>>> df = pd.DataFrame(data, columns=[""a"", ""b"", ""c""],
...                   index=[""tuna"", ""salmon"", ""catfish"", ""goldfish""])
>>> df
           a  b  c
    tuna   1  2  3
  salmon   1  5  6
 catfish   2  5  8
goldfish   2  6  9
>>> df.groupby(""a"").pct_change()
            b  c
    tuna    NaN    NaN
  salmon    1.5  1.000
 catfish    NaN    NaN
goldfish    0.2  0.125
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.pct_change.html, pandas.DataFrame pandas.DataFrame.groupby
">>> lst = ['a', 'a', 'b', 'b']
>>> ser = pd.Series([1, 2, 3, 4], index=lst)
>>> ser
a    1
a    2
b    3
b    4
dtype: int64
>>> ser.groupby(level=0).shift(1)
a    NaN
a    1.0
b    NaN
b    3.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.shift.html, pandas.Series pandas.Series.groupby
">>> data = [[1, 2, 3], [1, 5, 6], [2, 5, 8], [2, 6, 9]]
>>> df = pd.DataFrame(data, columns=[""a"", ""b"", ""c""],
...                   index=[""tuna"", ""salmon"", ""catfish"", ""goldfish""])
>>> df
           a  b  c
    tuna   1  2  3
  salmon   1  5  6
 catfish   2  5  8
goldfish   2  6  9
>>> df.groupby(""a"").shift(1)
              b    c
    tuna    NaN  NaN
  salmon    2.0  3.0
 catfish    NaN  NaN
goldfish    5.0  8.0
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.shift.html, pandas.DataFrame pandas.DataFrame.groupby
">>> lst = ['a', 'a', 'b', 'b']
>>> ser = pd.Series([1, 2, 3, 4], index=lst)
>>> ser
a    1
a    2
b    3
b    4
dtype: int64
>>> ser.groupby(level=0).sum()
a    3
b    7
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.sum.html, pandas.Series pandas.Series.groupby
">>> data = [[1, 8, 2], [1, 2, 5], [2, 5, 8], [2, 6, 9]]
>>> df = pd.DataFrame(data, columns=[""a"", ""b"", ""c""],
...                   index=[""tiger"", ""leopard"", ""cheetah"", ""lion""])
>>> df
          a  b  c
  tiger   1  8  2
leopard   1  2  5
cheetah   2  5  8
   lion   2  6  9
>>> df.groupby(""a"").sum()
     b   c
a
1   10   7
2   11  17
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.sum.html, pandas.DataFrame pandas.DataFrame.groupby
">>> df = pd.DataFrame(
...     {
...         ""key"": [0, 0, 1, 1, 1],
...         ""A"": [np.nan, 2, np.nan, 3, np.nan],
...         ""B"": [2, 3, np.nan, np.nan, np.nan],
...         ""C"": [np.nan, np.nan, 2, np.nan, np.nan],
...     }
... )
>>> df
   key    A    B   C
0    0  NaN  2.0 NaN
1    0  2.0  3.0 NaN
2    1  NaN  NaN 2.0
3    1  3.0  NaN NaN
4    1  NaN  NaN NaN
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.fillna.html, pandas.DataFrame
">>> df.groupby(""key"").fillna(method=""ffill"")
     A    B   C
0  NaN  2.0 NaN
1  2.0  3.0 NaN
2  NaN  NaN 2.0
3  3.0  NaN 2.0
4  3.0  NaN 2.0
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.fillna.html, pandas.DataFrame.groupby
">>> df.groupby(""key"").fillna(method=""bfill"")
     A    B   C
0  2.0  2.0 NaN
1  2.0  3.0 NaN
2  3.0  NaN 2.0
3  3.0  NaN NaN
4  NaN  NaN NaN
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.fillna.html, pandas.DataFrame.groupby
">>> df.groupby(""key"").fillna(method=""ffill"", limit=1)
     A    B    C
0  NaN  2.0  NaN
1  2.0  3.0  NaN
2  NaN  NaN  2.0
3  3.0  NaN  2.0
4  3.0  NaN  NaN
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.fillna.html, pandas.DataFrame.groupby
">>> lst = ['a', 'a', 'a', 'b', 'b', 'b']
>>> ser = pd.Series([1, 6, 2, 3, 0, 4], index=lst)
>>> ser
a    1
a    6
a    2
b    3
b    0
b    4
dtype: int64
>>> ser.groupby(level=0).cummin()
a    1
a    1
a    1
b    3
b    0
b    0
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.cummin.html, pandas.Series pandas.Series.groupby
">>> data = [[1, 0, 2], [1, 1, 5], [6, 6, 9]]
>>> df = pd.DataFrame(data, columns=[""a"", ""b"", ""c""],
...                   index=[""snake"", ""rabbit"", ""turtle""])
>>> df
        a   b   c
snake   1   0   2
rabbit  1   1   5
turtle  6   6   9
>>> df.groupby(""a"").groups
{1: ['snake', 'rabbit'], 6: ['turtle']}
>>> df.groupby(""a"").cummin()
        b   c
snake   0   2
rabbit  0   2
turtle  6   9
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.cummin.html, pandas.DataFrame pandas.DataFrame.groupby
">>> lst = ['a', 'a', 'b']
>>> ser = pd.Series([1, 2, 3], index=lst)
>>> ser
a    1
a    2
b    3
dtype: int64
>>> for x, y in ser.groupby(level=0):
...     print(f'{x}\n{y}\n')
a
a    1
a    2
dtype: int64
b
b    3
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.__iter__.html, pandas.Series pandas.Series.groupby
">>> data = [[1, 2, 3], [1, 5, 6], [7, 8, 9]]
>>> df = pd.DataFrame(data, columns=[""a"", ""b"", ""c""])
>>> df
   a  b  c
0  1  2  3
1  1  5  6
2  7  8  9
>>> for x, y in df.groupby(by=[""a""]):
...     print(f'{x}\n{y}\n')
(1,)
   a  b  c
0  1  2  3
1  1  5  6
(7,)
   a  b  c
2  7  8  9
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.__iter__.html, pandas.DataFrame pandas.DataFrame.groupby
">>> ser = pd.Series([1, 2, 3, 4], index=pd.DatetimeIndex(
...                 ['2023-01-01', '2023-01-15', '2023-02-01', '2023-02-15']))
>>> ser
2023-01-01    1
2023-01-15    2
2023-02-01    3
2023-02-15    4
dtype: int64
>>> for x, y in ser.resample('MS'):
...     print(f'{x}\n{y}\n')
2023-01-01 00:00:00
2023-01-01    1
2023-01-15    2
dtype: int64
2023-02-01 00:00:00
2023-02-01    3
2023-02-15    4
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.__iter__.html, pandas.Series pandas.DatetimeIndex pandas.Series.resample
">>> ser = pd.Series([390.0, 350.0, 30.0, 20.0],
...                 index=[""Falcon"", ""Falcon"", ""Parrot"", ""Parrot""],
...                 name=""Max Speed"")
>>> grouped = ser.groupby([1, 1, 2, 2])
>>> grouped.transform(lambda x: (x - x.mean()) / x.std())
    Falcon    0.707107
    Falcon   -0.707107
    Parrot    0.707107
    Parrot   -0.707107
    Name: Max Speed, dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.transform.html, pandas.Series pandas.Series.groupby pandas.Series.mean pandas.Series.std
">>> grouped.transform(lambda x: x.max() - x.min())
Falcon    40.0
Falcon    40.0
Parrot    10.0
Parrot    10.0
Name: Max Speed, dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.transform.html, pandas.Series.max pandas.Series.min
">>> grouped.transform(lambda x: x.astype(int).max())
Falcon    390
Falcon    390
Parrot     30
Parrot     30
Name: Max Speed, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.transform.html, pandas.Series.astype
">>> lst = ['a', 'a', 'b', 'b']
>>> ser = pd.Series([1, 2, 3, 4], index=lst)
>>> ser
a    1
a    2
b    3
b    4
dtype: int64
>>> ser.groupby(level=0).min()
a    1
b    3
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.min.html, pandas.Series pandas.Series.groupby
">>> data = [[1, 8, 2], [1, 2, 5], [2, 5, 8], [2, 6, 9]]
>>> df = pd.DataFrame(data, columns=[""a"", ""b"", ""c""],
...                   index=[""tiger"", ""leopard"", ""cheetah"", ""lion""])
>>> df
          a  b  c
  tiger   1  8  2
leopard   1  2  5
cheetah   2  5  8
   lion   2  6  9
>>> df.groupby(""a"").min()
    b  c
a
1   2  2
2   5  8
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.min.html, pandas.DataFrame pandas.DataFrame.groupby
">>> df = pd.DataFrame([('falcon', 'bird', 389.0),
...                    ('parrot', 'bird', 24.0),
...                    ('lion', 'mammal', 80.5),
...                    ('monkey', 'mammal', np.nan),
...                    ('rabbit', 'mammal', 15.0)],
...                   columns=['name', 'class', 'max_speed'],
...                   index=[4, 3, 2, 1, 0])
>>> df
     name   class  max_speed
4  falcon    bird      389.0
3  parrot    bird       24.0
2    lion  mammal       80.5
1  monkey  mammal        NaN
0  rabbit  mammal       15.0
>>> gb = df[""name""].groupby([1, 1, 2, 2, 2])
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.take.html, pandas.DataFrame
">>> df = pd.DataFrame({'A': [1, 1, 2, 1, 2],
...                    'B': [np.nan, 2, 3, 4, 5],
...                    'C': [1, 2, 1, 1, 2]}, columns=['A', 'B', 'C'])
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.mean.html, pandas.DataFrame
">>> df.groupby('A').mean()
     B         C
A
1  3.0  1.333333
2  4.0  1.500000
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.mean.html, pandas.DataFrame.groupby
">>> df.groupby(['A', 'B']).mean()
         C
A B
1 2.0  2.0
  4.0  1.0
2 3.0  1.0
  5.0  2.0
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.mean.html, pandas.DataFrame.groupby
">>> df.groupby('A')['B'].mean()
A
1    3.0
2    4.0
Name: B, dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.mean.html, pandas.DataFrame.groupby
">>> s = pd.Series([1, 2, 3])
>>> s.describe()
count    3.0
mean     2.0
std      1.0
min      1.0
25%      1.5
50%      2.0
75%      2.5
max      3.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.describe.html, pandas.Series pandas.Series.describe
">>> s = pd.Series(['a', 'a', 'b', 'c'])
>>> s.describe()
count     4
unique    3
top       a
freq      2
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.describe.html, pandas.Series pandas.Series.describe
">>> s = pd.Series([
...     np.datetime64(""2000-01-01""),
...     np.datetime64(""2010-01-01""),
...     np.datetime64(""2010-01-01"")
... ])
>>> s.describe()
count                      3
mean     2006-09-01 08:00:00
min      2000-01-01 00:00:00
25%      2004-12-31 12:00:00
50%      2010-01-01 00:00:00
75%      2010-01-01 00:00:00
max      2010-01-01 00:00:00
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.describe.html, pandas.Series pandas.Series.describe
">>> df = pd.DataFrame({'categorical': pd.Categorical(['d', 'e', 'f']),
...                    'numeric': [1, 2, 3],
...                    'object': ['a', 'b', 'c']
...                    })
>>> df.describe()
       numeric
count      3.0
mean       2.0
std        1.0
min        1.0
25%        1.5
50%        2.0
75%        2.5
max        3.0
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.describe.html, pandas.DataFrame pandas.Categorical pandas.DataFrame.describe
">>> df.describe(include='all')  
       categorical  numeric object
count            3      3.0      3
unique           3      NaN      3
top              f      NaN      a
freq             1      NaN      1
mean           NaN      2.0    NaN
std            NaN      1.0    NaN
min            NaN      1.0    NaN
25%            NaN      1.5    NaN
50%            NaN      2.0    NaN
75%            NaN      2.5    NaN
max            NaN      3.0    NaN
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.describe.html, pandas.DataFrame.describe
">>> df.describe(include=[np.number])
       numeric
count      3.0
mean       2.0
std        1.0
min        1.0
25%        1.5
50%        2.0
75%        2.5
max        3.0
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.describe.html, pandas.DataFrame.describe
">>> df.describe(include=[object])  
       object
count       3
unique      3
top         a
freq        1
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.describe.html, pandas.DataFrame.describe
">>> df.describe(include=['category'])
       categorical
count            3
unique           3
top              d
freq             1
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.describe.html, pandas.DataFrame.describe
">>> df.describe(exclude=[np.number])  
       categorical object
count            3      3
unique           3      3
top              f      a
freq             1      1
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.describe.html, pandas.DataFrame.describe
">>> df.describe(exclude=[object])  
       categorical  numeric
count            3      3.0
unique           3      NaN
top              f      NaN
freq             1      NaN
mean           NaN      2.0
std            NaN      1.0
min            NaN      1.0
25%            NaN      1.5
50%            NaN      2.0
75%            NaN      2.5
max            NaN      3.0
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.describe.html, pandas.DataFrame.describe
">>> arrays = [['falcon', 'parrot', 'cockatoo', 'kiwi',
...            'lion', 'monkey', 'rabbit'],
...           ['bird', 'bird', 'bird', 'bird',
...            'mammal', 'mammal', 'mammal']]
>>> index = pd.MultiIndex.from_arrays(arrays, names=('name', 'class'))
>>> df = pd.DataFrame({'max_speed': [389.0, 24.0, 70.0, np.nan,
...                                  80.5, 21.5, 15.0]},
...                   index=index)
>>> df
                max_speed
name     class
falcon   bird        389.0
parrot   bird         24.0
cockatoo bird         70.0
kiwi     bird          NaN
lion     mammal       80.5
monkey   mammal       21.5
rabbit   mammal       15.0
>>> gb = df.groupby([""class""])
>>> gb.skew()
        max_speed
class
bird     1.628296
mammal   1.669046
>>> gb.skew(skipna=False)
        max_speed
class
bird          NaN
mammal   1.669046
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.skew.html, pandas.MultiIndex.from_arrays pandas.DataFrame pandas.DataFrame.groupby
">>> df = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar',
...                           'foo', 'bar'],
...                    'B' : [1, 2, 3, 4, 5, 6],
...                    'C' : [2.0, 5., 8., 1., 2., 9.]})
>>> grouped = df.groupby('A')
>>> df.groupby('A').B.filter(lambda x: x.mean() > 3.)
1    2
3    4
5    6
Name: B, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.filter.html, pandas.DataFrame pandas.DataFrame.groupby pandas.Series.mean
">>> df = pd.DataFrame({'A': [1, 1, 2, 2],
...                    'B': [1, 2, 3, 4],
...                    'C': [0.362, 0.227, 1.267, -0.562]})
>>> df
      A  B      C
0     1  1  0.362
1     1  2  0.227
2     2  3  1.267
3     2  4 -0.562
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.rolling.html, pandas.DataFrame
">>> df.groupby('A').rolling(2).sum()
    B      C
A
1 0  NaN    NaN
  1  3.0  0.589
2 2  NaN    NaN
  3  7.0  0.705
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.rolling.html, pandas.DataFrame.groupby
">>> df.groupby('A').rolling(2, min_periods=1).sum()
    B      C
A
1 0  1.0  0.362
  1  3.0  0.589
2 2  3.0  1.267
  3  7.0  0.705
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.rolling.html, pandas.DataFrame.groupby
">>> df.groupby('A').rolling(2, on='B').sum()
    B      C
A
1 0  1    NaN
  1  2  0.589
2 2  3    NaN
  3  4  0.705
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.rolling.html, pandas.DataFrame.groupby
">>> index = [""a"", ""b"", ""c"", ""d"", ""e""]
>>> columns = [""one"", ""two"", ""three"", ""four""]
>>> df1 = pd.DataFrame(np.arange(20).reshape(5, 4), index=index, columns=columns)
>>> df2 = pd.DataFrame(np.arange(16).reshape(4, 4), index=index[:4], columns=columns)
>>> df1.corrwith(df2)
one      1.0
two      1.0
three    1.0
four     1.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.corrwith.html, pandas.DataFrame pandas.DataFrame.corrwith
">>> df2.corrwith(df1, axis=1)
a    1.0
b    1.0
c    1.0
d    1.0
e    NaN
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.corrwith.html, pandas.DataFrame.corrwith
">>> df = pd.DataFrame({'A': [1, 1, 2, 1, 2],
...                    'B': [np.nan, 2, 3, 4, 5],
...                    'C': [1, 2, 1, 1, 2]}, columns=['A', 'B', 'C'])
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.mean.html, pandas.DataFrame
">>> df.groupby('A').mean()
     B         C
A
1  3.0  1.333333
2  4.0  1.500000
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.mean.html, pandas.DataFrame.groupby
">>> df.groupby(['A', 'B']).mean()
         C
A B
1 2.0  2.0
  4.0  1.0
2 3.0  1.0
  5.0  2.0
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.mean.html, pandas.DataFrame.groupby
">>> df.groupby('A')['B'].mean()
A
1    3.0
2    4.0
Name: B, dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.mean.html, pandas.DataFrame.groupby
"self.apply(lambda x: pd.Series(np.arange(len(x)), x.index))
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.cumcount.html, pandas.Series
">>> df = pd.DataFrame([['a'], ['a'], ['a'], ['b'], ['b'], ['a']],
...                   columns=['A'])
>>> df
   A
0  a
1  a
2  a
3  b
4  b
5  a
>>> df.groupby('A').cumcount()
0    0
1    1
2    2
3    0
4    1
5    3
dtype: int64
>>> df.groupby('A').cumcount(ascending=False)
0    3
1    2
2    1
3    1
4    0
5    0
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.cumcount.html, pandas.DataFrame pandas.DataFrame.groupby
">>> df = pd.DataFrame(
...     {
...         ""group"": [""a"", ""a"", ""a"", ""a"", ""a"", ""b"", ""b"", ""b"", ""b"", ""b""],
...         ""value"": [2, 4, 2, 3, 5, 1, 2, 4, 1, 5],
...     }
... )
>>> df
  group  value
0     a      2
1     a      4
2     a      2
3     a      3
4     a      5
5     b      1
6     b      2
7     b      4
8     b      1
9     b      5
>>> for method in ['average', 'min', 'max', 'dense', 'first']:
...     df[f'{method}_rank'] = df.groupby('group')['value'].rank(method)
>>> df
  group  value  average_rank  min_rank  max_rank  dense_rank  first_rank
0     a      2           1.5       1.0       2.0         1.0         1.0
1     a      4           4.0       4.0       4.0         3.0         4.0
2     a      2           1.5       1.0       2.0         1.0         2.0
3     a      3           3.0       3.0       3.0         2.0         3.0
4     a      5           5.0       5.0       5.0         4.0         5.0
5     b      1           1.5       1.0       2.0         1.0         1.0
6     b      2           3.0       3.0       3.0         2.0         3.0
7     b      4           4.0       4.0       4.0         3.0         4.0
8     b      1           1.5       1.0       2.0         1.0         2.0
9     b      5           5.0       5.0       5.0         4.0         5.0
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.rank.html, pandas.DataFrame pandas.DataFrame.groupby
">>> def histogram_intersection(a, b):
...     v = np.minimum(a, b).sum().round(decimals=1)
...     return v
>>> s1 = pd.Series([.2, .0, .6, .2])
>>> s2 = pd.Series([.3, .6, .0, .1])
>>> s1.corr(s2, method=histogram_intersection)
0.3
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.corr.html, pandas.Series pandas.Series.corr
">>> s1 = pd.Series([1, 2, 3], index=[0, 1, 2])
>>> s2 = pd.Series([1, 2, 3], index=[2, 1, 0])
>>> s1.corr(s2)
-1.0
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.corr.html, pandas.Series pandas.Series.corr
">>> lst = ['a', 'a', 'a', 'b', 'b', 'b']
>>> ser = pd.Series([1, 6, 2, 3, 1, 4], index=lst)
>>> ser
a    1
a    6
a    2
b    3
b    1
b    4
dtype: int64
>>> ser.groupby(level=0).cummax()
a    1
a    6
a    6
b    3
b    3
b    4
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.cummax.html, pandas.Series pandas.Series.groupby
">>> data = [[1, 8, 2], [1, 1, 0], [2, 6, 9]]
>>> df = pd.DataFrame(data, columns=[""a"", ""b"", ""c""],
...                   index=[""cow"", ""horse"", ""bull""])
>>> df
        a   b   c
cow     1   8   2
horse   1   1   0
bull    2   6   9
>>> df.groupby(""a"").groups
{1: ['cow', 'horse'], 2: ['bull']}
>>> df.groupby(""a"").cummax()
        b   c
cow     8   2
horse   8   2
bull    6   9
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.cummax.html, pandas.DataFrame pandas.DataFrame.groupby
">>> df = pd.DataFrame({
...     'gender': ['male', 'male', 'female', 'male', 'female', 'male'],
...     'education': ['low', 'medium', 'high', 'low', 'high', 'low'],
...     'country': ['US', 'FR', 'US', 'FR', 'FR', 'FR']
... })
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.value_counts.html, pandas.DataFrame
">>> df.groupby('gender').value_counts()
gender  education  country
female  high       FR         1
                   US         1
male    low        FR         2
                   US         1
        medium     FR         1
Name: count, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.value_counts.html, pandas.DataFrame.groupby
">>> df.groupby('gender').value_counts(ascending=True)
gender  education  country
female  high       FR         1
                   US         1
male    low        US         1
        medium     FR         1
        low        FR         2
Name: count, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.value_counts.html, pandas.DataFrame.groupby
">>> df.groupby('gender').value_counts(normalize=True)
gender  education  country
female  high       FR         0.50
                   US         0.50
male    low        FR         0.50
                   US         0.25
        medium     FR         0.25
Name: proportion, dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.value_counts.html, pandas.DataFrame.groupby
">>> df.groupby('gender', as_index=False).value_counts()
   gender education country  count
0  female      high      FR      1
1  female      high      US      1
2    male       low      FR      2
3    male       low      US      1
4    male    medium      FR      1
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.value_counts.html, pandas.DataFrame.groupby
">>> df.groupby('gender', as_index=False).value_counts(normalize=True)
   gender education country  proportion
0  female      high      FR        0.50
1  female      high      US        0.50
2    male       low      FR        0.50
3    male       low      US        0.25
4    male    medium      FR        0.25
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.value_counts.html, pandas.DataFrame.groupby
">>> df = pd.DataFrame({'id': ['spam', 'egg', 'egg', 'spam',
...                           'ham', 'ham'],
...                    'value1': [1, 5, 5, 2, 5, 5],
...                    'value2': list('abbaxy')})
>>> df
     id  value1 value2
0  spam       1      a
1   egg       5      b
2   egg       5      b
3  spam       2      a
4   ham       5      x
5   ham       5      y
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.nunique.html, pandas.DataFrame
">>> df.groupby('id').nunique()
      value1  value2
id
egg        1       1
ham        1       2
spam       2       1
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.nunique.html, pandas.DataFrame.groupby
">>> df.groupby('id').filter(lambda g: (g.nunique() > 1).any())
     id  value1 value2
0  spam       1      a
3  spam       2      a
4   ham       5      x
5   ham       5      y
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.nunique.html, pandas.DataFrame.groupby
">>> lst = ['a', 'a', 'b', 'b']
>>> ser = pd.Series([1, 2, 3, 4], index=lst)
>>> ser
a    1
a    2
b    3
b    4
dtype: int64
>>> ser.groupby(level=0).max()
a    2
b    4
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.max.html, pandas.Series pandas.Series.groupby
">>> data = [[1, 8, 2], [1, 2, 5], [2, 5, 8], [2, 6, 9]]
>>> df = pd.DataFrame(data, columns=[""a"", ""b"", ""c""],
...                   index=[""tiger"", ""leopard"", ""cheetah"", ""lion""])
>>> df
          a  b  c
  tiger   1  8  2
leopard   1  2  5
cheetah   2  5  8
   lion   2  6  9
>>> df.groupby(""a"").max()
    b  c
a
1   8  5
2   6  9
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.max.html, pandas.DataFrame pandas.DataFrame.groupby
">>> df = pd.DataFrame([
...     ['a', 1], ['a', 2], ['a', 3],
...     ['b', 1], ['b', 3], ['b', 5]
... ], columns=['key', 'val'])
>>> df.groupby('key').quantile()
    val
key
a    2.0
b    3.0
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.quantile.html, pandas.DataFrame pandas.DataFrame.groupby
">>> df = pd.DataFrame([[1, 2], [1, 4], [5, 6]],
...                   columns=['A', 'B'])
>>> df.groupby('A').head(1)
   A  B
0  1  2
2  5  6
>>> df.groupby('A').head(-1)
   A  B
0  1  2
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.head.html, pandas.DataFrame pandas.DataFrame.groupby
">>> s = pd.Series(data=[1, None, 4, 1],
...               index=['A', 'B', 'C', 'D'])
>>> s
A    1.0
B    NaN
C    4.0
D    1.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.idxmin.html, pandas.Series
">>> s.idxmin()
'A'
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.idxmin.html, pandas.Series.idxmin
">>> s.idxmin(skipna=False)
nan
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.idxmin.html, pandas.Series.idxmin
">>> lst = ['a', 'a', 'b', 'b']
>>> ser = pd.Series([5, 10, 8, 14], index=lst)
>>> ser
a     5
a    10
b     8
b    14
dtype: int64
>>> ser.groupby(level=0).sem()
a    2.5
b    3.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.sem.html, pandas.Series pandas.Series.groupby
">>> data = [[1, 12, 11], [1, 15, 2], [2, 5, 8], [2, 6, 12]]
>>> df = pd.DataFrame(data, columns=[""a"", ""b"", ""c""],
...                   index=[""tuna"", ""salmon"", ""catfish"", ""goldfish""])
>>> df
           a   b   c
    tuna   1  12  11
  salmon   1  15   2
 catfish   2   5   8
goldfish   2   6  12
>>> df.groupby(""a"").sem()
      b  c
a
1    1.5  4.5
2    0.5  2.0
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.sem.html, pandas.DataFrame pandas.DataFrame.groupby
">>> ser = pd.Series([1, 3, 2, 4, 3, 8],
...                 index=pd.DatetimeIndex(['2023-01-01',
...                                         '2023-01-10',
...                                         '2023-01-15',
...                                         '2023-02-01',
...                                         '2023-02-10',
...                                         '2023-02-15']))
>>> ser.resample('MS').sem()
2023-01-01    0.577350
2023-02-01    1.527525
Freq: MS, dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.sem.html, pandas.Series pandas.DatetimeIndex pandas.Series.resample
">>> lst = ['a', 'a', 'b']
>>> ser = pd.Series([1, 2, 3], index=lst)
>>> ser
a    1
a    2
b    3
dtype: int64
>>> ser.groupby(level=0).indices
{'a': array([0, 1]), 'b': array([2])}
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.indices.html, pandas.Series pandas.Series.groupby pandas.array
">>> data = [[1, 2, 3], [1, 5, 6], [7, 8, 9]]
>>> df = pd.DataFrame(data, columns=[""a"", ""b"", ""c""],
...                   index=[""owl"", ""toucan"", ""eagle""])
>>> df
        a  b  c
owl     1  2  3
toucan  1  5  6
eagle   7  8  9
>>> df.groupby(by=[""a""]).indices
{1: array([0, 1]), 7: array([2])}
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.indices.html, pandas.DataFrame pandas.DataFrame.groupby pandas.array
">>> ser = pd.Series([1, 2, 3, 4], index=pd.DatetimeIndex(
...                 ['2023-01-01', '2023-01-15', '2023-02-01', '2023-02-15']))
>>> ser
2023-01-01    1
2023-01-15    2
2023-02-01    3
2023-02-15    4
dtype: int64
>>> ser.resample('MS').indices
defaultdict(, {Timestamp('2023-01-01 00:00:00'): [0, 1],
Timestamp('2023-02-01 00:00:00'): [2, 3]})
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.indices.html, pandas.Series pandas.DatetimeIndex pandas.Series.resample
">>> index = ['Falcon', 'Falcon', 'Parrot', 'Parrot', 'Parrot']
>>> s = pd.Series([None, 1, None, None, 3], index=index)
>>> s
Falcon    NaN
Falcon    1.0
Parrot    NaN
Parrot    NaN
Parrot    3.0
dtype: float64
>>> s.groupby(level=0).bfill()
Falcon    1.0
Falcon    1.0
Parrot    3.0
Parrot    3.0
Parrot    3.0
dtype: float64
>>> s.groupby(level=0).bfill(limit=1)
Falcon    1.0
Falcon    1.0
Parrot    NaN
Parrot    3.0
Parrot    3.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.bfill.html, pandas.Series pandas.Series.groupby
">>> df = pd.DataFrame({'A': [1, None, None, None, 4],
...                    'B': [None, None, 5, None, 7]}, index=index)
>>> df
          A         B
Falcon  1.0       NaN
Falcon  NaN       NaN
Parrot  NaN       5.0
Parrot  NaN       NaN
Parrot  4.0       7.0
>>> df.groupby(level=0).bfill()
          A         B
Falcon  1.0       NaN
Falcon  NaN       NaN
Parrot  4.0       5.0
Parrot  4.0       7.0
Parrot  4.0       7.0
>>> df.groupby(level=0).bfill(limit=1)
          A         B
Falcon  1.0       NaN
Falcon  NaN       NaN
Parrot  NaN       5.0
Parrot  4.0       7.0
Parrot  4.0       7.0
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.bfill.html, pandas.DataFrame pandas.DataFrame.groupby
">>> s1 = pd.Series([0.90010907, 0.13484424, 0.62036035])
>>> s2 = pd.Series([0.12528585, 0.26962463, 0.51111198])
>>> s1.cov(s2)
-0.01685762652715874
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.cov.html, pandas.Series pandas.Series.cov
">>> h = lambda x, arg2, arg3: x + 1 - arg2 * arg3
>>> g = lambda x, arg1: x * 5 / arg1
>>> f = lambda x: x ** 4
>>> df = pd.DataFrame([[""a"", 4], [""b"", 5]], columns=[""group"", ""value""])
>>> h(g(f(df.groupby('group')), arg1=1), arg2=2, arg3=3)  
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.pipe.html, pandas.DataFrame pandas.DataFrame.groupby
">>> (df.groupby('group')
...    .pipe(f)
...    .pipe(g, arg1=1)
...    .pipe(h, arg2=2, arg3=3))  
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.pipe.html, pandas.DataFrame.groupby
">>> df = pd.DataFrame({'A': 'a b a b'.split(), 'B': [1, 2, 3, 4]})
>>> df
   A  B
0  a  1
1  b  2
2  a  3
3  b  4
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.pipe.html, pandas.DataFrame pandas.Series.str.split
">>> df.groupby('A').pipe(lambda x: x.max() - x.min())
   B
A
a  2
b  2
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.pipe.html, pandas.DataFrame.groupby pandas.Series.max pandas.Series.min
">>> lst = ['a', 'a', 'b']
>>> ser = pd.Series([1, 2, 3], index=lst)
>>> ser
a    1
a    2
b    3
dtype: int64
>>> ser.groupby(level=0).indices
{'a': array([0, 1]), 'b': array([2])}
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.indices.html, pandas.Series pandas.Series.groupby pandas.array
">>> data = [[1, 2, 3], [1, 5, 6], [7, 8, 9]]
>>> df = pd.DataFrame(data, columns=[""a"", ""b"", ""c""],
...                   index=[""owl"", ""toucan"", ""eagle""])
>>> df
        a  b  c
owl     1  2  3
toucan  1  5  6
eagle   7  8  9
>>> df.groupby(by=[""a""]).indices
{1: array([0, 1]), 7: array([2])}
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.indices.html, pandas.DataFrame pandas.DataFrame.groupby pandas.array
">>> ser = pd.Series([1, 2, 3, 4], index=pd.DatetimeIndex(
...                 ['2023-01-01', '2023-01-15', '2023-02-01', '2023-02-15']))
>>> ser
2023-01-01    1
2023-01-15    2
2023-02-01    3
2023-02-15    4
dtype: int64
>>> ser.resample('MS').indices
defaultdict(, {Timestamp('2023-01-01 00:00:00'): [0, 1],
Timestamp('2023-02-01 00:00:00'): [2, 3]})
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.indices.html, pandas.Series pandas.DatetimeIndex pandas.Series.resample
">>> s = pd.Series([1, 2, 3])
>>> s.describe()
count    3.0
mean     2.0
std      1.0
min      1.0
25%      1.5
50%      2.0
75%      2.5
max      3.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.describe.html, pandas.Series pandas.Series.describe
">>> s = pd.Series(['a', 'a', 'b', 'c'])
>>> s.describe()
count     4
unique    3
top       a
freq      2
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.describe.html, pandas.Series pandas.Series.describe
">>> s = pd.Series([
...     np.datetime64(""2000-01-01""),
...     np.datetime64(""2010-01-01""),
...     np.datetime64(""2010-01-01"")
... ])
>>> s.describe()
count                      3
mean     2006-09-01 08:00:00
min      2000-01-01 00:00:00
25%      2004-12-31 12:00:00
50%      2010-01-01 00:00:00
75%      2010-01-01 00:00:00
max      2010-01-01 00:00:00
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.describe.html, pandas.Series pandas.Series.describe
">>> df = pd.DataFrame({'categorical': pd.Categorical(['d', 'e', 'f']),
...                    'numeric': [1, 2, 3],
...                    'object': ['a', 'b', 'c']
...                    })
>>> df.describe()
       numeric
count      3.0
mean       2.0
std        1.0
min        1.0
25%        1.5
50%        2.0
75%        2.5
max        3.0
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.describe.html, pandas.DataFrame pandas.Categorical pandas.DataFrame.describe
">>> df.describe(include='all')  
       categorical  numeric object
count            3      3.0      3
unique           3      NaN      3
top              f      NaN      a
freq             1      NaN      1
mean           NaN      2.0    NaN
std            NaN      1.0    NaN
min            NaN      1.0    NaN
25%            NaN      1.5    NaN
50%            NaN      2.0    NaN
75%            NaN      2.5    NaN
max            NaN      3.0    NaN
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.describe.html, pandas.DataFrame.describe
">>> df.describe(include=[np.number])
       numeric
count      3.0
mean       2.0
std        1.0
min        1.0
25%        1.5
50%        2.0
75%        2.5
max        3.0
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.describe.html, pandas.DataFrame.describe
">>> df.describe(include=[object])  
       object
count       3
unique      3
top         a
freq        1
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.describe.html, pandas.DataFrame.describe
">>> df.describe(include=['category'])
       categorical
count            3
unique           3
top              d
freq             1
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.describe.html, pandas.DataFrame.describe
">>> df.describe(exclude=[np.number])  
       categorical object
count            3      3
unique           3      3
top              f      a
freq             1      1
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.describe.html, pandas.DataFrame.describe
">>> df.describe(exclude=[object])  
       categorical  numeric
count            3      3.0
unique           3      NaN
top              f      NaN
freq             1      NaN
mean           NaN      2.0
std            NaN      1.0
min            NaN      1.0
25%            NaN      1.5
50%            NaN      2.0
75%            NaN      2.5
max            NaN      3.0
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.describe.html, pandas.DataFrame.describe
">>> df = pd.DataFrame(dict(A=[1, 1, 3], B=[5, None, 6], C=[1, 2, 3]))
>>> df.groupby(""A"").last()
     B  C
A
1  5.0  2
3  6.0  3
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.last.html, pandas.DataFrame pandas.DataFrame.groupby
">>> s = pd.Series([1, 2, 3, 4])
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.aggregate.html, pandas.Series
">>> s.groupby([1, 1, 2, 2]).min()
1    1
2    3
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.aggregate.html, pandas.Series.groupby
">>> s.groupby([1, 1, 2, 2]).agg('min')
1    1
2    3
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.aggregate.html, pandas.Series.groupby
">>> s.groupby([1, 1, 2, 2]).agg(['min', 'max'])
   min  max
1    1    2
2    3    4
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.aggregate.html, pandas.Series.groupby
">>> s.groupby([1, 1, 2, 2]).agg(
...     minimum='min',
...     maximum='max',
... )
   minimum  maximum
1        1        2
2        3        4
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.aggregate.html, pandas.Series.groupby
">>> s.groupby([1, 1, 2, 2]).agg(lambda x: x.astype(float).min())
1    1.0
2    3.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.aggregate.html, pandas.Series.groupby pandas.Series.astype
">>> df = pd.DataFrame(
...     {""a"": [""red""] * 2 + [""blue""] * 2 + [""black""] * 2, ""b"": range(6)}
... )
>>> df
       a  b
0    red  0
1    red  1
2   blue  2
3   blue  3
4  black  4
5  black  5
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.sample.html, pandas.DataFrame
">>> df.groupby(""a"").sample(n=1, random_state=1)
       a  b
4  black  4
2   blue  2
1    red  1
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.sample.html, pandas.DataFrame.groupby
">>> df.groupby(""a"")[""b""].sample(frac=0.5, random_state=2)
5    5
2    2
0    0
Name: b, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.sample.html, pandas.DataFrame.groupby
">>> df.groupby(""a"").sample(
...     n=1,
...     weights=[1, 1, 1, 0, 0, 1],
...     random_state=1,
... )
       a  b
5  black  5
2   blue  2
0    red  0
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.sample.html, pandas.DataFrame.groupby
">>> lst = ['a', 'a', 'b']
>>> ser = pd.Series([6, 2, 0], index=lst)
>>> ser
a    6
a    2
b    0
dtype: int64
>>> ser.groupby(level=0).cumprod()
a    6
a   12
b    0
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.cumprod.html, pandas.Series pandas.Series.groupby
">>> data = [[1, 8, 2], [1, 2, 5], [2, 6, 9]]
>>> df = pd.DataFrame(data, columns=[""a"", ""b"", ""c""],
...                   index=[""cow"", ""horse"", ""bull""])
>>> df
        a   b   c
cow     1   8   2
horse   1   2   5
bull    2   6   9
>>> df.groupby(""a"").groups
{1: ['cow', 'horse'], 2: ['bull']}
>>> df.groupby(""a"").cumprod()
        b   c
cow     8   2
horse  16  10
bull    6   9
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.cumprod.html, pandas.DataFrame pandas.DataFrame.groupby
">>> import itertools
>>> tuples = [t for t in itertools.product(range(1000), range(4))]
>>> index = pd.MultiIndex.from_tuples(tuples, names=['lvl0', 'lvl1'])
>>> data = np.random.randn(len(index), 4)
>>> df = pd.DataFrame(data, columns=list('ABCD'), index=index)
>>> grouped = df.groupby(level='lvl1')
>>> grouped.boxplot(rot=45, fontsize=12, figsize=(8, 10))  
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.boxplot.html, pandas.MultiIndex.from_tuples pandas.DataFrame pandas.DataFrame.groupby
">>> lst = ['a', 'a', 'b']
>>> ser = pd.Series([1, 2, 3], index=lst)
>>> ser
a     1
a     2
b     3
dtype: int64
>>> ser.groupby(level=0).size()
a    2
b    1
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.size.html, pandas.Series pandas.Series.groupby
">>> data = [[1, 2, 3], [1, 5, 6], [7, 8, 9]]
>>> df = pd.DataFrame(data, columns=[""a"", ""b"", ""c""],
...                   index=[""owl"", ""toucan"", ""eagle""])
>>> df
        a  b  c
owl     1  2  3
toucan  1  5  6
eagle   7  8  9
>>> df.groupby(""a"").size()
a
1    2
7    1
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.size.html, pandas.DataFrame pandas.DataFrame.groupby
">>> ser = pd.Series([1, 2, 3], index=pd.DatetimeIndex(
...                 ['2023-01-01', '2023-01-15', '2023-02-01']))
>>> ser
2023-01-01    1
2023-01-15    2
2023-02-01    3
dtype: int64
>>> ser.resample('MS').size()
2023-01-01    2
2023-02-01    1
Freq: MS, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.size.html, pandas.Series pandas.DatetimeIndex pandas.Series.resample
">>> lst = ['a', 'a', 'b', 'b']
>>> ser = pd.Series([1, 2, 3, 4], index=lst)
>>> ser
a    1
a    2
b    3
b    4
dtype: int64
>>> ser.groupby(level=0).prod()
a    2
b   12
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.prod.html, pandas.Series pandas.Series.groupby
">>> data = [[1, 8, 2], [1, 2, 5], [2, 5, 8], [2, 6, 9]]
>>> df = pd.DataFrame(data, columns=[""a"", ""b"", ""c""],
...                   index=[""tiger"", ""leopard"", ""cheetah"", ""lion""])
>>> df
          a  b  c
  tiger   1  8  2
leopard   1  2  5
cheetah   2  5  8
   lion   2  6  9
>>> df.groupby(""a"").prod()
     b    c
a
1   16   10
2   30   72
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.prod.html, pandas.DataFrame pandas.DataFrame.groupby
">>> lst = ['a', 'a', 'b', 'b']
>>> ser = pd.Series([1, 2, 3, 4], index=lst)
>>> ser
a    1
a    2
b    3
b    4
dtype: int64
>>> ser.groupby(level=0).max()
a    2
b    4
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.max.html, pandas.Series pandas.Series.groupby
">>> data = [[1, 8, 2], [1, 2, 5], [2, 5, 8], [2, 6, 9]]
>>> df = pd.DataFrame(data, columns=[""a"", ""b"", ""c""],
...                   index=[""tiger"", ""leopard"", ""cheetah"", ""lion""])
>>> df
          a  b  c
  tiger   1  8  2
leopard   1  2  5
cheetah   2  5  8
   lion   2  6  9
>>> df.groupby(""a"").max()
    b  c
a
1   8  5
2   6  9
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.max.html, pandas.DataFrame pandas.DataFrame.groupby
">>> df = pd.DataFrame(dict(A=[1, 1, 3], B=[None, 5, 6], C=[1, 2, 3],
...                        D=['3/11/2000', '3/12/2000', '3/13/2000']))
>>> df['D'] = pd.to_datetime(df['D'])
>>> df.groupby(""A"").first()
     B  C          D
A
1  5.0  1 2000-03-11
3  6.0  3 2000-03-13
>>> df.groupby(""A"").first(min_count=2)
    B    C          D
A
1 NaN  1.0 2000-03-11
3 NaN  NaN        NaT
>>> df.groupby(""A"").first(numeric_only=True)
     B  C
A
1  5.0  1
3  6.0  3
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.first.html, pandas.DataFrame pandas.to_datetime pandas.DataFrame.groupby
">>> s = pd.Series(data=[1, None, 4, 3, 4],
...               index=['A', 'B', 'C', 'D', 'E'])
>>> s
A    1.0
B    NaN
C    4.0
D    3.0
E    4.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.idxmax.html, pandas.Series
">>> s.idxmax()
'C'
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.idxmax.html, pandas.Series.idxmax
">>> s.idxmax(skipna=False)
nan
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.idxmax.html, pandas.Series.idxmax
">>> s = pd.Series([1, 2, 3, 4])
>>> s
0    1
1    2
2    3
3    4
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.add_prefix.html, pandas.Series
">>> s.add_prefix('item_')
item_0    1
item_1    2
item_2    3
item_3    4
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.add_prefix.html, pandas.Series.add_prefix
">>> df = pd.DataFrame({'A': [1, 2, 3, 4], 'B': [3, 4, 5, 6]})
>>> df
   A  B
0  1  3
1  2  4
2  3  5
3  4  6
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.add_prefix.html, pandas.DataFrame
">>> df.add_prefix('col_')
     col_A  col_B
0       1       3
1       2       4
2       3       5
3       4       6
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.add_prefix.html, pandas.DataFrame.add_prefix
">>> df = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar',
...                           'foo', 'bar'],
...                    'B' : [1, 2, 3, 4, 5, 6],
...                    'C' : [2.0, 5., 8., 1., 2., 9.]})
>>> grouped = df.groupby('A')
>>> grouped.filter(lambda x: x['B'].mean() > 3.)
     A  B    C
1  bar  2  5.0
3  bar  4  1.0
5  bar  6  9.0
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.filter.html, pandas.DataFrame pandas.DataFrame.groupby
">>> df = pd.DataFrame(
...     {
...         ""Animal"": [""Falcon"", ""Parrot"", ""Falcon"", ""Falcon"", ""Parrot""],
...         ""Speed"": [100, 5, 200, 300, 15],
...     }
... )
>>> df
   Animal  Speed
0  Falcon    100
1  Parrot      5
2  Falcon    200
3  Falcon    300
4  Parrot     15
>>> df.groupby(pd.Grouper(key=""Animal"")).mean()
        Speed
Animal
Falcon  200.0
Parrot   10.0
",https://pandas.pydata.org/docs/reference/api/pandas.Grouper.html, pandas.DataFrame pandas.DataFrame.groupby pandas.Grouper
">>> df = pd.DataFrame(
...    {
...        ""Publish date"": [
...             pd.Timestamp(""2000-01-02""),
...             pd.Timestamp(""2000-01-02""),
...             pd.Timestamp(""2000-01-09""),
...             pd.Timestamp(""2000-01-16"")
...         ],
...         ""ID"": [0, 1, 2, 3],
...         ""Price"": [10, 20, 30, 40]
...     }
... )
>>> df
  Publish date  ID  Price
0   2000-01-02   0     10
1   2000-01-02   1     20
2   2000-01-09   2     30
3   2000-01-16   3     40
>>> df.groupby(pd.Grouper(key=""Publish date"", freq=""1W"")).mean()
               ID  Price
Publish date
2000-01-02    0.5   15.0
2000-01-09    2.0   30.0
2000-01-16    3.0   40.0
",https://pandas.pydata.org/docs/reference/api/pandas.Grouper.html, pandas.DataFrame pandas.DataFrame.groupby pandas.Grouper
">>> start, end = '2000-10-01 23:30:00', '2000-10-02 00:30:00'
>>> rng = pd.date_range(start, end, freq='7min')
>>> ts = pd.Series(np.arange(len(rng)) * 3, index=rng)
>>> ts
2000-10-01 23:30:00     0
2000-10-01 23:37:00     3
2000-10-01 23:44:00     6
2000-10-01 23:51:00     9
2000-10-01 23:58:00    12
2000-10-02 00:05:00    15
2000-10-02 00:12:00    18
2000-10-02 00:19:00    21
2000-10-02 00:26:00    24
Freq: 7min, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Grouper.html, pandas.date_range pandas.Series
">>> ts.groupby(pd.Grouper(freq='17min')).sum()
2000-10-01 23:14:00     0
2000-10-01 23:31:00     9
2000-10-01 23:48:00    21
2000-10-02 00:05:00    54
2000-10-02 00:22:00    24
Freq: 17min, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Grouper.html, pandas.Series.groupby pandas.Grouper
">>> ts.groupby(pd.Grouper(freq='17min', origin='epoch')).sum()
2000-10-01 23:18:00     0
2000-10-01 23:35:00    18
2000-10-01 23:52:00    27
2000-10-02 00:09:00    39
2000-10-02 00:26:00    24
Freq: 17min, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Grouper.html, pandas.Series.groupby pandas.Grouper
">>> ts.groupby(pd.Grouper(freq='17min', origin='2000-01-01')).sum()
2000-10-01 23:24:00     3
2000-10-01 23:41:00    15
2000-10-01 23:58:00    45
2000-10-02 00:15:00    45
Freq: 17min, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Grouper.html, pandas.Series.groupby pandas.Grouper
">>> ts.groupby(pd.Grouper(freq='17min', origin='start')).sum()
2000-10-01 23:30:00     9
2000-10-01 23:47:00    21
2000-10-02 00:04:00    54
2000-10-02 00:21:00    24
Freq: 17min, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Grouper.html, pandas.Series.groupby pandas.Grouper
">>> ts.groupby(pd.Grouper(freq='17min', offset='23h30min')).sum()
2000-10-01 23:30:00     9
2000-10-01 23:47:00    21
2000-10-02 00:04:00    54
2000-10-02 00:21:00    24
Freq: 17min, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Grouper.html, pandas.Series.groupby pandas.Grouper
">>> ts.groupby(pd.Grouper(freq='17min', offset='2min')).sum()
2000-10-01 23:16:00     0
2000-10-01 23:33:00     9
2000-10-01 23:50:00    36
2000-10-02 00:07:00    39
2000-10-02 00:24:00    24
Freq: 17min, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Grouper.html, pandas.Series.groupby pandas.Grouper
">>> s = pd.Series([0, 1, 2], index='a a b'.split())
>>> g1 = s.groupby(s.index, group_keys=False)
>>> g2 = s.groupby(s.index, group_keys=True)
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.apply.html, pandas.Series pandas.Series.str.split pandas.Series.groupby
">>> g1.apply(lambda x: x.max() - x.min())
a    1
b    0
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.apply.html, pandas.Series.max pandas.Series.min
">>> g2.apply(lambda x: x.max() - x.min())
a    1
b    0
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.apply.html, pandas.Series.max pandas.Series.min
">>> lst = ['a', 'a', 'a', 'b', 'b', 'b']
>>> ser = pd.Series([7, 2, 8, 4, 3, 3], index=lst)
>>> ser
a     7
a     2
a     8
b     4
b     3
b     3
dtype: int64
>>> ser.groupby(level=0).var()
a    10.333333
b     0.333333
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.var.html, pandas.Series pandas.Series.groupby
">>> data = {'a': [1, 3, 5, 7, 7, 8, 3], 'b': [1, 4, 8, 4, 4, 2, 1]}
>>> df = pd.DataFrame(data, index=['dog', 'dog', 'dog',
...                   'mouse', 'mouse', 'mouse', 'mouse'])
>>> df
         a  b
  dog    1  1
  dog    3  4
  dog    5  8
mouse    7  4
mouse    7  4
mouse    8  2
mouse    3  1
>>> df.groupby(level=0).var()
              a          b
dog    4.000000  12.333333
mouse  4.916667   2.250000
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.var.html, pandas.DataFrame pandas.DataFrame.groupby
">>> s = pd.Series([1, 2, 3, 4])
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.agg.html, pandas.Series
">>> s.groupby([1, 1, 2, 2]).min()
1    1
2    3
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.agg.html, pandas.Series.groupby
">>> s.groupby([1, 1, 2, 2]).agg('min')
1    1
2    3
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.agg.html, pandas.Series.groupby
">>> s.groupby([1, 1, 2, 2]).agg(['min', 'max'])
   min  max
1    1    2
2    3    4
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.agg.html, pandas.Series.groupby
">>> s.groupby([1, 1, 2, 2]).agg(
...     minimum='min',
...     maximum='max',
... )
   minimum  maximum
1        1        2
2        3        4
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.agg.html, pandas.Series.groupby
">>> s.groupby([1, 1, 2, 2]).agg(lambda x: x.astype(float).min())
1    1.0
2    3.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.agg.html, pandas.Series.groupby pandas.Series.astype
">>> lst = ['SPX', 'CAC', 'SPX', 'CAC', 'SPX', 'CAC', 'SPX', 'CAC',]
>>> ser = pd.Series([3.4, 9.0, 7.2, 5.2, 8.8, 9.4, 0.1, 0.5], index=lst)
>>> ser
SPX     3.4
CAC     9.0
SPX     7.2
CAC     5.2
SPX     8.8
CAC     9.4
SPX     0.1
CAC     0.5
dtype: float64
>>> ser.groupby(level=0).ohlc()
     open  high  low  close
CAC   9.0   9.4  0.5    0.5
SPX   3.4   8.8  0.1    0.1
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.ohlc.html, pandas.Series pandas.Series.groupby
">>> data = {2022: [1.2, 2.3, 8.9, 4.5, 4.4, 3, 2 , 1],
...         2023: [3.4, 9.0, 7.2, 5.2, 8.8, 9.4, 8.2, 1.0]}
>>> df = pd.DataFrame(data, index=['SPX', 'CAC', 'SPX', 'CAC',
...                   'SPX', 'CAC', 'SPX', 'CAC'])
>>> df
     2022  2023
SPX   1.2   3.4
CAC   2.3   9.0
SPX   8.9   7.2
CAC   4.5   5.2
SPX   4.4   8.8
CAC   3.0   9.4
SPX   2.0   8.2
CAC   1.0   1.0
>>> df.groupby(level=0).ohlc()
    2022                 2023
    open high  low close open high  low close
CAC  2.3  4.5  1.0   1.0  9.0  9.4  1.0   1.0
SPX  1.2  8.9  1.2   2.0  3.4  8.8  3.4   8.2
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.ohlc.html, pandas.DataFrame pandas.DataFrame.groupby
">>> ser = pd.Series([1, 3, 2, 4, 3, 5],
...                 index=pd.DatetimeIndex(['2023-01-01',
...                                         '2023-01-10',
...                                         '2023-01-15',
...                                         '2023-02-01',
...                                         '2023-02-10',
...                                         '2023-02-15']))
>>> ser.resample('MS').ohlc()
            open  high  low  close
2023-01-01     1     3    1      2
2023-02-01     4     5    3      5
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.ohlc.html, pandas.Series pandas.DatetimeIndex pandas.Series.resample
">>> df = pd.DataFrame([
...     ['a', 1], ['a', 2], ['a', 3],
...     ['b', 1], ['b', 3], ['b', 5]
... ], columns=['key', 'val'])
>>> df.groupby('key').quantile()
    val
key
a    2.0
b    3.0
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.quantile.html, pandas.DataFrame pandas.DataFrame.groupby
">>> ser = pd.Series([1, 2, 3, 3])
>>> plot = ser.plot(kind='hist', title=""My plot"")
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.plot.html, pandas.Series pandas.Series.plot
">>> df = pd.DataFrame({'length': [1.5, 0.5, 1.2, 0.9, 3],
...                   'width': [0.7, 0.2, 0.15, 0.2, 1.1]},
...                   index=['pig', 'rabbit', 'duck', 'chicken', 'horse'])
>>> plot = df.plot(title=""DataFrame Plot"")
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.plot.html, pandas.DataFrame pandas.DataFrame.plot
">>> lst = [-1, -2, -3, 1, 2, 3]
>>> ser = pd.Series([1, 2, 2, 4, 6, 6], index=lst)
>>> plot = ser.groupby(lambda x: x > 0).plot(title=""SeriesGroupBy Plot"")
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.plot.html, pandas.Series pandas.Series.groupby
">>> df = pd.DataFrame({""col1"" : [1, 2, 3, 4],
...                   ""col2"" : [""A"", ""B"", ""A"", ""B""]})
>>> plot = df.groupby(""col2"").plot(kind=""bar"", title=""DataFrameGroupBy Plot"")
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.plot.html, pandas.DataFrame pandas.DataFrame.groupby
">>> s = pd.Series([2, 1, 3, 4], index=['Falcon', 'Falcon', 'Parrot', 'Parrot'])
>>> s.groupby(level=0).is_monotonic_increasing
Falcon    False
Parrot     True
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.is_monotonic_increasing.html, pandas.Series pandas.Series.groupby
">>> lst = ['a', 'a', 'b']
>>> ser = pd.Series([6, 2, 0], index=lst)
>>> ser
a    6
a    2
b    0
dtype: int64
>>> ser.groupby(level=0).cumsum()
a    6
a    8
b    0
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.cumsum.html, pandas.Series pandas.Series.groupby
">>> data = [[1, 8, 2], [1, 2, 5], [2, 6, 9]]
>>> df = pd.DataFrame(data, columns=[""a"", ""b"", ""c""],
...                   index=[""fox"", ""gorilla"", ""lion""])
>>> df
          a   b   c
fox       1   8   2
gorilla   1   2   5
lion      2   6   9
>>> df.groupby(""a"").groups
{1: ['fox', 'gorilla'], 2: ['lion']}
>>> df.groupby(""a"").cumsum()
          b   c
fox       8   2
gorilla  10   7
lion      6   9
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.cumsum.html, pandas.DataFrame pandas.DataFrame.groupby
">>> df = pd.DataFrame([[1, 2], [1, 4], [5, 6]],
...                   columns=['A', 'B'])
>>> df.groupby('A').head(1)
   A  B
0  1  2
2  5  6
>>> df.groupby('A').head(-1)
   A  B
0  1  2
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.head.html, pandas.DataFrame pandas.DataFrame.groupby
">>> key = [0, 0, 1, 1]
>>> ser = pd.Series([np.nan, 2, 3, np.nan], index=key)
>>> ser
0    NaN
0    2.0
1    3.0
1    NaN
dtype: float64
>>> ser.groupby(level=0).ffill()
0    NaN
0    2.0
1    3.0
1    3.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.ffill.html, pandas.Series pandas.Series.groupby
">>> df = pd.DataFrame(
...     {
...         ""key"": [0, 0, 1, 1, 1],
...         ""A"": [np.nan, 2, np.nan, 3, np.nan],
...         ""B"": [2, 3, np.nan, np.nan, np.nan],
...         ""C"": [np.nan, np.nan, 2, np.nan, np.nan],
...     }
... )
>>> df
   key    A    B   C
0    0  NaN  2.0 NaN
1    0  2.0  3.0 NaN
2    1  NaN  NaN 2.0
3    1  3.0  NaN NaN
4    1  NaN  NaN NaN
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.ffill.html, pandas.DataFrame
">>> df.groupby(""key"").ffill()
     A    B   C
0  NaN  2.0 NaN
1  2.0  3.0 NaN
2  NaN  NaN 2.0
3  3.0  NaN 2.0
4  3.0  NaN 2.0
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.ffill.html, pandas.DataFrame.groupby
">>> df.groupby(""key"").ffill(limit=1)
     A    B    C
0  NaN  2.0  NaN
1  2.0  3.0  NaN
2  NaN  NaN  2.0
3  3.0  NaN  2.0
4  3.0  NaN  NaN
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.ffill.html, pandas.DataFrame.groupby
">>> key = [0, 0, 1, 1]
>>> ser = pd.Series([np.nan, 2, 3, np.nan], index=key)
>>> ser
0    NaN
0    2.0
1    3.0
1    NaN
dtype: float64
>>> ser.groupby(level=0).ffill()
0    NaN
0    2.0
1    3.0
1    3.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.ffill.html, pandas.Series pandas.Series.groupby
">>> df = pd.DataFrame(
...     {
...         ""key"": [0, 0, 1, 1, 1],
...         ""A"": [np.nan, 2, np.nan, 3, np.nan],
...         ""B"": [2, 3, np.nan, np.nan, np.nan],
...         ""C"": [np.nan, np.nan, 2, np.nan, np.nan],
...     }
... )
>>> df
   key    A    B   C
0    0  NaN  2.0 NaN
1    0  2.0  3.0 NaN
2    1  NaN  NaN 2.0
3    1  3.0  NaN NaN
4    1  NaN  NaN NaN
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.ffill.html, pandas.DataFrame
">>> df.groupby(""key"").ffill()
     A    B   C
0  NaN  2.0 NaN
1  2.0  3.0 NaN
2  NaN  NaN 2.0
3  3.0  NaN 2.0
4  3.0  NaN 2.0
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.ffill.html, pandas.DataFrame.groupby
">>> df.groupby(""key"").ffill(limit=1)
     A    B    C
0  NaN  2.0  NaN
1  2.0  3.0  NaN
2  NaN  NaN  2.0
3  3.0  NaN  2.0
4  3.0  NaN  NaN
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.ffill.html, pandas.DataFrame.groupby
">>> h = lambda x, arg2, arg3: x + 1 - arg2 * arg3
>>> g = lambda x, arg1: x * 5 / arg1
>>> f = lambda x: x ** 4
>>> df = pd.DataFrame([[""a"", 4], [""b"", 5]], columns=[""group"", ""value""])
>>> h(g(f(df.groupby('group')), arg1=1), arg2=2, arg3=3)  
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.pipe.html, pandas.DataFrame pandas.DataFrame.groupby
">>> (df.groupby('group')
...    .pipe(f)
...    .pipe(g, arg1=1)
...    .pipe(h, arg2=2, arg3=3))  
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.pipe.html, pandas.DataFrame.groupby
">>> df = pd.DataFrame({'A': 'a b a b'.split(), 'B': [1, 2, 3, 4]})
>>> df
   A  B
0  a  1
1  b  2
2  a  3
3  b  4
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.pipe.html, pandas.DataFrame pandas.Series.str.split
">>> df.groupby('A').pipe(lambda x: x.max() - x.min())
   B
A
a  2
b  2
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.pipe.html, pandas.DataFrame.groupby pandas.Series.max pandas.Series.min
">>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]})
>>> df
     B
0  0.0
1  1.0
2  2.0
3  NaN
4  4.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rolling.html, pandas.DataFrame
">>> df.rolling(2).sum()
     B
0  NaN
1  1.0
2  3.0
3  NaN
4  NaN
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rolling.html, pandas.DataFrame.rolling
">>> df_time = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]},
...                        index=[pd.Timestamp('20130101 09:00:00'),
...                               pd.Timestamp('20130101 09:00:02'),
...                               pd.Timestamp('20130101 09:00:03'),
...                               pd.Timestamp('20130101 09:00:05'),
...                               pd.Timestamp('20130101 09:00:06')])
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rolling.html, pandas.DataFrame
">>> df_time.rolling('2s').sum()
                       B
2013-01-01 09:00:00  0.0
2013-01-01 09:00:02  1.0
2013-01-01 09:00:03  3.0
2013-01-01 09:00:05  NaN
2013-01-01 09:00:06  4.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rolling.html, pandas.DataFrame.rolling
">>> indexer = pd.api.indexers.FixedForwardWindowIndexer(window_size=2)
>>> df.rolling(window=indexer, min_periods=1).sum()
     B
0  1.0
1  3.0
2  2.0
3  4.0
4  4.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rolling.html, pandas.api.indexers.FixedForwardWindowIndexer pandas.DataFrame.rolling
">>> df.rolling(2, min_periods=1).sum()
     B
0  0.0
1  1.0
2  3.0
3  2.0
4  4.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rolling.html, pandas.DataFrame.rolling
">>> df.rolling(3, min_periods=1, center=True).sum()
     B
0  1.0
1  3.0
2  3.0
3  6.0
4  4.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rolling.html, pandas.DataFrame.rolling
">>> df.rolling(3, min_periods=1, center=False).sum()
     B
0  0.0
1  1.0
2  3.0
3  3.0
4  6.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rolling.html, pandas.DataFrame.rolling
">>> df.rolling(2, min_periods=1, step=2).sum()
     B
0  0.0
2  3.0
4  4.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rolling.html, pandas.DataFrame.rolling
">>> df.rolling(2, win_type='gaussian').sum(std=3)
          B
0       NaN
1  0.986207
2  2.958621
3       NaN
4       NaN
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rolling.html, pandas.DataFrame.rolling
">>> df = pd.DataFrame({
...     'A': [pd.to_datetime('2020-01-01'),
...           pd.to_datetime('2020-01-01'),
...           pd.to_datetime('2020-01-02'),],
...     'B': [1, 2, 3], },
...     index=pd.date_range('2020', periods=3))
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rolling.html, pandas.DataFrame pandas.to_datetime pandas.date_range
">>> df.rolling('2D', on='A').sum()
                    A    B
2020-01-01 2020-01-01  1.0
2020-01-02 2020-01-01  3.0
2020-01-03 2020-01-02  6.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rolling.html, pandas.DataFrame.rolling
">>> df = pd.DataFrame([1e-9, 1e-3, 1, 1e3, 1e6])
>>> df
              0
0  1.000000e-09
1  1.000000e-03
2  1.000000e+00
3  1.000000e+03
4  1.000000e+06
",https://pandas.pydata.org/docs/reference/api/pandas.set_eng_float_format.html, pandas.DataFrame
">>> pd.set_eng_float_format(accuracy=1)
>>> df
         0
0  1.0E-09
1  1.0E-03
2  1.0E+00
3  1.0E+03
4  1.0E+06
",https://pandas.pydata.org/docs/reference/api/pandas.set_eng_float_format.html, pandas.set_eng_float_format
">>> pd.set_eng_float_format(use_eng_prefix=True)
>>> df
        0
0  1.000n
1  1.000m
2   1.000
3  1.000k
4  1.000M
",https://pandas.pydata.org/docs/reference/api/pandas.set_eng_float_format.html, pandas.set_eng_float_format
">>> pd.set_eng_float_format(accuracy=1, use_eng_prefix=True)
>>> df
      0
0  1.0n
1  1.0m
2   1.0
3  1.0k
4  1.0M
",https://pandas.pydata.org/docs/reference/api/pandas.set_eng_float_format.html, pandas.set_eng_float_format
">>> index = [""a"", ""b"", ""c"", ""d"", ""e""]
>>> columns = [""one"", ""two"", ""three"", ""four""]
>>> df1 = pd.DataFrame(np.arange(20).reshape(5, 4), index=index, columns=columns)
>>> df2 = pd.DataFrame(np.arange(16).reshape(4, 4), index=index[:4], columns=columns)
>>> df1.corrwith(df2)
one      1.0
two      1.0
three    1.0
four     1.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corrwith.html, pandas.DataFrame pandas.DataFrame.corrwith
">>> df2.corrwith(df1, axis=1)
a    1.0
b    1.0
c    1.0
d    1.0
e    NaN
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corrwith.html, pandas.DataFrame.corrwith
">>> df = pd.DataFrame([(1, 2), (0, 3), (2, 0), (1, 1)],
...                   columns=['dogs', 'cats'])
>>> df.cov()
          dogs      cats
dogs  0.666667 -1.000000
cats -1.000000  1.666667
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.cov.html, pandas.DataFrame pandas.DataFrame.cov
">>> np.random.seed(42)
>>> df = pd.DataFrame(np.random.randn(1000, 5),
...                   columns=['a', 'b', 'c', 'd', 'e'])
>>> df.cov()
          a         b         c         d         e
a  0.998438 -0.020161  0.059277 -0.008943  0.014144
b -0.020161  1.059352 -0.008543 -0.024738  0.009826
c  0.059277 -0.008543  1.010670 -0.001486 -0.000271
d -0.008943 -0.024738 -0.001486  0.921297 -0.013692
e  0.014144  0.009826 -0.000271 -0.013692  0.977795
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.cov.html, pandas.DataFrame pandas.DataFrame.cov
">>> np.random.seed(42)
>>> df = pd.DataFrame(np.random.randn(20, 3),
...                   columns=['a', 'b', 'c'])
>>> df.loc[df.index[:5], 'a'] = np.nan
>>> df.loc[df.index[5:10], 'b'] = np.nan
>>> df.cov(min_periods=12)
          a         b         c
a  0.316741       NaN -0.150812
b       NaN  1.248003  0.191417
c -0.150812  0.191417  0.895202
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.cov.html, pandas.DataFrame pandas.DataFrame.cov
">>> df = pd.DataFrame({'A': [1, 1, 2, 1, 2],
...                    'B': [np.nan, 2, 3, 4, 5]}, columns=['A', 'B'])
>>> g = df.groupby('A')
>>> g.nth(0)
   A   B
0  1 NaN
2  2 3.0
>>> g.nth(1)
   A   B
1  1 2.0
4  2 5.0
>>> g.nth(-1)
   A   B
3  1 4.0
4  2 5.0
>>> g.nth([0, 1])
   A   B
0  1 NaN
1  1 2.0
2  2 3.0
4  2 5.0
>>> g.nth(slice(None, -1))
   A   B
0  1 NaN
1  1 2.0
2  2 3.0
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.nth.html, pandas.DataFrame pandas.DataFrame.groupby pandas.Series.str.slice
">>> df = pd.DataFrame(np.array([[1, 1], [2, 10], [3, 100], [4, 100]]),
...                   columns=['a', 'b'])
>>> df.quantile(.1)
a    1.3
b    3.7
Name: 0.1, dtype: float64
>>> df.quantile([.1, .5])
       a     b
0.1  1.3   3.7
0.5  2.5  55.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.quantile.html, pandas.DataFrame pandas.DataFrame.quantile
">>> df.quantile(.1, method=""table"", interpolation=""nearest"")
a    1
b    1
Name: 0.1, dtype: int64
>>> df.quantile([.1, .5], method=""table"", interpolation=""nearest"")
     a    b
0.1  1    1
0.5  3  100
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.quantile.html, pandas.DataFrame.quantile
">>> df = pd.DataFrame({'A': [1, 2],
...                    'B': [pd.Timestamp('2010'),
...                          pd.Timestamp('2011')],
...                    'C': [pd.Timedelta('1 days'),
...                          pd.Timedelta('2 days')]})
>>> df.quantile(0.5, numeric_only=False)
A                    1.5
B    2010-07-02 12:00:00
C        1 days 12:00:00
Name: 0.5, dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.quantile.html, pandas.DataFrame pandas.DataFrame.quantile
">>> def histogram_intersection(a, b):
...     v = np.minimum(a, b).sum().round(decimals=1)
...     return v
>>> df = pd.DataFrame([(.2, .3), (.0, .6), (.6, .0), (.2, .1)],
...                   columns=['dogs', 'cats'])
>>> df.corr(method=histogram_intersection)
      dogs  cats
dogs   1.0   0.3
cats   0.3   1.0
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.corr.html, pandas.DataFrame pandas.DataFrame.corr
">>> df = pd.DataFrame([(1, 1), (2, np.nan), (np.nan, 3), (4, 4)],
...                   columns=['dogs', 'cats'])
>>> df.corr(min_periods=3)
      dogs  cats
dogs   1.0   NaN
cats   NaN   1.0
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.corr.html, pandas.DataFrame pandas.DataFrame.corr
">>> df = pd.DataFrame(data={'Animal': ['cat', 'penguin', 'dog',
...                                    'spider', 'snake'],
...                         'Number_legs': [4, 2, 4, 8, np.nan]})
>>> df
    Animal  Number_legs
0      cat          4.0
1  penguin          2.0
2      dog          4.0
3   spider          8.0
4    snake          NaN
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rank.html, pandas.DataFrame
">>> s = pd.Series(range(5), index=list(""abcde""))
>>> s[""d""] = s[""b""]
>>> s.rank()
a    1.0
b    2.5
c    4.0
d    2.5
e    5.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rank.html, pandas.Series pandas.Series.rank
">>> data = {'col_1': [3, 2, 1, 0], 'col_2': ['a', 'b', 'c', 'd']}
>>> pd.DataFrame.from_dict(data)
   col_1 col_2
0      3     a
1      2     b
2      1     c
3      0     d
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.from_dict.html, pandas.DataFrame.from_dict
">>> data = {'row_1': [3, 2, 1, 0], 'row_2': ['a', 'b', 'c', 'd']}
>>> pd.DataFrame.from_dict(data, orient='index')
       0  1  2  3
row_1  3  2  1  0
row_2  a  b  c  d
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.from_dict.html, pandas.DataFrame.from_dict
">>> pd.DataFrame.from_dict(data, orient='index',
...                        columns=['A', 'B', 'C', 'D'])
       A  B  C  D
row_1  3  2  1  0
row_2  a  b  c  d
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.from_dict.html, pandas.DataFrame.from_dict
">>> data = {'index': [('a', 'b'), ('a', 'c')],
...         'columns': [('x', 1), ('y', 2)],
...         'data': [[1, 3], [2, 4]],
...         'index_names': ['n1', 'n2'],
...         'column_names': ['z1', 'z2']}
>>> pd.DataFrame.from_dict(data, orient='tight')
z1     x  y
z2     1  2
n1 n2
a  b   1  3
   c   2  4
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.from_dict.html, pandas.DataFrame.from_dict
">>> primes = pd.Series([2, 3, 5, 7])
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.squeeze.html, pandas.Series
">>> df = pd.DataFrame([[1, 2], [3, 4]], columns=['a', 'b'])
>>> df
   a  b
0  1  2
1  3  4
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.squeeze.html, pandas.DataFrame
">>> df = pd.DataFrame([1, 2, 3, 4, 5], index=[100, 29, 234, 1, 150],
...                   columns=['A'])
>>> df.sort_index()
     A
1    4
29   2
100  1
150  5
234  3
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_index.html, pandas.DataFrame pandas.DataFrame.sort_index
">>> df.sort_index(ascending=False)
     A
234  3
150  5
100  1
29   2
1    4
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_index.html, pandas.DataFrame.sort_index
">>> df = pd.DataFrame({""a"": [1, 2, 3, 4]}, index=['A', 'b', 'C', 'd'])
>>> df.sort_index(key=lambda x: x.str.lower())
   a
A  1
b  2
C  3
d  4
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_index.html, pandas.DataFrame pandas.DataFrame.sort_index pandas.Series.str.lower
">>> lst = ['a', 'a', 'b']
>>> ser = pd.Series([1, 2, 3], index=lst)
>>> ser
a    1
a    2
b    3
dtype: int64
>>> ser.groupby(level=0).get_group(""a"")
a    1
a    2
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.get_group.html, pandas.Series pandas.Series.groupby
">>> data = [[1, 2, 3], [1, 5, 6], [7, 8, 9]]
>>> df = pd.DataFrame(data, columns=[""a"", ""b"", ""c""],
...                   index=[""owl"", ""toucan"", ""eagle""])
>>> df
        a  b  c
owl     1  2  3
toucan  1  5  6
eagle   7  8  9
>>> df.groupby(by=[""a""]).get_group((1,))
        a  b  c
owl     1  2  3
toucan  1  5  6
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.get_group.html, pandas.DataFrame pandas.DataFrame.groupby
">>> ser = pd.Series([1, 2, 3, 4], index=pd.DatetimeIndex(
...                 ['2023-01-01', '2023-01-15', '2023-02-01', '2023-02-15']))
>>> ser
2023-01-01    1
2023-01-15    2
2023-02-01    3
2023-02-15    4
dtype: int64
>>> ser.resample('MS').get_group('2023-01-01')
2023-01-01    1
2023-01-15    2
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.get_group.html, pandas.Series pandas.DatetimeIndex pandas.Series.resample
">>> lst = ['a', 'a', 'b']
>>> ser = pd.Series([6, 2, 0], index=lst)
>>> ser
a    6
a    2
b    0
dtype: int64
>>> ser.groupby(level=0).cumsum()
a    6
a    8
b    0
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.cumsum.html, pandas.Series pandas.Series.groupby
">>> data = [[1, 8, 2], [1, 2, 5], [2, 6, 9]]
>>> df = pd.DataFrame(data, columns=[""a"", ""b"", ""c""],
...                   index=[""fox"", ""gorilla"", ""lion""])
>>> df
          a   b   c
fox       1   8   2
gorilla   1   2   5
lion      2   6   9
>>> df.groupby(""a"").groups
{1: ['fox', 'gorilla'], 2: ['lion']}
>>> df.groupby(""a"").cumsum()
          b   c
fox       8   2
gorilla  10   7
lion      6   9
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.cumsum.html, pandas.DataFrame pandas.DataFrame.groupby
"self.apply(lambda x: pd.Series(np.arange(len(x)), x.index))
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.cumcount.html, pandas.Series
">>> df = pd.DataFrame([['a'], ['a'], ['a'], ['b'], ['b'], ['a']],
...                   columns=['A'])
>>> df
   A
0  a
1  a
2  a
3  b
4  b
5  a
>>> df.groupby('A').cumcount()
0    0
1    1
2    2
3    0
4    1
5    3
dtype: int64
>>> df.groupby('A').cumcount(ascending=False)
0    3
1    2
2    1
3    1
4    0
5    0
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.cumcount.html, pandas.DataFrame pandas.DataFrame.groupby
">>> from pandas.api.indexers import VariableOffsetWindowIndexer
>>> df = pd.DataFrame(range(10), index=pd.date_range(""2020"", periods=10))
>>> offset = pd.offsets.BDay(1)
>>> indexer = VariableOffsetWindowIndexer(index=df.index, offset=offset)
>>> df
            0
2020-01-01  0
2020-01-02  1
2020-01-03  2
2020-01-04  3
2020-01-05  4
2020-01-06  5
2020-01-07  6
2020-01-08  7
2020-01-09  8
2020-01-10  9
>>> df.rolling(indexer).sum()
               0
2020-01-01   0.0
2020-01-02   1.0
2020-01-03   2.0
2020-01-04   3.0
2020-01-05   7.0
2020-01-06  12.0
2020-01-07   6.0
2020-01-08   7.0
2020-01-09   8.0
2020-01-10   9.0
",https://pandas.pydata.org/docs/reference/api/pandas.api.indexers.VariableOffsetWindowIndexer.html, pandas.DataFrame pandas.date_range pandas.api.indexers.VariableOffsetWindowIndexer pandas.DataFrame.rolling
">>> data = {""A"": [1, 1, 2, 2],
...         ""B"": [1, 2, 3, 4],
...         ""C"": [0.362838, 0.227877, 1.267767, -0.562860]}
>>> df = pd.DataFrame(data)
>>> df
   A  B         C
0  1  1  0.362838
1  1  2  0.227877
2  2  3  1.267767
3  2  4 -0.562860
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.aggregate.html, pandas.DataFrame
">>> df.groupby('A').agg('min')
   B         C
A
1  1  0.227877
2  3 -0.562860
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.aggregate.html, pandas.DataFrame.groupby
">>> df.groupby('A').agg(['min', 'max'])
    B             C
  min max       min       max
A
1   1   2  0.227877  0.362838
2   3   4 -0.562860  1.267767
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.aggregate.html, pandas.DataFrame.groupby
">>> df.groupby('A').B.agg(['min', 'max'])
   min  max
A
1    1    2
2    3    4
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.aggregate.html, pandas.DataFrame.groupby
">>> df.groupby('A').agg(lambda x: sum(x) + 2)
    B          C
A
1       5       2.590715
2       9       2.704907
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.aggregate.html, pandas.DataFrame.groupby
">>> df.groupby('A').agg({'B': ['min', 'max'], 'C': 'sum'})
    B             C
  min max       sum
A
1   1   2  0.590715
2   3   4  0.704907
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.aggregate.html, pandas.DataFrame.groupby
">>> df.groupby(""A"").agg(
...     b_min=pd.NamedAgg(column=""B"", aggfunc=""min""),
...     c_sum=pd.NamedAgg(column=""C"", aggfunc=""sum"")
... )
   b_min     c_sum
A
1      1  0.590715
2      3  0.704907
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.aggregate.html, pandas.DataFrame.groupby pandas.NamedAgg
">>> df.groupby(""A"")[[""B""]].agg(lambda x: x.astype(float).min())
      B
A
1   1.0
2   3.0
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.aggregate.html, pandas.DataFrame.groupby pandas.Series.astype
">>> lst = ['a', 'a', 'b']
>>> ser = pd.Series([1, 2, 3], index=lst)
>>> ser
a    1
a    2
b    3
dtype: int64
>>> ser.groupby(level=0).groups
{'a': ['a', 'a'], 'b': ['b']}
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.groups.html, pandas.Series pandas.Series.groupby
">>> data = [[1, 2, 3], [1, 5, 6], [7, 8, 9]]
>>> df = pd.DataFrame(data, columns=[""a"", ""b"", ""c""])
>>> df
   a  b  c
0  1  2  3
1  1  5  6
2  7  8  9
>>> df.groupby(by=[""a""]).groups
{1: [0, 1], 7: [2]}
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.groups.html, pandas.DataFrame pandas.DataFrame.groupby
">>> ser = pd.Series([1, 2, 3, 4], index=pd.DatetimeIndex(
...                 ['2023-01-01', '2023-01-15', '2023-02-01', '2023-02-15']))
>>> ser
2023-01-01    1
2023-01-15    2
2023-02-01    3
2023-02-15    4
dtype: int64
>>> ser.resample('MS').groups
{Timestamp('2023-01-01 00:00:00'): 2, Timestamp('2023-02-01 00:00:00'): 4}
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.groups.html, pandas.Series pandas.DatetimeIndex pandas.Series.resample
">>> df = pd.DataFrame([('falcon', 'bird', 389.0),
...                    ('parrot', 'bird', 24.0),
...                    ('lion', 'mammal', 80.5),
...                    ('monkey', 'mammal', np.nan),
...                    ('rabbit', 'mammal', 15.0)],
...                   columns=['name', 'class', 'max_speed'],
...                   index=[4, 3, 2, 1, 0])
>>> df
     name   class  max_speed
4  falcon    bird      389.0
3  parrot    bird       24.0
2    lion  mammal       80.5
1  monkey  mammal        NaN
0  rabbit  mammal       15.0
>>> gb = df.groupby([1, 1, 2, 2, 2])
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.take.html, pandas.DataFrame pandas.DataFrame.groupby
">>> lst = ['a', 'a', 'b']
>>> ser = pd.Series([1, 2, np.nan], index=lst)
>>> ser
a    1.0
a    2.0
b    NaN
dtype: float64
>>> ser.groupby(level=0).count()
a    2
b    0
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.count.html, pandas.Series pandas.Series.groupby
">>> data = [[1, np.nan, 3], [1, np.nan, 6], [7, 8, 9]]
>>> df = pd.DataFrame(data, columns=[""a"", ""b"", ""c""],
...                   index=[""cow"", ""horse"", ""bull""])
>>> df
        a         b     c
cow     1       NaN     3
horse   1       NaN     6
bull    7       8.0     9
>>> df.groupby(""a"").count()
    b   c
a
1   0   2
7   1   1
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.count.html, pandas.DataFrame pandas.DataFrame.groupby
">>> ser = pd.Series([1, 2, 3, 4], index=pd.DatetimeIndex(
...                 ['2023-01-01', '2023-01-15', '2023-02-01', '2023-02-15']))
>>> ser
2023-01-01    1
2023-01-15    2
2023-02-01    3
2023-02-15    4
dtype: int64
>>> ser.resample('MS').count()
2023-01-01    2
2023-02-01    2
Freq: MS, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.count.html, pandas.Series pandas.DatetimeIndex pandas.Series.resample
">>> lst = ['a', 'a', 'b']
>>> ser = pd.Series([1, 2, 0], index=lst)
>>> ser
a    1
a    2
b    0
dtype: int64
>>> ser.groupby(level=0).all()
a     True
b    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.all.html, pandas.Series pandas.Series.groupby
">>> data = [[1, 0, 3], [1, 5, 6], [7, 8, 9]]
>>> df = pd.DataFrame(data, columns=[""a"", ""b"", ""c""],
...                   index=[""ostrich"", ""penguin"", ""parrot""])
>>> df
         a  b  c
ostrich  1  0  3
penguin  1  5  6
parrot   7  8  9
>>> df.groupby(by=[""a""]).all()
       b      c
a
1  False   True
7   True   True
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.all.html, pandas.DataFrame pandas.DataFrame.groupby
">>> s = pd.Series([2, 1, 3, 4], index=['Falcon', 'Falcon', 'Parrot', 'Parrot'])
>>> s.groupby(level=0).is_monotonic_decreasing
Falcon     True
Parrot    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.is_monotonic_decreasing.html, pandas.Series pandas.Series.groupby
">>> lst = ['a', 'a', 'b', 'b']
>>> ser = pd.Series([1, 2, 3, 4], index=lst)
>>> ser
a    1
a    2
b    3
b    4
dtype: int64
>>> ser.groupby(level=0).min()
a    1
b    3
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.min.html, pandas.Series pandas.Series.groupby
">>> data = [[1, 8, 2], [1, 2, 5], [2, 5, 8], [2, 6, 9]]
>>> df = pd.DataFrame(data, columns=[""a"", ""b"", ""c""],
...                   index=[""tiger"", ""leopard"", ""cheetah"", ""lion""])
>>> df
          a  b  c
  tiger   1  8  2
leopard   1  2  5
cheetah   2  5  8
   lion   2  6  9
>>> df.groupby(""a"").min()
    b  c
a
1   2  2
2   5  8
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.min.html, pandas.DataFrame pandas.DataFrame.groupby
">>> df = pd.DataFrame({""A"": pd.arrays.SparseArray([0, 1, 0, 1])})
>>> df.sparse.to_coo()
<4x1 sparse matrix of type ''
        with 2 stored elements in COOrdinate format>
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sparse.to_coo.html, pandas.DataFrame pandas.arrays.SparseArray pandas.DataFrame.sparse.to_coo
">>> df = pd.DataFrame([[1, 2, 3],
...                    [4, 5, 6],
...                    [7, 8, 9],
...                    [np.nan, np.nan, np.nan]],
...                   columns=['A', 'B', 'C'])
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.agg.html, pandas.DataFrame
">>> df.agg(['sum', 'min'])
        A     B     C
sum  12.0  15.0  18.0
min   1.0   2.0   3.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.agg.html, pandas.DataFrame.agg
">>> df.agg({'A' : ['sum', 'min'], 'B' : ['min', 'max']})
        A    B
sum  12.0  NaN
min   1.0  2.0
max   NaN  8.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.agg.html, pandas.DataFrame.agg
">>> df.agg(x=('A', 'max'), y=('B', 'min'), z=('C', 'mean'))
     A    B    C
x  7.0  NaN  NaN
y  NaN  2.0  NaN
z  NaN  NaN  6.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.agg.html, pandas.DataFrame.agg
">>> df.agg(""mean"", axis=""columns"")
0    2.0
1    5.0
2    8.0
3    NaN
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.agg.html, pandas.DataFrame.agg
">>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]})
>>> df
     B
0  0.0
1  1.0
2  2.0
3  NaN
4  4.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.ewm.html, pandas.DataFrame
">>> df.ewm(com=0.5).mean()
          B
0  0.000000
1  0.750000
2  1.615385
3  1.615385
4  3.670213
>>> df.ewm(alpha=2 / 3).mean()
          B
0  0.000000
1  0.750000
2  1.615385
3  1.615385
4  3.670213
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.ewm.html, pandas.DataFrame.ewm
">>> df.ewm(com=0.5, adjust=True).mean()
          B
0  0.000000
1  0.750000
2  1.615385
3  1.615385
4  3.670213
>>> df.ewm(com=0.5, adjust=False).mean()
          B
0  0.000000
1  0.666667
2  1.555556
3  1.555556
4  3.650794
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.ewm.html, pandas.DataFrame.ewm
">>> df.ewm(com=0.5, ignore_na=True).mean()
          B
0  0.000000
1  0.750000
2  1.615385
3  1.615385
4  3.225000
>>> df.ewm(com=0.5, ignore_na=False).mean()
          B
0  0.000000
1  0.750000
2  1.615385
3  1.615385
4  3.670213
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.ewm.html, pandas.DataFrame.ewm
">>> times = ['2020-01-01', '2020-01-03', '2020-01-10', '2020-01-15', '2020-01-17']
>>> df.ewm(halflife='4 days', times=pd.DatetimeIndex(times)).mean()
          B
0  0.000000
1  0.585786
2  1.523889
3  1.523889
4  3.233686
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.ewm.html, pandas.DataFrame.ewm pandas.DatetimeIndex
">>> s = pd.Series([2, np.nan, 5, -1, 0])
>>> s
0    2.0
1    NaN
2    5.0
3   -1.0
4    0.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.cummax.html, pandas.Series
">>> s.cummax()
0    2.0
1    NaN
2    5.0
3    5.0
4    5.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.cummax.html, pandas.Series.cummax
">>> s.cummax(skipna=False)
0    2.0
1    NaN
2    NaN
3    NaN
4    NaN
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.cummax.html, pandas.Series.cummax
">>> df = pd.DataFrame([[2.0, 1.0],
...                    [3.0, np.nan],
...                    [1.0, 0.0]],
...                   columns=list('AB'))
>>> df
     A    B
0  2.0  1.0
1  3.0  NaN
2  1.0  0.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.cummax.html, pandas.DataFrame
">>> df.cummax()
     A    B
0  2.0  1.0
1  3.0  NaN
2  3.0  1.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.cummax.html, pandas.DataFrame.cummax
">>> df.cummax(axis=1)
     A    B
0  2.0  2.0
1  3.0  NaN
2  1.0  1.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.cummax.html, pandas.DataFrame.cummax
">>> df = pd.DataFrame(np.random.randint(1, 7, 6000), columns=['one'])
>>> df['two'] = df['one'] + np.random.randint(1, 7, 6000)
>>> ax = df.plot.hist(bins=12, alpha=0.5)
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.hist.html, pandas.DataFrame pandas.DataFrame.plot.hist
">>> age_list = [8, 10, 12, 14, 72, 74, 76, 78, 20, 25, 30, 35, 60, 85]
>>> df = pd.DataFrame({""gender"": list(""MMMMMMMMFFFFFF""), ""age"": age_list})
>>> ax = df.plot.hist(column=[""age""], by=""gender"", figsize=(10, 8))
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.hist.html, pandas.DataFrame pandas.DataFrame.plot.hist
">>> df = pd.DataFrame({'animal': ['alligator', 'bee', 'falcon', 'lion',
...                    'monkey', 'parrot', 'shark', 'whale', 'zebra']})
>>> df
      animal
0  alligator
1        bee
2     falcon
3       lion
4     monkey
5     parrot
6      shark
7      whale
8      zebra
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html, pandas.DataFrame
">>> df.head()
      animal
0  alligator
1        bee
2     falcon
3       lion
4     monkey
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html, pandas.DataFrame.head
">>> df.head(3)
      animal
0  alligator
1        bee
2     falcon
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html, pandas.DataFrame.head
">>> df.head(-3)
      animal
0  alligator
1        bee
2     falcon
3       lion
4     monkey
5     parrot
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html, pandas.DataFrame.head
">>> df = pd.DataFrame({'A': [1, 2, 3],
...                    'B': [400, 500, 600]})
>>> new_df = pd.DataFrame({'B': [4, 5, 6],
...                        'C': [7, 8, 9]})
>>> df.update(new_df)
>>> df
   A  B
0  1  4
1  2  5
2  3  6
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.update.html, pandas.DataFrame pandas.DataFrame.update
">>> df = pd.DataFrame({'A': ['a', 'b', 'c'],
...                    'B': ['x', 'y', 'z']})
>>> new_df = pd.DataFrame({'B': ['d', 'e', 'f', 'g', 'h', 'i']})
>>> df.update(new_df)
>>> df
   A  B
0  a  d
1  b  e
2  c  f
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.update.html, pandas.DataFrame pandas.DataFrame.update
">>> df = pd.DataFrame({'A': ['a', 'b', 'c'],
...                    'B': ['x', 'y', 'z']})
>>> new_df = pd.DataFrame({'B': ['d', 'f']}, index=[0, 2])
>>> df.update(new_df)
>>> df
   A  B
0  a  d
1  b  y
2  c  f
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.update.html, pandas.DataFrame pandas.DataFrame.update
">>> df = pd.DataFrame({'A': ['a', 'b', 'c'],
...                    'B': ['x', 'y', 'z']})
>>> new_column = pd.Series(['d', 'e', 'f'], name='B')
>>> df.update(new_column)
>>> df
   A  B
0  a  d
1  b  e
2  c  f
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.update.html, pandas.DataFrame pandas.Series pandas.DataFrame.update
">>> df = pd.DataFrame({'A': [1, 2, 3],
...                    'B': [400., 500., 600.]})
>>> new_df = pd.DataFrame({'B': [4, np.nan, 6]})
>>> df.update(new_df)
>>> df
   A      B
0  1    4.0
1  2  500.0
2  3    6.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.update.html, pandas.DataFrame pandas.DataFrame.update
">>> df = pd.DataFrame(
...     data={""animal_1"": [""elk"", ""pig""], ""animal_2"": [""dog"", ""quetzal""]}
... )
>>> print(df.to_markdown())
|    | animal_1   | animal_2   |
|---:|:-----------|:-----------|
|  0 | elk        | dog        |
|  1 | pig        | quetzal    |
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_markdown.html, pandas.DataFrame pandas.DataFrame.to_markdown
">>> print(df.to_markdown(tablefmt=""grid""))
+----+------------+------------+
|    | animal_1   | animal_2   |
+====+============+============+
|  0 | elk        | dog        |
+----+------------+------------+
|  1 | pig        | quetzal    |
+----+------------+------------+
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_markdown.html, pandas.DataFrame.to_markdown
">>> df1 = pd.DataFrame({'lkey': ['foo', 'bar', 'baz', 'foo'],
...                     'value': [1, 2, 3, 5]})
>>> df2 = pd.DataFrame({'rkey': ['foo', 'bar', 'baz', 'foo'],
...                     'value': [5, 6, 7, 8]})
>>> df1
    lkey value
0   foo      1
1   bar      2
2   baz      3
3   foo      5
>>> df2
    rkey value
0   foo      5
1   bar      6
2   baz      7
3   foo      8
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html, pandas.DataFrame
">>> df1.merge(df2, left_on='lkey', right_on='rkey')
  lkey  value_x rkey  value_y
0  foo        1  foo        5
1  foo        1  foo        8
2  bar        2  bar        6
3  baz        3  baz        7
4  foo        5  foo        5
5  foo        5  foo        8
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html, pandas.DataFrame.merge
">>> df1.merge(df2, left_on='lkey', right_on='rkey',
...           suffixes=('_left', '_right'))
  lkey  value_left rkey  value_right
0  foo           1  foo            5
1  foo           1  foo            8
2  bar           2  bar            6
3  baz           3  baz            7
4  foo           5  foo            5
5  foo           5  foo            8
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html, pandas.DataFrame.merge
">>> df1.merge(df2, left_on='lkey', right_on='rkey', suffixes=(False, False))
Traceback (most recent call last):
...
ValueError: columns overlap but no suffix specified:
    Index(['value'], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html, pandas.DataFrame.merge pandas.Index
">>> df1 = pd.DataFrame({'a': ['foo', 'bar'], 'b': [1, 2]})
>>> df2 = pd.DataFrame({'a': ['foo', 'baz'], 'c': [3, 4]})
>>> df1
      a  b
0   foo  1
1   bar  2
>>> df2
      a  c
0   foo  3
1   baz  4
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html, pandas.DataFrame
">>> df1.merge(df2, how='inner', on='a')
      a  b  c
0   foo  1  3
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html, pandas.DataFrame.merge
">>> df1.merge(df2, how='left', on='a')
      a  b  c
0   foo  1  3.0
1   bar  2  NaN
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html, pandas.DataFrame.merge
">>> df1 = pd.DataFrame({'left': ['foo', 'bar']})
>>> df2 = pd.DataFrame({'right': [7, 8]})
>>> df1
    left
0   foo
1   bar
>>> df2
    right
0   7
1   8
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html, pandas.DataFrame
">>> df1.merge(df2, how='cross')
   left  right
0   foo      7
1   foo      8
2   bar      7
3   bar      8
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html, pandas.DataFrame.merge
">>> df = pd.DataFrame({'angles': [0, 3, 4],
...                    'degrees': [360, 180, 360]},
...                   index=['circle', 'triangle', 'rectangle'])
>>> df
           angles  degrees
circle          0      360
triangle        3      180
rectangle       4      360
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mul.html, pandas.DataFrame
">>> df.add(1)
           angles  degrees
circle          1      361
triangle        4      181
rectangle       5      361
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mul.html, pandas.DataFrame.add
">>> df.div(10)
           angles  degrees
circle        0.0     36.0
triangle      0.3     18.0
rectangle     0.4     36.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mul.html, pandas.DataFrame.div
">>> df.rdiv(10)
             angles   degrees
circle          inf  0.027778
triangle   3.333333  0.055556
rectangle  2.500000  0.027778
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mul.html, pandas.DataFrame.rdiv
">>> df.sub([1, 2], axis='columns')
           angles  degrees
circle         -1      358
triangle        2      178
rectangle       3      358
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mul.html, pandas.DataFrame.sub
">>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),
...        axis='index')
           angles  degrees
circle         -1      359
triangle        2      179
rectangle       3      359
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mul.html, pandas.DataFrame.sub pandas.Series
">>> df.mul({'angles': 0, 'degrees': 2})
            angles  degrees
circle           0      720
triangle         0      360
rectangle        0      720
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mul.html, pandas.DataFrame.mul
">>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')
            angles  degrees
circle           0        0
triangle         6      360
rectangle       12     1080
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mul.html, pandas.DataFrame.mul
">>> other = pd.DataFrame({'angles': [0, 3, 4]},
...                      index=['circle', 'triangle', 'rectangle'])
>>> other
           angles
circle          0
triangle        3
rectangle       4
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mul.html, pandas.DataFrame
">>> df.mul(other, fill_value=0)
           angles  degrees
circle          0      0.0
triangle        9      0.0
rectangle      16      0.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mul.html, pandas.DataFrame.mul
">>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],
...                              'degrees': [360, 180, 360, 360, 540, 720]},
...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],
...                                    ['circle', 'triangle', 'rectangle',
...                                     'square', 'pentagon', 'hexagon']])
>>> df_multindex
             angles  degrees
A circle          0      360
  triangle        3      180
  rectangle       4      360
B square          4      360
  pentagon        5      540
  hexagon         6      720
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mul.html, pandas.DataFrame
">>> df.div(df_multindex, level=1, fill_value=0)
             angles  degrees
A circle        NaN      1.0
  triangle      1.0      1.0
  rectangle     1.0      1.0
B square        0.0      0.0
  pentagon      0.0      0.0
  hexagon       0.0      0.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mul.html, pandas.DataFrame.div
">>> df = pd.DataFrame()
>>> df.flags

>>> df.flags.allows_duplicate_labels = False
>>> df.flags

",https://pandas.pydata.org/docs/reference/api/pandas.Flags.html, pandas.DataFrame
">>> df = pd.DataFrame({'person_id': [0, 1, 2, 3],
...                    'age': [21, 25, 62, 43],
...                    'height': [1.61, 1.87, 1.49, 2.01]}
...                   ).set_index('person_id')
>>> df
           age  height
person_id
0           21    1.61
1           25    1.87
2           62    1.49
3           43    2.01
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.std.html, pandas.DataFrame pandas.DataFrame.set_index
">>> df.std()
age       18.786076
height     0.237417
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.std.html, pandas.DataFrame.std
">>> df.std(ddof=0)
age       16.269219
height     0.205609
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.std.html, pandas.DataFrame.std
">>> df = pd.DataFrame([
...     [1, 2, 3, 4],
...     [5, 6, 7, 8],
...     [9, 10, 11, 12]
... ]).set_index([0, 1]).rename_axis(['a', 'b'])
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.droplevel.html, pandas.DataFrame pandas.DataFrame.set_index
">>> df.columns = pd.MultiIndex.from_tuples([
...     ('c', 'e'), ('d', 'f')
... ], names=['level_1', 'level_2'])
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.droplevel.html, pandas.MultiIndex.from_tuples
">>> df.droplevel('a')
level_1   c   d
level_2   e   f
b
2        3   4
6        7   8
10      11  12
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.droplevel.html, pandas.DataFrame.droplevel
">>> df.droplevel('level_2', axis=1)
level_1   c   d
a b
1 2      3   4
5 6      7   8
9 10    11  12
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.droplevel.html, pandas.DataFrame.droplevel
">>> d = {'num_legs': [4, 4, 2, 2],
...      'num_wings': [0, 0, 2, 2],
...      'class': ['mammal', 'mammal', 'mammal', 'bird'],
...      'animal': ['cat', 'dog', 'bat', 'penguin'],
...      'locomotion': ['walks', 'walks', 'flies', 'walks']}
>>> df = pd.DataFrame(data=d)
>>> df = df.set_index(['class', 'animal', 'locomotion'])
>>> df
                           num_legs  num_wings
class  animal  locomotion
mammal cat     walks              4          0
       dog     walks              4          0
       bat     flies              2          2
bird   penguin walks              2          2
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.xs.html, pandas.DataFrame pandas.DataFrame.set_index
">>> df.xs('mammal')
                   num_legs  num_wings
animal locomotion
cat    walks              4          0
dog    walks              4          0
bat    flies              2          2
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.xs.html, pandas.DataFrame.xs
">>> df.xs(('mammal', 'dog', 'walks'))
num_legs     4
num_wings    0
Name: (mammal, dog, walks), dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.xs.html, pandas.DataFrame.xs
">>> df.xs('cat', level=1)
                   num_legs  num_wings
class  locomotion
mammal walks              4          0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.xs.html, pandas.DataFrame.xs
">>> df.xs(('bird', 'walks'),
...       level=[0, 'locomotion'])
         num_legs  num_wings
animal
penguin         2          2
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.xs.html, pandas.DataFrame.xs
">>> df.xs('num_wings', axis=1)
class   animal   locomotion
mammal  cat      walks         0
        dog      walks         0
        bat      flies         2
bird    penguin  walks         2
Name: num_wings, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.xs.html, pandas.DataFrame.xs
">>> s = pd.Series([1, 2, 2.5, 3, 3.5, 4, 5])
>>> ax = s.plot.kde()
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.kde.html, pandas.Series pandas.Series.plot.kde
">>> ax = s.plot.kde(bw_method=0.3)
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.kde.html, pandas.Series.plot.kde
">>> ax = s.plot.kde(bw_method=3)
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.kde.html, pandas.Series.plot.kde
">>> ax = s.plot.kde(ind=[1, 2, 3, 4, 5])
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.kde.html, pandas.Series.plot.kde
">>> df = pd.DataFrame({
...     'x': [1, 2, 2.5, 3, 3.5, 4, 5],
...     'y': [4, 4, 4.5, 5, 5.5, 6, 6],
... })
>>> ax = df.plot.kde()
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.kde.html, pandas.DataFrame pandas.DataFrame.plot.kde
">>> ax = df.plot.kde(bw_method=0.3)
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.kde.html, pandas.DataFrame.plot.kde
">>> ax = df.plot.kde(bw_method=3)
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.kde.html, pandas.DataFrame.plot.kde
">>> ax = df.plot.kde(ind=[1, 2, 3, 4, 5, 6])
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.kde.html, pandas.DataFrame.plot.kde
">>> d = {'col1': [1, 2], 'col2': [3, 4]}
>>> df = pd.DataFrame(data=d)
>>> df.dtypes
col1    int64
col2    int64
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.astype.html, pandas.DataFrame
">>> df.astype('int32').dtypes
col1    int32
col2    int32
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.astype.html, pandas.DataFrame.astype
">>> df.astype({'col1': 'int32'}).dtypes
col1    int32
col2    int64
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.astype.html, pandas.DataFrame.astype
">>> ser = pd.Series([1, 2], dtype='int32')
>>> ser
0    1
1    2
dtype: int32
>>> ser.astype('int64')
0    1
1    2
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.astype.html, pandas.Series pandas.Series.astype
">>> ser.astype('category')
0    1
1    2
dtype: category
Categories (2, int32): [1, 2]
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.astype.html, pandas.Series.astype
">>> from pandas.api.types import CategoricalDtype
>>> cat_dtype = CategoricalDtype(
...     categories=[2, 1], ordered=True)
>>> ser.astype(cat_dtype)
0    1
1    2
dtype: category
Categories (2, int64): [2 < 1]
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.astype.html, pandas.CategoricalDtype pandas.Series.astype
">>> ser_date = pd.Series(pd.date_range('20200101', periods=3))
>>> ser_date
0   2020-01-01
1   2020-01-02
2   2020-01-03
dtype: datetime64[ns]
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.astype.html, pandas.Series pandas.date_range
">>> lst = ['a', 'a', 'b', 'b']
>>> ser = pd.Series([1, 2, 3, 4], index=lst)
>>> ser
a    1
a    2
b    3
b    4
dtype: int64
>>> ser.groupby(level=0).pct_change()
a         NaN
a    1.000000
b         NaN
b    0.333333
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.pct_change.html, pandas.Series pandas.Series.groupby
">>> data = [[1, 2, 3], [1, 5, 6], [2, 5, 8], [2, 6, 9]]
>>> df = pd.DataFrame(data, columns=[""a"", ""b"", ""c""],
...                   index=[""tuna"", ""salmon"", ""catfish"", ""goldfish""])
>>> df
           a  b  c
    tuna   1  2  3
  salmon   1  5  6
 catfish   2  5  8
goldfish   2  6  9
>>> df.groupby(""a"").pct_change()
            b  c
    tuna    NaN    NaN
  salmon    1.5  1.000
 catfish    NaN    NaN
goldfish    0.2  0.125
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.pct_change.html, pandas.DataFrame pandas.DataFrame.groupby
">>> pd.Series([True, True]).all()
True
>>> pd.Series([True, False]).all()
False
>>> pd.Series([], dtype=""float64"").all()
True
>>> pd.Series([np.nan]).all()
True
>>> pd.Series([np.nan]).all(skipna=False)
True
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.all.html, pandas.Series
">>> df = pd.DataFrame({'col1': [True, True], 'col2': [True, False]})
>>> df
   col1   col2
0  True   True
1  True  False
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.all.html, pandas.DataFrame
">>> df.all()
col1     True
col2    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.all.html, pandas.DataFrame.all
">>> df.all(axis='columns')
0     True
1    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.all.html, pandas.DataFrame.all
">>> df.all(axis=None)
False
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.all.html, pandas.DataFrame.all
">>> df = pd.DataFrame({'num_legs': [2, 4, 4, 6],
...                    'num_wings': [2, 0, 0, 0]},
...                   index=['falcon', 'dog', 'cat', 'ant'])
>>> df
        num_legs  num_wings
falcon         2          2
dog            4          0
cat            4          0
ant            6          0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.value_counts.html, pandas.DataFrame
">>> df.value_counts()
num_legs  num_wings
4         0            2
2         2            1
6         0            1
Name: count, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.value_counts.html, pandas.DataFrame.value_counts
">>> df.value_counts(sort=False)
num_legs  num_wings
2         2            1
4         0            2
6         0            1
Name: count, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.value_counts.html, pandas.DataFrame.value_counts
">>> df.value_counts(ascending=True)
num_legs  num_wings
2         2            1
6         0            1
4         0            2
Name: count, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.value_counts.html, pandas.DataFrame.value_counts
">>> df.value_counts(normalize=True)
num_legs  num_wings
4         0            0.50
2         2            0.25
6         0            0.25
Name: proportion, dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.value_counts.html, pandas.DataFrame.value_counts
">>> df = pd.DataFrame({'first_name': ['John', 'Anne', 'John', 'Beth'],
...                    'middle_name': ['Smith', pd.NA, pd.NA, 'Louise']})
>>> df
  first_name middle_name
0       John       Smith
1       Anne        
2       John        
3       Beth      Louise
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.value_counts.html, pandas.DataFrame
">>> df.value_counts()
first_name  middle_name
Beth        Louise         1
John        Smith          1
Name: count, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.value_counts.html, pandas.DataFrame.value_counts
">>> df.value_counts(dropna=False)
first_name  middle_name
Anne        NaN            1
Beth        Louise         1
John        Smith          1
            NaN            1
Name: count, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.value_counts.html, pandas.DataFrame.value_counts
">>> df.value_counts(""first_name"")
first_name
John    2
Anne    1
Beth    1
Name: count, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.value_counts.html, pandas.DataFrame.value_counts
">>> df = pd.DataFrame(
...     [
...         [24.3, 75.7, ""high""],
...         [31, 87.8, ""high""],
...         [22, 71.6, ""medium""],
...         [35, 95, ""medium""],
...     ],
...     columns=[""temp_celsius"", ""temp_fahrenheit"", ""windspeed""],
...     index=pd.date_range(start=""2014-02-12"", end=""2014-02-15"", freq=""D""),
... )
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.get.html, pandas.DataFrame pandas.date_range
">>> df.get([""temp_celsius"", ""windspeed""])
            temp_celsius windspeed
2014-02-12          24.3      high
2014-02-13          31.0      high
2014-02-14          22.0    medium
2014-02-15          35.0    medium
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.get.html, pandas.DataFrame.get
">>> ser = df['windspeed']
>>> ser.get('2014-02-13')
'high'
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.get.html, pandas.Series.get
">>> df.get([""temp_celsius"", ""temp_kelvin""], default=""default_value"")
'default_value'
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.get.html, pandas.DataFrame.get
">>> ser.get('2014-02-10', '[unknown]')
'[unknown]'
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.get.html, pandas.Series.get
">>> df = pd.DataFrame({'angles': [0, 3, 4],
...                    'degrees': [360, 180, 360]},
...                   index=['circle', 'triangle', 'rectangle'])
>>> df
           angles  degrees
circle          0      360
triangle        3      180
rectangle       4      360
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.floordiv.html, pandas.DataFrame
">>> df.add(1)
           angles  degrees
circle          1      361
triangle        4      181
rectangle       5      361
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.floordiv.html, pandas.DataFrame.add
">>> df.div(10)
           angles  degrees
circle        0.0     36.0
triangle      0.3     18.0
rectangle     0.4     36.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.floordiv.html, pandas.DataFrame.div
">>> df.rdiv(10)
             angles   degrees
circle          inf  0.027778
triangle   3.333333  0.055556
rectangle  2.500000  0.027778
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.floordiv.html, pandas.DataFrame.rdiv
">>> df.sub([1, 2], axis='columns')
           angles  degrees
circle         -1      358
triangle        2      178
rectangle       3      358
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.floordiv.html, pandas.DataFrame.sub
">>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),
...        axis='index')
           angles  degrees
circle         -1      359
triangle        2      179
rectangle       3      359
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.floordiv.html, pandas.DataFrame.sub pandas.Series
">>> df.mul({'angles': 0, 'degrees': 2})
            angles  degrees
circle           0      720
triangle         0      360
rectangle        0      720
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.floordiv.html, pandas.DataFrame.mul
">>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')
            angles  degrees
circle           0        0
triangle         6      360
rectangle       12     1080
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.floordiv.html, pandas.DataFrame.mul
">>> other = pd.DataFrame({'angles': [0, 3, 4]},
...                      index=['circle', 'triangle', 'rectangle'])
>>> other
           angles
circle          0
triangle        3
rectangle       4
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.floordiv.html, pandas.DataFrame
">>> df.mul(other, fill_value=0)
           angles  degrees
circle          0      0.0
triangle        9      0.0
rectangle      16      0.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.floordiv.html, pandas.DataFrame.mul
">>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],
...                              'degrees': [360, 180, 360, 360, 540, 720]},
...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],
...                                    ['circle', 'triangle', 'rectangle',
...                                     'square', 'pentagon', 'hexagon']])
>>> df_multindex
             angles  degrees
A circle          0      360
  triangle        3      180
  rectangle       4      360
B square          4      360
  pentagon        5      540
  hexagon         6      720
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.floordiv.html, pandas.DataFrame
">>> df.div(df_multindex, level=1, fill_value=0)
             angles  degrees
A circle        NaN      1.0
  triangle      1.0      1.0
  rectangle     1.0      1.0
B square        0.0      0.0
  pentagon      0.0      0.0
  hexagon       0.0      0.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.floordiv.html, pandas.DataFrame.div
">>> df = pd.DataFrame(np.array(([1, 2, 3], [4, 5, 6])),
...                   index=['mouse', 'rabbit'],
...                   columns=['one', 'two', 'three'])
>>> df
        one  two  three
mouse     1    2      3
rabbit    4    5      6
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.filter.html, pandas.DataFrame
">>> # select columns by name
>>> df.filter(items=['one', 'three'])
         one  three
mouse     1      3
rabbit    4      6
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.filter.html, pandas.DataFrame.filter
">>> # select columns by regular expression
>>> df.filter(regex='e$', axis=1)
         one  three
mouse     1      3
rabbit    4      6
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.filter.html, pandas.DataFrame.filter
">>> # select rows containing 'bbi'
>>> df.filter(like='bbi', axis=0)
         one  two  three
rabbit    4    5      6
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.filter.html, pandas.DataFrame.filter
">>> df = pd.DataFrame({'temp_c': [17.0, 25.0]},
...                   index=['Portland', 'Berkeley'])
>>> df
          temp_c
Portland    17.0
Berkeley    25.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.assign.html, pandas.DataFrame
">>> df.assign(temp_f=lambda x: x.temp_c * 9 / 5 + 32)
          temp_c  temp_f
Portland    17.0    62.6
Berkeley    25.0    77.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.assign.html, pandas.DataFrame.assign
">>> df.assign(temp_f=df['temp_c'] * 9 / 5 + 32)
          temp_c  temp_f
Portland    17.0    62.6
Berkeley    25.0    77.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.assign.html, pandas.DataFrame.assign
">>> df.assign(temp_f=lambda x: x['temp_c'] * 9 / 5 + 32,
...           temp_k=lambda x: (x['temp_f'] + 459.67) * 5 / 9)
          temp_c  temp_f  temp_k
Portland    17.0    62.6  290.15
Berkeley    25.0    77.0  298.15
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.assign.html, pandas.DataFrame.assign
">>> df = pd.DataFrame({'angles': [0, 3, 4],
...                    'degrees': [360, 180, 360]},
...                   index=['circle', 'triangle', 'rectangle'])
>>> df
           angles  degrees
circle          0      360
triangle        3      180
rectangle       4      360
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rtruediv.html, pandas.DataFrame
">>> df.add(1)
           angles  degrees
circle          1      361
triangle        4      181
rectangle       5      361
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rtruediv.html, pandas.DataFrame.add
">>> df.div(10)
           angles  degrees
circle        0.0     36.0
triangle      0.3     18.0
rectangle     0.4     36.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rtruediv.html, pandas.DataFrame.div
">>> df.rdiv(10)
             angles   degrees
circle          inf  0.027778
triangle   3.333333  0.055556
rectangle  2.500000  0.027778
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rtruediv.html, pandas.DataFrame.rdiv
">>> df.sub([1, 2], axis='columns')
           angles  degrees
circle         -1      358
triangle        2      178
rectangle       3      358
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rtruediv.html, pandas.DataFrame.sub
">>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),
...        axis='index')
           angles  degrees
circle         -1      359
triangle        2      179
rectangle       3      359
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rtruediv.html, pandas.DataFrame.sub pandas.Series
">>> df.mul({'angles': 0, 'degrees': 2})
            angles  degrees
circle           0      720
triangle         0      360
rectangle        0      720
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rtruediv.html, pandas.DataFrame.mul
">>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')
            angles  degrees
circle           0        0
triangle         6      360
rectangle       12     1080
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rtruediv.html, pandas.DataFrame.mul
">>> other = pd.DataFrame({'angles': [0, 3, 4]},
...                      index=['circle', 'triangle', 'rectangle'])
>>> other
           angles
circle          0
triangle        3
rectangle       4
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rtruediv.html, pandas.DataFrame
">>> df.mul(other, fill_value=0)
           angles  degrees
circle          0      0.0
triangle        9      0.0
rectangle      16      0.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rtruediv.html, pandas.DataFrame.mul
">>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],
...                              'degrees': [360, 180, 360, 360, 540, 720]},
...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],
...                                    ['circle', 'triangle', 'rectangle',
...                                     'square', 'pentagon', 'hexagon']])
>>> df_multindex
             angles  degrees
A circle          0      360
  triangle        3      180
  rectangle       4      360
B square          4      360
  pentagon        5      540
  hexagon         6      720
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rtruediv.html, pandas.DataFrame
">>> df.div(df_multindex, level=1, fill_value=0)
             angles  degrees
A circle        NaN      1.0
  triangle      1.0      1.0
  rectangle     1.0      1.0
B square        0.0      0.0
  pentagon      0.0      0.0
  hexagon       0.0      0.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rtruediv.html, pandas.DataFrame.div
">>> df = pd.DataFrame({'foo': ['one', 'one', 'one', 'two', 'two',
...                            'two'],
...                    'bar': ['A', 'B', 'C', 'A', 'B', 'C'],
...                    'baz': [1, 2, 3, 4, 5, 6],
...                    'zoo': ['x', 'y', 'z', 'q', 'w', 't']})
>>> df
    foo   bar  baz  zoo
0   one   A    1    x
1   one   B    2    y
2   one   C    3    z
3   two   A    4    q
4   two   B    5    w
5   two   C    6    t
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pivot.html, pandas.DataFrame
">>> df.pivot(index='foo', columns='bar', values='baz')
bar  A   B   C
foo
one  1   2   3
two  4   5   6
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pivot.html, pandas.DataFrame.pivot
">>> df.pivot(index='foo', columns='bar')['baz']
bar  A   B   C
foo
one  1   2   3
two  4   5   6
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pivot.html, pandas.DataFrame.pivot
">>> df.pivot(index='foo', columns='bar', values=['baz', 'zoo'])
      baz       zoo
bar   A  B  C   A  B  C
foo
one   1  2  3   x  y  z
two   4  5  6   q  w  t
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pivot.html, pandas.DataFrame.pivot
">>> df = pd.DataFrame({
...        ""lev1"": [1, 1, 1, 2, 2, 2],
...        ""lev2"": [1, 1, 2, 1, 1, 2],
...        ""lev3"": [1, 2, 1, 2, 1, 2],
...        ""lev4"": [1, 2, 3, 4, 5, 6],
...        ""values"": [0, 1, 2, 3, 4, 5]})
>>> df
    lev1 lev2 lev3 lev4 values
0   1    1    1    1    0
1   1    1    2    2    1
2   1    2    1    3    2
3   2    1    2    4    3
4   2    1    1    5    4
5   2    2    2    6    5
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pivot.html, pandas.DataFrame
">>> df.pivot(index=""lev1"", columns=[""lev2"", ""lev3""], values=""values"")
lev2    1         2
lev3    1    2    1    2
lev1
1     0.0  1.0  2.0  NaN
2     4.0  3.0  NaN  5.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pivot.html, pandas.DataFrame.pivot
">>> df.pivot(index=[""lev1"", ""lev2""], columns=[""lev3""], values=""values"")
      lev3    1    2
lev1  lev2
   1     1  0.0  1.0
         2  2.0  NaN
   2     1  4.0  3.0
         2  NaN  5.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pivot.html, pandas.DataFrame.pivot
">>> df = pd.DataFrame({""foo"": ['one', 'one', 'two', 'two'],
...                    ""bar"": ['A', 'A', 'B', 'C'],
...                    ""baz"": [1, 2, 3, 4]})
>>> df
   foo bar  baz
0  one   A    1
1  one   A    2
2  two   B    3
3  two   C    4
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pivot.html, pandas.DataFrame
">>> df.pivot(index='foo', columns='bar', values='baz')
Traceback (most recent call last):
   ...
ValueError: Index contains duplicate entries, cannot reshape
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pivot.html, pandas.DataFrame.pivot
">>> pd.Series([], dtype=""float64"").prod()
1.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.product.html, pandas.Series
">>> pd.Series([], dtype=""float64"").prod(min_count=1)
nan
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.product.html, pandas.Series
">>> pd.Series([np.nan]).prod()
1.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.product.html, pandas.Series
">>> pd.Series([np.nan]).prod(min_count=1)
nan
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.product.html, pandas.Series
">>> df = pd.DataFrame({""A"": [1, 2]})
>>> df.flags.allows_duplicate_labels
True
>>> df2 = df.set_flags(allows_duplicate_labels=False)
>>> df2.flags.allows_duplicate_labels
False
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.set_flags.html, pandas.DataFrame pandas.DataFrame.set_flags
">>> int_values = [1, 2, 3, 4, 5]
>>> text_values = ['alpha', 'beta', 'gamma', 'delta', 'epsilon']
>>> float_values = [0.0, 0.25, 0.5, 0.75, 1.0]
>>> df = pd.DataFrame({""int_col"": int_values, ""text_col"": text_values,
...                   ""float_col"": float_values})
>>> df
    int_col text_col  float_col
0        1    alpha       0.00
1        2     beta       0.25
2        3    gamma       0.50
3        4    delta       0.75
4        5  epsilon       1.00
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html, pandas.DataFrame
">>> df.info(verbose=True)

RangeIndex: 5 entries, 0 to 4
Data columns (total 3 columns):
 #   Column     Non-Null Count  Dtype
---  ------     --------------  -----
 0   int_col    5 non-null      int64
 1   text_col   5 non-null      object
 2   float_col  5 non-null      float64
dtypes: float64(1), int64(1), object(1)
memory usage: 248.0+ bytes
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html, pandas.DataFrame.info
">>> df.info(verbose=False)

RangeIndex: 5 entries, 0 to 4
Columns: 3 entries, int_col to float_col
dtypes: float64(1), int64(1), object(1)
memory usage: 248.0+ bytes
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html, pandas.DataFrame.info
">>> import io
>>> buffer = io.StringIO()
>>> df.info(buf=buffer)
>>> s = buffer.getvalue()
>>> with open(""df_info.txt"", ""w"",
...           encoding=""utf-8"") as f:  
...     f.write(s)
260
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html, pandas.DataFrame.info
">>> random_strings_array = np.random.choice(['a', 'b', 'c'], 10 ** 6)
>>> df = pd.DataFrame({
...     'column_1': np.random.choice(['a', 'b', 'c'], 10 ** 6),
...     'column_2': np.random.choice(['a', 'b', 'c'], 10 ** 6),
...     'column_3': np.random.choice(['a', 'b', 'c'], 10 ** 6)
... })
>>> df.info()

RangeIndex: 1000000 entries, 0 to 999999
Data columns (total 3 columns):
 #   Column    Non-Null Count    Dtype
---  ------    --------------    -----
 0   column_1  1000000 non-null  object
 1   column_2  1000000 non-null  object
 2   column_3  1000000 non-null  object
dtypes: object(3)
memory usage: 22.9+ MB
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html, pandas.DataFrame pandas.DataFrame.info
">>> df.info(memory_usage='deep')

RangeIndex: 1000000 entries, 0 to 999999
Data columns (total 3 columns):
 #   Column    Non-Null Count    Dtype
---  ------    --------------    -----
 0   column_1  1000000 non-null  object
 1   column_2  1000000 non-null  object
 2   column_3  1000000 non-null  object
dtypes: object(3)
memory usage: 165.9 MB
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html, pandas.DataFrame.info
">>> s = pd.Series([1, 2, 3])
>>> s.skew()
0.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.skew.html, pandas.Series pandas.Series.skew
">>> df = pd.DataFrame({'a': [1, 2, 3], 'b': [2, 3, 4], 'c': [1, 3, 5]},
...                   index=['tiger', 'zebra', 'cow'])
>>> df
        a   b   c
tiger   1   2   1
zebra   2   3   3
cow     3   4   5
>>> df.skew()
a   0.0
b   0.0
c   0.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.skew.html, pandas.DataFrame pandas.DataFrame.skew
">>> df.skew(axis=1)
tiger   1.732051
zebra  -1.732051
cow     0.000000
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.skew.html, pandas.DataFrame.skew
">>> df = pd.DataFrame({'a': [1, 2, 3], 'b': ['T', 'Z', 'X']},
...                   index=['tiger', 'zebra', 'cow'])
>>> df.skew(numeric_only=True)
a   0.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.skew.html, pandas.DataFrame pandas.DataFrame.skew
">>> df = pd.DataFrame({'month': [1, 4, 7, 10],
...                    'year': [2012, 2014, 2013, 2014],
...                    'sale': [55, 40, 84, 31]})
>>> df
   month  year  sale
0      1  2012    55
1      4  2014    40
2      7  2013    84
3     10  2014    31
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.set_index.html, pandas.DataFrame
">>> df.set_index('month')
       year  sale
month
1      2012    55
4      2014    40
7      2013    84
10     2014    31
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.set_index.html, pandas.DataFrame.set_index
">>> df.set_index(['year', 'month'])
            sale
year  month
2012  1     55
2014  4     40
2013  7     84
2014  10    31
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.set_index.html, pandas.DataFrame.set_index
">>> df.set_index([pd.Index([1, 2, 3, 4]), 'year'])
         month  sale
   year
1  2012  1      55
2  2014  4      40
3  2013  7      84
4  2014  10     31
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.set_index.html, pandas.DataFrame.set_index pandas.Index
">>> s = pd.Series([1, 2, 3, 4])
>>> df.set_index([s, s**2])
      month  year  sale
1 1       1  2012    55
2 4       4  2014    40
3 9       7  2013    84
4 16     10  2014    31
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.set_index.html, pandas.Series pandas.DataFrame.set_index
">>> df = pd.DataFrame({'a': [1, 2, 3, 4, 5, 6],
...                    'b': [1, 1, 2, 3, 5, 8],
...                    'c': [1, 4, 9, 16, 25, 36]})
>>> df
   a  b   c
0  1  1   1
1  2  1   4
2  3  2   9
3  4  3  16
4  5  5  25
5  6  8  36
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.diff.html, pandas.DataFrame
">>> df.diff()
     a    b     c
0  NaN  NaN   NaN
1  1.0  0.0   3.0
2  1.0  1.0   5.0
3  1.0  1.0   7.0
4  1.0  2.0   9.0
5  1.0  3.0  11.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.diff.html, pandas.DataFrame.diff
">>> df.diff(axis=1)
    a  b   c
0 NaN  0   0
1 NaN -1   3
2 NaN -1   7
3 NaN -1  13
4 NaN  0  20
5 NaN  2  28
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.diff.html, pandas.DataFrame.diff
">>> df.diff(periods=3)
     a    b     c
0  NaN  NaN   NaN
1  NaN  NaN   NaN
2  NaN  NaN   NaN
3  3.0  2.0  15.0
4  3.0  4.0  21.0
5  3.0  6.0  27.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.diff.html, pandas.DataFrame.diff
">>> df.diff(periods=-1)
     a    b     c
0 -1.0  0.0  -3.0
1 -1.0 -1.0  -5.0
2 -1.0 -1.0  -7.0
3 -1.0 -2.0  -9.0
4 -1.0 -3.0 -11.0
5  NaN  NaN   NaN
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.diff.html, pandas.DataFrame.diff
">>> df = pd.DataFrame({'a': [1, 0]}, dtype=np.uint8)
>>> df.diff()
       a
0    NaN
1  255.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.diff.html, pandas.DataFrame pandas.DataFrame.diff
">>> df1 = pd.DataFrame({'A': [0, 0], 'B': [4, 4]})
>>> df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})
>>> take_smaller = lambda s1, s2: s1 if s1.sum() < s2.sum() else s2
>>> df1.combine(df2, take_smaller)
   A  B
0  0  3
1  0  3
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.combine.html, pandas.DataFrame pandas.Series.sum pandas.Series.sum pandas.DataFrame.combine
">>> df1 = pd.DataFrame({'A': [5, 0], 'B': [2, 4]})
>>> df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})
>>> df1.combine(df2, np.minimum)
   A  B
0  1  2
1  0  3
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.combine.html, pandas.DataFrame pandas.DataFrame.combine
">>> df1 = pd.DataFrame({'A': [0, 0], 'B': [None, 4]})
>>> df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})
>>> df1.combine(df2, take_smaller, fill_value=-5)
   A    B
0  0 -5.0
1  0  4.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.combine.html, pandas.DataFrame pandas.DataFrame.combine
">>> df1 = pd.DataFrame({'A': [0, 0], 'B': [None, 4]})
>>> df2 = pd.DataFrame({'A': [1, 1], 'B': [None, 3]})
>>> df1.combine(df2, take_smaller, fill_value=-5)
    A    B
0  0 -5.0
1  0  3.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.combine.html, pandas.DataFrame pandas.DataFrame.combine
">>> df1 = pd.DataFrame({'A': [0, 0], 'B': [4, 4]})
>>> df2 = pd.DataFrame({'B': [3, 3], 'C': [-10, 1], }, index=[1, 2])
>>> df1.combine(df2, take_smaller)
     A    B     C
0  NaN  NaN   NaN
1  NaN  3.0 -10.0
2  NaN  3.0   1.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.combine.html, pandas.DataFrame pandas.DataFrame.combine
">>> df1.combine(df2, take_smaller, overwrite=False)
     A    B     C
0  0.0  NaN   NaN
1  0.0  3.0 -10.0
2  NaN  3.0   1.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.combine.html, pandas.DataFrame.combine
">>> df2 = pd.DataFrame({'B': [3, 3], 'C': [1, 1], }, index=[1, 2])
>>> df2.combine(df1, take_smaller)
   A    B   C
0  0.0  NaN NaN
1  0.0  3.0 NaN
2  NaN  3.0 NaN
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.combine.html, pandas.DataFrame pandas.DataFrame.combine
">>> df2.combine(df1, take_smaller, overwrite=False)
     A    B   C
0  0.0  NaN NaN
1  0.0  3.0 1.0
2  NaN  3.0 1.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.combine.html, pandas.DataFrame.combine
">>> df = pd.DataFrame({'cost': [250, 150, 100],
...                    'revenue': [100, 250, 300]},
...                   index=['A', 'B', 'C'])
>>> df
   cost  revenue
A   250      100
B   150      250
C   100      300
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.ge.html, pandas.DataFrame
">>> df.eq(100)
    cost  revenue
A  False     True
B  False    False
C   True    False
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.ge.html, pandas.DataFrame.eq
">>> df != pd.Series([100, 250], index=[""cost"", ""revenue""])
    cost  revenue
A   True     True
B   True    False
C  False     True
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.ge.html, pandas.Series
">>> df.ne(pd.Series([100, 300], index=[""A"", ""D""]), axis='index')
   cost  revenue
A  True    False
B  True     True
C  True     True
D  True     True
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.ge.html, pandas.DataFrame.ne pandas.Series
">>> df.eq([250, 250, 100], axis='index')
    cost  revenue
A   True    False
B  False     True
C   True    False
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.ge.html, pandas.DataFrame.eq
">>> other = pd.DataFrame({'revenue': [300, 250, 100, 150]},
...                      index=['A', 'B', 'C', 'D'])
>>> other
   revenue
A      300
B      250
C      100
D      150
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.ge.html, pandas.DataFrame
">>> df.gt(other)
    cost  revenue
A  False    False
B  False    False
C  False     True
D  False    False
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.ge.html, pandas.DataFrame.gt
">>> df_multindex = pd.DataFrame({'cost': [250, 150, 100, 150, 300, 220],
...                              'revenue': [100, 250, 300, 200, 175, 225]},
...                             index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'],
...                                    ['A', 'B', 'C', 'A', 'B', 'C']])
>>> df_multindex
      cost  revenue
Q1 A   250      100
   B   150      250
   C   100      300
Q2 A   150      200
   B   300      175
   C   220      225
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.ge.html, pandas.DataFrame
">>> df.le(df_multindex, level=1)
       cost  revenue
Q1 A   True     True
   B   True     True
   C   True     True
Q2 A  False     True
   B   True    False
   C   True    False
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.ge.html, pandas.DataFrame.le
">>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})
>>> df
   col1  col2
0     1     3
1     2     4
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.T.html, pandas.DataFrame
">>> df = pd.DataFrame({""A"": pd.arrays.SparseArray([0, 1, 0])})
>>> df.sparse.to_dense()
   A
0  0
1  1
2  0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sparse.to_dense.html, pandas.DataFrame pandas.arrays.SparseArray pandas.DataFrame.sparse.to_dense
">>> df = pd.DataFrame({""name"": ['Alfred', 'Batman', 'Catwoman'],
...                    ""toy"": [np.nan, 'Batmobile', 'Bullwhip'],
...                    ""born"": [pd.NaT, pd.Timestamp(""1940-04-25""),
...                             pd.NaT]})
>>> df
       name        toy       born
0    Alfred        NaN        NaT
1    Batman  Batmobile 1940-04-25
2  Catwoman   Bullwhip        NaT
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html, pandas.DataFrame
">>> df.dropna()
     name        toy       born
1  Batman  Batmobile 1940-04-25
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html, pandas.DataFrame.dropna
">>> df.dropna(axis='columns')
       name
0    Alfred
1    Batman
2  Catwoman
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html, pandas.DataFrame.dropna
">>> df.dropna(how='all')
       name        toy       born
0    Alfred        NaN        NaT
1    Batman  Batmobile 1940-04-25
2  Catwoman   Bullwhip        NaT
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html, pandas.DataFrame.dropna
">>> df.dropna(thresh=2)
       name        toy       born
1    Batman  Batmobile 1940-04-25
2  Catwoman   Bullwhip        NaT
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html, pandas.DataFrame.dropna
">>> df.dropna(subset=['name', 'toy'])
       name        toy       born
1    Batman  Batmobile 1940-04-25
2  Catwoman   Bullwhip        NaT
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html, pandas.DataFrame.dropna
">>> df_single_level_cols = pd.DataFrame([[0, 1], [2, 3]],
...                                     index=['cat', 'dog'],
...                                     columns=['weight', 'height'])
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.stack.html, pandas.DataFrame
">>> df_single_level_cols
     weight height
cat       0      1
dog       2      3
>>> df_single_level_cols.stack(future_stack=True)
cat  weight    0
     height    1
dog  weight    2
     height    3
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.stack.html, pandas.DataFrame.stack
">>> multicol1 = pd.MultiIndex.from_tuples([('weight', 'kg'),
...                                        ('weight', 'pounds')])
>>> df_multi_level_cols1 = pd.DataFrame([[1, 2], [2, 4]],
...                                     index=['cat', 'dog'],
...                                     columns=multicol1)
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.stack.html, pandas.MultiIndex.from_tuples pandas.DataFrame
">>> df_multi_level_cols1
     weight
         kg    pounds
cat       1        2
dog       2        4
>>> df_multi_level_cols1.stack(future_stack=True)
            weight
cat kg           1
    pounds       2
dog kg           2
    pounds       4
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.stack.html, pandas.DataFrame.stack
">>> multicol2 = pd.MultiIndex.from_tuples([('weight', 'kg'),
...                                        ('height', 'm')])
>>> df_multi_level_cols2 = pd.DataFrame([[1.0, 2.0], [3.0, 4.0]],
...                                     index=['cat', 'dog'],
...                                     columns=multicol2)
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.stack.html, pandas.MultiIndex.from_tuples pandas.DataFrame
">>> df_multi_level_cols2
    weight height
        kg      m
cat    1.0    2.0
dog    3.0    4.0
>>> df_multi_level_cols2.stack(future_stack=True)
        weight  height
cat kg     1.0     NaN
    m      NaN     2.0
dog kg     3.0     NaN
    m      NaN     4.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.stack.html, pandas.DataFrame.stack
">>> df_multi_level_cols2.stack(0, future_stack=True)
             kg    m
cat weight  1.0  NaN
    height  NaN  2.0
dog weight  3.0  NaN
    height  NaN  4.0
>>> df_multi_level_cols2.stack([0, 1], future_stack=True)
cat  weight  kg    1.0
     height  m     2.0
dog  weight  kg    3.0
     height  m     4.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.stack.html, pandas.DataFrame.stack
">>> df = pd.DataFrame([('bird', 2, 2),
...                    ('mammal', 4, np.nan),
...                    ('arthropod', 8, 0),
...                    ('bird', 2, np.nan)],
...                   index=('falcon', 'horse', 'spider', 'ostrich'),
...                   columns=('species', 'legs', 'wings'))
>>> df
           species  legs  wings
falcon        bird     2    2.0
horse       mammal     4    NaN
spider   arthropod     8    0.0
ostrich       bird     2    NaN
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mode.html, pandas.DataFrame
">>> df.mode()
  species  legs  wings
0    bird   2.0    0.0
1     NaN   NaN    2.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mode.html, pandas.DataFrame.mode
">>> df.mode(dropna=False)
  species  legs  wings
0    bird     2    NaN
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mode.html, pandas.DataFrame.mode
">>> df.mode(numeric_only=True)
   legs  wings
0   2.0    0.0
1   NaN    2.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mode.html, pandas.DataFrame.mode
">>> df.mode(axis='columns', numeric_only=True)
           0    1
falcon   2.0  NaN
horse    4.0  NaN
spider   0.0  8.0
ostrich  2.0  NaN
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mode.html, pandas.DataFrame.mode
">>> df = pd.DataFrame({'animal': ['alligator', 'bee', 'falcon', 'lion',
...                    'monkey', 'parrot', 'shark', 'whale', 'zebra']})
>>> df
      animal
0  alligator
1        bee
2     falcon
3       lion
4     monkey
5     parrot
6      shark
7      whale
8      zebra
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.tail.html, pandas.DataFrame
">>> df.tail()
   animal
4  monkey
5  parrot
6   shark
7   whale
8   zebra
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.tail.html, pandas.DataFrame.tail
">>> df.tail(3)
  animal
6  shark
7  whale
8  zebra
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.tail.html, pandas.DataFrame.tail
">>> df.tail(-3)
   animal
3    lion
4  monkey
5  parrot
6   shark
7   whale
8   zebra
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.tail.html, pandas.DataFrame.tail
">>> df = pd.DataFrame(
...     {
...         ""col1"": [""a"", ""a"", ""b"", ""b"", ""a""],
...         ""col2"": [1.0, 2.0, 3.0, np.nan, 5.0],
...         ""col3"": [1.0, 2.0, 3.0, 4.0, 5.0]
...     },
...     columns=[""col1"", ""col2"", ""col3""],
... )
>>> df
  col1  col2  col3
0    a   1.0   1.0
1    a   2.0   2.0
2    b   3.0   3.0
3    b   NaN   4.0
4    a   5.0   5.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.compare.html, pandas.DataFrame
">>> df2 = df.copy()
>>> df2.loc[0, 'col1'] = 'c'
>>> df2.loc[2, 'col3'] = 4.0
>>> df2
  col1  col2  col3
0    c   1.0   1.0
1    a   2.0   2.0
2    b   3.0   4.0
3    b   NaN   4.0
4    a   5.0   5.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.compare.html, pandas.DataFrame.copy
">>> df.compare(df2)
  col1       col3
  self other self other
0    a     c  NaN   NaN
2  NaN   NaN  3.0   4.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.compare.html, pandas.DataFrame.compare
">>> df.compare(df2, result_names=(""left"", ""right""))
  col1       col3
  left right left right
0    a     c  NaN   NaN
2  NaN   NaN  3.0   4.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.compare.html, pandas.DataFrame.compare
">>> df.compare(df2, align_axis=0)
        col1  col3
0 self     a   NaN
  other    c   NaN
2 self   NaN   3.0
  other  NaN   4.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.compare.html, pandas.DataFrame.compare
">>> df.compare(df2, keep_equal=True)
  col1       col3
  self other self other
0    a     c  1.0   1.0
2    b     b  3.0   4.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.compare.html, pandas.DataFrame.compare
">>> df.compare(df2, keep_shape=True)
  col1       col2       col3
  self other self other self other
0    a     c  NaN   NaN  NaN   NaN
1  NaN   NaN  NaN   NaN  NaN   NaN
2  NaN   NaN  NaN   NaN  3.0   4.0
3  NaN   NaN  NaN   NaN  NaN   NaN
4  NaN   NaN  NaN   NaN  NaN   NaN
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.compare.html, pandas.DataFrame.compare
">>> df.compare(df2, keep_shape=True, keep_equal=True)
  col1       col2       col3
  self other self other self other
0    a     c  1.0   1.0  1.0   1.0
1    a     a  2.0   2.0  2.0   2.0
2    b     b  3.0   3.0  3.0   4.0
3    b     b  NaN   NaN  4.0   4.0
4    a     a  5.0   5.0  5.0   5.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.compare.html, pandas.DataFrame.compare
">>> d = {'col1': [1, 2], 'col2': [3, 4]}
>>> df = pd.DataFrame(data=d)
>>> df
   col1  col2
0     1     3
1     2     4
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html, pandas.DataFrame
">>> df = pd.DataFrame(data=d, dtype=np.int8)
>>> df.dtypes
col1    int8
col2    int8
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html, pandas.DataFrame
">>> d = {'col1': [0, 1, 2, 3], 'col2': pd.Series([2, 3], index=[2, 3])}
>>> pd.DataFrame(data=d, index=[0, 1, 2, 3])
   col1  col2
0     0   NaN
1     1   NaN
2     2   2.0
3     3   3.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html, pandas.Series pandas.DataFrame
">>> df2 = pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]),
...                    columns=['a', 'b', 'c'])
>>> df2
   a  b  c
0  1  2  3
1  4  5  6
2  7  8  9
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html, pandas.DataFrame
">>> data = np.array([(1, 2, 3), (4, 5, 6), (7, 8, 9)],
...                 dtype=[(""a"", ""i4""), (""b"", ""i4""), (""c"", ""i4"")])
>>> df3 = pd.DataFrame(data, columns=['c', 'a'])
...
>>> df3
   c  a
0  3  1
1  6  4
2  9  7
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html, pandas.DataFrame
">>> from dataclasses import make_dataclass
>>> Point = make_dataclass(""Point"", [(""x"", int), (""y"", int)])
>>> pd.DataFrame([Point(0, 0), Point(0, 3), Point(2, 3)])
   x  y
0  0  0
1  0  3
2  2  3
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html, pandas.DataFrame
">>> ser = pd.Series([1, 2, 3], index=[""a"", ""b"", ""c""])
>>> df = pd.DataFrame(data=ser, index=[""a"", ""c""])
>>> df
   0
a  1
c  3
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html, pandas.Series pandas.DataFrame
">>> df1 = pd.DataFrame([1, 2, 3], index=[""a"", ""b"", ""c""], columns=[""x""])
>>> df2 = pd.DataFrame(data=df1, index=[""a"", ""c""])
>>> df2
   x
a  1
c  3
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html, pandas.DataFrame
">>> df = pd.DataFrame([[5.1, 3.5, 0], [4.9, 3.0, 0], [7.0, 3.2, 1],
...                    [6.4, 3.2, 1], [5.9, 3.0, 2]],
...                   columns=['length', 'width', 'species'])
>>> ax1 = df.plot.scatter(x='length',
...                       y='width',
...                       c='DarkBlue')
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.scatter.html, pandas.DataFrame pandas.DataFrame.plot.scatter
">>> ax2 = df.plot.scatter(x='length',
...                       y='width',
...                       c='species',
...                       colormap='viridis')
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.scatter.html, pandas.DataFrame.plot.scatter
">>> df = pd.DataFrame([('falcon', 'bird', 389.0, 2),
...                    ('parrot', 'bird', 24.0, 2),
...                    ('lion', 'mammal', 80.5, 4),
...                    ('monkey', 'mammal', np.nan, 4)],
...                   columns=['name', 'class', 'max_speed',
...                            'num_legs'])
>>> df
     name   class  max_speed  num_legs
0  falcon    bird      389.0         2
1  parrot    bird       24.0         2
2    lion  mammal       80.5         4
3  monkey  mammal        NaN         4
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_xarray.html, pandas.DataFrame
">>> df.to_xarray()  

Dimensions:    (index: 4)
Coordinates:
  * index      (index) int64 32B 0 1 2 3
Data variables:
    name       (index) object 32B 'falcon' 'parrot' 'lion' 'monkey'
    class      (index) object 32B 'bird' 'bird' 'mammal' 'mammal'
    max_speed  (index) float64 32B 389.0 24.0 80.5 nan
    num_legs   (index) int64 32B 2 2 4 4
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_xarray.html, pandas.DataFrame.to_xarray
">>> df['max_speed'].to_xarray()  

array([389. ,  24. ,  80.5,   nan])
Coordinates:
  * index    (index) int64 0 1 2 3
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_xarray.html, pandas.array
">>> dates = pd.to_datetime(['2018-01-01', '2018-01-01',
...                         '2018-01-02', '2018-01-02'])
>>> df_multiindex = pd.DataFrame({'date': dates,
...                               'animal': ['falcon', 'parrot',
...                                          'falcon', 'parrot'],
...                               'speed': [350, 18, 361, 15]})
>>> df_multiindex = df_multiindex.set_index(['date', 'animal'])
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_xarray.html, pandas.to_datetime pandas.DataFrame pandas.DataFrame.set_index
">>> df_multiindex.to_xarray()  

Dimensions:  (date: 2, animal: 2)
Coordinates:
  * date     (date) datetime64[ns] 2018-01-01 2018-01-02
  * animal   (animal) object 'falcon' 'parrot'
Data variables:
    speed    (date, animal) int64 350 18 361 15
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_xarray.html, pandas.DataFrame.to_xarray
">>> data = {
...     ""class"": [""Mammals"", ""Mammals"", ""Reptiles""],
...     ""diet"": [""Omnivore"", ""Carnivore"", ""Carnivore""],
...     ""species"": [""Humans"", ""Dogs"", ""Snakes""],
... }
>>> df = pd.DataFrame(data, columns=[""class"", ""diet"", ""species""])
>>> df = df.set_index([""class"", ""diet""])
>>> df
                                  species
class      diet
Mammals    Omnivore                Humans
           Carnivore                 Dogs
Reptiles   Carnivore               Snakes
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reorder_levels.html, pandas.DataFrame pandas.DataFrame.set_index
">>> df.reorder_levels([""diet"", ""class""])
                                  species
diet      class
Omnivore  Mammals                  Humans
Carnivore Mammals                    Dogs
          Reptiles                 Snakes
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reorder_levels.html, pandas.DataFrame.reorder_levels
">>> np.random.seed(1234)
>>> df = pd.DataFrame(np.random.randn(10, 4),
...                   columns=['Col1', 'Col2', 'Col3', 'Col4'])
>>> boxplot = df.boxplot(column=['Col1', 'Col2', 'Col3'])  
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.boxplot.html, pandas.DataFrame pandas.DataFrame.boxplot
">>> df = pd.DataFrame(np.random.randn(10, 2),
...                   columns=['Col1', 'Col2'])
>>> df['X'] = pd.Series(['A', 'A', 'A', 'A', 'A',
...                      'B', 'B', 'B', 'B', 'B'])
>>> boxplot = df.boxplot(by='X')
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.boxplot.html, pandas.DataFrame pandas.Series pandas.DataFrame.boxplot
">>> df = pd.DataFrame(np.random.randn(10, 3),
...                   columns=['Col1', 'Col2', 'Col3'])
>>> df['X'] = pd.Series(['A', 'A', 'A', 'A', 'A',
...                      'B', 'B', 'B', 'B', 'B'])
>>> df['Y'] = pd.Series(['A', 'B', 'A', 'B', 'A',
...                      'B', 'A', 'B', 'A', 'B'])
>>> boxplot = df.boxplot(column=['Col1', 'Col2'], by=['X', 'Y'])
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.boxplot.html, pandas.DataFrame pandas.Series pandas.DataFrame.boxplot
">>> boxplot = df.boxplot(column=['Col1', 'Col2'], by='X',
...                      layout=(2, 1))
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.boxplot.html, pandas.DataFrame.boxplot
">>> boxplot = df.boxplot(grid=False, rot=45, fontsize=15)  
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.boxplot.html, pandas.DataFrame.boxplot
">>> boxplot = df.boxplot(column=['Col1', 'Col2'], return_type='axes')
>>> type(boxplot)

",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.boxplot.html, pandas.DataFrame.boxplot
">>> boxplot = df.boxplot(column=['Col1', 'Col2'], by='X',
...                      return_type='axes')
>>> type(boxplot)

",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.boxplot.html, pandas.DataFrame.boxplot
">>> boxplot = df.boxplot(column=['Col1', 'Col2'], by='X',
...                      return_type=None)
>>> type(boxplot)

",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.boxplot.html, pandas.DataFrame.boxplot
">>> df = pd.DataFrame({
...     'col1': ['A', 'A', 'B', np.nan, 'D', 'C'],
...     'col2': [2, 1, 9, 8, 7, 4],
...     'col3': [0, 1, 9, 4, 2, 3],
...     'col4': ['a', 'B', 'c', 'D', 'e', 'F']
... })
>>> df
  col1  col2  col3 col4
0    A     2     0    a
1    A     1     1    B
2    B     9     9    c
3  NaN     8     4    D
4    D     7     2    e
5    C     4     3    F
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html, pandas.DataFrame
">>> df.sort_values(by=['col1'])
  col1  col2  col3 col4
0    A     2     0    a
1    A     1     1    B
2    B     9     9    c
5    C     4     3    F
4    D     7     2    e
3  NaN     8     4    D
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html, pandas.DataFrame.sort_values
">>> df.sort_values(by=['col1', 'col2'])
  col1  col2  col3 col4
1    A     1     1    B
0    A     2     0    a
2    B     9     9    c
5    C     4     3    F
4    D     7     2    e
3  NaN     8     4    D
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html, pandas.DataFrame.sort_values
">>> df.sort_values(by='col1', ascending=False)
  col1  col2  col3 col4
4    D     7     2    e
5    C     4     3    F
2    B     9     9    c
0    A     2     0    a
1    A     1     1    B
3  NaN     8     4    D
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html, pandas.DataFrame.sort_values
">>> df.sort_values(by='col1', ascending=False, na_position='first')
  col1  col2  col3 col4
3  NaN     8     4    D
4    D     7     2    e
5    C     4     3    F
2    B     9     9    c
0    A     2     0    a
1    A     1     1    B
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html, pandas.DataFrame.sort_values
">>> df.sort_values(by='col4', key=lambda col: col.str.lower())
   col1  col2  col3 col4
0    A     2     0    a
1    A     1     1    B
2    B     9     9    c
3  NaN     8     4    D
4    D     7     2    e
5    C     4     3    F
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html, pandas.DataFrame.sort_values
">>> df = pd.DataFrame({
...    ""time"": ['0hr', '128hr', '72hr', '48hr', '96hr'],
...    ""value"": [10, 20, 30, 40, 50]
... })
>>> df
    time  value
0    0hr     10
1  128hr     20
2   72hr     30
3   48hr     40
4   96hr     50
>>> from natsort import index_natsorted
>>> df.sort_values(
...     by=""time"",
...     key=lambda x: np.argsort(index_natsorted(df[""time""]))
... )
    time  value
0    0hr     10
3   48hr     40
2   72hr     30
4   96hr     50
1  128hr     20
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html, pandas.DataFrame pandas.DataFrame.sort_values
">>> df = pd.DataFrame({'A': ['a', 'b', 'c', 'd', 'e'],
...                    'B': ['f', 'g', 'h', 'i', 'j'],
...                    'C': ['k', 'l', 'm', 'n', 'o']},
...                   index=[1, 2, 3, 4, 5])
>>> df
   A  B  C
1  a  f  k
2  b  g  l
3  c  h  m
4  d  i  n
5  e  j  o
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.truncate.html, pandas.DataFrame
">>> df.truncate(before=2, after=4)
   A  B  C
2  b  g  l
3  c  h  m
4  d  i  n
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.truncate.html, pandas.DataFrame.truncate
">>> df.truncate(before=""A"", after=""B"", axis=""columns"")
   A  B
1  a  f
2  b  g
3  c  h
4  d  i
5  e  j
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.truncate.html, pandas.DataFrame.truncate
">>> dates = pd.date_range('2016-01-01', '2016-02-01', freq='s')
>>> df = pd.DataFrame(index=dates, data={'A': 1})
>>> df.tail()
                     A
2016-01-31 23:59:56  1
2016-01-31 23:59:57  1
2016-01-31 23:59:58  1
2016-01-31 23:59:59  1
2016-02-01 00:00:00  1
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.truncate.html, pandas.date_range pandas.DataFrame pandas.DataFrame.tail
">>> df.truncate(before=pd.Timestamp('2016-01-05'),
...             after=pd.Timestamp('2016-01-10')).tail()
                     A
2016-01-09 23:59:56  1
2016-01-09 23:59:57  1
2016-01-09 23:59:58  1
2016-01-09 23:59:59  1
2016-01-10 00:00:00  1
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.truncate.html, pandas.DataFrame.truncate
">>> df.truncate('2016-01-05', '2016-01-10').tail()
                     A
2016-01-09 23:59:56  1
2016-01-09 23:59:57  1
2016-01-09 23:59:58  1
2016-01-09 23:59:59  1
2016-01-10 00:00:00  1
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.truncate.html, pandas.DataFrame.truncate
">>> df = pd.DataFrame({'Name': ['Alice', 'Bob', 'Aritra'],
...                    'Age': [25, 30, 35],
...                    'Location': ['Seattle', 'New York', 'Kona']},
...                   index=([10, 20, 30]))
>>> df.index
Index([10, 20, 30], dtype='int64')
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.index.html, pandas.DataFrame pandas.Index
">>> df = pd.DataFrame(
...     {
...         ""a"": pd.Series([1, 2, 3], dtype=np.dtype(""int32"")),
...         ""b"": pd.Series([""x"", ""y"", ""z""], dtype=np.dtype(""O"")),
...         ""c"": pd.Series([True, False, np.nan], dtype=np.dtype(""O"")),
...         ""d"": pd.Series([""h"", ""i"", np.nan], dtype=np.dtype(""O"")),
...         ""e"": pd.Series([10, np.nan, 20], dtype=np.dtype(""float"")),
...         ""f"": pd.Series([np.nan, 100.5, 200], dtype=np.dtype(""float"")),
...     }
... )
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.convert_dtypes.html, pandas.DataFrame pandas.Series
">>> dfn = df.convert_dtypes()
>>> dfn
   a  b      c     d     e      f
0  1  x   True     h    10   
1  2  y  False     i    100.5
2  3  z         20  200.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.convert_dtypes.html, pandas.DataFrame.convert_dtypes
">>> s = pd.Series([""a"", ""b"", np.nan])
>>> s
0      a
1      b
2    NaN
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.convert_dtypes.html, pandas.Series
">>> s.convert_dtypes()
0       a
1       b
2    
dtype: string
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.convert_dtypes.html, pandas.Series.convert_dtypes
">>> df1 = pd.DataFrame({'A': [None, 0], 'B': [None, 4]})
>>> df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})
>>> df1.combine_first(df2)
     A    B
0  1.0  3.0
1  0.0  4.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.combine_first.html, pandas.DataFrame pandas.DataFrame.combine_first
">>> df1 = pd.DataFrame({'A': [None, 0], 'B': [4, None]})
>>> df2 = pd.DataFrame({'B': [3, 3], 'C': [1, 1]}, index=[1, 2])
>>> df1.combine_first(df2)
     A    B    C
0  NaN  4.0  NaN
1  0.0  3.0  1.0
2  NaN  3.0  1.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.combine_first.html, pandas.DataFrame pandas.DataFrame.combine_first
">>> df = pd.DataFrame({""Col1"": [10, 20, 15, 30, 45],
...                    ""Col2"": [13, 23, 18, 33, 48],
...                    ""Col3"": [17, 27, 22, 37, 52]},
...                   index=pd.date_range(""2020-01-01"", ""2020-01-05""))
>>> df
            Col1  Col2  Col3
2020-01-01    10    13    17
2020-01-02    20    23    27
2020-01-03    15    18    22
2020-01-04    30    33    37
2020-01-05    45    48    52
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.shift.html, pandas.DataFrame pandas.date_range
">>> df.shift(periods=3)
            Col1  Col2  Col3
2020-01-01   NaN   NaN   NaN
2020-01-02   NaN   NaN   NaN
2020-01-03   NaN   NaN   NaN
2020-01-04  10.0  13.0  17.0
2020-01-05  20.0  23.0  27.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.shift.html, pandas.DataFrame.shift
">>> df.shift(periods=1, axis=""columns"")
            Col1  Col2  Col3
2020-01-01   NaN    10    13
2020-01-02   NaN    20    23
2020-01-03   NaN    15    18
2020-01-04   NaN    30    33
2020-01-05   NaN    45    48
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.shift.html, pandas.DataFrame.shift
">>> df.shift(periods=3, fill_value=0)
            Col1  Col2  Col3
2020-01-01     0     0     0
2020-01-02     0     0     0
2020-01-03     0     0     0
2020-01-04    10    13    17
2020-01-05    20    23    27
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.shift.html, pandas.DataFrame.shift
">>> df.shift(periods=3, freq=""D"")
            Col1  Col2  Col3
2020-01-04    10    13    17
2020-01-05    20    23    27
2020-01-06    15    18    22
2020-01-07    30    33    37
2020-01-08    45    48    52
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.shift.html, pandas.DataFrame.shift
">>> df.shift(periods=3, freq=""infer"")
            Col1  Col2  Col3
2020-01-04    10    13    17
2020-01-05    20    23    27
2020-01-06    15    18    22
2020-01-07    30    33    37
2020-01-08    45    48    52
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.shift.html, pandas.DataFrame.shift
">>> df = pd.DataFrame({""A"": pd.arrays.SparseArray([0, 1, 0, 1])})
>>> df.sparse.density
0.5
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sparse.density.html, pandas.DataFrame pandas.arrays.SparseArray
">>> s = pd.Series([0, 1, np.nan, 3])
>>> s
0    0.0
1    1.0
2    NaN
3    3.0
dtype: float64
>>> s.interpolate()
0    0.0
1    1.0
2    2.0
3    3.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.interpolate.html, pandas.Series pandas.Series.interpolate
">>> s = pd.Series([0, 2, np.nan, 8])
>>> s.interpolate(method='polynomial', order=2)
0    0.000000
1    2.000000
2    4.666667
3    8.000000
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.interpolate.html, pandas.Series pandas.Series.interpolate
">>> df = pd.DataFrame([(0.0, np.nan, -1.0, 1.0),
...                    (np.nan, 2.0, np.nan, np.nan),
...                    (2.0, 3.0, np.nan, 9.0),
...                    (np.nan, 4.0, -4.0, 16.0)],
...                   columns=list('abcd'))
>>> df
     a    b    c     d
0  0.0  NaN -1.0   1.0
1  NaN  2.0  NaN   NaN
2  2.0  3.0  NaN   9.0
3  NaN  4.0 -4.0  16.0
>>> df.interpolate(method='linear', limit_direction='forward', axis=0)
     a    b    c     d
0  0.0  NaN -1.0   1.0
1  1.0  2.0 -2.0   5.0
2  2.0  3.0 -3.0   9.0
3  2.0  4.0 -4.0  16.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.interpolate.html, pandas.DataFrame pandas.DataFrame.interpolate
">>> d = {'col1': [1, 2, 3], 'col2': [4, 5, 6]}
>>> df = pd.DataFrame(d)
>>> print(df.to_string())
   col1  col2
0     1     4
1     2     5
2     3     6
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_string.html, pandas.DataFrame pandas.DataFrame.to_string
">>> df = pd.DataFrame([[np.nan, 2, np.nan, 0],
...                    [3, 4, np.nan, 1],
...                    [np.nan, np.nan, np.nan, np.nan],
...                    [np.nan, 3, np.nan, 4]],
...                   columns=list(""ABCD""))
>>> df
     A    B   C    D
0  NaN  2.0 NaN  0.0
1  3.0  4.0 NaN  1.0
2  NaN  NaN NaN  NaN
3  NaN  3.0 NaN  4.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.fillna.html, pandas.DataFrame
">>> df.fillna(0)
     A    B    C    D
0  0.0  2.0  0.0  0.0
1  3.0  4.0  0.0  1.0
2  0.0  0.0  0.0  0.0
3  0.0  3.0  0.0  4.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.fillna.html, pandas.DataFrame.fillna
">>> values = {""A"": 0, ""B"": 1, ""C"": 2, ""D"": 3}
>>> df.fillna(value=values)
     A    B    C    D
0  0.0  2.0  2.0  0.0
1  3.0  4.0  2.0  1.0
2  0.0  1.0  2.0  3.0
3  0.0  3.0  2.0  4.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.fillna.html, pandas.DataFrame.fillna
">>> df.fillna(value=values, limit=1)
     A    B    C    D
0  0.0  2.0  2.0  0.0
1  3.0  4.0  NaN  1.0
2  NaN  1.0  NaN  3.0
3  NaN  3.0  NaN  4.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.fillna.html, pandas.DataFrame.fillna
">>> df2 = pd.DataFrame(np.zeros((4, 4)), columns=list(""ABCE""))
>>> df.fillna(df2)
     A    B    C    D
0  0.0  2.0  0.0  0.0
1  3.0  4.0  0.0  1.0
2  0.0  0.0  0.0  NaN
3  0.0  3.0  0.0  4.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.fillna.html, pandas.DataFrame pandas.DataFrame.fillna
">>> df = pd.DataFrame({'angles': [0, 3, 4],
...                    'degrees': [360, 180, 360]},
...                   index=['circle', 'triangle', 'rectangle'])
>>> df
           angles  degrees
circle          0      360
triangle        3      180
rectangle       4      360
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rfloordiv.html, pandas.DataFrame
">>> df.add(1)
           angles  degrees
circle          1      361
triangle        4      181
rectangle       5      361
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rfloordiv.html, pandas.DataFrame.add
">>> df.div(10)
           angles  degrees
circle        0.0     36.0
triangle      0.3     18.0
rectangle     0.4     36.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rfloordiv.html, pandas.DataFrame.div
">>> df.rdiv(10)
             angles   degrees
circle          inf  0.027778
triangle   3.333333  0.055556
rectangle  2.500000  0.027778
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rfloordiv.html, pandas.DataFrame.rdiv
">>> df.sub([1, 2], axis='columns')
           angles  degrees
circle         -1      358
triangle        2      178
rectangle       3      358
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rfloordiv.html, pandas.DataFrame.sub
">>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),
...        axis='index')
           angles  degrees
circle         -1      359
triangle        2      179
rectangle       3      359
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rfloordiv.html, pandas.DataFrame.sub pandas.Series
">>> df.mul({'angles': 0, 'degrees': 2})
            angles  degrees
circle           0      720
triangle         0      360
rectangle        0      720
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rfloordiv.html, pandas.DataFrame.mul
">>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')
            angles  degrees
circle           0        0
triangle         6      360
rectangle       12     1080
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rfloordiv.html, pandas.DataFrame.mul
">>> other = pd.DataFrame({'angles': [0, 3, 4]},
...                      index=['circle', 'triangle', 'rectangle'])
>>> other
           angles
circle          0
triangle        3
rectangle       4
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rfloordiv.html, pandas.DataFrame
">>> df.mul(other, fill_value=0)
           angles  degrees
circle          0      0.0
triangle        9      0.0
rectangle      16      0.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rfloordiv.html, pandas.DataFrame.mul
">>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],
...                              'degrees': [360, 180, 360, 360, 540, 720]},
...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],
...                                    ['circle', 'triangle', 'rectangle',
...                                     'square', 'pentagon', 'hexagon']])
>>> df_multindex
             angles  degrees
A circle          0      360
  triangle        3      180
  rectangle       4      360
B square          4      360
  pentagon        5      540
  hexagon         6      720
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rfloordiv.html, pandas.DataFrame
">>> df.div(df_multindex, level=1, fill_value=0)
             angles  degrees
A circle        NaN      1.0
  triangle      1.0      1.0
  rectangle     1.0      1.0
B square        0.0      0.0
  pentagon      0.0      0.0
  hexagon       0.0      0.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rfloordiv.html, pandas.DataFrame.div
">>> df = pd.DataFrame({'cost': [250, 150, 100],
...                    'revenue': [100, 250, 300]},
...                   index=['A', 'B', 'C'])
>>> df
   cost  revenue
A   250      100
B   150      250
C   100      300
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.lt.html, pandas.DataFrame
">>> df.eq(100)
    cost  revenue
A  False     True
B  False    False
C   True    False
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.lt.html, pandas.DataFrame.eq
">>> df != pd.Series([100, 250], index=[""cost"", ""revenue""])
    cost  revenue
A   True     True
B   True    False
C  False     True
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.lt.html, pandas.Series
">>> df.ne(pd.Series([100, 300], index=[""A"", ""D""]), axis='index')
   cost  revenue
A  True    False
B  True     True
C  True     True
D  True     True
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.lt.html, pandas.DataFrame.ne pandas.Series
">>> df.eq([250, 250, 100], axis='index')
    cost  revenue
A   True    False
B  False     True
C   True    False
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.lt.html, pandas.DataFrame.eq
">>> other = pd.DataFrame({'revenue': [300, 250, 100, 150]},
...                      index=['A', 'B', 'C', 'D'])
>>> other
   revenue
A      300
B      250
C      100
D      150
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.lt.html, pandas.DataFrame
">>> df.gt(other)
    cost  revenue
A  False    False
B  False    False
C  False     True
D  False    False
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.lt.html, pandas.DataFrame.gt
">>> df_multindex = pd.DataFrame({'cost': [250, 150, 100, 150, 300, 220],
...                              'revenue': [100, 250, 300, 200, 175, 225]},
...                             index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'],
...                                    ['A', 'B', 'C', 'A', 'B', 'C']])
>>> df_multindex
      cost  revenue
Q1 A   250      100
   B   150      250
   C   100      300
Q2 A   150      200
   B   300      175
   C   220      225
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.lt.html, pandas.DataFrame
">>> df.le(df_multindex, level=1)
       cost  revenue
Q1 A   True     True
   B   True     True
   C   True     True
Q2 A  False     True
   B   True    False
   C   True    False
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.lt.html, pandas.DataFrame.le
">>> df = pd.DataFrame({'A': [1, 2, 3]})
>>> df.style  
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.style.html, pandas.DataFrame
">>> d1 = {'col1': [1, 2], 'col2': [3, 4]}
>>> df1 = pd.DataFrame(data=d1)
>>> df1
   col1  col2
0     1     3
1     2     4
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.transpose.html, pandas.DataFrame
">>> df1_transposed = df1.T  # or df1.transpose()
>>> df1_transposed
      0  1
col1  1  2
col2  3  4
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.transpose.html, pandas.DataFrame.transpose
">>> d2 = {'name': ['Alice', 'Bob'],
...       'score': [9.5, 8],
...       'employed': [False, True],
...       'kids': [0, 0]}
>>> df2 = pd.DataFrame(data=d2)
>>> df2
    name  score  employed  kids
0  Alice    9.5     False     0
1    Bob    8.0      True     0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.transpose.html, pandas.DataFrame
">>> df2_transposed = df2.T  # or df2.transpose()
>>> df2_transposed
              0     1
name      Alice   Bob
score       9.5   8.0
employed  False  True
kids          0     0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.transpose.html, pandas.DataFrame.transpose
">>> df = pd.DataFrame({'angles': [0, 3, 4],
...                    'degrees': [360, 180, 360]},
...                   index=['circle', 'triangle', 'rectangle'])
>>> df
           angles  degrees
circle          0      360
triangle        3      180
rectangle       4      360
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.add.html, pandas.DataFrame
">>> df.add(1)
           angles  degrees
circle          1      361
triangle        4      181
rectangle       5      361
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.add.html, pandas.DataFrame.add
">>> df.div(10)
           angles  degrees
circle        0.0     36.0
triangle      0.3     18.0
rectangle     0.4     36.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.add.html, pandas.DataFrame.div
">>> df.rdiv(10)
             angles   degrees
circle          inf  0.027778
triangle   3.333333  0.055556
rectangle  2.500000  0.027778
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.add.html, pandas.DataFrame.rdiv
">>> df.sub([1, 2], axis='columns')
           angles  degrees
circle         -1      358
triangle        2      178
rectangle       3      358
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.add.html, pandas.DataFrame.sub
">>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),
...        axis='index')
           angles  degrees
circle         -1      359
triangle        2      179
rectangle       3      359
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.add.html, pandas.DataFrame.sub pandas.Series
">>> df.mul({'angles': 0, 'degrees': 2})
            angles  degrees
circle           0      720
triangle         0      360
rectangle        0      720
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.add.html, pandas.DataFrame.mul
">>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')
            angles  degrees
circle           0        0
triangle         6      360
rectangle       12     1080
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.add.html, pandas.DataFrame.mul
">>> other = pd.DataFrame({'angles': [0, 3, 4]},
...                      index=['circle', 'triangle', 'rectangle'])
>>> other
           angles
circle          0
triangle        3
rectangle       4
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.add.html, pandas.DataFrame
">>> df.mul(other, fill_value=0)
           angles  degrees
circle          0      0.0
triangle        9      0.0
rectangle      16      0.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.add.html, pandas.DataFrame.mul
">>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],
...                              'degrees': [360, 180, 360, 360, 540, 720]},
...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],
...                                    ['circle', 'triangle', 'rectangle',
...                                     'square', 'pentagon', 'hexagon']])
>>> df_multindex
             angles  degrees
A circle          0      360
  triangle        3      180
  rectangle       4      360
B square          4      360
  pentagon        5      540
  hexagon         6      720
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.add.html, pandas.DataFrame
">>> df.div(df_multindex, level=1, fill_value=0)
             angles  degrees
A circle        NaN      1.0
  triangle      1.0      1.0
  rectangle     1.0      1.0
B square        0.0      0.0
  pentagon      0.0      0.0
  hexagon       0.0      0.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.add.html, pandas.DataFrame.div
">>> s = pd.Series(
...     [1],
...     index=pd.DatetimeIndex(['2018-09-15 01:30:00+02:00']),
... )
>>> s.tz_convert('Asia/Shanghai')
2018-09-15 07:30:00+08:00    1
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.tz_convert.html, pandas.Series pandas.DatetimeIndex pandas.Series.tz_convert
">>> s = pd.Series([1],
...               index=pd.DatetimeIndex(['2018-09-15 01:30:00+02:00']))
>>> s.tz_convert(None)
2018-09-14 23:30:00    1
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.tz_convert.html, pandas.Series pandas.DatetimeIndex pandas.Series.tz_convert
">>> df = pd.DataFrame([[1, 1.5]], columns=['int', 'float'])
>>> row = next(df.iterrows())[1]
>>> row
int      1.0
float    1.5
Name: 0, dtype: float64
>>> print(row['int'].dtype)
float64
>>> print(df['int'].dtype)
int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iterrows.html, pandas.DataFrame pandas.DataFrame.iterrows
">>> dtypes = ['int64', 'float64', 'complex128', 'object', 'bool']
>>> data = dict([(t, np.ones(shape=5000, dtype=int).astype(t))
...              for t in dtypes])
>>> df = pd.DataFrame(data)
>>> df.head()
   int64  float64            complex128  object  bool
0      1      1.0              1.0+0.0j       1  True
1      1      1.0              1.0+0.0j       1  True
2      1      1.0              1.0+0.0j       1  True
3      1      1.0              1.0+0.0j       1  True
4      1      1.0              1.0+0.0j       1  True
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.memory_usage.html, pandas.DataFrame pandas.DataFrame.head
">>> df.memory_usage()
Index           128
int64         40000
float64       40000
complex128    80000
object        40000
bool           5000
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.memory_usage.html, pandas.DataFrame.memory_usage
">>> df.memory_usage(index=False)
int64         40000
float64       40000
complex128    80000
object        40000
bool           5000
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.memory_usage.html, pandas.DataFrame.memory_usage
">>> df.memory_usage(deep=True)
Index            128
int64          40000
float64        40000
complex128     80000
object        180000
bool            5000
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.memory_usage.html, pandas.DataFrame.memory_usage
">>> s = pd.Series([2, np.nan, 5, -1, 0])
>>> s
0    2.0
1    NaN
2    5.0
3   -1.0
4    0.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.cummin.html, pandas.Series
">>> s.cummin()
0    2.0
1    NaN
2    2.0
3   -1.0
4   -1.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.cummin.html, pandas.Series.cummin
">>> s.cummin(skipna=False)
0    2.0
1    NaN
2    NaN
3    NaN
4    NaN
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.cummin.html, pandas.Series.cummin
">>> df = pd.DataFrame([[2.0, 1.0],
...                    [3.0, np.nan],
...                    [1.0, 0.0]],
...                   columns=list('AB'))
>>> df
     A    B
0  2.0  1.0
1  3.0  NaN
2  1.0  0.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.cummin.html, pandas.DataFrame
">>> df.cummin()
     A    B
0  2.0  1.0
1  2.0  NaN
2  1.0  0.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.cummin.html, pandas.DataFrame.cummin
">>> df.cummin(axis=1)
     A    B
0  2.0  1.0
1  3.0  NaN
2  1.0  0.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.cummin.html, pandas.DataFrame.cummin
">>> idx = pd.MultiIndex.from_arrays([
...     ['warm', 'warm', 'cold', 'cold'],
...     ['dog', 'falcon', 'fish', 'spider']],
...     names=['blooded', 'animal'])
>>> s = pd.Series([4, 2, 0, 8], name='legs', index=idx)
>>> s
blooded  animal
warm     dog       4
         falcon    2
cold     fish      0
         spider    8
Name: legs, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.max.html, pandas.MultiIndex.from_arrays pandas.Series
">>> s.max()
8
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.max.html, pandas.Series.max
">>> df = pd.DataFrame({'consumption': [10.51, 103.11, 55.48],
...                     'co2_emissions': [37.2, 19.66, 1712]},
...                   index=['Pork', 'Wheat Products', 'Beef'])
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.idxmin.html, pandas.DataFrame
">>> df.idxmin()
consumption                Pork
co2_emissions    Wheat Products
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.idxmin.html, pandas.DataFrame.idxmin
">>> df.idxmin(axis=""columns"")
Pork                consumption
Wheat Products    co2_emissions
Beef                consumption
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.idxmin.html, pandas.DataFrame.idxmin
">>> df = pd.DataFrame({'A': [[0, 1, 2], 'foo', [], [3, 4]],
...                    'B': 1,
...                    'C': [['a', 'b', 'c'], np.nan, [], ['d', 'e']]})
>>> df
           A  B          C
0  [0, 1, 2]  1  [a, b, c]
1        foo  1        NaN
2         []  1         []
3     [3, 4]  1     [d, e]
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.explode.html, pandas.DataFrame
">>> df.explode('A')
     A  B          C
0    0  1  [a, b, c]
0    1  1  [a, b, c]
0    2  1  [a, b, c]
1  foo  1        NaN
2  NaN  1         []
3    3  1     [d, e]
3    4  1     [d, e]
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.explode.html, pandas.DataFrame.explode
">>> df.explode(list('AC'))
     A  B    C
0    0  1    a
0    1  1    b
0    2  1    c
1  foo  1  NaN
2  NaN  1  NaN
3    3  1    d
3    4  1    e
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.explode.html, pandas.DataFrame.explode
">>> df = pd.DataFrame({
...     'sales': [3, 2, 3, 9, 10, 6],
...     'signups': [5, 5, 6, 12, 14, 13],
...     'visits': [20, 42, 28, 62, 81, 50],
... }, index=pd.date_range(start='2018/01/01', end='2018/07/01',
...                        freq='ME'))
>>> ax = df.plot.area()
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.area.html, pandas.DataFrame pandas.date_range pandas.DataFrame.plot.area
">>> ax = df.plot.area(stacked=False)
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.area.html, pandas.DataFrame.plot.area
">>> ax = df.plot.area(y='sales')
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.area.html, pandas.DataFrame.plot.area
">>> df = pd.DataFrame({
...     'sales': [3, 2, 3],
...     'visits': [20, 42, 28],
...     'day': [1, 2, 3],
... })
>>> ax = df.plot.area(x='day')
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.area.html, pandas.DataFrame pandas.DataFrame.plot.area
">>> df = pd.DataFrame({'a': [1, 2] * 3,
...                    'b': [True, False] * 3,
...                    'c': [1.0, 2.0] * 3})
>>> df
        a      b  c
0       1   True  1.0
1       2  False  2.0
2       1   True  1.0
3       2  False  2.0
4       1   True  1.0
5       2  False  2.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.select_dtypes.html, pandas.DataFrame
">>> df.select_dtypes(include='bool')
   b
0  True
1  False
2  True
3  False
4  True
5  False
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.select_dtypes.html, pandas.DataFrame.select_dtypes
">>> df.select_dtypes(include=['float64'])
   c
0  1.0
1  2.0
2  1.0
3  2.0
4  1.0
5  2.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.select_dtypes.html, pandas.DataFrame.select_dtypes
">>> df.select_dtypes(exclude=['int64'])
       b    c
0   True  1.0
1  False  2.0
2   True  1.0
3  False  2.0
4   True  1.0
5  False  2.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.select_dtypes.html, pandas.DataFrame.select_dtypes
">>> df = pd.DataFrame([[0, 2, 3], [0, 4, 1], [10, 20, 30]],
...                   index=[4, 5, 6], columns=['A', 'B', 'C'])
>>> df
    A   B   C
4   0   2   3
5   0   4   1
6  10  20  30
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.at.html, pandas.DataFrame
">>> df = pd.DataFrame({
...     'brand': ['Yum Yum', 'Yum Yum', 'Indomie', 'Indomie', 'Indomie'],
...     'style': ['cup', 'cup', 'cup', 'pack', 'pack'],
...     'rating': [4, 4, 3.5, 15, 5]
... })
>>> df
    brand style  rating
0  Yum Yum   cup     4.0
1  Yum Yum   cup     4.0
2  Indomie   cup     3.5
3  Indomie  pack    15.0
4  Indomie  pack     5.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.duplicated.html, pandas.DataFrame
">>> df.duplicated()
0    False
1     True
2    False
3    False
4    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.duplicated.html, pandas.DataFrame.duplicated
">>> df.duplicated(keep='last')
0     True
1    False
2    False
3    False
4    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.duplicated.html, pandas.DataFrame.duplicated
">>> df.duplicated(keep=False)
0     True
1     True
2    False
3    False
4    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.duplicated.html, pandas.DataFrame.duplicated
">>> df.duplicated(subset=['brand'])
0    False
1     True
2    False
3     True
4     True
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.duplicated.html, pandas.DataFrame.duplicated
">>> s = pd.Series([None, 3, 4])
>>> s.first_valid_index()
1
>>> s.last_valid_index()
2
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.last_valid_index.html, pandas.Series pandas.Series.first_valid_index pandas.Series.last_valid_index
">>> s = pd.Series([None, None])
>>> print(s.first_valid_index())
None
>>> print(s.last_valid_index())
None
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.last_valid_index.html, pandas.Series pandas.Series.first_valid_index pandas.Series.last_valid_index
">>> s = pd.Series()
>>> print(s.first_valid_index())
None
>>> print(s.last_valid_index())
None
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.last_valid_index.html, pandas.Series pandas.Series.first_valid_index pandas.Series.last_valid_index
">>> df = pd.DataFrame({'A': [None, None, 2], 'B': [None, 3, 4]})
>>> df
     A      B
0  NaN    NaN
1  NaN    3.0
2  2.0    4.0
>>> df.first_valid_index()
1
>>> df.last_valid_index()
2
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.last_valid_index.html, pandas.DataFrame pandas.DataFrame.first_valid_index pandas.DataFrame.last_valid_index
">>> df = pd.DataFrame({'A': [None, None, None], 'B': [None, None, None]})
>>> df
     A      B
0  None   None
1  None   None
2  None   None
>>> print(df.first_valid_index())
None
>>> print(df.last_valid_index())
None
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.last_valid_index.html, pandas.DataFrame pandas.DataFrame.first_valid_index pandas.DataFrame.last_valid_index
">>> df = pd.DataFrame()
>>> df
Empty DataFrame
Columns: []
Index: []
>>> print(df.first_valid_index())
None
>>> print(df.last_valid_index())
None
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.last_valid_index.html, pandas.DataFrame pandas.DataFrame.first_valid_index pandas.DataFrame.last_valid_index
">>> idx = pd.PeriodIndex(['2023', '2024'], freq='Y')
>>> d = {'col1': [1, 2], 'col2': [3, 4]}
>>> df1 = pd.DataFrame(data=d, index=idx)
>>> df1
      col1   col2
2023     1      3
2024     2      4
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_timestamp.html, pandas.PeriodIndex pandas.DataFrame
">>> df1 = df1.to_timestamp()
>>> df1
            col1   col2
2023-01-01     1      3
2024-01-01     2      4
>>> df1.index
DatetimeIndex(['2023-01-01', '2024-01-01'], dtype='datetime64[ns]', freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_timestamp.html, pandas.DataFrame.to_timestamp pandas.DatetimeIndex
">>> df2 = pd.DataFrame(data=d, index=idx)
>>> df2 = df2.to_timestamp(freq='M')
>>> df2
            col1   col2
2023-01-31     1      3
2024-01-31     2      4
>>> df2.index
DatetimeIndex(['2023-01-31', '2024-01-31'], dtype='datetime64[ns]', freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_timestamp.html, pandas.DataFrame pandas.DataFrame.to_timestamp pandas.DatetimeIndex
">>> df = pd.DataFrame({1: [10], 2: [20]})
>>> df
    1   2
0  10  20
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.equals.html, pandas.DataFrame
">>> exactly_equal = pd.DataFrame({1: [10], 2: [20]})
>>> exactly_equal
    1   2
0  10  20
>>> df.equals(exactly_equal)
True
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.equals.html, pandas.DataFrame pandas.DataFrame.equals
">>> different_column_type = pd.DataFrame({1.0: [10], 2.0: [20]})
>>> different_column_type
   1.0  2.0
0   10   20
>>> df.equals(different_column_type)
True
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.equals.html, pandas.DataFrame pandas.DataFrame.equals
">>> different_data_type = pd.DataFrame({1: [10.0], 2: [20.0]})
>>> different_data_type
      1     2
0  10.0  20.0
>>> df.equals(different_data_type)
False
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.equals.html, pandas.DataFrame pandas.DataFrame.equals
">>> s = pd.Series([1, 3, 2])
>>> s.plot.line()  
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.line.html, pandas.Series pandas.Series.plot.line
">>> df = pd.DataFrame({
...    'pig': [20, 18, 489, 675, 1776],
...    'horse': [4, 25, 281, 600, 1900]
...    }, index=[1990, 1997, 2003, 2009, 2014])
>>> lines = df.plot.line()
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.line.html, pandas.DataFrame pandas.DataFrame.plot.line
">>> axes = df.plot.line(subplots=True)
>>> type(axes)

",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.line.html, pandas.DataFrame.plot.line
">>> axes = df.plot.line(
...     subplots=True, color={""pig"": ""pink"", ""horse"": ""#742802""}
... )
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.line.html, pandas.DataFrame.plot.line
">>> lines = df.plot.line(x='pig', y='horse')
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.line.html, pandas.DataFrame.plot.line
">>> df = pd.DataFrame({'population': [59000000, 65000000, 434000,
...                                   434000, 434000, 337000, 11300,
...                                   11300, 11300],
...                    'GDP': [1937894, 2583560 , 12011, 4520, 12128,
...                            17036, 182, 38, 311],
...                    'alpha-2': [""IT"", ""FR"", ""MT"", ""MV"", ""BN"",
...                                ""IS"", ""NR"", ""TV"", ""AI""]},
...                   index=[""Italy"", ""France"", ""Malta"",
...                          ""Maldives"", ""Brunei"", ""Iceland"",
...                          ""Nauru"", ""Tuvalu"", ""Anguilla""])
>>> df
          population      GDP alpha-2
Italy       59000000  1937894      IT
France      65000000  2583560      FR
Malta         434000    12011      MT
Maldives      434000     4520      MV
Brunei        434000    12128      BN
Iceland       337000    17036      IS
Nauru          11300      182      NR
Tuvalu         11300       38      TV
Anguilla       11300      311      AI
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.nlargest.html, pandas.DataFrame
">>> df.nlargest(3, 'population')
        population      GDP alpha-2
France    65000000  2583560      FR
Italy     59000000  1937894      IT
Malta       434000    12011      MT
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.nlargest.html, pandas.DataFrame.nlargest
">>> df.nlargest(3, 'population', keep='last')
        population      GDP alpha-2
France    65000000  2583560      FR
Italy     59000000  1937894      IT
Brunei      434000    12128      BN
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.nlargest.html, pandas.DataFrame.nlargest
">>> df.nlargest(3, 'population', keep='all')
          population      GDP alpha-2
France      65000000  2583560      FR
Italy       59000000  1937894      IT
Malta         434000    12011      MT
Maldives      434000     4520      MV
Brunei        434000    12128      BN
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.nlargest.html, pandas.DataFrame.nlargest
">>> df.nlargest(5, 'population', keep='all')
          population      GDP alpha-2
France      65000000  2583560      FR
Italy       59000000  1937894      IT
Malta         434000    12011      MT
Maldives      434000     4520      MV
Brunei        434000    12128      BN
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.nlargest.html, pandas.DataFrame.nlargest
">>> df.nlargest(3, ['population', 'GDP'])
        population      GDP alpha-2
France    65000000  2583560      FR
Italy     59000000  1937894      IT
Brunei      434000    12128      BN
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.nlargest.html, pandas.DataFrame.nlargest
">>> s = pd.Series(
...     [1],
...     index=pd.DatetimeIndex(['2018-09-15 01:30:00']),
... )
>>> s.tz_localize('CET')
2018-09-15 01:30:00+02:00    1
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.tz_localize.html, pandas.Series pandas.DatetimeIndex pandas.Series.tz_localize
">>> s = pd.Series([1],
...               index=pd.DatetimeIndex(['2018-09-15 01:30:00+02:00']))
>>> s.tz_localize(None)
2018-09-15 01:30:00    1
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.tz_localize.html, pandas.Series pandas.DatetimeIndex pandas.Series.tz_localize
">>> s = pd.Series(range(7),
...               index=pd.DatetimeIndex(['2018-10-28 01:30:00',
...                                       '2018-10-28 02:00:00',
...                                       '2018-10-28 02:30:00',
...                                       '2018-10-28 02:00:00',
...                                       '2018-10-28 02:30:00',
...                                       '2018-10-28 03:00:00',
...                                       '2018-10-28 03:30:00']))
>>> s.tz_localize('CET', ambiguous='infer')
2018-10-28 01:30:00+02:00    0
2018-10-28 02:00:00+02:00    1
2018-10-28 02:30:00+02:00    2
2018-10-28 02:00:00+01:00    3
2018-10-28 02:30:00+01:00    4
2018-10-28 03:00:00+01:00    5
2018-10-28 03:30:00+01:00    6
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.tz_localize.html, pandas.Series pandas.DatetimeIndex pandas.Series.tz_localize
">>> s = pd.Series(range(3),
...               index=pd.DatetimeIndex(['2018-10-28 01:20:00',
...                                       '2018-10-28 02:36:00',
...                                       '2018-10-28 03:46:00']))
>>> s.tz_localize('CET', ambiguous=np.array([True, True, False]))
2018-10-28 01:20:00+02:00    0
2018-10-28 02:36:00+02:00    1
2018-10-28 03:46:00+01:00    2
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.tz_localize.html, pandas.Series pandas.DatetimeIndex pandas.Series.tz_localize
">>> s = pd.Series(range(2),
...               index=pd.DatetimeIndex(['2015-03-29 02:30:00',
...                                       '2015-03-29 03:30:00']))
>>> s.tz_localize('Europe/Warsaw', nonexistent='shift_forward')
2015-03-29 03:00:00+02:00    0
2015-03-29 03:30:00+02:00    1
dtype: int64
>>> s.tz_localize('Europe/Warsaw', nonexistent='shift_backward')
2015-03-29 01:59:59.999999999+01:00    0
2015-03-29 03:30:00+02:00              1
dtype: int64
>>> s.tz_localize('Europe/Warsaw', nonexistent=pd.Timedelta('1h'))
2015-03-29 03:30:00+02:00    0
2015-03-29 03:30:00+02:00    1
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.tz_localize.html, pandas.Series pandas.DatetimeIndex pandas.Series.tz_localize
">>> s = pd.Series({'a': 1, 'b': 2, 'c': 3})
>>> s.ndim
1
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.ndim.html, pandas.Series
">>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})
>>> df.ndim
2
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.ndim.html, pandas.DataFrame
">>> df = pd.DataFrame({'num_legs': [4, 2], 'num_wings': [0, 2]},
...                   index=['dog', 'hawk'])
>>> df
      num_legs  num_wings
dog          4          0
hawk         2          2
>>> for row in df.itertuples():
...     print(row)
...
Pandas(Index='dog', num_legs=4, num_wings=0)
Pandas(Index='hawk', num_legs=2, num_wings=2)
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.itertuples.html, pandas.DataFrame pandas.DataFrame.itertuples
">>> for row in df.itertuples(index=False):
...     print(row)
...
Pandas(num_legs=4, num_wings=0)
Pandas(num_legs=2, num_wings=2)
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.itertuples.html, pandas.DataFrame.itertuples
">>> for row in df.itertuples(name='Animal'):
...     print(row)
...
Animal(Index='dog', num_legs=4, num_wings=0)
Animal(Index='hawk', num_legs=2, num_wings=2)
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.itertuples.html, pandas.DataFrame.itertuples
">>> s = pd.Series([1, None, None, 2])
>>> s.bfill()
0    1.0
1    2.0
2    2.0
3    2.0
dtype: float64
>>> s.bfill(limit=1)
0    1.0
1    NaN
2    2.0
3    2.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.bfill.html, pandas.Series pandas.Series.bfill
">>> df = pd.DataFrame({'A': [1, None, None, 4], 'B': [None, 5, None, 7]})
>>> df
      A     B
0   1.0   NaN
1   NaN   5.0
2   NaN   NaN
3   4.0   7.0
>>> df.bfill()
      A     B
0   1.0   5.0
1   4.0   5.0
2   4.0   7.0
3   4.0   7.0
>>> df.bfill(limit=1)
      A     B
0   1.0   5.0
1   NaN   5.0
2   4.0   7.0
3   4.0   7.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.bfill.html, pandas.DataFrame pandas.DataFrame.bfill
">>> s = pd.Series([1, 2, np.nan, 4], index=[10, 20, 30, 40])
>>> s
10    1.0
20    2.0
30    NaN
40    4.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.asof.html, pandas.Series
">>> s.asof(20)
2.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.asof.html, pandas.Series.asof
">>> s.asof([5, 20])
5     NaN
20    2.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.asof.html, pandas.Series.asof
">>> s.asof(30)
2.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.asof.html, pandas.Series.asof
">>> df = pd.DataFrame({'a': [10., 20., 30., 40., 50.],
...                    'b': [None, None, None, None, 500]},
...                   index=pd.DatetimeIndex(['2018-02-27 09:01:00',
...                                           '2018-02-27 09:02:00',
...                                           '2018-02-27 09:03:00',
...                                           '2018-02-27 09:04:00',
...                                           '2018-02-27 09:05:00']))
>>> df.asof(pd.DatetimeIndex(['2018-02-27 09:03:30',
...                           '2018-02-27 09:04:30']))
                      a   b
2018-02-27 09:03:30 NaN NaN
2018-02-27 09:04:30 NaN NaN
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.asof.html, pandas.DataFrame pandas.DatetimeIndex pandas.DataFrame.asof
">>> df.asof(pd.DatetimeIndex(['2018-02-27 09:03:30',
...                           '2018-02-27 09:04:30']),
...         subset=['a'])
                        a   b
2018-02-27 09:03:30  30.0 NaN
2018-02-27 09:04:30  40.0 NaN
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.asof.html, pandas.DataFrame.asof pandas.DatetimeIndex
">>> df = pd.DataFrame({'consumption': [10.51, 103.11, 55.48],
...                     'co2_emissions': [37.2, 19.66, 1712]},
...                   index=['Pork', 'Wheat Products', 'Beef'])
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.idxmax.html, pandas.DataFrame
">>> df.idxmax()
consumption     Wheat Products
co2_emissions             Beef
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.idxmax.html, pandas.DataFrame.idxmax
">>> df.idxmax(axis=""columns"")
Pork              co2_emissions
Wheat Products     consumption
Beef              co2_emissions
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.idxmax.html, pandas.DataFrame.idxmax
">>> df = pd.DataFrame({'angles': [0, 3, 4],
...                    'degrees': [360, 180, 360]},
...                   index=['circle', 'triangle', 'rectangle'])
>>> df
           angles  degrees
circle          0      360
triangle        3      180
rectangle       4      360
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sub.html, pandas.DataFrame
">>> df.add(1)
           angles  degrees
circle          1      361
triangle        4      181
rectangle       5      361
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sub.html, pandas.DataFrame.add
">>> df.div(10)
           angles  degrees
circle        0.0     36.0
triangle      0.3     18.0
rectangle     0.4     36.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sub.html, pandas.DataFrame.div
">>> df.rdiv(10)
             angles   degrees
circle          inf  0.027778
triangle   3.333333  0.055556
rectangle  2.500000  0.027778
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sub.html, pandas.DataFrame.rdiv
">>> df.sub([1, 2], axis='columns')
           angles  degrees
circle         -1      358
triangle        2      178
rectangle       3      358
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sub.html, pandas.DataFrame.sub
">>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),
...        axis='index')
           angles  degrees
circle         -1      359
triangle        2      179
rectangle       3      359
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sub.html, pandas.DataFrame.sub pandas.Series
">>> df.mul({'angles': 0, 'degrees': 2})
            angles  degrees
circle           0      720
triangle         0      360
rectangle        0      720
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sub.html, pandas.DataFrame.mul
">>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')
            angles  degrees
circle           0        0
triangle         6      360
rectangle       12     1080
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sub.html, pandas.DataFrame.mul
">>> other = pd.DataFrame({'angles': [0, 3, 4]},
...                      index=['circle', 'triangle', 'rectangle'])
>>> other
           angles
circle          0
triangle        3
rectangle       4
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sub.html, pandas.DataFrame
">>> df.mul(other, fill_value=0)
           angles  degrees
circle          0      0.0
triangle        9      0.0
rectangle      16      0.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sub.html, pandas.DataFrame.mul
">>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],
...                              'degrees': [360, 180, 360, 360, 540, 720]},
...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],
...                                    ['circle', 'triangle', 'rectangle',
...                                     'square', 'pentagon', 'hexagon']])
>>> df_multindex
             angles  degrees
A circle          0      360
  triangle        3      180
  rectangle       4      360
B square          4      360
  pentagon        5      540
  hexagon         6      720
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sub.html, pandas.DataFrame
">>> df.div(df_multindex, level=1, fill_value=0)
             angles  degrees
A circle        NaN      1.0
  triangle      1.0      1.0
  rectangle     1.0      1.0
B square        0.0      0.0
  pentagon      0.0      0.0
  hexagon       0.0      0.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sub.html, pandas.DataFrame.div
">>> s = pd.Series([""dog"", ""cat"", ""monkey""])
>>> s
0       dog
1       cat
2    monkey
dtype: object
>>> s.rename_axis(""animal"")
animal
0    dog
1    cat
2    monkey
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename_axis.html, pandas.Series pandas.Series.rename_axis
">>> df = pd.DataFrame({""num_legs"": [4, 4, 2],
...                    ""num_arms"": [0, 0, 2]},
...                   [""dog"", ""cat"", ""monkey""])
>>> df
        num_legs  num_arms
dog            4         0
cat            4         0
monkey         2         2
>>> df = df.rename_axis(""animal"")
>>> df
        num_legs  num_arms
animal
dog            4         0
cat            4         0
monkey         2         2
>>> df = df.rename_axis(""limbs"", axis=""columns"")
>>> df
limbs   num_legs  num_arms
animal
dog            4         0
cat            4         0
monkey         2         2
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename_axis.html, pandas.DataFrame pandas.DataFrame.rename_axis
">>> df.index = pd.MultiIndex.from_product([['mammal'],
...                                        ['dog', 'cat', 'monkey']],
...                                       names=['type', 'name'])
>>> df
limbs          num_legs  num_arms
type   name
mammal dog            4         0
       cat            4         0
       monkey         2         2
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename_axis.html, pandas.MultiIndex.from_product
">>> df.rename_axis(index={'type': 'class'})
limbs          num_legs  num_arms
class  name
mammal dog            4         0
       cat            4         0
       monkey         2         2
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename_axis.html, pandas.DataFrame.rename_axis
">>> df.rename_axis(columns=str.upper)
LIMBS          num_legs  num_arms
type   name
mammal dog            4         0
       cat            4         0
       monkey         2         2
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename_axis.html, pandas.DataFrame.rename_axis
">>> df = pd.DataFrame({'A': range(1, 6),
...                    'B': range(10, 0, -2),
...                    'C C': range(10, 5, -1)})
>>> df
   A   B  C C
0  1  10   10
1  2   8    9
2  3   6    8
3  4   4    7
4  5   2    6
>>> df.query('A > B')
   A  B  C C
4  5  2    6
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.query.html, pandas.DataFrame pandas.DataFrame.query
">>> df.query('B == `C C`')
   A   B  C C
0  1  10   10
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.query.html, pandas.DataFrame.query
">>> pd.DataFrame({""A"": [1, 2], ""B"": [3, 4]}).to_numpy()
array([[1, 3],
       [2, 4]])
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_numpy.html, pandas.DataFrame pandas.array
">>> df = pd.DataFrame({""A"": [1, 2], ""B"": [3.0, 4.5]})
>>> df.to_numpy()
array([[1. , 3. ],
       [2. , 4.5]])
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_numpy.html, pandas.DataFrame pandas.DataFrame.to_numpy pandas.array
">>> df['C'] = pd.date_range('2000', periods=2)
>>> df.to_numpy()
array([[1, 3.0, Timestamp('2000-01-01 00:00:00')],
       [2, 4.5, Timestamp('2000-01-02 00:00:00')]], dtype=object)
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_numpy.html, pandas.date_range pandas.DataFrame.to_numpy pandas.array
">>> df = pd.DataFrame({""Person"":
...                    [""John"", ""Myla"", ""Lewis"", ""John"", ""Myla""],
...                    ""Age"": [24., np.nan, 21., 33, 26],
...                    ""Single"": [False, True, True, True, False]})
>>> df
   Person   Age  Single
0    John  24.0   False
1    Myla   NaN    True
2   Lewis  21.0    True
3    John  33.0    True
4    Myla  26.0   False
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.count.html, pandas.DataFrame
">>> df.count()
Person    5
Age       4
Single    5
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.count.html, pandas.DataFrame.count
">>> df.count(axis='columns')
0    3
1    2
2    3
3    3
4    3
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.count.html, pandas.DataFrame.count
">>> df = pd.DataFrame([[np.nan, 2, np.nan, 0],
...                    [3, 4, np.nan, 1],
...                    [np.nan, np.nan, np.nan, np.nan],
...                    [np.nan, 3, np.nan, 4]],
...                   columns=list(""ABCD""))
>>> df
     A    B   C    D
0  NaN  2.0 NaN  0.0
1  3.0  4.0 NaN  1.0
2  NaN  NaN NaN  NaN
3  NaN  3.0 NaN  4.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.ffill.html, pandas.DataFrame
">>> df.ffill()
     A    B   C    D
0  NaN  2.0 NaN  0.0
1  3.0  4.0 NaN  1.0
2  3.0  4.0 NaN  1.0
3  3.0  3.0 NaN  4.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.ffill.html, pandas.DataFrame.ffill
">>> ser = pd.Series([1, np.nan, 2, 3])
>>> ser.ffill()
0   1.0
1   1.0
2   2.0
3   3.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.ffill.html, pandas.Series pandas.Series.ffill
">>> df = pd.DataFrame({'height': [1.5, 2.6], 'weight': [500, 800]},
...                   index=['elk', 'moose'])
>>> df
       height  weight
elk       1.5     500
moose     2.6     800
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.__add__.html, pandas.DataFrame
">>> s1 = pd.Series([0.5, 1.5], index=['weight', 'height'])
>>> df[['height', 'weight']] + s1
       height  weight
elk       3.0   500.5
moose     4.1   800.5
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.__add__.html, pandas.Series
">>> s2 = pd.Series([0.5, 1.5], index=['elk', 'moose'])
>>> df[['height', 'weight']] + s2
       elk  height  moose  weight
elk    NaN     NaN    NaN     NaN
moose  NaN     NaN    NaN     NaN
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.__add__.html, pandas.Series
">>> other = pd.DataFrame({'height': [0.2, 0.4, 0.6]},
...                      index=['elk', 'moose', 'deer'])
>>> df[['height', 'weight']] + other
       height  weight
deer      NaN     NaN
elk       1.7     NaN
moose     3.0     NaN
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.__add__.html, pandas.DataFrame
">>> s = pd.Series([1, 2, 2.5, 3, 3.5, 4, 5])
>>> ax = s.plot.kde()
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.density.html, pandas.Series pandas.Series.plot.kde
">>> ax = s.plot.kde(bw_method=0.3)
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.density.html, pandas.Series.plot.kde
">>> ax = s.plot.kde(bw_method=3)
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.density.html, pandas.Series.plot.kde
">>> ax = s.plot.kde(ind=[1, 2, 3, 4, 5])
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.density.html, pandas.Series.plot.kde
">>> df = pd.DataFrame({
...     'x': [1, 2, 2.5, 3, 3.5, 4, 5],
...     'y': [4, 4, 4.5, 5, 5.5, 6, 6],
... })
>>> ax = df.plot.kde()
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.density.html, pandas.DataFrame pandas.DataFrame.plot.kde
">>> ax = df.plot.kde(bw_method=0.3)
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.density.html, pandas.DataFrame.plot.kde
">>> ax = df.plot.kde(bw_method=3)
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.density.html, pandas.DataFrame.plot.kde
">>> ax = df.plot.kde(ind=[1, 2, 3, 4, 5, 6])
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.density.html, pandas.DataFrame.plot.kde
">>> df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]},
...                   index=['a', 'b', 'c'])  
>>> df.to_hdf('data.h5', key='df', mode='w')  
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_hdf.html, pandas.DataFrame pandas.DataFrame.to_hdf
">>> s = pd.Series([1, 2, 3, 4])  
>>> s.to_hdf('data.h5', key='s')  
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_hdf.html, pandas.Series pandas.Series.to_hdf
">>> pd.read_hdf('data.h5', 'df')  
A  B
a  1  4
b  2  5
c  3  6
>>> pd.read_hdf('data.h5', 's')  
0    1
1    2
2    3
3    4
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_hdf.html, pandas.read_hdf
">>> df = pd.DataFrame({'col1': [1, 2],
...                    'col2': [0.5, 0.75]},
...                   index=['row1', 'row2'])
>>> df
      col1  col2
row1     1  0.50
row2     2  0.75
>>> df.to_dict()
{'col1': {'row1': 1, 'row2': 2}, 'col2': {'row1': 0.5, 'row2': 0.75}}
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_dict.html, pandas.DataFrame
">>> import scipy.sparse
>>> mat = scipy.sparse.eye(3, dtype=float)
>>> pd.DataFrame.sparse.from_spmatrix(mat)
     0    1    2
0  1.0    0    0
1    0  1.0    0
2    0    0  1.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sparse.from_spmatrix.html, pandas.DataFrame.sparse.from_spmatrix
">>> df = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3', 'K4', 'K5'],
...                    'A': ['A0', 'A1', 'A2', 'A3', 'A4', 'A5']})
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.join.html, pandas.DataFrame
">>> other = pd.DataFrame({'key': ['K0', 'K1', 'K2'],
...                       'B': ['B0', 'B1', 'B2']})
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.join.html, pandas.DataFrame
">>> df.join(other, lsuffix='_caller', rsuffix='_other')
  key_caller   A key_other    B
0         K0  A0        K0   B0
1         K1  A1        K1   B1
2         K2  A2        K2   B2
3         K3  A3       NaN  NaN
4         K4  A4       NaN  NaN
5         K5  A5       NaN  NaN
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.join.html, pandas.DataFrame.join
">>> df.set_index('key').join(other.set_index('key'))
      A    B
key
K0   A0   B0
K1   A1   B1
K2   A2   B2
K3   A3  NaN
K4   A4  NaN
K5   A5  NaN
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.join.html, pandas.DataFrame.set_index pandas.DataFrame.set_index
">>> df.join(other.set_index('key'), on='key')
  key   A    B
0  K0  A0   B0
1  K1  A1   B1
2  K2  A2   B2
3  K3  A3  NaN
4  K4  A4  NaN
5  K5  A5  NaN
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.join.html, pandas.DataFrame.join pandas.DataFrame.set_index
">>> df = pd.DataFrame({'key': ['K0', 'K1', 'K1', 'K3', 'K0', 'K1'],
...                    'A': ['A0', 'A1', 'A2', 'A3', 'A4', 'A5']})
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.join.html, pandas.DataFrame
">>> df.join(other.set_index('key'), on='key', validate='m:1')
  key   A    B
0  K0  A0   B0
1  K1  A1   B1
2  K1  A2   B1
3  K3  A3  NaN
4  K0  A4   B0
5  K1  A5   B1
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.join.html, pandas.DataFrame.join pandas.DataFrame.set_index
">>> s = pd.Series([-1.10, 2, -3.33, 4])
>>> s.abs()
0    1.10
1    2.00
2    3.33
3    4.00
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.abs.html, pandas.Series pandas.Series.abs
">>> s = pd.Series([1.2 + 1j])
>>> s.abs()
0    1.56205
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.abs.html, pandas.Series pandas.Series.abs
">>> s = pd.Series([pd.Timedelta('1 days')])
>>> s.abs()
0   1 days
dtype: timedelta64[ns]
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.abs.html, pandas.Series pandas.Series.abs
">>> df = pd.DataFrame({
...     'a': [4, 5, 6, 7],
...     'b': [10, 20, 30, 40],
...     'c': [100, 50, -30, -50]
... })
>>> df
     a    b    c
0    4   10  100
1    5   20   50
2    6   30  -30
3    7   40  -50
>>> df.loc[(df.c - 43).abs().argsort()]
     a    b    c
1    5   20   50
0    4   10  100
2    6   30  -30
3    7   40  -50
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.abs.html, pandas.DataFrame
">>> index = pd.date_range('1/1/2000', periods=9, freq='min')
>>> series = pd.Series(range(9), index=index)
>>> series
2000-01-01 00:00:00    0
2000-01-01 00:01:00    1
2000-01-01 00:02:00    2
2000-01-01 00:03:00    3
2000-01-01 00:04:00    4
2000-01-01 00:05:00    5
2000-01-01 00:06:00    6
2000-01-01 00:07:00    7
2000-01-01 00:08:00    8
Freq: min, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.resample.html, pandas.date_range pandas.Series
">>> series.resample('3min').sum()
2000-01-01 00:00:00     3
2000-01-01 00:03:00    12
2000-01-01 00:06:00    21
Freq: 3min, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.resample.html, pandas.Series.resample
">>> series.resample('3min', label='right').sum()
2000-01-01 00:03:00     3
2000-01-01 00:06:00    12
2000-01-01 00:09:00    21
Freq: 3min, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.resample.html, pandas.Series.resample
">>> series.resample('3min', label='right', closed='right').sum()
2000-01-01 00:00:00     0
2000-01-01 00:03:00     6
2000-01-01 00:06:00    15
2000-01-01 00:09:00    15
Freq: 3min, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.resample.html, pandas.Series.resample
">>> series.resample('30s').asfreq()[0:5]   # Select first 5 rows
2000-01-01 00:00:00   0.0
2000-01-01 00:00:30   NaN
2000-01-01 00:01:00   1.0
2000-01-01 00:01:30   NaN
2000-01-01 00:02:00   2.0
Freq: 30s, dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.resample.html, pandas.Series.resample
">>> series.resample('30s').ffill()[0:5]
2000-01-01 00:00:00    0
2000-01-01 00:00:30    0
2000-01-01 00:01:00    1
2000-01-01 00:01:30    1
2000-01-01 00:02:00    2
Freq: 30s, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.resample.html, pandas.Series.resample
">>> series.resample('30s').bfill()[0:5]
2000-01-01 00:00:00    0
2000-01-01 00:00:30    1
2000-01-01 00:01:00    1
2000-01-01 00:01:30    2
2000-01-01 00:02:00    2
Freq: 30s, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.resample.html, pandas.Series.resample
">>> def custom_resampler(arraylike):
...     return np.sum(arraylike) + 5
...
>>> series.resample('3min').apply(custom_resampler)
2000-01-01 00:00:00     8
2000-01-01 00:03:00    17
2000-01-01 00:06:00    26
Freq: 3min, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.resample.html, pandas.Series.resample
">>> d = {'price': [10, 11, 9, 13, 14, 18, 17, 19],
...      'volume': [50, 60, 40, 100, 50, 100, 40, 50]}
>>> df = pd.DataFrame(d)
>>> df['week_starting'] = pd.date_range('01/01/2018',
...                                     periods=8,
...                                     freq='W')
>>> df
   price  volume week_starting
0     10      50    2018-01-07
1     11      60    2018-01-14
2      9      40    2018-01-21
3     13     100    2018-01-28
4     14      50    2018-02-04
5     18     100    2018-02-11
6     17      40    2018-02-18
7     19      50    2018-02-25
>>> df.resample('ME', on='week_starting').mean()
               price  volume
week_starting
2018-01-31     10.75    62.5
2018-02-28     17.00    60.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.resample.html, pandas.DataFrame pandas.date_range pandas.DataFrame.resample
">>> days = pd.date_range('1/1/2000', periods=4, freq='D')
>>> d2 = {'price': [10, 11, 9, 13, 14, 18, 17, 19],
...       'volume': [50, 60, 40, 100, 50, 100, 40, 50]}
>>> df2 = pd.DataFrame(
...     d2,
...     index=pd.MultiIndex.from_product(
...         [days, ['morning', 'afternoon']]
...     )
... )
>>> df2
                      price  volume
2000-01-01 morning       10      50
           afternoon     11      60
2000-01-02 morning        9      40
           afternoon     13     100
2000-01-03 morning       14      50
           afternoon     18     100
2000-01-04 morning       17      40
           afternoon     19      50
>>> df2.resample('D', level=0).sum()
            price  volume
2000-01-01     21     110
2000-01-02     22     140
2000-01-03     32     150
2000-01-04     36      90
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.resample.html, pandas.date_range pandas.DataFrame pandas.MultiIndex.from_product pandas.DataFrame.resample
">>> start, end = '2000-10-01 23:30:00', '2000-10-02 00:30:00'
>>> rng = pd.date_range(start, end, freq='7min')
>>> ts = pd.Series(np.arange(len(rng)) * 3, index=rng)
>>> ts
2000-10-01 23:30:00     0
2000-10-01 23:37:00     3
2000-10-01 23:44:00     6
2000-10-01 23:51:00     9
2000-10-01 23:58:00    12
2000-10-02 00:05:00    15
2000-10-02 00:12:00    18
2000-10-02 00:19:00    21
2000-10-02 00:26:00    24
Freq: 7min, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.resample.html, pandas.date_range pandas.Series
">>> ts.resample('17min').sum()
2000-10-01 23:14:00     0
2000-10-01 23:31:00     9
2000-10-01 23:48:00    21
2000-10-02 00:05:00    54
2000-10-02 00:22:00    24
Freq: 17min, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.resample.html, pandas.Series.resample
">>> ts.resample('17min', origin='epoch').sum()
2000-10-01 23:18:00     0
2000-10-01 23:35:00    18
2000-10-01 23:52:00    27
2000-10-02 00:09:00    39
2000-10-02 00:26:00    24
Freq: 17min, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.resample.html, pandas.Series.resample
">>> ts.resample('17min', origin='2000-01-01').sum()
2000-10-01 23:24:00     3
2000-10-01 23:41:00    15
2000-10-01 23:58:00    45
2000-10-02 00:15:00    45
Freq: 17min, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.resample.html, pandas.Series.resample
">>> ts.resample('17min', origin='start').sum()
2000-10-01 23:30:00     9
2000-10-01 23:47:00    21
2000-10-02 00:04:00    54
2000-10-02 00:21:00    24
Freq: 17min, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.resample.html, pandas.Series.resample
">>> ts.resample('17min', offset='23h30min').sum()
2000-10-01 23:30:00     9
2000-10-01 23:47:00    21
2000-10-02 00:04:00    54
2000-10-02 00:21:00    24
Freq: 17min, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.resample.html, pandas.Series.resample
">>> ts.resample('17min', origin='end').sum()
2000-10-01 23:35:00     0
2000-10-01 23:52:00    18
2000-10-02 00:09:00    27
2000-10-02 00:26:00    63
Freq: 17min, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.resample.html, pandas.Series.resample
">>> ts.resample('17min', origin='end_day').sum()
2000-10-01 23:38:00     3
2000-10-01 23:55:00    15
2000-10-02 00:12:00    45
2000-10-02 00:29:00    45
Freq: 17min, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.resample.html, pandas.Series.resample
">>> df = pd.DataFrame({'lab':['A', 'B', 'C'], 'val':[10, 30, 20]})
>>> ax = df.plot.bar(x='lab', y='val', rot=0)
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.bar.html, pandas.DataFrame pandas.DataFrame.plot.bar
">>> speed = [0.1, 17.5, 40, 48, 52, 69, 88]
>>> lifespan = [2, 8, 70, 1.5, 25, 12, 28]
>>> index = ['snail', 'pig', 'elephant',
...          'rabbit', 'giraffe', 'coyote', 'horse']
>>> df = pd.DataFrame({'speed': speed,
...                    'lifespan': lifespan}, index=index)
>>> ax = df.plot.bar(rot=0)
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.bar.html, pandas.DataFrame pandas.DataFrame.plot.bar
">>> ax = df.plot.bar(stacked=True)
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.bar.html, pandas.DataFrame.plot.bar
">>> axes = df.plot.bar(rot=0, subplots=True)
>>> axes[1].legend(loc=2)  
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.bar.html, pandas.DataFrame.plot.bar
">>> axes = df.plot.bar(
...     rot=0, subplots=True, color={""speed"": ""red"", ""lifespan"": ""green""}
... )
>>> axes[1].legend(loc=2)  
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.bar.html, pandas.DataFrame.plot.bar
">>> ax = df.plot.bar(y='speed', rot=0)
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.bar.html, pandas.DataFrame.plot.bar
">>> ax = df.plot.bar(x='lifespan', rot=0)
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.bar.html, pandas.DataFrame.plot.bar
">>> s = pd.Series({'a': 1, 'b': 2, 'c': 3})
>>> s.size
3
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.size.html, pandas.Series
">>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})
>>> df.size
4
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.size.html, pandas.DataFrame
">>> df = pd.DataFrame(dict(age=[5, 6, np.nan],
...                        born=[pd.NaT, pd.Timestamp('1939-05-27'),
...                              pd.Timestamp('1940-04-25')],
...                        name=['Alfred', 'Batman', ''],
...                        toy=[None, 'Batmobile', 'Joker']))
>>> df
   age       born    name        toy
0  5.0        NaT  Alfred       None
1  6.0 1939-05-27  Batman  Batmobile
2  NaN 1940-04-25              Joker
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isna.html, pandas.DataFrame
">>> df.isna()
     age   born   name    toy
0  False   True  False   True
1  False  False  False  False
2   True  False  False  False
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isna.html, pandas.DataFrame.isna
">>> ser = pd.Series([5, 6, np.nan])
>>> ser
0    5.0
1    6.0
2    NaN
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isna.html, pandas.Series
">>> ser.isna()
0    False
1    False
2     True
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isna.html, pandas.Series.isna
">>> mydict = [{'a': 1, 'b': 2, 'c': 3, 'd': 4},
...           {'a': 100, 'b': 200, 'c': 300, 'd': 400},
...           {'a': 1000, 'b': 2000, 'c': 3000, 'd': 4000}]
>>> df = pd.DataFrame(mydict)
>>> df
      a     b     c     d
0     1     2     3     4
1   100   200   300   400
2  1000  2000  3000  4000
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iloc.html, pandas.DataFrame
">>> df = pd.DataFrame({'A': range(3), 'B': range(1, 4)})
>>> df
   A  B
0  0  1
1  1  2
2  2  3
>>> df.transform(lambda x: x + 1)
   A  B
0  1  2
1  2  3
2  3  4
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.transform.html, pandas.DataFrame pandas.DataFrame.transform
">>> s = pd.Series(range(3))
>>> s
0    0
1    1
2    2
dtype: int64
>>> s.transform([np.sqrt, np.exp])
       sqrt        exp
0  0.000000   1.000000
1  1.000000   2.718282
2  1.414214   7.389056
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.transform.html, pandas.Series pandas.Series.transform
">>> df = pd.DataFrame({
...     ""Date"": [
...         ""2015-05-08"", ""2015-05-07"", ""2015-05-06"", ""2015-05-05"",
...         ""2015-05-08"", ""2015-05-07"", ""2015-05-06"", ""2015-05-05""],
...     ""Data"": [5, 8, 6, 1, 50, 100, 60, 120],
... })
>>> df
         Date  Data
0  2015-05-08     5
1  2015-05-07     8
2  2015-05-06     6
3  2015-05-05     1
4  2015-05-08    50
5  2015-05-07   100
6  2015-05-06    60
7  2015-05-05   120
>>> df.groupby('Date')['Data'].transform('sum')
0     55
1    108
2     66
3    121
4     55
5    108
6     66
7    121
Name: Data, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.transform.html, pandas.DataFrame pandas.DataFrame.groupby
">>> df = pd.DataFrame({
...     ""c"": [1, 1, 1, 2, 2, 2, 2],
...     ""type"": [""m"", ""n"", ""o"", ""m"", ""m"", ""n"", ""n""]
... })
>>> df
   c type
0  1    m
1  1    n
2  1    o
3  2    m
4  2    m
5  2    n
6  2    n
>>> df['size'] = df.groupby('c')['type'].transform(len)
>>> df
   c type size
0  1    m    3
1  1    n    3
2  1    o    3
3  2    m    4
4  2    m    4
5  2    n    4
6  2    n    4
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.transform.html, pandas.DataFrame pandas.DataFrame.groupby
">>> df = pd.DataFrame([[1, 2.12], [3.356, 4.567]])
>>> df
       0      1
0  1.000  2.120
1  3.356  4.567
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.applymap.html, pandas.DataFrame
">>> df.map(lambda x: len(str(x)))
   0  1
0  3  4
1  5  5
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.applymap.html, pandas.DataFrame.map
">>> df1 = pd.DataFrame([[24.3, 75.7, 'high'],
...                     [31, 87.8, 'high'],
...                     [22, 71.6, 'medium'],
...                     [35, 95, 'medium']],
...                    columns=['temp_celsius', 'temp_fahrenheit',
...                             'windspeed'],
...                    index=pd.date_range(start='2014-02-12',
...                                        end='2014-02-15', freq='D'))
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reindex_like.html, pandas.DataFrame pandas.date_range
">>> df2 = pd.DataFrame([[28, 'low'],
...                     [30, 'low'],
...                     [35.1, 'medium']],
...                    columns=['temp_celsius', 'windspeed'],
...                    index=pd.DatetimeIndex(['2014-02-12', '2014-02-13',
...                                            '2014-02-15']))
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reindex_like.html, pandas.DataFrame pandas.DatetimeIndex
">>> df2.reindex_like(df1)
            temp_celsius  temp_fahrenheit windspeed
2014-02-12          28.0              NaN       low
2014-02-13          30.0              NaN       low
2014-02-14           NaN              NaN       NaN
2014-02-15          35.1              NaN    medium
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reindex_like.html, pandas.DataFrame.reindex_like
">>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})
>>> df.shape
(2, 2)
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.shape.html, pandas.DataFrame
">>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4],
...                    'col3': [5, 6]})
>>> df.shape
(2, 3)
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.shape.html, pandas.DataFrame
">>> df = pd.DataFrame({'angles': [0, 3, 4],
...                    'degrees': [360, 180, 360]},
...                   index=['circle', 'triangle', 'rectangle'])
>>> df
           angles  degrees
circle          0      360
triangle        3      180
rectangle       4      360
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rdiv.html, pandas.DataFrame
">>> df.add(1)
           angles  degrees
circle          1      361
triangle        4      181
rectangle       5      361
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rdiv.html, pandas.DataFrame.add
">>> df.div(10)
           angles  degrees
circle        0.0     36.0
triangle      0.3     18.0
rectangle     0.4     36.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rdiv.html, pandas.DataFrame.div
">>> df.rdiv(10)
             angles   degrees
circle          inf  0.027778
triangle   3.333333  0.055556
rectangle  2.500000  0.027778
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rdiv.html, pandas.DataFrame.rdiv
">>> df.sub([1, 2], axis='columns')
           angles  degrees
circle         -1      358
triangle        2      178
rectangle       3      358
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rdiv.html, pandas.DataFrame.sub
">>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),
...        axis='index')
           angles  degrees
circle         -1      359
triangle        2      179
rectangle       3      359
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rdiv.html, pandas.DataFrame.sub pandas.Series
">>> df.mul({'angles': 0, 'degrees': 2})
            angles  degrees
circle           0      720
triangle         0      360
rectangle        0      720
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rdiv.html, pandas.DataFrame.mul
">>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')
            angles  degrees
circle           0        0
triangle         6      360
rectangle       12     1080
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rdiv.html, pandas.DataFrame.mul
">>> other = pd.DataFrame({'angles': [0, 3, 4]},
...                      index=['circle', 'triangle', 'rectangle'])
>>> other
           angles
circle          0
triangle        3
rectangle       4
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rdiv.html, pandas.DataFrame
">>> df.mul(other, fill_value=0)
           angles  degrees
circle          0      0.0
triangle        9      0.0
rectangle      16      0.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rdiv.html, pandas.DataFrame.mul
">>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],
...                              'degrees': [360, 180, 360, 360, 540, 720]},
...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],
...                                    ['circle', 'triangle', 'rectangle',
...                                     'square', 'pentagon', 'hexagon']])
>>> df_multindex
             angles  degrees
A circle          0      360
  triangle        3      180
  rectangle       4      360
B square          4      360
  pentagon        5      540
  hexagon         6      720
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rdiv.html, pandas.DataFrame
">>> df.div(df_multindex, level=1, fill_value=0)
             angles  degrees
A circle        NaN      1.0
  triangle      1.0      1.0
  rectangle     1.0      1.0
B square        0.0      0.0
  pentagon      0.0      0.0
  hexagon       0.0      0.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rdiv.html, pandas.DataFrame.div
">>> d = pd.DataFrame(data={'A': [1, 2, 3], 'B': [0, 4, 8]},
...                  index=['a', 'b', 'c'])
>>> d
   A  B
a  1  0
b  2  4
c  3  8
>>> d.keys()
Index(['A', 'B'], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.keys.html, pandas.DataFrame pandas.DataFrame.keys pandas.Index
">>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})
>>> df.axes
[RangeIndex(start=0, stop=2, step=1), Index(['col1', 'col2'],
dtype='object')]
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.axes.html, pandas.DataFrame pandas.RangeIndex pandas.Index
">>> s = pd.Series([1, 2, 3])
>>> s.describe()
count    3.0
mean     2.0
std      1.0
min      1.0
25%      1.5
50%      2.0
75%      2.5
max      3.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html, pandas.Series pandas.Series.describe
">>> s = pd.Series(['a', 'a', 'b', 'c'])
>>> s.describe()
count     4
unique    3
top       a
freq      2
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html, pandas.Series pandas.Series.describe
">>> s = pd.Series([
...     np.datetime64(""2000-01-01""),
...     np.datetime64(""2010-01-01""),
...     np.datetime64(""2010-01-01"")
... ])
>>> s.describe()
count                      3
mean     2006-09-01 08:00:00
min      2000-01-01 00:00:00
25%      2004-12-31 12:00:00
50%      2010-01-01 00:00:00
75%      2010-01-01 00:00:00
max      2010-01-01 00:00:00
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html, pandas.Series pandas.Series.describe
">>> df = pd.DataFrame({'categorical': pd.Categorical(['d', 'e', 'f']),
...                    'numeric': [1, 2, 3],
...                    'object': ['a', 'b', 'c']
...                    })
>>> df.describe()
       numeric
count      3.0
mean       2.0
std        1.0
min        1.0
25%        1.5
50%        2.0
75%        2.5
max        3.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html, pandas.DataFrame pandas.Categorical pandas.DataFrame.describe
">>> df.describe(include='all')  
       categorical  numeric object
count            3      3.0      3
unique           3      NaN      3
top              f      NaN      a
freq             1      NaN      1
mean           NaN      2.0    NaN
std            NaN      1.0    NaN
min            NaN      1.0    NaN
25%            NaN      1.5    NaN
50%            NaN      2.0    NaN
75%            NaN      2.5    NaN
max            NaN      3.0    NaN
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html, pandas.DataFrame.describe
">>> df.describe(include=[np.number])
       numeric
count      3.0
mean       2.0
std        1.0
min        1.0
25%        1.5
50%        2.0
75%        2.5
max        3.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html, pandas.DataFrame.describe
">>> df.describe(include=[object])  
       object
count       3
unique      3
top         a
freq        1
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html, pandas.DataFrame.describe
">>> df.describe(include=['category'])
       categorical
count            3
unique           3
top              d
freq             1
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html, pandas.DataFrame.describe
">>> df.describe(exclude=[np.number])  
       categorical object
count            3      3
unique           3      3
top              f      a
freq             1      1
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html, pandas.DataFrame.describe
">>> df.describe(exclude=[object])  
       categorical  numeric
count            3      3.0
unique           3      NaN
top              f      NaN
freq             1      NaN
mean           NaN      2.0
std            NaN      1.0
min            NaN      1.0
25%            NaN      1.5
50%            NaN      2.0
75%            NaN      2.5
max            NaN      3.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html, pandas.DataFrame.describe
">>> df = pd.DataFrame({'cost': [250, 150, 100],
...                    'revenue': [100, 250, 300]},
...                   index=['A', 'B', 'C'])
>>> df
   cost  revenue
A   250      100
B   150      250
C   100      300
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.le.html, pandas.DataFrame
">>> df.eq(100)
    cost  revenue
A  False     True
B  False    False
C   True    False
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.le.html, pandas.DataFrame.eq
">>> df != pd.Series([100, 250], index=[""cost"", ""revenue""])
    cost  revenue
A   True     True
B   True    False
C  False     True
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.le.html, pandas.Series
">>> df.ne(pd.Series([100, 300], index=[""A"", ""D""]), axis='index')
   cost  revenue
A  True    False
B  True     True
C  True     True
D  True     True
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.le.html, pandas.DataFrame.ne pandas.Series
">>> df.eq([250, 250, 100], axis='index')
    cost  revenue
A   True    False
B  False     True
C   True    False
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.le.html, pandas.DataFrame.eq
">>> other = pd.DataFrame({'revenue': [300, 250, 100, 150]},
...                      index=['A', 'B', 'C', 'D'])
>>> other
   revenue
A      300
B      250
C      100
D      150
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.le.html, pandas.DataFrame
">>> df.gt(other)
    cost  revenue
A  False    False
B  False    False
C  False     True
D  False    False
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.le.html, pandas.DataFrame.gt
">>> df_multindex = pd.DataFrame({'cost': [250, 150, 100, 150, 300, 220],
...                              'revenue': [100, 250, 300, 200, 175, 225]},
...                             index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'],
...                                    ['A', 'B', 'C', 'A', 'B', 'C']])
>>> df_multindex
      cost  revenue
Q1 A   250      100
   B   150      250
   C   100      300
Q2 A   150      200
   B   300      175
   C   220      225
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.le.html, pandas.DataFrame
">>> df.le(df_multindex, level=1)
       cost  revenue
Q1 A   True     True
   B   True     True
   C   True     True
Q2 A  False     True
   B   True    False
   C   True    False
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.le.html, pandas.DataFrame.le
">>> df = pd.DataFrame({'species': ['bear', 'bear', 'marsupial'],
...                   'population': [1864, 22000, 80000]},
...                   index=['panda', 'polar', 'koala'])
>>> df
        species   population
panda   bear      1864
polar   bear      22000
koala   marsupial 80000
>>> for label, content in df.items():
...     print(f'label: {label}')
...     print(f'content: {content}', sep='\n')
...
label: species
content:
panda         bear
polar         bear
koala    marsupial
Name: species, dtype: object
label: population
content:
panda     1864
polar    22000
koala    80000
Name: population, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.items.html, pandas.DataFrame pandas.DataFrame.items
">>> df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],
...                   index=['cobra', 'viper', 'sidewinder'],
...                   columns=['max_speed', 'shield'])
>>> df
            max_speed  shield
cobra               1       2
viper               4       5
sidewinder          7       8
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html, pandas.DataFrame
">>> df.loc[pd.Series([False, True, False],
...                  index=['viper', 'sidewinder', 'cobra'])]
                     max_speed  shield
sidewinder          7       8
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html, pandas.Series
">>> df.loc[pd.Index([""cobra"", ""viper""], name=""foo"")]
       max_speed  shield
foo
cobra          1       2
viper          4       5
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html, pandas.Index
">>> df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],
...                   index=[7, 8, 9], columns=['max_speed', 'shield'])
>>> df
   max_speed  shield
7          1       2
8          4       5
9          7       8
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html, pandas.DataFrame
">>> tuples = [
...     ('cobra', 'mark i'), ('cobra', 'mark ii'),
...     ('sidewinder', 'mark i'), ('sidewinder', 'mark ii'),
...     ('viper', 'mark ii'), ('viper', 'mark iii')
... ]
>>> index = pd.MultiIndex.from_tuples(tuples)
>>> values = [[12, 2], [0, 4], [10, 20],
...           [1, 4], [7, 1], [16, 36]]
>>> df = pd.DataFrame(values, columns=['max_speed', 'shield'], index=index)
>>> df
                     max_speed  shield
cobra      mark i           12       2
           mark ii           0       4
sidewinder mark i           10      20
           mark ii           1       4
viper      mark ii           7       1
           mark iii         16      36
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html, pandas.MultiIndex.from_tuples pandas.DataFrame
">>> n = 10000
>>> df = pd.DataFrame({'x': np.random.randn(n),
...                    'y': np.random.randn(n)})
>>> ax = df.plot.hexbin(x='x', y='y', gridsize=20)
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.hexbin.html, pandas.DataFrame pandas.DataFrame.plot.hexbin
">>> n = 500
>>> df = pd.DataFrame({
...     'coord_x': np.random.uniform(-3, 3, size=n),
...     'coord_y': np.random.uniform(30, 50, size=n),
...     'observations': np.random.randint(1,5, size=n)
...     })
>>> ax = df.plot.hexbin(x='coord_x',
...                     y='coord_y',
...                     C='observations',
...                     reduce_C_function=np.sum,
...                     gridsize=10,
...                     cmap=""viridis"")
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.hexbin.html, pandas.DataFrame pandas.DataFrame.plot.hexbin
">>> df = pd.DataFrame({'float': [1.0],
...                    'int': [1],
...                    'datetime': [pd.Timestamp('20180310')],
...                    'string': ['foo']})
>>> df.dtypes
float              float64
int                  int64
datetime    datetime64[ns]
string              object
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dtypes.html, pandas.DataFrame
">>> ser = pd.Series([1, 2, 3, 3])
>>> plot = ser.plot(kind='hist', title=""My plot"")
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html, pandas.Series pandas.Series.plot
">>> df = pd.DataFrame({'length': [1.5, 0.5, 1.2, 0.9, 3],
...                   'width': [0.7, 0.2, 0.15, 0.2, 1.1]},
...                   index=['pig', 'rabbit', 'duck', 'chicken', 'horse'])
>>> plot = df.plot(title=""DataFrame Plot"")
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html, pandas.DataFrame pandas.DataFrame.plot
">>> lst = [-1, -2, -3, 1, 2, 3]
>>> ser = pd.Series([1, 2, 2, 4, 6, 6], index=lst)
>>> plot = ser.groupby(lambda x: x > 0).plot(title=""SeriesGroupBy Plot"")
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html, pandas.Series pandas.Series.groupby
">>> df = pd.DataFrame({""col1"" : [1, 2, 3, 4],
...                   ""col2"" : [""A"", ""B"", ""A"", ""B""]})
>>> plot = df.groupby(""col2"").plot(kind=""bar"", title=""DataFrameGroupBy Plot"")
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html, pandas.DataFrame pandas.DataFrame.groupby
">>> df = pd.DataFrame({""A"": [1, 2, 3], ""B"": [4, 5, 6]})
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.set_axis.html, pandas.DataFrame
">>> df.set_axis(['a', 'b', 'c'], axis='index')
   A  B
a  1  4
b  2  5
c  3  6
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.set_axis.html, pandas.DataFrame.set_axis
">>> df.set_axis(['I', 'II'], axis='columns')
   I  II
0  1   4
1  2   5
2  3   6
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.set_axis.html, pandas.DataFrame.set_axis
">>> df = pd.DataFrame({'cost': [250, 150, 100],
...                    'revenue': [100, 250, 300]},
...                   index=['A', 'B', 'C'])
>>> df
   cost  revenue
A   250      100
B   150      250
C   100      300
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.gt.html, pandas.DataFrame
">>> df.eq(100)
    cost  revenue
A  False     True
B  False    False
C   True    False
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.gt.html, pandas.DataFrame.eq
">>> df != pd.Series([100, 250], index=[""cost"", ""revenue""])
    cost  revenue
A   True     True
B   True    False
C  False     True
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.gt.html, pandas.Series
">>> df.ne(pd.Series([100, 300], index=[""A"", ""D""]), axis='index')
   cost  revenue
A  True    False
B  True     True
C  True     True
D  True     True
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.gt.html, pandas.DataFrame.ne pandas.Series
">>> df.eq([250, 250, 100], axis='index')
    cost  revenue
A   True    False
B  False     True
C   True    False
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.gt.html, pandas.DataFrame.eq
">>> other = pd.DataFrame({'revenue': [300, 250, 100, 150]},
...                      index=['A', 'B', 'C', 'D'])
>>> other
   revenue
A      300
B      250
C      100
D      150
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.gt.html, pandas.DataFrame
">>> df.gt(other)
    cost  revenue
A  False    False
B  False    False
C  False     True
D  False    False
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.gt.html, pandas.DataFrame.gt
">>> df_multindex = pd.DataFrame({'cost': [250, 150, 100, 150, 300, 220],
...                              'revenue': [100, 250, 300, 200, 175, 225]},
...                             index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'],
...                                    ['A', 'B', 'C', 'A', 'B', 'C']])
>>> df_multindex
      cost  revenue
Q1 A   250      100
   B   150      250
   C   100      300
Q2 A   150      200
   B   300      175
   C   220      225
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.gt.html, pandas.DataFrame
">>> df.le(df_multindex, level=1)
       cost  revenue
Q1 A   True     True
   B   True     True
   C   True     True
Q2 A  False     True
   B   True    False
   C   True    False
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.gt.html, pandas.DataFrame.le
">>> df = pd.DataFrame({'A': {0: 'a', 1: 'b', 2: 'c'},
...                    'B': {0: 1, 1: 3, 2: 5},
...                    'C': {0: 2, 1: 4, 2: 6}})
>>> df
   A  B  C
0  a  1  2
1  b  3  4
2  c  5  6
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.melt.html, pandas.DataFrame
">>> df.melt(id_vars=['A'], value_vars=['B'])
   A variable  value
0  a        B      1
1  b        B      3
2  c        B      5
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.melt.html, pandas.DataFrame.melt
">>> df.melt(id_vars=['A'], value_vars=['B', 'C'])
   A variable  value
0  a        B      1
1  b        B      3
2  c        B      5
3  a        C      2
4  b        C      4
5  c        C      6
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.melt.html, pandas.DataFrame.melt
">>> df.melt(id_vars=['A'], value_vars=['B'],
...         var_name='myVarname', value_name='myValname')
   A myVarname  myValname
0  a         B          1
1  b         B          3
2  c         B          5
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.melt.html, pandas.DataFrame.melt
">>> df.melt(id_vars=['A'], value_vars=['B', 'C'], ignore_index=False)
   A variable  value
0  a        B      1
1  b        B      3
2  c        B      5
0  a        C      2
1  b        C      4
2  c        C      6
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.melt.html, pandas.DataFrame.melt
">>> df.melt(col_level=0, id_vars=['A'], value_vars=['B'])
   A variable  value
0  a        B      1
1  b        B      3
2  c        B      5
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.melt.html, pandas.DataFrame.melt
">>> df.melt(id_vars=[('A', 'D')], value_vars=[('B', 'E')])
  (A, D) variable_0 variable_1  value
0      a          B          E      1
1      b          B          E      3
2      c          B          E      5
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.melt.html, pandas.DataFrame.melt
">>> df = pd.DataFrame([(1, 2), (0, 3), (2, 0), (1, 1)],
...                   columns=['dogs', 'cats'])
>>> df.cov()
          dogs      cats
dogs  0.666667 -1.000000
cats -1.000000  1.666667
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.cov.html, pandas.DataFrame pandas.DataFrame.cov
">>> np.random.seed(42)
>>> df = pd.DataFrame(np.random.randn(1000, 5),
...                   columns=['a', 'b', 'c', 'd', 'e'])
>>> df.cov()
          a         b         c         d         e
a  0.998438 -0.020161  0.059277 -0.008943  0.014144
b -0.020161  1.059352 -0.008543 -0.024738  0.009826
c  0.059277 -0.008543  1.010670 -0.001486 -0.000271
d -0.008943 -0.024738 -0.001486  0.921297 -0.013692
e  0.014144  0.009826 -0.000271 -0.013692  0.977795
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.cov.html, pandas.DataFrame pandas.DataFrame.cov
">>> np.random.seed(42)
>>> df = pd.DataFrame(np.random.randn(20, 3),
...                   columns=['a', 'b', 'c'])
>>> df.loc[df.index[:5], 'a'] = np.nan
>>> df.loc[df.index[5:10], 'b'] = np.nan
>>> df.cov(min_periods=12)
          a         b         c
a  0.316741       NaN -0.150812
b       NaN  1.248003  0.191417
c -0.150812  0.191417  0.895202
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.cov.html, pandas.DataFrame pandas.DataFrame.cov
">>> df = pd.DataFrame({'angles': [0, 3, 4],
...                    'degrees': [360, 180, 360]},
...                   index=['circle', 'triangle', 'rectangle'])
>>> df
           angles  degrees
circle          0      360
triangle        3      180
rectangle       4      360
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.truediv.html, pandas.DataFrame
">>> df.add(1)
           angles  degrees
circle          1      361
triangle        4      181
rectangle       5      361
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.truediv.html, pandas.DataFrame.add
">>> df.div(10)
           angles  degrees
circle        0.0     36.0
triangle      0.3     18.0
rectangle     0.4     36.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.truediv.html, pandas.DataFrame.div
">>> df.rdiv(10)
             angles   degrees
circle          inf  0.027778
triangle   3.333333  0.055556
rectangle  2.500000  0.027778
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.truediv.html, pandas.DataFrame.rdiv
">>> df.sub([1, 2], axis='columns')
           angles  degrees
circle         -1      358
triangle        2      178
rectangle       3      358
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.truediv.html, pandas.DataFrame.sub
">>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),
...        axis='index')
           angles  degrees
circle         -1      359
triangle        2      179
rectangle       3      359
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.truediv.html, pandas.DataFrame.sub pandas.Series
">>> df.mul({'angles': 0, 'degrees': 2})
            angles  degrees
circle           0      720
triangle         0      360
rectangle        0      720
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.truediv.html, pandas.DataFrame.mul
">>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')
            angles  degrees
circle           0        0
triangle         6      360
rectangle       12     1080
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.truediv.html, pandas.DataFrame.mul
">>> other = pd.DataFrame({'angles': [0, 3, 4]},
...                      index=['circle', 'triangle', 'rectangle'])
>>> other
           angles
circle          0
triangle        3
rectangle       4
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.truediv.html, pandas.DataFrame
">>> df.mul(other, fill_value=0)
           angles  degrees
circle          0      0.0
triangle        9      0.0
rectangle      16      0.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.truediv.html, pandas.DataFrame.mul
">>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],
...                              'degrees': [360, 180, 360, 360, 540, 720]},
...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],
...                                    ['circle', 'triangle', 'rectangle',
...                                     'square', 'pentagon', 'hexagon']])
>>> df_multindex
             angles  degrees
A circle          0      360
  triangle        3      180
  rectangle       4      360
B square          4      360
  pentagon        5      540
  hexagon         6      720
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.truediv.html, pandas.DataFrame
">>> df.div(df_multindex, level=1, fill_value=0)
             angles  degrees
A circle        NaN      1.0
  triangle      1.0      1.0
  rectangle     1.0      1.0
B square        0.0      0.0
  pentagon      0.0      0.0
  hexagon       0.0      0.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.truediv.html, pandas.DataFrame.div
">>> s = pd.Series([1, 2], index=[""a"", ""b""])
>>> s
a    1
b    2
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.copy.html, pandas.Series
">>> s_copy = s.copy()
>>> s_copy
a    1
b    2
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.copy.html, pandas.Series.copy
">>> s = pd.Series([1, 2], index=[""a"", ""b""])
>>> deep = s.copy()
>>> shallow = s.copy(deep=False)
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.copy.html, pandas.Series pandas.Series.copy
">>> s = pd.Series([[1, 2], [3, 4]])
>>> deep = s.copy()
>>> s[0][0] = 10
>>> s
0    [10, 2]
1     [3, 4]
dtype: object
>>> deep
0    [10, 2]
1     [3, 4]
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.copy.html, pandas.Series pandas.Series.copy
">>> with pd.option_context(""mode.copy_on_write"", True):
...     s = pd.Series([1, 2], index=[""a"", ""b""])
...     copy = s.copy(deep=False)
...     s.iloc[0] = 100
...     s
a    100
b      2
dtype: int64
>>> copy
a    1
b    2
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.copy.html, pandas.Series pandas.Series.copy
">>> s = pd.Series(range(5))
>>> s.where(s > 0)
0    NaN
1    1.0
2    2.0
3    3.0
4    4.0
dtype: float64
>>> s.mask(s > 0)
0    0.0
1    NaN
2    NaN
3    NaN
4    NaN
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mask.html, pandas.Series pandas.Series.where pandas.Series.mask
">>> s = pd.Series(range(5))
>>> t = pd.Series([True, False])
>>> s.where(t, 99)
0     0
1    99
2    99
3    99
4    99
dtype: int64
>>> s.mask(t, 99)
0    99
1     1
2    99
3    99
4    99
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mask.html, pandas.Series pandas.Series.where pandas.Series.mask
">>> s.where(s > 1, 10)
0    10
1    10
2    2
3    3
4    4
dtype: int64
>>> s.mask(s > 1, 10)
0     0
1     1
2    10
3    10
4    10
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mask.html, pandas.Series.where pandas.Series.mask
">>> df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=['A', 'B'])
>>> df
   A  B
0  0  1
1  2  3
2  4  5
3  6  7
4  8  9
>>> m = df % 3 == 0
>>> df.where(m, -df)
   A  B
0  0 -1
1 -2  3
2 -4 -5
3  6 -7
4 -8  9
>>> df.where(m, -df) == np.where(m, df, -df)
      A     B
0  True  True
1  True  True
2  True  True
3  True  True
4  True  True
>>> df.where(m, -df) == df.mask(~m, -df)
      A     B
0  True  True
1  True  True
2  True  True
3  True  True
4  True  True
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mask.html, pandas.DataFrame pandas.DataFrame.where pandas.DataFrame.mask
">>> df = pd.DataFrame(np.arange(12).reshape(3, 4),
...                   columns=['A', 'B', 'C', 'D'])
>>> df
   A  B   C   D
0  0  1   2   3
1  4  5   6   7
2  8  9  10  11
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html, pandas.DataFrame
">>> df.drop(['B', 'C'], axis=1)
   A   D
0  0   3
1  4   7
2  8  11
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html, pandas.DataFrame.drop
">>> df.drop(columns=['B', 'C'])
   A   D
0  0   3
1  4   7
2  8  11
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html, pandas.DataFrame.drop
">>> df.drop([0, 1])
   A  B   C   D
2  8  9  10  11
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html, pandas.DataFrame.drop
">>> midx = pd.MultiIndex(levels=[['llama', 'cow', 'falcon'],
...                              ['speed', 'weight', 'length']],
...                      codes=[[0, 0, 0, 1, 1, 1, 2, 2, 2],
...                             [0, 1, 2, 0, 1, 2, 0, 1, 2]])
>>> df = pd.DataFrame(index=midx, columns=['big', 'small'],
...                   data=[[45, 30], [200, 100], [1.5, 1], [30, 20],
...                         [250, 150], [1.5, 0.8], [320, 250],
...                         [1, 0.8], [0.3, 0.2]])
>>> df
                big     small
llama   speed   45.0    30.0
        weight  200.0   100.0
        length  1.5     1.0
cow     speed   30.0    20.0
        weight  250.0   150.0
        length  1.5     0.8
falcon  speed   320.0   250.0
        weight  1.0     0.8
        length  0.3     0.2
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html, pandas.MultiIndex pandas.DataFrame
">>> df.drop(index=('falcon', 'weight'))
                big     small
llama   speed   45.0    30.0
        weight  200.0   100.0
        length  1.5     1.0
cow     speed   30.0    20.0
        weight  250.0   150.0
        length  1.5     0.8
falcon  speed   320.0   250.0
        length  0.3     0.2
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html, pandas.DataFrame.drop
">>> df.drop(index='cow', columns='small')
                big
llama   speed   45.0
        weight  200.0
        length  1.5
falcon  speed   320.0
        weight  1.0
        length  0.3
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html, pandas.DataFrame.drop
">>> df.drop(index='length', level=1)
                big     small
llama   speed   45.0    30.0
        weight  200.0   100.0
cow     speed   30.0    20.0
        weight  250.0   150.0
falcon  speed   320.0   250.0
        weight  1.0     0.8
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html, pandas.DataFrame.drop
">>> df = pd.DataFrame({'Animal': ['Falcon', 'Falcon',
...                               'Parrot', 'Parrot'],
...                    'Max Speed': [380., 370., 24., 26.]})
>>> df
   Animal  Max Speed
0  Falcon      380.0
1  Falcon      370.0
2  Parrot       24.0
3  Parrot       26.0
>>> df.groupby(['Animal']).mean()
        Max Speed
Animal
Falcon      375.0
Parrot       25.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html, pandas.DataFrame pandas.DataFrame.groupby
">>> arrays = [['Falcon', 'Falcon', 'Parrot', 'Parrot'],
...           ['Captive', 'Wild', 'Captive', 'Wild']]
>>> index = pd.MultiIndex.from_arrays(arrays, names=('Animal', 'Type'))
>>> df = pd.DataFrame({'Max Speed': [390., 350., 30., 20.]},
...                   index=index)
>>> df
                Max Speed
Animal Type
Falcon Captive      390.0
       Wild         350.0
Parrot Captive       30.0
       Wild          20.0
>>> df.groupby(level=0).mean()
        Max Speed
Animal
Falcon      370.0
Parrot       25.0
>>> df.groupby(level=""Type"").mean()
         Max Speed
Type
Captive      210.0
Wild         185.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html, pandas.MultiIndex.from_arrays pandas.DataFrame pandas.DataFrame.groupby
">>> l = [[1, 2, 3], [1, None, 4], [2, 1, 3], [1, 2, 2]]
>>> df = pd.DataFrame(l, columns=[""a"", ""b"", ""c""])
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html, pandas.DataFrame
">>> df.groupby(by=[""b""]).sum()
    a   c
b
1.0 2   3
2.0 2   5
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html, pandas.DataFrame.groupby
">>> df.groupby(by=[""b""], dropna=False).sum()
    a   c
b
1.0 2   3
2.0 2   5
NaN 1   4
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html, pandas.DataFrame.groupby
">>> l = [[""a"", 12, 12], [None, 12.3, 33.], [""b"", 12.3, 123], [""a"", 1, 1]]
>>> df = pd.DataFrame(l, columns=[""a"", ""b"", ""c""])
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html, pandas.DataFrame
">>> df.groupby(by=""a"").sum()
    b     c
a
a   13.0   13.0
b   12.3  123.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html, pandas.DataFrame.groupby
">>> df.groupby(by=""a"", dropna=False).sum()
    b     c
a
a   13.0   13.0
b   12.3  123.0
NaN 12.3   33.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html, pandas.DataFrame.groupby
">>> df = pd.DataFrame({'Animal': ['Falcon', 'Falcon',
...                               'Parrot', 'Parrot'],
...                    'Max Speed': [380., 370., 24., 26.]})
>>> df.groupby(""Animal"", group_keys=True)[['Max Speed']].apply(lambda x: x)
          Max Speed
Animal
Falcon 0      380.0
       1      370.0
Parrot 2       24.0
       3       26.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html, pandas.DataFrame pandas.DataFrame.groupby
">>> df.groupby(""Animal"", group_keys=False)[['Max Speed']].apply(lambda x: x)
   Max Speed
0      380.0
1      370.0
2       24.0
3       26.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html, pandas.DataFrame.groupby
">>> s = pd.Series(range(5))
>>> s.where(s > 0)
0    NaN
1    1.0
2    2.0
3    3.0
4    4.0
dtype: float64
>>> s.mask(s > 0)
0    0.0
1    NaN
2    NaN
3    NaN
4    NaN
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.where.html, pandas.Series pandas.Series.where pandas.Series.mask
">>> s = pd.Series(range(5))
>>> t = pd.Series([True, False])
>>> s.where(t, 99)
0     0
1    99
2    99
3    99
4    99
dtype: int64
>>> s.mask(t, 99)
0    99
1     1
2    99
3    99
4    99
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.where.html, pandas.Series pandas.Series.where pandas.Series.mask
">>> s.where(s > 1, 10)
0    10
1    10
2    2
3    3
4    4
dtype: int64
>>> s.mask(s > 1, 10)
0     0
1     1
2    10
3    10
4    10
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.where.html, pandas.Series.where pandas.Series.mask
">>> df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=['A', 'B'])
>>> df
   A  B
0  0  1
1  2  3
2  4  5
3  6  7
4  8  9
>>> m = df % 3 == 0
>>> df.where(m, -df)
   A  B
0  0 -1
1 -2  3
2 -4 -5
3  6 -7
4 -8  9
>>> df.where(m, -df) == np.where(m, df, -df)
      A     B
0  True  True
1  True  True
2  True  True
3  True  True
4  True  True
>>> df.where(m, -df) == df.mask(~m, -df)
      A     B
0  True  True
1  True  True
2  True  True
3  True  True
4  True  True
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.where.html, pandas.DataFrame pandas.DataFrame.where pandas.DataFrame.mask
">>> df = pd.DataFrame({'population': [59000000, 65000000, 434000,
...                                   434000, 434000, 337000, 337000,
...                                   11300, 11300],
...                    'GDP': [1937894, 2583560 , 12011, 4520, 12128,
...                            17036, 182, 38, 311],
...                    'alpha-2': [""IT"", ""FR"", ""MT"", ""MV"", ""BN"",
...                                ""IS"", ""NR"", ""TV"", ""AI""]},
...                   index=[""Italy"", ""France"", ""Malta"",
...                          ""Maldives"", ""Brunei"", ""Iceland"",
...                          ""Nauru"", ""Tuvalu"", ""Anguilla""])
>>> df
          population      GDP alpha-2
Italy       59000000  1937894      IT
France      65000000  2583560      FR
Malta         434000    12011      MT
Maldives      434000     4520      MV
Brunei        434000    12128      BN
Iceland       337000    17036      IS
Nauru         337000      182      NR
Tuvalu         11300       38      TV
Anguilla       11300      311      AI
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.nsmallest.html, pandas.DataFrame
">>> df.nsmallest(3, 'population')
          population    GDP alpha-2
Tuvalu         11300     38      TV
Anguilla       11300    311      AI
Iceland       337000  17036      IS
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.nsmallest.html, pandas.DataFrame.nsmallest
">>> df.nsmallest(3, 'population', keep='last')
          population  GDP alpha-2
Anguilla       11300  311      AI
Tuvalu         11300   38      TV
Nauru         337000  182      NR
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.nsmallest.html, pandas.DataFrame.nsmallest
">>> df.nsmallest(3, 'population', keep='all')
          population    GDP alpha-2
Tuvalu         11300     38      TV
Anguilla       11300    311      AI
Iceland       337000  17036      IS
Nauru         337000    182      NR
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.nsmallest.html, pandas.DataFrame.nsmallest
">>> df.nsmallest(4, 'population', keep='all')
          population    GDP alpha-2
Tuvalu         11300     38      TV
Anguilla       11300    311      AI
Iceland       337000  17036      IS
Nauru         337000    182      NR
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.nsmallest.html, pandas.DataFrame.nsmallest
">>> df.nsmallest(3, ['population', 'GDP'])
          population  GDP alpha-2
Tuvalu         11300   38      TV
Anguilla       11300  311      AI
Nauru         337000  182      NR
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.nsmallest.html, pandas.DataFrame.nsmallest
">>> pd.Series([], dtype=""float64"").prod()
1.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.prod.html, pandas.Series
">>> pd.Series([], dtype=""float64"").prod(min_count=1)
nan
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.prod.html, pandas.Series
">>> pd.Series([np.nan]).prod()
1.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.prod.html, pandas.Series
">>> pd.Series([np.nan]).prod(min_count=1)
nan
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.prod.html, pandas.Series
">>> df = pd.DataFrame({'mass': [0.330, 4.87 , 5.97],
...                    'radius': [2439.7, 6051.8, 6378.1]},
...                   index=['Mercury', 'Venus', 'Earth'])
>>> plot = df.plot.pie(y='mass', figsize=(5, 5))
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.pie.html, pandas.DataFrame pandas.DataFrame.plot.pie
">>> plot = df.plot.pie(subplots=True, figsize=(11, 6))
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.pie.html, pandas.DataFrame.plot.pie
">>> s = pd.Series([1, 2, 2, 3], index=['cat', 'dog', 'dog', 'mouse'])
>>> s
cat    1
dog    2
dog    2
mouse  3
dtype: int64
>>> s.kurt()
1.5
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.kurt.html, pandas.Series pandas.Series.kurt
">>> df = pd.DataFrame({'a': [1, 2, 2, 3], 'b': [3, 4, 4, 4]},
...                   index=['cat', 'dog', 'dog', 'mouse'])
>>> df
       a   b
  cat  1   3
  dog  2   4
  dog  2   4
mouse  3   4
>>> df.kurt()
a   1.5
b   4.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.kurt.html, pandas.DataFrame pandas.DataFrame.kurt
">>> df.kurt(axis=None).round(6)
-0.988693
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.kurt.html, pandas.DataFrame.kurt
">>> df = pd.DataFrame({'a': [1, 2], 'b': [3, 4], 'c': [3, 4], 'd': [1, 2]},
...                   index=['cat', 'dog'])
>>> df.kurt(axis=1)
cat   -6.0
dog   -6.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.kurt.html, pandas.DataFrame pandas.DataFrame.kurt
">>> s = pd.Series([1, 2, 2, 3], index=['cat', 'dog', 'dog', 'mouse'])
>>> s
cat    1
dog    2
dog    2
mouse  3
dtype: int64
>>> s.kurt()
1.5
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.kurtosis.html, pandas.Series pandas.Series.kurt
">>> df = pd.DataFrame({'a': [1, 2, 2, 3], 'b': [3, 4, 4, 4]},
...                   index=['cat', 'dog', 'dog', 'mouse'])
>>> df
       a   b
  cat  1   3
  dog  2   4
  dog  2   4
mouse  3   4
>>> df.kurt()
a   1.5
b   4.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.kurtosis.html, pandas.DataFrame pandas.DataFrame.kurt
">>> df.kurt(axis=None).round(6)
-0.988693
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.kurtosis.html, pandas.DataFrame.kurt
">>> df = pd.DataFrame({'a': [1, 2], 'b': [3, 4], 'c': [3, 4], 'd': [1, 2]},
...                   index=['cat', 'dog'])
>>> df.kurt(axis=1)
cat   -6.0
dog   -6.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.kurtosis.html, pandas.DataFrame pandas.DataFrame.kurt
">>> df = pd.DataFrame(
...     {""Grade"": [""A"", ""B"", ""A"", ""C""]},
...     index=[
...         [""Final exam"", ""Final exam"", ""Coursework"", ""Coursework""],
...         [""History"", ""Geography"", ""History"", ""Geography""],
...         [""January"", ""February"", ""March"", ""April""],
...     ],
... )
>>> df
                                    Grade
Final exam  History     January      A
            Geography   February     B
Coursework  History     March        A
            Geography   April        C
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.swaplevel.html, pandas.DataFrame
">>> df.swaplevel()
                                    Grade
Final exam  January     History         A
            February    Geography       B
Coursework  March       History         A
            April       Geography       C
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.swaplevel.html, pandas.DataFrame.swaplevel
">>> df.swaplevel(0)
                                    Grade
January     History     Final exam      A
February    Geography   Final exam      B
March       History     Coursework      A
April       Geography   Coursework      C
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.swaplevel.html, pandas.DataFrame.swaplevel
">>> df.swaplevel(0, 1)
                                    Grade
History     Final exam  January         A
Geography   Final exam  February        B
History     Coursework  March           A
Geography   Coursework  April           C
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.swaplevel.html, pandas.DataFrame.swaplevel
">>> df = pd.DataFrame({""A"": [1, 2, 3], ""B"": [4, 5, 6]})
>>> df.rename(columns={""A"": ""a"", ""B"": ""c""})
   a  c
0  1  4
1  2  5
2  3  6
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html, pandas.DataFrame pandas.DataFrame.rename
">>> df.rename(index={0: ""x"", 1: ""y"", 2: ""z""})
   A  B
x  1  4
y  2  5
z  3  6
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html, pandas.DataFrame.rename
">>> df.index
RangeIndex(start=0, stop=3, step=1)
>>> df.rename(index=str).index
Index(['0', '1', '2'], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html, pandas.RangeIndex pandas.DataFrame.rename pandas.Index
">>> df.rename(columns={""A"": ""a"", ""B"": ""b"", ""C"": ""c""}, errors=""raise"")
Traceback (most recent call last):
KeyError: ['C'] not found in axis
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html, pandas.DataFrame.rename
">>> df.rename(str.lower, axis='columns')
   a  b
0  1  4
1  2  5
2  3  6
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html, pandas.DataFrame.rename
">>> df.rename({1: 2, 2: 4}, axis='index')
   A  B
0  1  4
2  2  5
4  3  6
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html, pandas.DataFrame.rename
">>> data = {'col_0': [9, -3, 0, -1, 5], 'col_1': [-2, -7, 6, 8, -5]}
>>> df = pd.DataFrame(data)
>>> df
   col_0  col_1
0      9     -2
1     -3     -7
2      0      6
3     -1      8
4      5     -5
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.clip.html, pandas.DataFrame
">>> df.clip(-4, 6)
   col_0  col_1
0      6     -2
1     -3     -4
2      0      6
3     -1      6
4      5     -4
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.clip.html, pandas.DataFrame.clip
">>> df.clip([-2, -1], [4, 5])
    col_0  col_1
0      4     -1
1     -2     -1
2      0      5
3     -1      5
4      4     -1
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.clip.html, pandas.DataFrame.clip
">>> t = pd.Series([2, -4, -1, 6, 3])
>>> t
0    2
1   -4
2   -1
3    6
4    3
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.clip.html, pandas.Series
">>> df.clip(t, t + 4, axis=0)
   col_0  col_1
0      6      2
1     -3     -4
2      0      3
3      6      8
4      5      3
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.clip.html, pandas.DataFrame.clip
">>> t = pd.Series([2, -4, np.nan, 6, 3])
>>> t
0    2.0
1   -4.0
2    NaN
3    6.0
4    3.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.clip.html, pandas.Series
">>> df.clip(t, axis=0)
col_0  col_1
0      9      2
1     -3     -4
2      0      6
3      6      8
4      5      3
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.clip.html, pandas.DataFrame.clip
">>> s = pd.Series([1, 2, 3])
>>> s.median()
2.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.median.html, pandas.Series pandas.Series.median
">>> df = pd.DataFrame({'a': [1, 2], 'b': [2, 3]}, index=['tiger', 'zebra'])
>>> df
       a   b
tiger  1   2
zebra  2   3
>>> df.median()
a   1.5
b   2.5
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.median.html, pandas.DataFrame pandas.DataFrame.median
">>> df.median(axis=1)
tiger   1.5
zebra   2.5
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.median.html, pandas.DataFrame.median
">>> df = pd.DataFrame({'a': [1, 2], 'b': ['T', 'Z']},
...                   index=['tiger', 'zebra'])
>>> df.median(numeric_only=True)
a   1.5
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.median.html, pandas.DataFrame pandas.DataFrame.median
">>> df = pd.DataFrame({'angles': [0, 3, 4],
...                    'degrees': [360, 180, 360]},
...                   index=['circle', 'triangle', 'rectangle'])
>>> df
           angles  degrees
circle          0      360
triangle        3      180
rectangle       4      360
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mod.html, pandas.DataFrame
">>> df.add(1)
           angles  degrees
circle          1      361
triangle        4      181
rectangle       5      361
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mod.html, pandas.DataFrame.add
">>> df.div(10)
           angles  degrees
circle        0.0     36.0
triangle      0.3     18.0
rectangle     0.4     36.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mod.html, pandas.DataFrame.div
">>> df.rdiv(10)
             angles   degrees
circle          inf  0.027778
triangle   3.333333  0.055556
rectangle  2.500000  0.027778
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mod.html, pandas.DataFrame.rdiv
">>> df.sub([1, 2], axis='columns')
           angles  degrees
circle         -1      358
triangle        2      178
rectangle       3      358
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mod.html, pandas.DataFrame.sub
">>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),
...        axis='index')
           angles  degrees
circle         -1      359
triangle        2      179
rectangle       3      359
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mod.html, pandas.DataFrame.sub pandas.Series
">>> df.mul({'angles': 0, 'degrees': 2})
            angles  degrees
circle           0      720
triangle         0      360
rectangle        0      720
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mod.html, pandas.DataFrame.mul
">>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')
            angles  degrees
circle           0        0
triangle         6      360
rectangle       12     1080
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mod.html, pandas.DataFrame.mul
">>> other = pd.DataFrame({'angles': [0, 3, 4]},
...                      index=['circle', 'triangle', 'rectangle'])
>>> other
           angles
circle          0
triangle        3
rectangle       4
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mod.html, pandas.DataFrame
">>> df.mul(other, fill_value=0)
           angles  degrees
circle          0      0.0
triangle        9      0.0
rectangle      16      0.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mod.html, pandas.DataFrame.mul
">>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],
...                              'degrees': [360, 180, 360, 360, 540, 720]},
...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],
...                                    ['circle', 'triangle', 'rectangle',
...                                     'square', 'pentagon', 'hexagon']])
>>> df_multindex
             angles  degrees
A circle          0      360
  triangle        3      180
  rectangle       4      360
B square          4      360
  pentagon        5      540
  hexagon         6      720
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mod.html, pandas.DataFrame
">>> df.div(df_multindex, level=1, fill_value=0)
             angles  degrees
A circle        NaN      1.0
  triangle      1.0      1.0
  rectangle     1.0      1.0
B square        0.0      0.0
  pentagon      0.0      0.0
  hexagon       0.0      0.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mod.html, pandas.DataFrame.div
">>> df = pd.DataFrame({'angles': [0, 3, 4],
...                    'degrees': [360, 180, 360]},
...                   index=['circle', 'triangle', 'rectangle'])
>>> df
           angles  degrees
circle          0      360
triangle        3      180
rectangle       4      360
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.div.html, pandas.DataFrame
">>> df.add(1)
           angles  degrees
circle          1      361
triangle        4      181
rectangle       5      361
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.div.html, pandas.DataFrame.add
">>> df.div(10)
           angles  degrees
circle        0.0     36.0
triangle      0.3     18.0
rectangle     0.4     36.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.div.html, pandas.DataFrame.div
">>> df.rdiv(10)
             angles   degrees
circle          inf  0.027778
triangle   3.333333  0.055556
rectangle  2.500000  0.027778
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.div.html, pandas.DataFrame.rdiv
">>> df.sub([1, 2], axis='columns')
           angles  degrees
circle         -1      358
triangle        2      178
rectangle       3      358
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.div.html, pandas.DataFrame.sub
">>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),
...        axis='index')
           angles  degrees
circle         -1      359
triangle        2      179
rectangle       3      359
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.div.html, pandas.DataFrame.sub pandas.Series
">>> df.mul({'angles': 0, 'degrees': 2})
            angles  degrees
circle           0      720
triangle         0      360
rectangle        0      720
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.div.html, pandas.DataFrame.mul
">>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')
            angles  degrees
circle           0        0
triangle         6      360
rectangle       12     1080
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.div.html, pandas.DataFrame.mul
">>> other = pd.DataFrame({'angles': [0, 3, 4]},
...                      index=['circle', 'triangle', 'rectangle'])
>>> other
           angles
circle          0
triangle        3
rectangle       4
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.div.html, pandas.DataFrame
">>> df.mul(other, fill_value=0)
           angles  degrees
circle          0      0.0
triangle        9      0.0
rectangle      16      0.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.div.html, pandas.DataFrame.mul
">>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],
...                              'degrees': [360, 180, 360, 360, 540, 720]},
...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],
...                                    ['circle', 'triangle', 'rectangle',
...                                     'square', 'pentagon', 'hexagon']])
>>> df_multindex
             angles  degrees
A circle          0      360
  triangle        3      180
  rectangle       4      360
B square          4      360
  pentagon        5      540
  hexagon         6      720
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.div.html, pandas.DataFrame
">>> df.div(df_multindex, level=1, fill_value=0)
             angles  degrees
A circle        NaN      1.0
  triangle      1.0      1.0
  rectangle     1.0      1.0
B square        0.0      0.0
  pentagon      0.0      0.0
  hexagon       0.0      0.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.div.html, pandas.DataFrame.div
">>> s = pd.Series([90, 91, 85])
>>> s
0    90
1    91
2    85
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pct_change.html, pandas.Series
">>> s.pct_change()
0         NaN
1    0.011111
2   -0.065934
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pct_change.html, pandas.Series.pct_change
">>> s.pct_change(periods=2)
0         NaN
1         NaN
2   -0.055556
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pct_change.html, pandas.Series.pct_change
">>> s = pd.Series([90, 91, None, 85])
>>> s
0    90.0
1    91.0
2     NaN
3    85.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pct_change.html, pandas.Series
">>> s.ffill().pct_change()
0         NaN
1    0.011111
2    0.000000
3   -0.065934
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pct_change.html, pandas.Series.ffill
">>> df = pd.DataFrame({
...     'FR': [4.0405, 4.0963, 4.3149],
...     'GR': [1.7246, 1.7482, 1.8519],
...     'IT': [804.74, 810.01, 860.13]},
...     index=['1980-01-01', '1980-02-01', '1980-03-01'])
>>> df
                FR      GR      IT
1980-01-01  4.0405  1.7246  804.74
1980-02-01  4.0963  1.7482  810.01
1980-03-01  4.3149  1.8519  860.13
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pct_change.html, pandas.DataFrame
">>> df.pct_change()
                  FR        GR        IT
1980-01-01       NaN       NaN       NaN
1980-02-01  0.013810  0.013684  0.006549
1980-03-01  0.053365  0.059318  0.061876
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pct_change.html, pandas.DataFrame.pct_change
">>> df = pd.DataFrame({
...     '2016': [1769950, 30586265],
...     '2015': [1500923, 40912316],
...     '2014': [1371819, 41403351]},
...     index=['GOOG', 'APPL'])
>>> df
          2016      2015      2014
GOOG   1769950   1500923   1371819
APPL  30586265  40912316  41403351
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pct_change.html, pandas.DataFrame
">>> df.pct_change(axis='columns', periods=-1)
          2016      2015  2014
GOOG  0.179241  0.094112   NaN
APPL -0.252395 -0.011860   NaN
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pct_change.html, pandas.DataFrame.pct_change
">>> i = pd.date_range('2018-04-09', periods=4, freq='2D')
>>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)
>>> ts
            A
2018-04-09  1
2018-04-11  2
2018-04-13  3
2018-04-15  4
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.last.html, pandas.date_range pandas.DataFrame
">>> ts.last('3D')  
            A
2018-04-13  3
2018-04-15  4
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.last.html, pandas.DataFrame.last
">>> s = pd.Series([None, 3, 4])
>>> s.first_valid_index()
1
>>> s.last_valid_index()
2
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.first_valid_index.html, pandas.Series pandas.Series.first_valid_index pandas.Series.last_valid_index
">>> s = pd.Series([None, None])
>>> print(s.first_valid_index())
None
>>> print(s.last_valid_index())
None
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.first_valid_index.html, pandas.Series pandas.Series.first_valid_index pandas.Series.last_valid_index
">>> s = pd.Series()
>>> print(s.first_valid_index())
None
>>> print(s.last_valid_index())
None
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.first_valid_index.html, pandas.Series pandas.Series.first_valid_index pandas.Series.last_valid_index
">>> df = pd.DataFrame({'A': [None, None, 2], 'B': [None, 3, 4]})
>>> df
     A      B
0  NaN    NaN
1  NaN    3.0
2  2.0    4.0
>>> df.first_valid_index()
1
>>> df.last_valid_index()
2
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.first_valid_index.html, pandas.DataFrame pandas.DataFrame.first_valid_index pandas.DataFrame.last_valid_index
">>> df = pd.DataFrame({'A': [None, None, None], 'B': [None, None, None]})
>>> df
     A      B
0  None   None
1  None   None
2  None   None
>>> print(df.first_valid_index())
None
>>> print(df.last_valid_index())
None
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.first_valid_index.html, pandas.DataFrame pandas.DataFrame.first_valid_index pandas.DataFrame.last_valid_index
">>> df = pd.DataFrame()
>>> df
Empty DataFrame
Columns: []
Index: []
>>> print(df.first_valid_index())
None
>>> print(df.last_valid_index())
None
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.first_valid_index.html, pandas.DataFrame pandas.DataFrame.first_valid_index pandas.DataFrame.last_valid_index
">>> ser = pd.Series([1, 2, 3])
>>> ser.attrs = {""A"": [10, 20, 30]}
>>> ser.attrs
{'A': [10, 20, 30]}
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.attrs.html, pandas.Series
">>> df = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})
>>> df.attrs = {""A"": [10, 20, 30]}
>>> df.attrs
{'A': [10, 20, 30]}
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.attrs.html, pandas.DataFrame
">>> df_empty = pd.DataFrame({'A' : []})
>>> df_empty
Empty DataFrame
Columns: [A]
Index: []
>>> df_empty.empty
True
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.empty.html, pandas.DataFrame
">>> df = pd.DataFrame({'A' : [np.nan]})
>>> df
    A
0 NaN
>>> df.empty
False
>>> df.dropna().empty
True
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.empty.html, pandas.DataFrame pandas.DataFrame.dropna
">>> ser_empty = pd.Series({'A' : []})
>>> ser_empty
A    []
dtype: object
>>> ser_empty.empty
False
>>> ser_empty = pd.Series()
>>> ser_empty.empty
True
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.empty.html, pandas.Series
">>> df = pd.DataFrame({'angles': [0, 3, 4],
...                    'degrees': [360, 180, 360]},
...                   index=['circle', 'triangle', 'rectangle'])
>>> df
           angles  degrees
circle          0      360
triangle        3      180
rectangle       4      360
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.radd.html, pandas.DataFrame
">>> df.add(1)
           angles  degrees
circle          1      361
triangle        4      181
rectangle       5      361
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.radd.html, pandas.DataFrame.add
">>> df.div(10)
           angles  degrees
circle        0.0     36.0
triangle      0.3     18.0
rectangle     0.4     36.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.radd.html, pandas.DataFrame.div
">>> df.rdiv(10)
             angles   degrees
circle          inf  0.027778
triangle   3.333333  0.055556
rectangle  2.500000  0.027778
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.radd.html, pandas.DataFrame.rdiv
">>> df.sub([1, 2], axis='columns')
           angles  degrees
circle         -1      358
triangle        2      178
rectangle       3      358
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.radd.html, pandas.DataFrame.sub
">>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),
...        axis='index')
           angles  degrees
circle         -1      359
triangle        2      179
rectangle       3      359
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.radd.html, pandas.DataFrame.sub pandas.Series
">>> df.mul({'angles': 0, 'degrees': 2})
            angles  degrees
circle           0      720
triangle         0      360
rectangle        0      720
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.radd.html, pandas.DataFrame.mul
">>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')
            angles  degrees
circle           0        0
triangle         6      360
rectangle       12     1080
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.radd.html, pandas.DataFrame.mul
">>> other = pd.DataFrame({'angles': [0, 3, 4]},
...                      index=['circle', 'triangle', 'rectangle'])
>>> other
           angles
circle          0
triangle        3
rectangle       4
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.radd.html, pandas.DataFrame
">>> df.mul(other, fill_value=0)
           angles  degrees
circle          0      0.0
triangle        9      0.0
rectangle      16      0.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.radd.html, pandas.DataFrame.mul
">>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],
...                              'degrees': [360, 180, 360, 360, 540, 720]},
...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],
...                                    ['circle', 'triangle', 'rectangle',
...                                     'square', 'pentagon', 'hexagon']])
>>> df_multindex
             angles  degrees
A circle          0      360
  triangle        3      180
  rectangle       4      360
B square          4      360
  pentagon        5      540
  hexagon         6      720
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.radd.html, pandas.DataFrame
">>> df.div(df_multindex, level=1, fill_value=0)
             angles  degrees
A circle        NaN      1.0
  triangle      1.0      1.0
  rectangle     1.0      1.0
B square        0.0      0.0
  pentagon      0.0      0.0
  hexagon       0.0      0.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.radd.html, pandas.DataFrame.div
">>> df = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})
>>> df
     A  B
0    1  3
1    2  4
>>> df.columns
Index(['A', 'B'], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.columns.html, pandas.DataFrame pandas.Index
">>> df = pd.DataFrame([[1, 2.12], [3.356, 4.567]])
>>> df
       0      1
0  1.000  2.120
1  3.356  4.567
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.map.html, pandas.DataFrame
">>> df.map(lambda x: len(str(x)))
   0  1
0  3  4
1  5  5
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.map.html, pandas.DataFrame.map
">>> df_copy = df.copy()
>>> df_copy.iloc[0, 0] = pd.NA
>>> df_copy.map(lambda x: len(str(x)), na_action='ignore')
     0  1
0  NaN  4
1  5.0  5
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.map.html, pandas.DataFrame.copy
">>> df.map(round, ndigits=1)
     0    1
0  1.0  2.1
1  3.4  4.6
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.map.html, pandas.DataFrame.map
">>> df.map(lambda x: x**2)
           0          1
0   1.000000   4.494400
1  11.262736  20.857489
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.map.html, pandas.DataFrame.map
">>> s = pd.Series([""elk"", ""pig"", ""dog"", ""quetzal""], name=""animal"")
>>> print(s.to_markdown())
|    | animal   |
|---:|:---------|
|  0 | elk      |
|  1 | pig      |
|  2 | dog      |
|  3 | quetzal  |
",https://pandas.pydata.org/docs/reference/api/pandas.Series.to_markdown.html, pandas.Series pandas.Series.to_markdown
">>> print(s.to_markdown(tablefmt=""grid""))
+----+----------+
|    | animal   |
+====+==========+
|  0 | elk      |
+----+----------+
|  1 | pig      |
+----+----------+
|  2 | dog      |
+----+----------+
|  3 | quetzal  |
+----+----------+
",https://pandas.pydata.org/docs/reference/api/pandas.Series.to_markdown.html, pandas.Series.to_markdown
">>> df = pd.DataFrame({'angles': [0, 3, 4],
...                    'degrees': [360, 180, 360]},
...                   index=['circle', 'triangle', 'rectangle'])
>>> df
           angles  degrees
circle          0      360
triangle        3      180
rectangle       4      360
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rmul.html, pandas.DataFrame
">>> df.add(1)
           angles  degrees
circle          1      361
triangle        4      181
rectangle       5      361
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rmul.html, pandas.DataFrame.add
">>> df.div(10)
           angles  degrees
circle        0.0     36.0
triangle      0.3     18.0
rectangle     0.4     36.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rmul.html, pandas.DataFrame.div
">>> df.rdiv(10)
             angles   degrees
circle          inf  0.027778
triangle   3.333333  0.055556
rectangle  2.500000  0.027778
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rmul.html, pandas.DataFrame.rdiv
">>> df.sub([1, 2], axis='columns')
           angles  degrees
circle         -1      358
triangle        2      178
rectangle       3      358
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rmul.html, pandas.DataFrame.sub
">>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),
...        axis='index')
           angles  degrees
circle         -1      359
triangle        2      179
rectangle       3      359
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rmul.html, pandas.DataFrame.sub pandas.Series
">>> df.mul({'angles': 0, 'degrees': 2})
            angles  degrees
circle           0      720
triangle         0      360
rectangle        0      720
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rmul.html, pandas.DataFrame.mul
">>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')
            angles  degrees
circle           0        0
triangle         6      360
rectangle       12     1080
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rmul.html, pandas.DataFrame.mul
">>> other = pd.DataFrame({'angles': [0, 3, 4]},
...                      index=['circle', 'triangle', 'rectangle'])
>>> other
           angles
circle          0
triangle        3
rectangle       4
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rmul.html, pandas.DataFrame
">>> df.mul(other, fill_value=0)
           angles  degrees
circle          0      0.0
triangle        9      0.0
rectangle      16      0.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rmul.html, pandas.DataFrame.mul
">>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],
...                              'degrees': [360, 180, 360, 360, 540, 720]},
...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],
...                                    ['circle', 'triangle', 'rectangle',
...                                     'square', 'pentagon', 'hexagon']])
>>> df_multindex
             angles  degrees
A circle          0      360
  triangle        3      180
  rectangle       4      360
B square          4      360
  pentagon        5      540
  hexagon         6      720
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rmul.html, pandas.DataFrame
">>> df.div(df_multindex, level=1, fill_value=0)
             angles  degrees
A circle        NaN      1.0
  triangle      1.0      1.0
  rectangle     1.0      1.0
B square        0.0      0.0
  pentagon      0.0      0.0
  hexagon       0.0      0.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rmul.html, pandas.DataFrame.div
">>> index = pd.MultiIndex.from_tuples([('one', 'a'), ('one', 'b'),
...                                    ('two', 'a'), ('two', 'b')])
>>> s = pd.Series(np.arange(1.0, 5.0), index=index)
>>> s
one  a   1.0
     b   2.0
two  a   3.0
     b   4.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.unstack.html, pandas.MultiIndex.from_tuples pandas.Series
">>> s.unstack(level=-1)
     a   b
one  1.0  2.0
two  3.0  4.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.unstack.html, pandas.Series.unstack
">>> s.unstack(level=0)
   one  two
a  1.0   3.0
b  2.0   4.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.unstack.html, pandas.Series.unstack
">>> df = s.unstack(level=0)
>>> df.unstack()
one  a  1.0
     b  2.0
two  a  3.0
     b  4.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.unstack.html, pandas.Series.unstack pandas.DataFrame.unstack
">>> df = pd.DataFrame({'A': [1, 2], 'B': [0.5, 0.75]},
...                   index=['a', 'b'])
>>> df
   A     B
a  1  0.50
b  2  0.75
>>> df.to_records()
rec.array([('a', 1, 0.5 ), ('b', 2, 0.75)],
          dtype=[('index', 'O'), ('A', '
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_records.html, pandas.DataFrame pandas.DataFrame.to_records pandas.array
">>> df.index = df.index.rename(""I"")
>>> df.to_records()
rec.array([('a', 1, 0.5 ), ('b', 2, 0.75)],
          dtype=[('I', 'O'), ('A', '
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_records.html, pandas.DataFrame.to_records pandas.array
">>> df.to_records(index=False)
rec.array([(1, 0.5 ), (2, 0.75)],
          dtype=[('A', '
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_records.html, pandas.DataFrame.to_records pandas.array
">>> df.to_records(column_dtypes={""A"": ""int32""})
rec.array([('a', 1, 0.5 ), ('b', 2, 0.75)],
          dtype=[('I', 'O'), ('A', '
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_records.html, pandas.DataFrame.to_records pandas.array
">>> df.to_records(index_dtypes="")
rec.array([(b'a', 1, 0.5 ), (b'b', 2, 0.75)],
          dtype=[('I', 'S2'), ('A', '
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_records.html, pandas.DataFrame.to_records pandas.array
">>> index_dtypes = f""{df.index.str.len().max()}""
>>> df.to_records(index_dtypes=index_dtypes)
rec.array([(b'a', 1, 0.5 ), (b'b', 2, 0.75)],
          dtype=[('I', 'S1'), ('A', '
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_records.html, pandas.DataFrame.to_records pandas.array
">>> df = pd.DataFrame({'cost': [250, 150, 100],
...                    'revenue': [100, 250, 300]},
...                   index=['A', 'B', 'C'])
>>> df
   cost  revenue
A   250      100
B   150      250
C   100      300
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.eq.html, pandas.DataFrame
">>> df.eq(100)
    cost  revenue
A  False     True
B  False    False
C   True    False
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.eq.html, pandas.DataFrame.eq
">>> df != pd.Series([100, 250], index=[""cost"", ""revenue""])
    cost  revenue
A   True     True
B   True    False
C  False     True
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.eq.html, pandas.Series
">>> df.ne(pd.Series([100, 300], index=[""A"", ""D""]), axis='index')
   cost  revenue
A  True    False
B  True     True
C  True     True
D  True     True
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.eq.html, pandas.DataFrame.ne pandas.Series
">>> df.eq([250, 250, 100], axis='index')
    cost  revenue
A   True    False
B  False     True
C   True    False
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.eq.html, pandas.DataFrame.eq
">>> other = pd.DataFrame({'revenue': [300, 250, 100, 150]},
...                      index=['A', 'B', 'C', 'D'])
>>> other
   revenue
A      300
B      250
C      100
D      150
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.eq.html, pandas.DataFrame
">>> df.gt(other)
    cost  revenue
A  False    False
B  False    False
C  False     True
D  False    False
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.eq.html, pandas.DataFrame.gt
">>> df_multindex = pd.DataFrame({'cost': [250, 150, 100, 150, 300, 220],
...                              'revenue': [100, 250, 300, 200, 175, 225]},
...                             index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'],
...                                    ['A', 'B', 'C', 'A', 'B', 'C']])
>>> df_multindex
      cost  revenue
Q1 A   250      100
   B   150      250
   C   100      300
Q2 A   150      200
   B   300      175
   C   220      225
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.eq.html, pandas.DataFrame
">>> df.le(df_multindex, level=1)
       cost  revenue
Q1 A   True     True
   B   True     True
   C   True     True
Q2 A  False     True
   B   True    False
   C   True    False
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.eq.html, pandas.DataFrame.le
">>> df = pd.DataFrame({'num_legs': [2, 4, 8, 0],
...                    'num_wings': [2, 0, 0, 0],
...                    'num_specimen_seen': [10, 2, 1, 8]},
...                   index=['falcon', 'dog', 'spider', 'fish'])
>>> df
        num_legs  num_wings  num_specimen_seen
falcon         2          2                 10
dog            4          0                  2
spider         8          0                  1
fish           0          0                  8
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html, pandas.DataFrame
">>> df.sample(frac=0.5, replace=True, random_state=1)
      num_legs  num_wings  num_specimen_seen
dog          4          0                  2
fish         0          0                  8
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html, pandas.DataFrame.sample
">>> df.sample(frac=2, replace=True, random_state=1)
        num_legs  num_wings  num_specimen_seen
dog            4          0                  2
fish           0          0                  8
falcon         2          2                 10
falcon         2          2                 10
fish           0          0                  8
dog            4          0                  2
fish           0          0                  8
dog            4          0                  2
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html, pandas.DataFrame.sample
">>> df.sample(n=2, weights='num_specimen_seen', random_state=1)
        num_legs  num_wings  num_specimen_seen
falcon         2          2                 10
fish           0          0                  8
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html, pandas.DataFrame.sample
">>> s = pd.Series([1, 2, 3])
>>> s.sem().round(6)
0.57735
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sem.html, pandas.Series pandas.Series.sem
">>> df = pd.DataFrame({'a': [1, 2], 'b': [2, 3]}, index=['tiger', 'zebra'])
>>> df
       a   b
tiger  1   2
zebra  2   3
>>> df.sem()
a   0.5
b   0.5
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sem.html, pandas.DataFrame pandas.DataFrame.sem
">>> df.sem(axis=1)
tiger   0.5
zebra   0.5
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sem.html, pandas.DataFrame.sem
">>> df = pd.DataFrame({'a': [1, 2], 'b': ['T', 'Z']},
...                   index=['tiger', 'zebra'])
>>> df.sem(numeric_only=True)
a   0.5
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sem.html, pandas.DataFrame pandas.DataFrame.sem
">>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})
>>> df
   col1  col2
0     1     3
1     2     4
>>> df.insert(1, ""newcol"", [99, 99])
>>> df
   col1  newcol  col2
0     1      99     3
1     2      99     4
>>> df.insert(0, ""col1"", [100, 100], allow_duplicates=True)
>>> df
   col1  col1  newcol  col2
0   100     1      99     3
1   100     2      99     4
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.insert.html, pandas.DataFrame pandas.DataFrame.insert
">>> df.insert(0, ""col0"", pd.Series([5, 6], index=[1, 2]))
>>> df
   col0  col1  col1  newcol  col2
0   NaN   100     1      99     3
1   5.0   100     2      99     4
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.insert.html, pandas.DataFrame.insert pandas.Series
">>> def histogram_intersection(a, b):
...     v = np.minimum(a, b).sum().round(decimals=1)
...     return v
>>> df = pd.DataFrame([(.2, .3), (.0, .6), (.6, .0), (.2, .1)],
...                   columns=['dogs', 'cats'])
>>> df.corr(method=histogram_intersection)
      dogs  cats
dogs   1.0   0.3
cats   0.3   1.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html, pandas.DataFrame pandas.DataFrame.corr
">>> df = pd.DataFrame([(1, 1), (2, np.nan), (np.nan, 3), (4, 4)],
...                   columns=['dogs', 'cats'])
>>> df.corr(min_periods=3)
      dogs  cats
dogs   1.0   NaN
cats   NaN   1.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html, pandas.DataFrame pandas.DataFrame.corr
">>> df = pd.DataFrame({
...     'brand': ['Yum Yum', 'Yum Yum', 'Indomie', 'Indomie', 'Indomie'],
...     'style': ['cup', 'cup', 'cup', 'pack', 'pack'],
...     'rating': [4, 4, 3.5, 15, 5]
... })
>>> df
    brand style  rating
0  Yum Yum   cup     4.0
1  Yum Yum   cup     4.0
2  Indomie   cup     3.5
3  Indomie  pack    15.0
4  Indomie  pack     5.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html, pandas.DataFrame
">>> df.drop_duplicates()
    brand style  rating
0  Yum Yum   cup     4.0
2  Indomie   cup     3.5
3  Indomie  pack    15.0
4  Indomie  pack     5.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html, pandas.DataFrame.drop_duplicates
">>> df.drop_duplicates(subset=['brand'])
    brand style  rating
0  Yum Yum   cup     4.0
2  Indomie   cup     3.5
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html, pandas.DataFrame.drop_duplicates
">>> df.drop_duplicates(subset=['brand', 'style'], keep='last')
    brand style  rating
1  Yum Yum   cup     4.0
2  Indomie   cup     3.5
4  Indomie  pack     5.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html, pandas.DataFrame.drop_duplicates
">>> df = pd.DataFrame([('bird', 389.0),
...                    ('bird', 24.0),
...                    ('mammal', 80.5),
...                    ('mammal', np.nan)],
...                   index=['falcon', 'parrot', 'lion', 'monkey'],
...                   columns=('class', 'max_speed'))
>>> df
         class  max_speed
falcon    bird      389.0
parrot    bird       24.0
lion    mammal       80.5
monkey  mammal        NaN
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reset_index.html, pandas.DataFrame
">>> df.reset_index()
    index   class  max_speed
0  falcon    bird      389.0
1  parrot    bird       24.0
2    lion  mammal       80.5
3  monkey  mammal        NaN
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reset_index.html, pandas.DataFrame.reset_index
">>> df.reset_index(drop=True)
    class  max_speed
0    bird      389.0
1    bird       24.0
2  mammal       80.5
3  mammal        NaN
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reset_index.html, pandas.DataFrame.reset_index
">>> index = pd.MultiIndex.from_tuples([('bird', 'falcon'),
...                                    ('bird', 'parrot'),
...                                    ('mammal', 'lion'),
...                                    ('mammal', 'monkey')],
...                                   names=['class', 'name'])
>>> columns = pd.MultiIndex.from_tuples([('speed', 'max'),
...                                      ('species', 'type')])
>>> df = pd.DataFrame([(389.0, 'fly'),
...                    (24.0, 'fly'),
...                    (80.5, 'run'),
...                    (np.nan, 'jump')],
...                   index=index,
...                   columns=columns)
>>> df
               speed species
                 max    type
class  name
bird   falcon  389.0     fly
       parrot   24.0     fly
mammal lion     80.5     run
       monkey    NaN    jump
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reset_index.html, pandas.MultiIndex.from_tuples pandas.DataFrame
">>> df.reset_index(names=['classes', 'names'])
  classes   names  speed species
                     max    type
0    bird  falcon  389.0     fly
1    bird  parrot   24.0     fly
2  mammal    lion   80.5     run
3  mammal  monkey    NaN    jump
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reset_index.html, pandas.DataFrame.reset_index
">>> df.reset_index(level='class')
         class  speed species
                  max    type
name
falcon    bird  389.0     fly
parrot    bird   24.0     fly
lion    mammal   80.5     run
monkey  mammal    NaN    jump
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reset_index.html, pandas.DataFrame.reset_index
">>> df.reset_index(level='class', col_level=1)
                speed species
         class    max    type
name
falcon    bird  389.0     fly
parrot    bird   24.0     fly
lion    mammal   80.5     run
monkey  mammal    NaN    jump
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reset_index.html, pandas.DataFrame.reset_index
">>> df.reset_index(level='class', col_level=1, col_fill='species')
              species  speed species
                class    max    type
name
falcon           bird  389.0     fly
parrot           bird   24.0     fly
lion           mammal   80.5     run
monkey         mammal    NaN    jump
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reset_index.html, pandas.DataFrame.reset_index
">>> df.reset_index(level='class', col_level=1, col_fill='genus')
                genus  speed species
                class    max    type
name
falcon           bird  389.0     fly
parrot           bird   24.0     fly
lion           mammal   80.5     run
monkey         mammal    NaN    jump
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reset_index.html, pandas.DataFrame.reset_index
">>> df = pd.DataFrame([(.21, .32), (.01, .67), (.66, .03), (.21, .18)],
...                   columns=['dogs', 'cats'])
>>> df
    dogs  cats
0  0.21  0.32
1  0.01  0.67
2  0.66  0.03
3  0.21  0.18
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.round.html, pandas.DataFrame
">>> df.round(1)
    dogs  cats
0   0.2   0.3
1   0.0   0.7
2   0.7   0.0
3   0.2   0.2
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.round.html, pandas.DataFrame.round
">>> df.round({'dogs': 1, 'cats': 0})
    dogs  cats
0   0.2   0.0
1   0.0   1.0
2   0.7   0.0
3   0.2   0.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.round.html, pandas.DataFrame.round
">>> decimals = pd.Series([0, 1], index=['cats', 'dogs'])
>>> df.round(decimals)
    dogs  cats
0   0.2   0.0
1   0.0   1.0
2   0.7   0.0
3   0.2   0.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.round.html, pandas.Series pandas.DataFrame.round
">>> df = pd.DataFrame({'angles': [0, 3, 4],
...                    'degrees': [360, 180, 360]},
...                   index=['circle', 'triangle', 'rectangle'])
>>> df
           angles  degrees
circle          0      360
triangle        3      180
rectangle       4      360
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rpow.html, pandas.DataFrame
">>> df.add(1)
           angles  degrees
circle          1      361
triangle        4      181
rectangle       5      361
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rpow.html, pandas.DataFrame.add
">>> df.div(10)
           angles  degrees
circle        0.0     36.0
triangle      0.3     18.0
rectangle     0.4     36.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rpow.html, pandas.DataFrame.div
">>> df.rdiv(10)
             angles   degrees
circle          inf  0.027778
triangle   3.333333  0.055556
rectangle  2.500000  0.027778
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rpow.html, pandas.DataFrame.rdiv
">>> df.sub([1, 2], axis='columns')
           angles  degrees
circle         -1      358
triangle        2      178
rectangle       3      358
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rpow.html, pandas.DataFrame.sub
">>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),
...        axis='index')
           angles  degrees
circle         -1      359
triangle        2      179
rectangle       3      359
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rpow.html, pandas.DataFrame.sub pandas.Series
">>> df.mul({'angles': 0, 'degrees': 2})
            angles  degrees
circle           0      720
triangle         0      360
rectangle        0      720
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rpow.html, pandas.DataFrame.mul
">>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')
            angles  degrees
circle           0        0
triangle         6      360
rectangle       12     1080
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rpow.html, pandas.DataFrame.mul
">>> other = pd.DataFrame({'angles': [0, 3, 4]},
...                      index=['circle', 'triangle', 'rectangle'])
>>> other
           angles
circle          0
triangle        3
rectangle       4
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rpow.html, pandas.DataFrame
">>> df.mul(other, fill_value=0)
           angles  degrees
circle          0      0.0
triangle        9      0.0
rectangle      16      0.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rpow.html, pandas.DataFrame.mul
">>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],
...                              'degrees': [360, 180, 360, 360, 540, 720]},
...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],
...                                    ['circle', 'triangle', 'rectangle',
...                                     'square', 'pentagon', 'hexagon']])
>>> df_multindex
             angles  degrees
A circle          0      360
  triangle        3      180
  rectangle       4      360
B square          4      360
  pentagon        5      540
  hexagon         6      720
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rpow.html, pandas.DataFrame
">>> df.div(df_multindex, level=1, fill_value=0)
             angles  degrees
A circle        NaN      1.0
  triangle      1.0      1.0
  rectangle     1.0      1.0
B square        0.0      0.0
  pentagon      0.0      0.0
  hexagon       0.0      0.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rpow.html, pandas.DataFrame.div
">>> data = {'length': [1.5, 0.5, 1.2, 0.9, 3],
...         'width': [0.7, 0.2, 0.15, 0.2, 1.1]}
>>> index = ['pig', 'rabbit', 'duck', 'chicken', 'horse']
>>> df = pd.DataFrame(data, index=index)
>>> hist = df.hist(bins=3)
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.hist.html, pandas.DataFrame pandas.DataFrame.hist
">>> df = pd.DataFrame(
...     [[1, 2, 3, 4], [6, 7, 8, 9]], columns=[""D"", ""B"", ""E"", ""A""], index=[1, 2]
... )
>>> other = pd.DataFrame(
...     [[10, 20, 30, 40], [60, 70, 80, 90], [600, 700, 800, 900]],
...     columns=[""A"", ""B"", ""C"", ""D""],
...     index=[2, 3, 4],
... )
>>> df
   D  B  E  A
1  1  2  3  4
2  6  7  8  9
>>> other
    A    B    C    D
2   10   20   30   40
3   60   70   80   90
4  600  700  800  900
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.align.html, pandas.DataFrame
">>> left, right = df.align(other, join=""outer"", axis=1)
>>> left
   A  B   C  D  E
1  4  2 NaN  1  3
2  9  7 NaN  6  8
>>> right
    A    B    C    D   E
2   10   20   30   40 NaN
3   60   70   80   90 NaN
4  600  700  800  900 NaN
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.align.html, pandas.DataFrame.align
">>> left, right = df.align(other, join=""outer"", axis=0)
>>> left
    D    B    E    A
1  1.0  2.0  3.0  4.0
2  6.0  7.0  8.0  9.0
3  NaN  NaN  NaN  NaN
4  NaN  NaN  NaN  NaN
>>> right
    A      B      C      D
1    NaN    NaN    NaN    NaN
2   10.0   20.0   30.0   40.0
3   60.0   70.0   80.0   90.0
4  600.0  700.0  800.0  900.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.align.html, pandas.DataFrame.align
">>> left, right = df.align(other, join=""outer"", axis=None)
>>> left
     A    B   C    D    E
1  4.0  2.0 NaN  1.0  3.0
2  9.0  7.0 NaN  6.0  8.0
3  NaN  NaN NaN  NaN  NaN
4  NaN  NaN NaN  NaN  NaN
>>> right
       A      B      C      D   E
1    NaN    NaN    NaN    NaN NaN
2   10.0   20.0   30.0   40.0 NaN
3   60.0   70.0   80.0   90.0 NaN
4  600.0  700.0  800.0  900.0 NaN
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.align.html, pandas.DataFrame.align
">>> df = pd.DataFrame({'A': range(1, 6), 'B': range(10, 0, -2)})
>>> df
   A   B
0  1  10
1  2   8
2  3   6
3  4   4
4  5   2
>>> df.eval('A + B')
0    11
1    10
2     9
3     8
4     7
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.eval.html, pandas.DataFrame pandas.DataFrame.eval
">>> df.eval('C = A + B')
   A   B   C
0  1  10  11
1  2   8  10
2  3   6   9
3  4   4   8
4  5   2   7
>>> df
   A   B
0  1  10
1  2   8
2  3   6
3  4   4
4  5   2
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.eval.html, pandas.DataFrame.eval
">>> df.eval(
...     '''
... C = A + B
... D = A - B
... '''
... )
   A   B   C  D
0  1  10  11 -9
1  2   8  10 -6
2  3   6   9 -3
3  4   4   8  0
4  5   2   7  3
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.eval.html, pandas.DataFrame.eval
">>> df = pd.DataFrame({'cost': [250, 150, 100],
...                    'revenue': [100, 250, 300]},
...                   index=['A', 'B', 'C'])
>>> df
   cost  revenue
A   250      100
B   150      250
C   100      300
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.ne.html, pandas.DataFrame
">>> df.eq(100)
    cost  revenue
A  False     True
B  False    False
C   True    False
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.ne.html, pandas.DataFrame.eq
">>> df != pd.Series([100, 250], index=[""cost"", ""revenue""])
    cost  revenue
A   True     True
B   True    False
C  False     True
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.ne.html, pandas.Series
">>> df.ne(pd.Series([100, 300], index=[""A"", ""D""]), axis='index')
   cost  revenue
A  True    False
B  True     True
C  True     True
D  True     True
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.ne.html, pandas.DataFrame.ne pandas.Series
">>> df.eq([250, 250, 100], axis='index')
    cost  revenue
A   True    False
B  False     True
C   True    False
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.ne.html, pandas.DataFrame.eq
">>> other = pd.DataFrame({'revenue': [300, 250, 100, 150]},
...                      index=['A', 'B', 'C', 'D'])
>>> other
   revenue
A      300
B      250
C      100
D      150
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.ne.html, pandas.DataFrame
">>> df.gt(other)
    cost  revenue
A  False    False
B  False    False
C  False     True
D  False    False
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.ne.html, pandas.DataFrame.gt
">>> df_multindex = pd.DataFrame({'cost': [250, 150, 100, 150, 300, 220],
...                              'revenue': [100, 250, 300, 200, 175, 225]},
...                             index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'],
...                                    ['A', 'B', 'C', 'A', 'B', 'C']])
>>> df_multindex
      cost  revenue
Q1 A   250      100
   B   150      250
   C   100      300
Q2 A   150      200
   B   300      175
   C   220      225
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.ne.html, pandas.DataFrame
">>> df.le(df_multindex, level=1)
       cost  revenue
Q1 A   True     True
   B   True     True
   C   True     True
Q2 A  False     True
   B   True    False
   C   True    False
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.ne.html, pandas.DataFrame.le
">>> df = pd.DataFrame({'age':    [ 3,  29],
...                    'height': [94, 170],
...                    'weight': [31, 115]})
>>> df
   age  height  weight
0    3      94      31
1   29     170     115
>>> df.dtypes
age       int64
height    int64
weight    int64
dtype: object
>>> df.values
array([[  3,  94,  31],
       [ 29, 170, 115]])
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.values.html, pandas.DataFrame pandas.array
">>> df2 = pd.DataFrame([('parrot',   24.0, 'second'),
...                     ('lion',     80.5, 1),
...                     ('monkey', np.nan, None)],
...                   columns=('name', 'max_speed', 'rank'))
>>> df2.dtypes
name          object
max_speed    float64
rank          object
dtype: object
>>> df2.values
array([['parrot', 24.0, 'second'],
       ['lion', 80.5, 1],
       ['monkey', nan, None]], dtype=object)
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.values.html, pandas.DataFrame pandas.array
">>> df = pd.DataFrame([[1, 2, 3],
...                    [4, 5, 6],
...                    [7, 8, 9],
...                    [np.nan, np.nan, np.nan]],
...                   columns=['A', 'B', 'C'])
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.aggregate.html, pandas.DataFrame
">>> df.agg(['sum', 'min'])
        A     B     C
sum  12.0  15.0  18.0
min   1.0   2.0   3.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.aggregate.html, pandas.DataFrame.agg
">>> df.agg({'A' : ['sum', 'min'], 'B' : ['min', 'max']})
        A    B
sum  12.0  NaN
min   1.0  2.0
max   NaN  8.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.aggregate.html, pandas.DataFrame.agg
">>> df.agg(x=('A', 'max'), y=('B', 'min'), z=('C', 'mean'))
     A    B    C
x  7.0  NaN  NaN
y  NaN  2.0  NaN
z  NaN  NaN  6.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.aggregate.html, pandas.DataFrame.agg
">>> df.agg(""mean"", axis=""columns"")
0    2.0
1    5.0
2    8.0
3    NaN
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.aggregate.html, pandas.DataFrame.agg
">>> idx = pd.Index([1, 2, 3])
>>> idx.map({1: 'a', 2: 'b', 3: 'c'})
Index(['a', 'b', 'c'], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.Index.map.html, pandas.Index pandas.Index.map pandas.Index
">>> idx = pd.Index([1, 2, 3])
>>> idx.map('I am a {}'.format)
Index(['I am a 1', 'I am a 2', 'I am a 3'], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.Index.map.html, pandas.Index pandas.Index.map pandas.Index
">>> idx = pd.Index(['a', 'b', 'c'])
>>> idx.map(lambda x: x.upper())
Index(['A', 'B', 'C'], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.Index.map.html, pandas.Index pandas.Index.map pandas.Index
">>> s = pd.Series([1, 2, 3, 4])
>>> s
0    1
1    2
2    3
3    4
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.add_suffix.html, pandas.Series
">>> s.add_suffix('_item')
0_item    1
1_item    2
2_item    3
3_item    4
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.add_suffix.html, pandas.Series.add_suffix
">>> df = pd.DataFrame({'A': [1, 2, 3, 4], 'B': [3, 4, 5, 6]})
>>> df
   A  B
0  1  3
1  2  4
2  3  5
3  4  6
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.add_suffix.html, pandas.DataFrame
">>> df.add_suffix('_col')
     A_col  B_col
0       1       3
1       2       4
2       3       5
3       4       6
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.add_suffix.html, pandas.DataFrame.add_suffix
">>> df = pd.DataFrame([[0, 1, -2, -1], [1, 1, 1, 1]])
>>> s = pd.Series([1, 1, 2, 1])
>>> df.dot(s)
0    -4
1     5
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dot.html, pandas.DataFrame pandas.Series pandas.DataFrame.dot
">>> other = pd.DataFrame([[0, 1], [1, 2], [-1, -1], [2, 0]])
>>> df.dot(other)
    0   1
0   1   4
1   2   2
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dot.html, pandas.DataFrame pandas.DataFrame.dot
">>> arr = np.array([[0, 1], [1, 2], [-1, -1], [2, 0]])
>>> df.dot(arr)
    0   1
0   1   4
1   2   2
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dot.html, pandas.DataFrame.dot
">>> s2 = s.reindex([1, 0, 2, 3])
>>> df.dot(s2)
0    -4
1     5
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dot.html, pandas.Series.reindex pandas.DataFrame.dot
">>> df = pd.DataFrame([[4, 9]] * 3, columns=['A', 'B'])
>>> df
   A  B
0  4  9
1  4  9
2  4  9
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.apply.html, pandas.DataFrame
">>> df.apply(np.sqrt)
     A    B
0  2.0  3.0
1  2.0  3.0
2  2.0  3.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.apply.html, pandas.DataFrame.apply
">>> df.apply(np.sum, axis=0)
A    12
B    27
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.apply.html, pandas.DataFrame.apply
">>> df.apply(np.sum, axis=1)
0    13
1    13
2    13
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.apply.html, pandas.DataFrame.apply
">>> df.apply(lambda x: [1, 2], axis=1)
0    [1, 2]
1    [1, 2]
2    [1, 2]
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.apply.html, pandas.DataFrame.apply
">>> df.apply(lambda x: [1, 2], axis=1, result_type='expand')
   0  1
0  1  2
1  1  2
2  1  2
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.apply.html, pandas.DataFrame.apply
">>> df.apply(lambda x: pd.Series([1, 2], index=['foo', 'bar']), axis=1)
   foo  bar
0    1    2
1    1    2
2    1    2
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.apply.html, pandas.DataFrame.apply pandas.Series
">>> df.apply(lambda x: [1, 2], axis=1, result_type='broadcast')
   A  B
0  1  2
1  1  2
2  1  2
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.apply.html, pandas.DataFrame.apply
">>> df = pd.DataFrame({""B"": [0, 1, 2, np.nan, 4]})
>>> df
     B
0  0.0
1  1.0
2  2.0
3  NaN
4  4.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.expanding.html, pandas.DataFrame
">>> df.expanding(1).sum()
     B
0  0.0
1  1.0
2  3.0
3  3.0
4  7.0
>>> df.expanding(3).sum()
     B
0  NaN
1  NaN
2  3.0
3  3.0
4  7.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.expanding.html, pandas.DataFrame.expanding
">>> df = pd.DataFrame([('falcon', 'bird', 389.0),
...                    ('parrot', 'bird', 24.0),
...                    ('lion', 'mammal', 80.5),
...                    ('monkey', 'mammal', np.nan)],
...                   columns=['name', 'class', 'max_speed'],
...                   index=[0, 2, 3, 1])
>>> df
     name   class  max_speed
0  falcon    bird      389.0
2  parrot    bird       24.0
3    lion  mammal       80.5
1  monkey  mammal        NaN
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.take.html, pandas.DataFrame
">>> df.take([0, 3])
     name   class  max_speed
0  falcon    bird      389.0
1  monkey  mammal        NaN
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.take.html, pandas.DataFrame.take
">>> df.take([1, 2], axis=1)
    class  max_speed
0    bird      389.0
2    bird       24.0
3  mammal       80.5
1  mammal        NaN
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.take.html, pandas.DataFrame.take
">>> df.take([-1, -2])
     name   class  max_speed
1  monkey  mammal        NaN
3    lion  mammal       80.5
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.take.html, pandas.DataFrame.take
">>> idx = pd.to_datetime(
...     [
...         ""2001-03-31 00:00:00"",
...         ""2002-05-31 00:00:00"",
...         ""2003-08-31 00:00:00"",
...     ]
... )
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_period.html, pandas.to_datetime
">>> idx
DatetimeIndex(['2001-03-31', '2002-05-31', '2003-08-31'],
dtype='datetime64[ns]', freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_period.html, pandas.DatetimeIndex
">>> idx.to_period(""M"")
PeriodIndex(['2001-03', '2002-05', '2003-08'], dtype='period[M]')
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_period.html, pandas.PeriodIndex
">>> idx.to_period(""Y"")
PeriodIndex(['2001', '2002', '2003'], dtype='period[Y-DEC]')
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_period.html, pandas.PeriodIndex
">>> df = pd.DataFrame({'angles': [0, 3, 4],
...                    'degrees': [360, 180, 360]},
...                   index=['circle', 'triangle', 'rectangle'])
>>> df
           angles  degrees
circle          0      360
triangle        3      180
rectangle       4      360
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rsub.html, pandas.DataFrame
">>> df.add(1)
           angles  degrees
circle          1      361
triangle        4      181
rectangle       5      361
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rsub.html, pandas.DataFrame.add
">>> df.div(10)
           angles  degrees
circle        0.0     36.0
triangle      0.3     18.0
rectangle     0.4     36.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rsub.html, pandas.DataFrame.div
">>> df.rdiv(10)
             angles   degrees
circle          inf  0.027778
triangle   3.333333  0.055556
rectangle  2.500000  0.027778
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rsub.html, pandas.DataFrame.rdiv
">>> df.sub([1, 2], axis='columns')
           angles  degrees
circle         -1      358
triangle        2      178
rectangle       3      358
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rsub.html, pandas.DataFrame.sub
">>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),
...        axis='index')
           angles  degrees
circle         -1      359
triangle        2      179
rectangle       3      359
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rsub.html, pandas.DataFrame.sub pandas.Series
">>> df.mul({'angles': 0, 'degrees': 2})
            angles  degrees
circle           0      720
triangle         0      360
rectangle        0      720
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rsub.html, pandas.DataFrame.mul
">>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')
            angles  degrees
circle           0        0
triangle         6      360
rectangle       12     1080
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rsub.html, pandas.DataFrame.mul
">>> other = pd.DataFrame({'angles': [0, 3, 4]},
...                      index=['circle', 'triangle', 'rectangle'])
>>> other
           angles
circle          0
triangle        3
rectangle       4
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rsub.html, pandas.DataFrame
">>> df.mul(other, fill_value=0)
           angles  degrees
circle          0      0.0
triangle        9      0.0
rectangle      16      0.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rsub.html, pandas.DataFrame.mul
">>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],
...                              'degrees': [360, 180, 360, 360, 540, 720]},
...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],
...                                    ['circle', 'triangle', 'rectangle',
...                                     'square', 'pentagon', 'hexagon']])
>>> df_multindex
             angles  degrees
A circle          0      360
  triangle        3      180
  rectangle       4      360
B square          4      360
  pentagon        5      540
  hexagon         6      720
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rsub.html, pandas.DataFrame
">>> df.div(df_multindex, level=1, fill_value=0)
             angles  degrees
A circle        NaN      1.0
  triangle      1.0      1.0
  rectangle     1.0      1.0
B square        0.0      0.0
  pentagon      0.0      0.0
  hexagon       0.0      0.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rsub.html, pandas.DataFrame.div
">>> s = pd.Series([2, np.nan, 5, -1, 0])
>>> s
0    2.0
1    NaN
2    5.0
3   -1.0
4    0.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.cumprod.html, pandas.Series
">>> s.cumprod()
0     2.0
1     NaN
2    10.0
3   -10.0
4    -0.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.cumprod.html, pandas.Series.cumprod
">>> s.cumprod(skipna=False)
0    2.0
1    NaN
2    NaN
3    NaN
4    NaN
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.cumprod.html, pandas.Series.cumprod
">>> df = pd.DataFrame([[2.0, 1.0],
...                    [3.0, np.nan],
...                    [1.0, 0.0]],
...                   columns=list('AB'))
>>> df
     A    B
0  2.0  1.0
1  3.0  NaN
2  1.0  0.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.cumprod.html, pandas.DataFrame
">>> df.cumprod()
     A    B
0  2.0  1.0
1  6.0  NaN
2  6.0  0.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.cumprod.html, pandas.DataFrame.cumprod
">>> df.cumprod(axis=1)
     A    B
0  2.0  2.0
1  3.0  NaN
2  1.0  0.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.cumprod.html, pandas.DataFrame.cumprod
">>> s = pd.Series([2, np.nan, 5, -1, 0])
>>> s
0    2.0
1    NaN
2    5.0
3   -1.0
4    0.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.cumsum.html, pandas.Series
">>> s.cumsum()
0    2.0
1    NaN
2    7.0
3    6.0
4    6.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.cumsum.html, pandas.Series.cumsum
">>> s.cumsum(skipna=False)
0    2.0
1    NaN
2    NaN
3    NaN
4    NaN
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.cumsum.html, pandas.Series.cumsum
">>> df = pd.DataFrame([[2.0, 1.0],
...                    [3.0, np.nan],
...                    [1.0, 0.0]],
...                   columns=list('AB'))
>>> df
     A    B
0  2.0  1.0
1  3.0  NaN
2  1.0  0.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.cumsum.html, pandas.DataFrame
">>> df.cumsum()
     A    B
0  2.0  1.0
1  5.0  NaN
2  6.0  1.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.cumsum.html, pandas.DataFrame.cumsum
">>> df.cumsum(axis=1)
     A    B
0  2.0  3.0
1  3.0  NaN
2  1.0  1.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.cumsum.html, pandas.DataFrame.cumsum
">>> project_id = ""my-project""
>>> table_id = 'my_dataset.my_table'
>>> df = pd.DataFrame({
...                   ""my_string"": [""a"", ""b"", ""c""],
...                   ""my_int64"": [1, 2, 3],
...                   ""my_float64"": [4.0, 5.0, 6.0],
...                   ""my_bool1"": [True, False, True],
...                   ""my_bool2"": [False, True, False],
...                   ""my_dates"": pd.date_range(""now"", periods=3),
...                   }
...                   )
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_gbq.html, pandas.DataFrame pandas.date_range
">>> df.to_gbq(table_id, project_id=project_id)  
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_gbq.html, pandas.DataFrame.to_gbq
">>> data = np.array([(3, 'a'), (2, 'b'), (1, 'c'), (0, 'd')],
...                 dtype=[('col_1', 'i4'), ('col_2', 'U1')])
>>> pd.DataFrame.from_records(data)
   col_1 col_2
0      3     a
1      2     b
2      1     c
3      0     d
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.from_records.html, pandas.DataFrame.from_records
">>> data = [{'col_1': 3, 'col_2': 'a'},
...         {'col_1': 2, 'col_2': 'b'},
...         {'col_1': 1, 'col_2': 'c'},
...         {'col_1': 0, 'col_2': 'd'}]
>>> pd.DataFrame.from_records(data)
   col_1 col_2
0      3     a
1      2     b
2      1     c
3      0     d
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.from_records.html, pandas.DataFrame.from_records
">>> data = [(3, 'a'), (2, 'b'), (1, 'c'), (0, 'd')]
>>> pd.DataFrame.from_records(data, columns=['col_1', 'col_2'])
   col_1 col_2
0      3     a
1      2     b
2      1     c
3      0     d
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.from_records.html, pandas.DataFrame.from_records
">>> df = pd.DataFrame({""A"": [""foo"", ""foo"", ""foo"", ""foo"", ""foo"",
...                          ""bar"", ""bar"", ""bar"", ""bar""],
...                    ""B"": [""one"", ""one"", ""one"", ""two"", ""two"",
...                          ""one"", ""one"", ""two"", ""two""],
...                    ""C"": [""small"", ""large"", ""large"", ""small"",
...                          ""small"", ""large"", ""small"", ""small"",
...                          ""large""],
...                    ""D"": [1, 2, 2, 3, 3, 4, 5, 6, 7],
...                    ""E"": [2, 4, 5, 5, 6, 6, 8, 9, 9]})
>>> df
     A    B      C  D  E
0  foo  one  small  1  2
1  foo  one  large  2  4
2  foo  one  large  2  5
3  foo  two  small  3  5
4  foo  two  small  3  6
5  bar  one  large  4  6
6  bar  one  small  5  8
7  bar  two  small  6  9
8  bar  two  large  7  9
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pivot_table.html, pandas.DataFrame
">>> table = pd.pivot_table(df, values='D', index=['A', 'B'],
...                        columns=['C'], aggfunc=""sum"")
>>> table
C        large  small
A   B
bar one    4.0    5.0
    two    7.0    6.0
foo one    4.0    1.0
    two    NaN    6.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pivot_table.html, pandas.pivot_table
">>> table = pd.pivot_table(df, values='D', index=['A', 'B'],
...                        columns=['C'], aggfunc=""sum"", fill_value=0)
>>> table
C        large  small
A   B
bar one      4      5
    two      7      6
foo one      4      1
    two      0      6
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pivot_table.html, pandas.pivot_table
">>> table = pd.pivot_table(df, values=['D', 'E'], index=['A', 'C'],
...                        aggfunc={'D': ""mean"", 'E': ""mean""})
>>> table
                D         E
A   C
bar large  5.500000  7.500000
    small  5.500000  8.500000
foo large  2.000000  4.500000
    small  2.333333  4.333333
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pivot_table.html, pandas.pivot_table
">>> table = pd.pivot_table(df, values=['D', 'E'], index=['A', 'C'],
...                        aggfunc={'D': ""mean"",
...                                 'E': [""min"", ""max"", ""mean""]})
>>> table
                  D   E
               mean max      mean  min
A   C
bar large  5.500000   9  7.500000    6
    small  5.500000   9  8.500000    8
foo large  2.000000   5  4.500000    4
    small  2.333333   6  4.333333    2
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pivot_table.html, pandas.pivot_table
">>> df = pd.DataFrame({'person_id': [0, 1, 2, 3],
...                    'age': [21, 25, 62, 43],
...                    'height': [1.61, 1.87, 1.49, 2.01]}
...                   ).set_index('person_id')
>>> df
           age  height
person_id
0           21    1.61
1           25    1.87
2           62    1.49
3           43    2.01
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.var.html, pandas.DataFrame pandas.DataFrame.set_index
">>> df.var()
age       352.916667
height      0.056367
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.var.html, pandas.DataFrame.var
">>> df.var(ddof=0)
age       264.687500
height      0.042275
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.var.html, pandas.DataFrame.var
">>> s = pd.date_range('2016-12-31', '2017-01-08', freq='D').to_series()
>>> s.dt.dayofweek
2016-12-31    5
2017-01-01    6
2017-01-02    0
2017-01-03    1
2017-01-04    2
2017-01-05    3
2017-01-06    4
2017-01-07    5
2017-01-08    6
Freq: D, dtype: int32
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.day_of_week.html, pandas.date_range
">>> index = ['Firefox', 'Chrome', 'Safari', 'IE10', 'Konqueror']
>>> df = pd.DataFrame({'http_status': [200, 200, 404, 404, 301],
...                   'response_time': [0.04, 0.02, 0.07, 0.08, 1.0]},
...                   index=index)
>>> df
           http_status  response_time
Firefox            200           0.04
Chrome             200           0.02
Safari             404           0.07
IE10               404           0.08
Konqueror          301           1.00
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reindex.html, pandas.DataFrame
">>> new_index = ['Safari', 'Iceweasel', 'Comodo Dragon', 'IE10',
...              'Chrome']
>>> df.reindex(new_index)
               http_status  response_time
Safari               404.0           0.07
Iceweasel              NaN            NaN
Comodo Dragon          NaN            NaN
IE10                 404.0           0.08
Chrome               200.0           0.02
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reindex.html, pandas.DataFrame.reindex
">>> df.reindex(new_index, fill_value=0)
               http_status  response_time
Safari                 404           0.07
Iceweasel                0           0.00
Comodo Dragon            0           0.00
IE10                   404           0.08
Chrome                 200           0.02
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reindex.html, pandas.DataFrame.reindex
">>> df.reindex(new_index, fill_value='missing')
              http_status response_time
Safari                404          0.07
Iceweasel         missing       missing
Comodo Dragon     missing       missing
IE10                  404          0.08
Chrome                200          0.02
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reindex.html, pandas.DataFrame.reindex
">>> df.reindex(columns=['http_status', 'user_agent'])
           http_status  user_agent
Firefox            200         NaN
Chrome             200         NaN
Safari             404         NaN
IE10               404         NaN
Konqueror          301         NaN
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reindex.html, pandas.DataFrame.reindex
">>> df.reindex(['http_status', 'user_agent'], axis=""columns"")
           http_status  user_agent
Firefox            200         NaN
Chrome             200         NaN
Safari             404         NaN
IE10               404         NaN
Konqueror          301         NaN
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reindex.html, pandas.DataFrame.reindex
">>> date_index = pd.date_range('1/1/2010', periods=6, freq='D')
>>> df2 = pd.DataFrame({""prices"": [100, 101, np.nan, 100, 89, 88]},
...                    index=date_index)
>>> df2
            prices
2010-01-01   100.0
2010-01-02   101.0
2010-01-03     NaN
2010-01-04   100.0
2010-01-05    89.0
2010-01-06    88.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reindex.html, pandas.date_range pandas.DataFrame
">>> date_index2 = pd.date_range('12/29/2009', periods=10, freq='D')
>>> df2.reindex(date_index2)
            prices
2009-12-29     NaN
2009-12-30     NaN
2009-12-31     NaN
2010-01-01   100.0
2010-01-02   101.0
2010-01-03     NaN
2010-01-04   100.0
2010-01-05    89.0
2010-01-06    88.0
2010-01-07     NaN
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reindex.html, pandas.date_range pandas.DataFrame.reindex
">>> df2.reindex(date_index2, method='bfill')
            prices
2009-12-29   100.0
2009-12-30   100.0
2009-12-31   100.0
2010-01-01   100.0
2010-01-02   101.0
2010-01-03     NaN
2010-01-04   100.0
2010-01-05    89.0
2010-01-06    88.0
2010-01-07     NaN
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reindex.html, pandas.DataFrame.reindex
">>> c = pd.Categorical(['a', 'a', 'b'])
>>> c.rename_categories([0, 1])
[0, 0, 1]
Categories (2, int64): [0, 1]
",https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.rename_categories.html, pandas.Categorical
">>> i = pd.date_range('2018-04-09', periods=4, freq='12h')
>>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)
>>> ts
                     A
2018-04-09 00:00:00  1
2018-04-09 12:00:00  2
2018-04-10 00:00:00  3
2018-04-10 12:00:00  4
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.at_time.html, pandas.date_range pandas.DataFrame
">>> ts.at_time('12:00')
                     A
2018-04-09 12:00:00  2
2018-04-10 12:00:00  4
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.at_time.html, pandas.DataFrame.at_time
">>> df = pd.DataFrame({""A"": [""a"", 1, 2, 3]})
>>> df = df.iloc[1:]
>>> df
   A
1  1
2  2
3  3
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.infer_objects.html, pandas.DataFrame
">>> df.infer_objects().dtypes
A    int64
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.infer_objects.html, pandas.DataFrame.infer_objects
">>> df = pd.DataFrame([[0, 2, 3], [0, 4, 1], [10, 20, 30]],
...                   columns=['A', 'B', 'C'])
>>> df
    A   B   C
0   0   2   3
1   0   4   1
2  10  20  30
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iat.html, pandas.DataFrame
">>> pd.Series([True]).bool()  
True
>>> pd.Series([False]).bool()  
False
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.bool.html, pandas.Series
">>> pd.DataFrame({'col': [True]}).bool()  
True
>>> pd.DataFrame({'col': [False]}).bool()  
False
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.bool.html, pandas.DataFrame
">>> pd.Series([True]).item()  
True
>>> pd.Series([False]).item()  
False
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.bool.html, pandas.Series
">>> df = pd.DataFrame(dict(age=[5, 6, np.nan],
...                        born=[pd.NaT, pd.Timestamp('1939-05-27'),
...                              pd.Timestamp('1940-04-25')],
...                        name=['Alfred', 'Batman', ''],
...                        toy=[None, 'Batmobile', 'Joker']))
>>> df
   age       born    name        toy
0  5.0        NaT  Alfred       None
1  6.0 1939-05-27  Batman  Batmobile
2  NaN 1940-04-25              Joker
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.notna.html, pandas.DataFrame
">>> df.notna()
     age   born  name    toy
0   True  False  True  False
1   True   True  True   True
2  False   True  True   True
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.notna.html, pandas.DataFrame.notna
">>> ser = pd.Series([5, 6, np.nan])
>>> ser
0    5.0
1    6.0
2    NaN
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.notna.html, pandas.Series
">>> ser.notna()
0     True
1     True
2    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.notna.html, pandas.Series.notna
">>> df = pd.DataFrame({'num_legs': [2, 4], 'num_wings': [2, 0]},
...                   index=['falcon', 'dog'])
>>> df
        num_legs  num_wings
falcon         2          2
dog            4          0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isin.html, pandas.DataFrame
">>> df.isin([0, 2])
        num_legs  num_wings
falcon      True       True
dog        False       True
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isin.html, pandas.DataFrame.isin
">>> ~df.isin([0, 2])
        num_legs  num_wings
falcon     False      False
dog         True      False
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isin.html, pandas.DataFrame.isin
">>> df.isin({'num_wings': [0, 3]})
        num_legs  num_wings
falcon     False      False
dog        False       True
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isin.html, pandas.DataFrame.isin
">>> other = pd.DataFrame({'num_legs': [8, 3], 'num_wings': [0, 2]},
...                      index=['spider', 'falcon'])
>>> df.isin(other)
        num_legs  num_wings
falcon     False       True
dog        False      False
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isin.html, pandas.DataFrame pandas.DataFrame.isin
">>> df = pd.DataFrame({'angles': [0, 3, 4],
...                    'degrees': [360, 180, 360]},
...                   index=['circle', 'triangle', 'rectangle'])
>>> df
           angles  degrees
circle          0      360
triangle        3      180
rectangle       4      360
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pow.html, pandas.DataFrame
">>> df.add(1)
           angles  degrees
circle          1      361
triangle        4      181
rectangle       5      361
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pow.html, pandas.DataFrame.add
">>> df.div(10)
           angles  degrees
circle        0.0     36.0
triangle      0.3     18.0
rectangle     0.4     36.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pow.html, pandas.DataFrame.div
">>> df.rdiv(10)
             angles   degrees
circle          inf  0.027778
triangle   3.333333  0.055556
rectangle  2.500000  0.027778
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pow.html, pandas.DataFrame.rdiv
">>> df.sub([1, 2], axis='columns')
           angles  degrees
circle         -1      358
triangle        2      178
rectangle       3      358
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pow.html, pandas.DataFrame.sub
">>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),
...        axis='index')
           angles  degrees
circle         -1      359
triangle        2      179
rectangle       3      359
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pow.html, pandas.DataFrame.sub pandas.Series
">>> df.mul({'angles': 0, 'degrees': 2})
            angles  degrees
circle           0      720
triangle         0      360
rectangle        0      720
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pow.html, pandas.DataFrame.mul
">>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')
            angles  degrees
circle           0        0
triangle         6      360
rectangle       12     1080
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pow.html, pandas.DataFrame.mul
">>> other = pd.DataFrame({'angles': [0, 3, 4]},
...                      index=['circle', 'triangle', 'rectangle'])
>>> other
           angles
circle          0
triangle        3
rectangle       4
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pow.html, pandas.DataFrame
">>> df.mul(other, fill_value=0)
           angles  degrees
circle          0      0.0
triangle        9      0.0
rectangle      16      0.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pow.html, pandas.DataFrame.mul
">>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],
...                              'degrees': [360, 180, 360, 360, 540, 720]},
...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],
...                                    ['circle', 'triangle', 'rectangle',
...                                     'square', 'pentagon', 'hexagon']])
>>> df_multindex
             angles  degrees
A circle          0      360
  triangle        3      180
  rectangle       4      360
B square          4      360
  pentagon        5      540
  hexagon         6      720
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pow.html, pandas.DataFrame
">>> df.div(df_multindex, level=1, fill_value=0)
             angles  degrees
A circle        NaN      1.0
  triangle      1.0      1.0
  rectangle     1.0      1.0
B square        0.0      0.0
  pentagon      0.0      0.0
  hexagon       0.0      0.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pow.html, pandas.DataFrame.div
">>> df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})
>>> for x in df:
...     print(x)
A
B
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.__iter__.html, pandas.DataFrame
">>> df = pd.DataFrame(dict(age=[5, 6, np.nan],
...                        born=[pd.NaT, pd.Timestamp('1939-05-27'),
...                              pd.Timestamp('1940-04-25')],
...                        name=['Alfred', 'Batman', ''],
...                        toy=[None, 'Batmobile', 'Joker']))
>>> df
   age       born    name        toy
0  5.0        NaT  Alfred       None
1  6.0 1939-05-27  Batman  Batmobile
2  NaN 1940-04-25              Joker
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.notnull.html, pandas.DataFrame
">>> df.notna()
     age   born  name    toy
0   True  False  True  False
1   True   True  True   True
2  False   True  True   True
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.notnull.html, pandas.DataFrame.notna
">>> ser = pd.Series([5, 6, np.nan])
>>> ser
0    5.0
1    6.0
2    NaN
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.notnull.html, pandas.Series
">>> ser.notna()
0     True
1     True
2    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.notnull.html, pandas.Series.notna
">>> idx = pd.MultiIndex.from_arrays([
...     ['warm', 'warm', 'cold', 'cold'],
...     ['dog', 'falcon', 'fish', 'spider']],
...     names=['blooded', 'animal'])
>>> s = pd.Series([4, 2, 0, 8], name='legs', index=idx)
>>> s
blooded  animal
warm     dog       4
         falcon    2
cold     fish      0
         spider    8
Name: legs, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.min.html, pandas.MultiIndex.from_arrays pandas.Series
">>> s.min()
0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.min.html, pandas.Series.min
">>> df = pd.DataFrame({'A': [4, 5, 6], 'B': [4, 1, 1]})
>>> df.nunique()
A    3
B    2
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.nunique.html, pandas.DataFrame pandas.DataFrame.nunique
">>> df.nunique(axis=1)
0    1
1    2
2    2
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.nunique.html, pandas.DataFrame.nunique
">>> c = pd.Categorical(['a', 'c', 'b', 'c', 'd'])
>>> c
['a', 'c', 'b', 'c', 'd']
Categories (4, object): ['a', 'b', 'c', 'd']
",https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.remove_categories.html, pandas.Categorical
">>> idx = pd.MultiIndex.from_tuples(
...     [
...         (1, ""one""),
...         (1, ""two""),
...         (2, ""one""),
...         (2, ""two""),
...         (3, ""one""),
...         (3, ""two"")
...     ],
...     names=[""foo"", ""bar""]
... )
>>> idx
MultiIndex([(1, 'one'),
    (1, 'two'),
    (2, 'one'),
    (2, 'two'),
    (3, 'one'),
    (3, 'two')],
   names=['foo', 'bar'])
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.set_levels.html, pandas.MultiIndex.from_tuples pandas.MultiIndex
">>> idx.set_levels([['a', 'b', 'c'], [1, 2]])
MultiIndex([('a', 1),
            ('a', 2),
            ('b', 1),
            ('b', 2),
            ('c', 1),
            ('c', 2)],
           names=['foo', 'bar'])
>>> idx.set_levels(['a', 'b', 'c'], level=0)
MultiIndex([('a', 'one'),
            ('a', 'two'),
            ('b', 'one'),
            ('b', 'two'),
            ('c', 'one'),
            ('c', 'two')],
           names=['foo', 'bar'])
>>> idx.set_levels(['a', 'b'], level='bar')
MultiIndex([(1, 'a'),
            (1, 'b'),
            (2, 'a'),
            (2, 'b'),
            (3, 'a'),
            (3, 'b')],
           names=['foo', 'bar'])
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.set_levels.html, pandas.MultiIndex
">>> idx.set_levels([['a', 'b', 'c'], [1, 2, 3, 4]], level=[0, 1])
MultiIndex([('a', 1),
    ('a', 2),
    ('b', 1),
    ('b', 2),
    ('c', 1),
    ('c', 2)],
   names=['foo', 'bar'])
>>> idx.set_levels([['a', 'b', 'c'], [1, 2, 3, 4]], level=[0, 1]).levels
FrozenList([['a', 'b', 'c'], [1, 2, 3, 4]])
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.set_levels.html, pandas.MultiIndex
">>> dates = pd.Series(pd.date_range(""2017-12-30"", periods=3))
>>> dates
0   2017-12-30
1   2017-12-31
2   2018-01-01
dtype: datetime64[ns]
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.is_year_end.html, pandas.Series pandas.date_range
">>> idx = pd.date_range(""2017-12-30"", periods=3)
>>> idx
DatetimeIndex(['2017-12-30', '2017-12-31', '2018-01-01'],
              dtype='datetime64[ns]', freq='D')
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.is_year_end.html, pandas.date_range pandas.DatetimeIndex
">>> idx.is_year_end
array([False,  True, False])
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.is_year_end.html, pandas.array
">>> df = pd.DataFrame([('falcon', 'bird', 389.0),
...                    ('parrot', 'bird', 24.0),
...                    ('lion', 'mammal', 80.5),
...                    ('monkey', 'mammal', np.nan)],
...                   columns=('name', 'class', 'max_speed'))
>>> df
     name   class  max_speed
0  falcon    bird      389.0
1  parrot    bird       24.0
2    lion  mammal       80.5
3  monkey  mammal        NaN
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pop.html, pandas.DataFrame
">>> df.pop('class')
0      bird
1      bird
2    mammal
3    mammal
Name: class, dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pop.html, pandas.DataFrame.pop
">>> index = pd.date_range('1/1/2000', periods=4, freq='min')
>>> series = pd.Series([0.0, None, 2.0, 3.0], index=index)
>>> df = pd.DataFrame({'s': series})
>>> df
                       s
2000-01-01 00:00:00    0.0
2000-01-01 00:01:00    NaN
2000-01-01 00:02:00    2.0
2000-01-01 00:03:00    3.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.asfreq.html, pandas.date_range pandas.Series pandas.DataFrame
">>> df.asfreq(freq='30s')
                       s
2000-01-01 00:00:00    0.0
2000-01-01 00:00:30    NaN
2000-01-01 00:01:00    NaN
2000-01-01 00:01:30    NaN
2000-01-01 00:02:00    2.0
2000-01-01 00:02:30    NaN
2000-01-01 00:03:00    3.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.asfreq.html, pandas.DataFrame.asfreq
">>> df.asfreq(freq='30s', fill_value=9.0)
                       s
2000-01-01 00:00:00    0.0
2000-01-01 00:00:30    9.0
2000-01-01 00:01:00    NaN
2000-01-01 00:01:30    9.0
2000-01-01 00:02:00    2.0
2000-01-01 00:02:30    9.0
2000-01-01 00:03:00    3.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.asfreq.html, pandas.DataFrame.asfreq
">>> df.asfreq(freq='30s', method='bfill')
                       s
2000-01-01 00:00:00    0.0
2000-01-01 00:00:30    NaN
2000-01-01 00:01:00    NaN
2000-01-01 00:01:30    2.0
2000-01-01 00:02:00    2.0
2000-01-01 00:02:30    3.0
2000-01-01 00:03:00    3.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.asfreq.html, pandas.DataFrame.asfreq
">>> styler = pd.DataFrame([[1, 2], [3, 4]]).style
>>> styler2 = pd.DataFrame([[9, 9, 9]]).style
>>> styler.hide(axis=0).highlight_max(axis=1)  
>>> export = styler.export()
>>> styler2.use(export)  
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.use.html, pandas.DataFrame pandas.io.formats.style.Styler.highlight_max
">>> i = pd.date_range('2018-04-09', periods=4, freq='2D')
>>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)
>>> ts
            A
2018-04-09  1
2018-04-11  2
2018-04-13  3
2018-04-15  4
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.first.html, pandas.date_range pandas.DataFrame
">>> ts.first('3D')
            A
2018-04-09  1
2018-04-11  2
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.first.html, pandas.DataFrame.first
">>> data = np.random.randn(25, 4)
>>> df = pd.DataFrame(data, columns=list('ABCD'))
>>> ax = df.plot.box()
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.box.html, pandas.DataFrame pandas.DataFrame.plot.box
">>> age_list = [8, 10, 12, 14, 72, 74, 76, 78, 20, 25, 30, 35, 60, 85]
>>> df = pd.DataFrame({""gender"": list(""MMMMMMMMFFFFFF""), ""age"": age_list})
>>> ax = df.plot.box(column=""age"", by=""gender"", figsize=(10, 8))
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.box.html, pandas.DataFrame pandas.DataFrame.plot.box
">>> df = pd.DataFrame({'dates': pd.date_range(""2017-03-30"",
...                   periods=4)})
>>> df.assign(quarter=df.dates.dt.quarter,
...           is_quarter_start=df.dates.dt.is_quarter_start)
       dates  quarter  is_quarter_start
0 2017-03-30        1             False
1 2017-03-31        1             False
2 2017-04-01        2              True
3 2017-04-02        2             False
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.is_quarter_start.html, pandas.DataFrame pandas.date_range pandas.DataFrame.assign
">>> idx = pd.date_range('2017-03-30', periods=4)
>>> idx
DatetimeIndex(['2017-03-30', '2017-03-31', '2017-04-01', '2017-04-02'],
              dtype='datetime64[ns]', freq='D')
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.is_quarter_start.html, pandas.date_range pandas.DatetimeIndex
">>> idx.is_quarter_start
array([False, False,  True, False])
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.is_quarter_start.html, pandas.array
">>> s = pd.Series([1, 2, 3])
>>> s.mean()
2.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mean.html, pandas.Series pandas.Series.mean
">>> df = pd.DataFrame({'a': [1, 2], 'b': [2, 3]}, index=['tiger', 'zebra'])
>>> df
       a   b
tiger  1   2
zebra  2   3
>>> df.mean()
a   1.5
b   2.5
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mean.html, pandas.DataFrame pandas.DataFrame.mean
">>> df.mean(axis=1)
tiger   1.5
zebra   2.5
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mean.html, pandas.DataFrame.mean
">>> df = pd.DataFrame({'a': [1, 2], 'b': ['T', 'Z']},
...                   index=['tiger', 'zebra'])
>>> df.mean(numeric_only=True)
a   1.5
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mean.html, pandas.DataFrame pandas.DataFrame.mean
">>> data = [[8000, 1000], [9500, np.nan], [5000, 2000]]
>>> df = pd.DataFrame(data, columns=['Salary', 'Others'])
>>> df
   Salary  Others
0    8000  1000.0
1    9500     NaN
2    5000  2000.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pipe.html, pandas.DataFrame
">>> (
...     df.pipe(subtract_federal_tax)
...     .pipe(subtract_state_tax, rate=0.12)
...     .pipe(subtract_national_insurance, rate=0.05, rate_increase=0.02)
... )
    Salary   Others
0  5892.48   736.56
1  6997.32      NaN
2  3682.80  1473.12
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pipe.html, pandas.DataFrame.pipe
">>> def subtract_national_insurance(rate, df, rate_increase):
...     new_rate = rate + rate_increase
...     return df * (1 - new_rate)
>>> (
...     df.pipe(subtract_federal_tax)
...     .pipe(subtract_state_tax, rate=0.12)
...     .pipe(
...         (subtract_national_insurance, 'df'),
...         rate=0.05,
...         rate_increase=0.02
...     )
... )
    Salary   Others
0  5892.48   736.56
1  6997.32      NaN
2  3682.80  1473.12
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pipe.html, pandas.DataFrame.pipe
">>> s = pd.Series([""1/1/2020 10:00:00+00:00"", ""2/1/2020 11:00:00+00:00""])
>>> s = pd.to_datetime(s)
>>> s
0   2020-01-01 10:00:00+00:00
1   2020-02-01 11:00:00+00:00
dtype: datetime64[ns, UTC]
>>> s.dt.timetz
0    10:00:00+00:00
1    11:00:00+00:00
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.timetz.html, pandas.Series pandas.to_datetime
">>> idx = pd.DatetimeIndex([""1/1/2020 10:00:00+00:00"",
...                         ""2/1/2020 11:00:00+00:00""])
>>> idx.timetz
array([datetime.time(10, 0, tzinfo=datetime.timezone.utc),
datetime.time(11, 0, tzinfo=datetime.timezone.utc)], dtype=object)
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.timetz.html, pandas.DatetimeIndex pandas.array pandas.Timestamp.time
">>> interv_arr = pd.arrays.IntervalArray([pd.Interval(0, 1), pd.Interval(1, 5)])
>>> interv_arr

[(0, 1], (1, 5]]
Length: 2, dtype: interval[int64, right]
>>> interv_arr.is_non_overlapping_monotonic
True
",https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.is_non_overlapping_monotonic.html, pandas.arrays.IntervalArray pandas.Interval
">>> interv_arr = pd.arrays.IntervalArray([pd.Interval(0, 1),
...                                       pd.Interval(-1, 0.1)])
>>> interv_arr

[(0.0, 1.0], (-1.0, 0.1]]
Length: 2, dtype: interval[float64, right]
>>> interv_arr.is_non_overlapping_monotonic
False
",https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.is_non_overlapping_monotonic.html, pandas.arrays.IntervalArray pandas.Interval
">>> interv_idx = pd.interval_range(start=0, end=2)
>>> interv_idx
IntervalIndex([(0, 1], (1, 2]], dtype='interval[int64, right]')
>>> interv_idx.is_non_overlapping_monotonic
True
",https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.is_non_overlapping_monotonic.html, pandas.interval_range pandas.IntervalIndex
">>> interv_idx = pd.interval_range(start=0, end=2, closed='both')
>>> interv_idx
IntervalIndex([[0, 1], [1, 2]], dtype='interval[int64, both]')
>>> interv_idx.is_non_overlapping_monotonic
False
",https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.is_non_overlapping_monotonic.html, pandas.interval_range pandas.IntervalIndex
">>> pd.Series([False, False]).any()
False
>>> pd.Series([True, False]).any()
True
>>> pd.Series([], dtype=""float64"").any()
False
>>> pd.Series([np.nan]).any()
False
>>> pd.Series([np.nan]).any(skipna=False)
True
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.any.html, pandas.Series
">>> df = pd.DataFrame({""A"": [1, 2], ""B"": [0, 2], ""C"": [0, 0]})
>>> df
   A  B  C
0  1  0  0
1  2  2  0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.any.html, pandas.DataFrame
">>> df.any()
A     True
B     True
C    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.any.html, pandas.DataFrame.any
">>> df = pd.DataFrame({""A"": [True, False], ""B"": [1, 2]})
>>> df
       A  B
0   True  1
1  False  2
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.any.html, pandas.DataFrame
">>> df.any(axis='columns')
0    True
1    True
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.any.html, pandas.DataFrame.any
">>> df = pd.DataFrame({""A"": [True, False], ""B"": [1, 0]})
>>> df
       A  B
0   True  1
1  False  0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.any.html, pandas.DataFrame
">>> df.any(axis='columns')
0    True
1    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.any.html, pandas.DataFrame.any
">>> df.any(axis=None)
True
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.any.html, pandas.DataFrame.any
">>> pd.DataFrame([]).any()
Series([], dtype: bool)
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.any.html, pandas.DataFrame pandas.Series
">>> df_not_necessarily_pandas = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})
>>> interchange_object = df_not_necessarily_pandas.__dataframe__()
>>> interchange_object.column_names()
Index(['A', 'B'], dtype='object')
>>> df_pandas = (pd.api.interchange.from_dataframe
...              (interchange_object.select_columns_by_name(['A'])))
>>> df_pandas
     A
0    1
1    2
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.__dataframe__.html, pandas.DataFrame pandas.Index
">>> s = pd.Series([1, 2, 3, 4, 5])
>>> s.replace(1, 5)
0    5
1    2
2    3
3    4
4    5
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html, pandas.Series pandas.Series.replace
">>> df = pd.DataFrame({'A': [0, 1, 2, 3, 4],
...                    'B': [5, 6, 7, 8, 9],
...                    'C': ['a', 'b', 'c', 'd', 'e']})
>>> df.replace(0, 5)
    A  B  C
0  5  5  a
1  1  6  b
2  2  7  c
3  3  8  d
4  4  9  e
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html, pandas.DataFrame pandas.DataFrame.replace
">>> df.replace([0, 1, 2, 3], 4)
    A  B  C
0  4  5  a
1  4  6  b
2  4  7  c
3  4  8  d
4  4  9  e
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html, pandas.DataFrame.replace
">>> df.replace([0, 1, 2, 3], [4, 3, 2, 1])
    A  B  C
0  4  5  a
1  3  6  b
2  2  7  c
3  1  8  d
4  4  9  e
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html, pandas.DataFrame.replace
">>> s.replace([1, 2], method='bfill')
0    3
1    3
2    3
3    4
4    5
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html, pandas.Series.replace
">>> df.replace({0: 10, 1: 100})
        A  B  C
0   10  5  a
1  100  6  b
2    2  7  c
3    3  8  d
4    4  9  e
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html, pandas.DataFrame.replace
">>> df.replace({'A': 0, 'B': 5}, 100)
        A    B  C
0  100  100  a
1    1    6  b
2    2    7  c
3    3    8  d
4    4    9  e
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html, pandas.DataFrame.replace
">>> df.replace({'A': {0: 100, 4: 400}})
        A  B  C
0  100  5  a
1    1  6  b
2    2  7  c
3    3  8  d
4  400  9  e
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html, pandas.DataFrame.replace
">>> df = pd.DataFrame({'A': ['bat', 'foo', 'bait'],
...                    'B': ['abc', 'bar', 'xyz']})
>>> df.replace(to_replace=r'^ba.$', value='new', regex=True)
        A    B
0   new  abc
1   foo  new
2  bait  xyz
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html, pandas.DataFrame pandas.DataFrame.replace
">>> df.replace({'A': r'^ba.$'}, {'A': 'new'}, regex=True)
        A    B
0   new  abc
1   foo  bar
2  bait  xyz
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html, pandas.DataFrame.replace
">>> df.replace(regex=r'^ba.$', value='new')
        A    B
0   new  abc
1   foo  new
2  bait  xyz
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html, pandas.DataFrame.replace
">>> df.replace(regex={r'^ba.$': 'new', 'foo': 'xyz'})
        A    B
0   new  abc
1   xyz  new
2  bait  xyz
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html, pandas.DataFrame.replace
">>> df.replace(regex=[r'^ba.$', 'foo'], value='new')
        A    B
0   new  abc
1   new  new
2  bait  xyz
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html, pandas.DataFrame.replace
">>> s = pd.Series([10, 'a', 'a', 'b', 'a'])
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html, pandas.Series
">>> s.replace({'a': None})
0      10
1    None
2    None
3       b
4    None
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html, pandas.Series.replace
">>> s.replace('a')
0    10
1    10
2    10
3     b
4     b
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html, pandas.Series.replace
">>> s.replace('a', None)
0      10
1    None
2    None
3       b
4    None
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html, pandas.Series.replace
">>> df = pd.DataFrame({'A': [0, 1, 2, 3, 4],
...                    'B': ['a', 'b', 'c', 'd', 'e'],
...                    'C': ['f', 'g', 'h', 'i', 'j']})
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html, pandas.DataFrame
">>> df.replace(to_replace='^[a-g]', value='e', regex=True)
    A  B  C
0  0  e  e
1  1  e  e
2  2  e  h
3  3  e  i
4  4  e  j
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html, pandas.DataFrame.replace
">>> df.replace(to_replace={'B': '^[a-c]', 'C': '^[h-j]'}, value='e', regex=True)
    A  B  C
0  0  e  f
1  1  e  g
2  2  e  e
3  3  d  e
4  4  e  e
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html, pandas.DataFrame.replace
">>> df = pd.DataFrame(dict(age=[5, 6, np.nan],
...                        born=[pd.NaT, pd.Timestamp('1939-05-27'),
...                              pd.Timestamp('1940-04-25')],
...                        name=['Alfred', 'Batman', ''],
...                        toy=[None, 'Batmobile', 'Joker']))
>>> df
   age       born    name        toy
0  5.0        NaT  Alfred       None
1  6.0 1939-05-27  Batman  Batmobile
2  NaN 1940-04-25              Joker
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isnull.html, pandas.DataFrame
">>> df.isna()
     age   born   name    toy
0  False   True  False   True
1  False  False  False  False
2   True  False  False  False
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isnull.html, pandas.DataFrame.isna
">>> ser = pd.Series([5, 6, np.nan])
>>> ser
0    5.0
1    6.0
2    NaN
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isnull.html, pandas.Series
">>> ser.isna()
0    False
1    False
2     True
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isnull.html, pandas.Series.isna
">>> pd.Index([1, 2, 3])
Index([1, 2, 3], dtype='int64')
",https://pandas.pydata.org/docs/reference/api/pandas.Index.html, pandas.Index pandas.Index
">>> pd.Index(list('abc'))
Index(['a', 'b', 'c'], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.Index.html, pandas.Index pandas.Index
">>> pd.Index([1, 2, 3], dtype=""uint8"")
Index([1, 2, 3], dtype='uint8')
",https://pandas.pydata.org/docs/reference/api/pandas.Index.html, pandas.Index pandas.Index
">>> i = pd.date_range('2018-04-09', periods=4, freq='1D20min')
>>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)
>>> ts
                     A
2018-04-09 00:00:00  1
2018-04-10 00:20:00  2
2018-04-11 00:40:00  3
2018-04-12 01:00:00  4
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.between_time.html, pandas.date_range pandas.DataFrame
">>> ts.between_time('0:15', '0:45')
                     A
2018-04-10 00:20:00  2
2018-04-11 00:40:00  3
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.between_time.html, pandas.DataFrame.between_time
">>> ts.between_time('0:45', '0:15')
                     A
2018-04-09 00:00:00  1
2018-04-12 01:00:00  4
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.between_time.html, pandas.DataFrame.between_time
">>> df = pd.DataFrame({'lab': ['A', 'B', 'C'], 'val': [10, 30, 20]})
>>> ax = df.plot.barh(x='lab', y='val')
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.barh.html, pandas.DataFrame pandas.DataFrame.plot.barh
">>> speed = [0.1, 17.5, 40, 48, 52, 69, 88]
>>> lifespan = [2, 8, 70, 1.5, 25, 12, 28]
>>> index = ['snail', 'pig', 'elephant',
...          'rabbit', 'giraffe', 'coyote', 'horse']
>>> df = pd.DataFrame({'speed': speed,
...                    'lifespan': lifespan}, index=index)
>>> ax = df.plot.barh()
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.barh.html, pandas.DataFrame pandas.DataFrame.plot.barh
">>> ax = df.plot.barh(stacked=True)
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.barh.html, pandas.DataFrame.plot.barh
">>> ax = df.plot.barh(color={""speed"": ""red"", ""lifespan"": ""green""})
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.barh.html, pandas.DataFrame.plot.barh
">>> speed = [0.1, 17.5, 40, 48, 52, 69, 88]
>>> lifespan = [2, 8, 70, 1.5, 25, 12, 28]
>>> index = ['snail', 'pig', 'elephant',
...          'rabbit', 'giraffe', 'coyote', 'horse']
>>> df = pd.DataFrame({'speed': speed,
...                    'lifespan': lifespan}, index=index)
>>> ax = df.plot.barh(y='speed')
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.barh.html, pandas.DataFrame pandas.DataFrame.plot.barh
">>> speed = [0.1, 17.5, 40, 48, 52, 69, 88]
>>> lifespan = [2, 8, 70, 1.5, 25, 12, 28]
>>> index = ['snail', 'pig', 'elephant',
...          'rabbit', 'giraffe', 'coyote', 'horse']
>>> df = pd.DataFrame({'speed': speed,
...                    'lifespan': lifespan}, index=index)
>>> ax = df.plot.barh(x='lifespan')
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.barh.html, pandas.DataFrame pandas.DataFrame.plot.barh
">>> mi = pd.MultiIndex.from_arrays([[1, 2], [3, 4]], names=['x', 'y'])
>>> mi
MultiIndex([(1, 3),
            (2, 4)],
           names=['x', 'y'])
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.reorder_levels.html, pandas.MultiIndex.from_arrays pandas.MultiIndex
">>> mi.reorder_levels(order=[1, 0])
MultiIndex([(3, 1),
            (4, 2)],
           names=['y', 'x'])
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.reorder_levels.html, pandas.MultiIndex
">>> mi.reorder_levels(order=['y', 'x'])
MultiIndex([(3, 1),
            (4, 2)],
           names=['y', 'x'])
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.reorder_levels.html, pandas.MultiIndex
">>> idx = pd.MultiIndex.from_arrays([
...     ['warm', 'warm', 'cold', 'cold'],
...     ['dog', 'falcon', 'fish', 'spider']],
...     names=['blooded', 'animal'])
>>> s = pd.Series([4, 2, 0, 8], name='legs', index=idx)
>>> s
blooded  animal
warm     dog       4
         falcon    2
cold     fish      0
         spider    8
Name: legs, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sum.html, pandas.MultiIndex.from_arrays pandas.Series
">>> s.sum()
14
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sum.html, pandas.Series.sum
">>> pd.Series([], dtype=""float64"").sum()  # min_count=0 is the default
0.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sum.html, pandas.Series
">>> pd.Series([], dtype=""float64"").sum(min_count=1)
nan
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sum.html, pandas.Series
">>> pd.Series([np.nan]).sum()
0.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sum.html, pandas.Series
">>> pd.Series([np.nan]).sum(min_count=1)
nan
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sum.html, pandas.Series
">>> datetime_series = pd.Series(
...     pd.date_range(""2000-01-01"", periods=3, freq=""min"")
... )
>>> datetime_series
0   2000-01-01 00:00:00
1   2000-01-01 00:01:00
2   2000-01-01 00:02:00
dtype: datetime64[ns]
>>> datetime_series.dt.minute
0    0
1    1
2    2
dtype: int32
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.minute.html, pandas.Series pandas.date_range
">>> idx = pd.Index([1.0, 2.0, 3.0, 4.0])
>>> idx.is_floating()  
True
",https://pandas.pydata.org/docs/reference/api/pandas.Index.is_floating.html, pandas.Index
">>> idx = pd.Index([1.0, 2.0, np.nan, 4.0])
>>> idx.is_floating()  
True
",https://pandas.pydata.org/docs/reference/api/pandas.Index.is_floating.html, pandas.Index
">>> idx = pd.Index([1, 2, 3, 4, np.nan])
>>> idx.is_floating()  
True
",https://pandas.pydata.org/docs/reference/api/pandas.Index.is_floating.html, pandas.Index
">>> idx = pd.Index([1, 2, 3, 4])
>>> idx.is_floating()  
False
",https://pandas.pydata.org/docs/reference/api/pandas.Index.is_floating.html, pandas.Index
">>> df = pd.DataFrame({'angles': [0, 3, 4],
...                    'degrees': [360, 180, 360]},
...                   index=['circle', 'triangle', 'rectangle'])
>>> df
           angles  degrees
circle          0      360
triangle        3      180
rectangle       4      360
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rmod.html, pandas.DataFrame
">>> df.add(1)
           angles  degrees
circle          1      361
triangle        4      181
rectangle       5      361
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rmod.html, pandas.DataFrame.add
">>> df.div(10)
           angles  degrees
circle        0.0     36.0
triangle      0.3     18.0
rectangle     0.4     36.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rmod.html, pandas.DataFrame.div
">>> df.rdiv(10)
             angles   degrees
circle          inf  0.027778
triangle   3.333333  0.055556
rectangle  2.500000  0.027778
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rmod.html, pandas.DataFrame.rdiv
">>> df.sub([1, 2], axis='columns')
           angles  degrees
circle         -1      358
triangle        2      178
rectangle       3      358
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rmod.html, pandas.DataFrame.sub
">>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),
...        axis='index')
           angles  degrees
circle         -1      359
triangle        2      179
rectangle       3      359
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rmod.html, pandas.DataFrame.sub pandas.Series
">>> df.mul({'angles': 0, 'degrees': 2})
            angles  degrees
circle           0      720
triangle         0      360
rectangle        0      720
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rmod.html, pandas.DataFrame.mul
">>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')
            angles  degrees
circle           0        0
triangle         6      360
rectangle       12     1080
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rmod.html, pandas.DataFrame.mul
">>> other = pd.DataFrame({'angles': [0, 3, 4]},
...                      index=['circle', 'triangle', 'rectangle'])
>>> other
           angles
circle          0
triangle        3
rectangle       4
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rmod.html, pandas.DataFrame
">>> df.mul(other, fill_value=0)
           angles  degrees
circle          0      0.0
triangle        9      0.0
rectangle      16      0.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rmod.html, pandas.DataFrame.mul
">>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],
...                              'degrees': [360, 180, 360, 360, 540, 720]},
...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],
...                                    ['circle', 'triangle', 'rectangle',
...                                     'square', 'pentagon', 'hexagon']])
>>> df_multindex
             angles  degrees
A circle          0      360
  triangle        3      180
  rectangle       4      360
B square          4      360
  pentagon        5      540
  hexagon         6      720
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rmod.html, pandas.DataFrame
">>> df.div(df_multindex, level=1, fill_value=0)
             angles  degrees
A circle        NaN      1.0
  triangle      1.0      1.0
  rectangle     1.0      1.0
B square        0.0      0.0
  pentagon      0.0      0.0
  hexagon       0.0      0.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rmod.html, pandas.DataFrame.div
">>> rng = pd.date_range('1/1/2018 11:59:00', periods=3, freq='min')
>>> rng
DatetimeIndex(['2018-01-01 11:59:00', '2018-01-01 12:00:00',
               '2018-01-01 12:01:00'],
              dtype='datetime64[ns]', freq='min')
>>> rng.floor('h')
DatetimeIndex(['2018-01-01 11:00:00', '2018-01-01 12:00:00',
               '2018-01-01 12:00:00'],
              dtype='datetime64[ns]', freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.floor.html, pandas.date_range pandas.DatetimeIndex
">>> pd.Series(rng).dt.floor(""h"")
0   2018-01-01 11:00:00
1   2018-01-01 12:00:00
2   2018-01-01 12:00:00
dtype: datetime64[ns]
",https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.floor.html, pandas.Series
">>> rng_tz = pd.DatetimeIndex([""2021-10-31 03:30:00""], tz=""Europe/Amsterdam"")
",https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.floor.html, pandas.DatetimeIndex
">>> rng_tz.floor(""2h"", ambiguous=False)
DatetimeIndex(['2021-10-31 02:00:00+01:00'],
             dtype='datetime64[ns, Europe/Amsterdam]', freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.floor.html, pandas.DatetimeIndex.floor pandas.DatetimeIndex
">>> rng_tz.floor(""2h"", ambiguous=True)
DatetimeIndex(['2021-10-31 02:00:00+02:00'],
              dtype='datetime64[ns, Europe/Amsterdam]', freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.floor.html, pandas.DatetimeIndex.floor pandas.DatetimeIndex
">>> ser = pd.Series(pd.to_timedelta([1, 2, 3], unit='ns'))
>>> ser
0   0 days 00:00:00.000000001
1   0 days 00:00:00.000000002
2   0 days 00:00:00.000000003
dtype: timedelta64[ns]
>>> ser.dt.nanoseconds
0    1
1    2
2    3
dtype: int32
",https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.nanoseconds.html, pandas.Series pandas.to_timedelta
">>> tdelta_idx = pd.to_timedelta([1, 2, 3], unit='ns')
>>> tdelta_idx
TimedeltaIndex(['0 days 00:00:00.000000001', '0 days 00:00:00.000000002',
                '0 days 00:00:00.000000003'],
               dtype='timedelta64[ns]', freq=None)
>>> tdelta_idx.nanoseconds
Index([1, 2, 3], dtype='int32')
",https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.nanoseconds.html, pandas.to_timedelta pandas.TimedeltaIndex pandas.Index
">>> idx = pd.Index([5.2, 6.0, np.nan])
>>> idx
Index([5.2, 6.0, nan], dtype='float64')
>>> idx.notna()
array([ True,  True, False])
",https://pandas.pydata.org/docs/reference/api/pandas.Index.notna.html, pandas.Index pandas.Index pandas.array
">>> idx = pd.Index(['black', '', 'red', None])
>>> idx
Index(['black', '', 'red', None], dtype='object')
>>> idx.notna()
array([ True,  True,  True, False])
",https://pandas.pydata.org/docs/reference/api/pandas.Index.notna.html, pandas.Index pandas.Index pandas.array
">>> idx = pd.Index(['car', 'bike', 'train', 'tractor'])
>>> idx
Index(['car', 'bike', 'train', 'tractor'], dtype='object')
>>> idx.reindex(['car', 'bike'])
(Index(['car', 'bike'], dtype='object'), array([0, 1]))
",https://pandas.pydata.org/docs/reference/api/pandas.Index.reindex.html, pandas.Index pandas.Index pandas.Index.reindex pandas.array
">>> pd.CategoricalIndex([""a"", ""b"", ""c"", ""a"", ""b"", ""c""])
CategoricalIndex(['a', 'b', 'c', 'a', 'b', 'c'],
                 categories=['a', 'b', 'c'], ordered=False, dtype='category')
",https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.html, pandas.CategoricalIndex pandas.CategoricalIndex
">>> c = pd.Categorical([""a"", ""b"", ""c"", ""a"", ""b"", ""c""])
>>> pd.CategoricalIndex(c)
CategoricalIndex(['a', 'b', 'c', 'a', 'b', 'c'],
                 categories=['a', 'b', 'c'], ordered=False, dtype='category')
",https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.html, pandas.Categorical pandas.CategoricalIndex pandas.CategoricalIndex
">>> ci = pd.CategoricalIndex(
...     [""a"", ""b"", ""c"", ""a"", ""b"", ""c""], ordered=True, categories=[""c"", ""b"", ""a""]
... )
>>> ci
CategoricalIndex(['a', 'b', 'c', 'a', 'b', 'c'],
                 categories=['c', 'b', 'a'], ordered=True, dtype='category')
>>> ci.min()
'c'
",https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.html, pandas.CategoricalIndex pandas.CategoricalIndex
">>> idx = pd.DatetimeIndex([""1/1/2020 10:00:00+00:00""], freq=""D"")
>>> idx.freqstr
'D'
",https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.freqstr.html, pandas.DatetimeIndex
">>> idx = pd.DatetimeIndex([""2018-01-01"", ""2018-01-03"", ""2018-01-05""],
...                        freq=""infer"")
>>> idx.freqstr
'2D'
",https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.freqstr.html, pandas.DatetimeIndex
">>> idx = pd.PeriodIndex([""2023-1"", ""2023-2"", ""2023-3""], freq=""M"")
>>> idx.freqstr
'M'
",https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.freqstr.html, pandas.PeriodIndex
">>> mi = pd.MultiIndex.from_arrays([[0, 0], [2, 1]])
>>> mi
MultiIndex([(0, 2),
            (0, 1)],
           )
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.sortlevel.html, pandas.MultiIndex.from_arrays pandas.MultiIndex
">>> mi.sortlevel()
(MultiIndex([(0, 1),
            (0, 2)],
           ), array([1, 0]))
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.sortlevel.html, pandas.MultiIndex.sortlevel pandas.MultiIndex pandas.array
">>> mi.sortlevel(sort_remaining=False)
(MultiIndex([(0, 2),
            (0, 1)],
           ), array([0, 1]))
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.sortlevel.html, pandas.MultiIndex.sortlevel pandas.MultiIndex pandas.array
">>> mi.sortlevel(1)
(MultiIndex([(0, 1),
            (0, 2)],
           ), array([1, 0]))
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.sortlevel.html, pandas.MultiIndex.sortlevel pandas.MultiIndex pandas.array
">>> mi.sortlevel(1, ascending=False)
(MultiIndex([(0, 2),
            (0, 1)],
           ), array([0, 1]))
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.sortlevel.html, pandas.MultiIndex.sortlevel pandas.MultiIndex pandas.array
">>> idx = pd.Index(['A', 'C', 'A', 'B'], name='score')
>>> idx.rename('grade')
Index(['A', 'C', 'A', 'B'], dtype='object', name='grade')
",https://pandas.pydata.org/docs/reference/api/pandas.Index.rename.html, pandas.Index pandas.Index.rename pandas.Index
">>> idx = pd.MultiIndex.from_product([['python', 'cobra'],
...                                   [2018, 2019]],
...                                   names=['kind', 'year'])
>>> idx
MultiIndex([('python', 2018),
            ('python', 2019),
            ( 'cobra', 2018),
            ( 'cobra', 2019)],
           names=['kind', 'year'])
>>> idx.rename(['species', 'year'])
MultiIndex([('python', 2018),
            ('python', 2019),
            ( 'cobra', 2018),
            ( 'cobra', 2019)],
           names=['species', 'year'])
>>> idx.rename('species')
Traceback (most recent call last):
TypeError: Must pass list-like as `names`.
",https://pandas.pydata.org/docs/reference/api/pandas.Index.rename.html, pandas.MultiIndex.from_product pandas.MultiIndex pandas.Index.rename
">>> rng = pd.date_range('1/1/2018 11:59:00', periods=3, freq='min')
>>> rng
DatetimeIndex(['2018-01-01 11:59:00', '2018-01-01 12:00:00',
               '2018-01-01 12:01:00'],
              dtype='datetime64[ns]', freq='min')
>>> rng.ceil('h')
DatetimeIndex(['2018-01-01 12:00:00', '2018-01-01 12:00:00',
               '2018-01-01 13:00:00'],
              dtype='datetime64[ns]', freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.ceil.html, pandas.date_range pandas.DatetimeIndex
">>> pd.Series(rng).dt.ceil(""h"")
0   2018-01-01 12:00:00
1   2018-01-01 12:00:00
2   2018-01-01 13:00:00
dtype: datetime64[ns]
",https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.ceil.html, pandas.Series
">>> rng_tz = pd.DatetimeIndex([""2021-10-31 01:30:00""], tz=""Europe/Amsterdam"")
",https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.ceil.html, pandas.DatetimeIndex
">>> rng_tz.ceil(""h"", ambiguous=False)
DatetimeIndex(['2021-10-31 02:00:00+01:00'],
              dtype='datetime64[ns, Europe/Amsterdam]', freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.ceil.html, pandas.DatetimeIndex.ceil pandas.DatetimeIndex
">>> rng_tz.ceil(""h"", ambiguous=True)
DatetimeIndex(['2021-10-31 02:00:00+02:00'],
              dtype='datetime64[ns, Europe/Amsterdam]', freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.ceil.html, pandas.DatetimeIndex.ceil pandas.DatetimeIndex
">>> tz_naive = pd.date_range('2018-03-01 09:00', periods=3)
>>> tz_naive
DatetimeIndex(['2018-03-01 09:00:00', '2018-03-02 09:00:00',
               '2018-03-03 09:00:00'],
              dtype='datetime64[ns]', freq='D')
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.tz_localize.html, pandas.date_range pandas.DatetimeIndex
">>> tz_aware = tz_naive.tz_localize(tz='US/Eastern')
>>> tz_aware
DatetimeIndex(['2018-03-01 09:00:00-05:00',
               '2018-03-02 09:00:00-05:00',
               '2018-03-03 09:00:00-05:00'],
              dtype='datetime64[ns, US/Eastern]', freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.tz_localize.html, pandas.DatetimeIndex
">>> tz_aware.tz_localize(None)
DatetimeIndex(['2018-03-01 09:00:00', '2018-03-02 09:00:00',
               '2018-03-03 09:00:00'],
              dtype='datetime64[ns]', freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.tz_localize.html, pandas.DatetimeIndex
">>> s = pd.to_datetime(pd.Series(['2018-10-28 01:30:00',
...                               '2018-10-28 02:00:00',
...                               '2018-10-28 02:30:00',
...                               '2018-10-28 02:00:00',
...                               '2018-10-28 02:30:00',
...                               '2018-10-28 03:00:00',
...                               '2018-10-28 03:30:00']))
>>> s.dt.tz_localize('CET', ambiguous='infer')
0   2018-10-28 01:30:00+02:00
1   2018-10-28 02:00:00+02:00
2   2018-10-28 02:30:00+02:00
3   2018-10-28 02:00:00+01:00
4   2018-10-28 02:30:00+01:00
5   2018-10-28 03:00:00+01:00
6   2018-10-28 03:30:00+01:00
dtype: datetime64[ns, CET]
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.tz_localize.html, pandas.to_datetime pandas.Series pandas.Series.dt.tz_localize
">>> s = pd.to_datetime(pd.Series(['2018-10-28 01:20:00',
...                               '2018-10-28 02:36:00',
...                               '2018-10-28 03:46:00']))
>>> s.dt.tz_localize('CET', ambiguous=np.array([True, True, False]))
0   2018-10-28 01:20:00+02:00
1   2018-10-28 02:36:00+02:00
2   2018-10-28 03:46:00+01:00
dtype: datetime64[ns, CET]
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.tz_localize.html, pandas.to_datetime pandas.Series pandas.Series.dt.tz_localize
">>> s = pd.to_datetime(pd.Series(['2015-03-29 02:30:00',
...                               '2015-03-29 03:30:00']))
>>> s.dt.tz_localize('Europe/Warsaw', nonexistent='shift_forward')
0   2015-03-29 03:00:00+02:00
1   2015-03-29 03:30:00+02:00
dtype: datetime64[ns, Europe/Warsaw]
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.tz_localize.html, pandas.to_datetime pandas.Series pandas.Series.dt.tz_localize
">>> s.dt.tz_localize('Europe/Warsaw', nonexistent='shift_backward')
0   2015-03-29 01:59:59.999999999+01:00
1   2015-03-29 03:30:00+02:00
dtype: datetime64[ns, Europe/Warsaw]
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.tz_localize.html, pandas.Series.dt.tz_localize
">>> s.dt.tz_localize('Europe/Warsaw', nonexistent=pd.Timedelta('1h'))
0   2015-03-29 03:30:00+02:00
1   2015-03-29 03:30:00+02:00
dtype: datetime64[ns, Europe/Warsaw]
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.tz_localize.html, pandas.Series.dt.tz_localize
">>> idx = pd.date_range('2018-02-27', periods=3)
>>> idx.to_pydatetime()
array([datetime.datetime(2018, 2, 27, 0, 0),
       datetime.datetime(2018, 2, 28, 0, 0),
       datetime.datetime(2018, 3, 1, 0, 0)], dtype=object)
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.to_pydatetime.html, pandas.date_range pandas.array
">>> idx = pd.Index([1, 2, 3])
>>> idx.append(pd.Index([4]))
Index([1, 2, 3, 4], dtype='int64')
",https://pandas.pydata.org/docs/reference/api/pandas.Index.append.html, pandas.Index pandas.Index.append pandas.Index
">>> df = pd.DataFrame({'dates': pd.date_range(""2017-03-30"",
...                    periods=4)})
>>> df.assign(quarter=df.dates.dt.quarter,
...           is_quarter_end=df.dates.dt.is_quarter_end)
       dates  quarter    is_quarter_end
0 2017-03-30        1             False
1 2017-03-31        1              True
2 2017-04-01        2             False
3 2017-04-02        2             False
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.is_quarter_end.html, pandas.DataFrame pandas.date_range pandas.DataFrame.assign
">>> idx = pd.date_range('2017-03-30', periods=4)
>>> idx
DatetimeIndex(['2017-03-30', '2017-03-31', '2017-04-01', '2017-04-02'],
              dtype='datetime64[ns]', freq='D')
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.is_quarter_end.html, pandas.date_range pandas.DatetimeIndex
">>> idx.is_quarter_end
array([False,  True, False, False])
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.is_quarter_end.html, pandas.array
">>> idx = pd.Index([1, 2, 3], name='x')
>>> idx
Index([1, 2, 3], dtype='int64',  name='x')
>>> idx.name
'x'
",https://pandas.pydata.org/docs/reference/api/pandas.Index.name.html, pandas.Index pandas.Index
">>> mi = pd.MultiIndex.from_arrays([['a'], ['b'], ['c']])
>>> mi
MultiIndex([('a', 'b', 'c')],
           )
>>> mi.nlevels
3
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.nlevels.html, pandas.MultiIndex.from_arrays pandas.MultiIndex
">>> idx = pd.PeriodIndex([""2023-01"", ""2023-02"", ""2023-03""], freq=""M"")
>>> idx.quarter
Index([1, 1, 1], dtype='int64')
",https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.quarter.html, pandas.PeriodIndex pandas.Index
">>> mi = pd.MultiIndex.from_arrays([list('abb'), list('def')])
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.get_loc.html, pandas.MultiIndex.from_arrays
">>> mi.get_loc('b')
slice(1, 3, None)
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.get_loc.html, pandas.Series.str.slice
">>> pd.Index([3, 2, 1]).is_monotonic_decreasing
True
>>> pd.Index([3, 2, 2]).is_monotonic_decreasing
True
>>> pd.Index([3, 1, 2]).is_monotonic_decreasing
False
",https://pandas.pydata.org/docs/reference/api/pandas.Index.is_monotonic_decreasing.html, pandas.Index
">>> idx = pd.Index([10, 100, 1, 1000])
>>> idx
Index([10, 100, 1, 1000], dtype='int64')
",https://pandas.pydata.org/docs/reference/api/pandas.Index.sort_values.html, pandas.Index pandas.Index
">>> idx.sort_values()
Index([1, 10, 100, 1000], dtype='int64')
",https://pandas.pydata.org/docs/reference/api/pandas.Index.sort_values.html, pandas.Index.sort_values pandas.Index
">>> idx.sort_values(ascending=False, return_indexer=True)
(Index([1000, 100, 10, 1], dtype='int64'), array([3, 1, 0, 2]))
",https://pandas.pydata.org/docs/reference/api/pandas.Index.sort_values.html, pandas.Index.sort_values pandas.Index pandas.array
">>> s = pd.Series([""1/1/2020 10:00:00+00:00"", ""4/1/2020 11:00:00+00:00""])
>>> s = pd.to_datetime(s)
>>> s
0   2020-01-01 10:00:00+00:00
1   2020-04-01 11:00:00+00:00
dtype: datetime64[ns, UTC]
>>> s.dt.quarter
0    1
1    2
dtype: int32
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.quarter.html, pandas.Series pandas.to_datetime
">>> idx = pd.DatetimeIndex([""1/1/2020 10:00:00+00:00"",
...                         ""2/1/2020 11:00:00+00:00""])
>>> idx.quarter
Index([1, 1], dtype='int32')
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.quarter.html, pandas.DatetimeIndex pandas.Index
">>> mi = pd.MultiIndex.from_arrays([['a', 'b', 'c'], ['x', 'y', 'z']])
>>> mi
MultiIndex([('a', 'x'), ('b', 'y'), ('c', 'z')],
           )
>>> mi.truncate(before='a', after='b')
MultiIndex([('a', 'x'), ('b', 'y')],
           )
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.truncate.html, pandas.MultiIndex.from_arrays pandas.MultiIndex
">>> idx = pd.Index([pd.Interval(left=0, right=5),
...                 pd.Interval(left=5, right=10)])
>>> idx.is_interval()  
True
",https://pandas.pydata.org/docs/reference/api/pandas.Index.is_interval.html, pandas.Index pandas.Interval
">>> idx = pd.Index([1, 3, 5, 7])
>>> idx.is_interval()  
False
",https://pandas.pydata.org/docs/reference/api/pandas.Index.is_interval.html, pandas.Index
">>> s = pd.Series([1, 2, 3], index=['a', 'b', None])
>>> s
a    1
b    2
None 3
dtype: int64
>>> s.index.hasnans
True
",https://pandas.pydata.org/docs/reference/api/pandas.Index.hasnans.html, pandas.Series
">>> idx = pd.RangeIndex(5)
>>> idx.start
0
",https://pandas.pydata.org/docs/reference/api/pandas.RangeIndex.start.html, pandas.RangeIndex
">>> idx = pd.RangeIndex(2, -10, -3)
>>> idx.start
2
",https://pandas.pydata.org/docs/reference/api/pandas.RangeIndex.start.html, pandas.RangeIndex
">>> pd.IntervalIndex.from_arrays([0, 1, 2], [1, 2, 3])
IntervalIndex([(0, 1], (1, 2], (2, 3]],
              dtype='interval[int64, right]')
",https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.from_arrays.html, pandas.IntervalIndex.from_arrays pandas.IntervalIndex
">>> c = pd.Categorical(['c', 'b', 'c'])
>>> c
['c', 'b', 'c']
Categories (2, object): ['b', 'c']
",https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.add_categories.html, pandas.Categorical
">>> idx = pd.PeriodIndex([""2023"", ""2024"", ""2025""], freq=""Y"")
>>> idx.is_leap_year
array([False,  True, False])
",https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.is_leap_year.html, pandas.PeriodIndex pandas.array
">>> idx = pd.DatetimeIndex([""2018-01-01"", ""2018-01-03"", ""2018-01-05""])
>>> idx.inferred_freq
'2D'
",https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.inferred_freq.html, pandas.DatetimeIndex
">>> tdelta_idx = pd.to_timedelta([""0 days"", ""10 days"", ""20 days""])
>>> tdelta_idx
TimedeltaIndex(['0 days', '10 days', '20 days'],
               dtype='timedelta64[ns]', freq=None)
>>> tdelta_idx.inferred_freq
'10D'
",https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.inferred_freq.html, pandas.to_timedelta pandas.TimedeltaIndex
">>> idx = pd.DatetimeIndex([""1/1/2020 10:00"", ""2/1/2020 11:00"",
...                         ""3/1/2020 10:00""])
>>> idx.indexer_at_time(""10:00"")
array([0, 2])
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.indexer_at_time.html, pandas.DatetimeIndex pandas.DatetimeIndex.indexer_at_time pandas.array
">>> dti = pd.date_range(start='2014-08-01 09:00',
...                     freq='h', periods=3, tz='Europe/Berlin')
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.tz_convert.html, pandas.date_range
">>> dti
DatetimeIndex(['2014-08-01 09:00:00+02:00',
               '2014-08-01 10:00:00+02:00',
               '2014-08-01 11:00:00+02:00'],
              dtype='datetime64[ns, Europe/Berlin]', freq='h')
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.tz_convert.html, pandas.DatetimeIndex
">>> dti.tz_convert('US/Central')
DatetimeIndex(['2014-08-01 02:00:00-05:00',
               '2014-08-01 03:00:00-05:00',
               '2014-08-01 04:00:00-05:00'],
              dtype='datetime64[ns, US/Central]', freq='h')
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.tz_convert.html, pandas.DatetimeIndex
">>> dti = pd.date_range(start='2014-08-01 09:00', freq='h',
...                     periods=3, tz='Europe/Berlin')
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.tz_convert.html, pandas.date_range
">>> dti
DatetimeIndex(['2014-08-01 09:00:00+02:00',
               '2014-08-01 10:00:00+02:00',
               '2014-08-01 11:00:00+02:00'],
                dtype='datetime64[ns, Europe/Berlin]', freq='h')
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.tz_convert.html, pandas.DatetimeIndex
">>> dti.tz_convert(None)
DatetimeIndex(['2014-08-01 07:00:00',
               '2014-08-01 08:00:00',
               '2014-08-01 09:00:00'],
                dtype='datetime64[ns]', freq='h')
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.tz_convert.html, pandas.DatetimeIndex
">>> s = pd.Series({'Corn Flakes': 100.0, 'Almond Delight': 110.0,
...                'Cinnamon Toast Crunch': 120.0, 'Cocoa Puff': 110.0})
>>> s
Corn Flakes              100.0
Almond Delight           110.0
Cinnamon Toast Crunch    120.0
Cocoa Puff               110.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Index.argmin.html, pandas.Series
">>> s.argmax()
2
>>> s.argmin()
0
",https://pandas.pydata.org/docs/reference/api/pandas.Index.argmin.html, pandas.Series.argmax pandas.Series.argmin
">>> idx = pd.Index([1, 5, 7, 7])
>>> idx.has_duplicates
True
",https://pandas.pydata.org/docs/reference/api/pandas.Index.has_duplicates.html, pandas.Index
">>> idx = pd.Index([1, 5, 7])
>>> idx.has_duplicates
False
",https://pandas.pydata.org/docs/reference/api/pandas.Index.has_duplicates.html, pandas.Index
">>> idx = pd.Index([""Watermelon"", ""Orange"", ""Apple"",
...                 ""Watermelon""]).astype(""category"")
>>> idx.has_duplicates
True
",https://pandas.pydata.org/docs/reference/api/pandas.Index.has_duplicates.html, pandas.Index
">>> idx = pd.Index([""Orange"", ""Apple"",
...                 ""Watermelon""]).astype(""category"")
>>> idx.has_duplicates
False
",https://pandas.pydata.org/docs/reference/api/pandas.Index.has_duplicates.html, pandas.Index
">>> ser = pd.Series(['a', 'b', 'c', 'a'], dtype='category')
>>> ser = ser.cat.reorder_categories(['c', 'b', 'a'], ordered=True)
>>> ser
0   a
1   b
2   c
3   a
dtype: category
Categories (3, object): ['c' < 'b' < 'a']
",https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.reorder_categories.html, pandas.Series pandas.Series.cat.reorder_categories
">>> ser.sort_values()
2   c
1   b
0   a
3   a
dtype: category
Categories (3, object): ['c' < 'b' < 'a']
",https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.reorder_categories.html, pandas.Series.sort_values
">>> ci = pd.CategoricalIndex(['a', 'b', 'c', 'a'])
>>> ci
CategoricalIndex(['a', 'b', 'c', 'a'], categories=['a', 'b', 'c'],
                 ordered=False, dtype='category')
>>> ci.reorder_categories(['c', 'b', 'a'], ordered=True)
CategoricalIndex(['a', 'b', 'c', 'a'], categories=['c', 'b', 'a'],
                 ordered=True, dtype='category')
",https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.reorder_categories.html, pandas.CategoricalIndex pandas.CategoricalIndex pandas.CategoricalIndex.reorder_categories
">>> mi = pd.MultiIndex.from_arrays(
... [[1, 2], [3, 4], [5, 6]], names=['x', 'y', 'z'])
>>> mi
MultiIndex([(1, 3, 5),
            (2, 4, 6)],
           names=['x', 'y', 'z'])
>>> mi.names
FrozenList(['x', 'y', 'z'])
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.names.html, pandas.MultiIndex.from_arrays pandas.MultiIndex
">>> mi = pd.MultiIndex.from_arrays([['a'], ['b'], ['c']])
>>> mi
MultiIndex([('a', 'b', 'c')],
           )
>>> mi.copy()
MultiIndex([('a', 'b', 'c')],
           )
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.copy.html, pandas.MultiIndex.from_arrays pandas.MultiIndex
">>> raw_cat = pd.Categorical(['a', 'b', 'c', 'A'],
...                           categories=['a', 'b', 'c'], ordered=True)
>>> ser = pd.Series(raw_cat)
>>> ser
0   a
1   b
2   c
3   NaN
dtype: category
Categories (3, object): ['a' < 'b' < 'c']
",https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.set_categories.html, pandas.Categorical pandas.Series
">>> ser.cat.set_categories(['A', 'B', 'C'], rename=True)
0   A
1   B
2   C
3   NaN
dtype: category
Categories (3, object): ['A' < 'B' < 'C']
",https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.set_categories.html, pandas.Series.cat.set_categories
">>> ci = pd.CategoricalIndex(['a', 'b', 'c', 'A'],
...                          categories=['a', 'b', 'c'], ordered=True)
>>> ci
CategoricalIndex(['a', 'b', 'c', nan], categories=['a', 'b', 'c'],
                 ordered=True, dtype='category')
",https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.set_categories.html, pandas.CategoricalIndex pandas.CategoricalIndex
">>> ci.set_categories(['A', 'b', 'c'])
CategoricalIndex([nan, 'b', 'c', nan], categories=['A', 'b', 'c'],
                 ordered=True, dtype='category')
>>> ci.set_categories(['A', 'b', 'c'], rename=True)
CategoricalIndex(['A', 'b', 'c', nan], categories=['A', 'b', 'c'],
                 ordered=True, dtype='category')
",https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.set_categories.html, pandas.CategoricalIndex.set_categories pandas.CategoricalIndex
">>> idx = pd.Index(list('abc'))
>>> idx
Index(['a', 'b', 'c'], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.Index.get_level_values.html, pandas.Index pandas.Index
">>> idx.get_level_values(0)
Index(['a', 'b', 'c'], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.Index.get_level_values.html, pandas.Index.get_level_values pandas.Index
">>> pd.RangeIndex.from_range(range(5))
RangeIndex(start=0, stop=5, step=1)
",https://pandas.pydata.org/docs/reference/api/pandas.RangeIndex.from_range.html, pandas.RangeIndex.from_range pandas.RangeIndex
">>> pd.RangeIndex.from_range(range(2, -10, -3))
RangeIndex(start=2, stop=-10, step=-3)
",https://pandas.pydata.org/docs/reference/api/pandas.RangeIndex.from_range.html, pandas.RangeIndex.from_range pandas.RangeIndex
">>> pd.interval_range(start=0, end=5)
IntervalIndex([(0, 1], (1, 2], (2, 3], (3, 4], (4, 5]],
              dtype='interval[int64, right]')
",https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.html, pandas.interval_range pandas.IntervalIndex
">>> s = pd.date_range('2016-12-31', '2017-01-08', freq='D').to_series()
>>> s.dt.dayofweek
2016-12-31    5
2017-01-01    6
2017-01-02    0
2017-01-03    1
2017-01-04    2
2017-01-05    3
2017-01-06    4
2017-01-07    5
2017-01-08    6
Freq: D, dtype: int32
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.weekday.html, pandas.date_range
">>> idx = pd.DatetimeIndex(['2020-01-02 01:02:03.004005006'])
>>> idx
DatetimeIndex(['2020-01-02 01:02:03.004005006'],
              dtype='datetime64[ns]', freq=None)
>>> idx.as_unit('s')
DatetimeIndex(['2020-01-02 01:02:03'], dtype='datetime64[s]', freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.as_unit.html, pandas.DatetimeIndex pandas.DatetimeIndex pandas.DatetimeIndex.as_unit
">>> tdelta_idx = pd.to_timedelta(['1 day 3 min 2 us 42 ns'])
>>> tdelta_idx
TimedeltaIndex(['1 days 00:03:00.000002042'],
                dtype='timedelta64[ns]', freq=None)
>>> tdelta_idx.as_unit('s')
TimedeltaIndex(['1 days 00:03:00'], dtype='timedelta64[s]', freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.as_unit.html, pandas.to_timedelta pandas.TimedeltaIndex
">>> pd.Index([1, 2, 3]).is_monotonic_increasing
True
>>> pd.Index([1, 2, 2]).is_monotonic_increasing
True
>>> pd.Index([1, 3, 2]).is_monotonic_increasing
False
",https://pandas.pydata.org/docs/reference/api/pandas.Index.is_monotonic_increasing.html, pandas.Index
">>> idx = pd.RangeIndex(5)
>>> idx.get_slice_bound(3, 'left')
3
",https://pandas.pydata.org/docs/reference/api/pandas.Index.get_slice_bound.html, pandas.RangeIndex
">>> idx_duplicate = pd.Index(['a', 'b', 'a', 'c', 'd'])
>>> idx_duplicate.get_slice_bound('a', 'left')
Traceback (most recent call last):
KeyError: Cannot get left slice bound for non-unique label: 'a'
",https://pandas.pydata.org/docs/reference/api/pandas.Index.get_slice_bound.html, pandas.Index pandas.Index.get_slice_bound
">>> idx = pd.PeriodIndex.from_fields(year=[2000, 2002], quarter=[1, 3])
>>> idx
PeriodIndex(['2000Q1', '2002Q3'], dtype='period[Q-DEC]')
",https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.html, pandas.PeriodIndex.from_fields pandas.PeriodIndex
">>> rng = pd.date_range('1/1/2018 11:59:00', periods=3, freq='min')
>>> rng
DatetimeIndex(['2018-01-01 11:59:00', '2018-01-01 12:00:00',
               '2018-01-01 12:01:00'],
              dtype='datetime64[ns]', freq='min')
>>> rng.round('h')
DatetimeIndex(['2018-01-01 12:00:00', '2018-01-01 12:00:00',
               '2018-01-01 12:00:00'],
              dtype='datetime64[ns]', freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.round.html, pandas.date_range pandas.DatetimeIndex
">>> pd.Series(rng).dt.round(""h"")
0   2018-01-01 12:00:00
1   2018-01-01 12:00:00
2   2018-01-01 12:00:00
dtype: datetime64[ns]
",https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.round.html, pandas.Series
">>> rng_tz = pd.DatetimeIndex([""2021-10-31 03:30:00""], tz=""Europe/Amsterdam"")
",https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.round.html, pandas.DatetimeIndex
">>> rng_tz.floor(""2h"", ambiguous=False)
DatetimeIndex(['2021-10-31 02:00:00+01:00'],
              dtype='datetime64[ns, Europe/Amsterdam]', freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.round.html, pandas.DatetimeIndex.floor pandas.DatetimeIndex
">>> rng_tz.floor(""2h"", ambiguous=True)
DatetimeIndex(['2021-10-31 02:00:00+02:00'],
              dtype='datetime64[ns, Europe/Amsterdam]', freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.round.html, pandas.DatetimeIndex.floor pandas.DatetimeIndex
">>> idx = pd.date_range(start='2014-08-01 10:00', freq='h',
...                     periods=3, tz='Asia/Calcutta')
>>> idx
DatetimeIndex(['2014-08-01 10:00:00+05:30',
               '2014-08-01 11:00:00+05:30',
               '2014-08-01 12:00:00+05:30'],
                dtype='datetime64[ns, Asia/Calcutta]', freq='h')
>>> idx.normalize()
DatetimeIndex(['2014-08-01 00:00:00+05:30',
               '2014-08-01 00:00:00+05:30',
               '2014-08-01 00:00:00+05:30'],
               dtype='datetime64[ns, Asia/Calcutta]', freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.normalize.html, pandas.date_range pandas.DatetimeIndex
">>> datetime_series = pd.Series(
...     pd.date_range(""2000-01-01"", periods=3, freq=""ns"")
... )
>>> datetime_series
0   2000-01-01 00:00:00.000000000
1   2000-01-01 00:00:00.000000001
2   2000-01-01 00:00:00.000000002
dtype: datetime64[ns]
>>> datetime_series.dt.nanosecond
0       0
1       1
2       2
dtype: int32
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.nanosecond.html, pandas.Series pandas.date_range
">>> idx = pd.Index(['a', 'b', 'c'])
>>> idx.insert(1, 'x')
Index(['a', 'x', 'b', 'c'], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.Index.insert.html, pandas.Index pandas.Index.insert pandas.Index
">>> idx = pd.PeriodIndex([""2023-01"", ""2023-02"", ""2023-03""], freq=""M"")
>>> idx.week  # It can be written `weekofyear`
Index([5, 9, 13], dtype='int64')
",https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.week.html, pandas.PeriodIndex pandas.Index
">>> idx1 = pd.Index([1, 2, 3, 4])
>>> idx2 = pd.Index([3, 4, 5, 6])
>>> idx1.intersection(idx2)
Index([3, 4], dtype='int64')
",https://pandas.pydata.org/docs/reference/api/pandas.Index.intersection.html, pandas.Index pandas.Index
">>> idx = pd.Index(['Ant', 'Bear', 'Cow'], name='animal')
>>> idx.to_frame()
       animal
animal
Ant       Ant
Bear     Bear
Cow       Cow
",https://pandas.pydata.org/docs/reference/api/pandas.Index.to_frame.html, pandas.Index pandas.Index.to_frame
">>> idx.to_frame(index=False)
    animal
0   Ant
1  Bear
2   Cow
",https://pandas.pydata.org/docs/reference/api/pandas.Index.to_frame.html, pandas.Index.to_frame
">>> idx.to_frame(index=False, name='zoo')
    zoo
0   Ant
1  Bear
2   Cow
",https://pandas.pydata.org/docs/reference/api/pandas.Index.to_frame.html, pandas.Index.to_frame
">>> idx = pd.Index(['Ant', 'Bear', 'Cow'], name='animal')
>>> idx.to_frame()
       animal
animal
Ant       Ant
Bear     Bear
Cow       Cow
",https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.to_frame.html, pandas.Index pandas.Index.to_frame
">>> idx.to_frame(index=False)
    animal
0   Ant
1  Bear
2   Cow
",https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.to_frame.html, pandas.Index.to_frame
">>> idx.to_frame(index=False, name='zoo')
    zoo
0   Ant
1  Bear
2   Cow
",https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.to_frame.html, pandas.Index.to_frame
">>> idx1 = pd.Index([1, 2, 3])
>>> idx2 = pd.Index([5, 6, 7])
>>> idx1.putmask([True, False, False], idx2)
Index([5, 2, 3], dtype='int64')
",https://pandas.pydata.org/docs/reference/api/pandas.Index.putmask.html, pandas.Index pandas.Index.putmask pandas.Index
">>> idx = pd.Index([3, 2, 1])
>>> idx.max()
3
",https://pandas.pydata.org/docs/reference/api/pandas.Index.max.html, pandas.Index pandas.Index.max
">>> idx = pd.Index(['c', 'b', 'a'])
>>> idx.max()
'c'
",https://pandas.pydata.org/docs/reference/api/pandas.Index.max.html, pandas.Index pandas.Index.max
">>> idx = pd.MultiIndex.from_product([('a', 'b'), (2, 1)])
>>> idx.max()
('b', 2)
",https://pandas.pydata.org/docs/reference/api/pandas.Index.max.html, pandas.MultiIndex.from_product pandas.Index.max
">>> mi = pd.MultiIndex(levels=[['a', 'b'], ['bb', 'aa']],
...                    codes=[[0, 0, 1, 1], [0, 1, 0, 1]])
>>> mi
MultiIndex([('a', 'bb'),
            ('a', 'aa'),
            ('b', 'bb'),
            ('b', 'aa')],
           )
>>> mi.swaplevel(0, 1)
MultiIndex([('bb', 'a'),
            ('aa', 'a'),
            ('bb', 'b'),
            ('aa', 'b')],
           )
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.swaplevel.html, pandas.MultiIndex pandas.MultiIndex pandas.MultiIndex.swaplevel
">>> s = pd.Series([""1/1/2020 10:00:00+00:00"", ""2/1/2020 11:00:00+00:00""])
>>> s = pd.to_datetime(s)
>>> s
0   2020-01-01 10:00:00+00:00
1   2020-02-01 11:00:00+00:00
dtype: datetime64[ns, UTC]
>>> s.dt.tz
datetime.timezone.utc
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.tz.html, pandas.Series pandas.to_datetime
">>> idx = pd.DatetimeIndex([""1/1/2020 10:00:00+00:00"",
...                         ""2/1/2020 11:00:00+00:00""])
>>> idx.tz
datetime.timezone.utc
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.tz.html, pandas.DatetimeIndex
">>> idx = pd.PeriodIndex([""2023-01-01"", ""2023-01-02"", ""2023-01-03""], freq=""D"")
>>> idx.weekday
Index([6, 0, 1], dtype='int64')
",https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.dayofweek.html, pandas.PeriodIndex pandas.Index
">>> idx = pd.arrays.IntervalArray.from_tuples([(0, 1), (1, 2)])
>>> idx

[(0, 1], (1, 2]]
Length: 2, dtype: interval[int64, right]
>>> idx.to_tuples()
array([(0, 1), (1, 2)], dtype=object)
",https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.to_tuples.html, pandas.array
">>> idx = pd.interval_range(start=0, end=2)
>>> idx
IntervalIndex([(0, 1], (1, 2]], dtype='interval[int64, right]')
>>> idx.to_tuples()
Index([(0, 1), (1, 2)], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.to_tuples.html, pandas.interval_range pandas.IntervalIndex pandas.Index
">>> index = pd.Index(['c', 'a', 'b'])
>>> index.get_indexer(['a', 'b', 'x'])
array([ 1,  2, -1])
",https://pandas.pydata.org/docs/reference/api/pandas.Index.get_indexer.html, pandas.Index pandas.array
">>> rng = pd.date_range('1/1/2018 11:59:00', periods=3, freq='min')
>>> rng
DatetimeIndex(['2018-01-01 11:59:00', '2018-01-01 12:00:00',
               '2018-01-01 12:01:00'],
              dtype='datetime64[ns]', freq='min')
>>> rng.round('h')
DatetimeIndex(['2018-01-01 12:00:00', '2018-01-01 12:00:00',
               '2018-01-01 12:00:00'],
              dtype='datetime64[ns]', freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.round.html, pandas.date_range pandas.DatetimeIndex
">>> pd.Series(rng).dt.round(""h"")
0   2018-01-01 12:00:00
1   2018-01-01 12:00:00
2   2018-01-01 12:00:00
dtype: datetime64[ns]
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.round.html, pandas.Series
">>> rng_tz = pd.DatetimeIndex([""2021-10-31 03:30:00""], tz=""Europe/Amsterdam"")
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.round.html, pandas.DatetimeIndex
">>> rng_tz.floor(""2h"", ambiguous=False)
DatetimeIndex(['2021-10-31 02:00:00+01:00'],
              dtype='datetime64[ns, Europe/Amsterdam]', freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.round.html, pandas.DatetimeIndex.floor pandas.DatetimeIndex
">>> rng_tz.floor(""2h"", ambiguous=True)
DatetimeIndex(['2021-10-31 02:00:00+02:00'],
              dtype='datetime64[ns, Europe/Amsterdam]', freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.round.html, pandas.DatetimeIndex.floor pandas.DatetimeIndex
">>> datetime_series = pd.Series(
...     pd.date_range(""2000-01-01"", periods=3, freq=""YE"")
... )
>>> datetime_series
0   2000-12-31
1   2001-12-31
2   2002-12-31
dtype: datetime64[ns]
>>> datetime_series.dt.year
0    2000
1    2001
2    2002
dtype: int32
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.year.html, pandas.Series pandas.date_range
">>> idx = pd.Index([1, 2, 3])
>>> idx
Index([1, 2, 3], dtype='int64')
>>> idx.inferred_type
'integer'
",https://pandas.pydata.org/docs/reference/api/pandas.Index.inferred_type.html, pandas.Index pandas.Index
">>> ser = pd.Series(['a', 'b', 'c', 'a'], dtype='category')
>>> ser.cat.ordered
False
",https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.ordered.html, pandas.Series
">>> raw_cat = pd.Categorical(['a', 'b', 'c', 'a'], ordered=True)
>>> ser = pd.Series(raw_cat)
>>> ser.cat.ordered
True
",https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.ordered.html, pandas.Categorical pandas.Series
">>> cat = pd.Categorical(['a', 'b'], ordered=True)
>>> cat.ordered
True
",https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.ordered.html, pandas.Categorical
">>> cat = pd.Categorical(['a', 'b'], ordered=False)
>>> cat.ordered
False
",https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.ordered.html, pandas.Categorical
">>> ci = pd.CategoricalIndex(['a', 'b'], ordered=True)
>>> ci.ordered
True
",https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.ordered.html, pandas.CategoricalIndex
">>> ci = pd.CategoricalIndex(['a', 'b'], ordered=False)
>>> ci.ordered
False
",https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.ordered.html, pandas.CategoricalIndex
">>> idx = pd.Index([np.nan, np.nan, 3])
>>> idx.fillna(0)
Index([0.0, 0.0, 3.0], dtype='float64')
",https://pandas.pydata.org/docs/reference/api/pandas.Index.fillna.html, pandas.Index pandas.Index.fillna pandas.Index
">>> idx = pd.Index(['a', 'b', 'c'])
>>> idx.drop(['a'])
Index(['b', 'c'], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.Index.drop.html, pandas.Index pandas.Index.drop pandas.Index
">>> cat = pd.Categorical(['a', 'b'], ordered=True)
>>> cat.codes
array([0, 1], dtype=int8)
",https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.codes.html, pandas.Categorical pandas.array
">>> ci = pd.CategoricalIndex(['a', 'b', 'c', 'a', 'b', 'c'])
>>> ci.codes
array([0, 1, 2, 0, 1, 2], dtype=int8)
",https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.codes.html, pandas.CategoricalIndex pandas.array
">>> ci = pd.CategoricalIndex(['a', 'c'], categories=['c', 'b', 'a'])
>>> ci.codes
array([2, 0], dtype=int8)
",https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.codes.html, pandas.CategoricalIndex pandas.array
">>> ser = pd.Series(pd.to_timedelta([1, 2, 3], unit='us'))
>>> ser
0   0 days 00:00:00.000001
1   0 days 00:00:00.000002
2   0 days 00:00:00.000003
dtype: timedelta64[ns]
>>> ser.dt.microseconds
0    1
1    2
2    3
dtype: int32
",https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.microseconds.html, pandas.Series pandas.to_timedelta
">>> tdelta_idx = pd.to_timedelta([1, 2, 3], unit='us')
>>> tdelta_idx
TimedeltaIndex(['0 days 00:00:00.000001', '0 days 00:00:00.000002',
                '0 days 00:00:00.000003'],
               dtype='timedelta64[ns]', freq=None)
>>> tdelta_idx.microseconds
Index([1, 2, 3], dtype='int32')
",https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.microseconds.html, pandas.to_timedelta pandas.TimedeltaIndex pandas.Index
">>> datetime_series = pd.Series(
...     pd.date_range(""2000-01-01"", periods=3, freq=""D"")
... )
>>> datetime_series
0   2000-01-01
1   2000-01-02
2   2000-01-03
dtype: datetime64[ns]
>>> datetime_series.dt.day
0    1
1    2
2    3
dtype: int32
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.day.html, pandas.Series pandas.date_range
">>> idx = pd.MultiIndex.from_product([(0, 1, 2), ('green', 'purple')],
...                                  names=[""number"", ""color""])
>>> idx
MultiIndex([(0,  'green'),
            (0, 'purple'),
            (1,  'green'),
            (1, 'purple'),
            (2,  'green'),
            (2, 'purple')],
           names=['number', 'color'])
>>> idx.drop([(1, 'green'), (2, 'purple')])
MultiIndex([(0,  'green'),
            (0, 'purple'),
            (1, 'purple'),
            (2,  'green')],
           names=['number', 'color'])
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.drop.html, pandas.MultiIndex.from_product pandas.MultiIndex pandas.Index.drop
">>> idx.drop('green', level='color')
MultiIndex([(0, 'purple'),
            (1, 'purple'),
            (2, 'purple')],
           names=['number', 'color'])
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.drop.html, pandas.Index.drop pandas.MultiIndex
">>> idx.drop([1, 2], level=0)
MultiIndex([(0,  'green'),
            (0, 'purple')],
           names=['number', 'color'])
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.drop.html, pandas.Index.drop pandas.MultiIndex
">>> idx = pd.Index(['lama', 'cow', 'lama', 'beetle', 'lama'])
>>> idx.duplicated()
array([False, False,  True, False,  True])
",https://pandas.pydata.org/docs/reference/api/pandas.Index.duplicated.html, pandas.Index pandas.Index.duplicated pandas.array
">>> idx.duplicated(keep='first')
array([False, False,  True, False,  True])
",https://pandas.pydata.org/docs/reference/api/pandas.Index.duplicated.html, pandas.Index.duplicated pandas.array
">>> idx.duplicated(keep='last')
array([ True, False,  True, False, False])
",https://pandas.pydata.org/docs/reference/api/pandas.Index.duplicated.html, pandas.Index.duplicated pandas.array
">>> idx.duplicated(keep=False)
array([ True, False,  True, False,  True])
",https://pandas.pydata.org/docs/reference/api/pandas.Index.duplicated.html, pandas.Index.duplicated pandas.array
">>> idx = pd.Index([1, 2, 3, 4])
>>> idx.is_integer()  
True
",https://pandas.pydata.org/docs/reference/api/pandas.Index.is_integer.html, pandas.Index
">>> idx = pd.Index([1.0, 2.0, 3.0, 4.0])
>>> idx.is_integer()  
False
",https://pandas.pydata.org/docs/reference/api/pandas.Index.is_integer.html, pandas.Index
">>> idx = pd.Index([""Apple"", ""Mango"", ""Watermelon""])
>>> idx.is_integer()  
False
",https://pandas.pydata.org/docs/reference/api/pandas.Index.is_integer.html, pandas.Index
">>> intervals.contains(0.5)
array([ True, False, False])
",https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.contains.html, pandas.array
">>> pd.Period('2020-01', 'D').end_time
Timestamp('2020-01-01 23:59:59.999999999')
",https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.end_time.html, pandas.Period
">>> period_index = pd.period_range('2020-1-1 00:00', '2020-3-1 00:00', freq='M')
>>> s = pd.Series(period_index)
>>> s
0   2020-01
1   2020-02
2   2020-03
dtype: period[M]
>>> s.dt.end_time
0   2020-01-31 23:59:59.999999999
1   2020-02-29 23:59:59.999999999
2   2020-03-31 23:59:59.999999999
dtype: datetime64[ns]
",https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.end_time.html, pandas.period_range pandas.Series
">>> idx = pd.PeriodIndex([""2023-01"", ""2023-02"", ""2023-03""], freq=""M"")
>>> idx.end_time
DatetimeIndex(['2023-01-31 23:59:59.999999999',
               '2023-02-28 23:59:59.999999999',
               '2023-03-31 23:59:59.999999999'],
               dtype='datetime64[ns]', freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.end_time.html, pandas.PeriodIndex pandas.DatetimeIndex
">>> idx = pd.Index([1, 1, 2, 3, 3])
>>> idx.unique()
Index([1, 2, 3], dtype='int64')
",https://pandas.pydata.org/docs/reference/api/pandas.Index.unique.html, pandas.Index pandas.Index.unique pandas.Index
">>> idx = pd.Index(['lama', 'cow', 'lama', 'beetle', 'lama', 'hippo'])
",https://pandas.pydata.org/docs/reference/api/pandas.Index.drop_duplicates.html, pandas.Index
">>> idx.drop_duplicates(keep='first')
Index(['lama', 'cow', 'beetle', 'hippo'], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.Index.drop_duplicates.html, pandas.Index.drop_duplicates pandas.Index
">>> idx.drop_duplicates(keep='last')
Index(['cow', 'beetle', 'lama', 'hippo'], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.Index.drop_duplicates.html, pandas.Index.drop_duplicates pandas.Index
">>> idx.drop_duplicates(keep=False)
Index(['cow', 'beetle', 'hippo'], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.Index.drop_duplicates.html, pandas.Index.drop_duplicates pandas.Index
">>> df = pd.DataFrame({""y"": [1, 2, 3]},
...                   index=pd.to_datetime([""2000-03-31 00:00:00"",
...                                         ""2000-05-31 00:00:00"",
...                                         ""2000-08-31 00:00:00""]))
>>> df.index.to_period(""M"")
PeriodIndex(['2000-03', '2000-05', '2000-08'],
            dtype='period[M]')
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.to_period.html, pandas.DataFrame pandas.to_datetime pandas.PeriodIndex
">>> idx = pd.date_range(""2017-01-01"", periods=2)
>>> idx.to_period()
PeriodIndex(['2017-01-01', '2017-01-02'],
            dtype='period[D]')
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.to_period.html, pandas.date_range pandas.PeriodIndex
">>> idx = pd.Index([1, 2, 3, 4])
>>> idx
Index([1, 2, 3, 4], dtype='int64')
>>> idx.set_names('quarter')
Index([1, 2, 3, 4], dtype='int64', name='quarter')
",https://pandas.pydata.org/docs/reference/api/pandas.Index.set_names.html, pandas.Index pandas.Index pandas.Index.set_names
">>> idx = pd.MultiIndex.from_product([['python', 'cobra'],
...                                   [2018, 2019]])
>>> idx
MultiIndex([('python', 2018),
            ('python', 2019),
            ( 'cobra', 2018),
            ( 'cobra', 2019)],
           )
>>> idx = idx.set_names(['kind', 'year'])
>>> idx.set_names('species', level=0)
MultiIndex([('python', 2018),
            ('python', 2019),
            ( 'cobra', 2018),
            ( 'cobra', 2019)],
           names=['species', 'year'])
",https://pandas.pydata.org/docs/reference/api/pandas.Index.set_names.html, pandas.MultiIndex.from_product pandas.MultiIndex pandas.Index.set_names
">>> idx.set_names({'kind': 'snake'})
MultiIndex([('python', 2018),
            ('python', 2019),
            ( 'cobra', 2018),
            ( 'cobra', 2019)],
           names=['snake', 'year'])
",https://pandas.pydata.org/docs/reference/api/pandas.Index.set_names.html, pandas.Index.set_names pandas.MultiIndex
">>> s = pd.Series([""1/1/2020 10:00:00+00:00"", ""2/1/2020 11:00:00+00:00""])
>>> s = pd.to_datetime(s)
>>> s
0   2020-01-01 10:00:00+00:00
1   2020-02-01 11:00:00+00:00
dtype: datetime64[ns, UTC]
>>> s.dt.dayofyear
0    1
1   32
dtype: int32
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.day_of_year.html, pandas.Series pandas.to_datetime
">>> idx = pd.DatetimeIndex([""1/1/2020 10:00:00+00:00"",
...                         ""2/1/2020 11:00:00+00:00""])
>>> idx.dayofyear
Index([1, 32], dtype='int32')
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.day_of_year.html, pandas.DatetimeIndex pandas.Index
">>> datetime_series = pd.Series(
...     pd.date_range(""2000-01-01"", periods=3, freq=""ME"")
... )
>>> datetime_series
0   2000-01-31
1   2000-02-29
2   2000-03-31
dtype: datetime64[ns]
>>> datetime_series.dt.month
0    1
1    2
2    3
dtype: int32
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.month.html, pandas.Series pandas.date_range
">>> s = pd.Series(['Ant', 'Bear', 'Cow'])
>>> s
0     Ant
1    Bear
2     Cow
dtype: object
>>> s.size
3
",https://pandas.pydata.org/docs/reference/api/pandas.Index.size.html, pandas.Series
">>> idx = pd.Index([1, 2, 3])
>>> idx
Index([1, 2, 3], dtype='int64')
>>> idx.size
3
",https://pandas.pydata.org/docs/reference/api/pandas.Index.size.html, pandas.Index pandas.Index
">>> pd.Interval(0, 1, closed='right').is_empty
False
",https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.is_empty.html, pandas.Interval
">>> pd.Interval(0, 0, closed='right').is_empty
True
>>> pd.Interval(0, 0, closed='left').is_empty
True
>>> pd.Interval(0, 0, closed='neither').is_empty
True
",https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.is_empty.html, pandas.Interval
">>> pd.Interval(0, 0, closed='both').is_empty
False
",https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.is_empty.html, pandas.Interval
">>> ivs = [pd.Interval(0, 0, closed='neither'),
...        pd.Interval(1, 2, closed='neither')]
>>> pd.arrays.IntervalArray(ivs).is_empty
array([ True, False])
",https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.is_empty.html, pandas.Interval pandas.arrays.IntervalArray pandas.array
">>> ivs = [pd.Interval(0, 0, closed='neither'), np.nan]
>>> pd.IntervalIndex(ivs).is_empty
array([ True, False])
",https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.is_empty.html, pandas.Interval pandas.IntervalIndex pandas.array
">>> idx = pd.CategoricalIndex(['a', 'b', 'c'])
>>> idx
CategoricalIndex(['a', 'b', 'c'], categories=['a', 'b', 'c'],
                  ordered=False, dtype='category')
>>> idx.map(lambda x: x.upper())
CategoricalIndex(['A', 'B', 'C'], categories=['A', 'B', 'C'],
                 ordered=False, dtype='category')
>>> idx.map({'a': 'first', 'b': 'second', 'c': 'third'})
CategoricalIndex(['first', 'second', 'third'], categories=['first',
                 'second', 'third'], ordered=False, dtype='category')
",https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.map.html, pandas.CategoricalIndex pandas.CategoricalIndex pandas.CategoricalIndex.map
">>> idx = pd.CategoricalIndex(['a', 'b', 'c'], ordered=True)
>>> idx
CategoricalIndex(['a', 'b', 'c'], categories=['a', 'b', 'c'],
                 ordered=True, dtype='category')
>>> idx.map({'a': 3, 'b': 2, 'c': 1})
CategoricalIndex([3, 2, 1], categories=[3, 2, 1], ordered=True,
                 dtype='category')
",https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.map.html, pandas.CategoricalIndex pandas.CategoricalIndex pandas.CategoricalIndex.map
">>> idx.map({'a': 'first', 'b': 'second', 'c': 'first'})
Index(['first', 'second', 'first'], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.map.html, pandas.CategoricalIndex.map pandas.Index
">>> idx.map({'a': 'first', 'b': 'second'})
Index(['first', 'second', nan], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.map.html, pandas.CategoricalIndex.map pandas.Index
">>> idx = pd.PeriodIndex([""2023"", ""2024"", ""2025""], freq=""Y"")
>>> idx.year
Index([2023, 2024, 2025], dtype='int64')
",https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.year.html, pandas.PeriodIndex pandas.Index
">>> df = pd.DataFrame([['HI', 'Temp'], ['HI', 'Precip'],
...                    ['NJ', 'Temp'], ['NJ', 'Precip']],
...                   columns=['a', 'b'])
>>> df
      a       b
0    HI    Temp
1    HI  Precip
2    NJ    Temp
3    NJ  Precip
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.from_frame.html, pandas.DataFrame
">>> pd.MultiIndex.from_frame(df)
MultiIndex([('HI',   'Temp'),
            ('HI', 'Precip'),
            ('NJ',   'Temp'),
            ('NJ', 'Precip')],
           names=['a', 'b'])
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.from_frame.html, pandas.MultiIndex.from_frame pandas.MultiIndex
">>> pd.MultiIndex.from_frame(df, names=['state', 'observation'])
MultiIndex([('HI',   'Temp'),
            ('HI', 'Precip'),
            ('NJ',   'Temp'),
            ('NJ', 'Precip')],
           names=['state', 'observation'])
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.from_frame.html, pandas.MultiIndex.from_frame pandas.MultiIndex
">>> idx1 = pd.Index([1, 2, 3, 4])
>>> idx2 = pd.Index([2, 3, 4, 5])
>>> idx1.symmetric_difference(idx2)
Index([1, 5], dtype='int64')
",https://pandas.pydata.org/docs/reference/api/pandas.Index.symmetric_difference.html, pandas.Index pandas.Index.symmetric_difference pandas.Index
">>> idx = pd.PeriodIndex([""2023-01"", ""2023-02"", ""2023-03""], freq=""M"")
>>> idx.to_timestamp()
DatetimeIndex(['2023-01-01', '2023-02-01', '2023-03-01'],
dtype='datetime64[ns]', freq='MS')
",https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.to_timestamp.html, pandas.PeriodIndex pandas.PeriodIndex.to_timestamp pandas.DatetimeIndex
">>> s = pd.Series(pd.date_range(start='2018-01-01', freq='D', periods=3))
>>> s
0   2018-01-01
1   2018-01-02
2   2018-01-03
dtype: datetime64[ns]
>>> s.dt.day_name()
0       Monday
1      Tuesday
2    Wednesday
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.day_name.html, pandas.Series pandas.date_range pandas.Series.dt.day_name
">>> idx = pd.date_range(start='2018-01-01', freq='D', periods=3)
>>> idx
DatetimeIndex(['2018-01-01', '2018-01-02', '2018-01-03'],
              dtype='datetime64[ns]', freq='D')
>>> idx.day_name()
Index(['Monday', 'Tuesday', 'Wednesday'], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.day_name.html, pandas.date_range pandas.DatetimeIndex pandas.Index
">>> idx = pd.date_range(start='2018-01-01', freq='D', periods=3)
>>> idx
DatetimeIndex(['2018-01-01', '2018-01-02', '2018-01-03'],
              dtype='datetime64[ns]', freq='D')
>>> idx.day_name(locale='pt_BR.utf8') 
Index(['Segunda', 'Terça', 'Quarta'], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.day_name.html, pandas.date_range pandas.DatetimeIndex pandas.Index
">>> ser = pd.Series(['a', 'b', 'c', 'a'], dtype='category')
>>> ser.cat.ordered
False
>>> ser = ser.cat.as_ordered()
>>> ser.cat.ordered
True
",https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.as_ordered.html, pandas.Series pandas.Series.cat.as_ordered
">>> ci = pd.CategoricalIndex(['a', 'b', 'c', 'a'])
>>> ci.ordered
False
>>> ci = ci.as_ordered()
>>> ci.ordered
True
",https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.as_ordered.html, pandas.CategoricalIndex pandas.CategoricalIndex.as_ordered
">>> intervals.overlaps(pd.Interval(0.5, 1.5))
array([ True,  True, False])
",https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.overlaps.html, pandas.Interval pandas.array
">>> intervals.overlaps(pd.Interval(1, 3, closed='left'))
array([ True,  True, True])
",https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.overlaps.html, pandas.Interval pandas.array
">>> intervals.overlaps(pd.Interval(1, 2, closed='right'))
array([False,  True, False])
",https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.overlaps.html, pandas.Interval pandas.array
">>> mi = pd.MultiIndex.from_product([range(2), list('ab')])
>>> mi
MultiIndex([(0, 'a'),
            (0, 'b'),
            (1, 'a'),
            (1, 'b')],
           )
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.remove_unused_levels.html, pandas.MultiIndex.from_product pandas.MultiIndex
">>> mi[2:]
MultiIndex([(1, 'a'),
            (1, 'b')],
           )
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.remove_unused_levels.html, pandas.MultiIndex
">>> mi2 = mi[2:].remove_unused_levels()
>>> mi2.levels
FrozenList([[1], ['a', 'b']])
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.remove_unused_levels.html, pandas.MultiIndex.remove_unused_levels
">>> idx = pd.Index(['a', 'b', 'c'])
>>> idx
Index(['a', 'b', 'c'], dtype='object')
>>> idx.repeat(2)
Index(['a', 'a', 'b', 'b', 'c', 'c'], dtype='object')
>>> idx.repeat([1, 2, 3])
Index(['a', 'b', 'b', 'c', 'c', 'c'], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.Index.repeat.html, pandas.Index pandas.Index pandas.Index.repeat
">>> idx = pd.MultiIndex.from_product([(0, 1, 2), ('green', 'purple')],
...                                  names=['number', 'color'])
>>> idx
MultiIndex([(0,  'green'),
            (0, 'purple'),
            (1,  'green'),
            (1, 'purple'),
            (2,  'green'),
            (2, 'purple')],
           names=['number', 'color'])
>>> idx.dtypes
number     int64
color     object
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.dtypes.html, pandas.MultiIndex.from_product pandas.MultiIndex
">>> tdelta_idx = pd.to_timedelta(['1 day 3 min 2 us 42 ns'])
>>> tdelta_idx
TimedeltaIndex(['1 days 00:03:00.000002042'],
               dtype='timedelta64[ns]', freq=None)
>>> tdelta_idx.components
   days  hours  minutes  seconds  milliseconds  microseconds  nanoseconds
0     1      0        3        0             0             2           42
",https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.components.html, pandas.to_timedelta pandas.TimedeltaIndex
">>> c = pd.Categorical(['a', 'c', 'b', 'c', 'd'])
>>> c
['a', 'c', 'b', 'c', 'd']
Categories (4, object): ['a', 'b', 'c', 'd']
",https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.remove_unused_categories.html, pandas.Categorical
">>> month_starts = pd.date_range('1/1/2011', periods=5, freq='MS')
>>> month_starts
DatetimeIndex(['2011-01-01', '2011-02-01', '2011-03-01', '2011-04-01',
               '2011-05-01'],
              dtype='datetime64[ns]', freq='MS')
",https://pandas.pydata.org/docs/reference/api/pandas.Index.shift.html, pandas.date_range pandas.DatetimeIndex
">>> month_starts.shift(10, freq='D')
DatetimeIndex(['2011-01-11', '2011-02-11', '2011-03-11', '2011-04-11',
               '2011-05-11'],
              dtype='datetime64[ns]', freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.Index.shift.html, pandas.DatetimeIndex
">>> month_starts.shift(10)
DatetimeIndex(['2011-11-01', '2011-12-01', '2012-01-01', '2012-02-01',
               '2012-03-01'],
              dtype='datetime64[ns]', freq='MS')
",https://pandas.pydata.org/docs/reference/api/pandas.Index.shift.html, pandas.DatetimeIndex
">>> s = pd.Series([""1/1/2020 10:00:00+00:00"", ""2/1/2020 11:00:00+00:00""])
>>> s = pd.to_datetime(s)
>>> s
0   2020-01-01 10:00:00+00:00
1   2020-02-01 11:00:00+00:00
dtype: datetime64[ns, UTC]
>>> s.dt.time
0    10:00:00
1    11:00:00
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.time.html, pandas.Series pandas.to_datetime
">>> idx = pd.DatetimeIndex([""1/1/2020 10:00:00+00:00"",
...                         ""2/1/2020 11:00:00+00:00""])
>>> idx.time
array([datetime.time(10, 0), datetime.time(11, 0)], dtype=object)
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.time.html, pandas.DatetimeIndex pandas.array pandas.Timestamp.time
">>> idx = pd.PeriodIndex([""2023-01-01"", ""2023-01-02"", ""2023-01-03""], freq=""D"")
>>> idx.weekday
Index([6, 0, 1], dtype='int64')
",https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.weekday.html, pandas.PeriodIndex pandas.Index
">>> datetime_series = pd.Series(
...     pd.date_range(""2000-01-01"", periods=3, freq=""us"")
... )
>>> datetime_series
0   2000-01-01 00:00:00.000000
1   2000-01-01 00:00:00.000001
2   2000-01-01 00:00:00.000002
dtype: datetime64[ns]
>>> datetime_series.dt.microsecond
0       0
1       1
2       2
dtype: int32
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.microsecond.html, pandas.Series pandas.date_range
">>> tuples = [(1, 'red'), (1, 'blue'),
...           (2, 'red'), (2, 'blue')]
>>> pd.MultiIndex.from_tuples(tuples, names=('number', 'color'))
MultiIndex([(1,  'red'),
            (1, 'blue'),
            (2,  'red'),
            (2, 'blue')],
           names=['number', 'color'])
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.from_tuples.html, pandas.MultiIndex.from_tuples pandas.MultiIndex
">>> idx = pd.RangeIndex(5)
>>> idx.step
1
",https://pandas.pydata.org/docs/reference/api/pandas.RangeIndex.step.html, pandas.RangeIndex
">>> idx = pd.RangeIndex(2, -10, -3)
>>> idx.step
-3
",https://pandas.pydata.org/docs/reference/api/pandas.RangeIndex.step.html, pandas.RangeIndex
">>> idx = pd.RangeIndex(1, 0)
>>> idx.step
1
",https://pandas.pydata.org/docs/reference/api/pandas.RangeIndex.step.html, pandas.RangeIndex
">>> idx = pd.Index(['2013-12-31', '2014-01-02', '2014-01-03'])
>>> idx.asof('2014-01-01')
'2013-12-31'
",https://pandas.pydata.org/docs/reference/api/pandas.Index.asof.html, pandas.Index
">>> idx_not_sorted = pd.Index(['2013-12-31', '2015-01-02',
...                            '2014-01-03'])
>>> idx_not_sorted.asof('2013-12-31')
Traceback (most recent call last):
ValueError: index must be monotonic increasing or decreasing
",https://pandas.pydata.org/docs/reference/api/pandas.Index.asof.html, pandas.Index
">>> mi = pd.MultiIndex.from_arrays(
... [[1, 2], [3, 4], [5, 6]], names=['x', 'y', 'z'])
>>> mi
MultiIndex([(1, 3, 5),
            (2, 4, 6)],
           names=['x', 'y', 'z'])
",https://pandas.pydata.org/docs/reference/api/pandas.Index.droplevel.html, pandas.MultiIndex.from_arrays pandas.MultiIndex
">>> mi.droplevel()
MultiIndex([(3, 5),
            (4, 6)],
           names=['y', 'z'])
",https://pandas.pydata.org/docs/reference/api/pandas.Index.droplevel.html, pandas.MultiIndex.droplevel pandas.MultiIndex
">>> mi.droplevel(2)
MultiIndex([(1, 3),
            (2, 4)],
           names=['x', 'y'])
",https://pandas.pydata.org/docs/reference/api/pandas.Index.droplevel.html, pandas.MultiIndex.droplevel pandas.MultiIndex
">>> mi.droplevel('z')
MultiIndex([(1, 3),
            (2, 4)],
           names=['x', 'y'])
",https://pandas.pydata.org/docs/reference/api/pandas.Index.droplevel.html, pandas.MultiIndex.droplevel pandas.MultiIndex
">>> mi.droplevel(['x', 'y'])
Index([5, 6], dtype='int64', name='z')
",https://pandas.pydata.org/docs/reference/api/pandas.Index.droplevel.html, pandas.MultiIndex.droplevel pandas.Index
">>> idx = pd.date_range('2023-06-01', periods=3, freq='D')
>>> where = pd.DatetimeIndex(['2023-05-30 00:12:00', '2023-06-01 00:00:00',
...                           '2023-06-02 23:59:59'])
>>> mask = np.ones(3, dtype=bool)
>>> idx.asof_locs(where, mask)
array([-1,  0,  1])
",https://pandas.pydata.org/docs/reference/api/pandas.Index.asof_locs.html, pandas.date_range pandas.DatetimeIndex pandas.Index.asof_locs pandas.array
">>> mask[1] = False
>>> idx.asof_locs(where, mask)
array([-1,  0,  0])
",https://pandas.pydata.org/docs/reference/api/pandas.Index.asof_locs.html, pandas.Index.asof_locs pandas.array
">>> rng = pd.date_range('1/1/2018 11:59:00', periods=3, freq='min')
>>> rng
DatetimeIndex(['2018-01-01 11:59:00', '2018-01-01 12:00:00',
               '2018-01-01 12:01:00'],
              dtype='datetime64[ns]', freq='min')
>>> rng.floor('h')
DatetimeIndex(['2018-01-01 11:00:00', '2018-01-01 12:00:00',
               '2018-01-01 12:00:00'],
              dtype='datetime64[ns]', freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.floor.html, pandas.date_range pandas.DatetimeIndex
">>> pd.Series(rng).dt.floor(""h"")
0   2018-01-01 11:00:00
1   2018-01-01 12:00:00
2   2018-01-01 12:00:00
dtype: datetime64[ns]
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.floor.html, pandas.Series
">>> rng_tz = pd.DatetimeIndex([""2021-10-31 03:30:00""], tz=""Europe/Amsterdam"")
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.floor.html, pandas.DatetimeIndex
">>> rng_tz.floor(""2h"", ambiguous=False)
DatetimeIndex(['2021-10-31 02:00:00+01:00'],
             dtype='datetime64[ns, Europe/Amsterdam]', freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.floor.html, pandas.DatetimeIndex.floor pandas.DatetimeIndex
">>> rng_tz.floor(""2h"", ambiguous=True)
DatetimeIndex(['2021-10-31 02:00:00+02:00'],
              dtype='datetime64[ns, Europe/Amsterdam]', freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.floor.html, pandas.DatetimeIndex.floor pandas.DatetimeIndex
">>> s = pd.Series([""1/1/2020 10:00:00+00:00"", ""2/1/2020 11:00:00+00:00""])
>>> s = pd.to_datetime(s)
>>> s
0   2020-01-01 10:00:00+00:00
1   2020-02-01 11:00:00+00:00
dtype: datetime64[ns, UTC]
>>> s.dt.dayofyear
0    1
1   32
dtype: int32
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.dayofyear.html, pandas.Series pandas.to_datetime
">>> idx = pd.DatetimeIndex([""1/1/2020 10:00:00+00:00"",
...                         ""2/1/2020 11:00:00+00:00""])
>>> idx.dayofyear
Index([1, 32], dtype='int32')
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.dayofyear.html, pandas.DatetimeIndex pandas.Index
">>> idx = pd.date_range(""2023-01-01"", periods=4, freq=""h"")
>>> idx
DatetimeIndex(['2023-01-01 00:00:00', '2023-01-01 01:00:00',
                   '2023-01-01 02:00:00', '2023-01-01 03:00:00'],
                  dtype='datetime64[ns]', freq='h')
>>> idx.indexer_between_time(""00:00"", ""2:00"", include_end=False)
array([0, 1])
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.indexer_between_time.html, pandas.date_range pandas.DatetimeIndex pandas.DatetimeIndex.indexer_between_time pandas.array
">>> index = pd.Index(['c', 'b', 'a', 'b', 'b'])
>>> index.get_indexer_non_unique(['b', 'b'])
(array([1, 3, 4, 1, 3, 4]), array([], dtype=int64))
",https://pandas.pydata.org/docs/reference/api/pandas.Index.get_indexer_non_unique.html, pandas.Index pandas.Index.get_indexer_non_unique pandas.array
">>> index = pd.Index(['c', 'b', 'a', 'b', 'b'])
>>> index.get_indexer_non_unique(['q', 'r', 't'])
(array([-1, -1, -1]), array([0, 1, 2]))
",https://pandas.pydata.org/docs/reference/api/pandas.Index.get_indexer_non_unique.html, pandas.Index pandas.Index.get_indexer_non_unique pandas.array
">>> index = pd.Index(['c', 'b', 'a', 'b', 'b'])
>>> index.get_indexer_non_unique(['f', 'b', 's'])
(array([-1,  1,  3,  4, -1]), array([0, 2]))
",https://pandas.pydata.org/docs/reference/api/pandas.Index.get_indexer_non_unique.html, pandas.Index pandas.Index.get_indexer_non_unique pandas.array
">>> idx1 = pd.Index([1, 2, 3])
>>> idx2 = pd.Index([4, 5, 6])
>>> idx1.join(idx2, how='outer')
Index([1, 2, 3, 4, 5, 6], dtype='int64')
",https://pandas.pydata.org/docs/reference/api/pandas.Index.join.html, pandas.Index pandas.Index
">>> pd.IntervalIndex.from_tuples([(0, 1), (1, 2)])
IntervalIndex([(0, 1], (1, 2]],
               dtype='interval[int64, right]')
",https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.from_tuples.html, pandas.IntervalIndex.from_tuples pandas.IntervalIndex
">>> index = pd.MultiIndex.from_product([['mammal'],
...                                     ('goat', 'human', 'cat', 'dog')],
...                                    names=['Category', 'Animals'])
>>> leg_num = pd.DataFrame(data=(4, 2, 4, 4), index=index, columns=['Legs'])
>>> leg_num
                  Legs
Category Animals
mammal   goat        4
         human       2
         cat         4
         dog         4
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.levels.html, pandas.MultiIndex.from_product pandas.DataFrame
">>> pd.IntervalIndex.from_breaks([0, 1, 2, 3])
IntervalIndex([(0, 1], (1, 2], (2, 3]],
              dtype='interval[int64, right]')
",https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.from_breaks.html, pandas.IntervalIndex.from_breaks pandas.IntervalIndex
">>> idx = pd.Index(['b', 'a', 'd', 'c'])
>>> idx
Index(['b', 'a', 'd', 'c'], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.Index.argsort.html, pandas.Index pandas.Index
">>> order = idx.argsort()
>>> order
array([1, 0, 3, 2])
",https://pandas.pydata.org/docs/reference/api/pandas.Index.argsort.html, pandas.Index.argsort pandas.array
">>> idx[order]
Index(['a', 'b', 'c', 'd'], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.Index.argsort.html, pandas.Index
">>> idx = pd.Index([3, 2, 1])
>>> idx.min()
1
",https://pandas.pydata.org/docs/reference/api/pandas.Index.min.html, pandas.Index pandas.Index.min
">>> idx = pd.Index(['c', 'b', 'a'])
>>> idx.min()
'a'
",https://pandas.pydata.org/docs/reference/api/pandas.Index.min.html, pandas.Index pandas.Index.min
">>> idx = pd.MultiIndex.from_product([('a', 'b'), (2, 1)])
>>> idx.min()
('a', 1)
",https://pandas.pydata.org/docs/reference/api/pandas.Index.min.html, pandas.MultiIndex.from_product pandas.Index.min
">>> s = pd.Series(pd.date_range(""2018-02-27"", periods=3))
>>> s
0   2018-02-27
1   2018-02-28
2   2018-03-01
dtype: datetime64[ns]
>>> s.dt.is_month_start
0    False
1    False
2    True
dtype: bool
>>> s.dt.is_month_end
0    False
1    True
2    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.is_month_start.html, pandas.Series pandas.date_range
">>> idx = pd.date_range(""2018-02-27"", periods=3)
>>> idx.is_month_start
array([False, False, True])
>>> idx.is_month_end
array([False, True, False])
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.is_month_start.html, pandas.date_range pandas.array
">>> s = pd.Series([1, 3, 5, 7, 7])
>>> s
0    1
1    3
2    5
3    7
4    7
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Index.nunique.html, pandas.Series
">>> s.nunique()
4
",https://pandas.pydata.org/docs/reference/api/pandas.Index.nunique.html, pandas.Series.nunique
">>> ci = pd.CategoricalIndex(['a', 'b', 'c', 'a', 'b', 'c'])
>>> ci2 = pd.CategoricalIndex(pd.Categorical(['a', 'b', 'c', 'a', 'b', 'c']))
>>> ci.equals(ci2)
True
",https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.equals.html, pandas.CategoricalIndex pandas.Categorical pandas.CategoricalIndex.equals
">>> ci3 = pd.CategoricalIndex(['c', 'b', 'a', 'a', 'b', 'c'])
>>> ci.equals(ci3)
False
",https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.equals.html, pandas.CategoricalIndex pandas.CategoricalIndex.equals
">>> ci4 = ci.as_ordered()
>>> ci.equals(ci4)
False
",https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.equals.html, pandas.CategoricalIndex.as_ordered pandas.CategoricalIndex.equals
">>> ci5 = ci.set_categories(['a', 'b', 'c', 'd'])
>>> ci.equals(ci5)
False
",https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.equals.html, pandas.CategoricalIndex.set_categories pandas.CategoricalIndex.equals
">>> ci6 = ci.set_categories(['b', 'c', 'a'])
>>> ci.equals(ci6)
True
>>> ci_ordered = pd.CategoricalIndex(['a', 'b', 'c', 'a', 'b', 'c'],
...                                  ordered=True)
>>> ci2_ordered = ci_ordered.set_categories(['b', 'c', 'a'])
>>> ci_ordered.equals(ci2_ordered)
False
",https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.equals.html, pandas.CategoricalIndex.set_categories pandas.CategoricalIndex.equals pandas.CategoricalIndex pandas.CategoricalIndex.set_categories pandas.CategoricalIndex.equals
">>> midx = pd.MultiIndex.from_product([['A0','A1'], ['B0','B1','B2','B3']])
>>> columns = ['foo', 'bar']
>>> dfmi = pd.DataFrame(np.arange(16).reshape((len(midx), len(columns))),
...                     index=midx, columns=columns)
",https://pandas.pydata.org/docs/reference/api/pandas.IndexSlice.html, pandas.MultiIndex.from_product pandas.DataFrame
">>> dfmi.loc[(slice(None), slice('B0', 'B1')), :]
           foo  bar
    A0 B0    0    1
       B1    2    3
    A1 B0    8    9
       B1   10   11
",https://pandas.pydata.org/docs/reference/api/pandas.IndexSlice.html, pandas.Series.str.slice
">>> idx = pd.Index(list('abcd'))
>>> idx.slice_indexer(start='b', end='c')
slice(1, 3, None)
",https://pandas.pydata.org/docs/reference/api/pandas.Index.slice_indexer.html, pandas.Index pandas.Index.slice_indexer pandas.Series.str.slice
">>> idx = pd.MultiIndex.from_arrays([list('abcd'), list('efgh')])
>>> idx.slice_indexer(start='b', end=('c', 'g'))
slice(1, 3, None)
",https://pandas.pydata.org/docs/reference/api/pandas.Index.slice_indexer.html, pandas.MultiIndex.from_arrays pandas.Index.slice_indexer pandas.Series.str.slice
">>> index = pd.MultiIndex.from_product(
...     [['foo', 'bar'], ['baz', 'qux']],
...     names=['a', 'b'])
>>> index.to_flat_index()
Index([('foo', 'baz'), ('foo', 'qux'),
       ('bar', 'baz'), ('bar', 'qux')],
      dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.to_flat_index.html, pandas.MultiIndex.from_product pandas.Index
">>> unique_index = pd.Index(list('abc'))
>>> unique_index.get_loc('b')
1
",https://pandas.pydata.org/docs/reference/api/pandas.Index.get_loc.html, pandas.Index pandas.Index.get_loc
">>> monotonic_index = pd.Index(list('abbc'))
>>> monotonic_index.get_loc('b')
slice(1, 3, None)
",https://pandas.pydata.org/docs/reference/api/pandas.Index.get_loc.html, pandas.Index pandas.Index.get_loc pandas.Series.str.slice
">>> non_monotonic_index = pd.Index(list('abcb'))
>>> non_monotonic_index.get_loc('b')
array([False,  True, False,  True])
",https://pandas.pydata.org/docs/reference/api/pandas.Index.get_loc.html, pandas.Index pandas.Index.get_loc pandas.array
">>> tdelta_idx = pd.to_timedelta([1, 2, 3], unit='D')
>>> tdelta_idx
TimedeltaIndex(['1 days', '2 days', '3 days'],
                dtype='timedelta64[ns]', freq=None)
>>> tdelta_idx.to_pytimedelta()
array([datetime.timedelta(days=1), datetime.timedelta(days=2),
       datetime.timedelta(days=3)], dtype=object)
",https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.to_pytimedelta.html, pandas.to_timedelta pandas.TimedeltaIndex pandas.array
">>> list(pd.RangeIndex(5))
[0, 1, 2, 3, 4]
",https://pandas.pydata.org/docs/reference/api/pandas.RangeIndex.html, pandas.RangeIndex
">>> list(pd.RangeIndex(-2, 4))
[-2, -1, 0, 1, 2, 3]
",https://pandas.pydata.org/docs/reference/api/pandas.RangeIndex.html, pandas.RangeIndex
">>> list(pd.RangeIndex(0, 10, 2))
[0, 2, 4, 6, 8]
",https://pandas.pydata.org/docs/reference/api/pandas.RangeIndex.html, pandas.RangeIndex
">>> list(pd.RangeIndex(2, -10, -3))
[2, -1, -4, -7]
",https://pandas.pydata.org/docs/reference/api/pandas.RangeIndex.html, pandas.RangeIndex
">>> list(pd.RangeIndex(0))
[]
",https://pandas.pydata.org/docs/reference/api/pandas.RangeIndex.html, pandas.RangeIndex
">>> list(pd.RangeIndex(1, 0))
[]
",https://pandas.pydata.org/docs/reference/api/pandas.RangeIndex.html, pandas.RangeIndex
">>> s = pd.Series(['Ant', 'Bear', 'Cow'])
>>> s
0     Ant
1    Bear
2     Cow
dtype: object
>>> s.nbytes
24
",https://pandas.pydata.org/docs/reference/api/pandas.Index.nbytes.html, pandas.Series
">>> idx = pd.Index([1, 2, 3])
>>> idx
Index([1, 2, 3], dtype='int64')
>>> idx.nbytes
24
",https://pandas.pydata.org/docs/reference/api/pandas.Index.nbytes.html, pandas.Index pandas.Index
">>> mi = pd.MultiIndex.from_arrays([list('abb'), list('def')],
...                                names=['A', 'B'])
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.get_loc_level.html, pandas.MultiIndex.from_arrays
">>> mi.get_loc_level('b')
(slice(1, 3, None), Index(['e', 'f'], dtype='object', name='B'))
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.get_loc_level.html, pandas.MultiIndex.get_loc_level pandas.Series.str.slice pandas.Index
">>> mi.get_loc_level('e', level='B')
(array([False,  True, False]), Index(['b'], dtype='object', name='A'))
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.get_loc_level.html, pandas.MultiIndex.get_loc_level pandas.array pandas.Index
">>> mi.get_loc_level(['b', 'e'])
(1, None)
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.get_loc_level.html, pandas.MultiIndex.get_loc_level
">>> idx = pd.PeriodIndex([""2023-01"", ""2023-02"", ""2023-03""], freq=""M"")
>>> idx.month
Index([1, 2, 3], dtype='int64')
",https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.month.html, pandas.PeriodIndex pandas.Index
">>> idx = pd.PeriodIndex([""2023-01-01 10:00:30"",
...                       ""2023-01-01 10:00:31""], freq='s')
>>> idx.second
Index([30, 31], dtype='int64')
",https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.second.html, pandas.PeriodIndex pandas.Index
">>> idx = pd.Index([1, 2, 3])
>>> idx
Index([1, 2, 3], dtype='int64')
>>> idx.shape
(3,)
",https://pandas.pydata.org/docs/reference/api/pandas.Index.shape.html, pandas.Index pandas.Index
">>> s = pd.Series([1])
>>> s.item()
1
",https://pandas.pydata.org/docs/reference/api/pandas.Index.item.html, pandas.Series pandas.Series.item
">>> s = pd.Series([1], index=['a'])
>>> s.index.item()
'a'
",https://pandas.pydata.org/docs/reference/api/pandas.Index.item.html, pandas.Series
">>> idx = pd.Index([1, 2, 3])
>>> idx
Index([1, 2, 3], dtype='int64')
>>> idx.values
array([1, 2, 3])
",https://pandas.pydata.org/docs/reference/api/pandas.Index.values.html, pandas.Index pandas.Index pandas.array
">>> idx = pd.interval_range(start=0, end=5)
>>> idx.values

[(0, 1], (1, 2], (2, 3], (3, 4], (4, 5]]
Length: 5, dtype: interval[int64, right]
",https://pandas.pydata.org/docs/reference/api/pandas.Index.values.html, pandas.interval_range
">>> mi = pd.MultiIndex.from_arrays([['a'], ['b'], ['c']])
>>> mi
MultiIndex([('a', 'b', 'c')],
           )
>>> mi.levshape
(1, 1, 1)
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.levshape.html, pandas.MultiIndex.from_arrays pandas.MultiIndex
">>> index = pd.Index(['c', 'a', 'b'])
>>> index.get_indexer(['a', 'b', 'x'])
array([ 1,  2, -1])
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.get_indexer.html, pandas.Index pandas.array
">>> raw_cat = pd.Categorical(['a', 'b', 'c', 'a'], ordered=True)
>>> ser = pd.Series(raw_cat)
>>> ser.cat.ordered
True
>>> ser = ser.cat.as_unordered()
>>> ser.cat.ordered
False
",https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.as_unordered.html, pandas.Categorical pandas.Series pandas.Series.cat.as_unordered
">>> ci = pd.CategoricalIndex(['a', 'b', 'c', 'a'], ordered=True)
>>> ci.ordered
True
>>> ci = ci.as_unordered()
>>> ci.ordered
False
",https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.as_unordered.html, pandas.CategoricalIndex pandas.CategoricalIndex.as_unordered
">>> s = pd.date_range('2016-12-31', '2017-01-08', freq='D').to_series()
>>> s.dt.dayofweek
2016-12-31    5
2017-01-01    6
2017-01-02    0
2017-01-03    1
2017-01-04    2
2017-01-05    3
2017-01-06    4
2017-01-07    5
2017-01-08    6
Freq: D, dtype: int32
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.dayofweek.html, pandas.date_range
">>> idx = pd.date_range(""2012-01-01"", ""2015-01-01"", freq=""YE"")
>>> idx
DatetimeIndex(['2012-12-31', '2013-12-31', '2014-12-31'],
              dtype='datetime64[ns]', freq='YE-DEC')
>>> idx.is_leap_year
array([ True, False, False])
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.is_leap_year.html, pandas.date_range pandas.DatetimeIndex pandas.array
">>> dates_series = pd.Series(idx)
>>> dates_series
0   2012-12-31
1   2013-12-31
2   2014-12-31
dtype: datetime64[ns]
>>> dates_series.dt.is_leap_year
0     True
1    False
2    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.is_leap_year.html, pandas.Series
">>> period = pd.period_range('2020-1-1 00:00', '2020-3-1 00:00', freq='M')
>>> s = pd.Series(period)
>>> s
0   2020-01
1   2020-02
2   2020-03
dtype: period[M]
>>> s.dt.days_in_month
0    31
1    29
2    31
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.daysinmonth.html, pandas.period_range pandas.Series
">>> idx = pd.PeriodIndex([""2023-01"", ""2023-02"", ""2023-03""], freq=""M"")
>>> idx.days_in_month   # It can be also entered as `daysinmonth`
Index([31, 28, 31], dtype='int64')
",https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.daysinmonth.html, pandas.PeriodIndex pandas.Index
">>> mi = pd.MultiIndex.from_arrays([['a', 'b'], ['c', 'd']])
>>> mi
MultiIndex([('a', 'c'),
            ('b', 'd')],
           )
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.to_frame.html, pandas.MultiIndex.from_arrays pandas.MultiIndex
">>> df = mi.to_frame()
>>> df
     0  1
a c  a  c
b d  b  d
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.to_frame.html, pandas.MultiIndex.to_frame
">>> df = mi.to_frame(index=False)
>>> df
   0  1
0  a  c
1  b  d
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.to_frame.html, pandas.MultiIndex.to_frame
">>> df = mi.to_frame(name=['x', 'y'])
>>> df
     x  y
a c  a  c
b d  b  d
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.to_frame.html, pandas.MultiIndex.to_frame
">>> pd.Index([1, 2, 3]).all()
True
",https://pandas.pydata.org/docs/reference/api/pandas.Index.all.html, pandas.Index
">>> pd.Index([0, 1, 2]).all()
False
",https://pandas.pydata.org/docs/reference/api/pandas.Index.all.html, pandas.Index
">>> idx = pd.Index([True, False, True])
>>> idx.is_boolean()  
True
",https://pandas.pydata.org/docs/reference/api/pandas.Index.is_boolean.html, pandas.Index
">>> idx = pd.Index([""True"", ""False"", ""True""])
>>> idx.is_boolean()  
False
",https://pandas.pydata.org/docs/reference/api/pandas.Index.is_boolean.html, pandas.Index
">>> idx = pd.Index([True, False, ""True""])
>>> idx.is_boolean()  
False
",https://pandas.pydata.org/docs/reference/api/pandas.Index.is_boolean.html, pandas.Index
">>> idx = pd.DatetimeIndex([""1/1/2020 10:00:00+00:00""], freq=""D"")
>>> idx.freqstr
'D'
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.freqstr.html, pandas.DatetimeIndex
">>> idx = pd.DatetimeIndex([""2018-01-01"", ""2018-01-03"", ""2018-01-05""],
...                        freq=""infer"")
>>> idx.freqstr
'2D'
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.freqstr.html, pandas.DatetimeIndex
">>> idx = pd.PeriodIndex([""2023-1"", ""2023-2"", ""2023-3""], freq=""M"")
>>> idx.freqstr
'M'
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.freqstr.html, pandas.PeriodIndex
">>> mi = pd.MultiIndex.from_arrays(
... [[1, 2], [3, 4], [5, 6]], names=['x', 'y', 'z'])
>>> mi
MultiIndex([(1, 3, 5),
            (2, 4, 6)],
           names=['x', 'y', 'z'])
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.droplevel.html, pandas.MultiIndex.from_arrays pandas.MultiIndex
">>> mi.droplevel()
MultiIndex([(3, 5),
            (4, 6)],
           names=['y', 'z'])
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.droplevel.html, pandas.MultiIndex.droplevel pandas.MultiIndex
">>> mi.droplevel(2)
MultiIndex([(1, 3),
            (2, 4)],
           names=['x', 'y'])
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.droplevel.html, pandas.MultiIndex.droplevel pandas.MultiIndex
">>> mi.droplevel('z')
MultiIndex([(1, 3),
            (2, 4)],
           names=['x', 'y'])
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.droplevel.html, pandas.MultiIndex.droplevel pandas.MultiIndex
">>> mi.droplevel(['x', 'y'])
Index([5, 6], dtype='int64', name='z')
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.droplevel.html, pandas.MultiIndex.droplevel pandas.Index
">>> interv_arr = pd.arrays.IntervalArray([pd.Interval(0, 1), pd.Interval(1, 5)])
>>> interv_arr

[(0, 1], (1, 5]]
Length: 2, dtype: interval[int64, right]
>>> interv_arr.closed
'right'
",https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.closed.html, pandas.arrays.IntervalArray pandas.Interval
">>> interv_idx = pd.interval_range(start=0, end=2)
>>> interv_idx
IntervalIndex([(0, 1], (1, 2]], dtype='interval[int64, right]')
>>> interv_idx.closed
'right'
",https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.closed.html, pandas.interval_range pandas.IntervalIndex
">>> idx = pd.Index(list('abcd'))
>>> idx.slice_locs(start='b', end='c')
(1, 3)
",https://pandas.pydata.org/docs/reference/api/pandas.Index.slice_locs.html, pandas.Index pandas.Index.slice_locs
">>> datetime_series = pd.Series(
...     pd.date_range(""2000-01-01"", periods=3, freq=""s"")
... )
>>> datetime_series
0   2000-01-01 00:00:00
1   2000-01-01 00:00:01
2   2000-01-01 00:00:02
dtype: datetime64[ns]
>>> datetime_series.dt.second
0    0
1    1
2    2
dtype: int32
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.second.html, pandas.Series pandas.date_range
">>> idx = pd.MultiIndex.from_tuples(
...     [(1, ""one""), (1, ""two""), (2, ""one""), (2, ""two"")], names=[""foo"", ""bar""]
... )
>>> idx
MultiIndex([(1, 'one'),
    (1, 'two'),
    (2, 'one'),
    (2, 'two')],
   names=['foo', 'bar'])
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.set_codes.html, pandas.MultiIndex.from_tuples pandas.MultiIndex
">>> idx.set_codes([[1, 0, 1, 0], [0, 0, 1, 1]])
MultiIndex([(2, 'one'),
            (1, 'one'),
            (2, 'two'),
            (1, 'two')],
           names=['foo', 'bar'])
>>> idx.set_codes([1, 0, 1, 0], level=0)
MultiIndex([(2, 'one'),
            (1, 'two'),
            (2, 'one'),
            (1, 'two')],
           names=['foo', 'bar'])
>>> idx.set_codes([0, 0, 1, 1], level='bar')
MultiIndex([(1, 'one'),
            (1, 'one'),
            (2, 'two'),
            (2, 'two')],
           names=['foo', 'bar'])
>>> idx.set_codes([[1, 0, 1, 0], [0, 0, 1, 1]], level=[0, 1])
MultiIndex([(2, 'one'),
            (1, 'one'),
            (2, 'two'),
            (1, 'two')],
           names=['foo', 'bar'])
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.set_codes.html, pandas.MultiIndex
">>> idx = pd.PeriodIndex(['2020-01-31', '2020-02-28'], freq='D')
>>> idx.day
Index([31, 28], dtype='int64')
",https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.day.html, pandas.PeriodIndex pandas.Index
">>> datetime_series = pd.Series(
...     pd.date_range(""2000-01-01"", periods=3, freq=""h"")
... )
>>> datetime_series
0   2000-01-01 00:00:00
1   2000-01-01 01:00:00
2   2000-01-01 02:00:00
dtype: datetime64[ns]
>>> datetime_series.dt.hour
0    0
1    1
2    2
dtype: int32
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.hour.html, pandas.Series pandas.date_range
">>> idx = pd.Index([1, 2, 3])
>>> idx
Index([1, 2, 3], dtype='int64')
>>> idx.values
array([1, 2, 3])
",https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.values.html, pandas.Index pandas.Index pandas.array
">>> idx = pd.interval_range(start=0, end=5)
>>> idx.values

[(0, 1], (1, 2], (2, 3], (3, 4], (4, 5]]
Length: 5, dtype: interval[int64, right]
",https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.values.html, pandas.interval_range
">>> ser = pd.Series(pd.to_timedelta([1, 2, 3], unit='d'))
>>> ser
0   1 days
1   2 days
2   3 days
dtype: timedelta64[ns]
>>> ser.dt.days
0    1
1    2
2    3
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.days.html, pandas.Series pandas.to_timedelta
">>> tdelta_idx = pd.to_timedelta([""0 days"", ""10 days"", ""20 days""])
>>> tdelta_idx
TimedeltaIndex(['0 days', '10 days', '20 days'],
                dtype='timedelta64[ns]', freq=None)
>>> tdelta_idx.days
Index([0, 10, 20], dtype='int64')
",https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.days.html, pandas.to_timedelta pandas.TimedeltaIndex pandas.Index
">>> idx = pd.Index([""Apple"", ""Mango"", ""Watermelon""])
>>> idx.is_object()  
True
",https://pandas.pydata.org/docs/reference/api/pandas.Index.is_object.html, pandas.Index
">>> idx = pd.Index([""Apple"", ""Mango"", 2.0])
>>> idx.is_object()  
True
",https://pandas.pydata.org/docs/reference/api/pandas.Index.is_object.html, pandas.Index
">>> idx = pd.Index([""Watermelon"", ""Orange"", ""Apple"",
...                 ""Watermelon""]).astype(""category"")
>>> idx.is_object()  
False
",https://pandas.pydata.org/docs/reference/api/pandas.Index.is_object.html, pandas.Index
">>> idx = pd.Index([1.0, 2.0, 3.0, 4.0])
>>> idx.is_object()  
False
",https://pandas.pydata.org/docs/reference/api/pandas.Index.is_object.html, pandas.Index
">>> idx = pd.Index(['a', 'b', 'c'])
>>> idx.delete(1)
Index(['a', 'c'], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.Index.delete.html, pandas.Index pandas.Index.delete pandas.Index
">>> idx = pd.Index(['a', 'b', 'c'])
>>> idx.delete([0, 2])
Index(['b'], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.Index.delete.html, pandas.Index pandas.Index.delete pandas.Index
">>> numbers = [0, 1, 2]
>>> colors = ['green', 'purple']
>>> pd.MultiIndex.from_product([numbers, colors],
...                            names=['number', 'color'])
MultiIndex([(0,  'green'),
            (0, 'purple'),
            (1,  'green'),
            (1, 'purple'),
            (2,  'green'),
            (2, 'purple')],
           names=['number', 'color'])
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.from_product.html, pandas.MultiIndex.from_product pandas.MultiIndex
">>> index = pd.Index([3, 1, 2, 3, 4, np.nan])
>>> index.value_counts()
3.0    2
1.0    1
2.0    1
4.0    1
Name: count, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Index.value_counts.html, pandas.Index pandas.Index.value_counts
">>> s = pd.Series([3, 1, 2, 3, 4, np.nan])
>>> s.value_counts(normalize=True)
3.0    0.4
1.0    0.2
2.0    0.2
4.0    0.2
Name: proportion, dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Index.value_counts.html, pandas.Series pandas.Series.value_counts
">>> s.value_counts(bins=3)
(0.996, 2.0]    2
(2.0, 3.0]      2
(3.0, 4.0]      1
Name: count, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Index.value_counts.html, pandas.Series.value_counts
">>> s.value_counts(dropna=False)
3.0    2
1.0    1
2.0    1
4.0    1
NaN    1
Name: count, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Index.value_counts.html, pandas.Series.value_counts
">>> arrays = [[1, 1, 2, 2], ['red', 'blue', 'red', 'blue']]
>>> pd.MultiIndex.from_arrays(arrays, names=('number', 'color'))
MultiIndex([(1,  'red'),
            (1, 'blue'),
            (2,  'red'),
            (2, 'blue')],
           names=['number', 'color'])
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.from_arrays.html, pandas.MultiIndex.from_arrays pandas.MultiIndex
">>> idx = pd.Index([1, 2, 3])
>>> idx.memory_usage()
24
",https://pandas.pydata.org/docs/reference/api/pandas.Index.memory_usage.html, pandas.Index pandas.Index.memory_usage
">>> mi = pd.MultiIndex.from_arrays((list('abc'), list('def')))
>>> mi.names = ['level_1', 'level_2']
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.get_level_values.html, pandas.MultiIndex.from_arrays
">>> mi.get_level_values(0)
Index(['a', 'b', 'c'], dtype='object', name='level_1')
>>> mi.get_level_values('level_2')
Index(['d', 'e', 'f'], dtype='object', name='level_2')
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.get_level_values.html, pandas.MultiIndex.get_level_values pandas.Index
">>> pd.MultiIndex.from_arrays([[1, None, 2], [3, 4, 5]]).dtypes
level_0    int64
level_1    int64
dtype: object
>>> pd.MultiIndex.from_arrays([[1, None, 2], [3, 4, 5]]).get_level_values(0)
Index([1.0, nan, 2.0], dtype='float64')
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.get_level_values.html, pandas.MultiIndex.from_arrays pandas.Index
">>> idx = pd.PeriodIndex([""2023-01-10"", ""2023-02-01"", ""2023-03-01""], freq=""D"")
>>> idx.dayofyear
Index([10, 32, 60], dtype='int64')
",https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.day_of_year.html, pandas.PeriodIndex pandas.Index
">>> idx = pd.PeriodIndex([""2023"", ""2024"", ""2025""], freq=""Y"")
>>> idx
PeriodIndex(['2023', '2024', '2025'], dtype='period[Y-DEC]')
>>> idx.dayofyear
Index([365, 366, 365], dtype='int64')
",https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.day_of_year.html, pandas.PeriodIndex pandas.PeriodIndex pandas.Index
">>> s = pd.Series(pd.date_range(start='2018-01', freq='ME', periods=3))
>>> s
0   2018-01-31
1   2018-02-28
2   2018-03-31
dtype: datetime64[ns]
>>> s.dt.month_name()
0     January
1    February
2       March
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.month_name.html, pandas.Series pandas.date_range pandas.Series.dt.month_name
">>> idx = pd.date_range(start='2018-01', freq='ME', periods=3)
>>> idx
DatetimeIndex(['2018-01-31', '2018-02-28', '2018-03-31'],
              dtype='datetime64[ns]', freq='ME')
>>> idx.month_name()
Index(['January', 'February', 'March'], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.month_name.html, pandas.date_range pandas.DatetimeIndex pandas.Index
">>> idx = pd.date_range(start='2018-01', freq='ME', periods=3)
>>> idx
DatetimeIndex(['2018-01-31', '2018-02-28', '2018-03-31'],
              dtype='datetime64[ns]', freq='ME')
>>> idx.month_name(locale='pt_BR.utf8')  
Index(['Janeiro', 'Fevereiro', 'Março'], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.month_name.html, pandas.date_range pandas.DatetimeIndex pandas.Index
">>> idx = pd.DatetimeIndex(['2020-01-02 01:02:03.004005006'])
>>> idx
DatetimeIndex(['2020-01-02 01:02:03.004005006'],
              dtype='datetime64[ns]', freq=None)
>>> idx.as_unit('s')
DatetimeIndex(['2020-01-02 01:02:03'], dtype='datetime64[s]', freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.as_unit.html, pandas.DatetimeIndex pandas.DatetimeIndex pandas.DatetimeIndex.as_unit
">>> tdelta_idx = pd.to_timedelta(['1 day 3 min 2 us 42 ns'])
>>> tdelta_idx
TimedeltaIndex(['1 days 00:03:00.000002042'],
                dtype='timedelta64[ns]', freq=None)
>>> tdelta_idx.as_unit('s')
TimedeltaIndex(['1 days 00:03:00'], dtype='timedelta64[s]', freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.as_unit.html, pandas.to_timedelta pandas.TimedeltaIndex
">>> idx = pd.Index(['a', 'b', 'c'])
>>> new_idx = idx.copy()
>>> idx is new_idx
False
",https://pandas.pydata.org/docs/reference/api/pandas.Index.copy.html, pandas.Index pandas.Index.copy
">>> idx = pd.date_range('2001-01-01 00:00', periods=3)
>>> idx
DatetimeIndex(['2001-01-01', '2001-01-02', '2001-01-03'],
              dtype='datetime64[ns]', freq='D')
>>> idx.mean()
Timestamp('2001-01-02 00:00:00')
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.mean.html, pandas.date_range pandas.DatetimeIndex
">>> tdelta_idx = pd.to_timedelta([1, 2, 3], unit='D')
>>> tdelta_idx
TimedeltaIndex(['1 days', '2 days', '3 days'],
                dtype='timedelta64[ns]', freq=None)
>>> tdelta_idx.mean()
Timedelta('2 days 00:00:00')
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.mean.html, pandas.to_timedelta pandas.TimedeltaIndex
">>> s = pd.Series([1, 2, 3], index=['a', 'b', 'c'])
>>> s.index.ravel()
Index(['a', 'b', 'c'], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.Index.ravel.html, pandas.Series pandas.Index
">>> s = pd.Series(pd.date_range(""2018-02-27"", periods=3))
>>> s
0   2018-02-27
1   2018-02-28
2   2018-03-01
dtype: datetime64[ns]
>>> s.dt.is_month_start
0    False
1    False
2    True
dtype: bool
>>> s.dt.is_month_end
0    False
1    True
2    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.is_month_end.html, pandas.Series pandas.date_range
">>> idx = pd.date_range(""2018-02-27"", periods=3)
>>> idx.is_month_start
array([False, False, True])
>>> idx.is_month_end
array([False, True, False])
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.is_month_end.html, pandas.date_range pandas.array
">>> idx1 = pd.Index([1, 2, 3])
>>> idx1
Index([1, 2, 3], dtype='int64')
>>> idx1.equals(pd.Index([1, 2, 3]))
True
",https://pandas.pydata.org/docs/reference/api/pandas.Index.equals.html, pandas.Index pandas.Index pandas.Index.equals
">>> idx2 = pd.Index([""1"", ""2"", ""3""])
>>> idx2
Index(['1', '2', '3'], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.Index.equals.html, pandas.Index pandas.Index
">>> idx1.equals(idx2)
False
",https://pandas.pydata.org/docs/reference/api/pandas.Index.equals.html, pandas.Index.equals
">>> ascending_idx = pd.Index([1, 2, 3])
>>> ascending_idx
Index([1, 2, 3], dtype='int64')
>>> descending_idx = pd.Index([3, 2, 1])
>>> descending_idx
Index([3, 2, 1], dtype='int64')
>>> ascending_idx.equals(descending_idx)
False
",https://pandas.pydata.org/docs/reference/api/pandas.Index.equals.html, pandas.Index pandas.Index pandas.Index.equals
">>> int64_idx = pd.Index([1, 2, 3], dtype='int64')
>>> int64_idx
Index([1, 2, 3], dtype='int64')
>>> uint64_idx = pd.Index([1, 2, 3], dtype='uint64')
>>> uint64_idx
Index([1, 2, 3], dtype='uint64')
>>> int64_idx.equals(uint64_idx)
True
",https://pandas.pydata.org/docs/reference/api/pandas.Index.equals.html, pandas.Index pandas.Index pandas.Index.equals
">>> idx = pd.Index([1,2,3])
>>> idx
Index([1, 2, 3], dtype='int64')
",https://pandas.pydata.org/docs/reference/api/pandas.Index.isin.html, pandas.Index pandas.Index
">>> idx.isin([1, 4])
array([ True, False, False])
",https://pandas.pydata.org/docs/reference/api/pandas.Index.isin.html, pandas.Index.isin pandas.array
">>> midx = pd.MultiIndex.from_arrays([[1,2,3],
...                                  ['red', 'blue', 'green']],
...                                  names=('number', 'color'))
>>> midx
MultiIndex([(1,   'red'),
            (2,  'blue'),
            (3, 'green')],
           names=['number', 'color'])
",https://pandas.pydata.org/docs/reference/api/pandas.Index.isin.html, pandas.MultiIndex.from_arrays pandas.MultiIndex
">>> midx.isin(['red', 'orange', 'yellow'], level='color')
array([ True, False, False])
",https://pandas.pydata.org/docs/reference/api/pandas.Index.isin.html, pandas.array
">>> midx.isin([(1, 'red'), (3, 'red')])
array([ True, False, False])
",https://pandas.pydata.org/docs/reference/api/pandas.Index.isin.html, pandas.array
">>> idx = pd.DatetimeIndex([""2018-01-01"", ""2018-01-03"", ""2018-01-05""])
>>> idx.inferred_freq
'2D'
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.inferred_freq.html, pandas.DatetimeIndex
">>> tdelta_idx = pd.to_timedelta([""0 days"", ""10 days"", ""20 days""])
>>> tdelta_idx
TimedeltaIndex(['0 days', '10 days', '20 days'],
               dtype='timedelta64[ns]', freq=None)
>>> tdelta_idx.inferred_freq
'10D'
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.inferred_freq.html, pandas.to_timedelta pandas.TimedeltaIndex
">>> idx = pd.PeriodIndex([""2023-01-01 10:30:00"",
...                       ""2023-01-01 11:50:00""], freq='min')
>>> idx.minute
Index([30, 50], dtype='int64')
",https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.minute.html, pandas.PeriodIndex pandas.Index
">>> index = pd.IntervalIndex.from_tuples([(0, 2), (1, 3), (4, 5)])
>>> index
IntervalIndex([(0, 2], (1, 3], (4, 5]],
      dtype='interval[int64, right]')
>>> index.is_overlapping
True
",https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.is_overlapping.html, pandas.IntervalIndex.from_tuples pandas.IntervalIndex
">>> index = pd.interval_range(0, 3, closed='both')
>>> index
IntervalIndex([[0, 1], [1, 2], [2, 3]],
      dtype='interval[int64, both]')
>>> index.is_overlapping
True
",https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.is_overlapping.html, pandas.interval_range pandas.IntervalIndex
">>> index = pd.interval_range(0, 3, closed='left')
>>> index
IntervalIndex([[0, 1), [1, 2), [2, 3)],
      dtype='interval[int64, left]')
>>> index.is_overlapping
False
",https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.is_overlapping.html, pandas.interval_range pandas.IntervalIndex
">>> idx = pd.DatetimeIndex([""1/1/2020 10:00:00+00:00"", ""2/1/2020 11:00:00+00:00""])
>>> idx
DatetimeIndex(['2020-01-01 10:00:00+00:00', '2020-02-01 11:00:00+00:00'],
dtype='datetime64[ns, UTC]', freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.html, pandas.DatetimeIndex pandas.DatetimeIndex
">>> s = pd.Series([""1/1/2020 10:00:00+00:00"", ""2/1/2020 11:00:00+00:00""])
>>> s = pd.to_datetime(s)
>>> s
0   2020-01-01 10:00:00+00:00
1   2020-02-01 11:00:00+00:00
dtype: datetime64[ns, UTC]
>>> s.dt.date
0    2020-01-01
1    2020-02-01
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.date.html, pandas.Series pandas.to_datetime
">>> idx = pd.DatetimeIndex([""1/1/2020 10:00:00+00:00"",
...                         ""2/1/2020 11:00:00+00:00""])
>>> idx.date
array([datetime.date(2020, 1, 1), datetime.date(2020, 2, 1)], dtype=object)
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.date.html, pandas.DatetimeIndex pandas.array pandas.Timestamp.date
">>> idx1 = pd.Index(['1', '2', '3'])
>>> idx1.is_(idx1.view())
True
",https://pandas.pydata.org/docs/reference/api/pandas.Index.is_.html, pandas.Index pandas.Index.view
">>> idx1.is_(idx1.copy())
False
",https://pandas.pydata.org/docs/reference/api/pandas.Index.is_.html, pandas.Index.copy
">>> idx = pd.Index(['Ant', 'Bear', 'Cow'], name='animal')
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.to_series.html, pandas.Index
">>> idx = pd.date_range('2001-01-01 00:00', periods=3)
>>> idx
DatetimeIndex(['2001-01-01', '2001-01-02', '2001-01-03'],
              dtype='datetime64[ns]', freq='D')
>>> idx.mean()
Timestamp('2001-01-02 00:00:00')
",https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.mean.html, pandas.date_range pandas.DatetimeIndex
">>> tdelta_idx = pd.to_timedelta([1, 2, 3], unit='D')
>>> tdelta_idx
TimedeltaIndex(['1 days', '2 days', '3 days'],
                dtype='timedelta64[ns]', freq=None)
>>> tdelta_idx.mean()
Timedelta('2 days 00:00:00')
",https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.mean.html, pandas.to_timedelta pandas.TimedeltaIndex
">>> s = pd.Series(['Ant', 'Bear', 'Cow'])
>>> s
0     Ant
1    Bear
2     Cow
dtype: object
>>> s.T
0     Ant
1    Bear
2     Cow
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Index.T.html, pandas.Series
">>> idx = pd.Index([1, 2, 3])
>>> idx.T
Index([1, 2, 3], dtype='int64')
",https://pandas.pydata.org/docs/reference/api/pandas.Index.T.html, pandas.Index pandas.Index
">>> idx = pd.date_range('2001-01-01 00:00', periods=3)
>>> idx
DatetimeIndex(['2001-01-01', '2001-01-02', '2001-01-03'],
              dtype='datetime64[ns]', freq='D')
>>> idx.std()
Timedelta('1 days 00:00:00')
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.std.html, pandas.date_range pandas.DatetimeIndex
">>> idx = pd.Index([1.0, 2.0, 3.0, 4.0])
>>> idx.is_numeric()  
True
",https://pandas.pydata.org/docs/reference/api/pandas.Index.is_numeric.html, pandas.Index
">>> idx = pd.Index([1, 2, 3, 4.0])
>>> idx.is_numeric()  
True
",https://pandas.pydata.org/docs/reference/api/pandas.Index.is_numeric.html, pandas.Index
">>> idx = pd.Index([1, 2, 3, 4])
>>> idx.is_numeric()  
True
",https://pandas.pydata.org/docs/reference/api/pandas.Index.is_numeric.html, pandas.Index
">>> idx = pd.Index([1, 2, 3, 4.0, np.nan])
>>> idx.is_numeric()  
True
",https://pandas.pydata.org/docs/reference/api/pandas.Index.is_numeric.html, pandas.Index
">>> idx = pd.Index([1, 2, 3, 4.0, np.nan, ""Apple""])
>>> idx.is_numeric()  
False
",https://pandas.pydata.org/docs/reference/api/pandas.Index.is_numeric.html, pandas.Index
">>> pidx = pd.period_range('2010-01-01', '2015-01-01', freq='Y')
>>> pidx
PeriodIndex(['2010', '2011', '2012', '2013', '2014', '2015'],
dtype='period[Y-DEC]')
",https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.asfreq.html, pandas.period_range pandas.PeriodIndex
">>> pidx.asfreq('M')
PeriodIndex(['2010-12', '2011-12', '2012-12', '2013-12', '2014-12',
'2015-12'], dtype='period[M]')
",https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.asfreq.html, pandas.PeriodIndex
">>> pidx.asfreq('M', how='S')
PeriodIndex(['2010-01', '2011-01', '2012-01', '2013-01', '2014-01',
'2015-01'], dtype='period[M]')
",https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.asfreq.html, pandas.PeriodIndex
">>> pd.TimedeltaIndex(['0 days', '1 days', '2 days', '3 days', '4 days'])
TimedeltaIndex(['0 days', '1 days', '2 days', '3 days', '4 days'],
               dtype='timedelta64[ns]', freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.html, pandas.TimedeltaIndex pandas.TimedeltaIndex
">>> pd.TimedeltaIndex(np.arange(5) * 24 * 3600 * 1e9, freq='infer')
TimedeltaIndex(['0 days', '1 days', '2 days', '3 days', '4 days'],
               dtype='timedelta64[ns]', freq='D')
",https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.html, pandas.TimedeltaIndex pandas.TimedeltaIndex
">>> ser = pd.Series(['a', 'b', 'c', 'a'], dtype='category')
>>> ser.cat.categories
Index(['a', 'b', 'c'], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.categories.html, pandas.Series pandas.Index
">>> raw_cat = pd.Categorical(['a', 'b', 'c', 'a'], categories=['b', 'c', 'd'])
>>> ser = pd.Series(raw_cat)
>>> ser.cat.categories
Index(['b', 'c', 'd'], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.categories.html, pandas.Categorical pandas.Series pandas.Index
">>> cat = pd.Categorical(['a', 'b'], ordered=True)
>>> cat.categories
Index(['a', 'b'], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.categories.html, pandas.Categorical pandas.Index
">>> ci = pd.CategoricalIndex(['a', 'c', 'b', 'a', 'c', 'b'])
>>> ci.categories
Index(['a', 'b', 'c'], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.categories.html, pandas.CategoricalIndex pandas.Index
">>> ci = pd.CategoricalIndex(['a', 'c'], categories=['c', 'b', 'a'])
>>> ci.categories
Index(['c', 'b', 'a'], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.categories.html, pandas.CategoricalIndex pandas.Index
">>> idx1 = pd.Index([1, 2, 3, 4])
>>> idx2 = pd.Index([3, 4, 5, 6])
>>> idx1.union(idx2)
Index([1, 2, 3, 4, 5, 6], dtype='int64')
",https://pandas.pydata.org/docs/reference/api/pandas.Index.union.html, pandas.Index pandas.Index
">>> idx1 = pd.Index(['a', 'b', 'c', 'd'])
>>> idx2 = pd.Index([1, 2, 3, 4])
>>> idx1.union(idx2)
Index(['a', 'b', 'c', 'd', 1, 2, 3, 4], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.Index.union.html, pandas.Index pandas.Index
">>> idx1 = pd.MultiIndex.from_arrays(
...     [[1, 1, 2, 2], [""Red"", ""Blue"", ""Red"", ""Blue""]]
... )
>>> idx1
MultiIndex([(1,  'Red'),
    (1, 'Blue'),
    (2,  'Red'),
    (2, 'Blue')],
   )
>>> idx2 = pd.MultiIndex.from_arrays(
...     [[3, 3, 2, 2], [""Red"", ""Green"", ""Red"", ""Green""]]
... )
>>> idx2
MultiIndex([(3,   'Red'),
    (3, 'Green'),
    (2,   'Red'),
    (2, 'Green')],
   )
>>> idx1.union(idx2)
MultiIndex([(1,  'Blue'),
    (1,   'Red'),
    (2,  'Blue'),
    (2, 'Green'),
    (2,   'Red'),
    (3, 'Green'),
    (3,   'Red')],
   )
>>> idx1.union(idx2, sort=False)
MultiIndex([(1,   'Red'),
    (1,  'Blue'),
    (2,   'Red'),
    (2,  'Blue'),
    (3,   'Red'),
    (3, 'Green'),
    (2, 'Green')],
   )
",https://pandas.pydata.org/docs/reference/api/pandas.Index.union.html, pandas.MultiIndex.from_arrays pandas.MultiIndex
">>> idx1 = pd.Index([2, 1, 3, 4])
>>> idx2 = pd.Index([3, 4, 5, 6])
>>> idx1.difference(idx2)
Index([1, 2], dtype='int64')
>>> idx1.difference(idx2, sort=False)
Index([2, 1], dtype='int64')
",https://pandas.pydata.org/docs/reference/api/pandas.Index.difference.html, pandas.Index pandas.Index
">>> idx = pd.Index([1, np.nan, 3])
>>> idx.dropna()
Index([1.0, 3.0], dtype='float64')
",https://pandas.pydata.org/docs/reference/api/pandas.Index.dropna.html, pandas.Index pandas.Index.dropna pandas.Index
">>> s = pd.Series(['Ant', 'Bear', 'Cow'])
>>> s
0     Ant
1    Bear
2     Cow
dtype: object
>>> s.ndim
1
",https://pandas.pydata.org/docs/reference/api/pandas.Index.ndim.html, pandas.Series
">>> idx = pd.Index([1, 2, 3])
>>> idx
Index([1, 2, 3], dtype='int64')
>>> idx.ndim
1
",https://pandas.pydata.org/docs/reference/api/pandas.Index.ndim.html, pandas.Index pandas.Index
">>> idx = pd.Index(['Ant', 'Bear', 'Cow'], name='animal')
>>> idx.to_frame()
       animal
animal
Ant       Ant
Bear     Bear
Cow       Cow
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.to_frame.html, pandas.Index pandas.Index.to_frame
">>> idx.to_frame(index=False)
    animal
0   Ant
1  Bear
2   Cow
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.to_frame.html, pandas.Index.to_frame
">>> idx.to_frame(index=False, name='zoo')
    zoo
0   Ant
1  Bear
2   Cow
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.to_frame.html, pandas.Index.to_frame
">>> idx = pd.Index([1, 2, 3])
>>> idx
Index([1, 2, 3], dtype='int64')
>>> idx.astype('float')
Index([1.0, 2.0, 3.0], dtype='float64')
",https://pandas.pydata.org/docs/reference/api/pandas.Index.astype.html, pandas.Index pandas.Index pandas.Index.astype
">>> idx = pd.Index(['a', 'b', 'c'])
>>> idx.take([2, 2, 1, 2])
Index(['c', 'c', 'b', 'c'], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.Index.take.html, pandas.Index pandas.Index.take pandas.Index
">>> rng = pd.date_range(pd.Timestamp(""2018-03-10 09:00""),
...                     periods=3, freq='s')
>>> rng.strftime('%B %d, %Y, %r')
Index(['March 10, 2018, 09:00:00 AM', 'March 10, 2018, 09:00:01 AM',
       'March 10, 2018, 09:00:02 AM'],
      dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.strftime.html, pandas.date_range pandas.Index
">>> idx = pd.Index(['Ant', 'Bear', 'Cow'], name='animal')
",https://pandas.pydata.org/docs/reference/api/pandas.Index.to_series.html, pandas.Index
">>> index = pd.Index([0, 1, 2])
>>> index.any()
True
",https://pandas.pydata.org/docs/reference/api/pandas.Index.any.html, pandas.Index pandas.Index.any
">>> index = pd.Index([0, 0, 0])
>>> index.any()
False
",https://pandas.pydata.org/docs/reference/api/pandas.Index.any.html, pandas.Index pandas.Index.any
">>> idx = pd.PeriodIndex([""2023-01-01"", ""2023-01-02"", ""2023-01-03""], freq=""D"")
>>> idx.weekday
Index([6, 0, 1], dtype='int64')
",https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.day_of_week.html, pandas.PeriodIndex pandas.Index
">>> s = pd.Series({'Corn Flakes': 100.0, 'Almond Delight': 110.0,
...                'Cinnamon Toast Crunch': 120.0, 'Cocoa Puff': 110.0})
>>> s
Corn Flakes              100.0
Almond Delight           110.0
Cinnamon Toast Crunch    120.0
Cocoa Puff               110.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Index.argmax.html, pandas.Series
">>> s.argmax()
2
>>> s.argmin()
0
",https://pandas.pydata.org/docs/reference/api/pandas.Index.argmax.html, pandas.Series.argmax pandas.Series.argmin
">>> ser = pd.Series(pd.to_timedelta([1, 2, 3], unit='s'))
>>> ser
0   0 days 00:00:01
1   0 days 00:00:02
2   0 days 00:00:03
dtype: timedelta64[ns]
>>> ser.dt.seconds
0    1
1    2
2    3
dtype: int32
",https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.seconds.html, pandas.Series pandas.to_timedelta
">>> tdelta_idx = pd.to_timedelta([1, 2, 3], unit='s')
>>> tdelta_idx
TimedeltaIndex(['0 days 00:00:01', '0 days 00:00:02', '0 days 00:00:03'],
               dtype='timedelta64[ns]', freq=None)
>>> tdelta_idx.seconds
Index([1, 2, 3], dtype='int32')
",https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.seconds.html, pandas.to_timedelta pandas.TimedeltaIndex pandas.Index
">>> idx = pd.RangeIndex(5)
>>> idx.stop
5
",https://pandas.pydata.org/docs/reference/api/pandas.RangeIndex.stop.html, pandas.RangeIndex
">>> idx = pd.RangeIndex(2, -10, -3)
>>> idx.stop
-10
",https://pandas.pydata.org/docs/reference/api/pandas.RangeIndex.stop.html, pandas.RangeIndex
">>> period = pd.Period('2012-1-1', freq='D')
>>> period
Period('2012-01-01', 'D')
",https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.start_time.html, pandas.Period pandas.Period
">>> df = pd.DataFrame({""0categories"": pd.Series([2, 2])})
>>> df.to_stata('test') 
... # InvalidColumnName: Not all pandas column names were valid Stata variable...
",https://pandas.pydata.org/docs/reference/api/pandas.errors.InvalidColumnName.html, pandas.DataFrame pandas.Series pandas.DataFrame.to_stata
">>> from pandas import testing as tm
>>> a = pd.Index([1, 2, 3])
>>> b = pd.Index([1, 2, 3])
>>> tm.assert_index_equal(a, b)
",https://pandas.pydata.org/docs/reference/api/pandas.testing.assert_index_equal.html, pandas.Index
">>> idx = pd.PeriodIndex([""2023-01-10"", ""2023-02-01"", ""2023-03-01""], freq=""D"")
>>> idx.dayofyear
Index([10, 32, 60], dtype='int64')
",https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.dayofyear.html, pandas.PeriodIndex pandas.Index
">>> idx = pd.PeriodIndex([""2023"", ""2024"", ""2025""], freq=""Y"")
>>> idx
PeriodIndex(['2023', '2024', '2025'], dtype='period[Y-DEC]')
>>> idx.dayofyear
Index([365, 366, 365], dtype='int64')
",https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.dayofyear.html, pandas.PeriodIndex pandas.PeriodIndex pandas.Index
">>> idx = pd.PeriodIndex([""2023-01"", ""2023-02"", ""2023-03""], freq=""M"")
>>> idx.week  # It can be written `weekofyear`
Index([5, 9, 13], dtype='int64')
",https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.weekofyear.html, pandas.PeriodIndex pandas.Index
">>> period = pd.period_range('2020-1-1 00:00', '2020-3-1 00:00', freq='M')
>>> s = pd.Series(period)
>>> s
0   2020-01
1   2020-02
2   2020-03
dtype: period[M]
>>> s.dt.days_in_month
0    31
1    29
2    31
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.days_in_month.html, pandas.period_range pandas.Series
">>> idx = pd.PeriodIndex([""2023-01"", ""2023-02"", ""2023-03""], freq=""M"")
>>> idx.days_in_month   # It can be also entered as `daysinmonth`
Index([31, 28, 31], dtype='int64')
",https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.days_in_month.html, pandas.PeriodIndex pandas.Index
">>> rng = pd.date_range('1/1/2018 11:59:00', periods=3, freq='min')
>>> rng
DatetimeIndex(['2018-01-01 11:59:00', '2018-01-01 12:00:00',
               '2018-01-01 12:01:00'],
              dtype='datetime64[ns]', freq='min')
>>> rng.ceil('h')
DatetimeIndex(['2018-01-01 12:00:00', '2018-01-01 12:00:00',
               '2018-01-01 13:00:00'],
              dtype='datetime64[ns]', freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.ceil.html, pandas.date_range pandas.DatetimeIndex
">>> pd.Series(rng).dt.ceil(""h"")
0   2018-01-01 12:00:00
1   2018-01-01 12:00:00
2   2018-01-01 13:00:00
dtype: datetime64[ns]
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.ceil.html, pandas.Series
">>> rng_tz = pd.DatetimeIndex([""2021-10-31 01:30:00""], tz=""Europe/Amsterdam"")
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.ceil.html, pandas.DatetimeIndex
">>> rng_tz.ceil(""h"", ambiguous=False)
DatetimeIndex(['2021-10-31 02:00:00+01:00'],
              dtype='datetime64[ns, Europe/Amsterdam]', freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.ceil.html, pandas.DatetimeIndex.ceil pandas.DatetimeIndex
">>> rng_tz.ceil(""h"", ambiguous=True)
DatetimeIndex(['2021-10-31 02:00:00+02:00'],
              dtype='datetime64[ns, Europe/Amsterdam]', freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.ceil.html, pandas.DatetimeIndex.ceil pandas.DatetimeIndex
">>> data = '''a,b,c
... cat,foo,bar
... dog,foo,""baz'''
>>> from io import StringIO
>>> pd.read_csv(StringIO(data), skipfooter=1, engine='python')
Traceback (most recent call last):
ParserError: ',' expected after '""'. Error could possibly be due
to parsing errors in the skipped footer rows
",https://pandas.pydata.org/docs/reference/api/pandas.errors.ParserError.html, pandas.read_csv
">>> df = pd.DatetimeIndex([""2011-01-01 10:00"", ""2011-01-01""], freq=None)
>>> df.shift(2)
Traceback (most recent call last):
NullFrequencyError: Cannot shift with no freq
",https://pandas.pydata.org/docs/reference/api/pandas.errors.NullFrequencyError.html, pandas.DatetimeIndex
">>> df = pd.DataFrame({""s"": pd.Series([1, 2**53], dtype=np.int64)})
>>> df.to_stata('test') 
... # PossiblePrecisionLoss: Column converted from int64 to float64...
",https://pandas.pydata.org/docs/reference/api/pandas.errors.PossiblePrecisionLoss.html, pandas.DataFrame pandas.Series pandas.DataFrame.to_stata
">>> df = pd.DataFrame({'a': (['1'] * 100000 + ['X'] * 100000 +
...                          ['1'] * 100000),
...                    'b': ['b'] * 300000})  
>>> df.to_csv('test.csv', index=False)  
>>> df2 = pd.read_csv('test.csv')  
... # DtypeWarning: Columns (0) have mixed types
",https://pandas.pydata.org/docs/reference/api/pandas.errors.DtypeWarning.html, pandas.DataFrame pandas.DataFrame.to_csv pandas.read_csv
">>> df2 = pd.read_csv('test.csv', sep=',', dtype={'a': str})  
",https://pandas.pydata.org/docs/reference/api/pandas.errors.DtypeWarning.html, pandas.read_csv
">>> from pandas.testing import assert_frame_equal
>>> df1 = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})
>>> df2 = pd.DataFrame({'a': [1, 2], 'b': [3.0, 4.0]})
",https://pandas.pydata.org/docs/reference/api/pandas.testing.assert_frame_equal.html, pandas.DataFrame
">>> assert_frame_equal(df1, df1)
",https://pandas.pydata.org/docs/reference/api/pandas.testing.assert_frame_equal.html, pandas.testing.assert_frame_equal
">>> assert_frame_equal(df1, df2)
Traceback (most recent call last):
...
AssertionError: Attributes of DataFrame.iloc[:, 1] (column name=""b"") are different
",https://pandas.pydata.org/docs/reference/api/pandas.testing.assert_frame_equal.html, pandas.testing.assert_frame_equal
">>> assert_frame_equal(df1, df2, check_dtype=False)
",https://pandas.pydata.org/docs/reference/api/pandas.testing.assert_frame_equal.html, pandas.testing.assert_frame_equal
">>> idx = pd.MultiIndex.from_product([[""x"", ""y""], [0, 1]])
>>> df = pd.DataFrame([[1, 1, 2, 2],
...                   [3, 3, 4, 4]], columns=idx)
>>> df
    x       y
    0   1   0   1
0   1   1   2   2
1   3   3   4   4
>>> df[:, 0]
Traceback (most recent call last):
InvalidIndexError: (slice(None, None, None), 0)
",https://pandas.pydata.org/docs/reference/api/pandas.errors.InvalidIndexError.html, pandas.MultiIndex.from_product pandas.DataFrame pandas.Series.str.slice
">>> df = pd.DataFrame({""cat"": [0, 0, 1, 1],
...                    ""color"": [""white"", ""white"", ""brown"", ""black""],
...                    ""lives"": [4, 4, 3, 7]},
...                   )
>>> df = df.set_index([""cat"", ""color""])
>>> df
            lives
cat  color
0    white    4
     white    4
1    brown    3
     black    7
>>> df.loc[(0, ""black""):(1, ""white"")]
Traceback (most recent call last):
UnsortedIndexError: 'Key length (2) was greater
than MultiIndex lexsort depth (1)'
",https://pandas.pydata.org/docs/reference/api/pandas.errors.UnsortedIndexError.html, pandas.DataFrame pandas.DataFrame.set_index
">>> idx = pd.Index([""Watermelon"", ""Orange"", ""Apple"",
...                 ""Watermelon""]).astype(""category"")
>>> idx.is_categorical()  
True
",https://pandas.pydata.org/docs/reference/api/pandas.Index.is_categorical.html, pandas.Index
">>> idx = pd.Index([1, 3, 5, 7])
>>> idx.is_categorical()  
False
",https://pandas.pydata.org/docs/reference/api/pandas.Index.is_categorical.html, pandas.Index
">>> s = pd.Series([""Peter"", ""Victor"", ""Elisabeth"", ""Mar""])
>>> s
0        Peter
1       Victor
2    Elisabeth
3          Mar
dtype: object
>>> s.index.is_categorical()  
False
",https://pandas.pydata.org/docs/reference/api/pandas.Index.is_categorical.html, pandas.Series
">>> idx = pd.Index(['Ant', 'Bear', 'Cow'], name='animal')
",https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.to_series.html, pandas.Index
">>> rng = pd.date_range(pd.Timestamp(""2018-03-10 09:00""),
...                     periods=3, freq='s')
>>> rng.strftime('%B %d, %Y, %r')
Index(['March 10, 2018, 09:00:00 AM', 'March 10, 2018, 09:00:01 AM',
       'March 10, 2018, 09:00:02 AM'],
      dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.strftime.html, pandas.date_range pandas.Index
">>> ser = pd.Series([1, 2, 3])
>>> ser
0    1
1    2
2    3
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Index.searchsorted.html, pandas.Series
">>> ser.searchsorted(4)
3
",https://pandas.pydata.org/docs/reference/api/pandas.Index.searchsorted.html, pandas.Series.searchsorted
">>> ser.searchsorted([0, 4])
array([0, 3])
",https://pandas.pydata.org/docs/reference/api/pandas.Index.searchsorted.html, pandas.Series.searchsorted pandas.array
">>> ser.searchsorted([1, 3], side='left')
array([0, 2])
",https://pandas.pydata.org/docs/reference/api/pandas.Index.searchsorted.html, pandas.Series.searchsorted pandas.array
">>> ser.searchsorted([1, 3], side='right')
array([1, 3])
",https://pandas.pydata.org/docs/reference/api/pandas.Index.searchsorted.html, pandas.Series.searchsorted pandas.array
">>> ser = pd.Series(pd.to_datetime(['3/11/2000', '3/12/2000', '3/13/2000']))
>>> ser
0   2000-03-11
1   2000-03-12
2   2000-03-13
dtype: datetime64[ns]
",https://pandas.pydata.org/docs/reference/api/pandas.Index.searchsorted.html, pandas.Series pandas.to_datetime
">>> ser.searchsorted('3/14/2000')
3
",https://pandas.pydata.org/docs/reference/api/pandas.Index.searchsorted.html, pandas.Series.searchsorted
">>> ser = pd.Categorical(
...     ['apple', 'bread', 'bread', 'cheese', 'milk'], ordered=True
... )
>>> ser
['apple', 'bread', 'bread', 'cheese', 'milk']
Categories (4, object): ['apple' < 'bread' < 'cheese' < 'milk']
",https://pandas.pydata.org/docs/reference/api/pandas.Index.searchsorted.html, pandas.Categorical
">>> ser.searchsorted(['bread'], side='right')
array([3])
",https://pandas.pydata.org/docs/reference/api/pandas.Index.searchsorted.html, pandas.array
">>> ser = pd.Series([2, 1, 3])
>>> ser
0    2
1    1
2    3
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Index.searchsorted.html, pandas.Series
">>> ser.searchsorted(1)  
0  # wrong result, correct would be 1
",https://pandas.pydata.org/docs/reference/api/pandas.Index.searchsorted.html, pandas.Series.searchsorted
">>> pd.to_datetime(""08335394550"")
Traceback (most recent call last):
OutOfBoundsDatetime: Parsing ""08335394550"" to datetime overflows,
at position 0
",https://pandas.pydata.org/docs/reference/api/pandas.errors.OutOfBoundsDatetime.html, pandas.to_datetime
">>> idx = pd.Index([1, 2, 3])
>>> idx
Index([1, 2, 3], dtype='int64')
>>> idx.dtype
dtype('int64')
",https://pandas.pydata.org/docs/reference/api/pandas.Index.dtype.html, pandas.Index pandas.Index
">>> df = pd.DataFrame({""A"": [0, 0, 1, 1],
...                    ""B"": [""x"", ""x"", ""z"", ""y""],
...                    ""C"": [1, 2, 3, 4]}
...                   )
>>> np.cumsum(df.groupby([""A""]))
Traceback (most recent call last):
UnsupportedFunctionCall: numpy operations are not valid with groupby.
Use .groupby(...).cumsum() instead
",https://pandas.pydata.org/docs/reference/api/pandas.errors.UnsupportedFunctionCall.html, pandas.DataFrame pandas.DataFrame.groupby
">>> from sqlite3 import connect
>>> conn = connect(':memory:')
>>> pd.read_sql('select * test', conn) 
... # DatabaseError: Execution failed on sql 'test': near ""test"": syntax error
",https://pandas.pydata.org/docs/reference/api/pandas.errors.DatabaseError.html, pandas.read_sql
">>> i1, i2 = pd.Interval(0, 1), pd.Interval(1, 2)
>>> index = pd.IntervalIndex([i1, i2])
>>> index.get_loc(1)
0
",https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.get_loc.html, pandas.Interval pandas.IntervalIndex pandas.IntervalIndex.get_loc
">>> index.get_loc(1.5)
1
",https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.get_loc.html, pandas.IntervalIndex.get_loc
">>> i3 = pd.Interval(0, 2)
>>> overlapping_index = pd.IntervalIndex([i1, i2, i3])
>>> overlapping_index.get_loc(0.5)
array([ True, False,  True])
",https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.get_loc.html, pandas.Interval pandas.IntervalIndex pandas.IntervalIndex.get_loc pandas.array
">>> index.get_loc(pd.Interval(0, 1))
0
",https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.get_loc.html, pandas.IntervalIndex.get_loc pandas.Interval
">>> idx1 = pd.Index(['1', '2', '3'])
>>> idx2 = pd.Index(['1', '2', '3'])
>>> idx2.identical(idx1)
True
",https://pandas.pydata.org/docs/reference/api/pandas.Index.identical.html, pandas.Index
">>> idx1 = pd.Index(['1', '2', '3'], name=""A"")
>>> idx2 = pd.Index(['1', '2', '3'], name=""B"")
>>> idx2.identical(idx1)
False
",https://pandas.pydata.org/docs/reference/api/pandas.Index.identical.html, pandas.Index
">>> pd.options.mode.copy_on_write = True
>>> df = pd.DataFrame({'A': [1, 1, 1, 2, 2]}, columns=['A'])
>>> df[""A""][0:3] = 10 
... # ChainedAssignmentError: ...
>>> pd.options.mode.copy_on_write = False
",https://pandas.pydata.org/docs/reference/api/pandas.errors.ChainedAssignmentError.html, pandas.DataFrame
">>> arrays = [[1, 1, 2, 2], ['red', 'blue', 'red', 'blue']]
>>> pd.MultiIndex.from_arrays(arrays, names=('number', 'color'))
MultiIndex([(1,  'red'),
            (1, 'blue'),
            (2,  'red'),
            (2, 'blue')],
           names=['number', 'color'])
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.html, pandas.MultiIndex.from_arrays pandas.MultiIndex
">>> import datetime
>>> dt = datetime.datetime(2018, 10, 3)
>>> pd.api.types.is_scalar(dt)
True
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_scalar.html, pandas.api.types.is_scalar
">>> pd.api.types.is_scalar([2, 3])
False
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_scalar.html, pandas.api.types.is_scalar
">>> pd.api.types.is_scalar({0: 1, 2: 3})
False
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_scalar.html, pandas.api.types.is_scalar
">>> pd.api.types.is_scalar((0, 2))
False
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_scalar.html, pandas.api.types.is_scalar
">>> from fractions import Fraction
>>> pd.api.types.is_scalar(Fraction(3, 5))
True
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_scalar.html, pandas.api.types.is_scalar
">>> idx1 = pd.Index(['a', 'b'], name='name1')
>>> df1 = pd.DataFrame([[1, 2], [3, 4]], index=idx1)
>>> df1.to_hdf('file', 'data', 'w', append=True)  
>>> idx2 = pd.Index(['c', 'd'], name='name2')
>>> df2 = pd.DataFrame([[5, 6], [7, 8]], index=idx2)
>>> df2.to_hdf('file', 'data', 'a', append=True)  
AttributeConflictWarning: the [index_name] attribute of the existing index is
[name1] which conflicts with the new [name2]...
",https://pandas.pydata.org/docs/reference/api/pandas.errors.AttributeConflictWarning.html, pandas.Index pandas.DataFrame pandas.DataFrame.to_hdf pandas.DataFrame.to_hdf
">>> pd.DataFrame(np.array([[1, np.nan], [2, 3]]), dtype=""i8"")
Traceback (most recent call last):
IntCastingNaNError: Cannot convert non-finite values (NA or inf) to integer
",https://pandas.pydata.org/docs/reference/api/pandas.errors.IntCastingNaNError.html, pandas.DataFrame
">>> df = pd.DataFrame({'A': [1, 1, 1, 2, 2]}, columns=['A'])
>>> df.loc[0:3]['A'] = 'a' 
... # SettingWithCopyWarning: A value is trying to be set on a copy of a...
",https://pandas.pydata.org/docs/reference/api/pandas.errors.SettingWithCopyWarning.html, pandas.DataFrame
">>> df = pd.DataFrame({""categories"": pd.Series([""a"", 2], dtype=""category"")})
>>> df.to_stata('test') 
... # ValueLabelTypeMismatch: Stata value labels (pandas categories) must be str...
",https://pandas.pydata.org/docs/reference/api/pandas.errors.ValueLabelTypeMismatch.html, pandas.DataFrame pandas.Series pandas.DataFrame.to_stata
">>> codes, uniques = pd.factorize(np.array(['b', 'b', 'a', 'c', 'b'], dtype=""O""))
>>> codes
array([0, 0, 1, 2, 0])
>>> uniques
array(['b', 'a', 'c'], dtype=object)
",https://pandas.pydata.org/docs/reference/api/pandas.Index.factorize.html, pandas.factorize pandas.array
">>> codes, uniques = pd.factorize(np.array(['b', 'b', 'a', 'c', 'b'], dtype=""O""),
...                               sort=True)
>>> codes
array([1, 1, 0, 2, 1])
>>> uniques
array(['a', 'b', 'c'], dtype=object)
",https://pandas.pydata.org/docs/reference/api/pandas.Index.factorize.html, pandas.factorize pandas.array
">>> codes, uniques = pd.factorize(np.array(['b', None, 'a', 'c', 'b'], dtype=""O""))
>>> codes
array([ 0, -1,  1,  2,  0])
>>> uniques
array(['b', 'a', 'c'], dtype=object)
",https://pandas.pydata.org/docs/reference/api/pandas.Index.factorize.html, pandas.factorize pandas.array
">>> cat = pd.Categorical(['a', 'a', 'c'], categories=['a', 'b', 'c'])
>>> codes, uniques = pd.factorize(cat)
>>> codes
array([0, 0, 1])
>>> uniques
['a', 'c']
Categories (3, object): ['a', 'b', 'c']
",https://pandas.pydata.org/docs/reference/api/pandas.Index.factorize.html, pandas.Categorical pandas.factorize pandas.array
">>> cat = pd.Series(['a', 'a', 'c'])
>>> codes, uniques = pd.factorize(cat)
>>> codes
array([0, 0, 1])
>>> uniques
Index(['a', 'c'], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.Index.factorize.html, pandas.Series pandas.factorize pandas.array pandas.Index
">>> values = np.array([1, 2, 1, np.nan])
>>> codes, uniques = pd.factorize(values)  # default: use_na_sentinel=True
>>> codes
array([ 0,  1,  0, -1])
>>> uniques
array([1., 2.])
",https://pandas.pydata.org/docs/reference/api/pandas.Index.factorize.html, pandas.factorize pandas.array
">>> codes, uniques = pd.factorize(values, use_na_sentinel=False)
>>> codes
array([0, 1, 0, 2])
>>> uniques
array([ 1.,  2., nan])
",https://pandas.pydata.org/docs/reference/api/pandas.Index.factorize.html, pandas.factorize pandas.array
">>> dates = pd.Series(pd.date_range(""2017-12-30"", periods=3))
>>> dates
0   2017-12-30
1   2017-12-31
2   2018-01-01
dtype: datetime64[ns]
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.is_year_start.html, pandas.Series pandas.date_range
">>> idx = pd.date_range(""2017-12-30"", periods=3)
>>> idx
DatetimeIndex(['2017-12-30', '2017-12-31', '2018-01-01'],
              dtype='datetime64[ns]', freq='D')
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.is_year_start.html, pandas.date_range pandas.DatetimeIndex
">>> idx.is_year_start
array([False, False,  True])
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.is_year_start.html, pandas.array
">>> idx = pd.Index([5.2, 6.0, np.nan])
>>> idx
Index([5.2, 6.0, nan], dtype='float64')
>>> idx.isna()
array([False, False,  True])
",https://pandas.pydata.org/docs/reference/api/pandas.Index.isna.html, pandas.Index pandas.Index pandas.array
">>> idx = pd.Index(['black', '', 'red', None])
>>> idx
Index(['black', '', 'red', None], dtype='object')
>>> idx.isna()
array([False, False, False,  True])
",https://pandas.pydata.org/docs/reference/api/pandas.Index.isna.html, pandas.Index pandas.Index pandas.array
">>> idx = pd.DatetimeIndex([pd.Timestamp('1940-04-25'),
...                         pd.Timestamp(''), None, pd.NaT])
>>> idx
DatetimeIndex(['1940-04-25', 'NaT', 'NaT', 'NaT'],
              dtype='datetime64[ns]', freq=None)
>>> idx.isna()
array([False,  True,  True,  True])
",https://pandas.pydata.org/docs/reference/api/pandas.Index.isna.html, pandas.DatetimeIndex pandas.DatetimeIndex pandas.array
">>> df = pd.DataFrame({""key"": [""a"", ""a"", ""b"", ""b""], ""data"": [1, 2, 3, 4]},
...                   columns=[""key"", ""data""])
>>> def incorrect_function(x):
...     return sum(x) * 2.7
>>> df.groupby(""key"").agg(incorrect_function, engine=""numba"")
Traceback (most recent call last):
NumbaUtilError: The first 2 arguments to incorrect_function
must be ['values', 'index']
",https://pandas.pydata.org/docs/reference/api/pandas.errors.NumbaUtilError.html, pandas.DataFrame pandas.DataFrame.groupby
">>> pd.test()  
running: pytest...
",https://pandas.pydata.org/docs/reference/api/pandas.test.html, pandas.test
">>> idx = pd.Index(['car', 'bike', 'train', 'tractor'])
>>> idx
Index(['car', 'bike', 'train', 'tractor'], dtype='object')
>>> idx.where(idx.isin(['car', 'train']), 'other')
Index(['car', 'other', 'train', 'other'], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.Index.where.html, pandas.Index pandas.Index pandas.Index.isin
">>> idx = pd.DatetimeIndex(['2023-01-01', '2023-01-02',
...                        '2023-02-01', '2023-02-02'])
>>> idx
DatetimeIndex(['2023-01-01', '2023-01-02', '2023-02-01', '2023-02-02'],
dtype='datetime64[ns]', freq=None)
>>> idx.snap('MS')
DatetimeIndex(['2023-01-01', '2023-01-01', '2023-02-01', '2023-02-01'],
dtype='datetime64[ns]', freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.snap.html, pandas.DatetimeIndex pandas.DatetimeIndex pandas.DatetimeIndex.snap
">>> idx = pd.Index([1, 5, 7, 7])
>>> idx.is_unique
False
",https://pandas.pydata.org/docs/reference/api/pandas.Index.is_unique.html, pandas.Index
">>> idx = pd.Index([1, 5, 7])
>>> idx.is_unique
True
",https://pandas.pydata.org/docs/reference/api/pandas.Index.is_unique.html, pandas.Index
">>> idx = pd.Index([""Watermelon"", ""Orange"", ""Apple"",
...                 ""Watermelon""]).astype(""category"")
>>> idx.is_unique
False
",https://pandas.pydata.org/docs/reference/api/pandas.Index.is_unique.html, pandas.Index
">>> idx = pd.Index([""Orange"", ""Apple"",
...                 ""Watermelon""]).astype(""category"")
>>> idx.is_unique
True
",https://pandas.pydata.org/docs/reference/api/pandas.Index.is_unique.html, pandas.Index
">>> s = pd.Series([0, 1, 2], index=['a', 'b', 'c']).set_flags(
...     allows_duplicate_labels=False
... )
>>> s.reindex(['a', 'a', 'b'])
Traceback (most recent call last):
   ...
DuplicateLabelError: Index has duplicates.
      positions
label
a        [0, 1]
",https://pandas.pydata.org/docs/reference/api/pandas.errors.DuplicateLabelError.html, pandas.Series pandas.Series.reindex
">>> from pandas import testing as tm
>>> a = pd.Series([1, 2, 3, 4])
>>> b = pd.Series([1, 2, 3, 4])
>>> tm.assert_series_equal(a, b)
",https://pandas.pydata.org/docs/reference/api/pandas.testing.assert_series_equal.html, pandas.Series
">>> from pandas.api.types import is_unsigned_integer_dtype
>>> is_unsigned_integer_dtype(str)
False
>>> is_unsigned_integer_dtype(int)  # signed
False
>>> is_unsigned_integer_dtype(float)
False
>>> is_unsigned_integer_dtype(np.uint64)
True
>>> is_unsigned_integer_dtype('uint8')
True
>>> is_unsigned_integer_dtype('UInt8')
True
>>> is_unsigned_integer_dtype(pd.UInt8Dtype)
True
>>> is_unsigned_integer_dtype(np.array(['a', 'b']))
False
>>> is_unsigned_integer_dtype(pd.Series([1, 2]))  # signed
False
>>> is_unsigned_integer_dtype(pd.Index([1, 2.]))  # float
False
>>> is_unsigned_integer_dtype(np.array([1, 2], dtype=np.uint32))
True
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_unsigned_integer_dtype.html, pandas.api.types.is_unsigned_integer_dtype pandas.Series pandas.Index
">>> idx = pd.Index([np.nan, 'var1', np.nan])
>>> idx.get_indexer_for([np.nan])
array([0, 2])
",https://pandas.pydata.org/docs/reference/api/pandas.Index.get_indexer_for.html, pandas.Index pandas.array
">>> from pandas import testing as tm
>>> a = pd.Series([1, 2, 3, 4])
>>> b, c = a.array, a.array
>>> tm.assert_extension_array_equal(b, c)
",https://pandas.pydata.org/docs/reference/api/pandas.testing.assert_extension_array_equal.html, pandas.Series
">>> class Foo:
...     @classmethod
...     def classmethod(cls):
...         raise pd.errors.AbstractMethodError(cls, methodtype=""classmethod"")
...     def method(self):
...         raise pd.errors.AbstractMethodError(self)
>>> test = Foo.classmethod()
Traceback (most recent call last):
AbstractMethodError: This classmethod must be defined in the concrete class Foo
",https://pandas.pydata.org/docs/reference/api/pandas.errors.AbstractMethodError.html, pandas.errors.AbstractMethodError
">>> df = pd.DataFrame({'A': [1, 1, 1, 2, 2],
...                    'B': range(5),
...                    'C': range(5)})
>>> df.groupby('A').B.agg({'foo': 'count'}) 
... # SpecificationError: nested renamer is not supported
",https://pandas.pydata.org/docs/reference/api/pandas.errors.SpecificationError.html, pandas.DataFrame pandas.DataFrame.groupby
">>> df.groupby('A').agg({'B': {'foo': ['sum', 'max']}}) 
... # SpecificationError: nested renamer is not supported
",https://pandas.pydata.org/docs/reference/api/pandas.errors.SpecificationError.html, pandas.DataFrame.groupby
">>> df.groupby('A').agg(['min', 'min']) 
... # SpecificationError: nested renamer is not supported
",https://pandas.pydata.org/docs/reference/api/pandas.errors.SpecificationError.html, pandas.DataFrame.groupby
">>> pd.show_versions()  
Your output may look something like this:
INSTALLED VERSIONS
------------------
commit           : 37ea63d540fd27274cad6585082c91b1283f963d
python           : 3.10.6.final.0
python-bits      : 64
OS               : Linux
OS-release       : 5.10.102.1-microsoft-standard-WSL2
Version          : #1 SMP Wed Mar 2 00:30:59 UTC 2022
machine          : x86_64
processor        : x86_64
byteorder        : little
LC_ALL           : None
LANG             : en_GB.UTF-8
LOCALE           : en_GB.UTF-8
pandas           : 2.0.1
numpy            : 1.24.3
...
",https://pandas.pydata.org/docs/reference/api/pandas.show_versions.html, pandas.show_versions
">>> s = pd.Series([1, 2, 3])
>>> s.to_list()
[1, 2, 3]
",https://pandas.pydata.org/docs/reference/api/pandas.Index.to_list.html, pandas.Series pandas.Series.to_list
">>> idx = pd.Index([1, 2, 3])
>>> idx
Index([1, 2, 3], dtype='int64')
",https://pandas.pydata.org/docs/reference/api/pandas.Index.to_list.html, pandas.Index pandas.Index
">>> idx.to_list()
[1, 2, 3]
",https://pandas.pydata.org/docs/reference/api/pandas.Index.to_list.html, pandas.Index.to_list
">>> ts.tz_convert(tz='Asia/Tokyo')
Timestamp('2020-03-15 00:32:52.192548651+0900', tz='Asia/Tokyo')
",https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.tz_convert.html, pandas.DataFrame.tz_convert
">>> pd.options.mode.chained_assignment = 'raise'
>>> df = pd.DataFrame({'A': [1, 1, 1, 2, 2]}, columns=['A'])
>>> df.loc[0:3]['A'] = 'a' 
... # SettingWithCopyError: A value is trying to be set on a copy of a...
",https://pandas.pydata.org/docs/reference/api/pandas.errors.SettingWithCopyError.html, pandas.DataFrame
">>> import io
>>> csv = '''a;b;c
...           1;1,8
...           1;2,1'''
>>> df = pd.read_csv(io.StringIO(csv), sep='[;,]')  
... # ParserWarning: Falling back to the 'python' engine...
",https://pandas.pydata.org/docs/reference/api/pandas.errors.ParserWarning.html, pandas.read_csv
">>> df = pd.read_csv(io.StringIO(csv), sep='[;,]', engine='python')
",https://pandas.pydata.org/docs/reference/api/pandas.errors.ParserWarning.html, pandas.read_csv
">>> i1 = pd.Interval(0, 2)
>>> i2 = pd.Interval(1, 3)
>>> i1.overlaps(i2)
True
>>> i3 = pd.Interval(4, 5)
>>> i1.overlaps(i3)
False
",https://pandas.pydata.org/docs/reference/api/pandas.Interval.overlaps.html, pandas.Interval pandas.Interval.overlaps
">>> i4 = pd.Interval(0, 1, closed='both')
>>> i5 = pd.Interval(1, 2, closed='both')
>>> i4.overlaps(i5)
True
",https://pandas.pydata.org/docs/reference/api/pandas.Interval.overlaps.html, pandas.Interval pandas.Interval.overlaps
">>> i6 = pd.Interval(1, 2, closed='neither')
>>> i4.overlaps(i6)
False
",https://pandas.pydata.org/docs/reference/api/pandas.Interval.overlaps.html, pandas.Interval pandas.Interval.overlaps
">>> df = pd.DataFrame({'A': [1, 1, 1]})
>>> df.style.applymap(
...     lambda x: 'background-color: blueGreenRed;'
... ).to_excel('styled.xlsx')  
CSSWarning: Unhandled color format: 'blueGreenRed'
>>> df.style.applymap(
...     lambda x: 'border: 1px solid red red;'
... ).to_excel('styled.xlsx')  
CSSWarning: Unhandled color format: 'blueGreenRed'
",https://pandas.pydata.org/docs/reference/api/pandas.errors.CSSWarning.html, pandas.DataFrame
">>> from pandas.api.types import is_categorical_dtype
>>> from pandas import CategoricalDtype
>>> is_categorical_dtype(object)
False
>>> is_categorical_dtype(CategoricalDtype())
True
>>> is_categorical_dtype([1, 2, 3])
False
>>> is_categorical_dtype(pd.Categorical([1, 2, 3]))
True
>>> is_categorical_dtype(pd.CategoricalIndex([1, 2, 3]))
True
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_categorical_dtype.html, pandas.api.types.is_categorical_dtype pandas.CategoricalDtype pandas.Categorical pandas.CategoricalIndex
">>> idx = pd.PeriodIndex([""2023-01-01 10:00"", ""2023-01-01 11:00""], freq='h')
>>> idx.hour
Index([10, 11], dtype='int64')
",https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.hour.html, pandas.PeriodIndex pandas.Index
">>> period = pd.Period('2012-1-1', freq='D')
>>> period
Period('2012-01-01', 'D')
",https://pandas.pydata.org/docs/reference/api/pandas.Period.start_time.html, pandas.Period pandas.Period
">>> mi = pd.MultiIndex.from_arrays([['a'], ['b']])
>>> mi
MultiIndex([('a', 'b')],
           )
>>> mi.append(mi)
MultiIndex([('a', 'b'), ('a', 'b')],
           )
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.append.html, pandas.MultiIndex.from_arrays pandas.MultiIndex pandas.MultiIndex.append
">>> ser = pd.Series(['a', 'b', 'c'])
>>> ser.rolling(2).sum()
Traceback (most recent call last):
DataError: No numeric types to aggregate
",https://pandas.pydata.org/docs/reference/api/pandas.errors.DataError.html, pandas.Series pandas.Series.rolling
">>> period = pd.Period('2022-01', 'M')
>>> period.year
2022
",https://pandas.pydata.org/docs/reference/api/pandas.Period.year.html, pandas.Period
">>> df = pd.DataFrame({'A': [1, 1, 1]})
>>> df.query(""A > x"") 
... # UndefinedVariableError: name 'x' is not defined
>>> df.query(""A > @y"") 
... # UndefinedVariableError: local variable 'y' is not defined
>>> pd.eval('x + 1') 
... # UndefinedVariableError: name 'x' is not defined
",https://pandas.pydata.org/docs/reference/api/pandas.errors.UndefinedVariableError.html, pandas.DataFrame pandas.DataFrame.query pandas.eval
">>> pd.date_range(start=""1/1/1700"", freq=""B"", periods=100000)
Traceback (most recent call last):
OutOfBoundsTimedelta: Cannot cast 139999 days 00:00:00
to unit='ns' without overflow.
",https://pandas.pydata.org/docs/reference/api/pandas.errors.OutOfBoundsTimedelta.html, pandas.date_range
">>> left = pd.DataFrame({""a"": [""a"", ""b"", ""b"", ""d""],
...                     ""b"": [""cat"", ""dog"", ""weasel"", ""horse""]},
...                     index=range(4))
>>> right = pd.DataFrame({""a"": [""a"", ""b"", ""c"", ""d""],
...                      ""c"": [""meow"", ""bark"", ""chirp"", ""nay""]},
...                      index=range(4)).set_index(""a"")
>>> left.join(right, on=""a"", validate=""one_to_one"",)
Traceback (most recent call last):
MergeError: Merge keys are not unique in left dataset; not a one-to-one merge
",https://pandas.pydata.org/docs/reference/api/pandas.errors.MergeError.html, pandas.DataFrame pandas.DataFrame.set_index pandas.DataFrame.join
">>> index = pd.Index(['c', 'a', 'b'])
>>> index.get_indexer(['a', 'b', 'x'])
array([ 1,  2, -1])
",https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.get_indexer.html, pandas.Index pandas.array
">>> df = pd.DataFrame({""jim"": [0, 0, 1, 1],
...                    ""joe"": [""x"", ""x"", ""z"", ""y""],
...                    ""jolie"": [1, 2, 3, 4]})
>>> df = df.set_index([""jim"", ""joe""])
>>> df
          jolie
jim  joe
0    x    1
     x    2
1    z    3
     y    4
>>> df.loc[(1, 'z')]  
# PerformanceWarning: indexing past lexsort depth may impact performance.
df.loc[(1, 'z')]
          jolie
jim  joe
1    z        3
",https://pandas.pydata.org/docs/reference/api/pandas.errors.PerformanceWarning.html, pandas.DataFrame pandas.DataFrame.set_index
">>> pd.array(['a', 'b'], dtype=str)

['a', 'b']
Length: 2, dtype: str32
",https://pandas.pydata.org/docs/reference/api/pandas.array.html, pandas.array
">>> pd.array(['a', 'b'], dtype=np.dtype(""))

['a', 'b']
Length: 2, dtype: str32
",https://pandas.pydata.org/docs/reference/api/pandas.array.html, pandas.array
">>> pd.array(['2015', '2016'], dtype='datetime64[ns]')

['2015-01-01 00:00:00', '2016-01-01 00:00:00']
Length: 2, dtype: datetime64[ns]
",https://pandas.pydata.org/docs/reference/api/pandas.array.html, pandas.array
">>> pd.array([""1h"", ""2h""], dtype='timedelta64[ns]')

['0 days 01:00:00', '0 days 02:00:00']
Length: 2, dtype: timedelta64[ns]
",https://pandas.pydata.org/docs/reference/api/pandas.array.html, pandas.array
">>> pd.array([1, 2])

[1, 2]
Length: 2, dtype: Int64
",https://pandas.pydata.org/docs/reference/api/pandas.array.html, pandas.array
">>> pd.array([1, 2, np.nan])

[1, 2, ]
Length: 3, dtype: Int64
",https://pandas.pydata.org/docs/reference/api/pandas.array.html, pandas.array
">>> pd.array([1.1, 2.2])

[1.1, 2.2]
Length: 2, dtype: Float64
",https://pandas.pydata.org/docs/reference/api/pandas.array.html, pandas.array
">>> pd.array([""a"", None, ""c""])

['a', , 'c']
Length: 3, dtype: string
",https://pandas.pydata.org/docs/reference/api/pandas.array.html, pandas.array
">>> with pd.option_context(""string_storage"", ""pyarrow""):
...     arr = pd.array([""a"", None, ""c""])
...
>>> arr

['a', , 'c']
Length: 3, dtype: string
",https://pandas.pydata.org/docs/reference/api/pandas.array.html, pandas.array
">>> pd.array([pd.Period('2000', freq=""D""), pd.Period(""2000"", freq=""D"")])

['2000-01-01', '2000-01-01']
Length: 2, dtype: period[D]
",https://pandas.pydata.org/docs/reference/api/pandas.array.html, pandas.array pandas.Period
">>> pd.array(['a', 'b', 'a'], dtype='category')
['a', 'b', 'a']
Categories (2, object): ['a', 'b']
",https://pandas.pydata.org/docs/reference/api/pandas.array.html, pandas.array
">>> pd.array(['a', 'b', 'a'],
...          dtype=pd.CategoricalDtype(['a', 'b', 'c'], ordered=True))
['a', 'b', 'a']
Categories (3, object): ['a' < 'b' < 'c']
",https://pandas.pydata.org/docs/reference/api/pandas.array.html, pandas.array pandas.CategoricalDtype
">>> pd.array([1 + 1j, 3 + 2j])

[(1+1j), (3+2j)]
Length: 2, dtype: complex128
",https://pandas.pydata.org/docs/reference/api/pandas.array.html, pandas.array
">>> pd.array([1, 2], dtype=np.dtype(""int32""))

[1, 2]
Length: 2, dtype: int32
",https://pandas.pydata.org/docs/reference/api/pandas.array.html, pandas.array
">>> pd.array(1)
Traceback (most recent call last):
  ...
ValueError: Cannot pass scalar '1' to 'pandas.array'.
",https://pandas.pydata.org/docs/reference/api/pandas.array.html, pandas.array
">>> ts.replace(year=1999, hour=10)
Timestamp('1999-03-14 10:32:52.192548651+0000', tz='UTC')
",https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.replace.html, pandas.DataFrame.replace
">>> import pytz
>>> ts.replace(tzinfo=pytz.timezone('US/Pacific'))
Timestamp('2020-03-14 15:32:52.192548651-0700', tz='US/Pacific')
",https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.replace.html, pandas.DataFrame.replace
">>> period = pd.Period(""2015-10-23"", freq='h')
>>> period.day_of_year
296
>>> period = pd.Period(""2012-12-31"", freq='D')
>>> period.day_of_year
366
>>> period = pd.Period(""2013-01-01"", freq='D')
>>> period.day_of_year
1
",https://pandas.pydata.org/docs/reference/api/pandas.Period.day_of_year.html, pandas.Period
">>> from io import StringIO
>>> empty = StringIO()
>>> pd.read_csv(empty)
Traceback (most recent call last):
EmptyDataError: No columns to parse from file
",https://pandas.pydata.org/docs/reference/api/pandas.errors.EmptyDataError.html, pandas.read_csv
">>> pd.array(['This is', 'some text', None, 'data.'], dtype=""string"")

['This is', 'some text', , 'data.']
Length: 4, dtype: string
",https://pandas.pydata.org/docs/reference/api/pandas.arrays.StringArray.html, pandas.array
">>> pd.array(['1', 1], dtype=""object"")

['1', 1]
Length: 2, dtype: object
>>> pd.array(['1', 1], dtype=""string"")

['1', '1']
Length: 2, dtype: string
",https://pandas.pydata.org/docs/reference/api/pandas.arrays.StringArray.html, pandas.array
">>> pd.array([""a"", None, ""c""], dtype=""string"") == ""a""

[True, , False]
Length: 3, dtype: boolean
",https://pandas.pydata.org/docs/reference/api/pandas.arrays.StringArray.html, pandas.array
">>> from pandas.api.types import is_number
>>> is_number(1)
True
>>> is_number(7.15)
True
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_number.html, pandas.api.types.is_number
">>> is_number(False)
True
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_number.html, pandas.api.types.is_number
">>> is_number(""foo"")
False
>>> is_number(""5"")
False
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_number.html, pandas.api.types.is_number
">>> pd.api.types.is_bool(True)
True
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_bool.html, pandas.api.types.is_bool
">>> pd.api.types.is_bool(1)
False
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_bool.html, pandas.api.types.is_bool
">>> ts = pd.Timestamp('2023-01-01 10:00:00.00')
>>> ts
Timestamp('2023-01-01 10:00:00')
>>> ts.date()
datetime.date(2023, 1, 1)
",https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.date.html, pandas.Timestamp.date
">>> df = pd.DataFrame({'A': [1, 1, 1]})
>>> df.loc[..., ..., 'A'] 
... # IndexingError: indexer may only contain one '...' entry
>>> df = pd.DataFrame({'A': [1, 1, 1]})
>>> df.loc[1, ..., ...] 
... # IndexingError: Too many indexers
>>> df[pd.Series([True], dtype=bool)] 
... # IndexingError: Unalignable boolean Series provided as indexer...
>>> s = pd.Series(range(2),
...               index = pd.MultiIndex.from_product([[""a"", ""b""], [""c""]]))
>>> s.loc[""a"", ""c"", ""d""] 
... # IndexingError: Too many indexers
",https://pandas.pydata.org/docs/reference/api/pandas.errors.IndexingError.html, pandas.DataFrame pandas.Series pandas.MultiIndex.from_product
">>> mi = pd.MultiIndex.from_arrays([list('abb'), list('def')])
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.get_locs.html, pandas.MultiIndex.from_arrays
">>> mi.get_locs('b')  
array([1, 2], dtype=int64)
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.get_locs.html, pandas.MultiIndex.get_locs pandas.array
">>> mi.get_locs([slice(None), ['e', 'f']])  
array([1, 2], dtype=int64)
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.get_locs.html, pandas.MultiIndex.get_locs pandas.Series.str.slice pandas.array
">>> mi.get_locs([[True, False, True], slice('e', 'f')])  
array([2], dtype=int64)
",https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.get_locs.html, pandas.MultiIndex.get_locs pandas.Series.str.slice pandas.array
">>> df = pd.DataFrame({'abs': [1, 1, 1]})
>>> df.query(""abs > 2"") 
... # NumExprClobberingError: Variables in expression ""(abs) > (2)"" overlap...
>>> sin, a = 1, 2
>>> pd.eval(""sin + a"", engine='numexpr') 
... # NumExprClobberingError: Variables in expression ""(sin) + (a)"" overlap...
",https://pandas.pydata.org/docs/reference/api/pandas.errors.NumExprClobberingError.html, pandas.DataFrame pandas.DataFrame.query pandas.eval
">>> p = pd.Period(""2018-03-11 13:03:12.050000"")
>>> p.second
12
",https://pandas.pydata.org/docs/reference/api/pandas.Period.second.html, pandas.Period
">>> from pandas.api.types import is_numeric_dtype
>>> is_numeric_dtype(str)
False
>>> is_numeric_dtype(int)
True
>>> is_numeric_dtype(float)
True
>>> is_numeric_dtype(np.uint64)
True
>>> is_numeric_dtype(np.datetime64)
False
>>> is_numeric_dtype(np.timedelta64)
False
>>> is_numeric_dtype(np.array(['a', 'b']))
False
>>> is_numeric_dtype(pd.Series([1, 2]))
True
>>> is_numeric_dtype(pd.Index([1, 2.]))
True
>>> is_numeric_dtype(np.array([], dtype=np.timedelta64))
False
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_numeric_dtype.html, pandas.api.types.is_numeric_dtype pandas.Series pandas.Index
">>> ser = pd.Series([2, pd.NA], dtype=pd.Int8Dtype())
>>> ser.dtype
Int8Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.UInt64Dtype.html, pandas.Series pandas.Int8Dtype pandas.Int8Dtype
">>> ser = pd.Series([2, pd.NA], dtype=pd.Int16Dtype())
>>> ser.dtype
Int16Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.UInt64Dtype.html, pandas.Series pandas.Int16Dtype pandas.Int16Dtype
">>> ser = pd.Series([2, pd.NA], dtype=pd.Int32Dtype())
>>> ser.dtype
Int32Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.UInt64Dtype.html, pandas.Series pandas.Int32Dtype pandas.Int32Dtype
">>> ser = pd.Series([2, pd.NA], dtype=pd.Int64Dtype())
>>> ser.dtype
Int64Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.UInt64Dtype.html, pandas.Series pandas.Int64Dtype pandas.Int64Dtype
">>> ser = pd.Series([2, pd.NA], dtype=pd.UInt8Dtype())
>>> ser.dtype
UInt8Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.UInt64Dtype.html, pandas.Series pandas.UInt8Dtype pandas.UInt8Dtype
">>> ser = pd.Series([2, pd.NA], dtype=pd.UInt16Dtype())
>>> ser.dtype
UInt16Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.UInt64Dtype.html, pandas.Series pandas.UInt16Dtype pandas.UInt16Dtype
">>> ser = pd.Series([2, pd.NA], dtype=pd.UInt32Dtype())
>>> ser.dtype
UInt32Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.UInt64Dtype.html, pandas.Series pandas.UInt32Dtype pandas.UInt32Dtype
">>> ser = pd.Series([2, pd.NA], dtype=pd.UInt64Dtype())
>>> ser.dtype
UInt64Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.UInt64Dtype.html, pandas.Series pandas.UInt64Dtype pandas.UInt64Dtype
">>> p = pd.Period(""2018-03-11"", ""h"")
>>> p.weekofyear
10
",https://pandas.pydata.org/docs/reference/api/pandas.Period.weekofyear.html, pandas.Period
">>> p = pd.Period(""2018-02-01"", ""D"")
>>> p.weekofyear
5
",https://pandas.pydata.org/docs/reference/api/pandas.Period.weekofyear.html, pandas.Period
">>> p = pd.Period(""2018-01-06"", ""D"")
>>> p.weekofyear
1
",https://pandas.pydata.org/docs/reference/api/pandas.Period.weekofyear.html, pandas.Period
">>> period = pd.Period('2023-1-1', freq='D')
>>> timestamp = period.to_timestamp()
>>> timestamp
Timestamp('2023-01-01 00:00:00')
",https://pandas.pydata.org/docs/reference/api/pandas.Period.to_timestamp.html, pandas.Period pandas.Period.to_timestamp
">>> per = pd.Period('2017-12-31 22:00', 'h')
>>> per.day_of_week
6
",https://pandas.pydata.org/docs/reference/api/pandas.Period.day_of_week.html, pandas.Period
">>> per = pd.Period('2017-12-31 22:00', '4h')
>>> per.day_of_week
6
>>> per.start_time.day_of_week
6
",https://pandas.pydata.org/docs/reference/api/pandas.Period.day_of_week.html, pandas.Period
">>> per = pd.Period('2018-01', 'M')
>>> per.day_of_week
2
>>> per.end_time.day_of_week
2
",https://pandas.pydata.org/docs/reference/api/pandas.Period.day_of_week.html, pandas.Period
">>> pd.Timestamp.utcnow()   
Timestamp('2020-11-16 22:50:18.092888+0000', tz='UTC')
",https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.utcnow.html, pandas.Timestamp.utcnow
">>> period = pd.Period('2012-1-1', freq='D')
>>> period
Period('2012-01-01', 'D')
",https://pandas.pydata.org/docs/reference/api/pandas.Period.html, pandas.Period pandas.Period
">>> iv = pd.Interval(0, 5)
>>> iv.mid
2.5
",https://pandas.pydata.org/docs/reference/api/pandas.Interval.mid.html, pandas.Interval
">>> from pandas.api.types import is_object_dtype
>>> is_object_dtype(object)
True
>>> is_object_dtype(int)
False
>>> is_object_dtype(np.array([], dtype=object))
True
>>> is_object_dtype(np.array([], dtype=int))
False
>>> is_object_dtype([1, 2, 3])
False
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_object_dtype.html, pandas.api.types.is_object_dtype
">>> per = pd.Period('2017-12-31 22:00', 'h')
>>> per.day_of_week
6
",https://pandas.pydata.org/docs/reference/api/pandas.Period.dayofweek.html, pandas.Period
">>> per = pd.Period('2017-12-31 22:00', '4h')
>>> per.day_of_week
6
>>> per.start_time.day_of_week
6
",https://pandas.pydata.org/docs/reference/api/pandas.Period.dayofweek.html, pandas.Period
">>> per = pd.Period('2018-01', 'M')
>>> per.day_of_week
2
>>> per.end_time.day_of_week
2
",https://pandas.pydata.org/docs/reference/api/pandas.Period.dayofweek.html, pandas.Period
">>> ser = pd.Series([2, pd.NA], dtype=pd.Int8Dtype())
>>> ser.dtype
Int8Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.UInt8Dtype.html, pandas.Series pandas.Int8Dtype pandas.Int8Dtype
">>> ser = pd.Series([2, pd.NA], dtype=pd.Int16Dtype())
>>> ser.dtype
Int16Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.UInt8Dtype.html, pandas.Series pandas.Int16Dtype pandas.Int16Dtype
">>> ser = pd.Series([2, pd.NA], dtype=pd.Int32Dtype())
>>> ser.dtype
Int32Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.UInt8Dtype.html, pandas.Series pandas.Int32Dtype pandas.Int32Dtype
">>> ser = pd.Series([2, pd.NA], dtype=pd.Int64Dtype())
>>> ser.dtype
Int64Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.UInt8Dtype.html, pandas.Series pandas.Int64Dtype pandas.Int64Dtype
">>> ser = pd.Series([2, pd.NA], dtype=pd.UInt8Dtype())
>>> ser.dtype
UInt8Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.UInt8Dtype.html, pandas.Series pandas.UInt8Dtype pandas.UInt8Dtype
">>> ser = pd.Series([2, pd.NA], dtype=pd.UInt16Dtype())
>>> ser.dtype
UInt16Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.UInt8Dtype.html, pandas.Series pandas.UInt16Dtype pandas.UInt16Dtype
">>> ser = pd.Series([2, pd.NA], dtype=pd.UInt32Dtype())
>>> ser.dtype
UInt32Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.UInt8Dtype.html, pandas.Series pandas.UInt32Dtype pandas.UInt32Dtype
">>> ser = pd.Series([2, pd.NA], dtype=pd.UInt64Dtype())
>>> ser.dtype
UInt64Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.UInt8Dtype.html, pandas.Series pandas.UInt64Dtype pandas.UInt64Dtype
">>> p = pd.Period(""2018-03-11"", ""h"")
>>> p.week
10
",https://pandas.pydata.org/docs/reference/api/pandas.Period.week.html, pandas.Period
">>> p = pd.Period(""2018-02-01"", ""D"")
>>> p.week
5
",https://pandas.pydata.org/docs/reference/api/pandas.Period.week.html, pandas.Period
">>> p = pd.Period(""2018-01-06"", ""D"")
>>> p.week
1
",https://pandas.pydata.org/docs/reference/api/pandas.Period.week.html, pandas.Period
">>> pd.PeriodDtype(freq='D')
period[D]
",https://pandas.pydata.org/docs/reference/api/pandas.PeriodDtype.html, pandas.PeriodDtype
">>> pd.PeriodDtype(freq=pd.offsets.MonthEnd())
period[M]
",https://pandas.pydata.org/docs/reference/api/pandas.PeriodDtype.html, pandas.PeriodDtype
">>> td = pd.Timedelta('1001ms')
>>> td
Timedelta('0 days 00:00:01.001000')
>>> td.round('s')
Timedelta('0 days 00:00:01')
",https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.round.html, pandas.Series.round
">>> iv = pd.Interval(0, 5, closed='left')
>>> iv.closed_left
True
",https://pandas.pydata.org/docs/reference/api/pandas.Interval.closed_left.html, pandas.Interval
">>> iv = pd.Interval(0, 5, closed='right')
>>> iv.closed_left
False
",https://pandas.pydata.org/docs/reference/api/pandas.Interval.closed_left.html, pandas.Interval
">>> pd.array(['This is', 'some text', None, 'data.'], dtype=""string[pyarrow]"")

['This is', 'some text', , 'data.']
Length: 4, dtype: string
",https://pandas.pydata.org/docs/reference/api/pandas.arrays.ArrowStringArray.html, pandas.array
">>> interval = pd.Interval(left=1, right=2, closed='left')
>>> interval
Interval(1, 2, closed='left')
>>> interval.closed
'left'
",https://pandas.pydata.org/docs/reference/api/pandas.Interval.closed.html, pandas.Interval pandas.Interval
">>> pd.Interval(0, 1, closed='right').is_empty
False
",https://pandas.pydata.org/docs/reference/api/pandas.Interval.is_empty.html, pandas.Interval
">>> pd.Interval(0, 0, closed='right').is_empty
True
>>> pd.Interval(0, 0, closed='left').is_empty
True
>>> pd.Interval(0, 0, closed='neither').is_empty
True
",https://pandas.pydata.org/docs/reference/api/pandas.Interval.is_empty.html, pandas.Interval
">>> pd.Interval(0, 0, closed='both').is_empty
False
",https://pandas.pydata.org/docs/reference/api/pandas.Interval.is_empty.html, pandas.Interval
">>> ivs = [pd.Interval(0, 0, closed='neither'),
...        pd.Interval(1, 2, closed='neither')]
>>> pd.arrays.IntervalArray(ivs).is_empty
array([ True, False])
",https://pandas.pydata.org/docs/reference/api/pandas.Interval.is_empty.html, pandas.Interval pandas.arrays.IntervalArray pandas.array
">>> ivs = [pd.Interval(0, 0, closed='neither'), np.nan]
>>> pd.IntervalIndex(ivs).is_empty
array([ True, False])
",https://pandas.pydata.org/docs/reference/api/pandas.Interval.is_empty.html, pandas.Interval pandas.IntervalIndex pandas.array
">>> ser = pd.Series([2, pd.NA], dtype=pd.Int8Dtype())
>>> ser.dtype
Int8Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.UInt16Dtype.html, pandas.Series pandas.Int8Dtype pandas.Int8Dtype
">>> ser = pd.Series([2, pd.NA], dtype=pd.Int16Dtype())
>>> ser.dtype
Int16Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.UInt16Dtype.html, pandas.Series pandas.Int16Dtype pandas.Int16Dtype
">>> ser = pd.Series([2, pd.NA], dtype=pd.Int32Dtype())
>>> ser.dtype
Int32Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.UInt16Dtype.html, pandas.Series pandas.Int32Dtype pandas.Int32Dtype
">>> ser = pd.Series([2, pd.NA], dtype=pd.Int64Dtype())
>>> ser.dtype
Int64Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.UInt16Dtype.html, pandas.Series pandas.Int64Dtype pandas.Int64Dtype
">>> ser = pd.Series([2, pd.NA], dtype=pd.UInt8Dtype())
>>> ser.dtype
UInt8Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.UInt16Dtype.html, pandas.Series pandas.UInt8Dtype pandas.UInt8Dtype
">>> ser = pd.Series([2, pd.NA], dtype=pd.UInt16Dtype())
>>> ser.dtype
UInt16Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.UInt16Dtype.html, pandas.Series pandas.UInt16Dtype pandas.UInt16Dtype
">>> ser = pd.Series([2, pd.NA], dtype=pd.UInt32Dtype())
>>> ser.dtype
UInt32Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.UInt16Dtype.html, pandas.Series pandas.UInt32Dtype pandas.UInt32Dtype
">>> ser = pd.Series([2, pd.NA], dtype=pd.UInt64Dtype())
>>> ser.dtype
UInt64Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.UInt16Dtype.html, pandas.Series pandas.UInt64Dtype pandas.UInt64Dtype
">>> from pandas.api.types import is_re
>>> import re
>>> is_re(re.compile("".*""))
True
>>> is_re(""foo"")
False
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_re.html, pandas.api.types.is_re
">>> p = pd.Period('2018-2-17')
>>> p.days_in_month
28
",https://pandas.pydata.org/docs/reference/api/pandas.Period.days_in_month.html, pandas.Period
">>> pd.Period('2018-03-01').days_in_month
31
",https://pandas.pydata.org/docs/reference/api/pandas.Period.days_in_month.html, pandas.Period
">>> p = pd.Period('2016-2-17')
>>> p.days_in_month
29
",https://pandas.pydata.org/docs/reference/api/pandas.Period.days_in_month.html, pandas.Period
">>> ser = pd.Series([2, pd.NA], dtype=pd.Int8Dtype())
>>> ser.dtype
Int8Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.Int32Dtype.html, pandas.Series pandas.Int8Dtype pandas.Int8Dtype
">>> ser = pd.Series([2, pd.NA], dtype=pd.Int16Dtype())
>>> ser.dtype
Int16Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.Int32Dtype.html, pandas.Series pandas.Int16Dtype pandas.Int16Dtype
">>> ser = pd.Series([2, pd.NA], dtype=pd.Int32Dtype())
>>> ser.dtype
Int32Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.Int32Dtype.html, pandas.Series pandas.Int32Dtype pandas.Int32Dtype
">>> ser = pd.Series([2, pd.NA], dtype=pd.Int64Dtype())
>>> ser.dtype
Int64Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.Int32Dtype.html, pandas.Series pandas.Int64Dtype pandas.Int64Dtype
">>> ser = pd.Series([2, pd.NA], dtype=pd.UInt8Dtype())
>>> ser.dtype
UInt8Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.Int32Dtype.html, pandas.Series pandas.UInt8Dtype pandas.UInt8Dtype
">>> ser = pd.Series([2, pd.NA], dtype=pd.UInt16Dtype())
>>> ser.dtype
UInt16Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.Int32Dtype.html, pandas.Series pandas.UInt16Dtype pandas.UInt16Dtype
">>> ser = pd.Series([2, pd.NA], dtype=pd.UInt32Dtype())
>>> ser.dtype
UInt32Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.Int32Dtype.html, pandas.Series pandas.UInt32Dtype pandas.UInt32Dtype
">>> ser = pd.Series([2, pd.NA], dtype=pd.UInt64Dtype())
>>> ser.dtype
UInt64Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.Int32Dtype.html, pandas.Series pandas.UInt64Dtype pandas.UInt64Dtype
">>> pd.Categorical([1, 2, 3, 1, 2, 3])
[1, 2, 3, 1, 2, 3]
Categories (3, int64): [1, 2, 3]
",https://pandas.pydata.org/docs/reference/api/pandas.Categorical.html, pandas.Categorical
">>> pd.Categorical(['a', 'b', 'c', 'a', 'b', 'c'])
['a', 'b', 'c', 'a', 'b', 'c']
Categories (3, object): ['a', 'b', 'c']
",https://pandas.pydata.org/docs/reference/api/pandas.Categorical.html, pandas.Categorical
">>> c = pd.Categorical([1, 2, 3, 1, 2, 3, np.nan])
>>> c
[1, 2, 3, 1, 2, 3, NaN]
Categories (3, int64): [1, 2, 3]
",https://pandas.pydata.org/docs/reference/api/pandas.Categorical.html, pandas.Categorical
">>> c.codes
array([ 0,  1,  2,  0,  1,  2, -1], dtype=int8)
",https://pandas.pydata.org/docs/reference/api/pandas.Categorical.html, pandas.array
">>> c = pd.Categorical(['a', 'b', 'c', 'a', 'b', 'c'], ordered=True,
...                    categories=['c', 'b', 'a'])
>>> c
['a', 'b', 'c', 'a', 'b', 'c']
Categories (3, object): ['c' < 'b' < 'a']
>>> c.min()
'c'
",https://pandas.pydata.org/docs/reference/api/pandas.Categorical.html, pandas.Categorical
">>> import io
>>> from pandas.api.types import is_file_like
>>> buffer = io.StringIO(""data"")
>>> is_file_like(buffer)
True
>>> is_file_like([1, 2, 3])
False
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_file_like.html, pandas.api.types.is_file_like
">>> pd.Timestamp.fromtimestamp(1584199972)  
Timestamp('2020-03-14 15:32:52')
",https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.fromtimestamp.html, pandas.Timestamp.fromtimestamp
">>> from pandas.core.dtypes.common import is_period_dtype
>>> is_period_dtype(object)
False
>>> is_period_dtype(pd.PeriodDtype(freq=""D""))
True
>>> is_period_dtype([1, 2, 3])
False
>>> is_period_dtype(pd.Period(""2017-01-01""))
False
>>> is_period_dtype(pd.PeriodIndex([], freq=""Y""))
True
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_period_dtype.html, pandas.api.types.is_period_dtype pandas.PeriodDtype pandas.Period pandas.PeriodIndex
">>> p = pd.Period(""2018-03-11 13:03:12.050000"")
>>> p.hour
13
",https://pandas.pydata.org/docs/reference/api/pandas.Period.hour.html, pandas.Period
">>> p = pd.Period(""2018-03-11"", freq=""M"")
>>> p.hour
0
",https://pandas.pydata.org/docs/reference/api/pandas.Period.hour.html, pandas.Period
">>> from pandas.core.dtypes.common import is_timedelta64_ns_dtype
>>> is_timedelta64_ns_dtype(np.dtype('m8[ns]'))
True
>>> is_timedelta64_ns_dtype(np.dtype('m8[ps]'))  # Wrong frequency
False
>>> is_timedelta64_ns_dtype(np.array([1, 2], dtype='m8[ns]'))
True
>>> is_timedelta64_ns_dtype(np.array([1, 2], dtype=np.timedelta64))
False
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_timedelta64_ns_dtype.html, pandas.api.types.is_timedelta64_ns_dtype
">>> from pandas.api.types import is_complex_dtype
>>> is_complex_dtype(str)
False
>>> is_complex_dtype(int)
False
>>> is_complex_dtype(np.complex128)
True
>>> is_complex_dtype(np.array(['a', 'b']))
False
>>> is_complex_dtype(pd.Series([1, 2]))
False
>>> is_complex_dtype(np.array([1 + 1j, 5]))
True
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_complex_dtype.html, pandas.api.types.is_complex_dtype pandas.Series
">>> import datetime
>>> from pandas.api.types import is_iterator
>>> is_iterator((x for x in []))
True
>>> is_iterator([1, 2, 3])
False
>>> is_iterator(datetime.datetime(2017, 1, 1))
False
>>> is_iterator(""foo"")
False
>>> is_iterator(1)
False
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_iterator.html, pandas.api.types.is_iterator
">>> pd.arrays.DatetimeArray._from_sequence(
...    pd.DatetimeIndex(['2023-01-01', '2023-01-02'], freq='D'))

['2023-01-01 00:00:00', '2023-01-02 00:00:00']
Length: 2, dtype: datetime64[ns]
",https://pandas.pydata.org/docs/reference/api/pandas.arrays.DatetimeArray.html, pandas.DatetimeIndex
">>> p = pd.Period(""2018-03-11 13:03:12.050000"")
>>> p.minute
3
",https://pandas.pydata.org/docs/reference/api/pandas.Period.minute.html, pandas.Period
">>> cat = pd.Categorical(['a', 'b'], ordered=True)
>>> cat
['a', 'b']
Categories (2, object): ['a' < 'b']
>>> cat.dtype
CategoricalDtype(categories=['a', 'b'], ordered=True, categories_dtype=object)
",https://pandas.pydata.org/docs/reference/api/pandas.Categorical.dtype.html, pandas.Categorical pandas.CategoricalDtype
">>> period = pd.Period('2022-01', 'M')
>>> period.month
1
",https://pandas.pydata.org/docs/reference/api/pandas.Period.month.html, pandas.Period
">>> from pandas.api.types import is_bool_dtype
>>> is_bool_dtype(str)
False
>>> is_bool_dtype(int)
False
>>> is_bool_dtype(bool)
True
>>> is_bool_dtype(np.bool_)
True
>>> is_bool_dtype(np.array(['a', 'b']))
False
>>> is_bool_dtype(pd.Series([1, 2]))
False
>>> is_bool_dtype(np.array([True, False]))
True
>>> is_bool_dtype(pd.Categorical([True, False]))
True
>>> is_bool_dtype(pd.arrays.SparseArray([True, False]))
True
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_bool_dtype.html, pandas.api.types.is_bool_dtype pandas.Series pandas.Categorical pandas.arrays.SparseArray
">>> iv = pd.Interval(0, 5, closed='left')
>>> iv.open_right
True
",https://pandas.pydata.org/docs/reference/api/pandas.Interval.open_right.html, pandas.Interval
">>> iv = pd.Interval(0, 5)
>>> iv.open_right
False
",https://pandas.pydata.org/docs/reference/api/pandas.Interval.open_right.html, pandas.Interval
">>> from pandas.arrays import SparseArray
>>> arr = SparseArray([0, 0, 1, 2])
>>> arr
[0, 0, 1, 2]
Fill: 0
IntIndex
Indices: array([2, 3], dtype=int32)
",https://pandas.pydata.org/docs/reference/api/pandas.arrays.SparseArray.html, pandas.arrays.SparseArray pandas.array
">>> pd.Timestamp.fromordinal(737425)
Timestamp('2020-01-01 00:00:00')
",https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.fromordinal.html, pandas.Timestamp.fromordinal
">>> ser = pd.Series(['a', 'b', 'c', 'a'], dtype='category')
>>> ser.cat.ordered
False
",https://pandas.pydata.org/docs/reference/api/pandas.Categorical.ordered.html, pandas.Series
">>> raw_cat = pd.Categorical(['a', 'b', 'c', 'a'], ordered=True)
>>> ser = pd.Series(raw_cat)
>>> ser.cat.ordered
True
",https://pandas.pydata.org/docs/reference/api/pandas.Categorical.ordered.html, pandas.Categorical pandas.Series
">>> cat = pd.Categorical(['a', 'b'], ordered=True)
>>> cat.ordered
True
",https://pandas.pydata.org/docs/reference/api/pandas.Categorical.ordered.html, pandas.Categorical
">>> cat = pd.Categorical(['a', 'b'], ordered=False)
>>> cat.ordered
False
",https://pandas.pydata.org/docs/reference/api/pandas.Categorical.ordered.html, pandas.Categorical
">>> ci = pd.CategoricalIndex(['a', 'b'], ordered=True)
>>> ci.ordered
True
",https://pandas.pydata.org/docs/reference/api/pandas.Categorical.ordered.html, pandas.CategoricalIndex
">>> ci = pd.CategoricalIndex(['a', 'b'], ordered=False)
>>> ci.ordered
False
",https://pandas.pydata.org/docs/reference/api/pandas.Categorical.ordered.html, pandas.CategoricalIndex
">>> dtype = pd.CategoricalDtype(['a', 'b'], ordered=True)
>>> pd.Categorical.from_codes(codes=[0, 1, 0, 1], dtype=dtype)
['a', 'b', 'a', 'b']
Categories (2, object): ['a' < 'b']
",https://pandas.pydata.org/docs/reference/api/pandas.Categorical.from_codes.html, pandas.CategoricalDtype pandas.Categorical.from_codes
">>> ts.tz_convert(tz='Asia/Tokyo')
Timestamp('2020-03-15 00:32:52.192548651+0900', tz='Asia/Tokyo')
",https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.astimezone.html, pandas.DataFrame.tz_convert
">>> cat_type = pd.CategoricalDtype(categories=['a', 'b'], ordered=True)
>>> cat_type.categories
Index(['a', 'b'], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.CategoricalDtype.categories.html, pandas.CategoricalDtype pandas.Index
">>> interval = pd.Interval(left=1, right=2, closed='left')
>>> interval
Interval(1, 2, closed='left')
>>> interval.left
1
",https://pandas.pydata.org/docs/reference/api/pandas.Interval.left.html, pandas.Interval pandas.Interval
">>> pd.array([True, False, None], dtype=""boolean"")

[True, False, ]
Length: 3, dtype: boolean
",https://pandas.pydata.org/docs/reference/api/pandas.arrays.BooleanArray.html, pandas.array
">>> pd.arrays.IntervalArray([pd.Interval(0, 1), pd.Interval(1, 5)])

[(0, 1], (1, 5]]
Length: 2, dtype: interval[int64, right]
",https://pandas.pydata.org/docs/reference/api/pandas.arrays.IntervalArray.html, pandas.arrays.IntervalArray pandas.Interval
">>> pd.api.types.is_integer(1)
True
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_integer.html, pandas.api.types.is_integer
">>> pd.api.types.is_integer(1.0)
False
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_integer.html, pandas.api.types.is_integer
">>> interval = pd.Interval(left=1, right=2, closed='left')
>>> interval
Interval(1, 2, closed='left')
>>> interval.length
1
",https://pandas.pydata.org/docs/reference/api/pandas.Interval.length.html, pandas.Interval pandas.Interval
">>> from zoneinfo import ZoneInfo
>>> pd.DatetimeTZDtype(tz=ZoneInfo('UTC'))
datetime64[ns, UTC]
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeTZDtype.html, pandas.DatetimeTZDtype
">>> pd.DatetimeTZDtype(tz=ZoneInfo('Europe/Paris'))
datetime64[ns, Europe/Paris]
",https://pandas.pydata.org/docs/reference/api/pandas.DatetimeTZDtype.html, pandas.DatetimeTZDtype
">>> from pandas.core.dtypes.common import is_interval_dtype
>>> is_interval_dtype(object)
False
>>> is_interval_dtype(pd.IntervalDtype())
True
>>> is_interval_dtype([1, 2, 3])
False
>>>
>>> interval = pd.Interval(1, 2, closed=""right"")
>>> is_interval_dtype(interval)
False
>>> is_interval_dtype(pd.IntervalIndex([interval]))
True
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_interval_dtype.html, pandas.api.types.is_interval_dtype pandas.IntervalDtype pandas.Interval pandas.IntervalIndex
">>> from pandas.core.dtypes.common import is_timedelta64_dtype
>>> is_timedelta64_dtype(object)
False
>>> is_timedelta64_dtype(np.timedelta64)
True
>>> is_timedelta64_dtype([1, 2, 3])
False
>>> is_timedelta64_dtype(pd.Series([], dtype=""timedelta64[ns]""))
True
>>> is_timedelta64_dtype('0 days')
False
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_timedelta64_dtype.html, pandas.api.types.is_timedelta64_dtype pandas.Series
">>> from pandas.api.types import is_any_real_numeric_dtype
>>> is_any_real_numeric_dtype(int)
True
>>> is_any_real_numeric_dtype(float)
True
>>> is_any_real_numeric_dtype(object)
False
>>> is_any_real_numeric_dtype(str)
False
>>> is_any_real_numeric_dtype(complex(1, 2))
False
>>> is_any_real_numeric_dtype(bool)
False
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_any_real_numeric_dtype.html, pandas.api.types.is_any_real_numeric_dtype
">>> from pandas.core.dtypes.common import is_signed_integer_dtype
>>> is_signed_integer_dtype(str)
False
>>> is_signed_integer_dtype(int)
True
>>> is_signed_integer_dtype(float)
False
>>> is_signed_integer_dtype(np.uint64)  # unsigned
False
>>> is_signed_integer_dtype('int8')
True
>>> is_signed_integer_dtype('Int8')
True
>>> is_signed_integer_dtype(pd.Int8Dtype)
True
>>> is_signed_integer_dtype(np.datetime64)
False
>>> is_signed_integer_dtype(np.timedelta64)
False
>>> is_signed_integer_dtype(np.array(['a', 'b']))
False
>>> is_signed_integer_dtype(pd.Series([1, 2]))
True
>>> is_signed_integer_dtype(np.array([], dtype=np.timedelta64))
False
>>> is_signed_integer_dtype(pd.Index([1, 2.]))  # float
False
>>> is_signed_integer_dtype(np.array([1, 2], dtype=np.uint32))  # unsigned
False
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_signed_integer_dtype.html, pandas.api.types.is_signed_integer_dtype pandas.Series pandas.Index
">>> from collections import namedtuple
>>> from pandas.api.types import is_named_tuple
>>> Point = namedtuple(""Point"", [""x"", ""y""])
>>> p = Point(1, 2)
>>>
>>> is_named_tuple(p)
True
>>> is_named_tuple((1, 2))
False
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_named_tuple.html, pandas.api.types.is_named_tuple
">>> per = pd.Period('2018Q1', freq='Q')
>>> per.qyear
2018
>>> per.year
2018
",https://pandas.pydata.org/docs/reference/api/pandas.Period.qyear.html, pandas.Period
">>> per = pd.Period('2018Q1', freq='Q-MAR')
>>> per.start_time
Timestamp('2017-04-01 00:00:00')
>>> per.qyear
2018
>>> per.year
2017
",https://pandas.pydata.org/docs/reference/api/pandas.Period.qyear.html, pandas.Period
">>> pd.arrays.TimedeltaArray._from_sequence(pd.TimedeltaIndex(['1h', '2h']))

['0 days 01:00:00', '0 days 02:00:00']
Length: 2, dtype: timedelta64[ns]
",https://pandas.pydata.org/docs/reference/api/pandas.arrays.TimedeltaArray.html, pandas.TimedeltaIndex
">>> cat = pd.Categorical(['a', 'b'], ordered=True)
",https://pandas.pydata.org/docs/reference/api/pandas.Categorical.__array__.html, pandas.Categorical
">>> np.asarray(cat)
array(['a', 'b'], dtype=object)
",https://pandas.pydata.org/docs/reference/api/pandas.Categorical.__array__.html, pandas.array
">>> ts = pd.Timestamp('2023-01-01 10:00:00')
>>> ts
Timestamp('2023-01-01 10:00:00')
>>> ts.time()
datetime.time(10, 0)
",https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.time.html, pandas.Timestamp.time
">>> pd.IntervalDtype(subtype='int64', closed='both')
interval[int64, both]
",https://pandas.pydata.org/docs/reference/api/pandas.IntervalDtype.html, pandas.IntervalDtype
">>> period = pd.Period('2022-01', 'M')
>>> period.is_leap_year
False
",https://pandas.pydata.org/docs/reference/api/pandas.Period.is_leap_year.html, pandas.Period
">>> period = pd.Period('2020-01', 'M')
>>> period.is_leap_year
True
",https://pandas.pydata.org/docs/reference/api/pandas.Period.is_leap_year.html, pandas.Period
">>> pd.arrays.PeriodArray(pd.PeriodIndex(['2023-01-01',
...                                       '2023-01-02'], freq='D'))

['2023-01-01', '2023-01-02']
Length: 2, dtype: period[D]
",https://pandas.pydata.org/docs/reference/api/pandas.arrays.PeriodArray.html, pandas.arrays.PeriodArray pandas.PeriodIndex
">>> from pandas.api.types import is_datetime64tz_dtype
>>> is_datetime64tz_dtype(object)
False
>>> is_datetime64tz_dtype([1, 2, 3])
False
>>> is_datetime64tz_dtype(pd.DatetimeIndex([1, 2, 3]))  # tz-naive
False
>>> is_datetime64tz_dtype(pd.DatetimeIndex([1, 2, 3], tz=""US/Eastern""))
True
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_datetime64tz_dtype.html, pandas.api.types.is_datetime64tz_dtype pandas.DatetimeIndex
">>> from pandas.core.dtypes.dtypes import DatetimeTZDtype
>>> dtype = DatetimeTZDtype(""ns"", tz=""US/Eastern"")
>>> s = pd.Series([], dtype=dtype)
>>> is_datetime64tz_dtype(dtype)
True
>>> is_datetime64tz_dtype(s)
True
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_datetime64tz_dtype.html, pandas.DatetimeTZDtype pandas.Series pandas.api.types.is_datetime64tz_dtype
">>> iv = pd.Interval(0, 5, closed='neither')
>>> iv.open_left
True
",https://pandas.pydata.org/docs/reference/api/pandas.Interval.open_left.html, pandas.Interval
">>> iv = pd.Interval(0, 5, closed='both')
>>> iv.open_left
False
",https://pandas.pydata.org/docs/reference/api/pandas.Interval.open_left.html, pandas.Interval
">>> pd.api.types.is_float(1.0)
True
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_float.html, pandas.api.types.is_float
">>> pd.api.types.is_float(1)
False
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_float.html, pandas.api.types.is_float
">>> from pandas.api.types import is_string_dtype
>>> is_string_dtype(str)
True
>>> is_string_dtype(object)
True
>>> is_string_dtype(int)
False
>>> is_string_dtype(np.array(['a', 'b']))
True
>>> is_string_dtype(pd.Series([1, 2]))
False
>>> is_string_dtype(pd.Series([1, 2], dtype=object))
False
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_string_dtype.html, pandas.api.types.is_string_dtype pandas.Series
">>> period = pd.Period(""2015-10-23"", freq='h')
>>> period.day_of_year
296
>>> period = pd.Period(""2012-12-31"", freq='D')
>>> period.day_of_year
366
>>> period = pd.Period(""2013-01-01"", freq='D')
>>> period.day_of_year
1
",https://pandas.pydata.org/docs/reference/api/pandas.Period.dayofyear.html, pandas.Period
">>> iv = pd.Interval(left=0, right=5)
>>> iv
Interval(0, 5, closed='right')
",https://pandas.pydata.org/docs/reference/api/pandas.Interval.html, pandas.Interval pandas.Interval
">>> 2.5 in iv
True
>>> pd.Interval(left=2, right=5, closed='both') in iv
True
",https://pandas.pydata.org/docs/reference/api/pandas.Interval.html, pandas.Interval
">>> shifted_iv = iv + 3
>>> shifted_iv
Interval(3, 8, closed='right')
>>> extended_iv = iv * 10.0
>>> extended_iv
Interval(0.0, 50.0, closed='right')
",https://pandas.pydata.org/docs/reference/api/pandas.Interval.html, pandas.Interval
">>> year_2017 = pd.Interval(pd.Timestamp('2017-01-01 00:00:00'),
...                         pd.Timestamp('2018-01-01 00:00:00'),
...                         closed='left')
>>> pd.Timestamp('2017-01-01 00:00') in year_2017
True
>>> year_2017.length
Timedelta('365 days 00:00:00')
",https://pandas.pydata.org/docs/reference/api/pandas.Interval.html, pandas.Interval
">>> from pandas.api.types import is_datetime64_ns_dtype
>>> from pandas.core.dtypes.dtypes import DatetimeTZDtype
>>> is_datetime64_ns_dtype(str)
False
>>> is_datetime64_ns_dtype(int)
False
>>> is_datetime64_ns_dtype(np.datetime64)  # no unit
False
>>> is_datetime64_ns_dtype(DatetimeTZDtype(""ns"", ""US/Eastern""))
True
>>> is_datetime64_ns_dtype(np.array(['a', 'b']))
False
>>> is_datetime64_ns_dtype(np.array([1, 2]))
False
>>> is_datetime64_ns_dtype(np.array([], dtype=""datetime64""))  # no unit
False
>>> is_datetime64_ns_dtype(np.array([], dtype=""datetime64[ps]""))  # wrong unit
False
>>> is_datetime64_ns_dtype(pd.DatetimeIndex([1, 2, 3], dtype=""datetime64[ns]""))
True
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_datetime64_ns_dtype.html, pandas.api.types.is_datetime64_ns_dtype pandas.DatetimeTZDtype pandas.DatetimeIndex
">>> from pandas.api.types import is_datetime64_dtype
>>> is_datetime64_dtype(object)
False
>>> is_datetime64_dtype(np.datetime64)
True
>>> is_datetime64_dtype(np.array([], dtype=int))
False
>>> is_datetime64_dtype(np.array([], dtype=np.datetime64))
True
>>> is_datetime64_dtype([1, 2, 3])
False
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_datetime64_dtype.html, pandas.api.types.is_datetime64_dtype
">>> period = pd.Period('2023-1-1', freq='D')
>>> period.asfreq('h')
Period('2023-01-01 23:00', 'h')
",https://pandas.pydata.org/docs/reference/api/pandas.Period.asfreq.html, pandas.Period pandas.Period.asfreq pandas.Period
">>> pd.StringDtype()
string[python]
",https://pandas.pydata.org/docs/reference/api/pandas.StringDtype.html, pandas.StringDtype
">>> pd.StringDtype(storage=""pyarrow"")
string[pyarrow]
",https://pandas.pydata.org/docs/reference/api/pandas.StringDtype.html, pandas.StringDtype
">>> pd.array([1, 1, None], dtype=""int64[pyarrow]"")

[1, 1, ]
Length: 3, dtype: int64[pyarrow]
",https://pandas.pydata.org/docs/reference/api/pandas.arrays.ArrowExtensionArray.html, pandas.array
">>> ts = pd.Timestamp('2020-03-14T15:32:52.192548651')
>>> ts.to_numpy()
numpy.datetime64('2020-03-14T15:32:52.192548651')
",https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.to_numpy.html, pandas.DataFrame.to_numpy
">>> from pandas.api.types import is_datetime64_any_dtype
>>> from pandas.core.dtypes.dtypes import DatetimeTZDtype
>>> is_datetime64_any_dtype(str)
False
>>> is_datetime64_any_dtype(int)
False
>>> is_datetime64_any_dtype(np.datetime64)  # can be tz-naive
True
>>> is_datetime64_any_dtype(DatetimeTZDtype(""ns"", ""US/Eastern""))
True
>>> is_datetime64_any_dtype(np.array(['a', 'b']))
False
>>> is_datetime64_any_dtype(np.array([1, 2]))
False
>>> is_datetime64_any_dtype(np.array([], dtype=""datetime64[ns]""))
True
>>> is_datetime64_any_dtype(pd.DatetimeIndex([1, 2, 3], dtype=""datetime64[ns]""))
True
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_datetime64_any_dtype.html, pandas.api.types.is_datetime64_any_dtype pandas.DatetimeTZDtype pandas.DatetimeIndex
">>> from pandas.api.types import is_extension_array_dtype
>>> arr = pd.Categorical(['a', 'b'])
>>> is_extension_array_dtype(arr)
True
>>> is_extension_array_dtype(arr.dtype)
True
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_extension_array_dtype.html, pandas.Categorical pandas.api.types.is_extension_array_dtype
">>> arr = np.array(['a', 'b'])
>>> is_extension_array_dtype(arr.dtype)
False
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_extension_array_dtype.html, pandas.api.types.is_extension_array_dtype
">>> import pyarrow as pa
>>> pd.ArrowDtype(pa.int64())
int64[pyarrow]
",https://pandas.pydata.org/docs/reference/api/pandas.ArrowDtype.html, pandas.ArrowDtype
">>> pd.ArrowDtype(pa.timestamp(""s"", tz=""America/New_York""))
timestamp[s, tz=America/New_York][pyarrow]
>>> pd.ArrowDtype(pa.list_(pa.int64()))
list[pyarrow]
",https://pandas.pydata.org/docs/reference/api/pandas.ArrowDtype.html, pandas.ArrowDtype
">>> from pandas.api.types import is_float_dtype
>>> is_float_dtype(str)
False
>>> is_float_dtype(int)
False
>>> is_float_dtype(float)
True
>>> is_float_dtype(np.array(['a', 'b']))
False
>>> is_float_dtype(pd.Series([1, 2]))
False
>>> is_float_dtype(pd.Index([1, 2.]))
True
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_float_dtype.html, pandas.api.types.is_float_dtype pandas.Series pandas.Index
">>> pd.Period('2020-01', 'D').end_time
Timestamp('2020-01-01 23:59:59.999999999')
",https://pandas.pydata.org/docs/reference/api/pandas.Period.end_time.html, pandas.Period
">>> period_index = pd.period_range('2020-1-1 00:00', '2020-3-1 00:00', freq='M')
>>> s = pd.Series(period_index)
>>> s
0   2020-01
1   2020-02
2   2020-03
dtype: period[M]
>>> s.dt.end_time
0   2020-01-31 23:59:59.999999999
1   2020-02-29 23:59:59.999999999
2   2020-03-31 23:59:59.999999999
dtype: datetime64[ns]
",https://pandas.pydata.org/docs/reference/api/pandas.Period.end_time.html, pandas.period_range pandas.Series
">>> idx = pd.PeriodIndex([""2023-01"", ""2023-02"", ""2023-03""], freq=""M"")
>>> idx.end_time
DatetimeIndex(['2023-01-31 23:59:59.999999999',
               '2023-02-28 23:59:59.999999999',
               '2023-03-31 23:59:59.999999999'],
               dtype='datetime64[ns]', freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.Period.end_time.html, pandas.PeriodIndex pandas.DatetimeIndex
">>> ser = pd.Series([1, 0, 0], dtype=pd.SparseDtype(dtype=int, fill_value=0))
>>> ser
0    1
1    0
2    0
dtype: Sparse[int64, 0]
>>> ser.sparse.density
0.3333333333333333
",https://pandas.pydata.org/docs/reference/api/pandas.SparseDtype.html, pandas.Series
">>> pd.api.types.is_complex(1 + 1j)
True
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_complex.html, pandas.api.types.is_complex
">>> pd.api.types.is_complex(1)
False
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_complex.html, pandas.api.types.is_complex
">>> td = pd.Timedelta('3D')
>>> td
Timedelta('3 days 00:00:00')
>>> td.view(int)
259200000000000
",https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.view.html, pandas.Series.view
">>> cat_type = pd.CategoricalDtype(categories=['a', 'b'], ordered=True)
>>> cat_type.ordered
True
",https://pandas.pydata.org/docs/reference/api/pandas.CategoricalDtype.ordered.html, pandas.CategoricalDtype
">>> cat_type = pd.CategoricalDtype(categories=['a', 'b'], ordered=False)
>>> cat_type.ordered
False
",https://pandas.pydata.org/docs/reference/api/pandas.CategoricalDtype.ordered.html, pandas.CategoricalDtype
">>> p = pd.Period(""2018-03-11"", freq='h')
>>> p.daysinmonth
31
",https://pandas.pydata.org/docs/reference/api/pandas.Period.daysinmonth.html, pandas.Period
">>> pd.Period('2020-01', 'D').freqstr
'D'
",https://pandas.pydata.org/docs/reference/api/pandas.Period.freqstr.html, pandas.Period
">>> period = pd.Period('2022-04', 'M')
>>> period.quarter
2
",https://pandas.pydata.org/docs/reference/api/pandas.Period.quarter.html, pandas.Period
">>> ser = pd.Series([2, pd.NA], dtype=pd.Int8Dtype())
>>> ser.dtype
Int8Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.Int8Dtype.html, pandas.Series pandas.Int8Dtype pandas.Int8Dtype
">>> ser = pd.Series([2, pd.NA], dtype=pd.Int16Dtype())
>>> ser.dtype
Int16Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.Int8Dtype.html, pandas.Series pandas.Int16Dtype pandas.Int16Dtype
">>> ser = pd.Series([2, pd.NA], dtype=pd.Int32Dtype())
>>> ser.dtype
Int32Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.Int8Dtype.html, pandas.Series pandas.Int32Dtype pandas.Int32Dtype
">>> ser = pd.Series([2, pd.NA], dtype=pd.Int64Dtype())
>>> ser.dtype
Int64Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.Int8Dtype.html, pandas.Series pandas.Int64Dtype pandas.Int64Dtype
">>> ser = pd.Series([2, pd.NA], dtype=pd.UInt8Dtype())
>>> ser.dtype
UInt8Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.Int8Dtype.html, pandas.Series pandas.UInt8Dtype pandas.UInt8Dtype
">>> ser = pd.Series([2, pd.NA], dtype=pd.UInt16Dtype())
>>> ser.dtype
UInt16Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.Int8Dtype.html, pandas.Series pandas.UInt16Dtype pandas.UInt16Dtype
">>> ser = pd.Series([2, pd.NA], dtype=pd.UInt32Dtype())
>>> ser.dtype
UInt32Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.Int8Dtype.html, pandas.Series pandas.UInt32Dtype pandas.UInt32Dtype
">>> ser = pd.Series([2, pd.NA], dtype=pd.UInt64Dtype())
>>> ser.dtype
UInt64Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.Int8Dtype.html, pandas.Series pandas.UInt64Dtype pandas.UInt64Dtype
">>> import collections
>>> from pandas.api.types import is_hashable
>>> a = ([],)
>>> isinstance(a, collections.abc.Hashable)
True
>>> is_hashable(a)
False
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_hashable.html, pandas.api.types.is_hashable
">>> ser = pd.Series([2.25, pd.NA], dtype=pd.Float32Dtype())
>>> ser.dtype
Float32Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.Float32Dtype.html, pandas.Series pandas.Float32Dtype pandas.Float32Dtype
">>> ser = pd.Series([2.25, pd.NA], dtype=pd.Float64Dtype())
>>> ser.dtype
Float64Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.Float32Dtype.html, pandas.Series pandas.Float64Dtype pandas.Float64Dtype
">>> from pandas import Period
>>> a = Period(freq='Q-JUL', year=2006, quarter=1)
>>> a.strftime('%F-Q%q')
'2006-Q1'
>>> # Output the last month in the quarter of this date
>>> a.strftime('%b-%Y')
'Oct-2005'
>>>
>>> a = Period(freq='D', year=2001, month=1, day=1)
>>> a.strftime('%d-%b-%Y')
'01-Jan-2001'
>>> a.strftime('%b. %d, %Y was a %A')
'Jan. 01, 2001 was a Monday'
",https://pandas.pydata.org/docs/reference/api/pandas.Period.strftime.html, pandas.Period pandas.Period.strftime
">>> from pandas.api.types import is_integer_dtype
>>> is_integer_dtype(str)
False
>>> is_integer_dtype(int)
True
>>> is_integer_dtype(float)
False
>>> is_integer_dtype(np.uint64)
True
>>> is_integer_dtype('int8')
True
>>> is_integer_dtype('Int8')
True
>>> is_integer_dtype(pd.Int8Dtype)
True
>>> is_integer_dtype(np.datetime64)
False
>>> is_integer_dtype(np.timedelta64)
False
>>> is_integer_dtype(np.array(['a', 'b']))
False
>>> is_integer_dtype(pd.Series([1, 2]))
True
>>> is_integer_dtype(np.array([], dtype=np.timedelta64))
False
>>> is_integer_dtype(pd.Index([1, 2.]))  # float
False
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_integer_dtype.html, pandas.api.types.is_integer_dtype pandas.Series pandas.Index
">>> iv = pd.Interval(0, 5, closed='both')
>>> iv.closed_right
True
",https://pandas.pydata.org/docs/reference/api/pandas.Interval.closed_right.html, pandas.Interval
">>> iv = pd.Interval(0, 5, closed='left')
>>> iv.closed_right
False
",https://pandas.pydata.org/docs/reference/api/pandas.Interval.closed_right.html, pandas.Interval
">>> ser = pd.Series([2, pd.NA], dtype=pd.Int8Dtype())
>>> ser.dtype
Int8Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.Int16Dtype.html, pandas.Series pandas.Int8Dtype pandas.Int8Dtype
">>> ser = pd.Series([2, pd.NA], dtype=pd.Int16Dtype())
>>> ser.dtype
Int16Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.Int16Dtype.html, pandas.Series pandas.Int16Dtype pandas.Int16Dtype
">>> ser = pd.Series([2, pd.NA], dtype=pd.Int32Dtype())
>>> ser.dtype
Int32Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.Int16Dtype.html, pandas.Series pandas.Int32Dtype pandas.Int32Dtype
">>> ser = pd.Series([2, pd.NA], dtype=pd.Int64Dtype())
>>> ser.dtype
Int64Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.Int16Dtype.html, pandas.Series pandas.Int64Dtype pandas.Int64Dtype
">>> ser = pd.Series([2, pd.NA], dtype=pd.UInt8Dtype())
>>> ser.dtype
UInt8Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.Int16Dtype.html, pandas.Series pandas.UInt8Dtype pandas.UInt8Dtype
">>> ser = pd.Series([2, pd.NA], dtype=pd.UInt16Dtype())
>>> ser.dtype
UInt16Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.Int16Dtype.html, pandas.Series pandas.UInt16Dtype pandas.UInt16Dtype
">>> ser = pd.Series([2, pd.NA], dtype=pd.UInt32Dtype())
>>> ser.dtype
UInt32Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.Int16Dtype.html, pandas.Series pandas.UInt32Dtype pandas.UInt32Dtype
">>> ser = pd.Series([2, pd.NA], dtype=pd.UInt64Dtype())
>>> ser.dtype
UInt64Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.Int16Dtype.html, pandas.Series pandas.UInt64Dtype pandas.UInt64Dtype
">>> ts.round(freq='h') # hour
Timestamp('2020-03-14 16:00:00')
",https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.round.html, pandas.DataFrame.round
">>> ts.round(freq='min') # minute
Timestamp('2020-03-14 15:33:00')
",https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.round.html, pandas.DataFrame.round
">>> ts.round(freq='s') # seconds
Timestamp('2020-03-14 15:32:52')
",https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.round.html, pandas.DataFrame.round
">>> ts.round(freq='ms') # milliseconds
Timestamp('2020-03-14 15:32:52.193000')
",https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.round.html, pandas.DataFrame.round
">>> ts.round(freq='5min')
Timestamp('2020-03-14 15:35:00')
",https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.round.html, pandas.DataFrame.round
">>> ts.round(freq='1h30min')
Timestamp('2020-03-14 15:00:00')
",https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.round.html, pandas.DataFrame.round
">>> pd.BooleanDtype()
BooleanDtype
",https://pandas.pydata.org/docs/reference/api/pandas.BooleanDtype.html, pandas.BooleanDtype
">>> pd.Timestamp.strptime(""2023-01-01"", ""%d/%m/%y"")
Traceback (most recent call last):
NotImplementedError
",https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.strptime.html, pandas.Timestamp.strptime
">>> ser = pd.Series(['a', 'b', 'c', 'a'], dtype='category')
>>> ser.cat.categories
Index(['a', 'b', 'c'], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.Categorical.categories.html, pandas.Series pandas.Index
">>> raw_cat = pd.Categorical(['a', 'b', 'c', 'a'], categories=['b', 'c', 'd'])
>>> ser = pd.Series(raw_cat)
>>> ser.cat.categories
Index(['b', 'c', 'd'], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.Categorical.categories.html, pandas.Categorical pandas.Series pandas.Index
">>> cat = pd.Categorical(['a', 'b'], ordered=True)
>>> cat.categories
Index(['a', 'b'], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.Categorical.categories.html, pandas.Categorical pandas.Index
">>> ci = pd.CategoricalIndex(['a', 'c', 'b', 'a', 'c', 'b'])
>>> ci.categories
Index(['a', 'b', 'c'], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.Categorical.categories.html, pandas.CategoricalIndex pandas.Index
">>> ci = pd.CategoricalIndex(['a', 'c'], categories=['c', 'b', 'a'])
>>> ci.categories
Index(['c', 'b', 'a'], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.Categorical.categories.html, pandas.CategoricalIndex pandas.Index
">>> per = pd.Period('2017-12-31 22:00', 'h')
>>> per.dayofweek
6
",https://pandas.pydata.org/docs/reference/api/pandas.Period.weekday.html, pandas.Period
">>> per = pd.Period('2017-12-31 22:00', '4h')
>>> per.dayofweek
6
>>> per.start_time.dayofweek
6
",https://pandas.pydata.org/docs/reference/api/pandas.Period.weekday.html, pandas.Period
">>> per = pd.Period('2018-01', 'M')
>>> per.dayofweek
2
>>> per.end_time.dayofweek
2
",https://pandas.pydata.org/docs/reference/api/pandas.Period.weekday.html, pandas.Period
">>> ts.tz_localize(tz='Europe/Stockholm')
Timestamp('2020-03-14 15:32:52.192548651+0100', tz='Europe/Stockholm')
",https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.tz_localize.html, pandas.DataFrame.tz_localize
">>> t = pd.CategoricalDtype(categories=['b', 'a'], ordered=True)
>>> pd.Series(['a', 'b', 'a', 'c'], dtype=t)
0      a
1      b
2      a
3    NaN
dtype: category
Categories (2, object): ['b' < 'a']
",https://pandas.pydata.org/docs/reference/api/pandas.CategoricalDtype.html, pandas.CategoricalDtype pandas.Series
">>> pd.CategoricalDtype(pd.DatetimeIndex([])).categories.dtype
dtype('
",https://pandas.pydata.org/docs/reference/api/pandas.CategoricalDtype.html, pandas.CategoricalDtype pandas.DatetimeIndex
">>> from pandas.api.types import is_re_compilable
>>> is_re_compilable("".*"")
True
>>> is_re_compilable(1)
False
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_re_compilable.html, pandas.api.types.is_re_compilable
">>> a = pd.Categorical([""b"", ""c""])
>>> b = pd.Categorical([""a"", ""b""])
>>> pd.api.types.union_categoricals([a, b])
['b', 'c', 'a', 'b']
Categories (3, object): ['b', 'c', 'a']
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.union_categoricals.html, pandas.Categorical pandas.api.types.union_categoricals
">>> pd.api.types.union_categoricals([a, b], sort_categories=True)
['b', 'c', 'a', 'b']
Categories (3, object): ['a', 'b', 'c']
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.union_categoricals.html, pandas.api.types.union_categoricals
">>> a = pd.Categorical([""a"", ""b""], ordered=True)
>>> b = pd.Categorical([""a"", ""b"", ""a""], ordered=True)
>>> pd.api.types.union_categoricals([a, b])
['a', 'b', 'a', 'b', 'a']
Categories (2, object): ['a' < 'b']
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.union_categoricals.html, pandas.Categorical pandas.api.types.union_categoricals
">>> a = pd.Categorical([""a"", ""b""], ordered=True)
>>> b = pd.Categorical([""a"", ""b"", ""c""], ordered=True)
>>> pd.api.types.union_categoricals([a, b])
Traceback (most recent call last):
    ...
TypeError: to union ordered Categoricals, all categories must be the same
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.union_categoricals.html, pandas.Categorical pandas.api.types.union_categoricals
">>> a = pd.Categorical([""a"", ""b"", ""c""], ordered=True)
>>> b = pd.Categorical([""c"", ""b"", ""a""], ordered=True)
>>> pd.api.types.union_categoricals([a, b], ignore_order=True)
['a', 'b', 'c', 'c', 'b', 'a']
Categories (3, object): ['a', 'b', 'c']
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.union_categoricals.html, pandas.Categorical pandas.api.types.union_categoricals
">>> a = pd.Series([""b"", ""c""], dtype='category')
>>> b = pd.Series([""a"", ""b""], dtype='category')
>>> pd.api.types.union_categoricals([a, b])
['b', 'c', 'a', 'b']
Categories (3, object): ['b', 'c', 'a']
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.union_categoricals.html, pandas.Series pandas.api.types.union_categoricals
">>> pd.Period.now('h')  
Period('2023-06-12 11:00', 'h')
",https://pandas.pydata.org/docs/reference/api/pandas.Period.now.html, pandas.Period.now pandas.Period
">>> interval = pd.Interval(left=1, right=2, closed='left')
>>> interval
Interval(1, 2, closed='left')
>>> interval.right
2
",https://pandas.pydata.org/docs/reference/api/pandas.Interval.right.html, pandas.Interval pandas.Interval
">>> import datetime
>>> from pandas.api.types import is_list_like
>>> is_list_like([1, 2, 3])
True
>>> is_list_like({1, 2, 3})
True
>>> is_list_like(datetime.datetime(2017, 1, 1))
False
>>> is_list_like(""foo"")
False
>>> is_list_like(1)
False
>>> is_list_like(np.array([2]))
True
>>> is_list_like(np.array(2))
False
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_list_like.html, pandas.api.types.is_list_like
">>> ser = pd.Series([2.25, pd.NA], dtype=pd.Float32Dtype())
>>> ser.dtype
Float32Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.Float64Dtype.html, pandas.Series pandas.Float32Dtype pandas.Float32Dtype
">>> ser = pd.Series([2.25, pd.NA], dtype=pd.Float64Dtype())
>>> ser.dtype
Float64Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.Float64Dtype.html, pandas.Series pandas.Float64Dtype pandas.Float64Dtype
">>> p = pd.Period(""2018-03-11"", freq='h')
>>> p.day
11
",https://pandas.pydata.org/docs/reference/api/pandas.Period.day.html, pandas.Period
">>> ser = pd.Series([2, pd.NA], dtype=pd.Int8Dtype())
>>> ser.dtype
Int8Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.Int64Dtype.html, pandas.Series pandas.Int8Dtype pandas.Int8Dtype
">>> ser = pd.Series([2, pd.NA], dtype=pd.Int16Dtype())
>>> ser.dtype
Int16Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.Int64Dtype.html, pandas.Series pandas.Int16Dtype pandas.Int16Dtype
">>> ser = pd.Series([2, pd.NA], dtype=pd.Int32Dtype())
>>> ser.dtype
Int32Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.Int64Dtype.html, pandas.Series pandas.Int32Dtype pandas.Int32Dtype
">>> ser = pd.Series([2, pd.NA], dtype=pd.Int64Dtype())
>>> ser.dtype
Int64Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.Int64Dtype.html, pandas.Series pandas.Int64Dtype pandas.Int64Dtype
">>> ser = pd.Series([2, pd.NA], dtype=pd.UInt8Dtype())
>>> ser.dtype
UInt8Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.Int64Dtype.html, pandas.Series pandas.UInt8Dtype pandas.UInt8Dtype
">>> ser = pd.Series([2, pd.NA], dtype=pd.UInt16Dtype())
>>> ser.dtype
UInt16Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.Int64Dtype.html, pandas.Series pandas.UInt16Dtype pandas.UInt16Dtype
">>> ser = pd.Series([2, pd.NA], dtype=pd.UInt32Dtype())
>>> ser.dtype
UInt32Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.Int64Dtype.html, pandas.Series pandas.UInt32Dtype pandas.UInt32Dtype
">>> ser = pd.Series([2, pd.NA], dtype=pd.UInt64Dtype())
>>> ser.dtype
UInt64Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.Int64Dtype.html, pandas.Series pandas.UInt64Dtype pandas.UInt64Dtype
">>> from datetime import date, time
>>> pd.Timestamp.combine(date(2020, 3, 14), time(15, 30, 15))
Timestamp('2020-03-14 15:30:15')
",https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.combine.html, pandas.Timestamp.combine pandas.Timestamp.date pandas.Timestamp.time
">>> ts = pd.Timestamp('2023-01-01 10:00:00', tz='Europe/Brussels')
>>> ts
Timestamp('2023-01-01 10:00:00+0100', tz='Europe/Brussels')
>>> ts.timetz()
datetime.time(10, 0, tzinfo=)
",https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.timetz.html, pandas.Timestamp.time
">>> from pandas.api.types import is_int64_dtype
>>> is_int64_dtype(str)  
False
>>> is_int64_dtype(np.int32)  
False
>>> is_int64_dtype(np.int64)  
True
>>> is_int64_dtype('int8')  
False
>>> is_int64_dtype('Int8')  
False
>>> is_int64_dtype(pd.Int64Dtype)  
True
>>> is_int64_dtype(float)  
False
>>> is_int64_dtype(np.uint64)  # unsigned  
False
>>> is_int64_dtype(np.array(['a', 'b']))  
False
>>> is_int64_dtype(np.array([1, 2], dtype=np.int64))  
True
>>> is_int64_dtype(pd.Index([1, 2.]))  # float  
False
>>> is_int64_dtype(np.array([1, 2], dtype=np.uint32))  # unsigned  
False
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_int64_dtype.html, pandas.api.types.is_int64_dtype pandas.Index
">>> from pandas.api.types import is_dict_like
>>> is_dict_like({1: 2})
True
>>> is_dict_like([1, 2, 3])
False
>>> is_dict_like(dict)
False
>>> is_dict_like(dict())
True
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_dict_like.html, pandas.api.types.is_dict_like
">>> pd.Timestamp.today()    
Timestamp('2020-11-16 22:37:39.969883')
",https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.today.html, pandas.Timestamp.today
">>> pd.api.types.pandas_dtype(int)
dtype('int64')
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.pandas_dtype.html, pandas.api.types.pandas_dtype
">>> pd.Timestamp.now()  
Timestamp('2020-11-16 22:06:16.378782')
",https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.now.html, pandas.Timestamp.now
">>> from pandas.api.types import is_sparse
>>> is_sparse(pd.arrays.SparseArray([0, 0, 1, 0]))
True
>>> is_sparse(pd.Series(pd.arrays.SparseArray([0, 0, 1, 0])))
True
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_sparse.html, pandas.api.types.is_sparse pandas.arrays.SparseArray pandas.Series
">>> is_sparse(np.array([0, 0, 1, 0]))
False
>>> is_sparse(pd.Series([0, 1, 0, 0]))
False
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_sparse.html, pandas.api.types.is_sparse pandas.Series
">>> from scipy.sparse import bsr_matrix
>>> is_sparse(bsr_matrix([0, 1, 0, 0]))
False
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_sparse.html, pandas.api.types.is_sparse
">>> ts = pd.Timestamp('2020-03-14T15:32:52.192548651')
>>> # Year end frequency
>>> ts.to_period(freq='Y')
Period('2020', 'Y-DEC')
",https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.to_period.html, pandas.DataFrame.to_period pandas.Period
">>> # Month end frequency
>>> ts.to_period(freq='M')
Period('2020-03', 'M')
",https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.to_period.html, pandas.DataFrame.to_period pandas.Period
">>> # Weekly frequency
>>> ts.to_period(freq='W')
Period('2020-03-09/2020-03-15', 'W-SUN')
",https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.to_period.html, pandas.DataFrame.to_period pandas.Period
">>> # Quarter end frequency
>>> ts.to_period(freq='Q')
Period('2020Q1', 'Q-DEC')
",https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.to_period.html, pandas.DataFrame.to_period pandas.Period
">>> cat = pd.Categorical(['a', 'b'], ordered=True)
>>> cat.codes
array([0, 1], dtype=int8)
",https://pandas.pydata.org/docs/reference/api/pandas.Categorical.codes.html, pandas.Categorical pandas.array
">>> ci = pd.CategoricalIndex(['a', 'b', 'c', 'a', 'b', 'c'])
>>> ci.codes
array([0, 1, 2, 0, 1, 2], dtype=int8)
",https://pandas.pydata.org/docs/reference/api/pandas.Categorical.codes.html, pandas.CategoricalIndex pandas.array
">>> ci = pd.CategoricalIndex(['a', 'c'], categories=['c', 'b', 'a'])
>>> ci.codes
array([2, 0], dtype=int8)
",https://pandas.pydata.org/docs/reference/api/pandas.Categorical.codes.html, pandas.CategoricalIndex pandas.array
">>> td = pd.Timedelta('3D')
>>> td
Timedelta('3 days 00:00:00')
>>> td.to_numpy()
numpy.timedelta64(259200000000000,'ns')
",https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.to_numpy.html, pandas.Series.to_numpy
">>> ser = pd.Series([2, pd.NA], dtype=pd.Int8Dtype())
>>> ser.dtype
Int8Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.UInt32Dtype.html, pandas.Series pandas.Int8Dtype pandas.Int8Dtype
">>> ser = pd.Series([2, pd.NA], dtype=pd.Int16Dtype())
>>> ser.dtype
Int16Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.UInt32Dtype.html, pandas.Series pandas.Int16Dtype pandas.Int16Dtype
">>> ser = pd.Series([2, pd.NA], dtype=pd.Int32Dtype())
>>> ser.dtype
Int32Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.UInt32Dtype.html, pandas.Series pandas.Int32Dtype pandas.Int32Dtype
">>> ser = pd.Series([2, pd.NA], dtype=pd.Int64Dtype())
>>> ser.dtype
Int64Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.UInt32Dtype.html, pandas.Series pandas.Int64Dtype pandas.Int64Dtype
">>> ser = pd.Series([2, pd.NA], dtype=pd.UInt8Dtype())
>>> ser.dtype
UInt8Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.UInt32Dtype.html, pandas.Series pandas.UInt8Dtype pandas.UInt8Dtype
">>> ser = pd.Series([2, pd.NA], dtype=pd.UInt16Dtype())
>>> ser.dtype
UInt16Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.UInt32Dtype.html, pandas.Series pandas.UInt16Dtype pandas.UInt16Dtype
">>> ser = pd.Series([2, pd.NA], dtype=pd.UInt32Dtype())
>>> ser.dtype
UInt32Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.UInt32Dtype.html, pandas.Series pandas.UInt32Dtype pandas.UInt32Dtype
">>> ser = pd.Series([2, pd.NA], dtype=pd.UInt64Dtype())
>>> ser.dtype
UInt64Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.UInt32Dtype.html, pandas.Series pandas.UInt64Dtype pandas.UInt64Dtype
">>> from pandas.api.types import infer_dtype
>>> infer_dtype(['foo', 'bar'])
'string'
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.infer_dtype.html, pandas.api.types.infer_dtype
">>> infer_dtype(['a', np.nan, 'b'], skipna=True)
'string'
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.infer_dtype.html, pandas.api.types.infer_dtype
">>> infer_dtype(['a', np.nan, 'b'], skipna=False)
'mixed'
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.infer_dtype.html, pandas.api.types.infer_dtype
">>> infer_dtype([b'foo', b'bar'])
'bytes'
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.infer_dtype.html, pandas.api.types.infer_dtype
">>> infer_dtype([1, 2, 3])
'integer'
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.infer_dtype.html, pandas.api.types.infer_dtype
">>> infer_dtype([1, 2, 3.5])
'mixed-integer-float'
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.infer_dtype.html, pandas.api.types.infer_dtype
">>> infer_dtype([1.0, 2.0, 3.5])
'floating'
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.infer_dtype.html, pandas.api.types.infer_dtype
">>> infer_dtype(['a', 1])
'mixed-integer'
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.infer_dtype.html, pandas.api.types.infer_dtype
">>> from decimal import Decimal
>>> infer_dtype([Decimal(1), Decimal(2.0)])
'decimal'
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.infer_dtype.html, pandas.api.types.infer_dtype
">>> infer_dtype([True, False])
'boolean'
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.infer_dtype.html, pandas.api.types.infer_dtype
">>> infer_dtype([True, False, np.nan])
'boolean'
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.infer_dtype.html, pandas.api.types.infer_dtype
">>> infer_dtype([pd.Timestamp('20130101')])
'datetime'
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.infer_dtype.html, pandas.api.types.infer_dtype
">>> import datetime
>>> infer_dtype([datetime.date(2013, 1, 1)])
'date'
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.infer_dtype.html, pandas.api.types.infer_dtype pandas.Timestamp.date
">>> infer_dtype([np.datetime64('2013-01-01')])
'datetime64'
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.infer_dtype.html, pandas.api.types.infer_dtype
">>> infer_dtype([datetime.timedelta(0, 1, 1)])
'timedelta'
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.infer_dtype.html, pandas.api.types.infer_dtype
">>> infer_dtype(pd.Series(list('aabc')).astype('category'))
'categorical'
",https://pandas.pydata.org/docs/reference/api/pandas.api.types.infer_dtype.html, pandas.api.types.infer_dtype pandas.Series
">>> pd.array([0.1, None, 0.3], dtype=pd.Float32Dtype())

[0.1, , 0.3]
Length: 3, dtype: Float32
",https://pandas.pydata.org/docs/reference/api/pandas.arrays.FloatingArray.html, pandas.array pandas.Float32Dtype
">>> pd.array([0.1, None, 0.3], dtype=""Float32"")

[0.1, , 0.3]
Length: 3, dtype: Float32
",https://pandas.pydata.org/docs/reference/api/pandas.arrays.FloatingArray.html, pandas.array
">>> int_array = pd.array([1, None, 3], dtype=pd.Int32Dtype())
>>> int_array

[1, , 3]
Length: 3, dtype: Int32
",https://pandas.pydata.org/docs/reference/api/pandas.arrays.IntegerArray.html, pandas.array pandas.Int32Dtype
">>> pd.array([1, None, 3], dtype='Int32')

[1, , 3]
Length: 3, dtype: Int32
",https://pandas.pydata.org/docs/reference/api/pandas.arrays.IntegerArray.html, pandas.array
">>> pd.array([1, None, 3], dtype='UInt16')

[1, , 3]
Length: 3, dtype: UInt16
",https://pandas.pydata.org/docs/reference/api/pandas.arrays.IntegerArray.html, pandas.array
">>> pd.Timestamp.utcfromtimestamp(1584199972)
Timestamp('2020-03-14 15:32:52+0000', tz='UTC')
",https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.utcfromtimestamp.html, pandas.Timestamp.utcfromtimestamp
"In [10]: pd.get_option(""max"")
---------------------------------------------------------------------------
OptionError                               Traceback (most recent call last)
Cell In[10], line 1
----> 1 pd.get_option(""max"")

File ~/work/pandas/pandas/pandas/_config/config.py:274, in CallableDynamicDoc.__call__(self, *args, **kwds)
    273 def __call__(self, *args, **kwds) -> T:
--> 274     return self.__func__(*args, **kwds)

File ~/work/pandas/pandas/pandas/_config/config.py:146, in _get_option(pat, silent)
    145 def _get_option(pat: str, silent: bool = False) -> Any:
--> 146     key = _get_single_key(pat, silent)
    148     # walk the nested dict
    149     root, k = _get_root(key)

File ~/work/pandas/pandas/pandas/_config/config.py:134, in _get_single_key(pat, silent)
    132     raise OptionError(f""No such keys(s): {repr(pat)}"")
    133 if len(keys) > 1:
--> 134     raise OptionError(""Pattern matched multiple keys"")
    135 key = keys[0]
    137 if not silent:

OptionError: Pattern matched multiple keys
",https://pandas.pydata.org/docs/user_guide/options.html, pandas.errors.OptionError
"In [11]: pd.describe_option()
compute.use_bottleneck : bool
    Use the bottleneck library to accelerate if it is installed,
    the default is True
    Valid values: False,True
    [default: True] [currently: True]
compute.use_numba : bool
    Use the numba engine option for select operations if it is installed,
    the default is False
    Valid values: False,True
    [default: False] [currently: False]
compute.use_numexpr : bool
    Use the numexpr library to accelerate computation if it is installed,
    the default is True
    Valid values: False,True
    [default: True] [currently: True]
display.chop_threshold : float or None
    if set to a float value, all float values smaller than the given threshold
    will be displayed as exactly 0 by repr and friends.
    [default: None] [currently: None]
display.colheader_justify : 'left'/'right'
    Controls the justification of column headers. used by DataFrameFormatter.
    [default: right] [currently: right]
display.date_dayfirst : boolean
    When True, prints and parses dates with the day first, eg 20/01/2005
    [default: False] [currently: False]
display.date_yearfirst : boolean
    When True, prints and parses dates with the year first, eg 2005/01/20
    [default: False] [currently: False]
display.encoding : str/unicode
    Defaults to the detected encoding of the console.
    Specifies the encoding to be used for strings returned by to_string,
    these are generally strings meant to be displayed on the console.
    [default: utf-8] [currently: utf8]
display.expand_frame_repr : boolean
    Whether to print out the full DataFrame repr for wide DataFrames across
    multiple lines, `max_columns` is still respected, but the output will
    wrap-around across multiple ""pages"" if its width exceeds `display.width`.
    [default: True] [currently: True]
display.float_format : callable
    The callable should accept a floating point number and return
    a string with the desired format of the number. This is used
    in some places like SeriesFormatter.
    See formats.format.EngFormatter for an example.
    [default: None] [currently: None]
display.html.border : int
    A ``border=value`` attribute is inserted in the ```` tag
    for the DataFrame HTML repr.
    [default: 1] [currently: 1]
display.html.table_schema : boolean
    Whether to publish a Table Schema representation for frontends
    that support it.
    (default: False)
    [default: False] [currently: False]
display.html.use_mathjax : boolean
    When True, Jupyter notebook will process table contents using MathJax,
    rendering mathematical expressions enclosed by the dollar symbol.
    (default: True)
    [default: True] [currently: True]
display.large_repr : 'truncate'/'info'
    For DataFrames exceeding max_rows/max_cols, the repr (and HTML repr) can
    show a truncated table, or switch to the view from
    df.info() (the behaviour in earlier versions of pandas).
    [default: truncate] [currently: truncate]
display.max_categories : int
    This sets the maximum number of categories pandas should output when
    printing out a `Categorical` or a Series of dtype ""category"".
    [default: 8] [currently: 8]
display.max_columns : int
    If max_cols is exceeded, switch to truncate view. Depending on
    `large_repr`, objects are either centrally truncated or printed as
    a summary view. 'None' value means unlimited.

    In case python/IPython is running in a terminal and `large_repr`
    equals 'truncate' this can be set to 0 or None and pandas will auto-detect
    the width of the terminal and print a truncated object which fits
    the screen width. The IPython notebook, IPython qtconsole, or IDLE
    do not run in a terminal and hence it is not possible to do
    correct auto-detection and defaults to 20.
    [default: 0] [currently: 0]
display.max_colwidth : int or None
    The maximum width in characters of a column in the repr of
    a pandas data structure. When the column overflows, a ""...""
    placeholder is embedded in the output. A 'None' value means unlimited.
    [default: 50] [currently: 50]
display.max_dir_items : int
    The number of items that will be added to `dir(...)`. 'None' value means
    unlimited. Because dir is cached, changing this option will not immediately
    affect already existing dataframes until a column is deleted or added.

    This is for instance used to suggest columns from a dataframe to tab
    completion.
    [default: 100] [currently: 100]
display.max_info_columns : int
    max_info_columns is used in DataFrame.info method to decide if
    per column information will be printed.
    [default: 100] [currently: 100]
display.max_info_rows : int
    df.info() will usually show null-counts for each column.
    For large frames this can be quite slow. max_info_rows and max_info_cols
    limit this null check only to frames with smaller dimensions than
    specified.
    [default: 1690785] [currently: 1690785]
display.max_rows : int
    If max_rows is exceeded, switch to truncate view. Depending on
    `large_repr`, objects are either centrally truncated or printed as
    a summary view. 'None' value means unlimited.

    In case python/IPython is running in a terminal and `large_repr`
    equals 'truncate' this can be set to 0 and pandas will auto-detect
    the height of the terminal and print a truncated object which fits
    the screen height. The IPython notebook, IPython qtconsole, or
    IDLE do not run in a terminal and hence it is not possible to do
    correct auto-detection.
    [default: 60] [currently: 60]
display.max_seq_items : int or None
    When pretty-printing a long sequence, no more then `max_seq_items`
    will be printed. If items are omitted, they will be denoted by the
    addition of ""..."" to the resulting string.

    If set to None, the number of items to be printed is unlimited.
    [default: 100] [currently: 100]
display.memory_usage : bool, string or None
    This specifies if the memory usage of a DataFrame should be displayed when
    df.info() is called. Valid values True,False,'deep'
    [default: True] [currently: True]
display.min_rows : int
    The numbers of rows to show in a truncated view (when `max_rows` is
    exceeded). Ignored when `max_rows` is set to None or 0. When set to
    None, follows the value of `max_rows`.
    [default: 10] [currently: 10]
display.multi_sparse : boolean
    ""sparsify"" MultiIndex display (don't display repeated
    elements in outer levels within groups)
    [default: True] [currently: True]
display.notebook_repr_html : boolean
    When True, IPython notebook will use html representation for
    pandas objects (if it is available).
    [default: True] [currently: True]
display.pprint_nest_depth : int
    Controls the number of nested levels to process when pretty-printing
    [default: 3] [currently: 3]
display.precision : int
    Floating point output precision in terms of number of places after the
    decimal, for regular formatting as well as scientific notation. Similar
    to ``precision`` in :meth:`numpy.set_printoptions`.
    [default: 6] [currently: 6]
display.show_dimensions : boolean or 'truncate'
    Whether to print out dimensions at the end of DataFrame repr.
    If 'truncate' is specified, only print out the dimensions if the
    frame is truncated (e.g. not display all rows and/or columns)
    [default: truncate] [currently: truncate]
display.unicode.ambiguous_as_wide : boolean
    Whether to use the Unicode East Asian Width to calculate the display text
    width.
    Enabling this may affect to the performance (default: False)
    [default: False] [currently: False]
display.unicode.east_asian_width : boolean
    Whether to use the Unicode East Asian Width to calculate the display text
    width.
    Enabling this may affect to the performance (default: False)
    [default: False] [currently: False]
display.width : int
    Width of the display in characters. In case python/IPython is running in
    a terminal this can be set to None and pandas will correctly auto-detect
    the width.
    Note that the IPython notebook, IPython qtconsole, or IDLE do not run in a
    terminal and hence it is not possible to correctly detect the width.
    [default: 80] [currently: 80]
future.infer_string Whether to infer sequence of str objects as pyarrow string dtype, which will be the default in pandas 3.0 (at which point this option will be deprecated).
    [default: False] [currently: False]
future.no_silent_downcasting Whether to opt-in to the future behavior which will *not* silently downcast results from Series and DataFrame `where`, `mask`, and `clip` methods. Silent downcasting will be removed in pandas 3.0 (at which point this option will be deprecated).
    [default: False] [currently: False]
io.excel.ods.reader : string
    The default Excel reader engine for 'ods' files. Available options:
    auto, odf, calamine.
    [default: auto] [currently: auto]
io.excel.ods.writer : string
    The default Excel writer engine for 'ods' files. Available options:
    auto, odf.
    [default: auto] [currently: auto]
io.excel.xls.reader : string
    The default Excel reader engine for 'xls' files. Available options:
    auto, xlrd, calamine.
    [default: auto] [currently: auto]
io.excel.xlsb.reader : string
    The default Excel reader engine for 'xlsb' files. Available options:
    auto, pyxlsb, calamine.
    [default: auto] [currently: auto]
io.excel.xlsm.reader : string
    The default Excel reader engine for 'xlsm' files. Available options:
    auto, xlrd, openpyxl, calamine.
    [default: auto] [currently: auto]
io.excel.xlsm.writer : string
    The default Excel writer engine for 'xlsm' files. Available options:
    auto, openpyxl.
    [default: auto] [currently: auto]
io.excel.xlsx.reader : string
    The default Excel reader engine for 'xlsx' files. Available options:
    auto, xlrd, openpyxl, calamine.
    [default: auto] [currently: auto]
io.excel.xlsx.writer : string
    The default Excel writer engine for 'xlsx' files. Available options:
    auto, openpyxl, xlsxwriter.
    [default: auto] [currently: auto]
io.hdf.default_format : format
    default format writing format, if None, then
    put will default to 'fixed' and append will default to 'table'
    [default: None] [currently: None]
io.hdf.dropna_table : boolean
    drop ALL nan rows when appending to a table
    [default: False] [currently: False]
io.parquet.engine : string
    The default parquet reader/writer engine. Available options:
    'auto', 'pyarrow', 'fastparquet', the default is 'auto'
    [default: auto] [currently: auto]
io.sql.engine : string
    The default sql reader/writer engine. Available options:
    'auto', 'sqlalchemy', the default is 'auto'
    [default: auto] [currently: auto]
mode.chained_assignment : string
    Raise an exception, warn, or no action if trying to use chained assignment,
    The default is warn
    [default: warn] [currently: warn]
mode.copy_on_write : bool
    Use new copy-view behaviour using Copy-on-Write. Defaults to False,
    unless overridden by the 'PANDAS_COPY_ON_WRITE' environment variable
    (if set to ""1"" for True, needs to be set before pandas is imported).
    [default: False] [currently: False]
mode.data_manager : string
    Internal data manager type; can be ""block"" or ""array"". Defaults to ""block"",
    unless overridden by the 'PANDAS_DATA_MANAGER' environment variable (needs
    to be set before pandas is imported).
    [default: block] [currently: block]
    (Deprecated, use `` instead.)
mode.sim_interactive : boolean
    Whether to simulate interactive mode for purposes of testing
    [default: False] [currently: False]
mode.string_storage : string
    The default storage for StringDtype. This option is ignored if
    ``future.infer_string`` is set to True.
    [default: python] [currently: python]
mode.use_inf_as_na : boolean
    True means treat None, NaN, INF, -INF as NA (old way),
    False means None and NaN are null, but INF, -INF are not NA
    (new way).

    This option is deprecated in pandas 2.1.0 and will be removed in 3.0.
    [default: False] [currently: False]
    (Deprecated, use `` instead.)
plotting.backend : str
    The plotting backend to use. The default value is ""matplotlib"", the
    backend provided with pandas. Other backends can be specified by
    providing the name of the module that implements the backend.
    [default: matplotlib] [currently: matplotlib]
plotting.matplotlib.register_converters : bool or 'auto'.
    Whether to register converters with matplotlib's units registry for
    dates, times, datetimes, and Periods. Toggling to False will remove
    the converters, restoring any converters that pandas overwrote.
    [default: auto] [currently: auto]
styler.format.decimal : str
    The character representation for the decimal separator for floats and complex.
    [default: .] [currently: .]
styler.format.escape : str, optional
    Whether to escape certain characters according to the given context; html or latex.
    [default: None] [currently: None]
styler.format.formatter : str, callable, dict, optional
    A formatter object to be used as default within ``Styler.format``.
    [default: None] [currently: None]
styler.format.na_rep : str, optional
    The string representation for values identified as missing.
    [default: None] [currently: None]
styler.format.precision : int
    The precision for floats and complex numbers.
    [default: 6] [currently: 6]
styler.format.thousands : str, optional
    The character representation for thousands separator for floats, int and complex.
    [default: None] [currently: None]
styler.html.mathjax : bool
    If False will render special CSS classes to table attributes that indicate Mathjax
    will not be used in Jupyter Notebook.
    [default: True] [currently: True]
styler.latex.environment : str
    The environment to replace ``\begin{table}``. If ""longtable"" is used results
    in a specific longtable environment format.
    [default: None] [currently: None]
styler.latex.hrules : bool
    Whether to add horizontal rules on top and bottom and below the headers.
    [default: False] [currently: False]
styler.latex.multicol_align : {""r"", ""c"", ""l"", ""naive-l"", ""naive-r""}
    The specifier for horizontal alignment of sparsified LaTeX multicolumns. Pipe
    decorators can also be added to non-naive values to draw vertical
    rules, e.g. ""\|r"" will draw a rule on the left side of right aligned merged cells.
    [default: r] [currently: r]
styler.latex.multirow_align : {""c"", ""t"", ""b""}
    The specifier for vertical alignment of sparsified LaTeX multirows.
    [default: c] [currently: c]
styler.render.encoding : str
    The encoding used for output HTML and LaTeX files.
    [default: utf-8] [currently: utf-8]
styler.render.max_columns : int, optional
    The maximum number of columns that will be rendered. May still be reduced to
    satisfy ``max_elements``, which takes precedence.
    [default: None] [currently: None]
styler.render.max_elements : int
    The maximum number of data-cell () elements that will be rendered before
    trimming will occur over columns, rows or both if needed.
    [default: 262144] [currently: 262144]
styler.render.max_rows : int, optional
    The maximum number of rows that will be rendered. May still be reduced to
    satisfy ``max_elements``, which takes precedence.
    [default: None] [currently: None]
styler.render.repr : str
    Determine which output to use in Jupyter Notebook in {""html"", ""latex""}.
    [default: html] [currently: html]
styler.sparse.columns : bool
    Whether to sparsify the display of hierarchical columns. Setting to False will
    display each explicit level element in a hierarchical key for each column.
    [default: True] [currently: True]
styler.sparse.index : bool
    Whether to sparsify the display of a hierarchical index. Setting to False will
    display each explicit level element in a hierarchical key for each row.
    [default: True] [currently: True]
",https://pandas.pydata.org/docs/user_guide/options.html, pandas.DataFrame.info
"In [24]: df = pd.DataFrame(np.random.randn(7, 2))

In [25]: pd.set_option(""display.max_rows"", 7)

In [26]: df
Out[26]: 
          0         1
0  0.469112 -0.282863
1 -1.509059 -1.135632
2  1.212112 -0.173215
3  0.119209 -1.044236
4 -0.861849 -2.104569
5 -0.494929  1.071804
6  0.721555 -0.706771

In [27]: pd.set_option(""display.max_rows"", 5)

In [28]: df
Out[28]: 
           0         1
0   0.469112 -0.282863
1  -1.509059 -1.135632
..       ...       ...
5  -0.494929  1.071804
6   0.721555 -0.706771

[7 rows x 2 columns]

In [29]: pd.reset_option(""display.max_rows"")
",https://pandas.pydata.org/docs/user_guide/options.html, pandas.DataFrame
"In [30]: pd.set_option(""display.max_rows"", 8)

In [31]: pd.set_option(""display.min_rows"", 4)

# below max_rows -> all rows shown
In [32]: df = pd.DataFrame(np.random.randn(7, 2))

In [33]: df
Out[33]: 
          0         1
0 -1.039575  0.271860
1 -0.424972  0.567020
2  0.276232 -1.087401
3 -0.673690  0.113648
4 -1.478427  0.524988
5  0.404705  0.577046
6 -1.715002 -1.039268

# above max_rows -> only min_rows (4) rows shown
In [34]: df = pd.DataFrame(np.random.randn(9, 2))

In [35]: df
Out[35]: 
           0         1
0  -0.370647 -1.157892
1  -1.344312  0.844885
..       ...       ...
7   0.276662 -0.472035
8  -0.013960 -0.362543

[9 rows x 2 columns]

In [36]: pd.reset_option(""display.max_rows"")

In [37]: pd.reset_option(""display.min_rows"")
",https://pandas.pydata.org/docs/user_guide/options.html, pandas.DataFrame
"In [38]: df = pd.DataFrame(np.random.randn(5, 10))

In [39]: pd.set_option(""expand_frame_repr"", True)

In [40]: df
Out[40]: 
          0         1         2  ...         7         8         9
0 -0.006154 -0.923061  0.895717  ...  1.340309 -1.170299 -0.226169
1  0.410835  0.813850  0.132003  ... -1.436737 -1.413681  1.607920
2  1.024180  0.569605  0.875906  ... -0.078638  0.545952 -1.219217
3 -1.226825  0.769804 -1.281247  ...  0.341734  0.959726 -1.110336
4 -0.619976  0.149748 -0.732339  ...  0.301624 -2.179861 -1.369849

[5 rows x 10 columns]

In [41]: pd.set_option(""expand_frame_repr"", False)

In [42]: df
Out[42]: 
          0         1         2         3         4         5         6         7         8         9
0 -0.006154 -0.923061  0.895717  0.805244 -1.206412  2.565646  1.431256  1.340309 -1.170299 -0.226169
1  0.410835  0.813850  0.132003 -0.827317 -0.076467 -1.187678  1.130127 -1.436737 -1.413681  1.607920
2  1.024180  0.569605  0.875906 -2.211372  0.974466 -2.006747 -0.410001 -0.078638  0.545952 -1.219217
3 -1.226825  0.769804 -1.281247 -0.727707 -0.121306 -0.097883  0.695775  0.341734  0.959726 -1.110336
4 -0.619976  0.149748 -0.732339  0.687738  0.176444  0.403310 -0.154951  0.301624 -2.179861 -1.369849

In [43]: pd.reset_option(""expand_frame_repr"")
",https://pandas.pydata.org/docs/user_guide/options.html, pandas.DataFrame
"In [44]: df = pd.DataFrame(np.random.randn(10, 10))

In [45]: pd.set_option(""display.max_rows"", 5)

In [46]: pd.set_option(""large_repr"", ""truncate"")

In [47]: df
Out[47]: 
           0         1         2  ...         7         8         9
0  -0.954208  1.462696 -1.743161  ...  0.995761  2.396780  0.014871
1   3.357427 -0.317441 -1.236269  ...  0.380396  0.084844  0.432390
..       ...       ...       ...  ...       ...       ...       ...
8  -0.303421 -0.858447  0.306996  ...  0.476720  0.473424 -0.242861
9  -0.014805 -0.284319  0.650776  ...  1.613616  0.464000  0.227371

[10 rows x 10 columns]

In [48]: pd.set_option(""large_repr"", ""info"")

In [49]: df
Out[49]: 

RangeIndex: 10 entries, 0 to 9
Data columns (total 10 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       10 non-null     float64
 1   1       10 non-null     float64
 2   2       10 non-null     float64
 3   3       10 non-null     float64
 4   4       10 non-null     float64
 5   5       10 non-null     float64
 6   6       10 non-null     float64
 7   7       10 non-null     float64
 8   8       10 non-null     float64
 9   9       10 non-null     float64
dtypes: float64(10)
memory usage: 928.0 bytes

In [50]: pd.reset_option(""large_repr"")

In [51]: pd.reset_option(""display.max_rows"")
",https://pandas.pydata.org/docs/user_guide/options.html, pandas.DataFrame
"In [52]: df = pd.DataFrame(
   ....:     np.array(
   ....:         [
   ....:             [""foo"", ""bar"", ""bim"", ""uncomfortably long string""],
   ....:             [""horse"", ""cow"", ""banana"", ""apple""],
   ....:         ]
   ....:     )
   ....: )
   ....: 

In [53]: pd.set_option(""max_colwidth"", 40)

In [54]: df
Out[54]: 
       0    1       2                          3
0    foo  bar     bim  uncomfortably long string
1  horse  cow  banana                      apple

In [55]: pd.set_option(""max_colwidth"", 6)

In [56]: df
Out[56]: 
       0    1      2      3
0    foo  bar    bim  un...
1  horse  cow  ba...  apple

In [57]: pd.reset_option(""max_colwidth"")
",https://pandas.pydata.org/docs/user_guide/options.html, pandas.DataFrame
"In [58]: df = pd.DataFrame(np.random.randn(10, 10))

In [59]: pd.set_option(""max_info_columns"", 11)

In [60]: df.info()

RangeIndex: 10 entries, 0 to 9
Data columns (total 10 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       10 non-null     float64
 1   1       10 non-null     float64
 2   2       10 non-null     float64
 3   3       10 non-null     float64
 4   4       10 non-null     float64
 5   5       10 non-null     float64
 6   6       10 non-null     float64
 7   7       10 non-null     float64
 8   8       10 non-null     float64
 9   9       10 non-null     float64
dtypes: float64(10)
memory usage: 928.0 bytes

In [61]: pd.set_option(""max_info_columns"", 5)

In [62]: df.info()

RangeIndex: 10 entries, 0 to 9
Columns: 10 entries, 0 to 9
dtypes: float64(10)
memory usage: 928.0 bytes

In [63]: pd.reset_option(""max_info_columns"")
",https://pandas.pydata.org/docs/user_guide/options.html, pandas.DataFrame pandas.DataFrame.info
"In [64]: df = pd.DataFrame(np.random.choice([0, 1, np.nan], size=(10, 10)))

In [65]: df
Out[65]: 
     0    1    2    3    4    5    6    7    8    9
0  0.0  NaN  1.0  NaN  NaN  0.0  NaN  0.0  NaN  1.0
1  1.0  NaN  1.0  1.0  1.0  1.0  NaN  0.0  0.0  NaN
2  0.0  NaN  1.0  0.0  0.0  NaN  NaN  NaN  NaN  0.0
3  NaN  NaN  NaN  0.0  1.0  1.0  NaN  1.0  NaN  1.0
4  0.0  NaN  NaN  NaN  0.0  NaN  NaN  NaN  1.0  0.0
5  0.0  1.0  1.0  1.0  1.0  0.0  NaN  NaN  1.0  0.0
6  1.0  1.0  1.0  NaN  1.0  NaN  1.0  0.0  NaN  NaN
7  0.0  0.0  1.0  0.0  1.0  0.0  1.0  1.0  0.0  NaN
8  NaN  NaN  NaN  0.0  NaN  NaN  NaN  NaN  1.0  NaN
9  0.0  NaN  0.0  NaN  NaN  0.0  NaN  1.0  1.0  0.0

In [66]: pd.set_option(""max_info_rows"", 11)

In [67]: df.info()

RangeIndex: 10 entries, 0 to 9
Data columns (total 10 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       8 non-null      float64
 1   1       3 non-null      float64
 2   2       7 non-null      float64
 3   3       6 non-null      float64
 4   4       7 non-null      float64
 5   5       6 non-null      float64
 6   6       2 non-null      float64
 7   7       6 non-null      float64
 8   8       6 non-null      float64
 9   9       6 non-null      float64
dtypes: float64(10)
memory usage: 928.0 bytes

In [68]: pd.set_option(""max_info_rows"", 5)

In [69]: df.info()

RangeIndex: 10 entries, 0 to 9
Data columns (total 10 columns):
 #   Column  Dtype  
---  ------  -----  
 0   0       float64
 1   1       float64
 2   2       float64
 3   3       float64
 4   4       float64
 5   5       float64
 6   6       float64
 7   7       float64
 8   8       float64
 9   9       float64
dtypes: float64(10)
memory usage: 928.0 bytes

In [70]: pd.reset_option(""max_info_rows"")
",https://pandas.pydata.org/docs/user_guide/options.html, pandas.DataFrame pandas.DataFrame.info
"In [71]: df = pd.DataFrame(np.random.randn(5, 5))

In [72]: pd.set_option(""display.precision"", 7)

In [73]: df
Out[73]: 
           0          1          2          3          4
0 -1.1506406 -0.7983341 -0.5576966  0.3813531  1.3371217
1 -1.5310949  1.3314582 -0.5713290 -0.0266708 -1.0856630
2 -1.1147378 -0.0582158 -0.4867681  1.6851483  0.1125723
3 -1.4953086  0.8984347 -0.1482168 -1.5960698  0.1596530
4  0.2621358  0.0362196  0.1847350 -0.2550694 -0.2710197

In [74]: pd.set_option(""display.precision"", 4)

In [75]: df
Out[75]: 
        0       1       2       3       4
0 -1.1506 -0.7983 -0.5577  0.3814  1.3371
1 -1.5311  1.3315 -0.5713 -0.0267 -1.0857
2 -1.1147 -0.0582 -0.4868  1.6851  0.1126
3 -1.4953  0.8984 -0.1482 -1.5961  0.1597
4  0.2621  0.0362  0.1847 -0.2551 -0.2710
",https://pandas.pydata.org/docs/user_guide/options.html, pandas.DataFrame
"In [76]: df = pd.DataFrame(np.random.randn(6, 6))

In [77]: pd.set_option(""chop_threshold"", 0)

In [78]: df
Out[78]: 
        0       1       2       3       4       5
0  1.2884  0.2946 -1.1658  0.8470 -0.6856  0.6091
1 -0.3040  0.6256 -0.0593  0.2497  1.1039 -1.0875
2  1.9980 -0.2445  0.1362  0.8863 -1.3507 -0.8863
3 -1.0133  1.9209 -0.3882 -2.3144  0.6655  0.4026
4  0.3996 -1.7660  0.8504  0.3881  0.9923  0.7441
5 -0.7398 -1.0549 -0.1796  0.6396  1.5850  1.9067

In [79]: pd.set_option(""chop_threshold"", 0.5)

In [80]: df
Out[80]: 
        0       1       2       3       4       5
0  1.2884  0.0000 -1.1658  0.8470 -0.6856  0.6091
1  0.0000  0.6256  0.0000  0.0000  1.1039 -1.0875
2  1.9980  0.0000  0.0000  0.8863 -1.3507 -0.8863
3 -1.0133  1.9209  0.0000 -2.3144  0.6655  0.0000
4  0.0000 -1.7660  0.8504  0.0000  0.9923  0.7441
5 -0.7398 -1.0549  0.0000  0.6396  1.5850  1.9067

In [81]: pd.reset_option(""chop_threshold"")
",https://pandas.pydata.org/docs/user_guide/options.html, pandas.DataFrame
"In [82]: df = pd.DataFrame(
   ....:     np.array([np.random.randn(6), np.random.randint(1, 9, 6) * 0.1, np.zeros(6)]).T,
   ....:     columns=[""A"", ""B"", ""C""],
   ....:     dtype=""float"",
   ....: )
   ....: 

In [83]: pd.set_option(""colheader_justify"", ""right"")

In [84]: df
Out[84]: 
        A    B    C
0  0.1040  0.1  0.0
1  0.1741  0.5  0.0
2 -0.4395  0.4  0.0
3 -0.7413  0.8  0.0
4 -0.0797  0.4  0.0
5 -0.9229  0.3  0.0

In [85]: pd.set_option(""colheader_justify"", ""left"")

In [86]: df
Out[86]: 
   A       B    C  
0  0.1040  0.1  0.0
1  0.1741  0.5  0.0
2 -0.4395  0.4  0.0
3 -0.7413  0.8  0.0
4 -0.0797  0.4  0.0
5 -0.9229  0.3  0.0

In [87]: pd.reset_option(""colheader_justify"")
",https://pandas.pydata.org/docs/user_guide/options.html, pandas.DataFrame
"In [88]: import numpy as np

In [89]: pd.set_eng_float_format(accuracy=3, use_eng_prefix=True)

In [90]: s = pd.Series(np.random.randn(5), index=[""a"", ""b"", ""c"", ""d"", ""e""])

In [91]: s / 1.0e3
Out[91]: 
a    303.638u
b   -721.084u
c   -622.696u
d    648.250u
e     -1.945m
dtype: float64

In [92]: s / 1.0e6
Out[92]: 
a    303.638n
b   -721.084n
c   -622.696n
d    648.250n
e     -1.945u
dtype: float64
",https://pandas.pydata.org/docs/user_guide/options.html, pandas.set_eng_float_format pandas.Series
"In [93]: df = pd.DataFrame({""国籍"": [""UK"", ""日本""], ""名前"": [""Alice"", ""しのぶ""]})

In [94]: df
Out[94]: 
   国籍     名前
0  UK  Alice
1  日本    しのぶ
",https://pandas.pydata.org/docs/user_guide/options.html, pandas.DataFrame
"In [97]: df = pd.DataFrame({""a"": [""xxx"", ""¡¡""], ""b"": [""yyy"", ""¡¡""]})

In [98]: df
Out[98]: 
     a    b
0  xxx  yyy
1   ¡¡   ¡¡
",https://pandas.pydata.org/docs/user_guide/options.html, pandas.DataFrame
">>> ser = pd.Series(['a', 'b', 'c', 'a'], dtype='category')
>>> ser.cat.ordered
False
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.ordered.html, pandas.Series
">>> raw_cat = pd.Categorical(['a', 'b', 'c', 'a'], ordered=True)
>>> ser = pd.Series(raw_cat)
>>> ser.cat.ordered
True
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.ordered.html, pandas.Categorical pandas.Series
">>> cat = pd.Categorical(['a', 'b'], ordered=True)
>>> cat.ordered
True
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.ordered.html, pandas.Categorical
">>> cat = pd.Categorical(['a', 'b'], ordered=False)
>>> cat.ordered
False
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.ordered.html, pandas.Categorical
">>> ci = pd.CategoricalIndex(['a', 'b'], ordered=True)
>>> ci.ordered
True
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.ordered.html, pandas.CategoricalIndex
">>> ci = pd.CategoricalIndex(['a', 'b'], ordered=False)
>>> ci.ordered
False
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.ordered.html, pandas.CategoricalIndex
">>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])
>>> a
a    1.0
b    1.0
c    1.0
d    NaN
dtype: float64
>>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])
>>> b
a    1.0
b    NaN
d    1.0
e    NaN
dtype: float64
>>> a.mod(b, fill_value=0)
a    0.0
b    NaN
c    NaN
d    0.0
e    NaN
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.mod.html, pandas.Series pandas.Series.mod
">>> s = pd.Series(['1. Ant.  ', '2. Bee!\n', '3. Cat?\t', np.nan, 10, True])
>>> s
0    1. Ant.
1    2. Bee!\n
2    3. Cat?\t
3          NaN
4           10
5         True
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.rstrip.html, pandas.Series
">>> s.str.strip()
0    1. Ant.
1    2. Bee!
2    3. Cat?
3        NaN
4        NaN
5        NaN
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.rstrip.html, pandas.Series.str.strip
">>> s.str.lstrip('123.')
0    Ant.
1    Bee!\n
2    Cat?\t
3       NaN
4       NaN
5       NaN
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.rstrip.html, pandas.Series.str.lstrip
">>> s.str.rstrip('.!? \n\t')
0    1. Ant
1    2. Bee
2    3. Cat
3       NaN
4       NaN
5       NaN
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.rstrip.html, pandas.Series.str.rstrip
">>> s.str.strip('123.!? \n\t')
0    Ant
1    Bee
2    Cat
3    NaN
4    NaN
5    NaN
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.rstrip.html, pandas.Series.str.strip
">>> pd.Series([2, 1, 3, 3], name='A').unique()
array([2, 1, 3])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.unique.html, pandas.Series pandas.array
">>> pd.Series([pd.Timestamp('2016-01-01') for _ in range(3)]).unique()

['2016-01-01 00:00:00']
Length: 1, dtype: datetime64[ns]
",https://pandas.pydata.org/docs/reference/api/pandas.Series.unique.html, pandas.Series
">>> pd.Series([pd.Timestamp('2016-01-01', tz='US/Eastern')
...            for _ in range(3)]).unique()

['2016-01-01 00:00:00-05:00']
Length: 1, dtype: datetime64[ns, US/Eastern]
",https://pandas.pydata.org/docs/reference/api/pandas.Series.unique.html, pandas.Series
">>> pd.Series(pd.Categorical(list('baabc'))).unique()
['b', 'a', 'c']
Categories (3, object): ['a', 'b', 'c']
>>> pd.Series(pd.Categorical(list('baabc'), categories=list('abc'),
...                          ordered=True)).unique()
['b', 'a', 'c']
Categories (3, object): ['a' < 'b' < 'c']
",https://pandas.pydata.org/docs/reference/api/pandas.Series.unique.html, pandas.Series pandas.Categorical
">>> df = pd.DataFrame(data={'Animal': ['cat', 'penguin', 'dog',
...                                    'spider', 'snake'],
...                         'Number_legs': [4, 2, 4, 8, np.nan]})
>>> df
    Animal  Number_legs
0      cat          4.0
1  penguin          2.0
2      dog          4.0
3   spider          8.0
4    snake          NaN
",https://pandas.pydata.org/docs/reference/api/pandas.Series.rank.html, pandas.DataFrame
">>> s = pd.Series(range(5), index=list(""abcde""))
>>> s[""d""] = s[""b""]
>>> s.rank()
a    1.0
b    2.5
c    4.0
d    2.5
e    5.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.rank.html, pandas.Series pandas.Series.rank
">>> s1 = pd.Series(['one', 'one1', '1', ''])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isalnum.html, pandas.Series
">>> s1.str.isalpha()
0     True
1    False
2    False
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isalnum.html, pandas.Series.str.isalpha
">>> s1.str.isnumeric()
0    False
1    False
2     True
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isalnum.html, pandas.Series.str.isnumeric
">>> s1.str.isalnum()
0     True
1     True
2     True
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isalnum.html, pandas.Series.str.isalnum
">>> s2 = pd.Series(['A B', '1.5', '3,000'])
>>> s2.str.isalnum()
0    False
1    False
2    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isalnum.html, pandas.Series pandas.Series.str.isalnum
">>> s3 = pd.Series(['23', '³', '⅕', ''])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isalnum.html, pandas.Series
">>> s3.str.isdecimal()
0     True
1    False
2    False
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isalnum.html, pandas.Series.str.isdecimal
">>> s3.str.isdigit()
0     True
1     True
2    False
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isalnum.html, pandas.Series.str.isdigit
">>> s3.str.isnumeric()
0     True
1     True
2     True
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isalnum.html, pandas.Series.str.isnumeric
">>> s4 = pd.Series([' ', '\t\r\n ', ''])
>>> s4.str.isspace()
0     True
1     True
2    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isalnum.html, pandas.Series pandas.Series.str.isspace
">>> s5 = pd.Series(['leopard', 'Golden Eagle', 'SNAKE', ''])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isalnum.html, pandas.Series
">>> s5.str.islower()
0     True
1    False
2    False
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isalnum.html, pandas.Series.str.islower
">>> s5.str.isupper()
0    False
1    False
2     True
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isalnum.html, pandas.Series.str.isupper
">>> s5.str.istitle()
0    False
1     True
2    False
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isalnum.html, pandas.Series.str.istitle
">>> ser = pd.Series(['dog', 'bird', 'mouse'])
>>> ser.str.center(8, fillchar='.')
0   ..dog...
1   ..bird..
2   .mouse..
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.rjust.html, pandas.Series pandas.Series.str.center
">>> ser = pd.Series(['dog', 'bird', 'mouse'])
>>> ser.str.ljust(8, fillchar='.')
0   dog.....
1   bird....
2   mouse...
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.rjust.html, pandas.Series pandas.Series.str.ljust
">>> ser = pd.Series(['dog', 'bird', 'mouse'])
>>> ser.str.rjust(8, fillchar='.')
0   .....dog
1   ....bird
2   ...mouse
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.rjust.html, pandas.Series pandas.Series.str.rjust
">>> c = pd.Categorical(['c', 'b', 'c'])
>>> c
['c', 'b', 'c']
Categories (2, object): ['b', 'c']
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.add_categories.html, pandas.Categorical
">>> df = pd.DataFrame([[1, 2, 3], [4, 5, 6]], columns=['A', 'B', 'C'])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.to_clipboard.html, pandas.DataFrame
">>> df.to_clipboard(sep=',')  
... # Wrote the following to the system clipboard:
... # ,A,B,C
... # 0,1,2,3
... # 1,4,5,6
",https://pandas.pydata.org/docs/reference/api/pandas.Series.to_clipboard.html, pandas.DataFrame.to_clipboard
">>> df.to_clipboard(sep=',', index=False)  
... # Wrote the following to the system clipboard:
... # A,B,C
... # 1,2,3
... # 4,5,6
",https://pandas.pydata.org/docs/reference/api/pandas.Series.to_clipboard.html, pandas.DataFrame.to_clipboard
">>> s = pd.Series([""1/1/2020 10:00:00+00:00"", ""2/1/2020 11:00:00+00:00""])
>>> s = pd.to_datetime(s)
>>> s
0   2020-01-01 10:00:00+00:00
1   2020-02-01 11:00:00+00:00
dtype: datetime64[ns, UTC]
>>> s.dt.dayofyear
0    1
1   32
dtype: int32
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.dayofyear.html, pandas.Series pandas.to_datetime
">>> idx = pd.DatetimeIndex([""1/1/2020 10:00:00+00:00"",
...                         ""2/1/2020 11:00:00+00:00""])
>>> idx.dayofyear
Index([1, 32], dtype='int32')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.dayofyear.html, pandas.DatetimeIndex pandas.Index
">>> df = pd.DataFrame({""A"": [1, 2]})
>>> df.flags.allows_duplicate_labels
True
>>> df2 = df.set_flags(allows_duplicate_labels=False)
>>> df2.flags.allows_duplicate_labels
False
",https://pandas.pydata.org/docs/reference/api/pandas.Series.set_flags.html, pandas.DataFrame pandas.DataFrame.set_flags
">>> df = pd.DataFrame(np.array(([1, 2, 3], [4, 5, 6])),
...                   index=['mouse', 'rabbit'],
...                   columns=['one', 'two', 'three'])
>>> df
        one  two  three
mouse     1    2      3
rabbit    4    5      6
",https://pandas.pydata.org/docs/reference/api/pandas.Series.filter.html, pandas.DataFrame
">>> # select columns by name
>>> df.filter(items=['one', 'three'])
         one  three
mouse     1      3
rabbit    4      6
",https://pandas.pydata.org/docs/reference/api/pandas.Series.filter.html, pandas.DataFrame.filter
">>> # select columns by regular expression
>>> df.filter(regex='e$', axis=1)
         one  three
mouse     1      3
rabbit    4      6
",https://pandas.pydata.org/docs/reference/api/pandas.Series.filter.html, pandas.DataFrame.filter
">>> # select rows containing 'bbi'
>>> df.filter(like='bbi', axis=0)
         one  two  three
rabbit    4    5      6
",https://pandas.pydata.org/docs/reference/api/pandas.Series.filter.html, pandas.DataFrame.filter
">>> datetime_series = pd.Series(
...     pd.date_range(""2000-01-01"", periods=3, freq=""D"")
... )
>>> datetime_series
0   2000-01-01
1   2000-01-02
2   2000-01-03
dtype: datetime64[ns]
>>> datetime_series.dt.day
0    1
1    2
2    3
dtype: int32
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.day.html, pandas.Series pandas.date_range
">>> df = pd.DataFrame({
...     'sales': [3, 2, 3, 9, 10, 6],
...     'signups': [5, 5, 6, 12, 14, 13],
...     'visits': [20, 42, 28, 62, 81, 50],
... }, index=pd.date_range(start='2018/01/01', end='2018/07/01',
...                        freq='ME'))
>>> ax = df.plot.area()
",https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.area.html, pandas.DataFrame pandas.date_range pandas.DataFrame.plot.area
">>> ax = df.plot.area(stacked=False)
",https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.area.html, pandas.DataFrame.plot.area
">>> ax = df.plot.area(y='sales')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.area.html, pandas.DataFrame.plot.area
">>> df = pd.DataFrame({
...     'sales': [3, 2, 3],
...     'visits': [20, 42, 28],
...     'day': [1, 2, 3],
... })
>>> ax = df.plot.area(x='day')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.area.html, pandas.DataFrame pandas.DataFrame.plot.area
">>> d = {'a': 1, 'b': 2, 'c': 3}
>>> ser = pd.Series(data=d, index=['a', 'b', 'c'])
>>> ser
a   1
b   2
c   3
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.html, pandas.Series
">>> d = {'a': 1, 'b': 2, 'c': 3}
>>> ser = pd.Series(data=d, index=['x', 'y', 'z'])
>>> ser
x   NaN
y   NaN
z   NaN
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.html, pandas.Series
">>> r = [1, 2]
>>> ser = pd.Series(r, copy=False)
>>> ser.iloc[0] = 999
>>> r
[1, 2]
>>> ser
0    999
1      2
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.html, pandas.Series
">>> r = np.array([1, 2])
>>> ser = pd.Series(r, copy=False)
>>> ser.iloc[0] = 999
>>> r
array([999,   2])
>>> ser
0    999
1      2
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.html, pandas.Series pandas.array
">>> s = pd.Series([2, np.nan, 5, -1, 0])
>>> s
0    2.0
1    NaN
2    5.0
3   -1.0
4    0.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cumprod.html, pandas.Series
">>> s.cumprod()
0     2.0
1     NaN
2    10.0
3   -10.0
4    -0.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cumprod.html, pandas.Series.cumprod
">>> s.cumprod(skipna=False)
0    2.0
1    NaN
2    NaN
3    NaN
4    NaN
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cumprod.html, pandas.Series.cumprod
">>> df = pd.DataFrame([[2.0, 1.0],
...                    [3.0, np.nan],
...                    [1.0, 0.0]],
...                   columns=list('AB'))
>>> df
     A    B
0  2.0  1.0
1  3.0  NaN
2  1.0  0.0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cumprod.html, pandas.DataFrame
">>> df.cumprod()
     A    B
0  2.0  1.0
1  6.0  NaN
2  6.0  0.0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cumprod.html, pandas.DataFrame.cumprod
">>> df.cumprod(axis=1)
     A    B
0  2.0  2.0
1  3.0  NaN
2  1.0  0.0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cumprod.html, pandas.DataFrame.cumprod
">>> s = pd.Series(range(3))
>>> s.memory_usage()
152
",https://pandas.pydata.org/docs/reference/api/pandas.Series.memory_usage.html, pandas.Series pandas.Series.memory_usage
">>> s.memory_usage(index=False)
24
",https://pandas.pydata.org/docs/reference/api/pandas.Series.memory_usage.html, pandas.Series.memory_usage
">>> s = pd.Series([""a"", ""b""])
>>> s.values
array(['a', 'b'], dtype=object)
>>> s.memory_usage()
144
>>> s.memory_usage(deep=True)
244
",https://pandas.pydata.org/docs/reference/api/pandas.Series.memory_usage.html, pandas.Series pandas.array pandas.Series.memory_usage
">>> data = [[8000, 1000], [9500, np.nan], [5000, 2000]]
>>> df = pd.DataFrame(data, columns=['Salary', 'Others'])
>>> df
   Salary  Others
0    8000  1000.0
1    9500     NaN
2    5000  2000.0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.pipe.html, pandas.DataFrame
">>> (
...     df.pipe(subtract_federal_tax)
...     .pipe(subtract_state_tax, rate=0.12)
...     .pipe(subtract_national_insurance, rate=0.05, rate_increase=0.02)
... )
    Salary   Others
0  5892.48   736.56
1  6997.32      NaN
2  3682.80  1473.12
",https://pandas.pydata.org/docs/reference/api/pandas.Series.pipe.html, pandas.DataFrame.pipe
">>> def subtract_national_insurance(rate, df, rate_increase):
...     new_rate = rate + rate_increase
...     return df * (1 - new_rate)
>>> (
...     df.pipe(subtract_federal_tax)
...     .pipe(subtract_state_tax, rate=0.12)
...     .pipe(
...         (subtract_national_insurance, 'df'),
...         rate=0.05,
...         rate_increase=0.02
...     )
... )
    Salary   Others
0  5892.48   736.56
1  6997.32      NaN
2  3682.80  1473.12
",https://pandas.pydata.org/docs/reference/api/pandas.Series.pipe.html, pandas.DataFrame.pipe
">>> s = pd.Series([1, 2, 3, 4],
...               index=pd.MultiIndex.from_product([['one', 'two'],
...                                                 ['a', 'b']]))
>>> s
one  a    1
     b    2
two  a    3
     b    4
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.unstack.html, pandas.Series pandas.MultiIndex.from_product
">>> s.unstack(level=-1)
     a  b
one  1  2
two  3  4
",https://pandas.pydata.org/docs/reference/api/pandas.Series.unstack.html, pandas.Series.unstack
">>> s.unstack(level=0)
   one  two
a    1    3
b    2    4
",https://pandas.pydata.org/docs/reference/api/pandas.Series.unstack.html, pandas.Series.unstack
">>> s1 = pd.Series(['one', 'one1', '1', ''])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isupper.html, pandas.Series
">>> s1.str.isalpha()
0     True
1    False
2    False
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isupper.html, pandas.Series.str.isalpha
">>> s1.str.isnumeric()
0    False
1    False
2     True
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isupper.html, pandas.Series.str.isnumeric
">>> s1.str.isalnum()
0     True
1     True
2     True
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isupper.html, pandas.Series.str.isalnum
">>> s2 = pd.Series(['A B', '1.5', '3,000'])
>>> s2.str.isalnum()
0    False
1    False
2    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isupper.html, pandas.Series pandas.Series.str.isalnum
">>> s3 = pd.Series(['23', '³', '⅕', ''])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isupper.html, pandas.Series
">>> s3.str.isdecimal()
0     True
1    False
2    False
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isupper.html, pandas.Series.str.isdecimal
">>> s3.str.isdigit()
0     True
1     True
2    False
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isupper.html, pandas.Series.str.isdigit
">>> s3.str.isnumeric()
0     True
1     True
2     True
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isupper.html, pandas.Series.str.isnumeric
">>> s4 = pd.Series([' ', '\t\r\n ', ''])
>>> s4.str.isspace()
0     True
1     True
2    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isupper.html, pandas.Series pandas.Series.str.isspace
">>> s5 = pd.Series(['leopard', 'Golden Eagle', 'SNAKE', ''])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isupper.html, pandas.Series
">>> s5.str.islower()
0     True
1    False
2    False
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isupper.html, pandas.Series.str.islower
">>> s5.str.isupper()
0    False
1    False
2     True
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isupper.html, pandas.Series.str.isupper
">>> s5.str.istitle()
0    False
1     True
2    False
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isupper.html, pandas.Series.str.istitle
">>> ser = pd.Series(['a', 'b', 'c', 'a'], dtype='category')
>>> ser.cat.categories
Index(['a', 'b', 'c'], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.categories.html, pandas.Series pandas.Index
">>> raw_cat = pd.Categorical(['a', 'b', 'c', 'a'], categories=['b', 'c', 'd'])
>>> ser = pd.Series(raw_cat)
>>> ser.cat.categories
Index(['b', 'c', 'd'], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.categories.html, pandas.Categorical pandas.Series pandas.Index
">>> cat = pd.Categorical(['a', 'b'], ordered=True)
>>> cat.categories
Index(['a', 'b'], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.categories.html, pandas.Categorical pandas.Index
">>> ci = pd.CategoricalIndex(['a', 'c', 'b', 'a', 'c', 'b'])
>>> ci.categories
Index(['a', 'b', 'c'], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.categories.html, pandas.CategoricalIndex pandas.Index
">>> ci = pd.CategoricalIndex(['a', 'c'], categories=['c', 'b', 'a'])
>>> ci.categories
Index(['c', 'b', 'a'], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.categories.html, pandas.CategoricalIndex pandas.Index
">>> from pandas.arrays import SparseArray
>>> s = SparseArray([0, 0, 1, 1, 1], fill_value=0)
>>> s.density
0.6
",https://pandas.pydata.org/docs/reference/api/pandas.Series.sparse.density.html, pandas.arrays.SparseArray
">>> s = pd.Series([1, 2, 3, 4])
>>> s
0    1
1    2
2    3
3    4
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.agg.html, pandas.Series
">>> s.agg('min')
1
",https://pandas.pydata.org/docs/reference/api/pandas.Series.agg.html, pandas.Series.agg
">>> s.agg(['min', 'max'])
min   1
max   4
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.agg.html, pandas.Series.agg
">>> s = pd.Series(['dog',
...                 '',
...                 5,
...                 {'foo' : 'bar'},
...                 [2, 3, 5, 7],
...                 ('one', 'two', 'three')])
>>> s
0                  dog
1
2                    5
3       {'foo': 'bar'}
4         [2, 3, 5, 7]
5    (one, two, three)
dtype: object
>>> s.str.len()
0    3.0
1    0.0
2    NaN
3    1.0
4    4.0
5    3.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.len.html, pandas.Series pandas.Series.str.len
">>> s = pd.Series(['bat', 'bear', 'caT', np.nan])
>>> s
0     bat
1    bear
2     caT
3     NaN
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.endswith.html, pandas.Series
">>> s.str.endswith('t')
0     True
1    False
2    False
3      NaN
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.endswith.html, pandas.Series.str.endswith
">>> s.str.endswith(('t', 'T'))
0     True
1    False
2     True
3      NaN
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.endswith.html, pandas.Series.str.endswith
">>> s.str.endswith('t', na=False)
0     True
1    False
2    False
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.endswith.html, pandas.Series.str.endswith
">>> dates = pd.Series(pd.date_range(""2017-12-30"", periods=3))
>>> dates
0   2017-12-30
1   2017-12-31
2   2018-01-01
dtype: datetime64[ns]
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.is_year_start.html, pandas.Series pandas.date_range
">>> idx = pd.date_range(""2017-12-30"", periods=3)
>>> idx
DatetimeIndex(['2017-12-30', '2017-12-31', '2018-01-01'],
              dtype='datetime64[ns]', freq='D')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.is_year_start.html, pandas.date_range pandas.DatetimeIndex
">>> idx.is_year_start
array([False, False,  True])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.is_year_start.html, pandas.array
">>> s = pd.Series(['line to be wrapped', 'another line to be wrapped'])
>>> s.str.wrap(12)
0             line to be\nwrapped
1    another line\nto be\nwrapped
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.wrap.html, pandas.Series pandas.Series.str.wrap
">>> ser = pd.Series(pd.to_timedelta([1, 2, 3], unit='s'))
>>> ser
0   0 days 00:00:01
1   0 days 00:00:02
2   0 days 00:00:03
dtype: timedelta64[ns]
>>> ser.dt.seconds
0    1
1    2
2    3
dtype: int32
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.seconds.html, pandas.Series pandas.to_timedelta
">>> tdelta_idx = pd.to_timedelta([1, 2, 3], unit='s')
>>> tdelta_idx
TimedeltaIndex(['0 days 00:00:01', '0 days 00:00:02', '0 days 00:00:03'],
               dtype='timedelta64[ns]', freq=None)
>>> tdelta_idx.seconds
Index([1, 2, 3], dtype='int32')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.seconds.html, pandas.to_timedelta pandas.TimedeltaIndex pandas.Index
">>> s = pd.Series(['lower', 'CAPITALS', 'this is a sentence', 'SwApCaSe'])
>>> s
0                 lower
1              CAPITALS
2    this is a sentence
3              SwApCaSe
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.swapcase.html, pandas.Series
">>> s.str.lower()
0                 lower
1              capitals
2    this is a sentence
3              swapcase
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.swapcase.html, pandas.Series.str.lower
">>> s.str.upper()
0                 LOWER
1              CAPITALS
2    THIS IS A SENTENCE
3              SWAPCASE
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.swapcase.html, pandas.Series.str.upper
">>> s.str.title()
0                 Lower
1              Capitals
2    This Is A Sentence
3              Swapcase
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.swapcase.html, pandas.Series.str.title
">>> s.str.capitalize()
0                 Lower
1              Capitals
2    This is a sentence
3              Swapcase
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.swapcase.html, pandas.Series.str.capitalize
">>> s.str.swapcase()
0                 LOWER
1              capitals
2    THIS IS A SENTENCE
3              sWaPcAsE
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.swapcase.html, pandas.Series.str.swapcase
">>> s = pd.Series(['llama', 'cow', 'llama', 'beetle', 'llama',
...                'hippo'], name='animal')
>>> s.isin(['cow', 'llama'])
0     True
1     True
2     True
3    False
4     True
5    False
Name: animal, dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.isin.html, pandas.Series pandas.Series.isin
">>> ~s.isin(['cow', 'llama'])
0    False
1    False
2    False
3     True
4    False
5     True
Name: animal, dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.isin.html, pandas.Series.isin
">>> s.isin(['llama'])
0     True
1    False
2     True
3    False
4     True
5    False
Name: animal, dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.isin.html, pandas.Series.isin
">>> pd.Series([1]).isin(['1'])
0    False
dtype: bool
>>> pd.Series([1.1]).isin(['1.1'])
0    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.isin.html, pandas.Series
">>> s = pd.Series(list(""abbccc"")).astype(""category"")
>>> s
0    a
1    b
2    b
3    c
4    c
5    c
dtype: category
Categories (3, object): ['a', 'b', 'c']
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.html, pandas.Series
">>> s.cat.categories
Index(['a', 'b', 'c'], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.html, pandas.Index
">>> s.cat.rename_categories(list(""cba""))
0    c
1    b
2    b
3    a
4    a
5    a
dtype: category
Categories (3, object): ['c', 'b', 'a']
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.html, pandas.Series.cat.rename_categories
">>> s.cat.reorder_categories(list(""cba""))
0    a
1    b
2    b
3    c
4    c
5    c
dtype: category
Categories (3, object): ['c', 'b', 'a']
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.html, pandas.Series.cat.reorder_categories
">>> s.cat.add_categories([""d"", ""e""])
0    a
1    b
2    b
3    c
4    c
5    c
dtype: category
Categories (5, object): ['a', 'b', 'c', 'd', 'e']
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.html, pandas.Series.cat.add_categories
">>> s.cat.remove_categories([""a"", ""c""])
0    NaN
1      b
2      b
3    NaN
4    NaN
5    NaN
dtype: category
Categories (1, object): ['b']
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.html, pandas.Series.cat.remove_categories
">>> s1 = s.cat.add_categories([""d"", ""e""])
>>> s1.cat.remove_unused_categories()
0    a
1    b
2    b
3    c
4    c
5    c
dtype: category
Categories (3, object): ['a', 'b', 'c']
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.html, pandas.Series.cat.add_categories pandas.Series.cat.remove_unused_categories
">>> s.cat.set_categories(list(""abcde""))
0    a
1    b
2    b
3    c
4    c
5    c
dtype: category
Categories (5, object): ['a', 'b', 'c', 'd', 'e']
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.html, pandas.Series.cat.set_categories
">>> s.cat.as_ordered()
0    a
1    b
2    b
3    c
4    c
5    c
dtype: category
Categories (3, object): ['a' < 'b' < 'c']
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.html, pandas.Series.cat.as_ordered
">>> s.cat.as_unordered()
0    a
1    b
2    b
3    c
4    c
5    c
dtype: category
Categories (3, object): ['a', 'b', 'c']
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.html, pandas.Series.cat.as_unordered
">>> ser = pd.Series(pd.to_timedelta([1, 2, 3], unit='d'))
>>> ser
0   1 days
1   2 days
2   3 days
dtype: timedelta64[ns]
>>> ser.dt.days
0    1
1    2
2    3
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.days.html, pandas.Series pandas.to_timedelta
">>> tdelta_idx = pd.to_timedelta([""0 days"", ""10 days"", ""20 days""])
>>> tdelta_idx
TimedeltaIndex(['0 days', '10 days', '20 days'],
                dtype='timedelta64[ns]', freq=None)
>>> tdelta_idx.days
Index([0, 10, 20], dtype='int64')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.days.html, pandas.to_timedelta pandas.TimedeltaIndex pandas.Index
">>> ser = pd.Series([390., 350., 30., 20.],
...                 index=['Falcon', 'Falcon', 'Parrot', 'Parrot'],
...                 name=""Max Speed"")
>>> ser
Falcon    390.0
Falcon    350.0
Parrot     30.0
Parrot     20.0
Name: Max Speed, dtype: float64
>>> ser.groupby([""a"", ""b"", ""a"", ""b""]).mean()
a    210.0
b    185.0
Name: Max Speed, dtype: float64
>>> ser.groupby(level=0).mean()
Falcon    370.0
Parrot     25.0
Name: Max Speed, dtype: float64
>>> ser.groupby(ser > 100).mean()
Max Speed
False     25.0
True     370.0
Name: Max Speed, dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.groupby.html, pandas.Series pandas.Series.groupby
">>> arrays = [['Falcon', 'Falcon', 'Parrot', 'Parrot'],
...           ['Captive', 'Wild', 'Captive', 'Wild']]
>>> index = pd.MultiIndex.from_arrays(arrays, names=('Animal', 'Type'))
>>> ser = pd.Series([390., 350., 30., 20.], index=index, name=""Max Speed"")
>>> ser
Animal  Type
Falcon  Captive    390.0
        Wild       350.0
Parrot  Captive     30.0
        Wild        20.0
Name: Max Speed, dtype: float64
>>> ser.groupby(level=0).mean()
Animal
Falcon    370.0
Parrot     25.0
Name: Max Speed, dtype: float64
>>> ser.groupby(level=""Type"").mean()
Type
Captive    210.0
Wild       185.0
Name: Max Speed, dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.groupby.html, pandas.MultiIndex.from_arrays pandas.Series pandas.Series.groupby
">>> ser = pd.Series([1, 2, 3, 3], index=[""a"", 'a', 'b', np.nan])
>>> ser.groupby(level=0).sum()
a    3
b    3
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.groupby.html, pandas.Series pandas.Series.groupby
">>> ser.groupby(level=0, dropna=False).sum()
a    3
b    3
NaN  3
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.groupby.html, pandas.Series.groupby
">>> arrays = ['Falcon', 'Falcon', 'Parrot', 'Parrot']
>>> ser = pd.Series([390., 350., 30., 20.], index=arrays, name=""Max Speed"")
>>> ser.groupby([""a"", ""b"", ""a"", np.nan]).mean()
a    210.0
b    350.0
Name: Max Speed, dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.groupby.html, pandas.Series pandas.Series.groupby
">>> ser.groupby([""a"", ""b"", ""a"", np.nan], dropna=False).mean()
a    210.0
b    350.0
NaN   20.0
Name: Max Speed, dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.groupby.html, pandas.Series.groupby
">>> s = pd.Series([20, 21, 12],
...               index=['London', 'New York', 'Helsinki'])
>>> s
London      20
New York    21
Helsinki    12
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.apply.html, pandas.Series
">>> def square(x):
...     return x ** 2
>>> s.apply(square)
London      400
New York    441
Helsinki    144
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.apply.html, pandas.Series.apply
">>> s.apply(lambda x: x ** 2)
London      400
New York    441
Helsinki    144
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.apply.html, pandas.Series.apply
">>> s.apply(subtract_custom_value, args=(5,))
London      15
New York    16
Helsinki     7
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.apply.html, pandas.Series.apply
">>> s.apply(add_custom_values, june=30, july=20, august=25)
London      95
New York    96
Helsinki    87
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.apply.html, pandas.Series.apply
">>> s.apply(np.log)
London      2.995732
New York    3.044522
Helsinki    2.484907
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.apply.html, pandas.Series.apply
">>> s = pd.Series([0, 1, 2, 3])
>>> other = pd.Series([-1, 2, -3, 4])
>>> s.dot(other)
8
>>> s @ other
8
>>> df = pd.DataFrame([[0, 1], [-2, 3], [4, -5], [6, 7]])
>>> s.dot(df)
0    24
1    14
dtype: int64
>>> arr = np.array([[0, 1], [-2, 3], [4, -5], [6, 7]])
>>> s.dot(arr)
array([24, 14])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dot.html, pandas.Series pandas.Series.dot pandas.DataFrame pandas.array
">>> df = pd.DataFrame([('falcon', 'bird', 389.0),
...                    ('parrot', 'bird', 24.0),
...                    ('lion', 'mammal', 80.5),
...                    ('monkey', 'mammal', np.nan)],
...                   columns=['name', 'class', 'max_speed'],
...                   index=[0, 2, 3, 1])
>>> df
     name   class  max_speed
0  falcon    bird      389.0
2  parrot    bird       24.0
3    lion  mammal       80.5
1  monkey  mammal        NaN
",https://pandas.pydata.org/docs/reference/api/pandas.Series.take.html, pandas.DataFrame
">>> df.take([0, 3])
     name   class  max_speed
0  falcon    bird      389.0
1  monkey  mammal        NaN
",https://pandas.pydata.org/docs/reference/api/pandas.Series.take.html, pandas.DataFrame.take
">>> df.take([1, 2], axis=1)
    class  max_speed
0    bird      389.0
2    bird       24.0
3  mammal       80.5
1  mammal        NaN
",https://pandas.pydata.org/docs/reference/api/pandas.Series.take.html, pandas.DataFrame.take
">>> df.take([-1, -2])
     name   class  max_speed
1  monkey  mammal        NaN
3    lion  mammal       80.5
",https://pandas.pydata.org/docs/reference/api/pandas.Series.take.html, pandas.DataFrame.take
">>> s = pd.Series(['lower', 'CAPITALS', 'this is a sentence', 'SwApCaSe'])
>>> s
0                 lower
1              CAPITALS
2    this is a sentence
3              SwApCaSe
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.casefold.html, pandas.Series
">>> s.str.lower()
0                 lower
1              capitals
2    this is a sentence
3              swapcase
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.casefold.html, pandas.Series.str.lower
">>> s.str.upper()
0                 LOWER
1              CAPITALS
2    THIS IS A SENTENCE
3              SWAPCASE
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.casefold.html, pandas.Series.str.upper
">>> s.str.title()
0                 Lower
1              Capitals
2    This Is A Sentence
3              Swapcase
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.casefold.html, pandas.Series.str.title
">>> s.str.capitalize()
0                 Lower
1              Capitals
2    This is a sentence
3              Swapcase
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.casefold.html, pandas.Series.str.capitalize
">>> s.str.swapcase()
0                 LOWER
1              capitals
2    THIS IS A SENTENCE
3              sWaPcAsE
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.casefold.html, pandas.Series.str.swapcase
">>> pd.Period('2020-01', 'D').end_time
Timestamp('2020-01-01 23:59:59.999999999')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.end_time.html, pandas.Period
">>> period_index = pd.period_range('2020-1-1 00:00', '2020-3-1 00:00', freq='M')
>>> s = pd.Series(period_index)
>>> s
0   2020-01
1   2020-02
2   2020-03
dtype: period[M]
>>> s.dt.end_time
0   2020-01-31 23:59:59.999999999
1   2020-02-29 23:59:59.999999999
2   2020-03-31 23:59:59.999999999
dtype: datetime64[ns]
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.end_time.html, pandas.period_range pandas.Series
">>> idx = pd.PeriodIndex([""2023-01"", ""2023-02"", ""2023-03""], freq=""M"")
>>> idx.end_time
DatetimeIndex(['2023-01-31 23:59:59.999999999',
               '2023-02-28 23:59:59.999999999',
               '2023-03-31 23:59:59.999999999'],
               dtype='datetime64[ns]', freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.end_time.html, pandas.PeriodIndex pandas.DatetimeIndex
">>> s = pd.Series([np.nan, 1, 3, 10, 5])
>>> s
0     NaN
1     1.0
2     3.0
3     10.0
4     5.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.sort_values.html, pandas.Series
">>> s.sort_values(ascending=True)
1     1.0
2     3.0
4     5.0
3    10.0
0     NaN
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.sort_values.html, pandas.Series.sort_values
">>> s.sort_values(ascending=False)
3    10.0
4     5.0
2     3.0
1     1.0
0     NaN
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.sort_values.html, pandas.Series.sort_values
">>> s.sort_values(na_position='first')
0     NaN
1     1.0
2     3.0
4     5.0
3    10.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.sort_values.html, pandas.Series.sort_values
">>> s = pd.Series(['z', 'b', 'd', 'a', 'c'])
>>> s
0    z
1    b
2    d
3    a
4    c
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.sort_values.html, pandas.Series
">>> s.sort_values()
3    a
1    b
4    c
2    d
0    z
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.sort_values.html, pandas.Series.sort_values
">>> s = pd.Series(['a', 'B', 'c', 'D', 'e'])
>>> s.sort_values()
1    B
3    D
0    a
2    c
4    e
dtype: object
>>> s.sort_values(key=lambda x: x.str.lower())
0    a
1    B
2    c
3    D
4    e
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.sort_values.html, pandas.Series pandas.Series.sort_values pandas.Series.str.lower
">>> s = pd.Series([-4, -2, 0, 2, 4])
>>> s.sort_values(key=np.sin)
1   -2
4    4
2    0
0   -4
3    2
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.sort_values.html, pandas.Series pandas.Series.sort_values
">>> s.sort_values(key=lambda x: (np.tan(x.cumsum())))
0   -4
3    2
4    4
1   -2
2    0
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.sort_values.html, pandas.Series.sort_values pandas.Series.cumsum
">>> s = pd.Series([0.1, 1.3, 2.7])
>>> s.round()
0    0.0
1    1.0
2    3.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.round.html, pandas.Series pandas.Series.round
">>> s = pd.Series(data=np.arange(3), index=['A', 'B', 'C'])
>>> s
A  0
B  1
C  2
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.drop.html, pandas.Series
">>> s.drop(labels=['B', 'C'])
A  0
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.drop.html, pandas.Series.drop
">>> midx = pd.MultiIndex(levels=[['llama', 'cow', 'falcon'],
...                              ['speed', 'weight', 'length']],
...                      codes=[[0, 0, 0, 1, 1, 1, 2, 2, 2],
...                             [0, 1, 2, 0, 1, 2, 0, 1, 2]])
>>> s = pd.Series([45, 200, 1.2, 30, 250, 1.5, 320, 1, 0.3],
...               index=midx)
>>> s
llama   speed      45.0
        weight    200.0
        length      1.2
cow     speed      30.0
        weight    250.0
        length      1.5
falcon  speed     320.0
        weight      1.0
        length      0.3
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.drop.html, pandas.MultiIndex pandas.Series
">>> s.drop(labels='weight', level=1)
llama   speed      45.0
        length      1.2
cow     speed      30.0
        length      1.5
falcon  speed     320.0
        length      0.3
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.drop.html, pandas.Series.drop
">>> s = pd.date_range('2016-12-31', '2017-01-08', freq='D').to_series()
>>> s.dt.dayofweek
2016-12-31    5
2017-01-01    6
2017-01-02    0
2017-01-03    1
2017-01-04    2
2017-01-05    3
2017-01-06    4
2017-01-07    5
2017-01-08    6
Freq: D, dtype: int32
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.day_of_week.html, pandas.date_range
">>> s = pd.Series([1, 2, 3])
>>> s
0    1
1    2
2    3
dtype: int64
>>> s.rename(""my_name"")  # scalar, changes Series.name
0    1
1    2
2    3
Name: my_name, dtype: int64
>>> s.rename(lambda x: x ** 2)  # function, changes labels
0    1
1    2
4    3
dtype: int64
>>> s.rename({1: 3, 2: 5})  # mapping, changes labels
0    1
3    2
5    3
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.rename.html, pandas.Series pandas.Series.rename
">>> import pyarrow as pa
>>> s = pd.Series(
...     [
...         {""version"": 1, ""project"": ""pandas""},
...         {""version"": 2, ""project"": ""pandas""},
...         {""version"": 1, ""project"": ""numpy""},
...     ],
...     dtype=pd.ArrowDtype(pa.struct(
...         [(""version"", pa.int64()), (""project"", pa.string())]
...     ))
... )
",https://pandas.pydata.org/docs/reference/api/pandas.Series.struct.field.html, pandas.Series pandas.ArrowDtype
">>> s.struct.field(""project"")
0    pandas
1    pandas
2     numpy
Name: project, dtype: string[pyarrow]
",https://pandas.pydata.org/docs/reference/api/pandas.Series.struct.field.html, pandas.Series.struct.field
">>> s.struct.field(0)
0    1
1    2
2    1
Name: version, dtype: int64[pyarrow]
",https://pandas.pydata.org/docs/reference/api/pandas.Series.struct.field.html, pandas.Series.struct.field
">>> import pyarrow.compute as pc
>>> s.struct.field(pc.field(""project""))
0    pandas
1    pandas
2     numpy
Name: project, dtype: string[pyarrow]
",https://pandas.pydata.org/docs/reference/api/pandas.Series.struct.field.html, pandas.Series.struct.field
">>> version_type = pa.struct([
...     (""major"", pa.int64()),
...     (""minor"", pa.int64()),
... ])
>>> s = pd.Series(
...     [
...         {""version"": {""major"": 1, ""minor"": 5}, ""project"": ""pandas""},
...         {""version"": {""major"": 2, ""minor"": 1}, ""project"": ""pandas""},
...         {""version"": {""major"": 1, ""minor"": 26}, ""project"": ""numpy""},
...     ],
...     dtype=pd.ArrowDtype(pa.struct(
...         [(""version"", version_type), (""project"", pa.string())]
...     ))
... )
>>> s.struct.field([""version"", ""minor""])
0     5
1     1
2    26
Name: minor, dtype: int64[pyarrow]
>>> s.struct.field([0, 0])
0    1
1    2
2    1
Name: major, dtype: int64[pyarrow]
",https://pandas.pydata.org/docs/reference/api/pandas.Series.struct.field.html, pandas.Series pandas.ArrowDtype pandas.Series.struct.field
">>> df = pd.DataFrame({'dates': pd.date_range(""2017-03-30"",
...                    periods=4)})
>>> df.assign(quarter=df.dates.dt.quarter,
...           is_quarter_end=df.dates.dt.is_quarter_end)
       dates  quarter    is_quarter_end
0 2017-03-30        1             False
1 2017-03-31        1              True
2 2017-04-01        2             False
3 2017-04-02        2             False
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.is_quarter_end.html, pandas.DataFrame pandas.date_range pandas.DataFrame.assign
">>> idx = pd.date_range('2017-03-30', periods=4)
>>> idx
DatetimeIndex(['2017-03-30', '2017-03-31', '2017-04-01', '2017-04-02'],
              dtype='datetime64[ns]', freq='D')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.is_quarter_end.html, pandas.date_range pandas.DatetimeIndex
">>> idx.is_quarter_end
array([False,  True, False, False])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.is_quarter_end.html, pandas.array
">>> datetime_series = pd.Series(
...     pd.date_range(""2000-01-01"", periods=3, freq=""ME"")
... )
>>> datetime_series
0   2000-01-31
1   2000-02-29
2   2000-03-31
dtype: datetime64[ns]
>>> datetime_series.dt.month
0    1
1    2
2    3
dtype: int32
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.month.html, pandas.Series pandas.date_range
">>> s = pd.Series([1])
>>> s.item()
1
",https://pandas.pydata.org/docs/reference/api/pandas.Series.item.html, pandas.Series pandas.Series.item
">>> s = pd.Series([1], index=['a'])
>>> s.index.item()
'a'
",https://pandas.pydata.org/docs/reference/api/pandas.Series.item.html, pandas.Series
">>> s1 = pd.Series(['one', 'one1', '1', ''])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.istitle.html, pandas.Series
">>> s1.str.isalpha()
0     True
1    False
2    False
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.istitle.html, pandas.Series.str.isalpha
">>> s1.str.isnumeric()
0    False
1    False
2     True
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.istitle.html, pandas.Series.str.isnumeric
">>> s1.str.isalnum()
0     True
1     True
2     True
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.istitle.html, pandas.Series.str.isalnum
">>> s2 = pd.Series(['A B', '1.5', '3,000'])
>>> s2.str.isalnum()
0    False
1    False
2    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.istitle.html, pandas.Series pandas.Series.str.isalnum
">>> s3 = pd.Series(['23', '³', '⅕', ''])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.istitle.html, pandas.Series
">>> s3.str.isdecimal()
0     True
1    False
2    False
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.istitle.html, pandas.Series.str.isdecimal
">>> s3.str.isdigit()
0     True
1     True
2    False
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.istitle.html, pandas.Series.str.isdigit
">>> s3.str.isnumeric()
0     True
1     True
2     True
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.istitle.html, pandas.Series.str.isnumeric
">>> s4 = pd.Series([' ', '\t\r\n ', ''])
>>> s4.str.isspace()
0     True
1     True
2    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.istitle.html, pandas.Series pandas.Series.str.isspace
">>> s5 = pd.Series(['leopard', 'Golden Eagle', 'SNAKE', ''])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.istitle.html, pandas.Series
">>> s5.str.islower()
0     True
1    False
2    False
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.istitle.html, pandas.Series.str.islower
">>> s5.str.isupper()
0    False
1    False
2     True
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.istitle.html, pandas.Series.str.isupper
">>> s5.str.istitle()
0    False
1     True
2    False
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.istitle.html, pandas.Series.str.istitle
">>> s = pd.Series(
...     [
...         ""this is a regular sentence"",
...         ""https://docs.python.org/3/tutorial/index.html"",
...         np.nan
...     ]
... )
>>> s
0                       this is a regular sentence
1    https://docs.python.org/3/tutorial/index.html
2                                              NaN
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.rsplit.html, pandas.Series
">>> s.str.split()
0                   [this, is, a, regular, sentence]
1    [https://docs.python.org/3/tutorial/index.html]
2                                                NaN
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.rsplit.html, pandas.Series.str.split
">>> s.str.rsplit()
0                   [this, is, a, regular, sentence]
1    [https://docs.python.org/3/tutorial/index.html]
2                                                NaN
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.rsplit.html, pandas.Series.str.rsplit
">>> s.str.split(n=2)
0                     [this, is, a regular sentence]
1    [https://docs.python.org/3/tutorial/index.html]
2                                                NaN
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.rsplit.html, pandas.Series.str.split
">>> s.str.rsplit(n=2)
0                     [this is a, regular, sentence]
1    [https://docs.python.org/3/tutorial/index.html]
2                                                NaN
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.rsplit.html, pandas.Series.str.rsplit
">>> s.str.split(pat=""/"")
0                         [this is a regular sentence]
1    [https:, , docs.python.org, 3, tutorial, index...
2                                                  NaN
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.rsplit.html, pandas.Series.str.split
">>> s.str.split(expand=True)
                                               0     1     2        3         4
0                                           this    is     a  regular  sentence
1  https://docs.python.org/3/tutorial/index.html  None  None     None      None
2                                            NaN   NaN   NaN      NaN       NaN
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.rsplit.html, pandas.Series.str.split
">>> s.str.rsplit(""/"", n=1, expand=True)
                                    0           1
0          this is a regular sentence        None
1  https://docs.python.org/3/tutorial  index.html
2                                 NaN         NaN
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.rsplit.html, pandas.Series.str.rsplit
">>> s = pd.Series([1, 2, 3])
>>> s.to_list()
[1, 2, 3]
",https://pandas.pydata.org/docs/reference/api/pandas.Series.to_list.html, pandas.Series pandas.Series.to_list
">>> idx = pd.Index([1, 2, 3])
>>> idx
Index([1, 2, 3], dtype='int64')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.to_list.html, pandas.Index pandas.Index
">>> idx.to_list()
[1, 2, 3]
",https://pandas.pydata.org/docs/reference/api/pandas.Series.to_list.html, pandas.Index.to_list
">>> s1 = pd.Series(['one', 'one1', '1', ''])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isdecimal.html, pandas.Series
">>> s1.str.isalpha()
0     True
1    False
2    False
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isdecimal.html, pandas.Series.str.isalpha
">>> s1.str.isnumeric()
0    False
1    False
2     True
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isdecimal.html, pandas.Series.str.isnumeric
">>> s1.str.isalnum()
0     True
1     True
2     True
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isdecimal.html, pandas.Series.str.isalnum
">>> s2 = pd.Series(['A B', '1.5', '3,000'])
>>> s2.str.isalnum()
0    False
1    False
2    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isdecimal.html, pandas.Series pandas.Series.str.isalnum
">>> s3 = pd.Series(['23', '³', '⅕', ''])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isdecimal.html, pandas.Series
">>> s3.str.isdecimal()
0     True
1    False
2    False
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isdecimal.html, pandas.Series.str.isdecimal
">>> s3.str.isdigit()
0     True
1     True
2    False
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isdecimal.html, pandas.Series.str.isdigit
">>> s3.str.isnumeric()
0     True
1     True
2     True
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isdecimal.html, pandas.Series.str.isnumeric
">>> s4 = pd.Series([' ', '\t\r\n ', ''])
>>> s4.str.isspace()
0     True
1     True
2    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isdecimal.html, pandas.Series pandas.Series.str.isspace
">>> s5 = pd.Series(['leopard', 'Golden Eagle', 'SNAKE', ''])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isdecimal.html, pandas.Series
">>> s5.str.islower()
0     True
1    False
2    False
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isdecimal.html, pandas.Series.str.islower
">>> s5.str.isupper()
0    False
1    False
2     True
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isdecimal.html, pandas.Series.str.isupper
">>> s5.str.istitle()
0    False
1     True
2    False
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isdecimal.html, pandas.Series.str.istitle
">>> s = pd.Series(['a', 'b', 'c'])
>>> s
0    a
1    b
2    c
dtype: object
>>> s.repeat(2)
0    a
0    a
1    b
1    b
2    c
2    c
dtype: object
>>> s.repeat([1, 2, 3])
0    a
1    b
1    b
2    c
2    c
2    c
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.repeat.html, pandas.Series pandas.Series.repeat
">>> s = pd.Series(
...     [""A"", ""B"", ""A"", ""C""],
...     index=[
...         [""Final exam"", ""Final exam"", ""Coursework"", ""Coursework""],
...         [""History"", ""Geography"", ""History"", ""Geography""],
...         [""January"", ""February"", ""March"", ""April""],
...     ],
... )
>>> s
Final exam  History     January      A
            Geography   February     B
Coursework  History     March        A
            Geography   April        C
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.swaplevel.html, pandas.Series
">>> s.swaplevel()
Final exam  January     History         A
            February    Geography       B
Coursework  March       History         A
            April       Geography       C
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.swaplevel.html, pandas.Series.swaplevel
">>> s.swaplevel(0)
January     History     Final exam      A
February    Geography   Final exam      B
March       History     Coursework      A
April       Geography   Coursework      C
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.swaplevel.html, pandas.Series.swaplevel
">>> s.swaplevel(0, 1)
History     Final exam  January         A
Geography   Final exam  February        B
History     Coursework  March           A
Geography   Coursework  April           C
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.swaplevel.html, pandas.Series.swaplevel
">>> df = pd.DataFrame({'num_legs': [2, 4, 8, 0],
...                    'num_wings': [2, 0, 0, 0],
...                    'num_specimen_seen': [10, 2, 1, 8]},
...                   index=['falcon', 'dog', 'spider', 'fish'])
>>> df
        num_legs  num_wings  num_specimen_seen
falcon         2          2                 10
dog            4          0                  2
spider         8          0                  1
fish           0          0                  8
",https://pandas.pydata.org/docs/reference/api/pandas.Series.sample.html, pandas.DataFrame
">>> df.sample(frac=0.5, replace=True, random_state=1)
      num_legs  num_wings  num_specimen_seen
dog          4          0                  2
fish         0          0                  8
",https://pandas.pydata.org/docs/reference/api/pandas.Series.sample.html, pandas.DataFrame.sample
">>> df.sample(frac=2, replace=True, random_state=1)
        num_legs  num_wings  num_specimen_seen
dog            4          0                  2
fish           0          0                  8
falcon         2          2                 10
falcon         2          2                 10
fish           0          0                  8
dog            4          0                  2
fish           0          0                  8
dog            4          0                  2
",https://pandas.pydata.org/docs/reference/api/pandas.Series.sample.html, pandas.DataFrame.sample
">>> df.sample(n=2, weights='num_specimen_seen', random_state=1)
        num_legs  num_wings  num_specimen_seen
falcon         2          2                 10
fish           0          0                  8
",https://pandas.pydata.org/docs/reference/api/pandas.Series.sample.html, pandas.DataFrame.sample
">>> s = pd.Series([1, 2, 3])
>>> s.ravel()  
array([1, 2, 3])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.ravel.html, pandas.Series pandas.Series.ravel pandas.array
">>> s = pd.Series([1, 2, 3])
>>> s.mean()
2.0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.mean.html, pandas.Series pandas.Series.mean
">>> df = pd.DataFrame({'a': [1, 2], 'b': [2, 3]}, index=['tiger', 'zebra'])
>>> df
       a   b
tiger  1   2
zebra  2   3
>>> df.mean()
a   1.5
b   2.5
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.mean.html, pandas.DataFrame pandas.DataFrame.mean
">>> df.mean(axis=1)
tiger   1.5
zebra   2.5
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.mean.html, pandas.DataFrame.mean
">>> df = pd.DataFrame({'a': [1, 2], 'b': ['T', 'Z']},
...                   index=['tiger', 'zebra'])
>>> df.mean(numeric_only=True)
a   1.5
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.mean.html, pandas.DataFrame pandas.DataFrame.mean
">>> s = pd.Series([0.0, 1.0, np.nan])
>>> s.count()
2
",https://pandas.pydata.org/docs/reference/api/pandas.Series.count.html, pandas.Series pandas.Series.count
">>> s = pd.Series([1, 2, 3])
>>> s.dtypes
dtype('int64')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dtypes.html, pandas.Series
">>> df = pd.DataFrame({1: [10], 2: [20]})
>>> df
    1   2
0  10  20
",https://pandas.pydata.org/docs/reference/api/pandas.Series.equals.html, pandas.DataFrame
">>> exactly_equal = pd.DataFrame({1: [10], 2: [20]})
>>> exactly_equal
    1   2
0  10  20
>>> df.equals(exactly_equal)
True
",https://pandas.pydata.org/docs/reference/api/pandas.Series.equals.html, pandas.DataFrame pandas.DataFrame.equals
">>> different_column_type = pd.DataFrame({1.0: [10], 2.0: [20]})
>>> different_column_type
   1.0  2.0
0   10   20
>>> df.equals(different_column_type)
True
",https://pandas.pydata.org/docs/reference/api/pandas.Series.equals.html, pandas.DataFrame pandas.DataFrame.equals
">>> different_data_type = pd.DataFrame({1: [10.0], 2: [20.0]})
>>> different_data_type
      1     2
0  10.0  20.0
>>> df.equals(different_data_type)
False
",https://pandas.pydata.org/docs/reference/api/pandas.Series.equals.html, pandas.DataFrame pandas.DataFrame.equals
">>> ser = pd.Series(pd.Categorical(['a', 'b', 'a']))
>>> ser.to_numpy()
array(['a', 'b', 'a'], dtype=object)
",https://pandas.pydata.org/docs/reference/api/pandas.Series.to_numpy.html, pandas.Series pandas.Categorical pandas.Series.to_numpy pandas.array
">>> ser = pd.Series(pd.date_range('2000', periods=2, tz=""CET""))
>>> ser.to_numpy(dtype=object)
array([Timestamp('2000-01-01 00:00:00+0100', tz='CET'),
       Timestamp('2000-01-02 00:00:00+0100', tz='CET')],
      dtype=object)
",https://pandas.pydata.org/docs/reference/api/pandas.Series.to_numpy.html, pandas.Series pandas.date_range pandas.Series.to_numpy pandas.array
">>> ser.to_numpy(dtype=""datetime64[ns]"")
... 
array(['1999-12-31T23:00:00.000000000', '2000-01-01T23:00:00...'],
      dtype='datetime64[ns]')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.to_numpy.html, pandas.Series.to_numpy pandas.array
">>> s = pd.Series(data=[1, None, 4, 1],
...               index=['A', 'B', 'C', 'D'])
>>> s
A    1.0
B    NaN
C    4.0
D    1.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.idxmin.html, pandas.Series
">>> s.idxmin()
'A'
",https://pandas.pydata.org/docs/reference/api/pandas.Series.idxmin.html, pandas.Series.idxmin
">>> s.idxmin(skipna=False)
nan
",https://pandas.pydata.org/docs/reference/api/pandas.Series.idxmin.html, pandas.Series.idxmin
">>> df = pd.DataFrame({""Col1"": [10, 20, 15, 30, 45],
...                    ""Col2"": [13, 23, 18, 33, 48],
...                    ""Col3"": [17, 27, 22, 37, 52]},
...                   index=pd.date_range(""2020-01-01"", ""2020-01-05""))
>>> df
            Col1  Col2  Col3
2020-01-01    10    13    17
2020-01-02    20    23    27
2020-01-03    15    18    22
2020-01-04    30    33    37
2020-01-05    45    48    52
",https://pandas.pydata.org/docs/reference/api/pandas.Series.shift.html, pandas.DataFrame pandas.date_range
">>> df.shift(periods=3)
            Col1  Col2  Col3
2020-01-01   NaN   NaN   NaN
2020-01-02   NaN   NaN   NaN
2020-01-03   NaN   NaN   NaN
2020-01-04  10.0  13.0  17.0
2020-01-05  20.0  23.0  27.0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.shift.html, pandas.DataFrame.shift
">>> df.shift(periods=1, axis=""columns"")
            Col1  Col2  Col3
2020-01-01   NaN    10    13
2020-01-02   NaN    20    23
2020-01-03   NaN    15    18
2020-01-04   NaN    30    33
2020-01-05   NaN    45    48
",https://pandas.pydata.org/docs/reference/api/pandas.Series.shift.html, pandas.DataFrame.shift
">>> df.shift(periods=3, fill_value=0)
            Col1  Col2  Col3
2020-01-01     0     0     0
2020-01-02     0     0     0
2020-01-03     0     0     0
2020-01-04    10    13    17
2020-01-05    20    23    27
",https://pandas.pydata.org/docs/reference/api/pandas.Series.shift.html, pandas.DataFrame.shift
">>> df.shift(periods=3, freq=""D"")
            Col1  Col2  Col3
2020-01-04    10    13    17
2020-01-05    20    23    27
2020-01-06    15    18    22
2020-01-07    30    33    37
2020-01-08    45    48    52
",https://pandas.pydata.org/docs/reference/api/pandas.Series.shift.html, pandas.DataFrame.shift
">>> df.shift(periods=3, freq=""infer"")
            Col1  Col2  Col3
2020-01-04    10    13    17
2020-01-05    20    23    27
2020-01-06    15    18    22
2020-01-07    30    33    37
2020-01-08    45    48    52
",https://pandas.pydata.org/docs/reference/api/pandas.Series.shift.html, pandas.DataFrame.shift
">>> import pyarrow as pa
>>> s = pd.Series(
...     [
...         {""version"": 1, ""project"": ""pandas""},
...         {""version"": 2, ""project"": ""pandas""},
...         {""version"": 1, ""project"": ""numpy""},
...     ],
...     dtype=pd.ArrowDtype(pa.struct(
...         [(""version"", pa.int64()), (""project"", pa.string())]
...     ))
... )
",https://pandas.pydata.org/docs/reference/api/pandas.Series.struct.explode.html, pandas.Series pandas.ArrowDtype
">>> s.struct.explode()
   version project
0        1  pandas
1        2  pandas
2        1   numpy
",https://pandas.pydata.org/docs/reference/api/pandas.Series.struct.explode.html, pandas.Series.struct.explode
">>> s = pd.Series(['a1', 'b2', 'c3'])
>>> s.str.extract(r'([ab])(\d)')
    0    1
0    a    1
1    b    2
2  NaN  NaN
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.extract.html, pandas.Series pandas.Series.str.extract
">>> s.str.extract(r'([ab])?(\d)')
    0  1
0    a  1
1    b  2
2  NaN  3
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.extract.html, pandas.Series.str.extract
">>> s.str.extract(r'(?P[ab])(?P\d)')
letter digit
0      a     1
1      b     2
2    NaN   NaN
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.extract.html, pandas.Series.str.extract
">>> s.str.extract(r'[ab](\d)', expand=True)
    0
0    1
1    2
2  NaN
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.extract.html, pandas.Series.str.extract
">>> s.str.extract(r'[ab](\d)', expand=False)
0      1
1      2
2    NaN
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.extract.html, pandas.Series.str.extract
">>> c = pd.Categorical(['a', 'c', 'b', 'c', 'd'])
>>> c
['a', 'c', 'b', 'c', 'd']
Categories (4, object): ['a', 'b', 'c', 'd']
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.remove_unused_categories.html, pandas.Categorical
">>> s = pd.Series([None, 3, 4])
>>> s.first_valid_index()
1
>>> s.last_valid_index()
2
",https://pandas.pydata.org/docs/reference/api/pandas.Series.last_valid_index.html, pandas.Series pandas.Series.first_valid_index pandas.Series.last_valid_index
">>> s = pd.Series([None, None])
>>> print(s.first_valid_index())
None
>>> print(s.last_valid_index())
None
",https://pandas.pydata.org/docs/reference/api/pandas.Series.last_valid_index.html, pandas.Series pandas.Series.first_valid_index pandas.Series.last_valid_index
">>> s = pd.Series()
>>> print(s.first_valid_index())
None
>>> print(s.last_valid_index())
None
",https://pandas.pydata.org/docs/reference/api/pandas.Series.last_valid_index.html, pandas.Series pandas.Series.first_valid_index pandas.Series.last_valid_index
">>> df = pd.DataFrame({'A': [None, None, 2], 'B': [None, 3, 4]})
>>> df
     A      B
0  NaN    NaN
1  NaN    3.0
2  2.0    4.0
>>> df.first_valid_index()
1
>>> df.last_valid_index()
2
",https://pandas.pydata.org/docs/reference/api/pandas.Series.last_valid_index.html, pandas.DataFrame pandas.DataFrame.first_valid_index pandas.DataFrame.last_valid_index
">>> df = pd.DataFrame({'A': [None, None, None], 'B': [None, None, None]})
>>> df
     A      B
0  None   None
1  None   None
2  None   None
>>> print(df.first_valid_index())
None
>>> print(df.last_valid_index())
None
",https://pandas.pydata.org/docs/reference/api/pandas.Series.last_valid_index.html, pandas.DataFrame pandas.DataFrame.first_valid_index pandas.DataFrame.last_valid_index
">>> df = pd.DataFrame()
>>> df
Empty DataFrame
Columns: []
Index: []
>>> print(df.first_valid_index())
None
>>> print(df.last_valid_index())
None
",https://pandas.pydata.org/docs/reference/api/pandas.Series.last_valid_index.html, pandas.DataFrame pandas.DataFrame.first_valid_index pandas.DataFrame.last_valid_index
">>> s = pd.Series([1, 2, np.nan, 4], index=[10, 20, 30, 40])
>>> s
10    1.0
20    2.0
30    NaN
40    4.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.asof.html, pandas.Series
">>> s.asof(20)
2.0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.asof.html, pandas.Series.asof
">>> s.asof([5, 20])
5     NaN
20    2.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.asof.html, pandas.Series.asof
">>> s.asof(30)
2.0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.asof.html, pandas.Series.asof
">>> df = pd.DataFrame({'a': [10., 20., 30., 40., 50.],
...                    'b': [None, None, None, None, 500]},
...                   index=pd.DatetimeIndex(['2018-02-27 09:01:00',
...                                           '2018-02-27 09:02:00',
...                                           '2018-02-27 09:03:00',
...                                           '2018-02-27 09:04:00',
...                                           '2018-02-27 09:05:00']))
>>> df.asof(pd.DatetimeIndex(['2018-02-27 09:03:30',
...                           '2018-02-27 09:04:30']))
                      a   b
2018-02-27 09:03:30 NaN NaN
2018-02-27 09:04:30 NaN NaN
",https://pandas.pydata.org/docs/reference/api/pandas.Series.asof.html, pandas.DataFrame pandas.DatetimeIndex pandas.DataFrame.asof
">>> df.asof(pd.DatetimeIndex(['2018-02-27 09:03:30',
...                           '2018-02-27 09:04:30']),
...         subset=['a'])
                        a   b
2018-02-27 09:03:30  30.0 NaN
2018-02-27 09:04:30  40.0 NaN
",https://pandas.pydata.org/docs/reference/api/pandas.Series.asof.html, pandas.DataFrame.asof pandas.DatetimeIndex
">>> s1 = pd.Series({'falcon': 330.0, 'eagle': 160.0})
>>> s1
falcon    330.0
eagle     160.0
dtype: float64
>>> s2 = pd.Series({'falcon': 345.0, 'eagle': 200.0, 'duck': 30.0})
>>> s2
falcon    345.0
eagle     200.0
duck       30.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.combine.html, pandas.Series
">>> s1.combine(s2, max)
duck        NaN
eagle     200.0
falcon    345.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.combine.html, pandas.Series.combine
">>> s1.combine(s2, max, fill_value=0)
duck       30.0
eagle     200.0
falcon    345.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.combine.html, pandas.Series.combine
">>> ser = pd.Series(['ñ'])
>>> ser.str.normalize('NFC') == ser.str.normalize('NFD')
0   False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.normalize.html, pandas.Series pandas.Series.str.normalize
">>> df = pd.DataFrame([[np.nan, 2, np.nan, 0],
...                    [3, 4, np.nan, 1],
...                    [np.nan, np.nan, np.nan, np.nan],
...                    [np.nan, 3, np.nan, 4]],
...                   columns=list(""ABCD""))
>>> df
     A    B   C    D
0  NaN  2.0 NaN  0.0
1  3.0  4.0 NaN  1.0
2  NaN  NaN NaN  NaN
3  NaN  3.0 NaN  4.0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.ffill.html, pandas.DataFrame
">>> df.ffill()
     A    B   C    D
0  NaN  2.0 NaN  0.0
1  3.0  4.0 NaN  1.0
2  3.0  4.0 NaN  1.0
3  3.0  3.0 NaN  4.0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.ffill.html, pandas.DataFrame.ffill
">>> ser = pd.Series([1, np.nan, 2, 3])
>>> ser.ffill()
0   1.0
1   1.0
2   2.0
3   3.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.ffill.html, pandas.Series pandas.Series.ffill
">>> df = pd.DataFrame([[0, 2, 3], [0, 4, 1], [10, 20, 30]],
...                   index=[4, 5, 6], columns=['A', 'B', 'C'])
>>> df
    A   B   C
4   0   2   3
5   0   4   1
6  10  20  30
",https://pandas.pydata.org/docs/reference/api/pandas.Series.at.html, pandas.DataFrame
">>> s1 = pd.Series(['one', 'one1', '1', ''])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isspace.html, pandas.Series
">>> s1.str.isalpha()
0     True
1    False
2    False
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isspace.html, pandas.Series.str.isalpha
">>> s1.str.isnumeric()
0    False
1    False
2     True
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isspace.html, pandas.Series.str.isnumeric
">>> s1.str.isalnum()
0     True
1     True
2     True
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isspace.html, pandas.Series.str.isalnum
">>> s2 = pd.Series(['A B', '1.5', '3,000'])
>>> s2.str.isalnum()
0    False
1    False
2    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isspace.html, pandas.Series pandas.Series.str.isalnum
">>> s3 = pd.Series(['23', '³', '⅕', ''])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isspace.html, pandas.Series
">>> s3.str.isdecimal()
0     True
1    False
2    False
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isspace.html, pandas.Series.str.isdecimal
">>> s3.str.isdigit()
0     True
1     True
2    False
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isspace.html, pandas.Series.str.isdigit
">>> s3.str.isnumeric()
0     True
1     True
2     True
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isspace.html, pandas.Series.str.isnumeric
">>> s4 = pd.Series([' ', '\t\r\n ', ''])
>>> s4.str.isspace()
0     True
1     True
2    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isspace.html, pandas.Series pandas.Series.str.isspace
">>> s5 = pd.Series(['leopard', 'Golden Eagle', 'SNAKE', ''])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isspace.html, pandas.Series
">>> s5.str.islower()
0     True
1    False
2    False
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isspace.html, pandas.Series.str.islower
">>> s5.str.isupper()
0    False
1    False
2     True
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isspace.html, pandas.Series.str.isupper
">>> s5.str.istitle()
0    False
1     True
2    False
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isspace.html, pandas.Series.str.istitle
">>> df = pd.DataFrame({""A"": [1, 2]})
>>> df.flags

",https://pandas.pydata.org/docs/reference/api/pandas.Series.flags.html, pandas.DataFrame
">>> s = pd.Series([1, 2, 3, 4])
>>> s
0    1
1    2
2    3
3    4
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.add_suffix.html, pandas.Series
">>> s.add_suffix('_item')
0_item    1
1_item    2
2_item    3
3_item    4
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.add_suffix.html, pandas.Series.add_suffix
">>> df = pd.DataFrame({'A': [1, 2, 3, 4], 'B': [3, 4, 5, 6]})
>>> df
   A  B
0  1  3
1  2  4
2  3  5
3  4  6
",https://pandas.pydata.org/docs/reference/api/pandas.Series.add_suffix.html, pandas.DataFrame
">>> df.add_suffix('_col')
     A_col  B_col
0       1       3
1       2       4
2       3       5
3       4       6
",https://pandas.pydata.org/docs/reference/api/pandas.Series.add_suffix.html, pandas.DataFrame.add_suffix
">>> ser = pd.Series(pd.to_timedelta([1, 2, 3], unit='us'))
>>> ser
0   0 days 00:00:00.000001
1   0 days 00:00:00.000002
2   0 days 00:00:00.000003
dtype: timedelta64[ns]
>>> ser.dt.microseconds
0    1
1    2
2    3
dtype: int32
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.microseconds.html, pandas.Series pandas.to_timedelta
">>> tdelta_idx = pd.to_timedelta([1, 2, 3], unit='us')
>>> tdelta_idx
TimedeltaIndex(['0 days 00:00:00.000001', '0 days 00:00:00.000002',
                '0 days 00:00:00.000003'],
               dtype='timedelta64[ns]', freq=None)
>>> tdelta_idx.microseconds
Index([1, 2, 3], dtype='int32')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.microseconds.html, pandas.to_timedelta pandas.TimedeltaIndex pandas.Index
">>> s = pd.Series({'Corn Flakes': 100.0, 'Almond Delight': 110.0,
...                'Cinnamon Toast Crunch': 120.0, 'Cocoa Puff': 110.0})
>>> s
Corn Flakes              100.0
Almond Delight           110.0
Cinnamon Toast Crunch    120.0
Cocoa Puff               110.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.argmax.html, pandas.Series
">>> s.argmax()
2
>>> s.argmin()
0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.argmax.html, pandas.Series.argmax pandas.Series.argmin
">>> animals = pd.Series(['llama', 'cow', 'llama', 'beetle', 'llama'])
>>> animals.duplicated()
0    False
1    False
2     True
3    False
4     True
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.duplicated.html, pandas.Series pandas.Series.duplicated
">>> animals.duplicated(keep='first')
0    False
1    False
2     True
3    False
4     True
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.duplicated.html, pandas.Series.duplicated
">>> animals.duplicated(keep='last')
0     True
1    False
2     True
3    False
4    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.duplicated.html, pandas.Series.duplicated
">>> animals.duplicated(keep=False)
0     True
1    False
2     True
3    False
4     True
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.duplicated.html, pandas.Series.duplicated
">>> rng = pd.date_range('1/1/2018 11:59:00', periods=3, freq='min')
>>> rng
DatetimeIndex(['2018-01-01 11:59:00', '2018-01-01 12:00:00',
               '2018-01-01 12:01:00'],
              dtype='datetime64[ns]', freq='min')
>>> rng.ceil('h')
DatetimeIndex(['2018-01-01 12:00:00', '2018-01-01 12:00:00',
               '2018-01-01 13:00:00'],
              dtype='datetime64[ns]', freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.ceil.html, pandas.date_range pandas.DatetimeIndex
">>> pd.Series(rng).dt.ceil(""h"")
0   2018-01-01 12:00:00
1   2018-01-01 12:00:00
2   2018-01-01 13:00:00
dtype: datetime64[ns]
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.ceil.html, pandas.Series
">>> rng_tz = pd.DatetimeIndex([""2021-10-31 01:30:00""], tz=""Europe/Amsterdam"")
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.ceil.html, pandas.DatetimeIndex
">>> rng_tz.ceil(""h"", ambiguous=False)
DatetimeIndex(['2021-10-31 02:00:00+01:00'],
              dtype='datetime64[ns, Europe/Amsterdam]', freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.ceil.html, pandas.DatetimeIndex.ceil pandas.DatetimeIndex
">>> rng_tz.ceil(""h"", ambiguous=True)
DatetimeIndex(['2021-10-31 02:00:00+02:00'],
              dtype='datetime64[ns, Europe/Amsterdam]', freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.ceil.html, pandas.DatetimeIndex.ceil pandas.DatetimeIndex
">>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])
>>> a
a    1.0
b    1.0
c    1.0
d    NaN
dtype: float64
>>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])
>>> b
a    1.0
b    NaN
d    1.0
e    NaN
dtype: float64
>>> a.multiply(b, fill_value=0)
a    1.0
b    0.0
c    0.0
d    0.0
e    NaN
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.mul.html, pandas.Series
">>> s = pd.Series([1, 2, 2])
>>> s.is_monotonic_increasing
True
",https://pandas.pydata.org/docs/reference/api/pandas.Series.is_monotonic_increasing.html, pandas.Series
">>> s = pd.Series([3, 2, 1])
>>> s.is_monotonic_increasing
False
",https://pandas.pydata.org/docs/reference/api/pandas.Series.is_monotonic_increasing.html, pandas.Series
">>> ser = pd.Series([""horse"", ""eagle"", ""donkey""])
>>> ser.str.index(""e"")
0   4
1   0
2   4
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.index.html, pandas.Series pandas.Series.str.index
">>> ser = pd.Series([""Deer"", ""eagle"", ""Sheep""])
>>> ser.str.rindex(""e"")
0   2
1   4
2   3
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.index.html, pandas.Series pandas.Series.str.rindex
">>> s = pd.Series(['lower', 'CAPITALS', 'this is a sentence', 'SwApCaSe'])
>>> s
0                 lower
1              CAPITALS
2    this is a sentence
3              SwApCaSe
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.title.html, pandas.Series
">>> s.str.lower()
0                 lower
1              capitals
2    this is a sentence
3              swapcase
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.title.html, pandas.Series.str.lower
">>> s.str.upper()
0                 LOWER
1              CAPITALS
2    THIS IS A SENTENCE
3              SWAPCASE
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.title.html, pandas.Series.str.upper
">>> s.str.title()
0                 Lower
1              Capitals
2    This Is A Sentence
3              Swapcase
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.title.html, pandas.Series.str.title
">>> s.str.capitalize()
0                 Lower
1              Capitals
2    This is a sentence
3              Swapcase
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.title.html, pandas.Series.str.capitalize
">>> s.str.swapcase()
0                 LOWER
1              capitals
2    THIS IS A SENTENCE
3              sWaPcAsE
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.title.html, pandas.Series.str.swapcase
">>> df = pd.DataFrame([[0, 2, 3], [0, 4, 1], [10, 20, 30]],
...                   columns=['A', 'B', 'C'])
>>> df
    A   B   C
0   0   2   3
1   0   4   1
2  10  20  30
",https://pandas.pydata.org/docs/reference/api/pandas.Series.iat.html, pandas.DataFrame
">>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])
>>> a
a    1.0
b    1.0
c    1.0
d    NaN
dtype: float64
>>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])
>>> b
a    1.0
b    NaN
d    1.0
e    NaN
dtype: float64
>>> a.multiply(b, fill_value=0)
a    1.0
b    0.0
c    0.0
d    0.0
e    NaN
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.rmul.html, pandas.Series
">>> s = pd.Series(
...     [
...         ""this is a regular sentence"",
...         ""https://docs.python.org/3/tutorial/index.html"",
...         np.nan
...     ]
... )
>>> s
0                       this is a regular sentence
1    https://docs.python.org/3/tutorial/index.html
2                                              NaN
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.split.html, pandas.Series
">>> s.str.split()
0                   [this, is, a, regular, sentence]
1    [https://docs.python.org/3/tutorial/index.html]
2                                                NaN
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.split.html, pandas.Series.str.split
">>> s.str.rsplit()
0                   [this, is, a, regular, sentence]
1    [https://docs.python.org/3/tutorial/index.html]
2                                                NaN
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.split.html, pandas.Series.str.rsplit
">>> s.str.split(n=2)
0                     [this, is, a regular sentence]
1    [https://docs.python.org/3/tutorial/index.html]
2                                                NaN
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.split.html, pandas.Series.str.split
">>> s.str.rsplit(n=2)
0                     [this is a, regular, sentence]
1    [https://docs.python.org/3/tutorial/index.html]
2                                                NaN
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.split.html, pandas.Series.str.rsplit
">>> s.str.split(pat=""/"")
0                         [this is a regular sentence]
1    [https:, , docs.python.org, 3, tutorial, index...
2                                                  NaN
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.split.html, pandas.Series.str.split
">>> s.str.split(expand=True)
                                               0     1     2        3         4
0                                           this    is     a  regular  sentence
1  https://docs.python.org/3/tutorial/index.html  None  None     None      None
2                                            NaN   NaN   NaN      NaN       NaN
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.split.html, pandas.Series.str.split
">>> s.str.rsplit(""/"", n=1, expand=True)
                                    0           1
0          this is a regular sentence        None
1  https://docs.python.org/3/tutorial  index.html
2                                 NaN         NaN
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.split.html, pandas.Series.str.rsplit
">>> s = pd.Series([""foo and bar plus baz""])
>>> s.str.split(r""and|plus"", expand=True)
    0   1   2
0 foo bar baz
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.split.html, pandas.Series pandas.Series.str.split
">>> s = pd.Series(['foojpgbar.jpg'])
>>> s.str.split(r""."", expand=True)
           0    1
0  foojpgbar  jpg
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.split.html, pandas.Series pandas.Series.str.split
">>> s.str.split(r""\.jpg"", expand=True)
           0 1
0  foojpgbar
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.split.html, pandas.Series.str.split
">>> s.str.split(r""\.jpg"", regex=True, expand=True)
           0 1
0  foojpgbar
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.split.html, pandas.Series.str.split
">>> import re
>>> s.str.split(re.compile(r""\.jpg""), expand=True)
           0 1
0  foojpgbar
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.split.html, pandas.Series.str.split
">>> s.str.split(r""\.jpg"", regex=False, expand=True)
               0
0  foojpgbar.jpg
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.split.html, pandas.Series.str.split
">>> idx = pd.date_range(start='2014-08-01 10:00', freq='h',
...                     periods=3, tz='Asia/Calcutta')
>>> idx
DatetimeIndex(['2014-08-01 10:00:00+05:30',
               '2014-08-01 11:00:00+05:30',
               '2014-08-01 12:00:00+05:30'],
                dtype='datetime64[ns, Asia/Calcutta]', freq='h')
>>> idx.normalize()
DatetimeIndex(['2014-08-01 00:00:00+05:30',
               '2014-08-01 00:00:00+05:30',
               '2014-08-01 00:00:00+05:30'],
               dtype='datetime64[ns, Asia/Calcutta]', freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.normalize.html, pandas.date_range pandas.DatetimeIndex
">>> index = pd.date_range('1/1/2000', periods=9, freq='min')
>>> series = pd.Series(range(9), index=index)
>>> series
2000-01-01 00:00:00    0
2000-01-01 00:01:00    1
2000-01-01 00:02:00    2
2000-01-01 00:03:00    3
2000-01-01 00:04:00    4
2000-01-01 00:05:00    5
2000-01-01 00:06:00    6
2000-01-01 00:07:00    7
2000-01-01 00:08:00    8
Freq: min, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.resample.html, pandas.date_range pandas.Series
">>> series.resample('3min').sum()
2000-01-01 00:00:00     3
2000-01-01 00:03:00    12
2000-01-01 00:06:00    21
Freq: 3min, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.resample.html, pandas.Series.resample
">>> series.resample('3min', label='right').sum()
2000-01-01 00:03:00     3
2000-01-01 00:06:00    12
2000-01-01 00:09:00    21
Freq: 3min, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.resample.html, pandas.Series.resample
">>> series.resample('3min', label='right', closed='right').sum()
2000-01-01 00:00:00     0
2000-01-01 00:03:00     6
2000-01-01 00:06:00    15
2000-01-01 00:09:00    15
Freq: 3min, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.resample.html, pandas.Series.resample
">>> series.resample('30s').asfreq()[0:5]   # Select first 5 rows
2000-01-01 00:00:00   0.0
2000-01-01 00:00:30   NaN
2000-01-01 00:01:00   1.0
2000-01-01 00:01:30   NaN
2000-01-01 00:02:00   2.0
Freq: 30s, dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.resample.html, pandas.Series.resample
">>> series.resample('30s').ffill()[0:5]
2000-01-01 00:00:00    0
2000-01-01 00:00:30    0
2000-01-01 00:01:00    1
2000-01-01 00:01:30    1
2000-01-01 00:02:00    2
Freq: 30s, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.resample.html, pandas.Series.resample
">>> series.resample('30s').bfill()[0:5]
2000-01-01 00:00:00    0
2000-01-01 00:00:30    1
2000-01-01 00:01:00    1
2000-01-01 00:01:30    2
2000-01-01 00:02:00    2
Freq: 30s, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.resample.html, pandas.Series.resample
">>> def custom_resampler(arraylike):
...     return np.sum(arraylike) + 5
...
>>> series.resample('3min').apply(custom_resampler)
2000-01-01 00:00:00     8
2000-01-01 00:03:00    17
2000-01-01 00:06:00    26
Freq: 3min, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.resample.html, pandas.Series.resample
">>> d = {'price': [10, 11, 9, 13, 14, 18, 17, 19],
...      'volume': [50, 60, 40, 100, 50, 100, 40, 50]}
>>> df = pd.DataFrame(d)
>>> df['week_starting'] = pd.date_range('01/01/2018',
...                                     periods=8,
...                                     freq='W')
>>> df
   price  volume week_starting
0     10      50    2018-01-07
1     11      60    2018-01-14
2      9      40    2018-01-21
3     13     100    2018-01-28
4     14      50    2018-02-04
5     18     100    2018-02-11
6     17      40    2018-02-18
7     19      50    2018-02-25
>>> df.resample('ME', on='week_starting').mean()
               price  volume
week_starting
2018-01-31     10.75    62.5
2018-02-28     17.00    60.0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.resample.html, pandas.DataFrame pandas.date_range pandas.DataFrame.resample
">>> days = pd.date_range('1/1/2000', periods=4, freq='D')
>>> d2 = {'price': [10, 11, 9, 13, 14, 18, 17, 19],
...       'volume': [50, 60, 40, 100, 50, 100, 40, 50]}
>>> df2 = pd.DataFrame(
...     d2,
...     index=pd.MultiIndex.from_product(
...         [days, ['morning', 'afternoon']]
...     )
... )
>>> df2
                      price  volume
2000-01-01 morning       10      50
           afternoon     11      60
2000-01-02 morning        9      40
           afternoon     13     100
2000-01-03 morning       14      50
           afternoon     18     100
2000-01-04 morning       17      40
           afternoon     19      50
>>> df2.resample('D', level=0).sum()
            price  volume
2000-01-01     21     110
2000-01-02     22     140
2000-01-03     32     150
2000-01-04     36      90
",https://pandas.pydata.org/docs/reference/api/pandas.Series.resample.html, pandas.date_range pandas.DataFrame pandas.MultiIndex.from_product pandas.DataFrame.resample
">>> start, end = '2000-10-01 23:30:00', '2000-10-02 00:30:00'
>>> rng = pd.date_range(start, end, freq='7min')
>>> ts = pd.Series(np.arange(len(rng)) * 3, index=rng)
>>> ts
2000-10-01 23:30:00     0
2000-10-01 23:37:00     3
2000-10-01 23:44:00     6
2000-10-01 23:51:00     9
2000-10-01 23:58:00    12
2000-10-02 00:05:00    15
2000-10-02 00:12:00    18
2000-10-02 00:19:00    21
2000-10-02 00:26:00    24
Freq: 7min, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.resample.html, pandas.date_range pandas.Series
">>> ts.resample('17min').sum()
2000-10-01 23:14:00     0
2000-10-01 23:31:00     9
2000-10-01 23:48:00    21
2000-10-02 00:05:00    54
2000-10-02 00:22:00    24
Freq: 17min, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.resample.html, pandas.Series.resample
">>> ts.resample('17min', origin='epoch').sum()
2000-10-01 23:18:00     0
2000-10-01 23:35:00    18
2000-10-01 23:52:00    27
2000-10-02 00:09:00    39
2000-10-02 00:26:00    24
Freq: 17min, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.resample.html, pandas.Series.resample
">>> ts.resample('17min', origin='2000-01-01').sum()
2000-10-01 23:24:00     3
2000-10-01 23:41:00    15
2000-10-01 23:58:00    45
2000-10-02 00:15:00    45
Freq: 17min, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.resample.html, pandas.Series.resample
">>> ts.resample('17min', origin='start').sum()
2000-10-01 23:30:00     9
2000-10-01 23:47:00    21
2000-10-02 00:04:00    54
2000-10-02 00:21:00    24
Freq: 17min, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.resample.html, pandas.Series.resample
">>> ts.resample('17min', offset='23h30min').sum()
2000-10-01 23:30:00     9
2000-10-01 23:47:00    21
2000-10-02 00:04:00    54
2000-10-02 00:21:00    24
Freq: 17min, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.resample.html, pandas.Series.resample
">>> ts.resample('17min', origin='end').sum()
2000-10-01 23:35:00     0
2000-10-01 23:52:00    18
2000-10-02 00:09:00    27
2000-10-02 00:26:00    63
Freq: 17min, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.resample.html, pandas.Series.resample
">>> ts.resample('17min', origin='end_day').sum()
2000-10-01 23:38:00     3
2000-10-01 23:55:00    15
2000-10-02 00:12:00    45
2000-10-02 00:29:00    45
Freq: 17min, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.resample.html, pandas.Series.resample
">>> s = pd.Series([""a1a2"", ""b1"", ""c1""], index=[""A"", ""B"", ""C""])
>>> s.str.extractall(r""[ab](\d)"")
        0
match
A 0      1
  1      2
B 0      1
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.extractall.html, pandas.Series pandas.Series.str.extractall
">>> s.str.extractall(r""[ab](?P\d)"")
        digit
match
A 0         1
  1         2
B 0         1
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.extractall.html, pandas.Series.str.extractall
">>> s.str.extractall(r""(?P[ab])(?P\d)"")
        letter digit
match
A 0          a     1
  1          a     2
B 0          b     1
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.extractall.html, pandas.Series.str.extractall
">>> s.str.extractall(r""(?P[ab])?(?P\d)"")
        letter digit
match
A 0          a     1
  1          a     2
B 0          b     1
C 0        NaN     1
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.extractall.html, pandas.Series.str.extractall
">>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])
>>> a
a    1.0
b    1.0
c    1.0
d    NaN
dtype: float64
>>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])
>>> b
a    1.0
b    NaN
d    1.0
e    NaN
dtype: float64
>>> a.divide(b, fill_value=0)
a    1.0
b    inf
c    inf
d    0.0
e    NaN
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.rtruediv.html, pandas.Series
">>> s = pd.Series([-1.10, 2, -3.33, 4])
>>> s.abs()
0    1.10
1    2.00
2    3.33
3    4.00
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.abs.html, pandas.Series pandas.Series.abs
">>> s = pd.Series([1.2 + 1j])
>>> s.abs()
0    1.56205
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.abs.html, pandas.Series pandas.Series.abs
">>> s = pd.Series([pd.Timedelta('1 days')])
>>> s.abs()
0   1 days
dtype: timedelta64[ns]
",https://pandas.pydata.org/docs/reference/api/pandas.Series.abs.html, pandas.Series pandas.Series.abs
">>> df = pd.DataFrame({
...     'a': [4, 5, 6, 7],
...     'b': [10, 20, 30, 40],
...     'c': [100, 50, -30, -50]
... })
>>> df
     a    b    c
0    4   10  100
1    5   20   50
2    6   30  -30
3    7   40  -50
>>> df.loc[(df.c - 43).abs().argsort()]
     a    b    c
1    5   20   50
0    4   10  100
2    6   30  -30
3    7   40  -50
",https://pandas.pydata.org/docs/reference/api/pandas.Series.abs.html, pandas.DataFrame
">>> datetime_series = pd.Series(
...     pd.date_range(""2000-01-01"", periods=3, freq=""YE"")
... )
>>> datetime_series
0   2000-12-31
1   2001-12-31
2   2002-12-31
dtype: datetime64[ns]
>>> datetime_series.dt.year
0    2000
1    2001
2    2002
dtype: int32
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.year.html, pandas.Series pandas.date_range
">>> s = pd.Series(['-1', '1', '1000', 10, np.nan])
>>> s
0      -1
1       1
2    1000
3      10
4     NaN
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.zfill.html, pandas.Series
">>> s.str.zfill(3)
0     -01
1     001
2    1000
3     NaN
4     NaN
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.zfill.html, pandas.Series.str.zfill
">>> ser = pd.Series(['cow', '123', '()'])
>>> ser.str.encode(encoding='ascii')
0     b'cow'
1     b'123'
2      b'()'
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.encode.html, pandas.Series pandas.Series.str.encode
">>> s = pd.Series([""1/1/2020 10:00:00+00:00"", ""2/1/2020 11:00:00+00:00""])
>>> s = pd.to_datetime(s)
>>> s
0   2020-01-01 10:00:00+00:00
1   2020-02-01 11:00:00+00:00
dtype: datetime64[ns, UTC]
>>> s.dt.date
0    2020-01-01
1    2020-02-01
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.date.html, pandas.Series pandas.to_datetime
">>> idx = pd.DatetimeIndex([""1/1/2020 10:00:00+00:00"",
...                         ""2/1/2020 11:00:00+00:00""])
>>> idx.date
array([datetime.date(2020, 1, 1), datetime.date(2020, 2, 1)], dtype=object)
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.date.html, pandas.DatetimeIndex pandas.array pandas.Timestamp.date
">>> s1 = pd.Series(['one', 'one1', '1', ''])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isalpha.html, pandas.Series
">>> s1.str.isalpha()
0     True
1    False
2    False
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isalpha.html, pandas.Series.str.isalpha
">>> s1.str.isnumeric()
0    False
1    False
2     True
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isalpha.html, pandas.Series.str.isnumeric
">>> s1.str.isalnum()
0     True
1     True
2     True
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isalpha.html, pandas.Series.str.isalnum
">>> s2 = pd.Series(['A B', '1.5', '3,000'])
>>> s2.str.isalnum()
0    False
1    False
2    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isalpha.html, pandas.Series pandas.Series.str.isalnum
">>> s3 = pd.Series(['23', '³', '⅕', ''])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isalpha.html, pandas.Series
">>> s3.str.isdecimal()
0     True
1    False
2    False
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isalpha.html, pandas.Series.str.isdecimal
">>> s3.str.isdigit()
0     True
1     True
2    False
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isalpha.html, pandas.Series.str.isdigit
">>> s3.str.isnumeric()
0     True
1     True
2     True
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isalpha.html, pandas.Series.str.isnumeric
">>> s4 = pd.Series([' ', '\t\r\n ', ''])
>>> s4.str.isspace()
0     True
1     True
2    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isalpha.html, pandas.Series pandas.Series.str.isspace
">>> s5 = pd.Series(['leopard', 'Golden Eagle', 'SNAKE', ''])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isalpha.html, pandas.Series
">>> s5.str.islower()
0     True
1    False
2    False
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isalpha.html, pandas.Series.str.islower
">>> s5.str.isupper()
0    False
1    False
2     True
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isalpha.html, pandas.Series.str.isupper
">>> s5.str.istitle()
0    False
1     True
2    False
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isalpha.html, pandas.Series.str.istitle
">>> from pandas.arrays import SparseArray
>>> s = SparseArray([0, 0, 1, 1, 1], fill_value=0)
>>> s.npoints
3
",https://pandas.pydata.org/docs/reference/api/pandas.Series.sparse.npoints.html, pandas.arrays.SparseArray
">>> s = pd.Series(['Ant', 'Bear', 'Cow'])
>>> s
0     Ant
1    Bear
2     Cow
dtype: object
>>> s.size
3
",https://pandas.pydata.org/docs/reference/api/pandas.Series.size.html, pandas.Series
">>> idx = pd.Index([1, 2, 3])
>>> idx
Index([1, 2, 3], dtype='int64')
>>> idx.size
3
",https://pandas.pydata.org/docs/reference/api/pandas.Series.size.html, pandas.Index pandas.Index
">>> df_not_necessarily_pandas = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})
>>> interchange_object = df_not_necessarily_pandas.__dataframe__()
>>> interchange_object.column_names()
Index(['A', 'B'], dtype='object')
>>> df_pandas = (pd.api.interchange.from_dataframe
...              (interchange_object.select_columns_by_name(['A'])))
>>> df_pandas
     A
0    1
1    2
",https://pandas.pydata.org/docs/reference/api/pandas.api.interchange.from_dataframe.html, pandas.DataFrame pandas.Index
">>> df = pd.DataFrame({'animal': ['alligator', 'bee', 'falcon', 'lion',
...                    'monkey', 'parrot', 'shark', 'whale', 'zebra']})
>>> df
      animal
0  alligator
1        bee
2     falcon
3       lion
4     monkey
5     parrot
6      shark
7      whale
8      zebra
",https://pandas.pydata.org/docs/reference/api/pandas.Series.head.html, pandas.DataFrame
">>> df.head()
      animal
0  alligator
1        bee
2     falcon
3       lion
4     monkey
",https://pandas.pydata.org/docs/reference/api/pandas.Series.head.html, pandas.DataFrame.head
">>> df.head(3)
      animal
0  alligator
1        bee
2     falcon
",https://pandas.pydata.org/docs/reference/api/pandas.Series.head.html, pandas.DataFrame.head
">>> df.head(-3)
      animal
0  alligator
1        bee
2     falcon
3       lion
4     monkey
5     parrot
",https://pandas.pydata.org/docs/reference/api/pandas.Series.head.html, pandas.DataFrame.head
">>> s = pd.Series([""dog"", ""cat"", ""monkey""])
>>> s
0       dog
1       cat
2    monkey
dtype: object
>>> s.rename_axis(""animal"")
animal
0    dog
1    cat
2    monkey
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.rename_axis.html, pandas.Series pandas.Series.rename_axis
">>> df = pd.DataFrame({""num_legs"": [4, 4, 2],
...                    ""num_arms"": [0, 0, 2]},
...                   [""dog"", ""cat"", ""monkey""])
>>> df
        num_legs  num_arms
dog            4         0
cat            4         0
monkey         2         2
>>> df = df.rename_axis(""animal"")
>>> df
        num_legs  num_arms
animal
dog            4         0
cat            4         0
monkey         2         2
>>> df = df.rename_axis(""limbs"", axis=""columns"")
>>> df
limbs   num_legs  num_arms
animal
dog            4         0
cat            4         0
monkey         2         2
",https://pandas.pydata.org/docs/reference/api/pandas.Series.rename_axis.html, pandas.DataFrame pandas.DataFrame.rename_axis
">>> df.index = pd.MultiIndex.from_product([['mammal'],
...                                        ['dog', 'cat', 'monkey']],
...                                       names=['type', 'name'])
>>> df
limbs          num_legs  num_arms
type   name
mammal dog            4         0
       cat            4         0
       monkey         2         2
",https://pandas.pydata.org/docs/reference/api/pandas.Series.rename_axis.html, pandas.MultiIndex.from_product
">>> df.rename_axis(index={'type': 'class'})
limbs          num_legs  num_arms
class  name
mammal dog            4         0
       cat            4         0
       monkey         2         2
",https://pandas.pydata.org/docs/reference/api/pandas.Series.rename_axis.html, pandas.DataFrame.rename_axis
">>> df.rename_axis(columns=str.upper)
LIMBS          num_legs  num_arms
type   name
mammal dog            4         0
       cat            4         0
       monkey         2         2
",https://pandas.pydata.org/docs/reference/api/pandas.Series.rename_axis.html, pandas.DataFrame.rename_axis
">>> dti = pd.date_range(start='2014-08-01 09:00',
...                     freq='h', periods=3, tz='Europe/Berlin')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.tz_convert.html, pandas.date_range
">>> dti
DatetimeIndex(['2014-08-01 09:00:00+02:00',
               '2014-08-01 10:00:00+02:00',
               '2014-08-01 11:00:00+02:00'],
              dtype='datetime64[ns, Europe/Berlin]', freq='h')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.tz_convert.html, pandas.DatetimeIndex
">>> dti.tz_convert('US/Central')
DatetimeIndex(['2014-08-01 02:00:00-05:00',
               '2014-08-01 03:00:00-05:00',
               '2014-08-01 04:00:00-05:00'],
              dtype='datetime64[ns, US/Central]', freq='h')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.tz_convert.html, pandas.DatetimeIndex
">>> dti = pd.date_range(start='2014-08-01 09:00', freq='h',
...                     periods=3, tz='Europe/Berlin')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.tz_convert.html, pandas.date_range
">>> dti
DatetimeIndex(['2014-08-01 09:00:00+02:00',
               '2014-08-01 10:00:00+02:00',
               '2014-08-01 11:00:00+02:00'],
                dtype='datetime64[ns, Europe/Berlin]', freq='h')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.tz_convert.html, pandas.DatetimeIndex
">>> dti.tz_convert(None)
DatetimeIndex(['2014-08-01 07:00:00',
               '2014-08-01 08:00:00',
               '2014-08-01 09:00:00'],
                dtype='datetime64[ns]', freq='h')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.tz_convert.html, pandas.DatetimeIndex
">>> ser = pd.Series(['dog', 'bird', 'mouse'])
>>> ser.str.center(8, fillchar='.')
0   ..dog...
1   ..bird..
2   .mouse..
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.center.html, pandas.Series pandas.Series.str.center
">>> ser = pd.Series(['dog', 'bird', 'mouse'])
>>> ser.str.ljust(8, fillchar='.')
0   dog.....
1   bird....
2   mouse...
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.center.html, pandas.Series pandas.Series.str.ljust
">>> ser = pd.Series(['dog', 'bird', 'mouse'])
>>> ser.str.rjust(8, fillchar='.')
0   .....dog
1   ....bird
2   ...mouse
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.center.html, pandas.Series pandas.Series.str.rjust
">>> s = pd.Series({'Corn Flakes': 100.0, 'Almond Delight': 110.0,
...                'Cinnamon Toast Crunch': 120.0, 'Cocoa Puff': 110.0})
>>> s
Corn Flakes              100.0
Almond Delight           110.0
Cinnamon Toast Crunch    120.0
Cocoa Puff               110.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.argmin.html, pandas.Series
">>> s.argmax()
2
>>> s.argmin()
0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.argmin.html, pandas.Series.argmax pandas.Series.argmin
">>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])
>>> a
a    1.0
b    1.0
c    1.0
d    NaN
dtype: float64
>>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])
>>> b
a    1.0
b    NaN
d    1.0
e    NaN
dtype: float64
>>> a.subtract(b, fill_value=0)
a    0.0
b    1.0
c    1.0
d   -1.0
e    NaN
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.rsub.html, pandas.Series
">>> s = pd.date_range('2016-12-31', '2017-01-08', freq='D').to_series()
>>> s.dt.dayofweek
2016-12-31    5
2017-01-01    6
2017-01-02    0
2017-01-03    1
2017-01-04    2
2017-01-05    3
2017-01-06    4
2017-01-07    5
2017-01-08    6
Freq: D, dtype: int32
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.dayofweek.html, pandas.date_range
">>> df = pd.DataFrame(np.random.randint(1, 7, 6000), columns=['one'])
>>> df['two'] = df['one'] + np.random.randint(1, 7, 6000)
>>> ax = df.plot.hist(bins=12, alpha=0.5)
",https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.hist.html, pandas.DataFrame pandas.DataFrame.plot.hist
">>> age_list = [8, 10, 12, 14, 72, 74, 76, 78, 20, 25, 30, 35, 60, 85]
>>> df = pd.DataFrame({""gender"": list(""MMMMMMMMFFFFFF""), ""age"": age_list})
>>> ax = df.plot.hist(column=[""age""], by=""gender"", figsize=(10, 8))
",https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.hist.html, pandas.DataFrame pandas.DataFrame.plot.hist
">>> s = pd.Series([""a"", ""b"", ""c""],
...               name=""vals"")
>>> s.to_frame()
  vals
0    a
1    b
2    c
",https://pandas.pydata.org/docs/reference/api/pandas.Series.to_frame.html, pandas.Series pandas.Series.to_frame
">>> s1 = pd.Series([""a"", ""b"", ""c"", ""d"", ""e""])
>>> s2 = pd.Series([""a"", ""a"", ""c"", ""b"", ""e""])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.compare.html, pandas.Series
">>> s1.compare(s2)
  self other
1    b     a
3    d     b
",https://pandas.pydata.org/docs/reference/api/pandas.Series.compare.html, pandas.Series.compare
">>> s1.compare(s2, align_axis=0)
1  self     b
   other    a
3  self     d
   other    b
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.compare.html, pandas.Series.compare
">>> s1.compare(s2, keep_shape=True)
  self other
0  NaN   NaN
1    b     a
2  NaN   NaN
3    d     b
4  NaN   NaN
",https://pandas.pydata.org/docs/reference/api/pandas.Series.compare.html, pandas.Series.compare
">>> s1.compare(s2, keep_shape=True, keep_equal=True)
  self other
0    a     a
1    b     a
2    c     c
3    d     b
4    e     e
",https://pandas.pydata.org/docs/reference/api/pandas.Series.compare.html, pandas.Series.compare
">>> df = pd.DataFrame(dict(age=[5, 6, np.nan],
...                        born=[pd.NaT, pd.Timestamp('1939-05-27'),
...                              pd.Timestamp('1940-04-25')],
...                        name=['Alfred', 'Batman', ''],
...                        toy=[None, 'Batmobile', 'Joker']))
>>> df
   age       born    name        toy
0  5.0        NaT  Alfred       None
1  6.0 1939-05-27  Batman  Batmobile
2  NaN 1940-04-25              Joker
",https://pandas.pydata.org/docs/reference/api/pandas.Series.isna.html, pandas.DataFrame
">>> df.isna()
     age   born   name    toy
0  False   True  False   True
1  False  False  False  False
2   True  False  False  False
",https://pandas.pydata.org/docs/reference/api/pandas.Series.isna.html, pandas.DataFrame.isna
">>> ser = pd.Series([5, 6, np.nan])
>>> ser
0    5.0
1    6.0
2    NaN
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.isna.html, pandas.Series
">>> ser.isna()
0    False
1    False
2     True
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.isna.html, pandas.Series.isna
">>> def histogram_intersection(a, b):
...     v = np.minimum(a, b).sum().round(decimals=1)
...     return v
>>> s1 = pd.Series([.2, .0, .6, .2])
>>> s2 = pd.Series([.3, .6, .0, .1])
>>> s1.corr(s2, method=histogram_intersection)
0.3
",https://pandas.pydata.org/docs/reference/api/pandas.Series.corr.html, pandas.Series pandas.Series.corr
">>> s1 = pd.Series([1, 2, 3], index=[0, 1, 2])
>>> s2 = pd.Series([1, 2, 3], index=[2, 1, 0])
>>> s1.corr(s2)
-1.0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.corr.html, pandas.Series pandas.Series.corr
">>> a = pd.Series([1, 1, 1, np.nan, 1], index=['a', 'b', 'c', 'd', 'e'])
>>> a
a    1.0
b    1.0
c    1.0
d    NaN
e    1.0
dtype: float64
>>> b = pd.Series([0, 1, 2, np.nan, 1], index=['a', 'b', 'c', 'd', 'f'])
>>> b
a    0.0
b    1.0
c    2.0
d    NaN
f    1.0
dtype: float64
>>> a.le(b, fill_value=0)
a    False
b     True
c     True
d    False
e    False
f     True
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.le.html, pandas.Series pandas.Series.le
">>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])
>>> a
a    1.0
b    1.0
c    1.0
d    NaN
dtype: float64
>>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])
>>> b
a    1.0
b    NaN
d    1.0
e    NaN
dtype: float64
>>> a.add(b, fill_value=0)
a    2.0
b    1.0
c    1.0
d    1.0
e    NaN
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.radd.html, pandas.Series pandas.Series.add
">>> ser = pd.Series([""horse"", ""eagle"", ""donkey""])
>>> ser.str.match(""e"")
0   False
1   True
2   False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.match.html, pandas.Series pandas.Series.str.match
">>> df = pd.DataFrame({'lab':['A', 'B', 'C'], 'val':[10, 30, 20]})
>>> ax = df.plot.bar(x='lab', y='val', rot=0)
",https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.bar.html, pandas.DataFrame pandas.DataFrame.plot.bar
">>> speed = [0.1, 17.5, 40, 48, 52, 69, 88]
>>> lifespan = [2, 8, 70, 1.5, 25, 12, 28]
>>> index = ['snail', 'pig', 'elephant',
...          'rabbit', 'giraffe', 'coyote', 'horse']
>>> df = pd.DataFrame({'speed': speed,
...                    'lifespan': lifespan}, index=index)
>>> ax = df.plot.bar(rot=0)
",https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.bar.html, pandas.DataFrame pandas.DataFrame.plot.bar
">>> ax = df.plot.bar(stacked=True)
",https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.bar.html, pandas.DataFrame.plot.bar
">>> axes = df.plot.bar(rot=0, subplots=True)
>>> axes[1].legend(loc=2)  
",https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.bar.html, pandas.DataFrame.plot.bar
">>> axes = df.plot.bar(
...     rot=0, subplots=True, color={""speed"": ""red"", ""lifespan"": ""green""}
... )
>>> axes[1].legend(loc=2)  
",https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.bar.html, pandas.DataFrame.plot.bar
">>> ax = df.plot.bar(y='speed', rot=0)
",https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.bar.html, pandas.DataFrame.plot.bar
">>> ax = df.plot.bar(x='lifespan', rot=0)
",https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.bar.html, pandas.DataFrame.plot.bar
">>> s1 = pd.Series(['Mouse', 'dog', 'house and parrot', '23', np.nan])
>>> s1.str.contains('og', regex=False)
0    False
1     True
2    False
3    False
4      NaN
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.contains.html, pandas.Series pandas.Series.str.contains
">>> ind = pd.Index(['Mouse', 'dog', 'house and parrot', '23.0', np.nan])
>>> ind.str.contains('23', regex=False)
Index([False, False, False, True, nan], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.contains.html, pandas.Index pandas.Index
">>> s1.str.contains('oG', case=True, regex=True)
0    False
1    False
2    False
3    False
4      NaN
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.contains.html, pandas.Series.str.contains
">>> s1.str.contains('og', na=False, regex=True)
0    False
1     True
2    False
3    False
4    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.contains.html, pandas.Series.str.contains
">>> s1.str.contains('house|dog', regex=True)
0    False
1     True
2     True
3    False
4      NaN
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.contains.html, pandas.Series.str.contains
">>> import re
>>> s1.str.contains('PARROT', flags=re.IGNORECASE, regex=True)
0    False
1    False
2     True
3    False
4      NaN
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.contains.html, pandas.Series.str.contains
">>> s1.str.contains('\\d', regex=True)
0    False
1    False
2    False
3     True
4      NaN
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.contains.html, pandas.Series.str.contains
">>> s2 = pd.Series(['40', '40.0', '41', '41.0', '35'])
>>> s2.str.contains('.0', regex=True)
0     True
1     True
2    False
3     True
4    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.contains.html, pandas.Series pandas.Series.str.contains
">>> ser = pd.Series(['a', 'b', 'c', 'a'], dtype='category')
>>> ser = ser.cat.reorder_categories(['c', 'b', 'a'], ordered=True)
>>> ser
0   a
1   b
2   c
3   a
dtype: category
Categories (3, object): ['c' < 'b' < 'a']
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.reorder_categories.html, pandas.Series pandas.Series.cat.reorder_categories
">>> ser.sort_values()
2   c
1   b
0   a
3   a
dtype: category
Categories (3, object): ['c' < 'b' < 'a']
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.reorder_categories.html, pandas.Series.sort_values
">>> ci = pd.CategoricalIndex(['a', 'b', 'c', 'a'])
>>> ci
CategoricalIndex(['a', 'b', 'c', 'a'], categories=['a', 'b', 'c'],
                 ordered=False, dtype='category')
>>> ci.reorder_categories(['c', 'b', 'a'], ordered=True)
CategoricalIndex(['a', 'b', 'c', 'a'], categories=['c', 'b', 'a'],
                 ordered=True, dtype='category')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.reorder_categories.html, pandas.CategoricalIndex pandas.CategoricalIndex pandas.CategoricalIndex.reorder_categories
">>> s = pd.Series([1, 2, 2.5, 3, 3.5, 4, 5])
>>> ax = s.plot.kde()
",https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.density.html, pandas.Series pandas.Series.plot.kde
">>> ax = s.plot.kde(bw_method=0.3)
",https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.density.html, pandas.Series.plot.kde
">>> ax = s.plot.kde(bw_method=3)
",https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.density.html, pandas.Series.plot.kde
">>> ax = s.plot.kde(ind=[1, 2, 3, 4, 5])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.density.html, pandas.Series.plot.kde
">>> df = pd.DataFrame({
...     'x': [1, 2, 2.5, 3, 3.5, 4, 5],
...     'y': [4, 4, 4.5, 5, 5.5, 6, 6],
... })
>>> ax = df.plot.kde()
",https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.density.html, pandas.DataFrame pandas.DataFrame.plot.kde
">>> ax = df.plot.kde(bw_method=0.3)
",https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.density.html, pandas.DataFrame.plot.kde
">>> ax = df.plot.kde(bw_method=3)
",https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.density.html, pandas.DataFrame.plot.kde
">>> ax = df.plot.kde(ind=[1, 2, 3, 4, 5, 6])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.density.html, pandas.DataFrame.plot.kde
">>> countries_population = {""Italy"": 59000000, ""France"": 65000000,
...                         ""Malta"": 434000, ""Maldives"": 434000,
...                         ""Brunei"": 434000, ""Iceland"": 337000,
...                         ""Nauru"": 11300, ""Tuvalu"": 11300,
...                         ""Anguilla"": 11300, ""Montserrat"": 5200}
>>> s = pd.Series(countries_population)
>>> s
Italy       59000000
France      65000000
Malta         434000
Maldives      434000
Brunei        434000
Iceland       337000
Nauru          11300
Tuvalu         11300
Anguilla       11300
Montserrat      5200
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.nlargest.html, pandas.Series
">>> s.nlargest()
France      65000000
Italy       59000000
Malta         434000
Maldives      434000
Brunei        434000
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.nlargest.html, pandas.Series.nlargest
">>> s.nlargest(3)
France    65000000
Italy     59000000
Malta       434000
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.nlargest.html, pandas.Series.nlargest
">>> s.nlargest(3, keep='last')
France      65000000
Italy       59000000
Brunei        434000
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.nlargest.html, pandas.Series.nlargest
">>> s.nlargest(3, keep='all')
France      65000000
Italy       59000000
Malta         434000
Maldives      434000
Brunei        434000
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.nlargest.html, pandas.Series.nlargest
">>> primes = pd.Series([2, 3, 5, 7])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.squeeze.html, pandas.Series
">>> df = pd.DataFrame([[1, 2], [3, 4]], columns=['a', 'b'])
>>> df
   a  b
0  1  2
1  3  4
",https://pandas.pydata.org/docs/reference/api/pandas.Series.squeeze.html, pandas.DataFrame
">>> pd.Series([], dtype=""float64"").prod()
1.0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.product.html, pandas.Series
">>> pd.Series([], dtype=""float64"").prod(min_count=1)
nan
",https://pandas.pydata.org/docs/reference/api/pandas.Series.product.html, pandas.Series
">>> pd.Series([np.nan]).prod()
1.0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.product.html, pandas.Series
">>> pd.Series([np.nan]).prod(min_count=1)
nan
",https://pandas.pydata.org/docs/reference/api/pandas.Series.product.html, pandas.Series
">>> df = pd.DataFrame(
...     [
...         [24.3, 75.7, ""high""],
...         [31, 87.8, ""high""],
...         [22, 71.6, ""medium""],
...         [35, 95, ""medium""],
...     ],
...     columns=[""temp_celsius"", ""temp_fahrenheit"", ""windspeed""],
...     index=pd.date_range(start=""2014-02-12"", end=""2014-02-15"", freq=""D""),
... )
",https://pandas.pydata.org/docs/reference/api/pandas.Series.get.html, pandas.DataFrame pandas.date_range
">>> df.get([""temp_celsius"", ""windspeed""])
            temp_celsius windspeed
2014-02-12          24.3      high
2014-02-13          31.0      high
2014-02-14          22.0    medium
2014-02-15          35.0    medium
",https://pandas.pydata.org/docs/reference/api/pandas.Series.get.html, pandas.DataFrame.get
">>> ser = df['windspeed']
>>> ser.get('2014-02-13')
'high'
",https://pandas.pydata.org/docs/reference/api/pandas.Series.get.html, pandas.Series.get
">>> df.get([""temp_celsius"", ""temp_kelvin""], default=""default_value"")
'default_value'
",https://pandas.pydata.org/docs/reference/api/pandas.Series.get.html, pandas.DataFrame.get
">>> ser.get('2014-02-10', '[unknown]')
'[unknown]'
",https://pandas.pydata.org/docs/reference/api/pandas.Series.get.html, pandas.Series.get
">>> df = pd.DataFrame(
...     {
...         ""a"": pd.Series([1, 2, 3], dtype=np.dtype(""int32"")),
...         ""b"": pd.Series([""x"", ""y"", ""z""], dtype=np.dtype(""O"")),
...         ""c"": pd.Series([True, False, np.nan], dtype=np.dtype(""O"")),
...         ""d"": pd.Series([""h"", ""i"", np.nan], dtype=np.dtype(""O"")),
...         ""e"": pd.Series([10, np.nan, 20], dtype=np.dtype(""float"")),
...         ""f"": pd.Series([np.nan, 100.5, 200], dtype=np.dtype(""float"")),
...     }
... )
",https://pandas.pydata.org/docs/reference/api/pandas.Series.convert_dtypes.html, pandas.DataFrame pandas.Series
">>> dfn = df.convert_dtypes()
>>> dfn
   a  b      c     d     e      f
0  1  x   True     h    10   
1  2  y  False     i    100.5
2  3  z         20  200.0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.convert_dtypes.html, pandas.DataFrame.convert_dtypes
">>> s = pd.Series([""a"", ""b"", np.nan])
>>> s
0      a
1      b
2    NaN
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.convert_dtypes.html, pandas.Series
">>> s.convert_dtypes()
0       a
1       b
2    
dtype: string
",https://pandas.pydata.org/docs/reference/api/pandas.Series.convert_dtypes.html, pandas.Series.convert_dtypes
">>> s = pd.Series([1, 2, 3], index=[0, 1, 2])
>>> s.keys()
Index([0, 1, 2], dtype='int64')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.keys.html, pandas.Series pandas.Series.keys pandas.Index
">>> s = pd.Series(range(5))
>>> s.where(s > 0)
0    NaN
1    1.0
2    2.0
3    3.0
4    4.0
dtype: float64
>>> s.mask(s > 0)
0    0.0
1    NaN
2    NaN
3    NaN
4    NaN
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.mask.html, pandas.Series pandas.Series.where pandas.Series.mask
">>> s = pd.Series(range(5))
>>> t = pd.Series([True, False])
>>> s.where(t, 99)
0     0
1    99
2    99
3    99
4    99
dtype: int64
>>> s.mask(t, 99)
0    99
1     1
2    99
3    99
4    99
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.mask.html, pandas.Series pandas.Series.where pandas.Series.mask
">>> s.where(s > 1, 10)
0    10
1    10
2    2
3    3
4    4
dtype: int64
>>> s.mask(s > 1, 10)
0     0
1     1
2    10
3    10
4    10
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.mask.html, pandas.Series.where pandas.Series.mask
">>> df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=['A', 'B'])
>>> df
   A  B
0  0  1
1  2  3
2  4  5
3  6  7
4  8  9
>>> m = df % 3 == 0
>>> df.where(m, -df)
   A  B
0  0 -1
1 -2  3
2 -4 -5
3  6 -7
4 -8  9
>>> df.where(m, -df) == np.where(m, df, -df)
      A     B
0  True  True
1  True  True
2  True  True
3  True  True
4  True  True
>>> df.where(m, -df) == df.mask(~m, -df)
      A     B
0  True  True
1  True  True
2  True  True
3  True  True
4  True  True
",https://pandas.pydata.org/docs/reference/api/pandas.Series.mask.html, pandas.DataFrame pandas.DataFrame.where pandas.DataFrame.mask
">>> s = pd.Series([1, 2, 3])
>>> for x in s:
...     print(x)
1
2
3
",https://pandas.pydata.org/docs/reference/api/pandas.Series.__iter__.html, pandas.Series
">>> df = pd.DataFrame(dict(age=[5, 6, np.nan],
...                        born=[pd.NaT, pd.Timestamp('1939-05-27'),
...                              pd.Timestamp('1940-04-25')],
...                        name=['Alfred', 'Batman', ''],
...                        toy=[None, 'Batmobile', 'Joker']))
>>> df
   age       born    name        toy
0  5.0        NaT  Alfred       None
1  6.0 1939-05-27  Batman  Batmobile
2  NaN 1940-04-25              Joker
",https://pandas.pydata.org/docs/reference/api/pandas.Series.isnull.html, pandas.DataFrame
">>> df.isna()
     age   born   name    toy
0  False   True  False   True
1  False  False  False  False
2   True  False  False  False
",https://pandas.pydata.org/docs/reference/api/pandas.Series.isnull.html, pandas.DataFrame.isna
">>> ser = pd.Series([5, 6, np.nan])
>>> ser
0    5.0
1    6.0
2    NaN
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.isnull.html, pandas.Series
">>> ser.isna()
0    False
1    False
2     True
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.isnull.html, pandas.Series.isna
">>> countries_population = {""Italy"": 59000000, ""France"": 65000000,
...                         ""Brunei"": 434000, ""Malta"": 434000,
...                         ""Maldives"": 434000, ""Iceland"": 337000,
...                         ""Nauru"": 11300, ""Tuvalu"": 11300,
...                         ""Anguilla"": 11300, ""Montserrat"": 5200}
>>> s = pd.Series(countries_population)
>>> s
Italy       59000000
France      65000000
Brunei        434000
Malta         434000
Maldives      434000
Iceland       337000
Nauru          11300
Tuvalu         11300
Anguilla       11300
Montserrat      5200
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.nsmallest.html, pandas.Series
">>> s.nsmallest()
Montserrat    5200
Nauru        11300
Tuvalu       11300
Anguilla     11300
Iceland     337000
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.nsmallest.html, pandas.Series.nsmallest
">>> s.nsmallest(3)
Montserrat   5200
Nauru       11300
Tuvalu      11300
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.nsmallest.html, pandas.Series.nsmallest
">>> s.nsmallest(3, keep='last')
Montserrat   5200
Anguilla    11300
Tuvalu      11300
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.nsmallest.html, pandas.Series.nsmallest
">>> s.nsmallest(3, keep='all')
Montserrat   5200
Nauru       11300
Tuvalu      11300
Anguilla    11300
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.nsmallest.html, pandas.Series.nsmallest
">>> s1 = pd.Series(['one', 'one1', '1', ''])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isdigit.html, pandas.Series
">>> s1.str.isalpha()
0     True
1    False
2    False
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isdigit.html, pandas.Series.str.isalpha
">>> s1.str.isnumeric()
0    False
1    False
2     True
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isdigit.html, pandas.Series.str.isnumeric
">>> s1.str.isalnum()
0     True
1     True
2     True
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isdigit.html, pandas.Series.str.isalnum
">>> s2 = pd.Series(['A B', '1.5', '3,000'])
>>> s2.str.isalnum()
0    False
1    False
2    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isdigit.html, pandas.Series pandas.Series.str.isalnum
">>> s3 = pd.Series(['23', '³', '⅕', ''])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isdigit.html, pandas.Series
">>> s3.str.isdecimal()
0     True
1    False
2    False
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isdigit.html, pandas.Series.str.isdecimal
">>> s3.str.isdigit()
0     True
1     True
2    False
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isdigit.html, pandas.Series.str.isdigit
">>> s3.str.isnumeric()
0     True
1     True
2     True
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isdigit.html, pandas.Series.str.isnumeric
">>> s4 = pd.Series([' ', '\t\r\n ', ''])
>>> s4.str.isspace()
0     True
1     True
2    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isdigit.html, pandas.Series pandas.Series.str.isspace
">>> s5 = pd.Series(['leopard', 'Golden Eagle', 'SNAKE', ''])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isdigit.html, pandas.Series
">>> s5.str.islower()
0     True
1    False
2    False
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isdigit.html, pandas.Series.str.islower
">>> s5.str.isupper()
0    False
1    False
2     True
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isdigit.html, pandas.Series.str.isupper
">>> s5.str.istitle()
0    False
1     True
2    False
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isdigit.html, pandas.Series.str.istitle
">>> s = pd.Series([""1/1/2020 10:00:00+00:00"", ""2/1/2020 11:00:00+00:00""])
>>> s = pd.to_datetime(s)
>>> s
0   2020-01-01 10:00:00+00:00
1   2020-02-01 11:00:00+00:00
dtype: datetime64[ns, UTC]
>>> s.dt.time
0    10:00:00
1    11:00:00
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.time.html, pandas.Series pandas.to_datetime
">>> idx = pd.DatetimeIndex([""1/1/2020 10:00:00+00:00"",
...                         ""2/1/2020 11:00:00+00:00""])
>>> idx.time
array([datetime.time(10, 0), datetime.time(11, 0)], dtype=object)
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.time.html, pandas.DatetimeIndex pandas.array pandas.Timestamp.time
">>> s = pd.Series(
...     [1],
...     index=pd.DatetimeIndex(['2018-09-15 01:30:00']),
... )
>>> s.tz_localize('CET')
2018-09-15 01:30:00+02:00    1
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.tz_localize.html, pandas.Series pandas.DatetimeIndex pandas.Series.tz_localize
">>> s = pd.Series([1],
...               index=pd.DatetimeIndex(['2018-09-15 01:30:00+02:00']))
>>> s.tz_localize(None)
2018-09-15 01:30:00    1
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.tz_localize.html, pandas.Series pandas.DatetimeIndex pandas.Series.tz_localize
">>> s = pd.Series(range(7),
...               index=pd.DatetimeIndex(['2018-10-28 01:30:00',
...                                       '2018-10-28 02:00:00',
...                                       '2018-10-28 02:30:00',
...                                       '2018-10-28 02:00:00',
...                                       '2018-10-28 02:30:00',
...                                       '2018-10-28 03:00:00',
...                                       '2018-10-28 03:30:00']))
>>> s.tz_localize('CET', ambiguous='infer')
2018-10-28 01:30:00+02:00    0
2018-10-28 02:00:00+02:00    1
2018-10-28 02:30:00+02:00    2
2018-10-28 02:00:00+01:00    3
2018-10-28 02:30:00+01:00    4
2018-10-28 03:00:00+01:00    5
2018-10-28 03:30:00+01:00    6
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.tz_localize.html, pandas.Series pandas.DatetimeIndex pandas.Series.tz_localize
">>> s = pd.Series(range(3),
...               index=pd.DatetimeIndex(['2018-10-28 01:20:00',
...                                       '2018-10-28 02:36:00',
...                                       '2018-10-28 03:46:00']))
>>> s.tz_localize('CET', ambiguous=np.array([True, True, False]))
2018-10-28 01:20:00+02:00    0
2018-10-28 02:36:00+02:00    1
2018-10-28 03:46:00+01:00    2
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.tz_localize.html, pandas.Series pandas.DatetimeIndex pandas.Series.tz_localize
">>> s = pd.Series(range(2),
...               index=pd.DatetimeIndex(['2015-03-29 02:30:00',
...                                       '2015-03-29 03:30:00']))
>>> s.tz_localize('Europe/Warsaw', nonexistent='shift_forward')
2015-03-29 03:00:00+02:00    0
2015-03-29 03:30:00+02:00    1
dtype: int64
>>> s.tz_localize('Europe/Warsaw', nonexistent='shift_backward')
2015-03-29 01:59:59.999999999+01:00    0
2015-03-29 03:30:00+02:00              1
dtype: int64
>>> s.tz_localize('Europe/Warsaw', nonexistent=pd.Timedelta('1h'))
2015-03-29 03:30:00+02:00    0
2015-03-29 03:30:00+02:00    1
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.tz_localize.html, pandas.Series pandas.DatetimeIndex pandas.Series.tz_localize
">>> s = pd.Series([1, 2, 3])
>>> s.dtype
dtype('int64')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dtype.html, pandas.Series
">>> s = pd.Series(['Ant', 'Bear', 'Cow'])
>>> s
0     Ant
1    Bear
2     Cow
dtype: object
>>> s.T
0     Ant
1    Bear
2     Cow
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.T.html, pandas.Series
">>> idx = pd.Index([1, 2, 3])
>>> idx.T
Index([1, 2, 3], dtype='int64')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.T.html, pandas.Index pandas.Index
">>> idx = pd.MultiIndex.from_arrays([
...     ['warm', 'warm', 'cold', 'cold'],
...     ['dog', 'falcon', 'fish', 'spider']],
...     names=['blooded', 'animal'])
>>> s = pd.Series([4, 2, 0, 8], name='legs', index=idx)
>>> s
blooded  animal
warm     dog       4
         falcon    2
cold     fish      0
         spider    8
Name: legs, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.max.html, pandas.MultiIndex.from_arrays pandas.Series
">>> s.max()
8
",https://pandas.pydata.org/docs/reference/api/pandas.Series.max.html, pandas.Series.max
">>> df = pd.DataFrame({'mass': [0.330, 4.87 , 5.97],
...                    'radius': [2439.7, 6051.8, 6378.1]},
...                   index=['Mercury', 'Venus', 'Earth'])
>>> plot = df.plot.pie(y='mass', figsize=(5, 5))
",https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.pie.html, pandas.DataFrame pandas.DataFrame.plot.pie
">>> plot = df.plot.pie(subplots=True, figsize=(11, 6))
",https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.pie.html, pandas.DataFrame.plot.pie
">>> pd.Series(['a|b', 'a', 'a|c']).str.get_dummies()
   a  b  c
0  1  1  0
1  1  0  0
2  1  0  1
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.get_dummies.html, pandas.Series
">>> pd.Series(['a|b', np.nan, 'a|c']).str.get_dummies()
   a  b  c
0  1  1  0
1  0  0  0
2  1  0  1
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.get_dummies.html, pandas.Series
">>> ser = pd.Series([1., 2., np.nan])
>>> ser
0    1.0
1    2.0
2    NaN
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dropna.html, pandas.Series
">>> ser.dropna()
0    1.0
1    2.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dropna.html, pandas.Series.dropna
">>> ser = pd.Series([np.nan, 2, pd.NaT, '', None, 'I stay'])
>>> ser
0       NaN
1         2
2       NaT
3
4      None
5    I stay
dtype: object
>>> ser.dropna()
1         2
3
5    I stay
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dropna.html, pandas.Series pandas.Series.dropna
">>> pd.Series([True]).bool()  
True
>>> pd.Series([False]).bool()  
False
",https://pandas.pydata.org/docs/reference/api/pandas.Series.bool.html, pandas.Series
">>> pd.DataFrame({'col': [True]}).bool()  
True
>>> pd.DataFrame({'col': [False]}).bool()  
False
",https://pandas.pydata.org/docs/reference/api/pandas.Series.bool.html, pandas.DataFrame
">>> pd.Series([True]).item()  
True
>>> pd.Series([False]).item()  
False
",https://pandas.pydata.org/docs/reference/api/pandas.Series.bool.html, pandas.Series
">>> s = pd.Series([1, 2, 3, 4], name='foo',
...               index=pd.Index(['a', 'b', 'c', 'd'], name='idx'))
",https://pandas.pydata.org/docs/reference/api/pandas.Series.reset_index.html, pandas.Series pandas.Index
">>> s.reset_index()
  idx  foo
0   a    1
1   b    2
2   c    3
3   d    4
",https://pandas.pydata.org/docs/reference/api/pandas.Series.reset_index.html, pandas.Series.reset_index
">>> s.reset_index(name='values')
  idx  values
0   a       1
1   b       2
2   c       3
3   d       4
",https://pandas.pydata.org/docs/reference/api/pandas.Series.reset_index.html, pandas.Series.reset_index
">>> s.reset_index(drop=True)
0    1
1    2
2    3
3    4
Name: foo, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.reset_index.html, pandas.Series.reset_index
">>> arrays = [np.array(['bar', 'bar', 'baz', 'baz']),
...           np.array(['one', 'two', 'one', 'two'])]
>>> s2 = pd.Series(
...     range(4), name='foo',
...     index=pd.MultiIndex.from_arrays(arrays,
...                                     names=['a', 'b']))
",https://pandas.pydata.org/docs/reference/api/pandas.Series.reset_index.html, pandas.Series pandas.MultiIndex.from_arrays
">>> s2.reset_index(level='a')
       a  foo
b
one  bar    0
two  bar    1
one  baz    2
two  baz    3
",https://pandas.pydata.org/docs/reference/api/pandas.Series.reset_index.html, pandas.Series.reset_index
">>> s2.reset_index()
     a    b  foo
0  bar  one    0
1  bar  two    1
2  baz  one    2
3  baz  two    3
",https://pandas.pydata.org/docs/reference/api/pandas.Series.reset_index.html, pandas.Series.reset_index
">>> df = pd.DataFrame({'dates': pd.date_range(""2017-03-30"",
...                   periods=4)})
>>> df.assign(quarter=df.dates.dt.quarter,
...           is_quarter_start=df.dates.dt.is_quarter_start)
       dates  quarter  is_quarter_start
0 2017-03-30        1             False
1 2017-03-31        1             False
2 2017-04-01        2              True
3 2017-04-02        2             False
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.is_quarter_start.html, pandas.DataFrame pandas.date_range pandas.DataFrame.assign
">>> idx = pd.date_range('2017-03-30', periods=4)
>>> idx
DatetimeIndex(['2017-03-30', '2017-03-31', '2017-04-01', '2017-04-02'],
              dtype='datetime64[ns]', freq='D')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.is_quarter_start.html, pandas.date_range pandas.DatetimeIndex
">>> idx.is_quarter_start
array([False, False,  True, False])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.is_quarter_start.html, pandas.array
">>> s = pd.Series(['A', 'B', 'Aaba', 'Baca', np.nan, 'CABA', 'cat'])
>>> s.str.count('a')
0    0.0
1    0.0
2    2.0
3    2.0
4    NaN
5    0.0
6    1.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.count.html, pandas.Series pandas.Series.str.count
">>> s = pd.Series(['$', 'B', 'Aab$', '$$ca', 'C$B$', 'cat'])
>>> s.str.count('\\$')
0    1
1    0
2    1
3    2
4    2
5    0
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.count.html, pandas.Series pandas.Series.str.count
">>> pd.Index(['A', 'A', 'Aaba', 'cat']).str.count('a')
Index([0, 0, 2, 1], dtype='int64')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.count.html, pandas.Index pandas.Index
">>> df = pd.DataFrame({'name' : ['User 1', 'User 2', 'User 3']})
>>> df
     name
0  User 1
1  User 2
2  User 3
",https://pandas.pydata.org/docs/reference/api/pandas.Series.to_sql.html, pandas.DataFrame
">>> df.to_sql(name='users', con=engine)
3
>>> from sqlalchemy import text
>>> with engine.connect() as conn:
...    conn.execute(text(""SELECT * FROM users"")).fetchall()
[(0, 'User 1'), (1, 'User 2'), (2, 'User 3')]
",https://pandas.pydata.org/docs/reference/api/pandas.Series.to_sql.html, pandas.DataFrame.to_sql
">>> with engine.begin() as connection:
...     df1 = pd.DataFrame({'name' : ['User 4', 'User 5']})
...     df1.to_sql(name='users', con=connection, if_exists='append')
2
",https://pandas.pydata.org/docs/reference/api/pandas.Series.to_sql.html, pandas.DataFrame pandas.DataFrame.to_sql
">>> df2 = pd.DataFrame({'name' : ['User 6', 'User 7']})
>>> df2.to_sql(name='users', con=engine, if_exists='append')
2
>>> with engine.connect() as conn:
...    conn.execute(text(""SELECT * FROM users"")).fetchall()
[(0, 'User 1'), (1, 'User 2'), (2, 'User 3'),
 (0, 'User 4'), (1, 'User 5'), (0, 'User 6'),
 (1, 'User 7')]
",https://pandas.pydata.org/docs/reference/api/pandas.Series.to_sql.html, pandas.DataFrame pandas.DataFrame.to_sql
">>> df2.to_sql(name='users', con=engine, if_exists='replace',
...            index_label='id')
2
>>> with engine.connect() as conn:
...    conn.execute(text(""SELECT * FROM users"")).fetchall()
[(0, 'User 6'), (1, 'User 7')]
",https://pandas.pydata.org/docs/reference/api/pandas.Series.to_sql.html, pandas.DataFrame.to_sql
">>> df = pd.DataFrame({""A"": [1, None, 2]})
>>> df
     A
0  1.0
1  NaN
2  2.0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.to_sql.html, pandas.DataFrame
">>> from sqlalchemy.types import Integer
>>> df.to_sql(name='integers', con=engine, index=False,
...           dtype={""A"": Integer()})
3
",https://pandas.pydata.org/docs/reference/api/pandas.Series.to_sql.html, pandas.DataFrame.to_sql
">>> df = pd.DataFrame({""y"": [1, 2, 3]},
...                   index=pd.to_datetime([""2000-03-31 00:00:00"",
...                                         ""2000-05-31 00:00:00"",
...                                         ""2000-08-31 00:00:00""]))
>>> df.index.to_period(""M"")
PeriodIndex(['2000-03', '2000-05', '2000-08'],
            dtype='period[M]')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.to_period.html, pandas.DataFrame pandas.to_datetime pandas.PeriodIndex
">>> idx = pd.date_range(""2017-01-01"", periods=2)
>>> idx.to_period()
PeriodIndex(['2017-01-01', '2017-01-02'],
            dtype='period[D]')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.to_period.html, pandas.date_range pandas.PeriodIndex
">>> s = pd.Series([1, 2, 3, 4])
>>> s
0    1
1    2
2    3
3    4
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.add_prefix.html, pandas.Series
">>> s.add_prefix('item_')
item_0    1
item_1    2
item_2    3
item_3    4
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.add_prefix.html, pandas.Series.add_prefix
">>> df = pd.DataFrame({'A': [1, 2, 3, 4], 'B': [3, 4, 5, 6]})
>>> df
   A  B
0  1  3
1  2  4
2  3  5
3  4  6
",https://pandas.pydata.org/docs/reference/api/pandas.Series.add_prefix.html, pandas.DataFrame
">>> df.add_prefix('col_')
     col_A  col_B
0       1       3
1       2       4
2       3       5
3       4       6
",https://pandas.pydata.org/docs/reference/api/pandas.Series.add_prefix.html, pandas.DataFrame.add_prefix
">>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]})
>>> df
     B
0  0.0
1  1.0
2  2.0
3  NaN
4  4.0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.ewm.html, pandas.DataFrame
">>> df.ewm(com=0.5).mean()
          B
0  0.000000
1  0.750000
2  1.615385
3  1.615385
4  3.670213
>>> df.ewm(alpha=2 / 3).mean()
          B
0  0.000000
1  0.750000
2  1.615385
3  1.615385
4  3.670213
",https://pandas.pydata.org/docs/reference/api/pandas.Series.ewm.html, pandas.DataFrame.ewm
">>> df.ewm(com=0.5, adjust=True).mean()
          B
0  0.000000
1  0.750000
2  1.615385
3  1.615385
4  3.670213
>>> df.ewm(com=0.5, adjust=False).mean()
          B
0  0.000000
1  0.666667
2  1.555556
3  1.555556
4  3.650794
",https://pandas.pydata.org/docs/reference/api/pandas.Series.ewm.html, pandas.DataFrame.ewm
">>> df.ewm(com=0.5, ignore_na=True).mean()
          B
0  0.000000
1  0.750000
2  1.615385
3  1.615385
4  3.225000
>>> df.ewm(com=0.5, ignore_na=False).mean()
          B
0  0.000000
1  0.750000
2  1.615385
3  1.615385
4  3.670213
",https://pandas.pydata.org/docs/reference/api/pandas.Series.ewm.html, pandas.DataFrame.ewm
">>> times = ['2020-01-01', '2020-01-03', '2020-01-10', '2020-01-15', '2020-01-17']
>>> df.ewm(halflife='4 days', times=pd.DatetimeIndex(times)).mean()
          B
0  0.000000
1  0.585786
2  1.523889
3  1.523889
4  3.233686
",https://pandas.pydata.org/docs/reference/api/pandas.Series.ewm.html, pandas.DataFrame.ewm pandas.DatetimeIndex
">>> s = pd.Series(['a', 'b', np.nan, 'd'])
>>> s.str.cat(sep=' ')
'a b d'
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.cat.html, pandas.Series pandas.Series.str.cat
">>> s.str.cat(sep=' ', na_rep='?')
'a b ? d'
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.cat.html, pandas.Series.str.cat
">>> s.str.cat(['A', 'B', 'C', 'D'], sep=',')
0    a,A
1    b,B
2    NaN
3    d,D
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.cat.html, pandas.Series.str.cat
">>> s.str.cat(['A', 'B', 'C', 'D'], sep=',', na_rep='-')
0    a,A
1    b,B
2    -,C
3    d,D
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.cat.html, pandas.Series.str.cat
">>> s.str.cat(['A', 'B', 'C', 'D'], na_rep='-')
0    aA
1    bB
2    -C
3    dD
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.cat.html, pandas.Series.str.cat
">>> t = pd.Series(['d', 'a', 'e', 'c'], index=[3, 0, 4, 2])
>>> s.str.cat(t, join='left', na_rep='-')
0    aa
1    b-
2    -c
3    dd
dtype: object
>>>
>>> s.str.cat(t, join='outer', na_rep='-')
0    aa
1    b-
2    -c
3    dd
4    -e
dtype: object
>>>
>>> s.str.cat(t, join='inner', na_rep='-')
0    aa
2    -c
3    dd
dtype: object
>>>
>>> s.str.cat(t, join='right', na_rep='-')
3    dd
0    aa
4    -e
2    -c
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.cat.html, pandas.Series pandas.Series.str.cat
">>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])
>>> a
a    1.0
b    1.0
c    1.0
d    NaN
dtype: float64
>>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])
>>> b
a    1.0
b    NaN
d    1.0
e    NaN
dtype: float64
>>> a.floordiv(b, fill_value=0)
a    1.0
b    inf
c    inf
d    0.0
e    NaN
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.rfloordiv.html, pandas.Series pandas.Series.floordiv
">>> pd.Series([False, False]).any()
False
>>> pd.Series([True, False]).any()
True
>>> pd.Series([], dtype=""float64"").any()
False
>>> pd.Series([np.nan]).any()
False
>>> pd.Series([np.nan]).any(skipna=False)
True
",https://pandas.pydata.org/docs/reference/api/pandas.Series.any.html, pandas.Series
">>> df = pd.DataFrame({""A"": [1, 2], ""B"": [0, 2], ""C"": [0, 0]})
>>> df
   A  B  C
0  1  0  0
1  2  2  0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.any.html, pandas.DataFrame
">>> df.any()
A     True
B     True
C    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.any.html, pandas.DataFrame.any
">>> df = pd.DataFrame({""A"": [True, False], ""B"": [1, 2]})
>>> df
       A  B
0   True  1
1  False  2
",https://pandas.pydata.org/docs/reference/api/pandas.Series.any.html, pandas.DataFrame
">>> df.any(axis='columns')
0    True
1    True
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.any.html, pandas.DataFrame.any
">>> df = pd.DataFrame({""A"": [True, False], ""B"": [1, 0]})
>>> df
       A  B
0   True  1
1  False  0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.any.html, pandas.DataFrame
">>> df.any(axis='columns')
0    True
1    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.any.html, pandas.DataFrame.any
">>> df.any(axis=None)
True
",https://pandas.pydata.org/docs/reference/api/pandas.Series.any.html, pandas.DataFrame.any
">>> pd.DataFrame([]).any()
Series([], dtype: bool)
",https://pandas.pydata.org/docs/reference/api/pandas.Series.any.html, pandas.DataFrame pandas.Series
">>> s = pd.Series(['lower', 'CAPITALS', 'this is a sentence', 'SwApCaSe'])
>>> s
0                 lower
1              CAPITALS
2    this is a sentence
3              SwApCaSe
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.capitalize.html, pandas.Series
">>> s.str.lower()
0                 lower
1              capitals
2    this is a sentence
3              swapcase
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.capitalize.html, pandas.Series.str.lower
">>> s.str.upper()
0                 LOWER
1              CAPITALS
2    THIS IS A SENTENCE
3              SWAPCASE
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.capitalize.html, pandas.Series.str.upper
">>> s.str.title()
0                 Lower
1              Capitals
2    This Is A Sentence
3              Swapcase
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.capitalize.html, pandas.Series.str.title
">>> s.str.capitalize()
0                 Lower
1              Capitals
2    This is a sentence
3              Swapcase
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.capitalize.html, pandas.Series.str.capitalize
">>> s.str.swapcase()
0                 LOWER
1              capitals
2    THIS IS A SENTENCE
3              sWaPcAsE
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.capitalize.html, pandas.Series.str.swapcase
">>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])
>>> a
a    1.0
b    1.0
c    1.0
d    NaN
dtype: float64
>>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])
>>> b
a    1.0
b    NaN
d    1.0
e    NaN
dtype: float64
>>> a.subtract(b, fill_value=0)
a    0.0
b    1.0
c    1.0
d   -1.0
e    NaN
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.sub.html, pandas.Series
">>> df = pd.DataFrame({'person_id': [0, 1, 2, 3],
...                    'age': [21, 25, 62, 43],
...                    'height': [1.61, 1.87, 1.49, 2.01]}
...                   ).set_index('person_id')
>>> df
           age  height
person_id
0           21    1.61
1           25    1.87
2           62    1.49
3           43    2.01
",https://pandas.pydata.org/docs/reference/api/pandas.Series.std.html, pandas.DataFrame pandas.DataFrame.set_index
">>> df.std()
age       18.786076
height     0.237417
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.std.html, pandas.DataFrame.std
">>> df.std(ddof=0)
age       16.269219
height     0.205609
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.std.html, pandas.DataFrame.std
">>> s = pd.Series(['a', 'b', 'c'])
>>> s
0    a
1    b
2    c
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.repeat.html, pandas.Series
">>> s.str.repeat(repeats=2)
0    aa
1    bb
2    cc
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.repeat.html, pandas.Series.str.repeat
">>> s.str.repeat(repeats=[1, 2, 3])
0      a
1     bb
2    ccc
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.repeat.html, pandas.Series.str.repeat
">>> s = pd.Series(pd.to_timedelta(np.arange(5), unit='d'))
>>> s
0   0 days
1   1 days
2   2 days
3   3 days
4   4 days
dtype: timedelta64[ns]
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.total_seconds.html, pandas.Series pandas.to_timedelta
">>> s.dt.total_seconds()
0         0.0
1     86400.0
2    172800.0
3    259200.0
4    345600.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.total_seconds.html, pandas.Series.dt.total_seconds
">>> idx = pd.to_timedelta(np.arange(5), unit='d')
>>> idx
TimedeltaIndex(['0 days', '1 days', '2 days', '3 days', '4 days'],
               dtype='timedelta64[ns]', freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.total_seconds.html, pandas.to_timedelta pandas.TimedeltaIndex
">>> idx.total_seconds()
Index([0.0, 86400.0, 172800.0, 259200.0, 345600.0], dtype='float64')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.total_seconds.html, pandas.Index
">>> s = pd.Series([1, 1, 2, 3, 5, 8])
>>> s.diff()
0    NaN
1    0.0
2    1.0
3    1.0
4    2.0
5    3.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.diff.html, pandas.Series pandas.Series.diff
">>> s.diff(periods=3)
0    NaN
1    NaN
2    NaN
3    2.0
4    4.0
5    6.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.diff.html, pandas.Series.diff
">>> s.diff(periods=-1)
0    0.0
1   -1.0
2   -1.0
3   -2.0
4   -3.0
5    NaN
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.diff.html, pandas.Series.diff
">>> s = pd.Series([1, 0], dtype=np.uint8)
>>> s.diff()
0      NaN
1    255.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.diff.html, pandas.Series pandas.Series.diff
">>> s = pd.date_range('2016-12-31', '2017-01-08', freq='D').to_series()
>>> s.dt.dayofweek
2016-12-31    5
2017-01-01    6
2017-01-02    0
2017-01-03    1
2017-01-04    2
2017-01-05    3
2017-01-06    4
2017-01-07    5
2017-01-08    6
Freq: D, dtype: int32
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.weekday.html, pandas.date_range
">>> d = {'col1': [1, 2], 'col2': [3, 4]}
>>> df = pd.DataFrame(data=d)
>>> df.dtypes
col1    int64
col2    int64
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.astype.html, pandas.DataFrame
">>> df.astype('int32').dtypes
col1    int32
col2    int32
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.astype.html, pandas.DataFrame.astype
">>> df.astype({'col1': 'int32'}).dtypes
col1    int32
col2    int64
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.astype.html, pandas.DataFrame.astype
">>> ser = pd.Series([1, 2], dtype='int32')
>>> ser
0    1
1    2
dtype: int32
>>> ser.astype('int64')
0    1
1    2
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.astype.html, pandas.Series pandas.Series.astype
">>> ser.astype('category')
0    1
1    2
dtype: category
Categories (2, int32): [1, 2]
",https://pandas.pydata.org/docs/reference/api/pandas.Series.astype.html, pandas.Series.astype
">>> from pandas.api.types import CategoricalDtype
>>> cat_dtype = CategoricalDtype(
...     categories=[2, 1], ordered=True)
>>> ser.astype(cat_dtype)
0    1
1    2
dtype: category
Categories (2, int64): [2 < 1]
",https://pandas.pydata.org/docs/reference/api/pandas.Series.astype.html, pandas.CategoricalDtype pandas.Series.astype
">>> ser_date = pd.Series(pd.date_range('20200101', periods=3))
>>> ser_date
0   2020-01-01
1   2020-01-02
2   2020-01-03
dtype: datetime64[ns]
",https://pandas.pydata.org/docs/reference/api/pandas.Series.astype.html, pandas.Series pandas.date_range
">>> cities = ['Kolkata', 'Chicago', 'Toronto', 'Lisbon']
>>> populations = [14.85, 2.71, 2.93, 0.51]
>>> city_series = pd.Series(populations, index=cities)
>>> city_series.index
Index(['Kolkata', 'Chicago', 'Toronto', 'Lisbon'], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.index.html, pandas.Series pandas.Index
">>> city_series.index = ['KOL', 'CHI', 'TOR', 'LIS']
>>> city_series.index
Index(['KOL', 'CHI', 'TOR', 'LIS'], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.index.html, pandas.Index
">>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])
>>> a
a    1.0
b    1.0
c    1.0
d    NaN
dtype: float64
>>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])
>>> b
a    1.0
b    NaN
d    1.0
e    NaN
dtype: float64
>>> a.eq(b, fill_value=0)
a     True
b    False
c    False
d    False
e    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.eq.html, pandas.Series pandas.Series.eq
">>> s = pd.Series([2, 0, 4, 8, np.nan])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.between.html, pandas.Series
">>> s.between(1, 4)
0     True
1    False
2     True
3    False
4    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.between.html, pandas.Series.between
">>> s.between(1, 4, inclusive=""neither"")
0     True
1    False
2    False
3    False
4    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.between.html, pandas.Series.between
">>> s = pd.Series(['Alice', 'Bob', 'Carol', 'Eve'])
>>> s.between('Anna', 'Daniel')
0    False
1     True
2     True
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.between.html, pandas.Series pandas.Series.between
">>> ser = pd.Series([b'cow', b'123', b'()'])
>>> ser.str.decode('ascii')
0   cow
1   123
2   ()
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.decode.html, pandas.Series pandas.Series.str.decode
">>> datetime_series = pd.Series(
...     pd.date_range(""2000-01-01"", periods=3, freq=""s"")
... )
>>> datetime_series
0   2000-01-01 00:00:00
1   2000-01-01 00:00:01
2   2000-01-01 00:00:02
dtype: datetime64[ns]
>>> datetime_series.dt.second
0    0
1    1
2    2
dtype: int32
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.second.html, pandas.Series pandas.date_range
">>> s = pd.Series(['a', 'b', 'c', 'd'], index=[3, 2, 1, 4])
>>> s.sort_index()
1    c
2    b
3    a
4    d
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.sort_index.html, pandas.Series pandas.Series.sort_index
">>> s.sort_index(ascending=False)
4    d
3    a
2    b
1    c
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.sort_index.html, pandas.Series.sort_index
">>> s = pd.Series(['a', 'b', 'c', 'd'], index=[3, 2, 1, np.nan])
>>> s.sort_index(na_position='first')
NaN     d
 1.0    c
 2.0    b
 3.0    a
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.sort_index.html, pandas.Series pandas.Series.sort_index
">>> arrays = [np.array(['qux', 'qux', 'foo', 'foo',
...                     'baz', 'baz', 'bar', 'bar']),
...           np.array(['two', 'one', 'two', 'one',
...                     'two', 'one', 'two', 'one'])]
>>> s = pd.Series([1, 2, 3, 4, 5, 6, 7, 8], index=arrays)
>>> s.sort_index(level=1)
bar  one    8
baz  one    6
foo  one    4
qux  one    2
bar  two    7
baz  two    5
foo  two    3
qux  two    1
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.sort_index.html, pandas.Series pandas.Series.sort_index
">>> s.sort_index(level=1, sort_remaining=False)
qux  one    2
foo  one    4
baz  one    6
bar  one    8
qux  two    1
foo  two    3
baz  two    5
bar  two    7
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.sort_index.html, pandas.Series.sort_index
">>> s = pd.Series([1, 2, 3, 4], index=['A', 'b', 'C', 'd'])
>>> s.sort_index(key=lambda x : x.str.lower())
A    1
b    2
C    3
d    4
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.sort_index.html, pandas.Series pandas.Series.sort_index pandas.Series.str.lower
">>> rng = pd.date_range(pd.Timestamp(""2018-03-10 09:00""),
...                     periods=3, freq='s')
>>> rng.strftime('%B %d, %Y, %r')
Index(['March 10, 2018, 09:00:00 AM', 'March 10, 2018, 09:00:01 AM',
       'March 10, 2018, 09:00:02 AM'],
      dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.strftime.html, pandas.date_range pandas.Index
">>> s = pd.Series([1, 2, 2, 3], index=['cat', 'dog', 'dog', 'mouse'])
>>> s
cat    1
dog    2
dog    2
mouse  3
dtype: int64
>>> s.kurt()
1.5
",https://pandas.pydata.org/docs/reference/api/pandas.Series.kurt.html, pandas.Series pandas.Series.kurt
">>> df = pd.DataFrame({'a': [1, 2, 2, 3], 'b': [3, 4, 4, 4]},
...                   index=['cat', 'dog', 'dog', 'mouse'])
>>> df
       a   b
  cat  1   3
  dog  2   4
  dog  2   4
mouse  3   4
>>> df.kurt()
a   1.5
b   4.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.kurt.html, pandas.DataFrame pandas.DataFrame.kurt
">>> df.kurt(axis=None).round(6)
-0.988693
",https://pandas.pydata.org/docs/reference/api/pandas.Series.kurt.html, pandas.DataFrame.kurt
">>> df = pd.DataFrame({'a': [1, 2], 'b': [3, 4], 'c': [3, 4], 'd': [1, 2]},
...                   index=['cat', 'dog'])
>>> df.kurt(axis=1)
cat   -6.0
dog   -6.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.kurt.html, pandas.DataFrame pandas.DataFrame.kurt
">>> datetime_series = pd.Series(
...     pd.date_range(""2000-01-01"", periods=3, freq=""ns"")
... )
>>> datetime_series
0   2000-01-01 00:00:00.000000000
1   2000-01-01 00:00:00.000000001
2   2000-01-01 00:00:00.000000002
dtype: datetime64[ns]
>>> datetime_series.dt.nanosecond
0       0
1       1
2       2
dtype: int32
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.nanosecond.html, pandas.Series pandas.date_range
">>> rng = pd.date_range('1/1/2018 11:59:00', periods=3, freq='min')
>>> rng
DatetimeIndex(['2018-01-01 11:59:00', '2018-01-01 12:00:00',
               '2018-01-01 12:01:00'],
              dtype='datetime64[ns]', freq='min')
>>> rng.round('h')
DatetimeIndex(['2018-01-01 12:00:00', '2018-01-01 12:00:00',
               '2018-01-01 12:00:00'],
              dtype='datetime64[ns]', freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.round.html, pandas.date_range pandas.DatetimeIndex
">>> pd.Series(rng).dt.round(""h"")
0   2018-01-01 12:00:00
1   2018-01-01 12:00:00
2   2018-01-01 12:00:00
dtype: datetime64[ns]
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.round.html, pandas.Series
">>> rng_tz = pd.DatetimeIndex([""2021-10-31 03:30:00""], tz=""Europe/Amsterdam"")
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.round.html, pandas.DatetimeIndex
">>> rng_tz.floor(""2h"", ambiguous=False)
DatetimeIndex(['2021-10-31 02:00:00+01:00'],
              dtype='datetime64[ns, Europe/Amsterdam]', freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.round.html, pandas.DatetimeIndex.floor pandas.DatetimeIndex
">>> rng_tz.floor(""2h"", ambiguous=True)
DatetimeIndex(['2021-10-31 02:00:00+02:00'],
              dtype='datetime64[ns, Europe/Amsterdam]', freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.round.html, pandas.DatetimeIndex.floor pandas.DatetimeIndex
">>> i = pd.date_range('2018-04-09', periods=4, freq='12h')
>>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)
>>> ts
                     A
2018-04-09 00:00:00  1
2018-04-09 12:00:00  2
2018-04-10 00:00:00  3
2018-04-10 12:00:00  4
",https://pandas.pydata.org/docs/reference/api/pandas.Series.at_time.html, pandas.date_range pandas.DataFrame
">>> ts.at_time('12:00')
                     A
2018-04-09 12:00:00  2
2018-04-10 12:00:00  4
",https://pandas.pydata.org/docs/reference/api/pandas.Series.at_time.html, pandas.DataFrame.at_time
">>> raw_cate = pd.Categorical([""a"", ""b"", ""c"", ""a""], categories=[""a"", ""b""])
>>> ser = pd.Series(raw_cate)
>>> ser.cat.codes
0   0
1   1
2  -1
3   0
dtype: int8
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.codes.html, pandas.Categorical pandas.Series
">>> raw_cat = pd.Categorical(['a', 'b', 'c', 'a'], ordered=True)
>>> ser = pd.Series(raw_cat)
>>> ser.cat.ordered
True
>>> ser = ser.cat.as_unordered()
>>> ser.cat.ordered
False
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.as_unordered.html, pandas.Categorical pandas.Series pandas.Series.cat.as_unordered
">>> ci = pd.CategoricalIndex(['a', 'b', 'c', 'a'], ordered=True)
>>> ci.ordered
True
>>> ci = ci.as_unordered()
>>> ci.ordered
False
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.as_unordered.html, pandas.CategoricalIndex pandas.CategoricalIndex.as_unordered
">>> df = pd.DataFrame({'lab': ['A', 'B', 'C'], 'val': [10, 30, 20]})
>>> ax = df.plot.barh(x='lab', y='val')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.barh.html, pandas.DataFrame pandas.DataFrame.plot.barh
">>> speed = [0.1, 17.5, 40, 48, 52, 69, 88]
>>> lifespan = [2, 8, 70, 1.5, 25, 12, 28]
>>> index = ['snail', 'pig', 'elephant',
...          'rabbit', 'giraffe', 'coyote', 'horse']
>>> df = pd.DataFrame({'speed': speed,
...                    'lifespan': lifespan}, index=index)
>>> ax = df.plot.barh()
",https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.barh.html, pandas.DataFrame pandas.DataFrame.plot.barh
">>> ax = df.plot.barh(stacked=True)
",https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.barh.html, pandas.DataFrame.plot.barh
">>> ax = df.plot.barh(color={""speed"": ""red"", ""lifespan"": ""green""})
",https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.barh.html, pandas.DataFrame.plot.barh
">>> speed = [0.1, 17.5, 40, 48, 52, 69, 88]
>>> lifespan = [2, 8, 70, 1.5, 25, 12, 28]
>>> index = ['snail', 'pig', 'elephant',
...          'rabbit', 'giraffe', 'coyote', 'horse']
>>> df = pd.DataFrame({'speed': speed,
...                    'lifespan': lifespan}, index=index)
>>> ax = df.plot.barh(y='speed')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.barh.html, pandas.DataFrame pandas.DataFrame.plot.barh
">>> speed = [0.1, 17.5, 40, 48, 52, 69, 88]
>>> lifespan = [2, 8, 70, 1.5, 25, 12, 28]
>>> index = ['snail', 'pig', 'elephant',
...          'rabbit', 'giraffe', 'coyote', 'horse']
>>> df = pd.DataFrame({'speed': speed,
...                    'lifespan': lifespan}, index=index)
>>> ax = df.plot.barh(x='lifespan')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.barh.html, pandas.DataFrame pandas.DataFrame.plot.barh
">>> s = pd.Series([3, 2, 2, 1])
>>> s.is_monotonic_decreasing
True
",https://pandas.pydata.org/docs/reference/api/pandas.Series.is_monotonic_decreasing.html, pandas.Series
">>> s = pd.Series([1, 2, 3])
>>> s.is_monotonic_decreasing
False
",https://pandas.pydata.org/docs/reference/api/pandas.Series.is_monotonic_decreasing.html, pandas.Series
">>> seconds_series = pd.Series(pd.date_range(""2000-01-01"", periods=3, freq=""s""))
>>> seconds_series
0   2000-01-01 00:00:00
1   2000-01-01 00:00:01
2   2000-01-01 00:00:02
dtype: datetime64[ns]
>>> seconds_series.dt.second
0    0
1    1
2    2
dtype: int32
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.html, pandas.Series pandas.date_range
">>> hours_series = pd.Series(pd.date_range(""2000-01-01"", periods=3, freq=""h""))
>>> hours_series
0   2000-01-01 00:00:00
1   2000-01-01 01:00:00
2   2000-01-01 02:00:00
dtype: datetime64[ns]
>>> hours_series.dt.hour
0    0
1    1
2    2
dtype: int32
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.html, pandas.Series pandas.date_range
">>> quarters_series = pd.Series(pd.date_range(""2000-01-01"", periods=3, freq=""QE""))
>>> quarters_series
0   2000-03-31
1   2000-06-30
2   2000-09-30
dtype: datetime64[ns]
>>> quarters_series.dt.quarter
0    1
1    2
2    3
dtype: int32
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.html, pandas.Series pandas.date_range
">>> c = pd.Categorical(['a', 'c', 'b', 'c', 'd'])
>>> c
['a', 'c', 'b', 'c', 'd']
Categories (4, object): ['a', 'b', 'c', 'd']
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.remove_categories.html, pandas.Categorical
">>> s = pd.Series([3, 2, 1])
>>> s.argsort()
0    2
1    1
2    0
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.argsort.html, pandas.Series pandas.Series.argsort
">>> s = pd.Series([1, 2, 3], dtype=np.int64, name='Numbers')
>>> s
0    1
1    2
2    3
Name: Numbers, dtype: int64
>>> s.name = ""Integers""
>>> s
0    1
1    2
2    3
Name: Integers, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.name.html, pandas.Series
">>> df = pd.DataFrame([[1, 2], [3, 4], [5, 6]],
...                   columns=[""Odd Numbers"", ""Even Numbers""])
>>> df
   Odd Numbers  Even Numbers
0            1             2
1            3             4
2            5             6
>>> df[""Even Numbers""].name
'Even Numbers'
",https://pandas.pydata.org/docs/reference/api/pandas.Series.name.html, pandas.DataFrame
">>> s = pd.Series([90, 91, 85])
>>> s
0    90
1    91
2    85
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.pct_change.html, pandas.Series
">>> s.pct_change()
0         NaN
1    0.011111
2   -0.065934
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.pct_change.html, pandas.Series.pct_change
">>> s.pct_change(periods=2)
0         NaN
1         NaN
2   -0.055556
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.pct_change.html, pandas.Series.pct_change
">>> s = pd.Series([90, 91, None, 85])
>>> s
0    90.0
1    91.0
2     NaN
3    85.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.pct_change.html, pandas.Series
">>> s.ffill().pct_change()
0         NaN
1    0.011111
2    0.000000
3   -0.065934
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.pct_change.html, pandas.Series.ffill
">>> df = pd.DataFrame({
...     'FR': [4.0405, 4.0963, 4.3149],
...     'GR': [1.7246, 1.7482, 1.8519],
...     'IT': [804.74, 810.01, 860.13]},
...     index=['1980-01-01', '1980-02-01', '1980-03-01'])
>>> df
                FR      GR      IT
1980-01-01  4.0405  1.7246  804.74
1980-02-01  4.0963  1.7482  810.01
1980-03-01  4.3149  1.8519  860.13
",https://pandas.pydata.org/docs/reference/api/pandas.Series.pct_change.html, pandas.DataFrame
">>> df.pct_change()
                  FR        GR        IT
1980-01-01       NaN       NaN       NaN
1980-02-01  0.013810  0.013684  0.006549
1980-03-01  0.053365  0.059318  0.061876
",https://pandas.pydata.org/docs/reference/api/pandas.Series.pct_change.html, pandas.DataFrame.pct_change
">>> df = pd.DataFrame({
...     '2016': [1769950, 30586265],
...     '2015': [1500923, 40912316],
...     '2014': [1371819, 41403351]},
...     index=['GOOG', 'APPL'])
>>> df
          2016      2015      2014
GOOG   1769950   1500923   1371819
APPL  30586265  40912316  41403351
",https://pandas.pydata.org/docs/reference/api/pandas.Series.pct_change.html, pandas.DataFrame
">>> df.pct_change(axis='columns', periods=-1)
          2016      2015  2014
GOOG  0.179241  0.094112   NaN
APPL -0.252395 -0.011860   NaN
",https://pandas.pydata.org/docs/reference/api/pandas.Series.pct_change.html, pandas.DataFrame.pct_change
">>> i = pd.date_range('2018-04-09', periods=4, freq='2D')
>>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)
>>> ts
            A
2018-04-09  1
2018-04-11  2
2018-04-13  3
2018-04-15  4
",https://pandas.pydata.org/docs/reference/api/pandas.Series.last.html, pandas.date_range pandas.DataFrame
">>> ts.last('3D')  
            A
2018-04-13  3
2018-04-15  4
",https://pandas.pydata.org/docs/reference/api/pandas.Series.last.html, pandas.DataFrame.last
">>> import pyarrow as pa
>>> s = pd.Series(
...     [
...         [1, 2, 3],
...         [3],
...     ],
...     dtype=pd.ArrowDtype(pa.list_(
...         pa.int64()
...     ))
... )
>>> s.list.len()
0    3
1    1
dtype: int32[pyarrow]
",https://pandas.pydata.org/docs/reference/api/pandas.Series.list.len.html, pandas.Series pandas.ArrowDtype pandas.Series.list.len
">>> s = pd.Series([['lion', 'elephant', 'zebra'],
...                [1.1, 2.2, 3.3],
...                ['cat', np.nan, 'dog'],
...                ['cow', 4.5, 'goat'],
...                ['duck', ['swan', 'fish'], 'guppy']])
>>> s
0        [lion, elephant, zebra]
1                [1.1, 2.2, 3.3]
2                [cat, nan, dog]
3               [cow, 4.5, goat]
4    [duck, [swan, fish], guppy]
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.join.html, pandas.Series
">>> s.str.join('-')
0    lion-elephant-zebra
1                    NaN
2                    NaN
3                    NaN
4                    NaN
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.join.html, pandas.Series.str.join
">>> ser = pd.Series([1, 2, 3])
>>> np.asarray(ser)
array([1, 2, 3])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.__array__.html, pandas.Series pandas.array
">>> tzser = pd.Series(pd.date_range('2000', periods=2, tz=""CET""))
>>> np.asarray(tzser, dtype=""object"")
array([Timestamp('2000-01-01 00:00:00+0100', tz='CET'),
       Timestamp('2000-01-02 00:00:00+0100', tz='CET')],
      dtype=object)
",https://pandas.pydata.org/docs/reference/api/pandas.Series.__array__.html, pandas.Series pandas.date_range pandas.array
">>> np.asarray(tzser, dtype=""datetime64[ns]"")  
array(['1999-12-31T23:00:00.000000000', ...],
      dtype='datetime64[ns]')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.__array__.html, pandas.array
">>> idx = pd.MultiIndex.from_arrays([
...     ['warm', 'warm', 'cold', 'cold'],
...     ['dog', 'falcon', 'fish', 'spider']],
...     names=['blooded', 'animal'])
>>> s = pd.Series([4, 2, 0, 8], name='legs', index=idx)
>>> s
blooded  animal
warm     dog       4
         falcon    2
cold     fish      0
         spider    8
Name: legs, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.sum.html, pandas.MultiIndex.from_arrays pandas.Series
">>> s.sum()
14
",https://pandas.pydata.org/docs/reference/api/pandas.Series.sum.html, pandas.Series.sum
">>> pd.Series([], dtype=""float64"").sum()  # min_count=0 is the default
0.0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.sum.html, pandas.Series
">>> pd.Series([], dtype=""float64"").sum(min_count=1)
nan
",https://pandas.pydata.org/docs/reference/api/pandas.Series.sum.html, pandas.Series
">>> pd.Series([np.nan]).sum()
0.0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.sum.html, pandas.Series
">>> pd.Series([np.nan]).sum(min_count=1)
nan
",https://pandas.pydata.org/docs/reference/api/pandas.Series.sum.html, pandas.Series
">>> s = pd.Series([None, 3, 4])
>>> s.first_valid_index()
1
>>> s.last_valid_index()
2
",https://pandas.pydata.org/docs/reference/api/pandas.Series.first_valid_index.html, pandas.Series pandas.Series.first_valid_index pandas.Series.last_valid_index
">>> s = pd.Series([None, None])
>>> print(s.first_valid_index())
None
>>> print(s.last_valid_index())
None
",https://pandas.pydata.org/docs/reference/api/pandas.Series.first_valid_index.html, pandas.Series pandas.Series.first_valid_index pandas.Series.last_valid_index
">>> s = pd.Series()
>>> print(s.first_valid_index())
None
>>> print(s.last_valid_index())
None
",https://pandas.pydata.org/docs/reference/api/pandas.Series.first_valid_index.html, pandas.Series pandas.Series.first_valid_index pandas.Series.last_valid_index
">>> df = pd.DataFrame({'A': [None, None, 2], 'B': [None, 3, 4]})
>>> df
     A      B
0  NaN    NaN
1  NaN    3.0
2  2.0    4.0
>>> df.first_valid_index()
1
>>> df.last_valid_index()
2
",https://pandas.pydata.org/docs/reference/api/pandas.Series.first_valid_index.html, pandas.DataFrame pandas.DataFrame.first_valid_index pandas.DataFrame.last_valid_index
">>> df = pd.DataFrame({'A': [None, None, None], 'B': [None, None, None]})
>>> df
     A      B
0  None   None
1  None   None
2  None   None
>>> print(df.first_valid_index())
None
>>> print(df.last_valid_index())
None
",https://pandas.pydata.org/docs/reference/api/pandas.Series.first_valid_index.html, pandas.DataFrame pandas.DataFrame.first_valid_index pandas.DataFrame.last_valid_index
">>> df = pd.DataFrame()
>>> df
Empty DataFrame
Columns: []
Index: []
>>> print(df.first_valid_index())
None
>>> print(df.last_valid_index())
None
",https://pandas.pydata.org/docs/reference/api/pandas.Series.first_valid_index.html, pandas.DataFrame pandas.DataFrame.first_valid_index pandas.DataFrame.last_valid_index
">>> s = pd.Series(pd.date_range(start='2018-01-01', freq='D', periods=3))
>>> s
0   2018-01-01
1   2018-01-02
2   2018-01-03
dtype: datetime64[ns]
>>> s.dt.day_name()
0       Monday
1      Tuesday
2    Wednesday
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.day_name.html, pandas.Series pandas.date_range pandas.Series.dt.day_name
">>> idx = pd.date_range(start='2018-01-01', freq='D', periods=3)
>>> idx
DatetimeIndex(['2018-01-01', '2018-01-02', '2018-01-03'],
              dtype='datetime64[ns]', freq='D')
>>> idx.day_name()
Index(['Monday', 'Tuesday', 'Wednesday'], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.day_name.html, pandas.date_range pandas.DatetimeIndex pandas.Index
">>> idx = pd.date_range(start='2018-01-01', freq='D', periods=3)
>>> idx
DatetimeIndex(['2018-01-01', '2018-01-02', '2018-01-03'],
              dtype='datetime64[ns]', freq='D')
>>> idx.day_name(locale='pt_BR.utf8') 
Index(['Segunda', 'Terça', 'Quarta'], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.day_name.html, pandas.date_range pandas.DatetimeIndex pandas.Index
">>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])
>>> a
a    1.0
b    1.0
c    1.0
d    NaN
dtype: float64
>>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])
>>> b
a    1.0
b    NaN
d    1.0
e    NaN
dtype: float64
>>> a.pow(b, fill_value=0)
a    1.0
b    1.0
c    1.0
d    0.0
e    NaN
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.pow.html, pandas.Series pandas.Series.pow
">>> s = pd.Series(['A', 'B', 'C'])
>>> for index, value in s.items():
...     print(f""Index : {index}, Value : {value}"")
Index : 0, Value : A
Index : 1, Value : B
Index : 2, Value : C
",https://pandas.pydata.org/docs/reference/api/pandas.Series.items.html, pandas.Series pandas.Series.items
">>> df = pd.DataFrame({'person_id': [0, 1, 2, 3],
...                    'age': [21, 25, 62, 43],
...                    'height': [1.61, 1.87, 1.49, 2.01]}
...                   ).set_index('person_id')
>>> df
           age  height
person_id
0           21    1.61
1           25    1.87
2           62    1.49
3           43    2.01
",https://pandas.pydata.org/docs/reference/api/pandas.Series.var.html, pandas.DataFrame pandas.DataFrame.set_index
">>> df.var()
age       352.916667
height      0.056367
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.var.html, pandas.DataFrame.var
">>> df.var(ddof=0)
age       264.687500
height      0.042275
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.var.html, pandas.DataFrame.var
">>> s = pd.Series(data=[1, None, 4, 3, 4],
...               index=['A', 'B', 'C', 'D', 'E'])
>>> s
A    1.0
B    NaN
C    4.0
D    3.0
E    4.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.idxmax.html, pandas.Series
">>> s.idxmax()
'C'
",https://pandas.pydata.org/docs/reference/api/pandas.Series.idxmax.html, pandas.Series.idxmax
">>> s.idxmax(skipna=False)
nan
",https://pandas.pydata.org/docs/reference/api/pandas.Series.idxmax.html, pandas.Series.idxmax
">>> s = pd.Series(
...     [1],
...     index=pd.DatetimeIndex(['2018-09-15 01:30:00+02:00']),
... )
>>> s.tz_convert('Asia/Shanghai')
2018-09-15 07:30:00+08:00    1
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.tz_convert.html, pandas.Series pandas.DatetimeIndex pandas.Series.tz_convert
">>> s = pd.Series([1],
...               index=pd.DatetimeIndex(['2018-09-15 01:30:00+02:00']))
>>> s.tz_convert(None)
2018-09-14 23:30:00    1
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.tz_convert.html, pandas.Series pandas.DatetimeIndex pandas.Series.tz_convert
">>> s = pd.Series(['1. Ant.  ', '2. Bee!\n', '3. Cat?\t', np.nan, 10, True])
>>> s
0    1. Ant.
1    2. Bee!\n
2    3. Cat?\t
3          NaN
4           10
5         True
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.lstrip.html, pandas.Series
">>> s.str.strip()
0    1. Ant.
1    2. Bee!
2    3. Cat?
3        NaN
4        NaN
5        NaN
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.lstrip.html, pandas.Series.str.strip
">>> s.str.lstrip('123.')
0    Ant.
1    Bee!\n
2    Cat?\t
3       NaN
4       NaN
5       NaN
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.lstrip.html, pandas.Series.str.lstrip
">>> s.str.rstrip('.!? \n\t')
0    1. Ant
1    2. Bee
2    3. Cat
3       NaN
4       NaN
5       NaN
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.lstrip.html, pandas.Series.str.rstrip
">>> s.str.strip('123.!? \n\t')
0    Ant
1    Bee
2    Cat
3    NaN
4    NaN
5    NaN
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.lstrip.html, pandas.Series.str.strip
">>> s = pd.Series([1, 2, 3, 4])
>>> s
0    1
1    2
2    3
3    4
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.aggregate.html, pandas.Series
">>> s.agg('min')
1
",https://pandas.pydata.org/docs/reference/api/pandas.Series.aggregate.html, pandas.Series.agg
">>> s.agg(['min', 'max'])
min   1
max   4
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.aggregate.html, pandas.Series.agg
">>> s = pd.Series([1, 2, 2, 3], index=['cat', 'dog', 'dog', 'mouse'])
>>> s
cat    1
dog    2
dog    2
mouse  3
dtype: int64
>>> s.kurt()
1.5
",https://pandas.pydata.org/docs/reference/api/pandas.Series.kurtosis.html, pandas.Series pandas.Series.kurt
">>> df = pd.DataFrame({'a': [1, 2, 2, 3], 'b': [3, 4, 4, 4]},
...                   index=['cat', 'dog', 'dog', 'mouse'])
>>> df
       a   b
  cat  1   3
  dog  2   4
  dog  2   4
mouse  3   4
>>> df.kurt()
a   1.5
b   4.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.kurtosis.html, pandas.DataFrame pandas.DataFrame.kurt
">>> df.kurt(axis=None).round(6)
-0.988693
",https://pandas.pydata.org/docs/reference/api/pandas.Series.kurtosis.html, pandas.DataFrame.kurt
">>> df = pd.DataFrame({'a': [1, 2], 'b': [3, 4], 'c': [3, 4], 'd': [1, 2]},
...                   index=['cat', 'dog'])
>>> df.kurt(axis=1)
cat   -6.0
dog   -6.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.kurtosis.html, pandas.DataFrame pandas.DataFrame.kurt
">>> index = pd.date_range('1/1/2000', periods=4, freq='min')
>>> series = pd.Series([0.0, None, 2.0, 3.0], index=index)
>>> df = pd.DataFrame({'s': series})
>>> df
                       s
2000-01-01 00:00:00    0.0
2000-01-01 00:01:00    NaN
2000-01-01 00:02:00    2.0
2000-01-01 00:03:00    3.0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.asfreq.html, pandas.date_range pandas.Series pandas.DataFrame
">>> df.asfreq(freq='30s')
                       s
2000-01-01 00:00:00    0.0
2000-01-01 00:00:30    NaN
2000-01-01 00:01:00    NaN
2000-01-01 00:01:30    NaN
2000-01-01 00:02:00    2.0
2000-01-01 00:02:30    NaN
2000-01-01 00:03:00    3.0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.asfreq.html, pandas.DataFrame.asfreq
">>> df.asfreq(freq='30s', fill_value=9.0)
                       s
2000-01-01 00:00:00    0.0
2000-01-01 00:00:30    9.0
2000-01-01 00:01:00    NaN
2000-01-01 00:01:30    9.0
2000-01-01 00:02:00    2.0
2000-01-01 00:02:30    9.0
2000-01-01 00:03:00    3.0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.asfreq.html, pandas.DataFrame.asfreq
">>> df.asfreq(freq='30s', method='bfill')
                       s
2000-01-01 00:00:00    0.0
2000-01-01 00:00:30    NaN
2000-01-01 00:01:00    NaN
2000-01-01 00:01:30    2.0
2000-01-01 00:02:00    2.0
2000-01-01 00:02:30    3.0
2000-01-01 00:03:00    3.0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.asfreq.html, pandas.DataFrame.asfreq
">>> s = pd.Series(['1. Ant.  ', '2. Bee!\n', '3. Cat?\t', np.nan, 10, True])
>>> s
0    1. Ant.
1    2. Bee!\n
2    3. Cat?\t
3          NaN
4           10
5         True
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.strip.html, pandas.Series
">>> s.str.strip()
0    1. Ant.
1    2. Bee!
2    3. Cat?
3        NaN
4        NaN
5        NaN
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.strip.html, pandas.Series.str.strip
">>> s.str.lstrip('123.')
0    Ant.
1    Bee!\n
2    Cat?\t
3       NaN
4       NaN
5       NaN
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.strip.html, pandas.Series.str.lstrip
">>> s.str.rstrip('.!? \n\t')
0    1. Ant
1    2. Bee
2    3. Cat
3       NaN
4       NaN
5       NaN
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.strip.html, pandas.Series.str.rstrip
">>> s.str.strip('123.!? \n\t')
0    Ant
1    Bee
2    Cat
3    NaN
4    NaN
5    NaN
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.strip.html, pandas.Series.str.strip
">>> s = pd.Series([""str_foo"", ""str_bar"", ""no_prefix""])
>>> s
0    str_foo
1    str_bar
2    no_prefix
dtype: object
>>> s.str.removeprefix(""str_"")
0    foo
1    bar
2    no_prefix
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.removesuffix.html, pandas.Series pandas.Series.str.removeprefix
">>> s = pd.Series([""foo_str"", ""bar_str"", ""no_suffix""])
>>> s
0    foo_str
1    bar_str
2    no_suffix
dtype: object
>>> s.str.removesuffix(""_str"")
0    foo
1    bar
2    no_suffix
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.removesuffix.html, pandas.Series pandas.Series.str.removesuffix
">>> import pyarrow as pa
>>> s = pd.Series(
...     [
...         [1, 2, 3],
...         [3],
...     ],
...     dtype=pd.ArrowDtype(pa.list_(
...         pa.int64()
...     ))
... )
>>> s.list.flatten()
0    1
1    2
2    3
3    3
dtype: int64[pyarrow]
",https://pandas.pydata.org/docs/reference/api/pandas.Series.list.flatten.html, pandas.Series pandas.ArrowDtype pandas.Series.list.flatten
">>> s = pd.Series([1, 2, 3, None])
>>> s
0    1.0
1    2.0
2    3.0
3    NaN
dtype: float64
>>> s.hasnans
True
",https://pandas.pydata.org/docs/reference/api/pandas.Series.hasnans.html, pandas.Series
">>> s = pd.Series(pd.date_range(start='2018-01', freq='ME', periods=3))
>>> s
0   2018-01-31
1   2018-02-28
2   2018-03-31
dtype: datetime64[ns]
>>> s.dt.month_name()
0     January
1    February
2       March
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.month_name.html, pandas.Series pandas.date_range pandas.Series.dt.month_name
">>> idx = pd.date_range(start='2018-01', freq='ME', periods=3)
>>> idx
DatetimeIndex(['2018-01-31', '2018-02-28', '2018-03-31'],
              dtype='datetime64[ns]', freq='ME')
>>> idx.month_name()
Index(['January', 'February', 'March'], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.month_name.html, pandas.date_range pandas.DatetimeIndex pandas.Index
">>> idx = pd.date_range(start='2018-01', freq='ME', periods=3)
>>> idx
DatetimeIndex(['2018-01-31', '2018-02-28', '2018-03-31'],
              dtype='datetime64[ns]', freq='ME')
>>> idx.month_name(locale='pt_BR.utf8')  
Index(['Janeiro', 'Fevereiro', 'Março'], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.month_name.html, pandas.date_range pandas.DatetimeIndex pandas.Index
">>> s = pd.Series(['lower', 'CAPITALS', 'this is a sentence', 'SwApCaSe'])
>>> s
0                 lower
1              CAPITALS
2    this is a sentence
3              SwApCaSe
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.lower.html, pandas.Series
">>> s.str.lower()
0                 lower
1              capitals
2    this is a sentence
3              swapcase
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.lower.html, pandas.Series.str.lower
">>> s.str.upper()
0                 LOWER
1              CAPITALS
2    THIS IS A SENTENCE
3              SWAPCASE
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.lower.html, pandas.Series.str.upper
">>> s.str.title()
0                 Lower
1              Capitals
2    This Is A Sentence
3              Swapcase
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.lower.html, pandas.Series.str.title
">>> s.str.capitalize()
0                 Lower
1              Capitals
2    This is a sentence
3              Swapcase
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.lower.html, pandas.Series.str.capitalize
">>> s.str.swapcase()
0                 LOWER
1              capitals
2    THIS IS A SENTENCE
3              sWaPcAsE
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.lower.html, pandas.Series.str.swapcase
">>> mydict = [{'a': 1, 'b': 2, 'c': 3, 'd': 4},
...           {'a': 100, 'b': 200, 'c': 300, 'd': 400},
...           {'a': 1000, 'b': 2000, 'c': 3000, 'd': 4000}]
>>> df = pd.DataFrame(mydict)
>>> df
      a     b     c     d
0     1     2     3     4
1   100   200   300   400
2  1000  2000  3000  4000
",https://pandas.pydata.org/docs/reference/api/pandas.Series.iloc.html, pandas.DataFrame
">>> s = pd.Series([""str_foo"", ""str_bar"", ""no_prefix""])
>>> s
0    str_foo
1    str_bar
2    no_prefix
dtype: object
>>> s.str.removeprefix(""str_"")
0    foo
1    bar
2    no_prefix
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.removeprefix.html, pandas.Series pandas.Series.str.removeprefix
">>> s = pd.Series([""foo_str"", ""bar_str"", ""no_suffix""])
>>> s
0    foo_str
1    bar_str
2    no_suffix
dtype: object
>>> s.str.removesuffix(""_str"")
0    foo
1    bar
2    no_suffix
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.removeprefix.html, pandas.Series pandas.Series.str.removesuffix
">>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])
>>> a
a    1.0
b    1.0
c    1.0
d    NaN
dtype: float64
>>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])
>>> b
a    1.0
b    NaN
d    1.0
e    NaN
dtype: float64
>>> a.divide(b, fill_value=0)
a    1.0
b    inf
c    inf
d    0.0
e    NaN
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.div.html, pandas.Series
">>> s = pd.Series([2, 4, 2, 2, 4, None])
>>> s.mode()
0    2.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.mode.html, pandas.Series pandas.Series.mode
">>> s = pd.Series([2, 4, 8, 2, 4, None])
>>> s.mode()
0    2.0
1    4.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.mode.html, pandas.Series pandas.Series.mode
">>> s = pd.Series([2, 4, None, None, 4, None])
>>> s.mode(dropna=False)
0   NaN
dtype: float64
>>> s = pd.Series([2, 4, None, None, 4, None])
>>> s.mode()
0    4.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.mode.html, pandas.Series pandas.Series.mode
">>> df1 = pd.DataFrame([[24.3, 75.7, 'high'],
...                     [31, 87.8, 'high'],
...                     [22, 71.6, 'medium'],
...                     [35, 95, 'medium']],
...                    columns=['temp_celsius', 'temp_fahrenheit',
...                             'windspeed'],
...                    index=pd.date_range(start='2014-02-12',
...                                        end='2014-02-15', freq='D'))
",https://pandas.pydata.org/docs/reference/api/pandas.Series.reindex_like.html, pandas.DataFrame pandas.date_range
">>> df2 = pd.DataFrame([[28, 'low'],
...                     [30, 'low'],
...                     [35.1, 'medium']],
...                    columns=['temp_celsius', 'windspeed'],
...                    index=pd.DatetimeIndex(['2014-02-12', '2014-02-13',
...                                            '2014-02-15']))
",https://pandas.pydata.org/docs/reference/api/pandas.Series.reindex_like.html, pandas.DataFrame pandas.DatetimeIndex
">>> df2.reindex_like(df1)
            temp_celsius  temp_fahrenheit windspeed
2014-02-12          28.0              NaN       low
2014-02-13          30.0              NaN       low
2014-02-14           NaN              NaN       NaN
2014-02-15          35.1              NaN    medium
",https://pandas.pydata.org/docs/reference/api/pandas.Series.reindex_like.html, pandas.DataFrame.reindex_like
">>> s = pd.Series([1, 2, 3])
>>> s.describe()
count    3.0
mean     2.0
std      1.0
min      1.0
25%      1.5
50%      2.0
75%      2.5
max      3.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.describe.html, pandas.Series pandas.Series.describe
">>> s = pd.Series(['a', 'a', 'b', 'c'])
>>> s.describe()
count     4
unique    3
top       a
freq      2
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.describe.html, pandas.Series pandas.Series.describe
">>> s = pd.Series([
...     np.datetime64(""2000-01-01""),
...     np.datetime64(""2010-01-01""),
...     np.datetime64(""2010-01-01"")
... ])
>>> s.describe()
count                      3
mean     2006-09-01 08:00:00
min      2000-01-01 00:00:00
25%      2004-12-31 12:00:00
50%      2010-01-01 00:00:00
75%      2010-01-01 00:00:00
max      2010-01-01 00:00:00
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.describe.html, pandas.Series pandas.Series.describe
">>> df = pd.DataFrame({'categorical': pd.Categorical(['d', 'e', 'f']),
...                    'numeric': [1, 2, 3],
...                    'object': ['a', 'b', 'c']
...                    })
>>> df.describe()
       numeric
count      3.0
mean       2.0
std        1.0
min        1.0
25%        1.5
50%        2.0
75%        2.5
max        3.0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.describe.html, pandas.DataFrame pandas.Categorical pandas.DataFrame.describe
">>> df.describe(include='all')  
       categorical  numeric object
count            3      3.0      3
unique           3      NaN      3
top              f      NaN      a
freq             1      NaN      1
mean           NaN      2.0    NaN
std            NaN      1.0    NaN
min            NaN      1.0    NaN
25%            NaN      1.5    NaN
50%            NaN      2.0    NaN
75%            NaN      2.5    NaN
max            NaN      3.0    NaN
",https://pandas.pydata.org/docs/reference/api/pandas.Series.describe.html, pandas.DataFrame.describe
">>> df.describe(include=[np.number])
       numeric
count      3.0
mean       2.0
std        1.0
min        1.0
25%        1.5
50%        2.0
75%        2.5
max        3.0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.describe.html, pandas.DataFrame.describe
">>> df.describe(include=[object])  
       object
count       3
unique      3
top         a
freq        1
",https://pandas.pydata.org/docs/reference/api/pandas.Series.describe.html, pandas.DataFrame.describe
">>> df.describe(include=['category'])
       categorical
count            3
unique           3
top              d
freq             1
",https://pandas.pydata.org/docs/reference/api/pandas.Series.describe.html, pandas.DataFrame.describe
">>> df.describe(exclude=[np.number])  
       categorical object
count            3      3
unique           3      3
top              f      a
freq             1      1
",https://pandas.pydata.org/docs/reference/api/pandas.Series.describe.html, pandas.DataFrame.describe
">>> df.describe(exclude=[object])  
       categorical  numeric
count            3      3.0
unique           3      NaN
top              f      NaN
freq             1      NaN
mean           NaN      2.0
std            NaN      1.0
min            NaN      1.0
25%            NaN      1.5
50%            NaN      2.0
75%            NaN      2.5
max            NaN      3.0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.describe.html, pandas.DataFrame.describe
">>> s = pd.Series(['Linda van der Berg', 'George Pitt-Rivers'])
>>> s
0    Linda van der Berg
1    George Pitt-Rivers
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.rpartition.html, pandas.Series
">>> s.str.partition()
        0  1             2
0   Linda     van der Berg
1  George      Pitt-Rivers
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.rpartition.html, pandas.Series.str.partition
">>> s.str.rpartition()
               0  1            2
0  Linda van der            Berg
1         George     Pitt-Rivers
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.rpartition.html, pandas.Series.str.rpartition
">>> s.str.partition('-')
                    0  1       2
0  Linda van der Berg
1         George Pitt  -  Rivers
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.rpartition.html, pandas.Series.str.partition
">>> s.str.partition('-', expand=False)
0    (Linda van der Berg, , )
1    (George Pitt, -, Rivers)
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.rpartition.html, pandas.Series.str.partition
">>> idx = pd.Index(['X 123', 'Y 999'])
>>> idx
Index(['X 123', 'Y 999'], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.rpartition.html, pandas.Index pandas.Index
">>> idx.str.partition()
MultiIndex([('X', ' ', '123'),
            ('Y', ' ', '999')],
           )
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.rpartition.html, pandas.MultiIndex
">>> idx.str.partition(expand=False)
Index([('X', ' ', '123'), ('Y', ' ', '999')], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.rpartition.html, pandas.Index
">>> s = pd.Series([1, 2, 3])
>>> s.median()
2.0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.median.html, pandas.Series pandas.Series.median
">>> df = pd.DataFrame({'a': [1, 2], 'b': [2, 3]}, index=['tiger', 'zebra'])
>>> df
       a   b
tiger  1   2
zebra  2   3
>>> df.median()
a   1.5
b   2.5
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.median.html, pandas.DataFrame pandas.DataFrame.median
">>> df.median(axis=1)
tiger   1.5
zebra   2.5
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.median.html, pandas.DataFrame.median
">>> df = pd.DataFrame({'a': [1, 2], 'b': ['T', 'Z']},
...                   index=['tiger', 'zebra'])
>>> df.median(numeric_only=True)
a   1.5
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.median.html, pandas.DataFrame pandas.DataFrame.median
">>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])
>>> a
a    1.0
b    1.0
c    1.0
d    NaN
dtype: float64
>>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])
>>> b
a    1.0
b    NaN
d    1.0
e    NaN
dtype: float64
>>> a.floordiv(b, fill_value=0)
a    1.0
b    inf
c    inf
d    0.0
e    NaN
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.floordiv.html, pandas.Series pandas.Series.floordiv
">>> s = pd.Series([""caribou"", ""tiger""])
>>> s
0    caribou
1      tiger
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.pad.html, pandas.Series
">>> s.str.pad(width=10)
0       caribou
1         tiger
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.pad.html, pandas.Series.str.pad
">>> s.str.pad(width=10, side='right', fillchar='-')
0    caribou---
1    tiger-----
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.pad.html, pandas.Series.str.pad
">>> s.str.pad(width=10, side='both', fillchar='-')
0    -caribou--
1    --tiger---
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.pad.html, pandas.Series.str.pad
">>> index = ['Firefox', 'Chrome', 'Safari', 'IE10', 'Konqueror']
>>> df = pd.DataFrame({'http_status': [200, 200, 404, 404, 301],
...                   'response_time': [0.04, 0.02, 0.07, 0.08, 1.0]},
...                   index=index)
>>> df
           http_status  response_time
Firefox            200           0.04
Chrome             200           0.02
Safari             404           0.07
IE10               404           0.08
Konqueror          301           1.00
",https://pandas.pydata.org/docs/reference/api/pandas.Series.reindex.html, pandas.DataFrame
">>> new_index = ['Safari', 'Iceweasel', 'Comodo Dragon', 'IE10',
...              'Chrome']
>>> df.reindex(new_index)
               http_status  response_time
Safari               404.0           0.07
Iceweasel              NaN            NaN
Comodo Dragon          NaN            NaN
IE10                 404.0           0.08
Chrome               200.0           0.02
",https://pandas.pydata.org/docs/reference/api/pandas.Series.reindex.html, pandas.DataFrame.reindex
">>> df.reindex(new_index, fill_value=0)
               http_status  response_time
Safari                 404           0.07
Iceweasel                0           0.00
Comodo Dragon            0           0.00
IE10                   404           0.08
Chrome                 200           0.02
",https://pandas.pydata.org/docs/reference/api/pandas.Series.reindex.html, pandas.DataFrame.reindex
">>> df.reindex(new_index, fill_value='missing')
              http_status response_time
Safari                404          0.07
Iceweasel         missing       missing
Comodo Dragon     missing       missing
IE10                  404          0.08
Chrome                200          0.02
",https://pandas.pydata.org/docs/reference/api/pandas.Series.reindex.html, pandas.DataFrame.reindex
">>> df.reindex(columns=['http_status', 'user_agent'])
           http_status  user_agent
Firefox            200         NaN
Chrome             200         NaN
Safari             404         NaN
IE10               404         NaN
Konqueror          301         NaN
",https://pandas.pydata.org/docs/reference/api/pandas.Series.reindex.html, pandas.DataFrame.reindex
">>> df.reindex(['http_status', 'user_agent'], axis=""columns"")
           http_status  user_agent
Firefox            200         NaN
Chrome             200         NaN
Safari             404         NaN
IE10               404         NaN
Konqueror          301         NaN
",https://pandas.pydata.org/docs/reference/api/pandas.Series.reindex.html, pandas.DataFrame.reindex
">>> date_index = pd.date_range('1/1/2010', periods=6, freq='D')
>>> df2 = pd.DataFrame({""prices"": [100, 101, np.nan, 100, 89, 88]},
...                    index=date_index)
>>> df2
            prices
2010-01-01   100.0
2010-01-02   101.0
2010-01-03     NaN
2010-01-04   100.0
2010-01-05    89.0
2010-01-06    88.0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.reindex.html, pandas.date_range pandas.DataFrame
">>> date_index2 = pd.date_range('12/29/2009', periods=10, freq='D')
>>> df2.reindex(date_index2)
            prices
2009-12-29     NaN
2009-12-30     NaN
2009-12-31     NaN
2010-01-01   100.0
2010-01-02   101.0
2010-01-03     NaN
2010-01-04   100.0
2010-01-05    89.0
2010-01-06    88.0
2010-01-07     NaN
",https://pandas.pydata.org/docs/reference/api/pandas.Series.reindex.html, pandas.date_range pandas.DataFrame.reindex
">>> df2.reindex(date_index2, method='bfill')
            prices
2009-12-29   100.0
2009-12-30   100.0
2009-12-31   100.0
2010-01-01   100.0
2010-01-02   101.0
2010-01-03     NaN
2010-01-04   100.0
2010-01-05    89.0
2010-01-06    88.0
2010-01-07     NaN
",https://pandas.pydata.org/docs/reference/api/pandas.Series.reindex.html, pandas.DataFrame.reindex
">>> s = pd.Series(['Lion', 'Monkey', 'Rabbit'])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.findall.html, pandas.Series
">>> s.str.findall('Monkey')
0          []
1    [Monkey]
2          []
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.findall.html, pandas.Series.str.findall
">>> s.str.findall('MONKEY')
0    []
1    []
2    []
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.findall.html, pandas.Series.str.findall
">>> import re
>>> s.str.findall('MONKEY', flags=re.IGNORECASE)
0          []
1    [Monkey]
2          []
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.findall.html, pandas.Series.str.findall
">>> s.str.findall('on')
0    [on]
1    [on]
2      []
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.findall.html, pandas.Series.str.findall
">>> s.str.findall('on$')
0    [on]
1      []
2      []
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.findall.html, pandas.Series.str.findall
">>> s.str.findall('b')
0        []
1        []
2    [b, b]
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.findall.html, pandas.Series.str.findall
">>> datetime_series = pd.Series(
...     pd.date_range(""2000-01-01"", periods=3, freq=""min"")
... )
>>> datetime_series
0   2000-01-01 00:00:00
1   2000-01-01 00:01:00
2   2000-01-01 00:02:00
dtype: datetime64[ns]
>>> datetime_series.dt.minute
0    0
1    1
2    2
dtype: int32
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.minute.html, pandas.Series pandas.date_range
">>> data = {'col_0': [9, -3, 0, -1, 5], 'col_1': [-2, -7, 6, 8, -5]}
>>> df = pd.DataFrame(data)
>>> df
   col_0  col_1
0      9     -2
1     -3     -7
2      0      6
3     -1      8
4      5     -5
",https://pandas.pydata.org/docs/reference/api/pandas.Series.clip.html, pandas.DataFrame
">>> df.clip(-4, 6)
   col_0  col_1
0      6     -2
1     -3     -4
2      0      6
3     -1      6
4      5     -4
",https://pandas.pydata.org/docs/reference/api/pandas.Series.clip.html, pandas.DataFrame.clip
">>> df.clip([-2, -1], [4, 5])
    col_0  col_1
0      4     -1
1     -2     -1
2      0      5
3     -1      5
4      4     -1
",https://pandas.pydata.org/docs/reference/api/pandas.Series.clip.html, pandas.DataFrame.clip
">>> t = pd.Series([2, -4, -1, 6, 3])
>>> t
0    2
1   -4
2   -1
3    6
4    3
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.clip.html, pandas.Series
">>> df.clip(t, t + 4, axis=0)
   col_0  col_1
0      6      2
1     -3     -4
2      0      3
3      6      8
4      5      3
",https://pandas.pydata.org/docs/reference/api/pandas.Series.clip.html, pandas.DataFrame.clip
">>> t = pd.Series([2, -4, np.nan, 6, 3])
>>> t
0    2.0
1   -4.0
2    NaN
3    6.0
4    3.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.clip.html, pandas.Series
">>> df.clip(t, axis=0)
col_0  col_1
0      9      2
1     -3     -4
2      0      6
3      6      8
4      5      3
",https://pandas.pydata.org/docs/reference/api/pandas.Series.clip.html, pandas.DataFrame.clip
">>> s = pd.Series(pd.date_range('20180310', periods=2))
>>> s
0   2018-03-10
1   2018-03-11
dtype: datetime64[ns]
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.to_pydatetime.html, pandas.Series pandas.date_range
">>> s.dt.to_pydatetime()
array([datetime.datetime(2018, 3, 10, 0, 0),
       datetime.datetime(2018, 3, 11, 0, 0)], dtype=object)
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.to_pydatetime.html, pandas.Series.dt.to_pydatetime pandas.array
">>> s = pd.Series(pd.date_range('20180310', periods=2, freq='ns'))
>>> s
0   2018-03-10 00:00:00.000000000
1   2018-03-10 00:00:00.000000001
dtype: datetime64[ns]
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.to_pydatetime.html, pandas.Series pandas.date_range
">>> s.dt.to_pydatetime()
array([datetime.datetime(2018, 3, 10, 0, 0),
       datetime.datetime(2018, 3, 10, 0, 0)], dtype=object)
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.to_pydatetime.html, pandas.Series.dt.to_pydatetime pandas.array
">>> s = pd.Series([1, 2, 3, 4, 5])
>>> s.replace(1, 5)
0    5
1    2
2    3
3    4
4    5
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.replace.html, pandas.Series pandas.Series.replace
">>> df = pd.DataFrame({'A': [0, 1, 2, 3, 4],
...                    'B': [5, 6, 7, 8, 9],
...                    'C': ['a', 'b', 'c', 'd', 'e']})
>>> df.replace(0, 5)
    A  B  C
0  5  5  a
1  1  6  b
2  2  7  c
3  3  8  d
4  4  9  e
",https://pandas.pydata.org/docs/reference/api/pandas.Series.replace.html, pandas.DataFrame pandas.DataFrame.replace
">>> df.replace([0, 1, 2, 3], 4)
    A  B  C
0  4  5  a
1  4  6  b
2  4  7  c
3  4  8  d
4  4  9  e
",https://pandas.pydata.org/docs/reference/api/pandas.Series.replace.html, pandas.DataFrame.replace
">>> df.replace([0, 1, 2, 3], [4, 3, 2, 1])
    A  B  C
0  4  5  a
1  3  6  b
2  2  7  c
3  1  8  d
4  4  9  e
",https://pandas.pydata.org/docs/reference/api/pandas.Series.replace.html, pandas.DataFrame.replace
">>> s.replace([1, 2], method='bfill')
0    3
1    3
2    3
3    4
4    5
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.replace.html, pandas.Series.replace
">>> df.replace({0: 10, 1: 100})
        A  B  C
0   10  5  a
1  100  6  b
2    2  7  c
3    3  8  d
4    4  9  e
",https://pandas.pydata.org/docs/reference/api/pandas.Series.replace.html, pandas.DataFrame.replace
">>> df.replace({'A': 0, 'B': 5}, 100)
        A    B  C
0  100  100  a
1    1    6  b
2    2    7  c
3    3    8  d
4    4    9  e
",https://pandas.pydata.org/docs/reference/api/pandas.Series.replace.html, pandas.DataFrame.replace
">>> df.replace({'A': {0: 100, 4: 400}})
        A  B  C
0  100  5  a
1    1  6  b
2    2  7  c
3    3  8  d
4  400  9  e
",https://pandas.pydata.org/docs/reference/api/pandas.Series.replace.html, pandas.DataFrame.replace
">>> df = pd.DataFrame({'A': ['bat', 'foo', 'bait'],
...                    'B': ['abc', 'bar', 'xyz']})
>>> df.replace(to_replace=r'^ba.$', value='new', regex=True)
        A    B
0   new  abc
1   foo  new
2  bait  xyz
",https://pandas.pydata.org/docs/reference/api/pandas.Series.replace.html, pandas.DataFrame pandas.DataFrame.replace
">>> df.replace({'A': r'^ba.$'}, {'A': 'new'}, regex=True)
        A    B
0   new  abc
1   foo  bar
2  bait  xyz
",https://pandas.pydata.org/docs/reference/api/pandas.Series.replace.html, pandas.DataFrame.replace
">>> df.replace(regex=r'^ba.$', value='new')
        A    B
0   new  abc
1   foo  new
2  bait  xyz
",https://pandas.pydata.org/docs/reference/api/pandas.Series.replace.html, pandas.DataFrame.replace
">>> df.replace(regex={r'^ba.$': 'new', 'foo': 'xyz'})
        A    B
0   new  abc
1   xyz  new
2  bait  xyz
",https://pandas.pydata.org/docs/reference/api/pandas.Series.replace.html, pandas.DataFrame.replace
">>> df.replace(regex=[r'^ba.$', 'foo'], value='new')
        A    B
0   new  abc
1   new  new
2  bait  xyz
",https://pandas.pydata.org/docs/reference/api/pandas.Series.replace.html, pandas.DataFrame.replace
">>> s = pd.Series([10, 'a', 'a', 'b', 'a'])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.replace.html, pandas.Series
">>> s.replace({'a': None})
0      10
1    None
2    None
3       b
4    None
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.replace.html, pandas.Series.replace
">>> s.replace('a')
0    10
1    10
2    10
3     b
4     b
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.replace.html, pandas.Series.replace
">>> s.replace('a', None)
0      10
1    None
2    None
3       b
4    None
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.replace.html, pandas.Series.replace
">>> df = pd.DataFrame({'A': [0, 1, 2, 3, 4],
...                    'B': ['a', 'b', 'c', 'd', 'e'],
...                    'C': ['f', 'g', 'h', 'i', 'j']})
",https://pandas.pydata.org/docs/reference/api/pandas.Series.replace.html, pandas.DataFrame
">>> df.replace(to_replace='^[a-g]', value='e', regex=True)
    A  B  C
0  0  e  e
1  1  e  e
2  2  e  h
3  3  e  i
4  4  e  j
",https://pandas.pydata.org/docs/reference/api/pandas.Series.replace.html, pandas.DataFrame.replace
">>> df.replace(to_replace={'B': '^[a-c]', 'C': '^[h-j]'}, value='e', regex=True)
    A  B  C
0  0  e  f
1  1  e  g
2  2  e  e
3  3  d  e
4  4  e  e
",https://pandas.pydata.org/docs/reference/api/pandas.Series.replace.html, pandas.DataFrame.replace
">>> df = pd.DataFrame(
...     [[1, 2, 3, 4], [6, 7, 8, 9]], columns=[""D"", ""B"", ""E"", ""A""], index=[1, 2]
... )
>>> other = pd.DataFrame(
...     [[10, 20, 30, 40], [60, 70, 80, 90], [600, 700, 800, 900]],
...     columns=[""A"", ""B"", ""C"", ""D""],
...     index=[2, 3, 4],
... )
>>> df
   D  B  E  A
1  1  2  3  4
2  6  7  8  9
>>> other
    A    B    C    D
2   10   20   30   40
3   60   70   80   90
4  600  700  800  900
",https://pandas.pydata.org/docs/reference/api/pandas.Series.align.html, pandas.DataFrame
">>> left, right = df.align(other, join=""outer"", axis=1)
>>> left
   A  B   C  D  E
1  4  2 NaN  1  3
2  9  7 NaN  6  8
>>> right
    A    B    C    D   E
2   10   20   30   40 NaN
3   60   70   80   90 NaN
4  600  700  800  900 NaN
",https://pandas.pydata.org/docs/reference/api/pandas.Series.align.html, pandas.DataFrame.align
">>> left, right = df.align(other, join=""outer"", axis=0)
>>> left
    D    B    E    A
1  1.0  2.0  3.0  4.0
2  6.0  7.0  8.0  9.0
3  NaN  NaN  NaN  NaN
4  NaN  NaN  NaN  NaN
>>> right
    A      B      C      D
1    NaN    NaN    NaN    NaN
2   10.0   20.0   30.0   40.0
3   60.0   70.0   80.0   90.0
4  600.0  700.0  800.0  900.0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.align.html, pandas.DataFrame.align
">>> left, right = df.align(other, join=""outer"", axis=None)
>>> left
     A    B   C    D    E
1  4.0  2.0 NaN  1.0  3.0
2  9.0  7.0 NaN  6.0  8.0
3  NaN  NaN NaN  NaN  NaN
4  NaN  NaN NaN  NaN  NaN
>>> right
       A      B      C      D   E
1    NaN    NaN    NaN    NaN NaN
2   10.0   20.0   30.0   40.0 NaN
3   60.0   70.0   80.0   90.0 NaN
4  600.0  700.0  800.0  900.0 NaN
",https://pandas.pydata.org/docs/reference/api/pandas.Series.align.html, pandas.DataFrame.align
">>> s = pd.Series([""A_Str_Series""])
>>> s
0    A_Str_Series
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.html, pandas.Series
">>> s.str.split(""_"")
0    [A, Str, Series]
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.html, pandas.Series.str.split
">>> s.str.replace(""_"", """")
0    AStrSeries
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.html, pandas.Series.str.replace
">>> dates = pd.Series(pd.date_range(""2017-12-30"", periods=3))
>>> dates
0   2017-12-30
1   2017-12-31
2   2018-01-01
dtype: datetime64[ns]
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.is_year_end.html, pandas.Series pandas.date_range
">>> idx = pd.date_range(""2017-12-30"", periods=3)
>>> idx
DatetimeIndex(['2017-12-30', '2017-12-31', '2018-01-01'],
              dtype='datetime64[ns]', freq='D')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.is_year_end.html, pandas.date_range pandas.DatetimeIndex
">>> idx.is_year_end
array([False,  True, False])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.is_year_end.html, pandas.array
">>> s = pd.Series([[1, 2, 3], 'foo', [], [3, 4]])
>>> s
0    [1, 2, 3]
1          foo
2           []
3       [3, 4]
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.explode.html, pandas.Series
">>> s.explode()
0      1
0      2
0      3
1    foo
2    NaN
3      3
3      4
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.explode.html, pandas.Series.explode
">>> df = pd.DataFrame([[np.nan, 2, np.nan, 0],
...                    [3, 4, np.nan, 1],
...                    [np.nan, np.nan, np.nan, np.nan],
...                    [np.nan, 3, np.nan, 4]],
...                   columns=list(""ABCD""))
>>> df
     A    B   C    D
0  NaN  2.0 NaN  0.0
1  3.0  4.0 NaN  1.0
2  NaN  NaN NaN  NaN
3  NaN  3.0 NaN  4.0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.fillna.html, pandas.DataFrame
">>> df.fillna(0)
     A    B    C    D
0  0.0  2.0  0.0  0.0
1  3.0  4.0  0.0  1.0
2  0.0  0.0  0.0  0.0
3  0.0  3.0  0.0  4.0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.fillna.html, pandas.DataFrame.fillna
">>> values = {""A"": 0, ""B"": 1, ""C"": 2, ""D"": 3}
>>> df.fillna(value=values)
     A    B    C    D
0  0.0  2.0  2.0  0.0
1  3.0  4.0  2.0  1.0
2  0.0  1.0  2.0  3.0
3  0.0  3.0  2.0  4.0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.fillna.html, pandas.DataFrame.fillna
">>> df.fillna(value=values, limit=1)
     A    B    C    D
0  0.0  2.0  2.0  0.0
1  3.0  4.0  NaN  1.0
2  NaN  1.0  NaN  3.0
3  NaN  3.0  NaN  4.0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.fillna.html, pandas.DataFrame.fillna
">>> df2 = pd.DataFrame(np.zeros((4, 4)), columns=list(""ABCE""))
>>> df.fillna(df2)
     A    B    C    D
0  0.0  2.0  0.0  0.0
1  3.0  4.0  0.0  1.0
2  0.0  0.0  0.0  NaN
3  0.0  3.0  0.0  4.0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.fillna.html, pandas.DataFrame pandas.DataFrame.fillna
">>> s = pd.Series([1, 2, 3])
>>> s.is_unique
True
",https://pandas.pydata.org/docs/reference/api/pandas.Series.is_unique.html, pandas.Series
">>> s = pd.Series([1, 2, 3, 1])
>>> s.is_unique
False
",https://pandas.pydata.org/docs/reference/api/pandas.Series.is_unique.html, pandas.Series
">>> df = pd.DataFrame({'name': ['Raphael', 'Donatello'],
...                    'mask': ['red', 'purple'],
...                    'weapon': ['sai', 'bo staff']})
>>> df.to_csv('out.csv', index=False)  
",https://pandas.pydata.org/docs/reference/api/pandas.Series.to_csv.html, pandas.DataFrame pandas.DataFrame.to_csv
">>> df.to_csv(index=False)
'name,mask,weapon\nRaphael,red,sai\nDonatello,purple,bo staff\n'
>>> compression_opts = dict(method='zip',
...                         archive_name='out.csv')  
>>> df.to_csv('out.zip', index=False,
...           compression=compression_opts)  
",https://pandas.pydata.org/docs/reference/api/pandas.Series.to_csv.html, pandas.DataFrame.to_csv
">>> from pathlib import Path  
>>> filepath = Path('folder/subfolder/out.csv')  
>>> filepath.parent.mkdir(parents=True, exist_ok=True)  
>>> df.to_csv(filepath)  
",https://pandas.pydata.org/docs/reference/api/pandas.Series.to_csv.html, pandas.DataFrame.to_csv
">>> import os  
>>> os.makedirs('folder/subfolder', exist_ok=True)  
>>> df.to_csv('folder/subfolder/out.csv')  
",https://pandas.pydata.org/docs/reference/api/pandas.Series.to_csv.html, pandas.DataFrame.to_csv
">>> data = np.random.randn(25, 4)
>>> df = pd.DataFrame(data, columns=list('ABCD'))
>>> ax = df.plot.box()
",https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.box.html, pandas.DataFrame pandas.DataFrame.plot.box
">>> age_list = [8, 10, 12, 14, 72, 74, 76, 78, 20, 25, 30, 35, 60, 85]
>>> df = pd.DataFrame({""gender"": list(""MMMMMMMMFFFFFF""), ""age"": age_list})
>>> ax = df.plot.box(column=""age"", by=""gender"", figsize=(10, 8))
",https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.box.html, pandas.DataFrame pandas.DataFrame.plot.box
">>> s = pd.Series([1, 2], index=[""a"", ""b""])
>>> s
a    1
b    2
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.copy.html, pandas.Series
">>> s_copy = s.copy()
>>> s_copy
a    1
b    2
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.copy.html, pandas.Series.copy
">>> s = pd.Series([1, 2], index=[""a"", ""b""])
>>> deep = s.copy()
>>> shallow = s.copy(deep=False)
",https://pandas.pydata.org/docs/reference/api/pandas.Series.copy.html, pandas.Series pandas.Series.copy
">>> s = pd.Series([[1, 2], [3, 4]])
>>> deep = s.copy()
>>> s[0][0] = 10
>>> s
0    [10, 2]
1     [3, 4]
dtype: object
>>> deep
0    [10, 2]
1     [3, 4]
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.copy.html, pandas.Series pandas.Series.copy
">>> with pd.option_context(""mode.copy_on_write"", True):
...     s = pd.Series([1, 2], index=[""a"", ""b""])
...     copy = s.copy(deep=False)
...     s.iloc[0] = 100
...     s
a    100
b      2
dtype: int64
>>> copy
a    1
b    2
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.copy.html, pandas.Series pandas.Series.copy
">>> df = pd.DataFrame([
...     [1, 2, 3, 4],
...     [5, 6, 7, 8],
...     [9, 10, 11, 12]
... ]).set_index([0, 1]).rename_axis(['a', 'b'])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.droplevel.html, pandas.DataFrame pandas.DataFrame.set_index
">>> df.columns = pd.MultiIndex.from_tuples([
...     ('c', 'e'), ('d', 'f')
... ], names=['level_1', 'level_2'])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.droplevel.html, pandas.MultiIndex.from_tuples
">>> df.droplevel('a')
level_1   c   d
level_2   e   f
b
2        3   4
6        7   8
10      11  12
",https://pandas.pydata.org/docs/reference/api/pandas.Series.droplevel.html, pandas.DataFrame.droplevel
">>> df.droplevel('level_2', axis=1)
level_1   c   d
a b
1 2      3   4
5 6      7   8
9 10    11  12
",https://pandas.pydata.org/docs/reference/api/pandas.Series.droplevel.html, pandas.DataFrame.droplevel
">>> s = pd.Series(pd.date_range(""2018-02-27"", periods=3))
>>> s
0   2018-02-27
1   2018-02-28
2   2018-03-01
dtype: datetime64[ns]
>>> s.dt.is_month_start
0    False
1    False
2    True
dtype: bool
>>> s.dt.is_month_end
0    False
1    True
2    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.is_month_start.html, pandas.Series pandas.date_range
">>> idx = pd.date_range(""2018-02-27"", periods=3)
>>> idx.is_month_start
array([False, False, True])
>>> idx.is_month_end
array([False, True, False])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.is_month_start.html, pandas.date_range pandas.array
">>> df = pd.DataFrame({'animal': ['alligator', 'bee', 'falcon', 'lion',
...                    'monkey', 'parrot', 'shark', 'whale', 'zebra']})
>>> df
      animal
0  alligator
1        bee
2     falcon
3       lion
4     monkey
5     parrot
6      shark
7      whale
8      zebra
",https://pandas.pydata.org/docs/reference/api/pandas.Series.tail.html, pandas.DataFrame
">>> df.tail()
   animal
4  monkey
5  parrot
6   shark
7   whale
8   zebra
",https://pandas.pydata.org/docs/reference/api/pandas.Series.tail.html, pandas.DataFrame.tail
">>> df.tail(3)
  animal
6  shark
7  whale
8  zebra
",https://pandas.pydata.org/docs/reference/api/pandas.Series.tail.html, pandas.DataFrame.tail
">>> df.tail(-3)
   animal
3    lion
4  monkey
5  parrot
6   shark
7   whale
8   zebra
",https://pandas.pydata.org/docs/reference/api/pandas.Series.tail.html, pandas.DataFrame.tail
">>> ser = pd.Series([""cow_"", ""duck_"", ""do_ve""])
>>> ser.str.find(""_"")
0   3
1   4
2   2
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.find.html, pandas.Series pandas.Series.str.find
">>> ser = pd.Series([""_cow_"", ""duck_"", ""do_v_e""])
>>> ser.str.rfind(""_"")
0   4
1   4
2   4
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.find.html, pandas.Series pandas.Series.str.rfind
">>> from pandas.arrays import SparseArray
>>> s = SparseArray([0, 0, 1, 0, 2], fill_value=0)
>>> s.sp_values
array([1, 2])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.sparse.sp_values.html, pandas.arrays.SparseArray pandas.array
">>> df = pd.DataFrame({'A': range(3), 'B': range(1, 4)})
>>> df
   A  B
0  0  1
1  1  2
2  2  3
>>> df.transform(lambda x: x + 1)
   A  B
0  1  2
1  2  3
2  3  4
",https://pandas.pydata.org/docs/reference/api/pandas.Series.transform.html, pandas.DataFrame pandas.DataFrame.transform
">>> s = pd.Series(range(3))
>>> s
0    0
1    1
2    2
dtype: int64
>>> s.transform([np.sqrt, np.exp])
       sqrt        exp
0  0.000000   1.000000
1  1.000000   2.718282
2  1.414214   7.389056
",https://pandas.pydata.org/docs/reference/api/pandas.Series.transform.html, pandas.Series pandas.Series.transform
">>> df = pd.DataFrame({
...     ""Date"": [
...         ""2015-05-08"", ""2015-05-07"", ""2015-05-06"", ""2015-05-05"",
...         ""2015-05-08"", ""2015-05-07"", ""2015-05-06"", ""2015-05-05""],
...     ""Data"": [5, 8, 6, 1, 50, 100, 60, 120],
... })
>>> df
         Date  Data
0  2015-05-08     5
1  2015-05-07     8
2  2015-05-06     6
3  2015-05-05     1
4  2015-05-08    50
5  2015-05-07   100
6  2015-05-06    60
7  2015-05-05   120
>>> df.groupby('Date')['Data'].transform('sum')
0     55
1    108
2     66
3    121
4     55
5    108
6     66
7    121
Name: Data, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.transform.html, pandas.DataFrame pandas.DataFrame.groupby
">>> df = pd.DataFrame({
...     ""c"": [1, 1, 1, 2, 2, 2, 2],
...     ""type"": [""m"", ""n"", ""o"", ""m"", ""m"", ""n"", ""n""]
... })
>>> df
   c type
0  1    m
1  1    n
2  1    o
3  2    m
4  2    m
5  2    n
6  2    n
>>> df['size'] = df.groupby('c')['type'].transform(len)
>>> df
   c type size
0  1    m    3
1  1    n    3
2  1    o    3
3  2    m    4
4  2    m    4
5  2    n    4
6  2    n    4
",https://pandas.pydata.org/docs/reference/api/pandas.Series.transform.html, pandas.DataFrame pandas.DataFrame.groupby
">>> ser = pd.Series(['dog', 'bird', 'mouse'])
>>> ser.str.center(8, fillchar='.')
0   ..dog...
1   ..bird..
2   .mouse..
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.ljust.html, pandas.Series pandas.Series.str.center
">>> ser = pd.Series(['dog', 'bird', 'mouse'])
>>> ser.str.ljust(8, fillchar='.')
0   dog.....
1   bird....
2   mouse...
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.ljust.html, pandas.Series pandas.Series.str.ljust
">>> ser = pd.Series(['dog', 'bird', 'mouse'])
>>> ser.str.rjust(8, fillchar='.')
0   .....dog
1   ....bird
2   ...mouse
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.ljust.html, pandas.Series pandas.Series.str.rjust
">>> arrays = [np.array([""dog"", ""dog"", ""cat"", ""cat"", ""bird"", ""bird""]),
...           np.array([""white"", ""black"", ""white"", ""black"", ""white"", ""black""])]
>>> s = pd.Series([1, 2, 3, 3, 5, 2], index=arrays)
>>> s
dog   white    1
      black    2
cat   white    3
      black    3
bird  white    5
      black    2
dtype: int64
>>> s.reorder_levels([1, 0])
white  dog     1
black  dog     2
white  cat     3
black  cat     3
white  bird    5
black  bird    2
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.reorder_levels.html, pandas.Series pandas.Series.reorder_levels
">>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])
>>> a
a    1.0
b    1.0
c    1.0
d    NaN
dtype: float64
>>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])
>>> b
a    1.0
b    NaN
d    1.0
e    NaN
dtype: float64
>>> a.pow(b, fill_value=0)
a    1.0
b    1.0
c    1.0
d    0.0
e    NaN
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.rpow.html, pandas.Series pandas.Series.pow
">>> s = pd.Series([""String"",
...               (1, 2, 3),
...               [""a"", ""b"", ""c""],
...               123,
...               -456,
...               {1: ""Hello"", ""2"": ""World""}])
>>> s
0                        String
1                     (1, 2, 3)
2                     [a, b, c]
3                           123
4                          -456
5    {1: 'Hello', '2': 'World'}
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.get.html, pandas.Series
">>> s.str.get(1)
0        t
1        2
2        b
3      NaN
4      NaN
5    Hello
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.get.html, pandas.Series.str.get
">>> s.str.get(-1)
0      g
1      3
2      c
3    NaN
4    NaN
5    None
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.get.html, pandas.Series.str.get
">>> s = pd.Series([{""name"": ""Hello"", ""value"": ""World""},
...               {""name"": ""Goodbye"", ""value"": ""Planet""}])
>>> s.str.get('name')
0      Hello
1    Goodbye
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.get.html, pandas.Series pandas.Series.str.get
">>> datetime_series = pd.Series(
...     pd.date_range(""2000-01-01"", periods=3, freq=""h"")
... )
>>> datetime_series
0   2000-01-01 00:00:00
1   2000-01-01 01:00:00
2   2000-01-01 02:00:00
dtype: datetime64[ns]
>>> datetime_series.dt.hour
0    0
1    1
2    2
dtype: int32
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.hour.html, pandas.Series pandas.date_range
">>> s = pd.Series([3.0, np.nan, 1.0, 3.0, np.nan, np.nan])
>>> s.index = pd.MultiIndex.from_tuples(
...     [
...         (1, 2, ""a"", 0),
...         (1, 2, ""a"", 1),
...         (1, 1, ""b"", 0),
...         (1, 1, ""b"", 1),
...         (2, 1, ""b"", 0),
...         (2, 1, ""b"", 1)
...     ],
...     names=[""A"", ""B"", ""C"", ""D""],
... )
>>> s
A  B  C  D
1  2  a  0    3.0
         1    NaN
   1  b  0    1.0
         1    3.0
2  1  b  0    NaN
         1    NaN
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.sparse.to_coo.html, pandas.Series pandas.MultiIndex.from_tuples
">>> ss = s.astype(""Sparse"")
>>> ss
A  B  C  D
1  2  a  0    3.0
         1    NaN
   1  b  0    1.0
         1    3.0
2  1  b  0    NaN
         1    NaN
dtype: Sparse[float64, nan]
",https://pandas.pydata.org/docs/reference/api/pandas.Series.sparse.to_coo.html, pandas.Series.astype
">>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])
>>> a
a    1.0
b    1.0
c    1.0
d    NaN
dtype: float64
>>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])
>>> b
a    1.0
b    NaN
d    1.0
e    NaN
dtype: float64
>>> a.mod(b, fill_value=0)
a    0.0
b    NaN
c    NaN
d    0.0
e    NaN
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.rmod.html, pandas.Series pandas.Series.mod
">>> from json import loads, dumps
>>> df = pd.DataFrame(
...     [[""a"", ""b""], [""c"", ""d""]],
...     index=[""row 1"", ""row 2""],
...     columns=[""col 1"", ""col 2""],
... )
",https://pandas.pydata.org/docs/reference/api/pandas.Series.to_json.html, pandas.DataFrame
">>> result = df.to_json(orient=""split"")
>>> parsed = loads(result)
>>> dumps(parsed, indent=4)  
{
    ""columns"": [
        ""col 1"",
        ""col 2""
    ],
    ""index"": [
        ""row 1"",
        ""row 2""
    ],
    ""data"": [
        [
            ""a"",
            ""b""
        ],
        [
            ""c"",
            ""d""
        ]
    ]
}
",https://pandas.pydata.org/docs/reference/api/pandas.Series.to_json.html, pandas.DataFrame.to_json
">>> result = df.to_json(orient=""records"")
>>> parsed = loads(result)
>>> dumps(parsed, indent=4)  
[
    {
        ""col 1"": ""a"",
        ""col 2"": ""b""
    },
    {
        ""col 1"": ""c"",
        ""col 2"": ""d""
    }
]
",https://pandas.pydata.org/docs/reference/api/pandas.Series.to_json.html, pandas.DataFrame.to_json
">>> result = df.to_json(orient=""index"")
>>> parsed = loads(result)
>>> dumps(parsed, indent=4)  
{
    ""row 1"": {
        ""col 1"": ""a"",
        ""col 2"": ""b""
    },
    ""row 2"": {
        ""col 1"": ""c"",
        ""col 2"": ""d""
    }
}
",https://pandas.pydata.org/docs/reference/api/pandas.Series.to_json.html, pandas.DataFrame.to_json
">>> result = df.to_json(orient=""columns"")
>>> parsed = loads(result)
>>> dumps(parsed, indent=4)  
{
    ""col 1"": {
        ""row 1"": ""a"",
        ""row 2"": ""c""
    },
    ""col 2"": {
        ""row 1"": ""b"",
        ""row 2"": ""d""
    }
}
",https://pandas.pydata.org/docs/reference/api/pandas.Series.to_json.html, pandas.DataFrame.to_json
">>> result = df.to_json(orient=""values"")
>>> parsed = loads(result)
>>> dumps(parsed, indent=4)  
[
    [
        ""a"",
        ""b""
    ],
    [
        ""c"",
        ""d""
    ]
]
",https://pandas.pydata.org/docs/reference/api/pandas.Series.to_json.html, pandas.DataFrame.to_json
">>> result = df.to_json(orient=""table"")
>>> parsed = loads(result)
>>> dumps(parsed, indent=4)  
{
    ""schema"": {
        ""fields"": [
            {
                ""name"": ""index"",
                ""type"": ""string""
            },
            {
                ""name"": ""col 1"",
                ""type"": ""string""
            },
            {
                ""name"": ""col 2"",
                ""type"": ""string""
            }
        ],
        ""primaryKey"": [
            ""index""
        ],
        ""pandas_version"": ""1.4.0""
    },
    ""data"": [
        {
            ""index"": ""row 1"",
            ""col 1"": ""a"",
            ""col 2"": ""b""
        },
        {
            ""index"": ""row 2"",
            ""col 1"": ""c"",
            ""col 2"": ""d""
        }
    ]
}
",https://pandas.pydata.org/docs/reference/api/pandas.Series.to_json.html, pandas.DataFrame.to_json
">>> idx = pd.PeriodIndex(['2023', '2024', '2025'], freq='Y')
>>> s1 = pd.Series([1, 2, 3], index=idx)
>>> s1
2023    1
2024    2
2025    3
Freq: Y-DEC, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.to_timestamp.html, pandas.PeriodIndex pandas.Series
">>> s1 = s1.to_timestamp()
>>> s1
2023-01-01    1
2024-01-01    2
2025-01-01    3
Freq: YS-JAN, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.to_timestamp.html, pandas.Series.to_timestamp
">>> s2 = pd.Series([1, 2, 3], index=idx)
>>> s2 = s2.to_timestamp(freq='M')
>>> s2
2023-01-31    1
2024-01-31    2
2025-01-31    3
Freq: YE-JAN, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.to_timestamp.html, pandas.Series pandas.Series.to_timestamp
">>> tz_naive = pd.date_range('2018-03-01 09:00', periods=3)
>>> tz_naive
DatetimeIndex(['2018-03-01 09:00:00', '2018-03-02 09:00:00',
               '2018-03-03 09:00:00'],
              dtype='datetime64[ns]', freq='D')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.tz_localize.html, pandas.date_range pandas.DatetimeIndex
">>> tz_aware = tz_naive.tz_localize(tz='US/Eastern')
>>> tz_aware
DatetimeIndex(['2018-03-01 09:00:00-05:00',
               '2018-03-02 09:00:00-05:00',
               '2018-03-03 09:00:00-05:00'],
              dtype='datetime64[ns, US/Eastern]', freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.tz_localize.html, pandas.DatetimeIndex
">>> tz_aware.tz_localize(None)
DatetimeIndex(['2018-03-01 09:00:00', '2018-03-02 09:00:00',
               '2018-03-03 09:00:00'],
              dtype='datetime64[ns]', freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.tz_localize.html, pandas.DatetimeIndex
">>> s = pd.to_datetime(pd.Series(['2018-10-28 01:30:00',
...                               '2018-10-28 02:00:00',
...                               '2018-10-28 02:30:00',
...                               '2018-10-28 02:00:00',
...                               '2018-10-28 02:30:00',
...                               '2018-10-28 03:00:00',
...                               '2018-10-28 03:30:00']))
>>> s.dt.tz_localize('CET', ambiguous='infer')
0   2018-10-28 01:30:00+02:00
1   2018-10-28 02:00:00+02:00
2   2018-10-28 02:30:00+02:00
3   2018-10-28 02:00:00+01:00
4   2018-10-28 02:30:00+01:00
5   2018-10-28 03:00:00+01:00
6   2018-10-28 03:30:00+01:00
dtype: datetime64[ns, CET]
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.tz_localize.html, pandas.to_datetime pandas.Series pandas.Series.dt.tz_localize
">>> s = pd.to_datetime(pd.Series(['2018-10-28 01:20:00',
...                               '2018-10-28 02:36:00',
...                               '2018-10-28 03:46:00']))
>>> s.dt.tz_localize('CET', ambiguous=np.array([True, True, False]))
0   2018-10-28 01:20:00+02:00
1   2018-10-28 02:36:00+02:00
2   2018-10-28 03:46:00+01:00
dtype: datetime64[ns, CET]
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.tz_localize.html, pandas.to_datetime pandas.Series pandas.Series.dt.tz_localize
">>> s = pd.to_datetime(pd.Series(['2015-03-29 02:30:00',
...                               '2015-03-29 03:30:00']))
>>> s.dt.tz_localize('Europe/Warsaw', nonexistent='shift_forward')
0   2015-03-29 03:00:00+02:00
1   2015-03-29 03:30:00+02:00
dtype: datetime64[ns, Europe/Warsaw]
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.tz_localize.html, pandas.to_datetime pandas.Series pandas.Series.dt.tz_localize
">>> s.dt.tz_localize('Europe/Warsaw', nonexistent='shift_backward')
0   2015-03-29 01:59:59.999999999+01:00
1   2015-03-29 03:30:00+02:00
dtype: datetime64[ns, Europe/Warsaw]
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.tz_localize.html, pandas.Series.dt.tz_localize
">>> s.dt.tz_localize('Europe/Warsaw', nonexistent=pd.Timedelta('1h'))
0   2015-03-29 03:30:00+02:00
1   2015-03-29 03:30:00+02:00
dtype: datetime64[ns, Europe/Warsaw]
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.tz_localize.html, pandas.Series.dt.tz_localize
">>> datetime_series = pd.Series(
...     pd.date_range(""2000-01-01"", periods=3, freq=""us"")
... )
>>> datetime_series
0   2000-01-01 00:00:00.000000
1   2000-01-01 00:00:00.000001
2   2000-01-01 00:00:00.000002
dtype: datetime64[ns]
>>> datetime_series.dt.microsecond
0       0
1       1
2       2
dtype: int32
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.microsecond.html, pandas.Series pandas.date_range
">>> s = pd.Series([1, 3, 5, 7, 7])
>>> s
0    1
1    3
2    5
3    7
4    7
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.nunique.html, pandas.Series
">>> s.nunique()
4
",https://pandas.pydata.org/docs/reference/api/pandas.Series.nunique.html, pandas.Series.nunique
">>> s = pd.Series([1, 2, 3])
>>> s
0    1
1    2
2    3
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.set_axis.html, pandas.Series
">>> s.set_axis(['a', 'b', 'c'], axis=0)
a    1
b    2
c    3
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.set_axis.html, pandas.Series.set_axis
">>> import pyarrow as pa
>>> s = pd.Series(
...     [
...         {""version"": 1, ""project"": ""pandas""},
...         {""version"": 2, ""project"": ""pandas""},
...         {""version"": 1, ""project"": ""numpy""},
...     ],
...     dtype=pd.ArrowDtype(pa.struct(
...         [(""version"", pa.int64()), (""project"", pa.string())]
...     ))
... )
>>> s.struct.dtypes
version     int64[pyarrow]
project    string[pyarrow]
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.struct.dtypes.html, pandas.Series pandas.ArrowDtype
">>> i = pd.date_range('2018-04-09', periods=4, freq='2D')
>>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)
>>> ts
            A
2018-04-09  1
2018-04-11  2
2018-04-13  3
2018-04-15  4
",https://pandas.pydata.org/docs/reference/api/pandas.Series.first.html, pandas.date_range pandas.DataFrame
">>> ts.first('3D')
            A
2018-04-09  1
2018-04-11  2
",https://pandas.pydata.org/docs/reference/api/pandas.Series.first.html, pandas.DataFrame.first
">>> idx = pd.MultiIndex.from_arrays([
...     ['warm', 'warm', 'cold', 'cold'],
...     ['dog', 'falcon', 'fish', 'spider']],
...     names=['blooded', 'animal'])
>>> s = pd.Series([4, 2, 0, 8], name='legs', index=idx)
>>> s
blooded  animal
warm     dog       4
         falcon    2
cold     fish      0
         spider    8
Name: legs, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.min.html, pandas.MultiIndex.from_arrays pandas.Series
">>> s.min()
0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.min.html, pandas.Series.min
">>> ser = pd.to_datetime(pd.Series([""2010-01-01"", pd.NaT]))
>>> ser.dt.isocalendar()
   year  week  day
0  2009    53     5
1      
>>> ser.dt.isocalendar().week
0      53
1    
Name: week, dtype: UInt32
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.isocalendar.html, pandas.to_datetime pandas.Series pandas.Series.dt.isocalendar
">>> pd.Series(['foo', 'fuz', np.nan]).str.replace('f.', 'ba', regex=True)
0    bao
1    baz
2    NaN
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.replace.html, pandas.Series
">>> pd.Series(['f.o', 'fuz', np.nan]).str.replace('f.', 'ba', regex=False)
0    bao
1    fuz
2    NaN
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.replace.html, pandas.Series
">>> pd.Series(['foo', 'fuz', np.nan]).str.replace('f', repr, regex=True)
0    oo
1    uz
2                                            NaN
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.replace.html, pandas.Series
">>> repl = lambda m: m.group(0)[::-1]
>>> ser = pd.Series(['foo 123', 'bar baz', np.nan])
>>> ser.str.replace(r'[a-z]+', repl, regex=True)
0    oof 123
1    rab zab
2        NaN
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.replace.html, pandas.Series pandas.Series.str.replace
">>> pat = r""(?P\w+) (?P\w+) (?P\w+)""
>>> repl = lambda m: m.group('two').swapcase()
>>> ser = pd.Series(['One Two Three', 'Foo Bar Baz'])
>>> ser.str.replace(pat, repl, regex=True)
0    tWO
1    bAR
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.replace.html, pandas.Series.str.swapcase pandas.Series pandas.Series.str.replace
">>> import re
>>> regex_pat = re.compile(r'FUZ', flags=re.IGNORECASE)
>>> pd.Series(['foo', 'fuz', np.nan]).str.replace(regex_pat, 'bar', regex=True)
0    foo
1    bar
2    NaN
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.replace.html, pandas.Series
">>> df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],
...                   index=['cobra', 'viper', 'sidewinder'],
...                   columns=['max_speed', 'shield'])
>>> df
            max_speed  shield
cobra               1       2
viper               4       5
sidewinder          7       8
",https://pandas.pydata.org/docs/reference/api/pandas.Series.loc.html, pandas.DataFrame
">>> df.loc[pd.Series([False, True, False],
...                  index=['viper', 'sidewinder', 'cobra'])]
                     max_speed  shield
sidewinder          7       8
",https://pandas.pydata.org/docs/reference/api/pandas.Series.loc.html, pandas.Series
">>> df.loc[pd.Index([""cobra"", ""viper""], name=""foo"")]
       max_speed  shield
foo
cobra          1       2
viper          4       5
",https://pandas.pydata.org/docs/reference/api/pandas.Series.loc.html, pandas.Index
">>> df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],
...                   index=[7, 8, 9], columns=['max_speed', 'shield'])
>>> df
   max_speed  shield
7          1       2
8          4       5
9          7       8
",https://pandas.pydata.org/docs/reference/api/pandas.Series.loc.html, pandas.DataFrame
">>> tuples = [
...     ('cobra', 'mark i'), ('cobra', 'mark ii'),
...     ('sidewinder', 'mark i'), ('sidewinder', 'mark ii'),
...     ('viper', 'mark ii'), ('viper', 'mark iii')
... ]
>>> index = pd.MultiIndex.from_tuples(tuples)
>>> values = [[12, 2], [0, 4], [10, 20],
...           [1, 4], [7, 1], [16, 36]]
>>> df = pd.DataFrame(values, columns=['max_speed', 'shield'], index=index)
>>> df
                     max_speed  shield
cobra      mark i           12       2
           mark ii           0       4
sidewinder mark i           10      20
           mark ii           1       4
viper      mark ii           7       1
           mark iii         16      36
",https://pandas.pydata.org/docs/reference/api/pandas.Series.loc.html, pandas.MultiIndex.from_tuples pandas.DataFrame
">>> pd.Series([], dtype=""float64"").prod()
1.0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.prod.html, pandas.Series
">>> pd.Series([], dtype=""float64"").prod(min_count=1)
nan
",https://pandas.pydata.org/docs/reference/api/pandas.Series.prod.html, pandas.Series
">>> pd.Series([np.nan]).prod()
1.0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.prod.html, pandas.Series
">>> pd.Series([np.nan]).prod(min_count=1)
nan
",https://pandas.pydata.org/docs/reference/api/pandas.Series.prod.html, pandas.Series
">>> ser = pd.Series([""horse"", ""eagle"", ""donkey""])
>>> ser.str.index(""e"")
0   4
1   0
2   4
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.rindex.html, pandas.Series pandas.Series.str.index
">>> ser = pd.Series([""Deer"", ""eagle"", ""Sheep""])
>>> ser.str.rindex(""e"")
0   2
1   4
2   3
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.rindex.html, pandas.Series pandas.Series.str.rindex
">>> s = pd.Series([""1/1/2020 10:00:00+00:00"", ""4/1/2020 11:00:00+00:00""])
>>> s = pd.to_datetime(s)
>>> s
0   2020-01-01 10:00:00+00:00
1   2020-04-01 11:00:00+00:00
dtype: datetime64[ns, UTC]
>>> s.dt.quarter
0    1
1    2
dtype: int32
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.quarter.html, pandas.Series pandas.to_datetime
">>> idx = pd.DatetimeIndex([""1/1/2020 10:00:00+00:00"",
...                         ""2/1/2020 11:00:00+00:00""])
>>> idx.quarter
Index([1, 1], dtype='int32')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.quarter.html, pandas.DatetimeIndex pandas.Index
">>> df = pd.DataFrame([('falcon', 'bird', 389.0, 2),
...                    ('parrot', 'bird', 24.0, 2),
...                    ('lion', 'mammal', 80.5, 4),
...                    ('monkey', 'mammal', np.nan, 4)],
...                   columns=['name', 'class', 'max_speed',
...                            'num_legs'])
>>> df
     name   class  max_speed  num_legs
0  falcon    bird      389.0         2
1  parrot    bird       24.0         2
2    lion  mammal       80.5         4
3  monkey  mammal        NaN         4
",https://pandas.pydata.org/docs/reference/api/pandas.Series.to_xarray.html, pandas.DataFrame
">>> df.to_xarray()  

Dimensions:    (index: 4)
Coordinates:
  * index      (index) int64 32B 0 1 2 3
Data variables:
    name       (index) object 32B 'falcon' 'parrot' 'lion' 'monkey'
    class      (index) object 32B 'bird' 'bird' 'mammal' 'mammal'
    max_speed  (index) float64 32B 389.0 24.0 80.5 nan
    num_legs   (index) int64 32B 2 2 4 4
",https://pandas.pydata.org/docs/reference/api/pandas.Series.to_xarray.html, pandas.DataFrame.to_xarray
">>> df['max_speed'].to_xarray()  

array([389. ,  24. ,  80.5,   nan])
Coordinates:
  * index    (index) int64 0 1 2 3
",https://pandas.pydata.org/docs/reference/api/pandas.Series.to_xarray.html, pandas.array
">>> dates = pd.to_datetime(['2018-01-01', '2018-01-01',
...                         '2018-01-02', '2018-01-02'])
>>> df_multiindex = pd.DataFrame({'date': dates,
...                               'animal': ['falcon', 'parrot',
...                                          'falcon', 'parrot'],
...                               'speed': [350, 18, 361, 15]})
>>> df_multiindex = df_multiindex.set_index(['date', 'animal'])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.to_xarray.html, pandas.to_datetime pandas.DataFrame pandas.DataFrame.set_index
">>> df_multiindex.to_xarray()  

Dimensions:  (date: 2, animal: 2)
Coordinates:
  * date     (date) datetime64[ns] 2018-01-01 2018-01-02
  * animal   (animal) object 'falcon' 'parrot'
Data variables:
    speed    (date, animal) int64 350 18 361 15
",https://pandas.pydata.org/docs/reference/api/pandas.Series.to_xarray.html, pandas.DataFrame.to_xarray
">>> s = pd.Series([1, 2, 2.5, 3, 3.5, 4, 5])
>>> ax = s.plot.kde()
",https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.kde.html, pandas.Series pandas.Series.plot.kde
">>> ax = s.plot.kde(bw_method=0.3)
",https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.kde.html, pandas.Series.plot.kde
">>> ax = s.plot.kde(bw_method=3)
",https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.kde.html, pandas.Series.plot.kde
">>> ax = s.plot.kde(ind=[1, 2, 3, 4, 5])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.kde.html, pandas.Series.plot.kde
">>> df = pd.DataFrame({
...     'x': [1, 2, 2.5, 3, 3.5, 4, 5],
...     'y': [4, 4, 4.5, 5, 5.5, 6, 6],
... })
>>> ax = df.plot.kde()
",https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.kde.html, pandas.DataFrame pandas.DataFrame.plot.kde
">>> ax = df.plot.kde(bw_method=0.3)
",https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.kde.html, pandas.DataFrame.plot.kde
">>> ax = df.plot.kde(bw_method=3)
",https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.kde.html, pandas.DataFrame.plot.kde
">>> ax = df.plot.kde(ind=[1, 2, 3, 4, 5, 6])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.kde.html, pandas.DataFrame.plot.kde
">>> ser = pd.Series([1, 2, 3]).to_string()
>>> ser
'0    1\n1    2\n2    3'
",https://pandas.pydata.org/docs/reference/api/pandas.Series.to_string.html, pandas.Series
">>> ser = pd.Series([""El niño"", ""Françoise""])
>>> mytable = str.maketrans({'ñ': 'n', 'ç': 'c'})
>>> ser.str.translate(mytable)
0   El nino
1   Francoise
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.translate.html, pandas.Series pandas.Series.str.translate
">>> s = pd.Series([""A_Str_Series""])
>>> s
0    A_Str_Series
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Index.str.html, pandas.Series
">>> s.str.split(""_"")
0    [A, Str, Series]
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Index.str.html, pandas.Series.str.split
">>> s.str.replace(""_"", """")
0    AStrSeries
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Index.str.html, pandas.Series.str.replace
">>> ser = pd.Series([1, 2, 3])
>>> ser.attrs = {""A"": [10, 20, 30]}
>>> ser.attrs
{'A': [10, 20, 30]}
",https://pandas.pydata.org/docs/reference/api/pandas.Series.attrs.html, pandas.Series
">>> df = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})
>>> df.attrs = {""A"": [10, 20, 30]}
>>> df.attrs
{'A': [10, 20, 30]}
",https://pandas.pydata.org/docs/reference/api/pandas.Series.attrs.html, pandas.DataFrame
">>> ser = pd.Series(pd.to_timedelta([1, 2, 3], unit='ns'))
>>> ser
0   0 days 00:00:00.000000001
1   0 days 00:00:00.000000002
2   0 days 00:00:00.000000003
dtype: timedelta64[ns]
>>> ser.dt.nanoseconds
0    1
1    2
2    3
dtype: int32
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.nanoseconds.html, pandas.Series pandas.to_timedelta
">>> tdelta_idx = pd.to_timedelta([1, 2, 3], unit='ns')
>>> tdelta_idx
TimedeltaIndex(['0 days 00:00:00.000000001', '0 days 00:00:00.000000002',
                '0 days 00:00:00.000000003'],
               dtype='timedelta64[ns]', freq=None)
>>> tdelta_idx.nanoseconds
Index([1, 2, 3], dtype='int32')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.nanoseconds.html, pandas.to_timedelta pandas.TimedeltaIndex pandas.Index
">>> s = pd.Series(['Linda van der Berg', 'George Pitt-Rivers'])
>>> s
0    Linda van der Berg
1    George Pitt-Rivers
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.partition.html, pandas.Series
">>> s.str.partition()
        0  1             2
0   Linda     van der Berg
1  George      Pitt-Rivers
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.partition.html, pandas.Series.str.partition
">>> s.str.rpartition()
               0  1            2
0  Linda van der            Berg
1         George     Pitt-Rivers
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.partition.html, pandas.Series.str.rpartition
">>> s.str.partition('-')
                    0  1       2
0  Linda van der Berg
1         George Pitt  -  Rivers
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.partition.html, pandas.Series.str.partition
">>> s.str.partition('-', expand=False)
0    (Linda van der Berg, , )
1    (George Pitt, -, Rivers)
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.partition.html, pandas.Series.str.partition
">>> idx = pd.Index(['X 123', 'Y 999'])
>>> idx
Index(['X 123', 'Y 999'], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.partition.html, pandas.Index pandas.Index
">>> idx.str.partition()
MultiIndex([('X', ' ', '123'),
            ('Y', ' ', '999')],
           )
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.partition.html, pandas.MultiIndex
">>> idx.str.partition(expand=False)
Index([('X', ' ', '123'), ('Y', ' ', '999')], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.partition.html, pandas.Index
">>> s = pd.Series(['bat', 'Bear', 'cat', np.nan])
>>> s
0     bat
1    Bear
2     cat
3     NaN
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.startswith.html, pandas.Series
">>> s.str.startswith('b')
0     True
1    False
2    False
3      NaN
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.startswith.html, pandas.Series.str.startswith
">>> s.str.startswith(('b', 'B'))
0     True
1     True
2    False
3      NaN
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.startswith.html, pandas.Series.str.startswith
">>> s.str.startswith('b', na=False)
0     True
1    False
2    False
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.startswith.html, pandas.Series.str.startswith
">>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])
>>> a
a    1.0
b    1.0
c    1.0
d    NaN
dtype: float64
>>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])
>>> b
a    1.0
b    NaN
d    1.0
e    NaN
dtype: float64
>>> a.divide(b, fill_value=0)
a    1.0
b    inf
c    inf
d    0.0
e    NaN
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.truediv.html, pandas.Series
">>> s = pd.Series([1, 2, 3])
>>> s.sem().round(6)
0.57735
",https://pandas.pydata.org/docs/reference/api/pandas.Series.sem.html, pandas.Series pandas.Series.sem
">>> df = pd.DataFrame({'a': [1, 2], 'b': [2, 3]}, index=['tiger', 'zebra'])
>>> df
       a   b
tiger  1   2
zebra  2   3
>>> df.sem()
a   0.5
b   0.5
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.sem.html, pandas.DataFrame pandas.DataFrame.sem
">>> df.sem(axis=1)
tiger   0.5
zebra   0.5
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.sem.html, pandas.DataFrame.sem
">>> df = pd.DataFrame({'a': [1, 2], 'b': ['T', 'Z']},
...                   index=['tiger', 'zebra'])
>>> df.sem(numeric_only=True)
a   0.5
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.sem.html, pandas.DataFrame pandas.DataFrame.sem
">>> ser = pd.Series([1, 2, 3, 3])
>>> plot = ser.plot(kind='hist', title=""My plot"")
",https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.html, pandas.Series pandas.Series.plot
">>> df = pd.DataFrame({'length': [1.5, 0.5, 1.2, 0.9, 3],
...                   'width': [0.7, 0.2, 0.15, 0.2, 1.1]},
...                   index=['pig', 'rabbit', 'duck', 'chicken', 'horse'])
>>> plot = df.plot(title=""DataFrame Plot"")
",https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.html, pandas.DataFrame pandas.DataFrame.plot
">>> lst = [-1, -2, -3, 1, 2, 3]
>>> ser = pd.Series([1, 2, 2, 4, 6, 6], index=lst)
>>> plot = ser.groupby(lambda x: x > 0).plot(title=""SeriesGroupBy Plot"")
",https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.html, pandas.Series pandas.Series.groupby
">>> df = pd.DataFrame({""col1"" : [1, 2, 3, 4],
...                   ""col2"" : [""A"", ""B"", ""A"", ""B""]})
>>> plot = df.groupby(""col2"").plot(kind=""bar"", title=""DataFrameGroupBy Plot"")
",https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.html, pandas.DataFrame pandas.DataFrame.groupby
">>> s = pd.Series([2, np.nan, 5, -1, 0])
>>> s
0    2.0
1    NaN
2    5.0
3   -1.0
4    0.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cummax.html, pandas.Series
">>> s.cummax()
0    2.0
1    NaN
2    5.0
3    5.0
4    5.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cummax.html, pandas.Series.cummax
">>> s.cummax(skipna=False)
0    2.0
1    NaN
2    NaN
3    NaN
4    NaN
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cummax.html, pandas.Series.cummax
">>> df = pd.DataFrame([[2.0, 1.0],
...                    [3.0, np.nan],
...                    [1.0, 0.0]],
...                   columns=list('AB'))
>>> df
     A    B
0  2.0  1.0
1  3.0  NaN
2  1.0  0.0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cummax.html, pandas.DataFrame
">>> df.cummax()
     A    B
0  2.0  1.0
1  3.0  NaN
2  3.0  1.0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cummax.html, pandas.DataFrame.cummax
">>> df.cummax(axis=1)
     A    B
0  2.0  2.0
1  3.0  NaN
2  1.0  1.0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cummax.html, pandas.DataFrame.cummax
">>> s = pd.Series(['Ant', 'Bear', 'Cow'])
>>> s
0     Ant
1    Bear
2     Cow
dtype: object
>>> s.ndim
1
",https://pandas.pydata.org/docs/reference/api/pandas.Series.ndim.html, pandas.Series
">>> idx = pd.Index([1, 2, 3])
>>> idx
Index([1, 2, 3], dtype='int64')
>>> idx.ndim
1
",https://pandas.pydata.org/docs/reference/api/pandas.Series.ndim.html, pandas.Index pandas.Index
">>> pd.Series([1, 2, 3]).array

[1, 2, 3]
Length: 3, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.array.html, pandas.Series
">>> ser = pd.Series(pd.Categorical(['a', 'b', 'a']))
>>> ser.array
['a', 'b', 'a']
Categories (2, object): ['a', 'b']
",https://pandas.pydata.org/docs/reference/api/pandas.Series.array.html, pandas.Series pandas.Categorical
">>> s1 = pd.Series([0.90010907, 0.13484424, 0.62036035])
>>> s2 = pd.Series([0.12528585, 0.26962463, 0.51111198])
>>> s1.cov(s2)
-0.01685762652715874
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cov.html, pandas.Series pandas.Series.cov
">>> a = pd.Series([1, 1, 1, np.nan, 1], index=['a', 'b', 'c', 'd', 'e'])
>>> a
a    1.0
b    1.0
c    1.0
d    NaN
e    1.0
dtype: float64
>>> b = pd.Series([0, 1, 2, np.nan, 1], index=['a', 'b', 'c', 'd', 'f'])
>>> b
a    0.0
b    1.0
c    2.0
d    NaN
f    1.0
dtype: float64
>>> a.gt(b, fill_value=0)
a     True
b    False
c    False
d    False
e     True
f    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.gt.html, pandas.Series pandas.Series.gt
">>> s = pd.Series([""1/1/2020 10:00:00+00:00"", ""2/1/2020 11:00:00+00:00""])
>>> s = pd.to_datetime(s)
>>> s
0   2020-01-01 10:00:00+00:00
1   2020-02-01 11:00:00+00:00
dtype: datetime64[ns, UTC]
>>> s.dt.timetz
0    10:00:00+00:00
1    11:00:00+00:00
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.timetz.html, pandas.Series pandas.to_datetime
">>> idx = pd.DatetimeIndex([""1/1/2020 10:00:00+00:00"",
...                         ""2/1/2020 11:00:00+00:00""])
>>> idx.timetz
array([datetime.time(10, 0, tzinfo=datetime.timezone.utc),
datetime.time(11, 0, tzinfo=datetime.timezone.utc)], dtype=object)
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.timetz.html, pandas.DatetimeIndex pandas.array pandas.Timestamp.time
">>> s = pd.Series([""1/1/2020 10:00:00+00:00"", ""2/1/2020 11:00:00+00:00""])
>>> s = pd.to_datetime(s)
>>> s
0   2020-01-01 10:00:00+00:00
1   2020-02-01 11:00:00+00:00
dtype: datetime64[ns, UTC]
>>> s.dt.tz
datetime.timezone.utc
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.tz.html, pandas.Series pandas.to_datetime
">>> idx = pd.DatetimeIndex([""1/1/2020 10:00:00+00:00"",
...                         ""2/1/2020 11:00:00+00:00""])
>>> idx.tz
datetime.timezone.utc
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.tz.html, pandas.DatetimeIndex
">>> lst = ['a', 'a', 'a', 'b', 'b', 'b']
>>> ser = pd.Series([1, 2, 2, 4, 6, 6], index=lst)
>>> hist = ser.hist()
",https://pandas.pydata.org/docs/reference/api/pandas.Series.hist.html, pandas.Series pandas.Series.hist
">>> lst = ['a', 'a', 'a', 'b', 'b', 'b']
>>> ser = pd.Series([1, 2, 2, 4, 6, 6], index=lst)
>>> hist = ser.groupby(level=0).hist()
",https://pandas.pydata.org/docs/reference/api/pandas.Series.hist.html, pandas.Series pandas.Series.groupby
">>> raw_cat = pd.Categorical(['a', 'b', 'c', 'A'],
...                           categories=['a', 'b', 'c'], ordered=True)
>>> ser = pd.Series(raw_cat)
>>> ser
0   a
1   b
2   c
3   NaN
dtype: category
Categories (3, object): ['a' < 'b' < 'c']
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.set_categories.html, pandas.Categorical pandas.Series
">>> ser.cat.set_categories(['A', 'B', 'C'], rename=True)
0   A
1   B
2   C
3   NaN
dtype: category
Categories (3, object): ['A' < 'B' < 'C']
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.set_categories.html, pandas.Series.cat.set_categories
">>> ci = pd.CategoricalIndex(['a', 'b', 'c', 'A'],
...                          categories=['a', 'b', 'c'], ordered=True)
>>> ci
CategoricalIndex(['a', 'b', 'c', nan], categories=['a', 'b', 'c'],
                 ordered=True, dtype='category')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.set_categories.html, pandas.CategoricalIndex pandas.CategoricalIndex
">>> ci.set_categories(['A', 'b', 'c'])
CategoricalIndex([nan, 'b', 'c', nan], categories=['A', 'b', 'c'],
                 ordered=True, dtype='category')
>>> ci.set_categories(['A', 'b', 'c'], rename=True)
CategoricalIndex(['A', 'b', 'c', nan], categories=['A', 'b', 'c'],
                 ordered=True, dtype='category')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.set_categories.html, pandas.CategoricalIndex.set_categories pandas.CategoricalIndex
">>> df1 = pd.DataFrame([['a', 'b'], ['c', 'd']],
...                    index=['row 1', 'row 2'],
...                    columns=['col 1', 'col 2'])
>>> df1.to_excel(""output.xlsx"")  
",https://pandas.pydata.org/docs/reference/api/pandas.Series.to_excel.html, pandas.DataFrame pandas.DataFrame.to_excel
">>> df1.to_excel(""output.xlsx"",
...              sheet_name='Sheet_name_1')  
",https://pandas.pydata.org/docs/reference/api/pandas.Series.to_excel.html, pandas.DataFrame.to_excel
">>> df2 = df1.copy()
>>> with pd.ExcelWriter('output.xlsx') as writer:  
...     df1.to_excel(writer, sheet_name='Sheet_name_1')
...     df2.to_excel(writer, sheet_name='Sheet_name_2')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.to_excel.html, pandas.DataFrame.copy pandas.ExcelWriter pandas.DataFrame.to_excel pandas.DataFrame.to_excel
">>> with pd.ExcelWriter('output.xlsx',
...                     mode='a') as writer:  
...     df1.to_excel(writer, sheet_name='Sheet_name_3')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.to_excel.html, pandas.ExcelWriter pandas.DataFrame.to_excel
">>> df1.to_excel('output1.xlsx', engine='xlsxwriter')  
",https://pandas.pydata.org/docs/reference/api/pandas.Series.to_excel.html, pandas.DataFrame.to_excel
">>> ser = pd.Series([0, 0, 2, 2, 2], dtype=""Sparse[int]"")
>>> ser.sparse.density
0.6
>>> ser.sparse.sp_values
array([2, 2, 2])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.sparse.html, pandas.Series pandas.array
">>> ser = pd.Series([0, 0, 2, 2, 2], dtype=""Sparse[int]"")
>>> ser.sparse.fill_value
0
>>> spa_dtype = pd.SparseDtype(dtype=np.int32, fill_value=2)
>>> ser = pd.Series([0, 0, 2, 2, 2], dtype=spa_dtype)
>>> ser.sparse.fill_value
2
",https://pandas.pydata.org/docs/reference/api/pandas.Series.sparse.fill_value.html, pandas.Series
">>> import pyarrow as pa
>>> s = pd.Series(
...     [
...         [1, 2, 3],
...         [3],
...     ],
...     dtype=pd.ArrowDtype(pa.list_(
...         pa.int64()
...     ))
... )
>>> s.list[0]
0    1
1    3
dtype: int64[pyarrow]
",https://pandas.pydata.org/docs/reference/api/pandas.Series.list.__getitem__.html, pandas.Series pandas.ArrowDtype
">>> df = pd.DataFrame({""A"": [""a"", 1, 2, 3]})
>>> df = df.iloc[1:]
>>> df
   A
1  1
2  2
3  3
",https://pandas.pydata.org/docs/reference/api/pandas.Series.infer_objects.html, pandas.DataFrame
">>> df.infer_objects().dtypes
A    int64
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.infer_objects.html, pandas.DataFrame.infer_objects
">>> a = pd.Series([1, 1, 1, np.nan, 1], index=['a', 'b', 'c', 'd', 'e'])
>>> a
a    1.0
b    1.0
c    1.0
d    NaN
e    1.0
dtype: float64
>>> b = pd.Series([0, 1, 2, np.nan, 1], index=['a', 'b', 'c', 'd', 'f'])
>>> b
a    0.0
b    1.0
c    2.0
d    NaN
f    1.0
dtype: float64
>>> a.ge(b, fill_value=0)
a     True
b     True
c    False
d    False
e     True
f    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.ge.html, pandas.Series pandas.Series.ge
">>> ss = pd.Series.sparse.from_coo(A)
>>> ss
0  2    1.0
   3    2.0
1  0    3.0
dtype: Sparse[float64, nan]
",https://pandas.pydata.org/docs/reference/api/pandas.Series.sparse.from_coo.html, pandas.Series.sparse.from_coo
">>> i = pd.date_range('2018-04-09', periods=4, freq='1D20min')
>>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)
>>> ts
                     A
2018-04-09 00:00:00  1
2018-04-10 00:20:00  2
2018-04-11 00:40:00  3
2018-04-12 01:00:00  4
",https://pandas.pydata.org/docs/reference/api/pandas.Series.between_time.html, pandas.date_range pandas.DataFrame
">>> ts.between_time('0:15', '0:45')
                     A
2018-04-10 00:20:00  2
2018-04-11 00:40:00  3
",https://pandas.pydata.org/docs/reference/api/pandas.Series.between_time.html, pandas.DataFrame.between_time
">>> ts.between_time('0:45', '0:15')
                     A
2018-04-09 00:00:00  1
2018-04-12 01:00:00  4
",https://pandas.pydata.org/docs/reference/api/pandas.Series.between_time.html, pandas.DataFrame.between_time
">>> index = pd.Index([3, 1, 2, 3, 4, np.nan])
>>> index.value_counts()
3.0    2
1.0    1
2.0    1
4.0    1
Name: count, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.value_counts.html, pandas.Index pandas.Index.value_counts
">>> s = pd.Series([3, 1, 2, 3, 4, np.nan])
>>> s.value_counts(normalize=True)
3.0    0.4
1.0    0.2
2.0    0.2
4.0    0.2
Name: proportion, dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.value_counts.html, pandas.Series pandas.Series.value_counts
">>> s.value_counts(bins=3)
(0.996, 2.0]    2
(2.0, 3.0]      2
(3.0, 4.0]      1
Name: count, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.value_counts.html, pandas.Series.value_counts
">>> s.value_counts(dropna=False)
3.0    2
1.0    1
2.0    1
4.0    1
NaN    1
Name: count, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.value_counts.html, pandas.Series.value_counts
">>> s = pd.Series(['lower', 'CAPITALS', 'this is a sentence', 'SwApCaSe'])
>>> s
0                 lower
1              CAPITALS
2    this is a sentence
3              SwApCaSe
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.upper.html, pandas.Series
">>> s.str.lower()
0                 lower
1              capitals
2    this is a sentence
3              swapcase
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.upper.html, pandas.Series.str.lower
">>> s.str.upper()
0                 LOWER
1              CAPITALS
2    THIS IS A SENTENCE
3              SWAPCASE
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.upper.html, pandas.Series.str.upper
">>> s.str.title()
0                 Lower
1              Capitals
2    This Is A Sentence
3              Swapcase
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.upper.html, pandas.Series.str.title
">>> s.str.capitalize()
0                 Lower
1              Capitals
2    This is a sentence
3              Swapcase
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.upper.html, pandas.Series.str.capitalize
">>> s.str.swapcase()
0                 LOWER
1              capitals
2    THIS IS A SENTENCE
3              sWaPcAsE
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.upper.html, pandas.Series.str.swapcase
">>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]})
>>> df
     B
0  0.0
1  1.0
2  2.0
3  NaN
4  4.0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.rolling.html, pandas.DataFrame
">>> df.rolling(2).sum()
     B
0  NaN
1  1.0
2  3.0
3  NaN
4  NaN
",https://pandas.pydata.org/docs/reference/api/pandas.Series.rolling.html, pandas.DataFrame.rolling
">>> df_time = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]},
...                        index=[pd.Timestamp('20130101 09:00:00'),
...                               pd.Timestamp('20130101 09:00:02'),
...                               pd.Timestamp('20130101 09:00:03'),
...                               pd.Timestamp('20130101 09:00:05'),
...                               pd.Timestamp('20130101 09:00:06')])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.rolling.html, pandas.DataFrame
">>> df_time.rolling('2s').sum()
                       B
2013-01-01 09:00:00  0.0
2013-01-01 09:00:02  1.0
2013-01-01 09:00:03  3.0
2013-01-01 09:00:05  NaN
2013-01-01 09:00:06  4.0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.rolling.html, pandas.DataFrame.rolling
">>> indexer = pd.api.indexers.FixedForwardWindowIndexer(window_size=2)
>>> df.rolling(window=indexer, min_periods=1).sum()
     B
0  1.0
1  3.0
2  2.0
3  4.0
4  4.0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.rolling.html, pandas.api.indexers.FixedForwardWindowIndexer pandas.DataFrame.rolling
">>> df.rolling(2, min_periods=1).sum()
     B
0  0.0
1  1.0
2  3.0
3  2.0
4  4.0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.rolling.html, pandas.DataFrame.rolling
">>> df.rolling(3, min_periods=1, center=True).sum()
     B
0  1.0
1  3.0
2  3.0
3  6.0
4  4.0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.rolling.html, pandas.DataFrame.rolling
">>> df.rolling(3, min_periods=1, center=False).sum()
     B
0  0.0
1  1.0
2  3.0
3  3.0
4  6.0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.rolling.html, pandas.DataFrame.rolling
">>> df.rolling(2, min_periods=1, step=2).sum()
     B
0  0.0
2  3.0
4  4.0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.rolling.html, pandas.DataFrame.rolling
">>> df.rolling(2, win_type='gaussian').sum(std=3)
          B
0       NaN
1  0.986207
2  2.958621
3       NaN
4       NaN
",https://pandas.pydata.org/docs/reference/api/pandas.Series.rolling.html, pandas.DataFrame.rolling
">>> df = pd.DataFrame({
...     'A': [pd.to_datetime('2020-01-01'),
...           pd.to_datetime('2020-01-01'),
...           pd.to_datetime('2020-01-02'),],
...     'B': [1, 2, 3], },
...     index=pd.date_range('2020', periods=3))
",https://pandas.pydata.org/docs/reference/api/pandas.Series.rolling.html, pandas.DataFrame pandas.to_datetime pandas.date_range
">>> df.rolling('2D', on='A').sum()
                    A    B
2020-01-01 2020-01-01  1.0
2020-01-02 2020-01-01  3.0
2020-01-03 2020-01-02  6.0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.rolling.html, pandas.DataFrame.rolling
">>> s = pd.Series([0, 1, np.nan, 3])
>>> s
0    0.0
1    1.0
2    NaN
3    3.0
dtype: float64
>>> s.interpolate()
0    0.0
1    1.0
2    2.0
3    3.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.interpolate.html, pandas.Series pandas.Series.interpolate
">>> s = pd.Series([0, 2, np.nan, 8])
>>> s.interpolate(method='polynomial', order=2)
0    0.000000
1    2.000000
2    4.666667
3    8.000000
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.interpolate.html, pandas.Series pandas.Series.interpolate
">>> df = pd.DataFrame([(0.0, np.nan, -1.0, 1.0),
...                    (np.nan, 2.0, np.nan, np.nan),
...                    (2.0, 3.0, np.nan, 9.0),
...                    (np.nan, 4.0, -4.0, 16.0)],
...                   columns=list('abcd'))
>>> df
     a    b    c     d
0  0.0  NaN -1.0   1.0
1  NaN  2.0  NaN   NaN
2  2.0  3.0  NaN   9.0
3  NaN  4.0 -4.0  16.0
>>> df.interpolate(method='linear', limit_direction='forward', axis=0)
     a    b    c     d
0  0.0  NaN -1.0   1.0
1  1.0  2.0 -2.0   5.0
2  2.0  3.0 -3.0   9.0
3  2.0  4.0 -4.0  16.0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.interpolate.html, pandas.DataFrame pandas.DataFrame.interpolate
">>> c = pd.Categorical(['a', 'a', 'b'])
>>> c.rename_categories([0, 1])
[0, 0, 1]
Categories (2, int64): [0, 1]
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.rename_categories.html, pandas.Categorical
">>> s = pd.Series(pd.to_timedelta(np.arange(5), unit=""d""))
>>> s
0   0 days
1   1 days
2   2 days
3   3 days
4   4 days
dtype: timedelta64[ns]
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.to_pytimedelta.html, pandas.Series pandas.to_timedelta
">>> s.dt.to_pytimedelta()
array([datetime.timedelta(0), datetime.timedelta(days=1),
datetime.timedelta(days=2), datetime.timedelta(days=3),
datetime.timedelta(days=4)], dtype=object)
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.to_pytimedelta.html, pandas.Series.dt.to_pytimedelta pandas.array
">>> df = pd.DataFrame(dict(age=[5, 6, np.nan],
...                        born=[pd.NaT, pd.Timestamp('1939-05-27'),
...                              pd.Timestamp('1940-04-25')],
...                        name=['Alfred', 'Batman', ''],
...                        toy=[None, 'Batmobile', 'Joker']))
>>> df
   age       born    name        toy
0  5.0        NaT  Alfred       None
1  6.0 1939-05-27  Batman  Batmobile
2  NaN 1940-04-25              Joker
",https://pandas.pydata.org/docs/reference/api/pandas.Series.notna.html, pandas.DataFrame
">>> df.notna()
     age   born  name    toy
0   True  False  True  False
1   True   True  True   True
2  False   True  True   True
",https://pandas.pydata.org/docs/reference/api/pandas.Series.notna.html, pandas.DataFrame.notna
">>> ser = pd.Series([5, 6, np.nan])
>>> ser
0    5.0
1    6.0
2    NaN
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.notna.html, pandas.Series
">>> ser.notna()
0     True
1     True
2    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.notna.html, pandas.Series.notna
">>> s = pd.Series([1, 2, 3, 4])
>>> s.quantile(.5)
2.5
>>> s.quantile([.25, .5, .75])
0.25    1.75
0.50    2.50
0.75    3.25
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.quantile.html, pandas.Series pandas.Series.quantile
">>> a = pd.Series([1, 1, 1, np.nan, 1], index=['a', 'b', 'c', 'd', 'e'])
>>> a
a    1.0
b    1.0
c    1.0
d    NaN
e    1.0
dtype: float64
>>> b = pd.Series([0, 1, 2, np.nan, 1], index=['a', 'b', 'c', 'd', 'f'])
>>> b
a    0.0
b    1.0
c    2.0
d    NaN
f    1.0
dtype: float64
>>> a.lt(b, fill_value=0)
a    False
b    False
c     True
d    False
e    False
f     True
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.lt.html, pandas.Series pandas.Series.lt
">>> s = pd.Series([2, np.nan, 5, -1, 0])
>>> s
0    2.0
1    NaN
2    5.0
3   -1.0
4    0.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cumsum.html, pandas.Series
">>> s.cumsum()
0    2.0
1    NaN
2    7.0
3    6.0
4    6.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cumsum.html, pandas.Series.cumsum
">>> s.cumsum(skipna=False)
0    2.0
1    NaN
2    NaN
3    NaN
4    NaN
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cumsum.html, pandas.Series.cumsum
">>> df = pd.DataFrame([[2.0, 1.0],
...                    [3.0, np.nan],
...                    [1.0, 0.0]],
...                   columns=list('AB'))
>>> df
     A    B
0  2.0  1.0
1  3.0  NaN
2  1.0  0.0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cumsum.html, pandas.DataFrame
">>> df.cumsum()
     A    B
0  2.0  1.0
1  5.0  NaN
2  6.0  1.0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cumsum.html, pandas.DataFrame.cumsum
">>> df.cumsum(axis=1)
     A    B
0  2.0  3.0
1  3.0  NaN
2  1.0  1.0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cumsum.html, pandas.DataFrame.cumsum
">>> s = pd.Series([2, np.nan, 5, -1, 0])
>>> s
0    2.0
1    NaN
2    5.0
3   -1.0
4    0.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cummin.html, pandas.Series
">>> s.cummin()
0    2.0
1    NaN
2    2.0
3   -1.0
4   -1.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cummin.html, pandas.Series.cummin
">>> s.cummin(skipna=False)
0    2.0
1    NaN
2    NaN
3    NaN
4    NaN
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cummin.html, pandas.Series.cummin
">>> df = pd.DataFrame([[2.0, 1.0],
...                    [3.0, np.nan],
...                    [1.0, 0.0]],
...                   columns=list('AB'))
>>> df
     A    B
0  2.0  1.0
1  3.0  NaN
2  1.0  0.0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cummin.html, pandas.DataFrame
">>> df.cummin()
     A    B
0  2.0  1.0
1  2.0  NaN
2  1.0  0.0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cummin.html, pandas.DataFrame.cummin
">>> df.cummin(axis=1)
     A    B
0  2.0  1.0
1  3.0  NaN
2  1.0  0.0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cummin.html, pandas.DataFrame.cummin
">>> ser = pd.Series([""cow_"", ""duck_"", ""do_ve""])
>>> ser.str.find(""_"")
0   3
1   4
2   2
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.rfind.html, pandas.Series pandas.Series.str.find
">>> ser = pd.Series([""_cow_"", ""duck_"", ""do_v_e""])
>>> ser.str.rfind(""_"")
0   4
1   4
2   4
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.rfind.html, pandas.Series pandas.Series.str.rfind
">>> df = pd.DataFrame(dict(name=['Raphael', 'Donatello'],
...                        age=[26, 45],
...                        height=[181.23, 177.65]))
>>> print(df.to_latex(index=False,
...                   formatters={""name"": str.upper},
...                   float_format=""{:.1f}"".format,
... ))  
\begin{tabular}{lrr}
\toprule
name & age & height \\
\midrule
RAPHAEL & 26 & 181.2 \\
DONATELLO & 45 & 177.7 \\
\bottomrule
\end{tabular}
",https://pandas.pydata.org/docs/reference/api/pandas.Series.to_latex.html, pandas.DataFrame pandas.DataFrame.to_latex
">>> df = pd.DataFrame({""B"": [0, 1, 2, np.nan, 4]})
>>> df
     B
0  0.0
1  1.0
2  2.0
3  NaN
4  4.0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.expanding.html, pandas.DataFrame
">>> df.expanding(1).sum()
     B
0  0.0
1  1.0
2  3.0
3  3.0
4  7.0
>>> df.expanding(3).sum()
     B
0  NaN
1  NaN
2  3.0
3  3.0
4  7.0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.expanding.html, pandas.DataFrame.expanding
">>> df = pd.DataFrame({'A': ['a', 'b', 'c', 'd', 'e'],
...                    'B': ['f', 'g', 'h', 'i', 'j'],
...                    'C': ['k', 'l', 'm', 'n', 'o']},
...                   index=[1, 2, 3, 4, 5])
>>> df
   A  B  C
1  a  f  k
2  b  g  l
3  c  h  m
4  d  i  n
5  e  j  o
",https://pandas.pydata.org/docs/reference/api/pandas.Series.truncate.html, pandas.DataFrame
">>> df.truncate(before=2, after=4)
   A  B  C
2  b  g  l
3  c  h  m
4  d  i  n
",https://pandas.pydata.org/docs/reference/api/pandas.Series.truncate.html, pandas.DataFrame.truncate
">>> df.truncate(before=""A"", after=""B"", axis=""columns"")
   A  B
1  a  f
2  b  g
3  c  h
4  d  i
5  e  j
",https://pandas.pydata.org/docs/reference/api/pandas.Series.truncate.html, pandas.DataFrame.truncate
">>> dates = pd.date_range('2016-01-01', '2016-02-01', freq='s')
>>> df = pd.DataFrame(index=dates, data={'A': 1})
>>> df.tail()
                     A
2016-01-31 23:59:56  1
2016-01-31 23:59:57  1
2016-01-31 23:59:58  1
2016-01-31 23:59:59  1
2016-02-01 00:00:00  1
",https://pandas.pydata.org/docs/reference/api/pandas.Series.truncate.html, pandas.date_range pandas.DataFrame pandas.DataFrame.tail
">>> df.truncate(before=pd.Timestamp('2016-01-05'),
...             after=pd.Timestamp('2016-01-10')).tail()
                     A
2016-01-09 23:59:56  1
2016-01-09 23:59:57  1
2016-01-09 23:59:58  1
2016-01-09 23:59:59  1
2016-01-10 00:00:00  1
",https://pandas.pydata.org/docs/reference/api/pandas.Series.truncate.html, pandas.DataFrame.truncate
">>> df.truncate('2016-01-05', '2016-01-10').tail()
                     A
2016-01-09 23:59:56  1
2016-01-09 23:59:57  1
2016-01-09 23:59:58  1
2016-01-09 23:59:59  1
2016-01-10 00:00:00  1
",https://pandas.pydata.org/docs/reference/api/pandas.Series.truncate.html, pandas.DataFrame.truncate
">>> s = pd.Series([1, 2, 3, 4])
>>> s.to_dict()
{0: 1, 1: 2, 2: 3, 3: 4}
>>> from collections import OrderedDict, defaultdict
>>> s.to_dict(into=OrderedDict)
OrderedDict([(0, 1), (1, 2), (2, 3), (3, 4)])
>>> dd = defaultdict(list)
>>> s.to_dict(into=dd)
defaultdict(, {0: 1, 1: 2, 2: 3, 3: 4})
",https://pandas.pydata.org/docs/reference/api/pandas.Series.to_dict.html, pandas.Series
">>> s = pd.Series([1, None, None, 2])
>>> s.bfill()
0    1.0
1    2.0
2    2.0
3    2.0
dtype: float64
>>> s.bfill(limit=1)
0    1.0
1    NaN
2    2.0
3    2.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.bfill.html, pandas.Series pandas.Series.bfill
">>> df = pd.DataFrame({'A': [1, None, None, 4], 'B': [None, 5, None, 7]})
>>> df
      A     B
0   1.0   NaN
1   NaN   5.0
2   NaN   NaN
3   4.0   7.0
>>> df.bfill()
      A     B
0   1.0   5.0
1   4.0   5.0
2   4.0   7.0
3   4.0   7.0
>>> df.bfill(limit=1)
      A     B
0   1.0   5.0
1   NaN   5.0
2   4.0   7.0
3   4.0   7.0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.bfill.html, pandas.DataFrame pandas.DataFrame.bfill
">>> ser = pd.Series([1, 2, 3])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.pop.html, pandas.Series
">>> ser.pop(0)
1
",https://pandas.pydata.org/docs/reference/api/pandas.Series.pop.html, pandas.Series.pop
">>> df = pd.DataFrame(dict(age=[5, 6, np.nan],
...                        born=[pd.NaT, pd.Timestamp('1939-05-27'),
...                              pd.Timestamp('1940-04-25')],
...                        name=['Alfred', 'Batman', ''],
...                        toy=[None, 'Batmobile', 'Joker']))
>>> df
   age       born    name        toy
0  5.0        NaT  Alfred       None
1  6.0 1939-05-27  Batman  Batmobile
2  NaN 1940-04-25              Joker
",https://pandas.pydata.org/docs/reference/api/pandas.Series.notnull.html, pandas.DataFrame
">>> df.notna()
     age   born  name    toy
0   True  False  True  False
1   True   True  True   True
2  False   True  True   True
",https://pandas.pydata.org/docs/reference/api/pandas.Series.notnull.html, pandas.DataFrame.notna
">>> ser = pd.Series([5, 6, np.nan])
>>> ser
0    5.0
1    6.0
2    NaN
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.notnull.html, pandas.Series
">>> ser.notna()
0     True
1     True
2    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.notnull.html, pandas.Series.notna
">>> period = pd.Period('2012-1-1', freq='D')
>>> period
Period('2012-01-01', 'D')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.start_time.html, pandas.Period pandas.Period
">>> s = pd.Series([1, 2, 3])
>>> s.shape
(3,)
",https://pandas.pydata.org/docs/reference/api/pandas.Series.shape.html, pandas.Series
">>> ser = pd.Series([1, 2, 3])
>>> ser
0    1
1    2
2    3
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.searchsorted.html, pandas.Series
">>> ser.searchsorted(4)
3
",https://pandas.pydata.org/docs/reference/api/pandas.Series.searchsorted.html, pandas.Series.searchsorted
">>> ser.searchsorted([0, 4])
array([0, 3])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.searchsorted.html, pandas.Series.searchsorted pandas.array
">>> ser.searchsorted([1, 3], side='left')
array([0, 2])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.searchsorted.html, pandas.Series.searchsorted pandas.array
">>> ser.searchsorted([1, 3], side='right')
array([1, 3])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.searchsorted.html, pandas.Series.searchsorted pandas.array
">>> ser = pd.Series(pd.to_datetime(['3/11/2000', '3/12/2000', '3/13/2000']))
>>> ser
0   2000-03-11
1   2000-03-12
2   2000-03-13
dtype: datetime64[ns]
",https://pandas.pydata.org/docs/reference/api/pandas.Series.searchsorted.html, pandas.Series pandas.to_datetime
">>> ser.searchsorted('3/14/2000')
3
",https://pandas.pydata.org/docs/reference/api/pandas.Series.searchsorted.html, pandas.Series.searchsorted
">>> ser = pd.Categorical(
...     ['apple', 'bread', 'bread', 'cheese', 'milk'], ordered=True
... )
>>> ser
['apple', 'bread', 'bread', 'cheese', 'milk']
Categories (4, object): ['apple' < 'bread' < 'cheese' < 'milk']
",https://pandas.pydata.org/docs/reference/api/pandas.Series.searchsorted.html, pandas.Categorical
">>> ser.searchsorted(['bread'], side='right')
array([3])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.searchsorted.html, pandas.array
">>> ser = pd.Series([2, 1, 3])
>>> ser
0    2
1    1
2    3
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.searchsorted.html, pandas.Series
">>> ser.searchsorted(1)  
0  # wrong result, correct would be 1
",https://pandas.pydata.org/docs/reference/api/pandas.Series.searchsorted.html, pandas.Series.searchsorted
">>> s1 = pd.Series(['one', 'one1', '1', ''])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isnumeric.html, pandas.Series
">>> s1.str.isalpha()
0     True
1    False
2    False
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isnumeric.html, pandas.Series.str.isalpha
">>> s1.str.isnumeric()
0    False
1    False
2     True
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isnumeric.html, pandas.Series.str.isnumeric
">>> s1.str.isalnum()
0     True
1     True
2     True
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isnumeric.html, pandas.Series.str.isalnum
">>> s2 = pd.Series(['A B', '1.5', '3,000'])
>>> s2.str.isalnum()
0    False
1    False
2    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isnumeric.html, pandas.Series pandas.Series.str.isalnum
">>> s3 = pd.Series(['23', '³', '⅕', ''])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isnumeric.html, pandas.Series
">>> s3.str.isdecimal()
0     True
1    False
2    False
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isnumeric.html, pandas.Series.str.isdecimal
">>> s3.str.isdigit()
0     True
1     True
2    False
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isnumeric.html, pandas.Series.str.isdigit
">>> s3.str.isnumeric()
0     True
1     True
2     True
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isnumeric.html, pandas.Series.str.isnumeric
">>> s4 = pd.Series([' ', '\t\r\n ', ''])
>>> s4.str.isspace()
0     True
1     True
2    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isnumeric.html, pandas.Series pandas.Series.str.isspace
">>> s5 = pd.Series(['leopard', 'Golden Eagle', 'SNAKE', ''])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isnumeric.html, pandas.Series
">>> s5.str.islower()
0     True
1    False
2    False
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isnumeric.html, pandas.Series.str.islower
">>> s5.str.isupper()
0    False
1    False
2     True
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isnumeric.html, pandas.Series.str.isupper
">>> s5.str.istitle()
0    False
1     True
2    False
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isnumeric.html, pandas.Series.str.istitle
">>> idx = pd.DatetimeIndex(['2023', '2024', '2025'])
>>> s = pd.Series([1, 2, 3], index=idx)
>>> s = s.to_period()
>>> s
2023    1
2024    2
2025    3
Freq: Y-DEC, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.to_period.html, pandas.DatetimeIndex pandas.Series pandas.Series.to_period
">>> s.index
PeriodIndex(['2023', '2024', '2025'], dtype='period[Y-DEC]')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.to_period.html, pandas.PeriodIndex
">>> s = pd.Series(pd.date_range(""2018-02-27"", periods=3))
>>> s
0   2018-02-27
1   2018-02-28
2   2018-03-01
dtype: datetime64[ns]
>>> s.dt.is_month_start
0    False
1    False
2    True
dtype: bool
>>> s.dt.is_month_end
0    False
1    True
2    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.is_month_end.html, pandas.Series pandas.date_range
">>> idx = pd.date_range(""2018-02-27"", periods=3)
>>> idx.is_month_start
array([False, False, True])
>>> idx.is_month_end
array([False, True, False])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.is_month_end.html, pandas.date_range pandas.array
">>> ser = pd.Series([1, 2, 3, 4])
>>> ser.ewm(alpha=.2).mean()
0    1.000000
1    1.555556
2    2.147541
3    2.775068
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.ewm.ExponentialMovingWindow.mean.html, pandas.Series pandas.Series.ewm
">>> s = pd.Series([1, 2, 3])
>>> s.skew()
0.0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.skew.html, pandas.Series pandas.Series.skew
">>> df = pd.DataFrame({'a': [1, 2, 3], 'b': [2, 3, 4], 'c': [1, 3, 5]},
...                   index=['tiger', 'zebra', 'cow'])
>>> df
        a   b   c
tiger   1   2   1
zebra   2   3   3
cow     3   4   5
>>> df.skew()
a   0.0
b   0.0
c   0.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.skew.html, pandas.DataFrame pandas.DataFrame.skew
">>> df.skew(axis=1)
tiger   1.732051
zebra  -1.732051
cow     0.000000
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.skew.html, pandas.DataFrame.skew
">>> df = pd.DataFrame({'a': [1, 2, 3], 'b': ['T', 'Z', 'X']},
...                   index=['tiger', 'zebra', 'cow'])
>>> df.skew(numeric_only=True)
a   0.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.skew.html, pandas.DataFrame pandas.DataFrame.skew
">>> s1 = pd.Series([1, np.nan])
>>> s2 = pd.Series([3, 4, 5])
>>> s1.combine_first(s2)
0    1.0
1    4.0
2    5.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.combine_first.html, pandas.Series pandas.Series.combine_first
">>> s1 = pd.Series({'falcon': np.nan, 'eagle': 160.0})
>>> s2 = pd.Series({'eagle': 200.0, 'duck': 30.0})
>>> s1.combine_first(s2)
duck       30.0
eagle     160.0
falcon      NaN
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.combine_first.html, pandas.Series pandas.Series.combine_first
">>> codes, uniques = pd.factorize(np.array(['b', 'b', 'a', 'c', 'b'], dtype=""O""))
>>> codes
array([0, 0, 1, 2, 0])
>>> uniques
array(['b', 'a', 'c'], dtype=object)
",https://pandas.pydata.org/docs/reference/api/pandas.Series.factorize.html, pandas.factorize pandas.array
">>> codes, uniques = pd.factorize(np.array(['b', 'b', 'a', 'c', 'b'], dtype=""O""),
...                               sort=True)
>>> codes
array([1, 1, 0, 2, 1])
>>> uniques
array(['a', 'b', 'c'], dtype=object)
",https://pandas.pydata.org/docs/reference/api/pandas.Series.factorize.html, pandas.factorize pandas.array
">>> codes, uniques = pd.factorize(np.array(['b', None, 'a', 'c', 'b'], dtype=""O""))
>>> codes
array([ 0, -1,  1,  2,  0])
>>> uniques
array(['b', 'a', 'c'], dtype=object)
",https://pandas.pydata.org/docs/reference/api/pandas.Series.factorize.html, pandas.factorize pandas.array
">>> cat = pd.Categorical(['a', 'a', 'c'], categories=['a', 'b', 'c'])
>>> codes, uniques = pd.factorize(cat)
>>> codes
array([0, 0, 1])
>>> uniques
['a', 'c']
Categories (3, object): ['a', 'b', 'c']
",https://pandas.pydata.org/docs/reference/api/pandas.Series.factorize.html, pandas.Categorical pandas.factorize pandas.array
">>> cat = pd.Series(['a', 'a', 'c'])
>>> codes, uniques = pd.factorize(cat)
>>> codes
array([0, 0, 1])
>>> uniques
Index(['a', 'c'], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.factorize.html, pandas.Series pandas.factorize pandas.array pandas.Index
">>> values = np.array([1, 2, 1, np.nan])
>>> codes, uniques = pd.factorize(values)  # default: use_na_sentinel=True
>>> codes
array([ 0,  1,  0, -1])
>>> uniques
array([1., 2.])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.factorize.html, pandas.factorize pandas.array
">>> codes, uniques = pd.factorize(values, use_na_sentinel=False)
>>> codes
array([0, 1, 0, 2])
>>> uniques
array([ 1.,  2., nan])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.factorize.html, pandas.factorize pandas.array
">>> s = pd.Series([0.25, 0.5, 0.2, -0.05])
>>> s.autocorr()  
0.10355...
>>> s.autocorr(lag=2)  
-0.99999...
",https://pandas.pydata.org/docs/reference/api/pandas.Series.autocorr.html, pandas.Series pandas.Series.autocorr
">>> s = pd.Series([1, 0, 0, 0])
>>> s.autocorr()
nan
",https://pandas.pydata.org/docs/reference/api/pandas.Series.autocorr.html, pandas.Series pandas.Series.autocorr
">>> s = pd.Series(pd.to_timedelta(np.arange(5), unit='s'))
>>> s
0   0 days 00:00:00
1   0 days 00:00:01
2   0 days 00:00:02
3   0 days 00:00:03
4   0 days 00:00:04
dtype: timedelta64[ns]
>>> s.dt.components
   days  hours  minutes  seconds  milliseconds  microseconds  nanoseconds
0     0      0        0        0             0             0            0
1     0      0        0        1             0             0            0
2     0      0        0        2             0             0            0
3     0      0        0        3             0             0            0
4     0      0        0        4             0             0            0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.components.html, pandas.Series pandas.to_timedelta
">>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])
>>> a
a    1.0
b    1.0
c    1.0
d    NaN
dtype: float64
>>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])
>>> b
a    1.0
b    NaN
d    1.0
e    NaN
dtype: float64
>>> a.add(b, fill_value=0)
a    2.0
b    1.0
c    1.0
d    1.0
e    NaN
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.add.html, pandas.Series pandas.Series.add
">>> s = pd.Series([1, 3, 2])
>>> s.plot.line()  
",https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.line.html, pandas.Series pandas.Series.plot.line
">>> df = pd.DataFrame({
...    'pig': [20, 18, 489, 675, 1776],
...    'horse': [4, 25, 281, 600, 1900]
...    }, index=[1990, 1997, 2003, 2009, 2014])
>>> lines = df.plot.line()
",https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.line.html, pandas.DataFrame pandas.DataFrame.plot.line
">>> axes = df.plot.line(subplots=True)
>>> type(axes)

",https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.line.html, pandas.DataFrame.plot.line
">>> axes = df.plot.line(
...     subplots=True, color={""pig"": ""pink"", ""horse"": ""#742802""}
... )
",https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.line.html, pandas.DataFrame.plot.line
">>> lines = df.plot.line(x='pig', y='horse')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.line.html, pandas.DataFrame.plot.line
">>> ser = pd.Series([1, 5, 2, 7, 15, 6])
>>> ser.rolling(3).skew().round(6)
0         NaN
1         NaN
2    1.293343
3   -0.585583
4    0.670284
5    1.652317
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.skew.html, pandas.Series pandas.Series.rolling
">>> pd.Series([True, True]).all()
True
>>> pd.Series([True, False]).all()
False
>>> pd.Series([], dtype=""float64"").all()
True
>>> pd.Series([np.nan]).all()
True
>>> pd.Series([np.nan]).all(skipna=False)
True
",https://pandas.pydata.org/docs/reference/api/pandas.Series.all.html, pandas.Series
">>> df = pd.DataFrame({'col1': [True, True], 'col2': [True, False]})
>>> df
   col1   col2
0  True   True
1  True  False
",https://pandas.pydata.org/docs/reference/api/pandas.Series.all.html, pandas.DataFrame
">>> df.all()
col1     True
col2    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.all.html, pandas.DataFrame.all
">>> df.all(axis='columns')
0     True
1    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.all.html, pandas.DataFrame.all
">>> df.all(axis=None)
False
",https://pandas.pydata.org/docs/reference/api/pandas.Series.all.html, pandas.DataFrame.all
">>> df = pd.DataFrame({""A"": [1, 2, 3], ""B"": [4, 5, 6], ""C"": [7, 8, 9]})
>>> df
   A  B  C
0  1  4  7
1  2  5  8
2  3  6  9
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.aggregate.html, pandas.DataFrame
">>> df.ewm(alpha=0.5).mean()
          A         B         C
0  1.000000  4.000000  7.000000
1  1.666667  4.666667  7.666667
2  2.428571  5.428571  8.428571
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.aggregate.html, pandas.DataFrame.ewm
">>> idx = pd.date_range(""2012-01-01"", ""2015-01-01"", freq=""YE"")
>>> idx
DatetimeIndex(['2012-12-31', '2013-12-31', '2014-12-31'],
              dtype='datetime64[ns]', freq='YE-DEC')
>>> idx.is_leap_year
array([ True, False, False])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.is_leap_year.html, pandas.date_range pandas.DatetimeIndex pandas.array
">>> dates_series = pd.Series(idx)
>>> dates_series
0   2012-12-31
1   2013-12-31
2   2014-12-31
dtype: datetime64[ns]
>>> dates_series.dt.is_leap_year
0     True
1    False
2    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.is_leap_year.html, pandas.Series
">>> rng = pd.date_range('1/1/2018 11:59:00', periods=3, freq='min')
>>> rng
DatetimeIndex(['2018-01-01 11:59:00', '2018-01-01 12:00:00',
               '2018-01-01 12:01:00'],
              dtype='datetime64[ns]', freq='min')
>>> rng.floor('h')
DatetimeIndex(['2018-01-01 11:00:00', '2018-01-01 12:00:00',
               '2018-01-01 12:00:00'],
              dtype='datetime64[ns]', freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.floor.html, pandas.date_range pandas.DatetimeIndex
">>> pd.Series(rng).dt.floor(""h"")
0   2018-01-01 11:00:00
1   2018-01-01 12:00:00
2   2018-01-01 12:00:00
dtype: datetime64[ns]
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.floor.html, pandas.Series
">>> rng_tz = pd.DatetimeIndex([""2021-10-31 03:30:00""], tz=""Europe/Amsterdam"")
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.floor.html, pandas.DatetimeIndex
">>> rng_tz.floor(""2h"", ambiguous=False)
DatetimeIndex(['2021-10-31 02:00:00+01:00'],
             dtype='datetime64[ns, Europe/Amsterdam]', freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.floor.html, pandas.DatetimeIndex.floor pandas.DatetimeIndex
">>> rng_tz.floor(""2h"", ambiguous=True)
DatetimeIndex(['2021-10-31 02:00:00+02:00'],
              dtype='datetime64[ns, Europe/Amsterdam]', freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.floor.html, pandas.DatetimeIndex.floor pandas.DatetimeIndex
">>> c = pd.Series([6, 7, 8, 9], name='c')
>>> a = pd.Series([0, 0, 1, 2])
>>> b = pd.Series([0, 3, 4, 5])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.case_when.html, pandas.Series
">>> c.case_when(caselist=[(a.gt(0), a),  # condition, replacement
...                       (b.gt(0), b)])
0    6
1    3
2    1
3    2
Name: c, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.case_when.html, pandas.Series.case_when pandas.Series.gt pandas.Series.gt
">>> ser = pd.Series([1, 6, 5, 4])
>>> ser.rolling(2).apply(lambda s: s.sum() - s.min())
0    NaN
1    6.0
2    6.0
3    5.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.apply.html, pandas.Series pandas.Series.rolling pandas.Series.sum pandas.Series.min
">>> df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]},
...                   index=['a', 'b', 'c'])  
>>> df.to_hdf('data.h5', key='df', mode='w')  
",https://pandas.pydata.org/docs/reference/api/pandas.Series.to_hdf.html, pandas.DataFrame pandas.DataFrame.to_hdf
">>> s = pd.Series([1, 2, 3, 4])  
>>> s.to_hdf('data.h5', key='s')  
",https://pandas.pydata.org/docs/reference/api/pandas.Series.to_hdf.html, pandas.Series pandas.Series.to_hdf
">>> pd.read_hdf('data.h5', 'df')  
A  B
a  1  4
b  2  5
c  3  6
>>> pd.read_hdf('data.h5', 's')  
0    1
1    2
2    3
3    4
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.to_hdf.html, pandas.read_hdf
">>> s = pd.Series([1, 2, 3])
>>> s.update(pd.Series([4, 5, 6]))
>>> s
0    4
1    5
2    6
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.update.html, pandas.Series pandas.Series.update
">>> s = pd.Series(['a', 'b', 'c'])
>>> s.update(pd.Series(['d', 'e'], index=[0, 2]))
>>> s
0    d
1    b
2    e
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.update.html, pandas.Series pandas.Series.update
">>> s = pd.Series([1, 2, 3])
>>> s.update(pd.Series([4, 5, 6, 7, 8]))
>>> s
0    4
1    5
2    6
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.update.html, pandas.Series pandas.Series.update
">>> s = pd.Series([1, 2, 3])
>>> s.update(pd.Series([4, np.nan, 6]))
>>> s
0    4
1    2
2    6
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.update.html, pandas.Series pandas.Series.update
">>> s = pd.Series([1, 2, 3])
>>> s.update([4, np.nan, 6])
>>> s
0    4
1    2
2    6
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.update.html, pandas.Series pandas.Series.update
">>> s = pd.Series([1, 2, 3])
>>> s.update({1: 9})
>>> s
0    1
1    9
2    3
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.update.html, pandas.Series pandas.Series.update
">>> arr = [1, 2, 3, 4, 999]
>>> import scipy.stats
>>> print(f""{scipy.stats.kurtosis(arr[:-1], bias=False):.6f}"")
-1.200000
>>> print(f""{scipy.stats.kurtosis(arr, bias=False):.6f}"")
4.999874
>>> s = pd.Series(arr)
>>> s.expanding(4).kurt()
0         NaN
1         NaN
2         NaN
3   -1.200000
4    4.999874
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.kurt.html, pandas.Series pandas.Series.expanding
">>> s = pd.Series([5, 5, 6, 7, 5, 5, 5])
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.std.html, pandas.Series
">>> s.expanding(3).std()
0         NaN
1         NaN
2    0.577350
3    0.957427
4    0.894427
5    0.836660
6    0.786796
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.std.html, pandas.Series.expanding
">>> ser1 = pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])
>>> ser2 = pd.Series([10, 11, 13, 16], index=['a', 'b', 'c', 'd'])
>>> ser1.expanding().corr(ser2)
a         NaN
b    1.000000
c    0.981981
d    0.975900
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.corr.html, pandas.Series pandas.Series.expanding
">>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])
>>> a
a    1.0
b    1.0
c    1.0
d    NaN
dtype: float64
>>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])
>>> b
a    1.0
b    NaN
d    1.0
e    NaN
dtype: float64
>>> a.ne(b, fill_value=0)
a    False
b     True
c     True
d     True
e     True
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.ne.html, pandas.Series pandas.Series.ne
">>> s = pd.Series(range(5))
>>> s.where(s > 0)
0    NaN
1    1.0
2    2.0
3    3.0
4    4.0
dtype: float64
>>> s.mask(s > 0)
0    0.0
1    NaN
2    NaN
3    NaN
4    NaN
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.where.html, pandas.Series pandas.Series.where pandas.Series.mask
">>> s = pd.Series(range(5))
>>> t = pd.Series([True, False])
>>> s.where(t, 99)
0     0
1    99
2    99
3    99
4    99
dtype: int64
>>> s.mask(t, 99)
0    99
1     1
2    99
3    99
4    99
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.where.html, pandas.Series pandas.Series.where pandas.Series.mask
">>> s.where(s > 1, 10)
0    10
1    10
2    2
3    3
4    4
dtype: int64
>>> s.mask(s > 1, 10)
0     0
1     1
2    10
3    10
4    10
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.where.html, pandas.Series.where pandas.Series.mask
">>> df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=['A', 'B'])
>>> df
   A  B
0  0  1
1  2  3
2  4  5
3  6  7
4  8  9
>>> m = df % 3 == 0
>>> df.where(m, -df)
   A  B
0  0 -1
1 -2  3
2 -4 -5
3  6 -7
4 -8  9
>>> df.where(m, -df) == np.where(m, df, -df)
      A     B
0  True  True
1  True  True
2  True  True
3  True  True
4  True  True
>>> df.where(m, -df) == df.mask(~m, -df)
      A     B
0  True  True
1  True  True
2  True  True
3  True  True
4  True  True
",https://pandas.pydata.org/docs/reference/api/pandas.Series.where.html, pandas.DataFrame pandas.DataFrame.where pandas.DataFrame.mask
">>> ser = pd.Series(['a', 'b', 'c', 'a'], dtype='category')
>>> ser.cat.ordered
False
>>> ser = ser.cat.as_ordered()
>>> ser.cat.ordered
True
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.as_ordered.html, pandas.Series pandas.Series.cat.as_ordered
">>> ci = pd.CategoricalIndex(['a', 'b', 'c', 'a'])
>>> ci.ordered
False
>>> ci = ci.as_ordered()
>>> ci.ordered
True
",https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.as_ordered.html, pandas.CategoricalIndex pandas.CategoricalIndex.as_ordered
">>> ser = pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])
>>> ser.expanding().mean()
a    1.0
b    1.5
c    2.0
d    2.5
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.mean.html, pandas.Series pandas.Series.expanding
">>> s = pd.Series(['cat', 'dog', np.nan, 'rabbit'])
>>> s
0      cat
1      dog
2      NaN
3   rabbit
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.map.html, pandas.Series
">>> s.map({'cat': 'kitten', 'dog': 'puppy'})
0   kitten
1    puppy
2      NaN
3      NaN
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.map.html, pandas.Series.map
">>> s.map('I am a {}'.format)
0       I am a cat
1       I am a dog
2       I am a nan
3    I am a rabbit
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.map.html, pandas.Series.map
">>> s.map('I am a {}'.format, na_action='ignore')
0     I am a cat
1     I am a dog
2            NaN
3  I am a rabbit
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.map.html, pandas.Series.map
">>> s = pd.Series([""1/1/2020 10:00:00+00:00"", ""2/1/2020 11:00:00+00:00""])
>>> s = pd.to_datetime(s)
>>> s
0   2020-01-01 10:00:00+00:00
1   2020-02-01 11:00:00+00:00
dtype: datetime64[ns, UTC]
>>> s.dt.daysinmonth
0    31
1    29
dtype: int32
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.daysinmonth.html, pandas.Series pandas.to_datetime
">>> original_df = pd.DataFrame({""foo"": range(5), ""bar"": range(5, 10)})  
>>> original_df  
   foo  bar
0    0    5
1    1    6
2    2    7
3    3    8
4    4    9
>>> original_df.to_pickle(""./dummy.pkl"")  
",https://pandas.pydata.org/docs/reference/api/pandas.Series.to_pickle.html, pandas.DataFrame pandas.DataFrame.to_pickle
">>> unpickled_df = pd.read_pickle(""./dummy.pkl"")  
>>> unpickled_df  
   foo  bar
0    0    5
1    1    6
2    2    7
3    3    8
4    4    9
",https://pandas.pydata.org/docs/reference/api/pandas.Series.to_pickle.html, pandas.read_pickle
">>> s = pd.Series([""1/1/2020 10:00:00+00:00"", ""2/1/2020 11:00:00+00:00""])
>>> s = pd.to_datetime(s)
>>> s
0   2020-01-01 10:00:00+00:00
1   2020-02-01 11:00:00+00:00
dtype: datetime64[ns, UTC]
>>> s.dt.dayofyear
0    1
1   32
dtype: int32
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.day_of_year.html, pandas.Series pandas.to_datetime
">>> idx = pd.DatetimeIndex([""1/1/2020 10:00:00+00:00"",
...                         ""2/1/2020 11:00:00+00:00""])
>>> idx.dayofyear
Index([1, 32], dtype='int32')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.day_of_year.html, pandas.DatetimeIndex pandas.Index
">>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])
>>> a
a    1.0
b    1.0
c    1.0
d    NaN
dtype: float64
>>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])
>>> b
a    1.0
b    NaN
d    1.0
e    NaN
dtype: float64
>>> a.divide(b, fill_value=0)
a    1.0
b    inf
c    inf
d    0.0
e    NaN
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.rdiv.html, pandas.Series
">>> s = pd.Series([5, 5, 6, 7, 5, 5, 5])
>>> s.rolling(3).std()
0         NaN
1         NaN
2    0.577350
3    1.000000
4    1.000000
5    1.154701
6    0.000000
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.std.html, pandas.Series pandas.Series.rolling
">>> s = pd.Series([""1/1/2020 10:00:00+00:00"", ""2/1/2020 11:00:00+00:00""])
>>> s = pd.to_datetime(s)
>>> s
0   2020-01-01 10:00:00+00:00
1   2020-02-01 11:00:00+00:00
dtype: datetime64[ns, UTC]
>>> s.dt.daysinmonth
0    31
1    29
dtype: int32
",https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.days_in_month.html, pandas.Series pandas.to_datetime
">>> df_empty = pd.DataFrame({'A' : []})
>>> df_empty
Empty DataFrame
Columns: [A]
Index: []
>>> df_empty.empty
True
",https://pandas.pydata.org/docs/reference/api/pandas.Series.empty.html, pandas.DataFrame
">>> df = pd.DataFrame({'A' : [np.nan]})
>>> df
    A
0 NaN
>>> df.empty
False
>>> df.dropna().empty
True
",https://pandas.pydata.org/docs/reference/api/pandas.Series.empty.html, pandas.DataFrame pandas.DataFrame.dropna
">>> ser_empty = pd.Series({'A' : []})
>>> ser_empty
A    []
dtype: object
>>> ser_empty.empty
False
>>> ser_empty = pd.Series()
>>> ser_empty.empty
True
",https://pandas.pydata.org/docs/reference/api/pandas.Series.empty.html, pandas.Series
">>> v1 = [3, 3, 3, 5, 8]
>>> v2 = [3, 4, 4, 4, 8]
>>> np.corrcoef(v1[:-1], v2[:-1])
array([[1.        , 0.33333333],
       [0.33333333, 1.        ]])
>>> np.corrcoef(v1[1:], v2[1:])
array([[1.       , 0.9169493],
       [0.9169493, 1.       ]])
>>> s1 = pd.Series(v1)
>>> s2 = pd.Series(v2)
>>> s1.rolling(4).corr(s2)
0         NaN
1         NaN
2         NaN
3    0.333333
4    0.916949
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.corr.html, pandas.array pandas.Series pandas.Series.rolling
">>> matrix = np.array([[51., 35.],
...                    [49., 30.],
...                    [47., 32.],
...                    [46., 31.],
...                    [50., 36.]])
>>> np.corrcoef(matrix[:-1, 0], matrix[:-1, 1])
array([[1.       , 0.6263001],
       [0.6263001, 1.       ]])
>>> np.corrcoef(matrix[1:, 0], matrix[1:, 1])
array([[1.        , 0.55536811],
       [0.55536811, 1.        ]])
>>> df = pd.DataFrame(matrix, columns=['X', 'Y'])
>>> df
      X     Y
0  51.0  35.0
1  49.0  30.0
2  47.0  32.0
3  46.0  31.0
4  50.0  36.0
>>> df.rolling(4).corr(pairwise=True)
            X         Y
0 X       NaN       NaN
  Y       NaN       NaN
1 X       NaN       NaN
  Y       NaN       NaN
2 X       NaN       NaN
  Y       NaN       NaN
3 X  1.000000  0.626300
  Y  0.626300  1.000000
4 X  1.000000  0.555368
  Y  0.555368  1.000000
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.corr.html, pandas.array pandas.DataFrame pandas.DataFrame.rolling
">>> s = pd.Series([2, 3, np.nan, 10])
>>> s.rolling(2).count()
0    NaN
1    2.0
2    1.0
3    1.0
dtype: float64
>>> s.rolling(3).count()
0    NaN
1    NaN
2    2.0
3    2.0
dtype: float64
>>> s.rolling(4).count()
0    NaN
1    NaN
2    NaN
3    3.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.count.html, pandas.Series pandas.Series.rolling
">>> d = {'num_legs': [4, 4, 2, 2],
...      'num_wings': [0, 0, 2, 2],
...      'class': ['mammal', 'mammal', 'mammal', 'bird'],
...      'animal': ['cat', 'dog', 'bat', 'penguin'],
...      'locomotion': ['walks', 'walks', 'flies', 'walks']}
>>> df = pd.DataFrame(data=d)
>>> df = df.set_index(['class', 'animal', 'locomotion'])
>>> df
                           num_legs  num_wings
class  animal  locomotion
mammal cat     walks              4          0
       dog     walks              4          0
       bat     flies              2          2
bird   penguin walks              2          2
",https://pandas.pydata.org/docs/reference/api/pandas.Series.xs.html, pandas.DataFrame pandas.DataFrame.set_index
">>> df.xs('mammal')
                   num_legs  num_wings
animal locomotion
cat    walks              4          0
dog    walks              4          0
bat    flies              2          2
",https://pandas.pydata.org/docs/reference/api/pandas.Series.xs.html, pandas.DataFrame.xs
">>> df.xs(('mammal', 'dog', 'walks'))
num_legs     4
num_wings    0
Name: (mammal, dog, walks), dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.xs.html, pandas.DataFrame.xs
">>> df.xs('cat', level=1)
                   num_legs  num_wings
class  locomotion
mammal walks              4          0
",https://pandas.pydata.org/docs/reference/api/pandas.Series.xs.html, pandas.DataFrame.xs
">>> df.xs(('bird', 'walks'),
...       level=[0, 'locomotion'])
         num_legs  num_wings
animal
penguin         2          2
",https://pandas.pydata.org/docs/reference/api/pandas.Series.xs.html, pandas.DataFrame.xs
">>> df.xs('num_wings', axis=1)
class   animal   locomotion
mammal  cat      walks         0
        dog      walks         0
        bat      flies         2
bird    penguin  walks         2
Name: num_wings, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.xs.html, pandas.DataFrame.xs
">>> ser = pd.Series([0, 1, 5, 2, 8])
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Window.sum.html, pandas.Series
">>> type(ser.rolling(2, win_type='gaussian'))

",https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Window.sum.html, pandas.Series.rolling
">>> ser.rolling(2, win_type='gaussian').sum(std=3)
0         NaN
1    0.986207
2    5.917243
3    6.903450
4    9.862071
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Window.sum.html, pandas.Series.rolling
">>> s = pd.Series([1, 2, 3, 4, 5])
>>> s
0    1
1    2
2    3
3    4
4    5
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.sum.html, pandas.Series
">>> s.rolling(3).sum()
0     NaN
1     NaN
2     6.0
3     9.0
4    12.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.sum.html, pandas.Series.rolling
">>> s.rolling(3, center=True).sum()
0     NaN
1     6.0
2     9.0
3    12.0
4     NaN
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.sum.html, pandas.Series.rolling
">>> df = pd.DataFrame({""A"": s, ""B"": s ** 2})
>>> df
   A   B
0  1   1
1  2   4
2  3   9
3  4  16
4  5  25
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.sum.html, pandas.DataFrame
">>> df.rolling(3).sum()
      A     B
0   NaN   NaN
1   NaN   NaN
2   6.0  14.0
3   9.0  29.0
4  12.0  50.0
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.sum.html, pandas.DataFrame.rolling
">>> from pandas.api.indexers import BaseIndexer
>>> class CustomIndexer(BaseIndexer):
...     def get_window_bounds(self, num_values, min_periods, center, closed, step):
...         start = np.empty(num_values, dtype=np.int64)
...         end = np.empty(num_values, dtype=np.int64)
...         for i in range(num_values):
...             start[i] = i
...             end[i] = i + self.window_size
...         return start, end
>>> df = pd.DataFrame({""values"": range(5)})
>>> indexer = CustomIndexer(window_size=2)
>>> df.rolling(indexer).sum()
    values
0   1.0
1   3.0
2   5.0
3   7.0
4   4.0
",https://pandas.pydata.org/docs/reference/api/pandas.api.indexers.BaseIndexer.html, pandas.DataFrame pandas.DataFrame.rolling
">>> pd.Series([1, 2, 3]).values
array([1, 2, 3])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.values.html, pandas.Series pandas.array
">>> pd.Series(list('aabc')).values
array(['a', 'a', 'b', 'c'], dtype=object)
",https://pandas.pydata.org/docs/reference/api/pandas.Series.values.html, pandas.Series pandas.array
">>> pd.Series(list('aabc')).astype('category').values
['a', 'a', 'b', 'c']
Categories (3, object): ['a', 'b', 'c']
",https://pandas.pydata.org/docs/reference/api/pandas.Series.values.html, pandas.Series
">>> pd.Series(pd.date_range('20130101', periods=3,
...                         tz='US/Eastern')).values
array(['2013-01-01T05:00:00.000000000',
       '2013-01-02T05:00:00.000000000',
       '2013-01-03T05:00:00.000000000'], dtype='datetime64[ns]')
",https://pandas.pydata.org/docs/reference/api/pandas.Series.values.html, pandas.Series pandas.date_range pandas.array
">>> s1 = pd.Series(['one', 'one1', '1', ''])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.islower.html, pandas.Series
">>> s1.str.isalpha()
0     True
1    False
2    False
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.islower.html, pandas.Series.str.isalpha
">>> s1.str.isnumeric()
0    False
1    False
2     True
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.islower.html, pandas.Series.str.isnumeric
">>> s1.str.isalnum()
0     True
1     True
2     True
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.islower.html, pandas.Series.str.isalnum
">>> s2 = pd.Series(['A B', '1.5', '3,000'])
>>> s2.str.isalnum()
0    False
1    False
2    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.islower.html, pandas.Series pandas.Series.str.isalnum
">>> s3 = pd.Series(['23', '³', '⅕', ''])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.islower.html, pandas.Series
">>> s3.str.isdecimal()
0     True
1    False
2    False
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.islower.html, pandas.Series.str.isdecimal
">>> s3.str.isdigit()
0     True
1     True
2    False
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.islower.html, pandas.Series.str.isdigit
">>> s3.str.isnumeric()
0     True
1     True
2     True
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.islower.html, pandas.Series.str.isnumeric
">>> s4 = pd.Series([' ', '\t\r\n ', ''])
>>> s4.str.isspace()
0     True
1     True
2    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.islower.html, pandas.Series pandas.Series.str.isspace
">>> s5 = pd.Series(['leopard', 'Golden Eagle', 'SNAKE', ''])
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.islower.html, pandas.Series
">>> s5.str.islower()
0     True
1    False
2    False
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.islower.html, pandas.Series.str.islower
">>> s5.str.isupper()
0    False
1    False
2     True
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.islower.html, pandas.Series.str.isupper
">>> s5.str.istitle()
0    False
1     True
2    False
3    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.islower.html, pandas.Series.str.istitle
">>> ser = pd.Series([1, 2, 3, 4, 5, 6], index=['a', 'b', 'c', 'd', 'e', 'f'])
>>> ser.expanding(min_periods=4).quantile(.25)
a     NaN
b     NaN
c     NaN
d    1.75
e    2.00
f    2.25
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.quantile.html, pandas.Series pandas.Series.expanding
">>> s = pd.Series([""koala"", ""dog"", ""chameleon""])
>>> s
0        koala
1          dog
2    chameleon
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.slice.html, pandas.Series
">>> s.str.slice(start=1)
0        oala
1          og
2    hameleon
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.slice.html, pandas.Series.str.slice
">>> s.str.slice(start=-1)
0           a
1           g
2           n
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.slice.html, pandas.Series.str.slice
">>> s.str.slice(stop=2)
0    ko
1    do
2    ch
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.slice.html, pandas.Series.str.slice
">>> s.str.slice(step=2)
0      kaa
1       dg
2    caeen
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.slice.html, pandas.Series.str.slice
">>> s.str.slice(start=0, stop=5, step=3)
0    kl
1     d
2    cm
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.slice.html, pandas.Series.str.slice
">>> ser = pd.Series([""cat"", ""duck"", ""dove""])
>>> ser.str.fullmatch(r'd.+')
0   False
1    True
2    True
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.fullmatch.html, pandas.Series pandas.Series.str.fullmatch
">>> def some_highlights(styler, min_color=""red"", max_color=""blue""):
...      styler.highlight_min(color=min_color, axis=None)
...      styler.highlight_max(color=max_color, axis=None)
...      styler.highlight_null()
...      return styler
>>> df = pd.DataFrame([[1, 2, 3, pd.NA], [pd.NA, 4, 5, 6]], dtype=""Int64"")
>>> df.style.pipe(some_highlights, min_color=""green"")  
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.pipe.html, pandas.DataFrame
">>> (df.style.format(""{:.1f}"")
...         .pipe(some_highlights, min_color=""green"")
...         .highlight_between(left=2, right=5))  
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.pipe.html, pandas.io.formats.style.Styler.highlight_between
">>> def highlight_last_level(styler):
...     return styler.apply_index(
...         lambda v: ""background-color: pink; color: yellow"", axis=""columns"",
...         level=styler.columns.nlevels-1
...     )  
>>> df.columns = pd.MultiIndex.from_product([[""A"", ""B""], [""X"", ""Y""]])
>>> df.style.pipe(highlight_last_level)  
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.pipe.html, pandas.MultiIndex.from_product
">>> s = pd.Series(['a', 'ab', 'abc', 'abdc', 'abcde'])
>>> s
0        a
1       ab
2      abc
3     abdc
4    abcde
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.slice_replace.html, pandas.Series
">>> s.str.slice_replace(1, repl='X')
0    aX
1    aX
2    aX
3    aX
4    aX
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.slice_replace.html, pandas.Series.str.slice_replace
">>> s.str.slice_replace(stop=2, repl='X')
0       X
1       X
2      Xc
3     Xdc
4    Xcde
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.slice_replace.html, pandas.Series.str.slice_replace
">>> s.str.slice_replace(start=1, stop=3, repl='X')
0      aX
1      aX
2      aX
3     aXc
4    aXde
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.str.slice_replace.html, pandas.Series.str.slice_replace
">>> df = pd.DataFrame({""a"": [1, 2, 0, 0],
...                   ""b"": [3, 0, 0, 4]}, dtype=""Sparse[int]"")
>>> df.sparse.density
0.5
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sparse.html, pandas.DataFrame
">>> s = pd.Series(['llama', 'cow', 'llama', 'beetle', 'llama', 'hippo'],
...               name='animal')
>>> s
0     llama
1       cow
2     llama
3    beetle
4     llama
5     hippo
Name: animal, dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.drop_duplicates.html, pandas.Series
">>> s.drop_duplicates()
0     llama
1       cow
3    beetle
5     hippo
Name: animal, dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.drop_duplicates.html, pandas.Series.drop_duplicates
">>> s.drop_duplicates(keep='last')
1       cow
3    beetle
4     llama
5     hippo
Name: animal, dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.drop_duplicates.html, pandas.Series.drop_duplicates
">>> s.drop_duplicates(keep=False)
1       cow
3    beetle
5     hippo
Name: animal, dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.Series.drop_duplicates.html, pandas.Series.drop_duplicates
">>> ser1 = pd.Series([1, 2, 3, 4])
>>> ser2 = pd.Series([10, 11, 13, 16])
>>> ser1.ewm(alpha=.2).cov(ser2)
0         NaN
1    0.500000
2    1.524590
3    3.408836
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.ewm.ExponentialMovingWindow.cov.html, pandas.Series pandas.Series.ewm
">>> s = pd.Series(['Ant', 'Bear', 'Cow'])
>>> s
0     Ant
1    Bear
2     Cow
dtype: object
>>> s.nbytes
24
",https://pandas.pydata.org/docs/reference/api/pandas.Series.nbytes.html, pandas.Series
">>> idx = pd.Index([1, 2, 3])
>>> idx
Index([1, 2, 3], dtype='int64')
>>> idx.nbytes
24
",https://pandas.pydata.org/docs/reference/api/pandas.Series.nbytes.html, pandas.Index pandas.Index
">>> ser = pd.Series([0, 1, 5, 2, 8])
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Window.var.html, pandas.Series
">>> type(ser.rolling(2, win_type='gaussian'))

",https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Window.var.html, pandas.Series.rolling
">>> ser.rolling(2, win_type='gaussian').var(std=3)
0     NaN
1     0.5
2     8.0
3     4.5
4    18.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Window.var.html, pandas.Series.rolling
">>> s = pd.Series([0, 1, 2, 3])
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.sem.html, pandas.Series
">>> s.expanding().sem()
0         NaN
1    0.707107
2    0.707107
3    0.745356
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.sem.html, pandas.Series.expanding
">>> s = pd.Series([0, 1, 2, 3, 4])
>>> s.rolling(3).median()
0    NaN
1    NaN
2    1.0
3    2.0
4    3.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.median.html, pandas.Series pandas.Series.rolling
">>> ser1 = pd.Series([1, 2, 3, 4])
>>> ser2 = pd.Series([1, 4, 5, 8])
>>> ser1.rolling(2).cov(ser2)
0    NaN
1    1.5
2    0.5
3    1.5
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.cov.html, pandas.Series pandas.Series.rolling
">>> arr = [1, 2, 3, 4, 999]
>>> import scipy.stats
>>> print(f""{scipy.stats.kurtosis(arr[:-1], bias=False):.6f}"")
-1.200000
>>> print(f""{scipy.stats.kurtosis(arr[1:], bias=False):.6f}"")
3.999946
>>> s = pd.Series(arr)
>>> s.rolling(4).kurt()
0         NaN
1         NaN
2         NaN
3   -1.200000
4    3.999946
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.kurt.html, pandas.Series pandas.Series.rolling
">>> s = pd.Series([4, 3, 5, 2, 6])
>>> s.rolling(3).min()
0    NaN
1    NaN
2    3.0
3    2.0
4    2.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.min.html, pandas.Series pandas.Series.rolling
">>> ser = pd.Series([1, 2, 3, 4])
>>> ser.ewm(alpha=.2).std()
0         NaN
1    0.707107
2    0.995893
3    1.277320
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.ewm.ExponentialMovingWindow.std.html, pandas.Series pandas.Series.ewm
">>> s = pd.Series([5, 5, 6, 7, 5, 5, 5])
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.var.html, pandas.Series
">>> s.expanding(3).var()
0         NaN
1         NaN
2    0.333333
3    0.916667
4    0.800000
5    0.700000
6    0.619048
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.var.html, pandas.Series.expanding
">>> ser = pd.Series([3, 2, 1, 4], index=['a', 'b', 'c', 'd'])
>>> ser.expanding().max()
a    3.0
b    3.0
c    3.0
d    4.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.max.html, pandas.Series pandas.Series.expanding
">>> ser = pd.Series([-1, 0, 2, -1, 2], index=['a', 'b', 'c', 'd', 'e'])
>>> ser.expanding().skew()
a         NaN
b         NaN
c    0.935220
d    1.414214
e    0.315356
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.skew.html, pandas.Series pandas.Series.expanding
">>> ser = pd.Series([1, 2, 3, 4])
>>> ser.ewm(alpha=.2).sum()
0    1.000
1    2.800
2    5.240
3    8.192
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.ewm.ExponentialMovingWindow.sum.html, pandas.Series pandas.Series.ewm
">>> s = pd.Series([0, 1, 2, 3])
>>> s.rolling(2, min_periods=1).sem()
0         NaN
1    0.707107
2    0.707107
3    0.707107
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.sem.html, pandas.Series pandas.Series.rolling
">>> ser = pd.Series([0, 1, 5, 2, 8])
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Window.mean.html, pandas.Series
">>> type(ser.rolling(2, win_type='gaussian'))

",https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Window.mean.html, pandas.Series.rolling
">>> ser.rolling(2, win_type='gaussian').mean(std=3)
0    NaN
1    0.5
2    3.0
3    3.5
4    5.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Window.mean.html, pandas.Series.rolling
">>> s = pd.Series([1, 4, 2, 3, 5, 3])
>>> s.expanding().rank()
0    1.0
1    2.0
2    2.0
3    3.0
4    5.0
5    3.5
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.rank.html, pandas.Series pandas.Series.expanding
">>> s.expanding().rank(method=""max"")
0    1.0
1    2.0
2    2.0
3    3.0
4    5.0
5    4.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.rank.html, pandas.Series.expanding
">>> s.expanding().rank(method=""min"")
0    1.0
1    2.0
2    2.0
3    3.0
4    5.0
5    3.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.rank.html, pandas.Series.expanding
">>> ser = pd.Series([1, 2, 3, 4])
>>> ser.rolling(2).max()
0    NaN
1    2.0
2    3.0
3    4.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.max.html, pandas.Series pandas.Series.rolling
">>> ser1 = pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])
>>> ser2 = pd.Series([10, 11, 13, 16], index=['a', 'b', 'c', 'd'])
>>> ser1.expanding().cov(ser2)
a         NaN
b    0.500000
c    1.500000
d    3.333333
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.cov.html, pandas.Series pandas.Series.expanding
">>> ser = pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])
>>> ser.expanding().sum()
a     1.0
b     3.0
c     6.0
d    10.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.sum.html, pandas.Series pandas.Series.expanding
">>> ser = pd.Series([0, 1, 5, 2, 8])
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Window.std.html, pandas.Series
">>> type(ser.rolling(2, win_type='gaussian'))

",https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Window.std.html, pandas.Series.rolling
">>> ser.rolling(2, win_type='gaussian').std(std=3)
0         NaN
1    0.707107
2    2.828427
3    2.121320
4    4.242641
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Window.std.html, pandas.Series.rolling
">>> ser = pd.Series([2, 3, 4, 1], index=['a', 'b', 'c', 'd'])
>>> ser.expanding().min()
a    2.0
b    2.0
c    2.0
d    1.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.min.html, pandas.Series pandas.Series.expanding
">>> ser = pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])
>>> ser.expanding().count()
a    1.0
b    2.0
c    3.0
d    4.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.count.html, pandas.Series pandas.Series.expanding
">>> df = pd.DataFrame({""A"": [1, 2, 3], ""B"": [4, 5, 6], ""C"": [7, 8, 9]})
>>> df
   A  B  C
0  1  4  7
1  2  5  8
2  3  6  9
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.aggregate.html, pandas.DataFrame
">>> df.rolling(2).sum()
     A     B     C
0  NaN   NaN   NaN
1  3.0   9.0  15.0
2  5.0  11.0  17.0
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.aggregate.html, pandas.DataFrame.rolling
">>> df.rolling(2).agg({""A"": ""sum"", ""B"": ""min""})
     A    B
0  NaN  NaN
1  3.0  4.0
2  5.0  5.0
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.aggregate.html, pandas.DataFrame.rolling
">>> df = pd.DataFrame([[1,2], [3,4], [5,6]], index=[""a"", ""b"", ""c""])
>>> df.style.hide([""a"", ""b""])  
     0    1
c    5    6
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.hide.html, pandas.DataFrame
">>> midx = pd.MultiIndex.from_product([[""x"", ""y""], [""a"", ""b"", ""c""]])
>>> df = pd.DataFrame(np.random.randn(6,6), index=midx, columns=midx)
>>> df.style.format(""{:.1f}"").hide()  
                 x                    y
   a      b      c      a      b      c
 0.1    0.0    0.4    1.3    0.6   -1.4
 0.7    1.0    1.3    1.5   -0.0   -0.2
 1.4   -0.8    1.6   -0.2   -0.4   -0.3
 0.4    1.0   -0.2   -0.8   -1.2    1.1
-0.6    1.2    1.8    1.9    0.3    0.3
 0.8    0.5   -0.3    1.2    2.2   -0.8
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.hide.html, pandas.MultiIndex.from_product pandas.DataFrame pandas.io.formats.style.Styler.hide
">>> df.style.format(""{:.1f}"").hide(subset=(slice(None), [""a"", ""c""]))
...   
                         x                    y
           a      b      c      a      b      c
x   b    0.7    1.0    1.3    1.5   -0.0   -0.2
y   b   -0.6    1.2    1.8    1.9    0.3    0.3
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.hide.html, pandas.io.formats.style.Styler.hide pandas.Series.str.slice
">>> df.style.format(""{:.1f}"").hide(subset=(slice(None), [""a"", ""c""])).hide()
...   
                 x                    y
   a      b      c      a      b      c
 0.7    1.0    1.3    1.5   -0.0   -0.2
-0.6    1.2    1.8    1.9    0.3    0.3
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.hide.html, pandas.io.formats.style.Styler.hide pandas.Series.str.slice
">>> df.style.format(""{:,.1f}"").hide(level=1)  
                     x                    y
       a      b      c      a      b      c
x    0.1    0.0    0.4    1.3    0.6   -1.4
     0.7    1.0    1.3    1.5   -0.0   -0.2
     1.4   -0.8    1.6   -0.2   -0.4   -0.3
y    0.4    1.0   -0.2   -0.8   -1.2    1.1
    -0.6    1.2    1.8    1.9    0.3    0.3
     0.8    0.5   -0.3    1.2    2.2   -0.8
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.hide.html, pandas.io.formats.style.Styler.hide
">>> df.index.names = [""lev0"", ""lev1""]
>>> df.style.format(""{:,.1f}"").hide(names=True)  
                         x                    y
           a      b      c      a      b      c
x   a    0.1    0.0    0.4    1.3    0.6   -1.4
    b    0.7    1.0    1.3    1.5   -0.0   -0.2
    c    1.4   -0.8    1.6   -0.2   -0.4   -0.3
y   a    0.4    1.0   -0.2   -0.8   -1.2    1.1
    b   -0.6    1.2    1.8    1.9    0.3    0.3
    c    0.8    0.5   -0.3    1.2    2.2   -0.8
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.hide.html, pandas.io.formats.style.Styler.hide
">>> s = pd.Series([1, 2, 3, 4])
>>> s.rolling(2).quantile(.4, interpolation='lower')
0    NaN
1    1.0
2    2.0
3    3.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.quantile.html, pandas.Series pandas.Series.rolling
">>> s.rolling(2).quantile(.4, interpolation='midpoint')
0    NaN
1    1.5
2    2.5
3    3.5
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.quantile.html, pandas.Series.rolling
">>> ser = pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])
>>> ser.expanding().apply(lambda s: s.max() - 2 * s.min())
a   -1.0
b    0.0
c    1.0
d    2.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.apply.html, pandas.Series pandas.Series.expanding pandas.Series.max pandas.Series.min
">>> s = pd.Series([1, 2, 3, 4])
>>> s.rolling(2).mean()
0    NaN
1    1.5
2    2.5
3    3.5
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.mean.html, pandas.Series pandas.Series.rolling
">>> s.rolling(3).mean()
0    NaN
1    NaN
2    2.0
3    3.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.mean.html, pandas.Series.rolling
">>> s = pd.Series([5, 5, 6, 7, 5, 5, 5])
>>> s.rolling(3).var()
0         NaN
1         NaN
2    0.333333
3    1.000000
4    1.000000
5    1.333333
6    0.000000
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.var.html, pandas.Series pandas.Series.rolling
">>> ser = pd.Series([1, 2, 3, 4])
>>> ser.ewm(alpha=.2).var()
0         NaN
1    0.500000
2    0.991803
3    1.631547
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.ewm.ExponentialMovingWindow.var.html, pandas.Series pandas.Series.ewm
">>> ser = pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])
>>> ser.expanding().median()
a    1.0
b    1.5
c    2.0
d    2.5
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.median.html, pandas.Series pandas.Series.expanding
">>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]})
>>> df
     B
0  0.0
1  1.0
2  2.0
3  NaN
4  4.0
",https://pandas.pydata.org/docs/reference/api/pandas.api.indexers.FixedForwardWindowIndexer.html, pandas.DataFrame
">>> indexer = pd.api.indexers.FixedForwardWindowIndexer(window_size=2)
>>> df.rolling(window=indexer, min_periods=1).sum()
     B
0  1.0
1  3.0
2  2.0
3  4.0
4  4.0
",https://pandas.pydata.org/docs/reference/api/pandas.api.indexers.FixedForwardWindowIndexer.html, pandas.api.indexers.FixedForwardWindowIndexer pandas.DataFrame.rolling
">>> ser1 = pd.Series([1, 2, 3, 4])
>>> ser2 = pd.Series([10, 11, 13, 16])
>>> ser1.ewm(alpha=.2).corr(ser2)
0         NaN
1    1.000000
2    0.982821
3    0.977802
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.ewm.ExponentialMovingWindow.corr.html, pandas.Series pandas.Series.ewm
">>> s = pd.Series([1, 4, 2, 3, 5, 3])
>>> s.rolling(3).rank()
0    NaN
1    NaN
2    2.0
3    2.0
4    3.0
5    1.5
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.rank.html, pandas.Series pandas.Series.rolling
">>> s.rolling(3).rank(method=""max"")
0    NaN
1    NaN
2    2.0
3    2.0
4    3.0
5    2.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.rank.html, pandas.Series.rolling
">>> s.rolling(3).rank(method=""min"")
0    NaN
1    NaN
2    2.0
3    2.0
4    3.0
5    1.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.rank.html, pandas.Series.rolling
">>> df = pd.DataFrame([[1,2], [3,4]], index=[""A"", ""B""])
>>> def color_b(s):
...     return ""background-color: yellow;"" if v == ""B"" else None
>>> df.style.map_index(color_b)  
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.map_index.html, pandas.DataFrame
">>> midx = pd.MultiIndex.from_product([['ix', 'jy'], [0, 1], ['x3', 'z4']])
>>> df = pd.DataFrame([np.arange(8)], columns=midx)
>>> def highlight_x(v):
...     return ""background-color: yellow;"" if ""x"" in v else None
>>> df.style.map_index(highlight_x, axis=""columns"", level=[0, 2])
...  
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.map_index.html, pandas.MultiIndex.from_product pandas.DataFrame
">>> df = pd.DataFrame({
...     'One': [1.2, 1.6, 1.5],
...     'Two': [2.9, 2.1, 2.5],
...     'Three': [3.1, 3.2, 3.8],
... })
>>> df.style.highlight_between(left=2.1, right=2.9)  
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.highlight_between.html, pandas.DataFrame
">>> df = pd.DataFrame({'A': [2, 1], 'B': [3, 4]})
>>> df.style.highlight_max(color='yellow')  
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.highlight_max.html, pandas.DataFrame
">>> df = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})
>>> df.style.set_caption(""test"")  
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.set_caption.html, pandas.DataFrame
">>> df = pd.DataFrame([[4, 6], [1, 9], [3, 4], [5, 5], [9, 6]],
...                   columns=[""Mike"", ""Jim""],
...                   index=[""Mon"", ""Tue"", ""Wed"", ""Thurs"", ""Fri""])
>>> styler = df.style.concat(df.agg([""sum""]).style)  
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.concat.html, pandas.DataFrame pandas.DataFrame.agg
">>> descriptors = df.agg([""sum"", ""mean"", lambda s: s.dtype])
>>> descriptors.index = [""Total"", ""Average"", ""dtype""]
>>> other = (descriptors.style
...          .highlight_max(axis=1, subset=([""Total"", ""Average""], slice(None)))
...          .format(subset=(""Average"", slice(None)), precision=2, decimal="","")
...          .map(lambda v: ""font-weight: bold;""))
>>> styler = (df.style
...             .highlight_max(color=""salmon"")
...             .set_table_styles([{""selector"": "".foot_row0"",
...                                 ""props"": ""border-top: 1px solid black;""}]))
>>> styler.concat(other)  
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.concat.html, pandas.DataFrame.agg pandas.io.formats.style.Styler.highlight_max pandas.Series.str.slice pandas.io.formats.style.Styler.format pandas.io.formats.style.Styler.set_table_styles
">>> df = pd.DataFrame([[1], [2]],
...                   index=pd.MultiIndex.from_product([[0], [1, 2]]))
>>> descriptors = df.agg([""sum""])
>>> descriptors.index = pd.MultiIndex.from_product([[""""], descriptors.index])
>>> df.style.concat(descriptors.style)  
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.concat.html, pandas.DataFrame pandas.MultiIndex.from_product pandas.DataFrame.agg
">>> df = pd.DataFrame({'A': [1, 2], 'B': [3, np.nan]})
>>> df.style.highlight_null(color='yellow')  
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.highlight_null.html, pandas.DataFrame
">>> df = pd.DataFrame(np.random.randn(10, 4))
>>> df.style.set_properties(color=""white"", align=""right"")  
>>> df.style.set_properties(**{'background-color': 'yellow'})  
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.set_properties.html, pandas.DataFrame
">>> def color_negative(v, color):
...     return f""color: {color};"" if v < 0 else None
>>> df = pd.DataFrame(np.random.randn(5, 2), columns=[""A"", ""B""])
>>> df.style.map(color_negative, color='red')  
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.map.html, pandas.DataFrame
">>> df.style.map(color_negative, color='red',
...  subset=([0,1,2], slice(None)))  
>>> df.style.map(color_negative, color='red', subset=(slice(0,5,2), ""A""))
...  
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.map.html, pandas.Series.str.slice
">>> df = pd.DataFrame(np.arange(10).reshape(2,5) + 1)
>>> df.style.highlight_quantile(axis=None, q_left=0.8, color=""#fffd75"")
...  
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.highlight_quantile.html, pandas.DataFrame
">>> df = pd.DataFrame([[1, 2], [3, 4]], index=['A', 'B'], columns=['c1', 'c2'])
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.set_uuid.html, pandas.DataFrame
">>> df.style.set_uuid(""T_20a7d_level0_col0"")
... .set_caption(""Test"")  
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.set_uuid.html, pandas.io.formats.style.Styler.set_caption
"# relabel first, then hide
df = pd.DataFrame({""col"": [""a"", ""b"", ""c""]})
df.style.relabel_index([""A"", ""B"", ""C""]).hide([0,1])
# hide first, then relabel
df = pd.DataFrame({""col"": [""a"", ""b"", ""c""]})
df.style.hide([0,1]).relabel_index([""C""])
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.relabel_index.html, pandas.DataFrame pandas.io.formats.style.Styler.hide pandas.io.formats.style.Styler.relabel_index
">>> df = pd.DataFrame({""col"": [""a"", ""b"", ""c""]})
>>> df.style.relabel_index([""A"", ""B"", ""C""])  
     col
A      a
B      b
C      c
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.relabel_index.html, pandas.DataFrame
">>> df.style.hide([0,1]).relabel_index([""C""])  
     col
C      c
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.relabel_index.html, pandas.io.formats.style.Styler.relabel_index
">>> midx = pd.MultiIndex.from_product([[0, 1], [0, 1], [0, 1]])
>>> df = pd.DataFrame({""col"": list(range(8))}, index=midx)
>>> styler = df.style  
          col
0  0  0     0
      1     1
   1  0     2
      1     3
1  0  0     4
      1     5
   1  0     6
      1     7
>>> styler.hide((midx.get_level_values(0)==0)|(midx.get_level_values(1)==0))
...  
>>> styler.hide(level=[0,1])  
>>> styler.relabel_index([""binary6"", ""binary7""])  
          col
binary6     6
binary7     7
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.relabel_index.html, pandas.MultiIndex.from_product pandas.DataFrame pandas.MultiIndex.get_level_values
">>> styler = df.loc[[(1,1,0), (1,1,1)]].style
>>> styler.hide(level=[0,1]).relabel_index([""binary6"", ""binary7""])
...  
          col
binary6     6
binary7     7
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.relabel_index.html, pandas.io.formats.style.Styler.relabel_index
">>> df = pd.DataFrame({""samples"": np.random.rand(10)})
>>> styler = df.loc[np.random.randint(0,10,3)].style
>>> styler.relabel_index([f""sample{i+1} ({{}})"" for i in range(3)])
...  
                 samples
sample1 (5)     0.315811
sample2 (0)     0.495941
sample3 (2)     0.067946
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.relabel_index.html, pandas.DataFrame
">>> df = pd.DataFrame(data=[[0, 1], [2, 3]])
>>> ttips = pd.DataFrame(
...    data=[[""Min"", """"], [np.nan, ""Max""]], columns=df.columns, index=df.index
... )
>>> s = df.style.set_tooltips(ttips).to_html()
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.set_tooltips.html, pandas.DataFrame
">>> df = pd.DataFrame(columns=[""City"", ""Temp (c)"", ""Rain (mm)"", ""Wind (m/s)""],
...                   data=[[""Stockholm"", 21.6, 5.0, 3.2],
...                         [""Oslo"", 22.4, 13.3, 3.1],
...                         [""Copenhagen"", 24.5, 0.0, 6.7]])
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.text_gradient.html, pandas.DataFrame
">>> df = pd.DataFrame(columns=[""City"", ""Temp (c)"", ""Rain (mm)"", ""Wind (m/s)""],
...                   data=[[""Stockholm"", 21.6, 5.0, 3.2],
...                         [""Oslo"", 22.4, 13.3, 3.1],
...                         [""Copenhagen"", 24.5, 0.0, 6.7]])
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.background_gradient.html, pandas.DataFrame
">>> df = pd.DataFrame([[1.0, 2.0, 3.0], [4, 5, 6]], index=['a', 'b'],
...                   columns=['A', 'B', 'C'])
>>> pd.io.formats.style.Styler(df, precision=2,
...                            caption=""My table"")  
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.html, pandas.DataFrame pandas.io.formats.style.Styler
">>> df = pd.DataFrame([[1, 2, 3]], columns=[2.0, np.nan, 4.0])
>>> df.style.format_index(axis=1, na_rep='MISS', precision=3)  
    2.000    MISS   4.000
0       1       2       3
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.format_index.html, pandas.DataFrame
">>> df = pd.DataFrame([[1, 2, 3]],
...     columns=pd.MultiIndex.from_arrays([[""a"", ""a"", ""b""],[2, np.nan, 4]]))
>>> df.style.format_index({0: lambda v: v.upper()}, axis=1, precision=1)
...  
               A       B
      2.0    nan     4.0
0       1      2       3
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.format_index.html, pandas.DataFrame pandas.MultiIndex.from_arrays
">>> df = pd.DataFrame([[1, 2, 3]], columns=['""A""', 'A&B', None])
>>> s = df.style.format_index('$ {0}', axis=1, escape=""html"", na_rep=""NA"")
...  
$ ""A""
$ A&B
NA
...
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.format_index.html, pandas.DataFrame
">>> df = pd.DataFrame([[1, 2, 3]], columns=[""123"", ""~"", ""$%#""])
>>> df.style.format_index(""\\textbf{{{}}}"", escape=""latex"", axis=1).to_latex()
...  
\begin{tabular}{lrrr}
{} & {\textbf{123}} & {\textbf{\textasciitilde }} & {\textbf{\$\%\#}} \\
0 & 1 & 2 & 3 \\
\end{tabular}
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.format_index.html, pandas.DataFrame
">>> styler = pd.DataFrame([[1, 2], [3, 4]]).style
>>> styler2 = pd.DataFrame([[9, 9, 9]]).style
>>> styler.hide(axis=0).highlight_max(axis=1)  
>>> export = styler.export()
>>> styler2.use(export)  
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.export.html, pandas.DataFrame pandas.io.formats.style.Styler.highlight_max
">>> df = pd.DataFrame({'A': [1, 2], 'B': [3, np.nan]})
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.clear.html, pandas.DataFrame
">>> def highlight_max(x, color):
...     return np.where(x == np.nanmax(x.to_numpy()), f""color: {color};"", None)
>>> df = pd.DataFrame(np.random.randn(5, 2), columns=[""A"", ""B""])
>>> df.style.apply(highlight_max, color='red')  
>>> df.style.apply(highlight_max, color='blue', axis=1)  
>>> df.style.apply(highlight_max, color='green', axis=None)  
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.apply.html, pandas.io.formats.style.Styler.highlight_max pandas.Series.to_numpy pandas.DataFrame
">>> df.style.apply(highlight_max, color='red', subset=([0, 1, 2], slice(None)))
... 
>>> df.style.apply(highlight_max, color='red', subset=(slice(0, 5, 2), ""A""))
... 
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.apply.html, pandas.Series.str.slice
">>> df = pd.DataFrame([[1, 2], [3, 4], [4, 6]], index=[""A1"", ""A2"", ""Total""])
>>> total_style = pd.Series(""font-weight: bold;"", index=[""Total""])
>>> df.style.apply(lambda s: total_style)  
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.apply.html, pandas.DataFrame pandas.Series
">>> df = pd.DataFrame([[np.nan, 1.0, 'A'], [2.0, np.nan, 3.0]])
>>> df.style.format(na_rep='MISS', precision=3)  
        0       1       2
0    MISS   1.000       A
1   2.000    MISS   3.000
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.format.html, pandas.DataFrame
">>> (df.style.format(na_rep='MISS', precision=1, subset=[0])
...     .format(na_rep='PASS', precision=2, subset=[1, 2]))  
        0      1      2
0    MISS   1.00      A
1     2.0   PASS   3.00
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.format.html, pandas.io.formats.style.Styler.format
">>> df = pd.DataFrame([['', '""A&B""', None]])
>>> s = df.style.format(
...     '{0}"">{0}', escape=""html"", na_rep=""NA""
...     )
>>> s.to_html()  
...
<div></div>
""A&B""
NA
...
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.format.html, pandas.DataFrame
">>> df = pd.DataFrame([[""123""], [""~ ^""], [""$%#""]])
>>> df.style.format(""\\textbf{{{}}}"", escape=""latex"").to_latex()
...  
\begin{tabular}{ll}
 & 0 \\
0 & \textbf{123} \\
1 & \textbf{\textasciitilde \space \textasciicircum } \\
2 & \textbf{\$\%\#} \\
\end{tabular}
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.format.html, pandas.DataFrame
">>> df = pd.DataFrame([[r""$\sum_{i=1}^{10} a_i$ a~b $\alpha \
...     = \frac{\beta}{\zeta^2}$""], [""%#^ $ \$x^2 $""]])
>>> df.style.format(escape=""latex-math"").to_latex()
...  
\begin{tabular}{ll}
 & 0 \\
0 & $\sum_{i=1}^{10} a_i$ a\textasciitilde b $\alpha = \frac{\beta}{\zeta^2}$ \\
1 & \%\#\textasciicircum \space $ \$x^2 $ \\
\end{tabular}
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.format.html, pandas.DataFrame
">>> df = pd.DataFrame([[r""\(\sum_{i=1}^{10} a_i\) a~b \(\alpha \
...     = \frac{\beta}{\zeta^2}\)""], [""%#^ \( \$x^2 \)""]])
>>> df.style.format(escape=""latex-math"").to_latex()
...  
\begin{tabular}{ll}
 & 0 \\
0 & \(\sum_{i=1}^{10} a_i\) a\textasciitilde b \(\alpha
= \frac{\beta}{\zeta^2}\) \\
1 & \%\#\textasciicircum \space \( \$x^2 \) \\
\end{tabular}
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.format.html, pandas.DataFrame
">>> df = pd.DataFrame([[r""\( x^2 \)  $x^2$""], \
...     [r""$\frac{\beta}{\zeta}$ \(\frac{\beta}{\zeta}\)""]])
>>> df.style.format(escape=""latex-math"").to_latex()
...  
\begin{tabular}{ll}
 & 0 \\
0 & \textbackslash ( x\textasciicircum 2 \textbackslash )  $x^2$ \\
1 & $\frac{\beta}{\zeta}$ \textbackslash (\textbackslash
frac\{\textbackslash beta\}\{\textbackslash zeta\}\textbackslash ) \\
\end{tabular}
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.format.html, pandas.DataFrame
">>> df = pd.DataFrame({""A"": [1, 0, -1]})
>>> pseudo_css = ""number-format: 0§[Red](0)§-§@;""
>>> filename = ""formatted_file.xlsx""
>>> df.style.map(lambda v: pseudo_css).to_excel(filename) 
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.format.html, pandas.DataFrame
">>> df = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})
>>> df.style.to_string()
' A B\n0 1 3\n1 2 4\n'
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.to_string.html, pandas.DataFrame
">>> df = pd.DataFrame({'A': [2, 1], 'B': [3, 4]})
>>> df.style.highlight_min(color='yellow')  
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.highlight_min.html, pandas.DataFrame
">>> df = pd.DataFrame({'A': [1, 2, 3, 4], 'B': [3, 4, 5, 6]})
>>> df.style.bar(subset=['A'], color='gray')  
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.bar.html, pandas.DataFrame
">>> arr = pd.array([1, 2, 3])
>>> arr2 = arr.view()
>>> arr[0] = 2
>>> arr2

[2, 2, 3]
Length: 3, dtype: Int64
",https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.ExtensionArray.view.html, pandas.array
">>> df = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})
>>> df.style.set_sticky(axis=""index"")  
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.set_sticky.html, pandas.DataFrame
">>> arr = pd.array([1, 2, 3])
>>> arr.insert(2, -1)

[1, 2, -1, 3]
Length: 4, dtype: Int64
",https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.ExtensionArray.insert.html, pandas.array
">>> arr1 = pd.array([1, 2, np.nan])
>>> arr2 = pd.array([1, 2, np.nan])
>>> arr1.equals(arr2)
True
",https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.ExtensionArray.equals.html, pandas.array
">>> pd.array([1, 1, 2, 3, 3], dtype=""Int64"").duplicated()
array([False,  True, False, False,  True])
",https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.ExtensionArray.duplicated.html, pandas.array pandas.array
">>> pd.array([1, 2, 3])._values_for_factorize()
(array([1, 2, 3], dtype=object), nan)
",https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.ExtensionArray._values_for_factorize.html, pandas.array pandas.array
">>> arr = pd.array([np.nan, np.nan, 2, 3, np.nan, np.nan])
>>> arr.fillna(0)

[0, 0, 2, 3, 0, 0]
Length: 6, dtype: Int64
",https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.ExtensionArray.fillna.html, pandas.array
">>> pd.array([1, 2, 3])._reduce(""min"")
1
",https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.ExtensionArray._reduce.html, pandas.array
">>> pd.array([1, 2, 3]).ravel()

[1, 2, 3]
Length: 3, dtype: Int64
",https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.ExtensionArray.ravel.html, pandas.array
">>> arr = pd.array([1, 2, 3])
>>> arr.ndim
1
",https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.ExtensionArray.ndim.html, pandas.array
">>> arr = pd.array([1, 2, 3, 5])
>>> arr.searchsorted([4])
array([3])
",https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.ExtensionArray.searchsorted.html, pandas.array pandas.array
">>> arr = pd.array([1, 2, 3])
>>> arr.shape
(3,)
",https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.ExtensionArray.shape.html, pandas.array
">>> pd.array([1, 2, 3]).nbytes
27
",https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.ExtensionArray.nbytes.html, pandas.array
">>> arr = pd.array([3, 1, 2, 5, 4])
>>> arr.argsort()
array([1, 2, 0, 4, 3])
",https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.ExtensionArray.argsort.html, pandas.array pandas.array
">>> interv_arr = pd.arrays.IntervalArray([pd.Interval(0, 1),
...                                      pd.Interval(1, 5), pd.Interval(1, 5)])
>>> codes, uniques = pd.factorize(interv_arr)
>>> pd.arrays.IntervalArray._from_factorized(uniques, interv_arr)

[(0, 1], (1, 5]]
Length: 2, dtype: interval[int64, right]
",https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.ExtensionArray._from_factorized.html, pandas.arrays.IntervalArray pandas.Interval pandas.factorize
">>> pd.array([1, 2, 3]).dtype
Int64Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.ExtensionArray.dtype.html, pandas.array pandas.Int64Dtype
">>> pd.qcut(range(5), 4)
... 
[(-0.001, 1.0], (-0.001, 1.0], (1.0, 2.0], (2.0, 3.0], (3.0, 4.0]]
Categories (4, interval[float64, right]): [(-0.001, 1.0] < (1.0, 2.0] ...
",https://pandas.pydata.org/docs/reference/api/pandas.qcut.html, pandas.qcut
">>> pd.qcut(range(5), 3, labels=[""good"", ""medium"", ""bad""])
... 
[good, good, medium, bad, bad]
Categories (3, object): [good < medium < bad]
",https://pandas.pydata.org/docs/reference/api/pandas.qcut.html, pandas.qcut
">>> pd.qcut(range(5), 4, labels=False)
array([0, 0, 1, 2, 3])
",https://pandas.pydata.org/docs/reference/api/pandas.qcut.html, pandas.qcut pandas.array
">>> arr = pd.array([1, 2, 3])
>>> arr.tolist()
[1, 2, 3]
",https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.ExtensionArray.tolist.html, pandas.array
">>> arr = pd.array([1, 2, np.nan, np.nan])
>>> arr.isna()
array([False, False,  True,  True])
",https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.ExtensionArray.isna.html, pandas.array pandas.array
">>> pd.interval_range(start=0, end=5)
IntervalIndex([(0, 1], (1, 2], (2, 3], (3, 4], (4, 5]],
              dtype='interval[int64, right]')
",https://pandas.pydata.org/docs/reference/api/pandas.interval_range.html, pandas.interval_range pandas.IntervalIndex
">>> pd.interval_range(start=pd.Timestamp('2017-01-01'),
...                   end=pd.Timestamp('2017-01-04'))
IntervalIndex([(2017-01-01 00:00:00, 2017-01-02 00:00:00],
               (2017-01-02 00:00:00, 2017-01-03 00:00:00],
               (2017-01-03 00:00:00, 2017-01-04 00:00:00]],
              dtype='interval[datetime64[ns], right]')
",https://pandas.pydata.org/docs/reference/api/pandas.interval_range.html, pandas.interval_range pandas.IntervalIndex
">>> pd.interval_range(start=0, periods=4, freq=1.5)
IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]],
              dtype='interval[float64, right]')
",https://pandas.pydata.org/docs/reference/api/pandas.interval_range.html, pandas.interval_range pandas.IntervalIndex
">>> pd.interval_range(start=pd.Timestamp('2017-01-01'),
...                   periods=3, freq='MS')
IntervalIndex([(2017-01-01 00:00:00, 2017-02-01 00:00:00],
               (2017-02-01 00:00:00, 2017-03-01 00:00:00],
               (2017-03-01 00:00:00, 2017-04-01 00:00:00]],
              dtype='interval[datetime64[ns], right]')
",https://pandas.pydata.org/docs/reference/api/pandas.interval_range.html, pandas.interval_range pandas.IntervalIndex
">>> pd.interval_range(start=0, end=6, periods=4)
IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]],
          dtype='interval[float64, right]')
",https://pandas.pydata.org/docs/reference/api/pandas.interval_range.html, pandas.interval_range pandas.IntervalIndex
">>> pd.interval_range(end=5, periods=4, closed='both')
IntervalIndex([[1, 2], [2, 3], [3, 4], [4, 5]],
              dtype='interval[int64, both]')
",https://pandas.pydata.org/docs/reference/api/pandas.interval_range.html, pandas.interval_range pandas.IntervalIndex
">>> arr = pd.array([1, 2, 3])
>>> arr._values_for_argsort()
array([1, 2, 3])
",https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.ExtensionArray._values_for_argsort.html, pandas.array pandas.array
">>> pd.array([1, 2])._hash_pandas_object(encoding='utf-8',
...                                      hash_key=""1000000000000000"",
...                                      categorize=False
...                                      )
array([ 6238072747940578789, 15839785061582574730], dtype=uint64)
",https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.ExtensionArray._hash_pandas_object.html, pandas.array pandas.array
">>> pd.date_range(start='1/1/2018', end='1/08/2018')
DatetimeIndex(['2018-01-01', '2018-01-02', '2018-01-03', '2018-01-04',
               '2018-01-05', '2018-01-06', '2018-01-07', '2018-01-08'],
              dtype='datetime64[ns]', freq='D')
",https://pandas.pydata.org/docs/reference/api/pandas.date_range.html, pandas.date_range pandas.DatetimeIndex
">>> pd.date_range(
...     start=pd.to_datetime(""1/1/2018"").tz_localize(""Europe/Berlin""),
...     end=pd.to_datetime(""1/08/2018"").tz_localize(""Europe/Berlin""),
... )
DatetimeIndex(['2018-01-01 00:00:00+01:00', '2018-01-02 00:00:00+01:00',
               '2018-01-03 00:00:00+01:00', '2018-01-04 00:00:00+01:00',
               '2018-01-05 00:00:00+01:00', '2018-01-06 00:00:00+01:00',
               '2018-01-07 00:00:00+01:00', '2018-01-08 00:00:00+01:00'],
              dtype='datetime64[ns, Europe/Berlin]', freq='D')
",https://pandas.pydata.org/docs/reference/api/pandas.date_range.html, pandas.date_range pandas.to_datetime pandas.DatetimeIndex
">>> pd.date_range(start='1/1/2018', periods=8)
DatetimeIndex(['2018-01-01', '2018-01-02', '2018-01-03', '2018-01-04',
               '2018-01-05', '2018-01-06', '2018-01-07', '2018-01-08'],
              dtype='datetime64[ns]', freq='D')
",https://pandas.pydata.org/docs/reference/api/pandas.date_range.html, pandas.date_range pandas.DatetimeIndex
">>> pd.date_range(end='1/1/2018', periods=8)
DatetimeIndex(['2017-12-25', '2017-12-26', '2017-12-27', '2017-12-28',
               '2017-12-29', '2017-12-30', '2017-12-31', '2018-01-01'],
              dtype='datetime64[ns]', freq='D')
",https://pandas.pydata.org/docs/reference/api/pandas.date_range.html, pandas.date_range pandas.DatetimeIndex
">>> pd.date_range(start='2018-04-24', end='2018-04-27', periods=3)
DatetimeIndex(['2018-04-24 00:00:00', '2018-04-25 12:00:00',
               '2018-04-27 00:00:00'],
              dtype='datetime64[ns]', freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.date_range.html, pandas.date_range pandas.DatetimeIndex
">>> pd.date_range(start='1/1/2018', periods=5, freq='ME')
DatetimeIndex(['2018-01-31', '2018-02-28', '2018-03-31', '2018-04-30',
               '2018-05-31'],
              dtype='datetime64[ns]', freq='ME')
",https://pandas.pydata.org/docs/reference/api/pandas.date_range.html, pandas.date_range pandas.DatetimeIndex
">>> pd.date_range(start='1/1/2018', periods=5, freq='3ME')
DatetimeIndex(['2018-01-31', '2018-04-30', '2018-07-31', '2018-10-31',
               '2019-01-31'],
              dtype='datetime64[ns]', freq='3ME')
",https://pandas.pydata.org/docs/reference/api/pandas.date_range.html, pandas.date_range pandas.DatetimeIndex
">>> pd.date_range(start='1/1/2018', periods=5, freq=pd.offsets.MonthEnd(3))
DatetimeIndex(['2018-01-31', '2018-04-30', '2018-07-31', '2018-10-31',
               '2019-01-31'],
              dtype='datetime64[ns]', freq='3ME')
",https://pandas.pydata.org/docs/reference/api/pandas.date_range.html, pandas.date_range pandas.DatetimeIndex
">>> pd.date_range(start='1/1/2018', periods=5, tz='Asia/Tokyo')
DatetimeIndex(['2018-01-01 00:00:00+09:00', '2018-01-02 00:00:00+09:00',
               '2018-01-03 00:00:00+09:00', '2018-01-04 00:00:00+09:00',
               '2018-01-05 00:00:00+09:00'],
              dtype='datetime64[ns, Asia/Tokyo]', freq='D')
",https://pandas.pydata.org/docs/reference/api/pandas.date_range.html, pandas.date_range pandas.DatetimeIndex
">>> pd.date_range(start='2017-01-01', end='2017-01-04', inclusive=""both"")
DatetimeIndex(['2017-01-01', '2017-01-02', '2017-01-03', '2017-01-04'],
              dtype='datetime64[ns]', freq='D')
",https://pandas.pydata.org/docs/reference/api/pandas.date_range.html, pandas.date_range pandas.DatetimeIndex
">>> pd.date_range(start='2017-01-01', end='2017-01-04', inclusive='left')
DatetimeIndex(['2017-01-01', '2017-01-02', '2017-01-03'],
              dtype='datetime64[ns]', freq='D')
",https://pandas.pydata.org/docs/reference/api/pandas.date_range.html, pandas.date_range pandas.DatetimeIndex
">>> pd.date_range(start='2017-01-01', end='2017-01-04', inclusive='right')
DatetimeIndex(['2017-01-02', '2017-01-03', '2017-01-04'],
              dtype='datetime64[ns]', freq='D')
",https://pandas.pydata.org/docs/reference/api/pandas.date_range.html, pandas.date_range pandas.DatetimeIndex
">>> pd.date_range(start=""2017-01-01"", periods=10, freq=""100YS"", unit=""s"")
DatetimeIndex(['2017-01-01', '2117-01-01', '2217-01-01', '2317-01-01',
               '2417-01-01', '2517-01-01', '2617-01-01', '2717-01-01',
               '2817-01-01', '2917-01-01'],
              dtype='datetime64[s]', freq='100YS-JAN')
",https://pandas.pydata.org/docs/reference/api/pandas.date_range.html, pandas.date_range pandas.DatetimeIndex
">>> arr = pd.array([1, 2, 3])
>>> arr.isin([1])

[True, False, False]
Length: 3, dtype: boolean
",https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.ExtensionArray.isin.html, pandas.array
">>> s = pd.Series(['1.0', '2', -3])
>>> pd.to_numeric(s)
0    1.0
1    2.0
2   -3.0
dtype: float64
>>> pd.to_numeric(s, downcast='float')
0    1.0
1    2.0
2   -3.0
dtype: float32
>>> pd.to_numeric(s, downcast='signed')
0    1
1    2
2   -3
dtype: int8
>>> s = pd.Series(['apple', '1.0', '2', -3])
>>> pd.to_numeric(s, errors='coerce')
0    NaN
1    1.0
2    2.0
3   -3.0
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.to_numeric.html, pandas.Series pandas.to_numeric
">>> s = pd.Series([1, 2, 3], dtype=""Int64"")
>>> pd.to_numeric(s, downcast=""integer"")
0    1
1    2
2    3
dtype: Int8
>>> s = pd.Series([1.0, 2.1, 3.0], dtype=""Float64"")
>>> pd.to_numeric(s, downcast=""float"")
0    1.0
1    2.1
2    3.0
dtype: Float32
",https://pandas.pydata.org/docs/reference/api/pandas.to_numeric.html, pandas.Series pandas.to_numeric
">>> cat = pd.Categorical(['a', 'b', 'c'])
>>> cat
['a', 'b', 'c']
Categories (3, object): ['a', 'b', 'c']
>>> cat.repeat(2)
['a', 'a', 'b', 'b', 'c', 'c']
Categories (3, object): ['a', 'b', 'c']
>>> cat.repeat([1, 2, 3])
['a', 'b', 'b', 'c', 'c', 'c']
Categories (3, object): ['a', 'b', 'c']
",https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.ExtensionArray.repeat.html, pandas.Categorical
">>> import pyarrow as pa
>>> a = pd.array([[1, 2, 3], [4], [5, 6]],
...              dtype=pd.ArrowDtype(pa.list_(pa.int64())))
>>> a._explode()
(
[1, 2, 3, 4, 5, 6]
Length: 6, dtype: int64[pyarrow], array([3, 1, 2], dtype=int32))
",https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.ExtensionArray._explode.html, pandas.array pandas.ArrowDtype pandas.array
">>> pd.util.hash_array(np.array([1, 2, 3]))
array([ 6238072747940578789, 15839785061582574730,  2185194620014831856],
  dtype=uint64)
",https://pandas.pydata.org/docs/reference/api/pandas.util.hash_array.html, pandas.util.hash_array pandas.array
">>> arr = pd.arrays.NumpyExtensionArray(np.array([0, 1, np.nan, 3]))
>>> arr.interpolate(method=""linear"",
...                 limit=3,
...                 limit_direction=""forward"",
...                 index=pd.Index([1, 2, 3, 4]),
...                 fill_value=1,
...                 copy=False,
...                 axis=0,
...                 limit_area=""inside""
...                 )

[0.0, 1.0, 2.0, 3.0]
Length: 4, dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.ExtensionArray.interpolate.html, pandas.arrays.NumpyExtensionArray pandas.Index
">>> pd.notna('dog')
True
",https://pandas.pydata.org/docs/reference/api/pandas.notna.html, pandas.notna
">>> pd.notna(pd.NA)
False
",https://pandas.pydata.org/docs/reference/api/pandas.notna.html, pandas.notna
">>> pd.notna(np.nan)
False
",https://pandas.pydata.org/docs/reference/api/pandas.notna.html, pandas.notna
">>> array = np.array([[1, np.nan, 3], [4, 5, np.nan]])
>>> array
array([[ 1., nan,  3.],
       [ 4.,  5., nan]])
>>> pd.notna(array)
array([[ True, False,  True],
       [ True,  True, False]])
",https://pandas.pydata.org/docs/reference/api/pandas.notna.html, pandas.array pandas.notna
">>> index = pd.DatetimeIndex([""2017-07-05"", ""2017-07-06"", None,
...                          ""2017-07-08""])
>>> index
DatetimeIndex(['2017-07-05', '2017-07-06', 'NaT', '2017-07-08'],
              dtype='datetime64[ns]', freq=None)
>>> pd.notna(index)
array([ True,  True, False,  True])
",https://pandas.pydata.org/docs/reference/api/pandas.notna.html, pandas.DatetimeIndex pandas.DatetimeIndex pandas.notna pandas.array
">>> df = pd.DataFrame([['ant', 'bee', 'cat'], ['dog', None, 'fly']])
>>> df
     0     1    2
0  ant   bee  cat
1  dog  None  fly
>>> pd.notna(df)
      0      1     2
0  True   True  True
1  True  False  True
",https://pandas.pydata.org/docs/reference/api/pandas.notna.html, pandas.DataFrame pandas.notna
">>> pd.notna(df[1])
0     True
1    False
Name: 1, dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.notna.html, pandas.notna
">>> arr = pd.array([1, 2, 3])
>>> arr.shift(2)

[, , 1]
Length: 3, dtype: Int64
",https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.ExtensionArray.shift.html, pandas.array
">>> s = pd.Series(list('abca'))
",https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html, pandas.Series
">>> pd.get_dummies(s)
       a      b      c
0   True  False  False
1  False   True  False
2  False  False   True
3   True  False  False
",https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html, pandas.get_dummies
">>> pd.get_dummies(s1)
       a      b
0   True  False
1  False   True
2  False  False
",https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html, pandas.get_dummies
">>> pd.get_dummies(s1, dummy_na=True)
       a      b    NaN
0   True  False  False
1  False   True  False
2  False  False   True
",https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html, pandas.get_dummies
">>> df = pd.DataFrame({'A': ['a', 'b', 'a'], 'B': ['b', 'a', 'c'],
...                    'C': [1, 2, 3]})
",https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html, pandas.DataFrame
">>> pd.get_dummies(df, prefix=['col1', 'col2'])
   C  col1_a  col1_b  col2_a  col2_b  col2_c
0  1    True   False   False    True   False
1  2   False    True    True   False   False
2  3    True   False   False   False    True
",https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html, pandas.get_dummies
">>> pd.get_dummies(pd.Series(list('abcaa')))
       a      b      c
0   True  False  False
1  False   True  False
2  False  False   True
3   True  False  False
4   True  False  False
",https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html, pandas.get_dummies pandas.Series
">>> pd.get_dummies(pd.Series(list('abcaa')), drop_first=True)
       b      c
0  False  False
1   True  False
2  False   True
3  False  False
4  False  False
",https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html, pandas.get_dummies pandas.Series
">>> pd.get_dummies(pd.Series(list('abc')), dtype=float)
     a    b    c
0  1.0  0.0  0.0
1  0.0  1.0  0.0
2  0.0  0.0  1.0
",https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html, pandas.get_dummies pandas.Series
">>> df = pd.DataFrame({""A"": [""foo"", ""foo"", ""foo"", ""foo"", ""foo"",
...                          ""bar"", ""bar"", ""bar"", ""bar""],
...                    ""B"": [""one"", ""one"", ""one"", ""two"", ""two"",
...                          ""one"", ""one"", ""two"", ""two""],
...                    ""C"": [""small"", ""large"", ""large"", ""small"",
...                          ""small"", ""large"", ""small"", ""small"",
...                          ""large""],
...                    ""D"": [1, 2, 2, 3, 3, 4, 5, 6, 7],
...                    ""E"": [2, 4, 5, 5, 6, 6, 8, 9, 9]})
>>> df
     A    B      C  D  E
0  foo  one  small  1  2
1  foo  one  large  2  4
2  foo  one  large  2  5
3  foo  two  small  3  5
4  foo  two  small  3  6
5  bar  one  large  4  6
6  bar  one  small  5  8
7  bar  two  small  6  9
8  bar  two  large  7  9
",https://pandas.pydata.org/docs/reference/api/pandas.pivot_table.html, pandas.DataFrame
">>> table = pd.pivot_table(df, values='D', index=['A', 'B'],
...                        columns=['C'], aggfunc=""sum"")
>>> table
C        large  small
A   B
bar one    4.0    5.0
    two    7.0    6.0
foo one    4.0    1.0
    two    NaN    6.0
",https://pandas.pydata.org/docs/reference/api/pandas.pivot_table.html, pandas.pivot_table
">>> table = pd.pivot_table(df, values='D', index=['A', 'B'],
...                        columns=['C'], aggfunc=""sum"", fill_value=0)
>>> table
C        large  small
A   B
bar one      4      5
    two      7      6
foo one      4      1
    two      0      6
",https://pandas.pydata.org/docs/reference/api/pandas.pivot_table.html, pandas.pivot_table
">>> table = pd.pivot_table(df, values=['D', 'E'], index=['A', 'C'],
...                        aggfunc={'D': ""mean"", 'E': ""mean""})
>>> table
                D         E
A   C
bar large  5.500000  7.500000
    small  5.500000  8.500000
foo large  2.000000  4.500000
    small  2.333333  4.333333
",https://pandas.pydata.org/docs/reference/api/pandas.pivot_table.html, pandas.pivot_table
">>> table = pd.pivot_table(df, values=['D', 'E'], index=['A', 'C'],
...                        aggfunc={'D': ""mean"",
...                                 'E': [""min"", ""max"", ""mean""]})
>>> table
                  D   E
               mean max      mean  min
A   C
bar large  5.500000   9  7.500000    6
    small  5.500000   9  8.500000    8
foo large  2.000000   5  4.500000    4
    small  2.333333   6  4.333333    2
",https://pandas.pydata.org/docs/reference/api/pandas.pivot_table.html, pandas.pivot_table
">>> idx1 = pd.PeriodIndex([""2014-01"", ""2014-01"", ""2014-02"", ""2014-02"",
...                       ""2014-03"", ""2014-03""], freq=""M"")
>>> arr, idx = idx1.factorize()
>>> arr
array([0, 0, 1, 1, 2, 2])
>>> idx
PeriodIndex(['2014-01', '2014-02', '2014-03'], dtype='period[M]')
",https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.ExtensionArray.factorize.html, pandas.PeriodIndex pandas.array pandas.PeriodIndex
">>> df = pd.DataFrame({'foo': ['one', 'one', 'one', 'two', 'two',
...                            'two'],
...                    'bar': ['A', 'B', 'C', 'A', 'B', 'C'],
...                    'baz': [1, 2, 3, 4, 5, 6],
...                    'zoo': ['x', 'y', 'z', 'q', 'w', 't']})
>>> df
    foo   bar  baz  zoo
0   one   A    1    x
1   one   B    2    y
2   one   C    3    z
3   two   A    4    q
4   two   B    5    w
5   two   C    6    t
",https://pandas.pydata.org/docs/reference/api/pandas.pivot.html, pandas.DataFrame
">>> df.pivot(index='foo', columns='bar', values='baz')
bar  A   B   C
foo
one  1   2   3
two  4   5   6
",https://pandas.pydata.org/docs/reference/api/pandas.pivot.html, pandas.DataFrame.pivot
">>> df.pivot(index='foo', columns='bar')['baz']
bar  A   B   C
foo
one  1   2   3
two  4   5   6
",https://pandas.pydata.org/docs/reference/api/pandas.pivot.html, pandas.DataFrame.pivot
">>> df.pivot(index='foo', columns='bar', values=['baz', 'zoo'])
      baz       zoo
bar   A  B  C   A  B  C
foo
one   1  2  3   x  y  z
two   4  5  6   q  w  t
",https://pandas.pydata.org/docs/reference/api/pandas.pivot.html, pandas.DataFrame.pivot
">>> df = pd.DataFrame({
...        ""lev1"": [1, 1, 1, 2, 2, 2],
...        ""lev2"": [1, 1, 2, 1, 1, 2],
...        ""lev3"": [1, 2, 1, 2, 1, 2],
...        ""lev4"": [1, 2, 3, 4, 5, 6],
...        ""values"": [0, 1, 2, 3, 4, 5]})
>>> df
    lev1 lev2 lev3 lev4 values
0   1    1    1    1    0
1   1    1    2    2    1
2   1    2    1    3    2
3   2    1    2    4    3
4   2    1    1    5    4
5   2    2    2    6    5
",https://pandas.pydata.org/docs/reference/api/pandas.pivot.html, pandas.DataFrame
">>> df.pivot(index=""lev1"", columns=[""lev2"", ""lev3""], values=""values"")
lev2    1         2
lev3    1    2    1    2
lev1
1     0.0  1.0  2.0  NaN
2     4.0  3.0  NaN  5.0
",https://pandas.pydata.org/docs/reference/api/pandas.pivot.html, pandas.DataFrame.pivot
">>> df.pivot(index=[""lev1"", ""lev2""], columns=[""lev3""], values=""values"")
      lev3    1    2
lev1  lev2
   1     1  0.0  1.0
         2  2.0  NaN
   2     1  4.0  3.0
         2  NaN  5.0
",https://pandas.pydata.org/docs/reference/api/pandas.pivot.html, pandas.DataFrame.pivot
">>> df = pd.DataFrame({""foo"": ['one', 'one', 'two', 'two'],
...                    ""bar"": ['A', 'A', 'B', 'C'],
...                    ""baz"": [1, 2, 3, 4]})
>>> df
   foo bar  baz
0  one   A    1
1  one   A    2
2  two   B    3
3  two   C    4
",https://pandas.pydata.org/docs/reference/api/pandas.pivot.html, pandas.DataFrame
">>> df.pivot(index='foo', columns='bar', values='baz')
Traceback (most recent call last):
   ...
ValueError: Index contains duplicate entries, cannot reshape
",https://pandas.pydata.org/docs/reference/api/pandas.pivot.html, pandas.DataFrame.pivot
">>> a = np.array([""foo"", ""foo"", ""foo"", ""foo"", ""bar"", ""bar"",
...               ""bar"", ""bar"", ""foo"", ""foo"", ""foo""], dtype=object)
>>> b = np.array([""one"", ""one"", ""one"", ""two"", ""one"", ""one"",
...               ""one"", ""two"", ""two"", ""two"", ""one""], dtype=object)
>>> c = np.array([""dull"", ""dull"", ""shiny"", ""dull"", ""dull"", ""shiny"",
...               ""shiny"", ""dull"", ""shiny"", ""shiny"", ""shiny""],
...              dtype=object)
>>> pd.crosstab(a, [b, c], rownames=['a'], colnames=['b', 'c'])
b   one        two
c   dull shiny dull shiny
a
bar    1     2    1     0
foo    2     2    1     2
",https://pandas.pydata.org/docs/reference/api/pandas.crosstab.html, pandas.crosstab
">>> foo = pd.Categorical(['a', 'b'], categories=['a', 'b', 'c'])
>>> bar = pd.Categorical(['d', 'e'], categories=['d', 'e', 'f'])
>>> pd.crosstab(foo, bar)
col_0  d  e
row_0
a      1  0
b      0  1
>>> pd.crosstab(foo, bar, dropna=False)
col_0  d  e  f
row_0
a      1  0  0
b      0  1  0
c      0  0  0
",https://pandas.pydata.org/docs/reference/api/pandas.crosstab.html, pandas.Categorical pandas.crosstab
">>> pd.unique(pd.Series([2, 1, 3, 3]))
array([2, 1, 3])
",https://pandas.pydata.org/docs/reference/api/pandas.unique.html, pandas.unique pandas.Series pandas.array
">>> pd.unique(pd.Series([2] + [1] * 5))
array([2, 1])
",https://pandas.pydata.org/docs/reference/api/pandas.unique.html, pandas.unique pandas.Series pandas.array
">>> pd.unique(pd.Series([pd.Timestamp(""20160101""), pd.Timestamp(""20160101"")]))
array(['2016-01-01T00:00:00.000000000'], dtype='datetime64[ns]')
",https://pandas.pydata.org/docs/reference/api/pandas.unique.html, pandas.unique pandas.Series pandas.array
">>> pd.unique(
...     pd.Series(
...         [
...             pd.Timestamp(""20160101"", tz=""US/Eastern""),
...             pd.Timestamp(""20160101"", tz=""US/Eastern""),
...         ]
...     )
... )

['2016-01-01 00:00:00-05:00']
Length: 1, dtype: datetime64[ns, US/Eastern]
",https://pandas.pydata.org/docs/reference/api/pandas.unique.html, pandas.unique pandas.Series
">>> pd.unique(
...     pd.Index(
...         [
...             pd.Timestamp(""20160101"", tz=""US/Eastern""),
...             pd.Timestamp(""20160101"", tz=""US/Eastern""),
...         ]
...     )
... )
DatetimeIndex(['2016-01-01 00:00:00-05:00'],
        dtype='datetime64[ns, US/Eastern]',
        freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.unique.html, pandas.unique pandas.Index pandas.DatetimeIndex
">>> pd.unique(np.array(list(""baabc""), dtype=""O""))
array(['b', 'a', 'c'], dtype=object)
",https://pandas.pydata.org/docs/reference/api/pandas.unique.html, pandas.unique pandas.array
">>> pd.unique(pd.Series(pd.Categorical(list(""baabc""))))
['b', 'a', 'c']
Categories (3, object): ['a', 'b', 'c']
",https://pandas.pydata.org/docs/reference/api/pandas.unique.html, pandas.unique pandas.Series pandas.Categorical
">>> pd.unique(pd.Series(pd.Categorical(list(""baabc""), categories=list(""abc""))))
['b', 'a', 'c']
Categories (3, object): ['a', 'b', 'c']
",https://pandas.pydata.org/docs/reference/api/pandas.unique.html, pandas.unique pandas.Series pandas.Categorical
">>> pd.unique(
...     pd.Series(
...         pd.Categorical(list(""baabc""), categories=list(""abc""), ordered=True)
...     )
... )
['b', 'a', 'c']
Categories (3, object): ['a' < 'b' < 'c']
",https://pandas.pydata.org/docs/reference/api/pandas.unique.html, pandas.unique pandas.Series pandas.Categorical
">>> pd.unique(pd.Series([(""a"", ""b""), (""b"", ""a""), (""a"", ""c""), (""b"", ""a"")]).values)
array([('a', 'b'), ('b', 'a'), ('a', 'c')], dtype=object)
",https://pandas.pydata.org/docs/reference/api/pandas.unique.html, pandas.unique pandas.Series pandas.array
">>> data = pd.DataFrame({'hr1': [514, 573], 'hr2': [545, 526],
...                      'team': ['Red Sox', 'Yankees'],
...                      'year1': [2007, 2007], 'year2': [2008, 2008]})
>>> data
   hr1  hr2     team  year1  year2
0  514  545  Red Sox   2007   2008
1  573  526  Yankees   2007   2008
",https://pandas.pydata.org/docs/reference/api/pandas.lreshape.html, pandas.DataFrame
">>> pd.lreshape(data, {'year': ['year1', 'year2'], 'hr': ['hr1', 'hr2']})
      team  year   hr
0  Red Sox  2007  514
1  Yankees  2007  573
2  Red Sox  2008  545
3  Yankees  2008  526
",https://pandas.pydata.org/docs/reference/api/pandas.lreshape.html, pandas.lreshape
">>> pd.period_range(start='2017-01-01', end='2018-01-01', freq='M')
PeriodIndex(['2017-01', '2017-02', '2017-03', '2017-04', '2017-05', '2017-06',
         '2017-07', '2017-08', '2017-09', '2017-10', '2017-11', '2017-12',
         '2018-01'],
        dtype='period[M]')
",https://pandas.pydata.org/docs/reference/api/pandas.period_range.html, pandas.period_range pandas.PeriodIndex
">>> pd.period_range(start=pd.Period('2017Q1', freq='Q'),
...                 end=pd.Period('2017Q2', freq='Q'), freq='M')
PeriodIndex(['2017-03', '2017-04', '2017-05', '2017-06'],
            dtype='period[M]')
",https://pandas.pydata.org/docs/reference/api/pandas.period_range.html, pandas.period_range pandas.Period pandas.PeriodIndex
">>> df = pd.DataFrame({""animal"": [""dog"", ""pig""], ""age"": [10, 20]})
>>> df
  animal  age
0    dog   10
1    pig   20
",https://pandas.pydata.org/docs/reference/api/pandas.eval.html, pandas.DataFrame
">>> pd.eval(""double_age = df.age * 2"", target=df)
  animal  age  double_age
0    dog   10          20
1    pig   20          40
",https://pandas.pydata.org/docs/reference/api/pandas.eval.html, pandas.eval
">>> pd.bdate_range(start='1/1/2018', end='1/08/2018')
DatetimeIndex(['2018-01-01', '2018-01-02', '2018-01-03', '2018-01-04',
           '2018-01-05', '2018-01-08'],
          dtype='datetime64[ns]', freq='B')
",https://pandas.pydata.org/docs/reference/api/pandas.bdate_range.html, pandas.bdate_range pandas.DatetimeIndex
">>> arr = pd.array([1, 2, 3])
>>> arr._accumulate(name='cumsum')

[1, 3, 6]
Length: 3, dtype: Int64
",https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.ExtensionArray._accumulate.html, pandas.array
">>> pd.array([1, 2, np.nan]).dropna()

[1, 2]
Length: 2, dtype: Int64
",https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.ExtensionArray.dropna.html, pandas.array
">>> df = pd.DataFrame({""a"": [1, 0, 0, 1], ""b"": [0, 1, 0, 0],
...                    ""c"": [0, 0, 1, 0]})
",https://pandas.pydata.org/docs/reference/api/pandas.from_dummies.html, pandas.DataFrame
">>> pd.from_dummies(df)
0     a
1     b
2     c
3     a
",https://pandas.pydata.org/docs/reference/api/pandas.from_dummies.html, pandas.from_dummies
">>> df = pd.DataFrame({""col1_a"": [1, 0, 1], ""col1_b"": [0, 1, 0],
...                    ""col2_a"": [0, 1, 0], ""col2_b"": [1, 0, 0],
...                    ""col2_c"": [0, 0, 1]})
",https://pandas.pydata.org/docs/reference/api/pandas.from_dummies.html, pandas.DataFrame
">>> pd.from_dummies(df, sep=""_"")
    col1    col2
0    a       b
1    b       a
2    a       c
",https://pandas.pydata.org/docs/reference/api/pandas.from_dummies.html, pandas.from_dummies
">>> df = pd.DataFrame({""col1_a"": [1, 0, 0], ""col1_b"": [0, 1, 0],
...                    ""col2_a"": [0, 1, 0], ""col2_b"": [1, 0, 0],
...                    ""col2_c"": [0, 0, 0]})
",https://pandas.pydata.org/docs/reference/api/pandas.from_dummies.html, pandas.DataFrame
">>> pd.from_dummies(df, sep=""_"", default_category={""col1"": ""d"", ""col2"": ""e""})
    col1    col2
0    a       b
1    b       a
2    d       e
",https://pandas.pydata.org/docs/reference/api/pandas.from_dummies.html, pandas.from_dummies
">>> np.random.seed(123)
>>> df = pd.DataFrame({""A1970"" : {0 : ""a"", 1 : ""b"", 2 : ""c""},
...                    ""A1980"" : {0 : ""d"", 1 : ""e"", 2 : ""f""},
...                    ""B1970"" : {0 : 2.5, 1 : 1.2, 2 : .7},
...                    ""B1980"" : {0 : 3.2, 1 : 1.3, 2 : .1},
...                    ""X""     : dict(zip(range(3), np.random.randn(3)))
...                   })
>>> df[""id""] = df.index
>>> df
  A1970 A1980  B1970  B1980         X  id
0     a     d    2.5    3.2 -1.085631   0
1     b     e    1.2    1.3  0.997345   1
2     c     f    0.7    0.1  0.282978   2
>>> pd.wide_to_long(df, [""A"", ""B""], i=""id"", j=""year"")
... 
                X  A    B
id year
0  1970 -1.085631  a  2.5
1  1970  0.997345  b  1.2
2  1970  0.282978  c  0.7
0  1980 -1.085631  d  3.2
1  1980  0.997345  e  1.3
2  1980  0.282978  f  0.1
",https://pandas.pydata.org/docs/reference/api/pandas.wide_to_long.html, pandas.DataFrame pandas.wide_to_long
">>> df = pd.DataFrame({
...     'famid': [1, 1, 1, 2, 2, 2, 3, 3, 3],
...     'birth': [1, 2, 3, 1, 2, 3, 1, 2, 3],
...     'ht1': [2.8, 2.9, 2.2, 2, 1.8, 1.9, 2.2, 2.3, 2.1],
...     'ht2': [3.4, 3.8, 2.9, 3.2, 2.8, 2.4, 3.3, 3.4, 2.9]
... })
>>> df
   famid  birth  ht1  ht2
0      1      1  2.8  3.4
1      1      2  2.9  3.8
2      1      3  2.2  2.9
3      2      1  2.0  3.2
4      2      2  1.8  2.8
5      2      3  1.9  2.4
6      3      1  2.2  3.3
7      3      2  2.3  3.4
8      3      3  2.1  2.9
>>> l = pd.wide_to_long(df, stubnames='ht', i=['famid', 'birth'], j='age')
>>> l
... 
                  ht
famid birth age
1     1     1    2.8
            2    3.4
      2     1    2.9
            2    3.8
      3     1    2.2
            2    2.9
2     1     1    2.0
            2    3.2
      2     1    1.8
            2    2.8
      3     1    1.9
            2    2.4
3     1     1    2.2
            2    3.3
      2     1    2.3
            2    3.4
      3     1    2.1
            2    2.9
",https://pandas.pydata.org/docs/reference/api/pandas.wide_to_long.html, pandas.DataFrame pandas.wide_to_long
">>> np.random.seed(0)
>>> df = pd.DataFrame({'A(weekly)-2010': np.random.rand(3),
...                    'A(weekly)-2011': np.random.rand(3),
...                    'B(weekly)-2010': np.random.rand(3),
...                    'B(weekly)-2011': np.random.rand(3),
...                    'X' : np.random.randint(3, size=3)})
>>> df['id'] = df.index
>>> df 
   A(weekly)-2010  A(weekly)-2011  B(weekly)-2010  B(weekly)-2011  X  id
0        0.548814        0.544883        0.437587        0.383442  0   0
1        0.715189        0.423655        0.891773        0.791725  1   1
2        0.602763        0.645894        0.963663        0.528895  1   2
",https://pandas.pydata.org/docs/reference/api/pandas.wide_to_long.html, pandas.DataFrame
">>> pd.wide_to_long(df, ['A(weekly)', 'B(weekly)'], i='id',
...                 j='year', sep='-')
... 
         X  A(weekly)  B(weekly)
id year
0  2010  0   0.548814   0.437587
1  2010  1   0.715189   0.891773
2  2010  1   0.602763   0.963663
0  2011  0   0.544883   0.383442
1  2011  1   0.423655   0.791725
2  2011  1   0.645894   0.528895
",https://pandas.pydata.org/docs/reference/api/pandas.wide_to_long.html, pandas.wide_to_long
">>> df = pd.DataFrame({
...     'famid': [1, 1, 1, 2, 2, 2, 3, 3, 3],
...     'birth': [1, 2, 3, 1, 2, 3, 1, 2, 3],
...     'ht_one': [2.8, 2.9, 2.2, 2, 1.8, 1.9, 2.2, 2.3, 2.1],
...     'ht_two': [3.4, 3.8, 2.9, 3.2, 2.8, 2.4, 3.3, 3.4, 2.9]
... })
>>> df
   famid  birth  ht_one  ht_two
0      1      1     2.8     3.4
1      1      2     2.9     3.8
2      1      3     2.2     2.9
3      2      1     2.0     3.2
4      2      2     1.8     2.8
5      2      3     1.9     2.4
6      3      1     2.2     3.3
7      3      2     2.3     3.4
8      3      3     2.1     2.9
",https://pandas.pydata.org/docs/reference/api/pandas.wide_to_long.html, pandas.DataFrame
">>> l = pd.wide_to_long(df, stubnames='ht', i=['famid', 'birth'], j='age',
...                     sep='_', suffix=r'\w+')
>>> l
... 
                  ht
famid birth age
1     1     one  2.8
            two  3.4
      2     one  2.9
            two  3.8
      3     one  2.2
            two  2.9
2     1     one  2.0
            two  3.2
      2     one  1.8
            two  2.8
      3     one  1.9
            two  2.4
3     1     one  2.2
            two  3.3
      2     one  2.3
            two  3.4
      3     one  2.1
            two  2.9
",https://pandas.pydata.org/docs/reference/api/pandas.wide_to_long.html, pandas.wide_to_long
">>> pd.isna('dog')
False
",https://pandas.pydata.org/docs/reference/api/pandas.isna.html, pandas.isna
">>> pd.isna(pd.NA)
True
",https://pandas.pydata.org/docs/reference/api/pandas.isna.html, pandas.isna
">>> pd.isna(np.nan)
True
",https://pandas.pydata.org/docs/reference/api/pandas.isna.html, pandas.isna
">>> array = np.array([[1, np.nan, 3], [4, 5, np.nan]])
>>> array
array([[ 1., nan,  3.],
       [ 4.,  5., nan]])
>>> pd.isna(array)
array([[False,  True, False],
       [False, False,  True]])
",https://pandas.pydata.org/docs/reference/api/pandas.isna.html, pandas.array pandas.isna
">>> index = pd.DatetimeIndex([""2017-07-05"", ""2017-07-06"", None,
...                           ""2017-07-08""])
>>> index
DatetimeIndex(['2017-07-05', '2017-07-06', 'NaT', '2017-07-08'],
              dtype='datetime64[ns]', freq=None)
>>> pd.isna(index)
array([False, False,  True, False])
",https://pandas.pydata.org/docs/reference/api/pandas.isna.html, pandas.DatetimeIndex pandas.DatetimeIndex pandas.isna pandas.array
">>> df = pd.DataFrame([['ant', 'bee', 'cat'], ['dog', None, 'fly']])
>>> df
     0     1    2
0  ant   bee  cat
1  dog  None  fly
>>> pd.isna(df)
       0      1      2
0  False  False  False
1  False   True  False
",https://pandas.pydata.org/docs/reference/api/pandas.isna.html, pandas.DataFrame pandas.isna
">>> pd.isna(df[1])
0    False
1     True
Name: 1, dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.isna.html, pandas.isna
">>> pd.cut(np.array([1, 7, 5, 4, 6, 3]), 3)
... 
[(0.994, 3.0], (5.0, 7.0], (3.0, 5.0], (3.0, 5.0], (5.0, 7.0], ...
Categories (3, interval[float64, right]): [(0.994, 3.0] < (3.0, 5.0] ...
",https://pandas.pydata.org/docs/reference/api/pandas.cut.html, pandas.cut
">>> pd.cut(np.array([1, 7, 5, 4, 6, 3]), 3, retbins=True)
... 
([(0.994, 3.0], (5.0, 7.0], (3.0, 5.0], (3.0, 5.0], (5.0, 7.0], ...
Categories (3, interval[float64, right]): [(0.994, 3.0] < (3.0, 5.0] ...
array([0.994, 3.   , 5.   , 7.   ]))
",https://pandas.pydata.org/docs/reference/api/pandas.cut.html, pandas.cut pandas.array
">>> pd.cut(np.array([1, 7, 5, 4, 6, 3]),
...        3, labels=[""bad"", ""medium"", ""good""])
['bad', 'good', 'medium', 'medium', 'good', 'bad']
Categories (3, object): ['bad' < 'medium' < 'good']
",https://pandas.pydata.org/docs/reference/api/pandas.cut.html, pandas.cut
">>> pd.cut(np.array([1, 7, 5, 4, 6, 3]), 3,
...        labels=[""B"", ""A"", ""B""], ordered=False)
['B', 'B', 'A', 'A', 'B', 'B']
Categories (2, object): ['A', 'B']
",https://pandas.pydata.org/docs/reference/api/pandas.cut.html, pandas.cut
">>> pd.cut([0, 1, 1, 2], bins=4, labels=False)
array([0, 1, 1, 3])
",https://pandas.pydata.org/docs/reference/api/pandas.cut.html, pandas.cut pandas.array
">>> s = pd.Series(np.array([2, 4, 6, 8, 10]),
...               index=['a', 'b', 'c', 'd', 'e'])
>>> pd.cut(s, 3)
... 
a    (1.992, 4.667]
b    (1.992, 4.667]
c    (4.667, 7.333]
d     (7.333, 10.0]
e     (7.333, 10.0]
dtype: category
Categories (3, interval[float64, right]): [(1.992, 4.667] < (4.667, ...
",https://pandas.pydata.org/docs/reference/api/pandas.cut.html, pandas.Series pandas.cut
">>> s = pd.Series(np.array([2, 4, 6, 8, 10]),
...               index=['a', 'b', 'c', 'd', 'e'])
>>> pd.cut(s, [0, 2, 4, 6, 8, 10], labels=False, retbins=True, right=False)
... 
(a    1.0
 b    2.0
 c    3.0
 d    4.0
 e    NaN
 dtype: float64,
 array([ 0,  2,  4,  6,  8, 10]))
",https://pandas.pydata.org/docs/reference/api/pandas.cut.html, pandas.Series pandas.cut pandas.array
">>> pd.cut(s, [0, 2, 4, 6, 10, 10], labels=False, retbins=True,
...        right=False, duplicates='drop')
... 
(a    1.0
 b    2.0
 c    3.0
 d    3.0
 e    NaN
 dtype: float64,
 array([ 0,  2,  4,  6, 10]))
",https://pandas.pydata.org/docs/reference/api/pandas.cut.html, pandas.cut pandas.array
">>> bins = pd.IntervalIndex.from_tuples([(0, 1), (2, 3), (4, 5)])
>>> pd.cut([0, 0.5, 1.5, 2.5, 4.5], bins)
[NaN, (0.0, 1.0], NaN, (2.0, 3.0], (4.0, 5.0]]
Categories (3, interval[int64, right]): [(0, 1] < (2, 3] < (4, 5]]
",https://pandas.pydata.org/docs/reference/api/pandas.cut.html, pandas.IntervalIndex.from_tuples pandas.cut
">>> pd.timedelta_range(start='1 day', periods=4)
TimedeltaIndex(['1 days', '2 days', '3 days', '4 days'],
               dtype='timedelta64[ns]', freq='D')
",https://pandas.pydata.org/docs/reference/api/pandas.timedelta_range.html, pandas.timedelta_range pandas.TimedeltaIndex
">>> pd.timedelta_range(start='1 day', periods=4, closed='right')
TimedeltaIndex(['2 days', '3 days', '4 days'],
               dtype='timedelta64[ns]', freq='D')
",https://pandas.pydata.org/docs/reference/api/pandas.timedelta_range.html, pandas.timedelta_range pandas.TimedeltaIndex
">>> pd.timedelta_range(start='1 day', end='2 days', freq='6h')
TimedeltaIndex(['1 days 00:00:00', '1 days 06:00:00', '1 days 12:00:00',
                '1 days 18:00:00', '2 days 00:00:00'],
               dtype='timedelta64[ns]', freq='6h')
",https://pandas.pydata.org/docs/reference/api/pandas.timedelta_range.html, pandas.timedelta_range pandas.TimedeltaIndex
">>> pd.timedelta_range(start='1 day', end='5 days', periods=4)
TimedeltaIndex(['1 days 00:00:00', '2 days 08:00:00', '3 days 16:00:00',
                '5 days 00:00:00'],
               dtype='timedelta64[ns]', freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.timedelta_range.html, pandas.timedelta_range pandas.TimedeltaIndex
">>> pd.timedelta_range(""1 Day"", periods=3, freq=""100000D"", unit=""s"")
TimedeltaIndex(['1 days', '100001 days', '200001 days'],
               dtype='timedelta64[s]', freq='100000D')
",https://pandas.pydata.org/docs/reference/api/pandas.timedelta_range.html, pandas.timedelta_range pandas.TimedeltaIndex
">>> from pandas import merge_ordered
>>> df1 = pd.DataFrame(
...     {
...         ""key"": [""a"", ""c"", ""e"", ""a"", ""c"", ""e""],
...         ""lvalue"": [1, 2, 3, 1, 2, 3],
...         ""group"": [""a"", ""a"", ""a"", ""b"", ""b"", ""b""]
...     }
... )
>>> df1
  key  lvalue group
0   a       1     a
1   c       2     a
2   e       3     a
3   a       1     b
4   c       2     b
5   e       3     b
",https://pandas.pydata.org/docs/reference/api/pandas.merge_ordered.html, pandas.DataFrame
">>> df2 = pd.DataFrame({""key"": [""b"", ""c"", ""d""], ""rvalue"": [1, 2, 3]})
>>> df2
  key  rvalue
0   b       1
1   c       2
2   d       3
",https://pandas.pydata.org/docs/reference/api/pandas.merge_ordered.html, pandas.DataFrame
">>> merge_ordered(df1, df2, fill_method=""ffill"", left_by=""group"")
  key  lvalue group  rvalue
0   a       1     a     NaN
1   b       1     a     1.0
2   c       2     a     2.0
3   d       2     a     3.0
4   e       3     a     3.0
5   a       1     b     NaN
6   b       1     b     1.0
7   c       2     b     2.0
8   d       2     b     3.0
9   e       3     b     3.0
",https://pandas.pydata.org/docs/reference/api/pandas.merge_ordered.html, pandas.merge_ordered
">>> left = pd.DataFrame({""a"": [1, 5, 10], ""left_val"": [""a"", ""b"", ""c""]})
>>> left
    a left_val
0   1        a
1   5        b
2  10        c
",https://pandas.pydata.org/docs/reference/api/pandas.merge_asof.html, pandas.DataFrame
">>> right = pd.DataFrame({""a"": [1, 2, 3, 6, 7], ""right_val"": [1, 2, 3, 6, 7]})
>>> right
   a  right_val
0  1          1
1  2          2
2  3          3
3  6          6
4  7          7
",https://pandas.pydata.org/docs/reference/api/pandas.merge_asof.html, pandas.DataFrame
">>> pd.merge_asof(left, right, on=""a"")
    a left_val  right_val
0   1        a          1
1   5        b          3
2  10        c          7
",https://pandas.pydata.org/docs/reference/api/pandas.merge_asof.html, pandas.merge_asof
">>> pd.merge_asof(left, right, on=""a"", allow_exact_matches=False)
    a left_val  right_val
0   1        a        NaN
1   5        b        3.0
2  10        c        7.0
",https://pandas.pydata.org/docs/reference/api/pandas.merge_asof.html, pandas.merge_asof
">>> pd.merge_asof(left, right, on=""a"", direction=""forward"")
    a left_val  right_val
0   1        a        1.0
1   5        b        6.0
2  10        c        NaN
",https://pandas.pydata.org/docs/reference/api/pandas.merge_asof.html, pandas.merge_asof
">>> pd.merge_asof(left, right, on=""a"", direction=""nearest"")
    a left_val  right_val
0   1        a          1
1   5        b          6
2  10        c          7
",https://pandas.pydata.org/docs/reference/api/pandas.merge_asof.html, pandas.merge_asof
">>> left = pd.DataFrame({""left_val"": [""a"", ""b"", ""c""]}, index=[1, 5, 10])
>>> left
   left_val
1         a
5         b
10        c
",https://pandas.pydata.org/docs/reference/api/pandas.merge_asof.html, pandas.DataFrame
">>> right = pd.DataFrame({""right_val"": [1, 2, 3, 6, 7]}, index=[1, 2, 3, 6, 7])
>>> right
   right_val
1          1
2          2
3          3
6          6
7          7
",https://pandas.pydata.org/docs/reference/api/pandas.merge_asof.html, pandas.DataFrame
">>> pd.merge_asof(left, right, left_index=True, right_index=True)
   left_val  right_val
1         a          1
5         b          3
10        c          7
",https://pandas.pydata.org/docs/reference/api/pandas.merge_asof.html, pandas.merge_asof
">>> quotes = pd.DataFrame(
...     {
...         ""time"": [
...             pd.Timestamp(""2016-05-25 13:30:00.023""),
...             pd.Timestamp(""2016-05-25 13:30:00.023""),
...             pd.Timestamp(""2016-05-25 13:30:00.030""),
...             pd.Timestamp(""2016-05-25 13:30:00.041""),
...             pd.Timestamp(""2016-05-25 13:30:00.048""),
...             pd.Timestamp(""2016-05-25 13:30:00.049""),
...             pd.Timestamp(""2016-05-25 13:30:00.072""),
...             pd.Timestamp(""2016-05-25 13:30:00.075"")
...         ],
...         ""ticker"": [
...                ""GOOG"",
...                ""MSFT"",
...                ""MSFT"",
...                ""MSFT"",
...                ""GOOG"",
...                ""AAPL"",
...                ""GOOG"",
...                ""MSFT""
...            ],
...            ""bid"": [720.50, 51.95, 51.97, 51.99, 720.50, 97.99, 720.50, 52.01],
...            ""ask"": [720.93, 51.96, 51.98, 52.00, 720.93, 98.01, 720.88, 52.03]
...     }
... )
>>> quotes
                     time ticker     bid     ask
0 2016-05-25 13:30:00.023   GOOG  720.50  720.93
1 2016-05-25 13:30:00.023   MSFT   51.95   51.96
2 2016-05-25 13:30:00.030   MSFT   51.97   51.98
3 2016-05-25 13:30:00.041   MSFT   51.99   52.00
4 2016-05-25 13:30:00.048   GOOG  720.50  720.93
5 2016-05-25 13:30:00.049   AAPL   97.99   98.01
6 2016-05-25 13:30:00.072   GOOG  720.50  720.88
7 2016-05-25 13:30:00.075   MSFT   52.01   52.03
",https://pandas.pydata.org/docs/reference/api/pandas.merge_asof.html, pandas.DataFrame
">>> trades = pd.DataFrame(
...        {
...            ""time"": [
...                pd.Timestamp(""2016-05-25 13:30:00.023""),
...                pd.Timestamp(""2016-05-25 13:30:00.038""),
...                pd.Timestamp(""2016-05-25 13:30:00.048""),
...                pd.Timestamp(""2016-05-25 13:30:00.048""),
...                pd.Timestamp(""2016-05-25 13:30:00.048"")
...            ],
...            ""ticker"": [""MSFT"", ""MSFT"", ""GOOG"", ""GOOG"", ""AAPL""],
...            ""price"": [51.95, 51.95, 720.77, 720.92, 98.0],
...            ""quantity"": [75, 155, 100, 100, 100]
...        }
...    )
>>> trades
                     time ticker   price  quantity
0 2016-05-25 13:30:00.023   MSFT   51.95        75
1 2016-05-25 13:30:00.038   MSFT   51.95       155
2 2016-05-25 13:30:00.048   GOOG  720.77       100
3 2016-05-25 13:30:00.048   GOOG  720.92       100
4 2016-05-25 13:30:00.048   AAPL   98.00       100
",https://pandas.pydata.org/docs/reference/api/pandas.merge_asof.html, pandas.DataFrame
">>> pd.merge_asof(trades, quotes, on=""time"", by=""ticker"")
                     time ticker   price  quantity     bid     ask
0 2016-05-25 13:30:00.023   MSFT   51.95        75   51.95   51.96
1 2016-05-25 13:30:00.038   MSFT   51.95       155   51.97   51.98
2 2016-05-25 13:30:00.048   GOOG  720.77       100  720.50  720.93
3 2016-05-25 13:30:00.048   GOOG  720.92       100  720.50  720.93
4 2016-05-25 13:30:00.048   AAPL   98.00       100     NaN     NaN
",https://pandas.pydata.org/docs/reference/api/pandas.merge_asof.html, pandas.merge_asof
">>> pd.merge_asof(
...     trades, quotes, on=""time"", by=""ticker"", tolerance=pd.Timedelta(""2ms"")
... )
                     time ticker   price  quantity     bid     ask
0 2016-05-25 13:30:00.023   MSFT   51.95        75   51.95   51.96
1 2016-05-25 13:30:00.038   MSFT   51.95       155     NaN     NaN
2 2016-05-25 13:30:00.048   GOOG  720.77       100  720.50  720.93
3 2016-05-25 13:30:00.048   GOOG  720.92       100  720.50  720.93
4 2016-05-25 13:30:00.048   AAPL   98.00       100     NaN     NaN
",https://pandas.pydata.org/docs/reference/api/pandas.merge_asof.html, pandas.merge_asof
">>> pd.merge_asof(
...     trades,
...     quotes,
...     on=""time"",
...     by=""ticker"",
...     tolerance=pd.Timedelta(""10ms""),
...     allow_exact_matches=False
... )
                     time ticker   price  quantity     bid     ask
0 2016-05-25 13:30:00.023   MSFT   51.95        75     NaN     NaN
1 2016-05-25 13:30:00.038   MSFT   51.95       155   51.97   51.98
2 2016-05-25 13:30:00.048   GOOG  720.77       100     NaN     NaN
3 2016-05-25 13:30:00.048   GOOG  720.92       100     NaN     NaN
4 2016-05-25 13:30:00.048   AAPL   98.00       100     NaN     NaN
",https://pandas.pydata.org/docs/reference/api/pandas.merge_asof.html, pandas.merge_asof
">>> df = pd.DataFrame({'year': [2015, 2016],
...                    'month': [2, 3],
...                    'day': [4, 5]})
>>> pd.to_datetime(df)
0   2015-02-04
1   2016-03-05
dtype: datetime64[ns]
",https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html, pandas.DataFrame pandas.to_datetime
">>> pd.to_datetime(1490195805, unit='s')
Timestamp('2017-03-22 15:16:45')
>>> pd.to_datetime(1490195805433502912, unit='ns')
Timestamp('2017-03-22 15:16:45.433502912')
",https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html, pandas.to_datetime
">>> pd.to_datetime([1, 2, 3], unit='D',
...                origin=pd.Timestamp('1960-01-01'))
DatetimeIndex(['1960-01-02', '1960-01-03', '1960-01-04'],
              dtype='datetime64[ns]', freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html, pandas.to_datetime pandas.DatetimeIndex
">>> pd.to_datetime('2018-10-26 12:00:00.0000000011',
...                format='%Y-%m-%d %H:%M:%S.%f')
Timestamp('2018-10-26 12:00:00.000000001')
",https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html, pandas.to_datetime
">>> pd.to_datetime('13000101', format='%Y%m%d', errors='coerce')
NaT
",https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html, pandas.to_datetime
">>> pd.to_datetime(['2018-10-26 12:00:00', '2018-10-26 13:00:15'])
DatetimeIndex(['2018-10-26 12:00:00', '2018-10-26 13:00:15'],
              dtype='datetime64[ns]', freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html, pandas.to_datetime pandas.DatetimeIndex
">>> pd.to_datetime(['2018-10-26 12:00 -0500', '2018-10-26 13:00 -0500'])
DatetimeIndex(['2018-10-26 12:00:00-05:00', '2018-10-26 13:00:00-05:00'],
              dtype='datetime64[ns, UTC-05:00]', freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html, pandas.to_datetime pandas.DatetimeIndex
">>> pd.to_datetime(['2020-10-25 02:00 +0200',
...                 '2020-10-25 04:00 +0100'])  
FutureWarning: In a future version of pandas, parsing datetimes with mixed
time zones will raise an error unless `utc=True`. Please specify `utc=True`
to opt in to the new behaviour and silence this warning. To create a `Series`
with mixed offsets and `object` dtype, please use `apply` and
`datetime.datetime.strptime`.
Index([2020-10-25 02:00:00+02:00, 2020-10-25 04:00:00+01:00],
      dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html, pandas.to_datetime pandas.Index
">>> from datetime import datetime
>>> pd.to_datetime([""2020-01-01 01:00:00-01:00"",
...                 datetime(2020, 1, 1, 3, 0)])  
FutureWarning: In a future version of pandas, parsing datetimes with mixed
time zones will raise an error unless `utc=True`. Please specify `utc=True`
to opt in to the new behaviour and silence this warning. To create a `Series`
with mixed offsets and `object` dtype, please use `apply` and
`datetime.datetime.strptime`.
Index([2020-01-01 01:00:00-01:00, 2020-01-01 03:00:00], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html, pandas.to_datetime pandas.Index
">>> pd.to_datetime(['2018-10-26 12:00', '2018-10-26 13:00'], utc=True)
DatetimeIndex(['2018-10-26 12:00:00+00:00', '2018-10-26 13:00:00+00:00'],
              dtype='datetime64[ns, UTC]', freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html, pandas.to_datetime pandas.DatetimeIndex
">>> pd.to_datetime(['2018-10-26 12:00 -0530', '2018-10-26 12:00 -0500'],
...                utc=True)
DatetimeIndex(['2018-10-26 17:30:00+00:00', '2018-10-26 17:00:00+00:00'],
              dtype='datetime64[ns, UTC]', freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html, pandas.to_datetime pandas.DatetimeIndex
">>> pd.to_datetime(['2018-10-26 12:00', datetime(2020, 1, 1, 18)], utc=True)
DatetimeIndex(['2018-10-26 12:00:00+00:00', '2020-01-01 18:00:00+00:00'],
              dtype='datetime64[ns, UTC]', freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html, pandas.to_datetime pandas.DatetimeIndex
">>> from pandas.io.formats.style import Styler
>>> EasyStyler = Styler.from_custom_template(""path/to/template"",
...                                          ""template.tpl"",
...                                          )  
>>> df = pd.DataFrame({""A"": [1, 2]})
>>> EasyStyler(df)  
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.from_custom_template.html, pandas.io.formats.style.Styler.from_custom_template pandas.DataFrame
">>> codes, uniques = pd.factorize(np.array(['b', 'b', 'a', 'c', 'b'], dtype=""O""))
>>> codes
array([0, 0, 1, 2, 0])
>>> uniques
array(['b', 'a', 'c'], dtype=object)
",https://pandas.pydata.org/docs/reference/api/pandas.factorize.html, pandas.factorize pandas.array
">>> codes, uniques = pd.factorize(np.array(['b', 'b', 'a', 'c', 'b'], dtype=""O""),
...                               sort=True)
>>> codes
array([1, 1, 0, 2, 1])
>>> uniques
array(['a', 'b', 'c'], dtype=object)
",https://pandas.pydata.org/docs/reference/api/pandas.factorize.html, pandas.factorize pandas.array
">>> codes, uniques = pd.factorize(np.array(['b', None, 'a', 'c', 'b'], dtype=""O""))
>>> codes
array([ 0, -1,  1,  2,  0])
>>> uniques
array(['b', 'a', 'c'], dtype=object)
",https://pandas.pydata.org/docs/reference/api/pandas.factorize.html, pandas.factorize pandas.array
">>> cat = pd.Categorical(['a', 'a', 'c'], categories=['a', 'b', 'c'])
>>> codes, uniques = pd.factorize(cat)
>>> codes
array([0, 0, 1])
>>> uniques
['a', 'c']
Categories (3, object): ['a', 'b', 'c']
",https://pandas.pydata.org/docs/reference/api/pandas.factorize.html, pandas.Categorical pandas.factorize pandas.array
">>> cat = pd.Series(['a', 'a', 'c'])
>>> codes, uniques = pd.factorize(cat)
>>> codes
array([0, 0, 1])
>>> uniques
Index(['a', 'c'], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.factorize.html, pandas.Series pandas.factorize pandas.array pandas.Index
">>> values = np.array([1, 2, 1, np.nan])
>>> codes, uniques = pd.factorize(values)  # default: use_na_sentinel=True
>>> codes
array([ 0,  1,  0, -1])
>>> uniques
array([1., 2.])
",https://pandas.pydata.org/docs/reference/api/pandas.factorize.html, pandas.factorize pandas.array
">>> codes, uniques = pd.factorize(values, use_na_sentinel=False)
>>> codes
array([0, 1, 0, 2])
>>> uniques
array([ 1.,  2., nan])
",https://pandas.pydata.org/docs/reference/api/pandas.factorize.html, pandas.factorize pandas.array
">>> df = pd.DataFrame({'A': {0: 'a', 1: 'b', 2: 'c'},
...                    'B': {0: 1, 1: 3, 2: 5},
...                    'C': {0: 2, 1: 4, 2: 6}})
>>> df
   A  B  C
0  a  1  2
1  b  3  4
2  c  5  6
",https://pandas.pydata.org/docs/reference/api/pandas.melt.html, pandas.DataFrame
">>> pd.melt(df, id_vars=['A'], value_vars=['B'])
   A variable  value
0  a        B      1
1  b        B      3
2  c        B      5
",https://pandas.pydata.org/docs/reference/api/pandas.melt.html, pandas.melt
">>> pd.melt(df, id_vars=['A'], value_vars=['B', 'C'])
   A variable  value
0  a        B      1
1  b        B      3
2  c        B      5
3  a        C      2
4  b        C      4
5  c        C      6
",https://pandas.pydata.org/docs/reference/api/pandas.melt.html, pandas.melt
">>> pd.melt(df, id_vars=['A'], value_vars=['B'],
...         var_name='myVarname', value_name='myValname')
   A myVarname  myValname
0  a         B          1
1  b         B          3
2  c         B          5
",https://pandas.pydata.org/docs/reference/api/pandas.melt.html, pandas.melt
">>> pd.melt(df, id_vars=['A'], value_vars=['B', 'C'], ignore_index=False)
   A variable  value
0  a        B      1
1  b        B      3
2  c        B      5
0  a        C      2
1  b        C      4
2  c        C      6
",https://pandas.pydata.org/docs/reference/api/pandas.melt.html, pandas.melt
">>> pd.melt(df, col_level=0, id_vars=['A'], value_vars=['B'])
   A variable  value
0  a        B      1
1  b        B      3
2  c        B      5
",https://pandas.pydata.org/docs/reference/api/pandas.melt.html, pandas.melt
">>> pd.melt(df, id_vars=[('A', 'D')], value_vars=[('B', 'E')])
  (A, D) variable_0 variable_1  value
0      a          B          E      1
1      b          B          E      3
2      c          B          E      5
",https://pandas.pydata.org/docs/reference/api/pandas.melt.html, pandas.melt
">>> df = pd.DataFrame([[1,2], [3,4]], index=[""A"", ""B""])
>>> def color_b(s):
...     return np.where(s == ""B"", ""background-color: yellow;"", """")
>>> df.style.apply_index(color_b)  
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.apply_index.html, pandas.DataFrame
">>> midx = pd.MultiIndex.from_product([['ix', 'jy'], [0, 1], ['x3', 'z4']])
>>> df = pd.DataFrame([np.arange(8)], columns=midx)
>>> def highlight_x(s):
...     return [""background-color: yellow;"" if ""x"" in v else """" for v in s]
>>> df.style.apply_index(highlight_x, axis=""columns"", level=[0, 2])
...  
",https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.apply_index.html, pandas.MultiIndex.from_product pandas.DataFrame
">>> arr = pd.array([np.nan, np.nan, 2, 3, np.nan, np.nan])
>>> arr._pad_or_backfill(method=""backfill"", limit=1)

[, 2, 2, 3, , ]
Length: 6, dtype: Int64
",https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.ExtensionArray._pad_or_backfill.html, pandas.array
">>> arr = pd.array([1, 2, 3])
>>> arr2 = arr.copy()
>>> arr[0] = 2
>>> arr2

[1, 2, 3]
Length: 3, dtype: Int64
",https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.ExtensionArray.copy.html, pandas.array
">>> arr = pd.array([1, 2, 3])
>>> arr

[1, 2, 3]
Length: 3, dtype: Int64
",https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.ExtensionArray.astype.html, pandas.array
">>> arr1 = arr.astype('Float64')
>>> arr1

[1.0, 2.0, 3.0]
Length: 3, dtype: Float64
>>> arr1.dtype
Float64Dtype()
",https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.ExtensionArray.astype.html, pandas.Float64Dtype
">>> arr2 = arr.astype('float64')
>>> arr2
array([1., 2., 3.])
>>> arr2.dtype
dtype('float64')
",https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.ExtensionArray.astype.html, pandas.array
">>> arr1 = pd.array([1, 2, 3])
>>> arr2 = pd.array([4, 5, 6])
>>> pd.arrays.IntegerArray._concat_same_type([arr1, arr2])

[1, 2, 3, 4, 5, 6]
Length: 6, dtype: Int64
",https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.ExtensionArray._concat_same_type.html, pandas.array
">>> arr = pd.array([1, 2, 3, 1, 2, 3])
>>> arr.unique()

[1, 2, 3]
Length: 3, dtype: Int64
",https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.ExtensionArray.unique.html, pandas.array
">>> df1 = pd.DataFrame({'lkey': ['foo', 'bar', 'baz', 'foo'],
...                     'value': [1, 2, 3, 5]})
>>> df2 = pd.DataFrame({'rkey': ['foo', 'bar', 'baz', 'foo'],
...                     'value': [5, 6, 7, 8]})
>>> df1
    lkey value
0   foo      1
1   bar      2
2   baz      3
3   foo      5
>>> df2
    rkey value
0   foo      5
1   bar      6
2   baz      7
3   foo      8
",https://pandas.pydata.org/docs/reference/api/pandas.merge.html, pandas.DataFrame
">>> df1.merge(df2, left_on='lkey', right_on='rkey')
  lkey  value_x rkey  value_y
0  foo        1  foo        5
1  foo        1  foo        8
2  bar        2  bar        6
3  baz        3  baz        7
4  foo        5  foo        5
5  foo        5  foo        8
",https://pandas.pydata.org/docs/reference/api/pandas.merge.html, pandas.DataFrame.merge
">>> df1.merge(df2, left_on='lkey', right_on='rkey',
...           suffixes=('_left', '_right'))
  lkey  value_left rkey  value_right
0  foo           1  foo            5
1  foo           1  foo            8
2  bar           2  bar            6
3  baz           3  baz            7
4  foo           5  foo            5
5  foo           5  foo            8
",https://pandas.pydata.org/docs/reference/api/pandas.merge.html, pandas.DataFrame.merge
">>> df1.merge(df2, left_on='lkey', right_on='rkey', suffixes=(False, False))
Traceback (most recent call last):
...
ValueError: columns overlap but no suffix specified:
    Index(['value'], dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.merge.html, pandas.DataFrame.merge pandas.Index
">>> df1 = pd.DataFrame({'a': ['foo', 'bar'], 'b': [1, 2]})
>>> df2 = pd.DataFrame({'a': ['foo', 'baz'], 'c': [3, 4]})
>>> df1
      a  b
0   foo  1
1   bar  2
>>> df2
      a  c
0   foo  3
1   baz  4
",https://pandas.pydata.org/docs/reference/api/pandas.merge.html, pandas.DataFrame
">>> df1.merge(df2, how='inner', on='a')
      a  b  c
0   foo  1  3
",https://pandas.pydata.org/docs/reference/api/pandas.merge.html, pandas.DataFrame.merge
">>> df1.merge(df2, how='left', on='a')
      a  b  c
0   foo  1  3.0
1   bar  2  NaN
",https://pandas.pydata.org/docs/reference/api/pandas.merge.html, pandas.DataFrame.merge
">>> df1 = pd.DataFrame({'left': ['foo', 'bar']})
>>> df2 = pd.DataFrame({'right': [7, 8]})
>>> df1
    left
0   foo
1   bar
>>> df2
    right
0   7
1   8
",https://pandas.pydata.org/docs/reference/api/pandas.merge.html, pandas.DataFrame
">>> df1.merge(df2, how='cross')
   left  right
0   foo      7
1   foo      8
2   bar      7
3   bar      8
",https://pandas.pydata.org/docs/reference/api/pandas.merge.html, pandas.DataFrame.merge
">>> pd.isna('dog')
False
",https://pandas.pydata.org/docs/reference/api/pandas.isnull.html, pandas.isna
">>> pd.isna(pd.NA)
True
",https://pandas.pydata.org/docs/reference/api/pandas.isnull.html, pandas.isna
">>> pd.isna(np.nan)
True
",https://pandas.pydata.org/docs/reference/api/pandas.isnull.html, pandas.isna
">>> array = np.array([[1, np.nan, 3], [4, 5, np.nan]])
>>> array
array([[ 1., nan,  3.],
       [ 4.,  5., nan]])
>>> pd.isna(array)
array([[False,  True, False],
       [False, False,  True]])
",https://pandas.pydata.org/docs/reference/api/pandas.isnull.html, pandas.array pandas.isna
">>> index = pd.DatetimeIndex([""2017-07-05"", ""2017-07-06"", None,
...                           ""2017-07-08""])
>>> index
DatetimeIndex(['2017-07-05', '2017-07-06', 'NaT', '2017-07-08'],
              dtype='datetime64[ns]', freq=None)
>>> pd.isna(index)
array([False, False,  True, False])
",https://pandas.pydata.org/docs/reference/api/pandas.isnull.html, pandas.DatetimeIndex pandas.DatetimeIndex pandas.isna pandas.array
">>> df = pd.DataFrame([['ant', 'bee', 'cat'], ['dog', None, 'fly']])
>>> df
     0     1    2
0  ant   bee  cat
1  dog  None  fly
>>> pd.isna(df)
       0      1      2
0  False  False  False
1  False   True  False
",https://pandas.pydata.org/docs/reference/api/pandas.isnull.html, pandas.DataFrame pandas.isna
">>> pd.isna(df[1])
0    False
1     True
Name: 1, dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.isnull.html, pandas.isna
">>> pd.set_option('display.max_columns', 4)
>>> df = pd.DataFrame([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])
>>> df
   0  1  ...  3   4
0  1  2  ...  4   5
1  6  7  ...  9  10
[2 rows x 5 columns]
>>> pd.reset_option('display.max_columns')
",https://pandas.pydata.org/docs/reference/api/pandas.set_option.html, pandas.DataFrame
">>> pd.util.hash_pandas_object(pd.Series([1, 2, 3]))
0    14639053686158035780
1     3869563279212530728
2      393322362522515241
dtype: uint64
",https://pandas.pydata.org/docs/reference/api/pandas.util.hash_pandas_object.html, pandas.util.hash_pandas_object pandas.Series
">>> s1 = pd.Series(['a', 'b'])
>>> s2 = pd.Series(['c', 'd'])
>>> pd.concat([s1, s2])
0    a
1    b
0    c
1    d
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.concat.html, pandas.Series pandas.concat
">>> pd.concat([s1, s2], ignore_index=True)
0    a
1    b
2    c
3    d
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.concat.html, pandas.concat
">>> pd.concat([s1, s2], keys=['s1', 's2'])
s1  0    a
    1    b
s2  0    c
    1    d
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.concat.html, pandas.concat
">>> pd.concat([s1, s2], keys=['s1', 's2'],
...           names=['Series name', 'Row ID'])
Series name  Row ID
s1           0         a
             1         b
s2           0         c
             1         d
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.concat.html, pandas.concat
">>> df1 = pd.DataFrame([['a', 1], ['b', 2]],
...                    columns=['letter', 'number'])
>>> df1
  letter  number
0      a       1
1      b       2
>>> df2 = pd.DataFrame([['c', 3], ['d', 4]],
...                    columns=['letter', 'number'])
>>> df2
  letter  number
0      c       3
1      d       4
>>> pd.concat([df1, df2])
  letter  number
0      a       1
1      b       2
0      c       3
1      d       4
",https://pandas.pydata.org/docs/reference/api/pandas.concat.html, pandas.DataFrame pandas.concat
">>> df3 = pd.DataFrame([['c', 3, 'cat'], ['d', 4, 'dog']],
...                    columns=['letter', 'number', 'animal'])
>>> df3
  letter  number animal
0      c       3    cat
1      d       4    dog
>>> pd.concat([df1, df3], sort=False)
  letter  number animal
0      a       1    NaN
1      b       2    NaN
0      c       3    cat
1      d       4    dog
",https://pandas.pydata.org/docs/reference/api/pandas.concat.html, pandas.DataFrame pandas.concat
">>> pd.concat([df1, df3], join=""inner"")
  letter  number
0      a       1
1      b       2
0      c       3
1      d       4
",https://pandas.pydata.org/docs/reference/api/pandas.concat.html, pandas.concat
">>> df4 = pd.DataFrame([['bird', 'polly'], ['monkey', 'george']],
...                    columns=['animal', 'name'])
>>> pd.concat([df1, df4], axis=1)
  letter  number  animal    name
0      a       1    bird   polly
1      b       2  monkey  george
",https://pandas.pydata.org/docs/reference/api/pandas.concat.html, pandas.DataFrame pandas.concat
">>> df5 = pd.DataFrame([1], index=['a'])
>>> df5
   0
a  1
>>> df6 = pd.DataFrame([2], index=['a'])
>>> df6
   0
a  2
>>> pd.concat([df5, df6], verify_integrity=True)
Traceback (most recent call last):
    ...
ValueError: Indexes have overlapping values: ['a']
",https://pandas.pydata.org/docs/reference/api/pandas.concat.html, pandas.DataFrame pandas.concat
">>> df7 = pd.DataFrame({'a': 1, 'b': 2}, index=[0])
>>> df7
    a   b
0   1   2
>>> new_row = pd.Series({'a': 3, 'b': 4})
>>> new_row
a    3
b    4
dtype: int64
>>> pd.concat([df7, new_row.to_frame().T], ignore_index=True)
    a   b
0   1   2
1   3   4
",https://pandas.pydata.org/docs/reference/api/pandas.concat.html, pandas.DataFrame pandas.Series pandas.concat pandas.Series.to_frame
">>> pd.to_timedelta('1 days 06:05:01.00003')
Timedelta('1 days 06:05:01.000030')
>>> pd.to_timedelta('15.5us')
Timedelta('0 days 00:00:00.000015500')
",https://pandas.pydata.org/docs/reference/api/pandas.to_timedelta.html, pandas.to_timedelta
">>> pd.to_timedelta(['1 days 06:05:01.00003', '15.5us', 'nan'])
TimedeltaIndex(['1 days 06:05:01.000030', '0 days 00:00:00.000015500', NaT],
               dtype='timedelta64[ns]', freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.to_timedelta.html, pandas.to_timedelta pandas.TimedeltaIndex
">>> pd.to_timedelta(np.arange(5), unit='s')
TimedeltaIndex(['0 days 00:00:00', '0 days 00:00:01', '0 days 00:00:02',
                '0 days 00:00:03', '0 days 00:00:04'],
               dtype='timedelta64[ns]', freq=None)
>>> pd.to_timedelta(np.arange(5), unit='d')
TimedeltaIndex(['0 days', '1 days', '2 days', '3 days', '4 days'],
               dtype='timedelta64[ns]', freq=None)
",https://pandas.pydata.org/docs/reference/api/pandas.to_timedelta.html, pandas.to_timedelta pandas.TimedeltaIndex
">>> pd.notna('dog')
True
",https://pandas.pydata.org/docs/reference/api/pandas.notnull.html, pandas.notna
">>> pd.notna(pd.NA)
False
",https://pandas.pydata.org/docs/reference/api/pandas.notnull.html, pandas.notna
">>> pd.notna(np.nan)
False
",https://pandas.pydata.org/docs/reference/api/pandas.notnull.html, pandas.notna
">>> array = np.array([[1, np.nan, 3], [4, 5, np.nan]])
>>> array
array([[ 1., nan,  3.],
       [ 4.,  5., nan]])
>>> pd.notna(array)
array([[ True, False,  True],
       [ True,  True, False]])
",https://pandas.pydata.org/docs/reference/api/pandas.notnull.html, pandas.array pandas.notna
">>> index = pd.DatetimeIndex([""2017-07-05"", ""2017-07-06"", None,
...                          ""2017-07-08""])
>>> index
DatetimeIndex(['2017-07-05', '2017-07-06', 'NaT', '2017-07-08'],
              dtype='datetime64[ns]', freq=None)
>>> pd.notna(index)
array([ True,  True, False,  True])
",https://pandas.pydata.org/docs/reference/api/pandas.notnull.html, pandas.DatetimeIndex pandas.DatetimeIndex pandas.notna pandas.array
">>> df = pd.DataFrame([['ant', 'bee', 'cat'], ['dog', None, 'fly']])
>>> df
     0     1    2
0  ant   bee  cat
1  dog  None  fly
>>> pd.notna(df)
      0      1     2
0  True   True  True
1  True  False  True
",https://pandas.pydata.org/docs/reference/api/pandas.notnull.html, pandas.DataFrame pandas.notna
">>> pd.notna(df[1])
0     True
1    False
Name: 1, dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.notnull.html, pandas.notna
">>> idx = pd.date_range(start='2020/12/01', end='2020/12/30', periods=30)
>>> pd.infer_freq(idx)
'D'
",https://pandas.pydata.org/docs/reference/api/pandas.infer_freq.html, pandas.date_range pandas.infer_freq
">>> from pandas.tseries.api import guess_datetime_format
>>> guess_datetime_format('09/13/2023')
'%m/%d/%Y'
",https://pandas.pydata.org/docs/reference/api/pandas.tseries.api.guess_datetime_format.html, pandas.tseries.api.guess_datetime_format
">>> guess_datetime_format('2023|September|13')
",https://pandas.pydata.org/docs/reference/api/pandas.tseries.api.guess_datetime_format.html, pandas.tseries.api.guess_datetime_format
">>> ts + Micro(n=1000)
Timestamp('2022-12-09 15:00:00.001000')
",https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Micro.html, pandas.tseries.offsets.Micro
">>> ts - Micro(n=1000)
Timestamp('2022-12-09 14:59:59.999000')
",https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Micro.html, pandas.tseries.offsets.Micro
">>> ts + Micro(n=-1000)
Timestamp('2022-12-09 14:59:59.999000')
",https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Micro.html, pandas.tseries.offsets.Micro
">>> import datetime as dt
>>> freq = pd.offsets.CustomBusinessDay(weekmask=""Mon Wed Fri"")
>>> pd.date_range(dt.datetime(2022, 12, 10), dt.datetime(2022, 12, 21),
...               freq=freq).strftime('%a %d %b %Y %H:%M')
Index(['Mon 12 Dec 2022 00:00', 'Wed 14 Dec 2022 00:00',
       'Fri 16 Dec 2022 00:00', 'Mon 19 Dec 2022 00:00',
       'Wed 21 Dec 2022 00:00'],
       dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.html, pandas.date_range pandas.Index
">>> import datetime as dt
>>> bdc = np.busdaycalendar(holidays=['2022-12-12', '2022-12-14'])
>>> freq = pd.offsets.CustomBusinessDay(calendar=bdc)
>>> pd.date_range(dt.datetime(2022, 12, 10), dt.datetime(2022, 12, 25), freq=freq)
DatetimeIndex(['2022-12-13', '2022-12-15', '2022-12-16', '2022-12-19',
               '2022-12-20', '2022-12-21', '2022-12-22', '2022-12-23'],
               dtype='datetime64[ns]', freq='C')
",https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.html, pandas.date_range pandas.DatetimeIndex
">>> import datetime as dt
>>> freq = pd.offsets.CustomBusinessMonthEnd(weekmask=""Wed Thu"")
>>> pd.date_range(dt.datetime(2022, 7, 10), dt.datetime(2022, 12, 18),
...               freq=freq).strftime('%a %d %b %Y %H:%M')
Index(['Thu 28 Jul 2022 00:00', 'Wed 31 Aug 2022 00:00',
       'Thu 29 Sep 2022 00:00', 'Thu 27 Oct 2022 00:00',
       'Wed 30 Nov 2022 00:00'],
       dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.html, pandas.date_range pandas.Index
">>> import datetime as dt
>>> bdc = np.busdaycalendar(holidays=['2022-08-01', '2022-09-30',
...                                   '2022-10-31', '2022-11-01'])
>>> freq = pd.offsets.CustomBusinessMonthEnd(calendar=bdc)
>>> pd.date_range(dt.datetime(2022, 7, 10), dt.datetime(2022, 11, 10), freq=freq)
DatetimeIndex(['2022-07-29', '2022-08-31', '2022-09-29', '2022-10-28'],
               dtype='datetime64[ns]', freq='CBME')
",https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.html, pandas.date_range pandas.DatetimeIndex
">>> from pandas.tseries.offsets import DateOffset
>>> ts = pd.Timestamp('2017-01-01 09:10:11')
>>> ts + DateOffset(months=3)
Timestamp('2017-04-01 09:10:11')
",https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.html, pandas.tseries.offsets.DateOffset
">>> ts = pd.Timestamp('2017-01-01 09:10:11')
>>> ts + DateOffset(months=2)
Timestamp('2017-03-01 09:10:11')
>>> ts + DateOffset(day=31)
Timestamp('2017-01-31 09:10:11')
",https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.html, pandas.tseries.offsets.DateOffset
">>> from pandas.tseries.offsets import BYearBegin
>>> ts = pd.Timestamp('2020-05-24 05:01:15')
>>> ts + BYearBegin()
Timestamp('2021-01-01 05:01:15')
>>> ts - BYearBegin()
Timestamp('2020-01-01 05:01:15')
>>> ts + BYearBegin(-1)
Timestamp('2020-01-01 05:01:15')
>>> ts + BYearBegin(2)
Timestamp('2022-01-03 05:01:15')
>>> ts + BYearBegin(month=11)
Timestamp('2020-11-02 05:01:15')
",https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearBegin.html, pandas.tseries.offsets.BYearBegin
">>> ts + Hour()
Timestamp('2022-12-09 16:00:00')
>>> ts - Hour(4)
Timestamp('2022-12-09 11:00:00')
",https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Hour.html, pandas.tseries.offsets.Hour
">>> ts + Hour(-4)
Timestamp('2022-12-09 11:00:00')
",https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Hour.html, pandas.tseries.offsets.Hour
">>> ts + Second(n=10)
Timestamp('2022-12-09 15:00:10')
>>> ts - Second(n=10)
Timestamp('2022-12-09 14:59:50')
",https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Second.html, pandas.tseries.offsets.Second
">>> ts + Second(n=-10)
Timestamp('2022-12-09 14:59:50')
",https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Second.html, pandas.tseries.offsets.Second
">>> import datetime as dt
>>> freq = pd.offsets.BusinessHour(start=[""06:00"", ""10:00"", ""15:00""],
...                                end=[""08:00"", ""12:00"", ""17:00""])
>>> pd.date_range(dt.datetime(2022, 12, 9), dt.datetime(2022, 12, 13), freq=freq)
DatetimeIndex(['2022-12-09 06:00:00', '2022-12-09 07:00:00',
               '2022-12-09 10:00:00', '2022-12-09 11:00:00',
               '2022-12-09 15:00:00', '2022-12-09 16:00:00',
               '2022-12-12 06:00:00', '2022-12-12 07:00:00',
               '2022-12-12 10:00:00', '2022-12-12 11:00:00',
               '2022-12-12 15:00:00', '2022-12-12 16:00:00'],
               dtype='datetime64[ns]', freq='bh')
",https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.html, pandas.date_range pandas.DatetimeIndex
">>> import datetime as dt
>>> freq = pd.offsets.CustomBusinessMonthBegin(weekmask=""Wed Thu"")
>>> pd.date_range(dt.datetime(2022, 7, 10), dt.datetime(2022, 12, 18),
...               freq=freq).strftime('%a %d %b %Y %H:%M')
Index(['Wed 03 Aug 2022 00:00', 'Thu 01 Sep 2022 00:00',
       'Wed 05 Oct 2022 00:00', 'Wed 02 Nov 2022 00:00',
       'Thu 01 Dec 2022 00:00'],
       dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.html, pandas.date_range pandas.Index
">>> import datetime as dt
>>> bdc = np.busdaycalendar(holidays=['2022-08-01', '2022-09-30',
...                                   '2022-10-31', '2022-11-01'])
>>> freq = pd.offsets.CustomBusinessMonthBegin(calendar=bdc)
>>> pd.date_range(dt.datetime(2022, 7, 10), dt.datetime(2022, 11, 10), freq=freq)
DatetimeIndex(['2022-08-02', '2022-09-01', '2022-10-03', '2022-11-02'],
               dtype='datetime64[ns]', freq='CBMS')
",https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.html, pandas.date_range pandas.DatetimeIndex
">>> from pandas.tseries.offsets import BQuarterBegin
>>> ts = pd.Timestamp('2020-05-24 05:01:15')
>>> ts + BQuarterBegin()
Timestamp('2020-06-01 05:01:15')
>>> ts + BQuarterBegin(2)
Timestamp('2020-09-01 05:01:15')
>>> ts + BQuarterBegin(startingMonth=2)
Timestamp('2020-08-03 05:01:15')
>>> ts + BQuarterBegin(-1)
Timestamp('2020-03-02 05:01:15')
",https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterBegin.html, pandas.tseries.offsets.BQuarterBegin
">>> ts + Minute(n=10)
Timestamp('2022-12-09 15:10:00')
>>> ts - Minute(n=10)
Timestamp('2022-12-09 14:50:00')
",https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Minute.html, pandas.tseries.offsets.Minute
">>> ts + Minute(n=-10)
Timestamp('2022-12-09 14:50:00')
",https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Minute.html, pandas.tseries.offsets.Minute
">>> ts + Day()
Timestamp('2022-12-10 15:00:00')
>>> ts - Day(4)
Timestamp('2022-12-05 15:00:00')
",https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Day.html, pandas.tseries.offsets.Day
">>> ts + Day(-4)
Timestamp('2022-12-05 15:00:00')
",https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Day.html, pandas.tseries.offsets.Day
">>> from pandas.tseries.offsets import BYearEnd
>>> ts = pd.Timestamp('2020-05-24 05:01:15')
>>> ts - BYearEnd()
Timestamp('2019-12-31 05:01:15')
>>> ts + BYearEnd()
Timestamp('2020-12-31 05:01:15')
>>> ts + BYearEnd(3)
Timestamp('2022-12-30 05:01:15')
>>> ts + BYearEnd(-3)
Timestamp('2017-12-29 05:01:15')
>>> ts + BYearEnd(month=11)
Timestamp('2020-11-30 05:01:15')
",https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearEnd.html, pandas.tseries.offsets.BYearEnd
">>> ts + Nano(n=1000)
Timestamp('2022-12-09 15:00:00.000001')
",https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Nano.html, pandas.tseries.offsets.Nano
">>> ts - Nano(n=1000)
Timestamp('2022-12-09 14:59:59.999999')
",https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Nano.html, pandas.tseries.offsets.Nano
">>> ts + Nano(n=-1000)
Timestamp('2022-12-09 14:59:59.999999')
",https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Nano.html, pandas.tseries.offsets.Nano
">>> date_plus_one_week = date_object + pd.tseries.offsets.Week(n=1)
>>> date_plus_one_week
Timestamp('2023-01-20 00:00:00')
",https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Week.html, pandas.tseries.offsets.Week
">>> date_next_monday = date_object + pd.tseries.offsets.Week(weekday=0)
>>> date_next_monday
Timestamp('2023-01-16 00:00:00')
",https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Week.html, pandas.tseries.offsets.Week
">>> date_next_sunday = date_object + pd.tseries.offsets.Week(weekday=6)
>>> date_next_sunday
Timestamp('2023-01-15 00:00:00')
",https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Week.html, pandas.tseries.offsets.Week
">>> import datetime as dt
>>> freq = pd.offsets.CustomBusinessHour(start=[""06:00"", ""10:00"", ""15:00""],
...                                      end=[""08:00"", ""12:00"", ""17:00""])
>>> pd.date_range(dt.datetime(2022, 12, 9), dt.datetime(2022, 12, 13), freq=freq)
DatetimeIndex(['2022-12-09 06:00:00', '2022-12-09 07:00:00',
               '2022-12-09 10:00:00', '2022-12-09 11:00:00',
               '2022-12-09 15:00:00', '2022-12-09 16:00:00',
               '2022-12-12 06:00:00', '2022-12-12 07:00:00',
               '2022-12-12 10:00:00', '2022-12-12 11:00:00',
               '2022-12-12 15:00:00', '2022-12-12 16:00:00'],
               dtype='datetime64[ns]', freq='cbh')
",https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.html, pandas.date_range pandas.DatetimeIndex
">>> import datetime as dt
>>> freq = pd.offsets.CustomBusinessHour(weekmask=""Mon Wed Fri"",
...                                      start=""10:00"", end=""13:00"")
>>> pd.date_range(dt.datetime(2022, 12, 10), dt.datetime(2022, 12, 18),
...               freq=freq).strftime('%a %d %b %Y %H:%M')
Index(['Mon 12 Dec 2022 10:00', 'Mon 12 Dec 2022 11:00',
       'Mon 12 Dec 2022 12:00', 'Wed 14 Dec 2022 10:00',
       'Wed 14 Dec 2022 11:00', 'Wed 14 Dec 2022 12:00',
       'Fri 16 Dec 2022 10:00', 'Fri 16 Dec 2022 11:00',
       'Fri 16 Dec 2022 12:00'],
       dtype='object')
",https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.html, pandas.date_range pandas.Index
">>> import datetime as dt
>>> bdc = np.busdaycalendar(holidays=['2022-12-12', '2022-12-14'])
>>> freq = pd.offsets.CustomBusinessHour(calendar=bdc, start=""10:00"", end=""13:00"")
>>> pd.date_range(dt.datetime(2022, 12, 10), dt.datetime(2022, 12, 18), freq=freq)
DatetimeIndex(['2022-12-13 10:00:00', '2022-12-13 11:00:00',
               '2022-12-13 12:00:00', '2022-12-15 10:00:00',
               '2022-12-15 11:00:00', '2022-12-15 12:00:00',
               '2022-12-16 10:00:00', '2022-12-16 11:00:00',
               '2022-12-16 12:00:00'],
               dtype='datetime64[ns]', freq='cbh')
",https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.html, pandas.date_range pandas.DatetimeIndex
">>> ts + Milli(n=10)
Timestamp('2022-12-09 15:00:00.010000')
",https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Milli.html, pandas.tseries.offsets.Milli
">>> ts - Milli(n=10)
Timestamp('2022-12-09 14:59:59.990000')
",https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Milli.html, pandas.tseries.offsets.Milli
">>> ts + Milli(n=-10)
Timestamp('2022-12-09 14:59:59.990000')
",https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Milli.html, pandas.tseries.offsets.Milli
"import pandas as pd
pd.DataFrame({'A': [1, 2, 3]})
",https://pandas.pydata.org/pandas-docs/version/1.5.3/user_guide/index.html, pandas.DataFrame
"In [1]: import pandas as pd

In [2]: pd.DataFrame({'A': [1, 2, 3]})
Out[2]: 
   A
0  1
1  2
2  3
",https://pandas.pydata.org/pandas-docs/version/1.5.3/user_guide/index.html, pandas.DataFrame
">>> from pandas.tseries.offsets import BQuarterEnd
>>> ts = pd.Timestamp('2020-05-24 05:01:15')
>>> ts + BQuarterEnd()
Timestamp('2020-06-30 05:01:15')
>>> ts + BQuarterEnd(2)
Timestamp('2020-09-30 05:01:15')
>>> ts + BQuarterEnd(1, startingMonth=2)
Timestamp('2020-05-29 05:01:15')
>>> ts + BQuarterEnd(startingMonth=2)
Timestamp('2020-05-29 05:01:15')
",https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterEnd.html, pandas.tseries.offsets.BQuarterEnd
