,Unnamed: 0,id,Unnamed: 2,heuristic result,HAS_API,DISCUSSES_API,Unnamed: 6,Unnamed: 7,LSA_summary,discusses_api_result,lexrank_summary
0,15,50607740,https://stackoverflow.com/questions/50607740,True,True,False,,,"Reverse a get_dummies encoding in pandas Column names are: ID,1,2,3,4,5,6,7,8,9. The col values are either 0 or 1 My dataframe looks like this: I want the column names in front of the ID where the value in a row is 1.",False,Reverse a get_dummies encoding in pandas. The col values are either 0 or 1 My dataframe looks like this: I want the column names in front of the ID where the value in a row is 1.
1,16,37265312,https://stackoverflow.com/questions/37265312,True,True,True,,,"How to create dummies for certain columns with pandas.get_dummies() I just want Column A and D to get dummies not for Column B. If I used pd.get_dummies(df), all columns turned into dummies.",True,How to create dummies for certain columns with pandas.get_dummies(). I just want Column A and D to get dummies not for Column B.
2,17,18889588,https://stackoverflow.com/questions/18889588,True,True,True,,,"Create dummies from column with multiple values in pandas I am looking for for a pythonic way to handle the following problem. For example, if the column has values in ['A', 'B'], get_dummies() creates 2 dummy variables and assigns 0 or 1 accordingly.",False,"Create dummies from column with multiple values in pandas. For example, if the column has values in ['A', 'B'], get_dummies() creates 2 dummy variables and assigns 0 or 1 accordingly."
3,18,31498390,https://stackoverflow.com/questions/31498390,True,True,True,,,how to get pandas get_dummies to emit N-1 variables to avoid collinearity? pandas.get_dummies emits a dummy variable per categorical value.,True,how to get pandas get_dummies to emit N-1 variables to avoid collinearity?. pandas.get_dummies emits a dummy variable per categorical value.
4,19,38413579,https://stackoverflow.com/questions/38413579,True,True,True,,,What is the difference between sklearn LabelEncoder and pd.get_dummies? What is the advantage of using one over another?,False,What is the difference between sklearn LabelEncoder and pd.get_dummies?. What is the advantage of using one over another?
5,20,31888856,https://stackoverflow.com/questions/31888856,True,True,False,,,"I've tried loading it into a dense matrix first with read_csv and then calling to_sparse, but it takes a long time and chokes on text fields, although most of the data is floating point. This happens even if I strip the zeros out of the original file and call to_sparse() (so that the fill value is NaN).",False,"Read a large csv into a sparse pandas dataframe in a memory efficient way. I've tried loading it into a dense matrix first with read_csv and then calling to_sparse, but it takes a long time and chokes on text fields, although most of the data is floating point."
6,21,28465633,https://stackoverflow.com/questions/28465633,True,True,True,,,Easy way to apply transformation from `pandas.get_dummies` to new data? Now I have a single new observation that I want to run through my model.,True,Easy way to apply transformation from `pandas.get_dummies` to new data?. Now I have a single new observation that I want to run through my model.
7,22,48170405,https://stackoverflow.com/questions/48170405,True,True,True,,,"Is pd.get_dummies one-hot encoding? Given the difference between one-hot encoding and dummy coding, is the pandas.get_dummies method one-hot encoding when using default parameters (i.e. drop_first=False)?",True,"Is pd.get_dummies one-hot encoding?. Given the difference between one-hot encoding and dummy coding, is the pandas.get_dummies method one-hot encoding when using default parameters (i.e. drop_first=False)?"
8,23,26724872,https://stackoverflow.com/questions/26724872,True,True,False,,,,False,"Pandas: map values of categorical variable to a predefined list of dummy columns. I have a categorical variable with known levels (e.g. hour that just contains values between 0 and 23), but not all of them are available right now (say, we have measurements from between 0 and 11 o'clock, while hours from 12 to 23 are not covered), though other values are going to be added later."
9,24,29221894,https://stackoverflow.com/questions/29221894,True,True,False,,,,False,Pandas: get_dummies vs categorical. I have a dataset which has  a few columns with categorical data.
10,25,34529542,https://stackoverflow.com/questions/34529542,True,True,False,,,,True,"Create open bounds indicators from pandas get_dummies on discretized numerical. From a numeric age pandas column, discretize as ageD with qcut, we create open bounds from the qcut bounds: From Index([u'[5, 30]', u'(30, 70]'], dtype='object') we make bopens: Then we convert categorical variable into dummy/indicator variables with get_dummies: I want to enrich the data frame with the open bounds columns, df.shape will be quite big, ~(10e6, 32)."
11,26,37381862,https://stackoverflow.com/questions/37381862,True,True,True,,,,False,"get_dummies for Pandas column containing list. Given I have a DataFrame with a column that contains lists of strings, like this: How would I turn that into something like this?"
12,27,39923927,https://stackoverflow.com/questions/39923927,True,True,False,,,,False,How can I transform a pandas data frame to sklearn one-hot-encoded (dataframe / numpy array) where some columns do not require encoding? Is an already label encoded data frame and I would like to only encode the columns marked by columnsToEncode?
13,28,43334222,https://stackoverflow.com/questions/43334222,True,True,False,,,,True,"I'm doing one hot encoding over a categorical column which has some 18 different kind of values. I've explored pandas get_dummies and sci-kit learn's one hot encoder, but can't figure out how to bundle together less frequent values into one column."
14,29,47127388,https://stackoverflow.com/questions/47127388,True,True,False,,,,True,"I have a pandas dataframe similar to this: By using the pandas get_dummies() function on column ABC, I can get this: While I need something like this, where the ABC column has a list / array datatype: I tried using the get_dummies function and then combining all the columns into the column which I wanted. But I cannot figure out a way to combine them as a list."
15,30,50138787,https://stackoverflow.com/questions/50138787,True,True,True,,,,False,"I have a Pandas DataFrame, train, that I'm one-hot encoding. I'd like the output of one-hot encoding test to be: So it just ignores previously unseen values in test."
16,31,52072821,https://stackoverflow.com/questions/52072821,True,True,False,,,,False,"How to predict if number of features are not matching with number of features available in testset?. When we transform this set of test data using get_dummies, the resulting dataset may not have same number of features as we have trained our model with."
17,32,53002047,https://stackoverflow.com/questions/53002047,True,True,False,,,,True,python - is it possible to concat column after using pandas get_dummies?. here is my example df and i have use to make a vector matrix like this but i would like to concat the doc1 and doc2 then create a new column to see the expected result like this is it possible?
18,33,53004426,https://stackoverflow.com/questions/53004426,True,True,True,,,,True,"I would like to know if I have to use ""drop_first""-parameter of the pandas.get_dummies-function when I have NaN in the column. What I ask myself is, should I use the ""drop_first""-parameter when I have NaN in the column?"
19,34,54411582,https://stackoverflow.com/questions/54411582,True,True,True,,,,True,"How to fix the problem in pandas.get_dummies. I'm preprocessing my dataset with pd.get_dummies, but the result is not what I need."
20,35,55520223,https://stackoverflow.com/questions/55520223,True,True,False,,,,False,"What is the best/most Pythonic way to one-hot encode categorical features in a Pandas data frame while preserving the original order of the columns from which the categories (new column names) are extracted? For robustness, I want the order preserved when dealing with data frames with categorical columns arbitrarily ordered among the rest of the columns For example, for [""Cont1"", ""Cat1"", ""Cont2"", ""Cont3"", ""Cat2"", ""Labels""], I want the new columns resulting from ""Cat1"" to be in between ""Cont1"" and ""Cont2""."
21,36,55546321,https://stackoverflow.com/questions/55546321,True,True,True,,,,True,how to eliminate key error with pandas get_dummies function. When I run the pandas get_dummies() function it returns a keyerror stating that all of my columns are nonexistent.
22,37,55751906,https://stackoverflow.com/questions/55751906,True,True,False,,,,False,convert categorical values to numeric/float index?. is there a way in pandas or sklearn to convert categorical values to a unique numeric/float index and be included in the pipeline?
23,38,56099598,https://stackoverflow.com/questions/56099598,True,True,False,,,,False,Binary-vectorize pandas DataFrame column. In a fictional patients dataset one might encounter the following table: Which renders the following dataset:
24,39,56733297,https://stackoverflow.com/questions/56733297,True,True,False,,,,True,"I have a text file like this: The final field in the input file is 50k characters in length and is only ever 0,1 or 2. So my expected result is a dataframe like this: I have created an initial dataframe by reading in the input file: This creates a dataframe with 3 columns as: I thought I might be able to create initial individual columns using something like below and then using the pandas get_dummies function for the one hot encoding but I have been unable to create the individual columns."
25,40,56738267,https://stackoverflow.com/questions/56738267,True,True,True,,,,True,"How can I align pandas get_dummies across training / validation / testing?. I have 3 sets of data (training, validation and testing) and when I run: It gives me a certain number of features."
26,41,56742667,https://stackoverflow.com/questions/56742667,True,True,True,,,,False,"How can I do the get_dummies across the test file and ensure the categories are encoded in the same way? Additionally, my test data is missing job_performance column, how can I handle this in the function?"
27,42,56929119,https://stackoverflow.com/questions/56929119,True,True,True,,,,False,"Original data is below I am trying to convert this to a dataframe where every unique value present in columns (X1, X2, X3, Y) will become a new column and every ID will have a single record. Here Y is my target column."
28,43,57065878,https://stackoverflow.com/questions/57065878,True,True,False,,,,True,"Split pandas column and create new columns that count the split values. I have a goofy data where one column contains multiple values slammed together with a comma: Now I want to split column V, drop it, and add columns a through e.  Columns a through e should contains the count of the occurrences of that letter in that row: Maybe some combination of df['V'].str.split(',') and pandas.get_dummies but I can't quite work it out."
29,44,57950901,https://stackoverflow.com/questions/57950901,True,True,False,,,,False,One hot encoding of multi label images in keras. What is the best way to one-hot encode these labels as we don't have specific number of labels for each image.
30,45,58564612,https://stackoverflow.com/questions/58564612,True,True,True,,,,True,"Getting 'Series' objects are mutable, thus they cannot be hashed' error while running pandas.get_dummies. These three columns are categorical features while running  the above I am getting the error: Any suggestion?"
31,0,11869910,https://stackoverflow.com/questions/11869910,False,False,False,,,"pandas: filter rows of DataFrame with operator chaining Most operations in pandas can be accomplished with operator chaining (groupby, aggregate, apply, etc), but the only way I've found to filter rows is via normal bracket indexing This is unappealing as it requires I assign df to a variable before being able to filter on its values. Is there something more like the following?",False,"pandas: filter rows of DataFrame with operator chaining. Most operations in pandas can be accomplished with operator chaining (groupby, aggregate, apply, etc), but the only way I've found to filter rows is via normal bracket indexing This is unappealing as it requires I assign df to a variable before being able to filter on its values."
32,1,51174691,https://stackoverflow.com/questions/51174691,False,False,False,,,"How to increase image size of pandas.DataFrame.plot How can I modify the size of the output image of the function pandas.DataFrame.plot? I tried: plt.figure(figsize=(10, 5)) and %matplotlib notebook but none of them work.",False,How to increase image size of pandas.DataFrame.plot. How can I modify the size of the output image of the function pandas.DataFrame.plot?
33,2,33149428,https://stackoverflow.com/questions/33149428,False,False,False,,,Modify the legend of pandas bar plot I am always bothered when I make a bar plot with pandas and I want to change the names of the labels in the legend. Consider for instance the output of this code:,False,I am always bothered when I make a bar plot with pandas and I want to change the names of the labels in the legend. Consider for instance the output of this code:
34,3,12860421,https://stackoverflow.com/questions/12860421,False,False,False,,,How to aggregate unique count with pandas pivot_table This code: returns the following error: How do I get a Pivot Table with counts of unique values of one DataFrame column for two other columns? Should I be using np.bincount()?,False,How to aggregate unique count with pandas pivot_table. Should I be using np.bincount()?
35,4,43172970,https://stackoverflow.com/questions/43172970,False,False,False,,,"Python pandas groupby aggregate on multiple columns, then pivot In Python, I have a pandas DataFrame similar to the following: Where shop1, shop2 and shop3 are the costs of every item in different shops. Now, I need to  return a DataFrame, after some data cleaning, like this one: where size is the number of items in each Category and sum, mean and std are related to the same functions applied to the 3 shops.",False,"Python pandas groupby aggregate on multiple columns, then pivot. In Python, I have a pandas DataFrame similar to the following: Where shop1, shop2 and shop3 are the costs of every item in different shops."
36,5,38951345,https://stackoverflow.com/questions/38951345,False,False,False,,,"How to get rid of multilevel index after using pivot table pandas? I had following data frame (the real data frame is much more larger than this one ) : Then reshaped it to move the values in sale_product_id as column headers using the following code: and the resulting data frame is: as you can see we have a multililevel index , what i need is to have sale_user_is in the first column without multilevel indexing: i take the following approach : the the result would be like this i still have the sale_product_id column , but i do not need it anymore: i can subset this data frame to get rid of sale_product_id but i don't think it would be efficient.I am looking for an efficient way to get rid of multilevel indexing while reshaping the original data frame",False,"How to get rid of multilevel index after using pivot table pandas?. I had following data frame (the real data frame is much more larger than this one ) : Then reshaped it to move the values in sale_product_id as column headers using the following code: and the resulting data frame is: as you can see we have a multililevel index , what i need is to have sale_user_is in the first column without multilevel indexing: i take the following approach : the the result would be like this i still have the sale_product_id column , but i do not need it anymore: i can subset this data frame to get rid of sale_product_id but i don't think it would be efficient.I am looking for an efficient way to get rid of multilevel indexing while reshaping the original data frame"
37,6,33290374,https://stackoverflow.com/questions/33290374,False,False,False,,,pandas pivot_table column names For a dataframe like this: to which I apply pivot_table to get df2: is there an easy way to format resulting dataframe column names like If I do: I get: How to get rid of the extra level? thanks!,False,pandas pivot_table column names. For a dataframe like this: to which I apply pivot_table to get df2: is there an easy way to format resulting dataframe column names like If I do: I get: How to get rid of the extra level?
38,7,43821529,https://stackoverflow.com/questions/43821529,False,False,False,,,"Filter out nan rows in a specific column Given the dataframe df, I want to obtain a new dataframe df2 that does not contain nan in the column Col2. This is the expected result: df2 = I know that it's possible to use pandas.isnull and dropna, however how to specify only particular column to which filtering should be applied?",False,"Filter out nan rows in a specific column. Given the dataframe df, I want to obtain a new dataframe df2 that does not contain nan in the column Col2."
39,8,16860172,https://stackoverflow.com/questions/16860172,False,False,False,,,python pandas: pivot_table silently drops indices with nans Is there an option not to drop the indices with NaN in them? I think silently dropping these rows from the pivot will at some point cause someone serious pain.,False,python pandas: pivot_table silently drops indices with nans. Is there an option not to drop the indices with NaN in them?
40,9,42921854,https://stackoverflow.com/questions/42921854,False,False,False,,,How to check if a particular cell in pandas DataFrame isnull? I have the following df in pandas.,False,How to check if a particular cell in pandas DataFrame isnull?. I have the following df in pandas.
41,10,20119414,https://stackoverflow.com/questions/20119414,False,False,False,,,So is it possible to do so using pandas? Now this will get a pivot table with sum: And this for mean: How can I get sum for D and mean for E?,False,"Was trying to generate a pivot table with multiple ""values"" columns. Now this will get a pivot table with sum: And this for mean: How can I get sum for D and mean for E?"
42,11,43756052,https://stackoverflow.com/questions/43756052,False,False,False,,,transform pandas pivot table to regular dataframe How can I convert a pandas pivot table to a regular dataframe ? For example: to a regular datetime such as this:,False,transform pandas pivot table to regular dataframe. How can I convert a pandas pivot table to a regular dataframe ?
43,12,55204418,https://stackoverflow.com/questions/55204418,False,False,False,,,"How to rename categories after using pandas.cut with IntervalIndex? Example: The resulting categories will be: I am trying to change [(0, 1] < (2, 3] < (4, 5]] into something like 1, 2 ,3 or small, medium ,large.",False,"How to rename categories after using pandas.cut with IntervalIndex?. Example: The resulting categories will be: I am trying to change [(0, 1] < (2, 3] < (4, 5]] into something like 1, 2 ,3 or small, medium ,large."
44,13,25695986,https://stackoverflow.com/questions/25695986,False,False,False,,,"We can get the correct value with np.std(): But obviously, this is not a solution when I have more than one restaurant. There is a related discussion here, but their suggestions do not work either.",False,"We can get the correct value with np.std(): But obviously, this is not a solution when I have more than one restaurant. There is a related discussion here, but their suggestions do not work either."
45,14,32552027,https://stackoverflow.com/questions/32552027,False,False,False,,,"With `pandas.cut()`, how do I get integer bins and avoid getting a negative lowest bound? I am trying to use the precision and include_lowest parameters of pandas.cut(), but I can't get the intervals consist of integers rather than floats with one decimal.",False,"With `pandas.cut()`, how do I get integer bins and avoid getting a negative lowest bound?. I am trying to use the precision and include_lowest parameters of pandas.cut(), but I can't get the intervals consist of integers rather than floats with one decimal."
