,Unnamed: 0,Unnamed: 1,id,HAS_API,DISCUSSES_API,discusses_api_result,lexrank_summary
0,6,https://stackoverflow.com/questions/11622652,11622652,True,False,False,"Large, persistent DataFrame in pandas. I am exploring switching to python and pandas as a long-time SAS user."
1,10,https://stackoverflow.com/questions/20680272,20680272,True,False,False,Parsing a JSON string which was loaded from a CSV using Pandas. I am working with CSV files where several of the columns have a simple json object (several key value pairs) while other columns are normal.
2,15,https://stackoverflow.com/questions/34447448,34447448,True,False,True,StringIO and pandas read_csv. I'm trying to mix StringIO and BytesIO with pandas and struggling with some basic stuff.
3,16,https://stackoverflow.com/questions/23569771,23569771,True,False,False,"What is the maximum size of a dataframe? For context, I'm trying to read in the Survey of Consumer Finances 2007, both in ASCII format (using read_csv) and in Stata format (using read_stata)."
4,21,https://stackoverflow.com/questions/31888856,31888856,True,False,False,"Read a large csv into a sparse pandas dataframe in a memory efficient way. I've tried loading it into a dense matrix first with read_csv and then calling to_sparse, but it takes a long time and chokes on text fields, although most of the data is floating point."
5,32,https://stackoverflow.com/questions/39000481,39000481,True,False,True,"I would like to specify the dtypes returned when doing pandas.read_sql. pandas.read_csv allows for specifying dtypes as a dict, but I see no way to do that with read_sql."
6,36,https://stackoverflow.com/questions/28976546,28976546,True,False,True,"I started by reading a CSV into a Pandas Data Frame via the pandas read_csv() function. Now that the data is in an actual data frame, I tried to write something like this: This works but only the last row is saved to disk because I've been rewriting the file each time I make a call to row[1].to_json(path_to_file)."
7,40,https://stackoverflow.com/questions/45732459,45732459,True,False,False,"Retrieve delimiter infered by read_csv in pandas. When using the configuration for automatic separator detection to read csv files (pd.read_csv(file_path, sep=None)), pandas tries to infer the delimiter (or separator)."
8,49,https://stackoverflow.com/questions/56837418,56837418,True,False,True,"Efficient way to read 15 M lines csv files in python. I've already tried different approaches, notably pandas.read_csv with chunksize and dtype specifications, and dask.dataframe."
9,0,https://stackoverflow.com/questions/21269399,21269399,True,True,False,I'm reading in a csv file with multiple datetime columns. That information can change and comes from whatever informs my dtypes list.
10,1,https://stackoverflow.com/questions/10867028,10867028,True,True,False,"I managed to get pandas to read ""nan"" as a string, but I can't figure out how to get it not to read an empty value as NaN. I realize I can fill the values after reading, with fillna, but is there really no way to tell pandas that an empty cell in a particular CSV column should be read as an empty string instead of NaN?"
11,2,https://stackoverflow.com/questions/20637439,20637439,True,True,True,"Skip rows during csv import pandas. I'm trying to import a .csv file using pandas.read_csv(), however, I don't want to import the 2nd row of the data file (the row with index = 1 for 0-indexing)."
12,3,https://stackoverflow.com/questions/33952142,33952142,True,True,True,The pandas read_csv() method interprets 'NA' as nan (not a number) instead of a valid string. Is there a way to capture a valid string 'NA' instead of it being converted to nan?
13,4,https://stackoverflow.com/questions/15017072,15017072,True,True,True,"pandas read_csv and filter columns with usecols. I expect that df1 and df2 should be the same except for the missing dummy column, but the columns come in mislabeled."
14,5,https://stackoverflow.com/questions/15026698,15026698,True,True,False,"Is there a way to tell pandas to treat these files properly? By the way, I do not have this problem if I use Python."
15,7,https://stackoverflow.com/questions/31700691,31700691,True,True,False,"Convert commas decimal separators to dots within a Dataframe. I can't change the format of my input, and thus have to replace the commas in my DataFrame in order for my code to work, and I want python to do this without the need of doing it manually."
16,8,https://stackoverflow.com/questions/17557074,17557074,True,True,False,"The file I am trying to read is 366 Mb, the code above works if I cut the file down to something short (25 Mb). It has also happened that I get a pop up telling me that it can't write to address 0x1e0baf93... Stacktrace: A bit of background - I am trying to convince people that Python can do the same as R. For this I am trying to replicate an R script that does R not only manages to read the above file just fine, it even reads several of these files in a for loop (and then does some stuff with the data)."
17,9,https://stackoverflow.com/questions/12960574,12960574,True,True,False,"The trouble is that one of the columns of data is always being set as the index column, even when the index_col argument is set to None. Here is the loading code (to save time in the checking, I set the nrows=10): To keep it short I am excluding the data column outputs, but here is my output (please not the Index values): And here is the book's output (again with data columns excluded): The Index values in my output are actually the first column of data in the file, which is then moving all the rest of the data to the left by one."
18,11,https://stackoverflow.com/questions/18366797,18366797,True,True,False,I see in the help 'comment' of lines is not supported but it indicates an empty line should be returned. I see an error CParserError: Error tokenizing data.
19,12,https://stackoverflow.com/questions/20696479,20696479,True,True,True,pandas.read_csv from string or package data. I have some csv text data in a package which I want to read using read_csv.
20,13,https://stackoverflow.com/questions/25669588,25669588,True,True,True,Convert percent string to float in pandas read_csv. Is there a way to convert values like '34%' directly to int or float when using read_csv in pandas?
21,14,https://stackoverflow.com/questions/39263929,39263929,True,True,True,"How can I read tar.gz file using pandas read_csv with gzip compression option?. I have a very simple csv, with the following data, compressed inside the tar.gz file."
22,17,https://stackoverflow.com/questions/15210962,15210962,True,True,True,Specifying dtype float32 with pandas.read_csv on pandas 0.10.1. I'm attempting to read a simple space-separated file with pandas read_csv method.
23,18,https://stackoverflow.com/questions/28382735,28382735,True,True,False,"The problem is that I don't know why but it seems that pandas's read_csv always skips the first line (first row) of the csv (txt) file, resulting one less data. f[0] and g[0] that are displayed in the output have to match but it doesn't, indicating that pandas is skipping the first line of the Testarray.txt."
24,19,https://stackoverflow.com/questions/34139102,34139102,True,True,False,"Its documentation is here According to documentation, we know: dtype : Type name or dict of column -> type, default None Data type for data or columns. E.g. {‘a’: np.float64, ‘b’: np.int32} (Unsupported with engine=’python’) and converters : dict, default None Dict of functions for converting values in certain columns."
25,20,https://stackoverflow.com/questions/40769691,40769691,True,True,True,Prevent pandas read_csv treating first row as header of column names. I'm reading in a pandas DataFrame using pd.read_csv.
26,22,https://stackoverflow.com/questions/28284912,28284912,True,True,False,I would like to not have any quote character at all when I use read_csv. Is it possible to not have a quotechar at all when using read_csv?
27,23,https://stackoverflow.com/questions/26595819,26595819,True,True,True,"What options do I need to enter to pandas read_csv to read this correctly? C error: Expected 6 fields in line 3, saw 14 Which obviously means that it is ignoring the '""' and parsing every comma as a field."
28,24,https://stackoverflow.com/questions/38716643,38716643,True,True,True,using pandas.read_csv to read certain columns. I have a .csv file with three columns and many rows.
29,25,https://stackoverflow.com/questions/41235111,41235111,True,True,True,"Customizing the separator in pandas read_csv. Thus, every time I import the file, I have to manually go to that file and see the number of spaces that have been used and give those many number of spaces in sep: Is there any way I can tell pandas to assume ""any number of spaces"" as the separator?"
30,26,https://stackoverflow.com/questions/36909368,36909368,True,True,False,"Precision lost while using read_csv in pandas. When I try to read it into dataframe, I am not getting the last 4 integers How can I get the complete precision as present in the input file?"
31,27,https://stackoverflow.com/questions/47368296,47368296,True,True,True,"When I import the csv file (and other columns) via pandas read_csv, the column automatically gets the datatype object. How can I get the values imported and shown exactly as they are in the source csv file?"
32,28,https://stackoverflow.com/questions/26495408,26495408,True,True,True,"Pandas - pandas.DataFrame.from_csv vs pandas.read_csv. What's the difference between: pandas.DataFrame.from_csv, doc link: http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.from_csv.html and pandas.read_csv, doc link: http://pandas.pydata.org/pandas-docs/stable/generated/pandas.io.parsers.read_csv.html"
33,29,https://stackoverflow.com/questions/31194669,31194669,True,True,True,Use Multiple Character Delimiter in Python Pandas read_csv. It appears that the pandas read_csv function only allows single character delimiters/separators.
34,30,https://stackoverflow.com/questions/30494569,30494569,True,True,True,How to force pandas read_csv to use float32 for all float columns?. Because Note that not all columns in the raw csv file have float types.
35,31,https://stackoverflow.com/questions/29862864,29862864,True,True,False,"Different read_csv index_col = None / 0 / False in pandas. I used the read_csv command following below: The result shows column Unnamed:0 and it is simillar when I used index_col=False, but when I used index_col=0, the result is following below: The result did show the column Unnamed:0, In here I want to ask, what is the difference between index_col=None, index_col=0, and index_col=False, I have read the documentation in this, but I still did not get the idea."
36,33,https://stackoverflow.com/questions/14002158,14002158,True,True,False,How to set time zone of values in Pandas. I'd like to set the time zone of the values of a column in a Pandas DataFrame.
37,34,https://stackoverflow.com/questions/42165649,42165649,True,True,False,I'm trying to load a .csv file using the pd.read_csv() function when I get an error despite the file path being correct and using raw strings. Edit: I've found the issue that was causing the problem.
38,35,https://stackoverflow.com/questions/20095983,20095983,True,True,True,Specify correct dtypes to pandas.read_csv for datetimes and booleans. I am loading a csv file into a Pandas DataFrame.
39,37,https://stackoverflow.com/questions/22809061,22809061,True,True,True,"I used to read my data with numpy.loadtxt(). However, lately I found out in SO, that pandas.read_csv() is much more faster."
40,38,https://stackoverflow.com/questions/31362573,31362573,True,True,False,"Performance difference in pandas read_table vs. read_csv vs. from_csv vs. read_excel?. I tend to import .csv files into pandas, but sometimes I may get data in other formats to make DataFrame objects."
41,39,https://stackoverflow.com/questions/31620667,31620667,True,True,True,Why is `pandas.read_csv` not the reciprocal of `pandas.DataFrame.to_csv`?. It seems strange to me that pandas.read_csv is not a direct reciprocal function to df.to_csv.
42,41,https://stackoverflow.com/questions/13824840,13824840,True,True,True,Escaped quotes in pandas read_csv. I am unable to create a dataframe which has escaped quotes when using read_csv.
43,42,https://stackoverflow.com/questions/13719946,13719946,True,True,False,(The data file is [1]) It treats the extra delimiter as if there's an extra column. So there's one more column than what headers require.
44,43,https://stackoverflow.com/questions/20689288,20689288,True,True,False,"There are some columns however that in a particular data sample have ALL cells as ""Unknown"" and these get typed as object. My code to load the CSV is as follows: The output from print self.csvbear.dtypes As you can see, the Tertiary Payment Date col should be a datetime64 dtype, but it's simply a object, and the actual content of it is just NaN (put there from the read_csv function for string 'Unknown')."
45,44,https://stackoverflow.com/questions/49532873,49532873,True,True,True,What is the difference between `sep` and `delimiter` attributes in pandas.read_csv() method?. What is the difference between sep and delimiter attributes in pandas.read_csv() method?
46,45,https://stackoverflow.com/questions/38114654,38114654,True,True,True,pandas read_csv column dtype is set to decimal but converts to string. I am using pandas (v0.18.1) to import the following data from a file called 'test.csv': I have set the dtype to 'decimal.Decimal' for columns 'c' and 'd' but instead they return as type 'str'.
47,46,https://stackoverflow.com/questions/41681250,41681250,True,True,False,Is there a difference between read_table and read_csv in pandas?. I've tested it and also checked the documentation with no visible differences.Either way i wanted to ask just in case.
48,47,https://stackoverflow.com/questions/52774459,52774459,True,True,False,"In the document for pd.read_csv() method in pandas in python while describing the ""sep"" parameter there is a mention of engines such as C engine and Python engine. What is the role of each engine?"
49,48,https://stackoverflow.com/questions/69513799,69513799,True,True,True,"pandas read_csv: The error_bad_lines argument has been deprecated and will be removed in a future version. I am trying to read some data which may sometimes have erroneous and bad rows, so as always I passed error_bad_lines=False but the console keeps throwing the deprecation warning on every run."
50,50,https://stackoverflow.com/questions/24249690,24249690,True,True,True,"What do low_memory and memory_map flags do in pd.read_csv. the function signature for pandas.read_csv gives, among others, the following options: I couldn't find any documentation for either low_memoryor memory_map flags."
51,51,https://stackoverflow.com/questions/12101113,12101113,True,True,False,"Prevent pandas from automatically inferring type in read_csv. I have a #-separated file with three columns: the first is integer, the second looks like a float, but isn't, and the third is a string."
52,52,https://stackoverflow.com/questions/32737137,32737137,True,True,True,Old pre-0.17 pandas.read_csv behavior of `header=True` for inferring header row?. How did old pre-0.17 versions of pandas read_csv() interpret passing a boolean header=True/False for inferring the header row?
53,53,https://stackoverflow.com/questions/45652772,45652772,True,True,True,Pandas read csv is shifting columns. It seems like a problem with pandas read_csv() method.
54,54,https://stackoverflow.com/questions/44697714,44697714,True,True,False,"The documentation for the argument in this post's title says: float_precision : string, default None Specifies which converter the C engine should use for floating-point values. But even assuming I manage to find it, my experience with this sort of algorithm is that their implementations are so highly optimized, and at such a low level, that without some high-level description it is really difficult, at least for me, to follow what's going on."
