Example,Extracted Function,Linked Function,Source File,Matched
nltk.__init__.demo(),"(None, [])",N/A,N/A,False
"class nltk.collocations.BigramCollocationFinder(word_fd, bigram_fd, window_size=2)","('nltk.collocations.BigramCollocationFinder', ['word_fd', 'bigram_fd', 'window_size'])","('BigramCollocationFinder.__init__', ['bigram_fd', 'word_fd', 'window_size'])",nltk\nltk\collocations.py,True
"classmethod from_words(words, window_size=2)","('from_words', ['words', 'window_size'])","[('BigramCollocationFinder.from_words', {'source_file': 'nltk\\nltk\\collocations.py', 'req_args': ['words', 'cls'], 'opt_args': ['window_size']}), ('TrigramCollocationFinder.from_words', {'source_file': 'nltk\\nltk\\collocations.py', 'req_args': ['words', 'cls'], 'opt_args': ['window_size']}), ('QuadgramCollocationFinder.from_words', {'source_file': 'nltk\\nltk\\collocations.py', 'req_args': ['words', 'cls'], 'opt_args': ['window_size']})]",N/A,False
"score_ngram(score_fn, w1, w2)","('score_ngram', ['score_fn', 'w1', 'w2'])","[('BigramCollocationFinder.score_ngram', {'source_file': 'nltk\\nltk\\collocations.py', 'req_args': ['w2', 'w1', 'score_fn'], 'opt_args': []}), ('TrigramCollocationFinder.score_ngram', {'source_file': 'nltk\\nltk\\collocations.py', 'req_args': ['w3', 'w2', 'w1', 'score_fn'], 'opt_args': []}), ('QuadgramCollocationFinder.score_ngram', {'source_file': 'nltk\\nltk\\collocations.py', 'req_args': ['w4', 'w3', 'w2', 'w1', 'score_fn'], 'opt_args': []})]",N/A,False
"class nltk.collocations.QuadgramCollocationFinder(word_fd, quadgram_fd, ii, iii, ixi, ixxi, iixi, ixii)","('nltk.collocations.QuadgramCollocationFinder', ['word_fd', 'quadgram_fd', 'ii', 'iii', 'ixi', 'ixxi', 'iixi', 'ixii'])","('QuadgramCollocationFinder.__init__', ['ixii', 'iixi', 'ixxi', 'ixi', 'iii', 'ii', 'quadgram_fd', 'word_fd'])",nltk\nltk\collocations.py,True
"classmethod from_words(words, window_size=4)","('from_words', ['words', 'window_size'])","[('BigramCollocationFinder.from_words', {'source_file': 'nltk\\nltk\\collocations.py', 'req_args': ['words', 'cls'], 'opt_args': ['window_size']}), ('TrigramCollocationFinder.from_words', {'source_file': 'nltk\\nltk\\collocations.py', 'req_args': ['words', 'cls'], 'opt_args': ['window_size']}), ('QuadgramCollocationFinder.from_words', {'source_file': 'nltk\\nltk\\collocations.py', 'req_args': ['words', 'cls'], 'opt_args': ['window_size']})]",N/A,False
"score_ngram(score_fn, w1, w2, w3, w4)","('score_ngram', ['score_fn', 'w1', 'w2', 'w3', 'w4'])","('QuadgramCollocationFinder.score_ngram', {'source_file': 'nltk\\nltk\\collocations.py', 'req_args': ['w4', 'w3', 'w2', 'w1', 'score_fn'], 'opt_args': []})",nltk\nltk\collocations.py,True
"class nltk.collocations.TrigramCollocationFinder(word_fd, bigram_fd, wildcard_fd, trigram_fd)","('nltk.collocations.TrigramCollocationFinder', ['word_fd', 'bigram_fd', 'wildcard_fd', 'trigram_fd'])","('TrigramCollocationFinder.__init__', ['trigram_fd', 'wildcard_fd', 'bigram_fd', 'word_fd'])",nltk\nltk\collocations.py,True
bigram_finder(),"(None, [])",N/A,N/A,False
"classmethod from_words(words, window_size=3)","('from_words', ['words', 'window_size'])","[('BigramCollocationFinder.from_words', {'source_file': 'nltk\\nltk\\collocations.py', 'req_args': ['words', 'cls'], 'opt_args': ['window_size']}), ('TrigramCollocationFinder.from_words', {'source_file': 'nltk\\nltk\\collocations.py', 'req_args': ['words', 'cls'], 'opt_args': ['window_size']}), ('QuadgramCollocationFinder.from_words', {'source_file': 'nltk\\nltk\\collocations.py', 'req_args': ['words', 'cls'], 'opt_args': ['window_size']})]",N/A,False
"score_ngram(score_fn, w1, w2, w3)","('score_ngram', ['score_fn', 'w1', 'w2', 'w3'])","[('TrigramCollocationFinder.score_ngram', {'source_file': 'nltk\\nltk\\collocations.py', 'req_args': ['w3', 'w2', 'w1', 'score_fn'], 'opt_args': []}), ('QuadgramCollocationFinder.score_ngram', {'source_file': 'nltk\\nltk\\collocations.py', 'req_args': ['w4', 'w3', 'w2', 'w1', 'score_fn'], 'opt_args': []})]",N/A,False
"nltk.data.BufferedGzipFile(*args, **kwargs)","('nltk.data.BufferedGzipFile', ['args', 'kwargs'])","('BufferedGzipFile.__init__', ['fileobj', 'compresslevel', 'mode', 'filename', 'kwargs'])",nltk\nltk\data.py,True
"nltk.data.FORMATS = {'cfg': 'A context free grammar.', 'fcfg': 'A feature CFG.', 'fol': 'A list of first order logic expressions, parsed with nltk.sem.logic.Expression.fromstring.', 'json': 'A serialized python object, stored using the json module.', 'logic': 'A list of first order logic expressions, parsed with nltk.sem.logic.LogicParser.  Requires an additional logic_parser parameter', 'pcfg': 'A probabilistic CFG.', 'pickle': 'A serialized python object, stored using the pickle module.', 'raw': 'The raw (byte string) contents of a file.', 'text': 'The raw (unicode string) contents of a file. ', 'val': 'A semantic valuation, parsed by nltk.sem.Valuation.fromstring.', 'yaml': 'A serialized python object, stored using the yaml module.'}","(None, [])",N/A,N/A,False
class nltk.data.FileSystemPathPointer(_path),"('nltk.data.FileSystemPathPointer', ['_path'])","('FileSystemPathPointer.__init__', ['_path'])",nltk\nltk\data.py,True
file_size(),"(None, [])",N/A,N/A,False
join(fileid),"('join', ['fileid'])","[('PathPointer.join', {'source_file': 'nltk\\nltk\\data.py', 'req_args': ['fileid'], 'opt_args': []}), ('FileSystemPathPointer.join', {'source_file': 'nltk\\nltk\\data.py', 'req_args': ['fileid'], 'opt_args': []}), ('ZipFilePathPointer.join', {'source_file': 'nltk\\nltk\\data.py', 'req_args': ['fileid'], 'opt_args': []})]",N/A,False
open(encoding=None),"('open', ['encoding'])","[('PathPointer.open', {'source_file': 'nltk\\nltk\\data.py', 'req_args': [], 'opt_args': ['encoding']}), ('FileSystemPathPointer.open', {'source_file': 'nltk\\nltk\\data.py', 'req_args': [], 'opt_args': ['encoding']}), ('GzipFileSystemPathPointer.open', {'source_file': 'nltk\\nltk\\data.py', 'req_args': [], 'opt_args': ['encoding']}), ('ZipFilePathPointer.open', {'source_file': 'nltk\\nltk\\data.py', 'req_args': [], 'opt_args': ['encoding']})]",N/A,False
class nltk.data.GzipFileSystemPathPointer(_path),"('nltk.data.GzipFileSystemPathPointer', ['_path'])",['GzipFileSystemPathPointer.__init__'],N/A,False
class nltk.data.LazyLoader(_path),"('nltk.data.LazyLoader', ['_path'])","('LazyLoader.__init__', ['_path'])",nltk\nltk\data.py,True
class nltk.data.OpenOnDemandZipFile(filename),"('nltk.data.OpenOnDemandZipFile', ['filename'])","('OpenOnDemandZipFile.__init__', ['filename'])",nltk\nltk\data.py,True
read(name),"('read', ['name'])","('OpenOnDemandZipFile.read', {'source_file': 'nltk\\nltk\\data.py', 'req_args': ['name'], 'opt_args': []})",nltk\nltk\data.py,True
"write(*args, **kwargs)","('write', ['args', 'kwargs'])",N/A,N/A,False
"writestr(*args, **kwargs)","('writestr', ['args', 'kwargs'])",N/A,N/A,False
abstract file_size(),"(None, [])",N/A,N/A,False
abstract join(fileid),"('join', ['fileid'])","[('PathPointer.join', {'source_file': 'nltk\\nltk\\data.py', 'req_args': ['fileid'], 'opt_args': []}), ('FileSystemPathPointer.join', {'source_file': 'nltk\\nltk\\data.py', 'req_args': ['fileid'], 'opt_args': []}), ('ZipFilePathPointer.join', {'source_file': 'nltk\\nltk\\data.py', 'req_args': ['fileid'], 'opt_args': []})]",N/A,False
abstract open(encoding=None),"('open', ['encoding'])","[('PathPointer.open', {'source_file': 'nltk\\nltk\\data.py', 'req_args': [], 'opt_args': ['encoding']}), ('FileSystemPathPointer.open', {'source_file': 'nltk\\nltk\\data.py', 'req_args': [], 'opt_args': ['encoding']}), ('GzipFileSystemPathPointer.open', {'source_file': 'nltk\\nltk\\data.py', 'req_args': [], 'opt_args': ['encoding']}), ('ZipFilePathPointer.open', {'source_file': 'nltk\\nltk\\data.py', 'req_args': [], 'opt_args': ['encoding']})]",N/A,False
"class nltk.data.SeekableUnicodeStreamReader(stream, encoding, errors='strict')","('nltk.data.SeekableUnicodeStreamReader', ['stream', 'encoding', 'errors'])","('SeekableUnicodeStreamReader.__init__', ['encoding', 'stream', 'errors'])",nltk\nltk\data.py,True
char_seek_forward(offset),"('char_seek_forward', ['offset'])","('SeekableUnicodeStreamReader.char_seek_forward', {'source_file': 'nltk\\nltk\\data.py', 'req_args': ['offset'], 'opt_args': []})",nltk\nltk\data.py,True
close(),"(None, [])",N/A,N/A,False
discard_line(),"(None, [])",N/A,N/A,False
next(),"(None, [])",N/A,N/A,False
read(size=None),"('read', ['size'])","('SeekableUnicodeStreamReader.read', {'source_file': 'nltk\\nltk\\data.py', 'req_args': [], 'opt_args': ['size']})",nltk\nltk\data.py,True
readline(size=None),"('readline', ['size'])","('SeekableUnicodeStreamReader.readline', {'source_file': 'nltk\\nltk\\data.py', 'req_args': [], 'opt_args': ['size']})",nltk\nltk\data.py,True
"readlines(sizehint=None, keepends=True)","('readlines', ['sizehint', 'keepends'])","('SeekableUnicodeStreamReader.readlines', {'source_file': 'nltk\\nltk\\data.py', 'req_args': [], 'opt_args': ['keepends', 'sizehint']})",nltk\nltk\data.py,True
"seek(offset, whence=0)","('seek', ['offset', 'whence'])","('SeekableUnicodeStreamReader.seek', {'source_file': 'nltk\\nltk\\data.py', 'req_args': ['offset'], 'opt_args': ['whence']})",nltk\nltk\data.py,True
tell(),"(None, [])",N/A,N/A,False
xreadlines(),"(None, [])",N/A,N/A,False
nltk.data.clear_cache(),"(None, [])",N/A,N/A,False
"nltk.data.find(resource_name, paths=None)","('nltk.data.find', ['resource_name', 'paths'])","('nltk.find', {'source_file': 'nltk\\nltk\\data.py', 'req_args': ['resource_name'], 'opt_args': ['paths']})",nltk\nltk\data.py,True
"nltk.data.load(resource_url, format='auto', cache=True, verbose=False, logic_parser=None, fstruct_reader=None, encoding=None)","('nltk.data.load', ['resource_url', 'format', 'cache', 'verbose', 'logic_parser', 'fstruct_reader', 'encoding'])","('nltk.load', {'source_file': 'nltk\\nltk\\data.py', 'req_args': ['resource_url'], 'opt_args': ['encoding', 'fstruct_reader', 'logic_parser', 'verbose', 'cache', 'format']})",nltk\nltk\data.py,True
"nltk.data.retrieve(resource_url, filename=None, verbose=True)","('nltk.data.retrieve', ['resource_url', 'filename', 'verbose'])","('nltk.retrieve', {'source_file': 'nltk\\nltk\\data.py', 'req_args': ['resource_url'], 'opt_args': ['verbose', 'filename']})",nltk\nltk\data.py,True
"nltk.data.show_cfg(resource_url, escape='##')","('nltk.data.show_cfg', ['resource_url', 'escape'])","('nltk.show_cfg', {'source_file': 'nltk\\nltk\\data.py', 'req_args': ['resource_url'], 'opt_args': ['escape']})",nltk\nltk\data.py,True
"class nltk.downloader.Collection(id, children, name=None, **kw)","('nltk.downloader.Collection', ['id', 'children', 'name', 'kw'])","('Collection.__init__', ['children', 'id', 'name', 'kw'])",nltk\nltk\downloader.py,True
static fromxml(xml),"('fromxml', ['xml'])","[('Package.fromxml', {'source_file': 'nltk\\nltk\\downloader.py', 'req_args': ['xml'], 'opt_args': []}), ('Collection.fromxml', {'source_file': 'nltk\\nltk\\downloader.py', 'req_args': ['xml'], 'opt_args': []})]",N/A,False
"class nltk.downloader.Downloader(server_index_url=None, download_dir=None)","('nltk.downloader.Downloader', ['server_index_url', 'download_dir'])","('Downloader.__init__', ['download_dir', 'server_index_url'])",nltk\nltk\downloader.py,True
clear_status_cache(id=None),"('clear_status_cache', ['id'])","('Downloader.clear_status_cache', {'source_file': 'nltk\\nltk\\downloader.py', 'req_args': [], 'opt_args': ['id']})",nltk\nltk\downloader.py,True
collections(),"(None, [])",N/A,N/A,False
corpora(),"(None, [])",N/A,N/A,False
default_download_dir(),"(None, [])",N/A,N/A,False
"download(info_or_id=None, download_dir=None, quiet=False, force=False, prefix='[nltk_data] ', halt_on_error=True, raise_on_error=False, print_error_to=<_io.TextIOWrapper name='' mode='w' encoding='utf-8'>)","(None, [])",N/A,N/A,False
"incr_download(info_or_id, download_dir=None, force=False)","('incr_download', ['info_or_id', 'download_dir', 'force'])","('Downloader.incr_download', {'source_file': 'nltk\\nltk\\downloader.py', 'req_args': ['info_or_id'], 'opt_args': ['force', 'download_dir']})",nltk\nltk\downloader.py,True
index(),"(None, [])",N/A,N/A,False
info(id),"('info', ['id'])","('Downloader.info', {'source_file': 'nltk\\nltk\\downloader.py', 'req_args': ['id'], 'opt_args': []})",nltk\nltk\downloader.py,True
"is_installed(info_or_id, download_dir=None)","('is_installed', ['info_or_id', 'download_dir'])","('Downloader.is_installed', {'source_file': 'nltk\\nltk\\downloader.py', 'req_args': ['info_or_id'], 'opt_args': ['download_dir']})",nltk\nltk\downloader.py,True
"is_stale(info_or_id, download_dir=None)","('is_stale', ['info_or_id', 'download_dir'])","('Downloader.is_stale', {'source_file': 'nltk\\nltk\\downloader.py', 'req_args': ['info_or_id'], 'opt_args': ['download_dir']})",nltk\nltk\downloader.py,True
"list(download_dir=None, show_packages=True, show_collections=True, header=True, more_prompt=False, skip_installed=False)","('list', ['download_dir', 'show_packages', 'show_collections', 'header', 'more_prompt', 'skip_installed'])","('Downloader.list', {'source_file': 'nltk\\nltk\\downloader.py', 'req_args': [], 'opt_args': ['skip_installed', 'more_prompt', 'header', 'show_collections', 'show_packages', 'download_dir']})",nltk\nltk\downloader.py,True
models(),"(None, [])",N/A,N/A,False
packages(),"(None, [])",N/A,N/A,False
"status(info_or_id, download_dir=None)","('status', ['info_or_id', 'download_dir'])","('Downloader.status', {'source_file': 'nltk\\nltk\\downloader.py', 'req_args': ['info_or_id'], 'opt_args': ['download_dir']})",nltk\nltk\downloader.py,True
"update(quiet=False, prefix='[nltk_data] ')","('update', ['quiet', 'prefix'])","('Downloader.update', {'source_file': 'nltk\\nltk\\downloader.py', 'req_args': [], 'opt_args': ['prefix', 'quiet']})",nltk\nltk\downloader.py,True
xmlinfo(id),"('xmlinfo', ['id'])","('Downloader.xmlinfo', {'source_file': 'nltk\\nltk\\downloader.py', 'req_args': ['id'], 'opt_args': []})",nltk\nltk\downloader.py,True
"class nltk.downloader.DownloaderGUI(dataserver, use_threads=True)","('nltk.downloader.DownloaderGUI', ['dataserver', 'use_threads'])","('DownloaderGUI.__init__', ['dataserver', 'use_threads'])",nltk\nltk\downloader.py,True
about(*e),"('about', ['e'])",N/A,N/A,False
destroy(*e),"('destroy', ['e'])",N/A,N/A,False
help(*e),"('help', ['e'])",N/A,N/A,False
"mainloop(*args, **kwargs)","('mainloop', ['args', 'kwargs'])",N/A,N/A,False
class nltk.downloader.DownloaderShell(dataserver),"('nltk.downloader.DownloaderShell', ['dataserver'])","('DownloaderShell.__init__', ['dataserver'])",nltk\nltk\downloader.py,True
run(),"(None, [])",N/A,N/A,False
"class nltk.downloader.ErrorMessage(package, message)","('nltk.downloader.ErrorMessage', ['package', 'message'])","('ErrorMessage.__init__', ['message', 'package'])",nltk\nltk\downloader.py,True
class nltk.downloader.FinishCollectionMessage(collection),"('nltk.downloader.FinishCollectionMessage', ['collection'])","('FinishCollectionMessage.__init__', ['collection'])",nltk\nltk\downloader.py,True
class nltk.downloader.FinishDownloadMessage(package),"('nltk.downloader.FinishDownloadMessage', ['package'])","('FinishDownloadMessage.__init__', ['package'])",nltk\nltk\downloader.py,True
class nltk.downloader.FinishPackageMessage(package),"('nltk.downloader.FinishPackageMessage', ['package'])","('FinishPackageMessage.__init__', ['package'])",nltk\nltk\downloader.py,True
class nltk.downloader.FinishUnzipMessage(package),"('nltk.downloader.FinishUnzipMessage', ['package'])","('FinishUnzipMessage.__init__', ['package'])",nltk\nltk\downloader.py,True
"class nltk.downloader.Package(id, url, name=None, subdir='', size=None, unzipped_size=None, checksum=None, svn_revision=None, copyright='Unknown', contact='Unknown', license='Unknown', author='Unknown', unzip=True, **kw)","('nltk.downloader.Package', ['id', 'url', 'name', 'subdir', 'size', 'unzipped_size', 'checksum', 'svn_revision', 'copyright', 'contact', 'license', 'author', 'unzip', 'kw'])","('Package.__init__', ['url', 'id', 'unzip', 'author', 'license', 'contact', 'copyright', 'svn_revision', 'checksum', 'unzipped_size', 'size', 'subdir', 'name', 'kw'])",nltk\nltk\downloader.py,True
class nltk.downloader.ProgressMessage(progress),"('nltk.downloader.ProgressMessage', ['progress'])","('ProgressMessage.__init__', ['progress'])",nltk\nltk\downloader.py,True
class nltk.downloader.SelectDownloadDirMessage(download_dir),"('nltk.downloader.SelectDownloadDirMessage', ['download_dir'])","('SelectDownloadDirMessage.__init__', ['download_dir'])",nltk\nltk\downloader.py,True
class nltk.downloader.StaleMessage(package),"('nltk.downloader.StaleMessage', ['package'])","('StaleMessage.__init__', ['package'])",nltk\nltk\downloader.py,True
class nltk.downloader.StartCollectionMessage(collection),"('nltk.downloader.StartCollectionMessage', ['collection'])","('StartCollectionMessage.__init__', ['collection'])",nltk\nltk\downloader.py,True
class nltk.downloader.StartDownloadMessage(package),"('nltk.downloader.StartDownloadMessage', ['package'])","('StartDownloadMessage.__init__', ['package'])",nltk\nltk\downloader.py,True
class nltk.downloader.StartPackageMessage(package),"('nltk.downloader.StartPackageMessage', ['package'])","('StartPackageMessage.__init__', ['package'])",nltk\nltk\downloader.py,True
class nltk.downloader.StartUnzipMessage(package),"('nltk.downloader.StartUnzipMessage', ['package'])","('StartUnzipMessage.__init__', ['package'])",nltk\nltk\downloader.py,True
class nltk.downloader.UpToDateMessage(package),"('nltk.downloader.UpToDateMessage', ['package'])","('UpToDateMessage.__init__', ['package'])",nltk\nltk\downloader.py,True
"nltk.downloader.build_index(root, base_url)","('nltk.downloader.build_index', ['root', 'base_url'])","('nltk.build_index', {'source_file': 'nltk\\nltk\\downloader.py', 'req_args': ['base_url', 'root'], 'opt_args': []})",nltk\nltk\downloader.py,True
"nltk.downloader.download(info_or_id=None, download_dir=None, quiet=False, force=False, prefix='[nltk_data] ', halt_on_error=True, raise_on_error=False, print_error_to=<_io.TextIOWrapper name='' mode='w' encoding='utf-8'>)","(None, [])",N/A,N/A,False
nltk.downloader.download_gui(),"(None, [])",N/A,N/A,False
nltk.downloader.download_shell(),"(None, [])",N/A,N/A,False
nltk.downloader.md5_hexdigest(file),"('nltk.downloader.md5_hexdigest', ['file'])","('nltk.md5_hexdigest', {'source_file': 'nltk\\nltk\\downloader.py', 'req_args': ['file'], 'opt_args': []})",nltk\nltk\downloader.py,True
"nltk.downloader.unzip(filename, root, verbose=True)","('nltk.downloader.unzip', ['filename', 'root', 'verbose'])","('nltk.unzip', {'source_file': 'nltk\\nltk\\downloader.py', 'req_args': ['root', 'filename'], 'opt_args': ['verbose']})",nltk\nltk\downloader.py,True
nltk.downloader.update(),"(None, [])",N/A,N/A,False
"class nltk.featstruct.FeatDict(features=None, **morefeatures)","('nltk.featstruct.FeatDict', ['features', 'morefeatures'])","('FeatDict.__init__', ['features', 'morefeatures'])",nltk\nltk\featstruct.py,True
clear() → None.  Remove all items from D.,"(None, [])",N/A,N/A,False
"get(name_or_path, default=None)","('get', ['name_or_path', 'default'])","('FeatDict.get', {'source_file': 'nltk\\nltk\\featstruct.py', 'req_args': ['name_or_path'], 'opt_args': ['default']})",nltk\nltk\featstruct.py,True
has_key(name_or_path),"('has_key', ['name_or_path'])","('FeatDict.has_key', {'source_file': 'nltk\\nltk\\featstruct.py', 'req_args': ['name_or_path'], 'opt_args': []})",nltk\nltk\featstruct.py,True
"pop(k[, d]) → v, remove specified key and return the corresponding value.","(None, [])",N/A,N/A,False
"popitem(*args, **kwargs)","('popitem', ['args', 'kwargs'])",N/A,N/A,False
"setdefault(*args, **kwargs)","('setdefault', ['args', 'kwargs'])",N/A,N/A,False
"update([E, ]**F) → None.  Update D from dict/iterable E and F.","(None, [])",N/A,N/A,False
"class nltk.featstruct.FeatList(features=None, **morefeatures)","('nltk.featstruct.FeatList', ['features', 'morefeatures'])","('FeatList.__init__', ['features'])",nltk\nltk\featstruct.py,True
"append(*args, **kwargs)","('append', ['args', 'kwargs'])",N/A,N/A,False
"extend(*args, **kwargs)","('extend', ['args', 'kwargs'])",N/A,N/A,False
"insert(*args, **kwargs)","('insert', ['args', 'kwargs'])",N/A,N/A,False
"pop(*args, **kwargs)","('pop', ['args', 'kwargs'])",N/A,N/A,False
"remove(*args, **kwargs)","('remove', ['args', 'kwargs'])",N/A,N/A,False
"reverse(*args, **kwargs)","('reverse', ['args', 'kwargs'])",N/A,N/A,False
"sort(*args, **kwargs)","('sort', ['args', 'kwargs'])",N/A,N/A,False
"class nltk.featstruct.FeatStruct(features=None, **morefeatures)","('nltk.featstruct.FeatStruct', ['features', 'morefeatures'])",['FeatStruct.__init__'],N/A,False
copy(deep=True),"('copy', ['deep'])","[('FeatStruct.copy', {'source_file': 'nltk\\nltk\\featstruct.py', 'req_args': [], 'opt_args': ['deep']}), ('ImmutableProbabilisticTree.copy', {'source_file': 'nltk\\nltk\\tree\\immutable.py', 'req_args': [], 'opt_args': ['deep']}), ('ParentedTree.copy', {'source_file': 'nltk\\nltk\\tree\\parented.py', 'req_args': [], 'opt_args': ['deep']}), ('ProbabilisticTree.copy', {'source_file': 'nltk\\nltk\\tree\\probabilistic.py', 'req_args': [], 'opt_args': ['deep']}), ('Tree.copy', {'source_file': 'nltk\\nltk\\tree\\tree.py', 'req_args': [], 'opt_args': ['deep']})]",N/A,False
cyclic(),"(None, [])",N/A,N/A,False
"equal_values(other, check_reentrance=False)","('equal_values', ['other', 'check_reentrance'])","('FeatStruct.equal_values', {'source_file': 'nltk\\nltk\\featstruct.py', 'req_args': ['other'], 'opt_args': ['check_reentrance']})",nltk\nltk\featstruct.py,True
freeze(),"(None, [])",N/A,N/A,False
frozen(),"(None, [])",N/A,N/A,False
remove_variables(),"(None, [])",N/A,N/A,False
"rename_variables(vars=None, used_vars=(), new_vars=None)","('rename_variables', ['vars', 'used_vars', 'new_vars'])","[('FeatStruct.rename_variables', {'source_file': 'nltk\\nltk\\featstruct.py', 'req_args': [], 'opt_args': ['new_vars', 'used_vars', 'vars']}), ('nltk.rename_variables', {'source_file': 'nltk\\nltk\\featstruct.py', 'req_args': ['fstruct'], 'opt_args': ['fs_class', 'new_vars', 'used_vars', 'vars']})]",N/A,False
retract_bindings(bindings),"('retract_bindings', ['bindings'])","[('FeatStruct.retract_bindings', {'source_file': 'nltk\\nltk\\featstruct.py', 'req_args': ['bindings'], 'opt_args': []}), ('nltk.retract_bindings', {'source_file': 'nltk\\nltk\\featstruct.py', 'req_args': ['bindings', 'fstruct'], 'opt_args': ['fs_class']})]",N/A,False
substitute_bindings(bindings),"('substitute_bindings', ['bindings'])","[('FeatStruct.substitute_bindings', {'source_file': 'nltk\\nltk\\featstruct.py', 'req_args': ['bindings'], 'opt_args': []}), ('nltk.substitute_bindings', {'source_file': 'nltk\\nltk\\featstruct.py', 'req_args': ['bindings', 'fstruct'], 'opt_args': ['fs_class']}), ('SubstituteBindingsSequence.substitute_bindings', {'source_file': 'nltk\\nltk\\featstruct.py', 'req_args': ['bindings'], 'opt_args': []}), ('Clause.substitute_bindings', {'source_file': 'nltk\\nltk\\inference\\resolution.py', 'req_args': ['bindings'], 'opt_args': []}), ('Variable.substitute_bindings', {'source_file': 'nltk\\nltk\\sem\\logic.py', 'req_args': ['bindings'], 'opt_args': []}), ('SubstituteBindingsI.substitute_bindings', {'source_file': 'nltk\\nltk\\sem\\logic.py', 'req_args': ['bindings'], 'opt_args': []}), ('Expression.substitute_bindings', {'source_file': 'nltk\\nltk\\sem\\logic.py', 'req_args': ['bindings'], 'opt_args': []})]",N/A,False
subsumes(other),"('subsumes', ['other'])","[('FeatStruct.subsumes', {'source_file': 'nltk\\nltk\\featstruct.py', 'req_args': ['other'], 'opt_args': []}), ('Clause.subsumes', {'source_file': 'nltk\\nltk\\inference\\resolution.py', 'req_args': ['other'], 'opt_args': []})]",N/A,False
"unify(other, bindings=None, trace=False, fail=None, rename_vars=True)","('unify', ['other', 'bindings', 'trace', 'fail', 'rename_vars'])","('FeatStruct.unify', {'source_file': 'nltk\\nltk\\featstruct.py', 'req_args': ['other'], 'opt_args': ['rename_vars', 'fail', 'trace', 'bindings']})",nltk\nltk\featstruct.py,True
variables(),"(None, [])",N/A,N/A,False
walk(),"(None, [])",N/A,N/A,False
"class nltk.featstruct.FeatStructReader(features=(*slash*, *type*), fdict_class= 'nltk.featstruct.FeatStruct'>, flist_class= 'nltk.featstruct.FeatList'>, logic_parser=None)","(None, [])",N/A,N/A,False
"VALUE_HANDLERS = [('read_fstruct_value', re.compile('\\s*(?:\\((\\d+)\\)\\s*)?(\\??[\\w-]+)?(\\[)')), ('read_var_value', re.compile('\\?[a-zA-Z_][a-zA-Z0-9_]*')), ('read_str_value', re.compile('[uU]?[rR]?([\'""])')), ('read_int_value', re.compile('-?\\d+')), ('read_sym_value', re.compile('[a-zA-Z_][a-zA-Z0-9_]*')), ('read_app_value', re.compile('<(app)\\((\\?[a-z][a-z]*)\\s*,\\s*(\\?[a-z][a-z]*)\\)>')), ('read_logic_value', re.compile('<(.*?)(?')), ('read_set_value', re.compile('{')), ('read_tuple_value', re.compile('\\('))]","(None, [])",N/A,N/A,False
"fromstring(s, fstruct=None)","('fromstring', ['s', 'fstruct'])","('FeatStructReader.fromstring', {'source_file': 'nltk\\nltk\\featstruct.py', 'req_args': ['s'], 'opt_args': ['fstruct']})",nltk\nltk\featstruct.py,True
"read_app_value(s, position, reentrances, match)","('read_app_value', ['s', 'position', 'reentrances', 'match'])","('FeatStructReader.read_app_value', {'source_file': 'nltk\\nltk\\featstruct.py', 'req_args': ['match', 'reentrances', 'position', 's'], 'opt_args': []})",nltk\nltk\featstruct.py,True
"read_fstruct_value(s, position, reentrances, match)","('read_fstruct_value', ['s', 'position', 'reentrances', 'match'])","('FeatStructReader.read_fstruct_value', {'source_file': 'nltk\\nltk\\featstruct.py', 'req_args': ['match', 'reentrances', 'position', 's'], 'opt_args': []})",nltk\nltk\featstruct.py,True
"read_int_value(s, position, reentrances, match)","('read_int_value', ['s', 'position', 'reentrances', 'match'])","('FeatStructReader.read_int_value', {'source_file': 'nltk\\nltk\\featstruct.py', 'req_args': ['match', 'reentrances', 'position', 's'], 'opt_args': []})",nltk\nltk\featstruct.py,True
"read_logic_value(s, position, reentrances, match)","('read_logic_value', ['s', 'position', 'reentrances', 'match'])","('FeatStructReader.read_logic_value', {'source_file': 'nltk\\nltk\\featstruct.py', 'req_args': ['match', 'reentrances', 'position', 's'], 'opt_args': []})",nltk\nltk\featstruct.py,True
"read_partial(s, position=0, reentrances=None, fstruct=None)","('read_partial', ['s', 'position', 'reentrances', 'fstruct'])","('FeatStructReader.read_partial', {'source_file': 'nltk\\nltk\\featstruct.py', 'req_args': ['s'], 'opt_args': ['fstruct', 'reentrances', 'position']})",nltk\nltk\featstruct.py,True
"read_set_value(s, position, reentrances, match)","('read_set_value', ['s', 'position', 'reentrances', 'match'])","('FeatStructReader.read_set_value', {'source_file': 'nltk\\nltk\\featstruct.py', 'req_args': ['match', 'reentrances', 'position', 's'], 'opt_args': []})",nltk\nltk\featstruct.py,True
"read_str_value(s, position, reentrances, match)","('read_str_value', ['s', 'position', 'reentrances', 'match'])","('FeatStructReader.read_str_value', {'source_file': 'nltk\\nltk\\featstruct.py', 'req_args': ['match', 'reentrances', 'position', 's'], 'opt_args': []})",nltk\nltk\featstruct.py,True
"read_sym_value(s, position, reentrances, match)","('read_sym_value', ['s', 'position', 'reentrances', 'match'])","('FeatStructReader.read_sym_value', {'source_file': 'nltk\\nltk\\featstruct.py', 'req_args': ['match', 'reentrances', 'position', 's'], 'opt_args': []})",nltk\nltk\featstruct.py,True
"read_tuple_value(s, position, reentrances, match)","('read_tuple_value', ['s', 'position', 'reentrances', 'match'])","('FeatStructReader.read_tuple_value', {'source_file': 'nltk\\nltk\\featstruct.py', 'req_args': ['match', 'reentrances', 'position', 's'], 'opt_args': []})",nltk\nltk\featstruct.py,True
"read_value(s, position, reentrances)","('read_value', ['s', 'position', 'reentrances'])","[('Feature.read_value', {'source_file': 'nltk\\nltk\\featstruct.py', 'req_args': ['parser', 'reentrances', 'position', 's'], 'opt_args': []}), ('SlashFeature.read_value', {'source_file': 'nltk\\nltk\\featstruct.py', 'req_args': ['parser', 'reentrances', 'position', 's'], 'opt_args': []}), ('RangeFeature.read_value', {'source_file': 'nltk\\nltk\\featstruct.py', 'req_args': ['parser', 'reentrances', 'position', 's'], 'opt_args': []}), ('FeatStructReader.read_value', {'source_file': 'nltk\\nltk\\featstruct.py', 'req_args': ['reentrances', 'position', 's'], 'opt_args': []})]",N/A,False
"read_var_value(s, position, reentrances, match)","('read_var_value', ['s', 'position', 'reentrances', 'match'])","('FeatStructReader.read_var_value', {'source_file': 'nltk\\nltk\\featstruct.py', 'req_args': ['match', 'reentrances', 'position', 's'], 'opt_args': []})",nltk\nltk\featstruct.py,True
"class nltk.featstruct.Feature(name, default=None, display=None)","('nltk.featstruct.Feature', ['name', 'default', 'display'])","('Feature.__init__', ['positions', 'end'])",nltk\nltk\tbl\feature.py,True
"read_value(s, position, reentrances, parser)","('read_value', ['s', 'position', 'reentrances', 'parser'])","[('Feature.read_value', {'source_file': 'nltk\\nltk\\featstruct.py', 'req_args': ['parser', 'reentrances', 'position', 's'], 'opt_args': []}), ('SlashFeature.read_value', {'source_file': 'nltk\\nltk\\featstruct.py', 'req_args': ['parser', 'reentrances', 'position', 's'], 'opt_args': []}), ('RangeFeature.read_value', {'source_file': 'nltk\\nltk\\featstruct.py', 'req_args': ['parser', 'reentrances', 'position', 's'], 'opt_args': []})]",N/A,False
"unify_base_values(fval1, fval2, bindings)","('unify_base_values', ['fval1', 'fval2', 'bindings'])","[('Feature.unify_base_values', {'source_file': 'nltk\\nltk\\featstruct.py', 'req_args': ['bindings', 'fval2', 'fval1'], 'opt_args': []}), ('RangeFeature.unify_base_values', {'source_file': 'nltk\\nltk\\featstruct.py', 'req_args': ['bindings', 'fval2', 'fval1'], 'opt_args': []})]",N/A,False
"class nltk.featstruct.RangeFeature(name, default=None, display=None)","('nltk.featstruct.RangeFeature', ['name', 'default', 'display'])",['RangeFeature.__init__'],N/A,False
RANGE_RE = re.compile('(-?\\d+):(-?\\d+)'),"(None, [])",N/A,N/A,False
"class nltk.featstruct.SlashFeature(name, default=None, display=None)","('nltk.featstruct.SlashFeature', ['name', 'default', 'display'])",['SlashFeature.__init__'],N/A,False
"nltk.featstruct.conflicts(fstruct1, fstruct2, trace=0)","('nltk.featstruct.conflicts', ['fstruct1', 'fstruct2', 'trace'])","('nltk.conflicts', {'source_file': 'nltk\\nltk\\featstruct.py', 'req_args': ['fstruct2', 'fstruct1'], 'opt_args': ['trace']})",nltk\nltk\featstruct.py,True
"nltk.featstruct.subsumes(fstruct1, fstruct2)","('nltk.featstruct.subsumes', ['fstruct1', 'fstruct2'])","('nltk.subsumes', {'source_file': 'nltk\\nltk\\featstruct.py', 'req_args': ['fstruct2', 'fstruct1'], 'opt_args': []})",nltk\nltk\featstruct.py,True
"nltk.featstruct.unify(fstruct1, fstruct2, bindings=None, trace=False, fail=None, rename_vars=True, fs_class='default')","('nltk.featstruct.unify', ['fstruct1', 'fstruct2', 'bindings', 'trace', 'fail', 'rename_vars', 'fs_class'])","('nltk.unify', {'source_file': 'nltk\\nltk\\featstruct.py', 'req_args': ['fstruct2', 'fstruct1'], 'opt_args': ['fs_class', 'rename_vars', 'fail', 'trace', 'bindings']})",nltk\nltk\featstruct.py,True
"class nltk.grammar.CFG(start, productions, calculate_leftcorners=True)","('nltk.grammar.CFG', ['start', 'productions', 'calculate_leftcorners'])","('CFG.__init__', ['productions', 'start', 'calculate_leftcorners'])",nltk\nltk\grammar.py,True
"classmethod binarize(grammar, padding='@$@')","('binarize', ['grammar', 'padding'])","('CFG.binarize', {'source_file': 'nltk\\nltk\\grammar.py', 'req_args': ['grammar', 'cls'], 'opt_args': ['padding']})",nltk\nltk\grammar.py,True
check_coverage(tokens),"('check_coverage', ['tokens'])","('CFG.check_coverage', {'source_file': 'nltk\\nltk\\grammar.py', 'req_args': ['tokens'], 'opt_args': []})",nltk\nltk\grammar.py,True
"chomsky_normal_form(new_token_padding='@$@', flexible=False)","('chomsky_normal_form', ['new_token_padding', 'flexible'])","('CFG.chomsky_normal_form', {'source_file': 'nltk\\nltk\\grammar.py', 'req_args': [], 'opt_args': ['flexible', 'new_token_padding']})",nltk\nltk\grammar.py,True
classmethod eliminate_start(grammar),"('eliminate_start', ['grammar'])","('CFG.eliminate_start', {'source_file': 'nltk\\nltk\\grammar.py', 'req_args': ['grammar', 'cls'], 'opt_args': []})",nltk\nltk\grammar.py,True
"classmethod fromstring(input, encoding=None)","('fromstring', ['input', 'encoding'])","[('CFG.fromstring', {'source_file': 'nltk\\nltk\\grammar.py', 'req_args': ['input', 'cls'], 'opt_args': ['encoding']}), ('FeatureGrammar.fromstring', {'source_file': 'nltk\\nltk\\grammar.py', 'req_args': ['input', 'cls'], 'opt_args': ['encoding', 'fstruct_reader', 'logic_parser', 'features']}), ('PCFG.fromstring', {'source_file': 'nltk\\nltk\\grammar.py', 'req_args': ['input', 'cls'], 'opt_args': ['encoding']})]",N/A,False
is_binarised(),"(None, [])",N/A,N/A,False
is_chomsky_normal_form(),"(None, [])",N/A,N/A,False
is_flexible_chomsky_normal_form(),"(None, [])",N/A,N/A,False
"is_leftcorner(cat, left)","('is_leftcorner', ['cat', 'left'])","('CFG.is_leftcorner', {'source_file': 'nltk\\nltk\\grammar.py', 'req_args': ['left', 'cat'], 'opt_args': []})",nltk\nltk\grammar.py,True
is_lexical(),"(None, [])",N/A,N/A,False
is_nonempty(),"(None, [])",N/A,N/A,False
is_nonlexical(),"(None, [])",N/A,N/A,False
leftcorner_parents(cat),"('leftcorner_parents', ['cat'])","[('CFG.leftcorner_parents', {'source_file': 'nltk\\nltk\\grammar.py', 'req_args': ['cat'], 'opt_args': []}), ('FeatureGrammar.leftcorner_parents', {'source_file': 'nltk\\nltk\\grammar.py', 'req_args': ['cat'], 'opt_args': []})]",N/A,False
leftcorners(cat),"('leftcorners', ['cat'])","[('CFG.leftcorners', {'source_file': 'nltk\\nltk\\grammar.py', 'req_args': ['cat'], 'opt_args': []}), ('FeatureGrammar.leftcorners', {'source_file': 'nltk\\nltk\\grammar.py', 'req_args': ['cat'], 'opt_args': []})]",N/A,False
max_len(),"(None, [])",N/A,N/A,False
min_len(),"(None, [])",N/A,N/A,False
"productions(lhs=None, rhs=None, empty=False)","('productions', ['lhs', 'rhs', 'empty'])","[('CFG.productions', {'source_file': 'nltk\\nltk\\grammar.py', 'req_args': [], 'opt_args': ['empty', 'rhs', 'lhs']}), ('FeatureGrammar.productions', {'source_file': 'nltk\\nltk\\grammar.py', 'req_args': [], 'opt_args': ['empty', 'rhs', 'lhs']})]",N/A,False
classmethod remove_unitary_rules(grammar),"('remove_unitary_rules', ['grammar'])","('CFG.remove_unitary_rules', {'source_file': 'nltk\\nltk\\grammar.py', 'req_args': ['grammar', 'cls'], 'opt_args': []})",nltk\nltk\grammar.py,True
start(),"(None, [])",N/A,N/A,False
class nltk.grammar.DependencyGrammar(productions),"('nltk.grammar.DependencyGrammar', ['productions'])","('DependencyGrammar.__init__', ['productions'])",nltk\nltk\grammar.py,True
"contains(head, mod)","('contains', ['head', 'mod'])","[('DependencyGrammar.contains', {'source_file': 'nltk\\nltk\\grammar.py', 'req_args': ['mod', 'head'], 'opt_args': []}), ('ProbabilisticDependencyGrammar.contains', {'source_file': 'nltk\\nltk\\grammar.py', 'req_args': ['mod', 'head'], 'opt_args': []})]",N/A,False
classmethod fromstring(input),"('fromstring', ['input'])","[('CFG.fromstring', {'source_file': 'nltk\\nltk\\grammar.py', 'req_args': ['input', 'cls'], 'opt_args': ['encoding']}), ('FeatureGrammar.fromstring', {'source_file': 'nltk\\nltk\\grammar.py', 'req_args': ['input', 'cls'], 'opt_args': ['encoding', 'fstruct_reader', 'logic_parser', 'features']}), ('DependencyGrammar.fromstring', {'source_file': 'nltk\\nltk\\grammar.py', 'req_args': ['input', 'cls'], 'opt_args': []}), ('PCFG.fromstring', {'source_file': 'nltk\\nltk\\grammar.py', 'req_args': ['input', 'cls'], 'opt_args': ['encoding']})]",N/A,False
"class nltk.grammar.DependencyProduction(lhs, rhs)","('nltk.grammar.DependencyProduction', ['lhs', 'rhs'])",['DependencyProduction.__init__'],N/A,False
class nltk.grammar.Nonterminal(symbol),"('nltk.grammar.Nonterminal', ['symbol'])","('Nonterminal.__init__', ['symbol'])",nltk\nltk\grammar.py,True
symbol(),"(None, [])",N/A,N/A,False
"class nltk.grammar.PCFG(start, productions, calculate_leftcorners=True)","('nltk.grammar.PCFG', ['start', 'productions', 'calculate_leftcorners'])","('PCFG.__init__', ['productions', 'start', 'calculate_leftcorners'])",nltk\nltk\grammar.py,True
"class nltk.grammar.ProbabilisticDependencyGrammar(productions, events, tags)","('nltk.grammar.ProbabilisticDependencyGrammar', ['productions', 'events', 'tags'])","('ProbabilisticDependencyGrammar.__init__', ['tags', 'events', 'productions'])",nltk\nltk\grammar.py,True
"class nltk.grammar.ProbabilisticProduction(lhs, rhs, **prob)","('nltk.grammar.ProbabilisticProduction', ['lhs', 'rhs', 'prob'])","('ProbabilisticProduction.__init__', ['rhs', 'lhs', 'prob'])",nltk\nltk\grammar.py,True
"class nltk.grammar.Production(lhs, rhs)","('nltk.grammar.Production', ['lhs', 'rhs'])","('Production.__init__', ['rhs', 'lhs'])",nltk\nltk\grammar.py,True
lhs(),"(None, [])",N/A,N/A,False
rhs(),"(None, [])",N/A,N/A,False
"nltk.grammar.induce_pcfg(start, productions)","('nltk.grammar.induce_pcfg', ['start', 'productions'])","('nltk.induce_pcfg', {'source_file': 'nltk\\nltk\\grammar.py', 'req_args': ['productions', 'start'], 'opt_args': []})",nltk\nltk\grammar.py,True
nltk.grammar.nonterminals(symbols),"('nltk.grammar.nonterminals', ['symbols'])","('nltk.nonterminals', {'source_file': 'nltk\\nltk\\grammar.py', 'req_args': ['symbols'], 'opt_args': []})",nltk\nltk\grammar.py,True
"nltk.grammar.read_grammar(input, nonterm_parser, probabilistic=False, encoding=None)","('nltk.grammar.read_grammar', ['input', 'nonterm_parser', 'probabilistic', 'encoding'])","('nltk.read_grammar', {'source_file': 'nltk\\nltk\\grammar.py', 'req_args': ['nonterm_parser', 'input'], 'opt_args': ['encoding', 'probabilistic']})",nltk\nltk\grammar.py,True
nltk.help.brown_tagset(tagpattern=None),"('nltk.help.brown_tagset', ['tagpattern'])","('nltk.brown_tagset', {'source_file': 'nltk\\nltk\\help.py', 'req_args': [], 'opt_args': ['tagpattern']})",nltk\nltk\help.py,True
nltk.help.claws5_tagset(tagpattern=None),"('nltk.help.claws5_tagset', ['tagpattern'])","('nltk.claws5_tagset', {'source_file': 'nltk\\nltk\\help.py', 'req_args': [], 'opt_args': ['tagpattern']})",nltk\nltk\help.py,True
nltk.help.upenn_tagset(tagpattern=None),"('nltk.help.upenn_tagset', ['tagpattern'])","('nltk.upenn_tagset', {'source_file': 'nltk\\nltk\\help.py', 'req_args': [], 'opt_args': ['tagpattern']})",nltk\nltk\help.py,True
class nltk.probability.ConditionalFreqDist(cond_samples=None),"('nltk.probability.ConditionalFreqDist', ['cond_samples'])","('ConditionalFreqDist.__init__', ['cond_samples'])",nltk\nltk\probability.py,True
N(),"(None, [])",N/A,N/A,False
conditions(),"(None, [])",N/A,N/A,False
"plot(*args, **kwargs)","('plot', ['args', 'kwargs'])",N/A,N/A,False
"tabulate(*args, **kwargs)","('tabulate', ['args', 'kwargs'])",N/A,N/A,False
"class nltk.probability.ConditionalProbDist(cfdist, probdist_factory, *factory_args, **factory_kw_args)","('nltk.probability.ConditionalProbDist', ['cfdist', 'probdist_factory', 'factory_args', 'factory_kw_args'])","('ConditionalProbDist.__init__', ['probdist_factory', 'cfdist', 'factory_kw_args'])",nltk\nltk\probability.py,True
"class nltk.probability.CrossValidationProbDist(freqdists, bins)","('nltk.probability.CrossValidationProbDist', ['freqdists', 'bins'])","('CrossValidationProbDist.__init__', ['bins', 'freqdists'])",nltk\nltk\probability.py,True
discount(),"(None, [])",N/A,N/A,False
freqdists(),"(None, [])",N/A,N/A,False
prob(sample),"('prob', ['sample'])","[('ProbDistI.prob', {'source_file': 'nltk\\nltk\\probability.py', 'req_args': ['sample'], 'opt_args': []}), ('UniformProbDist.prob', {'source_file': 'nltk\\nltk\\probability.py', 'req_args': ['sample'], 'opt_args': []}), ('RandomProbDist.prob', {'source_file': 'nltk\\nltk\\probability.py', 'req_args': ['sample'], 'opt_args': []}), ('DictionaryProbDist.prob', {'source_file': 'nltk\\nltk\\probability.py', 'req_args': ['sample'], 'opt_args': []}), ('MLEProbDist.prob', {'source_file': 'nltk\\nltk\\probability.py', 'req_args': ['sample'], 'opt_args': []}), ('LidstoneProbDist.prob', {'source_file': 'nltk\\nltk\\probability.py', 'req_args': ['sample'], 'opt_args': []}), ('HeldoutProbDist.prob', {'source_file': 'nltk\\nltk\\probability.py', 'req_args': ['sample'], 'opt_args': []}), ('CrossValidationProbDist.prob', {'source_file': 'nltk\\nltk\\probability.py', 'req_args': ['sample'], 'opt_args': []}), ('WittenBellProbDist.prob', {'source_file': 'nltk\\nltk\\probability.py', 'req_args': ['sample'], 'opt_args': []}), ('SimpleGoodTuringProbDist.prob', {'source_file': 'nltk\\nltk\\probability.py', 'req_args': ['sample'], 'opt_args': []}), ('MutableProbDist.prob', {'source_file': 'nltk\\nltk\\probability.py', 'req_args': ['sample'], 'opt_args': []})]",N/A,False
samples(),"(None, [])",N/A,N/A,False
class nltk.probability.DictionaryConditionalProbDist(probdist_dict),"('nltk.probability.DictionaryConditionalProbDist', ['probdist_dict'])","('DictionaryConditionalProbDist.__init__', ['probdist_dict'])",nltk\nltk\probability.py,True
"class nltk.probability.DictionaryProbDist(prob_dict=None, log=False, normalize=False)","('nltk.probability.DictionaryProbDist', ['prob_dict', 'log', 'normalize'])","('DictionaryProbDist.__init__', ['normalize', 'log', 'prob_dict'])",nltk\nltk\probability.py,True
logprob(sample),"('logprob', ['sample'])","[('ProbDistI.logprob', {'source_file': 'nltk\\nltk\\probability.py', 'req_args': ['sample'], 'opt_args': []}), ('DictionaryProbDist.logprob', {'source_file': 'nltk\\nltk\\probability.py', 'req_args': ['sample'], 'opt_args': []}), ('MutableProbDist.logprob', {'source_file': 'nltk\\nltk\\probability.py', 'req_args': ['sample'], 'opt_args': []})]",N/A,False
max(),"(None, [])",N/A,N/A,False
"class nltk.probability.ELEProbDist(freqdist, bins=None)","('nltk.probability.ELEProbDist', ['freqdist', 'bins'])","('ELEProbDist.__init__', ['freqdist', 'bins'])",nltk\nltk\probability.py,True
class nltk.probability.FreqDist(samples=None),"('nltk.probability.FreqDist', ['samples'])","('FreqDist.__init__', ['samples'])",nltk\nltk\probability.py,True
B(),"(None, [])",N/A,N/A,False
"Nr(r, bins=None)","('Nr', ['r', 'bins'])","('FreqDist.Nr', {'source_file': 'nltk\\nltk\\probability.py', 'req_args': ['r'], 'opt_args': ['bins']})",nltk\nltk\probability.py,True
copy(),"(None, [])",N/A,N/A,False
freq(sample),"('freq', ['sample'])","('FreqDist.freq', {'source_file': 'nltk\\nltk\\probability.py', 'req_args': ['sample'], 'opt_args': []})",nltk\nltk\probability.py,True
hapaxes(),"(None, [])",N/A,N/A,False
pformat(maxlen=10),"('pformat', ['maxlen'])","('FreqDist.pformat', {'source_file': 'nltk\\nltk\\probability.py', 'req_args': [], 'opt_args': ['maxlen']})",nltk\nltk\probability.py,True
"pprint(maxlen=10, stream=None)","('pprint', ['maxlen', 'stream'])","('FreqDist.pprint', {'source_file': 'nltk\\nltk\\probability.py', 'req_args': [], 'opt_args': ['stream', 'maxlen']})",nltk\nltk\probability.py,True
r_Nr(bins=None),"('r_Nr', ['bins'])","('FreqDist.r_Nr', {'source_file': 'nltk\\nltk\\probability.py', 'req_args': [], 'opt_args': ['bins']})",nltk\nltk\probability.py,True
"setdefault(key, val)","('setdefault', ['key', 'val'])","('FreqDist.setdefault', {'source_file': 'nltk\\nltk\\probability.py', 'req_args': ['val', 'key'], 'opt_args': []})",nltk\nltk\probability.py,True
"update(*args, **kwargs)","('update', ['args', 'kwargs'])",N/A,N/A,False
"class nltk.probability.HeldoutProbDist(base_fdist, heldout_fdist, bins=None)","('nltk.probability.HeldoutProbDist', ['base_fdist', 'heldout_fdist', 'bins'])","('HeldoutProbDist.__init__', ['heldout_fdist', 'base_fdist', 'bins'])",nltk\nltk\probability.py,True
base_fdist(),"(None, [])",N/A,N/A,False
heldout_fdist(),"(None, [])",N/A,N/A,False
class nltk.probability.ImmutableProbabilisticMixIn(**kwargs),"('nltk.probability.ImmutableProbabilisticMixIn', ['kwargs'])",['ImmutableProbabilisticMixIn.__init__'],N/A,False
set_logprob(prob),"('set_logprob', ['prob'])","('ImmutableProbabilisticMixIn.set_logprob', {'source_file': 'nltk\\nltk\\probability.py', 'req_args': ['prob'], 'opt_args': []})",nltk\nltk\probability.py,True
set_prob(prob),"('set_prob', ['prob'])","[('ProbabilisticMixIn.set_prob', {'source_file': 'nltk\\nltk\\probability.py', 'req_args': ['prob'], 'opt_args': []}), ('ImmutableProbabilisticMixIn.set_prob', {'source_file': 'nltk\\nltk\\probability.py', 'req_args': ['prob'], 'opt_args': []})]",N/A,False
"class nltk.probability.KneserNeyProbDist(freqdist, bins=None, discount=0.75)","('nltk.probability.KneserNeyProbDist', ['freqdist', 'bins', 'discount'])","('KneserNeyProbDist.__init__', ['freqdist', 'discount', 'bins'])",nltk\nltk\probability.py,True
prob(trigram),"('prob', ['trigram'])","('KneserNeyProbDist.prob', {'source_file': 'nltk\\nltk\\probability.py', 'req_args': ['trigram'], 'opt_args': []})",nltk\nltk\probability.py,True
set_discount(discount),"('set_discount', ['discount'])","('KneserNeyProbDist.set_discount', {'source_file': 'nltk\\nltk\\probability.py', 'req_args': ['discount'], 'opt_args': []})",nltk\nltk\probability.py,True
"class nltk.probability.LaplaceProbDist(freqdist, bins=None)","('nltk.probability.LaplaceProbDist', ['freqdist', 'bins'])","('LaplaceProbDist.__init__', ['freqdist', 'bins'])",nltk\nltk\probability.py,True
"class nltk.probability.LidstoneProbDist(freqdist, gamma, bins=None)","('nltk.probability.LidstoneProbDist', ['freqdist', 'gamma', 'bins'])","('LidstoneProbDist.__init__', ['gamma', 'freqdist', 'bins'])",nltk\nltk\probability.py,True
freqdist(),"(None, [])",N/A,N/A,False
"class nltk.probability.MLEProbDist(freqdist, bins=None)","('nltk.probability.MLEProbDist', ['freqdist', 'bins'])","('MLEProbDist.__init__', ['freqdist', 'bins'])",nltk\nltk\probability.py,True
"class nltk.probability.MutableProbDist(prob_dist, samples, store_logs=True)","('nltk.probability.MutableProbDist', ['prob_dist', 'samples', 'store_logs'])","('MutableProbDist.__init__', ['samples', 'prob_dist', 'store_logs'])",nltk\nltk\probability.py,True
"update(sample, prob, log=True)","('update', ['sample', 'prob', 'log'])","('MutableProbDist.update', {'source_file': 'nltk\\nltk\\probability.py', 'req_args': ['prob', 'sample'], 'opt_args': ['log']})",nltk\nltk\probability.py,True
generate(),"(None, [])",N/A,N/A,False
abstract max(),"(None, [])",N/A,N/A,False
abstract prob(sample),"('prob', ['sample'])","[('ProbDistI.prob', {'source_file': 'nltk\\nltk\\probability.py', 'req_args': ['sample'], 'opt_args': []}), ('UniformProbDist.prob', {'source_file': 'nltk\\nltk\\probability.py', 'req_args': ['sample'], 'opt_args': []}), ('RandomProbDist.prob', {'source_file': 'nltk\\nltk\\probability.py', 'req_args': ['sample'], 'opt_args': []}), ('DictionaryProbDist.prob', {'source_file': 'nltk\\nltk\\probability.py', 'req_args': ['sample'], 'opt_args': []}), ('MLEProbDist.prob', {'source_file': 'nltk\\nltk\\probability.py', 'req_args': ['sample'], 'opt_args': []}), ('LidstoneProbDist.prob', {'source_file': 'nltk\\nltk\\probability.py', 'req_args': ['sample'], 'opt_args': []}), ('HeldoutProbDist.prob', {'source_file': 'nltk\\nltk\\probability.py', 'req_args': ['sample'], 'opt_args': []}), ('CrossValidationProbDist.prob', {'source_file': 'nltk\\nltk\\probability.py', 'req_args': ['sample'], 'opt_args': []}), ('WittenBellProbDist.prob', {'source_file': 'nltk\\nltk\\probability.py', 'req_args': ['sample'], 'opt_args': []}), ('SimpleGoodTuringProbDist.prob', {'source_file': 'nltk\\nltk\\probability.py', 'req_args': ['sample'], 'opt_args': []}), ('MutableProbDist.prob', {'source_file': 'nltk\\nltk\\probability.py', 'req_args': ['sample'], 'opt_args': []})]",N/A,False
abstract samples(),"(None, [])",N/A,N/A,False
class nltk.probability.ProbabilisticMixIn(**kwargs),"('nltk.probability.ProbabilisticMixIn', ['kwargs'])","('ProbabilisticMixIn.__init__', ['kwargs'])",nltk\nltk\probability.py,True
logprob(),"(None, [])",N/A,N/A,False
prob(),"(None, [])",N/A,N/A,False
set_logprob(logprob),"('set_logprob', ['logprob'])","('ProbabilisticMixIn.set_logprob', {'source_file': 'nltk\\nltk\\probability.py', 'req_args': ['logprob'], 'opt_args': []})",nltk\nltk\probability.py,True
"class nltk.probability.SimpleGoodTuringProbDist(freqdist, bins=None)","('nltk.probability.SimpleGoodTuringProbDist', ['freqdist', 'bins'])","('SimpleGoodTuringProbDist.__init__', ['freqdist', 'bins'])",nltk\nltk\probability.py,True
check(),"(None, [])",N/A,N/A,False
"find_best_fit(r, nr)","('find_best_fit', ['r', 'nr'])","('SimpleGoodTuringProbDist.find_best_fit', {'source_file': 'nltk\\nltk\\probability.py', 'req_args': ['nr', 'r'], 'opt_args': []})",nltk\nltk\probability.py,True
smoothedNr(r),"('smoothedNr', ['r'])","('SimpleGoodTuringProbDist.smoothedNr', {'source_file': 'nltk\\nltk\\probability.py', 'req_args': ['r'], 'opt_args': []})",nltk\nltk\probability.py,True
class nltk.probability.UniformProbDist(samples),"('nltk.probability.UniformProbDist', ['samples'])","('UniformProbDist.__init__', ['samples'])",nltk\nltk\probability.py,True
"class nltk.probability.WittenBellProbDist(freqdist, bins=None)","('nltk.probability.WittenBellProbDist', ['freqdist', 'bins'])","('WittenBellProbDist.__init__', ['freqdist', 'bins'])",nltk\nltk\probability.py,True
"nltk.probability.add_logs(logx, logy)","('nltk.probability.add_logs', ['logx', 'logy'])","('nltk.add_logs', {'source_file': 'nltk\\nltk\\probability.py', 'req_args': ['logy', 'logx'], 'opt_args': []})",nltk\nltk\probability.py,True
nltk.probability.entropy(pdist),"('nltk.probability.entropy', ['pdist'])","('nltk.entropy', {'source_file': 'nltk\\nltk\\probability.py', 'req_args': ['pdist'], 'opt_args': []})",nltk\nltk\probability.py,True
"nltk.probability.log_likelihood(test_pdist, actual_pdist)","('nltk.probability.log_likelihood', ['test_pdist', 'actual_pdist'])",N/A,N/A,False
nltk.probability.sum_logs(logs),"('nltk.probability.sum_logs', ['logs'])","('nltk.sum_logs', {'source_file': 'nltk\\nltk\\probability.py', 'req_args': ['logs'], 'opt_args': []})",nltk\nltk\probability.py,True
"class nltk.text.ConcordanceIndex(tokens, key= ConcordanceIndex.>)","(None, [])",N/A,N/A,False
"find_concordance(word, width=80)","('find_concordance', ['word', 'width'])","('ConcordanceIndex.find_concordance', {'source_file': 'nltk\\nltk\\text.py', 'req_args': ['word'], 'opt_args': ['width']})",nltk\nltk\text.py,True
offsets(word),"('offsets', ['word'])","('ConcordanceIndex.offsets', {'source_file': 'nltk\\nltk\\text.py', 'req_args': ['word'], 'opt_args': []})",nltk\nltk\text.py,True
"print_concordance(word, width=80, lines=25)","('print_concordance', ['word', 'width', 'lines'])","('ConcordanceIndex.print_concordance', {'source_file': 'nltk\\nltk\\text.py', 'req_args': ['word'], 'opt_args': ['lines', 'width']})",nltk\nltk\text.py,True
tokens(),"(None, [])",N/A,N/A,False
"class nltk.text.ContextIndex(tokens, context_func=None, filter=None, key= ContextIndex.>)","(None, [])",N/A,N/A,False
"common_contexts(words, fail_on_unknown=False)","('common_contexts', ['words', 'fail_on_unknown'])","('ContextIndex.common_contexts', {'source_file': 'nltk\\nltk\\text.py', 'req_args': ['words'], 'opt_args': ['fail_on_unknown']})",nltk\nltk\text.py,True
"similar_words(word, n=20)","('similar_words', ['word', 'n'])","('ContextIndex.similar_words', {'source_file': 'nltk\\nltk\\text.py', 'req_args': ['word'], 'opt_args': ['n']})",nltk\nltk\text.py,True
word_similarity_dict(word),"('word_similarity_dict', ['word'])","('ContextIndex.word_similarity_dict', {'source_file': 'nltk\\nltk\\text.py', 'req_args': ['word'], 'opt_args': []})",nltk\nltk\text.py,True
"class nltk.text.Text(tokens, name=None)","('nltk.text.Text', ['tokens', 'name'])","('Text.__init__', ['tokens', 'name'])",nltk\nltk\text.py,True
"collocation_list(num=20, window_size=2)","('collocation_list', ['num', 'window_size'])","('Text.collocation_list', {'source_file': 'nltk\\nltk\\text.py', 'req_args': [], 'opt_args': ['window_size', 'num']})",nltk\nltk\text.py,True
"collocations(num=20, window_size=2)","('collocations', ['num', 'window_size'])","('Text.collocations', {'source_file': 'nltk\\nltk\\text.py', 'req_args': [], 'opt_args': ['window_size', 'num']})",nltk\nltk\text.py,True
"common_contexts(words, num=20)","('common_contexts', ['words', 'num'])","('Text.common_contexts', {'source_file': 'nltk\\nltk\\text.py', 'req_args': ['words'], 'opt_args': ['num']})",nltk\nltk\text.py,True
"concordance(word, width=79, lines=25)","('concordance', ['word', 'width', 'lines'])","('Text.concordance', {'source_file': 'nltk\\nltk\\text.py', 'req_args': ['word'], 'opt_args': ['lines', 'width']})",nltk\nltk\text.py,True
"concordance_list(word, width=79, lines=25)","('concordance_list', ['word', 'width', 'lines'])","('Text.concordance_list', {'source_file': 'nltk\\nltk\\text.py', 'req_args': ['word'], 'opt_args': ['lines', 'width']})",nltk\nltk\text.py,True
count(word),"('count', ['word'])","('Text.count', {'source_file': 'nltk\\nltk\\text.py', 'req_args': ['word'], 'opt_args': []})",nltk\nltk\text.py,True
dispersion_plot(words),"('dispersion_plot', ['words'])","[('Text.dispersion_plot', {'source_file': 'nltk\\nltk\\text.py', 'req_args': ['words'], 'opt_args': []}), ('nltk.dispersion_plot', {'source_file': 'nltk\\nltk\\draw\\dispersion.py', 'req_args': ['words', 'text'], 'opt_args': ['title', 'ignore_case']})]",N/A,False
findall(regexp),"('findall', ['regexp'])","[('TokenSearcher.findall', {'source_file': 'nltk\\nltk\\text.py', 'req_args': ['regexp'], 'opt_args': []}), ('Text.findall', {'source_file': 'nltk\\nltk\\text.py', 'req_args': ['regexp'], 'opt_args': []})]",N/A,False
"generate(length=100, text_seed=None, random_seed=42)","('generate', ['length', 'text_seed', 'random_seed'])","('Text.generate', {'source_file': 'nltk\\nltk\\text.py', 'req_args': [], 'opt_args': ['random_seed', 'text_seed', 'length']})",nltk\nltk\text.py,True
index(word),"('index', ['word'])","('Text.index', {'source_file': 'nltk\\nltk\\text.py', 'req_args': ['word'], 'opt_args': []})",nltk\nltk\text.py,True
plot(*args),"('plot', ['args'])",N/A,N/A,False
readability(method),"('readability', ['method'])","('Text.readability', {'source_file': 'nltk\\nltk\\text.py', 'req_args': ['method'], 'opt_args': []})",nltk\nltk\text.py,True
"similar(word, num=20)","('similar', ['word', 'num'])","('Text.similar', {'source_file': 'nltk\\nltk\\text.py', 'req_args': ['word'], 'opt_args': ['num']})",nltk\nltk\text.py,True
vocab(),"(None, [])",N/A,N/A,False
class nltk.text.TextCollection(source),"('nltk.text.TextCollection', ['source'])","('TextCollection.__init__', ['source'])",nltk\nltk\text.py,True
idf(term),"('idf', ['term'])","('TextCollection.idf', {'source_file': 'nltk\\nltk\\text.py', 'req_args': ['term'], 'opt_args': []})",nltk\nltk\text.py,True
"tf(term, text)","('tf', ['term', 'text'])","('TextCollection.tf', {'source_file': 'nltk\\nltk\\text.py', 'req_args': ['text', 'term'], 'opt_args': []})",nltk\nltk\text.py,True
"tf_idf(term, text)","('tf_idf', ['term', 'text'])","('TextCollection.tf_idf', {'source_file': 'nltk\\nltk\\text.py', 'req_args': ['text', 'term'], 'opt_args': []})",nltk\nltk\text.py,True
class nltk.text.TokenSearcher(tokens),"('nltk.text.TokenSearcher', ['tokens'])","('TokenSearcher.__init__', ['tokens'])",nltk\nltk\text.py,True
"class nltk.toolbox.StandardFormat(filename=None, encoding=None)","('nltk.toolbox.StandardFormat', ['filename', 'encoding'])","('StandardFormat.__init__', ['encoding', 'filename'])",nltk\nltk\toolbox.py,True
"fields(strip=True, unwrap=True, encoding=None, errors='strict', unicode_fields=None)","('fields', ['strip', 'unwrap', 'encoding', 'errors', 'unicode_fields'])","[('StandardFormat.fields', {'source_file': 'nltk\\nltk\\toolbox.py', 'req_args': [], 'opt_args': ['unicode_fields', 'errors', 'encoding', 'unwrap', 'strip']}), ('ToolboxCorpusReader.fields', {'source_file': 'nltk\\nltk\\corpus\\reader\\toolbox.py', 'req_args': ['fileids'], 'opt_args': ['unicode_fields', 'errors', 'encoding', 'unwrap', 'strip']})]",N/A,False
open(sfm_file),"('open', ['sfm_file'])","('StandardFormat.open', {'source_file': 'nltk\\nltk\\toolbox.py', 'req_args': ['sfm_file'], 'opt_args': []})",nltk\nltk\toolbox.py,True
open_string(s),"('open_string', ['s'])","('StandardFormat.open_string', {'source_file': 'nltk\\nltk\\toolbox.py', 'req_args': ['s'], 'opt_args': []})",nltk\nltk\toolbox.py,True
raw_fields(),"(None, [])",N/A,N/A,False
"class nltk.toolbox.ToolboxData(filename=None, encoding=None)","('nltk.toolbox.ToolboxData', ['filename', 'encoding'])",['ToolboxData.__init__'],N/A,False
"parse(grammar=None, **kwargs)","('parse', ['grammar', 'kwargs'])","('ToolboxData.parse', {'source_file': 'nltk\\nltk\\toolbox.py', 'req_args': [], 'opt_args': ['grammar', 'kwargs']})",nltk\nltk\toolbox.py,True
"parse(encoding=None, errors='strict', **kwargs)","('parse', ['encoding', 'errors', 'kwargs'])","('ToolboxSettings.parse', {'source_file': 'nltk\\nltk\\toolbox.py', 'req_args': [], 'opt_args': ['errors', 'encoding', 'kwargs']})",nltk\nltk\toolbox.py,True
"nltk.toolbox.add_blank_lines(tree, blanks_before, blanks_between)","('nltk.toolbox.add_blank_lines', ['tree', 'blanks_before', 'blanks_between'])","('nltk.add_blank_lines', {'source_file': 'nltk\\nltk\\toolbox.py', 'req_args': ['blanks_between', 'blanks_before', 'tree'], 'opt_args': []})",nltk\nltk\toolbox.py,True
"nltk.toolbox.add_default_fields(elem, default_fields)","('nltk.toolbox.add_default_fields', ['elem', 'default_fields'])","('nltk.add_default_fields', {'source_file': 'nltk\\nltk\\toolbox.py', 'req_args': ['default_fields', 'elem'], 'opt_args': []})",nltk\nltk\toolbox.py,True
nltk.toolbox.demo(),"(None, [])",N/A,N/A,False
nltk.toolbox.remove_blanks(elem),"('nltk.toolbox.remove_blanks', ['elem'])","('nltk.remove_blanks', {'source_file': 'nltk\\nltk\\toolbox.py', 'req_args': ['elem'], 'opt_args': []})",nltk\nltk\toolbox.py,True
"nltk.toolbox.sort_fields(elem, field_orders)","('nltk.toolbox.sort_fields', ['elem', 'field_orders'])","('nltk.sort_fields', {'source_file': 'nltk\\nltk\\toolbox.py', 'req_args': ['field_orders', 'elem'], 'opt_args': []})",nltk\nltk\toolbox.py,True
"nltk.toolbox.to_settings_string(tree, encoding=None, errors='strict', unicode_fields=None)","('nltk.toolbox.to_settings_string', ['tree', 'encoding', 'errors', 'unicode_fields'])","('nltk.to_settings_string', {'source_file': 'nltk\\nltk\\toolbox.py', 'req_args': ['tree'], 'opt_args': ['unicode_fields', 'errors', 'encoding']})",nltk\nltk\toolbox.py,True
"nltk.toolbox.to_sfm_string(tree, encoding=None, errors='strict', unicode_fields=None)","('nltk.toolbox.to_sfm_string', ['tree', 'encoding', 'errors', 'unicode_fields'])","('nltk.to_sfm_string', {'source_file': 'nltk\\nltk\\toolbox.py', 'req_args': ['tree'], 'opt_args': ['unicode_fields', 'errors', 'encoding']})",nltk\nltk\toolbox.py,True
"class nltk.tree.ImmutableMultiParentedTree(node, children=None)","('nltk.tree.ImmutableMultiParentedTree', ['node', 'children'])",N/A,N/A,False
"class nltk.tree.ImmutableParentedTree(node, children=None)","('nltk.tree.ImmutableParentedTree', ['node', 'children'])",N/A,N/A,False
"class nltk.tree.ImmutableProbabilisticTree(node, children=None, **prob_kwargs)","('nltk.tree.ImmutableProbabilisticTree', ['node', 'children', 'prob_kwargs'])","('ImmutableProbabilisticTree.__init__', ['node', 'children', 'prob_kwargs'])",nltk\nltk\tree\immutable.py,True
classmethod convert(val),"('convert', ['val'])","[('ImmutableProbabilisticTree.convert', {'source_file': 'nltk\\nltk\\tree\\immutable.py', 'req_args': ['val', 'cls'], 'opt_args': []}), ('ProbabilisticTree.convert', {'source_file': 'nltk\\nltk\\tree\\probabilistic.py', 'req_args': ['val', 'cls'], 'opt_args': []})]",N/A,False
copy(deep=False),"('copy', ['deep'])","[('FeatStruct.copy', {'source_file': 'nltk\\nltk\\featstruct.py', 'req_args': [], 'opt_args': ['deep']}), ('ImmutableProbabilisticTree.copy', {'source_file': 'nltk\\nltk\\tree\\immutable.py', 'req_args': [], 'opt_args': ['deep']}), ('ParentedTree.copy', {'source_file': 'nltk\\nltk\\tree\\parented.py', 'req_args': [], 'opt_args': ['deep']}), ('ProbabilisticTree.copy', {'source_file': 'nltk\\nltk\\tree\\probabilistic.py', 'req_args': [], 'opt_args': ['deep']}), ('Tree.copy', {'source_file': 'nltk\\nltk\\tree\\tree.py', 'req_args': [], 'opt_args': ['deep']})]",N/A,False
"class nltk.tree.ImmutableTree(node, children=None)","('nltk.tree.ImmutableTree', ['node', 'children'])","('ImmutableTree.__init__', ['node', 'children'])",nltk\nltk\tree\immutable.py,True
append(v),"('append', ['v'])","('ImmutableTree.append', {'source_file': 'nltk\\nltk\\tree\\immutable.py', 'req_args': ['v'], 'opt_args': []})",nltk\nltk\tree\immutable.py,True
extend(v),"('extend', ['v'])","('ImmutableTree.extend', {'source_file': 'nltk\\nltk\\tree\\immutable.py', 'req_args': ['v'], 'opt_args': []})",nltk\nltk\tree\immutable.py,True
pop(v=None),"('pop', ['v'])","('ImmutableTree.pop', {'source_file': 'nltk\\nltk\\tree\\immutable.py', 'req_args': [], 'opt_args': ['v']})",nltk\nltk\tree\immutable.py,True
remove(v),"('remove', ['v'])","('ImmutableTree.remove', {'source_file': 'nltk\\nltk\\tree\\immutable.py', 'req_args': ['v'], 'opt_args': []})",nltk\nltk\tree\immutable.py,True
reverse(),"(None, [])",N/A,N/A,False
set_label(value),"('set_label', ['value'])","('ImmutableTree.set_label', {'source_file': 'nltk\\nltk\\tree\\immutable.py', 'req_args': ['value'], 'opt_args': []})",nltk\nltk\tree\immutable.py,True
sort(),"(None, [])",N/A,N/A,False
"class nltk.tree.MultiParentedTree(node, children=None)","('nltk.tree.MultiParentedTree', ['node', 'children'])","('MultiParentedTree.__init__', ['node', 'children'])",nltk\nltk\tree\parented.py,True
left_siblings(),"(None, [])",N/A,N/A,False
parent_indices(parent),"('parent_indices', ['parent'])","('MultiParentedTree.parent_indices', {'source_file': 'nltk\\nltk\\tree\\parented.py', 'req_args': ['parent'], 'opt_args': []})",nltk\nltk\tree\parented.py,True
parents(),"(None, [])",N/A,N/A,False
right_siblings(),"(None, [])",N/A,N/A,False
roots(),"(None, [])",N/A,N/A,False
treepositions(root),"('treepositions', ['root'])","('MultiParentedTree.treepositions', {'source_file': 'nltk\\nltk\\tree\\parented.py', 'req_args': ['root'], 'opt_args': []})",nltk\nltk\tree\parented.py,True
"class nltk.tree.ParentedTree(node, children=None)","('nltk.tree.ParentedTree', ['node', 'children'])","('ParentedTree.__init__', ['node', 'children'])",nltk\nltk\tree\parented.py,True
left_sibling(),"(None, [])",N/A,N/A,False
parent(),"(None, [])",N/A,N/A,False
parent_index(),"(None, [])",N/A,N/A,False
right_sibling(),"(None, [])",N/A,N/A,False
root(),"(None, [])",N/A,N/A,False
treeposition(),"(None, [])",N/A,N/A,False
class nltk.tree.ProbabilisticMixIn(**kwargs),"('nltk.tree.ProbabilisticMixIn', ['kwargs'])","('ProbabilisticMixIn.__init__', ['kwargs'])",nltk\nltk\probability.py,True
"class nltk.tree.ProbabilisticTree(node, children=None, **prob_kwargs)","('nltk.tree.ProbabilisticTree', ['node', 'children', 'prob_kwargs'])","('ProbabilisticTree.__init__', ['node', 'children', 'prob_kwargs'])",nltk\nltk\tree\probabilistic.py,True
"class nltk.tree.Tree(node, children=None)","('nltk.tree.Tree', ['node', 'children'])","('Tree.__init__', ['node', 'children'])",nltk\nltk\tree\tree.py,True
"Tree(label, children) constructs a new tree with the","(None, [])",N/A,N/A,False
"chomsky_normal_form(factor='right', horzMarkov=None, vertMarkov=0, childChar='|', parentChar='^')","('chomsky_normal_form', ['factor', 'horzMarkov', 'vertMarkov', 'childChar', 'parentChar'])","[('nltk.chomsky_normal_form', {'source_file': 'nltk\\nltk\\tree\\transforms.py', 'req_args': ['tree'], 'opt_args': ['parentChar', 'childChar', 'vertMarkov', 'horzMarkov', 'factor']}), ('Tree.chomsky_normal_form', {'source_file': 'nltk\\nltk\\tree\\tree.py', 'req_args': [], 'opt_args': ['parentChar', 'childChar', 'vertMarkov', 'horzMarkov', 'factor']})]",N/A,False
"collapse_unary(collapsePOS=False, collapseRoot=False, joinChar='+')","('collapse_unary', ['collapsePOS', 'collapseRoot', 'joinChar'])","[('nltk.collapse_unary', {'source_file': 'nltk\\nltk\\tree\\transforms.py', 'req_args': ['tree'], 'opt_args': ['joinChar', 'collapseRoot', 'collapsePOS']}), ('Tree.collapse_unary', {'source_file': 'nltk\\nltk\\tree\\tree.py', 'req_args': [], 'opt_args': ['joinChar', 'collapseRoot', 'collapsePOS']})]",N/A,False
classmethod convert(tree),"('convert', ['tree'])","('Tree.convert', {'source_file': 'nltk\\nltk\\tree\\tree.py', 'req_args': ['tree', 'cls'], 'opt_args': []})",nltk\nltk\tree\tree.py,True
draw(),"(None, [])",N/A,N/A,False
flatten(),"(None, [])",N/A,N/A,False
freeze(leaf_freezer=None),"('freeze', ['leaf_freezer'])","('Tree.freeze', {'source_file': 'nltk\\nltk\\tree\\tree.py', 'req_args': [], 'opt_args': ['leaf_freezer']})",nltk\nltk\tree\tree.py,True
classmethod fromlist(l),"('fromlist', ['l'])","('Tree.fromlist', {'source_file': 'nltk\\nltk\\tree\\tree.py', 'req_args': ['l', 'cls'], 'opt_args': []})",nltk\nltk\tree\tree.py,True
"classmethod fromstring(s, brackets='()', read_node=None, read_leaf=None, node_pattern=None, leaf_pattern=None, remove_empty_top_bracketing=False)","('fromstring', ['s', 'brackets', 'read_node', 'read_leaf', 'node_pattern', 'leaf_pattern', 'remove_empty_top_bracketing'])","('Tree.fromstring', {'source_file': 'nltk\\nltk\\tree\\tree.py', 'req_args': ['s', 'cls'], 'opt_args': ['remove_empty_top_bracketing', 'leaf_pattern', 'node_pattern', 'read_leaf', 'read_node', 'brackets']})",nltk\nltk\tree\tree.py,True
height(),"(None, [])",N/A,N/A,False
label(),"(None, [])",N/A,N/A,False
leaf_treeposition(index),"('leaf_treeposition', ['index'])","('Tree.leaf_treeposition', {'source_file': 'nltk\\nltk\\tree\\tree.py', 'req_args': ['index'], 'opt_args': []})",nltk\nltk\tree\tree.py,True
leaves(),"(None, [])",N/A,N/A,False
"pformat(margin=70, indent=0, nodesep='', parens='()', quotes=False)","('pformat', ['margin', 'indent', 'nodesep', 'parens', 'quotes'])","('Tree.pformat', {'source_file': 'nltk\\nltk\\tree\\tree.py', 'req_args': [], 'opt_args': ['quotes', 'parens', 'nodesep', 'indent', 'margin']})",nltk\nltk\tree\tree.py,True
pformat_latex_qtree(),"(None, [])",N/A,N/A,False
pos(),"(None, [])",N/A,N/A,False
pprint(**kwargs),"('pprint', ['kwargs'])","('Tree.pprint', {'source_file': 'nltk\\nltk\\tree\\tree.py', 'req_args': [], 'opt_args': ['kwargs']})",nltk\nltk\tree\tree.py,True
"pretty_print(sentence=None, highlight=(), stream=None, **kwargs)","('pretty_print', ['sentence', 'highlight', 'stream', 'kwargs'])","('Tree.pretty_print', {'source_file': 'nltk\\nltk\\tree\\tree.py', 'req_args': [], 'opt_args': ['stream', 'highlight', 'sentence', 'kwargs']})",nltk\nltk\tree\tree.py,True
productions(),"(None, [])",N/A,N/A,False
set_label(label),"('set_label', ['label'])","[('TreeSegmentWidget.set_label', {'source_file': 'nltk\\nltk\\draw\\tree.py', 'req_args': ['label'], 'opt_args': []}), ('Tree.set_label', {'source_file': 'nltk\\nltk\\tree\\tree.py', 'req_args': ['label'], 'opt_args': []})]",N/A,False
subtrees(filter=None),"('subtrees', ['filter'])","('Tree.subtrees', {'source_file': 'nltk\\nltk\\tree\\tree.py', 'req_args': [], 'opt_args': ['filter']})",nltk\nltk\tree\tree.py,True
"treeposition_spanning_leaves(start, end)","('treeposition_spanning_leaves', ['start', 'end'])","('Tree.treeposition_spanning_leaves', {'source_file': 'nltk\\nltk\\tree\\tree.py', 'req_args': ['end', 'start'], 'opt_args': []})",nltk\nltk\tree\tree.py,True
treepositions(order='preorder'),"('treepositions', ['order'])","('Tree.treepositions', {'source_file': 'nltk\\nltk\\tree\\tree.py', 'req_args': [], 'opt_args': ['order']})",nltk\nltk\tree\tree.py,True
"un_chomsky_normal_form(expandUnary=True, childChar='|', parentChar='^', unaryChar='+')","('un_chomsky_normal_form', ['expandUnary', 'childChar', 'parentChar', 'unaryChar'])","[('nltk.un_chomsky_normal_form', {'source_file': 'nltk\\nltk\\tree\\transforms.py', 'req_args': ['tree'], 'opt_args': ['unaryChar', 'parentChar', 'childChar', 'expandUnary']}), ('Tree.un_chomsky_normal_form', {'source_file': 'nltk\\nltk\\tree\\tree.py', 'req_args': [], 'opt_args': ['unaryChar', 'parentChar', 'childChar', 'expandUnary']})]",N/A,False
nltk.tree.bracket_parse(s),"('nltk.tree.bracket_parse', ['s'])","('nltk.bracket_parse', {'source_file': 'nltk\\nltk\\tree\\parsing.py', 'req_args': ['s'], 'opt_args': []})",nltk\nltk\tree\parsing.py,True
nltk.tree.sinica_parse(s),"('nltk.tree.sinica_parse', ['s'])","('nltk.sinica_parse', {'source_file': 'nltk\\nltk\\tree\\parsing.py', 'req_args': ['s'], 'opt_args': []})",nltk\nltk\tree\parsing.py,True
"nltk.treetransforms.chomsky_normal_form(tree, factor='right', horzMarkov=None, vertMarkov=0, childChar='|', parentChar='^')","('nltk.treetransforms.chomsky_normal_form', ['tree', 'factor', 'horzMarkov', 'vertMarkov', 'childChar', 'parentChar'])","('nltk.chomsky_normal_form', {'source_file': 'nltk\\nltk\\tree\\transforms.py', 'req_args': ['tree'], 'opt_args': ['parentChar', 'childChar', 'vertMarkov', 'horzMarkov', 'factor']})",nltk\nltk\tree\transforms.py,True
"nltk.treetransforms.collapse_unary(tree, collapsePOS=False, collapseRoot=False, joinChar='+')","('nltk.treetransforms.collapse_unary', ['tree', 'collapsePOS', 'collapseRoot', 'joinChar'])","('nltk.collapse_unary', {'source_file': 'nltk\\nltk\\tree\\transforms.py', 'req_args': ['tree'], 'opt_args': ['joinChar', 'collapseRoot', 'collapsePOS']})",nltk\nltk\tree\transforms.py,True
"nltk.treetransforms.un_chomsky_normal_form(tree, expandUnary=True, childChar='|', parentChar='^', unaryChar='+')","('nltk.treetransforms.un_chomsky_normal_form', ['tree', 'expandUnary', 'childChar', 'parentChar', 'unaryChar'])","('nltk.un_chomsky_normal_form', {'source_file': 'nltk\\nltk\\tree\\transforms.py', 'req_args': ['tree'], 'opt_args': ['unaryChar', 'parentChar', 'childChar', 'expandUnary']})",nltk\nltk\tree\transforms.py,True
class nltk.util.Index(pairs),"('nltk.util.Index', ['pairs'])","('Index.__init__', ['pairs'])",nltk\nltk\util.py,True
"nltk.util.acyclic_branches_depth_first(tree, children= function iter>, depth=-1, cut_mark=None, traversed=None)","(None, [])",N/A,N/A,False
"nltk.util.acyclic_breadth_first(tree, children= function iter>, maxdepth=-1)","(None, [])",N/A,N/A,False
"nltk.util.acyclic_depth_first(tree, children= function iter>, depth=-1, cut_mark=None, traversed=None)","(None, [])",N/A,N/A,False
"nltk.util.acyclic_dic2tree(node, dic)","('nltk.util.acyclic_dic2tree', ['node', 'dic'])","('nltk.acyclic_dic2tree', {'source_file': 'nltk\\nltk\\util.py', 'req_args': ['dic', 'node'], 'opt_args': []})",nltk\nltk\util.py,True
"nltk.util.bigrams(sequence, **kwargs)","('nltk.util.bigrams', ['sequence', 'kwargs'])","('nltk.bigrams', {'source_file': 'nltk\\nltk\\util.py', 'req_args': ['sequence'], 'opt_args': ['kwargs']})",nltk\nltk\util.py,True
"nltk.util.binary_search_file(file, key, cache={}, cacheDepth=- 1)","('nltk.util.binary_search_file', ['file', 'key', 'cache', 'cacheDepth'])","('nltk.binary_search_file', {'source_file': 'nltk\\nltk\\util.py', 'req_args': ['key', 'file'], 'opt_args': ['cacheDepth', 'cache']})",nltk\nltk\util.py,True
"nltk.util.breadth_first(tree, children= function iter>, maxdepth=-1)","(None, [])",N/A,N/A,False
"nltk.util.choose(n, k)","('nltk.util.choose', ['n', 'k'])","('nltk.choose', {'source_file': 'nltk\\nltk\\util.py', 'req_args': ['k', 'n'], 'opt_args': []})",nltk\nltk\util.py,True
nltk.util.clean_html(html),"('nltk.util.clean_html', ['html'])","('nltk.clean_html', {'source_file': 'nltk\\nltk\\util.py', 'req_args': ['html'], 'opt_args': []})",nltk\nltk\util.py,True
nltk.util.clean_url(url),"('nltk.util.clean_url', ['url'])","('nltk.clean_url', {'source_file': 'nltk\\nltk\\util.py', 'req_args': ['url'], 'opt_args': []})",nltk\nltk\util.py,True
"nltk.util.elementtree_indent(elem, level=0)","('nltk.util.elementtree_indent', ['elem', 'level'])","('nltk.elementtree_indent', {'source_file': 'nltk\\nltk\\util.py', 'req_args': ['elem'], 'opt_args': ['level']})",nltk\nltk\util.py,True
"nltk.util.everygrams(sequence, min_len=1, max_len=- 1, pad_left=False, pad_right=False, **kwargs)","('nltk.util.everygrams', ['sequence', 'min_len', 'max_len', 'pad_left', 'pad_right', 'kwargs'])","('nltk.everygrams', {'source_file': 'nltk\\nltk\\util.py', 'req_args': ['sequence'], 'opt_args': ['pad_right', 'pad_left', 'max_len', 'min_len', 'kwargs']})",nltk\nltk\util.py,True
nltk.util.filestring(f),"('nltk.util.filestring', ['f'])","('nltk.filestring', {'source_file': 'nltk\\nltk\\util.py', 'req_args': ['f'], 'opt_args': []})",nltk\nltk\util.py,True
nltk.util.flatten(*args),"('nltk.util.flatten', ['args'])",N/A,N/A,False
nltk.util.guess_encoding(data),"('nltk.util.guess_encoding', ['data'])","('nltk.guess_encoding', {'source_file': 'nltk\\nltk\\util.py', 'req_args': ['data'], 'opt_args': []})",nltk\nltk\util.py,True
nltk.util.in_idle(),"(None, [])",N/A,N/A,False
nltk.util.invert_dict(d),"('nltk.util.invert_dict', ['d'])","('nltk.invert_dict', {'source_file': 'nltk\\nltk\\util.py', 'req_args': ['d'], 'opt_args': []})",nltk\nltk\util.py,True
nltk.util.invert_graph(graph),"('nltk.util.invert_graph', ['graph'])","('nltk.invert_graph', {'source_file': 'nltk\\nltk\\util.py', 'req_args': ['graph'], 'opt_args': []})",nltk\nltk\util.py,True
"nltk.util.ngrams(sequence, n, **kwargs)","('nltk.util.ngrams', ['sequence', 'n', 'kwargs'])","('nltk.ngrams', {'source_file': 'nltk\\nltk\\util.py', 'req_args': ['n', 'sequence'], 'opt_args': ['kwargs']})",nltk\nltk\util.py,True
"nltk.util.pad_sequence(sequence, n, pad_left=False, pad_right=False, left_pad_symbol=None, right_pad_symbol=None)","('nltk.util.pad_sequence', ['sequence', 'n', 'pad_left', 'pad_right', 'left_pad_symbol', 'right_pad_symbol'])","('nltk.pad_sequence', {'source_file': 'nltk\\nltk\\util.py', 'req_args': ['n', 'sequence'], 'opt_args': ['right_pad_symbol', 'left_pad_symbol', 'pad_right', 'pad_left']})",nltk\nltk\util.py,True
nltk.util.pairwise(iterable),"('nltk.util.pairwise', ['iterable'])","('nltk.pairwise', {'source_file': 'nltk\\nltk\\util.py', 'req_args': ['iterable'], 'opt_args': []})",nltk\nltk\util.py,True
"nltk.util.parallelize_preprocess(func, iterator, processes, progress_bar=False)","('nltk.util.parallelize_preprocess', ['func', 'iterator', 'processes', 'progress_bar'])","('nltk.parallelize_preprocess', {'source_file': 'nltk\\nltk\\util.py', 'req_args': ['processes', 'iterator', 'func'], 'opt_args': ['progress_bar']})",nltk\nltk\util.py,True
"nltk.util.pr(data, start=0, end=None)","('nltk.util.pr', ['data', 'start', 'end'])","('nltk.pr', {'source_file': 'nltk\\nltk\\util.py', 'req_args': ['data'], 'opt_args': ['end', 'start']})",nltk\nltk\util.py,True
"nltk.util.print_string(s, width=70)","('nltk.util.print_string', ['s', 'width'])","('nltk.print_string', {'source_file': 'nltk\\nltk\\util.py', 'req_args': ['s'], 'opt_args': ['width']})",nltk\nltk\util.py,True
nltk.util.py25(),"(None, [])",N/A,N/A,False
"nltk.util.re_show(regexp, string, left='{', right='}')","('nltk.util.re_show', ['regexp', 'string', 'left', 'right'])","('nltk.re_show', {'source_file': 'nltk\\nltk\\util.py', 'req_args': ['string', 'regexp'], 'opt_args': ['right', 'left']})",nltk\nltk\util.py,True
"nltk.util.set_proxy(proxy, user=None, password='')","('nltk.util.set_proxy', ['proxy', 'user', 'password'])","('nltk.set_proxy', {'source_file': 'nltk\\nltk\\util.py', 'req_args': ['proxy'], 'opt_args': ['password', 'user']})",nltk\nltk\util.py,True
"nltk.util.skipgrams(sequence, n, k, **kwargs)","('nltk.util.skipgrams', ['sequence', 'n', 'k', 'kwargs'])","('nltk.skipgrams', {'source_file': 'nltk\\nltk\\util.py', 'req_args': ['k', 'n', 'sequence'], 'opt_args': ['kwargs']})",nltk\nltk\util.py,True
"nltk.util.tokenwrap(tokens, separator=' ', width=70)","('nltk.util.tokenwrap', ['tokens', 'separator', 'width'])","('nltk.tokenwrap', {'source_file': 'nltk\\nltk\\util.py', 'req_args': ['tokens'], 'opt_args': ['width', 'separator']})",nltk\nltk\util.py,True
"nltk.util.transitive_closure(graph, reflexive=False)","('nltk.util.transitive_closure', ['graph', 'reflexive'])","('nltk.transitive_closure', {'source_file': 'nltk\\nltk\\util.py', 'req_args': ['graph'], 'opt_args': ['reflexive']})",nltk\nltk\util.py,True
"nltk.util.trigrams(sequence, **kwargs)","('nltk.util.trigrams', ['sequence', 'kwargs'])","('nltk.trigrams', {'source_file': 'nltk\\nltk\\util.py', 'req_args': ['sequence'], 'opt_args': ['kwargs']})",nltk\nltk\util.py,True
nltk.util.unique_list(xs),"('nltk.util.unique_list', ['xs'])","('nltk.unique_list', {'source_file': 'nltk\\nltk\\util.py', 'req_args': ['xs'], 'opt_args': []})",nltk\nltk\util.py,True
"nltk.util.unweighted_minimum_spanning_tree(tree, children= function iter>)","(None, [])",N/A,N/A,False
"nltk.util.usage(obj, selfname='self')","('nltk.util.usage', ['obj', 'selfname'])",N/A,N/A,False
"nltk.wsd.lesk(context_sentence, ambiguous_word, pos=None, synsets=None)","('nltk.wsd.lesk', ['context_sentence', 'ambiguous_word', 'pos', 'synsets'])","('nltk.lesk', {'source_file': 'nltk\\nltk\\wsd.py', 'req_args': ['ambiguous_word', 'context_sentence'], 'opt_args': ['synsets', 'pos']})",nltk\nltk\wsd.py,True
load(),"(None, [])",N/A,N/A,False
retrieve(),"(None, [])",N/A,N/A,False
write(),"(None, [])",N/A,N/A,False
writestr(),"(None, [])",N/A,N/A,False
seek(),"(None, [])",N/A,N/A,False
readline(),"(None, [])",N/A,N/A,False
read(),"(None, [])",N/A,N/A,False
find(),"(None, [])",N/A,N/A,False
download(),"(None, [])",N/A,N/A,False
Downloader.default_download_dir(),"(None, [])",N/A,N/A,False
_package_to_columns(),"(None, [])",N/A,N/A,False
unify(),"(None, [])",N/A,N/A,False
"fstruct[(f1,f2,...,fn)]","(None, [])",N/A,N/A,False
equal_values(),"(None, [])",N/A,N/A,False
nltk.featstruct.rename_variables(),"(None, [])",N/A,N/A,False
nltk.featstruct.retract_bindings(),"(None, [])",N/A,N/A,False
nltk.featstruct.substitute_bindings(),"(None, [])",N/A,N/A,False
nltk.featstruct.find_variables(),"(None, [])",N/A,N/A,False
"(string, position)","(None, [])",N/A,N/A,False
"(nonterminal, position)","(None, [])",N/A,N/A,False
FreqDist.N(),"(None, [])",N/A,N/A,False
FreqDist.B(),"(None, [])",N/A,N/A,False
bins-self.B(),"(None, [])",N/A,N/A,False
self.B(),"(None, [])",N/A,N/A,False
Counter.setdefault(),"(None, [])",N/A,N/A,False
Counter.update(),"(None, [])",N/A,N/A,False
2**(logprob),"(None, [])",N/A,N/A,False
c+gamma)/(N+B*gamma),"(None, [])",N/A,N/A,False
self.prob(samp),"('self.prob', ['samp'])",N/A,N/A,False
log(p),"('log', ['p'])",N/A,N/A,False
log(2**(logx)+2**(logy)),"(None, [])",N/A,N/A,False
findall(),"(None, [])",N/A,N/A,False
"(marker, value)","(None, [])",N/A,N/A,False
fields(),"(None, [])",N/A,N/A,False
decode(),"(None, [])",N/A,N/A,False
StandardFormat.fields(),"(None, [])",N/A,N/A,False
encode(),"(None, [])",N/A,N/A,False
parent_indices(),"(None, [])",N/A,N/A,False
ptree.parent()[ptree.parent_index()] is ptree,"(None, [])",N/A,N/A,False
ptree.parent_index(),"(None, [])",N/A,N/A,False
ptree.parent.index(ptree),"('ptree.parent.index', ['ptree'])",['Index'],N/A,False
ptree.parent(),"(None, [])",N/A,N/A,False
(),"(None, [])",N/A,N/A,False
"Tree(label, children)","('Tree', ['label', 'children'])","('Tree.__init__', ['node', 'children'])",nltk\nltk\tree\tree.py,True
Tree.fromstring(s),"('Tree.fromstring', ['s'])","('Tree.fromstring', ['s', 'cls', 'remove_empty_top_bracketing', 'leaf_pattern', 'node_pattern', 'read_leaf', 'read_node', 'brackets'])",nltk\nltk\tree\tree.py,True
tp=self.leaf_treeposition(i),"('self.leaf_treeposition', ['i'])",N/A,N/A,False
self[tp]==self.leaves()[i],"(None, [])",N/A,N/A,False
(S: (NP: I) (VP: (V: saw) (NP: it))),"(None, [])",N/A,N/A,False
self.leaves()[start:end],"(None, [])",N/A,N/A,False
"(decoded_unicode, successful_encoding)","(None, [])",N/A,N/A,False
"nltk.data.FORMATS = {'cfg': 'A context free grammar.', 'fcfg': 'A feature CFG.', 'fol': 'A list of first order logic expressions, parsed with nltk.sem.logic.Expression.fromstring.', 'json': 'A serialized python object, stored using the json module.', 'logic': 'A list of first order logic expressions, parsed with nltk.sem.logic.LogicParser.  Requires an additional logic_parser parameter', 'pcfg': 'A probabilistic CFG.', 'pickle': 'A serialized python object, stored using the pickle module.', 'raw': 'The raw (byte string) contents of a file.', 'text': 'The raw (unicode string) contents of a file. ', 'val': 'A semantic valuation, parsed by nltk.sem.Valuation.fromstring.', 'yaml': 'A serialized python object, stored using the yaml module.'}","(None, [])",N/A,N/A,False
clear() → None.  Remove all items from D.,"(None, [])",N/A,N/A,False
"update([E, ]**F) → None.  Update D from dict/iterable E and F.","(None, [])",N/A,N/A,False
class nltk.featstruct.FeatList(features=()),"('nltk.featstruct.FeatList', ['features'])","('FeatList.__init__', ['features'])",nltk\nltk\featstruct.py,True
"class nltk.featstruct.FeatStructReader(features=(*slash*, *type*), fdict_class=, flist_class=, logic_parser=None)","(None, [])",N/A,N/A,False
"class nltk.text.ContextIndex(tokens, context_func=None, filter=None, key=>)","(None, [])",N/A,N/A,False
"class nltk.text.ConcordanceIndex(tokens, key=>)","(None, [])",N/A,N/A,False
"nltk.util.binary_search_file(file, key, cache={}, cacheDepth=-1)","('nltk.util.binary_search_file', ['file', 'key', 'cache', 'cacheDepth'])","('nltk.binary_search_file', {'source_file': 'nltk\\nltk\\util.py', 'req_args': ['key', 'file'], 'opt_args': ['cacheDepth', 'cache']})",nltk\nltk\util.py,True
"nltk.util.breadth_first(tree, children=, maxdepth=-1)","(None, [])",N/A,N/A,False
"nltk.util.everygrams(sequence, min_len=1, max_len=-1, **kwargs)","('nltk.util.everygrams', ['sequence', 'min_len', 'max_len', 'kwargs'])","('nltk.everygrams', {'source_file': 'nltk\\nltk\\util.py', 'req_args': ['sequence'], 'opt_args': ['pad_right', 'pad_left', 'max_len', 'min_len', 'kwargs']})",nltk\nltk\util.py,True
"nltk.util.ngrams(sequence, n, pad_left=False, pad_right=False, left_pad_symbol=None, right_pad_symbol=None)","('nltk.util.ngrams', ['sequence', 'n', 'pad_left', 'pad_right', 'left_pad_symbol', 'right_pad_symbol'])",N/A,N/A,False
nltk.util.py26(),"(None, [])",N/A,N/A,False
nltk.util.py27(),"(None, [])",N/A,N/A,False
nltk.demo(),"(None, [])",N/A,N/A,False
"def choose(n, k):
    """"""
    This function is a fast way to calculate binomial coefficients, commonly
    known as nCk, i.e. the number of combinations of n things taken k at a time. 
    (https://en.wikipedia.org/wiki/Binomial_coefficient).

        >>> choose(4, 2)
        6
        >>> choose(6, 2)
        15

    :param n: The number of things.
    :type n: int
    :param r: The number of times a thing is taken.
    :type r: int
    """"""
    if 0 <= k <= n:
        ntok, ktok = 1, 1
        for t in range(1, min(k, n - k) + 1):
            ntok *= n
            ktok *= t
            n -= 1
        return ntok // ktok
    else:
        return 0","(None, [])",N/A,N/A,False
"import itertools
def choose(n,k):
    return len(list(itertools.combinations(range(n),k)))","(None, [])",N/A,N/A,False
nltk.translate.ribes_score.choose(),"(None, [])",N/A,N/A,False
