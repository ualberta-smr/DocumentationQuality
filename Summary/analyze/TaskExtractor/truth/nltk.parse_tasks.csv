Paragraph,Tasks
"A processing class for deriving trees that represent possible structures for a sequence of tokens. These tree structures are known as “parses”. Typically, parsers are used to derive syntax trees for sentences. But parsers can also be used to derive other kinds of tree structure, such as morphological trees and discourse structures.",Use parser
The grammar used by this parser.,
An iterator that generates parse trees for the sentence.,Generate parse trees
When possible this list is sorted from most likely to least likely.,Sort list
Interface for parsing with BLLIP Parser. BllipParser objects can be constructed with the BllipParser.from_unified_model_dir class method or manually using the BllipParser constructor.,"Use BllipParser constructor
Use BllipParser objects"
Create a BllipParser object from a unified parsing model directory. Unified parsing model directories are a standardized way of storing BLLIP parser and reranker models together on disk. See bllipparser.RerankingParser.get_unified_model_parameters() for more information about unified model directories.,"Create BllipParser object from unified parsing model directory
Store BLLIP parser on disk
Store reranker models on disk"
A BllipParser object using the parser and reranker,"Use parser
Use reranker"
An iterator that generates parse trees for the sentence,Generate parse trees
"Use BLLIP to parse a sentence. Takes a sentence as a list of (word, tag) tuples; the sentence must have already been tokenized and tagged. BLLIP will attempt to use the tags provided but may use others if it can’t come up with a complete parse subject to those constraints. You may also specify a tag as None to leave a token’s tag unconstrained.","Use BLLIP
Specify tag as None"
An iterator that generates parse trees for the sentence,Generate parse trees
"Data classes and parser implementations for “chart parsers”, which use dynamic programming to efficiently parse a text. A chart parser derives parse trees for a text by iteratively adding “edges” to a “chart.” Each edge represents a hypothesis about the tree structure for a subsequence of the text. The chart is a “blackboard” for composing and combining these hypotheses.","Add edges to chart
compose hypotheses
combine hypotheses
Use chart parsers"
"When a chart parser begins parsing a text, it creates a new (empty) chart, spanning the text. It then incrementally adds new edges to the chart. A set of “chart rules” specifies the conditions under which new edges should be added to the chart. Once the chart reaches a stage where none of the chart rules adds any new edges, parsing is complete.","Create new chart
add new edges to chart
specify conditions
add new edges to chart
add conditions to chart
add new edges"
"Charts are encoded with the Chart class, and edges are encoded with the TreeEdge and LeafEdge classes. The chart parser module defines three chart parsers:","Encode charts with Chart class
Encode edges with TreeEdge LeafEdge classes
Define chart parsers"
"ChartParser is a simple and flexible chart parser. Given a set of chart rules, it will apply those rules to the chart until no more edges are added.",Apply rules to chart
SteppingChartParser is a subclass of ChartParser that can be used to step through the parsing process.,Use subclass of ChartParser
"A default implementation for __str__, which returns a name based on the rule’s class name.",Return name
"Return a generator that will add edges licensed by this rule and the given edges to the chart, one at a time. Each time the generator is resumed, it will either add a new edge and yield that edge; or return.","Add edges at time
add edges to chart
add new edge"
edges (list(EdgeI)) – A set of existing edges. The number of edges that should be passed to apply() is specified by the NUM_EDGES class variable.,Specify number of edges
"Return a generator that will add all edges licensed by this rule, given the edges that are currently in the chart, one at a time. Each time the generator is resumed, it will either add a new edge and yield that edge; or return.","Return generator
add edges
add new edge"
A ChartParser using a bottom-up parsing strategy. See ChartParser for more information.,Use bottom-up parsing strategy
A ChartParser using a bottom-up left-corner parsing strategy. This strategy is often more efficient than standard bottom-up. See ChartParser for more information.,Use bottom-up left-corner parsing strategy
"This is like BottomUpPredictRule, but it also applies the FundamentalRule to the resulting edge.",Apply FundamentalRule to resulting edge
"Return a generator that will add edges licensed by this rule and the given edges to the chart, one at a time. Each time the generator is resumed, it will either add a new edge and yield that edge; or return.","Add edges at time
add edges to chart
add new edge"
edges (list(EdgeI)) – A set of existing edges. The number of edges that should be passed to apply() is specified by the NUM_EDGES class variable.,Specify number of edges
"Return a generator that will add edges licensed by this rule and the given edges to the chart, one at a time. Each time the generator is resumed, it will either add a new edge and yield that edge; or return.","Add edges at time
add edges to chart
add new edge"
edges (list(EdgeI)) – A set of existing edges. The number of edges that should be passed to apply() is specified by the NUM_EDGES class variable.,Specify number of edges
"A cached version of TopDownPredictRule. After the first time this rule is applied to an edge with a given end and next, it will not generate any more edges for edges with that end and next.","Apply rule with next
Apply rule with given end
Apply rule to edge"
"If chart or grammar are changed, then the cache is flushed.",Flush cache
"Return a generator that will add edges licensed by this rule and the given edges to the chart, one at a time. Each time the generator is resumed, it will either add a new edge and yield that edge; or return.","Add edges at time
add edges to chart
add new edge"
edges (list(EdgeI)) – A set of existing edges. The number of edges that should be passed to apply() is specified by the NUM_EDGES class variable.,Specify number of edges
"A blackboard for hypotheses about the syntactic constituents of a sentence. A chart contains a set of edges, and each edge encodes a single hypothesis about the structure of some portion of the sentence.",Encode single hypotheses about structure
"The select method can be used to select a specific collection of edges. For example chart.select(is_complete=True, start=0) yields all complete edges whose start indices are 0. To ensure the efficiency of these selection operations, Chart dynamically creates and maintains an index for each set of attributes that have been selected on.","Select specific collection of edges
Use select method
Create index for set"
Return the set of child pointer lists for the given edge. Each child pointer list is a list of edges that have been used to form this edge.,"List fo given edge
Use edges"
Return a list of all edges in this chart. New edges that are added to the chart after the call to edges() will not be contained in this list.,Return list of edges in chart
"Add a new edge to the chart, and return True if this operation modified the chart. In particular, return true iff the chart did not already contain edge, or if it did not already associate child_pointer_lists with edge.","Add new edge to chart
Modify chart"
child_pointer_lists (sequence of tuple(EdgeI)) – A sequence of lists of the edges that were used to form this edge. This list is used to reconstruct the trees (or partial trees) that are associated with edge.,Use sequence of lists
"Add a new edge to the chart, using a pointer to the previous edge.","Add new edge to chart
Use pointer to previous edge"
Return an iterator over the edges in this chart. It is not guaranteed that new edges which are added to the chart before the iterator is exhausted will also be generated.,Return iterator over chart
Return the leaf value of the word at the given index.,Return leaf value of word
Return the number of edges contained in this chart.,Return number of edges
Return a pretty-printed string representation of a given edge in this chart.,Return pretty-printed string representation of given edge
Return a pretty-printed string representation of this chart’s leaves. This string can be used as a header for calls to pretty_format_edge.,Use string to pretty_format_edge
Return an iterator over the edges in this chart. Any new edges that are added to the chart before the iterator is exahusted will also be generated. restrictions can be used to restrict the set of edges that will be generated.,Return iterator over chart
span – Only generate edges e where e.span()==span,Generate edges e
start – Only generate edges e where e.start()==start,Generate edges e
end – Only generate edges e where e.end()==end,Generate edges e
length – Only generate edges e where e.length()==length,Generate edges e
lhs – Only generate edges e where e.lhs()==lhs,Generate edges e
rhs – Only generate edges e where e.rhs()==rhs,Generate edges e
nextsym – Only generate edges e where e.nextsym()==nextsym,Generate edges e
dot – Only generate edges e where e.dot()==dot,Generate edges e
is_complete – Only generate edges e where e.is_complete()==is_complete,Generate edges e
is_incomplete – Only generate edges e where e.is_incomplete()==is_incomplete,Generate edges e
Return an iterator of the tree structures that are associated with edge.,Return iterator of tree structures
"If edge is incomplete, then the unexpanded children will be encoded as childless subtrees, whose node value is the corresponding terminal or nonterminal.",Encoide unexpanded children as childless subtrees
"If two trees share a common subtree, then the same Tree may be used to encode that subtree in both trees. If you need to eliminate this subtree sharing, then create a deep copy of each tree.","Encode subtree in trees
Create deep copy of tree"
"A generic chart parser. A “strategy”, or list of ChartRuleI instances, is used to decide what edges to add to the chart. In particular, ChartParser uses the following algorithm to parse texts:","Use strategy of ChartRuleI instances
Add to chart"
Return the final parse Chart from which all possible parse trees can be extracted.,Return final parse chart
The grammar used by this parser.,
An iterator that generates parse trees for the sentence.,Generate parse trees
When possible this list is sorted from most likely to least likely.,Sort list
"A rule that specifies what new edges are licensed by any given set of existing edges. Each chart rule expects a fixed number of edges, as indicated by the class variable NUM_EDGES. In particular:",Specify rule of existing edges
"A chart rule with NUM_EDGES=0 specifies what new edges are licensed, regardless of existing edges.",Specify regardless of existing edges
"Return a generator that will add edges licensed by this rule and the given edges to the chart, one at a time. Each time the generator is resumed, it will either add a new edge and yield that edge; or return.","Add edges to chart
Add new edge"
edges (list(EdgeI)) – A set of existing edges. The number of edges that should be passed to apply() is specified by the NUM_EDGES class variable.,Specify number of edges
"Return a generator that will add all edges licensed by this rule, given the edges that are currently in the chart, one at a time. Each time the generator is resumed, it will either add a new edge and yield that edge; or return.","Add edges to chart
Add new edge"
"A left-hand side, specifying what kind of structure is hypothesized.",Specify kind of structure
"A right-hand side, specifying the contents of the hypothesized structure.",Specify contents of hypothesized structure
"An edge is incomplete if its structure is partially consistent with the sentence. For every incomplete edge, the span specifies a possible prefix for the edge’s structure.",Specify possible prefix for incomplete edge
A TreeEdge records which trees have been found to be (partially) consistent with the text.,
"The EdgeI interface provides a common interface to both types of edge, allowing chart parsers to treat them in a uniform manner.",
"Return this edge’s dot position, which indicates how much of the hypothesized structure is consistent with the sentence. In particular, self.rhs[:dot] is consistent with tokens[self.start():self.end()].",Return dot position
"Return this edge’s left-hand side, which specifies what kind of structure is hypothesized by this edge.","Return left-hand side
Specify kind of structure"
Return the element of this edge’s right-hand side that immediately follows its dot.,Return element of right-hand side
"Return this edge’s right-hand side, which specifies the content of the structure hypothesized by this edge.","Return right-hand side
Specify content of structure"
"Return a tuple (s, e), where tokens[s:e] is the portion of the sentence that is consistent with this edge’s structure.","Return tuple (s
e)"
"Return a generator that will add edges licensed by this rule and the given edges to the chart, one at a time. Each time the generator is resumed, it will either add a new edge and yield that edge; or return.","Add edges to chart
Add new edge"
edges (list(EdgeI)) – A set of existing edges. The number of edges that should be passed to apply() is specified by the NUM_EDGES class variable.,Specify number of edges
"Return a generator that will add edges licensed by this rule and the given edges to the chart, one at a time. Each time the generator is resumed, it will either add a new edge and yield that edge; or return.","Add edges to chart
Add new edge"
edges (list(EdgeI)) – A set of existing edges. The number of edges that should be passed to apply() is specified by the NUM_EDGES class variable.,Specify number of edges
"Return a generator that will add edges licensed by this rule and the given edges to the chart, one at a time. Each time the generator is resumed, it will either add a new edge and yield that edge; or return.","Add edges to chart
Add new edge"
edges (list(EdgeI)) – A set of existing edges. The number of edges that should be passed to apply() is specified by the NUM_EDGES class variable.,Specify number of edges
"A leaf, specifying the word’s content.",
"Return this edge’s dot position, which indicates how much of the hypothesized structure is consistent with the sentence. In particular, self.rhs[:dot] is consistent with tokens[self.start():self.end()].",Return dot position
"Return this edge’s left-hand side, which specifies what kind of structure is hypothesized by this edge.","Return left-hand side
Specify kind of structure"
Return the element of this edge’s right-hand side that immediately follows its dot.,Return element of right-hand side
"Return this edge’s right-hand side, which specifies the content of the structure hypothesized by this edge.","Return right-hand side
Specify content of structure"
"Return a tuple (s, e), where tokens[s:e] is the portion of the sentence that is consistent with this edge’s structure.","Return tuple (s, e)"
"Return a generator that will add edges licensed by this rule and the given edges to the chart, one at a time. Each time the generator is resumed, it will either add a new edge and yield that edge; or return.","Add edges to chart
Add new edge"
edges (list(EdgeI)) – A set of existing edges. The number of edges that should be passed to apply() is specified by the NUM_EDGES class variable.,Specify number of edges
"A rule that joins a given edge with adjacent edges in the chart, to form combined edges. In particular, this rule specifies that either of the edges:",
"Return a generator that will add edges licensed by this rule and the given edges to the chart, one at a time. Each time the generator is resumed, it will either add a new edge and yield that edge; or return.","Add edges to chart
Add new edge"
edges (list(EdgeI)) – A set of existing edges. The number of edges that should be passed to apply() is specified by the NUM_EDGES class variable.,Specify number of edges
"A ChartParser that allows you to step through the parsing process, adding a single edge at a time. It also allows you to change the parser’s strategy or grammar midway through parsing a text.","Add single edge at time
Change strategy
Change grammar"
The initialize method is used to start parsing a text. step adds a single edge to the chart. set_strategy changes the strategy used by the chart parser. parses returns the set of parses that has been found by the chart parser.,"Add single edge to chart
Change strategy
Return set of parses"
"_restart – Records whether the parser’s strategy, grammar, or chart has been changed. If so, then step must restart the parsing algorithm.","Change strategy
Change chart
Restart parsing algorithm"
Return the chart rule used to generate the most recent edge.,Generate recent edge
Return the grammar used by this parser.,
An iterator that generates parse trees for the sentence.,Generate parse trees
When possible this list is sorted from most likely to least likely.,Sort list
Load a given chart into the chart parser.,Loag given chart into chart parser
Change the grammar used by the parser.,Change grammar
Change the strategy that the parser uses to decide which edges to add to the chart.,"Change strategy
Add to chart"
strategy (list(ChartRuleI)) – A list of rules that should be used to decide what edges to add to the chart.,"Add to chart
Use rules"
"Return a generator that adds edges to the chart, one at a time. Each time the generator is resumed, it adds a single edge and yields that edge. If no more edges can be added, then it yields None.","Add edges to chart
add single edge
add more edges"
"If the parser’s strategy, grammar, or chart is changed, then the generator will continue adding edges using the new strategy, grammar, or chart.","Use new strategy
Use grammar
Use chart
Change strategy
Change Chart"
"Note that this generator never terminates, since the grammar or strategy might be changed to values that would add new edges. Instead, it yields None when no more edges can be added with the current strategy and grammar.",
A ChartParser using a top-down parsing strategy. See ChartParser for more information.,Use top-down parsing strategy
"Return a generator that will add edges licensed by this rule and the given edges to the chart, one at a time. Each time the generator is resumed, it will either add a new edge and yield that edge; or return.","Add edges to chart
Add new edge"
edges (list(EdgeI)) – A set of existing edges. The number of edges that should be passed to apply() is specified by the NUM_EDGES class variable.,Specify number of edges
"Return a generator that will add edges licensed by this rule and the given edges to the chart, one at a time. Each time the generator is resumed, it will either add a new edge and yield that edge; or return.","Add edges to chart
Add new edge"
edges (list(EdgeI)) – A set of existing edges. The number of edges that should be passed to apply() is specified by the NUM_EDGES class variable.,Specify number of edges
"A left-hand side, specifying the hypothesized tree’s node value.",Specify hypothesized tree
"A right-hand side, specifying the hypothesized tree’s children. Each element of the right-hand side is either a terminal, specifying a token with that terminal as its leaf value; or a nonterminal, specifying a subtree with that nonterminal’s symbol as its node value.",Specify hypothesized tree
"Return this edge’s dot position, which indicates how much of the hypothesized structure is consistent with the sentence. In particular, self.rhs[:dot] is consistent with tokens[self.start():self.end()].",Return dot position
"Return this edge’s left-hand side, which specifies what kind of structure is hypothesized by this edge.","Return left-hand side
Specify kind of structure"
"Return a new TreeEdge formed from this edge. The new edge’s dot position is increased by 1, and its end index will be replaced by new_end.",Replace end index
Return the element of this edge’s right-hand side that immediately follows its dot.,Return element of right-hand side
"Return this edge’s right-hand side, which specifies the content of the structure hypothesized by this edge.","Return right-hand side
Specify content of structure"
"Return a tuple (s, e), where tokens[s:e] is the portion of the sentence that is consistent with this edge’s structure.","Return tuple (s, e)"
"stderr (stdout,) – Specifies where CoreNLP output is redirected. Valid values are ‘devnull’, ‘stdout’, ‘pipe’",Redirect CoreNLP output
The text might contain several sentences which will be split by CoreNLP.,Split several sentences
Tools for reading and writing dependency trees. The input is assumed to be in Malt-TAB format (http://stp.lingfil.uu.se/~nivre/research/MaltXML.html).,"Read dependency trees
Write dependency trees "
Adds an arc from the node specified by head_address to the node specified by the mod address.,"Add arc from node
Specify to node"
Fully connects all non-root nodes. All nodes are set to be dependents of the root node.,Set nodes
"Returns true if the graph contains a node with the given node address, false otherwise.",
Return the node with the given address.,Return node with given address
Returns the number of left children under the node specified by the given address.,"Return number of left children
Return number under node"
"rather than 1 (as produced by, e.g., zpar) :param str cell_separator: the cell separator. If not provided, cells are split by whitespace. :param str top_relation_label: the label by which the top relation is identified, for examlple, ROOT, null or TOP.",Split cells
Convert the data in a nodelist into a networkx labeled directed graph.,"Convert data into networkx
Convert data in nodelist"
Removes the node with the given address. References to this node in others will still exist.,Remove node with given address
Returns the number of right children under the node specified by the given address.,"Return number of right children
Return number under node"
"style (int) – the style to use for the format (3, 4, 10 columns)",
Return a dot representation suitable for using with Graphviz.,Use with Graphviz
"Starting with the root node, build a dependency tree using the NLTK Tree constructor. Dependency labels are omitted.","Use NLTK Tree constructor
Omit dependency labels"
A demonstration of how to read a string representation of a CoNLL format dependency tree.,Read string representation of CoNLL
A demonstration of the result of reading a dependency version of the first sentence of the Penn Treebank.,Read dependency version of first sentence
"Data classes and parser implementations for incremental chart parsers, which use dynamic programming to efficiently parse a text. A “chart parser” derives parse trees for a text by iteratively adding “edges” to a “chart”. Each “edge” represents a hypothesis about the tree structure for a subsequence of the text. The “chart” is a “blackboard” for composing and combining these hypotheses.","Use incremental chart parsers
Add edges to chart
Compose hypothesis
Combine hypotheses"
"Return a generator that will add edges licensed by this rule and the given edges to the chart, one at a time. Each time the generator is resumed, it will either add a new edge and yield that edge; or return.","Add edges to chart
Add new edge"
edges (list(EdgeI)) – A set of existing edges. The number of edges that should be passed to apply() is specified by the NUM_EDGES class variable.,Specify new edge
Returns an iterator over the edges in this chart. See Chart.select for more information about the restrictions on the edges.,Return iterator over edges
"Return a generator that will add edges licensed by this rule and the given edges to the chart, one at a time. Each time the generator is resumed, it will either add a new edge and yield that edge; or return.","Add edges to chart
Add new edge"
edges (list(EdgeI)) – A set of existing edges. The number of edges that should be passed to apply() is specified by the NUM_EDGES class variable.,Specify number of edges
Return a list of all edges in this chart. New edges that are added to the chart after the call to edges() will not be contained in this list.,Return list of edges in chart
Return an iterator over the edges in this chart. It is not guaranteed that new edges which are added to the chart before the iterator is exhausted will also be generated.,Return iterator over chart
Return an iterator over the edges in this chart. Any new edges that are added to the chart before the iterator is exahusted will also be generated. restrictions can be used to restrict the set of edges that will be generated.,"Return iterator over edges
Use restrictions"
span – Only generate edges e where e.span()==span,Generate edges e
start – Only generate edges e where e.start()==start,Generate edges e
end – Only generate edges e where e.end()==end,Generate edges e
length – Only generate edges e where e.length()==length,Generate edges e
lhs – Only generate edges e where e.lhs()==lhs,Generate edges e
rhs – Only generate edges e where e.rhs()==rhs,Generate edges e
nextsym – Only generate edges e where e.nextsym()==nextsym,Generate edges e
dot – Only generate edges e where e.dot()==dot,Generate edges e
is_complete – Only generate edges e where e.is_complete()==is_complete,Generate edges e
is_incomplete – Only generate edges e where e.is_incomplete()==is_incomplete,Generate edges e
An incremental chart parser implementing Jay Earley’s parsing algorithm:,
Return the final parse Chart from which all possible parse trees can be extracted.,Return final parse chart
"Return a generator that will add edges licensed by this rule and the given edges to the chart, one at a time. Each time the generator is resumed, it will either add a new edge and yield that edge; or return.","Add edges to chart
Add new edge"
edges (list(EdgeI)) – A set of existing edges. The number of edges that should be passed to apply() is specified by the NUM_EDGES class variable.,Specify number of edges
Class for measuring labelled and unlabelled attachment score for dependency parsing. Note that the evaluation ignores punctuation.,Ignore punctuation
Extension of chart parsing implementation to handle grammars with feature structures as nodes.,Handle grammars with feature structures
"Return a generator that will add edges licensed by this rule and the given edges to the chart, one at a time. Each time the generator is resumed, it will either add a new edge and yield that edge; or return.","Add edges to chart
Add new edge"
edges (list(EdgeI)) – A set of existing edges. The number of edges that should be passed to apply() is specified by the NUM_EDGES class variable.,Specify number of edges
"Return a generator that will add edges licensed by this rule and the given edges to the chart, one at a time. Each time the generator is resumed, it will either add a new edge and yield that edge; or return.","Add edges to chart
Add new edge"
edges (list(EdgeI)) – A set of existing edges. The number of edges that should be passed to apply() is specified by the NUM_EDGES class variable.,Specify number of edges
Returns an iterator over the edges in this chart. See Chart.select for more information about the restrictions on the edges.,Return iterator over edges
"Return a generator that will add edges licensed by this rule and the given edges to the chart, one at a time. Each time the generator is resumed, it will either add a new edge and yield that edge; or return.","Add edges to chart
Add new edge"
edges (list(EdgeI)) – A set of existing edges. The number of edges that should be passed to apply() is specified by the NUM_EDGES class variable.,Specify number of edges
assuming that B1 and B2 can be unified to generate B3.,
"Return a generator that will add edges licensed by this rule and the given edges to the chart, one at a time. Each time the generator is resumed, it will either add a new edge and yield that edge; or return.","Add edges to chart
Add new edge"
edges (list(EdgeI)) – A set of existing edges. The number of edges that should be passed to apply() is specified by the NUM_EDGES class variable.,Specify number of edges
"A specialized version of the completer / single edge fundamental rule that operates on nonterminals whose symbols are ``FeatStructNonterminal``s. Rather than simply comparing the nonterminals for equality, they are unified.",Compare nonterminals for equality
"Return a generator that will add edges licensed by this rule and the given edges to the chart, one at a time. Each time the generator is resumed, it will either add a new edge and yield that edge; or return.","Add edges to chart
Add new edge"
edges (list(EdgeI)) – A set of existing edges. The number of edges that should be passed to apply() is specified by the NUM_EDGES class variable.,Specify number of edges
"A specialized version of the (cached) top down predict rule that operates on nonterminals whose symbols are ``FeatStructNonterminal``s. Rather than simply comparing the nonterminals for equality, they are unified.",Compare nonterminals for equality
The top down expand rule states that:,
"Return a generator that will add edges licensed by this rule and the given edges to the chart, one at a time. Each time the generator is resumed, it will either add a new edge and yield that edge; or return.","Add edges to chart
Add new edge"
edges (list(EdgeI)) – A set of existing edges. The number of edges that should be passed to apply() is specified by the NUM_EDGES class variable.,Specify number of edges
A specialized tree edge that allows shared variable bindings between nonterminals on the left-hand side and right-hand side.,Share variable bindings between nonterminals
"Each FeatureTreeEdge contains a set of bindings, i.e., a dictionary mapping from variables to values. If the edge is not complete, then these bindings are simply stored. However, if the edge is complete, then the constructor applies these bindings to every nonterminal in the edge whose symbol implements the interface SubstituteBindingsI.",Apply  bindings to nonterminal
"A new FeatureTreeEdge formed from this edge. The new edge’s dot position is increased by 1, and its end index will be replaced by new_end.",
The set of variables used by this edge.,
"A specialized chart that ‘instantiates’ variables whose names start with ‘@’, by replacing them with unique new variables. In particular, whenever a complete edge is added to the chart, any variables in the edge’s lhs whose names start with ‘@’ will be replaced by unique new ``Variable``s.",Replace with unique new variables
"Add a new edge to the chart, and return True if this operation modified the chart. In particular, return true iff the chart did not already contain edge, or if it did not already associate child_pointer_lists with edge.","Add new edge to chart
Modify chart"
child_pointer_lists (sequence of tuple(EdgeI)) – A sequence of lists of the edges that were used to form this edge. This list is used to reconstruct the trees (or partial trees) that are associated with edge.,Use sequence of lists
"If the edge is a FeatureTreeEdge, and it is complete, then instantiate all variables whose names start with ‘@’, by replacing them with unique new variables.","Instantiate variables
Replace with unique new variables"
grammar – The Grammar used to generate sentences.,Generate sentences
start – The Nonterminal from which to start generate sentences.,Generate sentences
A class for dependency parsing with MaltParser. The input is the paths to: - a maltparser directory - (optionally) the path to a pre-trained MaltParser .mco model file - (optionally) the tagger to use for POS tagging before parsing - (optionally) additional Java arguments,Use for POS
This function generates the maltparser command use at the terminal.,Generate maltparser command use at terminal
"Use MaltParser to parse multiple sentences. Takes a list of sentences, where each sentence is a list of words. Each sentence will be automatically tagged with this MaltParser instance’s tagger.",Use MaltParser
"Use MaltParser to parse multiple POS tagged sentences. Takes multiple sentences where each sentence is a list of (word, tag) tuples. The sentences must have already been tokenized and tagged.",Use MaltParser
A module to find pre-trained MaltParser model.,Find pre-trained MaltParser model
A module to find MaltParser .jar file and its dependencies.,Find MaltParser
"scored. :rtype: A three-dimensional list of numbers. :return: The score is returned in a multidimensional(3) list, such that the outer-dimension refers to the head, and the inner-dimension refers to the dependencies. For instance, scores[0][1] would reference the list of scores corresponding to arcs from node 0 to node 1. The node’s ‘address’ field can be used to determine its number identification.","Reference list of scores
Determine number identification"
"When used in conjunction with a MaxEntClassifier, each score would correspond to the confidence of a particular edge being classified with the positive training examples.",Use with MaxEntClassifier
"Typically the edges present in the graphs can be used as positive training examples, and the edges not present as negative examples.",
"A scorer for calculated the weights on the edges of a weighted dependency graph. This is used by a ProbabilisticNonprojectiveParser to initialize the edge weights of a DependencyGraph. While typically this would be done by training a binary classifier, any class that can return a multidimensional list representation of the edge weights can implement this interface. As such, it has no necessary fields.","Calculate weights on edges
Initialize edge weights of DependencyGraph
Return multidimensional list representation of edge weights"
"scored. :rtype: A three-dimensional list of numbers. :return: The score is returned in a multidimensional(3) list, such that the outer-dimension refers to the head, and the inner-dimension refers to the dependencies. For instance, scores[0][1] would reference the list of scores corresponding to arcs from node 0 to node 1. The node’s ‘address’ field can be used to determine its number identification.","Reference list of scores
Determine number identification"
"When used in conjunction with a MaxEntClassifier, each score would correspond to the confidence of a particular edge being classified with the positive training examples.",Use with MaxEntClassifier
"Typically the edges present in the graphs can be used as positive training examples, and the edges not present as negative examples.",
"A dependency scorer built around a MaxEnt classifier. In this particular class that classifier is a NaiveBayesClassifier. It uses head-word, head-tag, child-word, and child-tag features for classification.",Use child-tag features
"Converts the graph into a feature-based representation of each edge, and then assigns a score to each based on the confidence of the classifier in assigning it to the positive label. Scores are returned in a multidimensional list.","Convert graph into feature-based representation
Assign score
Assign positive label
Return scores in multidimensional list"
"Trains a NaiveBayesClassifier using the edges present in graphs list as positive examples, the edges not present as negative examples. Uses a feature vector of head-word, head-tag, child-word, and child-tag.","Use edges present list as positive examples
Train NaiveBayesClassifier"
"A non-projective, rule-based, dependency parser. This parser will return the set of all possible non-projective parses based on the word-to-word relations defined in the parser’s dependency grammar, and will allow the branches of the parse tree to cross in order to capture a variety of linguistic phenomena that a projective parser will not.",Return set of possible non-projective parses
"Parses the input tokens with respect to the parser’s grammar. Parsing is accomplished by representing the search-space of possible parses as a fully-connected directed graph. Arcs that would lead to ungrammatical parses are removed and a lattice is constructed of length n, where n is the number of input tokens, to represent all possible grammatical traversals. All possible paths through the lattice are then enumerated to produce the set of non-projective parses.",Produce set of non-projective parses
"Nonprojective dependencies allows for “crossing branches” in the parse tree which is necessary for representing particular linguistic phenomena, or even typical parses in some languages. This parser follows the MST parsing algorithm, outlined in McDonald(2005), which likens the search for the best non-projective parse to finding the maximum spanning tree in a weighted directed graph.",Find maximum spanning tree in weighted directed graph
Returns the source of the best incoming arc to the node with address: node_index,Return source of best incoming arc
"Takes a list of nodes that have been identified to belong to a cycle, and collapses them into on larger node. The arcs of all nodes in the graph must be updated to account for this.","Identify nodes
Collapse list of nodes"
When updating scores the score of the highest-weighted incoming arc is subtracted upon collapse. This returns the correct amount to subtract from that edge.,Update scores
"As nodes are collapsed into others, they are replaced by the new node in the graph, but it’s still necessary to keep track of what these original nodes were. This takes a list of node addresses and replaces any collapsed node addresses with their original addresses.",Replace collapsed node addresses with original addresses
Assigns a score to every edge in the DependencyGraph graph. These scores are generated via the parser’s scorer which was assigned during the training process.,"Assign score to edge
Generate scores via scorer
Assign scorer during training process"
graph (DependencyGraph) – A dependency graph to assign scores to.,Assign scores
Parses a list of tokens in accordance to the MST parsing algorithm for non-projective dependency parses. Assumes that the tokens to be parsed have already been tagged and those tags are provided. Various scoring methods can be used by implementing the DependencyScorerI interface and passing it to the training algorithm.,"Parse list of tokens
Provide tags"
"Trains a DependencyScorerI from a set of DependencyGraph objects, and establishes this as the parser’s scorer. This is used to initialize the scores on a DependencyGraph during the parsing procedure.","Initialize scores during parsing procedure
Initialize scores on DependencyGraph"
dependency_scorer (DependencyScorerI) – A scorer which implements the DependencyScorerI interface.,
Classes and interfaces for associating probabilities with tree structures that represent the internal organization of a text. The probabilistic parser module defines BottomUpProbabilisticChartParser.,
"BottomUpProbabilisticChartParser is an abstract class that implements a bottom-up chart parser for PCFG grammars. It maintains a queue of edges, and adds them to the chart one at a time. The ordering of this queue is based on the probabilities associated with the edges, allowing the parser to expand more likely edges before less likely ones. Each subclass implements a different queue ordering, producing different search strategies. Currently the following subclasses are defined:",Implement bottom-up chart parser for PCFG grammars
InsideChartParser searches edges in decreasing order of their trees’ inside probabilities.,
RandomChartParser searches edges in random order.,
LongestChartParser searches edges in decreasing order of their location’s length.,
"An abstract bottom-up parser for PCFG grammars that uses a Chart to record partial results. BottomUpProbabilisticChartParser maintains a queue of edges that can be added to the chart. This queue is initialized with edges for each token in the text that is being parsed. BottomUpProbabilisticChartParser inserts these edges into the chart one at a time, starting with the most likely edges, and proceeding to less likely edges. For each edge that is added to the chart, it may become possible to insert additional edges into the chart; these are added to the queue. This process continues until enough complete parses have been generated, or until the queue is empty.","Initialize queue with edges
Initialize queue in text
Insert additional edges into chart
Generate complete parses"
The sorting order for the queue is not specified by BottomUpProbabilisticChartParser. Different sorting orders will result in different search strategies. The sorting order for the queue is defined by the method sort_queue; subclasses are required to provide a definition for this method.,Define sorting order for queue
_trace – The level of tracing output that should be generated when parsing a text.,
The grammar used by this parser.,
An iterator that generates parse trees for the sentence.,Generate iterator
When possible this list is sorted from most likely to least likely.,Sort list
"Sort the given queue of Edge objects, placing the edge that should be tried first at the beginning of the queue. This method will be called after each Edge is added to the queue.","Sort given queue of Edge objects
Add edge to queue"
queue (list(Edge)) – The queue of Edge objects to sort. Each edge in this queue is an edge that could be added to the chart by the fundamental rule; but that has not yet been added.,Add edge to chart
chart (Chart) – The chart being used to parse the text. This chart can be used to provide extra information for sorting the queue.,"Provide extra information for sorting
Sort queue"
Set the level of tracing output that should be generated when parsing a text.,Set level of tracing
trace (int) – The trace level. A trace level of 0 will generate no tracing output; and higher trace levels will produce more verbose tracing output.,"Generate tracing output
Produce more verbose"
"A bottom-up parser for PCFG grammars that tries edges in descending order of the inside probabilities of their trees. The “inside probability” of a tree is simply the probability of the entire tree, ignoring its context. In particular, the inside probability of a tree generated by production p with children c[1], c[2], …, c[n] is P(p)P(c[1])P(c[2])…P(c[n]); and the inside probability of a token is 1 if it is present in the text, and 0 if it is absent.",Ignore context
"Sort the given queue of edges, in descending order of the inside probabilities of the edges’ trees.",Sort given queue of edges
queue (list(Edge)) – The queue of Edge objects to sort. Each edge in this queue is an edge that could be added to the chart by the fundamental rule; but that has not yet been added.,
chart (Chart) – The chart being used to parse the text. This chart can be used to provide extra information for sorting the queue.,"Provide extra information for sorting
Sort queue"
"Sort the given queue of Edge objects, placing the edge that should be tried first at the beginning of the queue. This method will be called after each Edge is added to the queue.","Sort given queue of Edge objects
Add edge to queue"
queue (list(Edge)) – The queue of Edge objects to sort. Each edge in this queue is an edge that could be added to the chart by the fundamental rule; but that has not yet been added.,Add edge to chart
chart (Chart) – The chart being used to parse the text. This chart can be used to provide extra information for sorting the queue.,"Provide extra information for sorting
Sort queue"
"Return a generator that will add edges licensed by this rule and the given edges to the chart, one at a time. Each time the generator is resumed, it will either add a new edge and yield that edge; or return.","Add edges to chart
Add new edge"
edges (list(EdgeI)) – A set of existing edges. The number of edges that should be passed to apply() is specified by the NUM_EDGES class variable.,Specify number of edges
"Return a generator that will add edges licensed by this rule and the given edges to the chart, one at a time. Each time the generator is resumed, it will either add a new edge and yield that edge; or return.","Add edges to chart
Add new edge"
edges (list(EdgeI)) – A set of existing edges. The number of edges that should be passed to apply() is specified by the NUM_EDGES class variable.,Specify number of edges
"Return a generator that will add edges licensed by this rule and the given edges to the chart, one at a time. Each time the generator is resumed, it will either add a new edge and yield that edge; or return.","Add edges to chart
Add new edge"
edges (list(EdgeI)) – A set of existing edges. The number of edges that should be passed to apply() is specified by the NUM_EDGES class variable.,Specify number of edges
"Sort the given queue of Edge objects, placing the edge that should be tried first at the beginning of the queue. This method will be called after each Edge is added to the queue.","Sort given queue of Edge objects
Add edge to queue"
queue (list(Edge)) – The queue of Edge objects to sort. Each edge in this queue is an edge that could be added to the chart by the fundamental rule; but that has not yet been added.,Add edge to chart
chart (Chart) – The chart being used to parse the text. This chart can be used to provide extra information for sorting the queue.,"Provide extra information for sorting
sort queue"
"Return a generator that will add edges licensed by this rule and the given edges to the chart, one at a time. Each time the generator is resumed, it will either add a new edge and yield that edge; or return.","Add edges to chart
Add new edge"
edges (list(EdgeI)) – A set of existing edges. The number of edges that should be passed to apply() is specified by the NUM_EDGES class variable.,Specify number of edges
"Sort the given queue of Edge objects, placing the edge that should be tried first at the beginning of the queue. This method will be called after each Edge is added to the queue.","Sort given queue of Edge objects
Add edge to queue"
queue (list(Edge)) – The queue of Edge objects to sort. Each edge in this queue is an edge that could be added to the chart by the fundamental rule; but that has not yet been added.,Add edge to chart
chart (Chart) – The chart being used to parse the text. This chart can be used to provide extra information for sorting the queue.,"Provide extra information for sorting
Sort queue"
"A demonstration of the probabilistic parsers. The user is prompted to select which demo to run, and how many parses should be found; and then each parser is run on the same demo, and a summary of the results are displayed.",
"A cell from the parse chart formed when performing the CYK algorithm. Each cell keeps track of its x and y coordinates (though this will probably be discarded), and a list of spans serving as the cell’s entries.",Perform CYK algorithm
Appends the given span to the list of spans representing the chart cell’s entries.,Append given span to list
"This parser returns the most probable projective parse derived from the probabilistic dependency grammar derived from the train() method. The probabilistic model is an implementation of Eisner’s (1996) Model C, which conditions on head-word, head-tag, child-word, and child-tag. The decoding uses a bottom-up chart-based span concatenation algorithm that’s identical to the one utilized by the rule-based projective parser.","Return probable projective parse
Use bottom-up chart based span concatentation algorithm"
Computes the probability of a dependency graph based on the parser’s probability model (defined by the parser’s statistical dependency grammar).,Compute probability of dependency graph
"Concatenates the two spans in whichever way possible. This includes rightward concatenation (from the leftmost word of the leftmost span to the rightmost word of the rightmost span) and leftward concatenation (vice-versa) between adjacent spans. Unlike Eisner’s presentation of span concatenation, these spans do not share or pivot on a particular word/word-index.",Concatenate spans
Parses the list of tokens subject to the projectivity constraint and the productions in the parser’s grammar. This uses a method similar to the span-concatenation algorithm defined in Eisner (1996). It returns the most probable parse derived from the parser’s probabilistic dependency grammar.,Retrun probable parse
"A projective, rule-based, dependency parser. A ProjectiveDependencyParser is created with a DependencyGrammar, a set of productions specifying word-to-word dependency relations. The parse() method will then return the set of all parses, in tree representation, for a given input sequence of tokens. Each parse must meet the requirements of the both the grammar and the projectivity constraint which specifies that the branches of the dependency tree are not allowed to cross. Alternatively, this can be understood as stating that each parent node and its children in the parse tree form a continuous substring of the input sequence.","Return set in tree representation
Return set of parses
Return set for given input sequence"
"Concatenates the two spans in whichever way possible. This includes rightward concatenation (from the leftmost word of the leftmost span to the rightmost word of the rightmost span) and leftward concatenation (vice-versa) between adjacent spans. Unlike Eisner’s presentation of span concatenation, these spans do not share or pivot on a particular word/word-index.",Concatenate spans
"Performs a projective dependency parse on the list of tokens using a chart-based, span-concatenation algorithm similar to Eisner (1996).",Use chart-based span-concatenation algorithm
A demonstration showing the creation of a DependencyGrammar in which a specific number of modifiers is listed for a given head. This can further constrain the number of possible parses created by a ProjectiveDependencyParser.,List specific number of modifiers
A demo showing the training and use of a projective dependency parser.,Use projective dependency parser
A demonstration showing the creation and use of a DependencyGrammar to perform a projective dependency parse.,"Use of DependencyGrammer
Perform projective dependency parse"
"A simple top-down CFG parser that parses texts by recursively expanding the fringe of a Tree, and matching it against a text.","Expand fringe of tree
Match against text"
RecursiveDescentParser uses a list of tree locations called a “frontier” to remember which subtrees have not yet been expanded and which leaves have not yet been matched against the text. Each tree location consists of a list of child indices specifying the path from the root of the tree to a subtree or a leaf; see the reference documentation for Tree for more information about tree locations.,
"When the parser begins parsing a text, it constructs a tree containing only the start symbol, and a frontier containing the location of the tree’s root node. It then extends the tree to cover the text, using the following recursive procedure:",Extend tree
"If the frontier is empty, and the text is covered by the tree, then return the tree as a possible parse.",Return tree as possible parse
"If the frontier is empty, and the text is not covered by the tree, then return no parses.",
"If the first element of the frontier is a subtree, then use CFG productions to “expand” it. For each applicable production, add the expanded subtree’s children to the frontier, and recursively find all parses that can be generated by the new tree and frontier.",Generate parses
"If the first element of the frontier is a token, then “match” it against the next token from the text. Remove the token from the frontier, and recursively find all parses that can be generated by the new tree and frontier.","Find parses
Generate parses"
The grammar used by this parser.,
An iterator that generates parse trees for the sentence.,
When possible this list is sorted from most likely to least likely.,Sort list
Set the level of tracing output that should be generated when parsing a text.,Set level of tracing
trace (int) – The trace level. A trace level of 0 will generate no tracing output; and higher trace levels will produce more verbose tracing output.,"Generate tracing output
Produce more verbose"
"A RecursiveDescentParser that allows you to step through the parsing process, performing a single operation at a time.",
"The initialize method is used to start parsing a text. expand expands the first element on the frontier using a single CFG production, and match matches the first element on the frontier against the next text token. backtrack undoes the most recent expand or match operation. step performs a single expand, match, or backtrack operation. parses returns the set of parses that have been found by the parser.",Use single CFG production
"_history – A list of (rtext, tree, frontier) tripples, containing the previous states of the parser. This history is used to implement the backtrack operation.",
_tried_e – A record of all productions that have been tried for a given tree. This record is used by expand to perform the next untried production.,
_tried_m – A record of what tokens have been matched for a given tree. This record is used by step to decide whether or not to match a token.,
"Return the parser to its state before the most recent match or expand operation. Calling undo repeatedly return the parser to successively earlier states. If no match or expand operations have been performed, undo will make no changes.",Return parser before most recent match
"Expand the first element of the frontier. In particular, if the first element of the frontier is a subtree whose node type is equal to production’s left hand side, then add a child to that subtree for each element of production’s right hand side. If production is not specified, then use the first untried expandable production. If all expandable productions have been tried, do nothing.",Expand first element of frontier 
"The production used to expand the frontier, if an expansion was performed. If no expansion was performed, return None.","Expand frontier
Perform expansion"
"Start parsing a given text. This sets the parser’s tree to the start symbol, its frontier to the root node, and its remaining text to token['SUBTOKENS'].",
"The token matched, if a match operation was performed. If no match was performed, return None",Perform match operation
An iterator that generates parse trees for the sentence.,
When possible this list is sorted from most likely to least likely.,Sort list
An iterator of the parses that have been found by this parser so far.,
"Perform a single parsing operation. If an untried match is possible, then perform the match, and return the matched token. If an untried expansion is possible, then perform the expansion, and return the production that it is based on. If backtracking is possible, then backtrack, and return True. Otherwise, return None.","Perform single parsing operation
Perform match
Return matched token
Perform expansion
Return production"
None if no operation was performed; a token if a match was performed; a production if an expansion was performed; and True if a backtrack operation was performed.,
A partial structure for the text that is currently being parsed. The elements specified by the frontier have not yet been expanded or matched.,
"A simple bottom-up CFG parser that uses two operations, “shift” and “reduce”, to find a single parse for a text.",Find single parse for text
"ShiftReduceParser maintains a stack, which records the structure of a portion of the text. This stack is a list of strings and Trees that collectively cover a portion of the text. For example, while parsing the sentence “the dog saw the man” with a typical grammar, ShiftReduceParser will produce the following stack, which covers “the dog saw”:",
"ShiftReduceParser attempts to extend the stack to cover the entire text, and to combine the stack elements into a single tree, producing a complete parse for the sentence.","Extend stack 
Combine stack elements into single tree
Produce complete parse for sentence"
"Initially, the stack is empty. It is extended to cover the text, from left to right, by repeatedly applying two operations:",
“shift” moves a token from the beginning of the text to the end of the stack.,
"Often, more than one operation can be performed on a given stack. In this case, ShiftReduceParser uses the following heuristics to decide which operation to perform:",
"If multiple reductions are available, then apply the reduction whose CFG production is listed earliest in the grammar.",
"Note that these heuristics are not guaranteed to choose an operation that leads to a parse of the text. Also, if multiple parses exists, ShiftReduceParser will return at most one of them.",
The grammar used by this parser.,
An iterator that generates parse trees for the sentence.,Generate parse trees
When possible this list is sorted from most likely to least likely.,Sort list
Set the level of tracing output that should be generated when parsing a text.,Set level of tracing
trace (int) – The trace level. A trace level of 0 will generate no tracing output; and higher trace levels will produce more verbose tracing output.,"Generate tracing output
Produce more verbose"
"A ShiftReduceParser that allows you to setp through the parsing process, performing a single operation at a time. It also allows you to change the parser’s grammar midway through parsing a text.",Change grammar
"The initialize method is used to start parsing a text. shift performs a single shift operation, and reduce performs a single reduce operation. step will perform a single reduce operation if possible; otherwise, it will perform a single shift operation. parses returns the set of parses that have been found by the parser.",Perform single shift operation
"_history – A list of (stack, remaining_text) pairs, containing all of the previous states of the parser. This history is used to implement the undo operation.",
Start parsing a given text. This sets the parser’s stack to [] and sets its remaining text to tokens.,
An iterator that generates parse trees for the sentence.,Generate parse trees
When possible this list is sorted from most likely to least likely.,Sort list
An iterator of the parses that have been found by this parser so far.,
"Use production to combine the rightmost stack elements into a single Tree. If production does not match the rightmost stack elements, then do nothing.",
"The production used to reduce the stack, if a reduction was performed. If no reduction was performed, return None.",
"Move a token from the beginning of the remaining text to the end of the stack. If there are no more tokens in the remaining text, then do nothing.",
"Perform a single parsing operation. If a reduction is possible, then perform that reduction, and return the production that it is based on. Otherwise, if a shift is possible, then perform it, and return True. Otherwise, return False.","Perform single parsing operation
Perform reduction"
False if no operation was performed; True if a shift was performed; and the CFG production used to reduce if a reduction was performed.,Perform shift
"Return the parser to its state before the most recent shift or reduce operation. Calling undo repeatedly return the parser to successively earlier states. If no shift or reduce operations have been performed, undo will make no changes.","Return parser before most recent shift
Return parser to state"
"Use StanfordParser to parse multiple sentences. Takes multiple sentences as a list where each sentence is a list of words. Each sentence will be automatically tagged with this StanfordParser instance’s tagger. If whitespaces exists inside a token, then the token will be treated as separate tokens.",['use StanfordParser']
"Use StanfordParser to parse a sentence. Takes a sentence as a string; before parsing, it will be automatically tokenized and tagged by the Stanford Parser.",['use StanfordParser']
Use StanfordParser to parse multiple sentences. Takes multiple sentences as a list of strings. Each sentence will be automatically tokenized and tagged by the Stanford Parser.,['use StanfordParser']
"Use StanfordParser to parse a sentence. Takes a sentence as a list of (word, tag) tuples; the sentence must have already been tokenized and tagged.",['use StanfordParser']
"Use StanfordParser to parse multiple sentences. Takes multiple sentences where each sentence is a list of (word, tag) tuples. The sentences must have already been tokenized and tagged.",['use StanfordParser']
Currently unimplemented because the neural dependency parser (and the StanfordCoreNLP pipeline class) doesn’t support passing in pre- tagged tokens.,
Class for holding configuration which is the partial analysis of the input sentence. The transition based parser aims at finding set of operators that transfer the initial configuration to the terminal configuration.,
Buffer: for storing remaining input words,
Set of arcs: for storing partially built dependency tree,Store build dependency tree
This class also provides a method to represent a configuration as list of features.,
"Extract the set of features for the current configuration. Implement standard features as describe in Table 3.2 (page 31) in Dependency Parsing book by Sandra Kubler, Ryan McDonal, Joakim Nivre. Please note that these features are very basic. :return: list(str)",Extract set of features
"This class defines a set of transition which is applied to a configuration to get another configuration Note that for different parsing algorithm, the transition is different.","Apply set of transition
Apply set to configuration"
Class for transition based parser. Implement 2 algorithms which are “arc-standard” and “arc-eager”,
:param depgraphs : list of DependencyGraph as the training data :type depgraphs : DependencyGraph :param modelfile : file name to save the trained model :type modelfile : str,Save trained model
"###################### Check The Transition ####################### Check the Initialized Configuration >>> print(conf) Stack : [0] Buffer : [1, 2, 3, 4, 5, 6, 7, 8, 9] Arcs : []",
"A. Check the ARC-STANDARD training >>> import tempfile >>> import os >>> input_file = tempfile.NamedTemporaryFile(prefix=’transition_parse.train’, dir=tempfile.gettempdir(), delete=False)",
Check the ARC-EAGER training,
Check the ARC-STANDARD parser,
Unit tests for CFG.,
"The result information is followed by a colon, and then the sentence. Empty lines and lines beginning with a comment char are ignored.",Ignore empty lines
"Load a grammar from a file, and build a parser based on that grammar. The parser depends on the grammar format, and might also depend on properties of the grammar itself.","Build parser
Load grammar from file"
trace (int) – The level of tracing that should be used when parsing a text. 0 will generate no tracing output; and higher numbers will produce more verbose tracing output.,"Generate tracing output
Produce more verbose"
"parser – The class used for parsing; should be ChartParser or a subclass. If None, the class depends on the grammar format.",
"chart_class – The class used for storing the chart; should be Chart or a subclass. Only used for CFGs and feature CFGs. If None, the chart class depends on the grammar format.",Store chart
beam_size (int) – The maximum length for the parser’s edge queue. Only used for probabilistic CFGs.,
load_args – Keyword parameters used when loading the grammar. See data.load for more information.,Load grammar
A module to convert a single POS tagged sentence into CONLL format.,Convert single POS
"A module to convert the a POS tagged document stream (i.e. list of list of tuples, a list of sentences) and yield lines in CONLL format. This module yields one line per word and two newlines for end of sentence.",Convert POS
"A bottom-up PCFG parser that uses dynamic programming to find the single most likely parse for a text. The ViterbiParser parser parses texts by filling in a “most likely constituent table”. This table records the most probable tree representation for any given span and node value. In particular, it has an entry for every start index, end index, and node value, recording the most likely subtree that spans from the start index to the end index, and has the given node value.","Find single likely parse for text
Fill in likely constituent table"
"The ViterbiParser parser fills in this table incrementally. It starts by filling in all entries for constituents that span one element of text (i.e., entries where the end index is one greater than the start index). After it has filled in all table entries for constituents that span one element of text, it fills in the entries for constitutants that span two elements of text. It continues filling in the entries for constituents spanning larger and larger portions of the text, until the entire table has been filled. Finally, it returns the table entry for a constituent spanning the entire text, whose node value is the grammar’s start symbol.",Retrun table entry for constituent
"In order to find the most likely constituent with a given span and node value, the ViterbiParser parser considers all productions that could produce that node value. For each production, it finds all children that collectively cover the span and have the node values specified by the production’s right hand side. If the probability of the tree formed by applying the production to the children is greater than the probability of the current entry in the table, then the table is updated with this new tree.","Find likely consitituent with given span
Find likely consitituent with node value
Apply production to children
Update table with new tree"
_trace – The level of tracing output that should be generated when parsing a text.,
The grammar used by this parser.,
An iterator that generates parse trees for the sentence.,Generate parse trees
When possible this list is sorted from most likely to least likely.,Sort list
Set the level of tracing output that should be generated when parsing a text.,Set level of tracing
trace (int) – The trace level. A trace level of 0 will generate no tracing output; and higher trace levels will produce more verbose tracing output.,"Generate tracing output
Produce more verbose"
"A demonstration of the probabilistic parsers. The user is prompted to select which demo to run, and how many parses should be found; and then each parser is run on the same demo, and a summary of the results are displayed.",
"Classes and interfaces for producing tree structures that represent the internal organization of a text. This task is known as “parsing” the text, and the resulting tree structures are called the text’s “parses”. Typically, the text is a single sentence, and the tree structure represents the syntactic structure of the sentence. However, parsers can also be used in other domains. For example, parsers can be used to derive the morphological structure of the morphemes that make up a word, or to derive the discourse structure for a set of utterances.",
"Sometimes, a single piece of text can be represented by more than one tree structure. Texts represented by more than one tree structure are called “ambiguous” texts. Note that there are actually two ways in which a text can be ambiguous:",
"The parser module defines ParserI, a standard interface for parsing texts; and two simple implementations of that interface, ShiftReduceParser and RecursiveDescentParser. It also contains three sub-modules for specialized kinds of parsing:",
"nltk.parser.chart defines chart parsing, which uses dynamic programming to efficiently parse texts.",Define chart parsing
"nltk.parser.probabilistic defines probabilistic parsing, which associates a probability with each parse.",Define probabilistic parsing
Bases: object,
"at least one of: parse(), parse_sents().",
grammar(),
sent (list(str)) – The sentence to be parsed,
iter(Tree),
list(Tree),
Tree or None,
Apply self.parse() to each element of sents. :rtype: iter(iter(Tree)),
Bases: nltk.parse.api.ParserI,
models in the model directory.,
model_dir (str) – Path to the unified model directory.,
"parser_options – optional dictionary of parser options, see",
"bllipparser.RerankingParser.RerankingParser.load_parser_options() for more information. :type parser_options: dict(str) :param reranker_options: optional dictionary of reranker options, see bllipparser.RerankingParser.RerankingParser.load_reranker_model() for more information. :type reranker_options: dict(str) :rtype: BllipParser",
Use BLLIP Parser to parse a sentence. Takes a sentence as a list of words; it will be automatically tagged with this BLLIP Parser instance’s tagger.,Use BLLIP
from most likely to least likely.,
sentence (list(str)) – The sentence to be parsed,
iter(Tree),
from most likely to least likely.,
"sentence (list(tuple(str, str))) – Input sentence to parse as (word, tag) pairs",
iter(Tree),
Bases: nltk.parse.chart.ChartRuleI,
An abstract base class for chart rules. AbstractChartRule provides:,
A default implementation for apply.,
"A default implementation for apply_everywhere, (Currently, this implementation assumes that ``NUM_EDGES``<=3.)",
iter(EdgeI),
iter(EdgeI),
Bases: nltk.parse.chart.ChartParser,
Bases: nltk.parse.chart.ChartParser,
Bases: nltk.parse.chart.BottomUpPredictRule,
"A rule licensing any edge corresponding to a production whose right-hand side begins with a complete edge’s left-hand side. In particular, this rule specifies that [A -> alpha \*] licenses the edge [B -> A \* beta] for each grammar production B -> A beta.",
iter(EdgeI),
Bases: nltk.parse.chart.AbstractChartRule,
"A rule licensing any edge corresponding to a production whose right-hand side begins with a complete edge’s left-hand side. In particular, this rule specifies that [A -> alpha \*] licenses the edge [B -> \* A beta] for each grammar production B -> A beta.",
iter(EdgeI),
Bases: nltk.parse.chart.TopDownPredictRule,
iter(EdgeI),
Bases: object,
"In order to reconstruct the trees that are represented by an edge, the chart associates each edge with a set of child pointer lists. A child pointer list is a list of the edges that license an edge’s right-hand side.",
_tokens – The sentence that the chart covers.,
_num_leaves – The number of tokens.,
_edges – A list of the edges in the chart,
_edge_to_cpls – A dictionary mapping each edge to a set of child pointer lists that are associated with that edge.,
"_indexes – A dictionary mapping tuples of edge attributes to indices, where each index maps the corresponding edge attribute values to lists of edges.",
list(list(EdgeI)),
list(EdgeI),
"iteredges, select",
Clear the chart.,Clear chart
edge (EdgeI) – The new edge,
bool,
iter(EdgeI),
"edges, select",
str,
Return a list of the leaf values of each word in the chart’s sentence.,Return list of leaf values
list(str),
int,
Return the number of words in this chart’s sentence.,
int,
"Return an iterator of the complete tree structures that span the entire chart, and whose root node is root.",Return iterator of tree structure
Return a pretty-printed string representation of this chart.,Return pretty-print representation of chart
width – The number of characters allotted to each index in the sentence.,
str,
str,
width – The number of characters allotted to each index in the sentence.,
iter(EdgeI),
list(Tree),
Bases: nltk.parse.api.ParserI,
tokens (list(str)) – The sentence to be parsed,
Chart,
sent (list(str)) – The sentence to be parsed,
iter(Tree),
Bases: object,
A chart rule with NUM_EDGES=1 specifies what new edges are licensed by a single existing edge.,Specify by single edge
A chart rule with NUM_EDGES=2 specifies what new edges are licensed by a pair of existing edges.,Specify by pair of edges
"NUM_EDGES – The number of existing edges that this rule uses to license new edges. Typically, this number ranges from zero to two.",
iter(EdgeI),
iter(EdgeI),
Bases: object,
A hypothesis about the structure of part of a sentence. Each edge records the fact that a structure is (partially) consistent with the sentence. An edge contains:,
"A span, indicating what part of the sentence is consistent with the hypothesized structure.",
"A dot position, indicating how much of the hypothesized structure is consistent with the sentence.",
Every edge is either complete or incomplete:,
An edge is complete if its structure is fully consistent with the sentence.,
There are two kinds of edge:,
A LeafEdge records the tokens occurring in the text.,
int,
Return the end index of this edge’s span.,Return end index
int,
Return True if this edge’s structure is fully consistent with the text.,
bool,
Return True if this edge’s structure is partially consistent with the text.,
bool,
Return the length of this edge’s span.,Return edge span length
int,
TreeEdge and LeafEdge for a description of the left-hand side values for each edge type.,
Nonterminal or terminal or None,
TreeEdge and LeafEdge for a description of the right-hand side values for each edge type.,
"tuple(int, int)",
Return the start index of this edge’s span.,Return start index
int,
Bases: nltk.parse.chart.AbstractChartRule,
"A rule that inserts all empty productions as passive edges, in every position in the chart.",
iter(EdgeI),
Bases: nltk.parse.chart.BottomUpPredictCombineRule,
iter(EdgeI),
Bases: nltk.parse.chart.SingleEdgeFundamentalRule,
Bases: nltk.parse.chart.AbstractChartRule,
"A rule that joins two adjacent edges to form a single combined edge. In particular, this rule specifies that any pair of edges",
[A -> alpha \* B beta][i:j],
[B -> gamma \*][j:k],
licenses the edge:,
[A -> alpha B * beta][i:j],
iter(EdgeI),
Bases: nltk.parse.chart.EdgeI,
An edge that records the fact that a leaf value is consistent with a word in the sentence. A leaf edge consists of:,
"An index, indicating the position of the word.",
"A leaf edge’s left-hand side is its leaf value, and its right hand side is (). Its span is [index, index+1], and its dot position is 0.",
int,
Return the end index of this edge’s span.,Return end index
int,
Return True if this edge’s structure is fully consistent with the text.,
bool,
Return True if this edge’s structure is partially consistent with the text.,
bool,
Return the length of this edge’s span.,Return edge span length
int,
TreeEdge and LeafEdge for a description of the left-hand side values for each edge type.,
Nonterminal or terminal or None,
TreeEdge and LeafEdge for a description of the right-hand side values for each edge type.,
"tuple(int, int)",
Return the start index of this edge’s span.,Return start index
int,
Bases: nltk.parse.chart.AbstractChartRule,
iter(EdgeI),
Bases: nltk.parse.chart.ChartParser,
Bases: nltk.parse.chart.FundamentalRule,
[A -> alpha \* B beta][i:j],
[B -> gamma \*][j:k],
licenses the edge:,
[A -> alpha B * beta][i:j],
if the other edge is already in the chart.,
"This is basically FundamentalRule, with one edge left unspecified.",
iter(EdgeI),
Bases: nltk.parse.chart.ChartParser,
Return the chart that is used by this parser.,
Begin parsing the given tokens.,
sent (list(str)) – The sentence to be parsed,
iter(Tree),
Return the parse trees currently contained in the chart.,
Return the strategy used by this parser.,
Bases: nltk.parse.chart.ChartParser,
Bases: nltk.parse.chart.AbstractChartRule,
"A rule licensing edges corresponding to the grammar productions for the grammar’s start symbol. In particular, this rule specifies that [S -> \* alpha][0:i] is licensed for each grammar production S -> alpha, where S is the grammar’s start symbol.",
iter(EdgeI),
Bases: nltk.parse.chart.AbstractChartRule,
"A rule licensing edges corresponding to the grammar productions for the nonterminal following an incomplete edge’s dot. In particular, this rule specifies that [A -> alpha \* B beta][i:j] licenses the edge [B -> \* gamma][j:j] for each grammar production B -> gamma.",
This rule corresponds to the Predictor Rule in Earley parsing.,
iter(EdgeI),
Bases: nltk.parse.chart.EdgeI,
An edge that records the fact that a tree is (partially) consistent with the sentence. A tree edge consists of:,
"A span, indicating what part of the sentence is consistent with the hypothesized tree.",
"A dot position, indicating which children are consistent with part of the sentence. In particular, if dot is the dot position, rhs is the right-hand size, (start,end) is the span, and sentence is the list of tokens in the sentence, then tokens[start:end] can be spanned by the children specified by rhs[:dot].",
"For more information about edges, see the EdgeI interface.",
int,
Return the end index of this edge’s span.,Return end index
int,
"Return a new TreeEdge formed from the given production. The new edge’s left-hand side and right-hand side will be taken from production; its span will be (index,index); and its dot position will be 0.",
TreeEdge,
Return True if this edge’s structure is fully consistent with the text.,
bool,
Return True if this edge’s structure is partially consistent with the text.,
bool,
Return the length of this edge’s span.,Return edge span length
int,
TreeEdge and LeafEdge for a description of the left-hand side values for each edge type.,
new_end (int) – The new end index.,
TreeEdge,
Nonterminal or terminal or None,
TreeEdge and LeafEdge for a description of the right-hand side values for each edge type.,
"tuple(int, int)",
Return the start index of this edge’s span.,Return start index
int,
A demonstration of the chart parsers.,
Bases: nltk.parse.corenlp.GenericCoreNLPParser,
Dependency parser.,
Non-breaking space inside of a token.,
Phone numbers.,
Bases: nltk.parse.corenlp.GenericCoreNLPParser,
Bases: object,
Starts the CoreNLP server,
Bases: OSError,
Exceptions associated with the Core NLP server.,
"Bases: nltk.parse.api.ParserI, nltk.tokenize.api.TokenizerI, nltk.tag.api.TaggerI",
Interface to the CoreNLP Parser.,
Parse multiple sentences.,
Takes multiple sentences as a list where each sentence is a list of words. Each sentence will be automatically tagged with this CoreNLPParser instance’s tagger.,
"If a whitespace exists inside a token, then the token will be treated as several tokens.",
sentences (list(list(str))) – Input sentences to parse,
iter(iter(Tree)),
Parse a piece of text.,
text (str) – text to be split.,
an iterable of syntactic structures. # TODO: should it be an iterable of iterables?,
Parse a sentence.,
"Takes a sentence as a string; before parsing, it will be automatically tokenized and tagged by the CoreNLP Parser.","Tokenize sentences
Tag sentence"
sentence (str) – Input sentence to parse,
iter(Tree),
Parse multiple sentences.,
Takes multiple sentences as a list of strings. Each sentence will be automatically tokenized and tagged.,"Tokenize sentences
Tag sentence"
sentences (list(str)) – Input sentences to parse.,
iter(iter(Tree)),
Tag multiple sentences.,
Takes multiple sentences as a list where each sentence is a string.,
sentences (list(str)) – Input sentences to tag,
"list(list(list(tuple(str, str)))",
Tag a list of tokens.,
"list(tuple(str, str))",
Tag multiple sentences.,
Takes multiple sentences as a list where each sentence is a list of tokens.,
sentences (list(list(str))) – Input sentences to tag,
"list(list(tuple(str, str))",
Tokenize a string of text.,
Bases: object,
A container for the nodes and labelled edges of a dependency structure.,
Check whether there are cycles.,Check cycles
filename – a name of a file in Malt-TAB format,
zero_based – nodes in the input file are numbered starting from 0,
a list of DependencyGraphs,
Redirects arcs to any of the nodes in the originals list to the redirect node address.,Redirect node arcs
The dependency graph in CoNLL format.,
str,
"Extract dependency triples of the form: ((head word, head tag), rel, (dep word, dep tag))",Extract dependency triples
Bases: Exception,
Dependency graph exception.,
"A parser is “incremental”, if it guarantees that for all i, j where i < j, all edges ending at i are built before any edges ending at j. This is appealing for, say, speech recognizer hypothesis filtering.",
"The main parser class is EarleyChartParser, which is a top-down algorithm, originally formulated by Jay Earley (1970).",
Bases: nltk.parse.chart.SingleEdgeFundamentalRule,
Bases: nltk.parse.earleychart.CompleteFundamentalRule,
iter(EdgeI),
Bases: nltk.parse.earleychart.IncrementalChartParser,
Bases: nltk.parse.featurechart.FeatureSingleEdgeFundamentalRule,
Bases: nltk.parse.earleychart.CompleterRule,
Bases: nltk.parse.earleychart.FeatureIncrementalChartParser,
Bases: nltk.parse.earleychart.FeatureIncrementalChartParser,
Bases: nltk.parse.earleychart.FeatureIncrementalChartParser,
"Bases: nltk.parse.earleychart.IncrementalChart, nltk.parse.featurechart.FeatureChart",
"Bases: nltk.parse.earleychart.IncrementalChartParser, nltk.parse.featurechart.FeatureChartParser",
Bases: nltk.parse.earleychart.FeatureIncrementalChartParser,
Bases: nltk.parse.featurechart.FeatureTopDownPredictRule,
Bases: nltk.parse.earleychart.ScannerRule,
Bases: nltk.parse.chart.FilteredSingleEdgeFundamentalRule,
iter(EdgeI),
Bases: nltk.parse.earleychart.IncrementalChartParser,
Bases: nltk.parse.earleychart.IncrementalChartParser,
Bases: nltk.parse.chart.Chart,
list(EdgeI),
"iteredges, select",
Clear the chart.,Clear chart
iter(EdgeI),
"edges, select",
iter(EdgeI),
Bases: nltk.parse.chart.ChartParser,
tokens (list(str)) – The sentence to be parsed,
Chart,
Bases: nltk.parse.earleychart.IncrementalChartParser,
Bases: nltk.parse.earleychart.IncrementalChartParser,
Bases: nltk.parse.chart.CachedTopDownPredictRule,
Bases: nltk.parse.earleychart.CompleteFundamentalRule,
iter(EdgeI),
A demonstration of the Earley parsers.,
Bases: object,
Return the Labeled Attachment Score (LAS) and Unlabeled Attachment Score (UAS),"Return labeled attachment score
Return unlabeled attachment score"
":return : tuple(float,float)",
Bases: nltk.parse.featurechart.FeatureChartParser,
Bases: nltk.parse.featurechart.FeatureChartParser,
Bases: nltk.parse.chart.BottomUpPredictCombineRule,
iter(EdgeI),
Bases: nltk.parse.chart.BottomUpPredictRule,
iter(EdgeI),
Bases: nltk.parse.chart.Chart,
A Chart for feature grammars. :see: Chart for more information.,
"Return an iterator of the complete tree structures that span the entire chart, and whose root node is root.",Return iterator of tree structure
Bases: nltk.parse.chart.ChartParser,
Bases: nltk.parse.chart.EmptyPredictRule,
iter(EdgeI),
Bases: nltk.parse.chart.FundamentalRule,
"A specialized version of the fundamental rule that operates on nonterminals whose symbols are FeatStructNonterminal``s.  Rather tha simply comparing the nonterminals for equality, they are unified.  Variable bindings from these unifications are collected and stored in the chart using a ``FeatureTreeEdge. When a complete edge is generated, these bindings are applied to all nonterminals in the edge.",
The fundamental rule states that:,
[A -> alpha \* B1 beta][i:j],
[B2 -> gamma \*][j:k],
licenses the edge:,
[A -> alpha B3 \* beta][i:j],
iter(EdgeI),
Bases: nltk.parse.chart.SingleEdgeFundamentalRule,
Bases: nltk.parse.featurechart.FeatureChartParser,
Bases: nltk.parse.chart.TopDownInitRule,
iter(EdgeI),
Bases: nltk.parse.chart.CachedTopDownPredictRule,
[A -> alpha \* B1 beta][i:j],
licenses the edge:,
[B2 -> \* gamma][j:j],
"for each grammar production B2 -> gamma, assuming that B1 and B2 can be unified.",
iter(EdgeI),
Bases: nltk.parse.chart.TreeEdge,
Return a copy of this edge’s bindings dictionary.,Return edge bindings
"A new TreeEdge formed from the given production. The new edge’s left-hand side and right-hand side will be taken from production; its span will be (index,index); and its dot position will be 0.",
TreeEdge,
FeatureTreeEdge,
new_end (int) – The new end index.,
bindings (dict) – Bindings for the new edge.,
set(Variable),
Bases: nltk.parse.featurechart.FeatureChart,
Clear the chart.,
edge (EdgeI) – The new edge,
bool,
"Note that instantiation is done in-place, since the parsing algorithms might already hold a reference to the edge for future use.",
Generates an iterator of all sentences from a CFG.,
depth – The maximal depth of the generated tree.,
n – The maximum number of sentences to return.,
An iterator of lists of terminal tokens.,
Bases: nltk.parse.api.ParserI,
inputfilename (str) – path to the input file,
outputfilename (str) – path to the output file,
sentences – Input sentences to parse,
iter(DependencyGraph),
sentences – Input sentences to parse,
iter(iter(DependencyGraph)) the dependency graph,
representation of each sentence,
Train MaltParser from a list of DependencyGraph objects,Train MaltParser
depgraphs (DependencyGraph) – list of DependencyGraph objects for training input data,
Train MaltParser from a file :param conll_file: str for the filename of the training input data :type conll_file: str,Train MaltParser
Bases: nltk.parse.nonprojectivedependencyparser.DependencyScorerI,
graph (DependencyGraph) – A dependency graph whose set of edges need to be,
"For further illustration, a score list corresponding to Fig.2 of Keith Hall’s ‘K-best Spanning Tree Parsing’ paper:",
"[[], [], [11], [4]], [[], [10], [], [5]], [[], [8], [8], []]]",
graphs (list(DependencyGraph)) – A list of dependency graphs to train the scorer.,
Bases: object,
graph (DependencyGraph) – A dependency graph whose set of edges need to be,
"For further illustration, a score list corresponding to Fig.2 of Keith Hall’s ‘K-best Spanning Tree Parsing’ paper:",
"[[], [], [11], [4]], [[], [10], [], [5]], [[], [8], [8], []]]",
graphs (list(DependencyGraph)) – A list of dependency graphs to train the scorer.,
Bases: nltk.parse.nonprojectivedependencyparser.DependencyScorerI,
graph (DependencyGraph) – A dependency graph to score.,
3 dimensional list,
Edge scores for the graph parameter.,
graphs (list(DependencyGraph)) – A list of dependency graphs to train the scorer.,
Bases: object,
param tokens: A list of tokens to parse. type tokens: list(str) return: An iterator of non-projective parses. rtype: iter(DependencyGraph),
Bases: object,
A probabilistic non-projective dependency parser.,
"node_index (integer.) – The address of the ‘destination’ node,",
the node that is arced to.,
new_node (Node.) – A Node (Dictionary) to collapse the cycle nodes into.,
"cycle_path (A list of integers.) – A list of node addresses, each of which is in the cycle.",
"b_graph, c_graph (g_graph,) – Graphs which need to be updated.",
column_index (integer.) – A index representing the column of incoming arcs,
to a particular node being updated :type cycle_indexes: A list of integers. :param cycle_indexes: Only arcs from cycle nodes are considered. This is a list of such nodes addresses.,
new_indexes (A list of integers.) – A list of node addresses to check for,
subsumed nodes.,
tokens (list(str)) – A list of words or punctuation to be parsed.,
tags (list(str)) – A list of tags corresponding by index to the words in the tokens list.,
An iterator of non-projective parses.,
iter(DependencyGraph),
graphs (list(DependencyGraph)) – A list of dependency graphs to train the scorer.,
Updates the edge scores to reflect a collapse operation into new_node.,
new_node (A Node.) – The node which cycle nodes are collapsed into.,
cycle_path (A list of integers.) – A list of node addresses that belong to the cycle.,
"The BottomUpProbabilisticChartParser constructor has an optional argument beam_size. If non-zero, this controls the size of the beam (aka the edge queue). This option is most useful with InsideChartParser.",
Bases: nltk.parse.api.ParserI,
_grammar – The grammar used to parse sentences.,
sent (list(str)) – The sentence to be parsed,
iter(Tree),
None,
None,
Bases: nltk.parse.pchart.BottomUpProbabilisticChartParser,
This sorting order results in a type of lowest-cost-first search strategy.,
None,
Bases: nltk.parse.pchart.BottomUpProbabilisticChartParser,
A bottom-up parser for PCFG grammars that tries longer edges before shorter ones. This sorting order results in a type of best-first search strategy.,
None,
Bases: nltk.parse.chart.AbstractChartRule,
iter(EdgeI),
Bases: nltk.parse.chart.AbstractChartRule,
iter(EdgeI),
Bases: nltk.parse.chart.AbstractChartRule,
iter(EdgeI),
Bases: nltk.parse.chart.LeafEdge,
Bases: nltk.parse.chart.TreeEdge,
"Return a new TreeEdge formed from the given production. The new edge’s left-hand side and right-hand side will be taken from production; its span will be (index,index); and its dot position will be 0.",Return TreeEdge
TreeEdge,
Bases: nltk.parse.pchart.BottomUpProbabilisticChartParser,
A bottom-up parser for PCFG grammars that tries edges in random order. This sorting order results in a random search strategy.,
None,
Bases: nltk.parse.chart.AbstractChartRule,
iter(EdgeI),
Bases: nltk.parse.pchart.BottomUpProbabilisticChartParser,
A bottom-up parser for PCFG grammars that tries edges in whatever order.,
None,
Bases: object,
span (DependencySpan) – The span to add.,
Bases: object,
"A contiguous span over some part of the input string representing dependency (head -> modifier) relationships amongst words. An atomic span corresponds to only one word so it isn’t a ‘span’ in the conventional sense, as its _start_index = _end_index = _head_index for concatenation purposes. All other spans are assumed to have arcs between all nodes within the start and end indexes of the span, and one head index corresponding to the head word for the entire span. This is the same as the root node if the dependency structure were depicted as a graph.",
An value indexing the head of the entire DependencySpan.,
int,
Bases: object,
"A probabilistic, projective dependency parser.",
dg (DependencyGraph) – A dependency graph to score.,
The probability of the dependency graph.,
int,
A list of new spans formed through concatenation.,
list(DependencySpan),
"Trains a ProbabilisticDependencyGrammar based on the list of input DependencyGraphs. This model is an implementation of Eisner’s (1996) Model C, which derives its statistics from head-word, head-tag, child-word, and child-tag relationships.",
graphs – A list of dependency graphs to train from.,
list(DependencyGraph),
Bases: object,
A list of new spans formed through concatenation.,
list(DependencySpan),
tokens (list(str)) – The list of input tokens.,
An iterator over parse trees.,
iter(Tree),
Bases: nltk.parse.api.ParserI,
nltk.grammar,
sent (list(str)) – The sentence to be parsed,
iter(Tree),
None,
Bases: nltk.parse.recursivedescent.RecursiveDescentParser,
nltk.grammar,
true if an operation was successfully undone.,
bool,
Whether the parser’s current state represents a complete parse.,
bool,
Production or None,
A list of all the productions for which expansions are available for the current parser state.,
list(Production),
"A list of the tree locations of all subtrees that have not yet been expanded, and all leaves that have not yet been matched.",
list(tuple(int)),
"Match the first element of the frontier. In particular, if the first element of the frontier has the same type as the next text token, then substitute the text token into the tree.",
str or None,
sent (list(str)) – The sentence to be parsed,
iter(Tree),
list of Tree,
The portion of the text that is not yet covered by the tree.,
list(str),
Change the grammar used to parse texts.,
grammar (CFG) – The new grammar.,
Production or String or bool,
Tree,
A list of all the untried productions for which expansions are available for the current parser state.,
list(Production),
Whether the first element of the frontier is a token that has not yet been matched.,
bool,
A demonstration of the recursive descent parser.,
Bases: nltk.parse.api.ParserI,
“reduce” uses a CFG production to combine the rightmost stack elements into a single Tree.,
Only shift if no reductions are available.,
nltk.grammar,
sent (list(str)) – The sentence to be parsed,
iter(Tree),
None,
Bases: nltk.parse.shiftreduce.ShiftReduceParser,
nltk.grammar,
sent (list(str)) – The sentence to be parsed,
iter(Tree),
iter(Tree),
Production or None,
A list of the productions for which reductions are available for the current parser state.,
list(Production),
The portion of the text that is not yet covered by the stack.,
list(str),
Change the grammar used to parse texts.,
grammar (CFG) – The new grammar.,
True if the shift operation was successful.,
bool,
The parser’s stack.,
list(str and Tree),
Production or bool,
true if an operation was successfully undone.,
bool,
A demonstration of the shift-reduce parser.,
Bases: nltk.parse.api.ParserI,
Interface to the Stanford Parser,
sentences (list(list(str))) – Input sentences to parse,
iter(iter(Tree)),
sentence (str) – Input sentence to parse,
iter(Tree),
sentences (list(str)) – Input sentences to parse,
iter(iter(Tree)),
"sentence (list(tuple(str, str))) – Input sentence to parse",
iter(Tree),
"sentences (list(list(tuple(str, str)))) – Input sentences to parse",
iter(iter(Tree)),
Bases: nltk.parse.stanford.GenericStanfordParser,
Bases: nltk.parse.stanford.GenericStanfordParser,
Bases: nltk.parse.stanford.GenericStanfordParser,
Bases: object,
Stack: for storing partially proceeded words,
Bases: object,
is the current configuration,
:return : A new configuration or -1 if the pre-condition is not satisfied,
is the current configuration,
:return : A new configuration or -1 if the pre-condition is not satisfied,
is the current configuration,
:return : A new configuration or -1 if the pre-condition is not satisfied,
is the current configuration,
:return : A new configuration or -1 if the pre-condition is not satisfied,
Bases: nltk.parse.api.ParserI,
"depgraphs (list(DependencyGraph)) – the list of test sentence, each sentence is represented as a dependency graph where the ‘head’ information is dummy",
modelfile (str) – the model file,
list (DependencyGraph) with the ‘head’ and ‘rel’ information,
###################### Check the Initial Feature ########################,
Do some transition checks for ARC-STANDARD,
"Middle Configuration and Features Check >>> print(conf) Stack : [0, 3, 5, 6] Buffer : [8, 9] Arcs : [(2, ‘ATT’, 1), (3, ‘SBJ’, 2), (5, ‘ATT’, 4), (8, ‘ATT’, 7)]",
"Terminated Configuration Check >>> print(conf) Stack : [0] Buffer : [] Arcs : [(2, ‘ATT’, 1), (3, ‘SBJ’, 2), (5, ‘ATT’, 4), (8, ‘ATT’, 7), (6, ‘PC’, 8), (5, ‘ATT’, 6), (3, ‘OBJ’, 5), (3, ‘PU’, 9), (0, ‘ROOT’, 3)]",
Do some transition checks for ARC-EAGER,
###################### Check The Training Function #######################,
###################### Check The Parsing Function ########################,
"B. Check the ARC-EAGER parser >>> result = parser_eager.parse([gold_sent], ‘temp.arceager.model’) >>> de = DependencyEvaluator(result, [gold_sent]) >>> de.eval() >= (0, 0) True",
Remove test temporary files >>> remove(‘temp.arceager.model’) >>> remove(‘temp.arcstd.model’),
Note that result is very poor because of only one training example.,
Utility functions for parsers.,
Bases: object,
grammatical (accept) and,
ungrammatical (reject).,
"If a sentence should parse accordng to the grammar, the value of trees will be a non-empty list. If a sentence should be rejected according to the grammar, then the value of trees will be None.",
Parses a string with one test sentence per line. Lines can optionally begin with:,
"a bool, saying if the sentence is grammatical or not, or",
"an int, giving the number of parse trees is should have,",
"a list of tuple of sentences and expected results, where a sentence is a list of str, and a result is None, or bool, or int",
comment_chars – str of possible comment characters.,
"encoding – the encoding of the string, if it is binary",
cfg' (CFGs: CFG),
pcfg' (probabilistic CFGs: PCFG),
fcfg' (feature-based CFGs: FeatureGrammar),
"grammar_url (str) – A URL specifying where the grammar is located. The default protocol is """"nltk:"""", which searches for the file in the the NLTK data package.",
"sentence (list(tuple(str, str))) – A single input sentence to parse",
iter(str),
a generator yielding a single sentence in CONLL format.,
sentences – Input sentences to parse,
iter(str),
a generator yielding sentences in CONLL format.,
Bases: nltk.parse.api.ParserI,
A pseudo-code description of the algorithm used by ViterbiParser is:,
_grammar – The grammar used to parse sentences.,
sent (list(str)) – The sentence to be parsed,
iter(Tree),
None,
NLTK Parsers,
The text has multiple correct parses.,
There is not enough information to decide which of several candidate parses is correct.,
"However, the parser module does not distinguish these two types of ambiguity.",
"A specialized version of the fundamental rule that operates on nonterminals whose symbols are FeatStructNonterminal``s.  Rather tha simply comparing the nonterminals for equality, they are unified.  Variable bindings from these unifications are collected and stored in the chart using a ``FeatureTreeEdge. When a complete edge is generated, these bindings are applied to all nonterminals in the edge.","Compare nonterminals for equality
Store variable bindings from unifications
Apply bindings to nonterminals"
"grammar_url (str) – A URL specifying where the grammar is located. The default protocol is ""nltk:"", which searches for the file in the the NLTK data package.",
