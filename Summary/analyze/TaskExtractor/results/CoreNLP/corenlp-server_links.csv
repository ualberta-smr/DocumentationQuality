Paragraph,Example,Page
"Stanford CoreNLP ships with a built-in server, which requires only the CoreNLP dependencies. To run this server, simply run:","# Run the server using all jars in the current directory (e.g., the CoreNLP home directory)
java -mx4g -cp ""*"" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 15000",https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
"If you want to process non-English languages, use this command with the appropriate language properties:","# Run a server using Chinese properties
java -Xmx4g -cp ""*"" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -serverProperties StanfordCoreNLP-chinese.properties -port 9000 -timeout 15000",https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
"If no value for port is provided, port 9000 will be used by default. You can then test your server by visiting",http://localhost:9000/,https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
"You should see a website similar to corenlp.run, with an input box for text and a list of annotators you can run. From this interface, you can test out each of the annotators by adding/removing them from this list. (Note: The first use will be slow to respond while models are loaded – it might take 30 seconds or so, but after that the server should run quite quickly.) You can test out the API by sending a POST request to the server with the appropriate properties. An easy way to do this is with wget. The following will annotate the sentence “the quick brown fox jumped over the lazy dog” with part of speech tags:","wget --post-data 'The quick brown fox jumped over the lazy dog.' 'localhost:9000/?properties={""annotators"":""tokenize,ssplit,pos"",""outputFormat"":""json""}' -O -",https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
"You should see a website similar to corenlp.run, with an input box for text and a list of annotators you can run. From this interface, you can test out each of the annotators by adding/removing them from this list. (Note: The first use will be slow to respond while models are loaded – it might take 30 seconds or so, but after that the server should run quite quickly.) You can test out the API by sending a POST request to the server with the appropriate properties. An easy way to do this is with wget. The following will annotate the sentence “the quick brown fox jumped over the lazy dog” with part of speech tags:","wget --post-data 'The quick brown fox jumped over the lazy dog.' 'http://[::]:9000/?properties={""annotators"":""tokenize,ssplit,pos"",""outputFormat"":""json""}' -O -",https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
"You should see a website similar to corenlp.run, with an input box for text and a list of annotators you can run. From this interface, you can test out each of the annotators by adding/removing them from this list. (Note: The first use will be slow to respond while models are loaded – it might take 30 seconds or so, but after that the server should run quite quickly.) You can test out the API by sending a POST request to the server with the appropriate properties. An easy way to do this is with wget. The following will annotate the sentence “the quick brown fox jumped over the lazy dog” with part of speech tags:",curl --data 'The quick brown fox jumped over the lazy dog.' 'http://localhost:9000/?properties={%22annotators%22%3A%22tokenize%2Cssplit%2Cpos%22%2C%22outputFormat%22%3A%22json%22}' -o -,https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
"Or finally, here’s a minimal Python program that interfaces with this endpoint using the requests library:","import requests
print(requests.post('http://[::]:9000/?properties={""annotators"":""tokenize,ssplit,pos"",""outputFormat"":""json""}', data = {'data':'The quick brown fox jumped over the lazy dog.'}).text)",https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
"For example, the following command will tokenize the input text, run part of speech tagging, and output the result as JSON to standard out:","wget --post-data 'the quick brown fox jumped over the lazy dog' 'localhost:9000/?properties={""annotators"": ""tokenize,ssplit,pos"", ""outputFormat"": ""json""}' -O -",https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
"The server also accepts input in a variety of formats. By default, it takes input as raw text sent as POST data to the server. However, it can also be configured to read the POST data using one of the CoreNLP serializers. This can be set up by setting the properties inputFormat and inputSerializer. For example, to read the data as a protocol buffer (useful if, e.g., it is already partially annotated), simply include the following in your url parameter properties={...}:","{""inputFormat"": ""serialized"",
 ""inputSerializer"": ""edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer""}",https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
"A complete call to the server, taking as input a protobuf serialized document at path /path/to/file.proto and returning as a response a protobuf for the document annotated for part of speech and named entity tags (to the file /path/to/annotated_file.proto could be:","wget --post-file /path/to/file.proto 'localhost:9000/?properties={""inputFormat"": ""serialized"", ""inputSerializer"", ""edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer"", ""annotators"": ""tokenize,ssplit,pos,lemma,ner"", ""outputFormat"": ""serialized"", ""serializer"", ""edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer""}' -O /path/to/annotated_file.proto",https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
"Similar to the CoreNLP target, /tokensregex takes a block of data (e.g., text) as POST data, and a series of url parameters. Currently, only plain-text POST data is supported. The two relevant url parameters are:","{""sentences"": {
	""0"": {
	  ""text"": ""the matched text"",
	  ""begin"": 2,
	  ""end"": 5,
	  ""$captureGroupKey"": {
		  ""text"": ""the matched text"",
		  ""begin"": 2,
		  ""end"": 5,
            }
        }
    }
}",https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
"The response is always in JSON, formatted identically to the tokensregex output, with the exception that all spans are single words (only the root of the match is returned):","{""sentences"": {
	""0"": {
	  ""text"": ""text"",
	  ""begin"": 4,
	  ""end"": 5,
	  ""$captureGroupKey"": {
		  ""text"": ""text"",
		  ""begin"": 4,
		  ""end"": 5,
            }
        }
    }
}",https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
CoreNLP includes a Java client to the server – StanfordCoreNLPClient – which mirrors the interface of the annotation pipeline (StanfordCoreNLP.java) as closely as possible. The primary motivating use cases for using this class and not the local pipeline are:,"// creates a StanfordCoreNLP object with POS tagging, lemmatization, NER, parsing, and coreference resolution
Properties props = new Properties();
props.setProperty(""annotators"", ""tokenize, ssplit, pos, lemma, ner, parse, dcoref"");
StanfordCoreNLPClient pipeline = new StanfordCoreNLPClient(props, ""http://localhost"", 9000, 2);
// read some text in the text variable
String text = ... // Add your text here!
// create an empty Annotation just with the given text
Annotation document = new Annotation(text);
// run all Annotators on this text
pipeline.annotate(document);",https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
"You can also run the client from the command line, and get an interface similar to the command line usage for the local CoreNLP program. The following will annotate a file input.txt with part-of-speech, lemmas, named entities, constituency parses, and coreference:","java -cp ""*"" -Xmx1g edu.stanford.nlp.pipeline.StanfordCoreNLPClient -annotators tokenize,ssplit,pos,lemma,ner,parse,dcoref -file input.txt",https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
"Once you have your own server(s) set up, you can run against them with a command like this:","java edu.stanford.nlp.pipeline.StanfordCoreNLPClient -cp ""*"" -annotators tokenize,ssplit,pos,lemma,ner,parse,dcoref -file input.txt  -backends http://localhost:9000",https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
"Providing that the server has foreign language models available on its classpath, you can ask for it to work with texts in other languages. If you have the French properties file and a file called french.txt in your current directory, then you should be able to successfully give a command like this:","java -cp ""*"" edu.stanford.nlp.pipeline.StanfordCoreNLPClient -props StanfordCoreNLP-french.properties -annotators tokenize,ssplit,pos,depparse ile french.txt -outputFormat conllu -backends localhost:9000",https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
"The server is started directly though calling it with java. For example, the following will start the server in the background on port 1337, assuming your classpath is set properly:",nohup java -mx4g edu.stanford.nlp.pipeline.StanfordCoreNLPServer 1337 &,https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
"The server can be stopped programmatically by making a call to the /shutdown endpoint with an appropriate shutdown key. This key is saved to the file corenlp.shutdown in the directory specified by System.getProperty(""java.io.tmpdir""); when the server starts. Typically this will be /tmp/corenlp.shutdown, though it can vary, especially on macOS. An example command to shut down the server would be:","wget ""localhost:9000/shutdown?key=`cat /tmp/corenlp.shutdown`"" -O -",https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
Create a user nlp with permissions to read the directory /opt/corenlp. Allow the user to bind to port 80:,"sudo mkdir -p /etc/authbind/byport/
 sudo touch /etc/authbind/byport/80
 sudo chown nlp:nlp /etc/authbind/byport/80
 sudo chmod 600 /etc/authbind/byport/80",https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
The above steps work using traditional SysVinit scripts. The other alternative on Ubuntu is to use Upstart instead. We haven’t tried that but believe that the corresponding thing to do is:,"sudo wget https://raw.githubusercontent.com/stanfordnlp/CoreNLP/master/src/edu/stanford/nlp/pipeline/demo/corenlp -O /etc/init/corenlp
   initctl reload-configuration",https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
"The CoreNLP server will now start on startup, running on port 80 under the user nlp. To manually start/stop/restart the server, you can use:",sudo service corenlp [start|stop|restart],https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
"When booting up an instance of the server for a shell script, make sure you wait for the server to be available before interacting with it. An example using the netcat tool on linux:","#!/bin/bash
java -mx4g edu.stanford.nlp.pipeline.StanfordCoreNLPServer &
# Wait until server starts
while ! nc -z localhost 9000; do
    sleep 0.1 # wait for 1/10 of the second before check again
done
# Rest of script
# ...",https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
