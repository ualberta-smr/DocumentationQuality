"Paragraph","Tasks"
"CoreNLP includes a simple web API server for servicing your human language understanding needs (starting with version 3.6.0). This page describes how to set it up. CoreNLP server provides both a convenient graphical way to interface with your installation of CoreNLP and an API with which to call CoreNLP using any programming language. If you’re writing a new wrapper of CoreNLP for using it in another language, you’re advised to do it using the CoreNLP Server.","include simple web API server for servicing
call CoreNLP
use programming language
write new wrapper of CoreNLP
use  in language
use CoreNLP server"
"Stanford CoreNLP ships with a built-in server, which requires only the CoreNLP dependencies. To run this server, simply run:","run server"
"If you want to process non-English languages, use this command with the appropriate language properties:","process non-english languages
use command with appropriate language properties"
"If no value for port is provided, port 9000 will be used by default. You can then test your server by visiting","use port
provide value for port
test server by visiting"
"You should see a website similar to corenlp.run, with an input box for text and a list of annotators you can run. From this interface, you can test out each of the annotators by adding/removing them from this list. (Note: The first use will be slow to respond while models are loaded – it might take 30 seconds or so, but after that the server should run quite quickly.) You can test out the API by sending a POST request to the server with the appropriate properties. An easy way to do this is with wget. The following will annotate the sentence “the quick brown fox jumped over the lazy dog” with part of speech tags:","run annotators
send POST request to server"
"Or finally, here’s a minimal Python program that interfaces with this endpoint using the requests library:","use requests library"
"The rest of this document: describes the API in more detail, describes a Java client to the API as a drop-in replacement for the StanfordCoreNLP annotator pipeline, and talks about administering the server. If you’re using Python or another programming language, we don’t suggest that you start with the minimal example above, but rather first look through available other language APIs that use the CoreNLP server.","use Python
use programming language
use CoreNLP server
use available other language apis"
"NOTE: Please do not make API calls against corenlp.run. It is not set up to handle a large volume of requests. Instructions for setting up your own server can be found in the Dedicated Server section.","handle large volume of requests
set up own server"
"This endpoint takes as input a JSON-formatted properties string under the key properties=, and as POSTdata text to annotate. The properties should mirror the properties file passed into the CoreNLP command line, except formatted as a JSON object. The POST data should be percent-encoded (otherwise known as URL encoded). In particular, you shoud esapce a % sign as %25. (Interfaces calling CoreNLP via the web service should do this escaping for their users.)","pass  into CoreNLP command line
format  as JSON object"
"For example, the following command will tokenize the input text, run part of speech tagging, and output the result as JSON to standard out:","tokenize output as JSON
tokenize output of speech tagging
tokenize output to standard out
tokenize input text as JSON
tokenize input text of speech tagging
tokenize input text to standard out
tokenize run part as JSON
tokenize run part of speech tagging
tokenize run part to standard out"
"A common property to set is the output format of the API. The server supports all output formats provided by CoreNLP. These are listed below, along with their relevant properties:","support output formats"
"The server also accepts input in a variety of formats. By default, it takes input as raw text sent as POST data to the server. However, it can also be configured to read the POST data using one of the CoreNLP serializers. This can be set up by setting the properties inputFormat and inputSerializer. For example, to read the data as a protocol buffer (useful if, e.g., it is already partially annotated), simply include the following in your url parameter properties={...}:","send  as POST data
send  to server
set properties inputFormat
set inputSerializer"
"A complete call to the server, taking as input a protobuf serialized document at path /path/to/file.proto and returning as a response a protobuf for the document annotated for part of speech and named entity tags (to the file /path/to/annotated_file.proto could be:","return  as response"
"Similar to the CoreNLP target, /tokensregex takes a block of data (e.g., text) as POST data, and a series of url parameters. Currently, only plain-text POST data is supported. The two relevant url parameters are:","support plain-text POST data"
"Similar to the CoreNLP target, and nearly identical to TokensRegex, /semgrex takes a block of data (e.g., text) as POST data, and a series of url parameters. Currently, only plain-text POST data is supported. The two relevant url parameters are:","support plain-text POST data"
"The response is always in JSON, formatted identically to the tokensregex output, with the exception that all spans are single words (only the root of the match is returned):","format  to tokensregex output"
"CoreNLP includes a Java client to the server – StanfordCoreNLPClient – which mirrors the interface of the annotation pipeline (StanfordCoreNLP.java) as closely as possible. The primary motivating use cases for using this class and not the local pipeline are:","include Java client to server
use class"
"You can also run the client from the command line, and get an interface similar to the command line usage for the local CoreNLP program. The following will annotate a file input.txt with part-of-speech, lemmas, named entities, constituency parses, and coreference:","run client from command line
get interface similar usage for local CoreNLP program"
"NOTE: Again, please do not make API calls against http://corenlp.run. It is not set up to handle a large volume of requests. Instructions for setting up your own server can be found in the Dedicated Server section.","handle large volume of requests
set up own server"
"Once you have your own server(s) set up, you can run against them with a command like this:","run  with command"
"You specify one or more back-end servers in a comma-separated list as the arguments of the -backends option. Each is specified as host:port.","specify back-end servers in comma-separated list
specify  as host:port"
"Providing that the server has foreign language models available on its classpath, you can ask for it to work with texts in other languages. If you have the French properties file and a file called french.txt in your current directory, then you should be able to successfully give a command like this:","call french.txt in current directory"
"The server is started directly though calling it with java. For example, the following will start the server in the background on port 1337, assuming your classpath is set properly:","call  with java
set classpath"
"The classpath must include all of the CoreNLP dependencies. The memory requirements of the server are the same as that of CoreNLP, though it will grow as you load more models (e.g., memory increases if you load both the PCFG and Shift-Reduce constituency parser models). A safe minimum is 4gb; 8gb is recommended if you can spare it.","load more models"
"If running the server under docker, the container’s port 9000 has to be published to the host. Give a command like: docker run -p 9000:9000 --name coreNLP --rm -i -t frnkenstien/corenlp. If, when going to localhost:9000/, you see the error This site can’t be reached. localhost refused to connect, then this is what you failed to do!","run server under docker
reach site
reach error"
"The server can be stopped programmatically by making a call to the /shutdown endpoint with an appropriate shutdown key. This key is saved to the file corenlp.shutdown in the directory specified by System.getProperty(""java.io.tmpdir""); when the server starts. Typically this will be /tmp/corenlp.shutdown, though it can vary, especially on macOS. An example command to shut down the server would be:","save key in directory
save key to file corenlp.shutdown"
"If you start the server with -server_id SERVER_NAME it will store the shutdown key in a file called corenlp.shutdown.SERVER_NAME.","call corenlp.shutdown.SERVER_NAME"
"This section describes how to set up a dedicated CoreNLP server on a fresh Linux install. These instructions are definitely okay on a CentOS 6 system, which is what our demo server runs on. We include a couple of notes of variations below. As always, make sure you understand the commands being run below, as they largely require root permissions:","set up dedicated CoreNLP server on fresh Linux
include couple of notes"
"Create a user nlp with permissions to read the directory /opt/corenlp. Allow the user to bind to port 80:","create user nlp with permissions"
"Link the script to /etc/rc.d/: ln -s /etc/init.d/corenlp /etc/rc.d/rc2.d/S75corenlp","link script"
"The above steps work using traditional SysVinit scripts. The other alternative on Ubuntu is to use Upstart instead. We haven’t tried that but believe that the corresponding thing to do is:","use traditional SysVinit scripts
use Upstart"
"The CoreNLP server will now start on startup, running on port 80 under the user nlp. To manually start/stop/restart the server, you can use:","run  under user nlp
run  on port"
"This section documents some of the subtle quirks of the server, and the motivations behind them.","document motivations"
"The official HTTP 1.1 specification recommends ISO-8859-1 as the encoding of a request, unless a different encoding is explicitly set by using the Content-Type header. However, for most NLP applications this is an unintuitive default, and so the server instead defaults to UTF-8. To enable the ISO-8859-1 default, pass in the -strict flag to the server at startup.","use content-type header
set different encoding
enable ISO-8859-1 default"
"When booting up an instance of the server for a shell script, make sure you wait for the server to be available before interacting with it. An example using the netcat tool on linux:","use netcat tool on linux"
