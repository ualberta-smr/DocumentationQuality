"Paragraph","Tasks"
"Out-of-the-box, Stanford CoreNLP expects and processes English language text. But, Stanford CoreNLP was designed from the start to work with multiple human languages and it is careful about things like different character encodings. We have developed components for several major languages, and make language packs (jar files) available for some of them. The table below summarizes our current first party foreign language support. Other people have developed models for other languages.","design stanford CoreNLP from start
develop components for several major languages
summarize current first party foreign language support
develop models for other languages"
"To run Stanford CoreNLP on a supported language, you have to include the models jar for that language in your CLASSPATH.","run Stanford CoreNLP on supported language
include models jar for language"
"There are sets of default properties that can be used to run pipelines for every supported language.","run pipelines for supported language
use sets of default properties"
"For instance, to run a Spanish pipeline, one could execute this command from the command line:","run Spanish pipeline
execute command for instance
execute command from command line"
"Or build and run a pipeline in Java in this manner:","build pipeline in Java
run pipeline in Java"
"These examples would use the following sets of properties (found in StanfordCoreNLP-spanish.properties)","use following sets of properties"
"Currently French (UD 2.2), German (UD 2.2), and Spanish (AnCora UD 2.0) work off of the UD 2.0 tokenization standard. This means among other things that words are split into multiword tokens. For instance the French word ""des"" will be tokenized in some circumstances as ""de"" ""les"". All tagging, parsing, and named entity recognition models rely on that tokenization standard, so it is necessary to use the mwt annotator which performs the multiword tokenization. For instance, in Spanish, the annotators required to run dependency parsing would be tokenize,ssplit,mwt,pos,lemma,depparse. The part of speech tags and dependency labels are from the UD 2.0 sets for each language.","split words into multiword tokens
tokenize French word in circumstances
tokenize French word for instance
use mwt annotator
perform multiword tokenization
perform mwt annotator
run dependency parsing"
"Other people have developed models using or compatible with CoreNLP for several further languages. They may or may not be compatible with the most recent release of CoreNLP that we provide.","develop models"
