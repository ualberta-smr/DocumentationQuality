library_name,paragraph,task,has_example,example_page
CoreNLP,"While every annotator can technically be run as a top-level component, in some cases it makes sense for one annotator to run another as a sub-annotator. For instance the coref annotator runs the coref.mention annotator (which identifies coref mentions) as a sub-annotator by default. So instead of supplying an annotator list of tokenize,ssplit,parse,coref.mention,coref the list can just be tokenize,ssplit,parse,coref. Another example is the ner annotator running the entitymentions annotator to detect full entities. Below is a table summarizing the annotator/sub-annotator relationships that currently exist in the pipeline. By default annotators will generally run their sub-annotators.",run annotator as top-level component,0,
CoreNLP,"While every annotator can technically be run as a top-level component, in some cases it makes sense for one annotator to run another as a sub-annotator. For instance the coref annotator runs the coref.mention annotator (which identifies coref mentions) as a sub-annotator by default. So instead of supplying an annotator list of tokenize,ssplit,parse,coref.mention,coref the list can just be tokenize,ssplit,parse,coref. Another example is the ner annotator running the entitymentions annotator to detect full entities. Below is a table summarizing the annotator/sub-annotator relationships that currently exist in the pipeline. By default annotators will generally run their sub-annotators.",run coref.mention annotator as sub-annotator,0,
CoreNLP,"While every annotator can technically be run as a top-level component, in some cases it makes sense for one annotator to run another as a sub-annotator. For instance the coref annotator runs the coref.mention annotator (which identifies coref mentions) as a sub-annotator by default. So instead of supplying an annotator list of tokenize,ssplit,parse,coref.mention,coref the list can just be tokenize,ssplit,parse,coref. Another example is the ner annotator running the entitymentions annotator to detect full entities. Below is a table summarizing the annotator/sub-annotator relationships that currently exist in the pipeline. By default annotators will generally run their sub-annotators.",run coref.mention annotator by default,0,
CoreNLP,"While every annotator can technically be run as a top-level component, in some cases it makes sense for one annotator to run another as a sub-annotator. For instance the coref annotator runs the coref.mention annotator (which identifies coref mentions) as a sub-annotator by default. So instead of supplying an annotator list of tokenize,ssplit,parse,coref.mention,coref the list can just be tokenize,ssplit,parse,coref. Another example is the ner annotator running the entitymentions annotator to detect full entities. Below is a table summarizing the annotator/sub-annotator relationships that currently exist in the pipeline. By default annotators will generally run their sub-annotators.",run coref.mention annotator for instance,0,
CoreNLP,"While every annotator can technically be run as a top-level component, in some cases it makes sense for one annotator to run another as a sub-annotator. For instance the coref annotator runs the coref.mention annotator (which identifies coref mentions) as a sub-annotator by default. So instead of supplying an annotator list of tokenize,ssplit,parse,coref.mention,coref the list can just be tokenize,ssplit,parse,coref. Another example is the ner annotator running the entitymentions annotator to detect full entities. Below is a table summarizing the annotator/sub-annotator relationships that currently exist in the pipeline. By default annotators will generally run their sub-annotators.",run entitymentions annotator,0,
CoreNLP,"While every annotator can technically be run as a top-level component, in some cases it makes sense for one annotator to run another as a sub-annotator. For instance the coref annotator runs the coref.mention annotator (which identifies coref mentions) as a sub-annotator by default. So instead of supplying an annotator list of tokenize,ssplit,parse,coref.mention,coref the list can just be tokenize,ssplit,parse,coref. Another example is the ner annotator running the entitymentions annotator to detect full entities. Below is a table summarizing the annotator/sub-annotator relationships that currently exist in the pipeline. By default annotators will generally run their sub-annotators.",summarize annotator/sub-annotator relationships,0,
CoreNLP,"While every annotator can technically be run as a top-level component, in some cases it makes sense for one annotator to run another as a sub-annotator. For instance the coref annotator runs the coref.mention annotator (which identifies coref mentions) as a sub-annotator by default. So instead of supplying an annotator list of tokenize,ssplit,parse,coref.mention,coref the list can just be tokenize,ssplit,parse,coref. Another example is the ner annotator running the entitymentions annotator to detect full entities. Below is a table summarizing the annotator/sub-annotator relationships that currently exist in the pipeline. By default annotators will generally run their sub-annotators.",run sub-annotators by default,0,
CoreNLP,Below is a quick snippet of code that demonstrates running a full pipeline on some sample text. It requires the english and english-kbp models jars which contain essential resources.,run full pipeline on sample text,0,
CoreNLP,It uses new wrapper classes that have been developed for Stanford CoreNLP 3.9.0 to make it easier to work with annotations.,use new wrapper classes,1,https://stanfordnlp.github.io/CoreNLP/api.html
CoreNLP,It uses new wrapper classes that have been developed for Stanford CoreNLP 3.9.0 to make it easier to work with annotations.,develop new wrapper classes for Stanford CoreNLP 3.9.0,1,https://stanfordnlp.github.io/CoreNLP/api.html
CoreNLP,"The backbone of the CoreNLP package is formed by two classes: Annotation and Annotator. Annotations are the data structure which hold the results of annotators. Annotations are basically maps, from keys to bits of the annotation, such as the parse, the part-of-speech tags, or named entity tags. Annotators are a lot like functions, except that they operate over Annotations instead of Objects. They do things like tokenize, parse, or NER tag sentences. Annotators and Annotations are integrated by AnnotationPipelines, which create sequences of generic Annotators. Stanford CoreNLP inherits from the AnnotationPipeline class, and is customized with NLP Annotators.",create sequences of generic annotators,0,
CoreNLP,"The backbone of the CoreNLP package is formed by two classes: Annotation and Annotator. Annotations are the data structure which hold the results of annotators. Annotations are basically maps, from keys to bits of the annotation, such as the parse, the part-of-speech tags, or named entity tags. Annotators are a lot like functions, except that they operate over Annotations instead of Objects. They do things like tokenize, parse, or NER tag sentences. Annotators and Annotations are integrated by AnnotationPipelines, which create sequences of generic Annotators. Stanford CoreNLP inherits from the AnnotationPipeline class, and is customized with NLP Annotators.",create AnnotationPipelines of generic annotators,0,
CoreNLP,"The backbone of the CoreNLP package is formed by two classes: Annotation and Annotator. Annotations are the data structure which hold the results of annotators. Annotations are basically maps, from keys to bits of the annotation, such as the parse, the part-of-speech tags, or named entity tags. Annotators are a lot like functions, except that they operate over Annotations instead of Objects. They do things like tokenize, parse, or NER tag sentences. Annotators and Annotations are integrated by AnnotationPipelines, which create sequences of generic Annotators. Stanford CoreNLP inherits from the AnnotationPipeline class, and is customized with NLP Annotators.",integrate annotators,0,
CoreNLP,"The backbone of the CoreNLP package is formed by two classes: Annotation and Annotator. Annotations are the data structure which hold the results of annotators. Annotations are basically maps, from keys to bits of the annotation, such as the parse, the part-of-speech tags, or named entity tags. Annotators are a lot like functions, except that they operate over Annotations instead of Objects. They do things like tokenize, parse, or NER tag sentences. Annotators and Annotations are integrated by AnnotationPipelines, which create sequences of generic Annotators. Stanford CoreNLP inherits from the AnnotationPipeline class, and is customized with NLP Annotators.",integrate Annotations,0,
CoreNLP,"The backbone of the CoreNLP package is formed by two classes: Annotation and Annotator. Annotations are the data structure which hold the results of annotators. Annotations are basically maps, from keys to bits of the annotation, such as the parse, the part-of-speech tags, or named entity tags. Annotators are a lot like functions, except that they operate over Annotations instead of Objects. They do things like tokenize, parse, or NER tag sentences. Annotators and Annotations are integrated by AnnotationPipelines, which create sequences of generic Annotators. Stanford CoreNLP inherits from the AnnotationPipeline class, and is customized with NLP Annotators.",inherit  from AnnotationPipeline class,0,
CoreNLP,"To construct a Stanford CoreNLP object from a given set of properties, use StanfordCoreNLP(Properties props). This method creates the pipeline using the annotators given in the “annotators” property (see below for an example setting). The complete list of accepted annotator names is listed in the first column of the table here. To parse an arbitrary text, use the annotate(Annotation document) method.",create pipeline,1,https://stanfordnlp.github.io/CoreNLP/api.html
CoreNLP,"To construct a Stanford CoreNLP object from a given set of properties, use StanfordCoreNLP(Properties props). This method creates the pipeline using the annotators given in the “annotators” property (see below for an example setting). The complete list of accepted annotator names is listed in the first column of the table here. To parse an arbitrary text, use the annotate(Annotation document) method.",use annotators,1,https://stanfordnlp.github.io/CoreNLP/api.html
CoreNLP,"To construct a Stanford CoreNLP object from a given set of properties, use StanfordCoreNLP(Properties props). This method creates the pipeline using the annotators given in the “annotators” property (see below for an example setting). The complete list of accepted annotator names is listed in the first column of the table here. To parse an arbitrary text, use the annotate(Annotation document) method.",parse arbitrary text,1,https://stanfordnlp.github.io/CoreNLP/api.html
CoreNLP,"To construct a Stanford CoreNLP object from a given set of properties, use StanfordCoreNLP(Properties props). This method creates the pipeline using the annotators given in the “annotators” property (see below for an example setting). The complete list of accepted annotator names is listed in the first column of the table here. To parse an arbitrary text, use the annotate(Annotation document) method.",use annotate(Annotation document) method,1,https://stanfordnlp.github.io/CoreNLP/api.html
CoreNLP,"You can give other properties to CoreNLP by building a Properties object with more stuff in it. There are some overall properties like ""annotators"" but most properties apply to one annotator and are written as annotator.property. Note that the value of a property is always a String. In our documentation of individual annotators, we variously refer to their Type as “boolean”, “file, classpath, or URL” or “List(String)”. This means that the String value will be interpreted as objects of this type by using String parsing methods. The value itself in the Properties object is always a String. If you want to set several properties, you might find it conventient to use our PropertiesUtils.asProperties(String ...) method which will take a list of Strings that are alternately keys and values and build a Properties object:",build Properties object with more stuff,1,https://stanfordnlp.github.io/CoreNLP/api.html
CoreNLP,"You can give other properties to CoreNLP by building a Properties object with more stuff in it. There are some overall properties like ""annotators"" but most properties apply to one annotator and are written as annotator.property. Note that the value of a property is always a String. In our documentation of individual annotators, we variously refer to their Type as “boolean”, “file, classpath, or URL” or “List(String)”. This means that the String value will be interpreted as objects of this type by using String parsing methods. The value itself in the Properties object is always a String. If you want to set several properties, you might find it conventient to use our PropertiesUtils.asProperties(String ...) method which will take a list of Strings that are alternately keys and values and build a Properties object:",write most properties as annotator.property,1,https://stanfordnlp.github.io/CoreNLP/api.html
CoreNLP,"You can give other properties to CoreNLP by building a Properties object with more stuff in it. There are some overall properties like ""annotators"" but most properties apply to one annotator and are written as annotator.property. Note that the value of a property is always a String. In our documentation of individual annotators, we variously refer to their Type as “boolean”, “file, classpath, or URL” or “List(String)”. This means that the String value will be interpreted as objects of this type by using String parsing methods. The value itself in the Properties object is always a String. If you want to set several properties, you might find it conventient to use our PropertiesUtils.asProperties(String ...) method which will take a list of Strings that are alternately keys and values and build a Properties object:",use String parsing methods,1,https://stanfordnlp.github.io/CoreNLP/api.html
CoreNLP,"You can give other properties to CoreNLP by building a Properties object with more stuff in it. There are some overall properties like ""annotators"" but most properties apply to one annotator and are written as annotator.property. Note that the value of a property is always a String. In our documentation of individual annotators, we variously refer to their Type as “boolean”, “file, classpath, or URL” or “List(String)”. This means that the String value will be interpreted as objects of this type by using String parsing methods. The value itself in the Properties object is always a String. If you want to set several properties, you might find it conventient to use our PropertiesUtils.asProperties(String ...) method which will take a list of Strings that are alternately keys and values and build a Properties object:",set several properties,1,https://stanfordnlp.github.io/CoreNLP/api.html
CoreNLP,"You can give other properties to CoreNLP by building a Properties object with more stuff in it. There are some overall properties like ""annotators"" but most properties apply to one annotator and are written as annotator.property. Note that the value of a property is always a String. In our documentation of individual annotators, we variously refer to their Type as “boolean”, “file, classpath, or URL” or “List(String)”. This means that the String value will be interpreted as objects of this type by using String parsing methods. The value itself in the Properties object is always a String. If you want to set several properties, you might find it conventient to use our PropertiesUtils.asProperties(String ...) method which will take a list of Strings that are alternately keys and values and build a Properties object:",use PropertiesUtils.asProperties(String ...) method,1,https://stanfordnlp.github.io/CoreNLP/api.html
CoreNLP,"You can give other properties to CoreNLP by building a Properties object with more stuff in it. There are some overall properties like ""annotators"" but most properties apply to one annotator and are written as annotator.property. Note that the value of a property is always a String. In our documentation of individual annotators, we variously refer to their Type as “boolean”, “file, classpath, or URL” or “List(String)”. This means that the String value will be interpreted as objects of this type by using String parsing methods. The value itself in the Properties object is always a String. If you want to set several properties, you might find it conventient to use our PropertiesUtils.asProperties(String ...) method which will take a list of Strings that are alternately keys and values and build a Properties object:",build Properties object,1,https://stanfordnlp.github.io/CoreNLP/api.html
CoreNLP,"You can give other properties to CoreNLP by building a Properties object with more stuff in it. There are some overall properties like ""annotators"" but most properties apply to one annotator and are written as annotator.property. Note that the value of a property is always a String. In our documentation of individual annotators, we variously refer to their Type as “boolean”, “file, classpath, or URL” or “List(String)”. This means that the String value will be interpreted as objects of this type by using String parsing methods. The value itself in the Properties object is always a String. If you want to set several properties, you might find it conventient to use our PropertiesUtils.asProperties(String ...) method which will take a list of Strings that are alternately keys and values and build a Properties object:",build PropertiesUtils.asProperties(String ...) method,1,https://stanfordnlp.github.io/CoreNLP/api.html
CoreNLP,"If you do not anticipate requiring extensive customization, consider using the Simple CoreNLP API.",use simple CoreNLP API,0,
CoreNLP,"If you want to do funkier things with CoreNLP, such as to use a second StanfordCoreNLP object to add additional analyses to an existing Annotation object, then you need to include the property enforceRequirements = false to avoid complaints about required earlier annotators not being present in the pipeline.",use second StanfordCoreNLP object,0,
CoreNLP,"If you want to do funkier things with CoreNLP, such as to use a second StanfordCoreNLP object to add additional analyses to an existing Annotation object, then you need to include the property enforceRequirements = false to avoid complaints about required earlier annotators not being present in the pipeline.",add additional analyses to existing annotation object,0,
CoreNLP,The output of the Annotators is accessed using the data structures CoreMap and CoreLabel.,use data structures CoreMap,1,https://stanfordnlp.github.io/CoreNLP/api.html
CoreNLP,The output of the Annotators is accessed using the data structures CoreMap and CoreLabel.,use CoreLabel,1,https://stanfordnlp.github.io/CoreNLP/api.html
CoreNLP,The output of the Annotators is accessed using the data structures CoreMap and CoreLabel.,access output of Annotators,1,https://stanfordnlp.github.io/CoreNLP/api.html
CoreNLP,"There are two strategies available to address this that may help. One is to try to first correctly capitalize the text with a truecaser, and then to process the text with the standard models. See the TrueCaseAnnotator for how to do this.",process text with standard models,0,
CoreNLP,An example command for using regular annotators following truecasing is:,use regular annotators following truecasing,1,https://stanfordnlp.github.io/CoreNLP/caseless.html
CoreNLP,The GATE folk made an English POS tagger model trained on twitter text. You can get it from the extensions page.,get  from extensions page,0,
CoreNLP,"We have made slightly different Stanford CoreNLP models for the tagger, parser, and NER that ignore capitalization. We have only trained such models for English, but the same method could be used for other languages.",ignore capitalization,0,
CoreNLP,"We have made slightly different Stanford CoreNLP models for the tagger, parser, and NER that ignore capitalization. We have only trained such models for English, but the same method could be used for other languages.",ignore tagger,0,
CoreNLP,"We have made slightly different Stanford CoreNLP models for the tagger, parser, and NER that ignore capitalization. We have only trained such models for English, but the same method could be used for other languages.",ignore NER,0,
CoreNLP,"We have made slightly different Stanford CoreNLP models for the tagger, parser, and NER that ignore capitalization. We have only trained such models for English, but the same method could be used for other languages.",ignore parser,0,
CoreNLP,"We have made slightly different Stanford CoreNLP models for the tagger, parser, and NER that ignore capitalization. We have only trained such models for English, but the same method could be used for other languages.",use same method for other languages,0,
CoreNLP,"To use these models, you need to download a jar file with caseless models. Prior to version 3.6, caseless models were packaged separately as their own jar file (approximately treating “caseless English” like a separate language). Starting with version 3.6, caseless models for English are included in the new comprehensive english jar file. You can find these jar files on the Release history page.",use models,0,
CoreNLP,"To use these models, you need to download a jar file with caseless models. Prior to version 3.6, caseless models were packaged separately as their own jar file (approximately treating “caseless English” like a separate language). Starting with version 3.6, caseless models for English are included in the new comprehensive english jar file. You can find these jar files on the Release history page.",download jar file with caseless models,0,
CoreNLP,"To use these models, you need to download a jar file with caseless models. Prior to version 3.6, caseless models were packaged separately as their own jar file (approximately treating “caseless English” like a separate language). Starting with version 3.6, caseless models for English are included in the new comprehensive english jar file. You can find these jar files on the Release history page.",include caseless models in new comprehensive english jar file,0,
CoreNLP,"To use these models, you need to download a jar file with caseless models. Prior to version 3.6, caseless models were packaged separately as their own jar file (approximately treating “caseless English” like a separate language). Starting with version 3.6, caseless models for English are included in the new comprehensive english jar file. You can find these jar files on the Release history page.",include caseless models for English,0,
CoreNLP,Be sure to include the path to the case-insensitive models jar in the -cp classpath flag and then you can ask for these models to be used like this:,include path to case-insensitive models jar,1,https://stanfordnlp.github.io/CoreNLP/caseless.html
CoreNLP,Be sure to include the path to the case-insensitive models jar in the -cp classpath flag and then you can ask for these models to be used like this:,ask  for models,1,https://stanfordnlp.github.io/CoreNLP/caseless.html
CoreNLP,"However, if we ask to use the caseless models, then we’re doing pretty well: All the name words are now recognized as proper nouns, and the two person names are recognized. However, the team name is still missed. Correct named entity recognition is just harder for caseless English than for well-edited English!",use caseless models,1,https://stanfordnlp.github.io/CoreNLP/caseless.html
CoreNLP,"However, if we ask to use the caseless models, then we’re doing pretty well: All the name words are now recognized as proper nouns, and the two person names are recognized. However, the team name is still missed. Correct named entity recognition is just harder for caseless English than for well-edited English!",recognize name words as proper nouns,1,https://stanfordnlp.github.io/CoreNLP/caseless.html
CoreNLP,"However, if we ask to use the caseless models, then we’re doing pretty well: All the name words are now recognized as proper nouns, and the two person names are recognized. However, the team name is still missed. Correct named entity recognition is just harder for caseless English than for well-edited English!",recognize person names,1,https://stanfordnlp.github.io/CoreNLP/caseless.html
CoreNLP,"To train your own caseless models, you need one additional property, which asks for a function to be called before a token is processed which leads to the case of all words being ignored. We use by default a function that also Americanizes the spelling of certain words:",ask additional property for function,1,https://stanfordnlp.github.io/CoreNLP/caseless.html
CoreNLP,"To train your own caseless models, you need one additional property, which asks for a function to be called before a token is processed which leads to the case of all words being ignored. We use by default a function that also Americanizes the spelling of certain words:",use spelling by default,1,https://stanfordnlp.github.io/CoreNLP/caseless.html
CoreNLP,"To train your own caseless models, you need one additional property, which asks for a function to be called before a token is processed which leads to the case of all words being ignored. We use by default a function that also Americanizes the spelling of certain words:",use spelling of certain words,1,https://stanfordnlp.github.io/CoreNLP/caseless.html
CoreNLP,"The caseless NER model edu/stanford/nlp/models/ner/english.all.3class.caseless.distsim.crf.ser.gz released with version 3.6.0 was defective and has very poor performance. Sorry! Stuff happens. If you want good caseless NER, you should either run with caseless models from a 3.5.x series release (all of which are compatible with version 3.6.0) or download the new fixed model from version 3.7.0 or a later version. Since the version 3.5.x releases have a separate caseless jar, it is easy to also specify an additional jar as a dependency; you just have to make sure that it appears on your classpath before other jars which contain models with the same name.",release  with version 3.6.0,0,
CoreNLP,"The caseless NER model edu/stanford/nlp/models/ner/english.all.3class.caseless.distsim.crf.ser.gz released with version 3.6.0 was defective and has very poor performance. Sorry! Stuff happens. If you want good caseless NER, you should either run with caseless models from a 3.5.x series release (all of which are compatible with version 3.6.0) or download the new fixed model from version 3.7.0 or a later version. Since the version 3.5.x releases have a separate caseless jar, it is easy to also specify an additional jar as a dependency; you just have to make sure that it appears on your classpath before other jars which contain models with the same name.",download new fixed model from later version,0,
CoreNLP,"The caseless NER model edu/stanford/nlp/models/ner/english.all.3class.caseless.distsim.crf.ser.gz released with version 3.6.0 was defective and has very poor performance. Sorry! Stuff happens. If you want good caseless NER, you should either run with caseless models from a 3.5.x series release (all of which are compatible with version 3.6.0) or download the new fixed model from version 3.7.0 or a later version. Since the version 3.5.x releases have a separate caseless jar, it is easy to also specify an additional jar as a dependency; you just have to make sure that it appears on your classpath before other jars which contain models with the same name.",download new fixed model from version 3.7.0,0,
CoreNLP,"The caseless NER model edu/stanford/nlp/models/ner/english.all.3class.caseless.distsim.crf.ser.gz released with version 3.6.0 was defective and has very poor performance. Sorry! Stuff happens. If you want good caseless NER, you should either run with caseless models from a 3.5.x series release (all of which are compatible with version 3.6.0) or download the new fixed model from version 3.7.0 or a later version. Since the version 3.5.x releases have a separate caseless jar, it is easy to also specify an additional jar as a dependency; you just have to make sure that it appears on your classpath before other jars which contain models with the same name.",run  with caseless models,0,
CoreNLP,"The caseless NER model edu/stanford/nlp/models/ner/english.all.3class.caseless.distsim.crf.ser.gz released with version 3.6.0 was defective and has very poor performance. Sorry! Stuff happens. If you want good caseless NER, you should either run with caseless models from a 3.5.x series release (all of which are compatible with version 3.6.0) or download the new fixed model from version 3.7.0 or a later version. Since the version 3.5.x releases have a separate caseless jar, it is easy to also specify an additional jar as a dependency; you just have to make sure that it appears on your classpath before other jars which contain models with the same name.",run  from 3.5.x series release,0,
CoreNLP,"The caseless NER model edu/stanford/nlp/models/ner/english.all.3class.caseless.distsim.crf.ser.gz released with version 3.6.0 was defective and has very poor performance. Sorry! Stuff happens. If you want good caseless NER, you should either run with caseless models from a 3.5.x series release (all of which are compatible with version 3.6.0) or download the new fixed model from version 3.7.0 or a later version. Since the version 3.5.x releases have a separate caseless jar, it is easy to also specify an additional jar as a dependency; you just have to make sure that it appears on your classpath before other jars which contain models with the same name.",specify additional jar as dependency,0,
CoreNLP,"This annotator removes XML tags from an input document. Stanford CoreNLP has the ability to remove all or most XML tags from a document before processing it. This functionality is provided by a finite automaton. It works fine for typical, simple XML, but complex constructions and CDATA sections will not be correctly handled. If you want full and correct handling of XML, then you should run XML documents through an XML parser (such as the one included standard in Java) before passing appropriate text nodes to Stanford CoreNLP. However, then you are unable to recover character offsets in the original XML text file.",remove XML tags from input document,0,
CoreNLP,"This annotator removes XML tags from an input document. Stanford CoreNLP has the ability to remove all or most XML tags from a document before processing it. This functionality is provided by a finite automaton. It works fine for typical, simple XML, but complex constructions and CDATA sections will not be correctly handled. If you want full and correct handling of XML, then you should run XML documents through an XML parser (such as the one included standard in Java) before passing appropriate text nodes to Stanford CoreNLP. However, then you are unable to recover character offsets in the original XML text file.",remove most XML tags before processing,0,
CoreNLP,"This annotator removes XML tags from an input document. Stanford CoreNLP has the ability to remove all or most XML tags from a document before processing it. This functionality is provided by a finite automaton. It works fine for typical, simple XML, but complex constructions and CDATA sections will not be correctly handled. If you want full and correct handling of XML, then you should run XML documents through an XML parser (such as the one included standard in Java) before passing appropriate text nodes to Stanford CoreNLP. However, then you are unable to recover character offsets in the original XML text file.",remove most XML tags from document,0,
CoreNLP,"This annotator removes XML tags from an input document. Stanford CoreNLP has the ability to remove all or most XML tags from a document before processing it. This functionality is provided by a finite automaton. It works fine for typical, simple XML, but complex constructions and CDATA sections will not be correctly handled. If you want full and correct handling of XML, then you should run XML documents through an XML parser (such as the one included standard in Java) before passing appropriate text nodes to Stanford CoreNLP. However, then you are unable to recover character offsets in the original XML text file.",run XML documents through XML parser,0,
CoreNLP,"This annotator removes XML tags from an input document. Stanford CoreNLP has the ability to remove all or most XML tags from a document before processing it. This functionality is provided by a finite automaton. It works fine for typical, simple XML, but complex constructions and CDATA sections will not be correctly handled. If you want full and correct handling of XML, then you should run XML documents through an XML parser (such as the one included standard in Java) before passing appropriate text nodes to Stanford CoreNLP. However, then you are unable to recover character offsets in the original XML text file.",run XML documents before passing,0,
CoreNLP,"This annotator removes XML tags from an input document. Stanford CoreNLP has the ability to remove all or most XML tags from a document before processing it. This functionality is provided by a finite automaton. It works fine for typical, simple XML, but complex constructions and CDATA sections will not be correctly handled. If you want full and correct handling of XML, then you should run XML documents through an XML parser (such as the one included standard in Java) before passing appropriate text nodes to Stanford CoreNLP. However, then you are unable to recover character offsets in the original XML text file.",pass appropriate text nodes to Stanford CoreNLP,0,
CoreNLP,"The cleanxml annotator supports many complex processing options: You can choose to only delete some XML tags, to treat certain XML tags as sentence ending, as marking the speaker in a dialog, etc. You can also extract document metadata from XML attributes. The cleanxml annotator can be placed after tokenize in processing order.",support many complex processing options,1,https://stanfordnlp.github.io/CoreNLP/cleanxml.html
CoreNLP,"The cleanxml annotator supports many complex processing options: You can choose to only delete some XML tags, to treat certain XML tags as sentence ending, as marking the speaker in a dialog, etc. You can also extract document metadata from XML attributes. The cleanxml annotator can be placed after tokenize in processing order.",delete XML tags,1,https://stanfordnlp.github.io/CoreNLP/cleanxml.html
CoreNLP,"The cleanxml annotator supports many complex processing options: You can choose to only delete some XML tags, to treat certain XML tags as sentence ending, as marking the speaker in a dialog, etc. You can also extract document metadata from XML attributes. The cleanxml annotator can be placed after tokenize in processing order.",mark speaker in dialog,1,https://stanfordnlp.github.io/CoreNLP/cleanxml.html
CoreNLP,"The cleanxml annotator supports many complex processing options: You can choose to only delete some XML tags, to treat certain XML tags as sentence ending, as marking the speaker in a dialog, etc. You can also extract document metadata from XML attributes. The cleanxml annotator can be placed after tokenize in processing order.",extract document metadata from XML attributes,1,https://stanfordnlp.github.io/CoreNLP/cleanxml.html
CoreNLP,"The cleanxml annotator supports many complex processing options: You can choose to only delete some XML tags, to treat certain XML tags as sentence ending, as marking the speaker in a dialog, etc. You can also extract document metadata from XML attributes. The cleanxml annotator can be placed after tokenize in processing order.",place cleanxml annotator after tokenize,1,https://stanfordnlp.github.io/CoreNLP/cleanxml.html
CoreNLP,Stanford CoreNLP deletes the XML tags and generates output that is basically the same as for the default input.txt example. The only difference between this and the original output is a change in CharacterOffsets.,delete XML tags,0,
CoreNLP,"Example 2: For some simple text files, the structure is basically just paragraphs contained in  elements. Then one might use a command like:",use command,1,https://stanfordnlp.github.io/CoreNLP/cleanxml.html
CoreNLP,"Example 3: For a somewhat more complex newspaper XML page, the title is in a  element and the text of the article is in  elements, but there are also a bunch of other elements for tracking, ads, etc. to be deleted, and one wants to treat the end of the above two elements as also being a sentence boundary. Finally, the article was published on 2020-05-23. One might use a command like:",use command,1,https://stanfordnlp.github.io/CoreNLP/cleanxml.html
CoreNLP,"Note that although the annotator is called “cleanxml” in the annotators list, the prefix for options is just “clean”. We should probably regularize this at some point…. Also, the option names are case sensitive, so get them right!",call annotator in annotators list,0,
CoreNLP,Here is an example of setting many of these options in order to access information from an XML file that is similar to the LDC MPDF (multi-post discussion forum) XML format.,set  from XML file,1,https://stanfordnlp.github.io/CoreNLP/cleanxml.html
CoreNLP,Here is an example of setting many of these options in order to access information from an XML file that is similar to the LDC MPDF (multi-post discussion forum) XML format.,set  to access information,1,https://stanfordnlp.github.io/CoreNLP/cleanxml.html
CoreNLP,"Here is the part of the JSON file output by that command, showing the section information. Information about quotes is not (yet) in out JSON output.",show section information,1,https://stanfordnlp.github.io/CoreNLP/cleanxml.html
CoreNLP,"Note: Stanford CoreNLP v.3.5+ requires Java 8, but works with Java 9/10/11 as well. If using Java 9/10/11, you need to add this Java flag to avoid errors (a CoreNLP library dependency uses the JAXB module that was deleted from the default libraries for Java 9+):",use Java 9,1,https://stanfordnlp.github.io/CoreNLP/cmdline.html
CoreNLP,"Note: Stanford CoreNLP v.3.5+ requires Java 8, but works with Java 9/10/11 as well. If using Java 9/10/11, you need to add this Java flag to avoid errors (a CoreNLP library dependency uses the JAXB module that was deleted from the default libraries for Java 9+):",add Java flag,1,https://stanfordnlp.github.io/CoreNLP/cmdline.html
CoreNLP,The minimal command to run Stanford CoreNLP from the command line is:,run Stanford CoreNLP from command line,1,https://stanfordnlp.github.io/CoreNLP/cmdline.html
CoreNLP,"If this command is run from the distribution directory, it processes the included sample file input.txt. We use a wildcard ""*"" after -cp to load all jar files in the current directory – it needs to be in quotes. This command writes the output to an XML file named input.txt.xml in the same directory.",process included sample file input.txt,0,
CoreNLP,"If this command is run from the distribution directory, it processes the included sample file input.txt. We use a wildcard ""*"" after -cp to load all jar files in the current directory – it needs to be in quotes. This command writes the output to an XML file named input.txt.xml in the same directory.",run command from distribution directory,0,
CoreNLP,"If this command is run from the distribution directory, it processes the included sample file input.txt. We use a wildcard ""*"" after -cp to load all jar files in the current directory – it needs to be in quotes. This command writes the output to an XML file named input.txt.xml in the same directory.",use wildcard * after cp,0,
CoreNLP,"If this command is run from the distribution directory, it processes the included sample file input.txt. We use a wildcard ""*"" after -cp to load all jar files in the current directory – it needs to be in quotes. This command writes the output to an XML file named input.txt.xml in the same directory.",load jar files in current directory,0,
CoreNLP,"If this command is run from the distribution directory, it processes the included sample file input.txt. We use a wildcard ""*"" after -cp to load all jar files in the current directory – it needs to be in quotes. This command writes the output to an XML file named input.txt.xml in the same directory.",write output to XML file,0,
CoreNLP,"Your command line has to load the code, libraries, and model jars that CoreNLP uses. These are all contained in JAR files (compressed archives with extension “.jar”) which come in the CoreNLP download or which can be downloaded on demand from Maven Central. The easiest way to make them available is with a command line like this, where /Users/me/corenlp/ should be changed to the path where you put CoreNLP:",load code,1,https://stanfordnlp.github.io/CoreNLP/cmdline.html
CoreNLP,"Your command line has to load the code, libraries, and model jars that CoreNLP uses. These are all contained in JAR files (compressed archives with extension “.jar”) which come in the CoreNLP download or which can be downloaded on demand from Maven Central. The easiest way to make them available is with a command line like this, where /Users/me/corenlp/ should be changed to the path where you put CoreNLP:",load libraries,1,https://stanfordnlp.github.io/CoreNLP/cmdline.html
CoreNLP,"Your command line has to load the code, libraries, and model jars that CoreNLP uses. These are all contained in JAR files (compressed archives with extension “.jar”) which come in the CoreNLP download or which can be downloaded on demand from Maven Central. The easiest way to make them available is with a command line like this, where /Users/me/corenlp/ should be changed to the path where you put CoreNLP:",load model jars,1,https://stanfordnlp.github.io/CoreNLP/cmdline.html
CoreNLP,"Your command line has to load the code, libraries, and model jars that CoreNLP uses. These are all contained in JAR files (compressed archives with extension “.jar”) which come in the CoreNLP download or which can be downloaded on demand from Maven Central. The easiest way to make them available is with a command line like this, where /Users/me/corenlp/ should be changed to the path where you put CoreNLP:",download  from Maven central,1,https://stanfordnlp.github.io/CoreNLP/cmdline.html
CoreNLP,"Your command line has to load the code, libraries, and model jars that CoreNLP uses. These are all contained in JAR files (compressed archives with extension “.jar”) which come in the CoreNLP download or which can be downloaded on demand from Maven Central. The easiest way to make them available is with a command line like this, where /Users/me/corenlp/ should be changed to the path where you put CoreNLP:",download  on demand,1,https://stanfordnlp.github.io/CoreNLP/cmdline.html
CoreNLP,"Your command line has to load the code, libraries, and model jars that CoreNLP uses. These are all contained in JAR files (compressed archives with extension “.jar”) which come in the CoreNLP download or which can be downloaded on demand from Maven Central. The easiest way to make them available is with a command line like this, where /Users/me/corenlp/ should be changed to the path where you put CoreNLP:",change /Users/me/corenlp/ to path,1,https://stanfordnlp.github.io/CoreNLP/cmdline.html
CoreNLP,"Alternatively, you can [add this path to your CLASSPATH environment variable](https://en.wikipedia.org/wiki/Classpath_(Java%29), so these libraries are always available.",add path to CLASSPATH environment variable,0,
CoreNLP,"The “*” (which must be enclosed in quotes) says to add all JAR files in the given directory to the classpath. You can also individually specify the needed jar files. Use the following sort of command line, adjusting the JAR file date extensions VV to your downloaded release.",add JAR files in given directory,1,https://stanfordnlp.github.io/CoreNLP/cmdline.html
CoreNLP,"The “*” (which must be enclosed in quotes) says to add all JAR files in the given directory to the classpath. You can also individually specify the needed jar files. Use the following sort of command line, adjusting the JAR file date extensions VV to your downloaded release.",specify needed jar files,1,https://stanfordnlp.github.io/CoreNLP/cmdline.html
CoreNLP,"The “*” (which must be enclosed in quotes) says to add all JAR files in the given directory to the classpath. You can also individually specify the needed jar files. Use the following sort of command line, adjusting the JAR file date extensions VV to your downloaded release.",use following sort of command line,1,https://stanfordnlp.github.io/CoreNLP/cmdline.html
CoreNLP,"The command above works for Mac OS X or Linux. For Windows, the colons (:) separating the jar files need to be semi-colons (;). If you are not sitting in the distribution directory, you’ll also need to include a path to the files before each.",include path to files,0,
CoreNLP,"Before using Stanford CoreNLP, it is usual to create a configuration file (a Java Properties file). Minimally, this file should contain the “annotators” property, which contains a comma-separated list of Annotators to use. For example, the setting below enables: tokenization, sentence splitting (required by most Annotators), POS tagging, lemmatization, NER, (constituency) parsing, and (rule-based) coreference resolution.",use Stanford CoreNLP,0,
CoreNLP,"Before using Stanford CoreNLP, it is usual to create a configuration file (a Java Properties file). Minimally, this file should contain the “annotators” property, which contains a comma-separated list of Annotators to use. For example, the setting below enables: tokenization, sentence splitting (required by most Annotators), POS tagging, lemmatization, NER, (constituency) parsing, and (rule-based) coreference resolution.",create configuration file,0,
CoreNLP,"Before using Stanford CoreNLP, it is usual to create a configuration file (a Java Properties file). Minimally, this file should contain the “annotators” property, which contains a comma-separated list of Annotators to use. For example, the setting below enables: tokenization, sentence splitting (required by most Annotators), POS tagging, lemmatization, NER, (constituency) parsing, and (rule-based) coreference resolution.",enable lemmatization,0,
CoreNLP,"Before using Stanford CoreNLP, it is usual to create a configuration file (a Java Properties file). Minimally, this file should contain the “annotators” property, which contains a comma-separated list of Annotators to use. For example, the setting below enables: tokenization, sentence splitting (required by most Annotators), POS tagging, lemmatization, NER, (constituency) parsing, and (rule-based) coreference resolution.",enable NER,0,
CoreNLP,"Before using Stanford CoreNLP, it is usual to create a configuration file (a Java Properties file). Minimally, this file should contain the “annotators” property, which contains a comma-separated list of Annotators to use. For example, the setting below enables: tokenization, sentence splitting (required by most Annotators), POS tagging, lemmatization, NER, (constituency) parsing, and (rule-based) coreference resolution.",enable parsing,0,
CoreNLP,"Before using Stanford CoreNLP, it is usual to create a configuration file (a Java Properties file). Minimally, this file should contain the “annotators” property, which contains a comma-separated list of Annotators to use. For example, the setting below enables: tokenization, sentence splitting (required by most Annotators), POS tagging, lemmatization, NER, (constituency) parsing, and (rule-based) coreference resolution.",enable tokenization,0,
CoreNLP,"Before using Stanford CoreNLP, it is usual to create a configuration file (a Java Properties file). Minimally, this file should contain the “annotators” property, which contains a comma-separated list of Annotators to use. For example, the setting below enables: tokenization, sentence splitting (required by most Annotators), POS tagging, lemmatization, NER, (constituency) parsing, and (rule-based) coreference resolution.",enable coreference resolution,0,
CoreNLP,"Before using Stanford CoreNLP, it is usual to create a configuration file (a Java Properties file). Minimally, this file should contain the “annotators” property, which contains a comma-separated list of Annotators to use. For example, the setting below enables: tokenization, sentence splitting (required by most Annotators), POS tagging, lemmatization, NER, (constituency) parsing, and (rule-based) coreference resolution.",enable sentence splitting,0,
CoreNLP,"Before using Stanford CoreNLP, it is usual to create a configuration file (a Java Properties file). Minimally, this file should contain the “annotators” property, which contains a comma-separated list of Annotators to use. For example, the setting below enables: tokenization, sentence splitting (required by most Annotators), POS tagging, lemmatization, NER, (constituency) parsing, and (rule-based) coreference resolution.",enable POS tagging,0,
CoreNLP,"To use the properties in the properties file sampleProps.properties, you give a command as follows:",use properties in properties file sampleProps.properties,1,https://stanfordnlp.github.io/CoreNLP/cmdline.html
CoreNLP,"However, if you just want to specify a few properties, you can instead place them on the command line. For example, we can specify annotators and the output format with:",specify few properties,1,https://stanfordnlp.github.io/CoreNLP/cmdline.html
CoreNLP,"However, if you just want to specify a few properties, you can instead place them on the command line. For example, we can specify annotators and the output format with:",place  on command line,1,https://stanfordnlp.github.io/CoreNLP/cmdline.html
CoreNLP,"However, if you just want to specify a few properties, you can instead place them on the command line. For example, we can specify annotators and the output format with:",specify annotators,1,https://stanfordnlp.github.io/CoreNLP/cmdline.html
CoreNLP,"However, if you just want to specify a few properties, you can instead place them on the command line. For example, we can specify annotators and the output format with:",specify output format,1,https://stanfordnlp.github.io/CoreNLP/cmdline.html
CoreNLP,"The -props parameter is optional. By default, Stanford CoreNLP will search for StanfordCoreNLP.properties in your classpath and use the defaults included in the distribution.",use defaults,0,
CoreNLP,"The -props parameter is optional. By default, Stanford CoreNLP will search for StanfordCoreNLP.properties in your classpath and use the defaults included in the distribution.",search  by default,0,
CoreNLP,"The -props parameter is optional. By default, Stanford CoreNLP will search for StanfordCoreNLP.properties in your classpath and use the defaults included in the distribution.",search  for StanfordCoreNLP.properties,0,
CoreNLP,"The -props parameter is optional. By default, Stanford CoreNLP will search for StanfordCoreNLP.properties in your classpath and use the defaults included in the distribution.",include  in distribution,0,
CoreNLP,"The -annotators argument is also optional. If you leave it out, the code uses a built in properties file, which enables the following annotators: tokenization and sentence splitting, POS tagging, lemmatization, NER, dependency parsing, and statistical coreference resolution: annotators = tokenize, ssplit, pos, lemma, ner, depparse, coref.",use built file,0,
CoreNLP,"The -annotators argument is also optional. If you leave it out, the code uses a built in properties file, which enables the following annotators: tokenization and sentence splitting, POS tagging, lemmatization, NER, dependency parsing, and statistical coreference resolution: annotators = tokenize, ssplit, pos, lemma, ner, depparse, coref.",build  in properties,0,
CoreNLP,"The -annotators argument is also optional. If you leave it out, the code uses a built in properties file, which enables the following annotators: tokenization and sentence splitting, POS tagging, lemmatization, NER, dependency parsing, and statistical coreference resolution: annotators = tokenize, ssplit, pos, lemma, ner, depparse, coref.",enable built file,0,
CoreNLP,"If you have a lot of text but all you want to do is to, say, get part-of-speech (POS) tags, then you should definitely specify an annotators list, as above, since you can then omit later annotators which invoke much more expensive processing that you don’t need. For example, you might give the command:",get part-of-speech tags,1,https://stanfordnlp.github.io/CoreNLP/cmdline.html
CoreNLP,"If you have a lot of text but all you want to do is to, say, get part-of-speech (POS) tags, then you should definitely specify an annotators list, as above, since you can then omit later annotators which invoke much more expensive processing that you don’t need. For example, you might give the command:",specify annotators list,1,https://stanfordnlp.github.io/CoreNLP/cmdline.html
CoreNLP,"If you have a lot of text but all you want to do is to, say, get part-of-speech (POS) tags, then you should definitely specify an annotators list, as above, since you can then omit later annotators which invoke much more expensive processing that you don’t need. For example, you might give the command:",omit later annotators,1,https://stanfordnlp.github.io/CoreNLP/cmdline.html
CoreNLP,"We provide a small shell script corenlp.sh. On Linux or OS X, this may be useful in allowing you to type shorter command lines to invoke CoreNLP. For example, you can instead say:",provide small shell script corenlp.sh,1,https://stanfordnlp.github.io/CoreNLP/cmdline.html
CoreNLP,"You first have to have available a models jar file for the language you wish to use. You can download it from this site or you can use the models file on Maven Central. If using Maven, you add it to your pom file like this:",download  from site,1,https://stanfordnlp.github.io/CoreNLP/cmdline.html
CoreNLP,"You first have to have available a models jar file for the language you wish to use. You can download it from this site or you can use the models file on Maven Central. If using Maven, you add it to your pom file like this:",use models file on maven Central,1,https://stanfordnlp.github.io/CoreNLP/cmdline.html
CoreNLP,"You first have to have available a models jar file for the language you wish to use. You can download it from this site or you can use the models file on Maven Central. If using Maven, you add it to your pom file like this:",use maven,1,https://stanfordnlp.github.io/CoreNLP/cmdline.html
CoreNLP,"You first have to have available a models jar file for the language you wish to use. You can download it from this site or you can use the models file on Maven Central. If using Maven, you add it to your pom file like this:",add  to pom file,1,https://stanfordnlp.github.io/CoreNLP/cmdline.html
CoreNLP,"Our examples assume that you are in the root directory of CoreNLP and that these extra jar files are also available there. Each language jar contains a default properties file for the appropriate language. Working with text in another language is then as easy as specifying this properties file. For example, for Chinese:",specify properties file,1,https://stanfordnlp.github.io/CoreNLP/cmdline.html
CoreNLP,You can as usual specify details on the annotators and properties:,specify details on annotators,1,https://stanfordnlp.github.io/CoreNLP/cmdline.html
CoreNLP,You can as usual specify details on the annotators and properties:,specify details on properties,1,https://stanfordnlp.github.io/CoreNLP/cmdline.html
CoreNLP,"To process one file, use the -file option followed by a filename. To process a list of files, use the -fileList parameter:",process file,1,https://stanfordnlp.github.io/CoreNLP/cmdline.html
CoreNLP,"To process one file, use the -file option followed by a filename. To process a list of files, use the -fileList parameter:",process list of files,1,https://stanfordnlp.github.io/CoreNLP/cmdline.html
CoreNLP,"If you do not specify any properties that load input files (and do not specify any input or output redirections), then you will be placed in the interactive shell. Type q to exit.",place  in interactive shell,0,
CoreNLP,"If you do not specify an option that loads input files and you redirect either input or output, then Stanford CoreNLP runs as a filter that reads from stdin and writes to stdout. The default mode is line-oriented: Each line of input counts as a document. If you give the flag/property -isOneDocument (isOneDocument = true) then the input till end-of-file will be treated as one document.",run  as filter,0,
CoreNLP,"If you do not specify an option that loads input files and you redirect either input or output, then Stanford CoreNLP runs as a filter that reads from stdin and writes to stdout. The default mode is line-oriented: Each line of input counts as a document. If you give the flag/property -isOneDocument (isOneDocument = true) then the input till end-of-file will be treated as one document.",write filter,0,
CoreNLP,"If your input files have XML tags in them, you may wish to add the cleanxml annotator to preprocess it. Place it immediately after tokenize.",add cleanxml annotator,0,
CoreNLP,"If your input files have XML tags in them, you may wish to add the cleanxml annotator to preprocess it. Place it immediately after tokenize.",place  after tokenize,0,
CoreNLP,"If your input is already tokenzed and one sentence per line, then you should use the flags: -tokenize.whitespace -ssplit.eolonly.",use flags,0,
CoreNLP,"Fine point: Stanford CoreNLP treats Unicode end of line markers (LS U+2028 and PS U+2029) as line ends, whereas conventional Unix utilities do not. If these characters are present and you are using CoreNLP in a Unix line-oriented processing pipeline, you may need to remap these characters to ‘\n’ or ‘ ‘ at the start of your processing pipeline.",use CoreNLP in Unix line-oriented processing pipeline,0,
CoreNLP,"If (and only if) the input filename ends with “.ser.gz” then CoreNLP will interpret the file as the output of a previous annotation run, to which you presumably want to add on further annotations. CoreNLP will read these Annotations using the class specified in the inputSerializer property. The options for this are the same as for outputSerializer below. Note: To successfully load a pipeline for layering on additional annotations, you need to include the property enforceRequirements = false to avoid complaints about required earlier annotators not being present in the pipeline.",add  on further annotations,0,
CoreNLP,"If (and only if) the input filename ends with “.ser.gz” then CoreNLP will interpret the file as the output of a previous annotation run, to which you presumably want to add on further annotations. CoreNLP will read these Annotations using the class specified in the inputSerializer property. The options for this are the same as for outputSerializer below. Note: To successfully load a pipeline for layering on additional annotations, you need to include the property enforceRequirements = false to avoid complaints about required earlier annotators not being present in the pipeline.",use class,0,
CoreNLP,"If (and only if) the input filename ends with “.ser.gz” then CoreNLP will interpret the file as the output of a previous annotation run, to which you presumably want to add on further annotations. CoreNLP will read these Annotations using the class specified in the inputSerializer property. The options for this are the same as for outputSerializer below. Note: To successfully load a pipeline for layering on additional annotations, you need to include the property enforceRequirements = false to avoid complaints about required earlier annotators not being present in the pipeline.",specify  in inputSerializer property,0,
CoreNLP,"If (and only if) the input filename ends with “.ser.gz” then CoreNLP will interpret the file as the output of a previous annotation run, to which you presumably want to add on further annotations. CoreNLP will read these Annotations using the class specified in the inputSerializer property. The options for this are the same as for outputSerializer below. Note: To successfully load a pipeline for layering on additional annotations, you need to include the property enforceRequirements = false to avoid complaints about required earlier annotators not being present in the pipeline.",load pipeline for layering,0,
CoreNLP,"For each input file, Stanford CoreNLP generates one output file, with a name that adds an extra extension to the input filename. (If reading input from stdin, then it will send output to stdout.) The output may contain the output of all annotations that were done, or just a subset of them. For the first example under Quick Start above, with input.txt containing the text below:",add extra extension to input filename,0,
CoreNLP,"For each input file, Stanford CoreNLP generates one output file, with a name that adds an extra extension to the input filename. (If reading input from stdin, then it will send output to stdout.) The output may contain the output of all annotations that were done, or just a subset of them. For the first example under Quick Start above, with input.txt containing the text below:",add name to input filename,0,
CoreNLP,"Note that this XML output can use the CoreNLP-to-HTML.xsl stylesheet file, which comes with the CoreNLP download or can be downloaded from here. This stylesheet enables human-readable display of the above XML content. For example, this example should display like this.",use CoreNLP-to-HTML.xsl stylesheet file,0,
CoreNLP,"Note that this XML output can use the CoreNLP-to-HTML.xsl stylesheet file, which comes with the CoreNLP download or can be downloaded from here. This stylesheet enables human-readable display of the above XML content. For example, this example should display like this.",download CoreNLP-to-HTML.xsl stylesheet file,0,
CoreNLP,"Note that this XML output can use the CoreNLP-to-HTML.xsl stylesheet file, which comes with the CoreNLP download or can be downloaded from here. This stylesheet enables human-readable display of the above XML content. For example, this example should display like this.",enable human-readable display of above XML content,0,
CoreNLP,"The value of the outputSerializer property is the name of a class which extends edu.stanford.nlp.pipeline.AnnotationSerializer. Valid choices include: edu.stanford.nlp.pipeline.GenericAnnotationSerializer, edu.stanford.nlp.pipeline.CustomAnnotationSerializer, edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer; edu.stanford.nlp.kbp.common.KBPProtobufAnnotationSerializer, edu.stanford.nlp.kbp.slotfilling.ir.index.KryoAnnotationSerializer. If unspecified the value of the serializer property will be tried instead. If it is also not defined, the default is to use edu.stanford.nlp.pipeline.GenericAnnotationSerializer.",include valid choices,0,
CoreNLP,"The value of the outputSerializer property is the name of a class which extends edu.stanford.nlp.pipeline.AnnotationSerializer. Valid choices include: edu.stanford.nlp.pipeline.GenericAnnotationSerializer, edu.stanford.nlp.pipeline.CustomAnnotationSerializer, edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer; edu.stanford.nlp.kbp.common.KBPProtobufAnnotationSerializer, edu.stanford.nlp.kbp.slotfilling.ir.index.KryoAnnotationSerializer. If unspecified the value of the serializer property will be tried instead. If it is also not defined, the default is to use edu.stanford.nlp.pipeline.GenericAnnotationSerializer.",use edu.stanford.nlp.pipeline.GenericAnnotationSerializer,0,
CoreNLP,"The ProtobufAnnotationSerializer is a non-lossy annotation serialization. It uses the Java methods writeDelimitedTo() and parseDelimitedFrom(), which allow sending several length-prefixed messages in one stream. Unfortunately, Google has declined to implement these methods for Python or C++. You can get information from Stack Overflow and other places on how to roll your own version for C++ or Python. Probably the best place is here but there are many other sources of information including: here, here, here, and here. This Stack Overflow question explicitly addresses the issue for CoreNLP.",use Java methods,0,
CoreNLP,"The ProtobufAnnotationSerializer is a non-lossy annotation serialization. It uses the Java methods writeDelimitedTo() and parseDelimitedFrom(), which allow sending several length-prefixed messages in one stream. Unfortunately, Google has declined to implement these methods for Python or C++. You can get information from Stack Overflow and other places on how to roll your own version for C++ or Python. Probably the best place is here but there are many other sources of information including: here, here, here, and here. This Stack Overflow question explicitly addresses the issue for CoreNLP.",send several length-prefixed messages in stream,0,
CoreNLP,"The ProtobufAnnotationSerializer is a non-lossy annotation serialization. It uses the Java methods writeDelimitedTo() and parseDelimitedFrom(), which allow sending several length-prefixed messages in one stream. Unfortunately, Google has declined to implement these methods for Python or C++. You can get information from Stack Overflow and other places on how to roll your own version for C++ or Python. Probably the best place is here but there are many other sources of information including: here, here, here, and here. This Stack Overflow question explicitly addresses the issue for CoreNLP.",get information from Stack overflow,0,
CoreNLP,"The ProtobufAnnotationSerializer is a non-lossy annotation serialization. It uses the Java methods writeDelimitedTo() and parseDelimitedFrom(), which allow sending several length-prefixed messages in one stream. Unfortunately, Google has declined to implement these methods for Python or C++. You can get information from Stack Overflow and other places on how to roll your own version for C++ or Python. Probably the best place is here but there are many other sources of information including: here, here, here, and here. This Stack Overflow question explicitly addresses the issue for CoreNLP.",get information from other places,0,
CoreNLP,"In all output formats (and in our code), we number sentences and character offsets from 0 and we number tokens from 1. We realize that this is inconsistent! However, it seemed to be the best thing to do. Numbering character offsets from 0 is the only good choice, given how the Java String class and most modern programming languages work, following Dijkstra’s arguments for indexing from 0 (which were influential at the time if not necessarily so water-tight). Numbering tokens from 1 not only corresponds to the human-natural convention (“the first word of the sentence”) but most importantly is consistent with common NLP standards, such as the CoNLL formats used from CoNLL-X through CoNLL 2009, etc., and in CoNLL-U, which number tokens starting from 1. For sentences, we could then choose to be consistent with either but not both of the above. We went with 0-indexing.",use  through CoNLL,0,
CoreNLP,"In all output formats (and in our code), we number sentences and character offsets from 0 and we number tokens from 1. We realize that this is inconsistent! However, it seemed to be the best thing to do. Numbering character offsets from 0 is the only good choice, given how the Java String class and most modern programming languages work, following Dijkstra’s arguments for indexing from 0 (which were influential at the time if not necessarily so water-tight). Numbering tokens from 1 not only corresponds to the human-natural convention (“the first word of the sentence”) but most importantly is consistent with common NLP standards, such as the CoNLL formats used from CoNLL-X through CoNLL 2009, etc., and in CoNLL-U, which number tokens starting from 1. For sentences, we could then choose to be consistent with either but not both of the above. We went with 0-indexing.",use  from conll-x,0,
CoreNLP,"In all output formats (and in our code), we number sentences and character offsets from 0 and we number tokens from 1. We realize that this is inconsistent! However, it seemed to be the best thing to do. Numbering character offsets from 0 is the only good choice, given how the Java String class and most modern programming languages work, following Dijkstra’s arguments for indexing from 0 (which were influential at the time if not necessarily so water-tight). Numbering tokens from 1 not only corresponds to the human-natural convention (“the first word of the sentence”) but most importantly is consistent with common NLP standards, such as the CoNLL formats used from CoNLL-X through CoNLL 2009, etc., and in CoNLL-U, which number tokens starting from 1. For sentences, we could then choose to be consistent with either but not both of the above. We went with 0-indexing.",choose  for sentences,0,
CoreNLP,CoreNLP’s default character encoding is Unicode’s UTF-8. You can change the encoding used by supplying the program with the command line flag -encoding FOO (or including the corresponding property in a properties file that you are using). We’ve done a lot of careful work to make sure CoreNLP works with any character encoding supported by Java. Want to use ISO-8859-15 or GB18030? Be our guest!,change encoding,0,
CoreNLP,CoreNLP’s default character encoding is Unicode’s UTF-8. You can change the encoding used by supplying the program with the command line flag -encoding FOO (or including the corresponding property in a properties file that you are using). We’ve done a lot of careful work to make sure CoreNLP works with any character encoding supported by Java. Want to use ISO-8859-15 or GB18030? Be our guest!,encode FOO,0,
CoreNLP,Have a support question? Please create an issue on github,create issue on github,0,
CoreNLP,"We have 3 mailing lists for Stanford CoreNLP, all of which are shared with other JavaNLP tools (with the exclusion of the parser). Each address is at @lists.stanford.edu:",share Stanford CoreNLP with other JavaNLP tools,0,
CoreNLP,"java-nlp-user This is the best list to post to in order to send feature requests, make announcements, or for discussion among JavaNLP users. (Please ask support questions on github.) You have to subscribe to be able to use this list. Join the list via this webpage or by emailing java-nlp-user-join@lists.stanford.edu. (Leave the subject and message body empty.) You can also look at the list archives.",send feature requests,0,
CoreNLP,"java-nlp-user This is the best list to post to in order to send feature requests, make announcements, or for discussion among JavaNLP users. (Please ask support questions on github.) You have to subscribe to be able to use this list. Join the list via this webpage or by emailing java-nlp-user-join@lists.stanford.edu. (Leave the subject and message body empty.) You can also look at the list archives.",use list,0,
CoreNLP,java-nlp-announce This list will be used only to announce new versions of Stanford JavaNLP tools. So it will be very low volume (expect 2-4 messages a year). Join the list via this webpage or by emailing java-nlp-announce-join@lists.stanford.edu. (Leave the subject and message body empty.),use java-nlp-announce list,0,
CoreNLP,"java-nlp-support This list goes only to the software maintainers. It’s a good address for licensing questions, etc. For general use and support questions, you’re better off using github or joining and using java-nlp-user. You cannot join java-nlp-support, but you can mail questions to java-nlp-support@lists.stanford.edu.",use github,0,
CoreNLP,"java-nlp-support This list goes only to the software maintainers. It’s a good address for licensing questions, etc. For general use and support questions, you’re better off using github or joining and using java-nlp-user. You cannot join java-nlp-support, but you can mail questions to java-nlp-support@lists.stanford.edu.",use github,0,
CoreNLP,"The CorefAnnotator finds mentions of the same entity in a text, such as when “Theresa May” and “she” refer to the same person. The annotator implements both pronominal and nominal coreference resolution. The entire coreference graph (with head words of mentions as nodes) is saved as a CorefChainAnnotation.",save entire coreference graph as CorefChainAnnotation,0,
CoreNLP,"Statistical: Machine-learning-based coreference resolution for English. Unlike the other systems, this one only requires dependency parses, which are faster to produce than constituency parses.",produce  than constituency parses,0,
CoreNLP,"The F1 scores are on the CoNLL 2012 evaluation data. Numbers are lower than reported in the associated papers because these models are designed for general-purpose use, not getting a high CoNLL score (see Running on CoNLL 2012).",design models for general-purpose use,0,
CoreNLP,"The speed measurements show the average time for processing a document in the CoNLL 2012 test set using a 2013 Macbook Pro with a 2.4 GHz Intel Core i7 processor. Preprocessing speed measures the time required for POS tagging, syntax parsing, mention detection, etc., while coref speed refers to the time spent by the coreference system.",show average time for processing,0,
CoreNLP,"The speed measurements show the average time for processing a document in the CoNLL 2012 test set using a 2013 Macbook Pro with a 2.4 GHz Intel Core i7 processor. Preprocessing speed measures the time required for POS tagging, syntax parsing, mention detection, etc., while coref speed refers to the time spent by the coreference system.",process document in CoNLL test,0,
CoreNLP,"The speed measurements show the average time for processing a document in the CoNLL 2012 test set using a 2013 Macbook Pro with a 2.4 GHz Intel Core i7 processor. Preprocessing speed measures the time required for POS tagging, syntax parsing, mention detection, etc., while coref speed refers to the time spent by the coreference system.",use macbook pro with ghz Intel core i7 processor,0,
CoreNLP,"There are example properties files for using the coreference systems in edu/stanford/nlp/coref/properties. The properties are named [system]-[language].properties. For example, to run the deterministic system on Chinese:",use coreference systems,1,https://stanfordnlp.github.io/CoreNLP/coref.html
CoreNLP,"There are example properties files for using the coreference systems in edu/stanford/nlp/coref/properties. The properties are named [system]-[language].properties. For example, to run the deterministic system on Chinese:",run deterministic system on chinese,1,https://stanfordnlp.github.io/CoreNLP/coref.html
CoreNLP,"Alternatively, the properties can be set manually. For example, to run the neural system on English:",set properties,1,https://stanfordnlp.github.io/CoreNLP/coref.html
CoreNLP,"Alternatively, the properties can be set manually. For example, to run the neural system on English:",run neural system on english,1,https://stanfordnlp.github.io/CoreNLP/coref.html
CoreNLP,The following example shows how to access coref and mention information from an Annotation:,access coref,1,https://stanfordnlp.github.io/CoreNLP/coref.html
CoreNLP,"This is a mention-ranking model using a large set of features. It operates by iterating through each mention in the document, possibly adding a coreference link between the current one and a preceding mention at each step. Some relevant options:",use large set of features,0,
CoreNLP,"This is a mention-ranking model using a large set of features. It operates by iterating through each mention in the document, possibly adding a coreference link between the current one and a preceding mention at each step. Some relevant options:",add coreference link between preceding mention,0,
CoreNLP,"coref.maxMentionDistanceWithStringMatch: The system will consider linking the current mention to a preceding one further than coref.maxMentionDistance away if they share a noun or proper noun. In this case, it looks coref.maxMentionDistanceWithStringMatch away instead. The default value is 500.",link current mention,0,
CoreNLP,"coref.maxMentionDistanceWithStringMatch: The system will consider linking the current mention to a preceding one further than coref.maxMentionDistance away if they share a noun or proper noun. In this case, it looks coref.maxMentionDistanceWithStringMatch away instead. The default value is 500.",share noun,0,
CoreNLP,"coref.maxMentionDistanceWithStringMatch: The system will consider linking the current mention to a preceding one further than coref.maxMentionDistance away if they share a noun or proper noun. In this case, it looks coref.maxMentionDistanceWithStringMatch away instead. The default value is 500.",share proper noun,0,
CoreNLP,"coref.statisical.pairwiseScoreThresholds: A number between 0 and 1 determining how greedy the model is about making coreference decisions. A value of 0 causes the system to add no coreference links and a value of 1 causes the system to link every pair of mentions, combining them all into a single coreference cluster. The default value is 0.35. The value can also be a comma-separated list of 4 numbers, in which case there are separate thresholds for when both mentions are pronouns, only the first mention is a pronoun, only the last mention is a pronoun, and neither mention is a pronoun.",add coreference links,0,
CoreNLP,"coref.statisical.pairwiseScoreThresholds: A number between 0 and 1 determining how greedy the model is about making coreference decisions. A value of 0 causes the system to add no coreference links and a value of 1 causes the system to link every pair of mentions, combining them all into a single coreference cluster. The default value is 0.35. The value can also be a comma-separated list of 4 numbers, in which case there are separate thresholds for when both mentions are pronouns, only the first mention is a pronoun, only the last mention is a pronoun, and neither mention is a pronoun.",link pair of mentions,0,
CoreNLP,"To use the English deterministic system, you need to use the dcoref annotator.",use English deterministic system,1,https://stanfordnlp.github.io/CoreNLP/coref.html
CoreNLP,"To use the English deterministic system, you need to use the dcoref annotator.",use dcoref annotator,1,https://stanfordnlp.github.io/CoreNLP/coref.html
CoreNLP,If you would like to run our statistical or neural systems on the CoNLL 2012 eval data:,run neural systems on CoNLL eval data,1,https://stanfordnlp.github.io/CoreNLP/coref.html
CoreNLP,"Because of this, we train models with a few extra features for running on this dataset. We configure these models for accuracy over speed (e.g., by not having a maximum mention distance for the mention-ranking models). These models can be run using the -conll properties files (e.g., neural-english-conll.properties). Note that the CoNLL-specific models for English are in the English models jar, not the default CoreNLP models jar.",run  on dataset,0,
CoreNLP,"Because of this, we train models with a few extra features for running on this dataset. We configure these models for accuracy over speed (e.g., by not having a maximum mention distance for the mention-ranking models). These models can be run using the -conll properties files (e.g., neural-english-conll.properties). Note that the CoNLL-specific models for English are in the English models jar, not the default CoreNLP models jar.",configure models for accuracy,0,
CoreNLP,"Because of this, we train models with a few extra features for running on this dataset. We configure these models for accuracy over speed (e.g., by not having a maximum mention distance for the mention-ranking models). These models can be run using the -conll properties files (e.g., neural-english-conll.properties). Note that the CoNLL-specific models for English are in the English models jar, not the default CoreNLP models jar.",run models,0,
CoreNLP,"As a rule-based system, there is nothing to train, but there are various data files for demonyms and to indicate noun gender, animacy, and plurality, which can be edited. See the Stanford Deterministic Coreference Resolution System page.",edit plurality,0,
CoreNLP,"See here for an example properties file. Training over the full CoNLL 2012 training set requires a large amount of memory. To reduce the memory footprint and runtime of training, the following options can be added to the properties file:",add following options to properties file,0,
CoreNLP,"CoreNLP includes a simple web API server for servicing your human language understanding needs (starting with version 3.6.0). This page describes how to set it up. CoreNLP server provides both a convenient graphical way to interface with your installation of CoreNLP and an API with which to call CoreNLP using any programming language. If you’re writing a new wrapper of CoreNLP for using it in another language, you’re advised to do it using the CoreNLP Server.",include simple web API server for servicing,0,
CoreNLP,"CoreNLP includes a simple web API server for servicing your human language understanding needs (starting with version 3.6.0). This page describes how to set it up. CoreNLP server provides both a convenient graphical way to interface with your installation of CoreNLP and an API with which to call CoreNLP using any programming language. If you’re writing a new wrapper of CoreNLP for using it in another language, you’re advised to do it using the CoreNLP Server.",call CoreNLP,0,
CoreNLP,"CoreNLP includes a simple web API server for servicing your human language understanding needs (starting with version 3.6.0). This page describes how to set it up. CoreNLP server provides both a convenient graphical way to interface with your installation of CoreNLP and an API with which to call CoreNLP using any programming language. If you’re writing a new wrapper of CoreNLP for using it in another language, you’re advised to do it using the CoreNLP Server.",use programming language,0,
CoreNLP,"CoreNLP includes a simple web API server for servicing your human language understanding needs (starting with version 3.6.0). This page describes how to set it up. CoreNLP server provides both a convenient graphical way to interface with your installation of CoreNLP and an API with which to call CoreNLP using any programming language. If you’re writing a new wrapper of CoreNLP for using it in another language, you’re advised to do it using the CoreNLP Server.",write new wrapper of CoreNLP,0,
CoreNLP,"CoreNLP includes a simple web API server for servicing your human language understanding needs (starting with version 3.6.0). This page describes how to set it up. CoreNLP server provides both a convenient graphical way to interface with your installation of CoreNLP and an API with which to call CoreNLP using any programming language. If you’re writing a new wrapper of CoreNLP for using it in another language, you’re advised to do it using the CoreNLP Server.",use  in language,0,
CoreNLP,"CoreNLP includes a simple web API server for servicing your human language understanding needs (starting with version 3.6.0). This page describes how to set it up. CoreNLP server provides both a convenient graphical way to interface with your installation of CoreNLP and an API with which to call CoreNLP using any programming language. If you’re writing a new wrapper of CoreNLP for using it in another language, you’re advised to do it using the CoreNLP Server.",use CoreNLP server,0,
CoreNLP,"Stanford CoreNLP ships with a built-in server, which requires only the CoreNLP dependencies. To run this server, simply run:",run server,1,https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
CoreNLP,"If you want to process non-English languages, use this command with the appropriate language properties:",process non-english languages,1,https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
CoreNLP,"If you want to process non-English languages, use this command with the appropriate language properties:",use command with appropriate language properties,1,https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
CoreNLP,"If no value for port is provided, port 9000 will be used by default. You can then test your server by visiting",use port,1,https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
CoreNLP,"If no value for port is provided, port 9000 will be used by default. You can then test your server by visiting",provide value for port,1,https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
CoreNLP,"If no value for port is provided, port 9000 will be used by default. You can then test your server by visiting",test server by visiting,1,https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
CoreNLP,"You should see a website similar to corenlp.run, with an input box for text and a list of annotators you can run. From this interface, you can test out each of the annotators by adding/removing them from this list. (Note: The first use will be slow to respond while models are loaded – it might take 30 seconds or so, but after that the server should run quite quickly.) You can test out the API by sending a POST request to the server with the appropriate properties. An easy way to do this is with wget. The following will annotate the sentence “the quick brown fox jumped over the lazy dog” with part of speech tags:",run annotators,1,https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
CoreNLP,"You should see a website similar to corenlp.run, with an input box for text and a list of annotators you can run. From this interface, you can test out each of the annotators by adding/removing them from this list. (Note: The first use will be slow to respond while models are loaded – it might take 30 seconds or so, but after that the server should run quite quickly.) You can test out the API by sending a POST request to the server with the appropriate properties. An easy way to do this is with wget. The following will annotate the sentence “the quick brown fox jumped over the lazy dog” with part of speech tags:",send POST request to server,1,https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
CoreNLP,"Or finally, here’s a minimal Python program that interfaces with this endpoint using the requests library:",use requests library,1,https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
CoreNLP,"The rest of this document: describes the API in more detail, describes a Java client to the API as a drop-in replacement for the StanfordCoreNLP annotator pipeline, and talks about administering the server. If you’re using Python or another programming language, we don’t suggest that you start with the minimal example above, but rather first look through available other language APIs that use the CoreNLP server.",use Python,0,
CoreNLP,"The rest of this document: describes the API in more detail, describes a Java client to the API as a drop-in replacement for the StanfordCoreNLP annotator pipeline, and talks about administering the server. If you’re using Python or another programming language, we don’t suggest that you start with the minimal example above, but rather first look through available other language APIs that use the CoreNLP server.",use programming language,0,
CoreNLP,"The rest of this document: describes the API in more detail, describes a Java client to the API as a drop-in replacement for the StanfordCoreNLP annotator pipeline, and talks about administering the server. If you’re using Python or another programming language, we don’t suggest that you start with the minimal example above, but rather first look through available other language APIs that use the CoreNLP server.",use CoreNLP server,0,
CoreNLP,"The rest of this document: describes the API in more detail, describes a Java client to the API as a drop-in replacement for the StanfordCoreNLP annotator pipeline, and talks about administering the server. If you’re using Python or another programming language, we don’t suggest that you start with the minimal example above, but rather first look through available other language APIs that use the CoreNLP server.",use available other language apis,0,
CoreNLP,NOTE: Please do not make API calls against corenlp.run. It is not set up to handle a large volume of requests. Instructions for setting up your own server can be found in the Dedicated Server section.,handle large volume of requests,0,
CoreNLP,NOTE: Please do not make API calls against corenlp.run. It is not set up to handle a large volume of requests. Instructions for setting up your own server can be found in the Dedicated Server section.,set up own server,0,
CoreNLP,"This endpoint takes as input a JSON-formatted properties string under the key properties=, and as POSTdata text to annotate. The properties should mirror the properties file passed into the CoreNLP command line, except formatted as a JSON object. The POST data should be percent-encoded (otherwise known as URL encoded). In particular, you shoud esapce a % sign as %25. (Interfaces calling CoreNLP via the web service should do this escaping for their users.)",pass  into CoreNLP command line,0,
CoreNLP,"This endpoint takes as input a JSON-formatted properties string under the key properties=, and as POSTdata text to annotate. The properties should mirror the properties file passed into the CoreNLP command line, except formatted as a JSON object. The POST data should be percent-encoded (otherwise known as URL encoded). In particular, you shoud esapce a % sign as %25. (Interfaces calling CoreNLP via the web service should do this escaping for their users.)",format  as JSON object,0,
CoreNLP,"For example, the following command will tokenize the input text, run part of speech tagging, and output the result as JSON to standard out:",tokenize output as JSON,1,https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
CoreNLP,"For example, the following command will tokenize the input text, run part of speech tagging, and output the result as JSON to standard out:",tokenize output of speech tagging,1,https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
CoreNLP,"For example, the following command will tokenize the input text, run part of speech tagging, and output the result as JSON to standard out:",tokenize output to standard out,1,https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
CoreNLP,"For example, the following command will tokenize the input text, run part of speech tagging, and output the result as JSON to standard out:",tokenize input text as JSON,1,https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
CoreNLP,"For example, the following command will tokenize the input text, run part of speech tagging, and output the result as JSON to standard out:",tokenize input text of speech tagging,1,https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
CoreNLP,"For example, the following command will tokenize the input text, run part of speech tagging, and output the result as JSON to standard out:",tokenize input text to standard out,1,https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
CoreNLP,"For example, the following command will tokenize the input text, run part of speech tagging, and output the result as JSON to standard out:",tokenize run part as JSON,1,https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
CoreNLP,"For example, the following command will tokenize the input text, run part of speech tagging, and output the result as JSON to standard out:",tokenize run part of speech tagging,1,https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
CoreNLP,"For example, the following command will tokenize the input text, run part of speech tagging, and output the result as JSON to standard out:",tokenize run part to standard out,1,https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
CoreNLP,"A common property to set is the output format of the API. The server supports all output formats provided by CoreNLP. These are listed below, along with their relevant properties:",support output formats,0,
CoreNLP,"The server also accepts input in a variety of formats. By default, it takes input as raw text sent as POST data to the server. However, it can also be configured to read the POST data using one of the CoreNLP serializers. This can be set up by setting the properties inputFormat and inputSerializer. For example, to read the data as a protocol buffer (useful if, e.g., it is already partially annotated), simply include the following in your url parameter properties={...}:",send  as POST data,1,https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
CoreNLP,"The server also accepts input in a variety of formats. By default, it takes input as raw text sent as POST data to the server. However, it can also be configured to read the POST data using one of the CoreNLP serializers. This can be set up by setting the properties inputFormat and inputSerializer. For example, to read the data as a protocol buffer (useful if, e.g., it is already partially annotated), simply include the following in your url parameter properties={...}:",send  to server,1,https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
CoreNLP,"The server also accepts input in a variety of formats. By default, it takes input as raw text sent as POST data to the server. However, it can also be configured to read the POST data using one of the CoreNLP serializers. This can be set up by setting the properties inputFormat and inputSerializer. For example, to read the data as a protocol buffer (useful if, e.g., it is already partially annotated), simply include the following in your url parameter properties={...}:",set properties inputFormat,1,https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
CoreNLP,"The server also accepts input in a variety of formats. By default, it takes input as raw text sent as POST data to the server. However, it can also be configured to read the POST data using one of the CoreNLP serializers. This can be set up by setting the properties inputFormat and inputSerializer. For example, to read the data as a protocol buffer (useful if, e.g., it is already partially annotated), simply include the following in your url parameter properties={...}:",set inputSerializer,1,https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
CoreNLP,"A complete call to the server, taking as input a protobuf serialized document at path /path/to/file.proto and returning as a response a protobuf for the document annotated for part of speech and named entity tags (to the file /path/to/annotated_file.proto could be:",return  as response,1,https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
CoreNLP,"Similar to the CoreNLP target, /tokensregex takes a block of data (e.g., text) as POST data, and a series of url parameters. Currently, only plain-text POST data is supported. The two relevant url parameters are:",support plain-text POST data,1,https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
CoreNLP,"Similar to the CoreNLP target, and nearly identical to TokensRegex, /semgrex takes a block of data (e.g., text) as POST data, and a series of url parameters. Currently, only plain-text POST data is supported. The two relevant url parameters are:",support plain-text POST data,0,
CoreNLP,"The response is always in JSON, formatted identically to the tokensregex output, with the exception that all spans are single words (only the root of the match is returned):",format  to tokensregex output,1,https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
CoreNLP,CoreNLP includes a Java client to the server – StanfordCoreNLPClient – which mirrors the interface of the annotation pipeline (StanfordCoreNLP.java) as closely as possible. The primary motivating use cases for using this class and not the local pipeline are:,include Java client to server,1,https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
CoreNLP,CoreNLP includes a Java client to the server – StanfordCoreNLPClient – which mirrors the interface of the annotation pipeline (StanfordCoreNLP.java) as closely as possible. The primary motivating use cases for using this class and not the local pipeline are:,use class,1,https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
CoreNLP,"You can also run the client from the command line, and get an interface similar to the command line usage for the local CoreNLP program. The following will annotate a file input.txt with part-of-speech, lemmas, named entities, constituency parses, and coreference:",run client from command line,1,https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
CoreNLP,"You can also run the client from the command line, and get an interface similar to the command line usage for the local CoreNLP program. The following will annotate a file input.txt with part-of-speech, lemmas, named entities, constituency parses, and coreference:",get interface similar usage for local CoreNLP program,1,https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
CoreNLP,"NOTE: Again, please do not make API calls against http://corenlp.run. It is not set up to handle a large volume of requests. Instructions for setting up your own server can be found in the Dedicated Server section.",handle large volume of requests,0,
CoreNLP,"NOTE: Again, please do not make API calls against http://corenlp.run. It is not set up to handle a large volume of requests. Instructions for setting up your own server can be found in the Dedicated Server section.",set up own server,0,
CoreNLP,"Once you have your own server(s) set up, you can run against them with a command like this:",run  with command,1,https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
CoreNLP,You specify one or more back-end servers in a comma-separated list as the arguments of the -backends option. Each is specified as host:port.,specify back-end servers in comma-separated list,0,
CoreNLP,You specify one or more back-end servers in a comma-separated list as the arguments of the -backends option. Each is specified as host:port.,specify  as host:port,0,
CoreNLP,"Providing that the server has foreign language models available on its classpath, you can ask for it to work with texts in other languages. If you have the French properties file and a file called french.txt in your current directory, then you should be able to successfully give a command like this:",call french.txt in current directory,1,https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
CoreNLP,"The server is started directly though calling it with java. For example, the following will start the server in the background on port 1337, assuming your classpath is set properly:",call  with java,1,https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
CoreNLP,"The server is started directly though calling it with java. For example, the following will start the server in the background on port 1337, assuming your classpath is set properly:",set classpath,1,https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
CoreNLP,"The classpath must include all of the CoreNLP dependencies. The memory requirements of the server are the same as that of CoreNLP, though it will grow as you load more models (e.g., memory increases if you load both the PCFG and Shift-Reduce constituency parser models). A safe minimum is 4gb; 8gb is recommended if you can spare it.",load more models,0,
CoreNLP,"If running the server under docker, the container’s port 9000 has to be published to the host. Give a command like: docker run -p 9000:9000 --name coreNLP --rm -i -t frnkenstien/corenlp. If, when going to localhost:9000/, you see the error This site can’t be reached. localhost refused to connect, then this is what you failed to do!",run server under docker,0,
CoreNLP,"If running the server under docker, the container’s port 9000 has to be published to the host. Give a command like: docker run -p 9000:9000 --name coreNLP --rm -i -t frnkenstien/corenlp. If, when going to localhost:9000/, you see the error This site can’t be reached. localhost refused to connect, then this is what you failed to do!",reach site,0,
CoreNLP,"If running the server under docker, the container’s port 9000 has to be published to the host. Give a command like: docker run -p 9000:9000 --name coreNLP --rm -i -t frnkenstien/corenlp. If, when going to localhost:9000/, you see the error This site can’t be reached. localhost refused to connect, then this is what you failed to do!",reach error,0,
CoreNLP,"The server can be stopped programmatically by making a call to the /shutdown endpoint with an appropriate shutdown key. This key is saved to the file corenlp.shutdown in the directory specified by System.getProperty(""java.io.tmpdir""); when the server starts. Typically this will be /tmp/corenlp.shutdown, though it can vary, especially on macOS. An example command to shut down the server would be:",save key in directory,1,https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
CoreNLP,"The server can be stopped programmatically by making a call to the /shutdown endpoint with an appropriate shutdown key. This key is saved to the file corenlp.shutdown in the directory specified by System.getProperty(""java.io.tmpdir""); when the server starts. Typically this will be /tmp/corenlp.shutdown, though it can vary, especially on macOS. An example command to shut down the server would be:",save key to file corenlp.shutdown,1,https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
CoreNLP,If you start the server with -server_id SERVER_NAME it will store the shutdown key in a file called corenlp.shutdown.SERVER_NAME.,call corenlp.shutdown.SERVER_NAME,0,
CoreNLP,"This section describes how to set up a dedicated CoreNLP server on a fresh Linux install. These instructions are definitely okay on a CentOS 6 system, which is what our demo server runs on. We include a couple of notes of variations below. As always, make sure you understand the commands being run below, as they largely require root permissions:",set up dedicated CoreNLP server on fresh Linux,0,
CoreNLP,"This section describes how to set up a dedicated CoreNLP server on a fresh Linux install. These instructions are definitely okay on a CentOS 6 system, which is what our demo server runs on. We include a couple of notes of variations below. As always, make sure you understand the commands being run below, as they largely require root permissions:",include couple of notes,0,
CoreNLP,Create a user nlp with permissions to read the directory /opt/corenlp. Allow the user to bind to port 80:,create user nlp with permissions,1,https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
CoreNLP,Link the script to /etc/rc.d/: ln -s /etc/init.d/corenlp /etc/rc.d/rc2.d/S75corenlp,link script,0,
CoreNLP,The above steps work using traditional SysVinit scripts. The other alternative on Ubuntu is to use Upstart instead. We haven’t tried that but believe that the corresponding thing to do is:,use traditional SysVinit scripts,1,https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
CoreNLP,The above steps work using traditional SysVinit scripts. The other alternative on Ubuntu is to use Upstart instead. We haven’t tried that but believe that the corresponding thing to do is:,use Upstart,1,https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
CoreNLP,"The CoreNLP server will now start on startup, running on port 80 under the user nlp. To manually start/stop/restart the server, you can use:",run  under user nlp,1,https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
CoreNLP,"The CoreNLP server will now start on startup, running on port 80 under the user nlp. To manually start/stop/restart the server, you can use:",run  on port,1,https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
CoreNLP,"This section documents some of the subtle quirks of the server, and the motivations behind them.",document motivations,0,
CoreNLP,"The official HTTP 1.1 specification recommends ISO-8859-1 as the encoding of a request, unless a different encoding is explicitly set by using the Content-Type header. However, for most NLP applications this is an unintuitive default, and so the server instead defaults to UTF-8. To enable the ISO-8859-1 default, pass in the -strict flag to the server at startup.",use content-type header,0,
CoreNLP,"The official HTTP 1.1 specification recommends ISO-8859-1 as the encoding of a request, unless a different encoding is explicitly set by using the Content-Type header. However, for most NLP applications this is an unintuitive default, and so the server instead defaults to UTF-8. To enable the ISO-8859-1 default, pass in the -strict flag to the server at startup.",set different encoding,0,
CoreNLP,"The official HTTP 1.1 specification recommends ISO-8859-1 as the encoding of a request, unless a different encoding is explicitly set by using the Content-Type header. However, for most NLP applications this is an unintuitive default, and so the server instead defaults to UTF-8. To enable the ISO-8859-1 default, pass in the -strict flag to the server at startup.",enable ISO-8859-1 default,0,
CoreNLP,"When booting up an instance of the server for a shell script, make sure you wait for the server to be available before interacting with it. An example using the netcat tool on linux:",use netcat tool on linux,1,https://stanfordnlp.github.io/CoreNLP/corenlp-server.html
CoreNLP,"CoreNLP is your one stop shop for natural language processing in Java! CoreNLP enables users to derive linguistic annotations for text, including token and sentence boundaries, parts of speech, named entities, numeric and time values, dependency and constituency parses, coreference, sentiment, quote attributions, and relations. CoreNLP currently supports 8 languages: Arabic, Chinese, English, French, German, Hungarian, Italian, and Spanish.",support languages,0,
CoreNLP,"The centerpiece of CoreNLP is the pipeline. Pipelines take in raw text, run a series of NLP annotators on the text, and produce a final set of annotations.",run series of NLP annotators,0,
CoreNLP,"The centerpiece of CoreNLP is the pipeline. Pipelines take in raw text, run a series of NLP annotators on the text, and produce a final set of annotations.",run series on text,0,
CoreNLP,"The centerpiece of CoreNLP is the pipeline. Pipelines take in raw text, run a series of NLP annotators on the text, and produce a final set of annotations.",produce final set of annotations,0,
CoreNLP,"Pipelines produce CoreDocuments, data objects that contain all of the annotation information, accessible with a simple API, and serializable to a Google Protocol Buffer.",produce CoreDocuments,0,
CoreNLP,Download and unzip CoreNLP 4.5.0 (HF Hub),download CoreNLP 4.5.0,0,
CoreNLP,"Download model jars for the language you want to work on and move the jars to the distribution directory. Jars are available directly from us, from Maven, and from Hugging Face.",move jars to distribution directory,0,
CoreNLP,"Stanford CoreNLP is written in Java; recent releases require Java 1.8+. You need to have Java installed to run CoreNLP. However, you can interact with CoreNLP via the command-line or its web service; many people use CoreNLP while writing their own code in Javascript, Python, or some other language.",write stanford CoreNLP in java,0,
CoreNLP,"Stanford CoreNLP is written in Java; recent releases require Java 1.8+. You need to have Java installed to run CoreNLP. However, you can interact with CoreNLP via the command-line or its web service; many people use CoreNLP while writing their own code in Javascript, Python, or some other language.",run CoreNLP,0,
CoreNLP,"Stanford CoreNLP is written in Java; recent releases require Java 1.8+. You need to have Java installed to run CoreNLP. However, you can interact with CoreNLP via the command-line or its web service; many people use CoreNLP while writing their own code in Javascript, Python, or some other language.",use CoreNLP while writing,0,
CoreNLP,"Stanford CoreNLP is written in Java; recent releases require Java 1.8+. You need to have Java installed to run CoreNLP. However, you can interact with CoreNLP via the command-line or its web service; many people use CoreNLP while writing their own code in Javascript, Python, or some other language.",write own code in other language,0,
CoreNLP,"Stanford CoreNLP is written in Java; recent releases require Java 1.8+. You need to have Java installed to run CoreNLP. However, you can interact with CoreNLP via the command-line or its web service; many people use CoreNLP while writing their own code in Javascript, Python, or some other language.",write own code in Javascript,0,
CoreNLP,"Stanford CoreNLP is written in Java; recent releases require Java 1.8+. You need to have Java installed to run CoreNLP. However, you can interact with CoreNLP via the command-line or its web service; many people use CoreNLP while writing their own code in Javascript, Python, or some other language.",write own code in Python,0,
CoreNLP,"You can use Stanford CoreNLP from the command-line, via its original Java programmatic API, via the object-oriented simple API, via third party APIs for most major modern programming languages, or via a web service. It works on Linux, macOS, and Windows.",use Stanford CoreNLP from command-line,0,
CoreNLP,"You can use Stanford CoreNLP from the command-line, via its original Java programmatic API, via the object-oriented simple API, via third party APIs for most major modern programming languages, or via a web service. It works on Linux, macOS, and Windows.",use Stanford CoreNLP via web service,0,
CoreNLP,"The full Stanford CoreNLP is licensed under the GNU General Public License v3 or later. More precisely, all the Stanford NLP code is GPL v2+, but CoreNLP uses some Apache-licensed libraries, and so our understanding is that the the composite is correctly licensed as v3+. You can run almost all of CoreNLP under GPL v2; you simply need to omit the time-related libraries, and then you lose the functionality of SUTime. Note that the license is the full GPL, which allows many free uses, but not its use in proprietary software which is distributed to others. For distributors of proprietary software, CoreNLP is also available from Stanford under a commercial licensing You can contact us at java-nlp-support@lists.stanford.edu. If you don’t need a commercial license, but would like to support maintenance of these tools, we welcome gift funding: use this form and write “Stanford NLP Group open source software” in the Special Instructions.",use apache-licensed libraries,0,
CoreNLP,"The full Stanford CoreNLP is licensed under the GNU General Public License v3 or later. More precisely, all the Stanford NLP code is GPL v2+, but CoreNLP uses some Apache-licensed libraries, and so our understanding is that the the composite is correctly licensed as v3+. You can run almost all of CoreNLP under GPL v2; you simply need to omit the time-related libraries, and then you lose the functionality of SUTime. Note that the license is the full GPL, which allows many free uses, but not its use in proprietary software which is distributed to others. For distributors of proprietary software, CoreNLP is also available from Stanford under a commercial licensing You can contact us at java-nlp-support@lists.stanford.edu. If you don’t need a commercial license, but would like to support maintenance of these tools, we welcome gift funding: use this form and write “Stanford NLP Group open source software” in the Special Instructions.",run  under GPL v2,0,
CoreNLP,"The full Stanford CoreNLP is licensed under the GNU General Public License v3 or later. More precisely, all the Stanford NLP code is GPL v2+, but CoreNLP uses some Apache-licensed libraries, and so our understanding is that the the composite is correctly licensed as v3+. You can run almost all of CoreNLP under GPL v2; you simply need to omit the time-related libraries, and then you lose the functionality of SUTime. Note that the license is the full GPL, which allows many free uses, but not its use in proprietary software which is distributed to others. For distributors of proprietary software, CoreNLP is also available from Stanford under a commercial licensing You can contact us at java-nlp-support@lists.stanford.edu. If you don’t need a commercial license, but would like to support maintenance of these tools, we welcome gift funding: use this form and write “Stanford NLP Group open source software” in the Special Instructions.",omit time-related libraries,0,
CoreNLP,"The full Stanford CoreNLP is licensed under the GNU General Public License v3 or later. More precisely, all the Stanford NLP code is GPL v2+, but CoreNLP uses some Apache-licensed libraries, and so our understanding is that the the composite is correctly licensed as v3+. You can run almost all of CoreNLP under GPL v2; you simply need to omit the time-related libraries, and then you lose the functionality of SUTime. Note that the license is the full GPL, which allows many free uses, but not its use in proprietary software which is distributed to others. For distributors of proprietary software, CoreNLP is also available from Stanford under a commercial licensing You can contact us at java-nlp-support@lists.stanford.edu. If you don’t need a commercial license, but would like to support maintenance of these tools, we welcome gift funding: use this form and write “Stanford NLP Group open source software” in the Special Instructions.",support maintenance of tools,0,
CoreNLP,"The full Stanford CoreNLP is licensed under the GNU General Public License v3 or later. More precisely, all the Stanford NLP code is GPL v2+, but CoreNLP uses some Apache-licensed libraries, and so our understanding is that the the composite is correctly licensed as v3+. You can run almost all of CoreNLP under GPL v2; you simply need to omit the time-related libraries, and then you lose the functionality of SUTime. Note that the license is the full GPL, which allows many free uses, but not its use in proprietary software which is distributed to others. For distributors of proprietary software, CoreNLP is also available from Stanford under a commercial licensing You can contact us at java-nlp-support@lists.stanford.edu. If you don’t need a commercial license, but would like to support maintenance of these tools, we welcome gift funding: use this form and write “Stanford NLP Group open source software” in the Special Instructions.",use form,0,
CoreNLP,"The full Stanford CoreNLP is licensed under the GNU General Public License v3 or later. More precisely, all the Stanford NLP code is GPL v2+, but CoreNLP uses some Apache-licensed libraries, and so our understanding is that the the composite is correctly licensed as v3+. You can run almost all of CoreNLP under GPL v2; you simply need to omit the time-related libraries, and then you lose the functionality of SUTime. Note that the license is the full GPL, which allows many free uses, but not its use in proprietary software which is distributed to others. For distributors of proprietary software, CoreNLP is also available from Stanford under a commercial licensing You can contact us at java-nlp-support@lists.stanford.edu. If you don’t need a commercial license, but would like to support maintenance of these tools, we welcome gift funding: use this form and write “Stanford NLP Group open source software” in the Special Instructions.",write stanford NLP group,0,
CoreNLP,"If you’re just running the CoreNLP pipeline, please cite this CoreNLP paper:",run CoreNLP pipeline,0,
CoreNLP,"Provides a fast syntactic dependency parser. We generate three dependency-based outputs, as follows: basic, uncollapsed dependencies, saved in BasicDependenciesAnnotation; enhanced dependencies saved in EnhancedDependenciesAnnotation; and enhanced++ dependencies in EnhancedPlusPlusDependenciesAnnotation. Most users of our parser will prefer the latter representation.",provide fast syntactic dependency parser,0,
CoreNLP,"Provides a fast syntactic dependency parser. We generate three dependency-based outputs, as follows: basic, uncollapsed dependencies, saved in BasicDependenciesAnnotation; enhanced dependencies saved in EnhancedDependenciesAnnotation; and enhanced++ dependencies in EnhancedPlusPlusDependenciesAnnotation. Most users of our parser will prefer the latter representation.",save  in basicdependenciesannotation,0,
CoreNLP,"Provides a fast syntactic dependency parser. We generate three dependency-based outputs, as follows: basic, uncollapsed dependencies, saved in BasicDependenciesAnnotation; enhanced dependencies saved in EnhancedDependenciesAnnotation; and enhanced++ dependencies in EnhancedPlusPlusDependenciesAnnotation. Most users of our parser will prefer the latter representation.",save  in enhanceddependenciesannotation,0,
CoreNLP,"For details about the dependency software, see this page. For more details about dependency parsing in general, see this page.",parse  in general,0,
CoreNLP,"Stanford CoreNLP can be downloaded via the link below. This will download a large (482 MB) zip file containing (1) the CoreNLP code jar, (2) the CoreNLP models jar (required in your classpath for most tasks) (3) the libraries required to run CoreNLP, and (4) documentation / source code for the project. This is everything for getting going on English! Unzip this file, open the folder that results and you’re ready to use it.",download stanford CoreNLP via link,0,
CoreNLP,"Stanford CoreNLP can be downloaded via the link below. This will download a large (482 MB) zip file containing (1) the CoreNLP code jar, (2) the CoreNLP models jar (required in your classpath for most tasks) (3) the libraries required to run CoreNLP, and (4) documentation / source code for the project. This is everything for getting going on English! Unzip this file, open the folder that results and you’re ready to use it.",download CoreNLP models jar for project,0,
CoreNLP,"Stanford CoreNLP can be downloaded via the link below. This will download a large (482 MB) zip file containing (1) the CoreNLP code jar, (2) the CoreNLP models jar (required in your classpath for most tasks) (3) the libraries required to run CoreNLP, and (4) documentation / source code for the project. This is everything for getting going on English! Unzip this file, open the folder that results and you’re ready to use it.",download large zip file for project,0,
CoreNLP,"Stanford CoreNLP can be downloaded via the link below. This will download a large (482 MB) zip file containing (1) the CoreNLP code jar, (2) the CoreNLP models jar (required in your classpath for most tasks) (3) the libraries required to run CoreNLP, and (4) documentation / source code for the project. This is everything for getting going on English! Unzip this file, open the folder that results and you’re ready to use it.",download documentation source code for project,0,
CoreNLP,"Stanford CoreNLP can be downloaded via the link below. This will download a large (482 MB) zip file containing (1) the CoreNLP code jar, (2) the CoreNLP models jar (required in your classpath for most tasks) (3) the libraries required to run CoreNLP, and (4) documentation / source code for the project. This is everything for getting going on English! Unzip this file, open the folder that results and you’re ready to use it.",run CoreNLP,0,
CoreNLP,"Stanford CoreNLP can be downloaded via the link below. This will download a large (482 MB) zip file containing (1) the CoreNLP code jar, (2) the CoreNLP models jar (required in your classpath for most tasks) (3) the libraries required to run CoreNLP, and (4) documentation / source code for the project. This is everything for getting going on English! Unzip this file, open the folder that results and you’re ready to use it.",open folder,0,
CoreNLP,"If you want to change the source code and recompile the files, see these instructions. Previous releases can be found on the release history page.",change source code,0,
CoreNLP,"If you want to change the source code and recompile the files, see these instructions. Previous releases can be found on the release history page.",recompile files,0,
CoreNLP,"Maven: You can find Stanford CoreNLP on Maven Central. The crucial thing to know is that CoreNLP needs its models to run (most parts beyond the tokenizer and sentence splitter) and so you need to specify both the code jar and the models jar in your pom.xml, as follows: (Note: Maven releases are usually made several days after a release on the website.)",specify code jar in pom.xml,1,https://stanfordnlp.github.io/CoreNLP/download.html
CoreNLP,"Maven: You can find Stanford CoreNLP on Maven Central. The crucial thing to know is that CoreNLP needs its models to run (most parts beyond the tokenizer and sentence splitter) and so you need to specify both the code jar and the models jar in your pom.xml, as follows: (Note: Maven releases are usually made several days after a release on the website.)",specify models jar in pom.xml,1,https://stanfordnlp.github.io/CoreNLP/download.html
CoreNLP,"If you want to get a language models jar off of Maven for Arabic, Chinese, German, or Spanish, also add this inside dependencies to your pom.xml:",get language models jar off_of Maven,1,https://stanfordnlp.github.io/CoreNLP/download.html
CoreNLP,"If you want to get a language models jar off of Maven for Arabic, Chinese, German, or Spanish, also add this inside dependencies to your pom.xml:",add inside dependencies to pom.xml,1,https://stanfordnlp.github.io/CoreNLP/download.html
CoreNLP,You can build the project with this command:,build project with command,1,https://stanfordnlp.github.io/CoreNLP/download.html
CoreNLP,And you can run a demo with a command like this:,run demo with command,1,https://stanfordnlp.github.io/CoreNLP/download.html
CoreNLP,"This example goes over how to set up CoreNLP from the latest official release. This example will take you through downloading the package, and running a simple command-line invocation of CoreNLP.",set up CoreNLP from latest official release,0,
CoreNLP,"This example goes over how to set up CoreNLP from the latest official release. This example will take you through downloading the package, and running a simple command-line invocation of CoreNLP.",download package,0,
CoreNLP,"This example goes over how to set up CoreNLP from the latest official release. This example will take you through downloading the package, and running a simple command-line invocation of CoreNLP.",run simple command-line invocation of CoreNLP,0,
CoreNLP,Or using curl (what you get by default on macOS):,use curl,1,https://stanfordnlp.github.io/CoreNLP/download.html
CoreNLP,"If you’ll be using CoreNLP frequently, the below line is a useful line to have in your ~/.bashrc (or equivalent) file, replacing the directory /path/to/corenlp/ with the appropriate path to where you unzipped CoreNLP:",use CoreNLP,1,https://stanfordnlp.github.io/CoreNLP/download.html
CoreNLP,"If you’ll be using CoreNLP frequently, the below lines are useful to have in your ~/.bashrc (or equivalent) file, replacing the directory /path/to/corenlp/ with the appropriate path to where you unzipped CoreNLP (3 replacements):",use CoreNLP,1,https://stanfordnlp.github.io/CoreNLP/download.html
CoreNLP,Uses a dictionary to match entity mention text to a specific entity in Wikipedia.,use dictionary,0,
CoreNLP,Uses a dictionary to match entity mention text to a specific entity in Wikipedia.,match entity mention text to specific entity,0,
CoreNLP,For instance the text Hank Williams is matched to Hank Williams.,match text hank Williams for instance,0,
CoreNLP,For instance the text Hank Williams is matched to Hank Williams.,match text hank Williams to hank Williams,0,
CoreNLP,"We’re happy to list other models and annotators that work with Stanford CoreNLP. If you have something, please get in touch!",get  in touch,0,
CoreNLP,We’ve moved this information to the page on other human languages,move information to page,0,
CoreNLP,We’ve moved this information to the page on other human languages,move information on other human languages,0,
CoreNLP,We’ve moved this information to the page on other languages and packages.,move information to page,0,
CoreNLP,We’ve moved this information to the page on other languages and packages.,move information on other languages,0,
CoreNLP,We’ve moved this information to the page on other languages and packages.,move information on packages,0,
CoreNLP,"The most likely cause of these errors is that one or more of the important jar files is missing. If it occurs when loading the models, make sure the current models file is in the classpath. The basic models file has a name like stanford-corenlp-V.V.V-models.jar, depending on the version. For other language models, you may also need additional models jars, which will have the language name in them. If you encounter this exception when trying to produce XML output, make sure xom.jar is included. Finally, if it seems to occur when loading SUTime, be sure to include joda-time.jar, etc.",load models,0,
CoreNLP,"The most likely cause of these errors is that one or more of the important jar files is missing. If it occurs when loading the models, make sure the current models file is in the classpath. The basic models file has a name like stanford-corenlp-V.V.V-models.jar, depending on the version. For other language models, you may also need additional models jars, which will have the language name in them. If you encounter this exception when trying to produce XML output, make sure xom.jar is included. Finally, if it seems to occur when loading SUTime, be sure to include joda-time.jar, etc.",produce XML output,0,
CoreNLP,"The most likely cause of these errors is that one or more of the important jar files is missing. If it occurs when loading the models, make sure the current models file is in the classpath. The basic models file has a name like stanford-corenlp-V.V.V-models.jar, depending on the version. For other language models, you may also need additional models jars, which will have the language name in them. If you encounter this exception when trying to produce XML output, make sure xom.jar is included. Finally, if it seems to occur when loading SUTime, be sure to include joda-time.jar, etc.",include xom.jar,0,
CoreNLP,"The most likely cause of these errors is that one or more of the important jar files is missing. If it occurs when loading the models, make sure the current models file is in the classpath. The basic models file has a name like stanford-corenlp-V.V.V-models.jar, depending on the version. For other language models, you may also need additional models jars, which will have the language name in them. If you encounter this exception when trying to produce XML output, make sure xom.jar is included. Finally, if it seems to occur when loading SUTime, be sure to include joda-time.jar, etc.",load SUTime,0,
CoreNLP,"The most likely cause of these errors is that one or more of the important jar files is missing. If it occurs when loading the models, make sure the current models file is in the classpath. The basic models file has a name like stanford-corenlp-V.V.V-models.jar, depending on the version. For other language models, you may also need additional models jars, which will have the language name in them. If you encounter this exception when trying to produce XML output, make sure xom.jar is included. Finally, if it seems to occur when loading SUTime, be sure to include joda-time.jar, etc.",include joda-time.jar,0,
CoreNLP,"Basically, you want to include all of the jar files in the download directory unless you are sure a particular jar is not needed.",include  in download directory,0,
CoreNLP,"A brief demo program included with the download will demonstrate how to load the tool and start processing text. When using this demo program, be sure to include all of the appropriate jar files in the classpath.",load tool,0,
CoreNLP,"A brief demo program included with the download will demonstrate how to load the tool and start processing text. When using this demo program, be sure to include all of the appropriate jar files in the classpath.",include  with download,0,
CoreNLP,"A brief demo program included with the download will demonstrate how to load the tool and start processing text. When using this demo program, be sure to include all of the appropriate jar files in the classpath.",use demo program,0,
CoreNLP,"Once you have tried this, there is quite a bit of information on the CoreNLP home page describing what Annotators are available, what annotations they add to the text, and what options they support.",support options,0,
CoreNLP,"Once you have tried this, there is quite a bit of information on the CoreNLP home page describing what Annotators are available, what annotations they add to the text, and what options they support.",add  to text,0,
CoreNLP,"By default, it uses Unicode’s UTF-8. You can change the encoding used when reading files by either setting the Java encoding property or more simply by supplying the program with the command line flag -encoding FOO (or including the corresponding property in a properties file that you are using).",use UTF-8 by default,0,
CoreNLP,"By default, it uses Unicode’s UTF-8. You can change the encoding used when reading files by either setting the Java encoding property or more simply by supplying the program with the command line flag -encoding FOO (or including the corresponding property in a properties file that you are using).",change encoding,0,
CoreNLP,"By default, it uses Unicode’s UTF-8. You can change the encoding used when reading files by either setting the Java encoding property or more simply by supplying the program with the command line flag -encoding FOO (or including the corresponding property in a properties file that you are using).",set Java encoding property by supplying,0,
CoreNLP,"By default, it uses Unicode’s UTF-8. You can change the encoding used when reading files by either setting the Java encoding property or more simply by supplying the program with the command line flag -encoding FOO (or including the corresponding property in a properties file that you are using).",encode FOO,0,
CoreNLP,"Either give CoreNLP more memory, use fewer annotators, or give CoreNLP smaller documents. Nearly all our annotators load large model files which use lots of memory. Running the full CoreNLP pipeline requires the sum of all these memory requirements. Typically, this means that CoreNLP needs about 2GB to run the entire pipeline. Additionally, the coreference module operates over an entire document. Unless things are size-limited, as either sentence length or document size increases, processing time and space increase without bound.",use fewer annotators,0,
CoreNLP,"Either give CoreNLP more memory, use fewer annotators, or give CoreNLP smaller documents. Nearly all our annotators load large model files which use lots of memory. Running the full CoreNLP pipeline requires the sum of all these memory requirements. Typically, this means that CoreNLP needs about 2GB to run the entire pipeline. Additionally, the coreference module operates over an entire document. Unless things are size-limited, as either sentence length or document size increases, processing time and space increase without bound.",load large model files,0,
CoreNLP,"Either give CoreNLP more memory, use fewer annotators, or give CoreNLP smaller documents. Nearly all our annotators load large model files which use lots of memory. Running the full CoreNLP pipeline requires the sum of all these memory requirements. Typically, this means that CoreNLP needs about 2GB to run the entire pipeline. Additionally, the coreference module operates over an entire document. Unless things are size-limited, as either sentence length or document size increases, processing time and space increase without bound.",use lots of memory,0,
CoreNLP,"Either give CoreNLP more memory, use fewer annotators, or give CoreNLP smaller documents. Nearly all our annotators load large model files which use lots of memory. Running the full CoreNLP pipeline requires the sum of all these memory requirements. Typically, this means that CoreNLP needs about 2GB to run the entire pipeline. Additionally, the coreference module operates over an entire document. Unless things are size-limited, as either sentence length or document size increases, processing time and space increase without bound.",use large model files of memory,0,
CoreNLP,"Either give CoreNLP more memory, use fewer annotators, or give CoreNLP smaller documents. Nearly all our annotators load large model files which use lots of memory. Running the full CoreNLP pipeline requires the sum of all these memory requirements. Typically, this means that CoreNLP needs about 2GB to run the entire pipeline. Additionally, the coreference module operates over an entire document. Unless things are size-limited, as either sentence length or document size increases, processing time and space increase without bound.",run full CoreNLP pipeline,0,
CoreNLP,"Either give CoreNLP more memory, use fewer annotators, or give CoreNLP smaller documents. Nearly all our annotators load large model files which use lots of memory. Running the full CoreNLP pipeline requires the sum of all these memory requirements. Typically, this means that CoreNLP needs about 2GB to run the entire pipeline. Additionally, the coreference module operates over an entire document. Unless things are size-limited, as either sentence length or document size increases, processing time and space increase without bound.",run entire pipeline,0,
CoreNLP,"Running from the command line, you need to supply a flag like -Xmx2g. If running CoreNLP from within Eclipse, follow these instructions to increase the memory given to a program being run from inside Eclipse. Increasing the amount of memory given to Eclipse itself won’t help.",run  from command line,0,
CoreNLP,"Running from the command line, you need to supply a flag like -Xmx2g. If running CoreNLP from within Eclipse, follow these instructions to increase the memory given to a program being run from inside Eclipse. Increasing the amount of memory given to Eclipse itself won’t help.",run CoreNLP,0,
CoreNLP,"Running from the command line, you need to supply a flag like -Xmx2g. If running CoreNLP from within Eclipse, follow these instructions to increase the memory given to a program being run from inside Eclipse. Increasing the amount of memory given to Eclipse itself won’t help.",run  from inside eclipse,0,
CoreNLP,"This is part of SUTime. It applies to repeating events such as “every other week” or “every two weeks”. SET is not the best name for such an event, but it matches the TIMEX3 standard (see section 2.3 of the linked document)",repeat events such_as other week,0,
CoreNLP,"This is part of SUTime. It applies to repeating events such as “every other week” or “every two weeks”. SET is not the best name for such an event, but it matches the TIMEX3 standard (see section 2.3 of the linked document)",repeat events such_as weeks,0,
CoreNLP,"This is part of SUTime. It applies to repeating events such as “every other week” or “every two weeks”. SET is not the best name for such an event, but it matches the TIMEX3 standard (see section 2.3 of the linked document)",match timex3 standard,0,
CoreNLP,"Other than English, we currently provide trained CoreNLP models for Chinese. To run CoreNLP on Chinese text, you first have to download the models, which can be found in our release history. Include this .jar in your classpath, and use the StanfordCoreNLP-chinese.properties file it contains to process Chinese. For example, if you put the .jar in your distribution directory, you could run (adjusting the .jar version file extensions to your current release): java -cp stanford-corenlp-VV.jar:stanford-chinese-corenlp-VV-models.jar -Xmx3g edu.stanford.nlp.pipeline.StanfordCoreNLP -props StanfordCoreNLP-chinese.properties -file your-chinese-file.txt",provide trained CoreNLP models for chinese,0,
CoreNLP,"Other than English, we currently provide trained CoreNLP models for Chinese. To run CoreNLP on Chinese text, you first have to download the models, which can be found in our release history. Include this .jar in your classpath, and use the StanfordCoreNLP-chinese.properties file it contains to process Chinese. For example, if you put the .jar in your distribution directory, you could run (adjusting the .jar version file extensions to your current release): java -cp stanford-corenlp-VV.jar:stanford-chinese-corenlp-VV-models.jar -Xmx3g edu.stanford.nlp.pipeline.StanfordCoreNLP -props StanfordCoreNLP-chinese.properties -file your-chinese-file.txt",run CoreNLP on Chinese text,0,
CoreNLP,"Other than English, we currently provide trained CoreNLP models for Chinese. To run CoreNLP on Chinese text, you first have to download the models, which can be found in our release history. Include this .jar in your classpath, and use the StanfordCoreNLP-chinese.properties file it contains to process Chinese. For example, if you put the .jar in your distribution directory, you could run (adjusting the .jar version file extensions to your current release): java -cp stanford-corenlp-VV.jar:stanford-chinese-corenlp-VV-models.jar -Xmx3g edu.stanford.nlp.pipeline.StanfordCoreNLP -props StanfordCoreNLP-chinese.properties -file your-chinese-file.txt",download models,0,
CoreNLP,"Other than English, we currently provide trained CoreNLP models for Chinese. To run CoreNLP on Chinese text, you first have to download the models, which can be found in our release history. Include this .jar in your classpath, and use the StanfordCoreNLP-chinese.properties file it contains to process Chinese. For example, if you put the .jar in your distribution directory, you could run (adjusting the .jar version file extensions to your current release): java -cp stanford-corenlp-VV.jar:stanford-chinese-corenlp-VV-models.jar -Xmx3g edu.stanford.nlp.pipeline.StanfordCoreNLP -props StanfordCoreNLP-chinese.properties -file your-chinese-file.txt",use StanfordCoreNLP-chinese.properties file,0,
CoreNLP,"Other than English, we currently provide trained CoreNLP models for Chinese. To run CoreNLP on Chinese text, you first have to download the models, which can be found in our release history. Include this .jar in your classpath, and use the StanfordCoreNLP-chinese.properties file it contains to process Chinese. For example, if you put the .jar in your distribution directory, you could run (adjusting the .jar version file extensions to your current release): java -cp stanford-corenlp-VV.jar:stanford-chinese-corenlp-VV-models.jar -Xmx3g edu.stanford.nlp.pipeline.StanfordCoreNLP -props StanfordCoreNLP-chinese.properties -file your-chinese-file.txt",process chinese,0,
CoreNLP,"The straightforward case is if you have an older version of a Stanford NLP tool. For example, you may still have a version of Stanford NER on your classpath that was released in 2009. In this case, you should upgrade, or at least use matching versions. For any releases from 2011 on, just use tools released at the same time – such as the most recent version of everything :) – and they will all be compatible and play nicely together.",release version of Stanford NER,0,
CoreNLP,"The straightforward case is if you have an older version of a Stanford NLP tool. For example, you may still have a version of Stanford NER on your classpath that was released in 2009. In this case, you should upgrade, or at least use matching versions. For any releases from 2011 on, just use tools released at the same time – such as the most recent version of everything :) – and they will all be compatible and play nicely together.",use matching versions,0,
CoreNLP,"The straightforward case is if you have an older version of a Stanford NLP tool. For example, you may still have a version of Stanford NER on your classpath that was released in 2009. In this case, you should upgrade, or at least use matching versions. For any releases from 2011 on, just use tools released at the same time – such as the most recent version of everything :) – and they will all be compatible and play nicely together.",release  at same time,0,
CoreNLP,"The straightforward case is if you have an older version of a Stanford NLP tool. For example, you may still have a version of Stanford NER on your classpath that was released in 2009. In this case, you should upgrade, or at least use matching versions. For any releases from 2011 on, just use tools released at the same time – such as the most recent version of everything :) – and they will all be compatible and play nicely together.",release  for releases,0,
CoreNLP,"The straightforward case is if you have an older version of a Stanford NLP tool. For example, you may still have a version of Stanford NER on your classpath that was released in 2009. In this case, you should upgrade, or at least use matching versions. For any releases from 2011 on, just use tools released at the same time – such as the most recent version of everything :) – and they will all be compatible and play nicely together.",play  at same time,0,
CoreNLP,"The straightforward case is if you have an older version of a Stanford NLP tool. For example, you may still have a version of Stanford NER on your classpath that was released in 2009. In this case, you should upgrade, or at least use matching versions. For any releases from 2011 on, just use tools released at the same time – such as the most recent version of everything :) – and they will all be compatible and play nicely together.",play  for releases,0,
CoreNLP,"The tricky case of this is when people distribute jar files that hide other people’s classes inside them. People think this will make it easy for users, since they can distribute one jar that has everything you need, but, in practice, as soon as people are building applications using multiple components, this results in a particular bad form of jar hell. People just shouldn’t do this. The only way to check that other jar files do not contain conflicting versions of Stanford tools is to look at what is inside them (for example, with the jar -tf command).",hide classes,0,
CoreNLP,"The tricky case of this is when people distribute jar files that hide other people’s classes inside them. People think this will make it easy for users, since they can distribute one jar that has everything you need, but, in practice, as soon as people are building applications using multiple components, this results in a particular bad form of jar hell. People just shouldn’t do this. The only way to check that other jar files do not contain conflicting versions of Stanford tools is to look at what is inside them (for example, with the jar -tf command).",hide jar files,0,
CoreNLP,"The tricky case of this is when people distribute jar files that hide other people’s classes inside them. People think this will make it easy for users, since they can distribute one jar that has everything you need, but, in practice, as soon as people are building applications using multiple components, this results in a particular bad form of jar hell. People just shouldn’t do this. The only way to check that other jar files do not contain conflicting versions of Stanford tools is to look at what is inside them (for example, with the jar -tf command).",build applications,0,
CoreNLP,"The tricky case of this is when people distribute jar files that hide other people’s classes inside them. People think this will make it easy for users, since they can distribute one jar that has everything you need, but, in practice, as soon as people are building applications using multiple components, this results in a particular bad form of jar hell. People just shouldn’t do this. The only way to check that other jar files do not contain conflicting versions of Stanford tools is to look at what is inside them (for example, with the jar -tf command).",use multiple components,0,
CoreNLP,"In practice, if you’re having problems, the most common cause (in 2013-2014) is that you have ark-tweet-nlp on your classpath. The jar file in their github download hides old versions of many other people’s jar files, including Apache commons-codec (v1.4), commons-lang, commons-math, commons-io, Lucene; Twitter commons; Google Guava (v10); Jackson; Berkeley NLP code; Percy Liang’s fig; GNU trove; and an outdated version of the Stanford POS tagger (from 2011). You should complain to them for creating you and us grief. But you can then fix the problem by using their jar file from Maven Central. It doesn’t have all those other libraries stuffed inside.",hide old versions including twitter commons,0,
CoreNLP,"In practice, if you’re having problems, the most common cause (in 2013-2014) is that you have ark-tweet-nlp on your classpath. The jar file in their github download hides old versions of many other people’s jar files, including Apache commons-codec (v1.4), commons-lang, commons-math, commons-io, Lucene; Twitter commons; Google Guava (v10); Jackson; Berkeley NLP code; Percy Liang’s fig; GNU trove; and an outdated version of the Stanford POS tagger (from 2011). You should complain to them for creating you and us grief. But you can then fix the problem by using their jar file from Maven Central. It doesn’t have all those other libraries stuffed inside.",hide old versions including GNU trove,0,
CoreNLP,"In practice, if you’re having problems, the most common cause (in 2013-2014) is that you have ark-tweet-nlp on your classpath. The jar file in their github download hides old versions of many other people’s jar files, including Apache commons-codec (v1.4), commons-lang, commons-math, commons-io, Lucene; Twitter commons; Google Guava (v10); Jackson; Berkeley NLP code; Percy Liang’s fig; GNU trove; and an outdated version of the Stanford POS tagger (from 2011). You should complain to them for creating you and us grief. But you can then fix the problem by using their jar file from Maven Central. It doesn’t have all those other libraries stuffed inside.",hide old versions including google Guava,0,
CoreNLP,"In practice, if you’re having problems, the most common cause (in 2013-2014) is that you have ark-tweet-nlp on your classpath. The jar file in their github download hides old versions of many other people’s jar files, including Apache commons-codec (v1.4), commons-lang, commons-math, commons-io, Lucene; Twitter commons; Google Guava (v10); Jackson; Berkeley NLP code; Percy Liang’s fig; GNU trove; and an outdated version of the Stanford POS tagger (from 2011). You should complain to them for creating you and us grief. But you can then fix the problem by using their jar file from Maven Central. It doesn’t have all those other libraries stuffed inside.",hide old versions including Apache lucene,0,
CoreNLP,"In practice, if you’re having problems, the most common cause (in 2013-2014) is that you have ark-tweet-nlp on your classpath. The jar file in their github download hides old versions of many other people’s jar files, including Apache commons-codec (v1.4), commons-lang, commons-math, commons-io, Lucene; Twitter commons; Google Guava (v10); Jackson; Berkeley NLP code; Percy Liang’s fig; GNU trove; and an outdated version of the Stanford POS tagger (from 2011). You should complain to them for creating you and us grief. But you can then fix the problem by using their jar file from Maven Central. It doesn’t have all those other libraries stuffed inside.",hide old versions including jackson,0,
CoreNLP,"In practice, if you’re having problems, the most common cause (in 2013-2014) is that you have ark-tweet-nlp on your classpath. The jar file in their github download hides old versions of many other people’s jar files, including Apache commons-codec (v1.4), commons-lang, commons-math, commons-io, Lucene; Twitter commons; Google Guava (v10); Jackson; Berkeley NLP code; Percy Liang’s fig; GNU trove; and an outdated version of the Stanford POS tagger (from 2011). You should complain to them for creating you and us grief. But you can then fix the problem by using their jar file from Maven Central. It doesn’t have all those other libraries stuffed inside.",hide old versions including outdated version,0,
CoreNLP,"In practice, if you’re having problems, the most common cause (in 2013-2014) is that you have ark-tweet-nlp on your classpath. The jar file in their github download hides old versions of many other people’s jar files, including Apache commons-codec (v1.4), commons-lang, commons-math, commons-io, Lucene; Twitter commons; Google Guava (v10); Jackson; Berkeley NLP code; Percy Liang’s fig; GNU trove; and an outdated version of the Stanford POS tagger (from 2011). You should complain to them for creating you and us grief. But you can then fix the problem by using their jar file from Maven Central. It doesn’t have all those other libraries stuffed inside.",hide old versions including berkeley NLP code,0,
CoreNLP,"In practice, if you’re having problems, the most common cause (in 2013-2014) is that you have ark-tweet-nlp on your classpath. The jar file in their github download hides old versions of many other people’s jar files, including Apache commons-codec (v1.4), commons-lang, commons-math, commons-io, Lucene; Twitter commons; Google Guava (v10); Jackson; Berkeley NLP code; Percy Liang’s fig; GNU trove; and an outdated version of the Stanford POS tagger (from 2011). You should complain to them for creating you and us grief. But you can then fix the problem by using their jar file from Maven Central. It doesn’t have all those other libraries stuffed inside.",hide old versions including percy liang s fig,0,
CoreNLP,"In practice, if you’re having problems, the most common cause (in 2013-2014) is that you have ark-tweet-nlp on your classpath. The jar file in their github download hides old versions of many other people’s jar files, including Apache commons-codec (v1.4), commons-lang, commons-math, commons-io, Lucene; Twitter commons; Google Guava (v10); Jackson; Berkeley NLP code; Percy Liang’s fig; GNU trove; and an outdated version of the Stanford POS tagger (from 2011). You should complain to them for creating you and us grief. But you can then fix the problem by using their jar file from Maven Central. It doesn’t have all those other libraries stuffed inside.",hide old versions of jar files,0,
CoreNLP,"In practice, if you’re having problems, the most common cause (in 2013-2014) is that you have ark-tweet-nlp on your classpath. The jar file in their github download hides old versions of many other people’s jar files, including Apache commons-codec (v1.4), commons-lang, commons-math, commons-io, Lucene; Twitter commons; Google Guava (v10); Jackson; Berkeley NLP code; Percy Liang’s fig; GNU trove; and an outdated version of the Stanford POS tagger (from 2011). You should complain to them for creating you and us grief. But you can then fix the problem by using their jar file from Maven Central. It doesn’t have all those other libraries stuffed inside.",use jar file from Maven central,0,
CoreNLP,"You need to add the flag -parse.flags """" (or the corresponding property parse.flags:   ). It’s sort of a misfeature/bug that the default properties of CoreNLP turn this option on by default, because it is useful for English, but it isn’t defined for other languages, and so you get an error.)",add flag -parse.flags,0,
CoreNLP,"You need to add the flag -parse.flags """" (or the corresponding property parse.flags:   ). It’s sort of a misfeature/bug that the default properties of CoreNLP turn this option on by default, because it is useful for English, but it isn’t defined for other languages, and so you get an error.)",get error,0,
CoreNLP,"You need to add the flag -parse.flags """" (or the corresponding property parse.flags:   ). It’s sort of a misfeature/bug that the default properties of CoreNLP turn this option on by default, because it is useful for English, but it isn’t defined for other languages, and so you get an error.)",define  for other languages,0,
CoreNLP,"The parser can be instructed to keep certain sets of tokens together as a single constituent. If you do this, it will try to make a parse which contains a subtree where the exact set of tokens in that subtree are the ones specified in the constraint.",specify  in constraint,0,
CoreNLP,"For any sentence where you want to add constraints, attach the ParserAnnotations.ConstraintAnnotation to that sentence. This annotation is a List, where ParserConstraint specifies the start (inclusive) and end (exclusive) of the range and a pattern which the enclosing constituent must match. However, there is a bug in the way patterns are handled in the parser, so it is strongly recommended to use .* for the matching pattern.",add constraints,0,
CoreNLP,"For any sentence where you want to add constraints, attach the ParserAnnotations.ConstraintAnnotation to that sentence. This annotation is a List, where ParserConstraint specifies the start (inclusive) and end (exclusive) of the range and a pattern which the enclosing constituent must match. However, there is a bug in the way patterns are handled in the parser, so it is strongly recommended to use .* for the matching pattern.",attach ParserAnnotations.ConstraintAnnotation for sentence,0,
CoreNLP,"For any sentence where you want to add constraints, attach the ParserAnnotations.ConstraintAnnotation to that sentence. This annotation is a List, where ParserConstraint specifies the start (inclusive) and end (exclusive) of the range and a pattern which the enclosing constituent must match. However, there is a bug in the way patterns are handled in the parser, so it is strongly recommended to use .* for the matching pattern.",attach ParserAnnotations.ConstraintAnnotation to sentence,0,
CoreNLP,"For any sentence where you want to add constraints, attach the ParserAnnotations.ConstraintAnnotation to that sentence. This annotation is a List, where ParserConstraint specifies the start (inclusive) and end (exclusive) of the range and a pattern which the enclosing constituent must match. However, there is a bug in the way patterns are handled in the parser, so it is strongly recommended to use .* for the matching pattern.",specify start of range,0,
CoreNLP,"For any sentence where you want to add constraints, attach the ParserAnnotations.ConstraintAnnotation to that sentence. This annotation is a List, where ParserConstraint specifies the start (inclusive) and end (exclusive) of the range and a pattern which the enclosing constituent must match. However, there is a bug in the way patterns are handled in the parser, so it is strongly recommended to use .* for the matching pattern.",specify start of pattern,0,
CoreNLP,"For any sentence where you want to add constraints, attach the ParserAnnotations.ConstraintAnnotation to that sentence. This annotation is a List, where ParserConstraint specifies the start (inclusive) and end (exclusive) of the range and a pattern which the enclosing constituent must match. However, there is a bug in the way patterns are handled in the parser, so it is strongly recommended to use .* for the matching pattern.",specify end of range,0,
CoreNLP,"For any sentence where you want to add constraints, attach the ParserAnnotations.ConstraintAnnotation to that sentence. This annotation is a List, where ParserConstraint specifies the start (inclusive) and end (exclusive) of the range and a pattern which the enclosing constituent must match. However, there is a bug in the way patterns are handled in the parser, so it is strongly recommended to use .* for the matching pattern.",specify end of pattern,0,
CoreNLP,"For any sentence where you want to add constraints, attach the ParserAnnotations.ConstraintAnnotation to that sentence. This annotation is a List, where ParserConstraint specifies the start (inclusive) and end (exclusive) of the range and a pattern which the enclosing constituent must match. However, there is a bug in the way patterns are handled in the parser, so it is strongly recommended to use .* for the matching pattern.",specify list of range,0,
CoreNLP,"For any sentence where you want to add constraints, attach the ParserAnnotations.ConstraintAnnotation to that sentence. This annotation is a List, where ParserConstraint specifies the start (inclusive) and end (exclusive) of the range and a pattern which the enclosing constituent must match. However, there is a bug in the way patterns are handled in the parser, so it is strongly recommended to use .* for the matching pattern.",specify list of pattern,0,
CoreNLP,"For any sentence where you want to add constraints, attach the ParserAnnotations.ConstraintAnnotation to that sentence. This annotation is a List, where ParserConstraint specifies the start (inclusive) and end (exclusive) of the range and a pattern which the enclosing constituent must match. However, there is a bug in the way patterns are handled in the parser, so it is strongly recommended to use .* for the matching pattern.",match start of range,0,
CoreNLP,"For any sentence where you want to add constraints, attach the ParserAnnotations.ConstraintAnnotation to that sentence. This annotation is a List, where ParserConstraint specifies the start (inclusive) and end (exclusive) of the range and a pattern which the enclosing constituent must match. However, there is a bug in the way patterns are handled in the parser, so it is strongly recommended to use .* for the matching pattern.",match start of pattern,0,
CoreNLP,"For any sentence where you want to add constraints, attach the ParserAnnotations.ConstraintAnnotation to that sentence. This annotation is a List, where ParserConstraint specifies the start (inclusive) and end (exclusive) of the range and a pattern which the enclosing constituent must match. However, there is a bug in the way patterns are handled in the parser, so it is strongly recommended to use .* for the matching pattern.",match end of range,0,
CoreNLP,"For any sentence where you want to add constraints, attach the ParserAnnotations.ConstraintAnnotation to that sentence. This annotation is a List, where ParserConstraint specifies the start (inclusive) and end (exclusive) of the range and a pattern which the enclosing constituent must match. However, there is a bug in the way patterns are handled in the parser, so it is strongly recommended to use .* for the matching pattern.",match end of pattern,0,
CoreNLP,"For any sentence where you want to add constraints, attach the ParserAnnotations.ConstraintAnnotation to that sentence. This annotation is a List, where ParserConstraint specifies the start (inclusive) and end (exclusive) of the range and a pattern which the enclosing constituent must match. However, there is a bug in the way patterns are handled in the parser, so it is strongly recommended to use .* for the matching pattern.",handle patterns in parser,0,
CoreNLP,"For any sentence where you want to add constraints, attach the ParserAnnotations.ConstraintAnnotation to that sentence. This annotation is a List, where ParserConstraint specifies the start (inclusive) and end (exclusive) of the range and a pattern which the enclosing constituent must match. However, there is a bug in the way patterns are handled in the parser, so it is strongly recommended to use .* for the matching pattern.",handle way in parser,0,
CoreNLP,"If you want CoreNLP to output the original Stanford Dependencies instead of the new Universal Dependencies, simply add the option -parse.originalDependencies or the property (""parse.originalDependencies"", true) to your command or code, respectively.",add option -parse.originalDependencies to command,0,
CoreNLP,"If you want CoreNLP to output the original Stanford Dependencies instead of the new Universal Dependencies, simply add the option -parse.originalDependencies or the property (""parse.originalDependencies"", true) to your command or code, respectively.",add option -parse.originalDependencies to code,0,
CoreNLP,"If you want CoreNLP to output the original Stanford Dependencies instead of the new Universal Dependencies, simply add the option -parse.originalDependencies or the property (""parse.originalDependencies"", true) to your command or code, respectively.",add property to command,0,
CoreNLP,"If you want CoreNLP to output the original Stanford Dependencies instead of the new Universal Dependencies, simply add the option -parse.originalDependencies or the property (""parse.originalDependencies"", true) to your command or code, respectively.",add property to code,0,
CoreNLP,"Note, however, that some annotators that use dependencies such as natlog might not function properly if you use this option. In case you are using the Neural Network Dependency Parser, use the following model to get Stanford Dependencies:",use option,1,https://stanfordnlp.github.io/CoreNLP/faq.html
CoreNLP,"Note, however, that some annotators that use dependencies such as natlog might not function properly if you use this option. In case you are using the Neural Network Dependency Parser, use the following model to get Stanford Dependencies:",use neural Network dependency Parser,1,https://stanfordnlp.github.io/CoreNLP/faq.html
CoreNLP,"Note, however, that some annotators that use dependencies such as natlog might not function properly if you use this option. In case you are using the Neural Network Dependency Parser, use the following model to get Stanford Dependencies:",use following model,1,https://stanfordnlp.github.io/CoreNLP/faq.html
CoreNLP,"Note, however, that some annotators that use dependencies such as natlog might not function properly if you use this option. In case you are using the Neural Network Dependency Parser, use the following model to get Stanford Dependencies:",get Stanford dependencies,1,https://stanfordnlp.github.io/CoreNLP/faq.html
CoreNLP,"Out-of-the-box, Stanford CoreNLP expects and processes English language text. But, Stanford CoreNLP was designed from the start to work with multiple human languages and it is careful about things like different character encodings. We have developed components for several major languages, and make language packs (jar files) available for some of them. The table below summarizes our current first party foreign language support. Other people have developed models for other languages.",design stanford CoreNLP from start,0,
CoreNLP,"Out-of-the-box, Stanford CoreNLP expects and processes English language text. But, Stanford CoreNLP was designed from the start to work with multiple human languages and it is careful about things like different character encodings. We have developed components for several major languages, and make language packs (jar files) available for some of them. The table below summarizes our current first party foreign language support. Other people have developed models for other languages.",develop components for several major languages,0,
CoreNLP,"Out-of-the-box, Stanford CoreNLP expects and processes English language text. But, Stanford CoreNLP was designed from the start to work with multiple human languages and it is careful about things like different character encodings. We have developed components for several major languages, and make language packs (jar files) available for some of them. The table below summarizes our current first party foreign language support. Other people have developed models for other languages.",summarize current first party foreign language support,0,
CoreNLP,"Out-of-the-box, Stanford CoreNLP expects and processes English language text. But, Stanford CoreNLP was designed from the start to work with multiple human languages and it is careful about things like different character encodings. We have developed components for several major languages, and make language packs (jar files) available for some of them. The table below summarizes our current first party foreign language support. Other people have developed models for other languages.",develop models for other languages,0,
CoreNLP,"To run Stanford CoreNLP on a supported language, you have to include the models jar for that language in your CLASSPATH.",run Stanford CoreNLP on supported language,0,
CoreNLP,"To run Stanford CoreNLP on a supported language, you have to include the models jar for that language in your CLASSPATH.",include models jar for language,0,
CoreNLP,There are sets of default properties that can be used to run pipelines for every supported language.,run pipelines for supported language,0,
CoreNLP,There are sets of default properties that can be used to run pipelines for every supported language.,use sets of default properties,0,
CoreNLP,"For instance, to run a Spanish pipeline, one could execute this command from the command line:",run Spanish pipeline,1,https://stanfordnlp.github.io/CoreNLP/human-languages.html
CoreNLP,"For instance, to run a Spanish pipeline, one could execute this command from the command line:",execute command for instance,1,https://stanfordnlp.github.io/CoreNLP/human-languages.html
CoreNLP,"For instance, to run a Spanish pipeline, one could execute this command from the command line:",execute command from command line,1,https://stanfordnlp.github.io/CoreNLP/human-languages.html
CoreNLP,Or build and run a pipeline in Java in this manner:,build pipeline in Java,1,https://stanfordnlp.github.io/CoreNLP/human-languages.html
CoreNLP,Or build and run a pipeline in Java in this manner:,run pipeline in Java,1,https://stanfordnlp.github.io/CoreNLP/human-languages.html
CoreNLP,These examples would use the following sets of properties (found in StanfordCoreNLP-spanish.properties),use following sets of properties,1,https://stanfordnlp.github.io/CoreNLP/human-languages.html
CoreNLP,"Currently French (UD 2.2), German (UD 2.2), and Spanish (AnCora UD 2.0) work off of the UD 2.0 tokenization standard. This means among other things that words are split into multiword tokens. For instance the French word ""des"" will be tokenized in some circumstances as ""de"" ""les"". All tagging, parsing, and named entity recognition models rely on that tokenization standard, so it is necessary to use the mwt annotator which performs the multiword tokenization. For instance, in Spanish, the annotators required to run dependency parsing would be tokenize,ssplit,mwt,pos,lemma,depparse. The part of speech tags and dependency labels are from the UD 2.0 sets for each language.",split words into multiword tokens,0,
CoreNLP,"Currently French (UD 2.2), German (UD 2.2), and Spanish (AnCora UD 2.0) work off of the UD 2.0 tokenization standard. This means among other things that words are split into multiword tokens. For instance the French word ""des"" will be tokenized in some circumstances as ""de"" ""les"". All tagging, parsing, and named entity recognition models rely on that tokenization standard, so it is necessary to use the mwt annotator which performs the multiword tokenization. For instance, in Spanish, the annotators required to run dependency parsing would be tokenize,ssplit,mwt,pos,lemma,depparse. The part of speech tags and dependency labels are from the UD 2.0 sets for each language.",tokenize French word in circumstances,0,
CoreNLP,"Currently French (UD 2.2), German (UD 2.2), and Spanish (AnCora UD 2.0) work off of the UD 2.0 tokenization standard. This means among other things that words are split into multiword tokens. For instance the French word ""des"" will be tokenized in some circumstances as ""de"" ""les"". All tagging, parsing, and named entity recognition models rely on that tokenization standard, so it is necessary to use the mwt annotator which performs the multiword tokenization. For instance, in Spanish, the annotators required to run dependency parsing would be tokenize,ssplit,mwt,pos,lemma,depparse. The part of speech tags and dependency labels are from the UD 2.0 sets for each language.",tokenize French word for instance,0,
CoreNLP,"Currently French (UD 2.2), German (UD 2.2), and Spanish (AnCora UD 2.0) work off of the UD 2.0 tokenization standard. This means among other things that words are split into multiword tokens. For instance the French word ""des"" will be tokenized in some circumstances as ""de"" ""les"". All tagging, parsing, and named entity recognition models rely on that tokenization standard, so it is necessary to use the mwt annotator which performs the multiword tokenization. For instance, in Spanish, the annotators required to run dependency parsing would be tokenize,ssplit,mwt,pos,lemma,depparse. The part of speech tags and dependency labels are from the UD 2.0 sets for each language.",use mwt annotator,0,
CoreNLP,"Currently French (UD 2.2), German (UD 2.2), and Spanish (AnCora UD 2.0) work off of the UD 2.0 tokenization standard. This means among other things that words are split into multiword tokens. For instance the French word ""des"" will be tokenized in some circumstances as ""de"" ""les"". All tagging, parsing, and named entity recognition models rely on that tokenization standard, so it is necessary to use the mwt annotator which performs the multiword tokenization. For instance, in Spanish, the annotators required to run dependency parsing would be tokenize,ssplit,mwt,pos,lemma,depparse. The part of speech tags and dependency labels are from the UD 2.0 sets for each language.",perform multiword tokenization,0,
CoreNLP,"Currently French (UD 2.2), German (UD 2.2), and Spanish (AnCora UD 2.0) work off of the UD 2.0 tokenization standard. This means among other things that words are split into multiword tokens. For instance the French word ""des"" will be tokenized in some circumstances as ""de"" ""les"". All tagging, parsing, and named entity recognition models rely on that tokenization standard, so it is necessary to use the mwt annotator which performs the multiword tokenization. For instance, in Spanish, the annotators required to run dependency parsing would be tokenize,ssplit,mwt,pos,lemma,depparse. The part of speech tags and dependency labels are from the UD 2.0 sets for each language.",perform mwt annotator,0,
CoreNLP,"Currently French (UD 2.2), German (UD 2.2), and Spanish (AnCora UD 2.0) work off of the UD 2.0 tokenization standard. This means among other things that words are split into multiword tokens. For instance the French word ""des"" will be tokenized in some circumstances as ""de"" ""les"". All tagging, parsing, and named entity recognition models rely on that tokenization standard, so it is necessary to use the mwt annotator which performs the multiword tokenization. For instance, in Spanish, the annotators required to run dependency parsing would be tokenize,ssplit,mwt,pos,lemma,depparse. The part of speech tags and dependency labels are from the UD 2.0 sets for each language.",run dependency parsing,0,
CoreNLP,Other people have developed models using or compatible with CoreNLP for several further languages. They may or may not be compatible with the most recent release of CoreNLP that we provide.,develop models,0,
CoreNLP,For example when run on the input sentence:,run  on input sentence,1,https://stanfordnlp.github.io/CoreNLP/kbp.html
CoreNLP,"There are descriptions of the sentence level statistical model, semgrex rules, and tokensregex rules in the write up for our 2016 TAC-KBP submission, though this paper also includes details about our overall KBP system which is not included in Stanford CoreNLP.",include details about overall KBP system,0,
CoreNLP,"People not infrequently complain that Stanford CoreNLP is slow or takes a ton of memory. In some configurations this is true. In other configurations, this is not true. This section tries to help you understand what you can or can’t do about speed and memory usage. The advice applies regardless of whether you are running CoreNLP from the command-line, from the Java API, from the web service, or from other languages. We show command-line examples here, but the principles are true of all ways of invoking CoreNLP. You will just need to pass in the appropriate properties in different ways. For these examples we will work with chapter 13 of Ulysses by James Joyce. You can download it if you want to follow along.",run CoreNLP from Java API,0,
CoreNLP,"People not infrequently complain that Stanford CoreNLP is slow or takes a ton of memory. In some configurations this is true. In other configurations, this is not true. This section tries to help you understand what you can or can’t do about speed and memory usage. The advice applies regardless of whether you are running CoreNLP from the command-line, from the Java API, from the web service, or from other languages. We show command-line examples here, but the principles are true of all ways of invoking CoreNLP. You will just need to pass in the appropriate properties in different ways. For these examples we will work with chapter 13 of Ulysses by James Joyce. You can download it if you want to follow along.",run CoreNLP from command-line,0,
CoreNLP,"People not infrequently complain that Stanford CoreNLP is slow or takes a ton of memory. In some configurations this is true. In other configurations, this is not true. This section tries to help you understand what you can or can’t do about speed and memory usage. The advice applies regardless of whether you are running CoreNLP from the command-line, from the Java API, from the web service, or from other languages. We show command-line examples here, but the principles are true of all ways of invoking CoreNLP. You will just need to pass in the appropriate properties in different ways. For these examples we will work with chapter 13 of Ulysses by James Joyce. You can download it if you want to follow along.",show command-line examples,0,
CoreNLP,"People not infrequently complain that Stanford CoreNLP is slow or takes a ton of memory. In some configurations this is true. In other configurations, this is not true. This section tries to help you understand what you can or can’t do about speed and memory usage. The advice applies regardless of whether you are running CoreNLP from the command-line, from the Java API, from the web service, or from other languages. We show command-line examples here, but the principles are true of all ways of invoking CoreNLP. You will just need to pass in the appropriate properties in different ways. For these examples we will work with chapter 13 of Ulysses by James Joyce. You can download it if you want to follow along.",pass  in appropriate properties,0,
CoreNLP,"How slow and memory intensive CoreNLP is depends on the annotators you choose. This is the first rule. In practice many people who have issues are just running CoreNLP out of the box with its default annotators. Not making any explicit choices about annotators or parameters is itself a choice. This page helps you make these choices wisely. Of course, sometimes the choices that are fast and memory efficient aren’t the choices that produce the highest quality annotations. Sometimes you have to make trade-offs.",run CoreNLP with default annotators,0,
CoreNLP,"How slow and memory intensive CoreNLP is depends on the annotators you choose. This is the first rule. In practice many people who have issues are just running CoreNLP out of the box with its default annotators. Not making any explicit choices about annotators or parameters is itself a choice. This page helps you make these choices wisely. Of course, sometimes the choices that are fast and memory efficient aren’t the choices that produce the highest quality annotations. Sometimes you have to make trade-offs.",run CoreNLP in practice,0,
CoreNLP,"How slow and memory intensive CoreNLP is depends on the annotators you choose. This is the first rule. In practice many people who have issues are just running CoreNLP out of the box with its default annotators. Not making any explicit choices about annotators or parameters is itself a choice. This page helps you make these choices wisely. Of course, sometimes the choices that are fast and memory efficient aren’t the choices that produce the highest quality annotations. Sometimes you have to make trade-offs.",run CoreNLP out_of box,0,
CoreNLP,"How slow and memory intensive CoreNLP is depends on the annotators you choose. This is the first rule. In practice many people who have issues are just running CoreNLP out of the box with its default annotators. Not making any explicit choices about annotators or parameters is itself a choice. This page helps you make these choices wisely. Of course, sometimes the choices that are fast and memory efficient aren’t the choices that produce the highest quality annotations. Sometimes you have to make trade-offs.",produce highest quality annotations of course,0,
CoreNLP,"How slow and memory intensive CoreNLP is depends on the annotators you choose. This is the first rule. In practice many people who have issues are just running CoreNLP out of the box with its default annotators. Not making any explicit choices about annotators or parameters is itself a choice. This page helps you make these choices wisely. Of course, sometimes the choices that are fast and memory efficient aren’t the choices that produce the highest quality annotations. Sometimes you have to make trade-offs.",produce choices of course,0,
CoreNLP,Some uses of CoreNLP don’t need much time or space. It can just tokenize and sentence split text using very little time and space. It can do this on the sample text while giving Java just 20MB of memory:,use little time,1,https://stanfordnlp.github.io/CoreNLP/memory-time.html
CoreNLP,Some uses of CoreNLP don’t need much time or space. It can just tokenize and sentence split text using very little time and space. It can do this on the sample text while giving Java just 20MB of memory:,use space,1,https://stanfordnlp.github.io/CoreNLP/memory-time.html
CoreNLP,"CoreNLP will probably report a speed around 50,000–100,000 tokens per second for running this command. (That’s actually well under its actual speed for doing just these two operations – the text isn’t long enough for the code to be warmed up, and I/O costs, etc. dominate. Likely its real speed on your computer is well over 200,000 tokens a second in this configuration.)",run command,0,
CoreNLP,"So, the first thing to know is that CoreNLP will be slow and take a lot of memory if and only if you choose annotators and annotation options that are slow and use a lot of memory.",choose annotators,0,
CoreNLP,"So, the first thing to know is that CoreNLP will be slow and take a lot of memory if and only if you choose annotators and annotation options that are slow and use a lot of memory.",choose annotation options,0,
CoreNLP,"So, the first thing to know is that CoreNLP will be slow and take a lot of memory if and only if you choose annotators and annotation options that are slow and use a lot of memory.",use lot of memory,0,
CoreNLP,"A whole “document” is represented in memory while processing it. Therefore, if you have a large file, like a novel, the next secret to reducing memory usage is to not treat the whole file as a “document”. Process a large file a piece, say a chapter, at a time, not all at once.",process large file,0,
CoreNLP,"If you’re using lots of annotators, CoreNLP can easily spend 10–40 seconds just loading an annotation pipeline. Pipeline loading time can easily dominate actual annotation time. So, if you load a new pipeline frequently, such as for every sentence, then CoreNLP will be painfully slow. You should load an annotation pipleline – what you get when you call new StanfordCoreNLP(props) in code – as infrequently as possible. Usually you can and should just load one pipeline and use it for everything. You only need to use multiple pipelines if you simultaneously need different configurations, such as working with multiple human languages or doing processing with different options or annotators.",use lots of annotators,0,
CoreNLP,"If you’re using lots of annotators, CoreNLP can easily spend 10–40 seconds just loading an annotation pipeline. Pipeline loading time can easily dominate actual annotation time. So, if you load a new pipeline frequently, such as for every sentence, then CoreNLP will be painfully slow. You should load an annotation pipleline – what you get when you call new StanfordCoreNLP(props) in code – as infrequently as possible. Usually you can and should just load one pipeline and use it for everything. You only need to use multiple pipelines if you simultaneously need different configurations, such as working with multiple human languages or doing processing with different options or annotators.",load annotation pipeline,0,
CoreNLP,"If you’re using lots of annotators, CoreNLP can easily spend 10–40 seconds just loading an annotation pipeline. Pipeline loading time can easily dominate actual annotation time. So, if you load a new pipeline frequently, such as for every sentence, then CoreNLP will be painfully slow. You should load an annotation pipleline – what you get when you call new StanfordCoreNLP(props) in code – as infrequently as possible. Usually you can and should just load one pipeline and use it for everything. You only need to use multiple pipelines if you simultaneously need different configurations, such as working with multiple human languages or doing processing with different options or annotators.",load new pipeline,0,
CoreNLP,"If you’re using lots of annotators, CoreNLP can easily spend 10–40 seconds just loading an annotation pipeline. Pipeline loading time can easily dominate actual annotation time. So, if you load a new pipeline frequently, such as for every sentence, then CoreNLP will be painfully slow. You should load an annotation pipleline – what you get when you call new StanfordCoreNLP(props) in code – as infrequently as possible. Usually you can and should just load one pipeline and use it for everything. You only need to use multiple pipelines if you simultaneously need different configurations, such as working with multiple human languages or doing processing with different options or annotators.",load annotation pipleline,0,
CoreNLP,"If you’re using lots of annotators, CoreNLP can easily spend 10–40 seconds just loading an annotation pipeline. Pipeline loading time can easily dominate actual annotation time. So, if you load a new pipeline frequently, such as for every sentence, then CoreNLP will be painfully slow. You should load an annotation pipleline – what you get when you call new StanfordCoreNLP(props) in code – as infrequently as possible. Usually you can and should just load one pipeline and use it for everything. You only need to use multiple pipelines if you simultaneously need different configurations, such as working with multiple human languages or doing processing with different options or annotators.",call new StanfordCoreNLP(props) in code,0,
CoreNLP,"If you’re using lots of annotators, CoreNLP can easily spend 10–40 seconds just loading an annotation pipeline. Pipeline loading time can easily dominate actual annotation time. So, if you load a new pipeline frequently, such as for every sentence, then CoreNLP will be painfully slow. You should load an annotation pipleline – what you get when you call new StanfordCoreNLP(props) in code – as infrequently as possible. Usually you can and should just load one pipeline and use it for everything. You only need to use multiple pipelines if you simultaneously need different configurations, such as working with multiple human languages or doing processing with different options or annotators.",load pipeline,0,
CoreNLP,"If you’re using lots of annotators, CoreNLP can easily spend 10–40 seconds just loading an annotation pipeline. Pipeline loading time can easily dominate actual annotation time. So, if you load a new pipeline frequently, such as for every sentence, then CoreNLP will be painfully slow. You should load an annotation pipleline – what you get when you call new StanfordCoreNLP(props) in code – as infrequently as possible. Usually you can and should just load one pipeline and use it for everything. You only need to use multiple pipelines if you simultaneously need different configurations, such as working with multiple human languages or doing processing with different options or annotators.",use multiple pipelines,0,
CoreNLP,"If you’re using lots of annotators, CoreNLP can easily spend 10–40 seconds just loading an annotation pipeline. Pipeline loading time can easily dominate actual annotation time. So, if you load a new pipeline frequently, such as for every sentence, then CoreNLP will be painfully slow. You should load an annotation pipleline – what you get when you call new StanfordCoreNLP(props) in code – as infrequently as possible. Usually you can and should just load one pipeline and use it for everything. You only need to use multiple pipelines if you simultaneously need different configurations, such as working with multiple human languages or doing processing with different options or annotators.",process  with different options,0,
CoreNLP,"If you’re using lots of annotators, CoreNLP can easily spend 10–40 seconds just loading an annotation pipeline. Pipeline loading time can easily dominate actual annotation time. So, if you load a new pipeline frequently, such as for every sentence, then CoreNLP will be painfully slow. You should load an annotation pipleline – what you get when you call new StanfordCoreNLP(props) in code – as infrequently as possible. Usually you can and should just load one pipeline and use it for everything. You only need to use multiple pipelines if you simultaneously need different configurations, such as working with multiple human languages or doing processing with different options or annotators.",process  with annotators,0,
CoreNLP,Beware that some old interfaces to CoreNLP from other programming languages fork a new CoreNLP process every time they are called. Look for a library that either talks to the CoreNLP web service API or directly calls into the Java code and so can avoid creating new annotation pipelines.,create new annotation pipelines,0,
CoreNLP,Beware that some old interfaces to CoreNLP from other programming languages fork a new CoreNLP process every time they are called. Look for a library that either talks to the CoreNLP web service API or directly calls into the Java code and so can avoid creating new annotation pipelines.,call  into Java code,0,
CoreNLP,"Even at the command-line, if you have one thousand paragraph-long files named para1.txt, para2.txt, … then you will get much faster processing by doing this:",get faster processing by doing,1,https://stanfordnlp.github.io/CoreNLP/memory-time.html
CoreNLP,"Many people run Stanford CoreNLP with its default annotators, by just using a simple command-line like:",run Stanford CoreNLP with default annotators,1,https://stanfordnlp.github.io/CoreNLP/memory-time.html
CoreNLP,"Many people run Stanford CoreNLP with its default annotators, by just using a simple command-line like:",use simple command-line,1,https://stanfordnlp.github.io/CoreNLP/memory-time.html
CoreNLP,"However, the default runs a lot of annotators, some of them very expensive. This is a great command if you want to have your text parsed and coreference run on it. However, if really the only things that you are going to use are parts of speech and named entities, you can get your processing done an order of magnitude more quickly by turning off expensive annotators like parsing and coreference.",get processing,0,
CoreNLP,"If you run the above command in CoreNLP v.3.7.0 or later, your annotation speed is probably about 200 tokens per second. That’s 3 orders of magnitude slower than just tokenizing and sentence splitting, but actually this is the new good news for this version. We’ve changed the default annotator pipeline to make things faster.",run v.3.7.0,0,
CoreNLP,"If you run the above command in CoreNLP v.3.7.0 or later, your annotation speed is probably about 200 tokens per second. That’s 3 orders of magnitude slower than just tokenizing and sentence splitting, but actually this is the new good news for this version. We’ve changed the default annotator pipeline to make things faster.",change default annotator pipeline,0,
CoreNLP,"Because of different default annotator choices, if you you try to process this file with the default annotation pipeline from earlier releases of CoreNLP v.3, most likely, it will just fail from lack of memory or your patience will run out before it finishes. In v.3.6, you need more than 20GB of RAM to run the default model with default options on this text. The default statistical coreference in v.3.6 was just too slow to run fully on large documents like this!",process file with default annotation pipeline,1,https://stanfordnlp.github.io/CoreNLP/memory-time.html
CoreNLP,"Because of different default annotator choices, if you you try to process this file with the default annotation pipeline from earlier releases of CoreNLP v.3, most likely, it will just fail from lack of memory or your patience will run out before it finishes. In v.3.6, you need more than 20GB of RAM to run the default model with default options on this text. The default statistical coreference in v.3.6 was just too slow to run fully on large documents like this!",process file from earlier releases,1,https://stanfordnlp.github.io/CoreNLP/memory-time.html
CoreNLP,"Because of different default annotator choices, if you you try to process this file with the default annotation pipeline from earlier releases of CoreNLP v.3, most likely, it will just fail from lack of memory or your patience will run out before it finishes. In v.3.6, you need more than 20GB of RAM to run the default model with default options on this text. The default statistical coreference in v.3.6 was just too slow to run fully on large documents like this!",run default model with default options,1,https://stanfordnlp.github.io/CoreNLP/memory-time.html
CoreNLP,"Because of different default annotator choices, if you you try to process this file with the default annotation pipeline from earlier releases of CoreNLP v.3, most likely, it will just fail from lack of memory or your patience will run out before it finishes. In v.3.6, you need more than 20GB of RAM to run the default model with default options on this text. The default statistical coreference in v.3.6 was just too slow to run fully on large documents like this!",run  on large documents,1,https://stanfordnlp.github.io/CoreNLP/memory-time.html
CoreNLP,"Returning to v.3.7.0 and continuing with turning annotators off, if all you need are parts of speech and named entities, you should run a pipeline like this:",run pipeline,1,https://stanfordnlp.github.io/CoreNLP/memory-time.html
CoreNLP,"Returning to v.3.7.0 and continuing with turning annotators off, if all you need are parts of speech and named entities, you should run a pipeline like this:",return  to v.3.7.0,1,https://stanfordnlp.github.io/CoreNLP/memory-time.html
CoreNLP,and the annotation speed is about 6500 tokens per second – another 5 times faster. Limiting the number of annotators run can improve speed by orders of magnitude.,limit number of annotators,0,
CoreNLP,"For 1., you should avoid having documents that are too large. Don’t try to parse a whole novel as one CoreNLP document. Parse each chapter as a separate document. This has already been covered above.",parse whole novel as CoreNLP document,0,
CoreNLP,"For 1., you should avoid having documents that are too large. Don’t try to parse a whole novel as one CoreNLP document. Parse each chapter as a separate document. This has already been covered above.",parse chapter as separate document,0,
CoreNLP,"For 2., the only thing you can do is to either remove annotators that you do not need or to make choices for smaller annotators. These models are what fills the large models jar. They are even larger when they are uncompressed and represented in memory. Here are some examples.",remove annotators,1,https://stanfordnlp.github.io/CoreNLP/memory-time.html
CoreNLP,"For 2., the only thing you can do is to either remove annotators that you do not need or to make choices for smaller annotators. These models are what fills the large models jar. They are even larger when they are uncompressed and represented in memory. Here are some examples.",fill large models jar,1,https://stanfordnlp.github.io/CoreNLP/memory-time.html
CoreNLP,"For 3., the classic problem case is parsing long sentences with dynamic programmed parsers like the traditional englishPCFG.ser.gz constituency parsing. This takes space proportional to the square of the longest sentence length, with a large constant factor. Parsing sentences that are hundreds of words long will take additional gigabytes of memory just for the parser data structures. The easiest fix for that is just to not parse super-long sentences. You can do that with a property like: -parse.maxlen 70. This can be a fine solution for something like web pages or newswire, where anything over 70 words is likely a table or list or something that isn’t a real sentence. However, it is unappealing for James Joyce: Several of the sentences in Chapter 13 are over 100 words but are well-formed, proper sentences. For example, here is one of the longer sentences in the chapter:",parse long sentences with dynamic programmed parsers,0,
CoreNLP,"A better way to lessen memory use is to use a different parser. The shift-reduce constituency parse is much faster, usually more accurate, and uses much less memory for parse structures (though it does require loading a much bigger machine learning model). You can invoke it with -parse.model edu/stanford/nlp/models/srparser/englishSR.ser.gz, or as appropriate for the language you are parsing.",use different parser,0,
CoreNLP,"A better way to lessen memory use is to use a different parser. The shift-reduce constituency parse is much faster, usually more accurate, and uses much less memory for parse structures (though it does require loading a much bigger machine learning model). You can invoke it with -parse.model edu/stanford/nlp/models/srparser/englishSR.ser.gz, or as appropriate for the language you are parsing.",use less memory for parse structures,0,
CoreNLP,"Alternatively, if you do not require constituency parses but can make do with dependency parses (perhaps then using components like coreference algorithms that work with dependency parses), then things are much better again: The neural dependency parser is compact and much faster again than the shift-reduce constituency parser. You invoke it by choosing the annotator depparse instead of parse.",choose annotator depparse instead_of parse,0,
CoreNLP,"Nevertheless, in general, very long sentences blow out processing time and memory. One thing to be aware of is that CoreNLP currently uses simple, heuristic sentence splitting on sentence terminators like ‘.’ and ‘?’. If you are parsing “noisy” text without explicit sentence breaks – this often happens if you parse things like tables or web pages – you can end up with “sentences” more than 500 words long, which it isn’t even useful to try to parse. You should either clean these up in data preprocessing or limit the sentence length that annotators try to process. Several annotators support a maximum sentence length property and will simply skip processing of longer sentence. The most commonly useful of these is parse.maxlen but there is also kbp.maxlen, ner.maxlen, and pos.maxlen.",use simple heuristic sentence splitting on sentence terminators,0,
CoreNLP,"Nevertheless, in general, very long sentences blow out processing time and memory. One thing to be aware of is that CoreNLP currently uses simple, heuristic sentence splitting on sentence terminators like ‘.’ and ‘?’. If you are parsing “noisy” text without explicit sentence breaks – this often happens if you parse things like tables or web pages – you can end up with “sentences” more than 500 words long, which it isn’t even useful to try to parse. You should either clean these up in data preprocessing or limit the sentence length that annotators try to process. Several annotators support a maximum sentence length property and will simply skip processing of longer sentence. The most commonly useful of these is parse.maxlen but there is also kbp.maxlen, ner.maxlen, and pos.maxlen.",parse noisy text without explicit sentence breaks,0,
CoreNLP,"Nevertheless, in general, very long sentences blow out processing time and memory. One thing to be aware of is that CoreNLP currently uses simple, heuristic sentence splitting on sentence terminators like ‘.’ and ‘?’. If you are parsing “noisy” text without explicit sentence breaks – this often happens if you parse things like tables or web pages – you can end up with “sentences” more than 500 words long, which it isn’t even useful to try to parse. You should either clean these up in data preprocessing or limit the sentence length that annotators try to process. Several annotators support a maximum sentence length property and will simply skip processing of longer sentence. The most commonly useful of these is parse.maxlen but there is also kbp.maxlen, ner.maxlen, and pos.maxlen.",parse things like tables,0,
CoreNLP,"Nevertheless, in general, very long sentences blow out processing time and memory. One thing to be aware of is that CoreNLP currently uses simple, heuristic sentence splitting on sentence terminators like ‘.’ and ‘?’. If you are parsing “noisy” text without explicit sentence breaks – this often happens if you parse things like tables or web pages – you can end up with “sentences” more than 500 words long, which it isn’t even useful to try to parse. You should either clean these up in data preprocessing or limit the sentence length that annotators try to process. Several annotators support a maximum sentence length property and will simply skip processing of longer sentence. The most commonly useful of these is parse.maxlen but there is also kbp.maxlen, ner.maxlen, and pos.maxlen.",parse things like web pages,0,
CoreNLP,"Nevertheless, in general, very long sentences blow out processing time and memory. One thing to be aware of is that CoreNLP currently uses simple, heuristic sentence splitting on sentence terminators like ‘.’ and ‘?’. If you are parsing “noisy” text without explicit sentence breaks – this often happens if you parse things like tables or web pages – you can end up with “sentences” more than 500 words long, which it isn’t even useful to try to parse. You should either clean these up in data preprocessing or limit the sentence length that annotators try to process. Several annotators support a maximum sentence length property and will simply skip processing of longer sentence. The most commonly useful of these is parse.maxlen but there is also kbp.maxlen, ner.maxlen, and pos.maxlen.",clean preprocessing,0,
CoreNLP,"Nevertheless, in general, very long sentences blow out processing time and memory. One thing to be aware of is that CoreNLP currently uses simple, heuristic sentence splitting on sentence terminators like ‘.’ and ‘?’. If you are parsing “noisy” text without explicit sentence breaks – this often happens if you parse things like tables or web pages – you can end up with “sentences” more than 500 words long, which it isn’t even useful to try to parse. You should either clean these up in data preprocessing or limit the sentence length that annotators try to process. Several annotators support a maximum sentence length property and will simply skip processing of longer sentence. The most commonly useful of these is parse.maxlen but there is also kbp.maxlen, ner.maxlen, and pos.maxlen.",limit sentence length,0,
CoreNLP,"Nevertheless, in general, very long sentences blow out processing time and memory. One thing to be aware of is that CoreNLP currently uses simple, heuristic sentence splitting on sentence terminators like ‘.’ and ‘?’. If you are parsing “noisy” text without explicit sentence breaks – this often happens if you parse things like tables or web pages – you can end up with “sentences” more than 500 words long, which it isn’t even useful to try to parse. You should either clean these up in data preprocessing or limit the sentence length that annotators try to process. Several annotators support a maximum sentence length property and will simply skip processing of longer sentence. The most commonly useful of these is parse.maxlen but there is also kbp.maxlen, ner.maxlen, and pos.maxlen.",support maximum sentence length property,0,
CoreNLP,"Nevertheless, in general, very long sentences blow out processing time and memory. One thing to be aware of is that CoreNLP currently uses simple, heuristic sentence splitting on sentence terminators like ‘.’ and ‘?’. If you are parsing “noisy” text without explicit sentence breaks – this often happens if you parse things like tables or web pages – you can end up with “sentences” more than 500 words long, which it isn’t even useful to try to parse. You should either clean these up in data preprocessing or limit the sentence length that annotators try to process. Several annotators support a maximum sentence length property and will simply skip processing of longer sentence. The most commonly useful of these is parse.maxlen but there is also kbp.maxlen, ner.maxlen, and pos.maxlen.",skip processing of longer sentence,0,
CoreNLP,"The slowest annotators are coreference and parsing. Many coreference methods are especially sensitive to the total document length, since they are quadratic or cubic in the number of mentions in the document. The parsing annotators, particularly dynamic-programming constituency parsing, is especially sensitive to maximum sentence length. Your processing will be much faster if you either leave out these annotators or choose options that make them as fast as possible. In v.3.7.0, the fastest, most memory-efficient models are the default: neural network dependency parsing followed by statistical coreference. In earlier versions, you should choose non-default options to maximize speed and memory efficiency. Again, the most time and memory efficient options are neural network dependency parsing followed by statistical coreference if you only need dependency parses, or shift-reduce constituency parsing followed by deterministic coreference if you do need constituency parses.",choose options,0,
CoreNLP,"The slowest annotators are coreference and parsing. Many coreference methods are especially sensitive to the total document length, since they are quadratic or cubic in the number of mentions in the document. The parsing annotators, particularly dynamic-programming constituency parsing, is especially sensitive to maximum sentence length. Your processing will be much faster if you either leave out these annotators or choose options that make them as fast as possible. In v.3.7.0, the fastest, most memory-efficient models are the default: neural network dependency parsing followed by statistical coreference. In earlier versions, you should choose non-default options to maximize speed and memory efficiency. Again, the most time and memory efficient options are neural network dependency parsing followed by statistical coreference if you only need dependency parses, or shift-reduce constituency parsing followed by deterministic coreference if you do need constituency parses.",choose non-default options in earlier versions,0,
CoreNLP,"The POS tagger does support a pos.maxlen flag, but this should rarely be needed, since the POS tagger uses memory and time linearly with sentence length. The default english-left3words-distsim.tagger is much faster than the english-bidirectional-distsim.tagger. (That is, about 10 times faster.)",support pos.maxlen flag,0,
CoreNLP,"The POS tagger does support a pos.maxlen flag, but this should rarely be needed, since the POS tagger uses memory and time linearly with sentence length. The default english-left3words-distsim.tagger is much faster than the english-bidirectional-distsim.tagger. (That is, about 10 times faster.)",use memory time linearly with sentence length,0,
CoreNLP,"Until v.3.6.0, the default parser was englishPCFG.ser.gz. It was small and quick to load, but takes quadratic space and cubic time with sentence length. Bad news! If you have long sentences, you should either limit the maximum length parsed with a flag like -parse.maxlen 70 or choose a different parser.",limit maximum length,0,
CoreNLP,"Until v.3.6.0, the default parser was englishPCFG.ser.gz. It was small and quick to load, but takes quadratic space and cubic time with sentence length. Bad news! If you have long sentences, you should either limit the maximum length parsed with a flag like -parse.maxlen 70 or choose a different parser.",choose different parser,0,
CoreNLP,"Until v.3.6.0, the default parser was englishPCFG.ser.gz. It was small and quick to load, but takes quadratic space and cubic time with sentence length. Bad news! If you have long sentences, you should either limit the maximum length parsed with a flag like -parse.maxlen 70 or choose a different parser.",parse  with flag,0,
CoreNLP,"The shift-reduce constituency parser takes space and time linear in sentence length. It still supports parse.maxlen, though. If you only need dependency parses, you can get even faster and more memory efficient parsing by using the depparse annotator instead.",support parse.maxlen,0,
CoreNLP,"The shift-reduce constituency parser takes space and time linear in sentence length. It still supports parse.maxlen, though. If you only need dependency parses, you can get even faster and more memory efficient parsing by using the depparse annotator instead.",get faster more memory parsing,0,
CoreNLP,"The shift-reduce constituency parser takes space and time linear in sentence length. It still supports parse.maxlen, though. If you only need dependency parses, you can get even faster and more memory efficient parsing by using the depparse annotator instead.",use depparse annotator,0,
CoreNLP,"The dependency parser (depparse) annotator is faster and uses less space than even the shift-reduce constituency parser. It should be your tool of choice for parsing large amounts of data, unless you need constituency parses, of course. It does not at present support any options to limit parsing time or sentence length.",use less space than shift-reduce constituency parser,0,
CoreNLP,"The dependency parser (depparse) annotator is faster and uses less space than even the shift-reduce constituency parser. It should be your tool of choice for parsing large amounts of data, unless you need constituency parses, of course. It does not at present support any options to limit parsing time or sentence length.",parse large amounts of course,0,
CoreNLP,"The dependency parser (depparse) annotator is faster and uses less space than even the shift-reduce constituency parser. It should be your tool of choice for parsing large amounts of data, unless you need constituency parses, of course. It does not at present support any options to limit parsing time or sentence length.",parse large amounts of data,0,
CoreNLP,"The dependency parser (depparse) annotator is faster and uses less space than even the shift-reduce constituency parser. It should be your tool of choice for parsing large amounts of data, unless you need constituency parses, of course. It does not at present support any options to limit parsing time or sentence length.",limit parsing time,0,
CoreNLP,"The dependency parser (depparse) annotator is faster and uses less space than even the shift-reduce constituency parser. It should be your tool of choice for parsing large amounts of data, unless you need constituency parses, of course. It does not at present support any options to limit parsing time or sentence length.",limit sentence length,0,
CoreNLP,"If you are working using dependency parses, the fastest choice is to use the fast statistical coreference model, which uses only dependency parse features. If you’re already committed to constituency parsing, the fastest choice for coreference is deterministic coreference (dcoref), but it’s the least accurate. Neural-english coref is a reasonable choice for higher quality coreference. Several of the coreference models have some properties that will speed up their application to long documents:",use dependency parses,0,
CoreNLP,"If you are working using dependency parses, the fastest choice is to use the fast statistical coreference model, which uses only dependency parse features. If you’re already committed to constituency parsing, the fastest choice for coreference is deterministic coreference (dcoref), but it’s the least accurate. Neural-english coref is a reasonable choice for higher quality coreference. Several of the coreference models have some properties that will speed up their application to long documents:",use fast statistical coreference model,0,
CoreNLP,"If you are working using dependency parses, the fastest choice is to use the fast statistical coreference model, which uses only dependency parse features. If you’re already committed to constituency parsing, the fastest choice for coreference is deterministic coreference (dcoref), but it’s the least accurate. Neural-english coref is a reasonable choice for higher quality coreference. Several of the coreference models have some properties that will speed up their application to long documents:",use parse features,0,
CoreNLP,"If you are working using dependency parses, the fastest choice is to use the fast statistical coreference model, which uses only dependency parse features. If you’re already committed to constituency parsing, the fastest choice for coreference is deterministic coreference (dcoref), but it’s the least accurate. Neural-english coref is a reasonable choice for higher quality coreference. Several of the coreference models have some properties that will speed up their application to long documents:",use fast statistical coreference model,0,
CoreNLP,"The neural models for English, French, German, and Spanish have been retrained with UD 2.0 dependencies, this will change several labels for the dependency parses. Info about UD 2.0 can be found here.",change several labels for dependency parses,0,
CoreNLP,"Annotators, models, and rules for English, French, German, and Spanish now work with UD 2.0 tokenization by default. This includes models for tagging, parsing, named entity recognition (with an important exception), and KBP relation extraction. For example, the English tokenizer now splits most hyphenated tokens, does not normalize parentheses (e.g. turn ( into -LRB-), and does not normalize quotation marks.",include KBP relation extraction for tagging,0,
CoreNLP,"Annotators, models, and rules for English, French, German, and Spanish now work with UD 2.0 tokenization by default. This includes models for tagging, parsing, named entity recognition (with an important exception), and KBP relation extraction. For example, the English tokenizer now splits most hyphenated tokens, does not normalize parentheses (e.g. turn ( into -LRB-), and does not normalize quotation marks.",include models for tagging,0,
CoreNLP,"Annotators, models, and rules for English, French, German, and Spanish now work with UD 2.0 tokenization by default. This includes models for tagging, parsing, named entity recognition (with an important exception), and KBP relation extraction. For example, the English tokenizer now splits most hyphenated tokens, does not normalize parentheses (e.g. turn ( into -LRB-), and does not normalize quotation marks.",split hyphenated tokens,0,
CoreNLP,A specialized tokenization that is mostly the UD 2.0 version is used for named entity recognition (see below).,use specialized tokenization for named entity recognition,0,
CoreNLP,"The tokenization process for these languages has been designed to maximize F1 on dev/test sets from the CoNLL 2018 shared task, similar to Stanza.",design tokenization process for languages,0,
CoreNLP,"A complication is that the UD 2.0 standard for English and German says to split tokens on hyphen, but this can lead to diminished performance. Consider the example of double barrel names such as Daniel Day-Lewis or hyphenated place names such as Bergen-Enkheim. It was found that splitting on hyphen dropped F1 score, so the hyphen splitting is mostly deactivated for named entity recognition. The only exceptions are the following key words: based, area, registered, headquartered, native, born, raised, backed, controlled, owned, resident, trained, educated. So Chicago-based WILL be split into Chicago - based to allow for the token Chicago to be recognized as a CITY.",split tokens on hyphen,0,
CoreNLP,"A complication is that the UD 2.0 standard for English and German says to split tokens on hyphen, but this can lead to diminished performance. Consider the example of double barrel names such as Daniel Day-Lewis or hyphenated place names such as Bergen-Enkheim. It was found that splitting on hyphen dropped F1 score, so the hyphen splitting is mostly deactivated for named entity recognition. The only exceptions are the following key words: based, area, registered, headquartered, native, born, raised, backed, controlled, owned, resident, trained, educated. So Chicago-based WILL be split into Chicago - based to allow for the token Chicago to be recognized as a CITY.",deactivate hyphen splitting for named entity recognition,0,
CoreNLP,"A complication is that the UD 2.0 standard for English and German says to split tokens on hyphen, but this can lead to diminished performance. Consider the example of double barrel names such as Daniel Day-Lewis or hyphenated place names such as Bergen-Enkheim. It was found that splitting on hyphen dropped F1 score, so the hyphen splitting is mostly deactivated for named entity recognition. The only exceptions are the following key words: based, area, registered, headquartered, native, born, raised, backed, controlled, owned, resident, trained, educated. So Chicago-based WILL be split into Chicago - based to allow for the token Chicago to be recognized as a CITY.",split chicago-based WILL into chicago,0,
CoreNLP,"A complication is that the UD 2.0 standard for English and German says to split tokens on hyphen, but this can lead to diminished performance. Consider the example of double barrel names such as Daniel Day-Lewis or hyphenated place names such as Bergen-Enkheim. It was found that splitting on hyphen dropped F1 score, so the hyphen splitting is mostly deactivated for named entity recognition. The only exceptions are the following key words: based, area, registered, headquartered, native, born, raised, backed, controlled, owned, resident, trained, educated. So Chicago-based WILL be split into Chicago - based to allow for the token Chicago to be recognized as a CITY.",recognize  as CITY,0,
CoreNLP,"The NERAnnotator by default takes in UD 2.0 tokens, and then merges all tokens that were originally joined by a hyphen in the text (except for cases like Chicago-based). The model is run on the modified tokens list, and the labels are finally applied to the original UD 2.0 tokens. This behavior can be turned off by setting ner.useNERSpecificTokenization to false.",run model on modified tokens list,0,
CoreNLP,"The NERAnnotator by default takes in UD 2.0 tokens, and then merges all tokens that were originally joined by a hyphen in the text (except for cases like Chicago-based). The model is run on the modified tokens list, and the labels are finally applied to the original UD 2.0 tokens. This behavior can be turned off by setting ner.useNERSpecificTokenization to false.",set ner.useNERSpecificTokenization to false,0,
CoreNLP,"Related to the tokenization change, French, German, and Spanish now require the use of the MWTAnnotator which splits some tokens into multiple words with rules and statistical models. For instance the French token “des” is sometimes split into the words “de” and “les”.",split tokens into multiple words,0,
CoreNLP,"Related to the tokenization change, French, German, and Spanish now require the use of the MWTAnnotator which splits some tokens into multiple words with rules and statistical models. For instance the French token “des” is sometimes split into the words “de” and “les”.",split MWTAnnotator into multiple words,0,
CoreNLP,"Related to the tokenization change, French, German, and Spanish now require the use of the MWTAnnotator which splits some tokens into multiple words with rules and statistical models. For instance the French token “des” is sometimes split into the words “de” and “les”.",split French token des into words,0,
CoreNLP,"Related to the tokenization change, French, German, and Spanish now require the use of the MWTAnnotator which splits some tokens into multiple words with rules and statistical models. For instance the French token “des” is sometimes split into the words “de” and “les”.",split French token des for instance,0,
CoreNLP,"Some multi-word token splitting for these languages used to occur in the tokenize annotator, but now this annotator focuses on creating tokens, and the mwt annotator is used to make token splitting decisions, sometimes via a dictionary and other times via a statistical model.",create tokens,0,
CoreNLP,"Some multi-word token splitting for these languages used to occur in the tokenize annotator, but now this annotator focuses on creating tokens, and the mwt annotator is used to make token splitting decisions, sometimes via a dictionary and other times via a statistical model.",use mwt annotator,0,
CoreNLP,These languages require the mwt annotator be run immediately after the ssplit annotator.,run mwt annotator after ssplit annotator,1,https://stanfordnlp.github.io/CoreNLP/migration.html
CoreNLP,"The ner, coref, and quote annotators will run some of the annotators themselves as sub-annotators. This means for instance that the ner annotator will run a combination of CRF classifiers (adding ner tags to tokens), then the TokensRegex based regexner to produce fine-grained annotations (“LOCATION” -> “COUNTRY”), and then finally it will annotate the full entity mentions (“Joe”, “Smith” –> “Joe Smith”) with its internal entitymentions annotator.",run  as sub-annotators,0,
CoreNLP,"The ner, coref, and quote annotators will run some of the annotators themselves as sub-annotators. This means for instance that the ner annotator will run a combination of CRF classifiers (adding ner tags to tokens), then the TokensRegex based regexner to produce fine-grained annotations (“LOCATION” -> “COUNTRY”), and then finally it will annotate the full entity mentions (“Joe”, “Smith” –> “Joe Smith”) with its internal entitymentions annotator.",run combination of CRF classifiers,0,
CoreNLP,"The ner, coref, and quote annotators will run some of the annotators themselves as sub-annotators. This means for instance that the ner annotator will run a combination of CRF classifiers (adding ner tags to tokens), then the TokensRegex based regexner to produce fine-grained annotations (“LOCATION” -> “COUNTRY”), and then finally it will annotate the full entity mentions (“Joe”, “Smith” –> “Joe Smith”) with its internal entitymentions annotator.",produce fine-grained annotations,0,
CoreNLP,You can run the ner annotator without the additional annotators with these options,run ner annotator without additional annotators,1,https://stanfordnlp.github.io/CoreNLP/migration.html
CoreNLP,If you wish to set parameters for the ner annotator’s internal regexner annotator set ner.fine.regexner properties. For instance:,set parameters for internal regexner annotator,0,
CoreNLP,If you wish to set parameters for the ner annotator’s internal regexner annotator set ner.fine.regexner properties. For instance:,set ner.fine.regexner properties,0,
CoreNLP,"Likewise to set the ner annotator’s internal entitymentions annotator, set ner.entitymentions properties. For instance:",set internal entitymentions annotator,1,https://stanfordnlp.github.io/CoreNLP/migration.html
CoreNLP,"Likewise to set the ner annotator’s internal entitymentions annotator, set ner.entitymentions properties. For instance:",set ner.entitymentions properties,1,https://stanfordnlp.github.io/CoreNLP/migration.html
CoreNLP,"And for quote annotation, quote attribution can be deactivated with",deactivate quote attribution for quote annotation,1,https://stanfordnlp.github.io/CoreNLP/migration.html
CoreNLP,A variety of third-party groups have created extensions for Stanford CoreNLP.,create extensions for Stanford CoreNLP,0,
CoreNLP,"In the table below we provide access to their work. By simply adding the jar for an entry to your classpath, you can begin using the extension.",provide access to work,0,
CoreNLP,"In the table below we provide access to their work. By simply adding the jar for an entry to your classpath, you can begin using the extension.",add jar for entry,0,
CoreNLP,"In the table below we provide access to their work. By simply adding the jar for an entry to your classpath, you can begin using the extension.",add jar to classpath,0,
CoreNLP,"In the table below we provide access to their work. By simply adding the jar for an entry to your classpath, you can begin using the extension.",use extension,0,
CoreNLP,"For example, if you download corenlp-swedish-1.0.0.jar and place it in your CLASSPATH, you can then run a POS tagger on Swedish.",place  in CLASSPATH,1,https://stanfordnlp.github.io/CoreNLP/model-zoo.html
CoreNLP,"For example, if you download corenlp-swedish-1.0.0.jar and place it in your CLASSPATH, you can then run a POS tagger on Swedish.",run POS tagger on swedish,1,https://stanfordnlp.github.io/CoreNLP/model-zoo.html
CoreNLP,"Multi Word Token Expansion is the process of splitting tokens into syntactic words which are used by downstream tasks such as part of speech tagging and dependency parsing. In CoreNLP, MWT expansion is only performed for French, German, and Spanish. The expansions are designed to be consistent with the UD 2.0 standard.",tag parsing,0,
CoreNLP,"Multi Word Token Expansion is the process of splitting tokens into syntactic words which are used by downstream tasks such as part of speech tagging and dependency parsing. In CoreNLP, MWT expansion is only performed for French, German, and Spanish. The expansions are designed to be consistent with the UD 2.0 standard.",use syntactic words,0,
CoreNLP,"Multi Word Token Expansion is the process of splitting tokens into syntactic words which are used by downstream tasks such as part of speech tagging and dependency parsing. In CoreNLP, MWT expansion is only performed for French, German, and Spanish. The expansions are designed to be consistent with the UD 2.0 standard.",perform MWT expansion in CoreNLP,0,
CoreNLP,"Multi Word Token Expansion is the process of splitting tokens into syntactic words which are used by downstream tasks such as part of speech tagging and dependency parsing. In CoreNLP, MWT expansion is only performed for French, German, and Spanish. The expansions are designed to be consistent with the UD 2.0 standard.",perform MWT expansion for french,0,
CoreNLP,"Multi Word Token Expansion is the process of splitting tokens into syntactic words which are used by downstream tasks such as part of speech tagging and dependency parsing. In CoreNLP, MWT expansion is only performed for French, German, and Spanish. The expansions are designed to be consistent with the UD 2.0 standard.",perform MWT expansion for german,0,
CoreNLP,"Multi Word Token Expansion is the process of splitting tokens into syntactic words which are used by downstream tasks such as part of speech tagging and dependency parsing. In CoreNLP, MWT expansion is only performed for French, German, and Spanish. The expansions are designed to be consistent with the UD 2.0 standard.",perform MWT expansion for spanish,0,
CoreNLP,"Multi Word Token Expansion is the process of splitting tokens into syntactic words which are used by downstream tasks such as part of speech tagging and dependency parsing. In CoreNLP, MWT expansion is only performed for French, German, and Spanish. The expansions are designed to be consistent with the UD 2.0 standard.",design expansions,0,
CoreNLP,"Each language has different rules for MWT expansion. For instance consider the Spanish sentence Pude haber querido escribirlo.. This sentence contains an example of an enclitic pronoun, which is split off from the verb by MWT expansion. So escribirlo is split into escribir and lo.",split escribirlo into escribir,0,
CoreNLP,"Each language has different rules for MWT expansion. For instance consider the Spanish sentence Pude haber querido escribirlo.. This sentence contains an example of an enclitic pronoun, which is split off from the verb by MWT expansion. So escribirlo is split into escribir and lo.",split escribirlo into lo,0,
CoreNLP,"In French, the word “des” is only split in certain circumstances. Thus, a statistical model is needed to make decisions on when to split “des” into “de” and “les”. First a part of speech tag model for MWT expansion is applied (mwt.pos.model). This model applies special tags to words that should be split. For French, it applies the tag “ADP_DET” to the word “des” in cases where “des” should be split. A corresponding dictionary is provided via mwt.statisticalMappingFile which maps word-tag pairs to splits. In the case of French, “des-ADP_DET” is mapped to “de,les”. Mapping files should consist of 2 tab separated columns. The first column contains the word and tag (e.g. “des-ADP_DET”), and the second column should consist of a comma separated list of multi word tokens (e.g. “de,les”).",split word des in french,1,https://stanfordnlp.github.io/CoreNLP/mwt.html
CoreNLP,"In French, the word “des” is only split in certain circumstances. Thus, a statistical model is needed to make decisions on when to split “des” into “de” and “les”. First a part of speech tag model for MWT expansion is applied (mwt.pos.model). This model applies special tags to words that should be split. For French, it applies the tag “ADP_DET” to the word “des” in cases where “des” should be split. A corresponding dictionary is provided via mwt.statisticalMappingFile which maps word-tag pairs to splits. In the case of French, “des-ADP_DET” is mapped to “de,les”. Mapping files should consist of 2 tab separated columns. The first column contains the word and tag (e.g. “des-ADP_DET”), and the second column should consist of a comma separated list of multi word tokens (e.g. “de,les”).",split word des in certain circumstances,1,https://stanfordnlp.github.io/CoreNLP/mwt.html
CoreNLP,"In French, the word “des” is only split in certain circumstances. Thus, a statistical model is needed to make decisions on when to split “des” into “de” and “les”. First a part of speech tag model for MWT expansion is applied (mwt.pos.model). This model applies special tags to words that should be split. For French, it applies the tag “ADP_DET” to the word “des” in cases where “des” should be split. A corresponding dictionary is provided via mwt.statisticalMappingFile which maps word-tag pairs to splits. In the case of French, “des-ADP_DET” is mapped to “de,les”. Mapping files should consist of 2 tab separated columns. The first column contains the word and tag (e.g. “des-ADP_DET”), and the second column should consist of a comma separated list of multi word tokens (e.g. “de,les”).",split words,1,https://stanfordnlp.github.io/CoreNLP/mwt.html
CoreNLP,"In French, the word “des” is only split in certain circumstances. Thus, a statistical model is needed to make decisions on when to split “des” into “de” and “les”. First a part of speech tag model for MWT expansion is applied (mwt.pos.model). This model applies special tags to words that should be split. For French, it applies the tag “ADP_DET” to the word “des” in cases where “des” should be split. A corresponding dictionary is provided via mwt.statisticalMappingFile which maps word-tag pairs to splits. In the case of French, “des-ADP_DET” is mapped to “de,les”. Mapping files should consist of 2 tab separated columns. The first column contains the word and tag (e.g. “des-ADP_DET”), and the second column should consist of a comma separated list of multi word tokens (e.g. “de,les”).",provide corresponding dictionary via mwt.statisticalMappingFile,1,https://stanfordnlp.github.io/CoreNLP/mwt.html
CoreNLP,"This command will take in the text of the file input.txt (assumed to be French in this example) and produce a human readable output of the sentences, with MWT expansion applied.",produce human readable output with MWT expansion,1,https://stanfordnlp.github.io/CoreNLP/mwt.html
CoreNLP,"This command will take in the text of the file input.txt (assumed to be French in this example) and produce a human readable output of the sentences, with MWT expansion applied.",produce human readable output of sentences,1,https://stanfordnlp.github.io/CoreNLP/mwt.html
CoreNLP,"This demo code will produce this output, which shows the enclitic pronoun being split from the verb:",produce output,1,https://stanfordnlp.github.io/CoreNLP/mwt.html
CoreNLP,"This demo code will produce this output, which shows the enclitic pronoun being split from the verb:",show enclitic pronoun,1,https://stanfordnlp.github.io/CoreNLP/mwt.html
CoreNLP,"This demo code will produce this output, which shows the enclitic pronoun being split from the verb:",show output,1,https://stanfordnlp.github.io/CoreNLP/mwt.html
CoreNLP,"This demo code will produce this output, which shows the enclitic pronoun being split from the verb:",split  from verb,1,https://stanfordnlp.github.io/CoreNLP/mwt.html
CoreNLP,"Recognizes named entities (person and company names, etc.) in text. Principally, this annotator uses one or more machine learning sequence models to label entities, but it may also call specialist rule-based components, such as for labeling and interpreting times and dates. Numerical entities that require normalization, e.g., dates, have their normalized value stored in NormalizedNamedEntityTagAnnotation. For more extensive support for rule-based NER, you may also want to look at the RegexNER annotator. The set of entities recognized is language-dependent, and the recognized set of entities is frequently more limited for other languages than what is described below for English. As the name “NERClassifierCombiner” implies, commonly this annotator will run several named entity recognizers and then combine their results but it can run just a single annotator or only rule-based quantity NER.",use machine,0,
CoreNLP,"Recognizes named entities (person and company names, etc.) in text. Principally, this annotator uses one or more machine learning sequence models to label entities, but it may also call specialist rule-based components, such as for labeling and interpreting times and dates. Numerical entities that require normalization, e.g., dates, have their normalized value stored in NormalizedNamedEntityTagAnnotation. For more extensive support for rule-based NER, you may also want to look at the RegexNER annotator. The set of entities recognized is language-dependent, and the recognized set of entities is frequently more limited for other languages than what is described below for English. As the name “NERClassifierCombiner” implies, commonly this annotator will run several named entity recognizers and then combine their results but it can run just a single annotator or only rule-based quantity NER.",learn sequence models to label entities,0,
CoreNLP,"Recognizes named entities (person and company names, etc.) in text. Principally, this annotator uses one or more machine learning sequence models to label entities, but it may also call specialist rule-based components, such as for labeling and interpreting times and dates. Numerical entities that require normalization, e.g., dates, have their normalized value stored in NormalizedNamedEntityTagAnnotation. For more extensive support for rule-based NER, you may also want to look at the RegexNER annotator. The set of entities recognized is language-dependent, and the recognized set of entities is frequently more limited for other languages than what is described below for English. As the name “NERClassifierCombiner” implies, commonly this annotator will run several named entity recognizers and then combine their results but it can run just a single annotator or only rule-based quantity NER.",call specialist rule-based components,0,
CoreNLP,"Recognizes named entities (person and company names, etc.) in text. Principally, this annotator uses one or more machine learning sequence models to label entities, but it may also call specialist rule-based components, such as for labeling and interpreting times and dates. Numerical entities that require normalization, e.g., dates, have their normalized value stored in NormalizedNamedEntityTagAnnotation. For more extensive support for rule-based NER, you may also want to look at the RegexNER annotator. The set of entities recognized is language-dependent, and the recognized set of entities is frequently more limited for other languages than what is described below for English. As the name “NERClassifierCombiner” implies, commonly this annotator will run several named entity recognizers and then combine their results but it can run just a single annotator or only rule-based quantity NER.",run several named entity recognizers,0,
CoreNLP,"Recognizes named entities (person and company names, etc.) in text. Principally, this annotator uses one or more machine learning sequence models to label entities, but it may also call specialist rule-based components, such as for labeling and interpreting times and dates. Numerical entities that require normalization, e.g., dates, have their normalized value stored in NormalizedNamedEntityTagAnnotation. For more extensive support for rule-based NER, you may also want to look at the RegexNER annotator. The set of entities recognized is language-dependent, and the recognized set of entities is frequently more limited for other languages than what is described below for English. As the name “NERClassifierCombiner” implies, commonly this annotator will run several named entity recognizers and then combine their results but it can run just a single annotator or only rule-based quantity NER.",run single annotator,0,
CoreNLP,"For English, by default, this annotator recognizes named (PERSON, LOCATION, ORGANIZATION, MISC), numerical (MONEY, NUMBER, ORDINAL, PERCENT), and temporal (DATE, TIME, DURATION, SET) entities (12 classes). Adding the regexner annotator and using the supplied RegexNER pattern files adds support for the fine-grained and additional entity classes EMAIL, URL, CITY, STATE_OR_PROVINCE, COUNTRY, NATIONALITY, RELIGION, (job) TITLE, IDEOLOGY, CRIMINAL_CHARGE, CAUSE_OF_DEATH, (Twitter, etc.) HANDLE (12 classes) for a total of 24 classes. Named entities are recognized using a combination of three CRF sequence taggers trained on various corpora, including CoNLL, ACE, MUC, and ERE corpora. Numerical entities are recognized using a rule-based system.",recognize temporal entities by default,0,
CoreNLP,"For English, by default, this annotator recognizes named (PERSON, LOCATION, ORGANIZATION, MISC), numerical (MONEY, NUMBER, ORDINAL, PERCENT), and temporal (DATE, TIME, DURATION, SET) entities (12 classes). Adding the regexner annotator and using the supplied RegexNER pattern files adds support for the fine-grained and additional entity classes EMAIL, URL, CITY, STATE_OR_PROVINCE, COUNTRY, NATIONALITY, RELIGION, (job) TITLE, IDEOLOGY, CRIMINAL_CHARGE, CAUSE_OF_DEATH, (Twitter, etc.) HANDLE (12 classes) for a total of 24 classes. Named entities are recognized using a combination of three CRF sequence taggers trained on various corpora, including CoNLL, ACE, MUC, and ERE corpora. Numerical entities are recognized using a rule-based system.",recognize temporal entities for english,0,
CoreNLP,"For English, by default, this annotator recognizes named (PERSON, LOCATION, ORGANIZATION, MISC), numerical (MONEY, NUMBER, ORDINAL, PERCENT), and temporal (DATE, TIME, DURATION, SET) entities (12 classes). Adding the regexner annotator and using the supplied RegexNER pattern files adds support for the fine-grained and additional entity classes EMAIL, URL, CITY, STATE_OR_PROVINCE, COUNTRY, NATIONALITY, RELIGION, (job) TITLE, IDEOLOGY, CRIMINAL_CHARGE, CAUSE_OF_DEATH, (Twitter, etc.) HANDLE (12 classes) for a total of 24 classes. Named entities are recognized using a combination of three CRF sequence taggers trained on various corpora, including CoNLL, ACE, MUC, and ERE corpora. Numerical entities are recognized using a rule-based system.",add regexner annotator,0,
CoreNLP,"For English, by default, this annotator recognizes named (PERSON, LOCATION, ORGANIZATION, MISC), numerical (MONEY, NUMBER, ORDINAL, PERCENT), and temporal (DATE, TIME, DURATION, SET) entities (12 classes). Adding the regexner annotator and using the supplied RegexNER pattern files adds support for the fine-grained and additional entity classes EMAIL, URL, CITY, STATE_OR_PROVINCE, COUNTRY, NATIONALITY, RELIGION, (job) TITLE, IDEOLOGY, CRIMINAL_CHARGE, CAUSE_OF_DEATH, (Twitter, etc.) HANDLE (12 classes) for a total of 24 classes. Named entities are recognized using a combination of three CRF sequence taggers trained on various corpora, including CoNLL, ACE, MUC, and ERE corpora. Numerical entities are recognized using a rule-based system.",use RegexNER pattern files,0,
CoreNLP,"For English, by default, this annotator recognizes named (PERSON, LOCATION, ORGANIZATION, MISC), numerical (MONEY, NUMBER, ORDINAL, PERCENT), and temporal (DATE, TIME, DURATION, SET) entities (12 classes). Adding the regexner annotator and using the supplied RegexNER pattern files adds support for the fine-grained and additional entity classes EMAIL, URL, CITY, STATE_OR_PROVINCE, COUNTRY, NATIONALITY, RELIGION, (job) TITLE, IDEOLOGY, CRIMINAL_CHARGE, CAUSE_OF_DEATH, (Twitter, etc.) HANDLE (12 classes) for a total of 24 classes. Named entities are recognized using a combination of three CRF sequence taggers trained on various corpora, including CoNLL, ACE, MUC, and ERE corpora. Numerical entities are recognized using a rule-based system.",add support for additional entity classes,0,
CoreNLP,"For English, by default, this annotator recognizes named (PERSON, LOCATION, ORGANIZATION, MISC), numerical (MONEY, NUMBER, ORDINAL, PERCENT), and temporal (DATE, TIME, DURATION, SET) entities (12 classes). Adding the regexner annotator and using the supplied RegexNER pattern files adds support for the fine-grained and additional entity classes EMAIL, URL, CITY, STATE_OR_PROVINCE, COUNTRY, NATIONALITY, RELIGION, (job) TITLE, IDEOLOGY, CRIMINAL_CHARGE, CAUSE_OF_DEATH, (Twitter, etc.) HANDLE (12 classes) for a total of 24 classes. Named entities are recognized using a combination of three CRF sequence taggers trained on various corpora, including CoNLL, ACE, MUC, and ERE corpora. Numerical entities are recognized using a rule-based system.",use combination of CRF sequence taggers,0,
CoreNLP,"For English, by default, this annotator recognizes named (PERSON, LOCATION, ORGANIZATION, MISC), numerical (MONEY, NUMBER, ORDINAL, PERCENT), and temporal (DATE, TIME, DURATION, SET) entities (12 classes). Adding the regexner annotator and using the supplied RegexNER pattern files adds support for the fine-grained and additional entity classes EMAIL, URL, CITY, STATE_OR_PROVINCE, COUNTRY, NATIONALITY, RELIGION, (job) TITLE, IDEOLOGY, CRIMINAL_CHARGE, CAUSE_OF_DEATH, (Twitter, etc.) HANDLE (12 classes) for a total of 24 classes. Named entities are recognized using a combination of three CRF sequence taggers trained on various corpora, including CoNLL, ACE, MUC, and ERE corpora. Numerical entities are recognized using a rule-based system.",recognize named entities,0,
CoreNLP,"For English, by default, this annotator recognizes named (PERSON, LOCATION, ORGANIZATION, MISC), numerical (MONEY, NUMBER, ORDINAL, PERCENT), and temporal (DATE, TIME, DURATION, SET) entities (12 classes). Adding the regexner annotator and using the supplied RegexNER pattern files adds support for the fine-grained and additional entity classes EMAIL, URL, CITY, STATE_OR_PROVINCE, COUNTRY, NATIONALITY, RELIGION, (job) TITLE, IDEOLOGY, CRIMINAL_CHARGE, CAUSE_OF_DEATH, (Twitter, etc.) HANDLE (12 classes) for a total of 24 classes. Named entities are recognized using a combination of three CRF sequence taggers trained on various corpora, including CoNLL, ACE, MUC, and ERE corpora. Numerical entities are recognized using a rule-based system.",use rule-based system,0,
CoreNLP,"For English, by default, this annotator recognizes named (PERSON, LOCATION, ORGANIZATION, MISC), numerical (MONEY, NUMBER, ORDINAL, PERCENT), and temporal (DATE, TIME, DURATION, SET) entities (12 classes). Adding the regexner annotator and using the supplied RegexNER pattern files adds support for the fine-grained and additional entity classes EMAIL, URL, CITY, STATE_OR_PROVINCE, COUNTRY, NATIONALITY, RELIGION, (job) TITLE, IDEOLOGY, CRIMINAL_CHARGE, CAUSE_OF_DEATH, (Twitter, etc.) HANDLE (12 classes) for a total of 24 classes. Named entities are recognized using a combination of three CRF sequence taggers trained on various corpora, including CoNLL, ACE, MUC, and ERE corpora. Numerical entities are recognized using a rule-based system.",recognize numerical entities,0,
CoreNLP,The main class that runs this process is edu.stanford.nlp.pipeline.NERCombinerAnnotator,run process,0,
CoreNLP,The main class that runs this process is edu.stanford.nlp.pipeline.NERCombinerAnnotator,run main class,0,
CoreNLP,During this phase a series of trained CRF’s will be run on each sentence. These CRF’s are trained on large tagged data sets. They evaluate the entire sequence and pick the optimal tag sequence.,run series of trained CRF s,0,
CoreNLP,During this phase a series of trained CRF’s will be run on each sentence. These CRF’s are trained on large tagged data sets. They evaluate the entire sequence and pick the optimal tag sequence.,run series during phase,0,
CoreNLP,During this phase a series of trained CRF’s will be run on each sentence. These CRF’s are trained on large tagged data sets. They evaluate the entire sequence and pick the optimal tag sequence.,run series on sentence,0,
CoreNLP,During this phase a series of trained CRF’s will be run on each sentence. These CRF’s are trained on large tagged data sets. They evaluate the entire sequence and pick the optimal tag sequence.,evaluate entire sequence,0,
CoreNLP,These are the default models that are run:,run default models,1,https://stanfordnlp.github.io/CoreNLP/ner.html
CoreNLP,There are two options for how the models are combined. These are selected with the ner.combinationMode property.,select  with ner.combinationMode property,0,
CoreNLP,"So for example, if the ner.combinationMode is set to NORMAL, only the 3-class model’s ORGANIZATION tags will be applied. If it is set to HIGH_RECALL, the 7-class and 4-class models’ ORGANIZATION tags will also be applied.",set ner.combinationMode to NORMAL,0,
CoreNLP,"So for example, if the ner.combinationMode is set to NORMAL, only the 3-class model’s ORGANIZATION tags will be applied. If it is set to HIGH_RECALL, the 7-class and 4-class models’ ORGANIZATION tags will also be applied.",set  to HIGH_RECALL,0,
CoreNLP,"If you do not want to run any statistical models, set ner.model to the empty string.",run statistical models,0,
CoreNLP,"If you do not want to run any statistical models, set ner.model to the empty string.",set ner.model to empty string,0,
CoreNLP,Next a series of rule based systems are run to recognize and tag numeric sequences and time related sequences.,recognize time related sequences,0,
CoreNLP,Next a series of rule based systems are run to recognize and tag numeric sequences and time related sequences.,recognize numeric sequences,0,
CoreNLP,Next a series of rule based systems are run to recognize and tag numeric sequences and time related sequences.,tag time related sequences,0,
CoreNLP,Next a series of rule based systems are run to recognize and tag numeric sequences and time related sequences.,tag numeric sequences,0,
CoreNLP,Next a series of rule based systems are run to recognize and tag numeric sequences and time related sequences.,run systems,0,
CoreNLP,"This phase runs by default, but can be deactivated by setting ner.applyNumericClassifiers to false.",set ner.applyNumericClassifiers to false,0,
CoreNLP,"This phase runs by default, but can be deactivated by setting ner.applyNumericClassifiers to false.",run  by default,0,
CoreNLP,"This phase runs by default, but can be deactivated by setting ner.applyNumericClassifiers to false.",deactivate phase,0,
CoreNLP,"This produces tags such as NUMBER, ORDINAL, MONEY, DATE, and TIME",produce tags such_as NUMBER,0,
CoreNLP,The class that runs this phase is edu.stanford.nlp.ie.regexp.NumberSequenceClassifier,run phase,0,
CoreNLP,The class that runs this phase is edu.stanford.nlp.ie.regexp.NumberSequenceClassifier,run class,0,
CoreNLP,SUTime (described in more detail below) is also used by default. You can deactivate this by setting ner.useSUTime to false.,use SUTime,0,
CoreNLP,SUTime (described in more detail below) is also used by default. You can deactivate this by setting ner.useSUTime to false.,deactivate  by setting,0,
CoreNLP,SUTime (described in more detail below) is also used by default. You can deactivate this by setting ner.useSUTime to false.,set ner.useSUTime to false,0,
CoreNLP,"At this point, a series of rules used for the KBP 2017 competition will be run to create more fine-grained NER tags. These rules are applied using a TokensRegexNERAnnotator sub-annotator. That is the main NERCombinerAnnotator builds a TokensRegexNERAnnotator as a sub-annotator and runs it on all sentences as part of it’s entire tagging process. The purpose of these rules is give tokens more specific tags. So for instance California would be tagged as a STATE_OR_PROVINCE rather than just a LOCATION.",create more fine-grained NER tags,0,
CoreNLP,"At this point, a series of rules used for the KBP 2017 competition will be run to create more fine-grained NER tags. These rules are applied using a TokensRegexNERAnnotator sub-annotator. That is the main NERCombinerAnnotator builds a TokensRegexNERAnnotator as a sub-annotator and runs it on all sentences as part of it’s entire tagging process. The purpose of these rules is give tokens more specific tags. So for instance California would be tagged as a STATE_OR_PROVINCE rather than just a LOCATION.",use  for KBP competition,0,
CoreNLP,"At this point, a series of rules used for the KBP 2017 competition will be run to create more fine-grained NER tags. These rules are applied using a TokensRegexNERAnnotator sub-annotator. That is the main NERCombinerAnnotator builds a TokensRegexNERAnnotator as a sub-annotator and runs it on all sentences as part of it’s entire tagging process. The purpose of these rules is give tokens more specific tags. So for instance California would be tagged as a STATE_OR_PROVINCE rather than just a LOCATION.",run series at point,0,
CoreNLP,"At this point, a series of rules used for the KBP 2017 competition will be run to create more fine-grained NER tags. These rules are applied using a TokensRegexNERAnnotator sub-annotator. That is the main NERCombinerAnnotator builds a TokensRegexNERAnnotator as a sub-annotator and runs it on all sentences as part of it’s entire tagging process. The purpose of these rules is give tokens more specific tags. So for instance California would be tagged as a STATE_OR_PROVINCE rather than just a LOCATION.",run series of rules,0,
CoreNLP,"At this point, a series of rules used for the KBP 2017 competition will be run to create more fine-grained NER tags. These rules are applied using a TokensRegexNERAnnotator sub-annotator. That is the main NERCombinerAnnotator builds a TokensRegexNERAnnotator as a sub-annotator and runs it on all sentences as part of it’s entire tagging process. The purpose of these rules is give tokens more specific tags. So for instance California would be tagged as a STATE_OR_PROVINCE rather than just a LOCATION.",use TokensRegexNERAnnotator sub-annotator,0,
CoreNLP,"At this point, a series of rules used for the KBP 2017 competition will be run to create more fine-grained NER tags. These rules are applied using a TokensRegexNERAnnotator sub-annotator. That is the main NERCombinerAnnotator builds a TokensRegexNERAnnotator as a sub-annotator and runs it on all sentences as part of it’s entire tagging process. The purpose of these rules is give tokens more specific tags. So for instance California would be tagged as a STATE_OR_PROVINCE rather than just a LOCATION.",build TokensRegexNERAnnotator as sub-annotator,0,
CoreNLP,"At this point, a series of rules used for the KBP 2017 competition will be run to create more fine-grained NER tags. These rules are applied using a TokensRegexNERAnnotator sub-annotator. That is the main NERCombinerAnnotator builds a TokensRegexNERAnnotator as a sub-annotator and runs it on all sentences as part of it’s entire tagging process. The purpose of these rules is give tokens more specific tags. So for instance California would be tagged as a STATE_OR_PROVINCE rather than just a LOCATION.",build main NERCombinerAnnotator as sub-annotator,0,
CoreNLP,"At this point, a series of rules used for the KBP 2017 competition will be run to create more fine-grained NER tags. These rules are applied using a TokensRegexNERAnnotator sub-annotator. That is the main NERCombinerAnnotator builds a TokensRegexNERAnnotator as a sub-annotator and runs it on all sentences as part of it’s entire tagging process. The purpose of these rules is give tokens more specific tags. So for instance California would be tagged as a STATE_OR_PROVINCE rather than just a LOCATION.",run main NERCombinerAnnotator on sentences,0,
CoreNLP,"At this point, a series of rules used for the KBP 2017 competition will be run to create more fine-grained NER tags. These rules are applied using a TokensRegexNERAnnotator sub-annotator. That is the main NERCombinerAnnotator builds a TokensRegexNERAnnotator as a sub-annotator and runs it on all sentences as part of it’s entire tagging process. The purpose of these rules is give tokens more specific tags. So for instance California would be tagged as a STATE_OR_PROVINCE rather than just a LOCATION.",tag california as STATE_OR_PROVINCE,0,
CoreNLP,"At this point, a series of rules used for the KBP 2017 competition will be run to create more fine-grained NER tags. These rules are applied using a TokensRegexNERAnnotator sub-annotator. That is the main NERCombinerAnnotator builds a TokensRegexNERAnnotator as a sub-annotator and runs it on all sentences as part of it’s entire tagging process. The purpose of these rules is give tokens more specific tags. So for instance California would be tagged as a STATE_OR_PROVINCE rather than just a LOCATION.",tag california as LOCATION,0,
CoreNLP,"At this point, a series of rules used for the KBP 2017 competition will be run to create more fine-grained NER tags. These rules are applied using a TokensRegexNERAnnotator sub-annotator. That is the main NERCombinerAnnotator builds a TokensRegexNERAnnotator as a sub-annotator and runs it on all sentences as part of it’s entire tagging process. The purpose of these rules is give tokens more specific tags. So for instance California would be tagged as a STATE_OR_PROVINCE rather than just a LOCATION.",tag california for instance,0,
CoreNLP,The TokensRegexNERAnnotator runs TokensRegex rules. You can review all of the settings for a TokensRegexNERAnnotator here.,run TokensRegex rules,1,https://stanfordnlp.github.io/CoreNLP/ner.html
CoreNLP,"If you do not want to run the fine-grained rules, set ner.applyFineGrained to false.",run fine-grained rules,0,
CoreNLP,"If you do not want to run the fine-grained rules, set ner.applyFineGrained to false.",set ner.applyFineGrained to false,0,
CoreNLP,"The first column is the tokens pattern, the second column is the NER tag to apply, the third is the types of NER tags that can be overwritten, and the fourth is a priority used for tie-breaking if two rules match a sequence.",match sequence,1,https://stanfordnlp.github.io/CoreNLP/ner.html
CoreNLP,"The first column is the tokens pattern, the second column is the NER tag to apply, the third is the types of NER tags that can be overwritten, and the fourth is a priority used for tie-breaking if two rules match a sequence.",use  for tie-breaking,1,https://stanfordnlp.github.io/CoreNLP/ner.html
CoreNLP,"means to match the token “Los” followed by the token “Angeles”, and label them both as CITY, provided they have a current NER tag of O, LOCATION, or MISC.",match token los,1,https://stanfordnlp.github.io/CoreNLP/ner.html
CoreNLP,Here is a breakdown of how to customize the fine-grained NER. The overall ner annotator creates a sub-annotator called ner.fine.regexner which is an instance of a TokensRegexNERAnnotator.,call ner.fine.regexner,0,
CoreNLP,The ner.fine.regexner.mapping property allows one to specify a set of rules files and additional properties for each rules file.,specify set of rules files,1,https://stanfordnlp.github.io/CoreNLP/ner.html
CoreNLP,The ner.fine.regexner.mapping property allows one to specify a set of rules files and additional properties for each rules file.,specify set for rules file,1,https://stanfordnlp.github.io/CoreNLP/ner.html
CoreNLP,The ner.fine.regexner.mapping property allows one to specify a set of rules files and additional properties for each rules file.,specify additional properties of rules files,1,https://stanfordnlp.github.io/CoreNLP/ner.html
CoreNLP,The ner.fine.regexner.mapping property allows one to specify a set of rules files and additional properties for each rules file.,specify additional properties for rules file,1,https://stanfordnlp.github.io/CoreNLP/ner.html
CoreNLP,while there are no options set for edu/stanford/nlp/models/kbp/english/gazetteers/regexner_cased.tab in this example.,set  for edu/stanford/nlp/models/kbp/english/gazetteers/regexner_cased.tab,0,
CoreNLP,"If you want to set global settings that will apply for all rules files, remember to use ner.fine.regexner.ignorecase and ner.fine.regexner.validpospattern. If you are setting options for a specific rules file with the ner.fine.regexner.mapping option, follow the pattern from above.",set global settings,0,
CoreNLP,"If you want to set global settings that will apply for all rules files, remember to use ner.fine.regexner.ignorecase and ner.fine.regexner.validpospattern. If you are setting options for a specific rules file with the ner.fine.regexner.mapping option, follow the pattern from above.",use ner.fine.regexner.ignorecase,0,
CoreNLP,"If you want to set global settings that will apply for all rules files, remember to use ner.fine.regexner.ignorecase and ner.fine.regexner.validpospattern. If you are setting options for a specific rules file with the ner.fine.regexner.mapping option, follow the pattern from above.",use ner.fine.regexner.validpospattern,0,
CoreNLP,"If you want to set global settings that will apply for all rules files, remember to use ner.fine.regexner.ignorecase and ner.fine.regexner.validpospattern. If you are setting options for a specific rules file with the ner.fine.regexner.mapping option, follow the pattern from above.",set options for specific rules file,0,
CoreNLP,"After the fine-grained rules are run, there is also an option for a user to specify additional rules they would like to have run after the fine-grained NER phase.",specify additional rules,0,
CoreNLP,"After the fine-grained rules are run, there is also an option for a user to specify additional rules they would like to have run after the fine-grained NER phase.",run  after fine-grained NER phase,0,
CoreNLP,"After the fine-grained rules are run, there is also an option for a user to specify additional rules they would like to have run after the fine-grained NER phase.",run fine-grained rules,0,
CoreNLP,This second TokensRegexNERAnnotator sub-annotator has the name ner.additional.regexner and is customized in the same manner. This is for the case when users want to run their own rules after the standard rules we provide.,run own rules after standard rules,0,
CoreNLP,This second TokensRegexNERAnnotator sub-annotator has the name ner.additional.regexner and is customized in the same manner. This is for the case when users want to run their own rules after the standard rules we provide.,provide standard rules,0,
CoreNLP,"For instance, suppose you want to match sports teams after the previous NER steps have been run.",match sports teams,1,https://stanfordnlp.github.io/CoreNLP/ner.html
CoreNLP,"For instance, suppose you want to match sports teams after the previous NER steps have been run.",run previous NER steps,1,https://stanfordnlp.github.io/CoreNLP/ner.html
CoreNLP,You could integrate this into the entire NER process by setting ner.additional.regexner.mapping to /path/to/sports_teams.rules,integrate  into entire NER process,0,
CoreNLP,You could integrate this into the entire NER process by setting ner.additional.regexner.mapping to /path/to/sports_teams.rules,integrate  by setting,0,
CoreNLP,You could integrate this into the entire NER process by setting ner.additional.regexner.mapping to /path/to/sports_teams.rules,set ner.additional.regexner.mapping to /path/to/sports_teams.rules,0,
CoreNLP,"By default no additional rules are run, so leaving ner.additional.regexner.mapping blank will cause this phase to not be run at all.",run additional rules,0,
CoreNLP,"If you want to run a series of TokensRegex rules before entity building, you can also specify a set of TokensRegex rules. A TokensRegexAnnotator sub-annotator will be called. It has the name ner.additional.tokensregex.",run series before entity building,1,https://stanfordnlp.github.io/CoreNLP/ner.html
CoreNLP,"If you want to run a series of TokensRegex rules before entity building, you can also specify a set of TokensRegex rules. A TokensRegexAnnotator sub-annotator will be called. It has the name ner.additional.tokensregex.",run series of TokensRegex rules,1,https://stanfordnlp.github.io/CoreNLP/ner.html
CoreNLP,"If you want to run a series of TokensRegex rules before entity building, you can also specify a set of TokensRegex rules. A TokensRegexAnnotator sub-annotator will be called. It has the name ner.additional.tokensregex.",specify set of TokensRegex rules,1,https://stanfordnlp.github.io/CoreNLP/ner.html
CoreNLP,"If you want to run a series of TokensRegex rules before entity building, you can also specify a set of TokensRegex rules. A TokensRegexAnnotator sub-annotator will be called. It has the name ner.additional.tokensregex.",call TokensRegexAnnotator sub-annotator,1,https://stanfordnlp.github.io/CoreNLP/ner.html
CoreNLP,"After all of the previous steps have been run, entity detection will be run to combine the tagged tokens into entities. The entity mention detection will be based off of the tagging scheme. This is accomplished with an EntityMentionsAnnotator sub-annotator.",run entity detection,0,
CoreNLP,"If a basic IO tagging scheme (example: PERSON, ORGANIZATION, LOCATION) is used, all contiguous sequences of tokens with the same tag will be marked as an entity.",mark contiguous sequences as entity,0,
CoreNLP,"If a basic IO tagging scheme (example: PERSON, ORGANIZATION, LOCATION) is used, all contiguous sequences of tokens with the same tag will be marked as an entity.",mark contiguous sequences of tokens,0,
CoreNLP,"If a basic IO tagging scheme (example: PERSON, ORGANIZATION, LOCATION) is used, all contiguous sequences of tokens with the same tag will be marked as an entity.",use basic IO tagging scheme,0,
CoreNLP,"If a more advanced tagging scheme (such as BIO with tags like B-PERSON and I-PERSON) is used, sequences with the same tag split by a B-tag will be turned into multiple entities.",use advanced tagging scheme,0,
CoreNLP,"All of our models and rule files use a basic tagging scheme, but you could create your own models and rules that use BIO.",use basic tagging scheme,0,
CoreNLP,"All of our models and rule files use a basic tagging scheme, but you could create your own models and rules that use BIO.",create own models,0,
CoreNLP,"All of our models and rule files use a basic tagging scheme, but you could create your own models and rules that use BIO.",create rules,0,
CoreNLP,"All of our models and rule files use a basic tagging scheme, but you could create your own models and rules that use BIO.",use BIO,0,
CoreNLP,For instance (Joe PERSON) (Smith PERSON) (Jane PERSON) (Smith PERSON) will create the entity Joe Smith Jane Smith.,create entity for instance,0,
CoreNLP,On the other hand (Joe B-PERSON) (Smith I-PERSON) (Jane B-PERSON) (Smith I-PERSON) will create two entities: Joe Smith and Jane Smith.,create entities on other hand,0,
CoreNLP,You can deactivate this with ner.buildEntityMentions being set to false.,deactivate  with ner.buildEntityMentions,0,
CoreNLP,You can deactivate this with ner.buildEntityMentions being set to false.,set  to false,0,
CoreNLP,"At this point the NER process will be finished, having tagged tokens with NER tags and created entities.",tag tokens with NER tags,0,
CoreNLP,"At this point the NER process will be finished, having tagged tokens with NER tags and created entities.",tag tokens with created entities,0,
CoreNLP,"Stanford CoreNLP includes SUTime, Stanford’s temporal expression recognizer. SUTime is transparently called from the “ner” annotator, so no configuration is necessary. Furthermore, the “cleanxml” annotator can extract the reference date for a given XML document, so relative dates, e.g., “yesterday”, are transparently normalized with no configuration necessary.",include SUTime,0,
CoreNLP,"Stanford CoreNLP includes SUTime, Stanford’s temporal expression recognizer. SUTime is transparently called from the “ner” annotator, so no configuration is necessary. Furthermore, the “cleanxml” annotator can extract the reference date for a given XML document, so relative dates, e.g., “yesterday”, are transparently normalized with no configuration necessary.",call  from ner annotator,0,
CoreNLP,"Stanford CoreNLP includes SUTime, Stanford’s temporal expression recognizer. SUTime is transparently called from the “ner” annotator, so no configuration is necessary. Furthermore, the “cleanxml” annotator can extract the reference date for a given XML document, so relative dates, e.g., “yesterday”, are transparently normalized with no configuration necessary.",extract reference date for given XML document,0,
CoreNLP,"SUTime supports the same annotations as before, i.e., NamedEntityTagAnnotation is set with the label of the numeric entity (DATE, TIME, DURATION, MONEY, PERCENT, or NUMBER) and NormalizedNamedEntityTagAnnotation is set to the value of the normalized temporal expression.",support same annotations,0,
CoreNLP,"SUTime supports the same annotations as before, i.e., NamedEntityTagAnnotation is set with the label of the numeric entity (DATE, TIME, DURATION, MONEY, PERCENT, or NUMBER) and NormalizedNamedEntityTagAnnotation is set to the value of the normalized temporal expression.",set NamedEntityTagAnnotation with label,0,
CoreNLP,"SUTime supports the same annotations as before, i.e., NamedEntityTagAnnotation is set with the label of the numeric entity (DATE, TIME, DURATION, MONEY, PERCENT, or NUMBER) and NormalizedNamedEntityTagAnnotation is set to the value of the normalized temporal expression.",set NormalizedNamedEntityTagAnnotation to value,0,
CoreNLP,"Also, SUTime sets the TimexAnnotation key to an edu.stanford.nlp.time.Timex object, which contains the complete list of TIMEX3 fields for the corresponding expressions, such as “val”, “alt_val”, “type”, “tid”. This might be useful to developers interested in recovering complete TIMEX3 expressions.",set TimexAnnotation key to edu.stanford.nlp.time.Timex object,0,
CoreNLP,"Reference dates are by default extracted from the “datetime” and “date” tags in an xml document. To set a different set of tags to use, use the clean.datetags property. When using the API, reference dates can be added to an Annotation via edu.stanford.nlp.ling.CoreAnnotations.DocDateAnnotation, although note that when processing an xml document, the cleanxml annotator will overwrite the DocDateAnnotation if “datetime” or “date” are specified in the document.",extract  in xml document,0,
CoreNLP,"Reference dates are by default extracted from the “datetime” and “date” tags in an xml document. To set a different set of tags to use, use the clean.datetags property. When using the API, reference dates can be added to an Annotation via edu.stanford.nlp.ling.CoreAnnotations.DocDateAnnotation, although note that when processing an xml document, the cleanxml annotator will overwrite the DocDateAnnotation if “datetime” or “date” are specified in the document.",extract  from datetime date tags,0,
CoreNLP,"Reference dates are by default extracted from the “datetime” and “date” tags in an xml document. To set a different set of tags to use, use the clean.datetags property. When using the API, reference dates can be added to an Annotation via edu.stanford.nlp.ling.CoreAnnotations.DocDateAnnotation, although note that when processing an xml document, the cleanxml annotator will overwrite the DocDateAnnotation if “datetime” or “date” are specified in the document.",set different set of tags,0,
CoreNLP,"Reference dates are by default extracted from the “datetime” and “date” tags in an xml document. To set a different set of tags to use, use the clean.datetags property. When using the API, reference dates can be added to an Annotation via edu.stanford.nlp.ling.CoreAnnotations.DocDateAnnotation, although note that when processing an xml document, the cleanxml annotator will overwrite the DocDateAnnotation if “datetime” or “date” are specified in the document.",use clean.datetags property,0,
CoreNLP,"Reference dates are by default extracted from the “datetime” and “date” tags in an xml document. To set a different set of tags to use, use the clean.datetags property. When using the API, reference dates can be added to an Annotation via edu.stanford.nlp.ling.CoreAnnotations.DocDateAnnotation, although note that when processing an xml document, the cleanxml annotator will overwrite the DocDateAnnotation if “datetime” or “date” are specified in the document.",use API,0,
CoreNLP,"Reference dates are by default extracted from the “datetime” and “date” tags in an xml document. To set a different set of tags to use, use the clean.datetags property. When using the API, reference dates can be added to an Annotation via edu.stanford.nlp.ling.CoreAnnotations.DocDateAnnotation, although note that when processing an xml document, the cleanxml annotator will overwrite the DocDateAnnotation if “datetime” or “date” are specified in the document.",process xml document,0,
CoreNLP,"Reference dates are by default extracted from the “datetime” and “date” tags in an xml document. To set a different set of tags to use, use the clean.datetags property. When using the API, reference dates can be added to an Annotation via edu.stanford.nlp.ling.CoreAnnotations.DocDateAnnotation, although note that when processing an xml document, the cleanxml annotator will overwrite the DocDateAnnotation if “datetime” or “date” are specified in the document.",overwrite DocDateAnnotation,0,
CoreNLP,"Reference dates are by default extracted from the “datetime” and “date” tags in an xml document. To set a different set of tags to use, use the clean.datetags property. When using the API, reference dates can be added to an Annotation via edu.stanford.nlp.ling.CoreAnnotations.DocDateAnnotation, although note that when processing an xml document, the cleanxml annotator will overwrite the DocDateAnnotation if “datetime” or “date” are specified in the document.",add reference dates to annotation,0,
CoreNLP,"Reference dates are by default extracted from the “datetime” and “date” tags in an xml document. To set a different set of tags to use, use the clean.datetags property. When using the API, reference dates can be added to an Annotation via edu.stanford.nlp.ling.CoreAnnotations.DocDateAnnotation, although note that when processing an xml document, the cleanxml annotator will overwrite the DocDateAnnotation if “datetime” or “date” are specified in the document.",specify datetime in document,0,
CoreNLP,"Reference dates are by default extracted from the “datetime” and “date” tags in an xml document. To set a different set of tags to use, use the clean.datetags property. When using the API, reference dates can be added to an Annotation via edu.stanford.nlp.ling.CoreAnnotations.DocDateAnnotation, although note that when processing an xml document, the cleanxml annotator will overwrite the DocDateAnnotation if “datetime” or “date” are specified in the document.",specify date in document,0,
CoreNLP,The DocDateAnnotator provides a variety of options for setting the document date. The ner annotator will run this annotator as a sub-annotator. These can be specified by setting properties for the ner.docdate sub-annotator.,provide variety of options,0,
CoreNLP,The DocDateAnnotator provides a variety of options for setting the document date. The ner annotator will run this annotator as a sub-annotator. These can be specified by setting properties for the ner.docdate sub-annotator.,set document date,0,
CoreNLP,The DocDateAnnotator provides a variety of options for setting the document date. The ner annotator will run this annotator as a sub-annotator. These can be specified by setting properties for the ner.docdate sub-annotator.,run annotator as sub-annotator,0,
CoreNLP,The DocDateAnnotator provides a variety of options for setting the document date. The ner annotator will run this annotator as a sub-annotator. These can be specified by setting properties for the ner.docdate sub-annotator.,set properties for ner.docdate sub-annotator,0,
CoreNLP,The following example shows how to access label confidences for tokens and entities. Each token stores the probability of its NER label given by the CRF that was used to assign the label in the CoreAnnotations.NamedEntityTagProbsAnnotation.class. Each entity mention contains the probability of the token with the lowest label probability in its span. For example if Los Angeles had the following probabilities:,access label confidences for tokens,1,https://stanfordnlp.github.io/CoreNLP/ner.html
CoreNLP,The following example shows how to access label confidences for tokens and entities. Each token stores the probability of its NER label given by the CRF that was used to assign the label in the CoreAnnotations.NamedEntityTagProbsAnnotation.class. Each entity mention contains the probability of the token with the lowest label probability in its span. For example if Los Angeles had the following probabilities:,access label confidences for entities,1,https://stanfordnlp.github.io/CoreNLP/ner.html
CoreNLP,The following example shows how to access label confidences for tokens and entities. Each token stores the probability of its NER label given by the CRF that was used to assign the label in the CoreAnnotations.NamedEntityTagProbsAnnotation.class. Each entity mention contains the probability of the token with the lowest label probability in its span. For example if Los Angeles had the following probabilities:,assign label in CoreAnnotations.NamedEntityTagProbsAnnotation.class,1,https://stanfordnlp.github.io/CoreNLP/ner.html
CoreNLP,The following example shows how to access label confidences for tokens and entities. Each token stores the probability of its NER label given by the CRF that was used to assign the label in the CoreAnnotations.NamedEntityTagProbsAnnotation.class. Each entity mention contains the probability of the token with the lowest label probability in its span. For example if Los Angeles had the following probabilities:,use CRF,1,https://stanfordnlp.github.io/CoreNLP/ner.html
CoreNLP,the entity Los Angeles would be assigned the LOCATION tag with a confidence of .992.,assign LOCATION tag with confidence,0,
CoreNLP,the entity Los Angeles would be assigned the LOCATION tag with a confidence of .992.,assign entity los Angeles with confidence,0,
CoreNLP,Below is code for accessing these confidences.,access confidences,1,https://stanfordnlp.github.io/CoreNLP/ner.html
CoreNLP,It is possible to run Stanford CoreNLP with NER models that ignore capitalization. We have trained models like this for English. You can find details on the Caseless models page.,run Stanford CoreNLP with NER models,0,
CoreNLP,It is possible to run Stanford CoreNLP with NER models that ignore capitalization. We have trained models like this for English. You can find details on the Caseless models page.,ignore capitalization,0,
CoreNLP,It is possible to run Stanford CoreNLP with NER models that ignore capitalization. We have trained models like this for English. You can find details on the Caseless models page.,ignore NER models,0,
CoreNLP,The training process can be customized using a properties file. Here is an example properties file for training an English model(ner.model.props):,use properties file,1,https://stanfordnlp.github.io/CoreNLP/ner.html
CoreNLP,"SUTime rules can be changed by modifying its included TokensRegex rule files. Changing other rule-based components (money, etc.) requires changes to the Java source code.",modify included TokensRegex rule files,0,
CoreNLP,"SUTime rules can be changed by modifying its included TokensRegex rule files. Changing other rule-based components (money, etc.) requires changes to the Java source code.",change SUTime rules,0,
CoreNLP,"SUTime rules can be changed by modifying its included TokensRegex rule files. Changing other rule-based components (money, etc.) requires changes to the Java source code.",change other rule-based components,0,
CoreNLP,Users can add custom annotators to StanfordCoreNLP.,add custom annotators to StanfordCoreNLP,0,
CoreNLP,First write the custom annotator class. Here is an example which will take in a dictionary that maps words to lemmas:,write custom annotator class,1,https://stanfordnlp.github.io/CoreNLP/new_annotator.html
CoreNLP,Then produce a properties file which allows Stanford CoreNLP to use your custom annotator:,produce properties,1,https://stanfordnlp.github.io/CoreNLP/new_annotator.html
CoreNLP,Then produce a properties file which allows Stanford CoreNLP to use your custom annotator:,use custom annotator,1,https://stanfordnlp.github.io/CoreNLP/new_annotator.html
CoreNLP,Finally you can run this example with this command:,run  with command,1,https://stanfordnlp.github.io/CoreNLP/new_annotator.html
CoreNLP,"The Open Information Extraction (OpenIE) annotator extracts open-domain relation triples, representing a subject, a relation, and the object of the relation. For example, born-in(Barack Obama, Hawaii). This is useful for (1) relation extraction tasks where there is limited or no training data, and it is easy to extract the information required from such open domain triples; and, (2) when speed is essential. The system can process around 100 sentences per second per CPU core. The Collection of extracted relation triples are stored under the RelationTriplesAnnotation key of a CoreMap (i.e., sentence). The OpenIE annotator (openie) requires the natural logic annotation (natlog).",extract open-domain relation triples,0,
CoreNLP,"The Open Information Extraction (OpenIE) annotator extracts open-domain relation triples, representing a subject, a relation, and the object of the relation. For example, born-in(Barack Obama, Hawaii). This is useful for (1) relation extraction tasks where there is limited or no training data, and it is easy to extract the information required from such open domain triples; and, (2) when speed is essential. The system can process around 100 sentences per second per CPU core. The Collection of extracted relation triples are stored under the RelationTriplesAnnotation key of a CoreMap (i.e., sentence). The OpenIE annotator (openie) requires the natural logic annotation (natlog).",extract information,0,
CoreNLP,"In addition to extracting relation triples, the annotator produces a number of sentence fragments corresponding to entailed fragments from the given original sentence. These are stored on the EntailedSentencesAnnotation key of a CoreMap (i.e., sentence).",extract relation triples,0,
CoreNLP,"In addition to extracting relation triples, the annotator produces a number of sentence fragments corresponding to entailed fragments from the given original sentence. These are stored on the EntailedSentencesAnnotation key of a CoreMap (i.e., sentence).",produce  in_addition_to extracting,0,
CoreNLP,All option are specified as Properties. The value of a property is always a String. The type referred to here is how the String will be interpreted/parsed.,specify option as properties,0,
CoreNLP,"The final group of options for specifying models are provided to fine-tune the inner workings of the OpenIE system. These should be changed only in very rare situations; for example, if you are developing extensions to the system itself.",specify models,0,
CoreNLP,"The final group of options for specifying models are provided to fine-tune the inner workings of the OpenIE system. These should be changed only in very rare situations; for example, if you are developing extensions to the system itself.",provide final group of options,0,
CoreNLP,"The final group of options for specifying models are provided to fine-tune the inner workings of the OpenIE system. These should be changed only in very rare situations; for example, if you are developing extensions to the system itself.",develop extensions to system,0,
CoreNLP,"The final group of options for specifying models are provided to fine-tune the inner workings of the OpenIE system. These should be changed only in very rare situations; for example, if you are developing extensions to the system itself.",change  in rare situations,0,
CoreNLP,"The OpenIE system can be run both through the command line, and through the CoreNLP API",run OpenIE system through command line,0,
CoreNLP,An interactive command-line shell can be run with the command:,run interactive command-line shell with command,1,https://stanfordnlp.github.io/CoreNLP/openie.html
CoreNLP,"In addition, the program can be run on a collection of files either by passing the files directly as command-line arguments:",pass files as command-line arguments,1,https://stanfordnlp.github.io/CoreNLP/openie.html
CoreNLP,"In addition, the program can be run on a collection of files either by passing the files directly as command-line arguments:",run program on collection,1,https://stanfordnlp.github.io/CoreNLP/openie.html
CoreNLP,"or by setting the -filelist argument to a file containing a list of files to annotate, one per line:",set filelist argument to file,1,https://stanfordnlp.github.io/CoreNLP/openie.html
CoreNLP,Relation triples can be accessed through the CoreNLP API using the standard annotation pipeline. An example class which does this is given below:,use standard annotation pipeline,1,https://stanfordnlp.github.io/CoreNLP/openie.html
CoreNLP,Relation triples can be accessed through the CoreNLP API using the standard annotation pipeline. An example class which does this is given below:,access relation triples through CoreNLP API,1,https://stanfordnlp.github.io/CoreNLP/openie.html
CoreNLP,"The Simple CoreNLP API includes bindings for the OpenIE system, via the method Sentence.openieTriples(). An example usage is given below:",include bindings for OpenIE system,1,https://stanfordnlp.github.io/CoreNLP/openie.html
CoreNLP,"The Simple CoreNLP API includes bindings for the OpenIE system, via the method Sentence.openieTriples(). An example usage is given below:",include bindings via method Sentence.openieTriples(),1,https://stanfordnlp.github.io/CoreNLP/openie.html
CoreNLP,Below are interfaces and packages for running Stanford CoreNLP from other languages or within other packages. They have been written by many other people (thanks!). In general you should contact these people directly if you have problems with these packages.,run Stanford CoreNLP within other packages,0,
CoreNLP,Below are interfaces and packages for running Stanford CoreNLP from other languages or within other packages. They have been written by many other people (thanks!). In general you should contact these people directly if you have problems with these packages.,run Stanford CoreNLP from other languages,0,
CoreNLP,"Note on running the CoreNLP server under docker: The container’s port 9000 has to be published to the host. For example, give a command like: docker run -p 9000:9000 --name coreNLP --rm -i -t motiz88/corenlp. If, when going to localhost:9000/, you see the error This site can’t be reached. localhost refused to connect, then this is what you failed to do!",run CoreNLP server under docker,0,
CoreNLP,"Note on running the CoreNLP server under docker: The container’s port 9000 has to be published to the host. For example, give a command like: docker run -p 9000:9000 --name coreNLP --rm -i -t motiz88/corenlp. If, when going to localhost:9000/, you see the error This site can’t be reached. localhost refused to connect, then this is what you failed to do!",reach site,0,
CoreNLP,"Note on running the CoreNLP server under docker: The container’s port 9000 has to be published to the host. For example, give a command like: docker run -p 9000:9000 --name coreNLP --rm -i -t motiz88/corenlp. If, when going to localhost:9000/, you see the error This site can’t be reached. localhost refused to connect, then this is what you failed to do!",reach error,0,
CoreNLP,And there are many others – it’s not so hard to build a dockerfile. Here are a few more:,build dockerfile,0,
CoreNLP,"We are actively developing a Python package called Stanza, with state-of-the-art NLP performance enabled by deep learning. Besides, this package also includes an API for starting and making requests to a Stanford CoreNLP server. It is the recommended way to use Stanford CoreNLP in Python.",develop Python package,0,
CoreNLP,"We are actively developing a Python package called Stanza, with state-of-the-art NLP performance enabled by deep learning. Besides, this package also includes an API for starting and making requests to a Stanford CoreNLP server. It is the recommended way to use Stanford CoreNLP in Python.",call stanza with state-of-the-art NLP performance,0,
CoreNLP,"We are actively developing a Python package called Stanza, with state-of-the-art NLP performance enabled by deep learning. Besides, this package also includes an API for starting and making requests to a Stanford CoreNLP server. It is the recommended way to use Stanford CoreNLP in Python.",include API for starting,0,
CoreNLP,"We are actively developing a Python package called Stanza, with state-of-the-art NLP performance enabled by deep learning. Besides, this package also includes an API for starting and making requests to a Stanford CoreNLP server. It is the recommended way to use Stanford CoreNLP in Python.",include API for making,0,
CoreNLP,"We are actively developing a Python package called Stanza, with state-of-the-art NLP performance enabled by deep learning. Besides, this package also includes an API for starting and making requests to a Stanford CoreNLP server. It is the recommended way to use Stanford CoreNLP in Python.",use Stanford CoreNLP in Python,0,
CoreNLP,These packages use the Stanford CoreNLP server that we’ve developed over the last couple of years.,use Stanford CoreNLP server,0,
CoreNLP,These packages use the Stanford CoreNLP server that we’ve developed over the last couple of years.,develop  over last couple,0,
CoreNLP,These packages are miscellaneous utilities or other frameworks that use Stanford CoreNLP.,use Stanford CoreNLP,0,
CoreNLP,These packages are miscellaneous utilities or other frameworks that use Stanford CoreNLP.,use other frameworks,0,
CoreNLP,"These are previous generation Python interfaces to Stanford CoreNLP, using a subprocess or their own server. They are now not generally being developed and are obsolete. (But thanks a lot to the people who wrote them in the early days!)",use own server,0,
CoreNLP,"These are previous generation Python interfaces to Stanford CoreNLP, using a subprocess or their own server. They are now not generally being developed and are obsolete. (But thanks a lot to the people who wrote them in the early days!)",use subprocess,0,
CoreNLP,CoreNLP wrapper for Apache Spark by Xiangrui Meng of Databricks. Last we checked it was at version 0.41 supporting version 3.9.1 of CoreNLP.,support version 3.9.1 of CoreNLP,0,
CoreNLP,"The Stanford Parser can be used to generate constituency and dependency parses of sentences for a variety of languages. The package includes PCFG, Shift Reduce, and Neural Dependency parsers. To fully utilize the parser, also make sure to download the models jar for the specific language you are interested in. Links to models jars provided below in History section or here.",use Stanford parser,0,
CoreNLP,"The Stanford Parser can be used to generate constituency and dependency parses of sentences for a variety of languages. The package includes PCFG, Shift Reduce, and Neural Dependency parsers. To fully utilize the parser, also make sure to download the models jar for the specific language you are interested in. Links to models jars provided below in History section or here.",include PCFG,0,
CoreNLP,"The Stanford Parser can be used to generate constituency and dependency parses of sentences for a variety of languages. The package includes PCFG, Shift Reduce, and Neural Dependency parsers. To fully utilize the parser, also make sure to download the models jar for the specific language you are interested in. Links to models jars provided below in History section or here.",include shift reduce,0,
CoreNLP,"The Stanford Parser can be used to generate constituency and dependency parses of sentences for a variety of languages. The package includes PCFG, Shift Reduce, and Neural Dependency parsers. To fully utilize the parser, also make sure to download the models jar for the specific language you are interested in. Links to models jars provided below in History section or here.",include Neural dependency parsers,0,
CoreNLP,"The Stanford Parser can be used to generate constituency and dependency parses of sentences for a variety of languages. The package includes PCFG, Shift Reduce, and Neural Dependency parsers. To fully utilize the parser, also make sure to download the models jar for the specific language you are interested in. Links to models jars provided below in History section or here.",download models jar for specific language,0,
CoreNLP,"If you are using Stanford NLP software for non-commercial purposes, you should use the full CoreNLP package.",use Stanford NLP software for non-commercial purposes,0,
CoreNLP,"If you are using Stanford NLP software for non-commercial purposes, you should use the full CoreNLP package.",use full CoreNLP package,0,
CoreNLP,"Parsing requires tokenization and in some cases part-of-speech tagging. The Stanford Parser distribution includes English tokenization, but does not provide tokenization used for French, German, and Spanish. Access to that tokenization requires using the full CoreNLP package. Likewise usage of the part-of-speech tagging models requires the license for the Stanford POS tagger or full CoreNLP distribution.",include English tokenization,0,
CoreNLP,"Parsing requires tokenization and in some cases part-of-speech tagging. The Stanford Parser distribution includes English tokenization, but does not provide tokenization used for French, German, and Spanish. Access to that tokenization requires using the full CoreNLP package. Likewise usage of the part-of-speech tagging models requires the license for the Stanford POS tagger or full CoreNLP distribution.",use  for french,0,
CoreNLP,"Parsing requires tokenization and in some cases part-of-speech tagging. The Stanford Parser distribution includes English tokenization, but does not provide tokenization used for French, German, and Spanish. Access to that tokenization requires using the full CoreNLP package. Likewise usage of the part-of-speech tagging models requires the license for the Stanford POS tagger or full CoreNLP distribution.",use  for german,0,
CoreNLP,"Parsing requires tokenization and in some cases part-of-speech tagging. The Stanford Parser distribution includes English tokenization, but does not provide tokenization used for French, German, and Spanish. Access to that tokenization requires using the full CoreNLP package. Likewise usage of the part-of-speech tagging models requires the license for the Stanford POS tagger or full CoreNLP distribution.",use  for spanish,0,
CoreNLP,"Parsing requires tokenization and in some cases part-of-speech tagging. The Stanford Parser distribution includes English tokenization, but does not provide tokenization used for French, German, and Spanish. Access to that tokenization requires using the full CoreNLP package. Likewise usage of the part-of-speech tagging models requires the license for the Stanford POS tagger or full CoreNLP distribution.",use full CoreNLP package,0,
CoreNLP,"The parser code is dual licensed (in a similar manner to MySQL, etc.). Open source licensing is under the full GPL, which allows many free uses. For distributors of proprietary software, commercial licensing is available. (Fine print: The traditional (dynamic programmed) Stanford Parser does part-of-speech tagging as it works, but the newer constituency and neural network dependency shift-reduce parsers require pre-tagged input. For convenience, we include the part-of-speech tagger code, but not models with the parser download. However, if you want to use these parsers under a commercial license, then you need a license to both the Stanford Parser and the Stanford POS tagger. Or you can get the whole bundle of Stanford CoreNLP.) If you don’t need a commercial license, but would like to support maintenance of these tools, we welcome gift funding: use this form and write “Stanford NLP Group open source software” in the Special Instructions.",include part-of-speech tagger code with parser download,0,
CoreNLP,"The parser code is dual licensed (in a similar manner to MySQL, etc.). Open source licensing is under the full GPL, which allows many free uses. For distributors of proprietary software, commercial licensing is available. (Fine print: The traditional (dynamic programmed) Stanford Parser does part-of-speech tagging as it works, but the newer constituency and neural network dependency shift-reduce parsers require pre-tagged input. For convenience, we include the part-of-speech tagger code, but not models with the parser download. However, if you want to use these parsers under a commercial license, then you need a license to both the Stanford Parser and the Stanford POS tagger. Or you can get the whole bundle of Stanford CoreNLP.) If you don’t need a commercial license, but would like to support maintenance of these tools, we welcome gift funding: use this form and write “Stanford NLP Group open source software” in the Special Instructions.",include part-of-speech tagger code for convenience,0,
CoreNLP,"The parser code is dual licensed (in a similar manner to MySQL, etc.). Open source licensing is under the full GPL, which allows many free uses. For distributors of proprietary software, commercial licensing is available. (Fine print: The traditional (dynamic programmed) Stanford Parser does part-of-speech tagging as it works, but the newer constituency and neural network dependency shift-reduce parsers require pre-tagged input. For convenience, we include the part-of-speech tagger code, but not models with the parser download. However, if you want to use these parsers under a commercial license, then you need a license to both the Stanford Parser and the Stanford POS tagger. Or you can get the whole bundle of Stanford CoreNLP.) If you don’t need a commercial license, but would like to support maintenance of these tools, we welcome gift funding: use this form and write “Stanford NLP Group open source software” in the Special Instructions.",include models with parser download,0,
CoreNLP,"The parser code is dual licensed (in a similar manner to MySQL, etc.). Open source licensing is under the full GPL, which allows many free uses. For distributors of proprietary software, commercial licensing is available. (Fine print: The traditional (dynamic programmed) Stanford Parser does part-of-speech tagging as it works, but the newer constituency and neural network dependency shift-reduce parsers require pre-tagged input. For convenience, we include the part-of-speech tagger code, but not models with the parser download. However, if you want to use these parsers under a commercial license, then you need a license to both the Stanford Parser and the Stanford POS tagger. Or you can get the whole bundle of Stanford CoreNLP.) If you don’t need a commercial license, but would like to support maintenance of these tools, we welcome gift funding: use this form and write “Stanford NLP Group open source software” in the Special Instructions.",include models for convenience,0,
CoreNLP,"The parser code is dual licensed (in a similar manner to MySQL, etc.). Open source licensing is under the full GPL, which allows many free uses. For distributors of proprietary software, commercial licensing is available. (Fine print: The traditional (dynamic programmed) Stanford Parser does part-of-speech tagging as it works, but the newer constituency and neural network dependency shift-reduce parsers require pre-tagged input. For convenience, we include the part-of-speech tagger code, but not models with the parser download. However, if you want to use these parsers under a commercial license, then you need a license to both the Stanford Parser and the Stanford POS tagger. Or you can get the whole bundle of Stanford CoreNLP.) If you don’t need a commercial license, but would like to support maintenance of these tools, we welcome gift funding: use this form and write “Stanford NLP Group open source software” in the Special Instructions.",use parsers under commercial license,0,
CoreNLP,"The parser code is dual licensed (in a similar manner to MySQL, etc.). Open source licensing is under the full GPL, which allows many free uses. For distributors of proprietary software, commercial licensing is available. (Fine print: The traditional (dynamic programmed) Stanford Parser does part-of-speech tagging as it works, but the newer constituency and neural network dependency shift-reduce parsers require pre-tagged input. For convenience, we include the part-of-speech tagger code, but not models with the parser download. However, if you want to use these parsers under a commercial license, then you need a license to both the Stanford Parser and the Stanford POS tagger. Or you can get the whole bundle of Stanford CoreNLP.) If you don’t need a commercial license, but would like to support maintenance of these tools, we welcome gift funding: use this form and write “Stanford NLP Group open source software” in the Special Instructions.",support maintenance of tools,0,
CoreNLP,"The parser code is dual licensed (in a similar manner to MySQL, etc.). Open source licensing is under the full GPL, which allows many free uses. For distributors of proprietary software, commercial licensing is available. (Fine print: The traditional (dynamic programmed) Stanford Parser does part-of-speech tagging as it works, but the newer constituency and neural network dependency shift-reduce parsers require pre-tagged input. For convenience, we include the part-of-speech tagger code, but not models with the parser download. However, if you want to use these parsers under a commercial license, then you need a license to both the Stanford Parser and the Stanford POS tagger. Or you can get the whole bundle of Stanford CoreNLP.) If you don’t need a commercial license, but would like to support maintenance of these tools, we welcome gift funding: use this form and write “Stanford NLP Group open source software” in the Special Instructions.",use form,0,
CoreNLP,"The parser code is dual licensed (in a similar manner to MySQL, etc.). Open source licensing is under the full GPL, which allows many free uses. For distributors of proprietary software, commercial licensing is available. (Fine print: The traditional (dynamic programmed) Stanford Parser does part-of-speech tagging as it works, but the newer constituency and neural network dependency shift-reduce parsers require pre-tagged input. For convenience, we include the part-of-speech tagger code, but not models with the parser download. However, if you want to use these parsers under a commercial license, then you need a license to both the Stanford Parser and the Stanford POS tagger. Or you can get the whole bundle of Stanford CoreNLP.) If you don’t need a commercial license, but would like to support maintenance of these tools, we welcome gift funding: use this form and write “Stanford NLP Group open source software” in the Special Instructions.",write stanford NLP group,0,
CoreNLP,"Provides full syntactic analysis, minimally a constituency (phrase-structure tree) parse of sentences. If a rule-based conversion from constituency parses to dependency parses is available (this is currently the case for English and Chinese, only), then a dependency representation is also generated using this conversion. The constituent-based output is saved in TreeAnnotation. We generate three dependency-based outputs, as follows: basic dependencies, saved in BasicDependenciesAnnotation; enhanced dependencies saved in EnhancedDependenciesAnnotation; and enhanced++ dependencies in EnhancedPlusPlusDependenciesAnnotation. Most users of our parser will prefer the latter representation. Constituency parsers internally generate binary parse trees, which can also be saved.",provide full syntactic analysis,0,
CoreNLP,"Provides full syntactic analysis, minimally a constituency (phrase-structure tree) parse of sentences. If a rule-based conversion from constituency parses to dependency parses is available (this is currently the case for English and Chinese, only), then a dependency representation is also generated using this conversion. The constituent-based output is saved in TreeAnnotation. We generate three dependency-based outputs, as follows: basic dependencies, saved in BasicDependenciesAnnotation; enhanced dependencies saved in EnhancedDependenciesAnnotation; and enhanced++ dependencies in EnhancedPlusPlusDependenciesAnnotation. Most users of our parser will prefer the latter representation. Constituency parsers internally generate binary parse trees, which can also be saved.",use conversion,0,
CoreNLP,"Provides full syntactic analysis, minimally a constituency (phrase-structure tree) parse of sentences. If a rule-based conversion from constituency parses to dependency parses is available (this is currently the case for English and Chinese, only), then a dependency representation is also generated using this conversion. The constituent-based output is saved in TreeAnnotation. We generate three dependency-based outputs, as follows: basic dependencies, saved in BasicDependenciesAnnotation; enhanced dependencies saved in EnhancedDependenciesAnnotation; and enhanced++ dependencies in EnhancedPlusPlusDependenciesAnnotation. Most users of our parser will prefer the latter representation. Constituency parsers internally generate binary parse trees, which can also be saved.",save constituent-based output in TreeAnnotation,0,
CoreNLP,"Provides full syntactic analysis, minimally a constituency (phrase-structure tree) parse of sentences. If a rule-based conversion from constituency parses to dependency parses is available (this is currently the case for English and Chinese, only), then a dependency representation is also generated using this conversion. The constituent-based output is saved in TreeAnnotation. We generate three dependency-based outputs, as follows: basic dependencies, saved in BasicDependenciesAnnotation; enhanced dependencies saved in EnhancedDependenciesAnnotation; and enhanced++ dependencies in EnhancedPlusPlusDependenciesAnnotation. Most users of our parser will prefer the latter representation. Constituency parsers internally generate binary parse trees, which can also be saved.",save  in basicdependenciesannotation,0,
CoreNLP,"Provides full syntactic analysis, minimally a constituency (phrase-structure tree) parse of sentences. If a rule-based conversion from constituency parses to dependency parses is available (this is currently the case for English and Chinese, only), then a dependency representation is also generated using this conversion. The constituent-based output is saved in TreeAnnotation. We generate three dependency-based outputs, as follows: basic dependencies, saved in BasicDependenciesAnnotation; enhanced dependencies saved in EnhancedDependenciesAnnotation; and enhanced++ dependencies in EnhancedPlusPlusDependenciesAnnotation. Most users of our parser will prefer the latter representation. Constituency parsers internally generate binary parse trees, which can also be saved.",save  in enhanceddependenciesannotation,0,
CoreNLP,"Provides full syntactic analysis, minimally a constituency (phrase-structure tree) parse of sentences. If a rule-based conversion from constituency parses to dependency parses is available (this is currently the case for English and Chinese, only), then a dependency representation is also generated using this conversion. The constituent-based output is saved in TreeAnnotation. We generate three dependency-based outputs, as follows: basic dependencies, saved in BasicDependenciesAnnotation; enhanced dependencies saved in EnhancedDependenciesAnnotation; and enhanced++ dependencies in EnhancedPlusPlusDependenciesAnnotation. Most users of our parser will prefer the latter representation. Constituency parsers internally generate binary parse trees, which can also be saved.",save parse trees,0,
CoreNLP,"If you only need dependency parses, then you can get only dependency parses more quickly (and using less memory) by using the direct dependency parser annotator depparse. Note that this is a separate annotator, with different options.",use direct dependency parser annotator depparse,0,
CoreNLP,"Note: The values of all options, in a Properties object or on the command-line, are of type String. The listed type says what kinds of values are appropriate and hence how the String will be parsed.",parse String,0,
CoreNLP,It is possible to run StanfordCoreNLP with a parser model that ignores capitalization. We have trained models like this for English. You can find details on the Caseless models page.,run StanfordCoreNLP with parser model,0,
CoreNLP,It is possible to run StanfordCoreNLP with a parser model that ignores capitalization. We have trained models like this for English. You can find details on the Caseless models page.,ignore capitalization,0,
CoreNLP,It is possible to run StanfordCoreNLP with a parser model that ignores capitalization. We have trained models like this for English. You can find details on the Caseless models page.,ignore parser model,0,
CoreNLP,"All of our parsers make use of parts of speech. Some of the models (e.g., neural dependency parser and shift-reduce parser) require an external PoS tagger; you must specify the pos annotator. Other parsers, such as the PCFG and Factored parsers can either do their own PoS tagging or use an external PoS tagger as a preprocessor. If you want to use a parser as the PoS tagger, make sure you do not include pos in the list of annotators and position the annotator parse prior to any other annotator that requires part-of-speech information (such as lemma):",specify pos annotator,1,https://stanfordnlp.github.io/CoreNLP/parse.html
CoreNLP,"All of our parsers make use of parts of speech. Some of the models (e.g., neural dependency parser and shift-reduce parser) require an external PoS tagger; you must specify the pos annotator. Other parsers, such as the PCFG and Factored parsers can either do their own PoS tagging or use an external PoS tagger as a preprocessor. If you want to use a parser as the PoS tagger, make sure you do not include pos in the list of annotators and position the annotator parse prior to any other annotator that requires part-of-speech information (such as lemma):",use external pos tagger as preprocessor,1,https://stanfordnlp.github.io/CoreNLP/parse.html
CoreNLP,"All of our parsers make use of parts of speech. Some of the models (e.g., neural dependency parser and shift-reduce parser) require an external PoS tagger; you must specify the pos annotator. Other parsers, such as the PCFG and Factored parsers can either do their own PoS tagging or use an external PoS tagger as a preprocessor. If you want to use a parser as the PoS tagger, make sure you do not include pos in the list of annotators and position the annotator parse prior to any other annotator that requires part-of-speech information (such as lemma):",use parser as pos tagger,1,https://stanfordnlp.github.io/CoreNLP/parse.html
CoreNLP,"For more details on the original parsers, please see this page. There is also a page on the shift reduce parser. For more details about Stanford dependencies, please refer to this page. A separate site documents Universal Dependencies.",document universal Dependencies,0,
CoreNLP,"StanfordCoreNLP includes Bootstrapped Pattern Learning, a framework for learning patterns to learn entities of given entity types from unlabeled text starting with seed sets of entities.",include bootstrapped Pattern learning,0,
CoreNLP,"StanfordCoreNLP includes Bootstrapped Pattern Learning, a framework for learning patterns to learn entities of given entity types from unlabeled text starting with seed sets of entities.",learn patterns,0,
CoreNLP,"StanfordCoreNLP includes Bootstrapped Pattern Learning, a framework for learning patterns to learn entities of given entity types from unlabeled text starting with seed sets of entities.",learn entities of given entity types,0,
CoreNLP,"StanfordCoreNLP includes Bootstrapped Pattern Learning, a framework for learning patterns to learn entities of given entity types from unlabeled text starting with seed sets of entities.",learn entities from unlabeled text,0,
CoreNLP,"CoreNLP implements an annotation pipeline. An Annotation object is used that stores analyses of a piece of text. It is a Map. Initially, the text of a document is added to the Annotation as its only contents. Then, an AnnotationPipeline is run on the Annotation. An AnnotationPipeline is essentially a List of Annotators, each of which is run in turn. (And an AnnotationPipeline is itself an Annotator, so you can actually nest AnnotationPipelines inside each other.) Each Annotator reads the value of one or more keys from the Annotation, does some natural language analysis, and then writes the results back to the Annotation. Typically, each Annotator stores its analyses under different keys, so that the information stored in an Annotation is cumulative rather than things being overwritten. The overall picture is given in this picture.",use stores analyses of piece,0,
CoreNLP,"CoreNLP implements an annotation pipeline. An Annotation object is used that stores analyses of a piece of text. It is a Map. Initially, the text of a document is added to the Annotation as its only contents. Then, an AnnotationPipeline is run on the Annotation. An AnnotationPipeline is essentially a List of Annotators, each of which is run in turn. (And an AnnotationPipeline is itself an Annotator, so you can actually nest AnnotationPipelines inside each other.) Each Annotator reads the value of one or more keys from the Annotation, does some natural language analysis, and then writes the results back to the Annotation. Typically, each Annotator stores its analyses under different keys, so that the information stored in an Annotation is cumulative rather than things being overwritten. The overall picture is given in this picture.",use annotation object of piece,0,
CoreNLP,"CoreNLP implements an annotation pipeline. An Annotation object is used that stores analyses of a piece of text. It is a Map. Initially, the text of a document is added to the Annotation as its only contents. Then, an AnnotationPipeline is run on the Annotation. An AnnotationPipeline is essentially a List of Annotators, each of which is run in turn. (And an AnnotationPipeline is itself an Annotator, so you can actually nest AnnotationPipelines inside each other.) Each Annotator reads the value of one or more keys from the Annotation, does some natural language analysis, and then writes the results back to the Annotation. Typically, each Annotator stores its analyses under different keys, so that the information stored in an Annotation is cumulative rather than things being overwritten. The overall picture is given in this picture.",add text as only contents,0,
CoreNLP,"CoreNLP implements an annotation pipeline. An Annotation object is used that stores analyses of a piece of text. It is a Map. Initially, the text of a document is added to the Annotation as its only contents. Then, an AnnotationPipeline is run on the Annotation. An AnnotationPipeline is essentially a List of Annotators, each of which is run in turn. (And an AnnotationPipeline is itself an Annotator, so you can actually nest AnnotationPipelines inside each other.) Each Annotator reads the value of one or more keys from the Annotation, does some natural language analysis, and then writes the results back to the Annotation. Typically, each Annotator stores its analyses under different keys, so that the information stored in an Annotation is cumulative rather than things being overwritten. The overall picture is given in this picture.",add text of document,0,
CoreNLP,"CoreNLP implements an annotation pipeline. An Annotation object is used that stores analyses of a piece of text. It is a Map. Initially, the text of a document is added to the Annotation as its only contents. Then, an AnnotationPipeline is run on the Annotation. An AnnotationPipeline is essentially a List of Annotators, each of which is run in turn. (And an AnnotationPipeline is itself an Annotator, so you can actually nest AnnotationPipelines inside each other.) Each Annotator reads the value of one or more keys from the Annotation, does some natural language analysis, and then writes the results back to the Annotation. Typically, each Annotator stores its analyses under different keys, so that the information stored in an Annotation is cumulative rather than things being overwritten. The overall picture is given in this picture.",add text to annotation,0,
CoreNLP,"CoreNLP implements an annotation pipeline. An Annotation object is used that stores analyses of a piece of text. It is a Map. Initially, the text of a document is added to the Annotation as its only contents. Then, an AnnotationPipeline is run on the Annotation. An AnnotationPipeline is essentially a List of Annotators, each of which is run in turn. (And an AnnotationPipeline is itself an Annotator, so you can actually nest AnnotationPipelines inside each other.) Each Annotator reads the value of one or more keys from the Annotation, does some natural language analysis, and then writes the results back to the Annotation. Typically, each Annotator stores its analyses under different keys, so that the information stored in an Annotation is cumulative rather than things being overwritten. The overall picture is given in this picture.",run AnnotationPipeline on annotation,0,
CoreNLP,"CoreNLP implements an annotation pipeline. An Annotation object is used that stores analyses of a piece of text. It is a Map. Initially, the text of a document is added to the Annotation as its only contents. Then, an AnnotationPipeline is run on the Annotation. An AnnotationPipeline is essentially a List of Annotators, each of which is run in turn. (And an AnnotationPipeline is itself an Annotator, so you can actually nest AnnotationPipelines inside each other.) Each Annotator reads the value of one or more keys from the Annotation, does some natural language analysis, and then writes the results back to the Annotation. Typically, each Annotator stores its analyses under different keys, so that the information stored in an Annotation is cumulative rather than things being overwritten. The overall picture is given in this picture.",run annotator s in turn,0,
CoreNLP,"Around this basic skeleton, StanfordCoreNLP adds a lot of stuff, for processing options, caching Annotators, writing output in different formats, and all the other modcons of life. Normally, this stuff is convenient to have. However, if it is getting in your way, you can actually fairly easily make your own AnnotationPipeline using either or both the various Annotators provided with CoreNLP or additional implementations of Annotator that you write. In Java code, creating an AnnotationPipeline looks something like this:",add lot of stuff,1,https://stanfordnlp.github.io/CoreNLP/pipelines.html
CoreNLP,"Around this basic skeleton, StanfordCoreNLP adds a lot of stuff, for processing options, caching Annotators, writing output in different formats, and all the other modcons of life. Normally, this stuff is convenient to have. However, if it is getting in your way, you can actually fairly easily make your own AnnotationPipeline using either or both the various Annotators provided with CoreNLP or additional implementations of Annotator that you write. In Java code, creating an AnnotationPipeline looks something like this:",add lot for processing options,1,https://stanfordnlp.github.io/CoreNLP/pipelines.html
CoreNLP,"Around this basic skeleton, StanfordCoreNLP adds a lot of stuff, for processing options, caching Annotators, writing output in different formats, and all the other modcons of life. Normally, this stuff is convenient to have. However, if it is getting in your way, you can actually fairly easily make your own AnnotationPipeline using either or both the various Annotators provided with CoreNLP or additional implementations of Annotator that you write. In Java code, creating an AnnotationPipeline looks something like this:",add lot around basic skeleton,1,https://stanfordnlp.github.io/CoreNLP/pipelines.html
CoreNLP,"Around this basic skeleton, StanfordCoreNLP adds a lot of stuff, for processing options, caching Annotators, writing output in different formats, and all the other modcons of life. Normally, this stuff is convenient to have. However, if it is getting in your way, you can actually fairly easily make your own AnnotationPipeline using either or both the various Annotators provided with CoreNLP or additional implementations of Annotator that you write. In Java code, creating an AnnotationPipeline looks something like this:",cache annotator s,1,https://stanfordnlp.github.io/CoreNLP/pipelines.html
CoreNLP,"Around this basic skeleton, StanfordCoreNLP adds a lot of stuff, for processing options, caching Annotators, writing output in different formats, and all the other modcons of life. Normally, this stuff is convenient to have. However, if it is getting in your way, you can actually fairly easily make your own AnnotationPipeline using either or both the various Annotators provided with CoreNLP or additional implementations of Annotator that you write. In Java code, creating an AnnotationPipeline looks something like this:",write output in different formats,1,https://stanfordnlp.github.io/CoreNLP/pipelines.html
CoreNLP,"Around this basic skeleton, StanfordCoreNLP adds a lot of stuff, for processing options, caching Annotators, writing output in different formats, and all the other modcons of life. Normally, this stuff is convenient to have. However, if it is getting in your way, you can actually fairly easily make your own AnnotationPipeline using either or both the various Annotators provided with CoreNLP or additional implementations of Annotator that you write. In Java code, creating an AnnotationPipeline looks something like this:",write output of life,1,https://stanfordnlp.github.io/CoreNLP/pipelines.html
CoreNLP,"Around this basic skeleton, StanfordCoreNLP adds a lot of stuff, for processing options, caching Annotators, writing output in different formats, and all the other modcons of life. Normally, this stuff is convenient to have. However, if it is getting in your way, you can actually fairly easily make your own AnnotationPipeline using either or both the various Annotators provided with CoreNLP or additional implementations of Annotator that you write. In Java code, creating an AnnotationPipeline looks something like this:",write other modcons in different formats,1,https://stanfordnlp.github.io/CoreNLP/pipelines.html
CoreNLP,"Around this basic skeleton, StanfordCoreNLP adds a lot of stuff, for processing options, caching Annotators, writing output in different formats, and all the other modcons of life. Normally, this stuff is convenient to have. However, if it is getting in your way, you can actually fairly easily make your own AnnotationPipeline using either or both the various Annotators provided with CoreNLP or additional implementations of Annotator that you write. In Java code, creating an AnnotationPipeline looks something like this:",write other modcons of life,1,https://stanfordnlp.github.io/CoreNLP/pipelines.html
CoreNLP,"Around this basic skeleton, StanfordCoreNLP adds a lot of stuff, for processing options, caching Annotators, writing output in different formats, and all the other modcons of life. Normally, this stuff is convenient to have. However, if it is getting in your way, you can actually fairly easily make your own AnnotationPipeline using either or both the various Annotators provided with CoreNLP or additional implementations of Annotator that you write. In Java code, creating an AnnotationPipeline looks something like this:",use various annotator,1,https://stanfordnlp.github.io/CoreNLP/pipelines.html
CoreNLP,"Around this basic skeleton, StanfordCoreNLP adds a lot of stuff, for processing options, caching Annotators, writing output in different formats, and all the other modcons of life. Normally, this stuff is convenient to have. However, if it is getting in your way, you can actually fairly easily make your own AnnotationPipeline using either or both the various Annotators provided with CoreNLP or additional implementations of Annotator that you write. In Java code, creating an AnnotationPipeline looks something like this:",get  in way,1,https://stanfordnlp.github.io/CoreNLP/pipelines.html
CoreNLP,"Around this basic skeleton, StanfordCoreNLP adds a lot of stuff, for processing options, caching Annotators, writing output in different formats, and all the other modcons of life. Normally, this stuff is convenient to have. However, if it is getting in your way, you can actually fairly easily make your own AnnotationPipeline using either or both the various Annotators provided with CoreNLP or additional implementations of Annotator that you write. In Java code, creating an AnnotationPipeline looks something like this:",provide various annotator with CoreNLP additional implementations,1,https://stanfordnlp.github.io/CoreNLP/pipelines.html
CoreNLP,This pipeline could be used like this:,use pipeline,1,https://stanfordnlp.github.io/CoreNLP/pipelines.html
CoreNLP,"With a custom analysis pipeline, only the first method is used. The other two methods are used in StanfordCoreNLP to check for dependencies between Annotators.",use first method with custom analysis pipeline,0,
CoreNLP,"With a custom analysis pipeline, only the first method is used. The other two methods are used in StanfordCoreNLP to check for dependencies between Annotators.",use other methods in StanfordCoreNLP,0,
CoreNLP,"With a custom analysis pipeline, only the first method is used. The other two methods are used in StanfordCoreNLP to check for dependencies between Annotators.",check  for dependencies,0,
CoreNLP,"A new thing provided with v.3.9 of CoreNLP is a default WebServiceAnnotator. This is an abstract implementation of an Annotator that makes it relatively easy to tie external webservices into a CoreNLP AnnotationPipeline. You simply have to provide a class that extends this class and which specifies three methods which say how to call your webservice, how to check if it’s running, and (optionally) how to start the webservice.",provide  with v.3.9,0,
CoreNLP,"A new thing provided with v.3.9 of CoreNLP is a default WebServiceAnnotator. This is an abstract implementation of an Annotator that makes it relatively easy to tie external webservices into a CoreNLP AnnotationPipeline. You simply have to provide a class that extends this class and which specifies three methods which say how to call your webservice, how to check if it’s running, and (optionally) how to start the webservice.",provide class,0,
CoreNLP,"A new thing provided with v.3.9 of CoreNLP is a default WebServiceAnnotator. This is an abstract implementation of an Annotator that makes it relatively easy to tie external webservices into a CoreNLP AnnotationPipeline. You simply have to provide a class that extends this class and which specifies three methods which say how to call your webservice, how to check if it’s running, and (optionally) how to start the webservice.",specify methods,0,
CoreNLP,"A new thing provided with v.3.9 of CoreNLP is a default WebServiceAnnotator. This is an abstract implementation of an Annotator that makes it relatively easy to tie external webservices into a CoreNLP AnnotationPipeline. You simply have to provide a class that extends this class and which specifies three methods which say how to call your webservice, how to check if it’s running, and (optionally) how to start the webservice.",call webservice,0,
CoreNLP,Pipelines are constructed with Properties objects which provide specifications for what annotators to run and how to customize the annotators.,provide specifications,0,
CoreNLP,Pipelines are constructed with Properties objects which provide specifications for what annotators to run and how to customize the annotators.,provide Properties objects,0,
CoreNLP,You can immediately run a pipeline by issuing the following command:,run pipeline by issuing,1,https://stanfordnlp.github.io/CoreNLP/pipeline.html
CoreNLP,You can customize your pipeline by providing properties in a properties file.,provide properties in properties file,1,https://stanfordnlp.github.io/CoreNLP/pipeline.html
CoreNLP,Here is the command for running a pipeline with these configurations:,run pipeline with configurations,1,https://stanfordnlp.github.io/CoreNLP/pipeline.html
CoreNLP,Of course all of those properties could be specified at the command line as well:,specify properties at command line,1,https://stanfordnlp.github.io/CoreNLP/pipeline.html
CoreNLP,"If you want to run a non-English language pipeline, you can just specify the name of one of the CoreNLP supported languages:",run non-english language pipeline,1,https://stanfordnlp.github.io/CoreNLP/pipeline.html
CoreNLP,"If you want to run a non-English language pipeline, you can just specify the name of one of the CoreNLP supported languages:",specify name of CoreNLP,1,https://stanfordnlp.github.io/CoreNLP/pipeline.html
CoreNLP,"If you want to run a non-English language pipeline, you can just specify the name of one of the CoreNLP supported languages:",support languages,1,https://stanfordnlp.github.io/CoreNLP/pipeline.html
CoreNLP,Here is a basic demo class showing how to run a pipeline in Java code:,run pipeline in Java code,1,https://stanfordnlp.github.io/CoreNLP/pipeline.html
CoreNLP,"To customize pipelines in Java, add properties to the Properties object in the same way the annotators property is set in the code example.",add properties to Properties object,0,
CoreNLP,"To customize pipelines in Java, add properties to the Properties object in the same way the annotators property is set in the code example.",set annotators property,0,
CoreNLP,"Part of speech tagging assigns part of speech labels to tokens, such as whether they are verbs or nouns. Every token in a sentence is applied a tag. For instance, in the sentence Marie was born in Paris. the word Marie is assigned the tag NNP.",assign part of speech labels,0,
CoreNLP,"Part of speech tagging assigns part of speech labels to tokens, such as whether they are verbs or nouns. Every token in a sentence is applied a tag. For instance, in the sentence Marie was born in Paris. the word Marie is assigned the tag NNP.",assign part to tokens,0,
CoreNLP,"Part of speech tagging assigns part of speech labels to tokens, such as whether they are verbs or nouns. Every token in a sentence is applied a tag. For instance, in the sentence Marie was born in Paris. the word Marie is assigned the tag NNP.",assign part such_as verbs,0,
CoreNLP,"Part of speech tagging assigns part of speech labels to tokens, such as whether they are verbs or nouns. Every token in a sentence is applied a tag. For instance, in the sentence Marie was born in Paris. the word Marie is assigned the tag NNP.",assign part such_as nouns,0,
CoreNLP,"Part of speech tagging assigns part of speech labels to tokens, such as whether they are verbs or nouns. Every token in a sentence is applied a tag. For instance, in the sentence Marie was born in Paris. the word Marie is assigned the tag NNP.",assign tag NNP,0,
CoreNLP,"Part of speech tagging assigns part of speech labels to tokens, such as whether they are verbs or nouns. Every token in a sentence is applied a tag. For instance, in the sentence Marie was born in Paris. the word Marie is assigned the tag NNP.",assign word marie,0,
CoreNLP,This command will apply part of speech tags using a non-default model (e.g. the more powerful but slower bidirectional model):,use non-default model,1,https://stanfordnlp.github.io/CoreNLP/pos.html
CoreNLP,"If running on French, German, or Spanish, it is crucial to use the MWT annotator:",use MWT annotator,1,https://stanfordnlp.github.io/CoreNLP/pos.html
CoreNLP,"If running on French, German, or Spanish, it is crucial to use the MWT annotator:",run  on french,1,https://stanfordnlp.github.io/CoreNLP/pos.html
CoreNLP,"If running on French, German, or Spanish, it is crucial to use the MWT annotator:",run  on german,1,https://stanfordnlp.github.io/CoreNLP/pos.html
CoreNLP,"If running on French, German, or Spanish, it is crucial to use the MWT annotator:",run  on spanish,1,https://stanfordnlp.github.io/CoreNLP/pos.html
CoreNLP,CoreNLP dependency parser models are trained with a PyTorch system for speed considerations. The PyTorch models can be converted to the format CoreNLP’s dependency parser expects.,convert PyTorch models to format,0,
CoreNLP,"The purpose of this library is to train models for the Java code base. If you want a full featured Python dependency parser, you should look into using Stanza.",use stanza,0,
CoreNLP,"Note that the above command will automatically tag the input data with the CoreNLP tagger. Thus you need to have CoreNLP and the Italian models (for this example) in your CLASSPATH, and you need the latest version of Stanza installed.",tag input data with CoreNLP tagger,0,
CoreNLP,"Why is this done? When CoreNLP runs a dependency parser, it relies on part of speech tags, so the training and development data used during training need to have the predicted tags CoreNLP will use for optimal performance.",run dependency parser,0,
CoreNLP,"Why is this done? When CoreNLP runs a dependency parser, it relies on part of speech tags, so the training and development data used during training need to have the predicted tags CoreNLP will use for optimal performance.",use  during training,0,
CoreNLP,"Why is this done? When CoreNLP runs a dependency parser, it relies on part of speech tags, so the training and development data used during training need to have the predicted tags CoreNLP will use for optimal performance.",use predicted tags CoreNLP for optimal performance,0,
CoreNLP,"After the model is trained, it can be converted to a format usable by CoreNLP:",convert  to format usable,1,https://stanfordnlp.github.io/CoreNLP/pytorch-depparse.html
CoreNLP,This will save a CoreNLP useable model at /path/to/italian-corenlp-parser.txt.,save CoreNLP useable model at /path/to/italian-corenlp-parser.txt,0,
CoreNLP,"Deterministically picks out quotes from a text. All top-level quotes, are supplied by the top level annotation for a text. If a QuotationAnnotation corresponds to a quote that contains embedded quotes, these quotes will appear as embedded QuotationAnnotations that can be accessed from the QuotationAnnotation that they are embedded in. The QuoteAnnotator can handle multi-line and cross-paragraph quotes, but any embedded quotes must be delimited by a different kind of quotation mark than its parents.",access embedded QuotationAnnotations from QuotationAnnotation,0,
CoreNLP,"Deterministically picks out quotes from a text. All top-level quotes, are supplied by the top level annotation for a text. If a QuotationAnnotation corresponds to a quote that contains embedded quotes, these quotes will appear as embedded QuotationAnnotations that can be accessed from the QuotationAnnotation that they are embedded in. The QuoteAnnotator can handle multi-line and cross-paragraph quotes, but any embedded quotes must be delimited by a different kind of quotation mark than its parents.",handle multi-line cross-paragraph quotes,0,
CoreNLP,"Note: extracts everything within these pairs as a whole quote segment, which may or may not be the desired behaviour for texts that use different formatting styles than standard english ones.",use different formatting styles for texts,0,
CoreNLP,"Note: extracts everything within these pairs as a whole quote segment, which may or may not be the desired behaviour for texts that use different formatting styles than standard english ones.",use desired behaviour for texts,0,
CoreNLP,This can be deactivated by setting the quote.attributeQuotes property to false.,set quote.attributeQuotes property to false,0,
CoreNLP,If you run this command:,run command,1,https://stanfordnlp.github.io/CoreNLP/tokensregex.html
CoreNLP,You should get this output for the quote in the text:,get output for quote,1,https://stanfordnlp.github.io/CoreNLP/quote.html
CoreNLP,"If you didn’t want to run quote attribution, you would add -quote.attributeQuotes false to your command.",run quote attribution,0,
CoreNLP,"If you didn’t want to run quote attribution, you would add -quote.attributeQuotes false to your command.",add -quote.attributeQuotes false to command,0,
CoreNLP,You can use interactive mode with either StanfordCoreNLP or the combination of running StanfordCoreNLPServer and StanfordCoreNLPClient. You can specify whatever annotators and other properties that you want.,use interactive mode with StanfordCoreNLP,0,
CoreNLP,You can use interactive mode with either StanfordCoreNLP or the combination of running StanfordCoreNLPServer and StanfordCoreNLPClient. You can specify whatever annotators and other properties that you want.,use interactive mode with combination,0,
CoreNLP,You can use interactive mode with either StanfordCoreNLP or the combination of running StanfordCoreNLPServer and StanfordCoreNLPClient. You can specify whatever annotators and other properties that you want.,run StanfordCoreNLPClient,0,
CoreNLP,You can use interactive mode with either StanfordCoreNLP or the combination of running StanfordCoreNLPServer and StanfordCoreNLPClient. You can specify whatever annotators and other properties that you want.,run StanfordCoreNLPServer,0,
CoreNLP,You can use interactive mode with either StanfordCoreNLP or the combination of running StanfordCoreNLPServer and StanfordCoreNLPClient. You can specify whatever annotators and other properties that you want.,specify other properties,0,
CoreNLP,"If you do not specify any flag that directs CoreNLP to process text from a particular file, then after the pipeline is loaded, you will be placed into an interactive loop. (That is, if you don’t specify either -file or -filelist.)",process text from particular file,1,https://stanfordnlp.github.io/CoreNLP/repl.html
CoreNLP,"If you do not specify any flag that directs CoreNLP to process text from a particular file, then after the pipeline is loaded, you will be placed into an interactive loop. (That is, if you don’t specify either -file or -filelist.)",place  into interactive loop,1,https://stanfordnlp.github.io/CoreNLP/repl.html
CoreNLP,"If you do not specify any flag that directs CoreNLP to process text from a particular file, then after the pipeline is loaded, you will be placed into an interactive loop. (That is, if you don’t specify either -file or -filelist.)",load pipeline,1,https://stanfordnlp.github.io/CoreNLP/repl.html
CoreNLP,"If you are trying out the REPL for Java 9, you might want to try out using the CoreNLP simple API with it. It works quite well.",use CoreNLP simple API,0,
CoreNLP,"In this section, we include additional resources that might be helpful for you when using CoreNLP.",include additional resources in section,0,
CoreNLP,"In this section, we include additional resources that might be helpful for you when using CoreNLP.",use CoreNLP,0,
CoreNLP,StanfordCoreNLP includes the sentiment tool and various programs which support it. The model can be used to analyze text as part of StanfordCoreNLP by adding “sentiment” to the list of annotators. There is also command line support and model training support.,include sentiment tool,0,
CoreNLP,StanfordCoreNLP includes the sentiment tool and various programs which support it. The model can be used to analyze text as part of StanfordCoreNLP by adding “sentiment” to the list of annotators. There is also command line support and model training support.,include various programs,0,
CoreNLP,StanfordCoreNLP includes the sentiment tool and various programs which support it. The model can be used to analyze text as part of StanfordCoreNLP by adding “sentiment” to the list of annotators. There is also command line support and model training support.,support various programs,0,
CoreNLP,StanfordCoreNLP includes the sentiment tool and various programs which support it. The model can be used to analyze text as part of StanfordCoreNLP by adding “sentiment” to the list of annotators. There is also command line support and model training support.,add sentiment to list,0,
CoreNLP,StanfordCoreNLP includes the sentiment tool and various programs which support it. The model can be used to analyze text as part of StanfordCoreNLP by adding “sentiment” to the list of annotators. There is also command line support and model training support.,use model,0,
CoreNLP,"In addition to the fully-featured annotator pipeline interface to CoreNLP, Stanford provides a simple API for users who do not need a lot of customization. The intended audience of this package is users of CoreNLP who want “import nlp” to work as fast and easily as possible, and do not care about the details of the behaviors of the algorithms.",provide simple API for users,1,https://stanfordnlp.github.io/CoreNLP/simple.html
CoreNLP,"In addition to the fully-featured annotator pipeline interface to CoreNLP, Stanford provides a simple API for users who do not need a lot of customization. The intended audience of this package is users of CoreNLP who want “import nlp” to work as fast and easily as possible, and do not care about the details of the behaviors of the algorithms.",provide simple API in_addition_to fully-featured annotator pipeline interface,1,https://stanfordnlp.github.io/CoreNLP/simple.html
CoreNLP,The API is included in the CoreNLP release from 3.6.0 onwards. Visit the download page to download CoreNLP; make sure to include both the code jar and the models jar in your classpath!,include API in CoreNLP release,0,
CoreNLP,The API is included in the CoreNLP release from 3.6.0 onwards. Visit the download page to download CoreNLP; make sure to include both the code jar and the models jar in your classpath!,include API from 3.6.0 onwards,0,
CoreNLP,The API is included in the CoreNLP release from 3.6.0 onwards. Visit the download page to download CoreNLP; make sure to include both the code jar and the models jar in your classpath!,download corenlp,0,
CoreNLP,The API is included in the CoreNLP release from 3.6.0 onwards. Visit the download page to download CoreNLP; make sure to include both the code jar and the models jar in your classpath!,include code jar in classpath,0,
CoreNLP,The API is included in the CoreNLP release from 3.6.0 onwards. Visit the download page to download CoreNLP; make sure to include both the code jar and the models jar in your classpath!,include models jar in classpath,0,
CoreNLP,This interface offers a number of advantages (and a few disadvantages – see below) over the default annotator pipeline:,offer number of advantages,0,
CoreNLP,Lazy Computation Annotations are run as needed only when requested. This allows you to “change your mind” later in a program and request new annotations.,run lazy Computation annotations,0,
CoreNLP,Lazy Computation Annotations are run as needed only when requested. This allows you to “change your mind” later in a program and request new annotations.,change mind in program,0,
CoreNLP,Lazy Computation Annotations are run as needed only when requested. This allows you to “change your mind” later in a program and request new annotations.,request new annotations,0,
CoreNLP,No NullPointerExceptions Lazy computation allows us to ensure that no function will ever return null. Items which may not exist are wrapped inside of an Optional to clearly mark that they may be empty.,return null,0,
CoreNLP,No NullPointerExceptions Lazy computation allows us to ensure that no function will ever return null. Items which may not exist are wrapped inside of an Optional to clearly mark that they may be empty.,wrap items inside_of optional,0,
CoreNLP,"Less Customizability Although the ability to pass properties to annotators is supported, it is significantly more clunky than the annotation pipeline interface, and is generally discouraged.",pass properties to annotators,0,
CoreNLP,"Less Customizability Although the ability to pass properties to annotators is supported, it is significantly more clunky than the annotation pipeline interface, and is generally discouraged.",support ability,0,
CoreNLP,"Possible Nondeterminism There is no guarantee that the same algorithm will be used to compute the requested function on each invocation. For example, if a dependency parse is requested, followed by a constituency parse, we will compute the dependency parse with the Neural Dependency Parser, and then use the Stanford Parser for the constituency parse. If, however, you request the constituency parse before the dependency parse, we will use the Stanford Parser for both.",compute requested function on invocation,0,
CoreNLP,"Possible Nondeterminism There is no guarantee that the same algorithm will be used to compute the requested function on each invocation. For example, if a dependency parse is requested, followed by a constituency parse, we will compute the dependency parse with the Neural Dependency Parser, and then use the Stanford Parser for the constituency parse. If, however, you request the constituency parse before the dependency parse, we will use the Stanford Parser for both.",use same algorithm,0,
CoreNLP,"Possible Nondeterminism There is no guarantee that the same algorithm will be used to compute the requested function on each invocation. For example, if a dependency parse is requested, followed by a constituency parse, we will compute the dependency parse with the Neural Dependency Parser, and then use the Stanford Parser for the constituency parse. If, however, you request the constituency parse before the dependency parse, we will use the Stanford Parser for both.",compute dependency parse with neural Dependency parser,0,
CoreNLP,"Possible Nondeterminism There is no guarantee that the same algorithm will be used to compute the requested function on each invocation. For example, if a dependency parse is requested, followed by a constituency parse, we will compute the dependency parse with the Neural Dependency Parser, and then use the Stanford Parser for the constituency parse. If, however, you request the constituency parse before the dependency parse, we will use the Stanford Parser for both.",use stanford Parser for constituency parse,0,
CoreNLP,"Possible Nondeterminism There is no guarantee that the same algorithm will be used to compute the requested function on each invocation. For example, if a dependency parse is requested, followed by a constituency parse, we will compute the dependency parse with the Neural Dependency Parser, and then use the Stanford Parser for the constituency parse. If, however, you request the constituency parse before the dependency parse, we will use the Stanford Parser for both.",request dependency parse,0,
CoreNLP,"Possible Nondeterminism There is no guarantee that the same algorithm will be used to compute the requested function on each invocation. For example, if a dependency parse is requested, followed by a constituency parse, we will compute the dependency parse with the Neural Dependency Parser, and then use the Stanford Parser for the constituency parse. If, however, you request the constituency parse before the dependency parse, we will use the Stanford Parser for both.",request constituency parse before dependency parse,0,
CoreNLP,"Possible Nondeterminism There is no guarantee that the same algorithm will be used to compute the requested function on each invocation. For example, if a dependency parse is requested, followed by a constituency parse, we will compute the dependency parse with the Neural Dependency Parser, and then use the Stanford Parser for the constituency parse. If, however, you request the constituency parse before the dependency parse, we will use the Stanford Parser for both.",use Stanford parser,0,
CoreNLP,"There are two main classes in the interface: Document and Sentence. Tokens are represented as array elements in a sentence; e.g., to get the lemma of a token, get the lemmas array from the sentence and index it at the appropriate index. A constructor is provided for both the Document and Sentence class. For the former, the text is treated as an entire document containing potentially multiple sentences. For the latter, the text is forced to be interpreted as a single sentence.",get lemma,0,
CoreNLP,"There are two main classes in the interface: Document and Sentence. Tokens are represented as array elements in a sentence; e.g., to get the lemma of a token, get the lemmas array from the sentence and index it at the appropriate index. A constructor is provided for both the Document and Sentence class. For the former, the text is treated as an entire document containing potentially multiple sentences. For the latter, the text is forced to be interpreted as a single sentence.",get  at appropriate index,0,
CoreNLP,"There are two main classes in the interface: Document and Sentence. Tokens are represented as array elements in a sentence; e.g., to get the lemma of a token, get the lemmas array from the sentence and index it at the appropriate index. A constructor is provided for both the Document and Sentence class. For the former, the text is treated as an entire document containing potentially multiple sentences. For the latter, the text is forced to be interpreted as a single sentence.",provide constructor for sentence class,0,
CoreNLP,"There are two main classes in the interface: Document and Sentence. Tokens are represented as array elements in a sentence; e.g., to get the lemma of a token, get the lemmas array from the sentence and index it at the appropriate index. A constructor is provided for both the Document and Sentence class. For the former, the text is treated as an entire document containing potentially multiple sentences. For the latter, the text is forced to be interpreted as a single sentence.",force text for latter,0,
CoreNLP,An example program using the interface is given below:,use interface,1,https://stanfordnlp.github.io/CoreNLP/simple.html
CoreNLP,"The interface is not guaranteed to support all of the annotators in the CoreNLP pipeline. However, most common annotators are supported. A list of these, and their invocation, is given below. Functionality is the plain-english description of the task to be performed. The second column lists the analogous CoreNLP annotator for that task. The implementing class and function describe the class and function used in this wrapper to perform the same tasks.",support common annotators,0,
CoreNLP,"The interface is not guaranteed to support all of the annotators in the CoreNLP pipeline. However, most common annotators are supported. A list of these, and their invocation, is given below. Functionality is the plain-english description of the task to be performed. The second column lists the analogous CoreNLP annotator for that task. The implementing class and function describe the class and function used in this wrapper to perform the same tasks.",perform same tasks,0,
CoreNLP,"The interface is not guaranteed to support all of the annotators in the CoreNLP pipeline. However, most common annotators are supported. A list of these, and their invocation, is given below. Functionality is the plain-english description of the task to be performed. The second column lists the analogous CoreNLP annotator for that task. The implementing class and function describe the class and function used in this wrapper to perform the same tasks.",use  in wrapper,0,
CoreNLP,"Some potentially useful utility functions are implemented in the SentenceAlgorithms class. These can be called from a Sentence object with, e.g.:",call  from sentence object,1,https://stanfordnlp.github.io/CoreNLP/simple.html
CoreNLP,"headOfSpan(Span) Finds the index of the head word of the given span. So, for example, United States president Barack Obama would return Obama.",return obama,0,
CoreNLP,"dependencyPathBetween(int, int) Returns the dependency path between the words at the given two indices. This is returned as a list of String objects, meant primarily as an input to a featurizer.",return  as list,0,
CoreNLP,Sentence splitting is the process of dividing text into sentences. For instance the document Hello world. Hello world again. would be split into the sentences Hello world. and Hello world again. CoreNLP splits documents into sentences via a set of rules.,divide text into sentences,0,
CoreNLP,Sentence splitting is the process of dividing text into sentences. For instance the document Hello world. Hello world again. would be split into the sentences Hello world. and Hello world again. CoreNLP splits documents into sentences via a set of rules.,split  into sentences hello world,0,
CoreNLP,Sentence splitting is the process of dividing text into sentences. For instance the document Hello world. Hello world again. would be split into the sentences Hello world. and Hello world again. CoreNLP splits documents into sentences via a set of rules.,split documents into sentences,0,
CoreNLP,This command will take in the text of the file input.txt and produce a human readable output of the sentences:,produce human readable output of sentences,1,https://stanfordnlp.github.io/CoreNLP/ssplit.html
CoreNLP,This demo code will produce this output:,produce output,1,https://stanfordnlp.github.io/CoreNLP/ssplit.html
CoreNLP,"StanfordCoreNLP includes SUTime, a library for processing temporal expressions such as February 4th, 2019. SUTime is built on top of TokensRegex.",include SUTime,0,
CoreNLP,"StanfordCoreNLP includes SUTime, a library for processing temporal expressions such as February 4th, 2019. SUTime is built on top of TokensRegex.",process temporal expressions such_as february,0,
CoreNLP,"StanfordCoreNLP includes SUTime, a library for processing temporal expressions such as February 4th, 2019. SUTime is built on top of TokensRegex.",build SUTime on_top_of TokensRegex,0,
CoreNLP,SUTime will match a variety of temporal expressions and link them to a TIMEX3 object.,match variety of temporal expressions,0,
CoreNLP,SUTime will match a variety of temporal expressions and link them to a TIMEX3 object.,link  to timex3 object,0,
CoreNLP,4 types of temporal expression can be recognized.,recognize types of temporal expression,0,
CoreNLP,Phrases are recognized and linked based on a set of TokensRegex rules.,recognize phrases,1,https://stanfordnlp.github.io/CoreNLP/sutime.html
CoreNLP,Phrases are recognized and linked based on a set of TokensRegex rules.,link phrases,1,https://stanfordnlp.github.io/CoreNLP/sutime.html
CoreNLP,"SUTime is generally run as a subcomponent of the ner annotator. After it has run, the tokens of a time phrase will have a NamedEntityTagAnnotation for the type (e.g. DATE, TIME, DURATION, SET), and will have a edu.stanford.nlp.time.Timex object stored in the TimexAnnotation field.",run SUTime as subcomponent,0,
CoreNLP,"Recognized temporal expressions can be resolved relative to the document date. For instance, the expression this Wednesday will be resolved to the Wednesday that is closest to the document date, be it the current date or any other date. The document date can be set in several ways as will be documented below.",resolve recognized temporal expressions to document date,0,
CoreNLP,"Recognized temporal expressions can be resolved relative to the document date. For instance, the expression this Wednesday will be resolved to the Wednesday that is closest to the document date, be it the current date or any other date. The document date can be set in several ways as will be documented below.",resolve expression for instance,0,
CoreNLP,"Recognized temporal expressions can be resolved relative to the document date. For instance, the expression this Wednesday will be resolved to the Wednesday that is closest to the document date, be it the current date or any other date. The document date can be set in several ways as will be documented below.",resolve expression to Wednesday,0,
CoreNLP,"Recognized temporal expressions can be resolved relative to the document date. For instance, the expression this Wednesday will be resolved to the Wednesday that is closest to the document date, be it the current date or any other date. The document date can be set in several ways as will be documented below.",set document date in several ways,0,
CoreNLP,"If you would like to customize SUTime or make additions, you can alter the rules files accordingly or add new rules files. Setting the property sutime.rules = /path/to/my-rules.txt (or a comma-separated list of rules files) will set the pipeline to use your custom rules.",add new rules files,0,
CoreNLP,"If you would like to customize SUTime or make additions, you can alter the rules files accordingly or add new rules files. Setting the property sutime.rules = /path/to/my-rules.txt (or a comma-separated list of rules files) will set the pipeline to use your custom rules.",set pipeline,0,
CoreNLP,"If you would like to customize SUTime or make additions, you can alter the rules files accordingly or add new rules files. Setting the property sutime.rules = /path/to/my-rules.txt (or a comma-separated list of rules files) will set the pipeline to use your custom rules.",use custom rules,0,
CoreNLP,SUTime will be run automatically as a subcomponent of the ner annotator. Several properties can be set to alter the behavior of SUTime.,run SUTime as subcomponent,0,
CoreNLP,SUTime will be run automatically as a subcomponent of the ner annotator. Several properties can be set to alter the behavior of SUTime.,set several properties,0,
CoreNLP,The document date used by SUTime can also be set by specifying a date in an xml file and using the cleanxml annotator.,specify date in xml file,0,
CoreNLP,The document date used by SUTime can also be set by specifying a date in an xml file and using the cleanxml annotator.,use cleanxml annotator,0,
CoreNLP,The document date used by SUTime can also be set by specifying a date in an xml file and using the cleanxml annotator.,set document date,0,
CoreNLP,The English SUTime system in Stanford CoreNLP is specified in 3 rules files:,specify English SUTime system in rules files,0,
CoreNLP,The English SUTime system in Stanford CoreNLP is specified in 3 rules files:,specify English SUTime system in Stanford CoreNLP,0,
CoreNLP,"In general, temporal concepts are set up in defs.sutime.txt, and the rules for matching phrases to temporal concepts are specified in english.sutime.txt. We will follow this pattern when adding fiscal year rules.",set up temporal concepts in general,0,
CoreNLP,"In general, temporal concepts are set up in defs.sutime.txt, and the rules for matching phrases to temporal concepts are specified in english.sutime.txt. We will follow this pattern when adding fiscal year rules.",set up temporal concepts in defs.sutime.txt,0,
CoreNLP,"In general, temporal concepts are set up in defs.sutime.txt, and the rules for matching phrases to temporal concepts are specified in english.sutime.txt. We will follow this pattern when adding fiscal year rules.",specify rules in english.sutime.txt,0,
CoreNLP,"In general, temporal concepts are set up in defs.sutime.txt, and the rules for matching phrases to temporal concepts are specified in english.sutime.txt. We will follow this pattern when adding fiscal year rules.",specify rules for matching phrases,0,
CoreNLP,In this example we will add rules to match phrases such as Q3 FY 2018.,match phrases such_as q3 FY,0,
CoreNLP,The fiscal year is typically divided into 4 quarters. Here is an example for FY 2019.,divide fiscal year into quarters,0,
CoreNLP,The first step is to specify these periods of time in defs.sutime.txt. Here are the rules in that file that define those blocks of time:,specify periods in defs.sutime.txt,1,https://stanfordnlp.github.io/CoreNLP/sutime.html
CoreNLP,The first step is to specify these periods of time in defs.sutime.txt. Here are the rules in that file that define those blocks of time:,specify periods of time,1,https://stanfordnlp.github.io/CoreNLP/sutime.html
CoreNLP,The first step is to specify these periods of time in defs.sutime.txt. Here are the rules in that file that define those blocks of time:,define blocks of time,1,https://stanfordnlp.github.io/CoreNLP/sutime.html
CoreNLP,The first step is to specify these periods of time in defs.sutime.txt. Here are the rules in that file that define those blocks of time:,define file of time,1,https://stanfordnlp.github.io/CoreNLP/sutime.html
CoreNLP,"After this rule has been specified in defs.sutime.txt, further in that rule file and in the subsequent rule files FYQ1 can be accessed to refer to that temporal concept.",specify rule in defs.sutime.txt,1,https://stanfordnlp.github.io/CoreNLP/sutime.html
CoreNLP,"After this rule has been specified in defs.sutime.txt, further in that rule file and in the subsequent rule files FYQ1 can be accessed to refer to that temporal concept.",access fyq1,1,https://stanfordnlp.github.io/CoreNLP/sutime.html
CoreNLP,"Here two maps are produced, which will map String’s to specific financial quarters, and to integer offsets. When we specify the final rule, we need to potentially subtract 1 from the year if we are recognizing Q1. Also, using the CreateRegex function, we can generate a regex that will match any of the keys in the FISCAL_YEAR_QUARTER_MAP.",produce maps,0,
CoreNLP,"Here two maps are produced, which will map String’s to specific financial quarters, and to integer offsets. When we specify the final rule, we need to potentially subtract 1 from the year if we are recognizing Q1. Also, using the CreateRegex function, we can generate a regex that will match any of the keys in the FISCAL_YEAR_QUARTER_MAP.",specify final rule,0,
CoreNLP,"Here two maps are produced, which will map String’s to specific financial quarters, and to integer offsets. When we specify the final rule, we need to potentially subtract 1 from the year if we are recognizing Q1. Also, using the CreateRegex function, we can generate a regex that will match any of the keys in the FISCAL_YEAR_QUARTER_MAP.",recognize q1,0,
CoreNLP,"Here two maps are produced, which will map String’s to specific financial quarters, and to integer offsets. When we specify the final rule, we need to potentially subtract 1 from the year if we are recognizing Q1. Also, using the CreateRegex function, we can generate a regex that will match any of the keys in the FISCAL_YEAR_QUARTER_MAP.",use CreateRegex function,0,
CoreNLP,"Here two maps are produced, which will map String’s to specific financial quarters, and to integer offsets. When we specify the final rule, we need to potentially subtract 1 from the year if we are recognizing Q1. Also, using the CreateRegex function, we can generate a regex that will match any of the keys in the FISCAL_YEAR_QUARTER_MAP.",match regex,0,
CoreNLP,"Now that we have these tools, we can write the final TokensRegex rule that will match the actual phrases for financial quarters.",write final TokensRegex rule,1,https://stanfordnlp.github.io/CoreNLP/sutime.html
CoreNLP,"Now that we have these tools, we can write the final TokensRegex rule that will match the actual phrases for financial quarters.",match actual phrases for financial quarters,1,https://stanfordnlp.github.io/CoreNLP/sutime.html
CoreNLP,"Now that we have these tools, we can write the final TokensRegex rule that will match the actual phrases for financial quarters.",match final TokensRegex rule for financial quarters,1,https://stanfordnlp.github.io/CoreNLP/sutime.html
CoreNLP,"The TokensRegex rule specifies a pattern over tokens, and then specifies the temporal value to return.",specify pattern over tokens,0,
CoreNLP,"The TokensRegex rule specifies a pattern over tokens, and then specifies the temporal value to return.",specify temporal value to return,0,
CoreNLP,"As a reminder, TokensRegex rules specify regular expression which match tokens. Each space separated regular expression matches a single token or sequence of tokens.",specify regular expression as reminder,0,
CoreNLP,"As a reminder, TokensRegex rules specify regular expression which match tokens. Each space separated regular expression matches a single token or sequence of tokens.",match tokens,0,
CoreNLP,"As a reminder, TokensRegex rules specify regular expression which match tokens. Each space separated regular expression matches a single token or sequence of tokens.",match regular expression,0,
CoreNLP,"As a reminder, TokensRegex rules specify regular expression which match tokens. Each space separated regular expression matches a single token or sequence of tokens.",match single token of tokens,0,
CoreNLP,"As a reminder, TokensRegex rules specify regular expression which match tokens. Each space separated regular expression matches a single token or sequence of tokens.",match sequence of tokens,0,
CoreNLP,"The (/$FiscalYearQuarterTerm/) token would represent Q1, Q2, Q3, Q4. The (FY)? represents an optional FY token. This is so both Q1 2019 can be recognized as well as Q1 FY 2019. The (/(FY)?([0-9]{4})/) token captures the year component of phrase, so both Q1 FY2019 can be recognized as well as Q1 2019.",recognize q1,0,
CoreNLP,"The (/$FiscalYearQuarterTerm/) token would represent Q1, Q2, Q3, Q4. The (FY)? represents an optional FY token. This is so both Q1 2019 can be recognized as well as Q1 FY 2019. The (/(FY)?([0-9]{4})/) token captures the year component of phrase, so both Q1 FY2019 can be recognized as well as Q1 2019.",recognize q1 fy2019 as q1,0,
CoreNLP,The result part of the rule specifies what temporal object to create when this pattern over tokens is recognized.,recognize pattern over tokens,1,https://stanfordnlp.github.io/CoreNLP/sutime.html
CoreNLP,"Keep in mind that there are two types of patterns to consider, patterns over tokens, and patterns that match the String contents of a given token.",match string contents of given token,0,
CoreNLP,"Keep in mind that there are two types of patterns to consider, patterns over tokens, and patterns that match the String contents of a given token.",match patterns of given token,0,
CoreNLP,"For example (/Q*/) (/[0-9]{4}/) will match 2 tokens, the first token must start with a Q, and the second must be any 4-digit number.",match tokens,0,
CoreNLP,"In our example, the token pattern has 3 capture groups, and the String pattern for matching the year token has 2 capture groups (FY)? and ([0-9]{4}). This means $$3.matchResults[0].word.group(2) will refer to the 3rd capture group of the token pattern (the year token), and the 2nd group of the regex matching the year token’s String, which is the numerical part of the String.",match string,0,
CoreNLP,"The first component of the intersection is the result of the Subtract, which simply subtracts the quarter offset from the numerical value of the year token. So if FY2019 is matched, the numerical component will be 2019. The FISCAL_YEAR_QUARTER_YEAR_OFFSETS_MAP is used to determine the offset. If Q1 FY2019 was matched, Q1 would be mapped to 1, otherwise 0. So either 1 or 0 will be subtracted from 2019, giving the correct year. Note the Subtract is wrapped in an IsoDate. You can build a specific date with IsoDate($Year, $Month, $Day). Passing ANY to IsoDate will create a date with nothing specified for that field. So IsoDate(2019, ANY, ANY) means the year 2019.",match fy2019,0,
CoreNLP,"The first component of the intersection is the result of the Subtract, which simply subtracts the quarter offset from the numerical value of the year token. So if FY2019 is matched, the numerical component will be 2019. The FISCAL_YEAR_QUARTER_YEAR_OFFSETS_MAP is used to determine the offset. If Q1 FY2019 was matched, Q1 would be mapped to 1, otherwise 0. So either 1 or 0 will be subtracted from 2019, giving the correct year. Note the Subtract is wrapped in an IsoDate. You can build a specific date with IsoDate($Year, $Month, $Day). Passing ANY to IsoDate will create a date with nothing specified for that field. So IsoDate(2019, ANY, ANY) means the year 2019.",determine offset,0,
CoreNLP,"The first component of the intersection is the result of the Subtract, which simply subtracts the quarter offset from the numerical value of the year token. So if FY2019 is matched, the numerical component will be 2019. The FISCAL_YEAR_QUARTER_YEAR_OFFSETS_MAP is used to determine the offset. If Q1 FY2019 was matched, Q1 would be mapped to 1, otherwise 0. So either 1 or 0 will be subtracted from 2019, giving the correct year. Note the Subtract is wrapped in an IsoDate. You can build a specific date with IsoDate($Year, $Month, $Day). Passing ANY to IsoDate will create a date with nothing specified for that field. So IsoDate(2019, ANY, ANY) means the year 2019.",use FISCAL_YEAR_QUARTER_YEAR_OFFSETS_MAP,0,
CoreNLP,"The first component of the intersection is the result of the Subtract, which simply subtracts the quarter offset from the numerical value of the year token. So if FY2019 is matched, the numerical component will be 2019. The FISCAL_YEAR_QUARTER_YEAR_OFFSETS_MAP is used to determine the offset. If Q1 FY2019 was matched, Q1 would be mapped to 1, otherwise 0. So either 1 or 0 will be subtracted from 2019, giving the correct year. Note the Subtract is wrapped in an IsoDate. You can build a specific date with IsoDate($Year, $Month, $Day). Passing ANY to IsoDate will create a date with nothing specified for that field. So IsoDate(2019, ANY, ANY) means the year 2019.",match q1 fy2019,0,
CoreNLP,"The first component of the intersection is the result of the Subtract, which simply subtracts the quarter offset from the numerical value of the year token. So if FY2019 is matched, the numerical component will be 2019. The FISCAL_YEAR_QUARTER_YEAR_OFFSETS_MAP is used to determine the offset. If Q1 FY2019 was matched, Q1 would be mapped to 1, otherwise 0. So either 1 or 0 will be subtracted from 2019, giving the correct year. Note the Subtract is wrapped in an IsoDate. You can build a specific date with IsoDate($Year, $Month, $Day). Passing ANY to IsoDate will create a date with nothing specified for that field. So IsoDate(2019, ANY, ANY) means the year 2019.",wrap Subtract in IsoDate,0,
CoreNLP,"The first component of the intersection is the result of the Subtract, which simply subtracts the quarter offset from the numerical value of the year token. So if FY2019 is matched, the numerical component will be 2019. The FISCAL_YEAR_QUARTER_YEAR_OFFSETS_MAP is used to determine the offset. If Q1 FY2019 was matched, Q1 would be mapped to 1, otherwise 0. So either 1 or 0 will be subtracted from 2019, giving the correct year. Note the Subtract is wrapped in an IsoDate. You can build a specific date with IsoDate($Year, $Month, $Day). Passing ANY to IsoDate will create a date with nothing specified for that field. So IsoDate(2019, ANY, ANY) means the year 2019.","build specific date with IsoDate($Year, $Month, $Day)",0,
CoreNLP,"The first component of the intersection is the result of the Subtract, which simply subtracts the quarter offset from the numerical value of the year token. So if FY2019 is matched, the numerical component will be 2019. The FISCAL_YEAR_QUARTER_YEAR_OFFSETS_MAP is used to determine the offset. If Q1 FY2019 was matched, Q1 would be mapped to 1, otherwise 0. So either 1 or 0 will be subtracted from 2019, giving the correct year. Note the Subtract is wrapped in an IsoDate. You can build a specific date with IsoDate($Year, $Month, $Day). Passing ANY to IsoDate will create a date with nothing specified for that field. So IsoDate(2019, ANY, ANY) means the year 2019.",create date with nothing,0,
CoreNLP,"The first component of the intersection is the result of the Subtract, which simply subtracts the quarter offset from the numerical value of the year token. So if FY2019 is matched, the numerical component will be 2019. The FISCAL_YEAR_QUARTER_YEAR_OFFSETS_MAP is used to determine the offset. If Q1 FY2019 was matched, Q1 would be mapped to 1, otherwise 0. So either 1 or 0 will be subtracted from 2019, giving the correct year. Note the Subtract is wrapped in an IsoDate. You can build a specific date with IsoDate($Year, $Month, $Day). Passing ANY to IsoDate will create a date with nothing specified for that field. So IsoDate(2019, ANY, ANY) means the year 2019.",specify  for field,0,
CoreNLP,The final temporal object is built and associated with the phrase.,build final temporal object with phrase,0,
CoreNLP,"If you have created a custom rules file, you can tell SUTime to use it by setting the sutime.rules property when running a pipeline. This property takes in a list of rules files and reads them in order.",create custom rules file,0,
CoreNLP,"If you have created a custom rules file, you can tell SUTime to use it by setting the sutime.rules property when running a pipeline. This property takes in a list of rules files and reads them in order.",use  by setting,0,
CoreNLP,"If you have created a custom rules file, you can tell SUTime to use it by setting the sutime.rules property when running a pipeline. This property takes in a list of rules files and reads them in order.",set sutime.rules property,0,
CoreNLP,"If you have created a custom rules file, you can tell SUTime to use it by setting the sutime.rules property when running a pipeline. This property takes in a list of rules files and reads them in order.",run pipeline,0,
CoreNLP,"Tokenization is the process of turning text into tokens. For instance, the sentence Marie was born in Paris. would be tokenized as the list ""Marie"", ""was"", ""born"", ""in"", ""Paris"", ""."". CoreNLP splits texts into tokens with an elaborate collection of rules, designed to follow UD 2.0 specifications.",tokenize  as list marie,0,
CoreNLP,"Tokenization is the process of turning text into tokens. For instance, the sentence Marie was born in Paris. would be tokenized as the list ""Marie"", ""was"", ""born"", ""in"", ""Paris"", ""."". CoreNLP splits texts into tokens with an elaborate collection of rules, designed to follow UD 2.0 specifications.",split texts into tokens,0,
CoreNLP,"It is important to note that the full tokenization process for French, German, and Spanish also involves running the MWTAnnotator for multi-word token expansion after sentence splitting. Most of the following documentation is focused on English tokenization.",run MWTAnnotator for multi-word token expansion,0,
CoreNLP,"It is important to note that the full tokenization process for French, German, and Spanish also involves running the MWTAnnotator for multi-word token expansion after sentence splitting. Most of the following documentation is focused on English tokenization.",run MWTAnnotator after sentence splitting,0,
CoreNLP,This command will take in the text of the file input.txt and produce a human readable output of the tokens and their character offsets:,produce human readable output of tokens,1,https://stanfordnlp.github.io/CoreNLP/tokenize.html
CoreNLP,This command will take in the text of the file input.txt and produce a human readable output of the tokens and their character offsets:,produce human readable output of character offsets,1,https://stanfordnlp.github.io/CoreNLP/tokenize.html
CoreNLP,"Other output formats include conllu, json, and serialized.",include conllu,0,
CoreNLP,"Other output formats include conllu, json, and serialized.",include json,0,
CoreNLP,"Other output formats include conllu, json, and serialized.",include serialized,0,
CoreNLP,The following command is an example of specifying PTBTokenizer options with the tokenize.options option:,specify PTBTokenizer options with tokenize.options option,1,https://stanfordnlp.github.io/CoreNLP/tokenize.html
CoreNLP,This demo code will produce the tokens and the character offsets of the text.,produce tokens of text,1,https://stanfordnlp.github.io/CoreNLP/tokenize.html
CoreNLP,This demo code will produce the tokens and the character offsets of the text.,produce character offsets of text,1,https://stanfordnlp.github.io/CoreNLP/tokenize.html
CoreNLP,"StanfordCoreNLP includes TokensRegex, a framework for defining regular expressions over text and tokens, and mapping matched text to semantic objects.",include TokensRegex,0,
CoreNLP,"StanfordCoreNLP includes TokensRegex, a framework for defining regular expressions over text and tokens, and mapping matched text to semantic objects.",define regular expressions over text,0,
CoreNLP,"StanfordCoreNLP includes TokensRegex, a framework for defining regular expressions over text and tokens, and mapping matched text to semantic objects.",define regular expressions over tokens,0,
CoreNLP,"TokensRegex is a complex and powerful library for identifying and acting on patterns in text. To fully utilize TokensRegex, you should review the high level overview and then work through the specific examples below.",identify  on patterns,0,
CoreNLP,"With TokensRegex, you can build a rule based system for searching for patterns and performing actions when the patterns are found.",build rule with TokensRegex,0,
CoreNLP,"With TokensRegex, you can build a rule based system for searching for patterns and performing actions when the patterns are found.",perform actions,0,
CoreNLP,"With TokensRegex, you can build a rule based system for searching for patterns and performing actions when the patterns are found.",search  for patterns,0,
CoreNLP,"In a typical TokensRegex pipeline, you will need some basic Java code to load in your text, split it into sentences, and set up the CoreMapExpressionExtractor. Below is an example class TokensRegexDemo which contains the necessary code for running a TokensRegex pipeline.",split  into sentences,0,
CoreNLP,"In a typical TokensRegex pipeline, you will need some basic Java code to load in your text, split it into sentences, and set up the CoreMapExpressionExtractor. Below is an example class TokensRegexDemo which contains the necessary code for running a TokensRegex pipeline.",set up CoreMapExpressionExtractor,0,
CoreNLP,"In a typical TokensRegex pipeline, you will need some basic Java code to load in your text, split it into sentences, and set up the CoreMapExpressionExtractor. Below is an example class TokensRegexDemo which contains the necessary code for running a TokensRegex pipeline.",load  in text,0,
CoreNLP,"In a typical TokensRegex pipeline, you will need some basic Java code to load in your text, split it into sentences, and set up the CoreMapExpressionExtractor. Below is an example class TokensRegexDemo which contains the necessary code for running a TokensRegex pipeline.",run TokensRegex pipeline,0,
CoreNLP,"In this code, some util classes and a StanfordCoreNLP pipeline are used to load the text and split it into sentences.",load text,0,
CoreNLP,"In this code, some util classes and a StanfordCoreNLP pipeline are used to load the text and split it into sentences.",split  into sentences,0,
CoreNLP,"In this code, some util classes and a StanfordCoreNLP pipeline are used to load the text and split it into sentences.",use util classes in code,0,
CoreNLP,"In this code, some util classes and a StanfordCoreNLP pipeline are used to load the text and split it into sentences.",use StanfordCoreNLP pipeline in code,0,
CoreNLP,"Then the TokensRegex pipeline is built (not be confused with a general StanfordCoreNLP pipeline). The TokensRegex pipeline is specified by a list of rules files, and an Env object. The next section will contain a thorough example of a rules file which specifies a TokensRegex pipeline. In the example code you can see how the environment is built, and an example of specifying that you want all patterns to be case-insensitive. The list of rules files and the Env are used to construct a CoreMapExpressionExtractor, the main class which runs a TokensRegex pipeline.",build TokensRegex pipeline,0,
CoreNLP,"Then the TokensRegex pipeline is built (not be confused with a general StanfordCoreNLP pipeline). The TokensRegex pipeline is specified by a list of rules files, and an Env object. The next section will contain a thorough example of a rules file which specifies a TokensRegex pipeline. In the example code you can see how the environment is built, and an example of specifying that you want all patterns to be case-insensitive. The list of rules files and the Env are used to construct a CoreMapExpressionExtractor, the main class which runs a TokensRegex pipeline.",specify TokensRegex pipeline,0,
CoreNLP,"Then the TokensRegex pipeline is built (not be confused with a general StanfordCoreNLP pipeline). The TokensRegex pipeline is specified by a list of rules files, and an Env object. The next section will contain a thorough example of a rules file which specifies a TokensRegex pipeline. In the example code you can see how the environment is built, and an example of specifying that you want all patterns to be case-insensitive. The list of rules files and the Env are used to construct a CoreMapExpressionExtractor, the main class which runs a TokensRegex pipeline.",specify TokensRegex pipeline of rules file,0,
CoreNLP,"Then the TokensRegex pipeline is built (not be confused with a general StanfordCoreNLP pipeline). The TokensRegex pipeline is specified by a list of rules files, and an Env object. The next section will contain a thorough example of a rules file which specifies a TokensRegex pipeline. In the example code you can see how the environment is built, and an example of specifying that you want all patterns to be case-insensitive. The list of rules files and the Env are used to construct a CoreMapExpressionExtractor, the main class which runs a TokensRegex pipeline.",specify thorough example of rules file,0,
CoreNLP,"Then the TokensRegex pipeline is built (not be confused with a general StanfordCoreNLP pipeline). The TokensRegex pipeline is specified by a list of rules files, and an Env object. The next section will contain a thorough example of a rules file which specifies a TokensRegex pipeline. In the example code you can see how the environment is built, and an example of specifying that you want all patterns to be case-insensitive. The list of rules files and the Env are used to construct a CoreMapExpressionExtractor, the main class which runs a TokensRegex pipeline.",build environment,0,
CoreNLP,"Then the TokensRegex pipeline is built (not be confused with a general StanfordCoreNLP pipeline). The TokensRegex pipeline is specified by a list of rules files, and an Env object. The next section will contain a thorough example of a rules file which specifies a TokensRegex pipeline. In the example code you can see how the environment is built, and an example of specifying that you want all patterns to be case-insensitive. The list of rules files and the Env are used to construct a CoreMapExpressionExtractor, the main class which runs a TokensRegex pipeline.",run TokensRegex pipeline,0,
CoreNLP,"Then the TokensRegex pipeline is built (not be confused with a general StanfordCoreNLP pipeline). The TokensRegex pipeline is specified by a list of rules files, and an Env object. The next section will contain a thorough example of a rules file which specifies a TokensRegex pipeline. In the example code you can see how the environment is built, and an example of specifying that you want all patterns to be case-insensitive. The list of rules files and the Env are used to construct a CoreMapExpressionExtractor, the main class which runs a TokensRegex pipeline.",run main class,0,
CoreNLP,"Then the TokensRegex pipeline is built (not be confused with a general StanfordCoreNLP pipeline). The TokensRegex pipeline is specified by a list of rules files, and an Env object. The next section will contain a thorough example of a rules file which specifies a TokensRegex pipeline. In the example code you can see how the environment is built, and an example of specifying that you want all patterns to be case-insensitive. The list of rules files and the Env are used to construct a CoreMapExpressionExtractor, the main class which runs a TokensRegex pipeline.",use list of rules files,0,
CoreNLP,"Then the TokensRegex pipeline is built (not be confused with a general StanfordCoreNLP pipeline). The TokensRegex pipeline is specified by a list of rules files, and an Env object. The next section will contain a thorough example of a rules file which specifies a TokensRegex pipeline. In the example code you can see how the environment is built, and an example of specifying that you want all patterns to be case-insensitive. The list of rules files and the Env are used to construct a CoreMapExpressionExtractor, the main class which runs a TokensRegex pipeline.",use list of env,0,
CoreNLP,"When a CoreMapExpressionExtractor is run on a sentence, it will run a TokensRegex pipeline on the sentence, alter the token CoreLabel’s annotations in the sentence, and potentially generate a list of MatchedExpression objects which can be used in your overall logic.",run TokensRegex pipeline on sentence,0,
CoreNLP,"When a CoreMapExpressionExtractor is run on a sentence, it will run a TokensRegex pipeline on the sentence, alter the token CoreLabel’s annotations in the sentence, and potentially generate a list of MatchedExpression objects which can be used in your overall logic.",run CoreMapExpressionExtractor on sentence,0,
CoreNLP,"When a CoreMapExpressionExtractor is run on a sentence, it will run a TokensRegex pipeline on the sentence, alter the token CoreLabel’s annotations in the sentence, and potentially generate a list of MatchedExpression objects which can be used in your overall logic.",use list in overall logic,0,
CoreNLP,"When a CoreMapExpressionExtractor is run on a sentence, it will run a TokensRegex pipeline on the sentence, alter the token CoreLabel’s annotations in the sentence, and potentially generate a list of MatchedExpression objects which can be used in your overall logic.",use list of MatchedExpression objects,0,
CoreNLP,"Another way to run TokensRegex rules is to use the TokensRegexAnnotator. For instance you might want to run a full StanfordCoreNLP pipeline, but run named entity recogntion with TokensRegex rules. This can be achieved with the tokensregex annotator.",run TokensRegex rules,1,https://stanfordnlp.github.io/CoreNLP/tokensregex.html
CoreNLP,"Another way to run TokensRegex rules is to use the TokensRegexAnnotator. For instance you might want to run a full StanfordCoreNLP pipeline, but run named entity recogntion with TokensRegex rules. This can be achieved with the tokensregex annotator.",use TokensRegexAnnotator,1,https://stanfordnlp.github.io/CoreNLP/tokensregex.html
CoreNLP,"Another way to run TokensRegex rules is to use the TokensRegexAnnotator. For instance you might want to run a full StanfordCoreNLP pipeline, but run named entity recogntion with TokensRegex rules. This can be achieved with the tokensregex annotator.",run full StanfordCoreNLP pipeline,1,https://stanfordnlp.github.io/CoreNLP/tokensregex.html
CoreNLP,"If you run this command, it will run the TokensRegex rules of basic_ner.rules as part of the pipeline when the tokensregex annotator runs.",run command,1,https://stanfordnlp.github.io/CoreNLP/tokensregex.html
CoreNLP,"If you run this command, it will run the TokensRegex rules of basic_ner.rules as part of the pipeline when the tokensregex annotator runs.",run TokensRegex rules as part,1,https://stanfordnlp.github.io/CoreNLP/tokensregex.html
CoreNLP,"If you run this command, it will run the TokensRegex rules of basic_ner.rules as part of the pipeline when the tokensregex annotator runs.",run TokensRegex rules of basic_ner.rules,1,https://stanfordnlp.github.io/CoreNLP/tokensregex.html
CoreNLP,"As you work through the examples, it is helpful to understand the high level design of a TokensRegex pipeline. The pipeline is specified in a set of rules files, that are evaluated with respect to an environment. The environment can be initialized in Java code, and altered in the rules files.",specify pipeline in set,0,
CoreNLP,"As you work through the examples, it is helpful to understand the high level design of a TokensRegex pipeline. The pipeline is specified in a set of rules files, that are evaluated with respect to an environment. The environment can be initialized in Java code, and altered in the rules files.",evaluate rules files with respect,0,
CoreNLP,"As you work through the examples, it is helpful to understand the high level design of a TokensRegex pipeline. The pipeline is specified in a set of rules files, that are evaluated with respect to an environment. The environment can be initialized in Java code, and altered in the rules files.",evaluate rules files to environment,0,
CoreNLP,"As you work through the examples, it is helpful to understand the high level design of a TokensRegex pipeline. The pipeline is specified in a set of rules files, that are evaluated with respect to an environment. The environment can be initialized in Java code, and altered in the rules files.",initialize environment in Java code,0,
CoreNLP,"Generally assignments are made at the top, which set up variables to be used in the TokensRegex pipeline.",set up variables,0,
CoreNLP,"Generally assignments are made at the top, which set up variables to be used in the TokensRegex pipeline.",set up top,0,
CoreNLP,"Generally assignments are made at the top, which set up variables to be used in the TokensRegex pipeline.",use  in TokensRegex pipeline,0,
CoreNLP,"Then the rules are specified. A TokensRegex pipeline can be split into stages (as many as you’d like). Each stage runs until completion, and then the next stage runs. The Multi-Step NER example below illustrates this.",specify rules,0,
CoreNLP,"Then the rules are specified. A TokensRegex pipeline can be split into stages (as many as you’d like). Each stage runs until completion, and then the next stage runs. The Multi-Step NER example below illustrates this.",split TokensRegex pipeline into stages,0,
CoreNLP,"Then the rules are specified. A TokensRegex pipeline can be split into stages (as many as you’d like). Each stage runs until completion, and then the next stage runs. The Multi-Step NER example below illustrates this.",run  until completion,0,
CoreNLP,"Then the rules are specified. A TokensRegex pipeline can be split into stages (as many as you’d like). Each stage runs until completion, and then the next stage runs. The Multi-Step NER example below illustrates this.",run  until completion,0,
CoreNLP,"The Basic NER example shows token rules, the Extract Quotes example shows a text rule, the Process Math Expressions example shows a composite rule, and the Multi-Step NER example shows a filter rule.",show token rules,0,
CoreNLP,"The Basic NER example shows token rules, the Extract Quotes example shows a text rule, the Process Math Expressions example shows a composite rule, and the Multi-Step NER example shows a filter rule.",show text rule,0,
CoreNLP,"The Basic NER example shows token rules, the Extract Quotes example shows a text rule, the Process Math Expressions example shows a composite rule, and the Multi-Step NER example shows a filter rule.",show composite rule,0,
CoreNLP,"The Basic NER example shows token rules, the Extract Quotes example shows a text rule, the Process Math Expressions example shows a composite rule, and the Multi-Step NER example shows a filter rule.",show filter rule,0,
CoreNLP,"In the pipeline all of the text/token rules are run, then the composite rules are run over and over again until no changes occur, and finally the filter rules are run.",run  in pipeline,0,
CoreNLP,"In the pipeline all of the text/token rules are run, then the composite rules are run over and over again until no changes occur, and finally the filter rules are run.",run filter rules,0,
CoreNLP,The most common type of rule is the “tokens” rule. This rule type searches for patterns over a list of tokens.,search  for patterns,1,https://stanfordnlp.github.io/CoreNLP/tokensregex.html
CoreNLP,The “pattern” field specifies the pattern to search for in the list of tokens. Here is a description of the pattern in this example:,specify pattern,0,
CoreNLP,The “pattern” field specifies the pattern to search for in the list of tokens. Here is a description of the pattern in this example:,search  in list,0,
CoreNLP,This pattern will match “I like pizza” or “I love pizza” (assuming like and love have the proper part of speech tag).,match  like pizza,0,
CoreNLP,"Note there are parenthesis around the pizza token. This specifies a group. In this example, the whole match is group $0, and the match on “pizza” is group $1. We can use the group numbers to specify lists of tokens to alter in the action part of the rule.",specify group,0,
CoreNLP,"Note there are parenthesis around the pizza token. This specifies a group. In this example, the whole match is group $0, and the match on “pizza” is group $1. We can use the group numbers to specify lists of tokens to alter in the action part of the rule.",specify lists of tokens,0,
CoreNLP,The “action” field specifies an action to take. The Expressions Javadoc shows more info about the kinds of actions there are. The most common one is Annotate(). In this example we specify to annotate the word “pizza” with the NER tag “FOOD”. (Note: make sure that “ner” is tied to CoreAnnotations.NamedEntityTagAnnotation.class which is shown below). The Annotate() call says to annotate all tokens in group match $1 with named entity tag “FOOD”.,specify action,0,
CoreNLP,The “action” field specifies an action to take. The Expressions Javadoc shows more info about the kinds of actions there are. The most common one is Annotate(). In this example we specify to annotate the word “pizza” with the NER tag “FOOD”. (Note: make sure that “ner” is tied to CoreAnnotations.NamedEntityTagAnnotation.class which is shown below). The Annotate() call says to annotate all tokens in group match $1 with named entity tag “FOOD”.,show more info about kinds,0,
CoreNLP,There are a lot of ways to match patterns in token sequences. Below is a helpful cheat sheet,match patterns in token sequences,0,
CoreNLP,"Let’s imagine that we want to identify company names. For our simple example, we will assume we are interested in any string of capitalized tokens that ends with a company ending token.",identify company names,0,
CoreNLP,We will define the company ending tokens to be “Corp” or “Inc” (and optionally containing a “.”).,define company,0,
CoreNLP,"To show more functionality, we will also add the constraint that the non-ending tokens in the pattern have to have the part of speech tag “NNP”.",show more functionality,1,https://stanfordnlp.github.io/CoreNLP/tokensregex.html
CoreNLP,"To show more functionality, we will also add the constraint that the non-ending tokens in the pattern have to have the part of speech tag “NNP”.",add constraint,1,https://stanfordnlp.github.io/CoreNLP/tokensregex.html
CoreNLP,"The first section influences the environment of the pipeline. Since our Java code sets the rules to be case-insensitive, we will set them to case-sensitive in our rules file for this TokensRegex pipeline. By setting those two flags to 0, the rules will be case-sensitive.",set flags,0,
CoreNLP,In the next section we bind certain variables to Java classes used as annotation keys. Here we bind “ner” and “tokens” to the corresponding annotation keys.,bind certain variables in next section,0,
CoreNLP,In the next section we bind certain variables to Java classes used as annotation keys. Here we bind “ner” and “tokens” to the corresponding annotation keys.,bind certain variables to Java classes,0,
CoreNLP,In the next section we bind certain variables to Java classes used as annotation keys. Here we bind “ner” and “tokens” to the corresponding annotation keys.,use  as annotation keys,0,
CoreNLP,In the next section we bind certain variables to Java classes used as annotation keys. Here we bind “ner” and “tokens” to the corresponding annotation keys.,bind ner to corresponding annotation keys,0,
CoreNLP,In the next section we bind certain variables to Java classes used as annotation keys. Here we bind “ner” and “tokens” to the corresponding annotation keys.,bind tokens to corresponding annotation keys,0,
CoreNLP,"In the third section we bind some variables to larger regexes. This would be especially useful if the regexes were especially large, though they are small in our simple example. Note that these are regexes that match the full text of a token. So $COMPANY_BEGINING will match all tokens that start with a capital letter and only contain letters (e.g. “Apple”). $COMPANY_ENDING will match the tokens “Corp”, “Inc”, “Corp.”, and “Inc.” By setting these variables to regexes, we don’t have to write out the full regex again every time we want to use it.",bind variables in third section,0,
CoreNLP,"In the third section we bind some variables to larger regexes. This would be especially useful if the regexes were especially large, though they are small in our simple example. Note that these are regexes that match the full text of a token. So $COMPANY_BEGINING will match all tokens that start with a capital letter and only contain letters (e.g. “Apple”). $COMPANY_ENDING will match the tokens “Corp”, “Inc”, “Corp.”, and “Inc.” By setting these variables to regexes, we don’t have to write out the full regex again every time we want to use it.",bind variables to larger regexes,0,
CoreNLP,"In the third section we bind some variables to larger regexes. This would be especially useful if the regexes were especially large, though they are small in our simple example. Note that these are regexes that match the full text of a token. So $COMPANY_BEGINING will match all tokens that start with a capital letter and only contain letters (e.g. “Apple”). $COMPANY_ENDING will match the tokens “Corp”, “Inc”, “Corp.”, and “Inc.” By setting these variables to regexes, we don’t have to write out the full regex again every time we want to use it.",match full text,0,
CoreNLP,"In the third section we bind some variables to larger regexes. This would be especially useful if the regexes were especially large, though they are small in our simple example. Note that these are regexes that match the full text of a token. So $COMPANY_BEGINING will match all tokens that start with a capital letter and only contain letters (e.g. “Apple”). $COMPANY_ENDING will match the tokens “Corp”, “Inc”, “Corp.”, and “Inc.” By setting these variables to regexes, we don’t have to write out the full regex again every time we want to use it.",match regexes,0,
CoreNLP,"In the third section we bind some variables to larger regexes. This would be especially useful if the regexes were especially large, though they are small in our simple example. Note that these are regexes that match the full text of a token. So $COMPANY_BEGINING will match all tokens that start with a capital letter and only contain letters (e.g. “Apple”). $COMPANY_ENDING will match the tokens “Corp”, “Inc”, “Corp.”, and “Inc.” By setting these variables to regexes, we don’t have to write out the full regex again every time we want to use it.",match tokens,0,
CoreNLP,"In the third section we bind some variables to larger regexes. This would be especially useful if the regexes were especially large, though they are small in our simple example. Note that these are regexes that match the full text of a token. So $COMPANY_BEGINING will match all tokens that start with a capital letter and only contain letters (e.g. “Apple”). $COMPANY_ENDING will match the tokens “Corp”, “Inc”, “Corp.”, and “Inc.” By setting these variables to regexes, we don’t have to write out the full regex again every time we want to use it.",match corp corp.,0,
CoreNLP,"In the third section we bind some variables to larger regexes. This would be especially useful if the regexes were especially large, though they are small in our simple example. Note that these are regexes that match the full text of a token. So $COMPANY_BEGINING will match all tokens that start with a capital letter and only contain letters (e.g. “Apple”). $COMPANY_ENDING will match the tokens “Corp”, “Inc”, “Corp.”, and “Inc.” By setting these variables to regexes, we don’t have to write out the full regex again every time we want to use it.",match inc.,0,
CoreNLP,"In the third section we bind some variables to larger regexes. This would be especially useful if the regexes were especially large, though they are small in our simple example. Note that these are regexes that match the full text of a token. So $COMPANY_BEGINING will match all tokens that start with a capital letter and only contain letters (e.g. “Apple”). $COMPANY_ENDING will match the tokens “Corp”, “Inc”, “Corp.”, and “Inc.” By setting these variables to regexes, we don’t have to write out the full regex again every time we want to use it.",set variables to regexes,0,
CoreNLP,"Finally in the fourth section we define the rule for the token pattern we wish to match. The “ruleType” of the rule is “tokens”, meaning we want to find patterns over sequences of tokens.",define rule for token pattern,0,
CoreNLP,"Finally in the fourth section we define the rule for the token pattern we wish to match. The “ruleType” of the rule is “tokens”, meaning we want to find patterns over sequences of tokens.",define fourth section for token pattern,0,
CoreNLP,The “pattern” of the rule defines the actual pattern we want to see in the tokens. In this case we say we want to see a number of $COMPANY_BEGINNING’s that have the “NNP” part of speech tag. Then we want to end with one token that matches the $COMPANY_ENDING pattern.,define actual pattern,0,
CoreNLP,The “pattern” of the rule defines the actual pattern we want to see in the tokens. In this case we say we want to see a number of $COMPANY_BEGINNING’s that have the “NNP” part of speech tag. Then we want to end with one token that matches the $COMPANY_ENDING pattern.,match $COMPANY_ENDING pattern,0,
CoreNLP,The “pattern” of the rule defines the actual pattern we want to see in the tokens. In this case we say we want to see a number of $COMPANY_BEGINNING’s that have the “NNP” part of speech tag. Then we want to end with one token that matches the $COMPANY_ENDING pattern.,match token,0,
CoreNLP,"If the pattern is matched,the “action” part of the rule will be executed. In the most typical case, this means we want to annotate all of the tokens in the matched pattern in some manner. This is done with the Annotate() function. In this rule, we state we want to annotate all of the matched tokens in the pattern (indicated by the group $0 in the token pattern), and that we want to set their “CoreAnnotation.NamedEntityTagAnnotation.class” value (indicated by “ner”), to the value “COMPANY”. This is where the actual CoreLabel’s are being altered by having their CoreAnnotations.NamedEntityTagAnnotation.class field changed.",match pattern,0,
CoreNLP,"If the pattern is matched,the “action” part of the rule will be executed. In the most typical case, this means we want to annotate all of the tokens in the matched pattern in some manner. This is done with the Annotate() function. In this rule, we state we want to annotate all of the matched tokens in the pattern (indicated by the group $0 in the token pattern), and that we want to set their “CoreAnnotation.NamedEntityTagAnnotation.class” value (indicated by “ner”), to the value “COMPANY”. This is where the actual CoreLabel’s are being altered by having their CoreAnnotations.NamedEntityTagAnnotation.class field changed.",execute action part of rule,0,
CoreNLP,"If the pattern is matched,the “action” part of the rule will be executed. In the most typical case, this means we want to annotate all of the tokens in the matched pattern in some manner. This is done with the Annotate() function. In this rule, we state we want to annotate all of the matched tokens in the pattern (indicated by the group $0 in the token pattern), and that we want to set their “CoreAnnotation.NamedEntityTagAnnotation.class” value (indicated by “ner”), to the value “COMPANY”. This is where the actual CoreLabel’s are being altered by having their CoreAnnotations.NamedEntityTagAnnotation.class field changed.",set CoreAnnotation.NamedEntityTagAnnotation.class value to value COMPANY,0,
CoreNLP,"If the pattern is matched,the “action” part of the rule will be executed. In the most typical case, this means we want to annotate all of the tokens in the matched pattern in some manner. This is done with the Annotate() function. In this rule, we state we want to annotate all of the matched tokens in the pattern (indicated by the group $0 in the token pattern), and that we want to set their “CoreAnnotation.NamedEntityTagAnnotation.class” value (indicated by “ner”), to the value “COMPANY”. This is where the actual CoreLabel’s are being altered by having their CoreAnnotations.NamedEntityTagAnnotation.class field changed.",change CoreAnnotations.NamedEntityTagAnnotation.class field,0,
CoreNLP,"Finally we may want to produce a MatchedExpression for this to operate on in our Java code, and we may want to set the value of that MatchedExpression to something. So we have the rule return a “result” when it fires, and we say the result is “COMPANY_RESULT”. The value of the MatchedExpression will be set to “COMPANY_RESULT” as a result.",produce MatchedExpression,0,
CoreNLP,"Finally we may want to produce a MatchedExpression for this to operate on in our Java code, and we may want to set the value of that MatchedExpression to something. So we have the rule return a “result” when it fires, and we say the result is “COMPANY_RESULT”. The value of the MatchedExpression will be set to “COMPANY_RESULT” as a result.",set value of MatchedExpression,0,
CoreNLP,"Finally we may want to produce a MatchedExpression for this to operate on in our Java code, and we may want to set the value of that MatchedExpression to something. So we have the rule return a “result” when it fires, and we say the result is “COMPANY_RESULT”. The value of the MatchedExpression will be set to “COMPANY_RESULT” as a result.",set value to something,0,
CoreNLP,"Finally we may want to produce a MatchedExpression for this to operate on in our Java code, and we may want to set the value of that MatchedExpression to something. So we have the rule return a “result” when it fires, and we say the result is “COMPANY_RESULT”. The value of the MatchedExpression will be set to “COMPANY_RESULT” as a result.",return result,0,
CoreNLP,"Finally we may want to produce a MatchedExpression for this to operate on in our Java code, and we may want to set the value of that MatchedExpression to something. So we have the rule return a “result” when it fires, and we say the result is “COMPANY_RESULT”. The value of the MatchedExpression will be set to “COMPANY_RESULT” as a result.",set value of MatchedExpression,0,
CoreNLP,If you run this TokensRegex pipeline on this file basic_ner.txt:,run TokensRegex pipeline on file basic_ner.txt,1,https://stanfordnlp.github.io/CoreNLP/tokensregex.html
CoreNLP,And run this Java command:,run Java command,1,https://stanfordnlp.github.io/CoreNLP/tokensregex.html
CoreNLP,"Note: in this command we are only running tokenize,ssplit,pos so the CoreLabels will have “null” for the NER token unless our rules find patterns in the input sentences. Also remember that the Java code specifies to create sentences based on newlines, so the input file is interpreted as one-sentence-per-line.",run  in command,1,https://stanfordnlp.github.io/CoreNLP/tokensregex.html
CoreNLP,"Note: in this command we are only running tokenize,ssplit,pos so the CoreLabels will have “null” for the NER token unless our rules find patterns in the input sentences. Also remember that the Java code specifies to create sentences based on newlines, so the input file is interpreted as one-sentence-per-line.",create sentences,1,https://stanfordnlp.github.io/CoreNLP/tokensregex.html
CoreNLP,"Note that “apple inc” is not being matched, meaning we have successfully set the rules to be case sensitive.",set rules,0,
CoreNLP,In this section we will go through building a pipeline that performs multi-step named entity recognition.,build pipeline,0,
CoreNLP,In this section we will go through building a pipeline that performs multi-step named entity recognition.,perform multi-step named entity recognition,0,
CoreNLP,In this section we will go through building a pipeline that performs multi-step named entity recognition.,perform pipeline,0,
CoreNLP,"In the first phase, we will identify basic components of a job title. The two we will identify are JOB_TITLE_BASE (e.g. “president”) and JOB_TITLE_MODIFIER (e.g. “vice”).",identify basic components in first phase,0,
CoreNLP,"In the first phase, we will identify basic components of a job title. The two we will identify are JOB_TITLE_BASE (e.g. “president”) and JOB_TITLE_MODIFIER (e.g. “vice”).",identify basic components of job title,0,
CoreNLP,"In the second phase, we will build on named entity tags that were applied in the first phase. Every time we see a sequence of JOB_TITLE_MODIFIER’s ending in a JOB_TITLE_BASE we will mark all of those tokens as a COMPLETE_JOB_TITLE.",build  in second phase,1,https://stanfordnlp.github.io/CoreNLP/tokensregex.html
CoreNLP,"In the second phase, we will build on named entity tags that were applied in the first phase. Every time we see a sequence of JOB_TITLE_MODIFIER’s ending in a JOB_TITLE_BASE we will mark all of those tokens as a COMPLETE_JOB_TITLE.",build  on named entity tags,1,https://stanfordnlp.github.io/CoreNLP/tokensregex.html
CoreNLP,"In the second phase, we will build on named entity tags that were applied in the first phase. Every time we see a sequence of JOB_TITLE_MODIFIER’s ending in a JOB_TITLE_BASE we will mark all of those tokens as a COMPLETE_JOB_TITLE.",mark JOB_TITLE_BASE as COMPLETE_JOB_TITLE,1,https://stanfordnlp.github.io/CoreNLP/tokensregex.html
CoreNLP,You can run this for yourself with this command:,run  with command,1,https://stanfordnlp.github.io/CoreNLP/tokensregex.html
CoreNLP,If you run it on this example file multi_step_ner.txt,run  on example file multi_step_ner.txt,1,https://stanfordnlp.github.io/CoreNLP/tokensregex.html
CoreNLP,You should get this output:,get output,1,https://stanfordnlp.github.io/CoreNLP/tokensregex.html
CoreNLP,"Note that the sentence containing “deputy vice president” does have those tokens tagged as COMPLETE_JOB_TITLE’s, but that no matched expression is found for “deputy vice president” because of the filter. Note that the last two sentences have no named entity tags because we added a cleanup rule at the end. If we didn’t have that cleanup rule “president” and “President” would’ve been tagged with “JOB_TITLE_BASE”.",tag  as COMPLETE_JOB_TITLE,0,
CoreNLP,"Note that the sentence containing “deputy vice president” does have those tokens tagged as COMPLETE_JOB_TITLE’s, but that no matched expression is found for “deputy vice president” because of the filter. Note that the last two sentences have no named entity tags because we added a cleanup rule at the end. If we didn’t have that cleanup rule “president” and “President” would’ve been tagged with “JOB_TITLE_BASE”.",add cleanup rule at end,0,
CoreNLP,"Note that the sentence containing “deputy vice president” does have those tokens tagged as COMPLETE_JOB_TITLE’s, but that no matched expression is found for “deputy vice president” because of the filter. Note that the last two sentences have no named entity tags because we added a cleanup rule at the end. If we didn’t have that cleanup rule “president” and “President” would’ve been tagged with “JOB_TITLE_BASE”.",tag  with job_title_base,0,
CoreNLP,"If the pattern is found, we will get a MatchedExpression which will contain a list of tokens. This could be useful if you wanted to find quoted text and then work on the tokens of the quote.",get MatchedExpression,1,https://stanfordnlp.github.io/CoreNLP/tokensregex.html
CoreNLP,you should get this output:,get output,0,
CoreNLP,"The pattern finds a quote, and it returns a MatchedExpression with the values shown in the output.",return MatchedExpression with values,0,
CoreNLP,"The pattern finds a quote, and it returns a MatchedExpression with the values shown in the output.",show  in output,0,
CoreNLP,"This example demonstrates the composite rule type, it will run on a math equation and calculate the value of it. The rule should match (among other things) two numbers separated by an operator, and assign that expression the value of executing the operation on the operands. “(“, expression, “)” will be matched to be the same expression and have the same value as the enclosed expression (this is to process parenthesis). Every time a pattern is matched, all of the tokens in the pattern match will be replaced with an “aggregate token” representing the whole matched pattern.",calculate value,0,
CoreNLP,"This example demonstrates the composite rule type, it will run on a math equation and calculate the value of it. The rule should match (among other things) two numbers separated by an operator, and assign that expression the value of executing the operation on the operands. “(“, expression, “)” will be matched to be the same expression and have the same value as the enclosed expression (this is to process parenthesis). Every time a pattern is matched, all of the tokens in the pattern match will be replaced with an “aggregate token” representing the whole matched pattern.",run  on math equation,0,
CoreNLP,"This example demonstrates the composite rule type, it will run on a math equation and calculate the value of it. The rule should match (among other things) two numbers separated by an operator, and assign that expression the value of executing the operation on the operands. “(“, expression, “)” will be matched to be the same expression and have the same value as the enclosed expression (this is to process parenthesis). Every time a pattern is matched, all of the tokens in the pattern match will be replaced with an “aggregate token” representing the whole matched pattern.",match numbers,0,
CoreNLP,"This example demonstrates the composite rule type, it will run on a math equation and calculate the value of it. The rule should match (among other things) two numbers separated by an operator, and assign that expression the value of executing the operation on the operands. “(“, expression, “)” will be matched to be the same expression and have the same value as the enclosed expression (this is to process parenthesis). Every time a pattern is matched, all of the tokens in the pattern match will be replaced with an “aggregate token” representing the whole matched pattern.",assign numbers,0,
CoreNLP,"This example demonstrates the composite rule type, it will run on a math equation and calculate the value of it. The rule should match (among other things) two numbers separated by an operator, and assign that expression the value of executing the operation on the operands. “(“, expression, “)” will be matched to be the same expression and have the same value as the enclosed expression (this is to process parenthesis). Every time a pattern is matched, all of the tokens in the pattern match will be replaced with an “aggregate token” representing the whole matched pattern.",execute operation on operands,0,
CoreNLP,"This example demonstrates the composite rule type, it will run on a math equation and calculate the value of it. The rule should match (among other things) two numbers separated by an operator, and assign that expression the value of executing the operation on the operands. “(“, expression, “)” will be matched to be the same expression and have the same value as the enclosed expression (this is to process parenthesis). Every time a pattern is matched, all of the tokens in the pattern match will be replaced with an “aggregate token” representing the whole matched pattern.",replace  with aggregate token,0,
CoreNLP,"This example demonstrates the composite rule type, it will run on a math equation and calculate the value of it. The rule should match (among other things) two numbers separated by an operator, and assign that expression the value of executing the operation on the operands. “(“, expression, “)” will be matched to be the same expression and have the same value as the enclosed expression (this is to process parenthesis). Every time a pattern is matched, all of the tokens in the pattern match will be replaced with an “aggregate token” representing the whole matched pattern.",match pattern,0,
CoreNLP,For instance if you process (5 + 5) + 5 it will run the composite rules and end up calculating 15.,run composite rules for instance,0,
CoreNLP,The composite rules are run over and over again until nothing changes. Matched expressions are replaced with an aggregate token which represents the whole matched expression.,replace matched expressions with aggregate token,1,https://stanfordnlp.github.io/CoreNLP/tokensregex.html
CoreNLP,If you run on this example sentence: math_expression.txt,run  on example sentence math_expression.txt,1,https://stanfordnlp.github.io/CoreNLP/tokensregex.html
CoreNLP,"However, here are some tutorials by third parties. Note that some of this tutorial material ages with the release of newer versions of CoreNLP, and it may not be fully up to date with current CoreNLP. Check the date/version of it.",check date/version,0,
CoreNLP,"In this section we cover getting started with CoreNLP and different usage modes. CoreNLP can be used via the command line, in Java code, or with calls to a server, and can be run on multiple languages including Arabic, Chinese, English, French, German, and Spanish.",use CoreNLP with calls,0,
CoreNLP,"In this section we cover getting started with CoreNLP and different usage modes. CoreNLP can be used via the command line, in Java code, or with calls to a server, and can be run on multiple languages including Arabic, Chinese, English, French, German, and Spanish.",use CoreNLP in Java code,0,
CoreNLP,"In this section we cover getting started with CoreNLP and different usage modes. CoreNLP can be used via the command line, in Java code, or with calls to a server, and can be run on multiple languages including Arabic, Chinese, English, French, German, and Spanish.",use CoreNLP via command line,0,
CoreNLP,"In this section we cover getting started with CoreNLP and different usage modes. CoreNLP can be used via the command line, in Java code, or with calls to a server, and can be run on multiple languages including Arabic, Chinese, English, French, German, and Spanish.",run CoreNLP on multiple languages,0,
