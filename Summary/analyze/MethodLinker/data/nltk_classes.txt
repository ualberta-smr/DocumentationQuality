{   'ARFF_Formatter': {'source_file': 'nltk\\nltk\\classify\\weka.py'},
    'ARLSTem': {'source_file': 'nltk\\nltk\\stem\\arlstem.py'},
    'ARLSTem2': {'source_file': 'nltk\\nltk\\stem\\arlstem2.py'},
    'AbsoluteDiscounting': {'source_file': 'nltk\\nltk\\lm\\smoothing.py'},
    'AbsoluteDiscountingInterpolated': {   'source_file': 'nltk\\nltk\\lm\\models.py'},
    'AbstractBoxerDrs': {'source_file': 'nltk\\nltk\\sem\\boxer.py'},
    'AbstractCCGCategory': {'source_file': 'nltk\\nltk\\ccg\\api.py'},
    'AbstractChartRule': {'source_file': 'nltk\\nltk\\parse\\chart.py'},
    'AbstractCollocationFinder': {'source_file': 'nltk\\nltk\\collocations.py'},
    'AbstractContainerWidget': {'source_file': 'nltk\\nltk\\draw\\util.py'},
    'AbstractLazySequence': {'source_file': 'nltk\\nltk\\collections.py'},
    'AbstractParentedTree': {'source_file': 'nltk\\nltk\\tree\\parented.py'},
    'AbstractVariableExpression': {'source_file': 'nltk\\nltk\\sem\\logic.py'},
    'AffixTagger': {'source_file': 'nltk\\nltk\\tag\\sequential.py'},
    'Agenda': {'source_file': 'nltk\\nltk\\inference\\tableau.py'},
    'AlignedCorpusReader': {   'source_file': 'nltk\\nltk\\corpus\\reader\\aligned.py'},
    'AlignedSent': {'source_file': 'nltk\\nltk\\translate\\api.py'},
    'AlignedSentCorpusView': {   'source_file': 'nltk\\nltk\\corpus\\reader\\aligned.py'},
    'Alignment': {'source_file': 'nltk\\nltk\\translate\\api.py'},
    'AlignmentInfo': {'source_file': 'nltk\\nltk\\translate\\ibm_model.py'},
    'AllExpression': {'source_file': 'nltk\\nltk\\sem\\logic.py'},
    'AlpinoCorpusReader': {   'source_file': 'nltk\\nltk\\corpus\\reader\\bracket_parse.py'},
    'AndExpression': {'source_file': 'nltk\\nltk\\sem\\logic.py'},
    'AnnotationTask': {'source_file': 'nltk\\nltk\\metrics\\agreement.py'},
    'AnyType': {'source_file': 'nltk\\nltk\\sem\\logic.py'},
    'ApplicationExpression': {'source_file': 'nltk\\nltk\\sem\\logic.py'},
    'ArabicStemmer': {'source_file': 'nltk\\nltk\\stem\\snowball.py'},
    'Assignment': {'source_file': 'nltk\\nltk\\sem\\evaluate.py'},
    'AtomicExpression': {'source_file': 'nltk\\nltk\\sem\\linearlogic.py'},
    'AttrDict': {'source_file': 'nltk\\nltk\\corpus\\reader\\framenet.py'},
    'Authenticate': {'source_file': 'nltk\\nltk\\twitter\\util.py'},
    'AveragedPerceptron': {'source_file': 'nltk\\nltk\\tag\\perceptron.py'},
    'BNCCorpusReader': {'source_file': 'nltk\\nltk\\corpus\\reader\\bnc.py'},
    'BNCSentence': {'source_file': 'nltk\\nltk\\corpus\\reader\\bnc.py'},
    'BNCWordView': {'source_file': 'nltk\\nltk\\corpus\\reader\\bnc.py'},
    'BackwardCombinator': {'source_file': 'nltk\\nltk\\ccg\\combinator.py'},
    'BackwardTypeRaiseRule': {'source_file': 'nltk\\nltk\\ccg\\chart.py'},
    'BaseModelBuilderCommand': {'source_file': 'nltk\\nltk\\inference\\api.py'},
    'BaseProverCommand': {'source_file': 'nltk\\nltk\\inference\\api.py'},
    'BaseTheoremToolCommand': {'source_file': 'nltk\\nltk\\inference\\api.py'},
    'BasicTweetHandler': {'source_file': 'nltk\\nltk\\twitter\\api.py'},
    'BasicType': {'source_file': 'nltk\\nltk\\sem\\logic.py'},
    'BigramAssocMeasures': {   'source_file': 'nltk\\nltk\\metrics\\association.py'},
    'BigramCollocationFinder': {'source_file': 'nltk\\nltk\\collocations.py'},
    'BigramTagger': {'source_file': 'nltk\\nltk\\tag\\sequential.py'},
    'BinaryCombinatorRule': {'source_file': 'nltk\\nltk\\ccg\\chart.py'},
    'BinaryExpression': {'source_file': 'nltk\\nltk\\sem\\logic.py'},
    'BinaryMaxentFeatureEncoding': {   'source_file': 'nltk\\nltk\\classify\\maxent.py'},
    'BindingDict': {'source_file': 'nltk\\nltk\\sem\\linearlogic.py'},
    'BindingException': {'source_file': 'nltk\\nltk\\inference\\resolution.py'},
    'BlanklineTokenizer': {'source_file': 'nltk\\nltk\\tokenize\\regexp.py'},
    'BllipParser': {'source_file': 'nltk\\nltk\\parse\\bllip.py'},
    'BottomUpChartParser': {'source_file': 'nltk\\nltk\\parse\\chart.py'},
    'BottomUpLeftCornerChartParser': {   'source_file': 'nltk\\nltk\\parse\\chart.py'},
    'BottomUpPredictCombineRule': {   'source_file': 'nltk\\nltk\\parse\\chart.py'},
    'BottomUpPredictRule': {'source_file': 'nltk\\nltk\\parse\\chart.py'},
    'BottomUpProbabilisticChartParser': {   'source_file': 'nltk\\nltk\\parse\\pchart.py'},
    'BoxWidget': {'source_file': 'nltk\\nltk\\draw\\util.py'},
    'Boxer': {'source_file': 'nltk\\nltk\\sem\\boxer.py'},
    'BoxerCard': {'source_file': 'nltk\\nltk\\sem\\boxer.py'},
    'BoxerDrs': {'source_file': 'nltk\\nltk\\sem\\boxer.py'},
    'BoxerDrsParser': {'source_file': 'nltk\\nltk\\sem\\boxer.py'},
    'BoxerEq': {'source_file': 'nltk\\nltk\\sem\\boxer.py'},
    'BoxerIndexed': {'source_file': 'nltk\\nltk\\sem\\boxer.py'},
    'BoxerNamed': {'source_file': 'nltk\\nltk\\sem\\boxer.py'},
    'BoxerNot': {'source_file': 'nltk\\nltk\\sem\\boxer.py'},
    'BoxerOr': {'source_file': 'nltk\\nltk\\sem\\boxer.py'},
    'BoxerOutputDrsParser': {'source_file': 'nltk\\nltk\\sem\\boxer.py'},
    'BoxerPred': {'source_file': 'nltk\\nltk\\sem\\boxer.py'},
    'BoxerProp': {'source_file': 'nltk\\nltk\\sem\\boxer.py'},
    'BoxerRel': {'source_file': 'nltk\\nltk\\sem\\boxer.py'},
    'BoxerWhq': {'source_file': 'nltk\\nltk\\sem\\boxer.py'},
    'BracketParseCorpusReader': {   'source_file': 'nltk\\nltk\\corpus\\reader\\bracket_parse.py'},
    'BracketWidget': {'source_file': 'nltk\\nltk\\draw\\util.py'},
    'BrillTagger': {'source_file': 'nltk\\nltk\\tag\\brill.py'},
    'BrillTaggerTrainer': {'source_file': 'nltk\\nltk\\tag\\brill_trainer.py'},
    'BrillTemplateI': {'source_file': 'nltk\\nltk\\tbl\\template.py'},
    'BufferedGzipFile': {'source_file': 'nltk\\nltk\\data.py'},
    'CCGChart': {'source_file': 'nltk\\nltk\\ccg\\chart.py'},
    'CCGChartParser': {'source_file': 'nltk\\nltk\\ccg\\chart.py'},
    'CCGEdge': {'source_file': 'nltk\\nltk\\ccg\\chart.py'},
    'CCGLeafEdge': {'source_file': 'nltk\\nltk\\ccg\\chart.py'},
    'CCGLexicon': {'source_file': 'nltk\\nltk\\ccg\\lexicon.py'},
    'CCGVar': {'source_file': 'nltk\\nltk\\ccg\\api.py'},
    'CFG': {'source_file': 'nltk\\nltk\\grammar.py'},
    'CFGDemo': {'source_file': 'nltk\\nltk\\draw\\cfg.py'},
    'CFGEditor': {'source_file': 'nltk\\nltk\\draw\\cfg.py'},
    'CHILDESCorpusReader': {   'source_file': 'nltk\\nltk\\corpus\\reader\\childes.py'},
    'CMUDictCorpusReader': {   'source_file': 'nltk\\nltk\\corpus\\reader\\cmudict.py'},
    'CRFTagger': {'source_file': 'nltk\\nltk\\tag\\crf.py'},
    'CachedTopDownPredictRule': {'source_file': 'nltk\\nltk\\parse\\chart.py'},
    'CanvasFrame': {'source_file': 'nltk\\nltk\\draw\\util.py'},
    'CanvasWidget': {'source_file': 'nltk\\nltk\\draw\\util.py'},
    'CategorizedBracketParseCorpusReader': {   'source_file': 'nltk\\nltk\\corpus\\reader\\bracket_parse.py'},
    'CategorizedCorpusReader': {   'source_file': 'nltk\\nltk\\corpus\\reader\\api.py'},
    'CategorizedPlaintextCorpusReader': {   'source_file': 'nltk\\nltk\\corpus\\reader\\plaintext.py'},
    'CategorizedSentencesCorpusReader': {   'source_file': 'nltk\\nltk\\corpus\\reader\\categorized_sents.py'},
    'CategorizedTaggedCorpusReader': {   'source_file': 'nltk\\nltk\\corpus\\reader\\tagged.py'},
    'CfgReadingCommand': {'source_file': 'nltk\\nltk\\inference\\discourse.py'},
    'CharTokenizer': {'source_file': 'nltk\\nltk\\tokenize\\simple.py'},
    'Chart': {'source_file': 'nltk\\nltk\\parse\\chart.py'},
    'ChartCell': {   'source_file': 'nltk\\nltk\\parse\\projectivedependencyparser.py'},
    'ChartComparer': {'source_file': 'nltk\\nltk\\app\\chartparser_app.py'},
    'ChartMatrixView': {'source_file': 'nltk\\nltk\\app\\chartparser_app.py'},
    'ChartParser': {'source_file': 'nltk\\nltk\\parse\\chart.py'},
    'ChartParserApp': {'source_file': 'nltk\\nltk\\app\\chartparser_app.py'},
    'ChartResultsView': {'source_file': 'nltk\\nltk\\app\\chartparser_app.py'},
    'ChartRuleI': {'source_file': 'nltk\\nltk\\parse\\chart.py'},
    'ChartView': {'source_file': 'nltk\\nltk\\app\\chartparser_app.py'},
    'ChasenCorpusReader': {   'source_file': 'nltk\\nltk\\corpus\\reader\\chasen.py'},
    'ChasenCorpusView': {   'source_file': 'nltk\\nltk\\corpus\\reader\\chasen.py'},
    'Chat': {'source_file': 'nltk\\nltk\\chat\\util.py'},
    'ChunkParserI': {'source_file': 'nltk\\nltk\\chunk\\api.py'},
    'ChunkRule': {'source_file': 'nltk\\nltk\\chunk\\regexp.py'},
    'ChunkRuleWithContext': {'source_file': 'nltk\\nltk\\chunk\\regexp.py'},
    'ChunkScore': {'source_file': 'nltk\\nltk\\chunk\\util.py'},
    'ChunkString': {'source_file': 'nltk\\nltk\\chunk\\regexp.py'},
    'ChunkedCorpusReader': {   'source_file': 'nltk\\nltk\\corpus\\reader\\chunked.py'},
    'ChunkedCorpusView': {   'source_file': 'nltk\\nltk\\corpus\\reader\\chunked.py'},
    'Cistem': {'source_file': 'nltk\\nltk\\stem\\cistem.py'},
    'ClassifierBasedPOSTagger': {   'source_file': 'nltk\\nltk\\tag\\sequential.py'},
    'ClassifierBasedTagger': {'source_file': 'nltk\\nltk\\tag\\sequential.py'},
    'ClassifierI': {'source_file': 'nltk\\nltk\\classify\\api.py'},
    'Clause': {'source_file': 'nltk\\nltk\\inference\\resolution.py'},
    'ClosedDomainProver': {   'source_file': 'nltk\\nltk\\inference\\nonmonotonic.py'},
    'ClosedWorldProver': {   'source_file': 'nltk\\nltk\\inference\\nonmonotonic.py'},
    'ClusterI': {'source_file': 'nltk\\nltk\\cluster\\api.py'},
    'Collection': {'source_file': 'nltk\\nltk\\downloader.py'},
    'CollocationsModel': {   'source_file': 'nltk\\nltk\\app\\collocations_app.py'},
    'CollocationsView': {'source_file': 'nltk\\nltk\\app\\collocations_app.py'},
    'ColorizedList': {'source_file': 'nltk\\nltk\\draw\\util.py'},
    'ComparativeSentencesCorpusReader': {   'source_file': 'nltk\\nltk\\corpus\\reader\\comparative_sents.py'},
    'Comparison': {   'source_file': 'nltk\\nltk\\corpus\\reader\\comparative_sents.py'},
    'CompleterRule': {'source_file': 'nltk\\nltk\\parse\\earleychart.py'},
    'ComplexType': {'source_file': 'nltk\\nltk\\sem\\logic.py'},
    'ConcatenatedCorpusView': {   'source_file': 'nltk\\nltk\\corpus\\reader\\util.py'},
    'Concept': {'source_file': 'nltk\\nltk\\sem\\chat80.py'},
    'ConcordanceIndex': {'source_file': 'nltk\\nltk\\text.py'},
    'ConcordanceSearchModel': {   'source_file': 'nltk\\nltk\\app\\concordance_app.py'},
    'ConcordanceSearchView': {   'source_file': 'nltk\\nltk\\app\\concordance_app.py'},
    'ConditionalFreqDist': {'source_file': 'nltk\\nltk\\probability.py'},
    'ConditionalProbDist': {'source_file': 'nltk\\nltk\\probability.py'},
    'ConditionalProbDistI': {'source_file': 'nltk\\nltk\\probability.py'},
    'Configuration': {'source_file': 'nltk\\nltk\\parse\\transitionparser.py'},
    'ConfusionMatrix': {   'source_file': 'nltk\\nltk\\metrics\\confusionmatrix.py'},
    'ConllChunkCorpusReader': {   'source_file': 'nltk\\nltk\\corpus\\reader\\conll.py'},
    'ConllCorpusReader': {   'source_file': 'nltk\\nltk\\corpus\\reader\\conll.py'},
    'ConllSRLInstance': {'source_file': 'nltk\\nltk\\corpus\\reader\\conll.py'},
    'ConllSRLInstanceList': {   'source_file': 'nltk\\nltk\\corpus\\reader\\conll.py'},
    'ConstantExpression': {'source_file': 'nltk\\nltk\\sem\\logic.py'},
    'Constraint': {'source_file': 'nltk\\nltk\\sem\\hole.py'},
    'ContextIndex': {'source_file': 'nltk\\nltk\\text.py'},
    'ContextTagger': {'source_file': 'nltk\\nltk\\tag\\sequential.py'},
    'ContingencyMeasures': {   'source_file': 'nltk\\nltk\\metrics\\association.py'},
    'CooperStore': {'source_file': 'nltk\\nltk\\sem\\cooper_storage.py'},
    'CoreNLPDependencyParser': {'source_file': 'nltk\\nltk\\parse\\corenlp.py'},
    'CoreNLPParser': {'source_file': 'nltk\\nltk\\parse\\corenlp.py'},
    'CoreNLPServer': {'source_file': 'nltk\\nltk\\parse\\corenlp.py'},
    'CorpusReader': {'source_file': 'nltk\\nltk\\corpus\\reader\\api.py'},
    'Counter': {'source_file': 'nltk\\nltk\\internals.py'},
    'Counts': {'source_file': 'nltk\\nltk\\translate\\ibm_model.py'},
    'CrossValidationProbDist': {'source_file': 'nltk\\nltk\\probability.py'},
    'CrubadanCorpusReader': {   'source_file': 'nltk\\nltk\\corpus\\reader\\crubadan.py'},
    'CustomFeatureValue': {'source_file': 'nltk\\nltk\\featstruct.py'},
    'CutoffChecker': {'source_file': 'nltk\\nltk\\classify\\util.py'},
    'DRS': {'source_file': 'nltk\\nltk\\sem\\drt.py'},
    'DanishStemmer': {'source_file': 'nltk\\nltk\\stem\\snowball.py'},
    'Debug': {'source_file': 'nltk\\nltk\\inference\\tableau.py'},
    'DebugObject': {'source_file': 'nltk\\nltk\\inference\\resolution.py'},
    'DecisionTreeClassifier': {   'source_file': 'nltk\\nltk\\classify\\decisiontree.py'},
    'DefaultTagger': {'source_file': 'nltk\\nltk\\tag\\sequential.py'},
    'DemoScorer': {   'source_file': 'nltk\\nltk\\parse\\nonprojectivedependencyparser.py'},
    'Dendrogram': {'source_file': 'nltk\\nltk\\cluster\\util.py'},
    'DependencyCorpusReader': {   'source_file': 'nltk\\nltk\\corpus\\reader\\dependency.py'},
    'DependencyCorpusView': {   'source_file': 'nltk\\nltk\\corpus\\reader\\dependency.py'},
    'DependencyEvaluator': {'source_file': 'nltk\\nltk\\parse\\evaluate.py'},
    'DependencyGrammar': {'source_file': 'nltk\\nltk\\grammar.py'},
    'DependencyGraph': {'source_file': 'nltk\\nltk\\parse\\dependencygraph.py'},
    'DependencyProduction': {'source_file': 'nltk\\nltk\\grammar.py'},
    'DependencyScorerI': {   'source_file': 'nltk\\nltk\\parse\\nonprojectivedependencyparser.py'},
    'DependencySpan': {   'source_file': 'nltk\\nltk\\parse\\projectivedependencyparser.py'},
    'Deprecated': {'source_file': 'nltk\\nltk\\internals.py'},
    'DictionaryConditionalProbDist': {   'source_file': 'nltk\\nltk\\probability.py'},
    'DictionaryProbDist': {'source_file': 'nltk\\nltk\\probability.py'},
    'DirectedBinaryCombinator': {   'source_file': 'nltk\\nltk\\ccg\\combinator.py'},
    'Direction': {'source_file': 'nltk\\nltk\\ccg\\api.py'},
    'DiscourseTester': {'source_file': 'nltk\\nltk\\inference\\discourse.py'},
    'Downloader': {'source_file': 'nltk\\nltk\\downloader.py'},
    'DownloaderGUI': {'source_file': 'nltk\\nltk\\downloader.py'},
    'DownloaderShell': {'source_file': 'nltk\\nltk\\downloader.py'},
    'DrsDrawer': {'source_file': 'nltk\\nltk\\sem\\drt.py'},
    'DrsWidget': {'source_file': 'nltk\\nltk\\sem\\drt_glue_demo.py'},
    'DrtAbstractVariableExpression': {'source_file': 'nltk\\nltk\\sem\\drt.py'},
    'DrtApplicationExpression': {'source_file': 'nltk\\nltk\\sem\\drt.py'},
    'DrtBinaryExpression': {'source_file': 'nltk\\nltk\\sem\\drt.py'},
    'DrtConcatenation': {'source_file': 'nltk\\nltk\\sem\\drt.py'},
    'DrtEqualityExpression': {'source_file': 'nltk\\nltk\\sem\\drt.py'},
    'DrtExpression': {'source_file': 'nltk\\nltk\\sem\\drt.py'},
    'DrtGlue': {'source_file': 'nltk\\nltk\\sem\\glue.py'},
    'DrtGlueDemo': {'source_file': 'nltk\\nltk\\sem\\drt_glue_demo.py'},
    'DrtGlueDict': {'source_file': 'nltk\\nltk\\sem\\glue.py'},
    'DrtGlueFormula': {'source_file': 'nltk\\nltk\\sem\\glue.py'},
    'DrtGlueReadingCommand': {   'source_file': 'nltk\\nltk\\inference\\discourse.py'},
    'DrtLambdaExpression': {'source_file': 'nltk\\nltk\\sem\\drt.py'},
    'DrtNegatedExpression': {'source_file': 'nltk\\nltk\\sem\\drt.py'},
    'DrtOrExpression': {'source_file': 'nltk\\nltk\\sem\\drt.py'},
    'DrtParser': {'source_file': 'nltk\\nltk\\sem\\drt.py'},
    'DrtProposition': {'source_file': 'nltk\\nltk\\sem\\drt.py'},
    'DutchStemmer': {'source_file': 'nltk\\nltk\\stem\\snowball.py'},
    'ELEProbDist': {'source_file': 'nltk\\nltk\\probability.py'},
    'EMClusterer': {'source_file': 'nltk\\nltk\\cluster\\em.py'},
    'EarleyChartParser': {'source_file': 'nltk\\nltk\\parse\\earleychart.py'},
    'EdgeI': {'source_file': 'nltk\\nltk\\parse\\chart.py'},
    'EdgeRule': {'source_file': 'nltk\\nltk\\app\\chartparser_app.py'},
    'ElementWrapper': {'source_file': 'nltk\\nltk\\internals.py'},
    'EmptyPredictRule': {'source_file': 'nltk\\nltk\\parse\\chart.py'},
    'EnglishStemmer': {'source_file': 'nltk\\nltk\\stem\\snowball.py'},
    'EntityType': {'source_file': 'nltk\\nltk\\sem\\logic.py'},
    'EntryDialog': {'source_file': 'nltk\\nltk\\draw\\util.py'},
    'EqualityExpression': {'source_file': 'nltk\\nltk\\sem\\logic.py'},
    'ErrorMessage': {'source_file': 'nltk\\nltk\\downloader.py'},
    'EuroparlCorpusReader': {   'source_file': 'nltk\\nltk\\corpus\\reader\\plaintext.py'},
    'EventType': {'source_file': 'nltk\\nltk\\sem\\logic.py'},
    'ExistsExpression': {'source_file': 'nltk\\nltk\\sem\\logic.py'},
    'ExpandLeftRule': {'source_file': 'nltk\\nltk\\chunk\\regexp.py'},
    'ExpandRightRule': {'source_file': 'nltk\\nltk\\chunk\\regexp.py'},
    'ExpectedMoreTokensException': {'source_file': 'nltk\\nltk\\sem\\logic.py'},
    'Expression': {'source_file': 'nltk\\nltk\\sem\\logic.py'},
    'FStructure': {'source_file': 'nltk\\nltk\\sem\\lfg.py'},
    'FeatDict': {'source_file': 'nltk\\nltk\\featstruct.py'},
    'FeatList': {'source_file': 'nltk\\nltk\\featstruct.py'},
    'FeatStruct': {'source_file': 'nltk\\nltk\\featstruct.py'},
    'FeatStructNonterminal': {'source_file': 'nltk\\nltk\\grammar.py'},
    'FeatStructReader': {'source_file': 'nltk\\nltk\\featstruct.py'},
    'Feature': {'source_file': 'nltk\\nltk\\tbl\\feature.py'},
    'FeatureBottomUpChartParser': {   'source_file': 'nltk\\nltk\\parse\\featurechart.py'},
    'FeatureBottomUpLeftCornerChartParser': {   'source_file': 'nltk\\nltk\\parse\\featurechart.py'},
    'FeatureBottomUpPredictCombineRule': {   'source_file': 'nltk\\nltk\\parse\\featurechart.py'},
    'FeatureBottomUpPredictRule': {   'source_file': 'nltk\\nltk\\parse\\featurechart.py'},
    'FeatureChart': {'source_file': 'nltk\\nltk\\parse\\featurechart.py'},
    'FeatureChartParser': {'source_file': 'nltk\\nltk\\parse\\featurechart.py'},
    'FeatureEarleyChartParser': {   'source_file': 'nltk\\nltk\\parse\\earleychart.py'},
    'FeatureEmptyPredictRule': {   'source_file': 'nltk\\nltk\\parse\\featurechart.py'},
    'FeatureFundamentalRule': {   'source_file': 'nltk\\nltk\\parse\\featurechart.py'},
    'FeatureGrammar': {'source_file': 'nltk\\nltk\\grammar.py'},
    'FeatureIncrementalBottomUpChartParser': {   'source_file': 'nltk\\nltk\\parse\\earleychart.py'},
    'FeatureIncrementalBottomUpLeftCornerChartParser': {   'source_file': 'nltk\\nltk\\parse\\earleychart.py'},
    'FeatureIncrementalChart': {   'source_file': 'nltk\\nltk\\parse\\earleychart.py'},
    'FeatureIncrementalChartParser': {   'source_file': 'nltk\\nltk\\parse\\earleychart.py'},
    'FeatureIncrementalTopDownChartParser': {   'source_file': 'nltk\\nltk\\parse\\earleychart.py'},
    'FeatureTopDownChartParser': {   'source_file': 'nltk\\nltk\\parse\\featurechart.py'},
    'FeatureTopDownInitRule': {   'source_file': 'nltk\\nltk\\parse\\featurechart.py'},
    'FeatureTopDownPredictRule': {   'source_file': 'nltk\\nltk\\parse\\featurechart.py'},
    'FeatureTreeEdge': {'source_file': 'nltk\\nltk\\parse\\featurechart.py'},
    'FeatureValueConcat': {'source_file': 'nltk\\nltk\\featstruct.py'},
    'FeatureValueSet': {'source_file': 'nltk\\nltk\\featstruct.py'},
    'FeatureValueTuple': {'source_file': 'nltk\\nltk\\featstruct.py'},
    'FeatureValueType': {'source_file': 'nltk\\nltk\\grammar.py'},
    'FeatureValueUnion': {'source_file': 'nltk\\nltk\\featstruct.py'},
    'FileSystemPathPointer': {'source_file': 'nltk\\nltk\\data.py'},
    'FilteredBottomUpPredictCombineRule': {   'source_file': 'nltk\\nltk\\parse\\chart.py'},
    'FilteredCompleteFundamentalRule': {   'source_file': 'nltk\\nltk\\parse\\earleychart.py'},
    'FindZone': {'source_file': 'nltk\\nltk\\app\\nemo_app.py'},
    'FinishCollectionMessage': {'source_file': 'nltk\\nltk\\downloader.py'},
    'FinishDownloadMessage': {'source_file': 'nltk\\nltk\\downloader.py'},
    'FinishPackageMessage': {'source_file': 'nltk\\nltk\\downloader.py'},
    'FinishUnzipMessage': {'source_file': 'nltk\\nltk\\downloader.py'},
    'FinnishStemmer': {'source_file': 'nltk\\nltk\\stem\\snowball.py'},
    'ForwardCombinator': {'source_file': 'nltk\\nltk\\ccg\\combinator.py'},
    'ForwardTypeRaiseRule': {'source_file': 'nltk\\nltk\\ccg\\chart.py'},
    'FramenetCorpusReader': {   'source_file': 'nltk\\nltk\\corpus\\reader\\framenet.py'},
    'FrenchStemmer': {'source_file': 'nltk\\nltk\\stem\\snowball.py'},
    'FreqDist': {'source_file': 'nltk\\nltk\\probability.py'},
    'FunctionBackedMaxentFeatureEncoding': {   'source_file': 'nltk\\nltk\\classify\\maxent.py'},
    'FunctionVariableExpression': {'source_file': 'nltk\\nltk\\sem\\logic.py'},
    'FunctionalCategory': {'source_file': 'nltk\\nltk\\ccg\\api.py'},
    'FundamentalRule': {'source_file': 'nltk\\nltk\\parse\\chart.py'},
    'Future': {'source_file': 'nltk\\nltk\\corpus\\reader\\framenet.py'},
    'GAAClusterer': {'source_file': 'nltk\\nltk\\cluster\\gaac.py'},
    'GISEncoding': {'source_file': 'nltk\\nltk\\classify\\maxent.py'},
    'GenericCoreNLPParser': {'source_file': 'nltk\\nltk\\parse\\corenlp.py'},
    'GenericStanfordParser': {'source_file': 'nltk\\nltk\\parse\\stanford.py'},
    'GermanStemmer': {'source_file': 'nltk\\nltk\\stem\\snowball.py'},
    'Glue': {'source_file': 'nltk\\nltk\\sem\\glue.py'},
    'GlueDict': {'source_file': 'nltk\\nltk\\sem\\glue.py'},
    'GlueFormula': {'source_file': 'nltk\\nltk\\sem\\glue.py'},
    'GzipFileSystemPathPointer': {'source_file': 'nltk\\nltk\\data.py'},
    'HeldoutProbDist': {'source_file': 'nltk\\nltk\\probability.py'},
    'HiddenMarkovModelTagger': {'source_file': 'nltk\\nltk\\tag\\hmm.py'},
    'HiddenMarkovModelTrainer': {'source_file': 'nltk\\nltk\\tag\\hmm.py'},
    'HoleSemantics': {'source_file': 'nltk\\nltk\\sem\\hole.py'},
    'HungarianStemmer': {'source_file': 'nltk\\nltk\\stem\\snowball.py'},
    'HunposTagger': {'source_file': 'nltk\\nltk\\tag\\hunpos.py'},
    'IBMModel': {'source_file': 'nltk\\nltk\\translate\\ibm_model.py'},
    'IBMModel1': {'source_file': 'nltk\\nltk\\translate\\ibm1.py'},
    'IBMModel2': {'source_file': 'nltk\\nltk\\translate\\ibm2.py'},
    'IBMModel3': {'source_file': 'nltk\\nltk\\translate\\ibm3.py'},
    'IBMModel4': {'source_file': 'nltk\\nltk\\translate\\ibm4.py'},
    'IBMModel5': {'source_file': 'nltk\\nltk\\translate\\ibm5.py'},
    'IEERCorpusReader': {'source_file': 'nltk\\nltk\\corpus\\reader\\ieer.py'},
    'IEERDocument': {'source_file': 'nltk\\nltk\\corpus\\reader\\ieer.py'},
    'IPIPANCorpusReader': {   'source_file': 'nltk\\nltk\\corpus\\reader\\ipipan.py'},
    'IPIPANCorpusView': {   'source_file': 'nltk\\nltk\\corpus\\reader\\ipipan.py'},
    'ISRIStemmer': {'source_file': 'nltk\\nltk\\stem\\isri.py'},
    'IffExpression': {'source_file': 'nltk\\nltk\\sem\\logic.py'},
    'IgnoreReadmeCorpusView': {   'source_file': 'nltk\\nltk\\corpus\\reader\\opinion_lexicon.py'},
    'IllegalTypeException': {'source_file': 'nltk\\nltk\\sem\\logic.py'},
    'ImmutableProbabilisticMixIn': {   'source_file': 'nltk\\nltk\\probability.py'},
    'ImmutableProbabilisticTree': {   'source_file': 'nltk\\nltk\\tree\\immutable.py'},
    'ImmutableTree': {'source_file': 'nltk\\nltk\\tree\\immutable.py'},
    'ImpExpression': {'source_file': 'nltk\\nltk\\sem\\logic.py'},
    'InconsistentTypeHierarchyException': {   'source_file': 'nltk\\nltk\\sem\\logic.py'},
    'IncrementalBottomUpChartParser': {   'source_file': 'nltk\\nltk\\parse\\earleychart.py'},
    'IncrementalBottomUpLeftCornerChartParser': {   'source_file': 'nltk\\nltk\\parse\\earleychart.py'},
    'IncrementalChart': {'source_file': 'nltk\\nltk\\parse\\earleychart.py'},
    'IncrementalChartParser': {   'source_file': 'nltk\\nltk\\parse\\earleychart.py'},
    'IncrementalLeftCornerChartParser': {   'source_file': 'nltk\\nltk\\parse\\earleychart.py'},
    'IncrementalTopDownChartParser': {   'source_file': 'nltk\\nltk\\parse\\earleychart.py'},
    'Index': {'source_file': 'nltk\\nltk\\util.py'},
    'IndianCorpusReader': {   'source_file': 'nltk\\nltk\\corpus\\reader\\indian.py'},
    'IndianCorpusView': {   'source_file': 'nltk\\nltk\\corpus\\reader\\indian.py'},
    'IndividualVariableExpression': {   'source_file': 'nltk\\nltk\\sem\\logic.py'},
    'InsideChartParser': {'source_file': 'nltk\\nltk\\parse\\pchart.py'},
    'InstantiateVarsChart': {   'source_file': 'nltk\\nltk\\parse\\featurechart.py'},
    'InterpolatedLanguageModel': {'source_file': 'nltk\\nltk\\lm\\models.py'},
    'IotaExpression': {'source_file': 'nltk\\nltk\\sem\\logic.py'},
    'ItalianStemmer': {'source_file': 'nltk\\nltk\\stem\\snowball.py'},
    'JSONTaggedDecoder': {'source_file': 'nltk\\nltk\\jsontags.py'},
    'JSONTaggedEncoder': {'source_file': 'nltk\\nltk\\jsontags.py'},
    'KMeansClusterer': {'source_file': 'nltk\\nltk\\cluster\\kmeans.py'},
    'KNBCorpusReader': {'source_file': 'nltk\\nltk\\corpus\\reader\\knbc.py'},
    'KneserNey': {'source_file': 'nltk\\nltk\\lm\\smoothing.py'},
    'KneserNeyInterpolated': {'source_file': 'nltk\\nltk\\lm\\models.py'},
    'KneserNeyProbDist': {'source_file': 'nltk\\nltk\\probability.py'},
    'LambdaExpression': {'source_file': 'nltk\\nltk\\sem\\logic.py'},
    'LancasterStemmer': {'source_file': 'nltk\\nltk\\stem\\lancaster.py'},
    'LanguageModel': {'source_file': 'nltk\\nltk\\lm\\api.py'},
    'Laplace': {'source_file': 'nltk\\nltk\\lm\\models.py'},
    'LaplaceProbDist': {'source_file': 'nltk\\nltk\\probability.py'},
    'LazyConcatenation': {'source_file': 'nltk\\nltk\\collections.py'},
    'LazyCorpusLoader': {'source_file': 'nltk\\nltk\\corpus\\util.py'},
    'LazyEnumerate': {'source_file': 'nltk\\nltk\\collections.py'},
    'LazyIteratorList': {'source_file': 'nltk\\nltk\\collections.py'},
    'LazyLoader': {'source_file': 'nltk\\nltk\\data.py'},
    'LazyMap': {'source_file': 'nltk\\nltk\\collections.py'},
    'LazyModule': {'source_file': 'nltk\\nltk\\lazyimport.py'},
    'LazySubsequence': {'source_file': 'nltk\\nltk\\collections.py'},
    'LazyZip': {'source_file': 'nltk\\nltk\\collections.py'},
    'LeafEdge': {'source_file': 'nltk\\nltk\\parse\\chart.py'},
    'LeafInitRule': {'source_file': 'nltk\\nltk\\parse\\chart.py'},
    'LeftCornerChartParser': {'source_file': 'nltk\\nltk\\parse\\chart.py'},
    'LegalitySyllableTokenizer': {   'source_file': 'nltk\\nltk\\tokenize\\legality_principle.py'},
    'Lemma': {'source_file': 'nltk\\nltk\\corpus\\reader\\wordnet.py'},
    'Lidstone': {'source_file': 'nltk\\nltk\\lm\\models.py'},
    'LidstoneProbDist': {'source_file': 'nltk\\nltk\\probability.py'},
    'LinThesaurusCorpusReader': {   'source_file': 'nltk\\nltk\\corpus\\reader\\lin.py'},
    'LineTokenizer': {'source_file': 'nltk\\nltk\\tokenize\\simple.py'},
    'LinearLogicParser': {'source_file': 'nltk\\nltk\\sem\\linearlogic.py'},
    'LocalTimezoneOffsetWithUTC': {   'source_file': 'nltk\\nltk\\twitter\\api.py'},
    'LogicParser': {'source_file': 'nltk\\nltk\\sem\\logic.py'},
    'LogicalExpressionException': {'source_file': 'nltk\\nltk\\sem\\logic.py'},
    'LongestChartParser': {'source_file': 'nltk\\nltk\\parse\\pchart.py'},
    'MLE': {'source_file': 'nltk\\nltk\\lm\\models.py'},
    'MLEProbDist': {'source_file': 'nltk\\nltk\\probability.py'},
    'MTECorpusReader': {'source_file': 'nltk\\nltk\\corpus\\reader\\mte.py'},
    'MTECorpusView': {'source_file': 'nltk\\nltk\\corpus\\reader\\mte.py'},
    'MTEFileReader': {'source_file': 'nltk\\nltk\\corpus\\reader\\mte.py'},
    'MTETagConverter': {'source_file': 'nltk\\nltk\\corpus\\reader\\mte.py'},
    'MWAPPDBCorpusReader': {   'source_file': 'nltk\\nltk\\corpus\\reader\\wordlist.py'},
    'MWETokenizer': {'source_file': 'nltk\\nltk\\tokenize\\mwe.py'},
    'MacMorphoCorpusReader': {   'source_file': 'nltk\\nltk\\corpus\\reader\\tagged.py'},
    'Mace': {'source_file': 'nltk\\nltk\\inference\\mace.py'},
    'MaceCommand': {'source_file': 'nltk\\nltk\\inference\\mace.py'},
    'MaltParser': {'source_file': 'nltk\\nltk\\parse\\malt.py'},
    'MaxentClassifier': {'source_file': 'nltk\\nltk\\classify\\maxent.py'},
    'MaxentFeatureEncodingI': {   'source_file': 'nltk\\nltk\\classify\\maxent.py'},
    'Meaning': {'source_file': 'nltk\\nltk\\corpus\\reader\\panlex_lite.py'},
    'MergeRule': {'source_file': 'nltk\\nltk\\chunk\\regexp.py'},
    'MinimalSet': {'source_file': 'nltk\\nltk\\misc\\minimalset.py'},
    'Model': {'source_file': 'nltk\\nltk\\sem\\evaluate.py'},
    'Model2Counts': {'source_file': 'nltk\\nltk\\translate\\ibm2.py'},
    'Model3Counts': {'source_file': 'nltk\\nltk\\translate\\ibm3.py'},
    'Model4Counts': {'source_file': 'nltk\\nltk\\translate\\ibm4.py'},
    'Model5Counts': {'source_file': 'nltk\\nltk\\translate\\ibm5.py'},
    'ModelBuilder': {'source_file': 'nltk\\nltk\\inference\\api.py'},
    'ModelBuilderCommand': {'source_file': 'nltk\\nltk\\inference\\api.py'},
    'ModelBuilderCommandDecorator': {   'source_file': 'nltk\\nltk\\inference\\api.py'},
    'MultiClassifierI': {'source_file': 'nltk\\nltk\\classify\\api.py'},
    'MultiListbox': {'source_file': 'nltk\\nltk\\draw\\table.py'},
    'MultiParentedTree': {'source_file': 'nltk\\nltk\\tree\\parented.py'},
    'MutableOptionMenu': {'source_file': 'nltk\\nltk\\draw\\util.py'},
    'MutableProbDist': {'source_file': 'nltk\\nltk\\probability.py'},
    'MyServerHandler': {'source_file': 'nltk\\nltk\\app\\wordnet_app.py'},
    'NEChunkParser': {'source_file': 'nltk\\nltk\\chunk\\named_entity.py'},
    'NEChunkParserTagger': {   'source_file': 'nltk\\nltk\\chunk\\named_entity.py'},
    'NISTTokenizer': {'source_file': 'nltk\\nltk\\tokenize\\nist.py'},
    'NKJPCorpusReader': {'source_file': 'nltk\\nltk\\corpus\\reader\\nkjp.py'},
    'NKJPCorpus_Header_View': {   'source_file': 'nltk\\nltk\\corpus\\reader\\nkjp.py'},
    'NKJPCorpus_Morph_View': {   'source_file': 'nltk\\nltk\\corpus\\reader\\nkjp.py'},
    'NKJPCorpus_Segmentation_View': {   'source_file': 'nltk\\nltk\\corpus\\reader\\nkjp.py'},
    'NKJPCorpus_Text_View': {   'source_file': 'nltk\\nltk\\corpus\\reader\\nkjp.py'},
    'NLTKWordTokenizer': {   'source_file': 'nltk\\nltk\\tokenize\\destructive.py'},
    'NPSChatCorpusReader': {   'source_file': 'nltk\\nltk\\corpus\\reader\\nps_chat.py'},
    'NaiveBayesClassifier': {   'source_file': 'nltk\\nltk\\classify\\naivebayes.py'},
    'NaiveBayesDependencyScorer': {   'source_file': 'nltk\\nltk\\parse\\nonprojectivedependencyparser.py'},
    'NegatedExpression': {'source_file': 'nltk\\nltk\\sem\\logic.py'},
    'NgramAssocMeasures': {   'source_file': 'nltk\\nltk\\metrics\\association.py'},
    'NgramCounter': {'source_file': 'nltk\\nltk\\lm\\counter.py'},
    'NgramTagger': {'source_file': 'nltk\\nltk\\tag\\sequential.py'},
    'NltkDrtBoxerDrsInterpreter': {'source_file': 'nltk\\nltk\\sem\\boxer.py'},
    'NombankChainTreePointer': {   'source_file': 'nltk\\nltk\\corpus\\reader\\nombank.py'},
    'NombankCorpusReader': {   'source_file': 'nltk\\nltk\\corpus\\reader\\nombank.py'},
    'NombankInstance': {   'source_file': 'nltk\\nltk\\corpus\\reader\\nombank.py'},
    'NombankPointer': {'source_file': 'nltk\\nltk\\corpus\\reader\\nombank.py'},
    'NombankSplitTreePointer': {   'source_file': 'nltk\\nltk\\corpus\\reader\\nombank.py'},
    'NombankTreePointer': {   'source_file': 'nltk\\nltk\\corpus\\reader\\nombank.py'},
    'NonbreakingPrefixesCorpusReader': {   'source_file': 'nltk\\nltk\\corpus\\reader\\wordlist.py'},
    'NonprojectiveDependencyParser': {   'source_file': 'nltk\\nltk\\parse\\nonprojectivedependencyparser.py'},
    'Nonterminal': {'source_file': 'nltk\\nltk\\grammar.py'},
    'NorwegianStemmer': {'source_file': 'nltk\\nltk\\stem\\snowball.py'},
    'OpenOnDemandZipFile': {'source_file': 'nltk\\nltk\\data.py'},
    'OpinionLexiconCorpusReader': {   'source_file': 'nltk\\nltk\\corpus\\reader\\opinion_lexicon.py'},
    'OrExpression': {'source_file': 'nltk\\nltk\\sem\\logic.py'},
    'OrderedDict': {'source_file': 'nltk\\nltk\\collections.py'},
    'OvalWidget': {'source_file': 'nltk\\nltk\\draw\\util.py'},
    'PCFG': {'source_file': 'nltk\\nltk\\grammar.py'},
    'PPAttachment': {'source_file': 'nltk\\nltk\\corpus\\reader\\ppattach.py'},
    'PPAttachmentCorpusReader': {   'source_file': 'nltk\\nltk\\corpus\\reader\\ppattach.py'},
    'Package': {'source_file': 'nltk\\nltk\\downloader.py'},
    'Paice': {'source_file': 'nltk\\nltk\\metrics\\paice.py'},
    'PanLexLiteCorpusReader': {   'source_file': 'nltk\\nltk\\corpus\\reader\\panlex_lite.py'},
    'PanlexSwadeshCorpusReader': {   'source_file': 'nltk\\nltk\\corpus\\reader\\panlex_swadesh.py'},
    'ParallelProverBuilder': {'source_file': 'nltk\\nltk\\inference\\api.py'},
    'ParallelProverBuilderCommand': {   'source_file': 'nltk\\nltk\\inference\\api.py'},
    'ParenWidget': {'source_file': 'nltk\\nltk\\draw\\util.py'},
    'ParentedTree': {'source_file': 'nltk\\nltk\\tree\\parented.py'},
    'ParserI': {'source_file': 'nltk\\nltk\\parse\\api.py'},
    'PassthroughBoxerDrsInterpreter': {   'source_file': 'nltk\\nltk\\sem\\boxer.py'},
    'PathPointer': {'source_file': 'nltk\\nltk\\data.py'},
    'PerceptronTagger': {'source_file': 'nltk\\nltk\\tag\\perceptron.py'},
    'PhraseTable': {'source_file': 'nltk\\nltk\\translate\\api.py'},
    'PickleCorpusView': {'source_file': 'nltk\\nltk\\corpus\\reader\\util.py'},
    'Pl196xCorpusReader': {   'source_file': 'nltk\\nltk\\corpus\\reader\\pl196x.py'},
    'PlaintextCorpusReader': {   'source_file': 'nltk\\nltk\\corpus\\reader\\plaintext.py'},
    'PorterStemmer': {'source_file': 'nltk\\nltk\\stem\\porter.py'},
    'PortugueseCategorizedPlaintextCorpusReader': {   'source_file': 'nltk\\nltk\\corpus\\reader\\plaintext.py'},
    'PortugueseStemmer': {'source_file': 'nltk\\nltk\\stem\\snowball.py'},
    'Pos': {'source_file': 'nltk\\nltk\\tag\\brill.py'},
    'PositiveNaiveBayesClassifier': {   'source_file': 'nltk\\nltk\\classify\\positivenaivebayes.py'},
    'PossibleAntecedents': {'source_file': 'nltk\\nltk\\sem\\drt.py'},
    'PredHolder': {'source_file': 'nltk\\nltk\\inference\\nonmonotonic.py'},
    'PrettyDict': {'source_file': 'nltk\\nltk\\corpus\\reader\\framenet.py'},
    'PrettyLazyConcatenation': {   'source_file': 'nltk\\nltk\\corpus\\reader\\framenet.py'},
    'PrettyLazyIteratorList': {   'source_file': 'nltk\\nltk\\corpus\\reader\\framenet.py'},
    'PrettyLazyMap': {'source_file': 'nltk\\nltk\\corpus\\reader\\framenet.py'},
    'PrettyList': {'source_file': 'nltk\\nltk\\corpus\\reader\\framenet.py'},
    'PrimitiveCategory': {'source_file': 'nltk\\nltk\\ccg\\api.py'},
    'ProbDistI': {'source_file': 'nltk\\nltk\\probability.py'},
    'ProbabilisticBottomUpInitRule': {   'source_file': 'nltk\\nltk\\parse\\pchart.py'},
    'ProbabilisticBottomUpPredictRule': {   'source_file': 'nltk\\nltk\\parse\\pchart.py'},
    'ProbabilisticDependencyGrammar': {'source_file': 'nltk\\nltk\\grammar.py'},
    'ProbabilisticFundamentalRule': {   'source_file': 'nltk\\nltk\\parse\\pchart.py'},
    'ProbabilisticLeafEdge': {'source_file': 'nltk\\nltk\\parse\\pchart.py'},
    'ProbabilisticMixIn': {'source_file': 'nltk\\nltk\\probability.py'},
    'ProbabilisticNonprojectiveParser': {   'source_file': 'nltk\\nltk\\parse\\nonprojectivedependencyparser.py'},
    'ProbabilisticProduction': {'source_file': 'nltk\\nltk\\grammar.py'},
    'ProbabilisticProjectiveDependencyParser': {   'source_file': 'nltk\\nltk\\parse\\projectivedependencyparser.py'},
    'ProbabilisticTree': {'source_file': 'nltk\\nltk\\tree\\probabilistic.py'},
    'ProbabilisticTreeEdge': {'source_file': 'nltk\\nltk\\parse\\pchart.py'},
    'Production': {'source_file': 'nltk\\nltk\\grammar.py'},
    'ProgressMessage': {'source_file': 'nltk\\nltk\\downloader.py'},
    'ProjectiveDependencyParser': {   'source_file': 'nltk\\nltk\\parse\\projectivedependencyparser.py'},
    'PropbankChainTreePointer': {   'source_file': 'nltk\\nltk\\corpus\\reader\\propbank.py'},
    'PropbankCorpusReader': {   'source_file': 'nltk\\nltk\\corpus\\reader\\propbank.py'},
    'PropbankInflection': {   'source_file': 'nltk\\nltk\\corpus\\reader\\propbank.py'},
    'PropbankInstance': {   'source_file': 'nltk\\nltk\\corpus\\reader\\propbank.py'},
    'PropbankPointer': {   'source_file': 'nltk\\nltk\\corpus\\reader\\propbank.py'},
    'PropbankSplitTreePointer': {   'source_file': 'nltk\\nltk\\corpus\\reader\\propbank.py'},
    'PropbankTreePointer': {   'source_file': 'nltk\\nltk\\corpus\\reader\\propbank.py'},
    'ProsConsCorpusReader': {   'source_file': 'nltk\\nltk\\corpus\\reader\\pros_cons.py'},
    'Prover': {'source_file': 'nltk\\nltk\\inference\\api.py'},
    'Prover9': {'source_file': 'nltk\\nltk\\inference\\prover9.py'},
    'Prover9Command': {'source_file': 'nltk\\nltk\\inference\\prover9.py'},
    'Prover9CommandParent': {   'source_file': 'nltk\\nltk\\inference\\prover9.py'},
    'Prover9Exception': {'source_file': 'nltk\\nltk\\inference\\prover9.py'},
    'Prover9Parent': {'source_file': 'nltk\\nltk\\inference\\prover9.py'},
    'ProverCommand': {'source_file': 'nltk\\nltk\\inference\\api.py'},
    'ProverCommandDecorator': {'source_file': 'nltk\\nltk\\inference\\api.py'},
    'PunktBaseClass': {'source_file': 'nltk\\nltk\\tokenize\\punkt.py'},
    'PunktLanguageVars': {'source_file': 'nltk\\nltk\\tokenize\\punkt.py'},
    'PunktParameters': {'source_file': 'nltk\\nltk\\tokenize\\punkt.py'},
    'PunktSentenceTokenizer': {'source_file': 'nltk\\nltk\\tokenize\\punkt.py'},
    'PunktToken': {'source_file': 'nltk\\nltk\\tokenize\\punkt.py'},
    'PunktTrainer': {'source_file': 'nltk\\nltk\\tokenize\\punkt.py'},
    'QuadgramCollocationFinder': {'source_file': 'nltk\\nltk\\collocations.py'},
    'QuantifiedExpression': {'source_file': 'nltk\\nltk\\sem\\logic.py'},
    'Query': {'source_file': 'nltk\\nltk\\twitter\\twitterclient.py'},
    'RSLPStemmer': {'source_file': 'nltk\\nltk\\stem\\rslp.py'},
    'RTECorpusReader': {'source_file': 'nltk\\nltk\\corpus\\reader\\rte.py'},
    'RTEFeatureExtractor': {   'source_file': 'nltk\\nltk\\classify\\rte_classify.py'},
    'RTEPair': {'source_file': 'nltk\\nltk\\corpus\\reader\\rte.py'},
    'RandomChartParser': {'source_file': 'nltk\\nltk\\parse\\pchart.py'},
    'RandomProbDist': {'source_file': 'nltk\\nltk\\probability.py'},
    'RangeFeature': {'source_file': 'nltk\\nltk\\featstruct.py'},
    'ReadError': {'source_file': 'nltk\\nltk\\internals.py'},
    'ReadingCommand': {'source_file': 'nltk\\nltk\\inference\\discourse.py'},
    'RecursiveDescentApp': {'source_file': 'nltk\\nltk\\app\\rdparser_app.py'},
    'RecursiveDescentParser': {   'source_file': 'nltk\\nltk\\parse\\recursivedescent.py'},
    'Reference': {'source_file': 'nltk\\nltk\\app\\wordnet_app.py'},
    'RegexpChunkApp': {'source_file': 'nltk\\nltk\\app\\chunkparser_app.py'},
    'RegexpChunkParser': {'source_file': 'nltk\\nltk\\chunk\\regexp.py'},
    'RegexpChunkRule': {'source_file': 'nltk\\nltk\\chunk\\regexp.py'},
    'RegexpParser': {'source_file': 'nltk\\nltk\\chunk\\regexp.py'},
    'RegexpStemmer': {'source_file': 'nltk\\nltk\\stem\\regexp.py'},
    'RegexpTagger': {'source_file': 'nltk\\nltk\\tag\\sequential.py'},
    'RegexpTokenizer': {'source_file': 'nltk\\nltk\\tokenize\\regexp.py'},
    'ReplaceZone': {'source_file': 'nltk\\nltk\\app\\nemo_app.py'},
    'ReppTokenizer': {'source_file': 'nltk\\nltk\\tokenize\\repp.py'},
    'ResolutionProverCommand': {   'source_file': 'nltk\\nltk\\inference\\resolution.py'},
    'Review': {'source_file': 'nltk\\nltk\\corpus\\reader\\reviews.py'},
    'ReviewLine': {'source_file': 'nltk\\nltk\\corpus\\reader\\reviews.py'},
    'ReviewsCorpusReader': {   'source_file': 'nltk\\nltk\\corpus\\reader\\reviews.py'},
    'RomanianStemmer': {'source_file': 'nltk\\nltk\\stem\\snowball.py'},
    'Rule': {'source_file': 'nltk\\nltk\\tbl\\rule.py'},
    'RussianStemmer': {'source_file': 'nltk\\nltk\\stem\\snowball.py'},
    'SExprTokenizer': {'source_file': 'nltk\\nltk\\tokenize\\sexpr.py'},
    'ScannerRule': {'source_file': 'nltk\\nltk\\parse\\earleychart.py'},
    'ScrollWatcherWidget': {'source_file': 'nltk\\nltk\\draw\\util.py'},
    'SeekableUnicodeStreamReader': {'source_file': 'nltk\\nltk\\data.py'},
    'SelectDownloadDirMessage': {'source_file': 'nltk\\nltk\\downloader.py'},
    'SemcorCorpusReader': {   'source_file': 'nltk\\nltk\\corpus\\reader\\semcor.py'},
    'SemcorSentence': {'source_file': 'nltk\\nltk\\corpus\\reader\\semcor.py'},
    'SemcorWordView': {'source_file': 'nltk\\nltk\\corpus\\reader\\semcor.py'},
    'Senna': {'source_file': 'nltk\\nltk\\classify\\senna.py'},
    'SennaChunkTagger': {'source_file': 'nltk\\nltk\\tag\\senna.py'},
    'SennaNERTagger': {'source_file': 'nltk\\nltk\\tag\\senna.py'},
    'SennaTagger': {'source_file': 'nltk\\nltk\\tag\\senna.py'},
    'SensevalCorpusReader': {   'source_file': 'nltk\\nltk\\corpus\\reader\\senseval.py'},
    'SensevalCorpusView': {   'source_file': 'nltk\\nltk\\corpus\\reader\\senseval.py'},
    'SensevalInstance': {   'source_file': 'nltk\\nltk\\corpus\\reader\\senseval.py'},
    'SentiSynset': {   'source_file': 'nltk\\nltk\\corpus\\reader\\sentiwordnet.py'},
    'SentiText': {'source_file': 'nltk\\nltk\\sentiment\\vader.py'},
    'SentiWordNetCorpusReader': {   'source_file': 'nltk\\nltk\\corpus\\reader\\sentiwordnet.py'},
    'SentimentAnalyzer': {   'source_file': 'nltk\\nltk\\sentiment\\sentiment_analyzer.py'},
    'SentimentIntensityAnalyzer': {   'source_file': 'nltk\\nltk\\sentiment\\vader.py'},
    'SequenceWidget': {'source_file': 'nltk\\nltk\\draw\\util.py'},
    'SequentialBackoffTagger': {   'source_file': 'nltk\\nltk\\tag\\sequential.py'},
    'SetHolder': {'source_file': 'nltk\\nltk\\inference\\nonmonotonic.py'},
    'ShiftReduceApp': {'source_file': 'nltk\\nltk\\app\\srparser_app.py'},
    'ShiftReduceParser': {'source_file': 'nltk\\nltk\\parse\\shiftreduce.py'},
    'ShowText': {'source_file': 'nltk\\nltk\\draw\\util.py'},
    'SimpleGoodTuringProbDist': {'source_file': 'nltk\\nltk\\probability.py'},
    'SingleEdgeFundamentalRule': {'source_file': 'nltk\\nltk\\parse\\chart.py'},
    'SingleEdgeProbabilisticFundamentalRule': {   'source_file': 'nltk\\nltk\\parse\\pchart.py'},
    'SklearnClassifier': {   'source_file': 'nltk\\nltk\\classify\\scikitlearn.py'},
    'SlashFeature': {'source_file': 'nltk\\nltk\\featstruct.py'},
    'Slots': {'source_file': 'nltk\\nltk\\translate\\ibm5.py'},
    'Smoothing': {'source_file': 'nltk\\nltk\\lm\\api.py'},
    'SmoothingFunction': {   'source_file': 'nltk\\nltk\\translate\\bleu_score.py'},
    'SnowballStemmer': {'source_file': 'nltk\\nltk\\stem\\snowball.py'},
    'SpaceWidget': {'source_file': 'nltk\\nltk\\draw\\util.py'},
    'SpanishStemmer': {'source_file': 'nltk\\nltk\\stem\\snowball.py'},
    'SpeakerInfo': {'source_file': 'nltk\\nltk\\corpus\\reader\\timit.py'},
    'SpecialList': {'source_file': 'nltk\\nltk\\corpus\\reader\\framenet.py'},
    'SplitRule': {'source_file': 'nltk\\nltk\\chunk\\regexp.py'},
    'StackDecoder': {'source_file': 'nltk\\nltk\\translate\\stack_decoder.py'},
    'StackWidget': {'source_file': 'nltk\\nltk\\draw\\util.py'},
    'StaleMessage': {'source_file': 'nltk\\nltk\\downloader.py'},
    'StandardFormat': {'source_file': 'nltk\\nltk\\toolbox.py'},
    'StanfordDependencyParser': {   'source_file': 'nltk\\nltk\\parse\\stanford.py'},
    'StanfordNERTagger': {'source_file': 'nltk\\nltk\\tag\\stanford.py'},
    'StanfordNeuralDependencyParser': {   'source_file': 'nltk\\nltk\\parse\\stanford.py'},
    'StanfordPOSTagger': {'source_file': 'nltk\\nltk\\tag\\stanford.py'},
    'StanfordParser': {'source_file': 'nltk\\nltk\\parse\\stanford.py'},
    'StanfordSegmenter': {   'source_file': 'nltk\\nltk\\tokenize\\stanford_segmenter.py'},
    'StanfordTagger': {'source_file': 'nltk\\nltk\\tag\\stanford.py'},
    'StanfordTokenizer': {'source_file': 'nltk\\nltk\\tokenize\\stanford.py'},
    'StartCollectionMessage': {'source_file': 'nltk\\nltk\\downloader.py'},
    'StartDownloadMessage': {'source_file': 'nltk\\nltk\\downloader.py'},
    'StartPackageMessage': {'source_file': 'nltk\\nltk\\downloader.py'},
    'StartUnzipMessage': {'source_file': 'nltk\\nltk\\downloader.py'},
    'StemmerI': {'source_file': 'nltk\\nltk\\stem\\api.py'},
    'SteppingChartParser': {'source_file': 'nltk\\nltk\\parse\\chart.py'},
    'SteppingRecursiveDescentParser': {   'source_file': 'nltk\\nltk\\parse\\recursivedescent.py'},
    'SteppingShiftReduceParser': {   'source_file': 'nltk\\nltk\\parse\\shiftreduce.py'},
    'StreamBackedCorpusView': {   'source_file': 'nltk\\nltk\\corpus\\reader\\util.py'},
    'Streamer': {'source_file': 'nltk\\nltk\\twitter\\twitterclient.py'},
    'StringCategoryCorpusReader': {   'source_file': 'nltk\\nltk\\corpus\\reader\\string_category.py'},
    'StringTokenizer': {'source_file': 'nltk\\nltk\\tokenize\\api.py'},
    'StripRule': {'source_file': 'nltk\\nltk\\chunk\\regexp.py'},
    'StupidBackoff': {'source_file': 'nltk\\nltk\\lm\\models.py'},
    'SubstituteBindingsI': {'source_file': 'nltk\\nltk\\sem\\logic.py'},
    'SubstituteBindingsSequence': {'source_file': 'nltk\\nltk\\featstruct.py'},
    'SvmClassifier': {'source_file': 'nltk\\nltk\\classify\\svm.py'},
    'SwadeshCorpusReader': {   'source_file': 'nltk\\nltk\\corpus\\reader\\wordlist.py'},
    'SwedishStemmer': {'source_file': 'nltk\\nltk\\stem\\snowball.py'},
    'SwitchboardCorpusReader': {   'source_file': 'nltk\\nltk\\corpus\\reader\\switchboard.py'},
    'SwitchboardTurn': {   'source_file': 'nltk\\nltk\\corpus\\reader\\switchboard.py'},
    'SyllableTokenizer': {   'source_file': 'nltk\\nltk\\tokenize\\sonority_sequencing.py'},
    'SymbolWidget': {'source_file': 'nltk\\nltk\\draw\\util.py'},
    'Synset': {'source_file': 'nltk\\nltk\\corpus\\reader\\wordnet.py'},
    'SyntaxCorpusReader': {'source_file': 'nltk\\nltk\\corpus\\reader\\api.py'},
    'TEICorpusView': {'source_file': 'nltk\\nltk\\corpus\\reader\\pl196x.py'},
    'Table': {'source_file': 'nltk\\nltk\\draw\\table.py'},
    'TableauProver': {'source_file': 'nltk\\nltk\\inference\\tableau.py'},
    'TableauProverCommand': {   'source_file': 'nltk\\nltk\\inference\\tableau.py'},
    'TadmEventMaxentFeatureEncoding': {   'source_file': 'nltk\\nltk\\classify\\maxent.py'},
    'TadmMaxentClassifier': {'source_file': 'nltk\\nltk\\classify\\maxent.py'},
    'TagRule': {'source_file': 'nltk\\nltk\\tbl\\rule.py'},
    'TaggedCorpusReader': {   'source_file': 'nltk\\nltk\\corpus\\reader\\tagged.py'},
    'TaggedCorpusView': {   'source_file': 'nltk\\nltk\\corpus\\reader\\tagged.py'},
    'TaggerI': {'source_file': 'nltk\\nltk\\tag\\api.py'},
    'Template': {'source_file': 'nltk\\nltk\\tbl\\template.py'},
    'TestGrammar': {'source_file': 'nltk\\nltk\\parse\\util.py'},
    'Text': {'source_file': 'nltk\\nltk\\text.py'},
    'TextCat': {'source_file': 'nltk\\nltk\\classify\\textcat.py'},
    'TextCollection': {'source_file': 'nltk\\nltk\\text.py'},
    'TextTilingTokenizer': {   'source_file': 'nltk\\nltk\\tokenize\\texttiling.py'},
    'TextWidget': {'source_file': 'nltk\\nltk\\draw\\util.py'},
    'TheoremToolCommand': {'source_file': 'nltk\\nltk\\inference\\api.py'},
    'TheoremToolCommandDecorator': {   'source_file': 'nltk\\nltk\\inference\\api.py'},
    'TheoremToolThread': {'source_file': 'nltk\\nltk\\inference\\api.py'},
    'TimitCorpusReader': {   'source_file': 'nltk\\nltk\\corpus\\reader\\timit.py'},
    'TimitTaggedCorpusReader': {   'source_file': 'nltk\\nltk\\corpus\\reader\\tagged.py'},
    'TnT': {'source_file': 'nltk\\nltk\\tag\\tnt.py'},
    'Token': {'source_file': 'nltk\\nltk\\ccg\\lexicon.py'},
    'TokenSearcher': {'source_file': 'nltk\\nltk\\text.py'},
    'TokenSequence': {'source_file': 'nltk\\nltk\\tokenize\\texttiling.py'},
    'TokenTableField': {'source_file': 'nltk\\nltk\\tokenize\\texttiling.py'},
    'TokenizerI': {'source_file': 'nltk\\nltk\\tokenize\\api.py'},
    'ToktokTokenizer': {'source_file': 'nltk\\nltk\\tokenize\\toktok.py'},
    'ToolboxCorpusReader': {   'source_file': 'nltk\\nltk\\corpus\\reader\\toolbox.py'},
    'ToolboxData': {'source_file': 'nltk\\nltk\\toolbox.py'},
    'ToolboxSettings': {'source_file': 'nltk\\nltk\\toolbox.py'},
    'TopDownChartParser': {'source_file': 'nltk\\nltk\\parse\\chart.py'},
    'TopDownInitRule': {'source_file': 'nltk\\nltk\\parse\\chart.py'},
    'TopDownPredictRule': {'source_file': 'nltk\\nltk\\parse\\chart.py'},
    'Transition': {'source_file': 'nltk\\nltk\\parse\\transitionparser.py'},
    'TransitionParser': {   'source_file': 'nltk\\nltk\\parse\\transitionparser.py'},
    'Tree': {'source_file': 'nltk\\nltk\\tree\\tree.py'},
    'TreeEdge': {'source_file': 'nltk\\nltk\\parse\\chart.py'},
    'TreePrettyPrinter': {'source_file': 'nltk\\nltk\\tree\\prettyprinter.py'},
    'TreeSegmentWidget': {'source_file': 'nltk\\nltk\\draw\\tree.py'},
    'TreeView': {'source_file': 'nltk\\nltk\\draw\\tree.py'},
    'TreeWidget': {'source_file': 'nltk\\nltk\\draw\\tree.py'},
    'TreebankWordDetokenizer': {   'source_file': 'nltk\\nltk\\tokenize\\treebank.py'},
    'TreebankWordTokenizer': {   'source_file': 'nltk\\nltk\\tokenize\\treebank.py'},
    'Trie': {'source_file': 'nltk\\nltk\\collections.py'},
    'TrigramCollocationFinder': {'source_file': 'nltk\\nltk\\collocations.py'},
    'TrigramTagger': {'source_file': 'nltk\\nltk\\tag\\sequential.py'},
    'TruthValueType': {'source_file': 'nltk\\nltk\\sem\\logic.py'},
    'TweetHandlerI': {'source_file': 'nltk\\nltk\\twitter\\api.py'},
    'TweetTokenizer': {'source_file': 'nltk\\nltk\\tokenize\\casual.py'},
    'TweetViewer': {'source_file': 'nltk\\nltk\\twitter\\twitterclient.py'},
    'TweetWriter': {'source_file': 'nltk\\nltk\\twitter\\twitterclient.py'},
    'Twitter': {'source_file': 'nltk\\nltk\\twitter\\twitterclient.py'},
    'TwitterCorpusReader': {   'source_file': 'nltk\\nltk\\corpus\\reader\\twitter.py'},
    'Type': {'source_file': 'nltk\\nltk\\sem\\logic.py'},
    'TypeException': {'source_file': 'nltk\\nltk\\sem\\logic.py'},
    'TypeResolutionException': {'source_file': 'nltk\\nltk\\sem\\logic.py'},
    'TypedMaxentFeatureEncoding': {   'source_file': 'nltk\\nltk\\classify\\maxent.py'},
    'UdhrCorpusReader': {'source_file': 'nltk\\nltk\\corpus\\reader\\udhr.py'},
    'UnChunkRule': {'source_file': 'nltk\\nltk\\chunk\\regexp.py'},
    'UndirectedBinaryCombinator': {   'source_file': 'nltk\\nltk\\ccg\\combinator.py'},
    'UndirectedComposition': {'source_file': 'nltk\\nltk\\ccg\\combinator.py'},
    'UndirectedFunctionApplication': {   'source_file': 'nltk\\nltk\\ccg\\combinator.py'},
    'UndirectedSubstitution': {'source_file': 'nltk\\nltk\\ccg\\combinator.py'},
    'UndirectedTypeRaise': {'source_file': 'nltk\\nltk\\ccg\\combinator.py'},
    'UnexpectedTokenException': {'source_file': 'nltk\\nltk\\sem\\logic.py'},
    'UnicharsCorpusReader': {   'source_file': 'nltk\\nltk\\corpus\\reader\\wordlist.py'},
    'UnificationException': {'source_file': 'nltk\\nltk\\sem\\linearlogic.py'},
    'UniformProbDist': {'source_file': 'nltk\\nltk\\probability.py'},
    'UnigramTagger': {'source_file': 'nltk\\nltk\\tag\\sequential.py'},
    'UniqueNamesProver': {   'source_file': 'nltk\\nltk\\inference\\nonmonotonic.py'},
    'UnsortedChartParser': {'source_file': 'nltk\\nltk\\parse\\pchart.py'},
    'UpToDateMessage': {'source_file': 'nltk\\nltk\\downloader.py'},
    'VaderConstants': {'source_file': 'nltk\\nltk\\sentiment\\vader.py'},
    'Valuation': {'source_file': 'nltk\\nltk\\sem\\evaluate.py'},
    'Variable': {'source_file': 'nltk\\nltk\\sem\\logic.py'},
    'VariableBinderExpression': {'source_file': 'nltk\\nltk\\sem\\logic.py'},
    'VariableExpression': {'source_file': 'nltk\\nltk\\sem\\linearlogic.py'},
    'VectorSpaceClusterer': {'source_file': 'nltk\\nltk\\cluster\\util.py'},
    'VerbnetCorpusReader': {   'source_file': 'nltk\\nltk\\corpus\\reader\\verbnet.py'},
    'ViterbiParser': {'source_file': 'nltk\\nltk\\parse\\viterbi.py'},
    'Vocabulary': {'source_file': 'nltk\\nltk\\lm\\vocabulary.py'},
    'WekaClassifier': {'source_file': 'nltk\\nltk\\classify\\weka.py'},
    'WhitespaceTokenizer': {'source_file': 'nltk\\nltk\\tokenize\\regexp.py'},
    'WittenBell': {'source_file': 'nltk\\nltk\\lm\\smoothing.py'},
    'WittenBellInterpolated': {'source_file': 'nltk\\nltk\\lm\\models.py'},
    'WittenBellProbDist': {'source_file': 'nltk\\nltk\\probability.py'},
    'Word': {'source_file': 'nltk\\nltk\\tag\\brill.py'},
    'WordListCorpusReader': {   'source_file': 'nltk\\nltk\\corpus\\reader\\wordlist.py'},
    'WordNetCorpusReader': {   'source_file': 'nltk\\nltk\\corpus\\reader\\wordnet.py'},
    'WordNetICCorpusReader': {   'source_file': 'nltk\\nltk\\corpus\\reader\\wordnet.py'},
    'WordNetLemmatizer': {'source_file': 'nltk\\nltk\\stem\\wordnet.py'},
    'WordPunctTokenizer': {'source_file': 'nltk\\nltk\\tokenize\\regexp.py'},
    'XMLCorpusReader': {   'source_file': 'nltk\\nltk\\corpus\\reader\\xmldocs.py'},
    'XMLCorpusView': {'source_file': 'nltk\\nltk\\corpus\\reader\\xmldocs.py'},
    'XML_Tool': {'source_file': 'nltk\\nltk\\corpus\\reader\\nkjp.py'},
    'YCOECorpusReader': {'source_file': 'nltk\\nltk\\corpus\\reader\\ycoe.py'},
    'YCOETaggedCorpusReader': {   'source_file': 'nltk\\nltk\\corpus\\reader\\ycoe.py'},
    'ZipFilePathPointer': {'source_file': 'nltk\\nltk\\data.py'},
    'Zone': {'source_file': 'nltk\\nltk\\app\\nemo_app.py'},
    '_DendrogramNode': {'source_file': 'nltk\\nltk\\cluster\\util.py'},
    '_Hypothesis': {'source_file': 'nltk\\nltk\\translate\\stack_decoder.py'},
    '_LanguageSpecificStemmer': {   'source_file': 'nltk\\nltk\\stem\\snowball.py'},
    '_Stack': {'source_file': 'nltk\\nltk\\translate\\stack_decoder.py'},
    '_UnificationFailure': {'source_file': 'nltk\\nltk\\featstruct.py'},
    '_WordNetObject': {'source_file': 'nltk\\nltk\\corpus\\reader\\wordnet.py'},
    'nltk': {'source_file': 'nltk\\nltk\\twitter\\util.py'}}
